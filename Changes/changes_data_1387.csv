id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fpuppet-nova~master~I43c03e7d77fba2f5153eac62a73e9f0a45ac5b33,openstack/puppet-nova,master,I43c03e7d77fba2f5153eac62a73e9f0a45ac5b33,Pin rabbit and mysql to major version for fixtures,MERGED,2013-07-24 20:39:30.000000000,2013-07-24 20:44:26.000000000,2013-07-24 20:44:26.000000000,"[{'_account_id': 3}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-07-24 20:39:30.000000000', 'files': ['.fixtures.yml'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/bdd9e7a943bd94e2481ec68c1f73d0a3f666de60', 'message': 'Pin rabbit and mysql to major version for fixtures\n\nPreviously, unit tests were using master for testing.\n\nThis commit changes them to use the newly created major version\nbranches. This allows us to backport bug fixes while we wait for\nupstream to stabilize.\n\nChange-Id: I43c03e7d77fba2f5153eac62a73e9f0a45ac5b33\n'}]",0,38536,bdd9e7a943bd94e2481ec68c1f73d0a3f666de60,5,2,1,2265,,,0,"Pin rabbit and mysql to major version for fixtures

Previously, unit tests were using master for testing.

This commit changes them to use the newly created major version
branches. This allows us to backport bug fixes while we wait for
upstream to stabilize.

Change-Id: I43c03e7d77fba2f5153eac62a73e9f0a45ac5b33
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/36/38536/1 && git format-patch -1 --stdout FETCH_HEAD,['.fixtures.yml'],1,bdd9e7a943bd94e2481ec68c1f73d0a3f666de60,master," ""mysql"": repo: ""git://github.com/puppetlabs/puppetlabs-mysql.git"" ref: ""origin/0.x"" ref: ""origin/2.x"""," ""mysql"": ""git://github.com/puppetlabs/puppetlabs-mysql.git"" ref: 43a000b95b13c62e4fbea14e31bc61929bda1b23",4,2
openstack%2Fopenstack-manuals~master~I973624113d5b18ec8d53f6434a40f7250d91c04d,openstack/openstack-manuals,master,I973624113d5b18ec8d53f6434a40f7250d91c04d,More basic install cleanup,MERGED,2013-07-18 16:23:46.000000000,2013-07-24 20:43:54.000000000,2013-07-24 20:43:54.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 3153}, {'_account_id': 7923}]","[{'number': 1, 'created': '2013-07-18 16:23:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/eeda5568a6ae2735a810c2cb428a3a1b2d6633b5', 'message': ""More basic install cleanup\n\n* Make sure to apply the sysctl settings (restarting the network service\n  isn't enough)\n* Make sure that glance uses keystone for authentication\n* Add a note about lost iptables rules after reboot\n* Be more consistent with docbook tags\n* Be more consistent with spacing\n* Define the my_ip setting for nova nodes (the metadata service might\n  not work properly if not defined)\n\nChange-Id: I973624113d5b18ec8d53f6434a40f7250d91c04d\n""}, {'number': 2, 'created': '2013-07-19 16:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f5f0a3976e132285830512c5a37ad8eb09108051', 'message': ""More basic install cleanup\n\n* Make sure to apply the sysctl settings (restarting the network service\n  isn't enough)\n* Make sure that glance uses keystone for authentication\n* Add a note about lost iptables rules after reboot\n* Be more consistent with docbook tags\n* Be more consistent with spacing\n* Define the my_ip setting for nova nodes (the metadata service might\n  not work properly if not defined)\n* Use the controller IP addres to access horizon\n\nChange-Id: I973624113d5b18ec8d53f6434a40f7250d91c04d\n""}, {'number': 3, 'created': '2013-07-19 17:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/777ca8f3d1cdd3a5a93706c564b60f9adaef9640', 'message': ""More basic install cleanup\n\n* Make sure to apply the sysctl settings (restarting the network service\n  isn't enough)\n* Make sure that glance uses keystone for authentication\n* Add a note about lost iptables rules after reboot\n* Be more consistent with docbook tags\n* Be more consistent with spacing\n* Define the my_ip setting for nova nodes (the metadata service might\n  not work properly if not defined)\n* Use the controller IP addres to access horizon\n\nChange-Id: I973624113d5b18ec8d53f6434a40f7250d91c04d\n""}, {'number': 4, 'created': '2013-07-19 17:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/be131e7df5c1eb25c2757b8e8dafe5e3f5f1b0ee', 'message': ""More basic install cleanup\n\n* Make sure to apply the sysctl settings (restarting the network service\n  isn't enough)\n* Make sure that glance uses keystone for authentication\n* Add a note about lost iptables rules after reboot\n* Be more consistent with docbook tags\n* Be more consistent with spacing\n* Define the my_ip setting for nova nodes (the metadata service might\n  not work properly if not defined)\n* Use the controller IP addres to access horizon\n\nChange-Id: I973624113d5b18ec8d53f6434a40f7250d91c04d\n""}, {'number': 5, 'created': '2013-07-24 20:39:29.000000000', 'files': ['doc/src/docbkx/basic-install/src/basic-install_controller-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-common.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-dashboard.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-common.xml', 'doc/src/docbkx/basic-install/src/bk-basic-install.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-common.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-glance.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-services.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b51d16f71b7e3240a7cb72b2ec890390ad329748', 'message': ""More basic install cleanup\n\n* Make sure to apply the sysctl settings (restarting the network service\n  isn't enough)\n* Make sure that glance uses keystone for authentication\n* Add a note about lost iptables rules after reboot\n* Be more consistent with docbook tags\n* Be more consistent with spacing\n* Define the my_ip setting for nova nodes (the metadata service might\n  not work properly if not defined)\n* Use the controller IP addres to access horizon\n\nChange-Id: I973624113d5b18ec8d53f6434a40f7250d91c04d\n""}]",9,37712,b51d16f71b7e3240a7cb72b2ec890390ad329748,21,5,5,7923,,,0,"More basic install cleanup

* Make sure to apply the sysctl settings (restarting the network service
  isn't enough)
* Make sure that glance uses keystone for authentication
* Add a note about lost iptables rules after reboot
* Be more consistent with docbook tags
* Be more consistent with spacing
* Define the my_ip setting for nova nodes (the metadata service might
  not work properly if not defined)
* Use the controller IP addres to access horizon

Change-Id: I973624113d5b18ec8d53f6434a40f7250d91c04d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/12/37712/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/basic-install/src/basic-install_compute-common.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-dashboard.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-common.xml', 'doc/src/docbkx/basic-install/src/bk-basic-install.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-common.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-glance.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-operating.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-services.xml']",10,eeda5568a6ae2735a810c2cb428a3a1b2d6633b5,basic_install-fixes," quantum-dhcp-agent quantum-l3-agent</userinput></screen> <screen><prompt>#</prompt> <userinput>iptables -A FORWARD -i eth0 -o br-ex -s 10.10.10.0/24 -m conntrack --ctstate NEW -j ACCEPT</userinput> <prompt>#</prompt> <userinput>iptables -A FORWARD -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT</userinput> <prompt>#</prompt> <userinput>iptables -A POSTROUTING -s 10.10.10.0/24 -t nat -j MASQUERADE</userinput></screen></para> <note><para>These rules will be lost on reboot. Make sure to save and restore them using your distribution tools.</para></note>","quantum-dhcp-agent quantum-l3-agent</userinput></screen> <screen><userinput>echo 1 > /proc/sys/net/ipv4/conf/all/forwarding iptables -A FORWARD -i eth0 -o br-ex -s 10.10.10.0/24 -m conntrack --ctstate NEW -j ACCEPT iptables -A FORWARD -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT iptables -A POSTROUTING -s 10.10.10.0/24 -t nat -j MASQUERADE</userinput></screen></para>",40,15
openstack%2Fnova~master~I91ebbf4e046c024fab520da97be6dc65dc8d637c,openstack/nova,master,I91ebbf4e046c024fab520da97be6dc65dc8d637c,Imported Translations from Transifex,MERGED,2013-07-15 19:37:57.000000000,2013-07-24 20:36:07.000000000,2013-07-24 20:36:05.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2271}]","[{'number': 1, 'created': '2013-07-15 19:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/247a379518759b6df1ebd160f789bb916136e4f9', 'message': 'Imported Translations from Transifex\n\nChange-Id: I91ebbf4e046c024fab520da97be6dc65dc8d637c\n'}, {'number': 2, 'created': '2013-07-16 19:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3eea145baf70658c703edf91efd42d37e5daa1da', 'message': 'Imported Translations from Transifex\n\nChange-Id: I91ebbf4e046c024fab520da97be6dc65dc8d637c\n'}, {'number': 3, 'created': '2013-07-17 20:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63ba99dbad3fbe958e826deaf13af1dee07dd60e', 'message': 'Imported Translations from Transifex\n\nChange-Id: I91ebbf4e046c024fab520da97be6dc65dc8d637c\n'}, {'number': 4, 'created': '2013-07-18 19:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cdb73042b5f95b26850682ad85f34f72ac78a8a0', 'message': 'Imported Translations from Transifex\n\nChange-Id: I91ebbf4e046c024fab520da97be6dc65dc8d637c\n'}, {'number': 5, 'created': '2013-07-19 19:37:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f3f6fb6cd36d1ce5b5c3fb60ba06b89002ff1b9', 'message': 'Imported Translations from Transifex\n\nChange-Id: I91ebbf4e046c024fab520da97be6dc65dc8d637c\n'}, {'number': 6, 'created': '2013-07-20 19:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2368fc1815277c8d63119f41de545798e9ddcd5a', 'message': 'Imported Translations from Transifex\n\nChange-Id: I91ebbf4e046c024fab520da97be6dc65dc8d637c\n'}, {'number': 7, 'created': '2013-07-21 19:37:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01bc35ef130f60a31051d78fd075133a46a022cb', 'message': 'Imported Translations from Transifex\n\nChange-Id: I91ebbf4e046c024fab520da97be6dc65dc8d637c\n'}, {'number': 8, 'created': '2013-07-22 19:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a5e36a96eb90d7cd3a9803606be13e4e492184dd', 'message': 'Imported Translations from Transifex\n\nChange-Id: I91ebbf4e046c024fab520da97be6dc65dc8d637c\n'}, {'number': 9, 'created': '2013-07-23 19:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/724915b9bb47ebb275b0ff07a904f316d3a88d20', 'message': 'Imported Translations from Transifex\n\nChange-Id: I91ebbf4e046c024fab520da97be6dc65dc8d637c\n'}, {'number': 10, 'created': '2013-07-24 19:37:49.000000000', 'files': ['nova/locale/hr/LC_MESSAGES/nova.po', 'nova/locale/pl_PL/LC_MESSAGES/nova.po', 'nova/locale/zh_HK/LC_MESSAGES/nova.po', 'nova/locale/it_IT/LC_MESSAGES/nova.po', 'nova/locale/ru_RU/LC_MESSAGES/nova.po', 'nova/locale/pt_BR/LC_MESSAGES/nova.po', 'nova/locale/zh_CN/LC_MESSAGES/nova.po', 'nova/locale/hu/LC_MESSAGES/nova.po', 'nova/locale/fr/LC_MESSAGES/nova.po', 'nova/locale/vi_VN/LC_MESSAGES/nova.po', 'nova/locale/tr/LC_MESSAGES/nova.po', 'nova/locale/ko_KR/LC_MESSAGES/nova.po', 'nova/locale/zh_TW/LC_MESSAGES/nova.po', 'nova/locale/da/LC_MESSAGES/nova.po', 'nova/locale/ru/LC_MESSAGES/nova.po', 'nova/locale/en_US/LC_MESSAGES/nova.po', 'nova/locale/en_GB/LC_MESSAGES/nova.po', 'nova/locale/id/LC_MESSAGES/nova.po', 'nova/locale/bs/LC_MESSAGES/nova.po', 'nova/locale/nb/LC_MESSAGES/nova.po', 'nova/locale/nl_NL/LC_MESSAGES/nova.po', 'nova/locale/nova.pot', 'nova/locale/sw_KE/LC_MESSAGES/nova.po', 'nova/locale/ms/LC_MESSAGES/nova.po', 'nova/locale/bg_BG/LC_MESSAGES/nova.po', 'nova/locale/ca/LC_MESSAGES/nova.po', 'nova/locale/en_AU/LC_MESSAGES/nova.po', 'nova/locale/ka_GE/LC_MESSAGES/nova.po', 'nova/locale/es/LC_MESSAGES/nova.po', 'nova/locale/ja/LC_MESSAGES/nova.po', 'nova/locale/uk/LC_MESSAGES/nova.po', 'nova/locale/cs/LC_MESSAGES/nova.po', 'nova/locale/ro/LC_MESSAGES/nova.po', 'nova/locale/tr_TR/LC_MESSAGES/nova.po', 'nova/locale/ko/LC_MESSAGES/nova.po', 'nova/locale/it/LC_MESSAGES/nova.po', 'nova/locale/pt/LC_MESSAGES/nova.po', 'nova/locale/tl/LC_MESSAGES/nova.po', 'nova/locale/de/LC_MESSAGES/nova.po', 'nova/locale/fi_FI/LC_MESSAGES/nova.po', 'nova/locale/sl_SI/LC_MESSAGES/nova.po'], 'web_link': 'https://opendev.org/openstack/nova/commit/6fa4eafe071fcc3091a8eb05e54d3509092a952f', 'message': 'Imported Translations from Transifex\n\nChange-Id: I91ebbf4e046c024fab520da97be6dc65dc8d637c\n'}]",0,37114,6fa4eafe071fcc3091a8eb05e54d3509092a952f,32,4,10,3,,,0,"Imported Translations from Transifex

Change-Id: I91ebbf4e046c024fab520da97be6dc65dc8d637c
",git fetch https://review.opendev.org/openstack/nova refs/changes/14/37114/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/locale/hr/LC_MESSAGES/nova.po', 'nova/locale/pl_PL/LC_MESSAGES/nova.po', 'nova/locale/zh_HK/LC_MESSAGES/nova.po', 'nova/locale/it_IT/LC_MESSAGES/nova.po', 'nova/locale/ru_RU/LC_MESSAGES/nova.po', 'nova/locale/pt_BR/LC_MESSAGES/nova.po', 'nova/locale/zh_CN/LC_MESSAGES/nova.po', 'nova/locale/hu/LC_MESSAGES/nova.po', 'nova/locale/fr/LC_MESSAGES/nova.po', 'nova/locale/vi_VN/LC_MESSAGES/nova.po', 'nova/locale/tr/LC_MESSAGES/nova.po', 'nova/locale/ko_KR/LC_MESSAGES/nova.po', 'nova/locale/zh_TW/LC_MESSAGES/nova.po', 'nova/locale/da/LC_MESSAGES/nova.po', 'nova/locale/ru/LC_MESSAGES/nova.po', 'nova/locale/en_US/LC_MESSAGES/nova.po', 'nova/locale/en_GB/LC_MESSAGES/nova.po', 'nova/locale/id/LC_MESSAGES/nova.po', 'nova/locale/bs/LC_MESSAGES/nova.po', 'nova/locale/nb/LC_MESSAGES/nova.po', 'nova/locale/nl_NL/LC_MESSAGES/nova.po', 'nova/locale/nova.pot', 'nova/locale/sw_KE/LC_MESSAGES/nova.po', 'nova/locale/ms/LC_MESSAGES/nova.po', 'nova/locale/bg_BG/LC_MESSAGES/nova.po', 'nova/locale/ca/LC_MESSAGES/nova.po', 'nova/locale/en_AU/LC_MESSAGES/nova.po', 'nova/locale/ka_GE/LC_MESSAGES/nova.po', 'nova/locale/es/LC_MESSAGES/nova.po', 'nova/locale/ja/LC_MESSAGES/nova.po', 'nova/locale/uk/LC_MESSAGES/nova.po', 'nova/locale/cs/LC_MESSAGES/nova.po', 'nova/locale/ro/LC_MESSAGES/nova.po', 'nova/locale/tr_TR/LC_MESSAGES/nova.po', 'nova/locale/ko/LC_MESSAGES/nova.po', 'nova/locale/it/LC_MESSAGES/nova.po', 'nova/locale/pt/LC_MESSAGES/nova.po', 'nova/locale/tl/LC_MESSAGES/nova.po', 'nova/locale/de/LC_MESSAGES/nova.po', 'nova/locale/fi_FI/LC_MESSAGES/nova.po', 'nova/locale/sl_SI/LC_MESSAGES/nova.po']",41,247a379518759b6df1ebd160f789bb916136e4f9,transifex/translations,"""POT-Creation-Date: 2013-07-15 19:36+0000\n""#: nova/api/openstack/compute/plugins/v3/admin_actions.py:241 #: nova/api/openstack/compute/plugins/v3/servers.py:1398msgid """" ""More than one possible network found. Specify network ID(s) to select "" ""which one(s) to connect to,"" msgstr """" #: nova/exception.py:567#: nova/exception.py:571#: nova/exception.py:575#: nova/exception.py:579#: nova/exception.py:583#: nova/exception.py:587#: nova/exception.py:591#: nova/exception.py:595#: nova/exception.py:599#: nova/exception.py:604#: nova/exception.py:608#: nova/exception.py:613#: nova/exception.py:618#: nova/exception.py:623#: nova/exception.py:627#: nova/exception.py:631#: nova/exception.py:635#: nova/exception.py:639#: nova/exception.py:643#: nova/exception.py:647#: nova/exception.py:651#: nova/exception.py:655#: nova/exception.py:659#: nova/exception.py:664#: nova/exception.py:669#: nova/exception.py:673#: nova/exception.py:677#: nova/exception.py:681#: nova/exception.py:685 nova/api/ec2/cloud.py:1307#: nova/exception.py:689#: nova/exception.py:693#: nova/exception.py:697#: nova/exception.py:701#: nova/exception.py:705#: nova/exception.py:709#: nova/exception.py:713#: nova/exception.py:717#: nova/exception.py:721#: nova/exception.py:726msgid ""Quota exists for project %(project_id)s, resource %(resource)s"" msgstr """" #: nova/exception.py:735 #, python-format#: nova/exception.py:739#: nova/exception.py:743#: nova/exception.py:747#: nova/exception.py:751#: nova/exception.py:755#: nova/exception.py:759#: nova/exception.py:763#: nova/exception.py:768#: nova/exception.py:772#: nova/exception.py:777#: nova/exception.py:782#: nova/exception.py:787#: nova/exception.py:791#: nova/exception.py:796#: nova/exception.py:801#: nova/exception.py:805#: nova/exception.py:810#: nova/exception.py:814#: nova/exception.py:820#: nova/exception.py:826#: nova/exception.py:830#: nova/exception.py:834#: nova/exception.py:839#: nova/exception.py:843#: nova/exception.py:847#: nova/exception.py:852#: nova/exception.py:856#: nova/exception.py:861#: nova/exception.py:865#: nova/exception.py:869#: nova/exception.py:873#: nova/exception.py:877#: nova/exception.py:881#: nova/exception.py:885#: nova/exception.py:889#: nova/exception.py:893#: nova/exception.py:897#: nova/exception.py:901#: nova/exception.py:906#: nova/exception.py:911#: nova/exception.py:916#: nova/exception.py:920msgid ""Virtual switch associated with the network adapter %(adapter)s not found."" msgstr """" #: nova/exception.py:929 #, python-format#: nova/exception.py:933#: nova/exception.py:937#: nova/exception.py:941#: nova/exception.py:945#: nova/exception.py:949 nova/tests/compute/test_keypairs.py:118#: nova/exception.py:953#: nova/exception.py:957#: nova/exception.py:961#: nova/exception.py:965#: nova/exception.py:970#: nova/exception.py:974#: nova/exception.py:978#: nova/exception.py:982#: nova/exception.py:986#: nova/exception.py:992#: nova/exception.py:996#: nova/exception.py:1000#: nova/exception.py:1004#: nova/exception.py:1008#: nova/exception.py:1012#: nova/exception.py:1016#: nova/exception.py:1020#: nova/exception.py:1024#: nova/exception.py:1028#: nova/exception.py:1035#: nova/exception.py:1040#: nova/exception.py:1044#: nova/exception.py:1048#: nova/exception.py:1052#: nova/exception.py:1056#: nova/exception.py:1060#: nova/exception.py:1064 nova/tests/compute/test_keypairs.py:129#: nova/exception.py:1068#: nova/exception.py:1072#: nova/exception.py:1077#: nova/exception.py:1081#: nova/exception.py:1085#: nova/exception.py:1089#: nova/exception.py:1094#: nova/exception.py:1098#: nova/exception.py:1102#: nova/exception.py:1108#: nova/exception.py:1112#: nova/exception.py:1117#: nova/exception.py:1121#: nova/exception.py:1126#: nova/exception.py:1130#: nova/exception.py:1134#: nova/exception.py:1138#: nova/exception.py:1142#: nova/exception.py:1146#: nova/exception.py:1150#: nova/exception.py:1154#: nova/exception.py:1158#: nova/exception.py:1162#: nova/exception.py:1166#: nova/exception.py:1171#: nova/exception.py:1176#: nova/exception.py:1180#: nova/exception.py:1184#: nova/exception.py:1190#: nova/exception.py:1194#: nova/exception.py:1199#: nova/exception.py:1204#: nova/exception.py:1208#: nova/exception.py:1213#: nova/exception.py:1217#: nova/exception.py:1221#: nova/exception.py:1225#: nova/exception.py:1230#: nova/exception.py:1235#: nova/exception.py:1240#: nova/exception.py:1245#: nova/exception.py:1249#: nova/exception.py:1253#: nova/exception.py:1258#: nova/exception.py:1263#: nova/exception.py:1269#: nova/exception.py:1273#: nova/exception.py:1277#: nova/exception.py:1281#: nova/exception.py:1285#: nova/exception.py:1289#: nova/exception.py:1294#: nova/exception.py:1298#: nova/exception.py:1302#: nova/exception.py:1306#: nova/exception.py:1311#: nova/exception.py:1316#: nova/api/openstack/compute/plugins/v3/servers.py:468#: nova/api/openstack/compute/plugins/v3/servers.py:473#: nova/api/openstack/compute/plugins/v3/servers.py:606#: nova/api/openstack/compute/plugins/v3/admin_actions.py:210#: nova/api/openstack/compute/image_metadata.py:112 #: nova/api/openstack/compute/plugins/v3/image_metadata.py:127#: nova/api/openstack/compute/plugins/v3/servers.py:570#: nova/api/openstack/compute/plugins/v3/servers.py:589#: nova/api/openstack/compute/plugins/v3/servers.py:609#: nova/api/openstack/compute/plugins/v3/servers.py:627 #: nova/api/openstack/compute/plugins/v3/servers.py:790 #: nova/api/openstack/compute/plugins/v3/servers.py:1066 #: nova/api/openstack/compute/plugins/v3/servers.py:1171 #: nova/api/openstack/compute/plugins/v3/servers.py:1350#: nova/api/openstack/compute/plugins/v3/servers.py:646#: nova/api/openstack/compute/plugins/v3/servers.py:663#: nova/api/openstack/compute/plugins/v3/servers.py:666#: nova/api/openstack/compute/plugins/v3/servers.py:669#: nova/api/openstack/compute/plugins/v3/servers.py:705#: nova/api/openstack/compute/plugins/v3/servers.py:708#: nova/api/openstack/compute/plugins/v3/servers.py:718#: nova/api/openstack/compute/plugins/v3/servers.py:728#: nova/api/openstack/compute/plugins/v3/servers.py:741#: nova/api/openstack/compute/plugins/v3/servers.py:747#: nova/api/openstack/compute/plugins/v3/servers.py:750#: nova/api/openstack/compute/plugins/v3/servers.py:773#: nova/api/openstack/compute/plugins/v3/servers.py:778#: nova/api/openstack/compute/plugins/v3/servers.py:806#: nova/api/openstack/compute/plugins/v3/servers.py:875 #: nova/api/openstack/compute/plugins/v3/servers.py:966#: nova/api/openstack/compute/plugins/v3/servers.py:908#: nova/api/openstack/compute/plugins/v3/servers.py:911#: nova/api/openstack/compute/plugins/v3/servers.py:917#: nova/api/openstack/compute/plugins/v3/servers.py:920#: nova/api/openstack/compute/plugins/v3/servers.py:924#: nova/api/openstack/compute/plugins/v3/servers.py:963#: nova/api/openstack/compute/plugins/v3/servers.py:969#: nova/api/openstack/compute/plugins/v3/servers.py:972#: nova/api/openstack/compute/plugins/v3/servers.py:1053#: nova/api/openstack/compute/plugins/v3/servers.py:1057#: nova/api/openstack/compute/plugins/v3/servers.py:1081 #: nova/api/openstack/compute/plugins/v3/servers.py:1098#: nova/api/openstack/compute/plugins/v3/servers.py:1101#: nova/api/openstack/compute/plugins/v3/servers.py:1117#: nova/api/openstack/compute/plugins/v3/servers.py:1121#: nova/api/openstack/compute/plugins/v3/servers.py:1143#: nova/api/openstack/compute/plugins/v3/servers.py:1146#: nova/api/openstack/compute/plugins/v3/servers.py:1152#: nova/api/openstack/compute/plugins/v3/servers.py:1156#: nova/api/openstack/compute/plugins/v3/servers.py:1160#: nova/api/openstack/compute/plugins/v3/servers.py:1181#: nova/api/openstack/compute/plugins/v3/servers.py:1190#: nova/api/openstack/compute/plugins/v3/servers.py:1223#: nova/api/openstack/compute/plugins/v3/servers.py:1236#: nova/api/openstack/compute/plugins/v3/servers.py:1240 #: nova/api/openstack/compute/plugins/v3/servers.py:1448#: nova/api/openstack/compute/plugins/v3/servers.py:1246#: nova/api/openstack/compute/plugins/v3/servers.py:1255#: nova/api/openstack/compute/plugins/v3/servers.py:1268#: nova/api/openstack/compute/plugins/v3/servers.py:1271#: nova/api/openstack/compute/plugins/v3/servers.py:1289#: nova/api/openstack/compute/plugins/v3/servers.py:1295#: nova/api/openstack/compute/plugins/v3/servers.py:1356#: nova/api/openstack/compute/plugins/v3/servers.py:1389#: nova/api/openstack/compute/plugins/v3/servers.py:1515#: nova/api/openstack/compute/plugins/v3/admin_actions.py:59#: nova/api/openstack/compute/plugins/v3/admin_actions.py:76#: nova/api/openstack/compute/plugins/v3/admin_actions.py:93#: nova/api/openstack/compute/plugins/v3/admin_actions.py:110#: nova/api/openstack/compute/plugins/v3/admin_actions.py:126#: nova/api/openstack/compute/plugins/v3/admin_actions.py:140#: nova/api/openstack/compute/plugins/v3/admin_actions.py:153 #: nova/api/openstack/compute/plugins/v3/admin_actions.py:169 #: nova/api/openstack/compute/plugins/v3/admin_actions.py:185 #: nova/api/openstack/compute/plugins/v3/admin_actions.py:321#: nova/api/openstack/compute/plugins/v3/admin_actions.py:156#: nova/api/openstack/compute/plugins/v3/admin_actions.py:172#: nova/api/openstack/compute/plugins/v3/admin_actions.py:188#: nova/api/openstack/compute/plugins/v3/admin_actions.py:218#: nova/api/openstack/compute/plugins/v3/admin_actions.py:222#: nova/api/openstack/compute/plugins/v3/admin_actions.py:228#: nova/api/openstack/compute/plugins/v3/admin_actions.py:231#: nova/api/openstack/compute/plugins/v3/admin_actions.py:247#: nova/api/openstack/compute/plugins/v3/admin_actions.py:277#: nova/api/openstack/compute/plugins/v3/admin_actions.py:292#: nova/api/openstack/compute/plugins/v3/admin_actions.py:295#: nova/api/openstack/compute/plugins/v3/admin_actions.py:313#: nova/api/openstack/compute/plugins/v3/admin_actions.py:324#: nova/api/openstack/compute/plugins/v3/servers.py:1486#: nova/api/openstack/compute/plugins/v3/servers.py:1499#: nova/api/openstack/compute/plugins/v3/services.py:153#: nova/api/openstack/compute/plugins/v3/services.py:160#: nova/api/openstack/compute/plugins/v3/services.py:162#: nova/api/openstack/compute/plugins/v3/instance_actions.py:110 #, python-format msgid ""Action %s not found"" msgstr """" #: nova/api/openstack/compute/plugins/v3/servers.py:486#: nova/api/openstack/compute/plugins/v3/servers.py:493#: nova/api/openstack/compute/plugins/v3/servers.py:514#: nova/api/openstack/compute/plugins/v3/servers.py:526#: nova/api/openstack/compute/plugins/v3/servers.py:1008#: nova/api/openstack/compute/plugins/v3/servers.py:1464#: nova/compute/api.py:494#: nova/compute/api.py:576#: nova/compute/api.py:672#: nova/compute/api.py:819#: nova/compute/api.py:846#: nova/compute/api.py:1129#: nova/compute/api.py:1265#: nova/compute/api.py:1271#: nova/compute/api.py:1281#: nova/compute/api.py:1325#: nova/compute/api.py:1350#: nova/compute/api.py:1401#: nova/compute/api.py:1417#: nova/compute/api.py:1492#: nova/compute/api.py:1757#: nova/compute/api.py:2095#: nova/compute/api.py:2104#: nova/compute/api.py:2152#: nova/compute/api.py:2291#: nova/compute/api.py:2396#: nova/compute/api.py:2404#: nova/compute/api.py:2476#: nova/compute/api.py:2595#: nova/compute/api.py:2617#: nova/compute/api.py:2621#: nova/compute/api.py:2926 nova/tests/compute/test_keypairs.py:108#: nova/compute/api.py:2930 nova/tests/compute/test_keypairs.py:100#: nova/compute/api.py:3012#: nova/compute/api.py:3015#: nova/compute/api.py:3023#: nova/compute/api.py:3029#: nova/compute/api.py:3047#: nova/compute/api.py:3050#: nova/compute/api.py:3062#: nova/compute/api.py:3075#: nova/compute/api.py:3135#: nova/compute/api.py:3140#: nova/compute/api.py:3148#: nova/compute/api.py:3151#: nova/compute/api.py:3228 nova/compute/api.py:3302#: nova/compute/api.py:3244#: nova/compute/api.py:3247#: nova/compute/api.py:3256#: nova/compute/api.py:3309#: nova/network/neutronv2/api.py:485 msgid ""Multiple possible networks found, use a Network ID to be more specific."" msgstr """" #: nova/network/neutronv2/api.py:731#: nova/network/neutronv2/api.py:826#: nova/scheduler/chance.py:56#: nova/scheduler/chance.py:61#: nova/tests/api/openstack/compute/plugins/v3/test_servers.py:3373#: nova/tests/api/openstack/compute/plugins/v3/test_servers.py:3378#: nova/tests/api/openstack/compute/plugins/v3/test_servers.py:3383#: nova/tests/compute/test_compute.py:9208#: nova/virt/images.py:222#: nova/virt/baremetal/utils.py:61#: nova/virt/baremetal/utils.py:77#: nova/virt/disk/mount/api.py:47 nova/virt/disk/mount/api.py:65#: nova/virt/disk/mount/api.py:52 nova/virt/disk/mount/api.py:70#: nova/virt/disk/mount/api.py:59#: nova/virt/disk/mount/api.py:121#: nova/virt/disk/mount/api.py:124#: nova/virt/disk/mount/api.py:139#: nova/virt/disk/mount/api.py:144#: nova/virt/disk/mount/api.py:160#: nova/virt/disk/mount/api.py:161#: nova/virt/disk/mount/api.py:183#: nova/virt/disk/mount/api.py:191#: nova/virt/disk/mount/api.py:196#: nova/virt/disk/mount/api.py:207#: nova/virt/disk/mount/api.py:218#: nova/virt/disk/vfs/api.py:33#: nova/virt/disk/vfs/api.py:40#: nova/virt/disk/vfs/api.py:45msgid ""Make directory path=%s""msgid ""Append file path=%s""msgid ""Replace file path=%s""msgid ""Read file path=%s""msgid ""Has file path=%s""#: nova/virt/disk/vfs/guestfs.py:189#: nova/virt/disk/vfs/guestfs.py:203#: nova/virt/disk/vfs/localfs.py:145#~ msgid ""Make directory path=%(path)s"" #~ msgstr """" #~ msgid ""Append file path=%(path)s"" #~ msgstr """" #~ msgid ""Replace file path=%(path)s"" #~ msgstr """" #~ msgid ""Read file path=%(path)s"" #~ msgstr """" #~ msgid ""Has file path=%(path)s"" #~ msgstr """" ","""POT-Creation-Date: 2013-07-14 19:36+0000\n""#: nova/api/openstack/compute/plugins/v3/admin_actions.py:242 #: nova/api/openstack/compute/plugins/v3/servers.py:1426#: nova/exception.py:566#: nova/exception.py:570#: nova/exception.py:574#: nova/exception.py:578#: nova/exception.py:582#: nova/exception.py:586#: nova/exception.py:590#: nova/exception.py:594#: nova/exception.py:599#: nova/exception.py:603#: nova/exception.py:608#: nova/exception.py:613#: nova/exception.py:618#: nova/exception.py:622#: nova/exception.py:626#: nova/exception.py:630#: nova/exception.py:634#: nova/exception.py:638#: nova/exception.py:642#: nova/exception.py:646#: nova/exception.py:650#: nova/exception.py:654#: nova/exception.py:659#: nova/exception.py:664#: nova/exception.py:668#: nova/exception.py:672#: nova/exception.py:676#: nova/exception.py:680 nova/api/ec2/cloud.py:1307#: nova/exception.py:684#: nova/exception.py:688#: nova/exception.py:692#: nova/exception.py:696#: nova/exception.py:700#: nova/exception.py:704#: nova/exception.py:708#: nova/exception.py:712#: nova/exception.py:716#: nova/exception.py:721#: nova/exception.py:725 #, python-format msgid ""Quota exists for project %(project_id)s, resource %(resource)s"" msgstr """" #: nova/exception.py:734#: nova/exception.py:738#: nova/exception.py:742#: nova/exception.py:746#: nova/exception.py:750#: nova/exception.py:754#: nova/exception.py:758#: nova/exception.py:763#: nova/exception.py:767#: nova/exception.py:772#: nova/exception.py:777#: nova/exception.py:782#: nova/exception.py:786#: nova/exception.py:791#: nova/exception.py:796#: nova/exception.py:800#: nova/exception.py:805#: nova/exception.py:809#: nova/exception.py:815#: nova/exception.py:821#: nova/exception.py:825#: nova/exception.py:829#: nova/exception.py:834#: nova/exception.py:838#: nova/exception.py:842#: nova/exception.py:847#: nova/exception.py:851#: nova/exception.py:856#: nova/exception.py:860#: nova/exception.py:864#: nova/exception.py:868#: nova/exception.py:872#: nova/exception.py:876#: nova/exception.py:880#: nova/exception.py:884#: nova/exception.py:888#: nova/exception.py:892#: nova/exception.py:896#: nova/exception.py:901#: nova/exception.py:906#: nova/exception.py:911#: nova/exception.py:915#: nova/exception.py:919 #, python-format msgid ""Virtual switch associated with the network adapter %(adapter)s not found."" msgstr """" #: nova/exception.py:928#: nova/exception.py:932#: nova/exception.py:936#: nova/exception.py:940#: nova/exception.py:944 nova/tests/compute/test_keypairs.py:118#: nova/exception.py:948#: nova/exception.py:952#: nova/exception.py:956#: nova/exception.py:960#: nova/exception.py:965#: nova/exception.py:969#: nova/exception.py:973#: nova/exception.py:977#: nova/exception.py:981#: nova/exception.py:987#: nova/exception.py:991#: nova/exception.py:995#: nova/exception.py:999#: nova/exception.py:1003#: nova/exception.py:1007#: nova/exception.py:1011#: nova/exception.py:1015#: nova/exception.py:1019#: nova/exception.py:1023#: nova/exception.py:1030#: nova/exception.py:1035#: nova/exception.py:1039#: nova/exception.py:1043#: nova/exception.py:1047#: nova/exception.py:1051#: nova/exception.py:1055#: nova/exception.py:1059 nova/tests/compute/test_keypairs.py:129#: nova/exception.py:1063#: nova/exception.py:1067#: nova/exception.py:1072#: nova/exception.py:1076#: nova/exception.py:1080#: nova/exception.py:1084#: nova/exception.py:1089#: nova/exception.py:1093#: nova/exception.py:1097#: nova/exception.py:1103#: nova/exception.py:1107#: nova/exception.py:1112#: nova/exception.py:1116#: nova/exception.py:1121#: nova/exception.py:1125#: nova/exception.py:1129#: nova/exception.py:1133#: nova/exception.py:1137#: nova/exception.py:1141#: nova/exception.py:1145#: nova/exception.py:1149#: nova/exception.py:1153#: nova/exception.py:1157#: nova/exception.py:1161#: nova/exception.py:1166#: nova/exception.py:1171#: nova/exception.py:1175#: nova/exception.py:1179#: nova/exception.py:1185#: nova/exception.py:1189#: nova/exception.py:1194#: nova/exception.py:1199#: nova/exception.py:1203#: nova/exception.py:1208#: nova/exception.py:1212#: nova/exception.py:1216#: nova/exception.py:1220#: nova/exception.py:1225#: nova/exception.py:1230#: nova/exception.py:1235#: nova/exception.py:1240#: nova/exception.py:1244#: nova/exception.py:1248#: nova/exception.py:1253#: nova/exception.py:1258#: nova/exception.py:1264#: nova/exception.py:1268#: nova/exception.py:1272#: nova/exception.py:1276#: nova/exception.py:1280#: nova/exception.py:1284#: nova/exception.py:1289#: nova/exception.py:1293#: nova/exception.py:1297#: nova/exception.py:1301#: nova/exception.py:1306#: nova/exception.py:1311#: nova/api/openstack/compute/plugins/v3/servers.py:472#: nova/api/openstack/compute/plugins/v3/servers.py:477#: nova/api/openstack/compute/plugins/v3/servers.py:610#: nova/api/openstack/compute/plugins/v3/admin_actions.py:211#: nova/api/openstack/compute/image_metadata.py:109 #: nova/api/openstack/compute/plugins/v3/image_metadata.py:124#: nova/api/openstack/compute/plugins/v3/servers.py:574#: nova/api/openstack/compute/plugins/v3/servers.py:593#: nova/api/openstack/compute/plugins/v3/servers.py:613#: nova/api/openstack/compute/plugins/v3/servers.py:631 #: nova/api/openstack/compute/plugins/v3/servers.py:802 #: nova/api/openstack/compute/plugins/v3/servers.py:1094 #: nova/api/openstack/compute/plugins/v3/servers.py:1199 #: nova/api/openstack/compute/plugins/v3/servers.py:1378#: nova/api/openstack/compute/plugins/v3/servers.py:650#: nova/api/openstack/compute/plugins/v3/servers.py:667#: nova/api/openstack/compute/plugins/v3/servers.py:670#: nova/api/openstack/compute/plugins/v3/servers.py:673#: nova/api/openstack/compute/plugins/v3/servers.py:709#: nova/api/openstack/compute/plugins/v3/servers.py:712#: nova/api/openstack/compute/plugins/v3/servers.py:722#: nova/api/openstack/compute/plugins/v3/servers.py:732#: nova/api/openstack/compute/plugins/v3/servers.py:745#: nova/api/openstack/compute/plugins/v3/servers.py:751#: nova/api/openstack/compute/plugins/v3/servers.py:754#: nova/api/openstack/compute/plugins/v3/servers.py:780#: nova/api/openstack/compute/plugins/v3/servers.py:785#: nova/api/openstack/compute/plugins/v3/servers.py:790#: nova/api/openstack/compute/plugins/v3/servers.py:818#: nova/api/openstack/compute/plugins/v3/servers.py:887 #: nova/api/openstack/compute/plugins/v3/servers.py:995#: nova/api/openstack/compute/plugins/v3/servers.py:935#: nova/api/openstack/compute/plugins/v3/servers.py:938#: nova/api/openstack/compute/plugins/v3/servers.py:944#: nova/api/openstack/compute/plugins/v3/servers.py:947#: nova/api/openstack/compute/plugins/v3/servers.py:951#: nova/api/openstack/compute/plugins/v3/servers.py:992#: nova/api/openstack/compute/plugins/v3/servers.py:998#: nova/api/openstack/compute/plugins/v3/servers.py:1001#: nova/api/openstack/compute/plugins/v3/servers.py:1081#: nova/api/openstack/compute/plugins/v3/servers.py:1085#: nova/api/openstack/compute/plugins/v3/servers.py:1109 #: nova/api/openstack/compute/plugins/v3/servers.py:1126#: nova/api/openstack/compute/plugins/v3/servers.py:1129#: nova/api/openstack/compute/plugins/v3/servers.py:1145#: nova/api/openstack/compute/plugins/v3/servers.py:1149#: nova/api/openstack/compute/plugins/v3/servers.py:1171#: nova/api/openstack/compute/plugins/v3/servers.py:1174#: nova/api/openstack/compute/plugins/v3/servers.py:1180#: nova/api/openstack/compute/plugins/v3/servers.py:1184#: nova/api/openstack/compute/plugins/v3/servers.py:1188#: nova/api/openstack/compute/plugins/v3/servers.py:1209#: nova/api/openstack/compute/plugins/v3/servers.py:1218#: nova/api/openstack/compute/plugins/v3/servers.py:1251#: nova/api/openstack/compute/plugins/v3/servers.py:1264#: nova/api/openstack/compute/plugins/v3/servers.py:1268 #: nova/api/openstack/compute/plugins/v3/servers.py:1476#: nova/api/openstack/compute/plugins/v3/servers.py:1274#: nova/api/openstack/compute/plugins/v3/servers.py:1283#: nova/api/openstack/compute/plugins/v3/servers.py:1296#: nova/api/openstack/compute/plugins/v3/servers.py:1299#: nova/api/openstack/compute/plugins/v3/servers.py:1317#: nova/api/openstack/compute/plugins/v3/servers.py:1323#: nova/api/openstack/compute/plugins/v3/servers.py:1384#: nova/api/openstack/compute/plugins/v3/servers.py:1417#: nova/api/openstack/compute/plugins/v3/servers.py:1543#: nova/api/openstack/compute/plugins/v3/admin_actions.py:60#: nova/api/openstack/compute/plugins/v3/admin_actions.py:77#: nova/api/openstack/compute/plugins/v3/admin_actions.py:94#: nova/api/openstack/compute/plugins/v3/admin_actions.py:111#: nova/api/openstack/compute/plugins/v3/admin_actions.py:127#: nova/api/openstack/compute/plugins/v3/admin_actions.py:141#: nova/api/openstack/compute/plugins/v3/admin_actions.py:154 #: nova/api/openstack/compute/plugins/v3/admin_actions.py:170 #: nova/api/openstack/compute/plugins/v3/admin_actions.py:186 #: nova/api/openstack/compute/plugins/v3/admin_actions.py:322#: nova/api/openstack/compute/plugins/v3/admin_actions.py:157#: nova/api/openstack/compute/plugins/v3/admin_actions.py:173#: nova/api/openstack/compute/plugins/v3/admin_actions.py:189#: nova/api/openstack/compute/plugins/v3/admin_actions.py:219#: nova/api/openstack/compute/plugins/v3/admin_actions.py:223#: nova/api/openstack/compute/plugins/v3/admin_actions.py:229#: nova/api/openstack/compute/plugins/v3/admin_actions.py:232#: nova/api/openstack/compute/plugins/v3/admin_actions.py:248#: nova/api/openstack/compute/plugins/v3/admin_actions.py:278#: nova/api/openstack/compute/plugins/v3/admin_actions.py:293#: nova/api/openstack/compute/plugins/v3/admin_actions.py:296#: nova/api/openstack/compute/plugins/v3/admin_actions.py:314#: nova/api/openstack/compute/plugins/v3/admin_actions.py:325#: nova/api/openstack/compute/plugins/v3/servers.py:1514#: nova/api/openstack/compute/plugins/v3/servers.py:1527#: nova/api/openstack/compute/plugins/v3/services.py:173#: nova/api/openstack/compute/plugins/v3/services.py:180#: nova/api/openstack/compute/plugins/v3/services.py:182#: nova/api/openstack/compute/plugins/v3/services.py:188#: nova/api/openstack/compute/plugins/v3/servers.py:490#: nova/api/openstack/compute/plugins/v3/servers.py:497#: nova/api/openstack/compute/plugins/v3/servers.py:518#: nova/api/openstack/compute/plugins/v3/servers.py:530#: nova/api/openstack/compute/plugins/v3/servers.py:1036#: nova/api/openstack/compute/plugins/v3/servers.py:1492#: nova/compute/api.py:497#: nova/compute/api.py:579#: nova/compute/api.py:675#: nova/compute/api.py:822#: nova/compute/api.py:849#: nova/compute/api.py:1132#: nova/compute/api.py:1268#: nova/compute/api.py:1274#: nova/compute/api.py:1284#: nova/compute/api.py:1328#: nova/compute/api.py:1353#: nova/compute/api.py:1404#: nova/compute/api.py:1420#: nova/compute/api.py:1495#: nova/compute/api.py:1761#: nova/compute/api.py:2099#: nova/compute/api.py:2108#: nova/compute/api.py:2156#: nova/compute/api.py:2296#: nova/compute/api.py:2401#: nova/compute/api.py:2409#: nova/compute/api.py:2481#: nova/compute/api.py:2598#: nova/compute/api.py:2620#: nova/compute/api.py:2624#: nova/compute/api.py:2929 nova/tests/compute/test_keypairs.py:108#: nova/compute/api.py:2933 nova/tests/compute/test_keypairs.py:100#: nova/compute/api.py:3015#: nova/compute/api.py:3018#: nova/compute/api.py:3026#: nova/compute/api.py:3032#: nova/compute/api.py:3050#: nova/compute/api.py:3053#: nova/compute/api.py:3065#: nova/compute/api.py:3078#: nova/compute/api.py:3138#: nova/compute/api.py:3143#: nova/compute/api.py:3151#: nova/compute/api.py:3154#: nova/compute/api.py:3231 nova/compute/api.py:3305#: nova/compute/api.py:3247#: nova/compute/api.py:3250#: nova/compute/api.py:3259#: nova/compute/api.py:3312#: nova/network/neutronv2/api.py:719#: nova/network/neutronv2/api.py:814#: nova/scheduler/chance.py:57#: nova/scheduler/chance.py:62#: nova/tests/api/openstack/compute/plugins/v3/test_servers.py:3425#: nova/tests/api/openstack/compute/plugins/v3/test_servers.py:3430#: nova/tests/api/openstack/compute/plugins/v3/test_servers.py:3435#: nova/tests/compute/test_compute.py:9173#: nova/virt/images.py:221#: nova/virt/baremetal/utils.py:60#: nova/virt/baremetal/utils.py:75#: nova/virt/disk/mount/api.py:45 nova/virt/disk/mount/api.py:61#: nova/virt/disk/mount/api.py:50 nova/virt/disk/mount/api.py:66#: nova/virt/disk/mount/api.py:57#: nova/virt/disk/mount/api.py:117#: nova/virt/disk/mount/api.py:120#: nova/virt/disk/mount/api.py:135#: nova/virt/disk/mount/api.py:140#: nova/virt/disk/mount/api.py:156#: nova/virt/disk/mount/api.py:157#: nova/virt/disk/mount/api.py:179#: nova/virt/disk/mount/api.py:187#: nova/virt/disk/mount/api.py:192#: nova/virt/disk/mount/api.py:203#: nova/virt/disk/mount/api.py:214#: nova/virt/disk/vfs/api.py:32#: nova/virt/disk/vfs/api.py:39#: nova/virt/disk/vfs/api.py:44msgid ""Make directory path=%(path)s""msgid ""Append file path=%(path)s""msgid ""Replace file path=%(path)s""msgid ""Read file path=%(path)s""msgid ""Has file path=%(path)s""#: nova/virt/disk/vfs/guestfs.py:188#: nova/virt/disk/vfs/guestfs.py:201#: nova/virt/disk/vfs/localfs.py:144",16063,14930
openstack%2Fcookbook-openstack-compute~master~Ib7c3eae117a33cc2a7a5668e033851acaecd880b,openstack/cookbook-openstack-compute,master,Ib7c3eae117a33cc2a7a5668e033851acaecd880b,Allow auth_version in auth_token middleware,MERGED,2013-07-24 19:16:14.000000000,2013-07-24 20:29:42.000000000,2013-07-24 20:29:42.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 216}]","[{'number': 1, 'created': '2013-07-24 19:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/7c617d95b387990798e4780d7cb1c123d19046ae', 'message': 'Allow auth_version in auth_token middleware\n\nAllows the auth_version to be only included when a node\nattribute is set to v2.0. This ensures that Keystone v3 works\nwith Nova when not on Keystone v2.0.\n\nFixes LP #1204627\n\nChange-Id: Ib7c3eae117a33cc2a7a5668e033851acaecd880b\n'}, {'number': 2, 'created': '2013-07-24 20:13:13.000000000', 'files': ['Berksfile.lock', 'recipes/api-metadata.rb', 'recipes/api-ec2.rb', 'attributes/default.rb', 'templates/default/api-paste.ini.erb', 'recipes/api-os-compute.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/ee622854d111699cafb79deac6e937ec203dd14d', 'message': 'Allow auth_version in auth_token middleware\n\nAllows the auth_version to be only included when a node\nattribute is set to v2.0. This ensures that Keystone v3 works\nwith Nova when not on Keystone v2.0.\n\nAlso corrects the auth endpoint to the main endpoint not\nthe admin one.\n\nFixes LP #1204627\n\nChange-Id: Ib7c3eae117a33cc2a7a5668e033851acaecd880b\n'}]",0,38519,ee622854d111699cafb79deac6e937ec203dd14d,11,3,2,7,,,0,"Allow auth_version in auth_token middleware

Allows the auth_version to be only included when a node
attribute is set to v2.0. This ensures that Keystone v3 works
with Nova when not on Keystone v2.0.

Also corrects the auth endpoint to the main endpoint not
the admin one.

Fixes LP #1204627

Change-Id: Ib7c3eae117a33cc2a7a5668e033851acaecd880b
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/19/38519/2 && git format-patch -1 --stdout FETCH_HEAD,"['Berksfile.lock', 'attributes/default.rb', 'templates/default/api-paste.ini.erb', 'recipes/api-os-compute.rb']",4,7c617d95b387990798e4780d7cb1c123d19046ae,bug/1204627,"identity_endpoint = endpoint ""identity"" :identity_endpoint => identity_endpoint,","identity_admin_endpoint = endpoint ""identity-admin"" :identity_admin_endpoint => identity_admin_endpoint,",19,20
openstack%2Fopenstack-manuals~master~I9408afdbd4b90495e2f34f5acb97a98dd5e7d179,openstack/openstack-manuals,master,I9408afdbd4b90495e2f34f5acb97a98dd5e7d179,updated installation notes for SLES,MERGED,2013-07-22 14:12:10.000000000,2013-07-24 20:26:31.000000000,2013-07-24 20:26:30.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-07-22 14:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ccecff6c0ebd28a2a1b4b58f3f0bd91f4f43a654', 'message': ""updated installation notes for SLES\n\nRemoved note about deprecated packages provided by B1 Systems\non the openSUSE Build Service. B1 Systems is now working on\nthe packages provided in the project Cloud:Master and it's\nsubprojects.\n\nUpdated the note about declaring the repository for SLES 11, the\nlastes release of SLES 11 is SP3.\n\nAdded the note that there are no known issues with the Python\ninterpreter on SLES11 SP3.\n\nAdded the note that the latest development snapshots are available\nin the project Cloud:OpenStack:Master on the openSUSE Build\nService.\n\nChange-Id: I9408afdbd4b90495e2f34f5acb97a98dd5e7d179\n""}, {'number': 2, 'created': '2013-07-22 14:16:28.000000000', 'files': ['doc/src/docbkx/openstack-compute-admin/computeinstall.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a5a583841526df971366690c2d3a7e9ababa59bf', 'message': ""updated installation notes for SLES\n\nRemoved note about deprecated packages provided by B1 Systems\non the openSUSE Build Service. B1 Systems is now working on\nthe packages provided in the project Cloud:Master and it's\nsubprojects.\n\nUpdated the note about declaring the repository for SLES 11, the\nlastes release of SLES 11 is SP3.\n\nAdded the note that there are no known issues with the Python\ninterpreter on SLES11 SP3.\n\nAdded the note that the latest development snapshots are available\nin the project Cloud:OpenStack:Master on the openSUSE Build\nService.\n\nChange-Id: I9408afdbd4b90495e2f34f5acb97a98dd5e7d179\n""}]",0,38153,a5a583841526df971366690c2d3a7e9ababa59bf,8,3,2,167,,,0,"updated installation notes for SLES

Removed note about deprecated packages provided by B1 Systems
on the openSUSE Build Service. B1 Systems is now working on
the packages provided in the project Cloud:Master and it's
subprojects.

Updated the note about declaring the repository for SLES 11, the
lastes release of SLES 11 is SP3.

Added the note that there are no known issues with the Python
interpreter on SLES11 SP3.

Added the note that the latest development snapshots are available
in the project Cloud:OpenStack:Master on the openSUSE Build
Service.

Change-Id: I9408afdbd4b90495e2f34f5acb97a98dd5e7d179
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/53/38153/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-compute-admin/computeinstall.xml'],1,ccecff6c0ebd28a2a1b4b58f3f0bd91f4f43a654,updating_suse_installation_notes," e.g. <link xlink:href=""https://build.opensuse.org/project/show?project=Cloud%3AOpenStack%3AGrizzly"">Cloud:OpenStack:Grizzly</link>. Latest development snapshots can be found in the project <link xlink:href=""https://build.opensuse.org/project/show?project=Cloud%3AOpenStack%3AGrizzly"">Cloud:OpenStack:Master</link>.</para><prompt>#</prompt> <userinput>zypper ar -f http://download.opensuse.org/repositories/Cloud:/OpenStack:/Grizzly/SLE_11_SP3/Cloud:OpenStack:Grizzly.repo Adding repository 'OpenStack Grizzly (Stable branch) (SLE_11_SP3)' [done] Repository 'OpenStack Grizzly (Stable branch) (SLE_11_SP3)' successfully addedURI: http://download.opensuse.org/repositories/Cloud:/OpenStack:/Grizzly/SLE_11_SP3/</computeroutput> If you're still using SLES11 SP2 you have to apply the latest available updates. Without doing evaluation for SLES11 SP2</link> to gain updates. There are no more issues with the Python interpreter on SLES11 SP3."," e.g. <link xlink:href=""https://build.opensuse.org/project/show?project=Cloud%3AOpenStack%3AGrizzly"">Cloud:OpenStack:Grizzly</link>.</para> <para><link xlink:href=""http://www.b1-systems.de"">B1 Systems GmbH</link> provides packages for openSUSE 12.2 and SUSE Linux Enterprise Server 11 SP2 on the <link xlink:href=""https://build.opensuse.org/"">openSUSE Open Build Server</link>.</para><prompt>#</prompt> <userinput> zypper ar -f http://download.opensuse.org/repositories/Cloud:/OpenStack:/Grizzly/SLE_11_SP2/Cloud:OpenStack:Grizzly.repo </userinput> <computeroutput> Adding repository 'OpenStack Grizzly (Stable branch) (SLE_11_SP2)' ......................................................................[done] Repository 'OpenStack Grizzly (Stable branch) (SLE_11_SP2)' successfully addedURI: http://download.opensuse.org/repositories/Cloud:/OpenStack:/Grizzly/SLE_11_SP2/</computeroutput> You have to apply the latest available updates for SLES11 SP2. Without doing evaluation for SLES11 SP2</link> to gain updates.",7,15
openstack%2Fcinder~master~I8c8422f0ffc6d55ebe80fa8b2962b54eca266974,openstack/cinder,master,I8c8422f0ffc6d55ebe80fa8b2962b54eca266974,Implements extend volume feature in HP 3PAR driver,MERGED,2013-07-22 18:54:20.000000000,2013-07-24 20:23:04.000000000,2013-07-24 20:23:04.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1773}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 4355}, {'_account_id': 6043}, {'_account_id': 7837}]","[{'number': 1, 'created': '2013-07-22 18:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f767d985ad6dccd9a2170c8eeaf540c422a1c1cf', 'message': 'Implements extend volume feature in HP 3PAR driver\n\nThis patch enables the extend volume feature to be used in cinder\nwhen the backend storage is a 3PAR array.\n\nChange-Id: I8c8422f0ffc6d55ebe80fa8b2962b54eca266974\n'}, {'number': 2, 'created': '2013-07-22 22:53:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dcca0d73852492bc229322f97dfc81c7d134a573', 'message': 'Implements extend volume feature in HP 3PAR driver\n\nThis patch enables the extend volume feature to be used in cinder\nwhen the backend storage is a 3PAR array.\n\nChange-Id: I8c8422f0ffc6d55ebe80fa8b2962b54eca266974\n'}, {'number': 3, 'created': '2013-07-23 00:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6989b544b8f39d0b1e34dbb4290dbecc139246bf', 'message': 'Implements extend volume feature in HP 3PAR driver\n\nThis patch enables the extend volume feature to be used in cinder\nwhen the backend storage is a 3PAR array.\n\nChange-Id: I8c8422f0ffc6d55ebe80fa8b2962b54eca266974\n'}, {'number': 4, 'created': '2013-07-23 19:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/86282391e849ac660b830bf269bbd5b5f414543d', 'message': 'Implements extend volume feature in HP 3PAR driver\n\nThis patch enables the extend volume feature to be used in cinder\nwhen the backend storage is a 3PAR array.\n\nChange-Id: I8c8422f0ffc6d55ebe80fa8b2962b54eca266974\n'}, {'number': 5, 'created': '2013-07-24 16:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/efd0aede0cdb3ecbeab65b080b81af9f3c8d1911', 'message': 'Implements extend volume feature in HP 3PAR driver\n\nThis patch enables the extend volume feature to be used in cinder\nwhen the backend storage is a 3PAR array.\n\nChange-Id: I8c8422f0ffc6d55ebe80fa8b2962b54eca266974\n'}, {'number': 6, 'created': '2013-07-24 18:39:21.000000000', 'files': ['cinder/volume/drivers/san/hp/hp_3par_fc.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ef75b0c97352f16c5e02fc28bcd34aefe079ccfc', 'message': 'Implements extend volume feature in HP 3PAR driver\n\nThis patch enables the extend volume feature to be used in cinder\nwhen the backend storage is a 3PAR array.\n\nChange-Id: I8c8422f0ffc6d55ebe80fa8b2962b54eca266974\n'}]",36,38192,ef75b0c97352f16c5e02fc28bcd34aefe079ccfc,33,8,6,7837,,,0,"Implements extend volume feature in HP 3PAR driver

This patch enables the extend volume feature to be used in cinder
when the backend storage is a 3PAR array.

Change-Id: I8c8422f0ffc6d55ebe80fa8b2962b54eca266974
",git fetch https://review.opendev.org/openstack/cinder refs/changes/92/38192/5 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/san/hp/hp_3par_fc.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py']",4,f767d985ad6dccd9a2170c8eeaf540c422a1c1cf,hp3par_extend_volume," def extend_volume(self, volume, new_size): try: hp_name = self.get_volume_metadata_value(volume, '3ParName') if (hp_name is None): err = ""Volume not found"" LOG.error(err) raise exception.InvalidInput(reason=err) else: old_size = volume.size if not (new_size > old_size): err = ""Invalid size specified. Cannot shrink volumes"" LOG.error(err) raise exception.InvalidInput(reason=err) growth_size = new_size - old_size LOG.debug(""Extending Volume %s from %s to %s, by %s GB."" % (hp_name, old_size, new_size, growth_size)) self._cli_run(""growvv -f %s %sg"" % (hp_name, growth_size), None) except Exception: err = ""Volume extend failed for %s"" % (volume) LOG.error(err) raise Exception(err) ",,76,0
openstack%2Fcinder~master~I5fb8c6967e6f3df1adfef46e05c832a953dd7131,openstack/cinder,master,I5fb8c6967e6f3df1adfef46e05c832a953dd7131,Implement extend volume for Storwize/SVC.,MERGED,2013-07-17 04:24:50.000000000,2013-07-24 20:09:47.000000000,2013-07-24 20:09:46.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 2166}, {'_account_id': 4355}, {'_account_id': 6043}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-07-17 04:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/441e459453c51a34693d0bc4c92f01c54160d109', 'message': 'Implement extend volume for Storwize/SVC.\n\nThis implements the extend volume functionality for the Storwize/SVC\ndriver.  Extending volumes with snapshots is not supported, as this\nwill require converting the snapshots into full copies, which will eat\nup free space.\n\nChange-Id: I5fb8c6967e6f3df1adfef46e05c832a953dd7131\n'}, {'number': 2, 'created': '2013-07-17 05:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6e055d2e55979762aa9a4f534f542a956f325d47', 'message': 'Implement extend volume for Storwize/SVC.\n\nThis implements the extend volume functionality for the Storwize/SVC\ndriver.  Extending volumes with snapshots is not supported, as this\nwill require converting the snapshots into full copies, which will eat\nup free space.\n\nChange-Id: I5fb8c6967e6f3df1adfef46e05c832a953dd7131\n'}, {'number': 3, 'created': '2013-07-22 10:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cc9dab2d2191458431f4bd56e886c2d86bcd9ed1', 'message': 'Implement extend volume for Storwize/SVC.\n\nThis implements the extend volume functionality for the Storwize/SVC\ndriver.  Extending volumes with snapshots is not supported, as this\nwill require converting the snapshots into full copies, which will eat\nup free space.\n\nChange-Id: I5fb8c6967e6f3df1adfef46e05c832a953dd7131\n'}, {'number': 4, 'created': '2013-07-22 11:43:07.000000000', 'files': ['cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/storwize_svc.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/abc5692c03c17ff4c0a5debd18f30e059d64877b', 'message': 'Implement extend volume for Storwize/SVC.\n\nThis implements the extend volume functionality for the Storwize/SVC\ndriver.  Extending volumes with snapshots is not supported, as this\nwill require converting the snapshots into full copies, which will eat\nup free space.\n\nChange-Id: I5fb8c6967e6f3df1adfef46e05c832a953dd7131\n'}]",2,37392,abc5692c03c17ff4c0a5debd18f30e059d64877b,20,7,4,4355,,,0,"Implement extend volume for Storwize/SVC.

This implements the extend volume functionality for the Storwize/SVC
driver.  Extending volumes with snapshots is not supported, as this
will require converting the snapshots into full copies, which will eat
up free space.

Change-Id: I5fb8c6967e6f3df1adfef46e05c832a953dd7131
",git fetch https://review.opendev.org/openstack/cinder refs/changes/92/37392/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/storwize_svc.py']",2,441e459453c51a34693d0bc4c92f01c54160d109,svc-extend-volume," def _ensure_vdisk_no_fc_mappings(self, name, allow_snaps=True): # Ensure vdisk has no FlashCopy mappings mapping_ids = self._get_vdisk_fc_mappings(name) while len(mapping_ids): wait_for_copy = False for map_id in mapping_ids: attrs = self._get_flashcopy_mapping_attributes(map_id) if not attrs: continue source = attrs['source_vdisk_name'] target = attrs['target_vdisk_name'] copy_rate = attrs['copy_rate'] status = attrs['status'] if copy_rate == '0': # Case #2: A vdisk that has snapshots if source == name: if not allow_snaps: return False ssh_cmd = ('svctask chfcmap -copyrate 50 ' '-autodelete on %s' % map_id) out, err = self._run_ssh(ssh_cmd) wait_for_copy = True # Case #3: A snapshot else: msg = (_('Vdisk %(name)s not involved in ' 'mapping %(src)s -> %(tgt)s') % {'name': name, 'src': source, 'tgt': target}) self._driver_assert(target == name, msg) if status in ['copying', 'prepared']: self._run_ssh('svctask stopfcmap %s' % map_id) elif status == 'stopping': wait_for_copy = True else: self._run_ssh('svctask rmfcmap -force %s' % map_id) # Case 4: Copy in progress - wait and will autodelete else: if status == 'prepared': self._run_ssh('svctask stopfcmap %s' % map_id) self._run_ssh('svctask rmfcmap -force %s' % map_id) elif status == 'idle_or_copied': # Prepare failed self._run_ssh('svctask rmfcmap -force %s' % map_id) else: wait_for_copy = True if wait_for_copy: time.sleep(5) mapping_ids = self._get_vdisk_fc_mappings(name) return True self._ensure_vdisk_no_fc_mappings(name) def extend_volume(self, volume, new_size): LOG.debug(_('enter: extend_volume: volume %s') % volume['id']) ret = self._ensure_vdisk_no_fc_mappings(volume['name'], allow_snaps=False) if not ret: exception_message = (_('extend_volume: Extending a volume with' 'snapshots is not supported.')) raise exception.VolumeBackendAPIException(data=exception_message) extend_amt = int(new_size) - volume['size'] ssh_cmd = ('svctask expandvdisksize -size %(amt)d -unit gb %(name)s' % {'amt': extend_amt, 'name': volume['name']}) out, err = self._run_ssh(ssh_cmd) # No output should be returned from expandvdisksize self._assert_ssh_return(len(out.strip()) == 0, 'extend_volume', ssh_cmd, out, err) LOG.debug(_('leave: extend_volume: volume %s') % volume['id']) "," # Ensure vdisk has no FlashCopy mappings mapping_ids = self._get_vdisk_fc_mappings(name) while len(mapping_ids): wait_for_copy = False for map_id in mapping_ids: attrs = self._get_flashcopy_mapping_attributes(map_id) if not attrs: continue source = attrs['source_vdisk_name'] target = attrs['target_vdisk_name'] copy_rate = attrs['copy_rate'] status = attrs['status'] if copy_rate == '0': # Case #2: A vdisk that has snapshots if source == name: ssh_cmd = ('svctask chfcmap -copyrate 50 ' '-autodelete on %s' % map_id) out, err = self._run_ssh(ssh_cmd) wait_for_copy = True # Case #3: A snapshot else: msg = (_('Vdisk %(name)s not involved in ' 'mapping %(src)s -> %(tgt)s') % {'name': name, 'src': source, 'tgt': target}) self._driver_assert(target == name, msg) if status in ['copying', 'prepared']: self._run_ssh('svctask stopfcmap %s' % map_id) elif status == 'stopping': wait_for_copy = True else: self._run_ssh('svctask rmfcmap -force %s' % map_id) # Case 4: Copy in progress - wait and will autodelete else: if status == 'prepared': self._run_ssh('svctask stopfcmap %s' % map_id) self._run_ssh('svctask rmfcmap -force %s' % map_id) elif status == 'idle_or_copied': # Prepare failed self._run_ssh('svctask rmfcmap -force %s' % map_id) else: wait_for_copy = True if wait_for_copy: time.sleep(5) mapping_ids = self._get_vdisk_fc_mappings(name)",108,45
openstack%2Ftaskflow~master~Ib6b108ec3cfbba4ebd31656a45eb446687e44422,openstack/taskflow,master,Ib6b108ec3cfbba4ebd31656a45eb446687e44422,Added Generic Persistence API and Datatypes,ABANDONED,2013-07-11 21:26:08.000000000,2013-07-24 19:57:59.000000000,,"[{'_account_id': 1297}, {'_account_id': 7839}]","[{'number': 1, 'created': '2013-07-11 21:26:08.000000000', 'files': ['taskflow/generics/taskdetail.py', 'taskflow/tests/unit/test_linear_flow.py', 'taskflow/job.py', 'taskflow/tests/unit/memory_api/test_logbook_api.py', 'taskflow/tests/unit/memory_api/test_taskdetail_api.py', 'taskflow/backends/memory/api.py', 'taskflow/backends/memory/lockingdict.py', 'taskflow/tests/unit/sql_db_api/test_flowdetail_api.py', 'taskflow/backends/memory/__init__.py', 'taskflow/backends/migration.py', 'taskflow/catalog.py', 'taskflow/db/api.py', 'taskflow/tests/unit/test_memory.py', 'taskflow/backends/api.py', 'taskflow/backends/memory.py', 'taskflow/utils.py', 'taskflow/generics/task.py', 'taskflow/tests/utils.py', 'taskflow/backends/sqlalchemy/__init__.py', 'taskflow/generics/jobboard.py', 'taskflow/generics/flowdetail.py', 'taskflow/tests/unit/sql_db_api/test_logbook_api.py', 'taskflow/db/sqlalchemy/api.py', 'taskflow/tests/unit/sql_db_api/__init__.py', 'taskflow/tests/unit/memory_api/__init__.py', 'taskflow/tests/unit/test_sql_db_api.py', 'taskflow/backends/sqlalchemy/models.py', 'taskflow/generics/flow.py', 'taskflow/patterns/graph_flow.py', 'taskflow/patterns/linear_flow.py', 'taskflow/backends/sqlalchemy/session.py', 'taskflow/backends/sqlalchemy/api.py', 'taskflow/generics/__init__.py', 'taskflow/task.py', 'taskflow/backends/memory/memory.py', 'taskflow/backends/__init__.py', 'taskflow/tests/unit/memory_api/test_flowdetail_api.py', 'taskflow/generics/logbook.py', 'taskflow/jobboard.py', 'taskflow/backends/base.py', 'taskflow/generics/job.py', 'taskflow/logbook.py', 'taskflow/tests/unit/sql_db_api/test_taskdetail_api.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d05c78c277aa186355c24504066a1c49b1c5f22d', 'message': 'Added Generic Persistence API and Datatypes\n\nAdded a generic persistence API for JobBoards,\nJobs, LogBooks, Workflows, FlowDetails, Tasks,\nand TaskDetails. The currently implemented\nbackends are in-memory and sqlite db (by use\nof sqlalchemy). Also implemented generic return\ntypes (listed above) for the generic API.\n\nChange-Id: Ib6b108ec3cfbba4ebd31656a45eb446687e44422\n'}]",145,36736,d05c78c277aa186355c24504066a1c49b1c5f22d,16,2,1,7839,,,0,"Added Generic Persistence API and Datatypes

Added a generic persistence API for JobBoards,
Jobs, LogBooks, Workflows, FlowDetails, Tasks,
and TaskDetails. The currently implemented
backends are in-memory and sqlite db (by use
of sqlalchemy). Also implemented generic return
types (listed above) for the generic API.

Change-Id: Ib6b108ec3cfbba4ebd31656a45eb446687e44422
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/36/36736/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/generics/taskdetail.py', 'taskflow/tests/unit/test_linear_flow.py', 'taskflow/job.py', 'taskflow/tests/unit/memory_api/test_logbook_api.py', 'taskflow/tests/unit/memory_api/test_taskdetail_api.py', 'taskflow/backends/memory/api.py', 'taskflow/backends/memory/lockingdict.py', 'taskflow/tests/unit/sql_db_api/test_flowdetail_api.py', 'taskflow/backends/memory/__init__.py', 'taskflow/backends/migration.py', 'taskflow/catalog.py', 'taskflow/db/api.py', 'taskflow/tests/unit/test_memory.py', 'taskflow/backends/api.py', 'taskflow/backends/memory.py', 'taskflow/utils.py', 'taskflow/generics/task.py', 'taskflow/tests/utils.py', 'taskflow/backends/sqlalchemy/__init__.py', 'taskflow/generics/jobboard.py', 'taskflow/generics/flowdetail.py', 'taskflow/tests/unit/sql_db_api/test_logbook_api.py', 'taskflow/db/sqlalchemy/api.py', 'taskflow/tests/unit/sql_db_api/__init__.py', 'taskflow/tests/unit/memory_api/__init__.py', 'taskflow/tests/unit/test_sql_db_api.py', 'taskflow/backends/sqlalchemy/models.py', 'taskflow/generics/flow.py', 'taskflow/patterns/graph_flow.py', 'taskflow/patterns/linear_flow.py', 'taskflow/backends/sqlalchemy/session.py', 'taskflow/backends/sqlalchemy/api.py', 'taskflow/generics/__init__.py', 'taskflow/task.py', 'taskflow/backends/memory/memory.py', 'taskflow/backends/__init__.py', 'taskflow/tests/unit/memory_api/test_flowdetail_api.py', 'taskflow/generics/logbook.py', 'taskflow/jobboard.py', 'taskflow/backends/base.py', 'taskflow/generics/job.py', 'taskflow/logbook.py', 'taskflow/tests/unit/sql_db_api/test_taskdetail_api.py']",43,d05c78c277aa186355c24504066a1c49b1c5f22d,generic-api,"# -*- coding: utf-8 -*- # vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright (C) 2013 Rackspace Hosting All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Import required libraries"""""" import unittest2 from taskflow.backends import api as b_api from taskflow.generics import task, taskdetail from taskflow.openstack.common import exception, uuidutils from taskflow.tests import utils class TaskDetailTest(unittest2.TestCase): tsks = [] td_names = [] td_ids = [] @classmethod def setUpClass(cls): task_id = uuidutils.generate_uuid() task_name = 'task-%s' % (task_id) tsk = task.Task(task_name, task_id) tsk.requires.update('r') tsk.optional.update('o') tsk.provides.update('p') cls.tsks.append(tsk) @classmethod def tearDownClass(cls): utils.drain(cls.tsks) def setUp(self): td_id = uuidutils.generate_uuid() td_name = 'td-%s' % (td_id) b_api.taskdetail_create(td_name, self.tsks[0], td_id) self.td_names.append(td_name) self.td_ids.append(td_id) def tearDown(self): for id in self.td_ids: b_api.taskdetail_destroy(id) utils.drain(self.td_names) utils.drain(self.td_ids) def test_taskdetail_create(self): td_id = uuidutils.generate_uuid() td_name = 'td-%s' % (td_id) b_api.taskdetail_create(td_name, self.tsks[0], td_id) self.td_names.append(td_name) self.td_ids.append(td_id) actual = b_api.taskdetail_get(td_id) self.assertIsNotNone(actual) def test_taskdetail_destroy(self): id = self.td_ids.pop() b_api.taskdetail_destroy(id) self.td_names.pop() self.assertRaises(exception.NotFound, b_api.taskdetail_get, id) def test_taskdetail_save(self): td_id = uuidutils.generate_uuid() td_name = 'td-%s' % (td_id) tsk = self.tsks[0] td = taskdetail.TaskDetail(td_name, tsk, td_id) b_api.taskdetail_save(td) self.td_names.append(td_name) self.td_ids.append(td_id) actual = b_api.taskdetail_get(td_id) self.assertIsNotNone(actual) self.assertIsNone(actual.state) self.assertIsNone(actual.results) self.assertIsNone(actual.exception) self.assertIsNone(actual.stacktrace) self.assertIsNone(actual.meta) td.state = 'SUCCESS' td.exception = 'ERROR' td.stacktrace = 'STACKTRACE' td.meta = 'META' b_api.taskdetail_save(td) actual = b_api.taskdetail_get(td_id) self.assertEquals(actual.state, 'SUCCESS') self.assertIsNone(actual.results) self.assertEquals(actual.exception, 'ERROR') self.assertEquals(actual.stacktrace, 'STACKTRACE') self.assertEquals(actual.meta, 'META') def test_taskdetail_delete(self): id = self.td_ids.pop() td = b_api.taskdetail_get(id) b_api.taskdetail_delete(td) self.td_names.pop() self.assertRaises(exception.NotFound, b_api.taskdetail_get, id) def test_taskdetail_get(self): actual = b_api.taskdetail_get(self.td_ids[0]) self.assertIsInstance(actual, taskdetail.TaskDetail) self.assertEquals(actual.name, self.td_names[0]) def test_taskdetail_update(self): actual = b_api.taskdetail_get(self.td_ids[0]) self.assertIsNone(actual.state) self.assertIsNone(actual.results) self.assertIsNone(actual.exception) self.assertIsNone(actual.stacktrace) self.assertIsNone(actual.meta) values = dict(state='SUCCESS', exception='ERROR', stacktrace='STACKTRACE', meta='META') b_api.taskdetail_update(self.td_ids[0], values) actual = b_api.taskdetail_get(self.td_ids[0]) self.assertEquals(actual.state, 'SUCCESS') self.assertIsNone(actual.results) self.assertEquals(actual.exception, 'ERROR') self.assertEquals(actual.stacktrace, 'STACKTRACE') self.assertEquals(actual.meta, 'META') def test_taskdetail_get_ids_names(self): actual = b_api.taskdetail_get_ids_names() self.assertEquals(actual.values(), self.td_names) self.assertEquals(actual.keys(), self.td_ids) ",,2602,2000
openstack%2Fneutron~master~I0e29ec033969c3fb958ed3a12b8962b73b0e3d94,openstack/neutron,master,I0e29ec033969c3fb958ed3a12b8962b73b0e3d94,Fix DHCP agent to work with latest dnsmasq,MERGED,2013-07-23 21:20:20.000000000,2013-07-24 19:41:09.000000000,2013-07-24 19:41:08.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 107}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-07-23 21:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d525c4c1a7b850735ba476207dd77a8796af60fb', 'message': 'Fix DHCP agent to work with latest dnsmasq\n\nThe latest dnsmasq no longer accepts hostnames which begin with a number. This\naffects Fedora 19 right now, and will mean Fedora 19 will not work with Neutron\nDHCP. dnsmasq should work with hostnames beginning with a number (RFC 1123 says\nthis is valid), but until this is fixed, many users will be left unable to use\nFedora 19 with Neutron.\n\nThis patch adds a ""host-"" prefix to each hostname entry generated by the DHCP\nagent. This fixes the issue in Neutron.\n\nFixes bug 1204125\n\nChange-Id: I0e29ec033969c3fb958ed3a12b8962b73b0e3d94\n'}, {'number': 2, 'created': '2013-07-24 16:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a0aa2ab578c7053acb3551f0ae7f9850565d623e', 'message': 'Fix DHCP agent to work with latest dnsmasq\n\nThe latest dnsmasq no longer accepts hostnames which begin with a number. This\naffects Fedora 19 right now, and will mean Fedora 19 will not work with Neutron\nDHCP. dnsmasq should work with hostnames beginning with a number (RFC 1123 says\nthis is valid), but until this is fixed, many users will be left unable to use\nFedora 19 with Neutron.\n\nThis patch adds a ""host-"" prefix to each hostname entry generated by the DHCP\nagent. This fixes the issue in Neutron.\n\nFixes bug 1204125\n\nChange-Id: I0e29ec033969c3fb958ed3a12b8962b73b0e3d94\n'}, {'number': 3, 'created': '2013-07-24 18:03:45.000000000', 'files': ['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/acebf769a41a9a55cdc6789bf4962ea64cf87773', 'message': 'Fix DHCP agent to work with latest dnsmasq\n\nThe latest dnsmasq no longer accepts hostnames which begin with a number. This\naffects Fedora 19 right now, and will mean Fedora 19 will not work with Neutron\nDHCP. dnsmasq should work with hostnames beginning with a number (RFC 1123 says\nthis is valid), but until this is fixed, many users will be left unable to use\nFedora 19 with Neutron.\n\nThis patch adds a ""host-"" prefix to each hostname entry generated by the DHCP\nagent. This fixes the issue in Neutron.\n\nFixes bug 1204125\n\nChange-Id: I0e29ec033969c3fb958ed3a12b8962b73b0e3d94\n'}]",2,38376,acebf769a41a9a55cdc6789bf4962ea64cf87773,14,6,3,105,,,0,"Fix DHCP agent to work with latest dnsmasq

The latest dnsmasq no longer accepts hostnames which begin with a number. This
affects Fedora 19 right now, and will mean Fedora 19 will not work with Neutron
DHCP. dnsmasq should work with hostnames beginning with a number (RFC 1123 says
this is valid), but until this is fixed, many users will be left unable to use
Fedora 19 with Neutron.

This patch adds a ""host-"" prefix to each hostname entry generated by the DHCP
agent. This fixes the issue in Neutron.

Fixes bug 1204125

Change-Id: I0e29ec033969c3fb958ed3a12b8962b73b0e3d94
",git fetch https://review.opendev.org/openstack/neutron refs/changes/76/38376/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/dhcp.py'],1,d525c4c1a7b850735ba476207dd77a8796af60fb,bug/1204125," name = '%s-%s.%s' % ('host', r.sub('-', alloc.ip_address), self.conf.dhcp_domain)"," name = '%s.%s' % (r.sub('-', alloc.ip_address), self.conf.dhcp_domain)",3,2
openstack-attic%2Fcompute-api~master~I4678126362ac6ba35518c0ef76d6f6ee5f7c965d,openstack-attic/compute-api,master,I4678126362ac6ba35518c0ef76d6f6ee5f7c965d,Add documentation on how to pass in networks on server creation.,MERGED,2013-06-14 00:39:58.000000000,2013-07-24 19:39:21.000000000,2013-07-24 19:39:21.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 964}, {'_account_id': 1561}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-06-14 00:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/b7a710ba4c1979b95710cf7af4fbc9bd85998cf0', 'message': 'Add documentation on how to pass in networks on server creation.\n\nFixes bug #1121479\n\nChange-Id: I4678126362ac6ba35518c0ef76d6f6ee5f7c965d\n'}, {'number': 2, 'created': '2013-06-27 21:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/0c6af6ae0ff8ae60fb6fa4367001b343c3b7988a', 'message': 'Add documentation on how to pass in networks on server creation.\n\nFixes bug #1121479\n\nChange-Id: I4678126362ac6ba35518c0ef76d6f6ee5f7c965d\n'}, {'number': 3, 'created': '2013-07-17 17:58:47.000000000', 'files': ['openstack-compute-api-2/src/samples/server-post-req.xml', 'openstack-compute-api-2/src/os-compute-devguide.xml', 'openstack-compute-api-2/src/samples/server-post-req.json'], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/d011826c54d97812852c9ebba551c9694462dc08', 'message': 'Add documentation on how to pass in networks on server creation.\n\nFixes bug #1121479\n\nChange-Id: I4678126362ac6ba35518c0ef76d6f6ee5f7c965d\n'}]",15,32979,d011826c54d97812852c9ebba551c9694462dc08,21,7,3,748,,,0,"Add documentation on how to pass in networks on server creation.

Fixes bug #1121479

Change-Id: I4678126362ac6ba35518c0ef76d6f6ee5f7c965d
",git fetch https://review.opendev.org/openstack-attic/compute-api refs/changes/79/32979/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack-compute-api-2/src/samples/server-post-req.xml', 'openstack-compute-api-2/src/os-compute-devguide.xml', 'openstack-compute-api-2/src/samples/server-post-req.json']",3,b7a710ba4c1979b95710cf7af4fbc9bd85998cf0,bug/1121479," ], ""networks"": [ { ""uuid"": ""c6a48469-4638-4346-b755-6e66ed7abdff"", ""fixed_ip"": ""10.0.0.10"" } } } ", ] } },75,2
openstack%2Fcinder~master~Ia984fca524ee33c0ce76931187a5293fb80d8b26,openstack/cinder,master,Ia984fca524ee33c0ce76931187a5293fb80d8b26,Imported Translations from Transifex,MERGED,2013-07-19 18:10:11.000000000,2013-07-24 19:17:34.000000000,2013-07-24 19:17:33.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 4355}]","[{'number': 1, 'created': '2013-07-19 18:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b73e25d6c13914e828e7e50bd26dbf389fb4350d', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ia984fca524ee33c0ce76931187a5293fb80d8b26\n'}, {'number': 2, 'created': '2013-07-20 18:10:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ebb905bef214a7ecbe4c891b44deffa4e7512a12', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ia984fca524ee33c0ce76931187a5293fb80d8b26\n'}, {'number': 3, 'created': '2013-07-21 18:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b1421ca116cbdd0a6edbd1c3320f2b93ec914cbd', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ia984fca524ee33c0ce76931187a5293fb80d8b26\n'}, {'number': 4, 'created': '2013-07-22 18:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/aa854559a764ef1ede89e89bcd086cbf3e45d9d6', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ia984fca524ee33c0ce76931187a5293fb80d8b26\n'}, {'number': 5, 'created': '2013-07-23 18:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b2f857ea5df22e5951c0fb25f11ad43b367d7f0b', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ia984fca524ee33c0ce76931187a5293fb80d8b26\n'}, {'number': 6, 'created': '2013-07-24 18:10:06.000000000', 'files': ['cinder/locale/ko/LC_MESSAGES/cinder.po', 'cinder/locale/hu/LC_MESSAGES/cinder.po', 'cinder/locale/tr/LC_MESSAGES/cinder.po', 'cinder/locale/en_US/LC_MESSAGES/cinder.po', 'cinder/locale/fi_FI/LC_MESSAGES/cinder.po', 'cinder/locale/pt_BR/LC_MESSAGES/cinder.po', 'cinder/locale/tr_TR/LC_MESSAGES/cinder.po', 'cinder/locale/ca/LC_MESSAGES/cinder.po', 'cinder/locale/cinder.pot', 'cinder/locale/nb/LC_MESSAGES/cinder.po', 'cinder/locale/it/LC_MESSAGES/cinder.po', 'cinder/locale/zh_CN/LC_MESSAGES/cinder.po', 'cinder/locale/ko_KR/LC_MESSAGES/cinder.po', 'cinder/locale/ms/LC_MESSAGES/cinder.po', 'cinder/locale/nl_NL/LC_MESSAGES/cinder.po', 'cinder/locale/zh_HK/LC_MESSAGES/cinder.po', 'cinder/locale/es/LC_MESSAGES/cinder.po', 'cinder/locale/cs/LC_MESSAGES/cinder.po', 'cinder/locale/pt/LC_MESSAGES/cinder.po', 'cinder/locale/sw_KE/LC_MESSAGES/cinder.po', 'cinder/locale/tl/LC_MESSAGES/cinder.po', 'cinder/locale/en_GB/LC_MESSAGES/cinder.po', 'cinder/locale/ru_RU/LC_MESSAGES/cinder.po', 'cinder/locale/bg_BG/LC_MESSAGES/cinder.po', 'cinder/locale/uk/LC_MESSAGES/cinder.po', 'cinder/locale/en_AU/LC_MESSAGES/cinder.po', 'cinder/locale/fr/LC_MESSAGES/cinder.po', 'cinder/locale/id/LC_MESSAGES/cinder.po', 'cinder/locale/da/LC_MESSAGES/cinder.po', 'cinder/locale/ru/LC_MESSAGES/cinder.po', 'cinder/locale/vi_VN/LC_MESSAGES/cinder.po', 'cinder/locale/hr/LC_MESSAGES/cinder.po', 'cinder/locale/pl_PL/LC_MESSAGES/cinder.po', 'cinder/locale/ro/LC_MESSAGES/cinder.po', 'cinder/locale/ja/LC_MESSAGES/cinder.po', 'cinder/locale/ka_GE/LC_MESSAGES/cinder.po', 'cinder/locale/zh_TW/LC_MESSAGES/cinder.po', 'cinder/locale/sl_SI/LC_MESSAGES/cinder.po', 'cinder/locale/it_IT/LC_MESSAGES/cinder.po', 'cinder/locale/de/LC_MESSAGES/cinder.po', 'cinder/locale/bs/LC_MESSAGES/cinder.po'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6196bbe015a629b357a5378e88b73e8bc40a0dc1', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ia984fca524ee33c0ce76931187a5293fb80d8b26\n'}]",0,37949,6196bbe015a629b357a5378e88b73e8bc40a0dc1,22,3,6,3,,,0,"Imported Translations from Transifex

Change-Id: Ia984fca524ee33c0ce76931187a5293fb80d8b26
",git fetch https://review.opendev.org/openstack/cinder refs/changes/49/37949/6 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/locale/ko/LC_MESSAGES/cinder.po', 'cinder/locale/hu/LC_MESSAGES/cinder.po', 'cinder/locale/tr/LC_MESSAGES/cinder.po', 'cinder/locale/en_US/LC_MESSAGES/cinder.po', 'cinder/locale/fi_FI/LC_MESSAGES/cinder.po', 'cinder/locale/pt_BR/LC_MESSAGES/cinder.po', 'cinder/locale/tr_TR/LC_MESSAGES/cinder.po', 'cinder/locale/ca/LC_MESSAGES/cinder.po', 'cinder/locale/cinder.pot', 'cinder/locale/nb/LC_MESSAGES/cinder.po', 'cinder/locale/it/LC_MESSAGES/cinder.po', 'cinder/locale/zh_CN/LC_MESSAGES/cinder.po', 'cinder/locale/ko_KR/LC_MESSAGES/cinder.po', 'cinder/locale/ms/LC_MESSAGES/cinder.po', 'cinder/locale/nl_NL/LC_MESSAGES/cinder.po', 'cinder/locale/zh_HK/LC_MESSAGES/cinder.po', 'cinder/locale/es/LC_MESSAGES/cinder.po', 'cinder/locale/cs/LC_MESSAGES/cinder.po', 'cinder/locale/pt/LC_MESSAGES/cinder.po', 'cinder/locale/sw_KE/LC_MESSAGES/cinder.po', 'cinder/locale/tl/LC_MESSAGES/cinder.po', 'cinder/locale/en_GB/LC_MESSAGES/cinder.po', 'cinder/locale/ru_RU/LC_MESSAGES/cinder.po', 'cinder/locale/bg_BG/LC_MESSAGES/cinder.po', 'cinder/locale/uk/LC_MESSAGES/cinder.po', 'cinder/locale/en_AU/LC_MESSAGES/cinder.po', 'cinder/locale/fr/LC_MESSAGES/cinder.po', 'cinder/locale/id/LC_MESSAGES/cinder.po', 'cinder/locale/da/LC_MESSAGES/cinder.po', 'cinder/locale/ru/LC_MESSAGES/cinder.po', 'cinder/locale/vi_VN/LC_MESSAGES/cinder.po', 'cinder/locale/hr/LC_MESSAGES/cinder.po', 'cinder/locale/pl_PL/LC_MESSAGES/cinder.po', 'cinder/locale/ro/LC_MESSAGES/cinder.po', 'cinder/locale/ja/LC_MESSAGES/cinder.po', 'cinder/locale/ka_GE/LC_MESSAGES/cinder.po', 'cinder/locale/zh_TW/LC_MESSAGES/cinder.po', 'cinder/locale/sl_SI/LC_MESSAGES/cinder.po', 'cinder/locale/it_IT/LC_MESSAGES/cinder.po', 'cinder/locale/de/LC_MESSAGES/cinder.po', 'cinder/locale/bs/LC_MESSAGES/cinder.po']",41,b73e25d6c13914e828e7e50bd26dbf389fb4350d,transifex/translations,"""POT-Creation-Date: 2013-07-19 18:09+0000\n""#: cinder/tests/fake_driver.py:45 cinder/volume/driver.py:525#: cinder/tests/test_storwize_svc.py:244#: cinder/tests/test_storwize_svc.py:1222#: cinder/tests/test_storwize_svc.py:1225#: cinder/tests/test_storwize_svc.py:1230#: cinder/volume/manager.py:610#: cinder/volume/driver.py:281#: cinder/volume/driver.py:307 cinder/volume/drivers/emc/emc_smis_iscsi.py:113#: cinder/volume/driver.py:355#: cinder/volume/driver.py:359 cinder/volume/drivers/emc/emc_smis_iscsi.py:156#: cinder/volume/driver.py:452#: cinder/volume/driver.py:482 cinder/volume/manager.py:772#: cinder/volume/drivers/storwize_svc.py:1359#: cinder/volume/driver.py:563#: cinder/volume/manager.py:235#: cinder/volume/manager.py:246#: cinder/volume/manager.py:250#: cinder/volume/manager.py:254#: cinder/volume/manager.py:263#: cinder/volume/manager.py:274#: cinder/volume/manager.py:301#: cinder/volume/manager.py:322#: cinder/volume/manager.py:332#: cinder/volume/manager.py:375#: cinder/volume/manager.py:383#: cinder/volume/manager.py:402#: cinder/volume/manager.py:415#: cinder/volume/manager.py:419#: cinder/volume/manager.py:424#: cinder/volume/manager.py:453 cinder/volume/manager.py:466#: cinder/volume/manager.py:459#: cinder/volume/manager.py:464#: cinder/volume/manager.py:469#: cinder/volume/manager.py:492#: cinder/volume/manager.py:496#: cinder/volume/manager.py:511#: cinder/volume/manager.py:516#: cinder/volume/manager.py:535#: cinder/volume/manager.py:544 cinder/volume/manager.py:549#: cinder/volume/manager.py:552#: cinder/volume/manager.py:582#: cinder/volume/manager.py:585#: cinder/volume/manager.py:603#: cinder/volume/manager.py:607#: cinder/volume/manager.py:673 cinder/volume/manager.py:678#: cinder/volume/manager.py:683#: cinder/volume/manager.py:702#: cinder/volume/manager.py:785#: cinder/volume/manager.py:789#: cinder/volume/manager.py:827#: cinder/volume/manager.py:838#: cinder/volume/manager.py:840#: cinder/volume/manager.py:842#: cinder/volume/drivers/storwize_svc.py:360#: cinder/volume/drivers/storwize_svc.py:396#: cinder/volume/drivers/storwize_svc.py:419#: cinder/volume/drivers/storwize_svc.py:487#: cinder/volume/drivers/storwize_svc.py:515#: cinder/volume/drivers/storwize_svc.py:527#: cinder/volume/drivers/storwize_svc.py:542#: cinder/volume/drivers/storwize_svc.py:555#: cinder/volume/drivers/storwize_svc.py:578#: cinder/volume/drivers/storwize_svc.py:611#: cinder/volume/drivers/storwize_svc.py:621#: cinder/volume/drivers/storwize_svc.py:627#: cinder/volume/drivers/storwize_svc.py:637#: cinder/volume/drivers/storwize_svc.py:645#: cinder/volume/drivers/storwize_svc.py:671#: cinder/volume/drivers/storwize_svc.py:690#: cinder/volume/drivers/storwize_svc.py:706#: cinder/volume/drivers/storwize_svc.py:717#: cinder/volume/drivers/storwize_svc.py:724#: cinder/volume/drivers/storwize_svc.py:726#: cinder/volume/drivers/storwize_svc.py:743#: cinder/volume/drivers/storwize_svc.py:751#: cinder/volume/drivers/storwize_svc.py:784#: cinder/volume/drivers/storwize_svc.py:789#: cinder/volume/drivers/storwize_svc.py:807#: cinder/volume/drivers/storwize_svc.py:817#: cinder/volume/drivers/storwize_svc.py:832#: cinder/volume/drivers/storwize_svc.py:840#: cinder/volume/drivers/storwize_svc.py:897#: cinder/volume/drivers/storwize_svc.py:921#: cinder/volume/drivers/storwize_svc.py:959#: cinder/volume/drivers/storwize_svc.py:964#: cinder/volume/drivers/storwize_svc.py:976 #: cinder/volume/drivers/storwize_svc.py:990#: cinder/volume/drivers/storwize_svc.py:1002 #: cinder/volume/drivers/storwize_svc.py:1012#: cinder/volume/drivers/storwize_svc.py:1026#: cinder/volume/drivers/storwize_svc.py:1053#: cinder/volume/drivers/storwize_svc.py:1064#: cinder/volume/drivers/storwize_svc.py:1069#: cinder/volume/drivers/storwize_svc.py:1076#: cinder/volume/drivers/storwize_svc.py:1083#: cinder/volume/drivers/storwize_svc.py:1094#: cinder/volume/drivers/storwize_svc.py:1106#: cinder/volume/drivers/storwize_svc.py:1114#: cinder/volume/drivers/storwize_svc.py:1121#: cinder/volume/drivers/storwize_svc.py:1133#: cinder/volume/drivers/storwize_svc.py:1143#: cinder/volume/drivers/storwize_svc.py:1148#: cinder/volume/drivers/storwize_svc.py:1170#: cinder/volume/drivers/storwize_svc.py:1178#: cinder/volume/drivers/storwize_svc.py:1180#: cinder/volume/drivers/storwize_svc.py:1208#: cinder/volume/drivers/storwize_svc.py:1213#: cinder/volume/drivers/storwize_svc.py:1239#: cinder/volume/drivers/storwize_svc.py:1272#: cinder/volume/drivers/storwize_svc.py:1297#: cinder/volume/drivers/storwize_svc.py:1311#: cinder/volume/drivers/storwize_svc.py:1376#: cinder/volume/drivers/storwize_svc.py:1388#: cinder/volume/drivers/storwize_svc.py:1389#: cinder/volume/drivers/storwize_svc.py:1427#: cinder/volume/drivers/storwize_svc.py:1433#: cinder/volume/drivers/storwize_svc.py:1440#: cinder/volume/drivers/storwize_svc.py:1447#: cinder/volume/drivers/storwize_svc.py:1452#: cinder/volume/drivers/storwize_svc.py:1458#: cinder/volume/drivers/storwize_svc.py:1467#: cinder/volume/drivers/storwize_svc.py:1479#: cinder/volume/drivers/storwize_svc.py:1486#: cinder/volume/drivers/storwize_svc.py:1503#: cinder/volume/drivers/storwize_svc.py:1522#: cinder/volume/drivers/storwize_svc.py:1530#: cinder/volume/drivers/storwize_svc.py:1544#: cinder/volume/drivers/storwize_svc.py:1552","""POT-Creation-Date: 2013-07-18 18:09+0000\n""#: cinder/tests/fake_driver.py:45 cinder/volume/driver.py:524#: cinder/tests/test_storwize_svc.py:242#: cinder/tests/test_storwize_svc.py:1215#: cinder/tests/test_storwize_svc.py:1218#: cinder/tests/test_storwize_svc.py:1223#: cinder/volume/manager.py:606#: cinder/volume/driver.py:280#: cinder/volume/driver.py:306 cinder/volume/drivers/emc/emc_smis_iscsi.py:113#: cinder/volume/driver.py:354#: cinder/volume/driver.py:358 cinder/volume/drivers/emc/emc_smis_iscsi.py:156#: cinder/volume/driver.py:451#: cinder/volume/driver.py:481 cinder/volume/manager.py:768#: cinder/volume/drivers/storwize_svc.py:1356#: cinder/volume/driver.py:562#: cinder/volume/manager.py:231#: cinder/volume/manager.py:242#: cinder/volume/manager.py:246#: cinder/volume/manager.py:250#: cinder/volume/manager.py:259#: cinder/volume/manager.py:270#: cinder/volume/manager.py:297#: cinder/volume/manager.py:318#: cinder/volume/manager.py:328#: cinder/volume/manager.py:371#: cinder/volume/manager.py:379#: cinder/volume/manager.py:398#: cinder/volume/manager.py:411#: cinder/volume/manager.py:415#: cinder/volume/manager.py:420#: cinder/volume/manager.py:449 cinder/volume/manager.py:462#: cinder/volume/manager.py:455#: cinder/volume/manager.py:460#: cinder/volume/manager.py:465#: cinder/volume/manager.py:488#: cinder/volume/manager.py:492#: cinder/volume/manager.py:507#: cinder/volume/manager.py:512#: cinder/volume/manager.py:531#: cinder/volume/manager.py:540 cinder/volume/manager.py:545#: cinder/volume/manager.py:548#: cinder/volume/manager.py:578#: cinder/volume/manager.py:581#: cinder/volume/manager.py:599#: cinder/volume/manager.py:603#: cinder/volume/manager.py:669 cinder/volume/manager.py:674#: cinder/volume/manager.py:679#: cinder/volume/manager.py:698#: cinder/volume/manager.py:781#: cinder/volume/manager.py:785#: cinder/volume/manager.py:823#: cinder/volume/manager.py:834#: cinder/volume/manager.py:836#: cinder/volume/manager.py:838#: cinder/volume/drivers/storwize_svc.py:359#: cinder/volume/drivers/storwize_svc.py:395#: cinder/volume/drivers/storwize_svc.py:418#: cinder/volume/drivers/storwize_svc.py:486#: cinder/volume/drivers/storwize_svc.py:514#: cinder/volume/drivers/storwize_svc.py:526#: cinder/volume/drivers/storwize_svc.py:541#: cinder/volume/drivers/storwize_svc.py:557#: cinder/volume/drivers/storwize_svc.py:580#: cinder/volume/drivers/storwize_svc.py:610#: cinder/volume/drivers/storwize_svc.py:623#: cinder/volume/drivers/storwize_svc.py:629#: cinder/volume/drivers/storwize_svc.py:639#: cinder/volume/drivers/storwize_svc.py:647#: cinder/volume/drivers/storwize_svc.py:673#: cinder/volume/drivers/storwize_svc.py:692#: cinder/volume/drivers/storwize_svc.py:708#: cinder/volume/drivers/storwize_svc.py:719#: cinder/volume/drivers/storwize_svc.py:726#: cinder/volume/drivers/storwize_svc.py:728#: cinder/volume/drivers/storwize_svc.py:745#: cinder/volume/drivers/storwize_svc.py:753#: cinder/volume/drivers/storwize_svc.py:786#: cinder/volume/drivers/storwize_svc.py:791#: cinder/volume/drivers/storwize_svc.py:809#: cinder/volume/drivers/storwize_svc.py:819#: cinder/volume/drivers/storwize_svc.py:834#: cinder/volume/drivers/storwize_svc.py:842#: cinder/volume/drivers/storwize_svc.py:899#: cinder/volume/drivers/storwize_svc.py:923#: cinder/volume/drivers/storwize_svc.py:957#: cinder/volume/drivers/storwize_svc.py:962#: cinder/volume/drivers/storwize_svc.py:972 #: cinder/volume/drivers/storwize_svc.py:986#: cinder/volume/drivers/storwize_svc.py:998 #: cinder/volume/drivers/storwize_svc.py:1008#: cinder/volume/drivers/storwize_svc.py:1022#: cinder/volume/drivers/storwize_svc.py:1049#: cinder/volume/drivers/storwize_svc.py:1060#: cinder/volume/drivers/storwize_svc.py:1065#: cinder/volume/drivers/storwize_svc.py:1072#: cinder/volume/drivers/storwize_svc.py:1079#: cinder/volume/drivers/storwize_svc.py:1090#: cinder/volume/drivers/storwize_svc.py:1102#: cinder/volume/drivers/storwize_svc.py:1110#: cinder/volume/drivers/storwize_svc.py:1117#: cinder/volume/drivers/storwize_svc.py:1129#: cinder/volume/drivers/storwize_svc.py:1139#: cinder/volume/drivers/storwize_svc.py:1144#: cinder/volume/drivers/storwize_svc.py:1166#: cinder/volume/drivers/storwize_svc.py:1174#: cinder/volume/drivers/storwize_svc.py:1176#: cinder/volume/drivers/storwize_svc.py:1204#: cinder/volume/drivers/storwize_svc.py:1209#: cinder/volume/drivers/storwize_svc.py:1235#: cinder/volume/drivers/storwize_svc.py:1269#: cinder/volume/drivers/storwize_svc.py:1294#: cinder/volume/drivers/storwize_svc.py:1308#: cinder/volume/drivers/storwize_svc.py:1373#: cinder/volume/drivers/storwize_svc.py:1385#: cinder/volume/drivers/storwize_svc.py:1386#: cinder/volume/drivers/storwize_svc.py:1424#: cinder/volume/drivers/storwize_svc.py:1430#: cinder/volume/drivers/storwize_svc.py:1437#: cinder/volume/drivers/storwize_svc.py:1444#: cinder/volume/drivers/storwize_svc.py:1449#: cinder/volume/drivers/storwize_svc.py:1455#: cinder/volume/drivers/storwize_svc.py:1464#: cinder/volume/drivers/storwize_svc.py:1476#: cinder/volume/drivers/storwize_svc.py:1483#: cinder/volume/drivers/storwize_svc.py:1500#: cinder/volume/drivers/storwize_svc.py:1519#: cinder/volume/drivers/storwize_svc.py:1527#: cinder/volume/drivers/storwize_svc.py:1541#: cinder/volume/drivers/storwize_svc.py:1549",5290,5290
openstack%2Fswift~master~Icb99d5c59227a32994db25afe3d11c59767e09b1,openstack/swift,master,Icb99d5c59227a32994db25afe3d11c59767e09b1,Move the mount checking into the _diskfile method,ABANDONED,2013-07-03 15:50:21.000000000,2013-07-24 19:17:14.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 4108}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-07-03 15:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/97ba38fd2789c8561e8058cac943902b2804b3e1', 'message': 'Move the mount checking into the _diskfile method\n\nChange-Id: Icb99d5c59227a32994db25afe3d11c59767e09b1\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 2, 'created': '2013-07-03 19:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/031b43f1ca8972035d5eddc071d657bb31735f6b', 'message': 'Move the mount checking into the _diskfile method\n\nChange-Id: Icb99d5c59227a32994db25afe3d11c59767e09b1\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 3, 'created': '2013-07-05 21:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bf98e2fc40e69a79c258e45ebd2d35e02fe0a57e', 'message': 'Move the mount checking into the _diskfile method\n\nChange-Id: Icb99d5c59227a32994db25afe3d11c59767e09b1\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 4, 'created': '2013-07-16 01:20:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6fc9f1ce7951ef841d29f39669067eef9dd04e8f', 'message': 'Move the mount checking into the _diskfile method\n\nChange-Id: Icb99d5c59227a32994db25afe3d11c59767e09b1\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 5, 'created': '2013-07-19 20:47:17.000000000', 'files': ['swift/obj/server.py', 'swift/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c46a3ef999b825cb8346486d51b349c29a3e0663', 'message': 'Move the mount checking into the _diskfile method\n\nChange-Id: Icb99d5c59227a32994db25afe3d11c59767e09b1\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",0,35505,c46a3ef999b825cb8346486d51b349c29a3e0663,17,6,5,6198,,,0,"Move the mount checking into the _diskfile method

Change-Id: Icb99d5c59227a32994db25afe3d11c59767e09b1
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/05/35505/5 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/server.py', 'swift/common/exceptions.py']",2,97ba38fd2789c8561e8058cac943902b2804b3e1,quarantine,class DiskFileMountError(SwiftException): pass ,,22,12
openstack%2Fsahara~master~Ie408c0d368e172c92e4823bed8fdbebefa0b3739,openstack/sahara,master,Ie408c0d368e172c92e4823bed8fdbebefa0b3739,Added REST API skeleton for EDP component,MERGED,2013-07-24 13:51:47.000000000,2013-07-24 19:10:38.000000000,2013-07-24 19:10:38.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 6823}, {'_account_id': 7125}, {'_account_id': 7132}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-24 13:51:47.000000000', 'files': ['savanna/service/edp/__init__.py', 'savanna/api/v11.py', 'savanna/main.py', 'savanna/service/edp/api.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/791c607f633d5eace6b841e6412229646c6a762c', 'message': 'Added REST API skeleton for EDP component\n\nChange-Id: Ie408c0d368e172c92e4823bed8fdbebefa0b3739\n'}]",3,38472,791c607f633d5eace6b841e6412229646c6a762c,13,6,1,6823,,,0,"Added REST API skeleton for EDP component

Change-Id: Ie408c0d368e172c92e4823bed8fdbebefa0b3739
",git fetch https://review.opendev.org/openstack/sahara refs/changes/72/38472/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/service/edp/__init__.py', 'savanna/api/v11.py', 'savanna/main.py', 'savanna/service/edp/api.py']",4,791c607f633d5eace6b841e6412229646c6a762c,edp,"# Copyright (c) 2013 Mirantis Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. def get_jobs(): return [] ",,52,0
openstack%2Fnova~stable%2Fgrizzly~Iaba099225a9b3b0390cae4c5fbd82d7e6c11f0e0,openstack/nova,stable/grizzly,Iaba099225a9b3b0390cae4c5fbd82d7e6c11f0e0,Naming instance directory by uuid in VMware Hyper.,MERGED,2013-07-20 17:43:52.000000000,2013-07-24 18:23:25.000000000,2013-07-24 18:23:23.000000000,"[{'_account_id': 3}, {'_account_id': 1313}, {'_account_id': 1420}, {'_account_id': 1653}]","[{'number': 1, 'created': '2013-07-20 17:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d99adef843e286184649add4109f08155b6420f0', 'message': 'Naming instance directory by uuid in VMware Hyper.\n\nLike Libvirt Hyper, Using EC2 template for naming instance\ndirectory may cause conflict. we follow what Libvirt does to use\ninstance uuid instead of EC2 template naming. To keep backwards\ncompability, when fails to find a instance by uuid, fall back to use\nEC2 name.\n\nFix bug #1186944\n\n(cherry picked from commit e517e5668ab20214432e06ef87f7b16776edaf7c)\n\nConflicts:\n\n\tnova/tests/vmwareapi/db_fakes.py\n\tnova/virt/vmwareapi/vmops.py\n\nChange-Id: Iaba099225a9b3b0390cae4c5fbd82d7e6c11f0e0\n'}, {'number': 2, 'created': '2013-07-24 07:22:11.000000000', 'files': ['nova/tests/vmwareapi/db_fakes.py', 'nova/virt/vmwareapi/vmops.py', 'nova/tests/test_vmwareapi.py', 'nova/virt/vmwareapi/vm_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7ad1db6140c49c85ba643a6217878ef8f3d30463', 'message': 'Naming instance directory by uuid in VMware Hyper.\n\nLike Libvirt Hyper, Using EC2 template for naming instance\ndirectory may cause conflict. we follow what Libvirt does to use\ninstance uuid instead of EC2 template naming. To keep backwards\ncompability, when fails to find a instance by uuid, fall back to use\nEC2 name.\n\nFix bug #1186944\n\n(cherry picked from commit e517e5668ab20214432e06ef87f7b16776edaf7c)\n\nConflicts:\n\n\tnova/tests/vmwareapi/db_fakes.py\n\tnova/virt/vmwareapi/vmops.py\n\nChange-Id: Iaba099225a9b3b0390cae4c5fbd82d7e6c11f0e0\n'}]",0,38043,7ad1db6140c49c85ba643a6217878ef8f3d30463,17,4,2,1653,,,0,"Naming instance directory by uuid in VMware Hyper.

Like Libvirt Hyper, Using EC2 template for naming instance
directory may cause conflict. we follow what Libvirt does to use
instance uuid instead of EC2 template naming. To keep backwards
compability, when fails to find a instance by uuid, fall back to use
EC2 name.

Fix bug #1186944

(cherry picked from commit e517e5668ab20214432e06ef87f7b16776edaf7c)

Conflicts:

	nova/tests/vmwareapi/db_fakes.py
	nova/virt/vmwareapi/vmops.py

Change-Id: Iaba099225a9b3b0390cae4c5fbd82d7e6c11f0e0
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/38043/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/vmwareapi/db_fakes.py', 'nova/virt/vmwareapi/vmops.py', 'nova/tests/test_vmwareapi.py', 'nova/virt/vmwareapi/vm_util.py']",4,d99adef843e286184649add4109f08155b6420f0,bug/1186944," config_spec.name = instance['uuid']def get_vm_ref_from_uuid(session, instance_uuid): """"""Get reference to the VM with the uuid specified."""""" vms = session._call_method(vim_util, ""get_objects"", ""VirtualMachine"", [""name""]) for vm in vms: if vm.propSet[0].val == instance_uuid: return vm.obj def get_vm_ref(session, instance): """"""Get reference to the VM through uuid or vm name."""""" vm_ref = get_vm_ref_from_uuid(session, instance['uuid']) if not vm_ref: vm_ref = get_vm_ref_from_name(session, instance['name']) if vm_ref is None: raise exception.InstanceNotFound(instance_id=instance['uuid']) return vm_ref ", config_spec.name = instance['name'],86,93
openstack%2Fheat~master~I2a02b490e45c3cb838243b9dad62cc52b609b336,openstack/heat,master,I2a02b490e45c3cb838243b9dad62cc52b609b336,Fix loguserdata output to file issue,MERGED,2013-07-23 10:15:57.000000000,2013-07-24 18:15:17.000000000,2013-07-24 18:15:16.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7040}]","[{'number': 1, 'created': '2013-07-23 10:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6041f9dcfabb45877845dfbcf1b1fcc7c7c4dcd8', 'message': 'Fix loguserdata output to file issue\n\nFixes bug #1191685\n\nChange-Id: I2a02b490e45c3cb838243b9dad62cc52b609b336\n'}, {'number': 2, 'created': '2013-07-23 10:50:11.000000000', 'files': ['heat/cloudinit/loguserdata.py', 'heat/tests/test_loguserdata.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/dc416551760b042ede6f844537c394316743073d', 'message': 'Fix loguserdata output to file issue\n\nFixes bug #1191685\n\nChange-Id: I2a02b490e45c3cb838243b9dad62cc52b609b336\n'}]",1,38276,dc416551760b042ede6f844537c394316743073d,8,7,2,7040,,,0,"Fix loguserdata output to file issue

Fixes bug #1191685

Change-Id: I2a02b490e45c3cb838243b9dad62cc52b609b336
",git fetch https://review.opendev.org/openstack/heat refs/changes/76/38276/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/cloudinit/loguserdata.py'],1,6041f9dcfabb45877845dfbcf1b1fcc7c7c4dcd8,bug/1191685," p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE) data = p.communicate() if data: for x in data: ls.write(x)"," def __getattr__(self, attr): return getattr(sys.stdout, attr) p = subprocess.Popen(args, stdout=ls, stderr=ls) p.wait()",6,5
openstack%2Fneutron~master~Iecab3832ba9fd65099b354d5bf9f80d1a063a762,openstack/neutron,master,Iecab3832ba9fd65099b354d5bf9f80d1a063a762,Imported Translations from Transifex,MERGED,2013-07-23 19:55:17.000000000,2013-07-24 18:15:09.000000000,2013-07-24 18:15:09.000000000,"[{'_account_id': 3}, {'_account_id': 2031}, {'_account_id': 2592}]","[{'number': 1, 'created': '2013-07-23 19:55:17.000000000', 'files': ['neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7f0ba38b0f47629d239ea6f67beafac2b89d727f', 'message': 'Imported Translations from Transifex\n\nChange-Id: Iecab3832ba9fd65099b354d5bf9f80d1a063a762\n'}]",0,38362,7f0ba38b0f47629d239ea6f67beafac2b89d727f,10,3,1,3,,,0,"Imported Translations from Transifex

Change-Id: Iecab3832ba9fd65099b354d5bf9f80d1a063a762
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/38362/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po']",40,7f0ba38b0f47629d239ea6f67beafac2b89d727f,transifex/translations,"""POT-Creation-Date: 2013-07-23 19:54+0000\n""#: neutron/agent/linux/ovs_lib.py:232#: neutron/agent/linux/ovs_lib.py:295#: neutron/agent/linux/ovs_lib.py:313#: neutron/agent/linux/ovs_lib.py:322#: neutron/agent/linux/ovs_lib.py:331#: neutron/agent/linux/ovs_lib.py:342#: neutron/agent/linux/ovs_lib.py:354#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:211#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:232#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:291#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:377#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:336#: neutron/plugins/cisco/db/network_db_v2.py:108#: neutron/plugins/cisco/common/config.py:38#: neutron/plugins/cisco/common/config.py:42#: neutron/plugins/cisco/common/config.py:46#: neutron/plugins/cisco/db/network_db_v2.py:33 #: neutron/plugins/cisco/db/network_db_v2.py:100#: neutron/plugins/cisco/db/network_db_v2.py:40#: neutron/plugins/cisco/db/network_db_v2.py:52#: neutron/plugins/cisco/db/network_db_v2.py:67#: neutron/plugins/cisco/db/network_db_v2.py:81#: neutron/plugins/cisco/db/network_db_v2.py:116#: neutron/plugins/cisco/db/network_db_v2.py:130#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:137#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:138#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:358#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:413#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:434 #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:461#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:449#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:734#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:747#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:868#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:762#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:753#: neutron/tests/unit/openvswitch/test_ovs_tunnel.py:382#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:720#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:740#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:772#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:780#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:791#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:798#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:803#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:818#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:837#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:840#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:856#~ msgid ""VLAN start value"" #~ msgstr """" #~ msgid ""VLAN end value"" #~ msgstr """" #~ msgid ""Maximum Port value"" #~ msgstr """" #~ msgid ""Maximum Port Profile value"" #~ msgstr """" #~ msgid ""Maximum Network value"" #~ msgstr """" #~ msgid ""Manager Class"" #~ msgstr """" #~ msgid ""create_vlanids() called"" #~ msgstr """" ","""POT-Creation-Date: 2013-07-22 19:54+0000\n""#: neutron/agent/linux/ovs_lib.py:230#: neutron/agent/linux/ovs_lib.py:293#: neutron/agent/linux/ovs_lib.py:311#: neutron/agent/linux/ovs_lib.py:320#: neutron/agent/linux/ovs_lib.py:329#: neutron/agent/linux/ovs_lib.py:340#: neutron/agent/linux/ovs_lib.py:352#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:205#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:226#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:282#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:368#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:327#: neutron/plugins/cisco/db/network_db_v2.py:128msgid ""VLAN start value"" msgstr """" #: neutron/plugins/cisco/common/config.py:38 msgid ""VLAN end value"" msgstr """" #: neutron/plugins/cisco/common/config.py:40#: neutron/plugins/cisco/common/config.py:42 msgid ""Maximum Port value"" msgstr """" #: neutron/plugins/cisco/common/config.py:44 msgid ""Maximum Port Profile value"" msgstr """" #: neutron/plugins/cisco/common/config.py:46 msgid ""Maximum Network value"" msgstr """" #: neutron/plugins/cisco/common/config.py:48#: neutron/plugins/cisco/common/config.py:52#: neutron/plugins/cisco/common/config.py:56 msgid ""Manager Class"" msgstr """" #: neutron/plugins/cisco/common/config.py:60#: neutron/plugins/cisco/db/network_db_v2.py:34 msgid ""create_vlanids() called"" msgstr """" #: neutron/plugins/cisco/db/network_db_v2.py:53 #: neutron/plugins/cisco/db/network_db_v2.py:120#: neutron/plugins/cisco/db/network_db_v2.py:60#: neutron/plugins/cisco/db/network_db_v2.py:72#: neutron/plugins/cisco/db/network_db_v2.py:87#: neutron/plugins/cisco/db/network_db_v2.py:101#: neutron/plugins/cisco/db/network_db_v2.py:136#: neutron/plugins/cisco/db/network_db_v2.py:150#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:131#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:132#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:349#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:403#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:424 #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:451#: neutron/plugins/cisco/models/virt_phy_sw_v2.py:439#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:733#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:746#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:867#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:761#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:752#: neutron/tests/unit/openvswitch/test_ovs_tunnel.py:381#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:719#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:739#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:771#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:779#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:790#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:797#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:802#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:817#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:836#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:839#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:855",2780,3081
openstack%2Fhorizon~master~I7389652cff37a1282cff48c919ab36b645fbee88,openstack/horizon,master,I7389652cff37a1282cff48c919ab36b645fbee88,added Compute Services to System Info panel,MERGED,2013-07-08 05:38:45.000000000,2013-07-24 18:15:07.000000000,2013-07-24 18:15:07.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1941}, {'_account_id': 5623}]","[{'number': 1, 'created': '2013-07-08 05:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7cfe383aebfd25a240f757e94db353c10cfd8771', 'message': 'added Compute Services to System Info panel\n\nAdded a new tab to the System Info panel showing all Compute Services.\n\nfixes bug #1198247\n\nChange-Id: I7389652cff37a1282cff48c919ab36b645fbee88\n'}, {'number': 2, 'created': '2013-07-08 07:20:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3a0618b04ff770fde8ad79cff3968156a0274d10', 'message': 'added Compute Services to System Info panel\n\nAdded a new tab to the System Info panel showing all Compute Services.\n\nfixes bug #1198247\n\nChange-Id: I7389652cff37a1282cff48c919ab36b645fbee88\n'}, {'number': 3, 'created': '2013-07-20 17:04:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a21f790b1e15f3cbf30763618ef903afadad0c7a', 'message': 'added Compute Services to System Info panel\n\nAdded a new tab to the System Info panel showing all Compute Services.\n\nfixes bug #1198247\n\nChange-Id: I7389652cff37a1282cff48c919ab36b645fbee88\n'}, {'number': 4, 'created': '2013-07-24 06:32:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6d487e910e17cb53342250f1bdeb49a609c35892', 'message': 'added Compute Services to System Info panel\n\nAdded a new tab to the System Info panel showing all Compute Services.\n\nfixes bug #1198247\n\nChange-Id: I7389652cff37a1282cff48c919ab36b645fbee88\n'}, {'number': 5, 'created': '2013-07-24 07:33:49.000000000', 'files': ['openstack_dashboard/dashboards/admin/info/tabs.py', 'openstack_dashboard/dashboards/admin/info/tables.py', 'openstack_dashboard/test/test_data/nova_data.py', 'openstack_dashboard/dashboards/admin/info/tests.py', 'openstack_dashboard/api/nova.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/699926413ccfd89207b22fd3c1f5db771665fd37', 'message': 'added Compute Services to System Info panel\n\nAdded a new tab to the System Info panel showing all Compute Services.\n\nfixes bug #1198247\n\nChange-Id: I7389652cff37a1282cff48c919ab36b645fbee88\n'}]",4,36024,699926413ccfd89207b22fd3c1f5db771665fd37,23,4,5,167,,,0,"added Compute Services to System Info panel

Added a new tab to the System Info panel showing all Compute Services.

fixes bug #1198247

Change-Id: I7389652cff37a1282cff48c919ab36b645fbee88
",git fetch https://review.opendev.org/openstack/horizon refs/changes/24/36024/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/info/tabs.py', 'openstack_dashboard/dashboards/admin/info/tables.py', 'openstack_dashboard/test/test_data/nova_data.py', 'openstack_dashboard/api/nova.py']",4,7cfe383aebfd25a240f757e94db353c10cfd8771,bug/1198247, def service_list(request): return novaclient(request).services.list(),,77,1
openstack%2Ftempest~master~Ifae7bb74a4aa8f853fbd87ad80a63a9dcfc3b9d1,openstack/tempest,master,Ifae7bb74a4aa8f853fbd87ad80a63a9dcfc3b9d1,Move isolated credential code to BaseTestCase,MERGED,2013-07-23 20:56:44.000000000,2013-07-24 18:15:06.000000000,2013-07-24 18:15:05.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-23 20:56:44.000000000', 'files': ['tempest/api/compute/base.py', 'tempest/api/volume/base.py', 'tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/3e04685db6db7ef268e3d6034da0a2d667bba0f5', 'message': ""Move isolated credential code to BaseTestCase\n\nThis commit takes the isolated credential code from BaseComputeTest\nand moves it up to it's super class: BaseTestCase. This allows the\nisolated credential code to be reused by all the test classes. All\nexisting(only compute and volume) isolated credential methods in\nthe base classes are then update to use the common methods.\n\nChange-Id: Ifae7bb74a4aa8f853fbd87ad80a63a9dcfc3b9d1\n""}]",0,38370,3e04685db6db7ef268e3d6034da0a2d667bba0f5,6,3,1,5196,,,0,"Move isolated credential code to BaseTestCase

This commit takes the isolated credential code from BaseComputeTest
and moves it up to it's super class: BaseTestCase. This allows the
isolated credential code to be reused by all the test classes. All
existing(only compute and volume) isolated credential methods in
the base classes are then update to use the common methods.

Change-Id: Ifae7bb74a4aa8f853fbd87ad80a63a9dcfc3b9d1
",git fetch https://review.opendev.org/openstack/tempest refs/changes/70/38370/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/base.py', 'tempest/api/volume/base.py', 'tempest/test.py']",3,3e04685db6db7ef268e3d6034da0a2d667bba0f5,admin_isolation,"from tempest import clientsfrom tempest.common.utils.data_utils import rand_namefrom tempest import exceptions @classmethod def _get_identity_admin_client(cls): """""" Returns an instance of the Identity Admin API client """""" os = clients.AdminManager(interface=cls._interface) admin_client = os.identity_client return admin_client @classmethod def _get_client_args(cls): return ( cls.config, cls.config.identity.admin_username, cls.config.identity.admin_password, cls.config.identity.uri ) @classmethod def _get_isolated_creds(cls, admin=False): """""" Creates a new set of user/tenant/password credentials for a **regular** user of the Compute API so that a test case can operate in an isolated tenant container. """""" admin_client = cls._get_identity_admin_client() password = ""pass"" while True: try: rand_name_root = rand_name(cls.__name__) if cls.isolated_creds: # Main user already created. Create the alt or admin one... if admin: rand_name_root += '-admin' else: rand_name_root += '-alt' tenant_name = rand_name_root + ""-tenant"" tenant_desc = tenant_name + ""-desc"" resp, tenant = admin_client.create_tenant( name=tenant_name, description=tenant_desc) break except exceptions.Duplicate: if cls.config.compute.allow_tenant_reuse: tenant = admin_client.get_tenant_by_name(tenant_name) LOG.info('Re-using existing tenant %s', tenant) break while True: try: rand_name_root = rand_name(cls.__name__) if cls.isolated_creds: # Main user already created. Create the alt one... rand_name_root += '-alt' username = rand_name_root + ""-user"" email = rand_name_root + ""@example.com"" resp, user = admin_client.create_user(username, password, tenant['id'], email) break except exceptions.Duplicate: if cls.config.compute.allow_tenant_reuse: user = admin_client.get_user_by_username(tenant['id'], username) LOG.info('Re-using existing user %s', user) break # Store the complete creds (including UUID ids...) for later # but return just the username, tenant_name, password tuple # that the various clients will use. cls.isolated_creds.append((user, tenant)) # Assign admin role if this is for admin creds if admin: _, roles = admin_client.list_roles() role = None try: _, roles = admin_client.list_roles() role = next(r for r in roles if r['name'] == 'admin') except StopIteration: msg = ""No admin role found"" raise exceptions.NotFound(msg) admin_client.assign_user_role(tenant['id'], user['id'], role['id']) return username, tenant_name, password @classmethod def _clear_isolated_creds(cls): if not cls.isolated_creds: return admin_client = cls._get_identity_admin_client() for user, tenant in cls.isolated_creds: admin_client.delete_user(user['id']) admin_client.delete_tenant(tenant['id']) ",,112,150
openstack%2Fneutron~master~I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb,openstack/neutron,master,I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb,set static route for windows 2003,MERGED,2013-07-06 16:06:39.000000000,2013-07-24 18:14:58.000000000,2013-07-24 18:14:58.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 2634}]","[{'number': 8, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/face48e4a96fe591f065be9ec7c0fe06576b1c17', 'message': 'set static route for windows 2003\n\nFixes: bug #1190108\n\nChange-Id: I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb\n'}, {'number': 7, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc0ad7c190cda604c85114c4239b65f58580e135', 'message': 'set static route for windows 2003\n\nFixes: bug #1190108\n\nChange-Id: I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb\n'}, {'number': 6, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/646cdfee0412b5474039c899dd16e339e3f7ad5e', 'message': 'set static route for windows 2003\n\nFixes: bug #1190108\n\nChange-Id: I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb\n'}, {'number': 5, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f6a936d1d7fdc30f3f75d7a6c36b338d49b0e682', 'message': 'set static route for windows 2003\n\nFixes: bug #1190108\n\nChange-Id: I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb\n'}, {'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/21072ffbbf83886e2ffa8a2b509d6c467b04cb6f', 'message': 'set static route for windows 2003\n\nFixes: bug #1190108\n\nChange-Id: I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb\n'}, {'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b17cd63414d85dbc6b3662b81e2ee21cfa8b5b85', 'message': 'set static route for windows 2003\n\nFixes: bug #1190108\n\nChange-Id: I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb\n'}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/309dad12b23c0e98a04077a325c81408a813dddb', 'message': 'set static route for windows 2003\n\nFixes: bug #1190108\n\nChange-Id: I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb\n'}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a5749f2481bb1c44a0b6ddaef59d56566e738358', 'message': 'set static route for windows 2003\n\nFixes: bug #1190108\n\nChange-Id: I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb\n'}, {'number': 9, 'created': '2013-07-08 15:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e08e253f7a81656fcde8ed5394c75eda7c3477a', 'message': 'set static route for windows 2003\n\nFixes: bug #1190108\n\nChange-Id: I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb\n'}, {'number': 10, 'created': '2013-07-21 00:01:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1ae546842b9250a2ba71c4e9b6f07c81a0c06694', 'message': 'set static route for windows 2003\n\nFixes: bug #1190108\n\nChange-Id: I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb\n'}, {'number': 11, 'created': '2013-07-21 02:29:35.000000000', 'files': ['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a669a910b9a411cdd0e6b3914a214014ed126289', 'message': 'set static route for windows 2003\n\nFixes: bug #1190108\n\nChange-Id: I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb\n'}]",10,32675,a669a910b9a411cdd0e6b3914a214014ed126289,38,6,11,2634,,,0,"set static route for windows 2003

Fixes: bug #1190108

Change-Id: I97266cf007d2a5d7ca8080d83bdfadd121d0fbeb
",git fetch https://review.opendev.org/openstack/neutron refs/changes/75/32675/11 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/agent/linux/dhcp.py', 'quantum/tests/unit/test_linux_dhcp.py']",2,face48e4a96fe591f065be9ec7c0fe06576b1c17,bug/1190108,"tag:tag0,249,20.0.0.1/24,20.0.0.1tag:tag1,option:classless-static-route,%s,%s tag:tag1,249,%s,%s"""""".lstrip() % (fake_v6, fake_v6_cidr, fake_v6, fake_v6_cidr, fake_v6)tag:tag1,option:classless-static-route,%s,%s tag:tag1,249,%s,%s"""""".lstrip() % (fake_v6, fake_v6_cidr, fake_v6, fake_v6_cidr, fake_v6)tag:tag0,249,20.0.0.1/24,20.0.0.1tag0,249,20.0.0.1/24,20.0.0.1tag:tag0,249,169.254.169.254/32,192.168.1.1tag:tag0,249,20.0.0.1/24,20.0.0.1tag:tag1,option:classless-static-route,%s,%s tag:tag1,249,%s,%s"""""".lstrip() % (fake_v6, fake_v6_cidr, fake_v6, fake_v6_cidr, fake_v6)tag:tag0,249,20.0.0.1/24,20.0.0.1tag:tag1,option:classless-static-route,%s,%s tag:tag1,249,%s,%s"""""".lstrip() % (fake_v6, fake_v6_cidr, fake_v6, fake_v6_cidr, fake_v6)","tag:tag1,option:classless-static-route,%s,%s"""""".lstrip() % (fake_v6, fake_v6_cidr, fake_v6)tag:tag1,option:classless-static-route,%s,%s"""""".lstrip() % (fake_v6, fake_v6_cidr, fake_v6)tag:tag1,option:classless-static-route,%s,%s"""""".lstrip() % (fake_v6, fake_v6_cidr, fake_v6)tag:tag1,option:classless-static-route,%s,%s"""""".lstrip() % (fake_v6, fake_v6_cidr, fake_v6)",47,20
openstack%2Fneutron~master~Ia0a9b8738fa8ffe913d2e2b1ef28232abb18340d,openstack/neutron,master,Ia0a9b8738fa8ffe913d2e2b1ef28232abb18340d,"remove ""get_agents"" rule in policy.json",MERGED,2013-07-15 03:53:59.000000000,2013-07-24 18:14:50.000000000,2013-07-24 18:14:50.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2592}, {'_account_id': 2874}]","[{'number': 1, 'created': '2013-07-15 03:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f15be4578b31e91ec7cfaa69045c14db73f9838', 'message': 'Add authz on whole get_xxxs action\n\nBug #1200933\n\nChange-Id: Ia0a9b8738fa8ffe913d2e2b1ef28232abb18340d\n'}, {'number': 2, 'created': '2013-07-15 23:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d18bad686abc1f1a2e43cfbc83c41a33929005fa', 'message': 'Add authz on whole get_xxxs action\n\nBug #1200933\n\nChange-Id: Ia0a9b8738fa8ffe913d2e2b1ef28232abb18340d\n'}, {'number': 3, 'created': '2013-07-23 03:14:23.000000000', 'files': ['etc/policy.json'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1c8e5f1d3bfd9ced27f0a314538db41e04bc874c', 'message': 'remove ""get_agents"" rule in policy.json\n\nBug #1200933\n\nkeep the current API behaviour due to compatibility\nand leave list op authz in new API version.\n\nChange-Id: Ia0a9b8738fa8ffe913d2e2b1ef28232abb18340d\n'}]",4,37012,1c8e5f1d3bfd9ced27f0a314538db41e04bc874c,13,4,3,2874,,,0,"remove ""get_agents"" rule in policy.json

Bug #1200933

keep the current API behaviour due to compatibility
and leave list op authz in new API version.

Change-Id: Ia0a9b8738fa8ffe913d2e2b1ef28232abb18340d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/12/37012/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/api/v2/base.py', 'neutron/tests/unit/test_policy.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/tests/unit/test_agent_ext_plugin.py', 'neutron/policy.py', 'etc/policy.json']",6,2f15be4578b31e91ec7cfaa69045c14db73f9838,bug/1200933," ""res_list_or_admin_or_owner"": ""list_resources: or rule:admin_or_owner"", ""default"": ""rule:res_list_or_admin_or_owner"","," ""default"": ""rule:admin_or_owner"",",75,5
openstack%2Fneutron~master~I611f794279fea4a4155309cd0668e3b9718221b1,openstack/neutron,master,I611f794279fea4a4155309cd0668e3b9718221b1,Remove use_namespaces option from etc/lbaas_agent.ini,MERGED,2013-07-15 06:19:20.000000000,2013-07-24 18:14:43.000000000,2013-07-24 18:14:42.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 8149}]","[{'number': 2, 'created': '2013-07-15 06:19:20.000000000', 'files': ['etc/lbaas_agent.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/078a73c6166fdd6f126feb8f7c7debf12b518159', 'message': 'Remove use_namespaces option from etc/lbaas_agent.ini\n\nfixes bug 1201249\n\nRemove option from ini file since it is nor registered nor used\nin lbaas agent.\n\nChange-Id: I611f794279fea4a4155309cd0668e3b9718221b1\n'}, {'number': 1, 'created': '2013-07-15 06:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/913c089479e0ea47a2865ee08edcbeec13b5b4a7', 'message': 'Remove use_namespaces option from etc/lbaas_agent.ini\n\nfixes bug 1201249\n\nRemove option from ini file since it is nor registered nor used\nin lbaas agent.\n\nChange-Id: I611f794279fea4a4155309cd0668e3b9718221b1\n'}]",0,37022,078a73c6166fdd6f126feb8f7c7debf12b518159,14,6,2,6072,,,0,"Remove use_namespaces option from etc/lbaas_agent.ini

fixes bug 1201249

Remove option from ini file since it is nor registered nor used
in lbaas agent.

Change-Id: I611f794279fea4a4155309cd0668e3b9718221b1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/22/37022/2 && git format-patch -1 --stdout FETCH_HEAD,['etc/lbaas_agent.ini'],1,078a73c6166fdd6f126feb8f7c7debf12b518159,bug/1201249,,# Allow overlapping IP (Must have kernel build with CONFIG_NET_NS=y and # iproute2 package that supports namespaces). # use_namespaces = True ,0,4
openstack%2Fswift~master~I3e1bfc6e43231f51e0710aa54869f3774ee896b1,openstack/swift,master,I3e1bfc6e43231f51e0710aa54869f3774ee896b1,Unified format of boolean params in conf files,MERGED,2013-07-21 04:20:24.000000000,2013-07-24 18:14:40.000000000,2013-07-24 18:14:40.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 866}, {'_account_id': 1009}, {'_account_id': 1607}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-07-21 04:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6be299a579e88fda7796b56ddfdba43a6b3a04f6', 'message': 'Unified format of boolean params in conf files\n\nThis patch is aim to using lowcase boolean value true/false\nto replace other representions in swift conf files.\n\nFix Bug #1203421\n\nChange-Id: I3e1bfc6e43231f51e0710aa54869f3774ee896b1\n'}, {'number': 2, 'created': '2013-07-21 09:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/43514409f4e628a83a889261061ee9ee2dc84531', 'message': ""Unified format of boolean params in conf files\n\nThis patch is aim to using lowcase true/false to unify\nboolean value formats in swift conf files. It's also\nhelpful for boolean params management in puppet-openstack.\n\nFix Bug #1203421\n\nChange-Id: I3e1bfc6e43231f51e0710aa54869f3774ee896b1\n""}, {'number': 3, 'created': '2013-07-23 07:46:52.000000000', 'files': ['etc/container-server.conf-sample', 'etc/proxy-server.conf-sample', 'etc/account-server.conf-sample', 'etc/object-server.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/5c1a7871d9173db9fbd855b72a98ecd8ff163800', 'message': 'Unified format of boolean params in conf files\n\nIn swift conf files, boolean options use different\nformat: some use true/false, and some use True/False.\nThis patch is aim to using lowcase true/false to unify\nboolean params formats in swift conf files.\n\nFix Bug #1203421\n\nChange-Id: I3e1bfc6e43231f51e0710aa54869f3774ee896b1\n'}]",1,38059,5c1a7871d9173db9fbd855b72a98ecd8ff163800,22,8,3,1607,,,0,"Unified format of boolean params in conf files

In swift conf files, boolean options use different
format: some use true/false, and some use True/False.
This patch is aim to using lowcase true/false to unify
boolean params formats in swift conf files.

Fix Bug #1203421

Change-Id: I3e1bfc6e43231f51e0710aa54869f3774ee896b1
",git fetch https://review.opendev.org/openstack/swift refs/changes/59/38059/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/container-server.conf-sample', 'etc/proxy-server.conf-sample', 'etc/account-server.conf-sample', 'etc/object-server.conf-sample']",4,6be299a579e88fda7796b56ddfdba43a6b3a04f6,bug/1203421,# set log_requests = true# keep_cache_private = false# replication_server = false,# set log_requests = True# keep_cache_private = False# replication_server = False,17,17
openstack%2Fnova~master~I5fae28a86064a0582fd2a53a1a7277947b6a3525,openstack/nova,master,I5fae28a86064a0582fd2a53a1a7277947b6a3525,Sync some of Instance* models with migrations,MERGED,2013-06-17 10:57:14.000000000,2013-07-24 18:13:27.000000000,2013-07-24 18:13:25.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 6172}, {'_account_id': 6507}, {'_account_id': 6509}, {'_account_id': 7727}]","[{'number': 1, 'created': '2013-06-17 10:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b0d0d6587bf23fde680d9fc58a125c5380955987', 'message': 'Fix db description for some of Instance* models\n\nUpdate db.models description for:\n\n * InstanceFault\n * InstanceAction\n * InstanceActionEvent\n\nThat brings it in sync with the actual database\nschemas.\n\nChange-Id: I5fae28a86064a0582fd2a53a1a7277947b6a3525\nBlueprint: db-sync-models-with-migrations\n'}, {'number': 2, 'created': '2013-06-17 10:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d0e0e6d2664d1df5fdd09ab05a06ecdcb8d2825', 'message': 'Fix db description for some of Instance* models\n\nUpdate db.models description for:\n\n * InstanceFault\n * InstanceAction\n * InstanceActionEvent\n\nThat brings it in sync with the actual database\nschemas.\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I5fae28a86064a0582fd2a53a1a7277947b6a3525\n'}, {'number': 3, 'created': '2013-06-19 09:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d8af4d3470e08aa3d27129f5d089b1c1b318d25', 'message': 'Fix db description for some of Instance* models\n\nUpdate db.models description for:\n\n * InstanceFault\n * InstanceAction\n * InstanceActionEvent\n\nThat brings it in sync with the actual database\nschemas.\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I5fae28a86064a0582fd2a53a1a7277947b6a3525\n'}, {'number': 4, 'created': '2013-07-01 07:22:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edbf64260194e39dd0afdf6208d8a9e89fd6c7ad', 'message': 'Fix db description for some of Instance* models\n\nUpdate db.models description for:\n\n * InstanceFault\n * InstanceAction\n * InstanceActionEvent\n\nThat brings it in sync with the actual database\nschemas.\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I5fae28a86064a0582fd2a53a1a7277947b6a3525\n'}, {'number': 5, 'created': '2013-07-03 17:32:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aee63f5f6c950da49ebba753e1ae682557acfbfe', 'message': 'Sync some of Instance* models with migrations\n\nUpdate db.models description for:\n\n * InstanceFault\n * InstanceAction\n * InstanceActionEvent\n\nThat brings it in sync with the actual database\nschemas.\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I5fae28a86064a0582fd2a53a1a7277947b6a3525\n'}, {'number': 6, 'created': '2013-07-24 08:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c31461a1be86458e80daaa2d555375bc2d7601d', 'message': 'Sync some of Instance* models with migrations\n\nUpdate db.models description for:\n\n * InstanceFault\n * InstanceAction\n * InstanceActionEvent\n\nThat brings it in sync with the actual database\nschemas.\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I5fae28a86064a0582fd2a53a1a7277947b6a3525\n'}, {'number': 7, 'created': '2013-07-24 08:12:02.000000000', 'files': ['nova/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/356904f8b9cea1f5782d4634fdefe87ed823c2ba', 'message': 'Sync some of Instance* models with migrations\n\nUpdate db.models description for:\n\n * InstanceFault\n * InstanceAction\n * InstanceActionEvent\n\nThat brings it in sync with the actual database\nschemas.\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I5fae28a86064a0582fd2a53a1a7277947b6a3525\n'}]",7,33248,356904f8b9cea1f5782d4634fdefe87ed823c2ba,49,9,7,6509,,,0,"Sync some of Instance* models with migrations

Update db.models description for:

 * InstanceFault
 * InstanceAction
 * InstanceActionEvent

That brings it in sync with the actual database
schemas.

Blueprint: db-sync-models-with-migrations

Change-Id: I5fae28a86064a0582fd2a53a1a7277947b6a3525
",git fetch https://review.opendev.org/openstack/nova refs/changes/48/33248/5 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/models.py'],1,b0d0d6587bf23fde680d9fc58a125c5380955987,bp/db-sync-models-with-migrations," __table_args__ = ( Index('instance_faults_host_idx', 'host'), Index('instance_faults_instance_uuid_deleted_created_at_idx', 'instance_uuid', 'deleted', 'created_at') ) id = Column(Integer, primary_key=True, nullable=False, autoincrement=True) nullable=True) message = Column(String(255), nullable=True) details = Column(Text, nullable=True) host = Column(String(255), nullable=True) __table_args__ = ( Index('instance_uuid_idx', 'instance_uuid'), Index('request_id_idx', 'request_id') ) action = Column(String(255), nullable=True) nullable=True) request_id = Column(String(255), nullable=True) user_id = Column(String(255), nullable=True) project_id = Column(String(255), nullable=True) start_time = Column(DateTime, default=timeutils.utcnow, nullable=True) finish_time = Column(DateTime, nullable=True) message = Column(String(255), nullable=True) __table_args__ = ( Index('action_id', 'action_id'), ) event = Column(String(255), nullable=True) nullable=True) start_time = Column(DateTime, default=timeutils.utcnow, nullable=True) finish_time = Column(DateTime, nullable=True) result = Column(String(255), nullable=True) traceback = Column(Text, nullable=True)"," id = Column(Integer(), primary_key=True, autoincrement=True) nullable=False) message = Column(String(255)) details = Column(Text) host = Column(String(255)) action = Column(String(255)) nullable=False) request_id = Column(String(255)) user_id = Column(String(255)) project_id = Column(String(255)) start_time = Column(DateTime, default=timeutils.utcnow) finish_time = Column(DateTime) message = Column(String(255)) event = Column(String(255)) nullable=False) start_time = Column(DateTime, default=timeutils.utcnow) finish_time = Column(DateTime) result = Column(String(255)) traceback = Column(Text)",34,19
openstack%2Fceilometer~master~Ie7f84e1c266239cf7052fd5aba55577a257d2b1b,openstack/ceilometer,master,Ie7f84e1c266239cf7052fd5aba55577a257d2b1b,Sets storage_conn in CollectorService.,MERGED,2013-07-23 15:16:26.000000000,2013-07-24 17:33:16.000000000,2013-07-24 17:33:16.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5678}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-23 15:16:26.000000000', 'files': ['ceilometer/collector/service.py', 'tests/collector/test_service.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d73b1c5e6b45db7db33a1dfc91fe3d6e3aaf1f12', 'message': 'Sets storage_conn in CollectorService.\n\nFixes bug 1204133\n\nStorage_conn was not being set when the CollectorService\nwas instantiated, thus enabling event storage would cause\nexceptions when trying to store the event.\n\nChange-Id: Ie7f84e1c266239cf7052fd5aba55577a257d2b1b\n'}]",0,38309,d73b1c5e6b45db7db33a1dfc91fe3d6e3aaf1f12,8,4,1,5387,,,0,"Sets storage_conn in CollectorService.

Fixes bug 1204133

Storage_conn was not being set when the CollectorService
was instantiated, thus enabling event storage would cause
exceptions when trying to store the event.

Change-Id: Ie7f84e1c266239cf7052fd5aba55577a257d2b1b
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/09/38309/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/collector/service.py', 'tests/collector/test_service.py']",2,d73b1c5e6b45db7db33a1dfc91fe3d6e3aaf1f12,bug/1204133," def test_service_has_storage_conn(self): srv = service.UDPCollectorService() self.assertIsNotNone(srv.storage_conn) def test_service_has_storage_conn(self): # Test an unmocked default CollectorService srv = service.CollectorService('the-host', 'the-topic') self.assertIsNotNone(srv.storage_conn) ",,10,0
openstack%2Fsahara~stable%2F0.2~I105812e4dd01525a0499c4085568ee8e5c13ad3a,openstack/sahara,stable/0.2,I105812e4dd01525a0499c4085568ee8e5c13ad3a,Fixes issue with ng names duplicates,MERGED,2013-07-24 14:14:35.000000000,2013-07-24 17:28:27.000000000,2013-07-24 17:28:27.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 6823}, {'_account_id': 7125}, {'_account_id': 7132}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-24 14:14:35.000000000', 'files': ['savanna/tests/unit/service/validation/test_cluster_template_create_validation.py', 'savanna/service/validations/base.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/9fe9c04bdeb6411c9bbf9049a0ff1608334174b0', 'message': 'Fixes issue with ng names duplicates\n\nFixes: bug #1202732\n\nChange-Id: I105812e4dd01525a0499c4085568ee8e5c13ad3a\n(cherry picked from commit f8e99c669045e8ea1a00f86eaa9fdc1cc87e4666)\n'}]",0,38474,9fe9c04bdeb6411c9bbf9049a0ff1608334174b0,13,6,1,6786,,,0,"Fixes issue with ng names duplicates

Fixes: bug #1202732

Change-Id: I105812e4dd01525a0499c4085568ee8e5c13ad3a
(cherry picked from commit f8e99c669045e8ea1a00f86eaa9fdc1cc87e4666)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/74/38474/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/tests/unit/service/validation/test_cluster_template_create_validation.py', 'savanna/service/validations/base.py']",2,9fe9c04bdeb6411c9bbf9049a0ff1608334174b0,bug/1202732, check_duplicates_node_groups_names(data['node_groups']),,24,0
openstack%2Fceilometer~master~Ieb7e391cd27a60035faa075e5944bc36424992c7,openstack/ceilometer,master,Ieb7e391cd27a60035faa075e5944bc36424992c7,doc: how to inject user-defined data,MERGED,2013-07-18 11:52:40.000000000,2013-07-24 17:00:33.000000000,2013-07-24 17:00:32.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 7336}, {'_account_id': 7993}]","[{'number': 1, 'created': '2013-07-18 11:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b155d6d6ea3ad761fba22aadf6055941d3431169', 'message': 'doc: how to inject user-defined data\n\nChange-Id: Ieb7e391cd27a60035faa075e5944bc36424992c7\n'}, {'number': 2, 'created': '2013-07-18 14:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2a9bfabddf16935b1da834337d5cf8a25454c8d3', 'message': 'doc: how to inject user-defined data\n\nChange-Id: Ieb7e391cd27a60035faa075e5944bc36424992c7\n'}, {'number': 3, 'created': '2013-07-24 15:53:45.000000000', 'files': ['doc/source/webapi/v2.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3589de735eb216bad3a11560f0d398e7ba73c095', 'message': 'doc: how to inject user-defined data\n\nChange-Id: Ieb7e391cd27a60035faa075e5944bc36424992c7\n'}]",9,37667,3589de735eb216bad3a11560f0d398e7ba73c095,20,6,3,7993,,,0,"doc: how to inject user-defined data

Change-Id: Ieb7e391cd27a60035faa075e5944bc36424992c7
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/67/37667/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/webapi/v2.rst'],1,b155d6d6ea3ad761fba22aadf6055941d3431169,ff/api-v2-doc-improvement," User-defined data +++++++++++++++++ It is possible to add your own samples (created from data retrieved by your own way like monitoring agents on your instances) in Ceilometer to store them and query on them. You can even get *Statistics* on your own inserted data. By adding a *Sample* to a *Resource*, you create automatically the corresponding *Meter* if not existing already. To achieve this, you have to POST a list of one to many samples in JSON format:: curl -X 'POST' -H 'X-Auth-Token: <inserttokenhere>' -H 'Content-Type: application/json' \ -d '<insertyoursampleslisthere>' \ http://localhost:8777/v2/meters/<insertyourmeternamehere> Fields *source*, *timestamp*, *project_id* and *user_id* are automatically added if not present in the samples. Field *message_id* is not taken into account if present and an internal value will be set. Here is an example showing how to add a sample for a *ram_util* meter (already existing or not):: POST /v2/meters/ram_util body: [ { ""counter_name"": ""ram_util"", ""user_id"": ""4790fbafad2e44dab37b1d7bfc36299b"", ""resource_id"": ""87acaca4-ae45-43ae-ac91-846d8d96a89b"", ""resource_metadata"": { ""display_name"": ""my_instance"", ""my_custom_metadata_1"": ""value1"", ""my_custom_metadata_2"": ""value2"" }, ""counter_unit"": ""%"", ""counter_volume"": 8.57762938230384, ""project_id"": ""97f9a6aaa9d842fcab73797d3abb2f53"", ""counter_type"": ""gauge"" } ] You get back the same list containing your example completed with the missing fields : *source* and *timestamp* in this case.",,42,0
openstack%2Fbarbican~master~If0b3afc22bed3aa7c7b0a771a2565d6fbffc2b0d,openstack/barbican,master,If0b3afc22bed3aa7c7b0a771a2565d6fbffc2b0d,Fix PyCrypto rpm package name built by fpm.,MERGED,2013-07-24 16:22:13.000000000,2013-07-24 16:26:55.000000000,2013-07-24 16:26:54.000000000,"[{'_account_id': 3}, {'_account_id': 8004}]","[{'number': 1, 'created': '2013-07-24 16:22:13.000000000', 'files': ['rpmbuild/package_dependencies.sh'], 'web_link': 'https://opendev.org/openstack/barbican/commit/e4e1816c5faea47102a1ac24bd6ac41f96dc7906', 'message': 'Fix PyCrypto rpm package name built by fpm.\n\nfpm package naming convention does not match existing\nCentOS package.\n\nChange-Id: If0b3afc22bed3aa7c7b0a771a2565d6fbffc2b0d\n'}]",0,38498,e4e1816c5faea47102a1ac24bd6ac41f96dc7906,4,2,1,7973,,,0,"Fix PyCrypto rpm package name built by fpm.

fpm package naming convention does not match existing
CentOS package.

Change-Id: If0b3afc22bed3aa7c7b0a771a2565d6fbffc2b0d
",git fetch https://review.opendev.org/openstack/barbican refs/changes/98/38498/1 && git format-patch -1 --stdout FETCH_HEAD,['rpmbuild/package_dependencies.sh'],1,e4e1816c5faea47102a1ac24bd6ac41f96dc7906,fix-crypto-rpm-name,fpm -s python -t rpm -n python-crypto pycrypto,fpm -s python -t rpm pycrypto,1,1
openstack%2Fswift~master~Id8f83358ad7709f0df826fbc520b3dfba026a2f1,openstack/swift,master,Id8f83358ad7709f0df826fbc520b3dfba026a2f1,Make stale_reads_ok an argument of __init__,MERGED,2013-07-12 23:16:46.000000000,2013-07-24 16:26:17.000000000,2013-07-24 16:26:17.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 1009}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-07-12 23:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a2d4de1e34d67281aabe4d223349e6931ec15160', 'message': ""Make stale_reads_ok an argument of __init__\n\nActually, it appears that it is already an argument, but for some\nreason it was not used anywhere in the code. So, just use it.\nWe borrow the existing code from the object server, which uses\nsetdefault(). We don't really need it, and could simply use\nkwargs['stale_reads_ok']=stale_reads_ok, but let's keep the\ndivergencies down.\n\nThis was prompted by the desire to document the API of DB Broker\nfor the LFS work, and finding that documenting magical assignments\nwas a pain.\n\nChange-Id: Id8f83358ad7709f0df826fbc520b3dfba026a2f1\n""}, {'number': 2, 'created': '2013-07-21 01:13:53.000000000', 'files': ['swift/container/server.py', 'swift/account/server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b84afc598b188ef6e654c20fd44ba9d1b17ea55e', 'message': ""Make stale_reads_ok an argument of __init__\n\nActually, stale_reads_ok is already an argument, but for some\nreason it was not used anywhere in the code. So, just use it.\nWe borrow the existing code from the object server, which uses\nsetdefault(). We don't really need it, and could simply use\nkwargs['stale_reads_ok']=stale_reads_ok, but let's keep the\ndivergencies down.\n\nThis was prompted by the desire to document the API of DB Broker\nfor the LFS work, and finding that documenting magical assignments\nwas a pain.\n\nChange-Id: Id8f83358ad7709f0df826fbc520b3dfba026a2f1\n""}]",3,36919,b84afc598b188ef6e654c20fd44ba9d1b17ea55e,14,6,2,597,,,0,"Make stale_reads_ok an argument of __init__

Actually, stale_reads_ok is already an argument, but for some
reason it was not used anywhere in the code. So, just use it.
We borrow the existing code from the object server, which uses
setdefault(). We don't really need it, and could simply use
kwargs['stale_reads_ok']=stale_reads_ok, but let's keep the
divergencies down.

This was prompted by the desire to document the API of DB Broker
for the LFS work, and finding that documenting magical assignments
was a pain.

Change-Id: Id8f83358ad7709f0df826fbc520b3dfba026a2f1
",git fetch https://review.opendev.org/openstack/swift refs/changes/19/36919/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/server.py', 'swift/account/server.py']",2,a2d4de1e34d67281aabe4d223349e6931ec15160,stale_reads_ok," def _get_account_broker(self, drive, part, account, **kwargs): kwargs.setdefault('account', account) kwargs.setdefault('logger', self.logger) return AccountBroker(db_path, **kwargs) broker = self._get_account_broker(drive, part, account, stale_reads_ok=True) broker = self._get_account_broker(drive, part, account, stale_reads_ok=True)"," def _get_account_broker(self, drive, part, account): return AccountBroker(db_path, account=account, logger=self.logger) broker = self._get_account_broker(drive, part, account) broker.stale_reads_ok = True broker = self._get_account_broker(drive, part, account) broker.stale_reads_ok = True",17,13
openstack%2Fglance~master~Ie5f07ed6dfeaa8428de4f79c4d40d182328e6ab4,openstack/glance,master,Ie5f07ed6dfeaa8428de4f79c4d40d182328e6ab4,Glance api to pass identity headers to registry v1,MERGED,2013-07-10 21:38:10.000000000,2013-07-24 16:26:11.000000000,2013-07-24 16:26:10.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 6493}, {'_account_id': 8158}]","[{'number': 1, 'created': '2013-07-10 21:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/02fbcc5fef3831dbb9974780b852278523010523', 'message': 'Glance api to pass identity headers to registry v1\n\nThis patch introduces the send_identity_headers\nconfig option that allows glance-api to pass auth identity\nheaders when making calls to the registry v1.\n\ndocImpact\nFixes bug 1199990\n\nChange-Id: Ie5f07ed6dfeaa8428de4f79c4d40d182328e6ab4\n'}, {'number': 2, 'created': '2013-07-22 17:19:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/24ad086c9b0ad8723fbddfe13c5f025f2f716bd9', 'message': 'Glance api to pass identity headers to registry v1\n\nThis patch introduces the send_identity_headers\nconfig option that allows glance-api to pass auth identity\nheaders when making calls to the registry v1.\n\ndocImpact\nFixes bug 1199990\n\nChange-Id: Ie5f07ed6dfeaa8428de4f79c4d40d182328e6ab4\n'}, {'number': 3, 'created': '2013-07-22 22:25:36.000000000', 'files': ['etc/glance-registry-paste.ini', 'glance/registry/client/v1/client.py', 'glance/tests/unit/v1/test_registry_client.py', 'etc/glance-api.conf', 'glance/registry/client/v1/api.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/3fa3891595463259f467e31d1d635e8f96a8f9dd', 'message': 'Glance api to pass identity headers to registry v1\n\nThis patch introduces the send_identity_headers\nconfig option that allows glance-api to pass auth identity\nheaders when making calls to the registry v1.\n\ndocImpact\nFixes bug 1199990\n\nChange-Id: Ie5f07ed6dfeaa8428de4f79c4d40d182328e6ab4\n'}]",1,36563,3fa3891595463259f467e31d1d635e8f96a8f9dd,20,7,3,177,,,0,"Glance api to pass identity headers to registry v1

This patch introduces the send_identity_headers
config option that allows glance-api to pass auth identity
headers when making calls to the registry v1.

docImpact
Fixes bug 1199990

Change-Id: Ie5f07ed6dfeaa8428de4f79c4d40d182328e6ab4
",git fetch https://review.opendev.org/openstack/glance refs/changes/63/36563/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/registry/client/v1/client.py', 'glance/tests/unit/v1/test_registry_client.py', 'glance/registry/client/v1/api.py']",3,02fbcc5fef3831dbb9974780b852278523010523,bug/1199990,"import json cfg.BoolOpt('send_identity_headers', default=False, help=_('Whether to pass through headers containing user ' 'and tenant information when making requests to ' 'the registry in order to use an authenticated context ' 'without calls to auth.')), if CONF.send_identity_headers: identity_headers = { 'X-User-Id': cxt.user, 'X-Tenant-Id': cxt.tenant, 'X-Roles': ','.join(cxt.roles), 'X-Identity-Status': 'Confirmed', 'X-Service-Catalog': json.dumps(cxt.service_catalog), } kwargs['identity_headers'] = identity_headers",,83,1
openstack%2Fnova~stable%2Fgrizzly~I3f5488cc14c692fde7d5bd3376389e2f2f5550ff,openstack/nova,stable/grizzly,I3f5488cc14c692fde7d5bd3376389e2f2f5550ff,Fix nic order not correct after reboot,MERGED,2013-07-16 00:39:19.000000000,2013-07-24 16:25:53.000000000,2013-07-24 16:25:51.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 1561}, {'_account_id': 1636}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-07-16 00:39:19.000000000', 'files': ['nova/network/quantumv2/api.py', 'nova/tests/network/test_quantumv2.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/45fd6be08a04bc49dbc5c7fd67cdc7defb889284', 'message': 'Fix nic order not correct after reboot\n\nPreviously if an instance was rebooted or migrated the original nic order\nwould not be maintained. This patch retrieves the correct nic order from\ninfo_cache so that the order is mantained.\n\nFixes bug 1187092\n\nChange-Id: I3f5488cc14c692fde7d5bd3376389e2f2f5550ff\n(cherry picked from commit bcd12a776e8cde8c4b64e7c1a21a7387ece55b31)\n'}]",0,37150,45fd6be08a04bc49dbc5c7fd67cdc7defb889284,9,7,1,4395,,,0,"Fix nic order not correct after reboot

Previously if an instance was rebooted or migrated the original nic order
would not be maintained. This patch retrieves the correct nic order from
info_cache so that the order is mantained.

Fixes bug 1187092

Change-Id: I3f5488cc14c692fde7d5bd3376389e2f2f5550ff
(cherry picked from commit bcd12a776e8cde8c4b64e7c1a21a7387ece55b31)
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/37150/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/quantumv2/api.py', 'nova/tests/network/test_quantumv2.py']",2,45fd6be08a04bc49dbc5c7fd67cdc7defb889284,bug/1187092,"from nova.conductor import api as conductor_apifrom nova.openstack.common import jsonutils self.mox.StubOutWithMock(conductor_api.API, 'instance_get_by_uuid') net_info_cache = [] for port in port_data: net_info_cache.append({""network"": {""id"": port['network_id']}}) info_cache = {'info_cache': {'network_info': jsonutils.dumps(net_info_cache)}} api.conductor_api.instance_get_by_uuid( mox.IgnoreArg(), mox.IgnoreArg()).AndReturn(info_cache) self.mox.StubOutWithMock(conductor_api.API, 'instance_get_by_uuid') net_info_cache = [] for port in self.port_data3: net_info_cache.append({""network"": {""id"": port['network_id']}}) info_cache = {'info_cache': {'network_info': jsonutils.dumps(net_info_cache)}} api.conductor_api.instance_get_by_uuid( mox.IgnoreArg(), mox.IgnoreArg()).AndReturn(info_cache) self.mox.StubOutWithMock(conductor_api.API, 'instance_get_by_uuid') net_info_cache = [] for port in port_data: net_info_cache.append({""network"": {""id"": port['network_id']}}) info_cache = {'info_cache': {'network_info': jsonutils.dumps(net_info_cache)}} api = quantumapi.API() api.conductor_api.instance_get_by_uuid( mox.IgnoreArg(), mox.IgnoreArg()).AndReturn(info_cache)", api = quantumapi.API(),39,2
openstack%2Fswift~master~I8fcab2d95091f72b831b906bfc87a36d8be12631,openstack/swift,master,I8fcab2d95091f72b831b906bfc87a36d8be12631,Fix bulk's unit tests on Mac OS.,MERGED,2013-07-22 23:33:14.000000000,2013-07-24 16:25:48.000000000,2013-07-24 16:25:48.000000000,"[{'_account_id': 3}, {'_account_id': 1009}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-22 23:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/62b64e1a5060a5d0bfe1d0449330a107a71822a9', 'message': ""Fix bulk's unit tests on Mac OS.\n\nTurns out if your $TMPDIR is really long\n(e.g. /var/folders/vq/n32yszdn4s76z6l8dxklmwdh0000gn/T/, which is 50\ncharacters), then the test that drops stuff into $TMPDIR and adds it\nto a tarball and uploads it will fail due to every added file's name\nbeing too long.\n\nChange-Id: I8fcab2d95091f72b831b906bfc87a36d8be12631\n""}, {'number': 2, 'created': '2013-07-23 22:34:27.000000000', 'files': ['test/unit/common/middleware/test_bulk.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f2c3e1af9cf0ad1fbf7753cd2e5caef9bd297cb5', 'message': ""Fix bulk's unit tests on Mac OS.\n\nTurns out if your $TMPDIR is really long\n(e.g. /var/folders/vq/n32yszdn4s76z6l8dxklmwdh0000gn/T/, which is 50\ncharacters), then the test that drops stuff into $TMPDIR and adds it\nto a tarball and uploads it will fail due to every added file's name\nbeing too long.\n\nChange-Id: I8fcab2d95091f72b831b906bfc87a36d8be12631\n""}]",2,38227,f2c3e1af9cf0ad1fbf7753cd2e5caef9bd297cb5,13,5,2,2622,,,0,"Fix bulk's unit tests on Mac OS.

Turns out if your $TMPDIR is really long
(e.g. /var/folders/vq/n32yszdn4s76z6l8dxklmwdh0000gn/T/, which is 50
characters), then the test that drops stuff into $TMPDIR and adds it
to a tarball and uploads it will fail due to every added file's name
being too long.

Change-Id: I8fcab2d95091f72b831b906bfc87a36d8be12631
",git fetch https://review.opendev.org/openstack/swift refs/changes/27/38227/2 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/common/middleware/test_bulk.py'],1,62b64e1a5060a5d0bfe1d0449330a107a71822a9,bulk-tests-and-long-paths," self.max_pathlen = 100 if len(env['PATH_INFO']) > self.max_pathlen: if len(env['PATH_INFO']) > self.max_pathlen: # On systems where $TMPDIR is long (like OS X), we need to do this # or else every upload will fail due to the path being too long. self.app.max_pathlen += len(self.testdir) ", if len(env['PATH_INFO']) > 100: if len(env['PATH_INFO']) > 100:,8,2
openstack%2Fnova~master~Ie79a0d1eeeee7d4fce7a61d8e0cec90982368cf2,openstack/nova,master,Ie79a0d1eeeee7d4fce7a61d8e0cec90982368cf2,Port migrations extension to v3 API part 2,MERGED,2013-07-24 11:55:59.000000000,2013-07-24 16:23:50.000000000,2013-07-24 16:23:48.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2166}, {'_account_id': 5292}]","[{'number': 1, 'created': '2013-07-24 11:55:59.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/migrations.py', 'etc/nova/policy.json', 'nova/tests/fake_policy.py', 'nova/tests/api/openstack/compute/plugins/v3/test_migrations.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/nova/commit/f404751a65cdd030821dd1cec414fcb811299978', 'message': 'Port migrations extension to v3 API part 2\n\nThis patch contains changes to port migrations extension to v3.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Ie79a0d1eeeee7d4fce7a61d8e0cec90982368cf2\n'}]",0,38454,f404751a65cdd030821dd1cec414fcb811299978,7,4,1,7393,,,0,"Port migrations extension to v3 API part 2

This patch contains changes to port migrations extension to v3.

Partially implements blueprint nova-v3-api

Change-Id: Ie79a0d1eeeee7d4fce7a61d8e0cec90982368cf2
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/38454/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/migrations.py', 'etc/nova/policy.json', 'nova/tests/fake_policy.py', 'nova/tests/api/openstack/compute/plugins/v3/test_migrations.py', 'setup.cfg']",5,f404751a65cdd030821dd1cec414fcb811299978,bp/nova-v3-api, migrations = nova.api.openstack.compute.plugins.v3.migrations:Migrations,,11,6
openstack%2Fopenstack-manuals~master~Ia7b6c82fd33c8ed16b2e0330de47a545dc6a2e91,openstack/openstack-manuals,master,Ia7b6c82fd33c8ed16b2e0330de47a545dc6a2e91,added note about setting a non noop firewall driver,MERGED,2013-07-24 10:47:39.000000000,2013-07-24 16:18:44.000000000,2013-07-24 16:18:44.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-07-24 10:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/637033370f2768cad57b46293f07d72d6ed3df40', 'message': 'added note about setting a non noop firewall driver\n\nChange-Id: Ia7b6c82fd33c8ed16b2e0330de47a545dc6a2e91\n'}, {'number': 2, 'created': '2013-07-24 14:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d000e2dad6d8799767af664dd73fd304e73c66a0', 'message': 'added note about setting a non noop firewall driver\n\nChange-Id: Ia7b6c82fd33c8ed16b2e0330de47a545dc6a2e91\n'}, {'number': 3, 'created': '2013-07-24 15:46:29.000000000', 'files': ['doc/src/docbkx/openstack-network-connectivity-admin/ch_adv_features.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/64e39b0ec48b2b3b32e5e2229875cdbc8cc4ea48', 'message': 'added note about setting a non noop firewall driver\n\nChange-Id: Ia7b6c82fd33c8ed16b2e0330de47a545dc6a2e91\n'}]",5,38449,64e39b0ec48b2b3b32e5e2229875cdbc8cc4ea48,11,3,3,167,,,0,"added note about setting a non noop firewall driver

Change-Id: Ia7b6c82fd33c8ed16b2e0330de47a545dc6a2e91
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/49/38449/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-network-connectivity-admin/ch_adv_features.xml'],1,637033370f2768cad57b46293f07d72d6ed3df40,add_notes_about_configuring_the_firewall_driver," <note> <para>It's mandatory to set the proper firewall driver inside the plugin/agent configuration in the section <literal>securitygroup</literal>. Some plugins/agents, like the Linux Bridge Agent or the Open vSwitch Agent, are using the no-operation driver as default which results in non working security groups. </para> </note>",,7,0
openstack%2Fnova~master~I94d4ce6903da4c16545092f5618c4d130b700462,openstack/nova,master,I94d4ce6903da4c16545092f5618c4d130b700462,Port migrations extension to v3 API part 1,MERGED,2013-07-19 11:35:14.000000000,2013-07-24 16:17:10.000000000,2013-07-24 16:17:08.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2166}, {'_account_id': 5292}, {'_account_id': 7393}]","[{'number': 1, 'created': '2013-07-19 11:35:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/645367e3829675dafbed30398a57544cc02010ea', 'message': 'Port migrations extension to v3 API\n\nThis ports v2 migration extension and unit tests to v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I94d4ce6903da4c16545092f5618c4d130b700462\n'}, {'number': 2, 'created': '2013-07-24 11:29:09.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/migrations.py', 'nova/tests/api/openstack/compute/plugins/v3/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6944343237d1ae91ba3fdec4aec04c17839c4ad5', 'message': 'Port migrations extension to v3 API part 1\n\nThis is part 1 of the two part commit to port migrations to v3.\nAs part of this commit the api and test files are copied over to v3\nplugins folder. The second changeset will have changes to port\nmigrations to v3.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I94d4ce6903da4c16545092f5618c4d130b700462\n'}]",0,37878,6944343237d1ae91ba3fdec4aec04c17839c4ad5,12,5,2,7393,,,0,"Port migrations extension to v3 API part 1

This is part 1 of the two part commit to port migrations to v3.
As part of this commit the api and test files are copied over to v3
plugins folder. The second changeset will have changes to port
migrations to v3.

Partially implements blueprint nova-v3-api

Change-Id: I94d4ce6903da4c16545092f5618c4d130b700462
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/37878/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/migrations.py', 'etc/nova/policy.json', 'nova/tests/fake_policy.py', 'nova/tests/api/openstack/compute/plugins/v3/test_migrations.py']",4,645367e3829675dafbed30398a57544cc02010ea,bp/nova-v3-api,"# vim: tabstop=5 shiftwidth=4 softtabstop=4 # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import datetime from lxml import etree from nova.api.openstack.compute.plugins.v3 import migrations from nova import context from nova import exception from nova import test from nova.test import MoxStubout fake_migrations = [ { 'id': 1234, 'source_node': 'node1', 'dest_node': 'node2', 'source_compute': 'compute1', 'dest_compute': 'compute2', 'dest_host': '1.2.3.4', 'status': 'Done', 'instance_uuid': 'instance_id_123', 'old_instance_type_id': 1, 'new_instance_type_id': 2, 'created_at': datetime.datetime(2012, 10, 29, 13, 42, 2), 'updated_at': datetime.datetime(2012, 10, 29, 13, 42, 2), }, { 'id': 5678, 'source_node': 'node10', 'dest_node': 'node20', 'source_compute': 'compute10', 'dest_compute': 'compute20', 'dest_host': '5.6.7.8', 'status': 'Done', 'instance_uuid': 'instance_id_456', 'old_instance_type_id': 5, 'new_instance_type_id': 6, 'created_at': datetime.datetime(2013, 10, 22, 13, 42, 2), 'updated_at': datetime.datetime(2013, 10, 22, 13, 42, 2), } ] class FakeRequest(object): environ = {""nova.context"": context.get_admin_context()} GET = {} class MigrationsTestCase(test.TestCase): def setUp(self): """"""Run before each test."""""" super(MigrationsTestCase, self).setUp() self.controller = migrations.MigrationsController() self.context = context.get_admin_context() self.req = FakeRequest() self.req.environ['nova.context'] = self.context mox_fixture = self.useFixture(MoxStubout()) self.mox = mox_fixture.mox def test_index(self): migrations_in_progress = {'migrations': fake_migrations} filters = {'host': 'host1', 'status': 'migrating', 'cell_name': 'ChildCell'} self.req.GET = filters self.mox.StubOutWithMock(self.controller.compute_api, ""get_migrations"") self.controller.compute_api.\ get_migrations(self.context, filters).\ AndReturn(fake_migrations) self.mox.ReplayAll() response = self.controller.index(self.req) self.assertEqual(migrations_in_progress, response) def test_index_needs_authorization(self): user_context = context.RequestContext(user_id=None, project_id=None, is_admin=False, read_deleted=""no"", overwrite=False) self.req.environ['nova.context'] = user_context self.assertRaises(exception.PolicyNotAuthorized, self.controller.index, self.req) class MigrationsTemplateTest(test.TestCase): def setUp(self): super(MigrationsTemplateTest, self).setUp() self.serializer = migrations.MigrationsTemplate() def test_index_serialization(self): res_xml = self.serializer.serialize({'migrations': fake_migrations}) tree = etree.XML(res_xml) children = tree.findall('migration') self.assertEqual(tree.tag, 'migrations') self.assertEqual(2, len(children)) for idx, child in enumerate(children): self.assertEqual(child.tag, 'migration') migration = fake_migrations[idx] for attr in migration.keys(): self.assertEqual(str(migration[attr]), child.get(attr)) ",,204,0
openstack%2Fdesignate~master~I15061ed48bef09890ac4649a4705b0bf83c02a81,openstack/designate,master,I15061ed48bef09890ac4649a4705b0bf83c02a81,Ensure StorageAPI always re-raises exceptions appropriately,MERGED,2013-07-24 14:51:22.000000000,2013-07-24 16:01:25.000000000,2013-07-24 16:01:25.000000000,"[{'_account_id': 3}, {'_account_id': 741}]","[{'number': 1, 'created': '2013-07-24 14:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/23769f68d0b80b8f1c901c066049e5256809748a', 'message': 'Ensure StorageAPI always re-raises exceptions appropriately\n\nFixes bug #1204539\n\nChange-Id: I15061ed48bef09890ac4649a4705b0bf83c02a81\n'}, {'number': 2, 'created': '2013-07-24 14:54:03.000000000', 'files': ['designate/storage/api.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/e2419eae65698c303e23c7070f77e832d11c60de', 'message': 'Ensure StorageAPI always re-raises exceptions appropriately\n\nDue to the I/O included the exception handlers, eventlet correctly switches\ngreenthreads in order to not block. This has the side effect of clearing\npythons internal exception context, resulting in the reraise failing with\na confusing error message.\n\nFixes bug #1204539\n\nChange-Id: I15061ed48bef09890ac4649a4705b0bf83c02a81\n'}]",0,38478,e2419eae65698c303e23c7070f77e832d11c60de,10,2,2,741,,,0,"Ensure StorageAPI always re-raises exceptions appropriately

Due to the I/O included the exception handlers, eventlet correctly switches
greenthreads in order to not block. This has the side effect of clearing
pythons internal exception context, resulting in the reraise failing with
a confusing error message.

Fixes bug #1204539

Change-Id: I15061ed48bef09890ac4649a4705b0bf83c02a81
",git fetch https://review.opendev.org/openstack/designate refs/changes/78/38478/2 && git format-patch -1 --stdout FETCH_HEAD,['designate/storage/api.py'],1,23769f68d0b80b8f1c901c066049e5256809748a,bug/1204539,"from designate.openstack.common import excutils with excutils.save_and_reraise_exception(): self.storage.delete_quota(context, quota['id']) with excutils.save_and_reraise_exception(): restore = self._extract_dict_subset(backup, values.keys()) self.storage.update_quota(context, quota_id, restore) with excutils.save_and_reraise_exception(): self.storage.delete_server(context, server['id']) with excutils.save_and_reraise_exception(): restore = self._extract_dict_subset(backup, values.keys()) self.storage.update_server(context, server_id, restore) with excutils.save_and_reraise_exception(): self.storage.delete_tsigkey(context, tsigkey['id']) with excutils.save_and_reraise_exception(): restore = self._extract_dict_subset(backup, values.keys()) self.storage.update_tsigkey(context, tsigkey_id, restore) with excutils.save_and_reraise_exception(): self.storage.delete_domain(context, domain['id']) with excutils.save_and_reraise_exception(): restore = self._extract_dict_subset(backup, values.keys()) self.storage.update_domain(context, domain_id, restore) with excutils.save_and_reraise_exception(): self.storage.delete_record(context, record['id']) with excutils.save_and_reraise_exception(): restore = self._extract_dict_subset(backup, values.keys()) self.storage.update_record(context, record_id, restore)"," self.storage.delete_quota(context, quota['id']) raise restore = self._extract_dict_subset(backup, values.keys()) self.storage.update_quota(context, quota_id, restore) raise self.storage.delete_server(context, server['id']) raise restore = self._extract_dict_subset(backup, values.keys()) self.storage.update_server(context, server_id, restore) raise self.storage.delete_tsigkey(context, tsigkey['id']) raise restore = self._extract_dict_subset(backup, values.keys()) self.storage.update_tsigkey(context, tsigkey_id, restore) raise self.storage.delete_domain(context, domain['id']) raise restore = self._extract_dict_subset(backup, values.keys()) self.storage.update_domain(context, domain_id, restore) raise self.storage.delete_record(context, record['id']) raise restore = self._extract_dict_subset(backup, values.keys()) self.storage.update_record(context, record_id, restore) raise",26,25
openstack%2Freviewstats~master~I266c39daf96e332949d740cfadb30e4a29ec2a63,openstack/reviewstats,master,I266c39daf96e332949d740cfadb30e4a29ec2a63,Update oslo-core membership,MERGED,2013-07-24 15:47:30.000000000,2013-07-24 15:50:54.000000000,2013-07-24 15:50:54.000000000,"[{'_account_id': 3}, {'_account_id': 1561}]","[{'number': 1, 'created': '2013-07-24 15:47:30.000000000', 'files': ['projects/oslo.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/a41416bd7c6870a962b34280ad21edce97041886', 'message': 'Update oslo-core membership\n\nJulien and Ben have joined, Jason has left.\n\nChange-Id: I266c39daf96e332949d740cfadb30e4a29ec2a63\n'}]",0,38490,a41416bd7c6870a962b34280ad21edce97041886,4,2,1,1247,,,0,"Update oslo-core membership

Julien and Ben have joined, Jason has left.

Change-Id: I266c39daf96e332949d740cfadb30e4a29ec2a63
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/90/38490/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/oslo.json'],1,a41416bd7c6870a962b34280ad21edce97041886,," ""bnemec"", ""jdanjou"","," ""jason-koelker"",",2,1
openstack%2Freviewstats~master~I1d296da6312a2a36141d3b605302eaf03adcb984,openstack/reviewstats,master,I1d296da6312a2a36141d3b605302eaf03adcb984,Add oslo.messaging and oslo.sphinx,MERGED,2013-07-24 15:47:30.000000000,2013-07-24 15:50:52.000000000,2013-07-24 15:50:52.000000000,"[{'_account_id': 3}, {'_account_id': 1561}]","[{'number': 1, 'created': '2013-07-24 15:47:30.000000000', 'files': ['projects/oslo.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/17d270c6b320c28c04d29bc1e4be521cab89871e', 'message': 'Add oslo.messaging and oslo.sphinx\n\nChange-Id: I1d296da6312a2a36141d3b605302eaf03adcb984\n'}]",0,38489,17d270c6b320c28c04d29bc1e4be521cab89871e,4,2,1,1247,,,0,"Add oslo.messaging and oslo.sphinx

Change-Id: I1d296da6312a2a36141d3b605302eaf03adcb984
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/89/38489/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/oslo.json'],1,17d270c6b320c28c04d29bc1e4be521cab89871e,," ""openstack/oslo.messaging"", ""openstack/oslo.sphinx"",",,2,0
openstack%2Freviewstats~master~Iaed169176f517f2fcae6900af5523b5097ab03ce,openstack/reviewstats,master,Iaed169176f517f2fcae6900af5523b5097ab03ce,Re-format oslo metadata,MERGED,2013-07-24 15:47:30.000000000,2013-07-24 15:50:48.000000000,2013-07-24 15:50:48.000000000,"[{'_account_id': 3}, {'_account_id': 1561}]","[{'number': 1, 'created': '2013-07-24 15:47:30.000000000', 'files': ['projects/oslo.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/a70889f9ca0bf9f851d4dcb2c84f259dbf5d7616', 'message': 'Re-format oslo metadata\n\nChange-Id: Iaed169176f517f2fcae6900af5523b5097ab03ce\n'}]",0,38488,a70889f9ca0bf9f851d4dcb2c84f259dbf5d7616,4,2,1,1247,,,0,"Re-format oslo metadata

Change-Id: Iaed169176f517f2fcae6900af5523b5097ab03ce
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/88/38488/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/oslo.json'],1,a70889f9ca0bf9f851d4dcb2c84f259dbf5d7616,,"{ ""name"": ""oslo"", ""subprojects"": [ ""openstack-dev/hacking"" ""openstack-dev/pbr"", ""openstack/oslo-incubator"", ""openstack/oslo.config"", ], ""core-team"": [ ""dims-v"", ""doug-hellmann"", ""flaper87"" ""jason-koelker"", ""markmc"", ""mikalstill"", ""russellb"", ""zyluo"", ] }","{""name"": ""oslo"", ""subprojects"": [""openstack/oslo-incubator"", ""openstack/oslo.config"", ""openstack-dev/pbr"", ""openstack-dev/hacking""], ""core-team"": [""dims-v"", ""doug-hellmann"", ""jason-koelker"", ""markmc"", ""mikalstill"", ""russellb"", ""zyluo"", ""flaper87""]}",19,1
openstack%2Fopenstack-manuals~master~If157177d3d7e6d423ee0ceba871530d9f347c06d,openstack/openstack-manuals,master,If157177d3d7e6d423ee0ceba871530d9f347c06d,added php-opencloud to Instance Management,MERGED,2013-07-24 07:42:32.000000000,2013-07-24 15:46:00.000000000,2013-07-24 15:46:00.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-07-24 07:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/971390db3f7cf813de89c56f2dcd9eca7486cc37', 'message': 'added php-opencloud to Instance Management\n\nChange-Id: If157177d3d7e6d423ee0ceba871530d9f347c06d\n'}, {'number': 2, 'created': '2013-07-24 14:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/478aaac12eca15dcd566b70fdf7e0cdb86f9b6b9', 'message': 'added php-opencloud to Instance Management\n\nChange-Id: If157177d3d7e6d423ee0ceba871530d9f347c06d\n'}, {'number': 3, 'created': '2013-07-24 14:26:17.000000000', 'files': ['doc/src/docbkx/openstack-compute-admin/ch_instance_mgmt.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/53648c1a687c6b6ae2c855bb459689c672e4e6ef', 'message': 'added php-opencloud to Instance Management\n\nChange-Id: If157177d3d7e6d423ee0ceba871530d9f347c06d\n'}]",1,38428,53648c1a687c6b6ae2c855bb459689c672e4e6ef,11,3,3,167,,,0,"added php-opencloud to Instance Management

Change-Id: If157177d3d7e6d423ee0ceba871530d9f347c06d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/28/38428/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-compute-admin/ch_instance_mgmt.xml'],1,971390db3f7cf813de89c56f2dcd9eca7486cc37,add_php_opencloud," <listitem> <para><link xlink:href=""http://www.php-opencloud.com"" >php-opencloud</link> is a PHP SDK which should work with most OpenStack-based cloud deployments and the Rackspace public cloud. </para> </listitem>",,9,0
openstack%2Fopenstack-manuals~stable%2Fgrizzly~I2ff4cd28a7984a47c75de38f0f54c3eeb8a49f19,openstack/openstack-manuals,stable/grizzly,I2ff4cd28a7984a47c75de38f0f54c3eeb8a49f19,Cherry pick from https://review.openstack.org/#/c/38375/,MERGED,2013-07-24 15:08:38.000000000,2013-07-24 15:10:38.000000000,2013-07-24 15:10:38.000000000,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-07-24 15:08:38.000000000', 'files': ['doc/src/docbkx/openstack-install/install-config-glance.xml', 'doc/src/docbkx/openstack-install/identity-verify-install.xml', 'doc/src/docbkx/openstack-install/images-verifying-install.xml', 'doc/src/docbkx/openstack-install/identity-install-keystone.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-glance.xml', 'doc/src/docbkx/common/dashboard-install.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-operating.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-keystone.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a6f6bae41372098f392e6d5fff6032d0a3d9c1a3', 'message': 'Cherry pick from https://review.openstack.org/#/c/38375/\n\nFixes to install guide and basic install guide.\nFix bug 1199133\n\nChange-Id: I2ff4cd28a7984a47c75de38f0f54c3eeb8a49f19\n'}]",0,38479,a6f6bae41372098f392e6d5fff6032d0a3d9c1a3,5,2,1,964,,,0,"Cherry pick from https://review.openstack.org/#/c/38375/

Fixes to install guide and basic install guide.
Fix bug 1199133

Change-Id: I2ff4cd28a7984a47c75de38f0f54c3eeb8a49f19
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/79/38479/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-install/install-config-glance.xml', 'doc/src/docbkx/openstack-install/identity-verify-install.xml', 'doc/src/docbkx/openstack-install/identity-install-keystone.xml', 'doc/src/docbkx/openstack-install/images-verifying-install.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-glance.xml', 'doc/src/docbkx/common/dashboard-install.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-operating.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-keystone.xml']",8,a6f6bae41372098f392e6d5fff6032d0a3d9c1a3,bug/1199133," <para>Create an <literal>openrc</literal> file:</para> <para>Create a file called <emphasis role=""bold"">~/openrc</emphasis>. This file contains the OpenStack admin credentials that are used when interacting with the OpenStack environment on the command line.export OS_SERVICE_ENDPOINT=""http://localhost:35357/v2.0"" export OS_SERVICE_TOKEN=password</programlisting></para> <note> <para>Best practice for bootstrapping the first administrative user is to use the OS_SERVICE_ENDPOINT and OS_SERVICE_TOKEN together as environment variables, then set up a separate RC file just for Identity administration that uses port 35357 for the OS_AUTH_URL. This example is meant to provide a quick setup, not an audit-able environment.</para> </note> <para>Source the credentials into your environment: <screen><userinput>source ~/openrc</userinput></screen></para> </listitem> <para> Configure the Bash shell to load these credentials upon each login: </programlisting>"," <para>Create an <literal>openrc</literal> File</para> <para>Create a file called <emphasis role=""bold"">~/openrc</emphasis>. This file contains the OpenStack admin credentials that will be used when interacting with the OpenStack environment on the command line.export SERVICE_ENDPOINT=""http://localhost:35357/v2.0"" export SERVICE_TOKEN=password</programlisting></para> <para>Source the credentials into your environment: <screen><userinput>source ~/openrc</userinput></screen></para></listitem> <para> Configure the Bash shell to load these credentials upon each login: </programlisting> ",234,93
openstack%2Fbarbican~master~Ifa000d1fb633de5b69194e557978587280e47b02,openstack/barbican,master,Ifa000d1fb633de5b69194e557978587280e47b02,Package PyCrypto 2.6 into an rpm using fpm.,MERGED,2013-07-23 23:04:12.000000000,2013-07-24 15:08:56.000000000,2013-07-24 15:08:55.000000000,"[{'_account_id': 3}, {'_account_id': 8004}]","[{'number': 1, 'created': '2013-07-23 23:04:12.000000000', 'files': ['rpmbuild/package_dependencies.sh'], 'web_link': 'https://opendev.org/openstack/barbican/commit/803a044ddba780f28744c9f3793afc47e486ee57', 'message': 'Package PyCrypto 2.6 into an rpm using fpm.\n\nThe available python-crypto package in CentOS 6.4 (version 2.0.1)\nis too old.  Specifically the Crypto.Random package is unavaliable.\n\nChange-Id: Ifa000d1fb633de5b69194e557978587280e47b02\n'}]",0,38392,803a044ddba780f28744c9f3793afc47e486ee57,5,2,1,7973,,,0,"Package PyCrypto 2.6 into an rpm using fpm.

The available python-crypto package in CentOS 6.4 (version 2.0.1)
is too old.  Specifically the Crypto.Random package is unavaliable.

Change-Id: Ifa000d1fb633de5b69194e557978587280e47b02
",git fetch https://review.opendev.org/openstack/barbican refs/changes/92/38392/1 && git format-patch -1 --stdout FETCH_HEAD,['rpmbuild/package_dependencies.sh'],1,803a044ddba780f28744c9f3793afc47e486ee57,rpm-package-crypto,"fpm -s python -t rpm pycrypto # --> python-crypto 2.0.1-22.el6 exists, but is too oldpopd ",# fpm -s python -t rpm pycrypto # --> python-crypto 2.0.1-22.el6popd,3,3
openstack%2Fopenstack-manuals~master~Ief6fabc99886ef7946ab98b74ae592e63697f302,openstack/openstack-manuals,master,Ief6fabc99886ef7946ab98b74ae592e63697f302,Fixes to install guide and basic install guide.,MERGED,2013-07-23 21:20:12.000000000,2013-07-24 14:46:26.000000000,2013-07-24 14:46:26.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6772}]","[{'number': 1, 'created': '2013-07-23 21:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/515a868d0fd54e10d713720b3d62657e67fa34b3', 'message': 'Fixes to install guide and basic install guide.\n\nFix bug 1199133\n\nChange-Id: Ief6fabc99886ef7946ab98b74ae592e63697f302\n'}, {'number': 2, 'created': '2013-07-24 02:35:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9b2c4f053a291b765e6a47d92c9f81f2242f24f8', 'message': 'Fixes to install guide and basic install guide.\n\nFix bug 1199133\n\nChange-Id: Ief6fabc99886ef7946ab98b74ae592e63697f302\n'}, {'number': 3, 'created': '2013-07-24 14:38:27.000000000', 'files': ['doc/src/docbkx/openstack-install/install-config-glance.xml', 'doc/src/docbkx/openstack-install/identity-verify-install.xml', 'doc/src/docbkx/openstack-install/images-verifying-install.xml', 'doc/src/docbkx/openstack-install/identity-install-keystone.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-glance.xml', 'doc/src/docbkx/common/dashboard-install.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-operating.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-keystone.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a95e3733a566ce42815c7678e1fee70f8be204bc', 'message': 'Fixes to install guide and basic install guide.\n\nFix bug 1199133\n\nChange-Id: Ief6fabc99886ef7946ab98b74ae592e63697f302\n'}]",19,38375,a95e3733a566ce42815c7678e1fee70f8be204bc,16,4,3,964,,,0,"Fixes to install guide and basic install guide.

Fix bug 1199133

Change-Id: Ief6fabc99886ef7946ab98b74ae592e63697f302
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/75/38375/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-install/install-config-glance.xml', 'doc/src/docbkx/openstack-install/identity-verify-install.xml', 'doc/src/docbkx/openstack-install/identity-install-keystone.xml', 'doc/src/docbkx/openstack-install/images-verifying-install.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-glance.xml', 'doc/src/docbkx/common/dashboard-install.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-operating.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-keystone.xml']",8,515a868d0fd54e10d713720b3d62657e67fa34b3,bug/1199133," <para>Create an <literal>openrc</literal> file:</para> <para>Create a file called <emphasis role=""bold"">~/openrc</emphasis>. This file contains the OpenStack admin credentials that are used when interacting with the OpenStack environment on the command line.export OS_SERVICE_ENDPOINT=""http://localhost:35357/v2.0"" export OS_SERVICE_TOKEN=password</programlisting></para> <note> <para>Best practice for bootstrapping the first administrative user is to use the OS_SERVICE_ENDPOINT and OS_SERVICE_TOKEN together as environment variables, then set up a separate RC file just for Identity administration that uses port 35357 for the OS_AUTH_URL. This example is meant to provide a quick setup, not an audit-able environment.</para> </note> <para>Source the credentials into your environment: <screen><userinput>source ~/openrc</userinput></screen></para> </listitem> <para> Configure the Bash shell to load these credentials upon each login:keystone endpoint-create --region $KEYSTONE_REGION --service-id $IDENTITY_SERVICE --publicurl 'http://'""$KEYSTONE_HOST""':35357/v2.0' --adminurl 'http://'""$KEYSTONE_HOST""':35357/v2.0' --internalurl 'http://'""$KEYSTONE_HOST""':35357/v2.0' </programlisting>"," <para>Create an <literal>openrc</literal> File</para> <para>Create a file called <emphasis role=""bold"">~/openrc</emphasis>. This file contains the OpenStack admin credentials that are used when interacting with the OpenStack environment on the command line.export SERVICE_ENDPOINT=""http://localhost:35357/v2.0"" export SERVICE_TOKEN=password</programlisting></para> <para>Source the credentials into your environment: <screen><userinput>source ~/openrc</userinput></screen></para></listitem> <para> Configure the Bash shell to load these credentials upon each login:keystone endpoint-create --region $KEYSTONE_REGION --service-id $IDENTITY_SERVICE --publicurl 'http://'""$KEYSTONE_HOST""':5000/v2.0' --adminurl 'http://'""$KEYSTONE_HOST""':35357/v2.0' --internalurl 'http://'""$KEYSTONE_HOST""':5000/v2.0' </programlisting> ",78,60
openstack%2Fceilometer~master~I16320ea453995c625f62bbe2ce904e4b53572ac3,openstack/ceilometer,master,I16320ea453995c625f62bbe2ce904e4b53572ac3,Imported Translations from Transifex,MERGED,2013-07-17 09:39:55.000000000,2013-07-24 14:10:30.000000000,2013-07-24 14:10:30.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4491}]","[{'number': 1, 'created': '2013-07-17 09:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a7c0a0b9299dc02b8c6b98817d2071d261bced47', 'message': 'Imported Translations from Transifex\n\nChange-Id: I16320ea453995c625f62bbe2ce904e4b53572ac3\n'}, {'number': 2, 'created': '2013-07-18 09:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1e84496ceda79aa0248b9b3fcc0d07cc12ecc47a', 'message': 'Imported Translations from Transifex\n\nChange-Id: I16320ea453995c625f62bbe2ce904e4b53572ac3\n'}, {'number': 3, 'created': '2013-07-19 09:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/92dee4640d8cf7e516a554b5d22b143c6e41692b', 'message': 'Imported Translations from Transifex\n\nChange-Id: I16320ea453995c625f62bbe2ce904e4b53572ac3\n'}, {'number': 4, 'created': '2013-07-20 09:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d056edfd4936b88631abb78fa2e7940f685606be', 'message': 'Imported Translations from Transifex\n\nChange-Id: I16320ea453995c625f62bbe2ce904e4b53572ac3\n'}, {'number': 5, 'created': '2013-07-21 09:39:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/643c0eef7b739f0e7dab2aa6654e4fd371efcdf8', 'message': 'Imported Translations from Transifex\n\nChange-Id: I16320ea453995c625f62bbe2ce904e4b53572ac3\n'}, {'number': 6, 'created': '2013-07-22 09:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/84bc25b4f46e475ff490365028ab302aa6bcefb5', 'message': 'Imported Translations from Transifex\n\nChange-Id: I16320ea453995c625f62bbe2ce904e4b53572ac3\n'}, {'number': 7, 'created': '2013-07-23 09:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/08823a2158dea9e495e0f4bcf971dc9b91e009f0', 'message': 'Imported Translations from Transifex\n\nChange-Id: I16320ea453995c625f62bbe2ce904e4b53572ac3\n'}, {'number': 8, 'created': '2013-07-24 09:39:58.000000000', 'files': ['ceilometer/locale/tl/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ca/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/hr/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/pt/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/nb/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/nl_NL/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/es/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/pt_BR/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ro/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/bg_BG/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/hu/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ka_GE/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/pl_PL/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ru_RU/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/zh_TW/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/id/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ja/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/bs/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/it_IT/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/uk/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/en_US/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/zh_HK/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/zh_CN/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/fr/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/cs/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ms/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/en_AU/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/da/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/de/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ko_KR/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ru/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/sw_KE/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/fi_FI/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ko/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/it/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/sl_SI/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ceilometer.pot', 'ceilometer/locale/tr_TR/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/vi_VN/LC_MESSAGES/ceilometer.po'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f9e4225e6f3ee2fe30584b7117f4ab2aef669b21', 'message': 'Imported Translations from Transifex\n\nChange-Id: I16320ea453995c625f62bbe2ce904e4b53572ac3\n'}]",0,37437,f9e4225e6f3ee2fe30584b7117f4ab2aef669b21,20,3,8,3,,,0,"Imported Translations from Transifex

Change-Id: I16320ea453995c625f62bbe2ce904e4b53572ac3
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/37/37437/8 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/locale/zh_CN/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/fr/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/cs/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/es/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/pt_BR/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/da/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/de/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ko_KR/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ro/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ru/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/fi_FI/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/bg_BG/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/pl_PL/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/zh_TW/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/it/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/sl_SI/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ja/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ceilometer.pot', 'ceilometer/locale/vi_VN/LC_MESSAGES/ceilometer.po']",19,a7c0a0b9299dc02b8c6b98817d2071d261bced47,transifex/translations,"""POT-Creation-Date: 2013-07-17 09:39+0000\n""#: ceilometer/api/controllers/v2.py:701#: ceilometer/api/controllers/v2.py:827#: ceilometer/api/controllers/v2.py:834#: ceilometer/api/controllers/v2.py:851 ceilometer/api/controllers/v2.py:873 #: ceilometer/api/controllers/v2.py:887#: ceilometer/transformer/conversions.py:70#: ceilometer/transformer/conversions.py:117 #: ceilometer/transformer/conversions.py:168#: ceilometer/transformer/conversions.py:171","""POT-Creation-Date: 2013-07-16 09:39+0000\n""#: ceilometer/api/controllers/v2.py:702#: ceilometer/api/controllers/v2.py:828#: ceilometer/api/controllers/v2.py:835#: ceilometer/api/controllers/v2.py:852 ceilometer/api/controllers/v2.py:874 #: ceilometer/api/controllers/v2.py:888#: ceilometer/transformer/conversions.py:47#: ceilometer/transformer/conversions.py:93 #: ceilometer/transformer/conversions.py:144#: ceilometer/transformer/conversions.py:147",191,191
openstack%2Fneutron~master~I0970ca7d8c92fcd1c3dfaded4a9ce6e82b8c033f,openstack/neutron,master,I0970ca7d8c92fcd1c3dfaded4a9ce6e82b8c033f,remove netifaces dependency of ryu-agent,MERGED,2013-07-23 06:53:45.000000000,2013-07-24 14:08:04.000000000,2013-07-24 14:08:04.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1653}, {'_account_id': 2583}, {'_account_id': 4726}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-07-23 06:53:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7398f12192b313037f6941a35a5bc11aaa86bc64', 'message': 'remove netifaces dependency of ryu-agent\n\nFixes bug #1203663\n\nThis patch removes the netifaces dependency.\n\nChange-Id: I0970ca7d8c92fcd1c3dfaded4a9ce6e82b8c033f\n'}, {'number': 2, 'created': '2013-07-24 03:21:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e628c2c8dd8c89098802edf22ebfe6505ba42a15', 'message': 'remove netifaces dependency of ryu-agent\n\nFixes bug #1203663\n\nThis patch removes the netifaces dependency.\n\nChange-Id: I0970ca7d8c92fcd1c3dfaded4a9ce6e82b8c033f\n'}, {'number': 3, 'created': '2013-07-24 11:35:27.000000000', 'files': ['neutron/plugins/ryu/agent/ryu_neutron_agent.py', 'neutron/tests/unit/ryu/test_ryu_agent.py', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/85dc410ef8f79366931bc754440039d265f8a6b4', 'message': 'remove netifaces dependency of ryu-agent\n\nFixes bug #1203663\n\nThis patch removes the netifaces dependency.\n\nChange-Id: I0970ca7d8c92fcd1c3dfaded4a9ce6e82b8c033f\n'}]",6,38257,85dc410ef8f79366931bc754440039d265f8a6b4,16,6,3,4726,,,0,"remove netifaces dependency of ryu-agent

Fixes bug #1203663

This patch removes the netifaces dependency.

Change-Id: I0970ca7d8c92fcd1c3dfaded4a9ce6e82b8c033f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/57/38257/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ryu/agent/ryu_neutron_agent.py', 'neutron/tests/unit/ryu/test_ryu_agent.py', 'test-requirements.txt']",3,7398f12192b313037f6941a35a5bc11aaa86bc64,bug/1203663,, # Packages for the Ryu Plugin ############################### netifaces ###############################,74,24
openstack%2Fdevstack~master~I9d543f3368bdadadae482c163d814065009ab395,openstack/devstack,master,I9d543f3368bdadadae482c163d814065009ab395,Update README for swift off by default,MERGED,2013-07-24 03:04:32.000000000,2013-07-24 14:07:57.000000000,2013-07-24 14:07:57.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-24 03:04:32.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0352f584abe0e88f372b9b8898b10e2ac25842f0', 'message': ""Update README for swift off by default\n\nChange 11277b1f3cfa850c074d3effbb43987b6e6e6391 disabled swift due to\nport conflicts but the documentation still states that it is enabled\nby default, which can be quite confusing.\n\nWhile we're there, wrap affected lines to 80 chars.\n\nChange-Id: I9d543f3368bdadadae482c163d814065009ab395\n""}]",0,38407,0352f584abe0e88f372b9b8898b10e2ac25842f0,6,4,1,7118,,,0,"Update README for swift off by default

Change 11277b1f3cfa850c074d3effbb43987b6e6e6391 disabled swift due to
port conflicts but the documentation still states that it is enabled
by default, which can be quite confusing.

While we're there, wrap affected lines to 80 chars.

Change-Id: I9d543f3368bdadadae482c163d814065009ab395
",git fetch https://review.opendev.org/openstack/devstack refs/changes/07/38407/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,0352f584abe0e88f372b9b8898b10e2ac25842f0,swift-doc,"Swift is disabled by default. When enabled, it is configured with only one replica to avoid being IO/memory intensive on a small vm. When running with only one replica the account, container and object services will run directly in screen. The others services like replicator, updaters or auditor runs in background. If you would like to enable Swift you can add this to your `localrc` : enable_service s-proxy s-object s-container s-account If you want a minimal Swift install with only Swift and Keystone you can have this instead in your `localrc`:If you only want to do some testing of a real normal swift cluster with multiple replicas you can do so by customizing the variable `SWIFT_REPLICAS` in your `localrc` (usually to 3).If you are enabling `swift3` in `ENABLED_SERVICES` devstack will install the swift3 middleware emulation. Swift will be configured to act as a S3 endpoint for Keystone so effectively replacing the `nova-objectstore`. Only Swift proxy server is launched in the screen session all other services are started in background and managed by `swift-init` tool.In order to enable Neutron a single node setup, you'll need the following settings in your `localrc` :","Swift is enabled by default configured with only one replica to avoid being IO/memory intensive on a small vm. When running with only one replica the account, container and object services will run directly in screen. The others services like replicator, updaters or auditor runs in background. If you would like to disable Swift you can add this to your `localrc` : disable_service s-proxy s-object s-container s-account If you want a minimal Swift install with only Swift and Keystone you can have this instead in your `localrc`:If you only want to do some testing of a real normal swift cluster with multiple replicas you can do so by customizing the variable `SWIFT_REPLICAS` in your `localrc` (usually to 3).If you are enabling `swift3` in `ENABLED_SERVICES` devstack will install the swift3 middleware emulation. Swift will be configured to act as a S3 endpoint for Keystone so effectively replacing the `nova-objectstore`. Only Swift proxy server is launched in the screen session all other services are started in background and managed by `swift-init` tool.In order to enable Neutron a single node setup, you'll need the following settings in your `localrc` :",20,8
openstack%2Fsahara~master~I105812e4dd01525a0499c4085568ee8e5c13ad3a,openstack/sahara,master,I105812e4dd01525a0499c4085568ee8e5c13ad3a,Fixes issue with ng names duplicates,MERGED,2013-07-24 12:47:34.000000000,2013-07-24 14:03:17.000000000,2013-07-24 14:03:17.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 6823}, {'_account_id': 7125}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-24 12:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b83e18f105013ae629b83bc7fd2cd5c36be477b2', 'message': 'Fix delete templates that are in use\n\nChange-Id: I105812e4dd01525a0499c4085568ee8e5c13ad3a\nFixes: bug #1202732\n'}, {'number': 2, 'created': '2013-07-24 12:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/362e9c0e0a151d90fee5ae7eeacc4782bba54262', 'message': 'Fix delete templates that are in use\n\nFixes: bug #1202732\n\nChange-Id: I105812e4dd01525a0499c4085568ee8e5c13ad3a\n'}, {'number': 3, 'created': '2013-07-24 13:00:35.000000000', 'files': ['savanna/tests/unit/service/validation/test_cluster_template_create_validation.py', 'savanna/service/validations/base.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/f8e99c669045e8ea1a00f86eaa9fdc1cc87e4666', 'message': 'Fixes issue with ng names duplicates\n\nFixes: bug #1202732\n\nChange-Id: I105812e4dd01525a0499c4085568ee8e5c13ad3a\n'}]",1,38462,f8e99c669045e8ea1a00f86eaa9fdc1cc87e4666,13,5,3,7125,,,0,"Fixes issue with ng names duplicates

Fixes: bug #1202732

Change-Id: I105812e4dd01525a0499c4085568ee8e5c13ad3a
",git fetch https://review.opendev.org/openstack/sahara refs/changes/62/38462/3 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/tests/unit/service/validation/test_cluster_template_create_validation.py', 'savanna/service/validations/base.py']",2,b83e18f105013ae629b83bc7fd2cd5c36be477b2,bug/1202732, check_duplicates_node_groups_names(data['node_groups']),,24,0
openstack%2Fopenstack-manuals~master~I9c38a3fc327a5ee577c1a93b183426f7db5e6b00,openstack/openstack-manuals,master,I9c38a3fc327a5ee577c1a93b183426f7db5e6b00,added missing space between prompt and userinput,MERGED,2013-07-24 07:59:10.000000000,2013-07-24 13:53:33.000000000,2013-07-24 13:53:33.000000000,"[{'_account_id': 3}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-07-24 07:59:10.000000000', 'files': ['doc/src/docbkx/common/nova_cli_evacuate.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e548d7016317479e0640f56f213758a431f32048', 'message': 'added missing space between prompt and userinput\n\nChange-Id: I9c38a3fc327a5ee577c1a93b183426f7db5e6b00\n'}]",0,38431,e548d7016317479e0640f56f213758a431f32048,5,2,1,167,,,0,"added missing space between prompt and userinput

Change-Id: I9c38a3fc327a5ee577c1a93b183426f7db5e6b00
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/31/38431/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/common/nova_cli_evacuate.xml'],1,e548d7016317479e0640f56f213758a431f32048,fixing_style_of_nova_cli_evacuate, <prompt>$</prompt> <userinput>nova evacuate <replaceable>evacuated_server_name</replaceable> <replaceable>host_b</replaceable></userinput></section> , <prompt>$</prompt><userinput>nova evacuate <replaceable>evacuated_server_name</replaceable> <replaceable>host_b</replaceable></userinput></section>,2,2
openstack%2Fopenstack-manuals~master~Iad76d23007ba3e970d732b57114e824fddb26d7f,openstack/openstack-manuals,master,Iad76d23007ba3e970d732b57114e824fddb26d7f,added missing space between prompt and userinput,MERGED,2013-07-24 08:06:14.000000000,2013-07-24 13:51:25.000000000,2013-07-24 13:51:24.000000000,"[{'_account_id': 3}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-07-24 08:06:14.000000000', 'files': ['doc/src/docbkx/openstack-compute-admin/ch_instance_mgmt.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ceaee974b955019276f716f0d9f52eba878883dc', 'message': 'added missing space between prompt and userinput\n\nChange-Id: Iad76d23007ba3e970d732b57114e824fddb26d7f\n'}]",0,38433,ceaee974b955019276f716f0d9f52eba878883dc,5,2,1,167,,,0,"added missing space between prompt and userinput

Change-Id: Iad76d23007ba3e970d732b57114e824fddb26d7f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/33/38433/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-compute-admin/ch_instance_mgmt.xml'],1,ceaee974b955019276f716f0d9f52eba878883dc,fixing_style_of_ch_instance_mgmt, <screen><prompt>#</prompt> <userinput>nova --debug list</userinput> <screen><prompt>$</prompt> <userinput>nova image-list</userinput> <screen><prompt>#</prompt> <userinput>nova boot --image aee1d242-730f-431f-88c1-87630c0f07ba --flavor 1 --availability-zone nova:nova-1 testhost</userinput></screen></para>, <screen><prompt>#</prompt><userinput>nova --debug list</userinput> <screen><prompt>$</prompt><userinput>nova image-list</userinput> <screen><prompt>#</prompt><userinput>nova boot --image aee1d242-730f-431f-88c1-87630c0f07ba --flavor 1 --availability-zone nova:nova-1 testhost</userinput></screen></para>,3,3
openstack%2Ftripleo-ci~master~I57ecbe884e835bc129058804ae0db7be11ac77e0,openstack/tripleo-ci,master,I57ecbe884e835bc129058804ae0db7be11ac77e0,Always apply patches,MERGED,2013-07-24 13:39:20.000000000,2013-07-24 13:39:40.000000000,2013-07-24 13:39:40.000000000,"[{'_account_id': 3}, {'_account_id': 1926}]","[{'number': 1, 'created': '2013-07-24 13:39:20.000000000', 'files': ['toci_functions.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1c8506402b3463a2d1ca1371dcfecc7a9aa0d4a7', 'message': ""Always apply patches\n\nWe always want to apply patches, even if we didn't checkout\nthe repositories\n\nChange-Id: I57ecbe884e835bc129058804ae0db7be11ac77e0\n""}]",0,38469,1c8506402b3463a2d1ca1371dcfecc7a9aa0d4a7,5,2,1,1926,,,0,"Always apply patches

We always want to apply patches, even if we didn't checkout
the repositories

Change-Id: I57ecbe884e835bc129058804ae0db7be11ac77e0
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/69/38469/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_functions.sh'],1,1c8506402b3463a2d1ca1371dcfecc7a9aa0d4a7,always-patch, # Repositories in $TOCI_WORKING_DIR aren't updated but we do fetch origin # this fetch will make it a little more obvious to a user that upstream has changed repo_basename=${1#*/} apply_patches ${repo_basename} ${repo_basename}*, repo_basename=${1#*/} apply_patches ${repo_basename} ${repo_basename}*,4,2
openstack%2Ftripleo-ci~master~I67c41b23539287eabf72ec15f70f89d7c44bab7f,openstack/tripleo-ci,master,I67c41b23539287eabf72ec15f70f89d7c44bab7f,Increase size of VM disk,MERGED,2013-07-24 09:54:53.000000000,2013-07-24 13:39:08.000000000,2013-07-24 13:39:08.000000000,"[{'_account_id': 3}, {'_account_id': 1926}]","[{'number': 1, 'created': '2013-07-24 09:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3073fc1ca4fbe8a813e00b37445e737d473d3c48', 'message': ""Increase size of VM disk\n\n10G doesn't seem to be enough for the undercloud\n\nChange-Id: I67c41b23539287eabf72ec15f70f89d7c44bab7f\n""}, {'number': 2, 'created': '2013-07-24 09:57:29.000000000', 'files': ['toci_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b12cdf8d73d9ee7a4eac167108b067fab04c72ad', 'message': ""Increase size of VM disk\n\n10G doesn't seem to be enough for the undercloud\n\nChange-Id: I67c41b23539287eabf72ec15f70f89d7c44bab7f\n""}]",0,38442,b12cdf8d73d9ee7a4eac167108b067fab04c72ad,7,2,2,1926,,,0,"Increase size of VM disk

10G doesn't seem to be enough for the undercloud

Change-Id: I67c41b23539287eabf72ec15f70f89d7c44bab7f
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/42/38442/2 && git format-patch -1 --stdout FETCH_HEAD,['toci_test.sh'],1,3073fc1ca4fbe8a813e00b37445e737d473d3c48,bigger-disks, create-nodes 1 1024 30 3 setup-baremetal 1 1024 30 seedsetup-baremetal 1 1024 30 undercloud, create-nodes 1 1024 10 5 setup-baremetal 1 1024 10 seedsetup-baremetal 1 1024 10 undercloud,3,3
openstack%2Ftripleo-ci~master~I92dcdd41cfdab6a94de7d8e92e8fa77927cee440,openstack/tripleo-ci,master,I92dcdd41cfdab6a94de7d8e92e8fa77927cee440,Remove edit of controller-address,MERGED,2013-07-23 23:05:01.000000000,2013-07-24 13:38:55.000000000,2013-07-24 13:38:55.000000000,"[{'_account_id': 3}, {'_account_id': 1926}]","[{'number': 1, 'created': '2013-07-23 23:05:01.000000000', 'files': ['toci_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/542419d34ba6ea4c02384cb5960d16cda560d154', 'message': ""Remove edit of controller-address\n\nWe were editing the heat template to replace the controller ip\nwith 192.0.2.2, this isn't needed as heat-localip changes the\nmetadata.\n\nChange-Id: I92dcdd41cfdab6a94de7d8e92e8fa77927cee440\n""}]",0,38393,542419d34ba6ea4c02384cb5960d16cda560d154,6,2,1,1926,,,0,"Remove edit of controller-address

We were editing the heat template to replace the controller ip
with 192.0.2.2, this isn't needed as heat-localip changes the
metadata.

Change-Id: I92dcdd41cfdab6a94de7d8e92e8fa77927cee440
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/93/38393/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_test.sh'],1,542419d34ba6ea4c02384cb5960d16cda560d154,no-edit-template,,# TODO : find a better solution then guessing what the controller-address will be sed -i $TOCI_WORKING_DIR/tripleo-heat-templates/undercloud-vm.yaml -e 's/\(.*controller-address:\).*/\1 192.0.2.2/',0,2
openstack%2Foslo-incubator~master~I040fe8e0e4640e7cdd805ab49891b94da6cc4595,openstack/oslo-incubator,master,I040fe8e0e4640e7cdd805ab49891b94da6cc4595,python3: handle module moves in log,MERGED,2013-07-12 20:03:15.000000000,2013-07-24 13:36:27.000000000,2013-07-24 13:36:27.000000000,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 5638}]","[{'number': 1, 'created': '2013-07-12 20:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/9da46515f280b1110d8844820b98cf448c88618a', 'message': 'python3: Add basic compaitbility.\n\nPython 3 reorganized the standard library and moved several functions to different modules.\nSix provides a consistent interface to them through the fake six.moves module.\n\nChange-Id: I040fe8e0e4640e7cdd805ab49891b94da6cc4595\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}, {'number': 2, 'created': '2013-07-15 17:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/ef01f96cf614270263f25645e8047f582381b1cf', 'message': 'python3: Add basic compatibility.\n\nPython 3 reorganized the standard library and moved several functions to different modules.\nSix provides a consistent interface to them through the fake six.moves module.\n\nChange-Id: I040fe8e0e4640e7cdd805ab49891b94da6cc4595\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}, {'number': 3, 'created': '2013-07-23 14:19:42.000000000', 'files': ['openstack/common/log.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/3243cdfbe9bd7d7b96aa164ec58ee3bf8342eb17', 'message': 'python3: handle module moves in log\n\nPython 3 reorganized the standard library and moved several functions to different modules.\nSix provides a consistent interface to them through the fake six.moves module.\n\nChange-Id: I040fe8e0e4640e7cdd805ab49891b94da6cc4595\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",4,36894,3243cdfbe9bd7d7b96aa164ec58ee3bf8342eb17,16,6,3,24,,,0,"python3: handle module moves in log

Python 3 reorganized the standard library and moved several functions to different modules.
Six provides a consistent interface to them through the fake six.moves module.

Change-Id: I040fe8e0e4640e7cdd805ab49891b94da6cc4595
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/94/36894/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/log.py'],1,9da46515f280b1110d8844820b98cf448c88618a,(detached,from six import moves except moves.configparser.Error as exc: stringbuffer = moves.StringIO(),import ConfigParser import cStringIO except ConfigParser.Error as exc: stringbuffer = cStringIO.StringIO(),4,4
openstack%2Fcinder~master~I433b1cfbae26691eba2e781fc6008dc525b1895c,openstack/cinder,master,I433b1cfbae26691eba2e781fc6008dc525b1895c,Extend snapshot before LVM delete snapshot,ABANDONED,2013-07-10 17:45:07.000000000,2013-07-24 13:31:18.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2481}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-07-10 17:45:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ad2c069ad4a52f2a515ff25c4c52e1f718243646', 'message': 'Extend snapshot before LVM delete snapshot\n\nWe need zero the snapshot when delete LVM snapshot, but you can\'t actually\nwrite full size of data to it since there is a small percentage of space\nconsumed by the metadata used to track the snapshot data, and this lives\ninside the space allocated for the snap LV itself. This makes the device-mapper\ngenerates an ""Unable to allocate exception"" error. So we could extend\nadditional space for the the snapshot to enable it can be zero successfully.\nWhen the snapshot is removed, the additional space will be recycled.\n\nFixes bug #1199909\n\nChange-Id: I433b1cfbae26691eba2e781fc6008dc525b1895c\n'}, {'number': 2, 'created': '2013-07-10 17:47:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e0048f8f59b4606a53fddc17f38e7344d8d6d97b', 'message': 'Extend snapshot before LVM delete snapshot\n\nWe need zero the snapshot when delete LVM snapshot, but you can\'t actually\nwrite full size of data to it since there is a small percentage of space\nconsumed by the metadata used to track the snapshot data, and this lives\ninside the space allocated for the snap LV itself. This makes the device-mapper\ngenerates an ""Unable to allocate exception"" error. So we could extend\nadditional space for the the snapshot to enable it can be zero successfully.\nWhen the snapshot is removed, the additional space will be recycled.\n\nFixes bug #1199909\n\nChange-Id: I433b1cfbae26691eba2e781fc6008dc525b1895c\n'}, {'number': 3, 'created': '2013-07-10 18:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dbb5afa3140b457c3acf5aab3a9309d3aecf3d85', 'message': 'Extend snapshot before LVM delete snapshot\n\nWe need zero the snapshot when delete LVM snapshot, but you can\'t actually\nwrite full size of data to it since there is a small percentage of space\nconsumed by the metadata used to track the snapshot data, and this lives\ninside the space allocated for the snap LV itself. This makes the device-mapper\ngenerates an ""Unable to allocate exception"" error. So we could extend\nadditional space for the the snapshot to enable it can be zero successfully.\nWhen the snapshot is removed, the additional space will be recycled.\n\nFixes bug #1199909\n\nChange-Id: I433b1cfbae26691eba2e781fc6008dc525b1895c\n'}, {'number': 4, 'created': '2013-07-10 18:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d40c1e84540aa2da970e881f83deb58c80f9467d', 'message': 'Extend snapshot before LVM delete snapshot\n\nWe need zero the snapshot when delete LVM snapshot, but you can\'t actually\nwrite full size of data to it since there is a small percentage of space\nconsumed by the metadata used to track the snapshot data, and this lives\ninside the space allocated for the snap LV itself. This makes the device-mapper\ngenerates an ""Unable to allocate exception"" error. So we could extend\nadditional space for the the snapshot to enable it can be zero successfully.\nWhen the snapshot is removed, the additional space will be recycled.\n\nFixes bug #1191812\n\nChange-Id: I433b1cfbae26691eba2e781fc6008dc525b1895c\n'}, {'number': 5, 'created': '2013-07-10 19:03:52.000000000', 'files': ['cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9ebd28d8001f6fd91946b66272d36e0d260be0c8', 'message': 'Extend snapshot before LVM delete snapshot\n\nWe need zero the snapshot when delete LVM snapshot, but you can\'t actually\nwrite full size of data to it since there is a small percentage of space\nconsumed by the metadata used to track the snapshot data, and this lives\ninside the space allocated for the snap LV itself. This makes the device-mapper\ngenerates an ""Unable to allocate exception"" error. So we could extend\nadditional space for the the snapshot to enable it can be zero successfully.\nWhen the snapshot is removed, the additional space will be recycled.\n\nFixes bug #1191812\n\nChange-Id: I433b1cfbae26691eba2e781fc6008dc525b1895c\n'}]",7,36512,9ebd28d8001f6fd91946b66272d36e0d260be0c8,23,7,5,2481,,,0,"Extend snapshot before LVM delete snapshot

We need zero the snapshot when delete LVM snapshot, but you can't actually
write full size of data to it since there is a small percentage of space
consumed by the metadata used to track the snapshot data, and this lives
inside the space allocated for the snap LV itself. This makes the device-mapper
generates an ""Unable to allocate exception"" error. So we could extend
additional space for the the snapshot to enable it can be zero successfully.
When the snapshot is removed, the additional space will be recycled.

Fixes bug #1191812

Change-Id: I433b1cfbae26691eba2e781fc6008dc525b1895c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/12/36512/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/lvm.py'],1,ad2c069ad4a52f2a515ff25c4c52e1f718243646,bug/1191812," def _extend_volume(self, volume, size_in_g): """"""Extend a logical volume."""""" self._try_execute('lvextend', '-L', '+%s' % self.sizestr(size_in_g), ""%s/%s"" % (self.configuration.volume_group, self._escape_snapshot(volume['name'])), run_as_root=True) # NOTE(rongze): you can't actually write full size of data to it # since there is a small percentage of space consumed by the metadata # used to track the snapshot data, and this lives inside the space # allocated for the snap LV itself. So we could extend space for the # the snapshot to enable it can be zero successfully. I think 1GB # additional space enough. When the snapshot is removed, the additional # space will be recycled. self._extent_volume(snapshot, 1) ",,18,0
openstack%2Fdesignate~master~Ie22b66291b2c88ea00f99d18edc889a25b1b1d75,openstack/designate,master,Ie22b66291b2c88ea00f99d18edc889a25b1b1d75,corrected event details in Nova Handler notes,MERGED,2013-07-24 13:26:13.000000000,2013-07-24 13:29:30.000000000,2013-07-24 13:29:30.000000000,"[{'_account_id': 3}, {'_account_id': 6494}]","[{'number': 1, 'created': '2013-07-24 13:26:13.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/designate/commit/17e01b560465e01835b02fa2da3cf605b2b2848d', 'message': 'corrected event details in Nova Handler notes\n\nChange-Id: Ie22b66291b2c88ea00f99d18edc889a25b1b1d75\n'}]",0,38466,17e01b560465e01835b02fa2da3cf605b2b2848d,5,2,1,6494,,,0,"corrected event details in Nova Handler notes

Change-Id: Ie22b66291b2c88ea00f99d18edc889a25b1b1d75
",git fetch https://review.opendev.org/openstack/designate refs/changes/66/38466/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,17e01b560465e01835b02fa2da3cf605b2b2848d,sink_docs," compute.instance.create.end, eg: |br|"," compute.instance.create.start, eg: |br|",1,1
openstack%2Fdesignate~master~I0ef0b9c1bc1907a7d43397dcc98183bc52cd40a3,openstack/designate,master,I0ef0b9c1bc1907a7d43397dcc98183bc52cd40a3,Logging & docs improvement for notification_handler,MERGED,2013-07-24 12:40:28.000000000,2013-07-24 13:16:01.000000000,2013-07-24 13:16:01.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 6494}]","[{'number': 1, 'created': '2013-07-24 12:40:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/162cfc8ac78c1909697ca6e127cdd783e110d38d', 'message': 'Logging & docs improvement for notification_handler\n\nChange-Id: I0ef0b9c1bc1907a7d43397dcc98183bc52cd40a3\n'}, {'number': 2, 'created': '2013-07-24 13:10:45.000000000', 'files': ['designate/notification_handler/base.py', 'doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/designate/commit/88265bbdd927142b5637c9498012e9c64ebaa669', 'message': 'Logging & docs improvement for notification_handler\n\nChange-Id: I0ef0b9c1bc1907a7d43397dcc98183bc52cd40a3\n'}]",1,38461,88265bbdd927142b5637c9498012e9c64ebaa669,11,3,2,6494,,,0,"Logging & docs improvement for notification_handler

Change-Id: I0ef0b9c1bc1907a7d43397dcc98183bc52cd40a3
",git fetch https://review.opendev.org/openstack/designate refs/changes/61/38461/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/notification_handler/base.py', 'doc/source/configuration.rst']",2,162cfc8ac78c1909697ca6e127cdd783e110d38d,nova_fixed_docs,".. |br| raw:: html <br /> ==================domain_id None UUID of a domain/zone where records are to be created/deleted format None you can use any field in the notification message, compute.instance.create.start, eg: |br| format = '%(octet0)s-%(octet1)s-%(octet2)s-%(octet3)s.%(domain)s' |br| format = '%(display_name)s.%(domain)s'",================,13,1
openstack%2Fceilometer~master~I12623181d289fc0ee3cdb6fcdbacf8e76e53d244,openstack/ceilometer,master,I12623181d289fc0ee3cdb6fcdbacf8e76e53d244,Remove replace/preserve logic from rate of change transformer,MERGED,2013-07-22 12:12:49.000000000,2013-07-24 13:03:41.000000000,2013-07-24 13:03:41.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-22 12:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d6cbc837187023d9ec5586dac092c1cbd8d26f13', 'message': 'Exclude cpu counter from general pipeline\n\nEnsure the cpu counter is excluded from the general-purpose\npipeline to avoid publishing twice.\n\nChange-Id: I12623181d289fc0ee3cdb6fcdbacf8e76e53d244\n'}, {'number': 2, 'created': '2013-07-22 15:25:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1285717404a46f8f58f6783d239c77abc5540dad', 'message': 'Default replace=True in rate of change transformer\n\nThe idea is to not re-emit cpu samples from the cpu_pipeline\nby default, but instead simplify the pipeline.yaml by allowing\nthese original samples to be emitted by the general-purpose\npipeline as before, thus avoiding unintended double-publication.\n\nBy default only the derived samples would be emitted from the\nscaling or rate of change transformers.\n\nChange-Id: I12623181d289fc0ee3cdb6fcdbacf8e76e53d244\n'}, {'number': 3, 'created': '2013-07-23 14:28:25.000000000', 'files': ['tests/test_pipeline.py', 'etc/ceilometer/pipeline.yaml', 'ceilometer/transformer/conversions.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f8ccabfcc585c12772e870a8420a36dd397ee666', 'message': 'Remove replace/preserve logic from rate of change transformer\n\nThe idea is to not re-emit cpu samples from the cpu_pipeline\nby default, but instead simplify the pipeline.yaml by allowing\nthese original samples to be emitted by the general-purpose\npipeline as before, thus avoiding unintended double-publication.\n\nNow only the derived samples would be emitted from the\nscaling or rate of change transformers.\n\nChange-Id: I12623181d289fc0ee3cdb6fcdbacf8e76e53d244\n'}]",0,38137,f8ccabfcc585c12772e870a8420a36dd397ee666,17,5,3,2284,,,0,"Remove replace/preserve logic from rate of change transformer

The idea is to not re-emit cpu samples from the cpu_pipeline
by default, but instead simplify the pipeline.yaml by allowing
these original samples to be emitted by the general-purpose
pipeline as before, thus avoiding unintended double-publication.

Now only the derived samples would be emitted from the
scaling or rate of change transformers.

Change-Id: I12623181d289fc0ee3cdb6fcdbacf8e76e53d244
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/37/38137/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/ceilometer/pipeline.yaml'],1,d6cbc837187023d9ec5586dac092c1cbd8d26f13,," - ""!cpu""",,1,0
openstack%2Ftempest~master~Icb412876f5a989e6b8aa4886f2a246127a76521a,openstack/tempest,master,Icb412876f5a989e6b8aa4886f2a246127a76521a,Fixing man page generation,MERGED,2013-07-24 08:25:56.000000000,2013-07-24 12:49:18.000000000,2013-07-24 12:49:18.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-24 08:25:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/501604b361f1584c7ffb51c17caf62050687c045', 'message': 'Fix several sphinx warning\n\nChange-Id: Icb412876f5a989e6b8aa4886f2a246127a76521a\n'}, {'number': 2, 'created': '2013-07-24 10:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ce25802a819f3e75f05bf66bd2844900fa440ba7', 'message': 'Use sphinx 1.2b1\n\nThe Man page generation failed sphinx with v1.1.3, so using the\nexact 1.2b1 version.\n\nSeveral doc creation warning and error also fixed.\n\nChange-Id: Icb412876f5a989e6b8aa4886f2a246127a76521a\n'}, {'number': 3, 'created': '2013-07-24 11:18:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1a03e7e0f86218ae0547f2f0f3c80b77d197f02c', 'message': 'Fixing man page generaration\n\nThe man page generation failed with sphinx v1.1.3\nand docutils 0.10 and 0.11.\n\nAdding docutils==0.9.1 test-requirements.txt in order to solve\nthe issue.\n\nThe docutils==0.9.1 is in the common OpenStack dependency list.\n\nSeveral doc creation warning and error also fixed by this change.\n\nChange-Id: Icb412876f5a989e6b8aa4886f2a246127a76521a\n'}, {'number': 4, 'created': '2013-07-24 11:50:14.000000000', 'files': ['tempest/cli/README.rst', 'test-requirements.txt', 'tempest/README.rst', 'README.rst', 'tempest/thirdparty/README.rst', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/tempest/commit/58d23301ba51be2e8e96e906ea5d134cb2211542', 'message': 'Fixing man page generation\n\nThe man page generation failed with sphinx v1.1.3\nand docutils 0.10 and 0.11.\n\nAdding docutils==0.9.1 to the test-requirements.txt\nin order to solve this issue.\n\nThe docutils==0.9.1 is on the common OpenStack dependency list.\n\nSeveral doc creation warning and error also fixed by this change.\n\nChange-Id: Icb412876f5a989e6b8aa4886f2a246127a76521a\n'}]",1,38434,58d23301ba51be2e8e96e906ea5d134cb2211542,9,3,4,5803,,,0,"Fixing man page generation

The man page generation failed with sphinx v1.1.3
and docutils 0.10 and 0.11.

Adding docutils==0.9.1 to the test-requirements.txt
in order to solve this issue.

The docutils==0.9.1 is on the common OpenStack dependency list.

Several doc creation warning and error also fixed by this change.

Change-Id: Icb412876f5a989e6b8aa4886f2a246127a76521a
",git fetch https://review.opendev.org/openstack/tempest refs/changes/34/38434/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/cli/README.rst', 'README.rst', 'tempest/thirdparty/README.rst', 'HACKING.rst']",4,501604b361f1584c7ffb51c17caf62050687c045,sphinx,``Errors should never pass silently.``, ``Errors should never pass silently.``,8,8
openstack%2Fbarbican~master~If5e8e3081935284419f28a21d79920e4c31084b1,openstack/barbican,master,If5e8e3081935284419f28a21d79920e4c31084b1,Stop barbican-api during rpm removal.,MERGED,2013-07-23 06:52:14.000000000,2013-07-24 12:43:04.000000000,2013-07-24 12:43:04.000000000,"[{'_account_id': 3}, {'_account_id': 7973}, {'_account_id': 8004}]","[{'number': 1, 'created': '2013-07-23 06:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/90615365397c4a1e24db1839c78901319b93f0c3', 'message': 'Start/stop barbican-api during rpm installation.\n\nChange-Id: If5e8e3081935284419f28a21d79920e4c31084b1\n'}, {'number': 2, 'created': '2013-07-23 15:47:02.000000000', 'files': ['rpmbuild/SPECS/barbican.spec'], 'web_link': 'https://opendev.org/openstack/barbican/commit/4b01ccca78296bd363597c286991667688132977', 'message': 'Stop barbican-api during rpm removal.\n\nChange-Id: If5e8e3081935284419f28a21d79920e4c31084b1\n'}]",0,38256,4b01ccca78296bd363597c286991667688132977,9,3,2,7973,,,0,"Stop barbican-api during rpm removal.

Change-Id: If5e8e3081935284419f28a21d79920e4c31084b1
",git fetch https://review.opendev.org/openstack/barbican refs/changes/56/38256/1 && git format-patch -1 --stdout FETCH_HEAD,['rpmbuild/SPECS/barbican.spec'],1,90615365397c4a1e24db1839c78901319b93f0c3,rpm-control-api," %post -n barbican-api if [ $1 -eq 1 ] ; then # initial installation /sbin/start barbican-api >/dev/null 2>&1 || : fi %preun -n barbican-api if [ $1 -eq 0 ] ; then # Package removal, not upgrade /sbin/stop barbican-api >/dev/null 2>&1 || : fi %postun -n barbican-api if [ $1 -ge 1 ] ; then # Package upgrade, not uninstall /sbin/restart barbican-api >/dev/null 2>&1 || : fi",,18,0
openstack%2Fceilometer~master~Iac6ace9a2402237543ed35be7f4fcee91ff3e036,openstack/ceilometer,master,Iac6ace9a2402237543ed35be7f4fcee91ff3e036,storage: remove per-driver options,MERGED,2013-07-17 14:58:51.000000000,2013-07-24 12:40:37.000000000,2013-07-24 12:40:37.000000000,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-17 14:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ef9b668116f82628b29922a01f766c02f9fe5a5e', 'message': 'storage: remove per-driver options\n\nFixes: bug #1195538\n\nChange-Id: Iac6ace9a2402237543ed35be7f4fcee91ff3e036\nSigned-off-by: Julien Danjou <julien@danjou.info>\n'}, {'number': 2, 'created': '2013-07-23 13:43:51.000000000', 'files': ['ceilometer/storage/base.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/impl_log.py', 'tests/storage/test_register_opts.py', 'ceilometer/storage/__init__.py', 'ceilometer/storage/impl_sqlalchemy.py', 'tools/show_data.py', 'ceilometer/api/v1/app.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5345f4f8016ffb81678c821e9adf03a12657425f', 'message': 'storage: remove per-driver options\n\nFixes: bug #1195538\n\nChange-Id: Iac6ace9a2402237543ed35be7f4fcee91ff3e036\nSigned-off-by: Julien Danjou <julien@danjou.info>\n'}]",0,37492,5345f4f8016ffb81678c821e9adf03a12657425f,15,6,2,1669,,,0,"storage: remove per-driver options

Fixes: bug #1195538

Change-Id: Iac6ace9a2402237543ed35be7f4fcee91ff3e036
Signed-off-by: Julien Danjou <julien@danjou.info>
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/92/37492/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/base.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/impl_log.py', 'tests/storage/test_register_opts.py', 'ceilometer/storage/__init__.py', 'ceilometer/api/v1/app.py', 'ceilometer/storage/impl_sqlalchemy.py', 'tools/show_data.py']",9,ef9b668116f82628b29922a01f766c02f9fe5a5e,bug/1195538,, storage.register_opts(cfg.CONF),1,75
openstack%2Fceilometer~master~I53e26f72d9a7fb0e2778402801a71c2682883452,openstack/ceilometer,master,I53e26f72d9a7fb0e2778402801a71c2682883452,hbase: do not register table_prefix as a global option,MERGED,2013-07-17 14:58:49.000000000,2013-07-24 12:40:31.000000000,2013-07-24 12:40:31.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 4491}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-17 14:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c83e925710165c49ca792d43e1f3b5d5be711ee9', 'message': 'hbase: do not register table_prefix as a global option\n\nRather use a per-connection option.\n\nChange-Id: I53e26f72d9a7fb0e2778402801a71c2682883452\n'}, {'number': 2, 'created': '2013-07-23 13:43:51.000000000', 'files': ['ceilometer/storage/impl_hbase.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/46e673f9fb40cae06e984a031daf336e64b41dca', 'message': 'hbase: do not register table_prefix as a global option\n\nRather use a per-connection option.\n\nChange-Id: I53e26f72d9a7fb0e2778402801a71c2682883452\n'}]",0,37491,46e673f9fb40cae06e984a031daf336e64b41dca,11,4,2,1669,,,0,"hbase: do not register table_prefix as a global option

Rather use a per-connection option.

Change-Id: I53e26f72d9a7fb0e2778402801a71c2682883452
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/91/37491/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/storage/impl_hbase.py'],1,c83e925710165c49ca792d43e1f3b5d5be711ee9,bug/1195538,"import urlparsefrom ceilometer.openstack.common import network_utils pass result = network_utils.urlsplit(url) opts['table_prefix'] = urlparse.parse_qs( result.query).get('table_prefix', [None])[0]","from urlparse import urlparsefrom oslo.config import cfg OPTIONS = [ cfg.StrOpt('table_prefix', default=None, help='Database table prefix', ), ] conf.register_opts(self.OPTIONS) opts['table_prefix'] = conf.table_prefix result = urlparse(url)",6,12
openstack%2Fceilometer~master~I141f063f18993e69e6fb1da0d8ea6dd9821a248f,openstack/ceilometer,master,I141f063f18993e69e6fb1da0d8ea6dd9821a248f,mongodb: do not set replica_set as a global option,MERGED,2013-07-17 14:58:49.000000000,2013-07-24 12:40:24.000000000,2013-07-24 12:40:24.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-17 14:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e34c0526c8861b1eb9490afafc5055b9aeb28d47', 'message': 'mongodb: do not set replica_set as a global option\n\nRather use a per-connection parameter.\n\nChange-Id: I141f063f18993e69e6fb1da0d8ea6dd9821a248f\n'}, {'number': 2, 'created': '2013-07-23 13:43:51.000000000', 'files': ['ceilometer/storage/impl_mongodb.py', 'tests/storage/test_impl_mongodb.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/dbe5f363bcc4335147d5f74bdb4c115081fc0f45', 'message': 'mongodb: do not set replica_set as a global option\n\nRather use a per-connection parameter.\n\nChange-Id: I141f063f18993e69e6fb1da0d8ea6dd9821a248f\n'}]",2,37490,dbe5f363bcc4335147d5f74bdb4c115081fc0f45,15,5,2,1669,,,0,"mongodb: do not set replica_set as a global option

Rather use a per-connection parameter.

Change-Id: I141f063f18993e69e6fb1da0d8ea6dd9821a248f
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/90/37490/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/impl_mongodb.py', 'tests/storage/test_impl_mongodb.py']",2,e34c0526c8861b1eb9490afafc5055b9aeb28d47,bug/1195538," def test_replica_set(self): cfg.CONF.set_override( 'connection', 'mongodb://__test__?replica_set=foobar', group='database') conn = impl_mongodb.Connection(cfg.CONF) self.assertTrue(conn.conn) ",,12,16
openstack%2Fsahara~master~I65dbde6ca95ed22ad1deb04c2a5ec0e31a0b417f,openstack/sahara,master,I65dbde6ca95ed22ad1deb04c2a5ec0e31a0b417f,Instance remote usage refactoring,MERGED,2013-07-24 09:23:36.000000000,2013-07-24 12:10:39.000000000,2013-07-24 12:10:39.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 6823}, {'_account_id': 7132}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-24 09:23:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/6f08cadac3cbb3200fafd159c6e8f81e34cb5f1c', 'message': 'Instance remote usage refactoring\n\nRemote property removed from model module\n\nChange-Id: I65dbde6ca95ed22ad1deb04c2a5ec0e31a0b417f\n'}, {'number': 2, 'created': '2013-07-24 10:32:23.000000000', 'files': ['savanna/plugins/vanilla/scaling.py', 'savanna/plugins/vanilla/plugin.py', 'savanna/service/volumes.py', 'savanna/plugins/hdp/hadoopserver.py', 'savanna/utils/remote.py', 'savanna/service/instances.py', 'savanna/db/models.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/7512d3effa8753ee38d19e5cd7311974e0c84c21', 'message': 'Instance remote usage refactoring\n\nRemote property removed from model module\n\nChange-Id: I65dbde6ca95ed22ad1deb04c2a5ec0e31a0b417f\n'}]",0,38439,7512d3effa8753ee38d19e5cd7311974e0c84c21,10,5,2,7132,,,0,"Instance remote usage refactoring

Remote property removed from model module

Change-Id: I65dbde6ca95ed22ad1deb04c2a5ec0e31a0b417f
",git fetch https://review.opendev.org/openstack/sahara refs/changes/39/38439/2 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/plugins/vanilla/scaling.py', 'savanna/plugins/vanilla/plugin.py', 'savanna/service/volumes.py', 'savanna/plugins/hdp/hadoopserver.py', 'savanna/utils/remote.py', 'savanna/service/instances.py', 'savanna/db/models.py']",7,6f08cadac3cbb3200fafd159c6e8f81e34cb5f1c,0.3,,from savanna.utils import remote @property def remote(self): return remote.InstanceInteropHelper(self) ,40,35
openstack%2Fceilometer~master~I0fb5afae91a3b1240402d252b8e3a4fe0497fa05,openstack/ceilometer,master,I0fb5afae91a3b1240402d252b8e3a4fe0497fa05,Fixed timestamp creation in MongoDB mapreduce,MERGED,2013-07-23 08:53:09.000000000,2013-07-24 12:07:53.000000000,2013-07-24 12:07:52.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 6537}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-07-23 08:53:09.000000000', 'files': ['ceilometer/storage/impl_mongodb.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e9e82cf1f2104264cb8a181f2a3c135757864b08', 'message': ""Fixed timestamp creation in MongoDB mapreduce\n\ndatetime.strftime('%s') doesn't respect tzinfo see:\nhttp://bugs.python.org/issue12750\n\nNaive time in UTC was converted as a local time\ncausing test failures in timezone with DST\n\nChange-Id: I0fb5afae91a3b1240402d252b8e3a4fe0497fa05\n""}]",0,38264,e9e82cf1f2104264cb8a181f2a3c135757864b08,8,5,1,7763,,,0,"Fixed timestamp creation in MongoDB mapreduce

datetime.strftime('%s') doesn't respect tzinfo see:
http://bugs.python.org/issue12750

Naive time in UTC was converted as a local time
causing test failures in timezone with DST

Change-Id: I0fb5afae91a3b1240402d252b8e3a4fe0497fa05
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/64/38264/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/storage/impl_mongodb.py'],1,e9e82cf1f2104264cb8a181f2a3c135757864b08,bug/datetime.strftime,import time period_start = int(time.mktime(period_start.utctimetuple())), period_start = int(period_start.strftime('%s')),2,1
openstack%2Fceilometer~master~Id11215edae79e5bd007fb28590f9c4cca25aacc9,openstack/ceilometer,master,Id11215edae79e5bd007fb28590f9c4cca25aacc9,Refactored API V2 tests to use testscenarios,MERGED,2013-07-23 14:33:10.000000000,2013-07-24 12:04:21.000000000,2013-07-24 12:04:21.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 6537}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-07-23 14:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e18bbbac1978908446dccc65055bdf0139913888', 'message': 'Refactored API V2 tests to use testscenarios\n\nRelated to blueprint db-tests-with-scenarios\n\nChange-Id: Id11215edae79e5bd007fb28590f9c4cca25aacc9\n'}, {'number': 2, 'created': '2013-07-24 09:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c5d081dfff5a2eeff9136a9ae6616e27ffec2ae6', 'message': 'Refactored API V2 tests to use testscenarios\n\nRelated to blueprint db-tests-with-scenarios\n\nChange-Id: Id11215edae79e5bd007fb28590f9c4cca25aacc9\n'}, {'number': 3, 'created': '2013-07-24 11:18:50.000000000', 'files': ['tests/api/v2/test_impl_hbase.py', 'tests/api/v2/test_alarm_scenarios.py', 'tests/api/v2/test_acl_scenarios.py', 'tests/api/v2/test_impl_mongodb.py', 'tests/api/v2/test_list_resources_scenarios.py', 'tests/api/v2/test_post_samples_scenarios.py', 'tests/api/v2/test_impl_sqlalchemy.py', 'tests/api/v2/test_list_meters_scenarios.py', 'tests/api/v2/test_list_events_scenarios.py', 'tests/api/v2/test_statistics_scenarios.py', 'tests/api/v2/test_compute_duration_by_resource_scenarios.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a88b9581c58fbb0cd3a8db3c0602c48613d789b5', 'message': 'Refactored API V2 tests to use testscenarios\n\nRelated to blueprint db-tests-with-scenarios\n\nChange-Id: Id11215edae79e5bd007fb28590f9c4cca25aacc9\n'}]",0,38300,a88b9581c58fbb0cd3a8db3c0602c48613d789b5,16,5,3,7763,,,0,"Refactored API V2 tests to use testscenarios

Related to blueprint db-tests-with-scenarios

Change-Id: Id11215edae79e5bd007fb28590f9c4cca25aacc9
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/00/38300/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/api/v2/test_alarm_scenarios.py', 'tests/api/v2/test_impl_hbase.py', 'tests/api/v2/test_acl_scenarios.py', 'tests/api/v2/test_impl_mongodb.py', 'tests/api/v2/test_list_resources_scenarios.py', 'tests/api/v2/test_impl_sqlalchemy.py', 'tests/api/v2/test_post_samples_scenarios.py', 'tests/api/v2/test_list_meters_scenarios.py', 'tests/api/v2/test_list_events_scenarios.py', 'tests/api/v2/test_statistics_scenarios.py', 'tests/api/v2/test_compute_duration_by_resource_scenarios.py']",11,e18bbbac1978908446dccc65055bdf0139913888,bp/db-tests-with-scenarios,"from testscenarios import load_tests_apply_scenarios as load_tests # noqa F401 scenarios = [ ('sqlalchemy', dict(database_connection='sqlite://')), ('mongodb', dict(database_connection='mongodb://__test__')), ('hbase', dict(database_connection='hbase://__test__')), ] ",,94,228
openstack%2Fnova~master~I969a0c2c03ff6a33169570b966e4c7842948b039,openstack/nova,master,I969a0c2c03ff6a33169570b966e4c7842948b039,Converting to datetime before updating the inst,ABANDONED,2013-07-17 11:40:06.000000000,2013-07-24 11:27:05.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 7094}, {'_account_id': 7502}]","[{'number': 1, 'created': '2013-07-17 11:40:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/592e9c2e7ff348fa3dde596b3117d6f8d4281ccc', 'message': 'Converting to datetime before updating the inst\n\nWhile updating the instance, we expect some fields to be datetime,\non which we try to strip off the timezone using replace. The fields come\nin as string, so converting them to datetime before we strip the\ntimezone\nfixes LP 1201766\n\nChange-Id: I969a0c2c03ff6a33169570b966e4c7842948b039\n'}, {'number': 2, 'created': '2013-07-19 11:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/025b52e444ef4569cf6309ab49bb2ba06f597068', 'message': 'Converting to datetime before updating the inst\n\nWhile updating the instance, we expect some fields to be datetime,\non which we try to strip off the timezone using replace. The fields come\nin as string, so converting them to datetime before we strip the\ntimezone\nfixes LP 1201766\n\nChange-Id: I969a0c2c03ff6a33169570b966e4c7842948b039\n'}, {'number': 3, 'created': '2013-07-22 10:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a613b4b5b8eae59f540b930d69059434f5d90aac', 'message': 'Converting to datetime before updating the inst\n\nWhile updating the instance, we expect some fields to be datetime,\non which we try to strip off the timezone using replace. The fields come\nin as string, so converting them to datetime before we strip the\ntimezone\nfixes LP 1201766\n\nChange-Id: I969a0c2c03ff6a33169570b966e4c7842948b039\n'}, {'number': 4, 'created': '2013-07-23 10:07:14.000000000', 'files': ['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c13eb02d13ad7e28ebd879f150393cc1fba5fa59', 'message': 'Converting to datetime before updating the inst\n\nWhile updating the instance, we expect some fields to be datetime,\non which we try to strip off the timezone using replace. The fields come\nin as string, so converting them to datetime before we strip the\ntimezone\n\nThe fix is already present. Removing code duplication and reusing\nexisting function which converts string to datetime. Also adding tests\nto check that timezone is removed from datetime\n\nfixes LP 1201766\n\nChange-Id: I969a0c2c03ff6a33169570b966e4c7842948b039\n'}]",3,37452,c13eb02d13ad7e28ebd879f150393cc1fba5fa59,13,6,4,7094,,,0,"Converting to datetime before updating the inst

While updating the instance, we expect some fields to be datetime,
on which we try to strip off the timezone using replace. The fields come
in as string, so converting them to datetime before we strip the
timezone

The fix is already present. Removing code duplication and reusing
existing function which converts string to datetime. Also adding tests
to check that timezone is removed from datetime

fixes LP 1201766

Change-Id: I969a0c2c03ff6a33169570b966e4c7842948b039
",git fetch https://review.opendev.org/openstack/nova refs/changes/52/37452/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,592e9c2e7ff348fa3dde596b3117d6f8d4281ccc,bug/1201766,from dateutil import parser values[key] = parser.parse(values[key]).replace(tzinfo=None), values[key] = values[key].replace(tzinfo=None),19,1
openstack%2Fceilometer~master~I12294aa191ff4dfa5adaf2e24419bdfca70e8726,openstack/ceilometer,master,I12294aa191ff4dfa5adaf2e24419bdfca70e8726,alarm: Per user setting to disable ssl verify,MERGED,2013-07-16 11:18:34.000000000,2013-07-24 10:57:25.000000000,2013-07-24 10:57:25.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 4715}]","[{'number': 1, 'created': '2013-07-16 11:18:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0a5b4ecc675e0ddaf060d26e188726c1f12b471e', 'message': 'alarm: Per user setting to disable ssl verificat.\n\nThis allow the user the disable ssl verification via a query string\nparameter in the action url.\n\nexample of action:\n https://unstrusted-ssl-host/?ceilometer-alarm-ssl-verify=0\n\nChange-Id: I12294aa191ff4dfa5adaf2e24419bdfca70e8726\nBlueprint: alarm-notifier\n'}, {'number': 2, 'created': '2013-07-16 13:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0bd46394538064f67380cdf0185b03793f08d06f', 'message': 'alarm: Per user setting to disable ssl verify\n\nThis allows the user to disable ssl verification via a query string\nparameter in the action url.\n\nexample of action:\n https://unstrusted-ssl-host/?ceilometer-alarm-ssl-verify=0\n\nChange-Id: I12294aa191ff4dfa5adaf2e24419bdfca70e8726\nBlueprint: alarm-notifier\n'}, {'number': 3, 'created': '2013-07-16 14:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/14b40a5ba49684836be86e8bbd92febedc4374d2', 'message': 'alarm: Per user setting to disable ssl verify\n\nThis allows the user to disable ssl verification via a query string\nparameter in the action url.\n\nexample of action:\n https://unstrusted-ssl-host/?ceilometer-alarm-ssl-verify=0\n\nChange-Id: I12294aa191ff4dfa5adaf2e24419bdfca70e8726\nBlueprint: alarm-notifier\n'}, {'number': 4, 'created': '2013-07-18 06:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4e33546c0f2a5f543240f7a7a380b7b61baea6cd', 'message': 'alarm: Per user setting to disable ssl verify\n\nThis allows the user to disable ssl verification via a query string\nparameter in the action url.\n\nexample of action:\n https://unstrusted-ssl-host/?ceilometer-alarm-ssl-verify=0\n\nChange-Id: I12294aa191ff4dfa5adaf2e24419bdfca70e8726\nBlueprint: alarm-notifier\n'}, {'number': 5, 'created': '2013-07-18 13:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/31cbd20aaf91c85861a606fad3fc7d32dcde1c16', 'message': 'alarm: Per user setting to disable ssl verify\n\nThis allows the user to disable ssl verification via a query string\nparameter in the action url.\n\nexample of action:\n https://unstrusted-ssl-host/?ceilometer-alarm-ssl-verify=0\n\nChange-Id: I12294aa191ff4dfa5adaf2e24419bdfca70e8726\nBlueprint: alarm-notifier\n'}, {'number': 6, 'created': '2013-07-18 14:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e23dc3e2f275d04a03c7e96bda0bed855581a03e', 'message': 'alarm: Per user setting to disable ssl verify\n\nThis allows the user to disable ssl verification via a query string\nparameter in the action url.\n\nexample of action:\n https://unstrusted-ssl-host/?ceilometer-alarm-ssl-verify=0\n\nChange-Id: I12294aa191ff4dfa5adaf2e24419bdfca70e8726\nBlueprint: alarm-notifier\n'}, {'number': 7, 'created': '2013-07-22 08:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/913cef6003be503cd7fc837408fc10c9f50c3e7f', 'message': 'alarm: Per user setting to disable ssl verify\n\nThis allows the user to disable ssl verification via a query string\nparameter in the action url.\n\nexample of action:\n https://unstrusted-ssl-host/?ceilometer-alarm-ssl-verify=0\n\nChange-Id: I12294aa191ff4dfa5adaf2e24419bdfca70e8726\nBlueprint: alarm-notifier\n'}, {'number': 8, 'created': '2013-07-22 18:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8ffd5cb5289def02ccf0dd59feffb99de7724d67', 'message': 'alarm: Per user setting to disable ssl verify\n\nThis allows the user to disable ssl verification via a query string\nparameter in the action url.\n\nexample of action:\n https://unstrusted-ssl-host/?ceilometer-alarm-ssl-verify=0\n\nChange-Id: I12294aa191ff4dfa5adaf2e24419bdfca70e8726\nBlueprint: alarm-notifier\n'}, {'number': 9, 'created': '2013-07-23 16:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/036a611af9a08adc66bb97f579f2b96c40248ee2', 'message': 'alarm: Per user setting to disable ssl verify\n\nThis allows the user to disable ssl verification via a query string\nparameter in the action url.\n\nexample of action:\n https://unstrusted-ssl-host/?ceilometer-alarm-ssl-verify=0\n\nChange-Id: I12294aa191ff4dfa5adaf2e24419bdfca70e8726\nBlueprint: alarm-notifier\n'}, {'number': 10, 'created': '2013-07-24 09:47:37.000000000', 'files': ['tests/alarm/test_notifier.py', 'ceilometer/alarm/notifier/rest.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bc495c3dc9e644a37324fc5025efbd6669e0436d', 'message': 'alarm: Per user setting to disable ssl verify\n\nThis allows the user to disable ssl verification via a query string\nparameter in the action url.\n\nexample of action:\n https://unstrusted-ssl-host/?ceilometer-alarm-ssl-verify=0\n\nChange-Id: I12294aa191ff4dfa5adaf2e24419bdfca70e8726\nBlueprint: alarm-notifier\n'}]",10,37218,bc495c3dc9e644a37324fc5025efbd6669e0436d,46,6,10,2813,,,0,"alarm: Per user setting to disable ssl verify

This allows the user to disable ssl verification via a query string
parameter in the action url.

example of action:
 https://unstrusted-ssl-host/?ceilometer-alarm-ssl-verify=0

Change-Id: I12294aa191ff4dfa5adaf2e24419bdfca70e8726
Blueprint: alarm-notifier
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/18/37218/9 && git format-patch -1 --stdout FETCH_HEAD,"['tests/alarm/test_notifier.py', 'ceilometer/alarm/notifier/rest.py']",2,0a5b4ecc675e0ddaf060d26e188726c1f12b471e,bp/alarm-notifier,"import urlparse if action.scheme == 'https': options = urlparse.parse_qs(action.query) verify = bool(int(options.get('ceilometer-alarm-ssl-verify', [1])[-1])) if not verify: kwargs['verify'] = False elif cfg.CONF.alarm.rest_notifier_certificate: kwargs['cert'] = cfg.CONF.alarm.rest_notifier_certificate", if action.scheme == 'https' and \ cfg.CONF.alarm.rest_notifier_certificate: kwargs['cert'] = cfg.CONF.alarm.rest_notifier_certificate,32,3
openstack%2Fceilometer~master~Iaf296a3ef204ef64612794ec93d571813051e333,openstack/ceilometer,master,Iaf296a3ef204ef64612794ec93d571813051e333,Handle user_metadata in alarm threshold evaluator,ABANDONED,2013-07-19 13:19:00.000000000,2013-07-24 10:30:01.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}]","[{'number': 1, 'created': '2013-07-19 13:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/96f8e1b23a10e3a4dbde1965d9ddba4bd9daa1ba', 'message': ""Handle user_metadata in alarm threshold evaluator\n\nThis change allow to use the reserved_metadata_namespace in the alarm\nmatching_metadata field. Example:\n\nWhen alarm want to match 'metering.whatever.key' of a resouce_metadata,\nthe alarm threshold evaluator convert the key to\n'metadata.user_metadata.whatever_key'.\n\nChange-Id: Iaf296a3ef204ef64612794ec93d571813051e333\n""}, {'number': 2, 'created': '2013-07-19 13:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bbc42a4376f3276e03f88d1c180f5a5ced953e1d', 'message': ""Handle user_metadata in alarm threshold evaluator\n\nThis change allow to use the reserved_metadata_namespace in the alarm\nmatching_metadata field. Example:\n\nWhen alarm want to match 'metering.whatever.key' of a resouce_metadata,\nthe alarm threshold evaluator convert the key to\n'metadata.user_metadata.whatever_key'.\n\nChange-Id: Iaf296a3ef204ef64612794ec93d571813051e333\n""}, {'number': 3, 'created': '2013-07-19 15:04:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e3e0059f1d2ea5f02bf3f02540d413a11be6a787', 'message': ""Handle user_metadata in alarm threshold evaluator\n\nThis change allow to use the reserved_metadata_namespace in the alarm\nmatching_metadata field. Example:\n\nWhen alarm want to match 'metering.whatever.key' of a resouce_metadata,\nthe alarm threshold evaluator convert the key to\n'metadata.user_metadata.whatever_key'.\n\nChange-Id: Iaf296a3ef204ef64612794ec93d571813051e333\n""}, {'number': 4, 'created': '2013-07-22 07:36:16.000000000', 'files': ['ceilometer/alarm/threshold_evaluation.py', 'tests/alarm/test_threshold_evaluation.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e221e98584e71e6d55ec02ba95893dad90dd51ec', 'message': ""Handle user_metadata in alarm threshold evaluator\n\nThis change allow to use the reserved_metadata_namespace in the alarm\nmatching_metadata field. Example:\n\nWhen alarm want to match 'metering.whatever.key' of a resouce_metadata,\nthe alarm threshold evaluator convert the key to\n'metadata.user_metadata.whatever_key'.\n\nChange-Id: Iaf296a3ef204ef64612794ec93d571813051e333\n""}]",6,37897,e221e98584e71e6d55ec02ba95893dad90dd51ec,11,4,4,2813,,,0,"Handle user_metadata in alarm threshold evaluator

This change allow to use the reserved_metadata_namespace in the alarm
matching_metadata field. Example:

When alarm want to match 'metering.whatever.key' of a resouce_metadata,
the alarm threshold evaluator convert the key to
'metadata.user_metadata.whatever_key'.

Change-Id: Iaf296a3ef204ef64612794ec93d571813051e333
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/97/37897/3 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/alarm/threshold_evaluation.py', 'tests/alarm/test_threshold_evaluation.py']",2,96f8e1b23a10e3a4dbde1965d9ddba4bd9daa1ba,sileht/rpcnotifier,"from oslo.config import cfg matching_metadata={ 'resource_id': 'my_instance', 'metering.autoscale.group': 'meme', 'custom_metering.key': 'a_value' }), matching_metadata={ 'metering.what': 'ok', 'metadata.user_metadata.AS': 'my_group' }), def test_user_metadata_conversion(self): cfg.CONF.set_override('reserved_metadata_namespace', [ 'metering.', 'custom_metering.']) with mock.patch('ceilometerclient.client.get_client', return_value=self.api_client): self.api_client.statistics.list.return_value = [] self.evaluator.evaluate() expected_query_params = [ [('resource_id', 'eq', 'my_instance'), ('metadata.user_metadata.autoscale_group', 'eq', 'meme'), ('metadata.user_metadata.key', 'eq', 'a_value')], [('metadata.user_metadata.what', 'eq', 'ok'), ('metadata.user_metadata.AS', 'eq', 'my_group')] ] self.assertEqual( [mock.call(mock.ANY, q=QueryMatcher(qp), period=mock.ANY) for qp in expected_query_params], self.api_client.statistics.list.call_args_list ) class QueryMatcher(object): def __init__(self, expected_items): self.expected_items = expected_items def __eq__(self, objs): for item in self.expected_items: for obj in objs: if item == (obj['field'], obj['op'], obj['value']): break else: return False return True def __repr__(self): return '<QueryMatcher ""%s"">' % self.expected_items"," matching_metadata={'resource_id': 'my_instance'}), matching_metadata={'metadata.user_metadata.AS': 'my_group'}),",63,4
openstack%2Fceilometer~master~Id44ac158b8ff39c3d414c511f1bb2b3c948db0d2,openstack/ceilometer,master,Id44ac158b8ff39c3d414c511f1bb2b3c948db0d2,Refactored API V1 tests to use testscenarios,MERGED,2013-07-23 14:33:10.000000000,2013-07-24 10:28:50.000000000,2013-07-24 10:28:50.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 6537}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-07-23 14:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/721637413c164c3c2755f8b49606034bbe2e1705', 'message': 'Refactored API V1 tests to use testscenarios\n\nRelated to blueprint db-tests-with-scenarios\n\nChange-Id: Id44ac158b8ff39c3d414c511f1bb2b3c948db0d2\n'}, {'number': 2, 'created': '2013-07-24 09:43:33.000000000', 'files': ['tests/api/v1/test_impl_hbase.py', 'tests/api/v1/test_max_resource_volume_scenarios.py', 'tests/api/v1/test_sum_resource_volume_scenarios.py', 'tests/api/v1/test_impl_sqlalchemy.py', 'tests/api/v1/test_list_events_scenarios.py', 'tests/api/v1/test_max_project_volume_scenarios.py', 'tests/api/v1/test_list_projects_scenarios.py', 'tests/api/v1/test_impl_mongodb.py', 'tests/api/v1/test_sum_project_volume_scenarios.py', 'tests/api/v1/test_compute_duration_by_resource_scenarios.py', 'tests/api/v1/test_list_meters_scenarios.py', 'tests/api/v1/test_list_resources_scenarios.py', 'tests/api/v1/test_list_users_scenarios.py', 'tests/api/v1/test_list_sources_scenarios.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/db423dde9cdc20bb31b9f05684a5c3125cb5d7da', 'message': 'Refactored API V1 tests to use testscenarios\n\nRelated to blueprint db-tests-with-scenarios\n\nChange-Id: Id44ac158b8ff39c3d414c511f1bb2b3c948db0d2\n'}]",7,38299,db423dde9cdc20bb31b9f05684a5c3125cb5d7da,12,5,2,7763,,,0,"Refactored API V1 tests to use testscenarios

Related to blueprint db-tests-with-scenarios

Change-Id: Id44ac158b8ff39c3d414c511f1bb2b3c948db0d2
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/99/38299/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/api/v1/test_impl_hbase.py', 'tests/api/v1/test_max_resource_volume_scenarios.py', 'tests/api/v1/test_sum_resource_volume_scenarios.py', 'tests/api/v1/test_impl_sqlalchemy.py', 'tests/api/v1/test_list_events_scenarios.py', 'tests/api/v1/test_max_project_volume_scenarios.py', 'tests/api/v1/test_list_projects_scenarios.py', 'tests/api/v1/test_impl_mongodb.py', 'tests/api/v1/test_sum_project_volume_scenarios.py', 'tests/api/v1/test_compute_duration_by_resource_scenarios.py', 'tests/api/v1/test_list_meters_scenarios.py', 'tests/api/v1/test_list_resources_scenarios.py', 'tests/api/v1/test_list_users_scenarios.py', 'tests/api/v1/test_list_sources_scenarios.py']",14,721637413c164c3c2755f8b49606034bbe2e1705,bp/db-tests-with-scenarios,"from testscenarios import load_tests_apply_scenarios as load_tests # noqa F401 scenarios = [ ('sqlalchemy', dict(database_connection='sqlite://')), ('mongodb', dict(database_connection='mongodb://__test__')), ('hbase', dict(database_connection='hbase://__test__')), ] ",,124,294
openstack%2Fceilometer~master~I9f7301f4804f0a58d0ab8a21fecdaf3643547191,openstack/ceilometer,master,I9f7301f4804f0a58d0ab8a21fecdaf3643547191,alarm: Global setting to disable ssl verification,MERGED,2013-07-16 11:18:35.000000000,2013-07-24 10:22:16.000000000,2013-07-24 10:22:16.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 4715}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-16 11:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/15967f092f17cf9bb819cf8d07c8f8db7059b73a', 'message': 'alarm: Global setting to disable ssl verification\n\nAllow to disable the ssl server certificate verification when\nthe action url is a https request in the global configuration file:\n\n [alarm]\n rest_notifier_ssl_verify = False\n\nChange-Id: I9f7301f4804f0a58d0ab8a21fecdaf3643547191\nBlueprint: alarm-notifier\n'}, {'number': 2, 'created': '2013-07-16 13:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d17b39bc8153668f1c9532376b4df53eb095fc9a', 'message': 'alarm: Global setting to disable ssl verification\n\nAllow to disable the ssl server certificate verification when\nthe action url is a https request in the global configuration file:\n\n [alarm]\n rest_notifier_ssl_verify = False\n\nChange-Id: I9f7301f4804f0a58d0ab8a21fecdaf3643547191\nBlueprint: alarm-notifier\n'}, {'number': 3, 'created': '2013-07-16 14:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/06dc3504d04f8c92c0e06955dcc0966057eb0bc1', 'message': 'alarm: Global setting to disable ssl verification\n\nAllow to disable the ssl server certificate verification when\nthe action url is a https request in the global configuration file:\n\n [alarm]\n rest_notifier_ssl_verify = False\n\nChange-Id: I9f7301f4804f0a58d0ab8a21fecdaf3643547191\nBlueprint: alarm-notifier\n'}, {'number': 4, 'created': '2013-07-18 06:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9149b6e783e566544d803afbc18c24e059d80a1c', 'message': 'alarm: Global setting to disable ssl verification\n\nAllow to disable the ssl server certificate verification when\nthe action url is a https request in the global configuration file:\n\n [alarm]\n rest_notifier_ssl_verify = False\n\nChange-Id: I9f7301f4804f0a58d0ab8a21fecdaf3643547191\nBlueprint: alarm-notifier\n'}, {'number': 5, 'created': '2013-07-18 13:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ae80a0296d9ad3a973ba07025b1db614563cda5b', 'message': 'alarm: Global setting to disable ssl verification\n\nAllow to disable the ssl server certificate verification when\nthe action url is a https request in the global configuration file:\n\n [alarm]\n rest_notifier_ssl_verify = False\n\nChange-Id: I9f7301f4804f0a58d0ab8a21fecdaf3643547191\nBlueprint: alarm-notifier\n'}, {'number': 6, 'created': '2013-07-18 14:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4c80f0f84d5787e0d72e507e1dad0f4bf31475e6', 'message': 'alarm: Global setting to disable ssl verification\n\nAllow to disable the ssl server certificate verification when\nthe action url is a https request in the global configuration file:\n\n [alarm]\n rest_notifier_ssl_verify = False\n\nChange-Id: I9f7301f4804f0a58d0ab8a21fecdaf3643547191\nBlueprint: alarm-notifier\n'}, {'number': 7, 'created': '2013-07-22 08:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4800c2eef0ba47f573b51e6c5ce2baa1a947312d', 'message': 'alarm: Global setting to disable ssl verification\n\nAllow to disable the ssl server certificate verification when\nthe action url is a https request in the global configuration file:\n\n [alarm]\n rest_notifier_ssl_verify = False\n\nChange-Id: I9f7301f4804f0a58d0ab8a21fecdaf3643547191\nBlueprint: alarm-notifier\n'}, {'number': 8, 'created': '2013-07-22 18:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4f4b7d33f5264f3ab0ee435e758fe4b3ab13b4dd', 'message': 'alarm: Global setting to disable ssl verification\n\nAllow to disable the ssl server certificate verification when\nthe action url is a https request in the global configuration file:\n\n [alarm]\n rest_notifier_ssl_verify = False\n\nChange-Id: I9f7301f4804f0a58d0ab8a21fecdaf3643547191\nBlueprint: alarm-notifier\n'}, {'number': 9, 'created': '2013-07-23 16:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/13eb94b828aae23313fb42182c7c68343e52d15b', 'message': 'alarm: Global setting to disable ssl verification\n\nAllow to disable the ssl server certificate verification when\nthe action url is a https request in the global configuration file:\n\n [alarm]\n rest_notifier_ssl_verify = False\n\nChange-Id: I9f7301f4804f0a58d0ab8a21fecdaf3643547191\nBlueprint: alarm-notifier\n'}, {'number': 10, 'created': '2013-07-24 09:47:37.000000000', 'files': ['tests/alarm/test_notifier.py', 'ceilometer/alarm/notifier/rest.py', 'etc/ceilometer/ceilometer.conf.sample'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e3131c73ce477fd191d150b54fd4f0d3288d8e2e', 'message': 'alarm: Global setting to disable ssl verification\n\nAllow to disable the ssl server certificate verification when\nthe action url is a https request in the global configuration file:\n\n [alarm]\n rest_notifier_ssl_verify = False\n\nChange-Id: I9f7301f4804f0a58d0ab8a21fecdaf3643547191\nBlueprint: alarm-notifier\n'}]",8,37219,e3131c73ce477fd191d150b54fd4f0d3288d8e2e,49,7,10,2813,,,0,"alarm: Global setting to disable ssl verification

Allow to disable the ssl server certificate verification when
the action url is a https request in the global configuration file:

 [alarm]
 rest_notifier_ssl_verify = False

Change-Id: I9f7301f4804f0a58d0ab8a21fecdaf3643547191
Blueprint: alarm-notifier
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/19/37219/7 && git format-patch -1 --stdout FETCH_HEAD,"['tests/alarm/test_notifier.py', 'ceilometer/alarm/notifier/rest.py', 'etc/ceilometer/ceilometer.conf.sample']",3,15967f092f17cf9bb819cf8d07c8f8db7059b73a,bp/alarm-notifier,# Do the ssl server certificate when calling alarm action # (boolean value) #rest_notifier_ssl_verify=true # Total option count: 124,# Total option count: 123,34,3
openstack%2Frequirements~master~I1dddeec13a45949f01f94014a8451d98cb443b4e,openstack/requirements,master,I1dddeec13a45949f01f94014a8451d98cb443b4e,Add sockjs-tornado requirement,MERGED,2013-07-22 13:28:34.000000000,2013-07-24 10:19:39.000000000,2013-07-24 10:19:39.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 4330}]","[{'number': 1, 'created': '2013-07-22 13:28:34.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/695d9a785703e55cd37665b39615e8bb2a952642', 'message': 'Add sockjs-tornado requirement\n\nThis is a prerequisite for the blueprint realtime-communication in Horizon.\n\nChange-Id: I1dddeec13a45949f01f94014a8451d98cb443b4e\nSigned-off-by: Tomas Sedovic <tomas@sedovic.cz>\n'}]",0,38146,695d9a785703e55cd37665b39615e8bb2a952642,9,4,1,4330,,,0,"Add sockjs-tornado requirement

This is a prerequisite for the blueprint realtime-communication in Horizon.

Change-Id: I1dddeec13a45949f01f94014a8451d98cb443b4e
Signed-off-by: Tomas Sedovic <tomas@sedovic.cz>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/46/38146/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,695d9a785703e55cd37665b39615e8bb2a952642,bp/realtime-communication,"sockjs-tornado>=1.0.0,<2.0.0",,1,0
openstack%2Fnova~master~Ic9b425a3d9ea2b614643ba8d3db50b065947c806,openstack/nova,master,Ic9b425a3d9ea2b614643ba8d3db50b065947c806,Create vmware section,MERGED,2013-07-17 17:36:49.000000000,2013-07-24 10:15:33.000000000,2013-07-24 10:15:31.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 7400}, {'_account_id': 7629}]","[{'number': 1, 'created': '2013-07-17 17:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e0fe5b40e84b54a2213d65482d144e211ebaebf', 'message': 'Create vmware section\n\nImplements blueprint vmware-configuration-section\n\nChange-Id: Ic9b425a3d9ea2b614643ba8d3db50b065947c806\n'}, {'number': 2, 'created': '2013-07-17 19:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f287924ac90e8e32b1370c36f8b113de9a7424d', 'message': 'Create vmware section\n\nImplements blueprint vmware-configuration-section\n\nVMware specific parameters will be moved to a new section. The\nchange is backward compatible and supports existing\nconfigurations.\n\nChange-Id: Ic9b425a3d9ea2b614643ba8d3db50b065947c806\n'}, {'number': 3, 'created': '2013-07-19 21:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ecc3121154a2667c1acb8dda396cbdf6ad483e8', 'message': 'Create vmware section\n\nImplements blueprint vmware-configuration-section\n\nVMware specific parameters will be moved to a new section. The\nchange is backward compatible and supports existing\nconfigurations.\n\nDocImpact\n\nChange-Id: Ic9b425a3d9ea2b614643ba8d3db50b065947c806\n'}, {'number': 4, 'created': '2013-07-19 23:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3cfe06114f3754ce678282718d9575202e540134', 'message': 'Create vmware section\n\nImplements blueprint vmware-configuration-section\n\nVMware specific parameters will be moved to a new section. The\nchange is backward compatible and supports existing\nconfigurations.\n\nDocImpact\n\nChange-Id: Ic9b425a3d9ea2b614643ba8d3db50b065947c806\n'}, {'number': 5, 'created': '2013-07-22 23:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66b6a02c594b58f4318600a1765fb3aa1fdbb50e', 'message': 'Create vmware section\n\nImplements blueprint vmware-configuration-section\n\nVMware specific parameters will be moved to a new section. The\nchange is backward compatible and supports existing\nconfigurations.\n\nDocImpact\n\nChange-Id: Ic9b425a3d9ea2b614643ba8d3db50b065947c806\n'}, {'number': 6, 'created': '2013-07-23 00:10:49.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_vmwareapi.py', 'etc/nova/nova.conf.sample', 'nova/virt/vmwareapi/volumeops.py', 'nova/virt/vmwareapi/driver.py', 'nova/virt/vmwareapi/vif.py', 'nova/tests/virt/vmwareapi/test_vmwareapi_vif.py', 'nova/virt/vmwareapi/vim.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2642897d6f5b8a211424519d99feddc89c3bf180', 'message': 'Create vmware section\n\nImplements blueprint vmware-configuration-section\n\nVMware specific parameters will be moved to a new section. The\nchange is backward compatible and supports existing\nconfigurations.\n\nDocImpact\n\nChange-Id: Ic9b425a3d9ea2b614643ba8d3db50b065947c806\n'}]",0,37539,2642897d6f5b8a211424519d99feddc89c3bf180,32,7,6,1653,,,0,"Create vmware section

Implements blueprint vmware-configuration-section

VMware specific parameters will be moved to a new section. The
change is backward compatible and supports existing
configurations.

DocImpact

Change-Id: Ic9b425a3d9ea2b614643ba8d3db50b065947c806
",git fetch https://review.opendev.org/openstack/nova refs/changes/39/37539/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/virt/vmwareapi/driver.py', 'nova/virt/vmwareapi/volumeops.py', 'nova/virt/vmwareapi/vif.py', 'nova/tests/virt/vmwareapi/test_vmwareapi_vif.py', 'nova/virt/vmwareapi/vim.py']",7,0e0fe5b40e84b54a2213d65482d144e211ebaebf,bp/vmware-configuration-section,"vmwareapi_wsdl_loc_opt = cfg.StrOpt('wsdl_location', deprecated_name='vmwareapi_wsdl_loc', deprecated_group='DEFAULT',CONF.register_opt(vmwareapi_wsdl_loc_opt, 'vmware') wsdl_url = CONF.vmware.wsdl_location","vmwareapi_wsdl_loc_opt = cfg.StrOpt('vmwareapi_wsdl_loc',CONF.register_opt(vmwareapi_wsdl_loc_opt) wsdl_url = CONF.vmwareapi_wsdl_loc",67,45
openstack%2Fcinder~master~I75e71b3e5df69e6b507ee64d330a9ec2455266c5,openstack/cinder,master,I75e71b3e5df69e6b507ee64d330a9ec2455266c5,Adding driver minimum features and volume stats to dev doc,MERGED,2013-07-23 22:26:42.000000000,2013-07-24 09:49:28.000000000,2013-07-24 09:49:27.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1107}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 6043}]","[{'number': 1, 'created': '2013-07-23 22:26:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/003215f1a3064b814071b66f3b817e928ce502e4', 'message': 'Adding driver minimum features and volume stats to dev doc\n\nThis is a first pass in getting information out of the wiki and into the\ndev docs, so changes can be reviewed properly as discussed at the Havana\nsummit.\n\nChange-Id: I75e71b3e5df69e6b507ee64d330a9ec2455266c5\n'}, {'number': 2, 'created': '2013-07-24 06:16:15.000000000', 'files': ['doc/source/devref/drivers.rst', 'doc/source/devref/index.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/72ebea66b63ed386f78049f2f9c923f44f8e0c89', 'message': 'Adding driver minimum features and volume stats to dev doc\n\nThis is a first pass in getting information out of the wiki and into the\ndev docs, so changes can be reviewed properly as discussed at the Havana\nsummit.\n\nChange-Id: I75e71b3e5df69e6b507ee64d330a9ec2455266c5\n'}]",2,38383,72ebea66b63ed386f78049f2f9c923f44f8e0c89,13,7,2,170,,,0,"Adding driver minimum features and volume stats to dev doc

This is a first pass in getting information out of the wiki and into the
dev docs, so changes can be reviewed properly as discussed at the Havana
summit.

Change-Id: I75e71b3e5df69e6b507ee64d330a9ec2455266c5
",git fetch https://review.opendev.org/openstack/cinder refs/changes/83/38383/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/devref/drivers.rst', 'doc/source/devref/index.rst']",2,003215f1a3064b814071b66f3b817e928ce502e4,update-driver-doc, drivers,,69,0
openstack%2Fnova~master~I2f285b405b598d69f80504b040b4a0e32d80020b,openstack/nova,master,I2f285b405b598d69f80504b040b4a0e32d80020b,Fixes wrong action comment 'lock' to 'unlock',MERGED,2013-07-17 07:46:49.000000000,2013-07-24 09:30:32.000000000,2013-07-24 09:30:29.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 5511}, {'_account_id': 6610}]","[{'number': 1, 'created': '2013-07-17 07:46:49.000000000', 'files': ['nova/api/openstack/compute/contrib/admin_actions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c57674c6bb5d0ba8c10357e91faa39004102fd78', 'message': ""Fixes wrong action comment 'lock' to 'unlock'\n\nChange-Id: I2f285b405b598d69f80504b040b4a0e32d80020b\n""}]",0,37416,c57674c6bb5d0ba8c10357e91faa39004102fd78,9,7,1,6610,,,0,"Fixes wrong action comment 'lock' to 'unlock'

Change-Id: I2f285b405b598d69f80504b040b4a0e32d80020b
",git fetch https://review.opendev.org/openstack/nova refs/changes/16/37416/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/contrib/admin_actions.py'],1,c57674c6bb5d0ba8c10357e91faa39004102fd78,master," """"""Permit admins to unlock a server."""""""," """"""Permit admins to lock a server.""""""",1,1
openstack%2Fnova~master~I8394c7ccbd0d71ffcf5f35c64a5c307dbf579364,openstack/nova,master,I8394c7ccbd0d71ffcf5f35c64a5c307dbf579364,Code dedup in class ImageXMLSerializationTest,MERGED,2013-07-02 11:53:11.000000000,2013-07-24 09:30:10.000000000,2013-07-24 09:30:08.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 6172}, {'_account_id': 6509}, {'_account_id': 6938}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7727}]","[{'number': 1, 'created': '2013-07-02 11:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de045497809d17e53e32a54566f08aee82b2ff35', 'message': 'Refactor class ImageXMLSerializationTest\n\nRemoved code duplication.\n\nbp nova-tests-code-duplication\n\nChange-Id: I8394c7ccbd0d71ffcf5f35c64a5c307dbf579364\n'}, {'number': 2, 'created': '2013-07-02 13:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/23133a032a7c48dea3a6bce6f0fd2f29c8c05499', 'message': 'Refactor class ImageXMLSerializationTest\n\nRemoved code duplication.\n\nbp nova-tests-code-duplication\n\nChange-Id: I8394c7ccbd0d71ffcf5f35c64a5c307dbf579364\n'}, {'number': 3, 'created': '2013-07-16 10:38:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d37f9ed476663f7eaa917356238deb69ec92f6c', 'message': 'Code dedup in class ImageXMLSerializationTest\n\nExterned common parts to setUp():\n- fixture with test image data\n- test image\n- dictionary with test images\n- test serializer\nThese parts were equal in the most part of the methods.\n\nbp nova-tests-code-duplication\n\nChange-Id: I8394c7ccbd0d71ffcf5f35c64a5c307dbf579364\n'}, {'number': 4, 'created': '2013-07-16 13:20:18.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/74e189fe1354eaa1b0ab88482ded6266fb539566', 'message': 'Code dedup in class ImageXMLSerializationTest\n\nExterned common parts to setUp():\n- fixture with test image data\n- test image\n- dictionary with test images\n- test serializer\nThese parts were equal in the most part of the methods.\n\nbp nova-tests-code-duplication\n\nChange-Id: I8394c7ccbd0d71ffcf5f35c64a5c307dbf579364\n'}]",0,35277,74e189fe1354eaa1b0ab88482ded6266fb539566,23,11,4,7249,,,0,"Code dedup in class ImageXMLSerializationTest

Externed common parts to setUp():
- fixture with test image data
- test image
- dictionary with test images
- test serializer
These parts were equal in the most part of the methods.

bp nova-tests-code-duplication

Change-Id: I8394c7ccbd0d71ffcf5f35c64a5c307dbf579364
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/35277/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/openstack/compute/plugins/v3/test_images.py'],1,de045497809d17e53e32a54566f08aee82b2ff35,bp/nova-tests-code-duplication," def setUp(self): super(ImageXMLSerializationTest, self).setUp() self.fixture = { image = self.fixture['image'] image['id'] = '2' image['name'] = 'Image2' image['status'] = 'SAVING' image['links'][0]['href'] = self.IMAGE_HREF % 2 image['links'][1]['href'] = self.IMAGE_BOOKMARK % 2 self.fixture_list = { self.fixture['image'], image, self.serializer = images.ImageTemplate() def test_xml_declaration(self): output = self.serializer.serialize(self.fixture) has_dec = output.startswith(""<?xml version='1.0' encoding='UTF-8'?>"") self.assertTrue(has_dec) def test_show(self): self.fixture['image']['minRam'] = 10 self.fixture['image']['minDisk'] = 100 output = self.serializer.serialize(self.fixture) root = etree.XML(output) xmlutil.validate_schema(root, 'image') image_dict = self.fixture['image'] self._assertElementEquals(root, image_dict, ['name', 'id', 'updated', 'created', 'status', 'progress']) self._assertMetadataEquals(root, image_dict) self._assertServerIdAndLinksEquals(root, image_dict) def test_show_zero_metadata(self): self.fixture['image']['metadata'] = {} output = self.serializer.serialize(self.fixture) root = etree.XML(output) xmlutil.validate_schema(root, 'image') image_dict = self.fixture['image'] meta_nodes = root.findall('{0}meta'.format(ATOMNS)) self.assertEqual(len(meta_nodes), 0) self._assertElementEquals(root, image_dict, ['name', 'id', 'updated', 'created', 'status']) self._assertServerIdAndLinksEquals(root, image_dict) def test_show_image_no_metadata_key(self): del self.fixture['image']['metadata'] output = self.serializer.serialize(self.fixture) root = etree.XML(output) xmlutil.validate_schema(root, 'image') image_dict = self.fixture['image'] meta_nodes = root.findall('{0}meta'.format(ATOMNS)) self.assertEqual(len(meta_nodes), 0) self._assertElementEquals(root, image_dict, ['name', 'id', 'updated', 'created', 'status']) self._assertServerIdAndLinksEquals(root, image_dict) def test_show_no_server(self): del self.fixture['image']['server'] output = self.serializer.serialize(self.fixture) root = etree.XML(output) xmlutil.validate_schema(root, 'image') image_dict = self.fixture['image'] server_root = root.find('{0}server'.format(NS)) self.assertEqual(server_root, None) self._assertElementEquals(root, image_dict, ['name', 'id', 'updated', 'created', 'status']) self._assertMetadataEquals(root, image_dict) def test_show_with_min_ram(self): self.fixture['image']['minRam'] = 256 output = self.serializer.serialize(self.fixture) root = etree.XML(output) xmlutil.validate_schema(root, 'image') image_dict = self.fixture['image'] self._assertElementEquals(root, image_dict, ['name', 'id', 'updated', 'created', 'status', 'progress', 'minRam']) self._assertMetadataEquals(root, image_dict) self._assertServerIdAndLinksEquals(root, image_dict) def test_show_with_min_disk(self): self.fixture['image']['minDisk'] = 5 output = self.serializer.serialize(self.fixture) root = etree.XML(output) xmlutil.validate_schema(root, 'image') image_dict = self.fixture['image'] self._assertElementEquals(root, image_dict, ['name', 'id', 'updated', 'created', 'status', 'progress', 'minDisk']) self._assertMetadataEquals(root, image_dict) self._assertServerIdAndLinksEquals(root, image_dict) def test_index(self): serializer = images.MinimalImagesTemplate() output = serializer.serialize(self.fixture_list) image_dict = self.fixture_list['images'][i] self._assertElementEquals(image_elem, image_dict, ['name', 'id']) def test_index_with_links(self): serializer = images.MinimalImagesTemplate() output = serializer.serialize(self.fixture_list) root = etree.XML(output) xmlutil.validate_schema(root, 'images_index') image_elems = root.findall('{0}image'.format(NS)) self.assertEqual(len(image_elems), 2) for i, image_elem in enumerate(image_elems): image_dict = self.fixture_list['images'][i] self._assertElementEquals(image_elem, image_dict, ['name', 'id']) for i, link in enumerate(self.fixture_list['images_links']): del self.fixture_list['images'] output = serializer.serialize(self.fixture_list) output = serializer.serialize(self.fixture_list) image_dict = self.fixture_list['images'][i] self._assertElementEquals(image_elem, image_dict, ['name', 'id', 'updated', 'created', 'status']) def _assertElementEquals(self, elem, dict, keys): for key in keys: self.assertEquals(elem.get(key),str(dict[key])) self._assertElementsAndLinksEquals(elem, dict) def _assertElementsAndLinksEquals(self, root, dict): link_nodes = root.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(dict['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) def _assertServerIdAndLinksEquals(self, root, dict): server_root = root.find('{0}server'.format(NS)) self.assertEqual(server_root.get('id'), dict['server']['id']) self._assertElementsAndLinksEquals(server_root, dict['server']) def _assertMetadataEquals(self, root, dict): metadata_root = root.find('{0}metadata'.format(NS)) metadata_elems = metadata_root.findall('{0}meta'.format(NS)) self.assertEqual(len(metadata_elems), 1) for i, metadata_elem in enumerate(metadata_elems): (meta_key, meta_value) = dict['metadata'].items()[i] self.assertEqual(str(metadata_elem.get('key')), str(meta_key)) self.assertEqual(str(metadata_elem.text).strip(), str(meta_value))"," def test_xml_declaration(self): serializer = images.ImageTemplate() fixture = { output = serializer.serialize(fixture) has_dec = output.startswith(""<?xml version='1.0' encoding='UTF-8'?>"") self.assertTrue(has_dec) def test_show(self): serializer = images.ImageTemplate() fixture = { 'image': { 'id': 1, 'name': 'Image1', 'created': self.TIMESTAMP, 'updated': self.TIMESTAMP, 'status': 'ACTIVE', 'progress': 80, 'minRam': 10, 'minDisk': 100, 'server': { 'id': self.SERVER_UUID, 'links': [ { 'href': self.SERVER_HREF, 'rel': 'self', }, { 'href': self.SERVER_BOOKMARK, 'rel': 'bookmark', }, ], }, 'metadata': { 'key1': 'value1', }, 'links': [ { 'href': self.IMAGE_HREF % 1, 'rel': 'self', }, { 'href': self.IMAGE_BOOKMARK % 1, 'rel': 'bookmark', }, ], }, } output = serializer.serialize(fixture) root = etree.XML(output) xmlutil.validate_schema(root, 'image') image_dict = fixture['image'] for key in ['name', 'id', 'updated', 'created', 'status', 'progress']: self.assertEqual(root.get(key), str(image_dict[key])) link_nodes = root.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) metadata_root = root.find('{0}metadata'.format(NS)) metadata_elems = metadata_root.findall('{0}meta'.format(NS)) self.assertEqual(len(metadata_elems), 1) for i, metadata_elem in enumerate(metadata_elems): (meta_key, meta_value) = image_dict['metadata'].items()[i] self.assertEqual(str(metadata_elem.get('key')), str(meta_key)) self.assertEqual(str(metadata_elem.text).strip(), str(meta_value)) server_root = root.find('{0}server'.format(NS)) self.assertEqual(server_root.get('id'), image_dict['server']['id']) link_nodes = server_root.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['server']['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) def test_show_zero_metadata(self): serializer = images.ImageTemplate() fixture = { 'image': { 'id': 1, 'name': 'Image1', 'created': self.TIMESTAMP, 'updated': self.TIMESTAMP, 'status': 'ACTIVE', 'server': { 'id': self.SERVER_UUID, 'links': [ { 'href': self.SERVER_HREF, 'rel': 'self', }, { 'href': self.SERVER_BOOKMARK, 'rel': 'bookmark', }, ], }, 'metadata': {}, 'links': [ { 'href': self.IMAGE_HREF % 1, 'rel': 'self', }, { 'href': self.IMAGE_BOOKMARK % 1, 'rel': 'bookmark', }, ], }, } output = serializer.serialize(fixture) root = etree.XML(output) xmlutil.validate_schema(root, 'image') image_dict = fixture['image'] for key in ['name', 'id', 'updated', 'created', 'status']: self.assertEqual(root.get(key), str(image_dict[key])) link_nodes = root.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) meta_nodes = root.findall('{0}meta'.format(ATOMNS)) self.assertEqual(len(meta_nodes), 0) server_root = root.find('{0}server'.format(NS)) self.assertEqual(server_root.get('id'), image_dict['server']['id']) link_nodes = server_root.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['server']['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) def test_show_image_no_metadata_key(self): serializer = images.ImageTemplate() fixture = { 'image': { 'id': 1, 'name': 'Image1', 'created': self.TIMESTAMP, 'updated': self.TIMESTAMP, 'status': 'ACTIVE', 'server': { 'id': self.SERVER_UUID, 'links': [ { 'href': self.SERVER_HREF, 'rel': 'self', }, { 'href': self.SERVER_BOOKMARK, 'rel': 'bookmark', }, ], }, 'links': [ { 'href': self.IMAGE_HREF % 1, 'rel': 'self', }, { 'href': self.IMAGE_BOOKMARK % 1, 'rel': 'bookmark', }, ], }, } output = serializer.serialize(fixture) root = etree.XML(output) xmlutil.validate_schema(root, 'image') image_dict = fixture['image'] for key in ['name', 'id', 'updated', 'created', 'status']: self.assertEqual(root.get(key), str(image_dict[key])) link_nodes = root.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) meta_nodes = root.findall('{0}meta'.format(ATOMNS)) self.assertEqual(len(meta_nodes), 0) server_root = root.find('{0}server'.format(NS)) self.assertEqual(server_root.get('id'), image_dict['server']['id']) link_nodes = server_root.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['server']['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) def test_show_no_server(self): serializer = images.ImageTemplate() fixture = { 'image': { 'id': 1, 'name': 'Image1', 'created': self.TIMESTAMP, 'updated': self.TIMESTAMP, 'status': 'ACTIVE', 'metadata': { 'key1': 'value1', }, 'links': [ { 'href': self.IMAGE_HREF % 1, 'rel': 'self', }, { 'href': self.IMAGE_BOOKMARK % 1, 'rel': 'bookmark', }, ], }, } output = serializer.serialize(fixture) root = etree.XML(output) xmlutil.validate_schema(root, 'image') image_dict = fixture['image'] for key in ['name', 'id', 'updated', 'created', 'status']: self.assertEqual(root.get(key), str(image_dict[key])) link_nodes = root.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) metadata_root = root.find('{0}metadata'.format(NS)) metadata_elems = metadata_root.findall('{0}meta'.format(NS)) self.assertEqual(len(metadata_elems), 1) for i, metadata_elem in enumerate(metadata_elems): (meta_key, meta_value) = image_dict['metadata'].items()[i] self.assertEqual(str(metadata_elem.get('key')), str(meta_key)) self.assertEqual(str(metadata_elem.text).strip(), str(meta_value)) server_root = root.find('{0}server'.format(NS)) self.assertEqual(server_root, None) def test_show_with_min_ram(self): serializer = images.ImageTemplate() fixture = { 'image': { 'id': 1, 'name': 'Image1', 'created': self.TIMESTAMP, 'updated': self.TIMESTAMP, 'status': 'ACTIVE', 'progress': 80, 'minRam': 256, 'server': { 'id': self.SERVER_UUID, 'links': [ { 'href': self.SERVER_HREF, 'rel': 'self', }, { 'href': self.SERVER_BOOKMARK, 'rel': 'bookmark', }, ], }, 'metadata': { 'key1': 'value1', }, 'links': [ { 'href': self.IMAGE_HREF % 1, 'rel': 'self', }, { 'href': self.IMAGE_BOOKMARK % 1, 'rel': 'bookmark', }, ], }, } output = serializer.serialize(fixture) root = etree.XML(output) xmlutil.validate_schema(root, 'image') image_dict = fixture['image'] for key in ['name', 'id', 'updated', 'created', 'status', 'progress', 'minRam']: self.assertEqual(root.get(key), str(image_dict[key])) link_nodes = root.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) metadata_root = root.find('{0}metadata'.format(NS)) metadata_elems = metadata_root.findall('{0}meta'.format(NS)) self.assertEqual(len(metadata_elems), 1) for i, metadata_elem in enumerate(metadata_elems): (meta_key, meta_value) = image_dict['metadata'].items()[i] self.assertEqual(str(metadata_elem.get('key')), str(meta_key)) self.assertEqual(str(metadata_elem.text).strip(), str(meta_value)) server_root = root.find('{0}server'.format(NS)) self.assertEqual(server_root.get('id'), image_dict['server']['id']) link_nodes = server_root.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['server']['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) def test_show_with_min_disk(self): serializer = images.ImageTemplate() fixture = { 'image': { 'id': 1, 'name': 'Image1', 'created': self.TIMESTAMP, 'updated': self.TIMESTAMP, 'status': 'ACTIVE', 'progress': 80, 'minDisk': 5, 'server': { 'id': self.SERVER_UUID, 'links': [ { 'href': self.SERVER_HREF, 'rel': 'self', }, { 'href': self.SERVER_BOOKMARK, 'rel': 'bookmark', }, ], }, 'metadata': { 'key1': 'value1', }, 'links': [ { 'href': self.IMAGE_HREF % 1, 'rel': 'self', }, { 'href': self.IMAGE_BOOKMARK % 1, 'rel': 'bookmark', }, ], }, } output = serializer.serialize(fixture) root = etree.XML(output) xmlutil.validate_schema(root, 'image') image_dict = fixture['image'] for key in ['name', 'id', 'updated', 'created', 'status', 'progress', 'minDisk']: self.assertEqual(root.get(key), str(image_dict[key])) link_nodes = root.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) metadata_root = root.find('{0}metadata'.format(NS)) metadata_elems = metadata_root.findall('{0}meta'.format(NS)) self.assertEqual(len(metadata_elems), 1) for i, metadata_elem in enumerate(metadata_elems): (meta_key, meta_value) = image_dict['metadata'].items()[i] self.assertEqual(str(metadata_elem.get('key')), str(meta_key)) self.assertEqual(str(metadata_elem.text).strip(), str(meta_value)) server_root = root.find('{0}server'.format(NS)) self.assertEqual(server_root.get('id'), image_dict['server']['id']) link_nodes = server_root.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['server']['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) def test_index(self): serializer = images.MinimalImagesTemplate() fixture = { { 'id': 1, 'name': 'Image1', 'links': [ { 'href': self.IMAGE_HREF % 1, 'rel': 'self', }, { 'href': self.IMAGE_BOOKMARK % 1, 'rel': 'bookmark', }, ], }, { 'id': 2, 'name': 'Image2', 'links': [ { 'href': self.IMAGE_HREF % 2, 'rel': 'self', }, { 'href': self.IMAGE_BOOKMARK % 2, 'rel': 'bookmark', }, ], }, ] } output = serializer.serialize(fixture) root = etree.XML(output) xmlutil.validate_schema(root, 'images_index') image_elems = root.findall('{0}image'.format(NS)) self.assertEqual(len(image_elems), 2) for i, image_elem in enumerate(image_elems): image_dict = fixture['images'][i] for key in ['name', 'id']: self.assertEqual(image_elem.get(key), str(image_dict[key])) link_nodes = image_elem.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) def test_index_with_links(self): serializer = images.MinimalImagesTemplate() fixture = { 'images': [ { 'id': 1, 'name': 'Image1', 'links': [ { 'href': self.IMAGE_HREF % 1, 'rel': 'self', }, { 'href': self.IMAGE_BOOKMARK % 1, 'rel': 'bookmark', }, ], }, { 'id': 2, 'name': 'Image2', 'links': [ { 'href': self.IMAGE_HREF % 2, 'rel': 'self', }, { 'href': self.IMAGE_BOOKMARK % 2, 'rel': 'bookmark', }, ], }, output = serializer.serialize(fixture) image_dict = fixture['images'][i] for key in ['name', 'id']: self.assertEqual(image_elem.get(key), str(image_dict[key])) link_nodes = image_elem.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) # Check images_links for i, link in enumerate(fixture['images_links']): fixtures = { 'images': [], } output = serializer.serialize(fixtures) fixture = { 'images': [ { 'id': 1, 'name': 'Image1', 'created': self.TIMESTAMP, 'updated': self.TIMESTAMP, 'status': 'ACTIVE', 'server': { 'id': self.SERVER_UUID, 'links': [ { 'href': self.SERVER_HREF, 'rel': 'self', }, { 'href': self.SERVER_BOOKMARK, 'rel': 'bookmark', }, ], }, 'links': [ { 'href': self.IMAGE_HREF % 1, 'rel': 'self', }, { 'href': self.IMAGE_BOOKMARK % 1, 'rel': 'bookmark', }, ], }, { 'id': '2', 'name': 'Image2', 'created': self.TIMESTAMP, 'updated': self.TIMESTAMP, 'status': 'SAVING', 'progress': 80, 'metadata': { 'key1': 'value1', }, 'links': [ { 'href': self.IMAGE_HREF % 2, 'rel': 'self', }, { 'href': self.IMAGE_BOOKMARK % 2, 'rel': 'bookmark', }, ], }, ] } output = serializer.serialize(fixture) image_dict = fixture['images'][i] for key in ['name', 'id', 'updated', 'created', 'status']: self.assertEqual(image_elem.get(key), str(image_dict[key])) link_nodes = image_elem.findall('{0}link'.format(ATOMNS)) self.assertEqual(len(link_nodes), 2) for i, link in enumerate(image_dict['links']): for key, value in link.items(): self.assertEqual(link_nodes[i].get(key), value) ",142,567
openstack%2Fnova~master~I83bfd8b597121c9de091283845b841680e150e76,openstack/nova,master,I83bfd8b597121c9de091283845b841680e150e76,Code dedup in test_libvirt_volume,MERGED,2013-07-08 08:28:49.000000000,2013-07-24 09:29:49.000000000,2013-07-24 09:29:47.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 6938}, {'_account_id': 7249}, {'_account_id': 7293}]","[{'number': 1, 'created': '2013-07-08 08:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5ee4fae393b3b38c9769b588c199d978d68a52d1', 'message': 'Refactor test_libvirt_volume\n\nRemoved code duplication.\n\nbp nova-tests-code-duplication\n\nChange-Id: I83bfd8b597121c9de091283845b841680e150e76\n'}, {'number': 2, 'created': '2013-07-16 12:58:53.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt_volume.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f81ae35c57490e999f8dd6f694539c77d05d4ac7', 'message': 'Code dedup in test_libvirt_volume\n\n- externed common assertions to methods\n- externed common parts to setUp():\n  - test disk info\n  - test connector\n  - test volume name, location, iqn, data, uuid\n  - test user\n  - test fake connection\n\nbp nova-tests-code-duplication\n\nChange-Id: I83bfd8b597121c9de091283845b841680e150e76\n'}]",0,36032,f81ae35c57490e999f8dd6f694539c77d05d4ac7,18,8,2,7249,,,0,"Code dedup in test_libvirt_volume

- externed common assertions to methods
- externed common parts to setUp():
  - test disk info
  - test connector
  - test volume name, location, iqn, data, uuid
  - test user
  - test fake connection

bp nova-tests-code-duplication

Change-Id: I83bfd8b597121c9de091283845b841680e150e76
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/36032/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/test_libvirt_volume.py'],1,5ee4fae393b3b38c9769b588c199d978d68a52d1,bp/nova-tests-code-duplication," self.disk_info = { } self.name = 'volume-00000001' self.location = '10.0.2.15:3260' self.iqn = 'iqn.2010-10.org.openstack:%s' % self.name self.vol = {'id': 1, 'name': self.name} self.uuid = '875a8070-d0b9-4949-8b31-104d125c9a64' self.user = 'foo' def _assertNetworkAndProtocolEquals(self, tree): self.assertEqual(tree.get('type'), 'network') self.assertEqual(tree.find('./source').get('protocol'), 'rbd') rbd_name = '%s/%s' % ('rbd', self.name) self.assertEqual(tree.find('./source').get('name'), rbd_name) def _assertFileTypeEquals(self, tree, file_path): self.assertEqual(tree.get('type'), 'file') self.assertEqual(tree.find('./source').get('file'), file_path) def test_libvirt_volume_driver_serial(self): libvirt_driver = volume.LibvirtVolumeDriver(self.fake_conn) connection_info = { 'driver_volume_type': 'fake', 'data': { 'device_path': '/foo', }, 'serial': 'fake_serial', } conf = libvirt_driver.connect_volume(connection_info, self.disk_info) connection_info = self.iscsi_connection(self.vol, self.location, self.iqn) conf = libvirt_driver.connect_volume(connection_info, self.disk_info) dev_str = '/dev/disk/by-path/ip-%s-iscsi-%s-lun-1' % (self.location, self.iqn) expected_commands = [('iscsiadm', '-m', 'node', '-T', self.iqn, '-p', self.location), ('iscsiadm', '-m', 'node', '-T', self.iqn, '-p', self.location, '--login'), ('iscsiadm', '-m', 'node', '-T', self.iqn, '-p', self.location, '--op', 'update', ('iscsiadm', '-m', 'node', '-T', self.iqn, '-p', self.location, '--op', 'update', ('iscsiadm', '-m', 'node', '-T', self.iqn, '-p', self.location, '--logout'), ('iscsiadm', '-m', 'node', '-T', self.iqn, '-p', self.location, '--op', 'delete')] devs = ['/dev/disk/by-path/ip-%s-iscsi-%s-lun-1' % (self.location, self.iqn)] vol = {'id': 1, 'name': self.name} connection_info = self.iscsi_connection(vol, self.location, self.iqn) conf = libvirt_driver.connect_volume(connection_info, self.disk_info) dev_str = '/dev/disk/by-path/ip-%s-iscsi-%s-lun-1' % (self.location, self.iqn) expected_commands = [('iscsiadm', '-m', 'node', '-T', self.iqn, '-p', self.location), ('iscsiadm', '-m', 'node', '-T', self.iqn, '-p', self.location, '--login'), ('iscsiadm', '-m', 'node', '-T', self.iqn, '-p', self.location, '--op', 'update', connection_info = self.sheepdog_connection(self.vol) conf = libvirt_driver.connect_volume(connection_info, self.disk_info) self.assertEqual(tree.find('./source').get('name'), self.name) connection_info = self.rbd_connection(self.vol) conf = libvirt_driver.connect_volume(connection_info, self.disk_info) self._assertNetworkAndProtocolEquals(tree) connection_info = self.rbd_connection(self.vol) conf = libvirt_driver.connect_volume(connection_info, self.disk_info) self._assertNetworkAndProtocolEquals(tree) connection_info = self.rbd_connection(self.vol) connection_info['data']['auth_username'] = self.user connection_info['data']['secret_uuid'] = self.uuid conf = libvirt_driver.connect_volume(connection_info, self.disk_info) self._assertNetworkAndProtocolEquals(tree) self.assertEqual(tree.find('./auth').get('username'), self.user) self.assertEqual(tree.find('./auth/secret').get('uuid'), self.uuid) connection_info = self.rbd_connection(self.vol) connection_info['data']['auth_username'] = self.user connection_info['data']['secret_uuid'] = self.uuid conf = libvirt_driver.connect_volume(connection_info, self.disk_info) self._assertNetworkAndProtocolEquals(tree) connection_info = self.rbd_connection(self.vol) connection_info['data']['auth_username'] = self.user connection_info['data']['secret_uuid'] = self.uuid conf = libvirt_driver.connect_volume(connection_info, self.disk_info) self._assertNetworkAndProtocolEquals(tree) connection_info = self.rbd_connection(self.vol) connection_info['data']['auth_username'] = self.user connection_info['data']['secret_uuid'] = self.uuid conf = libvirt_driver.connect_volume(connection_info, self.disk_info) self._assertNetworkAndProtocolEquals(tree) connection_info = self.iscsi_connection(self.vol, self.location, self.iqn) conf = libvirt_driver.connect_volume(connection_info, self.disk_info) dev_str = '/dev/disk/by-path/ip-%s-iscsi-%s-lun-1' % (self.location, self.iqn) connection_info = self.iscsi_connection(self.vol, self.location, self.iqn) conf = libvirt_driver.connect_volume(connection_info, self.disk_info) dev0 = '/dev/disk/by-path/ip-%s-iscsi-%s-lun-0' % (self.location, iqn0) dev = '/dev/disk/by-path/ip-%s-iscsi-%s-lun-1' % (self.location, self.iqn) connection_info = self.iscsi_connection(self.vol, self.location, self.iqn) conf = libvirt_driver.connect_volume(connection_info, self.disk_info) file_path = os.path.join(export_mnt_base, self.name) connection_info = {'data': {'export': export_string, 'name': self.name}} conf = libvirt_driver.connect_volume(connection_info, self.disk_info) self._assertFileTypeEquals(tree, file_path) file_path = os.path.join(export_mnt_base, self.name) 'name': self.name, conf = libvirt_driver.connect_volume(connection_info, self.disk_info) self._assertFileTypeEquals(tree, file_path) conf = libvirt_driver.connect_volume(connection_info, self.disk_info) file_path = os.path.join(export_mnt_base, self.name) connection_info = {'data': {'export': export_string, 'name': self.name}} conf = libvirt_driver.connect_volume(connection_info, self.disk_info) self._assertFileTypeEquals(tree, file_path) file_path = os.path.join(export_mnt_base, self.name) 'name': self.name, conf = libvirt_driver.connect_volume(connection_info, self.disk_info) self._assertFileTypeEquals(tree, file_path) connection_info = self.fibrechan_connection(self.vol, self.location, wwn) conf = libvirt_driver.connect_volume(connection_info, self.disk_info) connection_info, self.disk_info) connection_info, self.disk_info) conf = driver.connect_volume(TEST_CONN_INFO, self.disk_info) self._assertFileTypeEquals(tree, TEST_VOLPATH)"," def test_libvirt_volume_driver_serial(self): libvirt_driver = volume.LibvirtVolumeDriver(self.fake_conn) name = 'volume-00000001' vol = {'id': 1, 'name': name} connection_info = { 'driver_volume_type': 'fake', 'data': { 'device_path': '/foo', }, 'serial': 'fake_serial', } disk_info = { } conf = libvirt_driver.connect_volume(connection_info, disk_info) location = '10.0.2.15:3260' name = 'volume-00000001' iqn = 'iqn.2010-10.org.openstack:%s' % name vol = {'id': 1, 'name': name} connection_info = self.iscsi_connection(vol, location, iqn) disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) dev_str = '/dev/disk/by-path/ip-%s-iscsi-%s-lun-1' % (location, iqn) expected_commands = [('iscsiadm', '-m', 'node', '-T', iqn, '-p', location), ('iscsiadm', '-m', 'node', '-T', iqn, '-p', location, '--login'), ('iscsiadm', '-m', 'node', '-T', iqn, '-p', location, '--op', 'update', ('iscsiadm', '-m', 'node', '-T', iqn, '-p', location, '--op', 'update', ('iscsiadm', '-m', 'node', '-T', iqn, '-p', location, '--logout'), ('iscsiadm', '-m', 'node', '-T', iqn, '-p', location, '--op', 'delete')] location = '10.0.2.15:3260' name = 'volume-00000001' iqn = 'iqn.2010-10.org.openstack:%s' % name devs = ['/dev/disk/by-path/ip-%s-iscsi-%s-lun-1' % (location, iqn)] vol = {'id': 1, 'name': name} connection_info = self.iscsi_connection(vol, location, iqn) disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) dev_str = '/dev/disk/by-path/ip-%s-iscsi-%s-lun-1' % (location, iqn) expected_commands = [('iscsiadm', '-m', 'node', '-T', iqn, '-p', location), ('iscsiadm', '-m', 'node', '-T', iqn, '-p', location, '--login'), ('iscsiadm', '-m', 'node', '-T', iqn, '-p', location, '--op', 'update', name = 'volume-00000001' vol = {'id': 1, 'name': name} connection_info = self.sheepdog_connection(vol) disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) self.assertEqual(tree.find('./source').get('name'), name) name = 'volume-00000001' vol = {'id': 1, 'name': name} connection_info = self.rbd_connection(vol) disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) self.assertEqual(tree.get('type'), 'network') self.assertEqual(tree.find('./source').get('protocol'), 'rbd') rbd_name = '%s/%s' % ('rbd', name) self.assertEqual(tree.find('./source').get('name'), rbd_name) name = 'volume-00000001' vol = {'id': 1, 'name': name} connection_info = self.rbd_connection(vol) disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) self.assertEqual(tree.get('type'), 'network') self.assertEqual(tree.find('./source').get('protocol'), 'rbd') rbd_name = '%s/%s' % ('rbd', name) self.assertEqual(tree.find('./source').get('name'), rbd_name) name = 'volume-00000001' vol = {'id': 1, 'name': name} connection_info = self.rbd_connection(vol) uuid = '875a8070-d0b9-4949-8b31-104d125c9a64' user = 'foo' connection_info['data']['auth_username'] = user connection_info['data']['secret_uuid'] = uuid disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) self.assertEqual(tree.get('type'), 'network') self.assertEqual(tree.find('./source').get('protocol'), 'rbd') rbd_name = '%s/%s' % ('rbd', name) self.assertEqual(tree.find('./source').get('name'), rbd_name) self.assertEqual(tree.find('./auth').get('username'), user) self.assertEqual(tree.find('./auth/secret').get('uuid'), uuid) name = 'volume-00000001' vol = {'id': 1, 'name': name} connection_info = self.rbd_connection(vol) uuid = '875a8070-d0b9-4949-8b31-104d125c9a64' user = 'foo' connection_info['data']['auth_username'] = user connection_info['data']['secret_uuid'] = uuid disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) self.assertEqual(tree.get('type'), 'network') self.assertEqual(tree.find('./source').get('protocol'), 'rbd') rbd_name = '%s/%s' % ('rbd', name) self.assertEqual(tree.find('./source').get('name'), rbd_name) name = 'volume-00000001' vol = {'id': 1, 'name': name} connection_info = self.rbd_connection(vol) uuid = '875a8070-d0b9-4949-8b31-104d125c9a64' user = 'foo' connection_info['data']['auth_username'] = user connection_info['data']['secret_uuid'] = uuid disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) self.assertEqual(tree.get('type'), 'network') self.assertEqual(tree.find('./source').get('protocol'), 'rbd') rbd_name = '%s/%s' % ('rbd', name) self.assertEqual(tree.find('./source').get('name'), rbd_name) name = 'volume-00000001' vol = {'id': 1, 'name': name} connection_info = self.rbd_connection(vol) uuid = '875a8070-d0b9-4949-8b31-104d125c9a64' user = 'foo' connection_info['data']['auth_username'] = user connection_info['data']['secret_uuid'] = uuid disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) self.assertEqual(tree.get('type'), 'network') self.assertEqual(tree.find('./source').get('protocol'), 'rbd') rbd_name = '%s/%s' % ('rbd', name) self.assertEqual(tree.find('./source').get('name'), rbd_name) name = 'volume-00000001' location = '10.0.2.15:3260' iqn = 'iqn.2010-10.org.openstack:%s' % name vol = {'id': 1, 'name': name} connection_info = self.iscsi_connection(vol, location, iqn) disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) dev_str = '/dev/disk/by-path/ip-%s-iscsi-%s-lun-1' % (location, iqn) name = 'volume-00000001' location = '10.0.2.15:3260' iqn = 'iqn.2010-10.org.openstack:%s' % name vol = {'id': 1, 'name': name} connection_info = self.iscsi_connection(vol, location, iqn) disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) location0 = '10.0.2.15:3260' vol0 = {'id': 0, 'name': name0} dev0 = '/dev/disk/by-path/ip-%s-iscsi-%s-lun-0' % (location0, iqn0) name = 'volume-00000001' location = '10.0.2.15:3260' iqn = 'iqn.2010-10.org.openstack:%s' % name vol = {'id': 1, 'name': name} dev = '/dev/disk/by-path/ip-%s-iscsi-%s-lun-1' % (location, iqn) connection_info = self.iscsi_connection(vol, location, iqn) disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) name = 'volume-00001' file_path = os.path.join(export_mnt_base, name) connection_info = {'data': {'export': export_string, 'name': name}} disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) self.assertEqual(tree.get('type'), 'file') self.assertEqual(tree.find('./source').get('file'), file_path) name = 'volume-00001' file_path = os.path.join(export_mnt_base, name) 'name': name, disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) self.assertEqual(tree.get('type'), 'file') self.assertEqual(tree.find('./source').get('file'), file_path) disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) name = 'volume-00001' file_path = os.path.join(export_mnt_base, name) connection_info = {'data': {'export': export_string, 'name': name}} disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) self.assertEqual(tree.get('type'), 'file') self.assertEqual(tree.find('./source').get('file'), file_path) name = 'volume-00001' file_path = os.path.join(export_mnt_base, name) 'name': name, disk_info = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = libvirt_driver.connect_volume(connection_info, disk_info) self.assertEqual(tree.get('type'), 'file') self.assertEqual(tree.find('./source').get('file'), file_path) location = '10.0.2.15:3260' name = 'volume-00000001' vol = {'id': 1, 'name': name} connection_info = self.fibrechan_connection(vol, location, wwn) disk_info = { ""bus"": ""virtio"", ""dev"": mount_device, ""type"": ""disk"" } conf = libvirt_driver.connect_volume(connection_info, disk_info) connection_info, disk_info) connection_info, disk_info) TEST_DISK_INFO = { ""bus"": ""virtio"", ""dev"": ""vde"", ""type"": ""disk"", } conf = driver.connect_volume(TEST_CONN_INFO, TEST_DISK_INFO) self.assertEqual(tree.get('type'), 'file') self.assertEqual(tree.find('./source').get('file'), TEST_VOLPATH)",130,275
openstack%2Frequirements~master~I265b35def7cdd20c2d1c1040b7fb788c2f2a3e8f,openstack/requirements,master,I265b35def7cdd20c2d1c1040b7fb788c2f2a3e8f,Add lesscpy>=0.9h,MERGED,2013-07-18 09:30:54.000000000,2013-07-24 09:06:43.000000000,2013-07-24 09:06:43.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2592}, {'_account_id': 4375}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-07-18 09:30:54.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/479cf1d25e6ef1d288c71f44895e52bc3aadfdd0', 'message': ""Add lesscpy>=0.9h\n\nA prereq to drop horizon's less.js (and thus NodeJS) dependency for\ncompiling static assets.\n\nSee https://review.openstack.org/#/c/37473/\n\nChange-Id: I265b35def7cdd20c2d1c1040b7fb788c2f2a3e8f\n""}]",0,37649,479cf1d25e6ef1d288c71f44895e52bc3aadfdd0,9,6,1,4375,,,0,"Add lesscpy>=0.9h

A prereq to drop horizon's less.js (and thus NodeJS) dependency for
compiling static assets.

See https://review.openstack.org/#/c/37473/

Change-Id: I265b35def7cdd20c2d1c1040b7fb788c2f2a3e8f
",git fetch https://review.opendev.org/openstack/requirements refs/changes/49/37649/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,479cf1d25e6ef1d288c71f44895e52bc3aadfdd0,master,lesscpy>=0.9h,,1,0
openstack%2Fsahara~master~I64318b5c745074741a197a5ef1940bae900f6358,openstack/sahara,master,I64318b5c745074741a197a5ef1940bae900f6358,Image Registry tags validation,MERGED,2013-07-18 13:11:28.000000000,2013-07-24 09:00:48.000000000,2013-07-24 09:00:48.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7478}, {'_account_id': 7729}]","[{'number': 1, 'created': '2013-07-18 13:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0850f864b0a4643b6fd4b868aa889cfc6e93a5f2', 'message': 'Image Registry tags validation\n\nFixes: bug #1200199\n\nChange-Id: I64318b5c745074741a197a5ef1940bae900f6358\n'}, {'number': 2, 'created': '2013-07-22 12:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/07e525667325fbb3314fa1a9ee59ecb8d5e96b40', 'message': 'Image Registry tags validation\n\nFixes: bug #1200199\n\nChange-Id: I64318b5c745074741a197a5ef1940bae900f6358\n'}, {'number': 3, 'created': '2013-07-22 13:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/70a7d4543de0a394ad7e769709a312a60e23818d', 'message': ""Image Registry tags validation\n\nNew format 'valid_tag' was added to jsonschema and tags check to match 'valid_tag'\nAdded UT for this.\n\nFixes: bug #1200199\n\nChange-Id: I64318b5c745074741a197a5ef1940bae900f6358\n""}, {'number': 4, 'created': '2013-07-24 07:30:21.000000000', 'files': ['savanna/service/validations/images.py', 'savanna/utils/api_validator.py', 'savanna/tests/unit/service/validation/test_add_tags_validation.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4bb456933bec9e5e0fd9678ae6fc5509f6716cc3', 'message': ""Image Registry tags validation\n\nNew format 'valid_tag' was added to jsonschema and tags check to match 'valid_tag'\nAdded UT for this.\n\nFixes: bug #1200199\n\nChange-Id: I64318b5c745074741a197a5ef1940bae900f6358\n""}]",3,37676,4bb456933bec9e5e0fd9678ae6fc5509f6716cc3,27,6,4,7729,,,0,"Image Registry tags validation

New format 'valid_tag' was added to jsonschema and tags check to match 'valid_tag'
Added UT for this.

Fixes: bug #1200199

Change-Id: I64318b5c745074741a197a5ef1940bae900f6358
",git fetch https://review.opendev.org/openstack/sahara refs/changes/76/37676/4 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/service/validations/images.py', 'savanna/utils/api_validator.py', 'savanna/tests/unit/service/validation/test_add_tags_validation.py']",3,0850f864b0a4643b6fd4b868aa889cfc6e93a5f2,bug/1200199,"# Copyright (c) 2013 Mirantis Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from savanna.service.validations import images as im from savanna.tests.unit.service.validation import utils as u class TestTagsAddingValidation(u.ValidationTestCase): def test_add_tags_validation(self): self._create_object_fun = im.check_tags scheme = im.image_tags_schema right_tags = ['1', 'a', 'a_1', 'a.2', 'a.A', 'a-A'] wrong_tags = ['a.', '_a', 'a..a'] wrong_symbols = ""!@#$%^&*,"" data = { 'tags': [] } for tag in right_tags: data[""tags""] = [tag] self._assert_create_object_validation( scheme=scheme, data=data) for tag in wrong_tags: data[""tags""] = [tag] self._assert_create_object_validation( scheme=scheme, data=data, bad_req_i=(1, 'VALIDATION_ERROR', u""'%s' is not a 'valid_tag'"" % tag)) for symb in wrong_symbols: tag = ""a%sa"" % symb data['tags'] = [tag] self._assert_create_object_validation( scheme=scheme, data=data, bad_req_i=(1, 'VALIDATION_ERROR', u""'%s' is not a 'valid_tag'"" % tag)) ",,59,0
openstack%2Fceilometer~master~I1dd3b5aabe5221a37903a4e87de64702aec94ad2,openstack/ceilometer,master,I1dd3b5aabe5221a37903a4e87de64702aec94ad2,Implementation of the alarm RPCAlarmNotifier,MERGED,2013-07-19 08:32:21.000000000,2013-07-24 08:45:21.000000000,2013-07-24 08:45:21.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 4491}]","[{'number': 1, 'created': '2013-07-19 08:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a89ee119db95c8744f970e7a5afcc0f48864e5b3', 'message': 'Implementation of the alarm RPCNotifier\n\nThis change implement the alarm RPCNotifier to allow\nthe threshold-evaluator to communicate with the notifier\n\nChange-Id: I1dd3b5aabe5221a37903a4e87de64702aec94ad2\n'}, {'number': 2, 'created': '2013-07-19 08:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/38a77d1878686ea3ddc78e831cdf8982eab8efe5', 'message': 'Implementation of the alarm RPCAlarmNotifier\n\nThis change implement the RPCAlarmNotifier to allow\nthe threshold-evaluator to communicate with the notifier.\n\nChange-Id: I1dd3b5aabe5221a37903a4e87de64702aec94ad2\n'}, {'number': 3, 'created': '2013-07-22 07:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5161d69ce0698996437a8ac57119befa191be2f1', 'message': 'Implementation of the alarm RPCAlarmNotifier\n\nThis change implement the RPCAlarmNotifier to allow\nthe threshold-evaluator to communicate with the notifier.\n\nChange-Id: I1dd3b5aabe5221a37903a4e87de64702aec94ad2\n'}, {'number': 4, 'created': '2013-07-22 16:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9950a5719852327b35d635ed14c2f3ced941e0ad', 'message': 'Implementation of the alarm RPCAlarmNotifier\n\nThis change implement the RPCAlarmNotifier to allow\nthe threshold-evaluator to communicate with the notifier.\n\nChange-Id: I1dd3b5aabe5221a37903a4e87de64702aec94ad2\n'}, {'number': 5, 'created': '2013-07-23 06:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6cd186aa3000e45a0206bf4835afc0213359baa1', 'message': 'Implementation of the alarm RPCAlarmNotifier\n\nThis change implement the RPCAlarmNotifier to allow\nthe threshold-evaluator to communicate with the notifier.\n\nChange-Id: I1dd3b5aabe5221a37903a4e87de64702aec94ad2\n'}, {'number': 6, 'created': '2013-07-24 07:52:35.000000000', 'files': ['tests/alarm/test_notifier.py', 'tests/alarm/test_rpc.py', 'ceilometer/storage/models.py', 'ceilometer/alarm/service.py', 'etc/ceilometer/ceilometer.conf.sample', 'ceilometer/alarm/rpc.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/88b4cf0812f29ea93a475797c07cfd04de84564d', 'message': 'Implementation of the alarm RPCAlarmNotifier\n\nThis change implement the RPCAlarmNotifier to allow\nthe threshold-evaluator to communicate with the notifier.\n\nChange-Id: I1dd3b5aabe5221a37903a4e87de64702aec94ad2\n'}]",8,37852,88b4cf0812f29ea93a475797c07cfd04de84564d,25,5,6,2813,,,0,"Implementation of the alarm RPCAlarmNotifier

This change implement the RPCAlarmNotifier to allow
the threshold-evaluator to communicate with the notifier.

Change-Id: I1dd3b5aabe5221a37903a4e87de64702aec94ad2
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/52/37852/5 && git format-patch -1 --stdout FETCH_HEAD,"['tests/alarm/test_notifier.py', 'ceilometer/storage/models.py', 'ceilometer/alarm/service.py', 'etc/ceilometer/ceilometer.conf.sample']",4,a89ee119db95c8744f970e7a5afcc0f48864e5b3,sileht/rpcnotifier,# the topic ceilometer uses for alarm notifier messages # (string value) #notifier_rpc_topic=alarm_notifier # Total option count: 128,# Total option count: 127,113,1
openstack%2Fnova~master~I62f7d6cf7bc950fe06eb42fabd6f3db5bd8f3543,openstack/nova,master,I62f7d6cf7bc950fe06eb42fabd6f3db5bd8f3543,Increase default OS_TEST_TIMEOUT value.,ABANDONED,2013-07-16 16:39:40.000000000,2013-07-24 08:01:10.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-07-16 16:39:40.000000000', 'files': ['.testr.conf'], 'web_link': 'https://opendev.org/openstack/nova/commit/96499344406e7657915c520fb2a5ad2a9762608b', 'message': 'Increase default OS_TEST_TIMEOUT value.\n\nThere are large amount of migration scripts in Nova.\nThis is why migrations tests (espetially on postgresql or mysql) failed\nwith `TimeoutException`.\nWe increased default timeout value from 60 to 120 seconds to fix it.\n\nFixes bug 1200289\n\nChange-Id: I62f7d6cf7bc950fe06eb42fabd6f3db5bd8f3543\n'}]",0,37284,96499344406e7657915c520fb2a5ad2a9762608b,5,3,1,7491,,,0,"Increase default OS_TEST_TIMEOUT value.

There are large amount of migration scripts in Nova.
This is why migrations tests (espetially on postgresql or mysql) failed
with `TimeoutException`.
We increased default timeout value from 60 to 120 seconds to fix it.

Fixes bug 1200289

Change-Id: I62f7d6cf7bc950fe06eb42fabd6f3db5bd8f3543
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/37284/1 && git format-patch -1 --stdout FETCH_HEAD,['.testr.conf'],1,96499344406e7657915c520fb2a5ad2a9762608b,bug/1200289, OS_TEST_TIMEOUT=${OS_TEST_TIMEOUT:-120} \, OS_TEST_TIMEOUT=${OS_TEST_TIMEOUT:-60} \,1,1
openstack%2Fheat~master~I6733be7c13e2e9fdbed27d5c21044fb5f457ed17,openstack/heat,master,I6733be7c13e2e9fdbed27d5c21044fb5f457ed17,HOT parameter validation model translation,MERGED,2013-07-23 06:33:32.000000000,2013-07-24 07:58:29.000000000,2013-07-24 07:58:28.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6434}, {'_account_id': 6602}, {'_account_id': 7090}, {'_account_id': 7193}, {'_account_id': 7761}]","[{'number': 1, 'created': '2013-07-23 06:33:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6e8ad2c45a592cfe35eb6c619d6d45cca38839b7', 'message': 'HOT parameter validation model translation\n\nTranslate hot parameters into heat parameter model.\n\nChange-Id: I6733be7c13e2e9fdbed27d5c21044fb5f457ed17\nImplements: blueprint hot-parameters\n'}, {'number': 2, 'created': '2013-07-23 08:27:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/71a4a0f53502fb2bda6e921fc5fed4b9b1ce11d6', 'message': 'HOT parameter validation model translation\n\nTranslate hot parameters into heat parameter model.\n\nChange-Id: I6733be7c13e2e9fdbed27d5c21044fb5f457ed17\nImplements: blueprint hot-parameters\n'}, {'number': 3, 'created': '2013-07-23 10:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a2f5c1538bfde22bc237d608b08afb730e05df15', 'message': 'HOT parameter validation model translation\n\nTranslate hot parameters into heat parameter model.\n\nChange-Id: I6733be7c13e2e9fdbed27d5c21044fb5f457ed17\nImplements: blueprint hot-parameters\n'}, {'number': 4, 'created': '2013-07-24 01:56:39.000000000', 'files': ['heat/engine/hot.py', 'heat/tests/test_hot.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/929c9edd5c46f2c9cb7c48bc8b2b9b0ee64df594', 'message': 'HOT parameter validation model translation\n\nTranslate hot parameters into heat parameter model.\n\nChange-Id: I6733be7c13e2e9fdbed27d5c21044fb5f457ed17\nImplements: blueprint hot-parameters\n'}]",2,38254,929c9edd5c46f2c9cb7c48bc8b2b9b0ee64df594,14,9,4,7761,,,0,"HOT parameter validation model translation

Translate hot parameters into heat parameter model.

Change-Id: I6733be7c13e2e9fdbed27d5c21044fb5f457ed17
Implements: blueprint hot-parameters
",git fetch https://review.opendev.org/openstack/heat refs/changes/54/38254/4 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/hot.py', 'heat/tests/test_hot.py']",2,6e8ad2c45a592cfe35eb6c619d6d45cca38839b7,bp/hot-parameters," 'Type': 'UnsupportedType'}} def test_translate_parameters_length_range(self): hot_tpl = template_format.parse(''' heat_template_version: 2013-05-23 parameters: wait_time: description: application wait time type: number default: 150 constraints: - range: { min: 120, max: 600} description: min value 120 seconds, max value 600 seconds key_name: description: Name of an existing EC2 KeyPair type: string default: heat_key constraints: - length: {min: 1, max: 32} description: length should be between 1 and 32 ''') expected = { 'wait_time': { 'Description': 'application wait time', 'Type': 'Number', 'Default': 150, 'MaxValue': [(600, 'min value 120 seconds, max value 600 seconds')], 'MinValue': [(120, 'min value 120 seconds, max value 600 seconds')] }, 'key_name': { 'Description': 'Name of an existing EC2 KeyPair', 'Type': 'String', 'Default': 'heat_key', 'MaxLength': [(32, u'length should be between 1 and 32')], 'MinLength': [(1, u'length should be between 1 and 32')] }} tmpl = parser.Template(hot_tpl) self.assertEqual(expected, tmpl[hot.PARAMETERS]) def test_translate_parameters_allowed_values(self): hot_tpl = template_format.parse(''' heat_template_version: 2013-05-23 parameters: instance_type: description: instance type type: string default: m1.small constraints: - allowed_values: [""m1.tiny"", ""m1.small"", ""m1.medium"", ""m1.large"", ""m1.xlarge""] description: must be a valid EC2 instance type. ''') expected = { 'instance_type': { 'Description': 'instance type', 'Type': 'String', 'Default': 'm1.small', 'AllowedValues': [([""m1.tiny"", ""m1.small"", ""m1.medium"", ""m1.large"", ""m1.xlarge""], 'must be a valid EC2 instance type.')]}} tmpl = parser.Template(hot_tpl) self.assertEqual(expected, tmpl[hot.PARAMETERS]) def test_translate_parameters_allowed_patterns(self): hot_tpl = template_format.parse(''' heat_template_version: 2013-05-23 parameters: db_name: description: The WordPress database name type: string default: wordpress constraints: - length: { min: 1, max: 64 } description: string lenght should between 1 and 64 - allowed_pattern: ""[a-zA-Z]+"" description: Value must consist of characters only - allowed_pattern: ""[a-z]+[a-zA-Z]*"" description: Value must start with a lowercase character ''') expected = { 'db_name': { 'Description': 'The WordPress database name', 'Type': 'String', 'Default': 'wordpress', 'MinLength': [(1, 'string lenght should between 1 and 64')], 'MaxLength': [(64, 'string lenght should between 1 and 64')], 'AllowedPattern': [ ('[a-zA-Z]+', 'Value must consist of characters only'), ('[a-z]+[a-zA-Z]*', 'Value must start with a lowercase character')]}} tmpl = parser.Template(hot_tpl) self.assertEqual(expected, tmpl[hot.PARAMETERS]) def test_translate_parameters_hidden(self): hot_tpl = template_format.parse(''' heat_template_version: 2013-05-23 parameters: user_roles: description: User roles type: comma_delimited_list default: guest,newhire hidden: TRUE ''') expected = { 'user_roles': { 'Description': 'User roles', 'Type': 'CommaDelimitedList', 'Default': 'guest,newhire', 'NoEcho': True }} tmpl = parser.Template(hot_tpl) self.assertEqual(expected, tmpl[hot.PARAMETERS]) ", 'Type': 'unsupported_type'}},176,28
openstack%2Fglance~master~Ia7f289e15615ef31865ebfd23902aa1ae1b05d66,openstack/glance,master,Ia7f289e15615ef31865ebfd23902aa1ae1b05d66,Fix cache delete-all-queued-images for xattr,MERGED,2013-07-03 13:18:50.000000000,2013-07-24 07:49:24.000000000,2013-07-24 07:49:24.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 1390}, {'_account_id': 2166}, {'_account_id': 6159}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-07-03 13:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fce62816fc0602528b762f5a636ec5278090e216', 'message': ""Fix cache delete-all-queued-images for xattr\n\nDeleting all queued images was broken when using caching with the xattr\ndriver, due to a missing get_cache_files function.\n\nAdd this from the sqlite driver, removing the check for db_path which\nisn't applicable to xattr.\n\nFixes bug 1197402\n\nChange-Id: Ia7f289e15615ef31865ebfd23902aa1ae1b05d66\n""}, {'number': 2, 'created': '2013-07-08 16:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d989928421aaaf4e173d9ebf121a381e7c458b18', 'message': 'Fix cache delete-all-queued-images for xattr\n\nDeleting all queued images was broken when using caching with the xattr\ndriver, due to a missing get_cache_files function.\n\nThe missing function can be satisfied by substituting the call to\nget_cache_files() with get_all_regular_files()\n\nFixes bug 1197402\n\nChange-Id: Ia7f289e15615ef31865ebfd23902aa1ae1b05d66\n'}, {'number': 3, 'created': '2013-07-08 17:08:23.000000000', 'files': ['glance/tests/functional/test_cache_middleware.py', 'glance/image_cache/drivers/xattr.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/7e844389c5adbb3d23505b3b52ced9a175b22d1a', 'message': 'Fix cache delete-all-queued-images for xattr\n\nDeleting all queued images was broken when using caching with the xattr\ndriver, due to a missing get_cache_files function.\n\nThe missing function can be satisfied by substituting the call to\nget_cache_files() with get_all_regular_files()\n\nFixes bug 1197402\n\nChange-Id: Ia7f289e15615ef31865ebfd23902aa1ae1b05d66\n'}]",1,35482,7e844389c5adbb3d23505b3b52ced9a175b22d1a,16,6,3,1390,,,0,"Fix cache delete-all-queued-images for xattr

Deleting all queued images was broken when using caching with the xattr
driver, due to a missing get_cache_files function.

The missing function can be satisfied by substituting the call to
get_cache_files() with get_all_regular_files()

Fixes bug 1197402

Change-Id: Ia7f289e15615ef31865ebfd23902aa1ae1b05d66
",git fetch https://review.opendev.org/openstack/glance refs/changes/82/35482/3 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/functional/test_cache_middleware.py', 'glance/image_cache/drivers/xattr.py']",2,fce62816fc0602528b762f5a636ec5278090e216,bug/1197402," def get_cache_files(self, basepath): """""" Returns cache files in the supplied directory :param basepath: Directory to look in for cache files """""" for fname in os.listdir(basepath): path = os.path.join(basepath, fname) if os.path.isfile(path): yield path ",,58,0
openstack%2Frequirements~master~Icc96bea4810bc38ea34e07aed8398ac748bdb922,openstack/requirements,master,Icc96bea4810bc38ea34e07aed8398ac748bdb922,Raise psutil requirement,ABANDONED,2013-07-24 06:17:42.000000000,2013-07-24 07:32:03.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-07-24 06:17:42.000000000', 'files': ['requirement.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/851dcfdb9982429610a18e66d4e3edfc66b88d97', 'message': ""Raise psutil requirement\n\nPsutil API need use new 'require' condition for users to get network information.\n\nRaise psutil requirement to >=0.6.1,<1.0\n\nChange-Id: Icc96bea4810bc38ea34e07aed8398ac748bdb922\n""}]",0,38420,851dcfdb9982429610a18e66d4e3edfc66b88d97,2,1,1,8009,,,0,"Raise psutil requirement

Psutil API need use new 'require' condition for users to get network information.

Raise psutil requirement to >=0.6.1,<1.0

Change-Id: Icc96bea4810bc38ea34e07aed8398ac748bdb922
",git fetch https://review.opendev.org/openstack/requirements refs/changes/20/38420/1 && git format-patch -1 --stdout FETCH_HEAD,['requirement.txt'],1,851dcfdb9982429610a18e66d4e3edfc66b88d97,bp/ubs,,,0,0
openstack%2Frequirements~master~Ie5cee8576a3486026304231c406119357f24f7f2,openstack/requirements,master,Ie5cee8576a3486026304231c406119357f24f7f2,Raise psutil requirement,ABANDONED,2013-07-23 07:06:21.000000000,2013-07-24 07:31:51.000000000,,"[{'_account_id': 3}, {'_account_id': 8009}]","[{'number': 1, 'created': '2013-07-23 07:06:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/43ad7e60179e3f9337ded71e616652d663038176', 'message': ""Raise psutil requirement\n\nPsutil API need use new 'require' condition for users to get network information.\n\nRaise psutil requirement to >=0.6.1,<1.0\n\nChange-Id: Ie5cee8576a3486026304231c406119357f24f7f2\n""}, {'number': 2, 'created': '2013-07-24 05:49:44.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/90ac8ab5bc0a41497acbb2380624c560f952cc78', 'message': ""Raise psutil requirement\n\nPsutil API need use new 'require' condition for users to get network information.\n\nRaise psutil requirement to >=0.6.1,<1.0\n\nChange-Id: Ie5cee8576a3486026304231c406119357f24f7f2\n""}]",0,38258,90ac8ab5bc0a41497acbb2380624c560f952cc78,4,2,2,8009,,,0,"Raise psutil requirement

Psutil API need use new 'require' condition for users to get network information.

Raise psutil requirement to >=0.6.1,<1.0

Change-Id: Ie5cee8576a3486026304231c406119357f24f7f2
",git fetch https://review.opendev.org/openstack/requirements refs/changes/58/38258/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,43ad7e60179e3f9337ded71e616652d663038176,bp/ubs,"psutil>=0.6.1,<1.0",psutil<1.0,1,1
openstack%2Foslo.messaging~master~I18115e9dd5241b1bdfae14671a62328c47125400,openstack/oslo.messaging,master,I18115e9dd5241b1bdfae14671a62328c47125400,Don't register options with cfg.CONF at module import,MERGED,2013-07-23 17:38:21.000000000,2013-07-24 07:18:37.000000000,2013-07-24 07:18:37.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1994}, {'_account_id': 6159}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-07-23 17:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/b3b692548e92076f56fdca8afd5ec308eebf501e', 'message': ""Don't register options with cfg.CONF at module import\n\noslo.messaging will only register options with a ConfigOpts object\nsupplied by the caller.\n\nChange-Id: I18115e9dd5241b1bdfae14671a62328c47125400\n""}, {'number': 2, 'created': '2013-07-24 07:15:44.000000000', 'files': ['oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/amqp.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/37bd6923dc235c3b67c0f6cd0479df12d9aad5f0', 'message': ""Don't register options with cfg.CONF at module import\n\noslo.messaging will only register options with a ConfigOpts object\nsupplied by the caller.\n\nChange-Id: I18115e9dd5241b1bdfae14671a62328c47125400\n""}]",0,38333,37bd6923dc235c3b67c0f6cd0479df12d9aad5f0,15,5,2,1247,,,0,"Don't register options with cfg.CONF at module import

oslo.messaging will only register options with a ConfigOpts object
supplied by the caller.

Change-Id: I18115e9dd5241b1bdfae14671a62328c47125400
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/33/38333/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/amqp.py']",3,b3b692548e92076f56fdca8afd5ec308eebf501e,,,cfg.CONF.register_opts(amqp_opts) ,0,6
openstack%2Foslo.messaging~master~I3581eff3427858c8f46673e4a3c376367c626bb3,openstack/oslo.messaging,master,I3581eff3427858c8f46673e4a3c376367c626bb3,Adjust imports in rabbit/qpid drivers,MERGED,2013-07-23 17:38:21.000000000,2013-07-24 07:18:07.000000000,2013-07-24 07:18:07.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1994}, {'_account_id': 6159}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-07-23 17:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/03b03ede9bbacd468ee7f12560a935886bb230f6', 'message': 'Adjust imports in rabbit/qpid drivers\n\nSome modules are in oslo.messaging.openstack.common and others are in\noslo.messaging._drivers.\n\nChange-Id: I3581eff3427858c8f46673e4a3c376367c626bb3\n'}, {'number': 2, 'created': '2013-07-24 07:15:44.000000000', 'files': ['oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/common.py', 'oslo/messaging/_drivers/amqp.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/04dd4e177331ede7d7859a88a8418727818a44ba', 'message': 'Adjust imports in rabbit/qpid drivers\n\nSome modules are in oslo.messaging.openstack.common and others are in\noslo.messaging._drivers.\n\nChange-Id: I3581eff3427858c8f46673e4a3c376367c626bb3\n'}]",0,38332,04dd4e177331ede7d7859a88a8418727818a44ba,16,5,2,1247,,,0,"Adjust imports in rabbit/qpid drivers

Some modules are in oslo.messaging.openstack.common and others are in
oslo.messaging._drivers.

Change-Id: I3581eff3427858c8f46673e4a3c376367c626bb3
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/32/38332/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/common.py', 'oslo/messaging/_drivers/amqp.py']",4,03b03ede9bbacd468ee7f12560a935886bb230f6,,from oslo.messaging._drivers import common as rpc_common from oslo.messaging.openstack.common import excutils from oslo.messaging.openstack.common.gettextutils import _ # noqa from oslo.messaging.openstack.common import local from oslo.messaging.openstack.common import log as logging,from openstack.common import excutils from openstack.common.gettextutils import _ # noqa from openstack.common import local from openstack.common import log as logging from openstack.common.rpc import common as rpc_common,23,23
openstack%2Frequirements~master~I3929c1b71172935b7bee1e0399809ab32531a051,openstack/requirements,master,I3929c1b71172935b7bee1e0399809ab32531a051,Raise psutil requirement,ABANDONED,2013-07-24 06:17:42.000000000,2013-07-24 07:14:16.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-07-24 06:17:42.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/964d72c09e97e31f9710c87e6430c6f4d45c9244', 'message': ""Raise psutil requirement\n\nPsutil API need use new 'require' condition for users to get network information.\n\nRaise psutil requirement to >=0.6.1,<1.0\n\nChange-Id: I3929c1b71172935b7bee1e0399809ab32531a051\n""}]",0,38421,964d72c09e97e31f9710c87e6430c6f4d45c9244,2,1,1,8009,,,0,"Raise psutil requirement

Psutil API need use new 'require' condition for users to get network information.

Raise psutil requirement to >=0.6.1,<1.0

Change-Id: I3929c1b71172935b7bee1e0399809ab32531a051
",git fetch https://review.opendev.org/openstack/requirements refs/changes/21/38421/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,964d72c09e97e31f9710c87e6430c6f4d45c9244,bp/ubs,"alembic>=0.4.1 amqplib>=0.6.1 anyjson>=0.3.3 argparse Babel>=0.9.6 boto>=2.4.0 Cheetah>=2.4.4 cliff>=1.4 d2to1>=0.2.10,<0.3 Django>=1.4,<1.6 django_compressor>=1.3 django_openstack_auth>=1.1.0 dnspython>=1.9.4 eventlet>=0.12.0 extras Flask==0.9 greenlet>=0.3.2 happybase>=0.4 httplib2 iso8601>=0.1.4 Jinja2 jsonrpclib jsonschema>=1.0.0,!=1.4.0,<2 kazoo>=0.9,<=1.1 kombu>=2.4.8 lockfile>=0.8 lxml>=2.3 msgpack-python netaddr netifaces>=0.5 oauth2 oslo.config>=1.1.0 pam>=0.1.4 paramiko>=1.8.0 passlib Paste PasteDeploy>=1.5.0 pbr>=0.5.16,<0.6 pecan>=0.2.0 pip>=1.0 PrettyTable>=0.6,<0.8 psutil>=0.6.1,<1.0 pyasn1 pycrypto>=2.6 pymongo>=2.2 pyOpenSSL pyparsing>=1.5.7,<2.0 # OpenStack clients. None of these should have an upper bound # as that has implications for testing in the gate. An exception # is currently being made for neutron client because of the need # for an incompatible change in their next release. python-cinderclient>=1.0.4 python-ceilometerclient>=1.0.1 python-heatclient>=0.2.2 python-glanceclient>=0.9.0 python-keystoneclient>=0.3.0 python-memcached python-neutronclient>=2.2.3,<3 python-novaclient>=2.12.0 python-quantumclient>=2.2.0 python-swiftclient>=1.2 pytz>=2010h pyudev PyYAML>=3.1.0 qpid-python requests>=1.1,<1.2.3 Routes>=1.12.3 setuptools_git>=0.4 simplejson>=2.0.9 six SQLAlchemy>=0.7,<=0.7.99 sqlalchemy-migrate>=0.7 stevedore>=0.10 suds>=0.4 warlock>=0.7.0,<2 WebOb>=1.2.3,<1.3 websockify>=0.5.1,<0.6 wsgiref>=0.1.2 WSME>=0.5b2 xattr>=0.4 ",,80,0
openstack%2Foslo.messaging~master~I3674bfbc4b1c93afc746b84fbbf8859456cbcb3c,openstack/oslo.messaging,master,I3674bfbc4b1c93afc746b84fbbf8859456cbcb3c,Import some needed modules from oslo-incubator,MERGED,2013-07-23 17:38:21.000000000,2013-07-24 07:13:33.000000000,2013-07-24 07:13:33.000000000,"[{'_account_id': 3}, {'_account_id': 1994}, {'_account_id': 6159}]","[{'number': 1, 'created': '2013-07-23 17:38:21.000000000', 'files': ['oslo/messaging/openstack/common/gettextutils.py', 'oslo/messaging/openstack/common/log.py', 'oslo/messaging/openstack/common/network_utils.py', 'openstack-common.conf', 'oslo/messaging/openstack/common/sslutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/51be674f3095c88440c30ba982cba3cdc85ea85c', 'message': ""Import some needed modules from oslo-incubator\n\nSome additional modules from oslo-incubator are required by the driver\ncode. Don't fret, some of these will be removed in subsequent patches!\n\nChange-Id: I3674bfbc4b1c93afc746b84fbbf8859456cbcb3c\n""}]",0,38331,51be674f3095c88440c30ba982cba3cdc85ea85c,6,3,1,1247,,,0,"Import some needed modules from oslo-incubator

Some additional modules from oslo-incubator are required by the driver
code. Don't fret, some of these will be removed in subsequent patches!

Change-Id: I3674bfbc4b1c93afc746b84fbbf8859456cbcb3c
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/31/38331/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/openstack/common/gettextutils.py', 'oslo/messaging/openstack/common/log.py', 'oslo/messaging/openstack/common/network_utils.py', 'openstack-common.conf', 'oslo/messaging/openstack/common/sslutils.py']",5,51be674f3095c88440c30ba982cba3cdc85ea85c,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2013 IBM Corp. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os import ssl from oslo.config import cfg from oslo.messaging.openstack.common.gettextutils import _ # noqa ssl_opts = [ cfg.StrOpt('ca_file', default=None, help=""CA certificate file to use to verify "" ""connecting clients""), cfg.StrOpt('cert_file', default=None, help=""Certificate file to use when starting "" ""the server securely""), cfg.StrOpt('key_file', default=None, help=""Private key file to use when starting "" ""the server securely""), ] CONF = cfg.CONF CONF.register_opts(ssl_opts, ""ssl"") def is_enabled(): cert_file = CONF.ssl.cert_file key_file = CONF.ssl.key_file ca_file = CONF.ssl.ca_file use_ssl = cert_file or key_file if cert_file and not os.path.exists(cert_file): raise RuntimeError(_(""Unable to find cert_file : %s"") % cert_file) if ca_file and not os.path.exists(ca_file): raise RuntimeError(_(""Unable to find ca_file : %s"") % ca_file) if key_file and not os.path.exists(key_file): raise RuntimeError(_(""Unable to find key_file : %s"") % key_file) if use_ssl and (not cert_file or not key_file): raise RuntimeError(_(""When running server in SSL mode, you must "" ""specify both a cert_file and key_file "" ""option value in your configuration file"")) return use_ssl def wrap(sock): ssl_kwargs = { 'server_side': True, 'certfile': CONF.ssl.cert_file, 'keyfile': CONF.ssl.key_file, 'cert_reqs': ssl.CERT_NONE, } if CONF.ssl.ca_file: ssl_kwargs['ca_certs'] = CONF.ssl.ca_file ssl_kwargs['cert_reqs'] = ssl.CERT_REQUIRED return ssl.wrap_socket(sock, **ssl_kwargs) _SSL_PROTOCOLS = { ""tlsv1"": ssl.PROTOCOL_TLSv1, ""sslv23"": ssl.PROTOCOL_SSLv23, ""sslv3"": ssl.PROTOCOL_SSLv3 } try: _SSL_PROTOCOLS[""sslv2""] = ssl.PROTOCOL_SSLv2 except AttributeError: pass def validate_ssl_version(version): key = version.lower() try: return _SSL_PROTOCOLS[key] except KeyError: raise RuntimeError(_(""Invalid SSL version : %s"") % version) ",,1006,0
openstack%2Foslo.messaging~master~I38507382b1ce68c7f8f697522f9a1bf00e76532d,openstack/oslo.messaging,master,I38507382b1ce68c7f8f697522f9a1bf00e76532d,Add oslo-incubator code unmodified,MERGED,2013-07-23 17:38:21.000000000,2013-07-24 07:13:19.000000000,2013-07-24 07:13:19.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-07-23 17:38:21.000000000', 'files': ['oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/common.py', 'oslo/messaging/_drivers/amqp.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e91dbef454999a4ada980365bf1b8594207740bd', 'message': ""Add oslo-incubator code unmodified\n\nI want to make it absolutely clear what changes we're making from the\noriginal driver code, so let's start with a pristine copy.\n\nChange-Id: I38507382b1ce68c7f8f697522f9a1bf00e76532d\n""}]",0,38330,e91dbef454999a4ada980365bf1b8594207740bd,6,3,1,1247,,,0,"Add oslo-incubator code unmodified

I want to make it absolutely clear what changes we're making from the
original driver code, so let's start with a pristine copy.

Change-Id: I38507382b1ce68c7f8f697522f9a1bf00e76532d
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/30/38330/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/common.py', 'oslo/messaging/_drivers/amqp.py']",4,e91dbef454999a4ada980365bf1b8594207740bd,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2010 United States Government as represented by the # Administrator of the National Aeronautics and Space Administration. # All Rights Reserved. # Copyright 2011 - 2012, Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Shared code between AMQP based openstack.common.rpc implementations. The code in this module is shared between the rpc implemenations based on AMQP. Specifically, this includes impl_kombu and impl_qpid. impl_carrot also uses AMQP, but is deprecated and predates this code. """""" import collections import inspect import sys import uuid from eventlet import greenpool from eventlet import pools from eventlet import queue from eventlet import semaphore from oslo.config import cfg from openstack.common import excutils from openstack.common.gettextutils import _ # noqa from openstack.common import local from openstack.common import log as logging from openstack.common.rpc import common as rpc_common amqp_opts = [ cfg.BoolOpt('amqp_durable_queues', default=False, deprecated_name='rabbit_durable_queues', deprecated_group='DEFAULT', help='Use durable queues in amqp.'), cfg.BoolOpt('amqp_auto_delete', default=False, help='Auto-delete queues in amqp.'), ] cfg.CONF.register_opts(amqp_opts) UNIQUE_ID = '_unique_id' LOG = logging.getLogger(__name__) class Pool(pools.Pool): """"""Class that implements a Pool of Connections."""""" def __init__(self, conf, connection_cls, *args, **kwargs): self.connection_cls = connection_cls self.conf = conf kwargs.setdefault(""max_size"", self.conf.rpc_conn_pool_size) kwargs.setdefault(""order_as_stack"", True) super(Pool, self).__init__(*args, **kwargs) self.reply_proxy = None # TODO(comstud): Timeout connections not used in a while def create(self): LOG.debug(_('Pool creating new connection')) return self.connection_cls(self.conf) def empty(self): while self.free_items: self.get().close() # Force a new connection pool to be created. # Note that this was added due to failing unit test cases. The issue # is the above ""while loop"" gets all the cached connections from the # pool and closes them, but never returns them to the pool, a pool # leak. The unit tests hang waiting for an item to be returned to the # pool. The unit tests get here via the tearDown() method. In the run # time code, it gets here via cleanup() and only appears in service.py # just before doing a sys.exit(), so cleanup() only happens once and # the leakage is not a problem. self.connection_cls.pool = None _pool_create_sem = semaphore.Semaphore() def get_connection_pool(conf, connection_cls): with _pool_create_sem: # Make sure only one thread tries to create the connection pool. if not connection_cls.pool: connection_cls.pool = Pool(conf, connection_cls) return connection_cls.pool class ConnectionContext(rpc_common.Connection): """"""The class that is actually returned to the create_connection() caller. This is essentially a wrapper around Connection that supports 'with'. It can also return a new Connection, or one from a pool. The function will also catch when an instance of this class is to be deleted. With that we can return Connections to the pool on exceptions and so forth without making the caller be responsible for catching them. If possible the function makes sure to return a connection to the pool. """""" def __init__(self, conf, connection_pool, pooled=True, server_params=None): """"""Create a new connection, or get one from the pool."""""" self.connection = None self.conf = conf self.connection_pool = connection_pool if pooled: self.connection = connection_pool.get() else: self.connection = connection_pool.connection_cls( conf, server_params=server_params) self.pooled = pooled def __enter__(self): """"""When with ConnectionContext() is used, return self."""""" return self def _done(self): """"""If the connection came from a pool, clean it up and put it back. If it did not come from a pool, close it. """""" if self.connection: if self.pooled: # Reset the connection so it's ready for the next caller # to grab from the pool self.connection.reset() self.connection_pool.put(self.connection) else: try: self.connection.close() except Exception: pass self.connection = None def __exit__(self, exc_type, exc_value, tb): """"""End of 'with' statement. We're done here."""""" self._done() def __del__(self): """"""Caller is done with this connection. Make sure we cleaned up."""""" self._done() def close(self): """"""Caller is done with this connection."""""" self._done() def create_consumer(self, topic, proxy, fanout=False): self.connection.create_consumer(topic, proxy, fanout) def create_worker(self, topic, proxy, pool_name): self.connection.create_worker(topic, proxy, pool_name) def join_consumer_pool(self, callback, pool_name, topic, exchange_name, ack_on_error=True): self.connection.join_consumer_pool(callback, pool_name, topic, exchange_name, ack_on_error) def consume_in_thread(self): self.connection.consume_in_thread() def __getattr__(self, key): """"""Proxy all other calls to the Connection instance."""""" if self.connection: return getattr(self.connection, key) else: raise rpc_common.InvalidRPCConnectionReuse() class ReplyProxy(ConnectionContext): """"""Connection class for RPC replies / callbacks."""""" def __init__(self, conf, connection_pool): self._call_waiters = {} self._num_call_waiters = 0 self._num_call_waiters_wrn_threshhold = 10 self._reply_q = 'reply_' + uuid.uuid4().hex super(ReplyProxy, self).__init__(conf, connection_pool, pooled=False) self.declare_direct_consumer(self._reply_q, self._process_data) self.consume_in_thread() def _process_data(self, message_data): msg_id = message_data.pop('_msg_id', None) waiter = self._call_waiters.get(msg_id) if not waiter: LOG.warn(_('No calling threads waiting for msg_id : %(msg_id)s' ', message : %(data)s'), {'msg_id': msg_id, 'data': message_data}) LOG.warn(_('_call_waiters: %s') % str(self._call_waiters)) else: waiter.put(message_data) def add_call_waiter(self, waiter, msg_id): self._num_call_waiters += 1 if self._num_call_waiters > self._num_call_waiters_wrn_threshhold: LOG.warn(_('Number of call waiters is greater than warning ' 'threshhold: %d. There could be a MulticallProxyWaiter ' 'leak.') % self._num_call_waiters_wrn_threshhold) self._num_call_waiters_wrn_threshhold *= 2 self._call_waiters[msg_id] = waiter def del_call_waiter(self, msg_id): self._num_call_waiters -= 1 del self._call_waiters[msg_id] def get_reply_q(self): return self._reply_q def msg_reply(conf, msg_id, reply_q, connection_pool, reply=None, failure=None, ending=False, log_failure=True): """"""Sends a reply or an error on the channel signified by msg_id. Failure should be a sys.exc_info() tuple. """""" with ConnectionContext(conf, connection_pool) as conn: if failure: failure = rpc_common.serialize_remote_exception(failure, log_failure) msg = {'result': reply, 'failure': failure} if ending: msg['ending'] = True _add_unique_id(msg) # If a reply_q exists, add the msg_id to the reply and pass the # reply_q to direct_send() to use it as the response queue. # Otherwise use the msg_id for backward compatibilty. if reply_q: msg['_msg_id'] = msg_id conn.direct_send(reply_q, rpc_common.serialize_msg(msg)) else: conn.direct_send(msg_id, rpc_common.serialize_msg(msg)) class RpcContext(rpc_common.CommonRpcContext): """"""Context that supports replying to a rpc.call."""""" def __init__(self, **kwargs): self.msg_id = kwargs.pop('msg_id', None) self.reply_q = kwargs.pop('reply_q', None) self.conf = kwargs.pop('conf') super(RpcContext, self).__init__(**kwargs) def deepcopy(self): values = self.to_dict() values['conf'] = self.conf values['msg_id'] = self.msg_id values['reply_q'] = self.reply_q return self.__class__(**values) def reply(self, reply=None, failure=None, ending=False, connection_pool=None, log_failure=True): if self.msg_id: msg_reply(self.conf, self.msg_id, self.reply_q, connection_pool, reply, failure, ending, log_failure) if ending: self.msg_id = None def unpack_context(conf, msg): """"""Unpack context from msg."""""" context_dict = {} for key in list(msg.keys()): # NOTE(vish): Some versions of python don't like unicode keys # in kwargs. key = str(key) if key.startswith('_context_'): value = msg.pop(key) context_dict[key[9:]] = value context_dict['msg_id'] = msg.pop('_msg_id', None) context_dict['reply_q'] = msg.pop('_reply_q', None) context_dict['conf'] = conf ctx = RpcContext.from_dict(context_dict) rpc_common._safe_log(LOG.debug, _('unpacked context: %s'), ctx.to_dict()) return ctx def pack_context(msg, context): """"""Pack context into msg. Values for message keys need to be less than 255 chars, so we pull context out into a bunch of separate keys. If we want to support more arguments in rabbit messages, we may want to do the same for args at some point. """""" context_d = dict([('_context_%s' % key, value) for (key, value) in context.to_dict().iteritems()]) msg.update(context_d) class _MsgIdCache(object): """"""This class checks any duplicate messages."""""" # NOTE: This value is considered can be a configuration item, but # it is not necessary to change its value in most cases, # so let this value as static for now. DUP_MSG_CHECK_SIZE = 16 def __init__(self, **kwargs): self.prev_msgids = collections.deque([], maxlen=self.DUP_MSG_CHECK_SIZE) def check_duplicate_message(self, message_data): """"""AMQP consumers may read same message twice when exceptions occur before ack is returned. This method prevents doing it. """""" if UNIQUE_ID in message_data: msg_id = message_data[UNIQUE_ID] if msg_id not in self.prev_msgids: self.prev_msgids.append(msg_id) else: raise rpc_common.DuplicateMessageError(msg_id=msg_id) def _add_unique_id(msg): """"""Add unique_id for checking duplicate messages."""""" unique_id = uuid.uuid4().hex msg.update({UNIQUE_ID: unique_id}) LOG.debug(_('UNIQUE_ID is %s.') % (unique_id)) class _ThreadPoolWithWait(object): """"""Base class for a delayed invocation manager. Used by the Connection class to start up green threads to handle incoming messages. """""" def __init__(self, conf, connection_pool): self.pool = greenpool.GreenPool(conf.rpc_thread_pool_size) self.connection_pool = connection_pool self.conf = conf def wait(self): """"""Wait for all callback threads to exit."""""" self.pool.waitall() class CallbackWrapper(_ThreadPoolWithWait): """"""Wraps a straight callback. Allows it to be invoked in a green thread. """""" def __init__(self, conf, callback, connection_pool): """"""Initiates CallbackWrapper object. :param conf: cfg.CONF instance :param callback: a callable (probably a function) :param connection_pool: connection pool as returned by get_connection_pool() """""" super(CallbackWrapper, self).__init__( conf=conf, connection_pool=connection_pool, ) self.callback = callback def __call__(self, message_data): self.pool.spawn_n(self.callback, message_data) class ProxyCallback(_ThreadPoolWithWait): """"""Calls methods on a proxy object based on method and args."""""" def __init__(self, conf, proxy, connection_pool): super(ProxyCallback, self).__init__( conf=conf, connection_pool=connection_pool, ) self.proxy = proxy self.msg_id_cache = _MsgIdCache() def __call__(self, message_data): """"""Consumer callback to call a method on a proxy object. Parses the message for validity and fires off a thread to call the proxy object method. Message data should be a dictionary with two keys: method: string representing the method to call args: dictionary of arg: value Example: {'method': 'echo', 'args': {'value': 42}} """""" # It is important to clear the context here, because at this point # the previous context is stored in local.store.context if hasattr(local.store, 'context'): del local.store.context rpc_common._safe_log(LOG.debug, _('received %s'), message_data) self.msg_id_cache.check_duplicate_message(message_data) ctxt = unpack_context(self.conf, message_data) method = message_data.get('method') args = message_data.get('args', {}) version = message_data.get('version') namespace = message_data.get('namespace') if not method: LOG.warn(_('no method for message: %s') % message_data) ctxt.reply(_('No method for message: %s') % message_data, connection_pool=self.connection_pool) return self.pool.spawn_n(self._process_data, ctxt, version, method, namespace, args) def _process_data(self, ctxt, version, method, namespace, args): """"""Process a message in a new thread. If the proxy object we have has a dispatch method (see rpc.dispatcher.RpcDispatcher), pass it the version, method, and args and let it dispatch as appropriate. If not, use the old behavior of magically calling the specified method on the proxy we have here. """""" ctxt.update_store() try: rval = self.proxy.dispatch(ctxt, version, method, namespace, **args) # Check if the result was a generator if inspect.isgenerator(rval): for x in rval: ctxt.reply(x, None, connection_pool=self.connection_pool) else: ctxt.reply(rval, None, connection_pool=self.connection_pool) # This final None tells multicall that it is done. ctxt.reply(ending=True, connection_pool=self.connection_pool) except rpc_common.ClientException as e: LOG.debug(_('Expected exception during message handling (%s)') % e._exc_info[1]) ctxt.reply(None, e._exc_info, connection_pool=self.connection_pool, log_failure=False) except Exception: # sys.exc_info() is deleted by LOG.exception(). exc_info = sys.exc_info() LOG.error(_('Exception during message handling'), exc_info=exc_info) ctxt.reply(None, exc_info, connection_pool=self.connection_pool) class MulticallProxyWaiter(object): def __init__(self, conf, msg_id, timeout, connection_pool): self._msg_id = msg_id self._timeout = timeout or conf.rpc_response_timeout self._reply_proxy = connection_pool.reply_proxy self._done = False self._got_ending = False self._conf = conf self._dataqueue = queue.LightQueue() # Add this caller to the reply proxy's call_waiters self._reply_proxy.add_call_waiter(self, self._msg_id) self.msg_id_cache = _MsgIdCache() def put(self, data): self._dataqueue.put(data) def done(self): if self._done: return self._done = True # Remove this caller from reply proxy's call_waiters self._reply_proxy.del_call_waiter(self._msg_id) def _process_data(self, data): result = None self.msg_id_cache.check_duplicate_message(data) if data['failure']: failure = data['failure'] result = rpc_common.deserialize_remote_exception(self._conf, failure) elif data.get('ending', False): self._got_ending = True else: result = data['result'] return result def __iter__(self): """"""Return a result until we get a reply with an 'ending' flag."""""" if self._done: raise StopIteration while True: try: data = self._dataqueue.get(timeout=self._timeout) result = self._process_data(data) except queue.Empty: self.done() raise rpc_common.Timeout() except Exception: with excutils.save_and_reraise_exception(): self.done() if self._got_ending: self.done() raise StopIteration if isinstance(result, Exception): self.done() raise result yield result def create_connection(conf, new, connection_pool): """"""Create a connection."""""" return ConnectionContext(conf, connection_pool, pooled=not new) _reply_proxy_create_sem = semaphore.Semaphore() def multicall(conf, context, topic, msg, timeout, connection_pool): """"""Make a call that returns multiple times."""""" LOG.debug(_('Making synchronous call on %s ...'), topic) msg_id = uuid.uuid4().hex msg.update({'_msg_id': msg_id}) LOG.debug(_('MSG_ID is %s') % (msg_id)) _add_unique_id(msg) pack_context(msg, context) with _reply_proxy_create_sem: if not connection_pool.reply_proxy: connection_pool.reply_proxy = ReplyProxy(conf, connection_pool) msg.update({'_reply_q': connection_pool.reply_proxy.get_reply_q()}) wait_msg = MulticallProxyWaiter(conf, msg_id, timeout, connection_pool) with ConnectionContext(conf, connection_pool) as conn: conn.topic_send(topic, rpc_common.serialize_msg(msg), timeout) return wait_msg def call(conf, context, topic, msg, timeout, connection_pool): """"""Sends a message on a topic and wait for a response."""""" rv = multicall(conf, context, topic, msg, timeout, connection_pool) # NOTE(vish): return the last result from the multicall rv = list(rv) if not rv: return return rv[-1] def cast(conf, context, topic, msg, connection_pool): """"""Sends a message on a topic without waiting for a response."""""" LOG.debug(_('Making asynchronous cast on %s...'), topic) _add_unique_id(msg) pack_context(msg, context) with ConnectionContext(conf, connection_pool) as conn: conn.topic_send(topic, rpc_common.serialize_msg(msg)) def fanout_cast(conf, context, topic, msg, connection_pool): """"""Sends a message on a fanout exchange without waiting for a response."""""" LOG.debug(_('Making asynchronous fanout cast...')) _add_unique_id(msg) pack_context(msg, context) with ConnectionContext(conf, connection_pool) as conn: conn.fanout_send(topic, rpc_common.serialize_msg(msg)) def cast_to_server(conf, context, server_params, topic, msg, connection_pool): """"""Sends a message on a topic to a specific server."""""" _add_unique_id(msg) pack_context(msg, context) with ConnectionContext(conf, connection_pool, pooled=False, server_params=server_params) as conn: conn.topic_send(topic, rpc_common.serialize_msg(msg)) def fanout_cast_to_server(conf, context, server_params, topic, msg, connection_pool): """"""Sends a message on a fanout exchange to a specific server."""""" _add_unique_id(msg) pack_context(msg, context) with ConnectionContext(conf, connection_pool, pooled=False, server_params=server_params) as conn: conn.fanout_send(topic, rpc_common.serialize_msg(msg)) def notify(conf, context, topic, msg, connection_pool, envelope): """"""Sends a notification event on a topic."""""" LOG.debug(_('Sending %(event_type)s on %(topic)s'), dict(event_type=msg.get('event_type'), topic=topic)) _add_unique_id(msg) pack_context(msg, context) with ConnectionContext(conf, connection_pool) as conn: if envelope: msg = rpc_common.serialize_msg(msg) conn.notify_send(topic, msg) def cleanup(connection_pool): if connection_pool: connection_pool.empty() def get_control_exchange(conf): return conf.control_exchange ",,2723,0
openstack%2Foslo.messaging~master~I0787fa619a6a8a35a303627f8ce119c93f2c8765,openstack/oslo.messaging,master,I0787fa619a6a8a35a303627f8ce119c93f2c8765,Make executor threads more robust,MERGED,2013-07-23 17:38:21.000000000,2013-07-24 07:12:31.000000000,2013-07-24 07:12:31.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6786}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-07-23 17:38:21.000000000', 'files': ['oslo/messaging/_executors/impl_eventlet.py', 'oslo/messaging/openstack/common/excutils.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/43ab36d1a19c2021ca079afd9c8e629988dd2981', 'message': 'Make executor threads more robust\n\nSee bug #1189711\n\nPrevent the executor thread getting killed by exceptions.\n\nChange-Id: I0787fa619a6a8a35a303627f8ce119c93f2c8765\n'}]",0,38329,43ab36d1a19c2021ca079afd9c8e629988dd2981,7,4,1,1247,,,0,"Make executor threads more robust

See bug #1189711

Prevent the executor thread getting killed by exceptions.

Change-Id: I0787fa619a6a8a35a303627f8ce119c93f2c8765
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/29/38329/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_executors/impl_eventlet.py', 'oslo/messaging/openstack/common/excutils.py', 'openstack-common.conf']",3,43ab36d1a19c2021ca079afd9c8e629988dd2981,,module=excutils,,101,0
openstack%2Fheat~master~I94306e2b70c7fa77d1b5a1177fede88262f8bbc9,openstack/heat,master,I94306e2b70c7fa77d1b5a1177fede88262f8bbc9,remove remote_error and corresponding try...catches.,MERGED,2013-07-19 14:11:09.000000000,2013-07-24 07:09:04.000000000,2013-07-24 07:09:04.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7676}, {'_account_id': 7761}]","[{'number': 1, 'created': '2013-07-19 14:11:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/76c13b14d153ac7cf10669a45c8d233a43fabcb6', 'message': 'remove remote_error and corresponding try...catches.\n\nImplements blueprint exception-formatting\n\nChange-Id: I94306e2b70c7fa77d1b5a1177fede88262f8bbc9\n'}, {'number': 2, 'created': '2013-07-19 14:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/22239f1687c8075e38b35dd00d95b79b59779345', 'message': 'remove remote_error and corresponding try...catches.\n\nImplements blueprint exception-formatting\n\nChange-Id: I94306e2b70c7fa77d1b5a1177fede88262f8bbc9\n'}, {'number': 3, 'created': '2013-07-24 05:17:40.000000000', 'files': ['heat/api/openstack/v1/resources.py', 'heat/api/openstack/v1/actions.py', 'heat/api/openstack/v1/stacks.py', 'heat/api/openstack/v1/util.py', 'heat/api/openstack/v1/events.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/6ab8e1b6b619230c7c59130ae3beb24ba9aefb6d', 'message': 'remove remote_error and corresponding try...catches.\n\nImplements blueprint exception-formatting\n\nChange-Id: I94306e2b70c7fa77d1b5a1177fede88262f8bbc9\n'}]",0,37908,6ab8e1b6b619230c7c59130ae3beb24ba9aefb6d,13,5,3,7676,,,0,"remove remote_error and corresponding try...catches.

Implements blueprint exception-formatting

Change-Id: I94306e2b70c7fa77d1b5a1177fede88262f8bbc9
",git fetch https://review.opendev.org/openstack/heat refs/changes/08/37908/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/api/openstack/v1/resources.py', 'heat/api/openstack/v1/actions.py', 'heat/api/openstack/v1/stacks.py', 'heat/api/openstack/v1/events.py', 'heat/api/openstack/v1/util.py']",5,76c13b14d153ac7cf10669a45c8d233a43fabcb6,bp/exception-formatting,," def remote_error(ex): """"""The RemoteError mapping work has been moved to heat.api.middleware.fault which handles error formating now. This function will be deprecated in the future, so please raise exceptions directly. """""" # TODO(jianingy): add a deprecated warning here to inform others. raise ex",38,97
openstack%2Fmurano~master~I2025709d25de130d1e0ac3dd2f4b6f3c0e0ad773,openstack/murano,master,I2025709d25de130d1e0ac3dd2f4b6f3c0e0ad773,Increment environment,MERGED,2013-07-22 07:57:12.000000000,2013-07-24 07:07:41.000000000,2013-07-24 07:07:41.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-07-22 07:57:12.000000000', 'files': ['muranoapi/common/service.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/ec22326dfe7f2b5fe55ac8cceb8fcdbc4df08227', 'message': 'Increment environment\n\nChange-Id: I2025709d25de130d1e0ac3dd2f4b6f3c0e0ad773\n'}]",0,38113,ec22326dfe7f2b5fe55ac8cceb8fcdbc4df08227,5,2,1,7549,,,0,"Increment environment

Change-Id: I2025709d25de130d1e0ac3dd2f4b6f3c0e0ad773
",git fetch https://review.opendev.org/openstack/murano refs/changes/13/38113/1 && git format-patch -1 --stdout FETCH_HEAD,['muranoapi/common/service.py'],1,ec22326dfe7f2b5fe55ac8cceb8fcdbc4df08227,env_inctement, environment.version += 1,,1,0
openstack%2Fcinder~master~Id678d972b9bf744239460fe97155a6a7bd8a868e,openstack/cinder,master,Id678d972b9bf744239460fe97155a6a7bd8a868e,Update RBD driver to be compliant with HACKING,MERGED,2013-07-24 02:44:00.000000000,2013-07-24 06:42:43.000000000,2013-07-24 06:42:43.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4355}]","[{'number': 1, 'created': '2013-07-24 02:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6596ae24929e4fcad0059eb903a31308c610fbb8', 'message': 'Update RBD driver to be compliant with HACKING\n\nFixes imports, doc strings, and dict style.\n\nChange-Id: Id678d972b9bf744239460fe97155a6a7bd8a868e\n'}, {'number': 2, 'created': '2013-07-24 05:09:07.000000000', 'files': ['cinder/volume/drivers/rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2d6a7f0718461d4a5884c286f2a358bf13652caf', 'message': 'Update RBD driver to be compliant with HACKING\n\nFixes imports, doc strings, and dict style.\n\nChange-Id: Id678d972b9bf744239460fe97155a6a7bd8a868e\n'}]",2,38405,2d6a7f0718461d4a5884c286f2a358bf13652caf,12,5,2,170,,,0,"Update RBD driver to be compliant with HACKING

Fixes imports, doc strings, and dict style.

Change-Id: Id678d972b9bf744239460fe97155a6a7bd8a868e
",git fetch https://review.opendev.org/openstack/cinder refs/changes/05/38405/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/rbd.py'],1,6596ae24929e4fcad0059eb903a31308c610fbb8,driver-compliant,"# Copyright 2013 OpenStack LLC""""""RADOS Block Device Driver""""""from oslo.config import cfg from cinder.backup.drivers import ceph as ceph_backup This is useful when a parameter is None by default, or a string. LibRBD only accepts ascii, hence the need for conversion. """"""Enables LibRBD.Image objects to be treated as Python IO objects. This handles connecting to rados and opening an ioctx automatically, and otherwise acts like a librbd Image object. The underlying librados client and ioctx can be accessed as the attributes 'client' and 'ioctx'. stats = { 'vendor_name': 'Open Source', 'driver_version': VERSION, 'storage_protocol': 'ceph', 'total_capacity_gb': 'unknown', 'free_capacity_gb': 'unknown', 'reserved_percentage': 0 } """"""Extend an existing volume.""""""","# Copyright 2012 OpenStack LLC"""""" RADOS Block Device Driver """""" import cinder.backup.drivers.ceph as ceph_backupfrom cinder import utilsfrom oslo.config import cfg This is useful where a parameter may be None by default, or a string. librbd only accepts ascii, hence the need for conversion. """"""Wrapper to provide standard Python IO interface to RBD images. This enables librbd.Image objects to be treated as standard Python IO objects. This handles connecting to rados and opening an ioctx automatically, and otherwise acts like a librbd Image object. The underlying librados client and ioctx can be accessed as the attributes 'client' and 'ioctx'. stats = {'vendor_name': 'Open Source', 'driver_version': VERSION, 'storage_protocol': 'ceph', 'total_capacity_gb': 'unknown', 'free_capacity_gb': 'unknown', 'reserved_percentage': 0} """"""Extend an Existing Volume.""""""",21,26
openstack%2Fceilometer~master~I583a0fe9755c9bec8bcb08b13a3f1d03a3acf336,openstack/ceilometer,master,I583a0fe9755c9bec8bcb08b13a3f1d03a3acf336,trailing slash in url causes 404 error,MERGED,2013-07-19 18:58:04.000000000,2013-07-24 06:16:28.000000000,2013-07-24 06:16:28.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 4491}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-19 18:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/04a0baecbd588a886427aec7b2f54014c707d404', 'message': ""trailing slash in url causes 404 error\n\nwhen accessing samples for a specific meter, appending a trailing\nslash will add an empty target path to 'remainder', in turn\ntriggering 404 error. in case last target path in remainder, we\nwill drop that empty instance.\n\nChange-Id: I583a0fe9755c9bec8bcb08b13a3f1d03a3acf336\nFixes:Bug#1202739\n""}, {'number': 2, 'created': '2013-07-22 12:44:44.000000000', 'files': ['tests/api/v2/list_events.py', 'ceilometer/api/controllers/v2.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e757d69a3cd3316a3b18f0b21a1867efa83e5af8', 'message': ""trailing slash in url causes 404 error\n\nwhen accessing samples for a specific meter, appending a trailing\nslash will add an empty target path to 'remainder', in turn\ntriggering 404 error. in case last target path in remainder, we\nwill drop that empty instance.\n\nChange-Id: I583a0fe9755c9bec8bcb08b13a3f1d03a3acf336\nFixes:Bug#1202739\n""}]",0,37956,e757d69a3cd3316a3b18f0b21a1867efa83e5af8,9,4,2,6537,,,0,"trailing slash in url causes 404 error

when accessing samples for a specific meter, appending a trailing
slash will add an empty target path to 'remainder', in turn
triggering 404 error. in case last target path in remainder, we
will drop that empty instance.

Change-Id: I583a0fe9755c9bec8bcb08b13a3f1d03a3acf336
Fixes:Bug#1202739
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/56/37956/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/api/controllers/v2.py'],1,04a0baecbd588a886427aec7b2f54014c707d404,bug/1202739, # NOTE(gordc): drop last path if empty (Bug #1202739) if remainder and not remainder[-1]: remainder = remainder[:-1],,3,0
openstack%2Fceilometer~master~I4f3c104a05f9d79ec25c8f2b0f6075039b5d2b26,openstack/ceilometer,master,I4f3c104a05f9d79ec25c8f2b0f6075039b5d2b26,Added functions to sync db in both alembic and migrate,ABANDONED,2013-07-16 11:33:55.000000000,2013-07-24 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-07-16 11:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/417410fa4e19209a127ff1848b471bbd36c2a383', 'message': 'Added functions to sync db in both alembic and migrate\n\nThis functionality allows to port existing migrations one by one without\nbreaking db structure. It uses migration description to match migrate\nfiles to alembic example:\n167b3be5fd4a_add_meter_table.py <-> 001_add_meter_table.py\n\nMigrations are supposed to be ported starting from the oldest ones.\n\nRelated to blueprint convert-to-alembic\n\nChange-Id: I4f3c104a05f9d79ec25c8f2b0f6075039b5d2b26\n'}, {'number': 2, 'created': '2013-07-16 12:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7f54c65b40a4f7c3907348eb2d14cb57fa539497', 'message': 'Added functions to sync db in both alembic and migrate\n\nThis functionality allows to port existing migrations one by one without\nbreaking db structure. It uses migration description to match migrate\nfiles to alembic example:\n167b3be5fd4a_add_meter_table.py <-> 001_add_meter_table.py\n\nMigrations are supposed to be ported starting from the oldest ones.\n\nRelated to blueprint convert-to-alembic\n\nChange-Id: I4f3c104a05f9d79ec25c8f2b0f6075039b5d2b26\n'}, {'number': 3, 'created': '2013-07-16 12:33:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/98a1ea19d7033b6c819d91b541efad94f8a254a3', 'message': 'Added functions to sync db in both alembic and migrate\n\nThis functionality allows to port existing migrations one by one without\nbreaking db structure. It uses migration description to match migrate\nfiles to alembic example:\n167b3be5fd4a_add_meter_table.py <-> 001_add_meter_table.py\n\nMigrations are supposed to be ported starting from the oldest ones.\n\nRelated to blueprint convert-to-alembic\n\nChange-Id: I4f3c104a05f9d79ec25c8f2b0f6075039b5d2b26\n'}, {'number': 4, 'created': '2013-07-16 13:07:38.000000000', 'files': ['ceilometer/storage/sqlalchemy/migration.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/04607bb35792df7dab2e781f8a903d330ffb4734', 'message': 'Added functions to sync db in both alembic and migrate\n\nThis functionality allows to port existing migrations one by one without\nbreaking db structure. It uses migration description to match migrate\nfiles to alembic example:\n167b3be5fd4a_add_meter_table.py <-> 001_add_meter_table.py\n\nMigrations are supposed to be ported starting from the oldest ones.\n\nRelated to blueprint convert-to-alembic\n\nChange-Id: I4f3c104a05f9d79ec25c8f2b0f6075039b5d2b26\n'}]",2,37224,04607bb35792df7dab2e781f8a903d330ffb4734,9,3,4,7763,,,0,"Added functions to sync db in both alembic and migrate

This functionality allows to port existing migrations one by one without
breaking db structure. It uses migration description to match migrate
files to alembic example:
167b3be5fd4a_add_meter_table.py <-> 001_add_meter_table.py

Migrations are supposed to be ported starting from the oldest ones.

Related to blueprint convert-to-alembic

Change-Id: I4f3c104a05f9d79ec25c8f2b0f6075039b5d2b26
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/24/37224/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/storage/sqlalchemy/migration.py'],1,417410fa4e19209a127ff1848b471bbd36c2a383,bp/convert-to-alembic,"import alembic from alembic import config as alembic_config from alembic.migration import MigrationContext import reimport ceilometer.openstack.common.db.sqlalchemy.session as sqlalchemy_session run_migrate = _run_alembic_migrations(engine) if not run_migrate: return def _run_alembic_migrations(engine): current_version = 0 run_migrate = True try: current_version = db_version(engine) except versioning_exceptions.DatabaseNotControlledError: # Migrate table is not present # Assume that we don't need to apply migrate migrations run_migrate = False if current_version: # DB already have some migrations up result = _fix_alembic_version_stamp(engine, current_version) if not result: return True alembic.command.upgrade(_alembic_config(), ""head"") if run_migrate: run_migrate = _fix_migrate_version_stamp(engine) return run_migrate def _fix_alembic_version_stamp(engine, current_version): alembic_src = _alembic_db_version() try: alembic_dest = _migrate_version_to_alembic(current_version) except ValueError: # Unable to determine corresponding alembic migration # assume that alembic migration should not run return False alembic_context = MigrationContext.configure(engine.connect()) alembic_context._update_current_rev(alembic_src, alembic_dest) return True def _fix_migrate_version_stamp(engine): repository = _find_migrate_repo() versioning_api.drop_version_control(engine, repository) try: alembic_version = _alembic_db_version() if not alembic_version: # No alembic version available # seems don't have any alembic migration # we still need to run migrate return True migrate_version = _alembic_version_to_migrate(alembic_version) except ValueError: # Unable to map id of migrate version # Assume that we don't need migrate anymore return False versioning_api.version_control(engine, repository, migrate_version) return True return versioning_api.db_version(engine, repository) if not tables or (len(tables) == 1 and 'alembic_version' in tables): raise def _alembic_config(): path = os.path.join(os.path.dirname(__file__), 'alembic/alembic.ini') config = alembic_config.Config(path) # used for offline migrations mode only #config.set_main_option('sqlalchemy.url', str(engine.url)) return config def _alembic_db_version(): current_version = [] config = _alembic_config() config.print_stdout = lambda rev: current_version.append(rev) alembic.command.current(config, True) version = current_version[0].split(' ')[0] if version == 'None': version = None return version def _alembic_history(): alembic_history = [] config = _alembic_config() config.print_stdout = lambda rev: alembic_history.append(str(rev)) alembic.command.history(config) return alembic_history def _alembic_version_to_migrate(alembic_version): revision_name = None for revision in _alembic_history(): if ('-> ' + alembic_version) in revision: revision_name = revision.split(', ')[1] break if revision_name: repo = _find_migrate_repo() for ver_num, version in repo.versions.versions.items(): if revision_name in str(version.python): return ver_num raise ValueError(_('Specified revision not found in migrate history')) def _migrate_version_to_alembic(migrate_version): migration_file = str(_find_migrate_repo().version(migrate_version).python) regex = '-> (?P<id>[a-z0-9]+)( \(head\))?, (?P<name>[a-zA-Z_0-9]*)$' revision_matcher = re.compile(regex) for revision in _alembic_history(): revision_data = revision_matcher.search(revision) if not revision_data: continue revision_name = revision_data.group('name') if revision_name in migration_file: return revision_data.group('id') raise ValueError(_('Unable to find alembic revision from migrate id'))"," return versioning_api.db_version(engine, repository) if len(tables) == 0:",124,3
openstack%2Fceilometer~master~I0fc28bc148411b390bb8b3ffcb15b7951ee20e06,openstack/ceilometer,master,I0fc28bc148411b390bb8b3ffcb15b7951ee20e06,Adding hardware-agent,ABANDONED,2013-05-28 10:46:16.000000000,2013-07-24 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 1669}, {'_account_id': 4491}, {'_account_id': 7547}]","[{'number': 1, 'created': '2013-05-28 10:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/784e7c4030811f34c4632115a01fcf70c0fce807', 'message': 'Adding hardware-agent\n\nThis adds basic monitoring for physical devices. The structure is similar to the compute-agent.\nThis hardware-agent includes a plugin to collect data over snmp. The agent is designed for easy extending with other plugins.\nThe hardware-agent is configurable over the hardware-agent.conf as well as over the ceilometer.conf\n\nChange-Id: I0fc28bc148411b390bb8b3ffcb15b7951ee20e06\nImplements: blueprint monitoring-physical-devices\n'}, {'number': 2, 'created': '2013-06-07 09:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6a998750219d0f2526aa81e0b876bfc53ad06d26', 'message': 'Adding hardware-agent\n\nThis adds basic monitoring for physical devices. The structure is similar to the compute-agent.\nThe agent is designed for easy extending with inspectors.\nThe hardware-agent is configurable over the hardware-agent.conf as well as over the ceilometer.conf\n\nImplements: blueprint monitoring-physical-devices\n\nChange-Id: I0fc28bc148411b390bb8b3ffcb15b7951ee20e06\n'}, {'number': 3, 'created': '2013-07-16 12:31:31.000000000', 'files': ['ceilometer/hardware/pollsters.py', 'ceilometer/hardware/inspector/manager.py', 'etc/ceilometer/hardware-agent.conf.sample', 'tests/hardware/inspector/__init__.py', 'ceilometer/hardware/__init__.py', 'ceilometer/hardware/inspector/__init__.py', 'ceilometer/service.py', 'ceilometer/hardware/host.py', 'tests/hardware/inspector/test_manager.py', 'tests/hardware/__init__.py', 'tests/hardware/test_host.py', 'tests/hardware/test_manager.py', 'ceilometer/hardware/inspector/inspector.py', 'ceilometer/hardware/manager.py', 'setup.cfg', 'tests/hardware/test_pollsters.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/95038e8208540f546275bff45183d44263cb5ea9', 'message': 'Adding hardware-agent\n\nThis adds basic monitoring for physical devices. The structure is similar to the compute-agent.\nThe agent is designed for easy extending with inspectors.\nThe hardware-agent is configurable over the hardware-agent.conf as well as over the ceilometer.conf\n\nImplements: blueprint monitoring-physical-devices\n\nChange-Id: I0fc28bc148411b390bb8b3ffcb15b7951ee20e06\n'}]",28,30700,95038e8208540f546275bff45183d44263cb5ea9,18,5,3,7547,,,0,"Adding hardware-agent

This adds basic monitoring for physical devices. The structure is similar to the compute-agent.
The agent is designed for easy extending with inspectors.
The hardware-agent is configurable over the hardware-agent.conf as well as over the ceilometer.conf

Implements: blueprint monitoring-physical-devices

Change-Id: I0fc28bc148411b390bb8b3ffcb15b7951ee20e06
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/00/30700/2 && git format-patch -1 --stdout FETCH_HEAD,"['bin/ceilometer-agent-hardware', 'ceilometer/hardware/pollsters.py', 'ceilometer/hardware/inspector/snmp/__init__.py', 'ceilometer/hardware/inspector/manager.py', 'ceilometer/hardware/plugin.py', 'etc/ceilometer/hardware-agent.conf.sample', 'tests/hardware/inspector/__init__.py', 'ceilometer/hardware/__init__.py', 'ceilometer/hardware/inspector/__init__.py', 'tests/hardware/inspector/snmp/test_inspector.py', 'ceilometer/service.py', 'tests/hardware/inspector/snmp/__init__.py', 'ceilometer/hardware/inspector/snmp/inspector.py', 'ceilometer/hardware/host.py', 'tests/hardware/inspector/test_manager.py', 'tests/hardware/__init__.py', 'tests/hardware/test_host.py', 'tests/hardware/test_manager.py', 'tools/pip-requires', 'ceilometer/hardware/inspector/inspector.py', 'ceilometer/hardware/manager.py', 'setup.cfg', 'tests/hardware/test_pollsters.py']",23,784e7c4030811f34c4632115a01fcf70c0fce807,bp/monitoring-physical-devices,"# -*- encoding: utf-8 -*- # # Copyright  2013 ZHAW SoE # # Authors: Lucas Graf <graflu0@students.zhaw.ch> # Toni Zehnder <zehndton@students.zhaw.ch> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Tests for ceilometer/hardware/pollsters """""" import mock import time from ceilometer.hardware import pollsters from ceilometer.hardware import manager from ceilometer.hardware.inspector import manager as hardware_manager from ceilometer.hardware.inspector import inspector as hardware_inspector from ceilometer.tests import base as test_base class TestPollsterBase(test_base.TestCase): #TODO: correct setUp def setUp(self): super(TestPollsterBase, self).setUp() self.inspector_manager = self.mox.CreateMock( hardware_manager.InspectorManager) self.mox.StubOutWithMock(hardware_manager, 'InspectorManager') hardware_manager.InspectorManager().AndReturn(self.inspector_manager) self.host = mock.MagicMock() self.host.id = ""001122334455"" self.host.ip_address = ""127.0.0.1"" self.host.name = ""name.of.host"" class TestDiskSpacePollster(TestPollsterBase): def setUp(self): super(TestDiskSpacePollster, self).setUp() @mock.patch('ceilometer.pipeline.setup_pipeline', mock.MagicMock()) def test_get_counters(self): disks = [ (hardware_inspector.Disk(device='l', path='/'), hardware_inspector.DiskStats(size=10000, used=9000)) ] self.inspector_manager.inspect_diskspace(self.host).AndReturn(disks) self.mox.ReplayAll() mgr = manager.AgentManager() pollster = pollsters.DiskSpacePollster() counters = list(pollster.get_counters(mgr, self.host)) assert counters self.assertEqual( set([c.name for c in counters]), set(pollster.get_counter_names())) def _verify_disk_monitoring(name, expected_volume): match = [c for c in counters if c.name == name] self.assertEquals(len(match), 1, 'missing counter %s' % name) self.assertEquals(match[0].volume, expected_volume) self.assertEquals(match[0].type, 'gauge') _verify_disk_monitoring('disk.size.total', 10000) _verify_disk_monitoring('disk.size.used', 9000) class TestNetPollster(TestPollsterBase): def setUp(self): super(TestNetPollster, self).setUp() @mock.patch('ceilometer.pipeline.setup_pipeline', mock.MagicMock()) def test_get_counters(self): nic0 = hardware_inspector.Interface( name='eth0', mac='fa163e71ec6d', ip='10.0.0.2') stats0 = hardware_inspector.InterfaceStats( bandwidth=1L, rx_bytes=2L, tx_bytes=3L, error=4L) nic1 = hardware_inspector.Interface( name='eth1', mac='fa163e71ec6e', ip='192.168.0.3') stats1 = hardware_inspector.InterfaceStats( bandwidth=5L, rx_bytes=6L, tx_bytes=7L, error=8L) nics = [(nic0, stats0), (nic1, stats1)] self.inspector_manager.inspect_nics(self.host).AndReturn(nics) self.mox.ReplayAll() mgr = manager.AgentManager() pollster = pollsters.NetPollster() counters = list(pollster.get_counters(mgr, self.host)) assert counters self.assertEqual( set([c.name for c in counters]), set(pollster.get_counter_names())) def _verify_nics_monitoring(name, ip, expected_volume): match = [c for c in counters if c.name == name and c.resource_metadata['ip'] == ip] self.assertEquals(len(match), 1, 'missing counter %s' % name) self.assertEquals(match[0].volume, expected_volume) self.assertEquals(match[0].type, 'cumulative') _verify_nics_monitoring('network.bandwidth.bytes', '10.0.0.2', 1L) _verify_nics_monitoring('network.bandwidth.bytes', '192.168.0.3', 5L) _verify_nics_monitoring('network.incoming.bytes', '10.0.0.2', 2L) _verify_nics_monitoring('network.incoming.bytes', '192.168.0.3', 6L) _verify_nics_monitoring('network.outgoing.bytes', '10.0.0.2', 3L) _verify_nics_monitoring('network.outgoing.bytes', '192.168.0.3', 7L) _verify_nics_monitoring('network.outgoing.errors', '10.0.0.2', 4L) _verify_nics_monitoring('network.outgoing.errors', '192.168.0.3', 8L) class TestCPUPollster(TestPollsterBase): def setUp(self): super(TestCPUPollster, self).setUp() @mock.patch('ceilometer.pipeline.setup_pipeline', mock.MagicMock()) def test_get_counters(self): self.inspector_manager.inspect_cpu(self.host).AndReturn( hardware_inspector.CPUStats( cpu1MinLoad=0.1, cpu5MinLoad=0.2, cpu15MinLoad=0.3)) self.mox.ReplayAll() mgr = manager.AgentManager() pollster = pollsters.CPUPollster() counters = list(pollster.get_counters(mgr, self.host)) assert counters self.assertEqual( set([c.name for c in counters]), set(pollster.get_counter_names())) def _verify_cpu_monitoring(name, expected_volume): match = [c for c in counters if c.name == name] self.assertEquals(len(match), 1, 'missing counter %s' % name) self.assertEquals(match[0].volume, expected_volume) self.assertEquals(match[0].type, 'gauge') _verify_cpu_monitoring('cpu.util.1min', 0.1) _verify_cpu_monitoring('cpu.util.5min', 0.2) _verify_cpu_monitoring('cpu.util.15min', 0.3) class TestMemorySpacePollster(TestPollsterBase): def setUp(self): super(TestMemorySpacePollster, self).setUp() @mock.patch('ceilometer.pipeline.setup_pipeline', mock.MagicMock()) def test_get_counters(self): self.inspector_manager.inspect_memoryspace(self.host).AndReturn( hardware_inspector.MemoryStats(total=123456789, used=12345678)) self.mox.ReplayAll() mgr = manager.AgentManager() pollster = pollsters.MemorySpacePollster() counters = list(pollster.get_counters(mgr, self.host)) assert counters self.assertEqual( set([c.name for c in counters]), set(pollster.get_counter_names())) def _verify_memoryspace_monitoring(name, expected_volume): match = [c for c in counters if c.name == name] self.assertEquals(len(match), 1, 'missing counter %s' % name) self.assertEquals(match[0].volume, expected_volume) self.assertEquals(match[0].type, 'gauge') _verify_memoryspace_monitoring('memory.size.total', 123456789) _verify_memoryspace_monitoring('memory.size.used', 12345678) ",,1766,2
openstack%2Ftempest~master~I89105f030162eeb3c824222a40ee193acc654d20,openstack/tempest,master,I89105f030162eeb3c824222a40ee193acc654d20,some basic tests are missing in scenarios.In bug #1201662 I have locked a bug.,ABANDONED,2013-07-16 09:47:22.000000000,2013-07-24 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 1921}, {'_account_id': 8154}]","[{'number': 1, 'created': '2013-07-16 09:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/410b1b3f696611aff53812770363c0e4486687b5', 'message': 'some basic tests\n\nChange-Id: I89105f030162eeb3c824222a40ee193acc654d20\n'}, {'number': 2, 'created': '2013-07-16 11:18:03.000000000', 'files': ['tempest/scenario/test_server_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/39d01dbfe74f25da666c6f31771b234be27e6f8f', 'message': 'some basic tests are missing\nin scenarios.In bug #1201662\nI have locked a bug.\n\nChange-Id: I89105f030162eeb3c824222a40ee193acc654d20\n'}]",2,37204,39d01dbfe74f25da666c6f31771b234be27e6f8f,8,4,2,8154,,,0,"some basic tests are missing
in scenarios.In bug #1201662
I have locked a bug.

Change-Id: I89105f030162eeb3c824222a40ee193acc654d20
",git fetch https://review.opendev.org/openstack/tempest refs/changes/04/37204/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_server_basic_ops.py'],1,410b1b3f696611aff53812770363c0e4486687b5,bug/1201662," def lock_server(self): instance = self.get_resource('instance') instance_id = instance.id LOG.debug(""Lockin server %s. Current status: %s"", instance_id, instance.status) instance.lock() self.status_timeout( self.compute_client.servers, instance_id, 'LOCK') def unlock_server(self): instance = self.get_resource('instance') instance_id = instance.id LOG.debug(""Unlocking server %s. Current status: %s"", instance_id, instance.status) instance.unlock() self.status_timeout( self.compute_client.servers, instance_id, 'ACTIVE') self.lock_server() self.unlock_server()",,20,0
openstack%2Fheat~master~I50ba5fe2933f1eac024b7ed17d767f3d13a2e3c1,openstack/heat,master,I50ba5fe2933f1eac024b7ed17d767f3d13a2e3c1,start of moving the dbinstance into a provider template,ABANDONED,2013-07-12 12:58:50.000000000,2013-07-24 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 6434}, {'_account_id': 7256}]","[{'number': 1, 'created': '2013-07-12 12:58:50.000000000', 'files': ['etc/heat/templates/AWS_RDS_DBInstance.template', 'etc/heat/environment.yaml', 'heat/engine/resources/template_resource.py', 'heat/engine/resources/dbinstance.py', 'heat/engine/resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/48a10a46fb0ce365a634d2a296a5beabb15e8f58', 'message': 'start of moving the dbinstance into a provider template\n\nChange-Id: I50ba5fe2933f1eac024b7ed17d767f3d13a2e3c1\n'}]",1,36822,48a10a46fb0ce365a634d2a296a5beabb15e8f58,6,3,1,4715,,,0,"start of moving the dbinstance into a provider template

Change-Id: I50ba5fe2933f1eac024b7ed17d767f3d13a2e3c1
",git fetch https://review.opendev.org/openstack/heat refs/changes/22/36822/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/heat/templates/AWS_RDS_DBInstance.template', 'etc/heat/environment.yaml', 'heat/engine/resources/dbinstance.py', 'heat/engine/resources/template_resource.py', 'heat/engine/resource.py']",5,48a10a46fb0ce365a634d2a296a5beabb15e8f58,db_provider,"import yamlfrom heat.engine import environment_environment = Nonedef global_env(): global _environment if _environment: return _environment with open('/etc/heat/environment.yaml') as env_fd: _environment = environment.Environment(yaml.safe_load(env_fd.read())) return _environment if cls is None: cls = global_env().get_resource_type(resource_type, resource_name) ",,163,251
openstack%2Fceilometer~master~I0c3c7ca17db5eb5098cab5947934fd24350ad754,openstack/ceilometer,master,I0c3c7ca17db5eb5098cab5947934fd24350ad754,update requires to prevent version cap,ABANDONED,2013-07-11 15:49:41.000000000,2013-07-24 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 2472}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-07-11 15:49:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9a7029ac552903d6056c2fbacc2903d3cb4d1e30', 'message': 'update requires to prevent version cap\n\nbased on talks in openstack-dev group mails\n\nfixes bug #1200214\n\nChange-Id: I0c3c7ca17db5eb5098cab5947934fd24350ad754\n'}, {'number': 2, 'created': '2013-07-11 17:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ea65ed2369da4eb91122fc544b1d8d8eef925ff5', 'message': 'update requires to prevent version cap\n\nbased on talks in openstack-dev group\nmails(http://lists.openstack.org/pipermail/openstack-dev/2013-July/011660.html)\n\nfixes bug #1200214\n\nChange-Id: I0c3c7ca17db5eb5098cab5947934fd24350ad754\n'}, {'number': 3, 'created': '2013-07-12 02:56:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3f6ee3d829b4b482f6578347423f8863b81de220', 'message': 'update requires to prevent version cap\n\nbased on talks in openstack-dev group\nmails(http://lists.openstack.org/pipermail/openstack-dev/2013-July/011660.html)\n\nnow, no upper bould on python-*clients\n\nfixes bug #1200214\n\nChange-Id: I0c3c7ca17db5eb5098cab5947934fd24350ad754\n'}, {'number': 4, 'created': '2013-07-16 16:39:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2a1aa33fba423ba7bd97d3b0e5a950491be486d8', 'message': 'update requires to prevent version cap\n\nOpenStack clients. None of these should have an upper bound\nas that has implications for testing in the gate. An exception\nis currently being made for neutron client because of the need\nfor an incompatible change in their next release.\nhttps://github.com/openstack/requirements\n\nfixes bug #1200214\nChange-Id: I0c3c7ca17db5eb5098cab5947934fd24350ad754\n'}, {'number': 5, 'created': '2013-07-16 17:03:37.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e8c2c9aa7fdba2278422f4470b8d6cdceb67a2eb', 'message': 'update requires to prevent version cap\n\nOpenStack clients. None of these should have an upper bound\nas that has implications for testing in the gate. An exception\nis currently being made for neutron client because of the need\nfor an incompatible change in their next release.\nhttps://github.com/openstack/requirements\n\nfixes bug #1200214\nChange-Id: I0c3c7ca17db5eb5098cab5947934fd24350ad754\n'}]",0,36684,e8c2c9aa7fdba2278422f4470b8d6cdceb67a2eb,17,4,5,6835,,,0,"update requires to prevent version cap

OpenStack clients. None of these should have an upper bound
as that has implications for testing in the gate. An exception
is currently being made for neutron client because of the need
for an incompatible change in their next release.
https://github.com/openstack/requirements

fixes bug #1200214
Change-Id: I0c3c7ca17db5eb5098cab5947934fd24350ad754
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/84/36684/5 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9a7029ac552903d6056c2fbacc2903d3cb4d1e30,bug/1200214,"python-novaclient>=2.12.0,<3 python-keystoneclient>=0.2,<0.4","python-novaclient>=2.6.10 python-keystoneclient>=0.2,<0.3",2,2
openstack%2Fpbr~master~I3b6708444ec8b3d37271c0c8df91fee2cd593088,openstack/pbr,master,I3b6708444ec8b3d37271c0c8df91fee2cd593088,Defer to pip for requirements processing,ABANDONED,2013-07-03 02:28:29.000000000,2013-07-24 06:03:07.000000000,,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2013-07-03 02:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/39601450368513bc18117d1ecea3e8b31c58f2f6', 'message': ""Defer to pip for requirements processing.\n\npip knows what it's doing, we should stop doing its job for it.\nAdditionally, we should not inject version numbers into the\ninstall_requires itself, as upstream pip tells us this is bad form.\ninstall_requires should list the requirement itself, requirements.txt\nshould indicate the version that should be installed.\n\nChange-Id: I3b6708444ec8b3d37271c0c8df91fee2cd593088\n""}, {'number': 2, 'created': '2013-07-03 16:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/119e70748f54a56901514b67a705fad996c628f4', 'message': ""Defer to pip for requirements processing.\n\npip knows what it's doing, we should stop doing its job for it.\nAdditionally, we should not inject version numbers into the\ninstall_requires itself, as upstream pip tells us this is bad form.\ninstall_requires should list the requirement itself, requirements.txt\nshould indicate the version that should be installed.\n\nChange-Id: I3b6708444ec8b3d37271c0c8df91fee2cd593088\n""}, {'number': 3, 'created': '2013-07-03 17:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/eecbd3f5bda03e5f3864156409fe191d9639782d', 'message': ""Defer to pip for requirements processing.\n\npip knows what it's doing, we should stop doing its job for it.\nAdditionally, we should not inject version numbers into the\ninstall_requires itself, as upstream pip tells us this is bad form.\ninstall_requires should list the requirement itself, requirements.txt\nshould indicate the version that should be installed.\n\nChange-Id: I3b6708444ec8b3d37271c0c8df91fee2cd593088\n""}, {'number': 4, 'created': '2013-07-04 16:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/8678069c01190a09868796053e6aa79368184ed4', 'message': ""Defer to pip for requirements processing.\n\npip knows what it's doing, we should stop doing its job for it.\nAdditionally, we should not inject version numbers into the\ninstall_requires itself, as upstream pip tells us this is bad form.\ninstall_requires should list the requirement itself, requirements.txt\nshould indicate the version that should be installed.\n\nChange-Id: I3b6708444ec8b3d37271c0c8df91fee2cd593088\n""}, {'number': 5, 'created': '2013-07-05 02:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/af65408eef519116c4fea6112943514ae5e780fa', 'message': ""Defer to pip for requirements processing.\n\npip knows what it's doing, we should stop doing its job for it.\nAdditionally, we should not inject version numbers into the\ninstall_requires itself, as upstream pip tells us this is bad form.\ninstall_requires should list the requirement itself, requirements.txt\nshould indicate the version that should be installed.\n\nChange-Id: I3b6708444ec8b3d37271c0c8df91fee2cd593088\n""}, {'number': 6, 'created': '2013-07-05 02:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/5a1b82a76016cfacbb54564fc30947ab99c41125', 'message': ""Defer to pip for requirements processing.\n\npip knows what it's doing, we should stop doing its job for it.\nAdditionally, we should not inject version numbers into the\ninstall_requires itself, as upstream pip tells us this is bad form.\ninstall_requires should list the requirement itself, requirements.txt\nshould indicate the version that should be installed.\n\nChange-Id: I3b6708444ec8b3d37271c0c8df91fee2cd593088\n""}, {'number': 7, 'created': '2013-07-16 16:39:57.000000000', 'files': ['pbr/tests/test_setup.py', 'pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/6b498f21c60982cd405c40fc4e156c455ec4a02d', 'message': ""Defer to pip for requirements processing\n\npip knows what it's doing, we should stop doing its job for it.\nAdditionally, we should not inject version numbers into the\ninstall_requires itself, as upstream pip tells us this is bad form.\ninstall_requires should list the requirement itself, requirements.txt\nshould indicate the version that should be installed.\n\nChange-Id: I3b6708444ec8b3d37271c0c8df91fee2cd593088\n""}]",0,35428,6b498f21c60982cd405c40fc4e156c455ec4a02d,21,2,7,2,,,0,"Defer to pip for requirements processing

pip knows what it's doing, we should stop doing its job for it.
Additionally, we should not inject version numbers into the
install_requires itself, as upstream pip tells us this is bad form.
install_requires should list the requirement itself, requirements.txt
should indicate the version that should be installed.

Change-Id: I3b6708444ec8b3d37271c0c8df91fee2cd593088
",git fetch https://review.opendev.org/openstack/pbr refs/changes/28/35428/2 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/tests/test_setup.py', 'pbr/packaging.py', 'pbr/hooks/backwards.py']",3,39601450368513bc18117d1ecea3e8b31c58f2f6,fix-pip-install,," self.config, 'dependency_links', packaging.parse_dependency_links()) packaging.append_text_list(",24,108
openstack%2Fpython-novaclient~master~I558d95d2f8556da8e9a6a65222dc555a19c57480,openstack/python-novaclient,master,I558d95d2f8556da8e9a6a65222dc555a19c57480,Support API fping in shell.,ABANDONED,2013-06-23 03:23:32.000000000,2013-07-24 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1678}, {'_account_id': 1849}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-06-23 03:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/75b8f7b4334cc65b2e286efb622b9b6e936c25fe', 'message': 'Support API fping in shell.\n\nmake novaclient support these API:\nGET /v2/{tenant}/os-fping?all_tenants=1&include=1,2&exclude=3,4\nGET /v2/{tenant}/os-fping/{instance-id}\nalso add some tests for it.\n\nDocImpact\n\nimplemented bp: support-fping-api\n\nChange-Id: I558d95d2f8556da8e9a6a65222dc555a19c57480\n'}, {'number': 2, 'created': '2013-06-23 03:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/1aa6226d2ad1efc685e067efc906491d343b9a70', 'message': 'Support API fping in shell.\n\nmake novaclient support these API:\nGET /v2/{tenant}/os-fping?all_tenants=1&include=1,2&exclude=3,4\nGET /v2/{tenant}/os-fping/{instance-id}\nalso add some tests for it.\n\nDocImpact\n\nimplemented bp: support-fping-api\n\nChange-Id: I558d95d2f8556da8e9a6a65222dc555a19c57480\n'}, {'number': 3, 'created': '2013-06-25 09:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/eebc571207351db642e28db817136049a0dfac58', 'message': 'Support API fping in shell.\n\nmake novaclient support these API:\nGET /v2/{tenant}/os-fping?all_tenants=1&include=1,2&exclude=3,4\nGET /v2/{tenant}/os-fping/{instance-id}\nalso add some tests for it.\n\nDocImpact\n\nimplemented bp: support-fping-api\n\nChange-Id: I558d95d2f8556da8e9a6a65222dc555a19c57480\n'}, {'number': 4, 'created': '2013-07-16 08:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/2253f4cb5ed1aceb2b86f8e15d2b944d1317fdc1', 'message': 'Support API fping in shell.\n\n""It may be interesting for a cloud user or administrator to perform a\nsimple instance monitoring. A ping could be an acceptable solution: it\nis fast and quite reliable. A limit for ping is 1 time a minute by\ndefault.""\n\nThis patch make novaclient support the API:\nGET /v2/{tenant}/os-fping?all_tenants=1&include=1,2&exclude=3,4\nGET /v2/{tenant}/os-fping/{instance-id}\nalso add some tests for it.\n\nDocImpact\n\nimplemented bp: support-fping-api\n\nChange-Id: I558d95d2f8556da8e9a6a65222dc555a19c57480\n'}, {'number': 5, 'created': '2013-07-16 08:53:10.000000000', 'files': ['novaclient/v1_1/contrib/fping.py', 'novaclient/tests/v1_1/fakes.py', 'novaclient/tests/v1_1/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/10788607aa1ef2a681efabe7f222cda9c9f6f809', 'message': 'Support API fping in shell.\n\n""It may be interesting for a cloud user or administrator to perform a\nsimple instance monitoring. A ping could be an acceptable solution: it\nis fast and quite reliable. A limit for ping is 1 time a minute by\ndefault.""\n\nThis patch make novaclient support the API:\nGET /v2/{tenant}/os-fping?all_tenants=1&include=1,2&exclude=3,4\nGET /v2/{tenant}/os-fping/{instance-id}\nalso add some tests for it.\n\nDocImpact\n\nimplemented bp: support-fping-api\n\nChange-Id: I558d95d2f8556da8e9a6a65222dc555a19c57480\n'}]",7,34124,10788607aa1ef2a681efabe7f222cda9c9f6f809,26,5,5,1678,,,0,"Support API fping in shell.

""It may be interesting for a cloud user or administrator to perform a
simple instance monitoring. A ping could be an acceptable solution: it
is fast and quite reliable. A limit for ping is 1 time a minute by
default.""

This patch make novaclient support the API:
GET /v2/{tenant}/os-fping?all_tenants=1&include=1,2&exclude=3,4
GET /v2/{tenant}/os-fping/{instance-id}
also add some tests for it.

DocImpact

implemented bp: support-fping-api

Change-Id: I558d95d2f8556da8e9a6a65222dc555a19c57480
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/24/34124/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/v1_1/fakes.py', 'novaclient/tests/v1_1/test_shell.py', 'novaclient/v1_1/shell.py']",3,75b8f7b4334cc65b2e286efb622b9b6e936c25fe,bp/support-fping-api,"def _translate_fping_keys(collection): _translate_keys(collection, [('id', 'instance_id'), ('project_id', 'project_id'), ('alive', 'alive')]) @utils.arg('--all', dest='all', action='store_true', default=False, help=""Fping all tenants' instances (Admin only)."") @utils.arg('--include', default='', metavar='<include>', help=""Comma separated list of instance id to include in result."") @utils.arg('--exclude', default='', metavar='<exclude>', help=""Comma separated list of instance id to exclude in result."") def do_fping_list(cs, args): """"""Print a list of instances fping result."""""" include = args.include.split(',') if args.include else [] exclude = args.exclude.split(',') if args.exclude else [] fpings = cs.fping.list(all_tenants=args.all, include=include, exclude=exclude) utils.print_list(fpings, ['id', 'project_id', 'alive']) @utils.arg('id', metavar='<id>', help=""ID of instance"") def do_fping_show(cs, args): """"""Show details about the given flavor."""""" server = _find_server(cs, args.id) fping = cs.fping.get(server) utils.print_dict(fping._info)",,63,0
openstack%2Fnova~master~I43eb073fb0280a5457e9ac3433bce136eaa2402a,openstack/nova,master,I43eb073fb0280a5457e9ac3433bce136eaa2402a,Creates parent directory when injecting a file.,ABANDONED,2013-07-08 20:54:49.000000000,2013-07-24 06:03:06.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 2166}, {'_account_id': 6686}, {'_account_id': 7277}]","[{'number': 1, 'created': '2013-07-08 20:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a7f1385111f51edb665b8ef58c025a09c840b20', 'message': 'If necessary, creates the parent directory when injecting a file into the\nguest filesystem.\n\nChecks that the parent directory exists for injected files. If the\nparent directory does not exist, it is created using make_path.\n\nChange-Id: I43eb073fb0280a5457e9ac3433bce136eaa2402a\nFixes: bug 1157923\n'}, {'number': 2, 'created': '2013-07-09 23:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/700d5687af881fb6715aa8d85810bec47806e7b0', 'message': 'Creates parent directory when injecting a file.\n\nChecks that the parent directory exists for injected files. If the\nparent directory does not exist, it is created using make_path.\n\nChange-Id: I43eb073fb0280a5457e9ac3433bce136eaa2402a\nFixes: bug 1157923\n'}, {'number': 3, 'created': '2013-07-10 02:46:44.000000000', 'files': ['nova/tests/virt/test_virt_disk.py', 'nova/virt/disk/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/676f57064e13aa25ed37ad9c08425ce8a705035f', 'message': 'Creates parent directory when injecting a file.\n\nChecks that the parent directory exists for injected files. If the\nparent directory does not exist, it is created using make_path.\n\nChange-Id: I43eb073fb0280a5457e9ac3433bce136eaa2402a\nFixes: bug 1157923\n'}]",0,36129,676f57064e13aa25ed37ad9c08425ce8a705035f,12,6,3,6686,,,0,"Creates parent directory when injecting a file.

Checks that the parent directory exists for injected files. If the
parent directory does not exist, it is created using make_path.

Change-Id: I43eb073fb0280a5457e9ac3433bce136eaa2402a
Fixes: bug 1157923
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/36129/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/disk/api.py'],1,4a7f1385111f51edb665b8ef58c025a09c840b20,bug/1157923, parent_dir = os.path.dirname(path) if not os.path.exists(parent_dir): fs.make_path(parent_dir) ,,5,0
openstack%2Fpython-novaclient~master~I37e3a4ba368b2c3a55041cc34cca3d6e9f597cf9,openstack/python-novaclient,master,I37e3a4ba368b2c3a55041cc34cca3d6e9f597cf9,python3: Fix failure in test suite.,ABANDONED,2013-07-04 16:34:50.000000000,2013-07-24 06:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}]","[{'number': 1, 'created': '2013-07-04 16:34:50.000000000', 'files': ['novaclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/767397ba4e115299ac31941709cb190d3139755b', 'message': 'python3: Fix failure in test suite.\n\nManipulating strings has changed between python2 and python3.\nMake sure that we are slugifying strings properly.\n\nChange-Id: I37e3a4ba368b2c3a55041cc34cca3d6e9f597cf9\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",0,35683,767397ba4e115299ac31941709cb190d3139755b,5,3,1,24,,,0,"python3: Fix failure in test suite.

Manipulating strings has changed between python2 and python3.
Make sure that we are slugifying strings properly.

Change-Id: I37e3a4ba368b2c3a55041cc34cca3d6e9f597cf9
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/83/35683/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/utils.py'],1,767397ba4e115299ac31941709cb190d3139755b,," value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')"," value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore')",2,1
openstack%2Fpython-novaclient~master~Ie363e3a31574833043e36dd15beb9fbbef138edf,openstack/python-novaclient,master,Ie363e3a31574833043e36dd15beb9fbbef138edf,python3: Fix tracebacks while running testsuite.,ABANDONED,2013-07-03 14:30:38.000000000,2013-07-24 06:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5652}]","[{'number': 1, 'created': '2013-07-03 14:30:38.000000000', 'files': ['novaclient/base.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/96c753a8c9a106b6d02f2456368d5f07e347b181', 'message': 'python3: Fix tracebacks while running testsuite.\n\nAccording to PEP 3115, the syntax for changing\nmetaclasses has been altered. So use six to deal\nwith this incompatibility betwen python2 and python3.\n\nChange-Id: Ie363e3a31574833043e36dd15beb9fbbef138edf\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",0,35495,96c753a8c9a106b6d02f2456368d5f07e347b181,7,5,1,24,,,0,"python3: Fix tracebacks while running testsuite.

According to PEP 3115, the syntax for changing
metaclasses has been altered. So use six to deal
with this incompatibility betwen python2 and python3.

Change-Id: Ie363e3a31574833043e36dd15beb9fbbef138edf
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/95/35495/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/base.py'],1,96c753a8c9a106b6d02f2456368d5f07e347b181,,"class ManagerWithFind(six.with_metaclass(abc.ABCMeta, Manager)):",class ManagerWithFind(Manager): __metaclass__ = abc.ABCMeta ,1,3
openstack%2Fpython-novaclient~master~I648305cc23ee84f412aab57f8e3c3dfc301f1d24,openstack/python-novaclient,master,I648305cc23ee84f412aab57f8e3c3dfc301f1d24,python3: Fix tracebacks while running  tests,ABANDONED,2013-07-04 16:43:14.000000000,2013-07-24 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5652}]","[{'number': 1, 'created': '2013-07-04 16:43:14.000000000', 'files': ['novaclient/v1_1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/37e5a691e85b0c961a7d13f4598c86a9ca82cd30', 'message': ""python3: Fix tracebacks while running  tests\n\nWhile running the testsuite under python3, you will\nget the following traceback:\n\nTypeError: 'map' object is not subscriptable\n\nwhich is due to a change in python3. In python3\nmap returns an iterable object of type map,\nand not a subscriptible (i.e. you can write map[i]) list.\n\nChange-Id: I648305cc23ee84f412aab57f8e3c3dfc301f1d24\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n""}]",0,35689,37e5a691e85b0c961a7d13f4598c86a9ca82cd30,7,5,1,24,,,0,"python3: Fix tracebacks while running  tests

While running the testsuite under python3, you will
get the following traceback:

TypeError: 'map' object is not subscriptable

which is due to a change in python3. In python3
map returns an iterable object of type map,
and not a subscriptible (i.e. you can write map[i]) list.

Change-Id: I648305cc23ee84f412aab57f8e3c3dfc301f1d24
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/89/35689/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v1_1/shell.py'],1,37e5a691e85b0c961a7d13f4598c86a9ca82cd30,," simplerows = [x.lower().replace("" "", ""_"") for x in rows] simplerows = [x.lower().replace("" "", ""_"") for x in rows]"," simplerows = map(lambda x: x.lower().replace("" "", ""_""), rows) simplerows = map(lambda x: x.lower().replace("" "", ""_""), rows)",2,2
openstack%2Fdevstack~master~Ifb5cabc8e56594bf54b3e83f3f98f9778341d1cf,openstack/devstack,master,Ifb5cabc8e56594bf54b3e83f3f98f9778341d1cf,Add trunk oslo.config and oslo.messaging,ABANDONED,2013-07-16 17:33:01.000000000,2013-07-24 06:03:03.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-07-16 17:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f80056970db40d38cb347f596c209a4e6a1d9da7', 'message': ""Add trunk oslo.config and oslo.messaging\n\nThe oslo libraries release on the OpenStack cadence, so we should\nbe running their trunk with project's trunk like everything else.\n\nDepends-on: https://review.openstack.org/37294\nChange-Id: Ifb5cabc8e56594bf54b3e83f3f98f9778341d1cf\n""}, {'number': 2, 'created': '2013-07-16 21:41:51.000000000', 'files': ['stackrc', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a40aa4891f0ae29b3c27ca67468b5325c4679068', 'message': ""Add trunk oslo.config and oslo.messaging\n\nThe oslo libraries release on the OpenStack cadence, so we should\nbe running their trunk with project's trunk like everything else.\n\nDepends-on: https://review.openstack.org/37294\nChange-Id: Ifb5cabc8e56594bf54b3e83f3f98f9778341d1cf\n""}]",0,37295,a40aa4891f0ae29b3c27ca67468b5325c4679068,5,3,2,2,,,0,"Add trunk oslo.config and oslo.messaging

The oslo libraries release on the OpenStack cadence, so we should
be running their trunk with project's trunk like everything else.

Depends-on: https://review.openstack.org/37294
Change-Id: Ifb5cabc8e56594bf54b3e83f3f98f9778341d1cf
",git fetch https://review.opendev.org/openstack/devstack refs/changes/95/37295/2 && git format-patch -1 --stdout FETCH_HEAD,"['stackrc', 'stack.sh']",2,f80056970db40d38cb347f596c209a4e6a1d9da7,35705,# Install support libraries # Install oslo.config git_clone $OSLO_CONFIG_REPO $OSLO_CONFIG_DIR $OSLO_CONFIG_BRANCH setup_develop $OSLO_CONFIG_DIR # Install oslo.messaging git_clone $OSLO_MESSAGING_REPO $OSLO_MESSAGING_DIR $OSLO_MESSAGING_BRANCH setup_develop $OSLO_MESSAGING_DIR ,,16,0
openstack%2Fceilometer~master~I3e34c3e87b3d3df63971fe9994afc63fe27594f8,openstack/ceilometer,master,I3e34c3e87b3d3df63971fe9994afc63fe27594f8,Fix missing foreign keys.,MERGED,2013-07-19 11:57:28.000000000,2013-07-24 06:00:19.000000000,2013-07-24 06:00:18.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 4491}, {'_account_id': 6172}, {'_account_id': 6507}]","[{'number': 2, 'created': '2013-07-19 11:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9ddf01fff50b32bc5285407cc58e407baa5e3364', 'message': 'Fix missing foreign keys.\n\nThere are a lot of ForeignKey that had been skipped in database but\ndeclared in models.\nThis migration adds them.\n\nbp: ceilometer-db-sync-models-with-migrations\n\nChange-Id: I3e34c3e87b3d3df63971fe9994afc63fe27594f8\n'}, {'number': 1, 'created': '2013-07-19 11:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6799cb272acea14db71626d520faf183b56f5abd', 'message': 'Fix missing foreign keys.\n\nThere are a lot of ForeignKey that had been skipped in database but\ndeclared in models.\nThis migration adds them.\n\nbp: ceilometer-db-sync-models-with-migrations\n\nChange-Id: I3e34c3e87b3d3df63971fe9994afc63fe27594f8\n'}, {'number': 3, 'created': '2013-07-22 06:30:10.000000000', 'files': ['ceilometer/storage/sqlalchemy/migrate_repo/versions/012_add_missing_foreign_keys.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fa6f980759e9bf810e922ba715ef6e6a64893860', 'message': 'Fix missing foreign keys.\n\nThere are a lot of ForeignKey that had been skipped in database but\ndeclared in models.\nThis migration adds them.\n\nbp: ceilometer-db-sync-models-with-migrations\n\nChange-Id: I3e34c3e87b3d3df63971fe9994afc63fe27594f8\n'}]",0,37885,fa6f980759e9bf810e922ba715ef6e6a64893860,10,5,3,6507,,,0,"Fix missing foreign keys.

There are a lot of ForeignKey that had been skipped in database but
declared in models.
This migration adds them.

bp: ceilometer-db-sync-models-with-migrations

Change-Id: I3e34c3e87b3d3df63971fe9994afc63fe27594f8
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/85/37885/3 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/storage/sqlalchemy/migrate_repo/versions/012_add_missing_foreign_keys.py'],1,9ddf01fff50b32bc5285407cc58e407baa5e3364,bp/ceilometer-db-sync-models-with-migrations,"# -*- encoding: utf-8 -*- # # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from migrate import ForeignKeyConstraint from sqlalchemy import MetaData, Table TABLES = ['resource', 'sourceassoc', 'user', 'project', 'resource', 'meter', 'source', 'trait', 'unique_name', 'event', 'alarm', 'meter'] INDEXES = { ""resource"": (('user_id', 'user', 'id'), ('project_id', 'project', 'id')), ""sourceassoc"": (('user_id', 'user', 'id'), ('project_id', 'project', 'id'), ('resource_id', 'resource', 'id'), ('meter_id', 'meter', 'id'), ('source_id', 'source', 'id')), ""alarm"": (('user_id', 'user', 'id'), ('project_id', 'project', 'id')), ""meter"": (('user_id', 'user', 'id'), ('project_id', 'project', 'id'), ('resource_id', 'resource', 'id'),) } def upgrade(migrate_engine): meta = MetaData(bind=migrate_engine) load_tables = dict((table_name, Table(table_name, meta, autoload=True)) for table_name in TABLES) for table_name, indexes in INDEXES.items(): table = load_tables[table_name] for column, ref_table_name, ref_column_name in indexes: ref_table = load_tables[ref_table_name] params = {'columns': [table.c[column]], 'refcolumns': [ref_table.c[ref_column_name]]} if migrate_engine.name == 'mysql': params['name'] = ""_"".join(('fk', table_name, column)) fkey = ForeignKeyConstraint(**params) fkey.create() def downgrade(migrate_engine): meta = MetaData(bind=migrate_engine) load_tables = dict((table_name, Table(table_name, meta, autoload=True)) for table_name in TABLES) for table_name, indexes in INDEXES.items(): table = load_tables[table_name] for column, ref_table_name, ref_column_name in indexes: ref_table = load_tables[ref_table_name] params = {'columns': [table.c[column]], 'refcolumns': [ref_table.c[ref_column_name]]} if migrate_engine.name == 'mysql': params['name'] = ""_"".join(('fk', table_name, column)) fkey = ForeignKeyConstraint(**params) fkey.drop() ",,67,0
openstack%2Fceilometer~master~I44d569de81f078aef27451382baf0a3061f38be2,openstack/ceilometer,master,I44d569de81f078aef27451382baf0a3061f38be2,Add cleanup migration for indexes.,MERGED,2013-07-19 11:53:40.000000000,2013-07-24 06:00:12.000000000,2013-07-24 06:00:12.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 4491}, {'_account_id': 6172}, {'_account_id': 6507}]","[{'number': 1, 'created': '2013-07-19 11:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8393954f0f472fea5ead008e6d76a5d6f74e924e', 'message': 'Add cleanup migration for indexes.\n\nThere are a lot of extra indexes in database (for primary key).\n\nbp: ceilometer-db-sync-models-with-migrations\n\nChange-Id: I44d569de81f078aef27451382baf0a3061f38be2\n'}, {'number': 2, 'created': '2013-07-22 05:47:26.000000000', 'files': ['ceilometer/storage/sqlalchemy/migrate_repo/versions/011_indexes_cleanup.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5fdc462be0381a5273008a7a7b702a861bffc1a4', 'message': 'Add cleanup migration for indexes.\n\nThere are a lot of extra indexes in database (for primary key).\n\nbp: ceilometer-db-sync-models-with-migrations\n\nChange-Id: I44d569de81f078aef27451382baf0a3061f38be2\n'}]",0,37883,5fdc462be0381a5273008a7a7b702a861bffc1a4,9,5,2,6507,,,0,"Add cleanup migration for indexes.

There are a lot of extra indexes in database (for primary key).

bp: ceilometer-db-sync-models-with-migrations

Change-Id: I44d569de81f078aef27451382baf0a3061f38be2
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/83/37883/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/storage/sqlalchemy/migrate_repo/versions/011_indexes_cleanup.py'],1,8393954f0f472fea5ead008e6d76a5d6f74e924e,bp/ceilometer-db-sync-models-with-migrations,"# -*- encoding: utf-8 -*- # # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from sqlalchemy import Index, MetaData, Table TABLES = ['user', 'source', 'project', 'meter', 'alarm', 'resource', 'sourceassoc'] INDEXES = { ""user"": (('ix_user_id', 'id', False),), ""source"": (('ix_source_id', 'id', False),), ""project"": (('ix_project_id', 'id', False),), ""meter"": (('ix_meter_id', 'id', False),), ""alarm"": (('ix_alarm_id', 'id', False),), ""resource"": (('ix_resource_id', 'id', False),) } actions = {True: 'create', False: 'drop'} def upgrade(migrate_engine): meta = MetaData(bind=migrate_engine) load_tables = dict((table_name, Table(table_name, meta, autoload=True)) for table_name in TABLES) for table_name, indexes in INDEXES.items(): table = load_tables[table_name] for index_name, column, action in indexes: index = Index(index_name, table.c[column]) getattr(index, actions[action])() def downgrade(migrate_engine): meta = MetaData(bind=migrate_engine) load_tables = dict((table_name, Table(table_name, meta, autoload=True)) for table_name in TABLES) for table_name, indexes in INDEXES.items(): table = load_tables[table_name] for index_name, column, action in indexes: index = Index(index_name, table.c[column]) getattr(index, actions[not action])() ",,53,0
openstack%2Ftaskflow~master~Ibfea7f10fc67d5dd3ddfa6f6fe6c08805562998a,openstack/taskflow,master,Ibfea7f10fc67d5dd3ddfa6f6fe6c08805562998a,Provide the length of the flows.,MERGED,2013-07-10 07:01:09.000000000,2013-07-24 05:53:44.000000000,2013-07-24 05:53:44.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2013-07-10 07:01:09.000000000', 'files': ['taskflow/patterns/linear_flow.py', 'taskflow/patterns/graph_flow.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/81d0884d556928ff14054878112bfbb8229931e6', 'message': 'Provide the length of the flows.\n\nIts useful to be able to check if a flow contains\nanything by just inspecting the len() of the flow.\nThis can be used to avoid running a flow in the\nfirst place if nothing is in said flow.\n\nChange-Id: Ibfea7f10fc67d5dd3ddfa6f6fe6c08805562998a\n'}]",0,36398,81d0884d556928ff14054878112bfbb8229931e6,5,2,1,1297,,,0,"Provide the length of the flows.

Its useful to be able to check if a flow contains
anything by just inspecting the len() of the flow.
This can be used to avoid running a flow in the
first place if nothing is in said flow.

Change-Id: Ibfea7f10fc67d5dd3ddfa6f6fe6c08805562998a
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/98/36398/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/patterns/linear_flow.py', 'taskflow/patterns/graph_flow.py']",2,81d0884d556928ff14054878112bfbb8229931e6,master, def __len__(self): return len(self._graph) ,,6,0
openstack%2Ftaskflow~master~Ic2a0ed73a2a7211184deb92d57720ff417429dca,openstack/taskflow,master,Ic2a0ed73a2a7211184deb92d57720ff417429dca,Parents should be frozen after creation.,MERGED,2013-07-10 06:55:59.000000000,2013-07-24 05:53:09.000000000,2013-07-24 05:53:09.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2013-07-10 06:55:59.000000000', 'files': ['taskflow/patterns/base.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1c99d9c32240cddb8b3b001f77d3de3e6c8fd9b6', 'message': 'Parents should be frozen after creation.\n\nUse a tuple to ensure that the parents list\ncan not be mutated after flow creation.\n\nChange-Id: Ic2a0ed73a2a7211184deb92d57720ff417429dca\n'}]",0,36397,1c99d9c32240cddb8b3b001f77d3de3e6c8fd9b6,5,2,1,1297,,,0,"Parents should be frozen after creation.

Use a tuple to ensure that the parents list
can not be mutated after flow creation.

Change-Id: Ic2a0ed73a2a7211184deb92d57720ff417429dca
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/97/36397/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/patterns/base.py'],1,1c99d9c32240cddb8b3b001f77d3de3e6c8fd9b6,master, self.parents = tuple(parents) else: self.parents = tuple([]), self.parents = list(parents) else: self.parents = [],2,2
openstack%2Fnova~master~I8bf10f505a13c82a5faf6e1dbcf7b920d64669d8,openstack/nova,master,I8bf10f505a13c82a5faf6e1dbcf7b920d64669d8,Set the image_ref when booting from a volume.,ABANDONED,2013-07-19 11:03:32.000000000,2013-07-24 05:27:06.000000000,,"[{'_account_id': 3}, {'_account_id': 1501}, {'_account_id': 2166}, {'_account_id': 2861}, {'_account_id': 5292}, {'_account_id': 5511}]","[{'number': 1, 'created': '2013-07-19 11:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3d15e39c29a4885869900672fccfe0dedb0dee8', 'message': 'Set the image_ref when booting from a volume.\n\nFixed Bug 1191069.\n\nChange-Id: I8bf10f505a13c82a5faf6e1dbcf7b920d64669d8\n'}, {'number': 2, 'created': '2013-07-19 11:10:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11df329c4731203327da8fb2588f091d1a0c1d69', 'message': 'Set the image_ref when booting from a volume.\n\nFixed Bug 1191069.\n\nChange-Id: I8bf10f505a13c82a5faf6e1dbcf7b920d64669d8\n'}, {'number': 3, 'created': '2013-07-22 09:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/103575c681ef7d1512d212b7e86f05da4f360725', 'message': 'Set the image_ref when booting from a volume.\n\nWhen booting a VM from a volume, the image information should be retrieved from\nthe system_metadata instead of image_ref. Furthermore, if the original image is deleted, image_meta should be retrieved from volume_image_metadata\nin volume.\n\nFixed Bug 1191069.\n\nChange-Id: I8bf10f505a13c82a5faf6e1dbcf7b920d64669d8\n'}, {'number': 4, 'created': '2013-07-22 10:04:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/345a4d4275c1eac35a8bde293a0f2c9208f42c71', 'message': 'Set the image_ref when booting from a volume.\n\nWhen booting a VM from a volume, the image information should be retrieved from\nthe system_metadata instead of image_ref. Furthermore, if the original image is deleted, image_meta should be retrieved from volume_image_metadata\nin volume.\n\nFixed Bug 1191069.\n\nChange-Id: I8bf10f505a13c82a5faf6e1dbcf7b920d64669d8\n'}, {'number': 5, 'created': '2013-07-22 10:07:30.000000000', 'files': ['nova/compute/api.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0b36bb2b4c656c715b03547a064461d7cdda219e', 'message': 'Set the image_ref when booting from a volume.\n\nWhen booting a VM from a volume, the image information should be retrieved\nfrom the system_metadata instead of image_ref. Furthermore, if the original\nimage is deleted, image_meta should be retrieved from volume_image_metadata\nin volume.\n\nFixed Bug 1191069.\n\nChange-Id: I8bf10f505a13c82a5faf6e1dbcf7b920d64669d8\n'}]",3,37872,0b36bb2b4c656c715b03547a064461d7cdda219e,13,6,5,2861,,,0,"Set the image_ref when booting from a volume.

When booting a VM from a volume, the image information should be retrieved
from the system_metadata instead of image_ref. Furthermore, if the original
image is deleted, image_meta should be retrieved from volume_image_metadata
in volume.

Fixed Bug 1191069.

Change-Id: I8bf10f505a13c82a5faf6e1dbcf7b920d64669d8
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/37872/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/api.py', 'nova/api/openstack/compute/servers.py']",2,f3d15e39c29a4885869900672fccfe0dedb0dee8,bug/1191069, LOG.error(_('image_href is %s.') % img),,3,0
openstack%2Fnova~master~Ib848147225707f1c7eda27b1ba796022161ba20f,openstack/nova,master,Ib848147225707f1c7eda27b1ba796022161ba20f,Allow exceptions to propagate through stevedore map,MERGED,2013-07-12 02:06:02.000000000,2013-07-24 05:09:23.000000000,2013-07-24 05:09:21.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2835}, {'_account_id': 5292}, {'_account_id': 5754}]","[{'number': 1, 'created': '2013-07-12 02:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a9365d307c63d918e6c85655e637312af603f0d', 'message': 'Allow exceptions to propagate through stevedore map\n\nAllow exceptions to propagate up through the stevedore map\nfunction used by the V3 API servers core extension. This allows\nfor functionality such as extension specific parsing of client\nsupplied data formerly required to be handled by the core API to\nbe handled by the extension itself instead.\n\nThis functionality requires stevedore 0.10 or later\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Ib848147225707f1c7eda27b1ba796022161ba20f\n'}, {'number': 2, 'created': '2013-07-12 05:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e038b045bdc3d62b396f9307ab1b8327acdff5e', 'message': 'Allow exceptions to propagate through stevedore map\n\nAllow exceptions to propagate up through the stevedore map\nfunction used by the V3 API servers core extension. This allows\nfor functionality such as extension specific parsing of client\nsupplied data formerly required to be handled by the core API to\nbe handled by the extension itself instead.\n\nThis functionality requires stevedore 0.10 or later\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Ib848147225707f1c7eda27b1ba796022161ba20f\n'}, {'number': 3, 'created': '2013-07-22 11:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb08605fc7a63fd523385ebb8a618dfb247572ea', 'message': 'Allow exceptions to propagate through stevedore map\n\nAllow exceptions to propagate up through the stevedore map\nfunction used by the V3 API servers core extension. This allows\nfor functionality such as extension specific parsing of client\nsupplied data formerly required to be handled by the core API to\nbe handled by the extension itself instead.\n\nThis functionality requires stevedore 0.10 or later\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Ib848147225707f1c7eda27b1ba796022161ba20f\n'}, {'number': 4, 'created': '2013-07-23 01:21:02.000000000', 'files': ['requirements.txt', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/aad95316d4c3e72e4f84a8506a32c21b72d20835', 'message': 'Allow exceptions to propagate through stevedore map\n\nAllow exceptions to propagate up through the stevedore map\nfunction used by the V3 API servers core extension. This allows\nfor functionality such as extension specific parsing of client\nsupplied data formerly required to be handled by the core API to\nbe handled by the extension itself instead.\n\nThis functionality requires stevedore 0.10 or later\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Ib848147225707f1c7eda27b1ba796022161ba20f\n'}]",5,36762,aad95316d4c3e72e4f84a8506a32c21b72d20835,17,7,4,5292,,,0,"Allow exceptions to propagate through stevedore map

Allow exceptions to propagate up through the stevedore map
function used by the V3 API servers core extension. This allows
for functionality such as extension specific parsing of client
supplied data formerly required to be handled by the core API to
be handled by the extension itself instead.

This functionality requires stevedore 0.10 or later

Partially implements blueprint nova-v3-api

Change-Id: Ib848147225707f1c7eda27b1ba796022161ba20f
",git fetch https://review.opendev.org/openstack/nova refs/changes/62/36762/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'nova/api/openstack/compute/plugins/v3/servers.py']",2,9a9365d307c63d918e6c85655e637312af603f0d,bp/nova-v3-api," invoke_kwds={""extension_info"": self.extension_info}, propagate_map_exceptions=True) invoke_kwds={""extension_info"": self.extension_info}, propagate_map_exceptions=True)"," invoke_kwds={""extension_info"": self.extension_info}) invoke_kwds={""extension_info"": self.extension_info})",5,3
openstack%2Fnova~master~Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890,openstack/nova,master,Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890,Add unique constraint to InstanceTypeExtraSpecs.,MERGED,2013-06-26 16:19:26.000000000,2013-07-24 02:39:06.000000000,2013-07-24 02:39:04.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 6849}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-06-26 16:19:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1a2b1c52388a76909feb9584d38cb2ff31cebf8', 'message': ""Add unique constraints to InstanceTypeExtraSpecs.\n\nAdded unique constraint 'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted') to InstanceTypeExtraSpecs model and migrate\nsripts.\nImplementation instance_type_extra_specs_update_or_create in sqlalchemy.api\nrewrited.\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}, {'number': 3, 'created': '2013-06-26 16:19:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33586f7ef4160dba71a6ab3dbc5f85ce8a219f25', 'message': ""Add unique constraints to InstanceTypeExtraSpecs.\n\nAdded unique constraint 'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted') to InstanceTypeExtraSpecs model and migrate\nsripts.\nImplementation instance_type_extra_specs_update_or_create in sqlalchemy.api\nrewrited.\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}, {'number': 2, 'created': '2013-06-26 16:19:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fdcccf0ad3ea6f41cf9f51d8206889cc61fdff9e', 'message': ""Add unique constraints to InstanceTypeExtraSpecs.\n\nAdded unique constraint 'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted') to InstanceTypeExtraSpecs model and migrate\nsripts.\nImplementation instance_type_extra_specs_update_or_create in sqlalchemy.api\nrewrited.\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}, {'number': 4, 'created': '2013-06-27 12:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ed351949d635ab222427ede58f2bc6e39e4efae', 'message': ""Add unique constraints to InstanceTypeExtraSpecs.\n\nAdded unique constraint 'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted') to InstanceTypeExtraSpecs model and migrate\nsripts.\nImplementation instance_type_extra_specs_update_or_create in sqlalchemy.api\nrewrited.\n\nblueprint db-enforce-unique-keys\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}, {'number': 5, 'created': '2013-07-01 12:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c8c4e6c5f718364cb27ec7b96f3efcca73703992', 'message': ""Add unique constraints to InstanceTypeExtraSpecs.\n\nAdded unique constraint 'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted') to InstanceTypeExtraSpecs model and migrate\nsripts.\nImplementation instance_type_extra_specs_update_or_create in sqlalchemy.api\nrewrited.\n\nblueprint db-enforce-unique-keys\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}, {'number': 6, 'created': '2013-07-08 10:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7455c02ed6714bf2f2a3f0615863d1136c837e72', 'message': ""Add unique constraints to InstanceTypeExtraSpecs.\n\nAdded unique constraint 'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted') to InstanceTypeExtraSpecs model and migrate\nsripts.\nImplementation instance_type_extra_specs_update_or_create in sqlalchemy.api\nrewrited.\n\nblueprint db-enforce-unique-keys\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}, {'number': 7, 'created': '2013-07-10 09:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d2ffdf94fd82cc0da1a5273e12ba3eabec45618', 'message': ""Add unique constraints to InstanceTypeExtraSpecs.\n\nAdded unique constraint 'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted') to InstanceTypeExtraSpecs model and migrate\nsripts.\nImplementation instance_type_extra_specs_update_or_create in sqlalchemy.api\nrewritten.\n\nblueprint db-enforce-unique-keys\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}, {'number': 8, 'created': '2013-07-10 14:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8963c96a84feb018ac782563759cf5249567f75c', 'message': ""Add unique constraints to InstanceTypeExtraSpecs.\n\nAdded unique constraint 'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted') to InstanceTypeExtraSpecs model and migrate\nsripts.\nImplementation instance_type_extra_specs_update_or_create in sqlalchemy.api\nrewritten.\n\nblueprint db-enforce-unique-keys\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}, {'number': 9, 'created': '2013-07-10 14:35:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a185614f02c1e123f1f471879dea26f127e167f', 'message': ""Add unique constraints to InstanceTypeExtraSpecs.\n\nAdded unique constraint 'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted') to InstanceTypeExtraSpecs model and migrate\nsripts.\nImplementation instance_type_extra_specs_update_or_create in sqlalchemy.api\nrewritten.\n\nblueprint db-enforce-unique-keys\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}, {'number': 11, 'created': '2013-07-11 08:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce202726a389dceedc0fb2f7441caf7f4f8e85c6', 'message': ""Add unique constraint to InstanceTypeExtraSpecs.\n\nAdded unique constraint\n'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted')\nto InstanceTypeExtraSpecs model and migrate\nscripts.\n\nException from UC violation used in method\ninstance_type_extra_specs_update_or_create()\nfor race condition check.\nGet-update-create procedure will be restarted\nin case race condition.\n\nblueprint db-enforce-unique-keys\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}, {'number': 10, 'created': '2013-07-11 08:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db0ae51b64e1acb127285222a4abd32b7fbe8f57', 'message': ""Add unique constraint to InstanceTypeExtraSpecs.\n\nAdded unique constraint\n'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted')\nto InstanceTypeExtraSpecs model and migrate\nscripts.\n\nException from UC violation used in method\ninstance_type_extra_specs_update_or_create()\nfor race condition check.\nGet-update-create procedure will be restarted\nin case race condition.\n\nblueprint db-enforce-unique-keys\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}, {'number': 12, 'created': '2013-07-12 17:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d9cf62bfc929c7bd844b7722c380e029ffc50d4', 'message': ""Add unique constraint to InstanceTypeExtraSpecs.\n\nAdded unique constraint\n'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted')\nto InstanceTypeExtraSpecs model and migrate\nscripts.\n\nException from UC violation used in method\ninstance_type_extra_specs_update_or_create()\nfor race condition check.\nGet-update-create procedure will be restarted\nin case race condition.\n\nblueprint db-enforce-unique-keys\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}, {'number': 13, 'created': '2013-07-15 12:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd8e6f02e5f1abbc210f597f28bd200e31af9849', 'message': ""Add unique constraint to InstanceTypeExtraSpecs.\n\nAdded unique constraint\n'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted')\nto InstanceTypeExtraSpecs model and migrate\nscripts.\n\nException from UC violation used in method\nflavor_extra_specs_update_or_create()\nfor race condition check.\nGet-update-create procedure will be restarted\nin case race condition.\n\nblueprint db-enforce-unique-keys\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}, {'number': 14, 'created': '2013-07-24 01:31:19.000000000', 'files': ['nova/db/sqlalchemy/models.py', 'nova/db/sqlalchemy/migrate_repo/versions/202_add_instance_type_extra_specs_uc.py', 'nova/tests/db/test_migrations.py', 'nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/abb752763345053b018a25eca932bd4193df72c1', 'message': ""Add unique constraint to InstanceTypeExtraSpecs.\n\nAdded unique constraint\n'uniq_instance_type_extra_specs0instance_type_id0key0deleted'\n('instance_type_id', 'key', 'deleted')\nto InstanceTypeExtraSpecs model and migrate\nscripts.\n\nException from UC violation used in method\nflavor_extra_specs_update_or_create()\nfor race condition check.\nGet-update-create procedure will be restarted\nin case race condition.\n\nblueprint db-enforce-unique-keys\n\nChange-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890\n""}]",37,34578,abb752763345053b018a25eca932bd4193df72c1,77,9,14,7711,,,0,"Add unique constraint to InstanceTypeExtraSpecs.

Added unique constraint
'uniq_instance_type_extra_specs0instance_type_id0key0deleted'
('instance_type_id', 'key', 'deleted')
to InstanceTypeExtraSpecs model and migrate
scripts.

Exception from UC violation used in method
flavor_extra_specs_update_or_create()
for race condition check.
Get-update-create procedure will be restarted
in case race condition.

blueprint db-enforce-unique-keys

Change-Id: Ie91c6fc19ca01526b5f48f85cbb63a6842f9c890
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/34578/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/models.py', 'nova/tests/db/test_db_api.py', 'nova/tests/db/test_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/190_add_instance_type_extra_specs_uc.py', 'nova/db/sqlalchemy/api.py']",5,c1a2b1c52388a76909feb9584d38cb2ff31cebf8,bp/db-enforce-unique-keys,"def _instance_type_extra_specs_safe_create(instance_type_id, specs, session): failed_keys = [] def specs_create(): for key, value in specs.copy().iteritems(): try: session.add(spec_ref) session.flush() except db_exc.DBDuplicateEntry: del specs[key] session.rollback() session.begin() return key return None while True: dup = specs_create() if dup is None: break failed_keys.append(dup) return failed_keys def _instance_type_extra_specs_get_by_keys(context, instance_type_id, keys, session): return model_query(context, models.InstanceTypeExtraSpecs, session=session, read_deleted=""no"").\ filter_by(instance_type_id=instance_type_id).\ filter(models.InstanceTypeExtraSpecs.key.in_(keys)).\ all() @require_context def instance_type_extra_specs_update_or_create(context, flavor_id, specs): session = get_session() session.begin() instance_type_id = \ _instance_type_get_id_from_flavor(context, flavor_id, session) spec_refs = _instance_type_extra_specs_get_by_keys(context, instance_type_id, specs.keys(), session) existing_keys = set([spec_ref[""key""] for spec_ref in spec_refs]) not_existing = dict([(k, v) for k, v in specs.iteritems() if k not in existing_keys]) failed = _instance_type_extra_specs_safe_create(instance_type_id, not_existing, session) if len(failed) != 0: fail_refs = _instance_type_extra_specs_get_by_keys(context, instance_type_id, failed, session) spec_refs.extend(fail_refs) for spec_ref in spec_refs: key = spec_ref[""key""] spec_ref.update({""value"": specs[key]}) session.commit()","@require_context def instance_type_extra_specs_update_or_create(context, flavor_id, specs): # NOTE(boris-42): There is a race condition in this method. We should add # UniqueConstraint on (instance_type_id, key, deleted) to # avoid duplicated instance_type_extra_specs. This will be # possible after bp/db-unique-keys implementation. session = get_session() with session.begin(): instance_type_id = \ _instance_type_get_id_from_flavor(context, flavor_id, session) spec_refs = model_query(context, models.InstanceTypeExtraSpecs, session=session, read_deleted=""no"").\ filter_by(instance_type_id=instance_type_id).\ filter(models.InstanceTypeExtraSpecs.key.in_(specs.keys())).\ all() existing_keys = set() for spec_ref in spec_refs: key = spec_ref[""key""] existing_keys.add(key) spec_ref.update({""value"": specs[key]}) for key, value in specs.iteritems(): if key in existing_keys: continue session.add(spec_ref)",163,26
openstack%2Fos-apply-config~master~Id7b4b25dded8c4bc34eadd7836fd7939b351f365,openstack/os-apply-config,master,Id7b4b25dded8c4bc34eadd7836fd7939b351f365,Fix entry points missed when module was renamed,MERGED,2013-07-24 02:23:41.000000000,2013-07-24 02:23:41.000000000,2013-07-24 02:23:41.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4190}]","[{'number': 1, 'created': '2013-07-24 02:23:41.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/6ed3b5a3324e80bb36e82934862fa4a5aadea6b9', 'message': 'Fix entry points missed when module was renamed\n\nChange-Id: Id7b4b25dded8c4bc34eadd7836fd7939b351f365\n'}]",0,38311,6ed3b5a3324e80bb36e82934862fa4a5aadea6b9,6,3,1,6488,,,0,"Fix entry points missed when module was renamed

Change-Id: Id7b4b25dded8c4bc34eadd7836fd7939b351f365
",git fetch https://review.opendev.org/openstack/os-apply-config refs/changes/11/38311/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,6ed3b5a3324e80bb36e82934862fa4a5aadea6b9,OCC, os-config-applier = os_apply_config.apply_config:main os-apply-config = os_apply_config.apply_config:main, os-config-applier = os_apply_config.os_apply_config:main os-apply-config = os_apply_config.os_apply_config:main,2,2
openstack%2Fopenstack-manuals~master~If891a065f5d0d8c753f88051093aa3691f0420a2,openstack/openstack-manuals,master,If891a065f5d0d8c753f88051093aa3691f0420a2,Remove remaining references to quantum,MERGED,2013-07-19 17:30:55.000000000,2013-07-24 02:07:25.000000000,2013-07-24 02:07:25.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6772}, {'_account_id': 6850}]","[{'number': 1, 'created': '2013-07-19 17:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d985fc08f4aa5d876aa718766200dd5e62653a49', 'message': 'Remove remaining references to quantum\n\nChange-Id: If891a065f5d0d8c753f88051093aa3691f0420a2\n'}, {'number': 2, 'created': '2013-07-19 17:37:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/624203e19babd94740196b7a2c35b343b9476b08', 'message': 'Remove remaining references to quantum\n\nChange-Id: If891a065f5d0d8c753f88051093aa3691f0420a2\n'}, {'number': 4, 'created': '2013-07-19 17:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/16382c20ae0bbc1df42760967754545176969cc5', 'message': 'Remove remaining references to quantum\n\nChange-Id: If891a065f5d0d8c753f88051093aa3691f0420a2\n'}, {'number': 3, 'created': '2013-07-19 17:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e75b7e08451e794f18022dddde0eccd7c669bac7', 'message': 'Remove remaining references to quantum\n\nChange-Id: If891a065f5d0d8c753f88051093aa3691f0420a2\n'}, {'number': 5, 'created': '2013-07-22 16:17:39.000000000', 'files': ['doc/src/docbkx/openstack-network-connectivity-admin/app_demo_flat.xml', 'doc/src/docbkx/common/figures/Neutron-PhysNet-Diagram.png', 'doc/src/docbkx/openstack-security/ch032_networking-best-practices.xml', 'doc/src/docbkx/openstack-install/ch_terminology.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/app_demo_routers_with_private_networks.xml', 'doc/src/docbkx/openstack-security/ch031_neutron-architecture.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/app_core.xml', 'doc/src/docbkx/openstack-security/ch021_paste-and-middleware.xml', 'doc/src/docbkx/openstack-security/ch030_state-of-networking.xml', 'doc/src/docbkx/openstack-security/ch035_case-studies-networking.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_config.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_overview.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_adv_features.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_adv_config.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/figures/Quantum-PhysNet-Diagram.png', 'doc/src/docbkx/openstack-network-connectivity-admin/app_demo_single_router.xml', 'doc/src/docbkx/openstack-security/ch034_tenant-secure-networking-best-practices.xml', 'doc/src/docbkx/openstack-install/ch_externals.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_using.xml', 'doc/src/docbkx/openstack-security/static/1aa-logical-neutron-flow.png', 'doc/src/docbkx/openstack-security/ch033_securing-neutron-services.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/14faa253f2c0c20403db6fcc01e885cf79d0d49c', 'message': 'Remove remaining references to quantum\n\nChange-Id: If891a065f5d0d8c753f88051093aa3691f0420a2\n'}]",0,37946,14faa253f2c0c20403db6fcc01e885cf79d0d49c,24,6,5,6850,,,0,"Remove remaining references to quantum

Change-Id: If891a065f5d0d8c753f88051093aa3691f0420a2
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/46/37946/5 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-network-connectivity-admin/app_demo_flat.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/app_demo_routers_with_private_networks.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/app_core.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_using.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_config.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_overview.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_adv_features.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/figures/Neutron-PhysNet-Diagram.png', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_adv_config.xml']",9,d985fc08f4aa5d876aa718766200dd5e62653a49,goodbye-quantum," <section xml:id=""neutron_server"">"," <section xml:id=""quantum_server"">",19,19
openstack%2Fheat~master~If6a63a5079464758f42d5d5e83dfffb196f4a7f6,openstack/heat,master,If6a63a5079464758f42d5d5e83dfffb196f4a7f6,Only use a token for openstack client operations.,MERGED,2013-07-18 01:48:14.000000000,2013-07-24 00:40:29.000000000,2013-07-24 00:40:28.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-18 01:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e8aac52ffab377b2571ff1c85cb7e59fc84b73d2', 'message': 'Only use a token for openstack client operations.\n\nThis uses the same techniques as horizon for getting client\ninstances with an existing token.\n\nThis change also fetches a new auth_token if the context has none,\nas will happen when the context is created from saved user_creds\nrather than a real request.\n\nWhile it appears that some code paths will result in an extra call to the\nkeystone client, the actual calls to keystone will be less. This is\nbecause each client was making its own calls to keystone when\nauthenticating with a username and password.\n\nImplements blueprint auth-token-only\n\nChange-Id: If6a63a5079464758f42d5d5e83dfffb196f4a7f6\n'}, {'number': 2, 'created': '2013-07-18 20:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e22e6eae4032251808cff6ad6a93c768951edfce', 'message': 'Only use a token for openstack client operations.\n\nThis uses the same techniques as horizon for getting client\ninstances with an existing token.\n\nThis change also fetches a new auth_token if the context has none,\nas will happen when the context is created from saved user_creds\nrather than a real request.\n\nWhile it appears that some code paths will result in an extra call to the\nkeystone client, the actual calls to keystone will be less. This is\nbecause each client was making its own calls to keystone when\nauthenticating with a username and password.\n\nImplements blueprint auth-token-only\n\nChange-Id: If6a63a5079464758f42d5d5e83dfffb196f4a7f6\n'}, {'number': 3, 'created': '2013-07-18 21:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/299409074f47b3e39b733b9a19c49746b0f2ad43', 'message': 'Only use a token for openstack client operations.\n\nThis uses the same techniques as horizon for getting client\ninstances with an existing token.\n\nThis change also fetches a new auth_token if the context has none,\nas will happen when the context is created from saved user_creds\nrather than a real request.\n\nWhile it appears that some code paths will result in an extra call to the\nkeystone client, the actual calls to keystone will be less. This is\nbecause each client was making its own calls to keystone when\nauthenticating with a username and password.\n\nImplements blueprint auth-token-only\n\nChange-Id: If6a63a5079464758f42d5d5e83dfffb196f4a7f6\n'}, {'number': 4, 'created': '2013-07-21 23:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f405974742076ac316fc588856d8491d6784533b', 'message': 'Only use a token for openstack client operations.\n\nThis uses the same techniques as horizon for getting client\ninstances with an existing token.\n\nThis change also fetches a new auth_token if the context has none,\nas will happen when the context is created from saved user_creds\nrather than a real request.\n\nWhile it appears that some code paths will result in an extra call to the\nkeystone client, the actual calls to keystone will be less. This is\nbecause each client was making its own calls to keystone when\nauthenticating with a username and password.\n\nImplements blueprint auth-token-only\n\nChange-Id: If6a63a5079464758f42d5d5e83dfffb196f4a7f6\n'}, {'number': 5, 'created': '2013-07-22 00:42:04.000000000', 'files': ['heat/tests/test_vpc.py', 'heat/tests/utils.py', 'heat/tests/test_s3.py', 'heat/tests/test_parser.py', 'heat/tests/test_swift.py', 'heat/tests/fakes.py', 'heat/common/heat_keystoneclient.py', 'heat/tests/test_quantum.py', 'heat/tests/test_security_group.py', 'heat/engine/clients.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f77195cb6876227b456920cd917a688409c11fdf', 'message': 'Only use a token for openstack client operations.\n\nThis uses the same techniques as horizon for getting client\ninstances with an existing token.\n\nThis change also fetches a new auth_token if the context has none,\nas will happen when the context is created from saved user_creds\nrather than a real request.\n\nWhile it appears that some code paths will result in an extra call to the\nkeystone client, the actual calls to keystone will be less. This is\nbecause each client was making its own calls to keystone when\nauthenticating with a username and password.\n\nImplements blueprint auth-token-only\n\nChange-Id: If6a63a5079464758f42d5d5e83dfffb196f4a7f6\n'}]",0,37604,f77195cb6876227b456920cd917a688409c11fdf,18,4,5,4571,,,0,"Only use a token for openstack client operations.

This uses the same techniques as horizon for getting client
instances with an existing token.

This change also fetches a new auth_token if the context has none,
as will happen when the context is created from saved user_creds
rather than a real request.

While it appears that some code paths will result in an extra call to the
keystone client, the actual calls to keystone will be less. This is
because each client was making its own calls to keystone when
authenticating with a username and password.

Implements blueprint auth-token-only

Change-Id: If6a63a5079464758f42d5d5e83dfffb196f4a7f6
",git fetch https://review.opendev.org/openstack/heat refs/changes/04/37604/5 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_vpc.py', 'heat/tests/utils.py', 'heat/tests/test_s3.py', 'heat/tests/test_parser.py', 'heat/tests/test_swift.py', 'heat/tests/fakes.py', 'heat/common/heat_keystoneclient.py', 'heat/tests/test_quantum.py', 'heat/tests/test_security_group.py', 'heat/engine/clients.py']",10,e8aac52ffab377b2571ff1c85cb7e59fc84b73d2,bp/auth-token-only," @property def auth_token(self): # if there is no auth token in the context # attempt to get one using the context username and password return self.context.auth_token or self.keystone().auth_token if self.auth_token is None: logger.error(""Nova connection failed, no auth_token!"") return None 'username': None, 'api_key': None } management_url = self.url_for(service_type=service_type) client.client.auth_token = self.auth_token client.client.management_url = management_url if self.auth_token is None: logger.error(""Swift connection failed, no auth_token!"") return None 'user': con.username, 'key': None, 'authurl': None, 'preauthtoken': self.auth_token, 'preauthurl': self.url_for(service_type='object-store') } if self.auth_token is None: logger.error(""Quantum connection failed, no auth_token!"") return None 'token': self.auth_token, 'endpoint_url': self.url_for(service_type='network') } if self.auth_token is None: logger.error(""Cinder connection failed, no auth_token!"") return None 'project_id': con.tenant, 'username': None, 'api_key': None } management_url = self.url_for(service_type='volume') self._cinder.client.auth_token = self.auth_token self._cinder.client.management_url = management_url"," } if con.password is not None: args['username'] = con.username args['api_key'] = con.password elif con.auth_token is not None: args['username'] = None args['api_key'] = None else: logger.error(""Nova connection failed, no password or auth_token!"") return None if con.password is None and con.auth_token is not None: management_url = self.url_for(service_type=service_type) client.client.auth_token = con.auth_token client.client.management_url = management_url 'user': con.username } if con.password is not None: args['key'] = con.password args['authurl'] = con.auth_url elif con.auth_token is not None: args['key'] = None args['authurl'] = None args['preauthtoken'] = con.auth_token args['preauthurl'] = self.url_for(service_type='object-store') else: logger.error(""Swift connection failed, no password or "" + ""auth_token!"") return None logger.debug('using existing _quantum') } if con.password is not None: args['username'] = con.username args['password'] = con.password args['tenant_name'] = con.tenant elif con.auth_token is not None: args['token'] = con.auth_token args['endpoint_url'] = self.url_for(service_type='network') else: logger.error(""Quantum connection failed, "" ""no password or auth_token!"") return None logger.debug('quantum args %s', args) 'project_id': con.tenant } if con.password is not None: args['username'] = con.username args['api_key'] = con.password elif con.auth_token is not None: args['username'] = None args['api_key'] = None else: logger.error(""Cinder connection failed, "" ""no password or auth_token!"") return None logger.debug('cinder args %s', args) if con.password is None and con.auth_token is not None: management_url = self.url_for(service_type='volume') self._cinder.client.auth_token = con.auth_token self._cinder.client.management_url = management_url",136,60
openstack%2Fcookbook-openstack-common~master~I180fe8c6a4d0e31e877b91f8cbad54018ef81049,openstack/cookbook-openstack-common,master,I180fe8c6a4d0e31e877b91f8cbad54018ef81049,"Revert ""Correct faulty Chef search query""",MERGED,2013-07-17 04:22:38.000000000,2013-07-24 00:21:56.000000000,2013-07-23 23:53:09.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 216}, {'_account_id': 2340}, {'_account_id': 7572}, {'_account_id': 8185}]","[{'number': 1, 'created': '2013-07-17 04:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/41519e3836035dd602c01783dfd3d30d90714a61', 'message': ""Fix can't convert String into Integer error\n\nWhen a role is present on the current node either the node attributes or a subset are returned depending if section is passed.  Conversely if role is not present on the current node search_for is called which always returns an array.  This is inconsistant.  Since it appears the roles should contain the attributes it doesn't matter which one is return, so the first should suffice.\n\nChange-Id: I180fe8c6a4d0e31e877b91f8cbad54018ef81049\n""}, {'number': 2, 'created': '2013-07-17 06:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/db172f41338c808372253ac09710e6ba02728717', 'message': ""Fix can't convert String into Integer error\n\nWhen a role is present on the current node either the node attributes or a subset are returned depending if section is passed.  Conversely if role is not present on the current node search_for is called which always returns an array.  This is inconsistant.  Since it appears the roles should contain the attributes it doesn't matter which one is return, so the first should suffice.\n\nupdate spec tests stub to properly return an array from search_for\n\nChange-Id: I180fe8c6a4d0e31e877b91f8cbad54018ef81049\n""}, {'number': 3, 'created': '2013-07-23 23:46:15.000000000', 'files': ['libraries/roles.rb', 'CHANGELOG.md', 'metadata.rb', 'spec/roles_spec.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/4af229d56319b44945fe9e8ebd2ab2aa87b29c83', 'message': 'Revert ""Correct faulty Chef search query""\n\nThis reverts commit 8311869e5b99fecefd567ce3f1ad1cbdf8d5c5c6.\n\nWhen a role is present on the current node either the node attributes or a\nsubset are returned depending if section is passed.  Conversely if role is\nnot present on the current node search_for is called which always returns an\narray.  This is inconsistant.  Since it appears the roles should contain the\nattributes it doesn\'t matter which one is return, so the first should suffice.\nUpdate spec tests stub to properly return an array from search_for\n\nChange-Id: I180fe8c6a4d0e31e877b91f8cbad54018ef81049\n'}]",0,37391,4af229d56319b44945fe9e8ebd2ab2aa87b29c83,14,6,3,8185,,,0,"Revert ""Correct faulty Chef search query""

This reverts commit 8311869e5b99fecefd567ce3f1ad1cbdf8d5c5c6.

When a role is present on the current node either the node attributes or a
subset are returned depending if section is passed.  Conversely if role is
not present on the current node search_for is called which always returns an
array.  This is inconsistant.  Since it appears the roles should contain the
attributes it doesn't matter which one is return, so the first should suffice.
Update spec tests stub to properly return an array from search_for

Change-Id: I180fe8c6a4d0e31e877b91f8cbad54018ef81049
",git fetch https://review.opendev.org/openstack/cookbook-openstack-common refs/changes/91/37391/2 && git format-patch -1 --stdout FETCH_HEAD,['libraries/roles.rb'],1,41519e3836035dd602c01783dfd3d30d90714a61,convert-err, section.nil? ? result.first : result.first[section], section.nil? ? result : result[section],1,1
openstack%2Fheat~master~Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9,openstack/heat,master,Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9,make heat-api return a parsable error,MERGED,2013-07-11 15:28:14.000000000,2013-07-24 00:04:56.000000000,2013-07-24 00:04:55.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6800}, {'_account_id': 7135}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 7395}, {'_account_id': 7676}, {'_account_id': 7761}]","[{'number': 1, 'created': '2013-07-11 15:28:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d51e728fc3bb86121c88a225503505e8dbb4ade2', 'message': ""make heat-api return a parsable error\n\nadd a wsgi middleware (faultwrap) that catches exceptions\nand transform those exceptions into a parsable format\naccording to 'Content-Type' of the request.\n\nFixes bug 1158598\n\nChange-Id: Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9\n""}, {'number': 2, 'created': '2013-07-11 16:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9df463102a8092ddc28610fb32a89155c86c58c7', 'message': ""make heat-api return a parsable error\n\nadd a wsgi middleware (faultwrap) that catches exceptions\nand transform those exceptions into a parsable format\naccording to 'Content-Type' of the request.\n\nFixes bug 1158598\n\nChange-Id: Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9\n""}, {'number': 3, 'created': '2013-07-14 14:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a78fd0aea80b27ecbb8456b3762ded1f51625920', 'message': ""make heat-api return a parsable error\n\nadd a wsgi middleware (faultwrap) that catches exceptions\nand transform those exceptions into a parsable format\naccording to 'Content-Type' of the request.\n\nFixes bug 1158598\n\nChange-Id: Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9\n""}, {'number': 4, 'created': '2013-07-15 04:39:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b011bf4f02327f68784064198802eac341fd0f85', 'message': ""make heat-api return a parsable error\n\nadd a wsgi middleware (faultwrap) that catches exceptions\nand transform those exceptions into a parsable format\naccording to 'Content-Type' of the request.\n\nFixes bug 1158598\nImplements blueprint exception-formatting\n\nChange-Id: Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9\n""}, {'number': 5, 'created': '2013-07-17 07:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/44405031fec5fb028877bef0639ae0ff488b9b2f', 'message': ""make heat-api return a parsable error\n\nadd a wsgi middleware (faultwrap) that catches exceptions\nand transform those exceptions into a parsable format\naccording to 'Content-Type' of the request.\n\nFixes bug 1158598\nImplements blueprint exception-formatting\n\nChange-Id: Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9\n""}, {'number': 6, 'created': '2013-07-18 02:40:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e755006d1d658b27d4cf30390df71a19cf994b8e', 'message': ""make heat-api return a parsable error\n\nadd a wsgi middleware (faultwrap) that catches exceptions\nand transform those exceptions into a parsable format\naccording to 'Content-Type' of the request.\n\nFixes bug 1158598\nImplements blueprint exception-formatting\n\nChange-Id: Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9\n""}, {'number': 7, 'created': '2013-07-18 03:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bb8d424a5d625e856e57a98cad1516a26f814761', 'message': ""make heat-api return a parsable error\n\nadd a wsgi middleware (faultwrap) that catches exceptions\nand transform those exceptions into a parsable format\naccording to 'Content-Type' of the request.\n\nFixes bug 1158598\nImplements blueprint exception-formatting\n\nChange-Id: Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9\n""}, {'number': 8, 'created': '2013-07-19 14:11:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cf8f6c376f9bed83df9770297b4c7bcba1e5e6a1', 'message': ""make heat-api return a parsable error\n\nadd a wsgi middleware (faultwrap) that catches exceptions\nand transform those exceptions into a parsable format\naccording to 'Content-Type' of the request.\n\nFixes bug 1158598\nImplements blueprint exception-formatting\n\nChange-Id: Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9\n""}, {'number': 9, 'created': '2013-07-22 01:19:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3a036dd8c149837f9bff5c5c6f45fe2c43d98e37', 'message': ""make heat-api return a parsable error\n\nadd a wsgi middleware (faultwrap) that catches exceptions\nand transform those exceptions into a parsable format\naccording to 'Content-Type' of the request.\n\nFixes bug 1158598\nImplements blueprint exception-formatting\n\nChange-Id: Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9\n""}, {'number': 10, 'created': '2013-07-22 06:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b70af897a598def251d8a893d0ba39aebff7e5ce', 'message': ""make heat-api return a parsable error\n\nadd a wsgi middleware (faultwrap) that catches exceptions\nand transform those exceptions into a parsable format\naccording to 'Content-Type' of the request.\n\nFixes bug 1158598\nImplements blueprint exception-formatting\n\nChange-Id: Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9\n""}, {'number': 11, 'created': '2013-07-23 04:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/76a84a620b776afa3aa340f09c8e45f272d9817d', 'message': ""make heat-api return a parsable error\n\nadd a wsgi middleware (faultwrap) that catches exceptions\nand transform those exceptions into a parsable format\naccording to 'Content-Type' of the request.\n\nFixes bug 1158598\nImplements blueprint exception-formatting\n\nChange-Id: Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9\n""}, {'number': 12, 'created': '2013-07-23 23:02:45.000000000', 'files': ['heat/api/middleware/fault.py', 'heat/api/openstack/__init__.py', 'heat/tests/test_api_openstack_v1.py', 'heat/api/openstack/v1/util.py', 'etc/heat/api-paste.ini', 'heat/common/config.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c5ab33614b465be28d823072ab1fc897313ae6f3', 'message': ""make heat-api return a parsable error\n\nadd a wsgi middleware (faultwrap) that catches exceptions\nand transform those exceptions into a parsable format\naccording to 'Content-Type' of the request.\n\nFixes bug 1158598\nImplements blueprint exception-formatting\n\nChange-Id: Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9\n""}]",25,36678,c5ab33614b465be28d823072ab1fc897313ae6f3,54,16,12,7676,,,0,"make heat-api return a parsable error

add a wsgi middleware (faultwrap) that catches exceptions
and transform those exceptions into a parsable format
according to 'Content-Type' of the request.

Fixes bug 1158598
Implements blueprint exception-formatting

Change-Id: Iacdb8cc119b250ff1e39c99b7a7f66fd4c35e7d9
",git fetch https://review.opendev.org/openstack/heat refs/changes/78/36678/12 && git format-patch -1 --stdout FETCH_HEAD,"['heat/api/middleware/fault.py', 'heat/api/openstack/__init__.py', 'heat/api/openstack/v1/util.py', 'etc/heat/api-paste.ini']",4,d51e728fc3bb86121c88a225503505e8dbb4ade2,bug/1158598,pipeline = faultwrap versionnegotiation authtoken context apiv1app[filter:faultwrap] paste.filter_factory = heat.common.wsgi:filter_factory heat.filter_factory = heat.api.openstack:faultwrap_filter ,pipeline = versionnegotiation authtoken context apiv1app,101,19
openstack%2Fironic~master~I426aa830d35d97af43a80b161697c5618fa85931,openstack/ironic,master,I426aa830d35d97af43a80b161697c5618fa85931,remove improper assert syntax,ABANDONED,2013-07-13 09:59:06.000000000,2013-07-23 23:56:01.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-07-13 09:59:06.000000000', 'files': ['ironic/nova/pxe.py', 'ironic/nova/tilera.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/ed0c3dda4c41c969eb84d77b826ca2f019f3c802', 'message': ""remove improper assert syntax\n\n'assert' raise AssertionError only when run python without '-O' flag. It\nis bad to except Assertionerror to do some bussiness logic.\n\nChange-Id: I426aa830d35d97af43a80b161697c5618fa85931\n""}]",0,36933,ed0c3dda4c41c969eb84d77b826ca2f019f3c802,7,3,1,6835,,,0,"remove improper assert syntax

'assert' raise AssertionError only when run python without '-O' flag. It
is bad to except Assertionerror to do some bussiness logic.

Change-Id: I426aa830d35d97af43a80b161697c5618fa85931
",git fetch https://review.opendev.org/openstack/ironic refs/changes/33/36933/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/nova/pxe.py', 'ironic/nova/tilera.py']",2,ed0c3dda4c41c969eb84d77b826ca2f019f3c802,rm_assert," if not isinstance(network_info, list):"," try: assert isinstance(network_info, list) except AssertionError:",2,6
openstack%2Fswift~master~I727ec2d01c093af61fd3895e5701d87ef67cd9ff,openstack/swift,master,I727ec2d01c093af61fd3895e5701d87ef67cd9ff,Add notes for /srv/node in swift-object-info,MERGED,2013-07-07 09:26:17.000000000,2013-07-23 23:46:52.000000000,2013-07-23 23:46:51.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 866}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-07-07 09:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5b8ef5434c8147a680780025c0ac75ab19b2cbf0', 'message': ""Add notes for /srv/node in swift-object-info\n\n'devices' is set in object-server.conf on each node, not in ring data,\nand the things printed here is just for watching not for running, so\njust leave a note here. (this https://review.openstack.org/#/c/23951/\nis used for running, so just a note is not enough)\n\nmark this commit as bug fixing is because this script is the last place\nusing /srv/node but not from conf as Chmouel said.\n\nfixes bug #885006\n\nChange-Id: I727ec2d01c093af61fd3895e5701d87ef67cd9ff\n""}, {'number': 2, 'created': '2013-07-17 02:15:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/518b71bc4dd91d7e1bba24cbdb5eda8cfa2dbeae', 'message': ""Add notes for /srv/node in swift-object-info\n\n'devices' is set in object-server.conf on each node, not in ring data,\nand the things printed here is just for watching not for running, so\njust leave a note here. (this https://review.openstack.org/#/c/23951/\nis used for running, so just a note is not enough)\n\nmark this commit as bug fixing is because this script is the last place\nusing /srv/node but not from conf as Chmouel said.\n\nfixes bug #885006\n\nChange-Id: I727ec2d01c093af61fd3895e5701d87ef67cd9ff\n""}, {'number': 3, 'created': '2013-07-23 05:48:41.000000000', 'files': ['bin/swift-object-info'], 'web_link': 'https://opendev.org/openstack/swift/commit/63061e37ed098bf1ad509177484037544eb6b089', 'message': ""Add notes for /srv/node in swift-object-info\n\n'devices' is set in object-server.conf on each node, not in ring data,\nand the things printed here is just for watching not for running, so\njust leave a note here. (this https://review.openstack.org/#/c/23951/\nis used for running, so just a note is not enough)\n\nmark this commit as bug fixing is because this script is the last place\nusing /srv/node but not from conf as Chmouel said.\n\nfixes import change on read_metadata\nfixes bug #885006\nChange-Id: I727ec2d01c093af61fd3895e5701d87ef67cd9ff\n""}]",2,35989,63061e37ed098bf1ad509177484037544eb6b089,24,6,3,6835,,,0,"Add notes for /srv/node in swift-object-info

'devices' is set in object-server.conf on each node, not in ring data,
and the things printed here is just for watching not for running, so
just leave a note here. (this https://review.openstack.org/#/c/23951/
is used for running, so just a note is not enough)

mark this commit as bug fixing is because this script is the last place
using /srv/node but not from conf as Chmouel said.

fixes import change on read_metadata
fixes bug #885006
Change-Id: I727ec2d01c093af61fd3895e5701d87ef67cd9ff
",git fetch https://review.opendev.org/openstack/swift refs/changes/89/35989/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift-object-info'],1,5b8ef5434c8147a680780025c0ac75ab19b2cbf0,bug/885006," print print 'note: /srv/node is used as defalut value of `devices`, the real '\ 'is set in object-server.conf on each storage node.'",,3,0
openstack%2Fdevstack-gate~master~Ifa63142b5587846e6c61c9337a9b85489e0f8b87,openstack/devstack-gate,master,Ifa63142b5587846e6c61c9337a9b85489e0f8b87,Fixed pyflakes issues.,MERGED,2013-06-16 21:14:38.000000000,2013-07-23 23:15:24.000000000,2013-07-23 23:15:23.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 7217}]","[{'number': 1, 'created': '2013-06-16 21:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/b2599f36279b40738a3e023e865b6fb0bd8749a5', 'message': 'Fixed pyflakes issues.\n\nChange-Id: Ifa63142b5587846e6c61c9337a9b85489e0f8b87\n'}, {'number': 2, 'created': '2013-06-16 21:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/0a62b6c205cc225f173e7ee7b84b478e89005d6d', 'message': 'Fixed pyflakes issues.\n\nChange-Id: Ifa63142b5587846e6c61c9337a9b85489e0f8b87\n'}, {'number': 3, 'created': '2013-07-19 16:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/1a996e80871b4ca0555f6f0239bdbbdbaf327370', 'message': 'Fixed pyflakes issues.\n\nChange-Id: Ifa63142b5587846e6c61c9337a9b85489e0f8b87\n'}, {'number': 4, 'created': '2013-07-19 16:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/9f04743963e791868eae6df9bbe73e271ffa09df', 'message': 'Fixed pyflakes issues.\n\nChange-Id: Ifa63142b5587846e6c61c9337a9b85489e0f8b87\n'}, {'number': 5, 'created': '2013-07-22 19:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/0c6c6cd745695d3bf390574e25d881d0743fb678', 'message': 'Fixed pyflakes issues.\n\nChange-Id: Ifa63142b5587846e6c61c9337a9b85489e0f8b87\n'}, {'number': 6, 'created': '2013-07-22 22:02:28.000000000', 'files': ['devstack-vm-launch.py', 'tests/test_vmdatabase.py', 'utils.py', 'devstack-vm-inprogress.py', 'devstack-vm-delete.py', 'vmdatabase.py', 'devstack-vm-give.py', 'devstack-vm-reap.py', 'tox.ini', 'devstack-vm-update-image.py'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/20dbec1ff9e1b714128f55f7a9ce61139ff90141', 'message': 'Fixed pyflakes issues.\n\nChange-Id: Ifa63142b5587846e6c61c9337a9b85489e0f8b87\n'}]",0,33208,20dbec1ff9e1b714128f55f7a9ce61139ff90141,26,6,6,2,,,0,"Fixed pyflakes issues.

Change-Id: Ifa63142b5587846e6c61c9337a9b85489e0f8b87
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/08/33208/3 && git format-patch -1 --stdout FETCH_HEAD,"['devstack-vm-launch.py', 'tests/test_vmdatabase.py', 'utils.py', 'devstack-vm-delete.py', 'devstack-vm-inprogress.py', 'vmdatabase.py', 'devstack-vm-give.py', 'devstack-vm-reap.py', 'tox.ini', 'devstack-vm-update-image.py']",10,b2599f36279b40738a3e023e865b6fb0bd8749a5,33205," except Exception: except Exception: except Exception: build_image(provider, client, base_image, remote_base_image, flavor, remote_snap_image_name, branches, timestamp)","import commandsimport socket sp = project.split('/')[0] except Exception, real_error: except Exception, delete_error: except Execption, database_error: remote_snap_image = build_image(provider, client, base_image, remote_base_image, flavor, remote_snap_image_name, branches, timestamp)",18,37
openstack%2Fdevstack-gate~master~I43e4597eccc7a400bad6674ec803028a53e409ad,openstack/devstack-gate,master,I43e4597eccc7a400bad6674ec803028a53e409ad,Fixed some line-length and whitespace warnings.,MERGED,2013-06-16 21:14:38.000000000,2013-07-23 23:15:23.000000000,2013-07-23 23:15:23.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 7217}]","[{'number': 1, 'created': '2013-06-16 21:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ac26ac1fba9c9ddf8561f3860861de6996c1627d', 'message': 'Fixed some line-length warnings.\n\nChange-Id: I43e4597eccc7a400bad6674ec803028a53e409ad\n'}, {'number': 2, 'created': '2013-06-16 21:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/e694fe339cc1f73511ff87d881a48657c91324a9', 'message': 'Fixed some line-length and whitespace warnings.\n\nChange-Id: I43e4597eccc7a400bad6674ec803028a53e409ad\n'}, {'number': 3, 'created': '2013-07-19 16:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/c94098e0ae8623bf0e5d9d3c148aca8f413d22bb', 'message': 'Fixed some line-length and whitespace warnings.\n\nChange-Id: I43e4597eccc7a400bad6674ec803028a53e409ad\n'}, {'number': 4, 'created': '2013-07-19 16:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/dbe1af4561dacd85e145a68eab05c9832f501b36', 'message': 'Fixed some line-length and whitespace warnings.\n\nChange-Id: I43e4597eccc7a400bad6674ec803028a53e409ad\n'}, {'number': 5, 'created': '2013-07-22 19:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/bc0d71294b9ff220aa5ffb380fa9a07bc6bc96eb', 'message': 'Fixed some line-length and whitespace warnings.\n\nChange-Id: I43e4597eccc7a400bad6674ec803028a53e409ad\n'}, {'number': 6, 'created': '2013-07-22 22:02:28.000000000', 'files': ['tests/test_vmdatabase.py', 'utils.py', 'devstack-vm-inprogress.py', 'devstack-vm-delete.py', 'myjenkins.py', 'tox.ini', 'devstack-vm-update-image.py'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/948c1786d6da6b5f147a6b4d24fa589b788dd7b8', 'message': 'Fixed some line-length and whitespace warnings.\n\nChange-Id: I43e4597eccc7a400bad6674ec803028a53e409ad\n'}]",1,33206,948c1786d6da6b5f147a6b4d24fa589b788dd7b8,27,6,6,2,,,0,"Fixed some line-length and whitespace warnings.

Change-Id: I43e4597eccc7a400bad6674ec803028a53e409ad
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/06/33206/6 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_vmdatabase.py', 'utils.py', 'myjenkins.py', 'tox.ini', 'devstack-vm-update-image.py']",5,ac26ac1fba9c9ddf8561f3860861de6996c1627d,33205," remote_snap_image_name = ( '%sdevstack-%s-%s.template.openstack.org' % (DEVSTACK_GATE_PREFIX, base_image.name, str(timestamp)))"," remote_snap_image_name = ('%sdevstack-%s-%s.template.openstack.org' % (DEVSTACK_GATE_PREFIX, base_image.name, str(timestamp)))",57,44
openstack%2Fdevstack-gate~master~I748a0f54416ca540153ed5a9e7edfff739acaaea,openstack/devstack-gate,master,I748a0f54416ca540153ed5a9e7edfff739acaaea,Use testr and flake8.,MERGED,2013-06-16 21:14:37.000000000,2013-07-23 23:14:37.000000000,2013-07-23 23:14:37.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2013-06-16 21:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/55c627c33c931c3875cb34a1c8a219737a9b914a', 'message': 'Use testr and flake8.\n\nChange-Id: I748a0f54416ca540153ed5a9e7edfff739acaaea\n'}, {'number': 2, 'created': '2013-06-16 21:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f5a1ec6d8a600404216d6178c0d77b7a61a45961', 'message': 'Use testr and flake8.\n\nChange-Id: I748a0f54416ca540153ed5a9e7edfff739acaaea\n'}, {'number': 3, 'created': '2013-07-05 13:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/951d9982bf1d3f4f2fcd425b90125076aba98bca', 'message': 'Use testr and flake8.\n\nChange-Id: I748a0f54416ca540153ed5a9e7edfff739acaaea\n'}, {'number': 4, 'created': '2013-07-19 16:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/d6d0233fd99388b38de859d95a6c7ad222ecace9', 'message': 'Use testr and flake8.\n\nChange-Id: I748a0f54416ca540153ed5a9e7edfff739acaaea\n'}, {'number': 5, 'created': '2013-07-19 16:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f978cee72a26fd14631c5967c8c5dc8b3dd96517', 'message': 'Use testr and flake8.\n\nChange-Id: I748a0f54416ca540153ed5a9e7edfff739acaaea\n'}, {'number': 6, 'created': '2013-07-22 22:02:28.000000000', 'files': ['devstack-vm-threshold.py', '.gitignore', 'sshclient.py', 'devstack-vm-check.py', 'tests/test_vmdatabase.py', 'tools/test-requires', 'utils.py', 'devstack-vm-delete.py', '.testr.conf', 'myjenkins.py', 'tox.ini', 'tests/__init__.py'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f5aaf25aa473f82cdb3bf7633f7a4d93e69784c6', 'message': 'Use testr and flake8.\n\nChange-Id: I748a0f54416ca540153ed5a9e7edfff739acaaea\n'}]",5,33205,f5aaf25aa473f82cdb3bf7633f7a4d93e69784c6,27,6,6,2,,,0,"Use testr and flake8.

Change-Id: I748a0f54416ca540153ed5a9e7edfff739acaaea
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/05/33205/2 && git format-patch -1 --stdout FETCH_HEAD,"['devstack-vm-threshold.py', '.gitignore', 'tests/test_vmdatabase.py', 'sshclient.py', 'test-requirements.txt', 'utils.py', '.testr.conf', 'myjenkins.py', 'tox.ini', 'tests/__init__.py']",10,55c627c33c931c3875cb34a1c8a219737a9b914a,33205,,,70,37
openstack%2Fdevstack-gate~master~Icd6a6eb6e6896f88e06ff0c8e9d53b6b34092ad8,openstack/devstack-gate,master,Icd6a6eb6e6896f88e06ff0c8e9d53b6b34092ad8,Set state to deleted when deleting,MERGED,2013-07-22 16:34:59.000000000,2013-07-23 23:10:20.000000000,2013-07-23 23:10:20.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2013-07-22 16:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/530cc6ea6e80ba7f664594120a71ce1c6dea0e63', 'message': 'Set state to deleted when deleting\n\nIn some cases (eg when all servers are deleted), a machine may be\ndeleted even if the current db state is not DELETE (or ERROR).\nIn all cases, if the db state is not DELETE when a machine is\ndeleted, set it to DELETE, so that it will be removed from the\ndb during the next pass.\n\nChange-Id: Icd6a6eb6e6896f88e06ff0c8e9d53b6b34092ad8\n'}, {'number': 2, 'created': '2013-07-22 16:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f4bf56172ee3f1255baf867254e9bd13b274ed8d', 'message': 'Set state to deleted when deleting\n\nIn some cases (e.g. when all servers are deleted), a machine may be\ndeleted even if the current db state is not DELETE (or ERROR).\nIn all cases, if the db state is not DELETE when a machine is\ndeleted, set it to DELETE, so that it will be removed from the\ndb during the next pass.\n\nChange-Id: Icd6a6eb6e6896f88e06ff0c8e9d53b6b34092ad8\n'}, {'number': 3, 'created': '2013-07-22 19:12:47.000000000', 'files': ['devstack-vm-reap.py'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/54cb13ead23a427e156af23f4c33ed1dd96a9807', 'message': 'Set state to deleted when deleting\n\nIn some cases (e.g. when all servers are deleted), a machine may be\ndeleted even if the current db state is not DELETE (or ERROR).\nIn all cases, if the db state is not DELETE when a machine is\ndeleted, set it to DELETE, so that it will be removed from the\ndb during the next pass.\n\nChange-Id: Icd6a6eb6e6896f88e06ff0c8e9d53b6b34092ad8\n'}]",0,38171,54cb13ead23a427e156af23f4c33ed1dd96a9807,14,5,3,1,,,0,"Set state to deleted when deleting

In some cases (e.g. when all servers are deleted), a machine may be
deleted even if the current db state is not DELETE (or ERROR).
In all cases, if the db state is not DELETE when a machine is
deleted, set it to DELETE, so that it will be removed from the
db during the next pass.

Change-Id: Icd6a6eb6e6896f88e06ff0c8e9d53b6b34092ad8
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/71/38171/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-reap.py'],1,530cc6ea6e80ba7f664594120a71ce1c6dea0e63,," if machine.state != vmdatabase.DELETE: utils.log.debug(""Set deleted ID: %s old state: %s"" % ( machine.id, machine.state)) machine.state = vmdatabase.DELETE ",,5,0
openstack%2Fswift~master~Idcbb5a912d8c7d956dac96ff523c1cf1163c98a6,openstack/swift,master,Idcbb5a912d8c7d956dac96ff523c1cf1163c98a6,Move the mount checking into DiskFile constructor,MERGED,2013-07-17 21:42:14.000000000,2013-07-23 23:01:44.000000000,2013-07-23 23:01:44.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-07-17 21:42:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a82f761e7ef6339461188a68016bd7202ccabfe8', 'message': 'Move the mount checking into the _diskfile method\n\nChange-Id: Idcbb5a912d8c7d956dac96ff523c1cf1163c98a6\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 2, 'created': '2013-07-18 18:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3af80c32fa4573cb2b50f83dd31ab98fcf1c4043', 'message': 'Move the mount checking into DiskFile constructor\n\nMove the mount checking into the DiskFile object constructor. The\nREPLICATE method does not use the DiskFile object currently, so that\nmethod still has to perform its own mount check.\n\nWe also refactored the DiskFile exceptions a bit for a hierarchy.\n\nChange-Id: Idcbb5a912d8c7d956dac96ff523c1cf1163c98a6\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 3, 'created': '2013-07-18 20:35:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9b2c7434b505eb83ceb57920516703f720b45c60', 'message': 'Move the mount checking into DiskFile constructor\n\nMove the mount checking into the DiskFile object constructor. The\nREPLICATE method does not use the DiskFile object currently, so that\nmethod still has to perform its own mount check.\n\nWe also refactored the DiskFile exceptions a bit for a hierarchy.\n\nChange-Id: Idcbb5a912d8c7d956dac96ff523c1cf1163c98a6\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 4, 'created': '2013-07-22 14:07:50.000000000', 'files': ['swift/obj/server.py', 'swift/obj/auditor.py', 'test/unit/obj/test_diskfile.py', 'swift/common/exceptions.py', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/fc293a750c8a83ec99d3b462b4689741c1e66a9b', 'message': 'Move the mount checking into DiskFile constructor\n\nMove the mount checking into the DiskFile object constructor. The\nREPLICATE method does not use the DiskFile object currently, so that\nmethod still has to perform its own mount check.\n\nWe also refactored the DiskFile exceptions a bit for a hierarchy.\n\nChange-Id: Idcbb5a912d8c7d956dac96ff523c1cf1163c98a6\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",0,37579,fc293a750c8a83ec99d3b462b4689741c1e66a9b,22,5,4,6198,,,0,"Move the mount checking into DiskFile constructor

Move the mount checking into the DiskFile object constructor. The
REPLICATE method does not use the DiskFile object currently, so that
method still has to perform its own mount check.

We also refactored the DiskFile exceptions a bit for a hierarchy.

Change-Id: Idcbb5a912d8c7d956dac96ff523c1cf1163c98a6
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/79/37579/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/server.py', 'swift/common/exceptions.py']",2,a82f761e7ef6339461188a68016bd7202ccabfe8,diskfile-mount-check,class DiskFileMountError(SwiftException): pass ,,29,13
openstack%2Fnova~master~I2e4a4cf28376d933be47bc496933e6964e19a56e,openstack/nova,master,I2e4a4cf28376d933be47bc496933e6964e19a56e,Sync db.models.Security* and db.models.Volume*.,MERGED,2013-06-19 10:26:36.000000000,2013-07-23 23:01:26.000000000,2013-07-23 23:01:24.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 5652}, {'_account_id': 6172}, {'_account_id': 6507}, {'_account_id': 8003}]","[{'number': 1, 'created': '2013-06-19 10:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5412786d18243d233771d990a5f8ef205967b5c7', 'message': 'Sync db.models.Security* with migrations.\n\nChange-Id: I2e4a4cf28376d933be47bc496933e6964e19a56e\n'}, {'number': 2, 'created': '2013-06-26 08:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c197fce20e26df4e6892cd13a0cc5cae341320b4', 'message': 'Sync db.models.Security* with migrations.\n\nChange-Id: I2e4a4cf28376d933be47bc496933e6964e19a56e\n'}, {'number': 3, 'created': '2013-07-10 10:06:42.000000000', 'files': ['nova/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/704110056b8970770e39263d9231ace4631de307', 'message': 'Sync db.models.Security* and db.models.Volume*.\n\nThis patch syncs models with migrations.\n\nChange-Id: I2e4a4cf28376d933be47bc496933e6964e19a56e\n'}]",8,33627,704110056b8970770e39263d9231ace4631de307,26,9,3,6507,,,0,"Sync db.models.Security* and db.models.Volume*.

This patch syncs models with migrations.

Change-Id: I2e4a4cf28376d933be47bc496933e6964e19a56e
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/33627/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/models.py'],1,5412786d18243d233771d990a5f8ef205967b5c7,bp/db-sync-models-with-migrations," __table_args__ = ( Index('security_group_instance_association_instance_uuid_idx', 'instance_uuid'), ) id = Column(Integer, primary_key=True, nullable=False) security_group_id = Column(Integer, ForeignKey('security_groups.id'), nullable=True) instance_uuid = Column(String(36), ForeignKey('instances.uuid'), nullable=True) __table_args__ = () id = Column(Integer, primary_key=True, nullable=False) name = Column(String(255), nullable=True) description = Column(String(255), nullable=True) user_id = Column(String(255), nullable=True) project_id = Column(String(255), nullable=True) __table_args__ = () id = Column(Integer, primary_key=True, nullable=False) parent_group_id = Column(Integer, ForeignKey('security_groups.id'), nullable=False) protocol = Column(String(5), nullable=True) # ""tcp"", ""udp"", or ""icmp"" from_port = Column(Integer, nullable=True) to_port = Column(Integer, nullable=True) cidr = Column(types.CIDR(), nullable=True) group_id = Column(Integer, ForeignKey('security_groups.id'), nullable=False) __table_args__ = () id = Column(Integer, primary_key=True, nullable=False) protocol = Column(String(5), nullable=True) # ""tcp"", ""udp"" or ""icmp"" from_port = Column(Integer, nullable=True) to_port = Column(Integer, nullable=True) cidr = Column(types.CIDR(), nullable=True)"," id = Column(Integer, primary_key=True) security_group_id = Column(Integer, ForeignKey('security_groups.id')) instance_uuid = Column(String(36), ForeignKey('instances.uuid')) id = Column(Integer, primary_key=True) name = Column(String(255)) description = Column(String(255)) user_id = Column(String(255)) project_id = Column(String(255)) id = Column(Integer, primary_key=True) parent_group_id = Column(Integer, ForeignKey('security_groups.id')) protocol = Column(String(5)) # ""tcp"", ""udp"", or ""icmp"" from_port = Column(Integer) to_port = Column(Integer) cidr = Column(types.CIDR()) group_id = Column(Integer, ForeignKey('security_groups.id')) id = Column(Integer, primary_key=True) protocol = Column(String(5)) # ""tcp"", ""udp"" or ""icmp"" from_port = Column(Integer) to_port = Column(Integer) cidr = Column(types.CIDR())",31,20
openstack%2Fnova~master~I8e16375fe48744513167272e956cdbfdbfd8af23,openstack/nova,master,I8e16375fe48744513167272e956cdbfdbfd8af23,Sync 10 DB models and migrations.,MERGED,2013-06-18 11:04:05.000000000,2013-07-23 23:01:12.000000000,2013-07-23 23:01:10.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2889}, {'_account_id': 5511}, {'_account_id': 5652}, {'_account_id': 6172}, {'_account_id': 6507}]","[{'number': 1, 'created': '2013-06-18 11:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d5069248c64b3c8e632454657084f27d43455241', 'message': 'Brought into line models and migrations.\n\nThis patch syncs models with migrations for:\n  - AggregateMetadata\n  - BandwidthUsage\n  - BlockDeviceMapping\n  - Console\n  - ConsolePool\n  - DNSDomain\n  - FixedIp\n  - FloatingIp\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I8e16375fe48744513167272e956cdbfdbfd8af23\n'}, {'number': 2, 'created': '2013-06-18 13:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5135c12483247dfbb43d694cac3eacc4713dc40e', 'message': 'Sync models and migrations.\n\nThis patch syncs models with migrations for:\n  - AggregateMetadata\n  - BandwidthUsage\n  - BlockDeviceMapping\n  - Console\n  - ConsolePool\n  - DNSDomain\n  - FixedIp\n  - FloatingIp\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I8e16375fe48744513167272e956cdbfdbfd8af23\n'}, {'number': 3, 'created': '2013-06-19 06:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6915865526bceb6a76bb5db563a123ba29879479', 'message': 'Sync models and migrations.\n\nThis patch syncs models with migrations for:\n  - AggregateMetadata\n  - BandwidthUsage\n  - BlockDeviceMapping\n  - Console\n  - ConsolePool\n  - DNSDomain\n  - FixedIp\n  - FloatingIp\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I8e16375fe48744513167272e956cdbfdbfd8af23\n'}, {'number': 4, 'created': '2013-06-24 06:36:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8fe7cd27fb48ec86bfc035e5e17c116165c8c05c', 'message': 'Sync models and migrations.\n\nThis patch syncs models with migrations for:\n  - AggregateMetadata\n  - BandwidthUsage\n  - BlockDeviceMapping\n  - Console\n  - ConsolePool\n  - DNSDomain\n  - FixedIp\n  - FloatingIp\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I8e16375fe48744513167272e956cdbfdbfd8af23\n'}, {'number': 5, 'created': '2013-06-25 12:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/94fde082e731ce2099a52953256fc260b8c64310', 'message': 'Sync models and migrations.\n\nThis patch syncs models with migrations for:\n- BlockDeviceMapping\n- FixedIp\n- FloatingIp\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I8e16375fe48744513167272e956cdbfdbfd8af23\n'}, {'number': 6, 'created': '2013-06-28 13:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d2882698d61b8d59c9c16154eeadc46c389430eb', 'message': 'Sync models and migrations.\n\nThis patch syncs models with migrations for:\n- BlockDeviceMapping\n- FixedIp\n- FloatingIp\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I8e16375fe48744513167272e956cdbfdbfd8af23\n'}, {'number': 7, 'created': '2013-07-09 08:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1bfc566330b25dca6f156a36911b9c46822eae48', 'message': 'Sync BlockDeviceMapping, FixedIp, FloatingIp in models with migrations.\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I8e16375fe48744513167272e956cdbfdbfd8af23\n'}, {'number': 8, 'created': '2013-07-09 08:57:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/874ddb5d91b531981ebf7eda29fb8ca9aaeb59ed', 'message': 'Sync BlockDeviceMapping, FixedIp, FloatingIp.\n\nThis patch syncs models with migrations for:\n- BlockDeviceMapping\n- FixedIp\n- FloatingIp\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I8e16375fe48744513167272e956cdbfdbfd8af23\n'}, {'number': 9, 'created': '2013-07-10 11:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/525c0a266364cb5e434b8ac2e033fb703d614968', 'message': 'Sync models and migrations.\n\nThis patch syncs models with migrations for:\n- BlockDeviceMapping\n- IscsiTarget\n- FixedIp\n- FloatingIp\n- KeyPair\n- Migration\n- Network\n- ProviderFirewallRule\n- Reservation\n- S3Image\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I8e16375fe48744513167272e956cdbfdbfd8af23\n'}, {'number': 10, 'created': '2013-07-11 05:27:19.000000000', 'files': ['nova/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b1ee1f9f2d9a5fc79101ee5201763f771c7a35ec', 'message': 'Sync 10 DB models and migrations.\n\nThis patch syncs models with migrations for:\n- BlockDeviceMapping\n- IscsiTarget\n- FixedIp\n- FloatingIp\n- KeyPair\n- Migration\n- Network\n- ProviderFirewallRule\n- Reservation\n- S3Image\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: I8e16375fe48744513167272e956cdbfdbfd8af23\n'}]",22,33426,b1ee1f9f2d9a5fc79101ee5201763f771c7a35ec,60,12,10,6507,,,0,"Sync 10 DB models and migrations.

This patch syncs models with migrations for:
- BlockDeviceMapping
- IscsiTarget
- FixedIp
- FloatingIp
- KeyPair
- Migration
- Network
- ProviderFirewallRule
- Reservation
- S3Image

Blueprint: db-sync-models-with-migrations

Change-Id: I8e16375fe48744513167272e956cdbfdbfd8af23
",git fetch https://review.opendev.org/openstack/nova refs/changes/26/33426/10 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/models.py'],1,d5069248c64b3c8e632454657084f27d43455241,bp/db-sync-models-with-migrations," __table_args__ = ( Index('block_device_mapping_instance_uuid_device_name_idx', 'instance_uuid', 'device_name'), Index('block_device_mapping_instance_uuid_volume_id_idx', 'instance_uuid', 'volume_id')) __table_args__ = ( Index('fixed_ips_virtual_interface_id_fkey', 'virtual_interface_id'), Index('network_id', 'network_id'), Index('address', 'address'), Index('fixed_ips_instance_uuid_fkey', 'instance_uuid'), Index('fixed_ips_host_idx', 'host'), Index('fixed_ips_network_id_host_deleted_idx', 'network_id', 'host', 'deleted'), Index('fixed_ips_address_reserved_network_id_deleted_idx', 'address', 'reserved', 'network_id', 'deleted'), Index('fixed_ips_deleted_allocated_idx', 'address', 'deleted', 'allocated') ) Index('floating_ips_host_idx', 'host'), Index('floating_ips_project_id_idx', 'project_id'), Index('floating_ips_pool_deleted_fixed_ip_id_project_id_idx', 'pool', 'deleted', 'fixed_ip_id', 'project_id') __table_args__ = ( Index('dns_domains_domain_deleted_idx', 'domain', 'deleted'), ) __table_args__ = () __table_args__ = ( Index('consoles_instance_uuid_idx', 'instance_uuid'), ) __table_args__ = ( Index('aggregate_metadata_key_idx', 'key'), ) __table_args__ = ( Index('bw_usage_cache_uuid_start_period_idx', 'uuid', 'start_period'), )",,36,0
openstack%2Fpuppet-swift~master~Icc08c10db35e48ad60ef480924212549c103b776,openstack/puppet-swift,master,Icc08c10db35e48ad60ef480924212549c103b776,DO NOT MERGE - Debug puppet-lint,ABANDONED,2013-07-17 21:55:17.000000000,2013-07-23 22:58:01.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2265}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-07-17 21:55:17.000000000', 'files': ['Rakefile'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/c18d2856f50ac9e365a553072f1c4eed360ad3a7', 'message': 'DO NOT MERGE - Debug puppet-lint\n\nChange-Id: Icc08c10db35e48ad60ef480924212549c103b776\n'}]",0,37581,c18d2856f50ac9e365a553072f1c4eed360ad3a7,6,4,1,7156,,,0,"DO NOT MERGE - Debug puppet-lint

Change-Id: Icc08c10db35e48ad60ef480924212549c103b776
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/81/37581/1 && git format-patch -1 --stdout FETCH_HEAD,['Rakefile'],1,c18d2856f50ac9e365a553072f1c4eed360ad3a7,test_puppet_lint,require 'puppet-lint' PuppetLint.configuration.log_format = '%{filename} %{path} %{fullpath} %{linenumber} %{kind} %{check} %{message}',,3,0
openstack%2Ftrove-integration~master~I6d95ba9c0946fb31a219c0d00438f42b636599c1,openstack/trove-integration,master,I6d95ba9c0946fb31a219c0d00438f42b636599c1,Removed restart tests from blackbox group,MERGED,2013-07-23 20:49:43.000000000,2013-07-23 22:49:43.000000000,2013-07-23 22:49:43.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 739}, {'_account_id': 1375}, {'_account_id': 5293}, {'_account_id': 6268}, {'_account_id': 7092}]","[{'number': 1, 'created': '2013-07-23 20:49:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/0322688c123378f917faa354097226d47e45d1b5', 'message': 'Removed restart tests from blackbox group\n\nRemoving the restart tests from the integration blackbox group. This\ntest has been causing intermittent failures due to an indeterministic\ninteraction with upstart, so pulling it out of the group until we figure\nout a long term fix.\n\nFixes bug: bug/1204235\n\nChange-Id: I6d95ba9c0946fb31a219c0d00438f42b636599c1\n'}, {'number': 2, 'created': '2013-07-23 21:35:46.000000000', 'files': ['tests/integration/int_tests.py'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/a9172a428a6b52c25843a2fb0bc497d7e2a8653b', 'message': 'Removed restart tests from blackbox group\n\nRemoving the restart tests from the integration blackbox group. This\ntest has been causing intermittent failures due to an indeterministic\ninteraction with upstart, so pulling it out of the group until we figure\nout a long term fix.\n\nFixes bug: bug/1204235\n\nChange-Id: I6d95ba9c0946fb31a219c0d00438f42b636599c1\n'}]",2,38368,a9172a428a6b52c25843a2fb0bc497d7e2a8653b,16,7,2,5293,,,0,"Removed restart tests from blackbox group

Removing the restart tests from the integration blackbox group. This
test has been causing intermittent failures due to an indeterministic
interaction with upstart, so pulling it out of the group until we figure
out a long term fix.

Fixes bug: bug/1204235

Change-Id: I6d95ba9c0946fb31a219c0d00438f42b636599c1
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/68/38368/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/integration/int_tests.py'],1,0322688c123378f917faa354097226d47e45d1b5,bug/1204235,," ""dbaas.api.instances.actions.restart"",",0,1
openstack%2Fhorizon~master~I94f704990efc4ea6348c5707c774e1141ef1f3c2,openstack/horizon,master,I94f704990efc4ea6348c5707c774e1141ef1f3c2,fix r'home/$' in url partten,MERGED,2013-07-22 06:31:42.000000000,2013-07-23 22:00:14.000000000,2013-07-23 22:00:14.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 1952}, {'_account_id': 2455}, {'_account_id': 6914}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-22 06:31:42.000000000', 'files': ['horizon/site_urls.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e4f5edb9a48400b1c17b590b66395df047b8e965', 'message': ""fix r'home/$' in url partten\n\nr'home/$' will match a container-name like 'test-name' or a path like\n'somepath/a-key-name-home'. It should be r'^home/$'\n\nfixes bug #1202079\n\nChange-Id: I94f704990efc4ea6348c5707c774e1141ef1f3c2\n""}]",0,38105,e4f5edb9a48400b1c17b590b66395df047b8e965,9,6,1,6835,,,0,"fix r'home/$' in url partten

r'home/$' will match a container-name like 'test-name' or a path like
'somepath/a-key-name-home'. It should be r'^home/$'

fixes bug #1202079

Change-Id: I94f704990efc4ea6348c5707c774e1141ef1f3c2
",git fetch https://review.opendev.org/openstack/horizon refs/changes/05/38105/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/site_urls.py'],1,e4f5edb9a48400b1c17b590b66395df047b8e965,bug/1202079," url(r'^home/$', 'user_home', name='user_home')"," url(r'home/$', 'user_home', name='user_home')",1,1
openstack%2Ftempest~master~I74339662ab769e005cb79b2d741a04640c5546ce,openstack/tempest,master,I74339662ab769e005cb79b2d741a04640c5546ce,Add isolated tenants for admin compute tests,MERGED,2013-07-22 21:29:11.000000000,2013-07-23 22:00:08.000000000,2013-07-23 22:00:07.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-22 21:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7cdbc44216b3f69783f678485882acf45f242612', 'message': 'Add isolated tenants for admin tests.\n\nThis adds support for isolated credentials on admin tests. Previously\nthe admin tests just ran with the admin username, password, and\ntenant from the config file. This changes that behavior by getting\nisolated credentials for the admin base test class and then adding\nthe create user to the admin role.\n\nThis may fix a race condition uncovered by the testr runs.\n\nPossibly part of: bp speed-up-tempest\n\nChange-Id: I74339662ab769e005cb79b2d741a04640c5546ce\n'}, {'number': 2, 'created': '2013-07-22 21:37:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4d7a9547ae6497d6d87ea93287656eb75c7f6df8', 'message': 'Add isolated tenants for admin compute tests\n\nThis adds support for isolated credentials on admin tests. Previously\nthe admin tests just ran with the admin username, password, and\ntenant from the config file. This changes that behavior by getting\nisolated credentials for the admin base test class and then adding\nthe create user to the admin role.\n\nThis may fix a race condition uncovered by the testr runs.\n\nPossibly part of: bp speed-up-tempest\n\nChange-Id: I74339662ab769e005cb79b2d741a04640c5546ce\n'}, {'number': 3, 'created': '2013-07-23 18:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/70292d420f3dbb50ea0396004582a7e2df0705d1', 'message': 'Add isolated tenants for admin compute tests\n\nThis adds support for isolated credentials on admin tests. Previously\nthe admin tests just ran with the admin username, password, and\ntenant from the config file. This changes that behavior by getting\nisolated credentials for the admin base test class and then adding\nthe create user to the admin role.\n\nThis may fix a race condition uncovered by the testr runs.\n\nPossibly part of: bp speed-up-tempest\n\nChange-Id: I74339662ab769e005cb79b2d741a04640c5546ce\n'}, {'number': 4, 'created': '2013-07-23 20:56:44.000000000', 'files': ['tempest/api/compute/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/47ff791416dea008a51e0a2b36b088778c0e1fb5', 'message': 'Add isolated tenants for admin compute tests\n\nThis adds support for isolated credentials on admin tests. Previously\nthe admin tests just ran with the admin username, password, and\ntenant from the config file. This changes that behavior by getting\nisolated credentials for the admin base test class and then adding\nthe create user to the admin role.\n\nThis may fix a race condition uncovered by the testr runs.\n\nPossibly part of: bp speed-up-tempest\n\nChange-Id: I74339662ab769e005cb79b2d741a04640c5546ce\n'}]",2,38203,47ff791416dea008a51e0a2b36b088778c0e1fb5,18,6,4,5196,,,0,"Add isolated tenants for admin compute tests

This adds support for isolated credentials on admin tests. Previously
the admin tests just ran with the admin username, password, and
tenant from the config file. This changes that behavior by getting
isolated credentials for the admin base test class and then adding
the create user to the admin role.

This may fix a race condition uncovered by the testr runs.

Possibly part of: bp speed-up-tempest

Change-Id: I74339662ab769e005cb79b2d741a04640c5546ce
",git fetch https://review.opendev.org/openstack/tempest refs/changes/03/38203/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/base.py'],1,7cdbc44216b3f69783f678485882acf45f242612,admin_isolation," def _get_isolated_creds(cls, admin=False): #Assign admin role if this is for admin creds if admin: _, roles = admin_client.list_roles() role = None for r in roles: if r['name'] == 'admin': role = r break if not role: msg = ""No admin role found"" raise exceptions.NotFound(msg) admin_client.assign_user_role(tenant['id'], user['id'], role['id']) if cls.config.compute.allow_tenant_isolation: creds = cls._get_isolated_creds(admin=True) admin_username, admin_tenant_name, admin_password = creds cls.os_adm = clients.Manager(username=admin_username, password=admin_password, tenant_name=admin_tenant_name, interface=cls._interface) else: cls.os_adm = clients.ComputeAdminManager(interface=cls._interface)", def _get_isolated_creds(cls): cls.os_adm = clients.ComputeAdminManager(interface=cls._interface),23,4
openstack%2Fnova~master~Ia6c1bad5c3cc35e772c32803c27a50a7728045e5,openstack/nova,master,Ia6c1bad5c3cc35e772c32803c27a50a7728045e5,Clarify flavorid vs instance_type_id in db,MERGED,2013-07-10 10:36:09.000000000,2013-07-23 21:59:57.000000000,2013-07-23 21:59:55.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2711}]","[{'number': 1, 'created': '2013-07-10 10:36:09.000000000', 'files': ['nova/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5dc997c26bdb002e51a8da22ae9e81170d3c94f7', 'message': 'Clarify flavorid vs instance_type_id in db\n\nAnd add comment about future direction.\n\nPartially implements bp flavor-instance-type-dedup\n\nChange-Id: Ia6c1bad5c3cc35e772c32803c27a50a7728045e5\n'}]",0,36428,5dc997c26bdb002e51a8da22ae9e81170d3c94f7,9,6,1,1849,,,0,"Clarify flavorid vs instance_type_id in db

And add comment about future direction.

Partially implements bp flavor-instance-type-dedup

Change-Id: Ia6c1bad5c3cc35e772c32803c27a50a7728045e5
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/36428/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/models.py'],1,5dc997c26bdb002e51a8da22ae9e81170d3c94f7,bp/flavor-instance-type-dedup," # *not* flavorid, this is the internal primary_key """"""Represents possible flavors for instances. Note: instance_type and flavor are synonyms and the term instance_type is deprecated and in the process of being removed. """""" # Internal only primary key/id # Public facing id will be renamed public_id"," # *not* flavor_id """"""Represent possible instance_types or flavor of VM offered.""""""",8,2
openstack%2Fsahara~master~I458f9986f924bf553e68fd7c41390c853c340b2b,openstack/sahara,master,I458f9986f924bf553e68fd7c41390c853c340b2b,Fix delete templates that are in use,MERGED,2013-07-19 10:39:43.000000000,2013-07-23 21:53:58.000000000,2013-07-23 21:53:58.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}]","[{'number': 1, 'created': '2013-07-19 10:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/51accefd985fe15aad2359398cb9b6060de4bd32', 'message': 'Fix delete templates that are in use\n\nChange-Id: I458f9986f924bf553e68fd7c41390c853c340b2b\nFixes: bug #1201876\n'}, {'number': 2, 'created': '2013-07-19 11:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/22b40142eefaa2287246debe4a7bd56885af31d5', 'message': 'Fix delete templates that are in use\n\nChange-Id: I458f9986f924bf553e68fd7c41390c853c340b2b\nFixes: bug #1201876\n'}, {'number': 3, 'created': '2013-07-19 11:50:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/6776402cd4eb4c992c52a2a43750816c4f81fa3e', 'message': 'Fix delete templates that are in use\n\nFixes: bug #1201876\n\nChange-Id: I458f9986f924bf553e68fd7c41390c853c340b2b\n'}, {'number': 4, 'created': '2013-07-19 13:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f96faafde6ab5671ec9dd386f97ad9b2b334abc7', 'message': 'Fix delete templates that are in use\n\nFixes: bug #1201876\n\nChange-Id: I458f9986f924bf553e68fd7c41390c853c340b2b\n'}, {'number': 5, 'created': '2013-07-23 10:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/fe5acf840b972f4c0ab287013e4ad11043ad163f', 'message': 'Fix delete templates that are in use\n\nFixes: bug #1201876\n\nChange-Id: I458f9986f924bf553e68fd7c41390c853c340b2b\n'}, {'number': 7, 'created': '2013-07-23 10:44:09.000000000', 'files': ['savanna/service/validations/node_group_templates.py', 'savanna/service/validations/cluster_templates.py', 'savanna/api/v10.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/11c3cb0b42ae7825e40add1b28f1c9b91ecd500a', 'message': 'Fix delete templates that are in use\n\nFixes: bug #1201876\n\nChange-Id: I458f9986f924bf553e68fd7c41390c853c340b2b\n'}, {'number': 6, 'created': '2013-07-23 10:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/be8402c7f18ab6718661a77acca8f4dcf5af6965', 'message': 'Fix delete templates that are in use\n\nFixes: bug #1201876\n\nChange-Id: I458f9986f924bf553e68fd7c41390c853c340b2b\n'}]",14,37868,11c3cb0b42ae7825e40add1b28f1c9b91ecd500a,44,5,7,7710,,,0,"Fix delete templates that are in use

Fixes: bug #1201876

Change-Id: I458f9986f924bf553e68fd7c41390c853c340b2b
",git fetch https://review.opendev.org/openstack/sahara refs/changes/68/37868/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/service/validation.py', 'savanna/api/v10.py']",2,51accefd985fe15aad2359398cb9b6060de4bd32,bug/1201876,@v.check_use('cluster_template_id')@v.check_use('node_group_template_id'),,43,0
openstack%2Fnova~master~I647795907b22790759d3be74afcaf70b712cb338,openstack/nova,master,I647795907b22790759d3be74afcaf70b712cb338,Fix DB access when refreshing the network cache.,MERGED,2013-07-18 15:18:05.000000000,2013-07-23 21:52:51.000000000,2013-07-23 21:52:48.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 7450}, {'_account_id': 8122}]","[{'number': 1, 'created': '2013-07-18 15:18:05.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3379e95515dbc4f0574a9c030127ba19ba07f0e2', 'message': 'Fix DB access when refreshing the network cache.\n\nWhen calling ComputeManager.attach_interface(), the following happens:\n\n1) self.network_api.allocate_port_for_instance() is called from within\n   ComputeManager.attach_interface();\n2) refresh_cache() is called, since it decorates allocate_port_for_instance();\n3) refresh_cache calls update_instance_cache_with_nw_info(), with\n   ""conductor_api=None"" since \'conductor_api\' cannot be found in the kwargs;\n4) update_instance_cache_with_nw_info() calls\n   api.db.instance_info_cache_update();\n5) Since the call to the database should be made through the conductor, a\n   DBNotAllowed exception is raised, which prevents the cache from being updated.\n\nThis patch fixes the call to allocate_port_for_instance (step 1) so that\n\'conductor_api\' can be found in the kwargs (step 3).\n\nWhen using ComputeManager.detach_interface, the exact same problem arises (with\ndeallocate_port_for_instance instead of allocate_port_for_instance).\n\nThis is a first step towards fixing bug #1197192.\n\nChange-Id: I647795907b22790759d3be74afcaf70b712cb338\n'}]",0,37700,3379e95515dbc4f0574a9c030127ba19ba07f0e2,8,7,1,8122,,,0,"Fix DB access when refreshing the network cache.

When calling ComputeManager.attach_interface(), the following happens:

1) self.network_api.allocate_port_for_instance() is called from within
   ComputeManager.attach_interface();
2) refresh_cache() is called, since it decorates allocate_port_for_instance();
3) refresh_cache calls update_instance_cache_with_nw_info(), with
   ""conductor_api=None"" since 'conductor_api' cannot be found in the kwargs;
4) update_instance_cache_with_nw_info() calls
   api.db.instance_info_cache_update();
5) Since the call to the database should be made through the conductor, a
   DBNotAllowed exception is raised, which prevents the cache from being updated.

This patch fixes the call to allocate_port_for_instance (step 1) so that
'conductor_api' can be found in the kwargs (step 3).

When using ComputeManager.detach_interface, the exact same problem arises (with
deallocate_port_for_instance instead of allocate_port_for_instance).

This is a first step towards fixing bug #1197192.

Change-Id: I647795907b22790759d3be74afcaf70b712cb338
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/37700/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",2,3379e95515dbc4f0574a9c030127ba19ba07f0e2,bug/1197192," conductor_api=self.compute.conductor_api).AndReturn(nwinfo) lambda a, b, c, conductor_api=None: [])"," self.compute.conductor_api).AndReturn(nwinfo) lambda a, b, c, d: [])",4,5
openstack%2Fsahara~master~I155e831b5411deb0e7f572a00230dff482d39d22,openstack/sahara,master,I155e831b5411deb0e7f572a00230dff482d39d22,Added integration test for cluster scaling,MERGED,2013-07-22 16:43:29.000000000,2013-07-23 21:48:16.000000000,2013-07-23 21:48:16.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7428}]","[{'number': 1, 'created': '2013-07-22 16:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a2d67bd44ea32a6984e207dbd233476e018b4b72', 'message': 'Added integration test for cluster scaling\n\n*cluster scaling via node addition to existing node group was checked.\n*cluster scaling via new node group addition was checked.\n\nChange-Id: I155e831b5411deb0e7f572a00230dff482d39d22\n'}, {'number': 2, 'created': '2013-07-23 09:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9558aa2f58b52c054019b12c04128c666a52dca1', 'message': 'Added integration test for cluster scaling\n\n*cluster scaling via node addition to existing node group was checked;\n*cluster scaling via new node group addition was checked.\n\nChange-Id: I155e831b5411deb0e7f572a00230dff482d39d22\n'}, {'number': 3, 'created': '2013-07-23 15:46:45.000000000', 'files': ['savanna/tests/integration/scaling_test/test_scaling.py', 'savanna/tests/integration/configs/parameters.py', 'savanna/tests/integration/configs/config.py.sample', 'savanna/tests/integration/base.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/d9a1265d6887e62a7cbf1541cba67bf0da66ba58', 'message': 'Added integration test for cluster scaling\n\n*cluster scaling via node addition to existing node group was checked;\n*cluster scaling via new node group addition was checked.\n\nChange-Id: I155e831b5411deb0e7f572a00230dff482d39d22\n'}]",4,38173,d9a1265d6887e62a7cbf1541cba67bf0da66ba58,21,5,3,7428,,,0,"Added integration test for cluster scaling

*cluster scaling via node addition to existing node group was checked;
*cluster scaling via new node group addition was checked.

Change-Id: I155e831b5411deb0e7f572a00230dff482d39d22
",git fetch https://review.opendev.org/openstack/sahara refs/changes/73/38173/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/tests/integration/scaling_test/test_scaling.py', 'savanna/tests/integration/base.py']",2,a2d67bd44ea32a6984e207dbd233476e018b4b72,master," def put_object(self, url, object_id, body, code): data = self._put(url + object_id, json.dumps(body)) self.assertEquals(data.status_code, code) data = json.loads(data.content) return data attempts_count = 20 'within 1 minute.')", attempts_count = 10 'within 30 sec.'),253,2
openstack%2Fopenstack-manuals~master~Id353b068ef217e540c7e650076576648286f5977,openstack/openstack-manuals,master,Id353b068ef217e540c7e650076576648286f5977,"Fix bug 1196187: In tables, add whitespace to long strings that overrun column width.",ABANDONED,2013-07-19 14:09:35.000000000,2013-07-23 21:41:16.000000000,,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-07-19 14:09:35.000000000', 'files': ['doc/src/docbkx/common/tables/nova-volumes.xml', 'doc/src/docbkx/common/tables/nova-scheduling.xml', 'doc/src/docbkx/common/tables/nova-logging.xml', 'doc/src/docbkx/common/tables/nova-console.xml', 'doc/src/docbkx/common/tables/nova-testing.xml', 'doc/src/docbkx/common/tables/nova-xen.xml', 'doc/src/docbkx/common/tables/nova-network.xml', 'doc/src/docbkx/common/tables/nova-hypervisor.xml', 'doc/src/docbkx/common/tables/nova-zeromq.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e8e67004645e8c5ae94c791d5bdccbdcd790dc4a', 'message': 'Fix bug 1196187: In tables, add whitespace to long strings that overrun column width.\n\nChange-Id: Id353b068ef217e540c7e650076576648286f5977\n'}]",0,37906,e8e67004645e8c5ae94c791d5bdccbdcd790dc4a,6,4,1,8043,,,0,"Fix bug 1196187: In tables, add whitespace to long strings that overrun column width.

Change-Id: Id353b068ef217e540c7e650076576648286f5977
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/06/37906/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/common/tables/nova-volumes.xml', 'doc/src/docbkx/common/tables/nova-scheduling.xml', 'doc/src/docbkx/common/tables/nova-logging.xml', 'doc/src/docbkx/common/tables/nova-console.xml', 'doc/src/docbkx/common/tables/nova-testing.xml', 'doc/src/docbkx/common/tables/nova-xen.xml', 'doc/src/docbkx/common/tables/nova-network.xml', 'doc/src/docbkx/common/tables/nova-hypervisor.xml', 'doc/src/docbkx/common/tables/nova-zeromq.xml']",9,e8e67004645e8c5ae94c791d5bdccbdcd790dc4a,bug/1196187, <td>rpc_zmq_matchmaker=nova.openstack.common\ .rpc.matchmaker.MatchMakerLocalhost</td>, <td>rpc_zmq_matchmaker=nova.openstack.common.rpc.matchmaker.MatchMakerLocalhost</td>,48,32
openstack%2Fpython-novaclient~master~I2018bc5b73ce86d6d5383958375d5dbbde2e763c,openstack/python-novaclient,master,I2018bc5b73ce86d6d5383958375d5dbbde2e763c,make v2_auth and plugin_auth explictly return their results,MERGED,2013-07-02 23:52:08.000000000,2013-07-23 21:40:16.000000000,2013-07-23 21:40:16.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 5280}]","[{'number': 1, 'created': '2013-07-02 23:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/1fcfe74a64b6cef6e81170528bf8efff5085e601', 'message': 'make v2_auth and plugin_auth explictly return their results\n\nIn cases where the respective authentication methods return\nnon-NoneTypes, (e.g., HTTP 305 redirects) they would get dropped\non the floor previously.\n\nChange-Id: I2018bc5b73ce86d6d5383958375d5dbbde2e763c\nFixes: Bug 1197191\n'}, {'number': 2, 'created': '2013-07-08 23:51:02.000000000', 'files': ['novaclient/client.py', 'novaclient/tests/v1_1/test_auth.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/912288c4862e4023cb1952ce3e37453dc5cff883', 'message': 'make v2_auth and plugin_auth explictly return their results\n\nIn cases where the respective authentication methods return\nnon-NoneTypes, (e.g., HTTP 305 redirects) they would get dropped\non the floor previously.\n\nThis patch set splits the test_auth_redirect unit test into two\nnearly-identical unit tests to exercise the different code paths.\nWithout the patch, the test_v2_auth_redirect unit test fails with\nan HTTP 401 error\n\nChange-Id: I2018bc5b73ce86d6d5383958375d5dbbde2e763c\nFixes: Bug 1197191\n'}]",0,35419,912288c4862e4023cb1952ce3e37453dc5cff883,9,5,2,5280,,,0,"make v2_auth and plugin_auth explictly return their results

In cases where the respective authentication methods return
non-NoneTypes, (e.g., HTTP 305 redirects) they would get dropped
on the floor previously.

This patch set splits the test_auth_redirect unit test into two
nearly-identical unit tests to exercise the different code paths.
Without the patch, the test_v2_auth_redirect unit test fails with
an HTTP 401 error

Change-Id: I2018bc5b73ce86d6d5383958375d5dbbde2e763c
Fixes: Bug 1197191
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/19/35419/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/client.py'],1,1fcfe74a64b6cef6e81170528bf8efff5085e601,bug/1197191," return self.auth_plugin.authenticate(self, auth_url) return self._authenticate(url, body)"," self.auth_plugin.authenticate(self, auth_url) self._authenticate(url, body)",2,2
openstack%2Fneutron~master~Ic13010dc5941f71a7d59755bee2205d26fb6f7ae,openstack/neutron,master,Ic13010dc5941f71a7d59755bee2205d26fb6f7ae,multi-host feature,ABANDONED,2013-07-06 16:06:39.000000000,2013-07-23 21:34:52.000000000,,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 1119}, {'_account_id': 1387}, {'_account_id': 2468}, {'_account_id': 2592}, {'_account_id': 2711}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 6447}, {'_account_id': 6678}, {'_account_id': 6697}, {'_account_id': 7170}]","[{'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa6c23167d7862345a931c7cec45c5004347bd46', 'message': ""multi-host feature\n\nblueprint quantum-multihost\n\nDHCP port's IP will be the gateway ip of subnet of multihost network.\ndon't support add|delete-interface on multihost router.\n\nChange-Id: Ic13010dc5941f71a7d59755bee2205d26fb6f7ae\n""}, {'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5fafa6e001b041e19321cebed68b4565d1a0f8bf', 'message': ""multi-host feature\n\nblueprint quantum-multihost\n\nDHCP port's IP will be the gateway ip of subnet of multihost network.\n\nChange-Id: Ic13010dc5941f71a7d59755bee2205d26fb6f7ae\n""}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6321ef921880119204e87929c2ff8c359a7646ab', 'message': ""multi-host feature\n\nblueprint quantum-multihost\n\nDHCP port's IP will be the gateway ip of subnet of multihost network.\ndon't support add|delete-interface on multihost router.\n\nChange-Id: Ic13010dc5941f71a7d59755bee2205d26fb6f7ae\n""}, {'number': 5, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/70413597fc8a2f28938eb4e2cd52d5233adab571', 'message': ""multi-host feature\n\nblueprint quantum-multihost\n\nDHCP port's IP will be the gateway ip of subnet of multihost network.\n\nChange-Id: Ic13010dc5941f71a7d59755bee2205d26fb6f7ae\n""}, {'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d17b16fcbebcb0e78be87b3fc63040cd87116e15', 'message': ""multi-host feature\n\nblueprint quantum-multihost\n\nDHCP port's IP will be the gateway ip of subnet of multihost network.\n\nChange-Id: Ic13010dc5941f71a7d59755bee2205d26fb6f7ae\n""}, {'number': 6, 'created': '2013-07-06 16:06:39.000000000', 'files': ['quantum/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'quantum/api/rpc/pluginapi/multihost_plugin_api.py', 'quantum/plugins/openvswitch/ovs_quantum_plugin.py', 'quantum/tests/unit/openvswitch/test_openvswitch_plugin.py', 'quantum/api/rpc/agentnotifiers/l3_rpc_agent_api.py', 'etc/l3_agent.ini', 'quantum/agent/linux/dhcp.py', 'quantum/tests/unit/_test_extension_mutihost.py', 'quantum/tests/unit/test_linux_dhcp.py', 'quantum/agent/common/agent_utils.py', 'quantum/api/rpc/pluginapi/__init__.py', 'quantum/db/l3_rpc_base.py', 'quantum/agent/l3_agent.py', 'quantum/tests/unit/test_l3_agent.py', 'quantum/db/agents_db.py', 'quantum/tests/unit/test_dhcp_agent.py', 'etc/policy.json', 'quantum/agent/dhcp_agent.py', 'quantum/common/topics.py', 'etc/dhcp_agent.ini', 'quantum/tests/unit/test_l3_plugin.py', 'quantum/extensions/multihost.py', 'quantum/common/constants.py', 'quantum/db/l3_db.py', 'quantum/db/multihost_db.py', 'quantum/db/dhcp_rpc_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1149a2edbe2c42d63a3f2dab80c86cdd54922bf7', 'message': ""multi-host feature\n\nblueprint quantum-multihost\n\nDHCP port's IP will be the gateway ip of subnet of multihost network.\n\nto experiment, download patch https://review.openstack.org/#/c/29767/\n\nChange-Id: Ic13010dc5941f71a7d59755bee2205d26fb6f7ae\n""}]",75,24771,1149a2edbe2c42d63a3f2dab80c86cdd54922bf7,46,13,6,2874,,,0,"multi-host feature

blueprint quantum-multihost

DHCP port's IP will be the gateway ip of subnet of multihost network.

to experiment, download patch https://review.openstack.org/#/c/29767/

Change-Id: Ic13010dc5941f71a7d59755bee2205d26fb6f7ae
",git fetch https://review.opendev.org/openstack/neutron refs/changes/71/24771/1 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'quantum/api/rpc/pluginapi/multihost_plugin_api.py', 'quantum/plugins/openvswitch/ovs_quantum_plugin.py', 'quantum/api/rpc/agentnotifiers/l3_rpc_agent_api.py', 'quantum/common/topics.py', 'quantum/agent/common/agent_utils.py', 'quantum/api/rpc/pluginapi/__init__.py', 'quantum/extensions/multihost.py', 'quantum/db/l3_rpc_base.py', 'quantum/agent/l3_agent.py', 'quantum/common/constants.py', 'quantum/db/agents_db.py', 'quantum/db/multihost_db.py', 'quantum/db/dhcp_rpc_base.py', 'etc/policy.json', 'quantum/agent/dhcp_agent.py', 'quantum/common/utils.py']",17,aa6c23167d7862345a931c7cec45c5004347bd46,bp/quantum-multihost,"import uuid def get_dhcp_port_device_id(host, network_id): host_uuid = uuid.uuid5(uuid.NAMESPACE_DNS, host) return 'dhcp%s-%s' % (host_uuid, network_id)",,478,28
openstack%2Fneutron~master~I9222144e401261ea4e3f9f7828f53e80a19f0879,openstack/neutron,master,I9222144e401261ea4e3f9f7828f53e80a19f0879,Fix wrong default option type in Plumgrid plugin,ABANDONED,2013-07-23 09:36:37.000000000,2013-07-23 21:26:51.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-07-23 09:36:37.000000000', 'files': ['neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/247f9fcf8be56d8f3a6fbb080bc1f18e650ff8a7', 'message': 'Fix wrong default option type in Plumgrid plugin\n\nChange-Id: I9222144e401261ea4e3f9f7828f53e80a19f0879\n'}]",0,38270,247f9fcf8be56d8f3a6fbb080bc1f18e650ff8a7,6,5,1,1669,,,0,"Fix wrong default option type in Plumgrid plugin

Change-Id: I9222144e401261ea4e3f9f7828f53e80a19f0879
",git fetch https://review.opendev.org/openstack/neutron refs/changes/70/38270/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py'],1,247f9fcf8be56d8f3a6fbb080bc1f18e650ff8a7,jd/fix-default-option-type," cfg.StrOpt('topologyname', default='t1',"," cfg.IntOpt('topologyname', default='t1',",1,1
openstack%2Fnova~master~Id02786127ee35124e58425c699e5d3e84f42f527,openstack/nova,master,Id02786127ee35124e58425c699e5d3e84f42f527,Remove instance_metadata_get_all* from db api,MERGED,2013-07-23 20:12:13.000000000,2013-07-23 21:24:32.000000000,2013-07-23 21:24:30.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-07-23 20:12:13.000000000', 'files': ['nova/tests/db/test_db_api.py', 'nova/db/api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/daa26dd561f359ce3ca749ad6f678bf3ea66d574', 'message': 'Remove instance_metadata_get_all* from db api\n\nThe following calls are no longer called by nova.compute.api and should\nbe removed along with their associated tests:\n\ndb.api.instance_metadata_get_all\ndb.api.sqlalchemy.instance_metadata_get_all\ndb.api.sqlalchemy._instance_metadata_get_all_query\n\nChange-Id: Id02786127ee35124e58425c699e5d3e84f42f527\n'}]",0,38364,daa26dd561f359ce3ca749ad6f678bf3ea66d574,8,5,1,6661,,,0,"Remove instance_metadata_get_all* from db api

The following calls are no longer called by nova.compute.api and should
be removed along with their associated tests:

db.api.instance_metadata_get_all
db.api.sqlalchemy.instance_metadata_get_all
db.api.sqlalchemy._instance_metadata_get_all_query

Change-Id: Id02786127ee35124e58425c699e5d3e84f42f527
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/38364/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/db/test_db_api.py', 'nova/db/api.py', 'nova/db/sqlalchemy/api.py']",3,daa26dd561f359ce3ca749ad6f678bf3ea66d574,bug/1190845,,"def _instance_metadata_get_all_query(context, session=None, read_deleted='no', search_filts=[]): or_query = None query = model_query(context, models.InstanceMetadata, session=session, read_deleted=read_deleted) # We want to incrementally build an OR query out of the search filters. # So: # {'filter': # [{'resource_id': 'i-0000001'}], # [{'key': 'foo', 'value': 'bar'}]} # Should produce: # AND ((instance_metadata.uuid IN ('1')) OR # (instance_metadata.key IN ('foo')) OR # (instance_metadata.value IN ('bar'))) def make_tuple(item): if isinstance(item, dict): item = item.values() if not isinstance(item, (tuple, list, set)): item = (item,) return item for search_filt in search_filts: subq = None if search_filt.get('resource_id'): uuid = make_tuple(search_filt['resource_id']) subq = models.InstanceMetadata.instance_uuid.in_(uuid) elif search_filt.get('key'): key = make_tuple(search_filt['key']) subq = models.InstanceMetadata.key.in_(key) elif search_filt.get('value'): value = make_tuple(search_filt['value']) subq = models.InstanceMetadata.value.in_(value) if subq is not None: if or_query is None: or_query = subq else: or_query = or_(or_query, subq) if or_query is not None: query = query.filter(or_query) return query def instance_metadata_get_all(context, search_filts=[], read_deleted=""no""): rows = _instance_metadata_get_all_query(context, read_deleted=read_deleted, search_filts=search_filts).all() return [{'key': row['key'], 'value': row['value'], 'instance_id': row['instance_uuid']} for row in rows] @require_context",0,101
openstack%2Fswift~master~I027c862a2b7d9ff99d7f61bd43ccc0825dba525c,openstack/swift,master,I027c862a2b7d9ff99d7f61bd43ccc0825dba525c,Remove extra lstat() calls from check_mount,MERGED,2013-07-19 15:59:49.000000000,2013-07-23 21:24:27.000000000,2013-07-23 21:24:26.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 917}, {'_account_id': 1179}, {'_account_id': 2166}, {'_account_id': 6198}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-19 15:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/262a8c7b4dff967aaec9096f3b39a44416bc49a1', 'message': 'Remove extra lstat() calls from check_mount\n\nThe os.path.exists call performs an lstat, but os.path.ismount already\nperforms the same check. However, it performs a separate lstat() call\nto check for a symlink, which we remove as well, cutting the number\nperformed in half.\n\nSample program to be straced for comparison:\n\nfrom swift.common.constraints import check_mount\nimport os\nos.write(1, ""Starting\\n"")\nif check_mount(""/"", ""tmp""):\n    os.write(1, ""Mounted\\n"")\n\nHere is the output of a check on a mounted file system (common case)\nusing the new method:\n\n---- strace new ----\nwrite(1, ""Starting\\n"", 9) = 9\nlstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp/.."", {st_mode=S_IFDIR|0555, st_size=4096, ...}) = 0\nwrite(1, ""Mounted\\n"", 8) = 8\n\n---- strace old ----\nwrite(1, ""Starting\\n"", 9) = 9\nstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp/.."", {st_mode=S_IFDIR|0555, st_size=4096, ...}) = 0\nwrite(1, ""Mounted\\n"", 8) = 8\n\nChange-Id: I027c862a2b7d9ff99d7f61bd43ccc0825dba525c\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 2, 'created': '2013-07-19 16:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c4bb509317fb100c55fedb99a608b5364149024d', 'message': 'Remove extra lstat() calls from check_mount\n\nThe os.path.exists call performs an lstat, but os.path.ismount already\nperforms the same check. However, it performs a separate lstat() call\nto check for a symlink, which we remove as well, cutting the number\nperformed in half.\n\nSample program to be straced for comparison:\n\nfrom swift.common.constraints import check_mount\nimport os\nos.write(1, ""Starting\\n"")\nif check_mount(""/"", ""tmp""):\n    os.write(1, ""Mounted\\n"")\n\nHere is the output of a check on a mounted file system (common case)\nusing the new method:\n\n---- strace new ----\nwrite(1, ""Starting\\n"", 9) = 9\nlstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp/.."", {st_mode=S_IFDIR|0555, st_size=4096, ...}) = 0\nwrite(1, ""Mounted\\n"", 8) = 8\n\n---- strace old ----\nwrite(1, ""Starting\\n"", 9) = 9\nstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp/.."", {st_mode=S_IFDIR|0555, st_size=4096, ...}) = 0\nwrite(1, ""Mounted\\n"", 8) = 8\n\nChange-Id: I027c862a2b7d9ff99d7f61bd43ccc0825dba525c\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 3, 'created': '2013-07-19 18:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/aa286bf74259e11dbde8a433d0e423bbc08e7762', 'message': 'Remove extra lstat() calls from check_mount\n\nThe os.path.exists call performs an lstat, but os.path.ismount already\nperforms the same check. However, it performs a separate lstat() call\nto check for a symlink, which we remove as well, cutting the number\nperformed in half.\n\nSample program to be straced for comparison:\n\nfrom swift.common.constraints import check_mount\nimport os\nos.write(1, ""Starting\\n"")\nif check_mount(""/"", ""tmp""):\n    os.write(1, ""Mounted\\n"")\n\nHere is the output of a check on a mounted file system (common case)\nusing the new method:\n\n---- strace new ----\nwrite(1, ""Starting\\n"", 9) = 9\nlstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp/.."", {st_mode=S_IFDIR|0555, st_size=4096, ...}) = 0\nwrite(1, ""Mounted\\n"", 8) = 8\n\n---- strace old ----\nwrite(1, ""Starting\\n"", 9) = 9\nstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp/.."", {st_mode=S_IFDIR|0555, st_size=4096, ...}) = 0\nwrite(1, ""Mounted\\n"", 8) = 8\n\nChange-Id: I027c862a2b7d9ff99d7f61bd43ccc0825dba525c\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 4, 'created': '2013-07-22 14:05:58.000000000', 'files': ['test/unit/common/test_constraints.py', 'swift/common/utils.py', 'test/unit/common/middleware/test_recon.py', 'test/unit/common/test_db.py', 'swift/common/constraints.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/e0535f9bf358d290f7cce6001f3adcee64c9073f', 'message': 'Remove extra lstat() calls from check_mount\n\nThe os.path.exists call performs an lstat, but os.path.ismount already\nperforms the same check. However, it performs a separate lstat() call\nto check for a symlink, which we remove as well, cutting the number\nperformed in half.\n\nSample program to be straced for comparison:\n\nfrom swift.common.constraints import check_mount\nimport os\nos.write(1, ""Starting\\n"")\nif check_mount(""/"", ""tmp""):\n    os.write(1, ""Mounted\\n"")\n\nHere is the output of a check on a mounted file system (common case)\nusing the new method:\n\n---- strace new ----\nwrite(1, ""Starting\\n"", 9) = 9\nlstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp/.."", {st_mode=S_IFDIR|0555, st_size=4096, ...}) = 0\nwrite(1, ""Mounted\\n"", 8) = 8\n\n---- strace old ----\nwrite(1, ""Starting\\n"", 9) = 9\nstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0\nlstat(""/tmp/.."", {st_mode=S_IFDIR|0555, st_size=4096, ...}) = 0\nwrite(1, ""Mounted\\n"", 8) = 8\n\nChange-Id: I027c862a2b7d9ff99d7f61bd43ccc0825dba525c\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",10,37929,e0535f9bf358d290f7cce6001f3adcee64c9073f,25,7,4,6198,,,0,"Remove extra lstat() calls from check_mount

The os.path.exists call performs an lstat, but os.path.ismount already
performs the same check. However, it performs a separate lstat() call
to check for a symlink, which we remove as well, cutting the number
performed in half.

Sample program to be straced for comparison:

from swift.common.constraints import check_mount
import os
os.write(1, ""Starting\n"")
if check_mount(""/"", ""tmp""):
    os.write(1, ""Mounted\n"")

Here is the output of a check on a mounted file system (common case)
using the new method:

---- strace new ----
write(1, ""Starting\n"", 9) = 9
lstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0
lstat(""/tmp/.."", {st_mode=S_IFDIR|0555, st_size=4096, ...}) = 0
write(1, ""Mounted\n"", 8) = 8

---- strace old ----
write(1, ""Starting\n"", 9) = 9
stat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0
lstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0
lstat(""/tmp"", {st_mode=S_IFDIR|S_ISVTX|0777, st_size=8460, ...}) = 0
lstat(""/tmp/.."", {st_mode=S_IFDIR|0555, st_size=4096, ...}) = 0
write(1, ""Mounted\n"", 8) = 8

Change-Id: I027c862a2b7d9ff99d7f61bd43ccc0825dba525c
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/29/37929/3 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_constraints.py', 'swift/common/utils.py', 'test/unit/common/middleware/test_recon.py', 'test/unit/common/test_db.py', 'swift/common/constraints.py', 'test/unit/common/test_utils.py']",6,262a8c7b4dff967aaec9096f3b39a44416bc49a1,cache-mount-check,"import shutilfrom tempfile import TemporaryFile, NamedTemporaryFile, mkdtemp # Get a file that is definitely on disk def test_ismount_path_does_not_exist(self): tmpdir = mkdtemp() try: assert False == utils.ismount(os.path.join(tmpdir, 'bar')) finally: shutil.rmtree(tmpdir) def test_ismount_path_not_mount(self): tmpdir = mkdtemp() try: assert False == utils.ismount(tmpdir) finally: shutil.rmtree(tmpdir) def test_ismount_path_error(self): def _mock_os_lstat(path): raise OSError(13, ""foo"") tmpdir = mkdtemp() try: with patch(""os.lstat"", _mock_os_lstat): try: utils.ismount(tmpdir) except OSError as err: pass else: self.fail(""Expected OSError"") finally: shutil.rmtree(tmpdir) def test_ismount_path_is_symlink(self): tmpdir = mkdtemp() try: link = os.path.join(tmpdir, ""tmp"") os.symlink(""/tmp"", link) assert False == utils.ismount(link) finally: shutil.rmtree(tmpdir) def test_ismount_path_is_root(self): assert True == utils.ismount('/') def test_ismount_parent_path_error(self): _os_lstat = os.lstat def _mock_os_lstat(path): if path.endswith(""..""): raise OSError(13, ""foo"") else: return _os_lstat(path) tmpdir = mkdtemp() try: with patch(""os.lstat"", _mock_os_lstat): try: utils.ismount(tmpdir) except OSError as err: pass else: self.fail(""Expected OSError"") finally: shutil.rmtree(tmpdir) def test_ismount_successes_dev(self): _os_lstat = os.lstat class MockStat(object): def __init__(self, mode, dev, ino): self.st_mode = mode self.st_dev = dev self.st_ino = ino def _mock_os_lstat(path): if path.endswith(""..""): parent = _os_lstat(path) return MockStat(parent.st_mode, parent.st_dev + 1, parent.st_ino) else: return _os_lstat(path) tmpdir = mkdtemp() try: with patch(""os.lstat"", _mock_os_lstat): try: utils.ismount(tmpdir) except OSError as err: self.fail(""Unexpected exception"") else: pass finally: shutil.rmtree(tmpdir) def test_ismount_successes_ino(self): _os_lstat = os.lstat class MockStat(object): def __init__(self, mode, dev, ino): self.st_mode = mode self.st_dev = dev self.st_ino = ino def _mock_os_lstat(path): if path.endswith(""..""): return _os_lstat(path) else: parent_path = os.path.join(path, "".."") child = _os_lstat(path) parent = _os_lstat(parent_path) return MockStat(child.st_mode, parent.st_ino, child.st_dev) tmpdir = mkdtemp() try: with patch(""os.lstat"", _mock_os_lstat): try: utils.ismount(tmpdir) except OSError as err: self.fail(""Unexpected exception"") else: pass finally: shutil.rmtree(tmpdir) ","from tempfile import TemporaryFile, NamedTemporaryFile # use mkstemp to get a file that is definitely on disk",207,54
openstack%2Ftripleo-ci~master~I19a34b1a400ec646f37310f265d1345bb6882dc3,openstack/tripleo-ci,master,I19a34b1a400ec646f37310f265d1345bb6882dc3,Sync toci with current devtest,MERGED,2013-07-23 11:59:46.000000000,2013-07-23 21:23:04.000000000,2013-07-23 21:23:04.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 6773}]","[{'number': 1, 'created': '2013-07-23 11:59:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2f15376f85c7d64b8f6c97c602eee1a90844694d', 'message': ""Sync toci with current devtest\n\nToci hasn't worked in nearly two weeks, ever since some stuff was refactored,\nafter this commit toci\n1. is now back in sync with devtest in incubator.\n2. brings up an overcloud by default (set TOCI_DO_OVERCLOUD=0 to stop a\n   undercloud).\n3. clones all git repositories to /opt/toci (these arn't refreshed\n   between toci runs unless removed).\n4. changes some env variables so that the default behaviour is now\n   closer to a what a user setting up a dev env would want.\n5. removes unused patches and adds some new ones.\n6. Adds a bit more documentation.\n\nChange-Id: I19a34b1a400ec646f37310f265d1345bb6882dc3\n""}, {'number': 2, 'created': '2013-07-23 12:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bdee21ab428bedc00d2c7334a6d6a28e881cd21f', 'message': ""Sync toci with current devtest\n\nToci hasn't worked in nearly two weeks, ever since some stuff was refactored,\nafter this commit toci\n1. is now back in sync with devtest in incubator.\n2. brings up an overcloud by default (set TOCI_DO_OVERCLOUD=0 to stop a\n   undercloud).\n3. clones all git repositories to /opt/toci (these arn't refreshed\n   between toci runs unless removed).\n4. changes some env variables so that the default behaviour is now\n   closer to a what a user setting up a dev env would want.\n5. removes unused patches and adds some new ones.\n6. Adds a bit more documentation.\n\nChange-Id: I19a34b1a400ec646f37310f265d1345bb6882dc3\n""}, {'number': 3, 'created': '2013-07-23 14:52:43.000000000', 'files': ['patches/diskimage-builder-Downgrade-dnsmasq.patch', 'toci.sh', 'FAQ.md', 'patches/tripleo-image-elements-metadata.patch', 'patches/diskimage-builder-Allow-heat-admin-sudo-without-tty.patch', 'patches/tripleo-image-elements-0002-Restart-rabbitmq-server-in-case-of-failure.patch', 'toci_setup.sh', 'patches/tripleo-image-elements-0001-heat-log-chown.patch', 'patches/tripleo-incubator-0001-no-virsh-prealloc-metadata.patch', 'README.md', 'patches_dev/diskimage-builder-Save-images-in-a-toci-cache-file-or-use-if-present.patch', 'toci_cleanup.sh', 'toci_git.sh', 'toci_test.sh', 'toci_functions.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b2efaa39faed5a7eff20353e081a55c6bf3f3c6d', 'message': ""Sync toci with current devtest\n\nToci hasn't worked in nearly two weeks, ever since some stuff was refactored,\nafter this commit toci\n1. is now back in sync with devtest in incubator.\n2. brings up an overcloud by default (set TOCI_DO_OVERCLOUD=0 to stop a\n   undercloud).\n3. clones all git repositories to /opt/toci (these arn't refreshed\n   between toci runs unless removed).\n4. changes some env variables so that the default behaviour is now\n   closer to a what a user setting up a dev env would want.\n5. removes unused patches and adds some new ones.\n6. Adds a bit more documentation.\n\nChange-Id: I19a34b1a400ec646f37310f265d1345bb6882dc3\n""}]",12,38283,b2efaa39faed5a7eff20353e081a55c6bf3f3c6d,14,4,3,1926,,,0,"Sync toci with current devtest

Toci hasn't worked in nearly two weeks, ever since some stuff was refactored,
after this commit toci
1. is now back in sync with devtest in incubator.
2. brings up an overcloud by default (set TOCI_DO_OVERCLOUD=0 to stop a
   undercloud).
3. clones all git repositories to /opt/toci (these arn't refreshed
   between toci runs unless removed).
4. changes some env variables so that the default behaviour is now
   closer to a what a user setting up a dev env would want.
5. removes unused patches and adds some new ones.
6. Adds a bit more documentation.

Change-Id: I19a34b1a400ec646f37310f265d1345bb6882dc3
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/83/38283/1 && git format-patch -1 --stdout FETCH_HEAD,"['patches/diskimage-builder-Downgrade-dnsmasq.patch', 'toci.sh', 'FAQ.md', 'patches/tripleo-image-elements-metadata.patch', 'patches/diskimage-builder-Allow-heat-admin-sudo-without-tty.patch', 'patches/tripleo-image-elements-0002-Restart-rabbitmq-server-in-case-of-failure.patch', 'toci_setup.sh', 'patches/tripleo-image-elements-0001-heat-log-chown.patch', 'patches/tripleo-incubator-0001-no-virsh-prealloc-metadata.patch', 'README.md', 'patches_dev/diskimage-builder-Save-images-in-a-toci-cache-file-or-use-if-present.patch', 'toci_cleanup.sh', 'toci_git.sh', 'toci_test.sh', 'patches/diskimage-builder-Save-images-in-a-toci-cache-file-or-use-if-present.patch', 'toci_functions.sh']",16,2f15376f85c7d64b8f6c97c602eee1a90844694d,update," CACHEDIR=$TOCI_WORKING_DIR/${1/[^\/]*\//} repo_basename=${1#*/} apply_patches ${repo_basename} ${repo_basename}* ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=QUIET -o PasswordAuthentication=no $@ scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=QUIET -o PasswordAuthentication=no $@# On Exit write relevant toci env to a rc file get_tocienv(){ declare | grep -e ""^PATH="" -e ""^http.*proxy"" -e ""^TOCI_"" -e '^DIB_' | sed -e 's/^/export /g' > $TOCI_WORKING_DIR/toci_env # Some IP we sont want to proxy echo 'export no_proxy=$($TOCI_WORKING_DIR/tripleo-incubator/scripts/get-vm-ip seed),192.0.2.2,192.0.2.5,192.0.2.6,192.0.2.7,192.0.2.8' >> $TOCI_WORKING_DIR/toci_env } ERROR(){ echo $@ exit 1 }", CACHEDIR=$TOCI_CACHE_DIR/${1/[^\/]*\//} git reset --hard origin/master cp -r $CACHEDIR $TOCI_WORKING_DIR/${1/[^\/]*\//} ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=QUIET $@ scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=QUIET $@,397,161
openstack%2Fdiskimage-builder~master~I29f3b534e28e8c0efe94736dcdc7f4c453738676,openstack/diskimage-builder,master,I29f3b534e28e8c0efe94736dcdc7f4c453738676,Update TripleO incubator URL reference.,MERGED,2013-07-23 21:16:21.000000000,2013-07-23 21:16:21.000000000,2013-07-23 21:16:21.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6488}, {'_account_id': 6773}]","[{'number': 1, 'created': '2013-07-23 21:16:21.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f33c4ebdde0ff352a9178ad5aa0b73a00f17beaa', 'message': ""Update TripleO incubator URL reference.\n\nThe old location has been deleted and 404's.\n\nChange-Id: I29f3b534e28e8c0efe94736dcdc7f4c453738676\n""}]",0,38244,f33c4ebdde0ff352a9178ad5aa0b73a00f17beaa,7,4,1,4190,,,0,"Update TripleO incubator URL reference.

The old location has been deleted and 404's.

Change-Id: I29f3b534e28e8c0efe94736dcdc7f4c453738676
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/44/38244/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,f33c4ebdde0ff352a9178ad5aa0b73a00f17beaa,,These tools are the components of TripleO (https://github.com/openstack/tripleo-incubator) that are responsible for building disk images.,These tools are the components of TripleO (https://github.com/tripleo/incubator) umbrella project that do the plumbing involved in building disk images.,3,2
openstack%2Ftripleo-incubator~master~I67e7eeaba365ded8fcaa1ba6b48d6759e90d5222,openstack/tripleo-incubator,master,I67e7eeaba365ded8fcaa1ba6b48d6759e90d5222,Fix call to install-dependencies.,MERGED,2013-07-23 18:34:53.000000000,2013-07-23 21:16:11.000000000,2013-07-23 21:16:11.000000000,"[{'_account_id': 3}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-23 18:34:53.000000000', 'files': ['scripts/install-dependencies'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/57f8e4e2d4b8439ff1ff675433d57062b467e840', 'message': 'Fix call to install-dependencies.\n\nIf the current user running install-dependencies is not in the\nlibvirtd group, the user is added and install-dependencies is\nreran.  This patch calls install-dependencies with $0 instead\nof $PWD/$0.  There is no gaurantee that that the current working\ndirectory is the scripts directory, so using $PWD/$0 could result\nin an error.\n\nChange-Id: I67e7eeaba365ded8fcaa1ba6b48d6759e90d5222\n'}]",0,38350,57f8e4e2d4b8439ff1ff675433d57062b467e840,5,2,1,7144,,,0,"Fix call to install-dependencies.

If the current user running install-dependencies is not in the
libvirtd group, the user is added and install-dependencies is
reran.  This patch calls install-dependencies with $0 instead
of $PWD/$0.  There is no gaurantee that that the current working
directory is the scripts directory, so using $PWD/$0 could result
in an error.

Change-Id: I67e7eeaba365ded8fcaa1ba6b48d6759e90d5222
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/50/38350/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/install-dependencies'],1,57f8e4e2d4b8439ff1ff675433d57062b467e840,dev-install-dependencies, exec sudo su -l $USER $0, exec sudo su -l $USER $PWD/$0,1,1
openstack%2Fkeystone~master~I9c92408c30a18176f03f8f3f0b2045c61598332a,openstack/keystone,master,I9c92408c30a18176f03f8f3f0b2045c61598332a,Migrating ec2 credentials to credential.,ABANDONED,2013-06-29 02:28:37.000000000,2013-07-23 20:48:11.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 866}, {'_account_id': 994}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 5971}]","[{'number': 1, 'created': '2013-06-29 02:28:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/57236d5bacc95b3cbc275cf7f264f4d73d3b81eb', 'message': 'Initial Commit.\n\nChange-Id: I9c92408c30a18176f03f8f3f0b2045c61598332a\n'}, {'number': 2, 'created': '2013-07-05 23:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9830d28cecb1dd823f46fec77d550cfcbbe8bf96', 'message': 'Initial Commit.\n\nChange-Id: I9c92408c30a18176f03f8f3f0b2045c61598332a\n'}, {'number': 3, 'created': '2013-07-06 02:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cd3bc2f307d8ee7dddc5eda3d1b3a9d797891037', 'message': 'Initial Commit.\n\nChange-Id: I9c92408c30a18176f03f8f3f0b2045c61598332a\n'}, {'number': 4, 'created': '2013-07-06 03:13:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/76eec54d0b11b4e9fd29d5f500aca12825454284', 'message': 'Initial Commit.\n\nChange-Id: I9c92408c30a18176f03f8f3f0b2045c61598332a\n'}, {'number': 5, 'created': '2013-07-11 00:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c6b12e8af27edbc006fcb67c3906b89d4e9b9d55', 'message': 'Migrating ec2 credentials to credential.(WIP)\n\nImplementation to migrate ec2 credentials\ntable data to credentials data and also\nmodified the ec2 core to store the ec2 credentials\nin credentials table.\n\nhttps://blueprints.launchpad.net/keystone/+spec/migrate-ec2-credentials\n\nChange-Id: I9c92408c30a18176f03f8f3f0b2045c61598332a\n'}, {'number': 6, 'created': '2013-07-11 22:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c543235d052a9da4ee7010b50d5881d258e440dc', 'message': 'Migrating ec2 credentials to credential.(WIP)\n\nMerging ec2 credentials into the credentials\ntable to simplify management of ec2\ncredentials.\n\nblueprint migrate-ec2-credentials\n\nChange-Id: I9c92408c30a18176f03f8f3f0b2045c61598332a\n'}, {'number': 7, 'created': '2013-07-12 21:21:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/49d759a96e2975ad9c3f44d4460b7db919b9b924', 'message': 'Migrating ec2 credentials to credential.(WIP)\n\nMerging ec2 credentials into the credentials\ntable to simplify management of ec2\ncredentials.\n\nblueprint migrate-ec2-credentials\n\nChange-Id: I9c92408c30a18176f03f8f3f0b2045c61598332a\n'}, {'number': 8, 'created': '2013-07-13 21:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c93f2f62ad305c20e0085d77d6fdd15910d4eed1', 'message': 'Migrating ec2 credentials to credential.(WIP)\n\nMerging ec2 credentials into the credentials\ntable to simplify management of ec2\ncredentials.\n\nblueprint migrate-ec2-credentials\n\nChange-Id: I9c92408c30a18176f03f8f3f0b2045c61598332a\n'}, {'number': 9, 'created': '2013-07-14 01:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ab1e3e751004c1edf9bb623aecfac39b57f6785b', 'message': 'Migrating ec2 credentials to credential.(WIP)\n\nMerging ec2 credentials into the credentials\ntable to simplify management of ec2\ncredentials.\n\nblueprint migrate-ec2-credentials\n\nChange-Id: I9c92408c30a18176f03f8f3f0b2045c61598332a\n'}, {'number': 10, 'created': '2013-07-17 18:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7f3ccfb780808bd217ce5ecfcdc3afa33c10c72f', 'message': 'Migrating ec2 credentials to credential.(WIP)\n\nMerging ec2 credentials into the credentials\ntable to simplify management of ec2\ncredentials.\n\nblueprint migrate-ec2-credentials\n\nChange-Id: I9c92408c30a18176f03f8f3f0b2045c61598332a\n'}, {'number': 11, 'created': '2013-07-18 16:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d09a5b6cad55d63363b3b3b466d491ff560a5d80', 'message': 'Migrating ec2 credentials to credential.\n\nMerging ec2 credentials into the credentials\ntable to simplify management of ec2\ncredentials.\n\nblueprint migrate-ec2-credentials\n\nChange-Id: I9c92408c30a18176f03f8f3f0b2045c61598332a\n'}, {'number': 12, 'created': '2013-07-19 00:05:41.000000000', 'files': ['keystone/contrib/ec2/backends/kvs.py', 'keystone/common/sql/legacy.py', 'tests/test_keystoneclient_sql.py', 'keystone/credential/backends/sql.py', 'keystone/common/sql/migrate_repo/versions/030_migrate_ec2credentials_table_credentials.py', 'keystone/common/sql/nova.py', 'tests/test_sql_upgrade.py', 'tests/test_contrib_s3_core.py', 'tests/test_keystoneclient.py', 'keystone/contrib/ec2/core.py', 'keystone/service.py', 'keystone/contrib/ec2/backends/__init__.py', 'keystone/contrib/ec2/backends/sql.py', 'keystone/credential/core.py', 'keystone/common/utils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/5b7bb0b748ef9b9c32eea36703d69b06e174a5ae', 'message': 'Migrating ec2 credentials to credential.\n\nMerging ec2 credentials into the credentials\ntable to simplify management of ec2\ncredentials.\n\nblueprint migrate-ec2-credentials\n\nChange-Id: I9c92408c30a18176f03f8f3f0b2045c61598332a\n'}]",28,34973,5b7bb0b748ef9b9c32eea36703d69b06e174a5ae,42,9,12,5971,,,0,"Migrating ec2 credentials to credential.

Merging ec2 credentials into the credentials
table to simplify management of ec2
credentials.

blueprint migrate-ec2-credentials

Change-Id: I9c92408c30a18176f03f8f3f0b2045c61598332a
",git fetch https://review.opendev.org/openstack/keystone refs/changes/73/34973/8 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/sql/migrate_repo/versions/027_migrate_ec2credentials_table_credentials.py', 'keystone/contrib/ec2/core.py', 'keystone/credential/controllers.py']",3,57236d5bacc95b3cbc275cf7f264f4d73d3b81eb,bp/migrate-ec2-credentials," @controller.filterprotected('user_id') def list_credentials(self, context, filters): refs = self.credential_api.list_credentials(context) return CredentialV3.wrap_collection(context, refs, filters)"," @controller.protected def list_credentials(self, context): refs = self.credential_api.list_credentials() return CredentialV3.wrap_collection(context, refs)",123,16
openstack%2Fnova~master~Icc0a7df1f93da803bbb2d7c9d18a4ce42bbe6720,openstack/nova,master,Icc0a7df1f93da803bbb2d7c9d18a4ce42bbe6720,Change filters on getting instance metadata to AND instead of OR,ABANDONED,2013-07-05 15:14:17.000000000,2013-07-23 20:23:33.000000000,,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2140}, {'_account_id': 2166}, {'_account_id': 6172}, {'_account_id': 6624}, {'_account_id': 6661}, {'_account_id': 6873}]","[{'number': 1, 'created': '2013-07-05 15:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6697acc00a93178d880fded3b06335891cf3ab1b', 'message': 'Change filters on getting instance metadata to OR instead of AND\n\nFrom the EC2 API on DescribeTags:\n\nhttp://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-DescribeTags.html\n\nYou can specify multiple filters (for example, specify a specific\nresource type and tag values that contain the string database). The\nresponse includes information for a tag only if it matches all the\nfilters that you specified. If there\'s no match, no special message is\nreturned, the response is simply empty.\n\nThe phrase ""only if it matches all the filters"" means we should AND\nsearch filters together.\n\nFixes bug #1190845\n\nChange-Id: Icc0a7df1f93da803bbb2d7c9d18a4ce42bbe6720\n'}, {'number': 2, 'created': '2013-07-05 19:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f2b5cc92b3236055a69803e82bd591ebf7e3fb7', 'message': 'Change filters on getting instance metadata to AND instead of OR\n\nFrom the EC2 API on DescribeTags:\n\nhttp://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-DescribeTags.html\n\nYou can specify multiple filters (for example, specify a specific\nresource type and tag values that contain the string database). The\nresponse includes information for a tag only if it matches all the\nfilters that you specified. If there\'s no match, no special message is\nreturned, the response is simply empty.\n\nThe phrase ""only if it matches all the filters"" means we should AND\nsearch filters together.\n\nFixes bug #1190845\n\nChange-Id: Icc0a7df1f93da803bbb2d7c9d18a4ce42bbe6720\n'}, {'number': 3, 'created': '2013-07-06 18:24:07.000000000', 'files': ['nova/tests/api/ec2/test_cloud.py', 'nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f53b43ab851cf773c1d42bc3544725a420360877', 'message': 'Change filters on getting instance metadata to AND instead of OR\n\nFrom the EC2 API on DescribeTags:\n\nhttp://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-DescribeTags.html\n\nYou can specify multiple filters (for example, specify a specific\nresource type and tag values that contain the string database). The\nresponse includes information for a tag only if it matches all the\nfilters that you specified. If there\'s no match, no special message is\nreturned, the response is simply empty.\n\nThe phrase ""only if it matches all the filters"" means we should AND\nsearch filters together.\n\nFixes bug #1190845\n\nDocImpact\n\nChange-Id: Icc0a7df1f93da803bbb2d7c9d18a4ce42bbe6720\n'}]",9,35822,f53b43ab851cf773c1d42bc3544725a420360877,25,11,3,6661,,,0,"Change filters on getting instance metadata to AND instead of OR

From the EC2 API on DescribeTags:

http://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-DescribeTags.html

You can specify multiple filters (for example, specify a specific
resource type and tag values that contain the string database). The
response includes information for a tag only if it matches all the
filters that you specified. If there's no match, no special message is
returned, the response is simply empty.

The phrase ""only if it matches all the filters"" means we should AND
search filters together.

Fixes bug #1190845

DocImpact

Change-Id: Icc0a7df1f93da803bbb2d7c9d18a4ce42bbe6720
",git fetch https://review.opendev.org/openstack/nova refs/changes/22/35822/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/ec2/test_cloud.py', 'nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",3,6697acc00a93178d880fded3b06335891cf3ab1b,bug/1190845," and_query = None # We want to incrementally build an AND query out of the search filters. # AND ((instance_metadata.uuid IN ('1')) AND # (instance_metadata.key IN ('foo')) AND if and_query is None: and_query = subq else: and_query = and_(and_query, subq) if and_query is not None: query = query.filter(and_query)"," or_query = None # We want to incrementally build an OR query out of the search filters. # AND ((instance_metadata.uuid IN ('1')) OR # (instance_metadata.key IN ('foo')) OR if or_query is None: or_query = subq else: or_query = or_(or_query, subq) if or_query is not None: query = query.filter(or_query)",15,12
openstack%2Fpbr~master~I4ef0f59eef0477d5ebb8da2f2e8c3f2cb9ba6daa,openstack/pbr,master,I4ef0f59eef0477d5ebb8da2f2e8c3f2cb9ba6daa,This should Fail,ABANDONED,2013-07-23 17:21:08.000000000,2013-07-23 20:12:31.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1849}]","[{'number': 1, 'created': '2013-07-23 17:21:08.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/8723bae23df7caad9671ae24c6f595e91ffe94d6', 'message': 'This should Fail\n\nChange-Id: I4ef0f59eef0477d5ebb8da2f2e8c3f2cb9ba6daa\n'}]",0,38327,8723bae23df7caad9671ae24c6f595e91ffe94d6,3,3,1,1849,,,0,"This should Fail

Change-Id: I4ef0f59eef0477d5ebb8da2f2e8c3f2cb9ba6daa
",git fetch https://review.opendev.org/openstack/pbr refs/changes/27/38327/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,8723bae23df7caad9671ae24c6f595e91ffe94d6,test,,import sys,0,1
openstack%2Fnova~master~Icc34359cc935920e2d4780849d9310c4961c8f74,openstack/nova,master,Icc34359cc935920e2d4780849d9310c4961c8f74,Remove project_id from alternate image link path,MERGED,2013-06-28 06:49:46.000000000,2013-07-23 20:00:40.000000000,2013-07-23 20:00:38.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5292}]","[{'number': 1, 'created': '2013-06-28 06:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/088a1af0b633194ccaeb2adc2201e0b5a6f3d2c8', 'message': 'Remove project_id from alternate image link path\n\nRemoves the project id from the alternate link path\ngenerated for the v3 API os-images extension.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Icc34359cc935920e2d4780849d9310c4961c8f74\n'}, {'number': 2, 'created': '2013-06-28 13:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/477058be6899c51229f5b37698fc1fd81b7d4b09', 'message': 'Remove project_id from alternate image link path\n\nRemoves the project id from the alternate link path\ngenerated for the v3 API os-images extension.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Icc34359cc935920e2d4780849d9310c4961c8f74\n'}, {'number': 3, 'created': '2013-07-01 00:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ac29a3fabbec6cb734f6772033fbb83d6393d34', 'message': 'Remove project_id from alternate image link path\n\nRemoves the project id from the alternate link path\ngenerated for the v3 API os-images extension.\n\nAlso fixes issue with os.path.join being used to generate\nurls which will break on Windows.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Icc34359cc935920e2d4780849d9310c4961c8f74\n'}, {'number': 4, 'created': '2013-07-01 03:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c2d9d97844cca7f4535b3108e4fc01abde614f9f', 'message': 'Remove project_id from alternate image link path\n\nRemoves the project id from the alternate link path\ngenerated for the v3 API os-images extension.\n\nAlso fixes issue with os.path.join being used to generate\nurls which will break on Windows.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Icc34359cc935920e2d4780849d9310c4961c8f74\n'}, {'number': 5, 'created': '2013-07-17 08:28:42.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_images.py', 'nova/api/openstack/compute/views/images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fd398fbb73ae317e15ff39da9316700a523ec154', 'message': 'Remove project_id from alternate image link path\n\nRemoves the project id from the alternate link path\ngenerated for the v3 API os-images extension.\n\nAlso fixes issue with os.path.join being used to generate\nurls which will break on Windows.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Icc34359cc935920e2d4780849d9310c4961c8f74\n'}]",3,34848,fd398fbb73ae317e15ff39da9316700a523ec154,27,8,5,5292,,,0,"Remove project_id from alternate image link path

Removes the project id from the alternate link path
generated for the v3 API os-images extension.

Also fixes issue with os.path.join being used to generate
urls which will break on Windows.

Partially implements blueprint nova-v3-api

Change-Id: Icc34359cc935920e2d4780849d9310c4961c8f74
",git fetch https://review.opendev.org/openstack/nova refs/changes/48/34848/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_images.py', 'nova/api/openstack/compute/views/images.py']",2,088a1af0b633194ccaeb2adc2201e0b5a6f3d2c8,bp/nova-v3-api," def _get_alternate_link(self, request, identifier): """"""Create an alternate link for a specific image id."""""" glance_url = glance.generate_glance_url() glance_url = self._update_glance_link_prefix(glance_url) return os.path.join(glance_url, self._collection_name, str(identifier)) ",,22,13
openstack%2Fopenstack-manuals~master~I80337845f3aa2a85fb2fa816f5adc04ca7c88466,openstack/openstack-manuals,master,I80337845f3aa2a85fb2fa816f5adc04ca7c88466,Change all Quantum's to Neutron's,MERGED,2013-07-19 16:25:30.000000000,2013-07-23 19:49:27.000000000,2013-07-23 19:49:27.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6772}, {'_account_id': 6850}]","[{'number': 1, 'created': '2013-07-19 16:25:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8d546a94b529b7f9338ee98aa6533f3f4794b8ff', 'message': ""Change all Quantum's to Neutron's\n\nChange-Id: I80337845f3aa2a85fb2fa816f5adc04ca7c88466\n""}, {'number': 2, 'created': '2013-07-19 16:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1b84f7f2db8c48d7d9c54ad880ea57f705e5ebe0', 'message': ""Change all Quantum's to Neutron's\n\nChange-Id: I80337845f3aa2a85fb2fa816f5adc04ca7c88466\n""}, {'number': 3, 'created': '2013-07-19 16:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9b0fd796f4ed3e0e1100fbc9c7af952197bf3a44', 'message': ""Change all Quantum's to Neutron's\n\nChange-Id: I80337845f3aa2a85fb2fa816f5adc04ca7c88466\n""}, {'number': 4, 'created': '2013-07-22 16:28:09.000000000', 'files': ['doc/src/docbkx/basic-install/src/basic-install_requirements.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-intro.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-common.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-intro.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-intro.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-keystone.xml', 'doc/src/docbkx/basic-install/src/figures/Quantum-PhysNet-Diagram.png', 'doc/src/docbkx/basic-install/src/basic-install_compute-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-neutron.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute.xml', 'doc/src/docbkx/basic-install/src/basic-install_architecture.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-neutron.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-operating.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-services.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7b424a541aef007d166785c9b48ab0eb5205576d', 'message': ""Change all Quantum's to Neutron's\n\nChange-Id: I80337845f3aa2a85fb2fa816f5adc04ca7c88466\n""}]",0,37934,7b424a541aef007d166785c9b48ab0eb5205576d,15,6,4,6850,,,0,"Change all Quantum's to Neutron's

Change-Id: I80337845f3aa2a85fb2fa816f5adc04ca7c88466
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/34/37934/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/basic-install/src/basic-install_requirements.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-intro.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-common.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-intro.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-intro.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-keystone.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-neutron.xml', 'doc/src/docbkx/basic-install/src/figures/Neutron-PhysNet-Diagram.png', 'doc/src/docbkx/basic-install/src/basic-install_compute.xml', 'doc/src/docbkx/basic-install/src/basic-install_architecture.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-neutron.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-operating.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-services.xml']",16,8d546a94b529b7f9338ee98aa6533f3f4794b8ff,good2," <screen os=""ubuntu""><prompt>#</prompt> <userinput>apt-get install neutron-plugin-openvswitch-agent \ neutron-dhcp-agent neutron-l3-agent</userinput></screen> <screen os=""centos;rhel;fedora""><prompt>#</prompt> <userinput>yum install openstack-neutron openstack-neutron-openvswitch\ <section xml:id=""network-neutron""> <para>Edit <emphasis role=""bold"">/etc/neutron/neutron.conf</emphasis>:admin_user = neutron admin_user = neutron <para>Edit <emphasis role=""bold"">/etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini</emphasis>:sql_connection = mysql://neutron:password@10.10.10.10/neutronfirewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver</programlisting> <para>Edit <emphasis role=""bold"">/etc/neutron/dhcp_agent.ini</emphasis>: <para>Edit <emphasis role=""bold"">/etc/neutron/metadata_agent.ini</emphasis>:admin_user = neutron <screen os=""ubuntu""><prompt>#</prompt> <userinput>service neutron-plugin-openvswitch-agent start</userinput> <prompt>#</prompt> <userinput>service neutron-dhcp-agent restart</userinput> <prompt>#</prompt> <userinput>service neutron-metadata-agent restart</userinput> <prompt>#</prompt> <userinput>service neutron-l3-agent restart</userinput></screen> <screen os=""centos;rhel;fedora""><prompt>#</prompt> <userinput>service neutron-server restart</userinput> <prompt>#</prompt> <userinput>service neutron-openvswitch-agent restart</userinput> <prompt>#</prompt> <userinput>service neutron-dhcp-agent restart</userinput> <prompt>#</prompt> <userinput>service neutron-l3-agent restart</userinput> <prompt>#</prompt> <userinput>chkconfig neutron-server on</userinput> <prompt>#</prompt> <userinput>chkconfig neutron-openvswitch-agent on</userinput> <prompt>#</prompt> <userinput>chkconfig neutron-dhcp-agent on</userinput> <prompt>#</prompt> <userinput>chkconfig neutron-l3-agent on</userinput></screen> Check the <literal>/var/log/neutron/*.log</literal> files for errors that would prevent"," <screen os=""ubuntu""><prompt>#</prompt> <userinput>apt-get install quantum-plugin-openvswitch-agent \ quantum-dhcp-agent quantum-l3-agent</userinput></screen> <screen os=""centos;rhel;fedora""><prompt>#</prompt> <userinput>yum install openstack-quantum openstack-quantum-openvswitch\ <section xml:id=""network-quantum""> <para>Edit <emphasis role=""bold"">/etc/quantum/quantum.conf</emphasis>:admin_user = quantum admin_user = quantum <para>Edit <emphasis role=""bold"">/etc/quantum/plugins/openvswitch/ovs_quantum_plugin.ini</emphasis>:sql_connection = mysql://quantum:password@10.10.10.10/quantumfirewall_driver = quantum.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver</programlisting> <para>Edit <emphasis role=""bold"">/etc/quantum/dhcp_agent.ini</emphasis>: <para>Edit <emphasis role=""bold"">/etc/quantum/metadata_agent.ini</emphasis>:admin_user = quantum <screen os=""ubuntu""><prompt>#</prompt> <userinput>service quantum-plugin-openvswitch-agent start</userinput> <prompt>#</prompt> <userinput>service quantum-dhcp-agent restart</userinput> <prompt>#</prompt> <userinput>service quantum-metadata-agent restart</userinput> <prompt>#</prompt> <userinput>service quantum-l3-agent restart</userinput></screen> <screen os=""centos;rhel;fedora""><prompt>#</prompt> <userinput>service quantum-server restart</userinput> <prompt>#</prompt> <userinput>service quantum-openvswitch-agent restart</userinput> <prompt>#</prompt> <userinput>service quantum-dhcp-agent restart</userinput> <prompt>#</prompt> <userinput>service quantum-l3-agent restart</userinput> <prompt>#</prompt> <userinput>chkconfig quantum-server on</userinput> <prompt>#</prompt> <userinput>chkconfig quantum-openvswitch-agent on</userinput> <prompt>#</prompt> <userinput>chkconfig quantum-dhcp-agent on</userinput> <prompt>#</prompt> <userinput>chkconfig quantum-l3-agent on</userinput></screen> Check the <literal>/var/log/quantum/*.log</literal> files for errors that would prevent",125,125
openstack%2Fneutron~master~Ibb5a9a12ee451c317ae747924b336ffa044a20b1,openstack/neutron,master,Ibb5a9a12ee451c317ae747924b336ffa044a20b1,Clean up Cisco plugin config parameters,MERGED,2013-07-17 21:25:13.000000000,2013-07-23 19:24:52.000000000,2013-07-23 19:24:51.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 107}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6685}, {'_account_id': 6694}, {'_account_id': 6695}, {'_account_id': 6754}, {'_account_id': 6994}]","[{'number': 1, 'created': '2013-07-17 21:25:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6170f9205a4f22020a20d0aabc20db055de77875', 'message': 'Clean up Cisco plugin config paramaters\n\nChange-Id: Ibb5a9a12ee451c317ae747924b336ffa044a20b1\nFixes: bug 1201537\n'}, {'number': 2, 'created': '2013-07-17 21:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff97a30c37f6c6f06fa5478087d9b963442a33ee', 'message': 'Clean up Cisco plugin config paramaters\n\nFixes: bug 1201537\n\nChange-Id: Ibb5a9a12ee451c317ae747924b336ffa044a20b1\n'}, {'number': 3, 'created': '2013-07-17 21:38:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6334e9dc3814d95e48aa4b78214664931e8e41b7', 'message': 'Clean up Cisco plugin config parameters\n\nFixes: bug 1201537\n\nChange-Id: Ibb5a9a12ee451c317ae747924b336ffa044a20b1\n'}, {'number': 4, 'created': '2013-07-18 14:25:02.000000000', 'files': ['etc/neutron/plugins/cisco/cisco_plugins.ini', 'neutron/plugins/cisco/db/network_db_v2.py', 'neutron/plugins/cisco/common/config.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b40edd1d00c651daa698883c6bd87c8ce40f216b', 'message': 'Clean up Cisco plugin config parameters\n\nFixes: bug 1201537\n\nChange-Id: Ibb5a9a12ee451c317ae747924b336ffa044a20b1\n'}]",6,37575,b40edd1d00c651daa698883c6bd87c8ce40f216b,22,12,4,6524,,,0,"Clean up Cisco plugin config parameters

Fixes: bug 1201537

Change-Id: Ibb5a9a12ee451c317ae747924b336ffa044a20b1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/75/37575/3 && git format-patch -1 --stdout FETCH_HEAD,"['etc/neutron/plugins/cisco/cisco_plugins.ini', 'neutron/plugins/cisco/common/config.py']",2,6170f9205a4f22020a20d0aabc20db055de77875,bug/1201537,," cfg.StrOpt('max_ports', default='100', help=_(""Maximum Port value"")), cfg.StrOpt('max_port_profiles', default='65568', help=_(""Maximum Port Profile value"")), cfg.StrOpt('max_networks', default='65568', help=_(""Maximum Network value"")), cfg.StrOpt('manager_class', default='neutron.plugins.cisco.segmentation.' 'l2network_vlan_mgr_v2.L2NetworkVLANMgr', help=_(""Manager Class"")),",61,31
openstack%2Fneutron~master~Idcdaea0636e01381064983d8de5bfe3936357fb9,openstack/neutron,master,Idcdaea0636e01381064983d8de5bfe3936357fb9,LBaaS: add delete_health_monitor() to driver API,MERGED,2013-07-19 13:14:27.000000000,2013-07-23 19:24:44.000000000,2013-07-23 19:24:43.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 7317}]","[{'number': 1, 'created': '2013-07-19 13:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc1388c7a85c471e7d211d825065cc3eb7838eaa', 'message': 'LBaaS: add delete_health_monitor() to driver API\n\nCurrently there is create_health_monitor() in the driver API so\na driver may create an object on device but there is no delete_health_monitor()\nand monitor objects will remain on device forever.\nDriver should at least call plugin to delete a db object.\n\nFixes bug 1198996\n\nChange-Id: Idcdaea0636e01381064983d8de5bfe3936357fb9\n'}, {'number': 2, 'created': '2013-07-19 13:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/337c8c91e75f8968a63c6804969544db8acb379a', 'message': 'LBaaS: add delete_health_monitor() to driver API\n\nCurrently there is create_health_monitor() in the driver API so\na driver may create an object on device but there is no delete_health_monitor()\nand monitor objects will remain on device forever.\nDriver should at least call plugin to delete a db object.\n\nFixes bug 1198996\n\nChange-Id: Idcdaea0636e01381064983d8de5bfe3936357fb9\n'}, {'number': 3, 'created': '2013-07-19 13:38:38.000000000', 'files': ['neutron/services/loadbalancer/drivers/noop/noop_driver.py', 'neutron/services/loadbalancer/drivers/abstract_driver.py', 'neutron/services/loadbalancer/plugin.py', 'neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4bd7bea0dbb54b6ed287f21ab7a6d65b177f017c', 'message': 'LBaaS: add delete_health_monitor() to driver API\n\nCurrently there is create_health_monitor() in the driver API so\na driver may create an object on device but there is no delete_health_monitor()\nand monitor objects will remain on device forever.\nDriver should at least call plugin to delete a db object.\n\nFixes bug 1198996\n\nChange-Id: Idcdaea0636e01381064983d8de5bfe3936357fb9\n'}]",9,37895,4bd7bea0dbb54b6ed287f21ab7a6d65b177f017c,25,7,3,5948,,,0,"LBaaS: add delete_health_monitor() to driver API

Currently there is create_health_monitor() in the driver API so
a driver may create an object on device but there is no delete_health_monitor()
and monitor objects will remain on device forever.
Driver should at least call plugin to delete a db object.

Fixes bug 1198996

Change-Id: Idcdaea0636e01381064983d8de5bfe3936357fb9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/37895/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/loadbalancer/drivers/noop/noop_driver.py', 'neutron/services/loadbalancer/drivers/abstract_driver.py', 'neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py', 'neutron/services/loadbalancer/plugin.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py']",5,fc1388c7a85c471e7d211d825065cc3eb7838eaa,bug/1198996, ctx = context.get_admin_context() qry = ctx.session.query(ldb.HealthMonitor) qry = qry.filter_by(id=monitor['health_monitor']['id']) self.assertIsNotNone(qry.first()) qry = ctx.session.query(ldb.HealthMonitor) qry = qry.filter_by(id=monitor['health_monitor']['id']) self.assertIsNone(qry.first()),,26,0
openstack%2Fneutron~master~Iee8a2f4e8a8fdbb5e070b4bab78f7c6ba21daba1,openstack/neutron,master,Iee8a2f4e8a8fdbb5e070b4bab78f7c6ba21daba1,remove policy checks in port_security tests,MERGED,2013-07-23 01:40:34.000000000,2013-07-23 19:24:36.000000000,2013-07-23 19:24:36.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 4395}]","[{'number': 1, 'created': '2013-07-23 01:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/01b23b736fca82973f2a4f757ce1112240a8e154', 'message': 'remove policy checks in port_security tests\n\nThis patch removes the unneed policy checks in the port_security_tests\nthat are now done in the policy engine.\n\nFixes bug: 1203925\n\nChange-Id: Iee8a2f4e8a8fdbb5e070b4bab78f7c6ba21daba1\n'}, {'number': 2, 'created': '2013-07-23 15:52:27.000000000', 'files': ['neutron/tests/unit/test_extension_portsecurity.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9b0ccf6125809a5a568926101a04b52ed69a269d', 'message': 'remove policy checks in port_security tests\n\nThis patch removes the unneeded policy checks in the port_security_tests\nthat are now done in the policy engine.\n\nFixes bug: 1203925\n\nChange-Id: Iee8a2f4e8a8fdbb5e070b4bab78f7c6ba21daba1\n'}]",1,38239,9b0ccf6125809a5a568926101a04b52ed69a269d,12,7,2,4395,,,0,"remove policy checks in port_security tests

This patch removes the unneeded policy checks in the port_security_tests
that are now done in the policy engine.

Fixes bug: 1203925

Change-Id: Iee8a2f4e8a8fdbb5e070b4bab78f7c6ba21daba1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/38239/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/test_extension_portsecurity.py'],1,01b23b736fca82973f2a4f757ce1112240a8e154,bug/1203925,,"from neutron import policy port_security_enabled_create = ""create_port:port_security_enabled"" port_security_enabled_update = ""update_port:port_security_enabled"" def _enforce_set_auth(self, context, resource, action): return policy.enforce(context, action, resource) if attr.is_attr_set(port['port'][psec.PORTSECURITY]): self._enforce_set_auth(context, port, self.port_security_enabled_create) self._enforce_set_auth(context, port, self.port_security_enabled_update)",0,11
openstack%2Ftempest~master~Idcf55163614f69d81fed538f7190bb63fe11dc2c,openstack/tempest,master,Idcf55163614f69d81fed538f7190bb63fe11dc2c,Add exit codes if run_stress.py detects an error,MERGED,2013-07-22 07:43:40.000000000,2013-07-23 19:23:13.000000000,2013-07-23 19:23:13.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5803}, {'_account_id': 6743}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-07-22 07:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0cfd672e2b701ce17f445f9c12a059397c0891d5', 'message': 'Add exit codes if run_stress.py detects an error\n\nThis is just a very basic exit code handling. Could be later enhanced by\ndifferent exit codes.\n\nImplements: blueprint stress-tests\n\nChange-Id: Idcf55163614f69d81fed538f7190bb63fe11dc2c\n'}, {'number': 2, 'created': '2013-07-23 17:12:18.000000000', 'files': ['tempest/stress/run_stress.py', 'tempest/stress/driver.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/888ddc497239c085cf14151eef5a77e9d9a99938', 'message': 'Add exit codes if run_stress.py detects an error\n\nThis is just a very basic exit code handling. Could be later enhanced by\ndifferent exit codes.\n\nImplements: blueprint stress-tests\n\nChange-Id: Idcf55163614f69d81fed538f7190bb63fe11dc2c\n'}]",1,38111,888ddc497239c085cf14151eef5a77e9d9a99938,13,6,2,7872,,,0,"Add exit codes if run_stress.py detects an error

This is just a very basic exit code handling. Could be later enhanced by
different exit codes.

Implements: blueprint stress-tests

Change-Id: Idcf55163614f69d81fed538f7190bb63fe11dc2c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/11/38111/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/stress/run_stress.py', 'tempest/stress/driver.py']",2,0cfd672e2b701ce17f445f9c12a059397c0891d5,bp/stress-tests, if had_errors: return -1 else: return 0,,12,2
openstack%2Foslo.messaging~master~I91d8eafc2fa50cb4fab4df2960274be2f5c237a4,openstack/oslo.messaging,master,I91d8eafc2fa50cb4fab4df2960274be2f5c237a4,Allow use of hacking 0.6.0 and fix min version,MERGED,2013-07-19 20:47:02.000000000,2013-07-23 18:54:28.000000000,2013-07-23 18:54:28.000000000,"[{'_account_id': 3}, {'_account_id': 1994}, {'_account_id': 6786}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-07-19 20:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/cee9ce2011b1d5e17d814d208534ca02bfc1c9d0', 'message': 'Allow use of hacking 0.6.0\n\nChange-Id: I91d8eafc2fa50cb4fab4df2960274be2f5c237a4\n'}, {'number': 2, 'created': '2013-07-19 20:56:19.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/8eeaf67be905603038e225b96f3573a2a8dda5c8', 'message': 'Allow use of hacking 0.6.0 and fix min version\n\nChange-Id: I91d8eafc2fa50cb4fab4df2960274be2f5c237a4\n'}]",0,37966,8eeaf67be905603038e225b96f3573a2a8dda5c8,8,4,2,6786,,,0,"Allow use of hacking 0.6.0 and fix min version

Change-Id: I91d8eafc2fa50cb4fab4df2960274be2f5c237a4
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/66/37966/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,cee9ce2011b1d5e17d814d208534ca02bfc1c9d0,,"hacking>=0.5.3,<0.7","hacking>=0.5.3,<0.6",1,1
openstack%2Frequirements~master~I8eb668d8320174c2986a95b33ea412b7c0ee010f,openstack/requirements,master,I8eb668d8320174c2986a95b33ea412b7c0ee010f,Bump requests to 1.2.3.,ABANDONED,2013-07-03 17:08:36.000000000,2013-07-23 18:42:04.000000000,,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 1420}, {'_account_id': 1812}, {'_account_id': 2592}, {'_account_id': 6476}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-07-03 17:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/fd3c3ccafa4f58d46c5070d04943f517a72ab621', 'message': 'Bump requests to 1.2.3.\n\nUbuntu 13.10 ships requests, to include, 1.2.3, so make sure\nwe are instaling a newer version.\n\nChange-Id: I8eb668d8320174c2986a95b33ea412b7c0ee010f\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}, {'number': 2, 'created': '2013-07-10 19:45:23.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/94cad78546e62decfdec6e25b4ce86baac24e3b3', 'message': 'Bump requests to 1.2.3.\n\nUbuntu 13.10 ships requests, to include, 1.2.3, so make sure\nwe are instaling a newer version.\n\nChange-Id: I8eb668d8320174c2986a95b33ea412b7c0ee010f\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",3,35513,94cad78546e62decfdec6e25b4ce86baac24e3b3,14,7,2,24,,,0,"Bump requests to 1.2.3.

Ubuntu 13.10 ships requests, to include, 1.2.3, so make sure
we are instaling a newer version.

Change-Id: I8eb668d8320174c2986a95b33ea412b7c0ee010f
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/13/35513/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,fd3c3ccafa4f58d46c5070d04943f517a72ab621,(detached,"requests>=1.1,<=1.2.3","requests>=1.1,<1.2.3",1,1
openstack%2Fhorizon~stable%2Fgrizzly~I57510033fcc309b5d570d7ee6a9369a97775719b,openstack/horizon,stable/grizzly,I57510033fcc309b5d570d7ee6a9369a97775719b,Fix a few visual issues on the network topology diagram.,MERGED,2013-07-15 20:57:07.000000000,2013-07-23 18:39:05.000000000,2013-07-23 18:39:05.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 5623}]","[{'number': 1, 'created': '2013-07-15 20:57:07.000000000', 'files': ['openstack_dashboard/static/dashboard/less/horizon.less', 'horizon/static/horizon/js/horizon.networktopology.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b163c97c4cd0fac6d851d5264df823a620e8f67e', 'message': 'Fix a few visual issues on the network topology diagram.\n\nThis commit separates CIDR labels with a comma and adjusts the vertical\npositioning of port labels for improved readability.\n\nChange-Id: I57510033fcc309b5d570d7ee6a9369a97775719b\nFixes: bug #1199086\n'}]",0,37130,b163c97c4cd0fac6d851d5264df823a620e8f67e,7,4,1,8005,,,0,"Fix a few visual issues on the network topology diagram.

This commit separates CIDR labels with a comma and adjusts the vertical
positioning of port labels for improved readability.

Change-Id: I57510033fcc309b5d570d7ee6a9369a97775719b
Fixes: bug #1199086
",git fetch https://review.opendev.org/openstack/horizon refs/changes/30/37130/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/static/dashboard/less/horizon.less', 'horizon/static/horizon/js/horizon.networktopology.js']",2,b163c97c4cd0fac6d851d5264df823a620e8f67e,bug/1199086," var cidr = []; cidr.push(subnet.cidr); return cidr.join(', '); $('div.port span.ip').each(function(i, ip){ $(ip).css('top', '-'+$(ip).height()+'px'); }); ip_label += this.ip_address + ""<br />"";"," var cidr = """"; cidr += subnet.cidr; return cidr; ip_label += this.ip_address + "" "";",7,5
openstack%2Fnova~stable%2Fgrizzly~I9e39a7152e37756b34b1c8d77de057012743f0f7,openstack/nova,stable/grizzly,I9e39a7152e37756b34b1c8d77de057012743f0f7,Return proper error message when network conflicts,MERGED,2013-05-29 13:58:11.000000000,2013-07-23 18:30:44.000000000,2013-07-23 18:30:42.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1711}, {'_account_id': 4468}, {'_account_id': 5652}, {'_account_id': 6348}]","[{'number': 1, 'created': '2013-05-29 13:58:11.000000000', 'files': ['nova/exception.py', 'nova/network/manager.py', 'nova/tests/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/26ae09c6b49c202d65df401b1f6353329d006c63', 'message': ""Return proper error message when network conflicts\n\nFixes bug 1158075\nWhen creating a network which is already existing, we got\nan internal server error which can't show the error reason.\nThis patch returns conflict error(HTTP 409) instead of\ninternal server error(HTTP 500), so that users can know\nthe error reason from the error message.\n\nChange-Id: I9e39a7152e37756b34b1c8d77de057012743f0f7\n(cherry picked from commit 8a80c4c0968a9deceaa6d99629c6d7f7889769e5)\n""}]",0,30884,26ae09c6b49c202d65df401b1f6353329d006c63,12,8,1,6618,,,0,"Return proper error message when network conflicts

Fixes bug 1158075
When creating a network which is already existing, we got
an internal server error which can't show the error reason.
This patch returns conflict error(HTTP 409) instead of
internal server error(HTTP 500), so that users can know
the error reason from the error message.

Change-Id: I9e39a7152e37756b34b1c8d77de057012743f0f7
(cherry picked from commit 8a80c4c0968a9deceaa6d99629c6d7f7889769e5)
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/30884/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/network/manager.py', 'nova/tests/network/test_manager.py']",3,26ae09c6b49c202d65df401b1f6353329d006c63,bug/1158075," # CidrConflict: requested cidr (192.168.2.0/24) conflicts with # existing smaller cidr self.assertRaises(exception.CidrConflict, manager.create_networks, *args) # CidrConflict: Not enough subnets avail to satisfy requested num_ # networks - some subnets in requested range already # in use self.assertRaises(exception.CidrConflict, manager.create_networks, *args) # CidrConflict: cidr already in use self.assertRaises(exception.CidrConflict, manager.create_networks, *args) # CidrConflict: requested cidr (192.168.0.0/24) conflicts # with existing supernet self.assertRaises(exception.CidrConflict, manager.create_networks, *args) self.assertRaises(exception.CidrConflict, manager.create_networks, *args)"," # ValueError: requested cidr (192.168.2.0/24) conflicts with # existing smaller cidr self.assertRaises(ValueError, manager.create_networks, *args) # ValueError: Not enough subnets avail to satisfy requested num_ # networks - some subnets in requested range already # in use self.assertRaises(ValueError, manager.create_networks, *args) # ValueError: cidr already in use self.assertRaises(ValueError, manager.create_networks, *args) # ValueError: requested cidr (192.168.0.0/24) conflicts # with existing supernet self.assertRaises(ValueError, manager.create_networks, *args) self.assertRaises(ValueError, manager.create_networks, *args)",28,18
openstack%2Fnova~master~Ied716a5964fd86a919ffb8bac99100afb770896e,openstack/nova,master,Ied716a5964fd86a919ffb8bac99100afb770896e,Cell Scheduler support for hypervisor versions,MERGED,2013-07-17 06:36:54.000000000,2013-07-23 18:30:29.000000000,2013-07-23 18:30:27.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 782}, {'_account_id': 1313}, {'_account_id': 2166}, {'_account_id': 5441}, {'_account_id': 6992}, {'_account_id': 7502}, {'_account_id': 7602}]","[{'number': 1, 'created': '2013-07-17 06:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4eab98a0291d24d9391b9887e832569352254d01', 'message': 'Cell Scheduler support for hypervisor versions\n\nAdding the hypervisor version to cell capacities\nCreating a filter in cell scheduler to filter cells based on prominent hypervisor version\n\nPartially Implements blueprint xen-support-for-hypervisor-versions\n\nChange-Id: Ied716a5964fd86a919ffb8bac99100afb770896e\n'}, {'number': 2, 'created': '2013-07-18 10:48:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee91d3d9c19f7a8236ebf256bcbcadf61006b19e', 'message': 'Cell Scheduler support for hypervisor versions\n\nAdding the hypervisor version to cell capacities\nCreating a filter in cell scheduler to filter cells based on prominent hypervisor version\n\nPartially Implements blueprint xen-support-for-hypervisor-versions\n\nChange-Id: Ied716a5964fd86a919ffb8bac99100afb770896e\n'}, {'number': 3, 'created': '2013-07-18 10:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb166564fabf0d3770d23374f83f6ad2ba9a78e3', 'message': 'Cell Scheduler support for hypervisor versions\n\nAdding the hypervisor version to cell capacities\nCreating a filter in cell scheduler to filter cells based on prominent hypervisor version\n\nPartially Implements blueprint xen-support-for-hypervisor-versions\nDocImpact\n\nChange-Id: Ied716a5964fd86a919ffb8bac99100afb770896e\n'}, {'number': 4, 'created': '2013-07-19 09:10:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa1071ce2cb24655eaea7a11e2fe90a3fffef248', 'message': 'Cell Scheduler support for hypervisor versions\n\nAdding the hypervisor version to cell capacities\nCreating a filter in cell scheduler to filter cells based on\nprominent hypervisor version\n\nPartially Implements blueprint xen-support-for-hypervisor-versions\nDocImpact\n\nChange-Id: Ied716a5964fd86a919ffb8bac99100afb770896e\n'}, {'number': 5, 'created': '2013-07-22 10:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/314354b6e67c207389e7141defe59df8507879ac', 'message': ""Cell Scheduler support for hypervisor versions\n\nAdding the hypervisor version to cell capacities\nCreating a filter in cell scheduler to filter cells based on\nprominent hypervisor version\n\nPartially Implements blueprint xen-support-for-hypervisor-versions\n\nDocImpact: Adding a filter in cell scheduler to pick cells based on\nthe hypervisor version required by the image. The image can have\nmetadata called hypervisor_version_requires which will be matched\nagainst the cell's prominent hypervisor version.\nThe prominent_hypervisor_version is stored in nova.conf under cell\ncapabilities.\n\nChange-Id: Ied716a5964fd86a919ffb8bac99100afb770896e\n""}, {'number': 6, 'created': '2013-07-23 08:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd84ca07ebcd7bc96c6eebe593e3491f3aed2873', 'message': ""Cell Scheduler support for hypervisor versions\n\nAdding the hypervisor version to cell capacities\nCreating a filter in cell scheduler to filter cells based on\nprominent hypervisor version\n\nPartially Implements blueprint xen-support-for-hypervisor-versions\n\nDocImpact: Adding a filter in cell scheduler to pick cells based on\nthe hypervisor version required by the image. The image can have\nmetadata called hypervisor_version_requires which will be matched\nagainst the cell's prominent hypervisor version.\nThe prominent_hypervisor_version is stored in nova.conf under cell\ncapabilities.\n\nChange-Id: Ied716a5964fd86a919ffb8bac99100afb770896e\n""}, {'number': 7, 'created': '2013-07-23 09:38:41.000000000', 'files': ['nova/tests/cells/test_cells_filters.py', 'nova/cells/filters/image_properties.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0c22f71fb338b1aa7c4a2b30555449a464ad3874', 'message': ""Cell Scheduler support for hypervisor versions\n\nAdding the hypervisor version to cell capacities\nCreating a filter in cell scheduler to filter cells based on\nprominent hypervisor version\n\nPartially Implements blueprint xen-support-for-hypervisor-versions\n\nDocImpact: Adding a filter in cell scheduler to pick cells based on\nthe hypervisor version required by the image. The image can have\nmetadata called hypervisor_version_requires which will be matched\nagainst the cell's prominent hypervisor version.\nThe prominent_hypervisor_version is stored in nova.conf under cell\ncapabilities.\n\nChange-Id: Ied716a5964fd86a919ffb8bac99100afb770896e\n""}]",33,37404,0c22f71fb338b1aa7c4a2b30555449a464ad3874,39,9,7,6992,,,0,"Cell Scheduler support for hypervisor versions

Adding the hypervisor version to cell capacities
Creating a filter in cell scheduler to filter cells based on
prominent hypervisor version

Partially Implements blueprint xen-support-for-hypervisor-versions

DocImpact: Adding a filter in cell scheduler to pick cells based on
the hypervisor version required by the image. The image can have
metadata called hypervisor_version_requires which will be matched
against the cell's prominent hypervisor version.
The prominent_hypervisor_version is stored in nova.conf under cell
capabilities.

Change-Id: Ied716a5964fd86a919ffb8bac99100afb770896e
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/37404/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/cells/test_cells_filters.py', 'nova/cells/filters/image_properties.py']",2,4eab98a0291d24d9391b9887e832569352254d01,bp/xen-support-for-hypervisor-versions,"# Copyright (c) 2012-2013 Rackspace Hosting # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Image properties filter. A scheduler hint of 'target_cell' with a value of a full cell name may be specified to route a build to a particular cell. No error handling is done as there's no way to know whether the full path is a valid. """""" from distutils import versionpredicate from nova.cells import filters from nova.openstack.common import log as logging LOG = logging.getLogger(__name__) class ImagePropertiesFilter(filters.BaseCellFilter): """"""Target cell filter. Works by specifying a scheduler hint of 'target_cell'. The value should be the full cell path. """""" def filter_all(self, cells, filter_properties): """"""Override filter_all() which operates on the full list of cells... """""" # if not self.authorized(filter_properties['context']): # return cells image_properties = filter_properties.get('image_properties') if not image_properties: return cells hypervisor_version_requires =\ image_properties.get('hypervisor_version_requires', None) if not hypervisor_version_requires: return cells filtered_cells = [] for cell in cells: version = cell.capabilities.get('prominent_hypervisor_version') if version is None or self._matches_version(version, hypervisor_version_requires): filtered_cells.append(cell) return filtered_cells def _matches_version(self, version, version_requires): predicate = versionpredicate.VersionPredicate( 'prop (%s)' % version_requires) return predicate.satisfied_by(version) ",,105,0
openstack%2Fcinder~master~Ib9577ac160596a6878d1729f6022885b6cfa90e2,openstack/cinder,master,Ib9577ac160596a6878d1729f6022885b6cfa90e2,Add create & attach times to SolidFire attributes.,MERGED,2013-07-19 23:09:19.000000000,2013-07-23 18:24:44.000000000,2013-07-23 18:24:44.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-07-19 23:09:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1f229bbec0ef851371c04e6597f116d89f31a446', 'message': ""Add create & attach times to SolidFire attributes.\n\nThis change simply adds create_time and attach_time to\nthe SolidFire devices attributes.\n\nTimes are taken from the volume-ref object, attach_time\nis only set/present after an attach, and is also removed\nfrom the attributes list on a detach.\n\nThis also required that we actually set attach_time on the\nvolume in the db.  We have the column, but we weren't actually\nsetting it, so this change required that be fixed.\n\nIn the future we should also look at changing the attach_time\nfrom a string to a proper date-time object.\n\nChange-Id: Ib9577ac160596a6878d1729f6022885b6cfa90e2\n""}, {'number': 2, 'created': '2013-07-22 15:06:32.000000000', 'files': ['cinder/volume/manager.py', 'cinder/volume/drivers/solidfire.py', 'cinder/volume/driver.py', 'cinder/tests/test_solidfire.py', 'cinder/db/sqlalchemy/api.py', 'cinder/volume/drivers/scality.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5d8a457c4e91a7cfe1ab5a09cdb2ca48ec6aa977', 'message': ""Add create & attach times to SolidFire attributes.\n\nThis change simply adds create_time and attach_time to\nthe SolidFire devices attributes.\n\nTimes are taken from the volume-ref object, attach_time\nis only set/present after an attach, and is also removed\nfrom the attributes list on a detach.\n\nThis also required that we actually set attach_time on the\nvolume in the db.  We have the column, but we weren't actually\nsetting it, so this change required that be fixed.\n\nIn the future we should also look at changing the attach_time\nfrom a string to a proper date-time object.\n\nChange-Id: Ib9577ac160596a6878d1729f6022885b6cfa90e2\n""}]",9,37997,5d8a457c4e91a7cfe1ab5a09cdb2ca48ec6aa977,14,5,2,2243,,,0,"Add create & attach times to SolidFire attributes.

This change simply adds create_time and attach_time to
the SolidFire devices attributes.

Times are taken from the volume-ref object, attach_time
is only set/present after an attach, and is also removed
from the attributes list on a detach.

This also required that we actually set attach_time on the
volume in the db.  We have the column, but we weren't actually
setting it, so this change required that be fixed.

In the future we should also look at changing the attach_time
from a string to a proper date-time object.

Change-Id: Ib9577ac160596a6878d1729f6022885b6cfa90e2
",git fetch https://review.opendev.org/openstack/cinder refs/changes/97/37997/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/manager.py', 'cinder/volume/driver.py', 'cinder/volume/drivers/solidfire.py', 'cinder/tests/test_solidfire.py', 'cinder/db/sqlalchemy/api.py']",5,1f229bbec0ef851371c04e6597f116d89f31a446,add_create_and_attach_to_sf_attributes, volume_ref['attach_time'] = None,,105,20
openstack%2Frequirements~master~Id0b033c91e78c74643f79a36607dccd34370dd6d,openstack/requirements,master,Id0b033c91e78c74643f79a36607dccd34370dd6d,"Put zmq, redis, mysql into requirements.txt",ABANDONED,2013-07-23 18:06:38.000000000,2013-07-23 18:10:21.000000000,,[],"[{'number': 1, 'created': '2013-07-23 18:06:38.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/85b5a184f464b0ce5d48788bad9bc99a47c0bbfe', 'message': 'Put zmq, redis, mysql into requirements.txt\n\nZeroMQ, Redis, and MySQL dependencies were incorrectly\nplaced into test-requirements.txt. Move them!\n\nI believe they were in here because they had C dependencies and\nwere optional for testing in an age before we used tox. Other\noptional modules with C dependencies (such as Qpid) are in\nthe standard requirements.txt file.\n\nChange-Id: Id0b033c91e78c74643f79a36607dccd34370dd6d\n'}]",0,38344,85b5a184f464b0ce5d48788bad9bc99a47c0bbfe,2,0,1,159,,,0,"Put zmq, redis, mysql into requirements.txt

ZeroMQ, Redis, and MySQL dependencies were incorrectly
placed into test-requirements.txt. Move them!

I believe they were in here because they had C dependencies and
were optional for testing in an age before we used tox. Other
optional modules with C dependencies (such as Qpid) are in
the standard requirements.txt file.

Change-Id: Id0b033c91e78c74643f79a36607dccd34370dd6d
",git fetch https://review.opendev.org/openstack/requirements refs/changes/44/38344/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,85b5a184f464b0ce5d48788bad9bc99a47c0bbfe,,,MySQL-pythonpyzmq==2.2.0.1 redis,3,3
openstack%2Foslo-incubator~master~I26a67d41f5844a6d847cdbe43318459004c75629,openstack/oslo-incubator,master,I26a67d41f5844a6d847cdbe43318459004c75629,"Put zmq, redis, mysql into requirements.txt",ABANDONED,2013-07-23 18:03:22.000000000,2013-07-23 18:08:29.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-07-23 18:03:22.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a6c8fb461caa644e6212b8d53ed47224a403db22', 'message': 'Put zmq, redis, mysql into requirements.txt\n\nZeroMQ, Redis, and MySQL dependencies were incorrectly\nplaced into test-requirements.txt. Move them!\n\nI believe they were in here because they had C dependencies and\nwere optional for testing in an age before we used tox. Other\noptional modules with C dependencies (such as Qpid) are in\nthe standard requirements.txt file.\n\nChange-Id: I26a67d41f5844a6d847cdbe43318459004c75629\n'}]",0,38343,a6c8fb461caa644e6212b8d53ed47224a403db22,2,1,1,159,,,0,"Put zmq, redis, mysql into requirements.txt

ZeroMQ, Redis, and MySQL dependencies were incorrectly
placed into test-requirements.txt. Move them!

I believe they were in here because they had C dependencies and
were optional for testing in an age before we used tox. Other
optional modules with C dependencies (such as Qpid) are in
the standard requirements.txt file.

Change-Id: I26a67d41f5844a6d847cdbe43318459004c75629
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/43/38343/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,a6c8fb461caa644e6212b8d53ed47224a403db22,zmq-req-file,,mysql-pythonpyzmq==2.2.0.1 redis,3,3
openstack%2Fhorizon~master~I64c68db0632b6547a6340c952bdb9cafe11ea1d9,openstack/horizon,master,I64c68db0632b6547a6340c952bdb9cafe11ea1d9,Unpinning upper bound on python-*clients,MERGED,2013-07-12 20:25:02.000000000,2013-07-23 17:48:07.000000000,2013-07-23 17:48:06.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 4978}, {'_account_id': 5623}]","[{'number': 1, 'created': '2013-07-12 20:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b0e19f21bc3fd8ce02d6e474acda5d9c6fcb6ba2', 'message': 'Unpinning upper bound on python-*clients\n\nFixes: bug #1200214\n\nChange-Id: I64c68db0632b6547a6340c952bdb9cafe11ea1d9\n'}, {'number': 2, 'created': '2013-07-23 14:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/423fc9085549b41b78f2888c0795f45bc698390b', 'message': 'Unpinning upper bound on python-*clients\n\nIf any of the projects specify a capped client, it has the\npotential for preventing that client from being tested in the\ngate. To fix this, maximum versions are uncapped for all\nopenstack client code in all openstack projects.\n\npython-neutronclient is treated as an exception for now.\n\nFixes: bug #1200214\n\nChange-Id: I64c68db0632b6547a6340c952bdb9cafe11ea1d9\n'}, {'number': 3, 'created': '2013-07-23 15:41:48.000000000', 'files': ['run_tests.sh', 'requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/129a3d912998abef768492af125bea29bd6f0aa7', 'message': 'Unpinning upper bound on python-*clients\n\nIf any of the projects specify a capped client, it has the\npotential for preventing that client from being tested in the\ngate. To fix this, maximum versions are uncapped for all\nopenstack client code in all openstack projects.\n\npython-neutronclient is treated as an exception for now.\n\nFixes: bug #1200214\n\nChange-Id: I64c68db0632b6547a6340c952bdb9cafe11ea1d9\n'}]",0,36897,129a3d912998abef768492af125bea29bd6f0aa7,15,5,3,5623,,,0,"Unpinning upper bound on python-*clients

If any of the projects specify a capped client, it has the
potential for preventing that client from being tested in the
gate. To fix this, maximum versions are uncapped for all
openstack client code in all openstack projects.

python-neutronclient is treated as an exception for now.

Fixes: bug #1200214

Change-Id: I64c68db0632b6547a6340c952bdb9cafe11ea1d9
",git fetch https://review.opendev.org/openstack/horizon refs/changes/97/36897/2 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'requirements.txt']",2,b0e19f21bc3fd8ce02d6e474acda5d9c6fcb6ba2,bug/1200214,"python-cinderclient>=1.0.4 python-glanceclient>=0.9.0python-keystoneclient>=0.2.1 python-novaclient>=2.12.0 python-neutronclient>=2.2.3,<3 python-swiftclient>=1.2","python-cinderclient>=1.0.4,<2 python-glanceclient>=0.9.0,<2python-keystoneclient>=0.2,<0.3 python-novaclient>=2.12.0,<3 python-neutronclient>=2.2.3,<3.0.0 python-swiftclient>=1.2,<2",7,7
openstack%2Fpython-swiftclient~master~Ie08fe63b87e75bb099105ca1de860f9ab6c3340b,openstack/python-swiftclient,master,Ie08fe63b87e75bb099105ca1de860f9ab6c3340b,python3: Start of adding basic python3 support.,MERGED,2013-07-18 17:56:41.000000000,2013-07-23 17:41:16.000000000,2013-07-23 17:41:16.000000000,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 866}, {'_account_id': 2622}]","[{'number': 1, 'created': '2013-07-18 17:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/8c96cf7faabbe9a8bec99c347e4a0e48f551cb07', 'message': 'python3: Start of adding basic python3 support.\n\nFix imports so its python3 compliant.\n\nChange-Id: Ie08fe63b87e75bb099105ca1de860f9ab6c3340b\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}, {'number': 2, 'created': '2013-07-18 18:00:09.000000000', 'files': ['tests/test_swiftclient.py', 'swiftclient/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/69281a580f360a6d8c6a9631a55155e47cde2e40', 'message': 'python3: Start of adding basic python3 support.\n\nFix imports so its python3 compliant.\n\nChange-Id: Ie08fe63b87e75bb099105ca1de860f9ab6c3340b\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",0,37733,69281a580f360a6d8c6a9631a55155e47cde2e40,7,4,2,24,,,0,"python3: Start of adding basic python3 support.

Fix imports so its python3 compliant.

Change-Id: Ie08fe63b87e75bb099105ca1de860f9ab6c3340b
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/33/37733/2 && git format-patch -1 --stdout FETCH_HEAD,['swiftclient/__init__.py'],1,8c96cf7faabbe9a8bec99c347e4a0e48f551cb07,(detached,from .client import *,from client import *,1,1
openstack%2Fcinder~master~I0892af8d81415880d5e0f9aab5c7cd95ff3bf6b9,openstack/cinder,master,I0892af8d81415880d5e0f9aab5c7cd95ff3bf6b9,Fixes RBD driver docstring format issues.,MERGED,2013-07-22 23:07:02.000000000,2013-07-23 17:23:04.000000000,2013-07-23 17:23:04.000000000,"[{'_account_id': 3}, {'_account_id': 1107}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 6737}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-07-22 23:07:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1cca587f6f2d572c9087cc786f78f2202dfd5eef', 'message': 'Fixes RBD driver docstring format issues.\n\nAll docstrings should now comply with HACKING.rst\n\nChange-Id: I0892af8d81415880d5e0f9aab5c7cd95ff3bf6b9\nFixes: bug #1203697\n'}, {'number': 2, 'created': '2013-07-23 07:30:01.000000000', 'files': ['cinder/volume/drivers/rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/adae17dcf49878d8a9785399081651f1c3bc641c', 'message': 'Fixes RBD driver docstring format issues.\n\nAll docstrings should now comply with HACKING.rst\n\nChange-Id: I0892af8d81415880d5e0f9aab5c7cd95ff3bf6b9\nFixes: bug #1203697\n'}]",2,38220,adae17dcf49878d8a9785399081651f1c3bc641c,14,9,2,6737,,,0,"Fixes RBD driver docstring format issues.

All docstrings should now comply with HACKING.rst

Change-Id: I0892af8d81415880d5e0f9aab5c7cd95ff3bf6b9
Fixes: bug #1203697
",git fetch https://review.opendev.org/openstack/cinder refs/changes/20/38220/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/rbd.py'],1,1cca587f6f2d572c9087cc786f78f2202dfd5eef,bug/1203697," """"""Convert a string to ascii, or return None if the input is None. """"""RBD image metadata to be used with RBDImageIOWrapper."""""" """"""Wrapper to provide standard Python IO interface to RBD images. This enables librbd.Image objects to be treated as standard Python IO objects. Calling unimplemented interfaces will raise IOError. # NOTE(dosaboy): posix files do not barf if you read beyond their # length (they just return nothing) but rbd images do so we need to # return empty string if we have reached the end of the image. RBD does not have support for fileno() so we raise IOError. Raising IOError is recommended way to notify caller that interface is not supported - see http://docs.python.org/2/library/io.html#io.IOBase """"""Context manager for dealing with an existing rbd volume. """"""Context manager to simplify error handling for connecting to ceph."""""" """"""Implements RADOS block device (RBD) volume commands."""""" """"""Returns an error if prerequisites aren't met."""""" """"""Return the current state of the volume service. If 'refresh' is True, run the update first. """"""Clone a logical volume."""""" """"""Creates an rbd snapshot."""""" """"""Deletes an rbd snapshot."""""" """"""Exports the volume."""""" """"""Removes an export for a logical volume."""""""," """""" Convert a string to ascii, or return None if the input is None. """"""RBD image metadata to be used with RBDImageIOWrapper"""""" """""" Wrapper to provide standard Python IO interface to RBD images so that they can be treated as files. # (dosaboy): posix files do not barf if you read beyond their length # (they just return nothing) but rbd images do so we need to return # empty string if we are at the end of the image Since rbd image does not have a fileno we raise an IOError (recommended for IOBase class implementations - see http://docs.python.org/2/library/io.html#io.IOBase) """""" Context manager for dealing with an existing rbd volume. """""" Context manager to simplify error handling for connecting to ceph """""" """"""Implements RADOS block device (RBD) volume commands"""""" """"""Returns an error if prerequisites aren't met"""""" """"""Return the current state of the volume service. If 'refresh' is True, run the update first. """"""Clone a logical volume"""""" """"""Creates an rbd snapshot"""""" """"""Deletes an rbd snapshot"""""" """"""Exports the volume"""""" """"""Removes an export for a logical volume""""""",27,26
openstack%2Fceilometer~master~If00ed219d42f268dd3229980f13e9de82929890e,openstack/ceilometer,master,If00ed219d42f268dd3229980f13e9de82929890e,Change nose to testr in the documentation,MERGED,2013-07-23 10:15:16.000000000,2013-07-23 17:22:56.000000000,2013-07-23 17:22:56.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-23 10:15:16.000000000', 'files': ['doc/source/contributing/source.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e12e2da9e63bb3dada5b4c25cfce463e019865af', 'message': 'Change nose to testr in the documentation\n\nThis change update how to running test of the documentation.\nIt change nose reference to the testr.\n\nDocImpact\nFixes bug #1193165\n\nChange-Id: If00ed219d42f268dd3229980f13e9de82929890e\n'}]",1,38275,e12e2da9e63bb3dada5b4c25cfce463e019865af,11,4,1,2813,,,0,"Change nose to testr in the documentation

This change update how to running test of the documentation.
It change nose reference to the testr.

DocImpact
Fixes bug #1193165

Change-Id: If00ed219d42f268dd3229980f13e9de82929890e
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/75/38275/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributing/source.rst'],1,e12e2da9e63bb3dada5b4c25cfce463e019865af,bug/1193165," As tox is a wrapper around testr, it also accepts the same flags as testr. See the `testr documentation`_ for details about these additional flags. .. _testr documentation: https://testrepository.readthedocs.org/en/latest/MANUAL.html Use a double hyphen to pass options to testr. For example, to run only tests under tests/api/v2:: $ tox -e py27 -- api.v2"," As tox is a wrapper around nose, it also accepts the same flags as nosetests. See the `nose options documentation`_ for details about these additional flags. .. _nose options documentation: http://readthedocs.org/docs/nose/en/latest/usage.html#options Use a double hyphen to pass options to nose. For example, to set verbose flag and to run only tests under tests/api/v2:: $ tox -e py27 -- -v api/v2",5,6
openstack%2Fswift~master~Ib599b5ec8fd223878ec18df7c1ec8d952fc2630a,openstack/swift,master,Ib599b5ec8fd223878ec18df7c1ec8d952fc2630a,Add 'Z' into isoformat for UTC time,MERGED,2013-07-20 01:54:23.000000000,2013-07-23 17:19:19.000000000,2013-07-23 17:19:19.000000000,"[{'_account_id': 3}, {'_account_id': 1009}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-07-20 01:54:23.000000000', 'files': ['swift/container/server.py', 'test/unit/container/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/7cd01a63d340c254116da1ef9937d30048184dbe', 'message': ""Add 'Z' into isoformat for UTC time\n\nBased on this http://en.wikipedia.org/wiki/ISO_8601#Time_zone_designators.\nA isofomt of time need a 'Z' for UTC time zone, or none for local time zone\n\nrequest on GET /<version>/<account>/<container>?format=json still output a\nUTC time without 'Z'\n\nfixes bug #1169287\nChange-Id: Ib599b5ec8fd223878ec18df7c1ec8d952fc2630a\n""}]",0,38008,7cd01a63d340c254116da1ef9937d30048184dbe,9,5,1,6835,,,0,"Add 'Z' into isoformat for UTC time

Based on this http://en.wikipedia.org/wiki/ISO_8601#Time_zone_designators.
A isofomt of time need a 'Z' for UTC time zone, or none for local time zone

request on GET /<version>/<account>/<container>?format=json still output a
UTC time without 'Z'

fixes bug #1169287
Change-Id: Ib599b5ec8fd223878ec18df7c1ec8d952fc2630a
",git fetch https://review.opendev.org/openstack/swift refs/changes/08/38008/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/server.py', 'test/unit/container/test_server.py']",2,7cd01a63d340c254116da1ef9937d30048184dbe,bug/1169287," ""last_modified"":""1970-01-01T00:00:01.000000Z""}, ""last_modified"":""1970-01-01T00:00:01.000000Z""}, ""last_modified"":""1970-01-01T00:00:01.000000Z""}] ""last_modified"":""1970-01-01T00:00:01.500000Z""}, ""last_modified"":""1970-01-01T00:00:01.000000Z""}, ] '<last_modified>1970-01-01T00:00:01.000000Z' \ '<last_modified>1970-01-01T00:00:01.000000Z' \ '<last_modified>1970-01-01T00:00:01.000000Z' \ ""last_modified"":""1970-01-01T00:00:01.000000Z""}, ""last_modified"":""1970-01-01T00:00:01.000000Z""}])"," ""last_modified"":""1970-01-01T00:00:01.000000""}, ""last_modified"":""1970-01-01T00:00:01.000000""}, ""last_modified"":""1970-01-01T00:00:01.000000""}] ""last_modified"":""1970-01-01T00:00:01.500000""}, ""last_modified"":""1970-01-01T00:00:01.000000""}, ] '<last_modified>1970-01-01T00:00:01.000000' \ '<last_modified>1970-01-01T00:00:01.000000' \ '<last_modified>1970-01-01T00:00:01.000000' \ ""last_modified"":""1970-01-01T00:00:01.000000""}, ""last_modified"":""1970-01-01T00:00:01.000000""}])",12,10
openstack%2Fceilometer~master~I37842e945a7e2908e17d5ce886e17047a36818f7,openstack/ceilometer,master,I37842e945a7e2908e17d5ce886e17047a36818f7,Always init cfg.CONF before running a test,MERGED,2013-07-23 16:10:14.000000000,2013-07-23 17:19:13.000000000,2013-07-23 17:19:12.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-23 16:10:14.000000000', 'files': ['ceilometer/tests/base.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3ee1fa3f136dd769710b6b24ca1454ee864bbbd9', 'message': 'Always init cfg.CONF before running a test\n\nIn all tests cfg.CONF is not (re)initialised correctly\nBy chance in ceilometer , the only method that fail when conf is not\ninitialised is cfg.CONF.find_file.\nAnd because some tests do special initialisation (ie: the ones that test\nceilometer.service.prepare_service stuff), the method cfg.CONF.find_file\nworks when we run all tests.\n\nBut if you decide to run only one test (like below) that use find_file it fail\nbecause cfg.CONF is not initialised.\n\n  tox -epy27,pep8 api.v2\n\nNot all configurations opts are impacted but only the CLI opts ones that are\nset only when cfg.CONF() is called.\n\nThis change initialise cfg.CONF on each test (but the test can\ncontinue to reinitialise it if needed)\n\nChange-Id: I37842e945a7e2908e17d5ce886e17047a36818f7\n'}]",0,38319,3ee1fa3f136dd769710b6b24ca1454ee864bbbd9,6,3,1,2813,,,0,"Always init cfg.CONF before running a test

In all tests cfg.CONF is not (re)initialised correctly
By chance in ceilometer , the only method that fail when conf is not
initialised is cfg.CONF.find_file.
And because some tests do special initialisation (ie: the ones that test
ceilometer.service.prepare_service stuff), the method cfg.CONF.find_file
works when we run all tests.

But if you decide to run only one test (like below) that use find_file it fail
because cfg.CONF is not initialised.

  tox -epy27,pep8 api.v2

Not all configurations opts are impacted but only the CLI opts ones that are
set only when cfg.CONF() is called.

This change initialise cfg.CONF on each test (but the test can
continue to reinitialise it if needed)

Change-Id: I37842e945a7e2908e17d5ce886e17047a36818f7
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/19/38319/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/base.py'],1,3ee1fa3f136dd769710b6b24ca1454ee864bbbd9,sileht/init-cfg_CONF," cfg.CONF([], project='ceilometer')",,1,0
openstack%2Fironic~master~Id37949caa5a487cd98b6b85c026689fbd63cb5d8,openstack/ironic,master,Id37949caa5a487cd98b6b85c026689fbd63cb5d8,Remove extra pep8/flake8/pyflakes requirements,MERGED,2013-07-22 23:08:26.000000000,2013-07-23 17:17:38.000000000,2013-07-23 17:17:38.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2889}, {'_account_id': 6773}]","[{'number': 1, 'created': '2013-07-22 23:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/39b43767f90c78f94d9264f3af36670d268ca53a', 'message': ""Remove extra requirements\n\npep8 flake8 and pyflakes are pinned as part of hacking.  So they don't\nneed to be pinned here as well.\n\nAlso add posargs to flake8, so can do things like 'tox -epep8 --\n--statistics'\n\nChange-Id: Id37949caa5a487cd98b6b85c026689fbd63cb5d8\n""}, {'number': 2, 'created': '2013-07-22 23:09:14.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic/commit/464d9ba42605967e6b0a11e13ffcad06449ea904', 'message': ""Remove extra pep8/flake8/pyflakes requirements\n\npep8 flake8 and pyflakes are pinned as part of hacking.  So they don't\nneed to be pinned here as well.\n\nAlso add posargs to flake8, so can do things like 'tox -epep8 --\n--statistics'\n\nChange-Id: Id37949caa5a487cd98b6b85c026689fbd63cb5d8\n""}]",0,38221,464d9ba42605967e6b0a11e13ffcad06449ea904,10,4,2,1849,,,0,"Remove extra pep8/flake8/pyflakes requirements

pep8 flake8 and pyflakes are pinned as part of hacking.  So they don't
need to be pinned here as well.

Also add posargs to flake8, so can do things like 'tox -epep8 --
--statistics'

Change-Id: Id37949caa5a487cd98b6b85c026689fbd63cb5d8
",git fetch https://review.opendev.org/openstack/ironic refs/changes/21/38221/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,39b43767f90c78f94d9264f3af36670d268ca53a,hacking, flake8 {posargs}, flake8,1,5
openstack%2Fswift~master~Ib5e81ad0476c56cf84d222d67f55b8db3eb0249e,openstack/swift,master,Ib5e81ad0476c56cf84d222d67f55b8db3eb0249e,Corrected a number of style violations in the tests.,MERGED,2013-07-22 22:28:32.000000000,2013-07-23 17:06:07.000000000,2013-07-23 17:06:06.000000000,"[{'_account_id': 3}, {'_account_id': 1009}, {'_account_id': 2166}, {'_account_id': 2622}]","[{'number': 1, 'created': '2013-07-22 22:28:32.000000000', 'files': ['test/unit/obj/test_replicator.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/0e3103c0dd3690f5e69ec7953c270430d0564d12', 'message': 'Corrected a number of style violations in the tests.\n\nChange-Id: Ib5e81ad0476c56cf84d222d67f55b8db3eb0249e\n'}]",0,38216,0e3103c0dd3690f5e69ec7953c270430d0564d12,9,4,1,7680,,,0,"Corrected a number of style violations in the tests.

Change-Id: Ib5e81ad0476c56cf84d222d67f55b8db3eb0249e
",git fetch https://review.opendev.org/openstack/swift refs/changes/16/38216/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/obj/test_replicator.py'],1,0e3103c0dd3690f5e69ec7953c270430d0564d12,style-fixups," ] self.ring.get_part_nodes(int(cur_part)) self.ring.get_part_nodes(int(cur_part)) self.ring.get_part_nodes(int(cur_part)) reqs.append(mock.call(node, local_job, ['a83'])) node['replication_ip'] = '127.0.0.11' node['replication_port'] = '6011'"," ] process_errors = [] self.ring.get_part_nodes(int(cur_part)) \ self.ring.get_part_nodes(int(cur_part)) \ self.ring.get_part_nodes(int(cur_part)) \ reqs.append(mock.call(node, local_job, ['a83'])) node['replication_ip'] = '127.0.0.11' node['replication_port'] = '6011'",7,8
openstack%2Fneutron~master~I8cabf1868d5eac04dd31271932d5c4fadae78935,openstack/neutron,master,I8cabf1868d5eac04dd31271932d5c4fadae78935,"Fixes Opt type of ""topologyname""",MERGED,2013-07-18 06:33:01.000000000,2013-07-23 16:15:30.000000000,2013-07-23 16:15:29.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 1994}, {'_account_id': 2583}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5948}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-07-18 06:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bac0a3e89550748c349081b70cdff192d0e07000', 'message': 'Fixes Opt type of ""topologyname""\n\nChanged topologyname from IntOpt to StrOpt\n\nChange-Id: I8cabf1868d5eac04dd31271932d5c4fadae78935\n'}, {'number': 2, 'created': '2013-07-18 07:50:32.000000000', 'files': ['neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/95a63d1b701b5b0c7fe731bf170ccd4f22de9fa6', 'message': 'Fixes Opt type of ""topologyname""\n\nChanged topologyname from IntOpt to StrOpt\n\nFixes bug #1202538\n\nChange-Id: I8cabf1868d5eac04dd31271932d5c4fadae78935\n'}]",0,37628,95a63d1b701b5b0c7fe731bf170ccd4f22de9fa6,15,10,2,1994,,,0,"Fixes Opt type of ""topologyname""

Changed topologyname from IntOpt to StrOpt

Fixes bug #1202538

Change-Id: I8cabf1868d5eac04dd31271932d5c4fadae78935
",git fetch https://review.opendev.org/openstack/neutron refs/changes/28/37628/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py'],1,bac0a3e89550748c349081b70cdff192d0e07000,bug/1202538," cfg.StrOpt('topologyname', default='t1',"," cfg.IntOpt('topologyname', default='t1',",1,1
openstack%2Fnova~stable%2Fgrizzly~Ia02b0b4c7027cbd09a51042ca1b5d28890413626,openstack/nova,stable/grizzly,Ia02b0b4c7027cbd09a51042ca1b5d28890413626,Fix the filtered characters list from console-log,MERGED,2013-07-10 15:49:21.000000000,2013-07-23 16:15:19.000000000,2013-07-23 16:15:17.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 1955}, {'_account_id': 7808}]","[{'number': 1, 'created': '2013-07-10 15:49:21.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_console_output.py', 'nova/api/openstack/compute/contrib/console_output.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/01fd5c212ae80318aacd60d4e1a36f91c78867f7', 'message': ""Fix the filtered characters list from console-log\n\nIn fffcaea1 ^M was added to the list of characters to filter from the\nconsole-log output but, because of a typo in the regexp, the\ncharacter '-' was added to that list too and has been removed since\nthen.\n\nFixes bug #1194032\n\nChange-Id: Ia02b0b4c7027cbd09a51042ca1b5d28890413626\n(cherry picked from commit c651f4928c65407cff86a9f9efc046a0f76a9519)\n""}]",0,36496,01fd5c212ae80318aacd60d4e1a36f91c78867f7,9,6,1,7808,,,0,"Fix the filtered characters list from console-log

In fffcaea1 ^M was added to the list of characters to filter from the
console-log output but, because of a typo in the regexp, the
character '-' was added to that list too and has been removed since
then.

Fixes bug #1194032

Change-Id: Ia02b0b4c7027cbd09a51042ca1b5d28890413626
(cherry picked from commit c651f4928c65407cff86a9f9efc046a0f76a9519)
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/36496/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/contrib/test_console_output.py', 'nova/api/openstack/compute/contrib/console_output.py']",2,01fd5c212ae80318aacd60d4e1a36f91c78867f7,bug/1194032, remove_re = re.compile('[\x00-\x08\x0B-\x1F]'), remove_re = re.compile('[\x00-\x08\x0B-\x0C\x0E-\x1F-\x0D]'),20,1
openstack%2Freviewstats~master~I811fb9608da716228f169f52579bcdae8b8535bd,openstack/reviewstats,master,I811fb9608da716228f169f52579bcdae8b8535bd,add devstack project to review stats,MERGED,2013-07-23 14:53:02.000000000,2013-07-23 15:59:31.000000000,2013-07-23 15:59:31.000000000,"[{'_account_id': 3}, {'_account_id': 1561}]","[{'number': 1, 'created': '2013-07-23 14:53:02.000000000', 'files': ['projects/devstack.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/c8ecff17f840718cd4ab4d71777b55c3e262f83c', 'message': 'add devstack project to review stats\n\nChange-Id: I811fb9608da716228f169f52579bcdae8b8535bd\n'}]",0,38305,c8ecff17f840718cd4ab4d71777b55c3e262f83c,5,2,1,2750,,,0,"add devstack project to review stats

Change-Id: I811fb9608da716228f169f52579bcdae8b8535bd
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/05/38305/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/devstack.json'],1,c8ecff17f840718cd4ab4d71777b55c3e262f83c,adds,"{ ""name"": ""devstack"", ""subprojects"": [""openstack-dev/devstack""], ""core-team"": [ ""sdague"", ""dtroyer"", ""garyk"", ""danwent"", ""anotherjesse"", ""vishvananda"", ""corvus"", ""bcwaldon"", ""termie"" ] } ",,15,0
openstack%2Freviewstats~master~Ie196aceb5647e70e62791e2f60ad57fcb11b7b34,openstack/reviewstats,master,Ie196aceb5647e70e62791e2f60ad57fcb11b7b34,add grenade project to review stats,MERGED,2013-07-23 14:53:02.000000000,2013-07-23 15:59:27.000000000,2013-07-23 15:59:27.000000000,"[{'_account_id': 3}, {'_account_id': 1561}]","[{'number': 1, 'created': '2013-07-23 14:53:02.000000000', 'files': ['projects/grenade.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/0f66461ba6be51813b87784bbea3abd72d5809b0', 'message': 'add grenade project to review stats\n\nChange-Id: Ie196aceb5647e70e62791e2f60ad57fcb11b7b34\n'}]",0,38304,0f66461ba6be51813b87784bbea3abd72d5809b0,5,2,1,2750,,,0,"add grenade project to review stats

Change-Id: Ie196aceb5647e70e62791e2f60ad57fcb11b7b34
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/04/38304/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/grenade.json'],1,0f66461ba6be51813b87784bbea3abd72d5809b0,adds,"{ ""name"": ""grenade"", ""subprojects"": [""openstack-dev/grenade""], ""core-team"": [ ""sdague"", ""dtroyer"" ] } ",,8,0
openstack%2Fsahara~master~I510cadb001875661f638cb9afd3bab8762af9ae5,openstack/sahara,master,I510cadb001875661f638cb9afd3bab8762af9ae5,Fix a bug in integration tests,MERGED,2013-07-19 15:48:02.000000000,2013-07-23 15:32:44.000000000,2013-07-23 15:32:44.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7428}]","[{'number': 1, 'created': '2013-07-19 15:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/5fa89398b01aebd9411891c8304c33307a443e6f', 'message': 'Bug fixing in test code\n\nBug in hadoop test was corrected\n\nChange-Id: I510cadb001875661f638cb9afd3bab8762af9ae5\n'}, {'number': 2, 'created': '2013-07-22 08:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/3055e54d9fa1bc2bfab804d40522382e6f06b85c', 'message': 'Bug fixing in test code\n\nBug in hadoop test was corrected\n\nChange-Id: I510cadb001875661f638cb9afd3bab8762af9ae5\n'}, {'number': 3, 'created': '2013-07-22 16:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/5411b4694b1914115fe7a8fcd775178a885ccf65', 'message': 'Bug fixing in test code\n\nBug in hadoop test was corrected. Cluster template deletion during cluster work was bug.\n\nChange-Id: I510cadb001875661f638cb9afd3bab8762af9ae5\n'}, {'number': 4, 'created': '2013-07-22 16:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d5fe1443f59c44cabdc58a10264680c21188b67e', 'message': 'Bug fixing in test code\n\nBug in hadoop test was corrected\n\nChange-Id: I510cadb001875661f638cb9afd3bab8762af9ae5\n'}, {'number': 5, 'created': '2013-07-23 12:01:48.000000000', 'files': ['savanna/tests/integration/crud_tests/test_cluster_cluster_templates.py', 'savanna/tests/integration/base.py', 'savanna/tests/integration/hadoop_test/test_hadoop.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/e9bd6d69aa0ccba5c96aa7d0c4a4747cfdbdec32', 'message': 'Fix a bug in integration tests\n\nA bug in hadoop test has been corrected. Bug: cluster template deleted during work of cluster.\n\nChange-Id: I510cadb001875661f638cb9afd3bab8762af9ae5\n'}]",2,37928,e9bd6d69aa0ccba5c96aa7d0c4a4747cfdbdec32,27,5,5,7428,,,0,"Fix a bug in integration tests

A bug in hadoop test has been corrected. Bug: cluster template deleted during work of cluster.

Change-Id: I510cadb001875661f638cb9afd3bab8762af9ae5
",git fetch https://review.opendev.org/openstack/sahara refs/changes/28/37928/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/tests/integration/crud_tests/test_cluster_cluster_templates.py', 'savanna/tests/integration/base.py']",2,5fa89398b01aebd9411891c8304c33307a443e6f,master, self.fail('failure: ' + str(e)), print(str(e)) finally:,1,2
openstack%2Fpython-openstackclient~master~Iea1a9214db90f15815a456955040c0c5a795ff3d,openstack/python-openstackclient,master,Iea1a9214db90f15815a456955040c0c5a795ff3d,"Change volume manager to volume type, unset property for type",MERGED,2013-07-21 19:47:25.000000000,2013-07-23 15:26:29.000000000,2013-07-23 15:26:29.000000000,"[{'_account_id': 3}, {'_account_id': 970}]","[{'number': 1, 'created': '2013-07-21 19:47:25.000000000', 'files': ['openstackclient/volume/v1/type.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8dd9feb6434243c72f8bd27994418be6409c6c96', 'message': 'Change volume manager to volume type, unset property for type\n\nIn the unset method in volume_type, it was calling the volume\nmanager, instead of the volume_type.\n\nBug: 1203561\nChange-Id: Iea1a9214db90f15815a456955040c0c5a795ff3d\n'}]",0,38086,8dd9feb6434243c72f8bd27994418be6409c6c96,6,2,1,6482,,,0,"Change volume manager to volume type, unset property for type

In the unset method in volume_type, it was calling the volume
manager, instead of the volume_type.

Bug: 1203561
Change-Id: Iea1a9214db90f15815a456955040c0c5a795ff3d
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/86/38086/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/volume/v1/type.py'],1,8dd9feb6434243c72f8bd27994418be6409c6c96,bug/1203561, volume_type.unset_keys(parsed_args.property)," volume_client.volumes.delete_metadata( volume_type.id, parsed_args.property, )",1,4
openstack%2Fpython-openstackclient~master~I0eb748444b86b374265b6e1dd02f69a922a9b043,openstack/python-openstackclient,master,I0eb748444b86b374265b6e1dd02f69a922a9b043,Add password field to set user,MERGED,2013-07-20 21:20:51.000000000,2013-07-23 15:26:29.000000000,2013-07-23 15:26:29.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1699}, {'_account_id': 6482}]","[{'number': 1, 'created': '2013-07-20 21:20:51.000000000', 'files': ['openstackclient/identity/v3/user.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b4904b0a4a83db57e9ed70dad5ebefab85201e2f', 'message': ""Add password field to set user\n\nNoticed this was missing in set user, the password from parsed\nargs wasn't being passed in.\n\nChange-Id: I0eb748444b86b374265b6e1dd02f69a922a9b043\n""}]",0,38053,b4904b0a4a83db57e9ed70dad5ebefab85201e2f,11,4,1,6482,,,0,"Add password field to set user

Noticed this was missing in set user, the password from parsed
args wasn't being passed in.

Change-Id: I0eb748444b86b374265b6e1dd02f69a922a9b043
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/53/38053/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/identity/v3/user.py'],1,b4904b0a4a83db57e9ed70dad5ebefab85201e2f,user_password_fix, if parsed_args.password: kwargs['password'] = parsed_args.password,,2,0
openstack%2Fpython-openstackclient~master~I90eebf6b84ae200532f09cd925f371598ea54a64,openstack/python-openstackclient,master,I90eebf6b84ae200532f09cd925f371598ea54a64,Clean up properties (metadata) formatting,MERGED,2013-07-18 16:51:28.000000000,2013-07-23 15:25:26.000000000,2013-07-23 15:25:26.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}]","[{'number': 1, 'created': '2013-07-18 16:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/feabb47d3049431665c5376162487adf59812b9c', 'message': ""Clean up properties (metadata) formatting\n\n* Reformat default dict output to key='value' using utils.format_dict()\n* Changes utils.get_item_properties() to pass the specific field to\n  the formatter function rather than the entire resource object, this\n  allows the formatter to handle multiple attributes.\n* Updates server, volume, volume type commands\n\nChange-Id: I90eebf6b84ae200532f09cd925f371598ea54a64\n""}, {'number': 2, 'created': '2013-07-18 19:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e5f3022d1d5d71506604efd463f555e2ce2c808c', 'message': ""Clean up properties (metadata) formatting\n\n* Reformat default dict output to key='value' using utils.format_dict()\n* Changes utils.get_item_properties() to pass the specific field to\n  the formatter function rather than the entire resource object, this\n  allows the formatter to handle multiple attributes.\n* Updates server, volume, volume type commands\n\nChange-Id: I90eebf6b84ae200532f09cd925f371598ea54a64\n""}, {'number': 3, 'created': '2013-07-21 19:01:05.000000000', 'files': ['openstackclient/common/utils.py', 'openstackclient/volume/v1/type.py', 'openstackclient/volume/v1/volume.py', 'openstackclient/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/818c94875221f606ed56f276c1cbd320a9106754', 'message': ""Clean up properties (metadata) formatting\n\n* Reformat default dict output to key='value' using utils.format_dict()\n* Changes utils.get_item_properties() to pass the specific field to\n  the formatter function rather than the entire resource object, this\n  allows the formatter to handle multiple attributes.\n* Updates server, volume, volume type commands\n\nChange-Id: I90eebf6b84ae200532f09cd925f371598ea54a64\n""}]",5,37720,818c94875221f606ed56f276c1cbd320a9106754,12,3,3,970,,,0,"Clean up properties (metadata) formatting

* Reformat default dict output to key='value' using utils.format_dict()
* Changes utils.get_item_properties() to pass the specific field to
  the formatter function rather than the entire resource object, this
  allows the formatter to handle multiple attributes.
* Updates server, volume, volume type commands

Change-Id: I90eebf6b84ae200532f09cd925f371598ea54a64
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/20/37720/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/common/utils.py', 'openstackclient/volume/v1/type.py', 'openstackclient/volume/v1/volume.py', 'openstackclient/compute/v2/server.py']",4,feabb47d3049431665c5376162487adf59812b9c,metadata-format,"# Copyright 2012-2013 OpenStack Foundation""""""Compute v2 Server action implementations""""""def _format_servers_list_networks(networks): """"""Return a formatted string of a server's the networks :param server: a Server.networks field for (network, addresses) in networks.items(): info['addresses'] = _format_servers_list_networks(server.networks)","# Copyright 2012-2013 OpenStack, LLC.""""""Server action implementations""""""def _format_servers_list_networks(server): """"""Return a string containing the networks a server is attached to. :param server: a single Server resource for (network, addresses) in server.networks.items(): info['addresses'] = _format_servers_list_networks(server)",75,67
openstack%2Fopenstack-manuals~master~I151ada4c797ef980203fa665ab6b6942156351cf,openstack/openstack-manuals,master,I151ada4c797ef980203fa665ab6b6942156351cf,HP 3PAR Doc changes for QOS feature,MERGED,2013-07-22 16:32:50.000000000,2013-07-23 15:21:40.000000000,2013-07-23 15:21:39.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 6043}]","[{'number': 1, 'created': '2013-07-22 16:32:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/414bda21aeab978feb20863d7f18f592358ebe9b', 'message': 'HP 3PAR Doc changes for QOS feature\n\nAdded doc changes for the new QoS feature for the HP 3PAR\ndrivers, also removed the iSCSI tag on copy volume to image\nand copy image to volume as the FC driver now supports it.\n\nChange-Id: I151ada4c797ef980203fa665ab6b6942156351cf\nFixes: bug 1202779\n'}, {'number': 2, 'created': '2013-07-23 15:15:22.000000000', 'files': ['doc/src/docbkx/openstack-block-storage-admin/drivers/hp-3par-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7fcd81429558699056566cb5416b281ccca13f08', 'message': 'HP 3PAR Doc changes for QOS feature\n\nAdded doc changes for the new QoS feature for the HP 3PAR\ndrivers, also removed the iSCSI tag on copy volume to image\nand copy image to volume as the FC driver now supports it.\n\nChange-Id: I151ada4c797ef980203fa665ab6b6942156351cf\nFixes: bug 1202779\n'}]",12,38170,7fcd81429558699056566cb5416b281ccca13f08,9,3,2,6043,,,0,"HP 3PAR Doc changes for QOS feature

Added doc changes for the new QoS feature for the HP 3PAR
drivers, also removed the iSCSI tag on copy volume to image
and copy image to volume as the FC driver now supports it.

Change-Id: I151ada4c797ef980203fa665ab6b6942156351cf
Fixes: bug 1202779
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/70/38170/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-block-storage-admin/drivers/hp-3par-driver.xml'],1,414bda21aeab978feb20863d7f18f592358ebe9b,bug/1202779," <para>Copy images to volumes.</para> <para>Copy volumes to images.</para> <listitem> <para><literal>hp3par:vvs</literal></para> </listitem> <listitem> <para><literal>qos:maxBWS</literal></para> </listitem> <listitem> <para><literal>qos:maxIOPS</literal></para> </listitem> <para>The key values are case sensitive and scoped with <literal>hp3par:</literal> or <literal>qos:</literal> in order to work with the default filter scheduler. Run <command>cinder help type-key</command> for information about setting the key value pairings and associating them with a volume type.</para> <para>The <literal>hp3par:vvs</literal>, <literal>qos:maxBWS</literal> and <literal>qos:maxIOPS</literal> keys below requires that the HP 3PAR StoreServ storage array has a Priority Optimization license installed. </para> <para> <itemizedlist> <listitem> <para><literal>hp3par:vvs</literal> - The virtual volume set name that has been predefined by the Administrator with Quality of Service(QoS) rules associated to it. If <literal>hp3par:vvs</literal> is specified the <literal>qos:maxIOPS</literal> and <literal>qos:maxBWS</literal> settings will be ignored.</para> </listitem> <listitem> <para><literal>qos:maxBWS</literal> - The QoS I/O issue count rate limit in Megabyes. If not set, there is no limit on I/O issue bandwidth rate.</para> </listitem> <listitem> <para><literal>qos:maxIOPS</literal> - The QoS I/O issue count rate limit. If not set, there is no limit on I/O issue count.</para> </listitem> </itemizedlist> </para>", <para>Copy images to volumes (HP 3PAR iSCSI driver only).</para> <para>Copy volumes to images (HP 3PAR iSCSI driver only).</para> <para>The key values are case sensitive and scoped with <literal>hp3par:</literal> in order to work with the default filter scheduler. Run <command>cinder help type-key</command> for information about setting the key value pairings and associating them with a volume type.</para>,38,6
openstack%2Fceilometer~master~Ibfdd51f06edffc4ea744ff21cd53591c2db6e251,openstack/ceilometer,master,Ibfdd51f06edffc4ea744ff21cd53591c2db6e251,Ensure url is a string for requests.post,MERGED,2013-07-19 08:32:21.000000000,2013-07-23 15:17:56.000000000,2013-07-23 15:17:56.000000000,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}]","[{'number': 1, 'created': '2013-07-19 08:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ad0d89b7a5b3d4e5cbb750bab515f1228321b81a', 'message': ""Ensure url is a string for requests.post\n\nrequests.post doesn't support SplitResult object as url\n\nThis change ensure that the url passed to requests.port is a string\n\nChange-Id: Ibfdd51f06edffc4ea744ff21cd53591c2db6e251\n""}, {'number': 2, 'created': '2013-07-22 07:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/eaefd6651061d549529865710eb8ee6c0f219758', 'message': ""Ensure url is a string for requests.post\n\nrequests.post doesn't support SplitResult object as url\n\nThis change ensure that the url passed to requests.port is a string\n\nChange-Id: Ibfdd51f06edffc4ea744ff21cd53591c2db6e251\n""}, {'number': 3, 'created': '2013-07-22 16:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ff399b5c3fec8cdae0457ede85ceb99fdd76d97e', 'message': ""Ensure url is a string for requests.post\n\nrequests.post doesn't support SplitResult object as url\n\nThis change ensure that the url passed to requests.port is a string\n\nChange-Id: Ibfdd51f06edffc4ea744ff21cd53591c2db6e251\n""}, {'number': 4, 'created': '2013-07-23 06:53:09.000000000', 'files': ['tests/alarm/test_notifier.py', 'ceilometer/alarm/notifier/rest.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/33b691fa577646be11d907daa089cb396baa04ae', 'message': ""Ensure url is a string for requests.post\n\nrequests.post doesn't support SplitResult object as url\n\nThis change ensure that the url passed to requests.port is a string\n\nChange-Id: Ibfdd51f06edffc4ea744ff21cd53591c2db6e251\n""}]",0,37851,33b691fa577646be11d907daa089cb396baa04ae,24,5,4,2813,,,0,"Ensure url is a string for requests.post

requests.post doesn't support SplitResult object as url

This change ensure that the url passed to requests.port is a string

Change-Id: Ibfdd51f06edffc4ea744ff21cd53591c2db6e251
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/51/37851/3 && git format-patch -1 --stdout FETCH_HEAD,"['tests/alarm/test_notifier.py', 'ceilometer/alarm/notifier/rest.py']",2,ad0d89b7a5b3d4e5cbb750bab515f1228321b81a,sileht/rpcnotifier," eventlet.spawn_n(requests.post, action.geturl(),"," eventlet.spawn_n(requests.post, action,",2,3
openstack%2Fapi-site~master~I9177ab85a266da7e57ea99f8870e6782d51ad379,openstack/api-site,master,I9177ab85a266da7e57ea99f8870e6782d51ad379,"Changed the api.openstack.org page to refer to ""References"" Put API references on this page, rather than linking to another page",ABANDONED,2013-07-13 18:47:30.000000000,2013-07-23 15:14:21.000000000,,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-07-13 18:47:30.000000000', 'files': ['www/index.html'], 'web_link': 'https://opendev.org/openstack/api-site/commit/c552d0fb992565ca91bc1e32f9024a339b5cfd14', 'message': 'Changed the api.openstack.org page to refer to ""References""\nPut API references on this page, rather than linking to another page\n\nChange-Id: I9177ab85a266da7e57ea99f8870e6782d51ad379\nauthor: diane fleming\n'}]",0,36951,c552d0fb992565ca91bc1e32f9024a339b5cfd14,6,3,1,2448,,,0,"Changed the api.openstack.org page to refer to ""References""
Put API references on this page, rather than linking to another page

Change-Id: I9177ab85a266da7e57ea99f8870e6782d51ad379
author: diane fleming
",git fetch https://review.opendev.org/openstack/api-site refs/changes/51/36951/1 && git format-patch -1 --stdout FETCH_HEAD,['www/index.html'],1,c552d0fb992565ca91bc1e32f9024a339b5cfd14,api-site-fix," <meta name=""generator"" content=""HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org"" /> <meta http-equiv=""Content-Type"" content=""text/html; charset=us-ascii"" /> <meta name=""google-site-verification"" content=""Ip5yk0nd8yQHEo8I7SjzVfAiadlHvTvqQHLGwn1GFyU"" /> <title>OpenStack Docs: APIs</title> <!-- Google Fonts --> <link href=""http://fonts.googleapis.com/css?family=PT+Sans&amp;subset=latin"" rel=""stylesheet"" type=""text/css"" /> <!-- Framework CSS --> <link rel=""stylesheet"" href=""http://openstack.org/themes/openstack/css/blueprint/screen.css"" type=""text/css"" media=""screen, projection"" /> <link rel=""stylesheet"" href=""http://openstack.org/themes/openstack/css/blueprint/print.css"" type=""text/css"" media=""print"" /> <link rel=""stylesheet"" href=""http://openstack.org/themes/openstack/css/main.css"" type=""text/css"" media=""screen, projection, print"" /> <link rel=""stylesheet"" type=""text/css"" href=""http://docs.openstack.org/common/css/docblitz.css"" /> var _gaq = _gaq ||[]; _gaq.push([ '_setAccount', 'UA-17511903-1']); _gaq.push([ '_setDomainName', '.openstack.org']); _gaq.push([ '_trackPageview']); (function () { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl': 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })();//]]> <h1 id=""logo""><a href=""http://www.openstack.org/"" >OpenStack</a></h1> <div id=""navigation"" class=""span-19""> <ul id=""Menu1""> <li><a href=""http://www.openstack.org/"" title=""Go to the Home page"">Home</a></li> <li><a href=""http://www.openstack.org/software/"" title=""Go to the Software page"" class=""link"" >Software</a></li> <li><a href=""http://www.openstack.org/user-stories/"" title=""Go to the User Stories page"" class=""link"" >User Stories</a></li> <li><a href=""http://www.openstack.org/community/"" title=""Go to the Community page"" class=""link"" >Community</a></li> <li><a href=""http://www.openstack.org/profile/"" title=""Go to the Profile page"" class=""link"" >Profile</a></li> <li><a href=""http://www.openstack.org/blog/"" title=""Go to the OpenStack Blog"">Blog</a></li> <li><a href=""http://wiki.openstack.org/"" title=""Go to the OpenStack Wiki"">Wiki</a></li> <li><a href=""http://docs.openstack.org/"" title=""Go to OpenStack Documentation"" class=""current"">Documentation</a></li> </ul> </div> </div> </div> </div> <!-- Page Content --> <div class=""container""> <div class=""span-12""> <h3 class=""subhead"">Documentation > API</h3> </div> <div class=""searchArea span-10 last""> <div id=""cse"" style=""width: 100%;""> Loading </div> <script src=""http://www.google.com/jsapi"" type=""text/javascript""> </script>//<![CDATA[ google.load('search', '1', { language: 'en' }); var _gaq = _gaq ||[]; _gaq.push([ ""_setAccount"", ""UA-17511903-6""]); function _trackQuery(control, searcher, query) { var gaQueryParamName = ""q""; var loc = document.location; var url =[ loc.pathname, loc.search, loc.search ? '&': '?', gaQueryParamName == '' ? 'q': encodeURIComponent(gaQueryParamName), '=', encodeURIComponent(query)].join(''); _gaq.push([ ""_trackPageview"", url]); } google.setOnLoadCallback(function () { var customSearchControl = new google.search.CustomSearchControl('011012898598057286222:elxsl505o0o'); customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET); customSearchControl.setSearchStartingCallback(null, _trackQuery); customSearchControl.draw('cse'); }, true);//]]> </script> </div> <div class=""container""> <div class=""span-12""> <p>&nbsp;</p> <h4 class=""special"">Use or develop applications for OpenStack clouds</h4> <dl> <dd><a href=""http://docs.openstack.org/api/quick-start/content/"" >API Quick Start</a></dd> <dd><a href=""http://docs.openstack.org/api/openstack-compute/programmer/content/"" >Programming Compute API with Shell and Python, 1st ed.</a></dd> <dd><a href=""http://docs.openstack.org/cli/quick-start/content/"" >Clients Guide</a></dd> <dd><a href=""http://api.openstack.org/api-ref.html"" >API Complete Reference</a> </dd> <dd><a href=""http://docs.openstack.org/api/openstack-block-storage/2.0/content/"" >Block Storage Service API v2 Reference</a></dd> <dd><a href=""http://docs.openstack.org/api/openstack-compute/2/content/"" >Compute API v2 and Extensions Reference</a></dd> <dd><a href=""http://docs.openstack.org/api/openstack-identity-service/2.0/content/"" >Identity Service API v2.0 Reference</a></dd> <dd><a href=""http://docs.openstack.org/api/openstack-network/2.0/content/"" >Networking API v2.0 Reference</a></dd> <dd><a href=""http://docs.openstack.org/api/openstack-image-service/2.0/content/"" >Image Service API v2 Reference</a></dd> <dd><a href=""http://docs.openstack.org/api/openstack-image-service/1.1/content/"" >Image Service API v1 Reference</a></dd> <dd><a href=""http://docs.openstack.org/api/openstack-object-storage/1.0/content/"" >Object Storage API v1 Reference</a></dd> </dl> </div> </div> </div> <p>Documentation treated like code, powered by the community - interested? Here's <a href=""http://wiki.openstack.org/Documentation/HowTo"">how to contribute</a>. </p> <p>The OpenStack project is provided under the Apache 2.0 license. Openstack.org is powered by <a href=""http://www.rackspacecloud.com/"">Rackspace Cloud Computing</a>.</p> </div> <script type=""text/javascript"" src=""http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.js""> </script> <script src=""/common/jquery/jquery.hoverIntent.minified.js"" type=""text/javascript"" charset=""utf-8""> </script> <script type=""text/javascript"" charset=""utf-8""> $(document).ready(function () { function addMenu() { $("".dropDown"").addClass(""menuHover""); } function removeMenu() { $("".dropDown"").removeClass(""menuHover""); } var menuConfig = { interval: 500, sensitivity: 4, over: addMenu, timeout: 500, out: removeMenu }; $("".dropDownTrigger"").hoverIntent(menuConfig); });//]]>"," <meta name=""generator"" content= ""HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org"" /> <meta http-equiv=""Content-Type"" content=""text/html; charset=us-ascii"" /> <meta name=""google-site-verification"" content= ""Ip5yk0nd8yQHEo8I7SjzVfAiadlHvTvqQHLGwn1GFyU"" /> <title>OpenStack Docs: APIs</title><!-- Google Fonts --> <link href='http://fonts.googleapis.com/css?family=PT+Sans&amp;subset=latin' rel='stylesheet' type='text/css' /><!-- Framework CSS --> <link rel=""stylesheet"" href= ""http://openstack.org/themes/openstack/css/blueprint/screen.css"" type= ""text/css"" media=""screen, projection"" /> <link rel=""stylesheet"" href= ""http://openstack.org/themes/openstack/css/blueprint/print.css"" type= ""text/css"" media=""print"" /> <link rel=""stylesheet"" href= ""http://openstack.org/themes/openstack/css/main.css"" type=""text/css"" media= ""screen, projection, print"" /> <link rel=""stylesheet"" type=""text/css"" href=""http://docs.openstack.org/common/css/docblitz.css"" /> var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-17511903-1']); _gaq.push(['_setDomainName', '.openstack.org']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })(); //]]> <h1 id=""logo""><a href=""http://www.openstack.org/"">OpenStack</a></h1> <div id=""navigation"" class=""span-19""> <ul id=""Menu1""> <li><a href=""http://www.openstack.org/"" title=""Go to the Home page"">Home</a></li> <li><a href=""http://www.openstack.org/software/"" title=""Go to the Software page"" class=""link"">Software</a></li> <li><a href=""http://www.openstack.org/user-stories/"" title=""Go to the User Stories page"" class=""link"">User Stories</a></li> <li><a href=""http://www.openstack.org/community/"" title=""Go to the Community page"" class=""link"">Community</a></li> <li><a href=""http://www.openstack.org/profile/"" title=""Go to the Profile page"" class=""link"">Profile</a></li> <li><a href=""http://www.openstack.org/blog/"" title=""Go to the OpenStack Blog"">Blog</a></li> <li><a href=""http://wiki.openstack.org/"" title=""Go to the OpenStack Wiki"">Wiki</a></li> <li><a href=""http://docs.openstack.org/"" title=""Go to OpenStack Documentation"" class=""current"">Documentation</a></li> </ul> </div> </div> </div> </div> <!-- Page Content --> <div class=""container""> <div class=""span-12""> <h3 class=""subhead"">Documentation > API</h3> </div> <div class=""searchArea span-10 last""> <div id=""cse"" style=""width: 100%;""> Loading </div> <script src=""http://www.google.com/jsapi"" type=""text/javascript""> </script> <script type=""text/javascript""> //<![CDATA[ google.load('search', '1', {language : 'en'}); var _gaq = _gaq || []; _gaq.push([""_setAccount"", ""UA-17511903-6""]); function _trackQuery(control, searcher, query) { var gaQueryParamName = ""q""; var loc = document.location; var url = [ loc.pathname, loc.search, loc.search ? '&' : '?', gaQueryParamName == '' ? 'q' : encodeURIComponent(gaQueryParamName), '=', encodeURIComponent(query) ].join(''); _gaq.push([""_trackPageview"", url]); } google.setOnLoadCallback(function() { var customSearchControl = new google.search.CustomSearchControl('011012898598057286222:elxsl505o0o'); customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET); customSearchControl.setSearchStartingCallback(null, _trackQuery); customSearchControl.draw('cse'); }, true); //]]> </script> </div><!-- <link rel=""stylesheet"" href=""http://www.google.com/cse/style/look/default.css"" type=""text/css"" /> --> <!-- <div id=""cse"" style=""width: 100%;"">Loading</div> <script src=""http://www.google.com/jsapi"" type=""text/javascript""></script> google.load('search', '1', {language : 'en'}); google.setOnLoadCallback(function() { var customSearchControl = new google.search.CustomSearchControl('011012898598057286222:elxsl505o0o'); customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET); customSearchControl.draw('cse'); }, true); </script> </div> --> <div class=""container""> <div class=""span-12""> <h2><a href=""http://docs.openstack.org/api/quick-start/content/"">OpenStack API Quick Start</a> </h2> <p>Shows how to make requests against an OpenStack cloud. </p> <h2><a href=""http://docs.openstack.org/api/openstack-compute/programmer/content/"">Programming OpenStack Compute API with Shell and Python</a> </h2> <p>Walk through of all Compute API commands using Python and shell. </p> <h2><a href=""http://docs.openstack.org/api/api-specs.html"">API Specifications</a> </h2> <p>Specifications for the OpenStack APIs. </p> </div> <div class=""span-12 last""> <h2><a href=""http://api.openstack.org/api-ref.html"">API Complete Reference </a> </h2> <p>Complete listing of all calls for OpenStack APIs except for the Network Connectivity (Quantum) API.</p> </div> </div> </div> <p>Documentation treated like code, powered by the community - interested? Here's <a href=""http://wiki.openstack.org/Documentation/HowTo"">how to contribute</a>. </p> <p>The OpenStack project is provided under the Apache 2.0 license. Openstack.org is powered by <a href= ""http://www.rackspacecloud.com/"">Rackspace Cloud Computing</a>.</p> </div><script type=""text/javascript"" src= ""http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.js""> </script><script src=""/common/jquery/jquery.hoverIntent.minified.js"" type= ""text/javascript"" charset=""utf-8""> </script><script type=""text/javascript"" charset=""utf-8""> $(document).ready(function() { function addMenu(){ $("".dropDown"").addClass(""menuHover""); } function removeMenu(){ $("".dropDown"").removeClass(""menuHover""); } var menuConfig = { interval: 500, sensitivity: 4, over: addMenu, timeout: 500, out: removeMenu }; $("".dropDownTrigger"").hoverIntent(menuConfig); }); //]]>",189,172
openstack%2Fdevstack~master~I7d5074209fe81f6100f380512d7702fbc8e252ac,openstack/devstack,master,I7d5074209fe81f6100f380512d7702fbc8e252ac,Update neutron_available config option.,MERGED,2013-07-23 00:58:29.000000000,2013-07-23 15:10:27.000000000,2013-07-23 15:10:27.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-23 00:58:29.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/c373cf8b89a6ad5d97027964db5f42e98b568b7d', 'message': ""Update neutron_available config option.\n\nTempest change I5ee9ec816845de483fe88d76d1bb047e7bb1af7e changed\nthe behavior of the neutron_available config option. This commit\nupdates devstack to use it's new name and group.\n\nChange-Id: I7d5074209fe81f6100f380512d7702fbc8e252ac\n""}]",0,38235,c373cf8b89a6ad5d97027964db5f42e98b568b7d,7,4,1,5196,,,0,"Update neutron_available config option.

Tempest change I5ee9ec816845de483fe88d76d1bb047e7bb1af7e changed
the behavior of the neutron_available config option. This commit
updates devstack to use it's new name and group.

Change-Id: I7d5074209fe81f6100f380512d7702fbc8e252ac
",git fetch https://review.opendev.org/openstack/devstack refs/changes/35/38235/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,c373cf8b89a6ad5d97027964db5f42e98b568b7d,fix-neutron-available," iniset $TEMPEST_CONF service_available neutron ""True"""," iniset $TEMPEST_CONF network neutron_available ""True""",1,1
openstack%2Fglance~master~If489f42bb97a01519d13de47eeb5d180b31ba6a7,openstack/glance,master,If489f42bb97a01519d13de47eeb5d180b31ba6a7,improving error handling in chunked upload,MERGED,2013-07-09 03:59:52.000000000,2013-07-23 15:07:50.000000000,2013-07-23 15:07:49.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2166}, {'_account_id': 2537}, {'_account_id': 4463}, {'_account_id': 6484}, {'_account_id': 6493}, {'_account_id': 6610}, {'_account_id': 6835}, {'_account_id': 7491}, {'_account_id': 7780}]","[{'number': 1, 'created': '2013-07-09 03:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5f7054024cce5a10ef98795872407396ee19bcea', 'message': 'improving error handling in chunked upload\n\nKeep traceback of chucked upload in a variable and raise it after\ndeleting orphaned data to avoid covering sys.exc_info().\n\nfixed bug #1185609\nfixed bug #1199125\n\nChange-Id: If489f42bb97a01519d13de47eeb5d180b31ba6a7\n'}, {'number': 2, 'created': '2013-07-09 16:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1d1105b8b47c8c98c127ec64339743e29d6995d3', 'message': 'improving error handling in chunked upload\n\nKeep traceback of chunked upload in a variable and raise it after\ndeleting orphaned data to avoid covering sys.exc_info().\n\nfixed bug #1185609\nfixed bug #1199125\n\nChange-Id: If489f42bb97a01519d13de47eeb5d180b31ba6a7\n'}, {'number': 3, 'created': '2013-07-17 14:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3f45457ea73b1c0d2147cc1e660e9e0c2ea54635', 'message': 'improving error handling in chunked upload\n\nKeep traceback of chunked upload in a variable and raise it after\ndeleting orphaned data to avoid covering sys.exc_info().\n\nfixed bug #1185609\nfixed bug #1199125\n\nChange-Id: If489f42bb97a01519d13de47eeb5d180b31ba6a7\n'}, {'number': 4, 'created': '2013-07-17 16:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/157d82db1a65c161ed8af5519549a83444272d18', 'message': 'improving error handling in chunked upload\n\nKeep traceback of chunked upload in a variable and raise it after\ndeleting orphaned data to avoid covering sys.exc_info().\n\nfixed bug #1185609\nfixed bug #1199125\n\nChange-Id: If489f42bb97a01519d13de47eeb5d180b31ba6a7\n'}, {'number': 5, 'created': '2013-07-17 17:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f3090af2d80d6f38a36ae38ca6d01e9c278cb91b', 'message': 'improving error handling in chunked upload\n\nKeep traceback of chunked upload in a variable and raise it after\ndeleting orphaned data to avoid covering sys.exc_info().\n\nfixed bug #1185609\nfixed bug #1199125\n\nChange-Id: If489f42bb97a01519d13de47eeb5d180b31ba6a7\n'}, {'number': 6, 'created': '2013-07-18 00:11:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/dc8dbda175a2755b891e6b56c555927053c8f805', 'message': 'improving error handling in chunked upload\n\nKeep traceback of chunked upload in a variable and raise it after\ndeleting orphaned data to avoid covering sys.exc_info().\n\nfixed bug #1185609\nfixed bug #1199125\n\nChange-Id: If489f42bb97a01519d13de47eeb5d180b31ba6a7\n'}, {'number': 7, 'created': '2013-07-18 09:46:15.000000000', 'files': ['glance/store/swift.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/159a6491cd41843d856fbe06fc824c0a0230c88f', 'message': 'improving error handling in chunked upload\n\nKeep traceback of chunked upload in a variable and raise it after\ndeleting orphaned data to avoid covering sys.exc_info().\n\nfixed bug #1185609\nfixed bug #1199125\n\nChange-Id: If489f42bb97a01519d13de47eeb5d180b31ba6a7\n'}]",29,36163,159a6491cd41843d856fbe06fc824c0a0230c88f,56,11,7,6835,,,0,"improving error handling in chunked upload

Keep traceback of chunked upload in a variable and raise it after
deleting orphaned data to avoid covering sys.exc_info().

fixed bug #1185609
fixed bug #1199125

Change-Id: If489f42bb97a01519d13de47eeb5d180b31ba6a7
",git fetch https://review.opendev.org/openstack/glance refs/changes/63/36163/4 && git format-patch -1 --stdout FETCH_HEAD,['glance/store/swift.py'],1,5f7054024cce5a10ef98795872407396ee19bcea,bug/1185609,"import sys LOG.error(""Errors in chucked upload!"") err = sys.exc_info() raise err[0], err[1], err[2]", raise,4,1
openstack%2Ftempest~master~Iaf0accdcd1d5e37658ca56528b1709d0a00928d2,openstack/tempest,master,Iaf0accdcd1d5e37658ca56528b1709d0a00928d2,Updating HACKING with some test writing recommendations,MERGED,2013-07-22 13:06:01.000000000,2013-07-23 15:07:43.000000000,2013-07-23 15:07:43.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-22 13:06:01.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c2ff727a73ff36fc25717041c9fdf894e510540a', 'message': 'Updating HACKING with some test writing recommendations\n\nAdds a recommendation against submitting changesets with only\nskipped tests and some recommendations for writing tests.\n\nChange-Id: Iaf0accdcd1d5e37658ca56528b1709d0a00928d2\n'}]",0,38144,c2ff727a73ff36fc25717041c9fdf894e510540a,8,5,1,5292,,,0,"Updating HACKING with some test writing recommendations

Adds a recommendation against submitting changesets with only
skipped tests and some recommendations for writing tests.

Change-Id: Iaf0accdcd1d5e37658ca56528b1709d0a00928d2
",git fetch https://review.opendev.org/openstack/tempest refs/changes/44/38144/1 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,c2ff727a73ff36fc25717041c9fdf894e510540a,hacking_update,"Use of ``self.addCleanup`` is often a good way to avoid having to catch exceptions and still ensure resources are correctly cleaned up if the test fails part way through. Guidelines ---------- - Do not submit changesets with only testcases which are skipped as they will not be merged. - Consistently check the status code of responses in testcases. The earlier a problem is detected the easier it is to debug, especially where there is complicated setup required.", ,11,2
openstack%2Fcookbook-openstack-block-storage~master~I923557c4a38d9f5bdae6e7ca4cbec270224fb3fd,openstack/cookbook-openstack-block-storage,master,I923557c4a38d9f5bdae6e7ca4cbec270224fb3fd,fix volume package name on suse,MERGED,2013-07-23 14:34:57.000000000,2013-07-23 14:44:50.000000000,2013-07-23 14:44:50.000000000,"[{'_account_id': 3}, {'_account_id': 7}]","[{'number': 1, 'created': '2013-07-23 14:34:57.000000000', 'files': ['spec/volume-opensuse_spec.rb', 'attributes/default.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/1a704f550ce3674fe448d18284255ddab8a92a3b', 'message': 'fix volume package name on suse\n\nChange-Id: I923557c4a38d9f5bdae6e7ca4cbec270224fb3fd\n'}]",0,38301,1a704f550ce3674fe448d18284255ddab8a92a3b,5,2,1,2340,,,0,"fix volume package name on suse

Change-Id: I923557c4a38d9f5bdae6e7ca4cbec270224fb3fd
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/01/38301/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/volume-opensuse_spec.rb', 'attributes/default.rb']",2,1a704f550ce3674fe448d18284255ddab8a92a3b,volume-package-name," ""cinder_volume_packages"" => [""openstack-cinder-volume""],"," ""cinder_volume_packages"" => [""openstack-cinder""],",2,2
openstack%2Frequirements~master~I1d815b45e1e98cb051fca3f1585312ef65974fd4,openstack/requirements,master,I1d815b45e1e98cb051fca3f1585312ef65974fd4,Add python-troveclient to requirements,MERGED,2013-07-18 14:23:19.000000000,2013-07-23 14:16:09.000000000,2013-07-23 14:16:09.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 24}, {'_account_id': 2592}, {'_account_id': 5623}, {'_account_id': 6434}, {'_account_id': 7230}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7395}]","[{'number': 1, 'created': '2013-07-18 14:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/839b19571fb62b06664eb22dbfffb63e2b1ac11b', 'message': 'Add python-troveclient to requirements\n\npython-troveclient is required for Database as a Service (DbaaS) resource implementation.\n\nChange-Id: I1d815b45e1e98cb051fca3f1585312ef65974fd4\n'}, {'number': 2, 'created': '2013-07-19 17:00:11.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/42c20331c85e57bde284cc759d4afe1cc279ddec', 'message': 'Add python-troveclient to requirements\n\npython-troveclient is required for Database as a Service (DbaaS) resource implementation.\nChange-Id: I1d815b45e1e98cb051fca3f1585312ef65974fd4\n'}]",0,37686,42c20331c85e57bde284cc759d4afe1cc279ddec,14,10,2,7230,,,0,"Add python-troveclient to requirements

python-troveclient is required for Database as a Service (DbaaS) resource implementation.
Change-Id: I1d815b45e1e98cb051fca3f1585312ef65974fd4
",git fetch https://review.opendev.org/openstack/requirements refs/changes/86/37686/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,839b19571fb62b06664eb22dbfffb63e2b1ac11b,bp/dbaas-trove-resource,python-troveclient,,1,0
openstack%2Fsahara~master~I81ea12220c010e47ae4b6a4b2fc4acf596eb9155,openstack/sahara,master,I81ea12220c010e47ae4b6a4b2fc4acf596eb9155,Fix HDP plugin should register service urls,MERGED,2013-07-22 12:26:57.000000000,2013-07-23 14:10:51.000000000,2013-07-23 14:10:51.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 7737}]","[{'number': 1, 'created': '2013-07-22 12:26:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/735814cf74c3f4056c05dea17bfda177a0f14304', 'message': 'Fix: HDP plugin should register service urls\n\nFixes: bug #1203331\n\nChange-Id: I81ea12220c010e47ae4b6a4b2fc4acf596eb9155\n'}, {'number': 2, 'created': '2013-07-22 12:40:32.000000000', 'files': ['savanna/plugins/hdp/ambariplugin.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/5ad60b29243fb802baa417f857834b0c40515dca', 'message': 'Fix HDP plugin should register service urls\n\nFixes: bug #1203331\n\nChange-Id: I81ea12220c010e47ae4b6a4b2fc4acf596eb9155\n'}]",7,38141,5ad60b29243fb802baa417f857834b0c40515dca,16,6,2,7710,,,0,"Fix HDP plugin should register service urls

Fixes: bug #1203331

Change-Id: I81ea12220c010e47ae4b6a4b2fc4acf596eb9155
",git fetch https://review.opendev.org/openstack/sahara refs/changes/41/38141/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/plugins/hdp/ambariplugin.py'],1,735814cf74c3f4056c05dea17bfda177a0f14304,bug/1203331," # add service urls self._set_cluster_info(cluster, cluster_spec, hosts) def _set_cluster_info(self, cluster, cluster_spec, hosts): info = cluster.info try: jobtracker_ip = self._determine_host_for_server_component( 'JOBTRACKER', cluster_spec, hosts).management_ip except Exception: pass else: info['MapReduce'] = { 'Web UI': 'http://%s:50030' % jobtracker_ip } try: namenode_ip = self._determine_host_for_server_component( 'NAMENODE', cluster_spec, hosts).management_ip except Exception: pass else: info['HDFS'] = { 'Web UI': 'http://%s:50070' % namenode_ip } try: ambari_ip = self._determine_host_for_server_component( 'AMBARI_SERVER', cluster_spec, hosts).management_ip except Exception: pass else: info['Ambari Console'] = { 'Web UI': 'http://%s:8080/#/main' % ambari_ip } ",,35,1
openstack%2Fneutron~master~Iedd488b7bdc9b1a1317000d249f03b0eafbea419,openstack/neutron,master,Iedd488b7bdc9b1a1317000d249f03b0eafbea419,nvp plugin rxtx_factor readonly update port,MERGED,2013-07-17 22:05:09.000000000,2013-07-23 14:10:20.000000000,2013-07-23 14:10:19.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2583}, {'_account_id': 2592}, {'_account_id': 4395}]","[{'number': 1, 'created': '2013-07-17 22:05:09.000000000', 'files': ['neutron/plugins/nicira/extensions/nvp_qos.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b69d98e196a98295048d311786b9f23586dc4fd', 'message': ""nvp plugin rxtx_factor readonly update port\n\nThe following change done in nova 7de916 started passing in the\nrxtx_factor on update port rather than just on create_port which\nis what we only originally supported. Therefore currently when\nbooting a vm and specifying --nic port-id it will fail to boot with:\nCannot update read-only attribute rxtx_factor. This patch is a work\naround to allow the rxtx_factor value to be passed in on update port even\nthough we ignore the value. Later we'll implement updating rxtx_factor on\nports but this is a good work around for now.\n\nFixes bug: 1202406\n\nChange-Id: Iedd488b7bdc9b1a1317000d249f03b0eafbea419\n""}]",3,37582,7b69d98e196a98295048d311786b9f23586dc4fd,10,7,1,4395,,,0,"nvp plugin rxtx_factor readonly update port

The following change done in nova 7de916 started passing in the
rxtx_factor on update port rather than just on create_port which
is what we only originally supported. Therefore currently when
booting a vm and specifying --nic port-id it will fail to boot with:
Cannot update read-only attribute rxtx_factor. This patch is a work
around to allow the rxtx_factor value to be passed in on update port even
though we ignore the value. Later we'll implement updating rxtx_factor on
ports but this is a good work around for now.

Fixes bug: 1202406

Change-Id: Iedd488b7bdc9b1a1317000d249f03b0eafbea419
",git fetch https://review.opendev.org/openstack/neutron refs/changes/82/37582/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/nicira/extensions/nvp_qos.py'],1,7b69d98e196a98295048d311786b9f23586dc4fd,bug/1202406," # FIXME(arosen): the nvp plugin currently does not # implement updating rxtx factor on port. 'allow_put': True,"," 'allow_put': False,",3,1
openstack%2Fnova~master~Id66010eacb24c86e32f5455c5d869f9f037cff23,openstack/nova,master,Id66010eacb24c86e32f5455c5d869f9f037cff23,Sync gettextutils from oslo,MERGED,2013-06-24 20:56:38.000000000,2013-07-23 14:10:09.000000000,2013-07-23 14:10:07.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 2166}, {'_account_id': 5371}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-06-24 20:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b99b07190f649b33ada63f8e869b44b644a9b3f8', 'message': 'Sync gettextutils from oslo\n\nBring in some needed extra code for handling Nova translations\n\nPartially implements bp user-locale-api\n\nChange-Id: Id66010eacb24c86e32f5455c5d869f9f037cff23\n'}, {'number': 2, 'created': '2013-07-11 18:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5adb97885274d5e8495b165f4ac7cc89168a3f46', 'message': 'Sync gettextutils from oslo\n\nBring in some needed extra code for handling Nova translations\n\nPartially implements bp user-locale-api\n\nChange-Id: Id66010eacb24c86e32f5455c5d869f9f037cff23\n'}, {'number': 3, 'created': '2013-07-15 17:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ac072b914ea8689147a6c73265f75f8b0222795', 'message': 'Sync gettextutils from oslo\n\nBring in some needed extra code for handling Nova translations\n\nPartially implements bp user-locale-api\n\nChange-Id: Id66010eacb24c86e32f5455c5d869f9f037cff23\n'}, {'number': 4, 'created': '2013-07-19 18:54:14.000000000', 'files': ['nova/openstack/common/gettextutils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/97e1f41a325f2d23f71b9faf244c3f499626808f', 'message': 'Sync gettextutils from oslo\n\nBring in some needed extra code for handling Nova translations\n\nPartially implements bp user-locale-api\n\nChange-Id: Id66010eacb24c86e32f5455c5d869f9f037cff23\n'}]",0,34260,97e1f41a325f2d23f71b9faf244c3f499626808f,24,5,4,5371,,,0,"Sync gettextutils from oslo

Bring in some needed extra code for handling Nova translations

Partially implements bp user-locale-api

Change-Id: Id66010eacb24c86e32f5455c5d869f9f037cff23
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/34260/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/openstack/common/gettextutils.py'],1,b99b07190f649b33ada63f8e869b44b644a9b3f8,bp/user-locale-api,"import re def _save_dictionary_parameter(self, dict_param): full_msg = self.data # look for %(blah) fields in string; # ignore %% and deal with the # case where % is first character on the line keys = re.findall('(?:[^%]|^)%\((\w*)\)[a-z]', full_msg) # if we don't find any %(blah) blocks but have a %s if not keys and re.findall('(?:[^%]|^)%[a-z]', full_msg): # apparently the full dictionary is the parameter params = copy.deepcopy(dict_param) else: params = {} for key in keys: try: params[key] = copy.deepcopy(dict_param[key]) except Exception: # cast uncopyable thing to unicode string params[key] = unicode(dict_param[key]) return params elif isinstance(other, dict): self.params = self._save_dictionary_parameter(other) else: # fallback to casting to unicode, # this will handle the problematic python code-like # objects that cannot be deep-copied try: self.params = copy.deepcopy(other) except TypeError: self.params = unicode(other)", else: self.params = copy.deepcopy(other),32,1
openstack%2Fsahara~master~I1de3f893ace15d84add50f4e2359c01b503b842f,openstack/sahara,master,I1de3f893ace15d84add50f4e2359c01b503b842f,Refactoring unit tests for validation,MERGED,2013-07-18 12:04:01.000000000,2013-07-23 13:52:26.000000000,2013-07-23 13:52:26.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7478}, {'_account_id': 7729}]","[{'number': 1, 'created': '2013-07-18 12:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/fcf2979002cf4425e818722783c2047db7d81313', 'message': 'Refactoring unit tests for validation\n\nChange-Id: I1de3f893ace15d84add50f4e2359c01b503b842f\n'}, {'number': 2, 'created': '2013-07-22 11:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9d6974f0abfa28fc793bc619929b989acae0d5ed', 'message': 'Refactoring unit tests for validation\n\nChange-Id: I1de3f893ace15d84add50f4e2359c01b503b842f\n'}, {'number': 3, 'created': '2013-07-22 11:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1fe7cd547dd5866f00c62491ec05374487ebd2ef', 'message': 'Refactoring unit tests for validation\n\nChange-Id: I1de3f893ace15d84add50f4e2359c01b503b842f\n'}, {'number': 4, 'created': '2013-07-22 12:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/be550138249b93f410dd832e098f1328290ad85f', 'message': 'Refactoring unit tests for validation\n\nChange-Id: I1de3f893ace15d84add50f4e2359c01b503b842f\n'}, {'number': 5, 'created': '2013-07-22 13:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/87f8b63b3043efcd599e3e1027f798518f1eef05', 'message': 'Refactoring unit tests for validation:\n\nCreated utils.py for validation UT\nCreated common class for validation UT - ValidationTestCase\ntest_validation.py was splitted to test files for each file in validation\n\nChange-Id: I1de3f893ace15d84add50f4e2359c01b503b842f\n'}, {'number': 6, 'created': '2013-07-23 06:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c5f2f1c549f17ea3f1d73f610edebbadf1737194', 'message': 'Refactoring unit tests for validation\n\nCreated utils.py for validation UT\nCreated common class for validation UT - ValidationTestCase\nFile test_validation.py was splitted to test files for each file in validation\n\nChange-Id: I1de3f893ace15d84add50f4e2359c01b503b842f\n'}, {'number': 7, 'created': '2013-07-23 12:00:21.000000000', 'files': ['savanna/tests/unit/service/validation/test_cluster_template_create_validation.py', 'savanna/tests/unit/service/validation/__init__.py', 'savanna/tests/unit/service/validation/utils.py', 'savanna/tests/unit/service/test_validation.py', 'savanna/tests/unit/service/validation/test_cluster_scaling_validation.py', 'savanna/tests/unit/service/validation/test_cluster_create_validation.py', 'savanna/tests/unit/service/validation/test_ng_template_validation_create.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/29abc401faba80966f18e5e61ebb44ebf0200bd7', 'message': 'Refactoring unit tests for validation\n\nCreated utils.py for validation UT\nCreated common class for validation UT - ValidationTestCase\nFile test_validation.py was splitted to test files for each file in validation\n\nChange-Id: I1de3f893ace15d84add50f4e2359c01b503b842f\n'}]",38,37669,29abc401faba80966f18e5e61ebb44ebf0200bd7,35,6,7,7729,,,0,"Refactoring unit tests for validation

Created utils.py for validation UT
Created common class for validation UT - ValidationTestCase
File test_validation.py was splitted to test files for each file in validation

Change-Id: I1de3f893ace15d84add50f4e2359c01b503b842f
",git fetch https://review.opendev.org/openstack/sahara refs/changes/69/37669/6 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/tests/unit/service/validation/test_cluster_template_create_validation.py', 'savanna/tests/unit/service/validation/__init__.py', 'savanna/tests/unit/service/validation/utils.py', 'savanna/tests/unit/service/test_validation.py', 'savanna/tests/unit/service/validation/test_cluster_scaling_validation.py', 'savanna/tests/unit/service/validation/test_cluster_create_validation.py', 'savanna/tests/unit/service/validation/test_ng_template_validation_create.py']",7,fcf2979002cf4425e818722783c2047db7d81313,bug/2,"# Copyright (c) 2013 Mirantis Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from savanna.service.validations import node_group_templates as nt from savanna.tests.unit.service.validation import utils as u class TestNGTemplateCreateValidation(u.ValidationTestCase): def test_node_groups_create_required(self): self._create_object_fun = nt.check_node_group_template_create scheme = nt.NODE_GROUP_TEMPLATE_SCHEMA self._assert_create_object_validation( scheme=scheme, data={ }, bad_req_i=(1, ""VALIDATION_ERROR"", u""'name' is a required property"") ) self._assert_create_object_validation( scheme=scheme, data={ 'name': 'a' }, bad_req_i=(1, ""VALIDATION_ERROR"", u""'flavor_id' is a required property"") ) self._assert_create_object_validation( scheme=scheme, data={ 'name': 'a', 'flavor_id': '42', 'plugin_name': 'vanilla', }, bad_req_i=(1, ""VALIDATION_ERROR"", u""'hadoop_version' is a required property"") ) self._assert_create_object_validation( scheme=scheme, data={ 'name': 'a', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2' }, bad_req_i=(1, ""VALIDATION_ERROR"", u""'node_processes' is a required property"") ) self._assert_create_object_validation( scheme=scheme, data={ 'name': ""a"", 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': [] }, bad_req_i=(1, 'VALIDATION_ERROR', u'[] is too short') ) def test_ng_template_create_v_names(self): self._create_object_fun = nt.check_node_group_template_create scheme = nt.NODE_GROUP_TEMPLATE_SCHEMA data = { 'name': 'a', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['namenode'] } self._assert_object_name_validation(scheme, data, ""valid_name"") def test_ng_template_create_v_node_processes(self): self._create_object_fun = nt.check_node_group_template_create scheme = nt.NODE_GROUP_TEMPLATE_SCHEMA self._assert_create_object_validation( scheme=scheme, data={ 'name': ""a"", 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': [""namenode"", ""namenode""] }, bad_req_i=(1, 'INVALID_REFERENCE', 'Duplicates in node processes have been detected') ) self._assert_create_object_validation( scheme=scheme, data={ 'name': 'a', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['wrong_process'] }, bad_req_i=(1, 'INVALID_REFERENCE', ""Plugin supports the following node procesess: "" ""['namenode', 'datanode', 'secondarynamenode', "" ""'tasktracker', 'jobtracker']"") ) def test_ng_template_create_v_right(self): self._create_object_fun = nt.check_node_group_template_create scheme = nt.NODE_GROUP_TEMPLATE_SCHEMA self._assert_create_object_validation( scheme=scheme, data={ 'name': 'a', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['namenode', 'datanode', 'secondarynamenode', 'tasktracker', 'jobtracker'], 'node_configs': { 'HDFS': { u'hadoop.tmp.dir': '/temp/' } }, 'image_id': '550e8400-e29b-41d4-a716-446655440000', 'volumes_per_node': 2, 'volumes_size': 10, 'description': 'test node template' } ) def test_ng_template_create_v_minimum_ints(self): self._create_object_fun = nt.check_node_group_template_create scheme = nt.NODE_GROUP_TEMPLATE_SCHEMA self._assert_create_object_validation( scheme=scheme, data={ 'name': 'a', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['wrong_process'], 'volumes_per_node': -1 }, bad_req_i=(1, 'VALIDATION_ERROR', u'-1.0 is less than the minimum of 0') ) self._assert_create_object_validation( scheme=scheme, data={ 'name': 'a', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['wrong_process'], 'volumes_size': 0 }, bad_req_i=(1, 'VALIDATION_ERROR', u'0.0 is less than the minimum of 1') ) def test_ng_template_create_v_types(self): self._create_object_fun = nt.check_node_group_template_create scheme = nt.NODE_GROUP_TEMPLATE_SCHEMA default_data = { 'name': 'a', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['namenode'] } self._assert_types(default_data, scheme) def test_ng_template_create_v_unique_ng(self): self._create_object_fun = nt.check_node_group_template_create scheme = nt.NODE_GROUP_TEMPLATE_SCHEMA data = { 'name': 'test', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['namenode']} self._assert_create_object_validation( scheme=scheme, data=data, bad_req_i=(1, 'NAME_ALREADY_EXISTS', ""NodeGroup template with name 'test' already exists"") ) def test_ng_template_create_v_flavor_exists(self): self._create_object_fun = nt.check_node_group_template_create scheme = nt.NODE_GROUP_TEMPLATE_SCHEMA self._assert_create_object_validation( scheme=scheme, data={ 'name': 'test-ng', 'flavor_id': '1', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['namenode'] }, bad_req_i=(1, 'INVALID_REFERENCE', ""Requested flavor '1' not found"") ) def test_ng_template_create_v_ng_configs(self): self._create_object_fun = nt.check_node_group_template_create scheme = nt.NODE_GROUP_TEMPLATE_SCHEMA self._assert_create_object_validation( scheme=scheme, data={ 'name': 'test-ng', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['namenode'], 'node_configs': { 'wrong_target': { u'hadoop.tmp.dir': '/temp/' } }}, bad_req_i=(1, 'INVALID_REFERENCE', ""Plugin doesn't contain applicable "" ""target 'wrong_target'"") ) self._assert_create_object_validation( scheme=scheme, data={ 'name': 'test-ng', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['namenode'], 'node_configs': { 'HDFS': { 's': 'a' } } }, bad_req_i=(1, 'INVALID_REFERENCE', ""Plugin's applicable target 'HDFS' doesn't "" ""contain config with name 's'"") ) def test_ng_template_cinder(self): self._create_object_fun = nt.check_node_group_template_create scheme = nt.NODE_GROUP_TEMPLATE_SCHEMA self._assert_create_object_validation( scheme=scheme, data={ 'name': 'a', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['wrong_process'], 'volumes_per_node': -1 }, bad_req_i=(1, 'VALIDATION_ERROR', u'-1.0 is less than the minimum of 0') ) self._assert_create_object_validation( scheme=scheme, data={ 'name': 'a', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['wrong_process'], 'volumes_size': 0 }, bad_req_i=(1, 'VALIDATION_ERROR', u'0.0 is less than the minimum of 1') ) self._assert_create_object_validation( scheme=scheme, data={ 'name': 'a', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['datanode', 'tasktracker'], 'volumes_per_node': 1, 'volumes_size': 1, 'volume_mount_prefix': '/mnt/volume' } ) data = { 'name': 'a', 'flavor_id': '42', 'plugin_name': 'vanilla', 'hadoop_version': '1.1.2', 'node_processes': ['datanode', 'tasktracker'], 'volumes_per_node': 1, 'volumes_size': 1, 'volume_mount_prefix': 'qwerty' } self._assert_create_object_validation( scheme=scheme, data=data, bad_req_i=(1, 'VALIDATION_ERROR', ""'qwerty' is not a 'posix_path'"") ) ",,1351,1205
openstack%2Foslo-incubator~master~I9adaa90bbd6dffd7f58f5ff0403859e8806e37fb,openstack/oslo-incubator,master,I9adaa90bbd6dffd7f58f5ff0403859e8806e37fb,Exception code cleanup,MERGED,2013-07-19 15:18:52.000000000,2013-07-23 13:28:45.000000000,2013-07-23 13:28:45.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 5638}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-07-19 15:18:52.000000000', 'files': ['tests/unit/rpc/test_common.py', 'tests/unit/test_exception.py', 'openstack/common/exception.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/05f33ec591acd2870130a2e5eb4c29994b11fbe6', 'message': 'Exception code cleanup\n\nRemove old commented code\nRemove some incorrect comments\nRemove unnecessary __class__ indirection\nConvert err.__str__() to str(err)\nRemove unused tb item in test\n\nChange-Id: I9adaa90bbd6dffd7f58f5ff0403859e8806e37fb\n'}]",0,37923,05f33ec591acd2870130a2e5eb4c29994b11fbe6,7,4,1,6928,,,0,"Exception code cleanup

Remove old commented code
Remove some incorrect comments
Remove unnecessary __class__ indirection
Convert err.__str__() to str(err)
Remove unused tb item in test

Change-Id: I9adaa90bbd6dffd7f58f5ff0403859e8806e37fb
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/23/37923/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/rpc/test_common.py', 'tests/unit/test_exception.py', 'openstack/common/exception.py']",3,05f33ec591acd2870130a2e5eb4c29994b11fbe6,rename-message," msg = self.msg_fmt % scheme msg = self.msg_fmt % (uri, reason)"," msg = self.__class__.msg_fmt % scheme msg = self.__class__.msg_fmt % (uri, reason) #exc_type, exc_value, exc_traceback = sys.exc_info() #logging.error(traceback.extract_stack(exc_traceback))",4,9
openstack%2Foslo-incubator~master~I913a8a5d025cc392ef2003951763cf55629fd8d2,openstack/oslo-incubator,master,I913a8a5d025cc392ef2003951763cf55629fd8d2,Avoid shadowing Exception 'message' attribute,MERGED,2013-07-16 23:38:12.000000000,2013-07-23 13:28:25.000000000,2013-07-23 13:28:25.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 7996}]","[{'number': 1, 'created': '2013-07-16 23:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/6ad1bd2e673ea14041a22d09e547c417794fae48', 'message': ""Avoid shadowing Exception 'message' attribute\n\nException.message is deprecated in Python 3, and it's confusing\nthat we shadow it right now, so change class attributes named\nmessage to something else.\n\nFor reference, see commit 7bfd4439fe48e861675e3930486b55f8badd072e\n\nAlso removed a couple of unnecessary commented lines that didn't\nseem to warrant an entire change by themselves.\n\nChange-Id: I913a8a5d025cc392ef2003951763cf55629fd8d2\n""}, {'number': 2, 'created': '2013-07-17 00:35:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/16aa10736f9533924c89410109319a1208c070e2', 'message': ""Avoid shadowing Exception 'message' attribute\n\nException.message is deprecated in Python 3, and it's confusing\nthat we shadow it right now, so change class attributes named\nmessage to something else.\n\nFor reference, see commit 7bfd4439fe48e861675e3930486b55f8badd072e\n\nAlso removed a couple of unnecessary commented lines that didn't\nseem to warrant an entire change by themselves.\n\nChange-Id: I913a8a5d025cc392ef2003951763cf55629fd8d2\n""}, {'number': 3, 'created': '2013-07-19 15:18:52.000000000', 'files': ['tests/unit/rpc/test_common.py', 'tests/unit/test_exception.py', 'openstack/common/exception.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/9a3ebf2ff5b995085d0fb8e075687b48681d391f', 'message': ""Avoid shadowing Exception 'message' attribute\n\nException.message is deprecated in Python 3, and it's confusing\nthat we shadow it right now, so change class attributes named\nmessage to something else.\n\nFor reference, see commit 7bfd4439fe48e861675e3930486b55f8badd072e\n\nChange-Id: I913a8a5d025cc392ef2003951763cf55629fd8d2\n""}]",14,37354,9a3ebf2ff5b995085d0fb8e075687b48681d391f,23,6,3,6928,,,0,"Avoid shadowing Exception 'message' attribute

Exception.message is deprecated in Python 3, and it's confusing
that we shadow it right now, so change class attributes named
message to something else.

For reference, see commit 7bfd4439fe48e861675e3930486b55f8badd072e

Change-Id: I913a8a5d025cc392ef2003951763cf55629fd8d2
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/54/37354/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/exception.py'],1,6ad1bd2e673ea14041a22d09e547c417794fae48,rename-message," self.api_message = message msg_fmt = ""Unknown scheme '%s' found in URI"" msg = self.__class__.msg_fmt % scheme msg_fmt = ""The Store URI %s was malformed. Reason: %s"" msg = self.__class__.msg_fmt % (uri, reason) a 'msg_fmt' property. That message will get printf'd msg_fmt = ""An unknown exception occurred"" self._error_string = self.msg_fmt % kwargs self._error_string = self.msg_fmt msg_fmt = ""Malformed message body: %(reason)s"" msg_fmt = ""Invalid content type %(content_type)s"""," self.message = message msg = ""Unknown scheme '%s' found in URI"" msg = self.__class__.msg % scheme msg = ""The Store URI %s was malformed. Reason: %s"" msg = self.__class__.msg % (uri, reason) #exc_type, exc_value, exc_traceback = sys.exc_info() #logging.error(traceback.extract_stack(exc_traceback)) a 'message' property. That message will get printf'd message = ""An unknown exception occurred"" self._error_string = self.message % kwargs self._error_string = self.message message = ""Malformed message body: %(reason)s"" message = ""Invalid content type %(content_type)s""",11,13
openstack%2Foslo-incubator~master~I48442696b66392de33520714b9beb2c645ec1b58,openstack/oslo-incubator,master,I48442696b66392de33520714b9beb2c645ec1b58,python3: Add python3 compatibility support,MERGED,2013-07-12 18:14:40.000000000,2013-07-23 13:26:51.000000000,2013-07-23 13:26:51.000000000,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 5638}]","[{'number': 1, 'created': '2013-07-12 18:14:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/eb0cbee6b81ed25dfe8a1d33c373bf163860268b', 'message': 'python3: Add python3 compatibility support\n\nAdd python2/python3 compatibility support:\n\n- Use six.iteritems() to replace dictionary.iteritems()\n  on python2 or dictionary.items() on python3.\n\n- Use six.advanced_iterator as a replacement to call\n  it.next() on python2 and next(it) on python3.\n\nChange-Id: I48442696b66392de33520714b9beb2c645ec1b58\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}, {'number': 2, 'created': '2013-07-15 17:59:44.000000000', 'files': ['openstack/common/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/31c19959ba784f0f4ac100ac9765d91b696f8214', 'message': 'python3: Add python3 compatibility support\n\nAdd python2/python3 compatibility support:\n\n- Use six.iteritems() to replace dictionary.iteritems()\n  on python2 or dictionary.items() on python3.\n\n- Use six.advanced_iterator as a replacement to call\n  it.next() on python2 and next(it) on python3.\n\nChange-Id: I48442696b66392de33520714b9beb2c645ec1b58\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",3,36874,31c19959ba784f0f4ac100ac9765d91b696f8214,12,6,2,24,,,0,"python3: Add python3 compatibility support

Add python2/python3 compatibility support:

- Use six.iteritems() to replace dictionary.iteritems()
  on python2 or dictionary.items() on python3.

- Use six.advanced_iterator as a replacement to call
  it.next() on python2 and next(it) on python3.

Change-Id: I48442696b66392de33520714b9beb2c645ec1b58
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/74/36874/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/db/sqlalchemy/models.py'],1,eb0cbee6b81ed25dfe8a1d33c373bf163860268b,(detached,"import six n = six.advance_iterator(self._i) for k, v in six.iteritems(values): joined = dict([(k, v) for k, v in six.iteritems(self.__dict__)"," n = self._i.next() for k, v in values.iteritems(): joined = dict([(k, v) for k, v in self.__dict__.iteritems()",5,3
openstack%2Foslo-incubator~master~I85dafc392023f0ae845efe851a5a4a9438e40e37,openstack/oslo-incubator,master,I85dafc392023f0ae845efe851a5a4a9438e40e37,Add serializer param to RPC service,MERGED,2013-07-18 22:36:21.000000000,2013-07-23 13:26:45.000000000,2013-07-23 13:26:45.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 2889}, {'_account_id': 4393}, {'_account_id': 5638}, {'_account_id': 6786}]","[{'number': 1, 'created': '2013-07-18 22:36:21.000000000', 'files': ['openstack/common/rpc/service.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f52446cbe291e8c8f603ddb39acb950b72195884', 'message': 'Add serializer param to RPC service\n\nAllow a serializer to be passed to RPC service class\nwhen it is instantiated.\n\nChange-Id: I85dafc392023f0ae845efe851a5a4a9438e40e37\n'}]",0,37799,f52446cbe291e8c8f603ddb39acb950b72195884,10,6,1,2889,,,0,"Add serializer param to RPC service

Allow a serializer to be passed to RPC service class
when it is instantiated.

Change-Id: I85dafc392023f0ae845efe851a5a4a9438e40e37
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/99/37799/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/rpc/service.py'],1,f52446cbe291e8c8f603ddb39acb950b72195884,master," def __init__(self, host, topic, manager=None, serializer=None): self.serializer = serializer dispatcher = rpc_dispatcher.RpcDispatcher([self.manager], self.serializer)"," def __init__(self, host, topic, manager=None): dispatcher = rpc_dispatcher.RpcDispatcher([self.manager])",4,2
openstack%2Fopenstack-manuals~master~Ic23b6c4b11c35148ea3d386d3d6c22322eaefbcc,openstack/openstack-manuals,master,Ic23b6c4b11c35148ea3d386d3d6c22322eaefbcc,fix broken link in heat cli-guide,MERGED,2013-07-22 18:34:43.000000000,2013-07-23 12:56:59.000000000,2013-07-23 12:56:59.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-07-22 18:34:43.000000000', 'files': ['doc/src/docbkx/cli-guide/src/section_cli_heat.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/39b2f3a5d74ae8954c49b83e046cdf7e8b392596', 'message': 'fix broken link in heat cli-guide\n\nIn the current heat_client quickstart guide there is a link to the wordpress\ntemplates that gets a 404 error. I have updated section_cli_heat.xml to reflect\nhttps://github.com/openstack/heat-templates which is referenced as the proper\nurl in the bug description.\n\nChange-Id: Ic23b6c4b11c35148ea3d386d3d6c22322eaefbcc\nFixes: bug #1203814\n'}]",0,38190,39b2f3a5d74ae8954c49b83e046cdf7e8b392596,6,3,1,8118,,,0,"fix broken link in heat cli-guide

In the current heat_client quickstart guide there is a link to the wordpress
templates that gets a 404 error. I have updated section_cli_heat.xml to reflect
https://github.com/openstack/heat-templates which is referenced as the proper
url in the bug description.

Change-Id: Ic23b6c4b11c35148ea3d386d3d6c22322eaefbcc
Fixes: bug #1203814
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/90/38190/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/cli-guide/src/section_cli_heat.xml'],1,39b2f3a5d74ae8954c49b83e046cdf7e8b392596,bug/1203814," xlink:href=""https://github.com/openstack/heat-templates"">example template file</link>, run following command:</para>"," xlink:href=""https://github.com/openstack/heat/blob/master/templates/WordPress_Single_Instance.template"" >example template file</link>, run following command:</para>",2,3
openstack%2Fopenstack-manuals~master~I6edd5516bf85640a2a2958bf7883fd2dcce707a7,openstack/openstack-manuals,master,I6edd5516bf85640a2a2958bf7883fd2dcce707a7,Adding missing parenthesis on String,MERGED,2013-07-22 23:21:09.000000000,2013-07-23 12:55:25.000000000,2013-07-23 12:55:25.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 2448}, {'_account_id': 6772}, {'_account_id': 8217}]","[{'number': 1, 'created': '2013-07-22 23:21:09.000000000', 'files': ['doc/src/docbkx/openstack-install/bk_openstackinstallguide.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/169696baf09803990ed7edc58b8de1e62c9252cc', 'message': 'Adding missing parenthesis on String\n\nChange-Id: I6edd5516bf85640a2a2958bf7883fd2dcce707a7\n'}]",0,38223,169696baf09803990ed7edc58b8de1e62c9252cc,10,5,1,8217,,,0,"Adding missing parenthesis on String

Change-Id: I6edd5516bf85640a2a2958bf7883fd2dcce707a7
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/23/38223/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-install/bk_openstackinstallguide.xml'],1,169696baf09803990ed7edc58b8de1e62c9252cc,, Networking (Quantum)).</para>, Networking (Quantum).</para>,1,1
openstack%2Fcookbook-openstack-ops-messaging~master~I53da70583c50ae985d3842c3d709eb81f565d63d,openstack/cookbook-openstack-ops-messaging,master,I53da70583c50ae985d3842c3d709eb81f565d63d,"Revert ""Configure rabbit and EPMD to bind to an address""",MERGED,2013-07-22 22:14:07.000000000,2013-07-23 12:46:02.000000000,2013-07-23 12:46:02.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 2340}]","[{'number': 1, 'created': '2013-07-22 22:14:07.000000000', 'files': ['recipes/rabbitmq-server.rb', 'spec/spec_helper.rb', 'attributes/default.rb', 'spec/server_spec.rb', 'spec/rabbitmq-server_spec.rb', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-messaging/commit/b1ad1fd679e9dec7601212f4427214db64afe582', 'message': 'Revert ""Configure rabbit and EPMD to bind to an address""\n\nSince this breaks people using rabbit in the standard way, I\nrather revert this change, and fork my own ops-messaging cookbook\nsince this is intended as an example cookbook (granted others\nmay use it directly).  This code would be better off in my\nown fork, where i do not impact others, with a non-merged upstream\nrabbitmq feature.\n\nThis reverts commit 3b35ac204d7b117e86cc51d72bfc4a927183a92a.\n\nChange-Id: I53da70583c50ae985d3842c3d709eb81f565d63d\n'}]",0,38213,b1ad1fd679e9dec7601212f4427214db64afe582,6,3,1,216,,,0,"Revert ""Configure rabbit and EPMD to bind to an address""

Since this breaks people using rabbit in the standard way, I
rather revert this change, and fork my own ops-messaging cookbook
since this is intended as an example cookbook (granted others
may use it directly).  This code would be better off in my
own fork, where i do not impact others, with a non-merged upstream
rabbitmq feature.

This reverts commit 3b35ac204d7b117e86cc51d72bfc4a927183a92a.

Change-Id: I53da70583c50ae985d3842c3d709eb81f565d63d
",git fetch https://review.opendev.org/openstack/cookbook-openstack-ops-messaging refs/changes/13/38213/1 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/rabbitmq-server.rb', 'spec/spec_helper.rb', 'attributes/default.rb', 'spec/server_spec.rb', 'spec/rabbitmq-server_spec.rb', 'README.md']",6,b1ad1fd679e9dec7601212f4427214db64afe582,revert-epmd,,"* `openstack[""mq""][""erl_bind_networking""]` - whether or not to bind rabbit and epmd to the listen address determined by `openstack[""mq""][""bind_interface""]`",3,75
openstack%2Fceilometer~master~I8a57d69e1665689a4b58ddef6785980b48bba8f7,openstack/ceilometer,master,I8a57d69e1665689a4b58ddef6785980b48bba8f7,CloudWatch API for Ceilometer,ABANDONED,2013-07-23 12:33:00.000000000,2013-07-23 12:40:37.000000000,,[],"[{'number': 1, 'created': '2013-07-23 12:33:00.000000000', 'files': ['tests/api/v2/post_samples_cw.py', 'ceilometer/api/cloudwatch/cw/__init__.py', '.gitreview', 'ceilometer/api/cloudwatch/context.py', 'ceilometer/api/cloudwatch/utils.py', 'ceilometer/api/cloudwatch/auth.py', 'ceilometer/api/cloudwatch/cw/cloudwatch.py', 'ceilometer/api/cloudwatch/policy.py', 'ceilometer/api/cloudwatch/service.py', 'requirements.txt', 'ceilometer/api/cloudwatch/cw/faults.py', 'ceilometer/api/cloudwatch/wsgi.py', 'ceilometer/api/cloudwatch/exception.py', 'ceilometer/api/cloudwatch/api_cw.py', 'setup.cfg', 'etc/ceilometer/api-paste.ini', 'ceilometer/api/cloudwatch/config.py', 'ceilometer/api/cloudwatch/__init__.py', 'ceilometer/api/cloudwatch/cw/apirequest.py', 'ceilometer/api/cloudwatch/validator.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/84dc6fb93232341b021c2a930dafbe5d01bc8719', 'message': 'CloudWatch API for Ceilometer\n\nIf ceilometer has cloudwatch compatible api, then there are many tools\ndeveloped for aws cloudwatch can be used by ceilometer. It will save our\ntime to collect data and publish data.\n\nChange-Id: I8a57d69e1665689a4b58ddef6785980b48bba8f7\n'}]",0,38286,84dc6fb93232341b021c2a930dafbe5d01bc8719,1,0,1,5055,,,0,"CloudWatch API for Ceilometer

If ceilometer has cloudwatch compatible api, then there are many tools
developed for aws cloudwatch can be used by ceilometer. It will save our
time to collect data and publish data.

Change-Id: I8a57d69e1665689a4b58ddef6785980b48bba8f7
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/86/38286/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/api/v2/post_samples_cw.py', 'ceilometer/api/cloudwatch/cw/__init__.py', '.gitreview', 'ceilometer/api/cloudwatch/context.py', 'ceilometer/api/cloudwatch/utils.py', 'ceilometer/api/cloudwatch/auth.py', 'ceilometer/api/cloudwatch/cw/cloudwatch.py', 'ceilometer/api/cloudwatch/policy.py', 'ceilometer/api/cloudwatch/service.py', 'requirements.txt', 'ceilometer/api/cloudwatch/cw/faults.py', 'ceilometer/api/cloudwatch/wsgi.py', 'ceilometer/api/cloudwatch/exception.py', 'ceilometer/api/cloudwatch/api_cw.py', 'setup.cfg', 'etc/ceilometer/api-paste.ini', 'ceilometer/api/cloudwatch/config.py', 'ceilometer/api/cloudwatch/__init__.py', 'ceilometer/api/cloudwatch/cw/apirequest.py', 'ceilometer/api/cloudwatch/validator.py']",20,84dc6fb93232341b021c2a930dafbe5d01bc8719,cloudwatch-api,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 Cloudscaling, Inc. # Author: Matthew Hooker <matt@cloudscaling.com> # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import re from ceilometer.openstack.common import log as logging LOG = logging.getLogger(__name__) def validate_str(max_length=None): def _do(val): if not isinstance(val, basestring): return False if max_length and len(val) > max_length: return False return True return _do def validate_int(max_value=None): def _do(val): if not isinstance(val, int): return False if max_value and val > max_value: return False return True return _do def validate(args, validator): """"""Validate values of args against validators in validator. :param args: Dict of values to be validated. :param validator: A dict where the keys map to keys in args and the values are validators. Applies each validator to ``args[key]`` :returns: True if validation succeeds. Otherwise False. A validator should be a callable which accepts 1 argument and which returns True if the argument passes validation. False otherwise. A validator should not raise an exception to indicate validity of the argument. Only validates keys which show up in both args and validator. """""" for key in validator: if key not in args: continue f = validator[key] assert callable(f) if not f(args[key]): LOG.debug(_(""%(key)s with value %(value)s failed"" "" validator %(name)s""), {'key': key, 'value': args[key], 'name': f.__name__}) return False return True ",,3883,2
openstack%2Fheat~master~I8466493fbeba2023916f2d92814c1cc8f2827e51,openstack/heat,master,I8466493fbeba2023916f2d92814c1cc8f2827e51,api : Implement OnFailure option to cfn API CreateStack call,MERGED,2013-07-05 21:49:55.000000000,2013-07-23 12:35:33.000000000,2013-07-23 12:35:33.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7135}, {'_account_id': 7385}]","[{'number': 1, 'created': '2013-07-05 21:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9fdb1bc3a2c2b01babe674b471b48eaf2fe8b66c', 'message': 'api : Implement OnFailure option to cfn API CreateStack call\n\nblueprint createstack-onfailure\n\nChange-Id: I8466493fbeba2023916f2d92814c1cc8f2827e51\n'}, {'number': 2, 'created': '2013-07-22 15:43:55.000000000', 'files': ['heat/api/cfn/v1/stacks.py', 'heat/tests/test_api_cfn_v1.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/5056908945edb721b04713347b780dfa8e28a21a', 'message': 'api : Implement OnFailure option to cfn API CreateStack call\n\nblueprint createstack-onfailure\n\nChange-Id: I8466493fbeba2023916f2d92814c1cc8f2827e51\n'}]",2,35900,5056908945edb721b04713347b780dfa8e28a21a,13,6,2,4328,,,0,"api : Implement OnFailure option to cfn API CreateStack call

blueprint createstack-onfailure

Change-Id: I8466493fbeba2023916f2d92814c1cc8f2827e51
",git fetch https://review.opendev.org/openstack/heat refs/changes/00/35900/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/api/cfn/v1/stacks.py', 'heat/tests/test_api_cfn_v1.py']",2,9fdb1bc3a2c2b01babe674b471b48eaf2fe8b66c,bp/createstack-onfailure," def test_create_rollback(self): # Format a dummy request stack_name = ""wordpress"" template = {u'Foo': u'bar'} json_template = json.dumps(template) params = {'Action': 'CreateStack', 'StackName': stack_name, 'TemplateBody': '%s' % json_template, 'TimeoutInMinutes': 30, 'DisableRollback': 'false', 'Parameters.member.1.ParameterKey': 'InstanceType', 'Parameters.member.1.ParameterValue': 'm1.xlarge'} engine_parms = {u'InstanceType': u'm1.xlarge'} engine_args = {'timeout_mins': u'30', 'disable_rollback': 'false'} dummy_req = self._dummy_GET_request(params) # Stub out the RPC call to the engine with a pre-canned response engine_resp = {u'tenant': u't', u'stack_name': u'wordpress', u'stack_id': u'1', u'path': u''} self.m.StubOutWithMock(rpc, 'call') rpc.call(dummy_req.context, self.topic, {'namespace': None, 'method': 'create_stack', 'args': {'stack_name': stack_name, 'template': template, 'params': engine_parms, 'files': {}, 'args': engine_args}, 'version': self.api_version}, None).AndReturn(engine_resp) self.m.ReplayAll() response = self.controller.create(dummy_req) expected = { 'CreateStackResponse': { 'CreateStackResult': { u'StackId': u'arn:openstack:heat::t:stacks/wordpress/1' } } } self.assertEqual(response, expected) self.m.VerifyAll() def test_create_onfailure_true(self): # Format a dummy request stack_name = ""wordpress"" template = {u'Foo': u'bar'} json_template = json.dumps(template) params = {'Action': 'CreateStack', 'StackName': stack_name, 'TemplateBody': '%s' % json_template, 'TimeoutInMinutes': 30, 'OnFailure': 'DO_NOTHING', 'Parameters.member.1.ParameterKey': 'InstanceType', 'Parameters.member.1.ParameterValue': 'm1.xlarge'} engine_parms = {u'InstanceType': u'm1.xlarge'} engine_args = {'timeout_mins': u'30', 'disable_rollback': 'true'} dummy_req = self._dummy_GET_request(params) # Stub out the RPC call to the engine with a pre-canned response engine_resp = {u'tenant': u't', u'stack_name': u'wordpress', u'stack_id': u'1', u'path': u''} self.m.StubOutWithMock(rpc, 'call') rpc.call(dummy_req.context, self.topic, {'namespace': None, 'method': 'create_stack', 'args': {'stack_name': stack_name, 'template': template, 'params': engine_parms, 'files': {}, 'args': engine_args}, 'version': self.api_version}, None).AndReturn(engine_resp) self.m.ReplayAll() response = self.controller.create(dummy_req) expected = { 'CreateStackResponse': { 'CreateStackResult': { u'StackId': u'arn:openstack:heat::t:stacks/wordpress/1' } } } self.assertEqual(response, expected) self.m.VerifyAll() def test_create_onfailure_false_delete(self): # Format a dummy request stack_name = ""wordpress"" template = {u'Foo': u'bar'} json_template = json.dumps(template) params = {'Action': 'CreateStack', 'StackName': stack_name, 'TemplateBody': '%s' % json_template, 'TimeoutInMinutes': 30, 'OnFailure': 'DELETE', 'Parameters.member.1.ParameterKey': 'InstanceType', 'Parameters.member.1.ParameterValue': 'm1.xlarge'} engine_parms = {u'InstanceType': u'm1.xlarge'} engine_args = {'timeout_mins': u'30', 'disable_rollback': 'false'} dummy_req = self._dummy_GET_request(params) # Stub out the RPC call to the engine with a pre-canned response engine_resp = {u'tenant': u't', u'stack_name': u'wordpress', u'stack_id': u'1', u'path': u''} self.m.StubOutWithMock(rpc, 'call') rpc.call(dummy_req.context, self.topic, {'namespace': None, 'method': 'create_stack', 'args': {'stack_name': stack_name, 'template': template, 'params': engine_parms, 'files': {}, 'args': engine_args}, 'version': self.api_version}, None).AndReturn(engine_resp) self.m.ReplayAll() response = self.controller.create(dummy_req) expected = { 'CreateStackResponse': { 'CreateStackResult': { u'StackId': u'arn:openstack:heat::t:stacks/wordpress/1' } } } self.assertEqual(response, expected) self.m.VerifyAll() def test_create_onfailure_false_rollback(self): # Format a dummy request stack_name = ""wordpress"" template = {u'Foo': u'bar'} json_template = json.dumps(template) params = {'Action': 'CreateStack', 'StackName': stack_name, 'TemplateBody': '%s' % json_template, 'TimeoutInMinutes': 30, 'OnFailure': 'ROLLBACK', 'Parameters.member.1.ParameterKey': 'InstanceType', 'Parameters.member.1.ParameterValue': 'm1.xlarge'} engine_parms = {u'InstanceType': u'm1.xlarge'} engine_args = {'timeout_mins': u'30', 'disable_rollback': 'false'} dummy_req = self._dummy_GET_request(params) # Stub out the RPC call to the engine with a pre-canned response engine_resp = {u'tenant': u't', u'stack_name': u'wordpress', u'stack_id': u'1', u'path': u''} self.m.StubOutWithMock(rpc, 'call') rpc.call(dummy_req.context, self.topic, {'namespace': None, 'method': 'create_stack', 'args': {'stack_name': stack_name, 'template': template, 'params': engine_parms, 'files': {}, 'args': engine_args}, 'version': self.api_version}, None).AndReturn(engine_resp) self.m.ReplayAll() response = self.controller.create(dummy_req) expected = { 'CreateStackResponse': { 'CreateStackResult': { u'StackId': u'arn:openstack:heat::t:stacks/wordpress/1' } } } self.assertEqual(response, expected) self.m.VerifyAll() def test_create_onfailure_err(self): # Format a dummy request stack_name = ""wordpress"" template = {u'Foo': u'bar'} json_template = json.dumps(template) params = {'Action': 'CreateStack', 'StackName': stack_name, 'TemplateBody': '%s' % json_template, 'TimeoutInMinutes': 30, 'DisableRollback': 'true', 'OnFailure': 'DO_NOTHING', 'Parameters.member.1.ParameterKey': 'InstanceType', 'Parameters.member.1.ParameterValue': 'm1.xlarge'} engine_parms = {u'InstanceType': u'm1.xlarge'} engine_args = {'timeout_mins': u'30', 'disable_rollback': 'false'} dummy_req = self._dummy_GET_request(params) self.assertRaises(exception.HeatInvalidParameterCombinationError, self.controller.create, dummy_req) ",,224,1
openstack%2Fdesignate~master~I5a2e8ec6bb0ca988e31c21cbd4e514f83bfd5ba0,openstack/designate,master,I5a2e8ec6bb0ca988e31c21cbd4e514f83bfd5ba0,Remove unnecessary default criterion value,MERGED,2013-07-23 10:46:49.000000000,2013-07-23 12:29:19.000000000,2013-07-23 12:29:19.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 6494}]","[{'number': 1, 'created': '2013-07-23 10:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/cda80d9a7d8330f0f488cc576855d537af9487b5', 'message': 'Remove unnecessary default criterion value\n\nChange-Id: I5a2e8ec6bb0ca988e31c21cbd4e514f83bfd5ba0\n'}, {'number': 2, 'created': '2013-07-23 10:48:19.000000000', 'files': ['designate/central/service.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/6e275e2f23e303705478021a2f53cef9fde6752e', 'message': 'Remove unnecessary default criterion value\n\nChange-Id: I5a2e8ec6bb0ca988e31c21cbd4e514f83bfd5ba0\n'}]",0,38280,6e275e2f23e303705478021a2f53cef9fde6752e,6,3,2,741,,,0,"Remove unnecessary default criterion value

Change-Id: I5a2e8ec6bb0ca988e31c21cbd4e514f83bfd5ba0
",git fetch https://review.opendev.org/openstack/designate refs/changes/80/38280/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/central/service.py'],1,cda80d9a7d8330f0f488cc576855d537af9487b5,,, if criterion is None: criterion = {} ,0,3
openstack%2Fdesignate~master~Ic4724c2aed8a2bcaa3409998c7d23c5c3855f975,openstack/designate,master,Ic4724c2aed8a2bcaa3409998c7d23c5c3855f975,find_record should take a domain_id argument,MERGED,2013-07-23 10:36:51.000000000,2013-07-23 12:29:18.000000000,2013-07-23 12:29:18.000000000,"[{'_account_id': 3}, {'_account_id': 741}]","[{'number': 1, 'created': '2013-07-23 10:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/2514cd6719779d0e4057c7e71b1ec3701a151ab1', 'message': ""find_record should take a domain_id argument\n\nThis allows us to use domain['tenant_id'] rather than context.is_admin\nfor privilege checks.\n\nChange-Id: Ic4724c2aed8a2bcaa3409998c7d23c5c3855f975\n""}, {'number': 2, 'created': '2013-07-23 10:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/0d22a995578c5ab7ef7924222dfb46d09dc38e4c', 'message': ""find_record should take a domain_id argument\n\nThis allows us to use domain['tenant_id'] rather than context.is_admin\nfor privilege checks.\n\nChange-Id: Ic4724c2aed8a2bcaa3409998c7d23c5c3855f975\n""}, {'number': 3, 'created': '2013-07-23 10:48:19.000000000', 'files': ['designate/storage/api.py', 'designate/tests/test_storage/test_api.py', 'designate/central/rpcapi.py', 'designate/tests/test_storage/__init__.py', 'designate/central/service.py', 'designate/storage/impl_sqlalchemy/__init__.py', 'designate/storage/base.py', 'designate/tests/test_central/test_service.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/306967c57ad310da3699cb934552115b25a285f9', 'message': ""find_record should take a domain_id argument\n\nThis allows us to use domain['tenant_id'] rather than context.is_admin\nfor privilege checks.\n\nChange-Id: Ic4724c2aed8a2bcaa3409998c7d23c5c3855f975\n""}]",0,38279,306967c57ad310da3699cb934552115b25a285f9,9,2,3,741,,,0,"find_record should take a domain_id argument

This allows us to use domain['tenant_id'] rather than context.is_admin
for privilege checks.

Change-Id: Ic4724c2aed8a2bcaa3409998c7d23c5c3855f975
",git fetch https://review.opendev.org/openstack/designate refs/changes/79/38279/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/storage/api.py', 'designate/tests/test_storage/test_api.py', 'designate/central/rpcapi.py', 'designate/tests/test_storage/__init__.py', 'designate/central/service.py', 'designate/storage/impl_sqlalchemy/__init__.py', 'designate/context.py', 'designate/storage/base.py', 'designate/tests/test_central/test_service.py']",9,2514cd6719779d0e4057c7e71b1ec3701a151ab1,," record = self.central_service.find_record(context, domain['id'], criterion)"," record = self.central_service.find_record(context, criterion)",35,30
openstack%2Fdesignate~master~I14cbc8a334dca5b5106d672b68ac355fd0e54080,openstack/designate,master,I14cbc8a334dca5b5106d672b68ac355fd0e54080,find_records does not need to perform an is_admin check,MERGED,2013-07-23 10:34:07.000000000,2013-07-23 12:28:54.000000000,2013-07-23 12:28:53.000000000,"[{'_account_id': 3}, {'_account_id': 741}]","[{'number': 1, 'created': '2013-07-23 10:34:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/670a3fdef905a7a445eeb4433dc41334492b73d2', 'message': 'find_records does not need to perform an is_admin check.\n\nFixes bug #1203804\n\nChange-Id: I14cbc8a334dca5b5106d672b68ac355fd0e54080\n'}, {'number': 2, 'created': '2013-07-23 10:48:19.000000000', 'files': ['designate/central/service.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/b4a08ae048f360a11b430bdc80dc6d68908af7e1', 'message': 'find_records does not need to perform an is_admin check\n\nFixes bug #1203804\n\nChange-Id: I14cbc8a334dca5b5106d672b68ac355fd0e54080\n'}]",0,38278,b4a08ae048f360a11b430bdc80dc6d68908af7e1,8,2,2,741,,,0,"find_records does not need to perform an is_admin check

Fixes bug #1203804

Change-Id: I14cbc8a334dca5b5106d672b68ac355fd0e54080
",git fetch https://review.opendev.org/openstack/designate refs/changes/78/38278/2 && git format-patch -1 --stdout FETCH_HEAD,['designate/central/service.py'],1,670a3fdef905a7a445eeb4433dc41334492b73d2,bug/1203804,, if not context.is_admin: criterion['tenant_id'] = context.tenant_id ,0,3
openstack%2Fnova~master~I018e29ba46f2017241c13742169896625944194e,openstack/nova,master,I018e29ba46f2017241c13742169896625944194e,Add indexes to sqlite,MERGED,2013-06-19 08:10:10.000000000,2013-07-23 12:13:07.000000000,2013-07-23 12:13:05.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5174}, {'_account_id': 5652}, {'_account_id': 6849}, {'_account_id': 7491}]","[{'number': 1, 'created': '2013-06-19 08:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a6869e0a4fc4d99f367bf9c6a2bc4bdf6674f0e', 'message': 'Add indexes to sqlite\n\nMigration `133_folsom.py` do not create indexes for sqlite.\n\nFixes bug 1191838\n\nChange-Id: I018e29ba46f2017241c13742169896625944194e\n'}, {'number': 2, 'created': '2013-06-20 15:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9876d4c275a01421bf3386cfaf4be5706955f650', 'message': 'Add indexes to sqlite\n\nMigration `133_folsom.py` do not create indexes for sqlite.\n\nFixes bug 1191838\n\nChange-Id: I018e29ba46f2017241c13742169896625944194e\n'}, {'number': 3, 'created': '2013-06-27 08:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/642aeb55aef1a87571e0bfb4e9a89445b8afe1dd', 'message': 'Add indexes to sqlite\n\nMigration `133_folsom.py` do not create indexes for sqlite.\n\nFixes bug 1191838\n\nChange-Id: I018e29ba46f2017241c13742169896625944194e\n'}, {'number': 4, 'created': '2013-07-08 09:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b3e071add2982d4bd4b478c614408c72bda111f', 'message': 'Add indexes to sqlite\n\nMigration `133_folsom.py` do not create indexes for sqlite.\n\nFixes bug 1191838\n\nChange-Id: I018e29ba46f2017241c13742169896625944194e\n'}, {'number': 5, 'created': '2013-07-08 09:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d709428a821fa92e50b30d59dc332d15154e1c50', 'message': 'Add indexes to sqlite\n\nMigration `133_folsom.py` do not create indexes for sqlite.\n\nFixes bug 1191838\n\nChange-Id: I018e29ba46f2017241c13742169896625944194e\n'}, {'number': 6, 'created': '2013-07-12 13:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/94f5d2bf5919e2f18282cdd3c73105fff1fe2cf1', 'message': 'Add indexes to sqlite\n\nMigration `133_folsom.py` do not create indexes for sqlite.\n\nFixes bug 1191838\n\nChange-Id: I018e29ba46f2017241c13742169896625944194e\n'}, {'number': 7, 'created': '2013-07-15 09:04:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84b95c8e0f3d0c5fb246d117ea9ce6ddca4ceae8', 'message': 'Add indexes to sqlite\n\nMigration `133_folsom.py` do not create indexes for sqlite.\n\nFixes bug 1191838\n\nChange-Id: I018e29ba46f2017241c13742169896625944194e\n'}, {'number': 8, 'created': '2013-07-19 12:08:36.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/versions/201_add_sqlite_indexes.py', 'nova/tests/db/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8f4a7e298bcb6bc1f0332309497a5c3ae7fd1c7e', 'message': 'Add indexes to sqlite\n\nMigration `133_folsom.py` do not create indexes for sqlite.\nAdded missed indexes with tests.\n\nFixes bug 1191838\n\nChange-Id: I018e29ba46f2017241c13742169896625944194e\n'}]",6,33608,8f4a7e298bcb6bc1f0332309497a5c3ae7fd1c7e,53,9,8,7491,,,0,"Add indexes to sqlite

Migration `133_folsom.py` do not create indexes for sqlite.
Added missed indexes with tests.

Fixes bug 1191838

Change-Id: I018e29ba46f2017241c13742169896625944194e
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/33608/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/migrate_repo/versions/190_add_sqlite_indexes.py', 'nova/tests/db/test_migrations.py']",2,7a6869e0a4fc4d99f367bf9c6a2bc4bdf6674f0e,bug/1191838," def _check_190(self, engine, data): if engine.name != 'sqlite': return data = { # table_name: ((idx_1, (c1, c2,)), (idx2, (c1, c2,)), ...) 'agent_builds': ( ('agent_builds_hypervisor_os_arch_idx', ('hypervisor', 'os', 'architecture'),), ), 'aggregate_metadata': ( ('aggregate_metadata_key_idx', ('key',),), ), 'block_device_mapping': ( ('block_device_mapping_instance_uuid_idx', ('instance_uuid',),), ('block_device_mapping_instance_uuid_device_name_idx', ('instance_uuid', 'device_name',),), ('block_device_mapping_instance_uuid_volume_id_idx', ('instance_uuid', 'volume_id',)), ('snapshot_id', ('snapshot_id',)), ('volume_id', ('volume_id',)), ), 'bw_usage_cache': ( ('bw_usage_cache_uuid_start_period_idx', ('uuid', 'start_period',)), ), 'certificates': ( ('certificates_project_id_deleted_idx', ('project_id', 'deleted',)), ('certificates_user_id_deleted_idx', ('user_id', 'deleted',)), ), 'compute_node_stats': ( ('ix_compute_node_stats_compute_node_id', ('compute_node_id',)), ), 'consoles': ( ('consoles_instance_uuid_idx', ('instance_uuid',)), ), 'dns_domains': ( ('dns_domains_domain_deleted_idx', ('domain', 'deleted',)), ('project_id', ('project_id',)), ), 'fixed_ips': ( ('address', ('address',)), ('fixed_ips_host_idx', ('host',)), ('fixed_ips_network_id_host_deleted_idx', ('network_id', 'host', 'deleted',)), ('fixed_ips_address_reserved_network_id_deleted_idx', ('address', 'reserved', 'network_id', 'deleted',)), ('network_id', ('network_id',)), ('fixed_ips_virtual_interface_id_fkey', ('virtual_interface_id',)), ('fixed_ips_instance_uuid_fkey', ('instance_uuid',)), ), 'floating_ips': ( ('fixed_ip_id', ('fixed_ip_id',)), ('floating_ips_host_idx', ('host',)), ('floating_ips_project_id_idx', ('project_id',)), ('floating_ips_pool_deleted_fixed_ip_id_project_id_idx', ('pool', 'deleted', 'fixed_ip_id', 'project_id',)), ), 'instance_group_member': ( ('instance_group_member_instance_idx', ('instance_id',)), ), 'instance_group_metadata': ( ('instance_instance_group_metadata_key_idx', ('key',)), ), 'instance_group_policy': ( ('instance_instance_group_policy_policy_idx', ('policy',)), ), 'instance_faults': ( ('instance_faults_instance_uuid_deleted_created_at_idx', ('instance_uuid', 'deleted', 'created_at',)), ), 'instance_id_mappings': ( ('ix_instance_id_mappings_uuid', ('uuid',)), ), 'instance_type_extra_specs': ( ('instance_type_extra_specs_instance_type_id_key_idx', ('instance_type_id', 'key',)), ), 'instance_system_metadata': ( ('instance_uuid', ('instance_uuid',)), ), 'instance_metadata': ( ('instance_metadata_instance_uuid_idx', ('instance_uuid',)), ), 'instance_type_projects': ( ('instance_type_id', ('instance_type_id',)), ), 'instances': ( ('uuid', ('uuid',)), ), 'iscsi_targets': ( ('iscsi_targets_host_idx', ('host',)), ('iscsi_targets_volume_id_fkey', ('volume_id',)), ('iscsi_targets_host_volume_id_deleted_idx', ('host', 'volume_id', 'deleted',)), ), 'networks': ( ('networks_bridge_deleted_idx', ('bridge', 'deleted',)), ('networks_host_idx', ('host',)), ('networks_project_id_deleted_idx', ('project_id', 'deleted',)), ('networks_uuid_project_id_deleted_idx', ('uuid', 'project_id', 'deleted',)), ('networks_vlan_deleted_idx', ('vlan', 'deleted',)), ('networks_cidr_v6_idx', ('cidr_v6',)), ), 'reservations': ( ('ix_reservations_project_id', ('project_id',)), ('usage_id', ('usage_id',)), ), 'security_group_instance_association': ( ('security_group_instance_association_instance_uuid_idx', ('instance_uuid',)), ), 'quota_classes': ( ('ix_quota_classes_class_name', ('class_name',)), ), 'quota_usages': ( ('ix_quota_usages_project_id', ('project_id',)), ), 'sm_volume': ( ('backend_id', ('backend_id',)), ), 'virtual_interfaces': ( ('virtual_interfaces_network_id_idx', ('network_id',)), ('virtual_interfaces_instance_uuid_fkey', ('instance_uuid',)), ), 'volume_metadata': ( ('volume_metadata_volume_id_fkey', ('volume_id',)), ), 'volumes': ( ('volumes_instance_uuid_idx', ('instance_uuid',)), ), 'task_log': ( ('ix_task_log_period_beginning', ('period_beginning',)), ('ix_task_log_host', ('host',)), ('ix_task_log_period_ending', ('period_ending',)), ), } meta = sqlalchemy.MetaData() meta.bind = engine for table_name in data: table = sqlalchemy.Table(table_name, meta, autoload=True) indexes = [(i.name, tuple(i.columns.keys())) for i in table.indexes] for index in data[table_name]: self.assertIn(index, indexes) ",,395,0
openstack%2Fswift~master~Ic12b5a916bc89ae8d4480879723201c1715285af,openstack/swift,master,Ic12b5a916bc89ae8d4480879723201c1715285af,fix unit tests in 2.6 by using closing(GzipFile),MERGED,2013-07-23 04:13:51.000000000,2013-07-23 10:29:57.000000000,2013-07-23 10:29:57.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-23 04:13:51.000000000', 'files': ['test/unit/proxy/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/13bbe4b7c31b17efbebd91bd01586757600a082b', 'message': ""fix unit tests in 2.6 by using closing(GzipFile)\n\nPython 2.6 doesn't support using GzipFile as a context manager.\n\nChange-Id: Ic12b5a916bc89ae8d4480879723201c1715285af\n""}]",0,38250,13bbe4b7c31b17efbebd91bd01586757600a082b,8,5,1,2828,,,0,"fix unit tests in 2.6 by using closing(GzipFile)

Python 2.6 doesn't support using GzipFile as a context manager.

Change-Id: Ic12b5a916bc89ae8d4480879723201c1715285af
",git fetch https://review.opendev.org/openstack/swift refs/changes/50/38250/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/proxy/test_server.py'],1,13bbe4b7c31b17efbebd91bd01586757600a082b,fixtests,"from contextlib import contextmanager, nested, closing with closing(GzipFile(os.path.join(_testdir, 'account.ring.gz'), 'wb')) \ as f: with closing(GzipFile(os.path.join(_testdir, 'container.ring.gz'), 'wb')) \ as f: with closing(GzipFile(os.path.join(_testdir, 'object.ring.gz'), 'wb')) \ as f:","from contextlib import contextmanager, nested with GzipFile(os.path.join(_testdir, 'account.ring.gz'), 'wb') as f: with GzipFile(os.path.join(_testdir, 'container.ring.gz'), 'wb') as f: with GzipFile(os.path.join(_testdir, 'object.ring.gz'), 'wb') as f:",7,4
openstack%2Fnova~master~I47d1a883529b61d4bc5bc07e137dc421bfcb7512,openstack/nova,master,I47d1a883529b61d4bc5bc07e137dc421bfcb7512,Move nova.quota to oslo,ABANDONED,2013-06-25 14:46:40.000000000,2013-07-23 10:20:20.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-06-25 14:46:40.000000000', 'files': ['nova/tests/compute/test_compute_cells.py', 'nova/tests/test_quota.py', 'nova/quota.py', 'nova/openstack/common/quota.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c0416d5f1a3d128d67f8dc6e1ef3d451df21b812', 'message': 'Move nova.quota to oslo\n\nMove common code from nova.quota to oslo\n\nwork-in-progress\n\nChange-Id: I47d1a883529b61d4bc5bc07e137dc421bfcb7512\nblueprint: common-quota\n'}]",0,34413,c0416d5f1a3d128d67f8dc6e1ef3d451df21b812,4,2,1,7369,,,0,"Move nova.quota to oslo

Move common code from nova.quota to oslo

work-in-progress

Change-Id: I47d1a883529b61d4bc5bc07e137dc421bfcb7512
blueprint: common-quota
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/34413/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_cells.py', 'nova/tests/test_quota.py', 'nova/quota.py', 'nova/openstack/common/quota.py']",4,c0416d5f1a3d128d67f8dc6e1ef3d451df21b812,bp/common-quota,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2010 United States Government as represented by the # Administrator of the National Aeronautics and Space Administration. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Quotas for instances, and floating ips."""""" import datetime from oslo.config import cfg from nova import db from nova import exception from nova.openstack.common import importutils from nova.openstack.common import log as logging from nova.openstack.common import timeutils LOG = logging.getLogger(__name__) CONF = cfg.CONF class DbQuotaDriver(object): """""" Driver to perform necessary checks to enforce quotas and obtain quota information. The default driver utilizes the local database. """""" def get_by_project(self, context, project_id, resource): """"""Get a specific quota by project."""""" return db.quota_get(context, project_id, resource) def get_by_class(self, context, quota_class, resource): """"""Get a specific quota by quota class."""""" return db.quota_class_get(context, quota_class, resource) def get_defaults(self, context, resources): """"""Given a list of resources, retrieve the default quotas. Use the class quotas named `_DEFAULT_QUOTA_NAME` as default quotas, if it exists. :param context: The request context, for access checks. :param resources: A dictionary of the registered resources. """""" quotas = {} default_quotas = db.quota_class_get_default(context) for resource in resources.values(): quotas[resource.name] = default_quotas.get(resource.name, resource.default) return quotas def get_class_quotas(self, context, resources, quota_class, defaults=True): """""" Given a list of resources, retrieve the quotas for the given quota class. :param context: The request context, for access checks. :param resources: A dictionary of the registered resources. :param quota_class: The name of the quota class to return quotas for. :param defaults: If True, the default value will be reported if there is no specific value for the resource. """""" quotas = {} class_quotas = db.quota_class_get_all_by_name(context, quota_class) for resource in resources.values(): if defaults or resource.name in class_quotas: quotas[resource.name] = class_quotas.get(resource.name, resource.default) return quotas def get_project_quotas(self, context, resources, project_id, quota_class=None, defaults=True, usages=True): """""" Given a list of resources, retrieve the quotas for the given project. :param context: The request context, for access checks. :param resources: A dictionary of the registered resources. :param project_id: The ID of the project to return quotas for. :param quota_class: If project_id != context.project_id, the quota class cannot be determined. This parameter allows it to be specified. It will be ignored if project_id == context.project_id. :param defaults: If True, the quota class value (or the default value, if there is no value from the quota class) will be reported if there is no specific value for the resource. :param usages: If True, the current in_use and reserved counts will also be returned. """""" quotas = {} project_quotas = db.quota_get_all_by_project(context, project_id) if usages: project_usages = db.quota_usage_get_all_by_project(context, project_id) # Get the quotas for the appropriate class. If the project ID # matches the one in the context, we use the quota_class from # the context, otherwise, we use the provided quota_class (if # any) if project_id == context.project_id: quota_class = context.quota_class if quota_class: class_quotas = db.quota_class_get_all_by_name(context, quota_class) else: class_quotas = {} default_quotas = self.get_defaults(context, resources) for resource in resources.values(): # Omit default/quota class values if not defaults and resource.name not in project_quotas: continue quotas[resource.name] = dict( limit=project_quotas.get(resource.name, class_quotas.get( resource.name, default_quotas[resource.name])), ) # Include usages if desired. This is optional because one # internal consumer of this interface wants to access the # usages directly from inside a transaction. if usages: usage = project_usages.get(resource.name, {}) quotas[resource.name].update( in_use=usage.get('in_use', 0), reserved=usage.get('reserved', 0), ) return quotas def _get_quotas(self, context, resources, keys, has_sync, project_id=None): """""" A helper method which retrieves the quotas for the specific resources identified by keys, and which apply to the current context. :param context: The request context, for access checks. :param resources: A dictionary of the registered resources. :param keys: A list of the desired quotas to retrieve. :param has_sync: If True, indicates that the resource must have a sync function; if False, indicates that the resource must NOT have a sync function. :param project_id: Specify the project_id if current context is admin and admin wants to impact on common user's tenant. """""" # Filter resources if has_sync: sync_filt = lambda x: hasattr(x, 'sync') else: sync_filt = lambda x: not hasattr(x, 'sync') desired = set(keys) sub_resources = dict((k, v) for k, v in resources.items() if k in desired and sync_filt(v)) # Make sure we accounted for all of them... if len(keys) != len(sub_resources): unknown = desired - set(sub_resources.keys()) raise exception.QuotaResourceUnknown(unknown=sorted(unknown)) # Grab and return the quotas (without usages) quotas = self.get_project_quotas(context, sub_resources, project_id, context.quota_class, usages=False) return dict((k, v['limit']) for k, v in quotas.items()) def limit_check(self, context, resources, values, project_id=None): """"""Check simple quota limits. For limits--those quotas for which there is no usage synchronization function--this method checks that a set of proposed values are permitted by the limit restriction. This method will raise a QuotaResourceUnknown exception if a given resource is unknown or if it is not a simple limit resource. If any of the proposed values is over the defined quota, an OverQuota exception will be raised with the sorted list of the resources which are too high. Otherwise, the method returns nothing. :param context: The request context, for access checks. :param resources: A dictionary of the registered resources. :param values: A dictionary of the values to check against the quota. :param project_id: Specify the project_id if current context is admin and admin wants to impact on common user's tenant. """""" # Ensure no value is less than zero unders = [key for key, val in values.items() if val < 0] if unders: raise exception.InvalidQuotaValue(unders=sorted(unders)) # If project_id is None, then we use the project_id in context if project_id is None: project_id = context.project_id # Get the applicable quotas quotas = self._get_quotas(context, resources, values.keys(), has_sync=False, project_id=project_id) # Check the quotas and construct a list of the resources that # would be put over limit by the desired values overs = [key for key, val in values.items() if quotas[key] >= 0 and quotas[key] < val] if overs: raise exception.OverQuota(overs=sorted(overs), quotas=quotas, usages={}) def reserve(self, context, resources, deltas, expire=None, project_id=None): """"""Check quotas and reserve resources. For counting quotas--those quotas for which there is a usage synchronization function--this method checks quotas against current usage and the desired deltas. This method will raise a QuotaResourceUnknown exception if a given resource is unknown or if it does not have a usage synchronization function. If any of the proposed values is over the defined quota, an OverQuota exception will be raised with the sorted list of the resources which are too high. Otherwise, the method returns a list of reservation UUIDs which were created. :param context: The request context, for access checks. :param resources: A dictionary of the registered resources. :param deltas: A dictionary of the proposed delta changes. :param expire: An optional parameter specifying an expiration time for the reservations. If it is a simple number, it is interpreted as a number of seconds and added to the current time; if it is a datetime.timedelta object, it will also be added to the current time. A datetime.datetime object will be interpreted as the absolute expiration time. If None is specified, the default expiration time set by --default-reservation-expire will be used (this value will be treated as a number of seconds). :param project_id: Specify the project_id if current context is admin and admin wants to impact on common user's tenant. """""" # Set up the reservation expiration if expire is None: expire = CONF.reservation_expire if isinstance(expire, (int, long)): expire = datetime.timedelta(seconds=expire) if isinstance(expire, datetime.timedelta): expire = timeutils.utcnow() + expire if not isinstance(expire, datetime.datetime): raise exception.InvalidReservationExpiration(expire=expire) # If project_id is None, then we use the project_id in context if project_id is None: project_id = context.project_id # Get the applicable quotas. # NOTE(Vek): We're not worried about races at this point. # Yes, the admin may be in the process of reducing # quotas, but that's a pretty rare thing. quotas = self._get_quotas(context, resources, deltas.keys(), has_sync=True, project_id=project_id) # NOTE(Vek): Most of the work here has to be done in the DB # API, because we have to do it in a transaction, # which means access to the session. Since the # session isn't available outside the DBAPI, we # have to do the work there. return db.quota_reserve(context, resources, quotas, deltas, expire, CONF.until_refresh, CONF.max_age, project_id=project_id) def commit(self, context, reservations, project_id=None): """"""Commit reservations. :param context: The request context, for access checks. :param reservations: A list of the reservation UUIDs, as returned by the reserve() method. :param project_id: Specify the project_id if current context is admin and admin wants to impact on common user's tenant. """""" # If project_id is None, then we use the project_id in context if project_id is None: project_id = context.project_id db.reservation_commit(context, reservations, project_id=project_id) def rollback(self, context, reservations, project_id=None): """"""Roll back reservations. :param context: The request context, for access checks. :param reservations: A list of the reservation UUIDs, as returned by the reserve() method. :param project_id: Specify the project_id if current context is admin and admin wants to impact on common user's tenant. """""" # If project_id is None, then we use the project_id in context if project_id is None: project_id = context.project_id db.reservation_rollback(context, reservations, project_id=project_id) def usage_reset(self, context, resources): """""" Reset the usage records for a particular user on a list of resources. This will force that user's usage records to be refreshed the next time a reservation is made. Note: this does not affect the currently outstanding reservations the user has; those reservations must be committed or rolled back (or expired). :param context: The request context, for access checks. :param resources: A list of the resource names for which the usage must be reset. """""" # We need an elevated context for the calls to # quota_usage_update() elevated = context.elevated() for resource in resources: try: # Reset the usage to -1, which will force it to be # refreshed db.quota_usage_update(elevated, context.project_id, resource, in_use=-1) except exception.QuotaUsageNotFound: # That means it'll be refreshed anyway pass def destroy_all_by_project(self, context, project_id): """""" Destroy all quotas, usages, and reservations associated with a project. :param context: The request context, for access checks. :param project_id: The ID of the project being deleted. """""" db.quota_destroy_all_by_project(context, project_id) def expire(self, context): """"""Expire reservations. Explores all currently existing reservations and rolls back any that have expired. :param context: The request context, for access checks. """""" db.reservation_expire(context) class NoopQuotaDriver(object): """"""Driver that turns quotas calls into no-ops and pretends that quotas for all resources are unlimited. This can be used if you do not wish to have any quota checking. For instance, with nova compute cells, the parent cell should do quota checking, but the child cell should not. """""" def get_by_project(self, context, project_id, resource): """"""Get a specific quota by project."""""" # Unlimited return -1 def get_by_class(self, context, quota_class, resource): """"""Get a specific quota by quota class."""""" # Unlimited return -1 def get_defaults(self, context, resources): """"""Given a list of resources, retrieve the default quotas. :param context: The request context, for access checks. :param resources: A dictionary of the registered resources. """""" quotas = {} for resource in resources.values(): quotas[resource.name] = -1 return quotas def get_class_quotas(self, context, resources, quota_class, defaults=True): """""" Given a list of resources, retrieve the quotas for the given quota class. :param context: The request context, for access checks. :param resources: A dictionary of the registered resources. :param quota_class: The name of the quota class to return quotas for. :param defaults: If True, the default value will be reported if there is no specific value for the resource. """""" quotas = {} for resource in resources.values(): quotas[resource.name] = -1 return quotas def get_project_quotas(self, context, resources, project_id, quota_class=None, defaults=True, usages=True): """""" Given a list of resources, retrieve the quotas for the given project. :param context: The request context, for access checks. :param resources: A dictionary of the registered resources. :param project_id: The ID of the project to return quotas for. :param quota_class: If project_id != context.project_id, the quota class cannot be determined. This parameter allows it to be specified. It will be ignored if project_id == context.project_id. :param defaults: If True, the quota class value (or the default value, if there is no value from the quota class) will be reported if there is no specific value for the resource. :param usages: If True, the current in_use and reserved counts will also be returned. """""" quotas = {} for resource in resources.values(): quotas[resource.name] = -1 return quotas def limit_check(self, context, resources, values, project_id=None): """"""Check simple quota limits. For limits--those quotas for which there is no usage synchronization function--this method checks that a set of proposed values are permitted by the limit restriction. This method will raise a QuotaResourceUnknown exception if a given resource is unknown or if it is not a simple limit resource. If any of the proposed values is over the defined quota, an OverQuota exception will be raised with the sorted list of the resources which are too high. Otherwise, the method returns nothing. :param context: The request context, for access checks. :param resources: A dictionary of the registered resources. :param values: A dictionary of the values to check against the quota. :param project_id: Specify the project_id if current context is admin and admin wants to impact on common user's tenant. """""" pass def reserve(self, context, resources, deltas, expire=None, project_id=None): """"""Check quotas and reserve resources. For counting quotas--those quotas for which there is a usage synchronization function--this method checks quotas against current usage and the desired deltas. This method will raise a QuotaResourceUnknown exception if a given resource is unknown or if it does not have a usage synchronization function. If any of the proposed values is over the defined quota, an OverQuota exception will be raised with the sorted list of the resources which are too high. Otherwise, the method returns a list of reservation UUIDs which were created. :param context: The request context, for access checks. :param resources: A dictionary of the registered resources. :param deltas: A dictionary of the proposed delta changes. :param expire: An optional parameter specifying an expiration time for the reservations. If it is a simple number, it is interpreted as a number of seconds and added to the current time; if it is a datetime.timedelta object, it will also be added to the current time. A datetime.datetime object will be interpreted as the absolute expiration time. If None is specified, the default expiration time set by --default-reservation-expire will be used (this value will be treated as a number of seconds). :param project_id: Specify the project_id if current context is admin and admin wants to impact on common user's tenant. """""" return [] def commit(self, context, reservations, project_id=None): """"""Commit reservations. :param context: The request context, for access checks. :param reservations: A list of the reservation UUIDs, as returned by the reserve() method. :param project_id: Specify the project_id if current context is admin and admin wants to impact on common user's tenant. """""" pass def rollback(self, context, reservations, project_id=None): """"""Roll back reservations. :param context: The request context, for access checks. :param reservations: A list of the reservation UUIDs, as returned by the reserve() method. :param project_id: Specify the project_id if current context is admin and admin wants to impact on common user's tenant. """""" pass def usage_reset(self, context, resources): """""" Reset the usage records for a particular user on a list of resources. This will force that user's usage records to be refreshed the next time a reservation is made. Note: this does not affect the currently outstanding reservations the user has; those reservations must be committed or rolled back (or expired). :param context: The request context, for access checks. :param resources: A list of the resource names for which the usage must be reset. """""" pass def destroy_all_by_project(self, context, project_id): """""" Destroy all quotas, usages, and reservations associated with a project. :param context: The request context, for access checks. :param project_id: The ID of the project being deleted. """""" pass def expire(self, context): """"""Expire reservations. Explores all currently existing reservations and rolls back any that have expired. :param context: The request context, for access checks. """""" pass class BaseResource(object): """"""Describe a single resource for quota checking."""""" def __init__(self, name, flag=None): """""" Initializes a Resource. :param name: The name of the resource, i.e., ""instances"". :param flag: The name of the flag or configuration option which specifies the default value of the quota for this resource. """""" self.name = name self.flag = flag def quota(self, driver, context, **kwargs): """""" Given a driver and context, obtain the quota for this resource. :param driver: A quota driver. :param context: The request context. :param project_id: The project to obtain the quota value for. If not provided, it is taken from the context. If it is given as None, no project-specific quota will be searched for. :param quota_class: The quota class corresponding to the project, or for which the quota is to be looked up. If not provided, it is taken from the context. If it is given as None, no quota class-specific quota will be searched for. Note that the quota class defaults to the value in the context, which may not correspond to the project if project_id is not the same as the one in the context. """""" # Get the project ID project_id = kwargs.get('project_id', context.project_id) # Ditto for the quota class quota_class = kwargs.get('quota_class', context.quota_class) # Look up the quota for the project if project_id: try: return driver.get_by_project(context, project_id, self.name) except exception.ProjectQuotaNotFound: pass # Try for the quota class if quota_class: try: return driver.get_by_class(context, quota_class, self.name) except exception.QuotaClassNotFound: pass # OK, return the default return self.default @property def default(self): """"""Return the default value of the quota."""""" return CONF[self.flag] if self.flag else -1 class ReservableResource(BaseResource): """"""Describe a reservable resource."""""" sync = True def __init__(self, name, flag=None): """"""Initializes a ReservableResource. Reservable resources are those resources which directly correspond to objects in the database, i.e., instances, cores, etc. Usage synchronization function must be associated with each object. This function will be called to determine the current counts of one or more resources. This association is done in database backend. See QUOTA_SYNC_FUNCTIONS in db/sqlalchemy/api.py. The usage synchronization function will be passed three arguments: an admin context, the project ID, and an opaque session object, which should in turn be passed to the underlying database function. Synchronization functions should return a dictionary mapping resource names to the current in_use count for those resources; more than one resource and resource count may be returned. Note that synchronization functions may be associated with more than one ReservableResource. :param name: The name of the resource, i.e., ""instances"". This name is also key for QUOTA_SYNC_FUNCTIONS. :param flag: The name of the flag or configuration option which specifies the default value of the quota for this resource. """""" super(ReservableResource, self).__init__(name, flag=flag) class AbsoluteResource(BaseResource): """"""Describe a non-reservable resource."""""" pass class CountableResource(AbsoluteResource): """""" Describe a resource where the counts aren't based solely on the project ID. """""" def __init__(self, name, count, flag=None): """""" Initializes a CountableResource. Countable resources are those resources which directly correspond to objects in the database, i.e., instances, cores, etc., but for which a count by project ID is inappropriate. A CountableResource must be constructed with a counting function, which will be called to determine the current counts of the resource. The counting function will be passed the context, along with the extra positional and keyword arguments that are passed to Quota.count(). It should return an integer specifying the count. Note that this counting is not performed in a transaction-safe manner. This resource class is a temporary measure to provide required functionality, until a better approach to solving this problem can be evolved. :param name: The name of the resource, i.e., ""instances"". :param count: A callable which returns the count of the resource. The arguments passed are as described above. :param flag: The name of the flag or configuration option which specifies the default value of the quota for this resource. """""" super(CountableResource, self).__init__(name, flag=flag) self.count = count class QuotaEngine(object): """"""Represent the set of recognized quotas."""""" def __init__(self, quota_driver_class=None): """"""Initialize a Quota object."""""" self._resources = {} self._driver_cls = quota_driver_class self.__driver = None @property def _driver(self): if self.__driver: return self.__driver if not self._driver_cls: self._driver_cls = CONF.quota_driver if isinstance(self._driver_cls, basestring): self._driver_cls = importutils.import_object(self._driver_cls) self.__driver = self._driver_cls return self.__driver def __contains__(self, resource): return resource in self._resources def register_resource(self, resource): """"""Register a resource."""""" self._resources[resource.name] = resource def register_resources(self, resources): """"""Register a list of resources."""""" for resource in resources: self.register_resource(resource) def get_by_project(self, context, project_id, resource): """"""Get a specific quota by project."""""" return self._driver.get_by_project(context, project_id, resource) def get_by_class(self, context, quota_class, resource): """"""Get a specific quota by quota class."""""" return self._driver.get_by_class(context, quota_class, resource) def get_defaults(self, context): """"""Retrieve the default quotas. :param context: The request context, for access checks. """""" return self._driver.get_defaults(context, self._resources) def get_class_quotas(self, context, quota_class, defaults=True): """"""Retrieve the quotas for the given quota class. :param context: The request context, for access checks. :param quota_class: The name of the quota class to return quotas for. :param defaults: If True, the default value will be reported if there is no specific value for the resource. """""" return self._driver.get_class_quotas(context, self._resources, quota_class, defaults=defaults) def get_project_quotas(self, context, project_id, quota_class=None, defaults=True, usages=True): """"""Retrieve the quotas for the given project. :param context: The request context, for access checks. :param project_id: The ID of the project to return quotas for. :param quota_class: If project_id != context.project_id, the quota class cannot be determined. This parameter allows it to be specified. :param defaults: If True, the quota class value (or the default value, if there is no value from the quota class) will be reported if there is no specific value for the resource. :param usages: If True, the current in_use and reserved counts will also be returned. """""" return self._driver.get_project_quotas(context, self._resources, project_id, quota_class=quota_class, defaults=defaults, usages=usages) def count(self, context, resource, *args, **kwargs): """"""Count a resource. For countable resources, invokes the count() function and returns its result. Arguments following the context and resource are passed directly to the count function declared by the resource. :param context: The request context, for access checks. :param resource: The name of the resource, as a string. """""" # Get the resource res = self._resources.get(resource) if not res or not hasattr(res, 'count'): raise exception.QuotaResourceUnknown(unknown=[resource]) return res.count(context, *args, **kwargs) def limit_check(self, context, project_id=None, **values): """"""Check simple quota limits. For limits--those quotas for which there is no usage synchronization function--this method checks that a set of proposed values are permitted by the limit restriction. The values to check are given as keyword arguments, where the key identifies the specific quota limit to check, and the value is the proposed value. This method will raise a QuotaResourceUnknown exception if a given resource is unknown or if it is not a simple limit resource. If any of the proposed values is over the defined quota, an OverQuota exception will be raised with the sorted list of the resources which are too high. Otherwise, the method returns nothing. :param context: The request context, for access checks. :param project_id: Specify the project_id if current context is admin and admin wants to impact on common user's tenant. """""" return self._driver.limit_check(context, self._resources, values, project_id=project_id) def reserve(self, context, expire=None, project_id=None, **deltas): """"""Check quotas and reserve resources. For counting quotas--those quotas for which there is a usage synchronization function--this method checks quotas against current usage and the desired deltas. The deltas are given as keyword arguments, and current usage and other reservations are factored into the quota check. This method will raise a QuotaResourceUnknown exception if a given resource is unknown or if it does not have a usage synchronization function. If any of the proposed values is over the defined quota, an OverQuota exception will be raised with the sorted list of the resources which are too high. Otherwise, the method returns a list of reservation UUIDs which were created. :param context: The request context, for access checks. :param expire: An optional parameter specifying an expiration time for the reservations. If it is a simple number, it is interpreted as a number of seconds and added to the current time; if it is a datetime.timedelta object, it will also be added to the current time. A datetime.datetime object will be interpreted as the absolute expiration time. If None is specified, the default expiration time set by --default-reservation-expire will be used (this value will be treated as a number of seconds). :param project_id: Specify the project_id if current context is admin and admin wants to impact on common user's tenant. """""" reservations = self._driver.reserve(context, self._resources, deltas, expire=expire, project_id=project_id) LOG.debug(_(""Created reservations %(reservations)s"") % locals()) return reservations def commit(self, context, reservations, project_id=None): """"""Commit reservations. :param context: The request context, for access checks. :param reservations: A list of the reservation UUIDs, as returned by the reserve() method. :param project_id: Specify the project_id if current context is admin and admin wants to impact on common user's tenant. """""" try: self._driver.commit(context, reservations, project_id=project_id) except Exception: # NOTE(Vek): Ignoring exceptions here is safe, because the # usage resynchronization and the reservation expiration # mechanisms will resolve the issue. The exception is # logged, however, because this is less than optimal. LOG.exception(_(""Failed to commit reservations "" ""%(reservations)s"") % locals()) return LOG.debug(_(""Committed reservations %(reservations)s"") % locals()) def rollback(self, context, reservations, project_id=None): """"""Roll back reservations. :param context: The request context, for access checks. :param reservations: A list of the reservation UUIDs, as returned by the reserve() method. :param project_id: Specify the project_id if current context is admin and admin wants to impact on common user's tenant. """""" try: self._driver.rollback(context, reservations, project_id=project_id) except Exception: # NOTE(Vek): Ignoring exceptions here is safe, because the # usage resynchronization and the reservation expiration # mechanisms will resolve the issue. The exception is # logged, however, because this is less than optimal. LOG.exception(_(""Failed to roll back reservations "" ""%(reservations)s"") % locals()) return LOG.debug(_(""Rolled back reservations %(reservations)s"") % locals()) def usage_reset(self, context, resources): """""" Reset the usage records for a particular user on a list of resources. This will force that user's usage records to be refreshed the next time a reservation is made. Note: this does not affect the currently outstanding reservations the user has; those reservations must be committed or rolled back (or expired). :param context: The request context, for access checks. :param resources: A list of the resource names for which the usage must be reset. """""" self._driver.usage_reset(context, resources) def destroy_all_by_project(self, context, project_id): """""" Destroy all quotas, usages, and reservations associated with a project. :param context: The request context, for access checks. :param project_id: The ID of the project being deleted. """""" self._driver.destroy_all_by_project(context, project_id) def expire(self, context): """"""Expire reservations. Explores all currently existing reservations and rolls back any that have expired. :param context: The request context, for access checks. """""" self._driver.expire(context) @property def resources(self): return sorted(self._resources.keys()) ",,1034,999
openstack%2Fpython-neutronclient~master~Ia6f498b9a9b189404fe08cacf6ab09ad34e217e8,openstack/python-neutronclient,master,Ia6f498b9a9b189404fe08cacf6ab09ad34e217e8,Fixes encoding output issues for python-quantumclient.,ABANDONED,2013-07-06 16:06:52.000000000,2013-07-23 10:20:03.000000000,,"[{'_account_id': 3}, {'_account_id': 447}, {'_account_id': 841}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 5754}, {'_account_id': 5950}, {'_account_id': 6983}, {'_account_id': 7138}, {'_account_id': 7620}, {'_account_id': 8106}]","[{'number': 1, 'created': '2013-07-06 16:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/007a4347957b078484905a0a19bf2cea984b6054', 'message': 'Fixes encoding output issues for python-quantumclient.\n\n* As per https://wiki.openstack.org/wiki/Encoding.\n\nFixes bug #1189112\n\nChange-Id: Ia6f498b9a9b189404fe08cacf6ab09ad34e217e8\n'}, {'number': 2, 'created': '2013-07-06 16:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/1e0964d8380ecbb3cee2c48ce022079a6d71f661', 'message': 'Fixes encoding output issues for python-quantumclient.\n\n* As per https://wiki.openstack.org/wiki/Encoding.\n\nFixes bug #1189112\n\nChange-Id: Ia6f498b9a9b189404fe08cacf6ab09ad34e217e8\n'}, {'number': 3, 'created': '2013-07-06 16:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/0bd611c043fb1af14014838afa3f08e3260258e4', 'message': 'Fixes encoding output issues for python-quantumclient.\n\nUse strutils.safe_encode() to make sure\nthe encoding output is safe.\nexample: stdout.write(strutils.safe_encode(formatted))\n\n* As per https://wiki.openstack.org/wiki/Encoding.\n\nFixes bug #1189112\n\nChange-Id: Ia6f498b9a9b189404fe08cacf6ab09ad34e217e8\n'}, {'number': 4, 'created': '2013-07-06 16:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/b213ceb5752d50ae9da9ca2303feb11eed353af2', 'message': 'Fixes encoding output issues for python-quantumclient.\n\nUse strutils.safe_encode() to make sure\nthe encoding output is safe.\nexample: stdout.write(strutils.safe_encode(formatted))\n\n* As per https://wiki.openstack.org/wiki/Encoding.\n\nFixes bug #1189112\n\nChange-Id: Ia6f498b9a9b189404fe08cacf6ab09ad34e217e8\n'}, {'number': 5, 'created': '2013-07-06 16:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/da1dff65cd58b383f28149a7042a09652e16ad4f', 'message': 'Fixes encoding output issues for python-quantumclient.\n\nUse strutils.safe_encode() to make sure\nthe encoding output is safe.\nexample: stdout.write(strutils.safe_encode(formatted))\n\n* As per https://wiki.openstack.org/wiki/Encoding.\n\nFixes bug #1189112\n\nChange-Id: Ia6f498b9a9b189404fe08cacf6ab09ad34e217e8\n'}, {'number': 6, 'created': '2013-07-06 16:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/fe7e22c055eff36c03192aace2ffaec66939e989', 'message': 'Fixes encoding output issues for python-quantumclient.\n\nUse strutils.safe_encode() to make sure\nthe encoding output is safe.\nexample: stdout.write(strutils.safe_encode(formatted))\n\n* As per https://wiki.openstack.org/wiki/Encoding.\n\nFixes bug #1189112\n\nChange-Id: Ia6f498b9a9b189404fe08cacf6ab09ad34e217e8\n'}, {'number': 7, 'created': '2013-07-06 16:06:52.000000000', 'files': ['tests/unit/test_cli20.py', 'quantumclient/quantum/v2_0/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c5d20cd9c3528c8ac6462a2913b79ba0e93de7ea', 'message': 'Fixes encoding output issues for python-quantumclient.\n\nUse strutils.safe_encode() to make sure\nthe encoding output is safe.\nexample: stdout.write(strutils.safe_encode(formatted))\n\n* As per https://wiki.openstack.org/wiki/Encoding.\n\nFixes bug #1189112\n\nChange-Id: Ia6f498b9a9b189404fe08cacf6ab09ad34e217e8\n'}]",11,33384,c5d20cd9c3528c8ac6462a2913b79ba0e93de7ea,30,11,7,6983,,,0,"Fixes encoding output issues for python-quantumclient.

Use strutils.safe_encode() to make sure
the encoding output is safe.
example: stdout.write(strutils.safe_encode(formatted))

* As per https://wiki.openstack.org/wiki/Encoding.

Fixes bug #1189112

Change-Id: Ia6f498b9a9b189404fe08cacf6ab09ad34e217e8
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/84/33384/1 && git format-patch -1 --stdout FETCH_HEAD,['quantumclient/quantum/v2_0/__init__.py'],1,007a4347957b078484905a0a19bf2cea984b6054,bug/1189112," x = prettytable.PrettyTable(column_names) x.padding_width = 1 # Figure out the types of the columns in the # first row and set the alignment of the # output accordingly. data_iter = iter(data) try: first_row = next(data_iter) except StopIteration: pass else: for value, name in zip(first_row, column_names): alignment = self.ALIGNMENTS.get(type(value), 'l') x.align[name] = alignment # Now iterate over the data and add the rows. x.add_row(first_row) for row in data_iter: x.add_row(row) formatted = x.get_string(fields=column_names) stdout.write(formatted.encode('utf-8')) stdout.write('\n') def emit_one(self, column_names, data, stdout, parsed_args): x = prettytable.PrettyTable(field_names=('Field', 'Value')) x.padding_width = 1 # Align all columns left because the values are # not all the same type. x.align['Field'] = 'l' x.align['Value'] = 'l' for name, value in zip(column_names, data): x.add_row((name, value)) formatted = x.get_string(fields=('Field', 'Value')) stdout.write(formatted.encode('utf-8')) stdout.write('\n') return "," super(TableFormater, self).emit_list(column_names, data, stdout, parsed_args)",35,2
openstack%2Ftripleo-image-elements~master~If97107556a5b5de7c33049b6a798cc80b75b0cb8,openstack/tripleo-image-elements,master,If97107556a5b5de7c33049b6a798cc80b75b0cb8,Refine regex that converts localip,MERGED,2013-07-23 10:01:32.000000000,2013-07-23 10:01:32.000000000,2013-07-23 10:01:32.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4190}]","[{'number': 2, 'created': '2013-07-23 10:01:32.000000000', 'files': ['elements/heat-localip/os-refresh-config/configure.d/49-heat-localip'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/3482706b3a9e95566f627e7b395f77895ed0a099', 'message': 'Refine regex that converts localip\n\nThe regex is converting 0.0.0.0 to the hosts localip, in most cases this\nwould be ok but on the overcloud in the metadata we have ""ovs_range"":\n""10.0.0.0/8"" which was getting converted to 1192.0.2.5/8.\n\nChange-Id: If97107556a5b5de7c33049b6a798cc80b75b0cb8\n'}, {'number': 1, 'created': '2013-07-23 10:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e3ffa97885f2b9119ba7df5c7fd02da6fad14043', 'message': 'Refine regex that converts localip\n\nThe regex is converting 0.0.0.0 to the hosts localip, in most cases this\nwould be ok but on the overcloud in the metadata we have ""ovs_range"":\n""10.0.0.0/8"" which was getting converted to 1192.0.2.5/8.\n\nChange-Id: If97107556a5b5de7c33049b6a798cc80b75b0cb8\n'}]",2,38269,3482706b3a9e95566f627e7b395f77895ed0a099,9,3,2,1926,,,0,"Refine regex that converts localip

The regex is converting 0.0.0.0 to the hosts localip, in most cases this
would be ok but on the overcloud in the metadata we have ""ovs_range"":
""10.0.0.0/8"" which was getting converted to 1192.0.2.5/8.

Change-Id: If97107556a5b5de7c33049b6a798cc80b75b0cb8
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/69/38269/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/heat-localip/os-refresh-config/configure.d/49-heat-localip'],1,3482706b3a9e95566f627e7b395f77895ed0a099,metadata-fixes," sed -i ""s/\<0\.0\.0\.0\>/$local_ip/g"" $f"," sed -i ""s/0\.0\.0\.0/$local_ip/g"" $f",1,1
openstack%2Fmurano-dashboard~master~I91ecfc7c2463cb9b97dbb813aea67591709cec4b,openstack/murano-dashboard,master,I91ecfc7c2463cb9b97dbb813aea67591709cec4b,Filter selected image by murano_enabled property,MERGED,2013-07-23 09:01:14.000000000,2013-07-23 09:49:32.000000000,2013-07-23 09:49:32.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7821}]","[{'number': 1, 'created': '2013-07-23 09:01:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/a05a31d7dee56dbfd62a6a8e6972c77fd325947d', 'message': 'Filer selected image by murano_enabled property\n\nChange-Id: I91ecfc7c2463cb9b97dbb813aea67591709cec4b\n'}, {'number': 2, 'created': '2013-07-23 09:02:55.000000000', 'files': ['muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/forms.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/847c265095a81ce4f0b4a4fdb30be205e9586307', 'message': 'Filter selected image by murano_enabled property\n\nChange-Id: I91ecfc7c2463cb9b97dbb813aea67591709cec4b\n'}]",0,38266,847c265095a81ce4f0b4a4fdb30be205e9586307,11,4,2,7549,,,0,"Filter selected image by murano_enabled property

Change-Id: I91ecfc7c2463cb9b97dbb813aea67591709cec4b
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/66/38266/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/forms.py']",2,a05a31d7dee56dbfd62a6a8e6972c77fd325947d,,"from openstack_dashboard.api import glance image = forms.ChoiceField(label=_('Instance image'), required=False) try: # public filter removed public_images, _more = glance.image_list_detailed(request) except: public_images = [] exceptions.handle(request, _(""Unable to retrieve public images."")) choices = [(image.id, image.name) for image in public_images if image.properties.get('murano_enabled')] if choices: choices.insert(0, ("""", _(""Select Image""))) else: choices.insert(0, ("""", _(""No images available""))) self.fields['image'].choices = choices az_choices.insert(0, ("""", _(""No availability zone available"")))","# from openstack_dashboard.api import glance # image = forms.ChoiceField(label=_('Instance image'), # required=False) #TODO: uncomment this when custom filter for valid images will # be created # try: # # public filter removed # public_images, _more = glance.image_list_detailed(request) # except: # public_images = [] # exceptions.handle(request, # _(""Unable to retrieve public images."")) # # choices = [(image.id, image.name) # for image in public_images # if image.properties.get(""image_type"", '') != ""snapshot""] # if choices: # choices.insert(0, ("""", _(""Select Image""))) # else: # choices.insert(0, ("""", _(""No images available.""))) # # self.fields['image'].choices = choices az_choices.insert(0, ("""", _(""No availability zone available."")))",33,24
openstack%2Fheat~master~Ide3bbcd2d24f949a2a550fcc2210617f34c8cd0b,openstack/heat,master,Ide3bbcd2d24f949a2a550fcc2210617f34c8cd0b,Use new style classes,MERGED,2013-07-23 01:29:14.000000000,2013-07-23 09:43:19.000000000,2013-07-23 09:43:19.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 7193}]","[{'number': 1, 'created': '2013-07-23 01:29:14.000000000', 'files': ['heat/tests/test_dbinstance.py', 'heat/tests/test_engine_service.py', 'heat/cloudinit/loguserdata.py', 'heat/tests/test_loguserdata.py', 'heat/tests/test_parser.py', 'heat/tests/fakes.py', 'heat/api/cfn/v1/waitcondition.py', 'heat/tests/test_api_ec2token.py', 'heat/tests/test_volume.py', 'heat/tests/test_watch.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/e3caef4452ba85214abe3ac5c1fff7992cbc2ef1', 'message': 'Use new style classes\n\nChange a couple of old style classes into the newer styled ones.\n\nChange-Id: Ide3bbcd2d24f949a2a550fcc2210617f34c8cd0b\n'}]",0,38238,e3caef4452ba85214abe3ac5c1fff7992cbc2ef1,6,4,1,4715,,,0,"Use new style classes

Change a couple of old style classes into the newer styled ones.

Change-Id: Ide3bbcd2d24f949a2a550fcc2210617f34c8cd0b
",git fetch https://review.opendev.org/openstack/heat refs/changes/38/38238/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_dbinstance.py', 'heat/tests/test_engine_service.py', 'heat/cloudinit/loguserdata.py', 'heat/tests/test_loguserdata.py', 'heat/tests/test_parser.py', 'heat/tests/fakes.py', 'heat/api/cfn/v1/waitcondition.py', 'heat/tests/test_api_ec2token.py', 'heat/tests/test_volume.py', 'heat/tests/test_watch.py']",10,e3caef4452ba85214abe3ac5c1fff7992cbc2ef1,bp/watch-ceilometer,class WatchData(object):class DummyAction(object):,class WatchData:class DummyAction:,15,15
openstack%2Fhorizon~master~Ibeb038c713ae7f91c8e6ca897fe24911da6bd465,openstack/horizon,master,Ibeb038c713ae7f91c8e6ca897fe24911da6bd465,Removed a comment from tox.ini that no longer applied.,MERGED,2013-07-23 06:40:14.000000000,2013-07-23 09:15:49.000000000,2013-07-23 09:15:49.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4264}]","[{'number': 1, 'created': '2013-07-23 06:40:14.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f194236a73f3a1157c30ace9bdc80c0c4375f368', 'message': ""Removed a comment from tox.ini that no longer applied.\n\nThis refered to a flake8 rule that's no longer in\nuse.\n\nChange-Id: Ibeb038c713ae7f91c8e6ca897fe24911da6bd465\n""}]",0,38255,f194236a73f3a1157c30ace9bdc80c0c4375f368,6,3,1,7680,,,0,"Removed a comment from tox.ini that no longer applied.

This refered to a flake8 rule that's no longer in
use.

Change-Id: Ibeb038c713ae7f91c8e6ca897fe24911da6bd465
",git fetch https://review.opendev.org/openstack/horizon refs/changes/55/38255/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f194236a73f3a1157c30ace9bdc80c0c4375f368,remove-unused-comment,,# F401 '<smth>' imported but unused,0,1
openstack%2Fkeystone~master~I7805b338c48d57ca1922bb622a3f474f2341f4ac,openstack/keystone,master,I7805b338c48d57ca1922bb622a3f474f2341f4ac,Use assignment_api rather than assignment,MERGED,2013-07-19 20:27:33.000000000,2013-07-23 09:15:42.000000000,2013-07-23 09:15:42.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 5707}, {'_account_id': 6456}, {'_account_id': 6460}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-19 20:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dba183da35eed98d1bd86956d14064793184ccb3', 'message': 'Use assignment_api rather than assignment\n\nWhen normal dependency injection is used the variables\nare named like ""xxx_api"".\nThis change makes it so that the identity backend and\ndrivers use ""assignment_api"" rather than ""assignment""\nso it will be easier to switch to normal dependency\ninjection.\n\nChange-Id: I7805b338c48d57ca1922bb622a3f474f2341f4ac\n'}, {'number': 2, 'created': '2013-07-23 01:05:04.000000000', 'files': ['keystone/identity/core.py', 'keystone/identity/backends/sql.py', 'keystone/identity/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/639d62cdbacbe3c3da5183137d900d82bea5389d', 'message': 'Use assignment_api rather than assignment\n\nWhen normal dependency injection is used the variables\nare named like ""xxx_api"".\nThis change makes it so that the identity backend and\ndrivers use ""assignment_api"" rather than ""assignment""\nso it will be easier to switch to normal dependency\ninjection.\n\nPart of fix for bug 1200769\n\nChange-Id: I7805b338c48d57ca1922bb622a3f474f2341f4ac\n'}]",0,37962,639d62cdbacbe3c3da5183137d900d82bea5389d,20,8,2,6486,,,0,"Use assignment_api rather than assignment

When normal dependency injection is used the variables
are named like ""xxx_api"".
This change makes it so that the identity backend and
drivers use ""assignment_api"" rather than ""assignment""
so it will be easier to switch to normal dependency
injection.

Part of fix for bug 1200769

Change-Id: I7805b338c48d57ca1922bb622a3f474f2341f4ac
",git fetch https://review.opendev.org/openstack/keystone refs/changes/62/37962/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/identity/core.py', 'keystone/identity/backends/sql.py', 'keystone/identity/backends/ldap.py']",3,dba183da35eed98d1bd86956d14064793184ccb3,assignment_identity_dependency," return self.assignment_api.create_project(project_id, project) return self.assignment_api.get_project(project_id) return self.assignment_api._set_default_domain( return self.assignment_api._set_default_domain(ref) return self.assignment_api._set_default_domain(self.user.get_all()) self.assignment_api._validate_default_domain_id(domain_id) return self.assignment_api._set_default_domain(ref) user = self.assignment_api._validate_default_domain(user) self.assignment_api.add_user_to_project(tenant_id, user_id) return (self.assignment_api._set_default_domain user = self.assignment_api._validate_default_domain(user) return (self.assignment_api._set_default_domain self.assignment_api.delete_user(user_id) group = self.assignment_api._validate_default_domain(group) return self.assignment_api._set_default_domain( self.group.create(group)) return self.assignment_api._set_default_domain( self.group.get(group_id)) group = self.assignment_api._validate_default_domain(group) return (self.assignment_api._set_default_domain return (self.assignment_api._set_default_domain return self.assignment_api._set_default_domain(self.group.get_all()) return self.assignment_api._set_default_domain(users)"," return self.assignment.create_project(project_id, project) return self.assignment.get_project(project_id) return self.assignment._set_default_domain( return self.assignment._set_default_domain(ref) return self.assignment._set_default_domain(self.user.get_all()) self.assignment._validate_default_domain_id(domain_id) return self.assignment._set_default_domain(ref) user = self.assignment._validate_default_domain(user) self.assignment.add_user_to_project(tenant_id, user_id) return (self.assignment._set_default_domain user = self.assignment._validate_default_domain(user) return (self.assignment._set_default_domain self.assignment.delete_user(user_id) group = self.assignment._validate_default_domain(group) return self.assignment._set_default_domain(self.group.create(group)) return self.assignment._set_default_domain(self.group.get(group_id)) group = self.assignment._validate_default_domain(group) return (self.assignment._set_default_domain return (self.assignment._set_default_domain return self.assignment._set_default_domain(self.group.get_all()) return self.assignment._set_default_domain(users)",55,53
openstack%2Foslo-incubator~master~I54c6257e9bbd70bc121016f3778836104ad16140,openstack/oslo-incubator,master,I54c6257e9bbd70bc121016f3778836104ad16140,Change file bit of sample config file generator,MERGED,2013-07-21 00:58:33.000000000,2013-07-23 09:08:15.000000000,2013-07-23 09:08:14.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 1994}]","[{'number': 1, 'created': '2013-07-21 00:58:33.000000000', 'files': ['openstack/common/config/generator.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/01e5c8ecc5cccc3642405930423e16ffb3f48479', 'message': 'Change file bit of sample config file generator\n\nThe module will never execute by itself.\nDeleted the shebang line and redundant author line.\n\nChange-Id: I54c6257e9bbd70bc121016f3778836104ad16140\n'}]",0,38056,01e5c8ecc5cccc3642405930423e16ffb3f48479,7,4,1,1994,,,0,"Change file bit of sample config file generator

The module will never execute by itself.
Deleted the shebang line and redundant author line.

Change-Id: I54c6257e9bbd70bc121016f3778836104ad16140
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/56/38056/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/config/generator.py'],1,01e5c8ecc5cccc3642405930423e16ffb3f48479,config_chmod,,"#!/usr/bin/env python# @author: Zhongyue Luo, SINA Corporation. #",0,3
openstack%2Fhorizon~master~I0bd91f7bb43f97b99051fed65b75fc05d5149cc8,openstack/horizon,master,I0bd91f7bb43f97b99051fed65b75fc05d5149cc8,Use oslo.sphinx and remove local copy of doc theme,MERGED,2013-07-05 20:10:53.000000000,2013-07-23 08:46:04.000000000,2013-07-23 08:46:03.000000000,"[{'_account_id': 3}, {'_account_id': 1816}, {'_account_id': 2472}, {'_account_id': 4264}, {'_account_id': 7553}]","[{'number': 1, 'created': '2013-07-05 20:10:53.000000000', 'files': ['test-requirements.txt', 'doc/source/_static/nature.css', 'doc/source/_static/tweaks.css', 'doc/source/_static/openstack_logo.png', 'doc/source/_templates/.placeholder', 'doc/source/conf.py', 'doc/source/_static/.gitignore', 'doc/source/_static/default.css', 'doc/source/_theme/theme.conf', 'doc/source/_static/header_bg.jpg', 'doc/source/_theme/layout.html', 'doc/source/_static/header-line.gif', 'doc/source/_static/basic.css', 'doc/source/_static/jquery.tweet.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b6f7d8318bf909cc9989809127fc108e405fa400', 'message': 'Use oslo.sphinx and remove local copy of doc theme\n\nUse the new oslo.sphinx version of the OpenStack doc\ntheme instead of copying it into this repo.\n\nblueprint oslo.sphinx\n\nSigned-off-by: Doug Hellmann <doug.hellmann@dreamhost.com>\nChange-Id: I0bd91f7bb43f97b99051fed65b75fc05d5149cc8\n'}]",0,35884,b6f7d8318bf909cc9989809127fc108e405fa400,9,5,1,2472,,,0,"Use oslo.sphinx and remove local copy of doc theme

Use the new oslo.sphinx version of the OpenStack doc
theme instead of copying it into this repo.

blueprint oslo.sphinx

Signed-off-by: Doug Hellmann <doug.hellmann@dreamhost.com>
Change-Id: I0bd91f7bb43f97b99051fed65b75fc05d5149cc8
",git fetch https://review.opendev.org/openstack/horizon refs/changes/84/35884/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/source/_static/nature.css', 'doc/source/_static/tweaks.css', 'doc/source/_static/openstack_logo.png', 'doc/source/_templates/.placeholder', 'doc/source/conf.py', 'doc/source/_static/.gitignore', 'doc/source/_static/default.css', 'doc/source/_theme/theme.conf', 'doc/source/_static/header_bg.jpg', 'doc/source/_theme/layout.html', 'doc/source/_static/header-line.gif', 'doc/source/_static/basic.css', 'doc/source/_static/jquery.tweet.js']",14,b6f7d8318bf909cc9989809127fc108e405fa400,bp/oslo,,"(function($) { $.fn.tweet = function(o){ var s = { username: [""seaofclouds""], // [string] required, unless you want to display our tweets. :) it can be an array, just do [""username1"",""username2"",""etc""] list: null, //[string] optional name of list belonging to username avatar_size: null, // [integer] height and width of avatar if displayed (48px max) count: 3, // [integer] how many tweets to display? intro_text: null, // [string] do you want text BEFORE your your tweets? outro_text: null, // [string] do you want text AFTER your tweets? join_text: null, // [string] optional text in between date and tweet, try setting to ""auto"" auto_join_text_default: ""i said,"", // [string] auto text for non verb: ""i said"" bullocks auto_join_text_ed: ""i"", // [string] auto text for past tense: ""i"" surfed auto_join_text_ing: ""i am"", // [string] auto tense for present tense: ""i was"" surfing auto_join_text_reply: ""i replied to"", // [string] auto tense for replies: ""i replied to"" @someone ""with"" auto_join_text_url: ""i was looking at"", // [string] auto tense for urls: ""i was looking at"" http:... loading_text: null, // [string] optional loading text, displayed while tweets load query: null // [string] optional search query }; if(o) $.extend(s, o); $.fn.extend({ linkUrl: function() { var returning = []; var regexp = /((ftp|http|https):\/\/(\w+:{0,1}\w*@)?(\S+)(:[0-9]+)?(\/|\/([\w#!:.?+=&%@!\-\/]))?)/gi; this.each(function() { returning.push(this.replace(regexp,""<a href=\""$1\"">$1</a>"")); }); return $(returning); }, linkUser: function() { var returning = []; var regexp = /[\@]+([A-Za-z0-9-_]+)/gi; this.each(function() { returning.push(this.replace(regexp,""<a href=\""http://twitter.com/$1\"">@$1</a>"")); }); return $(returning); }, linkHash: function() { var returning = []; var regexp = / [\#]+([A-Za-z0-9-_]+)/gi; this.each(function() { returning.push(this.replace(regexp, ' <a href=""http://search.twitter.com/search?q=&tag=$1&lang=all&from='+s.username.join(""%2BOR%2B"")+'"">#$1</a>')); }); return $(returning); }, capAwesome: function() { var returning = []; this.each(function() { returning.push(this.replace(/\b(awesome)\b/gi, '<span class=""awesome"">$1</span>')); }); return $(returning); }, capEpic: function() { var returning = []; this.each(function() { returning.push(this.replace(/\b(epic)\b/gi, '<span class=""epic"">$1</span>')); }); return $(returning); }, makeHeart: function() { var returning = []; this.each(function() { returning.push(this.replace(/(&lt;)+[3]/gi, ""<tt class='heart'>&#x2665;</tt>"")); }); return $(returning); } }); function relative_time(time_value) { var parsed_date = Date.parse(time_value); var relative_to = (arguments.length > 1) ? arguments[1] : new Date(); var delta = parseInt((relative_to.getTime() - parsed_date) / 1000); var pluralize = function (singular, n) { return '' + n + ' ' + singular + (n == 1 ? '' : 's'); }; if(delta < 60) { return 'less than a minute ago'; } else if(delta < (45*60)) { return 'about ' + pluralize(""minute"", parseInt(delta / 60)) + ' ago'; } else if(delta < (24*60*60)) { return 'about ' + pluralize(""hour"", parseInt(delta / 3600)) + ' ago'; } else { return 'about ' + pluralize(""day"", parseInt(delta / 86400)) + ' ago'; } } function build_url() { var proto = ('https:' == document.location.protocol ? 'https:' : 'http:'); if (s.list) { return proto+""//api.twitter.com/1/""+s.username[0]+""/lists/""+s.list+""/statuses.json?per_page=""+s.count+""&callback=?""; } else if (s.query == null && s.username.length == 1) { return proto+'//twitter.com/status/user_timeline/'+s.username[0]+'.json?count='+s.count+'&callback=?'; } else { var query = (s.query || 'from:'+s.username.join('%20OR%20from:')); return proto+'//search.twitter.com/search.json?&q='+query+'&rpp='+s.count+'&callback=?'; } } return this.each(function(){ var list = $('<ul class=""tweet_list"">').appendTo(this); var intro = '<p class=""tweet_intro"">'+s.intro_text+'</p>'; var outro = '<p class=""tweet_outro"">'+s.outro_text+'</p>'; var loading = $('<p class=""loading"">'+s.loading_text+'</p>'); if(typeof(s.username) == ""string""){ s.username = [s.username]; } if (s.loading_text) $(this).append(loading); $.getJSON(build_url(), function(data){ if (s.loading_text) loading.remove(); if (s.intro_text) list.before(intro); $.each((data.results || data), function(i,item){ // auto join text based on verb tense and content if (s.join_text == ""auto"") { if (item.text.match(/^(@([A-Za-z0-9-_]+)) .*/i)) { var join_text = s.auto_join_text_reply; } else if (item.text.match(/(^\w+:\/\/[A-Za-z0-9-_]+\.[A-Za-z0-9-_:%&\?\/.=]+) .*/i)) { var join_text = s.auto_join_text_url; } else if (item.text.match(/^((\w+ed)|just) .*/im)) { var join_text = s.auto_join_text_ed; } else if (item.text.match(/^(\w*ing) .*/i)) { var join_text = s.auto_join_text_ing; } else { var join_text = s.auto_join_text_default; } } else { var join_text = s.join_text; }; var from_user = item.from_user || item.user.screen_name; var profile_image_url = item.profile_image_url || item.user.profile_image_url; var join_template = '<span class=""tweet_join""> '+join_text+' </span>'; var join = ((s.join_text) ? join_template : ' '); var avatar_template = '<a class=""tweet_avatar"" href=""http://twitter.com/'+from_user+'""><img src=""'+profile_image_url+'"" height=""'+s.avatar_size+'"" width=""'+s.avatar_size+'"" alt=""'+from_user+'\'s avatar"" title=""'+from_user+'\'s avatar"" border=""0""/></a>'; var avatar = (s.avatar_size ? avatar_template : ''); var date = '<a href=""http://twitter.com/'+from_user+'/statuses/'+item.id+'"" title=""view tweet on twitter"">'+relative_time(item.created_at)+'</a>'; var text = '<span class=""tweet_text"">' +$([item.text]).linkUrl().linkUser().linkHash().makeHeart().capAwesome().capEpic()[0]+ '</span>'; // until we create a template option, arrange the items below to alter a tweet's display. list.append('<li>' + avatar + date + join + text + '</li>'); list.children('li:first').addClass('tweet_first'); list.children('li:odd').addClass('tweet_even'); list.children('li:even').addClass('tweet_odd'); }); if (s.outro_text) list.after(outro); }); }); }; })(jQuery);",7,1234
openstack%2Fcinder~master~I0564a0e84fc48d537cf2cc55358d9656e8e47f80,openstack/cinder,master,I0564a0e84fc48d537cf2cc55358d9656e8e47f80,Add strip_unit and strip_count to Rbd driver,ABANDONED,2013-07-23 05:20:05.000000000,2013-07-23 08:38:21.000000000,,"[{'_account_id': 3}, {'_account_id': 1107}, {'_account_id': 2166}, {'_account_id': 2759}, {'_account_id': 7593}]","[{'number': 1, 'created': '2013-07-23 05:20:05.000000000', 'files': ['cinder/volume/drivers/rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/49df0c3348fc4124d0e1ec97e6f14bb4298cfeae', 'message': ""Add strip_unit and strip_count to Rbd driver\n\nAccording to my tests, 'strip_count' and 'strip_unit' are critical arguments to\nimprove rbd performance.\n\nSo I want to add these two arguments to Rbd driver to let users adjust. The two\narguments are also implemented in Ceph backup driver.\n\nChange-Id: I0564a0e84fc48d537cf2cc55358d9656e8e47f80\n""}]",1,38252,49df0c3348fc4124d0e1ec97e6f14bb4298cfeae,8,5,1,7593,,,0,"Add strip_unit and strip_count to Rbd driver

According to my tests, 'strip_count' and 'strip_unit' are critical arguments to
improve rbd performance.

So I want to add these two arguments to Rbd driver to let users adjust. The two
arguments are also implemented in Ceph backup driver.

Change-Id: I0564a0e84fc48d537cf2cc55358d9656e8e47f80
",git fetch https://review.opendev.org/openstack/cinder refs/changes/52/38252/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/rbd.py'],1,49df0c3348fc4124d0e1ec97e6f14bb4298cfeae,bp/add-rbd-strip," 'driver does not write them directly to the volume'), cfg.IntOpt('rbd_stripe_unit', default=0, help='RBD stripe unit to use when creating a rbd volume'), cfg.IntOpt('rbd_stripe_count', default=0, help='RBD stripe count to use when creating a rbd volume')] if self._supports_stripingv2(): self.rbd_stripe_unit = CONF.rbd_stripe_unit self.rbd_stripe_count = CONF.rbd_stripe_count else: LOG.info(_(""rbd striping not supported - ignoring configuration "" ""settings for rbd striping"")) self.rbd_stripe_count = 0 self.rbd_stripe_unit = 0 def _supports_stripingv2(self): """"""Determine if striping is supported by our version of librbd."""""" return hasattr(self.rbd, 'RBD_FEATURE_STRIPINGV2') features=features, stripe_unit=self.rbd_stripe_unit, stripe_count=self.rbd_stripe_count)"," 'driver does not write them directly to the volume'), ] features=features)",21,2
openstack%2Fmurano-deployment~master~I27ba357bc654175136ab7a2505a23eda4569fde6,openstack/murano-deployment,master,I27ba357bc654175136ab7a2505a23eda4569fde6,Cleaned up unused code.,MERGED,2013-07-23 03:46:45.000000000,2013-07-23 08:24:56.000000000,2013-07-23 08:24:56.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-23 03:46:45.000000000', 'files': ['WindowsPowerShell/Functions/SQLServerInstaller.ps1', 'WindowsPowerShell/Functions/SQLServerOptionParsers.ps1', 'WindowsPowerShell/Functions/OptionParser.ps1'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/f11c1f49b96b3abc0432d57d4c061c76b350c6ae', 'message': 'Cleaned up unused code.\n\nChange-Id: I27ba357bc654175136ab7a2505a23eda4569fde6\n'}]",0,38247,f11c1f49b96b3abc0432d57d4c061c76b350c6ae,5,2,1,8241,,,0,"Cleaned up unused code.

Change-Id: I27ba357bc654175136ab7a2505a23eda4569fde6
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/47/38247/1 && git format-patch -1 --stdout FETCH_HEAD,"['WindowsPowerShell/Functions/SQLServerInstaller.ps1', 'WindowsPowerShell/Functions/SQLServerOptionParsers.ps1', 'WindowsPowerShell/Functions/OptionParser.ps1']",3,f11c1f49b96b3abc0432d57d4c061c76b350c6ae,mssql-deployment,,#$ErrorActionPreference = 'Stop' #Export-ModuleMember -Function New-OptionParser #Export-ModuleMember -Function New-Option,0,49
openstack%2Ftempest~master~I5ee9ec816845de483fe88d76d1bb047e7bb1af7e,openstack/tempest,master,I5ee9ec816845de483fe88d76d1bb047e7bb1af7e,Move neutron_available option to service_available,MERGED,2013-07-19 21:02:44.000000000,2013-07-23 08:24:16.000000000,2013-07-23 00:38:21.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5292}]","[{'number': 1, 'created': '2013-07-19 21:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/51752682bb69252ea7f4ac97f276bb5b00cb6ae3', 'message': 'Move neutron_available option to service_available\n\nThis commit moves the neutron_available config option from the\nnetwork group to under the service_available group. The option\nis also renamed to neutron.\n\nChange-Id: I5ee9ec816845de483fe88d76d1bb047e7bb1af7e\n'}, {'number': 2, 'created': '2013-07-19 22:23:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6580895278003ae93c9949f4077e9657945f8c94', 'message': 'Move neutron_available option to service_available\n\nThis commit moves the neutron_available config option from the\nnetwork group to under the service_available group. The option\nis also renamed to neutron.\n\nChange-Id: I5ee9ec816845de483fe88d76d1bb047e7bb1af7e\n'}, {'number': 3, 'created': '2013-07-22 20:17:03.000000000', 'files': ['tempest/api/compute/servers/test_attach_interfaces.py', 'tempest/api/compute/servers/test_virtual_interfaces.py', 'tempest/scenario/manager.py', 'tempest/api/compute/admin/test_fixed_ips.py', 'tempest/cli/simple_read_only/test_compute.py', 'etc/tempest.conf.sample', 'tempest/api/compute/security_groups/test_security_groups.py', 'tempest/config.py', 'tempest/api/network/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/faa340d498f339f10306c28a0862e0ed6057dca1', 'message': 'Move neutron_available option to service_available\n\nThis commit moves the neutron_available config option from the\nnetwork group to under the service_available group. The option\nis also renamed to neutron.\n\nChange-Id: I5ee9ec816845de483fe88d76d1bb047e7bb1af7e\n'}]",0,37971,faa340d498f339f10306c28a0862e0ed6057dca1,18,5,3,5196,,,0,"Move neutron_available option to service_available

This commit moves the neutron_available config option from the
network group to under the service_available group. The option
is also renamed to neutron.

Change-Id: I5ee9ec816845de483fe88d76d1bb047e7bb1af7e
",git fetch https://review.opendev.org/openstack/tempest refs/changes/71/37971/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/servers/test_attach_interfaces.py', 'tempest/api/compute/servers/test_virtual_interfaces.py', 'tempest/api/compute/admin/test_fixed_ips.py', 'tempest/scenario/manager.py', 'etc/tempest.conf.sample', 'tempest/api/compute/security_groups/test_security_groups.py', 'tempest/config.py', 'tempest/api/network/base.py']",8,51752682bb69252ea7f4ac97f276bb5b00cb6ae3,service-avail-group, if not cls.service_available.neutron:, if not cls.network_cfg.neutron_available:,11,11
openstack%2Fneutron~stable%2Fgrizzly~I3095f6aa0aa182592bd939ec59bac1820f15676f,openstack/neutron,stable/grizzly,I3095f6aa0aa182592bd939ec59bac1820f15676f,Clean up Cisco plugin config parameters,MERGED,2013-07-19 01:06:36.000000000,2013-07-23 07:36:08.000000000,2013-07-23 07:36:07.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 107}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 6072}, {'_account_id': 6659}, {'_account_id': 6695}, {'_account_id': 6754}, {'_account_id': 6994}]","[{'number': 1, 'created': '2013-07-19 01:06:36.000000000', 'files': ['etc/quantum/plugins/cisco/l2network_plugin.ini', 'quantum/plugins/cisco/l2network_plugin_configuration.py', 'quantum/plugins/cisco/db/network_db_v2.py', 'quantum/plugins/cisco/tests/unit/test_database.py', 'quantum/plugins/cisco/db/l2network_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3df809b0d1d4b98aad707dd96594b374c119b324', 'message': 'Clean up Cisco plugin config parameters\n\nChange-Id: I3095f6aa0aa182592bd939ec59bac1820f15676f\nFixes: bug 1201537\n'}]",2,37822,3df809b0d1d4b98aad707dd96594b374c119b324,10,11,1,6524,,,0,"Clean up Cisco plugin config parameters

Change-Id: I3095f6aa0aa182592bd939ec59bac1820f15676f
Fixes: bug 1201537
",git fetch https://review.opendev.org/openstack/neutron refs/changes/22/37822/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/quantum/plugins/cisco/l2network_plugin.ini', 'quantum/plugins/cisco/l2network_plugin_configuration.py', 'quantum/plugins/cisco/db/network_db_v2.py', 'quantum/plugins/cisco/tests/unit/test_database.py', 'quantum/plugins/cisco/db/l2network_db.py']",5,3df809b0d1d4b98aad707dd96594b374c119b324,bug/1201537,,"def create_vlanids(): """"""Prepopulates the vlan_bindings table"""""" LOG.debug(_(""create_vlanids() called"")) session = db.get_session() try: vlanid = session.query(l2network_models.VlanID).one() except exc.MultipleResultsFound: pass except exc.NoResultFound: start = int(conf.VLAN_START) end = int(conf.VLAN_END) while start <= end: vlanid = l2network_models.VlanID(start) session.add(vlanid) start += 1 session.flush() return ",8,91
openstack%2Fnova~master~If828bf42fa077665d1d92e08758fbddd342ab626,openstack/nova,master,If828bf42fa077665d1d92e08758fbddd342ab626,Missed message -> msg_fmt conversion,MERGED,2013-07-17 15:34:42.000000000,2013-07-23 07:29:01.000000000,2013-07-23 07:28:59.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 5174}]","[{'number': 1, 'created': '2013-07-17 15:34:42.000000000', 'files': ['nova/exception.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/388187144dc59d48730ad5815bf1d2b0f517bc92', 'message': ""Missed message -> msg_fmt conversion\n\nWe recently changed NovaException's to define `msg_fmt` instead of `message`\non the class. Looks like this exception was missed for some reason.\n\nFixes bug 1202255\n\nChange-Id: If828bf42fa077665d1d92e08758fbddd342ab626\n""}]",0,37499,388187144dc59d48730ad5815bf1d2b0f517bc92,8,5,1,475,,,0,"Missed message -> msg_fmt conversion

We recently changed NovaException's to define `msg_fmt` instead of `message`
on the class. Looks like this exception was missed for some reason.

Fixes bug 1202255

Change-Id: If828bf42fa077665d1d92e08758fbddd342ab626
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/37499/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/exception.py'],1,388187144dc59d48730ad5815bf1d2b0f517bc92,bug/1202255," msg_fmt = _(""Cannot update cells configuration file."")"," message = _(""Cannot update cells configuration file."")",1,1
openstack%2Fnova~master~Ib2f1a0d49a12114b28f0cd5ce0bb7119f864d1a6,openstack/nova,master,Ib2f1a0d49a12114b28f0cd5ce0bb7119f864d1a6,Fix inconsistency between Nova-Net and Neutron,MERGED,2013-06-14 09:33:44.000000000,2013-07-23 07:13:57.000000000,2013-07-23 07:13:55.000000000,"[{'_account_id': 3}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5652}, {'_account_id': 5803}, {'_account_id': 6873}, {'_account_id': 7781}, {'_account_id': 7823}]","[{'number': 1, 'created': '2013-06-14 09:33:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c54935234bde3b9b85dd0faf8ff2627b1126c639', 'message': 'Fix Nova API floating IP error code inconsistent between Nova-Net and Quantum\n\nThe quantum client raises QuantumClientException (status_code 404)\nthat is not unknown for nova, and is translated in 500 computeFault.\nCatching this exception in nova/nova/network/quantumv2/api.py and\nraising more generic exception as exception.NotFound solves the problem.\n\nAdded also an unitary test to test quantumv2 api\n\nChange-Id: Ib2f1a0d49a12114b28f0cd5ce0bb7119f864d1a6\nFixes: bug  #1160309\n'}, {'number': 2, 'created': '2013-06-14 10:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1d50cfb1fba9b7ecac4756932d26c8469c5df0c', 'message': 'Fix inconsistency between Nova-Net and Quantum\n\nThe quantum client raises QuantumClientException (status_code 404)\nthat is not unknown for nova, and is translated in 500 computeFault.\nCatching this exception in nova/nova/network/quantumv2/api.py and\nraising more generic exception as exception.NotFound solves the problem.\n\nAdded also an unitary test to test quantumv2 api\n\nChange-Id: Ib2f1a0d49a12114b28f0cd5ce0bb7119f864d1a6\nFixes: bug  #1160309\n'}, {'number': 3, 'created': '2013-06-14 15:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0544d3a6a5b62fc4475274ef438aae5368e5f9b6', 'message': 'Fix inconsistency between Nova-Net and Quantum\n\nThe quantum client raises QuantumClientException (status_code 404)\nthat is not unknown for nova, and is translated in 500 computeFault.\nCatching this exception in nova/nova/network/quantumv2/api.py and\nraising more generic exception as exception.NotFound solves the problem.\n\nAdded also an unitary test to test quantumv2 api\n\nChange-Id: Ib2f1a0d49a12114b28f0cd5ce0bb7119f864d1a6\nFixes: bug  #1160309\n'}, {'number': 4, 'created': '2013-06-26 06:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8918f6ce8184d270cb6ab08df1ea443e5d6da43', 'message': 'Fix inconsistency between Nova-Net and Quantum\n\nThe quantum client raises QuantumClientException (status_code 404)\nthat is not unknown for nova, and is translated in 500 computeFault.\nCatching this exception in nova/nova/network/quantumv2/api.py and\nraising more generic exception as exception.NotFound solves the problem.\n\nAdded also an unitary test to test quantumv2 api\n\nChange-Id: Ib2f1a0d49a12114b28f0cd5ce0bb7119f864d1a6\nFixes: bug  #1160309\n'}, {'number': 5, 'created': '2013-07-15 07:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b99f9e5709e2f50e52ba13aac2d7ccb80a9207d', 'message': 'Fix inconsistency between Nova-Net and Neutron\n\nThe neutron client raises NeutronClientException (status_code 404)\nthat is not unknown for nova, and is translated in 500 computeFault.\nCatching this exception in nova/nova/network/neutronv2/api.py and\nraising more generic exception as exception.NotFound solves the problem.\n\nAdded also an unitary test to test quantumv2 api\n\nChange-Id: Ib2f1a0d49a12114b28f0cd5ce0bb7119f864d1a6\nFixes: bug #1160309\n'}, {'number': 6, 'created': '2013-07-15 16:01:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/450e5950fa54d4d21d748c8dcaf816bf21ac708e', 'message': 'Fix inconsistency between Nova-Net and Neutron\n\nThe neutron client raises NeutronClientException (status_code 404)\nthat is not unknown for nova, and is translated in 500 computeFault.\nCatching this exception in nova/nova/network/neutronv2/api.py and\nraising more generic exception as exception.NotFound solves the problem.\n\nAdded also an unitary test to test quantumv2 api\n\nChange-Id: Ib2f1a0d49a12114b28f0cd5ce0bb7119f864d1a6\nFixes: bug #1160309\n'}, {'number': 7, 'created': '2013-07-16 08:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c78d830f8ba024f49e0609f94e58071dec93cfb1', 'message': 'Fix inconsistency between Nova-Net and Neutron\n\nThe neutron client raises NeutronClientException (status_code 404)\nthat is not unknown for nova, and is translated in 500 computeFault.\nCatching this exception in nova/nova/network/neutronv2/api.py and\nraising more generic exception as exception.NotFound solves the problem.\n\nAdded also an unitary test to test quantumv2 api\n\nChange-Id: Ib2f1a0d49a12114b28f0cd5ce0bb7119f864d1a6\nFixes: bug #1160309\n'}, {'number': 8, 'created': '2013-07-18 09:49:44.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4a2915b4e389bfba0ff25583369fd75b24e19118', 'message': 'Fix inconsistency between Nova-Net and Neutron\n\nThe neutron client raises NeutronClientException (status_code 404)\nthat is not unknown for nova, and is translated in 500 computeFault.\nCatching this exception in nova/nova/network/neutronv2/api.py and\nraising more generic exception as exception.NotFound solves the problem.\n\nAdded also an unitary test to test neutronv2 api\n\nbug #1160309\nbug #1200175\n\nChange-Id: Ib2f1a0d49a12114b28f0cd5ce0bb7119f864d1a6\n'}]",9,33024,4a2915b4e389bfba0ff25583369fd75b24e19118,61,14,8,7781,,,0,"Fix inconsistency between Nova-Net and Neutron

The neutron client raises NeutronClientException (status_code 404)
that is not unknown for nova, and is translated in 500 computeFault.
Catching this exception in nova/nova/network/neutronv2/api.py and
raising more generic exception as exception.NotFound solves the problem.

Added also an unitary test to test neutronv2 api

bug #1160309
bug #1200175

Change-Id: Ib2f1a0d49a12114b28f0cd5ce0bb7119f864d1a6
",git fetch https://review.opendev.org/openstack/nova refs/changes/24/33024/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/quantumv2/api.py', 'nova/tests/network/test_quantumv2.py']",2,c54935234bde3b9b85dd0faf8ff2627b1126c639,bug/1160309," def test_get_floating_ip_by_id_not_found(self): api = quantumapi.API() QuantumNotFound = quantum_exceptions.QuantumClientException( status_code=404) floating_ip_id = self.fip_unassociated['id'] self.moxed_client.show_floatingip(floating_ip_id).\ AndRaise(QuantumNotFound) self.mox.ReplayAll() self.assertRaises(exception.NotFound, api.get_floating_ip, self.context, floating_ip_id) ",,16,1
openstack%2Fnova~master~Icbd467888cc7f16fa3694ed2b93548d0285461b5,openstack/nova,master,Icbd467888cc7f16fa3694ed2b93548d0285461b5,Sync sample config file generator with Oslo,MERGED,2013-07-23 01:28:20.000000000,2013-07-23 06:56:22.000000000,2013-07-23 06:56:20.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 1849}, {'_account_id': 1994}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-07-23 01:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1952d94bc50d6fbb0ab813eafef7eb5150610d59', 'message': 'Sync sample config file generator with Oslo\n\nChange-Id: Icbd467888cc7f16fa3694ed2b93548d0285461b5\n'}, {'number': 2, 'created': '2013-07-23 05:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2785a403143f9dcd83ffaa428b51eae111c3d048', 'message': ""Sync sample config file generator with Oslo\n\nThe sample generator tool in Oslo is located in tools/config therefore\nthis patch moves the files in tools/conf to tools/config. The reason\nOslo chose 'config' is because the generator.py module is located in\nthe openstack.common.config package and update.py looks for the\ncorresponding directory in tools when it syncs the 'config' package.\n\n./update.sh --module config --base nova --dest-dir $NOVA_HOME --nodep\n\nSince every thing moved to tools/config, changes had to happen on\nthe tox.ini file and check_update.sh\n\nChange-Id: Icbd467888cc7f16fa3694ed2b93548d0285461b5\n""}, {'number': 3, 'created': '2013-07-23 05:04:28.000000000', 'files': ['tools/conf/check_uptodate.sh', 'tools/config/check_uptodate.sh', 'tools/config/analyze_opts.py', 'tools/config/README', 'tools/config/generate_sample.sh', 'tools/conf/generate_sample.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/ca08c4447a11192f5ca2a5a63ffe3f2656dda2b7', 'message': ""Sync sample config file generator with Oslo\n\nThe sample generator tool in Oslo is located in tools/config therefore\nthis patch moves the files in tools/conf to tools/config. The reason\nOslo chose 'config' is because the generator.py module is located in\nthe openstack.common.config package and update.py looks for the\ncorresponding directory in tools when it syncs the 'config' package.\n\n./update.sh --module config --base nova --dest-dir $NOVA_HOME --nodep\n\nSince every thing moved to tools/config, changes had to happen on\nthe tox.ini file and check_update.sh\n\nChange-Id: Icbd467888cc7f16fa3694ed2b93548d0285461b5\n""}]",0,38237,ca08c4447a11192f5ca2a5a63ffe3f2656dda2b7,11,6,3,1994,,,0,"Sync sample config file generator with Oslo

The sample generator tool in Oslo is located in tools/config therefore
this patch moves the files in tools/conf to tools/config. The reason
Oslo chose 'config' is because the generator.py module is located in
the openstack.common.config package and update.py looks for the
corresponding directory in tools when it syncs the 'config' package.

./update.sh --module config --base nova --dest-dir $NOVA_HOME --nodep

Since every thing moved to tools/config, changes had to happen on
the tox.ini file and check_update.sh

Change-Id: Icbd467888cc7f16fa3694ed2b93548d0285461b5
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/38237/3 && git format-patch -1 --stdout FETCH_HEAD,"['tools/conf/check_uptodate.sh', 'tools/config/check_uptodate.sh', 'tools/config/analyze_opts.py', 'tools/config/README', 'tools/config/generate_sample.sh', 'tools/conf/generate_sample.sh', 'tox.ini']",7,1952d94bc50d6fbb0ab813eafef7eb5150610d59,update_config, {toxinidir}/tools/config/check_uptodate.sh, {toxinidir}/tools/conf/check_uptodate.sh,81,41
openstack%2Ftempest~master~I0f7f4f02c0a2751098522d5add5519dd706e8fdc,openstack/tempest,master,I0f7f4f02c0a2751098522d5add5519dd706e8fdc,Added bogus line,ABANDONED,2013-07-20 12:07:44.000000000,2013-07-23 06:44:28.000000000,,"[{'_account_id': 5803}, {'_account_id': 7020}]","[{'number': 1, 'created': '2013-07-20 12:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9d81ded8596e63d5850a53fd5d3597bd14c99ebe', 'message': 'Added bogus line\n\nChange-Id: I0f7f4f02c0a2751098522d5add5519dd706e8fdc\n'}, {'number': 2, 'created': '2013-07-20 15:49:45.000000000', 'files': ['README.rst', 'tempest/clients.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/022a903930e95cf1fd8f2eecdef9e93194282ef1', 'message': 'Added bogus line\n\nChange-Id: I0f7f4f02c0a2751098522d5add5519dd706e8fdc\n'}]",1,38033,022a903930e95cf1fd8f2eecdef9e93194282ef1,3,2,2,7020,,,0,"Added bogus line

Change-Id: I0f7f4f02c0a2751098522d5add5519dd706e8fdc
",git fetch https://review.opendev.org/openstack/tempest refs/changes/33/38033/1 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'tempest/clients.py']",2,9d81ded8596e63d5850a53fd5d3597bd14c99ebe,tryingsomething, conf = None,,2,0
openstack%2Fhorizon~master~I7c186df41b5601078ffc54588aace8136c6576bd,openstack/horizon,master,I7c186df41b5601078ffc54588aace8136c6576bd,Enable pep8 F841 checking.,MERGED,2013-07-22 08:09:53.000000000,2013-07-23 06:36:51.000000000,2013-07-23 06:36:51.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6914}]","[{'number': 1, 'created': '2013-07-22 08:09:53.000000000', 'files': ['openstack_dashboard/dashboards/admin/groups/forms.py', 'openstack_dashboard/dashboards/admin/roles/tests.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/volumes/views.py', 'openstack_dashboard/dashboards/project/routers/views.py', 'openstack_dashboard/dashboards/admin/projects/tests.py', 'openstack_dashboard/dashboards/project/networks/workflows.py', 'openstack_dashboard/test/test_data/neutron_data.py', 'openstack_dashboard/dashboards/project/loadbalancers/tests.py', 'openstack_dashboard/dashboards/project/loadbalancers/workflows.py', 'openstack_dashboard/dashboards/settings/password/forms.py', 'openstack_dashboard/dashboards/project/volumes/tests.py', 'openstack_dashboard/test/api_tests/network_tests.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/tests.py', 'openstack_dashboard/dashboards/admin/flavors/tests.py', 'openstack_dashboard/dashboards/admin/domains/workflows.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/horizon/commit/56ae8fdfc564b3081599e73f945496edcc2a5ef6', 'message': 'Enable pep8 F841 checking.\n\nThis check looks to see whether a local variable\nis unused. Also fixed all violators of said check.\n\nChange-Id: I7c186df41b5601078ffc54588aace8136c6576bd\n'}]",0,38115,56ae8fdfc564b3081599e73f945496edcc2a5ef6,7,4,1,7680,,,0,"Enable pep8 F841 checking.

This check looks to see whether a local variable
is unused. Also fixed all violators of said check.

Change-Id: I7c186df41b5601078ffc54588aace8136c6576bd
",git fetch https://review.opendev.org/openstack/horizon refs/changes/15/38115/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/groups/forms.py', 'openstack_dashboard/dashboards/admin/roles/tests.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/volumes/views.py', 'openstack_dashboard/dashboards/project/routers/views.py', 'openstack_dashboard/dashboards/admin/projects/tests.py', 'openstack_dashboard/dashboards/project/networks/workflows.py', 'openstack_dashboard/test/test_data/neutron_data.py', 'openstack_dashboard/dashboards/project/loadbalancers/tests.py', 'openstack_dashboard/dashboards/project/loadbalancers/workflows.py', 'openstack_dashboard/dashboards/settings/password/forms.py', 'openstack_dashboard/dashboards/project/volumes/tests.py', 'openstack_dashboard/test/api_tests/network_tests.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/tests.py', 'openstack_dashboard/dashboards/admin/flavors/tests.py', 'openstack_dashboard/dashboards/admin/domains/workflows.py', 'tox.ini']",17,56ae8fdfc564b3081599e73f945496edcc2a5ef6,unused-var-cleanup,"ignore = E121,E126,E127,E128,F403,F999,H201,H302,H303,H4,H701,H702","# F841 local variable '<smth>' is assigned to but never usedignore = E121,E126,E127,E128,F403,F841,F999,H201,H302,H303,H4,H701,H702",14,41
openstack%2Foslo.config~master~I0ce5e0cfe908928408a9a6598b12da6b73c0cdd5,openstack/oslo.config,master,I0ce5e0cfe908928408a9a6598b12da6b73c0cdd5,Fix oslo.config version generation,ABANDONED,2013-07-13 19:03:05.000000000,2013-07-23 06:03:12.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1247}]","[{'number': 1, 'created': '2013-07-13 19:03:05.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/0a960386a8eb2d865c1a92049c68097e667cd4bb', 'message': 'Fix oslo.config version generation\n\nSimply use the git version extracted by pbr.\n\nFixes LP Bug #1200984\n\nChange-Id: I0ce5e0cfe908928408a9a6598b12da6b73c0cdd5\n'}]",0,36953,0a960386a8eb2d865c1a92049c68097e667cd4bb,4,3,1,6593,,,0,"Fix oslo.config version generation

Simply use the git version extracted by pbr.

Fixes LP Bug #1200984

Change-Id: I0ce5e0cfe908928408a9a6598b12da6b73c0cdd5
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/53/36953/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,0a960386a8eb2d865c1a92049c68097e667cd4bb,bug/1200984,,version = 1.2.0,0,1
openstack%2Fnova~master~Ic142932ed92259b80518ebe695a53ee44bb8e4f0,openstack/nova,master,Ic142932ed92259b80518ebe695a53ee44bb8e4f0,Check of equal models and migrations (mysql).,ABANDONED,2013-06-24 14:15:57.000000000,2013-07-23 06:03:11.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2889}, {'_account_id': 6172}, {'_account_id': 6507}, {'_account_id': 6509}, {'_account_id': 6849}, {'_account_id': 7491}]","[{'number': 1, 'created': '2013-06-24 14:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7ba7dbabc8f7d937efeef054b9c15d8cf19b191', 'message': 'Check of equal models and migrations.\n\nWe have a lot of problems with sync models and migrations today.\nChanges in this structures can be differences and there are no tests\nfor determination this problem.\n\nThis test checking equality of models and state of migrations.\nObject for check:\n- set of columns\n\there type, limit of length, default value, unique and nullable params will be checked,\n- ForeignKeyConstraint\n- UniqueKeyConstraint\n- indexes.\n\nNot merge this change while patches of sync models and migrations are not merged!\nDuring this work few extra tables in db after migrations was found.\n\nI will fix this bug later.\n\nChange-Id: Ic142932ed92259b80518ebe695a53ee44bb8e4f0\n'}, {'number': 2, 'created': '2013-06-25 10:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d33612fddf9eed05ed3da27b2f27bdeb5b160a4', 'message': 'Check of equal models and migrations.\n\nWe have a lot of problems with sync models and migrations today.\nChanges in this structures can be differences and there are no tests\nfor determination this problem.\n\nThis test checking equality of models and state of migrations.\nObject for check:\n- set of columns\n\there type, limit of length, default value, unique and nullable params will be checked,\n- ForeignKeyConstraint\n- UniqueKeyConstraint\n- indexes.\n\nNot merge this change while patches of sync models and migrations are not merged!\nDuring this work few extra tables in db after migrations was found.\n\nI will fix this bug later.\n\nChange-Id: Ic142932ed92259b80518ebe695a53ee44bb8e4f0\n'}, {'number': 3, 'created': '2013-06-27 08:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/70455f346b161012c72de57e40df39b6a92343e3', 'message': 'Check of equal models and migrations.\n\nWe have a lot of problems with sync models and migrations today.\nChanges in this structures can be differences and there are no tests\nfor determination this problem.\n\nThis test checking equality of models and state of migrations.\nObject for check:\n- set of columns\nhere type, limit of length, default value, unique and nullable params will be checked,\n- ForeignKeyConstraint\n- UniqueKeyConstraint\n- indexes.\n\nNot merge this change while patches of sync models and migrations are not merged!\nDuring this work few extra tables in db after migrations was found.\n\nI will fix this bug later.\n\nChange-Id: Ic142932ed92259b80518ebe695a53ee44bb8e4f0\n'}, {'number': 4, 'created': '2013-06-27 12:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b8958323c6df119206c37f1df0014981819f903', 'message': 'Check of equal models and migrations.\n\nWe have a lot of problems with sync models and migrations today.\nChanges in this structures can be differences and there are no tests\nfor determination this problem.\n\nThis test checking equality of models and state of migrations.\nObject for check:\n- set of columns\nhere type, limit of length, default value, unique and nullable params will be checked,\n- ForeignKeyConstraint\n- UniqueKeyConstraint\n- indexes.\n\nNot merge this change while patches of sync models and migrations are not merged!\nDuring this work few extra tables in db after migrations was found.\n\nI will fix this bug later.\n\nChange-Id: Ic142932ed92259b80518ebe695a53ee44bb8e4f0\n'}, {'number': 5, 'created': '2013-06-28 10:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d55b9c305aa289a42ffb0e32bea0efc84e208b06', 'message': 'Check of equal models and migrations (mysql).\n\nWe have a lot of problems with sync models and migrations today.\nChanges in this structures can be differences and there are no tests\nfor determination this problem.\n\nThis test checking equality of models and state of migrations.\nObject for check:\n- set of columns\nhere type, limit of length, default value, unique and nullable params will be checked,\n- ForeignKeyConstraint\n- UniqueKeyConstraint\n- indexes.\n\nThis test cover only mysql dialect.\n\nNot merge this change while patches of sync models and migrations are not merged!\nDuring this work few extra tables in db after migrations was found.\n\nI will fix this bug later.\n\nChange-Id: Ic142932ed92259b80518ebe695a53ee44bb8e4f0\n'}, {'number': 6, 'created': '2013-06-28 10:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b702e26a09c64a3883643d8b79f794adf958f1f', 'message': 'Check of equal models and migrations (mysql).\n\nWe have a lot of problems with sync models and migrations today.\nChanges in this structures can be differences and there are no tests\nfor determination this problem.\n\nThis test checking equality of models and state of migrations.\nObject for check:\n- set of columns\nhere type, limit of length, default value, unique and nullable params will be checked,\n- ForeignKeyConstraint\n- UniqueKeyConstraint\n- indexes.\n\nThis test covers only mysql dialect.\n\nNot merge this change while patches of sync models and migrations are not merged!\nDuring this work few extra tables in db after migrations was found.\n\nI will fix this bug later.\n\nChange-Id: Ic142932ed92259b80518ebe695a53ee44bb8e4f0\n'}, {'number': 7, 'created': '2013-06-28 12:36:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/20f8ffcf4a003fe770a55d230f44fd02bdc0ff2a', 'message': 'Check of equal models and migrations (mysql).\n\nWe have a lot of problems with sync models and migrations today.\nChanges in this structures can be differences and there are no tests\nfor determination this problem.\n\nThis test checking equality of models and state of migrations.\nObject for check:\n- set of columns\nhere type, limit of length, default value, unique and nullable params will be checked,\n- ForeignKeyConstraint\n- UniqueKeyConstraint\n- indexes.\n\nThis test covers only mysql dialect.\n\nNot merge this change while patches of sync models and migrations are not merged!\nDuring this work few extra tables in db after migrations was found.\n\nI will fix this bug later.\n\nChange-Id: Ic142932ed92259b80518ebe695a53ee44bb8e4f0\n'}, {'number': 8, 'created': '2013-07-02 13:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2539742c05eb64a48ff0dbe08cde579a7539d6fe', 'message': 'Check of equal models and migrations (mysql).\n\nWe have a lot of problems with sync models and migrations today.\nChanges in this structures can be differences and there are no tests\nfor determination this problem.\n\nThis test checking equality of models and state of migrations.\nObject for check:\n- set of columns\nhere type, limit of length, default value, unique and nullable params will be checked,\n- ForeignKeyConstraint\n- UniqueKeyConstraint\n- indexes.\n\nThis test covers only mysql dialect.\n\nNot merge this change while patches of sync models and migrations are not merged!\nDuring this work few extra tables in db after migrations was found.\n\nI will fix this bug later.\n\nChange-Id: Ic142932ed92259b80518ebe695a53ee44bb8e4f0\n'}, {'number': 9, 'created': '2013-07-05 13:23:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/934cfe9a499035ff1639eba6fdfda0e4598712ce', 'message': 'Check of equal models and migrations (mysql).\n\nWe have a lot of problems with sync models and migrations today.\nChanges in this structures can be differences and there are no tests\nfor determination this problem.\n\nThis test checking equality of models and state of migrations.\nObject for check:\n- set of columns\nhere type, limit of length, default value, unique and nullable params will be checked,\n- ForeignKeyConstraint\n- UniqueKeyConstraint\n- indexes.\n\nThis test covers only mysql dialect.\n\nNot merge this change while patches of sync models and migrations are not merged!\nDuring this work few extra tables in db after migrations was found.\n\nI will fix this bug later.\n\nChange-Id: Ic142932ed92259b80518ebe695a53ee44bb8e4f0\n'}, {'number': 10, 'created': '2013-07-05 13:25:10.000000000', 'files': ['nova/tests/db/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cd8f8681ee0d89c98368aa2de857dd40d3c052b9', 'message': 'Check of equal models and migrations (mysql).\n\nWe have a lot of problems with sync models and migrations today.\nChanges in this structures can be differences and there are no tests\nfor determination this problem.\n\nThis test checking equality of models and state of migrations.\nObject for check:\n- set of columns\nhere type, limit of length, default value, unique and nullable params will be checked,\n- ForeignKeyConstraint\n- UniqueKeyConstraint\n- indexes.\n\nThis test covers only mysql dialect.\n\nNot merge this change while patches of sync models and migrations are not merged!\nDuring this work few extra tables in db after migrations was found.\n\nI will fix this bug later.\n\nBlueprint: db-sync-models-with-migrations\nChange-Id: Ic142932ed92259b80518ebe695a53ee44bb8e4f0\n'}]",51,34212,cd8f8681ee0d89c98368aa2de857dd40d3c052b9,47,9,10,6507,,,0,"Check of equal models and migrations (mysql).

We have a lot of problems with sync models and migrations today.
Changes in this structures can be differences and there are no tests
for determination this problem.

This test checking equality of models and state of migrations.
Object for check:
- set of columns
here type, limit of length, default value, unique and nullable params will be checked,
- ForeignKeyConstraint
- UniqueKeyConstraint
- indexes.

This test covers only mysql dialect.

Not merge this change while patches of sync models and migrations are not merged!
During this work few extra tables in db after migrations was found.

I will fix this bug later.

Blueprint: db-sync-models-with-migrations
Change-Id: Ic142932ed92259b80518ebe695a53ee44bb8e4f0
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/34212/10 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/db/test_sync_model_with_migration.py'],1,d7ba7dbabc8f7d937efeef054b9c15d8cf19b191,bp/db-sync-models-with-migrations,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Tests of equality database migrations and model. This test case reads the configuration file test_migrations.conf for database connection settings to use in the tests. For each connection found in the config file, the test case runs a series of test cases to ensure that acual schema is equal to defined model. For testing you need to set up a db named 'openstack_citest' with user 'openstack_citest' and password 'openstack_citest' on localhost. """""" import inspect import sys import collections import commands import ConfigParser import datetime import glob import os import urlparse import uuid from migrate.versioning import repository import netaddr import sqlalchemy from sqlalchemy.schema import MetaData from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.dialects import postgresql from sqlalchemy.dialects import sqlite import sqlalchemy.exc from nova.db.sqlalchemy import api as db from nova.db.sqlalchemy import models import nova.db.sqlalchemy.migrate_repo from nova.db.sqlalchemy import utils as db_utils from nova.openstack.common import log as logging from nova.openstack.common import timeutils from nova.openstack.common import uuidutils from nova import test from nova import utils import nova.virt.baremetal.db.sqlalchemy.migrate_repo from nova.tests.db import test_migrations LOG = logging.getLogger(__name__) class TestNovaMigrationsSync(test_migrations.BaseMigrationTestCase): """"""Test sqlalchemy-migrate migrations."""""" USER = ""openstack_citest"" PASSWD = ""openstack_citest"" DATABASE = ""openstack_citest"" def __init__(self, *args, **kwargs): super(TestNovaMigrationsSync, self).__init__(*args, **kwargs) self.DEFAULT_CONFIG_FILE = os.path.join(os.path.dirname(__file__), 'test_migrations.conf') self.CONFIG_FILE_PATH = os.environ.get('NOVA_TEST_MIGRATIONS_CONF', self.DEFAULT_CONFIG_FILE) self.MIGRATE_FILE = nova.db.sqlalchemy.migrate_repo.__file__ self.REPOSITORY = repository.Repository( os.path.abspath(os.path.dirname(self.MIGRATE_FILE))) def setUp(self): super(TestNovaMigrationsSync, self).setUp() if self.migration is None: self.migration = __import__('nova.db.migration', globals(), locals(), ['INIT_VERSION'], -1) self.INIT_VERSION = self.migration.INIT_VERSION if self.migration_api is None: temp = __import__('nova.db.sqlalchemy.migration', globals(), locals(), ['versioning_api'], -1) self.migration_api = temp.versioning_api def tearDown(self): #needs for testing pass def test_list_of_tables(self): if not test_migrations._have_mysql(self.USER, self.PASSWD, self.DATABASE): self.skipTest(""mysql not available"") connect_string = test_migrations._get_connect_string(""mysql"", self.USER, self.PASSWD, self.DATABASE) (user, password, database, host) = \ test_migrations.get_mysql_connection_info( urlparse.urlparse(connect_string)) engine = sqlalchemy.create_engine(connect_string) self.engines[database] = engine self.test_databases[database] = connect_string #Section commented for testing # self._reset_databases() # self._walk_versions(engine, False, False) metadata = MetaData(bind=engine, reflect=True) db_tables = metadata.tables check_tables = set(db_tables.keys()) - set(['migrate_version']) models_tables = inspect.getmembers(models, inspect.isclass) self.errors = [] for name, obj in models_tables: if issubclass(obj, models.BASE) and obj != models.BASE: table = obj.__table__ table_name = table.name self.assertEqual(table_name not in check_tables, False, message=""Table `%s` is missing in "" ""migrations."" % (table_name,)) self.db_indexes = dict([(index.name, index) for index in db_tables[table_name].indexes]) self._check_columns(table, db_tables[table_name]) self._check_uniques(table, db_tables[table_name]) self._check_fkeys(table, db_tables[table_name]) self._check_indexes(table, db_tables[table_name]) check_tables = check_tables - set([table_name, 'shadow_' + table_name]) self.assertEqual(check_tables, set([]), message=""Tables %s are not presented in "" ""models."" % ("","".join(check_tables))) self.assertEqual(1,0) def _check_column_type(self, column_model, column_db, column_name, table_name): msg = ""Wrong type for column `%s` in `%s`"" % (column_name, table_name) if issubclass(column_model.type.__class__, sqlalchemy.types.Boolean): self.assertEqual(issubclass(column_db.type.__class__, sqlalchemy.types.Integer), True, message=msg) elif issubclass(column_model.type.__class__, sqlalchemy.types.TypeDecorator): impl = column_model.type.__class__.impl.impl self.assertEqual(issubclass(column_db.type.__class__, impl.__class__), True, message=msg) else: self.assertEqual(issubclass(column_db.type.__class__, column_model.type.__class__), True, message=msg) model_column_type_len = getattr(column_model.type, 'length', None) db_column_type_len = getattr(column_db.type, 'length', None) self.assertEqual(model_column_type_len, db_column_type_len, message=""Wrong length for column %s in "" ""`%s` (model: %s, "" ""db: %s)"" % (column_name, table_name, model_column_type_len, db_column_type_len)) def _check_columns(self, table_model, table_db): table_name = table_model.name check_attrs = [ 'nullable', 'unique', 'primary_key', 'index' ] db_columns = set(table_db.c.keys()) model_columns = set(table_model.c.keys()) diff_columns = db_columns.symmetric_difference(model_columns) self.assertEqual(diff_columns, set([]), message=""Undefined columns in table "" ""`%s`: %s"" % (table_name, "","".join(diff_columns),)) for column_name in table_model.c.keys(): column_model = table_model.c[column_name] column_db = table_db.c[column_name] self._check_column_type(column_model, column_db, column_name, table_name) if column_db.default is not None: self.assertEqual(column_db.default, column_model.default, message=""Wrong default value in models for "" ""`%s.%s`"" % (table_name, column_name,)) for attr in check_attrs: model_attr = getattr(column_model, attr) db_attr = getattr(column_db, attr) self.assertEqual(model_attr, db_attr, message=""Wrong value for `%s` attribute in "" ""`%s.%s` (models:%s, "" ""db:%s)"" % (attr, table_name, column_name, model_attr, db_attr)) def _check_indexes(self, table_model, table_db): """"""Base checking of index constraint. This test checks name and columns in index"""""" table_name = table_model.name model_indexes = dict([(index.name, index) for index in table_model.indexes]) diff_indexes = set(self.db_indexes.keys()).symmetric_difference( set(model_indexes.keys())) self.assertEqual(diff_indexes, set([]), message=""Undefined indexes for table `%s`: "" ""%s"" % (table_name, "","".join(diff_indexes))) for index_name in self.db_indexes.keys(): db_index_c = set([c.name for c in self.db_indexes[index_name].columns]) model_index_c = set([c.name for c in model_indexes[index_name].columns]) diff_index_c = db_index_c.symmetric_difference(model_index_c) self.assertEqual(diff_index_c, set([]), message=""Columns `%s` in index `%s.%s` are "" ""missing."" % ("","".join(diff_index_c), table_name, index_name)) def _check_fkeys(self, table_model, table_db): table_name = table_model.name constraint_class = sqlalchemy.schema.ForeignKeyConstraint constraint_label = ""ForeignKeyConstraint"" constraint_keys = [c for c in table_model.constraints if isinstance(c, constraint_class)] for constraint in constraint_keys: constraint_name = constraint.name or constraint.columns[0].name self.assertEqual(constraint_name in self.db_indexes, True, message=""%s `%s.%s` declared in "" ""models is skipped in migrations."" % (constraint_label, table_name, constraint_name)) db_index = self.db_indexes.pop(constraint_name) self._get_diff(db_index.columns.keys(), [c.name for c in constraint.columns], constraint_label, constraint_name, table_name) def _check_uniques(self, table_model, table_db): table_name = table_model.name constraint_class = sqlalchemy.schema.UniqueConstraint constraint_label = ""UniqueConstraint"" constraint_keys = [c for c in table_model.constraints if isinstance(c, constraint_class)] for constraint in constraint_keys: constraint_name = constraint.name or constraint.columns.keys()[0] self.assertEqual(constraint_name in self.db_indexes, True, message=""%s `%s.%s` declared in "" ""models is skipped in migrations."" % (constraint_label, table_name, constraint_name)) db_index = self.db_indexes.pop(constraint_name) self._get_diff(db_index.columns.keys(), constraint.columns.keys(), constraint_label, constraint_name, table_name) def _get_diff(self, db_obj, model_obj, obj_label, obj_name, table_name): obj_diff = set(db_obj).symmetric_difference(set(model_obj)) self.assertEqual(obj_diff, set([]), message=""%s `%s.%s` have a difference with migrations : "" ""(%s)"" % (obj_label, table_name, obj_name, "","".join(obj_diff))) ",,278,0
openstack%2Fnova~master~Idf89daa0498849d64eaac6d28c1d6d6f40e248c7,openstack/nova,master,Idf89daa0498849d64eaac6d28c1d6d6f40e248c7,Replace deprecated assertEquals with assertEqual,ABANDONED,2013-07-06 19:41:23.000000000,2013-07-23 06:03:08.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 6873}]","[{'number': 1, 'created': '2013-07-06 19:41:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a88540f1feb4a11240710386996ded29c765c9d', 'message': 'Replace deprecated assertEquals with assertEqual\n\nassertEqual is deprecated as of python 2.7. Change the codebase to\nuse the non-deprecated alias. Also, add in some flake8 ignores to\nfuture-proof against hacking trunk changes.\n\nChange-Id: Idf89daa0498849d64eaac6d28c1d6d6f40e248c7\n'}, {'number': 2, 'created': '2013-07-10 17:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/03a374daf9aeaac3bbcd37abe8a2b7020a4a246f', 'message': 'Replace deprecated assertEquals with assertEqual\n\nassertEqual is deprecated as of python 2.7. Change the codebase to\nuse the non-deprecated alias. Also, add in some flake8 ignores to\nfuture-proof against hacking trunk changes.\n\nChange-Id: Idf89daa0498849d64eaac6d28c1d6d6f40e248c7\n'}, {'number': 3, 'created': '2013-07-12 01:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/99381ece2b999974e8514a11413b16bd8da46cad', 'message': 'Replace deprecated assertEquals with assertEqual\n\nassertEqual is deprecated as of python 2.7. Change the codebase to\nuse the non-deprecated alias.\n\nChange-Id: Idf89daa0498849d64eaac6d28c1d6d6f40e248c7\n'}, {'number': 4, 'created': '2013-07-15 07:00:10.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_instance_usage_audit_log.py', 'nova/tests/api/openstack/compute/contrib/test_networks.py', 'nova/tests/api/openstack/compute/test_server_actions.py', 'nova/tests/test_notifications.py', 'nova/tests/virt/xenapi/test_xenapi.py', 'nova/tests/api/openstack/compute/contrib/test_config_drive.py', 'nova/tests/api/openstack/compute/test_api.py', 'nova/tests/virt/disk/test_nbd.py', 'nova/tests/virt/libvirt/test_libvirt_blockinfo.py', 'nova/tests/virt/test_virt_disk.py', 'nova/tests/compute/test_compute_utils.py', 'nova/tests/test_instance_types_extra_specs.py', 'nova/tests/virt/baremetal/test_volume_driver.py', 'nova/tests/virt/test_virt_disk_vfs_localfs.py', 'nova/tests/test_ipv6.py', 'nova/tests/api/ec2/test_faults.py', 'nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/tests/api/openstack/compute/contrib/test_security_groups.py', 'nova/tests/network/test_api.py', 'nova/tests/api/openstack/compute/contrib/test_neutron_security_groups.py', 'nova/tests/api/openstack/compute/contrib/test_keypairs.py', 'nova/tests/api/openstack/compute/contrib/test_volumes.py', 'nova/tests/virt/libvirt/test_libvirt_vif.py', 'nova/tests/api/openstack/compute/plugins/v3/test_security_groups.py', 'nova/tests/network/test_neutronv2.py', 'nova/tests/virt/test_virt_disk_vfs_guestfs.py', 'nova/tests/virt/libvirt/test_libvirt.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py', 'smoketests/test_sysadmin.py', 'nova/tests/api/openstack/compute/contrib/test_security_group_default_rules.py', 'nova/tests/network/test_manager.py', 'nova/tests/image/test_glance.py', 'nova/tests/test_objectstore.py', 'nova/tests/test_nova_manage.py', 'nova/tests/api/openstack/compute/contrib/test_flavorextradata.py', 'nova/tests/api/openstack/test_common.py', 'nova/tests/api/openstack/compute/contrib/test_instance_usage_audit_log.py', 'nova/tests/api/openstack/compute/plugins/v3/test_config_drive.py', 'nova/tests/api/ec2/test_api.py', 'nova/tests/test_availability_zones.py', 'nova/tests/virt/test_driver.py', 'nova/tests/cells/test_cells_messaging.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/tests/virt/baremetal/db/test_bm_node.py', 'nova/tests/compute/test_compute.py', 'nova/tests/network/test_linux_net.py', 'nova/tests/test_exception.py', 'nova/tests/api/openstack/compute/plugins/v3/test_scheduler_hints.py', 'nova/tests/compute/test_stats.py', 'nova/tests/api/openstack/compute/plugins/v3/test_keypairs.py', 'nova/tests/test_context.py', 'nova/tests/virt/libvirt/test_imagecache.py', 'nova/tests/db/test_db_api.py', 'nova/tests/virt/libvirt/test_fakelibvirt.py', 'nova/tests/virt/powervm/test_powervm.py', 'nova/tests/api/test_sizelimit.py', 'nova/tests/api/openstack/compute/test_servers.py', 'nova/tests/test_cinder.py', 'nova/tests/virt/libvirt/test_image_utils.py', 'nova/tests/image/test_fake.py', 'nova/tests/virt/xenapi/test_vmops.py', 'nova/tests/virt/xenapi/test_vm_utils.py', 'nova/tests/test_wsgi.py', 'nova/tests/api/openstack/compute/contrib/test_flavor_manage.py', 'nova/tests/scheduler/test_scheduler_options.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'nova/tests/virt/xenapi/test_volumeops.py', 'nova/tests/virt/disk/test_loop.py', 'nova/tests/api/openstack/compute/contrib/test_createserverext.py', 'nova/tests/scheduler/test_chance_scheduler.py', 'nova/tests/scheduler/test_filter_scheduler.py', 'nova/tests/virt/vmwareapi/test_vmwareapi_vm_util.py', 'nova/tests/test_block_device.py', 'nova/tests/virt/test_virt_drivers.py', 'nova/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/37af4d3f03e9cfab2e75812de5fba89ebbf08c25', 'message': 'Replace deprecated assertEquals with assertEqual\n\nassertEquals is deprecated as of python 2.7. Change the codebase to\nuse the non-deprecated alias.\n\nChange-Id: Idf89daa0498849d64eaac6d28c1d6d6f40e248c7\n'}]",4,35966,37af4d3f03e9cfab2e75812de5fba89ebbf08c25,17,5,4,2,,,0,"Replace deprecated assertEquals with assertEqual

assertEquals is deprecated as of python 2.7. Change the codebase to
use the non-deprecated alias.

Change-Id: Idf89daa0498849d64eaac6d28c1d6d6f40e248c7
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/35966/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/contrib/test_networks.py', 'nova/tests/api/openstack/compute/test_server_actions.py', 'nova/tests/test_notifications.py', 'nova/tests/virt/xenapi/test_xenapi.py', 'nova/tests/conductor/test_conductor.py', 'nova/tests/api/openstack/compute/contrib/test_quantum_security_groups.py', 'nova/tests/api/openstack/compute/contrib/test_config_drive.py', 'nova/tests/api/openstack/compute/test_api.py', 'nova/tests/virt/disk/test_nbd.py', 'nova/tests/virt/libvirt/test_libvirt_blockinfo.py', 'nova/tests/virt/test_virt_disk.py', 'nova/tests/compute/test_compute_utils.py', 'nova/tests/test_instance_types_extra_specs.py', 'nova/tests/virt/baremetal/test_volume_driver.py', 'nova/tests/network/test_quantumv2.py', 'nova/tests/virt/test_virt_disk_vfs_localfs.py', 'nova/tests/test_ipv6.py', 'nova/tests/api/ec2/test_faults.py', 'nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/tests/api/openstack/compute/contrib/test_security_groups.py', 'nova/tests/network/test_api.py', 'nova/tests/api/openstack/compute/contrib/test_keypairs.py', 'nova/tests/api/openstack/compute/contrib/test_volumes.py', 'nova/tests/virt/libvirt/test_libvirt_vif.py', 'nova/tests/virt/test_virt_disk_vfs_guestfs.py', 'nova/tests/virt/libvirt/test_libvirt.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py', 'smoketests/test_sysadmin.py', 'nova/tests/api/openstack/compute/contrib/test_security_group_default_rules.py', 'nova/tests/network/test_manager.py', 'tox.ini', 'nova/tests/image/test_glance.py', 'nova/tests/test_objectstore.py', 'nova/tests/test_nova_manage.py', 'nova/tests/api/openstack/compute/contrib/test_flavorextradata.py', 'nova/tests/api/openstack/test_common.py', 'nova/tests/api/openstack/compute/contrib/test_instance_usage_audit_log.py', 'nova/tests/api/ec2/test_api.py', 'nova/tests/test_availability_zones.py', 'nova/tests/virt/test_driver.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/tests/virt/baremetal/db/test_bm_node.py', 'nova/tests/compute/test_compute.py', 'nova/tests/network/test_linux_net.py', 'nova/tests/test_exception.py', 'nova/tests/compute/test_stats.py', 'nova/tests/api/openstack/compute/plugins/v3/test_keypairs.py', 'nova/tests/test_context.py', 'nova/tests/virt/libvirt/test_imagecache.py', 'nova/tests/db/test_db_api.py', 'nova/tests/virt/libvirt/test_fakelibvirt.py', 'nova/tests/virt/powervm/test_powervm.py', 'nova/tests/api/test_sizelimit.py', 'nova/tests/api/openstack/compute/test_servers.py', 'nova/tests/test_cinder.py', 'nova/tests/virt/libvirt/test_image_utils.py', 'nova/tests/image/test_fake.py', 'nova/tests/virt/xenapi/test_vmops.py', 'nova/tests/virt/xenapi/test_vm_utils.py', 'nova/tests/test_wsgi.py', 'nova/tests/api/openstack/compute/contrib/test_flavor_manage.py', 'nova/tests/scheduler/test_scheduler_options.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'nova/tests/virt/xenapi/test_volumeops.py', 'nova/tests/virt/disk/test_loop.py', 'nova/tests/api/openstack/compute/contrib/test_createserverext.py', 'nova/tests/scheduler/test_chance_scheduler.py', 'nova/tests/scheduler/test_filter_scheduler.py', 'nova/tests/virt/vmwareapi/test_vmwareapi_vm_util.py', 'nova/tests/test_block_device.py', 'nova/tests/virt/test_virt_drivers.py', 'nova/tests/test_utils.py']",72,5a88540f1feb4a11240710386996ded29c765c9d,build-updates," self.assertEqual(expected_value, b_value) self.assertEqual(expected_value * -1, b_value) self.assertEqual([], f(input, ""a"")) self.assertEqual([], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([], f(input, ""a"")) self.assertEqual([], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([], f(input, ""a"")) self.assertEqual([], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([{'b': None}], f(input, ""a"")) self.assertEqual([], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([{'b': {'c': None}}], f(input, ""a"")) self.assertEqual([{'c': None}], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([{'b': {'c': None}}], f(input, ""a"")) self.assertEqual([{'c': None}], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([{'b': {'c': None}}, {'b': None}], f(input, ""a"")) self.assertEqual([{'c': None}], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual(['a_1'], f(input, ""a"")) self.assertEqual([], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([{'b': 'b_1'}], f(input, ""a"")) self.assertEqual(['b_1'], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([{'b': {'c': 'c_1'}}], f(input, ""a"")) self.assertEqual([{'c': 'c_1'}], f(input, ""a/b"")) self.assertEqual(['c_1'], f(input, ""a/b/c"")) self.assertEqual([{'b': {'c': 'c_1'}}], f(input, ""a"")) self.assertEqual([{'c': 'c_1'}], f(input, ""a/b"")) self.assertEqual(['c_1'], f(input, ""a/b/c"")) self.assertEqual([{'b': {'c': 'c_1'}}, {'b': None}], f(input, ""a"")) self.assertEqual([{'c': 'c_1'}], f(input, ""a/b"")) self.assertEqual(['c_1'], f(input, ""a/b/c"")) self.assertEqual([{'b': {'c': 'c_1'}}, {'b': {'c': 'c_2'}}], self.assertEqual([{'c': 'c_1'}, {'c': 'c_2'}], f(input, ""a/b"")) self.assertEqual(['c_1', 'c_2'], f(input, ""a/b/c"")) self.assertEqual([], f(input, ""a/b/c/d"")) self.assertEqual([], f(input, ""c/a/b/d"")) self.assertEqual([], f(input, ""i/r/t"")) self.assertEqual([1, 2, 3], f(input, ""a"")) self.assertEqual([], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([{'b': [1, 2, 3]}], f(input, ""a"")) self.assertEqual([1, 2, 3], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([1, 2, 3, 4, 5, 6], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([1, 2, 3, 4, 5, 6], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([1, 2, {'b': 'b_1'}], f(input, ""a"")) self.assertEqual(['b_1'], f(input, ""a/b"")) self.assertEqual(['192.168.0.3'], private_ips) self.assertEqual(['1.2.3.4'], public_ips) self.assertEqual([1, 2, 3], f(input, ""a"")) self.assertEqual([], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([{'b': [1, 2, 3]}], f(input, ""a"")) self.assertEqual([1, 2, 3], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([1, 2, 3, 4, 5, 6], f(input, ""a/b"")) self.assertEqual([], f(input, ""a/b/c"")) self.assertEqual([1, 2, {'b': 'b_1'}], f(input, ""a"")) self.assertEqual(['b_1'], f(input, ""a/b"")) self.assertEqual(h1, h2) self.assertEqual(""abcd:ef01:2345:6789:abcd:ef01:c0a8:fefe"", self.assertEqual(""::1"", utils.get_shortened_ipv6( self.assertEqual(""caca::caca:0:babe:201:102"", self.assertEqual(""2600::/64"", utils.get_shortened_ipv6_cidr( self.assertEqual(""2600::/64"", utils.get_shortened_ipv6_cidr( self.assertEqual(begin, datetime.datetime( self.assertEqual(end, datetime.datetime( self.assertEqual(begin, datetime.datetime( self.assertEqual(end, datetime.datetime( self.assertEqual(begin, datetime.datetime( self.assertEqual(end, datetime.datetime( self.assertEqual(begin, datetime.datetime( self.assertEqual(end, datetime.datetime( self.assertEqual(begin, datetime.datetime( self.assertEqual(end, datetime.datetime( self.assertEqual(begin, datetime.datetime( self.assertEqual(end, datetime.datetime( self.assertEqual(begin, datetime.datetime( self.assertEqual(end, datetime.datetime( self.assertEqual(begin, datetime.datetime( self.assertEqual(end, datetime.datetime( self.assertEqual(begin, datetime.datetime( self.assertEqual(end, datetime.datetime( self.assertEqual(begin, datetime.datetime( self.assertEqual(end, datetime.datetime( self.assertEqual(begin, datetime.datetime( self.assertEqual(end, datetime.datetime( self.assertEqual(begin, datetime.datetime( self.assertEqual(end, datetime.datetime("," self.assertEquals(expected_value, b_value) self.assertEquals(expected_value * -1, b_value) self.assertEquals([], f(input, ""a"")) self.assertEquals([], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([], f(input, ""a"")) self.assertEquals([], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([], f(input, ""a"")) self.assertEquals([], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([{'b': None}], f(input, ""a"")) self.assertEquals([], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([{'b': {'c': None}}], f(input, ""a"")) self.assertEquals([{'c': None}], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([{'b': {'c': None}}], f(input, ""a"")) self.assertEquals([{'c': None}], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([{'b': {'c': None}}, {'b': None}], f(input, ""a"")) self.assertEquals([{'c': None}], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals(['a_1'], f(input, ""a"")) self.assertEquals([], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([{'b': 'b_1'}], f(input, ""a"")) self.assertEquals(['b_1'], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([{'b': {'c': 'c_1'}}], f(input, ""a"")) self.assertEquals([{'c': 'c_1'}], f(input, ""a/b"")) self.assertEquals(['c_1'], f(input, ""a/b/c"")) self.assertEquals([{'b': {'c': 'c_1'}}], f(input, ""a"")) self.assertEquals([{'c': 'c_1'}], f(input, ""a/b"")) self.assertEquals(['c_1'], f(input, ""a/b/c"")) self.assertEquals([{'b': {'c': 'c_1'}}, {'b': None}], f(input, ""a"")) self.assertEquals([{'c': 'c_1'}], f(input, ""a/b"")) self.assertEquals(['c_1'], f(input, ""a/b/c"")) self.assertEquals([{'b': {'c': 'c_1'}}, {'b': {'c': 'c_2'}}], self.assertEquals([{'c': 'c_1'}, {'c': 'c_2'}], f(input, ""a/b"")) self.assertEquals(['c_1', 'c_2'], f(input, ""a/b/c"")) self.assertEquals([], f(input, ""a/b/c/d"")) self.assertEquals([], f(input, ""c/a/b/d"")) self.assertEquals([], f(input, ""i/r/t"")) self.assertEquals([1, 2, 3], f(input, ""a"")) self.assertEquals([], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([{'b': [1, 2, 3]}], f(input, ""a"")) self.assertEquals([1, 2, 3], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([1, 2, 3, 4, 5, 6], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([1, 2, 3, 4, 5, 6], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([1, 2, {'b': 'b_1'}], f(input, ""a"")) self.assertEquals(['b_1'], f(input, ""a/b"")) self.assertEquals(['192.168.0.3'], private_ips) self.assertEquals(['1.2.3.4'], public_ips) self.assertEquals([1, 2, 3], f(input, ""a"")) self.assertEquals([], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([{'b': [1, 2, 3]}], f(input, ""a"")) self.assertEquals([1, 2, 3], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([1, 2, 3, 4, 5, 6], f(input, ""a/b"")) self.assertEquals([], f(input, ""a/b/c"")) self.assertEquals([1, 2, {'b': 'b_1'}], f(input, ""a"")) self.assertEquals(['b_1'], f(input, ""a/b"")) self.assertEquals(h1, h2) self.assertEquals(""abcd:ef01:2345:6789:abcd:ef01:c0a8:fefe"", self.assertEquals(""::1"", utils.get_shortened_ipv6( self.assertEquals(""caca::caca:0:babe:201:102"", self.assertEquals(""2600::/64"", utils.get_shortened_ipv6_cidr( self.assertEquals(""2600::/64"", utils.get_shortened_ipv6_cidr( self.assertEquals(begin, datetime.datetime( self.assertEquals(end, datetime.datetime( self.assertEquals(begin, datetime.datetime( self.assertEquals(end, datetime.datetime( self.assertEquals(begin, datetime.datetime( self.assertEquals(end, datetime.datetime( self.assertEquals(begin, datetime.datetime( self.assertEquals(end, datetime.datetime( self.assertEquals(begin, datetime.datetime( self.assertEquals(end, datetime.datetime( self.assertEquals(begin, datetime.datetime( self.assertEquals(end, datetime.datetime( self.assertEquals(begin, datetime.datetime( self.assertEquals(end, datetime.datetime( self.assertEquals(begin, datetime.datetime( self.assertEquals(end, datetime.datetime( self.assertEquals(begin, datetime.datetime( self.assertEquals(end, datetime.datetime( self.assertEquals(begin, datetime.datetime( self.assertEquals(end, datetime.datetime( self.assertEquals(begin, datetime.datetime( self.assertEquals(end, datetime.datetime( self.assertEquals(begin, datetime.datetime( self.assertEquals(end, datetime.datetime(",1343,1343
openstack%2Fnova~master~Ib13e831dc504c6d1c3d675a9a85c3d501842027c,openstack/nova,master,Ib13e831dc504c6d1c3d675a9a85c3d501842027c,Refactor test_update_* in current API tests and v3,ABANDONED,2013-06-28 06:50:02.000000000,2013-07-23 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 6509}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7727}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-06-28 06:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b7e8890a3fbcebc238c6c124cf44f9226f9f80c', 'message': 'Refactor test_update_* from test_servers.py in current API tests and v3.\n\n- Cleanup from copy-paste code.\n- Move all test_update to separate class.\n\nblueprint api-compute-servers-tests\n\nChange-Id: Ib13e831dc504c6d1c3d675a9a85c3d501842027c\n'}, {'number': 2, 'created': '2013-06-28 06:53:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cbd97e2451a4aab0a4584af501293ad898813cbb', 'message': 'Refactor test_update_* from test_servers.py in current API tests and v3.\n\n- Cleanup from copy-paste code.\n- Move all test_update to separate class.\n\nblueprint api-compute-servers-tests\n\nChange-Id: Ib13e831dc504c6d1c3d675a9a85c3d501842027c\n'}, {'number': 3, 'created': '2013-06-28 08:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a67270a363ea773bd8a2a53e5350662c469e55d8', 'message': 'Refactor test_update_* from test_servers.py in current API tests and v3.\n\n- Cleanup from copy-paste code.\n- Move all test_update to separate class.\n\nblueprint api-compute-servers-tests\n\nChange-Id: Ib13e831dc504c6d1c3d675a9a85c3d501842027c\n'}, {'number': 4, 'created': '2013-06-28 10:10:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/857c9de652e68cdbae6877fe513460f9d2b13f99', 'message': 'Refactor test_update_* in current API tests and v3\n\n- Cleanup from copy-paste code.\n- Move all test_update to separate class.\n\nblueprint api-compute-servers-tests\n\nChange-Id: Ib13e831dc504c6d1c3d675a9a85c3d501842027c\n'}, {'number': 5, 'created': '2013-07-02 05:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/484434813128a7fb878b55504f6966d8aa25f209', 'message': 'Refactor test_update_* in current API tests and v3\n\n- Cleanup from copy-paste code.\n- Move all test_update to separate class.\n\nblueprint api-compute-servers-tests\n\nChange-Id: Ib13e831dc504c6d1c3d675a9a85c3d501842027c\n'}, {'number': 6, 'created': '2013-07-03 05:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/663596df2dae8a52bdbbf8fe713433190482597c', 'message': 'Refactor test_update_* in current API tests and v3\n\n- Cleanup from copy-paste code.\n- Move all test_update to separate class.\n\nblueprint api-compute-servers-tests\n\nChange-Id: Ib13e831dc504c6d1c3d675a9a85c3d501842027c\n'}, {'number': 7, 'created': '2013-07-03 05:54:10.000000000', 'files': ['nova/tests/api/openstack/compute/test_servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/da2b4c13cf39824709edca68820fd62816dcbe7c', 'message': 'Refactor test_update_* in current API tests and v3\n\n- Cleanup from copy-paste code.\n- Move all test_update to separate class.\n\nblueprint api-compute-servers-tests\n\nChange-Id: Ib13e831dc504c6d1c3d675a9a85c3d501842027c\n'}]",5,34849,da2b4c13cf39824709edca68820fd62816dcbe7c,27,8,7,7727,,,0,"Refactor test_update_* in current API tests and v3

- Cleanup from copy-paste code.
- Move all test_update to separate class.

blueprint api-compute-servers-tests

Change-Id: Ib13e831dc504c6d1c3d675a9a85c3d501842027c
",git fetch https://review.opendev.org/openstack/nova refs/changes/49/34849/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/openstack/compute/test_servers.py'],1,7b7e8890a3fbcebc238c6c124cf44f9226f9f80c,nova-tests-code-duplication,"class ControllerTest(test.TestCase): def setUp(self): super(ControllerTest, self).setUp() self.flags(verbose=True, use_ipv6=False) fakes.stub_out_rate_limiting(self.stubs) fakes.stub_out_key_pair_funcs(self.stubs) fake.stub_out_image_service(self.stubs) return_server = fakes.fake_instance_get() return_servers = fakes.fake_instance_get_all_by_filters() self.stubs.Set(db, 'instance_get_all_by_filters', return_servers) self.stubs.Set(db, 'instance_get_by_uuid', return_server) self.stubs.Set(db, 'instance_add_security_group', return_security_group) self.stubs.Set(db, 'instance_update_and_get_original', instance_update) self.ext_mgr = extensions.ExtensionManager() self.ext_mgr.extensions = {} self.controller = servers.Controller(self.ext_mgr) self.ips_controller = ips.Controller() policy.reset() policy.init() fake_network.stub_out_nw_api_get_instance_nw_info(self.stubs, spectacular=True) return_servers) instance_update) class ServersControllerUpdateTest(ControllerTest): def test_update_server_all_attributes(self): self.stubs.Set(db, 'instance_get', fakes.fake_instance_get(name='server_test', access_ipv4='0.0.0.0', access_ipv6='beef::0123')) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': { 'name': 'server_test', 'accessIPv4': '0.0.0.0', 'accessIPv6': 'beef::0123', }} req.body = jsonutils.dumps(body) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['name'], 'server_test') self.assertEqual(res_dict['server']['accessIPv4'], '0.0.0.0') self.assertEqual(res_dict['server']['accessIPv6'], 'beef::0123') def test_update_server_invalid_xml_raises_lookup(self): req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/xml' #xml request which raises LookupError req.body = """"""<?xml version=""1.0"" encoding=""TF-8""?> <metadata xmlns=""http://docs.openstack.org/compute/api/v1.1"" key=""Label""></meta>"""""" res = req.get_response(fakes.wsgi_app()) self.assertEqual(res.status_int, 400) def test_update_server_invalid_xml_raises_expat(self): req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/xml' #xml request which raises ExpatError req.body = """"""<?xml version=""1.0"" encoding=""UTF-8""?> <metadata xmlns=""http://docs.openstack.org/compute/api/v1.1"" key=""Label""></meta>"""""" res = req.get_response(fakes.wsgi_app()) self.assertEqual(res.status_int, 400) def test_update_server_name(self): self.stubs.Set(db, 'instance_get', fakes.fake_instance_get(name='server_test')) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'name': 'server_test'}} req.body = jsonutils.dumps(body) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['name'], 'server_test') def test_update_server_name_too_long(self): self.stubs.Set(db, 'instance_get', fakes.fake_instance_get(name='server_test')) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'name': 'x' * 256}} req.body = jsonutils.dumps(body) self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update, req, FAKE_UUID, body) def test_update_server_name_all_blank_spaces(self): self.stubs.Set(db, 'instance_get', fakes.fake_instance_get(name='server_test')) req = fakes.HTTPRequest.blank('/v2/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'name': ' ' * 64}} req.body = jsonutils.dumps(body) self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update, req, FAKE_UUID, body) def test_update_server_access_ipv4(self): self.stubs.Set(db, 'instance_get', fakes.fake_instance_get(access_ipv4='0.0.0.0')) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'accessIPv4': '0.0.0.0'}} req.body = jsonutils.dumps(body) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['accessIPv4'], '0.0.0.0') def test_update_server_access_ipv4_bad_format(self): self.stubs.Set(db, 'instance_get', fakes.fake_instance_get(access_ipv4='0.0.0.0')) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'accessIPv4': 'bad_format'}} req.body = jsonutils.dumps(body) self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update, req, FAKE_UUID, body) def test_update_server_access_ipv4_none(self): self.stubs.Set(db, 'instance_get', fakes.fake_instance_get(access_ipv4='0.0.0.0')) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'accessIPv4': None}} req.body = jsonutils.dumps(body) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['accessIPv4'], '') def test_update_server_access_ipv4_blank(self): self.stubs.Set(db, 'instance_get', fakes.fake_instance_get(access_ipv4='0.0.0.0')) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'accessIPv4': ''}} req.body = jsonutils.dumps(body) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['accessIPv4'], '') def test_update_server_access_ipv6(self): self.stubs.Set(db, 'instance_get', fakes.fake_instance_get(access_ipv6='beef::0123')) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'accessIPv6': 'beef::0123'}} req.body = jsonutils.dumps(body) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['accessIPv6'], 'beef::0123') def test_update_server_access_ipv6_bad_format(self): self.stubs.Set(db, 'instance_get', fakes.fake_instance_get(access_ipv6='beef::0123')) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'accessIPv6': 'bad_format'}} req.body = jsonutils.dumps(body) self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update, req, FAKE_UUID, body) def test_update_server_access_ipv6_none(self): self.stubs.Set(db, 'instance_get', fakes.fake_instance_get(access_ipv6='beef::0123')) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'accessIPv6': None}} req.body = jsonutils.dumps(body) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['accessIPv6'], '') def test_update_server_access_ipv6_blank(self): self.stubs.Set(db, 'instance_get', fakes.fake_instance_get(access_ipv6='beef::0123')) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'accessIPv6': ''}} req.body = jsonutils.dumps(body) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['accessIPv6'], '') def test_update_server_personality(self): req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = { 'server': { 'personality': [] } } req.body = jsonutils.dumps(body) self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update, req, FAKE_UUID, body) def test_update_server_adminPass_ignored(self): inst_dict = dict(name='server_test', adminPass='bacon') body = dict(server=inst_dict) def server_update(context, id, params): filtered_dict = { 'display_name': 'server_test', } self.assertEqual(params, filtered_dict) filtered_dict['uuid'] = id return filtered_dict self.stubs.Set(db, 'instance_update', server_update) # FIXME (comstud) # self.stubs.Set(db, 'instance_get', # return_server_with_attributes(name='server_test')) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = ""application/json"" req.body = jsonutils.dumps(body) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['name'], 'server_test') def test_update_server_not_found(self): def fake_get(*args, **kwargs): raise exception.InstanceNotFound(instance_id='fake') self.stubs.Set(compute_api.API, 'get', fake_get) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'name': 'server_test'}} req.body = jsonutils.dumps(body) self.assertRaises(webob.exc.HTTPNotFound, self.controller.update, req, FAKE_UUID, body) def test_update_server_not_found_on_update(self): def fake_update(*args, **kwargs): raise exception.InstanceNotFound(instance_id='fake') self.stubs.Set(compute_api.API, 'update', fake_update) req = fakes.HTTPRequest.blank('/fake/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'name': 'server_test'}} req.body = jsonutils.dumps(body) self.assertRaises(webob.exc.HTTPNotFound, self.controller.update, req, FAKE_UUID, body) ", return_servers) instance_update),280,2
openstack%2Fnova~master~I52406d2ce32b26ef67737e908415b06e3cc0ad87,openstack/nova,master,I52406d2ce32b26ef67737e908415b06e3cc0ad87,WIP Refactor run_instance/spawn,ABANDONED,2013-07-11 20:35:01.000000000,2013-07-23 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1849}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-11 20:35:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/60aedc5c8d7f8af3233452e2d3a60529a87445e9', 'message': 'WIP Refactor run_instance/spawn\n\nBreak down scheduling and building instances into steps to allow for\nfine grained retry logic of different steps.  Sets up the use of\nan orchestration library at a later time.\n\nVery rough right now, just laying a foundation\n\nChange-Id: I52406d2ce32b26ef67737e908415b06e3cc0ad87\n'}, {'number': 2, 'created': '2013-07-11 21:01:09.000000000', 'files': ['nova/virt/driver.py', 'nova/conductor/tasks/build_instance.py', 'nova/conductor/manager.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b2fa99bfb85d74a9489b2e09f3ec5c29e3747f4c', 'message': 'WIP Refactor run_instance/spawn\n\nBreak down scheduling and building instances into steps to allow for\nfine grained retry logic of different steps.  Sets up the use of\nan orchestration library at a later time.\n\nVery rough right now, just laying a foundation\n\npart of bp query-scheduler\n\nChange-Id: I52406d2ce32b26ef67737e908415b06e3cc0ad87\n'}]",1,36729,b2fa99bfb85d74a9489b2e09f3ec5c29e3747f4c,6,4,2,5441,,,0,"WIP Refactor run_instance/spawn

Break down scheduling and building instances into steps to allow for
fine grained retry logic of different steps.  Sets up the use of
an orchestration library at a later time.

Very rough right now, just laying a foundation

part of bp query-scheduler

Change-Id: I52406d2ce32b26ef67737e908415b06e3cc0ad87
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/36729/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/driver.py', 'nova/conductor/manager.py', 'nova/conductor/tasks/build_instance.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py']",5,60aedc5c8d7f8af3233452e2d3a60529a87445e9,bp/query-scheduler," 2.30 - Adds supports_build_instance(), allocate_network(), claim_instance(), abort_claim() def supports_build_instance(self, ctxt, host): return self.call(ctxt, self.make_msg('supports_build_instance'), topic=_compute_topic(self.topic, ctxt, host, None), version='2.30') def allocate_network(self, ctxt, instance, security_groups, host): instance_p = jsonutils.to_primitive(instance) return self.call(ctxt, self.make_msg('allocate_network', instance=instance_p, security_groups=security_groups), topic=_compute_topic(self.topic, ctxt, host, None), version='2.30') def claim_instance(self, ctxt, instance, host, node, limits): instance_p = jsonutils.to_primitive(instance) return self.call(ctxt, self.make_msg('claim_instance', instance=instance_p, node=node, limits=limits), topic=_compute_topic(self.topic, ctxt, host, None), version='2.30') def abort_claim(self, ctxt, host, claim_id): return self.call(ctxt, self.make_msg('abort_claim', claim_id=claim_id), topic=_compute_topic(self.topic, ctxt, host, None), version='2.30') ",,237,7
openstack%2Fnova~master~Icb7b4422cad72ede3501b81ef87702c2ffba02c7,openstack/nova,master,Icb7b4422cad72ede3501b81ef87702c2ffba02c7,Add 405 response with allowed methods list,ABANDONED,2013-06-12 14:20:01.000000000,2013-07-23 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2166}, {'_account_id': 5174}, {'_account_id': 5292}]","[{'number': 1, 'created': '2013-06-12 14:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c36f736b96cc766b92da794f318cd0576f8abb45', 'message': ""Add 405 response with allowed methods list\n\nWith this change we're able to give a proper response when a request is done\nagainst an api entry point with a invalid method.\nSo now if you try, for instance, a DELETE against /servers you will get 405\nresponse, NotAllowedMethod and a list of valid methods against that same entry\npoint.\n\nImplements bp v3-api-return-allowed-methods\n\nChange-Id: Icb7b4422cad72ede3501b81ef87702c2ffba02c7\n""}, {'number': 2, 'created': '2013-06-28 14:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/02c57d0244f3a65d49cf86971ab414050c49776a', 'message': ""Add 405 response with allowed methods list\n\nWith this change we're able to give a proper response when a request is done\nagainst an api entry point with a invalid method.\nSo now if you try, for instance, a DELETE against /servers you will get 405\nresponse, NotAllowedMethod and a list of valid methods against that same entry\npoint.\n\nImplements bp v3-api-return-allowed-methods\n\nChange-Id: Icb7b4422cad72ede3501b81ef87702c2ffba02c7\n""}, {'number': 3, 'created': '2013-07-01 10:38:09.000000000', 'files': ['nova/api/openstack/__init__.py', 'nova/tests/api/openstack/test_mapper.py', 'nova/wsgi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d43d9e715876a9bab207f053fe3d7504facd7ee4', 'message': ""Add 405 response with allowed methods list\n\nWith this change we're able to give a proper response when a request is done\nagainst an api entry point with a invalid method.\nSo now if you try, for instance, a DELETE against /servers you will get 405\nresponse, NotAllowedMethod and a list of valid methods against that same entry\npoint.\n\nImplements bp v3-api-return-allowed-methods\n\nChange-Id: Icb7b4422cad72ede3501b81ef87702c2ffba02c7\n""}]",9,32728,d43d9e715876a9bab207f053fe3d7504facd7ee4,15,5,3,5174,,,0,"Add 405 response with allowed methods list

With this change we're able to give a proper response when a request is done
against an api entry point with a invalid method.
So now if you try, for instance, a DELETE against /servers you will get 405
response, NotAllowedMethod and a list of valid methods against that same entry
point.

Implements bp v3-api-return-allowed-methods

Change-Id: Icb7b4422cad72ede3501b81ef87702c2ffba02c7
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/32728/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/__init__.py', 'nova/wsgi.py']",2,c36f736b96cc766b92da794f318cd0576f8abb45,bp/v3-api-return-allowed-methods," # NOTE(maurosr): this only happens in v3 api since it's the only # api with valid_url check. url = req.environ.get('valid_url', None) if url: msg = _(""The method %s is not allowed for %s resource."" ""\nAllowed methods: %s"") % (req.environ['REQUEST_METHOD'], url, req.environ['valid_methods']) raise webob.exc.HTTPMethodNotAllowed(msg)",,50,0
openstack%2Fnova~master~I905288eda0a2d392abd25399b4dfe53e70ca825d,openstack/nova,master,I905288eda0a2d392abd25399b4dfe53e70ca825d,Refactor test_evacuate.,ABANDONED,2013-07-02 10:59:12.000000000,2013-07-23 06:03:06.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 5174}, {'_account_id': 6509}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7711}, {'_account_id': 7727}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-07-02 10:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/931e977984b708cd9a9ed0d40586752e88f44873', 'message': 'Refactor test_evacuate.\n\n-Cleanup from copy-paste code.\n\nblueprint nova-tests-code-duplication\n\nChange-Id: I905288eda0a2d392abd25399b4dfe53e70ca825d\n'}, {'number': 2, 'created': '2013-07-03 05:48:31.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_evacuate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/587db080a55c9676bb7181efea0191e67ae90fe3', 'message': 'Refactor test_evacuate.\n\n-Cleanup from copy-paste code.\n\nblueprint nova-tests-code-duplication\n\nChange-Id: I905288eda0a2d392abd25399b4dfe53e70ca825d\n'}]",4,35271,587db080a55c9676bb7181efea0191e67ae90fe3,14,11,2,7727,,,0,"Refactor test_evacuate.

-Cleanup from copy-paste code.

blueprint nova-tests-code-duplication

Change-Id: I905288eda0a2d392abd25399b4dfe53e70ca825d
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/35271/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/openstack/compute/plugins/v3/test_evacuate.py'],1,931e977984b708cd9a9ed0d40586752e88f44873,nova-tests-code-duplication," def _fake_update(inst, context, instance, task_state, expected_task_state): return None def _gen_reqest_with_app(self, json_load={}): base_json_load = { 'evacuate': { 'onSharedStorage': 'False'}} base_json_load['evacuate'].update(json_load) req.body = jsonutils.dumps(base_json_load) return (req,app) def test_evacuate_instance_with_no_target(self): req, app = self._gen_reqest_with_app({'adminPass': 'MyNewPass'}) req, app = self._gen_reqest_with_app({'host': 'my_host', 'adminPass': 'MyNewPass'}) self.stubs.Set(compute_api.API, 'update', self._fake_update) req, app = self._gen_reqest_with_app({'host': 'my_host', 'adminPass': 'MyNewPass', 'onSharedStorage': 'True'}) self.stubs.Set(compute_api.API, 'update', self._fake_update) req, app = self._gen_reqest_with_app({'host': 'my_host'}) self.stubs.Set(compute_api.API, 'update', self._fake_update) req, app = self._gen_reqest_with_app({'host': 'my_host', 'onSharedStorage': 'True'}) self.stubs.Set(compute_api.API, 'update', self._fake_update)"," def test_evacuate_instance_with_no_target(self): req.body = jsonutils.dumps({ 'evacuate': { 'onSharedStorage': 'False', 'adminPass': 'MyNewPass' } }) ctxt = context.get_admin_context() ctxt.user_id = 'fake' ctxt.project_id = 'fake' ctxt.is_admin = True app = fakes.wsgi_app_v3(fake_auth_context=ctxt) uuid1 = self.UUID req = webob.Request.blank('/v3/servers/%s/action' % uuid1) req.method = 'POST' req.body = jsonutils.dumps({ 'evacuate': { 'host': 'my_host', 'onSharedStorage': 'false', 'adminPass': 'MyNewPass' } }) req.content_type = 'application/json' def fake_update(inst, context, instance, task_state, expected_task_state): return None self.stubs.Set(compute_api.API, 'update', fake_update) ctxt = context.get_admin_context() ctxt.user_id = 'fake' ctxt.project_id = 'fake' ctxt.is_admin = True app = fakes.wsgi_app_v3(fake_auth_context=ctxt) uuid1 = self.UUID req = webob.Request.blank('/v3/servers/%s/action' % uuid1) req.method = 'POST' req.body = jsonutils.dumps({ 'evacuate': { 'host': 'my_host', 'onSharedStorage': 'True', 'adminPass': 'MyNewPass' } }) req.content_type = 'application/json' def fake_update(inst, context, instance, task_state, expected_task_state): return None self.stubs.Set(compute_api.API, 'update', fake_update) ctxt = context.get_admin_context() ctxt.user_id = 'fake' ctxt.project_id = 'fake' ctxt.is_admin = True app = fakes.wsgi_app_v3(fake_auth_context=ctxt) uuid1 = self.UUID req = webob.Request.blank('/v3/servers/%s/action' % uuid1) req.method = 'POST' req.body = jsonutils.dumps({ 'evacuate': { 'host': 'my_host', 'onSharedStorage': 'False', } }) req.content_type = 'application/json' def fake_update(inst, context, instance, task_state, expected_task_state): return None self.stubs.Set(compute_api.API, 'update', fake_update) ctxt = context.get_admin_context() ctxt.user_id = 'fake' ctxt.project_id = 'fake' ctxt.is_admin = True app = fakes.wsgi_app_v3(fake_auth_context=ctxt) uuid1 = self.UUID req = webob.Request.blank('/v3/servers/%s/action' % uuid1) req.method = 'POST' req.body = jsonutils.dumps({ 'evacuate': { 'host': 'my_host', 'onSharedStorage': 'True', } }) req.content_type = 'application/json' def fake_update(inst, context, instance, task_state, expected_task_state): return None self.stubs.Set(compute_api.API, 'update', fake_update) ",25,94
openstack%2Fnova~master~I95dcbefb5382a683ec93fd1cfdea11b57ab451d9,openstack/nova,master,I95dcbefb5382a683ec93fd1cfdea11b57ab451d9,Added transactional annotation to _build_instance,ABANDONED,2013-06-18 15:23:43.000000000,2013-07-23 06:03:06.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2166}, {'_account_id': 6172}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-06-18 15:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9651d7cd4ef5693e04a25499ffa04de76263adb', 'message': 'Added transactional annotation to _build_instance\n\nblueprint transaction-manager\n\nFixes bug #1173413\n\nChange-Id: I95dcbefb5382a683ec93fd1cfdea11b57ab451d9\n'}, {'number': 2, 'created': '2013-06-18 16:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b8dba701f8c256dd4bbe42e721db972e68bd5d3', 'message': 'Added transactional annotation to _build_instance\n\nblueprint transaction-manager\n\nFixes bug #1173413\n\nChange-Id: I95dcbefb5382a683ec93fd1cfdea11b57ab451d9\n'}, {'number': 3, 'created': '2013-06-21 08:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0cf215dbdd83619d9cc435c3d789e7ce007c4b41', 'message': 'Added transactional annotation to _build_instance\n\nblueprint transaction-manager\n\nFixes bug #1173413\n\nChange-Id: I95dcbefb5382a683ec93fd1cfdea11b57ab451d9\n'}, {'number': 4, 'created': '2013-07-03 13:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c7bc64ca578129a3c12354554a740331dd5cf5c', 'message': 'Added transactional annotation to _build_instance\n\nblueprint transaction-manager\n\nFixes bug #1173413\n\nChange-Id: I95dcbefb5382a683ec93fd1cfdea11b57ab451d9\n'}, {'number': 5, 'created': '2013-07-03 14:21:23.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4700050c3735f4e1f6d903b103bff32ad4b7ee9e', 'message': 'Added transactional annotation to _build_instance\n\nblueprint transaction-manager\n\nFixes bug #1173413\n\nChange-Id: I95dcbefb5382a683ec93fd1cfdea11b57ab451d9\n'}]",3,33460,4700050c3735f4e1f6d903b103bff32ad4b7ee9e,18,5,5,7763,,,0,"Added transactional annotation to _build_instance

blueprint transaction-manager

Fixes bug #1173413

Change-Id: I95dcbefb5382a683ec93fd1cfdea11b57ab451d9
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/33460/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",2,f9651d7cd4ef5693e04a25499ffa04de76263adb,bug/1173413," fake_network.unset_stub_network_methods(self.stubs) self.mox.StubOutWithMock(network_api.API, 'deallocate_for_instance') network_api.API.deallocate_for_instance(mox.IgnoreArg(), mox.IgnoreArg())"," self.mox.StubOutWithMock(self.compute, '_deallocate_network') self.compute._deallocate_network(mox.IgnoreArg(), mox.IgnoreArg())",16,22
openstack%2Fzaqar~master~I655d52b4c92b6b0e40b158c2b7810c311ec3aaaa,openstack/zaqar,master,I655d52b4c92b6b0e40b158c2b7810c311ec3aaaa,Adds a framework for input-validation,ABANDONED,2013-07-10 22:32:02.000000000,2013-07-23 06:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6943}, {'_account_id': 6944}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-10 22:32:02.000000000', 'files': ['marconi/middleware/__init__.py', 'marconi/middleware/validation/validators.py', 'marconi/tests/middleware/validation/test_validation.py', 'marconi/middleware/validation/driver.py', 'marconi/common/decorators.py', 'marconi/common/exceptions.py', 'marconi/bootstrap.py', 'marconi/middleware/validation/__init__.py', 'marconi/tests/middleware/validation/__init__.py', 'marconi/tests/middleware/__init__.py', 'marconi/middleware/base.py', 'marconi/tests/middleware/validation/base.py', 'marconi/tests/common/test_decorators.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/938317acfd2409183b11e77632dff24ad2ae4f5a', 'message': 'Adds a framework for input-validation\n\nThis change implements the framework for input validation middleware.\nActual validation of the data passing between the transport and\nstorage layers will be implemented in subsequent patches.  The\nframework allows authors of validation routines to implement their\ncode in ""Validator"" classes (one each for Queues, Messages, and\nClaims).  Any methods with the same name as the underlying\ncontroller will execute prior to the original logic.  The expectation\nis that the validating routine will throw if a validation fails.\n\nChange-Id: I655d52b4c92b6b0e40b158c2b7810c311ec3aaaa\nImplements: blueprint input-validation\n'}]",21,36572,938317acfd2409183b11e77632dff24ad2ae4f5a,8,6,1,7044,,,0,"Adds a framework for input-validation

This change implements the framework for input validation middleware.
Actual validation of the data passing between the transport and
storage layers will be implemented in subsequent patches.  The
framework allows authors of validation routines to implement their
code in ""Validator"" classes (one each for Queues, Messages, and
Claims).  Any methods with the same name as the underlying
controller will execute prior to the original logic.  The expectation
is that the validating routine will throw if a validation fails.

Change-Id: I655d52b4c92b6b0e40b158c2b7810c311ec3aaaa
Implements: blueprint input-validation
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/72/36572/1 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/middleware/__init__.py', 'marconi/middleware/validation/validators.py', 'marconi/tests/middleware/validation/test_validation.py', 'marconi/middleware/validation/driver.py', 'marconi/common/decorators.py', 'marconi/common/exceptions.py', 'marconi/bootstrap.py', 'marconi/middleware/validation/__init__.py', 'marconi/tests/middleware/validation/__init__.py', 'marconi/tests/middleware/__init__.py', 'marconi/middleware/base.py', 'marconi/tests/middleware/validation/base.py', 'marconi/tests/common/test_decorators.py', 'setup.cfg']",14,938317acfd2409183b11e77632dff24ad2ae4f5a,bp/input-validation,marconi.middleware = validation = marconi.middleware.validation.driver:Driver ,,408,1
openstack%2Fneutron~master~I22e69ad3f9488867cb6bf70f7a79d77ea56f9222,openstack/neutron,master,I22e69ad3f9488867cb6bf70f7a79d77ea56f9222,add tox command to check for branches in migration,ABANDONED,2013-07-08 03:51:09.000000000,2013-07-23 06:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 2592}]","[{'number': 1, 'created': '2013-07-08 03:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/632e2848ee4fd53a4d017bbcc91ba9e761f9bc91', 'message': 'add tox command to check for branches in migration\n\nfixes bug: 1198792\n\nChange-Id: I22e69ad3f9488867cb6bf70f7a79d77ea56f9222\n'}, {'number': 2, 'created': '2013-07-08 04:05:48.000000000', 'files': ['neutron/common/legacy.py', 'neutron/db/migration/cli.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/697d93584ab6661389b506fbad328e9900fd0025', 'message': 'add tox command to check for branches in migration\n\nfixes bug: 1198792\n\nChange-Id: I22e69ad3f9488867cb6bf70f7a79d77ea56f9222\n'}]",0,36017,697d93584ab6661389b506fbad328e9900fd0025,8,2,2,2592,,,0,"add tox command to check for branches in migration

fixes bug: 1198792

Change-Id: I22e69ad3f9488867cb6bf70f7a79d77ea56f9222
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/36017/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/legacy.py', 'neutron/db/migration/cli.py', 'tox.ini']",3,632e2848ee4fd53a4d017bbcc91ba9e761f9bc91,bug/1198792, neutron-db-manage --config-file=etc/neutron.conf check_migration, ,5,2
openstack%2Fnova~master~Iaf3d062a7969653a922e30adee7a9c68fb751075,openstack/nova,master,Iaf3d062a7969653a922e30adee7a9c68fb751075,Invalid entries in OVS flow table using GRE Tunnels,ABANDONED,2013-07-07 06:50:41.000000000,2013-07-23 06:03:03.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2711}, {'_account_id': 2874}, {'_account_id': 4395}]","[{'number': 1, 'created': '2013-07-07 06:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10a7c21d52770ca22aeec04cedeb294ce61fd787', 'message': ""Invalid entries in OVS flow table using GRE Tunnels\n\nThe MAC addresses in the flows are wrong and don't match the\nones displayed by ifconfig or the ones shown in Wireshark.\n\nFixes the bug: 1154383\n\nChange-Id: Iaf3d062a7969653a922e30adee7a9c68fb751075\n""}, {'number': 2, 'created': '2013-07-10 10:33:30.000000000', 'files': ['nova/virt/libvirt/vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fdbe8fe9f9255c71735b700d9152aaad71dac4fa', 'message': ""Invalid entries in OVS flow table using GRE Tunnels\n\nThe VM can't ping outer network because\nThe MAC addresses in the flows are wrong and don't match the\nones displayed by ifconfig or the ones shown in Wireshark.\n\nFixes bug #1154383\n\nChange-Id: Iaf3d062a7969653a922e30adee7a9c68fb751075\n""}]",0,35984,fdbe8fe9f9255c71735b700d9152aaad71dac4fa,11,7,2,2711,,,0,"Invalid entries in OVS flow table using GRE Tunnels

The VM can't ping outer network because
The MAC addresses in the flows are wrong and don't match the
ones displayed by ifconfig or the ones shown in Wireshark.

Fixes bug #1154383

Change-Id: Iaf3d062a7969653a922e30adee7a9c68fb751075
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/35984/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/vif.py'],1,10a7c21d52770ca22aeec04cedeb294ce61fd787,bug/1154383," linux_net.create_tap_dev(dev, mapping['mac'])", linux_net.create_tap_dev(dev),1,1
openstack%2Fkeystone~master~I2c3ef3acf6520a964244ab66548fafb3cacc7c2e,openstack/keystone,master,I2c3ef3acf6520a964244ab66548fafb3cacc7c2e,Keystone reports internal error when policy.json is broken,ABANDONED,2013-06-25 09:20:20.000000000,2013-07-23 06:03:03.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 91}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 6486}, {'_account_id': 7302}]","[{'number': 1, 'created': '2013-06-25 09:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f07ceeb05644a163d1880f1c702d0899ba007701', 'message': 'Keystone reports internal error when policy.json is broken\n\nNeed to provide an enhanced message to client of what had happened to\nlet user have enough information\n\nChange-Id: I2c3ef3acf6520a964244ab66548fafb3cacc7c2e\nFixes: Bug 1177623\n'}, {'number': 2, 'created': '2013-06-26 01:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4fb0b06f9b9df1964a04550728a16222166ab291', 'message': 'Keystone reports internal error when policy.json is broken\n\nNeed to provide an enhanced message to client of what had happened to\nlet user have enough information\n\nChange-Id: I2c3ef3acf6520a964244ab66548fafb3cacc7c2e\nFixes: Bug 1177623\n'}, {'number': 3, 'created': '2013-07-12 06:54:03.000000000', 'files': ['keystone/policy/backends/rules.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/598cc409eb02950e3c0b278c881ea0806bfcccea', 'message': 'Keystone reports internal error when policy.json is broken\n\nNeed to provide an enhanced message to client of what had happened to\nlet user have enough information\n\nChange-Id: I2c3ef3acf6520a964244ab66548fafb3cacc7c2e\nFixes: Bug 1177623\n'}]",9,34339,598cc409eb02950e3c0b278c881ea0806bfcccea,24,8,3,7302,,,0,"Keystone reports internal error when policy.json is broken

Need to provide an enhanced message to client of what had happened to
let user have enough information

Change-Id: I2c3ef3acf6520a964244ab66548fafb3cacc7c2e
Fixes: Bug 1177623
",git fetch https://review.opendev.org/openstack/keystone refs/changes/39/34339/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/policy/backends/rules.py'],1,f07ceeb05644a163d1880f1c702d0899ba007701,bug/1177623," global _POLICY_PATH try: common_policy.set_rules(common_policy.Rules.load_json( data, default_rule)) except Exception as e: LOG.exception(e) raise ValueError(_('Could not parse policy file: %s ' % _POLICY_PATH + e.message))"," common_policy.set_rules(common_policy.Rules.load_json( data, default_rule))",8,2
openstack%2Fkeystone~master~I4284c2e2c062a14d315b527602acc3f94bf383ba,openstack/keystone,master,I4284c2e2c062a14d315b527602acc3f94bf383ba,Add documentation for Apache HTTPD config,ABANDONED,2013-06-24 15:31:50.000000000,2013-07-23 06:03:02.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 91}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6486}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-06-24 15:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/772a5888b13e82e3efc24a528984da194133813b', 'message': 'Add documentation for Apache HTTPD config\n\nThis change is non functional but adds documentation for running\nKeystone on Apache HTTPD.\n\nChange-Id: I4284c2e2c062a14d315b527602acc3f94bf383ba\n'}, {'number': 2, 'created': '2013-06-25 12:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5bcbac58fe31f49cb61f10f1022cb0079ddd6045', 'message': 'Add documentation for Apache HTTPD config\n\nThis change adds documentation for running Keystone on Apache HTTPD.\n\nChange-Id: I4284c2e2c062a14d315b527602acc3f94bf383ba\n'}, {'number': 3, 'created': '2013-06-25 12:57:44.000000000', 'files': ['doc/source/external-auth.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/667d0640552d59366762bb3c75124da8e7a8b219', 'message': 'Add documentation for Apache HTTPD config\n\nThis change adds documentation for running Keystone on Apache HTTPD to\nexternal-auth.rst.\n\nChange-Id: I4284c2e2c062a14d315b527602acc3f94bf383ba\n'}]",31,34226,667d0640552d59366762bb3c75124da8e7a8b219,22,9,3,5046,,,0,"Add documentation for Apache HTTPD config

This change adds documentation for running Keystone on Apache HTTPD to
external-auth.rst.

Change-Id: I4284c2e2c062a14d315b527602acc3f94bf383ba
",git fetch https://review.opendev.org/openstack/keystone refs/changes/26/34226/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/apache-httpd.rst'],1,772a5888b13e82e3efc24a528984da194133813b,httpd-doc," Authentication File Setup ------------------------- Create a new directory ``/var/www/stack/auth/`` and make sure HTTPD has access to the directory:: $ sudo mkdir /var/www/stack/auth $ sudo chmod 755 /var/www/stack/auth Create an .htpasswd file in ``/var/www/stack/auth/`` with at least one user. The user will need to have the same username as an OpenStack user that has sufficient permissions to do what is needed in OpenStack after HTTPD authentication occurs. Replace admin with whichever user you plan to use:: $ sudo htpasswd -c /var/www/stack/auth/.htpasswd admin New password: Re-type new password: Ensure the .htpasswd file has permission so HTTPD can access it:: $ sudo chmod 755 /var/www/stack/auth/.htpasswd Devstack with RedHat -------------------- Make sure mod_nss and mod_wsgi packages are installed:: $ yum install mod_nss Disable port 80 in '/etc/httpd/conf/httpd.conf' to prevent port conflicts. Verify that the ``/opt/stack/keystone/httpd/keystone.py`` file exists and create symlinks to keystone.py such that Apache can differentiate admin and main URIs:: $ ln -s /opt/stack/keystone/httpd/keystone.py /opt/stack/keystone/httpd/admin $ ln -s /opt/stack/keystone/httpd/keystone.py /opt/stack/keystone/httpd/main Create a ``/etc/httpd/conf.d/keystone.conf`` file with these contents. This tells Apache where to find the Keystone admin and main scripts, what ports to use them for, and what file to use for authentication:: Listen 35357 <VirtualHost *:35357> WSGIScriptAlias / [Keystone Install Root]/httpd/admin <Location /v2.0/tokens> AuthType Basic AuthName OpenStack AuthUserFile /var/www/stack/auth/.htpasswd Require valid-user </Location> </VirtualHost> Listen 5000 <VirtualHost *:5000> WSGIScriptAlias / [Keystone Install Root]/httpd/main <Location /v2.0/tokens> AuthType Basic AuthName OpenStack AuthUserFile /var/www/stack/auth/.htpasswd Require valid-user </Location> </VirtualHost> Ensure the user running Apache will have access to the keystone.conf file:: $ chmod 0744 /etc/keystone/keystone.conf Make sure MySQL is running and verify the Keystone standalone process is still down. Restart Apache to pick up all changes:: $ sudo service httpd restart If no configuration errors get thrown by the Apache restart, Keystone should now be accessible. Verification Authentication Works --------------------------------- A quick way to verify the authentication is working is to use curl commands from the command line. Note that the Keystone API commands can't be used, as they don't set a username and password in the HTTP header. Apache verifies the username and password passed in the header using the REMOTE_USER variable for authentication. Example of getting a new token with authentication of the username and password in the .htpasswd file:: $ curl -i --user [Username for File Authentication]:[Password for File Authentication] -H ""Content-Type: application/json"" -d '{""auth"": {}}' http://localhost:35357/v2.0/tokens Response:: HTTP/1.1 200 OK Date: Mon, 04 Mar 2013 22:49:49 GMT Server: Apache/2.2.22 (Ubuntu) Vary: X-Auth-Token Content-Length: 1133 Content-Type: application/json {""access"": {""token"": {""issued_at"": ""2013-03-04T22:49:49.463120"", ""expires"": ""2013-03-05T22:49:49Z"", ""id"": ""MIICbgYJKoZIhvcNAQcCoIICXzCCAlsCAQExCTAHBgUrDgMCGjCCAUcGCSqGSIb3DQEHAaCCATgEggE0eyJhY2Nlc3MiOiB7InRva2VuIjogeyJpc3N1ZWRfYXQiOiAiMjAxMy0wMy0wNFQyMjo0OTo0OS40NjMxMjAiLCAiZXhwaXJlcyI6ICIyMDEzLTAzLTA1VDIyOjQ5OjQ5WiIsICJpZCI6ICJwbGFjZWhvbGRlciJ9LCAic2VydmljZUNhdGFsb2ciOiBbXSwgInVzZXIiOiB7InVzZXJuYW1lIjogImFkbWluIiwgInJvbGVzX2xpbmtzIjogW10sICJpZCI6ICI0MjRmOTc5NTgzODQ0MjU4YWMwMDgyNWU2MjE0MDE1NCIsICJyb2xlcyI6IFtdLCAibmFtZSI6ICJhZG1pbiJ9LCAibWV0YWRhdGEiOiB7ImlzX2FkbWluIjogMCwgInJvbGVzIjogW119fX0xgf8wgfwCAQEwXDBXMQswCQYDVQQGEwJVUzEOMAwGA1UECBMFVW5zZXQxDjAMBgNVBAcTBVVuc2V0MQ4wDAYDVQQKEwVVbnNldDEYMBYGA1UEAxMPd3d3LmV4YW1wbGUuY29tAgEBMAcGBSsOAwIaMA0GCSqGSIb3DQEBAQUABIGAnTE7sARodxe3Rm-eD-9HP9E1KgusnEZSaLO-Fpz5+Nfx68WZknB61AQDllZ3WG4nPzttpxEQ28fl6qZXuFHnb7PBHuTSI1-xVx5TIAoJaW7EO6-0kwsqn0lRclY6NoHsYUPOdJn7K41Rf8XoXovQVYd5lsxZPgrCkZHomC0Vc10=""}, ""serviceCatalog"": [], ""user"": {""username"": ""admin"", ""roles_links"": [], ""id"": ""424f979583844258ac00825e62140154"", ""roles"": [], ""name"": ""admin""}, ""metadata"": {""is_admin"": 0, ""roles"": []}}} Note: Depending on your setup, the token ID value in the response may be a different format/length.",,103,0
openstack%2Fneutron~master~Ib7760cc7bb24e2c7f6692cbd8274aefa71dc21a1,openstack/neutron,master,Ib7760cc7bb24e2c7f6692cbd8274aefa71dc21a1,Cisco plugin check for a valid nexus driver,MERGED,2013-07-18 20:05:28.000000000,2013-07-23 05:54:52.000000000,2013-07-23 05:54:51.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 107}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 6524}, {'_account_id': 6659}]","[{'number': 1, 'created': '2013-07-18 20:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff2e2590c8b7f41e9890766f51d96728927010f1', 'message': 'Cisco plugin check for a valid nexus driver\n\nThe Cisco plugin model should check for a valid Nexus driver before performing any\noperations on hardware nexus devices.\n\nChange-Id: Ib7760cc7bb24e2c7f6692cbd8274aefa71dc21a1\nFixes: Bug #1202822\n'}, {'number': 2, 'created': '2013-07-18 20:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/257501a6c113e297cd4a87b2b5ac430ea67573c2', 'message': 'Cisco plugin check for a valid nexus driver\n\nThe Cisco plugin model should check for a valid Nexus driver before performing any\noperations on hardware nexus devices.\n\nChange-Id: Ib7760cc7bb24e2c7f6692cbd8274aefa71dc21a1\nFixes: Bug #1202822\n'}, {'number': 3, 'created': '2013-07-18 21:08:29.000000000', 'files': ['neutron/plugins/cisco/models/virt_phy_sw_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b6d787cdc32445858b1a2e89fd373790103444c2', 'message': 'Cisco plugin check for a valid nexus driver\n\nThe Cisco plugin model should check for a valid Nexus driver before performing any\noperations on hardware nexus devices.\n\nChange-Id: Ib7760cc7bb24e2c7f6692cbd8274aefa71dc21a1\nFixes: Bug #1202822\n'}]",3,37759,b6d787cdc32445858b1a2e89fd373790103444c2,16,7,3,107,,,0,"Cisco plugin check for a valid nexus driver

The Cisco plugin model should check for a valid Nexus driver before performing any
operations on hardware nexus devices.

Change-Id: Ib7760cc7bb24e2c7f6692cbd8274aefa71dc21a1
Fixes: Bug #1202822
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/37759/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/cisco/models/virt_phy_sw_v2.py'],1,ff2e2590c8b7f41e9890766f51d96728927010f1,bug/1202822," nexus_driver = cfg.CONF.CISCO.nexus_driver if not nexus_driver.endswith('CiscoNEXUSDriver'): return False nexus_driver = cfg.CONF.CISCO.nexus_driver if nexus_driver.endswith('CiscoNEXUSDriver'): self._invoke_plugin_per_device(const.NEXUS_PLUGIN, self._func_name(), n_args)"," self._invoke_plugin_per_device(const.NEXUS_PLUGIN, self._func_name(), n_args)",9,3
openstack%2Ftempest~master~Iaf782831372ba4e94ea0329675923b822077afa5,openstack/tempest,master,Iaf782831372ba4e94ea0329675923b822077afa5,E125 validation,ABANDONED,2013-07-12 07:33:00.000000000,2013-07-23 05:50:09.000000000,,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-12 07:33:00.000000000', 'files': ['tempest/thirdparty/boto/test.py', 'tempest/thirdparty/boto/test_ec2_instance_run.py', 'tempest/services/botoclients.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f88de8f7ad8e3a89dc3fd98c45405bd8428fc3ca', 'message': 'E125 validation\n\nTempest among the default pep8 rules just violates,\n the E125 in the boto tests (4 times).\n\nJust with a minimal change tempest\n can pass on all default pep8 checks.\n\nFixing bug 1199262\n\nChange-Id: Iaf782831372ba4e94ea0329675923b822077afa5\n'}]",0,36788,f88de8f7ad8e3a89dc3fd98c45405bd8428fc3ca,16,6,1,5803,,,0,"E125 validation

Tempest among the default pep8 rules just violates,
 the E125 in the boto tests (4 times).

Just with a minimal change tempest
 can pass on all default pep8 checks.

Fixing bug 1199262

Change-Id: Iaf782831372ba4e94ea0329675923b822077afa5
",git fetch https://review.opendev.org/openstack/tempest refs/changes/88/36788/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/thirdparty/boto/test.py', 'tempest/services/botoclients.py', 'tempest/thirdparty/boto/test_ec2_instance_run.py', 'tox.ini']",4,f88de8f7ad8e3a89dc3fd98c45405bd8428fc3ca,bug/1199262,"ignore = H302,H404","ignore = E125,H302,H404",10,9
openstack%2Fheat~master~Ie6659e0e8b519180ce5973cc798c914b56a95426,openstack/heat,master,Ie6659e0e8b519180ce5973cc798c914b56a95426,Add resource for Rackspace Cloud Servers.,MERGED,2013-06-11 16:22:08.000000000,2013-07-23 05:00:29.000000000,2013-07-23 05:00:29.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6434}, {'_account_id': 7135}, {'_account_id': 7230}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 7395}]","[{'number': 1, 'created': '2013-06-11 16:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b568ebf1a930ef4eb4b6a1b8210535c429af217c', 'message': 'Create Rackspace Cloud Servers resource provider.\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 2, 'created': '2013-06-11 18:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/754df0a4cdddf0652476188b1199199576407aae', 'message': 'Create Rackspace Cloud Servers resource provider.\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 3, 'created': '2013-06-19 21:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bae4226aee2b068d7b4aa200ff99674ec392fd6a', 'message': 'Create Rackspace Cloud Servers resource provider.\n\n(Still working on unit tests ATM)\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 4, 'created': '2013-06-21 20:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/42ebebf5a3b233787a7e711e23b0e75262db1a9f', 'message': 'Added resource for Rackspace Cloud Servers.\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 5, 'created': '2013-06-21 20:17:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2e8a424066c28b6008b998a1f827f1e04ac064b2', 'message': 'Add resource for Rackspace Cloud Servers.\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 6, 'created': '2013-06-21 20:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f63e5ef6db25d23ac8c77425481071ca5b209591', 'message': 'Add resource for Rackspace Cloud Servers.\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 7, 'created': '2013-06-25 19:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7925621e93bd1130b3d3a32a08b600771ddfec61', 'message': 'Add resource for Rackspace Cloud Servers.\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 8, 'created': '2013-06-26 19:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/13f36758240ee40e4a8e12abea3bb6c5c45a5b2a', 'message': 'Add resource for Rackspace Cloud Servers.\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 9, 'created': '2013-07-03 17:17:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1b1dbcd67f8927b80fc38ae1b463a4fce08c0927', 'message': 'Add resource for Rackspace Cloud Servers.\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 10, 'created': '2013-07-08 20:22:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c5958b74b9587aabb8025e9cd6acfddec236a56b', 'message': 'Add resource for Rackspace Cloud Servers.\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 11, 'created': '2013-07-11 21:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fadd797f6311661f51ae004997ed3f9244290da0', 'message': 'Add resource for Rackspace Cloud Servers.\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 12, 'created': '2013-07-16 18:14:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fadda8531c13991903ba5b09b6e6021bf44770f3', 'message': 'Add resource for Rackspace Cloud Servers.\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 13, 'created': '2013-07-16 19:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/615f3a89b2a5630eb18f6e452ef69dac65dc1b5e', 'message': 'Add resource for Rackspace Cloud Servers.\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 14, 'created': '2013-07-19 19:21:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/42185f550490f0f8140e6168e1f9a15eecfb179b', 'message': 'Add resource for Rackspace Cloud Servers.\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 15, 'created': '2013-07-19 20:47:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9b3a09bf46f85374fa4ed4efac50459524d59084', 'message': 'Add resource for Rackspace Cloud Servers.\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}, {'number': 16, 'created': '2013-07-22 16:01:34.000000000', 'files': ['requirements.txt', 'heat/tests/test_instance.py', 'test-requirements.txt', 'heat/common/exception.py', 'heat/engine/resources/rackspace/cloud_server.py', 'heat/tests/test_rackspace_cloud_server.py', 'heat/engine/resources/instance.py', 'heat/api/openstack/v1/util.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/2684f2bb4cda1b1a23ce596fcdb476bb961ea3f8', 'message': 'Add resource for Rackspace Cloud Servers.\n\nBlueprint rackspace-cloud-servers-provider\n\nChange-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426\n'}]",117,32587,2684f2bb4cda1b1a23ce596fcdb476bb961ea3f8,73,11,16,7253,,,0,"Add resource for Rackspace Cloud Servers.

Blueprint rackspace-cloud-servers-provider

Change-Id: Ie6659e0e8b519180ce5973cc798c914b56a95426
",git fetch https://review.opendev.org/openstack/heat refs/changes/87/32587/16 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'heat/engine/resources/rackspace/cloud_server.py']",2,b568ebf1a930ef4eb4b6a1b8210535c429af217c,bp/rackspace-cloud-servers-provider,"from heat.engine import resource from heat.openstack.common import log as logging import pyrax from heat.common import short_id, exception import json from oslo.config import cfg from email.mime.text import MIMEText import pkgutil import os from email.mime.multipart import MIMEMultipart import paramiko from Crypto.PublicKey import RSA import tempfile logger = logging.getLogger(__name__) class CloudServer(resource.Resource): tags_schema = { 'Key': {'Type': 'String', 'Required': True}, 'Value': {'Type': 'String', 'Required': True} } properties_schema = { 'UserData': {'Type': 'String'}, 'KeyName': {'Type': 'String'}, 'AvailabilityZone': {'Type': 'String'}, 'SecurityGroups': {'Type': 'List'}, 'SecurityGroupIds': {'Type': 'List'}, 'NovaSchedulerHints': { 'Type': 'List', 'Schema': {'Type': 'Map', 'Schema': tags_schema} }, 'Volumes': {'Type': 'List'}, 'SubnetId': {'Type': 'String'}, 'NetworkInterfaces': {'Type': 'List'}, 'InstanceName': {'Type': 'String', 'Required': True}, 'Flavor': {'Type': 'String', 'Required': True}, 'ImageName': {'Type': 'String', 'Required': True}, 'Tags': {'Type': 'List', 'Schema': {'Type': 'Map', 'Schema': tags_schema}} } rackspace_images = { ""F17"": ""76856c8b-e56e-4301-b454-c8cd1be22cfb"", ""U12.04"": ""e4dbdba7-b2a4-4ee5-8e8f-4595b6d694ce"" } image_scripts = { ""F17"": """"""#!/bin/bash -e # Install cloud-init and heat-cfntools yum install -y cloud-init python-boto curl http://repos.fedorapeople.org/repos/heat/heat-trunk/fedora-17/x86_64/heat\ -cfntools-1.0-20130118.fc17.noarch.rpm > heat-cfntools.rpm rpm -i heat-cfntools.rpm # Create data source for cloud-init mkdir -p /var/lib/cloud/seed/nocloud-net mv /tmp/userdata /var/lib/cloud/seed/nocloud-net/user-data touch /var/lib/cloud/seed/nocloud-net/meta-data # Run cloud-init & cfn-init cloud-init start bash /var/lib/cloud/data/cfn-userdata # Clean up rm -f /root/.ssh/authorized_keys """""" } def __init__(self, name, json_snippet, stack): super(CloudServer, self).__init__(name, json_snippet, stack) self.ipaddress = None self.mime_string = None # Retrieve auth info from file (temporary solution) pyrax.set_setting(""identity_type"", ""rackspace"") pyrax.set_credential_file(""/opt/stack/heat/heat/engine/resources/"" ""rackspace/rs-pyrax-creds.txt"") self.cs = pyrax.connect_to_cloudservers() def _create_container_name(self, name=None): return name or '%s-%s-%s' % (self.stack.name, self.name, short_id.generate_id()) def _build_userdata(self, userdata): """"""Build mime multipart data blob for cloudinit userdata"""""" if not self.mime_string: def make_subpart(content, filename, subtype=None): if subtype is None: subtype = os.path.splitext(filename)[0] msg = MIMEText(content, _subtype=subtype) msg.add_header('Content-Disposition', 'attachment', filename=filename) return msg def read_cloudinit_file(fn): data = pkgutil.get_data('heat', 'cloudinit/%s' % fn) data = data.replace('@INSTANCE_USER@', cfg.CONF.instance_user) return data attachments = [(read_cloudinit_file('config'), 'cloud-config'), (read_cloudinit_file('boothook.sh'), 'boothook.sh', 'cloud-boothook'), (read_cloudinit_file('part-handler.py'), 'part-handler.py'), (userdata, 'cfn-userdata', 'x-cfninitdata'), (read_cloudinit_file('loguserdata.py'), 'loguserdata.py', 'x-shellscript')] if 'Metadata' in self.t: attachments.append((json.dumps(self.metadata), 'cfn-init-data', 'x-cfninitdata')) subparts = [make_subpart(*args) for args in attachments] mime_blob = MIMEMultipart(_subparts=subparts) self.mime_string = mime_blob.as_string() return self.mime_string def handle_create(self): """"""Create a Rackspace Cloud Servers container. Rackspace Cloud Servers does not have the metadata service running, so we have to transfer the user-data file to the server and then trigger cloud-init. """""" def create_temp_file(data): temp_file = tempfile.NamedTemporaryFile() temp_file.write(data) temp_file.seek(0) return temp_file # Retrieve server creation parameters from properties name = self.properties['InstanceName'] image_name = self.properties['ImageName'] image_id = self.rackspace_images[image_name] script = self.image_scripts[image_name] flavor = self.properties['Flavor'] raw_userdata = self.properties['UserData'] or '' userdata = self._build_userdata(raw_userdata) # Generate one-time-use SSH public/private keypair (public key # will be put on server using personalities) rsa = RSA.generate(1024) private_key = rsa.exportKey() public_key = rsa.publickey().exportKey('OpenSSH') files = {""/root/.ssh/authorized_keys"": public_key} # Create server server = self.cs.servers.create(name, image_id, flavor, files=files) complete = pyrax.utils.wait_until(server, ""status"", [""ACTIVE"", ""ERROR""], attempts=0) # Get public IP for ip in complete.addresses['public']: if ip['version'] == 4: public_ip = ip['addr'] if not public_ip: raise exception.Error('Could not determine public IP of server') # Create temp files for SFTP userdata_file = create_temp_file(userdata) script_file = create_temp_file(script) private_key_file = create_temp_file(private_key) # Transfer files to server via SFTP pkey = paramiko.RSAKey.from_private_key_file(private_key_file.name) transport = paramiko.Transport((public_ip, 22)) transport.connect(hostkey=None, username=""root"", pkey=pkey) sftp = paramiko.SFTPClient.from_transport(transport) sftp.put(userdata_file.name, ""/tmp/userdata"") sftp.put(script_file.name, ""/root/heat-script"") # Connect via SSH and run script ssh = paramiko.SSHClient() ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) ssh.connect(public_ip, username=""root"", key_filename=private_key_file.name) stdin, stdout, stderr = ssh.exec_command(""bash /root/heat-script"") logger.debug(stdout.read()) logger.debug(stderr.read()) # Clean up temp files private_key_file.close() userdata_file.close() script_file.close() def handle_delete(self): raise NotImplementedError def handle_update(self): raise NotImplementedError def resource_mapping(): return { 'Rackspace::CloudServer': CloudServer } ",,209,1
openstack%2Ftripleo-image-elements~master~Icc10b368d519d49d5f010d373265e5b0a0759b10,openstack/tripleo-image-elements,master,Icc10b368d519d49d5f010d373265e5b0a0759b10,Use source-repository interface in openstack-db,MERGED,2013-07-23 04:18:41.000000000,2013-07-23 04:18:41.000000000,2013-07-23 04:18:41.000000000,"[{'_account_id': 3}, {'_account_id': 4190}]","[{'number': 1, 'created': '2013-07-23 04:18:41.000000000', 'files': ['elements/openstack-db/install.d/50-openstack-db', 'elements/openstack-db/element-deps', 'elements/openstack-db/source-repository-openstack'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/3f588310212df765845d2277a5badbd2dbbc0722', 'message': 'Use source-repository interface in openstack-db\n\nChange-Id: Icc10b368d519d49d5f010d373265e5b0a0759b10\n'}]",0,38125,3f588310212df765845d2277a5badbd2dbbc0722,5,2,1,1926,,,0,"Use source-repository interface in openstack-db

Change-Id: Icc10b368d519d49d5f010d373265e5b0a0759b10
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/25/38125/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/openstack-db/install.d/50-openstack-db', 'elements/openstack-db/element-deps', 'elements/openstack-db/source-repository-openstack']",3,3f588310212df765845d2277a5badbd2dbbc0722,source-repository,keystone git /opt/stack/keystone https://github.com/openstack/keystone.git cinder git /opt/stack/cinder https://github.com/openstack/cinder.git nova git /opt/stack/nova https://github.com/openstack/nova.git glance git /opt/stack/glance https://github.com/openstack/glance.git neutron git /opt/stack/neutron https://github.com/openstack/neutron.git ,,11,5
openstack%2Ftripleo-image-elements~master~I9650133140683f73b9418e1596ef22b9e4532fa0,openstack/tripleo-image-elements,master,I9650133140683f73b9418e1596ef22b9e4532fa0,Install wget in the heat-localip element,MERGED,2013-07-23 04:18:35.000000000,2013-07-23 04:18:35.000000000,2013-07-23 04:18:35.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4190}]","[{'number': 1, 'created': '2013-07-23 04:18:35.000000000', 'files': ['elements/heat-localip/install.d/74-heat-localip'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0337bc52bdf0dad410e0d33fc0fae1befc734903', 'message': 'Install wget in the heat-localip element\n\nThe configure.d script uses wget, we need to make sure its installed.\n\nChange-Id: I9650133140683f73b9418e1596ef22b9e4532fa0\n'}]",0,38163,0337bc52bdf0dad410e0d33fc0fae1befc734903,6,3,1,1926,,,0,"Install wget in the heat-localip element

The configure.d script uses wget, we need to make sure its installed.

Change-Id: I9650133140683f73b9418e1596ef22b9e4532fa0
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/63/38163/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/heat-localip/install.d/74-heat-localip'],1,0337bc52bdf0dad410e0d33fc0fae1befc734903,install-wget,#!/bin/bash set -eux install-packages wget ,,4,0
openstack%2Fswift~master~I8585d8442c7ccf538b819b036192b28c1f13847b,openstack/swift,master,I8585d8442c7ccf538b819b036192b28c1f13847b,Fix the way possibly_quarantine reraises an exception,MERGED,2013-07-17 21:02:15.000000000,2013-07-23 03:54:01.000000000,2013-07-23 03:54:01.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 4108}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-07-17 21:02:15.000000000', 'files': ['swift/common/db.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/53f502687be1d2e4983c2e6cb1fbf643176af4a1', 'message': 'Fix the way possibly_quarantine reraises an exception\n\nFixes Bug #1202386\n\nChange-Id: I8585d8442c7ccf538b819b036192b28c1f13847b\n'}]",0,37569,53f502687be1d2e4983c2e6cb1fbf643176af4a1,14,6,1,4108,,,0,"Fix the way possibly_quarantine reraises an exception

Fixes Bug #1202386

Change-Id: I8585d8442c7ccf538b819b036192b28c1f13847b
",git fetch https://review.opendev.org/openstack/swift refs/changes/69/37569/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/db.py'],1,53f502687be1d2e4983c2e6cb1fbf643176af4a1,bug/1202386," raise exc_type, exc_value, exc_traceback"," raise exc_type(*exc_value.args), None, exc_traceback",1,1
openstack%2Fcinder~master~Ia7413db4d71c85cbb382f289f36c02b0f838571d,openstack/cinder,master,Ia7413db4d71c85cbb382f289f36c02b0f838571d,Cleanup README.rst,MERGED,2013-07-22 09:26:37.000000000,2013-07-23 03:34:50.000000000,2013-07-23 03:34:50.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2166}, {'_account_id': 4355}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-07-22 09:26:37.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3e703930f6c3c119946765b8db4db9090aa9ed1f', 'message': 'Cleanup README.rst\n\nChange-Id: Ia7413db4d71c85cbb382f289f36c02b0f838571d\n'}]",0,38126,3e703930f6c3c119946765b8db4db9090aa9ed1f,8,5,1,7102,,,0,"Cleanup README.rst

Change-Id: Ia7413db4d71c85cbb382f289f36c02b0f838571d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/26/38126/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,3e703930f6c3c119946765b8db4db9090aa9ed1f,cleanup-readme,To hack at it: read HACKING.rst,To hack at it: read HACKING To cry over its pylint problems: http://jenkins.openstack.org/job/cinder-pylint/violations,1,3
openstack%2Fcinder~master~Ic2bf2fa1ad82cf8669b6c491c955dcab39eb1510,openstack/cinder,master,Ic2bf2fa1ad82cf8669b6c491c955dcab39eb1510,Refactor SSHPool.get() to use Pool.get(),MERGED,2013-07-12 08:58:13.000000000,2013-07-23 03:34:49.000000000,2013-07-23 03:34:48.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 6604}, {'_account_id': 6939}]","[{'number': 1, 'created': '2013-07-12 08:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/81bf2e3c975e54d8ac9f3d2ad45b7156c414bdc4', 'message': ""Refactor SSHPool.get() with Pool.get()\n\nIn previous code of SSHPool.get(), we pasted the code\nfrom Pool.get() and check if a connection is active before return\nit.\n\nHowever, it's much simpler and cleaner to just call the Pool.get()\nand then check the connection before return. With this,we can free\nfrom manually keeping up with code of Pool.get() in upstream package\neventlet\n\nas a side effect, this patch fixed bug #1194393 due to the bug in\neventlet code before revision 1072(and also previous code in utils.py)\n\nChange-Id: Ic2bf2fa1ad82cf8669b6c491c955dcab39eb1510\n""}, {'number': 2, 'created': '2013-07-12 15:33:57.000000000', 'files': ['cinder/utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cccf7b92c189bcadf6898019730d84bfd4fe70b6', 'message': ""Refactor SSHPool.get() to use Pool.get()\n\nIn previous code of SSHPool.get(), we pasted the code\nfrom Pool.get() and check if a connection is active before return\nit.\n\nHowever, it's much simpler and cleaner to just call the Pool.get()\nand then check the connection before return. With this,we can free\nourselves from manually keeping up with code of Pool.get() in\nupstream package eventlet\n\nAs a side effect,this patch fixed bug #1194393 which caused by a\nprevious bug in eventlet codes before revision 1072\n\nfixed bug #1194393\nChange-Id: Ic2bf2fa1ad82cf8669b6c491c955dcab39eb1510\n""}]",3,36793,cccf7b92c189bcadf6898019730d84bfd4fe70b6,13,7,2,6939,,,0,"Refactor SSHPool.get() to use Pool.get()

In previous code of SSHPool.get(), we pasted the code
from Pool.get() and check if a connection is active before return
it.

However, it's much simpler and cleaner to just call the Pool.get()
and then check the connection before return. With this,we can free
ourselves from manually keeping up with code of Pool.get() in
upstream package eventlet

As a side effect,this patch fixed bug #1194393 which caused by a
previous bug in eventlet codes before revision 1072

fixed bug #1194393
Change-Id: Ic2bf2fa1ad82cf8669b6c491c955dcab39eb1510
",git fetch https://review.opendev.org/openstack/cinder refs/changes/93/36793/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/utils.py'],1,81bf2e3c975e54d8ac9f3d2ad45b7156c414bdc4,bug/1194393," conn = super(SSHPool, self).get() if conn: if conn.get_transport().is_active(): return conn else: conn.close() return self.create()", if self.free_items: conn = self.free_items.popleft() if conn: if conn.get_transport().is_active(): return conn else: conn.close() return self.create() if self.current_size < self.max_size: created = self.create() self.current_size += 1 return created return self.channel.get(),8,13
openstack%2Fkeystone~master~I7267ca0d4740f037884fae95f8a6562ee86584b9,openstack/keystone,master,I7267ca0d4740f037884fae95f8a6562ee86584b9,Load app before loading legacy client in tests.,MERGED,2013-07-10 06:52:51.000000000,2013-07-23 03:34:47.000000000,2013-07-23 03:34:46.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1313}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 8116}]","[{'number': 1, 'created': '2013-07-10 06:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e84b148c7fffebf8e906214165c010f762fe6954', 'message': ""Load app before loading legacy client in tests.\n\nWhen you load an old version of keystoneclient doing legacy tests and\nthen start the test app the ec2 work that depends on keystoneclient sees\nthe recently loaded legacy one which doesn't have the required modules\nin it.\n\nIf we load the app first the ec2 modules are resolved and finds the\noriginal keystone client. The ec2 module then uses\n'from keystoneclient.contrib.ec2 import utils as ec2_utils' so the\nec2_utils reference is kept in the file scope so isn't affected by the\ntests changing keystoneclient.\n\nIt is not a long term fix for bug 1178532 but it solves the immediate\nsymptoms when running client tests independently.\n\nChange-Id: I7267ca0d4740f037884fae95f8a6562ee86584b9\n""}, {'number': 2, 'created': '2013-07-18 23:51:57.000000000', 'files': ['tests/test_keystoneclient.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2aaa902d6eb16fe9ee2e7bc262c1b29731c03a0c', 'message': ""Load app before loading legacy client in tests.\n\nWhen you load an old version of keystoneclient doing legacy tests and\nthen start the test app the ec2 work that depends on keystoneclient sees\nthe recently loaded legacy one which doesn't have the required modules\nin it.\n\nIf we load the app first the ec2 modules are resolved and finds the\noriginal keystone client. The ec2 module then uses\n'from keystoneclient.contrib.ec2 import utils as ec2_utils' so the\nec2_utils reference is kept in the file scope so isn't affected by the\ntests changing keystoneclient.\n\nIt is not a long term fix for bug 1178532 but it solves the immediate\nsymptoms when running client tests independently.\n\nChange-Id: I7267ca0d4740f037884fae95f8a6562ee86584b9\n""}]",2,36395,2aaa902d6eb16fe9ee2e7bc262c1b29731c03a0c,20,9,2,7191,,,0,"Load app before loading legacy client in tests.

When you load an old version of keystoneclient doing legacy tests and
then start the test app the ec2 work that depends on keystoneclient sees
the recently loaded legacy one which doesn't have the required modules
in it.

If we load the app first the ec2 modules are resolved and finds the
original keystone client. The ec2 module then uses
'from keystoneclient.contrib.ec2 import utils as ec2_utils' so the
ec2_utils reference is kept in the file scope so isn't affected by the
tests changing keystoneclient.

It is not a long term fix for bug 1178532 but it solves the immediate
symptoms when running client tests independently.

Change-Id: I7267ca0d4740f037884fae95f8a6562ee86584b9
",git fetch https://review.opendev.org/openstack/keystone refs/changes/95/36395/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_keystoneclient.py'],1,e84b148c7fffebf8e906214165c010f762fe6954,bug/1178532," self.public_server = self.serveapp('keystone', name='main') self.admin_server = self.serveapp('keystone', name='admin') "," self.public_server = self.serveapp('keystone', name='main') self.admin_server = self.serveapp('keystone', name='admin') ",3,3
openstack%2Fpuppet-neutron~master~I8c131ebdbab149f589c84e52be8f810e39624941,openstack/puppet-neutron,master,I8c131ebdbab149f589c84e52be8f810e39624941,Support Cisco quantum plugin,MERGED,2013-07-23 02:59:16.000000000,2013-07-23 02:59:16.000000000,2013-07-23 02:59:16.000000000,"[{'_account_id': 3}, {'_account_id': 2265}, {'_account_id': 6524}, {'_account_id': 6967}, {'_account_id': 6994}]","[{'number': 4, 'created': '2013-07-23 02:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/a916c17fe258a781e8526faa86125f676d3aa103', 'message': 'Support Cisco quantum plugin (WORKINPROGRESS)\n\nThis patch adds native types for the config files\nneeded to enable the cisco quantum plugin as well\nas a class that will create these config files.\n\nUsers will be able to select their plugin\nof choice by setting the core_plugin on the\nopenstack::controller, which will then create\nthe quantum::plugins::cisco class.\n\nChange-Id: I8c131ebdbab149f589c84e52be8f810e39624941\n'}, {'number': 5, 'created': '2013-07-23 02:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/5cb821915328e565f39c6e4679078a07f12b8989', 'message': 'Support Cisco quantum plugin (WORKINPROGRESS)\n\nThis patch adds native types for the config files\nneeded to enable the cisco quantum plugin as well\nas a class that will create these config files.\n\nUsers will be able to select their plugin\nof choice by setting the core_plugin on the\nopenstack::controller, which will then create\nthe quantum::plugins::cisco class.\n\nChange-Id: I8c131ebdbab149f589c84e52be8f810e39624941\n'}, {'number': 6, 'created': '2013-07-23 02:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/8f9afb1080a1e09947396fdaa40088f7e6fb80b1', 'message': 'Support Cisco quantum plugin\n\nThis patch adds native types for the config files\nneeded to enable the cisco quantum plugin as well\nas a class that will create these config files.\n\nUsers will be able to select their plugin\nof choice by setting the core_plugin on the\nopenstack::controller, which will then create\nthe quantum::plugins::cisco class.\n\nChange-Id: I8c131ebdbab149f589c84e52be8f810e39624941\n'}, {'number': 7, 'created': '2013-07-23 02:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/0a4d4e96319585a85bf969c566a522caba2bbb37', 'message': 'Support Cisco quantum plugin\n\nThis patch adds native types for the config files\nneeded to enable the cisco quantum plugin as well\nas a class that will create these config files.\n\nUsers will be able to select their plugin\nof choice by setting the core_plugin on the\nopenstack::controller, which will then create\nthe quantum::plugins::cisco class.\n\nChange-Id: I8c131ebdbab149f589c84e52be8f810e39624941\n'}, {'number': 1, 'created': '2013-07-23 02:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/8a24a9b74df1b5e26ac42156589b11f01fe6383f', 'message': 'Support Cisco quantum plugin (WORKINPROGRESS)\n\nThis patch adds native types for the config files\nneeded to enable the cisco quantum plugin as well\nas a class that will create these config files.\n\nUsers will be able to select their plugin\nof choice by setting the core_plugin on the\nopenstack::controller, which will then create\nthe quantum::plugins::cisco class.\n\nChange-Id: I8c131ebdbab149f589c84e52be8f810e39624941\n'}, {'number': 2, 'created': '2013-07-23 02:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/0316ed749f4060d00056b3e90fa05e3f8d3fb7ec', 'message': 'Support Cisco quantum plugin (WORKINPROGRESS)\n\nThis patch adds native types for the config files\nneeded to enable the cisco quantum plugin as well\nas a class that will create these config files.\n\nUsers will be able to select their plugin\nof choice by setting the core_plugin on the\nopenstack::controller, which will then create\nthe quantum::plugins::cisco class.\n\nChange-Id: I8c131ebdbab149f589c84e52be8f810e39624941\n'}, {'number': 3, 'created': '2013-07-23 02:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/f88b1e546d2b08fd3106f301db5e77044601adfa', 'message': 'Support Cisco quantum plugin (WORKINPROGRESS)\n\nThis patch adds native types for the config files\nneeded to enable the cisco quantum plugin as well\nas a class that will create these config files.\n\nUsers will be able to select their plugin\nof choice by setting the core_plugin on the\nopenstack::controller, which will then create\nthe quantum::plugins::cisco class.\n\nChange-Id: I8c131ebdbab149f589c84e52be8f810e39624941\n'}, {'number': 12, 'created': '2013-07-23 02:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/bbdde1f0a5069f9777bf36c20ce9666d75b82de5', 'message': 'Support Cisco quantum plugin\n\nThis patch adds native types for the config files\nneeded to enable the cisco quantum plugin as well\nas a class that will create these config files.\n\nUsers will be able to select their plugin\nof choice by setting the core_plugin on the\nopenstack::controller, and then creating\nthe quantum::plugins::cisco class separately.\n\nChange-Id: I8c131ebdbab149f589c84e52be8f810e39624941\n'}, {'number': 13, 'created': '2013-07-23 02:59:16.000000000', 'files': ['lib/puppet/type/quantum_plugin_cisco_credentials.rb', 'lib/puppet/type/quantum_plugin_cisco.rb', 'lib/puppet/type/quantum_plugin_cisco_db_conn.rb', 'lib/puppet/provider/quantum_plugin_cisco_db_conn/ini_setting.rb', 'spec/classes/quantum_plugins_cisco_spec.rb', 'lib/puppet/provider/quantum_plugin_cisco_l2network/ini_setting.rb', 'manifests/init.pp', 'manifests/plugins/cisco.pp', 'lib/puppet/type/quantum_plugin_cisco_l2network.rb', 'lib/puppet/provider/quantum_plugin_cisco_credentials/ini_setting.rb', 'lib/puppet/provider/quantum_plugin_cisco/ini_setting.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/e25c367a26dcf9c3acede8a40ec60b88249be64a', 'message': 'Support Cisco quantum plugin\n\nThis patch adds native types for the config files\nneeded to enable the cisco quantum plugin as well\nas a class that will create these config files.\n\nUsers will be able to select their plugin\nof choice by setting the core_plugin on the\nopenstack::controller, and then creating\nthe quantum::plugins::cisco class separately.\n\nChange-Id: I8c131ebdbab149f589c84e52be8f810e39624941\n'}, {'number': 8, 'created': '2013-07-23 02:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/2b92e47dbcb3b1241e7a448b05d1fb729ffb4d6d', 'message': 'Support Cisco quantum plugin\n\nThis patch adds native types for the config files\nneeded to enable the cisco quantum plugin as well\nas a class that will create these config files.\n\nUsers will be able to select their plugin\nof choice by setting the core_plugin on the\nopenstack::controller, which will then create\nthe quantum::plugins::cisco class.\n\nChange-Id: I8c131ebdbab149f589c84e52be8f810e39624941\n'}, {'number': 9, 'created': '2013-07-23 02:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/c65c60d3de0eedf018b2c5c60a8767188c93dfb1', 'message': 'Support Cisco quantum plugin\n\nThis patch adds native types for the config files\nneeded to enable the cisco quantum plugin as well\nas a class that will create these config files.\n\nUsers will be able to select their plugin\nof choice by setting the core_plugin on the\nopenstack::controller, which will then create\nthe quantum::plugins::cisco class.\n\nChange-Id: I8c131ebdbab149f589c84e52be8f810e39624941\n'}, {'number': 10, 'created': '2013-07-23 02:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/9d0a5570a866753c6116d01846b2a28273092e18', 'message': 'Support Cisco quantum plugin\n\nThis patch adds native types for the config files\nneeded to enable the cisco quantum plugin as well\nas a class that will create these config files.\n\nUsers will be able to select their plugin\nof choice by setting the core_plugin on the\nopenstack::controller, and then creating\nthe quantum::plugins::cisco class separately.\n\nChange-Id: I8c131ebdbab149f589c84e52be8f810e39624941\n'}, {'number': 11, 'created': '2013-07-23 02:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/67064fd0ceb11b255c07548ee9c6472fe84ccdc0', 'message': 'Support Cisco quantum plugin\n\nThis patch adds native types for the config files\nneeded to enable the cisco quantum plugin as well\nas a class that will create these config files.\n\nUsers will be able to select their plugin\nof choice by setting the core_plugin on the\nopenstack::controller, and then creating\nthe quantum::plugins::cisco class separately.\n\nChange-Id: I8c131ebdbab149f589c84e52be8f810e39624941\n'}]",12,36830,e25c367a26dcf9c3acede8a40ec60b88249be64a,45,5,13,6994,,,0,"Support Cisco quantum plugin

This patch adds native types for the config files
needed to enable the cisco quantum plugin as well
as a class that will create these config files.

Users will be able to select their plugin
of choice by setting the core_plugin on the
openstack::controller, and then creating
the quantum::plugins::cisco class separately.

Change-Id: I8c131ebdbab149f589c84e52be8f810e39624941
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/30/36830/4 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/type/quantum_plugin_cisco.rb', 'lib/puppet/type/quantum_plugin_cisco_db_conn.rb', 'lib/puppet/provider/quantum_plugin_cisco_db_conn/ini_setting.rb', 'lib/puppet/provider/quantum_plugin_cisco_l2network/ini_setting.rb', 'manifests/init.pp', 'manifests/plugins/cisco.pp', 'lib/puppet/type/quantum_plugin_cisco_l2network.rb', 'lib/puppet/provider/quantum_plugin_cisco/ini_setting.rb']",8,a916c17fe258a781e8526faa86125f676d3aa103,cisco_plugin,"Puppet::Type.type(:quantum_plugin_cisco).provide( :ini_setting, :parent => Puppet::Type.type(:ini_setting).provider(:ruby) ) do def section resource[:name].split('/', 2).first end def setting resource[:name].split('/', 2).last end def separator '=' end def file_path '/etc/quantum/plugins/cisco/cisco_plugins.ini' end end ",,246,1
openstack%2Fpuppet-cinder~master~I8c6cd9d63b3e6da683bf210f1b4db7bd7fd3d315,openstack/puppet-cinder,master,I8c6cd9d63b3e6da683bf210f1b4db7bd7fd3d315,Add support for NetApp direct drivers,MERGED,2013-07-17 20:55:22.000000000,2013-07-23 02:41:14.000000000,2013-07-23 02:41:14.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2265}, {'_account_id': 6850}, {'_account_id': 7156}, {'_account_id': 7822}]","[{'number': 2, 'created': '2013-07-17 20:55:22.000000000', 'files': ['spec/classes/cinder_volume_netapp_spec.rb', 'manifests/volume/netapp.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/b4819ab7adcd93642f9ba4b3ffd467edacdd80b1', 'message': 'Add support for NetApp direct drivers\n\nnetapp_wsdl_url is only valid for the regular drivers.\nnetapp_storage_service is optional for all NetApp drivers.\nSee here for example:\nhttp://docs.openstack.org/grizzly/openstack-block-storage/admin/content/netapp-iscsi-driver-direct-7mode.html\n\nChange-Id: I8c6cd9d63b3e6da683bf210f1b4db7bd7fd3d315\n'}, {'number': 1, 'created': '2013-07-17 20:55:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/7f33f4feaffb7c4c48411e706188adb8b8f4890b', 'message': 'Add support for NetApp direct drivers\n\nnetapp_wsdl_url is only valid for the regular drivers.\nnetapp_storage_service is optional for all NetApp drivers.\nSee here for example:\nhttp://docs.openstack.org/grizzly/openstack-block-storage/admin/content/netapp-iscsi-driver-direct-7mode.html\n\nChange-Id: I8c6cd9d63b3e6da683bf210f1b4db7bd7fd3d315\n'}]",0,37568,b4819ab7adcd93642f9ba4b3ffd467edacdd80b1,15,6,2,6850,,,0,"Add support for NetApp direct drivers

netapp_wsdl_url is only valid for the regular drivers.
netapp_storage_service is optional for all NetApp drivers.
See here for example:
http://docs.openstack.org/grizzly/openstack-block-storage/admin/content/netapp-iscsi-driver-direct-7mode.html

Change-Id: I8c6cd9d63b3e6da683bf210f1b4db7bd7fd3d315
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/68/37568/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/cinder_volume_netapp_spec.rb', 'manifests/volume/netapp.pp']",2,b4819ab7adcd93642f9ba4b3ffd467edacdd80b1,netapp-direct," $netapp_wsdl_url = undef, $netapp_storage_service = undef,"," $netapp_wsdl_url, $netapp_storage_service,",2,4
openstack%2Fswift~master~Ieb563ace9f65a4ad204b01be32bf7a9d5f226005,openstack/swift,master,Ieb563ace9f65a4ad204b01be32bf7a9d5f226005,Ensure that files are always closed explicitly.,MERGED,2013-07-22 22:01:03.000000000,2013-07-23 02:37:25.000000000,2013-07-23 02:37:25.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-22 22:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ff800a0e30ae0723bdd80cc027d230464a158972', 'message': 'Ensure that files are always closed explicitly.\n\nThis is needed on Pythons without reference\ncounting garbage collectors (e.g. PyPy).\n\nChange-Id: Ieb563ace9f65a4ad204b01be32bf7a9d5f226005\n'}, {'number': 2, 'created': '2013-07-22 23:11:01.000000000', 'files': ['swift/common/ring/builder.py', 'test/unit/common/ring/test_builder.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/6384b192b55b823d86078588f22b8bc847954aad', 'message': 'Ensure that files are always closed explicitly.\n\nThis is needed on Pythons without reference\ncounting garbage collectors (e.g. PyPy).\n\nChange-Id: Ieb563ace9f65a4ad204b01be32bf7a9d5f226005\n'}]",0,38205,6384b192b55b823d86078588f22b8bc847954aad,12,5,2,7680,,,0,"Ensure that files are always closed explicitly.

This is needed on Pythons without reference
counting garbage collectors (e.g. PyPy).

Change-Id: Ieb563ace9f65a4ad204b01be32bf7a9d5f226005
",git fetch https://review.opendev.org/openstack/swift refs/changes/05/38205/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/ring/builder.py'],1,ff800a0e30ae0723bdd80cc027d230464a158972,close-files," with open(builder_file, 'wb') as f: pickle.dump(self.to_dict(), f, protocol=2)"," pickle.dump(self.to_dict(), open(builder_file, 'wb'), protocol=2)",2,1
openstack%2Fceilometer~master~Iab94c675749331ff7bfb0f74728dbd8f947f26f6,openstack/ceilometer,master,Iab94c675749331ff7bfb0f74728dbd8f947f26f6,Implement dot in matching_metadata key for mongodb,MERGED,2013-07-18 08:41:52.000000000,2013-07-23 02:11:42.000000000,2013-07-23 02:11:42.000000000,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 4715}]","[{'number': 1, 'created': '2013-07-18 08:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1688a9feb8036dec58d672a097d9dca4f8749df4', 'message': ""Implement dot in maching_metadata key for mongodb\n\nBefore the dict maching_metadata was stored as dict in mongo.\nBut mongo doesn't allow dot in dictionnary key\n\nThis change converts the maching_metadata dict into a array like this:\n\n[ { 'key': 'info.key.dotted', 'value': 'the_value'} ]\n\nFixes bug #1201886\n\nChange-Id: Iab94c675749331ff7bfb0f74728dbd8f947f26f6\n""}, {'number': 2, 'created': '2013-07-18 14:31:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cd4f07cf4fe34ca06ae5cf48df68c7092125b042', 'message': ""Implement dot in maching_metadata key for mongodb\n\nBefore the dict maching_metadata was stored as dict in mongo.\nBut mongo doesn't allow dot in dictionnary key\n\nThis change converts the maching_metadata dict into a array like this:\n\n[ { 'key': 'info.key.dotted', 'value': 'the_value'} ]\n\nFixes bug #1201886\n\nChange-Id: Iab94c675749331ff7bfb0f74728dbd8f947f26f6\n""}, {'number': 3, 'created': '2013-07-18 15:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/79150640351ba47dd189c20de27e3baf1408833f', 'message': ""Implement dot in maching_metadata key for mongodb\n\nBefore the dict maching_metadata was stored as dict in mongo.\nBut mongo doesn't allow dot in dictionnary key\n\nThis change converts the maching_metadata dict into a array like this:\n\n[ { 'key': 'info.key.dotted', 'value': 'the_value'} ]\n\nFixes bug #1201886\n\nChange-Id: Iab94c675749331ff7bfb0f74728dbd8f947f26f6\n""}, {'number': 4, 'created': '2013-07-19 08:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/53c2cf277ecfbf354b8ee9503740462e169ba8ac', 'message': ""Implement dot in maching_metadata key for mongodb\n\nBefore the dict maching_metadata was stored as dict in mongo.\nBut mongo doesn't allow dot in dictionnary key\n\nThis change converts the maching_metadata dict into a array like this:\n\n[ { 'key': 'info.key.dotted', 'value': 'the_value'} ]\n\nFixes bug #1201886\n\nChange-Id: Iab94c675749331ff7bfb0f74728dbd8f947f26f6\n""}, {'number': 5, 'created': '2013-07-22 07:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fc77c191801ef43f3d457b5a4775b6aeda21f1f6', 'message': ""Implement dot in matching_metadata key for mongodb\n\nBefore the dict matching_metadata was stored as dict in mongo.\nBut mongo doesn't allow dot in dictionary key\n\nThis change converts the matching_metadata dict into a array like this:\n\n[ { 'key': 'info.key.dotted', 'value': 'the_value'} ]\n\nFixes bug #1201886\n\nChange-Id: Iab94c675749331ff7bfb0f74728dbd8f947f26f6\n""}, {'number': 6, 'created': '2013-07-22 16:12:52.000000000', 'files': ['tests/storage/base.py', 'ceilometer/storage/impl_mongodb.py', 'tests/storage/test_impl_mongodb.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a958d6c2cebc03638100364765e6f3a6ced984ff', 'message': ""Implement dot in matching_metadata key for mongodb\n\nBefore the dict matching_metadata was stored as dict in mongo.\nBut mongo doesn't allow dot in dictionary key\n\nThis change converts the matching_metadata dict into a array like this:\n\n[ { 'key': 'info.key.dotted', 'value': 'the_value'} ]\n\nFixes bug #1201886\n\nChange-Id: Iab94c675749331ff7bfb0f74728dbd8f947f26f6\n""}]",14,37641,a958d6c2cebc03638100364765e6f3a6ced984ff,25,5,6,2813,,,0,"Implement dot in matching_metadata key for mongodb

Before the dict matching_metadata was stored as dict in mongo.
But mongo doesn't allow dot in dictionary key

This change converts the matching_metadata dict into a array like this:

[ { 'key': 'info.key.dotted', 'value': 'the_value'} ]

Fixes bug #1201886

Change-Id: Iab94c675749331ff7bfb0f74728dbd8f947f26f6
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/41/37641/6 && git format-patch -1 --stdout FETCH_HEAD,"['tests/storage/base.py', 'ceilometer/storage/impl_mongodb.py']",2,1688a9feb8036dec58d672a097d9dca4f8749df4,sileht/rpcnotifier," self._decode_matching_metadata(a) def _decode_matching_metadata(self, data): matching_metadata = data['matching_metadata'] if isinstance(matching_metadata, list): data['matching_metadata'] = {} for elem in matching_metadata: data['matching_metadata'][elem['key']] = elem['value'] def _encode_matching_metadata(self, data): matching_metadata = data['matching_metadata'] data['matching_metadata'] = [] for k, v in matching_metadata.iteritems(): data['matching_metadata'].append({'key': k, 'value': v}) self._encode_matching_metadata(data) self._decode_matching_metadata(stored_alarm)",,28,3
openstack%2Fceilometer~master~Id06e0a45ef88c15674052faeb941d87b70c7b99b,openstack/ceilometer,master,Id06e0a45ef88c15674052faeb941d87b70c7b99b,Implement a https:// in REST alarm notification,MERGED,2013-07-16 10:57:51.000000000,2013-07-23 02:05:40.000000000,2013-07-23 02:05:40.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 4715}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-16 10:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/caf90013960d18e587eb0bb8a90f345859246702', 'message': 'Implement a https:// in REST alarm notification\n\nThis change adds schemes https:// to the alarm notifier.\n\nBy default, the server certificate is verified like a browser does\nbut with the system CA.\n\nA client certificate can be set in the configuration file.\nIt must contains the certificate and the private key.\n\n [alarm]\n rest_notifier_certificate = /path/certificate.pem\n\nChange-Id: Id06e0a45ef88c15674052faeb941d87b70c7b99b\nBlueprint: alarm-notifier\n'}, {'number': 2, 'created': '2013-07-16 13:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8823eb78e29ea21861c5ea4b1066d3e3f30336c6', 'message': 'Implement a https:// in REST alarm notification\n\nThis change adds schemes https:// to the alarm notifier.\n\nBy default, the server certificate is verified like a browser does\nbut with the system CA.\n\nA client certificate can be set in the configuration file.\nIt must contains the certificate and the private key.\n\n [alarm]\n rest_notifier_certificate = /path/certificate.pem\n\nChange-Id: Id06e0a45ef88c15674052faeb941d87b70c7b99b\nBlueprint: alarm-notifier\n'}, {'number': 3, 'created': '2013-07-16 14:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7b2f53d7a9dca902f988e725a463a08a1374e2e9', 'message': 'Implement a https:// in REST alarm notification\n\nThis change adds schemes https:// to the alarm notifier.\n\nBy default, the server certificate is verified like a browser does\nbut with the system CA.\n\nA client certificate can be set in the configuration file.\nIt must contains the certificate and the private key.\n\n [alarm]\n rest_notifier_certificate = /path/certificate.pem\n\nChange-Id: Id06e0a45ef88c15674052faeb941d87b70c7b99b\nBlueprint: alarm-notifier\n'}, {'number': 4, 'created': '2013-07-18 06:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/801d0c07572b97ab8b8be87e6e2042e4fce5ddaf', 'message': 'Implement a https:// in REST alarm notification\n\nThis change adds schemes https:// to the alarm notifier.\n\nBy default, the server certificate is verified like a browser does\nbut with the system CA.\n\nA client certificate can be set in the configuration file.\nIt must contains the certificate and the private key.\n\n [alarm]\n rest_notifier_certificate = /path/certificate.pem\n\nChange-Id: Id06e0a45ef88c15674052faeb941d87b70c7b99b\nBlueprint: alarm-notifier\n'}, {'number': 5, 'created': '2013-07-18 13:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/61c05967bb36c88b5f05cc467bafd47970f75335', 'message': 'Implement a https:// in REST alarm notification\n\nThis change adds schemes https:// to the alarm notifier.\n\nBy default, the server certificate is verified like a browser does\nbut with the system CA.\n\nA client certificate can be set in the configuration file.\n\n [alarm]\n rest_notifier_certificate_file = /path/certificate.pem\n rest_notifier_certificate_key = /path/private_key.pem\n\nChange-Id: Id06e0a45ef88c15674052faeb941d87b70c7b99b\nBlueprint: alarm-notifier\n'}, {'number': 6, 'created': '2013-07-22 08:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f9934ed6c40b71d8035d62e8272aba5a941255c0', 'message': 'Implement a https:// in REST alarm notification\n\nThis change adds schemes https:// to the alarm notifier.\n\nBy default, the server certificate is verified like a browser does\nbut with the system CA.\n\nA client certificate can be set in the configuration file.\n\n [alarm]\n rest_notifier_certificate_file = /path/certificate.pem\n rest_notifier_certificate_key = /path/private_key.pem\n\nChange-Id: Id06e0a45ef88c15674052faeb941d87b70c7b99b\nBlueprint: alarm-notifier\n'}, {'number': 7, 'created': '2013-07-22 18:39:56.000000000', 'files': ['tests/alarm/test_notifier.py', 'ceilometer/tests/base.py', 'setup.cfg', 'ceilometer/alarm/notifier/rest.py', 'etc/ceilometer/ceilometer.conf.sample'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fc9b416a47deea14f8c9c6de384b4c6d5995008a', 'message': 'Implement a https:// in REST alarm notification\n\nThis change adds schemes https:// to the alarm notifier.\n\nBy default, the server certificate is verified like a browser does\nbut with the system CA.\n\nA client certificate can be set in the configuration file.\n\n [alarm]\n rest_notifier_certificate_file = /path/certificate.pem\n rest_notifier_certificate_key = /path/private_key.pem\n\nChange-Id: Id06e0a45ef88c15674052faeb941d87b70c7b99b\nBlueprint: alarm-notifier\n'}]",12,37211,fc9b416a47deea14f8c9c6de384b4c6d5995008a,45,6,7,2813,,,0,"Implement a https:// in REST alarm notification

This change adds schemes https:// to the alarm notifier.

By default, the server certificate is verified like a browser does
but with the system CA.

A client certificate can be set in the configuration file.

 [alarm]
 rest_notifier_certificate_file = /path/certificate.pem
 rest_notifier_certificate_key = /path/private_key.pem

Change-Id: Id06e0a45ef88c15674052faeb941d87b70c7b99b
Blueprint: alarm-notifier
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/11/37211/5 && git format-patch -1 --stdout FETCH_HEAD,"['tests/alarm/test_notifier.py', 'setup.cfg', 'ceilometer/alarm/notifier/rest.py', 'etc/ceilometer/ceilometer.conf.sample']",4,caf90013960d18e587eb0bb8a90f345859246702,bp/alarm-notifier,# Options defined in ceilometer.alarm.notifier.rest # # SSL Client certificate for REST notifier should be # the concatenation of the certificate and the private key # (string value) #rest_notifier_certificate= ## Total option count: 123,# Total option count: 122,65,7
openstack%2Fneutron~master~I5d612bf9e4f6652af8b155cdd1748d73ac4539ff,openstack/neutron,master,I5d612bf9e4f6652af8b155cdd1748d73ac4539ff,GRE tunnels should include local_ip.,MERGED,2013-07-06 16:06:39.000000000,2013-07-23 02:01:43.000000000,2013-07-23 02:01:42.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1689}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 6072}, {'_account_id': 7707}]","[{'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c6b00cc0af160709b0d0ae9573cf93ed3bbf9240', 'message': ""GRE tunnels should include local_ip.\n\nBecause you may only specify one local IP for a quantum agent, and\nyour agents could be routed across different subnets (even for small\ninstallations, for various reasons), it's important to also specify\nthe used local_ip when setting up the GRE tunnels. As long as the\naddress is routable on both ends, this will work. If the local_ip is\nnot specified, then traffic will mysteriously be dropped on one end\nwhere the IP does not match the expected IP in the GRE tunnel.\n\nBug: https://bugs.launchpad.net/quantum/+bug/1184696\n\nChange-Id: I5d612bf9e4f6652af8b155cdd1748d73ac4539ff\nSigned-off-by: Adin Scannell <adin@scannell.ca>\n""}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/64a6e9f2c83a6d7ab22ec741b1e8ee46e4a89409', 'message': ""GRE tunnels should include local_ip.\n\nBecause you may only specify one local IP for a quantum agent, and\nyour agents could be routed across different subnets (even for small\ninstallations, for various reasons), it's important to also specify\nthe used local_ip when setting up the GRE tunnels. As long as the\naddress is routable on both ends, this will work. If the local_ip is\nnot specified, then traffic will mysteriously be dropped on one end\nwhere the IP does not match the expected IP in the GRE tunnel.\n\nBug: https://bugs.launchpad.net/quantum/+bug/1184696\n\nChange-Id: I5d612bf9e4f6652af8b155cdd1748d73ac4539ff\nSigned-off-by: Adin Scannell <adin@scannell.ca>\n""}, {'number': 3, 'created': '2013-07-15 17:45:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ba4a0c2e2b4a57b970438a5e405d0fce36a71a1d', 'message': ""GRE tunnels should include local_ip.\n\nBecause you may only specify one local IP for a quantum agent, and\nyour agents could be routed across different subnets (even for small\ninstallations, for various reasons), it's important to also specify\nthe used local_ip when setting up the GRE tunnels. As long as the\naddress is routable on both ends, this will work. If the local_ip is\nnot specified, then traffic will mysteriously be dropped on one end\nwhere the IP does not match the expected IP in the GRE tunnel.\n\nBug: https://bugs.launchpad.net/quantum/+bug/1184696\n\nChange-Id: I5d612bf9e4f6652af8b155cdd1748d73ac4539ff\nSigned-off-by: Adin Scannell <adin@scannell.ca>\n""}, {'number': 4, 'created': '2013-07-18 14:39:32.000000000', 'files': ['neutron/agent/linux/ovs_lib.py', 'neutron/tests/unit/openvswitch/test_ovs_lib.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/openvswitch/test_ovs_tunnel.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c98ec249614b44d8e1a44cb07903338c3056e772', 'message': ""GRE tunnels should include local_ip.\n\nThis addresses the issue of having one or more multi-homed host.\n\nBecause you may only specify one local IP for a quantum agent, and\nother hosts could be routed across different subnets (even for small\ninstallations, for various reasons), it's important to also specify\nthe used local_ip when setting up the GRE tunnels. As long as the\naddress is routable on both ends, this will work. If the local_ip is\nnot specified, then traffic will mysteriously be dropped on one end\nwhere the IP does not match the expected IP in the GRE tunnel.\n\nBug: https://bugs.launchpad.net/quantum/+bug/1184696\n\nChange-Id: I5d612bf9e4f6652af8b155cdd1748d73ac4539ff\nSigned-off-by: Adin Scannell <adin@scannell.ca>\n""}]",1,30637,c98ec249614b44d8e1a44cb07903338c3056e772,18,7,4,7707,,,0,"GRE tunnels should include local_ip.

This addresses the issue of having one or more multi-homed host.

Because you may only specify one local IP for a quantum agent, and
other hosts could be routed across different subnets (even for small
installations, for various reasons), it's important to also specify
the used local_ip when setting up the GRE tunnels. As long as the
address is routable on both ends, this will work. If the local_ip is
not specified, then traffic will mysteriously be dropped on one end
where the IP does not match the expected IP in the GRE tunnel.

Bug: https://bugs.launchpad.net/quantum/+bug/1184696

Change-Id: I5d612bf9e4f6652af8b155cdd1748d73ac4539ff
Signed-off-by: Adin Scannell <adin@scannell.ca>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/30637/3 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/tests/unit/openvswitch/test_ovs_tunnel.py', 'quantum/agent/linux/ovs_lib.py', 'quantum/plugins/openvswitch/agent/ovs_quantum_agent.py', 'quantum/tests/unit/openvswitch/test_ovs_lib.py']",4,c6b00cc0af160709b0d0ae9573cf93ed3bbf9240,fix_gre_across_subnets," local_ip = ""1.1.1.1"" remote_ip = ""9.9.9.9"" pname, ""options:remote_ip="" + remote_ip], root_helper=self.root_helper) utils.execute([""ovs-vsctl"", self.TO, ""set"", ""Interface"", pname, ""options:local_ip="" + local_ip], self.assertEqual( self.br.add_tunnel_port(pname, remote_ip, local_ip), ofport)"," ip = ""9.9.9.9"" pname, ""options:remote_ip="" + ip], self.assertEqual(self.br.add_tunnel_port(pname, ip), ofport)",16,7
openstack%2Fswift~master~I085124acb6ef3cecb2375bb97d27996e0c6fd36e,openstack/swift,master,I085124acb6ef3cecb2375bb97d27996e0c6fd36e,Fix make_pre_authed_request function to not fail when path arg is None.,MERGED,2013-07-05 15:01:45.000000000,2013-07-23 01:38:05.000000000,2013-07-23 01:38:04.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 995}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 7847}]","[{'number': 1, 'created': '2013-07-05 15:01:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c1b0dbbe09d9a20a2adbf5460ef4f5f1b29116ed', 'message': 'Fix make_pre_authed_request function to not fail when path arg is None.\n\nThe default value for the path arg to the function is None. However, if\nthe path arg is not set or is set to None an exception is generated when\nthe path value is passed to urllib.unquote(). The function doc states that\nif path is not provided then the value in the env is used, so fix is to\nimplement this behaviour.\n\nChange-Id: I085124acb6ef3cecb2375bb97d27996e0c6fd36e\nFixes: bug #1198149\n'}, {'number': 2, 'created': '2013-07-08 16:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2e98cb408d0062e587d92a05a6129f14cb5f8ddc', 'message': 'Fix make_pre_authed_request function to not fail when path arg is None.\n\nThe default value for the path arg to the function is None. However, if\nthe path arg is not set or is set to None an exception is generated when\nthe path value is passed to urllib.unquote(). The function doc states that\nif path is not provided then the value in the env is used, so fix is to\nimplement this behaviour.\n\nChange-Id: I085124acb6ef3cecb2375bb97d27996e0c6fd36e\nFixes: bug #1198149\n'}, {'number': 3, 'created': '2013-07-12 08:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2c4250a30dab0fa1f65739f704bee04ed3c4d432', 'message': 'Fix make_pre_authed_request function to not fail when path arg is None.\n\nThe default value for the path arg to the function is None. However, if\nthe path arg is not set or is set to None an exception is generated when\nthe path value is passed to urllib.unquote(). The function doc states that\nif path is not provided then the value in the env is used, so fix is to\nimplement this behaviour.\n\nChange-Id: I085124acb6ef3cecb2375bb97d27996e0c6fd36e\nFixes: bug #1198149\n'}, {'number': 4, 'created': '2013-07-15 13:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/204e9330c8567d40c4ed6e66e988e196fbf25e4c', 'message': 'Fix make_pre_authed_request function to not fail when path arg is None.\n\nThe default value for the path arg to the function is None. However, if\nthe path arg is not set or is set to None an exception is generated when\nthe path value is passed to urllib.unquote(). The function doc states that\nif path is not provided then the value in the env is used, so fix is to\nimplement this behaviour.\n\nChange-Id: I085124acb6ef3cecb2375bb97d27996e0c6fd36e\nFixes: bug #1198149\n'}, {'number': 5, 'created': '2013-07-15 13:55:33.000000000', 'files': ['swift/common/wsgi.py', 'test/unit/common/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/27dc73fe0458ae5334c4547d700f912681a4bcfd', 'message': 'Fix make_pre_authed_request function to not fail when path arg is None.\n\nThe default value for the path arg to the function is None. However, if\nthe path arg is not set or is set to None an exception is generated when\nthe path value is passed to urllib.unquote(). The function doc states that\nif path is not provided then the value in the env is used, so fix is to\nimplement this behaviour.\n\nChange-Id: I085124acb6ef3cecb2375bb97d27996e0c6fd36e\nFixes: bug #1198149\n'}]",0,35816,27dc73fe0458ae5334c4547d700f912681a4bcfd,25,6,5,7847,,,0,"Fix make_pre_authed_request function to not fail when path arg is None.

The default value for the path arg to the function is None. However, if
the path arg is not set or is set to None an exception is generated when
the path value is passed to urllib.unquote(). The function doc states that
if path is not provided then the value in the env is used, so fix is to
implement this behaviour.

Change-Id: I085124acb6ef3cecb2375bb97d27996e0c6fd36e
Fixes: bug #1198149
",git fetch https://review.opendev.org/openstack/swift refs/changes/16/35816/4 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/wsgi.py', 'test/unit/common/test_wsgi.py']",2,c1b0dbbe09d9a20a2adbf5460ef4f5f1b29116ed,bug/1198149," def test_pre_auth_req_with_env_path(self): r = wsgi.make_pre_authed_request( {'PATH_INFO': '/path'}, 'GET') self.assertEquals(r.path, quote('/path')) ",,6,0
openstack%2Fswift~master~I825c5a968e8eae0991915056825fe0e0c195647e,openstack/swift,master,I825c5a968e8eae0991915056825fe0e0c195647e,Don't allow users to delete their own account.,MERGED,2013-05-15 08:54:09.000000000,2013-07-23 01:23:54.000000000,2013-07-23 01:23:54.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 866}, {'_account_id': 917}, {'_account_id': 1179}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 2649}, {'_account_id': 2696}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-05-15 08:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8a91506af9acfe097342f9a75b5e2eb00ad0f188', 'message': ""Don't allow users to delete their own account.\n\n- In keystoneauth we allowed authenticated users to delete their own\n  account we are disallowing that and only allow users with reseller\n  admin to do that for its own or for the others.\n- Fixes bug 1177526.\n\nChange-Id: I825c5a968e8eae0991915056825fe0e0c195647e\n""}, {'number': 2, 'created': '2013-05-17 08:27:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0b1e51a7007c586ea03443828015ae974eec0086', 'message': ""Don't allow users to delete their own account.\n\n- In keystoneauth we allowed authenticated users to delete their own\n  account we are disallowing that and only allow users with reseller\n  admin to do that for its own or for the others.\n- Fixes bug 1177526.\n\nChange-Id: I825c5a968e8eae0991915056825fe0e0c195647e\n""}, {'number': 3, 'created': '2013-05-21 07:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9833faf8d84a6252414c41f1dee8606d313b6dfb', 'message': ""Don't allow users to delete their own account.\n\n- In keystoneauth we allowed authenticated users to delete their own\n  account we are disallowing that and only allow users with reseller\n  admin to do that for its own or for the others.\n- Fixes bug 1177526.\n\nChange-Id: I825c5a968e8eae0991915056825fe0e0c195647e\n""}, {'number': 4, 'created': '2013-05-30 07:20:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b2646d93710eb33cfd71018cabebffa78007aa84', 'message': ""Don't allow users to delete their own account.\n\n- In keystoneauth we allowed authenticated users to delete their own\n  account we are disallowing that and only allow users with reseller\n  admin to do that for its own or for the others.\n- Fixes bug 1177526.\n\nChange-Id: I825c5a968e8eae0991915056825fe0e0c195647e\n""}, {'number': 5, 'created': '2013-05-30 08:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f0f6dd205802b44d54290cd5fedd9ca8048009fa', 'message': ""Don't allow users to delete their own account.\n\n- In keystoneauth we allowed authenticated users to delete their own\n  account we are disallowing that and only allow users with reseller\n  admin to do that for its own or for the others.\n- Fixed a few pep8 in test_keystoneauth along the way.\n- Fixes bug 1177526.\n\nChange-Id: I825c5a968e8eae0991915056825fe0e0c195647e\n""}, {'number': 6, 'created': '2013-06-13 08:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/310fea9112add99e7242bddfbcb7dce82da3c2f4', 'message': ""Don't allow users to delete their own account.\n\n- In keystoneauth we allowed authenticated users to delete their own\n  account we are disallowing that and only allow users with reseller\n  admin to do that for its own or for the others.\n- Fixes bug 1177526.\n\nChange-Id: I825c5a968e8eae0991915056825fe0e0c195647e\n""}, {'number': 7, 'created': '2013-07-03 16:33:25.000000000', 'files': ['test/unit/common/middleware/test_keystoneauth.py', 'swift/common/middleware/keystoneauth.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/6f722f7320c42415407587974ac9100a2cb8d08f', 'message': ""Don't allow users to delete their own account.\n\n- In keystoneauth we allowed authenticated users to delete their own\n  account we are disallowing that and only allow users with reseller\n  admin to do that for its own or for the others.\n- Fixes bug 1177526.\n\nChange-Id: I825c5a968e8eae0991915056825fe0e0c195647e\n""}]",2,29212,6f722f7320c42415407587974ac9100a2cb8d08f,61,10,7,866,,,0,"Don't allow users to delete their own account.

- In keystoneauth we allowed authenticated users to delete their own
  account we are disallowing that and only allow users with reseller
  admin to do that for its own or for the others.
- Fixes bug 1177526.

Change-Id: I825c5a968e8eae0991915056825fe0e0c195647e
",git fetch https://review.opendev.org/openstack/swift refs/changes/12/29212/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/test_keystoneauth.py', 'swift/common/middleware/keystoneauth.py']",2,8a91506af9acfe097342f9a75b5e2eb00ad0f188,bug/1177526," # If we are not reseller admin and user is trying to delete its own # account then deny it. if not container and not obj and req.method == 'DELETE': # User is not allowed to issue a DELETE on its own account msg = 'User %s:%s is not allowed to delete its own account' self.logger.debug(msg % (tenant_name, user)) return self.denied_response(req) ",,25,0
openstack%2Fkeystone~master~I7dfddeccbb766204e9d746ccaefd679e4860ff45,openstack/keystone,master,I7dfddeccbb766204e9d746ccaefd679e4860ff45,Get assignment driver,ABANDONED,2013-07-17 20:43:28.000000000,2013-07-23 01:07:15.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 5707}, {'_account_id': 6456}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-17 20:43:28.000000000', 'files': ['keystone/identity/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/7cfdf246b6f32e1fb5588db1b4df0ae397297ed0', 'message': 'Get assignment driver\n\nFixes Bug1200769\n\nChange-Id: I7dfddeccbb766204e9d746ccaefd679e4860ff45\n'}]",0,37561,7cfdf246b6f32e1fb5588db1b4df0ae397297ed0,9,6,1,6456,,,0,"Get assignment driver

Fixes Bug1200769

Change-Id: I7dfddeccbb766204e9d746ccaefd679e4860ff45
",git fetch https://review.opendev.org/openstack/keystone refs/changes/61/37561/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/identity/backends/ldap.py'],1,7cfdf246b6f32e1fb5588db1b4df0ae397297ed0,bug/1200769,from keystone import assignment self.assignment = assignment.Driver(),,2,0
openstack%2Fkeystone~master~I41b147bcc70b79b4fc6df50b242a73cfcad33114,openstack/keystone,master,I41b147bcc70b79b4fc6df50b242a73cfcad33114,Deprecate kvs token backend,MERGED,2013-06-27 01:16:04.000000000,2013-07-23 01:01:34.000000000,2013-07-23 01:01:33.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1849}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 4190}, {'_account_id': 5046}, {'_account_id': 6456}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-06-27 01:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/982c30e95d7126133bbbe28948041da4c6667ef2', 'message': ""Indicate kvs backend for tokens is only for testing\n\nThis backend is not usable in any production environment. All OpenStack\nenvironments will already have a SQL DB, and if someone does not want to\nuse the DB they can use the memcache backend.\n\nTo explicitly show this backend shouldn't be used rename it to fake, as\nthat is what it is a fake backend for testing.\n\nFixes  bug 1188301 and bug 1188370\n\nChange-Id: I41b147bcc70b79b4fc6df50b242a73cfcad33114\n""}, {'number': 2, 'created': '2013-06-27 18:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/df94b2003651aa5b478516f3ad9bdad89aadb81e', 'message': ""Indicate kvs backend for tokens is only for testing\n\nThis backend is not usable in any production environment. All OpenStack\nenvironments will already have a SQL DB, and if someone does not want to\nuse the DB they can use the memcache backend.\n\nTo explicitly show this backend shouldn't be used rename it to fake, as\nthat is what it is a fake backend for testing. To preserve backwards\ncompatibility, make a new kvs driver that inherits the fake driver and\nlogs a warning saying it is deprecated.\n\nFixes bug 1188301 and bug 1188370\n\nChange-Id: I41b147bcc70b79b4fc6df50b242a73cfcad33114\n""}, {'number': 3, 'created': '2013-06-27 22:10:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1e37cb6093a01c598b083c7beea1d970612e24cc', 'message': ""Indicate kvs backend for tokens is only for testing\n\nThis backend is not usable in any production environment. All OpenStack\nenvironments will already have a SQL DB, and if someone does not want to\nuse the DB they can use the memcache backend.\n\nTo explicitly show this backend shouldn't be used rename it to fake, as\nthat is what it is a fake backend for testing. To preserve backwards\ncompatibility, make a new kvs driver that inherits the fake driver and\nlogs a warning saying it is deprecated.\n\nFixes bug 1188301 and bug 1188370\n\nDocImpact\n\nChange-Id: I41b147bcc70b79b4fc6df50b242a73cfcad33114\n""}, {'number': 4, 'created': '2013-06-27 23:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/65efd7c1df7c50f5e616e6b3865c0439ba1e74fe', 'message': 'Deprecate kvs token backend\n\nThis backend is not usable in any production environment. All OpenStack\nenvironments will already have a SQL DB, and if someone does not want to\nuse the DB they can use the memcache backend.\n\nFixes bug 1188301 and bug 1188370\n\nDocImpact This backend should not be mentioned in documentation, as it\nis not production grade and is deprecated.\n\nChange-Id: I41b147bcc70b79b4fc6df50b242a73cfcad33114\n'}, {'number': 5, 'created': '2013-07-02 15:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1746c838bc8d798cc38e3ad011fff02f7d1918a2', 'message': 'Deprecate kvs token backend\n\nThis backend is not usable in any production environment. All OpenStack\nenvironments will already have a SQL DB, and if someone does not want to\nuse the DB they can use the memcache backend.\n\nFixes bug 1188301 and bug 1188370\n\nDocImpact This backend should not be mentioned in documentation, as it\nis not production grade and is deprecated.\n\nChange-Id: I41b147bcc70b79b4fc6df50b242a73cfcad33114\n'}, {'number': 6, 'created': '2013-07-02 17:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/05a9890ab5e15052754fa6ffca01d8bcd7bcadf4', 'message': 'Deprecate kvs token backend\n\nThis backend is not usable in any production environment. All OpenStack\nenvironments will already have a SQL DB, and if someone does not want to\nuse the DB they can use the memcache backend.\n\nFixes bug 1188301 and bug 1188370\n\nDocImpact This backend should not be mentioned in documentation, as it\nis not production grade and is deprecated.\n\nChange-Id: I41b147bcc70b79b4fc6df50b242a73cfcad33114\n'}, {'number': 7, 'created': '2013-07-16 21:32:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2620460a81d49e8028916d75a0cabbf3388a2084', 'message': 'Deprecate kvs token backend\n\nThis backend is not usable in any production environment. All OpenStack\nenvironments will already have a SQL DB, and if someone does not want to\nuse the DB they can use the memcache backend.\n\nFixes bug 1188301 and bug 1188370\n\nDocImpact This backend should not be mentioned in documentation, as it\nis not production grade and is deprecated.\n\nChange-Id: I41b147bcc70b79b4fc6df50b242a73cfcad33114\n'}, {'number': 8, 'created': '2013-07-16 23:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c65f4ecd6f744eb919bcb8e57df727a8b53ca141', 'message': 'Deprecate kvs token backend\n\nThis backend is not usable in any production environment. All OpenStack\nenvironments will already have a SQL DB, and if someone does not want to\nuse the DB they can use the memcache backend.\n\nFixes bug 1188301 and bug 1188370\n\nDocImpact This backend should not be mentioned in documentation, as it\nis not production grade and is deprecated.\n\nChange-Id: I41b147bcc70b79b4fc6df50b242a73cfcad33114\n'}, {'number': 9, 'created': '2013-07-18 21:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7fd5b43d3f4f9d9cc7b5f3f278073a8557bbd39c', 'message': 'Deprecate kvs token backend\n\nThis backend is not usable in any production environment. All OpenStack\nenvironments will already have a SQL DB, and if someone does not want to\nuse the DB they can use the memcache backend.\n\nFixes bug 1188301 and bug 1188370\n\nDocImpact This backend should not be mentioned in documentation, as it\nis not production grade and is deprecated.\n\nChange-Id: I41b147bcc70b79b4fc6df50b242a73cfcad33114\n'}, {'number': 10, 'created': '2013-07-22 20:57:38.000000000', 'files': ['keystone/token/backends/kvs.py', 'doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3f51d2addd38c418a55c01ca2f37e8bbe94319b5', 'message': 'Deprecate kvs token backend\n\nThis backend is not usable in any production environment. All OpenStack\nenvironments will already have a SQL DB, and if someone does not want to\nuse the DB they can use the memcache backend.\n\nFixes bug 1188301 and bug 1188370\n\nDocImpact This backend should not be mentioned in documentation, as it\nis not production grade and is deprecated.\n\nChange-Id: I41b147bcc70b79b4fc6df50b242a73cfcad33114\n'}]",4,34650,3f51d2addd38c418a55c01ca2f37e8bbe94319b5,54,9,10,1849,,,0,"Deprecate kvs token backend

This backend is not usable in any production environment. All OpenStack
environments will already have a SQL DB, and if someone does not want to
use the DB they can use the memcache backend.

Fixes bug 1188301 and bug 1188370

DocImpact This backend should not be mentioned in documentation, as it
is not production grade and is deprecated.

Change-Id: I41b147bcc70b79b4fc6df50b242a73cfcad33114
",git fetch https://review.opendev.org/openstack/keystone refs/changes/50/34650/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/backends/fake.py', 'tests/test_backend_kvs.py', 'tests/test_overrides.conf']",3,982c30e95d7126133bbbe28948041da4c6667ef2,bug/1188301,driver = keystone.token.backends.fake.Token,driver = keystone.token.backends.kvs.Token,2,2
openstack%2Fpython-novaclient~master~I7ab518886abf8d449caf1c70563a79a990d7765e,openstack/python-novaclient,master,I7ab518886abf8d449caf1c70563a79a990d7765e,Skip setting volume_size if not given,MERGED,2013-06-27 17:14:05.000000000,2013-07-23 01:01:32.000000000,2013-07-23 01:01:32.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-06-27 17:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/5c2bbbcbca7617b2e633c987ee73b0f3a86931a6', 'message': ""Skip setting volume_size if not given\n\nWhen the block-device parameters skip volume_size,\ndon't set it.\n\nFixes bug LP #1047568\n\nChange-Id: I7ab518886abf8d449caf1c70563a79a990d7765e\n""}, {'number': 2, 'created': '2013-06-29 10:52:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/fb37111665dfcd3b082dc3fd2ab3fce195fc6f8c', 'message': ""Skip setting volume_size if not given\n\nWhen the block-device parameters skip volume_size,\ndon't set it. Setting to an empty volume_size\nwould be invalid as it has to be an integer,\nand Nova API will reject the request if api validation\nis implemented. (proposed e.g. at\nhttps://review.openstack.org/#/c/34749/)\n\nFixes bug LP #1047568\n\nChange-Id: I7ab518886abf8d449caf1c70563a79a990d7765e\n""}, {'number': 3, 'created': '2013-07-10 15:09:57.000000000', 'files': ['novaclient/tests/v1_1/test_shell.py', 'novaclient/v1_1/base.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/f50ff361e27a8ca688c0f1ba448bbc8bfb284905', 'message': ""Skip setting volume_size if not given\n\nWhen the block-device parameters skip volume_size,\ndon't set it. Setting to an empty volume_size\nwould be invalid as it has to be an integer,\nand Nova API will reject the request if api validation\nis implemented. (proposed e.g. at\nhttps://review.openstack.org/#/c/34749/)\n\nFixes bug LP #1199539\n\nChange-Id: I7ab518886abf8d449caf1c70563a79a990d7765e\n""}]",0,34769,f50ff361e27a8ca688c0f1ba448bbc8bfb284905,13,4,3,6593,,,0,"Skip setting volume_size if not given

When the block-device parameters skip volume_size,
don't set it. Setting to an empty volume_size
would be invalid as it has to be an integer,
and Nova API will reject the request if api validation
is implemented. (proposed e.g. at
https://review.openstack.org/#/c/34749/)

Fixes bug LP #1199539

Change-Id: I7ab518886abf8d449caf1c70563a79a990d7765e
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/69/34769/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v1_1/base.py'],1,5c2bbbcbca7617b2e633c987ee73b0f3a86931a6,bug/1199539, if mapping_parts[2]: bdm_dict['volume_size'] = mapping_parts[2], bdm_dict['volume_size'] = mapping_parts[2],2,1
openstack%2Fswift~master~I18e6d0ee3fd6f9d889275ee8335e711c729b7171,openstack/swift,master,I18e6d0ee3fd6f9d889275ee8335e711c729b7171,Accept valid Accept headers in swob.,MERGED,2013-07-18 23:54:51.000000000,2013-07-23 01:01:14.000000000,2013-07-23 01:01:14.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1216}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 2828}]","[{'number': 1, 'created': '2013-07-18 23:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/453153eb5caa35f7bf47c1291ed9f63c87403663', 'message': 'Allow some valid Accept headers.\n\n""Accept: application/xml; charset=UTF-8"" is totally valid, and has an\nimplicit q (quality) value of 1.0, just the same as ""Accept: text/xml""\ndoes.\n\nAlso, you can say things like:\nAccept: text/xml; charset=UTF-8; q=0.9; anglebrackets=""are awesome""\nwith as many arbitrary extensions as you want.\n\nSee RFC 2616 sections 14.1 Accept and 2.2 Basic Rules for details.\n\nFixes bug 1202453.\n\nChange-Id: I18e6d0ee3fd6f9d889275ee8335e711c729b7171\n'}, {'number': 2, 'created': '2013-07-18 23:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ab0e3c2bb58e61698bb8dfca2eed2a5cfbf25332', 'message': 'Accept valid Accept headers in swob.\n\n""Accept: application/xml; charset=UTF-8"" is totally valid, and has an\nimplicit q (quality) value of 1.0, just the same as ""Accept: text/xml""\ndoes.\n\nAlso, you can say things like:\nAccept: text/xml; charset=UTF-8; q=0.9; anglebrackets=""are awesome""\nwith as many arbitrary extensions as you want.\n\nSee RFC 2616 sections 14.1 Accept and 2.2 Basic Rules for details.\n\nFixes bug 1202453.\n\nChange-Id: I18e6d0ee3fd6f9d889275ee8335e711c729b7171\n'}, {'number': 3, 'created': '2013-07-19 18:24:46.000000000', 'files': ['swift/common/swob.py', 'test/unit/common/test_swob.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/91e7e876b54c44e81df9fa10b111fb57d6c92107', 'message': 'Accept valid Accept headers in swob.\n\n""Accept: application/xml; charset=UTF-8"" is totally valid, and has an\nimplicit q (quality) value of 1.0, just the same as ""Accept: text/xml""\ndoes.\n\nAlso, you can say things like:\nAccept: text/xml; charset=UTF-8; q=0.9; anglebrackets=""are awesome""\nwith as many arbitrary extensions as you want.\n\nSee RFC 2616 sections 14.1 Accept and 2.2 Basic Rules for details.\n\nFixes bug 1202453.\n\nChange-Id: I18e6d0ee3fd6f9d889275ee8335e711c729b7171\n'}]",2,37812,91e7e876b54c44e81df9fa10b111fb57d6c92107,21,6,3,2622,,,0,"Accept valid Accept headers in swob.

""Accept: application/xml; charset=UTF-8"" is totally valid, and has an
implicit q (quality) value of 1.0, just the same as ""Accept: text/xml""
does.

Also, you can say things like:
Accept: text/xml; charset=UTF-8; q=0.9; anglebrackets=""are awesome""
with as many arbitrary extensions as you want.

See RFC 2616 sections 14.1 Accept and 2.2 Basic Rules for details.

Fixes bug 1202453.

Change-Id: I18e6d0ee3fd6f9d889275ee8335e711c729b7171
",git fetch https://review.opendev.org/openstack/swift refs/changes/12/37812/3 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/swob.py', 'test/unit/common/test_swob.py']",2,453153eb5caa35f7bf47c1291ed9f63c87403663,bug/1202453," '*/*;q=0.9,application/xml;q=1.0', 'application/xml;charset=UTF-8', 'application/xml;charset=UTF-8;qws=""quoted with space""', 'application/xml; q=0.99 ; qws=""quoted with space""'): 'text /plain', 'text\x7f/plain', 'text/plain;a=b=c', 'text/plain;q=1;q=2', 'text/plain; ubq=""unbalanced "" quotes""'):"," '*/*;q=0.9,application/xml;q=1.0'): 'text /plain', 'text\x7f/plain'):",36,7
openstack%2Fopenstack-manuals~master~I408a2d8c735cabc80d736654570894730f05960b,openstack/openstack-manuals,master,I408a2d8c735cabc80d736654570894730f05960b,update to pom file,MERGED,2013-07-23 00:35:17.000000000,2013-07-23 00:57:27.000000000,2013-07-23 00:57:26.000000000,"[{'_account_id': 3}, {'_account_id': 6923}]","[{'number': 1, 'created': '2013-07-23 00:35:17.000000000', 'files': ['doc/src/docbkx/openstack-training/pom.xml', 'doc/src/docbkx/openstack-training/bk002-ch001-associate-getting-started.xml', 'doc/src/docbkx/openstack-training/st-training-guides.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/756832cf7b9577c676fca8d77f71c7048a785515', 'message': 'update to pom file\n\nChange-Id: I408a2d8c735cabc80d736654570894730f05960b\n'}]",0,38234,756832cf7b9577c676fca8d77f71c7048a785515,5,2,1,6923,,,0,"update to pom file

Change-Id: I408a2d8c735cabc80d736654570894730f05960b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/34/38234/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-training/pom.xml', 'doc/src/docbkx/openstack-training/bk002-ch001-associate-getting-started.xml', 'doc/src/docbkx/openstack-training/st-training-guides.xml']",3,756832cf7b9577c676fca8d77f71c7048a785515,bb/training-manuals,,,97,131
openstack%2Fnova~master~Id9dfe482db3471d6a1b9b6c7d59a5ddc48775d7f,openstack/nova,master,Id9dfe482db3471d6a1b9b6c7d59a5ddc48775d7f,Check instance on dest once during block migration,MERGED,2013-06-27 03:08:50.000000000,2013-07-23 00:55:01.000000000,2013-07-23 00:54:59.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1011}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 3189}, {'_account_id': 4120}, {'_account_id': 4393}, {'_account_id': 5280}, {'_account_id': 6896}, {'_account_id': 7138}]","[{'number': 1, 'created': '2013-06-27 03:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/73ca15947b74a7b6be3b5ca124b24bdad217daec', 'message': ""Check instance on dest once during block migration\n\nDuring live block migrations both pre_live_migration and\npre_block_migration check for the prescence of the instance on\nthe destination and create the instance dir if it doesn't exist.\n\nAs a result the call to pre_block_migration always fails as\npre_live_migration has already created the instance dir on the\ndestination.\n\nFixes bug: #1193359\n\nChange-Id: Id9dfe482db3471d6a1b9b6c7d59a5ddc48775d7f\n""}, {'number': 2, 'created': '2013-06-30 05:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eff6f0844ede39b7a5df30223a3f383f5a020fd6', 'message': ""Check instance on dest once during block migration\n\nDuring live block migrations both pre_live_migration and\npre_block_migration check for the prescence of the instance on\nthe destination and create the instance dir if it doesn't exist.\n\nAs a result the call to pre_block_migration always fails as\npre_live_migration has already created the instance dir on the\ndestination.\n\nThe test of pre_block_migration is removed as all the function\ndoes now is download images and create backing files via\nnova.virt.libvirt.imagebackend which has a comprehensive set of\ntests.\n\nFixes bug: #1193359\n\nChange-Id: Id9dfe482db3471d6a1b9b6c7d59a5ddc48775d7f\n""}, {'number': 3, 'created': '2013-06-30 18:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db95a4fd3609fbf509b6c9945fc21d53ced3bdf7', 'message': ""Check instance on dest once during block migration\n\nDuring live block migrations both pre_live_migration and\npre_block_migration check for the prescence of the instance on\nthe destination and create the instance dir if it doesn't exist.\n\nAs a result the call to pre_block_migration always fails as\npre_live_migration has already created the instance dir on the\ndestination.\n\nThe test of pre_block_migration is removed as all the function\ndoes now is download images and create backing files via\nnova.virt.libvirt.imagebackend which has a comprehensive set of\ntests.\n\nFixes bug: #1193359\n\nChange-Id: Id9dfe482db3471d6a1b9b6c7d59a5ddc48775d7f\n""}, {'number': 4, 'created': '2013-07-04 02:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c8456474f4c95466aa8875932d6271a5d37384e9', 'message': ""Check instance on dest once during block migration\n\nDuring live block migrations both pre_live_migration and\npre_block_migration check for the presence of the instance on\nthe destination and create the instance dir if it doesn't exist.\n\nAs a result the call to pre_block_migration always fails as\npre_live_migration has already created the instance dir on the\ndestination.\n\nAs it turns out the pre_block_migration call is completely\nunnecessary. The libvirt driver is the only driver that uses the\ncall and the work it does can easily be done in the existing\npre_live_migration call. In order to streamline things we\ncompletely remove the pre_block_migration call from all\ndrivers. Additionally we update the function definition for\npre_live_migration to pass needed disk info down to the\nvirt drivers.\n\nFixes bug: #1193359\n\nChange-Id: Id9dfe482db3471d6a1b9b6c7d59a5ddc48775d7f\n""}, {'number': 5, 'created': '2013-07-22 23:06:12.000000000', 'files': ['nova/virt/hyperv/driver.py', 'nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py', 'nova/virt/xenapi/driver.py', 'nova/virt/fake.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'nova/tests/virt/xenapi/test_xenapi.py', 'nova/virt/driver.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/659ec75eaf052742a6269e0aae258f1c874749f7', 'message': ""Check instance on dest once during block migration\n\nDuring live block migrations both pre_live_migration and\npre_block_migration check for the presence of the instance on\nthe destination and create the instance dir if it doesn't exist.\n\nAs a result the call to pre_block_migration always fails as\npre_live_migration has already created the instance dir on the\ndestination.\n\nAs it turns out the pre_block_migration call is completely\nunnecessary. The libvirt driver is the only driver that uses the\ncall and the work it does can easily be done in the existing\npre_live_migration call. In order to streamline things we\ncompletely remove the pre_block_migration call from all\ndrivers. Additionally we update the function definition for\npre_live_migration to pass needed disk info down to the\nvirt drivers.\n\nFixes bug: #1193359\nChange-Id: Id9dfe482db3471d6a1b9b6c7d59a5ddc48775d7f\n""}]",7,34661,659ec75eaf052742a6269e0aae258f1c874749f7,36,11,5,3189,,,0,"Check instance on dest once during block migration

During live block migrations both pre_live_migration and
pre_block_migration check for the presence of the instance on
the destination and create the instance dir if it doesn't exist.

As a result the call to pre_block_migration always fails as
pre_live_migration has already created the instance dir on the
destination.

As it turns out the pre_block_migration call is completely
unnecessary. The libvirt driver is the only driver that uses the
call and the work it does can easily be done in the existing
pre_live_migration call. In order to streamline things we
completely remove the pre_block_migration call from all
drivers. Additionally we update the function definition for
pre_live_migration to pass needed disk info down to the
virt drivers.

Fixes bug: #1193359
Change-Id: Id9dfe482db3471d6a1b9b6c7d59a5ddc48775d7f
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/34661/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py']",2,73ca15947b74a7b6be3b5ca124b24bdad217daec,bug/1193359,," # NOTE (rmk): When preparing for a block migration, the instance dir # should not exist on the destination hypervisor. instance_dir = libvirt_utils.get_instance_path(instance) if os.path.exists(instance_dir): raise exception.DestinationDiskExists(path=instance_dir) os.mkdir(instance_dir)",2,8
openstack%2Ftempest~master~I86c93331a53b5a7323afe27839338ffa1428015f,openstack/tempest,master,I86c93331a53b5a7323afe27839338ffa1428015f,Move heat_available option to service_available,MERGED,2013-07-19 21:02:44.000000000,2013-07-23 00:48:38.000000000,2013-07-23 00:48:38.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5292}]","[{'number': 3, 'created': '2013-07-19 21:02:44.000000000', 'files': ['etc/tempest.conf.sample', 'tempest/config.py', 'tempest/api/orchestration/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a9d4388a72f66bde640e879b3a8d9210f8859cdb', 'message': 'Move heat_available option to service_available\n\nThis commit moves the heat_available config option from the\norchestration group to under the service_available group. The option\nis also renamed to heat.\n\nChange-Id: I86c93331a53b5a7323afe27839338ffa1428015f\n'}, {'number': 2, 'created': '2013-07-19 21:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/34eb3a19431b49b1a608db5a353551cafdc08cec', 'message': 'Move heat_available option to service_available\n\nThis commit moves the heat_available config option from the\norchestration group to under the service_available group. The option\nis also renamed to heat.\n\nChange-Id: I86c93331a53b5a7323afe27839338ffa1428015f\n'}, {'number': 1, 'created': '2013-07-19 21:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4ba917213fcfb27bfe4c6407b322decfaf44fef4', 'message': 'Move heat_available option to service_available\n\nThis commit moves the heat_available config option from the\norchestration group to under the service_available group. The option\nis also renamed to heat.\n\nChange-Id: I86c93331a53b5a7323afe27839338ffa1428015f\n'}]",0,37975,a9d4388a72f66bde640e879b3a8d9210f8859cdb,11,3,3,5196,,,0,"Move heat_available option to service_available

This commit moves the heat_available config option from the
orchestration group to under the service_available group. The option
is also renamed to heat.

Change-Id: I86c93331a53b5a7323afe27839338ffa1428015f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/75/37975/3 && git format-patch -1 --stdout FETCH_HEAD,"['etc/tempest.conf.sample', 'tempest/config.py', 'tempest/api/orchestration/base.py']",3,a9d4388a72f66bde640e879b3a8d9210f8859cdb,service-avail-group, if not os.config.service_available.heat:, if not cls.orchestration_cfg.heat_available:,6,7
openstack%2Ftempest~master~I658f70f259734e366cecce1c8e0409255351af87,openstack/tempest,master,I658f70f259734e366cecce1c8e0409255351af87,Add nova config option to service_available group,MERGED,2013-07-19 21:02:44.000000000,2013-07-23 00:48:32.000000000,2013-07-23 00:48:31.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-19 21:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/395056f26e7124000bd38de5b5765cfb5de96b6e', 'message': 'Add nova config option to service_available group\n\nThis commit adds a new config option, nova, to the service_available\nconfig group. This option is used to specify whether nova is running\nor not. It also add a skip to base compute api test class.\n\nChange-Id: I658f70f259734e366cecce1c8e0409255351af87\n'}, {'number': 2, 'created': '2013-07-19 21:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5adac31547aab52cfe8ce2d902e9de69a9e167ec', 'message': 'Add nova config option to service_available group\n\nThis commit adds a new config option, nova, to the service_available\nconfig group. This option is used to specify whether nova is running\nor not. It also add a skip to base compute api test class.\n\nChange-Id: I658f70f259734e366cecce1c8e0409255351af87\n'}, {'number': 3, 'created': '2013-07-19 21:02:44.000000000', 'files': ['tempest/api/compute/base.py', 'etc/tempest.conf.sample', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6b41e243331628b0a9efbc2ef1b65e5134be5609', 'message': 'Add nova config option to service_available group\n\nThis commit adds a new config option, nova, to the service_available\nconfig group. This option is used to specify whether nova is running\nor not. It also add a skip to base compute api test class.\n\nChange-Id: I658f70f259734e366cecce1c8e0409255351af87\n'}]",0,37974,6b41e243331628b0a9efbc2ef1b65e5134be5609,12,3,3,5196,,,0,"Add nova config option to service_available group

This commit adds a new config option, nova, to the service_available
config group. This option is used to specify whether nova is running
or not. It also add a skip to base compute api test class.

Change-Id: I658f70f259734e366cecce1c8e0409255351af87
",git fetch https://review.opendev.org/openstack/tempest refs/changes/74/37974/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/base.py', 'etc/tempest.conf.sample', 'tempest/config.py']",3,395056f26e7124000bd38de5b5765cfb5de96b6e,service-avail-group," cfg.BoolOpt('nova', default=True, help=""Whether or not nova is expected to be available""),",,8,0
openstack%2Ftempest~master~I8d81071cf5077fb880f04c04b330b1f4132a58f0,openstack/tempest,master,I8d81071cf5077fb880f04c04b330b1f4132a58f0,Add swift config option to service_available group,MERGED,2013-07-19 21:02:44.000000000,2013-07-23 00:48:25.000000000,2013-07-23 00:48:25.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5292}]","[{'number': 1, 'created': '2013-07-19 21:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/55badb2622262a484252b3b9b8e0aacc6aa4705a', 'message': 'Add swift config option to service_available group\n\nThis commit adds a new config option, swift, to the service_available\ngroup. This option can be used to specify whether swift is running.\nIt also adds a skip to the base object test class, replacing the\nendpoint detection skip.\n\nChange-Id: I8d81071cf5077fb880f04c04b330b1f4132a58f0\n'}, {'number': 2, 'created': '2013-07-19 21:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/214d63c817dc75de325bda40204b8ec82cf7a68c', 'message': 'Add swift config option to service_available group\n\nThis commit adds a new config option, swift, to the service_available\ngroup. This option can be used to specify whether swift is running.\nIt also adds a skip to the base object test class, replacing the\nendpoint detection skip.\n\nChange-Id: I8d81071cf5077fb880f04c04b330b1f4132a58f0\n'}, {'number': 3, 'created': '2013-07-19 21:02:44.000000000', 'files': ['tempest/api/object_storage/base.py', 'etc/tempest.conf.sample', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/61e332b00ba0ecfdb51b5d17c1715b17edcb7221', 'message': 'Add swift config option to service_available group\n\nThis commit adds a new config option, swift, to the service_available\ngroup. This option can be used to specify whether swift is running.\nIt also adds a skip to the base object test class, replacing the\nendpoint detection skip.\n\nChange-Id: I8d81071cf5077fb880f04c04b330b1f4132a58f0\n'}]",0,37973,61e332b00ba0ecfdb51b5d17c1715b17edcb7221,13,3,3,5196,,,0,"Add swift config option to service_available group

This commit adds a new config option, swift, to the service_available
group. This option can be used to specify whether swift is running.
It also adds a skip to the base object test class, replacing the
endpoint detection skip.

Change-Id: I8d81071cf5077fb880f04c04b330b1f4132a58f0
",git fetch https://review.opendev.org/openstack/tempest refs/changes/73/37973/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/object_storage/base.py', 'etc/tempest.conf.sample', 'tempest/config.py']",3,55badb2622262a484252b3b9b8e0aacc6aa4705a,service-avail-group," cfg.BoolOpt('swift', default=True, help=""Whether or not swift is expected to be available""),",,8,6
openstack%2Ftempest~master~I732b4d1d273bce4ba9d702bd3dbaae2bc5442e35,openstack/tempest,master,I732b4d1d273bce4ba9d702bd3dbaae2bc5442e35,Add glance to service_available config group,MERGED,2013-07-19 21:02:44.000000000,2013-07-23 00:46:16.000000000,2013-07-23 00:46:15.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5292}]","[{'number': 1, 'created': '2013-07-19 21:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0eb9c1ccd8c7fc4b87a4cff0beda8f3945439acc', 'message': 'Add glance to service_available config group\n\nThis commit adds a new config option, glance, to the service_available\nconfig group. This option is used to specify whether glance is running\nor not. It also adds skips for the appropriate api tests.\n\nChange-Id: I732b4d1d273bce4ba9d702bd3dbaae2bc5442e35\n'}, {'number': 2, 'created': '2013-07-19 21:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9b3b4bf4870955ae62ab8aa8aa6cdada091f37d0', 'message': 'Add glance to service_available config group\n\nThis commit adds a new config option, glance, to the service_available\nconfig group. This option is used to specify whether glance is running\nor not. It also adds skips for the appropriate api tests.\n\nChange-Id: I732b4d1d273bce4ba9d702bd3dbaae2bc5442e35\n'}, {'number': 3, 'created': '2013-07-19 21:02:44.000000000', 'files': ['tempest/api/compute/images/test_list_images.py', 'tempest/api/image/base.py', 'etc/tempest.conf.sample', 'tempest/api/compute/images/test_images.py', 'tempest/api/compute/images/test_image_metadata.py', 'tempest/config.py', 'tempest/api/compute/images/test_list_image_filters.py', 'tempest/api/compute/images/test_images_oneserver.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/853ae4476a40bbda60b4a458ca4fd3633ec8994b', 'message': 'Add glance to service_available config group\n\nThis commit adds a new config option, glance, to the service_available\nconfig group. This option is used to specify whether glance is running\nor not. It also adds skips for the appropriate api tests.\n\nChange-Id: I732b4d1d273bce4ba9d702bd3dbaae2bc5442e35\n'}]",0,37972,853ae4476a40bbda60b4a458ca4fd3633ec8994b,17,4,3,5196,,,0,"Add glance to service_available config group

This commit adds a new config option, glance, to the service_available
config group. This option is used to specify whether glance is running
or not. It also adds skips for the appropriate api tests.

Change-Id: I732b4d1d273bce4ba9d702bd3dbaae2bc5442e35
",git fetch https://review.opendev.org/openstack/tempest refs/changes/72/37972/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/images/test_list_images.py', 'tempest/api/image/base.py', 'etc/tempest.conf.sample', 'tempest/api/compute/images/test_images.py', 'tempest/api/compute/images/test_image_metadata.py', 'tempest/config.py', 'tempest/api/compute/images/test_list_image_filters.py', 'tempest/api/compute/images/test_images_oneserver.py']",8,0eb9c1ccd8c7fc4b87a4cff0beda8f3945439acc,service-avail-group," if not cls.config.service_available.glance: skip_msg = (""%s skipped as glance is not available"" % cls.__name__) raise cls.skipException(skip_msg)",,24,0
openstack%2Fdevstack-gate~master~I8cea5f4df7563dcc7d44a046e2d3fb09e0d8fc9e,openstack/devstack-gate,master,I8cea5f4df7563dcc7d44a046e2d3fb09e0d8fc9e,Add jeepyb to the list of cached repos,MERGED,2013-07-13 00:00:38.000000000,2013-07-23 00:33:37.000000000,2013-07-23 00:33:37.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6609}]","[{'number': 1, 'created': '2013-07-13 00:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/dc6081f0ac5449d301987b08b53b96729845a079', 'message': 'Add jeepyb to the list of cached repos\n\nChange-Id: I8cea5f4df7563dcc7d44a046e2d3fb09e0d8fc9e\n'}, {'number': 2, 'created': '2013-07-19 16:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/eebac9e61cf8498e3ebe88c33b4446b47e1719e3', 'message': ""Add jeepyb to the list of cached repos\n\nThe pbr integration test turns out to also be a good test of the\ncontents of the requirements repo and of jeepyb's run-mirror script,\nsince it uses both. If we add jeepyb to the list of repos that are\non a devstack-gate node, then we can construct the integration test\nto actually gate not only changes to pbr, but also changes to jeepyb\nand requirements, which should ensure that we don't wind up with\nbad requirements added or mirror breakages.\n\nChange-Id: I8cea5f4df7563dcc7d44a046e2d3fb09e0d8fc9e\n""}, {'number': 3, 'created': '2013-07-22 21:57:13.000000000', 'files': ['devstack-vm-gate-wrap.sh', 'devstack-vm-update-image.py'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/d2e6f354ca1100fe92b1d75331d768d251fcdce3', 'message': ""Add jeepyb to the list of cached repos\n\nThe pbr integration test turns out to also be a good test of the\ncontents of the requirements repo and of jeepyb's run-mirror script,\nsince it uses both. If we add jeepyb to the list of repos that are\non a devstack-gate node, then we can construct the integration test\nto actually gate not only changes to pbr, but also changes to jeepyb\nand requirements, which should ensure that we don't wind up with\nbad requirements added or mirror breakages.\n\nChange-Id: I8cea5f4df7563dcc7d44a046e2d3fb09e0d8fc9e\n""}]",0,36923,d2e6f354ca1100fe92b1d75331d768d251fcdce3,24,6,3,2,,,0,"Add jeepyb to the list of cached repos

The pbr integration test turns out to also be a good test of the
contents of the requirements repo and of jeepyb's run-mirror script,
since it uses both. If we add jeepyb to the list of repos that are
on a devstack-gate node, then we can construct the integration test
to actually gate not only changes to pbr, but also changes to jeepyb
and requirements, which should ensure that we don't wind up with
bad requirements added or mirror breakages.

Change-Id: I8cea5f4df7563dcc7d44a046e2d3fb09e0d8fc9e
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/23/36923/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,dc6081f0ac5449d301987b08b53b96729845a079,projects-list,"PROJECTS=""openstack-infra/jeepyb $PROJECTS""",,1,0
openstack%2Fpython-swiftclient~master~Ic6afdb92882284f843aacb06d20f682ddcb47151,openstack/python-swiftclient,master,Ic6afdb92882284f843aacb06d20f682ddcb47151,Refuse carriage return in header value,MERGED,2013-07-07 08:53:27.000000000,2013-07-23 00:09:47.000000000,2013-07-23 00:09:47.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 866}, {'_account_id': 2622}, {'_account_id': 2696}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-07-07 08:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/dca9c232acaaaffdab3bbcac56de826d4fbd47e3', 'message': 'refuse carriage return in meta value\n\nSome talks are in bug #1188896.\nComparing with Curl and Django, they refuse carriage returns in header\nvalues, so I add a clientexception in swift client.\n\nFixes bug #1188896\n\nChange-Id: Ic6afdb92882284f843aacb06d20f682ddcb47151\n'}, {'number': 2, 'created': '2013-07-09 02:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/dc90db494d724ed1af0a53056df3425e240a71d4', 'message': 'refuse carriage return in meta value\n\nSome talks are in bug #1188896.\nComparing with Curl and Django, they refuse carriage returns in header\nvalues, so I add a clientexception in swift client.\n\n(and fix some pep8 issues)\n\nFixes bug #1188896\n\nChange-Id: Ic6afdb92882284f843aacb06d20f682ddcb47151\n'}, {'number': 3, 'created': '2013-07-09 02:43:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/7d39517c88bb2220507ce5e828b9a6bc0f246ef6', 'message': 'refuse carriage return in meta value\n\nSome talks are in bug #1188896.\nComparing with Curl and Django, they refuse carriage returns in header\nvalues, so I add a clientexception in swift client.\n\nFixes bug #1188896\n\nChange-Id: Ic6afdb92882284f843aacb06d20f682ddcb47151\n'}, {'number': 4, 'created': '2013-07-09 02:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/d66bb3378d4079c1ca6c9d7f6e2b8b6c15e09c3f', 'message': 'refuse carriage return in header value\n\nSome talks are in bug #1188896.\nComparing with Curl and Django, they refuse carriage returns in header\nvalues, so I add a clientexception in swift client.\n\nFixes bug #1188896\n\nChange-Id: Ic6afdb92882284f843aacb06d20f682ddcb47151\n'}, {'number': 5, 'created': '2013-07-12 22:20:49.000000000', 'files': ['tests/test_swiftclient.py', 'swiftclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/7d88d14def2541227fb4d3f96016a51b0bafa36b', 'message': 'Refuse carriage return in header value\n\nSee bug #1188896.\nComparing with Curl and Django, they both refuse carriage returns in\nheader values, so the request() method on the HTTP(S)Connection instance\nreturned by swiftclient.client.http_connection() will raise an\nInvalidHeadersException if any of the headers to be sent contain a\nnewline.\n\nDrive-by fix for a couple of header values which were integers instead\nof strings (Content-Length getting set to zero).\n\nFixes bug #1188896\n\nChange-Id: Ic6afdb92882284f843aacb06d20f682ddcb47151\n'}]",1,35987,7d88d14def2541227fb4d3f96016a51b0bafa36b,20,7,5,6835,,,0,"Refuse carriage return in header value

See bug #1188896.
Comparing with Curl and Django, they both refuse carriage returns in
header values, so the request() method on the HTTP(S)Connection instance
returned by swiftclient.client.http_connection() will raise an
InvalidHeadersException if any of the headers to be sent contain a
newline.

Drive-by fix for a couple of header values which were integers instead
of strings (Content-Length getting set to zero).

Fixes bug #1188896

Change-Id: Ic6afdb92882284f843aacb06d20f682ddcb47151
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/87/35987/4 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift'],1,dca9c232acaaaffdab3bbcac56de826d4fbd47e3,bug/1188896," if '\n' in split_item[1]: raise ClientException(""meta value can't contain carriage returns"")",,2,0
openstack%2Foslo-incubator~master~Iacae482fda07507c3e7ce8e6da8dbb7bde699016,openstack/oslo-incubator,master,Iacae482fda07507c3e7ce8e6da8dbb7bde699016,Allow use of hacking 0.6.0 and enable new checks,MERGED,2013-07-19 19:03:32.000000000,2013-07-23 00:07:15.000000000,2013-07-23 00:07:15.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 1849}, {'_account_id': 1994}, {'_account_id': 4146}, {'_account_id': 6593}, {'_account_id': 6786}]","[{'number': 1, 'created': '2013-07-19 19:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/8ed81b7d0493f7654f0ac8dee1242fbd6430d3d1', 'message': ""Allow use of hacking 0.6.0 and enable new checks\n\nThere are only several erros after runing hacking 0.6.0:\n\n* H501  Do not use locals() for string formatting\n* H231  Python 3.x incompatible 'except x,y:' construct\n\nChange-Id: Iacae482fda07507c3e7ce8e6da8dbb7bde699016\n""}, {'number': 2, 'created': '2013-07-19 20:37:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/2aefac778e456d2b5f57dad30a74f76f050279c0', 'message': ""Allow use of hacking 0.6.0 and enable new checks\n\nThere are only several errors after runing hacking 0.6.0:\n\n* H501  Do not use locals() for string formatting\n* H231  Python 3.x incompatible 'except x,y:' construct\n\nChange-Id: Iacae482fda07507c3e7ce8e6da8dbb7bde699016\n""}, {'number': 3, 'created': '2013-07-19 23:25:09.000000000', 'files': ['openstack/common/policy.py', 'tests/unit/db/sqlalchemy/test_migrations.py', 'test-requirements.txt', 'tests/unit/rpc/common.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/7bf8ee930b1838a1b1640912df0e2050bd9b96ae', 'message': ""Allow use of hacking 0.6.0 and enable new checks\n\nThere are only several errors after running hacking 0.6.0:\n\n* H501  Do not use locals() for string formatting\n* H231  Python 3.x incompatible 'except x,y:' construct\n\nChange-Id: Iacae482fda07507c3e7ce8e6da8dbb7bde699016\n""}]",4,37957,7bf8ee930b1838a1b1640912df0e2050bd9b96ae,30,8,3,6786,,,0,"Allow use of hacking 0.6.0 and enable new checks

There are only several errors after running hacking 0.6.0:

* H501  Do not use locals() for string formatting
* H231  Python 3.x incompatible 'except x,y:' construct

Change-Id: Iacae482fda07507c3e7ce8e6da8dbb7bde699016
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/57/37957/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/policy.py', 'tests/unit/db/sqlalchemy/test_migrations.py', 'test-requirements.txt', 'tests/unit/rpc/common.py']",4,8ed81b7d0493f7654f0ac8dee1242fbd6430d3d1,," % {'queue': queue, 'value': value})", % locals()),14,12
openstack%2Foslo-incubator~master~Id40422ae170935d2fc1c7443eee4b31161b7d3d3,openstack/oslo-incubator,master,Id40422ae170935d2fc1c7443eee4b31161b7d3d3,Import config file generator module from python path,MERGED,2013-07-17 03:55:12.000000000,2013-07-22 23:42:20.000000000,2013-07-22 23:42:20.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2472}, {'_account_id': 6159}]","[{'number': 1, 'created': '2013-07-17 03:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/0e4526813b2dc1b1806fe778145c245e451858a4', 'message': ""Makes config file generator executable from anywhere\n\nThe generator script has to be executed from oslo's base dir otherwise\nthe script won't be able to finde the generator.py module. It will be\npossible to run the generator anywhere if we add oslo's base dir to the\ntemporary python path.\n\nChange-Id: Id40422ae170935d2fc1c7443eee4b31161b7d3d3\n""}, {'number': 2, 'created': '2013-07-18 16:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/550e2b291d293f913c003c4b78f0aa4849f44812', 'message': 'Makes config file generator executable from anywhere\n\nThe generator script was not able to find the generator.py module\nbecause of the wrong module path. This patch makes it possible\nto run the generator anywhere after imported to a projet.\n\nChange-Id: Id40422ae170935d2fc1c7443eee4b31161b7d3d3\n'}, {'number': 3, 'created': '2013-07-20 08:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/979e3a94d17cc32a4391224a4904f99a02339661', 'message': 'Import config file generator module from python path\n\nThe sample config file generator will be executed in each project\nby being copied using the update.py module. Therefore accessing\nthe generator module would not work the current way of using relative paths.\nThis patch executes the generator module from by directly importing it.\nThe update.py will update the module path when copying to each project.\n\nChange-Id: Id40422ae170935d2fc1c7443eee4b31161b7d3d3\n'}, {'number': 4, 'created': '2013-07-20 14:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f68089be786caba4f496c5ea1e0ad9e501a7c205', 'message': 'Import config file generator module from python path\n\nThe sample config file generator will be executed in each project\nby being copied using the update.py module. Therefore accessing\nthe generator module would not work the current way of using relative paths.\nThis patch executes the generator module from by directly importing it.\nThe update.py will update the module path when copying to each project.\n\nChange-Id: Id40422ae170935d2fc1c7443eee4b31161b7d3d3\n'}, {'number': 5, 'created': '2013-07-20 14:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/fa528fcb8673830eeb33b17b276beb2d5a58b299', 'message': 'Import config file generator module from python path\n\nThe sample config file generator will be executed in each project\nby being copied using the update.py module. Therefore accessing\nthe generator module would not work the current way of using relative paths.\nThis patch executes the generator module from by directly importing it.\nThe update.py will update the module path when copying to each project.\n\nChange-Id: Id40422ae170935d2fc1c7443eee4b31161b7d3d3\n'}, {'number': 6, 'created': '2013-07-21 00:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b65599fbdf909a5f5c2350f7e410c4cb763e0287', 'message': ""Import config file generator module from python path\n\nThe sample config file generator will be executed in each project's\nvirtualenv after being copied using the update.py module. Therefore\naccessing the generator module would not work the current way\nof using relative paths. This patch executes the generator module\nby directly importing it. The update.py will update the module path\nwhen copying to each project.\n\nChange-Id: Id40422ae170935d2fc1c7443eee4b31161b7d3d3\n""}, {'number': 7, 'created': '2013-07-22 11:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/017c84de7b768f83280d8af7f34597c231febebe', 'message': ""Import config file generator module from python path\n\nThe sample config file generator will be executed in each project's\nvirtualenv after being copied using the update.py module. Therefore\naccessing the generator module would not work the current way\nof using relative paths. This patch executes the generator module\nby directly importing it. The update.py will update the module path\nwhen copying to each project.\n\nChange-Id: Id40422ae170935d2fc1c7443eee4b31161b7d3d3\n""}, {'number': 8, 'created': '2013-07-22 11:50:06.000000000', 'files': ['tools/config/generate_sample.sh'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/8667c73dbededde1629dbcff4d6760f44cf2547b', 'message': ""Import config file generator module from python path\n\nThe sample config file generator will be executed in each project's\nvirtualenv after being copied using the update.py module. Therefore\naccessing the generator module would not work the current way\nof using relative paths. This patch executes the generator module\nby directly importing it. The update.py will update the module path\nwhen copying to each project.\n\nChange-Id: Id40422ae170935d2fc1c7443eee4b31161b7d3d3\n""}]",0,37387,8667c73dbededde1629dbcff4d6760f44cf2547b,39,6,8,1994,,,0,"Import config file generator module from python path

The sample config file generator will be executed in each project's
virtualenv after being copied using the update.py module. Therefore
accessing the generator module would not work the current way
of using relative paths. This patch executes the generator module
by directly importing it. The update.py will update the module path
when copying to each project.

Change-Id: Id40422ae170935d2fc1c7443eee4b31161b7d3d3
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/87/37387/3 && git format-patch -1 --stdout FETCH_HEAD,['tools/config/generate_sample.sh'],1,0e4526813b2dc1b1806fe778145c245e451858a4,2,"OSLOBASEDIR=$(dirname ""$0"")/../.. MODULEPATH=$OSLOBASEDIR/openstack/common/config/generator.pyPYTHONPATH=$OSLOBASEDIR/:$BASEDIR/:$PYTHONPATH python $MODULEPATH $FILES > $OUTPUTFILE","MODULEPATH=$(dirname ""$0"")/../../openstack/common/config/generator.pyPYTHONPATH=$BASEDIR/:${PYTHONPATH} python $MODULEPATH $FILES > $OUTPUTFILE",4,2
openstack%2Foslo-incubator~master~Ie8336b070573c74691ab5e7304dd05c540826c53,openstack/oslo-incubator,master,Ie8336b070573c74691ab5e7304dd05c540826c53,Fix issues syncing sample generator in update.py,MERGED,2013-07-19 07:35:55.000000000,2013-07-22 23:41:29.000000000,2013-07-22 23:41:29.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2271}, {'_account_id': 5638}]","[{'number': 1, 'created': '2013-07-19 07:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/2e542669b9f941c49bcbe34a62b76ac119759e11', 'message': 'Fix glob against tools dir in update.py\n\nWhen updating the openstack.common.config module,\nthe glob module finds the wrong files in the tools directory.\nFixed to grab the files inside the directory which name matches\nthe module name.\n\nChange-Id: Ie8336b070573c74691ab5e7304dd05c540826c53\n'}, {'number': 2, 'created': '2013-07-19 08:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f69e0caa05c6c3406add9625d1a4c1a8fc6158b3', 'message': 'Fix glob against tools dir in update.py\n\nWhen updating the openstack.common.config module, the shutil module\nraises an exception when attemting to copy a directory.\nFixed to skip directories as copy targets and handle directories\nof target module names.\n\nChange-Id: Ie8336b070573c74691ab5e7304dd05c540826c53\n'}, {'number': 3, 'created': '2013-07-20 08:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f9d1de6790c06db7e78e65bb17d75abfb29032b3', 'message': 'Fix issues syncing sample generator in update.py\n\nWhen updating the openstack.common.config module, the shutil module\nraises an exception when attemting to copy a directory.\nFixed to skip directories as copy targets and handle directories\nof target module names.\nFixed problem of wrong import path of the generator module.\n\nChange-Id: Ie8336b070573c74691ab5e7304dd05c540826c53\n'}, {'number': 4, 'created': '2013-07-20 14:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/3ed4a704ad5a6147a9d1a7fc09eaceda7f2f45f4', 'message': 'Fix issues syncing sample generator in update.py\n\nWhen updating the openstack.common.config module, the shutil module\nraises an exception when attemting to copy a directory.\nFixed to skip directories as copy targets and handle directories\nof target module names.\nFixed problem of wrong import path of the generator module.\n\nChange-Id: Ie8336b070573c74691ab5e7304dd05c540826c53\n'}, {'number': 5, 'created': '2013-07-20 14:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/fc1d3de1bff6e469b7923b23d7202d11903aae84', 'message': 'Fix issues syncing sample generator in update.py\n\nWhen updating the openstack.common.config module, the shutil module\nraises an exception when attemting to copy a directory.\nFixed to skip directories as copy targets and handle directories\nof target module names.\nFixed problem of wrong import path of the generator module.\n\nChange-Id: Ie8336b070573c74691ab5e7304dd05c540826c53\n'}, {'number': 6, 'created': '2013-07-21 00:48:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/44130856eb47057f64a46f52c055a1c379b06b91', 'message': 'Fix issues syncing sample generator in update.py\n\nWhen updating the openstack.common.config module, the shutil module\nraises an exception when attemting to copy a directory.\nFixed to skip directories as copy targets and handle directories\nof target module names.\nFixed problem of wrong import path of the generator module.\n\nChange-Id: Ie8336b070573c74691ab5e7304dd05c540826c53\n'}, {'number': 7, 'created': '2013-07-22 11:37:44.000000000', 'files': ['update.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/4cd94cd7633eb18c6928eef6ad3db1ac4ed4d406', 'message': 'Fix issues syncing sample generator in update.py\n\nWhen updating the openstack.common.config module, the shutil module\nraises an exception when attemting to copy a directory.\nFixed to skip directories as copy targets and handle directories\nof target module names.\nFixed problem of wrong import path of the generator module.\n\nChange-Id: Ie8336b070573c74691ab5e7304dd05c540826c53\n'}]",0,37846,4cd94cd7633eb18c6928eef6ad3db1ac4ed4d406,31,6,7,1994,,,0,"Fix issues syncing sample generator in update.py

When updating the openstack.common.config module, the shutil module
raises an exception when attemting to copy a directory.
Fixed to skip directories as copy targets and handle directories
of target module names.
Fixed problem of wrong import path of the generator module.

Change-Id: Ie8336b070573c74691ab5e7304dd05c540826c53
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/46/37846/7 && git format-patch -1 --stdout FETCH_HEAD,['update.py'],1,2e542669b9f941c49bcbe34a62b76ac119759e11,update_config," os.path.join('tools', mod, '*'), os.path.join('tools', mod + '*py'),"," os.path.join('tools', mod + '*'),",2,1
openstack%2Fironic~master~I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5,openstack/ironic,master,I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5,Add RPC methods for updating nodes.,MERGED,2013-06-22 20:27:21.000000000,2013-07-22 23:26:16.000000000,2013-07-22 21:26:52.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2889}, {'_account_id': 4919}, {'_account_id': 5805}, {'_account_id': 6773}]","[{'number': 1, 'created': '2013-06-22 20:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e3e6ecde4af7ce94d50b5314598a5e1eea0a6978', 'message': ""WIP: add 'update_node' RPC method\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nAlso, this is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n""}, {'number': 2, 'created': '2013-06-24 18:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c2e216cb3dbc397d686561fd228acb15ca4ddcf0', 'message': ""WIP: add 'update_node' RPC method\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nAlso, this is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n""}, {'number': 3, 'created': '2013-07-02 15:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0a399657668209773908e146615918526859c85c', 'message': ""Add 'update_node' RPC method\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nAlso, this is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n""}, {'number': 4, 'created': '2013-07-10 15:57:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8dd850cebaa4c6791ac0934cca30f6d09eac64d3', 'message': ""Add 'update_node' RPC method\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nAlso, this is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n""}, {'number': 5, 'created': '2013-07-10 16:03:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/884f6ebd286ac8b1fa6c94c712443c89da94f1a7', 'message': ""Add 'update_node' RPC method\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nAlso, this is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n""}, {'number': 6, 'created': '2013-07-12 14:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b477f66e2da3203946a28b6da769df5c17db4a98', 'message': ""Add 'update_node' RPC method\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nAlso, this is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n""}, {'number': 7, 'created': '2013-07-14 16:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/445b8e53d3db8200dcbcec51466260bc71d31516', 'message': 'Add RPC methods for updating nodes.\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nThis is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nThis patch also clarifies the description of node state changes\nin states.py, and does a minimal amount of reasonable checking\nto ensure that nodes do not get put into inconsistent situations.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n'}, {'number': 8, 'created': '2013-07-15 16:00:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/63042cc070a776010db0c60f2df1e393b6cea84c', 'message': 'Add RPC methods for updating nodes.\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nThis is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nThis patch also clarifies the description of node state changes\nin states.py, and does a minimal amount of reasonable checking\nto ensure that nodes do not get put into inconsistent situations.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n'}, {'number': 9, 'created': '2013-07-18 17:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/49f0cd49b2877075a43a166586ea99bd8bc9cc64', 'message': 'Add RPC methods for updating nodes.\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nThis is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nThis patch also clarifies the description of node state changes\nin states.py, and does a minimal amount of reasonable checking\nto ensure that nodes do not get put into inconsistent situations.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n'}, {'number': 10, 'created': '2013-07-18 18:09:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/998e033935004d9bfacc2e43a3ce78d07b7ad185', 'message': 'Add RPC methods for updating nodes.\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nThis is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nThis patch also clarifies the description of node state changes\nin states.py, and does a minimal amount of reasonable checking\nto ensure that nodes do not get put into inconsistent situations.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n'}, {'number': 11, 'created': '2013-07-18 22:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0efa3650c0031c4ab8bc735a125c142ff50e6694', 'message': 'Add RPC methods for updating nodes.\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nThis is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nThis patch also clarifies the description of node state changes\nin states.py, and does a minimal amount of reasonable checking\nto ensure that nodes do not get put into inconsistent situations.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n'}, {'number': 12, 'created': '2013-07-18 22:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a5a3dad5113c8073c767707d6f1223dd08f5acb5', 'message': 'Add RPC methods for updating nodes.\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nThis is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nThis patch also clarifies the description of node state changes\nin states.py, and does a minimal amount of reasonable checking\nto ensure that nodes do not get put into inconsistent situations.\n\nIt also adds some unit tests to the API for both the new method\nand for get_all, which already existed.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n'}, {'number': 13, 'created': '2013-07-18 22:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bb95a5122859be6ce34e09f4f7944a4877c94af5', 'message': 'Add RPC methods for updating nodes.\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nThis is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nThis patch also clarifies the description of node state changes\nin states.py, and does a minimal amount of reasonable checking\nto ensure that nodes do not get put into inconsistent situations.\n\nIt also adds some unit tests to the API for both the new method\nand for get_all, which already existed.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n'}, {'number': 14, 'created': '2013-07-19 06:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/127705269e0502d8b3fbd3ca7fb8714bca2d55d8', 'message': 'Add RPC methods for updating nodes.\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nThis is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nThis patch also clarifies the description of node state changes\nin states.py, and does a minimal amount of reasonable checking\nto ensure that nodes do not get put into inconsistent situations.\n\nIt also adds some unit tests to the API for both the new method\nand for get_all, which already existed.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n'}, {'number': 15, 'created': '2013-07-19 19:14:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/05c0f9d26d8fed7d2e16293845e93c2aff2b0a13', 'message': 'Add RPC methods for updating nodes.\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nThis is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nThis patch also clarifies the description of node state changes\nin states.py, and does a minimal amount of reasonable checking\nto ensure that nodes do not get put into inconsistent situations.\n\nIt also adds some unit tests to the API for both the new method\nand for get_all, which already existed.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n'}, {'number': 16, 'created': '2013-07-22 21:20:42.000000000', 'files': ['ironic/tests/api/test_list_nodes.py', 'ironic/api/controllers/v1/base.py', 'ironic/tests/conductor/test_task_manager.py', 'ironic/tests/conductor/test_rpcapi.py', 'ironic/conductor/rpcapi.py', 'ironic/tests/api/test_nodes.py', 'ironic/common/exception.py', 'ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py', 'ironic/api/hooks.py', 'ironic/common/states.py', 'ironic/tests/api/base.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/55222ce07b1b3192ea4eb38799268bbda82b781f', 'message': 'Add RPC methods for updating nodes.\n\nBy having the API service use an RPC call to the Conductor,\nwe can take an exclusive task lock on the node being updated.\nThis will prevent updates to a node while a task is in process on it.\n\nThis is the first method implemented using RPC of a versioned\nobject to provide distributed locking between API and Conductor\ninstances.\n\nThis patch also clarifies the description of node state changes\nin states.py, and does a minimal amount of reasonable checking\nto ensure that nodes do not get put into inconsistent situations.\n\nIt also adds some unit tests to the API for both the new method\nand for get_all, which already existed.\n\nChange-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5\n'}]",10,34115,55222ce07b1b3192ea4eb38799268bbda82b781f,51,6,16,2889,,,0,"Add RPC methods for updating nodes.

By having the API service use an RPC call to the Conductor,
we can take an exclusive task lock on the node being updated.
This will prevent updates to a node while a task is in process on it.

This is the first method implemented using RPC of a versioned
object to provide distributed locking between API and Conductor
instances.

This patch also clarifies the description of node state changes
in states.py, and does a minimal amount of reasonable checking
to ensure that nodes do not get put into inconsistent situations.

It also adds some unit tests to the API for both the new method
and for get_all, which already existed.

Change-Id: I8364ef19bfe177d56ec7bc1c0f1e166125a20ec5
",git fetch https://review.opendev.org/openstack/ironic refs/changes/15/34115/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/conductor/manager.py', 'ironic/api/controllers/v1.py', 'ironic/tests/conductor/test_task_manager.py', 'ironic/conductor/rpcapi.py']",4,e3e6ecde4af7ce94d50b5314598a5e1eea0a6978,rpc-updates," Included get_node_power_status 1.1 - Added update_node. RPC_API_VERSION = '1.1' """"""Ask a conductor for the node power state. def update_node(self, context, node_obj): """"""Have conductor update node information. Locks the node for update. :param context: request context. :param node object: an instance of objects.node.Node. only set those properties that should be updated. :returns: updated node object, including all fields. """""" return self.call(context, self.make_msg('update_node', node_obj=node_obj))"," RPC_API_VERSION = '1.0' """"""Ask a manager for the node power state.",34,14
openstack%2Fkeystone~master~I2946bfa6813d90feb634634e1b09c566ef58bef5,openstack/keystone,master,I2946bfa6813d90feb634634e1b09c566ef58bef5,Fixing broken credential schema in sqlite.,ABANDONED,2013-06-18 21:17:37.000000000,2013-07-22 22:52:47.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 5971}]","[{'number': 1, 'created': '2013-06-18 21:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a3c73b1b84569b9a82ca06d46aab0dff6f83f286', 'message': 'Fixing broken credential schema in sqlite.\n\nCredential table has foreign key constraint\nreferring to tenant table which is dropped.\nSince sqlite does not support alter table\ndrop constraint, the foreign key constraint\nwas not dropped. When we try to load credential\ntable in sqlalchemy it fails because tenant\ntable does not exist. Fix is provided such that\nthe credential table is recreated without foriegn\nkey constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}, {'number': 2, 'created': '2013-06-19 04:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/314758ab2fe3e302d90b7a3a5be91ec7715826a4', 'message': 'Fixing broken credential schema in sqlite.\n\nCredential table has foreign key constraint\nreferring to tenant table which is dropped.\nSince sqlite does not support alter table\ndrop constraint, the foreign key constraint\nwas not dropped. When we try to load credential\ntable using sqlite backend it fails because tenant\ntable does not exist. Fix is provided such that\nthe credential table is recreated without foriegn\nkey constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}, {'number': 3, 'created': '2013-06-26 19:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/618af5a82a0ebd06da5fcfa3c728d968d75b49b1', 'message': 'Fixing broken credential schema in sqlite\n\nCredential table has foreign key constraint referring to tenant table\nwhich is dropped.  Since sqlite does not support alter table drop\nconstraint, the foreign key constraint was not dropped. When we try to\nload credential table using sqlite backend it fails because tenant table\ndoes not exist. Fix is provided such that the credential table is\nrecreated without foriegn key constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}, {'number': 4, 'created': '2013-07-09 22:34:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2dde254c37ee66244812f721125b5182b1991a38', 'message': 'Fixing broken credential schema in sqlite.\n\nCredential table has foreign key constraint\nreferring to tenant table which is dropped.\nSince sqlite does not support alter table\ndrop constraint, the foreign key constraint\nwas not dropped. When we try to load credential\ntable using sqlite backend it fails because tenant\ntable does not exist. Fix is provided such that\nthe credential table is recreated without foriegn\nkey constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}, {'number': 5, 'created': '2013-07-10 04:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c21f91cb6742eca2b85fd01a94b0994d478bcf93', 'message': 'Fixing broken credential schema in sqlite.\n\nCredential table has foreign key constraint\nreferring to tenant table which is dropped.\nSince sqlite does not support alter table\ndrop constraint, the foreign key constraint\nwas not dropped. When we try to load credential\ntable using sqlite backend it fails because tenant\ntable does not exist. Fix is provided such that\nthe credential table is recreated without foriegn\nkey constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}, {'number': 6, 'created': '2013-07-11 20:23:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8d6a4045f25ca8c83674773449a37232a3d30412', 'message': 'Fixing broken credential schema in sqlite.\n\nCredential table has foreign key constraint\nreferring to tenant table which is dropped.\nSince sqlite does not support alter table\ndrop constraint, the foreign key constraint\nwas not dropped. When we try to load credential\ntable using sqlite backend it fails because tenant\ntable does not exist. Fix is provided such that\nthe credential table is recreated without foriegn\nkey constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}, {'number': 7, 'created': '2013-07-11 22:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/af76d9c0645df1d5f35023151184c56c54957f37', 'message': 'Fixing broken credential schema in sqlite.\n\nCredential table has foreign key constraint\nreferring to tenant table which is dropped.\nSince sqlite does not support alter table\ndrop constraint, the foreign key constraint\nwas not dropped. When we try to load credential\ntable using sqlite backend it fails because tenant\ntable does not exist. Fix is provided such that\nthe credential table is recreated without foriegn\nkey constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}, {'number': 8, 'created': '2013-07-13 21:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/74561b92aa5ca9b9d70c92a317952ff7ce066c0c', 'message': 'Fixing broken credential schema in sqlite.\n\nCredential table has foreign key constraint\nreferring to tenant table which is dropped.\nSince sqlite does not support alter table\ndrop constraint, the foreign key constraint\nwas not dropped. When we try to load credential\ntable using sqlite backend it fails because tenant\ntable does not exist. Fix is provided such that\nthe credential table is recreated without foriegn\nkey constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}, {'number': 9, 'created': '2013-07-17 18:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/896831caa2253dee47f39ef1b9d2418cca1180ac', 'message': 'Fixing broken credential schema in sqlite.\n\nCredential table has foreign key constraint\nreferring to tenant table which is dropped.\nSince sqlite does not support alter table\ndrop constraint, the foreign key constraint\nwas not dropped. When we try to load credential\ntable using sqlite backend it fails because tenant\ntable does not exist. Fix is provided such that\nthe credential table is recreated without foriegn\nkey constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}, {'number': 10, 'created': '2013-07-18 16:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/642fcc03f7dea2acfa04a8eb62e7234af5af6623', 'message': 'Fixing broken credential schema in sqlite.\n\nCredential table has foreign key constraint\nreferring to tenant table which is dropped.\nSince sqlite does not support alter table\ndrop constraint, the foreign key constraint\nwas not dropped. When we try to load credential\ntable using sqlite backend it fails because tenant\ntable does not exist. Fix is provided such that\nthe credential table is recreated without foriegn\nkey constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}, {'number': 11, 'created': '2013-07-18 16:06:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/acd4e55c723e15761b5b3f589ef680f7f7638a6a', 'message': 'Fixing broken credential schema in sqlite.\n\nCredential table has foreign key constraint\nreferring to tenant table which is dropped.\nSince sqlite does not support alter table\ndrop constraint, the foreign key constraint\nwas not dropped. When we try to load credential\ntable using sqlite backend it fails because tenant\ntable does not exist. Fix is provided such that\nthe credential table is recreated without foriegn\nkey constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}, {'number': 12, 'created': '2013-07-19 06:18:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bb3b763b847fa3bc81307a70f57977d0ad1666d1', 'message': 'Fixing broken credential schema in sqlite.\n\nCredential table has foreign key constraint\nreferring to tenant table which is dropped.\nSince sqlite does not support alter table\ndrop constraint, the foreign key constraint\nwas not dropped. When we try to load credential\ntable using sqlite backend it fails because tenant\ntable does not exist. Fix is provided such that\nthe credential table is recreated without foriegn\nkey constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}, {'number': 13, 'created': '2013-07-19 22:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4d3dec941953bfd176a64dd2458d14ce77ef27bf', 'message': 'Fixing broken credential schema in sqlite.\n\nCredential table has foreign key constraint\nreferring to tenant table which is dropped.\nSince sqlite does not support alter table\ndrop constraint, the foreign key constraint\nwas not dropped. When we try to load credential\ntable using sqlite backend it fails because tenant\ntable does not exist. Fix is provided such that\nthe credential table is recreated without foriegn\nkey constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}, {'number': 14, 'created': '2013-07-19 22:33:38.000000000', 'files': ['keystone/common/sql/migrate_repo/versions/023_drop_credential_constraints.py', 'tests/test_sql_upgrade.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d42504415a9a7f084708e84c940de2c8a8c72332', 'message': 'Fixing broken credential schema in sqlite.\n\nCredential table has foreign key constraint\nreferring to tenant table which is dropped.\nSince sqlite does not support alter table\ndrop constraint, the foreign key constraint\nwas not dropped. When we try to load credential\ntable using sqlite backend it fails because tenant\ntable does not exist. Fix is provided such that\nthe credential table is recreated without foriegn\nkey constraint and the data is moved from old\ncredential table to the new credential table.\n\nFixes Bug #1190383\n\nChange-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5\n'}]",19,33525,d42504415a9a7f084708e84c940de2c8a8c72332,62,7,14,5971,,,0,"Fixing broken credential schema in sqlite.

Credential table has foreign key constraint
referring to tenant table which is dropped.
Since sqlite does not support alter table
drop constraint, the foreign key constraint
was not dropped. When we try to load credential
table using sqlite backend it fails because tenant
table does not exist. Fix is provided such that
the credential table is recreated without foriegn
key constraint and the data is moved from old
credential table to the new credential table.

Fixes Bug #1190383

Change-Id: I2946bfa6813d90feb634634e1b09c566ef58bef5
",git fetch https://review.opendev.org/openstack/keystone refs/changes/25/33525/14 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/sql/migrate_repo/versions/023_drop_credential_constraints.py'],1,a3c73b1b84569b9a82ca06d46aab0dff6f83f286,bug/1190383,"from sqlalchemy.orm import sessionmaker if migrate_engine.name == 'sqlite': drop_credential_table__foreign_key_constraints_for_sqlite(migrate_engine) else: migration_helpers.remove_constraints(list_constraints(migrate_engine)) add_credential_table_foreign_key_constraints_for_sqlite(migrate_engine) else: migration_helpers.add_constraints(list_constraints(migrate_engine)) def drop_credential_table__foreign_key_constraints_for_sqlite(migrate_engine): meta = sqlalchemy.MetaData() meta.bind = migrate_engine # SQLite does not support ALTER TABLE DROP constraint. # So we need to move the data to new credenital table without constraints, # drop the old table and rename the new table to credential. sqlalchemy.Table('user', meta, autoload=True) tenant_table = sqlalchemy.Table( 'tenant', meta, sqlalchemy.Column('id', sqlalchemy.String(64), primary_key=True), sqlalchemy.Column('name', sqlalchemy.String(64), unique=True, nullable=False), sqlalchemy.Column('extra', sqlalchemy.Text())) tenant_table.create(migrate_engine, checkfirst=True) cred_table = sqlalchemy.Table('credential', meta, autoload=True) session = sessionmaker(bind=migrate_engine)() new_credential_table = sqlalchemy.Table( 'new_credential', meta, sqlalchemy.Column('id', sqlalchemy.String(64), primary_key=True), sqlalchemy.Column('user_id', sqlalchemy.String(64), nullable=False), sqlalchemy.Column('project_id', sqlalchemy.String(64)), sqlalchemy.Column('blob', sqlalchemy.Text(), nullable=False), sqlalchemy.Column('type', sqlalchemy.String(255), nullable=False), sqlalchemy.Column('extra', sqlalchemy.Text())) new_credential_table.create(migrate_engine, checkfirst=True) insert = new_credential_table.insert() for credential in session.query(cred_table): insert.execute({'id': credential.id, 'user_id': credential.user_id, 'project_id': credential.project_id, 'blob': credential.blob, 'type': credential.type, 'extra': credential.extra}) cred_table.drop() tenant_table.drop() new_credential_table.rename('credential') session.commit() session.close() def add_credential_table_foreign_key_constraints_for_sqlite(migrate_engine): meta = sqlalchemy.MetaData() meta.bind = migrate_engine cred_table = sqlalchemy.Table('credential', meta, autoload=True) session = sessionmaker(bind=migrate_engine)() sqlalchemy.Table('user', meta, autoload=True) sqlalchemy.Table('project', meta, autoload=True) old_credential_table = sqlalchemy.Table( 'old_credential', meta, sqlalchemy.Column('id', sqlalchemy.String(64), primary_key=True), sqlalchemy.Column('user_id', sqlalchemy.String(64), sqlalchemy.ForeignKey('user.id'), nullable=False), sqlalchemy.Column('project_id', sqlalchemy.String(64), sqlalchemy.ForeignKey('project.id')), sqlalchemy.Column('blob', sqlalchemy.Text(), nullable=False), sqlalchemy.Column('type', sqlalchemy.String(255), nullable=False), sqlalchemy.Column('extra', sqlalchemy.Text())) old_credential_table.create(migrate_engine, checkfirst=True) insert = old_credential_table.insert() for credential in session.query(cred_table): insert.execute({'id': credential.id, 'user_id': credential.user_id, 'project_id': credential.project_id, 'blob': credential.blob, 'type': credential.type, 'extra': credential.extra}) cred_table.drop() old_credential_table.rename('credential') session.commit() session.close() "," # SQLite does not support constraints, and querying the constraints # raises an exception if migrate_engine.name == 'sqlite': return migration_helpers.remove_constraints(list_constraints(migrate_engine)) return migration_helpers.add_constraints(list_constraints(migrate_engine))",96,6
openstack%2Foslo-incubator~master~I9a4a96bc250cb0b61c3a64e8d96a7507e44447e6,openstack/oslo-incubator,master,I9a4a96bc250cb0b61c3a64e8d96a7507e44447e6,Simplify ZmqMsg,ABANDONED,2013-06-19 22:04:58.000000000,2013-07-22 22:03:56.000000000,,"[{'_account_id': 3}, {'_account_id': 159}]","[{'number': 1, 'created': '2013-06-19 22:04:58.000000000', 'files': ['openstack/common/rpc/impl_zmq.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/6d035ebd4868c09985dc2ce4b62a75d718a4f679', 'message': 'Simplify ZmqMsg\n\nChange-Id: I9a4a96bc250cb0b61c3a64e8d96a7507e44447e6\n'}]",2,33726,6d035ebd4868c09985dc2ce4b62a75d718a4f679,4,2,1,1247,,,0,"Simplify ZmqMsg

Change-Id: I9a4a96bc250cb0b61c3a64e8d96a7507e44447e6
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/26/33726/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/rpc/impl_zmq.py'],1,6d035ebd4868c09985dc2ce4b62a75d718a4f679,," def __init__(self): emsg = _(""ZMQ Envelope version unsupported or unknown."") super(ZmqMsgInvalid, self).__init__(emsg) def __init__(self, data): self.data = data self._msg = None @staticmethod def _deserialize(data): version = None version = 2 packenv = data[4:] ctx = data[3] version = 1 packenv = data[3] ctx = None except IndexError: pass if version is None: raise ZmqMsgInvalid() elif version == 2: assert ctx is not None envelope = unflatten_envelope(packenv) elif version == 1: ctx, envelope = _deserialize(packenv) return (rpc_common.deserialize_msg(envelope), RpcContext.unmarshal(ctx)) if self._msg is None: self._msg = self._deserialize(self.data) return self._msg[0] @property def context(self): if self._msg is None: self._msg = self._deserialize(self.data) return self._msg[1]"," pass def __init__(self, data): self._rpcctx = None self._rpcmsg = None self._ctx = None self._envelope = None self.raw = data emsg = _(""ZMQ Envelope version unsupported or unknown."") self.version = 2 self.packenv = data[4:] self._ctx = data[3] self.version = 1 self.packenv = data[3] else: raise ZmqMsgInvalid(emsg) except IndexError: raise ZmqMsgInvalid(emsg) def _deserialize_v1(self, msg): if self._ctx and self._envelope: return self._ctx, self._envelope self._ctx, self._envelope = _deserialize(msg) return self._ctx, self._envelope @property def context(self): if self._rpcctx: return self._rpcctx if self.version == 2: self._rpcctx = RpcContext.unmarshal(self._ctx) elif self.version == 1: ctx, envelope = self._deserialize_v1(self.packenv) self._rpcctx = RpcContext.unmarshal(ctx) return self._rpcctx if self._rpcmsg: return self._rpcmsg if self.version == 2: envelope = unflatten_envelope(self.packenv) elif self.version == 1: ctx, envelope = self._deserialize_v1(self.packenv) self._rpcmsg = rpc_common.deserialize_msg(envelope) return self._rpcmsg",34,41
openstack%2Fironic~master~I4604a62aa07e5026d219dc6e5b8b4c23b3caa3f1,openstack/ironic,master,I4604a62aa07e5026d219dc6e5b8b4c23b3caa3f1,Sync requirements with OpenStack/requirements,MERGED,2013-07-19 21:23:50.000000000,2013-07-22 22:02:42.000000000,2013-07-22 22:02:42.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6593}, {'_account_id': 6773}]","[{'number': 1, 'created': '2013-07-19 21:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fd2f02ddc0f4c5193b48ac9428ad33a9e22d57dc', 'message': 'Sync requirements with OpenStack/requirements\n\nMainly to fix proper casing of requirements and\nraise keystoneclient minimum requirement to\nmatch those required by other projects.\n\nChange-Id: I4604a62aa07e5026d219dc6e5b8b4c23b3caa3f1\n'}, {'number': 2, 'created': '2013-07-19 22:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d9fdc940abd1400b110729e85d86d6c8f88a1bf0', 'message': 'Sync requirements with OpenStack/requirements\n\nFixes proper casing of requirements\nAllows usage of Hacking 0.6, which has a few\nextra checks (Fix fallout).\nRaises keystoneclient minimum requirement to\nmatch those required by other projects.\n\nChange-Id: I4604a62aa07e5026d219dc6e5b8b4c23b3caa3f1\n'}, {'number': 3, 'created': '2013-07-20 15:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2355802506c1de541783aab4838902ecf9d1ad49', 'message': 'Sync requirements with OpenStack/requirements\n\nFixes proper casing of requirements\nAllows usage of Hacking 0.6, which has a few\nextra checks (Fix fallout).\nRaises keystoneclient minimum requirement to\nmatch those required by other projects.\n\nChange-Id: I4604a62aa07e5026d219dc6e5b8b4c23b3caa3f1\n'}, {'number': 4, 'created': '2013-07-22 21:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ed3e6f021f5b907ad086c3d6d6e9b7a4659d56ce', 'message': 'Sync requirements with OpenStack/requirements\n\nFixes proper casing of requirements\nAllows usage of Hacking 0.6, which has a few\nextra checks (Fix fallout).\nRaises keystoneclient minimum requirement to\nmatch those required by other projects.\n\nChange-Id: I4604a62aa07e5026d219dc6e5b8b4c23b3caa3f1\n'}, {'number': 5, 'created': '2013-07-22 21:55:59.000000000', 'files': ['ironic/common/exception.py', 'requirements.txt', 'test-requirements.txt', 'ironic/cmd/ironic_deploy_helper.py', 'ironic/common/utils.py', 'ironic/objects/base.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d1b78db89aab171028a1c9278c5c0ce914806ef4', 'message': 'Sync requirements with OpenStack/requirements\n\nFixes proper casing of requirements\nAllows usage of Hacking 0.6, which has a few\nextra checks (Fix fallout).\nRaises keystoneclient minimum requirement to\nmatch those required by other projects.\n\nChange-Id: I4604a62aa07e5026d219dc6e5b8b4c23b3caa3f1\n'}]",0,37983,d1b78db89aab171028a1c9278c5c0ce914806ef4,23,5,5,6593,,,0,"Sync requirements with OpenStack/requirements

Fixes proper casing of requirements
Allows usage of Hacking 0.6, which has a few
extra checks (Fix fallout).
Raises keystoneclient minimum requirement to
match those required by other projects.

Change-Id: I4604a62aa07e5026d219dc6e5b8b4c23b3caa3f1
",git fetch https://review.opendev.org/openstack/ironic refs/changes/83/37983/5 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,fd2f02ddc0f4c5193b48ac9428ad33a9e22d57dc,req_sync,"hacking>=0.5.6,<0.7MySQL-pythontestrepository>=0.0.17","hacking>=0.5.6,<0.6mysql-pythontestrepository>=0.0.15",11,11
openstack%2Foslo-incubator~master~Ifbb5762b6e16b315f4066ceff35e85d2ac6f990f,openstack/oslo-incubator,master,Ifbb5762b6e16b315f4066ceff35e85d2ac6f990f,Add eclipse project files to .gitignore,MERGED,2013-07-18 22:46:05.000000000,2013-07-22 21:57:43.000000000,2013-07-22 21:57:42.000000000,"[{'_account_id': 3}, {'_account_id': 1247}]","[{'number': 1, 'created': '2013-07-18 22:46:05.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/2454ff8a4851b00756f30198886bbcd9ce2483a3', 'message': 'Add eclipse project files to .gitignore\n\nLike some of the other projects (nova, heat) ignore eclipse\nproject files, for those people that work with eclipse (yuck :)\n\nChange-Id: Ifbb5762b6e16b315f4066ceff35e85d2ac6f990f\n'}]",0,37802,2454ff8a4851b00756f30198886bbcd9ce2483a3,5,2,1,7996,,,0,"Add eclipse project files to .gitignore

Like some of the other projects (nova, heat) ignore eclipse
project files, for those people that work with eclipse (yuck :)

Change-Id: Ifbb5762b6e16b315f4066ceff35e85d2ac6f990f
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/02/37802/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,2454ff8a4851b00756f30198886bbcd9ce2483a3,eclipse-ignore,.project .pydevproject,,2,0
openstack%2Fhorizon~master~I050bdcccdc88c80b636f1061d60cc2dc5086d9b8,openstack/horizon,master,I050bdcccdc88c80b636f1061d60cc2dc5086d9b8,Remove all_tenants from server_list of Floating IPs tab,MERGED,2013-07-22 06:52:09.000000000,2013-07-22 21:55:49.000000000,2013-07-22 21:55:48.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6610}]","[{'number': 1, 'created': '2013-07-22 06:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/25479f49abfff6af1c1e78b2087e4b22c75742dd', 'message': 'Remove all_tenants from server_list of Floating IPs tab\n\nChange-Id: I050bdcccdc88c80b636f1061d60cc2dc5086d9b8\nFixes: bug #1203394\n'}, {'number': 2, 'created': '2013-07-22 09:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/33c5b90417bb2a6299cf2d2b7eaac9d2db3271b7', 'message': 'Remove all_tenants from server_list of Floating IPs tab\n\nChange-Id: I050bdcccdc88c80b636f1061d60cc2dc5086d9b8\nFixes: bug #1203394\n'}, {'number': 3, 'created': '2013-07-22 09:18:43.000000000', 'files': ['openstack_dashboard/dashboards/project/access_and_security/floating_ips/tests.py', 'openstack_dashboard/dashboards/project/access_and_security/tests.py', 'openstack_dashboard/dashboards/project/access_and_security/tabs.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/29876534e9af084f10bf33e6e05ebec0f2f427d2', 'message': 'Remove all_tenants from server_list of Floating IPs tab\n\nChange-Id: I050bdcccdc88c80b636f1061d60cc2dc5086d9b8\nFixes: bug #1203394\n'}]",0,38106,29876534e9af084f10bf33e6e05ebec0f2f427d2,9,4,3,6610,,,0,"Remove all_tenants from server_list of Floating IPs tab

Change-Id: I050bdcccdc88c80b636f1061d60cc2dc5086d9b8
Fixes: bug #1203394
",git fetch https://review.opendev.org/openstack/horizon refs/changes/06/38106/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/access_and_security/tabs.py'],1,25479f49abfff6af1c1e78b2087e4b22c75742dd,bug/1203394," instances, has_more = nova.server_list(self.request)"," instances, has_more = nova.server_list(self.request, all_tenants=True)",1,2
openstack%2Fironic~master~Iab5e42d139d4414eb74b0ecc62710f0b23b882e4,openstack/ironic,master,Iab5e42d139d4414eb74b0ecc62710f0b23b882e4,Fix up API tests before updating hacking checks.,MERGED,2013-07-22 21:42:55.000000000,2013-07-22 21:53:05.000000000,2013-07-22 21:53:05.000000000,"[{'_account_id': 3}, {'_account_id': 2889}]","[{'number': 1, 'created': '2013-07-22 21:42:55.000000000', 'files': ['ironic/tests/api/test_nodes.py', 'ironic/tests/api/utils.py', 'ironic/tests/api/test_acl.py', 'ironic/tests/api/base.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/f0cf610a2ed741520ce261df9175ac05e3edc209', 'message': 'Fix up API tests before updating hacking checks.\n\nThe new hacking rules will enforce a license header check.\nThis patch updates a few recent files to clean up the header,\nand remove an extraneous print function that snuck in.\n\nChange-Id: Iab5e42d139d4414eb74b0ecc62710f0b23b882e4\n'}]",0,38204,f0cf610a2ed741520ce261df9175ac05e3edc209,5,2,1,2889,,,0,"Fix up API tests before updating hacking checks.

The new hacking rules will enforce a license header check.
This patch updates a few recent files to clean up the header,
and remove an extraneous print function that snuck in.

Change-Id: Iab5e42d139d4414eb74b0ecc62710f0b23b882e4
",git fetch https://review.opendev.org/openstack/ironic refs/changes/04/38204/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/api/test_nodes.py', 'ironic/tests/api/utils.py', 'ironic/tests/api/test_acl.py', 'ironic/tests/api/base.py']",4,f0cf610a2ed741520ce261df9175ac05e3edc209,req_sync,# -*- encoding: utf-8 -*- #,,29,23
openstack%2Fnova~master~I65f2b6474d572ed601d20dca9dda9936d306a219,openstack/nova,master,I65f2b6474d572ed601d20dca9dda9936d306a219,Move _validate_int_value controller func to utils,MERGED,2013-07-18 15:08:14.000000000,2013-07-22 21:51:51.000000000,2013-07-22 21:51:49.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1247}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 6172}, {'_account_id': 6593}, {'_account_id': 7996}]","[{'number': 1, 'created': '2013-07-18 15:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4828bb3ed8a055d0aa09a7227f9c3db1c5c432ed', 'message': 'Move _validate_int_value controller func to utils\n\nThis patch moves the _validate_int_value private method of the servers API\ncontroller (intorduced in change\nI18ac285d5b3c8200d7706c7d577809b15d6ab9e8) to utils, in order to make it\nusable by code outside of the controller class. This method is very\ngeneral - it checks weather a string is a valid integer.\n\nIt also changes what exceptions it raises from HTTPBadRequest to\nInvalidInput - all in the spirit of being more reusable.\n\nChange-Id: I65f2b6474d572ed601d20dca9dda9936d306a219\nblueprint: improve-block-device-handling\n'}, {'number': 2, 'created': '2013-07-19 16:23:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/91f9537d9f7a321215061729fcf5a1cb813a8bb3', 'message': 'Move _validate_int_value controller func to utils\n\nThis patch moves the _validate_int_value private method of the servers API\ncontroller (intorduced in change\nI18ac285d5b3c8200d7706c7d577809b15d6ab9e8) to utils, in order to make it\nusable by code outside of the controller class. This method is very\ngeneral - it checks weather a string is a valid integer.\n\nIt also changes what exceptions it raises from HTTPBadRequest to\nInvalidInput - all in the spirit of being more reusable.\n\nChange-Id: I65f2b6474d572ed601d20dca9dda9936d306a219\nblueprint: improve-block-device-handling\n'}, {'number': 3, 'created': '2013-07-22 10:21:52.000000000', 'files': ['nova/utils.py', 'nova/tests/test_utils.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/58fa5db328c240550d58460ebbfd04c5205dc3af', 'message': 'Move _validate_int_value controller func to utils\n\nThis patch moves the _validate_int_value private method of the servers API\ncontroller (intorduced in change\nI18ac285d5b3c8200d7706c7d577809b15d6ab9e8) to utils, in order to make it\nusable by code outside of the controller class. This method is very\ngeneral - it checks weather an input is a valid integer.\n\nIt also changes what exceptions it raises from HTTPBadRequest to\nInvalidInput - all in the spirit of being more reusable.\n\nFinally, it adds tests and fixes a small string formatting bug that was\nuncovered by adding them.\n\nChange-Id: I65f2b6474d572ed601d20dca9dda9936d306a219\nblueprint: improve-block-device-handling\n'}]",7,37698,58fa5db328c240550d58460ebbfd04c5205dc3af,35,12,3,5511,,,0,"Move _validate_int_value controller func to utils

This patch moves the _validate_int_value private method of the servers API
controller (intorduced in change
I18ac285d5b3c8200d7706c7d577809b15d6ab9e8) to utils, in order to make it
usable by code outside of the controller class. This method is very
general - it checks weather an input is a valid integer.

It also changes what exceptions it raises from HTTPBadRequest to
InvalidInput - all in the spirit of being more reusable.

Finally, it adds tests and fixes a small string formatting bug that was
uncovered by adding them.

Change-Id: I65f2b6474d572ed601d20dca9dda9936d306a219
blueprint: improve-block-device-handling
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/37698/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/utils.py', 'nova/api/openstack/compute/servers.py']",2,4828bb3ed8a055d0aa09a7227f9c3db1c5c432ed,bp/improve-block-device-handling," try: bd['volume_size'] = utils.validate_integer_string( bd['volume_size'], 'volume_size', min_value=0) except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) try: min_count = utils.validate_integer_string( min_count, ""min_count"", min_value=1) max_count = utils.validate_integer_string( max_count, ""max_count"", min_value=1) except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message())"," def _validate_int_value(self, str_value, str_name, min_value=None, max_value=None): try: value = int(str(str_value)) except ValueError: msg = _('%(value_name)s must be an integer') raise exc.HTTPBadRequest(explanation=msg % ( {'value_name': str_name})) if min_value is not None: if value < min_value: msg = _('%(value_name)s must be >= %(min_value)d') raise exc.HTTPBadRequest(explanation=msg % ( {'value_name': str_name, 'min_value': min_value})) if max_value is not None: if value > max_value: msg = _('%{value_name}s must be <= %(max_value)d') raise exc.HTTPBadRequest(explanation=msg % ( {'value_name': str_name, 'max_value': max_value})) return value self._validate_int_value(bd['volume_size'], 'volume_size', min_value=0) min_count = self._validate_int_value(min_count, ""min_count"", min_value=1) max_count = self._validate_int_value(max_count, ""max_count"", min_value=1)",38,29
openstack%2Fhorizon~master~I445ca58d1e05187c9d05fdb6814039c69543324c,openstack/horizon,master,I445ca58d1e05187c9d05fdb6814039c69543324c,Fixing the AJAX function location,MERGED,2013-07-18 15:04:54.000000000,2013-07-22 21:51:46.000000000,2013-07-22 21:51:45.000000000,"[{'_account_id': 3}, {'_account_id': 1816}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 5623}, {'_account_id': 7714}]","[{'number': 1, 'created': '2013-07-18 15:04:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/95de23d33fe1bdfbcf2cc383bd6f1e70bb0ea2e5', 'message': 'Fixing the AJAX function location\n\nThis bug addresses the incorrect location of the AJAX function call in api.py and moves it to the correct location in views.py\n\nChange-Id: I445ca58d1e05187c9d05fdb6814039c69543324c\nFixes: bug #1201980\n'}, {'number': 2, 'created': '2013-07-19 14:53:55.000000000', 'files': ['openstack_dashboard/dashboards/project/stacks/views.py', 'openstack_dashboard/dashboards/project/stacks/urls.py', 'openstack_dashboard/dashboards/project/stacks/api.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2c1e47d5c5410de9f9a02dffddc62f4a00e2b85b', 'message': 'Fixing the AJAX function location\n\nThis bug addresses the incorrect location of the AJAX function call in api.py and moves it to the correct location in views.py\nIt also standardizes the AJAX JSON function to use a generic Django class instead of a function.\n\nChange-Id: I445ca58d1e05187c9d05fdb6814039c69543324c\nFixes: bug #1201980\n'}]",0,37694,2c1e47d5c5410de9f9a02dffddc62f4a00e2b85b,16,6,2,7714,,,0,"Fixing the AJAX function location

This bug addresses the incorrect location of the AJAX function call in api.py and moves it to the correct location in views.py
It also standardizes the AJAX JSON function to use a generic Django class instead of a function.

Change-Id: I445ca58d1e05187c9d05fdb6814039c69543324c
Fixes: bug #1201980
",git fetch https://review.opendev.org/openstack/horizon refs/changes/94/37694/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/stacks/views.py', 'openstack_dashboard/dashboards/project/stacks/urls.py', 'openstack_dashboard/dashboards/project/stacks/api.py']",3,95de23d33fe1bdfbcf2cc383bd6f1e70bb0ea2e5,bug/1201980,,"from django.http import HttpResponse def get_d3_data(request, stack_id=''): return HttpResponse(d3_data(request, stack_id=stack_id), content_type=""application/json"")",8,8
openstack%2Fglance~master~I0d2adf36c7f5262770f5a3bda05c9ddd21efc17d,openstack/glance,master,I0d2adf36c7f5262770f5a3bda05c9ddd21efc17d,Fix list formatting in docs,MERGED,2013-07-05 20:10:28.000000000,2013-07-22 21:51:44.000000000,2013-07-22 21:51:43.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6159}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-07-05 20:10:28.000000000', 'files': ['doc/source/notifications.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/cc5a348de41ca265560e4d4f1082f29d4c97fc69', 'message': ""Fix list formatting in docs\n\nFix the way the notification payload is documented\nso it uses proper rst syntax and doesn't produce a\nwarning in the sphinx build.\n\nChange-Id: I0d2adf36c7f5262770f5a3bda05c9ddd21efc17d\nSigned-off-by: Doug Hellmann <doug.hellmann@dreamhost.com>\n""}]",0,35883,cc5a348de41ca265560e4d4f1082f29d4c97fc69,9,4,1,2472,,,0,"Fix list formatting in docs

Fix the way the notification payload is documented
so it uses proper rst syntax and doesn't produce a
warning in the sphinx build.

Change-Id: I0d2adf36c7f5262770f5a3bda05c9ddd21efc17d
Signed-off-by: Doug Hellmann <doug.hellmann@dreamhost.com>
",git fetch https://review.opendev.org/openstack/glance refs/changes/83/35883/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/notifications.rst'],1,cc5a348de41ca265560e4d4f1082f29d4c97fc69,blueprint/oslo.sphinx," The payload for INFO, WARN, and ERROR events contain the following: image_id ID of the image (UUID) owner_id Tenant or User ID that owns this image (string) receiver_tenant_id Tenant ID of the account receiving the image (string) receiver_user_id User ID of the account receiving the image (string) destination_ip bytes_sent The number of bytes actually sent"," The payload for INFO, WARN, and ERROR events contain the following:: image_id - ID of the image (UUID) owner_id - Tenant or User ID that owns this image (string) receiver_tenant_id - Tenant ID of the account receiving the image (string) receiver_user_id - User ID of the account receiving the image (string) destination_ip bytes_sent - The number of bytes actually sent",12,7
openstack%2Fglance~master~Icc1569cbeaa6c964d608a254095f7a778ff0c74e,openstack/glance,master,Icc1569cbeaa6c964d608a254095f7a778ff0c74e,Fix doc formatting issue,MERGED,2013-07-05 20:10:28.000000000,2013-07-22 21:51:42.000000000,2013-07-22 21:51:42.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6159}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-07-05 20:10:28.000000000', 'files': ['doc/source/common-image-properties.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/d6e51d9ab40ca9ae58825988516bd92d77791c45', 'message': 'Fix doc formatting issue\n\nFix the underline length to remove a warning from\nthe documentation build.\n\nChange-Id: Icc1569cbeaa6c964d608a254095f7a778ff0c74e\nSigned-off-by: Doug Hellmann <doug.hellmann@dreamhost.com>\n'}]",0,35882,d6e51d9ab40ca9ae58825988516bd92d77791c45,9,4,1,2472,,,0,"Fix doc formatting issue

Fix the underline length to remove a warning from
the documentation build.

Change-Id: Icc1569cbeaa6c964d608a254095f7a778ff0c74e
Signed-off-by: Doug Hellmann <doug.hellmann@dreamhost.com>
",git fetch https://review.opendev.org/openstack/glance refs/changes/82/35882/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/common-image-properties.rst'],1,d6e51d9ab40ca9ae58825988516bd92d77791c45,blueprint/oslo.sphinx,----------------,-----------,1,1
openstack%2Fglance~master~I46f34d9320ce39977facff705c52d272a160220f,openstack/glance,master,I46f34d9320ce39977facff705c52d272a160220f,Ignore files created by Sphinx build,MERGED,2013-07-05 20:10:27.000000000,2013-07-22 21:50:19.000000000,2013-07-22 21:50:18.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2472}, {'_account_id': 6159}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-07-05 20:10:27.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/glance/commit/9f9f01bf88dc7402124d91da753f6cea0ad09b38', 'message': 'Ignore files created by Sphinx build\n\nChange-Id: I46f34d9320ce39977facff705c52d272a160220f\nSigned-off-by: Doug Hellmann <doug.hellmann@dreamhost.com>\n'}]",0,35881,9f9f01bf88dc7402124d91da753f6cea0ad09b38,9,5,1,2472,,,0,"Ignore files created by Sphinx build

Change-Id: I46f34d9320ce39977facff705c52d272a160220f
Signed-off-by: Doug Hellmann <doug.hellmann@dreamhost.com>
",git fetch https://review.opendev.org/openstack/glance refs/changes/81/35881/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,9f9f01bf88dc7402124d91da753f6cea0ad09b38,blueprint/oslo.sphinx,# Files created by doc build doc/source/api,,2,0
openstack%2Fglance~master~I2aba8164ab9ef0c3bef31870cb3771233a722d27,openstack/glance,master,I2aba8164ab9ef0c3bef31870cb3771233a722d27,Remove references to clean arg from cache-manage,MERGED,2013-07-15 16:13:06.000000000,2013-07-22 21:50:17.000000000,2013-07-22 21:50:16.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-07-15 16:13:06.000000000', 'files': ['doc/source/man/glancecachemanage.rst', 'glance/cmd/cache_manage.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/84bf7e057a98255dd4e3f67d8a76bcfbf5b2c6a3', 'message': 'Remove references to clean arg from cache-manage\n\nThe usage message for glance-cache-manage lists ""clean"" as an available\ncommand, but this functionality is part of a separate tool,\nglance-cache-cleaner.\n\nRemove any references to this to avoid confusion.\n\nDocImpact\nFixes bug 1189451\n\nChange-Id: I2aba8164ab9ef0c3bef31870cb3771233a722d27\n'}]",0,37082,84bf7e057a98255dd4e3f67d8a76bcfbf5b2c6a3,7,4,1,1390,,,0,"Remove references to clean arg from cache-manage

The usage message for glance-cache-manage lists ""clean"" as an available
command, but this functionality is part of a separate tool,
glance-cache-cleaner.

Remove any references to this to avoid confusion.

DocImpact
Fixes bug 1189451

Change-Id: I2aba8164ab9ef0c3bef31870cb3771233a722d27
",git fetch https://review.opendev.org/openstack/glance refs/changes/82/37082/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/man/glancecachemanage.rst', 'glance/cmd/cache_manage.py']",2,84bf7e057a98255dd4e3f67d8a76bcfbf5b2c6a3,bug/1189451,, clean Removes any stale or invalid image files from the cache,0,6
openstack%2Fneutron~master~Iccd8aff56e7bf6ba45ab4ddc15aef05f1ab9ed30,openstack/neutron,master,Iccd8aff56e7bf6ba45ab4ddc15aef05f1ab9ed30,Imported Translations from Transifex,MERGED,2013-07-22 19:55:17.000000000,2013-07-22 21:50:09.000000000,2013-07-22 21:50:09.000000000,"[{'_account_id': 3}, {'_account_id': 2031}]","[{'number': 1, 'created': '2013-07-22 19:55:17.000000000', 'files': ['neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d766f1ffdfaeabe4d9aa6d78259a5f167fa7cc45', 'message': 'Imported Translations from Transifex\n\nChange-Id: Iccd8aff56e7bf6ba45ab4ddc15aef05f1ab9ed30\n'}]",0,38197,d766f1ffdfaeabe4d9aa6d78259a5f167fa7cc45,5,2,1,3,,,0,"Imported Translations from Transifex

Change-Id: Iccd8aff56e7bf6ba45ab4ddc15aef05f1ab9ed30
",git fetch https://review.opendev.org/openstack/neutron refs/changes/97/38197/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po']",40,d766f1ffdfaeabe4d9aa6d78259a5f167fa7cc45,transifex/translations,"""POT-Creation-Date: 2013-07-22 19:54+0000\n""#: neutron/manager.py:186#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:281#: neutron/db/agents_db.py:173#: neutron/db/agentschedulers_db.py:426#: neutron/db/l3_db.py:600 neutron/plugins/nicira/NeutronPlugin.py:1864#: neutron/extensions/lbaas_agentscheduler.py:117 #, python-format msgid ""No eligible loadbalancer agent found for pool %(pool_id)s."" msgstr """" #: neutron/extensions/lbaas_agentscheduler.py:122 #, python-format msgid ""No active loadbalancer agent found for pool %(pool_id)s."" msgstr """" #: neutron/plugins/brocade/NeutronPlugin.py:124#: neutron/plugins/brocade/NeutronPlugin.py:138 #: neutron/plugins/brocade/NeutronPlugin.py:155#: neutron/plugins/brocade/NeutronPlugin.py:284 #: neutron/plugins/brocade/NeutronPlugin.py:327 #: neutron/plugins/brocade/NeutronPlugin.py:377#: neutron/plugins/brocade/NeutronPlugin.py:285 #: neutron/plugins/brocade/NeutronPlugin.py:328 #: neutron/plugins/brocade/NeutronPlugin.py:378#: neutron/plugins/brocade/NeutronPlugin.py:286#: neutron/plugins/brocade/NeutronPlugin.py:294#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:285#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:332#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:479#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:283#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:324#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:378#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:328#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:382#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:334#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:388 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:407#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:337#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:391#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:344#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:411#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:350#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:417#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:356#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:423#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:362 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:429#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:368#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:435#: neutron/plugins/nicira/NeutronPlugin.py:1063#: neutron/plugins/ml2/plugin.py:138#: neutron/plugins/ml2/plugin.py:152#: neutron/plugins/ml2/plugin.py:184#: neutron/plugins/ml2/plugin.py:227#: neutron/plugins/ml2/plugin.py:330#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:330#: neutron/plugins/nec/nec_plugin.py:163#: neutron/plugins/nec/nec_plugin.py:167#: neutron/plugins/nec/nec_plugin.py:171#: neutron/plugins/nec/nec_plugin.py:187#: neutron/plugins/nec/nec_plugin.py:193#: neutron/plugins/nec/nec_plugin.py:211#: neutron/plugins/nec/nec_plugin.py:215#: neutron/plugins/nec/nec_plugin.py:234#: neutron/plugins/nec/nec_plugin.py:253#: neutron/plugins/nec/nec_plugin.py:269#: neutron/plugins/nec/nec_plugin.py:309#: neutron/plugins/nec/nec_plugin.py:318#: neutron/plugins/nec/nec_plugin.py:334#: neutron/plugins/nec/nec_plugin.py:347#: neutron/plugins/nec/nec_plugin.py:359#: neutron/plugins/nec/nec_plugin.py:378#: neutron/plugins/nec/nec_plugin.py:404#: neutron/plugins/nec/nec_plugin.py:484#: neutron/plugins/nec/nec_plugin.py:515#: neutron/plugins/nec/nec_plugin.py:534#: neutron/plugins/nec/nec_plugin.py:539#: neutron/plugins/nicira/NeutronPlugin.py:915#: neutron/plugins/nicira/NeutronPlugin.py:1809#: neutron/plugins/nicira/NeutronPlugin.py:839#: neutron/plugins/nicira/NeutronPlugin.py:897#: neutron/plugins/nicira/NeutronPlugin.py:925#: neutron/plugins/nicira/NeutronPlugin.py:928#: neutron/plugins/nicira/NeutronPlugin.py:954#: neutron/plugins/nicira/NeutronPlugin.py:964 #: neutron/plugins/nicira/NeutronPlugin.py:1012#: neutron/plugins/nicira/NeutronPlugin.py:1026#: neutron/plugins/nicira/NeutronPlugin.py:1041#: neutron/plugins/nicira/NeutronPlugin.py:1045#: neutron/plugins/nicira/NeutronPlugin.py:1131#: neutron/plugins/nicira/NeutronPlugin.py:1140#: neutron/plugins/nicira/NeutronPlugin.py:1167#: neutron/plugins/nicira/NeutronPlugin.py:1174#: neutron/plugins/nicira/NeutronPlugin.py:1240#: neutron/plugins/nicira/NeutronPlugin.py:1248#: neutron/plugins/nicira/NeutronPlugin.py:1252#: neutron/plugins/nicira/NeutronPlugin.py:1327#: neutron/plugins/nicira/NeutronPlugin.py:1353#: neutron/plugins/nicira/NeutronPlugin.py:1477 #: neutron/plugins/nicira/NeutronPlugin.py:1521#: neutron/plugins/nicira/NeutronPlugin.py:1490#: neutron/plugins/nicira/NeutronPlugin.py:1530#: neutron/plugins/nicira/NeutronPlugin.py:1546#: neutron/plugins/nicira/NeutronPlugin.py:1550#: neutron/plugins/nicira/NeutronPlugin.py:1552#: neutron/plugins/nicira/NeutronPlugin.py:1585#: neutron/plugins/nicira/NeutronPlugin.py:1589#: neutron/plugins/nicira/NeutronPlugin.py:1609#: neutron/plugins/nicira/NeutronPlugin.py:1636#: neutron/plugins/nicira/NeutronPlugin.py:1658#: neutron/plugins/nicira/NeutronPlugin.py:1684#: neutron/plugins/nicira/NeutronPlugin.py:1719#: neutron/plugins/nicira/NeutronPlugin.py:1764#: neutron/plugins/nicira/NeutronPlugin.py:1776#: neutron/plugins/nicira/NeutronPlugin.py:1805#: neutron/plugins/nicira/NeutronPlugin.py:1831#: neutron/plugins/nicira/NeutronPlugin.py:1837#: neutron/plugins/nicira/NeutronPlugin.py:1903#: neutron/plugins/nicira/NeutronPlugin.py:1927#: neutron/plugins/nicira/NeutronPlugin.py:1970#: neutron/plugins/nicira/NeutronPlugin.py:1973#: neutron/plugins/nicira/NeutronPlugin.py:1999#: neutron/plugins/nicira/NeutronPlugin.py:2021#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:341#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:345#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:398#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:401#: neutron/services/loadbalancer/agent_scheduler.py:94 #, python-format msgid ""Pool %(pool_id)s has already been hosted by lbaas agent %(agent_id)s"" msgstr """" #: neutron/services/loadbalancer/agent_scheduler.py:102 #, python-format msgid ""No active lbaas agents for pool %s"" msgstr """" #: neutron/services/loadbalancer/agent_scheduler.py:110 #, python-format msgid ""Pool %(pool_id)s is scheduled to lbaas agent %(agent_id)s"" msgstr """" #: neutron/services/loadbalancer/plugin.py:36#: neutron/services/loadbalancer/plugin.py:75#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:44#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:49#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:53#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:58#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:128#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:141#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:200#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:221#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:236#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:247#: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:48 msgid ""Driver to use for scheduling pool to a default loadbalancer agent"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:85 #, python-format msgid ""Multiple lbaas agents found on host %s"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:118#: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:163#: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:187 #: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:204#: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:162 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:186 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:207 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:232","""POT-Creation-Date: 2013-07-21 19:54+0000\n""#: neutron/manager.py:180#: neutron/db/agents_db.py:170#: neutron/db/agentschedulers_db.py:422#: neutron/db/l3_db.py:600 neutron/plugins/nicira/NeutronPlugin.py:1863#: neutron/plugins/brocade/NeutronPlugin.py:123#: neutron/plugins/brocade/NeutronPlugin.py:137 #: neutron/plugins/brocade/NeutronPlugin.py:154#: neutron/plugins/brocade/NeutronPlugin.py:279 #: neutron/plugins/brocade/NeutronPlugin.py:322 #: neutron/plugins/brocade/NeutronPlugin.py:372#: neutron/plugins/brocade/NeutronPlugin.py:280 #: neutron/plugins/brocade/NeutronPlugin.py:323 #: neutron/plugins/brocade/NeutronPlugin.py:373#: neutron/plugins/brocade/NeutronPlugin.py:281#: neutron/plugins/brocade/NeutronPlugin.py:289#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:281#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:328#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:475#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:279#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:320#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:374#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:324#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:378#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:330#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:384 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:403#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:333#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:387#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:340#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:407#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:346#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:413#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:352#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:419#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:358 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:425#: neutron/plugins/linuxbridge/lb_neutron_plugin.py:364#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:431#: neutron/plugins/nicira/NeutronPlugin.py:1062#: neutron/plugins/ml2/plugin.py:134#: neutron/plugins/ml2/plugin.py:148#: neutron/plugins/ml2/plugin.py:180#: neutron/plugins/ml2/plugin.py:223#: neutron/plugins/ml2/plugin.py:326#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:326#: neutron/plugins/nec/nec_plugin.py:158#: neutron/plugins/nec/nec_plugin.py:162#: neutron/plugins/nec/nec_plugin.py:166#: neutron/plugins/nec/nec_plugin.py:182#: neutron/plugins/nec/nec_plugin.py:188#: neutron/plugins/nec/nec_plugin.py:206#: neutron/plugins/nec/nec_plugin.py:210#: neutron/plugins/nec/nec_plugin.py:229#: neutron/plugins/nec/nec_plugin.py:248#: neutron/plugins/nec/nec_plugin.py:264#: neutron/plugins/nec/nec_plugin.py:304#: neutron/plugins/nec/nec_plugin.py:313#: neutron/plugins/nec/nec_plugin.py:329#: neutron/plugins/nec/nec_plugin.py:342#: neutron/plugins/nec/nec_plugin.py:354#: neutron/plugins/nec/nec_plugin.py:373#: neutron/plugins/nec/nec_plugin.py:399#: neutron/plugins/nec/nec_plugin.py:479#: neutron/plugins/nec/nec_plugin.py:510#: neutron/plugins/nec/nec_plugin.py:529#: neutron/plugins/nec/nec_plugin.py:534#: neutron/plugins/nicira/NeutronPlugin.py:914#: neutron/plugins/nicira/NeutronPlugin.py:1808#: neutron/plugins/nicira/NeutronPlugin.py:838#: neutron/plugins/nicira/NeutronPlugin.py:896#: neutron/plugins/nicira/NeutronPlugin.py:924#: neutron/plugins/nicira/NeutronPlugin.py:927#: neutron/plugins/nicira/NeutronPlugin.py:953#: neutron/plugins/nicira/NeutronPlugin.py:963 #: neutron/plugins/nicira/NeutronPlugin.py:1011#: neutron/plugins/nicira/NeutronPlugin.py:1025#: neutron/plugins/nicira/NeutronPlugin.py:1040#: neutron/plugins/nicira/NeutronPlugin.py:1044#: neutron/plugins/nicira/NeutronPlugin.py:1130#: neutron/plugins/nicira/NeutronPlugin.py:1139#: neutron/plugins/nicira/NeutronPlugin.py:1166#: neutron/plugins/nicira/NeutronPlugin.py:1173#: neutron/plugins/nicira/NeutronPlugin.py:1239#: neutron/plugins/nicira/NeutronPlugin.py:1247#: neutron/plugins/nicira/NeutronPlugin.py:1251#: neutron/plugins/nicira/NeutronPlugin.py:1326#: neutron/plugins/nicira/NeutronPlugin.py:1352#: neutron/plugins/nicira/NeutronPlugin.py:1476 #: neutron/plugins/nicira/NeutronPlugin.py:1520#: neutron/plugins/nicira/NeutronPlugin.py:1489#: neutron/plugins/nicira/NeutronPlugin.py:1529#: neutron/plugins/nicira/NeutronPlugin.py:1545#: neutron/plugins/nicira/NeutronPlugin.py:1549#: neutron/plugins/nicira/NeutronPlugin.py:1551#: neutron/plugins/nicira/NeutronPlugin.py:1584#: neutron/plugins/nicira/NeutronPlugin.py:1588#: neutron/plugins/nicira/NeutronPlugin.py:1608#: neutron/plugins/nicira/NeutronPlugin.py:1635#: neutron/plugins/nicira/NeutronPlugin.py:1657#: neutron/plugins/nicira/NeutronPlugin.py:1683#: neutron/plugins/nicira/NeutronPlugin.py:1718#: neutron/plugins/nicira/NeutronPlugin.py:1763#: neutron/plugins/nicira/NeutronPlugin.py:1775#: neutron/plugins/nicira/NeutronPlugin.py:1804#: neutron/plugins/nicira/NeutronPlugin.py:1830#: neutron/plugins/nicira/NeutronPlugin.py:1836#: neutron/plugins/nicira/NeutronPlugin.py:1902#: neutron/plugins/nicira/NeutronPlugin.py:1926#: neutron/plugins/nicira/NeutronPlugin.py:1969#: neutron/plugins/nicira/NeutronPlugin.py:1972#: neutron/plugins/nicira/NeutronPlugin.py:1998#: neutron/plugins/nicira/NeutronPlugin.py:2020#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:337#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:341#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:394#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:397#: neutron/services/loadbalancer/plugin.py:35#: neutron/services/loadbalancer/plugin.py:68#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:41#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:46#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:50#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:55#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:119#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:132#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:160#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:181#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:196#: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:207#: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:91#: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:136#: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:160 #: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:177#: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:180 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:204 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:225 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:250",6881,5481
openstack%2Fpython-glanceclient~master~Ib651548ab4289295a9b92ee039b2aff2d08aba5f,openstack/python-glanceclient,master,Ib651548ab4289295a9b92ee039b2aff2d08aba5f,Fix SSL certificate CNAME checking,MERGED,2013-06-18 15:36:36.000000000,2013-07-22 21:50:07.000000000,2013-07-22 21:50:07.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 455}, {'_account_id': 616}, {'_account_id': 7817}]","[{'number': 1, 'created': '2013-06-18 15:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/7b38005a45e5c74f19b582ddad0af3fad67aa1e2', 'message': ""Allow preverify_ok to be checked correctly\n\n'preverify_ok is True' will always return false\nchanged to 'preverify_ok == True'\n\nChange-Id: Ib651548ab4289295a9b92ee039b2aff2d08aba5f\n""}, {'number': 2, 'created': '2013-06-18 16:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/18554037d4d33befbe7cb34eb1896adc7fed30fa', 'message': ""Allow preverify_ok to be checked correctly\n\n'preverify_ok is True' will always return false\nchanged to 'preverify_ok == True'\n\nFixes bug 1192229\n\nChange-Id: Ib651548ab4289295a9b92ee039b2aff2d08aba5f\n""}, {'number': 3, 'created': '2013-06-18 16:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/92b368cebac6286c5cbc184d5855d2ee6b518184', 'message': ""Fix SSL certificate CNAME checking\n\n'preverify_ok is True' will always return false\nchanged to 'preverify_ok == True'\n\nFixes bug 1192229\n\nChange-Id: Ib651548ab4289295a9b92ee039b2aff2d08aba5f\n""}, {'number': 4, 'created': '2013-06-19 10:23:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/1bb7e98df3d4026405306237770379ed3d5ba3cc', 'message': ""Fix SSL certificate CNAME checking\n\nCurrently, accessing a host via ip address will pass SSL verification;\nthe CNAME is not checked as intended as part of verify_callback.\n\n'preverify_ok is True' will always return false (int/bool comparison).\npreverify_ok will be 1 if preverification has passed, >1 otherwise.\n\nFixes bug 1192229\n\nChange-Id: Ib651548ab4289295a9b92ee039b2aff2d08aba5f\n""}, {'number': 5, 'created': '2013-06-19 12:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/1be3301885633f21dd58cb2f7a62f1ba76f34520', 'message': ""Fix SSL certificate CNAME checking\n\nCurrently, accessing a host via ip address will pass SSL verification;\nthe CNAME is not checked as intended as part of verify_callback.\n\n'preverify_ok is True' will always return false (int/bool comparison).\npreverify_ok will be 1 if preverification has passed.\n\nFixes bug 1192229\n\nChange-Id: Ib651548ab4289295a9b92ee039b2aff2d08aba5f\n""}, {'number': 6, 'created': '2013-06-20 14:51:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/8fbff324e4c3de3a77b13cf7e0125614334a7c42', 'message': ""Fix SSL certificate CNAME checking\n\nCurrently, accessing a host via ip address will pass SSL verification;\nthe CNAME is not checked as intended as part of verify_callback.\n\n'preverify_ok is True' will always return false (int/bool comparison).\npreverify_ok will be 1 if preverification has passed.\n\nFixes bug 1192229\n\nChange-Id: Ib651548ab4289295a9b92ee039b2aff2d08aba5f\n""}, {'number': 7, 'created': '2013-07-01 12:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/511a6d293bcf55055f56cc9d79f6f14348d583f9', 'message': ""Fix SSL certificate CNAME checking\n\nCurrently, accessing a host via ip address will pass SSL verification;\nthe CNAME is not checked as intended as part of verify_callback.\n\n'preverify_ok is True' will always return false (int/bool comparison).\npreverify_ok will be 1 if preverification has passed.\n\nFixes bug 1192229\n\nChange-Id: Ib651548ab4289295a9b92ee039b2aff2d08aba5f\n""}, {'number': 8, 'created': '2013-07-15 08:50:54.000000000', 'files': ['glanceclient/common/http.py', 'tests/test_ssl.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/822cd64c0718b46a065abbb8709f6b466d12e708', 'message': ""Fix SSL certificate CNAME checking\n\nCurrently, accessing a host via ip address will pass SSL verification;\nthe CNAME is not checked as intended as part of verify_callback.\n\n'preverify_ok is True' will always return false (int/bool comparison).\npreverify_ok will be 1 if preverification has passed.\n\nFixes bug 1192229\n\nChange-Id: Ib651548ab4289295a9b92ee039b2aff2d08aba5f\n""}]",8,33464,822cd64c0718b46a065abbb8709f6b466d12e708,38,5,8,7817,,,0,"Fix SSL certificate CNAME checking

Currently, accessing a host via ip address will pass SSL verification;
the CNAME is not checked as intended as part of verify_callback.

'preverify_ok is True' will always return false (int/bool comparison).
preverify_ok will be 1 if preverification has passed.

Fixes bug 1192229

Change-Id: Ib651548ab4289295a9b92ee039b2aff2d08aba5f
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/64/33464/5 && git format-patch -1 --stdout FETCH_HEAD,['glanceclient/common/http.py'],1,7b38005a45e5c74f19b582ddad0af3fad67aa1e2,bug/1192229, if depth == 0 and preverify_ok == True:, if depth == 0 and preverify_ok is True:,1,1
openstack%2Fironic~master~I46d7ccaf3194832cdc72a8567c4777737da2e1aa,openstack/ironic,master,I46d7ccaf3194832cdc72a8567c4777737da2e1aa,Run extract_messages,MERGED,2013-07-22 07:52:08.000000000,2013-07-22 21:49:03.000000000,2013-07-22 21:49:03.000000000,"[{'_account_id': 3}, {'_account_id': 2889}]","[{'number': 1, 'created': '2013-07-22 07:52:08.000000000', 'files': ['ironic/locale/ironic.pot', 'requirements.txt', 'test-requirements.txt', 'babel.cfg'], 'web_link': 'https://opendev.org/openstack/ironic/commit/ae52281525ba2a8d99da3af84f92a9a875fc9222', 'message': 'Run extract_messages\n\nFix python setup.py extract_messages (babel.cfg\nwas missing). Move Babel to test-requires and\nadd the .pot file to git.\n\nChange-Id: I46d7ccaf3194832cdc72a8567c4777737da2e1aa\n'}]",0,38112,ae52281525ba2a8d99da3af84f92a9a875fc9222,5,2,1,6593,,,0,"Run extract_messages

Fix python setup.py extract_messages (babel.cfg
was missing). Move Babel to test-requires and
add the .pot file to git.

Change-Id: I46d7ccaf3194832cdc72a8567c4777737da2e1aa
",git fetch https://review.opendev.org/openstack/ironic refs/changes/12/38112/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/locale/ironic.pot', 'requirements.txt', 'test-requirements.txt', 'babel.cfg']",4,ae52281525ba2a8d99da3af84f92a9a875fc9222,message_extract,[python: **.py] ,,1298,1
openstack%2Fswift~master~I5a613e832e9a7a149b3e9317c053c3048f34afcb,openstack/swift,master,I5a613e832e9a7a149b3e9317c053c3048f34afcb,Ensure that files in tests are closed.,MERGED,2013-07-20 20:44:46.000000000,2013-07-22 21:39:04.000000000,2013-07-22 21:39:04.000000000,"[{'_account_id': 3}, {'_account_id': 917}, {'_account_id': 1009}, {'_account_id': 2472}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-20 20:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cd41af760ba6c75ab34b5b3e51a957290cf79497', 'message': 'Ensure that files in tests are closed.\n\nThis is needed on Pythons which do not have\nreference counting GCs (e.g. PyPy).\n\nChange-Id: I5a613e832e9a7a149b3e9317c053c3048f34afcb\n'}, {'number': 2, 'created': '2013-07-20 20:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c6a8728c0f6fd4941c786cbd4722b5d21445a586', 'message': 'Ensure that files in tests are closed.\n\nThis is needed on Pythons which do not have\nreference counting GCs (e.g. PyPy).\n\nChange-Id: I5a613e832e9a7a149b3e9317c053c3048f34afcb\n'}, {'number': 3, 'created': '2013-07-20 21:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/16d9610292138e8541dd282f13af642329794aec', 'message': 'Ensure that files in tests are closed.\n\nThis is needed on Pythons which do not have\nreference counting GCs (e.g. PyPy).\n\nChange-Id: I5a613e832e9a7a149b3e9317c053c3048f34afcb\n'}, {'number': 4, 'created': '2013-07-20 22:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ddca5349789f1f9a6a90d0cbf002920ac326b369', 'message': 'Ensure that files in tests are closed.\n\nThis is needed on Pythons which do not have\nreference counting GCs (e.g. PyPy).\n\nChange-Id: I5a613e832e9a7a149b3e9317c053c3048f34afcb\n'}, {'number': 5, 'created': '2013-07-20 23:13:57.000000000', 'files': ['test/unit/common/ring/test_ring.py', 'test/unit/container/test_updater.py', 'test/unit/obj/test_base.py', 'test/unit/obj/test_replicator.py', 'test/unit/obj/test_updater.py', 'test/unit/common/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c1f8f266d0c465760535d0305d65138199f67daf', 'message': 'Ensure that files in tests are closed.\n\nThis is needed on Pythons which do not have\nreference counting GCs (e.g. PyPy).\n\nChange-Id: I5a613e832e9a7a149b3e9317c053c3048f34afcb\n'}]",0,38051,c1f8f266d0c465760535d0305d65138199f67daf,14,7,5,7680,,,0,"Ensure that files in tests are closed.

This is needed on Pythons which do not have
reference counting GCs (e.g. PyPy).

Change-Id: I5a613e832e9a7a149b3e9317c053c3048f34afcb
",git fetch https://review.opendev.org/openstack/swift refs/changes/51/38051/4 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/common/ring/test_ring.py'],1,cd41af760ba6c75ab34b5b3e51a957290cf79497,close-file," with GzipFile(ring_fname, 'wb') as f: pickle.dump(rd, f, protocol=p) [array.array('H', [0, 1, 0, 1]), array.array('H', [0, 1, 0, 1])],"," pickle.dump(rd, GzipFile(ring_fname, 'wb'), protocol=p) [array.array('H', [0, 1, 0, 1]), array.array('H',[0, 1, 0, 1])],",3,2
openstack%2Ftrove~master~Ib82f7dcd43f1f7fbba5c5ade44785243d9d1186d,openstack/trove,master,Ib82f7dcd43f1f7fbba5c5ade44785243d9d1186d,Makes two tests wait for the instance to go ACTIVE,MERGED,2013-07-17 15:36:29.000000000,2013-07-22 21:36:18.000000000,2013-07-22 21:36:18.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 739}, {'_account_id': 5293}, {'_account_id': 6162}, {'_account_id': 7092}]","[{'number': 1, 'created': '2013-07-17 15:36:29.000000000', 'files': ['trove/tests/api/instances_actions.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/9678ecef3b9045b0ee2be1d56c731d69fe95a082', 'message': 'Makes two tests wait for the instance to go ACTIVE\n\nIn environments with limited resources, these two\ntests can fail intermittently because of some timing\nrelated to resizing. Waiting for the instance to\nreturn to active resolves the resulting 422s.\n\nChange-Id: Ib82f7dcd43f1f7fbba5c5ade44785243d9d1186d\n'}]",0,37502,9678ecef3b9045b0ee2be1d56c731d69fe95a082,12,6,1,1375,,,0,"Makes two tests wait for the instance to go ACTIVE

In environments with limited resources, these two
tests can fail intermittently because of some timing
related to resizing. Waiting for the instance to
return to active resolves the resulting 422s.

Change-Id: Ib82f7dcd43f1f7fbba5c5ade44785243d9d1186d
",git fetch https://review.opendev.org/openstack/trove refs/changes/02/37502/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/tests/api/instances_actions.py'],1,9678ecef3b9045b0ee2be1d56c731d69fe95a082,wait-on-resize-tests," def is_active(): return self.instance.status == 'ACTIVE' poll_until(is_active, time_out=TIME_OUT_TIME) assert_equal(self.instance.status, 'ACTIVE') old_flavor_href = self.get_flavor_href( flavor_id=self.expected_old_flavor_id) def is_active(): return self.instance.status == 'ACTIVE' poll_until(is_active, time_out=TIME_OUT_TIME) assert_equal(self.instance.status, 'ACTIVE') old_flavor_href = self.get_flavor_href( flavor_id=self.expected_old_flavor_id) self.dbaas.instances.resize_instance(self.instance_id, old_flavor_href)"," self.dbaas.instances.resize_instance( self.instance_id, self.get_flavor_href(flavor_id=self.expected_old_flavor_id))",18,3
openstack%2Ftrove~master~I2e25afc0a20d7d834aaf477a32b9a69aa27a9eba,openstack/trove,master,I2e25afc0a20d7d834aaf477a32b9a69aa27a9eba,Update to latest Oslo rpc modules,MERGED,2013-07-08 23:11:06.000000000,2013-07-22 21:33:17.000000000,2013-07-22 21:33:16.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 739}, {'_account_id': 1375}, {'_account_id': 7092}]","[{'number': 1, 'created': '2013-07-08 23:11:06.000000000', 'files': ['trove/openstack/common/gettextutils.py', 'trove/openstack/common/rpc/matchmaker.py', 'trove/openstack/common/service.py', 'trove/openstack/common/rpc/common.py', 'trove/openstack/common/network_utils.py', 'trove/openstack/common/rpc/amqp.py', 'trove/openstack/common/log.py', 'trove/openstack/common/excutils.py', 'trove/openstack/common/rpc/impl_fake.py', 'trove/openstack/common/rpc/serializer.py', 'trove/openstack/common/rpc/dispatcher.py', 'trove/openstack/common/rpc/impl_zmq.py', 'trove/openstack/common/jsonutils.py', 'trove/openstack/common/rpc/impl_kombu.py', 'trove/openstack/common/rpc/matchmaker_redis.py', 'trove/openstack/common/rpc/matchmaker_ring.py', 'trove/openstack/common/rpc/service.py', 'trove/openstack/common/threadgroup.py', 'trove/openstack/common/timeutils.py', 'trove/openstack/common/eventlet_backdoor.py', 'trove/openstack/common/rpc/impl_qpid.py', 'trove/openstack/common/rpc/proxy.py', 'trove/openstack/common/importutils.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/1b0d4239284480461947a8baf6184d966cc10df8', 'message': 'Update to latest Oslo rpc modules\n\n* Oslo rpc code now supports heartbeats which will provide Trove\n  reliable connections to guests\n* Updated the rpc module only via the oslo update procedures\n\nAddresses blueprint trove/update-oslo\n\nChange-Id: I2e25afc0a20d7d834aaf477a32b9a69aa27a9eba\n'}]",0,36140,1b0d4239284480461947a8baf6184d966cc10df8,17,5,1,1925,,,0,"Update to latest Oslo rpc modules

* Oslo rpc code now supports heartbeats which will provide Trove
  reliable connections to guests
* Updated the rpc module only via the oslo update procedures

Addresses blueprint trove/update-oslo

Change-Id: I2e25afc0a20d7d834aaf477a32b9a69aa27a9eba
",git fetch https://review.opendev.org/openstack/trove refs/changes/40/36140/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/openstack/common/gettextutils.py', 'trove/openstack/common/rpc/matchmaker.py', 'trove/openstack/common/service.py', 'trove/openstack/common/rpc/common.py', 'trove/openstack/common/network_utils.py', 'trove/openstack/common/rpc/amqp.py', 'trove/openstack/common/log.py', 'trove/openstack/common/excutils.py', 'trove/openstack/common/rpc/impl_fake.py', 'trove/openstack/common/rpc/serializer.py', 'trove/openstack/common/rpc/dispatcher.py', 'trove/openstack/common/rpc/impl_zmq.py', 'trove/openstack/common/jsonutils.py', 'trove/openstack/common/rpc/impl_kombu.py', 'trove/openstack/common/rpc/matchmaker_redis.py', 'trove/openstack/common/rpc/matchmaker_ring.py', 'trove/openstack/common/rpc/service.py', 'trove/openstack/common/threadgroup.py', 'trove/openstack/common/timeutils.py', 'trove/openstack/common/eventlet_backdoor.py', 'trove/openstack/common/rpc/impl_qpid.py', 'trove/openstack/common/rpc/proxy.py', 'trove/openstack/common/importutils.py']",23,1b0d4239284480461947a8baf6184d966cc10df8,bp/trove," """"""Returns a class from a string including module and class."""""" """"""Tries to import object from default namespace. Imports a class and return an instance of it, first by trying"," """"""Returns a class from a string including module and class"""""" """""" Import a class and return an instance of it, first by trying",1056,597
openstack%2Foslosphinx~master~If336be59cf790029b5e24f05074e6ec6e9658134,openstack/oslosphinx,master,If336be59cf790029b5e24f05074e6ec6e9658134,Allow use of hacking 0.6.0 and fix min version,MERGED,2013-07-19 20:49:01.000000000,2013-07-22 21:18:32.000000000,2013-07-22 21:18:32.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1994}, {'_account_id': 2472}, {'_account_id': 6786}]","[{'number': 1, 'created': '2013-07-19 20:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslosphinx/commit/fb6d8e93d880567a4a6166e3c635de5837fd98e1', 'message': 'Allow use of hacking 0.6.0\n\nChange-Id: If336be59cf790029b5e24f05074e6ec6e9658134\n'}, {'number': 2, 'created': '2013-07-22 04:11:47.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslosphinx/commit/9f34799a2c9880fce18d3f89033caa968cfd7ad1', 'message': 'Allow use of hacking 0.6.0 and fix min version\n\nChange-Id: If336be59cf790029b5e24f05074e6ec6e9658134\n'}]",2,37968,9f34799a2c9880fce18d3f89033caa968cfd7ad1,11,5,2,6786,,,0,"Allow use of hacking 0.6.0 and fix min version

Change-Id: If336be59cf790029b5e24f05074e6ec6e9658134
",git fetch https://review.opendev.org/openstack/oslosphinx refs/changes/68/37968/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,fb6d8e93d880567a4a6166e3c635de5837fd98e1,," hacking>=0.5.3,<0.7"," hacking>=0.5.3,<0.6",1,1
openstack%2Ftrove~master~Icff176de9f18fe08749473ee3d68c70c55be2c9c,openstack/trove,master,Icff176de9f18fe08749473ee3d68c70c55be2c9c,Added param name to validation error messages,MERGED,2013-07-18 15:47:52.000000000,2013-07-22 21:17:18.000000000,2013-07-22 21:17:18.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 739}, {'_account_id': 1375}, {'_account_id': 1925}, {'_account_id': 6156}, {'_account_id': 7092}]","[{'number': 1, 'created': '2013-07-18 15:47:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8bdc9a9da68bc9b27cb000dbae05a6ff31664ef5', 'message': 'Added param name to validation error messages\n\n    Validation errors now pre-fixed with param name so that its\n    easier to troubleshoot\n\nFixes: bug 1201993\n\nChange-Id: Icff176de9f18fe08749473ee3d68c70c55be2c9c\n'}, {'number': 2, 'created': '2013-07-19 06:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a83bebd7d30ead42e359d0aaac6d98e9508b1417', 'message': 'Added param name to validation error messages\n\n    Validation errors now pre-fixed with param name so that its\n    easier to troubleshoot\n\nFixes: bug 1201993\n\nChange-Id: Icff176de9f18fe08749473ee3d68c70c55be2c9c\n'}, {'number': 3, 'created': '2013-07-22 16:26:11.000000000', 'files': ['trove/common/wsgi.py', 'trove/tests/api/backups.py', 'trove/tests/api/mgmt/malformed_json.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/988d666af7e9d4f6c5bb036f99dc45e54fe5672a', 'message': 'Added param name to validation error messages\n\n    Validation errors now pre-fixed with param name so that its\n    easier to troubleshoot\n\nFixes: bug 1201993\n\nChange-Id: Icff176de9f18fe08749473ee3d68c70c55be2c9c\n'}]",3,37706,988d666af7e9d4f6c5bb036f99dc45e54fe5672a,35,7,3,6156,,,0,"Added param name to validation error messages

    Validation errors now pre-fixed with param name so that its
    easier to troubleshoot

Fixes: bug 1201993

Change-Id: Icff176de9f18fe08749473ee3d68c70c55be2c9c
",git fetch https://review.opendev.org/openstack/trove refs/changes/06/37706/3 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/wsgi.py', 'trove/tests/api/backups.py', 'trove/tests/api/mgmt/malformed_json.py']",3,8bdc9a9da68bc9b27cb000dbae05a6ff31664ef5,bug/1201993," ""instance.databases %s is not of type 'array'; "" ""instance.users %s is not of type 'array'; "" ""instance.volume 3 is not of type 'object'"" % (databases, users)) ""Validation error: "" ""databases %s is not of type 'array'"" % ""Validation error: users.0 "" ""Additional properties are not allowed "" ""users.0 'name' is a required property; "" ""users.0 'password' is a required property"") ""resize.volume.size %s is not valid under any of "" ""the given schemas; "" ""%s does not match '[0-9]+'"" % (data, data, data)) assert_equal(e.message, ""Validation error: "" ""users.0 'password' is a required property; "" ""users.0.name %s is too short; "" ""users.0.name %s does not match "" ""'^.*[0-9a-zA-Z]+.*$'"" % (password, password)) ""Validation error: "" ""instance.flavorRef %s is not valid under any "" ""instance.volume 2 is not of type 'object'"" % ""Validation error: "" ""instance.volume %s is not of type 'object'"" %"," ""%s is not of type 'array'; "" ""%s is not of type 'array'; "" ""3 is not of type 'object'"" % (databases, users)) ""Validation error: %s is not of type 'array'"" % ""Validation error: Additional properties are not "" ""allowed "" ""'name' is a required property; "" ""'password' is a required property"") ""%s is not valid under any of the given schemas; "" ""%s does not match '[0-9]+'"" % (data, data, data)) assert_equal(e.message, ""Validation error: "" ""'password' is a required property; "" ""%s is too short; "" ""%s does not match "" ""'^.*[0-9a-zA-Z]+.*$'"" % (password, password)) ""Validation error: %s is not valid under any "" ""2 is not of type 'object'"" % ""Validation error: %s is not of type 'object'"" %",30,22
openstack%2Fironic~master~I4162d8e94d023b9b724ea35b02823ddd6317032b,openstack/ironic,master,I4162d8e94d023b9b724ea35b02823ddd6317032b,Add serializer param to RPC service,MERGED,2013-07-18 22:28:44.000000000,2013-07-22 21:11:41.000000000,2013-07-22 21:11:41.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6773}]","[{'number': 1, 'created': '2013-07-18 22:28:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a20c862852a18044d7de1ad7083f306fef8cbf7b', 'message': 'Add serializer param to RPC service\n\nAllow a serializer to be passed to RPC service class\nwhen it is instantiated.\n\nChange-Id: I4162d8e94d023b9b724ea35b02823ddd6317032b\n'}, {'number': 2, 'created': '2013-07-18 22:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/736453f50f65a287f4f2d7b5d62082ec29139e44', 'message': 'Add serializer param to RPC service\n\nAllow a serializer to be passed to RPC service class\nwhen it is instantiated.\n\nChange-Id: I4162d8e94d023b9b724ea35b02823ddd6317032b\n'}, {'number': 3, 'created': '2013-07-19 06:21:20.000000000', 'files': ['ironic/openstack/common/rpc/service.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/cb3c489be3ecc90e27104e83feaf2b6105595aab', 'message': 'Add serializer param to RPC service\n\nAllow a serializer to be passed to RPC service class\nwhen it is instantiated.\n\nChange-Id: I4162d8e94d023b9b724ea35b02823ddd6317032b\n'}]",0,37796,cb3c489be3ecc90e27104e83feaf2b6105595aab,10,3,3,2889,,,0,"Add serializer param to RPC service

Allow a serializer to be passed to RPC service class
when it is instantiated.

Change-Id: I4162d8e94d023b9b724ea35b02823ddd6317032b
",git fetch https://review.opendev.org/openstack/ironic refs/changes/96/37796/2 && git format-patch -1 --stdout FETCH_HEAD,['ironic/openstack/common/rpc/service.py'],1,a20c862852a18044d7de1ad7083f306fef8cbf7b,rpc-updates," def __init__(self, host, topic, manager=None, serializer=None): self.serializer = serializer dispatcher = rpc_dispatcher.RpcDispatcher([self.manager], self.serializer)"," def __init__(self, host, topic, manager=None): dispatcher = rpc_dispatcher.RpcDispatcher([self.manager])",4,2
openstack%2Fironic~master~I0a16f45674f5d14f458e2bb490d909a9086ea8b4,openstack/ironic,master,I0a16f45674f5d14f458e2bb490d909a9086ea8b4,Import serialization and nesting from Nova Objects,MERGED,2013-07-18 17:22:08.000000000,2013-07-22 21:11:17.000000000,2013-07-22 21:11:17.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6773}]","[{'number': 1, 'created': '2013-07-18 17:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/374366e0af66258e3a1ce5e56fb8661e840bd67d', 'message': ""import updates from nova's RPC objects\n\nChange-Id: I0a16f45674f5d14f458e2bb490d909a9086ea8b4\n""}, {'number': 2, 'created': '2013-07-18 18:09:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2a9e28c04e276a8895493c3c228e5f5c41c917b1', 'message': ""import updates from nova's RPC objects\n\nChange-Id: I0a16f45674f5d14f458e2bb490d909a9086ea8b4\n""}, {'number': 3, 'created': '2013-07-18 22:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9d3b535907b59d29a55cc7bffd7e5cb4ebad46cd', 'message': ""import updates from nova's RPC objects\n\nChange-Id: I0a16f45674f5d14f458e2bb490d909a9086ea8b4\n""}, {'number': 4, 'created': '2013-07-18 22:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/99c051d72de49c42551b2183b7251b64e24edef3', 'message': 'Import serialization and nesting from Nova Objects\n\nChange-Id: I0a16f45674f5d14f458e2bb490d909a9086ea8b4\n'}, {'number': 5, 'created': '2013-07-18 22:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/209c79dbb5398f2940da0e8c4eb5cba634513c37', 'message': 'Import serialization and nesting from Nova Objects\n\nChange-Id: I0a16f45674f5d14f458e2bb490d909a9086ea8b4\n'}, {'number': 6, 'created': '2013-07-19 06:21:20.000000000', 'files': ['ironic/tests/objects/test_objects.py', 'ironic/tests/base.py', 'ironic/objects/utils.py', 'ironic/objects/base.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a5e5bd7cee6b8827dc89e9deee4cb2e36bca63a4', 'message': 'Import serialization and nesting from Nova Objects\n\nThis change mostly merges the following commits from Nova:\n\ne91c3d141c957485dcb66c73e84b41b775e4268b\nf1c4b8e5f34eb6b5e70da6711750dcf05cea8c0a\n65f6c536fecd3c788b2e0dfa9d66ecd24ca550e1\n92a3190128547403dc603e5a40e377c6eb0c8025\n68cb4d53385821c3ffdc40c299a77d11a7f98f27\n\nChange-Id: I0a16f45674f5d14f458e2bb490d909a9086ea8b4\n'}]",8,37726,a5e5bd7cee6b8827dc89e9deee4cb2e36bca63a4,22,5,6,2889,,,0,"Import serialization and nesting from Nova Objects

This change mostly merges the following commits from Nova:

e91c3d141c957485dcb66c73e84b41b775e4268b
f1c4b8e5f34eb6b5e70da6711750dcf05cea8c0a
65f6c536fecd3c788b2e0dfa9d66ecd24ca550e1
92a3190128547403dc603e5a40e377c6eb0c8025
68cb4d53385821c3ffdc40c299a77d11a7f98f27

Change-Id: I0a16f45674f5d14f458e2bb490d909a9086ea8b4
",git fetch https://review.opendev.org/openstack/ironic refs/changes/26/37726/4 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/objects/utils.py', 'ironic/objects/base.py']",2,374366e0af66258e3a1ce5e56fb8661e840bd67d,rpc-updates," def getter(self, name=name): self.obj_load_attr(name) 'created_at': obj_utils.datetime_or_str_or_none, 'updated_at': obj_utils.datetime_or_str_or_none, } obj_extra_fields = [] def obj_from_primitive(cls, primitive, context=None): self._context = context """"""Returns a set of fields that have been modified."""""" for name in self.fields.keys() + self.obj_extra_fields: if (hasattr(self, get_attrname(name)) or name in self.obj_extra_fields): def __contains__(self, name): """"""For backwards-compatibility with dict-based objects. NOTE(danms): May be removed in the future. """""" return hasattr(self, get_attrname(name)) def update(self, updates): """"""For backwards-compatibility with dict-base objects. NOTE(danms): May be removed in the future. """""" for key, value in updates.items(): self[key] = value class ObjectListBase(object): """"""Mixin class for lists of objects. This mixin class can be added as a base class for an object that is implementing a list of objects. It adds a single field of 'objects', which is the list store, and behaves like a list itself. It supports serialization of the list of objects automatically. """""" fields = { 'objects': list, } def __iter__(self): """"""List iterator interface."""""" return iter(self.objects) def __len__(self): """"""List length."""""" return len(self.objects) def __getitem__(self, index): """"""List index access."""""" if isinstance(index, slice): new_obj = self.__class__() new_obj.objects = self.objects[index] # NOTE(danms): We must be mixed in with an IronicObject! new_obj.obj_reset_changes() new_obj._context = self._context return new_obj return self.objects[index] def __contains__(self, value): """"""List membership test."""""" return value in self.objects def count(self, value): """"""List count of value occurrences."""""" return self.objects.count(value) def index(self, value): """"""List index of value."""""" return self.objects.index(value) def _attr_objects_to_primitive(self): """"""Serialization of object list."""""" return [x.obj_to_primitive() for x in self.objects] def _attr_objects_from_primitive(self, value): """"""Deserialization of object list."""""" objects = [] for entity in value: obj = IronicObject.obj_from_primitive(entity, context=self._context) objects.append(obj) return objects def _process_iterable(self, context, action_fn, values): """"""Process an iterable, taking an action on each value. :param:context: Request context :param:action_fn: Action to take on each item in values :param:values: Iterable container of things to take action on :returns: A new container of the same type (except set) with items from values having had action applied. """""" iterable = values.__class__ if iterable == set: # NOTE(danms): A set can't have an unhashable value inside, such as # a dict. Convert sets to tuples, which is fine, since we can't # send them over RPC anyway. iterable = tuple return iterable([action_fn(context, value) for value in values]) def serialize_entity(self, context, entity): print ""SERIALIZING IT"" if isinstance(entity, (tuple, list, set)): entity = self._process_iterable(context, self.serialize_entity, entity) elif (hasattr(entity, 'obj_to_primitive') and callable(entity.obj_to_primitive)): entity = IronicObject.obj_from_primitive(entity, context=context) elif isinstance(entity, (tuple, list, set)): entity = self._process_iterable(context, self.deserialize_entity, entity) def obj_to_primitive(obj): """"""Recursively turn an object into a python primitive. An IronicObject becomes a dict, and anything that implements ObjectListBase becomes a list. """""" if isinstance(obj, ObjectListBase): return [obj_to_primitive(x) for x in obj] elif isinstance(obj, IronicObject): result = {} for key, value in obj.iteritems(): result[key] = obj_to_primitive(value) return result else: return obj"," def getter(self, name=name, typefn=typefn): self.obj_load(name) 'created_at': obj_utils.datetime_or_none, 'updated_at': obj_utils.datetime_or_none, } def obj_from_primitive(cls, primitive): """"""Returns a list of fields that have been modified."""""" for name in self.fields: if hasattr(self, get_attrname(name)): def serialize_entity(self, context, entity): if (hasattr(entity, 'obj_to_primitive') and callable(entity.obj_to_primitive)): entity = IronicObject.obj_from_primitive(entity) entity._context = context",163,14
openstack%2Foslo.config~master~Iaf75b8991c6a7c79a22651ca15867adda4dac2b1,openstack/oslo.config,master,Iaf75b8991c6a7c79a22651ca15867adda4dac2b1,Allow use of hacking 0.6.0 and fix min version,MERGED,2013-07-19 20:48:58.000000000,2013-07-22 21:09:49.000000000,2013-07-22 21:09:49.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1994}, {'_account_id': 6786}]","[{'number': 1, 'created': '2013-07-19 20:48:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/de3ebe72934b443b652133e475659c256084310a', 'message': 'Allow use of hacking 0.6.0\n\nChange-Id: Iaf75b8991c6a7c79a22651ca15867adda4dac2b1\n'}, {'number': 2, 'created': '2013-07-19 20:51:46.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/b7f895fad2d5973a2a8515b537bd00740a725d01', 'message': 'Allow use of hacking 0.6.0 and fix min version\n\nChange-Id: Iaf75b8991c6a7c79a22651ca15867adda4dac2b1\n'}]",0,37967,b7f895fad2d5973a2a8515b537bd00740a725d01,8,4,2,6786,,,0,"Allow use of hacking 0.6.0 and fix min version

Change-Id: Iaf75b8991c6a7c79a22651ca15867adda4dac2b1
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/67/37967/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,de3ebe72934b443b652133e475659c256084310a,,"hacking>=0.5.3,<0.7","hacking>=0.5.3,<0.6",1,1
openstack%2Foslo-incubator~master~I7b3ca48502c9d5a99802c24dfcec0a1a8292fa07,openstack/oslo-incubator,master,I7b3ca48502c9d5a99802c24dfcec0a1a8292fa07,"On reconnecting a FanoutConsumer, don't grow the topic name",MERGED,2013-07-15 19:01:09.000000000,2013-07-22 21:00:55.000000000,2013-07-22 21:00:54.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 2472}, {'_account_id': 4912}, {'_account_id': 6786}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-07-15 19:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f6f1be46ccc3cc48cc8decf50689553c572603ae', 'message': ""On reconnecting a FanoutConsumer, don't grow the topic name\n\nCommit 719eba4cae7f2bc11753b17c65c7597b8d6ed72d in oslo-incubator introduced a small bug on reconnect. Because of the way the topic was extracted, an extra '_fanout' gets tacked onto the topic name with each reconnect. A one line fix in code (rpartition) and test case are needed.\n\nChange-Id: I7b3ca48502c9d5a99802c24dfcec0a1a8292fa07\nFixes: bug #1201552\n""}, {'number': 2, 'created': '2013-07-15 19:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/d2fecc14080d94d6f3f8479ec7aaf4ef5578c2b7', 'message': ""On reconnecting a FanoutConsumer, don't grow the topic name\n\nCommit 719eba4cae7f2bc11753b17c65c7597b8d6ed72d in oslo-incubator introduced a\nsmall bug on reconnect. Because of the way the topic was extracted, an extra\n'_fanout' gets tacked onto the topic name with each reconnect. A one line fix\nin code (rpartition) and test case are needed.\n\nChange-Id: I7b3ca48502c9d5a99802c24dfcec0a1a8292fa07\nFixes: bug #1201552\n""}, {'number': 3, 'created': '2013-07-15 19:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/55d324eb829cf3caa57d2dd44af5cfdeaeaa3582', 'message': ""On reconnecting a FanoutConsumer, don't grow the topic name\n\nCommit 719eba4cae7f2bc11753b17c65c7597b8d6ed72d in oslo-incubator\nintroduced a small bug on reconnect. Because of the way the topic\nwas extracted, an extra '_fanout' gets tacked onto the topic name\nwith each reconnect. A one line fix in code (rpartition) and test\ncase are needed.\n\nChange-Id: I7b3ca48502c9d5a99802c24dfcec0a1a8292fa07\nFixes: bug #1201552\n""}, {'number': 4, 'created': '2013-07-20 21:30:30.000000000', 'files': ['openstack/common/rpc/impl_qpid.py', 'tests/unit/rpc/test_qpid.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/34a684200e2f34be2f7c0b86da48c0c46691fe46', 'message': ""On reconnecting a FanoutConsumer, don't grow the topic name\n\nCommit 719eba4cae7f2bc11753b17c65c7597b8d6ed72d in oslo-incubator\nintroduced a small bug on reconnect. Because of the way the topic\nwas extracted, an extra '_fanout' gets tacked onto the topic name\nwith each reconnect. A one line fix in code (rpartition) and test\ncase are needed.\n\nChange-Id: I7b3ca48502c9d5a99802c24dfcec0a1a8292fa07\nFixes: bug #1201552\n""}]",2,37110,34a684200e2f34be2f7c0b86da48c0c46691fe46,20,7,4,4912,,,0,"On reconnecting a FanoutConsumer, don't grow the topic name

Commit 719eba4cae7f2bc11753b17c65c7597b8d6ed72d in oslo-incubator
introduced a small bug on reconnect. Because of the way the topic
was extracted, an extra '_fanout' gets tacked onto the topic name
with each reconnect. A one line fix in code (rpartition) and test
case are needed.

Change-Id: I7b3ca48502c9d5a99802c24dfcec0a1a8292fa07
Fixes: bug #1201552
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/10/37110/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/rpc/impl_qpid.py', 'tests/unit/rpc/test_qpid.py']",2,f6f1be46ccc3cc48cc8decf50689553c572603ae,bug/1201552," def test_fanout_reconnect(self): expected_address = mox.Regex( r'^impl_qpid_test_fanout ; ' '{""node"": {""x-declare"": {""auto-delete"": true, ""durable"": ' 'false, ""type"": ""fanout""}, ""type"": ""topic""}, ""create"": ' '""always"", ""link"": {""x-declare"": {""auto-delete"": true, ' '""exclusive"": true, ""durable"": false}, ""durable"": true, ' '""name"": ""impl_qpid_test_fanout_.*""}}$') self.mock_connection = self.mox.CreateMock(self.orig_connection) self.mock_session = self.mox.CreateMock(self.orig_session) self.mock_receiver = self.mox.CreateMock(self.orig_receiver) # First connection and create_consumer self.mock_connection.opened().AndReturn(False) self.mock_connection.open() self.mock_connection.session().AndReturn(self.mock_session) self.mock_session.receiver(expected_address).AndReturn( self.mock_receiver) self.mock_receiver.capacity = 1 # Now call reconnect self.mock_connection.opened().AndReturn(False) self.mock_connection.open() self.mock_connection.session().AndReturn(self.mock_session) # FIXME(wilsonmh): connect is currently part of __init__(), # causing a reconnect to declare two receivers :( self.mock_session.receiver(expected_address).AndReturn( self.mock_receiver) self.mock_session.receiver(expected_address).AndReturn( self.mock_receiver) self.mock_receiver.capacity = 1 self.mock_connection.close() self.mox.ReplayAll() connection = impl_qpid.create_connection(FLAGS) connection.create_consumer(""impl_qpid_test"", None, True) connection.reconnect() connection.close() ",,44,1
openstack%2Foslo.config~master~I1c0002d3992e25e7e0927eca85ccd5e4d57ee7d1,openstack/oslo.config,master,I1c0002d3992e25e7e0927eca85ccd5e4d57ee7d1,Fix python 3.3 test configuration,MERGED,2013-07-21 21:00:04.000000000,2013-07-22 20:59:29.000000000,2013-07-22 20:59:29.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 24}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2472}, {'_account_id': 5263}]","[{'number': 1, 'created': '2013-07-21 21:00:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/4c5679a602a6737e866e89f9b741c8613481335c', 'message': ""Fix python 3.3 test configuration\n\nIt is no longer necessary to install testrepository from bzr,\nso don't. That means we no longer need a separate py33\nenvironment definition, or the special requirements file.\n\nDo not use distribute in the test virtualenvs.\n\nChange-Id: I1c0002d3992e25e7e0927eca85ccd5e4d57ee7d1\n""}, {'number': 2, 'created': '2013-07-21 21:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/ef96ff6f3aa1290ca15905b7bf1e2e9935f49aa3', 'message': ""Fix python 3.3 test configuration\n\nIt is no longer necessary to install testrepository from bzr,\nso don't. That means we no longer need a separate py33\nenvironment definition, or the special requirements file.\n\nDo not use distribute in the test virtualenvs.\n\nChange-Id: I1c0002d3992e25e7e0927eca85ccd5e4d57ee7d1\n""}, {'number': 3, 'created': '2013-07-22 19:19:37.000000000', 'files': ['test-requirements.txt', 'test-requirements-py3.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/9bc1af398e888f5981453a3efbff2b913767d21a', 'message': ""Fix python 3.3 test configuration\n\nIt is no longer necessary to install testrepository from bzr,\nso don't. That means we no longer need a separate py33\nenvironment definition, or the special requirements file.\n\nDo not use distribute in the test virtualenvs.\n\nChange-Id: I1c0002d3992e25e7e0927eca85ccd5e4d57ee7d1\n""}]",0,38088,9bc1af398e888f5981453a3efbff2b913767d21a,13,8,3,2472,,,0,"Fix python 3.3 test configuration

It is no longer necessary to install testrepository from bzr,
so don't. That means we no longer need a separate py33
environment definition, or the special requirements file.

Do not use distribute in the test virtualenvs.

Change-Id: I1c0002d3992e25e7e0927eca85ccd5e4d57ee7d1
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/88/38088/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements-py3.txt', 'tox.ini']",2,4c5679a602a6737e866e89f9b741c8613481335c,python3tests,distribute = False,[testenv:py33] deps = -r{toxinidir}/test-requirements-py3.txt ,1,24
openstack%2Fswift~master~Ib9fe1b52733ffa5b919c2a524a4f3ad7baef09a5,openstack/swift,master,Ib9fe1b52733ffa5b919c2a524a4f3ad7baef09a5,Remove unused exceptions,MERGED,2013-07-18 20:06:31.000000000,2013-07-22 20:34:47.000000000,2013-07-22 20:34:46.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 917}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-18 20:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e1259260afd8552b45e4a38a0d2cdcd3bca9daf7', 'message': 'Remove unused exceptions\n\nChange-Id: Ib9fe1b52733ffa5b919c2a524a4f3ad7baef09a5\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 2, 'created': '2013-07-22 14:07:12.000000000', 'files': ['swift/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/8faa21d233c8c454fd156a9cb47020d501ca576f', 'message': 'Remove unused exceptions\n\nChange-Id: Ib9fe1b52733ffa5b919c2a524a4f3ad7baef09a5\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",0,37760,8faa21d233c8c454fd156a9cb47020d501ca576f,12,7,2,6198,,,0,"Remove unused exceptions

Change-Id: Ib9fe1b52733ffa5b919c2a524a4f3ad7baef09a5
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/60/37760/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/exceptions.py'],1,e1259260afd8552b45e4a38a0d2cdcd3bca9daf7,exc,,class SwiftConfigurationError(SwiftException): pass class AuthException(SwiftException): pass ,0,8
openstack%2Foslo.config~master~I12a861f2b8b5bd95d696563cb335ff240f9a8374,openstack/oslo.config,master,I12a861f2b8b5bd95d696563cb335ff240f9a8374,Simplify test-requirements for py33,ABANDONED,2013-07-22 08:27:04.000000000,2013-07-22 20:34:04.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-07-22 08:27:04.000000000', 'files': ['test-requirements.txt', 'test-requirements-py3.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/0d3c809262886de09d2112564595ecbfcfc25105', 'message': 'Simplify test-requirements for py33\n\nNow that testrepository 0.0.17 is released, we can depend on it to have a\nworking py33 environment.\n\nChange-Id: I12a861f2b8b5bd95d696563cb335ff240f9a8374\n'}]",0,38118,0d3c809262886de09d2112564595ecbfcfc25105,3,2,1,1669,,,0,"Simplify test-requirements for py33

Now that testrepository 0.0.17 is released, we can depend on it to have a
working py33 environment.

Change-Id: I12a861f2b8b5bd95d696563cb335ff240f9a8374
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/18/38118/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'test-requirements-py3.txt', 'tox.ini']",3,0d3c809262886de09d2112564595ecbfcfc25105,jd/python-3-simplify,,[testenv:py33] deps = -r{toxinidir}/test-requirements-py3.txt ,1,25
openstack%2Fpbr~master~If53dcdaea0a48ef613e3097ab55d34f056160188,openstack/pbr,master,If53dcdaea0a48ef613e3097ab55d34f056160188,Add more documentation,MERGED,2013-07-17 19:11:37.000000000,2013-07-22 20:01:18.000000000,2013-07-22 20:01:18.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2013-07-17 19:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/47029270de13d63b18f2c6fd7595a18ffe5a71b4', 'message': 'Add more documentation\n\nMoved a good portion of README into the sphinx docs. Also started\nfleshing out descriptions of how to use things.\n\nChange-Id: If53dcdaea0a48ef613e3097ab55d34f056160188\n'}, {'number': 2, 'created': '2013-07-17 19:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/ef23d462c470a984aae90a73eed9afa9e94a2836', 'message': 'Add more documentation\n\nMoved a good portion of README into the sphinx docs. Also started\nfleshing out descriptions of how to use things. Also, fix the sphinx\nconfig.\n\nChange-Id: If53dcdaea0a48ef613e3097ab55d34f056160188\n'}, {'number': 3, 'created': '2013-07-17 19:55:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/7c598002a6d3178f8c2f7ddaf0dbce568f742799', 'message': 'Add more documentation\n\nMoved a good portion of README into the sphinx docs. Also started\nfleshing out descriptions of how to use things. Also, fix the sphinx\nconfig.\n\nChange-Id: If53dcdaea0a48ef613e3097ab55d34f056160188\n'}, {'number': 4, 'created': '2013-07-17 22:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/0b5643bae3b2ebfb40c4a7dda24ffb1f5074e8ef', 'message': 'Add more documentation\n\nMoved a good portion of README into the sphinx docs. Also started\nfleshing out descriptions of how to use things. Also, fix the sphinx\nconfig.\n\nChange-Id: If53dcdaea0a48ef613e3097ab55d34f056160188\n'}, {'number': 5, 'created': '2013-07-22 02:55:08.000000000', 'files': ['doc/source/index.rst', 'README.rst', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/pbr/commit/904f79c867ac689df387f276b0a9c2afb02ddebf', 'message': 'Add more documentation\n\nMoved a good portion of README into the sphinx docs. Also started\nfleshing out descriptions of how to use things. Also, fix the sphinx\nconfig.\n\nChange-Id: If53dcdaea0a48ef613e3097ab55d34f056160188\n'}]",3,37553,904f79c867ac689df387f276b0a9c2afb02ddebf,15,5,5,2,,,0,"Add more documentation

Moved a good portion of README into the sphinx docs. Also started
fleshing out descriptions of how to use things. Also, fix the sphinx
config.

Change-Id: If53dcdaea0a48ef613e3097ab55d34f056160188
",git fetch https://review.opendev.org/openstack/pbr refs/changes/53/37553/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'README.rst']",2,47029270de13d63b18f2c6fd7595a18ffe5a71b4,file-globbing,,"`pbr` reads and then filters the `setup.cfg` data through a setup hook to fill in default values and provide more sensible behaviors, and then feeds the results in as the arguments to a call to `setup.py` - so the heavy lifting of handling python packaging needs is still being done by `setuptools`. Behaviors ========= What It Does ------------ PBR can and does do a bunch of things for you: * **Version**: Manage version number bad on git revisions and tags * **AUTHORS**: Generate AUTHORS file from git log * **ChangeLog**: Generate ChangeLog from git log * **Sphinx Autodoc**: Generate autodoc stub files for your whole module * **Requirements**: Store your dependencies in a pip requirements file * **long_description**: Use your README file as a long_description * **Smart find_packages**: Smartly find packages under your root package Version ^^^^^^^ Version strings will be inferred from git. If a given revision is tagged, that's the version. If it's not, and you don't provide a version, the version will be very similar to git describe. If you do, then we'll assume that's the version you are working towards, and will generate alpha version strings based on commits since last tag and the current git sha. AUTHORS and ChangeLog ^^^^^^^^^^^^^^^^^^^^^ Why keep an AUTHORS or a ChangeLog file, when git already has all of the information you need. AUTHORS generation supports filtering/combining based on a standard .mailmap file. Sphinx Autodoc ^^^^^^^^^^^^^^ Sphinx can produce auto documentation indexes based on signatures and docstrings of your project- but you have to give it index files to tell it to autodoc each module. That's kind of repetitive and boring. PBR will scan your project, find all of your modules, and generate all of the stub files for you. Sphinx documentation setups are altered to generate man pages by default. They also have several pieces of information that are known to setup.py injected into the sphinx config. Requirements ^^^^^^^^^^^^ You may not have noticed, but there are differences in how pip requirements.txt files work and how distutils wants to be told about requirements. The pip way is nicer, because it sure does make it easier to popuplate a virtualenv for testing, or to just install everything you need. Duplicating the information, though, is super lame. So PBR will let you keep requirements.txt format files around describing the requirements for your project, will parse them and split them up approprirately, and inject them into the install_requires and/or tests_require and/or dependency_links arguments to setup. Voila! long_description ^^^^^^^^^^^^^^^^ There is no need to maintain two long descriptions- and your README file is probably a good long_description. So we'll just inject the contents of your README.rst, README.txt or README file into your empty long_description. Yay for you. Usage ===== pbr requires a distribution to use distribute. Your distribution must include a distutils2-like setup.cfg file, and a minimal setup.py script. A simple sample can be found in pbr s own setup.cfg (it uses its own machinery to install itself):: [metadata] name = pbr author = OpenStack Foundation author-email = openstack-dev@lists.openstack.org summary = OpenStack's setup automation in a reuable form description-file = README license = Apache-2 classifier = Development Status :: 4 - Beta Environment :: Console Environment :: OpenStack Intended Audience :: Developers Intended Audience :: Information Technology License :: OSI Approved :: Apache Software License Operating System :: OS Independent Programming Language :: Python keywords = setup distutils [files] packages = oslo [hooks] setup-hooks = pbr.hooks.setup_hook The minimal setup.py should look something like this:: #!/usr/bin/env python from setuptools import setup setup( setup_requires=['pbr'], pbr=True, ) Note that it's important to specify `pbr=True` or else the pbr functionality will not be enabled. It should also work fine if additional arguments are passed to `setup()`, but it should be noted that they will be clobbered by any options in the setup.cfg file. ",185,125
openstack%2Ftripleo-ci~master~Ia4bf1152870ba1996171f5502f1f074f11ffd446,openstack/tripleo-ci,master,Ia4bf1152870ba1996171f5502f1f074f11ffd446,Rename CACHDIR to CACHEDIR,MERGED,2013-07-22 14:04:10.000000000,2013-07-22 19:40:21.000000000,2013-07-22 19:40:21.000000000,"[{'_account_id': 3}, {'_account_id': 1926}]","[{'number': 1, 'created': '2013-07-22 14:04:10.000000000', 'files': ['toci_functions.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2013457ca6edac60500178dab36fd36d9aa4566a', 'message': ""Rename CACHDIR to CACHEDIR\n\nLooks like it's just a typo.\n\nChange-Id: Ia4bf1152870ba1996171f5502f1f074f11ffd446\n""}]",0,38151,2013457ca6edac60500178dab36fd36d9aa4566a,4,2,1,1247,,,0,"Rename CACHDIR to CACHEDIR

Looks like it's just a typo.

Change-Id: Ia4bf1152870ba1996171f5502f1f074f11ffd446
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/51/38151/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_functions.sh'],1,2013457ca6edac60500178dab36fd36d9aa4566a,, CACHEDIR=$TOCI_CACHE_DIR/${1/[^\/]*\//} if [ ! -e $CACHEDIR ] ; then git clone https://github.com/$1.git $CACHEDIR pushd $CACHEDIR cp -r $CACHEDIR $TOCI_WORKING_DIR/${1/[^\/]*\//}, CACHDIR=$TOCI_CACHE_DIR/${1/[^\/]*\//} if [ ! -e $CACHDIR ] ; then git clone https://github.com/$1.git $CACHDIR pushd $CACHDIR cp -r $CACHDIR $TOCI_WORKING_DIR/${1/[^\/]*\//},5,5
openstack%2Ftripleo-ci~master~Iaa864e3f8adfae83be75e249882271c0058c72ae,openstack/tripleo-ci,master,Iaa864e3f8adfae83be75e249882271c0058c72ae,Add .gitreview file,MERGED,2013-07-22 14:03:51.000000000,2013-07-22 19:39:30.000000000,2013-07-22 19:39:30.000000000,"[{'_account_id': 3}, {'_account_id': 1926}]","[{'number': 1, 'created': '2013-07-22 14:03:51.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7c2cb0ca8bfb2241c08eb5412fb9e87bb7c87270', 'message': 'Add .gitreview file\n\nChange-Id: Iaa864e3f8adfae83be75e249882271c0058c72ae\n'}]",0,38150,7c2cb0ca8bfb2241c08eb5412fb9e87bb7c87270,4,2,1,1247,,,0,"Add .gitreview file

Change-Id: Iaa864e3f8adfae83be75e249882271c0058c72ae
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/50/38150/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,7c2cb0ca8bfb2241c08eb5412fb9e87bb7c87270,,[gerrit] host=review.openstack.org port=29418 project=openstack-infra/tripleo-ci.git ,,4,0
openstack%2Fpython-novaclient~master~I069b3c407e77cb6646eb52928b3208c1d49de1b5,openstack/python-novaclient,master,I069b3c407e77cb6646eb52928b3208c1d49de1b5,Fix disable service docstring,ABANDONED,2013-07-10 08:54:03.000000000,2013-07-22 19:38:05.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1653}]","[{'number': 1, 'created': '2013-07-10 08:54:03.000000000', 'files': ['novaclient/v1_1/services.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/e92272657c54371bd8b4a3a094162f7d62c27b95', 'message': 'Fix disable service docstring\n\ndocstring said enable not disable.\n\nChange-Id: I069b3c407e77cb6646eb52928b3208c1d49de1b5\n'}]",0,36412,e92272657c54371bd8b4a3a094162f7d62c27b95,4,3,1,1849,,,0,"Fix disable service docstring

docstring said enable not disable.

Change-Id: I069b3c407e77cb6646eb52928b3208c1d49de1b5
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/12/36412/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v1_1/services.py'],1,e92272657c54371bd8b4a3a094162f7d62c27b95,disble," """"""Disable the service specified by hostname and binary"""""""," """"""Enable the service specified by hostname and binary""""""",1,1
openstack%2Fcinder~master~Id59bf1963c6d35aae4baf6f49be17340982c205c,openstack/cinder,master,Id59bf1963c6d35aae4baf6f49be17340982c205c,Added incremental backup support to Ceph backup driver,MERGED,2013-07-01 22:22:43.000000000,2013-07-22 19:16:37.000000000,2013-07-22 19:16:37.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1107}, {'_account_id': 1207}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2583}, {'_account_id': 5044}, {'_account_id': 5997}, {'_account_id': 6737}, {'_account_id': 6743}]","[{'number': 1, 'created': '2013-07-01 22:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e2a157becf0fd31995ec9825f1e085756582b130', 'message': 'Added extensions to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nbackups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 2, 'created': '2013-07-02 14:42:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2b5ce7a5f6a90572767a6cd4dde490b0def44dd3', 'message': 'Added extensions to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nbackups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 3, 'created': '2013-07-02 15:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9beff59fa6f0e7cca3bd58b4787c610ccfb707e9', 'message': 'Added extensions to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nbackups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 4, 'created': '2013-07-03 14:48:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a0fcf7d9c65062e7f30971e803d362b1bdaa91c0', 'message': 'Added extensions to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nbackups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 5, 'created': '2013-07-04 17:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9c33f52af2faac1fe9a9e1a16ac761e7b197a8be', 'message': 'Added extensions to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 6, 'created': '2013-07-05 13:40:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1956a094a98f5369e13c2eb2c903bae75e90efcf', 'message': 'Added extensions to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 7, 'created': '2013-07-05 15:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7014552eb3a937ba04fe595307bb59d49a6e9218', 'message': 'Added extensions to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 8, 'created': '2013-07-05 15:47:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/97b982ff88c4ad0336777bdf5c6405227bbf9571', 'message': 'Added extensions to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 9, 'created': '2013-07-05 16:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/03fd2d964e1ec0ae672f3200da9844a8f45df181', 'message': 'Added extensions to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 10, 'created': '2013-07-09 12:03:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/89c8defe9c46b400c7c4dffdb030c5903235b79f', 'message': 'Added incremental backup support to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nAlso fixes bug 1198271\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 11, 'created': '2013-07-09 13:47:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cedf5fea6faa1befbace6bfd375ce6837da80756', 'message': 'Added incremental backup support to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nAlso fixes bug 1198271\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 12, 'created': '2013-07-10 16:43:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9919e1bd157c76e97ecdc0883cb76a0f3eccd1bc', 'message': 'Added incremental backup support to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nAlso fixes bug 1198271\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 13, 'created': '2013-07-11 17:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3d41a27740d55622677bc5923ee0013c35a39bed', 'message': 'Added incremental backup support to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 14, 'created': '2013-07-11 20:13:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f70851725686a47eb36cfcdf617cd3e316635bbe', 'message': 'Added incremental backup support to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 15, 'created': '2013-07-11 23:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f01ff6eb34ce72e894dd35440804e3a71d145d3d', 'message': 'Added incremental backup support to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 16, 'created': '2013-07-12 08:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e7ecb6c4c491712ec1b4da28e876c178f45bc9bb', 'message': 'Added incremental backup support to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 17, 'created': '2013-07-16 14:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a12ed1d1b18c52ae4187b552c7d11da3fbe29cd4', 'message': 'Added incremental backup support to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 18, 'created': '2013-07-17 12:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/84b3bf633e340306d229d0c00f433476e87f2554', 'message': 'Added incremental backup support to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 19, 'created': '2013-07-18 18:15:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fba27f9c2a01992e15705c35d4587adc211852b3', 'message': 'Added incremental backup support to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}, {'number': 20, 'created': '2013-07-18 20:24:40.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/tests/test_backup_ceph.py', 'etc/cinder/cinder.conf.sample', 'cinder/tests/backup/fake_rados.py', 'cinder/tests/test_rbd.py', 'cinder/exception.py', 'cinder/backup/drivers/ceph.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4796efe60d4e0cb0d2cbdf7f2ded3302b0670b3d', 'message': 'Added incremental backup support to Ceph backup driver\n\nThe Ceph backup driver is now capable of doing differential\nand incremental backups between or within Ceph clusters.\n\nImplements: blueprint cinder-backup-to-ceph\n\nChange-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c\n'}]",101,35216,4796efe60d4e0cb0d2cbdf7f2ded3302b0670b3d,86,11,20,6737,,,0,"Added incremental backup support to Ceph backup driver

The Ceph backup driver is now capable of doing differential
and incremental backups between or within Ceph clusters.

Implements: blueprint cinder-backup-to-ceph

Change-Id: Id59bf1963c6d35aae4baf6f49be17340982c205c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/16/35216/19 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_backup_ceph.py', 'cinder/volume/drivers/rbd.py', 'cinder/backup/api.py', 'cinder/backup/manager.py', 'etc/cinder/cinder.conf.sample', 'cinder/tests/backup/fake_rados.py', 'cinder/exception.py', 'cinder/backup/services/ceph.py']",8,e2a157becf0fd31995ec9825f1e085756582b130,bp/cinder-backup-to-ceph,"# Copyright 2013 Canonical Ltd. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Ceph Backup Service Implementation"""""" from cinder.db import base from cinder import exception from cinder.openstack.common import log as logging from cinder import units from cinder import utils import cinder.volume.drivers.rbd as rbddriver import eventlet import os from oslo.config import cfg import time try: import rados import rbd except ImportError: rados = None rbd = None LOG = logging.getLogger(__name__) service_opts = [ cfg.StrOpt('backup_ceph_conf', default='/etc/ceph/ceph.conf', help='Ceph config file to use.'), cfg.StrOpt('backup_ceph_user', default='cinder', help='the Ceph user to connect with'), cfg.StrOpt('backup_ceph_chunk_size', default=(units.MiB * 128), help='the chunk size in bytes that a backup will be broken ' 'into before transfer to backup store'), cfg.StrOpt('backup_ceph_pool', default='backups', help='the Ceph pool to backup to'), cfg.StrOpt('backup_ceph_stripe_unit', default=0, help='RBD stripe unit to use when creating a backup image'), cfg.StrOpt('backup_ceph_stripe_count', default=0, help='RBD stripe count to use when creating a backup image') ] CONF = cfg.CONF CONF.register_opts(service_opts) class CephBackupService(base.Base): """"""Backup up Cinder volumes to Ceph Object Store"""""" def __init__(self, context, db_driver=None): super(CephBackupService, self).__init__(db_driver) self.rbd = rbd self.rados = rados self.context = context self.chunk_size = CONF.backup_ceph_chunk_size if self._supports_stripingv2(): self.rbd_stripe_unit = int(CONF.backup_ceph_stripe_unit) self.rbd_stripe_count = int(CONF.backup_ceph_stripe_count) else: LOG.info(""rbd striping not supported - ignoring conf settings "" ""for rbd striping"") self.rbd_stripe_count = 0 self.rbd_stripe_unit = 0 self._ceph_backup_user = str(CONF.backup_ceph_user) self._ceph_backup_pool = str(CONF.backup_ceph_pool) self._ceph_backup_conf = str(CONF.backup_ceph_conf) def _try_execute(self, *command, **kwargs): return utils.execute(*command, **kwargs) def _ceph_args(self, user, conf): return ['--id', user, '--conf', conf] def _supports_layering(self): """""" Determine whether copy-on-write is supported by our version of librbd """""" return hasattr(self.rbd, 'RBD_FEATURE_LAYERING') def _supports_stripingv2(self): """""" Determine whether striping is supported by our version of librbd """""" return hasattr(self.rbd, 'RBD_FEATURE_STRIPINGV2') def _get_rbd_support(self): old_format = True features = 0 if self._supports_layering(): old_format = False features |= self.rbd.RBD_FEATURE_LAYERING if self._supports_stripingv2(): old_format = False features |= self.rbd.RBD_FEATURE_STRIPINGV2 return (old_format, features) def _connect_to_rados(self, pool=None): """"""Establish connection to the Ceph cluster"""""" client = self.rados.Rados(rados_id=self._ceph_backup_user, conffile=self._ceph_backup_conf) try: client.connect() pool_to_open = str(pool or self._ceph_backup_pool) ioctx = client.open_ioctx(pool_to_open) return client, ioctx except self.rados.Error: # shutdown cannot raise an exception client.shutdown() raise def _disconnect_from_rados(self, client, ioctx): """"""Terminate connection with the Ceph cluster"""""" # closing an ioctx cannot raise an exception ioctx.close() client.shutdown() def _get_backup_rbd_name(self, vol_name, backup_id): """"""Make sure we use a consistent format for backup names"""""" # ensure no unicode return str(""%s.backup.%s"" % (vol_name, backup_id)) def _transfer_data(self, src, dest, dest_name, length, src_is_rbd=False, dest_is_rbd=False): """""" Transfer data between files and/or rbds. Assume source and destination use standard Python IO interface unless stated to be RBD images in which case librbd interface is used. """""" src_adv = '' if not src_is_rbd: src_adv = 'NOT ' dest_adv = '' if not dest_is_rbd: dest_adv = 'NOT ' LOG.debug(""source is %san rbd, dest is %san rbd"" % (src_adv, dest_adv)) chunks = int(length / self.chunk_size) LOG.debug(""transferring %s chunks of %s bytes to '%s'"" % (chunks, self.chunk_size, dest_name)) for chunk in xrange(0, chunks): offset = chunk * self.chunk_size before = time.time() if src_is_rbd: data = src.read(offset, self.chunk_size) else: data = src.read(self.chunk_size) if dest_is_rbd: dest.write(data, offset) # note(dosaboy): librbd writes are synchronous so flush() will # have not effect. Also, flush only supported in more recent # versions of librbd. else: dest.write(data) dest.flush() delta = (time.time() - before) rate = (self.chunk_size / delta) / 1024 LOG.debug(""transferred chunk %s of %s (%dK/s)"" % (chunk, chunks, rate)) # yield to any other pending backups eventlet.sleep(0) rem = int(length % self.chunk_size) if rem: LOG.debug(""transferring remaining %s bytes"" % (rem)) offset = (length - rem) if src_is_rbd: data = src.read(offset, rem) else: data = src.read(rem) if dest_is_rbd: dest.write(data, offset) # note(dosaboy): librbd writes are synchronous so flush() will # have not effect. Also, flush only supported in more recent # versions of librbd. else: dest.write(data) dest.flush() # yield to any other pending backups eventlet.sleep(0) def _ceph_clusters_match(self, src_conn): """""" Returns True if src and destination clusters are the same. """""" # If we cannot get source fsid, assume not the same cluster if not hasattr(src_conn, 'get_fsid'): return False src_fsid = src_conn.get_fsid() with rbddriver.RADOSClient(self, self._ceph_backup_pool) as client: if hasattr(client.cluster, 'get_fsid'): dest_fsid = client.cluster.get_fsid() if src_fsid == dest_fsid: LOG.debug(""clusters are the same - %s"" % (src_fsid)) return True else: LOG.debug(""clusters are different - %s:%s"" % (src_fsid, dest_fsid)) return False def _full_backup(self, src_rbd, backup_name, backup_size): """""" Perform a full backup i.e. copy an entire volume (zeroes and all) to a new backup volume """""" # Only establish new connection if we are backing up to a different # cluster. with rbddriver.RADOSClient(self, self._ceph_backup_pool) as client: dest_rbd = self.rbd.Image(client.ioctx, backup_name) try: self._transfer_data(src_rbd, dest_rbd, backup_name, backup_size, dest_is_rbd=True, src_is_rbd=True) finally: dest_rbd.close() def _diff_backup(self, backup_name, src_rbd_name, src_pool, src_user=None, src_conf=None): """"""Create a differential export of an RBD image"""""" # NOTE(dosaboy): Need to be tolerant of clusters/clients that do # not support these operations since at the time of writing they # were very new. dest_ceph_args = self._ceph_args(self._ceph_backup_user, self._ceph_backup_conf) if all([src_user, src_conf]): src_ceph_args = self._ceph_args(src_user, src_conf) else: src_ceph_args = dest_ceph_args cmd = ['rbd', 'export-diff'] + src_ceph_args cmd += [str(""%s/%s"" % (src_pool, src_rbd_name)), '-'] out, err = self._try_execute(*cmd) cmd = ['rbd', 'import-diff'] + dest_ceph_args cmd += ['-', str(""%s/%s"" % (self._ceph_backup_pool, backup_name))] out, err = self._try_execute(*cmd, process_input=out) def _diff_restore(self, backup_name, dest_rbd_name, dest_pool, dest_user=None, dest_conf=None): """"""Restore RBD image from diff backup"""""" # NOTE(dosaboy): Need to be tolerant of clusters/clients that do # not support these operations since at the time of writing they # were very new. src_ceph_args = self._ceph_args(self._ceph_backup_user, self._ceph_backup_conf) if all([dest_user, dest_conf]): dest_ceph_args = self._ceph_args(dest_user, dest_conf) else: dest_ceph_args = dest_ceph_args cmd = ['rbd', 'export-diff'] + src_ceph_args cmd += [str(""%s/%s"" % (self._ceph_backup_pool, backup_name)), '-'] out, err = self._try_execute(*cmd) cmd = ['rbd', 'import-diff'] + dest_ceph_args cmd += ['-', str(""%s/%s"" % (dest_pool, dest_rbd_name))] out, err = self._try_execute(*cmd, process_input=out) def _create_backup_image_if_not_exists(self, name, size): """""" Create a base backup image if one does not already exist. We will use use this image to store our differential export(s) """""" old_format, features = self._get_rbd_support() with rbddriver.RADOSClient(self, self._ceph_backup_pool) as client: rbd_client = self.rbd.RBD() known_rbds = rbd_client.list(ioctx=client.ioctx) if name not in known_rbds: rbd_client.create(ioctx=client.ioctx, name=name, size=size, old_format=old_format, features=features, stripe_unit=self.rbd_stripe_unit, stripe_count=self.rbd_stripe_count) def _restore_rbd(self, volume_file, volume_name, backup_name, backup_size): """"""Restore RBD volume from RBD image"""""" LOG.debug(""restoring rbd from '%s'"" % (backup_name)) rbd_user = volume_file.rbd_user rbd_pool = volume_file.rbd_pool rbd_conf = volume_file.rbd_conf rbd_image = volume_file.rbd_image try: before = time.time() self._diff_restore(backup_name, volume_name, rbd_pool, rbd_user, rbd_conf) except Exception: LOG.exception(""differential backup failed, trying full backup"") before = time.time() self._full_backup(rbd_image, backup_name, backup_size) LOG.debug(""copy completed in %ss"" % (time.time() - before)) def _backup_rbd(self, volume_file, volume_name, backup_name, backup_size): """"""Create a backup from an RBD image"""""" LOG.debug(""copying rbd to '%s'"" % (backup_name)) rbd_user = volume_file.rbd_user rbd_pool = volume_file.rbd_pool rbd_conf = volume_file.rbd_conf rbd_image = volume_file.rbd_image # Create a base backup image onto which will save our diff exports (or # perform full copy if diff fails) self._create_backup_image_if_not_exists(backup_name, backup_size) try: before = time.time() self._diff_backup(backup_name, volume_name, rbd_pool, rbd_user, rbd_conf) except Exception: LOG.exception(""differential backup failed, trying full backup"") before = time.time() self._full_backup(rbd_image, backup_name, backup_size) LOG.debug(""copy completed in %ss"" % (time.time() - before)) def _file_is_rbd(self, volume_file): """"""Returns True if the volume_file is actually an RBD image"""""" return hasattr(volume_file, 'rbd_image') def _backup_volume_from_file(self, backup_name, volume_file, backup_size): """"""Backup a volume from file stream"""""" LOG.debug(""performing backup from file"") old_format, features = self._get_rbd_support() with rbddriver.RADOSClient(self, self._ceph_backup_pool) as client: self.rbd.RBD().create(ioctx=client.ioctx, name=backup_name, size=backup_size, old_format=old_format, features=features, stripe_unit=self.rbd_stripe_unit, stripe_count=self.rbd_stripe_count) dest_rbd = self.rbd.Image(client.ioctx, backup_name) try: self._transfer_data(volume_file, dest_rbd, backup_name, backup_size, dest_is_rbd=True) finally: dest_rbd.close() def backup(self, backup, volume_file): """"""Backup the given volume to Ceph object store"""""" backup_id = backup['id'] volume = self.db.volume_get(self.context, backup['volume_id']) backup_name = self._get_backup_rbd_name(volume['name'], backup_id) LOG.debug(""Starting backup of volume='%s' to rbd='%s'"" % (volume['name'], backup_name)) if int(volume['size']) == 0: raise exception.InvalidParameterValue(""need non-zero volume size"") else: backup_size = int(volume['size']) * units.GiB if volume_file: # If the source file is an RBD image we can do cool stuff if self._file_is_rbd(volume_file): self._backup_rbd(volume_file, volume['name'], backup_name, backup_size) else: # Otherwise it's a plain old copy self._backup_volume_from_file(backup_name, volume_file, backup_size) else: errmsg = (""No volume_file was provided so I cannot do requested "" ""backup (id=%s)"" % (backup_id)) raise exception.BackupVolumeInvalidType(errmsg) self.db.backup_update(self.context, backup['id'], {'container': self._ceph_backup_pool}) LOG.debug(_(""backup '%s' finished."") % (backup_id)) def _restore_volume_to_file(self, volume_file, vol_name, backup_name, backup_size): """"""Restore the given volume file from backup RBD"""""" with rbddriver.RADOSClient(self, self._ceph_backup_pool) as client: src_rbd = self.rbd.Image(client.ioctx, backup_name) try: self._transfer_data(src_rbd, volume_file, vol_name, backup_size, src_is_rbd=True, dest_is_rbd=False) finally: src_rbd.close() def restore(self, backup, volume_id, volume_file): """"""Restore the given volume backup from Ceph object store"""""" volume_id = backup['volume_id'] volume = self.db.volume_get(self.context, volume_id) backup_name = self._get_backup_rbd_name(volume['name'], backup['id']) LOG.debug('starting backup restore from Ceph backup=%s ' 'to volume=%s' % (backup['id'], volume['name'])) # Ensure we are at the beginning of the volume volume_file.seek(0) backup_size = int(volume['size']) * units.GiB # If the source file is an RBD image we can do cool stuff if self._file_is_rbd(volume_file): self._restore_rbd(volume_file, volume['name'], backup_name, backup_size) else: # Otherwise it's a plain old copy self._restore_volume_to_file(volume_file, volume['name'], backup_name, backup_size) # Be tolerant to IO implementations that do not support fileno() try: fileno = volume_file.fileno() except IOError: LOG.info(""volume_file does not support fileno() so skipping "" ""fsync()"") else: os.fsync(fileno) LOG.debug('restore %s to %s finished.' % (backup['id'], volume_id)) def delete(self, backup): """"""Delete the given backup from Ceph object store"""""" backup_id = backup['id'] volume_id = backup['volume_id'] volume = self.db.volume_get(self.context, volume_id) backup_name = self._get_backup_rbd_name(volume['name'], backup_id) LOG.debug('delete started for backup=%s', backup['id']) try: with rbddriver.RADOSClient(self) as client: self.rbd.RBD().remove(client.ioctx, backup_name) except self.rbd.ImageNotFound: LOG.warning(""rbd image '%s' not found but continuing anyway so "" ""that db entry can be removed"" % (backup_name)) LOG.debug(_(""delete '%s' finished"") % (backup_id)) def get_backup_service(context): return CephBackupService(context) ",,854,14
openstack%2Ftempest~master~I787cbc942989b50c57cbc22e4bf1e4956aa64df6,openstack/tempest,master,I787cbc942989b50c57cbc22e4bf1e4956aa64df6,update hacking to 0.6,MERGED,2013-07-19 18:32:54.000000000,2013-07-22 18:46:15.000000000,2013-07-22 18:46:15.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-19 18:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/417a4639f7bffbb03b8e08bef8a51a0ccab98e07', 'message': 'update hacking to 0.6\n\nallow hacking 0.6 to enforce new rules in tempest, especially the\nmissing license header one.\n\nChange-Id: I787cbc942989b50c57cbc22e4bf1e4956aa64df6\n'}, {'number': 2, 'created': '2013-07-22 12:08:38.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/tempest/commit/9f3b0c972f9ce46e0daaca98bbf6055ddaed2312', 'message': 'update hacking to 0.6\n\nallow hacking 0.6 to enforce new rules in tempest, especially the\nmissing license header one.\n\nChange-Id: I787cbc942989b50c57cbc22e4bf1e4956aa64df6\n'}]",1,37952,9f3b0c972f9ce46e0daaca98bbf6055ddaed2312,11,5,2,2750,,,0,"update hacking to 0.6

allow hacking 0.6 to enforce new rules in tempest, especially the
missing license header one.

Change-Id: I787cbc942989b50c57cbc22e4bf1e4956aa64df6
",git fetch https://review.opendev.org/openstack/tempest refs/changes/52/37952/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,417a4639f7bffbb03b8e08bef8a51a0ccab98e07,hacking_0_6,"hacking>=0.5.3,<0.7","hacking>=0.5.3,<0.6",1,2
openstack%2Ftempest~master~I34765932ba93cd6d7f0df23ab97d9483eb459978,openstack/tempest,master,I34765932ba93cd6d7f0df23ab97d9483eb459978,Add global statistic for stress tests,MERGED,2013-07-12 12:39:00.000000000,2013-07-22 18:27:47.000000000,2013-07-22 18:27:47.000000000,"[{'_account_id': 3}, {'_account_id': 1119}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 5997}, {'_account_id': 6743}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-07-12 12:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e59200833051ff380841ff74c501fcd12acc46b2', 'message': 'Add global statistic for stress tests\n\nAdds shared memory between all stress action processes and the driver in order\nto generate a global statistic. A new class introduced ""process_wapper""\nto fill those vaules and to count how often a certain action was\nexecuted. With this it is possbile to terminate an action if the\nspecifited number of execution is reached.\n\nThis commit is dependent on https://review.openstack.org/#/c/36752 and WIP.\n\nBlueprint merge-os-stress\n\nChange-Id: I34765932ba93cd6d7f0df23ab97d9483eb459978\n'}, {'number': 2, 'created': '2013-07-15 08:17:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/60218859329d2ea09f8325d0daa865f1e88c6c2b', 'message': 'Add global statistic for stress tests\n\nAdds shared memory between all stress action processes and the driver in order\nto generate a global statistic. A new command line option is introduced\nwith this it is possbile to terminate an action if the\nspecifited number of execution is reached.\n\nThis commit is dependent on https://review.openstack.org/#/c/36752\n\nImplements: blueprint stress-tests\n\nConflicts:\n\ttempest/stress/actions/create_destroy_server.py\n\ttempest/stress/actions/volume_create_delete.py\n\ttempest/stress/driver.py\n\nChange-Id: I34765932ba93cd6d7f0df23ab97d9483eb459978\n'}, {'number': 3, 'created': '2013-07-16 08:30:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c77b7c7b239f660e53520ae3ba889729c3404475', 'message': 'Add global statistic for stress tests\n\nAdds shared memory between all stress action processes and the driver in order\nto generate a global statistic. A new command line option is introduced\nwith this it is possbile to terminate an action if the\nspecifited number of execution is reached.\n\nThis commit is dependent on https://review.openstack.org/#/c/36752\n\nImplements: blueprint stress-tests\n\nConflicts:\n\ttempest/stress/actions/create_destroy_server.py\n\ttempest/stress/actions/volume_create_delete.py\n\ttempest/stress/driver.py\n\nChange-Id: I34765932ba93cd6d7f0df23ab97d9483eb459978\n'}, {'number': 4, 'created': '2013-07-17 05:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e39cc893ef5492238caf75ad0c4d917bab0137f7', 'message': 'Add global statistic for stress tests\n\nAdds shared memory between all stress action processes and the driver in order\nto generate a global statistic. A new command line option is introduced\nwith this it is possbile to terminate an action if the\nspecifited number of execution is reached.\n\nThis commit is dependent on https://review.openstack.org/#/c/36752\n\nImplements: blueprint stress-tests\n\nConflicts:\n\ttempest/stress/actions/create_destroy_server.py\n\ttempest/stress/actions/volume_create_delete.py\n\ttempest/stress/driver.py\n\ttempest/stress/run_stress.py\n\nChange-Id: I34765932ba93cd6d7f0df23ab97d9483eb459978\n'}, {'number': 5, 'created': '2013-07-18 06:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/756705aee58f9a49f59e9f65aa42d732406d1088', 'message': 'Add global statistic for stress tests\n\nAdds shared memory between all stress action processes and the driver in order\nto generate a global statistic. A new command line option is introduced\nwith this it is possbile to terminate an action if the\nspecifited number of execution is reached.\n\nImplements: blueprint stress-tests\n\nConflicts:\ntempest/stress/actions/create_destroy_server.py\ntempest/stress/actions/volume_create_delete.py\ntempest/stress/driver.py\ntempest/stress/run_stress.py\n\nChange-Id: I34765932ba93cd6d7f0df23ab97d9483eb459978\n'}, {'number': 6, 'created': '2013-07-22 07:30:34.000000000', 'files': ['tempest/stress/run_stress.py', 'tempest/stress/driver.py', 'tempest/stress/stressaction.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/69d3bea192d3312ab13bcfe0c7043b7b9fc17b61', 'message': 'Add global statistic for stress tests\n\nAdds shared memory between all stress action processes and the driver in order\nto generate a global statistic. A new command line option is introduced\nwith this it is possbile to terminate an action if the\nspecifited number of execution is reached.\n\nImplements: blueprint stress-tests\n\nConflicts:\ntempest/stress/actions/create_destroy_server.py\ntempest/stress/actions/volume_create_delete.py\ntempest/stress/driver.py\ntempest/stress/run_stress.py\n\nChange-Id: I34765932ba93cd6d7f0df23ab97d9483eb459978\n'}]",10,36820,69d3bea192d3312ab13bcfe0c7043b7b9fc17b61,27,8,6,7872,,,0,"Add global statistic for stress tests

Adds shared memory between all stress action processes and the driver in order
to generate a global statistic. A new command line option is introduced
with this it is possbile to terminate an action if the
specifited number of execution is reached.

Implements: blueprint stress-tests

Conflicts:
tempest/stress/actions/create_destroy_server.py
tempest/stress/actions/volume_create_delete.py
tempest/stress/driver.py
tempest/stress/run_stress.py

Change-Id: I34765932ba93cd6d7f0df23ab97d9483eb459978
",git fetch https://review.opendev.org/openstack/tempest refs/changes/20/36820/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/stress/run_stress.py', 'tempest/stress/process_wrapper.py', 'tempest/stress/actions/volume_create_delete.py', 'tempest/stress/driver.py', 'tempest/stress/actions/create_destroy_server.py']",5,e59200833051ff380841ff74c501fcd12acc46b2,bp/stress-tests," name = rand_name(""instance"") self.logger.info(""creating %s"" % name) resp, server = self.manager.servers_client.create_server( name, image, flavor) server_id = server['id'] assert(resp.status == 202) self.manager.servers_client.wait_for_server_status(server_id, 'ACTIVE') self.logger.info(""created %s"" % server_id) self.logger.info(""deleting %s"" % name) resp, _ = self.manager.servers_client.delete_server(server_id) assert(resp.status == 204) self.manager.servers_client.wait_for_server_termination(server_id) self.logger.info(""deleted %s"" % server_id)"," while True: name = rand_name(""instance"") self.logger.info(""creating %s"" % name) resp, server = self.manager.servers_client.create_server( name, image, flavor) server_id = server['id'] assert(resp.status == 202) self.manager.servers_client.wait_for_server_status(server_id, 'ACTIVE') self.logger.info(""created %s"" % server_id) self.logger.info(""deleting %s"" % name) resp, _ = self.manager.servers_client.delete_server(server_id) assert(resp.status == 204) self.manager.servers_client.wait_for_server_termination(server_id) self.logger.info(""deleted %s"" % server_id)",113,54
openstack%2Fheat~master~Ifd50dbb993dd0cb177b0e16652c6ef17d12cd2e5,openstack/heat,master,Ifd50dbb993dd0cb177b0e16652c6ef17d12cd2e5,Add `default` attribute in hot parameter definition,MERGED,2013-07-22 04:28:29.000000000,2013-07-22 18:27:40.000000000,2013-07-22 18:27:40.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 6488}, {'_account_id': 7193}, {'_account_id': 7676}]","[{'number': 1, 'created': '2013-07-22 04:28:29.000000000', 'files': ['heat/engine/hot.py', 'heat/tests/test_hot.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/239c38307b75d601c71cb676340c61aa2c43f1de', 'message': ""Add `default` attribute in hot parameter definition\n\nSo `default' in hot is translated to `Default' in cfn\n\nChange-Id: Ifd50dbb993dd0cb177b0e16652c6ef17d12cd2e5\nFixes: bug #1199311\n""}]",0,38099,239c38307b75d601c71cb676340c61aa2c43f1de,8,5,1,7761,,,0,"Add `default` attribute in hot parameter definition

So `default' in hot is translated to `Default' in cfn

Change-Id: Ifd50dbb993dd0cb177b0e16652c6ef17d12cd2e5
Fixes: bug #1199311
",git fetch https://review.opendev.org/openstack/heat refs/changes/99/38099/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/hot.py', 'heat/tests/test_hot.py']",2,239c38307b75d601c71cb676340c61aa2c43f1de,bug/1199311," default: boo expected = {'param1': {'Description': 'foo', 'Type': 'String', 'Default': 'boo'}}"," expected = {'param1': {'Description': 'foo', 'Type': 'String'}}",5,1
openstack%2Fheat~master~I01d9b44c1681142ef91fd91f678e173239ae6c98,openstack/heat,master,I01d9b44c1681142ef91fd91f678e173239ae6c98,Add missing Aapche 2.0 license headers (H102),MERGED,2013-07-19 21:10:33.000000000,2013-07-22 18:20:59.000000000,2013-07-22 18:20:58.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6488}, {'_account_id': 7676}]","[{'number': 1, 'created': '2013-07-19 21:10:33.000000000', 'files': ['heat/cloudinit/loguserdata.py', 'heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py', 'heat/db/sqlalchemy/manage.py', 'heat/cloudinit/part_handler.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/234a1f0f2e9133d610848da4e226dde7ae794388', 'message': 'Add missing Aapche 2.0 license headers (H102)\n\nSatisfy Hacking check of Hacking 0.6 or newer.\n\nChange-Id: I01d9b44c1681142ef91fd91f678e173239ae6c98\n'}]",0,37980,234a1f0f2e9133d610848da4e226dde7ae794388,7,4,1,6593,,,0,"Add missing Aapche 2.0 license headers (H102)

Satisfy Hacking check of Hacking 0.6 or newer.

Change-Id: I01d9b44c1681142ef91fd91f678e173239ae6c98
",git fetch https://review.opendev.org/openstack/heat refs/changes/80/37980/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/cloudinit/loguserdata.py', 'heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py', 'heat/cloudinit/part_handler.py', 'heat/db/sqlalchemy/manage.py']",4,234a1f0f2e9133d610848da4e226dde7ae794388,H102," # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ",,51,0
openstack%2Fpython-keystoneclient~master~I79826da6951b72ed61f25553020574063f4b181a,openstack/python-keystoneclient,master,I79826da6951b72ed61f25553020574063f4b181a,Pre-fetch pki certs to avoid startup ERRORs.,ABANDONED,2013-06-10 16:33:57.000000000,2013-07-22 17:59:10.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 360}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-06-10 16:33:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/2a6998505fc2b645dd01ac675f59977b8258eb75', 'message': 'Pre-fetch pki certs to avoid startup ERRORs.\n\nUpdates the auth_token middelware so that it pre-fetches the\nrequired PKI certificates before trying to verify a signed\ncertificate. This avoids logging some really unsightly log ERROR\nmessages in all of the various openstack service log files\nwhen using keystone w/ PKI.\n\nFixes LP Bug #1189539.\n\nChange-Id: I79826da6951b72ed61f25553020574063f4b181a\n'}, {'number': 2, 'created': '2013-06-10 16:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/fb09b253bea8fde63f2f8e7a849be8b76934253b', 'message': 'Pre-fetch pki certs to avoid startup ERRORs.\n\nUpdates the auth_token middelware so that it pre-fetches the\nrequired PKI certificates before trying to verify a signed\ncertificate. This avoids logging some really unsightly log ERROR\nmessages in all of the various openstack service log files\nwhen using keystone w/ PKI.\n\nFixes LP Bug #1189539.\n\nChange-Id: I79826da6951b72ed61f25553020574063f4b181a\n'}, {'number': 3, 'created': '2013-06-12 13:14:56.000000000', 'files': ['keystoneclient/middleware/auth_token.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/9eb36a6b0e1e905d10b41bf592ada9b92b79b714', 'message': 'Pre-fetch pki certs to avoid startup ERRORs.\n\nUpdates the auth_token middelware so that it pre-fetches the\nrequired PKI certificates before trying to verify a signed\ncertificate. This avoids logging some really unsightly log ERROR\nmessages in all of the various openstack service log files\nwhen using keystone w/ PKI.\n\nFixes LP Bug #1189539.\n\nChange-Id: I79826da6951b72ed61f25553020574063f4b181a\n'}]",9,32433,9eb36a6b0e1e905d10b41bf592ada9b92b79b714,23,6,3,360,,,0,"Pre-fetch pki certs to avoid startup ERRORs.

Updates the auth_token middelware so that it pre-fetches the
required PKI certificates before trying to verify a signed
certificate. This avoids logging some really unsightly log ERROR
messages in all of the various openstack service log files
when using keystone w/ PKI.

Fixes LP Bug #1189539.

Change-Id: I79826da6951b72ed61f25553020574063f4b181a
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/33/32433/2 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/middleware/auth_token.py'],1,2a6998505fc2b645dd01ac675f59977b8258eb75,bug/1189539, #NOTE(dprince): pre-fetch certs to avoid error messages in on startup if not os.path.exists(self.signing_cert_file_name): self.fetch_signing_cert() if not os.path.exists(self.ca_file_name): self.fetch_ca_cert() ,,7,0
openstack%2Fnova~master~Ie29dd090075915a4065ee395b4e50fc178f72f3b,openstack/nova,master,Ie29dd090075915a4065ee395b4e50fc178f72f3b,Code dedup in tests for server._action_rebuild,MERGED,2013-06-26 14:49:35.000000000,2013-07-22 17:52:12.000000000,2013-07-22 17:52:10.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 6172}, {'_account_id': 6938}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7727}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-06-26 14:49:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/858ba654b7111d968ba727d9bab3c94d23291e8a', 'message': 'Code dedup in tests for server._action_rebuild\n\nExterned common parts to setUp()\n\nbp api-compute-servers-tests\n\nChange-Id: Ie29dd090075915a4065ee395b4e50fc178f72f3b\n'}, {'number': 2, 'created': '2013-06-27 07:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bab38d3625ca5c46bdff6043cf3405c46a35864a', 'message': 'Code dedup in tests for server._action_rebuild\n\nExterned common parts to setUp()\n\nbp api-compute-servers-tests\n\nChange-Id: Ie29dd090075915a4065ee395b4e50fc178f72f3b\n'}, {'number': 3, 'created': '2013-06-27 11:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a99bf8c46eb80b80e019a2c711642ccd1502c0a5', 'message': 'Code dedup in tests for server._action_rebuild\n\nExterned common parts to setUp()\n\nbp api-compute-servers-tests\n\nChange-Id: Ie29dd090075915a4065ee395b4e50fc178f72f3b\n'}, {'number': 4, 'created': '2013-06-27 12:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/75a7b9139b618b4d3ed804a66ef972ebbaaa65d1', 'message': 'Code dedup in tests for server._action_rebuild\n\nExterned common parts to setUp()\n\nbp api-compute-servers-tests\n\nChange-Id: Ie29dd090075915a4065ee395b4e50fc178f72f3b\n'}, {'number': 5, 'created': '2013-07-01 07:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f87df983bd7c0d355e3d62ac2028f8955e3147b0', 'message': 'Code dedup in tests for server._action_rebuild\n\nExterned common parts to setUp()\n\nbp api-compute-servers-tests\n\nChange-Id: Ie29dd090075915a4065ee395b4e50fc178f72f3b\n'}, {'number': 6, 'created': '2013-07-01 07:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0371af1d921cb8741d20b90eb92655dabcd766b', 'message': 'Code dedup in tests for server._action_rebuild\n\nExterned common parts to setUp()\n\nbp api-compute-servers-tests\n\nChange-Id: Ie29dd090075915a4065ee395b4e50fc178f72f3b\n'}, {'number': 7, 'created': '2013-07-03 10:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d76970de3fdb5ed5e96db61774789126b6271965', 'message': 'Code dedup in tests for server._action_rebuild\n\nExterned common parts to setUp()\n\nbp nova-tests-code-duplication\n\nChange-Id: Ie29dd090075915a4065ee395b4e50fc178f72f3b\n'}, {'number': 8, 'created': '2013-07-09 09:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f12f10756298714e313175318bad2a93563a528', 'message': 'Code dedup in tests for server._action_rebuild\n\nExterned common parts to setUp()\n\nbp nova-tests-code-duplication\n\nChange-Id: Ie29dd090075915a4065ee395b4e50fc178f72f3b\n'}, {'number': 9, 'created': '2013-07-16 07:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b622aaec385262717d429ca57b7c5e7b4243637', 'message': 'Code dedup in tests for server._action_rebuild\n\nExterned common parts to setUp():\n- request body\n- request object\n- test image UUID\n- test image URL\nThese parts were equal in the most part of the methods.\n\nbp nova-tests-code-duplication\n\nChange-Id: Ie29dd090075915a4065ee395b4e50fc178f72f3b\n'}, {'number': 10, 'created': '2013-07-16 10:19:12.000000000', 'files': ['nova/tests/api/openstack/compute/test_servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4a24d140654db9ad769c971b3b879b462dc47616', 'message': 'Code dedup in tests for server._action_rebuild\n\nExterned common parts to setUp():\n- request body\n- request object\n- test image UUID\n- test image URL\nThese parts were equal in the most part of the methods.\n\nbp nova-tests-code-duplication\n\nChange-Id: Ie29dd090075915a4065ee395b4e50fc178f72f3b\n'}]",5,34556,4a24d140654db9ad769c971b3b879b462dc47616,43,10,10,7249,,,0,"Code dedup in tests for server._action_rebuild

Externed common parts to setUp():
- request body
- request object
- test image UUID
- test image URL
These parts were equal in the most part of the methods.

bp nova-tests-code-duplication

Change-Id: Ie29dd090075915a4065ee395b4e50fc178f72f3b
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/34556/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/openstack/compute/test_servers.py'],1,858ba654b7111d968ba727d9bab3c94d23291e8a,bp/api-compute-servers-tests," image_uuid = '76fa36fc-c930-4bf3-8c8a-ea2a2420deb6' image_href = 'http://localhost/v2/fake/images/%s' % image_uuid body = { 'rebuild': { 'name': 'new_name', 'imageRef': image_href, 'metadata': { 'open': 'stack', }, 'personality': [ { ""path"": ""/etc/banner.txt"", ""contents"": ""MQ=="", }, ], }, } req = fakes.HTTPRequest.blank('/v2/fake/servers/a/action') self.stubs.Set(db, 'instance_get_by_uuid', fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) self.req.method = 'POST' self.req.headers[""content-type""] = ""application/json"" self.body['rebuild']['accessIPv4'] = 'bad_format' self.body['rebuild']['accessIPv6'] = 'fead::1234' self.body['rebuild']['metadata']['hello'] = 'world' self.req.body = jsonutils.dumps(self.body) self.req, FAKE_UUID, self.body) self.body['rebuild']['accessIPv4'] = '0.0.0.0' self.body['rebuild']['accessIPv6'] = 'fead::1234' self.body['rebuild']['metadata'][''] = 'world' self.req.body = jsonutils.dumps(self.body) self.req, FAKE_UUID, self.body) self.body['rebuild']['accessIPv4'] = '0.0.0.0' self.body['rebuild']['accessIPv6'] = 'fead::1234' self.body['rebuild']['metadata'][('a' * 260)] = 'world' self.req.body = jsonutils.dumps(self.body) self.controller._action_rebuild, self.req, FAKE_UUID, self.body) self.body['rebuild']['accessIPv4'] = '0.0.0.0' self.body['rebuild']['accessIPv6'] = 'fead::1234' self.body['rebuild']['metadata']['key1'] = ('a' * 260) self.req.body = jsonutils.dumps(self.body) self.controller._action_rebuild, self.req, FAKE_UUID, self.body) self.req.body = jsonutils.dumps(self.body) self.req, FAKE_UUID, self.body) self.req.body = jsonutils.dumps(self.body) self.controller._action_rebuild, self.req, FAKE_UUID, self.body) self.req.body = jsonutils.dumps(self.body) self.controller._action_rebuild, self.req, FAKE_UUID, self.body) self.req.body = jsonutils.dumps(self.body) self.controller._action_rebuild, self.req, FAKE_UUID, self.body) self.body['rebuild']['accessIPv4'] = '1.2.3.4' self.body['rebuild']['accessIPv6'] = 'bad_format' self.body['rebuild']['metadata']['hello'] = 'world' self.req.body = jsonutils.dumps(self.body) self.req.headers[""content-type""] = ""application/json"" self.req, FAKE_UUID, self.body)"," self.stubs.Set(db, 'instance_get_by_uuid', fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) image_uuid = '76fa36fc-c930-4bf3-8c8a-ea2a2420deb6' image_href = 'http://localhost/v2/fake/images/%s' % image_uuid access_ipv4 = 'bad_format' access_ipv6 = 'fead::1234' body = { 'rebuild': { 'name': 'new_name', 'imageRef': image_href, 'accessIPv4': access_ipv4, 'accessIPv6': access_ipv6, 'metadata': { 'hello': 'world', 'open': 'stack', }, 'personality': [ { ""path"": ""/etc/banner.txt"", ""contents"": ""MQ=="", }, ], }, } req = fakes.HTTPRequest.blank('/v2/fake/servers/a/action') req.method = 'POST' req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" req, FAKE_UUID, body) self.stubs.Set(db, 'instance_get_by_uuid', fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) # proper local hrefs must start with 'http://localhost/v2/' image_uuid = '76fa36fc-c930-4bf3-8c8a-ea2a2420deb6' image_href = 'http://localhost/v2/fake/images/%s' % image_uuid access_ipv4 = '0.0.0.0' access_ipv6 = 'fead::1234' body = { 'rebuild': { 'name': 'new_name', 'imageRef': image_href, 'accessIPv4': access_ipv4, 'accessIPv6': access_ipv6, 'metadata': { '': 'world', 'open': 'stack', }, 'personality': [ { ""path"": ""/etc/banner.txt"", ""contents"": ""MQ=="", }, ], }, } req = fakes.HTTPRequest.blank('/v2/fake/servers/a/action') req.method = 'POST' req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" req, FAKE_UUID, body) self.stubs.Set(db, 'instance_get_by_uuid', fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) # proper local hrefs must start with 'http://localhost/v2/' image_uuid = '76fa36fc-c930-4bf3-8c8a-ea2a2420deb6' image_href = 'http://localhost/v2/fake/images/%s' % image_uuid access_ipv4 = '0.0.0.0' access_ipv6 = 'fead::1234' body = { 'rebuild': { 'name': 'new_name', 'imageRef': image_href, 'accessIPv4': access_ipv4, 'accessIPv6': access_ipv6, 'metadata': { ('a' * 260): 'world', 'open': 'stack', }, 'personality': [ { ""path"": ""/etc/banner.txt"", ""contents"": ""MQ=="", }, ], }, } req = fakes.HTTPRequest.blank('/v2/fake/servers/a/action') req.method = 'POST' req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" self.controller._action_rebuild, req, FAKE_UUID, body) self.stubs.Set(db, 'instance_get_by_uuid', fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) # proper local hrefs must start with 'http://localhost/v2/' image_uuid = '76fa36fc-c930-4bf3-8c8a-ea2a2420deb6' image_href = 'http://localhost/v2/fake/images/%s' % image_uuid access_ipv4 = '0.0.0.0' access_ipv6 = 'fead::1234' body = { 'rebuild': { 'name': 'new_name', 'imageRef': image_href, 'accessIPv4': access_ipv4, 'accessIPv6': access_ipv6, 'metadata': { 'key1': ('a' * 260), 'open': 'stack', }, 'personality': [ { ""path"": ""/etc/banner.txt"", ""contents"": ""MQ=="", }, ], }, } req = fakes.HTTPRequest.blank('/v2/fake/servers/a/action') req.method = 'POST' req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" self.controller._action_rebuild, req, FAKE_UUID, body) self.stubs.Set(db, 'instance_get_by_uuid', fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) image_uuid = '76fa36fc-c930-4bf3-8c8a-ea2a2420deb6' image_href = 'http://localhost/v2/fake/images/%s' % image_uuid body = { 'rebuild': { 'name': 'new_name', 'imageRef': image_href, }, } req = fakes.HTTPRequest.blank('/v2/fake/servers/a/action') req.method = 'POST' req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" req, FAKE_UUID, body) self.stubs.Set(db, 'instance_get_by_uuid', fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) image_uuid = '76fa36fc-c930-4bf3-8c8a-ea2a2420deb6' image_href = 'http://localhost/v2/fake/images/%s' % image_uuid body = { 'rebuild': { 'name': 'new_name', 'imageRef': image_href, }, } req = fakes.HTTPRequest.blank('/v2/fake/servers/a/action') req.method = 'POST' req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" self.controller._action_rebuild, req, FAKE_UUID, body) self.stubs.Set(db, 'instance_get_by_uuid', fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) image_uuid = '76fa36fc-c930-4bf3-8c8a-ea2a2420deb6' image_href = 'http://localhost/v2/fake/images/%s' % image_uuid body = { 'rebuild': { 'name': 'new_name', 'imageRef': image_href, }, } req = fakes.HTTPRequest.blank('/v2/fake/servers/a/action') req.method = 'POST' req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" self.controller._action_rebuild, req, FAKE_UUID, body) self.stubs.Set(db, 'instance_get_by_uuid', fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) image_uuid = '76fa36fc-c930-4bf3-8c8a-ea2a2420deb6' image_href = 'http://localhost/v2/fake/images/%s' % image_uuid body = { 'rebuild': { 'name': 'new_name', 'imageRef': image_href, }, } req = fakes.HTTPRequest.blank('/v2/fake/servers/a/action') req.method = 'POST' req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" self.controller._action_rebuild, req, FAKE_UUID, body) self.stubs.Set(db, 'instance_get_by_uuid', fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) image_uuid = '76fa36fc-c930-4bf3-8c8a-ea2a2420deb6' image_href = 'http://localhost/v2/fake/images/%s' % image_uuid access_ipv4 = '1.2.3.4' access_ipv6 = 'bad_format' body = { 'rebuild': { 'name': 'new_name', 'imageRef': image_href, 'accessIPv4': access_ipv4, 'accessIPv6': access_ipv6, 'metadata': { 'hello': 'world', 'open': 'stack', }, 'personality': [ { ""path"": ""/etc/banner.txt"", ""contents"": ""MQ=="", }, ], }, } req = fakes.HTTPRequest.blank('/v2/fake/servers/a/action') req.method = 'POST' req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" req, FAKE_UUID, body)",58,218
openstack%2Fnova~master~I985232fa0a9b2d5b73034047b06138a8a3d7e390,openstack/nova,master,I985232fa0a9b2d5b73034047b06138a8a3d7e390,Moved tests for server._action_rebuild,MERGED,2013-06-26 12:38:04.000000000,2013-07-22 17:48:32.000000000,2013-07-22 17:48:30.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 6172}, {'_account_id': 6938}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7727}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-06-26 12:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3b5d7a145d60475aefc3c962b72737d5208db2eb', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp api-compute-servers-tests\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 2, 'created': '2013-06-26 12:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9884229f076688e53fd30a3e6b973c661f0b642', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp api-compute-servers-tests\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 3, 'created': '2013-06-26 14:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a2f26a7b180d97adbb9dcb34f782dad43e4bf4a', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp api-compute-servers-tests\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 4, 'created': '2013-06-27 07:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2df4845f491d5f29e240e3e26a96a448df1cc061', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp api-compute-servers-tests\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 5, 'created': '2013-06-27 08:20:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd7cf61200a4aee12f440699115aca11a3d7a03e', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp api-compute-servers-tests\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 6, 'created': '2013-06-27 11:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33e9a81441e2253f15b955857c616ad0ea834a2d', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp api-compute-servers-tests\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 7, 'created': '2013-06-27 12:39:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7821cc48b18ada6e7dfa3a5ed2486c73d357a010', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp api-compute-servers-tests\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 8, 'created': '2013-06-27 13:52:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d22af844f806505f870b2c845069a92eac4e31f6', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp api-compute-servers-tests\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 9, 'created': '2013-07-01 07:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1715099d44db898d76c791e4cebe4912f5a79488', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp api-compute-servers-tests\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 10, 'created': '2013-07-01 07:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84ef34f4689e0eae137df5bb0f13caade3d67651', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp api-compute-servers-tests\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 11, 'created': '2013-07-01 07:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39fa663f215ee95730c3ad00207337dd16d4db1a', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp api-compute-servers-tests\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 12, 'created': '2013-07-03 10:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/446711efd08edde3830e9f5cf9d5c25a51fa7cbf', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp nova-tests-code-duplication\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 13, 'created': '2013-07-09 07:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e940a85f70bd6674e9ec53d9ba47d2067f9c9bb8', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp nova-tests-code-duplication\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 14, 'created': '2013-07-09 09:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b07c4c5a1ecb11070ce2a0d90cda594b4db333cc', 'message': 'Moved tests for server._action_rebuild\n\n- move tests to separate class\n\nbp nova-tests-code-duplication\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 15, 'created': '2013-07-16 07:34:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e40facbf635de8409e39af17258c88627622b6f', 'message': 'Moved tests for server._action_rebuild\n\nMove tests to separate class as a preparation for code\ndeduplication.\n\nThis work continues in https://review.openstack.org/34556\n\nbp nova-tests-code-duplication\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}, {'number': 16, 'created': '2013-07-16 10:19:10.000000000', 'files': ['nova/tests/api/openstack/compute/test_servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6b12076d4a8e4a3da82297760becbd0105260e46', 'message': 'Moved tests for server._action_rebuild\n\nMove tests to separate class as a preparation for code\ndeduplication.\n\nThis work continues in https://review.openstack.org/34556\n\nbp nova-tests-code-duplication\n\nChange-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390\n'}]",9,34538,6b12076d4a8e4a3da82297760becbd0105260e46,64,13,16,7249,,,0,"Moved tests for server._action_rebuild

Move tests to separate class as a preparation for code
deduplication.

This work continues in https://review.openstack.org/34556

bp nova-tests-code-duplication

Change-Id: I985232fa0a9b2d5b73034047b06138a8a3d7e390
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/34538/16 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/openstack/compute/test_servers.py'],1,3b5d7a145d60475aefc3c962b72737d5208db2eb,bp/api-compute-servers-tests," return_servers) instance_update) return_servers) instance_update) def test_get_all_server_details(self): expected_flavor = { ""id"": ""1"", ""links"": [ { ""rel"": ""bookmark"", ""href"": 'http://localhost/fake/flavors/1', }, ], } expected_image = { ""id"": ""10"", ""links"": [ { ""rel"": ""bookmark"", ""href"": 'http://localhost/fake/images/10', }, ], } req = fakes.HTTPRequest.blank('/v2/fake/servers/detail') res_dict = self.controller.detail(req) for i, s in enumerate(res_dict['servers']): self.assertEqual(s['id'], fakes.get_fake_uuid(i)) self.assertEqual(s['hostId'], '') self.assertEqual(s['name'], 'server%d' % (i + 1)) self.assertEqual(s['image'], expected_image) self.assertEqual(s['flavor'], expected_flavor) self.assertEqual(s['status'], 'BUILD') self.assertEqual(s['metadata']['seq'], str(i + 1)) def test_get_all_server_details_with_host(self): ''' We want to make sure that if two instances are on the same host, then they return the same hostId. If two instances are on different hosts, they should return different hostId's. In this test, there are 5 instances - 2 on one host and 3 on another. ''' def return_servers_with_host(context, *args, **kwargs): return [fakes.stub_instance(i + 1, 'fake', 'fake', host=i % 2, uuid=fakes.get_fake_uuid(i)) for i in xrange(5)] self.stubs.Set(db, 'instance_get_all_by_filters', return_servers_with_host) req = fakes.HTTPRequest.blank('/v2/fake/servers/detail') res_dict = self.controller.detail(req) server_list = res_dict['servers'] host_ids = [server_list[0]['hostId'], server_list[1]['hostId']] self.assertTrue(host_ids[0] and host_ids[1]) self.assertNotEqual(host_ids[0], host_ids[1]) for i, s in enumerate(server_list): self.assertEqual(s['id'], fakes.get_fake_uuid(i)) self.assertEqual(s['hostId'], host_ids[i % 2]) self.assertEqual(s['name'], 'server%d' % (i + 1)) class ServersControllerRebuildInstanceTest(ControllerTest): def setUp(self): super(ServersControllerRebuildInstanceTest,self).setUp() def test_rebuild_instance_with_access_ipv4_bad_format(self): self.controller._action_rebuild, req, FAKE_UUID, body) fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) self.controller._action_rebuild, req, FAKE_UUID, body) fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) name='public image', is_public=True, status='active', properties={'key1': 'value1'}, min_ram=""4096"", min_disk=""10"") fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) self.controller._action_rebuild, req, FAKE_UUID, body) name='public image', is_public=True, status='active', properties={'key1': 'value1'}, min_ram=""128"", min_disk=""100000"") self.controller._action_rebuild, req, FAKE_UUID, body) fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) self.controller._action_rebuild, req, FAKE_UUID, body)"," return_servers) instance_update) return_servers) instance_update) def test_rebuild_instance_with_access_ipv4_bad_format(self): self.stubs.Set(db, 'instance_get_by_uuid', fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) self.controller._action_rebuild, req, FAKE_UUID, body) fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) self.controller._action_rebuild, req, FAKE_UUID, body) fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) name='public image', is_public=True, status='active', properties={'key1': 'value1'}, min_ram=""4096"", min_disk=""10"") fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) self.controller._action_rebuild, req, FAKE_UUID, body) name='public image', is_public=True, status='active', properties={'key1': 'value1'}, min_ram=""128"", min_disk=""100000"") self.controller._action_rebuild, req, FAKE_UUID, body) fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) fakes.fake_instance_get(vm_state=vm_states.ACTIVE)) self.controller._action_rebuild, req, FAKE_UUID, body) def test_get_all_server_details(self): expected_flavor = { ""id"": ""1"", ""links"": [ { ""rel"": ""bookmark"", ""href"": 'http://localhost/fake/flavors/1', }, ], } expected_image = { ""id"": ""10"", ""links"": [ { ""rel"": ""bookmark"", ""href"": 'http://localhost/fake/images/10', }, ], } req = fakes.HTTPRequest.blank('/v2/fake/servers/detail') res_dict = self.controller.detail(req) for i, s in enumerate(res_dict['servers']): self.assertEqual(s['id'], fakes.get_fake_uuid(i)) self.assertEqual(s['hostId'], '') self.assertEqual(s['name'], 'server%d' % (i + 1)) self.assertEqual(s['image'], expected_image) self.assertEqual(s['flavor'], expected_flavor) self.assertEqual(s['status'], 'BUILD') self.assertEqual(s['metadata']['seq'], str(i + 1)) def test_get_all_server_details_with_host(self): ''' We want to make sure that if two instances are on the same host, then they return the same hostId. If two instances are on different hosts, they should return different hostId's. In this test, there are 5 instances - 2 on one host and 3 on another. ''' def return_servers_with_host(context, *args, **kwargs): return [fakes.stub_instance(i + 1, 'fake', 'fake', host=i % 2, uuid=fakes.get_fake_uuid(i)) for i in xrange(5)] self.stubs.Set(db, 'instance_get_all_by_filters', return_servers_with_host) req = fakes.HTTPRequest.blank('/v2/fake/servers/detail') res_dict = self.controller.detail(req) server_list = res_dict['servers'] host_ids = [server_list[0]['hostId'], server_list[1]['hostId']] self.assertTrue(host_ids[0] and host_ids[1]) self.assertNotEqual(host_ids[0], host_ids[1]) for i, s in enumerate(server_list): self.assertEqual(s['id'], fakes.get_fake_uuid(i)) self.assertEqual(s['hostId'], host_ids[i % 2]) self.assertEqual(s['name'], 'server%d' % (i + 1))",93,84
openstack%2Fpython-heatclient~master~I35a81a9518833ce9758228266deb36c8073f9fb8,openstack/python-heatclient,master,I35a81a9518833ce9758228266deb36c8073f9fb8,Set credentials headers if there is no auth token.,MERGED,2013-07-19 02:12:38.000000000,2013-07-22 17:23:49.000000000,2013-07-22 17:23:49.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-19 02:12:38.000000000', 'files': ['heatclient/common/http.py', 'heatclient/tests/test_common_http.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/78c98ee91bf0daac2337fec4474d3300417c0d40', 'message': 'Set credentials headers if there is no auth token.\n\nCredentials will be set instead of a token for all invocations where\n--os-no-client-auth is specified.\n\nChange-Id: I35a81a9518833ce9758228266deb36c8073f9fb8\n'}]",0,37828,78c98ee91bf0daac2337fec4474d3300417c0d40,6,3,1,4571,,,0,"Set credentials headers if there is no auth token.

Credentials will be set instead of a token for all invocations where
--os-no-client-auth is specified.

Change-Id: I35a81a9518833ce9758228266deb36c8073f9fb8
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/28/37828/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/common/http.py', 'heatclient/tests/test_common_http.py']",2,78c98ee91bf0daac2337fec4474d3300417c0d40,bp/heat-standalone," def test_token_or_credentials(self): # Record a 200 fake200 = fakes.FakeHTTPResponse( 200, 'OK', {'content-type': 'application/octet-stream'}, '') # no token or credentials mock_conn = http.httplib.HTTPConnection('example.com', 8004, timeout=600.0) mock_conn.request('GET', '/', headers={'Content-Type': 'application/octet-stream', 'User-Agent': 'python-heatclient'}) mock_conn.getresponse().AndReturn(fake200) # credentials mock_conn = http.httplib.HTTPConnection('example.com', 8004, timeout=600.0) mock_conn.request('GET', '/', headers={'Content-Type': 'application/octet-stream', 'User-Agent': 'python-heatclient', 'X-Auth-Key': 'pass', 'X-Auth-User': 'user'}) mock_conn.getresponse().AndReturn(fake200) # token suppresses credentials mock_conn = http.httplib.HTTPConnection('example.com', 8004, timeout=600.0) mock_conn.request('GET', '/', headers={'Content-Type': 'application/octet-stream', 'User-Agent': 'python-heatclient', 'X-Auth-Token': 'abcd1234'}) mock_conn.getresponse().AndReturn(fake200) # Replay, create client, assert self.m.ReplayAll() client = http.HTTPClient('http://example.com:8004') resp, body = client.raw_request('GET', '') self.assertEqual(resp.status, 200) client.username = 'user' client.password = 'pass' resp, body = client.raw_request('GET', '') self.assertEqual(resp.status, 200) client.auth_token = 'abcd1234' resp, body = client.raw_request('GET', '') self.assertEqual(resp.status, 200) self.m.VerifyAll() ",,58,4
openstack%2Fpython-heatclient~master~Ia9fbb694f38e583a0cf1898f576a894d1007f697,openstack/python-heatclient,master,Ia9fbb694f38e583a0cf1898f576a894d1007f697,Validate heat url is supplied for --os-no-client-auth.,MERGED,2013-07-19 02:12:38.000000000,2013-07-22 17:22:48.000000000,2013-07-22 17:22:48.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-19 02:12:38.000000000', 'files': ['heatclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/0254ad50a25816b80c854ea74f6a9b61cdad0e1f', 'message': 'Validate heat url is supplied for --os-no-client-auth.\n\nCurrently an obscure error is returned if --heat-url is not\nspecified.\n\nChange-Id: Ia9fbb694f38e583a0cf1898f576a894d1007f697\n'}]",0,37827,0254ad50a25816b80c854ea74f6a9b61cdad0e1f,6,3,1,4571,,,0,"Validate heat url is supplied for --os-no-client-auth.

Currently an obscure error is returned if --heat-url is not
specified.

Change-Id: Ia9fbb694f38e583a0cf1898f576a894d1007f697
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/27/37827/1 && git format-patch -1 --stdout FETCH_HEAD,['heatclient/shell.py'],1,0254ad50a25816b80c854ea74f6a9b61cdad0e1f,bp/heat-standalone," help=argparse.SUPPRESS) if args.os_no_client_auth and not args.heat_url: raise exc.CommandError(""If you specify --os-no-client-auth"" "" you must also specify a Heat API URL "" ""via either --heat-url or "" ""env[HEAT_URL]"")", help='DEPRECATED! Has no effect'),6,1
openstack%2Fdevstack~master~I8ad1b0b3d93d5068beec2021abf9afbacf8c48ff,openstack/devstack,master,I8ad1b0b3d93d5068beec2021abf9afbacf8c48ff,Set external ID on br-ex,MERGED,2013-07-15 16:45:05.000000000,2013-07-22 17:01:29.000000000,2013-07-22 17:01:28.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-15 16:45:05.000000000', 'files': ['lib/neutron_plugins/ovs_base'], 'web_link': 'https://opendev.org/openstack/devstack/commit/503e9ac4cf9ddb634279bf98c856adb135f43ac9', 'message': 'Set external ID on br-ex\n\nThis will enable Neurtron identify that the external bridge is a\nNeutron bridge (this is required for bug 1192883)\n\nChange-Id: I8ad1b0b3d93d5068beec2021abf9afbacf8c48ff\n'}]",0,37092,503e9ac4cf9ddb634279bf98c856adb135f43ac9,6,3,1,1653,,,0,"Set external ID on br-ex

This will enable Neurtron identify that the external bridge is a
Neutron bridge (this is required for bug 1192883)

Change-Id: I8ad1b0b3d93d5068beec2021abf9afbacf8c48ff
",git fetch https://review.opendev.org/openstack/devstack refs/changes/92/37092/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/ovs_base'],1,503e9ac4cf9ddb634279bf98c856adb135f43ac9,bug/1192883, sudo ovs-vsctl --no-wait br-set-external-id $PUBLIC_BRIDGE bridge-id $PUBLIC_BRIDGE,,1,0
openstack%2Fcookbook-openstack-dashboard~master~I5980cce629593220e098eee31abbe0f7614aee57,openstack/cookbook-openstack-dashboard,master,I5980cce629593220e098eee31abbe0f7614aee57,fix default false value; all ruby strings are true,MERGED,2013-07-22 16:00:15.000000000,2013-07-22 16:21:46.000000000,2013-07-22 16:21:46.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 216}]","[{'number': 1, 'created': '2013-07-22 16:00:15.000000000', 'files': ['attributes/default.rb', 'spec/server_spec.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/7a929d25e1e480cecbefb2c3d8ec69c0ae8491fd', 'message': 'fix default false value; all ruby strings are true\n\nChange-Id: I5980cce629593220e098eee31abbe0f7614aee57\n'}]",0,38165,7a929d25e1e480cecbefb2c3d8ec69c0ae8491fd,6,3,1,2340,,,0,"fix default false value; all ruby strings are true

Change-Id: I5980cce629593220e098eee31abbe0f7614aee57
",git fetch https://review.opendev.org/openstack/cookbook-openstack-dashboard refs/changes/65/38165/1 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/default.rb', 'spec/server_spec.rb']",2,7a929d25e1e480cecbefb2c3d8ec69c0ae8491fd,fix-false," it ""does not configure ssl proxy when ssl_offload is false"" do expect(@chef_run).not_to( create_file_with_content @file.name, ""SECURE_PROXY_SSL_HEADER"") end it ""configures ssl proxy when ssl_offload is set to true"" do chef_run = ::ChefSpec::ChefRunner.new ::UBUNTU_OPTS do |n| n.set[""openstack""][""dashboard""][""ssl_offload""] = true end chef_run.converge ""openstack-dashboard::server"" expect(chef_run).to( create_file_with_content @file.name, ""SECURE_PROXY_SSL_HEADER"") end",,16,1
openstack%2Ftripleo-incubator~master~I1ef9c8ffff7f4b8274365956682574fcd4fd3dc8,openstack/tripleo-incubator,master,I1ef9c8ffff7f4b8274365956682574fcd4fd3dc8,Setup .gitreview now that we have gerrit.,MERGED,2013-07-22 11:09:33.000000000,2013-07-22 16:20:03.000000000,2013-07-22 16:20:03.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-22 11:09:33.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/008d9064582e864fff74a28a6b6a5375d4baf7a5', 'message': 'Setup .gitreview now that we have gerrit.\n\nChange-Id: I1ef9c8ffff7f4b8274365956682574fcd4fd3dc8\n'}]",0,38133,008d9064582e864fff74a28a6b6a5375d4baf7a5,7,3,1,4190,,,0,"Setup .gitreview now that we have gerrit.

Change-Id: I1ef9c8ffff7f4b8274365956682574fcd4fd3dc8
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/33/38133/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,008d9064582e864fff74a28a6b6a5375d4baf7a5,,[gerrit] host=review.openstack.org port=29418 project=openstack/tripleo-incubator.git ,,4,0
openstack%2Fpuppet-swift~master~Id78be1a8c3dccd550c92204c4aaa1cf32edcbf61,openstack/puppet-swift,master,Id78be1a8c3dccd550c92204c4aaa1cf32edcbf61,Added the allow_versions flag to enable/disable object versioning in swift object container,MERGED,2013-07-17 15:09:17.000000000,2013-07-22 15:59:07.000000000,2013-07-22 15:59:07.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2265}, {'_account_id': 7360}, {'_account_id': 7822}, {'_account_id': 8083}]","[{'number': 1, 'created': '2013-07-17 15:09:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/7770b554fdc819f2e4f6d6fd9cd5602a01621fa9', 'message': 'Added the option flag to enable/disable object versioning\n\nChange-Id: Id78be1a8c3dccd550c92204c4aaa1cf32edcbf61\n'}, {'number': 2, 'created': '2013-07-17 15:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/0bfe94229d8f0f3518d27d9f3640480e5efc955b', 'message': 'Added the option flag to enable/disable object versioning\n\nChange-Id: Id78be1a8c3dccd550c92204c4aaa1cf32edcbf61\n'}, {'number': 3, 'created': '2013-07-18 11:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/33d1903855cc467fd809f665944c26bf386e7455', 'message': 'Added the allow_versions flag to enable/disable object versioning in swift object container\n\nChange-Id: Id78be1a8c3dccd550c92204c4aaa1cf32edcbf61\n'}, {'number': 4, 'created': '2013-07-19 14:33:58.000000000', 'files': ['spec/defines/swift_storage_server_spec.rb', 'templates/container-server.conf.erb', 'manifests/storage/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/4d96d896cac155acb87c2fd5e626cdf3585f24a0', 'message': 'Added the allow_versions flag to enable/disable object versioning in swift object container\n\nChange-Id: Id78be1a8c3dccd550c92204c4aaa1cf32edcbf61\n'}]",4,37493,4d96d896cac155acb87c2fd5e626cdf3585f24a0,25,6,4,8083,,,0,"Added the allow_versions flag to enable/disable object versioning in swift object container

Change-Id: Id78be1a8c3dccd550c92204c4aaa1cf32edcbf61
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/93/37493/4 && git format-patch -1 --stdout FETCH_HEAD,"['spec/defines/swift_storage_server_spec.rb', 'templates/container-server.conf.erb', 'manifests/storage/server.pp', 'spec/classes/swift_storage_container_spec.rb']",4,7770b554fdc819f2e4f6d6fd9cd5602a01621fa9,rhbz967308,,,12,0
openstack%2Fdevstack~master~I6ab0b7dd871acd6103b15b5fe10350667b72d1a8,openstack/devstack,master,I6ab0b7dd871acd6103b15b5fe10350667b72d1a8,"On openSUSE, qemu-tools provides qemu-img",MERGED,2013-07-04 07:48:52.000000000,2013-07-22 15:57:23.000000000,2013-07-22 15:57:23.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 4460}]","[{'number': 1, 'created': '2013-07-04 07:48:52.000000000', 'files': ['files/rpms-suse/cinder'], 'web_link': 'https://opendev.org/openstack/devstack/commit/19570302712d7ed252cf4303e39490d4e3e46f92', 'message': 'On openSUSE, qemu-tools provides qemu-img\n\nChange-Id: I6ab0b7dd871acd6103b15b5fe10350667b72d1a8\n'}]",0,35601,19570302712d7ed252cf4303e39490d4e3e46f92,16,4,1,4460,,,0,"On openSUSE, qemu-tools provides qemu-img

Change-Id: I6ab0b7dd871acd6103b15b5fe10350667b72d1a8
",git fetch https://review.opendev.org/openstack/devstack refs/changes/01/35601/1 && git format-patch -1 --stdout FETCH_HEAD,['files/rpms-suse/cinder'],1,19570302712d7ed252cf4303e39490d4e3e46f92,suse-cinder-pkg,qemu-tools,qemu-img,1,1
openstack%2Fpython-ceilometerclient~master~I22bf261b0a9580a06ae107ed45d082171f21fcc4,openstack/python-ceilometerclient,master,I22bf261b0a9580a06ae107ed45d082171f21fcc4,Allow to set matching_metadata with the cli,MERGED,2013-07-16 16:47:02.000000000,2013-07-22 15:56:26.000000000,2013-07-22 15:56:26.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}]","[{'number': 1, 'created': '2013-07-16 16:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/0acd4d1b0f08a0cf5a7072ff10aca274ca0ffae0', 'message': ""Allow to set matching_metadata with the cli\n\nThis change allows to set the matching_metadata of a alarm like this:\n\n ceilometer alarm-create --matching-metadata 'key:value' \\\n      --matching-metadata 'key2:value2' --name 'alarm' ...\n\nFixes bug #1201877\n\nChange-Id: I22bf261b0a9580a06ae107ed45d082171f21fcc4\n""}, {'number': 2, 'created': '2013-07-16 16:56:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/8e6f07fc63894b6121ecbb6b9e70e58adf29a9ce', 'message': ""Allow to set matching_metadata with the cli\n\nThis change allows to set the matching_metadata of a alarm like this:\n\n ceilometer alarm-create --matching-metadata 'key:value' \\\n      --matching-metadata 'key2:value2' --name 'alarm' ...\n\nFixes bug #1201877\n\nChange-Id: I22bf261b0a9580a06ae107ed45d082171f21fcc4\n""}, {'number': 3, 'created': '2013-07-22 08:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/c96108d89c07455e9ae85715ff15b6afe4319278', 'message': ""Allow to set matching_metadata with the cli\n\nThis change allows to set the matching_metadata of a alarm like this:\n\n ceilometer alarm-create --matching-metadata 'key:value' \\\n      --matching-metadata 'key2:value2' --name 'alarm' ...\n\nFixes bug #1201877\n\nChange-Id: I22bf261b0a9580a06ae107ed45d082171f21fcc4\n""}, {'number': 4, 'created': '2013-07-22 10:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/b36f3c5477e701ee293f0f8f7548096fff7c0645', 'message': ""Allow to set matching_metadata with the cli\n\nThis change allows to set the matching_metadata of a alarm like this:\n\n ceilometer alarm-create --matching-metadata 'key:value' \\\n      --matching-metadata 'key2:value2' --name 'alarm' ...\n\nFixes bug #1201877\n\nChange-Id: I22bf261b0a9580a06ae107ed45d082171f21fcc4\n""}, {'number': 5, 'created': '2013-07-22 15:43:06.000000000', 'files': ['ceilometerclient/common/utils.py', 'ceilometerclient/v2/shell.py', 'ceilometerclient/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/04cc271da208069e921da252554e839de46442ed', 'message': ""Allow to set matching_metadata with the cli\n\nThis change allows to set the matching_metadata of a alarm like this:\n\n ceilometer alarm-create --matching-metadata 'key=value' \\\n      --matching-metadata 'key2=value2' --name 'alarm' ...\n\nFixes bug #1201877\n\nChange-Id: I22bf261b0a9580a06ae107ed45d082171f21fcc4\n""}]",12,37287,04cc271da208069e921da252554e839de46442ed,24,4,5,2813,,,0,"Allow to set matching_metadata with the cli

This change allows to set the matching_metadata of a alarm like this:

 ceilometer alarm-create --matching-metadata 'key=value' \
      --matching-metadata 'key2=value2' --name 'alarm' ...

Fixes bug #1201877

Change-Id: I22bf261b0a9580a06ae107ed45d082171f21fcc4
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/87/37287/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometerclient/common/utils.py', 'ceilometerclient/v2/shell.py', 'ceilometerclient/tests/test_utils.py', 'ceilometerclient/tests/v2/test_alarms.py']",4,0acd4d1b0f08a0cf5a7072ff10aca274ca0ffae0,bug/1201877," u'matching_metadata': {u'metadata.test': 'valuetest'},",,41,2
openstack%2Fdevstack~master~I21d769b552d31fe099f2773c919e0c7b471399fc,openstack/devstack,master,I21d769b552d31fe099f2773c919e0c7b471399fc,Set external_network_bridge for the test configuration file,MERGED,2013-07-19 23:57:10.000000000,2013-07-22 15:51:15.000000000,2013-07-22 15:51:15.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 970}, {'_account_id': 1653}]","[{'number': 1, 'created': '2013-07-19 23:57:10.000000000', 'files': ['lib/neutron_plugins/nicira'], 'web_link': 'https://opendev.org/openstack/devstack/commit/dfe3f6bae7b74683472ffc510996a1fd0c41a7c7', 'message': 'Set external_network_bridge for the test configuration file\n\nFixes bug #1203210\nSupports blueprint nvp-third-party-support\n\nChange-Id: I21d769b552d31fe099f2773c919e0c7b471399fc\n'}]",0,38001,dfe3f6bae7b74683472ffc510996a1fd0c41a7c7,7,4,1,748,,,0,"Set external_network_bridge for the test configuration file

Fixes bug #1203210
Supports blueprint nvp-third-party-support

Change-Id: I21d769b552d31fe099f2773c919e0c7b471399fc
",git fetch https://review.opendev.org/openstack/devstack refs/changes/01/38001/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/nicira'],1,dfe3f6bae7b74683472ffc510996a1fd0c41a7c7,bug/1203210," iniset $NEUTRON_TEST_CONFIG_FILE DEFAULT external_network_bridge ""$PUBLIC_BRIDGE""",,1,0
openstack%2Ftempest~master~I124e6f14db81d030a470ef3e73a33b15e9dea9ef,openstack/tempest,master,I124e6f14db81d030a470ef3e73a33b15e9dea9ef,Document E125 as a won't fix.,MERGED,2013-07-18 21:12:09.000000000,2013-07-22 15:49:18.000000000,2013-07-22 15:49:18.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1849}, {'_account_id': 5292}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-18 21:12:09.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest/commit/dca03dd6ef39a088e7df5a325eb5f5702389a356', 'message': ""Document E125 as a won't fix.\n\nAs per the discussion in https://review.openstack.org/#/c/36788/ the\ntempest team does not want to use E125 until\nhttps://github.com/jcrocholl/pep8/issues/126 is  resolved.\n\nChange-Id: I124e6f14db81d030a470ef3e73a33b15e9dea9ef\n""}]",0,37778,dca03dd6ef39a088e7df5a325eb5f5702389a356,8,5,1,1849,,,0,"Document E125 as a won't fix.

As per the discussion in https://review.openstack.org/#/c/36788/ the
tempest team does not want to use E125 until
https://github.com/jcrocholl/pep8/issues/126 is  resolved.

Change-Id: I124e6f14db81d030a470ef3e73a33b15e9dea9ef
",git fetch https://review.opendev.org/openstack/tempest refs/changes/78/37778/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,dca03dd6ef39a088e7df5a325eb5f5702389a356,E125,# E125 is a won't fix until https://github.com/jcrocholl/pep8/issues/126 is resolved. For further detail see https://review.openstack.org/#/c/36788/,,1,0
openstack%2Fnova~master~I5e024871e5159f08cbba05fa261a9a2d08e4b8e5,openstack/nova,master,I5e024871e5159f08cbba05fa261a9a2d08e4b8e5,Unit-ify compute_api delete tests,MERGED,2013-07-09 22:56:54.000000000,2013-07-22 15:48:53.000000000,2013-07-22 15:48:51.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}]","[{'number': 1, 'created': '2013-07-09 22:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d4412a6c2d9d809d68885e4adea57a01907e4d2', 'message': ""Unit-ify compute_api delete tests\n\nThis makes the delete and soft_delete tests unit-like in nature,\nand moves them to test_compute_api, as has been done recently\nfor others that we're moving to objects.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5\n""}, {'number': 2, 'created': '2013-07-10 15:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48f1420c16b72dd053b1ae0088b9173dbe37f092', 'message': ""Unit-ify compute_api delete tests\n\nThis makes the delete and soft_delete tests unit-like in nature,\nand moves them to test_compute_api, as has been done recently\nfor others that we're moving to objects.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5\n""}, {'number': 3, 'created': '2013-07-11 01:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1f4e01ddeeb5d6f1978aa048bb92ca1eba4e9f4', 'message': ""Unit-ify compute_api delete tests\n\nThis makes the delete and soft_delete tests unit-like in nature,\nand moves them to test_compute_api, as has been done recently\nfor others that we're moving to objects.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5\n""}, {'number': 4, 'created': '2013-07-11 05:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db796fa9bacd10d2387b785aff0e3ba3f33cb183', 'message': ""Unit-ify compute_api delete tests\n\nThis makes the delete and soft_delete tests unit-like in nature,\nand moves them to test_compute_api, as has been done recently\nfor others that we're moving to objects.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5\n""}, {'number': 5, 'created': '2013-07-11 19:24:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e11be2a48a3a8ec2199ce5944de2045dfb51060', 'message': ""Unit-ify compute_api delete tests\n\nThis makes the delete and soft_delete tests unit-like in nature,\nand moves them to test_compute_api, as has been done recently\nfor others that we're moving to objects.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5\n""}, {'number': 6, 'created': '2013-07-12 21:13:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a1a51495f993573d2a68ea3f29ba2caefb921aa', 'message': ""Unit-ify compute_api delete tests\n\nThis makes the delete and soft_delete tests unit-like in nature,\nand moves them to test_compute_api, as has been done recently\nfor others that we're moving to objects.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5\n""}, {'number': 7, 'created': '2013-07-17 01:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c80a2d1a66c942541b9fadfcb1606018cebbd654', 'message': ""Unit-ify compute_api delete tests\n\nThis makes the delete and soft_delete tests unit-like in nature,\nand moves them to test_compute_api, as has been done recently\nfor others that we're moving to objects.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5\n""}, {'number': 8, 'created': '2013-07-17 16:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d206c089aefae3fb08343d96477dd260fd4edac4', 'message': ""Unit-ify compute_api delete tests\n\nThis makes the delete and soft_delete tests unit-like in nature,\nand moves them to test_compute_api, as has been done recently\nfor others that we're moving to objects.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5\n""}, {'number': 9, 'created': '2013-07-17 16:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8453b30986f1abba54714de64c37c16612b1b5d', 'message': ""Unit-ify compute_api delete tests\n\nThis makes the delete and soft_delete tests unit-like in nature,\nand moves them to test_compute_api, as has been done recently\nfor others that we're moving to objects.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5\n""}, {'number': 10, 'created': '2013-07-17 23:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a1fef7dba389986362751329db8b5b9924a43b6f', 'message': ""Unit-ify compute_api delete tests\n\nThis makes the delete and soft_delete tests unit-like in nature,\nand moves them to test_compute_api, as has been done recently\nfor others that we're moving to objects.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5\n""}, {'number': 11, 'created': '2013-07-18 17:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d20b0284998867325f14c889bba61ce5f28f8a2', 'message': ""Unit-ify compute_api delete tests\n\nThis makes the delete and soft_delete tests unit-like in nature,\nand moves them to test_compute_api, as has been done recently\nfor others that we're moving to objects.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5\n""}, {'number': 12, 'created': '2013-07-18 18:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/735640fa28aa3a8afa65ba9aadc4d1b1e79213ad', 'message': ""Unit-ify compute_api delete tests\n\nThis makes the delete and soft_delete tests unit-like in nature,\nand moves them to test_compute_api, as has been done recently\nfor others that we're moving to objects.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5\n""}, {'number': 13, 'created': '2013-07-22 14:21:34.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a56f0b33069b919ebb24c4afdcc6b6c31592c98e', 'message': ""Unit-ify compute_api delete tests\n\nThis makes the delete and soft_delete tests unit-like in nature,\nand moves them to test_compute_api, as has been done recently\nfor others that we're moving to objects.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5\n""}]",0,36358,a56f0b33069b919ebb24c4afdcc6b6c31592c98e,56,6,13,4393,,,0,"Unit-ify compute_api delete tests

This makes the delete and soft_delete tests unit-like in nature,
and moves them to test_compute_api, as has been done recently
for others that we're moving to objects.

Related to blueprint compute-api-objects

Change-Id: I5e024871e5159f08cbba05fa261a9a2d08e4b8e5
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/36358/12 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_api.py', 'nova/tests/compute/test_compute.py']",2,0d4412a6c2d9d809d68885e4adea57a01907e4d2,bp/compute-api-objects,," def test_delete(self): instance, instance_uuid = self._run_instance(params={ 'host': CONF.host}) self.compute_api.delete(self.context, instance) instance = db.instance_get_by_uuid(self.context, instance_uuid) self.assertEqual(instance['task_state'], task_states.DELETING) db.instance_destroy(self.context, instance['uuid']) def test_delete_if_not_launched(self): instance, instance_uuid = self._run_instance(params={ 'host': CONF.host}) db.instance_update(self.context, instance['uuid'], {""vm_state"": vm_states.ERROR, ""launched_at"": None}) self.compute_api.delete(self.context, instance) instance = db.instance_get_by_uuid(self.context, instance_uuid) self.assertEqual(instance['task_state'], task_states.DELETING) db.instance_destroy(self.context, instance['uuid']) def test_delete_in_resizing(self): def fake_quotas_reserve(context, expire=None, project_id=None, **deltas): old_type = flavors.get_flavor_by_name('m1.tiny') # ensure using old instance type to create reservations self.assertEqual(deltas['cores'], -old_type['vcpus']) self.assertEqual(deltas['ram'], -old_type['memory_mb']) self.stubs.Set(QUOTAS, 'reserve', fake_quotas_reserve) instance, instance_uuid = self._run_instance(params={ 'host': CONF.host}) # create a fake migration record (manager does this) new_inst_type = flavors.get_flavor_by_name('m1.small') db.migration_create(self.context.elevated(), {'instance_uuid': instance['uuid'], 'old_instance_type_id': instance['instance_type_id'], 'new_instance_type_id': new_inst_type['id'], 'status': 'post-migrating'}) # update instance type to resized one db.instance_update(self.context, instance['uuid'], {'instance_type_id': new_inst_type['id'], 'vcpus': new_inst_type['vcpus'], 'memory_mb': new_inst_type['memory_mb'], 'task_state': task_states.RESIZE_FINISH}) self.compute_api.delete(self.context, instance) db.instance_destroy(self.context, instance['uuid']) def test_delete_in_resized(self): instance, instance_uuid = self._run_instance(params={ 'host': CONF.host}) instance['vm_state'] = vm_states.RESIZED self.compute_api.delete(self.context, instance) instance = db.instance_get_by_uuid(self.context, instance_uuid) self.assertEqual(instance['task_state'], task_states.DELETING) db.instance_destroy(self.context, instance['uuid']) def test_delete_with_down_host(self): self.network_api_called = False def dummy(*args, **kwargs): self.network_api_called = True self.stubs.Set(self.compute_api.network_api, 'deallocate_for_instance', dummy) #use old time to disable machine old_time = datetime.datetime(2012, 4, 1) instance, instance_uuid = self._run_instance(params={ 'host': CONF.host}) timeutils.set_time_override(old_time) self.compute_api.delete(self.context, instance) timeutils.clear_time_override() self.assertEqual(instance['task_state'], None) self.assertTrue(self.network_api_called) # fetch the instance state from db and verify deletion. deleted_context = context.RequestContext('fake', 'fake', read_deleted='yes') instance = db.instance_get_by_uuid(deleted_context, instance_uuid) self.assertEqual(instance['vm_state'], vm_states.DELETED) self.assertEqual(instance['task_state'], None) self.assertTrue(instance['deleted']) def test_delete_fast_if_host_not_set(self): instance = self._create_fake_instance({'host': None}) self.compute_api.delete(self.context, instance) self.assertRaises(exception.InstanceNotFound, db.instance_get_by_uuid, self.context, instance['uuid']) def test_delete_handles_host_setting_race_condition(self): instance, instance_uuid = self._run_instance(params={ 'host': CONF.host}) instance['host'] = None # make it think host was never set self.compute_api.delete(self.context, instance) instance = db.instance_get_by_uuid(self.context, instance_uuid) self.assertEqual(instance['task_state'], task_states.DELETING) db.instance_destroy(self.context, instance['uuid']) def test_delete_fail(self): instance, instance_uuid = self._run_instance(params={ 'host': CONF.host}) instance = db.instance_update(self.context, instance_uuid, {'disable_terminate': True}) self.compute_api.delete(self.context, instance) instance = db.instance_get_by_uuid(self.context, instance_uuid) self.assertEqual(instance['task_state'], None) db.instance_destroy(self.context, instance['uuid']) def test_delete_soft(self): instance, instance_uuid = self._run_instance(params={ 'host': CONF.host}) # Make sure this is not called on the API side. self.mox.StubOutWithMock(nova.quota.QUOTAS, 'commit') self.mox.ReplayAll() self.compute_api.soft_delete(self.context, instance) instance = db.instance_get_by_uuid(self.context, instance_uuid) self.assertEqual(instance['task_state'], task_states.SOFT_DELETING) db.instance_destroy(self.context, instance['uuid']) def test_delete_soft_fail(self): instance, instance_uuid = self._run_instance(params={ 'host': CONF.host}) instance = db.instance_update(self.context, instance_uuid, {'disable_terminate': True}) self.compute_api.soft_delete(self.context, instance) instance = db.instance_get_by_uuid(self.context, instance_uuid) self.assertEqual(instance['task_state'], None) db.instance_destroy(self.context, instance['uuid']) def test_delete_soft_rollback(self): instance, instance_uuid = self._run_instance(params={ 'host': CONF.host}) self.mox.StubOutWithMock(nova.quota.QUOTAS, 'rollback') nova.quota.QUOTAS.rollback(mox.IgnoreArg(), mox.IgnoreArg(), project_id=mox.IgnoreArg()) self.mox.ReplayAll() def fail(*args, **kwargs): raise test.TestingException() self.stubs.Set(self.compute_api.compute_rpcapi, 'soft_delete_instance', fail) self.assertRaises(test.TestingException, self.compute_api.soft_delete, self.context, instance) instance = db.instance_get_by_uuid(self.context, instance_uuid) self.assertEqual(instance['task_state'], task_states.SOFT_DELETING) db.instance_destroy(self.context, instance['uuid']) def test_force_delete(self): # Ensure instance can be deleted after a soft delete. instance = jsonutils.to_primitive(self._create_fake_instance(params={ 'host': CONF.host}, services=True)) instance_uuid = instance['uuid'] self.compute.run_instance(self.context, instance=instance) instance = db.instance_get_by_uuid(self.context, instance_uuid) self.compute_api.soft_delete(self.context, instance) instance = db.instance_get_by_uuid(self.context, instance_uuid) self.assertEqual(instance['task_state'], task_states.SOFT_DELETING) # set the state that the instance gets when soft_delete finishes instance = db.instance_update(self.context, instance['uuid'], {'vm_state': vm_states.SOFT_DELETED, 'task_state': None}) self.compute_api.force_delete(self.context, instance) instance = db.instance_get_by_uuid(self.context, instance_uuid) self.assertEqual(instance['task_state'], task_states.DELETING) ",209,203
openstack%2Fmurano-dashboard~master~Iedf484e5d0f2f8ccf5f452f127d371686bb33c94,openstack/murano-dashboard,master,Iedf484e5d0f2f8ccf5f452f127d371686bb33c94,Extend password checking on the fly,MERGED,2013-07-22 11:58:10.000000000,2013-07-22 15:48:41.000000000,2013-07-22 15:48:41.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7821}]","[{'number': 1, 'created': '2013-07-22 11:58:10.000000000', 'files': ['muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/forms.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/db9b16793582d993078b6073e2018cd093a1c70b', 'message': 'Extend password checking on the fly\n\nChange-Id: Iedf484e5d0f2f8ccf5f452f127d371686bb33c94\n'}]",0,38135,db9b16793582d993078b6073e2018cd093a1c70b,6,3,1,7549,,,0,"Extend password checking on the fly

Change-Id: Iedf484e5d0f2f8ccf5f452f127d371686bb33c94
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/35/38135/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/forms.py']",2,db9b16793582d993078b6073e2018cd093a1c70b,,,,7,9
openstack%2Fnova~master~I1722c03d20511d67acc0a8947de1d4273dc78597,openstack/nova,master,I1722c03d20511d67acc0a8947de1d4273dc78597,Convert network API to use InfoCache object,MERGED,2013-07-11 22:19:27.000000000,2013-07-22 15:41:00.000000000,2013-07-22 15:40:58.000000000,"[{'_account_id': 3}, {'_account_id': 191}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}]","[{'number': 1, 'created': '2013-07-11 22:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2c1cbb3eac6abfa74369c27480a2342dd97551e8', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}, {'number': 2, 'created': '2013-07-11 22:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe7e6253cc7f394ad178365dcc81b198d816992a', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}, {'number': 3, 'created': '2013-07-11 22:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/59b09c6a0279acad8b0b536c42bfaf93a3c6d1f9', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}, {'number': 4, 'created': '2013-07-11 22:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e880e048d4dff37836204e42d4c95b4825791144', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}, {'number': 5, 'created': '2013-07-12 01:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae2334b8ec3e330f28ffd8e7adabbd3df1673c9d', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}, {'number': 6, 'created': '2013-07-12 06:39:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd0537bcd146d9f46a842e37769e3aac9266155f', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}, {'number': 7, 'created': '2013-07-12 21:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1433162baff371b33b3f841e068d68cd319aa069', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}, {'number': 8, 'created': '2013-07-17 01:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4dbc9ac80fa25711f7c55e44664da672c12e6933', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}, {'number': 9, 'created': '2013-07-17 16:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8a8a0c818527f5c81131c7b845db47e98f41250', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}, {'number': 10, 'created': '2013-07-17 16:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/592924d22dda1cfac7e6f2a46a549ecdf9024cd6', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}, {'number': 11, 'created': '2013-07-17 23:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/08e304be3bde84199a0d5e4b99bc84758dceafbb', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}, {'number': 12, 'created': '2013-07-18 17:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee370a4825b639a2047aeb5b8f4bbde13c0cf440', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}, {'number': 13, 'created': '2013-07-18 18:16:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2cbf22125605224a9eb92ee17bb0e691957987f9', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}, {'number': 14, 'created': '2013-07-22 14:21:36.000000000', 'files': ['nova/network/neutronv2/api.py', 'nova/network/api.py', 'nova/tests/objects/test_instance_info_cache.py', 'nova/api/metadata/base.py', 'nova/tests/test_metadata.py', 'nova/compute/manager.py', 'nova/virt/firewall.py', 'nova/tests/compute/test_compute.py', 'nova/objects/instance_info_cache.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d8eeea1bae6f0992f05b5438fd65d411703ce0f6', 'message': 'Convert network API to use InfoCache object\n\nThis converts the db.info_cache_update() call in network/api to use\nobjects.  The save() method has been extended to support what we need\nfor cells.\n\nConverting to the object allows us to ditch the conductor_api kwarg on\nsome methods.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I1722c03d20511d67acc0a8947de1d4273dc78597\n'}]",0,36745,d8eeea1bae6f0992f05b5438fd65d411703ce0f6,49,8,14,1030,,,0,"Convert network API to use InfoCache object

This converts the db.info_cache_update() call in network/api to use
objects.  The save() method has been extended to support what we need
for cells.

Converting to the object allows us to ditch the conductor_api kwarg on
some methods.

Related to blueprint unified-object-model

Change-Id: I1722c03d20511d67acc0a8947de1d4273dc78597
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/36745/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/api.py', 'nova/tests/objects/test_instance_info_cache.py', 'nova/compute/manager.py', 'nova/network/quantumv2/api.py', 'nova/tests/compute/test_compute.py', 'nova/objects/instance_info_cache.py']",6,2c1cbb3eac6abfa74369c27480a2342dd97551e8,bp/compute-api-objects,"from nova.cells import opts as cells_opts from nova.cells import rpcapi as cells_rpcapifrom nova.openstack.common import log as logging LOG = logging.getLogger(__name__) # Version 1.2: Added new() and update_cells kwarg to save(). @classmethod def new(cls, context, instance_uuid): """"""Create an InfoCache object that can be used to create the DB entry for the first time. When save()ing this object, the info_cache_update() DB call will properly handle creating it if it doesn't exist already. """""" info_cache = cls() info_cache.instance_uuid = instance_uuid info_cache.network_info = None info_cache._context = context # Leave the fields dirty return info_cache @staticmethod def _info_cache_cells_update(ctxt, info_cache): cell_type = cells_opts.get_cell_type() if cell_type != 'compute': return cells_api = cells_rpcapi.CellsAPI() try: cells_api.instance_info_cache_update_at_top(ctxt, info_cache) except Exception: LOG.exception(_(""Failed to notify cells of instance info "" ""cache update"")) def save(self, context, update_cells=True): rv = db.instance_info_cache_update(context, self.instance_uuid, {'network_info': nw_info_json}) if update_cells and rv: self._info_cache_cells_update(context, rv) self.obj_reset_changes()"," def save(self, context): db.instance_info_cache_update(context, self.instance_uuid, {'network_info': nw_info_json}) self.obj_reset_changes()",93,39
openstack%2Fglance~master~Ic88b142a40c548141be4b40a15f94b71603814e9,openstack/glance,master,Ic88b142a40c548141be4b40a15f94b71603814e9,Handle client disconnect during image upload,MERGED,2013-07-02 13:00:24.000000000,2013-07-22 15:40:50.000000000,2013-07-22 15:40:50.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 1390}, {'_account_id': 1706}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 6484}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-07-02 13:00:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/144bd594260a8a46ba2836ca105b6ede5bc72c29', 'message': 'Handle client disconnect during image upload\n\nIf a user does a ^C during a chunked image upload, eventlet.wsgi.server\nwill raise one of ValueError or IOError when trying to read the next\nchunk.\n\nHandle this common scenario by raising(logging) a HTTPBadRequest error rather\nthan HTTPInternalServerError.\n\nFixes bug 1196953\n\nChange-Id: Ic88b142a40c548141be4b40a15f94b71603814e9\n'}, {'number': 2, 'created': '2013-07-09 12:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/46a3471046d761acd2fe6747b646567d9b925fc3', 'message': 'Handle client disconnect during image upload\n\nIf a user does a ^C during a chunked image upload, eventlet.wsgi.server\nwill raise one of ValueError or IOError when trying to read the next\nchunk.\n\nHandle this common scenario by raising(logging) a HTTPBadRequest error rather\nthan HTTPInternalServerError.\n\nFixes bug 1196953\n\nChange-Id: Ic88b142a40c548141be4b40a15f94b71603814e9\n'}, {'number': 3, 'created': '2013-07-18 15:26:22.000000000', 'files': ['glance/tests/unit/v1/test_upload_utils.py', 'glance/api/v1/upload_utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/3904860467d87c74c046974963070e029a89ba5e', 'message': 'Handle client disconnect during image upload\n\nIf a user does a ^C during a chunked image upload, eventlet.wsgi.server\nwill raise one of ValueError or IOError when trying to read the next\nchunk.\n\nHandle this common scenario by raising(logging) a HTTPBadRequest error rather\nthan HTTPInternalServerError.\n\nFixes bug 1196953\n\nChange-Id: Ic88b142a40c548141be4b40a15f94b71603814e9\n'}]",1,35286,3904860467d87c74c046974963070e029a89ba5e,29,8,3,1390,,,0,"Handle client disconnect during image upload

If a user does a ^C during a chunked image upload, eventlet.wsgi.server
will raise one of ValueError or IOError when trying to read the next
chunk.

Handle this common scenario by raising(logging) a HTTPBadRequest error rather
than HTTPInternalServerError.

Fixes bug 1196953

Change-Id: Ic88b142a40c548141be4b40a15f94b71603814e9
",git fetch https://review.opendev.org/openstack/glance refs/changes/86/35286/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/v1/test_upload_utils.py', 'glance/api/v1/upload_utils.py']",2,144bd594260a8a46ba2836ca105b6ede5bc72c29,bug/1196953," except (ValueError, IOError) as e: msg = _(""Client disconnected before sending all data to backend"") LOG.error(msg) safe_kill(req, image_id) raise webob.exc.HTTPBadRequest(explanation=msg, content_type=""text/plain"", request=req) ",,18,0
openstack%2Fnova~master~I170dbd7c9093bd627e2a0d5984b7ad1bf105c8d5,openstack/nova,master,I170dbd7c9093bd627e2a0d5984b7ad1bf105c8d5,Use timeutils.utcnow() throughout the code,MERGED,2013-07-11 13:53:43.000000000,2013-07-22 15:40:25.000000000,2013-07-22 15:40:23.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 6172}, {'_account_id': 6849}]","[{'number': 1, 'created': '2013-07-11 13:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4926a8cc29d305e23fbb1c0cbab064547ebb84c8', 'message': 'Use timeutils.utcnow() throughout the code\n\ntimeutils.utcnow() should be used instead of direct calls to\ndatetime.datetime.utcnow() to make it easy to override its return\nvalue in tests.\n\nFixes bug 1200141.\n\nChange-Id: I170dbd7c9093bd627e2a0d5984b7ad1bf105c8d5\n'}, {'number': 2, 'created': '2013-07-12 14:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/69d962d7844cc3573e20a49ae9ceff8e35ecfa0c', 'message': 'Use timeutils.utcnow() throughout the code\n\ntimeutils.utcnow() should be used instead of direct calls to\ndatetime.datetime.utcnow() to make it easy to override its return\nvalue in tests.\n\nFixes bug 1200141.\n\nChange-Id: I170dbd7c9093bd627e2a0d5984b7ad1bf105c8d5\n'}, {'number': 3, 'created': '2013-07-16 10:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/abc5f3e4bcec2d8f2b8e8139d54d2d24ea689d92', 'message': 'Use timeutils.utcnow() throughout the code\n\ntimeutils.utcnow() should be used instead of direct calls to\ndatetime.datetime.utcnow() to make it easy to override its return\nvalue in tests.\n\nAdd a hacking rule to prevent regressions.\n\nFixes bug 1200141.\n\nChange-Id: I170dbd7c9093bd627e2a0d5984b7ad1bf105c8d5\n'}, {'number': 4, 'created': '2013-07-16 12:00:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e30c9c598cc1170e66579bf12fa7ee6d3ea5a6aa', 'message': 'Use timeutils.utcnow() throughout the code\n\ntimeutils.utcnow() should be used instead of direct calls to\ndatetime.datetime.utcnow() to make it easy to override its return\nvalue in tests.\n\nAdd a hacking rule to prevent regressions.\n\nFixes bug 1200141.\n\nChange-Id: I170dbd7c9093bd627e2a0d5984b7ad1bf105c8d5\n'}, {'number': 5, 'created': '2013-07-16 14:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/22197f415021e9dfdc89fdd6e3cfab1d26c0df6d', 'message': 'Use timeutils.utcnow() throughout the code\n\ntimeutils.utcnow() should be used instead of direct calls to\ndatetime.datetime.utcnow() to make it easy to override its return\nvalue in tests.\n\nAdd a hacking rule to prevent regressions.\n\nFixes bug 1200141.\n\nChange-Id: I170dbd7c9093bd627e2a0d5984b7ad1bf105c8d5\n'}, {'number': 6, 'created': '2013-07-18 14:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ec11bbd29e154b68a4bb702141d4f764049a735', 'message': 'Use timeutils.utcnow() throughout the code\n\ntimeutils.utcnow() should be used instead of direct calls to\ndatetime.datetime.utcnow() to make it easy to override its return\nvalue in tests.\n\nAdd a hacking rule to prevent regressions.\n\nFixes bug 1200141.\n\nChange-Id: I170dbd7c9093bd627e2a0d5984b7ad1bf105c8d5\n'}, {'number': 7, 'created': '2013-07-19 13:18:28.000000000', 'files': ['nova/tests/api/openstack/fakes.py', 'nova/tests/api/openstack/compute/contrib/test_simple_tenant_usage.py', 'nova/tests/api/openstack/compute/contrib/test_server_usage.py', 'nova/hacking/checks.py', 'nova/tests/objects/test_objects.py', 'nova/tests/integrated/test_servers.py', 'nova/tests/db/test_migrations.py', 'nova/tests/db/test_db_api.py', 'nova/tests/api/openstack/compute/plugins/v3/test_simple_tenant_usage.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/2e83be17d101c1501795708a9acc4671dee9c02d', 'message': 'Use timeutils.utcnow() throughout the code\n\ntimeutils.utcnow() should be used instead of direct calls to\ndatetime.datetime.utcnow() to make it easy to override its return\nvalue in tests.\n\nAdd a hacking rule to prevent regressions.\n\nFixes bug 1200141.\n\nChange-Id: I170dbd7c9093bd627e2a0d5984b7ad1bf105c8d5\n'}]",6,36662,2e83be17d101c1501795708a9acc4671dee9c02d,38,9,7,6849,,,0,"Use timeutils.utcnow() throughout the code

timeutils.utcnow() should be used instead of direct calls to
datetime.datetime.utcnow() to make it easy to override its return
value in tests.

Add a hacking rule to prevent regressions.

Fixes bug 1200141.

Change-Id: I170dbd7c9093bd627e2a0d5984b7ad1bf105c8d5
",git fetch https://review.opendev.org/openstack/nova refs/changes/62/36662/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/fakes.py', 'nova/tests/api/openstack/compute/contrib/test_server_usage.py', 'nova/tests/api/openstack/compute/contrib/test_simple_tenant_usage.py', 'nova/tests/objects/test_objects.py', 'nova/tests/integrated/test_servers.py', 'nova/tests/db/test_db_api.py', 'nova/tests/db/test_migrations.py', 'nova/tests/api/openstack/compute/plugins/v3/test_simple_tenant_usage.py']",8,4926a8cc29d305e23fbb1c0cbab064547ebb84c8,bp/db-api-tests-on-all-backends, now = timeutils.utcnow(), now = datetime.datetime.now(),14,15
openstack%2Fos-refresh-config~master~I33cbb065d6bc32c87f5e72132fceef9df82a190d,openstack/os-refresh-config,master,I33cbb065d6bc32c87f5e72132fceef9df82a190d,Add a lockfile.,MERGED,2013-07-22 15:39:57.000000000,2013-07-22 15:39:57.000000000,2013-07-22 15:39:57.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-22 15:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-refresh-config/commit/9250ee79b8b36d9a9bb0677c9645eae328de95bb', 'message': 'Add a lockfile.\n\nThe scripts run by os-refresh-config generally expect to be running\nonly once. This will ensure that. Because we use /var/run, this also\nnow assumes that os-refresh-config is run by root. Otherwise one must\npass in a different --lockfile path.\n\nChange-Id: I33cbb065d6bc32c87f5e72132fceef9df82a190d\n'}, {'number': 2, 'created': '2013-07-22 15:39:57.000000000', 'files': ['setup.py', 'os_refresh_config/os_refresh_config.py'], 'web_link': 'https://opendev.org/openstack/os-refresh-config/commit/d7ea66ee8dfe0a5b0d679f6c6e77f3bbaa184215', 'message': 'Add a lockfile.\n\nThe scripts run by os-refresh-config generally expect to be running\nonly once. This will ensure that. Because we use /var/run, this also\nnow assumes that os-refresh-config is run by root. Otherwise one must\npass in a different --lockfile path.\n\nChange-Id: I33cbb065d6bc32c87f5e72132fceef9df82a190d\n'}]",0,37319,d7ea66ee8dfe0a5b0d679f6c6e77f3bbaa184215,11,3,2,6488,,,0,"Add a lockfile.

The scripts run by os-refresh-config generally expect to be running
only once. This will ensure that. Because we use /var/run, this also
now assumes that os-refresh-config is run by root. Otherwise one must
pass in a different --lockfile path.

Change-Id: I33cbb065d6bc32c87f5e72132fceef9df82a190d
",git fetch https://review.opendev.org/openstack/os-refresh-config refs/changes/19/37319/1 && git format-patch -1 --stdout FETCH_HEAD,['os_refresh_config/os_refresh_config.py'],1,9250ee79b8b36d9a9bb0677c9645eae328de95bb,,"import fcntlimport subprocessimport time parser.add_argument('--lockfile', default='/var/run/os-refresh-config.lock', help='Lock file to prevent multiple running copies.') # Keep open (and thus, locked) for duration of program lock = open(options.lockfile, 'a') try: fcntl.flock(lock, fcntl.LOCK_EX | fcntl.LOCK_NB) except IOError as e: log.error('Could not lock %s. %s' % (options.lockfile, e)) return e.errno lock.truncate(0) lock.write(""Locked by pid==%d at %s\n"" % (os.getpid(), time.localtime())) subprocess.check_call(args, close_fds=True) except subprocess.CalledProcessError as e: lock.truncate(0) lock.close() ","from subprocess import check_call, CalledProcessError check_call(args) except CalledProcessError as e:",22,3
openstack%2Ftempest~master~I7a65be714627692ad80b3640af0ee617fd4697a9,openstack/tempest,master,I7a65be714627692ad80b3640af0ee617fd4697a9,Add unittest like output for testr-full in tox,MERGED,2013-07-18 19:59:57.000000000,2013-07-22 15:38:21.000000000,2013-07-22 15:38:21.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-18 19:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b7fabbbf2a5f58224f8cb1cf2b50ab0b7d3c4f65', 'message': ""Add unittest like output for testr-full in tox\n\nThis commit adds real time output similar to that when running with\nnose so that it's possible to watch the status of the job when using\ntestr with tempest.\n\nChange-Id: I7a65be714627692ad80b3640af0ee617fd4697a9\n""}, {'number': 2, 'created': '2013-07-18 20:48:12.000000000', 'files': ['tox.ini', 'tools/pretty_tox.sh'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8551278461848604d443bec2f44476e398a81459', 'message': ""Add unittest like output for testr-full in tox\n\nThis commit adds real time output similar to that when running with\nnose so that it's possible to watch the status of the job when using\ntestr with tempest.\n\nChange-Id: I7a65be714627692ad80b3640af0ee617fd4697a9\n""}]",0,37758,8551278461848604d443bec2f44476e398a81459,7,4,2,5196,,,0,"Add unittest like output for testr-full in tox

This commit adds real time output similar to that when running with
nose so that it's possible to watch the status of the job when using
testr with tempest.

Change-Id: I7a65be714627692ad80b3640af0ee617fd4697a9
",git fetch https://review.opendev.org/openstack/tempest refs/changes/58/37758/1 && git format-patch -1 --stdout FETCH_HEAD,"['tox.ini', 'tools/pretty_tox.sh']",2,b7fabbbf2a5f58224f8cb1cf2b50ab0b7d3c4f65,testr-fixes,"#!/bin/sh TESTRARGS=$1 python setup.py testr --slowest --testr-args=""--subunit $TESTRARGS"" | subunit2pyunit ",,5,1
openstack%2Ftempest~master~Idd1b820d103bf4d71f2645e98e86e5fadbd6cb0c,openstack/tempest,master,Idd1b820d103bf4d71f2645e98e86e5fadbd6cb0c,Use subunit colorizer from nova for run_tests.sh,MERGED,2013-07-18 19:59:57.000000000,2013-07-22 15:30:43.000000000,2013-07-22 15:30:43.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-18 19:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1981063c136e20c0d547aa041b28063fe7b681b0', 'message': 'Use subunit colorizer from nova for run_tests.sh\n\nThis commit copies the colorizer.py script over from nova and enables\nit for testr with run_tests.sh. This enables real time output from\ntestr about which tests ran and the result with colors.\n\nChange-Id: Idd1b820d103bf4d71f2645e98e86e5fadbd6cb0c\n'}, {'number': 2, 'created': '2013-07-18 20:48:12.000000000', 'files': ['run_tests.sh', 'tools/colorizer.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0e2d8aaea4a2d5ebe199c88e44e7aaf6bede6c83', 'message': 'Use subunit colorizer from nova for run_tests.sh\n\nThis commit copies the colorizer.py script over from nova and enables\nit for testr with run_tests.sh. This enables real time output from\ntestr about which tests ran and the result with colors.\n\nChange-Id: Idd1b820d103bf4d71f2645e98e86e5fadbd6cb0c\n'}]",2,37757,0e2d8aaea4a2d5ebe199c88e44e7aaf6bede6c83,12,5,2,5196,,,0,"Use subunit colorizer from nova for run_tests.sh

This commit copies the colorizer.py script over from nova and enables
it for testr with run_tests.sh. This enables real time output from
testr about which tests ran and the result with colors.

Change-Id: Idd1b820d103bf4d71f2645e98e86e5fadbd6cb0c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/57/37757/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'tools/colorizer.py']",2,1981063c136e20c0d547aa041b28063fe7b681b0,testr-fixes,"#!/usr/bin/env python # vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright (c) 2013, Nebula, Inc. # Copyright 2010 United States Government as represented by the # Administrator of the National Aeronautics and Space Administration. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # Colorizer Code is borrowed from Twisted: # Copyright (c) 2001-2010 Twisted Matrix Laboratories. # # Permission is hereby granted, free of charge, to any person obtaining # a copy of this software and associated documentation files (the # ""Software""), to deal in the Software without restriction, including # without limitation the rights to use, copy, modify, merge, publish, # distribute, sublicense, and/or sell copies of the Software, and to # permit persons to whom the Software is furnished to do so, subject to # the following conditions: # # The above copyright notice and this permission notice shall be # included in all copies or substantial portions of the Software. # # THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, # EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF # MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND # NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE # LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION # WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. """"""Display a subunit stream through a colorized unittest test runner."""""" import heapq import subunit import sys import unittest import testtools class _AnsiColorizer(object): """""" A colorizer is an object that loosely wraps around a stream, allowing callers to write text to the stream in a particular color. Colorizer classes must implement C{supported()} and C{write(text, color)}. """""" _colors = dict(black=30, red=31, green=32, yellow=33, blue=34, magenta=35, cyan=36, white=37) def __init__(self, stream): self.stream = stream def supported(cls, stream=sys.stdout): """""" A class method that returns True if the current platform supports coloring terminal output using this method. Returns False otherwise. """""" if not stream.isatty(): return False # auto color only on TTYs try: import curses except ImportError: return False else: try: try: return curses.tigetnum(""colors"") > 2 except curses.error: curses.setupterm() return curses.tigetnum(""colors"") > 2 except Exception: # guess false in case of error return False supported = classmethod(supported) def write(self, text, color): """""" Write the given text to the stream in the given color. @param text: Text to be written to the stream. @param color: A string label for a color. e.g. 'red', 'white'. """""" color = self._colors[color] self.stream.write('\x1b[%s;1m%s\x1b[0m' % (color, text)) class _Win32Colorizer(object): """""" See _AnsiColorizer docstring. """""" def __init__(self, stream): import win32console red, green, blue, bold = (win32console.FOREGROUND_RED, win32console.FOREGROUND_GREEN, win32console.FOREGROUND_BLUE, win32console.FOREGROUND_INTENSITY) self.stream = stream self.screenBuffer = win32console.GetStdHandle( win32console.STD_OUT_HANDLE) self._colors = { 'normal': red | green | blue, 'red': red | bold, 'green': green | bold, 'blue': blue | bold, 'yellow': red | green | bold, 'magenta': red | blue | bold, 'cyan': green | blue | bold, 'white': red | green | blue | bold } def supported(cls, stream=sys.stdout): try: import win32console screenBuffer = win32console.GetStdHandle( win32console.STD_OUT_HANDLE) except ImportError: return False import pywintypes try: screenBuffer.SetConsoleTextAttribute( win32console.FOREGROUND_RED | win32console.FOREGROUND_GREEN | win32console.FOREGROUND_BLUE) except pywintypes.error: return False else: return True supported = classmethod(supported) def write(self, text, color): color = self._colors[color] self.screenBuffer.SetConsoleTextAttribute(color) self.stream.write(text) self.screenBuffer.SetConsoleTextAttribute(self._colors['normal']) class _NullColorizer(object): """""" See _AnsiColorizer docstring. """""" def __init__(self, stream): self.stream = stream def supported(cls, stream=sys.stdout): return True supported = classmethod(supported) def write(self, text, color): self.stream.write(text) def get_elapsed_time_color(elapsed_time): if elapsed_time > 1.0: return 'red' elif elapsed_time > 0.25: return 'yellow' else: return 'green' class NovaTestResult(testtools.TestResult): def __init__(self, stream, descriptions, verbosity): super(NovaTestResult, self).__init__() self.stream = stream self.showAll = verbosity > 1 self.num_slow_tests = 10 self.slow_tests = [] # this is a fixed-sized heap self.colorizer = None # NOTE(vish): reset stdout for the terminal check stdout = sys.stdout sys.stdout = sys.__stdout__ for colorizer in [_Win32Colorizer, _AnsiColorizer, _NullColorizer]: if colorizer.supported(): self.colorizer = colorizer(self.stream) break sys.stdout = stdout self.start_time = None self.last_time = {} self.results = {} self.last_written = None def _writeElapsedTime(self, elapsed): color = get_elapsed_time_color(elapsed) self.colorizer.write("" %.2f"" % elapsed, color) def _addResult(self, test, *args): try: name = test.id() except AttributeError: name = 'Unknown.unknown' test_class, test_name = name.rsplit('.', 1) elapsed = (self._now() - self.start_time).total_seconds() item = (elapsed, test_class, test_name) if len(self.slow_tests) >= self.num_slow_tests: heapq.heappushpop(self.slow_tests, item) else: heapq.heappush(self.slow_tests, item) self.results.setdefault(test_class, []) self.results[test_class].append((test_name, elapsed) + args) self.last_time[test_class] = self._now() self.writeTests() def _writeResult(self, test_name, elapsed, long_result, color, short_result, success): if self.showAll: self.stream.write(' %s' % str(test_name).ljust(66)) self.colorizer.write(long_result, color) if success: self._writeElapsedTime(elapsed) self.stream.writeln() else: self.colorizer.write(short_result, color) def addSuccess(self, test): super(NovaTestResult, self).addSuccess(test) self._addResult(test, 'OK', 'green', '.', True) def addFailure(self, test, err): if test.id() == 'process-returncode': return super(NovaTestResult, self).addFailure(test, err) self._addResult(test, 'FAIL', 'red', 'F', False) def addError(self, test, err): super(NovaTestResult, self).addFailure(test, err) self._addResult(test, 'ERROR', 'red', 'E', False) def addSkip(self, test, reason=None, details=None): super(NovaTestResult, self).addSkip(test, reason, details) self._addResult(test, 'SKIP', 'blue', 'S', True) def startTest(self, test): self.start_time = self._now() super(NovaTestResult, self).startTest(test) def writeTestCase(self, cls): if not self.results.get(cls): return if cls != self.last_written: self.colorizer.write(cls, 'white') self.stream.writeln() for result in self.results[cls]: self._writeResult(*result) del self.results[cls] self.stream.flush() self.last_written = cls def writeTests(self): time = self.last_time.get(self.last_written, self._now()) if not self.last_written or (self._now() - time).total_seconds() > 2.0: diff = 3.0 while diff > 2.0: classes = self.results.keys() oldest = min(classes, key=lambda x: self.last_time[x]) diff = (self._now() - self.last_time[oldest]).total_seconds() self.writeTestCase(oldest) else: self.writeTestCase(self.last_written) def done(self): self.stopTestRun() def stopTestRun(self): for cls in list(self.results.iterkeys()): self.writeTestCase(cls) self.stream.writeln() self.writeSlowTests() def writeSlowTests(self): # Pare out 'fast' tests slow_tests = [item for item in self.slow_tests if get_elapsed_time_color(item[0]) != 'green'] if slow_tests: slow_total_time = sum(item[0] for item in slow_tests) slow = (""Slowest %i tests took %.2f secs:"" % (len(slow_tests), slow_total_time)) self.colorizer.write(slow, 'yellow') self.stream.writeln() last_cls = None # sort by name for elapsed, cls, name in sorted(slow_tests, key=lambda x: x[1] + x[2]): if cls != last_cls: self.colorizer.write(cls, 'white') self.stream.writeln() last_cls = cls self.stream.write(' %s' % str(name).ljust(68)) self._writeElapsedTime(elapsed) self.stream.writeln() def printErrors(self): if self.showAll: self.stream.writeln() self.printErrorList('ERROR', self.errors) self.printErrorList('FAIL', self.failures) def printErrorList(self, flavor, errors): for test, err in errors: self.colorizer.write(""="" * 70, 'red') self.stream.writeln() self.colorizer.write(flavor, 'red') self.stream.writeln("": %s"" % test.id()) self.colorizer.write(""-"" * 70, 'red') self.stream.writeln() self.stream.writeln(""%s"" % err) test = subunit.ProtocolTestCase(sys.stdin, passthrough=None) if sys.version_info[0:2] <= (2, 6): runner = unittest.TextTestRunner(verbosity=2) else: runner = unittest.TextTestRunner(verbosity=2, resultclass=NovaTestResult) if runner.run(test).wasSuccessful(): exit_code = 0 else: exit_code = 1 sys.exit(exit_code) ",,336,1
openstack%2Fnova~master~I882311c8a9f9df927c5650946e6398eeb33e74d0,openstack/nova,master,I882311c8a9f9df927c5650946e6398eeb33e74d0,Make InfoCache.network_info be the network model,MERGED,2013-07-11 19:19:38.000000000,2013-07-22 15:30:33.000000000,2013-07-22 15:30:30.000000000,"[{'_account_id': 3}, {'_account_id': 191}, {'_account_id': 642}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 4393}]","[{'number': 1, 'created': '2013-07-11 19:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea4829553e5e3411e9ae00bf67662a7cac9a99eb', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}, {'number': 2, 'created': '2013-07-11 19:28:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0e7286cba96fd0aac8a6745c8346f9530d15cba', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}, {'number': 3, 'created': '2013-07-11 22:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f150a04ac899a6afeb81d741d6aef05387ac2eb', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nThere's also a small issue with the get_by_instance_uuid() method that\nwould cause a traceback when no entry was found.  This method is not\nbeing used yet anywhere, but this is fixed to raise a NotFound.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}, {'number': 4, 'created': '2013-07-11 22:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/200657803a402e994ead192578e2478ebd9d6fdd', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nThere's also a small issue with the get_by_instance_uuid() method that\nwould cause a traceback when no entry was found.  This method is not\nbeing used yet anywhere, but this is fixed to raise a NotFound.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}, {'number': 5, 'created': '2013-07-11 22:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dcb6e12188da0865fd1615b23650e9906d435b73', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nThere's also a small issue with the get_by_instance_uuid() method that\nwould cause a traceback when no entry was found.  This method is not\nbeing used yet anywhere, but this is fixed to raise a NotFound.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}, {'number': 6, 'created': '2013-07-12 01:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1fd4159f6a929ed4785db8ae527c7826f5e609c1', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nThere's also a small issue with the get_by_instance_uuid() method that\nwould cause a traceback when no entry was found.  This method is not\nbeing used yet anywhere, but this is fixed to raise a NotFound.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}, {'number': 7, 'created': '2013-07-12 21:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6ef53575317aa6318c9f1db63a606a6ea3012c9a', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nThere's also a small issue with the get_by_instance_uuid() method that\nwould cause a traceback when no entry was found.  This method is not\nbeing used yet anywhere, but this is fixed to raise a NotFound.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}, {'number': 8, 'created': '2013-07-17 01:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/439d4b22dab07653c7d0663bd946abdc275e23f2', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nThere's also a small issue with the get_by_instance_uuid() method that\nwould cause a traceback when no entry was found.  This method is not\nbeing used yet anywhere, but this is fixed to raise a NotFound.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}, {'number': 9, 'created': '2013-07-17 16:31:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2864db39f4257e44c85517e48d1b5bc6d4c81e7d', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nThere's also a small issue with the get_by_instance_uuid() method that\nwould cause a traceback when no entry was found.  This method is not\nbeing used yet anywhere, but this is fixed to raise a NotFound.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}, {'number': 10, 'created': '2013-07-17 16:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90d6e7329320e6e76918146916223252ccea0d93', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nThere's also a small issue with the get_by_instance_uuid() method that\nwould cause a traceback when no entry was found.  This method is not\nbeing used yet anywhere, but this is fixed to raise a NotFound.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}, {'number': 11, 'created': '2013-07-17 23:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f118fef91468fff3be6fbb57a348b740733eb51e', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nThere's also a small issue with the get_by_instance_uuid() method that\nwould cause a traceback when no entry was found.  This method is not\nbeing used yet anywhere, but this is fixed to raise a NotFound.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}, {'number': 12, 'created': '2013-07-18 17:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/af64359e4e7d9700f1c700a68b9f9f4bf5e24966', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nThere's also a small issue with the get_by_instance_uuid() method that\nwould cause a traceback when no entry was found.  This method is not\nbeing used yet anywhere, but this is fixed to raise a NotFound.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}, {'number': 13, 'created': '2013-07-18 18:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e112d430693fcadb80f9f4d08079076ec4376b20', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nThere's also a small issue with the get_by_instance_uuid() method that\nwould cause a traceback when no entry was found.  This method is not\nbeing used yet anywhere, but this is fixed to raise a NotFound.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}, {'number': 14, 'created': '2013-07-22 14:21:38.000000000', 'files': ['nova/tests/objects/test_instance.py', 'nova/notifications.py', 'nova/tests/objects/test_instance_info_cache.py', 'nova/objects/utils.py', 'nova/api/ec2/ec2utils.py', 'nova/tests/api/openstack/compute/contrib/test_server_start_stop.py', 'nova/objects/instance_info_cache.py', 'nova/compute/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5701c4e5a8123f7dfda4337340055cea4097c614', 'message': ""Make InfoCache.network_info be the network model\n\nInstead of storing the DB version of network_info (which is a JSON\nversion of network.model.NetworkInfo) on the object, go ahead and turn\nit into its native object as well.  This means that all uses of the\nobject don't need to worry about hydrating network_info themselves.\n\nThis adjusts all uses in the code understand the old and new ways of\nlife.\n\nThere's also a small issue with the get_by_instance_uuid() method that\nwould cause a traceback when no entry was found.  This method is not\nbeing used yet anywhere, but this is fixed to raise a NotFound.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0\n""}]",2,36718,5701c4e5a8123f7dfda4337340055cea4097c614,66,8,14,1030,,,0,"Make InfoCache.network_info be the network model

Instead of storing the DB version of network_info (which is a JSON
version of network.model.NetworkInfo) on the object, go ahead and turn
it into its native object as well.  This means that all uses of the
object don't need to worry about hydrating network_info themselves.

This adjusts all uses in the code understand the old and new ways of
life.

There's also a small issue with the get_by_instance_uuid() method that
would cause a traceback when no entry was found.  This method is not
being used yet anywhere, but this is fixed to raise a NotFound.

Related to blueprint unified-object-model

Change-Id: I882311c8a9f9df927c5650946e6398eeb33e74d0
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/36718/11 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/objects/test_instance.py', 'nova/notifications.py', 'nova/tests/objects/test_instance_info_cache.py', 'nova/objects/utils.py', 'nova/api/ec2/ec2utils.py', 'nova/tests/api/openstack/compute/contrib/test_server_start_stop.py', 'nova/compute/utils.py', 'nova/objects/instance_info_cache.py']",8,ea4829553e5e3411e9ae00bf67662a7cac9a99eb,bp/compute-api-objects," VERSION = '1.1' # Version 1.0: Initial version # Version 1.1: Converted network_info to store the model. 'network_info': utils.network_model_or_none, nw_info_json = self.network_info.json() {'network_info': nw_info_json})"," 'network_info': utils.str_or_none, {'network_info': self.network_info})",73,30
openstack%2Fnova~master~I6c2c2dc6dedf521ed7b0c566411d6f0035038b7c,openstack/nova,master,I6c2c2dc6dedf521ed7b0c566411d6f0035038b7c,Make shelve pass old-world instance object to conductor,MERGED,2013-07-17 16:31:11.000000000,2013-07-22 15:30:19.000000000,2013-07-22 15:30:17.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-17 16:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/43db6c5cde2a1bfdf9a0d5500f13179c0c72bebd', 'message': ""Make shelve pass old-world instance object to conductor\n\nThe conductor interface for notify_usage_exists() doesn't yet\nwork with a new-world object, so convert it with the compatibility\nfunction before passing it from shelve().\n\nRelated to blueprint unified-object-model\n\nChange-Id: I6c2c2dc6dedf521ed7b0c566411d6f0035038b7c\n""}, {'number': 2, 'created': '2013-07-17 16:46:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7584ab5838b205d14bc506c4ffd0e229170bbd86', 'message': ""Make shelve pass old-world instance object to conductor\n\nThe conductor interface for notify_usage_exists() doesn't yet\nwork with a new-world object, so convert it with the compatibility\nfunction before passing it from shelve().\n\nRelated to blueprint unified-object-model\n\nChange-Id: I6c2c2dc6dedf521ed7b0c566411d6f0035038b7c\n""}, {'number': 3, 'created': '2013-07-17 23:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e831e48bf3c431ca8fa1078ba791b3737bf3107', 'message': ""Make shelve pass old-world instance object to conductor\n\nThe conductor interface for notify_usage_exists() doesn't yet\nwork with a new-world object, so convert it with the compatibility\nfunction before passing it from shelve().\n\nRelated to blueprint unified-object-model\n\nChange-Id: I6c2c2dc6dedf521ed7b0c566411d6f0035038b7c\n""}, {'number': 4, 'created': '2013-07-18 17:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b314689ac1dee7e4d123401124d14ca7ee00e61f', 'message': ""Make shelve pass old-world instance object to conductor\n\nThe conductor interface for notify_usage_exists() doesn't yet\nwork with a new-world object, so convert it with the compatibility\nfunction before passing it from shelve().\n\nRelated to blueprint unified-object-model\n\nChange-Id: I6c2c2dc6dedf521ed7b0c566411d6f0035038b7c\n""}, {'number': 5, 'created': '2013-07-18 18:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d80b0b294685cca48bad553b53c09518fda2441d', 'message': ""Make shelve pass old-world instance object to conductor\n\nThe conductor interface for notify_usage_exists() doesn't yet\nwork with a new-world object, so convert it with the compatibility\nfunction before passing it from shelve().\n\nRelated to blueprint unified-object-model\n\nChange-Id: I6c2c2dc6dedf521ed7b0c566411d6f0035038b7c\n""}, {'number': 6, 'created': '2013-07-22 14:21:35.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/96a5baf673d2a7ebbc18e6fd2c7cab34db68132b', 'message': ""Make shelve pass old-world instance object to conductor\n\nThe conductor interface for notify_usage_exists() doesn't yet\nwork with a new-world object, so convert it with the compatibility\nfunction before passing it from shelve().\n\nRelated to blueprint unified-object-model\n\nChange-Id: I6c2c2dc6dedf521ed7b0c566411d6f0035038b7c\n""}]",0,37521,96a5baf673d2a7ebbc18e6fd2c7cab34db68132b,39,7,6,4393,,,0,"Make shelve pass old-world instance object to conductor

The conductor interface for notify_usage_exists() doesn't yet
work with a new-world object, so convert it with the compatibility
function before passing it from shelve().

Related to blueprint unified-object-model

Change-Id: I6c2c2dc6dedf521ed7b0c566411d6f0035038b7c
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/37521/5 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,43db6c5cde2a1bfdf9a0d5500f13179c0c72bebd,bp/compute-api-objects," self.conductor_api.notify_usage_exists( context, obj_base.obj_to_primitive(instance), current_period=True)"," self.conductor_api.notify_usage_exists(context, instance, current_period=True)",3,2
openstack%2Fnova~master~I28d1ca9d711679cc55375774e879870f457a5b0b,openstack/nova,master,I28d1ca9d711679cc55375774e879870f457a5b0b,Make admin API state resets use Instance.save(),MERGED,2013-07-04 00:26:35.000000000,2013-07-22 15:18:38.000000000,2013-07-22 15:18:36.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-04 00:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da22df834930d35df14ff74ab6104859fe3d6cf0', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 2, 'created': '2013-07-05 23:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ee21a0b585de2ece45043798953cc83f39acd39', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 3, 'created': '2013-07-05 23:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a15e750f19367b955fc562345c7dfb6625dfa256', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 4, 'created': '2013-07-05 23:31:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/908e988b2d8eb35174851d7eebe4472496a12775', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 5, 'created': '2013-07-08 17:18:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c2ef3c86f1c41734d632c5b7de8512a33736c71e', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 6, 'created': '2013-07-08 20:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5dcb851f5d85d8f0eff99bddaff2fa4ebfa4a331', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 7, 'created': '2013-07-08 20:42:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/26be033b968f4926da74e85ac9b86b60cd095a5a', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 8, 'created': '2013-07-08 22:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/52425a0f08e16f6c066eacaad716a64e283bb349', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 9, 'created': '2013-07-09 23:09:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7bf9a772521041291706bac54072832f068356f6', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 10, 'created': '2013-07-10 20:19:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b29baa31f8d7accd9d60b69a953888d6b48906ae', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 11, 'created': '2013-07-10 23:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a1299380007b5c3e31852490b7c099cde3b1419', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 12, 'created': '2013-07-10 23:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/395f8b71746d07e6b2494702840d2ca7822ea8c9', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 13, 'created': '2013-07-11 00:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37a033c64cc8bdb97877564e070eb41fd58396f0', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 14, 'created': '2013-07-11 05:56:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/430409b5a3bfa488a8c2e0d5d3f5dcdef07d58ad', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 15, 'created': '2013-07-11 17:02:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f969b59ea7340f31022c1ca96f7694d865611e5', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 16, 'created': '2013-07-11 19:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e6b2b04dad23bc03f3c261c4102194230ad379be', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 17, 'created': '2013-07-11 22:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9703f2ce13c46152b4bde583b72f7edf3b359181', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 18, 'created': '2013-07-11 22:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e3c083e6dfd5366ff81013fbf24c1702ac74a317', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 19, 'created': '2013-07-12 01:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4d4294c56372fc53153c2d5223292419a106074', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 20, 'created': '2013-07-12 21:10:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62490ab8bab897334d54e1b61b999dd44ccb5ef6', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 21, 'created': '2013-07-17 01:57:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6ab7848df6d4322b836523029efe9e70dff14c3e', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 22, 'created': '2013-07-17 16:31:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fcfd649471b6c7fd7474ac8a6aa2ed4ed424c575', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 23, 'created': '2013-07-17 23:22:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e7e90c8769aefe35e17f5459516adc3c97c0c96', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 24, 'created': '2013-07-18 17:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0284dd3dfb7c3221a7a247532647203f06b34c9', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 25, 'created': '2013-07-18 18:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/329d8a1cfed58254df32d0e3e1b2505a3fb4701d', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}, {'number': 26, 'created': '2013-07-22 14:21:37.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/admin_actions.py', 'nova/tests/api/openstack/compute/contrib/test_admin_actions.py', 'nova/tests/api/openstack/compute/contrib/test_admin_actions_with_cells.py', 'nova/compute/cells_api.py', 'nova/tests/api/openstack/compute/plugins/v3/test_admin_actions.py', 'nova/api/openstack/compute/contrib/admin_actions.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cadd015cbdbe2760f948f366cb66cd5a9a22a2d9', 'message': ""Make admin API state resets use Instance.save()\n\nThis removes the 'update_state' compute API method in favor of having\nthe admin API use the Instance object's save() method.\n\nThis also removes the non-unity cells test for resetting state.  Cells\nbehavior is tested via tests on Instance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I28d1ca9d711679cc55375774e879870f457a5b0b\n""}]",2,35578,cadd015cbdbe2760f948f366cb66cd5a9a22a2d9,78,7,26,1030,,,0,"Make admin API state resets use Instance.save()

This removes the 'update_state' compute API method in favor of having
the admin API use the Instance object's save() method.

This also removes the non-unity cells test for resetting state.  Cells
behavior is tested via tests on Instance.save().

Related to blueprint compute-api-objects

Change-Id: I28d1ca9d711679cc55375774e879870f457a5b0b
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/35578/16 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/cells_api.py', 'nova/api/openstack/compute/contrib/admin_actions.py', 'nova/compute/api.py']",3,da22df834930d35df14ff74ab6104859fe3d6cf0,bp/compute-api-objects,," def update_state(self, context, instance, new_state): """"""Updates the state of a compute instance. For example to 'active' or 'error'. Also sets 'task_state' to None. Used by admin_actions api :param context: The security context :param instance: The instance to update :param new_state: A member of vm_state, eg. 'active' """""" self.update(context, instance, vm_state=new_state, task_state=None) ",10,44
openstack%2Fopenstack-manuals~master~I29a3c47c1a21e62e49d91ab092831c82136c1335,openstack/openstack-manuals,master,I29a3c47c1a21e62e49d91ab092831c82136c1335,Add swift-temp-url command usage example,MERGED,2013-07-22 13:07:47.000000000,2013-07-22 14:51:58.000000000,2013-07-22 14:51:58.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 3153}, {'_account_id': 6889}]","[{'number': 1, 'created': '2013-07-22 13:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3613fdfe17244ef671dc5e253b53829ab79580f4', 'message': 'Add swift-temp-url command usage example\n\nAdd in tempurl section of Additional features\na mention to swift-temp-url command\nand an usage example.\n\nChange-Id: I29a3c47c1a21e62e49d91ab092831c82136c1335\n'}, {'number': 2, 'created': '2013-07-22 14:46:35.000000000', 'files': ['doc/src/docbkx/openstack-object-storage-admin/objectstorageadmin.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/79d0d65ad849506d2d481418e19fb0607ec91788', 'message': 'Add swift-temp-url command usage example\n\nAdd in tempurl section of Additional features\na mention to swift-temp-url command\nand an usage example.\n\nChange-Id: I29a3c47c1a21e62e49d91ab092831c82136c1335\n'}]",0,38145,79d0d65ad849506d2d481418e19fb0607ec91788,7,4,2,6889,,,0,"Add swift-temp-url command usage example

Add in tempurl section of Additional features
a mention to swift-temp-url command
and an usage example.

Change-Id: I29a3c47c1a21e62e49d91ab092831c82136c1335
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/45/38145/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-object-storage-admin/objectstorageadmin.xml'],1,3613fdfe17244ef671dc5e253b53829ab79580f4,add-tempurl-cmd, <para>A script called swift-temp-url distributed with swift source code will ease the temporary url creation : <programlisting> $ bin/swift-temp-url GET 3600 /v1/AUTH_account/container/object mykey /v1/AUTH_account/container/object? temp_url_sig=5c4cc8886f36a9d0919d708ade98bf0cc71c9e91&amp; temp_url_expires=1374497657 </programlisting> The path returned by the above command must obviously be prefixed with swift storage hostname. </para>,,11,0
openstack%2Fmurano-dashboard~master~I35ff31af18bd55189f7f9f5f74e146806cae2c61,openstack/murano-dashboard,master,I35ff31af18bd55189f7f9f5f74e146806cae2c61,Set medium flavor as default,MERGED,2013-07-22 11:24:53.000000000,2013-07-22 14:35:17.000000000,2013-07-22 14:35:17.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7821}]","[{'number': 1, 'created': '2013-07-22 11:24:53.000000000', 'files': ['muranodashboard/panel/forms.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/12c68815441aa6d7973ef7e2debf4a0e0d1b3249', 'message': 'Set medium flavor as default\n\nChange-Id: I35ff31af18bd55189f7f9f5f74e146806cae2c61\n'}]",0,38134,12c68815441aa6d7973ef7e2debf4a0e0d1b3249,6,3,1,7549,,,0,"Set medium flavor as default

Change-Id: I35ff31af18bd55189f7f9f5f74e146806cae2c61
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/34/38134/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/panel/forms.py'],1,12c68815441aa6d7973ef7e2debf4a0e0d1b3249,," flavor_choices = [(flavor.name, flavor.name) for flavor in flavors] self.fields['flavor'].choices = flavor_choices for flavor in flavor_choices: if 'medium' in flavor[1]: self.fields['flavor'].initial = flavor[0] break "," self.fields['flavor'].choices = [(flavor.name, flavor.name) for flavor in flavors]",8,2
openstack%2Fopenstack-chef-repo~master~Ied901f470166a5548ea21bda81ac129381d8e783,openstack/openstack-chef-repo,master,Ied901f470166a5548ea21bda81ac129381d8e783,bugfix: os-ops-messaging role needs to call openstack-ops-messaging::server,ABANDONED,2013-07-20 02:19:46.000000000,2013-07-22 14:34:45.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1032}]","[{'number': 1, 'created': '2013-07-20 02:19:46.000000000', 'files': ['roles/os-ops-messaging.rb'], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/720c033b7bd561c45981ffafc93a6138835aceff', 'message': 'bugfix: os-ops-messaging role needs to call openstack-ops-messaging::server\n\nChange-Id: Ied901f470166a5548ea21bda81ac129381d8e783\n'}]",0,38010,720c033b7bd561c45981ffafc93a6138835aceff,5,3,1,7858,,,0,"bugfix: os-ops-messaging role needs to call openstack-ops-messaging::server

Change-Id: Ied901f470166a5548ea21bda81ac129381d8e783
",git fetch https://review.opendev.org/openstack/openstack-chef-repo refs/changes/10/38010/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/os-ops-messaging.rb'],1,720c033b7bd561c45981ffafc93a6138835aceff,fixrole," ""recipe[openstack-ops-messaging::server]"""," ""recipe[openstack-ops-messaging]""",1,1
openstack%2Fnova~master~Ice28b9d545f60f7df381e3fcf2c86a2b8e7350d3,openstack/nova,master,Ice28b9d545f60f7df381e3fcf2c86a2b8e7350d3,Sync db.models.Instance* with migrations.,MERGED,2013-06-25 13:29:11.000000000,2013-07-22 14:28:23.000000000,2013-07-22 14:28:21.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2270}, {'_account_id': 5652}, {'_account_id': 6507}]","[{'number': 1, 'created': '2013-06-25 13:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5d6a6339ec10e3fefd80e9a3254c22588a7da411', 'message': 'Sync db.models.Instance* with migrations.\n\nThis patch syncs models with migrations for:\n\t- InstanceIdMapping\n\t- InstanceMetadata\n\t- InstanceSystemMetadata\n\t- InstanceTypeExtraSpecs\n\t- InstanceTypeProjects\n\t- InstanceTypes\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: Ice28b9d545f60f7df381e3fcf2c86a2b8e7350d3\n'}, {'number': 2, 'created': '2013-07-10 08:53:00.000000000', 'files': ['nova/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ed7d159fac087eeb2ad377f29534d90cc073d353', 'message': 'Sync db.models.Instance* with migrations.\n\nThis patch syncs models with migrations for:\n    - InstanceIdMapping\n    - InstanceMetadata\n    - InstanceSystemMetadata\n    - InstanceTypeExtraSpecs\n    - InstanceTypeProjects\n    - InstanceTypes\n    - InstanceGroupMember\n    - InstanceGroupPolicy\n    - InstanceGroupMetadata\n\nBlueprint: db-sync-models-with-migrations\n\nChange-Id: Ice28b9d545f60f7df381e3fcf2c86a2b8e7350d3\n'}]",0,34394,ed7d159fac087eeb2ad377f29534d90cc073d353,12,7,2,6507,,,0,"Sync db.models.Instance* with migrations.

This patch syncs models with migrations for:
    - InstanceIdMapping
    - InstanceMetadata
    - InstanceSystemMetadata
    - InstanceTypeExtraSpecs
    - InstanceTypeProjects
    - InstanceTypes
    - InstanceGroupMember
    - InstanceGroupPolicy
    - InstanceGroupMetadata

Blueprint: db-sync-models-with-migrations

Change-Id: Ice28b9d545f60f7df381e3fcf2c86a2b8e7350d3
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/34394/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/models.py'],1,5d6a6339ec10e3fefd80e9a3254c22588a7da411,bp/db-sync-models-with-migrations," name = Column(String(255), nullable=True) memory_mb = Column(Integer, nullable=False) vcpus = Column(Integer, nullable=False) root_gb = Column(Integer, nullable=True) ephemeral_gb = Column(Integer, nullable=True) flavorid = Column(String(255), nullable=True) rxtx_factor = Column(Float, nullable=True, default=1) __table_args__ = ( Index('instance_metadata_instance_uuid_idx', 'instance_uuid'), ) key = Column(String(255), nullable=True) value = Column(String(255), nullable=True) nullable=True) __table_args__ = () key = Column(String(255), nullable=False) value = Column(String(255), nullable=True) project_id = Column(String(255), nullable=True) __table_args__ = ( Index('instance_type_extra_specs_instance_type_id_key_idx', 'instance_type_id', 'key'), ) key = Column(String(255), nullable=True) value = Column(String(255), nullable=True) __table_args__ = ( Index('ix_instance_id_mappings_uuid', 'uuid'), )"," name = Column(String(255)) memory_mb = Column(Integer) vcpus = Column(Integer) root_gb = Column(Integer) ephemeral_gb = Column(Integer) flavorid = Column(String(255)) rxtx_factor = Column(Float, nullable=False, default=1) key = Column(String(255)) value = Column(String(255)) nullable=False) key = Column(String(255)) value = Column(String(255)) project_id = Column(String(255)) key = Column(String(255)) value = Column(String(255))",26,15
openstack%2Fopenstack-chef-repo~master~I97990591437d23b5142470f0300fafcbb8bdd56d,openstack/openstack-chef-repo,master,I97990591437d23b5142470f0300fafcbb8bdd56d,os-ops-messaging points to missing default recipe,MERGED,2013-07-17 21:36:39.000000000,2013-07-22 14:15:25.000000000,2013-07-22 14:15:25.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1032}]","[{'number': 1, 'created': '2013-07-17 21:36:39.000000000', 'files': ['roles/os-ops-messaging.rb'], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/1d69ea3d745d4350b4650bb091c16ece6e359297', 'message': 'os-ops-messaging points to missing default recipe\n\nFixes bug 1202400\n\nChange-Id: I97990591437d23b5142470f0300fafcbb8bdd56d\n'}]",0,37578,1d69ea3d745d4350b4650bb091c16ece6e359297,6,3,1,4277,,,0,"os-ops-messaging points to missing default recipe

Fixes bug 1202400

Change-Id: I97990591437d23b5142470f0300fafcbb8bdd56d
",git fetch https://review.opendev.org/openstack/openstack-chef-repo refs/changes/78/37578/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/os-ops-messaging.rb'],1,1d69ea3d745d4350b4650bb091c16ece6e359297,bug/1202400," ""recipe[openstack-ops-messaging::server]"""," ""recipe[openstack-ops-messaging]""",1,1
openstack%2Fopenstack-manuals~master~I47dc830933cc41f804d9b80b9f192d620b0fdcc2,openstack/openstack-manuals,master,I47dc830933cc41f804d9b80b9f192d620b0fdcc2,misspelled word fix (harware -> hardware),MERGED,2013-07-20 03:24:27.000000000,2013-07-22 14:12:39.000000000,2013-07-22 14:12:39.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6772}, {'_account_id': 8217}]","[{'number': 1, 'created': '2013-07-20 03:24:27.000000000', 'files': ['doc/src/docbkx/openstack-install/compute-sys-requirements.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/418900ceb9dd2765d784505190e620aa21007964', 'message': 'misspelled word fix (harware -> hardware)\n\nChange-Id: I47dc830933cc41f804d9b80b9f192d620b0fdcc2\n'}]",0,38016,418900ceb9dd2765d784505190e620aa21007964,7,4,1,8217,,,0,"misspelled word fix (harware -> hardware)

Change-Id: I47dc830933cc41f804d9b80b9f192d620b0fdcc2
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/16/38016/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-install/compute-sys-requirements.xml'],1,418900ceb9dd2765d784505190e620aa21007964,typo_fix, XenServer hardware compatibility list</link>.</para>, XenServer harware compatibility list</link>.</para>,1,1
openstack%2Fsahara-extra~master~I3f7662d9e6561900ca64a15778c6304c0679acbd,openstack/sahara-extra,master,I3f7662d9e6561900ca64a15778c6304c0679acbd,Change in 'root-passwd' element.,ABANDONED,2013-07-22 11:58:54.000000000,2013-07-22 13:43:10.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7555}, {'_account_id': 7732}]","[{'number': 1, 'created': '2013-07-22 11:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-extra/commit/f40f13ecf88f367fd34b6ce30af1aeb597c3277c', 'message': ""Change in 'root-passwd' element.\n* setup password using parameter 'DIB_PASSWORD'\n* add possibility to login as root\n\nChange-Id: I3f7662d9e6561900ca64a15778c6304c0679acbd\nFixes: big #1199970\n""}, {'number': 2, 'created': '2013-07-22 12:28:05.000000000', 'files': ['elements/root-passwd/post-install.d/99-setup'], 'web_link': 'https://opendev.org/openstack/sahara-extra/commit/b0d33c6cde7d9e96fc0816bcd2c4a9d49479a53a', 'message': ""Change in 'root-passwd' element.\n\n* setup password using parameter 'DIB_PASSWORD'\n* add possibility to login as root\n\nChange-Id: I3f7662d9e6561900ca64a15778c6304c0679acbd\nFixes: big #1199970\n""}]",1,38136,b0d33c6cde7d9e96fc0816bcd2c4a9d49479a53a,10,4,2,7732,,,0,"Change in 'root-passwd' element.

* setup password using parameter 'DIB_PASSWORD'
* add possibility to login as root

Change-Id: I3f7662d9e6561900ca64a15778c6304c0679acbd
Fixes: big #1199970
",git fetch https://review.opendev.org/openstack/sahara-extra refs/changes/36/38136/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/root-passwd/post-install.d/99-setup'],1,f40f13ecf88f367fd34b6ce30af1aeb597c3277c,master,"if [ -z ""$DIB_PASSWORD"" ]; then echo ""Error during setup password for root"" exit 1 fi install-packages augeas-tools openssh-server openssh-client augtool -s set /files/etc/ssh/sshd_config/PasswordAuthentication yes augtool -s set /files/etc/ssh/sshd_config/PermitRootLogin yes echo -e ""$DIB_PASSWORD\n$DIB_PASSWORD\n"" | passwd","echo ""Setting up root password"" echo -e ""swordfish\nswordfish\n"" | passwd",8,2
openstack%2Fheat~master~Idc00ccbd254aca2c64c1bcb376fe7a3aab4d1cb4,openstack/heat,master,Idc00ccbd254aca2c64c1bcb376fe7a3aab4d1cb4,Migrate all tests to use dummy_context.,MERGED,2013-07-18 01:48:14.000000000,2013-07-22 13:39:37.000000000,2013-07-22 13:39:37.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-18 01:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/85b582d1168ba88489826713d8ea24846e137552', 'message': 'Migrate all tests to use dummy_context.\n\nChange-Id: Idc00ccbd254aca2c64c1bcb376fe7a3aab4d1cb4\n'}, {'number': 2, 'created': '2013-07-18 20:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5e43f56bfedd74d3d7d59af77f41d73a46cc53b9', 'message': 'Migrate all tests to use dummy_context.\n\nChange-Id: Idc00ccbd254aca2c64c1bcb376fe7a3aab4d1cb4\n'}, {'number': 3, 'created': '2013-07-18 21:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/24bb26aa3947959fc7fd67ecefdfc75c828c7d2f', 'message': 'Migrate all tests to use dummy_context.\n\nChange-Id: Idc00ccbd254aca2c64c1bcb376fe7a3aab4d1cb4\n'}, {'number': 4, 'created': '2013-07-21 23:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/597cea4ddc2ba96139afd3ac15fada7c1c591714', 'message': 'Migrate all tests to use dummy_context.\n\nChange-Id: Idc00ccbd254aca2c64c1bcb376fe7a3aab4d1cb4\n'}, {'number': 5, 'created': '2013-07-22 00:42:03.000000000', 'files': ['heat/tests/test_nested_stack.py', 'heat/tests/test_parser.py', 'heat/tests/test_security_group.py', 'heat/tests/test_api_cloudwatch.py', 'heat/tests/test_engine_service.py', 'heat/tests/test_validate.py', 'heat/tests/test_clouddatabase.py', 'heat/tests/test_event.py', 'heat/tests/test_api_cfn_v1.py', 'heat/tests/test_heatclient.py', 'heat/tests/test_vpc.py', 'heat/tests/test_instance.py', 'heat/tests/test_waitcondition.py', 'heat/tests/test_provider_template.py', 'heat/tests/test_api_openstack_v1.py', 'heat/tests/test_common_policy.py', 'heat/tests/test_stack_resource.py', 'heat/tests/test_resource.py', 'heat/tests/test_metadata_refresh.py', 'heat/tests/test_rpc_client.py', 'heat/tests/test_watch.py', 'heat/tests/test_server_tags.py', 'heat/tests/test_instance_network.py', 'heat/tests/test_sqlalchemy_api.py', 'heat/tests/test_engine_api_utils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/44a101737fec6e2a9648d35593a091cf8ce3b243', 'message': 'Migrate all tests to use dummy_context.\n\nChange-Id: Idc00ccbd254aca2c64c1bcb376fe7a3aab4d1cb4\n'}]",2,37603,44a101737fec6e2a9648d35593a091cf8ce3b243,25,5,5,4571,,,0,"Migrate all tests to use dummy_context.

Change-Id: Idc00ccbd254aca2c64c1bcb376fe7a3aab4d1cb4
",git fetch https://review.opendev.org/openstack/heat refs/changes/03/37603/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_nested_stack.py', 'heat/tests/test_parser.py', 'heat/tests/test_security_group.py', 'heat/tests/test_api_cloudwatch.py', 'heat/tests/test_engine_service.py', 'heat/tests/test_validate.py', 'heat/tests/test_clouddatabase.py', 'heat/tests/test_event.py', 'heat/tests/test_api_cfn_v1.py', 'heat/tests/test_heatclient.py', 'heat/tests/test_vpc.py', 'heat/tests/test_instance.py', 'heat/tests/test_waitcondition.py', 'heat/tests/test_provider_template.py', 'heat/tests/test_api_openstack_v1.py', 'heat/tests/test_common_policy.py', 'heat/tests/test_stack_resource.py', 'heat/tests/test_resource.py', 'heat/tests/test_metadata_refresh.py', 'heat/tests/test_rpc_client.py', 'heat/tests/test_watch.py', 'heat/tests/test_server_tags.py', 'heat/tests/test_instance_network.py', 'heat/tests/test_sqlalchemy_api.py', 'heat/tests/test_engine_api_utils.py']",25,85b582d1168ba88489826713d8ea24846e137552,bp/auth-token-only,"from heat.tests.utils import dummy_context self.stack = parser.Stack(dummy_context(), 'test_stack', template,","from heat.common import context ctx = context.get_admin_context() self.m.StubOutWithMock(ctx, 'user') ctx.user = 'test_user' ctx.tenant_id = 'test_tenant' self.stack = parser.Stack(ctx, 'test_stack', template,",132,178
openstack%2Fmurano-dashboard~master~I657f49208e7e18ce9eb65d2effbe5f9f6fd0b4e3,openstack/murano-dashboard,master,I657f49208e7e18ce9eb65d2effbe5f9f6fd0b4e3,Minor UI changes,MERGED,2013-07-22 12:54:23.000000000,2013-07-22 13:05:56.000000000,2013-07-22 13:05:56.000000000,"[{'_account_id': 3}, {'_account_id': 7549}, {'_account_id': 7821}]","[{'number': 1, 'created': '2013-07-22 12:54:23.000000000', 'files': ['muranodashboard/panel/api.py', 'muranodashboard/templates/_service_logs.html', 'muranodashboard/panel/tables.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ba04ab53cf334b13fe0569e026eb45fb34d53c14', 'message': 'Minor UI changes\n\nDeployment Configuration now shows human-readable service Type\nService Logs panel now contains timestamps and is  properly formatted\n\nChange-Id: I657f49208e7e18ce9eb65d2effbe5f9f6fd0b4e3\n'}]",1,38143,ba04ab53cf334b13fe0569e026eb45fb34d53c14,8,3,1,8127,,,0,"Minor UI changes

Deployment Configuration now shows human-readable service Type
Service Logs panel now contains timestamps and is  properly formatted

Change-Id: I657f49208e7e18ce9eb65d2effbe5f9f6fd0b4e3
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/43/38143/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/panel/api.py', 'muranodashboard/templates/_service_logs.html', 'muranodashboard/panel/tables.py']",3,ba04ab53cf334b13fe0569e026eb45fb34d53c14,," _type = tables.Column('full_service_name',"," _type = tables.Column('type',",10,6
openstack%2Fnova~master~Ia63f6cd947c20a05e84385f2401d6b869ebeb456,openstack/nova,master,Ia63f6cd947c20a05e84385f2401d6b869ebeb456,Add expected_errors for extension deferred_delete v3,MERGED,2013-07-17 06:18:27.000000000,2013-07-22 12:53:39.000000000,2013-07-22 12:53:37.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 5174}, {'_account_id': 5292}]","[{'number': 1, 'created': '2013-07-17 06:18:27.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/deferred_delete.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f87cf68844f81a3958d366f953670dba8b5d7176', 'message': 'Add expected_errors for extension deferred_delete v3\n\nPartially implements bp v3-api-extension-versioning\n\nChange-Id: Ia63f6cd947c20a05e84385f2401d6b869ebeb456\n'}]",0,37403,f87cf68844f81a3958d366f953670dba8b5d7176,9,6,1,5754,,,0,"Add expected_errors for extension deferred_delete v3

Partially implements bp v3-api-extension-versioning

Change-Id: Ia63f6cd947c20a05e84385f2401d6b869ebeb456
",git fetch https://review.opendev.org/openstack/nova refs/changes/03/37403/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/plugins/v3/deferred_delete.py'],1,f87cf68844f81a3958d366f953670dba8b5d7176,bp/v3-api-extension-versioning," @extensions.expected_errors((404, 409, 413)) @extensions.expected_errors((404, 409))",,2,0
openstack%2Fnova~master~Idf92a043e8451626a62a651aa532c9ba1e614057,openstack/nova,master,Idf92a043e8451626a62a651aa532c9ba1e614057,Correct the action name for admin_actions API v3,MERGED,2013-06-26 07:24:18.000000000,2013-07-22 12:42:33.000000000,2013-07-22 12:42:31.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 964}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 5754}]","[{'number': 1, 'created': '2013-06-26 07:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d14e0b10e483f8bdeaee0ad811ae58bea0fd134d', 'message': 'Correct the action name for admin_actions API v3\n\nPartially implements bp v3-api-extension-versioning\n\nChange-Id: Idf92a043e8451626a62a651aa532c9ba1e614057\n'}, {'number': 2, 'created': '2013-07-08 12:07:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/153c2700121eb6f66bc5c2e7a0e95e1f26a92a21', 'message': 'Correct the action name for admin_actions API v3\n\nPartially implements bp v3-api-extension-versioning\n\nChange-Id: Idf92a043e8451626a62a651aa532c9ba1e614057\n'}, {'number': 3, 'created': '2013-07-09 02:48:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/75456b18d34d40b747cd1204547150a6ca532d4b', 'message': 'Correct the action name for admin_actions API v3\n\nPartially implements bp v3-api-extension-versioning\n\nChange-Id: Idf92a043e8451626a62a651aa532c9ba1e614057\n'}, {'number': 4, 'created': '2013-07-15 13:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a6693a5643980fab48baf752011815120fdfcb5', 'message': 'Correct the action name for admin_actions API v3\n\nPartially implements bp v3-api-extension-versioning\n\nChange-Id: Idf92a043e8451626a62a651aa532c9ba1e614057\n'}, {'number': 5, 'created': '2013-07-15 14:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3db23ccb86f4e4f6c94e92fbdaba6e373d339a5', 'message': 'Correct the action name for admin_actions API v3\n\nPartially implements bp v3-api-extension-versioning\n\nChange-Id: Idf92a043e8451626a62a651aa532c9ba1e614057\n'}, {'number': 6, 'created': '2013-07-22 08:32:09.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/admin_actions.py', 'nova/tests/api/openstack/compute/plugins/v3/test_admin_actions.py', 'etc/nova/policy.json', 'nova/tests/fake_policy.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1f97e47920939058eeb5059b67013fe5a70ec6fd', 'message': 'Correct the action name for admin_actions API v3\n\nPartially implements bp v3-api-extension-versioning\n\nDocImpact\n\nChange-Id: Idf92a043e8451626a62a651aa532c9ba1e614057\n'}]",0,34504,1f97e47920939058eeb5059b67013fe5a70ec6fd,39,9,6,5754,,,0,"Correct the action name for admin_actions API v3

Partially implements bp v3-api-extension-versioning

DocImpact

Change-Id: Idf92a043e8451626a62a651aa532c9ba1e614057
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/34504/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/admin_actions.py', 'nova/tests/api/openstack/compute/plugins/v3/test_admin_actions.py', 'etc/nova/policy.json', 'nova/tests/fake_policy.py']",4,d14e0b10e483f8bdeaee0ad811ae58bea0fd134d,bp/v3-api-extension-versioning," ""compute_extension:v3:os-admin-actions:reset_network"": """", ""compute_extension:v3:os-admin-actions:inject_network_info"": """", ""compute_extension:v3:os-admin-actions:create_backup"": """", ""compute_extension:v3:os-admin-actions:migrate_live"": """", ""compute_extension:v3:os-admin-actions:reset_state"": """","," ""compute_extension:v3:os-admin-actions:resetNetwork"": """", ""compute_extension:v3:os-admin-actions:injectNetworkInfo"": """", ""compute_extension:v3:os-admin-actions:createBackup"": """", ""compute_extension:v3:os-admin-actions:migrateLive"": """", ""compute_extension:v3:os-admin-actions:resetState"": """",",52,54
openstack%2Ftempest~master~Id894fc29ce2635f1f058290d93726e789c909a86,openstack/tempest,master,Id894fc29ce2635f1f058290d93726e789c909a86,Add cinder_available config option.,MERGED,2013-07-16 20:14:55.000000000,2013-07-22 12:28:59.000000000,2013-07-22 12:28:59.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5292}, {'_account_id': 5803}, {'_account_id': 6731}]","[{'number': 1, 'created': '2013-07-16 20:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3c0c07acab38a7a493b8234ba560f789a702da36', 'message': 'Add cinder_available config option.\n\nThis commit adds a new config option cinder_available which is used\nto specify whether cinder is running or not. This replaces the check\nin the volume api tests for a cinder endpoint.\n\nChange-Id: Id894fc29ce2635f1f058290d93726e789c909a86\n'}, {'number': 2, 'created': '2013-07-17 17:59:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6a0e122c8917c1b065a11b4e4711b517ace5864b', 'message': 'Add cinder_available config option.\n\nThis commit adds a new config option cinder_available which is used\nto specify whether cinder is running or not. This replaces the check\nin the volume api tests for a cinder endpoint.\n\nChange-Id: Id894fc29ce2635f1f058290d93726e789c909a86\n'}, {'number': 3, 'created': '2013-07-18 20:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b3da3eee5b13844d7a29c13e633be2f69e15319f', 'message': 'Add cinder_available config option.\n\nThis commit adds a new config option cinder_available which is used\nto specify whether cinder is running or not. This replaces the check\nin the volume api tests for a cinder endpoint.\n\nChange-Id: Id894fc29ce2635f1f058290d93726e789c909a86\n'}, {'number': 4, 'created': '2013-07-19 21:02:44.000000000', 'files': ['tempest/api/compute/volumes/test_volumes_list.py', 'tempest/api/compute/volumes/test_volumes_get.py', 'etc/tempest.conf.sample', 'tempest/config.py', 'tempest/api/volume/base.py', 'tempest/api/compute/volumes/test_attach_volume.py', 'tempest/api/compute/volumes/test_volumes_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4c41292be4f83ccb70ea81ae5ecd445646bef19c', 'message': 'Add cinder_available config option.\n\nThis commit adds a new config group service_available that will be\nused to specify whether a particular OpenStack project is expected to\nbe running or not. This group is added with one member cinder which is\nused to specify whether cinder is running or not. This replaces the\ncheck in the volume api tests for a cinder endpoint.\n\nChange-Id: Id894fc29ce2635f1f058290d93726e789c909a86\n'}]",0,37320,4c41292be4f83ccb70ea81ae5ecd445646bef19c,36,7,4,5196,,,0,"Add cinder_available config option.

This commit adds a new config group service_available that will be
used to specify whether a particular OpenStack project is expected to
be running or not. This group is added with one member cinder which is
used to specify whether cinder is running or not. This replaces the
check in the volume api tests for a cinder endpoint.

Change-Id: Id894fc29ce2635f1f058290d93726e789c909a86
",git fetch https://review.opendev.org/openstack/tempest refs/changes/20/37320/3 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/volumes/test_volumes_get.py', 'tempest/config.py', 'tempest/api/volume/base.py', 'tempest/api/compute/volumes/test_attach_volume.py', 'tempest/api/compute/volumes/test_volumes_negative.py']",5,3c0c07acab38a7a493b8234ba560f789a702da36,service-avail-group," if not cls.config.volume.cinder_available: skip_msg = (""%s skipped as Cinder is not available"" % cls.__name__) raise cls.skipException(skip_msg)",,21,12
openstack%2Fglance~master~Ifd105bf2f299c4ff8e0ead551687b10de3148239,openstack/glance,master,Ifd105bf2f299c4ff8e0ead551687b10de3148239,Code dedup in glance/tests/unit/v1/test_registry_api.py,ABANDONED,2013-07-11 11:39:53.000000000,2013-07-22 12:17:17.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 6172}, {'_account_id': 6484}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 8003}]","[{'number': 1, 'created': '2013-07-11 11:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/88ab6100b5cfb1de75bd0a9828af3733784d6c2b', 'message': 'Refactor glance/tests/unit/v1/test_registry_api.py\n\nRemove code duplication\n\nbp glance-tests-code-duplication\n\nChange-Id: Ifd105bf2f299c4ff8e0ead551687b10de3148239\n'}, {'number': 2, 'created': '2013-07-15 11:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2087ccf76294e010442516c68f0a236636798ee6', 'message': 'Refactor glance/tests/unit/v1/test_registry_api.py\n\nRemove code duplication\n\nbp glance-tests-code-duplication\n\nChange-Id: Ifd105bf2f299c4ff8e0ead551687b10de3148239\n'}, {'number': 3, 'created': '2013-07-17 09:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/218c5d1848a9e214edd9346973dd167f1b7b5e8e', 'message': 'Code dedup in glance/tests/unit/v1/test_registry_api.py\n\nRemove code duplication\n\nbp glance-tests-code-duplication\n\nChange-Id: Ifd105bf2f299c4ff8e0ead551687b10de3148239\n'}, {'number': 4, 'created': '2013-07-17 13:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3c243e10e2c766dc70a9c1be56f5bb795ea570a9', 'message': 'Code dedup in glance/tests/unit/v1/test_registry_api.py\n\nMove duplicated fixture set-ups, requests and assertions to separate functions\n\nbp glance-tests-code-duplication\n\nChange-Id: Ifd105bf2f299c4ff8e0ead551687b10de3148239\n'}, {'number': 5, 'created': '2013-07-17 14:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/babad950af94bc5695636090b41e717008676763', 'message': 'Code dedup in glance/tests/unit/v1/test_registry_api.py\n\nMove duplicated fixture set-ups, requests and assertions to separate functions\n\nbp glance-tests-code-duplication\n\nChange-Id: Ifd105bf2f299c4ff8e0ead551687b10de3148239\n'}, {'number': 6, 'created': '2013-07-18 13:24:39.000000000', 'files': ['glance/tests/unit/v1/test_registry_api.py', 'glance/tests/utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/9b2244b8ac2c9c8d0bb12941fcc5445313c18eb5', 'message': 'Code dedup in glance/tests/unit/v1/test_registry_api.py\n\nMove duplicated fixture set-ups, requests and assertions to tests.utils.py\n\nbp glance-tests-code-duplication\n\nChange-Id: Ifd105bf2f299c4ff8e0ead551687b10de3148239\n'}]",8,36638,9b2244b8ac2c9c8d0bb12941fcc5445313c18eb5,28,7,6,7293,,,0,"Code dedup in glance/tests/unit/v1/test_registry_api.py

Move duplicated fixture set-ups, requests and assertions to tests.utils.py

bp glance-tests-code-duplication

Change-Id: Ifd105bf2f299c4ff8e0ead551687b10de3148239
",git fetch https://review.opendev.org/openstack/glance refs/changes/38/36638/6 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/unit/v1/test_registry_api.py'],1,88ab6100b5cfb1de75bd0a9828af3733784d6c2b,bp/glance-tests-code-duplication," self.fixture = {'name': 'fake public image', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf'} self.extra_fixture = {'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 19, 'checksum': None} self.extra_fixture['id'] = UUID4 self.extra_fixture['owner'] = 'test user' self.extra_fixture['is_public'] = False self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['size'] = 18 db_api.image_create(self.context, self.extra_fixture) extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID3 extra_fixture['created_at'] = time1 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID4 extra_fixture['size'] = 20 extra_fixture['created_at'] = time2 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID5 extra_fixture['size'] = 20 extra_fixture['created_at'] = time3 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID3 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID4 extra_fixture['size'] = 20 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID3 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = _gen_uuid() extra_fixture['size'] = 20 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = _gen_uuid() extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = _gen_uuid() extra_fixture['size'] = 20 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID3 extra_fixture['created_at'] = time1 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID4 extra_fixture['size'] = 20 extra_fixture['created_at'] = time2 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID5 extra_fixture['size'] = 20 extra_fixture['created_at'] = time3 self.extra_fixture['id'] = UUID6 self.extra_fixture['size'] = 20 self.extra_fixture['name'] = None db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID6 self.extra_fixture['size'] = 20 self.extra_fixture['disk_format'] = None self.extra_fixture['name'] = 'Fake image' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID6 self.extra_fixture['size'] = 20 self.extra_fixture['container_format'] = None self.extra_fixture['name'] = 'Fake image' db_api.image_create(self.context, self.extra_fixture) extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID3 extra_fixture['name'] = 'asdf' extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID4 extra_fixture['name'] = 'xyz' extra_fixture['size'] = 20 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID3 extra_fixture['status'] = 'queued' extra_fixture['name'] = 'asdf' extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID4 extra_fixture['name'] = 'xyz' extra_fixture['size'] = 20 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID3 extra_fixture['disk_format'] = 'ami' extra_fixture['container_format'] = 'ami' extra_fixture['name'] = 'asdf' extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID4 extra_fixture['disk_format'] = 'vdi' extra_fixture['name'] = 'xyz' extra_fixture['size'] = 20 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID3 extra_fixture['disk_format'] = 'ami' extra_fixture['container_format'] = 'ami' extra_fixture['name'] = 'asdf' extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID4 extra_fixture['disk_format'] = 'iso' extra_fixture['container_format'] = 'bare' extra_fixture['name'] = 'xyz' extra_fixture['size'] = 20 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID3 extra_fixture['disk_format'] = 'ami' extra_fixture['container_format'] = 'ami' extra_fixture['name'] = 'asdf' extra_fixture['size'] = 100 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID4 extra_fixture['disk_format'] = 'iso' extra_fixture['container_format'] = 'bare' extra_fixture['name'] = 'xyz' extra_fixture['size'] = 2 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID3 extra_fixture['created_at'] = time1 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID4 extra_fixture['size'] = 20 extra_fixture['created_at'] = time2 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID3 extra_fixture['created_at'] = None extra_fixture['updated_at'] = time1 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID4 extra_fixture['size'] = 20 extra_fixture['created_at'] = None extra_fixture['updated_at'] = time2 self.extra_fixture['id'] = UUID3 db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['size'] = 20 db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['size'] = 20 db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['status'] = 'saving' self.extra_fixture['name'] = 'fake image #3' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['status'] = 'active' self.extra_fixture['name'] = 'fake image #4' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['disk_format'] = 'vdi' self.extra_fixture['name'] = 'fake image #3' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['disk_format'] = 'ami' self.extra_fixture['container_format'] = 'ami' self.extra_fixture['name'] = 'fake image #4' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['min_disk'] = 7 db_api.image_create(self.context, self.extra_fixture) del self.extra_fixture['min_disk'] self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['disk_format'] = 'ami' self.extra_fixture['container_format'] = 'ami' self.extra_fixture['name'] = 'fake image #4' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['min_ram'] = 514 db_api.image_create(self.context, self.extra_fixture) del self.extra_fixture['min_ram'] self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['disk_format'] = 'ami' self.extra_fixture['container_format'] = 'ami' self.extra_fixture['name'] = 'fake image #4' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['disk_format'] = 'ami' self.extra_fixture['container_format'] = 'ami' self.extra_fixture['name'] = 'fake image #4' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['size'] = 18 db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['disk_format'] = 'ami' self.extra_fixture['container_format'] = 'ami' self.extra_fixture['name'] = 'fake image #4' self.extra_fixture['size'] = 20 db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['size'] = 18 db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['disk_format'] = 'ami' self.extra_fixture['container_format'] = 'ami' self.extra_fixture['name'] = 'fake image #4' self.extra_fixture['size'] = 20 db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['size'] = 18 db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['disk_format'] = 'ami' self.extra_fixture['container_format'] = 'ami' self.extra_fixture['name'] = 'fake image #4' self.extra_fixture['size'] = 20 db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['name'] = 'fake image #5' self.extra_fixture['size'] = 6 db_api.image_create(self.context, self.extra_fixture) extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID3 extra_fixture['name'] = 'fake image #3' extra_fixture['size'] = 18 extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID4 extra_fixture['name'] = 'fake image #4' extra_fixture['disk_format'] = 'ami' extra_fixture['container_format'] = 'ami' extra_fixture['size'] = 20 extra_fixture['created_at'] = image_ts extra_fixture['updated_at'] = image_ts self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['properties'] = {'prop_123': 'v a'} db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['disk_format'] = 'ami' self.extra_fixture['container_format'] = 'ami' self.extra_fixture['name'] = 'fake image #4' self.extra_fixture['properties'] = {'prop_123': 'v b'} db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['is_public'] = False self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['size'] = 18 db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['is_public'] = False self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['size'] = 18 db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['is_public'] = False self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['size'] = 18 db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['is_public'] = 'true' self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['size'] = 18 db_api.image_create(self.context, self.extra_fixture) del self.extra_fixture['is_public'] self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['name'] = 'test deleted filter 1' self.extra_fixture['size'] = 18 self.extra_fixture['deleted'] = False db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID4 self.extra_fixture['is_public'] = False self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['size'] = 18 db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['size'] = 18 self.extra_fixture['protected'] = ""False"" db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = _gen_uuid() self.extra_fixture['name'] = 'fake image #3' self.extra_fixture['size'] = 18 self.extra_fixture['protected'] = ""True"" db_api.image_create(self.context, self.extra_fixture) extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID3 extra_fixture['name'] = 'asdf' extra_fixture = self.extra_fixture.copy() extra_fixture['id'] = UUID4 extra_fixture['name'] = 'xyz' extra_fixture['size'] = 20 req.body = json.dumps(dict(image=self.fixture)) for k, v in self.fixture.iteritems(): self.fixture['min_disk'] = 5 req.body = json.dumps(dict(image=self.fixture)) self.fixture['min_ram'] = 256 req.body = json.dumps(dict(image=self.fixture)) req.body = json.dumps(dict(image=self.fixture)) req.body = json.dumps(dict(image=self.fixture)) self.fixture['id'] = _gen_uuid() self.fixture['status'] = 'bad status' req.body = json.dumps(dict(image=self.fixture)) self.fixture['id'] = 'asdf' req.body = json.dumps(dict(image=self.fixture)) self.extra_fixture['id'] = UUID8 self.extra_fixture['is_public'] = False self.extra_fixture['name'] = 'test update private image' self.extra_fixture['protected'] = True self.extra_fixture['owner'] = 'test user' db_api.image_create(self.context, self.extra_fixture) req.body = json.dumps(dict(image=self.extra_fixture)) self.extra_fixture['id'] = UUID8 self.extra_fixture['name'] = 'test delete private image' self.extra_fixture['protected'] = True self.extra_fixture['owner'] = 'test user' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID8 self.extra_fixture['is_public'] = False self.extra_fixture['name'] = 'test delete private image' self.extra_fixture['protected'] = True self.extra_fixture['owner'] = 'test user' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID8 self.extra_fixture['is_public'] = False self.extra_fixture['name'] = 'test delete private image' self.extra_fixture['protected'] = True self.extra_fixture['owner'] = 'test user' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID8 self.extra_fixture['name'] = 'test delete private image' self.extra_fixture['protected'] = False self.extra_fixture['owner'] = 'test user' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID9 self.extra_fixture['name'] = 'test delete private image' self.extra_fixture['protected'] = False db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID8 self.extra_fixture['name'] = 'test delete private image' self.extra_fixture['protected'] = False self.extra_fixture['owner'] = 'test user' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID8 self.extra_fixture['name'] = 'test delete private image' self.extra_fixture['protected'] = False self.extra_fixture['owner'] = 'test user' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID8 self.extra_fixture['name'] = 'test delete private image' self.extra_fixture['protected'] = False self.extra_fixture['owner'] = 'test user' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID8 self.extra_fixture['name'] = 'test delete private image' self.extra_fixture['protected'] = False self.extra_fixture['owner'] = 'test user' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID9 self.extra_fixture['name'] = 'test delete private image' self.extra_fixture['protected'] = False db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID8 self.extra_fixture['name'] = 'test delete private image' self.extra_fixture['protected'] = False self.extra_fixture['owner'] = 'test user' db_api.image_create(self.context, self.extra_fixture) self.extra_fixture['id'] = UUID9 self.extra_fixture['name'] = 'test delete private image' self.extra_fixture['protected'] = False db_api.image_create(self.context, self.extra_fixture)"," extra_fixture = {'id': UUID4, 'owner': 'test user', 'status': 'active', 'is_public': False, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 18, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID3, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 19, 'checksum': None, 'created_at': time1} extra_fixture = {'id': UUID4, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 20, 'checksum': None, 'created_at': time2} extra_fixture = {'id': UUID5, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 20, 'checksum': None, 'created_at': time3} extra_fixture = {'id': UUID3, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 19, 'checksum': None} extra_fixture = {'id': UUID4, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 20, 'checksum': None} extra_fixture = {'id': UUID3, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 19, 'checksum': None} extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 20, 'checksum': None} fixture = {'id': UUID2, 'name': 'fake image #2', 'size': 19, 'checksum': None} extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 19, 'checksum': None} extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 20, 'checksum': None} extra_fixture = {'id': UUID3, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 19, 'checksum': None, 'created_at': time1} extra_fixture = {'id': UUID4, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 20, 'checksum': None, 'created_at': time2} extra_fixture = {'id': UUID5, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 20, 'checksum': None, 'created_at': time3} extra_fixture = {'id': UUID6, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'size': 20, 'name': None, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID6, 'status': 'active', 'is_public': True, 'disk_format': None, 'container_format': 'ovf', 'size': 20, 'name': 'Fake image', 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID6, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': None, 'size': 20, 'name': 'Fake image', 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID3, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'asdf', 'size': 19, 'checksum': None} extra_fixture = {'id': UUID4, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'xyz', 'size': 20, 'checksum': None} extra_fixture = {'id': UUID3, 'status': 'queued', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'asdf', 'size': 19, 'checksum': None} extra_fixture = {'id': UUID4, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'xyz', 'size': 20, 'checksum': None} extra_fixture = {'id': UUID3, 'status': 'active', 'is_public': True, 'disk_format': 'ami', 'container_format': 'ami', 'name': 'asdf', 'size': 19, 'checksum': None} extra_fixture = {'id': UUID4, 'status': 'active', 'is_public': True, 'disk_format': 'vdi', 'container_format': 'ovf', 'name': 'xyz', 'size': 20, 'checksum': None} extra_fixture = {'id': UUID3, 'status': 'active', 'is_public': True, 'disk_format': 'ami', 'container_format': 'ami', 'name': 'asdf', 'size': 19, 'checksum': None} extra_fixture = {'id': UUID4, 'status': 'active', 'is_public': True, 'disk_format': 'iso', 'container_format': 'bare', 'name': 'xyz', 'size': 20, 'checksum': None} extra_fixture = {'id': UUID3, 'status': 'active', 'is_public': True, 'disk_format': 'ami', 'container_format': 'ami', 'name': 'asdf', 'size': 100, 'checksum': None} extra_fixture = {'id': UUID4, 'status': 'active', 'is_public': True, 'disk_format': 'iso', 'container_format': 'bare', 'name': 'xyz', 'size': 2, 'checksum': None} extra_fixture = {'id': UUID3, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 19, 'checksum': None, 'created_at': time1} extra_fixture = {'id': UUID4, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 20, 'checksum': None, 'created_at': time2} extra_fixture = {'id': UUID3, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 19, 'checksum': None, 'created_at': None, 'updated_at': time1} extra_fixture = {'id': UUID4, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 20, 'checksum': None, 'created_at': None, 'updated_at': time2} extra_fixture = {'id': UUID3, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 19, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 20, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 19, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'new name! #123', 'size': 20, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'saving', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 19, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #4', 'size': 19, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vdi', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 19, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'ami', 'container_format': 'ami', 'name': 'fake image #4', 'size': 19, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 19, 'min_disk': 7, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'ami', 'container_format': 'ami', 'name': 'fake image #4', 'size': 19, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 19, 'min_ram': 514, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'ami', 'container_format': 'ami', 'name': 'fake image #4', 'size': 19, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 19, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'ami', 'container_format': 'ami', 'name': 'fake image #4', 'size': 19, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 18, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'ami', 'container_format': 'ami', 'name': 'fake image #4', 'size': 20, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 18, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'ami', 'container_format': 'ami', 'name': 'fake image #4', 'size': 20, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 18, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'ami', 'container_format': 'ami', 'name': 'fake image #4', 'size': 20, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'ami', 'container_format': 'ami', 'name': 'fake image #5', 'size': 6, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID3, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 18, 'checksum': None} extra_fixture = {'id': UUID4, 'status': 'active', 'is_public': True, 'disk_format': 'ami', 'container_format': 'ami', 'name': 'fake image #4', 'size': 20, 'checksum': None, 'created_at': image_ts, 'updated_at': image_ts} extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 19, 'checksum': None, 'properties': {'prop_123': 'v a'}} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'ami', 'container_format': 'ami', 'name': 'fake image #4', 'size': 19, 'checksum': None, 'properties': {'prop_123': 'v b'}} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': False, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 18, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': False, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 18, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': False, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 18, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': 'true', 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 18, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'name': 'test deleted filter 1', 'disk_format': 'vhd', 'container_format': 'ovf', 'size': 18, 'checksum': None, 'deleted': False} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID4, 'status': 'active', 'is_public': False, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 18, 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 18, 'protected': ""False"", 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': _gen_uuid(), 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'fake image #3', 'size': 18, 'protected': ""True"", 'checksum': None} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID3, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'asdf', 'size': 19, 'checksum': None} extra_fixture = {'id': UUID4, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'xyz', 'size': 20, 'checksum': None} fixture = {'name': 'fake public image', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf'} req.body = json.dumps(dict(image=fixture)) for k, v in fixture.iteritems(): fixture = {'name': 'fake public image', 'is_public': True, 'min_disk': 5, 'disk_format': 'vhd', 'container_format': 'ovf'} req.body = json.dumps(dict(image=fixture)) fixture = {'name': 'fake public image', 'is_public': True, 'min_ram': 256, 'disk_format': 'vhd', 'container_format': 'ovf'} req.body = json.dumps(dict(image=fixture)) fixture = {'name': 'fake public image', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf'} req.body = json.dumps(dict(image=fixture)) fixture = {'name': 'fake public image', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf'} req.body = json.dumps(dict(image=fixture)) fixture = {'id': _gen_uuid(), 'name': 'fake public image', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'status': 'bad status'} req.body = json.dumps(dict(image=fixture)) fixture = {'id': 'asdf', 'name': 'fake public image', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf'} req.body = json.dumps(dict(image=fixture)) extra_fixture = {'id': UUID8, 'status': 'active', 'is_public': False, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'test update private image', 'size': 19, 'checksum': None, 'protected': True, 'owner': 'test user'} db_api.image_create(self.context, extra_fixture) req.body = json.dumps(dict(image=extra_fixture)) extra_fixture = {'id': UUID8, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'test delete public image', 'size': 19, 'checksum': None, 'protected': True, 'owner': 'test user'} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID8, 'status': 'active', 'is_public': False, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'test delete private image', 'size': 19, 'checksum': None, 'protected': True, 'owner': 'test user'} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID8, 'status': 'active', 'is_public': False, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'test delete private image', 'size': 19, 'checksum': None, 'protected': True, 'owner': 'test user'} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID8, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'test delete private image', 'size': 19, 'checksum': None, 'protected': False, 'owner': 'test user'} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID9, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'test delete private image', 'size': 19, 'checksum': None, 'protected': False} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID8, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'test delete private image', 'size': 19, 'checksum': None, 'protected': False, 'owner': 'test user'} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID8, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'test delete private image', 'size': 19, 'checksum': None, 'protected': False, 'owner': 'test user'} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID8, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'test delete private image', 'size': 19, 'checksum': None, 'protected': False, 'owner': 'test user'} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID8, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'test delete private image', 'size': 19, 'checksum': None, 'protected': False, 'owner': 'test user'} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID9, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'test delete private image', 'size': 19, 'checksum': None, 'protected': False} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID8, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'test delete private image', 'size': 19, 'checksum': None, 'protected': False, 'owner': 'test user'} db_api.image_create(self.context, extra_fixture) extra_fixture = {'id': UUID9, 'status': 'active', 'is_public': True, 'disk_format': 'vhd', 'container_format': 'ovf', 'name': 'test delete private image', 'size': 19, 'checksum': None, 'protected': False} db_api.image_create(self.context, extra_fixture)",372,763
openstack%2Ftempest~master~I78f4608cce488cd515d72df2178d7a5b45bf2b85,openstack/tempest,master,I78f4608cce488cd515d72df2178d7a5b45bf2b85,Skip test that is not relevant to Neutron,MERGED,2013-07-19 13:47:50.000000000,2013-07-22 12:15:32.000000000,2013-07-22 12:15:32.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5292}]","[{'number': 1, 'created': '2013-07-19 13:47:50.000000000', 'files': ['tempest/cli/simple_read_only/test_compute.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/15373b034897cc549637c59ed0588fe340c4fd2d', 'message': 'Skip test that is not relevant to Neutron\n\nNeutron does not support DNS domain feature,\nthus this test must be skipped in Neutron environment.\nFixes: bug #1202991\n\nChange-Id: I78f4608cce488cd515d72df2178d7a5b45bf2b85\n'}]",1,37902,15373b034897cc549637c59ed0588fe340c4fd2d,7,3,1,7781,,,0,"Skip test that is not relevant to Neutron

Neutron does not support DNS domain feature,
thus this test must be skipped in Neutron environment.
Fixes: bug #1202991

Change-Id: I78f4608cce488cd515d72df2178d7a5b45bf2b85
",git fetch https://review.opendev.org/openstack/tempest refs/changes/02/37902/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cli/simple_read_only/test_compute.py'],1,15373b034897cc549637c59ed0588fe340c4fd2d,bug/1202991,"from tempest import config @testtools.skipIf(config.TempestConfig().network.neutron_available, ""Neutron does not provide this feature"")",,3,1
openstack%2Fnova~master~Iac6aa85b69d5a6dc563c00f3497cdab08e178ec1,openstack/nova,master,Iac6aa85b69d5a6dc563c00f3497cdab08e178ec1,ec2-api: Disable describing of instances using deleted tags as filter.,MERGED,2013-07-09 16:41:10.000000000,2013-07-22 11:40:04.000000000,2013-07-22 11:40:01.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2140}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 6172}, {'_account_id': 6661}, {'_account_id': 6899}]","[{'number': 1, 'created': '2013-07-09 16:41:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aef7a061bd1980a389c40f03a3371ed623f39730', 'message': 'Disable describing of instances using deleted tags as filter.\n\nPreviously, one could retrieve instances using a deleted tag\nfilter that was once associated to the instance. The current change\ndisables describing instances via a deleted tag.\n\nfixes bug #1197242\n\nChange-Id: Iac6aa85b69d5a6dc563c00f3497cdab08e178ec1\n'}, {'number': 2, 'created': '2013-07-09 17:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/049ccd3a00f1cccffff7ff79895273d29829dfe0', 'message': 'Disable describing of instances using deleted tags as filter.\n\nPreviously, one could retrieve instances using a deleted tag\nfilter that was once associated to the instance. The current change\ndisables describing instances via a deleted tag.\n\nfixes bug #1197242\n\nChange-Id: Iac6aa85b69d5a6dc563c00f3497cdab08e178ec1\n'}, {'number': 3, 'created': '2013-07-09 20:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cbf8e54ae8c41d32e8022cac34e3098ddf398c71', 'message': 'Disable describing of instances using deleted tags as filter.\n\nPreviously, one could retrieve instances using a deleted tag\nfilter that was once associated to the instance. The current change\ndisables describing instances via a deleted tag.\n\nfixes bug #1197242\n\nChange-Id: Iac6aa85b69d5a6dc563c00f3497cdab08e178ec1\n'}, {'number': 4, 'created': '2013-07-12 16:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b7b52c4964a3fd6085bcc19cf659c72ad30db0f', 'message': 'ec2-api: Disable describing of instances using deleted tags as filter.\n\nPreviously, one could describe instances using a deleted tag filter\nthat was once associated to the instance. The current change disables\ndescribing instances via a deleted tag. Also,minor refactor in the\nsame function.\n\nfixes bug #1197242\n\nChange-Id: Iac6aa85b69d5a6dc563c00f3497cdab08e178ec1\n'}, {'number': 5, 'created': '2013-07-17 16:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64b938e3c4b06f726160bb00748676d93efd9e90', 'message': 'ec2-api: Disable describing of instances using deleted tags as filter.\n\nPreviously, one could describe instances using a deleted tag filter\nthat was once associated to the instance. The current change disables\ndescribing instances via a deleted tag. Also,minor refactor in the\nsame function.\n\nfixes bug #1197242\n\nChange-Id: Iac6aa85b69d5a6dc563c00f3497cdab08e178ec1\n'}, {'number': 6, 'created': '2013-07-17 19:46:22.000000000', 'files': ['nova/tests/api/ec2/test_cloud.py', 'nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d73041f6082e8cb28403688e2e403fdf0cbdded2', 'message': 'ec2-api: Disable describing of instances using deleted tags as filter.\n\nPreviously, one could describe instances using a deleted tag filter\nthat was once associated to the instance. The current change disables\ndescribing instances via a deleted tag. Also,minor refactor in the\nsame function.\n\nfixes bug #1197242\n\nChange-Id: Iac6aa85b69d5a6dc563c00f3497cdab08e178ec1\n'}]",7,36289,d73041f6082e8cb28403688e2e403fdf0cbdded2,36,8,6,6899,,,0,"ec2-api: Disable describing of instances using deleted tags as filter.

Previously, one could describe instances using a deleted tag filter
that was once associated to the instance. The current change disables
describing instances via a deleted tag. Also,minor refactor in the
same function.

fixes bug #1197242

Change-Id: Iac6aa85b69d5a6dc563c00f3497cdab08e178ec1
",git fetch https://review.opendev.org/openstack/nova refs/changes/89/36289/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,aef7a061bd1980a389c40f03a3371ed623f39730,bug/1197242," subq = and_(subq, tag_model.deleted == 0) subq = subq.filter(tag_model.deleted == 0)",,13,0
openstack%2Fnova~master~I4febfa2c837e0f80cee85ca74553829c960a3efc,openstack/nova,master,I4febfa2c837e0f80cee85ca74553829c960a3efc,Add ability to factor in per-instance overheads,MERGED,2013-07-02 20:02:58.000000000,2013-07-22 11:39:50.000000000,2013-07-22 11:39:48.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2835}]","[{'number': 1, 'created': '2013-07-02 20:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ffc10e8cf62f7f1277c4fd758be78f5dd0bb0467', 'message': 'Add ability to factor in per-instance overheads\n\nCurrently free memory calculations in the compute layer use a single\nvalue to account for all memory overhead needed by a host.  This value\nis: CONF.reserved_host_memory_mb\n\nThis patch adds the ability to factor in per-instance memory\nvirtualization overheads into usage calculations.\n\nEach virt driver defaults to zero overhead for compatibility.\n\nChange-Id: I4febfa2c837e0f80cee85ca74553829c960a3efc\n'}, {'number': 2, 'created': '2013-07-03 15:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a585e1d4914ebbd77a179ef42409654195765afb', 'message': 'Add ability to factor in per-instance overheads\n\nCurrently free memory calculations in the compute layer use a single\nvalue to account for all memory overhead needed by a host.  This value\nis: CONF.reserved_host_memory_mb\n\nThis patch adds the ability to factor in per-instance memory\nvirtualization overheads into usage calculations.\n\nEach virt driver defaults to zero overhead for compatibility.\n\nChange-Id: I4febfa2c837e0f80cee85ca74553829c960a3efc\n'}, {'number': 3, 'created': '2013-07-15 19:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/97fdcf40b438362b39ff8dff8503aa5b9de524f9', 'message': 'Add ability to factor in per-instance overheads\n\nCurrently free memory calculations in the compute layer use a single\nvalue to account for all memory overhead needed by a host.  This value\nis: CONF.reserved_host_memory_mb\n\nThis patch adds the ability to factor in per-instance memory\nvirtualization overheads into usage calculations.\n\nEach virt driver defaults to zero overhead for compatibility.\n\nChange-Id: I4febfa2c837e0f80cee85ca74553829c960a3efc\n'}, {'number': 4, 'created': '2013-07-15 22:24:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/019223ab0098ab79a3934c2ec116b2f905998615', 'message': 'Add ability to factor in per-instance overheads\n\nCurrently free memory calculations in the compute layer use a single\nvalue to account for all memory overhead needed by a host.  This value\nis: CONF.reserved_host_memory_mb\n\nThis patch adds the ability to factor in per-instance memory\nvirtualization overheads into usage calculations.\n\nEach virt driver defaults to zero overhead for compatibility.\n\nChange-Id: I4febfa2c837e0f80cee85ca74553829c960a3efc\n'}, {'number': 5, 'created': '2013-07-17 18:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a45a0dcf2b683f0371280c1ee2b5f7502f170e04', 'message': ""Add ability to factor in per-instance overheads\n\nCurrently free memory calculations in the compute layer use a single\nvalue to account for all memory overhead needed by a host.  This value\nis: CONF.reserved_host_memory_mb\n\nThis patch adds the ability to factor in per-instance virtualization\noverheads into usage calculations.  Virtualization overhead may differ\nbased on the flavor or other factors such as number of vcpus on a host.\nThis feature's goal is to provide the ability to do more accurate\ncomputations of a host's overhead without having to pre-configure a\nbest guess in advance.\n\nThe actual calculation of overhead is left up to each virt driver to\nimplement.  This patch defaults to zero overhead for compatibility.\n\nChange-Id: I4febfa2c837e0f80cee85ca74553829c960a3efc\n""}, {'number': 6, 'created': '2013-07-19 15:55:11.000000000', 'files': ['nova/virt/driver.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/compute/claims.py', 'nova/tests/compute/test_claims.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e025ab6922dba142c7a3e1b0b52e3dbdb2be918b', 'message': ""Add ability to factor in per-instance overheads\n\nCurrently free memory calculations in the compute layer use a single\nvalue to account for all memory overhead needed by a host.  This value\nis: CONF.reserved_host_memory_mb\n\nThis patch adds the ability to factor in per-instance virtualization\noverheads into usage calculations.  Virtualization overhead may differ\nbased on the flavor or other factors such as number of vcpus on a host.\nThis feature's goal is to provide the ability to do more accurate\ncomputations of a host's overhead without having to pre-configure a\nbest guess in advance.\n\nThe actual calculation of overhead is left up to each virt driver to\nimplement.  This patch defaults to zero overhead for compatibility.\n\nChange-Id: I4febfa2c837e0f80cee85ca74553829c960a3efc\n""}]",10,35379,e025ab6922dba142c7a3e1b0b52e3dbdb2be918b,38,8,6,2835,,,0,"Add ability to factor in per-instance overheads

Currently free memory calculations in the compute layer use a single
value to account for all memory overhead needed by a host.  This value
is: CONF.reserved_host_memory_mb

This patch adds the ability to factor in per-instance virtualization
overheads into usage calculations.  Virtualization overhead may differ
based on the flavor or other factors such as number of vcpus on a host.
This feature's goal is to provide the ability to do more accurate
computations of a host's overhead without having to pre-configure a
best guess in advance.

The actual calculation of overhead is left up to each virt driver to
implement.  This patch defaults to zero overhead for compatibility.

Change-Id: I4febfa2c837e0f80cee85ca74553829c960a3efc
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/35379/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/driver.py', 'nova/compute/claims.py', 'nova/compute/resource_tracker.py']",3,ffc10e8cf62f7f1277c4fd758be78f5dd0bb0467,flavor_overhead_upstream," # get memory overhead required to build this instance: overhead = self.driver.instance_overhead(instance_ref['memory_mb']) LOG.debug(_(""Memory overhead for %(flavor)d MB instance; %(overhead)d "" ""MB""), {'flavor': instance_ref['memory_mb'], 'overhead': overhead}) claim = claims.Claim(instance_ref, self, overhead=overhead) # get memory overhead required to build this instance: overhead = self.driver.instance_overhead(instance_type['memory_mb']) LOG.debug(_(""Memory overhead for %(flavor)d MB instance; %(overhead)d "" ""MB""), {'flavor': instance_type['memory_mb'], 'overhead': overhead}) claim = claims.ResizeClaim(instance_ref, instance_type, self, overhead=overhead) mem_usage = usage['memory_mb'] mem_usage += self.driver.instance_overhead(mem_usage) resources['memory_mb_used'] += sign * mem_usage"," claim = claims.Claim(instance_ref, self) claim = claims.ResizeClaim(instance_ref, instance_type, self) resources['memory_mb_used'] += sign * usage['memory_mb']",39,11
openstack%2Fzaqar~master~I861201ea5493bbe4e1c0197000edbd8594162047,openstack/zaqar,master,I861201ea5493bbe4e1c0197000edbd8594162047,feat(transport): define acceptable integer range,MERGED,2013-07-18 21:19:24.000000000,2013-07-22 10:49:54.000000000,2013-07-22 10:49:54.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6943}, {'_account_id': 6944}, {'_account_id': 7044}]","[{'number': 1, 'created': '2013-07-18 21:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/59c5fd4acbeab543726a2308364386aa3718dfbc', 'message': 'feat(transport): define acceptable integer range\n\nChange-Id: I861201ea5493bbe4e1c0197000edbd8594162047\nFixes: bug #1202846\n'}, {'number': 2, 'created': '2013-07-19 13:49:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/f3658a6eed8c031615657cc7b020392be2beba2d', 'message': 'feat(transport): define acceptable integer range\n\nChange-Id: I861201ea5493bbe4e1c0197000edbd8594162047\nFixes: bug #1202846\n'}, {'number': 3, 'created': '2013-07-19 17:01:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/760e6117f47a8538397ff6a83631d0e8964ed596', 'message': 'feat(transport): define acceptable integer range\n\nChange-Id: I861201ea5493bbe4e1c0197000edbd8594162047\nFixes: bug #1202846\n'}, {'number': 4, 'created': '2013-07-19 17:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/2ee3ee727e58ed1b87c2458b05712e1cf37816e9', 'message': 'feat(transport): define acceptable integer range\n\nChange-Id: I861201ea5493bbe4e1c0197000edbd8594162047\nFixes: bug #1202846\n'}, {'number': 5, 'created': '2013-07-19 20:02:19.000000000', 'files': ['marconi/transport/wsgi/helpers.py', 'marconi/transport/helpers.py', 'marconi/tests/transport/wsgi/test_messages.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/8b9f01a66c574f77352881ca305552b3d0d04808', 'message': 'feat(transport): define acceptable integer range\n\nThe JSON parser in use (simplejson) supports Python big integers,\nwhile none of the storage drivers can serialize them.  The acceptable\nrange to both bson and msgpack is -2^63 ~ 2^63-1.\n\nChange-Id: I861201ea5493bbe4e1c0197000edbd8594162047\nFixes: bug #1202846\n'}]",5,37779,8b9f01a66c574f77352881ca305552b3d0d04808,21,6,5,6943,,,0,"feat(transport): define acceptable integer range

The JSON parser in use (simplejson) supports Python big integers,
while none of the storage drivers can serialize them.  The acceptable
range to both bson and msgpack is -2^63 ~ 2^63-1.

Change-Id: I861201ea5493bbe4e1c0197000edbd8594162047
Fixes: bug #1202846
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/79/37779/4 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/transport/wsgi/helpers.py', 'marconi/transport/helpers.py', 'marconi/tests/transport/wsgi/test_messages.py']",3,59c5fd4acbeab543726a2308364386aa3718dfbc,bug/1202846," def test_unsupported_json(self): for document in ('{""overflow"": 9223372036854775808}', '{""underflow"": -9223372036854775809}'): self.simulate_post(self.queue_path + '/messages', body=document, headers=self.headers) self.assertEquals(self.srmock.status, falcon.HTTP_400) ",,29,1
openstack%2Fsahara~master~Ibb4aaa271d3e0738c0c1d114efdefcba856fb190,openstack/sahara,master,Ibb4aaa271d3e0738c0c1d114efdefcba856fb190,Licence header added to tools/get_auth_token.py,MERGED,2013-07-22 06:58:04.000000000,2013-07-22 10:32:33.000000000,2013-07-22 10:32:33.000000000,"[{'_account_id': 3}, {'_account_id': 6786}]","[{'number': 1, 'created': '2013-07-22 06:58:04.000000000', 'files': ['tools/get_auth_token.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/c9e1f7296ad3c3bc688f221c4c301b3d05edfddc', 'message': 'Licence header added to tools/get_auth_token.py\n\nImports in this file refactored also\n\nFixes: bug #1203408\n\nChange-Id: Ibb4aaa271d3e0738c0c1d114efdefcba856fb190\n'}]",0,38107,c9e1f7296ad3c3bc688f221c4c301b3d05edfddc,5,2,1,7132,,,0,"Licence header added to tools/get_auth_token.py

Imports in this file refactored also

Fixes: bug #1203408

Change-Id: Ibb4aaa271d3e0738c0c1d114efdefcba856fb190
",git fetch https://review.opendev.org/openstack/sahara refs/changes/07/38107/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/get_auth_token.py'],1,c9e1f7296ad3c3bc688f221c4c301b3d05edfddc,bug/1203408,"# Copyright (c) 2013 Mirantis Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from keystoneclient.v2_0 import Client as keystone_client from oslo.config import cfg ",from keystoneclient.v2_0 import Client as keystone_clientfrom oslo.config import cfg,18,2
openstack%2Fceilometer~master~Id1da7a11af977233a036c7c70c49d3038500363b,openstack/ceilometer,master,Id1da7a11af977233a036c7c70c49d3038500363b,Merge from Oslo-Incubator,MERGED,2013-07-21 12:37:16.000000000,2013-07-22 10:31:28.000000000,2013-07-22 10:31:28.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 4491}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-07-21 12:37:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/32138974cdd0b554733f4394816cf61065f53ff9', 'message': 'Merge from Oslo-Incubator\n\nThis merges the common util classes from Oslo-Incubator,\nwhich brings a lot of Python 3.x related fixes and\nHacking warning fixes.\n\nChange-Id: Id1da7a11af977233a036c7c70c49d3038500363b\n'}, {'number': 2, 'created': '2013-07-21 14:24:50.000000000', 'files': ['ceilometer/openstack/common/jsonutils.py', 'ceilometer/openstack/common/excutils.py', 'ceilometer/openstack/common/gettextutils.py', 'ceilometer/openstack/common/timeutils.py', 'ceilometer/openstack/common/eventlet_backdoor.py', 'ceilometer/openstack/common/policy.py', 'etc/ceilometer/ceilometer.conf.sample', 'ceilometer/openstack/common/loopingcall.py', 'requirements.txt', 'ceilometer/openstack/common/exception.py', 'ceilometer/openstack/common/log.py', 'ceilometer/openstack/common/config/generator.py', 'ceilometer/openstack/common/context.py', 'ceilometer/openstack/common/threadgroup.py', 'ceilometer/openstack/common/fileutils.py', 'ceilometer/openstack/common/sslutils.py', 'openstack-common.conf', 'ceilometer/openstack/common/service.py', 'ceilometer/openstack/common/lockutils.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8da3eab93f2ad3cf252055c0645e3c534d07b1ce', 'message': 'Merge from Oslo-Incubator\n\nThis merges the common util classes from Oslo-Incubator,\nwhich brings a lot of Python 3.x related fixes and\nHacking warning fixes.\n\nChange-Id: Id1da7a11af977233a036c7c70c49d3038500363b\n'}]",0,38065,8da3eab93f2ad3cf252055c0645e3c534d07b1ce,8,4,2,6593,,,0,"Merge from Oslo-Incubator

This merges the common util classes from Oslo-Incubator,
which brings a lot of Python 3.x related fixes and
Hacking warning fixes.

Change-Id: Id1da7a11af977233a036c7c70c49d3038500363b
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/65/38065/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/openstack/common/jsonutils.py', 'ceilometer/openstack/common/excutils.py', 'ceilometer/openstack/common/gettextutils.py', 'ceilometer/openstack/common/timeutils.py', 'ceilometer/openstack/common/eventlet_backdoor.py', 'ceilometer/openstack/common/policy.py', 'ceilometer/openstack/common/loopingcall.py', 'requirements.txt', 'ceilometer/openstack/common/exception.py', 'ceilometer/openstack/common/log.py', 'ceilometer/openstack/common/config/generator.py', 'ceilometer/openstack/common/context.py', 'ceilometer/openstack/common/threadgroup.py', 'ceilometer/openstack/common/fileutils.py', 'ceilometer/openstack/common/sslutils.py', 'openstack-common.conf', 'ceilometer/openstack/common/service.py', 'ceilometer/openstack/common/lockutils.py']",18,32138974cdd0b554733f4394816cf61065f53ff9,oslo_merge,"import contextlibfrom ceilometer.openstack.common.gettextutils import _ # noqa help=('Directory to use for lock files.'))@contextlib.contextmanager def lock(name, lock_file_prefix=None, external=False, lock_path=None): """"""Context based lock This function yields a `semaphore.Semaphore` instance unless external is True, in which case, it'll yield an InterProcessLock instance. :param lock_file_prefix: The lock_file_prefix argument is used to provide lock files on disk with a meaningful prefix. :param external: The external keyword argument denotes whether this lock should work across multiple processes. This means that if two different workers both run a a method decorated with @synchronized('mylock', external=True), only one of them will execute at a time. :param lock_path: The lock_path keyword argument is used to specify a special location for external lock files to live. If nothing is set, then CONF.lock_path is used as a default. """""" # NOTE(soren): If we ever go natively threaded, this will be racy. # See http://stackoverflow.com/questions/5390569/dyn # amically-allocating-and-destroying-mutexes sem = _semaphores.get(name, semaphore.Semaphore()) if name not in _semaphores: # this check is not racy - we're already holding ref locally # so GC won't remove the item and there was no IO switch # (only valid in greenthreads) _semaphores[name] = sem with sem: LOG.debug(_('Got semaphore ""%(lock)s""'), {'lock': name}) # NOTE(mikal): I know this looks odd if not hasattr(local.strong_store, 'locks_held'): local.strong_store.locks_held = [] local.strong_store.locks_held.append(name) try: if external and not CONF.disable_process_locking: LOG.debug(_('Attempting to grab file lock ""%(lock)s""'), {'lock': name}) # We need a copy of lock_path because it is non-local local_lock_path = lock_path or CONF.lock_path if not local_lock_path: raise cfg.RequiredOptError('lock_path') if not os.path.exists(local_lock_path): fileutils.ensure_tree(local_lock_path) LOG.info(_('Created lock path: %s'), local_lock_path) def add_prefix(name, prefix): if not prefix: return name sep = '' if prefix.endswith('-') else '-' return '%s%s%s' % (prefix, sep, name) # NOTE(mikal): the lock name cannot contain directory # separators lock_file_name = add_prefix(name.replace(os.sep, '_'), lock_file_prefix) lock_file_path = os.path.join(local_lock_path, lock_file_name) try: lock = InterProcessLock(lock_file_path) with lock as lock: LOG.debug(_('Got file lock ""%(lock)s"" at %(path)s'), {'lock': name, 'path': lock_file_path}) yield lock finally: LOG.debug(_('Released file lock ""%(lock)s"" at %(path)s'), {'lock': name, 'path': lock_file_path}) else: yield sem finally: local.strong_store.locks_held.remove(name) def synchronized(name, lock_file_prefix=None, external=False, lock_path=None): with lock(name, lock_file_prefix, external, lock_path): LOG.debug(_('Got semaphore / lock ""%(function)s""'), {'function': f.__name__}) return f(*args, **kwargs) LOG.debug(_('Semaphore / lock released ""%(function)s""'), {'function': f.__name__}) meaningful prefix.","import shutil import tempfilefrom ceilometer.openstack.common.gettextutils import _ help=('Directory to use for lock files. Default to a ' 'temp directory'))def synchronized(name, lock_file_prefix, external=False, lock_path=None): :param lock_file_prefix: The lock_file_prefix argument is used to provide lock files on disk with a meaningful prefix. The prefix should end with a hyphen ('-') if specified. :param external: The external keyword argument denotes whether this lock should work across multiple processes. This means that if two different workers both run a a method decorated with @synchronized('mylock', external=True), only one of them will execute at a time. :param lock_path: The lock_path keyword argument is used to specify a special location for external lock files to live. If nothing is set, then CONF.lock_path is used as a default. # NOTE(soren): If we ever go natively threaded, this will be racy. # See http://stackoverflow.com/questions/5390569/dyn # amically-allocating-and-destroying-mutexes sem = _semaphores.get(name, semaphore.Semaphore()) if name not in _semaphores: # this check is not racy - we're already holding ref locally # so GC won't remove the item and there was no IO switch # (only valid in greenthreads) _semaphores[name] = sem with sem: LOG.debug(_('Got semaphore ""%(lock)s"" for method ' '""%(method)s""...'), {'lock': name, 'method': f.__name__}) # NOTE(mikal): I know this looks odd if not hasattr(local.strong_store, 'locks_held'): local.strong_store.locks_held = [] local.strong_store.locks_held.append(name) try: if external and not CONF.disable_process_locking: LOG.debug(_('Attempting to grab file lock ""%(lock)s"" ' 'for method ""%(method)s""...'), {'lock': name, 'method': f.__name__}) cleanup_dir = False # We need a copy of lock_path because it is non-local local_lock_path = lock_path if not local_lock_path: local_lock_path = CONF.lock_path if not local_lock_path: cleanup_dir = True local_lock_path = tempfile.mkdtemp() if not os.path.exists(local_lock_path): fileutils.ensure_tree(local_lock_path) # NOTE(mikal): the lock name cannot contain directory # separators safe_name = name.replace(os.sep, '_') lock_file_name = '%s%s' % (lock_file_prefix, safe_name) lock_file_path = os.path.join(local_lock_path, lock_file_name) try: lock = InterProcessLock(lock_file_path) with lock: LOG.debug(_('Got file lock ""%(lock)s"" at ' '%(path)s for method ' '""%(method)s""...'), {'lock': name, 'path': lock_file_path, 'method': f.__name__}) retval = f(*args, **kwargs) finally: LOG.debug(_('Released file lock ""%(lock)s"" at ' '%(path)s for method ""%(method)s""...'), {'lock': name, 'path': lock_file_path, 'method': f.__name__}) # NOTE(vish): This removes the tempdir if we needed # to create one. This is used to # cleanup the locks left behind by unit # tests. if cleanup_dir: shutil.rmtree(local_lock_path) else: retval = f(*args, **kwargs) finally: local.strong_store.locks_held.remove(name) return retval meaningful prefix. The prefix should end with a hyphen ('-') if specified.",570,168
openstack%2Fhorizon~master~I620843df730520b55bfb709aaff1d63ce3f6e772,openstack/horizon,master,I620843df730520b55bfb709aaff1d63ce3f6e772,"rename ""enable"" action to ""toggle""",MERGED,2013-06-21 14:12:47.000000000,2013-07-22 10:17:04.000000000,2013-07-22 10:17:04.000000000,"[{'_account_id': 3}, {'_account_id': 1816}, {'_account_id': 1941}, {'_account_id': 2340}, {'_account_id': 5623}, {'_account_id': 7553}]","[{'number': 1, 'created': '2013-06-21 14:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f0d11f5f014af2f52e000549f65e32b4f6bf36d0', 'message': 'rename ""enable"" action to ""toggle""\n\nThe previous action caused confusion when it was called ""enable"" in the\nWebUI for both a disabled and an enabled user. It created an expectation\nthat its name would change when the state of the user would change.\n\nChange-Id: I620843df730520b55bfb709aaff1d63ce3f6e772\n'}, {'number': 2, 'created': '2013-07-17 13:14:42.000000000', 'files': ['openstack_dashboard/dashboards/admin/users/tests.py', 'openstack_dashboard/dashboards/admin/users/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/4c847ed34b29f374708c9886762f8c86ee03cf0c', 'message': 'rename ""enable"" action to ""toggle""\n\nThe previous action caused confusion when it was called ""enable"" in the\nWebUI for both a disabled and an enabled user. It created an expectation\nthat its name would change when the state of the user would change.\n\nFixes bug 1202187\n\nChange-Id: I620843df730520b55bfb709aaff1d63ce3f6e772\n'}]",2,33984,4c847ed34b29f374708c9886762f8c86ee03cf0c,23,6,2,2340,,,0,"rename ""enable"" action to ""toggle""

The previous action caused confusion when it was called ""enable"" in the
WebUI for both a disabled and an enabled user. It created an expectation
that its name would change when the state of the user would change.

Fixes bug 1202187

Change-Id: I620843df730520b55bfb709aaff1d63ce3f6e772
",git fetch https://review.opendev.org/openstack/horizon refs/changes/84/33984/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/users/tests.py', 'openstack_dashboard/dashboards/admin/users/tables.py']",2,f0d11f5f014af2f52e000549f65e32b4f6bf36d0,bug/1202187," name = ""toggle"" classes = (""btn-toggle"",)"," name = ""enable"" classes = (""btn-enable"",)",6,6
openstack%2Frequirements~master~I7e885bfe08959f6d328abb6655a24ff3bb6a7803,openstack/requirements,master,I7e885bfe08959f6d328abb6655a24ff3bb6a7803,Add dateutil to parse date and time,ABANDONED,2013-07-19 13:39:06.000000000,2013-07-22 10:03:28.000000000,,"[{'_account_id': 3}, {'_account_id': 5441}, {'_account_id': 6593}, {'_account_id': 6735}, {'_account_id': 7502}]","[{'number': 1, 'created': '2013-07-19 13:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/ea6136043c946de1ad8e7b8fe2db2935e024b85f', 'message': 'Add dateutil to parse date and time\n\nWe need to set datetime fields of sqlalchemy\nmodels using datetime type. dateutil\nprovides a parser to convert string to\ndatetime object\n\nfixes LP 1201766\n\nChange-Id: I7e885bfe08959f6d328abb6655a24ff3bb6a7803\n'}, {'number': 2, 'created': '2013-07-19 14:08:31.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/501b321d71da798135547fac81f7cfd34b3201fb', 'message': 'Add dateutil to parse date and time\n\nWe need to set datetime fields of sqlalchemy\nmodels using datetime type. dateutil\nprovides a parser to convert string to\ndatetime object\n\nfixes LP 1201766\n\nChange-Id: I7e885bfe08959f6d328abb6655a24ff3bb6a7803\n'}]",2,37899,501b321d71da798135547fac81f7cfd34b3201fb,9,5,2,7502,,,0,"Add dateutil to parse date and time

We need to set datetime fields of sqlalchemy
models using datetime type. dateutil
provides a parser to convert string to
datetime object

fixes LP 1201766

Change-Id: I7e885bfe08959f6d328abb6655a24ff3bb6a7803
",git fetch https://review.opendev.org/openstack/requirements refs/changes/99/37899/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,ea6136043c946de1ad8e7b8fe2db2935e024b85f,bug/1201766,python-dateutil==2.1,,1,0
openstack%2Fmurano-deployment~master~I6371cfa582b72a5853fe0188773278c910cc5c43,openstack/murano-deployment,master,I6371cfa582b72a5853fe0188773278c910cc5c43,murano-git-install updated.,MERGED,2013-07-22 09:45:25.000000000,2013-07-22 09:45:53.000000000,2013-07-22 09:45:53.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-22 09:45:25.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/feef3db8a1d7f285feed45355f4d549b46faec37', 'message': 'murano-git-install updated.\n\nChange-Id: I6371cfa582b72a5853fe0188773278c910cc5c43\n'}]",0,38128,feef3db8a1d7f285feed45355f4d549b46faec37,5,2,1,7562,,,0,"murano-git-install updated.

Change-Id: I6371cfa582b72a5853fe0188773278c910cc5c43
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/28/38128/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,feef3db8a1d7f285feed45355f4d549b46faec37,devbox-script-fix," printf ""$@\n"" | tee --append /tmp/murano-git-install.log '/etc/openstack-dashboard/local_settings.py') iniset '' 'OPENSTACK_HOST' ""'$LAB_HOST'"" ""$config_file"" ;;"," printf ""$@\n""",4,1
openstack%2Fcinder~master~Ia9d5a6e59e71f15ca8a31f463d9f77093b80f9e9,openstack/cinder,master,Ia9d5a6e59e71f15ca8a31f463d9f77093b80f9e9,add suds in requirements.txt,ABANDONED,2013-07-22 08:12:23.000000000,2013-07-22 09:32:03.000000000,,"[{'_account_id': 3}, {'_account_id': 1994}]","[{'number': 1, 'created': '2013-07-22 08:12:23.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/50c4bd959a1faa766de42f6ab2c10c3c36bf1071', 'message': ""add suds in requirements.txt\n\nsuds is imported in codes but not in requirements.txt, let's add it\n\nfixes bug #1203634\n\nChange-Id: Ia9d5a6e59e71f15ca8a31f463d9f77093b80f9e9\n""}]",0,38116,50c4bd959a1faa766de42f6ab2c10c3c36bf1071,3,2,1,6835,,,0,"add suds in requirements.txt

suds is imported in codes but not in requirements.txt, let's add it

fixes bug #1203634

Change-Id: Ia9d5a6e59e71f15ca8a31f463d9f77093b80f9e9
",git fetch https://review.opendev.org/openstack/cinder refs/changes/16/38116/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,50c4bd959a1faa766de42f6ab2c10c3c36bf1071,bug/1203634,suds>=0.4,,1,0
openstack%2Fheat~master~Ief258fd601b48e2495ac69091a942f23a019e92c,openstack/heat,master,Ief258fd601b48e2495ac69091a942f23a019e92c,Reset the the watch_rule.last_evaluated on start up,MERGED,2013-07-19 05:09:18.000000000,2013-07-22 09:30:13.000000000,2013-07-22 09:30:12.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7761}]","[{'number': 1, 'created': '2013-07-19 05:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fa2be38e02a19c33f03bd03133e282178bd0a176', 'message': ""Reset the the watch_rule.last_evaluated on start up\n\nThis is so we don't fire off alarms when the engine has not been running.\n\nbug 1202552\n\nChange-Id: Ief258fd601b48e2495ac69091a942f23a019e92c\n""}, {'number': 2, 'created': '2013-07-19 06:06:55.000000000', 'files': ['heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/07d1a9c90b2c96f231f9bd8fe6d59bfec8c1d22d', 'message': ""Reset the the watch_rule.last_evaluated on start up\n\nThis is so we don't fire off alarms when the engine has not been running.\n\nbug 1202552\n\nChange-Id: Ief258fd601b48e2495ac69091a942f23a019e92c\n""}]",0,37839,07d1a9c90b2c96f231f9bd8fe6d59bfec8c1d22d,9,5,2,4715,,,0,"Reset the the watch_rule.last_evaluated on start up

This is so we don't fire off alarms when the engine has not been running.

bug 1202552

Change-Id: Ief258fd601b48e2495ac69091a942f23a019e92c
",git fetch https://review.opendev.org/openstack/heat refs/changes/39/37839/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/service.py'],1,fa2be38e02a19c33f03bd03133e282178bd0a176,bug/1202552,from heat.openstack.common import timeutils # reset the last_evaluated so we don't fire off alarms when # the engine has not been running. now = timeutils.utcnow() for wr in wrs: wr.last_evaluated = now ,,8,0
openstack%2Fheat~master~I5053c53a3eebf5f43cddfb96ee63a1f4f8615e76,openstack/heat,master,I5053c53a3eebf5f43cddfb96ee63a1f4f8615e76,Refactor the code in heat/tests/test_volume.py,MERGED,2013-07-22 02:27:16.000000000,2013-07-22 09:28:06.000000000,2013-07-22 09:28:05.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}]","[{'number': 1, 'created': '2013-07-22 02:27:16.000000000', 'files': ['heat/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d12ebfa7b2e8d9ca93c94574cdfbe94ba5ad603a', 'message': 'Refactor the code in heat/tests/test_volume.py\n\nThe test code in heat/tests/test_volume.py has lots of\nduplicated code and logic.\nExtract them into common method and reuse the methods.\n\nChange-Id: I5053c53a3eebf5f43cddfb96ee63a1f4f8615e76'}]",0,38094,d12ebfa7b2e8d9ca93c94574cdfbe94ba5ad603a,6,3,1,7162,,,0,"Refactor the code in heat/tests/test_volume.py

The test code in heat/tests/test_volume.py has lots of
duplicated code and logic.
Extract them into common method and reuse the methods.

Change-Id: I5053c53a3eebf5f43cddfb96ee63a1f4f8615e76",git fetch https://review.opendev.org/openstack/heat refs/changes/94/38094/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_volume.py'],1,d12ebfa7b2e8d9ca93c94574cdfbe94ba5ad603a,bug#1197747," self._mock_create_volume(fv, stack_name) self._mock_create_volume(fv, stack_name) self._mock_create_volume(fv, stack_name) self._mock_create_server_volume_script(fva) self._mock_create_volume(fv, stack_name) self._mock_create_server_volume_script(fva) self._mock_create_volume(fv, stack_name) self._mock_create_server_volume_script(fva) self._mock_create_volume(fv, stack_name) self._mock_create_server_volume_script(fva) self._mock_create_volume(fv, stack_name) self._mock_create_volume(fv, stack_name) self._mock_create_volume(fv, stack_name) self._mock_create_volume(fv, stack_name) self._mock_create_server_volume_script(fva)"," clients.OpenStackClients.cinder().MultipleTimes().AndReturn( self.cinder_fc) vol_name = utils.PhysName(stack_name, 'DataVolume') self.cinder_fc.volumes.create( size=u'1', availability_zone='nova', display_description=vol_name, display_name=vol_name).AndReturn(fv) # create script clients.OpenStackClients.cinder().AndReturn(self.cinder_fc) vol_name = utils.PhysName(stack_name, 'DataVolume') self.cinder_fc.volumes.create( size=u'1', availability_zone='nova', display_description=vol_name, display_name=vol_name).AndReturn(fv) # volume create clients.OpenStackClients.cinder().MultipleTimes().AndReturn( self.cinder_fc) vol_name = utils.PhysName(stack_name, 'DataVolume') self.cinder_fc.volumes.create( size=u'1', availability_zone='nova', display_description=vol_name, display_name=vol_name).AndReturn(fv) # create script clients.OpenStackClients.nova().MultipleTimes().AndReturn(self.fc) self.fc.volumes.create_server_volume( device=u'/dev/vdc', server_id=u'WikiDatabase', volume_id=u'vol-123').AndReturn(fva) self.cinder_fc.volumes.get('vol-123').AndReturn(fva) # volume create clients.OpenStackClients.cinder().MultipleTimes().AndReturn( self.cinder_fc) vol_name = utils.PhysName(stack_name, 'DataVolume') self.cinder_fc.volumes.create( size=u'1', availability_zone='nova', display_description=vol_name, display_name=vol_name).AndReturn(fv) # create script clients.OpenStackClients.nova().MultipleTimes().AndReturn(self.fc) self.fc.volumes.create_server_volume( device=u'/dev/vdc', server_id=u'WikiDatabase', volume_id=u'vol-123').AndReturn(fva) self.cinder_fc.volumes.get('vol-123').AndReturn(fva) vol_name = utils.PhysName(stack_name, 'DataVolume') # volume create clients.OpenStackClients.cinder().MultipleTimes().AndReturn( self.cinder_fc) self.cinder_fc.volumes.create( size=u'1', availability_zone='nova', display_description=vol_name, display_name=vol_name).AndReturn(fv) # create script clients.OpenStackClients.nova().MultipleTimes().AndReturn(self.fc) self.fc.volumes.create_server_volume( device=u'/dev/vdc', server_id=u'WikiDatabase', volume_id=u'vol-123').AndReturn(fva) self.cinder_fc.volumes.get('vol-123').AndReturn(fva) vol_name = utils.PhysName(stack_name, 'DataVolume') # volume create clients.OpenStackClients.cinder().MultipleTimes().AndReturn( self.cinder_fc) self.cinder_fc.volumes.create( size=u'1', availability_zone='nova', display_description=vol_name, display_name=vol_name).AndReturn(fv) # create script clients.OpenStackClients.nova().MultipleTimes().AndReturn(self.fc) self.fc.volumes.create_server_volume( device=u'/dev/vdc', server_id=u'WikiDatabase', volume_id=u'vol-123').AndReturn(fva) self.cinder_fc.volumes.get('vol-123').AndReturn(fva) # create script clients.OpenStackClients.cinder().MultipleTimes().AndReturn( self.cinder_fc) vol_name = utils.PhysName(stack_name, 'DataVolume') self.cinder_fc.volumes.create( size=u'1', availability_zone='nova', display_description=vol_name, display_name=vol_name).AndReturn(fv) # create script clients.OpenStackClients.cinder().MultipleTimes().AndReturn( self.cinder_fc) vol_name = utils.PhysName(stack_name, 'DataVolume') self.cinder_fc.volumes.create( size=u'1', availability_zone='nova', display_description=vol_name, display_name=vol_name).AndReturn(fv) # create script clients.OpenStackClients.cinder().MultipleTimes().AndReturn( self.cinder_fc) vol_name = utils.PhysName(stack_name, 'DataVolume') self.cinder_fc.volumes.create( size=u'1', availability_zone='nova', display_description=vol_name, display_name=vol_name).AndReturn(fv) # volume create clients.OpenStackClients.cinder().MultipleTimes().AndReturn( self.cinder_fc) vol_name = utils.PhysName(stack_name, 'DataVolume') self.cinder_fc.volumes.create( size=u'1', availability_zone='nova', display_description=vol_name, display_name=vol_name).AndReturn(fv) # create script clients.OpenStackClients.nova().MultipleTimes().AndReturn(self.fc) self.fc.volumes.create_server_volume( device=u'/dev/vdc', server_id=u'WikiDatabase', volume_id=u'vol-123').AndReturn(fva) self.cinder_fc.volumes.get('vol-123').AndReturn(fva)",15,119
openstack%2Fheat~master~I555eea19409142ccb306c0cceaf7c55e71385bc6,openstack/heat,master,I555eea19409142ccb306c0cceaf7c55e71385bc6,Handle 'detaching' state of Volume,MERGED,2013-07-17 09:24:54.000000000,2013-07-22 09:21:14.000000000,2013-07-22 09:21:14.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 7162}, {'_account_id': 7253}, {'_account_id': 7761}]","[{'number': 1, 'created': '2013-07-17 09:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/49b9481840bf01d91cba61599c9e146a95aa3aa6', 'message': 'Fix bug when delete attached volume\n\nfixed bug #1197747\n\nChange-Id: I555eea19409142ccb306c0cceaf7c55e71385bc6'}, {'number': 2, 'created': '2013-07-18 08:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/83e771893143978c5d157e62d385a4b8e034f0aa', 'message': 'Fix bug when delete attached volume\n\nfixed bug #1197747\n\nChange-Id: I555eea19409142ccb306c0cceaf7c55e71385bc6'}, {'number': 3, 'created': '2013-07-19 03:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/75f8887b354ed6554a3e9d7cdc18aae0d7e09398', 'message': 'Fix bug when delete attached volume\n\nfixed bug #1197747\n\nChange-Id: I555eea19409142ccb306c0cceaf7c55e71385bc6'}, {'number': 4, 'created': '2013-07-22 02:13:38.000000000', 'files': ['heat/engine/resources/volume.py', 'heat/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/cd7acb5027e6e0c2e2bac80669f468ef95a1187b', 'message': ""Handle 'detaching' state of Volume\n\nWhen detaching volume, the state of volume changed from 'in-use'\nto 'detaching', and then from 'detaching' to 'available'.\nThe code used to ignore 'detaching' state by assuming the volume\nhas been detached when its state is not 'in-use' any more.\nNow we take care 'detaching' state and raise error if detaching\nfailed.\n\nFixes bug #1197747\n\nChange-Id: I555eea19409142ccb306c0cceaf7c55e71385bc6""}]",4,37434,cd7acb5027e6e0c2e2bac80669f468ef95a1187b,20,8,4,7162,,,0,"Handle 'detaching' state of Volume

When detaching volume, the state of volume changed from 'in-use'
to 'detaching', and then from 'detaching' to 'available'.
The code used to ignore 'detaching' state by assuming the volume
has been detached when its state is not 'in-use' any more.
Now we take care 'detaching' state and raise error if detaching
failed.

Fixes bug #1197747

Change-Id: I555eea19409142ccb306c0cceaf7c55e71385bc6",git fetch https://review.opendev.org/openstack/heat refs/changes/34/37434/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/volume.py'],1,49b9481840bf01d91cba61599c9e146a95aa3aa6,bug/1197747, while vol.status != 'available' and vol.status != 'error':, while vol.status == 'in-use':,1,1
openstack%2Fmurano-deployment~master~I1e8784054a9c7e6b0738ab05433196ee7966065c,openstack/murano-deployment,master,I1e8784054a9c7e6b0738ab05433196ee7966065c,murano-git-install updated.,MERGED,2013-07-22 08:25:24.000000000,2013-07-22 08:26:16.000000000,2013-07-22 08:26:16.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-22 08:25:24.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/b1448e09b73dc92c90f0f09d7ff910bcd012cfb4', 'message': 'murano-git-install updated.\n\nHere string fixed.\nHelp string updated.\n\nChange-Id: I1e8784054a9c7e6b0738ab05433196ee7966065c\n'}]",0,38117,b1448e09b73dc92c90f0f09d7ff910bcd012cfb4,5,2,1,7562,,,0,"murano-git-install updated.

Here string fixed.
Help string updated.

Change-Id: I1e8784054a9c7e6b0738ab05433196ee7966065c
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/17/38117/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,b1448e09b73dc92c90f0f09d7ff910bcd012cfb4,devbox-script-fix," cat << ""EOF"" > /etc/murano-deployment/lab-binding.rc # Vi / Vim notes # * Press 'i' to enter INSERT mode # * Edit the file # * Press <ESC>, then type ':wq' to (w)rite changes and (q)uit editor. printf '\n\n' read -p ""Press <Enter> to start editing the file in 'vi' (you have no choice) ... "" if [ -f '/etc/murano-deployment/lab-binding.rc' ] ; then vi '/etc/murano-deployment/lab-binding.rc' fi * reinstall - unisntall and then install all Murano components.", cat << EOF > /etc/murano-deployment/lab-binding.rc,13,1
openstack%2Ftripleo-image-elements~master~Ic35eca943ba76d421b61710b9fff018e17fb40bf,openstack/tripleo-image-elements,master,Ic35eca943ba76d421b61710b9fff018e17fb40bf,Do not automatically start os-refresh-config.,MERGED,2013-07-22 08:14:15.000000000,2013-07-22 08:14:15.000000000,2013-07-22 08:14:15.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}]","[{'number': 9, 'created': '2013-07-22 08:14:15.000000000', 'files': ['elements/heat-cfntools/os-config-applier/etc/cfn/hooks.conf', 'elements/os-refresh-config/install.d/75-cfn-hup-cronjob', 'elements/os-refresh-config/install.d/cfn-hup-wrapper', 'elements/os-refresh-config/install.d/01-os-refresh-config'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0d78da501fc72fe4db56ff018de9b5cfb40bea87', 'message': ""Do not automatically start os-refresh-config.\n\ncfn-hup needs to be the only thing running os-refresh-config. Otherwise\nthe other orc scripts will race with cfn-hup writing out new metadata.\nThe exception introduced here is to also let crond (which runs cfn-hup)\nrun os-refresh-config @reboot to seed the configuration.\n\nWithout a need to start up automatically, there doesn't seem to be any\ngood reason to use an upstart job / systemd service unit. Instead we\ncan just pipe os-refresh-config output to logger.\n\nAlso because we have several places to run os-refresh-config, we\nneed to move the locking into os-refresh-config itself. Please see\nhttps://review.openstack.org/37319 for that change.\n\nChange-Id: Ic35eca943ba76d421b61710b9fff018e17fb40bf\n""}, {'number': 8, 'created': '2013-07-22 08:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/c15cddaf2a8dc5dbcba6a3a2113175f44cd0b394', 'message': ""Do not automatically start os-refresh-config.\n\ncfn-hup needs to be the only thing running os-refresh-config. Otherwise\nthe other orc scripts will race with cfn-hup writing out new metadata.\nThe exception introduced here is to also let crond (which runs cfn-hup)\nrun os-refresh-config @reboot to seed the configuration.\n\nWithout a need to start up automatically, there doesn't seem to be any\ngood reason to use an upstart job / systemd service unit. Instead we\ncan just pipe os-refresh-config output to logger.\n\nAlso because we have several places to run os-refresh-config, we\nneed to move the locking into os-refresh-config itself. Please see\nhttps://review.openstack.org/37319 for that change.\n\nChange-Id: Ic35eca943ba76d421b61710b9fff018e17fb40bf\n""}, {'number': 5, 'created': '2013-07-22 08:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/57db3d4125168fb6fd10b78015411e1ad9bebeca', 'message': ""Do not automatically start os-refresh-config.\n\ncfn-hup needs to be the only thing running os-refresh-config. Otherwise\nthe other orc scripts will race with cfn-hup writing out new metadata.\nThe exception introduced here is to also let crond (which runs cfn-hup)\nrun os-refresh-config @reboot to seed the configuration.\n\nWithout a need to start up automatically, there doesn't seem to be any\ngood reason to use an upstart job / systemd service unit. Instead we\ncan just pipe os-refresh-config output to logger.\n\nAlso because we have several places to run os-refresh-config, we\nneed to move the locking into os-refresh-config itself. Please see\nhttps://review.openstack.org/37319 for that change.\n\nChange-Id: Ic35eca943ba76d421b61710b9fff018e17fb40bf\n""}, {'number': 4, 'created': '2013-07-22 08:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/7409e929a279cdd6f340609d0839c831ae030530', 'message': ""Do not automatically start os-refresh-config.\n\ncfn-hup needs to be the only thing running os-refresh-config. Otherwise\nthe other orc scripts will race with cfn-hup writing out new metadata.\n\nWithout a need to start up automatically, there doesn't seem to be any\ngood reason to use an upstart job / systemd service unit. Instead we\ncan just pipe os-refresh-config output to logger.\n\nOne circular dependency we have to resolve is that cfn-hup is configured\nby os-apply-config, which is run by os-refresh-config, which is run\nby cfn-hup.\n\nSo, to break this loop, we can run os-refresh-config when cfn-hup has\nno configuration.\n\nChange-Id: Ic35eca943ba76d421b61710b9fff018e17fb40bf\n""}, {'number': 7, 'created': '2013-07-22 08:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/aa91fcff0b6aa13b90e1cada0b0c2bc3a496009e', 'message': ""Do not automatically start os-refresh-config.\n\ncfn-hup needs to be the only thing running os-refresh-config. Otherwise\nthe other orc scripts will race with cfn-hup writing out new metadata.\nThe exception introduced here is to also let crond (which runs cfn-hup)\nrun os-refresh-config @reboot to seed the configuration.\n\nWithout a need to start up automatically, there doesn't seem to be any\ngood reason to use an upstart job / systemd service unit. Instead we\ncan just pipe os-refresh-config output to logger.\n\nAlso because we have several places to run os-refresh-config, we\nneed to move the locking into os-refresh-config itself. Please see\nhttps://review.openstack.org/37319 for that change.\n\nChange-Id: Ic35eca943ba76d421b61710b9fff018e17fb40bf\n""}, {'number': 6, 'created': '2013-07-22 08:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/b756e1b58358a176f241ce34bb292fcae698bc31', 'message': ""Do not automatically start os-refresh-config.\n\ncfn-hup needs to be the only thing running os-refresh-config. Otherwise\nthe other orc scripts will race with cfn-hup writing out new metadata.\nThe exception introduced here is to also let crond (which runs cfn-hup)\nrun os-refresh-config @reboot to seed the configuration.\n\nWithout a need to start up automatically, there doesn't seem to be any\ngood reason to use an upstart job / systemd service unit. Instead we\ncan just pipe os-refresh-config output to logger.\n\nAlso because we have several places to run os-refresh-config, we\nneed to move the locking into os-refresh-config itself. Please see\nhttps://review.openstack.org/37319 for that change.\n\nChange-Id: Ic35eca943ba76d421b61710b9fff018e17fb40bf\n""}, {'number': 1, 'created': '2013-07-22 08:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/76c3ac25625976cdf45647a2f72edbbcf6ffc998', 'message': ""Do not automatically start os-refresh-config.\n\ncfn-hup needs to be the only thing starting os-refresh-config. Otherwise\nthe other orc scripts will race with cfn-hup writing out new metadata.\n\nAlso we do actually want 'stop on runlevel [06]' to make sure that the\njob stops ASAP when the box is rebooting or shutting down.\n\nChange-Id: Ic35eca943ba76d421b61710b9fff018e17fb40bf\n""}, {'number': 3, 'created': '2013-07-22 08:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6cb5e15efd19b1939ed624d898aa2d6d6c3909b0', 'message': ""Do not automatically start os-refresh-config.\n\ncfn-hup needs to be the only thing running os-refresh-config. Otherwise\nthe other orc scripts will race with cfn-hup writing out new metadata.\n\nWithout a need to start up automatically, there doesn't seem to be any\ngood reason to use an upstart job / systemd service unit. Instead we\ncan just pipe os-refresh-config output to logger.\n\nOne circular dependency we have to resolve is that cfn-hup is configured\nby os-apply-config, which is normally only run by os-refresh-config. We\ncan run os-apply-config before orc to configure cfn-hup, but in this\none-time window between first boot and first complete run of orc we may\nhave inaccurate or broken configs on disk.\n\nChange-Id: Ic35eca943ba76d421b61710b9fff018e17fb40bf\n""}, {'number': 2, 'created': '2013-07-22 08:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f6c3619431349fcd5b6fd8cd04afb74a14b49f13', 'message': ""Do not automatically start os-refresh-config.\n\ncfn-hup needs to be the only thing running os-refresh-config. Otherwise\nthe other orc scripts will race with cfn-hup writing out new metadata.\n\nWithout a need to start up automatically, there doesn't seem to be any\ngood reason to use an upstart job / systemd service unit. Instead we\ncan just pipe os-refresh-config output to logger.\n\nOne circular dependency we have to resolve is that cfn-hup is configurd\nby os-apply-config, which is normally only run by os-refresh-config. We\ncan run os-apply-config before orc to configure cfn-hup, but in this\none-time window between first boot and first complete run of orc we may\nhave inaccurate or broken configs on disk.\n\nChange-Id: Ic35eca943ba76d421b61710b9fff018e17fb40bf\n""}]",1,37174,0d78da501fc72fe4db56ff018de9b5cfb40bea87,27,3,9,6488,,,0,"Do not automatically start os-refresh-config.

cfn-hup needs to be the only thing running os-refresh-config. Otherwise
the other orc scripts will race with cfn-hup writing out new metadata.
The exception introduced here is to also let crond (which runs cfn-hup)
run os-refresh-config @reboot to seed the configuration.

Without a need to start up automatically, there doesn't seem to be any
good reason to use an upstart job / systemd service unit. Instead we
can just pipe os-refresh-config output to logger.

Also because we have several places to run os-refresh-config, we
need to move the locking into os-refresh-config itself. Please see
https://review.openstack.org/37319 for that change.

Change-Id: Ic35eca943ba76d421b61710b9fff018e17fb40bf
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/74/37174/9 && git format-patch -1 --stdout FETCH_HEAD,"['elements/heat-cfntools/os-config-applier/etc/cfn/hooks.conf', 'elements/os-refresh-config/install.d/75-cfn-hup-cronjob', 'elements/os-refresh-config/install.d/cfn-hup-wrapper', 'elements/os-refresh-config/install.d/01-os-refresh-config']",4,0d78da501fc72fe4db56ff018de9b5cfb40bea87,ORC-REFACTOR,, # Upstart if [ -d /etc/init ] ; then cat > /etc/init/os-refresh-config.conf <<eof start on runlevel [2345] task exec os-refresh-config eof # Systemd elif [ -d /lib/systemd/system ] ; then cat > /lib/systemd/system/os-refresh-config.service <<eof [Unit] Description=Refresh Config on state change After=cloud-final.service Before=crond.service [Service] ExecStart=/bin/os-refresh-config [Install] WantedBy=multi-user.target eof # Make systemd take notice of it systemctl daemon-reload # Enable the service systemctl enable os-refresh-config.service else echo Only systems with systemd or upstart are supported. exit 1 fi,7,77
openstack%2Ftripleo-image-elements~master~I407678104353b180102e16894408c3ffa2d7db90,openstack/tripleo-image-elements,master,I407678104353b180102e16894408c3ffa2d7db90,Remove os-refresh-config call from wipe-openstack.,MERGED,2013-07-22 08:14:01.000000000,2013-07-22 08:14:01.000000000,2013-07-22 08:14:01.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4190}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-22 08:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/641fbe2abae398046470c027fc44f2556b975bb8', 'message': 'Just call init-neutron-ovs in wipe-openstack.\n\nPreviously we were running os-refresh-config to make sure we caught\neverything that had been refactored into orc scripts. After analysis, it\nseems that the only thing we need beore init-quantum is\ninit-neutron-ovs.\n\nChange-Id: I407678104353b180102e16894408c3ffa2d7db90\n'}, {'number': 3, 'created': '2013-07-22 08:14:01.000000000', 'files': ['elements/boot-stack/os-refresh-config/configure.d/85-init-neutron', 'elements/boot-stack/bin/wipe-openstack', 'elements/boot-stack/os-refresh-config/configure.d/51-init-openstack'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e86dc75725787f8f9e1e4d5e787343ae083d3321', 'message': 'Remove os-refresh-config call from wipe-openstack.\n\nPreviously we were running os-refresh-config to make sure we\ncaught everything that had been refactored into orc scripts. After\nanalysis, it seems that the only thing we need before init-neutron is\ninit-neutron-ovs. This is called later in the orc chain, so we have\nsplit wipe-openstack\'s call to init-neutron out into 85-init-neutron.\n\nIn addition, there was a check for ""is it already running"" behavior that\nis no longer needed since we should only have one orc running at a time\nwith the impending lock change. We have removed that behavior.\n\nFinally the init/wipe scripts don\'t need to be in the system PATH and thus\nhave been merged with their orc scripts, which were their only callers.\n\nChange-Id: I407678104353b180102e16894408c3ffa2d7db90\n'}, {'number': 2, 'created': '2013-07-22 08:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0dd64582f94edb1a90bb76c4cfeebed3ed2f68fa', 'message': ""Remove os-refresh-config call from wipe-openstack.\n\nPreviously we were running os-refresh-config to make sure we\ncaught everything that had been refactored into orc scripts. After\nanalysis, it seems that the only thing we need before init-neutron is\ninit-neutron-ovs. This is called later in the orc chain, so we have\nsplit wipe-openstack's call to init-neutron out into 85-init-neutron.\n\nChange-Id: I407678104353b180102e16894408c3ffa2d7db90\n""}]",1,37342,e86dc75725787f8f9e1e4d5e787343ae083d3321,13,4,3,6488,,,0,"Remove os-refresh-config call from wipe-openstack.

Previously we were running os-refresh-config to make sure we
caught everything that had been refactored into orc scripts. After
analysis, it seems that the only thing we need before init-neutron is
init-neutron-ovs. This is called later in the orc chain, so we have
split wipe-openstack's call to init-neutron out into 85-init-neutron.

In addition, there was a check for ""is it already running"" behavior that
is no longer needed since we should only have one orc running at a time
with the impending lock change. We have removed that behavior.

Finally the init/wipe scripts don't need to be in the system PATH and thus
have been merged with their orc scripts, which were their only callers.

Change-Id: I407678104353b180102e16894408c3ffa2d7db90
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/42/37342/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/boot-stack/bin/wipe-openstack'],1,641fbe2abae398046470c027fc44f2556b975bb8,ORC-REFACTOR,init-neutron-ovs,# XXX: Is this still needed ? # Reentering into os-refresh-config is a little terrifying : later refactoring # should remove this. os-refresh-config,1,5
openstack%2Fdesignate~master~I6658a0209fc7f0942188f7c518171e6b1fa2b4aa,openstack/designate,master,I6658a0209fc7f0942188f7c518171e6b1fa2b4aa,Sync requirements with openstack/requirements,MERGED,2013-07-20 12:10:30.000000000,2013-07-22 07:49:24.000000000,2013-07-22 07:49:24.000000000,"[{'_account_id': 3}, {'_account_id': 741}]","[{'number': 1, 'created': '2013-07-20 12:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/6e70dee3d56a8103975bffe3668d3021d8a37f26', 'message': 'Sync requirements with openstack/requirements\n\nThis switches us from the ipaddr lib, to the netaddr lib which is\nin use by other openstack projects.\n\nThis also means an updated:\n\n- keystoneclient\n- hacking\n- distribute\n- setuptools\n\nChange-Id: I6658a0209fc7f0942188f7c518171e6b1fa2b4aa\n'}, {'number': 2, 'created': '2013-07-20 12:18:58.000000000', 'files': ['designate/backend/base.py', 'requirements.txt', 'test-requirements.txt', 'designate/schema.py', 'designate/central/service.py', 'designate/storage/impl_sqlalchemy/migrate_repo/utils.py', 'designate/sqlalchemy/models.py', 'designate/api/v1/__init__.py', 'designate/sqlalchemy/session.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/eb16b1e1be8da26193fd3482c8f5eb55eebfcbc2', 'message': ""Sync requirements with openstack/requirements\n\nThis switches us from the ipaddr lib, to the netaddr lib which is\nin use by other openstack projects.\n\nThis also means an updated:\n\n- keystoneclient\n- hacking\n- distribute\n- setuptools\n\nFinally, we're violating two new Hacking rules (H231 / H501), so\nwe cleanup these violations.\n\nChange-Id: I6658a0209fc7f0942188f7c518171e6b1fa2b4aa\n""}]",0,38034,eb16b1e1be8da26193fd3482c8f5eb55eebfcbc2,7,2,2,741,,,0,"Sync requirements with openstack/requirements

This switches us from the ipaddr lib, to the netaddr lib which is
in use by other openstack projects.

This also means an updated:

- keystoneclient
- hacking
- distribute
- setuptools

Finally, we're violating two new Hacking rules (H231 / H501), so
we cleanup these violations.

Change-Id: I6658a0209fc7f0942188f7c518171e6b1fa2b4aa
",git fetch https://review.opendev.org/openstack/designate refs/changes/34/38034/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'designate/schema.py']",3,6e70dee3d56a8103975bffe3668d3021d8a37f26,,"import netaddr netaddr.IPAddress(instance, version=4) except netaddr.AddrFormatError: netaddr.IPAddress(instance, version=6) except netaddr.AddrFormatError:",import ipaddr ipaddr.IPv4Address(instance) except ipaddr.AddressValueError: ipaddr.IPv6Address(instance) except ipaddr.AddressValueError:,17,17
openstack%2Fceilometer~master~Iefb3ac8e92c273ddfff28fe848d2e7b0e6406321,openstack/ceilometer,master,Iefb3ac8e92c273ddfff28fe848d2e7b0e6406321,fix resource_metadata failure missing image data,MERGED,2013-07-09 00:31:38.000000000,2013-07-22 07:15:21.000000000,2013-07-22 07:15:21.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 4277}, {'_account_id': 4491}, {'_account_id': 7302}, {'_account_id': 7975}]","[{'number': 1, 'created': '2013-07-09 00:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/63715acac37f8894a874a31a65453d6f23e17a18', 'message': 'fix resource_metadata failure missing image data\n\nWhen image metadata is missing kernel and ramdisk causes exception.\n\nFixes bug 1197180\n\nChange-Id: Iefb3ac8e92c273ddfff28fe848d2e7b0e6406321\n'}, {'number': 2, 'created': '2013-07-12 22:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e67f7cf21e33175143d3a74c0543fdf27d0ef0c1', 'message': 'fix resource_metadata failure missing image data\n\nWhen image metadata is missing kernel and ramdisk causes exception.\n\nFixes bug 1197180\n\nChange-Id: Iefb3ac8e92c273ddfff28fe848d2e7b0e6406321\n'}, {'number': 3, 'created': '2013-07-16 12:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5be2aa3107523fdab341962fb313617637c16523', 'message': 'fix resource_metadata failure missing image data\n\nWhen image metadata is missing kernel and ramdisk causes exception.\n\nFixes bug 1197180\n\nChange-Id: Iefb3ac8e92c273ddfff28fe848d2e7b0e6406321\n'}, {'number': 4, 'created': '2013-07-16 12:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1434559be82cae683ae71e9db0710c01a53130c6', 'message': 'fix resource_metadata failure missing image data\n\nWhen image metadata is missing kernel and ramdisk causes exception.\n\nFixes bug 1197180\n\nChange-Id: Iefb3ac8e92c273ddfff28fe848d2e7b0e6406321\n'}, {'number': 5, 'created': '2013-07-16 13:10:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/75bcf7d0f08a47652d5222fe963150d4ccf72adc', 'message': 'fix resource_metadata failure missing image data\n\nWhen image metadata is missing kernel and ramdisk causes exception.\n\nFixes bug 1197180\n\nChange-Id: Iefb3ac8e92c273ddfff28fe848d2e7b0e6406321\n'}, {'number': 6, 'created': '2013-07-16 20:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4260317932f01fc2cbdeefb5bf0d745295c86d22', 'message': 'fix resource_metadata failure missing image data\n\nWhen image metadata is missing kernel and ramdisk causes exception.\n\nFixes bug 1197180\n\nChange-Id: Iefb3ac8e92c273ddfff28fe848d2e7b0e6406321\n'}, {'number': 7, 'created': '2013-07-18 02:07:19.000000000', 'files': ['tests/test_novaclient.py', 'ceilometer/nova_client.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e66e849cdd5e25e13b0a8a5862d40308a1206530', 'message': 'fix resource_metadata failure missing image data\n\nWhen image metadata is missing kernel and ramdisk causes exception.\n\nFixes bug 1197180\n\nChange-Id: Iefb3ac8e92c273ddfff28fe848d2e7b0e6406321\n'}]",13,36152,e66e849cdd5e25e13b0a8a5862d40308a1206530,29,9,7,4277,,,0,"fix resource_metadata failure missing image data

When image metadata is missing kernel and ramdisk causes exception.

Fixes bug 1197180

Change-Id: Iefb3ac8e92c273ddfff28fe848d2e7b0e6406321
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/52/36152/5 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_novaclient.py', 'ceilometer/nova_client.py']",2,63715acac37f8894a874a31a65453d6f23e17a18,bug/1197180," for instance in instances: self._with_flavor(instance) self._with_image(instance) def _with_flavor(self, instance): fid = instance.flavor['id'] try: flavor = self.nova_client.flavors.get(fid) except novaclient.exceptions.NotFound: instance.flavor['name'] = 'unknown-id-%s' % fid return for attr, default in [('name', 'unknown-id-%s' % fid), ('vcpus', 0), ('ram', 0), ('disk', 0)]: instance.flavor[attr] = getattr(flavor, attr, default) def _with_image(self, instance): iid = instance.image['id'] try: image = self.nova_client.images.get(iid) except novaclient.exceptions.NotFound: instance.image['name'] = 'unknown-id-%s' % iid instance.kernel_id = None instance.ramdisk_id = None return instance.image['name'] = getattr(image, 'name') try: image_metadata = getattr(image, 'metadata') except TypeError: return for attr in ['kernel_id', 'ramdisk_id']: try: setattr(instance, attr, image_metadata.get(attr)) except (KeyError): setattr(instance, attr, None) "," flavor_attrs = ['name', 'vcpus', 'ram', 'disk'] for instance in instances: fid = instance.flavor['id'] try: flavor = self.nova_client.flavors.get(fid) except novaclient.exceptions.NotFound: flavor = None for attr in flavor_attrs: try: instance.flavor[attr] = getattr(flavor, attr) except (KeyError, AttributeError): if attr == 'name': instance.flavor['name'] = 'unknown-id-%s' % fid iid = instance.image['id'] try: image = self.nova_client.images.get(iid) except novaclient.exceptions.NotFound: image = None try: image_meta = getattr(image, 'metadata') except (KeyError, AttributeError): instance.image['name'] = 'unknown-id-%s' % iid else: instance.image['name'] = getattr(image, 'name') instance.kernel_id = image_meta['kernel_id'] instance.ramdisk_id = image_meta['ramdisk_id']",76,30
openstack%2Fheat~master~I14c1b0b6aa6ea3529c4de994851f7a798a3061bf,openstack/heat,master,I14c1b0b6aa6ea3529c4de994851f7a798a3061bf,add docs from the heat wiki,MERGED,2013-07-16 18:36:49.000000000,2013-07-22 06:53:21.000000000,2013-07-22 06:53:21.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6434}, {'_account_id': 6460}, {'_account_id': 6602}, {'_account_id': 7090}, {'_account_id': 7193}, {'_account_id': 7253}]","[{'number': 1, 'created': '2013-07-16 18:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c5df6e907cb00ec3ccaa9c3bb25553820977246c', 'message': 'create new layout to match the docs that keystone maintains, porting more docs soon from https://wiki.openstack.org/wiki/Heat\n\nChange-Id: I14c1b0b6aa6ea3529c4de994851f7a798a3061bf\n'}, {'number': 2, 'created': '2013-07-16 18:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6369dcee97462b6b486c3a40669292ddec6cb68f', 'message': 'add docs from the heat wiki\n\ncreate new layout to match the docs that keystone maintains, porting more docs soon from https://wiki.openstack.org/wiki/Heat\n\nChange-Id: I14c1b0b6aa6ea3529c4de994851f7a798a3061bf\n'}, {'number': 3, 'created': '2013-07-16 18:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f60e7eb2cfcb54ca97546e5d92e883421965ba86', 'message': 'add docs from the heat wiki\n\nupdated index.rst to mimic the layout of the keystone docs\nupdated the structure for troubleshooting\nported guides from the heat wiki\nupdated the nav for the man pages and getting started\n\nChange-Id: I14c1b0b6aa6ea3529c4de994851f7a798a3061bf\n'}, {'number': 4, 'created': '2013-07-16 19:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e495cbf47b06412e181f1288d8f4d58810d31382', 'message': 'add docs from the heat wiki\n\nupdated index.rst to mimic the layout of the keystone docs\nupdated the structure for troubleshooting\nported howto guides from the heat wiki\nported the troubleshooting page from the heat wiki\nupdated the nav for the man pages and getting started\n\nChange-Id: I14c1b0b6aa6ea3529c4de994851f7a798a3061bf\n'}, {'number': 5, 'created': '2013-07-17 12:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/be212f080be3baf39562ad53c8bda31968f6cb7d', 'message': 'add docs from the heat wiki\n\nupdated index.rst to mimic the layout of the keystone docs\nupdated the structure for troubleshooting\nported howto guides from the heat wiki\nported the troubleshooting page from the heat wiki\nupdated the nav for the man pages and getting started\n\nChange-Id: I14c1b0b6aa6ea3529c4de994851f7a798a3061bf\n'}, {'number': 6, 'created': '2013-07-17 14:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fbf9a62667b5d11f05c44c273f36da44790acd00', 'message': 'add docs from the heat wiki\n\nupdated index.rst to mimic the layout of the keystone docs\nupdated the structure for troubleshooting\nported howto guides from the heat wiki\nported the troubleshooting page from the heat wiki\nupdated the nav for the man pages and getting started\nadded docs for a cfn template and hot template\n\nChange-Id: I14c1b0b6aa6ea3529c4de994851f7a798a3061bf\n'}, {'number': 7, 'created': '2013-07-17 20:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/64c35b16476f430febf135c6aee82858e13e9c0c', 'message': 'add docs from the heat wiki\n\nupdated index.rst to mimic the layout of the keystone docs\nupdated the structure for troubleshooting\nported howto guides from the heat wiki\nported the troubleshooting page from the heat wiki\nupdated the nav for the man pages and getting started\nadded docs for a cfn template and hot template\n\nChange-Id: I14c1b0b6aa6ea3529c4de994851f7a798a3061bf\n'}, {'number': 8, 'created': '2013-07-17 22:05:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f364976e0bfccc052babebfc2bcb2df642f5307d', 'message': 'add docs from the heat wiki\n\nupdated index.rst to mimic the layout of the keystone docs\nupdated the structure for troubleshooting\nported howto guides from the heat wiki\nported the troubleshooting page from the heat wiki\nupdated the nav for the man pages and getting started\nadded docs for a cfn template and hot template\n\nChange-Id: I14c1b0b6aa6ea3529c4de994851f7a798a3061bf\n'}, {'number': 9, 'created': '2013-07-17 22:35:27.000000000', 'files': ['doc/source/index.rst', 'doc/source/architecture.rst', 'doc/source/templates/cfn/WordPress_Single_Instance.rst', 'doc/source/getting_started/index.rst', 'doc/source/templates/index.rst', 'doc/source/templates/hot/hello_world.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/6bfd774df842195969814201f6bf5dc8a1ec4797', 'message': 'add docs from the heat wiki\n\nupdated index.rst to mimic the layout of the keystone docs\nupdated the structure for troubleshooting\nported howto guides from the heat wiki\nported the troubleshooting page from the heat wiki\nupdated the nav for the man pages and getting started\nadded docs for a cfn template and hot template\n\nChange-Id: I14c1b0b6aa6ea3529c4de994851f7a798a3061bf\n'}]",13,37302,6bfd774df842195969814201f6bf5dc8a1ec4797,30,9,9,7090,,,0,"add docs from the heat wiki

updated index.rst to mimic the layout of the keystone docs
updated the structure for troubleshooting
ported howto guides from the heat wiki
ported the troubleshooting page from the heat wiki
updated the nav for the man pages and getting started
added docs for a cfn template and hot template

Change-Id: I14c1b0b6aa6ea3529c4de994851f7a798a3061bf
",git fetch https://review.opendev.org/openstack/heat refs/changes/02/37302/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/howto_guides/index.rst', 'doc/source/howto_guides/using_the_metadata_server.rst', 'doc/source/index.rst', 'doc/source/troubleshooting/index.rst', 'doc/source/architecture.rst']",5,c5df6e907cb00ec3ccaa9c3bb25553820977246c,bug/1201823,".. Copyright 2011-2012 OpenStack, LLC All Rights Reserved. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Heat Architecture ===================== Heat is a service to orchestrate multiple composite cloud applications using the .. _AWS CloudFormation: http://docs.aws.amazon.com/AWSCloudFormation/latest/APIReference/Welcome.html?r=7078 template format, through both an OpenStack-native ReST API and a CloudFormation-compatible Query API. ------------ Detailed Description ------------ What is the purpose of the project and vision for it? * Heat provides an AWS CloudFormation implementation for OpenStack that orchestrates an AWS CloudFormation template describing a cloud application by executing appropriate OpenStack API calls to generate running cloud applications. Describe the relevance of the project to other OpenStack projects and the OpenStack mission to provide a ubiquitous cloud computing platform: *The software integrates other core components of OpenStack into a one-file template system. The templates allow creation of most OpenStack resource types (such as instances, floating ips, volumes, security groups, users, etc), as well as some more advanced functionality such as instance high availability, instance autoscaling, and nested stacks. By providing very tight integration with other OpenStack core projects, all OpenStack core projects could receive a larger user base. *Currently no other CloudFormation implementation exists for OpenStack. The developers believe cloud developers have a strong desire to move workloads from AWS to OpenStack deployments. Given the missing gap of a well-implemented and integrated CloudFormation API in OpenStack, we provide a high quality implementation of this gap improving the ubiquity of OpenStack. ------------ Heat Services ------------ The developers are focused on creating an OpenStack style project using OpenStack design tenets, implemented in Python. We have started with full integration with Keystone. We have a number of components. As the developers have only started development in March 2012, the architecture is evolving rapidly. heat -------- The heat tool is a CLI which communicates with the heat-api to execute AWS CloudFormation APIs. End developers could also use the heat REST API directly. heat-api ----- The heat-api component provides an OpenStack-native REST API that processes API requests by sending them to the heat-engine over RPC. heat-api-cfn ------- The heat-api-cfn component provides an AWS Query API that is compatible with AWS CloudFormation and processes API requests by sending them to the heat-engine over RPC. heat-engine ------ The heat engine's main responsibility is to orchestrate the launching of templates and provide events back to the API consumer. The templates integrate well with .. _Puppet: https://s3.amazonaws.com/cloudformation-examples/IntegratingAWSCloudFormationWithPuppet.pdf and .. _Chef: http://www.full360.com/2011/02/27/integrating-aws-cloudformation-and-chef.html",,191,11
openstack%2Fcinder~master~I69031c6d3febe11dd5f9ff17095b86f3fe72a2a4,openstack/cinder,master,I69031c6d3febe11dd5f9ff17095b86f3fe72a2a4,3PAR Driver modifications to support QOS,MERGED,2013-07-18 18:12:29.000000000,2013-07-22 06:46:07.000000000,2013-07-22 06:46:07.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 6604}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-07-18 18:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2391785e0a734121a904137eb5ac8da9c814f01a', 'message': '3PAR Driver modifications to support QOS\n\nCurrently, the OpenStack HP 3PAR Fibre Channel (FC) and iSCSI Drivers\ndo not support Quality of Service (QoS) extra specs. The QoS settings\nadded in this patch include;\n   maximum MB/second (maxBWS)\n   maximum IO/second (maxIOPS)\nThese new extra specs will be scoped keys, the scoping will be\nhp3par:maxIBWS and hp3par:maxIOPS. A new key hp3par:vvs was also\nadded to allow the admin to predefine QOS settings on a 3PAR\nvirtual volume set and the any volume created would be a added\nto that predefined volume set.\n\nThe 3PAR storage arrays set these values on virtual volume sets,\nnot the actual volume. So the change includes creating a virtual\nvolume set with these settings and then adding the volume to the\nvolume set.\n1.  Max IO/S & Max MB/S are not QoS guarantees\n2.  These are per volume maximums which the 3PAR is guaranteed\nnot to exceed.\n3.  Settings these values does not guarantee these performance\nrates will be achievable\n\nDocImpact\n\nImplements blueprint 3par-qos-support\n\nChange-Id: I69031c6d3febe11dd5f9ff17095b86f3fe72a2a4\n'}, {'number': 2, 'created': '2013-07-18 18:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dbc7bec21c5c6ef4767fc01bf769c564fc4be806', 'message': '3PAR Driver modifications to support QOS\n\nCurrently, the OpenStack HP 3PAR Fibre Channel (FC) and iSCSI Drivers\ndo not support Quality of Service (QoS) extra specs. The QoS settings\nadded in this patch include;\n   maximum MB/second (maxBWS)\n   maximum IO/second (maxIOPS)\nThese new extra specs will be scoped keys, the scoping will be\nhp3par:maxIBWS and hp3par:maxIOPS. A new key hp3par:vvs was also\nadded to allow the admin to predefine QOS settings on a 3PAR\nvirtual volume set and the any volume created would be a added\nto that predefined volume set.\n\nThe 3PAR storage arrays set these values on virtual volume sets,\nnot the actual volume. So the change includes creating a virtual\nvolume set with these settings and then adding the volume to the\nvolume set.\n1.  Max IO/S & Max MB/S are not QoS guarantees\n2.  These are per volume maximums which the 3PAR is guaranteed\nnot to exceed.\n3.  Settings these values does not guarantee these performance\nrates will be achievable\n\nDocImpact\n\nImplements blueprint 3par-qos-support\n\nChange-Id: I69031c6d3febe11dd5f9ff17095b86f3fe72a2a4\n'}, {'number': 3, 'created': '2013-07-18 22:04:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c6f629f3cb70a349e3e49e3735c941ca55b2bb62', 'message': '3PAR Driver modifications to support QOS\n\nCurrently, the OpenStack HP 3PAR Fibre Channel (FC) and iSCSI Drivers\ndo not support Quality of Service (QoS) extra specs. The QoS settings\nadded in this patch include;\n   maximum MB/second (maxBWS)\n   maximum IO/second (maxIOPS)\nThese new extra specs will be scoped keys, the scoping will be\nhp3par:maxIBWS and hp3par:maxIOPS. A new key hp3par:vvs was also\nadded to allow the admin to predefine QOS settings on a 3PAR\nvirtual volume set and any volume created would be added\nto that predefined volume set.\n\nThe 3PAR storage arrays set these values on virtual volume sets,\nnot the actual volume. So the change includes creating a virtual\nvolume set with these settings and then adding the volume to the\nvolume set.\n1.  Max IO/S & Max MB/S are not QoS guarantees\n2.  These are per volume maximums which the 3PAR is guaranteed\nnot to exceed.\n3.  Settings these values does not guarantee these performance\nrates will be achievable\n\nDocImpact\n\nImplements blueprint 3par-qos-support\n\nChange-Id: I69031c6d3febe11dd5f9ff17095b86f3fe72a2a4\n'}, {'number': 4, 'created': '2013-07-18 23:09:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4cd554dc887e659d2a0c387c196daa398567ab72', 'message': '3PAR Driver modifications to support QOS\n\nCurrently, the OpenStack HP 3PAR Fibre Channel (FC) and iSCSI Drivers\ndo not support Quality of Service (QoS) extra specs. The QoS settings\nadded in this patch include;\n   maximum MB/second (maxBWS)\n   maximum IO/second (maxIOPS)\nThese new extra specs will be scoped keys, the scoping will be\nqos:maxBWS and qos:maxIOPS. A new key hp3par:vvs was also\nadded to allow the admin to predefine QOS settings on a 3PAR\nvirtual volume set and any volume created would be added\nto that predefined volume set.\n\nThe 3PAR storage arrays set these values on virtual volume sets,\nnot the actual volume. So the change includes creating a virtual\nvolume set with these settings and then adding the volume to the\nvolume set.\n1.  Max IO/S & Max MB/S are not QoS guarantees\n2.  These are per volume maximums which the 3PAR is guaranteed\nnot to exceed.\n3.  Settings these values does not guarantee these performance\nrates will be achievable\n\nDocImpact\n\nImplements blueprint 3par-qos-support\n\nChange-Id: I69031c6d3febe11dd5f9ff17095b86f3fe72a2a4\n'}, {'number': 5, 'created': '2013-07-19 18:12:43.000000000', 'files': ['cinder/volume/drivers/san/hp/hp_3par_fc.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a048cd66d4af66f2d6095762e5293ae9d81d03a2', 'message': '3PAR Driver modifications to support QOS\n\nCurrently, the OpenStack HP 3PAR Fibre Channel (FC) and iSCSI Drivers\ndo not support Quality of Service (QoS) extra specs. The QoS settings\nadded in this patch include;\n   maximum MB/second (maxBWS)\n   maximum IO/second (maxIOPS)\nThese new extra specs will be scoped keys, the scoping will be\nqos:maxBWS and qos:maxIOPS. A new key hp3par:vvs was also\nadded to allow the admin to predefine QOS settings on a 3PAR\nvirtual volume set and any volume created would be added\nto that predefined volume set.\n\nThe 3PAR storage arrays set these values on virtual volume sets,\nnot the actual volume. So the change includes creating a virtual\nvolume set with these settings and then adding the volume to the\nvolume set.\n1.  Max IO/S & Max MB/S are not QoS guarantees\n2.  These are per volume maximums which the 3PAR is guaranteed\nnot to exceed.\n3.  Settings these values does not guarantee these performance\nrates will be achievable\n\nDocImpact\n\nImplements blueprint 3par-qos-support\n\nChange-Id: I69031c6d3febe11dd5f9ff17095b86f3fe72a2a4\n'}]",25,37736,a048cd66d4af66f2d6095762e5293ae9d81d03a2,36,9,5,6043,,,0,"3PAR Driver modifications to support QOS

Currently, the OpenStack HP 3PAR Fibre Channel (FC) and iSCSI Drivers
do not support Quality of Service (QoS) extra specs. The QoS settings
added in this patch include;
   maximum MB/second (maxBWS)
   maximum IO/second (maxIOPS)
These new extra specs will be scoped keys, the scoping will be
qos:maxBWS and qos:maxIOPS. A new key hp3par:vvs was also
added to allow the admin to predefine QOS settings on a 3PAR
virtual volume set and any volume created would be added
to that predefined volume set.

The 3PAR storage arrays set these values on virtual volume sets,
not the actual volume. So the change includes creating a virtual
volume set with these settings and then adding the volume to the
volume set.
1.  Max IO/S & Max MB/S are not QoS guarantees
2.  These are per volume maximums which the 3PAR is guaranteed
not to exceed.
3.  Settings these values does not guarantee these performance
rates will be achievable

DocImpact

Implements blueprint 3par-qos-support

Change-Id: I69031c6d3febe11dd5f9ff17095b86f3fe72a2a4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/36/37736/5 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/san/hp/hp_3par_fc.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py']",4,2391785e0a734121a904137eb5ac8da9c814f01a,bp/3par-qos-support," hp_qos_keys = ['maxIOPS', 'maxBWS'] err = (_(""Failed to get domain because CPG (%s) doesn't "" ""exist on array."") % cpg_name) def _get_3par_vvs_name(self, volume_id): vvs_name = self._encode_name(volume_id) return ""vvs-%s"" % vvs_name 'QoS_support': True, def _get_qos_value(self, qos, key, default=None): if key in qos: return qos[key] else: return default def _get_qos_by_volume_type(self, volume_type): qos = {} specs = volume_type.get('extra_specs') for key, value in specs.iteritems(): if ':' in key: fields = key.split(':') key = fields[1] if key in self.hp_qos_keys: qos[key] = int(value) return qos def _set_qos_rule(self, qos, vvs_name): max_io = self._get_qos_value(qos, 'maxIOPS') max_bw = self._get_qos_value(qos, 'maxBWS') cli_qos_string = """" if max_io is not None: cli_qos_string += ('-io %s ' % max_io) if max_bw is not None: cli_qos_string += ('-bw %sM ' % max_bw) self._cli_run('setqos %svvset:%s' % (cli_qos_string, vvs_name), None) def _add_volume_to_volume_set(self, volume, volume_name, cpg, vvs_name, qos): if vvs_name is not None: # Admin has set a volume set name to add the volume too self._cli_run('createvvset -add %s %s' % (vvs_name, volume_name), None) else: vvs_name = self._get_3par_vvs_name(volume['id']) domain = self.get_domain(cpg) self._cli_run('createvvset -domain %s %s' % (domain, vvs_name), None) self._set_qos_rule(qos, vvs_name) self._cli_run('createvvset -add %s %s' % (vvs_name, volume_name), None) def _remove_volume_set(self, vvs_name): # Must first clear the QoS rules before removing the volume set self._cli_run('setqos -clear vvset:%s' % (vvs_name), None) self._cli_run('removevvset -f %s' % (vvs_name), None) def _remove_volume_from_volume_set(self, volume_name, vvs_name): self._cli_run('removevvset -f %s %s' % (vvs_name, volume_name), None) vvs_name = None qos = {} vvs_name = self._get_key_value(hp3par_keys, 'vvs') if vvs_name is None: qos = self._get_qos_by_volume_type(volume_type) if vvs_name is not None: comments['vvs'] = vvs_name else: comments['qos'] = qos if qos or vvs_name is not None: try: self._add_volume_to_volume_set(volume, volume_name, cpg, vvs_name, qos) except Exception as ex: # Delete the volume if unable to add it to the volume set self.client.deleteVolume(volume_name) LOG.error(str(ex)) raise exception.CinderException(ex.get_description()) 'snapCPG': extras['snapCPG'], 'qos': str(qos), 'vvs': vvs_name} qos = self.get_volume_metadata_value(volume, 'qos') vvs_name = self.get_volume_metadata_value(volume, 'vvs') if vvs_name is not None: self._remove_volume_from_volume_set(volume_name, vvs_name) elif qos: self._remove_volume_set(self._get_3par_vvs_name(volume['id'])) volume_name = self._get_3par_vol_name(volume['id']) volume_type = None type_id = volume.get('volume_type_id', None) vvs_name = None qos = {} hp3par_keys = {} if type_id is not None: volume_type = self._get_volume_type(type_id) hp3par_keys = self._get_keys_by_volume_type(volume_type) vvs_name = self._get_key_value(hp3par_keys, 'vvs') if vvs_name is None: qos = self._get_qos_by_volume_type(volume_type) self.client.createSnapshot(volume_name, snap_name, optional) if qos or vvs_name is not None: cpg = self._get_key_value(hp3par_keys, 'cpg', self.config.hp3par_cpg) try: self._add_volume_to_volume_set(volume, volume_name, cpg, vvs_name, qos) except Exception as ex: # Delete the volume if unable to add it to the volume set self.client.deleteVolume(volume_name) LOG.error(str(ex)) raise exception.CinderException(ex.get_description()) except Exception as ex: LOG.error(str(ex)) raise exception.CinderException(ex.get_description()) metadata = {'3ParName': volume_name, 'qos': str(qos), 'vvs': vvs_name} return metadata"," err = (_(""CPG (%s) doesn't exist on array."") % cpg_name) 'snapCPG': extras['snapCPG']} vol_name = self._get_3par_vol_name(volume['id']) self.client.createSnapshot(vol_name, snap_name, optional)",197,23
openstack%2Fneutron~master~Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2,openstack/neutron,master,Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2,Add agent scheduling for LBaaS namespace agent,MERGED,2013-07-06 16:06:39.000000000,2013-07-22 06:21:05.000000000,2013-07-22 06:21:04.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 5948}, {'_account_id': 6072}]","[{'number': 8, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fe1f2daf2a7206e9a0be8046166457168829c418', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 9, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cc7ce80588713196b013b60b891c73a4d730d362', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 6, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fa23e8445c93ae4c08e40f8b56e321db1196eb13', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds controllers to agentscheduler extension to be able\n  to list pools hosted by a particular agent and\n  to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 7, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b4342dcf0b4a67cfa3e62bf7056e7c55541b89bc', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds controllers to agentscheduler extension to be able\n  to list pools hosted by a particular agent and\n  to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4416a57e7def4a595b7947a12ad3eb0b5cdb27c8', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds controllers to agentscheduler extension to be able\n  to list pools hosted by a particular agent and\n  to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 5, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/09791134792682ed9701e794325f2a7431423e04', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds controllers to agentscheduler extension to be able\n  to list pools hosted by a particular agent and\n  to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c8d1d2792d31f29ebaafe5d6cc4b319a95c15458', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds controllers to agentscheduler extension to be able\n  to list pools hosted by a particular agent and\n  to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/786e2c587de8cb2debb3cdd3e230e705320eb98b', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds controllers to agentscheduler extension to be able\n  to list pools hosted by a particular agent and\n  to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d14ce00dd7b8fa4c5746aa1afd4eeb42d45526c', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds controllers to agentscheduler extension to be able\n  to list pools hosted by a particular agent and\n  to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 10, 'created': '2013-07-08 11:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ddde1e54e81f3157a0b987e7cc39eed929765c95', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 11, 'created': '2013-07-16 09:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b1f4c1cb7b22cd2e37d76b3cf9b5bbd4e0a9842', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 12, 'created': '2013-07-16 10:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dfeb679d4206f4c8984b7b89ebb25c8599cd5fc5', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 13, 'created': '2013-07-16 14:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/50747d7048feb8994d8c780d0aa8828251855371', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 14, 'created': '2013-07-16 14:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/107bc694326e28c272d83cd7bf82e1bc787a0fe6', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 15, 'created': '2013-07-17 12:10:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e3ef65f264977611b7ecff0aba958fd56cc9c9a', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 16, 'created': '2013-07-17 12:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f48d9e3bddb63ddc166f7f82d9b5e031f77f6de', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 17, 'created': '2013-07-17 13:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e745292e9306e3c01e51e7962d8cc9f7eb7a1358', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 18, 'created': '2013-07-18 09:11:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/875bbb5bbdfb68ae20b914f576f7ce5a2169ff20', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 19, 'created': '2013-07-18 09:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b4f71d27609ece2c875761b4d34e550e01215a25', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 20, 'created': '2013-07-19 09:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f5c520175c361d37cd3d07254ea0eb0665ddd59', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}, {'number': 21, 'created': '2013-07-19 09:25:52.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/52c5e4a18807_lbaas_pool_scheduler.py', 'neutron/plugins/linuxbridge/lb_neutron_plugin.py', 'neutron/db/agentschedulers_db.py', 'neutron/plugins/openvswitch/ovs_neutron_plugin.py', 'neutron/services/loadbalancer/plugin.py', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/test_plugin_driver.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py', 'neutron/manager.py', 'neutron/tests/unit/test_neutron_manager.py', 'neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py', 'etc/policy.json', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py', 'neutron/services/loadbalancer/drivers/haproxy/agent.py', 'neutron/services/loadbalancer/drivers/noop/noop_driver.py', 'neutron/tests/unit/dummy_plugin.py', 'etc/neutron.conf', 'neutron/plugins/brocade/NeutronPlugin.py', 'neutron/extensions/lbaas_agentscheduler.py', 'neutron/plugins/nec/nec_plugin.py', 'neutron/services/loadbalancer/drivers/haproxy/agent_manager.py', 'neutron/services/loadbalancer/agent_scheduler.py', 'neutron/tests/unit/test_agent_ext_plugin.py', 'neutron/db/agents_db.py', 'neutron/common/constants.py', 'neutron/tests/unit/services/loadbalancer/test_agent_scheduler.py', 'neutron/plugins/nicira/NeutronPlugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/da65fe6951531146113185726dd0c955aa3df75d', 'message': 'Add agent scheduling for LBaaS namespace agent\n\n- adds simple chance scheduling on create pool operation\n- adds PoolsLoadbalancerAgentBinding db table\n- adds lbaas_agentscheduler extension to list pools hosted by a particular agent\n  and to get an agent hosting a particular pool\n- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier\n  for services to add their agent notifiers to the core plugin\n\nImplements blueprint lbaas-agent-scheduler\nChange-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2\n'}]",102,32137,da65fe6951531146113185726dd0c955aa3df75d,93,8,21,5948,,,0,"Add agent scheduling for LBaaS namespace agent

- adds simple chance scheduling on create pool operation
- adds PoolsLoadbalancerAgentBinding db table
- adds lbaas_agentscheduler extension to list pools hosted by a particular agent
  and to get an agent hosting a particular pool
- adds agent notifiers mapping to AgentSchedulerDbMixin to make it easier
  for services to add their agent notifiers to the core plugin

Implements blueprint lbaas-agent-scheduler
Change-Id: Id98649fd5c7873dcd5be1a2b117b8bed25f06cc2
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/32137/20 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/plugins/openvswitch/ovs_quantum_plugin.py', 'quantum/db/migration/alembic_migrations/versions/52c5e4a18807_lbaas_pool_scheduler.py', 'quantum/tests/unit/services/loadbalancer/test_agent_scheduler.py', 'quantum/tests/unit/dummy_plugin.py', 'quantum/tests/unit/test_quantum_manager.py', 'quantum/plugins/nec/nec_plugin.py', 'quantum/plugins/linuxbridge/lb_quantum_plugin.py', 'quantum/tests/unit/openvswitch/test_agent_scheduler.py', 'quantum/manager.py', 'quantum/services/loadbalancer/drivers/haproxy/agent.py', 'quantum/tests/unit/services/loadbalancer/drivers/haproxy/test_plugin_driver.py', 'quantum/db/agents_db.py', 'quantum/services/loadbalancer/drivers/haproxy/plugin_driver.py', 'etc/lbaas_agent.ini', 'etc/policy.json', 'quantum/plugins/nicira/QuantumPlugin.py', 'quantum/services/loadbalancer/plugin.py', 'quantum/extensions/lbaas_agentscheduler.py', 'quantum/services/loadbalancer/agent_scheduler.py', 'quantum/tests/unit/test_agent_ext_plugin.py', 'quantum/services/loadbalancer/drivers/haproxy/agent_manager.py', 'quantum/tests/unit/db/loadbalancer/test_db_loadbalancer.py', 'quantum/plugins/brocade/QuantumPlugin.py', 'quantum/plugins/ml2/plugin.py', 'quantum/common/constants.py', 'quantum/db/agentschedulers_db.py']",26,fe1f2daf2a7206e9a0be8046166457168829c418,bp/lbaas-agent-scheduler," # agent notifiers to handle agent update operations; # should be updated by plugins; agent_notifiers = { constants.AGENT_TYPE_DHCP: None, constants.AGENT_TYPE_L3: None, constants.AGENT_TYPE_LOADBALANCER: None, } agent_notifier = self.agent_notifiers.get(original_agent['agent_type']) if (agent_notifier and 'admin_state_up' in agent_data and original_agent['admin_state_up'] != agent_data['admin_state_up']): agent_notifier.agent_updated(context, agent_data['admin_state_up'], original_agent['host']) l3_notifier = self.agent_notifiers.get(constants.AGENT_TYPE_L3) if l3_notifier: l3_notifier.router_added_to_agent( l3_notifier = self.agent_notifiers.get(constants.AGENT_TYPE_L3) if l3_notifier: l3_notifier.router_removed_from_agent( dhcp_notifier = self.agent_notifiers.get(constants.AGENT_TYPE_DHCP) if dhcp_notifier: dhcp_notifier.network_added_to_agent( dhcp_notifier = self.agent_notifiers.get(constants.AGENT_TYPE_DHCP) if dhcp_notifier: dhcp_notifier.network_removed_from_agent("," dhcp_agent_notifier = None l3_agent_notifier = None if ('admin_state_up' in agent_data and original_agent['admin_state_up'] != agent_data['admin_state_up']): if (original_agent['agent_type'] == constants.AGENT_TYPE_DHCP and self.dhcp_agent_notifier): self.dhcp_agent_notifier.agent_updated( context, agent_data['admin_state_up'], original_agent['host']) elif (original_agent['agent_type'] == constants.AGENT_TYPE_L3 and self.l3_agent_notifier): self.l3_agent_notifier.agent_updated( context, agent_data['admin_state_up'], original_agent['host']) if self.l3_agent_notifier: self.l3_agent_notifier.router_added_to_agent( if self.l3_agent_notifier: self.l3_agent_notifier.router_removed_from_agent( if self.dhcp_agent_notifier: self.dhcp_agent_notifier.network_added_to_agent( if self.dhcp_agent_notifier: self.dhcp_agent_notifier.network_removed_from_agent(",886,144
openstack%2Fdevstack~master~I4cb4c6ded93a5c7b0bd39d65a754ddf86553463d,openstack/devstack,master,I4cb4c6ded93a5c7b0bd39d65a754ddf86553463d,make rejoin-stack.sh keep the same service tags,MERGED,2013-07-17 06:50:52.000000000,2013-07-22 06:20:58.000000000,2013-07-22 06:20:58.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1313}, {'_account_id': 1607}, {'_account_id': 1653}, {'_account_id': 1970}, {'_account_id': 2874}]","[{'number': 1, 'created': '2013-07-17 06:50:52.000000000', 'files': ['rejoin-stack.sh', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/8e58c0736fa7dba4a8d1da905c887cf603b7a653', 'message': ""make rejoin-stack.sh keep the same service tags\n\nCurrently rejoin-stack.sh can not keep the same screen service tags\nas the first you deploy openstack due to that the stack-screenrc lack\nproper command to configure screen's hardstatus. just delete the old\nstack-screenrc so that function screen_rc can write proper initialize\ncommand into stack-screenrc.\n\nfix bug 1182597\n\nChange-Id: I4cb4c6ded93a5c7b0bd39d65a754ddf86553463d\n""}]",0,37406,8e58c0736fa7dba4a8d1da905c887cf603b7a653,11,7,1,2967,,,0,"make rejoin-stack.sh keep the same service tags

Currently rejoin-stack.sh can not keep the same screen service tags
as the first you deploy openstack due to that the stack-screenrc lack
proper command to configure screen's hardstatus. just delete the old
stack-screenrc so that function screen_rc can write proper initialize
command into stack-screenrc.

fix bug 1182597

Change-Id: I4cb4c6ded93a5c7b0bd39d65a754ddf86553463d
",git fetch https://review.opendev.org/openstack/devstack refs/changes/06/37406/1 && git format-patch -1 --stdout FETCH_HEAD,"['rejoin-stack.sh', 'stack.sh']",2,8e58c0736fa7dba4a8d1da905c887cf603b7a653,bug/1182597, rm -f $SCREENRC, echo -n > $SCREENRC,2,2
openstack%2Fpbr~master~Ifa472f344489295a5b8a1910bff2672087653547,openstack/pbr,master,Ifa472f344489295a5b8a1910bff2672087653547,"We force installs via pip, we should declare it",MERGED,2013-06-23 22:43:53.000000000,2013-07-22 06:04:25.000000000,2013-07-22 06:04:25.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1994}, {'_account_id': 2472}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6786}]","[{'number': 1, 'created': '2013-06-23 22:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/2c217c404b21dd830d981c03e179ad82d4c9fdf0', 'message': 'We force installs via pip, we should declare it.\n\nChange-Id: Ifa472f344489295a5b8a1910bff2672087653547\n'}, {'number': 2, 'created': '2013-06-23 23:47:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/a0011034a59fff190f1880e7dfc18d56420d7f5c', 'message': 'We force installs via pip, we should declare it.\n\nChange-Id: Ifa472f344489295a5b8a1910bff2672087653547\n'}, {'number': 3, 'created': '2013-06-24 09:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/7b3a38fa13c6336b787be4bf133315accb7a1db4', 'message': 'We force installs via pip, we should declare it.\n\nChange-Id: Ifa472f344489295a5b8a1910bff2672087653547\n'}, {'number': 4, 'created': '2013-06-24 17:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/f433791f702c1f49a9a18668d640bc809806b9c9', 'message': 'We force installs via pip, we should declare it.\n\nChange-Id: Ifa472f344489295a5b8a1910bff2672087653547\n'}, {'number': 5, 'created': '2013-06-24 23:07:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/3e89bf20f086bd282003d81d79f1862cc357d35b', 'message': 'We force installs via pip, we should declare it.\n\nChange-Id: Ifa472f344489295a5b8a1910bff2672087653547\n'}, {'number': 6, 'created': '2013-07-05 02:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/7abebda95ff7b71b925b7dad259beab81f1be4be', 'message': 'We force installs via pip, we should declare it.\n\nChange-Id: Ifa472f344489295a5b8a1910bff2672087653547\n'}, {'number': 7, 'created': '2013-07-16 16:36:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/8fdd0db317d6afee54b85df91ffc773ff5d97ab2', 'message': 'We force installs via pip, we should declare it.\n\nChange-Id: Ifa472f344489295a5b8a1910bff2672087653547\n'}, {'number': 8, 'created': '2013-07-21 22:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/8910b430545a489c83c5952ca988de6c09670539', 'message': 'We force installs via pip, we should declare it.\n\nChange-Id: Ifa472f344489295a5b8a1910bff2672087653547\n'}, {'number': 9, 'created': '2013-07-22 02:30:55.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/pbr/commit/3395c2c6616d152c52e218528a380c9dc7cd79e9', 'message': 'We force installs via pip, we should declare it\n\npbr contains code that very explicitly uses pip, which means that pip is\na requirement.\n\nNote to packagers: it is possible to skip uses of pip, meaning that you\ncan totally use pbr-based things without needing to have them pip\ninstall things.\n\nChange-Id: Ifa472f344489295a5b8a1910bff2672087653547\n'}]",0,34154,3395c2c6616d152c52e218528a380c9dc7cd79e9,32,7,9,2,,,0,"We force installs via pip, we should declare it

pbr contains code that very explicitly uses pip, which means that pip is
a requirement.

Note to packagers: it is possible to skip uses of pip, meaning that you
can totally use pbr-based things without needing to have them pip
install things.

Change-Id: Ifa472f344489295a5b8a1910bff2672087653547
",git fetch https://review.opendev.org/openstack/pbr refs/changes/54/34154/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,2c217c404b21dd830d981c03e179ad82d4c9fdf0,replace-setuptols-git,pip,,1,0
openstack%2Fhorizon~master~I6dea82e5cd06b7dea6eb8b209a786999d2fc85e0,openstack/horizon,master,I6dea82e5cd06b7dea6eb8b209a786999d2fc85e0,Remove .mo files from Horizon git,ABANDONED,2013-07-02 16:40:18.000000000,2013-07-22 06:03:04.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4978}, {'_account_id': 6476}, {'_account_id': 7553}]","[{'number': 1, 'created': '2013-07-02 16:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e6c25c6b5648d6266e9100ad7669c5e7fe53d8f9', 'message': ""Remove .mo files from Horizon git\n\nHorizon source code is embedding the .mo files in its Git\nrepository, though they should be generated out of the .po\nfiles, and so shouldn't be there. Storing the .mo files\nposes 2 problems: we can't ensure that the .mo are built\nfrom source, and .mo files can generate merge conflicts.\nThis patch removes the .mo files, and adds the build of the\n.mo files when generating the sdist tarball, or when doing\npython setup.py install.\n\nFixes Bug1196982\n\nChange-Id: I6dea82e5cd06b7dea6eb8b209a786999d2fc85e0\n""}, {'number': 2, 'created': '2013-07-07 08:15:11.000000000', 'files': ['openstack_dashboard/locale/en_GB/LC_MESSAGES/django.mo', 'horizon/locale/ja/LC_MESSAGES/djangojs.mo', 'horizon/locale/pl/LC_MESSAGES/django.mo', 'horizon/locale/zh_CN/LC_MESSAGES/django.mo', 'horizon/locale/ko_KR/LC_MESSAGES/djangojs.mo', 'horizon/locale/zh_TW/LC_MESSAGES/djangojs.mo', 'horizon/locale/ka_GE/LC_MESSAGES/django.mo', 'horizon/locale/pt/LC_MESSAGES/django.mo', 'horizon/locale/ko_KR/LC_MESSAGES/django.mo', 'horizon/locale/zh_CN/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.mo', 'horizon/locale/ru/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.mo', 'horizon/locale/bg_BG/LC_MESSAGES/djangojs.mo', 'horizon/locale/bg_BG/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.mo', 'horizon/locale/pl/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/ca/LC_MESSAGES/django.mo', 'horizon/locale/ja/LC_MESSAGES/django.mo', 'horizon/locale/hu/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/en/LC_MESSAGES/django.mo', 'horizon/locale/zh_HK/LC_MESSAGES/django.mo', 'horizon/locale/es/LC_MESSAGES/django.mo', 'horizon/locale/nl_NL/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.mo', 'horizon/locale/it/LC_MESSAGES/django.mo', 'horizon/locale/fi_FI/LC_MESSAGES/django.mo', 'horizon/locale/en_GB/LC_MESSAGES/django.mo', 'setup.cfg', 'horizon/locale/fr/LC_MESSAGES/django.mo', 'gen_dot_mo_files.py', 'horizon/locale/nl_NL/LC_MESSAGES/django.mo', 'horizon/locale/ru/LC_MESSAGES/django.mo', 'horizon/locale/en/LC_MESSAGES/djangojs.mo', '.gitignore', 'horizon/locale/zh_TW/LC_MESSAGES/django.mo', 'horizon/locale/fr/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/pt/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/ka_GE/LC_MESSAGES/django.mo', 'horizon/locale/pt_BR/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/es/LC_MESSAGES/django.mo', 'horizon/locale/es/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.mo', 'horizon/locale/pt_BR/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/it/LC_MESSAGES/django.mo', 'horizon/locale/it/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/bg_BG/LC_MESSAGES/django.mo', 'horizon/locale/pt/LC_MESSAGES/djangojs.mo', 'horizon/locale/en/LC_MESSAGES/django.mo', 'horizon/locale/cs/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/pl/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/hu/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/fi_FI/LC_MESSAGES/django.mo', 'horizon/locale/ca/LC_MESSAGES/django.mo'], 'web_link': 'https://opendev.org/openstack/horizon/commit/43d734fe9f3282789f4b71dd62484b1b96d34bb4', 'message': ""Remove .mo files from Horizon git\n\nHorizon source code is embedding the .mo files in its Git\nrepository, though they should be generated out of the .po\nfiles, and so shouldn't be there. Storing the .mo files\nposes 2 problems: we can't ensure that the .mo are built\nfrom source, and .mo files can generate merge conflicts.\nThis patch removes the .mo files, and adds the build of the\n.mo files when generating the sdist tarball, or when doing\npython setup.py install.\n\nFixes Bug1196982\n\nChange-Id: I6dea82e5cd06b7dea6eb8b209a786999d2fc85e0\n""}]",4,35330,43d734fe9f3282789f4b71dd62484b1b96d34bb4,10,6,2,6476,,,0,"Remove .mo files from Horizon git

Horizon source code is embedding the .mo files in its Git
repository, though they should be generated out of the .po
files, and so shouldn't be there. Storing the .mo files
poses 2 problems: we can't ensure that the .mo are built
from source, and .mo files can generate merge conflicts.
This patch removes the .mo files, and adds the build of the
.mo files when generating the sdist tarball, or when doing
python setup.py install.

Fixes Bug1196982

Change-Id: I6dea82e5cd06b7dea6eb8b209a786999d2fc85e0
",git fetch https://review.opendev.org/openstack/horizon refs/changes/30/35330/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/en_GB/LC_MESSAGES/django.mo', 'horizon/locale/ja/LC_MESSAGES/djangojs.mo', 'horizon/locale/pl/LC_MESSAGES/django.mo', 'horizon/locale/zh_CN/LC_MESSAGES/django.mo', 'horizon/locale/ko_KR/LC_MESSAGES/djangojs.mo', 'horizon/locale/zh_TW/LC_MESSAGES/djangojs.mo', 'horizon/locale/ka_GE/LC_MESSAGES/django.mo', 'horizon/locale/pt/LC_MESSAGES/django.mo', 'horizon/locale/ko_KR/LC_MESSAGES/django.mo', 'horizon/locale/zh_CN/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.mo', 'horizon/locale/ru/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.mo', 'horizon/locale/bg_BG/LC_MESSAGES/djangojs.mo', 'horizon/locale/bg_BG/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.mo', 'horizon/locale/pl/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/ca/LC_MESSAGES/django.mo', 'horizon/locale/ja/LC_MESSAGES/django.mo', 'horizon/locale/hu/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/en/LC_MESSAGES/django.mo', 'horizon/locale/zh_HK/LC_MESSAGES/django.mo', 'horizon/locale/es/LC_MESSAGES/django.mo', 'horizon/locale/nl_NL/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.mo', 'horizon/locale/it/LC_MESSAGES/django.mo', 'horizon/locale/fi_FI/LC_MESSAGES/django.mo', 'horizon/locale/en_GB/LC_MESSAGES/django.mo', 'setup.cfg', 'horizon/locale/fr/LC_MESSAGES/django.mo', 'gen_dot_mo_files.py', 'horizon/locale/nl_NL/LC_MESSAGES/django.mo', 'horizon/locale/ru/LC_MESSAGES/django.mo', 'horizon/locale/en/LC_MESSAGES/djangojs.mo', '.gitignore', 'horizon/locale/zh_TW/LC_MESSAGES/django.mo', 'horizon/locale/fr/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/pt/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/ka_GE/LC_MESSAGES/django.mo', 'horizon/locale/pt_BR/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/es/LC_MESSAGES/django.mo', 'horizon/locale/es/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.mo', 'horizon/locale/pt_BR/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/it/LC_MESSAGES/django.mo', 'horizon/locale/it/LC_MESSAGES/djangojs.mo', 'openstack_dashboard/locale/bg_BG/LC_MESSAGES/django.mo', 'horizon/locale/pt/LC_MESSAGES/djangojs.mo', 'horizon/locale/en/LC_MESSAGES/django.mo', 'horizon/locale/cs/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/pl/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/hu/LC_MESSAGES/django.mo', 'openstack_dashboard/locale/fi_FI/LC_MESSAGES/django.mo', 'horizon/locale/ca/LC_MESSAGES/django.mo']",58,e6c25c6b5648d6266e9100ad7669c5e7fe53d8f9,bug/1196982,,,24,0
openstack%2Fswift~master~I419c135523b3acbb614c05d4ce0a08371a2bfd3d,openstack/swift,master,I419c135523b3acbb614c05d4ce0a08371a2bfd3d,Use testtools for test base class.,ABANDONED,2013-05-26 10:09:25.000000000,2013-07-22 06:03:04.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 917}]","[{'number': 1, 'created': '2013-05-26 10:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a1ba6d45a01f0d421456d759e8fe4096771d932e', 'message': 'Use testtools for test base class.\n\ntesttools is a step towards testr/subunit test processing. It also\nlays the groundwork for using things like addCleanup and fixtures\nin the test suites. testtools is a bit pedantic about upcalling,\nso the setUp/tearDown methods have all gotten upcalls.\n\nChange-Id: I419c135523b3acbb614c05d4ce0a08371a2bfd3d\n'}, {'number': 2, 'created': '2013-05-26 11:10:00.000000000', 'files': ['test/probe/test_replication_servers_working.py', 'test/unit/common/middleware/test_quotas.py', 'test/unit/common/middleware/test_recon.py', 'test/unit/common/middleware/test_ratelimit.py', 'test/unit/common/test_memcached.py', 'test/unit/proxy/controllers/test_base.py', 'test/unit/container/test_server.py', 'test/unit/common/middleware/test_cname_lookup.py', 'test/functionalnosetests/test_account.py', 'test/probe/test_object_handoff.py', 'test/unit/obj/test_auditor.py', 'test/unit/common/middleware/test_memcache.py', 'test/unit/common/middleware/test_name_check.py', 'test/unit/common/middleware/test_bulk.py', 'test/unit/common/middleware/test_slo.py', 'test/unit/common/test_bufferedhttp.py', 'test/unit/container/test_auditor.py', 'test/unit/common/middleware/test_healthcheck.py', 'test/unit/common/test_swob.py', 'test/unit/common/test_utils.py', 'test/unit/account/test_reaper.py', 'test/unit/container/test_replicator.py', 'test/unit/common/test_db_replicator.py', 'test/unit/proxy/test_server.py', 'test/unit/obj/test_server.py', 'test/unit/common/test_db.py', 'test/functional/swift_test_client.py', 'test/unit/common/test_bench.py', 'test/unit/common/middleware/test_account_quotas.py', 'test/unit/obj/test_expirer.py', 'test/unit/common/middleware/test_crossdomain.py', 'test/unit/common/middleware/test_domain_remap.py', 'test/probe/test_empty_device_handoff.py', 'test/unit/common/middleware/test_tempurl.py', 'test/unit/common/test_daemon.py', 'test/unit/common/ring/test_builder.py', 'test/unit/common/test_direct_client.py', 'test/functional/tests.py', 'test/unit/common/ring/test_ring.py', 'test/unit/account/test_replicator.py', 'test/unit/common/test_manager.py', 'test/unit/account/test_auditor.py', 'test/unit/common/middleware/test_except.py', 'test/unit/common/test_wsgi.py', 'test/functionalnosetests/test_object.py', 'test/unit/common/middleware/test_tempauth.py', 'tools/test-requires', 'test/unit/common/middleware/test_proxy_logging.py', 'test/unit/container/test_sync.py', 'test/unit/common/middleware/test_staticweb.py', 'test/functionalnosetests/test_container.py', 'test/unit/common/ring/test_utils.py', 'test/unit/common/test_constraints.py', 'test/unit/account/test_server.py', 'test/unit/common/middleware/test_formpost.py', 'test/unit/common/middleware/test_acl.py', 'test/unit/container/test_updater.py', 'test/unit/obj/test_base.py', 'test/unit/obj/test_replicator.py', 'test/unit/common/middleware/test_list_endpoints.py', 'test/unit/obj/test_updater.py', 'test/probe/test_object_failures.py', 'test/probe/test_container_failures.py', 'test/unit/common/middleware/test_keystoneauth.py', 'test/unit/common/test_internal_client.py', 'test/probe/test_account_failures.py', 'test/probe/test_object_async_update.py', 'test/unit/common/test_exceptions.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/7bcd0806bfa999ba9aeee02148ac158d164aae82', 'message': 'Use testtools for test base class.\n\ntesttools is a step towards testr/subunit test processing. It also\nlays the groundwork for using things like addCleanup and fixtures\nin the test suites. testtools is a bit pedantic about upcalling,\nso the setUp/tearDown methods have all gotten upcalls.\n\nChange-Id: I419c135523b3acbb614c05d4ce0a08371a2bfd3d\n'}]",0,30557,7bcd0806bfa999ba9aeee02148ac158d164aae82,17,3,2,2,,,0,"Use testtools for test base class.

testtools is a step towards testr/subunit test processing. It also
lays the groundwork for using things like addCleanup and fixtures
in the test suites. testtools is a bit pedantic about upcalling,
so the setUp/tearDown methods have all gotten upcalls.

Change-Id: I419c135523b3acbb614c05d4ce0a08371a2bfd3d
",git fetch https://review.opendev.org/openstack/swift refs/changes/57/30557/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/probe/test_replication_servers_working.py', 'test/unit/common/middleware/test_quotas.py', 'test/unit/common/middleware/test_recon.py', 'test/unit/common/middleware/test_ratelimit.py', 'test/unit/common/test_memcached.py', 'test/unit/proxy/controllers/test_base.py', 'test/unit/container/test_server.py', 'test/unit/common/middleware/test_cname_lookup.py', 'test/functionalnosetests/test_account.py', 'test/probe/test_object_handoff.py', 'test/unit/obj/test_auditor.py', 'test/unit/common/middleware/test_memcache.py', 'test/unit/common/middleware/test_name_check.py', 'test/unit/common/middleware/test_bulk.py', 'test/unit/common/middleware/test_slo.py', 'test/unit/common/test_bufferedhttp.py', 'test/unit/container/test_auditor.py', 'test/unit/common/middleware/test_healthcheck.py', 'test/unit/common/test_swob.py', 'test/unit/common/test_utils.py', 'test/unit/account/test_reaper.py', 'test/unit/container/test_replicator.py', 'test/unit/common/test_db_replicator.py', 'test/unit/proxy/test_server.py', 'test/unit/obj/test_server.py', 'test/unit/common/test_db.py', 'test/functional/swift_test_client.py', 'test/unit/common/test_bench.py', 'test/unit/common/middleware/test_account_quotas.py', 'test/unit/obj/test_expirer.py', 'test/unit/common/middleware/test_crossdomain.py', 'test/unit/common/middleware/test_domain_remap.py', 'test/probe/test_empty_device_handoff.py', 'test/unit/common/middleware/test_tempurl.py', 'test/unit/common/test_daemon.py', 'test/unit/common/ring/test_builder.py', 'test/unit/common/test_direct_client.py', 'test/functional/tests.py', 'test/unit/common/ring/test_ring.py', 'test/unit/account/test_replicator.py', 'test/unit/common/test_manager.py', 'test/unit/account/test_auditor.py', 'test/unit/common/middleware/test_except.py', 'test/unit/common/test_wsgi.py', 'test/functionalnosetests/test_object.py', 'test/unit/common/middleware/test_tempauth.py', 'tools/test-requires', 'test/unit/common/middleware/test_proxy_logging.py', 'test/unit/container/test_sync.py', 'test/unit/common/middleware/test_staticweb.py', 'test/functionalnosetests/test_container.py', 'test/unit/common/ring/test_utils.py', 'test/unit/common/test_constraints.py', 'test/unit/account/test_server.py', 'test/unit/common/middleware/test_formpost.py', 'test/unit/common/middleware/test_acl.py', 'test/unit/container/test_updater.py', 'test/unit/obj/test_base.py', 'test/unit/obj/test_replicator.py', 'test/unit/common/middleware/test_list_endpoints.py', 'test/unit/obj/test_updater.py', 'test/probe/test_object_failures.py', 'test/probe/test_container_failures.py', 'test/unit/common/middleware/test_keystoneauth.py', 'test/unit/common/test_internal_client.py', 'test/probe/test_account_failures.py', 'test/probe/test_object_async_update.py', 'test/unit/common/test_exceptions.py']",68,a1ba6d45a01f0d421456d759e8fe4096771d932e,,import testtoolsclass TestExceptions(testtools.TestCase): testtools.main(),import unittestclass TestExceptions(unittest.TestCase): unittest.main(),360,269
openstack%2Fheat~master~I5997bb3a514a66f0761b5731ab570c296290c74e,openstack/heat,master,I5997bb3a514a66f0761b5731ab570c296290c74e,update to use Neutron and deprecate Quantum,ABANDONED,2013-07-03 03:01:52.000000000,2013-07-22 06:03:03.000000000,,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 4571}, {'_account_id': 6593}, {'_account_id': 6800}, {'_account_id': 7162}]","[{'number': 1, 'created': '2013-07-03 03:01:52.000000000', 'files': ['heat/engine/resources/route_table.py', 'README.rst', 'heat/engine/resources/instance.py', 'heat/tests/test_security_group.py', 'heat/engine/resources/security_group.py', 'requirements.txt', 'heat/engine/resources/subnet.py', 'heat/tests/templates/Neutron.template', 'heat/engine/resources/neutron/port.py', 'heat/engine/resources/rackspace/rackspace_resource.py', 'heat/engine/resources/neutron/subnet.py', 'heat/tests/test_vpc.py', 'heat/engine/resources/network_interface.py', 'heat/engine/resources/neutron/floatingip.py', 'heat/engine/resources/neutron/net.py', 'heat/engine/resources/neutron/__init__.py', 'heat/engine/clients.py', 'heat/tests/templates/Neutron.yaml', 'heat/engine/resources/internet_gateway.py', 'heat/engine/resources/neutron/neutron.py', 'heat/tests/test_template_format.py', 'heat/engine/resources/neutron/router.py', 'heat/tests/test_instance_network.py', 'heat/tests/test_neutron.py', 'heat/engine/resource.py', 'heat/engine/resources/vpc.py', 'doc/docbkx/heat-cli-guide/src/heat_cli_howto.xml'], 'web_link': 'https://opendev.org/openstack/heat/commit/f1a0441735d22ee530e71acdd4ccd1509adb3fd9', 'message': 'update to use Neutron and deprecate Quantum\n\nimplements bug 1197208\n\nChange-Id: I5997bb3a514a66f0761b5731ab570c296290c74e\n'}]",3,35430,f1a0441735d22ee530e71acdd4ccd1509adb3fd9,9,6,1,2592,,,0,"update to use Neutron and deprecate Quantum

implements bug 1197208

Change-Id: I5997bb3a514a66f0761b5731ab570c296290c74e
",git fetch https://review.opendev.org/openstack/heat refs/changes/30/35430/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/route_table.py', 'README.rst', 'heat/engine/resources/instance.py', 'heat/tests/test_security_group.py', 'heat/engine/resources/security_group.py', 'requirements.txt', 'heat/engine/resources/subnet.py', 'heat/tests/templates/Neutron.template', 'heat/engine/resources/neutron/port.py', 'heat/engine/resources/rackspace/rackspace_resource.py', 'heat/engine/resources/neutron/subnet.py', 'heat/tests/test_vpc.py', 'heat/engine/resources/network_interface.py', 'heat/engine/resources/neutron/floatingip.py', 'heat/engine/resources/neutron/net.py', 'heat/engine/resources/neutron/__init__.py', 'heat/engine/clients.py', 'heat/tests/templates/Neutron.yaml', 'heat/engine/resources/internet_gateway.py', 'heat/engine/resources/neutron/neutron.py', 'heat/tests/test_template_format.py', 'heat/engine/resources/neutron/router.py', 'heat/tests/test_instance_network.py', 'heat/tests/test_neutron.py', 'heat/engine/resource.py', 'heat/engine/resources/vpc.py', 'doc/docbkx/heat-cli-guide/src/heat_cli_howto.xml']",27,f1a0441735d22ee530e71acdd4ccd1509adb3fd9,bug/1197208," xml:id=""neutron-cli-reference"">"," xml:id=""quantum-cli-reference"">",395,395
openstack%2Fcookbook-openstack-common~master~Ic818397125cefed4b37c71af855b2478838566c8,openstack/cookbook-openstack-common,master,Ic818397125cefed4b37c71af855b2478838566c8,"Added new `[""openstack""][""caching""]` attributes",ABANDONED,2013-07-03 23:50:52.000000000,2013-07-22 06:03:02.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 216}, {'_account_id': 7572}]","[{'number': 1, 'created': '2013-07-03 23:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/3b307d6336a96b6a5ea9f0733a8a68723b472918', 'message': 'Added new `[""openstack""][""caching""]` attributes\n\nObject caching should also be handled similar to `ops-database` and\n`ops-messaging`.\n\nChange-Id: Ic818397125cefed4b37c71af855b2478838566c8\n'}, {'number': 2, 'created': '2013-07-04 00:40:57.000000000', 'files': ['libraries/search.rb', 'attributes/default.rb', 'spec/search_spec.rb', 'CHANGELOG.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/aaf93e8de3b437db7e5063084a794dd81da7279d', 'message': 'Added new `[""openstack""][""caching""]` attributes\n\n* Updated version to 0.4.0 due to changes to `#memcached_servers`.\n* The `#memcached_servers` method no longer accepts a role, and the override\n  attributes were changed to make consistent with `#rabbit_servers`, and our\n  wrapper cookbook conventions.\n* There was a use case to handle an empty `[]` passed into memcached_servers\n  attribute.  Don\'t feel this is necessary, since one is explicitly setting it,\n  for it to be used.\n* We need to cleanup the cookbooks which use `#memcached_servers`, and make\n  the use of memcached optional.\n\nChange-Id: Ic818397125cefed4b37c71af855b2478838566c8\n'}]",0,35570,aaf93e8de3b437db7e5063084a794dd81da7279d,8,4,2,216,,,0,"Added new `[""openstack""][""caching""]` attributes

* Updated version to 0.4.0 due to changes to `#memcached_servers`.
* The `#memcached_servers` method no longer accepts a role, and the override
  attributes were changed to make consistent with `#rabbit_servers`, and our
  wrapper cookbook conventions.
* There was a use case to handle an empty `[]` passed into memcached_servers
  attribute.  Don't feel this is necessary, since one is explicitly setting it,
  for it to be used.
* We need to cleanup the cookbooks which use `#memcached_servers`, and make
  the use of memcached optional.

Change-Id: Ic818397125cefed4b37c71af855b2478838566c8
",git fetch https://review.opendev.org/openstack/cookbook-openstack-common refs/changes/70/35570/2 && git format-patch -1 --stdout FETCH_HEAD,['attributes/default.rb'],1,3b307d6336a96b6a5ea9f0733a8a68723b472918,memcached-attrs," # Default object caching attributes default[""openstack""][""caching""][""server_role""] = ""os-ops-caching"" default[""openstack""][""caching""][""service_type""] = ""memcached"" default[""openstack""][""caching""][""port""] = ""11211""",default['openstack']['memcached_servers'] = nil ,5,2
openstack%2Fneutron~master~I92259b07ec7d998f5dc8830cd4cafa2feeee5d0c,openstack/neutron,master,I92259b07ec7d998f5dc8830cd4cafa2feeee5d0c,Add unique constraint on mac_address,ABANDONED,2013-07-06 16:06:39.000000000,2013-07-22 06:03:02.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 5948}]","[{'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/68d624764d654b4eb4d217c9b2181c4acbb47de3', 'message': 'Add unique contraint on mac_address\n\nBug #1194565\n\nChange-Id: I92259b07ec7d998f5dc8830cd4cafa2feeee5d0c\n'}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d27edcf8adbfcb29864329425c9834e668f5b3a6', 'message': 'Add unique contraint on mac_address\n\nBug #1194565\n\nChange-Id: I92259b07ec7d998f5dc8830cd4cafa2feeee5d0c\n'}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a234f2ae6632332e1d167f113ca24d4b8e65e3fc', 'message': 'Add unique contraint on mac_address\n\nBug #1194565\n\nChange-Id: I92259b07ec7d998f5dc8830cd4cafa2feeee5d0c\n'}, {'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/08c90451b518c7b72b2f6723a163f60efbbc0cef', 'message': 'Add unique constraint on mac_address\n\nBug #1194565\n\nChange-Id: I92259b07ec7d998f5dc8830cd4cafa2feeee5d0c\n'}, {'number': 6, 'created': '2013-07-07 14:56:35.000000000', 'files': ['neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/migration/alembic_migrations/versions/16c37b5e3d1_unique_mac.py', 'neutron/db/models_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/96e01e5cade375ca2f14f13d5720352d9be274f6', 'message': 'Add unique constraint on mac_address\n\nBug #1194565\n\nChange-Id: I92259b07ec7d998f5dc8830cd4cafa2feeee5d0c\n'}, {'number': 5, 'created': '2013-07-07 14:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/659cb8b58b75d8d7b7cc99cac9a53ea26aa5dd40', 'message': 'Add unique constraint on mac_address\n\nBug #1194565\n\nChange-Id: I92259b07ec7d998f5dc8830cd4cafa2feeee5d0c\n'}]",27,34823,96e01e5cade375ca2f14f13d5720352d9be274f6,38,9,6,2874,,,0,"Add unique constraint on mac_address

Bug #1194565

Change-Id: I92259b07ec7d998f5dc8830cd4cafa2feeee5d0c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/23/34823/3 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/db/models_v2.py', 'quantum/db/db_base_plugin_v2.py', 'quantum/db/migration/alembic_migrations/versions/16c37b5e3d1_unique_mac.py', 'quantum/tests/unit/test_db_plugin.py']",4,68d624764d654b4eb4d217c9b2181c4acbb47de3,bug/1194565," def test_requested_duplicate_mac_generated(self): target_mac = ""12:34:56:00:00:33"" with mock.patch.object(quantum.db.db_base_plugin_v2.QuantumDbPluginV2, '_generate_mac', return_value=target_mac): with self.port(mac_address=target_mac) as port: net_id = port['port']['network_id'] res = self._create_port(self.fmt, net_id=net_id) self.assertEqual( res.status_int, webob.exc.HTTPServiceUnavailable.code) ",,142,51
openstack%2Foslosphinx~master~I7dfff9401e7dc7913c370238921d918c2124157c,openstack/oslosphinx,master,I7dfff9401e7dc7913c370238921d918c2124157c,Add the autoindex support from pbr,ABANDONED,2013-07-05 18:23:26.000000000,2013-07-22 06:03:01.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-07-05 18:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslosphinx/commit/9c5012f9e857e26471260f4bb0946363305fbad4', 'message': 'Add the autoindex support from pbr.\n\nChange-Id: I7dfff9401e7dc7913c370238921d918c2124157c\n'}, {'number': 2, 'created': '2013-07-08 13:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslosphinx/commit/28a7c888049d689bced02360827bb449fb360ce0', 'message': 'Add the autoindex support from pbr\n\nNow that we have a common sphinx home, move the logic for doing advanced\nSphinx things here and just have pbr do the work to enable those\nfeatures as needed.\n\nChange-Id: I7dfff9401e7dc7913c370238921d918c2124157c\n'}, {'number': 3, 'created': '2013-07-15 00:46:38.000000000', 'files': ['oslo/sphinx/autoindex.py'], 'web_link': 'https://opendev.org/openstack/oslosphinx/commit/aaba63eefdc94e5248cf34d04203575150889522', 'message': 'Add the autoindex support from pbr\n\nNow that we have a common sphinx home, move the logic for doing advanced\nSphinx things here and just have pbr do the work to enable those\nfeatures as needed.\n\nChange-Id: I7dfff9401e7dc7913c370238921d918c2124157c\n'}]",6,35852,aaba63eefdc94e5248cf34d04203575150889522,11,4,3,2,,,0,"Add the autoindex support from pbr

Now that we have a common sphinx home, move the logic for doing advanced
Sphinx things here and just have pbr do the work to enable those
features as needed.

Change-Id: I7dfff9401e7dc7913c370238921d918c2124157c
",git fetch https://review.opendev.org/openstack/oslosphinx refs/changes/52/35852/3 && git format-patch -1 --stdout FETCH_HEAD,['oslo/sphinx/autoindex.py'],1,9c5012f9e857e26471260f4bb0946363305fbad4,35852,"# Copyright (c) 2013 Hewlett-Packard Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import os _rst_template = """"""%(heading)s %(underline)s .. automodule:: %(module)s :members: :undoc-members: :show-inheritance: """""" _toctree_rst = """""".. toctree:: :maxdepth: 1 """""" def _find_modules(arg, dirname, files): for filename in files: if filename.endswith('.py') and filename != '__init__.py': arg[""%s.%s"" % (dirname.replace('/', '.'), filename[:-3])] = True def builder_inited(app): app.info(""[oslo.sphinx] Autodocumenting from %s"" % os.path.abspath(os.curdir)) source_dir = os.path.join(app.srcdir, 'api') if not os.path.exists(source_dir): os.makedirs(source_dir) modules = {} for pkg in app.config.autoindex_packages: if '.' not in pkg: for dirpath, dirnames, files in os.walk(pkg): _find_modules(modules, dirpath, files) module_list = list(modules.keys()) module_list.sort() autoindex_filename = os.path.join(source_dir, 'autoindex.rst') with open(autoindex_filename, 'w') as autoindex: autoindex.write(_toctree_rst) for module in module_list: output_filename = os.path.join(source_dir, ""%s.rst"" % module) heading = ""The :mod:`%s` Module"" % module underline = ""="" * len(heading) values = dict(module=module, heading=heading, underline=underline) app.info(""[oslo.sphinx] Generating %s"" % output_filename) with open(output_filename, 'w') as output_file: output_file.write(_rst_template % values) autoindex.write("" %s\n"" % module) def setup(app): app.add_config_value('autoindex_packages', [], True) app.connect('builder-inited', builder_inited) ",,74,0
openstack%2Ftempest~master~Icca21ea29f95683403004a0a7b079a10446d9317,openstack/tempest,master,Icca21ea29f95683403004a0a7b079a10446d9317,Adds tests for tags in boto (EC2 API),MERGED,2013-07-14 05:29:19.000000000,2013-07-22 05:47:28.000000000,2013-07-22 05:47:28.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5803}, {'_account_id': 6661}]","[{'number': 1, 'created': '2013-07-14 05:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1058348c1fb64969dd7032282af7618b925dfa78', 'message': 'Adds tests for tags in boto (EC2 API)\n\nThe EC2 API now supports tagging instances. This adds a simple\ntest for creation, retrieval, and updating tags. This test is disabled\nuntil 1192715 is fixed in nova.\n\nFixes bug #1201051\n\nChange-Id: Icca21ea29f95683403004a0a7b079a10446d9317\n'}, {'number': 2, 'created': '2013-07-17 17:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0e7a5102a2a022b317e38a38c80731619d27d18c', 'message': 'Adds tests for tags in boto (EC2 API)\n\nThe EC2 API now supports tagging instances. This adds a simple\ntest for creation, retrieval, and updating tags. This test is disabled\nuntil 1192715 is fixed in nova.\n\nFixes bug #1201051\n\nChange-Id: Icca21ea29f95683403004a0a7b079a10446d9317\n'}, {'number': 3, 'created': '2013-07-19 19:56:04.000000000', 'files': ['tempest/thirdparty/boto/test_ec2_instance_run.py', 'tempest/services/botoclients.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/bb575e1a568fabcf04409065636ef011273a720a', 'message': 'Adds tests for tags in boto (EC2 API)\n\nThe EC2 API now supports tagging instances. This adds a simple\ntest for creation, retrieval, and updating tags.\n\nFixes bug #1201051\n\nChange-Id: Icca21ea29f95683403004a0a7b079a10446d9317\n'}]",0,36964,bb575e1a568fabcf04409065636ef011273a720a,14,4,3,6661,,,0,"Adds tests for tags in boto (EC2 API)

The EC2 API now supports tagging instances. This adds a simple
test for creation, retrieval, and updating tags.

Fixes bug #1201051

Change-Id: Icca21ea29f95683403004a0a7b079a10446d9317
",git fetch https://review.opendev.org/openstack/tempest refs/changes/64/36964/3 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/botoclients.py', 'tempest/thirdparty/boto/test_ec2_instance_run.py']",2,1058348c1fb64969dd7032282af7618b925dfa78,bug/1201051," @testtools.skip(""Skipped until Nova Bug #1192715 is resolved"") def test_run_stop_terminate_instance_with_tags(self): # EC2 run, stop and terminate instance with tags image_ami = self.ec2_client.get_image(self.images[""ami""] [""image_id""]) reservation = image_ami.run(kernel_id=self.images[""aki""][""image_id""], ramdisk_id=self.images[""ari""][""image_id""], instance_type=self.instance_type) rcuk = self.addResourceCleanUp(self.destroy_reservation, reservation) for instance in reservation.instances: LOG.info(""state: %s"", instance.state) if instance.state != ""running"": self.assertInstanceStateWait(instance, ""running"") instance.add_tag('key1', value='value1') tags = self.ec2_client.get_all_tags() self.assertEquals(tags[0].name, 'key1') self.assertEquals(tags[0].value, 'value1') tags = self.ec2_client.get_all_tags(filters={'key':'key1'}) self.assertEquals(tags[0].name, 'key1') self.assertEquals(tags[0].value, 'value1') tags = self.ec2_client.get_all_tags(filters={'value':'value1'}) self.assertEquals(tags[0].name, 'key1') self.assertEquals(tags[0].value, 'value1') tags = self.ec2_client.get_all_tags(filters={'key':'value2'}) self.assertEquals(len(tags), 0) for instance in reservation.instances: instance.remove_tag('key1', value='value1') tags = self.ec2_client.get_all_tags() self.assertEquals(len(tags), 0) for instance in reservation.instances: instance.stop() LOG.info(""state: %s"", instance.state) if instance.state != ""stopped"": self.assertInstanceStateWait(instance, ""stopped"") for instance in reservation.instances: instance.terminate() self.cancelResourceCleanUp(rcuk) @attr(type='smoke')",,49,0
openstack%2Fpbr~master~I32975bd430635a38c7e737e70f381f7b07c6ed0c,openstack/pbr,master,I32975bd430635a38c7e737e70f381f7b07c6ed0c,Ignore project creator while generating AUTHORS,MERGED,2013-07-18 05:56:30.000000000,2013-07-22 03:56:59.000000000,2013-07-22 03:56:59.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2013-07-18 05:56:30.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/29afae0bf24ebd513291668a0dd3b57d7c25a782', 'message': ""Ignore project creator while generating AUTHORS\n\nNew projects created by OpenStack Project Creator\n<openstack-infra@lists.openstack.org>, so it'll be better to remove it\nfrom the AUTHORS file.\n\nChange-Id: I32975bd430635a38c7e737e70f381f7b07c6ed0c\n""}]",0,37624,29afae0bf24ebd513291668a0dd3b57d7c25a782,6,3,1,6786,,,0,"Ignore project creator while generating AUTHORS

New projects created by OpenStack Project Creator
<openstack-infra@lists.openstack.org>, so it'll be better to remove it
from the AUTHORS file.

Change-Id: I32975bd430635a38c7e737e70f381f7b07c6ed0c
",git fetch https://review.opendev.org/openstack/pbr refs/changes/24/37624/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,29afae0bf24ebd513291668a0dd3b57d7c25a782,authors-impr," ignore_emails = '(jenkins@review|infra@lists)' ""egrep -v '"" + ignore_emails + ""'"")"," jenkins_email = 'jenkins@review' ""egrep -v '"" + jenkins_email + ""'"")",2,2
openstack%2Fpbr~master~I9413591bb4a7d821382eae6dc3edd1df0c41a5e6,openstack/pbr,master,I9413591bb4a7d821382eae6dc3edd1df0c41a5e6,Do not assume the tests run as jenkins,MERGED,2013-07-21 14:59:30.000000000,2013-07-22 03:48:07.000000000,2013-07-22 03:48:07.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-07-21 14:59:30.000000000', 'files': ['tools/integration.sh'], 'web_link': 'https://opendev.org/openstack/pbr/commit/e6164128930f4d3e203b0a8434ab096895b81d18', 'message': 'Do not assume the tests run as jenkins\n\nUse $HOME instead of ""/home/jenkins"" in the generated configuration\nfiles to let the script be run as a user other than jenkins.\n\nChange-Id: I9413591bb4a7d821382eae6dc3edd1df0c41a5e6\n'}]",0,38071,e6164128930f4d3e203b0a8434ab096895b81d18,9,3,1,2472,,,0,"Do not assume the tests run as jenkins

Use $HOME instead of ""/home/jenkins"" in the generated configuration
files to let the script be run as a user other than jenkins.

Change-Id: I9413591bb4a7d821382eae6dc3edd1df0c41a5e6
",git fetch https://review.opendev.org/openstack/pbr refs/changes/71/38071/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/integration.sh'],1,e6164128930f4d3e203b0a8434ab096895b81d18,feature/shunit2,log = $HOME/pip.loglog = $HOME/pip.log,log = /home/jenkins/pip.loglog = /home/jenkins/pip.log,2,2
openstack%2Fpbr~master~I1ec46837cea07db514f2fb6338c7bced34a83c4a,openstack/pbr,master,I1ec46837cea07db514f2fb6338c7bced34a83c4a,Replace entry_points console_scripts,MERGED,2013-07-19 23:43:02.000000000,2013-07-22 03:48:06.000000000,2013-07-22 03:48:06.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2472}, {'_account_id': 4190}]","[{'number': 1, 'created': '2013-07-19 23:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/ae2d32831805b9d75055e075386ff276ac8b5fec', 'message': ""Replace entry_points console_scripts\n\nThe console scripts generated by entry_points are too complex for\nour needs and make things run slowly in service of a multi-version\ninstall that we don't use.\n\nInstead, install a simple script which just does a direct import.\n\nChange-Id: I1ec46837cea07db514f2fb6338c7bced34a83c4a\n""}, {'number': 2, 'created': '2013-07-19 23:49:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/fb0371e201f449f7e16ae7e4cda951c97f64ffef', 'message': ""Replace entry_points console_scripts\n\nThe console scripts generated by entry_points are too complex for\nour needs and make things run slowly in service of a multi-version\ninstall that we don't use.\n\nInstead, install a simple script which just does a direct import.\n\nChange-Id: I1ec46837cea07db514f2fb6338c7bced34a83c4a\n""}, {'number': 3, 'created': '2013-07-20 20:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/6d4b8ce124f7d92e379fad92be955a91893ebd36', 'message': ""Replace entry_points console_scripts\n\nThe console scripts generated by entry_points are too complex for\nour needs and make things run slowly in service of a multi-version\ninstall that we don't use.\n\nInstead, install a simple script which just does a direct import.\n\nChange-Id: I1ec46837cea07db514f2fb6338c7bced34a83c4a\n""}, {'number': 4, 'created': '2013-07-20 21:48:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/30622663657a68286c0f245111139c8328d1ed89', 'message': ""Replace entry_points console_scripts\n\nThe console scripts generated by entry_points are too complex for\nour needs and make things run slowly in service of a multi-version\ninstall that we don't use.\n\nInstead, install a simple script which just does a direct import.\n\nChange-Id: I1ec46837cea07db514f2fb6338c7bced34a83c4a\n""}, {'number': 5, 'created': '2013-07-21 00:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/489a6d5ba571e94f3fadae71e3cdad4053aacc8e', 'message': ""Replace entry_points console_scripts\n\nThe console scripts generated by entry_points are too complex for\nour needs and make things run slowly in service of a multi-version\ninstall that we don't use.\n\nInstead, install a simple script which just does a direct import.\n\nChange-Id: I1ec46837cea07db514f2fb6338c7bced34a83c4a\n""}, {'number': 6, 'created': '2013-07-21 00:32:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/d4bf54c9afb9c4be510c5d60f94bb82ba6783431', 'message': ""Replace entry_points console_scripts\n\nThe console scripts generated by entry_points are too complex for\nour needs and make things run slowly in service of a multi-version\ninstall that we don't use.\n\nInstead, install a simple script which just does a direct import.\n\nChange-Id: I1ec46837cea07db514f2fb6338c7bced34a83c4a\n""}, {'number': 7, 'created': '2013-07-21 01:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/d8b5b3f896e28b329b982b08743a7f396eb11bcf', 'message': ""Replace entry_points console_scripts\n\nThe console scripts generated by entry_points are too complex for\nour needs and make things run slowly in service of a multi-version\ninstall that we don't use.\n\nInstead, install a simple script which just does a direct import.\n\nChange-Id: I1ec46837cea07db514f2fb6338c7bced34a83c4a\n""}, {'number': 8, 'created': '2013-07-21 02:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/218cca13541d93ba07452cf9f891ade76ed7e483', 'message': ""Replace entry_points console_scripts\n\nThe console scripts generated by entry_points are too complex for\nour needs and make things run slowly in service of a multi-version\ninstall that we don't use.\n\nInstead, install a simple script which just does a direct import.\n\nChange-Id: I1ec46837cea07db514f2fb6338c7bced34a83c4a\n""}, {'number': 9, 'created': '2013-07-21 05:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/2bece7cc1af8c8e35fc624da4fbd8556f8e1ee3c', 'message': ""Replace entry_points console_scripts\n\nThe console scripts generated by entry_points are too complex for\nour needs and make things run slowly in service of a multi-version\ninstall that we don't use.\n\nInstead, install a simple script which just does a direct import.\n\nChange-Id: I1ec46837cea07db514f2fb6338c7bced34a83c4a\n""}, {'number': 10, 'created': '2013-07-21 15:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/be84b0569b9a4c03cd8969263242b8b5dde04dc8', 'message': ""Replace entry_points console_scripts\n\nThe console scripts generated by entry_points are too complex for\nour needs and make things run slowly in service of a multi-version\ninstall that we don't use.\n\nInstead, install a simple script which just does a direct import.\n\nChange-Id: I1ec46837cea07db514f2fb6338c7bced34a83c4a\n""}, {'number': 11, 'created': '2013-07-21 18:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/76e1e80898fd7e7d3880ac159f5101ac8c5c67ea', 'message': ""Replace entry_points console_scripts\n\nThe console scripts generated by entry_points are too complex for\nour needs and make things run slowly in service of a multi-version\ninstall that we don't use.\n\nInstead, install a simple script which just does a direct import.\n\nChange-Id: I1ec46837cea07db514f2fb6338c7bced34a83c4a\n""}, {'number': 12, 'created': '2013-07-21 19:44:04.000000000', 'files': ['tools/integration.sh', 'pbr/packaging.py', 'pbr/tests/testpackage/pbr_testpackage/cmd.py', 'pbr/tests/test_core.py', 'pbr/tests/__init__.py', 'pbr/tests/testpackage/setup.cfg', 'pbr/hooks/commands.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/8e58c2fa58fd1aa6f9985dcb4e210508a73e1df7', 'message': ""Replace entry_points console_scripts\n\nThe console scripts generated by entry_points are too complex for\nour needs and make things run slowly in service of a multi-version\ninstall that we don't use.\n\nInstead, install a simple script which just does a direct import.\n\nChange-Id: I1ec46837cea07db514f2fb6338c7bced34a83c4a\n""}]",2,38000,8e58c2fa58fd1aa6f9985dcb4e210508a73e1df7,45,5,12,2,,,0,"Replace entry_points console_scripts

The console scripts generated by entry_points are too complex for
our needs and make things run slowly in service of a multi-version
install that we don't use.

Instead, install a simple script which just does a direct import.

Change-Id: I1ec46837cea07db514f2fb6338c7bced34a83c4a
",git fetch https://review.opendev.org/openstack/pbr refs/changes/00/38000/11 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/packaging.py', 'pbr/hooks/commands.py']",2,ae2d32831805b9d75055e075386ff276ac8b5fec,replace-setuptols-git, self.add_command('pbr.packaging.LocalInstallScripts'),,37,0
openstack%2Fpbr~master~Ie33d3e08d5a4133f5caf2613859919ce4f02c4a0,openstack/pbr,master,Ie33d3e08d5a4133f5caf2613859919ce4f02c4a0,Remove the need to specify the pbr hook,MERGED,2013-07-21 17:22:03.000000000,2013-07-22 03:47:42.000000000,2013-07-22 03:47:42.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-07-21 17:22:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/4649ca3e42222c3560291ac02d0dd34dd6bb2c12', 'message': 'Remove the need to specify the pbr hook\n\nIf you\'re running pbr codepaths, you want the hook. There is no need\nto say ""pbr=True"" in setup.py and then to list the hook in setup.cfg\nnow that d2to1 is in the tree.\n\nChange-Id: Ie33d3e08d5a4133f5caf2613859919ce4f02c4a0\n'}, {'number': 2, 'created': '2013-07-21 18:41:41.000000000', 'files': ['pbr/tests/__init__.py', 'pbr/util.py', 'README.rst'], 'web_link': 'https://opendev.org/openstack/pbr/commit/c84876dc0f559a66fec19b2f81f5717204b253e2', 'message': 'Remove the need to specify the pbr hook\n\nIf you\'re running pbr codepaths, you want the hook. There is no need\nto say ""pbr=True"" in setup.py and then to list the hook in setup.cfg\nnow that d2to1 is in the tree.\n\nChange-Id: Ie33d3e08d5a4133f5caf2613859919ce4f02c4a0\n'}]",0,38080,c84876dc0f559a66fec19b2f81f5717204b253e2,9,3,2,2,,,0,"Remove the need to specify the pbr hook

If you're running pbr codepaths, you want the hook. There is no need
to say ""pbr=True"" in setup.py and then to list the hook in setup.cfg
now that d2to1 is in the tree.

Change-Id: Ie33d3e08d5a4133f5caf2613859919ce4f02c4a0
",git fetch https://review.opendev.org/openstack/pbr refs/changes/80/38080/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/tests/__init__.py', 'pbr/util.py']",2,4649ca3e42222c3560291ac02d0dd34dd6bb2c12,,import pbr.hooks setup_hooks = [ hook for hook in split_multiline(setup_hooks) if hook != 'pbr.hook.setup_hook'] # Run the pbr hook pbr.hooks.setup_hook(config) , setup_hooks = split_multiline(setup_hooks),8,1
openstack%2Fpbr~master~I3972b3132619e8e2dd7e362ca5fe9d1e3add43b8,openstack/pbr,master,I3972b3132619e8e2dd7e362ca5fe9d1e3add43b8,Move d2to1 more into the source tree,MERGED,2013-07-21 17:22:03.000000000,2013-07-22 03:46:19.000000000,2013-07-22 03:46:19.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-21 17:22:03.000000000', 'files': ['pbr/tests/testpackage/setup.py', 'pbr/tests/testpackage/LICENSE.txt', 'pbr/tests/testpackage/pbr_testpackage/__init__.py', 'pbr/util.py', 'pbr/tests/testpackage/data_files/c.rst', 'pbr/tests/testpackage/pbr_testpackage/package_data/2.txt', 'setup.py', 'pbr/core.py', 'pbr/tests/test_hooks.py', 'pbr/tests/testpackage/pbr_testpackage/_setup_hooks.py', 'pbr/tests/testpackage/data_files/a.txt', 'pbr/tests/testpackage/README.txt', 'pbr/tests/testpackage/pbr_testpackage/package_data/1.txt', 'pbr/tests/testpackage/data_files/b.txt', 'pbr/tests/__init__.py', 'pbr/tests/test_commands.py', 'pbr/tests/testpackage/src/testext.c', 'pbr/tests/testpackage/setup.cfg', 'pbr/d2to1/tests/testpackage/setup.cfg', 'pbr/tests/testpackage/MANIFEST.in', 'tools/integration.sh', 'pbr/d2to1/__init__.py', 'pbr/tests/test_core.py', 'pbr/tests/testpackage/extra-file.txt', 'pbr/d2to1/tests/__init__.py', 'pbr/tests/testpackage/CHANGES.txt', 'pbr/tests/util.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/71bea435b6f73644d5d7320001ac56d78bcc4687', 'message': ""Move d2to1 more into the source tree\n\nWhen we merged in d2to1, we kept it separate, but I don't think there\nis a great benefit to doing that.\n\nChange-Id: I3972b3132619e8e2dd7e362ca5fe9d1e3add43b8\n""}]",0,38079,71bea435b6f73644d5d7320001ac56d78bcc4687,7,4,1,2,,,0,"Move d2to1 more into the source tree

When we merged in d2to1, we kept it separate, but I don't think there
is a great benefit to doing that.

Change-Id: I3972b3132619e8e2dd7e362ca5fe9d1e3add43b8
",git fetch https://review.opendev.org/openstack/pbr refs/changes/79/38079/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/tests/testpackage/setup.py', 'pbr/tests/testpackage/LICENSE.txt', 'pbr/tests/testpackage/pbr_testpackage/__init__.py', 'pbr/util.py', 'pbr/tests/testpackage/data_files/c.rst', 'pbr/tests/testpackage/pbr_testpackage/package_data/2.txt', 'setup.py', 'pbr/core.py', 'pbr/tests/test_hooks.py', 'pbr/tests/testpackage/pbr_testpackage/_setup_hooks.py', 'pbr/tests/testpackage/data_files/a.txt', 'pbr/tests/testpackage/README.txt', 'pbr/tests/testpackage/pbr_testpackage/package_data/1.txt', 'pbr/tests/testpackage/data_files/b.txt', 'pbr/tests/__init__.py', 'pbr/tests/test_commands.py', 'pbr/tests/testpackage/src/testext.c', 'pbr/tests/testpackage/setup.cfg', 'pbr/d2to1/tests/testpackage/setup.cfg', 'pbr/tests/testpackage/MANIFEST.in', 'tools/integration.sh', 'pbr/d2to1/__init__.py', 'pbr/tests/test_core.py', 'pbr/tests/testpackage/extra-file.txt', 'pbr/d2to1/tests/__init__.py', 'pbr/tests/testpackage/CHANGES.txt', 'pbr/tests/util.py']",27,71bea435b6f73644d5d7320001ac56d78bcc4687,,,,126,151
openstack%2Fos-apply-config~master~I01827232cdc91648070ddf3af178cc777802b236,openstack/os-apply-config,master,I01827232cdc91648070ddf3af178cc777802b236,Fix print statements for python 3 compatibility,MERGED,2013-07-22 03:45:00.000000000,2013-07-22 03:45:00.000000000,2013-07-22 03:45:00.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}]","[{'number': 2, 'created': '2013-07-22 03:45:00.000000000', 'files': ['os_apply_config/apply_config.py'], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/dfb0980e13077ecd41b91aef61d53d9178fb75ec', 'message': 'Fix print statements for python 3 compatibility\n\nHacking 0.6 enforces this.\n\nChange-Id: I01827232cdc91648070ddf3af178cc777802b236\n'}, {'number': 1, 'created': '2013-07-22 03:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/ea8288403488524fdc2d06424e38c8d0da887e8c', 'message': 'Fix print statements for python 3 compatibility\n\nHacking 0.6 enforces this.\n\nChange-Id: I01827232cdc91648070ddf3af178cc777802b236\n'}]",2,37982,dfb0980e13077ecd41b91aef61d53d9178fb75ec,8,3,2,6488,,,0,"Fix print statements for python 3 compatibility

Hacking 0.6 enforces this.

Change-Id: I01827232cdc91648070ddf3af178cc777802b236
",git fetch https://review.opendev.org/openstack/os-apply-config refs/changes/82/37982/2 && git format-patch -1 --stdout FETCH_HEAD,['os_apply_config/apply_config.py'],1,dfb0980e13077ecd41b91aef61d53d9178fb75ec,OCC," print(str(default)) print(str(config)) os.chmod(newfile.name, 0o644)"," print default print config os.chmod(newfile.name, 0644)",3,3
openstack%2Fpbr~master~I0c56f9cde643ef8580ab305080bc62b87809bf7e,openstack/pbr,master,I0c56f9cde643ef8580ab305080bc62b87809bf7e,Fix python 3.3 tests,MERGED,2013-07-21 19:36:23.000000000,2013-07-22 03:25:30.000000000,2013-07-22 03:25:30.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-07-21 19:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/4350d43e462d49374d11fbb05cc08535066cf4a3', 'message': ""Fix python 3.3 test requirements\n\nPython 3.3 can't install testrepository from bzr, so use\nthe officially released version instead.\n\nChange-Id: I0c56f9cde643ef8580ab305080bc62b87809bf7e\n""}, {'number': 2, 'created': '2013-07-21 19:52:01.000000000', 'files': ['test-requirements-py3.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/pbr/commit/6aeee95e2acf703a6e41b7172f2333e899038332', 'message': 'Fix python 3.3 tests\n\nWe can go back to using the official release of\ntestrepository for testing under python 3, so\ndo.\n\nMake python 3.3 part of the default environment\nset for anyone running all of the tests.\n\nChange-Id: I0c56f9cde643ef8580ab305080bc62b87809bf7e\n'}]",0,38084,6aeee95e2acf703a6e41b7172f2333e899038332,9,3,2,2472,,,0,"Fix python 3.3 tests

We can go back to using the official release of
testrepository for testing under python 3, so
do.

Make python 3.3 part of the default environment
set for anyone running all of the tests.

Change-Id: I0c56f9cde643ef8580ab305080bc62b87809bf7e
",git fetch https://review.opendev.org/openstack/pbr refs/changes/84/38084/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements-py3.txt'],1,4350d43e462d49374d11fbb05cc08535066cf4a3,bug/python-3-type-error,testrepository,-e bzr+lp:testrepository#egg=testrepository,1,1
openstack%2Fheat~master~Id79988560e105c254d304e30d598427a2bbc5b26,openstack/heat,master,Id79988560e105c254d304e30d598427a2bbc5b26,Reset state before resource recreation,MERGED,2013-07-18 07:45:19.000000000,2013-07-22 02:31:31.000000000,2013-07-22 02:31:31.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6602}, {'_account_id': 7135}, {'_account_id': 7162}, {'_account_id': 7193}, {'_account_id': 7761}]","[{'number': 1, 'created': '2013-07-18 07:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ef1e0a1ac50c459775042d7ebcfa7e01428a163b', 'message': 'Continue creating resource if resource id is None\n\nSo the condition to create resource is one of resource id, resource\nstatus, resource action is None.\n\nChange-Id: Id79988560e105c254d304e30d598427a2bbc5b26\nFixes: bug #1202492\n'}, {'number': 2, 'created': '2013-07-18 10:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fcbf124f5e321612c9423599e828e8cbaf7bd5bc', 'message': 'Set action status to INIT COMPLETE after resource destroyed\n\nSo the destroyed resource can be created again.\n\nChange-Id: Id79988560e105c254d304e30d598427a2bbc5b26\nFixes: bug #1202492\n'}, {'number': 3, 'created': '2013-07-18 20:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2304ce757d450da7d7be2ea13bee6c808c850a45', 'message': 'Allow resource with None id to be recreated\n\nSo the destroyed resource can be recreated, and HARestarted main logic\nresource destory and create can work.\n\nChange-Id: Id79988560e105c254d304e30d598427a2bbc5b26\nFixes: bug #1202492\n'}, {'number': 5, 'created': '2013-07-19 02:24:01.000000000', 'files': ['heat/engine/parser.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f0b6b550d97464a6de2c15838475132dbbe022cd', 'message': 'Reset state before resource recreation\n\nSo the destroyed resource can be recreated, and HARestarted main logic\nresource destory and create can work.\n\nChange-Id: Id79988560e105c254d304e30d598427a2bbc5b26\nFixes: bug #1202492\n'}, {'number': 4, 'created': '2013-07-19 02:24:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/84472ec3438f314ddbb5bad1dcd6413d43c53206', 'message': 'Reset state before resource recreation\n\nSo the destroyed resource can be recreated, and HARestarted main logic\nresource destory and create can work.\n\nChange-Id: Id79988560e105c254d304e30d598427a2bbc5b26\nFixes: bug #1202492\n'}]",2,37637,f0b6b550d97464a6de2c15838475132dbbe022cd,20,8,5,7761,,,0,"Reset state before resource recreation

So the destroyed resource can be recreated, and HARestarted main logic
resource destory and create can work.

Change-Id: Id79988560e105c254d304e30d598427a2bbc5b26
Fixes: bug #1202492
",git fetch https://review.opendev.org/openstack/heat refs/changes/37/37637/5 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resource.py', 'heat/tests/test_resource.py']",2,ef1e0a1ac50c459775042d7ebcfa7e01428a163b,bug/1202492," def test_create_with_res_id_none(self): tmpl = {'Type': 'GenericResourceType'} rname = 'test_res_id_none' res = generic_rsrc.ResourceWithProps(rname, tmpl, self.stack) res.id = 'test_res_id' res.action = res.DELETE res.status = res.COMPLETE self.assertRaises(AssertionError, res.create) res.id = None scheduler.TaskRunner(res.create)() self.assertEqual((res.CREATE, res.COMPLETE), res.state) ",,14,1
openstack%2Fheat~master~I578cc6f2e933fbdc469dd14d23e9cf5b9f1d246f,openstack/heat,master,I578cc6f2e933fbdc469dd14d23e9cf5b9f1d246f,Add a py33 tox environment,MERGED,2013-07-19 21:02:54.000000000,2013-07-22 00:52:45.000000000,2013-07-22 00:52:44.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}]","[{'number': 1, 'created': '2013-07-19 21:02:54.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/heat/commit/a26b1df477142a66097613859ad620d7c500ed9f', 'message': 'Add a py33 tox environment\n\nThis way one can optionally run tests against Python 3.x\n\nChange-Id: I578cc6f2e933fbdc469dd14d23e9cf5b9f1d246f\n'}]",0,37976,a26b1df477142a66097613859ad620d7c500ed9f,6,3,1,6593,,,0,"Add a py33 tox environment

This way one can optionally run tests against Python 3.x

Change-Id: I578cc6f2e933fbdc469dd14d23e9cf5b9f1d246f
",git fetch https://review.opendev.org/openstack/heat refs/changes/76/37976/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a26b1df477142a66097613859ad620d7c500ed9f,python3,"envlist = py26,py27,py33,pep8","envlist = py26,py27,pep8",1,1
openstack%2Fheat~master~I7d096b11e70c234d0b2322c93bf5f4d4e6b01b4f,openstack/heat,master,I7d096b11e70c234d0b2322c93bf5f4d4e6b01b4f,Configure standalone pipelines for cfn and cloudwatch.,MERGED,2013-07-19 02:45:06.000000000,2013-07-22 00:29:36.000000000,2013-07-22 00:29:36.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-19 02:45:06.000000000', 'files': ['etc/heat/heat-api-cfn.conf', 'etc/heat/heat-api-cloudwatch.conf', 'etc/heat/api-paste.ini'], 'web_link': 'https://opendev.org/openstack/heat/commit/ce07ddb75982fdf48e62fb17f6b43ba13b2bae0f', 'message': ""Configure standalone pipelines for cfn and cloudwatch.\n\nThis allows waitconditions and cloud watch data to authenticate\nusing just the ec2token middleware. Stacks have been successfully launched\nwith a standalone heat onto an external grizzly openstack, including working\nwaitconditions and watch data.\n\nThis means that currently when in standalone mode, heat-cfn cannot\nauthenticate since it defaults to auth strategy keystone (and it appears\nthat auth strategy ec2 signing has not been implemented yet). This case\nis sufficiently obscure that it most likely won't affect anyone at this\nstage.\n\nImplements blueprint heat-standalone\n\nChange-Id: I7d096b11e70c234d0b2322c93bf5f4d4e6b01b4f\n""}]",0,37833,ce07ddb75982fdf48e62fb17f6b43ba13b2bae0f,6,3,1,4571,,,0,"Configure standalone pipelines for cfn and cloudwatch.

This allows waitconditions and cloud watch data to authenticate
using just the ec2token middleware. Stacks have been successfully launched
with a standalone heat onto an external grizzly openstack, including working
waitconditions and watch data.

This means that currently when in standalone mode, heat-cfn cannot
authenticate since it defaults to auth strategy keystone (and it appears
that auth strategy ec2 signing has not been implemented yet). This case
is sufficiently obscure that it most likely won't affect anyone at this
stage.

Implements blueprint heat-standalone

Change-Id: I7d096b11e70c234d0b2322c93bf5f4d4e6b01b4f
",git fetch https://review.opendev.org/openstack/heat refs/changes/33/37833/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/heat/heat-api-cfn.conf', 'etc/heat/heat-api-cloudwatch.conf', 'etc/heat/api-paste.ini']",3,ce07ddb75982fdf48e62fb17f6b43ba13b2bae0f,bp/heat-standalone,# heat-api-cfn pipeline for standalone heat # relies exclusively on authenticating with ec2 signed requests [pipeline:heat-api-cfn-standalone] pipeline = cfnversionnegotiation ec2authtoken context apicfnv1app # heat-api-cloudwatch pipeline for standalone heat # relies exclusively on authenticating with ec2 signed requests [pipeline:heat-api-cloudwatch-standalone] pipeline = versionnegotiation ec2authtoken context apicwapp ,,18,0
openstack%2Fheat~master~I1214e44c588f547ee6f90f0f71a085f786e7ea7f,openstack/heat,master,I1214e44c588f547ee6f90f0f71a085f786e7ea7f,Set role headers from ec2 authentication.,MERGED,2013-07-19 02:45:06.000000000,2013-07-22 00:28:25.000000000,2013-07-22 00:28:24.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 7761}]","[{'number': 1, 'created': '2013-07-19 02:45:06.000000000', 'files': ['heat/tests/test_api_ec2token.py', 'heat/api/aws/ec2token.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/674dbb70ee5f3dd3b0ba59e82aef45bd6a2d0b0f', 'message': 'Set role headers from ec2 authentication.\n\nWithout this roles are not available in the context when\nec2token middleware is used on its own.\n\nChange-Id: I1214e44c588f547ee6f90f0f71a085f786e7ea7f\n'}]",0,37832,674dbb70ee5f3dd3b0ba59e82aef45bd6a2d0b0f,7,4,1,4571,,,0,"Set role headers from ec2 authentication.

Without this roles are not available in the context when
ec2token middleware is used on its own.

Change-Id: I1214e44c588f547ee6f90f0f71a085f786e7ea7f
",git fetch https://review.opendev.org/openstack/heat refs/changes/32/37832/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_api_ec2token.py', 'heat/api/aws/ec2token.py']",2,674dbb70ee5f3dd3b0ba59e82aef45bd6a2d0b0f,bp/heat-standalone," metadata = result['access'].get('metadata', {}) roles = metadata.get('roles', []) req.headers['X-Roles'] = ','.join(roles) ",,36,1
openstack%2Fheat~master~I7a0867196741c0df222d491fb1bfbe203158032c,openstack/heat,master,I7a0867196741c0df222d491fb1bfbe203158032c,Set tenant headers from ec2 authentication.,MERGED,2013-07-19 02:45:06.000000000,2013-07-22 00:28:18.000000000,2013-07-22 00:28:18.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-19 02:45:06.000000000', 'files': ['heat/tests/test_api_ec2token.py', 'heat/api/aws/ec2token.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c8af819c7fc55c98c4b4871a44fa8b4d4964668e', 'message': ""Set tenant headers from ec2 authentication.\n\nWithout this, ec2token middleware on its own doesn't set enough\nheaders to perform heat requests.\n\nChange-Id: I7a0867196741c0df222d491fb1bfbe203158032c\n""}]",0,37831,c8af819c7fc55c98c4b4871a44fa8b4d4964668e,6,3,1,4571,,,0,"Set tenant headers from ec2 authentication.

Without this, ec2token middleware on its own doesn't set enough
headers to perform heat requests.

Change-Id: I7a0867196741c0df222d491fb1bfbe203158032c
",git fetch https://review.opendev.org/openstack/heat refs/changes/31/37831/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_api_ec2token.py', 'heat/api/aws/ec2token.py']",2,c8af819c7fc55c98c4b4871a44fa8b4d4964668e,bp/heat-standalone, tenant = result['access']['token']['tenant']['name'] tenant_id = result['access']['token']['tenant']['id'] req.headers['X-Tenant-Name'] = tenant req.headers['X-Tenant-Id'] = tenant_id,,10,2
openstack%2Fkeystone~master~I46e6c9fd9213fb0c05ac40710130f3614af4971e,openstack/keystone,master,I46e6c9fd9213fb0c05ac40710130f3614af4971e,Create a Credential Model.,ABANDONED,2013-07-03 07:56:58.000000000,2013-07-22 00:26:09.000000000,,"[{'_account_id': 3}, {'_account_id': 220}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 7191}]","[{'number': 2, 'created': '2013-07-03 07:56:58.000000000', 'files': ['keystone/credential/__init__.py', 'tests/test_v3.py', 'keystone/credential/credential.py', 'tests/test_v3_credential.py', 'keystone/identity/controllers.py', 'tests/test_v3_identity.py', 'keystone/credential/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a3fd4a26f87aab3b7c5d1f718029aa74366c49b8', 'message': ""Create a Credential Model.\n\nSo far we kind of have the C in MVC and everything else is a jumble.\nThis results in things like when working with tokens having to know the\nstructure of the dictionary and thus constantly checking for V2 or V3.\n\nObviously this doesn't touch token and in the case of credential it's\nnot really all that useful. However it is an easy target to show the idea,\nas the more useful ones like identity and token are undergoing large\nchanges that I don't want to get in the way of.\n\nBy inheriting the model from dict I expect that this transition can be\nhandled in pieces. Parts of the model will probably need to be\nabstracted but I expect the function names to remain as they are.\n\nChange-Id: I46e6c9fd9213fb0c05ac40710130f3614af4971e\nStarts: blueprint object-models\n""}, {'number': 1, 'created': '2013-07-03 07:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9f060a9f7c9c44a12e42afdb1868d8fbecca5c00', 'message': ""Create a Credential Model.\n\nSo far we kind of have the C in MVC and everything else is a jumble.\nThis results in things like when working with tokens having to know the\nstructure of the dictionary and thus constantly checking for V2 or V3.\n\nObviously this doesn't touch token and in the case of credential it's\nnot really all that useful. However it is an easy target to show the idea,\nas the more useful ones like identity and token are undergoing large\nchanges that I don't want to get in the way of.\n\nBy inheriting the model from dict I expect that this transition can be\nhandled in pieces. Parts of the model will probably need to be\nabstracted but I expect the function names to remain as they are.\n\nChange-Id: I46e6c9fd9213fb0c05ac40710130f3614af4971e\nStarts: blueprint object-models\n""}]",11,35462,a3fd4a26f87aab3b7c5d1f718029aa74366c49b8,15,6,2,7191,,,0,"Create a Credential Model.

So far we kind of have the C in MVC and everything else is a jumble.
This results in things like when working with tokens having to know the
structure of the dictionary and thus constantly checking for V2 or V3.

Obviously this doesn't touch token and in the case of credential it's
not really all that useful. However it is an easy target to show the idea,
as the more useful ones like identity and token are undergoing large
changes that I don't want to get in the way of.

By inheriting the model from dict I expect that this transition can be
handled in pieces. Parts of the model will probably need to be
abstracted but I expect the function names to remain as they are.

Change-Id: I46e6c9fd9213fb0c05ac40710130f3614af4971e
Starts: blueprint object-models
",git fetch https://review.opendev.org/openstack/keystone refs/changes/62/35462/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/credential/__init__.py', 'tests/test_v3.py', 'keystone/credential/credential.py', 'tests/test_v3_credential.py', 'keystone/identity/controllers.py', 'tests/test_v3_identity.py', 'keystone/credential/controllers.py']",7,a3fd4a26f87aab3b7c5d1f718029aa74366c49b8,bp/object-models,"from keystone.credential import credential as c ref = c.Credential.create(**self._normalize_dict(credential)) return self.wrap_member(context, ref) refs = c.Credential.list() return self.wrap_collection(context, refs) ref = c.Credential.get(credential_id) return self.wrap_member(context, ref) credential['id'] = credential_id ref = c.Credential.update(**credential) return self.wrap_member(context, ref) c.Credential.delete(credential_id)"," ref = self._assign_unique_id(self._normalize_dict(credential)) ref = self.credential_api.create_credential(ref['id'], ref) return CredentialV3.wrap_member(context, ref) refs = self.credential_api.list_credentials() return CredentialV3.wrap_collection(context, refs) ref = self.credential_api.get_credential(credential_id) return CredentialV3.wrap_member(context, ref) ref = self.credential_api.update_credential(credential_id, credential) return CredentialV3.wrap_member(context, ref) return self.credential_api.delete_credential(credential_id)",141,66
openstack%2Fheat~master~I065955d03df543df40af285f87a7fd3dfa779413,openstack/heat,master,I065955d03df543df40af285f87a7fd3dfa779413,Only create the period watch task if there is a watch in the stack,MERGED,2013-07-17 00:30:50.000000000,2013-07-22 00:12:20.000000000,2013-07-22 00:12:20.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 7135}]","[{'number': 1, 'created': '2013-07-17 00:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2851215e0e4b0a86221882667573d7698078cfc6', 'message': 'Only create the period watch task if there is a watch in the stack\n\nThis prevents unneccessary greentheads polling the db.\n\nChange-Id: I065955d03df543df40af285f87a7fd3dfa779413\n'}, {'number': 2, 'created': '2013-07-17 02:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0798e414a7cb11f9ac84fa94e3738001ee36c4b7', 'message': 'Only create the period watch task if there is a watch in the stack\n\nThis prevents unneccessary greentheads polling the db.\n\nbug 1202031\nChange-Id: I065955d03df543df40af285f87a7fd3dfa779413\n'}, {'number': 3, 'created': '2013-07-17 23:54:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/820c49466f3aeb4cd522079485bccdfd4ddb1d68', 'message': 'Only create the period watch task if there is a watch in the stack\n\nThis prevents unneccessary greentheads polling the db.\n\nbug 1202031\nChange-Id: I065955d03df543df40af285f87a7fd3dfa779413\n'}, {'number': 4, 'created': '2013-07-18 02:29:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/47403f2cde4b767e8f342c83d6871c6874d46cb4', 'message': 'Only create the period watch task if there is a watch in the stack\n\nThis prevents unneccessary greentheads polling the db.\n\nbug 1202031\nChange-Id: I065955d03df543df40af285f87a7fd3dfa779413\n'}, {'number': 5, 'created': '2013-07-19 05:09:18.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c3ecb29841629d03cc4a3c0242bfd229da598b56', 'message': 'Only create the period watch task if there is a watch in the stack\n\nThis prevents unneccessary greentheads polling the db.\n\nbug 1202031\nChange-Id: I065955d03df543df40af285f87a7fd3dfa779413\n'}]",0,37360,c3ecb29841629d03cc4a3c0242bfd229da598b56,20,5,5,4715,,,0,"Only create the period watch task if there is a watch in the stack

This prevents unneccessary greentheads polling the db.

bug 1202031
Change-Id: I065955d03df543df40af285f87a7fd3dfa779413
",git fetch https://review.opendev.org/openstack/heat refs/changes/60/37360/4 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/service.py'],1,2851215e0e4b0a86221882667573d7698078cfc6,bug/1202552," wrs = db_api.watch_rule_get_all_by_stack(stack.context, stack.id) if len(wrs) > 0: self._timer_in_thread(stack.id, self._periodic_watcher_task, sid=stack.id)"," self._timer_in_thread(stack.id, self._periodic_watcher_task, sid=stack.id)",5,2
openstack%2Fopenstack-manuals~master~I557303b68c4ca5b5d9f9664e200db3ab6286794e,openstack/openstack-manuals,master,I557303b68c4ca5b5d9f9664e200db3ab6286794e,"rough draft v2, structural changes removed sets, adding in remote include, editorial changes from diane",MERGED,2013-07-18 03:21:34.000000000,2013-07-22 00:04:07.000000000,2013-07-22 00:04:07.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 5263}, {'_account_id': 6923}]","[{'number': 1, 'created': '2013-07-18 03:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d484e4279806bf1de175f14643665761264de2a0', 'message': 'rough draft v2, structural changes\n\nChange-Id: I557303b68c4ca5b5d9f9664e200db3ab6286794e\n'}, {'number': 2, 'created': '2013-07-18 16:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6fd7ed3843c207c4f5155114cad896e807413de9', 'message': 'rough draft v2, structural changes\nremoved sets, adding in remote include\nChange-Id: I557303b68c4ca5b5d9f9664e200db3ab6286794e\n'}, {'number': 3, 'created': '2013-07-19 18:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/28e4415614b00a5f132309cfee1b725f732397fd', 'message': 'rough draft v2, structural changes\nremoved sets, adding in remote include, editorial changes from diane\n\nChange-Id: I557303b68c4ca5b5d9f9664e200db3ab6286794e\n'}, {'number': 4, 'created': '2013-07-20 01:00:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e28688c8f3025f6df4492052ed74da68322d4c10', 'message': 'rough draft v2, structural changes\nremoved sets, adding in remote include, editorial changes from diane\n\nChange-Id: I557303b68c4ca5b5d9f9664e200db3ab6286794e\n'}, {'number': 5, 'created': '2013-07-21 23:48:15.000000000', 'files': ['doc/src/docbkx/openstack-training/bk003-ch001-operations-getting-started.xml', 'doc/src/docbkx/openstack-training/operations-assessment.xml', 'doc/src/docbkx/openstack-training/bk005-devops-training-guide.xml', 'doc/src/docbkx/openstack-training/bk004-ch001-developer-getting-started.xml', 'doc/src/docbkx/openstack-training/bk004-developer-training-guide.xml', 'doc/src/docbkx/openstack-training/bk002-ch001-associate-getting-started.xml', 'doc/src/docbkx/openstack-training/bk002-ch050-associate-assessment.xml', 'doc/src/docbkx/openstack-training/bk002-associate-training-guide.xml', 'doc/src/docbkx/openstack-training/bk003-ch002-operations-fix-bug.xml', 'doc/src/docbkx/openstack-training/bk005-ch001-devops-getting-started.xml', 'doc/src/docbkx/openstack-training/bk005-ch050-devops-assessment.xml', 'doc/src/docbkx/openstack-training/pom.xml', 'doc/src/docbkx/openstack-training/bk004-ch050-developer-assessment.xml', 'doc/src/docbkx/openstack-training/preface.xml', 'doc/src/docbkx/openstack-training/st-training-guide.xml', 'doc/src/docbkx/openstack-training/bk003-operations-training-guide.xml', 'doc/src/docbkx/openstack-training/bk001-preface.xml', 'doc/src/docbkx/openstack-training/bk003-ch050-operations-assessment.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4291371b0465d266c57a21de4dc8ff6d412f85c1', 'message': 'rough draft v2, structural changes\nremoved sets, adding in remote include, editorial changes from diane\n\nChange-Id: I557303b68c4ca5b5d9f9664e200db3ab6286794e\n'}]",14,37613,4291371b0465d266c57a21de4dc8ff6d412f85c1,23,4,5,6923,,,0,"rough draft v2, structural changes
removed sets, adding in remote include, editorial changes from diane

Change-Id: I557303b68c4ca5b5d9f9664e200db3ab6286794e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/13/37613/5 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-training/bk003-ch001-operations-getting-started.xml', 'doc/src/docbkx/openstack-training/bk004-ch001-developer-getting-started.xml', 'doc/src/docbkx/openstack-training/bk002-ch001-associate-getting-started.xml', 'doc/src/docbkx/openstack-training/bk005-devops-training-manual.xml', 'doc/src/docbkx/openstack-training/bk004-developer-training-manual.xml', 'doc/src/docbkx/openstack-training/st-training-manuals.xml', 'doc/src/docbkx/openstack-training/bk002-ch050-associate-assessment.xml', 'doc/src/docbkx/openstack-training/bk003-ch002-operations-fix-bug.xml', 'doc/src/docbkx/openstack-training/bk003-operations-training-manual.xml', 'doc/src/docbkx/openstack-training/bk005-ch001-devops-getting-started.xml', 'doc/src/docbkx/openstack-training/bk005-ch050-devops-assessment.xml', 'doc/src/docbkx/openstack-training/pom.xml', 'doc/src/docbkx/openstack-training/bk002-associate-training-manual.xml', 'doc/src/docbkx/openstack-training/bk004-ch050-developer-assessment.xml', 'doc/src/docbkx/openstack-training/preface.xml', 'doc/src/docbkx/openstack-training/bk001-preface.xml', 'doc/src/docbkx/openstack-training/bk003-ch050-operations-assessment.xml']",17,d484e4279806bf1de175f14643665761264de2a0,bb/training-manuals," xml:id=""bk003-ch050-operations-assessment""></chapter> "," xml:id=""ch_operations-assessment""></chapter>",111,59
openstack%2Fheat~master~Iebb948f788270fca0dbef61a2e122fe3900d84b2,openstack/heat,master,Iebb948f788270fca0dbef61a2e122fe3900d84b2,Wrap the watch rule start in a method,MERGED,2013-07-17 00:30:49.000000000,2013-07-22 00:02:28.000000000,2013-07-22 00:02:28.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 7135}, {'_account_id': 7385}]","[{'number': 1, 'created': '2013-07-17 00:30:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b5c803f64a463547379beef5c49df7e5c2ac5248', 'message': 'Wrap the watch rule start in a method\n\nThis is the first step in making the watch task dependant on:\n1) whether we even have an alarm in the stack\n2) whether the alarm is a ceilometer alarm\n\nChange-Id: Iebb948f788270fca0dbef61a2e122fe3900d84b2\n'}, {'number': 2, 'created': '2013-07-17 02:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/33d30ef2d8c911dac8b0023fc6a8c5b99e552d35', 'message': 'Wrap the watch rule start in a method\n\nThis is the first step in making the watch task dependant on:\n1) whether we even have an alarm in the stack\n2) whether the alarm is a ceilometer alarm\n\nThe test confirms the current behaviour, which is a periodic task\nis created whether or not a watch is in the stack.\n\nbug 1202031\nChange-Id: Iebb948f788270fca0dbef61a2e122fe3900d84b2\n'}, {'number': 3, 'created': '2013-07-17 23:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/735aa3ebdfa53010f38bd8eec48ebe83cb63e1ca', 'message': 'Wrap the watch rule start in a method\n\nThis is the first step in making the watch task dependant on:\n1) whether we even have an alarm in the stack\n2) whether the alarm is a ceilometer alarm\n\nThe test confirms the current behaviour, which is a periodic task\nis created whether or not a watch is in the stack.\n\nbug 1202031\nChange-Id: Iebb948f788270fca0dbef61a2e122fe3900d84b2\n'}, {'number': 4, 'created': '2013-07-18 02:29:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/76affac4a31573e472684471e3edd301d04519b3', 'message': 'Wrap the watch rule start in a method\n\nThis is the first step in making the watch task dependant on:\n1) whether we even have an alarm in the stack\n2) whether the alarm is a ceilometer alarm\n\nThe test confirms the current behaviour, which is a periodic task\nis created whether or not a watch is in the stack.\n\nbug 1202031\nChange-Id: Iebb948f788270fca0dbef61a2e122fe3900d84b2\n'}, {'number': 5, 'created': '2013-07-19 05:09:18.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ef051aa291d202bed7f778070fa6df12cb4188db', 'message': 'Wrap the watch rule start in a method\n\nThis is the first step in making the watch task dependant on:\n1) whether we even have an alarm in the stack\n2) whether the alarm is a ceilometer alarm\n\nThe test confirms the current behaviour, which is a periodic task\nis created whether or not a watch is in the stack.\n\nbug 1202031\nChange-Id: Iebb948f788270fca0dbef61a2e122fe3900d84b2\n'}]",1,37359,ef051aa291d202bed7f778070fa6df12cb4188db,21,6,5,4715,,,0,"Wrap the watch rule start in a method

This is the first step in making the watch task dependant on:
1) whether we even have an alarm in the stack
2) whether the alarm is a ceilometer alarm

The test confirms the current behaviour, which is a periodic task
is created whether or not a watch is in the stack.

bug 1202031
Change-Id: Iebb948f788270fca0dbef61a2e122fe3900d84b2
",git fetch https://review.opendev.org/openstack/heat refs/changes/59/37359/3 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/service.py'],1,b5c803f64a463547379beef5c49df7e5c2ac5248,bug/1202552," def _start_watch_task(self, stack): self._timer_in_thread(stack.id, self._periodic_watcher_task, sid=stack.id) self._start_watch_task(s) self._start_watch_task(stack)"," self._timer_in_thread(s.id, self._periodic_watcher_task, sid=s.id) self._timer_in_thread(stack.id, self._periodic_watcher_task, sid=stack.id)",6,3
openstack%2Fopenstack-manuals~master~I706c4989c9619c7dfc3a4a00df4e2ec92ddd950f,openstack/openstack-manuals,master,I706c4989c9619c7dfc3a4a00df4e2ec92ddd950f,The docbookxi.rng schema moved to oasis-open.org.,MERGED,2013-07-21 19:08:12.000000000,2013-07-21 23:59:51.000000000,2013-07-21 23:59:50.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 612}, {'_account_id': 5263}]","[{'number': 1, 'created': '2013-07-21 19:08:12.000000000', 'files': ['tools/validate.py'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/04d83798d3ae8ce70ebc5d3c684d0a5af48a6b43', 'message': 'The docbookxi.rng schema moved to oasis-open.org.\n\nChange-Id: I706c4989c9619c7dfc3a4a00df4e2ec92ddd950f\n'}]",0,38082,04d83798d3ae8ce70ebc5d3c684d0a5af48a6b43,7,4,1,5263,,,0,"The docbookxi.rng schema moved to oasis-open.org.

Change-Id: I706c4989c9619c7dfc3a4a00df4e2ec92ddd950f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/82/38082/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/validate.py'],1,04d83798d3ae8ce70ebc5d3c684d0a5af48a6b43,docbookxi.rng," url = ""http://www.oasis-open.org/docbook/xml/5.0b5/rng/docbookxi.rng"""," url = ""http://www.docbook.org/xml/5.0/rng/docbookxi.rng""",1,1
openstack%2Fcookbook-openstack-block-storage~master~Ief3e20dd27f262d742db04549b5ac2213dc725fe,openstack/cookbook-openstack-block-storage,master,Ief3e20dd27f262d742db04549b5ac2213dc725fe,implement SUSE platform support,MERGED,2013-07-17 16:22:18.000000000,2013-07-21 23:46:43.000000000,2013-07-21 23:46:43.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 216}]","[{'number': 1, 'created': '2013-07-17 16:22:18.000000000', 'files': ['templates/default/targets.conf.erb', 'spec/volume-opensuse_spec.rb', 'spec/volume_spec.rb', 'spec/spec_helper.rb', 'spec/api-opensuse_spec.rb', 'attributes/default.rb', 'spec/api_spec.rb', 'metadata.rb', 'spec/scheduler-opensuse_spec.rb', 'spec/scheduler_spec.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/10765fd76e4e33a5a850bb2dd5c8e378f7a389ff', 'message': 'implement SUSE platform support\n\nChange-Id: Ief3e20dd27f262d742db04549b5ac2213dc725fe\n'}]",0,37520,10765fd76e4e33a5a850bb2dd5c8e378f7a389ff,6,3,1,2340,,,0,"implement SUSE platform support

Change-Id: Ief3e20dd27f262d742db04549b5ac2213dc725fe
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/20/37520/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/default/targets.conf.erb', 'spec/volume-opensuse_spec.rb', 'spec/volume_spec.rb', 'spec/spec_helper.rb', 'attributes/default.rb', 'spec/api-opensuse_spec.rb', 'spec/api_spec.rb', 'metadata.rb', 'spec/scheduler-opensuse_spec.rb', 'spec/scheduler_spec.rb']",10,10765fd76e4e33a5a850bb2dd5c8e378f7a389ff,suse," expect_creates_cinder_conf ""service[cinder-scheduler]"", ""cinder"", ""cinder"""," expect_creates_cinder_conf ""service[cinder-scheduler]""",179,15
openstack%2Fcookbook-openstack-object-storage~master~If4a87d526da1432c87526099fba87783be0ee656,openstack/cookbook-openstack-object-storage,master,If4a87d526da1432c87526099fba87783be0ee656,"Support more then 24 disks (/dev/sdaa, /dev/vdab, etc)",MERGED,2013-07-16 21:08:00.000000000,2013-07-21 23:45:26.000000000,2013-07-21 23:45:26.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 216}, {'_account_id': 1032}, {'_account_id': 7572}, {'_account_id': 7769}]","[{'number': 1, 'created': '2013-07-16 21:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/2344a8fe6576991b28be2c5b2046eead7380ce40', 'message': 'Support more then 24 disks attached so we import /dev/sdaa, /dev/sdab, etc.\n\nChange-Id: If4a87d526da1432c87526099fba87783be0ee656\n'}, {'number': 2, 'created': '2013-07-16 21:09:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/4629f1b21050227b3f3b8514b80cd7ffa839cc9d', 'message': 'Support more then 24 disks (/dev/sdaa, /dev/sdab, etc)\n\nChange-Id: If4a87d526da1432c87526099fba87783be0ee656\n'}, {'number': 3, 'created': '2013-07-19 19:27:36.000000000', 'files': ['attributes/default.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/fe10aaeeb99d555b5929bb0767688373dafd220c', 'message': 'Support more then 24 disks (/dev/sdaa, /dev/vdab, etc)\n\nChange-Id: If4a87d526da1432c87526099fba87783be0ee656\n'}]",1,37327,fe10aaeeb99d555b5929bb0767688373dafd220c,14,6,3,7769,,,0,"Support more then 24 disks (/dev/sdaa, /dev/vdab, etc)

Change-Id: If4a87d526da1432c87526099fba87783be0ee656
",git fetch https://review.opendev.org/openstack/cookbook-openstack-object-storage refs/changes/27/37327/3 && git format-patch -1 --stdout FETCH_HEAD,['attributes/default.rb'],1,2344a8fe6576991b28be2c5b2046eead7380ce40,,"default[""swift""][""disk_test_filter""] = [ ""candidate =~ /sd[^a]/ or candidate =~ /sda[a-z]/ or candidate =~ /hd[^a]/ or candidate =~ /vd[^a]/ or candidate =~ /xvd[^a]/"",","default[""swift""][""disk_test_filter""] = [ ""candidate =~ /sd[^a]/ or candidate =~ /hd[^a]/ or candidate =~ /vd[^a]/ or candidate =~ /xvd[^a]/"",",1,1
openstack%2Fpython-keystoneclient~master~Iba4b3fd8ad2e6fe054ed705d8990c13dc5a13430,openstack/python-keystoneclient,master,Iba4b3fd8ad2e6fe054ed705d8990c13dc5a13430,"Use ServiceCatalog.factory, the object has no __init__",MERGED,2013-07-01 08:42:44.000000000,2013-07-21 22:51:02.000000000,2013-07-21 22:51:02.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 4375}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-01 08:42:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/1f2bb664ca6e407b543cf16aaaae8cbfec9f27cb', 'message': 'Use ServiceCatalog.factory, the object has no __init__\n\nChange-Id: Iba4b3fd8ad2e6fe054ed705d8990c13dc5a13430\n'}, {'number': 2, 'created': '2013-07-09 09:06:08.000000000', 'files': ['keystoneclient/access.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/a6312d52b7a493dea156221f55a952ef21a628bf', 'message': 'Use ServiceCatalog.factory, the object has no __init__\n\nFixes LP bug #1199281\n\nChange-Id: Iba4b3fd8ad2e6fe054ed705d8990c13dc5a13430\n'}]",0,35103,a6312d52b7a493dea156221f55a952ef21a628bf,16,4,2,4375,,,0,"Use ServiceCatalog.factory, the object has no __init__

Fixes LP bug #1199281

Change-Id: Iba4b3fd8ad2e6fe054ed705d8990c13dc5a13430
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/03/35103/2 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/access.py'],1,1f2bb664ca6e407b543cf16aaaae8cbfec9f27cb,bug/1199281, self.service_catalog = service_catalog.ServiceCatalog.factory(, self.service_catalog = service_catalog.ServiceCatalog(,1,1
openstack%2Fpython-keystoneclient~master~Ib23c9ab5066cfdcdda4e07cd30fa8f6ff47949bd,openstack/python-keystoneclient,master,Ib23c9ab5066cfdcdda4e07cd30fa8f6ff47949bd,"Merge "" Cleanup docstrings "" from keystone/common/cms.py",MERGED,2013-07-09 16:30:09.000000000,2013-07-21 22:40:52.000000000,2013-07-21 22:40:52.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-09 16:30:09.000000000', 'files': ['keystoneclient/common/cms.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/c555662b20bd6890a44114f2debbd7d4a63d15a7', 'message': 'Merge "" Cleanup docstrings "" from keystone/common/cms.py\n\nIn an attempt to unify both implementations in order to\nbe able to remove one of the duplicated ones, merge the\nchanges from this commit in keystone:\n\n    Author: Dolph Mathews <dolph.mathews@gmail.com>\n    Date:   Fri May 24 11:36:44 2013 -0500\n\n    Cleanup docstrings (flake8 H401, H402, H403, H404)\n\nChange-Id: Ib23c9ab5066cfdcdda4e07cd30fa8f6ff47949bd\n'}]",0,36286,c555662b20bd6890a44114f2debbd7d4a63d15a7,10,3,1,6593,,,0,"Merge "" Cleanup docstrings "" from keystone/common/cms.py

In an attempt to unify both implementations in order to
be able to remove one of the duplicated ones, merge the
changes from this commit in keystone:

    Author: Dolph Mathews <dolph.mathews@gmail.com>
    Date:   Fri May 24 11:36:44 2013 -0500

    Cleanup docstrings (flake8 H401, H402, H403, H404)

Change-Id: Ib23c9ab5066cfdcdda4e07cd30fa8f6ff47949bd
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/86/36286/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/common/cms.py'],1,c555662b20bd6890a44114f2debbd7d4a63d15a7,cms_merge," """"""Verifies the signature of the contents IAW CMS syntax."""""" """"""Determine if a token appears to be PKI-based. """""" """"""Hash PKI tokens. "," """""" verifies the signature of the contents IAW CMS syntax """""" ''' ''' """"""",6,6
openstack%2Fpython-keystoneclient~master~I619fc32b62beab4458ee6f21bf8dc7499fe400d7,openstack/python-keystoneclient,master,I619fc32b62beab4458ee6f21bf8dc7499fe400d7,Raise key length defaults,MERGED,2013-07-09 15:43:05.000000000,2013-07-21 22:40:52.000000000,2013-07-21 22:40:52.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-09 15:43:05.000000000', 'files': ['examples/pki/certs/signing_cert.pem', 'examples/pki/certs/cacert.pem', 'examples/pki/cms/auth_token_scoped.pem', 'examples/pki/certs/middleware.pem', 'examples/pki/private/signing_key.pem', 'examples/pki/cms/auth_token_unscoped.pem', 'examples/pki/cms/auth_token_scoped_expired.pem', 'examples/pki/cms/revocation_list.pem', 'examples/pki/cms/auth_token_revoked.pem', 'examples/pki/gen_pki.sh', 'examples/pki/certs/ssl_cert.pem', 'examples/pki/cms/auth_v3_token_revoked.pem', 'examples/pki/private/ssl_key.pem', 'examples/pki/private/cakey.pem', 'examples/pki/cms/auth_v3_token_scoped.pem'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/3f1415026b2d1d00f71a906c84846ba56af1b56a', 'message': 'Raise key length defaults\n\nExtend RSA keylength to 2048 bits by default,\nas the previous default of 1024 bit is considered\nweak since 12/31/2010.\n\nAlso unify the message_md to the openssl builtin\ndefault.\n\nFixes bug 1103002\n\nChange-Id: I619fc32b62beab4458ee6f21bf8dc7499fe400d7\n'}]",0,36246,3f1415026b2d1d00f71a906c84846ba56af1b56a,10,3,1,6593,,,0,"Raise key length defaults

Extend RSA keylength to 2048 bits by default,
as the previous default of 1024 bit is considered
weak since 12/31/2010.

Also unify the message_md to the openssl builtin
default.

Fixes bug 1103002

Change-Id: I619fc32b62beab4458ee6f21bf8dc7499fe400d7
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/46/36246/1 && git format-patch -1 --stdout FETCH_HEAD,"['examples/pki/certs/signing_cert.pem', 'examples/pki/certs/cacert.pem', 'examples/pki/cms/auth_token_scoped.pem', 'examples/pki/certs/middleware.pem', 'examples/pki/private/signing_key.pem', 'examples/pki/cms/auth_token_unscoped.pem', 'examples/pki/cms/auth_token_scoped_expired.pem', 'examples/pki/cms/revocation_list.pem', 'examples/pki/cms/auth_token_revoked.pem', 'examples/pki/gen_pki.sh', 'examples/pki/certs/ssl_cert.pem', 'examples/pki/cms/auth_v3_token_revoked.pem', 'examples/pki/private/ssl_key.pem', 'examples/pki/private/cakey.pem', 'examples/pki/cms/auth_v3_token_scoped.pem']",15,3f1415026b2d1d00f71a906c84846ba56af1b56a,bug/1103002,MIIH/AYJKoZIhvcNAQcCoIIH7TCCB+kCAQExCTAHBgUrDgMCGjCCBgkGCSqGSIb3DQoxggHKMIIBxgIBATCBpDCBnjEKMAgGA1UEBRMBNTELMAkGA1UEBhMCVVMxCzAJCSqGSIb3DQEBAQUABIIBAICxNgyMnXQRLjYCXZYaRkkzQiVeSKKhXqYSvwYBgMjy JiDUbxHQmOZ5OY5OuCFyrrGNDw8v0JCuycVnr6dzLGMgeoVRtmRG5MhUV3aNK4gV zwrgASjFeoUftNnmlsqkes3kMnTd5OuTrrTcWeVOfVX+fMoJzGHMt0huGX/tpUv0 t4E9QDFXR4yTMswUXJDOjZHfyj/nZtSWT0ozSCQ44UUSPWYJafuT5XNH5Dw53rjH NUpbUyWE23SrnG8YophNLeYDU9bh1z4RbgYXCm3x/IqfkdcAZJ4n/NshocRsheWo 1hfzdub5Ugnq7FjBPqkyyMg6iOPevaYAwYjc5lFcoq8=,MIIHewYJKoZIhvcNAQcCoIIHbDCCB2gCAQExCTAHBgUrDgMCGjCCBgkGCSqGSIb3DQoxggFJMIIBRQIBATCBpDCBnjEKMAgGA1UEBRMBNTELMAkGA1UEBhMCVVMxCzAJCSqGSIb3DQEBAQUABIGAxb2GSHoV7yzFDoW6sJwRK49xgMO3bpcU6s+yxUh4auLR MQ8Wso1xzDPnG2Xp886u0Wvw9dUC2s1qTD1aXKDdaHY0FUXC3pWUypR+6Ky5M7WP YJvDJfD0fdPX44SHwXo9Zy+DcU4zcRCucC4/5zn5w30qd1t1mwvd8GNdxvUqmZ8=,230,144
openstack%2Fneutron~master~Ieabd6279524cbb26c3ae093550840f13c0e584f0,openstack/neutron,master,Ieabd6279524cbb26c3ae093550840f13c0e584f0,Imported Translations from Transifex,MERGED,2013-07-21 19:55:20.000000000,2013-07-21 21:39:26.000000000,2013-07-21 21:39:25.000000000,"[{'_account_id': 3}, {'_account_id': 2592}]","[{'number': 1, 'created': '2013-07-21 19:55:20.000000000', 'files': ['neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa39de6b31c14a24cb9f52f10758108faa69a9aa', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ieabd6279524cbb26c3ae093550840f13c0e584f0\n'}]",0,38087,aa39de6b31c14a24cb9f52f10758108faa69a9aa,5,2,1,3,,,0,"Imported Translations from Transifex

Change-Id: Ieabd6279524cbb26c3ae093550840f13c0e584f0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/87/38087/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po']",40,aa39de6b31c14a24cb9f52f10758108faa69a9aa,transifex/translations,"""POT-Creation-Date: 2013-07-21 19:54+0000\n""#: neutron/agent/securitygroups_rpc.py:32 msgid ""Driver for Security Groups Firewall"" msgstr """" #: neutron/agent/securitygroups_rpc.py:45#: neutron/agent/securitygroups_rpc.py:52#: neutron/agent/securitygroups_rpc.py:75#: neutron/agent/securitygroups_rpc.py:85#: neutron/agent/securitygroups_rpc.py:90 #: neutron/agent/securitygroups_rpc.py:139#: neutron/agent/securitygroups_rpc.py:101#: neutron/agent/securitygroups_rpc.py:107#: neutron/agent/securitygroups_rpc.py:115#: neutron/agent/securitygroups_rpc.py:122#: neutron/agent/securitygroups_rpc.py:145#: neutron/agent/securitygroups_rpc.py:154#: neutron/agent/securitygroups_rpc.py:161#: neutron/agent/securitygroups_rpc.py:167#: neutron/common/config.py:91 msgid """" ""Where to store Neutron state files. This directory must be writable by "" ""the agent."" msgstr """" #: neutron/common/config.py:117#: neutron/common/config.py:128#: neutron/common/config.py:141#: neutron/common/config.py:146#: neutron/plugins/bigswitch/plugin.py:141 msgid ""List of allowed vif_type values."" msgstr """" #: neutron/plugins/bigswitch/plugin.py:170#: neutron/plugins/bigswitch/plugin.py:206#: neutron/plugins/bigswitch/plugin.py:210#: neutron/plugins/bigswitch/plugin.py:219#: neutron/plugins/bigswitch/plugin.py:226#: neutron/plugins/bigswitch/plugin.py:243#: neutron/plugins/bigswitch/plugin.py:247#: neutron/plugins/bigswitch/plugin.py:297#: neutron/plugins/bigswitch/plugin.py:305#: neutron/plugins/bigswitch/plugin.py:339#: neutron/plugins/bigswitch/plugin.py:381#: neutron/plugins/bigswitch/plugin.py:407#: neutron/plugins/bigswitch/plugin.py:432#: neutron/plugins/bigswitch/plugin.py:464#: neutron/plugins/bigswitch/plugin.py:481 #: neutron/plugins/bigswitch/plugin.py:529 #: neutron/plugins/bigswitch/plugin.py:1283#: neutron/plugins/bigswitch/plugin.py:502#: neutron/plugins/bigswitch/plugin.py:559#: neutron/plugins/bigswitch/plugin.py:594 #: neutron/plugins/bigswitch/plugin.py:685#: neutron/plugins/bigswitch/plugin.py:649#: neutron/plugins/bigswitch/plugin.py:706#: neutron/plugins/bigswitch/plugin.py:740 #: neutron/plugins/bigswitch/plugin.py:798#: neutron/plugins/bigswitch/plugin.py:757#: neutron/plugins/bigswitch/plugin.py:775#: neutron/plugins/bigswitch/plugin.py:789#: neutron/plugins/bigswitch/plugin.py:803#: neutron/plugins/bigswitch/plugin.py:824#: neutron/plugins/bigswitch/plugin.py:847#: neutron/plugins/bigswitch/plugin.py:888#: neutron/plugins/bigswitch/plugin.py:913#: neutron/plugins/bigswitch/plugin.py:924#: neutron/plugins/bigswitch/plugin.py:946#: neutron/plugins/bigswitch/plugin.py:958#: neutron/plugins/bigswitch/plugin.py:989#: neutron/plugins/bigswitch/plugin.py:995#: neutron/plugins/bigswitch/plugin.py:1023#: neutron/plugins/bigswitch/plugin.py:1034#: neutron/plugins/bigswitch/plugin.py:1067#: neutron/plugins/bigswitch/plugin.py:1075#: neutron/plugins/bigswitch/plugin.py:1088#: neutron/plugins/bigswitch/plugin.py:1098#: neutron/plugins/bigswitch/plugin.py:1121#: neutron/plugins/bigswitch/plugin.py:1204#: neutron/plugins/bigswitch/plugin.py:1300#: neutron/plugins/bigswitch/plugin.py:1306#: neutron/plugins/bigswitch/plugin.py:1333","""POT-Creation-Date: 2013-07-20 19:55+0000\n""#: neutron/agent/securitygroups_rpc.py:44#: neutron/agent/securitygroups_rpc.py:51#: neutron/agent/securitygroups_rpc.py:74#: neutron/agent/securitygroups_rpc.py:84#: neutron/agent/securitygroups_rpc.py:89 #: neutron/agent/securitygroups_rpc.py:138#: neutron/agent/securitygroups_rpc.py:100#: neutron/agent/securitygroups_rpc.py:106#: neutron/agent/securitygroups_rpc.py:114#: neutron/agent/securitygroups_rpc.py:121#: neutron/agent/securitygroups_rpc.py:144#: neutron/agent/securitygroups_rpc.py:153#: neutron/agent/securitygroups_rpc.py:160#: neutron/agent/securitygroups_rpc.py:166#: neutron/common/config.py:114#: neutron/common/config.py:125#: neutron/common/config.py:138#: neutron/common/config.py:143#: neutron/plugins/bigswitch/plugin.py:168#: neutron/plugins/bigswitch/plugin.py:204#: neutron/plugins/bigswitch/plugin.py:208#: neutron/plugins/bigswitch/plugin.py:217#: neutron/plugins/bigswitch/plugin.py:224#: neutron/plugins/bigswitch/plugin.py:241#: neutron/plugins/bigswitch/plugin.py:245#: neutron/plugins/bigswitch/plugin.py:295#: neutron/plugins/bigswitch/plugin.py:303#: neutron/plugins/bigswitch/plugin.py:337#: neutron/plugins/bigswitch/plugin.py:379#: neutron/plugins/bigswitch/plugin.py:405#: neutron/plugins/bigswitch/plugin.py:430#: neutron/plugins/bigswitch/plugin.py:462#: neutron/plugins/bigswitch/plugin.py:479 #: neutron/plugins/bigswitch/plugin.py:527 #: neutron/plugins/bigswitch/plugin.py:1281#: neutron/plugins/bigswitch/plugin.py:500#: neutron/plugins/bigswitch/plugin.py:557#: neutron/plugins/bigswitch/plugin.py:592 #: neutron/plugins/bigswitch/plugin.py:683#: neutron/plugins/bigswitch/plugin.py:647#: neutron/plugins/bigswitch/plugin.py:704#: neutron/plugins/bigswitch/plugin.py:738 #: neutron/plugins/bigswitch/plugin.py:796#: neutron/plugins/bigswitch/plugin.py:755#: neutron/plugins/bigswitch/plugin.py:773#: neutron/plugins/bigswitch/plugin.py:787#: neutron/plugins/bigswitch/plugin.py:801#: neutron/plugins/bigswitch/plugin.py:822#: neutron/plugins/bigswitch/plugin.py:845#: neutron/plugins/bigswitch/plugin.py:886#: neutron/plugins/bigswitch/plugin.py:911#: neutron/plugins/bigswitch/plugin.py:922#: neutron/plugins/bigswitch/plugin.py:944#: neutron/plugins/bigswitch/plugin.py:956#: neutron/plugins/bigswitch/plugin.py:987#: neutron/plugins/bigswitch/plugin.py:993#: neutron/plugins/bigswitch/plugin.py:1021#: neutron/plugins/bigswitch/plugin.py:1032#: neutron/plugins/bigswitch/plugin.py:1065#: neutron/plugins/bigswitch/plugin.py:1073#: neutron/plugins/bigswitch/plugin.py:1086#: neutron/plugins/bigswitch/plugin.py:1096#: neutron/plugins/bigswitch/plugin.py:1119#: neutron/plugins/bigswitch/plugin.py:1202#: neutron/plugins/bigswitch/plugin.py:1298#: neutron/plugins/bigswitch/plugin.py:1304#: neutron/plugins/bigswitch/plugin.py:1331",3281,2721
openstack%2Fpbr~master~Iaa327862fc9e43aade2dd1ed66aa27f335f12ac7,openstack/pbr,master,Iaa327862fc9e43aade2dd1ed66aa27f335f12ac7,Set defaults directly in option processing,MERGED,2013-07-21 17:22:03.000000000,2013-07-21 21:22:42.000000000,2013-07-21 21:22:42.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5263}]","[{'number': 1, 'created': '2013-07-21 17:22:03.000000000', 'files': ['pbr/d2to1/util.py', 'pbr/hooks/backwards.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/d09372e59e0a951867da65cd152e7d3f0e8faf0f', 'message': 'Set defaults directly in option processing\n\nChange-Id: Iaa327862fc9e43aade2dd1ed66aa27f335f12ac7\n'}]",0,38078,d09372e59e0a951867da65cd152e7d3f0e8faf0f,6,3,1,2,,,0,"Set defaults directly in option processing

Change-Id: Iaa327862fc9e43aade2dd1ed66aa27f335f12ac7
",git fetch https://review.opendev.org/openstack/pbr refs/changes/78/38078/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/d2to1/util.py', 'pbr/hooks/backwards.py']",2,d09372e59e0a951867da65cd152e7d3f0e8faf0f,,, self.config['include_package_data'] = 'True',4,1
openstack%2Fcookbook-openstack-image~master~I78d1671e5ecc6dfd6cdb04f4218341cbb6594d33,openstack/cookbook-openstack-image,master,I78d1671e5ecc6dfd6cdb04f4218341cbb6594d33,Cannot refer to attributes in other cookbooks,MERGED,2013-07-21 21:02:33.000000000,2013-07-21 21:10:09.000000000,2013-07-21 21:10:09.000000000,"[{'_account_id': 3}, {'_account_id': 216}]","[{'number': 1, 'created': '2013-07-21 21:02:33.000000000', 'files': ['attributes/default.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/d933e964443c2ee843a934da5eff2d7f86860927', 'message': 'Cannot refer to attributes in other cookbooks\n\nThe way that Chef11 handles setting default attributes from\nreferences to other cookbook defaults is broken -- or at least\nnon-intuitive. We need to set string defaults for things otherwise\non compilation, the defaults will contain NilClass values.\n\nChange-Id: I78d1671e5ecc6dfd6cdb04f4218341cbb6594d33\n'}]",0,38089,d933e964443c2ee843a934da5eff2d7f86860927,5,2,1,7,,,0,"Cannot refer to attributes in other cookbooks

The way that Chef11 handles setting default attributes from
references to other cookbook defaults is broken -- or at least
non-intuitive. We need to set string defaults for things otherwise
on compilation, the defaults will contain NilClass values.

Change-Id: I78d1671e5ecc6dfd6cdb04f4218341cbb6594d33
",git fetch https://review.opendev.org/openstack/cookbook-openstack-image refs/changes/89/38089/1 && git format-patch -1 --stdout FETCH_HEAD,['attributes/default.rb'],1,d933e964443c2ee843a934da5eff2d7f86860927,attrs,"default[""openstack""][""image""][""rabbit_server_chef_role""] = ""os-ops-messaging""default[""openstack""][""image""][""rabbit""][""username""] = ""guest"" default[""openstack""][""image""][""rabbit""][""vhost""] = ""/"" default[""openstack""][""image""][""rabbit""][""port""] = 5672 default[""openstack""][""image""][""rabbit""][""host""] = ""127.0.0.1""","default[""openstack""][""image""][""rabbit_server_chef_role""] = node[""openstack""][""mq""][""server_role""]default[""openstack""][""image""][""rabbit""][""username""] = node[""openstack""][""mq""][""user""] default[""openstack""][""image""][""rabbit""][""vhost""] = node[""openstack""][""mq""][""vhost""] default[""openstack""][""image""][""rabbit""][""port""] = node[""openstack""][""mq""][""port""] default[""openstack""][""image""][""rabbit""][""host""] = node[""openstack""][""mq""][""host""]",5,5
openstack%2Fpbr~master~I8f9db1d76931ef834645095952f71415d98f0b5c,openstack/pbr,master,I8f9db1d76931ef834645095952f71415d98f0b5c,Fix integer_types type under python 3,MERGED,2013-07-21 19:28:15.000000000,2013-07-21 20:27:30.000000000,2013-07-21 20:27:30.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-21 19:28:15.000000000', 'files': ['pbr/core.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/aa7a6fd3270710e533f84e04c84a94d46fa15266', 'message': 'Fix integer_types type under python 3\n\nSet the integer_types variable to the same kind of object\nunder python 3 and 2 so that when we go to manipulate it\nlater it works.\n\nChange-Id: I8f9db1d76931ef834645095952f71415d98f0b5c\n'}]",0,38083,aa7a6fd3270710e533f84e04c84a94d46fa15266,6,3,1,2472,,,0,"Fix integer_types type under python 3

Set the integer_types variable to the same kind of object
under python 3 and 2 so that when we go to manipulate it
later it works.

Change-Id: I8f9db1d76931ef834645095952f71415d98f0b5c
",git fetch https://review.opendev.org/openstack/pbr refs/changes/83/38083/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/core.py'],1,aa7a6fd3270710e533f84e04c84a94d46fa15266,bug/python-3-type-error," integer_types = (int,)", integer_types = int,1,1
openstack%2Fcookbook-openstack-compute~master~Ie23ef1e04e5c29eeb99635dc5850de4acbaff1f7,openstack/cookbook-openstack-compute,master,Ie23ef1e04e5c29eeb99635dc5850de4acbaff1f7,Cookbook defines rabbit settings,MERGED,2013-07-20 20:07:12.000000000,2013-07-21 18:48:45.000000000,2013-07-21 18:48:45.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1032}]","[{'number': 1, 'created': '2013-07-20 20:07:12.000000000', 'files': ['attributes/default.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/04c10fa51009f242768a81b76fa9db4579ed43f3', 'message': 'Cookbook defines rabbit settings\n\nWhen setting a coobook\'s default attributes from the attributes\non another cookbook, it becomes impossible to override from\na wrapper cookbook.  We just started working on wrapper cookbooks,\nand attempting to override `openstack[""mq""]` settings proved\nunsuccessful.\n\nSince the community actively has people looking into wrapper\ncookbooks, this fix seems reasonable.\n\nChange-Id: Ie23ef1e04e5c29eeb99635dc5850de4acbaff1f7\n'}]",0,38048,04c10fa51009f242768a81b76fa9db4579ed43f3,6,3,1,216,,,0,"Cookbook defines rabbit settings

When setting a coobook's default attributes from the attributes
on another cookbook, it becomes impossible to override from
a wrapper cookbook.  We just started working on wrapper cookbooks,
and attempting to override `openstack[""mq""]` settings proved
unsuccessful.

Since the community actively has people looking into wrapper
cookbooks, this fix seems reasonable.

Change-Id: Ie23ef1e04e5c29eeb99635dc5850de4acbaff1f7
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/48/38048/1 && git format-patch -1 --stdout FETCH_HEAD,['attributes/default.rb'],1,04c10fa51009f242768a81b76fa9db4579ed43f3,non-mq-attrs,"default[""openstack""][""compute""][""rabbit_server_chef_role""] = ""os-ops-messaging""default[""openstack""][""compute""][""rabbit""][""username""] = ""guest"" default[""openstack""][""compute""][""rabbit""][""vhost""] = ""/"" default[""openstack""][""compute""][""rabbit""][""port""] = 5672 default[""openstack""][""compute""][""rabbit""][""host""] = ""127.0.0.1""","default[""openstack""][""compute""][""rabbit_server_chef_role""] = node[""openstack""][""mq""][""server_role""]default[""openstack""][""compute""][""rabbit""][""username""] = node[""openstack""][""mq""][""user""] default[""openstack""][""compute""][""rabbit""][""vhost""] = node[""openstack""][""mq""][""vhost""] default[""openstack""][""compute""][""rabbit""][""port""] = node[""openstack""][""mq""][""port""] default[""openstack""][""compute""][""rabbit""][""host""] = node[""openstack""][""mq""][""host""] # Rabbit HA queues",5,6
openstack%2Fcookbook-openstack-block-storage~master~Ibadc4bddd1bc66638cd826f5bc6e3f6ee3a38179,openstack/cookbook-openstack-block-storage,master,Ibadc4bddd1bc66638cd826f5bc6e3f6ee3a38179,Cookbook defines rabbit settings,MERGED,2013-07-20 19:56:13.000000000,2013-07-21 18:41:15.000000000,2013-07-21 18:41:15.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1032}, {'_account_id': 7220}]","[{'number': 1, 'created': '2013-07-20 19:56:13.000000000', 'files': ['attributes/default.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/39d04a4300b12c4f96ab4b3e53721fa148a7a948', 'message': 'Cookbook defines rabbit settings\n\nWhen setting a coobook\'s default attributes from the attributes\nof another cookbook, it becomes impossible to override from\na wrapper cookbook.  We just started working on wrapper cookbooks,\nand attempting to override `openstack[""mq""]` settings proved\nunsuccessful.\n\nSince the community actively has people looking into wrapper\ncookbooks, this fix seems reasonable.\n\nChange-Id: Ibadc4bddd1bc66638cd826f5bc6e3f6ee3a38179\n'}]",0,38047,39d04a4300b12c4f96ab4b3e53721fa148a7a948,7,4,1,216,,,0,"Cookbook defines rabbit settings

When setting a coobook's default attributes from the attributes
of another cookbook, it becomes impossible to override from
a wrapper cookbook.  We just started working on wrapper cookbooks,
and attempting to override `openstack[""mq""]` settings proved
unsuccessful.

Since the community actively has people looking into wrapper
cookbooks, this fix seems reasonable.

Change-Id: Ibadc4bddd1bc66638cd826f5bc6e3f6ee3a38179
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/47/38047/1 && git format-patch -1 --stdout FETCH_HEAD,['attributes/default.rb'],1,39d04a4300b12c4f96ab4b3e53721fa148a7a948,non-mq-attrs,"default[""openstack""][""block-storage""][""rabbit_server_chef_role""] = ""os-ops-messaging""default[""openstack""][""block-storage""][""rabbit""][""username""] = ""guest"" default[""openstack""][""block-storage""][""rabbit""][""vhost""] = ""/"" default[""openstack""][""block-storage""][""rabbit""][""port""] = 5672 default[""openstack""][""block-storage""][""rabbit""][""host""] = ""127.0.0.1""","default[""openstack""][""block-storage""][""rabbit_server_chef_role""] = node[""openstack""][""mq""][""server_role""]default[""openstack""][""block-storage""][""rabbit""][""username""] = node[""openstack""][""mq""][""user""] default[""openstack""][""block-storage""][""rabbit""][""vhost""] = node[""openstack""][""mq""][""vhost""] default[""openstack""][""block-storage""][""rabbit""][""port""] = node[""openstack""][""mq""][""port""] default[""openstack""][""block-storage""][""rabbit""][""host""] = node[""openstack""][""mq""][""host""]",5,5
openstack%2Fkeystone~master~I4beffa77c38321a44b44d1893d2335319c23b5a5,openstack/keystone,master,I4beffa77c38321a44b44d1893d2335319c23b5a5,Correct Spelling Mistake,MERGED,2013-07-21 09:21:03.000000000,2013-07-21 18:30:24.000000000,2013-07-21 18:30:23.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-21 09:21:03.000000000', 'files': ['tests/test_middleware.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/4d3dae48a077104412ba227f66c5f80802cd51c1', 'message': 'Correct Spelling Mistake\n\nModified one spelling mistake in tests/test_middleware\n\nChange-Id: I4beffa77c38321a44b44d1893d2335319c23b5a5\n'}]",0,38061,4d3dae48a077104412ba227f66c5f80802cd51c1,6,3,1,8229,,,0,"Correct Spelling Mistake

Modified one spelling mistake in tests/test_middleware

Change-Id: I4beffa77c38321a44b44d1893d2335319c23b5a5
",git fetch https://review.opendev.org/openstack/keystone refs/changes/61/38061/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_middleware.py'],1,4d3dae48a077104412ba227f66c5f80802cd51c1,refactorMisSpell," """"""JSON-only requests should be unaffected by the XML middleware."""""""," """"""JSON-only requests should be unnaffected by the XML middleware.""""""",1,1
openstack%2Fkeystone~master~I5d1914ae3490f715437711d594ec903a2c6632f5,openstack/keystone,master,I5d1914ae3490f715437711d594ec903a2c6632f5,Remove an enumerate call,MERGED,2013-07-21 08:58:16.000000000,2013-07-21 18:30:16.000000000,2013-07-21 18:30:16.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-21 08:58:16.000000000', 'files': ['tests/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/7ea4da4773f69c90e65d7b9e8d9af7e53a363fa9', 'message': 'Remove an enumerate call\n\nRefactor tests/test_backend.py, remove a useless enumerate call in\nfor loop.\n\nChange-Id: I5d1914ae3490f715437711d594ec903a2c6632f5\n'}]",0,38060,7ea4da4773f69c90e65d7b9e8d9af7e53a363fa9,6,3,1,8228,,,0,"Remove an enumerate call

Refactor tests/test_backend.py, remove a useless enumerate call in
for loop.

Change-Id: I5d1914ae3490f715437711d594ec903a2c6632f5
",git fetch https://review.opendev.org/openstack/keystone refs/changes/60/38060/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_backend.py'],1,7ea4da4773f69c90e65d7b9e8d9af7e53a363fa9,refactorRemoveUselessEnumerate, for ref in roles_ref:," for i, ref in enumerate(roles_ref):",1,1
openstack%2Fkeystone~master~I04b09c214b9ea997d8f540a72978ce9b19b4138d,openstack/keystone,master,I04b09c214b9ea997d8f540a72978ce9b19b4138d,Add [assignment].driver to sample config,MERGED,2013-07-18 18:23:44.000000000,2013-07-21 17:47:02.000000000,2013-07-21 17:47:01.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 994}, {'_account_id': 2166}, {'_account_id': 5707}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-18 18:23:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/00b1c947978d549e3f0f82d6c92659afc8823402', 'message': ""Add [assignment].driver to sample config\n\nThere's a new config option [assignment].driver that wasn't included\nin the sample config file. This makes it more difficult than necessary\nfor deployers to configure.\n\nFixes bug 1202778\n\nChange-Id: I04b09c214b9ea997d8f540a72978ce9b19b4138d\n""}, {'number': 2, 'created': '2013-07-18 18:24:33.000000000', 'files': ['etc/keystone.conf.sample'], 'web_link': 'https://opendev.org/openstack/keystone/commit/eca1ca35fcf9ceec071a1b550ae7faf9c1a4db98', 'message': ""Add [assignment].driver to sample config\n\nThere's a new config option [assignment].driver that wasn't included\nin the sample config file. This makes it more difficult than necessary\nfor deployers to configure.\n\nFixes bug 1202778\n\nChange-Id: I04b09c214b9ea997d8f540a72978ce9b19b4138d\n""}]",4,37739,eca1ca35fcf9ceec071a1b550ae7faf9c1a4db98,17,6,2,6486,,,0,"Add [assignment].driver to sample config

There's a new config option [assignment].driver that wasn't included
in the sample config file. This makes it more difficult than necessary
for deployers to configure.

Fixes bug 1202778

Change-Id: I04b09c214b9ea997d8f540a72978ce9b19b4138d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/39/37739/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/keystone.conf.sample'],1,00b1c947978d549e3f0f82d6c92659afc8823402,bug/1202778,[assignment] # driver = ,,3,0
openstack%2Fkeystone~master~Icba582a085939f58581fa909b63a36cbad3b4e69,openstack/keystone,master,Icba582a085939f58581fa909b63a36cbad3b4e69,Deprecation warning for [signing] token_format,MERGED,2013-07-18 16:40:16.000000000,2013-07-21 17:39:15.000000000,2013-07-21 17:39:14.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 5046}, {'_account_id': 6456}, {'_account_id': 6460}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-18 16:40:16.000000000', 'files': ['keystone/token/provider.py', 'tests/test_token_provider.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/76888e1ee21326adf1f4d44b64da81479fcde6c3', 'message': 'Deprecation warning for [signing] token_format\n\nThis also adds i18n to a few related strings and updates doc.\n\nChange-Id: Icba582a085939f58581fa909b63a36cbad3b4e69\n'}]",2,37716,76888e1ee21326adf1f4d44b64da81479fcde6c3,11,7,1,4,,,0,"Deprecation warning for [signing] token_format

This also adds i18n to a few related strings and updates doc.

Change-Id: Icba582a085939f58581fa909b63a36cbad3b4e69
",git fetch https://review.opendev.org/openstack/keystone refs/changes/16/37716/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/provider.py', 'tests/test_token_provider.py']",2,76888e1ee21326adf1f4d44b64da81479fcde6c3,(detached," self.assertEqual(token.provider.Manager.get_token_provider(), self.assertEqual(token.provider.Manager.get_token_provider(), token.provider.Manager.get_token_provider) token.provider.Manager.get_token_provider) self.assertEqual(token.provider.Manager.get_token_provider(), self.assertEqual(token.provider.Manager.get_token_provider(), self.assertEqual(token.provider.Manager.get_token_provider(),"," self.assertEqual(token.provider.Manager.check_and_get_token_provider(), self.assertEqual(token.provider.Manager.check_and_get_token_provider(), token.provider.Manager.check_and_get_token_provider) token.provider.Manager.check_and_get_token_provider) self.assertEqual(token.provider.Manager.check_and_get_token_provider(), self.assertEqual(token.provider.Manager.check_and_get_token_provider(), self.assertEqual(token.provider.Manager.check_and_get_token_provider(),",27,19
openstack%2Fpython-keystoneclient~master~I78528bf7055b6975a642e1f2f3264e94f5a4885b,openstack/python-keystoneclient,master,I78528bf7055b6975a642e1f2f3264e94f5a4885b,Update openstack-common.conf format,MERGED,2013-07-16 11:35:04.000000000,2013-07-21 17:39:13.000000000,2013-07-21 17:39:13.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6486}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-07-16 11:35:04.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/f62a7378f7c896e6d44d4ed351638ba1c4960760', 'message': 'Update openstack-common.conf format\n\nChange-Id: I78528bf7055b6975a642e1f2f3264e94f5a4885b\n'}]",0,37226,f62a7378f7c896e6d44d4ed351638ba1c4960760,8,4,1,1267,,,0,"Update openstack-common.conf format

Change-Id: I78528bf7055b6975a642e1f2f3264e94f5a4885b
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/26/37226/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,f62a7378f7c896e6d44d4ed351638ba1c4960760,,module=install_venv_common module=jsonutils module=timeutils,"modules=install_venv_common,jsonutils,timeutils",3,1
openstack%2Fkeystone~master~Ic649e7eb4633e258264f27280d938a08af380921,openstack/keystone,master,Ic649e7eb4633e258264f27280d938a08af380921,Return correct link for effective group roles in GET /role_assignments,MERGED,2013-07-15 17:47:17.000000000,2013-07-21 17:21:05.000000000,2013-07-21 17:21:05.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 994}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-15 17:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/099f9dc0a5ac884b462a1292896e4b39ce740841', 'message': 'Return correct link for effective group roles in GET /role_assignments\n\nThe assignment link returned for roles that are included by virtue of\ngroup membership should refer to the group assignment that led to this\nrole, rather than a direct user assignment.\n\nFixes bug 1201374\n\nChange-Id: Ic649e7eb4633e258264f27280d938a08af380921\n'}, {'number': 2, 'created': '2013-07-16 10:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ad502d20c3869ac6c827f059c106d3e33db27de0', 'message': 'Return correct link for effective group roles in GET /role_assignments\n\nThe assignment link returned for roles that are included by virtue of\ngroup membership should refer to the group assignment that led to this\nrole, rather than a direct user assignment.\n\nFixes bug 1201374\n\nChange-Id: Ic649e7eb4633e258264f27280d938a08af380921\n'}, {'number': 3, 'created': '2013-07-17 08:43:43.000000000', 'files': ['keystone/identity/controllers.py', 'tests/test_v3_identity.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2af9ce342788fdd3e407141a233c5393b061ffb0', 'message': 'Return correct link for effective group roles in GET /role_assignments\n\nThe assignment link returned for roles that are included by virtue of\ngroup membership should refer to the group assignment that led to this\nrole, rather than a direct user assignment.\n\nFixes bug 1201374\n\nChange-Id: Ic649e7eb4633e258264f27280d938a08af380921\n'}]",5,37104,2af9ce342788fdd3e407141a233c5393b061ffb0,23,9,3,5707,,,0,"Return correct link for effective group roles in GET /role_assignments

The assignment link returned for roles that are included by virtue of
group membership should refer to the group assignment that led to this
role, rather than a direct user assignment.

Fixes bug 1201374

Change-Id: Ic649e7eb4633e258264f27280d938a08af380921
",git fetch https://review.opendev.org/openstack/keystone refs/changes/04/37104/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/identity/controllers.py', 'tests/test_v3_identity.py']",2,099f9dc0a5ac884b462a1292896e4b39ce740841,bug/1201374," unused, ud_entity = self._build_role_assignment_url_and_entity( gd_url, unused = self._build_role_assignment_url_and_entity( domain_id=self.domain_id, group_id=self.group['id'], role_id=self.role_id) self.assertRoleAssignmentInListResponse(r, ud_entity, link_url=gd_url) self.assertRoleAssignmentInListResponse(r, ud_entity, link_url=gd_url) unused, up1_entity = self._build_role_assignment_url_and_entity( unused, ud1_entity = self._build_role_assignment_url_and_entity( gp1_url, unused = self._build_role_assignment_url_and_entity( project_id=self.project1['id'], group_id=self.group1['id'], role_id=self.role1['id']) gd1_url, unused = self._build_role_assignment_url_and_entity( domain_id=self.domain_id, group_id=self.group1['id'], role_id=self.role1['id']) link_url=gp1_url) link_url=gd1_url) link_url=gp1_url)"," ud_url, ud_entity = self._build_role_assignment_url_and_entity( self.assertRoleAssignmentInListResponse(r, ud_entity, link_url=ud_url) self.assertRoleAssignmentInListResponse(r, ud_entity, link_url=ud_url) up1_url, up1_entity = self._build_role_assignment_url_and_entity( ud1_url, ud1_entity = self._build_role_assignment_url_and_entity( link_url=up1_url) link_url=ud1_url) up1_url, up1_entity = self._build_role_assignment_url_and_entity( project_id=self.project1['id'], user_id=self.user1['id'], role_id=self.role1['id']) link_url=up1_url)",19,13
openstack%2Fpbr~master~I4dc822eba0e1597e9eec1ec057d37871d930eb84,openstack/pbr,master,I4dc822eba0e1597e9eec1ec057d37871d930eb84,Add libffi-dev,MERGED,2013-07-20 20:36:25.000000000,2013-07-21 16:54:20.000000000,2013-07-21 16:54:20.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5263}]","[{'number': 1, 'created': '2013-07-20 20:36:25.000000000', 'files': ['tools/integration.sh'], 'web_link': 'https://opendev.org/openstack/pbr/commit/705c04becdef75efbc67cb294981a7f6ab298a61', 'message': 'Add libffi-dev\n\nChange-Id: I4dc822eba0e1597e9eec1ec057d37871d930eb84\n'}]",0,38049,705c04becdef75efbc67cb294981a7f6ab298a61,6,3,1,2,,,0,"Add libffi-dev

Change-Id: I4dc822eba0e1597e9eec1ec057d37871d930eb84
",git fetch https://review.opendev.org/openstack/pbr refs/changes/49/38049/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/integration.sh'],1,705c04becdef75efbc67cb294981a7f6ab298a61,replace-setuptols-git,sudo apt-get install -y --force-yes libxml2-dev libxslt-dev libmysqlclient-dev libpq-dev libnspr4-dev pkg-config libsqlite3-dev libzmq-dev libffi-dev,sudo apt-get install -y --force-yes libxml2-dev libxslt-dev libmysqlclient-dev libpq-dev libnspr4-dev pkg-config libsqlite3-dev libzmq-dev,1,1
openstack%2Fpython-keystoneclient~master~I9c7bc83d75a964152ad5772554f9693706a2a2d4,openstack/python-keystoneclient,master,I9c7bc83d75a964152ad5772554f9693706a2a2d4,Add discover to test-requirements.,MERGED,2013-07-18 23:56:52.000000000,2013-07-21 16:54:19.000000000,2013-07-21 16:54:19.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-18 23:56:52.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/e748acd0a2c269a977ab1a4d50a9f6f67c77db37', 'message': 'Add discover to test-requirements.\n\nApparently this was always supposed to be required for py26 tests with\ntestresources however only recently does a newer version actually fail\nwithout it.\n\nChange-Id: I9c7bc83d75a964152ad5772554f9693706a2a2d4\n'}]",0,37813,e748acd0a2c269a977ab1a4d50a9f6f67c77db37,7,3,1,7191,,,0,"Add discover to test-requirements.

Apparently this was always supposed to be required for py26 tests with
testresources however only recently does a newer version actually fail
without it.

Change-Id: I9c7bc83d75a964152ad5772554f9693706a2a2d4
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/13/37813/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,e748acd0a2c269a977ab1a4d50a9f6f67c77db37,discover,discover,,1,0
openstack%2Fneutron~master~I5aa773d4acda9b45e758c72c263419b6dc165931,openstack/neutron,master,I5aa773d4acda9b45e758c72c263419b6dc165931,Avoid performing extra query for fetching port security binding,ABANDONED,2013-07-16 20:50:27.000000000,2013-07-21 16:07:26.000000000,,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2592}]","[{'number': 1, 'created': '2013-07-16 20:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b7df2a5b1de193bac957717ff4643a0fc09ba4a', 'message': ""Avoid performing extra query for fetching port security binding\n\nBug 1201597\n\nBeyond achieving the goal of avoiding an extra query for retrieving the\nport security bindings for both networks and ports, this patch also\nextends the facilities offered by the db base class in a way such that\na plugin might specifies which relationships should be eagerly loaded\nwhen a db operation is performed.\nThis will allow to perform the full joined load when doing, for instance\na get_network call, whereas it will be possible to specify which joins\nare needed when performing a call to the 'private' method _get_network.\n\nChange-Id: I5aa773d4acda9b45e758c72c263419b6dc165931\n""}, {'number': 2, 'created': '2013-07-17 16:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a67be5ba53be33a271d16759afe5d934c20c133', 'message': ""Avoid performing extra query for fetching port security binding\n\nBug 1201957\n\nBeyond achieving the goal of avoiding an extra query for retrieving the\nport security bindings for both networks and ports, this patch also\nextends the facilities offered by the db base class in a way such that\na plugin might specifies which relationships should be eagerly loaded\nwhen a db operation is performed.\nThis will allow to perform the full joined load when doing, for instance\na get_network call, whereas it will be possible to specify which joins\nare needed when performing a call to the 'private' method _get_network.\n\nChange-Id: I5aa773d4acda9b45e758c72c263419b6dc165931\n""}, {'number': 3, 'created': '2013-07-18 16:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b4e8dab6fb4ad529394a333b0e9f60326634a90', 'message': ""Avoid performing extra query for fetching port security binding\n\nBug 1201957\n\nBeyond achieving the goal of avoiding an extra query for retrieving the\nport security bindings for both networks and ports, this patch also\nextends the facilities offered by the db base class in a way such that\na plugin might specifies which relationships should be eagerly loaded\nwhen a db operation is performed.\nThis will allow to perform the full joined load when doing, for instance\na get_network call, whereas it will be possible to specify which joins\nare needed when performing a call to the 'private' method _get_network.\n\nChange-Id: I5aa773d4acda9b45e758c72c263419b6dc165931\n""}, {'number': 4, 'created': '2013-07-18 22:16:29.000000000', 'files': ['neutron/db/securitygroups_db.py', 'neutron/db/portsecurity_db.py', 'neutron/plugins/nicira/NeutronPlugin.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/tests/unit/test_extension_portsecurity.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3439598a021ee95dd6499c3b837a6d924fcbed9d', 'message': ""Avoid performing extra query for fetching port security binding\n\nBug 1201957\n\nBeyond achieving the goal of avoiding an extra query for retrieving the\nport security bindings for both networks and ports, this patch also\nextends the facilities offered by the db base class in a way such that\na plugin might specifies which relationships should be eagerly loaded\nwhen a db operation is performed.\nThis will allow to perform the full joined load when doing, for instance\na get_network call, whereas it will be possible to specify which joins\nare needed when performing a call to the 'private' method _get_network.\n\nChange-Id: I5aa773d4acda9b45e758c72c263419b6dc165931\n""}]",12,37324,3439598a021ee95dd6499c3b837a6d924fcbed9d,15,4,4,261,,,0,"Avoid performing extra query for fetching port security binding

Bug 1201957

Beyond achieving the goal of avoiding an extra query for retrieving the
port security bindings for both networks and ports, this patch also
extends the facilities offered by the db base class in a way such that
a plugin might specifies which relationships should be eagerly loaded
when a db operation is performed.
This will allow to perform the full joined load when doing, for instance
a get_network call, whereas it will be possible to specify which joins
are needed when performing a call to the 'private' method _get_network.

Change-Id: I5aa773d4acda9b45e758c72c263419b6dc165931
",git fetch https://review.opendev.org/openstack/neutron refs/changes/24/37324/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/securitygroups_db.py', 'neutron/db/portsecurity_db.py', 'neutron/plugins/nicira/NeutronPlugin.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/tests/unit/test_extension_portsecurity.py']",6,2b7df2a5b1de193bac957717ff4643a0fc09ba4a,bug/1201957," self._process_network_port_security_create( context, network['network'], neutron_db) self._process_network_port_security_update( context, network['network'], neutron_db) self._process_port_port_security_create(context, p, neutron_db) self._process_port_port_security_update( context, port['port'], ret_port)"," self._process_network_create_port_security( context, neutron_db) self._extend_network_port_security_dict(context, neutron_db) self._update_network_security_binding( context, id, network['network'][psec.PORTSECURITY]) self._extend_network_port_security_dict( context, neutron_db) self._extend_network_port_security_dict(context, net) self._process_port_security_create(context, p) self._extend_port_port_security_dict(context, p) self._update_port_security_binding( context, id, ret_port[psec.PORTSECURITY]) self._extend_port_port_security_dict(context, ret_port)",180,82
openstack%2Fkeystone~master~Ie65f27ab586e05a3c43a589499c115b56e734e07,openstack/keystone,master,Ie65f27ab586e05a3c43a589499c115b56e734e07,Regenerate example PKI after change of defaults,MERGED,2013-07-09 16:26:37.000000000,2013-07-21 15:58:38.000000000,2013-07-21 15:58:37.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2166}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-09 16:26:37.000000000', 'files': ['examples/pki/cms/auth_token_unscoped.pem', 'examples/pki/cms/revocation_list.pem', 'examples/pki/certs/signing_cert.pem', 'examples/pki/cms/auth_token_revoked.pem', 'examples/pki/certs/cacert.pem', 'examples/pki/certs/ssl_cert.pem', 'examples/pki/private/ssl_key.pem', 'examples/pki/cms/auth_token_scoped.pem', 'examples/pki/private/cakey.pem', 'examples/pki/certs/middleware.pem', 'examples/pki/private/signing_key.pem'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9741026404da60e2a26d952f321b2e43de5d15f7', 'message': 'Regenerate example PKI after change of defaults\n\nIn https://review.openstack.org/#/c/31374/ the PKI defaults\nwere changed but the example PKI not updated. Update it now.\n\nChange-Id: Ie65f27ab586e05a3c43a589499c115b56e734e07\n'}]",0,36284,9741026404da60e2a26d952f321b2e43de5d15f7,8,4,1,6593,,,0,"Regenerate example PKI after change of defaults

In https://review.openstack.org/#/c/31374/ the PKI defaults
were changed but the example PKI not updated. Update it now.

Change-Id: Ie65f27ab586e05a3c43a589499c115b56e734e07
",git fetch https://review.opendev.org/openstack/keystone refs/changes/84/36284/1 && git format-patch -1 --stdout FETCH_HEAD,"['examples/pki/cms/auth_token_unscoped.pem', 'examples/pki/cms/revocation_list.pem', 'examples/pki/certs/signing_cert.pem', 'examples/pki/cms/auth_token_revoked.pem', 'examples/pki/certs/cacert.pem', 'examples/pki/certs/ssl_cert.pem', 'examples/pki/private/ssl_key.pem', 'examples/pki/cms/auth_token_scoped.pem', 'examples/pki/private/cakey.pem', 'examples/pki/certs/middleware.pem', 'examples/pki/private/signing_key.pem']",11,9741026404da60e2a26d952f321b2e43de5d15f7,regen_pki,MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDEwuiHTXfQoNQ7 IXK0+YEVURd+pxJo0gPUFnYpOwfduTyu9FOBeo+Kc/+SS+6ZSKP/KyeIyc/XHBO5 tIgPiLgAbRIRMF5Bva4+OzstCeGcgxkoditQZe/DwPc8V0s8rFE0owSnQIdvXT2G yWO3IGSdLgtwLX1XHmIgDiIteEnRXmdC2Sw1wbi2qlJkjK5isCfcADDgm/42wT/f 92HHdBmI5b60gVOAam/PzR2rMjuA6TzevDgKMg+a+Y1LVfEGTdN1IyLKLsfHtJay +vjFbSaNDn1r5Uq5c0uRykq8mPrqqkBLsbWSqSTNjFfObo743PHg0goYdrIYQ4wX ptxSJRylAgMBAAECggEBAIDQPVz/CXarI+ZGQotaYPisqx3+kN3QyDLcNaVOgRrW P3UmfVjh/QEeae3ECkONu9e8z9gMjyX7uqo0F3NcBWI6Bb79FGgjnuQc8OPOeUZ2 yUyk+DxdT/eu5+04FQh2o387TjuU0lXFDBem1sI30cbZMyHQliMnwAPOXO+5tVH8 PusGNBMVvoCyfnj52uVjmAjPqLXyOMcKEhuJFbhnUURKvzkHRf43SWQsb081eh2m ACQ7uNzX7vg3aPXxSZXY2+hHX67POdqosjddu6CfoXcEHAOAUujvTOFvd1gGRkRo uOi5hNQqcN5uaqeq9enVThINDyFMzngZBhMCzRTWeK0CgYEA4qUhB7lJZLt9niDW 4Fudda1Pzu3XfxHsSG4D+xx5LunKb3ChG5x7PSLJvusfvnkm5fqhEEhbSVARo6Vn AAA52u5SPDDNwyk1ttvBR/Fc7eGwpbRQry2I6ui6baKiIOSV2K3vJlsSK8/GMQqu j0fstJuSvQR7Y6NUYxlWi+VNussCgYEA3j7tFAdGFc5JkeTHSzsU4h2+17uVDSSi yr7Duc9+9fwAbsO4go9x1CAOvV2r0WX10jPsTGg1d31pWLvJrS6QsAffmM+A0QIT eBX+umcavXWy69VExWa0xKU9wTE/nQvX9Fr8A+Klh/WfMcvoomK2zgOKoRSmes04 WKYlHWsSaE8CgYBUYcZ6abG5n1SVmwRlY7asKWqdUE/7L2EZVlyFEYTMwp5r/zL8 ZLY9fMZAHqoi8FhbJ4Tv2wChuv3WP66pgWwI5tIXNtRk5OLqwcakUmiW6IAsMYYY sotXam5+gx55wKFJmvh+/0k0ppbTi3aSQeUPGRz44sJNxnGUs8pVK3pVIQKBgQDD ga+lEtEAlbv6b7sx3wN79pbPyOBR84yRtkcPygzx74Gh7uL9V5rW9GyDAUgIqR0a kTqp7HI8b0KhIHFFu9TkRcjY8JFtS9o8pXy0FcdcK5H+DFq3HKag5ovwy5YeXTDY cMGJ2XOsqtIkSDCZySTvDgaBtVzOYoHS2jWEL5C92QKBgGmL2juXIB+HAi7UuKPg nWkVTikt5Zr2GNgYtso75E7+ljaRuf4D9eEBiOD1qYKQm8KvsiVzEs71BSmT1p1C b2hlM/5Crb7KumIkHTARQFr5NPwuBZ6NA6RLnd++vKi0WgOJtDAlR3bgwugfQdzZ 4Isaq9Rgfa/EHCKB2weQ7c3r,MIICdwIBADANBgkqhkiG9w0BAQEFAASCAmEwggJdAgEAAoGBANBnphDSfn7OTmk/ JOLgOxE0QwP6F/7VCglQH8X2L3hwHUKhCg3FG7YXV054ZAZ79DmSKcQT8cERGUmS tiP4XpD6wSC2eFEs6MxQoLnVwON0DJAZXLkPlTiNv6uR+M9pJ8WnsbAYz3iF+w/T aMLU2BZToEqgosfMViHDVtcdRJ9XAgMBAAECgYAqcJEO5+6+oACzyhoW4ZblwADN tIZibLvofZqa07GDE0HCKc1EVJl6EXLEFhw4fdGUT8GVnoIi0PqXUvsohBGtkmpM Ee+Yj5ii7VEL75Z5zzJZ50CM7vI0AqZ2WMIITjgsrMKdBh0tHolTCqenqv1t2/OZ dwAgPG1C90VsPgLW4QJBAOvuCwOZwAOlIygeSYfl9/aQuIQzP5yIQbv95Z+jeyii ly29FrPqhZvU4+hS7xUnT8X1d5XemsQTScoE/lF3LEkCQQDiIi5crENMdYX60ax7 /6U25Ej0XyQ3Gt8ryYDoPIaeWSlRV5TQnYfY9CdQqJmTyBWYHNBOhjHupNX4AgWJ 8y6fAkEAlYNZP4LkCGtSiE4JUzINnhfAlybTHSPMZJJWPoCfv/Sp0baO+J2a5lJX zBcipEkxaMZSbouPkMqYbIoVkRLw4QJAD8y5looGrbnsYYjy1zsWbQ5oNoLLQfpj q2iJ1DAea8PpCiDnaegHzNXKRW1yRYwOTjF9MG9Z38WumYRypJ/UGwJBAJShOlyg AA3ob9ajlJ3/NMNbIrVbDuG1c14HVHarnF9nrf8wmjACXP/rjFZo9tVAbQjG6kXH 41oYgyhOVRYT578=,196,118
openstack-attic%2Fidentity-api~master~I7c857ae71fa09581bbd11b56c913f6f0354aced2,openstack-attic/identity-api,master,I7c857ae71fa09581bbd11b56c913f6f0354aced2,Move OS-EP-FILTER into correct dir,MERGED,2013-07-12 16:28:28.000000000,2013-07-21 15:35:33.000000000,2013-07-21 15:35:33.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-12 16:28:28.000000000', 'files': ['openstack-identity-api/v3/src/markdown/identity-api-v3-os-ep-filter-ext.md'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/0695fa9918a514cf26facf7df24da86f0ea16d64', 'message': 'Move OS-EP-FILTER into correct dir\n\nIt appears this doc was written when the repo was layed out a bit\ndifferently.\n\nChange-Id: I7c857ae71fa09581bbd11b56c913f6f0354aced2\n'}]",0,36858,0695fa9918a514cf26facf7df24da86f0ea16d64,7,3,1,4,,,0,"Move OS-EP-FILTER into correct dir

It appears this doc was written when the repo was layed out a bit
differently.

Change-Id: I7c857ae71fa09581bbd11b56c913f6f0354aced2
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/58/36858/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-identity-api/v3/src/markdown/identity-api-v3-os-ep-filter-ext.md'],1,0695fa9918a514cf26facf7df24da86f0ea16d64,(detached,,,0,0
openstack%2Fnova~master~Ic3d5a3dd60ba50b561126279c00ca07022aaa20e,openstack/nova,master,Ic3d5a3dd60ba50b561126279c00ca07022aaa20e,Add missing tests for console_* methods.,MERGED,2013-07-04 12:50:13.000000000,2013-07-21 12:26:56.000000000,2013-07-21 12:26:54.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 2835}, {'_account_id': 4393}, {'_account_id': 7491}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-07-04 12:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9951fc87cf9cba9e02d7cbccd92d50c98021e5e5', 'message': 'Add missing tests for console_* methods.\n\nThere was no tests in test_db_api for console_* methods.\nAdd tests to ensure that all works.\n\nblueprint db-api-tests\n\nChange-Id: Ic3d5a3dd60ba50b561126279c00ca07022aaa20e\n'}, {'number': 2, 'created': '2013-07-04 13:34:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86dad7b1e33482bd09b403da9f4bdc5a5e2623bf', 'message': 'Add missing tests for console_* methods.\n\nThere was no tests in test_db_api for console_* methods.\nAdd tests to ensure that all works.\n\nblueprint db-api-tests\n\nChange-Id: Ic3d5a3dd60ba50b561126279c00ca07022aaa20e\n'}, {'number': 3, 'created': '2013-07-04 14:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be6e911d7fe8fe10f9461632e3c1a7e865cf96b6', 'message': 'Add missing tests for console_* methods.\n\nThere was no tests in test_db_api for console_* methods.\nAdd tests to ensure that all works.\n\nblueprint db-api-tests\n\nChange-Id: Ic3d5a3dd60ba50b561126279c00ca07022aaa20e\n'}, {'number': 4, 'created': '2013-07-15 11:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9aceaafc6f2890ed9e49a6e448652ae24dbf4716', 'message': 'Add missing tests for console_* methods.\n\nThere was no tests in test_db_api for console_* methods.\nAdd tests to ensure that all works.\n\nblueprint db-api-tests\n\nChange-Id: Ic3d5a3dd60ba50b561126279c00ca07022aaa20e\n'}, {'number': 5, 'created': '2013-07-15 11:05:31.000000000', 'files': ['nova/tests/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1f538810fdd4f58762dfe50699996ea7b4776683', 'message': 'Add missing tests for console_* methods.\n\nThere was no tests in test_db_api for console_* methods.\nAdd tests to ensure that all works.\n\nblueprint db-api-tests\n\nChange-Id: Ic3d5a3dd60ba50b561126279c00ca07022aaa20e\n'}]",22,35646,1f538810fdd4f58762dfe50699996ea7b4776683,25,8,5,7711,,,0,"Add missing tests for console_* methods.

There was no tests in test_db_api for console_* methods.
Add tests to ensure that all works.

blueprint db-api-tests

Change-Id: Ic3d5a3dd60ba50b561126279c00ca07022aaa20e
",git fetch https://review.opendev.org/openstack/nova refs/changes/46/35646/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/db/test_db_api.py'],1,9951fc87cf9cba9e02d7cbccd92d50c98021e5e5,bp/db-api-tests,"class ConsoleTestCase(test.TestCase, ModelsObjectComparatorMixin): def setUp(self): super(ConsoleTestCase, self).setUp() self.ctxt = context.get_admin_context() pools_data = [ {'address': '192.168.10.10', 'username': 'user1', 'password': 'passwd1', 'console_type': 'type1', 'public_hostname': 'public_host1', 'host': 'host1', 'compute_host': 'compute_host1' }, {'address': '192.168.10.11', 'username': 'user2', 'password': 'passwd2', 'console_type': 'type2', 'public_hostname': 'public_host2', 'host': 'host2', 'compute_host': 'compute_host2' }, ] console_pools = [db.console_pool_create(self.ctxt, val) for val in pools_data] self.console_data = [dict([('instance_name', 'name' + str(x)), ('instance_uuid', uuidutils.generate_uuid()), ('password', 'pass' + str(x)), ('port', 7878 + x), ('pool_id', console_pools[x]['id'])]) for x in xrange(len(pools_data))] self.consoles = [db.console_create(self.ctxt, val) for val in self.console_data] def test_console_create(self): ignored_keys = ['id', 'deleted', 'deleted_at', 'created_at', 'updated_at'] for console in self.consoles: self.assertFalse(console['id'] is None) self._assertEqualListsOfObjects(self.console_data, self.consoles, ignored_keys=ignored_keys) def test_console_get_by_id(self): for console in self.consoles: console_get = db.console_get(self.ctxt, console['id']) self._assertEqualObjects(console, console_get, ignored_keys=['pool']) def test_console_get_by_id_uuid(self): for console in self.consoles: console_get = db.console_get(self.ctxt, console['id'], console['instance_uuid']) self._assertEqualObjects(console, console_get, ignored_keys=['pool']) def test_console_get_by_pool_instance(self): for console in self.consoles: console_get = db.console_get_by_pool_instance(self.ctxt, console['pool_id'], console['instance_uuid']) self._assertEqualObjects(console, console_get, ignored_keys=['pool']) def test_console_get_all_by_instance(self): for console in self.consoles: console_get = db.console_get_all_by_instance(self.ctxt, console['instance_uuid']) self.assertEqual(len(console_get), 1) self._assertEqualObjects(console, console_get[0]) def test_console_delete(self): for console in self.consoles: db.console_delete(self.ctxt, console['id']) console_get = db.console_get_all_by_instance(self.ctxt, console['instance_uuid']) self.assertEqual(console_get, []) def test_console_get_by_pool_instance_not_found(self): self.assertRaises(exception.ConsoleNotFoundInPoolForInstance, db.console_get_by_pool_instance, self.ctxt, self.consoles[0]['pool_id'], uuidutils.generate_uuid()) def test_console_get_not_found(self): self.assertRaises(exception.ConsoleNotFound, db.console_get, self.ctxt, 100500) def test_console_get_not_found_instance(self): self.assertRaises(exception.ConsoleNotFoundForInstance, db.console_get, self.ctxt, self.consoles[0]['id'], uuidutils.generate_uuid()) ",,92,0
openstack%2Fdesignate~master~Ic24f444a66a0221a0618133e30e0f762b0f599e9,openstack/designate,master,Ic24f444a66a0221a0618133e30e0f762b0f599e9,Remove openstack.common.cfg.,MERGED,2013-07-20 11:53:44.000000000,2013-07-21 10:31:05.000000000,2013-07-21 10:31:05.000000000,"[{'_account_id': 3}, {'_account_id': 741}]","[{'number': 1, 'created': '2013-07-20 11:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/cabe9cce52457fbcb94626eea22aa91500fbe3a5', 'message': 'Remove openstack.common.cfg.\n\nWe migrated to oslo.config a while back, this was leftover.\n\nAdditionally, cleanup the openstack-common.conf file.\n\nChange-Id: Ic24f444a66a0221a0618133e30e0f762b0f599e9\n'}, {'number': 2, 'created': '2013-07-20 11:56:34.000000000', 'files': ['designate/openstack/common/iniparser.py', 'openstack-common.conf', 'designate/openstack/common/cfg.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/b59a696aca4648182a85efadd244cf1fe51473ad', 'message': 'Remove openstack.common.cfg.\n\nWe migrated to oslo.config a while back, this was leftover.\n\nAdditionally, cleanup the openstack-common.conf file.\n\nChange-Id: Ic24f444a66a0221a0618133e30e0f762b0f599e9\n'}]",0,38032,b59a696aca4648182a85efadd244cf1fe51473ad,7,2,2,741,,,0,"Remove openstack.common.cfg.

We migrated to oslo.config a while back, this was leftover.

Additionally, cleanup the openstack-common.conf file.

Change-Id: Ic24f444a66a0221a0618133e30e0f762b0f599e9
",git fetch https://review.opendev.org/openstack/designate refs/changes/32/38032/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/openstack/common/iniparser.py', 'openstack-common.conf', 'designate/openstack/common/cfg.py']",3,cabe9cce52457fbcb94626eea22aa91500fbe3a5,,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2012 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. r"""""" Configuration options which may be set on the command line or in config files. The schema for each option is defined using the Opt sub-classes, e.g.: :: common_opts = [ cfg.StrOpt('bind_host', default='0.0.0.0', help='IP address to listen on'), cfg.IntOpt('bind_port', default=9292, help='Port number to listen on') ] Options can be strings, integers, floats, booleans, lists or 'multi strings':: enabled_apis_opt = cfg.ListOpt('enabled_apis', default=['ec2', 'osapi_compute'], help='List of APIs to enable by default') DEFAULT_EXTENSIONS = [ 'nova.api.openstack.compute.contrib.standard_extensions' ] osapi_compute_extension_opt = cfg.MultiStrOpt('osapi_compute_extension', default=DEFAULT_EXTENSIONS) Option schemas are registered with the config manager at runtime, but before the option is referenced:: class ExtensionManager(object): enabled_apis_opt = cfg.ListOpt(...) def __init__(self, conf): self.conf = conf self.conf.register_opt(enabled_apis_opt) ... def _load_extensions(self): for ext_factory in self.conf.osapi_compute_extension: .... A common usage pattern is for each option schema to be defined in the module or class which uses the option:: opts = ... def add_common_opts(conf): conf.register_opts(opts) def get_bind_host(conf): return conf.bind_host def get_bind_port(conf): return conf.bind_port An option may optionally be made available via the command line. Such options must registered with the config manager before the command line is parsed (for the purposes of --help and CLI arg validation):: cli_opts = [ cfg.BoolOpt('verbose', short='v', default=False, help='Print more verbose output'), cfg.BoolOpt('debug', short='d', default=False, help='Print debugging output'), ] def add_common_opts(conf): conf.register_cli_opts(cli_opts) The config manager has two CLI options defined by default, --config-file and --config-dir:: class ConfigOpts(object): def __call__(self, ...): opts = [ MultiStrOpt('config-file', ...), StrOpt('config-dir', ...), ] self.register_cli_opts(opts) Option values are parsed from any supplied config files using openstack.common.iniparser. If none are specified, a default set is used e.g. glance-api.conf and glance-common.conf:: glance-api.conf: [DEFAULT] bind_port = 9292 glance-common.conf: [DEFAULT] bind_host = 0.0.0.0 Option values in config files override those on the command line. Config files are parsed in order, with values in later files overriding those in earlier files. The parsing of CLI args and config files is initiated by invoking the config manager e.g.:: conf = ConfigOpts() conf.register_opt(BoolOpt('verbose', ...)) conf(sys.argv[1:]) if conf.verbose: ... Options can be registered as belonging to a group:: rabbit_group = cfg.OptGroup(name='rabbit', title='RabbitMQ options') rabbit_host_opt = cfg.StrOpt('host', default='localhost', help='IP/hostname to listen on'), rabbit_port_opt = cfg.IntOpt('port', default=5672, help='Port number to listen on') def register_rabbit_opts(conf): conf.register_group(rabbit_group) # options can be registered under a group in either of these ways: conf.register_opt(rabbit_host_opt, group=rabbit_group) conf.register_opt(rabbit_port_opt, group='rabbit') If it no group attributes are required other than the group name, the group need not be explicitly registered e.g. def register_rabbit_opts(conf): # The group will automatically be created, equivalent calling:: # conf.register_group(OptGroup(name='rabbit')) conf.register_opt(rabbit_port_opt, group='rabbit') If no group is specified, options belong to the 'DEFAULT' section of config files:: glance-api.conf: [DEFAULT] bind_port = 9292 ... [rabbit] host = localhost port = 5672 use_ssl = False userid = guest password = guest virtual_host = / Command-line options in a group are automatically prefixed with the group name:: --rabbit-host localhost --rabbit-port 9999 Option values in the default group are referenced as attributes/properties on the config manager; groups are also attributes on the config manager, with attributes for each of the options associated with the group:: server.start(app, conf.bind_port, conf.bind_host, conf) self.connection = kombu.connection.BrokerConnection( hostname=conf.rabbit.host, port=conf.rabbit.port, ...) Option values may reference other values using PEP 292 string substitution:: opts = [ cfg.StrOpt('state_path', default=os.path.join(os.path.dirname(__file__), '../'), help='Top-level directory for maintaining nova state'), cfg.StrOpt('sqlite_db', default='nova.sqlite', help='file name for sqlite'), cfg.StrOpt('sql_connection', default='sqlite:///$state_path/$sqlite_db', help='connection string for sql database'), ] Note that interpolation can be avoided by using '$$'. Options may be declared as required so that an error is raised if the user does not supply a value for the option. Options may be declared as secret so that their values are not leaked into log files:: opts = [ cfg.StrOpt('s3_store_access_key', secret=True), cfg.StrOpt('s3_store_secret_key', secret=True), ... ] This module also contains a global instance of the ConfigOpts class in order to support a common usage pattern in OpenStack:: from oslo.config import cfg opts = [ cfg.StrOpt('bind_host', default='0.0.0.0'), cfg.IntOpt('bind_port', default=9292), ] CONF = cfg.CONF CONF.register_opts(opts) def start(server, app): server.start(app, CONF.bind_port, CONF.bind_host) Positional command line arguments are supported via a 'positional' Opt constructor argument:: >>> conf = ConfigOpts() >>> conf.register_cli_opt(MultiStrOpt('bar', positional=True)) True >>> conf(['a', 'b']) >>> conf.bar ['a', 'b'] It is also possible to use argparse ""sub-parsers"" to parse additional command line arguments using the SubCommandOpt class: >>> def add_parsers(subparsers): ... list_action = subparsers.add_parser('list') ... list_action.add_argument('id') ... >>> conf = ConfigOpts() >>> conf.register_cli_opt(SubCommandOpt('action', handler=add_parsers)) True >>> conf(args=['list', '10']) >>> conf.action.name, conf.action.id ('list', '10') """""" import argparse import collections import copy import functools import glob import os import string import sys from designate.openstack.common import iniparser class Error(Exception): """"""Base class for cfg exceptions."""""" def __init__(self, msg=None): self.msg = msg def __str__(self): return self.msg class ArgsAlreadyParsedError(Error): """"""Raised if a CLI opt is registered after parsing."""""" def __str__(self): ret = ""arguments already parsed"" if self.msg: ret += "": "" + self.msg return ret class NoSuchOptError(Error, AttributeError): """"""Raised if an opt which doesn't exist is referenced."""""" def __init__(self, opt_name, group=None): self.opt_name = opt_name self.group = group def __str__(self): if self.group is None: return ""no such option: %s"" % self.opt_name else: return ""no such option in group %s: %s"" % (self.group.name, self.opt_name) class NoSuchGroupError(Error): """"""Raised if a group which doesn't exist is referenced."""""" def __init__(self, group_name): self.group_name = group_name def __str__(self): return ""no such group: %s"" % self.group_name class DuplicateOptError(Error): """"""Raised if multiple opts with the same name are registered."""""" def __init__(self, opt_name): self.opt_name = opt_name def __str__(self): return ""duplicate option: %s"" % self.opt_name class RequiredOptError(Error): """"""Raised if an option is required but no value is supplied by the user."""""" def __init__(self, opt_name, group=None): self.opt_name = opt_name self.group = group def __str__(self): if self.group is None: return ""value required for option: %s"" % self.opt_name else: return ""value required for option: %s.%s"" % (self.group.name, self.opt_name) class TemplateSubstitutionError(Error): """"""Raised if an error occurs substituting a variable in an opt value."""""" def __str__(self): return ""template substitution error: %s"" % self.msg class ConfigFilesNotFoundError(Error): """"""Raised if one or more config files are not found."""""" def __init__(self, config_files): self.config_files = config_files def __str__(self): return ('Failed to read some config files: %s' % string.join(self.config_files, ',')) class ConfigFileParseError(Error): """"""Raised if there is an error parsing a config file."""""" def __init__(self, config_file, msg): self.config_file = config_file self.msg = msg def __str__(self): return 'Failed to parse %s: %s' % (self.config_file, self.msg) class ConfigFileValueError(Error): """"""Raised if a config file value does not match its opt type."""""" pass def _fixpath(p): """"""Apply tilde expansion and absolutization to a path."""""" return os.path.abspath(os.path.expanduser(p)) def _get_config_dirs(project=None): """"""Return a list of directors where config files may be located. :param project: an optional project name If a project is specified, following directories are returned:: ~/.${project}/ ~/ /etc/${project}/ /etc/ Otherwise, these directories:: ~/ /etc/ """""" cfg_dirs = [ _fixpath(os.path.join('~', '.' + project)) if project else None, _fixpath('~'), os.path.join('/etc', project) if project else None, '/etc' ] return filter(bool, cfg_dirs) def _search_dirs(dirs, basename, extension=""""): """"""Search a list of directories for a given filename. Iterator over the supplied directories, returning the first file found with the supplied name and extension. :param dirs: a list of directories :param basename: the filename, e.g. 'glance-api' :param extension: the file extension, e.g. '.conf' :returns: the path to a matching file, or None """""" for d in dirs: path = os.path.join(d, '%s%s' % (basename, extension)) if os.path.exists(path): return path def find_config_files(project=None, prog=None, extension='.conf'): """"""Return a list of default configuration files. :param project: an optional project name :param prog: the program name, defaulting to the basename of sys.argv[0] :param extension: the type of the config file We default to two config files: [${project}.conf, ${prog}.conf] And we look for those config files in the following directories:: ~/.${project}/ ~/ /etc/${project}/ /etc/ We return an absolute path for (at most) one of each the default config files, for the topmost directory it exists in. For example, if project=foo, prog=bar and /etc/foo/foo.conf, /etc/bar.conf and ~/.foo/bar.conf all exist, then we return ['/etc/foo/foo.conf', '~/.foo/bar.conf'] If no project name is supplied, we only look for ${prog.conf}. """""" if prog is None: prog = os.path.basename(sys.argv[0]) cfg_dirs = _get_config_dirs(project) config_files = [] if project: config_files.append(_search_dirs(cfg_dirs, project, extension)) config_files.append(_search_dirs(cfg_dirs, prog, extension)) return filter(bool, config_files) def _is_opt_registered(opts, opt): """"""Check whether an opt with the same name is already registered. The same opt may be registered multiple times, with only the first registration having any effect. However, it is an error to attempt to register a different opt with the same name. :param opts: the set of opts already registered :param opt: the opt to be registered :returns: True if the opt was previously registered, False otherwise :raises: DuplicateOptError if a naming conflict is detected """""" if opt.dest in opts: if opts[opt.dest]['opt'] != opt: raise DuplicateOptError(opt.name) return True else: return False def set_defaults(opts, **kwargs): for opt in opts: if opt.dest in kwargs: opt.default = kwargs[opt.dest] break class Opt(object): """"""Base class for all configuration options. An Opt object has no public methods, but has a number of public string properties: name: the name of the option, which may include hyphens dest: the (hyphen-less) ConfigOpts property which contains the option value short: a single character CLI option name default: the default value of the option positional: True if the option is a positional CLI argument metavar: the name shown as the argument to a CLI option in --help output help: an string explaining how the options value is used """""" multi = False def __init__(self, name, dest=None, short=None, default=None, positional=False, metavar=None, help=None, secret=False, required=False, deprecated_name=None): """"""Construct an Opt object. The only required parameter is the option's name. However, it is common to also supply a default and help string for all options. :param name: the option's name :param dest: the name of the corresponding ConfigOpts property :param short: a single character CLI option name :param default: the default value of the option :param positional: True if the option is a positional CLI argument :param metavar: the option argument to show in --help :param help: an explanation of how the option is used :param secret: true iff the value should be obfuscated in log output :param required: true iff a value must be supplied for this option :param deprecated_name: deprecated name option. Acts like an alias """""" self.name = name if dest is None: self.dest = self.name.replace('-', '_') else: self.dest = dest self.short = short self.default = default self.positional = positional self.metavar = metavar self.help = help self.secret = secret self.required = required if deprecated_name is not None: self.deprecated_name = deprecated_name.replace('-', '_') else: self.deprecated_name = None def __ne__(self, another): return vars(self) != vars(another) def _get_from_config_parser(self, cparser, section): """"""Retrieves the option value from a MultiConfigParser object. This is the method ConfigOpts uses to look up the option value from config files. Most opt types override this method in order to perform type appropriate conversion of the returned value. :param cparser: a ConfigParser object :param section: a section name """""" return self._cparser_get_with_deprecated(cparser, section) def _cparser_get_with_deprecated(self, cparser, section): """"""If cannot find option as dest try deprecated_name alias."""""" if self.deprecated_name is not None: return cparser.get(section, [self.dest, self.deprecated_name]) return cparser.get(section, [self.dest]) def _add_to_cli(self, parser, group=None): """"""Makes the option available in the command line interface. This is the method ConfigOpts uses to add the opt to the CLI interface as appropriate for the opt type. Some opt types may extend this method, others may just extend the helper methods it uses. :param parser: the CLI option parser :param group: an optional OptGroup object """""" container = self._get_argparse_container(parser, group) kwargs = self._get_argparse_kwargs(group) prefix = self._get_argparse_prefix('', group) self._add_to_argparse(container, self.name, self.short, kwargs, prefix, self.positional, self.deprecated_name) def _add_to_argparse(self, container, name, short, kwargs, prefix='', positional=False, deprecated_name=None): """"""Add an option to an argparse parser or group. :param container: an argparse._ArgumentGroup object :param name: the opt name :param short: the short opt name :param kwargs: the keyword arguments for add_argument() :param prefix: an optional prefix to prepend to the opt name :param position: whether the optional is a positional CLI argument :raises: DuplicateOptError if a naming confict is detected """""" def hyphen(arg): return arg if not positional else '' args = [hyphen('--') + prefix + name] if short: args.append(hyphen('-') + short) if deprecated_name: args.append(hyphen('--') + prefix + deprecated_name) try: container.add_argument(*args, **kwargs) except argparse.ArgumentError as e: raise DuplicateOptError(e) def _get_argparse_container(self, parser, group): """"""Returns an argparse._ArgumentGroup. :param parser: an argparse.ArgumentParser :param group: an (optional) OptGroup object :returns: an argparse._ArgumentGroup if group is given, else parser """""" if group is not None: return group._get_argparse_group(parser) else: return parser def _get_argparse_kwargs(self, group, **kwargs): """"""Build a dict of keyword arguments for argparse's add_argument(). Most opt types extend this method to customize the behaviour of the options added to argparse. :param group: an optional group :param kwargs: optional keyword arguments to add to :returns: a dict of keyword arguments """""" if not self.positional: dest = self.dest if group is not None: dest = group.name + '_' + dest kwargs['dest'] = dest else: kwargs['nargs'] = '?' kwargs.update({'default': None, 'metavar': self.metavar, 'help': self.help, }) return kwargs def _get_argparse_prefix(self, prefix, group): """"""Build a prefix for the CLI option name, if required. CLI options in a group are prefixed with the group's name in order to avoid conflicts between similarly named options in different groups. :param prefix: an existing prefix to append to (e.g. 'no' or '') :param group: an optional OptGroup object :returns: a CLI option prefix including the group name, if appropriate """""" if group is not None: return group.name + '-' + prefix else: return prefix class StrOpt(Opt): """""" String opts do not have their values transformed and are returned as str objects. """""" pass class BoolOpt(Opt): """""" Bool opts are set to True or False on the command line using --optname or --noopttname respectively. In config files, boolean values are case insensitive and can be set using 1/0, yes/no, true/false or on/off. """""" _boolean_states = {'1': True, 'yes': True, 'true': True, 'on': True, '0': False, 'no': False, 'false': False, 'off': False} def __init__(self, *args, **kwargs): if 'positional' in kwargs: raise ValueError('positional boolean args not supported') super(BoolOpt, self).__init__(*args, **kwargs) def _get_from_config_parser(self, cparser, section): """"""Retrieve the opt value as a boolean from ConfigParser."""""" def convert_bool(v): value = self._boolean_states.get(v.lower()) if value is None: raise ValueError('Unexpected boolean value %r' % v) return value return [convert_bool(v) for v in self._cparser_get_with_deprecated(cparser, section)] def _add_to_cli(self, parser, group=None): """"""Extends the base class method to add the --nooptname option."""""" super(BoolOpt, self)._add_to_cli(parser, group) self._add_inverse_to_argparse(parser, group) def _add_inverse_to_argparse(self, parser, group): """"""Add the --nooptname option to the option parser."""""" container = self._get_argparse_container(parser, group) kwargs = self._get_argparse_kwargs(group, action='store_false') prefix = self._get_argparse_prefix('no', group) kwargs[""help""] = ""The inverse of --"" + self.name self._add_to_argparse(container, self.name, None, kwargs, prefix, self.positional, self.deprecated_name) def _get_argparse_kwargs(self, group, action='store_true', **kwargs): """"""Extends the base argparse keyword dict for boolean options."""""" kwargs = super(BoolOpt, self)._get_argparse_kwargs(group, **kwargs) # metavar has no effect for BoolOpt if 'metavar' in kwargs: del kwargs['metavar'] if action != 'store_true': action = 'store_false' kwargs['action'] = action return kwargs class IntOpt(Opt): """"""Int opt values are converted to integers using the int() builtin."""""" def _get_from_config_parser(self, cparser, section): """"""Retrieve the opt value as a integer from ConfigParser."""""" return [int(v) for v in self._cparser_get_with_deprecated(cparser, section)] def _get_argparse_kwargs(self, group, **kwargs): """"""Extends the base argparse keyword dict for integer options."""""" return super(IntOpt, self)._get_argparse_kwargs(group, type=int, **kwargs) class FloatOpt(Opt): """"""Float opt values are converted to floats using the float() builtin."""""" def _get_from_config_parser(self, cparser, section): """"""Retrieve the opt value as a float from ConfigParser."""""" return [float(v) for v in self._cparser_get_with_deprecated(cparser, section)] def _get_argparse_kwargs(self, group, **kwargs): """"""Extends the base argparse keyword dict for float options."""""" return super(FloatOpt, self)._get_argparse_kwargs(group, type=float, **kwargs) class ListOpt(Opt): """""" List opt values are simple string values separated by commas. The opt value is a list containing these strings. """""" class _StoreListAction(argparse.Action): """""" An argparse action for parsing an option value into a list. """""" def __call__(self, parser, namespace, values, option_string=None): if values is not None: values = [a.strip() for a in values.split(',')] setattr(namespace, self.dest, values) def _get_from_config_parser(self, cparser, section): """"""Retrieve the opt value as a list from ConfigParser."""""" return [[a.strip() for a in v.split(',')] for v in self._cparser_get_with_deprecated(cparser, section)] def _get_argparse_kwargs(self, group, **kwargs): """"""Extends the base argparse keyword dict for list options."""""" return Opt._get_argparse_kwargs(self, group, action=ListOpt._StoreListAction, **kwargs) class MultiStrOpt(Opt): """""" Multistr opt values are string opts which may be specified multiple times. The opt value is a list containing all the string values specified. """""" multi = True def _get_argparse_kwargs(self, group, **kwargs): """"""Extends the base argparse keyword dict for multi str options."""""" kwargs = super(MultiStrOpt, self)._get_argparse_kwargs(group) if not self.positional: kwargs['action'] = 'append' else: kwargs['nargs'] = '*' return kwargs def _cparser_get_with_deprecated(self, cparser, section): """"""If cannot find option as dest try deprecated_name alias."""""" if self.deprecated_name is not None: return cparser.get(section, [self.dest, self.deprecated_name], multi=True) return cparser.get(section, [self.dest], multi=True) class SubCommandOpt(Opt): """""" Sub-command options allow argparse sub-parsers to be used to parse additional command line arguments. The handler argument to the SubCommandOpt contructor is a callable which is supplied an argparse subparsers object. Use this handler callable to add sub-parsers. The opt value is SubCommandAttr object with the name of the chosen sub-parser stored in the 'name' attribute and the values of other sub-parser arguments available as additional attributes. """""" def __init__(self, name, dest=None, handler=None, title=None, description=None, help=None): """"""Construct an sub-command parsing option. This behaves similarly to other Opt sub-classes but adds a 'handler' argument. The handler is a callable which is supplied an subparsers object when invoked. The add_parser() method on this subparsers object can be used to register parsers for sub-commands. :param name: the option's name :param dest: the name of the corresponding ConfigOpts property :param title: title of the sub-commands group in help output :param description: description of the group in help output :param help: a help string giving an overview of available sub-commands """""" super(SubCommandOpt, self).__init__(name, dest=dest, help=help) self.handler = handler self.title = title self.description = description def _add_to_cli(self, parser, group=None): """"""Add argparse sub-parsers and invoke the handler method."""""" dest = self.dest if group is not None: dest = group.name + '_' + dest subparsers = parser.add_subparsers(dest=dest, title=self.title, description=self.description, help=self.help) if self.handler is not None: self.handler(subparsers) class OptGroup(object): """""" Represents a group of opts. CLI opts in the group are automatically prefixed with the group name. Each group corresponds to a section in config files. An OptGroup object has no public methods, but has a number of public string properties: name: the name of the group title: the group title as displayed in --help help: the group description as displayed in --help """""" def __init__(self, name, title=None, help=None): """"""Constructs an OptGroup object. :param name: the group name :param title: the group title for --help :param help: the group description for --help """""" self.name = name if title is None: self.title = ""%s options"" % title else: self.title = title self.help = help self._opts = {} # dict of dicts of (opt:, override:, default:) self._argparse_group = None def _register_opt(self, opt, cli=False): """"""Add an opt to this group. :param opt: an Opt object :param cli: whether this is a CLI option :returns: False if previously registered, True otherwise :raises: DuplicateOptError if a naming conflict is detected """""" if _is_opt_registered(self._opts, opt): return False self._opts[opt.dest] = {'opt': opt, 'cli': cli} return True def _unregister_opt(self, opt): """"""Remove an opt from this group. :param opt: an Opt object """""" if opt.dest in self._opts: del self._opts[opt.dest] def _get_argparse_group(self, parser): if self._argparse_group is None: """"""Build an argparse._ArgumentGroup for this group."""""" self._argparse_group = parser.add_argument_group(self.title, self.help) return self._argparse_group def _clear(self): """"""Clear this group's option parsing state."""""" self._argparse_group = None class ParseError(iniparser.ParseError): def __init__(self, msg, lineno, line, filename): super(ParseError, self).__init__(msg, lineno, line) self.filename = filename def __str__(self): return 'at %s:%d, %s: %r' % (self.filename, self.lineno, self.msg, self.line) class ConfigParser(iniparser.BaseParser): def __init__(self, filename, sections): super(ConfigParser, self).__init__() self.filename = filename self.sections = sections self.section = None def parse(self): with open(self.filename) as f: return super(ConfigParser, self).parse(f) def new_section(self, section): self.section = section self.sections.setdefault(self.section, {}) def assignment(self, key, value): if not self.section: raise self.error_no_section() self.sections[self.section].setdefault(key, []) self.sections[self.section][key].append('\n'.join(value)) def parse_exc(self, msg, lineno, line=None): return ParseError(msg, lineno, line, self.filename) def error_no_section(self): return self.parse_exc('Section must be started before assignment', self.lineno) class MultiConfigParser(object): def __init__(self): self.parsed = [] def read(self, config_files): read_ok = [] for filename in config_files: sections = {} parser = ConfigParser(filename, sections) try: parser.parse() except IOError: continue self.parsed.insert(0, sections) read_ok.append(filename) return read_ok def get(self, section, names, multi=False): rvalue = [] for sections in self.parsed: if section not in sections: continue for name in names: if name in sections[section]: if multi: rvalue = sections[section][name] + rvalue else: return sections[section][name] if multi and rvalue != []: return rvalue raise KeyError class ConfigOpts(collections.Mapping): """""" Config options which may be set on the command line or in config files. ConfigOpts is a configuration option manager with APIs for registering option schemas, grouping options, parsing option values and retrieving the values of options. """""" def __init__(self): """"""Construct a ConfigOpts object."""""" self._opts = {} # dict of dicts of (opt:, override:, default:) self._groups = {} self._args = None self._oparser = None self._cparser = None self._cli_values = {} self.__cache = {} self._config_opts = [] def _pre_setup(self, project, prog, version, usage, default_config_files): """"""Initialize a ConfigCliParser object for option parsing."""""" if prog is None: prog = os.path.basename(sys.argv[0]) if default_config_files is None: default_config_files = find_config_files(project, prog) self._oparser = argparse.ArgumentParser(prog=prog, usage=usage) self._oparser.add_argument('--version', action='version', version=version) return prog, default_config_files def _setup(self, project, prog, version, usage, default_config_files): """"""Initialize a ConfigOpts object for option parsing."""""" self._config_opts = [ MultiStrOpt('config-file', default=default_config_files, metavar='PATH', help='Path to a config file to use. Multiple config ' 'files can be specified, with values in later ' 'files taking precedence. The default files ' ' used are: %s' % (default_config_files, )), StrOpt('config-dir', metavar='DIR', help='Path to a config directory to pull *.conf ' 'files from. This file set is sorted, so as to ' 'provide a predictable parse order if individual ' 'options are over-ridden. The set is parsed after ' 'the file(s), if any, specified via --config-file, ' 'hence over-ridden options in the directory take ' 'precedence.'), ] self.register_cli_opts(self._config_opts) self.project = project self.prog = prog self.version = version self.usage = usage self.default_config_files = default_config_files def __clear_cache(f): @functools.wraps(f) def __inner(self, *args, **kwargs): if kwargs.pop('clear_cache', True): self.__cache.clear() return f(self, *args, **kwargs) return __inner def __call__(self, args=None, project=None, prog=None, version=None, usage=None, default_config_files=None): """"""Parse command line arguments and config files. Calling a ConfigOpts object causes the supplied command line arguments and config files to be parsed, causing opt values to be made available as attributes of the object. The object may be called multiple times, each time causing the previous set of values to be overwritten. Automatically registers the --config-file option with either a supplied list of default config files, or a list from find_config_files(). If the --config-dir option is set, any *.conf files from this directory are pulled in, after all the file(s) specified by the --config-file option. :param args: command line arguments (defaults to sys.argv[1:]) :param project: the toplevel project name, used to locate config files :param prog: the name of the program (defaults to sys.argv[0] basename) :param version: the program version (for --version) :param usage: a usage string (%prog will be expanded) :param default_config_files: config files to use by default :returns: the list of arguments left over after parsing options :raises: SystemExit, ConfigFilesNotFoundError, ConfigFileParseError, RequiredOptError, DuplicateOptError """""" self.clear() prog, default_config_files = self._pre_setup(project, prog, version, usage, default_config_files) self._setup(project, prog, version, usage, default_config_files) self._cli_values = self._parse_cli_opts(args) self._parse_config_files() self._check_required_opts() def __getattr__(self, name): """"""Look up an option value and perform string substitution. :param name: the opt name (or 'dest', more precisely) :returns: the option value (after string subsititution) or a GroupAttr :raises: NoSuchOptError,ConfigFileValueError,TemplateSubstitutionError """""" return self._get(name) def __getitem__(self, key): """"""Look up an option value and perform string substitution."""""" return self.__getattr__(key) def __contains__(self, key): """"""Return True if key is the name of a registered opt or group."""""" return key in self._opts or key in self._groups def __iter__(self): """"""Iterate over all registered opt and group names."""""" for key in self._opts.keys() + self._groups.keys(): yield key def __len__(self): """"""Return the number of options and option groups."""""" return len(self._opts) + len(self._groups) def reset(self): """"""Clear the object state and unset overrides and defaults."""""" self._unset_defaults_and_overrides() self.clear() @__clear_cache def clear(self): """"""Clear the state of the object to before it was called. Any subparsers added using the add_cli_subparsers() will also be removed as a side-effect of this method. """""" self._args = None self._cli_values.clear() self._oparser = argparse.ArgumentParser() self._cparser = None self.unregister_opts(self._config_opts) for group in self._groups.values(): group._clear() @__clear_cache def register_opt(self, opt, group=None, cli=False): """"""Register an option schema. Registering an option schema makes any option value which is previously or subsequently parsed from the command line or config files available as an attribute of this object. :param opt: an instance of an Opt sub-class :param cli: whether this is a CLI option :param group: an optional OptGroup object or group name :return: False if the opt was already register, True otherwise :raises: DuplicateOptError """""" if group is not None: group = self._get_group(group, autocreate=True) return group._register_opt(opt, cli) if _is_opt_registered(self._opts, opt): return False self._opts[opt.dest] = {'opt': opt, 'cli': cli} return True @__clear_cache def register_opts(self, opts, group=None): """"""Register multiple option schemas at once."""""" for opt in opts: self.register_opt(opt, group, clear_cache=False) @__clear_cache def register_cli_opt(self, opt, group=None): """"""Register a CLI option schema. CLI option schemas must be registered before the command line and config files are parsed. This is to ensure that all CLI options are show in --help and option validation works as expected. :param opt: an instance of an Opt sub-class :param group: an optional OptGroup object or group name :return: False if the opt was already register, True otherwise :raises: DuplicateOptError, ArgsAlreadyParsedError """""" if self._args is not None: raise ArgsAlreadyParsedError(""cannot register CLI option"") return self.register_opt(opt, group, cli=True, clear_cache=False) @__clear_cache def register_cli_opts(self, opts, group=None): """"""Register multiple CLI option schemas at once."""""" for opt in opts: self.register_cli_opt(opt, group, clear_cache=False) def register_group(self, group): """"""Register an option group. An option group must be registered before options can be registered with the group. :param group: an OptGroup object """""" if group.name in self._groups: return self._groups[group.name] = copy.copy(group) @__clear_cache def unregister_opt(self, opt, group=None): """"""Unregister an option. :param opt: an Opt object :param group: an optional OptGroup object or group name :raises: ArgsAlreadyParsedError, NoSuchGroupError """""" if self._args is not None: raise ArgsAlreadyParsedError(""reset before unregistering options"") if group is not None: self._get_group(group)._unregister_opt(opt) elif opt.dest in self._opts: del self._opts[opt.dest] @__clear_cache def unregister_opts(self, opts, group=None): """"""Unregister multiple CLI option schemas at once."""""" for opt in opts: self.unregister_opt(opt, group, clear_cache=False) def import_opt(self, name, module_str, group=None): """"""Import an option definition from a module. Import a module and check that a given option is registered. This is intended for use with global configuration objects like cfg.CONF where modules commonly register options with CONF at module load time. If one module requires an option defined by another module it can use this method to explicitly declare the dependency. :param name: the name/dest of the opt :param module_str: the name of a module to import :param group: an option OptGroup object or group name :raises: NoSuchOptError, NoSuchGroupError """""" __import__(module_str) self._get_opt_info(name, group) @__clear_cache def set_override(self, name, override, group=None): """"""Override an opt value. Override the command line, config file and default values of a given option. :param name: the name/dest of the opt :param override: the override value :param group: an option OptGroup object or group name :raises: NoSuchOptError, NoSuchGroupError """""" opt_info = self._get_opt_info(name, group) opt_info['override'] = override @__clear_cache def set_default(self, name, default, group=None): """"""Override an opt's default value. Override the default value of given option. A command line or config file value will still take precedence over this default. :param name: the name/dest of the opt :param default: the default value :param group: an option OptGroup object or group name :raises: NoSuchOptError, NoSuchGroupError """""" opt_info = self._get_opt_info(name, group) opt_info['default'] = default @__clear_cache def clear_override(self, name, group=None): """"""Clear an override an opt value. Clear a previously set override of the command line, config file and default values of a given option. :param name: the name/dest of the opt :param group: an option OptGroup object or group name :raises: NoSuchOptError, NoSuchGroupError """""" opt_info = self._get_opt_info(name, group) opt_info.pop('override', None) @__clear_cache def clear_default(self, name, group=None): """"""Clear an override an opt's default value. Clear a previously set override of the default value of given option. :param name: the name/dest of the opt :param group: an option OptGroup object or group name :raises: NoSuchOptError, NoSuchGroupError """""" opt_info = self._get_opt_info(name, group) opt_info.pop('default', None) def _all_opt_infos(self): """"""A generator function for iteration opt infos."""""" for info in self._opts.values(): yield info, None for group in self._groups.values(): for info in group._opts.values(): yield info, group def _all_cli_opts(self): """"""A generator function for iterating CLI opts."""""" for info, group in self._all_opt_infos(): if info['cli']: yield info['opt'], group def _unset_defaults_and_overrides(self): """"""Unset any default or override on all options."""""" for info, group in self._all_opt_infos(): info.pop('default', None) info.pop('override', None) def find_file(self, name): """"""Locate a file located alongside the config files. Search for a file with the supplied basename in the directories which we have already loaded config files from and other known configuration directories. The directory, if any, supplied by the config_dir option is searched first. Then the config_file option is iterated over and each of the base directories of the config_files values are searched. Failing both of these, the standard directories searched by the module level find_config_files() function is used. The first matching file is returned. :param basename: the filename, e.g. 'policy.json' :returns: the path to a matching file, or None """""" dirs = [] if self.config_dir: dirs.append(_fixpath(self.config_dir)) for cf in reversed(self.config_file): dirs.append(os.path.dirname(_fixpath(cf))) dirs.extend(_get_config_dirs(self.project)) return _search_dirs(dirs, name) def log_opt_values(self, logger, lvl): """"""Log the value of all registered opts. It's often useful for an app to log its configuration to a log file at startup for debugging. This method dumps to the entire config state to the supplied logger at a given log level. :param logger: a logging.Logger object :param lvl: the log level (e.g. logging.DEBUG) arg to logger.log() """""" logger.log(lvl, ""*"" * 80) logger.log(lvl, ""Configuration options gathered from:"") logger.log(lvl, ""command line args: %s"", self._args) logger.log(lvl, ""config files: %s"", self.config_file) logger.log(lvl, ""="" * 80) def _sanitize(opt, value): """"""Obfuscate values of options declared secret"""""" return value if not opt.secret else '*' * len(str(value)) for opt_name in sorted(self._opts): opt = self._get_opt_info(opt_name)['opt'] logger.log(lvl, ""%-30s = %s"", opt_name, _sanitize(opt, getattr(self, opt_name))) for group_name in self._groups: group_attr = self.GroupAttr(self, self._get_group(group_name)) for opt_name in sorted(self._groups[group_name]._opts): opt = self._get_opt_info(opt_name, group_name)['opt'] logger.log(lvl, ""%-30s = %s"", ""%s.%s"" % (group_name, opt_name), _sanitize(opt, getattr(group_attr, opt_name))) logger.log(lvl, ""*"" * 80) def print_usage(self, file=None): """"""Print the usage message for the current program."""""" self._oparser.print_usage(file) def print_help(self, file=None): """"""Print the help message for the current program."""""" self._oparser.print_help(file) def _get(self, name, group=None): if isinstance(group, OptGroup): key = (group.name, name) else: key = (group, name) try: return self.__cache[key] except KeyError: value = self._substitute(self._do_get(name, group)) self.__cache[key] = value return value def _do_get(self, name, group=None): """"""Look up an option value. :param name: the opt name (or 'dest', more precisely) :param group: an OptGroup :returns: the option value, or a GroupAttr object :raises: NoSuchOptError, NoSuchGroupError, ConfigFileValueError, TemplateSubstitutionError """""" if group is None and name in self._groups: return self.GroupAttr(self, self._get_group(name)) info = self._get_opt_info(name, group) opt = info['opt'] if isinstance(opt, SubCommandOpt): return self.SubCommandAttr(self, group, opt.dest) if 'override' in info: return info['override'] values = [] if self._cparser is not None: section = group.name if group is not None else 'DEFAULT' try: value = opt._get_from_config_parser(self._cparser, section) except KeyError: pass except ValueError as ve: raise ConfigFileValueError(str(ve)) else: if not opt.multi: # No need to continue since the last value wins return value[-1] values.extend(value) name = name if group is None else group.name + '_' + name value = self._cli_values.get(name) if value is not None: if not opt.multi: return value # argparse ignores default=None for nargs='*' if opt.positional and not value: value = opt.default return value + values if values: return values if 'default' in info: return info['default'] return opt.default def _substitute(self, value): """"""Perform string template substitution. Substitute any template variables (e.g. $foo, ${bar}) in the supplied string value(s) with opt values. :param value: the string value, or list of string values :returns: the substituted string(s) """""" if isinstance(value, list): return [self._substitute(i) for i in value] elif isinstance(value, str): tmpl = string.Template(value) return tmpl.safe_substitute(self.StrSubWrapper(self)) else: return value def _get_group(self, group_or_name, autocreate=False): """"""Looks up a OptGroup object. Helper function to return an OptGroup given a parameter which can either be the group's name or an OptGroup object. The OptGroup object returned is from the internal dict of OptGroup objects, which will be a copy of any OptGroup object that users of the API have access to. :param group_or_name: the group's name or the OptGroup object itself :param autocreate: whether to auto-create the group if it's not found :raises: NoSuchGroupError """""" group = group_or_name if isinstance(group_or_name, OptGroup) else None group_name = group.name if group else group_or_name if group_name not in self._groups: if group is not None or not autocreate: raise NoSuchGroupError(group_name) self.register_group(OptGroup(name=group_name)) return self._groups[group_name] def _get_opt_info(self, opt_name, group=None): """"""Return the (opt, override, default) dict for an opt. :param opt_name: an opt name/dest :param group: an optional group name or OptGroup object :raises: NoSuchOptError, NoSuchGroupError """""" if group is None: opts = self._opts else: group = self._get_group(group) opts = group._opts if opt_name not in opts: raise NoSuchOptError(opt_name, group) return opts[opt_name] def _parse_config_files(self): """"""Parse the config files from --config-file and --config-dir. :raises: ConfigFilesNotFoundError, ConfigFileParseError """""" config_files = list(self.config_file) if self.config_dir: config_dir_glob = os.path.join(self.config_dir, '*.conf') config_files += sorted(glob.glob(config_dir_glob)) config_files = [_fixpath(p) for p in config_files] self._cparser = MultiConfigParser() try: read_ok = self._cparser.read(config_files) except iniparser.ParseError as pe: raise ConfigFileParseError(pe.filename, str(pe)) if read_ok != config_files: not_read_ok = filter(lambda f: f not in read_ok, config_files) raise ConfigFilesNotFoundError(not_read_ok) def _check_required_opts(self): """"""Check that all opts marked as required have values specified. :raises: RequiredOptError """""" for info, group in self._all_opt_infos(): opt = info['opt'] if opt.required: if 'default' in info or 'override' in info: continue if self._get(opt.dest, group) is None: raise RequiredOptError(opt.name, group) def _parse_cli_opts(self, args): """"""Parse command line options. Initializes the command line option parser and parses the supplied command line arguments. :param args: the command line arguments :returns: a dict of parsed option values :raises: SystemExit, DuplicateOptError """""" self._args = args for opt, group in self._all_cli_opts(): opt._add_to_cli(self._oparser, group) return vars(self._oparser.parse_args(args)) class GroupAttr(collections.Mapping): """""" A helper class representing the option values of a group as a mapping and attributes. """""" def __init__(self, conf, group): """"""Construct a GroupAttr object. :param conf: a ConfigOpts object :param group: an OptGroup object """""" self._conf = conf self._group = group def __getattr__(self, name): """"""Look up an option value and perform template substitution."""""" return self._conf._get(name, self._group) def __getitem__(self, key): """"""Look up an option value and perform string substitution."""""" return self.__getattr__(key) def __contains__(self, key): """"""Return True if key is the name of a registered opt or group."""""" return key in self._group._opts def __iter__(self): """"""Iterate over all registered opt and group names."""""" for key in self._group._opts.keys(): yield key def __len__(self): """"""Return the number of options and option groups."""""" return len(self._group._opts) class SubCommandAttr(object): """""" A helper class representing the name and arguments of an argparse sub-parser. """""" def __init__(self, conf, group, dest): """"""Construct a SubCommandAttr object. :param conf: a ConfigOpts object :param group: an OptGroup object :param dest: the name of the sub-parser """""" self._conf = conf self._group = group self._dest = dest def __getattr__(self, name): """"""Look up a sub-parser name or argument value."""""" if name == 'name': name = self._dest if self._group is not None: name = self._group.name + '_' + name return self._conf._cli_values[name] if name in self._conf: raise DuplicateOptError(name) try: return self._conf._cli_values[name] except KeyError: raise NoSuchOptError(name) class StrSubWrapper(object): """""" A helper class exposing opt values as a dict for string substitution. """""" def __init__(self, conf): """"""Construct a StrSubWrapper object. :param conf: a ConfigOpts object """""" self.conf = conf def __getitem__(self, key): """"""Look up an opt value from the ConfigOpts object. :param key: an opt name :returns: an opt value :raises: TemplateSubstitutionError if attribute is a group """""" value = getattr(self.conf, key) if isinstance(value, self.conf.GroupAttr): raise TemplateSubstitutionError( 'substituting group %s not supported' % key) return value CONF = ConfigOpts() ",12,1873
openstack%2Fnova~stable%2Fgrizzly~If617b570e082e3aa321414a2680a3aa0754f6153,openstack/nova,stable/grizzly,If617b570e082e3aa321414a2680a3aa0754f6153,Refresh volume connections when starting instances,MERGED,2013-06-26 19:05:36.000000000,2013-07-21 10:26:05.000000000,2013-07-21 10:26:02.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 1955}, {'_account_id': 3189}, {'_account_id': 5511}, {'_account_id': 6681}]","[{'number': 1, 'created': '2013-06-26 19:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da6fb9999f44ffa1f8a5c464356cd89850541fba', 'message': 'Refresh volume connections when starting instances\n\nThis patches adds network and block device information to the signature\nof the power_on method on the virtualization driver. The relevant call\nsites are also modified to provide the required information. The libvirt\nimplementation of power_on has been altered to re-establish network and\nvolume related connections.\n\nFixes bug: 1188326\n\n(cherry picked from commit db3989586a8d5bbbcf857b9294a124ecc5fc57e8)\n\nConflicts:\n\tnova/tests/test_vmwareapi.py\n\tnova/virt/baremetal/driver.py\n\tnova/virt/libvirt/driver.py\n\tnova/virt/vmwareapi/driver.py\n\tnova/virt/vmwareapi/vmops.py\n\n(Includes some collateral additions for console tests in the vmware\n tests.)\n\nChange-Id: If617b570e082e3aa321414a2680a3aa0754f6153\n'}, {'number': 2, 'created': '2013-06-26 19:56:54.000000000', 'files': ['nova/virt/fake.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/virt/driver.py', 'nova/tests/compute/test_compute.py', 'nova/virt/powervm/driver.py', 'nova/tests/test_hypervapi.py', 'nova/virt/hyperv/driver.py', 'nova/virt/vmwareapi/vmops.py', 'nova/virt/libvirt/driver.py', 'nova/virt/xenapi/driver.py', 'nova/tests/test_vmwareapi.py', 'nova/virt/vmwareapi/driver.py', 'nova/compute/manager.py', 'nova/tests/test_virt_drivers.py', 'nova/virt/baremetal/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ce789f7f62ad932fb3833ec6c69bfb3fdaadcbc6', 'message': 'Refresh volume connections when starting instances\n\nThis patches adds network and block device information to the signature\nof the power_on method on the virtualization driver. The relevant call\nsites are also modified to provide the required information. The libvirt\nimplementation of power_on has been altered to re-establish network and\nvolume related connections.\n\nFixes bug: 1188326\n\n(cherry picked from commit db3989586a8d5bbbcf857b9294a124ecc5fc57e8)\n\nConflicts:\n\tnova/tests/test_vmwareapi.py\n\tnova/virt/baremetal/driver.py\n\tnova/virt/libvirt/driver.py\n\tnova/virt/vmwareapi/driver.py\n\tnova/virt/vmwareapi/vmops.py\n\n(Includes some collateral additions for console tests in the vmware\n tests.)\n\nChange-Id: If617b570e082e3aa321414a2680a3aa0754f6153\n'}]",5,34597,ce789f7f62ad932fb3833ec6c69bfb3fdaadcbc6,19,9,2,6681,,,0,"Refresh volume connections when starting instances

This patches adds network and block device information to the signature
of the power_on method on the virtualization driver. The relevant call
sites are also modified to provide the required information. The libvirt
implementation of power_on has been altered to re-establish network and
volume related connections.

Fixes bug: 1188326

(cherry picked from commit db3989586a8d5bbbcf857b9294a124ecc5fc57e8)

Conflicts:
	nova/tests/test_vmwareapi.py
	nova/virt/baremetal/driver.py
	nova/virt/libvirt/driver.py
	nova/virt/vmwareapi/driver.py
	nova/virt/vmwareapi/vmops.py

(Includes some collateral additions for console tests in the vmware
 tests.)

Change-Id: If617b570e082e3aa321414a2680a3aa0754f6153
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/34597/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/fake.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/virt/driver.py', 'nova/tests/compute/test_compute.py', 'nova/virt/powervm/driver.py', 'nova/tests/test_hypervapi.py', 'nova/virt/hyperv/driver.py', 'nova/virt/vmwareapi/vmops.py', 'nova/virt/libvirt/driver.py', 'nova/virt/xenapi/driver.py', 'nova/tests/test_vmwareapi.py', 'nova/virt/vmwareapi/driver.py', 'nova/compute/manager.py', 'nova/tests/test_virt_drivers.py', 'nova/virt/baremetal/driver.py']",15,da6fb9999f44ffa1f8a5c464356cd89850541fba,bug/1188326," self.power_on(context, instance, network_info, block_device_info, node) def power_on(self, context, instance, network_info, block_device_info=None, node=None):"," self.power_on(instance, node) def power_on(self, instance, node=None):",171,39
openstack%2Fironic~master~Ie436d4b41ef9fb54b33f5a7dad77c3e46a26385a,openstack/ironic,master,Ie436d4b41ef9fb54b33f5a7dad77c3e46a26385a,Keystone authentiation.,MERGED,2013-07-15 17:32:05.000000000,2013-07-21 06:13:15.000000000,2013-07-21 06:13:15.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2889}, {'_account_id': 6623}]","[{'number': 1, 'created': '2013-07-15 17:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1a3073084a2d05253a5cb2a3c15eb684a12706df', 'message': 'WIP: Keystone authentiation.\n\nEnabled ACL and implemented a hook for configuring\nrequest context.\n\nAdded a method for determining the tenant a request\nshould be limited to.\n\nChange-Id: Ie436d4b41ef9fb54b33f5a7dad77c3e46a26385a\n'}, {'number': 2, 'created': '2013-07-19 15:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6b0da9ddf416627b19a02123a44df2e6bbad8dfc', 'message': 'WIP: Keystone authentiation.\n\nEnabled ACL and implemented a hook for configuring\nrequest context.\n\nAdded a method for determining the tenant a request\nshould be limited to.\n\nChange-Id: Ie436d4b41ef9fb54b33f5a7dad77c3e46a26385a\n'}, {'number': 3, 'created': '2013-07-19 15:27:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7477312b4c60a2140a62f446189eeebb3496ef69', 'message': 'Keystone authentiation.\n\nEnabled ACL and implemented a hook for configuring\nrequest context.\n\nImplemented a hook that rejects all non-admin requests.\n\nChange-Id: Ie436d4b41ef9fb54b33f5a7dad77c3e46a26385a\n'}, {'number': 4, 'created': '2013-07-19 22:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f04c018b2e71d70710d704aece0bcefbc6faf969', 'message': 'Keystone authentiation.\n\nEnabled ACL and implemented a hook for configuring\nrequest context.\n\nImplemented a hook that rejects all non-admin requests.\n\nChange-Id: Ie436d4b41ef9fb54b33f5a7dad77c3e46a26385a\n'}, {'number': 5, 'created': '2013-07-20 07:51:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ef45ad4774066a318c0e9a69167cf51edd9f66c4', 'message': 'Keystone authentiation.\n\nEnabled ACL and implemented a hook for configuring\nrequest context.\n\nImplemented a hook that rejects all non-admin requests.\n\nChange-Id: Ie436d4b41ef9fb54b33f5a7dad77c3e46a26385a\n'}, {'number': 6, 'created': '2013-07-20 08:13:34.000000000', 'files': ['ironic/tests/api/test_list_nodes.py', 'ironic/tests/policy.json', 'ironic/api/acl.py', 'ironic/tests/api/utils.py', 'ironic/api/hooks.py', 'ironic/tests/fake_policy.py', 'ironic/api/config.py', 'ironic/common/policy.py', 'ironic/tests/api/test_acl.py', 'etc/ironic/policy.json'], 'web_link': 'https://opendev.org/openstack/ironic/commit/71c2525d4d5da3856f1cac963aeaa6df95233935', 'message': 'Keystone authentiation.\n\nEnabled ACL and implemented a hook for configuring\nrequest context.\n\nImplemented a hook that rejects all non-admin requests.\n\nChange-Id: Ie436d4b41ef9fb54b33f5a7dad77c3e46a26385a\n'}]",18,37102,71c2525d4d5da3856f1cac963aeaa6df95233935,25,4,6,6623,,,0,"Keystone authentiation.

Enabled ACL and implemented a hook for configuring
request context.

Implemented a hook that rejects all non-admin requests.

Change-Id: Ie436d4b41ef9fb54b33f5a7dad77c3e46a26385a
",git fetch https://review.opendev.org/openstack/ironic refs/changes/02/37102/6 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/acl.py', 'ironic/api/hooks.py', 'ironic/api/config.py', 'ironic/common/policy.py', 'tools/patch_tox_venv.py', 'ironic/tests/api/test_acl.py']",6,1a3073084a2d05253a5cb2a3c15eb684a12706df,keystone_auth,"# -*- encoding: utf-8 -*- # # Copyright  2012 New Dream Network, LLC (DreamHost) # # Author: Julien Danjou <julien@danjou.info> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Test ACL."""""" import datetime from oslo.config import cfg from ironic.api import acl from ironic.tests.api import base VALID_TOKEN = '4562138218392831' VALID_TOKEN2 = '4562138218392832' class FakeMemcache(object): def __init__(self): self.set_key = None self.set_value = None self.token_expiration = None def get(self, key): if key == ""tokens/%s"" % VALID_TOKEN: dt = datetime.datetime.now() + datetime.timedelta(minutes=5) return ({'access': { 'token': {'id': VALID_TOKEN}, 'user': { 'id': 'user_id1', 'name': 'user_name1', 'tenantId': '123i2910', 'tenantName': 'mytenant', 'roles': [ {'name': 'admin'}, ]}, }}, dt.strftime(""%s"")) if key == ""tokens/%s"" % VALID_TOKEN2: dt = datetime.datetime.now() + datetime.timedelta(minutes=5) return ({'access': { 'token': {'id': VALID_TOKEN2}, 'user': { 'id': 'user_id2', 'name': 'user-good', 'tenantId': 'project-good', 'tenantName': 'goodies', 'roles': [ {'name': 'Member'}, ]}, }}, dt.strftime(""%s"")) def set(self, key, value, time=None): self.set_value = value self.set_key = key class TestAPIACL(base.FunctionalTest): def setUp(self): super(TestAPIACL, self).setUp() self.environ = {'fake.cache': FakeMemcache()} def get_json(self, path, expect_errors=False, headers=None, q=[], **param): return super(TestAPIACL, self).get_json(path, expect_errors=expect_errors, headers=headers, q=q, extra_environ=self.environ, **param) def _make_app(self): cfg.CONF.set_override(""cache"", ""fake.cache"", group=acl.OPT_GROUP_NAME) return super(TestAPIACL, self)._make_app(enable_acl=True) def test_non_authenticated(self): response = self.get_json('/nodes', expect_errors=True) self.assertEqual(response.status_int, 401) def test_authenticated_wrong_role(self): response = self.get_json('/nodes', expect_errors=True, headers={ ""X-Roles"": ""Member"", ""X-Tenant-Name"": ""admin"", ""X-Tenant-Id"": ""bc23a9d531064583ace8f67dad60f6bb"", }) self.assertEqual(response.status_int, 401) def test_authenticated(self): data = self.get_json('/nodes', headers={""X-Auth-Token"": VALID_TOKEN, ""X-Roles"": ""admin"", ""X-Tenant-Name"": ""admin"", ""X-Tenant-Id"": ""bc23a9d531064583ace8f67dad60f6bb"", }) ids = set(r['resource_id'] for r in data) self.assertEquals(set(['resource-good', 'resource-56']), ids) def test_with_non_admin_missing_project_query(self): data = self.get_json('/nodes', headers={""X-Roles"": ""Member"", ""X-Auth-Token"": VALID_TOKEN2, ""X-Tenant-Id"": ""project-good""}) ids = set(r['resource_id'] for r in data) self.assertEquals(set(['resource-good', 'resource-56']), ids) def test_with_non_admin(self): data = self.get_json('/nodes', headers={""X-Roles"": ""Member"", ""X-Auth-Token"": VALID_TOKEN2, ""X-Tenant-Id"": ""project-good""}, q=[{'field': 'project_id', 'value': 'project-good', }]) ids = set(r['resource_id'] for r in data) self.assertEquals(set(['resource-good', 'resource-56']), ids) def test_non_admin_wrong_project(self): data = self.get_json('/nodes', expect_errors=True, headers={""X-Roles"": ""Member"", ""X-Auth-Token"": VALID_TOKEN2, ""X-Tenant-Id"": ""project-good""}, q=[{'field': 'project_id', 'value': 'project-wrong', }]) self.assertEqual(data.status_int, 401) def test_non_admin_two_projects(self): data = self.get_json('/nodes', expect_errors=True, headers={""X-Roles"": ""Member"", ""X-Auth-Token"": VALID_TOKEN2, ""X-Tenant-Id"": ""project-good""}, q=[{'field': 'project_id', 'value': 'project-good', }, {'field': 'project_id', 'value': 'project-naughty', }]) self.assertEqual(data.status_int, 401) ",,182,16
openstack%2Foslo-incubator~master~I5acb0c924815caae1f96ed2fa6ee8b1f7ed93cf4,openstack/oslo-incubator,master,I5acb0c924815caae1f96ed2fa6ee8b1f7ed93cf4,Remove DnsmasqFilter and DeprecatedDnsmasqFilter,MERGED,2013-07-02 07:37:51.000000000,2013-07-21 01:33:09.000000000,2013-07-21 01:33:09.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1247}, {'_account_id': 1994}, {'_account_id': 6593}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-07-02 07:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/767f13b3f75da885b6f897e188d40d790bf7a2bf', 'message': 'Remove DnsmasqFilter and DeprecatedDnsmasqFilter\n\nEnvFilter supersedes both, so remove them as all\nusages have been converted to EnvFilter.\n\nChange-Id: I5acb0c924815caae1f96ed2fa6ee8b1f7ed93cf4\n'}, {'number': 2, 'created': '2013-07-20 06:47:38.000000000', 'files': ['openstack/common/rootwrap/filters.py', 'tests/unit/test_rootwrap.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/3b16d3144531ef6802c3ff621b4e96497df7d392', 'message': 'Remove DnsmasqFilter and DeprecatedDnsmasqFilter\n\nEnvFilter supersedes both, so remove them as all\nusages have been converted to EnvFilter.\n\nChange-Id: I5acb0c924815caae1f96ed2fa6ee8b1f7ed93cf4\n'}]",0,35253,3b16d3144531ef6802c3ff621b4e96497df7d392,17,6,2,6593,,,0,"Remove DnsmasqFilter and DeprecatedDnsmasqFilter

EnvFilter supersedes both, so remove them as all
usages have been converted to EnvFilter.

Change-Id: I5acb0c924815caae1f96ed2fa6ee8b1f7ed93cf4
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/53/35253/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/rootwrap/filters.py', 'tests/unit/test_rootwrap.py']",2,767f13b3f75da885b6f897e188d40d790bf7a2bf,remove_dnsmasq_filter,, def test_DnsmasqFilter(self): self._test_EnvFilter_as_DnsMasq('CONFIG_FILE') def test_DeprecatedDnsmasqFilter(self): self._test_EnvFilter_as_DnsMasq('FLAGFILE') ,0,36
openstack%2Foslo-incubator~master~I178684a1d8649b5bcfcb768be0a68c8efa3f00e4,openstack/oslo-incubator,master,I178684a1d8649b5bcfcb768be0a68c8efa3f00e4,Fix locking bug,MERGED,2013-07-09 22:10:16.000000000,2013-07-21 01:31:22.000000000,2013-07-21 01:31:22.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1865}, {'_account_id': 1994}, {'_account_id': 6159}, {'_account_id': 6928}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-07-09 22:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/91f0473f432387af07afa40c589fa829772a7da9', 'message': 'Fix locking bug\n\nWhen lock_path is not set, lockutils creates a new temp dir for\neach new call to synchronized.  This results in no actual lock\nenforcement.  Switch from creating a new temp dir for each lock\nto a single temp dir for this case.\n\nFixes bug 1162047\n\nChange-Id: I178684a1d8649b5bcfcb768be0a68c8efa3f00e4\n'}, {'number': 2, 'created': '2013-07-10 15:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/6f8c928a631cbf626f8738ba2a7584f3c86bcd5c', 'message': 'Fix locking bug\n\nWhen lock_path is not set, lockutils creates a new temp dir for\neach new call to synchronized.  This results in no actual lock\nenforcement.  Require setting of lock_path by throwing an\nexception if it is not found.\n\nFixes bug 1162047\n\nChange-Id: I178684a1d8649b5bcfcb768be0a68c8efa3f00e4\n'}, {'number': 3, 'created': '2013-07-17 17:22:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/c61c642729448c985ac012ddf976bf6983435820', 'message': 'Fix locking bug\n\nWhen lock_path is not set, lockutils creates a new temp dir for\neach new call to synchronized.  This results in no actual lock\nenforcement.  Require setting of lock_path by throwing an\nexception if it is not found.\n\nFixes bug 1065531\nFixes bug 1162047\n\nChange-Id: I178684a1d8649b5bcfcb768be0a68c8efa3f00e4\n'}, {'number': 4, 'created': '2013-07-17 17:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/409f901bce915c7447ea88c5bc58e0e3ad096bc8', 'message': 'Fix locking bug\n\nWhen lock_path is not set, lockutils creates a new temp dir for\neach new call to synchronized.  This results in no actual lock\nenforcement.  Require setting of lock_path by throwing an\nexception if it is not found.\n\nFixes bug 1065531\nFixes bug 1162047\n\nChange-Id: I178684a1d8649b5bcfcb768be0a68c8efa3f00e4\n'}, {'number': 5, 'created': '2013-07-18 17:17:11.000000000', 'files': ['openstack/common/lockutils.py', 'tests/unit/test_lockutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/90b6a65545dd2d41d674dd22f00bcd6dea695239', 'message': 'Fix locking bug\n\nWhen lock_path is not set, lockutils creates a new temp dir for\neach new call to synchronized.  This results in no actual lock\nenforcement.  Require setting of lock_path by throwing an\nexception if it is not found.\n\nFixes bug 1065531\nFixes bug 1162047\n\nChange-Id: I178684a1d8649b5bcfcb768be0a68c8efa3f00e4\n'}]",11,36350,90b6a65545dd2d41d674dd22f00bcd6dea695239,30,7,5,6928,,,0,"Fix locking bug

When lock_path is not set, lockutils creates a new temp dir for
each new call to synchronized.  This results in no actual lock
enforcement.  Require setting of lock_path by throwing an
exception if it is not found.

Fixes bug 1065531
Fixes bug 1162047

Change-Id: I178684a1d8649b5bcfcb768be0a68c8efa3f00e4
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/50/36350/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/lockutils.py'],1,91f0473f432387af07afa40c589fa829772a7da9,bug/1065531," local_lock_path = os.path.join( tempfile.gettempdir(), 'oslo-lock-path')", local_lock_path = tempfile.mkdtemp(),2,1
openstack%2Foslo-incubator~master~Ie61be9f0d08cd9c2485177b207216b3b775acd04,openstack/oslo-incubator,master,Ie61be9f0d08cd9c2485177b207216b3b775acd04,Fix stylistic problems with help text,MERGED,2013-07-15 21:51:24.000000000,2013-07-21 01:29:53.000000000,2013-07-21 01:29:53.000000000,"[{'_account_id': 3}, {'_account_id': 385}, {'_account_id': 679}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2750}, {'_account_id': 7708}]","[{'number': 1, 'created': '2013-07-15 21:51:24.000000000', 'files': ['openstack/common/eventlet_backdoor.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/1dcc747401419d57f923d31515545a8b24d6a6a5', 'message': 'Fix stylistic problems with help text\n\nThe help text for the backdoor_port configuration option was a little\ngroddy.  This reformats it to clean it up a little.  Some punctuation\nis also added to clarify the meaning of the text.\n\nChange-Id: Ie61be9f0d08cd9c2485177b207216b3b775acd04\n'}]",2,37142,1dcc747401419d57f923d31515545a8b24d6a6a5,11,8,1,679,,,0,"Fix stylistic problems with help text

The help text for the backdoor_port configuration option was a little
groddy.  This reformats it to clean it up a little.  Some punctuation
is also added to clarify the meaning of the text.

Change-Id: Ie61be9f0d08cd9c2485177b207216b3b775acd04
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/42/37142/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/eventlet_backdoor.py'],1,1dcc747401419d57f923d31515545a8b24d6a6a5,message-fix,"help_for_backdoor_port = ( ""Acceptable values are 0, <port>, and <start>:<end>, where 0 results "" ""in listening on a random tcp port number; <port> results in listening "" ""on the specified port number (and not enabling backdoor if that port "" ""is in use); and <start>:<end> results in listening on the smallest "" ""unused port number within the specified range of port numbers. The "" ""chosen port is displayed in the service's log file."") help=""Enable eventlet backdoor. %s"" % help_for_backdoor_port)","help_for_backdoor_port = 'Acceptable ' + \ 'values are 0, <port> and <start>:<end>, where 0 results in ' + \ 'listening on a random tcp port number, <port> results in ' + \ 'listening on the specified port number and not enabling backdoor' + \ 'if it is in use and <start>:<end> results in listening on the ' + \ 'smallest unused port number within the specified range of port ' + \ 'numbers. The chosen port is displayed in the service\'s log file.' help='Enable eventlet backdoor. %s' % help_for_backdoor_port)",8,8
openstack%2Fneutron~master~Idb25d3056791dced787695f8dea4720b8652235a,openstack/neutron,master,Idb25d3056791dced787695f8dea4720b8652235a,Imported Translations from Transifex,MERGED,2013-07-20 19:55:46.000000000,2013-07-20 21:33:29.000000000,2013-07-20 21:33:28.000000000,"[{'_account_id': 3}, {'_account_id': 2592}]","[{'number': 1, 'created': '2013-07-20 19:55:46.000000000', 'files': ['neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6cb8672eaf02d6e47158e8da4eac8bb95910e3b5', 'message': 'Imported Translations from Transifex\n\nChange-Id: Idb25d3056791dced787695f8dea4720b8652235a\n'}]",0,38046,6cb8672eaf02d6e47158e8da4eac8bb95910e3b5,5,2,1,3,,,0,"Imported Translations from Transifex

Change-Id: Idb25d3056791dced787695f8dea4720b8652235a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/46/38046/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po']",40,6cb8672eaf02d6e47158e8da4eac8bb95910e3b5,transifex/translations,"# Swahili (Kenya) translations for neutron. # Copyright (C) 2013 ORGANIZATION # This file is distributed under the same license as the neutron project. # # Translators: msgid """" msgstr """" ""Project-Id-Version: Neutron\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2013-07-20 19:55+0000\n"" ""PO-Revision-Date: 2013-01-28 21:54+0000\n"" ""Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"" ""Language-Team: Swahili (Kenya) "" ""(http://www.transifex.com/projects/p/openstack/language/sw_KE/)\n"" ""Plural-Forms: nplurals=2; plural=(n != 1)\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=utf-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 0.9.6\n"" #: quantum/auth.py:26 quantum/api/__init__.py:29 msgid """" ""You are using old configuration values for the api-paste config. Please "" ""update for Neutron."" msgstr """" #: neutron/auth.py:36 msgid ""Neither X_USER_ID nor X_USER found in request"" msgstr """" #: neutron/context.py:49 #, python-format msgid ""Arguments dropped when creating context: %s"" msgstr """" #: neutron/context.py:95 #, python-format msgid ""read_deleted can only be one of 'no', 'yes' or 'only', not %r"" msgstr """" #: neutron/manager.py:70 #, python-format msgid ""dhcp_agents_per_network must be >= 1. '%s' is invalid."" msgstr """" #: neutron/manager.py:82 msgid ""Neutron core_plugin not configured!"" msgstr """" #: neutron/manager.py:111 neutron/plugins/metaplugin/meta_neutron_plugin.py:114 #, python-format msgid ""Plugin location: %s"" msgstr """" #: neutron/manager.py:114 neutron/manager.py:163 #, python-format msgid ""Loading Plugin: %s"" msgstr """" #: neutron/manager.py:117 neutron/manager.py:166 msgid ""Error loading plugin"" msgstr """" #: neutron/manager.py:118 msgid ""Plugin not found. "" msgstr """" #: neutron/manager.py:136 msgid ""Loading services supported by the core plugin"" msgstr """" #: neutron/manager.py:145 #, python-format msgid ""Service %s is supported by the core plugin"" msgstr """" #: neutron/manager.py:158 #, python-format msgid ""Loading service plugins: %s"" msgstr """" #: neutron/manager.py:167 msgid ""Plugin not found."" msgstr """" #: neutron/manager.py:174 #, python-format msgid ""Multiple plugins for service %s were configured"" msgstr """" #: neutron/manager.py:180 #, python-format msgid ""Successfully loaded %(type)s plugin. Description: %(desc)s"" msgstr """" #: neutron/policy.py:88 #, python-format msgid ""loading policies from file: %s"" msgstr """" #: neutron/policy.py:95 #, python-format msgid """" ""Found deprecated policy rule:%s. Please consider upgrading your policy "" ""configuration file"" msgstr """" #: neutron/policy.py:107 #, python-format msgid """" ""Inserting policy:%(new_policy)s in place of deprecated "" ""policy:%(old_policy)s"" msgstr """" #: neutron/policy.py:115 #, python-format msgid """" ""Backward compatibility unavailable for deprecated policy %s. The policy "" ""will not be enforced"" msgstr """" #: neutron/policy.py:137 #, python-format msgid ""Unable to find data type descriptor for attribute %s"" msgstr """" #: neutron/policy.py:142 #, python-format msgid """" ""Attribute type descriptor is not a dict. Unable to generate any sub-attr "" ""policy rule for %s."" msgstr """" #: neutron/policy.py:216 #, python-format msgid """" ""Unable to identify a target field from:%s.match should be in the form "" ""%%(<field_name>)s"" msgstr """" #: neutron/policy.py:242 #, python-format msgid ""Unable to find ':' as separator in %s."" msgstr """" #: neutron/policy.py:246 #, python-format msgid ""Unable to find resource name in %s"" msgstr """" #: neutron/policy.py:255 #, python-format msgid """" ""Unable to verify match:%(match)s as the parent resource: %(res)s was not "" ""found"" msgstr """" #: neutron/policy.py:277 #, python-format msgid ""Policy check error while calling %s!"" msgstr """" #: neutron/policy.py:309 #, python-format msgid ""Unable to find requested field: %(field)s in target: %(target_dict)s"" msgstr """" #: neutron/quota.py:31 msgid ""Resource name(s) that are supported in quota features"" msgstr """" #: neutron/quota.py:35 msgid ""Default number of resource allowed per tenant, minus for unlimited"" msgstr """" #: neutron/quota.py:39 msgid ""Number of networks allowed per tenant,minus for unlimited"" msgstr """" #: neutron/quota.py:43 msgid ""Number of subnets allowed per tenant, minus for unlimited"" msgstr """" #: neutron/quota.py:47 msgid ""number of ports allowed per tenant, minus for unlimited"" msgstr """" #: neutron/quota.py:51 msgid ""Default driver to use for quota checks"" msgstr """" #: neutron/quota.py:225 #, python-format msgid ""%s is already registered."" msgstr """" #: neutron/service.py:38 msgid ""Seconds between running periodic tasks"" msgstr """" #: neutron/service.py:41 msgid """" ""range of seconds to randomly delay when starting the periodic task "" ""scheduler to reduce stampeding. (Disable by setting to 0)"" msgstr """" #: neutron/service.py:98 msgid ""Attempting fallback to old Quantum api-paste config"" msgstr """" #: neutron/service.py:102 msgid ""In serve_wsgi()"" msgstr """" #: neutron/service.py:111 msgid ""No known API applications configured."" msgstr """" #: neutron/service.py:117 #, python-format msgid ""Neutron service started, listening on %(host)s:%(port)s"" msgstr """" #: neutron/service.py:218 msgid ""Exception occurs when timer stops"" msgstr """" #: neutron/service.py:228 msgid ""Exception occurs when waiting for timer"" msgstr """" #: neutron/wsgi.py:46 msgid ""Number of backlog requests to configure the socket with"" msgstr """" #: neutron/wsgi.py:50 msgid """" ""Sets the value of TCP_KEEPIDLE in seconds for each server socket. Not "" ""supported on OS X."" msgstr """" #: neutron/wsgi.py:54 msgid ""Number of seconds to keep retrying to listen"" msgstr """" #: neutron/wsgi.py:57 msgid ""Enable SSL on the API server"" msgstr """" #: neutron/wsgi.py:60 msgid ""CA certificate file to use to verify connecting clients"" msgstr """" #: neutron/wsgi.py:64 msgid ""Certificate file to use when starting the server securely"" msgstr """" #: neutron/wsgi.py:68 msgid ""Private key file to use when starting the server securely"" msgstr """" #: neutron/wsgi.py:104 #, python-format msgid ""Unable to listen on %(host)s:%(port)s"" msgstr """" #: neutron/wsgi.py:110 #, python-format msgid ""Unable to find ssl_cert_file : %s"" msgstr """" #: neutron/wsgi.py:114 #, python-format msgid ""Unable to find ssl_key_file : %s"" msgstr """" #: neutron/wsgi.py:119 #, python-format msgid ""Unable to find ssl_ca_file : %s"" msgstr """" #: neutron/wsgi.py:151 #, python-format msgid ""Could not bind to %(host)s:%(port)s after trying for %(time)d seconds"" msgstr """" #: neutron/wsgi.py:295 msgid ""Missing Content-Type"" msgstr """" #: neutron/wsgi.py:470 #, python-format msgid ""Data %(data)s type is %(type)s"" msgstr """" #: neutron/wsgi.py:553 msgid ""Cannot understand JSON"" msgstr """" #: neutron/wsgi.py:566 neutron/wsgi.py:569 msgid ""Inline DTD forbidden"" msgstr """" #: neutron/wsgi.py:645 msgid ""Cannot understand XML"" msgstr """" #: neutron/wsgi.py:756 msgid ""Unrecognized Content-Type provided in request"" msgstr """" #: neutron/wsgi.py:760 msgid ""No Content-Type provided in request"" msgstr """" #: neutron/wsgi.py:764 msgid ""Empty body provided in request"" msgstr """" #: neutron/wsgi.py:770 msgid ""Unable to deserialize body as provided Content-Type"" msgstr """" #: neutron/wsgi.py:866 msgid ""You must implement __call__"" msgstr """" #: neutron/wsgi.py:1003 #, python-format msgid ""%(method)s %(url)s"" msgstr """" #: neutron/wsgi.py:1009 msgid ""Unsupported Content-Type"" msgstr """" #: neutron/wsgi.py:1010 #, python-format msgid ""InvalidContentType: %s"" msgstr """" #: neutron/wsgi.py:1014 msgid ""Malformed request body"" msgstr """" #: neutron/wsgi.py:1015 #, python-format msgid ""MalformedRequestBody: %s"" msgstr """" #: neutron/wsgi.py:1022 #, python-format msgid ""HTTP exception thrown: %s"" msgstr """" #: neutron/wsgi.py:1027 msgid ""Internal error"" msgstr """" #: neutron/wsgi.py:1042 neutron/wsgi.py:1144 #, python-format msgid ""%(url)s returned with HTTP %(status)d"" msgstr """" #: neutron/wsgi.py:1045 #, python-format msgid ""%(url)s returned a fault: %(exception)s"" msgstr """" #: neutron/wsgi.py:1221 msgid ""Could not deserialize data"" msgstr """" #: neutron/agent/dhcp_agent.py:58 msgid ""Interval to resync."" msgstr """" #: neutron/agent/dhcp_agent.py:61 neutron/agent/netns_cleanup_util.py:68 msgid ""The driver used to manage the DHCP server."" msgstr """" #: neutron/agent/dhcp_agent.py:63 neutron/agent/l3_agent.py:171 msgid ""Allow overlapping IP."" msgstr """" #: neutron/agent/dhcp_agent.py:65 msgid ""Support Metadata requests on isolated networks."" msgstr """" #: neutron/agent/dhcp_agent.py:67 msgid """" ""Allows for serving metadata requests from a dedicated network. Requires "" ""enable_isolated_metadata = True"" msgstr """" #: neutron/agent/dhcp_agent.py:71 msgid ""Number of threads to use during sync process."" msgstr """" #: neutron/agent/dhcp_agent.py:104 #, python-format msgid """" ""The '%s' DHCP-driver does not support retrieving of a list of existing "" ""networks"" msgstr """" #: neutron/agent/dhcp_agent.py:111 neutron/agent/dhcp_agent.py:865 msgid ""DHCP agent started"" msgstr """" #: neutron/agent/dhcp_agent.py:139 #, python-format msgid ""Unable to %s dhcp."" msgstr """" #: neutron/agent/dhcp_agent.py:147 msgid ""Unable to update lease"" msgstr """" #: neutron/agent/dhcp_agent.py:151 msgid ""Synchronizing state"" msgstr """" #: neutron/agent/dhcp_agent.py:166 msgid ""Unable to sync network state."" msgstr """" #: neutron/agent/dhcp_agent.py:186 neutron/agent/dhcp_agent.py:226 #, python-format msgid ""Network %s RPC info call failed."" msgstr """" #: neutron/agent/dhcp_agent.py:318 #, python-format msgid """" ""%(port_num)d router ports found on the metadata access network. Only the "" ""port %(port_id)s, for router %(router_id)s will be considered"" msgstr """" #: neutron/agent/dhcp_agent.py:528 neutron/agent/l3_agent.py:159 #: neutron/debug/debug_agent.py:45 msgid ""The driver used to manage the virtual interface."" msgstr """" #: neutron/agent/dhcp_agent.py:536 msgid ""You must specify an interface driver"" msgstr """" #: neutron/agent/dhcp_agent.py:542 neutron/agent/l3_agent.py:202 #, python-format msgid ""Error importing interface driver '%s'"" msgstr """" #: neutron/agent/dhcp_agent.py:590 #, python-format msgid ""Setting gateway for dhcp netns on net %(n)s to %(ip)s"" msgstr """" #: neutron/agent/dhcp_agent.py:600 #, python-format msgid ""Removing gateway for dhcp netns on net %s"" msgstr """" #: neutron/agent/dhcp_agent.py:641 #, python-format msgid ""DHCP port %(device_id)s on network %(network_id)s does not yet exist."" msgstr """" #: neutron/agent/dhcp_agent.py:682 neutron/debug/debug_agent.py:75 #, python-format msgid ""Reusing existing device: %s."" msgstr """" #: neutron/agent/dhcp_agent.py:769 msgid ""Location to DHCP lease relay UNIX domain socket"" msgstr """" #: neutron/agent/dhcp_agent.py:799 #, python-format msgid ""Network ID %s is not a valid UUID"" msgstr """" #: neutron/agent/dhcp_agent.py:805 msgid ""Unable to parse lease relay msg to dict."" msgstr """" #: neutron/agent/dhcp_agent.py:806 #, python-format msgid ""Exception value: %s"" msgstr """" #: neutron/agent/dhcp_agent.py:807 #, python-format msgid ""Message representation: %s"" msgstr """" #: neutron/agent/dhcp_agent.py:809 msgid ""Unable update lease. Exception"" msgstr """" #: neutron/agent/dhcp_agent.py:848 neutron/agent/l3_agent.py:805 msgid """" ""Neutron server does not support state report. State report for this agent"" "" will be disabled."" msgstr """" #: neutron/agent/dhcp_agent.py:854 neutron/agent/l3_agent.py:810 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:228 #: neutron/plugins/nec/agent/nec_neutron_agent.py:184 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:216 msgid ""Failed reporting state!"" msgstr """" #: neutron/agent/dhcp_agent.py:862 neutron/agent/l3_agent.py:815 #, python-format msgid ""agent_updated by server side %s!"" msgstr """" #: neutron/agent/l3_agent.py:156 neutron/debug/debug_agent.py:48 msgid ""Name of bridge used for external network traffic."" msgstr """" #: neutron/agent/l3_agent.py:163 msgid ""TCP Port used by Neutron metadata namespace proxy."" msgstr """" #: neutron/agent/l3_agent.py:167 msgid """" ""Send this many gratuitous ARPs for HA setup, set it below or equal to 0 "" ""to disable this feature."" msgstr """" #: neutron/agent/l3_agent.py:173 msgid """" ""If namespaces is disabled, the l3 agent can only configure a router that "" ""has the matching router ID."" msgstr """" #: neutron/agent/l3_agent.py:178 msgid ""Agent should implement routers with no gateway"" msgstr """" #: neutron/agent/l3_agent.py:180 msgid ""UUID of external network for routers implemented by the agents."" msgstr """" #: neutron/agent/l3_agent.py:183 msgid ""Allow running metadata proxy."" msgstr """" #: neutron/agent/l3_agent.py:195 msgid ""An interface driver must be specified"" msgstr """" #: neutron/agent/l3_agent.py:237 #, python-format msgid ""Failed deleting namespace '%s'"" msgstr """" #: neutron/agent/l3_agent.py:266 msgid """" ""The 'gateway_external_network_id' option must be configured for this "" ""agent as Neutron has more than one external network."" msgstr """" #: neutron/agent/l3_agent.py:334 #, python-format msgid ""Router port %s has no IP address"" msgstr """" #: neutron/agent/l3_agent.py:336 neutron/db/l3_db.py:924 #, python-format msgid ""Ignoring multiple IPs on router port %s"" msgstr """" #: neutron/agent/l3_agent.py:470 #, python-format msgid ""Failed sending gratuitous ARP: %s"" msgstr """" #: neutron/agent/l3_agent.py:607 #, python-format msgid ""Got router deleted notification for %s"" msgstr """" #: neutron/agent/l3_agent.py:612 #, python-format msgid ""Got routers updated notification :%s"" msgstr """" #: neutron/agent/l3_agent.py:620 #, python-format msgid ""Got router removed from agent :%r"" msgstr """" #: neutron/agent/l3_agent.py:624 #, python-format msgid ""Got router added to agent :%r"" msgstr """" #: neutron/agent/l3_agent.py:631 #, python-format msgid ""The external network bridge '%s' does not exist"" msgstr """" #: neutron/agent/l3_agent.py:687 neutron/agent/l3_agent.py:716 msgid ""Failed synchronizing routers"" msgstr """" #: neutron/agent/l3_agent.py:712 #, python-format msgid ""Processing :%r"" msgstr """" #: neutron/agent/l3_agent.py:720 msgid ""L3 agent started"" msgstr """" #: neutron/agent/l3_agent.py:740 #, python-format msgid ""Added route entry is '%s'"" msgstr """" #: neutron/agent/l3_agent.py:748 #, python-format msgid ""Removed route entry is '%s'"" msgstr """" #: neutron/agent/netns_cleanup_util.py:62 msgid ""Delete the namespace by removing all devices."" msgstr """" #: neutron/agent/netns_cleanup_util.py:123 #, python-format msgid ""Unable to find bridge for device: %s"" msgstr """" #: neutron/agent/netns_cleanup_util.py:147 #, python-format msgid ""Error unable to destroy namespace: %s"" msgstr """" #: neutron/agent/ovs_cleanup_util.py:41 msgid """" ""True to delete all ports on all the OpenvSwitch bridges. False to delete "" ""ports created by Neutron on integration and external network bridges."" msgstr """" #: neutron/agent/ovs_cleanup_util.py:73 #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:428 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:251 #, python-format msgid ""Delete %s"" msgstr """" #: neutron/agent/ovs_cleanup_util.py:103 #, python-format msgid ""Cleaning %s"" msgstr """" #: neutron/agent/ovs_cleanup_util.py:110 msgid ""OVS cleanup completed successfully"" msgstr """" #: neutron/agent/securitygroups_rpc.py:44 msgid ""Disabled security-group extension."" msgstr """" #: neutron/agent/securitygroups_rpc.py:51 #, python-format msgid ""Get security group rules for devices via rpc %r"" msgstr """" #: neutron/agent/securitygroups_rpc.py:74 #, python-format msgid ""Security group rule updated on remote: %s"" msgstr """" #: neutron/agent/securitygroups_rpc.py:84 #, python-format msgid ""Security group member updated on remote: %s"" msgstr """" #: neutron/agent/securitygroups_rpc.py:89 #: neutron/agent/securitygroups_rpc.py:138 msgid ""Provider rule updated"" msgstr """" #: neutron/agent/securitygroups_rpc.py:100 #, python-format msgid ""Init firewall settings (driver=%s)"" msgstr """" #: neutron/agent/securitygroups_rpc.py:106 #, python-format msgid ""Preparing filters for devices %s"" msgstr """" #: neutron/agent/securitygroups_rpc.py:114 #, python-format msgid ""Security group rule updated %r"" msgstr """" #: neutron/agent/securitygroups_rpc.py:121 #, python-format msgid ""Security group member updated %r"" msgstr """" #: neutron/agent/securitygroups_rpc.py:144 #, python-format msgid ""Remove device filter for %r"" msgstr """" #: neutron/agent/securitygroups_rpc.py:153 msgid ""Refresh firewall rules"" msgstr """" #: neutron/agent/securitygroups_rpc.py:160 msgid ""No ports here to refresh firewall"" msgstr """" #: neutron/agent/securitygroups_rpc.py:166 #, python-format msgid ""Update port filter for %s"" msgstr """" #: neutron/agent/common/config.py:31 msgid ""Root helper application."" msgstr """" #: neutron/agent/common/config.py:36 msgid ""Seconds between nodes reporting state to server"" msgstr """" #: neutron/agent/common/config.py:80 msgid """" ""DEFAULT.root_helper is deprecated! Please move root_helper configuration "" ""to [AGENT] section."" msgstr """" #: neutron/agent/common/config.py:91 msgid ""Top-level directory for maintaining dhcp state"" msgstr """" #: neutron/agent/linux/daemon.py:35 #, python-format msgid ""Failed to open pidfile: %s"" msgstr """" #: neutron/agent/linux/daemon.py:42 msgid ""Unable to lock pid file"" msgstr """" #: neutron/agent/linux/daemon.py:49 msgid ""Unable to unlock pid file"" msgstr """" #: neutron/agent/linux/daemon.py:98 msgid ""Fork failed"" msgstr """" #: neutron/agent/linux/daemon.py:136 #, python-format msgid ""Pidfile %s already exist. Daemon already running?"" msgstr """" #: neutron/agent/linux/dhcp.py:40 msgid ""Location to store DHCP server config files"" msgstr """" #: neutron/agent/linux/dhcp.py:43 msgid ""Domain to use for building the hostnames"" msgstr """" #: neutron/agent/linux/dhcp.py:46 msgid ""Override the default dnsmasq settings with this file"" msgstr """" #: neutron/agent/linux/dhcp.py:48 msgid ""Use another DNS server before any in /etc/resolv.conf."" msgstr """" #: neutron/agent/linux/dhcp.py:139 #, python-format msgid ""DHCP for %(net_id)s pid %(pid)d is stale, ignoring command"" msgstr """" #: neutron/agent/linux/dhcp.py:142 #, python-format msgid ""No DHCP started for %s"" msgstr """" #: neutron/agent/linux/dhcp.py:164 neutron/agent/linux/external_process.py:84 #, python-format msgid ""Error while reading %s"" msgstr """" #: neutron/agent/linux/dhcp.py:171 neutron/agent/linux/external_process.py:92 #, python-format msgid ""Unable to convert value in %s"" msgstr """" #: neutron/agent/linux/dhcp.py:173 neutron/agent/linux/external_process.py:90 #, python-format msgid ""Unable to access %s"" msgstr """" #: neutron/agent/linux/dhcp.py:233 #, python-format msgid """" ""FAILED VERSION REQUIREMENT FOR DNSMASQ. DHCP AGENT MAY NOT RUN CORRECTLY!"" "" Please ensure that its version is %s or above!"" msgstr """" #: neutron/agent/linux/dhcp.py:238 #, python-format msgid """" ""Unable to determine dnsmasq version. Please ensure that its version is %s"" "" or above!"" msgstr """" #: neutron/agent/linux/dhcp.py:326 #, python-format msgid ""Killing dhcpmasq for network since all subnets have turned off DHCP: %s"" msgstr """" #: neutron/agent/linux/dhcp.py:336 #, python-format msgid ""Pid %d is stale, relaunching dnsmasq"" msgstr """" #: neutron/agent/linux/dhcp.py:337 #, python-format msgid ""Reloading allocations for network: %s"" msgstr """" #: neutron/agent/linux/external_process.py:32 msgid ""Location to store child pid files"" msgstr """" #: neutron/agent/linux/external_process.py:67 #, python-format msgid ""Process for %(uuid)s pid %(pid)d is stale, ignoring command"" msgstr """" #: neutron/agent/linux/external_process.py:70 #, python-format msgid ""No process started for %s"" msgstr """" #: neutron/agent/linux/interface.py:38 msgid ""Name of Open vSwitch bridge to use"" msgstr """" #: neutron/agent/linux/interface.py:41 msgid ""Uses veth for an interface or not"" msgstr """" #: neutron/agent/linux/interface.py:43 msgid ""MTU setting for device."" msgstr """" #: neutron/agent/linux/interface.py:45 msgid ""Mapping between flavor and LinuxInterfaceDriver"" msgstr """" #: neutron/agent/linux/interface.py:47 msgid ""Admin username"" msgstr """" #: neutron/agent/linux/interface.py:49 neutron/agent/metadata/agent.py:46 #: neutron/plugins/metaplugin/common/config.py:40 msgid ""Admin password"" msgstr """" #: neutron/agent/linux/interface.py:52 neutron/agent/metadata/agent.py:49 #: neutron/plugins/metaplugin/common/config.py:43 msgid ""Admin tenant name"" msgstr """" #: neutron/agent/linux/interface.py:54 neutron/agent/metadata/agent.py:51 #: neutron/plugins/metaplugin/common/config.py:45 msgid ""Authentication URL"" msgstr """" #: neutron/agent/linux/interface.py:56 neutron/agent/metadata/agent.py:53 #: neutron/common/config.py:49 neutron/plugins/metaplugin/common/config.py:47 msgid ""The type of authentication to use"" msgstr """" #: neutron/agent/linux/interface.py:58 neutron/agent/metadata/agent.py:55 #: neutron/plugins/metaplugin/common/config.py:49 msgid ""Authentication region"" msgstr """" #: neutron/agent/linux/interface.py:198 neutron/agent/linux/interface.py:267 #: neutron/agent/linux/interface.py:316 #, python-format msgid ""Device %s already exists"" msgstr """" #: neutron/agent/linux/interface.py:216 neutron/agent/linux/interface.py:279 #: neutron/agent/linux/interface.py:323 #, python-format msgid ""Unplugged interface '%s'"" msgstr """" #: neutron/agent/linux/interface.py:218 neutron/agent/linux/interface.py:281 #: neutron/agent/linux/interface.py:325 #, python-format msgid ""Failed unplugging interface '%s'"" msgstr """" #: neutron/agent/linux/interface.py:383 #, python-format msgid ""Driver location: %s"" msgstr """" #: neutron/agent/linux/ip_lib.py:27 msgid ""Force ip_lib calls to use the root helper"" msgstr """" #: neutron/agent/linux/ip_lib.py:425 msgid ""No namespace defined for parent"" msgstr """" #: neutron/agent/linux/iptables_firewall.py:56 #, python-format msgid ""Preparing device (%s) filter"" msgstr """" #: neutron/agent/linux/iptables_firewall.py:64 #, python-format msgid ""Updating device (%s) filter"" msgstr """" #: neutron/agent/linux/iptables_firewall.py:66 #, python-format msgid ""Attempted to update port filter which is not filtered %s"" msgstr """" #: neutron/agent/linux/iptables_firewall.py:75 #, python-format msgid ""Removing device (%s) filter"" msgstr """" #: neutron/agent/linux/iptables_firewall.py:77 #, python-format msgid ""Attempted to remove port filter which is not filtered %r"" msgstr """" #: neutron/agent/linux/iptables_manager.py:148 #, python-format msgid ""Attempted to remove chain %s which does not exist"" msgstr """" #: neutron/agent/linux/iptables_manager.py:190 #, python-format msgid ""Unknown chain: %r"" msgstr """" #: neutron/agent/linux/iptables_manager.py:216 #, python-format msgid """" ""Tried to remove rule that was not there: %(chain)r %(rule)r %(wrap)r "" ""%(top)r"" msgstr """" #: neutron/agent/linux/iptables_manager.py:366 msgid ""IPTablesManager.apply completed with success"" msgstr """" #: neutron/agent/linux/iptables_manager.py:376 #, python-format msgid ""Unable to find table %s"" msgstr """" #: neutron/agent/linux/ovs_lib.py:71 neutron/agent/linux/ovs_lib.py:100 #: neutron/agent/linux/ovs_lib.py:230 #, python-format msgid ""Unable to execute %(cmd)s. Exception: %(exception)s"" msgstr """" #: neutron/agent/linux/ovs_lib.py:127 msgid ""Cannot match priority on flow deletion"" msgstr """" #: neutron/agent/linux/ovs_lib.py:151 msgid ""Must specify one or more actions"" msgstr """" #: neutron/agent/linux/ovs_lib.py:293 #, python-format msgid ""Unable to parse regex results. Exception: %s"" msgstr """" #: neutron/agent/linux/ovs_lib.py:311 #, python-format msgid ""Unable to determine mac address for %s"" msgstr """" #: neutron/agent/linux/ovs_lib.py:320 #, python-format msgid ""Interface %s not found."" msgstr """" #: neutron/agent/linux/ovs_lib.py:329 #, python-format msgid ""Unable to retrieve bridges. Exception: %s"" msgstr """" #: neutron/agent/linux/ovs_lib.py:340 msgid ""Unable to retrieve OVS userspace version."" msgstr """" #: neutron/agent/linux/ovs_lib.py:352 msgid ""Unable to retrieve OVS kernel module version."" msgstr """" #: neutron/agent/linux/utils.py:42 #, python-format msgid ""Running command: %s"" msgstr """" #: neutron/agent/linux/utils.py:56 #, python-format msgid """" ""\n"" ""Command: %(cmd)s\n"" ""Exit code: %(code)s\n"" ""Stdout: %(stdout)r\n"" ""Stderr: %(stderr)r"" msgstr """" #: neutron/agent/metadata/agent.py:44 #: neutron/plugins/metaplugin/common/config.py:38 msgid ""Admin user"" msgstr """" #: neutron/agent/metadata/agent.py:58 msgid ""Network service endpoint type to pull from the keystone catalog"" msgstr """" #: neutron/agent/metadata/agent.py:61 msgid ""IP address used by Nova metadata server."" msgstr """" #: neutron/agent/metadata/agent.py:64 msgid ""TCP Port used by Nova metadata server."" msgstr """" #: neutron/agent/metadata/agent.py:67 msgid ""Shared secret to sign instance-id request"" msgstr """" #: neutron/agent/metadata/agent.py:92 #: neutron/agent/metadata/namespace_proxy.py:75 #, python-format msgid ""Request: %s"" msgstr """" #: neutron/agent/metadata/agent.py:101 #: neutron/agent/metadata/namespace_proxy.py:83 msgid ""Unexpected error."" msgstr """" #: neutron/agent/metadata/agent.py:102 #: neutron/agent/metadata/namespace_proxy.py:84 msgid ""An unknown error has occurred. Please try your request again."" msgstr """" #: neutron/agent/metadata/agent.py:154 msgid """" ""The remote metadata server responded with Forbidden. This response "" ""usually occurs when shared secrets do not match."" msgstr """" #: neutron/agent/metadata/agent.py:165 #: neutron/agent/metadata/namespace_proxy.py:123 msgid ""Remote metadata server experienced an internal server error."" msgstr """" #: neutron/agent/metadata/agent.py:171 #: neutron/agent/metadata/namespace_proxy.py:129 #, python-format msgid ""Unexpected response code: %s"" msgstr """" #: neutron/agent/metadata/agent.py:209 msgid ""Location for Metadata Proxy UNIX domain socket"" msgstr """" #: neutron/agent/metadata/namespace_proxy.py:36 msgid ""Location of Metadata Proxy UNIX domain socket"" msgstr """" #: neutron/agent/metadata/namespace_proxy.py:70 msgid ""network_id and router_id are None. One must be provided."" msgstr """" #: neutron/agent/metadata/namespace_proxy.py:158 msgid ""TCP Port to listen for metadata server requests."" msgstr """" #: neutron/api/api_common.py:103 #, python-format msgid """" ""Invalid value for pagination_max_limit: %s. It should be an integer "" ""greater to 0"" msgstr """" #: neutron/api/api_common.py:117 #, python-format msgid ""Limit must be an integer 0 or greater and not '%d'"" msgstr """" #: neutron/api/api_common.py:134 msgid ""The number of sort_keys and sort_dirs must be same"" msgstr """" #: neutron/api/api_common.py:139 #, python-format msgid ""%s is invalid attribute for sort_keys"" msgstr """" #: neutron/api/api_common.py:143 #, python-format msgid """" ""%(invalid_dirs)s is invalid value for sort_dirs, valid value is '%(asc)s'"" "" and '%(desc)s'"" msgstr """" #: neutron/api/api_common.py:317 neutron/api/v2/base.py:547 #, python-format msgid ""Unable to find '%s' in request body"" msgstr """" #: neutron/api/api_common.py:324 #, python-format msgid ""Failed to parse request. Parameter '%s' not specified"" msgstr """" #: neutron/api/extensions.py:248 #, python-format msgid ""Extension with alias %s does not exist"" msgstr """" #: neutron/api/extensions.py:277 #, python-format msgid ""Extended resource: %s"" msgstr """" #: neutron/api/extensions.py:299 #, python-format msgid ""Extended action: %s"" msgstr """" #: neutron/api/extensions.py:307 #, python-format msgid ""Extended request: %s"" msgstr """" #: neutron/api/extensions.py:398 msgid ""Initializing extension manager."" msgstr """" #: neutron/api/extensions.py:480 #, python-format msgid ""Error fetching extended attributes for extension '%s'"" msgstr """" #: neutron/api/extensions.py:489 #, python-format msgid """" ""It was impossible to process the following extensions: %s because of "" ""missing requirements."" msgstr """" #: neutron/api/extensions.py:500 #, python-format msgid ""Ext name: %s"" msgstr """" #: neutron/api/extensions.py:501 #, python-format msgid ""Ext alias: %s"" msgstr """" #: neutron/api/extensions.py:502 #, python-format msgid ""Ext description: %s"" msgstr """" #: neutron/api/extensions.py:503 #, python-format msgid ""Ext namespace: %s"" msgstr """" #: neutron/api/extensions.py:504 #, python-format msgid ""Ext updated: %s"" msgstr """" #: neutron/api/extensions.py:506 neutron/api/extensions.py:512 #, python-format msgid ""Exception loading extension: %s"" msgstr """" #: neutron/api/extensions.py:532 #, python-format msgid ""Extension path '%s' doesn't exist!"" msgstr """" #: neutron/api/extensions.py:537 #, python-format msgid ""Loading extension file: %s"" msgstr """" #: neutron/api/extensions.py:545 #, python-format msgid ""Did not find expected name \""%(ext_name)s\"" in %(file)s"" msgstr """" #: neutron/api/extensions.py:553 #, python-format msgid ""Extension file %(f)s wasn't loaded due to %(exception)s"" msgstr """" #: neutron/api/extensions.py:562 #, python-format msgid ""Loaded extension: %s"" msgstr """" #: neutron/api/extensions.py:565 #, python-format msgid ""Found duplicate extension: %s"" msgstr """" #: neutron/api/extensions.py:595 #, python-format msgid ""Extension %s not supported by any of loaded plugins"" msgstr """" #: neutron/api/extensions.py:606 #, python-format msgid ""Loaded plugins do not implement extension %s interface"" msgstr """" #: neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py:37 #, python-format msgid ""Nofity agent at %(host)s the message %(method)s"" msgstr """" #: neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py:56 #, python-format msgid ""Notify agent at %(topic)s.%(host)s the message %(method)s"" msgstr """" #: neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py:85 #, python-format msgid """" ""Fanout notify agent at %(topic)s the message %(method)s on router "" ""%(router_id)s"" msgstr """" #: neutron/api/v2/attributes.py:43 #, python-format msgid """" ""Invalid input. '%(target_dict)s' must be a dictionary with keys: "" ""%(expected_keys)s"" msgstr """" #: neutron/api/v2/attributes.py:54 #, python-format msgid """" ""Validation of dictionary's keys failed.Expected keys: %(expected_keys)s "" ""Provided keys: %(provided_keys)s"" msgstr """" #: neutron/api/v2/attributes.py:68 #, python-format msgid ""'%(data)s' is not in %(valid_values)s"" msgstr """" #: neutron/api/v2/attributes.py:76 #, python-format msgid ""'%s' is not a valid string"" msgstr """" #: neutron/api/v2/attributes.py:81 #, python-format msgid ""'%(data)s' exceeds maximum length of %(max_len)s"" msgstr """" #: neutron/api/v2/attributes.py:91 #, python-format msgid ""'%s' is not a valid boolean value"" msgstr """" #: neutron/api/v2/attributes.py:100 #, python-format msgid ""'%(data)s' is not in range %(min_value)s through %(max_value)s"" msgstr """" #: neutron/api/v2/attributes.py:111 #, python-format msgid ""'%s' contains whitespace"" msgstr """" #: neutron/api/v2/attributes.py:121 #, python-format msgid ""'%s' is not a valid MAC address"" msgstr """" #: neutron/api/v2/attributes.py:130 #, python-format msgid ""'%s' is not a valid IP address"" msgstr """" #: neutron/api/v2/attributes.py:141 #, python-format msgid ""Invalid data format for IP pool: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:160 neutron/api/v2/attributes.py:167 #, python-format msgid ""Invalid data format for fixed IP: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:175 #, python-format msgid ""Duplicate IP address '%s'"" msgstr """" #: neutron/api/v2/attributes.py:191 #, python-format msgid ""Invalid data format for nameserver: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:202 #, python-format msgid ""'%s' is not a valid nameserver"" msgstr """" #: neutron/api/v2/attributes.py:206 #, python-format msgid ""Duplicate nameserver '%s'"" msgstr """" #: neutron/api/v2/attributes.py:214 #, python-format msgid ""Invalid data format for hostroute: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:234 #, python-format msgid ""Duplicate hostroute '%s'"" msgstr """" #: neutron/api/v2/attributes.py:252 neutron/tests/unit/test_attributes.py:383 #: neutron/tests/unit/test_attributes.py:392 #: neutron/tests/unit/test_attributes.py:401 #: neutron/tests/unit/test_attributes.py:410 #, python-format msgid ""'%(data)s' isn't a recognized IP subnet cidr, '%(cidr)s' is recommended"" msgstr """" #: neutron/api/v2/attributes.py:258 #, python-format msgid ""'%s' is not a valid IP subnet"" msgstr """" #: neutron/api/v2/attributes.py:271 #, python-format msgid ""'%s' is not a valid input"" msgstr """" #: neutron/api/v2/attributes.py:278 #, python-format msgid ""'%s' is not a valid UUID"" msgstr """" #: neutron/api/v2/attributes.py:290 #, python-format msgid ""'%s' is not a list"" msgstr """" #: neutron/api/v2/attributes.py:301 #, python-format msgid ""Duplicate items in the list: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:308 #, python-format msgid ""'%s' is not a dictionary"" msgstr """" #: neutron/api/v2/attributes.py:333 #, python-format msgid ""Validator '%s' does not exist."" msgstr """" #: neutron/api/v2/attributes.py:365 #, python-format msgid ""'%s' is not an integer"" msgstr """" #: neutron/api/v2/attributes.py:370 #, python-format msgid ""'%s' should be non-negative"" msgstr """" #: neutron/api/v2/attributes.py:389 #, python-format msgid ""'%s' cannot be converted to boolean"" msgstr """" #: neutron/api/v2/attributes.py:397 #: neutron/plugins/nec/extensions/packetfilter.py:48 #, python-format msgid ""'%s' is not a integer"" msgstr """" #: neutron/api/v2/attributes.py:410 #, python-format msgid ""'%s' is not of the form <key>=[value]"" msgstr """" #: neutron/api/v2/base.py:78 msgid ""Native pagination depend on native sorting"" msgstr """" #: neutron/api/v2/base.py:81 msgid ""Allow sorting is enabled because native pagination requires native sorting"" msgstr """" #: neutron/api/v2/base.py:134 #, python-format msgid """" ""The resource %(resource)s was not found in the RESOURCE_ATTRIBUTE_MAP; "" ""unable to perform authZ check for attribute %(attr)s"" msgstr """" #: neutron/api/v2/base.py:140 #, python-format msgid """" ""Policy rule:%(action)s not found. Assuming no authZ check is defined for "" ""%(attr)s"" msgstr """" #: neutron/api/v2/base.py:319 #, python-format msgid ""Unable to undo add for %(resource)s %(id)s"" msgstr """" #: neutron/api/v2/base.py:447 #, python-format msgid ""Invalid format: %s"" msgstr """" #: neutron/api/v2/base.py:501 msgid """" ""Specifying 'tenant_id' other than authenticated tenant in request "" ""requires admin privileges"" msgstr """" #: neutron/api/v2/base.py:509 msgid ""Running without keystone AuthN requires that tenant_id is specified"" msgstr """" #: neutron/api/v2/base.py:527 msgid ""Resource body required"" msgstr """" #: neutron/api/v2/base.py:538 msgid ""Bulk operation not supported"" msgstr """" #: neutron/api/v2/base.py:542 msgid ""Resources required"" msgstr """" #: neutron/api/v2/base.py:559 #, python-format msgid ""Failed to parse request. Required attribute '%s' not specified"" msgstr """" #: neutron/api/v2/base.py:566 #, python-format msgid ""Attribute '%s' not allowed in POST"" msgstr """" #: neutron/api/v2/base.py:571 #, python-format msgid ""Cannot update read-only attribute %s"" msgstr """" #: neutron/api/v2/base.py:589 #, python-format msgid ""Invalid input for %(attr)s. Reason: %(reason)s."" msgstr """" #: neutron/api/v2/base.py:598 #, python-format msgid ""Unrecognized attribute(s) '%s'"" msgstr """" #: neutron/api/v2/base.py:616 #, python-format msgid ""Tenant %(tenant_id)s not allowed to create %(resource)s on this network"" msgstr """" #: neutron/api/v2/resource.py:85 neutron/api/v2/resource.py:93 #: neutron/api/v2/resource.py:110 #, python-format msgid ""%s failed"" msgstr """" #: neutron/api/v2/resource.py:112 #: neutron/tests/unit/test_api_v2_resource.py:191 #: neutron/tests/unit/test_api_v2_resource.py:207 msgid ""Request Failed: internal server error while processing your request."" msgstr """" #: neutron/common/config.py:39 msgid ""The host IP to bind to"" msgstr """" #: neutron/common/config.py:41 msgid ""The port to bind to"" msgstr """" #: neutron/common/config.py:43 msgid ""The API paste config file to use"" msgstr """" #: neutron/common/config.py:45 msgid ""The path for API extensions"" msgstr """" #: neutron/common/config.py:47 msgid ""The policy file to use"" msgstr """" #: neutron/common/config.py:51 msgid ""The core plugin Neutron will use"" msgstr """" #: neutron/common/config.py:53 msgid ""The service plugins Neutron will use"" msgstr """" #: neutron/common/config.py:55 msgid ""The base MAC address Neutron will use for VIFs"" msgstr """" #: neutron/common/config.py:57 msgid ""How many times Neutron will retry MAC generation"" msgstr """" #: neutron/common/config.py:59 msgid ""Allow the usage of the bulk API"" msgstr """" #: neutron/common/config.py:61 msgid ""Allow the usage of the pagination"" msgstr """" #: neutron/common/config.py:63 msgid ""Allow the usage of the sorting"" msgstr """" #: neutron/common/config.py:65 msgid """" ""The maximum number of items returned in a single response, value was "" ""'infinite' or negative integer means no limit"" msgstr """" #: neutron/common/config.py:69 msgid ""Maximum number of DNS nameservers"" msgstr """" #: neutron/common/config.py:71 msgid ""Maximum number of host routes per subnet"" msgstr """" #: neutron/common/config.py:73 msgid ""Maximum number of fixed ips per port"" msgstr """" #: neutron/common/config.py:76 msgid ""DHCP lease duration"" msgstr """" #: neutron/common/config.py:78 msgid ""Allow sending resource operation notification to DHCP agent"" msgstr """" #: neutron/common/config.py:81 msgid ""Allow overlapping IP support in Neutron"" msgstr """" #: neutron/common/config.py:83 msgid ""The hostname Neutron is running on"" msgstr """" #: neutron/common/config.py:85 msgid ""Ensure that configured gateway is on subnet"" msgstr """" #: neutron/common/config.py:114 #, python-format msgid ""Base MAC: %s"" msgstr """" #: neutron/common/config.py:125 msgid ""Logging enabled!"" msgstr """" #: neutron/common/config.py:138 #, python-format msgid ""Config paste file: %s"" msgstr """" #: neutron/common/config.py:143 #, python-format msgid ""Unable to load %(app_name)s from configuration file %(config_path)s."" msgstr """" #: neutron/common/exceptions.py:34 neutron/plugins/nicira/NvpApiClient.py:213 msgid ""An unknown exception occurred."" msgstr """" #: neutron/common/exceptions.py:38 #, python-format msgid ""Bad %(resource)s request: %(msg)s"" msgstr """" #: neutron/common/exceptions.py:50 msgid ""Not authorized."" msgstr """" #: neutron/common/exceptions.py:54 msgid ""The service is unailable"" msgstr """" #: neutron/common/exceptions.py:58 #, python-format msgid ""User does not have admin privileges: %(reason)s"" msgstr """" #: neutron/common/exceptions.py:62 #, python-format msgid ""Policy doesn't allow %(action)s to be performed."" msgstr """" #: neutron/common/exceptions.py:66 #, python-format msgid ""Network %(net_id)s could not be found"" msgstr """" #: neutron/common/exceptions.py:70 #, python-format msgid ""Subnet %(subnet_id)s could not be found"" msgstr """" #: neutron/common/exceptions.py:74 #, python-format msgid ""Port %(port_id)s could not be found on network %(net_id)s"" msgstr """" #: neutron/common/exceptions.py:79 msgid ""Policy configuration policy.json could not be found"" msgstr """" #: neutron/common/exceptions.py:83 #, python-format msgid ""Requested rule:%(rule)s cannot be found"" msgstr """" #: neutron/common/exceptions.py:87 #, python-format msgid ""Failed to init policy %(policy)s because %(reason)s"" msgstr """" #: neutron/common/exceptions.py:91 #, python-format msgid ""Failed to check policy %(policy)s because %(reason)s"" msgstr """" #: neutron/common/exceptions.py:95 #, python-format msgid ""Unsupported port state: %(port_state)s"" msgstr """" #: neutron/common/exceptions.py:99 msgid ""The resource is inuse"" msgstr """" #: neutron/common/exceptions.py:103 #, python-format msgid """" ""Unable to complete operation on network %(net_id)s. There are one or more"" "" ports still in use on the network."" msgstr """" #: neutron/common/exceptions.py:108 #, python-format msgid """" ""Unable to complete operation on subnet %(subnet_id)s. One or more ports "" ""have an IP allocation from this subnet."" msgstr """" #: neutron/common/exceptions.py:113 #, python-format msgid """" ""Unable to complete operation on port %(port_id)s for network %(net_id)s. "" ""Port already has an attacheddevice %(device_id)s."" msgstr """" #: neutron/common/exceptions.py:119 #, python-format msgid """" ""Unable to complete operation for network %(net_id)s. The mac address "" ""%(mac)s is in use."" msgstr """" #: neutron/common/exceptions.py:125 #, python-format msgid """" ""Unable to complete operation for %(subnet_id)s. The number of host routes"" "" exceeds the limit %(quota)s."" msgstr """" #: neutron/common/exceptions.py:131 #, python-format msgid """" ""Unable to complete operation for %(subnet_id)s. The number of DNS "" ""nameservers exceeds the limit %(quota)s."" msgstr """" #: neutron/common/exceptions.py:136 #, python-format msgid """" ""Unable to complete operation for network %(net_id)s. The IP address "" ""%(ip_address)s is in use."" msgstr """" #: neutron/common/exceptions.py:141 #, python-format msgid """" ""Unable to create the network. The VLAN %(vlan_id)s on physical network "" ""%(physical_network)s is in use."" msgstr """" #: neutron/common/exceptions.py:147 #, python-format msgid """" ""Unable to create the flat network. Physical network %(physical_network)s "" ""is in use."" msgstr """" #: neutron/common/exceptions.py:152 #, python-format msgid ""Unable to create the network. The tunnel ID %(tunnel_id)s is in use."" msgstr """" #: neutron/common/exceptions.py:157 msgid ""Tenant network creation is not enabled."" msgstr """" #: neutron/common/exceptions.py:165 msgid """" ""Unable to create the network. No tenant network is available for "" ""allocation."" msgstr """" #: neutron/common/exceptions.py:170 #, python-format msgid """" ""Unable to plug the attachment %(att_id)s into port %(port_id)s for "" ""network %(net_id)s. The attachment is already plugged into port "" ""%(att_port_id)s"" msgstr """" #: neutron/common/exceptions.py:176 #, python-format msgid """" ""Subnet on port %(port_id)s does not match the requested subnet "" ""%(subnet_id)s"" msgstr """" #: neutron/common/exceptions.py:181 #, python-format msgid ""Malformed request body: %(reason)s"" msgstr """" #: neutron/common/exceptions.py:189 #, python-format msgid ""Invalid input for operation: %(error_message)s."" msgstr """" #: neutron/common/exceptions.py:193 #, python-format msgid ""The allocation pool %(pool)s is not valid."" msgstr """" #: neutron/common/exceptions.py:197 #, python-format msgid """" ""Found overlapping allocation pools:%(pool_1)s %(pool_2)s for subnet "" ""%(subnet_cidr)s."" msgstr """" #: neutron/common/exceptions.py:202 #, python-format msgid ""The allocation pool %(pool)s spans beyond the subnet cidr %(subnet_cidr)s."" msgstr """" #: neutron/common/exceptions.py:211 #, python-format msgid ""Unable to generate unique mac on network %(net_id)s."" msgstr """" #: neutron/common/exceptions.py:215 #, python-format msgid ""No more IP addresses available on network %(net_id)s."" msgstr """" #: neutron/common/exceptions.py:219 #, python-format msgid ""Bridge %(bridge)s does not exist."" msgstr """" #: neutron/common/exceptions.py:223 #, python-format msgid ""Creation failed. %(dev_name)s already exists."" msgstr """" #: neutron/common/exceptions.py:227 msgid ""Sudo priviledge is required to run this command."" msgstr """" #: neutron/common/exceptions.py:231 #, python-format msgid ""Unknown quota resources %(unknown)s."" msgstr """" #: neutron/common/exceptions.py:235 #, python-format msgid ""Quota exceeded for resources: %(overs)s"" msgstr """" #: neutron/common/exceptions.py:239 msgid ""Tenant-id was missing from Quota request"" msgstr """" #: neutron/common/exceptions.py:243 #, python-format msgid """" ""Change would make usage less than 0 for the following resources: "" ""%(unders)s"" msgstr """" #: neutron/common/exceptions.py:248 #, python-format msgid """" ""Unable to reconfigure sharing settings for network %(network)s. Multiple "" ""tenants are using it"" msgstr """" #: neutron/common/exceptions.py:253 #, python-format msgid ""Invalid extension environment: %(reason)s"" msgstr """" #: neutron/common/exceptions.py:257 #, python-format msgid ""Unable to find any IP address on external network %(net_id)s."" msgstr """" #: neutron/common/exceptions.py:262 msgid ""More than one external network exists"" msgstr """" #: neutron/common/exceptions.py:266 #, python-format msgid ""An invalid value was provided for %(opt_name)s: %(opt_value)s"" msgstr """" #: neutron/common/exceptions.py:271 #, python-format msgid ""Gateway ip %(ip_address)s conflicts with allocation pool %(pool)s"" msgstr """" #: neutron/common/exceptions.py:276 #, python-format msgid ""Invalid network VLAN range: '%(vlan_range)s' - '%(error)s'"" msgstr """" #: neutron/common/legacy.py:33 #, python-format msgid ""Old class module path in use. Please change '%(old)s' to '%(new)s'."" msgstr """" #: neutron/common/legacy.py:51 #, python-format msgid ""Skipping unknown group key: %s"" msgstr """" #: neutron/common/log.py:31 #, python-format msgid """" ""%(class_name)s method %(method_name)scalled with arguments %(args)s "" ""%(kwargs)s "" msgstr """" #: neutron/common/utils.py:55 neutron/openstack/common/fileutils.py:64 #, python-format msgid ""Reloading cached file %s"" msgstr """" #: neutron/common/utils.py:142 #, python-format msgid ""Invalid mapping: '%s'"" msgstr """" #: neutron/common/utils.py:145 #, python-format msgid ""Missing key in mapping: '%s'"" msgstr """" #: neutron/common/utils.py:148 #, python-format msgid ""Missing value in mapping: '%s'"" msgstr """" #: neutron/common/utils.py:150 #, python-format msgid ""Key %(key)s in mapping: '%(mapping)s' not unique"" msgstr """" #: neutron/common/utils.py:153 #, python-format msgid ""Value %(value)s in mapping: '%(mapping)s' not unique"" msgstr """" #: neutron/db/agents_db.py:33 msgid ""Seconds to regard the agent is down."" msgstr """" #: neutron/db/agents_db.py:79 #, python-format msgid ""Configuration for agent %(agent_type)s on host %(host)s is invalid."" msgstr """" #: neutron/db/agents_db.py:170 msgid ""Message with invalid timestamp received"" msgstr """" #: neutron/db/agentschedulers_db.py:39 msgid ""Driver to use for scheduling network to DHCP agent"" msgstr """" #: neutron/db/agentschedulers_db.py:42 msgid ""Driver to use for scheduling router to a default L3 agent"" msgstr """" #: neutron/db/agentschedulers_db.py:45 msgid ""Allow auto scheduling networks to DHCP agent."" msgstr """" #: neutron/db/agentschedulers_db.py:47 msgid ""Allow auto scheduling routers to L3 agent."" msgstr """" #: neutron/db/agentschedulers_db.py:49 msgid ""Number of DHCP agents scheduled to host a network."" msgstr """" #: neutron/db/agentschedulers_db.py:422 #, python-format msgid ""Fail scheduling network %s"" msgstr """" #: neutron/db/api.py:64 #, python-format msgid ""Database registration exception: %s"" msgstr """" #: neutron/db/api.py:75 msgid ""Database exception"" msgstr """" #: neutron/db/db_base_plugin_v2.py:126 msgid ""Cannot create resource for another tenant"" msgstr """" #: neutron/db/db_base_plugin_v2.py:274 #, python-format msgid ""Generated mac for network %(network_id)s is %(mac_address)s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:280 #, python-format msgid ""Generated mac %(mac_address)s exists. Remaining attempts %(max_retries)s."" msgstr """" #: neutron/db/db_base_plugin_v2.py:284 #, python-format msgid ""Unable to generate mac address after %s attempts"" msgstr """" #: neutron/db/db_base_plugin_v2.py:314 #, python-format msgid """" ""Hold allocated IP %(ip_address)s "" ""(%(network_id)s/%(subnet_id)s/%(port_id)s)"" msgstr """" #: neutron/db/db_base_plugin_v2.py:365 #, python-format msgid ""No allocation pool found for ip address:%s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:378 #, python-format msgid ""Recycle %s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:382 #, python-format msgid ""Recycle: first match for %(first_ip)s-%(last_ip)s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:389 #, python-format msgid ""Recycle: last match for %(first_ip)s-%(last_ip)s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:401 #, python-format msgid ""Recycle: merged %(first_ip1)s-%(last_ip1)s and %(first_ip2)s-%(last_ip2)s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:410 #, python-format msgid ""Recycle: updated first %(first_ip)s-%(last_ip)s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:415 #, python-format msgid ""Recycle: updated last %(first_ip)s-%(last_ip)s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:424 #, python-format msgid ""Recycle: created new %(first_ip)s-%(last_ip)s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:448 #, python-format msgid """" ""No fixed IP found that matches the network %(network_id)s and ip address "" ""%(ip_address)s."" msgstr """" #: neutron/db/db_base_plugin_v2.py:457 #, python-format msgid ""Delete allocated IP %(ip_address)s (%(network_id)s/%(subnet_id)s)"" msgstr """" #: neutron/db/db_base_plugin_v2.py:481 #, python-format msgid ""All IP's from subnet %(subnet_id)s (%(cidr)s) allocated"" msgstr """" #: neutron/db/db_base_plugin_v2.py:486 #, python-format msgid ""Allocated IP - %(ip_address)s from %(first_ip)s to %(last_ip)s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:493 msgid ""No more free IP's in slice. Deleting allocation pool."" msgstr """" #: neutron/db/db_base_plugin_v2.py:599 msgid ""IP allocation requires subnet_id or ip_address"" msgstr """" #: neutron/db/db_base_plugin_v2.py:611 #, python-format msgid ""IP address %s is not a valid IP for the defined networks subnets"" msgstr """" #: neutron/db/db_base_plugin_v2.py:617 #, python-format msgid """" ""Failed to create port on network %(network_id)s, because fixed_ips "" ""included invalid subnet %(subnet_id)s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:637 #, python-format msgid ""IP address %s is not a valid IP for the defined subnet"" msgstr """" #: neutron/db/db_base_plugin_v2.py:646 neutron/db/db_base_plugin_v2.py:679 msgid ""Exceeded maximim amount of fixed ips per port"" msgstr """" #: neutron/db/db_base_plugin_v2.py:694 #, python-format msgid ""Port update. Hold %s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:702 #, python-format msgid ""Port update. Adding %s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:757 #, python-format msgid """" ""Requested subnet with cidr: %(cidr)s for network: %(network_id)s overlaps"" "" with another subnet"" msgstr """" #: neutron/db/db_base_plugin_v2.py:762 #, python-format msgid """" ""Validation for CIDR: %(new_cidr)s failed - overlaps with subnet "" ""%(subnet_id)s (CIDR: %(cidr)s)"" msgstr """" #: neutron/db/db_base_plugin_v2.py:782 msgid ""Performing IP validity checks on allocation pools"" msgstr """" #: neutron/db/db_base_plugin_v2.py:789 #, python-format msgid ""Found invalid IP address in pool: %(start)s - %(end)s:"" msgstr """" #: neutron/db/db_base_plugin_v2.py:796 msgid ""Specified IP addresses do not match the subnet IP version"" msgstr """" #: neutron/db/db_base_plugin_v2.py:800 #, python-format msgid ""Start IP (%(start)s) is greater than end IP (%(end)s)"" msgstr """" #: neutron/db/db_base_plugin_v2.py:805 #, python-format msgid ""Found pool larger than subnet CIDR:%(start)s - %(end)s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:818 msgid ""Checking for overlaps among allocation pools and gateway ip"" msgstr """" #: neutron/db/db_base_plugin_v2.py:829 #, python-format msgid ""Found overlapping ranges: %(l_range)s and %(r_range)s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:842 neutron/db/db_base_plugin_v2.py:846 #, python-format msgid ""Invalid route: %s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:968 #, python-format msgid ""An exception occured while creating the %(resource)s:%(item)s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:1067 #, python-format msgid ""%(name)s '%(addr)s' does not match the ip_version '%(ip_version)s'"" msgstr """" #: neutron/db/db_base_plugin_v2.py:1091 msgid ""Gateway is not valid on subnet"" msgstr """" #: neutron/db/db_base_plugin_v2.py:1104 #, python-format msgid ""Error parsing dns address %s"" msgstr """" #: neutron/db/db_base_plugin_v2.py:1366 #, python-format msgid ""Allocated IP %(ip_address)s (%(network_id)s/%(subnet_id)s/%(port_id)s)"" msgstr """" #: neutron/db/db_base_plugin_v2.py:1446 #, python-format msgid ""%(address)s (%(subnet_id)s) is not recycled"" msgstr """" #: neutron/db/dhcp_rpc_base.py:53 #, python-format msgid ""get_active_networks requested from %s"" msgstr """" #: neutron/db/dhcp_rpc_base.py:60 #, python-format msgid ""get_active_networks_info from %s"" msgstr """" #: neutron/db/dhcp_rpc_base.py:80 #, python-format msgid ""Network %(network_id)s requested from %(host)s"" msgstr """" #: neutron/db/dhcp_rpc_base.py:109 #, python-format msgid ""Port %(device_id)s for %(network_id)s requested from %(host)s"" msgstr """" #: neutron/db/dhcp_rpc_base.py:143 #, python-format msgid """" ""DHCP port %(device_id)s on network %(network_id)s does not exist on "" ""%(host)s"" msgstr """" #: neutron/db/dhcp_rpc_base.py:176 #, python-format msgid ""DHCP port deletion for %(network_id)s request from %(host)s"" msgstr """" #: neutron/db/dhcp_rpc_base.py:193 #, python-format msgid ""DHCP port remove fixed_ip for %(subnet_id)s request from %(host)s"" msgstr """" #: neutron/db/dhcp_rpc_base.py:217 #, python-format msgid """" ""Updating lease expiration for %(ip_address)s on network %(network_id)s "" ""from %(host)s."" msgstr """" #: neutron/db/dhcp_rpc_base.py:231 #, python-format msgid ""Create dhcp port %(port)s from %(host)s."" msgstr """" #: neutron/db/dhcp_rpc_base.py:247 #, python-format msgid ""Update dhcp port %(port)s from %(host)s."" msgstr """" #: neutron/db/extraroute_db.py:38 msgid ""Maximum number of routes"" msgstr """" #: neutron/db/extraroute_db.py:100 msgid ""the nexthop is not connected with router"" msgstr """" #: neutron/db/extraroute_db.py:107 msgid ""the nexthop is used by router"" msgstr """" #: neutron/db/l3_db.py:205 #, python-format msgid ""No IPs available for external network %s"" msgstr """" #: neutron/db/l3_db.py:225 neutron/db/l3_db.py:632 #, python-format msgid ""Network %s is not a valid external network"" msgstr """" #: neutron/db/l3_db.py:311 #, python-format msgid ""Router already has a port on subnet %s"" msgstr """" #: neutron/db/l3_db.py:325 #, python-format msgid """" ""Cidr %(subnet_cidr)s of subnet %(subnet_id)s overlaps with cidr %(cidr)s "" ""of subnet %(sub_id)s"" msgstr """" #: neutron/db/l3_db.py:334 neutron/db/l3_db.py:410 msgid ""Either subnet_id or port_id must be specified"" msgstr """" #: neutron/db/l3_db.py:341 msgid ""Cannot specify both subnet-id and port-id"" msgstr """" #: neutron/db/l3_db.py:351 msgid ""Router port must have exactly one fixed IP"" msgstr """" #: neutron/db/l3_db.py:366 msgid ""Subnet for router interface must have a gateway IP"" msgstr """" #: neutron/db/l3_db.py:492 #, python-format msgid ""Cannot add floating IP to port on subnet %s which has no gateway_ip"" msgstr """" #: neutron/db/l3_db.py:531 #, python-format msgid """" ""Port %(port_id)s is associated with a different tenant than Floating IP "" ""%(floatingip_id)s and therefore cannot be bound."" msgstr """" #: neutron/db/l3_db.py:535 #, python-format msgid """" ""Cannnot create floating IP and bind it to Port %s, since that port is "" ""owned by a different tenant."" msgstr """" #: neutron/db/l3_db.py:547 #, python-format msgid ""Port %(id)s does not have fixed ip %(address)s"" msgstr """" #: neutron/db/l3_db.py:554 #, python-format msgid ""Cannot add floating IP to port %s that hasno fixed IP addresses"" msgstr """" #: neutron/db/l3_db.py:558 #, python-format msgid """" ""Port %s has multiple fixed IPs. Must provide a specific IP when "" ""assigning a floating IP"" msgstr """" #: neutron/db/l3_db.py:600 neutron/plugins/nicira/NeutronPlugin.py:1863 msgid ""fixed_ip_address cannot be specified without a port_id"" msgstr """" #: neutron/db/l3_db.py:756 #, python-format msgid """" ""Port %(port_id)s has owner %(port_owner)s, but no IP address, so it can "" ""be deleted"" msgstr """" #: neutron/db/l3_db.py:774 #, python-format msgid ""Multiple floating IPs found for port %s"" msgstr """" #: neutron/db/l3_db.py:930 #, python-format msgid ""Skipping port %s as no IP is configure on it"" msgstr """" #: neutron/db/l3_rpc_base.py:52 #, python-format msgid """" ""Routers returned to l3 agent:\n"" "" %s"" msgstr """" #: neutron/db/l3_rpc_base.py:65 #, python-format msgid ""External network ID returned to l3 agent: %s"" msgstr """" #: neutron/db/routedserviceinsertion_db.py:38 #, python-format msgid ""Resource type '%(resource_type)s' is longer than %(maxlen)d characters"" msgstr """" #: neutron/db/servicetype_db.py:40 msgid ""Textual description for the default service type"" msgstr """" #: neutron/db/servicetype_db.py:42 msgid """" ""Defines a provider for an advanced service using the format: "" ""<service>:<plugin>[:<driver>]"" msgstr """" #: neutron/db/servicetype_db.py:62 #, python-format msgid """" ""Default service type - no driver for service %(service_class)s and plugin"" "" %(plugin)s"" msgstr """" #: neutron/db/servicetype_db.py:73 msgid """" ""No default service definition in configuration file. Please add service "" ""definitions using the service_definition variable in the "" ""[default_servicetype] section"" msgstr """" #: neutron/db/servicetype_db.py:79 #, python-format msgid ""Service type %(service_type_id)s could not be found "" msgstr """" #: neutron/db/servicetype_db.py:83 #, python-format msgid """" ""There are still active instances of service type '%(service_type_id)s'. "" ""Therefore it cannot be removed."" msgstr """" #: neutron/db/servicetype_db.py:150 #, python-format msgid """" ""Default service type record updated in Neutron database. identifier is "" ""'%s'"" msgstr """" #: neutron/db/servicetype_db.py:218 #, python-format msgid ""Multiple default service type instances found.Will use instance '%s'"" msgstr """" #: neutron/db/servicetype_db.py:264 #, python-format msgid ""Created service type object:%s"" msgstr """" #: neutron/db/servicetype_db.py:311 #, python-format msgid ""Number of instances for service type '%s' is already 0."" msgstr """" #: neutron/db/sqlalchemyutils.py:74 #, python-format msgid ""%s is invalid attribute for sort_key"" msgstr """" #: neutron/db/sqlalchemyutils.py:77 #, python-format msgid """" ""The attribute '%(attr)s' is reference to other resource, can't used by "" ""sort '%(resource)s'"" msgstr """" #: neutron/db/loadbalancer/loadbalancer_db.py:68 #, python-format msgid ""The %(key)s field can not have negative value. Current value is %(value)d."" msgstr """" #: neutron/db/loadbalancer/loadbalancer_db.py:250 msgid ""'cookie_name' should be specified for this type of session persistence."" msgstr """" #: neutron/db/loadbalancer/loadbalancer_db.py:254 msgid ""'cookie_name' is not allowed for this type of session persistence"" msgstr """" #: neutron/db/migration/cli.py:32 msgid ""Neutron plugin provider module"" msgstr """" #: neutron/db/migration/cli.py:38 msgid ""Neutron quota driver class"" msgstr """" #: neutron/db/migration/cli.py:45 msgid ""URL to database"" msgstr """" #: neutron/db/migration/cli.py:67 msgid ""You must provide a revision or relative delta"" msgstr """" #: neutron/db/migration/cli.py:122 msgid ""Available commands"" msgstr """" #: neutron/debug/commands.py:34 msgid ""Unimplemented commands"" msgstr """" #: neutron/debug/commands.py:46 msgid ""ID of network to probe"" msgstr """" #: neutron/debug/commands.py:50 msgid ""owner type of the device: network/compute"" msgstr """" #: neutron/debug/commands.py:58 #, python-format msgid ""Probe created : %s "" msgstr """" #: neutron/debug/commands.py:70 msgid ""ID of probe port to delete"" msgstr """" #: neutron/debug/commands.py:77 #, python-format msgid ""Probe %s deleted"" msgstr """" #: neutron/debug/commands.py:108 msgid ""All Probes deleted "" msgstr """" #: neutron/debug/commands.py:120 msgid ""ID of probe port to execute command"" msgstr """" #: neutron/debug/commands.py:125 msgid ""Command to execute"" msgstr """" #: neutron/debug/commands.py:145 msgid ""Ping timeout"" msgstr """" #: neutron/debug/commands.py:149 msgid ""ID of network"" msgstr """" #: neutron/debug/debug_agent.py:43 msgid ""Use Linux network namespaces"" msgstr """" #: neutron/debug/debug_agent.py:128 #, python-format msgid ""Failed to delete namespace %s"" msgstr """" #: neutron/debug/shell.py:64 msgid ""Config file for interface driver (You may also use l3_agent.ini)"" msgstr """" #: neutron/debug/shell.py:72 msgid """" ""You must provide a config file for bridge - either --config-file or "" ""env[NEUTRON_TEST_CONFIG_FILE]"" msgstr """" #: neutron/extensions/agent.py:61 #, python-format msgid ""Agent %(id)s could not be found"" msgstr """" #: neutron/extensions/agent.py:65 #, python-format msgid ""Agent with agent_type=%(agent_type)s and host=%(host)s could not be found"" msgstr """" #: neutron/extensions/agent.py:70 #, python-format msgid ""Multiple agents with agent_type=%(agent_type)s and host=%(host)s found"" msgstr """" #: neutron/extensions/dhcpagentscheduler.py:121 #, python-format msgid ""Agent %(id)s is not a valid DHCP Agent or has been disabled"" msgstr """" #: neutron/extensions/dhcpagentscheduler.py:125 #, python-format msgid """" ""The network %(network_id)s has been already hosted by the DHCP Agent "" ""%(agent_id)s."" msgstr """" #: neutron/extensions/dhcpagentscheduler.py:130 #, python-format msgid ""The network %(network_id)s is not hosted by the DHCP agent %(agent_id)s."" msgstr """" #: neutron/extensions/extraroute.py:25 #, python-format msgid ""Invalid format for routes: %(routes)s, %(reason)s"" msgstr """" #: neutron/extensions/extraroute.py:29 #, python-format msgid """" ""Router interface for subnet %(subnet_id)s on router %(router_id)s cannot "" ""be deleted, as it is required by one or more routes."" msgstr """" #: neutron/extensions/extraroute.py:35 #, python-format msgid """" ""Unable to complete operation for %(router_id)s. The number of routes "" ""exceeds the maximum %(quota)s."" msgstr """" #: neutron/extensions/l3.py:35 #, python-format msgid ""Router %(router_id)s could not be found"" msgstr """" #: neutron/extensions/l3.py:39 #, python-format msgid ""Router %(router_id)s still has active ports"" msgstr """" #: neutron/extensions/l3.py:43 #, python-format msgid ""Router %(router_id)s does not have an interface with id %(port_id)s"" msgstr """" #: neutron/extensions/l3.py:48 #, python-format msgid ""Router %(router_id)s has no interface on subnet %(subnet_id)s"" msgstr """" #: neutron/extensions/l3.py:53 #, python-format msgid """" ""Router interface for subnet %(subnet_id)s on router %(router_id)s cannot "" ""be deleted, as it is required by one or more floating IPs."" msgstr """" #: neutron/extensions/l3.py:59 #, python-format msgid ""Floating IP %(floatingip_id)s could not be found"" msgstr """" #: neutron/extensions/l3.py:63 #, python-format msgid """" ""External network %(external_network_id)s is not reachable from subnet "" ""%(subnet_id)s. Therefore, cannot associate Port %(port_id)s with a "" ""Floating IP."" msgstr """" #: neutron/extensions/l3.py:69 #, python-format msgid """" ""Cannot associate floating IP %(floating_ip_address)s (%(fip_id)s) with "" ""port %(port_id)s using fixed IP %(fixed_ip)s, as that fixed IP already "" ""has a floating IP on external network %(net_id)s."" msgstr """" #: neutron/extensions/l3.py:76 #, python-format msgid """" ""Port %(port_id)s has owner %(device_owner)s and therefore cannot be "" ""deleted directly via the port API."" msgstr """" #: neutron/extensions/l3.py:81 #, python-format msgid """" ""External network %(net_id)s cannot be updated to be made non-external, "" ""since it has existing gateway ports"" msgstr """" #: neutron/extensions/l3.py:86 #, python-format msgid """" ""Gateway cannot be updated for router %(router_id)s, since a gateway to "" ""external network %(net_id)s is required by one or more floating IPs."" msgstr """" #: neutron/extensions/l3.py:156 msgid ""Number of routers allowed per tenant, -1 for unlimited"" msgstr """" #: neutron/extensions/l3.py:160 msgid ""Number of floating IPs allowed per tenant, -1 for unlimited"" msgstr """" #: neutron/extensions/l3_ext_gw_mode.py:27 #, python-format msgid """" ""DNat is disabled for the router %(router_id)s. Floating IPs cannot be "" ""associated."" msgstr """" #: neutron/extensions/l3agentscheduler.py:124 #, python-format msgid ""Agent %(id)s is not a L3 Agent or has been disabled"" msgstr """" #: neutron/extensions/l3agentscheduler.py:128 #, python-format msgid """" ""The router %(router_id)s has been already hosted by the L3 Agent "" ""%(agent_id)s."" msgstr """" #: neutron/extensions/l3agentscheduler.py:133 #, python-format msgid ""Failed scheduling router %(router_id)s to the L3 Agent %(agent_id)s."" msgstr """" #: neutron/extensions/l3agentscheduler.py:138 #, python-format msgid ""The router %(router_id)s is not hosted by L3 agent %(agent_id)s."" msgstr """" #: neutron/extensions/loadbalancer.py:33 #, python-format msgid ""Vip %(vip_id)s could not be found"" msgstr """" #: neutron/extensions/loadbalancer.py:37 #, python-format msgid ""Another Vip already exists for pool %(pool_id)s"" msgstr """" #: neutron/extensions/loadbalancer.py:41 #, python-format msgid ""Pool %(pool_id)s could not be found"" msgstr """" #: neutron/extensions/loadbalancer.py:45 #, python-format msgid ""Member %(member_id)s could not be found"" msgstr """" #: neutron/extensions/loadbalancer.py:49 #, python-format msgid ""Health_monitor %(monitor_id)s could not be found"" msgstr """" #: neutron/extensions/loadbalancer.py:53 #, python-format msgid ""Invalid state %(state)s of Loadbalancer resource %(id)s"" msgstr """" #: neutron/extensions/loadbalancer.py:57 #, python-format msgid ""Pool %(pool_id)s is still in use"" msgstr """" #: neutron/extensions/loadbalancer.py:61 #, python-format msgid ""Statistics of Pool %(pool_id)s could not be found"" msgstr """" #: neutron/extensions/loadbalancer.py:65 #, python-format msgid ""Protocol %(vip_proto)s does not match pool protocol %(pool_proto)s"" msgstr """" #: neutron/extensions/portsecurity.py:25 msgid """" ""Port has security group associated. Cannot disable port security or ip "" ""address until security group is removed"" msgstr """" #: neutron/extensions/portsecurity.py:30 msgid """" ""Port security must be enabled and port must have an IP address in order "" ""to use security groups."" msgstr """" #: neutron/extensions/portsecurity.py:35 msgid ""Port does not have port security binding."" msgstr """" #: neutron/extensions/providernet.py:56 msgid ""plugin does not support updating provider attributes"" msgstr """" #: neutron/extensions/quotasv2.py:87 msgid ""Non-admin is not authorised to access quotas for another tenant"" msgstr """" #: neutron/extensions/quotasv2.py:92 msgid ""Only admin can view or configure quota"" msgstr """" #: neutron/extensions/securitygroup.py:34 msgid ""For TCP/UDP protocols, port_range_min must be <= port_range_max"" msgstr """" #: neutron/extensions/securitygroup.py:39 #, python-format msgid ""Invalid value for port %(port)s"" msgstr """" #: neutron/extensions/securitygroup.py:43 #, python-format msgid """" ""Invalid value for ICMP %(field)s (%(attr)s) %(value)s. It must be 0 to "" ""255."" msgstr """" #: neutron/extensions/securitygroup.py:48 #, python-format msgid ""Security Group %(id)s in use."" msgstr """" #: neutron/extensions/securitygroup.py:52 msgid ""Removing default security group not allowed."" msgstr """" #: neutron/extensions/securitygroup.py:56 msgid ""Updating default security group not allowed."" msgstr """" #: neutron/extensions/securitygroup.py:60 msgid ""Default security group already exists."" msgstr """" #: neutron/extensions/securitygroup.py:64 #, python-format msgid """" ""Security group rule protocol %(protocol)s not supported. Only protocol "" ""values %(values)s and their integer representation (0 to 255) are "" ""supported."" msgstr """" #: neutron/extensions/securitygroup.py:70 msgid ""Multiple tenant_ids in bulk security group rule create not allowed"" msgstr """" #: neutron/extensions/securitygroup.py:75 msgid ""Only remote_ip_prefix or remote_group_id may be provided."" msgstr """" #: neutron/extensions/securitygroup.py:80 msgid ""Must also specifiy protocol if port range is given."" msgstr """" #: neutron/extensions/securitygroup.py:84 msgid ""Only allowed to update rules for one security profile at a time"" msgstr """" #: neutron/extensions/securitygroup.py:89 #, python-format msgid ""Security group %(id)s does not exist"" msgstr """" #: neutron/extensions/securitygroup.py:93 #, python-format msgid ""Security group rule %(id)s does not exist"" msgstr """" #: neutron/extensions/securitygroup.py:97 msgid ""Duplicate Security Group Rule in POST."" msgstr """" #: neutron/extensions/securitygroup.py:101 #, python-format msgid ""Security group rule already exists. Group id is %(id)s."" msgstr """" #: neutron/extensions/securitygroup.py:149 #, python-format msgid ""'%s' is not an integer or uuid"" msgstr """" #: neutron/extensions/securitygroup.py:226 msgid ""Number of security groups allowed per tenant,-1 for unlimited"" msgstr """" #: neutron/extensions/securitygroup.py:230 msgid ""Number of security rules allowed per tenant, -1 for unlimited"" msgstr """" #: neutron/extensions/servicetype.py:82 #, python-format msgid ""The service type '%s' does not exist"" msgstr """" #: neutron/extensions/servicetype.py:89 msgid """" ""No service type definition was provided. At least a service type "" ""definition must be provided"" msgstr """" #: neutron/extensions/servicetype.py:101 #, python-format msgid ""Required attributes missing in service definition: %s"" msgstr """" #: neutron/extensions/servicetype.py:103 neutron/extensions/servicetype.py:110 #: neutron/extensions/servicetype.py:117 neutron/extensions/servicetype.py:126 #: neutron/extensions/servicetype.py:131 neutron/extensions/servicetype.py:148 #: neutron/extensions/servicetype.py:156 #, python-format msgid ""%(f_name)s: %(msg)s"" msgstr """" #: neutron/extensions/servicetype.py:108 #, python-format msgid ""Service name '%s' unspecified or invalid"" msgstr """" #: neutron/extensions/servicetype.py:115 #, python-format msgid ""Plugin name not specified in service definition %s"" msgstr """" #: neutron/extensions/servicetype.py:125 #, python-format msgid ""No plugin for service '%s'"" msgstr """" #: neutron/extensions/servicetype.py:130 #, python-format msgid ""Plugin name '%s' is not correct "" msgstr """" #: neutron/extensions/servicetype.py:146 #, python-format msgid ""Unparseable attributes found in service definition %s"" msgstr """" #: neutron/extensions/servicetype.py:152 #, python-format msgid ""Exception while parsing service definition:%s"" msgstr """" #: neutron/extensions/servicetype.py:154 #, python-format msgid ""Was expecting a dict for service definition, found the following: %s"" msgstr """" #: neutron/extensions/servicetype.py:160 #: neutron/plugins/nicira/extensions/nvp_networkgw.py:86 #, python-format msgid ""%s: provided data are not iterable"" msgstr """" #: neutron/extensions/servicetype.py:171 msgid ""Neutron Service Type Management"" msgstr """" #: neutron/extensions/servicetype.py:179 msgid """" ""API for retrieving and managing service types for Neutron advanced "" ""services"" msgstr """" #: neutron/openstack/common/exception.py:104 msgid ""Uncaught exception"" msgstr """" #: neutron/openstack/common/excutils.py:48 #, python-format msgid ""Original exception being dropped: %s"" msgstr """" #: neutron/openstack/common/lockutils.py:102 #, python-format msgid ""Could not release the acquired lock `%s`"" msgstr """" #: neutron/openstack/common/lockutils.py:189 #, python-format msgid ""Got semaphore \""%(lock)s\"" for method \""%(method)s\""..."" msgstr """" #: neutron/openstack/common/lockutils.py:200 #, python-format msgid ""Attempting to grab file lock \""%(lock)s\"" for method \""%(method)s\""..."" msgstr """" #: neutron/openstack/common/lockutils.py:227 #, python-format msgid ""Got file lock \""%(lock)s\"" at %(path)s for method \""%(method)s\""..."" msgstr """" #: neutron/openstack/common/lockutils.py:235 #, python-format msgid ""Released file lock \""%(lock)s\"" at %(path)s for method \""%(method)s\""..."" msgstr """" #: neutron/openstack/common/log.py:244 #, python-format msgid ""Deprecated: %s"" msgstr """" #: neutron/openstack/common/log.py:336 #, python-format msgid ""Error loading logging config %(log_config)s: %(err_msg)s"" msgstr """" #: neutron/openstack/common/log.py:386 #, python-format msgid ""syslog facility must be one of: %s"" msgstr """" #: neutron/openstack/common/log.py:556 #, python-format msgid ""Fatal call to deprecated config: %(msg)s"" msgstr """" #: neutron/openstack/common/loopingcall.py:84 #, python-format msgid ""task run outlasted interval by %s sec"" msgstr """" #: neutron/openstack/common/loopingcall.py:91 msgid ""in fixed duration looping call"" msgstr """" #: neutron/openstack/common/loopingcall.py:131 #, python-format msgid ""Dynamic looping call sleeping for %.02f seconds"" msgstr """" #: neutron/openstack/common/loopingcall.py:138 msgid ""in dynamic looping call"" msgstr """" #: neutron/openstack/common/periodic_task.py:42 #, python-format msgid ""Unexpected argument for periodic task creation: %(arg)s."" msgstr """" #: neutron/openstack/common/periodic_task.py:133 #, python-format msgid ""Skipping periodic task %(task)s because its interval is negative"" msgstr """" #: neutron/openstack/common/periodic_task.py:138 #, python-format msgid ""Skipping periodic task %(task)s because it is disabled"" msgstr """" #: neutron/openstack/common/periodic_task.py:176 #, python-format msgid ""Running periodic task %(full_task_name)s"" msgstr """" #: neutron/openstack/common/periodic_task.py:184 #, python-format msgid ""Error during %(full_task_name)s: %(e)s"" msgstr """" #: neutron/openstack/common/policy.py:395 #, python-format msgid ""Failed to understand rule %(rule)s"" msgstr """" #: neutron/openstack/common/policy.py:405 #, python-format msgid ""No handler for matches of kind %s"" msgstr """" #: neutron/openstack/common/policy.py:680 #, python-format msgid ""Failed to understand rule %(rule)r"" msgstr """" #: neutron/openstack/common/processutils.py:127 #, python-format msgid ""Got unknown keyword args to utils.execute: %r"" msgstr """" #: neutron/openstack/common/processutils.py:142 #, python-format msgid ""Running cmd (subprocess): %s"" msgstr """" #: neutron/openstack/common/processutils.py:167 #: neutron/openstack/common/processutils.py:239 #, python-format msgid ""Result was %s"" msgstr """" #: neutron/openstack/common/processutils.py:179 #, python-format msgid ""%r failed. Retrying."" msgstr """" #: neutron/openstack/common/processutils.py:218 #, python-format msgid ""Running cmd (SSH): %s"" msgstr """" #: neutron/openstack/common/processutils.py:220 msgid ""Environment not supported over SSH"" msgstr """" #: neutron/openstack/common/processutils.py:224 msgid ""process_input not supported over SSH"" msgstr """" #: neutron/openstack/common/service.py:113 #: neutron/openstack/common/service.py:276 msgid ""Full set of CONF:"" msgstr """" #: neutron/openstack/common/service.py:122 #: neutron/openstack/common/service.py:219 #, python-format msgid ""Caught %s, exiting"" msgstr """" #: neutron/openstack/common/service.py:165 msgid ""Parent process has died unexpectedly, exiting"" msgstr """" #: neutron/openstack/common/service.py:201 msgid ""Forking too fast, sleeping"" msgstr """" #: neutron/openstack/common/service.py:224 msgid ""Unhandled exception"" msgstr """" #: neutron/openstack/common/service.py:231 #, python-format msgid ""Started child %d"" msgstr """" #: neutron/openstack/common/service.py:241 #, python-format msgid ""Starting %d workers"" msgstr """" #: neutron/openstack/common/service.py:258 #, python-format msgid ""Child %(pid)d killed by signal %(sig)d"" msgstr """" #: neutron/openstack/common/service.py:262 #, python-format msgid ""Child %(pid)s exited with status %(code)d"" msgstr """" #: neutron/openstack/common/service.py:266 #, python-format msgid ""pid %d not in child list"" msgstr """" #: neutron/openstack/common/service.py:294 #, python-format msgid ""Caught %s, stopping children"" msgstr """" #: neutron/openstack/common/service.py:305 #, python-format msgid ""Waiting on %d children to exit"" msgstr """" #: neutron/openstack/common/db/exception.py:44 msgid ""Invalid Parameter: Unicode is not supported by the current database."" msgstr """" #: neutron/openstack/common/db/sqlalchemy/session.py:544 msgid ""DB exception wrapped."" msgstr """" #: neutron/openstack/common/db/sqlalchemy/session.py:606 #, python-format msgid ""Got mysql server has gone away: %s"" msgstr """" #: neutron/openstack/common/db/sqlalchemy/session.py:686 #, python-format msgid ""SQL connection failed. %s attempts left."" msgstr """" #: neutron/openstack/common/db/sqlalchemy/utils.py:33 msgid ""Sort key supplied was not valid."" msgstr """" #: neutron/openstack/common/db/sqlalchemy/utils.py:72 msgid ""Id not in sort_keys; is sort_keys unique?"" msgstr """" #: neutron/openstack/common/db/sqlalchemy/utils.py:120 msgid ""Unknown sort direction, must be 'desc' or 'asc'"" msgstr """" #: neutron/openstack/common/notifier/api.py:125 #, python-format msgid ""%s not in valid priorities"" msgstr """" #: neutron/openstack/common/notifier/api.py:141 #, python-format msgid """" ""Problem '%(e)s' attempting to send to notification system. "" ""Payload=%(payload)s"" msgstr """" #: neutron/openstack/common/notifier/api.py:171 #, python-format msgid ""Failed to load notifier %s. These notifications will not be sent."" msgstr """" #: neutron/openstack/common/notifier/rabbit_notifier.py:27 msgid ""The rabbit_notifier is now deprecated. Please use rpc_notifier instead."" msgstr """" #: neutron/openstack/common/notifier/rpc_notifier.py:45 #: neutron/openstack/common/notifier/rpc_notifier2.py:51 #, python-format msgid ""Could not send notification to %(topic)s. Payload=%(message)s"" msgstr """" #: neutron/openstack/common/rpc/__init__.py:106 #, python-format msgid """" ""A RPC is being made while holding a lock. The locks currently held are "" ""%(locks)s. This is probably a bug. Please report it. Include the "" ""following: [%(stack)s]."" msgstr """" #: neutron/openstack/common/rpc/amqp.py:61 msgid ""Pool creating new connection"" msgstr """" #: neutron/openstack/common/rpc/amqp.py:186 #, python-format msgid ""No calling threads waiting for msg_id : %(msg_id)s, message : %(data)s"" msgstr """" #: neutron/openstack/common/rpc/amqp.py:189 #, python-format msgid ""_call_waiters: %s"" msgstr """" #: neutron/openstack/common/rpc/amqp.py:196 #, python-format msgid """" ""Number of call waiters is greater than warning threshhold: %d. There "" ""could be a MulticallProxyWaiter leak."" msgstr """" #: neutron/openstack/common/rpc/amqp.py:279 #, python-format msgid ""unpacked context: %s"" msgstr """" #: neutron/openstack/common/rpc/amqp.py:325 #, python-format msgid ""UNIQUE_ID is %s."" msgstr """" #: neutron/openstack/common/rpc/amqp.py:397 #, python-format msgid ""received %s"" msgstr """" #: neutron/openstack/common/rpc/amqp.py:405 #, python-format msgid ""no method for message: %s"" msgstr """" #: neutron/openstack/common/rpc/amqp.py:406 #, python-format msgid ""No method for message: %s"" msgstr """" #: neutron/openstack/common/rpc/amqp.py:434 #: neutron/openstack/common/rpc/impl_zmq.py:280 #, python-format msgid ""Expected exception during message handling (%s)"" msgstr """" #: neutron/openstack/common/rpc/amqp.py:442 #: neutron/openstack/common/rpc/impl_zmq.py:286 msgid ""Exception during message handling"" msgstr """" #: neutron/openstack/common/rpc/amqp.py:516 #, python-format msgid ""Making synchronous call on %s ..."" msgstr """" #: neutron/openstack/common/rpc/amqp.py:519 #, python-format msgid ""MSG_ID is %s"" msgstr """" #: neutron/openstack/common/rpc/amqp.py:545 #, python-format msgid ""Making asynchronous cast on %s..."" msgstr """" #: neutron/openstack/common/rpc/amqp.py:554 msgid ""Making asynchronous fanout cast..."" msgstr """" #: neutron/openstack/common/rpc/amqp.py:582 #, python-format msgid ""Sending %(event_type)s on %(topic)s"" msgstr """" #: neutron/openstack/common/rpc/common.py:77 msgid ""An unknown RPC related exception occurred."" msgstr """" #: neutron/openstack/common/rpc/common.py:89 msgid ""Exception in string format operation"" msgstr """" #: neutron/openstack/common/rpc/common.py:107 #, python-format msgid """" ""Remote error: %(exc_type)s %(value)s\n"" ""%(traceback)s."" msgstr """" #: neutron/openstack/common/rpc/common.py:124 #, python-format msgid """" ""Timeout while waiting on RPC response - topic: \""%(topic)s\"", RPC method:"" "" \""%(method)s\"" info: \""%(info)s\"""" msgstr """" #: neutron/openstack/common/rpc/common.py:141 #: neutron/openstack/common/rpc/common.py:142 #: neutron/openstack/common/rpc/common.py:143 msgid ""<unknown>"" msgstr """" #: neutron/openstack/common/rpc/common.py:147 #, python-format msgid ""Found duplicate message(%(msg_id)s). Skipping it."" msgstr """" #: neutron/openstack/common/rpc/common.py:151 msgid ""Invalid reuse of an RPC connection."" msgstr """" #: neutron/openstack/common/rpc/common.py:155 #, python-format msgid ""Specified RPC version, %(version)s, not supported by this endpoint."" msgstr """" #: neutron/openstack/common/rpc/common.py:160 #, python-format msgid """" ""Specified RPC envelope version, %(version)s, not supported by this "" ""endpoint."" msgstr """" #: neutron/openstack/common/rpc/common.py:165 #, python-format msgid ""Specified RPC version cap, %(version_cap)s, is too low"" msgstr """" #: neutron/openstack/common/rpc/common.py:288 #, python-format msgid ""Failed to sanitize %(item)s. Key error %(err)s"" msgstr """" #: neutron/openstack/common/rpc/common.py:310 #, python-format msgid ""Returning exception %s to caller"" msgstr """" #: neutron/openstack/common/rpc/impl_kombu.py:169 #: neutron/openstack/common/rpc/impl_qpid.py:153 msgid ""Failed to process message... skipping it."" msgstr """" #: neutron/openstack/common/rpc/impl_kombu.py:481 #, python-format msgid ""Reconnecting to AMQP server on %(hostname)s:%(port)d"" msgstr """" #: neutron/openstack/common/rpc/impl_kombu.py:503 #, python-format msgid ""Connected to AMQP server on %(hostname)s:%(port)d"" msgstr """" #: neutron/openstack/common/rpc/impl_kombu.py:540 #, python-format msgid """" ""Unable to connect to AMQP server on %(hostname)s:%(port)d after "" ""%(max_retries)d tries: %(err_str)s"" msgstr """" #: neutron/openstack/common/rpc/impl_kombu.py:556 #, python-format msgid """" ""AMQP server on %(hostname)s:%(port)d is unreachable: %(err_str)s. Trying "" ""again in %(sleep_time)d seconds."" msgstr """" #: neutron/openstack/common/rpc/impl_kombu.py:610 #: neutron/openstack/common/rpc/impl_qpid.py:457 #, python-format msgid ""Failed to declare consumer for topic '%(topic)s': %(err_str)s"" msgstr """" #: neutron/openstack/common/rpc/impl_kombu.py:628 #: neutron/openstack/common/rpc/impl_qpid.py:472 #, python-format msgid ""Timed out waiting for RPC response: %s"" msgstr """" #: neutron/openstack/common/rpc/impl_kombu.py:632 #: neutron/openstack/common/rpc/impl_qpid.py:476 #, python-format msgid ""Failed to consume message from queue: %s"" msgstr """" #: neutron/openstack/common/rpc/impl_kombu.py:671 #: neutron/openstack/common/rpc/impl_qpid.py:511 #, python-format msgid ""Failed to publish message to topic '%(topic)s': %(err_str)s"" msgstr """" #: neutron/openstack/common/rpc/impl_qpid.py:399 #, python-format msgid ""Unable to connect to AMQP server: %(e)s. Sleeping %(delay)s seconds"" msgstr """" #: neutron/openstack/common/rpc/impl_qpid.py:405 #, python-format msgid ""Connected to AMQP server on %s"" msgstr """" #: neutron/openstack/common/rpc/impl_qpid.py:418 msgid ""Re-established AMQP queues"" msgstr """" #: neutron/openstack/common/rpc/impl_qpid.py:484 msgid ""Error processing message. Skipping it."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:96 msgid ""JSON serialization failed."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:101 #, python-format msgid ""Deserializing: %s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:136 #, python-format msgid ""Connecting to %(addr)s with %(type)s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:137 #, python-format msgid ""-> Subscribed to %(subscribe)s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:138 #, python-format msgid ""-> bind: %(bind)s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:146 msgid ""Could not open socket."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:158 #, python-format msgid ""Subscribing to %s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:200 msgid ""You cannot recv on this socket."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:205 msgid ""You cannot send on this socket."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:267 #, python-format msgid ""Running func with context: %s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:305 msgid ""Sending reply"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:339 msgid ""RPC message did not include method."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:373 msgid ""Registering reactor"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:385 msgid ""In reactor registered"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:400 msgid ""Out reactor registered"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:404 msgid ""Consuming socket"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:454 #, python-format msgid ""Creating proxy for topic: %s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:460 msgid ""Topic contained dangerous characters."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:492 msgid ""Topic socket file creation failed."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:498 #, python-format msgid ""Local per-topic backlog buffer full for topic %(topic)s. Dropping message."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:514 #, python-format msgid ""Required IPC directory does not exist at %s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:524 #, python-format msgid ""Permission denied to IPC directory at %s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:527 msgid ""Could not create ZeroMQ receiver daemon. Socket may already be in use."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:561 #, python-format msgid ""CONSUMER RECEIVED DATA: %s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:563 #, python-format msgid ""ROUTER RELAY-OUT %(data)s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:585 msgid ""ZMQ Envelope version unsupported or unknown."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:613 msgid ""Skipping topic registration. Already registered."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:620 #, python-format msgid ""Consumer is a zmq.%s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:672 msgid ""Creating payload"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:685 msgid ""Creating queue socket for reply waiter"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:698 msgid ""Sending cast"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:701 msgid ""Cast sent; Waiting reply"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:704 #, python-format msgid ""Received message: %s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:705 msgid ""Unpacking response"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:714 msgid ""Unsupported or unknown ZMQ envelope returned."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:721 msgid ""RPC Message Invalid."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:744 #: neutron/plugins/midonet/plugin.py:42 #, python-format msgid ""%(msg)s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:747 #, python-format msgid ""Sending message(s) to: %s"" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:751 msgid ""No matchmaker results. Not casting."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:754 msgid ""No match from matchmaker."" msgstr """" #: neutron/openstack/common/rpc/impl_zmq.py:836 #, python-format msgid ""rpc_zmq_matchmaker = %(orig)s is deprecated; use %(new)s instead"" msgstr """" #: neutron/openstack/common/rpc/matchmaker.py:47 msgid ""Match not found by MatchMaker."" msgstr """" #: neutron/openstack/common/rpc/matchmaker.py:81 msgid ""Matchmaker does not implement registration or heartbeat."" msgstr """" #: neutron/openstack/common/rpc/matchmaker.py:217 #, python-format msgid ""Matchmaker unregistered: %(key)s, %(host)s"" msgstr """" #: neutron/openstack/common/rpc/matchmaker.py:229 msgid ""Register before starting heartbeat."" msgstr """" #: neutron/openstack/common/rpc/matchmaker_ring.py:79 #: neutron/openstack/common/rpc/matchmaker_ring.py:97 #, python-format msgid ""No key defining hosts for topic '%s', see ringfile"" msgstr """" #: neutron/openstack/common/rpc/service.py:48 #, python-format msgid ""Creating Consumer connection for Service %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:85 msgid """" ""A comma separated list of BigSwitch or Floodlight servers and port "" ""numbers. The plugin proxies the requests to the BigSwitch/Floodlight "" ""server, which performs the networking configuration. Note that only one "" ""server is needed per deployment, but you may wish to deploy multiple "" ""servers to support failover."" msgstr """" #: neutron/plugins/bigswitch/plugin.py:92 msgid """" ""The username and password for authenticating against the BigSwitch or "" ""Floodlight controller."" msgstr """" #: neutron/plugins/bigswitch/plugin.py:95 msgid """" ""If True, Use SSL when connecting to the BigSwitch or Floodlight "" ""controller."" msgstr """" #: neutron/plugins/bigswitch/plugin.py:98 msgid ""Sync data on connect"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:100 msgid """" ""Maximum number of seconds to wait for proxy request to connect and "" ""complete."" msgstr """" #: neutron/plugins/bigswitch/plugin.py:104 msgid ""User defined identifier for this Neutron deployment"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:106 msgid """" ""Flag to decide if a route to the metadata server should be injected into "" ""the VM"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:115 msgid """" ""The default router rules installed in new tenant routers. Repeat the "" ""config option for each rule. Format is "" ""<tenant>:<source>:<destination>:<action> Use an * to specify default for "" ""all tenants."" msgstr """" #: neutron/plugins/bigswitch/plugin.py:120 msgid ""Maximum number of router rules"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:127 msgid ""Virtual interface type to configure on Nova compute nodes"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:134 #, python-format msgid ""Nova compute nodes to manually set VIF type to %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:168 msgid ""Error in REST call to remote network controller"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:204 #, python-format msgid """" ""ServerProxy: server=%(server)s, port=%(port)d, ssl=%(ssl)r, "" ""action=%(action)s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:208 #, python-format msgid ""ServerProxy: resource=%(resource)s, data=%(data)r, headers=%(headers)r"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:217 msgid ""ServerProxy: Could not establish HTTPS connection"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:224 msgid ""ServerProxy: Could not establish HTTP connection"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:241 #, python-format msgid ""ServerProxy: %(action)s failure, %(e)r"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:245 #, python-format msgid """" ""ServerProxy: status=%(status)d, reason=%(reason)r, ret=%(ret)s, "" ""data=%(data)r"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:295 #, python-format msgid ""ServerProxy: %(action)s failure for servers: %(server)r"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:303 #, python-format msgid ""ServerProxy: %(action)s failure for all servers: %(server)r"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:337 #, python-format msgid ""NeutronRestProxy: Starting plugin. Version=%s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:379 msgid ""NeutronRestProxyV2: initialization done"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:405 msgid ""NeutronRestProxyV2: create_network() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:430 #, python-format msgid ""NeutronRestProxyV2:Unable to create remote network: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:462 msgid ""NeutronRestProxyV2.update_network() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:479 #: neutron/plugins/bigswitch/plugin.py:527 #: neutron/plugins/bigswitch/plugin.py:1281 #, python-format msgid ""NeutronRestProxyV2: Unable to update remote network: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:500 msgid ""NeutronRestProxyV2: delete_network() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:557 msgid ""NeutronRestProxyV2: create_port() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:592 #: neutron/plugins/bigswitch/plugin.py:683 #, python-format msgid ""NeutronRestProxyV2: Unable to create remote port: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:647 msgid ""NeutronRestProxyV2: update_port() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:704 msgid ""NeutronRestProxyV2: delete_port() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:738 #: neutron/plugins/bigswitch/plugin.py:796 #, python-format msgid ""NeutronRestProxyV2: Unable to update remote port: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:755 msgid ""NeutronRestProxyV2: _plug_interface() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:773 #, python-format msgid ""NeutronRestProxyV2:Unable to update remote network: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:787 msgid ""NeutronRestProxyV2: _unplug_interface() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:801 msgid ""NeutronRestProxyV2: create_subnet() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:822 msgid ""NeutronRestProxyV2: update_subnet() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:845 msgid ""NeutronRestProxyV2: delete_subnet() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:886 msgid ""NeutronRestProxyV2: create_router() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:911 #, python-format msgid ""NeutronRestProxyV2: Unable to create remote router: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:922 msgid ""NeutronRestProxyV2.update_router() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:944 #, python-format msgid ""NeutronRestProxyV2: Unable to update remote router: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:956 msgid ""NeutronRestProxyV2: delete_router() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:987 #, python-format msgid ""NeutronRestProxyV2: Unable to delete remote router: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:993 msgid ""NeutronRestProxyV2: add_router_interface() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:1021 #, python-format msgid ""NeutronRestProxyV2: Unable to create interface: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:1032 msgid ""NeutronRestProxyV2: remove_router_interface() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:1065 #, python-format msgid ""NeutronRestProxyV2:Unable to delete remote intf: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:1073 msgid ""NeutronRestProxyV2: create_floatingip() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:1086 #, python-format msgid ""NeutronRestProxyV2: Unable to create remote floatin IP: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:1096 msgid ""NeutronRestProxyV2: update_floatingip() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:1119 msgid ""NeutronRestProxyV2: delete_floatingip() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:1202 #, python-format msgid ""NeutronRestProxy: Unable to update remote topology: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:1298 #, python-format msgid """" ""Setting admin_state_up=False is not supported in this plugin version. "" ""Ignoring setting for resource: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:1304 #, python-format msgid """" ""Operational status is internally set by the plugin. Ignoring setting "" ""status=%s."" msgstr """" #: neutron/plugins/bigswitch/plugin.py:1331 #, python-format msgid ""Unrecognized vif_type in configuration [%s]. Defaulting to ovs. "" msgstr """" #: neutron/plugins/bigswitch/db/porttracker_db.py:43 msgid ""No host_id in port request to track port location."" msgstr """" #: neutron/plugins/bigswitch/db/porttracker_db.py:46 #, python-format msgid ""Received an empty port ID for host '%s'"" msgstr """" #: neutron/plugins/bigswitch/extensions/routerrule.py:30 #, python-format msgid ""Invalid format for router rules: %(rule)s, %(reason)s"" msgstr """" #: neutron/plugins/bigswitch/extensions/routerrule.py:34 #, python-format msgid """" ""Unable to complete rules update for %(router_id)s. The number of rules "" ""exceeds the maximum %(quota)s."" msgstr """" #: neutron/plugins/bigswitch/extensions/routerrule.py:50 #, python-format msgid ""Invalid data format for router rule: '%s'"" msgstr """" #: neutron/plugins/bigswitch/extensions/routerrule.py:82 #, python-format msgid ""Duplicate nexthop in rule '%s'"" msgstr """" #: neutron/plugins/bigswitch/extensions/routerrule.py:90 #, python-format msgid ""Action must be either permit or deny. '%s' was provided"" msgstr """" #: neutron/plugins/bigswitch/extensions/routerrule.py:102 #, python-format msgid ""Duplicate router rules (src,dst) found '%s'"" msgstr """" #: neutron/plugins/brocade/NeutronPlugin.py:123 #: neutron/plugins/hyperv/rpc_callbacks.py:53 #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:85 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:96 #, python-format msgid ""Device %(device)s details requested from %(agent_id)s"" msgstr """" #: neutron/plugins/brocade/NeutronPlugin.py:137 #: neutron/plugins/brocade/NeutronPlugin.py:154 #: neutron/plugins/hyperv/rpc_callbacks.py:69 #: neutron/plugins/hyperv/rpc_callbacks.py:88 #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:108 #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:128 #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:143 #: neutron/plugins/mlnx/rpc_callbacks.py:108 #: neutron/plugins/mlnx/rpc_callbacks.py:123 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:114 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:134 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:149 #, python-format msgid ""%s can not be found in database"" msgstr """" #: neutron/plugins/brocade/NeutronPlugin.py:279 #: neutron/plugins/brocade/NeutronPlugin.py:322 #: neutron/plugins/brocade/NeutronPlugin.py:372 msgid ""Brocade NOS driver:"" msgstr """" #: neutron/plugins/brocade/NeutronPlugin.py:280 #: neutron/plugins/brocade/NeutronPlugin.py:323 #: neutron/plugins/brocade/NeutronPlugin.py:373 #, python-format msgid ""%s"" msgstr """" #: neutron/plugins/brocade/NeutronPlugin.py:281 #, python-format msgid ""Returning the allocated vlan (%d) to the pool"" msgstr """" #: neutron/plugins/brocade/NeutronPlugin.py:289 #, python-format msgid ""Allocated vlan (%d) from the pool"" msgstr """" #: neutron/plugins/brocade/nos/nosdriver.py:63 #, python-format msgid ""Connect failed to switch: %s"" msgstr """" #: neutron/plugins/brocade/nos/nosdriver.py:66 #, python-format msgid ""Connect success to host %(host)s:%(ssh_port)d"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:75 #, python-format msgid ""Model %s manages state"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:88 msgid ""Plugin initialization complete"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:134 #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:205 msgid ""create_network() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:151 #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:226 msgid ""update_network() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:164 msgid ""delete_network() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:187 msgid ""get_network() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:192 msgid ""get_networks() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:197 #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:282 msgid ""create_port() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:207 #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:368 msgid ""delete_port() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:226 #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:327 msgid ""update_port() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:237 msgid ""create_subnet() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:249 #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:266 msgid ""update_subnet() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:255 msgid ""delete_subnet() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:278 #: neutron/plugins/cisco/db/network_db_v2.py:128 msgid ""get_all_qoss() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:284 msgid ""get_qos_details() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:294 msgid ""create_qos() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:300 msgid ""delete_qos() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:310 msgid ""rename_qos() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:321 msgid ""get_all_credentials() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:327 msgid ""get_credential_details() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:338 msgid ""create_credential() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:345 msgid ""delete_credential() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:356 msgid ""rename_credential() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:367 msgid ""schedule_host() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:379 msgid ""associate_port() called"" msgstr """" #: neutron/plugins/cisco/network_plugin.py:386 msgid ""detach_port() called"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:27 #, python-format msgid ""Segmentation ID for network %(net_id)s is not found."" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:32 msgid """" ""Unable to complete operation. No more dynamic nics are available in the "" ""system."" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:38 #, python-format msgid """" ""NetworkVlanBinding for %(vlan_id)s and network %(network_id)s already "" ""exists"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:44 #, python-format msgid ""Vlan ID %(vlan_id)s not found"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:49 msgid ""No Vlan ID available"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:54 #, python-format msgid ""QoS level %(qos_id)s could not be found for tenant %(tenant_id)s"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:60 #, python-format msgid ""QoS level with name %(qos_name)s already exists for tenant %(tenant_id)s"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:66 #, python-format msgid ""Credential %(credential_id)s could not be found for tenant %(tenant_id)s"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:72 #, python-format msgid ""Credential %(credential_name)s could not be found for tenant %(tenant_id)s"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:78 #, python-format msgid ""Credential %(credential_id)s already exists for tenant %(tenant_id)s"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:84 #, python-format msgid ""Connection to %(host)s is not configured."" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:89 #, python-format msgid ""Unable to connect to Nexus %(nexus_host)s. Reason: %(exc)s."" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:94 #, python-format msgid ""Failed to configure Nexus: %(config)s. Reason: %(exc)s."" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:99 #, python-format msgid ""Nexus Port Binding (%(filters)s) is not present"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:108 msgid ""No usable Nexus switch found to create SVI interface"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:113 #, python-format msgid ""PortVnic Binding %(port_id)s already exists"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:118 #, python-format msgid ""PortVnic Binding %(port_id)s is not present"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:123 msgid ""No subnet_id specified for router gateway"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:128 #, python-format msgid ""Subnet %(subnet_id)s has an interface on %(router_id)s"" msgstr """" #: neutron/plugins/cisco/common/cisco_exceptions.py:133 msgid ""Nexus hardware router gateway only uses Subnet Ids"" msgstr """" #: neutron/plugins/cisco/common/cisco_faults.py:74 msgid ""Port not Found"" msgstr """" #: neutron/plugins/cisco/common/cisco_faults.py:75 msgid ""Unable to find a port with the specified identifier."" msgstr """" #: neutron/plugins/cisco/common/cisco_faults.py:89 msgid ""Credential Not Found"" msgstr """" #: neutron/plugins/cisco/common/cisco_faults.py:90 msgid ""Unable to find a Credential with the specified identifier."" msgstr """" #: neutron/plugins/cisco/common/cisco_faults.py:105 msgid ""QoS Not Found"" msgstr """" #: neutron/plugins/cisco/common/cisco_faults.py:106 msgid ""Unable to find a QoS with the specified identifier."" msgstr """" #: neutron/plugins/cisco/common/cisco_faults.py:121 msgid ""Nova tenant Not Found"" msgstr """" #: neutron/plugins/cisco/common/cisco_faults.py:122 msgid ""Unable to find a Novatenant with the specified identifier."" msgstr """" #: neutron/plugins/cisco/common/cisco_faults.py:137 msgid ""Requested State Invalid"" msgstr """" #: neutron/plugins/cisco/common/cisco_faults.py:138 msgid ""Unable to update port state with specified value."" msgstr """" #: neutron/plugins/cisco/common/config.py:26 msgid ""Virtual Switch to use"" msgstr """" #: neutron/plugins/cisco/common/config.py:30 msgid ""Nexus Switch to use"" msgstr """" #: neutron/plugins/cisco/common/config.py:36 msgid ""VLAN start value"" msgstr """" #: neutron/plugins/cisco/common/config.py:38 msgid ""VLAN end value"" msgstr """" #: neutron/plugins/cisco/common/config.py:40 msgid ""VLAN Name prefix"" msgstr """" #: neutron/plugins/cisco/common/config.py:42 msgid ""Maximum Port value"" msgstr """" #: neutron/plugins/cisco/common/config.py:44 msgid ""Maximum Port Profile value"" msgstr """" #: neutron/plugins/cisco/common/config.py:46 msgid ""Maximum Network value"" msgstr """" #: neutron/plugins/cisco/common/config.py:48 msgid ""Distribute SVI interfaces over all switches"" msgstr """" #: neutron/plugins/cisco/common/config.py:52 msgid ""Model Class"" msgstr """" #: neutron/plugins/cisco/common/config.py:56 msgid ""Manager Class"" msgstr """" #: neutron/plugins/cisco/common/config.py:60 msgid ""Nexus Driver Name"" msgstr """" #: neutron/plugins/cisco/db/network_db_v2.py:34 msgid ""create_vlanids() called"" msgstr """" #: neutron/plugins/cisco/db/network_db_v2.py:53 #: neutron/plugins/cisco/db/network_db_v2.py:120 msgid ""get_all_vlanids() called"" msgstr """" #: neutron/plugins/cisco/db/network_db_v2.py:60 msgid ""is_vlanid_used() called"" msgstr """" #: neutron/plugins/cisco/db/network_db_v2.py:72 msgid ""release_vlanid() called"" msgstr """" #: neutron/plugins/cisco/db/network_db_v2.py:87 msgid ""delete_vlanid() called"" msgstr """" #: neutron/plugins/cisco/db/network_db_v2.py:101 msgid ""reserve_vlanid() called"" msgstr """" #: neutron/plugins/cisco/db/network_db_v2.py:136 msgid ""get_qos() called"" msgstr """" #: neutron/plugins/cisco/db/network_db_v2.py:150 msgid ""add_qos() called"" msgstr """" #: neutron/plugins/cisco/db/nexus_db_v2.py:34 msgid ""get_all_nexusport_bindings() called"" msgstr """" #: neutron/plugins/cisco/db/nexus_db_v2.py:41 msgid ""get_nexusport_binding() called"" msgstr """" #: neutron/plugins/cisco/db/nexus_db_v2.py:56 msgid ""get_nexusvlan_binding() called"" msgstr """" #: neutron/plugins/cisco/db/nexus_db_v2.py:70 msgid ""add_nexusport_binding() called"" msgstr """" #: neutron/plugins/cisco/db/nexus_db_v2.py:81 msgid ""remove_nexusport_binding() called"" msgstr """" #: neutron/plugins/cisco/db/nexus_db_v2.py:96 msgid ""update_nexusport_binding called"" msgstr """" #: neutron/plugins/cisco/db/nexus_db_v2.py:112 msgid ""get_nexusvm_binding() called"" msgstr """" #: neutron/plugins/cisco/db/nexus_db_v2.py:126 msgid ""get_port_vlan_switch_binding() called"" msgstr """" #: neutron/plugins/cisco/db/nexus_db_v2.py:140 #, python-format msgid """" ""get_port_switch_bindings() called, port:'%(port_id)s', "" ""switch:'%(switch_ip)s'"" msgstr """" #: neutron/plugins/cisco/db/nexus_db_v2.py:155 msgid ""get_nexussvi_bindings() called"" msgstr """" #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:73 #, python-format msgid ""Loaded device plugin %s\n"" msgstr """" #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:91 #, python-format msgid ""%(module)s.%(name)s init done"" msgstr """" #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:131 #, python-format msgid ""No %s Plugin loaded"" msgstr """" #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:132 #, python-format msgid ""%(plugin_key)s: %(function_name)s with args %(args)s ignored"" msgstr """" #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:349 #, python-format msgid ""Unable to update port '%s' on Nexus switch"" msgstr """" #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:403 msgid ""Nexus plugin loaded, creating SVI on switch"" msgstr """" #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:424 #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:451 msgid ""No Nexus plugin, sending to vswitch"" msgstr """" #: neutron/plugins/cisco/models/virt_phy_sw_v2.py:439 msgid ""Nexus plugin loaded, deleting SVI from switch"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_network_driver_v2.py:131 #: neutron/plugins/cisco/nexus/cisco_nexus_network_driver_v2.py:138 #: neutron/plugins/cisco/nexus/cisco_nexus_network_driver_v2.py:155 #: neutron/plugins/cisco/nexus/cisco_nexus_network_driver_v2.py:166 #: neutron/plugins/cisco/nexus/cisco_nexus_network_driver_v2.py:240 #: neutron/plugins/cisco/nexus/cisco_nexus_network_driver_v2.py:250 #, python-format msgid ""NexusDriver: %s"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_network_driver_v2.py:182 #, python-format msgid ""NexusDriver VLAN IDs: %s"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:50 #, python-format msgid ""Loaded driver %s"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:70 msgid ""NexusPlugin:get_all_networks() called"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:80 msgid ""NexusPlugin:create_network() called"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:208 msgid ""Grabbing a switch to create SVI"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:210 msgid ""Using round robin to create SVI"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:229 msgid ""No round robin or zero weights, using first switch"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:240 msgid ""NexusPlugin:delete_network() called"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:244 msgid ""NexusPlugin:get_network_details() called"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:250 msgid ""NexusPlugin:update_network() called"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:258 msgid ""NexusPlugin:get_all_ports() called"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:266 msgid ""NexusPlugin:create_port() called"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:274 msgid ""NexusPlugin:delete_port() called"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:322 msgid ""NexusPlugin:update_port() called"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:330 msgid ""NexusPlugin:get_port_details() called"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:339 msgid ""NexusPlugin:plug_interface() called"" msgstr """" #: neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py:347 msgid ""NexusPlugin:unplug_interface() called"" msgstr """" #: neutron/plugins/common/utils.py:31 #, python-format msgid ""%s is not a valid VLAN tag"" msgstr """" #: neutron/plugins/common/utils.py:35 msgid ""End of VLAN range is less than start of VLAN range"" msgstr """" #: neutron/plugins/hyperv/db.py:41 #: neutron/plugins/linuxbridge/db/l2network_db_v2.py:117 #: neutron/plugins/openvswitch/ovs_db_v2.py:135 #, python-format msgid """" ""Reserving vlan %(vlan_id)s on physical network %(physical_network)s from "" ""pool"" msgstr """" #: neutron/plugins/hyperv/db.py:56 #, python-format msgid ""Reserving flat physical network %(physical_network)s from pool"" msgstr """" #: neutron/plugins/hyperv/db.py:79 #: neutron/plugins/linuxbridge/db/l2network_db_v2.py:140 #: neutron/plugins/ml2/drivers/type_vlan.py:206 #: neutron/plugins/openvswitch/ovs_db_v2.py:159 #, python-format msgid """" ""Reserving specific vlan %(vlan_id)s on physical network "" ""%(physical_network)s from pool"" msgstr """" #: neutron/plugins/hyperv/db.py:136 #, python-format msgid ""Releasing vlan %(vlan_id)s on physical network %(physical_network)s"" msgstr """" #: neutron/plugins/hyperv/db.py:141 #: neutron/plugins/linuxbridge/db/l2network_db_v2.py:181 #: neutron/plugins/openvswitch/ovs_db_v2.py:200 #, python-format msgid ""vlan_id %(vlan_id)s on physical network %(physical_network)s not found"" msgstr """" #: neutron/plugins/hyperv/db.py:166 neutron/plugins/hyperv/db.py:179 #: neutron/plugins/linuxbridge/db/l2network_db_v2.py:68 #: neutron/plugins/linuxbridge/db/l2network_db_v2.py:87 #: neutron/plugins/ml2/drivers/type_vlan.py:128 #: neutron/plugins/ml2/drivers/type_vlan.py:149 #: neutron/plugins/openvswitch/ovs_db_v2.py:91 #: neutron/plugins/openvswitch/ovs_db_v2.py:109 #, python-format msgid """" ""Removing vlan %(vlan_id)s on physical network %(physical_network)s from "" ""pool"" msgstr """" #: neutron/plugins/hyperv/hyperv_neutron_plugin.py:42 msgid ""Network type for tenant networks (local, flat, vlan or none)"" msgstr """" #: neutron/plugins/hyperv/hyperv_neutron_plugin.py:46 #: neutron/plugins/linuxbridge/common/config.py:34 #: neutron/plugins/mlnx/common/config.py:32 #: neutron/plugins/openvswitch/common/config.py:51 msgid ""List of <physical_network>:<vlan_min>:<vlan_max> or <physical_network>"" msgstr """" #: neutron/plugins/hyperv/hyperv_neutron_plugin.py:74 #: neutron/plugins/hyperv/hyperv_neutron_plugin.py:96 #, python-format msgid ""segmentation_id specified for %s network"" msgstr """" #: neutron/plugins/hyperv/hyperv_neutron_plugin.py:81 #, python-format msgid ""physical_network specified for %s network"" msgstr """" #: neutron/plugins/hyperv/hyperv_neutron_plugin.py:123 msgid ""physical_network not provided"" msgstr """" #: neutron/plugins/hyperv/hyperv_neutron_plugin.py:172 #, python-format msgid ""Invalid tenant_network_type: %s. Agent terminated!"" msgstr """" #: neutron/plugins/hyperv/hyperv_neutron_plugin.py:194 #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:281 #: neutron/plugins/ml2/drivers/type_vlan.py:94 #: neutron/plugins/mlnx/mlnx_plugin.py:107 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:328 #, python-format msgid ""Network VLAN ranges: %s"" msgstr """" #: neutron/plugins/hyperv/hyperv_neutron_plugin.py:219 #, python-format msgid ""Network type %s not supported"" msgstr """" #: neutron/plugins/hyperv/hyperv_neutron_plugin.py:245 #: neutron/plugins/metaplugin/meta_neutron_plugin.py:174 #: neutron/plugins/mlnx/mlnx_plugin.py:271 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:475 #, python-format msgid ""Created network: %s"" msgstr """" #: neutron/plugins/hyperv/rpc_callbacks.py:77 #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:116 #: neutron/plugins/mlnx/rpc_callbacks.py:97 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:122 #, python-format msgid ""Device %(device)s no longer exists on %(agent_id)s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:44 msgid """" ""List of <physical_network>:<vswitch> where the physical networks can be "" ""expressed with wildcards, e.g.: .\""*:external\"""" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:50 msgid ""Private vswitch name used for local networks"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:52 #: neutron/plugins/linuxbridge/common/config.py:46 #: neutron/plugins/mlnx/common/config.py:54 #: neutron/plugins/nec/common/config.py:31 #: neutron/plugins/openvswitch/common/config.py:63 #: neutron/plugins/ryu/common/config.py:45 msgid """" ""The number of seconds the agent will wait between polling for local "" ""device changes."" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:95 #, python-format msgid ""Invalid physical network mapping: %s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:116 #, python-format msgid ""network_delete received. Deleting network %s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:122 #, python-format msgid ""Network %s not defined on agent."" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:125 msgid ""port_delete received"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:130 #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:432 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:168 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:260 msgid ""port_update received"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:151 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:130 #, python-format msgid ""Provisioning network %s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:164 #, python-format msgid """" ""Cannot provision unknown network type %(network_type)s for network "" ""%(net_uuid)s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:176 #, python-format msgid ""Reclaiming local network %s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:184 #, python-format msgid ""Binding port %s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:197 #, python-format msgid ""Binding VLAN ID %(segmentation_id)s to switch port %(port_id)s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:210 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:115 #, python-format msgid ""Unsupported network type %s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:215 #, python-format msgid ""Network %s is not avalailable on this agent"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:219 #, python-format msgid ""Unbinding port %s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:245 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:187 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:289 #, python-format msgid ""No port %s defined on agent."" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:250 #, python-format msgid ""Adding port %s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:257 #, python-format msgid ""Unable to get port details for device %(device)s: %(e)s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:263 #, python-format msgid ""Port %(device)s updated. Details: %(device_details)s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:278 #, python-format msgid ""Removing port %s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:285 #, python-format msgid ""Removing port failed for device %(device)s: %(e)s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:310 #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:640 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:352 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:733 msgid ""Agent out of sync with plugin!"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:318 #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:652 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:359 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:746 msgid ""Agent loop has new devices!"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:323 #, python-format msgid ""Error in agent event loop: %s"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:331 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:371 #, python-format msgid ""Loop iteration exceeded interval (%(polling_interval)s vs. %(elapsed)s)"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:345 #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:691 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:867 msgid ""Agent initialized successfully, now running... "" msgstr """" #: neutron/plugins/hyperv/agent/utils.py:38 #, python-format msgid ""HyperVException: %(msg)s"" msgstr """" #: neutron/plugins/hyperv/agent/utils.py:76 #, python-format msgid ""Vnic not found: %s"" msgstr """" #: neutron/plugins/hyperv/agent/utils.py:112 #, python-format msgid ""Job failed with error %d"" msgstr """" #: neutron/plugins/hyperv/agent/utils.py:131 #, python-format msgid """" ""WMI job failed with status %(job_state)d. Error details: %(err_sum_desc)s"" "" - %(err_desc)s - Error code: %(err_code)d"" msgstr """" #: neutron/plugins/hyperv/agent/utils.py:140 #, python-format msgid ""WMI job failed with status %(job_state)d. Error details: %(error)s"" msgstr """" #: neutron/plugins/hyperv/agent/utils.py:144 #, python-format msgid ""WMI job failed with status %d. No error description available"" msgstr """" #: neutron/plugins/hyperv/agent/utils.py:149 #, python-format msgid ""WMI job succeeded: %(desc)s, Elapsed=%(elap)s"" msgstr """" #: neutron/plugins/hyperv/agent/utils.py:163 #, python-format msgid ""Failed creating port for %s"" msgstr """" #: neutron/plugins/hyperv/agent/utils.py:183 #, python-format msgid """" ""Failed to disconnect port %(switch_port_name)s from switch "" ""%(vswitch_name)s with error %(ret_val)s"" msgstr """" #: neutron/plugins/hyperv/agent/utils.py:194 #, python-format msgid """" ""Failed to delete port %(switch_port_name)s from switch %(vswitch_name)s "" ""with error %(ret_val)s"" msgstr """" #: neutron/plugins/hyperv/agent/utils.py:201 #, python-format msgid ""VSwitch not found: %s"" msgstr """" #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:135 #: neutron/plugins/mlnx/rpc_callbacks.py:115 #, python-format msgid ""Device %(device)s up %(agent_id)s"" msgstr """" #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:247 #: neutron/plugins/mlnx/mlnx_plugin.py:136 #, python-format msgid ""Invalid tenant_network_type: %s. Service terminated!"" msgstr """" #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:258 msgid ""Linux Bridge Plugin initialization complete"" msgstr """" #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:279 #, python-format msgid ""%s. Agent terminated!"" msgstr """" #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:320 #: neutron/plugins/mlnx/mlnx_plugin.py:155 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:374 msgid ""provider:network_type required"" msgstr """" #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:324 #: neutron/plugins/mlnx/mlnx_plugin.py:180 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:378 msgid ""provider:segmentation_id specified for flat network"" msgstr """" #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:330 #: neutron/plugins/mlnx/mlnx_plugin.py:185 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:384 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:403 msgid ""provider:segmentation_id required"" msgstr """" #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:333 #: neutron/plugins/mlnx/mlnx_plugin.py:188 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:387 #, python-format msgid ""provider:segmentation_id out of range (%(min_id)s through %(max_id)s)"" msgstr """" #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:340 #: neutron/plugins/mlnx/mlnx_plugin.py:196 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:407 msgid ""provider:physical_network specified for local network"" msgstr """" #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:346 #: neutron/plugins/mlnx/mlnx_plugin.py:200 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:413 msgid ""provider:segmentation_id specified for local network"" msgstr """" #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:352 #: neutron/plugins/mlnx/mlnx_plugin.py:171 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:419 #, python-format msgid ""provider:network_type %s not supported"" msgstr """" #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:358 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:425 #, python-format msgid ""Unknown provider:physical_network %s"" msgstr """" #: neutron/plugins/linuxbridge/lb_neutron_plugin.py:364 #: neutron/plugins/mlnx/mlnx_plugin.py:218 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:431 msgid ""provider:physical_network required"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:89 msgid ""Invalid Network ID, will lead to incorrect bridgename"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:96 msgid ""Invalid VLAN ID, will lead to incorrect subinterface name"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:103 msgid ""Invalid Interface ID, will lead to incorrect tap device name"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:171 #, python-format msgid """" ""Creating subinterface %(interface)s for VLAN %(vlan_id)s on interface "" ""%(physical_interface)s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:184 #, python-format msgid ""Done creating subinterface %s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:219 #, python-format msgid ""Starting bridge %(bridge_name)s for subinterface %(interface)s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:234 #, python-format msgid ""Done starting bridge %(bridge_name)s for subinterface %(interface)s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:250 #, python-format msgid ""Unable to add %(interface)s to %(bridge_name)s! Exception: %(e)s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:263 #, python-format msgid ""No mapping for physical network %s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:272 #, python-format msgid ""Unknown network_type %(network_type)s for network %(network_id)s."" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:284 #, python-format msgid ""Tap device: %s does not exist on this host, skipped"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:302 #, python-format msgid ""Adding device %(tap_device_name)s to bridge %(bridge_name)s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:311 #, python-format msgid ""%(tap_device_name)s already exists on bridge %(bridge_name)s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:340 #, python-format msgid ""Deleting bridge %s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:347 #, python-format msgid ""Done deleting bridge %s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:350 #, python-format msgid ""Cannot delete bridge %s, does not exist"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:357 #, python-format msgid ""Removing device %(interface_name)s from bridge %(bridge_name)s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:364 #, python-format msgid ""Done removing device %(interface_name)s from bridge %(bridge_name)s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:370 #, python-format msgid """" ""Cannot remove device %(interface_name)s bridge %(bridge_name)s does not "" ""exist"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:378 #, python-format msgid ""Deleting subinterface %s for vlan"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:385 #, python-format msgid ""Done deleting subinterface %s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:425 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:159 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:249 msgid ""network_delete received"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:473 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:285 #, python-format msgid ""RPC timeout while updating port %s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:525 msgid ""Unable to obtain MAC address for unique ID. Agent terminated!"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:529 #: neutron/plugins/nec/agent/nec_neutron_agent.py:145 #, python-format msgid ""RPC agent_id: %s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:575 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:643 #, python-format msgid ""Port %s added"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:581 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:649 #, python-format msgid ""Unable to get port details for %(device)s: %(e)s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:587 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:656 #, python-format msgid ""Port %(device)s updated. Details: %(details)s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:608 #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:628 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:339 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:665 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:688 #, python-format msgid ""Device %s not defined on plugin"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:615 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:674 #, python-format msgid ""Attachment %s removed"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:621 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:680 #, python-format msgid ""port_removed failed for %(device)s: %(e)s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:625 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:336 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:685 #, python-format msgid ""Port %s updated."" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:635 msgid ""LinuxBridge Agent RPC Daemon Started!"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:647 msgid ""Update devices failed"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:658 #, python-format msgid ""Error in agent loop. Devices info: %s"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:666 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:761 #: neutron/plugins/ryu/agent/ryu_neutron_agent.py:269 #, python-format msgid ""Loop iteration exceeded interval (%(polling_interval)s vs. %(elapsed)s)!"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:681 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:386 #, python-format msgid ""Parsing physical_interface_mappings failed: %s. Agent terminated!"" msgstr """" #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:684 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:389 #, python-format msgid ""Interface mappings: %s"" msgstr """" #: neutron/plugins/linuxbridge/common/config.py:30 msgid ""Network type for tenant networks (local, vlan, or none)"" msgstr """" #: neutron/plugins/linuxbridge/common/config.py:41 #: neutron/plugins/mlnx/common/config.py:40 msgid ""List of <physical_network>:<physical_interface>"" msgstr """" #: neutron/plugins/linuxbridge/common/config.py:50 msgid ""Enable server RPC compatibility with old agents"" msgstr """" #: neutron/plugins/linuxbridge/db/l2network_db_v2.py:146 #: neutron/plugins/ml2/drivers/type_vlan.py:212 #: neutron/plugins/openvswitch/ovs_db_v2.py:165 #, python-format msgid """" ""Reserving specific vlan %(vlan_id)s on physical network "" ""%(physical_network)s outside pool"" msgstr """" #: neutron/plugins/linuxbridge/db/l2network_db_v2.py:170 #: neutron/plugins/ml2/drivers/type_vlan.py:261 #: neutron/plugins/openvswitch/ovs_db_v2.py:195 #, python-format msgid """" ""Releasing vlan %(vlan_id)s on physical network %(physical_network)s to "" ""pool"" msgstr """" #: neutron/plugins/linuxbridge/db/l2network_db_v2.py:175 #: neutron/plugins/ml2/drivers/type_vlan.py:256 #: neutron/plugins/openvswitch/ovs_db_v2.py:190 #, python-format msgid """" ""Releasing vlan %(vlan_id)s on physical network %(physical_network)s "" ""outside pool"" msgstr """" #: neutron/plugins/linuxbridge/db/l2network_db_v2.py:206 #: neutron/plugins/mlnx/db/mlnx_db_v2.py:215 msgid ""get_port_from_device() called"" msgstr """" #: neutron/plugins/linuxbridge/db/l2network_db_v2.py:234 #, python-format msgid ""set_port_status as %s called"" msgstr """" #: neutron/plugins/metaplugin/meta_neutron_plugin.py:40 #, python-format msgid ""Flavor %(flavor)s could not be found"" msgstr """" #: neutron/plugins/metaplugin/meta_neutron_plugin.py:44 msgid ""Failed to add flavor binding"" msgstr """" #: neutron/plugins/metaplugin/meta_neutron_plugin.py:51 msgid ""Start initializing metaplugin"" msgstr """" #: neutron/plugins/metaplugin/meta_neutron_plugin.py:93 #, python-format msgid ""default_flavor %s is not plugin list"" msgstr """" #: neutron/plugins/metaplugin/meta_neutron_plugin.py:98 #, python-format msgid ""default_l3_flavor %s is not plugin list"" msgstr """" #: neutron/plugins/metaplugin/meta_neutron_plugin.py:164 #, python-format msgid ""Created network: %(net_id)s with flavor %(flavor)s"" msgstr """" #: neutron/plugins/metaplugin/meta_neutron_plugin.py:170 msgid ""Failed to add flavor bindings"" msgstr """" #: neutron/plugins/metaplugin/meta_neutron_plugin.py:291 #, python-format msgid ""Created router: %(router_id)s with flavor %(flavor)s"" msgstr """" #: neutron/plugins/metaplugin/meta_neutron_plugin.py:297 #, python-format msgid ""Created router: %s"" msgstr """" #: neutron/plugins/metaplugin/proxy_neutron_plugin.py:67 #, python-format msgid ""Update subnet failed: %s"" msgstr """" #: neutron/plugins/metaplugin/proxy_neutron_plugin.py:74 msgid ""Subnet in remote have already deleted"" msgstr """" #: neutron/plugins/metaplugin/proxy_neutron_plugin.py:95 #, python-format msgid ""Update network failed: %s"" msgstr """" #: neutron/plugins/metaplugin/proxy_neutron_plugin.py:102 msgid ""Network in remote have already deleted"" msgstr """" #: neutron/plugins/metaplugin/proxy_neutron_plugin.py:123 #, python-format msgid ""Update port failed: %s"" msgstr """" #: neutron/plugins/metaplugin/proxy_neutron_plugin.py:134 msgid ""Port in remote have already deleted"" msgstr """" #: neutron/plugins/metaplugin/common/config.py:23 msgid ""List of plugins to load"" msgstr """" #: neutron/plugins/metaplugin/common/config.py:25 msgid ""List of L3 plugins to load"" msgstr """" #: neutron/plugins/metaplugin/common/config.py:27 msgid ""Default flavor to use"" msgstr """" #: neutron/plugins/metaplugin/common/config.py:29 msgid ""Default L3 flavor to use"" msgstr """" #: neutron/plugins/metaplugin/common/config.py:31 msgid ""Supported extension aliases"" msgstr """" #: neutron/plugins/metaplugin/common/config.py:33 msgid ""A list of extensions, per plugin, to load."" msgstr """" #: neutron/plugins/midonet/config.py:25 msgid ""MidoNet API server URI."" msgstr """" #: neutron/plugins/midonet/config.py:27 msgid ""MidoNet admin username."" msgstr """" #: neutron/plugins/midonet/config.py:30 msgid ""MidoNet admin password."" msgstr """" #: neutron/plugins/midonet/config.py:33 msgid ""ID of the project that MidoNet admin userbelongs to."" msgstr """" #: neutron/plugins/midonet/config.py:37 msgid ""Virtual provider router ID."" msgstr """" #: neutron/plugins/midonet/config.py:40 msgid ""Virtual metadata router ID."" msgstr """" #: neutron/plugins/midonet/config.py:43 msgid ""Operational mode. Internal dev use only."" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:79 #, python-format msgid ""MidoNet %(resource_type)s %(id)s could not be found"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:83 #, python-format msgid ""MidoNet API error: %(msg)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:99 #, python-format msgid ""MidoClient.create_bridge called: tenant_id=%(tenant_id)s, name=%(name)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:111 #, python-format msgid ""MidoClient.delete_bridge called: id=%(id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:121 #, python-format msgid ""MidoClient.get_bridge called: id=%s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:135 #, python-format msgid ""MidoClient.update_bridge called: id=%(id)s, name=%(name)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:152 #, python-format msgid """" ""MidoClient.create_dhcp called: bridge=%s(bridge)s, net_addr=%(net_addr)s,"" "" net_len=%(net_len)s, gateway_ip=%(gateway_ip)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:169 #, python-format msgid """" ""MidoClient.create_dhcp_hosts called: bridge=%s(bridge), ip=%(ip)s, "" ""mac=%(mac)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:186 #, python-format msgid """" ""MidoClient.delete_dhcp_hosts called: bridge_id=%s(bridge_id), ip=%(ip)s, "" ""mac=%(mac)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:202 #, python-format msgid ""MidoClient.delete_dhcp called: bridge=%s(bridge), "" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:215 #, python-format msgid ""MidoClient.delete_port called: id=%(id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:225 #, python-format msgid ""MidoClient.get_port called: id=%(id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:238 #, python-format msgid ""MidoClient.create_exterior_bridge_port called: bridge=%(bridge)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:249 #, python-format msgid ""MidoClient.create_interior_bridge_port called: bridge=%(bridge)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:261 #, python-format msgid ""MidoClient.create_router called: tenant_id=%(tenant_id)s, name=%(name)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:276 #, python-format msgid """" ""MidoClient.create_tenant_router called: tenant_id=%(tenant_id)s, "" ""name=%(name)smetadata_router=%(metadata_router)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:292 #, python-format msgid """" ""MidoClient.delete_tenant_router called: id=%(id)s, "" ""metadata_router=%(metadata_router)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:307 #, python-format msgid ""MidoClient.delete_router called: id=%(id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:317 #, python-format msgid ""MidoClient.get_router called: id=%(id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:331 #, python-format msgid ""MidoClient.update_router called: id=%(id)s, name=%(name)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:350 #, python-format msgid """" ""MidoClient.link_bridge_port_to_router called: port_id=%(port_id)s, "" ""router_id=%(router_id)s, gateway_ip=%(gateway_ip)s net_addr=%(net_addr)s,"" "" net_len=%(net_len)s, metadata_router=%(metadata_router)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:382 #, python-format msgid ""Couldn't find a md router port for the router=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:399 #, python-format msgid """" ""MidoClient.unlink_bridge_port_from_router called: port_id=%(port_id)s, "" ""net_addr=%(net_addr)s, net_len=%(net_len)s, "" ""metadata_router=%(metadata_router)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:414 #, python-format msgid ""Deleting route=%r ..."" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:429 #, python-format msgid """" ""MidoClient.link_bridge_to_provider_router called: bridge=%(bridge)s, "" ""provider_router=%(provider_router)s, gateway_ip=%(gateway_ip)s, "" ""net_addr=%(net_addr)s, net_len=%(net_len)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:458 #, python-format msgid """" ""MidoClient.unlink_bridge_from_provider_router called: bridge=%(bridge)s, "" ""provider_router=%(provider_router)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:489 #, python-format msgid """" ""MidoClient.set_router_external_gateway called: id=%(id)s, "" ""provider_router=%(provider_router)s, snat_ip=%s(snat_ip)s)"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:548 #, python-format msgid ""MidoClient.clear_router_external_gateway called: id=%(id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:591 #, python-format msgid """" ""MidoClient.get_router_chains called: tenant_id=%(tenant_id)s "" ""router_id=%(router_id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:613 #, python-format msgid ""MidoClient.create_router_chains called: router=%(router)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:637 #, python-format msgid ""MidoClient.destroy_router_chains called: id=%(id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:652 #, python-format msgid """" ""MidoClient.link_router_to_metadata_router called: router=%(router)s, "" ""metadata_router=%(metadata_router)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:678 #, python-format msgid """" ""MidoClient.unlink_router_from_metadata_router called: id=%(id)s, "" ""metadata_router=%(metadata_router)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:701 #, python-format msgid """" ""MidoClient.setup_floating_ip called: router_id=%(router_id)s, "" ""provider_router=%(provider_router)sfloating_ip=%(floating_ip)s, "" ""fixed_ip=%(fixed_ip)sidentifier=%(identifier)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:765 #, python-format msgid """" ""MidoClient.clear_floating_ip called: router_id=%(router_id)s, "" ""provider_router=%(provider_router)sfloating_ip=%(floating_ip)s, "" ""identifier=%(identifier)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:786 #: neutron/plugins/midonet/midonet_lib.py:793 #, python-format msgid ""deleting rule=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:804 #, python-format msgid """" ""MidoClient.create_for_sg called: tenant_id=%(tenant_id)s sg_id=%(sg_id)s "" ""sg_name=%(sg_name)s "" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:826 #, python-format msgid """" ""MidoClient.delete_for_sg called: tenant_id=%(tenant_id)s sg_id=%(sg_id)s "" ""sg_name=%(sg_name)s "" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:835 #, python-format msgid ""MidoClient.delete_for_sg: deleting chain=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:843 #, python-format msgid ""MidoClient.delete_for_sg: deleting pg=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:850 #, python-format msgid ""MidoClient.get_sg_chains called: tenant_id=%(tenant_id)s sg_id=%(sg_id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:870 #, python-format msgid """" ""MidoClient.get_port_groups_for_sg called: tenant_id=%(tenant_id)s "" ""sg_id=%(sg_id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:879 #, python-format msgid ""MidoClient.get_port_groups_for_sg exiting: pg=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:886 #, python-format msgid ""MidoClient.create_for_sg_rule called: rule=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:912 #: neutron/plugins/midonet/midonet_lib.py:945 #, python-format msgid ""Don't know what to do with rule=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:949 #, python-format msgid """" ""MidoClient.create_for_sg_rule: adding accept rule %(rule_id)s in "" ""portgroup %(port_group_id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:960 #, python-format msgid ""MidoClient.delete_for_sg_rule called: rule=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:973 #, python-format msgid ""MidoClient.delete_for_sg_rule: deleting rule %r"" msgstr """" #: neutron/plugins/midonet/plugin.py:76 msgid """" ""No provider router and metadata device ids found. But skipping because "" ""running in dev env."" msgstr """" #: neutron/plugins/midonet/plugin.py:80 msgid """" ""provider_router_id and metadata_router_id should be configured in the "" ""plugin config file"" msgstr """" #: neutron/plugins/midonet/plugin.py:92 #, python-format msgid ""MidonetPluginV2.create_subnet called: subnet=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:96 msgid ""MidoNet doesn't support IPv6."" msgstr """" #: neutron/plugins/midonet/plugin.py:102 msgid ""MidoNet doesn't support multiple subnets on the same network."" msgstr """" #: neutron/plugins/midonet/plugin.py:125 #, python-format msgid ""MidonetPluginV2.create_subnet exiting: sn_entry=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:134 #, python-format msgid ""MidonetPluginV2.delete_subnet called: id=%s"" msgstr """" #: neutron/plugins/midonet/plugin.py:149 msgid ""MidonetPluginV2.delete_subnet exiting"" msgstr """" #: neutron/plugins/midonet/plugin.py:156 #, python-format msgid ""MidonetPluginV2.create_network called: network=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:160 #, python-format msgid """" ""Ignoring admin_state_up=False for network=%r because it is not yet "" ""supported"" msgstr """" #: neutron/plugins/midonet/plugin.py:178 #, python-format msgid ""MidonetPluginV2.create_network exiting: net=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:187 #, python-format msgid ""MidonetPluginV2.update_network called: id=%(id)r, network=%(network)r"" msgstr """" #: neutron/plugins/midonet/plugin.py:193 #: neutron/plugins/nicira/NeutronPlugin.py:1062 msgid ""admin_state_up=False networks are not supported."" msgstr """" #: neutron/plugins/midonet/plugin.py:203 #, python-format msgid ""MidonetPluginV2.update_network exiting: net=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:211 #, python-format msgid ""MidonetPluginV2.get_network called: id=%(id)r, fields=%(fields)r"" msgstr """" #: neutron/plugins/midonet/plugin.py:217 #, python-format msgid ""MidonetPluginV2.get_network exiting: qnet=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:222 #, python-format msgid ""MidonetPluginV2.delete_network called: id=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:227 #, python-format msgid ""Failed to delete neutron db, while Midonet bridge=%rhad been deleted"" msgstr """" #: neutron/plugins/midonet/plugin.py:233 #, python-format msgid ""MidonetPluginV2.create_port called: port=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:274 #, python-format msgid ""MidonetPluginV2.create_port exiting: port_db_entry=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:280 #, python-format msgid ""MidonetPluginV2.get_port called: id=%(id)s fields=%(fields)r"" msgstr """" #: neutron/plugins/midonet/plugin.py:289 #, python-format msgid ""MidonetPluginV2.get_port exiting: port_db_entry=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:295 #, python-format msgid ""MidonetPluginV2.get_ports called: filters=%(filters)s fields=%(fields)r"" msgstr """" #: neutron/plugins/midonet/plugin.py:309 #, python-format msgid """" ""MidonetPluginV2.delete_port called: id=%(id)s "" ""l3_port_check=%(l3_port_check)r"" msgstr """" #: neutron/plugins/midonet/plugin.py:339 #, python-format msgid ""MidonetPluginV2.create_router called: router=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:342 #, python-format msgid ""Ignoring admin_state_up=False for router=%r. Overriding with True"" msgstr """" #: neutron/plugins/midonet/plugin.py:360 #, python-format msgid ""MidonetPluginV2.create_router exiting: qrouter=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:365 #, python-format msgid ""MidonetPluginV2.update_router called: id=%(id)s router=%(router)r"" msgstr """" #: neutron/plugins/midonet/plugin.py:369 msgid ""admin_state_up=False routers are not supported."" msgstr """" #: neutron/plugins/midonet/plugin.py:419 #, python-format msgid ""MidonetPluginV2.update_router exiting: qrouter=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:424 #, python-format msgid ""MidonetPluginV2.delete_router called: id=%s"" msgstr """" #: neutron/plugins/midonet/plugin.py:429 #, python-format msgid ""MidonetPluginV2.delete_router exiting: result=%s"" msgstr """" #: neutron/plugins/midonet/plugin.py:434 #, python-format msgid """" ""MidonetPluginV2.add_router_interface called: router_id=%(router_id)s "" ""interface_info=%(interface_info)r"" msgstr """" #: neutron/plugins/midonet/plugin.py:456 #, python-format msgid ""MidonetPluginV2.add_router_interface exiting: qport=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:462 #, python-format msgid """" ""MidonetPluginV2.remove_router_interface called: router_id=%(router_id)s "" ""interface_info=%(interface_info)r"" msgstr """" #: neutron/plugins/midonet/plugin.py:509 msgid ""MidonetPluginV2.remove_router_interface exiting"" msgstr """" #: neutron/plugins/midonet/plugin.py:513 #, python-format msgid """" ""MidonetPluginV2.update_floatingip called: id=%(id)s "" ""floatingip=%(floatingip)s "" msgstr """" #: neutron/plugins/midonet/plugin.py:537 #, python-format msgid ""MidonetPluginV2.update_floating_ip exiting: fip=%s"" msgstr """" #: neutron/plugins/midonet/plugin.py:546 #, python-format msgid """" ""MidonetPluginV2.create_security_group called: "" ""security_group=%(security_group)s default_sg=%(default_sg)s "" msgstr """" #: neutron/plugins/midonet/plugin.py:562 #, python-format msgid ""MidonetPluginV2.create_security_group exiting: sg_db_entry=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:568 #, python-format msgid ""MidonetPluginV2.delete_security_group called: id=%s"" msgstr """" #: neutron/plugins/midonet/plugin.py:597 #, python-format msgid """" ""MidonetPluginV2.get_security_groups called: filters=%(filters)r "" ""fields=%(fields)r"" msgstr """" #: neutron/plugins/midonet/plugin.py:604 #, python-format msgid """" ""MidonetPluginV2.get_security_group called: id=%(id)s fields=%(fields)r "" ""tenant_id=%(tenant_id)s"" msgstr """" #: neutron/plugins/midonet/plugin.py:611 #, python-format msgid """" ""MidonetPluginV2.create_security_group_rule called: "" ""security_group_rule=%(security_group_rule)r"" msgstr """" #: neutron/plugins/midonet/plugin.py:621 #, python-format msgid ""MidonetPluginV2.create_security_group_rule exiting: rule_db_entry=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:626 #, python-format msgid ""MidonetPluginV2.delete_security_group_rule called: sgrid=%s"" msgstr """" #: neutron/plugins/midonet/plugin.py:641 #, python-format msgid """" ""MidonetPluginV2.get_security_group_rules called: filters=%(filters)r "" ""fields=%(fields)r"" msgstr """" #: neutron/plugins/midonet/plugin.py:648 #, python-format msgid """" ""MidonetPluginV2.get_security_group_rule called: id=%(id)s "" ""fields=%(fields)r"" msgstr """" #: neutron/plugins/ml2/config.py:22 msgid """" ""List of network type driver entrypoints to be loaded from the "" ""neutron.ml2.type_drivers namespace."" msgstr """" #: neutron/plugins/ml2/config.py:26 msgid ""Ordered list of network_types to allocate as tenant networks."" msgstr """" #: neutron/plugins/ml2/config.py:30 msgid """" ""An ordered list of networking mechanism driver entrypoints to be loaded "" ""from the neutron.ml2.mechanism_drivers namespace."" msgstr """" #: neutron/plugins/ml2/db.py:44 #, python-format msgid ""Added segment %(id)s of type %(network_type)s for network %(network_id)s"" msgstr """" #: neutron/plugins/ml2/db.py:73 #, python-format msgid ""Multiple ports have port_id starting with %s"" msgstr """" #: neutron/plugins/ml2/db.py:81 #, python-format msgid ""get_port_and_sgs() called for port_id %s"" msgstr """" #: neutron/plugins/ml2/managers.py:41 #, python-format msgid ""Configured type driver names: %s"" msgstr """" #: neutron/plugins/ml2/managers.py:46 #, python-format msgid ""Loaded type driver names: %s"" msgstr """" #: neutron/plugins/ml2/managers.py:54 #, python-format msgid """" ""Type driver '%(new_driver)s' ignored because type driver '%(old_driver)s'"" "" is already registered for type '%(type)s'"" msgstr """" #: neutron/plugins/ml2/managers.py:62 #, python-format msgid ""Registered types: %s"" msgstr """" #: neutron/plugins/ml2/managers.py:70 #, python-format msgid ""No type driver for tenant network_type: %s. Service terminated!"" msgstr """" #: neutron/plugins/ml2/managers.py:74 #, python-format msgid ""Tenant network_types: %s"" msgstr """" #: neutron/plugins/ml2/managers.py:78 #, python-format msgid ""Initializing driver for type '%s'"" msgstr """" #: neutron/plugins/ml2/managers.py:87 #: neutron/plugins/ml2/drivers/type_tunnel.py:95 #, python-format msgid ""network_type value '%s' not supported"" msgstr """" #: neutron/plugins/ml2/managers.py:129 #, python-format msgid ""Configured mechanism driver names: %s"" msgstr """" #: neutron/plugins/ml2/managers.py:134 #, python-format msgid ""Loaded mechanism driver names: %s"" msgstr """" #: neutron/plugins/ml2/managers.py:145 #, python-format msgid ""Mechanism driver '%s' ignored because driver is already registered"" msgstr """" #: neutron/plugins/ml2/managers.py:151 #, python-format msgid ""Registered mechanism drivers: %s"" msgstr """" #: neutron/plugins/ml2/managers.py:156 #, python-format msgid ""Initializing mechanism driver '%s'"" msgstr """" #: neutron/plugins/ml2/managers.py:176 #, python-format msgid ""Mechanism driver '%(name)s' failed in %(method)s"" msgstr """" #: neutron/plugins/ml2/plugin.py:106 msgid ""Modular L2 Plugin initialization complete"" msgstr """" #: neutron/plugins/ml2/plugin.py:134 msgid ""network_type required if other provider attributes specified"" msgstr """" #: neutron/plugins/ml2/plugin.py:148 #, python-format msgid ""Network %s has no segments"" msgstr """" #: neutron/plugins/ml2/plugin.py:180 msgid """" ""In _notify_port_updated() for port %(port_id), network %(network_id) has "" ""no segments"" msgstr """" #: neutron/plugins/ml2/plugin.py:223 #, python-format msgid ""mechanism_manager.create_network failed, deleting network '%s'"" msgstr """" #: neutron/plugins/ml2/plugin.py:326 #, python-format msgid ""mechanism_manager.create_port failed, deleting port '%s'"" msgstr """" #: neutron/plugins/ml2/rpc.py:87 #, python-format msgid ""Device %(device)s details requested by agent %(agent_id)s"" msgstr """" #: neutron/plugins/ml2/rpc.py:96 #, python-format msgid ""Device %(device)s requested by agent %(agent_id)s not found in database"" msgstr """" #: neutron/plugins/ml2/rpc.py:102 #, python-format msgid """" ""Device %(device)s requested by agent %(agent_id)s has network "" ""%(network_id) with no segments"" msgstr """" #: neutron/plugins/ml2/rpc.py:122 #, python-format msgid ""Returning: %s"" msgstr """" #: neutron/plugins/ml2/rpc.py:130 #, python-format msgid ""Device %(device)s no longer exists at agent %(agent_id)s"" msgstr """" #: neutron/plugins/ml2/rpc.py:139 #, python-format msgid ""Device %(device)s updated down by agent %(agent_id)s not found in database"" msgstr """" #: neutron/plugins/ml2/rpc.py:153 #, python-format msgid ""Device %(device)s up at agent %(agent_id)s"" msgstr """" #: neutron/plugins/ml2/rpc.py:161 #, python-format msgid ""Device %(device)s updated up by agent %(agent_id)s not found in database"" msgstr """" #: neutron/plugins/ml2/common/exceptions.py:23 #, python-format msgid ""%(method)s failed."" msgstr """" #: neutron/plugins/ml2/drivers/type_flat.py:31 msgid """" ""List of physical_network names with which flat networks can be created. "" ""Use * to allow flat networks with arbitrary physical_network names."" msgstr """" #: neutron/plugins/ml2/drivers/type_flat.py:69 msgid ""Arbitrary flat physical_network names allowed"" msgstr """" #: neutron/plugins/ml2/drivers/type_flat.py:74 #, python-format msgid ""Allowable flat physical_network names: %s"" msgstr """" #: neutron/plugins/ml2/drivers/type_flat.py:81 msgid ""ML2 FlatTypeDriver initialization complete"" msgstr """" #: neutron/plugins/ml2/drivers/type_flat.py:86 msgid ""physical_network required for flat provider network"" msgstr """" #: neutron/plugins/ml2/drivers/type_flat.py:89 #, python-format msgid ""physical_network '%s' unknown for flat provider network"" msgstr """" #: neutron/plugins/ml2/drivers/type_flat.py:96 #, python-format msgid ""%s prohibited for flat provider network"" msgstr """" #: neutron/plugins/ml2/drivers/type_flat.py:112 #, python-format msgid ""Reserving flat network on physical network %s"" msgstr """" #: neutron/plugins/ml2/drivers/type_flat.py:130 #, python-format msgid ""Releasing flat network on physical network %s"" msgstr """" #: neutron/plugins/ml2/drivers/type_flat.py:133 #, python-format msgid ""No flat network found on physical network %s"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:34 msgid """" ""Comma-separated list of <tun_min>:<tun_max> tuples enumerating ranges of "" ""GRE tunnel IDs that are available for tenant network allocation"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:79 msgid ""provider:physical_network specified for GRE network"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:85 msgid ""segmentation_id required for GRE provider network"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:98 #, python-format msgid ""Reserving specific gre tunnel %s from pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:102 #, python-format msgid ""Reserving specific gre tunnel %s outside pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:115 #, python-format msgid ""Allocating gre tunnel id %(gre_id)s"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:133 #, python-format msgid ""Releasing gre tunnel %s to pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:138 #, python-format msgid ""Releasing gre tunnel %s outside pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:141 #, python-format msgid ""gre_id %s not found"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:151 #, python-format msgid ""Skipping unreasonable gre ID range %(tun_min)s:%(tun_max)s"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:169 #: neutron/plugins/ml2/drivers/type_vxlan.py:177 #: neutron/plugins/openvswitch/ovs_db_v2.py:233 #, python-format msgid ""Removing tunnel %s from pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:184 msgid ""get_gre_endpoints() called"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:193 #, python-format msgid ""add_gre_endpoint() called for ip %s"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:199 #, python-format msgid ""Gre endpoint with ip %s already exists"" msgstr """" #: neutron/plugins/ml2/drivers/type_local.py:36 msgid ""ML2 LocalTypeDriver initialization complete"" msgstr """" #: neutron/plugins/ml2/drivers/type_local.py:47 #, python-format msgid ""%s prohibited for local provider network"" msgstr """" #: neutron/plugins/ml2/drivers/type_tunnel.py:60 #, python-format msgid ""Invalid tunnel ID range: '%(range)s' - %(e)s. Agent terminated!"" msgstr """" #: neutron/plugins/ml2/drivers/type_tunnel.py:63 #, python-format msgid ""%(type)s ID ranges: %(range)s"" msgstr """" #: neutron/plugins/ml2/drivers/type_vlan.py:37 msgid """" ""List of <physical_network>:<vlan_min>:<vlan_max> or <physical_network> "" ""specifying physical_network names usable for VLAN provider and tenant "" ""networks, as well as ranges of VLAN tags on each available for allocation"" "" to tenant networks."" msgstr """" #: neutron/plugins/ml2/drivers/type_vlan.py:91 msgid ""Failed to parse network_vlan_ranges. Service terminated!"" msgstr """" #: neutron/plugins/ml2/drivers/type_vlan.py:161 msgid ""VlanTypeDriver initialization complete"" msgstr """" #: neutron/plugins/ml2/drivers/type_vlan.py:166 msgid ""physical_network required for VLAN provider network"" msgstr """" #: neutron/plugins/ml2/drivers/type_vlan.py:169 #, python-format msgid ""physical_network '%s' unknown for VLAN provider network"" msgstr """" #: neutron/plugins/ml2/drivers/type_vlan.py:175 msgid ""segmentation_id required for VLAN provider network"" msgstr """" #: neutron/plugins/ml2/drivers/type_vlan.py:178 #, python-format msgid ""segmentation_id out of range (%(min)s through %(max)s)"" msgstr """" #: neutron/plugins/ml2/drivers/type_vlan.py:188 #, python-format msgid ""%s prohibited for VLAN provider network"" msgstr """" #: neutron/plugins/ml2/drivers/type_vlan.py:228 #, python-format msgid """" ""Allocating vlan %(vlan_id)s on physical network %(physical_network)s from"" "" pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_vlan.py:266 #, python-format msgid ""No vlan_id %(vlan_id)s found on physical network %(physical_network)s"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:37 msgid """" ""Comma-separated list of <vni_min>:<vni_max> tuples enumerating ranges of "" ""VXLAN VNI IDs that are available for tenant network allocation"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:41 msgid ""Multicast group for VXLAN. If unset, disables VXLAN multicast mode."" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:86 msgid ""provider:physical_network specified for VXLAN network"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:92 msgid ""segmentation_id required for VXLAN provider network"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:105 #, python-format msgid ""Reserving specific vxlan tunnel %s from pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:109 #, python-format msgid ""Reserving specific vxlan tunnel %s outside pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:122 #, python-format msgid ""Allocating vxlan tunnel vni %(vxlan_vni)s"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:140 #, python-format msgid ""Releasing vxlan tunnel %s to pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:145 #, python-format msgid ""Releasing vxlan tunnel %s outside pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:148 #, python-format msgid ""vxlan_vni %s not found"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:159 #, python-format msgid ""Skipping unreasonable VXLAN VNI range %(tun_min)s:%(tun_max)s"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:194 msgid ""get_vxlan_endpoints() called"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:204 #, python-format msgid ""add_vxlan_endpoint() called for ip %s"" msgstr """" #: neutron/plugins/mlnx/agent_notify_api.py:44 msgid ""Sending delete network message"" msgstr """" #: neutron/plugins/mlnx/agent_notify_api.py:52 msgid ""Sending update port message"" msgstr """" #: neutron/plugins/mlnx/mlnx_plugin.py:86 msgid ""Mellanox Embedded Switch Plugin initialisation complete"" msgstr """" #: neutron/plugins/mlnx/mlnx_plugin.py:105 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:326 #, python-format msgid ""%s. Server terminated!"" msgstr """" #: neutron/plugins/mlnx/mlnx_plugin.py:212 #, python-format msgid ""unknown provider:physical_network %s"" msgstr """" #: neutron/plugins/mlnx/mlnx_plugin.py:233 msgid ""invalid vnic_type on port_create"" msgstr """" #: neutron/plugins/mlnx/mlnx_plugin.py:235 msgid ""vnic_type is not defined in port profile"" msgstr """" #: neutron/plugins/mlnx/mlnx_plugin.py:286 msgid ""delete network"" msgstr """" #: neutron/plugins/mlnx/mlnx_plugin.py:336 #, python-format msgid ""create_port with %s"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:55 #, python-format msgid ""Agent cache inconsistency - port id is not stored for %s"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:70 #, python-format msgid ""Network %s not defined on Agent."" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:83 #, python-format msgid ""Network %s is not available on this agent"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:94 #, python-format msgid ""Connecting port %s"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:104 #, python-format msgid ""Binding VLAN ID %(seg_id)sto eSwitch for vNIC mac_address %(mac)s"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:113 msgid ""Network Type IB currently not supported"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:125 #, python-format msgid ""Port_mac %s is not available on this agent"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:132 msgid ""creating VLAN Network"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:134 msgid ""currently IB network provisioning is not supported"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:136 #, python-format msgid ""Unknown network type %(network_type) for network %(network_id)"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:162 msgid ""Invalid Network ID, cannot remove Network"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:164 #, python-format msgid ""Delete network %s"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:266 msgid ""ports added!"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:269 msgid ""ports removed!"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:294 #, python-format msgid ""Adding port with mac %s"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:301 #, python-format msgid """" ""Unable to get device dev_details for device with mac_address %(device)s: "" ""due to %(exc)s"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:307 #, python-format msgid ""Port %s updated"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:308 #, python-format msgid ""Device details %s"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:317 #, python-format msgid ""Device with mac_address %s not defined on Neutron Plugin"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:324 #, python-format msgid ""Removing device with mac_address %s"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:331 #, python-format msgid ""Removing port failed for device %(device)s due to %(exc)s"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:346 msgid ""eSwitch Agent Started!"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:364 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:752 #: neutron/plugins/ryu/agent/ryu_neutron_agent.py:263 #: neutron/tests/unit/openvswitch/test_ovs_tunnel.py:381 msgid ""Error in agent event loop"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:394 #, python-format msgid ""Failed on Agent initialisation : %s. Agent terminated!"" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:399 msgid ""Agent initialised successfully, now running... "" msgstr """" #: neutron/plugins/mlnx/agent/utils.py:58 msgid ""eSwitchD: Request timeout"" msgstr """" #: neutron/plugins/mlnx/agent/utils.py:68 #, python-format msgid ""Action %(action)s failed: %(reason)s"" msgstr """" #: neutron/plugins/mlnx/agent/utils.py:70 #, python-format msgid ""Unknown operation status %s"" msgstr """" #: neutron/plugins/mlnx/agent/utils.py:75 msgid ""get_attached_vnics"" msgstr """" #: neutron/plugins/mlnx/agent/utils.py:82 #, python-format msgid """" ""Set Vlan %(segmentation_id)s on Port %(port_mac)s on Fabric "" ""%(physical_network)s"" msgstr """" #: neutron/plugins/mlnx/agent/utils.py:95 #, python-format msgid ""Define Fabric %(fabric)s on interface %(ifc)s"" msgstr """" #: neutron/plugins/mlnx/agent/utils.py:104 #, python-format msgid ""Port Up for %(port_mac)s on fabric %(fabric)s"" msgstr """" #: neutron/plugins/mlnx/agent/utils.py:113 #, python-format msgid ""Port Down for %(port_mac)s on fabric %(fabric)s"" msgstr """" #: neutron/plugins/mlnx/agent/utils.py:122 #, python-format msgid ""Port Release for %(port_mac)s on fabric %(fabric)s"" msgstr """" #: neutron/plugins/mlnx/common/config.py:28 msgid ""Network type for tenant networks (local, ib, vlan, or none)"" msgstr """" #: neutron/plugins/mlnx/common/config.py:43 msgid ""type of VM network interface: direct or hosdev"" msgstr """" #: neutron/plugins/mlnx/common/config.py:46 msgid ""eswitch daemon end point"" msgstr """" #: neutron/plugins/mlnx/common/config.py:48 msgid """" ""The number of milliseconds the agent will wait for response on request to"" "" daemon."" msgstr """" #: neutron/plugins/mlnx/common/exceptions.py:22 #, python-format msgid ""Mlnx Exception: %(err_msg)s"" msgstr """" #: neutron/plugins/mlnx/db/mlnx_db_v2.py:45 #, python-format msgid ""Removing vlan %(seg_id)s on physical network %(net)s from pool"" msgstr """" #: neutron/plugins/mlnx/db/mlnx_db_v2.py:66 #, python-format msgid ""removing vlan %(seg_id)s on physical network %(net)s from pool"" msgstr """" #: neutron/plugins/mlnx/db/mlnx_db_v2.py:121 #, python-format msgid ""Reserving vlan %(seg_id)s on physical network %(net)s from pool"" msgstr """" #: neutron/plugins/mlnx/db/mlnx_db_v2.py:140 #, python-format msgid """" ""Reserving specific vlan %(seg_id)s on physical network %(phy_net)s from "" ""pool"" msgstr """" #: neutron/plugins/mlnx/db/mlnx_db_v2.py:145 #, python-format msgid """" ""Reserving specific vlan %(seg_id)s on physical network %(phy_net)s "" ""outside pool"" msgstr """" #: neutron/plugins/mlnx/db/mlnx_db_v2.py:172 #, python-format msgid ""Releasing vlan %(seg_id)s on physical network %(phy_net)s to pool"" msgstr """" #: neutron/plugins/mlnx/db/mlnx_db_v2.py:177 #, python-format msgid ""Releasing vlan %(seg_id)s on physical network %(phy_net)s outside pool"" msgstr """" #: neutron/plugins/mlnx/db/mlnx_db_v2.py:183 #, python-format msgid ""vlan_id %(seg_id)s on physical network %(phy_net)s not found"" msgstr """" #: neutron/plugins/mlnx/db/mlnx_db_v2.py:225 msgid ""Get_port_from_device_mac() called"" msgstr """" #: neutron/plugins/mlnx/db/mlnx_db_v2.py:233 #, python-format msgid ""Set_port_status as %s called"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:158 msgid ""activate_port_if_ready(): skip, port.admin_state_up is False."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:162 msgid ""activate_port_if_ready(): skip, network.admin_state_up is False."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:166 msgid ""activate_port_if_ready(): skip, no portinfo for this port."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:182 msgid ""activate_port_if_ready(): skip, ofc_port already exists."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:188 #, python-format msgid ""create_ofc_port() failed due to %s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:206 #, python-format msgid ""delete_ofc_port() failed due to %s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:210 msgid ""deactivate_port(): skip, ofc_port does not exist."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:229 #, python-format msgid ""NECPluginV2.create_network() called, network=%s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:248 #, python-format msgid ""create_network() failed due to %s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:264 #, python-format msgid ""NECPluginV2.update_network() called, id=%(id)s network=%(network)s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:304 #, python-format msgid ""NECPluginV2.delete_network() called, id=%s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:313 #, python-format msgid ""delete_network(): deleting auto-delete port from OFC: %s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:329 #, python-format msgid ""delete_network() failed due to %s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:342 #, python-format msgid ""delete_ofc_tenant() failed due to %s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:354 #, python-format msgid ""NECPluginV2.create_port() called, port=%s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:373 #, python-format msgid ""NECPluginV2.update_port() called, id=%(id)s port=%(port)s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:399 #, python-format msgid ""NECPluginV2.delete_port() called, id=%s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:479 #, python-format msgid """" ""NECPluginV2RPCCallbacks.get_port_from_device() called, device=%(device)s "" ""=> %(ret)s."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:510 #, python-format msgid ""NECPluginV2RPCCallbacks.update_ports() called, kwargs=%s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:529 #, python-format msgid """" ""update_ports(): ignore port_removed message due to portinfo for "" ""port_id=%s was not registered"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:534 #, python-format msgid """" ""update_ports(): ignore port_removed message received from different host "" ""(registered_datapath_id=%(registered)s, "" ""received_datapath_id=%(received)s)."" msgstr """" #: neutron/plugins/nec/packet_filter.py:41 msgid ""Disabled packet-filter extension."" msgstr """" #: neutron/plugins/nec/packet_filter.py:46 #, python-format msgid ""create_packet_filter() called, packet_filter=%s ."" msgstr """" #: neutron/plugins/nec/packet_filter.py:59 #, python-format msgid ""update_packet_filter() called, id=%(id)s packet_filter=%(packet_filter)s ."" msgstr """" #: neutron/plugins/nec/packet_filter.py:85 #, python-format msgid ""delete_packet_filter() called, id=%s ."" msgstr """" #: neutron/plugins/nec/packet_filter.py:92 #, python-format msgid ""failed to delete packet_filter id=%s which remains in error status."" msgstr """" #: neutron/plugins/nec/packet_filter.py:106 #, python-format msgid ""activate_packet_filter_if_ready() called, packet_filter=%s."" msgstr """" #: neutron/plugins/nec/packet_filter.py:115 #, python-format msgid """" ""activate_packet_filter_if_ready(): skip pf_id=%s, "" ""packet_filter.admin_state_up is False."" msgstr """" #: neutron/plugins/nec/packet_filter.py:118 #, python-format msgid """" ""activate_packet_filter_if_ready(): skip pf_id=%s, no portinfo for the "" ""in_port."" msgstr """" #: neutron/plugins/nec/packet_filter.py:121 msgid """" ""_activate_packet_filter_if_ready(): skip, ofc_packet_filter already "" ""exists."" msgstr """" #: neutron/plugins/nec/packet_filter.py:124 #, python-format msgid ""activate_packet_filter_if_ready(): create packet_filter id=%s on OFC."" msgstr """" #: neutron/plugins/nec/packet_filter.py:131 #, python-format msgid ""failed to create packet_filter id=%(id)s on OFC: %(exc)s"" msgstr """" #: neutron/plugins/nec/packet_filter.py:144 #, python-format msgid ""deactivate_packet_filter_if_ready() called, packet_filter=%s."" msgstr """" #: neutron/plugins/nec/packet_filter.py:151 #, python-format msgid ""deactivate_packet_filter(): deleting packet_filter id=%s from OFC."" msgstr """" #: neutron/plugins/nec/packet_filter.py:157 #, python-format msgid ""failed to delete packet_filter id=%(id)s from OFC: %(exc)s"" msgstr """" #: neutron/plugins/nec/packet_filter.py:161 #, python-format msgid """" ""deactivate_packet_filter(): skip, Not found OFC Mapping for packet_filter"" "" id=%s."" msgstr """" #: neutron/plugins/nec/agent/nec_neutron_agent.py:54 #, python-format msgid ""Update ports: added=%(added)s, removed=%(removed)s"" msgstr """" #: neutron/plugins/nec/agent/nec_neutron_agent.py:66 msgid ""update_ports() failed."" msgstr """" #: neutron/plugins/nec/agent/nec_neutron_agent.py:80 #, python-format msgid ""port_update received: %s"" msgstr """" #: neutron/plugins/nec/agent/nec_neutron_agent.py:221 msgid ""No port changed."" msgstr """" #: neutron/plugins/nec/common/config.py:26 #: neutron/plugins/openvswitch/common/config.py:30 #: neutron/plugins/ryu/common/config.py:24 msgid ""Integration bridge to use"" msgstr """" #: neutron/plugins/nec/common/config.py:37 msgid ""Host to connect to"" msgstr """" #: neutron/plugins/nec/common/config.py:39 msgid ""Port to connect to"" msgstr """" #: neutron/plugins/nec/common/config.py:41 msgid ""Driver to use"" msgstr """" #: neutron/plugins/nec/common/config.py:43 msgid ""Enable packet filter"" msgstr """" #: neutron/plugins/nec/common/config.py:45 msgid ""Use SSL to connect"" msgstr """" #: neutron/plugins/nec/common/config.py:47 msgid ""Key file"" msgstr """" #: neutron/plugins/nec/common/config.py:49 msgid ""Certificate file"" msgstr """" #: neutron/plugins/nec/common/exceptions.py:22 #, python-format msgid ""An OFC exception has occurred: %(reason)s"" msgstr """" #: neutron/plugins/nec/common/exceptions.py:26 #, python-format msgid ""An exception occurred in NECPluginV2 DB: %(reason)s"" msgstr """" #: neutron/plugins/nec/common/exceptions.py:30 #, python-format msgid ""Consistency of neutron-OFC resource map is broken: %(reason)s"" msgstr """" #: neutron/plugins/nec/common/exceptions.py:35 #, python-format msgid ""PortInfo %(id)s could not be found"" msgstr """" #: neutron/plugins/nec/common/ofc_client.py:57 #, python-format msgid ""Client request: %(host)s:%(port)s %(method)s %(action)s [%(body)s]"" msgstr """" #: neutron/plugins/nec/common/ofc_client.py:76 #, python-format msgid ""OFC returns [%(status)s:%(data)s]"" msgstr """" #: neutron/plugins/nec/common/ofc_client.py:86 msgid ""An operation on OFC is failed."" msgstr """" #: neutron/plugins/nec/common/ofc_client.py:89 #, python-format msgid ""Failed to connect OFC : %s"" msgstr """" #: neutron/plugins/nec/db/api.py:129 #, python-format msgid ""_del_ofc_item(): NotFound item (model=%(model)s, id=%(id)s) "" msgstr """" #: neutron/plugins/nec/db/api.py:142 #, python-format msgid ""NotFound %(resource)s for neutron_id=%(id)s."" msgstr """" #: neutron/plugins/nec/db/api.py:168 #, python-format msgid ""_del_ofc_item(): NotFound item (resource=%(resource)s, id=%(id)s) "" msgstr """" #: neutron/plugins/nec/db/api.py:201 #, python-format msgid ""del_portinfo(): NotFound portinfo for port_id: %s"" msgstr """" #: neutron/plugins/nec/db/api.py:207 #: neutron/plugins/openvswitch/ovs_db_v2.py:321 #, python-format msgid ""get_port_with_securitygroups() called:port_id=%s"" msgstr """" #: neutron/plugins/nec/db/packetfilter.py:34 #, python-format msgid ""PacketFilter %(id)s could not be found"" msgstr """" #: neutron/plugins/nec/drivers/__init__.py:35 #, python-format msgid ""Loading OFC driver: %s"" msgstr """" #: neutron/plugins/nec/extensions/packetfilter.py:34 msgid ""Number of packet_filters allowed per tenant, -1 for unlimited"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:238 #, python-format msgid ""Unable to process default l2 gw service:%s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:273 #, python-format msgid ""Created NVP router port:%s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:275 #, python-format msgid ""Unable to create port on NVP logical router %s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:278 #, python-format msgid """" ""Unable to create logical router port for neutron port id %(port_id)s on "" ""router %(router_id)s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:353 #, python-format msgid ""Attached %(att)s to NVP router port %(port)s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:359 #, python-format msgid """" ""Unable to plug attachment in NVP logical router port %(r_port_id)s, "" ""associated with Neutron %(q_port_id)s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:365 #, python-format msgid """" ""Unable to plug attachment in router port %(r_port_id)s for neutron port "" ""id %(q_port_id)s on router %(router_id)s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:410 msgid ""An exception occured while selecting logical switch for the port"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:436 #: neutron/plugins/nicira/NeutronPlugin.py:471 #: neutron/plugins/nicira/NeutronPlugin.py:639 #, python-format msgid """" ""NVP plugin does not support regular VIF ports on external networks. Port "" ""%s will be down."" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:456 #: neutron/plugins/nicira/NeutronPlugin.py:536 #: neutron/plugins/nicira/NeutronPlugin.py:658 #, python-format msgid """" ""_nvp_create_port completed for port %(name)s on network %(network_id)s. "" ""The new port id is %(id)s."" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:460 #, python-format msgid ""An exception occured while plugging the interface into network:%s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:478 #, python-format msgid ""Port '%s' was already deleted on NVP platform"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:487 #, python-format msgid ""_nvp_delete_port completed for port %(port_id)s on network %(net_id)s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:493 #, python-format msgid ""port %s not found in NVP"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:512 #: neutron/plugins/nicira/NeutronPlugin.py:914 #, python-format msgid """" ""Ignoring exception as this means the peer for port '%s' has already been "" ""deleted."" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:524 #, python-format msgid """" ""It is not allowed to create router interface ports on external networks "" ""as '%s'"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:543 #, python-format msgid """" ""device_id field must be populated in order to create an external gateway "" ""port for network %s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:551 #, python-format msgid ""The gateway port for the router %s was not found on the NVP backend"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:588 #, python-format msgid """" ""_nvp_create_ext_gw_port completed on external network %(ext_net_id)s, "" ""attached to router:%(router_id)s. NVP port id is %(nvp_port_id)s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:620 #, python-format msgid ""Logical router resource %s not found on NVP platform"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:624 #: neutron/plugins/nicira/NeutronPlugin.py:1808 msgid ""Unable to update logical routeron NVP Platform"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:626 #, python-format msgid """" ""_nvp_delete_ext_gw_port completed on external network %(ext_net_id)s, "" ""attached to router:%(router_id)s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:696 #, python-format msgid ""Unable to find NVP uuid for Neutron port %s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:725 #, python-format msgid ""%s required"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:729 msgid ""Segmentation ID cannot be specified with flat network type"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:733 msgid ""Segmentation ID must be specified with vlan network type"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:737 #: neutron/plugins/nicira/NeutronPlugin.py:752 #, python-format msgid ""%(segmentation_id)s out of range (%(min_id)s through %(max_id)s)"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:758 #, python-format msgid ""%(net_type_param)s %(net_type_value)s not supported"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:789 #, python-format msgid ""No switch has available ports (%d checked)"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:811 #, python-format msgid ""Maximum number of logical ports reached for logical network %s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:838 #, python-format msgid """" ""Network with admin_state_up=False are not yet supported by this plugin. "" ""Ignoring setting for network %s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:896 #, python-format msgid ""A nvp lport identifier was not found for neutron port '%s'"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:924 #, python-format msgid ""delete_network completed for tenant: %s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:927 #, python-format msgid ""Did not found lswitch %s in NVP"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:953 #, python-format msgid """" ""Current network status:%(nvp_net_status)s; Status in Neutron "" ""DB:%(neutron_status)s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:963 #: neutron/plugins/nicira/NeutronPlugin.py:1011 msgid ""Unable to get logical switches"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1025 #, python-format msgid ""Logical Switch %s found in neutron database but not in NVP."" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1040 #, python-format msgid """" ""Found %s logical switches not bound to Neutron networks. Neutron and NVP "" ""are potentially out of sync"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1044 #, python-format msgid ""get_networks() completed for tenant %s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1130 #, python-format msgid ""Lswitch %s not found in NVP"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1139 msgid ""Unable to get ports"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1166 #, python-format msgid ""Neutron logical port %s was not found on NVP"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1173 #, python-format msgid """" ""Found %s logical ports not bound to Neutron ports. Neutron and NVP are "" ""potentially out of sync"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1239 #, python-format msgid ""Network %s was not found in NVP."" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1247 msgid ""Unable to create port or set port attachment in NVP."" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1251 #, python-format msgid ""create_port completed on NVP for tenant %(tenant_id)s: (%(id)s)"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1326 #, python-format msgid ""Update port request: %s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1352 #, python-format msgid ""Unable to update port id: %s."" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1476 #: neutron/plugins/nicira/NeutronPlugin.py:1520 #, python-format msgid ""Network '%s' is not a valid external network"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1489 msgid ""Unable to create logical router on NVP Platform"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1529 msgid """" ""'routes' cannot contain route '0.0.0.0/0', this must be updated through "" ""the default gateway attribute"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1545 #, python-format msgid ""Logical router %s not found on NVP Platform"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1549 msgid ""Unable to update logical router on NVP Platform"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1551 msgid """" ""Request cannot contain 'routes' with the NVP platform currently in "" ""execution. Please, try without specifying the static routes."" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1584 #, python-format msgid ""Logical router '%s' not found on NVP Platform"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1588 msgid ""Unable to delete logical routeron NVP Platform"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1608 #, python-format msgid """" ""Current router status:%(router_status)s;Status in Neutron "" ""DB:%(db_router_status)s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1635 msgid ""Unable to get logical routers from NVP controller"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1657 #, python-format msgid """" ""Found %s logical routers not bound to Neutron routers. Neutron and NVP "" ""are potentially out of sync"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1683 #, python-format msgid """" ""The port %(port_id)s, connected to the router %(router_id)s was not found"" "" on the NVP backend."" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1718 #, python-format msgid """" ""Add_router_interface completed for subnet:%(subnet_id)s and "" ""router:%(router_id)s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1763 #, python-format msgid """" ""The port %(port_id)s, connected to the router %(router_id)s was not found"" "" on the NVP backend"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1775 #, python-format msgid """" ""Unable to find NVP logical router port for Neutron port id:%s. Was this "" ""port ever paired with a logical router?"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1804 #, python-format msgid ""Logical router port resource %s not found on NVP platform"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1830 #, python-format msgid """" ""An error occurred while removing NAT rules on the NVP platform for "" ""floating ip:%s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1836 msgid ""An incorrect number of matching NAT rules was found on the NVP platform"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1902 #, python-format msgid ""Address list for NVP logical router port:%s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1926 #, python-format msgid """" ""An error occurred while creating NAT rules on the NVP platform for "" ""floating ip:%(floating_ip)s mapped to internal ip:%(internal_ip)s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1969 #, python-format msgid ""The port '%s' is not associated with floating IPs"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1972 #, python-format msgid ""Nat rules not found in nvp for port: %s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1998 #, python-format msgid """" ""Create_l2_gw_service did not return an uuid for the newly created "" ""resource:%s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:2020 msgid """" ""Unable to remove gateway service from NVP plaform - the resource was not "" ""found"" msgstr """" #: neutron/plugins/nicira/NvpApiClient.py:36 #, python-format msgid ""Unable to fetch NVP version from response headers:%s"" msgstr """" #: neutron/plugins/nicira/NvpApiClient.py:124 #, python-format msgid ""NVPApiHelper.request() returns \""%s\"""" msgstr """" #: neutron/plugins/nicira/NvpApiClient.py:137 #, python-format msgid ""Request timed out: %(method)s to %(url)s"" msgstr """" #: neutron/plugins/nicira/NvpApiClient.py:148 #, python-format msgid ""Received error code: %s"" msgstr """" #: neutron/plugins/nicira/NvpApiClient.py:149 #, python-format msgid ""Server Error Message: %s"" msgstr """" #: neutron/plugins/nicira/NvpApiClient.py:155 #, python-format msgid """" ""%(method)s to %(url)s, unexpected response code: %(status)d (content = "" ""'%(body)s')"" msgstr """" #: neutron/plugins/nicira/NvpApiClient.py:173 msgid ""Unable to determine NVP version. Plugin might not work as expected."" msgstr """" #: neutron/plugins/nicira/NvpApiClient.py:228 msgid ""Server denied session's authentication credentials."" msgstr """" #: neutron/plugins/nicira/NvpApiClient.py:232 msgid ""An entity referenced in the request was not found."" msgstr """" #: neutron/plugins/nicira/NvpApiClient.py:236 msgid ""Request conflicts with configuration on a different entity."" msgstr """" #: neutron/plugins/nicira/NvpApiClient.py:241 msgid """" ""Request could not completed because the associated resource could not be "" ""reached."" msgstr """" #: neutron/plugins/nicira/NvpApiClient.py:246 msgid ""The request is forbidden from accessing the referenced resource."" msgstr """" #: neutron/plugins/nicira/NvpApiClient.py:251 msgid ""The request has timed out."" msgstr """" #: neutron/plugins/nicira/nvp_cluster.py:55 #, python-format msgid """" ""Attribute '%s' has been deprecated or moved to a new section. See new "" ""configuration file for details."" msgstr """" #: neutron/plugins/nicira/nvp_cluster.py:67 #, python-format msgid ""The following cluster attributes were not specified: %s'"" msgstr """" #: neutron/plugins/nicira/nvp_cluster.py:104 #, python-format msgid ""Attribute:%s is empty or null"" msgstr """" #: neutron/plugins/nicira/nvplib.py:92 #, python-format msgid ""NVP version %(ver)s does not support method %(fun)s."" msgstr """" #: neutron/plugins/nicira/nvplib.py:148 #, python-format msgid ""Specified name:'%s' exceeds maximum length. It will be truncated on NVP"" msgstr """" #: neutron/plugins/nicira/nvplib.py:168 #, python-format msgid ""NVP controller cluster version: %s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:251 #, python-format msgid ""Created logical switch: %s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:267 neutron/plugins/nicira/nvplib.py:594 #, python-format msgid ""Network not found, Error: %s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:505 #, python-format msgid ""Cannot update NVP routes %(routes)s forrouter %(router_id)s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:621 msgid ""Port or Network not found"" msgstr """" #: neutron/plugins/nicira/nvplib.py:639 #, python-format msgid """" ""Looking for port with q_port_id tag '%(neutron_port_id)s' on: "" ""'%(lswitch_uuid)s'"" msgstr """" #: neutron/plugins/nicira/nvplib.py:647 #, python-format msgid """" ""Found '%(num_ports)d' ports with q_port_id tag: '%(neutron_port_id)s'. "" ""Only 1 was expected."" msgstr """" #: neutron/plugins/nicira/nvplib.py:656 #, python-format msgid ""get_port() %(network)s %(port)s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:664 neutron/plugins/nicira/nvplib.py:718 #, python-format msgid ""Port or Network not found, Error: %s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:713 #, python-format msgid ""Updated logical port %(result)s on logical switch %(uuid)s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:749 #, python-format msgid ""Created logical port %(result)s on logical swtich %(uuid)s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:773 #, python-format msgid ""Created logical port %(lport_uuid)s on logical router %(lrouter_uuid)s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:803 #, python-format msgid ""Updated logical port %(lport_uuid)s on logical router %(lrouter_uuid)s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:813 #, python-format msgid """" ""Delete logical router port %(lport_uuid)s on logical router "" ""%(lrouter_uuid)s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:868 #, python-format msgid ""Invalid NVP attachment type '%s'"" msgstr """" #: neutron/plugins/nicira/nvplib.py:880 #, python-format msgid ""Port not found, Error: %s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:999 #, python-format msgid ""Created Security Profile: %s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:1025 #, python-format msgid ""Updated Security Profile: %s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:1044 #, python-format msgid ""Invalid keys for NAT match: %s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:1050 #, python-format msgid ""Creating NAT rule: %s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:1064 msgid """" ""No SNAT rules cannot be applied as they are not available in this version"" "" of the NVP platform"" msgstr """" #: neutron/plugins/nicira/nvplib.py:1199 #, python-format msgid ""Router Port %(lport_id)s not found on router %(lrouter_id)s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:1204 #, python-format msgid """" ""An exception occurred while updating IP addresses on a router logical "" ""port:%s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:1245 msgid ""Failed to create logical queue"" msgstr """" #: neutron/plugins/nicira/nvplib.py:1256 msgid ""Failed to delete logical queue"" msgstr """" #: neutron/plugins/nicira/api_client/client.py:116 #, python-format msgid ""[%d] no API providers currently available."" msgstr """" #: neutron/plugins/nicira/api_client/client.py:119 #, python-format msgid ""[%d] Waiting to acquire API client connection."" msgstr """" #: neutron/plugins/nicira/api_client/client.py:123 #, python-format msgid ""[%(rid)d] Connection %(conn)s idle for %(sec)0.2f seconds; reconnecting."" msgstr """" #: neutron/plugins/nicira/api_client/client.py:132 #, python-format msgid ""[%(rid)d] Acquired connection %(conn)s. %(qsize)d connection(s) available."" msgstr """" #: neutron/plugins/nicira/api_client/client.py:152 #, python-format msgid """" ""[%(rid)d] Released connection %(conn)s is not an API provider for the "" ""cluster"" msgstr """" #: neutron/plugins/nicira/api_client/client.py:161 #, python-format msgid ""[%(rid)d] Connection returned in bad state, reconnecting to %(conn)s"" msgstr """" #: neutron/plugins/nicira/api_client/client.py:186 #, python-format msgid ""[%(rid)d] Released connection %(conn)s. %(qsize)d connection(s) available."" msgstr """" #: neutron/plugins/nicira/api_client/client.py:196 #, python-format msgid ""Login request for an invalid connection: '%s'"" msgstr """" #: neutron/plugins/nicira/api_client/client.py:207 msgid ""Waiting for auth to complete"" msgstr """" #: neutron/plugins/nicira/api_client/client.py:249 #, python-format msgid ""Invalid conn_params value: '%s'"" msgstr """" #: neutron/plugins/nicira/api_client/client_eventlet.py:148 #, python-format msgid ""NvpApiClient: login error \""%s\"""" msgstr """" #: neutron/plugins/nicira/api_client/client_eventlet.py:153 #, python-format msgid ""Saving new authentication cookie '%s'"" msgstr """" #: neutron/plugins/nicira/api_client/common.py:30 #, python-format msgid ""_conn_str() invalid connection type: %s"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:92 msgid ""No API connections available"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:97 #, python-format msgid ""[%(rid)d] Issuing - request %(conn)s"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:122 #, python-format msgid ""Setting X-Nvp-Wait-For-Config-Generation request header: '%s'"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:128 #, python-format msgid ""[%(rid)d] Exception issuing request: %(e)s"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:135 #, python-format msgid ""[%(rid)d] Completed request '%(conn)s': %(status)s (%(sec)0.2f seconds)"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:144 #, python-format msgid ""Reading X-Nvp-config-Generation response header: '%s'"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:173 #, python-format msgid ""[%d] Maximum redirects exceeded, aborting request"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:183 #, python-format msgid ""[%(rid)d] Redirecting request to: %(conn)s"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:195 #, python-format msgid ""[%(rid)d] Request '%(method)s %(url)s' received: %(status)s"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:199 #, python-format msgid ""Server error return: %s"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:203 msgid ""Invalid server response"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:206 #, python-format msgid ""[%(rid)d] Failed request '%(conn)s': '%(msg)s' (%(sec)0.2f seconds)"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:240 #, python-format msgid ""[%d] Received redirect status without location header field"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:257 #, python-format msgid ""[%(rid)d] Received invalid redirect location: '%(url)s'"" msgstr """" #: neutron/plugins/nicira/api_client/request.py:261 #, python-format msgid ""[%(rid)d] Received malformed redirect location: %(url)s"" msgstr """" #: neutron/plugins/nicira/api_client/request_eventlet.py:111 msgid ""Joining an invalid green thread"" msgstr """" #: neutron/plugins/nicira/api_client/request_eventlet.py:131 #, python-format msgid ""[%d] Request timeout."" msgstr """" #: neutron/plugins/nicira/api_client/request_eventlet.py:132 msgid ""Request timeout"" msgstr """" #: neutron/plugins/nicira/api_client/request_eventlet.py:153 #, python-format msgid ""[%(rid)d] Completed request '%(method)s %(url)s': %(status)s"" msgstr """" #: neutron/plugins/nicira/api_client/request_eventlet.py:160 #, python-format msgid ""[%(rid)d] Error while handling request: %(req)s"" msgstr """" #: neutron/plugins/nicira/api_client/request_eventlet.py:216 #, python-format msgid ""[%(rid)d] Failed to parse API provider: %(e)s"" msgstr """" #: neutron/plugins/nicira/common/config.py:21 msgid """" ""Maximum number of ports of a logical switch on a bridged transport zone "" ""(default 64)"" msgstr """" #: neutron/plugins/nicira/common/config.py:24 msgid """" ""Maximum number of ports of a logical switch on an overlay transport zone "" ""(default 64)"" msgstr """" #: neutron/plugins/nicira/common/config.py:27 msgid ""Maximum concurrent connections"" msgstr """" #: neutron/plugins/nicira/common/config.py:29 msgid """" ""Number of seconds a generation id should be valid for (default -1 meaning"" "" do not time out)"" msgstr """" #: neutron/plugins/nicira/common/config.py:32 msgid """" ""If set to access_network this enables a dedicated connection to the "" ""metadata proxy for metadata server access via Neutron router. If set to "" ""dhcp_host_route this enables host route injection via the dhcp agent. "" ""This option is only useful if running on a host that does not support "" ""namespaces otherwise access_network should be used."" msgstr """" #: neutron/plugins/nicira/common/config.py:40 msgid """" ""Enables dedicated connection to the metadata proxy for metadata server "" ""access via Neutron router"" msgstr """" #: neutron/plugins/nicira/common/config.py:43 msgid """" ""The default network tranport type to use (stt, gre, bridge, ipsec_gre, or"" "" ipsec_stt)"" msgstr """" #: neutron/plugins/nicira/common/config.py:50 msgid ""User name for NVP controllers in this cluster"" msgstr """" #: neutron/plugins/nicira/common/config.py:54 msgid ""Password for NVP controllers in this cluster"" msgstr """" #: neutron/plugins/nicira/common/config.py:57 msgid ""Total time limit for a cluster request"" msgstr """" #: neutron/plugins/nicira/common/config.py:60 msgid ""Time before aborting a request"" msgstr """" #: neutron/plugins/nicira/common/config.py:63 msgid ""Number of time a request should be retried"" msgstr """" #: neutron/plugins/nicira/common/config.py:66 msgid ""Number of times a redirect should be followed"" msgstr """" #: neutron/plugins/nicira/common/config.py:68 msgid ""Lists the NVP controllers in this cluster"" msgstr """" #: neutron/plugins/nicira/common/config.py:73 msgid """" ""This is uuid of the default NVP Transport zone that will be used for "" ""creating tunneled isolated \""Neutron\"" networks. It needs to be created "" ""in NVP before starting Neutron with the nvp plugin."" msgstr """" #: neutron/plugins/nicira/common/config.py:78 msgid """" ""Optional paramter identifying the UUID of the cluster in NVP. This can "" ""be retrieved from NVP management console \""admin\"" section."" msgstr """" #: neutron/plugins/nicira/common/config.py:82 msgid """" ""Unique identifier of the NVP L3 Gateway service which will be used for "" ""implementing routers and floating IPs"" msgstr """" #: neutron/plugins/nicira/common/config.py:86 msgid """" ""Unique identifier of the NVP L2 Gateway service which will be used by "" ""default for network gateways"" msgstr """" #: neutron/plugins/nicira/common/config.py:89 msgid """" ""Name of the interface on a L2 Gateway transport nodewhich should be used "" ""by default when setting up a network connection"" msgstr """" #: neutron/plugins/nicira/common/config.py:102 msgid """" ""Describes a connection to a single controller. A different connection for"" "" each controller in the cluster can be specified; there must be at least "" ""one connection per cluster."" msgstr """" #: neutron/plugins/nicira/common/exceptions.py:24 #, python-format msgid ""An unexpected error occurred in the NVP Plugin:%(err_msg)s"" msgstr """" #: neutron/plugins/nicira/common/exceptions.py:28 #, python-format msgid ""Unable to fulfill request with version %(version)s."" msgstr """" #: neutron/plugins/nicira/common/exceptions.py:32 #, python-format msgid ""Invalid NVP connection parameters: %(conn_params)s"" msgstr """" #: neutron/plugins/nicira/common/exceptions.py:36 #, python-format msgid """" ""Invalid cluster values: %(invalid_attrs)s. Please ensure that these "" ""values are specified in the [DEFAULT] section of the nvp plugin ini file."" msgstr """" #: neutron/plugins/nicira/common/exceptions.py:42 #, python-format msgid ""Unable to find cluster config entry for nova zone: %(nova_zone)s"" msgstr """" #: neutron/plugins/nicira/common/exceptions.py:47 #, python-format msgid """" ""Unable to create port on network %(network)s. Maximum number of ports "" ""reached"" msgstr """" #: neutron/plugins/nicira/common/exceptions.py:52 #, python-format msgid """" ""Unable to plug an interface into the port %(port_id)s for network "" ""%(net_id)s. This interface is already plugged into port %(att_port_id)s"" msgstr """" #: neutron/plugins/nicira/common/exceptions.py:58 #, python-format msgid """" ""While retrieving NAT rules, %(actual_rules)s were found whereas rules in "" ""the (%(min_rules)s,%(max_rules)s) interval were expected"" msgstr """" #: neutron/plugins/nicira/common/metadata_access.py:112 msgid ""Metadata access network is disabled"" msgstr """" #: neutron/plugins/nicira/common/metadata_access.py:115 msgid """" ""Overlapping IPs must be enabled in order to setup the metadata access "" ""network"" msgstr """" #: neutron/plugins/nicira/common/metadata_access.py:141 #, python-format msgid """" ""No router interface found for router '%s'. No metadata access network "" ""should be created or destroyed"" msgstr """" #: neutron/plugins/nicira/common/metadata_access.py:149 #, python-format msgid """" ""An error occurred while operating on the metadata access network for "" ""router:'%s'"" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:47 #, python-format msgid """" ""Network Gateway '%(gateway_id)s' still has active mappings with one or "" ""more neutron networks."" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:52 #, python-format msgid """" ""Port '%(port_id)s' is owned by '%(device_owner)s' and therefore cannot be"" "" deleted directly via the port API."" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:57 #, python-format msgid """" ""The specified mapping '%(mapping)s' is already in use on network gateway "" ""'%(gateway_id)s'."" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:62 #, python-format msgid """" ""Multiple network connections found on '%(gateway_id)s' with provided "" ""criteria."" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:67 #, python-format msgid """" ""The connection %(network_mapping_info)s was not found on the network "" ""gateway '%(network_gateway_id)s'"" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:72 #, python-format msgid ""The network gateway %(gateway_id)s cannot be updated or deleted"" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:167 msgid """" ""A network identifier must be specified when connecting a network to a "" ""network gateway. Unable to complete operation"" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:173 #, python-format msgid """" ""Invalid keys found among the ones provided in request body: "" ""%(connection_attrs)s."" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:179 msgid """" ""In order to specify a segmentation id the segmentation type must be "" ""specified as well"" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:183 msgid ""Cannot specify a segmentation id when the segmentation type is flat"" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:232 #, python-format msgid ""Created network gateway with id:%s"" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:244 #, python-format msgid ""Updated network gateway with id:%s"" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:259 #, python-format msgid ""Network gateway '%s' was destroyed."" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:269 #, python-format msgid ""Connecting network '%(network_id)s' to gateway '%(network_gateway_id)s'"" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:310 #, python-format msgid """" ""Requested network '%(network_id)s' not found.Unable to create network "" ""connection on gateway '%(network_gateway_id)s"" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:318 #, python-format msgid """" ""Gateway port for '%(network_gateway_id)s' created on network "" ""'%(network_id)s':%(port_id)s"" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:334 #, python-format msgid ""Ensured no Ip addresses are configured on port %s"" msgstr """" #: neutron/plugins/nicira/dbexts/nicira_networkgw_db.py:344 #, python-format msgid """" ""Disconnecting network '%(network_id)s' from gateway "" ""'%(network_gateway_id)s'"" msgstr """" #: neutron/plugins/nicira/extensions/nvp_networkgw.py:66 msgid ""Cannot create a gateway with an empty device list"" msgstr """" #: neutron/plugins/nicira/extensions/nvp_networkgw.py:92 msgid ""number of network gateways allowed per tenant, -1 for unlimited"" msgstr """" #: neutron/plugins/nicira/extensions/nvp_qos.py:38 msgid ""Need to be admin in order to create queue called default"" msgstr """" #: neutron/plugins/nicira/extensions/nvp_qos.py:42 msgid ""Default queue already exists."" msgstr """" #: neutron/plugins/nicira/extensions/nvp_qos.py:46 #, python-format msgid ""Invalid value for dscp %(data)s must be integer valuebetween 0 and 63."" msgstr """" #: neutron/plugins/nicira/extensions/nvp_qos.py:51 msgid ""Invalid bandwidth rate, min greater than max."" msgstr """" #: neutron/plugins/nicira/extensions/nvp_qos.py:55 #, python-format msgid ""Invalid bandwidth rate, %(data)s must be a non negative integer."" msgstr """" #: neutron/plugins/nicira/extensions/nvp_qos.py:60 msgid ""No DSCP field needed when QoS workload marked trusted"" msgstr """" #: neutron/plugins/nicira/extensions/nvp_qos.py:64 #, python-format msgid ""Queue %(id)s does not exist"" msgstr """" #: neutron/plugins/nicira/extensions/nvp_qos.py:68 msgid ""Unable to delete queue attached to port."" msgstr """" #: neutron/plugins/nicira/extensions/nvp_qos.py:72 msgid ""Port is not associated with lqueue"" msgstr """" #: neutron/plugins/nicira/extensions/nvp_qos.py:83 #, python-format msgid ""'%s' must be a non negative integer."" msgstr """" #: neutron/plugins/openvswitch/ovs_db_v2.py:214 #, python-format msgid ""Skipping unreasonable tunnel ID range %(tun_min)s:%(tun_max)s"" msgstr """" #: neutron/plugins/openvswitch/ovs_db_v2.py:262 #, python-format msgid ""Reserving tunnel %s from pool"" msgstr """" #: neutron/plugins/openvswitch/ovs_db_v2.py:277 #, python-format msgid ""Reserving specific tunnel %s from pool"" msgstr """" #: neutron/plugins/openvswitch/ovs_db_v2.py:280 #, python-format msgid ""Reserving specific tunnel %s outside pool"" msgstr """" #: neutron/plugins/openvswitch/ovs_db_v2.py:303 #, python-format msgid ""Releasing tunnel %s outside pool"" msgstr """" #: neutron/plugins/openvswitch/ovs_db_v2.py:305 #, python-format msgid ""Releasing tunnel %s to pool"" msgstr """" #: neutron/plugins/openvswitch/ovs_db_v2.py:307 #, python-format msgid ""tunnel_id %s not found"" msgstr """" #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:141 #, python-format msgid ""Device %(device)s up on %(agent_id)s"" msgstr """" #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:280 #, python-format msgid ""Invalid tenant_network_type: %s. Server terminated!"" msgstr """" #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:296 #, python-format msgid ""Tunneling disabled but tenant_network_type is '%s'. Server terminated!"" msgstr """" #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:337 #, python-format msgid ""Invalid tunnel ID range: '%(range)s' - %(e)s. Server terminated!"" msgstr """" #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:341 #, python-format msgid ""Tunnel ID ranges: %s"" msgstr """" #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:394 #, python-format msgid ""%s networks are not enabled"" msgstr """" #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:397 #, python-format msgid ""provider:physical_network specified for %s network"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:257 #, python-format msgid ""Network %s not used on agent."" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:288 msgid ""tunnel_update received"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:297 msgid ""No tunnel_type specified, cannot create tunnels"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:300 #, python-format msgid ""tunnel_type %s not supported by agent"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:328 #, python-format msgid ""No local VLAN available for net-id=%s"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:331 #, python-format msgid ""Assigning %(vlan_id)s as local vlan for net-id=%(net_uuid)s"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:353 #, python-format msgid """" ""Cannot provision %(network_type)s network for net-id=%(net_uuid)s - "" ""tunneling disabled"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:372 #, python-format msgid """" ""Cannot provision flat network for net-id=%(net_uuid)s - no bridge for "" ""physical_network %(physical_network)s"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:392 #, python-format msgid """" ""Cannot provision VLAN network for net-id=%(net_uuid)s - no bridge for "" ""physical_network %(physical_network)s"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:401 #, python-format msgid """" ""Cannot provision unknown network type %(network_type)s for net-"" ""id=%(net_uuid)s"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:413 #, python-format msgid ""Reclaiming vlan = %(vlan_id)s from net-id = %(net_uuid)s"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:447 #, python-format msgid """" ""Cannot reclaim unknown network type %(network_type)s for net-"" ""id=%(net_uuid)s"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:498 #, python-format msgid ""port_unbound() net_uuid %s not in local_vlan_map"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:511 #, python-format msgid ""port_unbound: vif_id %s not in local_vlan_map"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:556 msgid """" ""Failed to create OVS patch port. Cannot have tunneling enabled on this "" ""agent, since this version of OVS does not support tunnels or patch ports."" "" Agent terminated!"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:577 #, python-format msgid ""Mapping physical network %(physical_network)s to bridge %(bridge)s"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:583 #, python-format msgid """" ""Bridge %(bridge)s for physical network %(physical_network)s does not "" ""exist. Agent terminated!"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:637 #, python-format msgid ""No VIF port for port %s defined on agent."" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:719 #, python-format msgid ""Unable to sync tunnel IP %(local_ip)s: %(e)s"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:739 msgid ""Agent tunnel out of sync with plugin!"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:771 msgid ""Checking OVS version for VXLAN support"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:779 #, python-format msgid """" ""Failed userspace version check for Open vSwitch with VXLAN support. To "" ""use VXLAN tunnels with OVS, please ensure the OVS version is %s or newer!"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:790 #, python-format msgid """" ""Failed kernel version check for Open vSwitch with VXLAN support. To use "" ""VXLAN tunnels with OVS, please ensure the OVS version is %s or newer!"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:797 #, python-format msgid """" ""Cannot determine kernel Open vSwitch version, please ensure your Open "" ""vSwitch kernel module is at least version %s to support VXLAN tunnels."" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:802 #, python-format msgid """" ""Unable to determine Open vSwitch version. Please ensure that its version "" ""is %s or newer to use VXLAN tunnels with OVS."" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:817 #, python-format msgid ""Parsing bridge_mappings failed: %s."" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:836 #, python-format msgid ""Invalid tunnel type specificed: %s"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:839 msgid ""Tunneling cannot be enabled without a valid local_ip."" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:855 #, python-format msgid ""%s Agent terminated!"" msgstr """" #: neutron/plugins/openvswitch/common/config.py:32 msgid ""Enable tunneling support"" msgstr """" #: neutron/plugins/openvswitch/common/config.py:34 msgid ""Tunnel bridge to use"" msgstr """" #: neutron/plugins/openvswitch/common/config.py:36 msgid ""Peer patch port in integration bridge for tunnel bridge"" msgstr """" #: neutron/plugins/openvswitch/common/config.py:39 msgid ""Peer patch port in tunnel bridge for integration bridge"" msgstr """" #: neutron/plugins/openvswitch/common/config.py:42 msgid ""Local IP address of GRE tunnel endpoints."" msgstr """" #: neutron/plugins/openvswitch/common/config.py:45 msgid ""List of <physical_network>:<bridge>"" msgstr """" #: neutron/plugins/openvswitch/common/config.py:47 msgid ""Network type for tenant networks (local, vlan, gre, vxlan, or none)"" msgstr """" #: neutron/plugins/openvswitch/common/config.py:55 msgid ""List of <tun_min>:<tun_max>"" msgstr """" #: neutron/plugins/openvswitch/common/config.py:57 msgid ""The type of tunnels to use when utilizing tunnels, either 'gre' or 'vxlan'"" msgstr """" #: neutron/plugins/openvswitch/common/config.py:66 msgid ""Network types supported by the agent (gre and/or vxlan)"" msgstr """" #: neutron/plugins/openvswitch/common/config.py:69 msgid ""The UDP port to use for VXLAN tunnels."" msgstr """" #: neutron/plugins/plumgrid/common/exceptions.py:26 #, python-format msgid ""An unexpected error occurred in the PLUMgrid Plugin: %(err_msg)s"" msgstr """" #: neutron/plugins/plumgrid/common/exceptions.py:31 #, python-format msgid ""Connection failed with PLUMgrid NOS: %(err_msg)s"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_nos_snippets.py:34 msgid ""NeutronPluginPLUMgrid Status: NOS Body Data Creation"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:40 msgid ""PLUMgrid NOS server to connect to"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:42 msgid ""PLUMgrid NOS server port to connect to"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:44 msgid ""PLUMgrid NOS admin username"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:46 msgid ""PLUMgrid NOS admin password"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:48 msgid ""PLUMgrid NOS server timeout"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:50 msgid ""PLUMgrid NOS topology name"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:59 msgid ""NeutronPluginPLUMgrid Status: Starting Plugin"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:74 msgid ""NeutronPluginPLUMgrid Status: Aborting Plugin"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:82 #, python-format msgid ""NeutronPluginPLUMgrid NOS: %s"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:84 msgid ""NeutronPluginPLUMgrid Status: NOS value is missing in config file"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:87 msgid """" ""NeutronPluginPLUMgrid Status: Neutron server with PLUMgrid Plugin has "" ""started"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:93 msgid ""NeutronPluginPLUMgrid Status: create_network() called"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:105 #, python-format msgid ""NeutronPluginPLUMgrid Status: %(tenant_id)s, %(network)s, %(network_id)s"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:119 #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:151 #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:175 msgid ""PLUMgrid NOS communication failed"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:129 msgid ""NeutronPluginPLUMgridV2.update_network() called"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:160 msgid ""NeutronPluginPLUMgrid Status: delete_network() called"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:181 msgid ""NeutronPluginPLUMgrid Status: create_port() called"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:193 msgid ""NeutronPluginPLUMgrid Status: update_port() called"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:205 msgid ""NeutronPluginPLUMgrid Status: delete_port() called"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:216 msgid ""NeutronPluginPLUMgrid Status: create_subnet() called"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:234 #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:257 #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:289 msgid ""PLUMgrid NOS communication failed: "" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:243 msgid ""NeutronPluginPLUMgrid Status: delete_subnet() called"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:318 #, python-format msgid """" ""Network with admin_state_up=False are not supported yet by this plugin. "" ""Ignoring setting for network %s"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/plumgrid_plugin.py:322 msgid ""Network Admin State Validation Falied: "" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/rest_connection.py:40 msgid ""NeutronPluginPLUMgrid Status: REST Connection Started"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/rest_connection.py:53 #, python-format msgid ""PLUMgrid_NOS_Server: %(server)s %(port)s %(action)s"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/rest_connection.py:59 msgid ""PLUMgrid_NOS_Server: Could not establish HTTP connection"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/rest_connection.py:64 #, python-format msgid ""PLUMgrid_NOS_Server Sending Data: %(nos_url)s %(body_data)s %(headers)s"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/rest_connection.py:75 #, python-format msgid ""PLUMgrid_NOS_Server Connection Data: %(resp)s, %(resp_str)s"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/rest_connection.py:81 #, python-format msgid ""PLUMgrid_NOS_Server Connection RESP: %s"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/rest_connection.py:85 msgid ""PLUMgrid HTTP Connection Failed: "" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/rest_connection.py:91 #, python-format msgid ""PLUMgrid_NOS_Server: %(action)s failure, %(e)r"" msgstr """" #: neutron/plugins/plumgrid/plumgrid_nos_plugin/rest_connection.py:94 #, python-format msgid ""PLUMgrid_NOS_Server: status=%(status)d, reason=%(reason)r, ret=%(ret)s"" msgstr """" #: neutron/plugins/ryu/ryu_neutron_plugin.py:59 #, python-format msgid ""get_ofp_rest_api: %s"" msgstr """" #: neutron/plugins/ryu/ryu_neutron_plugin.py:110 msgid ""Invalid configuration. check ryu.ini"" msgstr """" #: neutron/plugins/ryu/agent/ryu_neutron_agent.py:150 #, python-format msgid ""External port %s"" msgstr """" #: neutron/plugins/ryu/agent/ryu_neutron_agent.py:158 msgid ""Get Ryu rest API address"" msgstr """" #: neutron/plugins/ryu/agent/ryu_neutron_agent.py:208 msgid ""Ryu rest API port isn't specified"" msgstr """" #: neutron/plugins/ryu/agent/ryu_neutron_agent.py:209 #, python-format msgid ""Going to ofp controller mode %s"" msgstr """" #: neutron/plugins/ryu/agent/ryu_neutron_agent.py:226 msgid ""port update received"" msgstr """" #: neutron/plugins/ryu/agent/ryu_neutron_agent.py:259 msgid ""Agent loop has new device"" msgstr """" #: neutron/plugins/ryu/agent/ryu_neutron_agent.py:286 #, python-format msgid ""tunnel_ip %s"" msgstr """" #: neutron/plugins/ryu/agent/ryu_neutron_agent.py:288 #, python-format msgid ""ovsdb_port %s"" msgstr """" #: neutron/plugins/ryu/agent/ryu_neutron_agent.py:290 #, python-format msgid ""ovsdb_ip %s"" msgstr """" #: neutron/plugins/ryu/agent/ryu_neutron_agent.py:296 #, python-format msgid ""Initialization failed: %s"" msgstr """" #: neutron/plugins/ryu/agent/ryu_neutron_agent.py:299 msgid """" ""Ryu initialization on the node is done. Agent initialized successfully, "" ""now running..."" msgstr """" #: neutron/plugins/ryu/common/config.py:26 msgid ""OpenFlow REST API location"" msgstr """" #: neutron/plugins/ryu/common/config.py:28 msgid ""Minimum tunnel ID to use"" msgstr """" #: neutron/plugins/ryu/common/config.py:30 msgid ""Maximum tunnel ID to use"" msgstr """" #: neutron/plugins/ryu/common/config.py:32 msgid ""Tunnel IP to use"" msgstr """" #: neutron/plugins/ryu/common/config.py:34 msgid ""Tunnel interface to use"" msgstr """" #: neutron/plugins/ryu/common/config.py:36 msgid ""OVSDB port to connect to"" msgstr """" #: neutron/plugins/ryu/common/config.py:38 msgid ""OVSDB IP to connect to"" msgstr """" #: neutron/plugins/ryu/common/config.py:40 msgid ""OVSDB interface to connect to"" msgstr """" #: neutron/plugins/ryu/db/api_v2.py:40 #, python-format msgid ""get_port_from_device() called:port_id=%s"" msgstr """" #: neutron/plugins/ryu/db/api_v2.py:76 #, python-format msgid """" ""Invalid tunnel key options tunnel_key_min: %(key_min)d tunnel_key_max: "" ""%(key_max)d. Using default value"" msgstr """" #: neutron/plugins/ryu/db/api_v2.py:156 #, python-format msgid ""last_key %(last_key)s new_key %(new_key)s"" msgstr """" #: neutron/plugins/ryu/db/api_v2.py:159 msgid ""No key found"" msgstr """" #: neutron/plugins/ryu/db/api_v2.py:192 #, python-format msgid ""Transaction retry exhausted (%d). Abandoned tunnel key allocation."" msgstr """" #: neutron/scheduler/dhcp_agent_scheduler.py:42 #, python-format msgid """" ""Network %(network_id)s is scheduled to be hosted by DHCP agent "" ""%(agent_id)s"" msgstr """" #: neutron/scheduler/dhcp_agent_scheduler.py:60 #, python-format msgid ""Network %s is hosted already"" msgstr """" #: neutron/scheduler/dhcp_agent_scheduler.py:69 #: neutron/scheduler/dhcp_agent_scheduler.py:78 msgid ""No more DHCP agents"" msgstr """" #: neutron/scheduler/dhcp_agent_scheduler.py:101 #, python-format msgid ""DHCP agent %s is not active"" msgstr """" #: neutron/scheduler/dhcp_agent_scheduler.py:108 msgid ""No non-hosted networks"" msgstr """" #: neutron/scheduler/l3_agent_scheduler.py:57 #, python-format msgid ""No enabled L3 agent on host %s"" msgstr """" #: neutron/scheduler/l3_agent_scheduler.py:62 #, python-format msgid ""L3 agent %s is not active"" msgstr """" #: neutron/scheduler/l3_agent_scheduler.py:70 #: neutron/scheduler/l3_agent_scheduler.py:128 #, python-format msgid ""Router %(router_id)s has already been hosted by L3 agent %(agent_id)s"" msgstr """" #: neutron/scheduler/l3_agent_scheduler.py:89 msgid ""No non-hosted routers"" msgstr """" #: neutron/scheduler/l3_agent_scheduler.py:103 #, python-format msgid ""No routers compatible with L3 agent configuration on host %s"" msgstr """" #: neutron/scheduler/l3_agent_scheduler.py:137 msgid ""No active L3 agents"" msgstr """" #: neutron/scheduler/l3_agent_scheduler.py:142 #, python-format msgid ""No L3 agents can host the router %s"" msgstr """" #: neutron/scheduler/l3_agent_scheduler.py:151 #, python-format msgid ""Router %(router_id)s is scheduled to L3 agent %(agent_id)s"" msgstr """" #: neutron/server/__init__.py:37 msgid """" ""ERROR: Unable to find configuration file via the default search paths "" ""(~/.neutron/, ~/, /etc/neutron/, /etc/) and the '--config-file' option!"" msgstr """" #: neutron/server/__init__.py:44 #, python-format msgid ""ERROR: %s"" msgstr """" #: neutron/services/loadbalancer/plugin.py:35 msgid ""LBaaS driver Fully Qualified Name"" msgstr """" #: neutron/services/loadbalancer/plugin.py:68 #, python-format msgid ""Error loading LBaaS driver %s"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/agent.py:36 msgid ""Seconds between periodic task runs"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:41 msgid ""The driver used to manage the loadbalancing device"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:46 msgid ""Location to store config and state files"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:50 msgid ""The driver used to manage the virtual interface"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:55 msgid ""The user group"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:119 #, python-format msgid ""Error importing interface driver: %s"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:132 #, python-format msgid ""Error importing loadbalancer device driver: %s"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:160 msgid ""Error upating stats"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:181 msgid ""Unable to retrieve ready devices"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:196 #, python-format msgid ""Unable to refresh device for pool: %s"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/agent_manager.py:207 #, python-format msgid ""Unable to destroy device for pool: %s"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py:123 #, python-format msgid ""Error while connecting to stats socket: %s"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py:126 #, python-format msgid ""Stats socket not found for pool %s"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py:216 #, python-format msgid ""Unable to kill haproxy process: %s"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:91 msgid ""Expected active pool and vip"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:136 #, python-format msgid ""Unable to find port %s to plug."" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:160 #: neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py:177 #, python-format msgid """" ""Unable to find port %s to unplug. This can occur when the Vip has been "" ""deleted first."" msgstr """" #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:180 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:204 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:225 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:250 #, python-format msgid ""Unexpected error code: %s"" msgstr """" #: neutron/tests/unit/ml2/drivers/mechanism_logger.py:32 #, python-format msgid """" ""%(method)s called with network settings %(current)s (original settings "" ""%(original)s) and network segments %(segments)s"" msgstr """" #: neutron/tests/unit/ml2/drivers/mechanism_logger.py:60 #, python-format msgid """" ""%(method)s called with port settings %(current)s (original settings "" ""%(original)s) on network %(network)s"" msgstr """" #: neutron/tests/unit/nicira/fake_nvpapiclient.py:375 #, python-format msgid ""lswitch:%s not found"" msgstr """" #: neutron/tests/unit/nicira/fake_nvpapiclient.py:384 #, python-format msgid ""lrouter:%s not found"" msgstr """" ",,175305,176
openstack%2Fpython-openstackclient~master~Ie2bfe660aac8a0fcf651c67fd1ea4842e76ce377,openstack/python-openstackclient,master,Ie2bfe660aac8a0fcf651c67fd1ea4842e76ce377,Complete Image v1,MERGED,2013-07-09 18:58:19.000000000,2013-07-20 20:17:00.000000000,2013-07-20 20:17:00.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1699}, {'_account_id': 2472}, {'_account_id': 6482}]","[{'number': 1, 'created': '2013-07-09 18:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4cb5212d03ff87dc4dba8242351ecca5c3c35ac4', 'message': 'Complete Image v1\n\n* Add v1 versions of image delete, list, save, show\n* Change default Image API to v1\n\nChange-Id: Ie2bfe660aac8a0fcf651c67fd1ea4842e76ce377\n'}, {'number': 2, 'created': '2013-07-09 20:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a57127d0627154b5e1102ac1952e4da88f23161c', 'message': 'Complete Image v1\n\n* Add v1 versions of image delete, list, save, set, show\n* Change default Image API to v1\n\nChange-Id: Ie2bfe660aac8a0fcf651c67fd1ea4842e76ce377\n'}, {'number': 3, 'created': '2013-07-12 17:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b70a5ed581df89cc141dded64aceb69e5b4be262', 'message': 'Complete Image v1\n\n* Add v1 versions of image delete, list, save, set, show\n* Change default Image API to v1\n\nRebased for https://review.openstack.org/#/c/36772/\n\nChange-Id: Ie2bfe660aac8a0fcf651c67fd1ea4842e76ce377\n'}, {'number': 4, 'created': '2013-07-18 19:14:46.000000000', 'files': ['openstackclient/tests/test_shell.py', 'openstackclient/image/client.py', 'openstackclient/shell.py', 'openstackclient/image/v1/image.py', 'setup.cfg', 'openstackclient/image/v2/image.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/cdaee1b71e21df56e6127689801240274af9d847', 'message': 'Complete Image v1\n\n* Add v1 versions of image delete, list, save, set, show\n* Change default Image API to v1\n\nRebased for https://review.openstack.org/#/c/36772/\n\nChange-Id: Ie2bfe660aac8a0fcf651c67fd1ea4842e76ce377\n'}]",6,36324,cdaee1b71e21df56e6127689801240274af9d847,16,5,4,970,,,0,"Complete Image v1

* Add v1 versions of image delete, list, save, set, show
* Change default Image API to v1

Rebased for https://review.openstack.org/#/c/36772/

Change-Id: Ie2bfe660aac8a0fcf651c67fd1ea4842e76ce377
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/24/36324/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/image/client.py', 'openstackclient/tests/test_shell.py', 'openstackclient/shell.py', 'openstackclient/image/v1/image.py', 'setup.cfg', 'openstackclient/image/v2/image.py']",6,4cb5212d03ff87dc4dba8242351ecca5c3c35ac4,image-v1,"# Copyright 2012-2013 OpenStack Foundationimport six """"""Delete an image"""""" ""image"", metavar=""<image>"", help=""Name or ID of image to delete"", ) image = utils.find_resource( image_client.images, parsed_args.image, ) image_client.images.delete(image) """"""List available images"""""" help=""Number of images to request in each paginated request"", ) """"""Save an image locally"""""" metavar=""<filename>"", help=""Downloaded image save filename [default: stdout]"", ) ""image"", metavar=""<image>"", help=""Name or ID of image to delete"", ) image = utils.find_resource( image_client.images, parsed_args.image, ) data = image_client.images.data(image) """"""Show image details"""""" ""image"", metavar=""<image>"", help=""Name or ID of image to display"", ) image = utils.find_resource( image_client.images, parsed_args.image, ) info = {} info.update(image._info) return zip(*sorted(six.iteritems(info)))","# Copyright 2012-2013 OpenStack, LLC. """"""Delete image command"""""" ""id"", metavar=""<image_id>"", help=""ID of image to delete."") image_client.images.delete(parsed_args.id) """"""List image command"""""" help=""Number of images to request in each paginated request."") """"""Save image command"""""" metavar=""<file>"", help=""Local file to save downloaded image data "" ""to. If this is not specified the image "" ""data will be written to stdout."") ""id"", metavar=""<image_id>"", help=""ID of image to describe."") data = image_client.images.data(parsed_args.id) """"""Show image command"""""" ""id"", metavar=""<image_id>"", help=""ID of image to describe."") data = image_client.images.get(parsed_args.id) return zip(*sorted(data.iteritems()))",271,51
openstack%2Fneutron~master~I9248a335db961aa5d776a545dcfba0ddb0f08bb2,openstack/neutron,master,I9248a335db961aa5d776a545dcfba0ddb0f08bb2,Add help strings to Config Options,MERGED,2013-07-19 16:50:56.000000000,2013-07-20 20:01:54.000000000,2013-07-20 20:01:53.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 2592}, {'_account_id': 6072}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-07-19 16:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/62070f9f1f61964828a932d7fd16ec48e680fcc1', 'message': 'Add help strings to Config Options\n\nAdd an help string to the config options\n\nChange-Id: I9248a335db961aa5d776a545dcfba0ddb0f08bb2\n'}, {'number': 2, 'created': '2013-07-19 20:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6bd870bdada54c6ff851efef7da5a80c22402cf2', 'message': 'Add help strings to Config Options\n\nAdd an help string to the config options\n\nChange-Id: I9248a335db961aa5d776a545dcfba0ddb0f08bb2\n'}, {'number': 3, 'created': '2013-07-20 06:34:49.000000000', 'files': ['neutron/plugins/bigswitch/plugin.py', 'neutron/common/config.py', 'neutron/agent/securitygroups_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a7c23c3247ac3acafaef26c9b8f16bdd007e3a13', 'message': 'Add help strings to Config Options\n\nAdd an help string to the config options\n\nChange-Id: I9248a335db961aa5d776a545dcfba0ddb0f08bb2\n'}]",7,37940,a7c23c3247ac3acafaef26c9b8f16bdd007e3a13,14,6,3,6593,,,0,"Add help strings to Config Options

Add an help string to the config options

Change-Id: I9248a335db961aa5d776a545dcfba0ddb0f08bb2
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/37940/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/bigswitch/plugin.py', 'neutron/common/config.py', 'neutron/agent/securitygroups_rpc.py']",3,62070f9f1f61964828a932d7fd16ec48e680fcc1,add_help_to_config," default='neutron.agent.firewall.NoopFirewallDriver', help='Driver for Firewall')", default='neutron.agent.firewall.NoopFirewallDriver'),9,3
openstack%2Ftempest~master~I90252fcbb90faec60eae59bcb9669f87e8fd50fa,openstack/tempest,master,I90252fcbb90faec60eae59bcb9669f87e8fd50fa,add missing apache2 license headers,MERGED,2013-07-19 18:32:54.000000000,2013-07-20 19:47:10.000000000,2013-07-20 19:47:10.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5196}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-19 18:32:54.000000000', 'files': ['tempest/services/network/json/network_client.py', 'tempest/common/utils/linux/remote_client.py', 'tempest/services/identity/json/identity_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/556add55af22c52daeb2fd3c148b130b9dc22e89', 'message': 'add missing apache2 license headers\n\nhacking 0.6 introduces H102 - missing apache license header on the\nfile, which was written because I found these three files missing\nthe headers. Fix them in prepartion for landing hacking 0.6\n\nChange-Id: I90252fcbb90faec60eae59bcb9669f87e8fd50fa\n'}]",0,37951,556add55af22c52daeb2fd3c148b130b9dc22e89,8,4,1,2750,,,0,"add missing apache2 license headers

hacking 0.6 introduces H102 - missing apache license header on the
file, which was written because I found these three files missing
the headers. Fix them in prepartion for landing hacking 0.6

Change-Id: I90252fcbb90faec60eae59bcb9669f87e8fd50fa
",git fetch https://review.opendev.org/openstack/tempest refs/changes/51/37951/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/network/json/network_client.py', 'tempest/common/utils/linux/remote_client.py', 'tempest/services/identity/json/identity_client.py']",3,556add55af22c52daeb2fd3c148b130b9dc22e89,hacking_0_6,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ",,43,0
openstack%2Ftempest~master~I7972befbb945a27ed8aa601975205736038eefa2,openstack/tempest,master,I7972befbb945a27ed8aa601975205736038eefa2,fix use of locals() in strings,MERGED,2013-07-19 18:32:54.000000000,2013-07-20 19:39:15.000000000,2013-07-20 19:39:15.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5196}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-19 18:32:54.000000000', 'files': ['tempest/api/compute/servers/test_list_servers_negative.py', 'tempest/scenario/manager.py', 'tempest/common/glance_http.py', 'tempest/clients.py', 'tempest/config.py', 'tempest/manager.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/43cd905141d805f1a4de6af0d96d092c90898d5e', 'message': ""fix use of locals() in strings\n\nhacking 0.6 brings in H501, don't use locals() in strings, as it\nhas the ability to hide errors. This fixes it in preparation of\nlanding hacking 0.6.\n\nChange-Id: I7972befbb945a27ed8aa601975205736038eefa2\n""}]",0,37950,43cd905141d805f1a4de6af0d96d092c90898d5e,7,4,1,2750,,,0,"fix use of locals() in strings

hacking 0.6 brings in H501, don't use locals() in strings, as it
has the ability to hide errors. This fixes it in preparation of
landing hacking 0.6.

Change-Id: I7972befbb945a27ed8aa601975205736038eefa2
",git fetch https://review.opendev.org/openstack/tempest refs/changes/50/37950/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/servers/test_list_servers_negative.py', 'tempest/scenario/manager.py', 'tempest/clients.py', 'tempest/common/glance_http.py', 'tempest/config.py', 'tempest/manager.py']",6,43cd905141d805f1a4de6af0d96d092c90898d5e,hacking_0_6," # we do this everywhere, have it be part of the super class def _validate_credentials(self, username, password, tenant_name): if None in (username, password, tenant_name): msg = (""Missing required credentials. "" ""username: %(u)s, password: %(p)s, "" ""tenant_name: %(t)s"" % {'u': username, 'p': password, 't': tenant_name}) raise exceptions.InvalidConfiguration(msg) self._validate_credentials(username, password, tenant_name)"," if None in (username, password, tenant_name): msg = (""Missing required credentials. "" ""username: %(username)s, password: %(password)s, "" ""tenant_name: %(tenant_name)s"") % locals() raise exceptions.InvalidConfiguration(msg)",27,31
openstack%2Fcookbook-openstack-block-storage~master~Ifcec59a28a4531f8e708c3d053c3cf6c8e99b710,openstack/cookbook-openstack-block-storage,master,Ifcec59a28a4531f8e708c3d053c3cf6c8e99b710,add PostgreSQL support,MERGED,2013-07-17 15:56:18.000000000,2013-07-20 17:17:18.000000000,2013-07-20 17:17:18.000000000,"[{'_account_id': 3}, {'_account_id': 216}, {'_account_id': 1032}]","[{'number': 1, 'created': '2013-07-17 15:56:18.000000000', 'files': ['recipes/volume.rb', 'spec/volume_spec.rb', 'spec/scheduler-redhat_spec.rb', 'spec/volume-redhat_spec.rb', 'attributes/default.rb', 'recipes/scheduler.rb', 'spec/api_spec.rb', 'spec/api-redhat_spec.rb', 'recipes/api.rb', 'spec/scheduler_spec.rb', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/4949b57572a089c9b23dab21d5ae45ace2316c68', 'message': 'add PostgreSQL support\n\nChange-Id: Ifcec59a28a4531f8e708c3d053c3cf6c8e99b710\n'}]",0,37513,4949b57572a089c9b23dab21d5ae45ace2316c68,6,3,1,2340,,,0,"add PostgreSQL support

Change-Id: Ifcec59a28a4531f8e708c3d053c3cf6c8e99b710
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/13/37513/1 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/volume.rb', 'spec/scheduler-redhat_spec.rb', 'spec/volume_spec.rb', 'spec/volume-redhat_spec.rb', 'attributes/default.rb', 'recipes/scheduler.rb', 'spec/api-redhat_spec.rb', 'spec/api_spec.rb', 'recipes/api.rb', 'spec/scheduler_spec.rb', 'README.md']",11,4949b57572a089c9b23dab21d5ae45ace2316c68,postgres,"| **Author** | Ionut Artarisi (<iartarisi@suse.cz>) || **Copyright** | Copyright (c) 2013, SUSE Linux GmbH |",,114,6
openstack%2Fheat~master~Ifae6c676cd47cdf7fe9d297e322643c4b1b024fb,openstack/heat,master,Ifae6c676cd47cdf7fe9d297e322643c4b1b024fb,Compress the userdata so more userdata can be passed,ABANDONED,2013-06-25 22:16:41.000000000,2013-07-20 14:00:37.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2834}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 5638}, {'_account_id': 6434}, {'_account_id': 6488}, {'_account_id': 7253}, {'_account_id': 7256}]","[{'number': 1, 'created': '2013-06-25 22:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bb12875e184a91c519381b4fc72440c2c23f6588', 'message': 'Compress the userdata so more userdata can be passed\n\nThis code compresses most of the cloudinit metadata.  A new mime\ntype is introduced c-shellscript-c which is like x-shellscript but\ncompressed.  This allows the loguserdata.py shell script to be\ncompressed since it is large.  All of the existing x-cfninitdata\nmime type is compressed before sending and decompressed in the\ninstance by the part handler.\n\nThis is pre-work for compressing the entire cfn tools into the\nuserdata.\n\nI attempted a full compression of the entire cloudinit mime message\nwhich does not appear to work well with the rest of openstack.\n\nblueprint gzip-userdata\n\nChange-Id: Ifae6c676cd47cdf7fe9d297e322643c4b1b024fb\n'}, {'number': 2, 'created': '2013-07-02 19:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cd3ee88a52eebfbf44760046553b311875e9f7fb', 'message': 'Compress the userdata so more userdata can be passed\n\nThis code compresses most of the cloudinit metadata.  A new mime\ntype is introduced c-shellscript-c which is like x-shellscript but\ncompressed.  This allows the loguserdata.py shell script to be\ncompressed since it is large.  All of the existing x-cfninitdata\nmime type is compressed before sending and decompressed in the\ninstance by the part handler.\n\nThis is pre-work for compressing the entire cfn tools into the\nuserdata.\n\nI attempted a full compression of the entire cloudinit mime message\nwhich does not appear to work well with the rest of openstack.\n\nblueprint gzip-userdata\n\nChange-Id: Ifae6c676cd47cdf7fe9d297e322643c4b1b024fb\n'}, {'number': 3, 'created': '2013-07-02 21:13:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4b24ccf884b248020bbd11d13189f36a007ce817', 'message': 'Compress the userdata so more userdata can be passed\n\nThis code compresses most of the cloudinit metadata.  A new mime\ntype is introduced c-shellscript-c which is like x-shellscript but\ncompressed.  This allows the loguserdata.py shell script to be\ncompressed since it is large.  All of the existing x-cfninitdata\nmime type is compressed before sending and decompressed in the\ninstance by the part handler.\n\nThis is pre-work for compressing the entire cfn tools into the\nuserdata.\n\nI attempted a full compression of the entire cloudinit mime message\nwhich does not appear to work well with the rest of openstack.\n\nblueprint gzip-userdata\n\nChange-Id: Ifae6c676cd47cdf7fe9d297e322643c4b1b024fb\n'}, {'number': 4, 'created': '2013-07-03 02:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fff98f8b2c8f6a39e7c17ed62b3f6e8f7c425f8b', 'message': 'Compress the userdata so more userdata can be passed\n\nThis code compresses most of the cloudinit metadata.  A new mime\ntype is introduced c-shellscript-c which is like x-shellscript but\ncompressed.  This allows the loguserdata.py shell script to be\ncompressed since it is large.  All of the existing x-cfninitdata\nmime type is compressed before sending and decompressed in the\ninstance by the part handler.\n\nThis is pre-work for compressing the entire cfn tools into the\nuserdata.\n\nI attempted a full compression of the entire cloudinit mime message\nwhich does not appear to work well with the rest of openstack.\n\nblueprint gzip-userdata\n\nChange-Id: Ifae6c676cd47cdf7fe9d297e322643c4b1b024fb\n'}, {'number': 5, 'created': '2013-07-10 21:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0712d12409c6c6b1922ad470d2766e353465ac3f', 'message': 'Compress the userdata so more userdata can be passed\n\nThis code compresses most of the cloudinit metadata.  A new mime\ntype is introduced c-shellscript-c which is like x-shellscript but\ncompressed.  This allows the loguserdata.py shell script to be\ncompressed since it is large.  All of the existing x-cfninitdata\nmime type is compressed before sending and decompressed in the\ninstance by the part handler.\n\nblueprint gzip-userdata\n\nChange-Id: Ifae6c676cd47cdf7fe9d297e322643c4b1b024fb\n'}, {'number': 6, 'created': '2013-07-12 00:47:44.000000000', 'files': ['heat/cloudinit/part_handler.py', 'heat/tests/test_part_handler.py', 'heat/engine/resources/instance.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/205eaee9bbd864025364993e91787aac550404ad', 'message': 'Compress the userdata so more userdata can be passed\n\nThis code compresses most of the cloudinit metadata.  A new mime\ntype is introduced c-shellscript-c which is like x-shellscript but\ncompressed.  This allows the loguserdata.py shell script to be\ncompressed since it is large.  All of the existing x-cfninitdata\nmime type is compressed before sending and decompressed in the\ninstance by the part handler.\n\nblueprint gzip-userdata\n\nChange-Id: Ifae6c676cd47cdf7fe9d297e322643c4b1b024fb\n'}]",29,34476,205eaee9bbd864025364993e91787aac550404ad,44,11,6,2834,,,0,"Compress the userdata so more userdata can be passed

This code compresses most of the cloudinit metadata.  A new mime
type is introduced c-shellscript-c which is like x-shellscript but
compressed.  This allows the loguserdata.py shell script to be
compressed since it is large.  All of the existing x-cfninitdata
mime type is compressed before sending and decompressed in the
instance by the part handler.

blueprint gzip-userdata

Change-Id: Ifae6c676cd47cdf7fe9d297e322643c4b1b024fb
",git fetch https://review.opendev.org/openstack/heat refs/changes/76/34476/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/cloudinit/part-handler.py', 'heat/engine/resources/instance.py']",2,bb12875e184a91c519381b4fc72440c2c23f6588,bp/gzip-userdata,"import gzipimport StringIO if subtype in ('x-cfninitdata', 'x-shellscript-c'): zip_blob = StringIO.StringIO() zipper = gzip.GzipFile(mode='wb', fileobj=zip_blob) zipper.write(content) zipper.close() zip_blob.seek(0) content = zip_blob.read() msg = MIMEText(content, _subtype=subtype, _charset='utf-8') else: if subtype is None: subtype = os.path.splitext(filename)[0] msg = MIMEText(content, _subtype=subtype) 'loguserdata.py', 'x-shellscript-c')]"," if subtype is None: subtype = os.path.splitext(filename)[0] msg = MIMEText(content, _subtype=subtype) 'loguserdata.py', 'x-shellscript')]",34,10
openstack%2Foslo-incubator~master~I65879875adf7a12fa0d1873167c2efadfc23a54b,openstack/oslo-incubator,master,I65879875adf7a12fa0d1873167c2efadfc23a54b,Add more robust gettext interpolation handling,MERGED,2013-06-24 20:16:53.000000000,2013-07-20 13:26:11.000000000,2013-07-20 13:26:11.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 2472}, {'_account_id': 3108}, {'_account_id': 5371}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-06-24 20:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a1cef9a85b9b4b29e8e308d0b139dc4a38e0120b', 'message': 'Add more robust gettext interpolation handling\n\nWhile integrating the new delayed messaging gettextutils\nfunctionality into Nova, there were issues with handling\nthe string interpolation operations. This change adds some\npaths for dealing with these cases, such as non-deep-copyable\nparameters, and python code-like objects. Also, adds some\nmuch needed test coverage.\n\nChange-Id: I65879875adf7a12fa0d1873167c2efadfc23a54b\n'}, {'number': 2, 'created': '2013-07-16 20:06:33.000000000', 'files': ['tests/unit/test_gettext.py', 'openstack/common/gettextutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/79ee3672d46ea324d5c1fca6e9f97876e3c267f2', 'message': 'Add more robust gettext interpolation handling\n\nWhile integrating the new delayed messaging gettextutils\nfunctionality into Nova, there were issues with handling\nthe string interpolation operations. This change adds some\npaths for dealing with these cases, such as non-deep-copyable\nparameters, and python code-like objects. Also, adds some\nmuch needed test coverage.\n\nChange-Id: I65879875adf7a12fa0d1873167c2efadfc23a54b\n'}]",9,34253,79ee3672d46ea324d5c1fca6e9f97876e3c267f2,17,6,2,5371,,,0,"Add more robust gettext interpolation handling

While integrating the new delayed messaging gettextutils
functionality into Nova, there were issues with handling
the string interpolation operations. This change adds some
paths for dealing with these cases, such as non-deep-copyable
parameters, and python code-like objects. Also, adds some
much needed test coverage.

Change-Id: I65879875adf7a12fa0d1873167c2efadfc23a54b
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/53/34253/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_gettext.py', 'openstack/common/gettextutils.py']",2,a1cef9a85b9b4b29e8e308d0b139dc4a38e0120b,gettext-enh,"import re def _save_dictionary_parameter(self, dict_param): full_msg = self.data # look for %(blah) fields in string; # ignore %% and deal with the # case where % is first character on the line keys = re.findall('(?:[^%]|^)%\((\w*)\)[a-z]', full_msg) # if we don't find any %(blah) blocks but have a %s if not keys and re.findall('(?:[^%]|^)%[a-z]', full_msg): # apparently the full dictionary is the parameter params = copy.deepcopy(dict_param) else: params = {} for key in keys: try: params[key] = copy.deepcopy(dict_param[key]) except Exception: # cast uncopyable thing to unicode string params[key] = unicode(dict_param[key]) return params elif isinstance(other, dict): self.params = self._save_dictionary_parameter(other) else: # fallback to casting to unicode, # this will handle the problematic python code-like # objects that cannot be deep-copied try: self.params = copy.deepcopy(other) except TypeError: self.params = unicode(other)", else: self.params = copy.deepcopy(other),75,1
openstack%2Foslo-incubator~master~I8cbc354559fcde889d53c1ed97fd7648797e1516,openstack/oslo-incubator,master,I8cbc354559fcde889d53c1ed97fd7648797e1516,Fix eventlet backdoor help formatting,ABANDONED,2013-07-16 15:21:21.000000000,2013-07-20 13:02:17.000000000,,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1994}, {'_account_id': 2472}, {'_account_id': 6159}, {'_account_id': 7996}]","[{'number': 1, 'created': '2013-07-16 15:21:21.000000000', 'files': ['openstack/common/eventlet_backdoor.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/c762ee39c4cdad1c0675650ba2f180cd21b70f7c', 'message': 'Fix eventlet backdoor help formatting\n\nChange-Id: I8cbc354559fcde889d53c1ed97fd7648797e1516\n'}]",1,37271,c762ee39c4cdad1c0675650ba2f180cd21b70f7c,9,6,1,1247,,,0,"Fix eventlet backdoor help formatting

Change-Id: I8cbc354559fcde889d53c1ed97fd7648797e1516
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/71/37271/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/eventlet_backdoor.py'],1,c762ee39c4cdad1c0675650ba2f180cd21b70f7c,,"help_for_backdoor_port = ( 'Acceptable values are 0, <port> and <start>:<end>, where 0 results in ' 'listening on a random tcp port number, <port> results in ' 'listening on the specified port number and not enabling backdoor' 'if it is in use and <start>:<end> results in listening on the ' 'smallest unused port number within the specified range of port ' 'numbers. The chosen port is displayed in the service\'s log file.')","help_for_backdoor_port = 'Acceptable ' + \ 'values are 0, <port> and <start>:<end>, where 0 results in ' + \ 'listening on a random tcp port number, <port> results in ' + \ 'listening on the specified port number and not enabling backdoor' + \ 'if it is in use and <start>:<end> results in listening on the ' + \ 'smallest unused port number within the specified range of port ' + \ 'numbers. The chosen port is displayed in the service\'s log file.'",7,7
openstack%2Fpython-zaqarclient~master~I60345e0ee7b92ee4f5b179924ff1c4e3186561ed,openstack/python-zaqarclient,master,I60345e0ee7b92ee4f5b179924ff1c4e3186561ed,Convert to more modern openstack-common.conf format,MERGED,2013-07-16 11:03:49.000000000,2013-07-20 09:43:24.000000000,2013-07-20 09:43:24.000000000,"[{'_account_id': 3}, {'_account_id': 1267}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6944}, {'_account_id': 8092}]","[{'number': 1, 'created': '2013-07-16 11:03:49.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/150bc5123e0a6d70600359717fdb6f3eef4e0329', 'message': 'Convert to more modern openstack-common.conf format\n\nChange-Id: I60345e0ee7b92ee4f5b179924ff1c4e3186561ed\n'}]",0,37213,150bc5123e0a6d70600359717fdb6f3eef4e0329,12,6,1,1267,,,0,"Convert to more modern openstack-common.conf format

Change-Id: I60345e0ee7b92ee4f5b179924ff1c4e3186561ed
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/13/37213/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,150bc5123e0a6d70600359717fdb6f3eef4e0329,,module=importutils module=strutils module=timeutils,"modules=importutils,strutils,timeutils",3,1
openstack%2Fblazar~master~I6ceab740fc49f10b6d88e8485840dab1686e57a0,openstack/blazar,master,I6ceab740fc49f10b6d88e8485840dab1686e57a0,REST API for managing the leases,ABANDONED,2013-07-04 16:36:17.000000000,2013-07-20 06:03:06.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2928}, {'_account_id': 3012}, {'_account_id': 6492}, {'_account_id': 6502}, {'_account_id': 6582}, {'_account_id': 7075}, {'_account_id': 7535}]","[{'number': 1, 'created': '2013-07-04 16:36:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/d10a344c8cdecef6b13a634e43aa30501d6d71eb', 'message': 'REST API for managing the leases\n\nBased on Flask, but Pecan could be used instead...\n\nChange-Id: I6ceab740fc49f10b6d88e8485840dab1686e57a0\n'}, {'number': 2, 'created': '2013-07-04 18:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/d47ab2e4e15d916fcfcea9189de6477dd994fa3c', 'message': 'REST API for managing the leases\n\nBased on Flask, but Pecan could be used instead...\n\nChange-Id: I6ceab740fc49f10b6d88e8485840dab1686e57a0\n'}, {'number': 3, 'created': '2013-07-04 18:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/6c143d7f306d0d57433a07a8979e58ec39bc824c', 'message': 'REST API for managing the leases\n\nBased on Flask, but Pecan could be used instead...\n\nChange-Id: I6ceab740fc49f10b6d88e8485840dab1686e57a0\n'}, {'number': 4, 'created': '2013-07-04 18:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/e319e99f6039195430e2b7e426b9da5e54e2feaa', 'message': 'REST API for managing the leases\n\nBased on Flask, but Pecan could be used instead...\n\nChange-Id: I6ceab740fc49f10b6d88e8485840dab1686e57a0\n'}, {'number': 5, 'created': '2013-07-04 18:33:44.000000000', 'files': ['climate/api/v1.py', 'etc/climate/policy.json', 'climate/api/acl.py', 'bin/climate-api', 'setup.py', 'tools/pip-requires', 'climate/api/__init__.py', 'etc/climate/climate.conf', 'climate/api/app.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/0c4e6ff7e4222127ccfbf56002de5d10b767e612', 'message': 'REST API for managing the leases\n\nBased on Flask, but Pecan could be used instead...\n\nChange-Id: I6ceab740fc49f10b6d88e8485840dab1686e57a0\n'}]",6,35687,0c4e6ff7e4222127ccfbf56002de5d10b767e612,12,9,5,6582,,,0,"REST API for managing the leases

Based on Flask, but Pecan could be used instead...

Change-Id: I6ceab740fc49f10b6d88e8485840dab1686e57a0
",git fetch https://review.opendev.org/openstack/blazar refs/changes/87/35687/3 && git format-patch -1 --stdout FETCH_HEAD,"['climate/api/v1.py', 'etc/climate/policy.json', 'climate/api/acl.py', 'bin/climate-api', 'setup.py', 'tools/pip-requires', 'climate/api/__init__.py', 'etc/climate/climate.conf', 'climate/api/app.py']",9,d10a344c8cdecef6b13a634e43aa30501d6d71eb,rest-api,"# -*- coding: utf-8 -*- # # Author: Franois Rossigneux <francois.rossigneux@inria.fr> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Set up the API server application instance."""""" import flask from oslo.config import cfg from climate.openstack.common import context from climate.openstack.common import log from climate.openstack.common import rpc from climate.openstack.common.rpc import proxy from climate.openstack.common import log import acl import v1 LOG = log.getLogger(__name__) app_opts = [ cfg.BoolOpt('acl_enabled', required=True, ), ] cfg.CONF.register_opts(app_opts) def make_app(): """"""Instantiates Flask app, attaches proxys, installs acl."""""" LOG.info('Starting API') app = flask.Flask(__name__) app.register_blueprint(v1.blueprint, url_prefix='/v1') rpc.set_defaults(control_exchange='climate') cxt = context.RequestContext('admin', 'admin', is_admin=True) inventory = proxy.RpcProxy('inventory', '1.0') scheduler = proxy.RpcProxy('scheduler', '1.0') @app.before_request def attach_config(): flask.request.context = cxt flask.request.inventory = inventory flask.request.scheduler = scheduler # Install the middleware wrapper if cfg.CONF.acl_enabled: app.wsgi_app = acl.install(app.wsgi_app, cfg.CONF) return app ",,312,1
openstack%2Foslo-incubator~master~I1ddcc6146c22987f9919ffb8dd4a920129d1e1cb,openstack/oslo-incubator,master,I1ddcc6146c22987f9919ffb8dd4a920129d1e1cb,Register node_topic in the reactor for ZMQ.,ABANDONED,2013-07-12 09:25:54.000000000,2013-07-20 06:03:05.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-07-12 09:25:54.000000000', 'files': ['openstack/common/rpc/impl_zmq.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/89504974a5169be497e4b02a5aeea2b58ceea667', 'message': 'Register node_topic in the reactor for ZMQ.\n\nFixed Bug 1200546.\n\nChange-Id: I1ddcc6146c22987f9919ffb8dd4a920129d1e1cb\n'}]",0,36797,89504974a5169be497e4b02a5aeea2b58ceea667,3,1,1,2861,,,0,"Register node_topic in the reactor for ZMQ.

Fixed Bug 1200546.

Change-Id: I1ddcc6146c22987f9919ffb8dd4a920129d1e1cb
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/97/36797/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/rpc/impl_zmq.py'],1,89504974a5169be497e4b02a5aeea2b58ceea667,bug/1200546," topic = '.'.join((topic, CONF.rpc_zmq_host))"," topic = '.'.join((topic.split('.', 1)[0], CONF.rpc_zmq_host))",1,1
openstack%2Fdevstack~master~Ibd8d675ef297a99e59bde41770d37f1dade8e746,openstack/devstack,master,Ibd8d675ef297a99e59bde41770d37f1dade8e746,Configure for actually logging in to hosts,ABANDONED,2013-07-10 23:37:08.000000000,2013-07-20 06:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 2976}]","[{'number': 1, 'created': '2013-07-10 23:37:08.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/94d338e0bad088e41872a69c08f3fd6c1248df64', 'message': ""Configure for actually logging in to hosts\n\nIn tracking down people complaining that tempest didn't work, I\nrealized that we do not actually test ssh-ing in to the hosts we\ncreate. Given how frequently this action fails on the public clouds,\nperhaps we should test it.\n\nChange-Id: Ibd8d675ef297a99e59bde41770d37f1dade8e746\n""}]",0,36582,94d338e0bad088e41872a69c08f3fd6c1248df64,5,3,1,2,,,0,"Configure for actually logging in to hosts

In tracking down people complaining that tempest didn't work, I
realized that we do not actually test ssh-ing in to the hosts we
create. Given how frequently this action fails on the public clouds,
perhaps we should test it.

Change-Id: Ibd8d675ef297a99e59bde41770d37f1dade8e746
",git fetch https://review.opendev.org/openstack/devstack refs/changes/82/36582/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,94d338e0bad088e41872a69c08f3fd6c1248df64,35693, iniset $TEMPEST_CONF compute run_ssh true ssh-keygen -q -t rsa -N '' -f $TEMPEST_DIR/id_rsa," # TODO(jaypipes): Create the key file here... right now, no whitebox # tests actually use a key.",3,2
openstack%2Fneutron~master~I6adec0af9a725d2292c2e409140fde49e5d66ae8,openstack/neutron,master,I6adec0af9a725d2292c2e409140fde49e5d66ae8,Fix support of multiple external networks in Quantum.,ABANDONED,2013-07-06 16:06:39.000000000,2013-07-20 06:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1689}, {'_account_id': 2874}, {'_account_id': 6072}, {'_account_id': 7073}]","[{'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': ['quantum/api/rpc/agentnotifiers/l3_rpc_agent_api.py', 'quantum/db/agents_db.py', 'quantum/db/agentschedulers_db.py', 'quantum/openstack/common/rpc/service.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/913bc2a542328ae01ac19b86622049e4ebe500c5', 'message': 'Fix support of multiple external networks in Quantum.\n\nAllow quantum to have more than one l3-agent per host, and change AMPQ\ncommunication between quantum-server and l3-agents to use broadcast\nmessaging instead of unicast.\n\nfixes bug: #1191729\n\nChange-Id: I6adec0af9a725d2292c2e409140fde49e5d66ae8\n'}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/89ab5978ca18ae2d44344948c88d98ddbcbb5a5d', 'message': 'Fix support of multiple external networks in Quantum.\n\nAllow quantum to have more than one l3-agent per host, and change AMPQ\ncommunication between quantum-server and l3-agents to use broadcast\nmessaging instead of unicast.\n\nfixes bug: #1191729\n\nChange-Id: I6adec0af9a725d2292c2e409140fde49e5d66ae8\n'}]",1,34192,913bc2a542328ae01ac19b86622049e4ebe500c5,16,6,2,7073,,,0,"Fix support of multiple external networks in Quantum.

Allow quantum to have more than one l3-agent per host, and change AMPQ
communication between quantum-server and l3-agents to use broadcast
messaging instead of unicast.

fixes bug: #1191729

Change-Id: I6adec0af9a725d2292c2e409140fde49e5d66ae8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/92/34192/2 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/api/rpc/agentnotifiers/l3_rpc_agent_api.py', 'quantum/db/agents_db.py', 'quantum/db/agentschedulers_db.py', 'quantum/openstack/common/rpc/service.py']",4,913bc2a542328ae01ac19b86622049e4ebe500c5,bug/1191729," # NOTE (Mouad): Allow all l3-agent to listen on 'l3_agent.<host>' # queue. use_fanout = self.topic == ""l3_agent"" self.conn.create_consumer(node_topic, dispatcher, fanout=use_fanout)"," self.conn.create_consumer(node_topic, dispatcher, fanout=False)",45,21
openstack%2Fnova~master~I52ad4de4726f007c14234d77b92979d4e101284f,openstack/nova,master,I52ad4de4726f007c14234d77b92979d4e101284f,Implementation of Volume Affinity Weigher.,ABANDONED,2013-07-12 09:36:49.000000000,2013-07-20 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 5511}, {'_account_id': 6938}]","[{'number': 1, 'created': '2013-07-12 09:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a43d8620d4d1a92afab1a96c3cf71d6d8960e5e5', 'message': 'Implementstion of Volume Affinity Weigher.\n\nThis weighter increases weight of a host that contains a volume\nto be associated with an instance. Please note that this works\nonly if the driver used by cinder has a notion of host (for\nexample LVM driver). It also must be noted that currently\nthe weigher does not support multi-backend, however this may change\nin future.\n\nChange-Id: I52ad4de4726f007c14234d77b92979d4e101284f\nBP: volume-affinity-weighter-function\n'}, {'number': 2, 'created': '2013-07-12 09:40:23.000000000', 'files': ['nova/scheduler/weights/volume_affinity.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/82f6dd3a9f63ea59879acfd3bd7d7080db92e745', 'message': 'Implementation of Volume Affinity Weigher.\n\nThis weighter increases weight of a host that contains a volume\nto be associated with an instance. Please note that this works\nonly if the driver used by cinder has a notion of host (for\nexample LVM driver). It also must be noted that currently\nthe weigher does not support multi-backend, however this may change\nin future.\n\nChange-Id: I52ad4de4726f007c14234d77b92979d4e101284f\nBP: volume-affinity-weighter-function\n'}]",1,36799,82f6dd3a9f63ea59879acfd3bd7d7080db92e745,8,5,2,6938,,,0,"Implementation of Volume Affinity Weigher.

This weighter increases weight of a host that contains a volume
to be associated with an instance. Please note that this works
only if the driver used by cinder has a notion of host (for
example LVM driver). It also must be noted that currently
the weigher does not support multi-backend, however this may change
in future.

Change-Id: I52ad4de4726f007c14234d77b92979d4e101284f
BP: volume-affinity-weighter-function
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/36799/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/weights/volume_affinity.py'],1,a43d8620d4d1a92afab1a96c3cf71d6d8960e5e5,bp/volume-affinity-weighter-function,"# Copyright (c) 2013 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Volume Affinity Weigher. Weigh hosts by their proximity to a volume. This weigher gives maximum weight to that host to which specified volume belongs. Other hosts get rejected. This weigher may be used with drivers that have a notion of host. """""" from oslo.config import cfg from cinderclient import exceptions as client_exceptions from nova.scheduler import weights from nova.volume import cinder ram_weight_opts = [ cfg.FloatOpt('volume_affinity_weight_multiplier', default=1.0, help='Multiplier used for weighing ram. Negative ' 'numbers mean to stack vs spread.'), ] CONF = cfg.CONF CONF.register_opts(ram_weight_opts) class VolumeAffinityWeigher(weights.BaseHostWeigher): """"""Gives bigger weight to a host to which specified volume belongs."""""" def __init__(self): self.target_host = None self.weighing_result = None def _weight_multiplier(self): """"""Override the weight multiplier."""""" return CONF.volume_affinity_weight_multiplier def _weigh_object(self, host_state, weight_properties): """"""Higher weights win. We want spreading to be the default."""""" if self.weighing_result is not None: return self.weighing_result if self.target_host is None: # NOTE(alexey): This is not a prefect way to decide which volume to use as # a reference, as a user may specify more than one block device. I'll leave # it as is for now, as it is not clear to me what volume affinity should mean # in case of multiple bdms. Probably this can be resolved with a hint. try: bdm = weight_properties['block_device_mapping'][0] except IndexError: self.weighing_result = 0.0 return self.weighing_result volume_id = bdm['volume_id'] context = weight_properties['context'] try: volume = cinder.cinderclient(context).volumes.get(volume_id) except client_exceptions.NotFound: self.weighing_result = 0.0 return self.weighing_result else: self.target_host = getattr(volume, 'os-vol-host-attr:host', None) if self.target_host == host_state.host: self.weighing_result = 0.0 return CONF.volume_affinity_weight_multiplier else: return 0.0 ",,80,0
openstack%2Fnova~master~If350e6d6faa02e7c40f2dd51c5d59822089ff00c,openstack/nova,master,If350e6d6faa02e7c40f2dd51c5d59822089ff00c,Return correct code when disassociate free address,ABANDONED,2013-07-03 08:48:58.000000000,2013-07-20 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-07-03 08:48:58.000000000', 'files': ['nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d70a8ef8c1166a1f6493962815f9139a5b8c3275', 'message': 'Return correct code when disassociate free address\n\nFixes bug #1179816\n\nReturn InvalidAssociationID.NotFound instead of InstanceNotFound when\ndisassociate a not associated address.\n\nChange-Id: If350e6d6faa02e7c40f2dd51c5d59822089ff00c\n'}]",1,35464,d70a8ef8c1166a1f6493962815f9139a5b8c3275,5,3,1,2245,,,0,"Return correct code when disassociate free address

Fixes bug #1179816

Return InvalidAssociationID.NotFound instead of InstanceNotFound when
disassociate a not associated address.

Change-Id: If350e6d6faa02e7c40f2dd51c5d59822089ff00c
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/35464/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py']",2,d70a8ef8c1166a1f6493962815f9139a5b8c3275,bug/1179816," LOG.audit(_(""Disassociate address %s""), public_ip, context=context) try: instance = self.compute_api.get(context, instance_id) except (exception.InstanceNotFound, exception.FloatingIpNotAssociated): raise exception.EC2APIError(msg, 'InvalidAssociationID.NotFound')"," instance = self.compute_api.get(context, instance_id) LOG.audit(_(""Disassociate address %s""), public_ip, context=context) try: except exception.FloatingIpNotAssociated: raise exception.EC2APIError(msg)",5,5
openstack%2Fnova~master~I9b4a636094628e04f0f9ad13a1d762ba596575be,openstack/nova,master,I9b4a636094628e04f0f9ad13a1d762ba596575be,Use PYTHONDONTWRITEBYTECODE to skip .pyc files,ABANDONED,2013-07-12 17:14:35.000000000,2013-07-20 06:03:02.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2472}, {'_account_id': 4992}]","[{'number': 1, 'created': '2013-07-12 17:14:35.000000000', 'files': ['run_tests.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/d1a7a5eb1efdcb9dd281d6eea31106919478a28d', 'message': 'Use PYTHONDONTWRITEBYTECODE to skip .pyc files\n\nTesting multiple python versions or multiple branches can cause\nevil things to happen with leftover or old .pyc files. run_tests.sh\nhas been doing a find -delete on them before test runs, but tox\nwas not doing that. Turns out there is a consistent way to solve\nthe problem - just setting PYTHONDONTWRITEBYTECODE=1 suppresses\nthe creation of the files in the first place.\n\nChange-Id: I9b4a636094628e04f0f9ad13a1d762ba596575be\n'}]",0,36862,d1a7a5eb1efdcb9dd281d6eea31106919478a28d,6,5,1,2,,,0,"Use PYTHONDONTWRITEBYTECODE to skip .pyc files

Testing multiple python versions or multiple branches can cause
evil things to happen with leftover or old .pyc files. run_tests.sh
has been doing a find -delete on them before test runs, but tox
was not doing that. Turns out there is a consistent way to solve
the problem - just setting PYTHONDONTWRITEBYTECODE=1 suppresses
the creation of the files in the first place.

Change-Id: I9b4a636094628e04f0f9ad13a1d762ba596575be
",git fetch https://review.opendev.org/openstack/nova refs/changes/62/36862/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'tox.ini']",2,d1a7a5eb1efdcb9dd281d6eea31106919478a28d,build-updates, PYTHONDONTWRITEBYTECODE=1,setenv = VIRTUAL_ENV={envdir}setenv = VIRTUAL_ENV={envdir},4,4
openstack%2Fpbr~master~Ie00accedee250fc11846a71a266600be82e56ffa,openstack/pbr,master,Ie00accedee250fc11846a71a266600be82e56ffa,Test that new pip 1.4 pre-release works.,ABANDONED,2013-07-05 19:19:19.000000000,2013-07-20 06:03:01.000000000,,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2013-07-05 19:19:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/bc6586360bcf5f681236232a2205bf602ca34804', 'message': 'Test that new pip 1.4 pre-release works.\n\nChange-Id: Ie00accedee250fc11846a71a266600be82e56ffa\n'}, {'number': 2, 'created': '2013-07-05 20:40:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/4ce23e82b5608bb77f71caee233c5a93cc4d8952', 'message': 'Test that new pip 1.4 pre-release works.\n\nChange-Id: Ie00accedee250fc11846a71a266600be82e56ffa\n'}, {'number': 3, 'created': '2013-07-08 13:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/e96819f2a97aba5aeba43f7dceb6ea5d9a1e333b', 'message': 'Test that new pip 1.4 pre-release works.\n\nChange-Id: Ie00accedee250fc11846a71a266600be82e56ffa\n'}, {'number': 5, 'created': '2013-07-08 13:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/1c9cfb2e2f77acdbd5e4849b59d4cac67fd090da', 'message': 'Test that new pip 1.4 pre-release works.\n\nChange-Id: Ie00accedee250fc11846a71a266600be82e56ffa\n'}, {'number': 4, 'created': '2013-07-08 13:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/a7913cfa037bafa29ea0ac2eef898812116ad923', 'message': 'Test that new pip 1.4 pre-release works.\n\nChange-Id: Ie00accedee250fc11846a71a266600be82e56ffa\n'}, {'number': 6, 'created': '2013-07-12 22:40:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/a2497bcbdb3c3ea81ab105b859e6dee53f62b53e', 'message': 'Test that new pip 1.4 pre-release works.\n\nChange-Id: Ie00accedee250fc11846a71a266600be82e56ffa\n'}, {'number': 7, 'created': '2013-07-12 22:46:06.000000000', 'files': ['tools/integration.sh'], 'web_link': 'https://opendev.org/openstack/pbr/commit/8019ead484d9541361c46a7b761d646d7c94a9c1', 'message': 'Test that new pip 1.4 pre-release works.\n\nChange-Id: Ie00accedee250fc11846a71a266600be82e56ffa\n'}]",0,35866,8019ead484d9541361c46a7b761d646d7c94a9c1,19,2,7,2,,,0,"Test that new pip 1.4 pre-release works.

Change-Id: Ie00accedee250fc11846a71a266600be82e56ffa
",git fetch https://review.opendev.org/openstack/pbr refs/changes/66/35866/7 && git format-patch -1 --stdout FETCH_HEAD,['tools/integration.sh'],1,bc6586360bcf5f681236232a2205bf602ca34804,jd/override-via-env, # Test pip pre-release pipprevenv=$tmpdir/pippre mkvenv $pipprevenv setuptools '-e https://github.com/pypa/pip/archive/1.4rc2.tar.gz' cd $tmpdir echo $pipprevenv/bin/pip install git+file://$REPODIR/$SHORT_PROJECT $pipprevenv/bin/pip install git+file://$REPODIR/$SHORT_PROJECT ,,7,0
openstack%2Ftrove~master~I66f52f8b8a3954989844d3b5fa0794913e94ddfa,openstack/trove,master,I66f52f8b8a3954989844d3b5fa0794913e94ddfa,Fix drift in deleted timestamp for Notification and Database,MERGED,2013-07-18 16:47:38.000000000,2013-07-20 04:07:09.000000000,2013-07-20 04:07:09.000000000,"[{'_account_id': 3}, {'_account_id': 739}, {'_account_id': 1925}, {'_account_id': 6156}, {'_account_id': 6162}, {'_account_id': 7092}]","[{'number': 1, 'created': '2013-07-18 16:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/eeb14e857c7c010f8d9f218ad07848dc54ed5406', 'message': 'Fix drift in Deleted timestamp between Usage Notification and Database\n\n    The deleted timestamp for the usage event and the database were being\n    set at different intervals.  Now the time is captured once and shared\n    between both usages.\n\nFixes: bug 1201685\n\nChange-Id: I66f52f8b8a3954989844d3b5fa0794913e94ddfa\n'}, {'number': 2, 'created': '2013-07-18 16:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/014807ff34662c2a19b1ea35d32007e8164da297', 'message': 'Fix drift in Deleted timestamp between Usage Notification and Database\n\n    The deleted timestamp for the usage event and the database\n    were being set at different intervals.  Now the time is\n    captured once and shared between both usages.\n\nFixes: bug 1201685\n\nChange-Id: I66f52f8b8a3954989844d3b5fa0794913e94ddfa\n'}, {'number': 3, 'created': '2013-07-18 16:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7c29aabb106228bacef97061fb06d1afb580665a', 'message': 'Fix drift in deleted timestamp for Notification and Database\n\n    The deleted timestamp for the usage event and the database\n    were being set at different intervals.  Now the time is\n    captured once and shared between both usages.\n\nFixes: bug 1201685\n\nChange-Id: I66f52f8b8a3954989844d3b5fa0794913e94ddfa\n'}, {'number': 4, 'created': '2013-07-18 18:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c7ff417b7b28a7943f50bdfb744026d8e1e6f297', 'message': 'Fix drift in deleted timestamp for Notification and Database\n\n    The deleted timestamp for the usage event and the database\n    were being set at different intervals.  Now the time is\n    captured once and shared between both usages.\n\nFixes: bug 1201685\n\nChange-Id: I66f52f8b8a3954989844d3b5fa0794913e94ddfa\n'}, {'number': 5, 'created': '2013-07-19 16:55:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/873a104eaecd7fbe6db8ca40065c364e42339acd', 'message': 'Fix drift in deleted timestamp for Notification and Database\n\n    The deleted timestamp for the usage event and the database\n    were being set at different intervals.  Now the time is\n    captured once and shared between both usages.\n\nFixes: bug 1201685\n\nChange-Id: I66f52f8b8a3954989844d3b5fa0794913e94ddfa\n'}, {'number': 6, 'created': '2013-07-19 21:15:06.000000000', 'files': ['trove/instance/models.py', 'trove/taskmanager/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/91943c7b3c6ce91fc057911f4e453fb13877d268', 'message': 'Fix drift in deleted timestamp for Notification and Database\n\n    The deleted timestamp for the usage event and the database\n    were being set at different intervals.  Now the time is\n    captured once and shared between both usages.\n\n    If the server deletion times out, a log message will be\n    recorded but it will not throw an exception.  Ensures\n    completion of clean up and record of deletion\n\nFixes: bug 1201685\n\nChange-Id: I66f52f8b8a3954989844d3b5fa0794913e94ddfa\n'}]",4,37718,91943c7b3c6ce91fc057911f4e453fb13877d268,33,6,6,6156,,,0,"Fix drift in deleted timestamp for Notification and Database

    The deleted timestamp for the usage event and the database
    were being set at different intervals.  Now the time is
    captured once and shared between both usages.

    If the server deletion times out, a log message will be
    recorded but it will not throw an exception.  Ensures
    completion of clean up and record of deletion

Fixes: bug 1201685

Change-Id: I66f52f8b8a3954989844d3b5fa0794913e94ddfa
",git fetch https://review.opendev.org/openstack/trove refs/changes/18/37718/6 && git format-patch -1 --stdout FETCH_HEAD,"['trove/instance/models.py', 'trove/taskmanager/models.py']",2,eeb14e857c7c010f8d9f218ad07848dc54ed5406,bug/1201685," deleted_at = timeutils.utcnow() self.send_usage_event('delete', deleted_at=timeutils.isotime(deleted_at), return deleted_at"," self.send_usage_event('delete', deleted_at=timeutils.isotime(),",7,7
openstack%2Fneutron~master~I539a135dbc3861e31cbb5c69cef0ff8c0f834527,openstack/neutron,master,I539a135dbc3861e31cbb5c69cef0ff8c0f834527,Avoid refreshing firewall rules unnecessarily.,MERGED,2013-07-17 17:51:55.000000000,2013-07-20 02:29:55.000000000,2013-07-20 02:29:55.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 7448}]","[{'number': 1, 'created': '2013-07-17 17:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c5de054b0af25e6bf4ce7b45d07f4fe55a6e6cae', 'message': 'Avoid refreshing firewall rules unnecessarily.\n\nAdds a parameter to refresh_firewall allowing an array of ports to\nbe passed.  If an array is passed then the firewall will be refreshed\nonly for those ports.  If not passed, it will still refresh all\nports as it did before.\n\nChange-Id: I539a135dbc3861e31cbb5c69cef0ff8c0f834527\nFixes: Bug #1202328\n'}, {'number': 2, 'created': '2013-07-19 16:22:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b67bb1b758d176d4349caf0926bfdcc2b3e6bad2', 'message': 'Avoid refreshing firewall rules unnecessarily.\n\nAdds a parameter to refresh_firewall allowing an array of ports to\nbe passed.  If an array is passed then the firewall will be refreshed\nonly for those ports.  If not passed, it will still refresh all\nports as it did before.\n\nChange-Id: I539a135dbc3861e31cbb5c69cef0ff8c0f834527\nFixes: Bug #1202328\n'}, {'number': 3, 'created': '2013-07-19 18:37:51.000000000', 'files': ['neutron/tests/unit/test_security_groups_rpc.py', 'neutron/agent/securitygroups_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/59fe0711dfd551739d5f5f98d05ffaf329467c07', 'message': 'Avoid refreshing firewall rules unnecessarily.\n\nAdds a parameter to refresh_firewall allowing an array of ports to\nbe passed.  If an array is passed then the firewall will be refreshed\nonly for those ports.  If not passed, it will still refresh all\nports as it did before.\n\nChange-Id: I539a135dbc3861e31cbb5c69cef0ff8c0f834527\nFixes: Bug #1202328\n'}]",7,37542,59fe0711dfd551739d5f5f98d05ffaf329467c07,17,6,3,7448,,,0,"Avoid refreshing firewall rules unnecessarily.

Adds a parameter to refresh_firewall allowing an array of ports to
be passed.  If an array is passed then the firewall will be refreshed
only for those ports.  If not passed, it will still refresh all
ports as it did before.

Change-Id: I539a135dbc3861e31cbb5c69cef0ff8c0f834527
Fixes: Bug #1202328
",git fetch https://review.opendev.org/openstack/neutron refs/changes/42/37542/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_security_groups_rpc.py', 'neutron/agent/securitygroups_rpc.py']",2,c5de054b0af25e6bf4ce7b45d07f4fe55a6e6cae,bug/1202328," devices = [] devices.append(device) if devices: self.refresh_firewall(devices) def refresh_firewall(self, devices=None): if devices: device_ids = [d['device'] for d in devices] else: device_ids = self.firewall.ports.keys() if not device_ids: LOG.info(_(""No ports here to refresh firewall""))", #check need update or not self.refresh_firewall() return def refresh_firewall(self): device_ids = self.firewall.ports.keys() if not device_ids:,14,7
openstack%2Fheat~master~I8e93a2aa0256b61039e38ade773997db856194b4,openstack/heat,master,I8e93a2aa0256b61039e38ade773997db856194b4,Resources state explicitly their allowed delete policies.,ABANDONED,2013-07-18 20:31:43.000000000,2013-07-20 01:18:28.000000000,,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 6602}, {'_account_id': 7230}]","[{'number': 1, 'created': '2013-07-18 20:31:43.000000000', 'files': ['heat/engine/resources/volume.py', 'heat/engine/resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f79d066d73c5a85ab26a6a9918d288bbce7cad4b', 'message': 'Resources state explicitly their allowed delete policies.\n\nCurrently this is implicit based on whether the handle_snapshot_delete\nmethod exists.\n\nThis is now brought in line with how resources indicate other\ncapabilities (update_allowed_keys, update_allowed_properties)\n\nThis is required to clean up the volume delete code paths for\nblueprint parallel-delete\n\nChange-Id: I8e93a2aa0256b61039e38ade773997db856194b4\n'}]",2,37764,f79d066d73c5a85ab26a6a9918d288bbce7cad4b,4,5,1,4571,,,0,"Resources state explicitly their allowed delete policies.

Currently this is implicit based on whether the handle_snapshot_delete
method exists.

This is now brought in line with how resources indicate other
capabilities (update_allowed_keys, update_allowed_properties)

This is required to clean up the volume delete code paths for
blueprint parallel-delete

Change-Id: I8e93a2aa0256b61039e38ade773997db856194b4
",git fetch https://review.opendev.org/openstack/heat refs/changes/64/37764/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/volume.py', 'heat/engine/resource.py']",2,f79d066d73c5a85ab26a6a9918d288bbce7cad4b,bp/parallel-delete," # Resource implementations set this to the delete policies they allow, # which may include 'Snapshot' delete_allowed_policies = ('Delete', 'Retain',) elif deletion_policy not in cls.delete_allowed_policies: msg = '%s DeletionPolicy not supported' % deletion_policy raise exception.StackValidationFailed(message=msg)"," elif deletion_policy == 'Snapshot': if not callable(getattr(cls, 'handle_snapshot_delete', None)): msg = 'Snapshot DeletionPolicy not supported' raise exception.StackValidationFailed(message=msg)",9,4
openstack%2Fnova~master~Ib678df424a58a0d7023ce3b2bdd5001998daf398,openstack/nova,master,Ib678df424a58a0d7023ce3b2bdd5001998daf398,Handle instance objects in conductor compute_stop,MERGED,2013-06-28 20:10:52.000000000,2013-07-20 00:55:22.000000000,2013-07-20 00:55:19.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 782}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 6873}]","[{'number': 1, 'created': '2013-06-28 20:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c387a873ad8460a2f08d1b2f5619bf0103e5d966', 'message': ""Handle instance objects in conductor compute_stop\n\nThe compute manager is sending instance objects to\ncompute_stop in conductor but conductor wasn't\nconverting the instance object to a dict before\nsending it to the compute API which results in\nan AttributeError.\n\nFixes bug 1195849\n\nChange-Id: Ib678df424a58a0d7023ce3b2bdd5001998daf398\n""}, {'number': 2, 'created': '2013-06-28 21:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/70d74f2abf4e6c798b5ec10f24b51965791e1dd2', 'message': ""Handle instance objects in conductor compute_stop\n\nThe compute manager is sending instance objects to\ncompute_stop in conductor but conductor wasn't\nconverting the instance object to a dict before\nsending it to the compute API which results in\nan AttributeError.\n\nFixes bug 1195849\n\nChange-Id: Ib678df424a58a0d7023ce3b2bdd5001998daf398\n""}, {'number': 3, 'created': '2013-06-30 19:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8b331f3f9f61d1a8ee82ee33fc5aa0f3768b46d', 'message': ""Handle instance objects in conductor compute_stop\n\nThe compute manager is sending instance objects to\ncompute_stop in conductor but conductor wasn't\nconverting the instance object to a dict before\nsending it to the compute API which results in\nan AttributeError.\n\nAlso updates the test case for compute_confirm_resize\nwhich wasn't using instance objects in the test case\nbefore this (but the conductor manager code is using\ninstance objects).\n\nFixes bug 1195849\n\nChange-Id: Ib678df424a58a0d7023ce3b2bdd5001998daf398\n""}, {'number': 4, 'created': '2013-07-01 14:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3477870d31acc736294710780196aff9b067b956', 'message': ""Handle instance objects in conductor compute_stop\n\nThe compute manager is sending instance objects to\ncompute_stop in conductor but conductor wasn't\nconverting the instance object to a dict before\nsending it to the compute API which results in\nan AttributeError.\n\nAlso updates the test case for compute_confirm_resize\nwhich wasn't using instance objects in the test case\nbefore this (but the conductor manager code is using\ninstance objects).\n\nFixes bug 1195849\n\nChange-Id: Ib678df424a58a0d7023ce3b2bdd5001998daf398\n""}, {'number': 5, 'created': '2013-07-03 15:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/49d16a017f0e46d04811bebe605fec7c0a5f43fa', 'message': ""Handle instance objects in conductor compute_stop\n\nThe compute manager is sending instance objects to\ncompute_stop in conductor but conductor's compute_stop\nRPC proxy wasn't handling objects. This patch fixes that\nand also handles compatibility with older installations\nusing the dict-style format in the conductor compute_stop\nRPC proxy.\n\nFixes bug 1195849\n\nChange-Id: Ib678df424a58a0d7023ce3b2bdd5001998daf398\n""}, {'number': 6, 'created': '2013-07-03 17:26:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c7a9a3664a90c1f8310090ec519eb16398f227b9', 'message': ""Handle instance objects in conductor compute_stop\n\nThe compute manager is sending instance objects to\ncompute_stop in conductor but conductor's compute_stop\nRPC proxy wasn't handling objects. This patch fixes that\nand also handles compatibility with older installations\nusing the dict-style format in the conductor compute_stop\nRPC proxy.\n\nFixes bug 1195849\n\nChange-Id: Ib678df424a58a0d7023ce3b2bdd5001998daf398\n""}, {'number': 7, 'created': '2013-07-08 20:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14530b64db85ffe241e5b9c05efcc5a772ccaaf8', 'message': ""Handle instance objects in conductor compute_stop\n\nThe compute manager is sending instance objects to\ncompute_stop in conductor but conductor's compute_stop\nRPC proxy wasn't handling objects. This patch fixes that\nand also handles compatibility with older installations\nusing the dict-style format in the conductor compute_stop\nRPC proxy.\n\nFixes bug 1195849\n\nChange-Id: Ib678df424a58a0d7023ce3b2bdd5001998daf398\n""}, {'number': 8, 'created': '2013-07-08 21:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec5e391703c55617fef54a31933ca844bd4118b6', 'message': ""Handle instance objects in conductor compute_stop\n\nThe compute manager is sending instance objects to\ncompute_stop in conductor but conductor's compute_stop\nRPC proxy wasn't handling objects. This patch fixes that\nand also handles compatibility with older installations\nusing the dict-style format in the conductor compute_stop\nRPC proxy.\n\nFixes bug 1195849\n\nChange-Id: Ib678df424a58a0d7023ce3b2bdd5001998daf398\n""}, {'number': 9, 'created': '2013-07-16 00:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/824c6c9512621206e69f79c42a228b354a4a0716', 'message': ""Handle instance objects in conductor compute_stop\n\nThe compute manager is sending instance objects to\ncompute_stop in conductor but conductor's compute_stop\nRPC proxy wasn't handling objects. This patch fixes that\nand also handles compatibility with older installations\nusing the dict-style format in the conductor compute_stop\nRPC proxy.\n\nFixes bug 1195849\n\nChange-Id: Ib678df424a58a0d7023ce3b2bdd5001998daf398""}, {'number': 10, 'created': '2013-07-19 14:06:36.000000000', 'files': ['nova/conductor/rpcapi.py', 'nova/tests/conductor/test_conductor.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/190d8ca4524df0b0fdd3514886672f51bd7da43a', 'message': ""Handle instance objects in conductor compute_stop\n\nThe compute manager is sending instance objects to\ncompute_stop in conductor but conductor's compute_stop\nRPC proxy wasn't handling objects. This patch fixes that\nand also handles compatibility with older installations\nusing the dict-style format in the conductor compute_stop\nRPC proxy.\n\nFixes bug 1195849\n\nChange-Id: Ib678df424a58a0d7023ce3b2bdd5001998daf398\n""}]",29,34947,190d8ca4524df0b0fdd3514886672f51bd7da43a,58,10,10,6873,,,0,"Handle instance objects in conductor compute_stop

The compute manager is sending instance objects to
compute_stop in conductor but conductor's compute_stop
RPC proxy wasn't handling objects. This patch fixes that
and also handles compatibility with older installations
using the dict-style format in the conductor compute_stop
RPC proxy.

Fixes bug 1195849

Change-Id: Ib678df424a58a0d7023ce3b2bdd5001998daf398
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/34947/10 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conductor/rpcapi.py', 'nova/conductor/manager.py']",2,c387a873ad8460a2f08d1b2f5619bf0103e5d966,bug/1195849,"# Copyright 2013 IBM Corp. RPC_API_VERSION = '1.53' if isinstance(instance, nova_object.NovaObject): # NOTE(mriedem): Remove this at RPC API v2.0 instance = dict(instance.items())",# Copyright 2012 IBM Corp. RPC_API_VERSION = '1.52',9,7
openstack%2Fswift~master~I39210616d323691ccb745149f24430a7a61382ec,openstack/swift,master,I39210616d323691ccb745149f24430a7a61382ec,Close SQLite cursors when creating functions.,MERGED,2013-07-19 21:53:27.000000000,2013-07-19 23:56:23.000000000,2013-07-19 23:56:22.000000000,"[{'_account_id': 3}, {'_account_id': 917}, {'_account_id': 2622}, {'_account_id': 2828}]","[{'number': 1, 'created': '2013-07-19 21:53:27.000000000', 'files': ['swift/common/db.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/0fdad0d9d9e68b00f61171bb2a0dfd840ef5345f', 'message': ""Close SQLite cursors when creating functions.\n\nIf the cursors are not closed, then when\ncreate_function is called, if they are not\nGC'd then create_function will fail. On Pythons\nwithout reference counting (e.g. PyPy) they\nwill not be GC'd immediately.\n\nChange-Id: I39210616d323691ccb745149f24430a7a61382ec\n""}]",0,37986,0fdad0d9d9e68b00f61171bb2a0dfd840ef5345f,10,4,1,7680,,,0,"Close SQLite cursors when creating functions.

If the cursors are not closed, then when
create_function is called, if they are not
GC'd then create_function will fail. On Pythons
without reference counting (e.g. PyPy) they
will not be GC'd immediately.

Change-Id: I39210616d323691ccb745149f24430a7a61382ec
",git fetch https://review.opendev.org/openstack/swift refs/changes/86/37986/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/db.py'],1,0fdad0d9d9e68b00f61171bb2a0dfd840ef5345f,close-sqlite-cursors,"from contextlib import contextmanager, closing with closing(conn.cursor()) as cur: cur.execute('PRAGMA synchronous = NORMAL') cur.execute('PRAGMA count_changes = OFF') cur.execute('PRAGMA temp_store = MEMORY') cur.execute('PRAGMA journal_mode = DELETE') with closing(conn.cursor()) as cur: cur.execute('PRAGMA synchronous = OFF') cur.execute('PRAGMA temp_store = MEMORY') cur.execute('PRAGMA journal_mode = MEMORY')",from contextlib import contextmanager conn.execute('PRAGMA synchronous = NORMAL') conn.execute('PRAGMA count_changes = OFF') conn.execute('PRAGMA temp_store = MEMORY') conn.execute('PRAGMA journal_mode = DELETE') conn.execute('PRAGMA synchronous = OFF') conn.execute('PRAGMA temp_store = MEMORY') conn.execute('PRAGMA journal_mode = MEMORY'),10,8
openstack%2Fglance~master~I0bd91f7bb43f97b99051fed65b75fc05d5149cc8,openstack/glance,master,I0bd91f7bb43f97b99051fed65b75fc05d5149cc8,Use oslo.sphinx and remove local copy of doc theme,MERGED,2013-07-05 20:10:27.000000000,2013-07-19 23:56:16.000000000,2013-07-19 23:56:16.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6159}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-07-05 20:10:27.000000000', 'files': ['doc/source/_static/nature.css', 'doc/source/_static/tweaks.css', 'doc/source/_static/openstack_logo.png', 'doc/source/_templates/.placeholder', 'doc/source/conf.py', 'doc/source/_static/default.css', 'doc/source/_theme/theme.conf', 'doc/source/_static/header_bg.jpg', 'doc/source/_theme/layout.html', 'tools/test-requires', 'doc/source/_static/header-line.gif', 'doc/source/_static/basic.css', 'doc/source/_static/jquery.tweet.js'], 'web_link': 'https://opendev.org/openstack/glance/commit/670b07eb56ee26a556af6b0ced4c23b691b9568d', 'message': 'Use oslo.sphinx and remove local copy of doc theme\n\nUse the new oslo.sphinx version of the OpenStack doc\ntheme instead of copying it into this repo.\n\nblueprint oslo.sphinx\n\nSigned-off-by: Doug Hellmann <doug.hellmann@dreamhost.com>\nChange-Id: I0bd91f7bb43f97b99051fed65b75fc05d5149cc8\n'}]",1,35880,670b07eb56ee26a556af6b0ced4c23b691b9568d,9,4,1,2472,,,0,"Use oslo.sphinx and remove local copy of doc theme

Use the new oslo.sphinx version of the OpenStack doc
theme instead of copying it into this repo.

blueprint oslo.sphinx

Signed-off-by: Doug Hellmann <doug.hellmann@dreamhost.com>
Change-Id: I0bd91f7bb43f97b99051fed65b75fc05d5149cc8
",git fetch https://review.opendev.org/openstack/glance refs/changes/80/35880/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/nature.css', 'doc/source/_static/tweaks.css', 'doc/source/_static/openstack_logo.png', 'doc/source/_templates/.placeholder', 'doc/source/conf.py', 'doc/source/_static/default.css', 'doc/source/_theme/theme.conf', 'doc/source/_static/header_bg.jpg', 'doc/source/_theme/layout.html', 'tools/test-requires', 'doc/source/_static/header-line.gif', 'doc/source/_static/basic.css', 'doc/source/_static/jquery.tweet.js']",13,670b07eb56ee26a556af6b0ced4c23b691b9568d,blueprint/oslo.sphinx,,"(function($) { $.fn.tweet = function(o){ var s = { username: [""seaofclouds""], // [string] required, unless you want to display our tweets. :) it can be an array, just do [""username1"",""username2"",""etc""] list: null, //[string] optional name of list belonging to username avatar_size: null, // [integer] height and width of avatar if displayed (48px max) count: 3, // [integer] how many tweets to display? intro_text: null, // [string] do you want text BEFORE your your tweets? outro_text: null, // [string] do you want text AFTER your tweets? join_text: null, // [string] optional text in between date and tweet, try setting to ""auto"" auto_join_text_default: ""i said,"", // [string] auto text for non verb: ""i said"" bullocks auto_join_text_ed: ""i"", // [string] auto text for past tense: ""i"" surfed auto_join_text_ing: ""i am"", // [string] auto tense for present tense: ""i was"" surfing auto_join_text_reply: ""i replied to"", // [string] auto tense for replies: ""i replied to"" @someone ""with"" auto_join_text_url: ""i was looking at"", // [string] auto tense for urls: ""i was looking at"" http:... loading_text: null, // [string] optional loading text, displayed while tweets load query: null // [string] optional search query }; if(o) $.extend(s, o); $.fn.extend({ linkUrl: function() { var returning = []; var regexp = /((ftp|http|https):\/\/(\w+:{0,1}\w*@)?(\S+)(:[0-9]+)?(\/|\/([\w#!:.?+=&%@!\-\/]))?)/gi; this.each(function() { returning.push(this.replace(regexp,""<a href=\""$1\"">$1</a>"")); }); return $(returning); }, linkUser: function() { var returning = []; var regexp = /[\@]+([A-Za-z0-9-_]+)/gi; this.each(function() { returning.push(this.replace(regexp,""<a href=\""http://twitter.com/$1\"">@$1</a>"")); }); return $(returning); }, linkHash: function() { var returning = []; var regexp = / [\#]+([A-Za-z0-9-_]+)/gi; this.each(function() { returning.push(this.replace(regexp, ' <a href=""http://search.twitter.com/search?q=&tag=$1&lang=all&from='+s.username.join(""%2BOR%2B"")+'"">#$1</a>')); }); return $(returning); }, capAwesome: function() { var returning = []; this.each(function() { returning.push(this.replace(/\b(awesome)\b/gi, '<span class=""awesome"">$1</span>')); }); return $(returning); }, capEpic: function() { var returning = []; this.each(function() { returning.push(this.replace(/\b(epic)\b/gi, '<span class=""epic"">$1</span>')); }); return $(returning); }, makeHeart: function() { var returning = []; this.each(function() { returning.push(this.replace(/(&lt;)+[3]/gi, ""<tt class='heart'>&#x2665;</tt>"")); }); return $(returning); } }); function relative_time(time_value) { var parsed_date = Date.parse(time_value); var relative_to = (arguments.length > 1) ? arguments[1] : new Date(); var delta = parseInt((relative_to.getTime() - parsed_date) / 1000); var pluralize = function (singular, n) { return '' + n + ' ' + singular + (n == 1 ? '' : 's'); }; if(delta < 60) { return 'less than a minute ago'; } else if(delta < (45*60)) { return 'about ' + pluralize(""minute"", parseInt(delta / 60)) + ' ago'; } else if(delta < (24*60*60)) { return 'about ' + pluralize(""hour"", parseInt(delta / 3600)) + ' ago'; } else { return 'about ' + pluralize(""day"", parseInt(delta / 86400)) + ' ago'; } } function build_url() { var proto = ('https:' == document.location.protocol ? 'https:' : 'http:'); if (s.list) { return proto+""//api.twitter.com/1/""+s.username[0]+""/lists/""+s.list+""/statuses.json?per_page=""+s.count+""&callback=?""; } else if (s.query == null && s.username.length == 1) { return proto+'//twitter.com/status/user_timeline/'+s.username[0]+'.json?count='+s.count+'&callback=?'; } else { var query = (s.query || 'from:'+s.username.join('%20OR%20from:')); return proto+'//search.twitter.com/search.json?&q='+query+'&rpp='+s.count+'&callback=?'; } } return this.each(function(){ var list = $('<ul class=""tweet_list"">').appendTo(this); var intro = '<p class=""tweet_intro"">'+s.intro_text+'</p>'; var outro = '<p class=""tweet_outro"">'+s.outro_text+'</p>'; var loading = $('<p class=""loading"">'+s.loading_text+'</p>'); if(typeof(s.username) == ""string""){ s.username = [s.username]; } if (s.loading_text) $(this).append(loading); $.getJSON(build_url(), function(data){ if (s.loading_text) loading.remove(); if (s.intro_text) list.before(intro); $.each((data.results || data), function(i,item){ // auto join text based on verb tense and content if (s.join_text == ""auto"") { if (item.text.match(/^(@([A-Za-z0-9-_]+)) .*/i)) { var join_text = s.auto_join_text_reply; } else if (item.text.match(/(^\w+:\/\/[A-Za-z0-9-_]+\.[A-Za-z0-9-_:%&\?\/.=]+) .*/i)) { var join_text = s.auto_join_text_url; } else if (item.text.match(/^((\w+ed)|just) .*/im)) { var join_text = s.auto_join_text_ed; } else if (item.text.match(/^(\w*ing) .*/i)) { var join_text = s.auto_join_text_ing; } else { var join_text = s.auto_join_text_default; } } else { var join_text = s.join_text; }; var from_user = item.from_user || item.user.screen_name; var profile_image_url = item.profile_image_url || item.user.profile_image_url; var join_template = '<span class=""tweet_join""> '+join_text+' </span>'; var join = ((s.join_text) ? join_template : ' '); var avatar_template = '<a class=""tweet_avatar"" href=""http://twitter.com/'+from_user+'""><img src=""'+profile_image_url+'"" height=""'+s.avatar_size+'"" width=""'+s.avatar_size+'"" alt=""'+from_user+'\'s avatar"" title=""'+from_user+'\'s avatar"" border=""0""/></a>'; var avatar = (s.avatar_size ? avatar_template : ''); var date = '<a href=""http://twitter.com/'+from_user+'/statuses/'+item.id+'"" title=""view tweet on twitter"">'+relative_time(item.created_at)+'</a>'; var text = '<span class=""tweet_text"">' +$([item.text]).linkUrl().linkUser().linkHash().makeHeart().capAwesome().capEpic()[0]+ '</span>'; // until we create a template option, arrange the items below to alter a tweet's display. list.append('<li>' + avatar + date + join + text + '</li>'); list.children('li:first').addClass('tweet_first'); list.children('li:odd').addClass('tweet_even'); list.children('li:even').addClass('tweet_odd'); }); if (s.outro_text) list.after(outro); }); }); }; })(jQuery);",9,1234
openstack%2Ftrove~master~Ic956e3d16cfb981eb778c77e0fe41b2e2e5f6e46,openstack/trove,master,Ic956e3d16cfb981eb778c77e0fe41b2e2e5f6e46,Make Volume conditionally required attribute in Instance Create Schema,MERGED,2013-07-11 00:26:54.000000000,2013-07-19 23:46:11.000000000,2013-07-19 23:46:11.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 1375}, {'_account_id': 1925}, {'_account_id': 6156}, {'_account_id': 7092}]","[{'number': 1, 'created': '2013-07-11 00:26:54.000000000', 'files': ['trove/common/apischema.py', 'trove/instance/service.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/a42419c4fe58c5555533daf4ce96d1ddccea8041', 'message': 'Make Volume conditionally required attribute in Instance Create Schema\n\n    volume attribute may be removed in cases where volume support is off\n\nFixes: bug 1200029\n\nChange-Id: Ic956e3d16cfb981eb778c77e0fe41b2e2e5f6e46\n'}]",3,36592,a42419c4fe58c5555533daf4ce96d1ddccea8041,22,6,1,6156,,,0,"Make Volume conditionally required attribute in Instance Create Schema

    volume attribute may be removed in cases where volume support is off

Fixes: bug 1200029

Change-Id: Ic956e3d16cfb981eb778c77e0fe41b2e2e5f6e46
",git fetch https://review.opendev.org/openstack/trove refs/changes/92/36592/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/apischema.py', 'trove/instance/service.py']",2,a42419c4fe58c5555533daf4ce96d1ddccea8041,bug/1200029," schemas = apischema.instance.copy() if not CONF.trove_volume_support: # see instance.models.create for further validation around this LOG.info(""Removing volume attributes from schema"") schemas['create']['properties']['instance']['required'].pop()", schemas = apischema.instance,10,2
openstack%2Fsahara~master~Ie9f628fcc2ccb34b50abd401a514b1602c518f58,openstack/sahara,master,Ie9f628fcc2ccb34b50abd401a514b1602c518f58,Allow hacking 0.6.0 and fix errors from new checks,MERGED,2013-07-19 20:17:40.000000000,2013-07-19 22:04:02.000000000,2013-07-19 22:04:02.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-19 20:17:40.000000000', 'files': ['savanna/utils/api.py', 'savanna/service/validation.py', 'tools/test-requires', 'savanna/main.py', 'savanna/tests/unit/service/test_validation.py', 'savanna/utils/hacking/checks.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/96ebbb52e54b935f70cd6fdadc96f65bb5ba22d6', 'message': 'Allow hacking 0.6.0 and fix errors from new checks\n\nChange-Id: Ie9f628fcc2ccb34b50abd401a514b1602c518f58\n'}]",0,37961,96ebbb52e54b935f70cd6fdadc96f65bb5ba22d6,6,3,1,6786,,,0,"Allow hacking 0.6.0 and fix errors from new checks

Change-Id: Ie9f628fcc2ccb34b50abd401a514b1602c518f58
",git fetch https://review.opendev.org/openstack/sahara refs/changes/61/37961/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/service/validation.py', 'savanna/utils/api.py', 'tools/test-requires', 'savanna/main.py', 'savanna/tests/unit/service/test_validation.py', 'savanna/utils/hacking/checks.py']",6,96ebbb52e54b935f70cd6fdadc96f65bb5ba22d6,, pass,"# Stolen from the hacking lib's trunk # TODO(slukjanov): remove it when it'll be released with hacking import logging import re # Don't need this for testing logging.disable('LOG') def _check_for_exact_apache(start, lines): """"""Check for the Apache 2.0 license header. We strip all the newlines and extra spaces so this license string should work regardless of indentation in the file. """""" APACHE2 = """""" Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."""""" # out of all the formatting I've seen, a 12 line version seems to be the # longest in the source tree. So just take the 12 lines starting with where # the Apache starting words were found, strip all the '#' and collapse the # spaces. content = ''.join(lines[start:(start + 12)]) content = re.sub('\#', '', content) content = re.sub('\s+', ' ', content) stripped_apache2 = re.sub('\s+', ' ', APACHE2) if stripped_apache2 in content: return True else: print (""<license>!=<apache2>:\n'%s' !=\n'%s'"" % (stripped_apache2, content)) return False def _project_is_apache(): """"""Determine if a project is Apache. Look for a key string in a set of possible license files to figure out if a project looks to be Apache. This is used as a precondition for enforcing license headers. """""" license_files = [""LICENSE""] for filename in license_files: try: with open(filename, ""r"") as file: for line in file: if re.search('Apache License', line): return True except IOError: pass return False def hacking_has_license(physical_line, filename, lines, line_number): """"""Check for Apache 2.0 license. H102 license header not found """""" # don't work about init files for now # TODO(sdague): enforce license in init file if it's not empty of content license_found = False # skip files that are < 10 lines, which isn't enough for a license to fit # this allows us to handle empty files, as well as not fail on the Okay # doctests. if _project_is_apache() and not line_number > 1 and len(lines) > 10: for idx, line in enumerate(lines): # if it's more than 10 characters in, it's probably not in the # header if 0 < line.find('Licensed under the Apache License') < 10: license_found = True if not license_found: return (0, ""H102: Apache 2.0 license header not found"") def hacking_has_correct_license(physical_line, filename, lines, line_number): """"""Check for Apache 2.0 license. H103 header does not match Apache 2.0 License notice """""" # don't work about init files for now # TODO(sdague): enforce license in init file if it's not empty of content # skip files that are < 10 lines, which isn't enough for a license to fit # this allows us to handle empty files, as well as not fail on the Okay # doctests. if _project_is_apache() and not line_number > 1 and len(lines) > 10: for idx, line in enumerate(lines): # if it's more than 10 characters in, it's probably not in the # header if (0 < line.find('Licensed under the Apache License') < 10 and not _check_for_exact_apache(idx, lines)): return (idx, ""H103: Header does not match Apache 2.0 "" ""License notice"") def hacking_python3x_print_function(logical_line): r""""""Check that all occurrences look like print functions, not print operator. As of Python 3.x, the print operator has been removed. Okay: print(msg) Okay: print (msg) H233: print msg H233: print >>sys.stderr, ""hello"" H233: print msg, """""" for match in re.finditer(r""\bprint\s+[^\(]"", logical_line): yield match.start(0), ( ""H233: Python 3.x incompatible use of print operator"") register(hacking_has_license) register(hacking_has_correct_license) register(hacking_python3x_print_function)",11,140
openstack%2Fneutron~master~I2c8877e5987b5251bf59680d77c281dde895e58c,openstack/neutron,master,I2c8877e5987b5251bf59680d77c281dde895e58c,Imported Translations from Transifex,MERGED,2013-07-19 19:55:02.000000000,2013-07-19 22:00:03.000000000,2013-07-19 22:00:03.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 2031}]","[{'number': 1, 'created': '2013-07-19 19:55:02.000000000', 'files': ['neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ce013f2875ffe850fad285ed36cf4cde5a85dbc3', 'message': 'Imported Translations from Transifex\n\nChange-Id: I2c8877e5987b5251bf59680d77c281dde895e58c\n'}]",0,37960,ce013f2875ffe850fad285ed36cf4cde5a85dbc3,6,3,1,3,,,0,"Imported Translations from Transifex

Change-Id: I2c8877e5987b5251bf59680d77c281dde895e58c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/60/37960/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po']",20,ce013f2875ffe850fad285ed36cf4cde5a85dbc3,transifex/translations,"""POT-Creation-Date: 2013-07-19 19:54+0000\n""#: neutron/common/log.py:31 #, python-format msgid """" ""%(class_name)s method %(method_name)scalled with arguments %(args)s "" ""%(kwargs)s "" msgstr """" #: neutron/db/l3_db.py:600 neutron/plugins/nicira/NeutronPlugin.py:1863#: neutron/plugins/nicira/NeutronPlugin.py:1062#: neutron/plugins/nicira/NeutronPlugin.py:238#: neutron/plugins/nicira/NeutronPlugin.py:273#: neutron/plugins/nicira/NeutronPlugin.py:275#: neutron/plugins/nicira/NeutronPlugin.py:278#: neutron/plugins/nicira/NeutronPlugin.py:353#: neutron/plugins/nicira/NeutronPlugin.py:359#: neutron/plugins/nicira/NeutronPlugin.py:365#: neutron/plugins/nicira/NeutronPlugin.py:410#: neutron/plugins/nicira/NeutronPlugin.py:436 #: neutron/plugins/nicira/NeutronPlugin.py:471 #: neutron/plugins/nicira/NeutronPlugin.py:639#: neutron/plugins/nicira/NeutronPlugin.py:456 #: neutron/plugins/nicira/NeutronPlugin.py:536 #: neutron/plugins/nicira/NeutronPlugin.py:658#: neutron/plugins/nicira/NeutronPlugin.py:460#: neutron/plugins/nicira/NeutronPlugin.py:478#: neutron/plugins/nicira/NeutronPlugin.py:487#: neutron/plugins/nicira/NeutronPlugin.py:493#: neutron/plugins/nicira/NeutronPlugin.py:512 #: neutron/plugins/nicira/NeutronPlugin.py:914#: neutron/plugins/nicira/NeutronPlugin.py:524#: neutron/plugins/nicira/NeutronPlugin.py:543#: neutron/plugins/nicira/NeutronPlugin.py:551#: neutron/plugins/nicira/NeutronPlugin.py:588#: neutron/plugins/nicira/NeutronPlugin.py:620#: neutron/plugins/nicira/NeutronPlugin.py:624 #: neutron/plugins/nicira/NeutronPlugin.py:1808#: neutron/plugins/nicira/NeutronPlugin.py:626#: neutron/plugins/nicira/NeutronPlugin.py:696#: neutron/plugins/nicira/NeutronPlugin.py:725#: neutron/plugins/nicira/NeutronPlugin.py:729#: neutron/plugins/nicira/NeutronPlugin.py:733#: neutron/plugins/nicira/NeutronPlugin.py:737 #: neutron/plugins/nicira/NeutronPlugin.py:752#: neutron/plugins/nicira/NeutronPlugin.py:758#: neutron/plugins/nicira/NeutronPlugin.py:789#: neutron/plugins/nicira/NeutronPlugin.py:811#: neutron/plugins/nicira/NeutronPlugin.py:838#: neutron/plugins/nicira/NeutronPlugin.py:896#: neutron/plugins/nicira/NeutronPlugin.py:924#: neutron/plugins/nicira/NeutronPlugin.py:927#: neutron/plugins/nicira/NeutronPlugin.py:953#: neutron/plugins/nicira/NeutronPlugin.py:963 #: neutron/plugins/nicira/NeutronPlugin.py:1011#: neutron/plugins/nicira/NeutronPlugin.py:1025#: neutron/plugins/nicira/NeutronPlugin.py:1040#: neutron/plugins/nicira/NeutronPlugin.py:1044#: neutron/plugins/nicira/NeutronPlugin.py:1130#: neutron/plugins/nicira/NeutronPlugin.py:1139#: neutron/plugins/nicira/NeutronPlugin.py:1166#: neutron/plugins/nicira/NeutronPlugin.py:1173#: neutron/plugins/nicira/NeutronPlugin.py:1239#: neutron/plugins/nicira/NeutronPlugin.py:1247#: neutron/plugins/nicira/NeutronPlugin.py:1251#: neutron/plugins/nicira/NeutronPlugin.py:1326#: neutron/plugins/nicira/NeutronPlugin.py:1352#: neutron/plugins/nicira/NeutronPlugin.py:1476 #: neutron/plugins/nicira/NeutronPlugin.py:1520#: neutron/plugins/nicira/NeutronPlugin.py:1489#: neutron/plugins/nicira/NeutronPlugin.py:1529#: neutron/plugins/nicira/NeutronPlugin.py:1545#: neutron/plugins/nicira/NeutronPlugin.py:1549#: neutron/plugins/nicira/NeutronPlugin.py:1551#: neutron/plugins/nicira/NeutronPlugin.py:1584#: neutron/plugins/nicira/NeutronPlugin.py:1588#: neutron/plugins/nicira/NeutronPlugin.py:1608#: neutron/plugins/nicira/NeutronPlugin.py:1635#: neutron/plugins/nicira/NeutronPlugin.py:1657#: neutron/plugins/nicira/NeutronPlugin.py:1683#: neutron/plugins/nicira/NeutronPlugin.py:1718#: neutron/plugins/nicira/NeutronPlugin.py:1763#: neutron/plugins/nicira/NeutronPlugin.py:1775#: neutron/plugins/nicira/NeutronPlugin.py:1804#: neutron/plugins/nicira/NeutronPlugin.py:1830#: neutron/plugins/nicira/NeutronPlugin.py:1836#: neutron/plugins/nicira/NeutronPlugin.py:1902#: neutron/plugins/nicira/NeutronPlugin.py:1926#: neutron/plugins/nicira/NeutronPlugin.py:1969#: neutron/plugins/nicira/NeutronPlugin.py:1972#: neutron/plugins/nicira/NeutronPlugin.py:1998#: neutron/plugins/nicira/NeutronPlugin.py:2020#~ ""NoopLbaaSDriver method %(method_name)scalled with"" #~ "" arguments %(args)s %(kwargs)s ""","""POT-Creation-Date: 2013-07-18 19:54+0000\n""#: neutron/db/l3_db.py:600 neutron/plugins/nicira/NeutronPlugin.py:1861#: neutron/plugins/nicira/NeutronPlugin.py:1060#: neutron/plugins/nicira/NeutronPlugin.py:236#: neutron/plugins/nicira/NeutronPlugin.py:271#: neutron/plugins/nicira/NeutronPlugin.py:273#: neutron/plugins/nicira/NeutronPlugin.py:276#: neutron/plugins/nicira/NeutronPlugin.py:351#: neutron/plugins/nicira/NeutronPlugin.py:357#: neutron/plugins/nicira/NeutronPlugin.py:363#: neutron/plugins/nicira/NeutronPlugin.py:408#: neutron/plugins/nicira/NeutronPlugin.py:434 #: neutron/plugins/nicira/NeutronPlugin.py:469 #: neutron/plugins/nicira/NeutronPlugin.py:637#: neutron/plugins/nicira/NeutronPlugin.py:454 #: neutron/plugins/nicira/NeutronPlugin.py:534 #: neutron/plugins/nicira/NeutronPlugin.py:656#: neutron/plugins/nicira/NeutronPlugin.py:458#: neutron/plugins/nicira/NeutronPlugin.py:476#: neutron/plugins/nicira/NeutronPlugin.py:485#: neutron/plugins/nicira/NeutronPlugin.py:491#: neutron/plugins/nicira/NeutronPlugin.py:510 #: neutron/plugins/nicira/NeutronPlugin.py:912#: neutron/plugins/nicira/NeutronPlugin.py:522#: neutron/plugins/nicira/NeutronPlugin.py:541#: neutron/plugins/nicira/NeutronPlugin.py:549#: neutron/plugins/nicira/NeutronPlugin.py:586#: neutron/plugins/nicira/NeutronPlugin.py:618#: neutron/plugins/nicira/NeutronPlugin.py:622 #: neutron/plugins/nicira/NeutronPlugin.py:1806#: neutron/plugins/nicira/NeutronPlugin.py:624#: neutron/plugins/nicira/NeutronPlugin.py:694#: neutron/plugins/nicira/NeutronPlugin.py:723#: neutron/plugins/nicira/NeutronPlugin.py:727#: neutron/plugins/nicira/NeutronPlugin.py:731#: neutron/plugins/nicira/NeutronPlugin.py:735 #: neutron/plugins/nicira/NeutronPlugin.py:750#: neutron/plugins/nicira/NeutronPlugin.py:756#: neutron/plugins/nicira/NeutronPlugin.py:787#: neutron/plugins/nicira/NeutronPlugin.py:809#: neutron/plugins/nicira/NeutronPlugin.py:836#: neutron/plugins/nicira/NeutronPlugin.py:894#: neutron/plugins/nicira/NeutronPlugin.py:922#: neutron/plugins/nicira/NeutronPlugin.py:925#: neutron/plugins/nicira/NeutronPlugin.py:951#: neutron/plugins/nicira/NeutronPlugin.py:961 #: neutron/plugins/nicira/NeutronPlugin.py:1009#: neutron/plugins/nicira/NeutronPlugin.py:1023#: neutron/plugins/nicira/NeutronPlugin.py:1038#: neutron/plugins/nicira/NeutronPlugin.py:1042#: neutron/plugins/nicira/NeutronPlugin.py:1128#: neutron/plugins/nicira/NeutronPlugin.py:1137#: neutron/plugins/nicira/NeutronPlugin.py:1164#: neutron/plugins/nicira/NeutronPlugin.py:1171#: neutron/plugins/nicira/NeutronPlugin.py:1237#: neutron/plugins/nicira/NeutronPlugin.py:1245#: neutron/plugins/nicira/NeutronPlugin.py:1249#: neutron/plugins/nicira/NeutronPlugin.py:1324#: neutron/plugins/nicira/NeutronPlugin.py:1350#: neutron/plugins/nicira/NeutronPlugin.py:1474 #: neutron/plugins/nicira/NeutronPlugin.py:1518#: neutron/plugins/nicira/NeutronPlugin.py:1487#: neutron/plugins/nicira/NeutronPlugin.py:1527#: neutron/plugins/nicira/NeutronPlugin.py:1543#: neutron/plugins/nicira/NeutronPlugin.py:1547#: neutron/plugins/nicira/NeutronPlugin.py:1549#: neutron/plugins/nicira/NeutronPlugin.py:1582#: neutron/plugins/nicira/NeutronPlugin.py:1586#: neutron/plugins/nicira/NeutronPlugin.py:1606#: neutron/plugins/nicira/NeutronPlugin.py:1633#: neutron/plugins/nicira/NeutronPlugin.py:1655#: neutron/plugins/nicira/NeutronPlugin.py:1681#: neutron/plugins/nicira/NeutronPlugin.py:1716#: neutron/plugins/nicira/NeutronPlugin.py:1761#: neutron/plugins/nicira/NeutronPlugin.py:1773#: neutron/plugins/nicira/NeutronPlugin.py:1802#: neutron/plugins/nicira/NeutronPlugin.py:1828#: neutron/plugins/nicira/NeutronPlugin.py:1834#: neutron/plugins/nicira/NeutronPlugin.py:1900#: neutron/plugins/nicira/NeutronPlugin.py:1924#: neutron/plugins/nicira/NeutronPlugin.py:1967#: neutron/plugins/nicira/NeutronPlugin.py:1970#: neutron/plugins/nicira/NeutronPlugin.py:1996#: neutron/plugins/nicira/NeutronPlugin.py:2018#: neutron/services/loadbalancer/drivers/noop/noop_driver.py:31 #, python-format msgid """" ""NoopLbaaSDriver method %(method_name)scalled with arguments %(args)s "" ""%(kwargs)s "" msgstr """" #~ ""_activate_packet_filter_if_ready(): skip, "" #~ ""packet_filter.admin_state_up is False."" #~ msgstr """" #~ msgid """" #~ ""_activate_packet_filter_if_ready(): skip, "" #~ ""network.admin_state_up is False."" #~ msgstr """" #~ msgid ""_activate_packet_filter_if_ready(): skip, invalid in_port_id."" #~ msgstr """" #~ msgid ""_activate_packet_filter_if_ready(): skip, no portinfo for in_port."" #~ msgstr """" #~ msgid ""create_ofc_packet_filter() failed due to %s"" #~ msgstr """" #~ msgid ""_deactivate_packet_filter(): skip, ofc_packet_filter does not exist."" #~ msgstr """" #~ msgid ""delete_ofc_packet_filter() failed due to %s"" #~ msgstr """" #~ msgid ""NECPluginV2.create_packet_filter() called, packet_filter=%s ."" #~ msgstr """" #~ msgid """" #~ ""NECPluginV2.update_packet_filter() called, id=%(id)s "" #~ ""packet_filter=%(packet_filter)s ."" #~ msgstr """" #~ msgid ""NECPluginV2.delete_packet_filter() called, id=%s ."" #~ msgstr """" #~ msgid ""No tunnel_type specified, cannot add tunnel port""",1859,2521
openstack%2Fcinder~master~Ibcf087c0f099262b90c115a155fdef619d3c5851,openstack/cinder,master,Ibcf087c0f099262b90c115a155fdef619d3c5851,Sync gettextutils from oslo,MERGED,2013-07-09 21:49:45.000000000,2013-07-19 21:59:56.000000000,2013-07-19 21:59:56.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2759}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 7996}]","[{'number': 1, 'created': '2013-07-09 21:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/86a2206f83221b5d1a92809f18cb5ec31c4eb472', 'message': 'Sync gettextutils from oslo\n\nBring in the necessary code for handling cinder translations\n\nPartially implements bp user-locale-api\n\nChange-Id: Ibcf087c0f099262b90c115a155fdef619d3c5851\n'}, {'number': 2, 'created': '2013-07-10 15:38:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0e7479732fc978d91a05daef278dd47d090ab612', 'message': 'Sync gettextutils from oslo\n\nBring in the necessary code for handling cinder translations\n\nPartially implements bp user-locale-api\n\nChange-Id: Ibcf087c0f099262b90c115a155fdef619d3c5851\n'}, {'number': 3, 'created': '2013-07-18 20:40:10.000000000', 'files': ['cinder/openstack/common/gettextutils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8e76231fda7ec828856a9fca32f37ff9089611a8', 'message': 'Sync gettextutils from oslo\n\nBring in the necessary code for handling cinder translations\n\nPartially implements bp user-locale-api\n\nChange-Id: Ibcf087c0f099262b90c115a155fdef619d3c5851\n'}]",0,36345,8e76231fda7ec828856a9fca32f37ff9089611a8,16,6,3,7996,,,0,"Sync gettextutils from oslo

Bring in the necessary code for handling cinder translations

Partially implements bp user-locale-api

Change-Id: Ibcf087c0f099262b90c115a155fdef619d3c5851
",git fetch https://review.opendev.org/openstack/cinder refs/changes/45/36345/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/openstack/common/gettextutils.py'],1,86a2206f83221b5d1a92809f18cb5ec31c4eb472,bp/user-locale-api,"# Copyright 2013 IBM Corp.import copyimport logging.handlersimport UserString """""" Lazy gettext functionality. The following is an attempt to introduce a deferred way to do translations on messages in OpenStack. We attempt to override the standard _() function and % (format string) operation to build Message objects that can later be translated when we have more information. Also included is an example LogHandler that translates Messages to an associated locale, effectively allowing many logs, each with their own locale. """""" def get_lazy_gettext(domain): """"""Assemble and return a lazy gettext function for a given domain. Factory method for a project/module to get a lazy gettext function for its own translation domain (i.e. nova, glance, cinder, etc.) """""" def _lazy_gettext(msg): """"""Create and return a Message object. Message encapsulates a string so that we can translate it later when needed. """""" return Message(msg, domain) return _lazy_gettext class Message(UserString.UserString, object): """"""Class used to encapsulate translatable messages."""""" def __init__(self, msg, domain): # _msg is the gettext msgid and should never change self._msg = msg self._left_extra_msg = '' self._right_extra_msg = '' self.params = None self.locale = None self.domain = domain @property def data(self): # NOTE(mrodden): this should always resolve to a unicode string # that best represents the state of the message currently localedir = os.environ.get(self.domain.upper() + '_LOCALEDIR') if self.locale: lang = gettext.translation(self.domain, localedir=localedir, languages=[self.locale], fallback=True) else: # use system locale for translations lang = gettext.translation(self.domain, localedir=localedir, fallback=True) full_msg = (self._left_extra_msg + lang.ugettext(self._msg) + self._right_extra_msg) if self.params is not None: full_msg = full_msg % self.params return unicode(full_msg) def _save_parameters(self, other): # we check for None later to see if # we actually have parameters to inject, # so encapsulate if our parameter is actually None if other is None: self.params = (other, ) else: self.params = copy.deepcopy(other) return self # overrides to be more string-like def __unicode__(self): return self.data def __str__(self): return self.data.encode('utf-8') def __getstate__(self): to_copy = ['_msg', '_right_extra_msg', '_left_extra_msg', 'domain', 'params', 'locale'] new_dict = self.__dict__.fromkeys(to_copy) for attr in to_copy: new_dict[attr] = copy.deepcopy(self.__dict__[attr]) return new_dict def __setstate__(self, state): for (k, v) in state.items(): setattr(self, k, v) # operator overloads def __add__(self, other): copied = copy.deepcopy(self) copied._right_extra_msg += other.__str__() return copied def __radd__(self, other): copied = copy.deepcopy(self) copied._left_extra_msg += other.__str__() return copied def __mod__(self, other): # do a format string to catch and raise # any possible KeyErrors from missing parameters self.data % other copied = copy.deepcopy(self) return copied._save_parameters(other) def __mul__(self, other): return self.data * other def __rmul__(self, other): return other * self.data def __getitem__(self, key): return self.data[key] def __getslice__(self, start, end): return self.data.__getslice__(start, end) def __getattribute__(self, name): # NOTE(mrodden): handle lossy operations that we can't deal with yet # These override the UserString implementation, since UserString # uses our __class__ attribute to try and build a new message # after running the inner data string through the operation. # At that point, we have lost the gettext message id and can just # safely resolve to a string instead. ops = ['capitalize', 'center', 'decode', 'encode', 'expandtabs', 'ljust', 'lstrip', 'replace', 'rjust', 'rstrip', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'] if name in ops: return getattr(self.data, name) else: return UserString.UserString.__getattribute__(self, name) class LocaleHandler(logging.Handler): """"""Handler that can have a locale associated to translate Messages. A quick example of how to utilize the Message class above. LocaleHandler takes a locale and a target logging.Handler object to forward LogRecord objects to after translating the internal Message. """""" def __init__(self, locale, target): """"""Initialize a LocaleHandler :param locale: locale to use for translating messages :param target: logging.Handler object to forward LogRecord objects to after translation """""" logging.Handler.__init__(self) self.locale = locale self.target = target def emit(self, record): if isinstance(record.msg, Message): # set the locale and resolve to a string record.msg.locale = self.locale self.target.emit(record)",,176,0
openstack%2Fpython-troveclient~master~Idf160cb5f8862665ded47146e96af521cf438519,openstack/python-troveclient,master,Idf160cb5f8862665ded47146e96af521cf438519,Fix Description param for Backups,MERGED,2013-07-18 01:13:28.000000000,2013-07-19 21:58:32.000000000,2013-07-19 21:58:32.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 739}, {'_account_id': 1375}, {'_account_id': 1925}, {'_account_id': 7092}]","[{'number': 1, 'created': '2013-07-18 01:13:28.000000000', 'files': ['troveclient/backups.py', 'troveclient/cli.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/b98893926d14bd0b5b2706c808688659695c1731', 'message': 'Fix Description param for Backups\n\n    If description is not specified do not send as null\n\nFixes: bug 1201990\n\nChange-Id: Idf160cb5f8862665ded47146e96af521cf438519\n'}]",0,37600,b98893926d14bd0b5b2706c808688659695c1731,9,6,1,6156,,,0,"Fix Description param for Backups

    If description is not specified do not send as null

Fixes: bug 1201990

Change-Id: Idf160cb5f8862665ded47146e96af521cf438519
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/00/37600/1 && git format-patch -1 --stdout FETCH_HEAD,"['troveclient/backups.py', 'troveclient/cli.py']",2,b98893926d14bd0b5b2706c808688659695c1731,bug/1201990, if self.size: if self.backup:, if self.size is not None: if self.backup is not None:,10,7
openstack%2Fcinder~master~I21337d5ca78090665b2feba50c74f853d3703650,openstack/cinder,master,I21337d5ca78090665b2feba50c74f853d3703650,Add test for volume status check when extending,MERGED,2013-07-19 19:51:56.000000000,2013-07-19 21:51:50.000000000,2013-07-19 21:51:50.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-07-19 19:51:56.000000000', 'files': ['cinder/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/25b75a640c6979b64d4eee62e88261101916fe50', 'message': ""Add test for volume status check when extending\n\nEnsure exception is raised if volume status is not 'available'\nwhen extending volume.\n\nChange-Id: I21337d5ca78090665b2feba50c74f853d3703650\n""}]",0,37958,25b75a640c6979b64d4eee62e88261101916fe50,7,4,1,7156,,,0,"Add test for volume status check when extending

Ensure exception is raised if volume status is not 'available'
when extending volume.

Change-Id: I21337d5ca78090665b2feba50c74f853d3703650
",git fetch https://review.opendev.org/openstack/cinder refs/changes/58/37958/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/test_volume.py'],1,25b75a640c6979b64d4eee62e88261101916fe50,test_volume_status_when_extending," volume['status'] = 'in-use' # Extend fails when status != available self.assertRaises(exception.InvalidVolume, volume_api.extend, self.context, volume, 3) volume['status'] = 'available'", volume['status'] = 'available',9,1
openstack%2Fbarbican~master~I769d44530be96ef18728b431acd1e198e8a84219,openstack/barbican,master,I769d44530be96ef18728b431acd1e198e8a84219,Fixing NoneType issue with limit and offset,MERGED,2013-07-18 23:43:27.000000000,2013-07-19 21:33:40.000000000,2013-07-19 21:33:40.000000000,"[{'_account_id': 3}, {'_account_id': 7262}, {'_account_id': 7973}]","[{'number': 1, 'created': '2013-07-18 23:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/5b202acd2a80c055c2a3bdf0df3db133a1c76397', 'message': 'Fixing NoneType issue with limit and offset\n\nFixes issue where the server returns 500 when the limit and/or offset in\npaging are set to None.\n\nFixes: bug #1202857\nChange-Id: I769d44530be96ef18728b431acd1e198e8a84219\n'}, {'number': 2, 'created': '2013-07-18 23:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/9533d1229db204d34d5a7beade8a2eacd96fec36', 'message': 'Fixing NoneType issue with limit and offset\n\nFixes issue where the server returns 500 when the limit and/or offset in\npaging are set to None.\n\nFixes: bug #1202857\nChange-Id: I769d44530be96ef18728b431acd1e198e8a84219\n'}, {'number': 3, 'created': '2013-07-19 21:02:26.000000000', 'files': ['barbican/model/repositories.py', 'barbican/tests/model/test_repositories.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/f73104ea35b0a88d47e512f723b3e554ce153ac2', 'message': 'Fixing NoneType issue with limit and offset\n\nFixes issue where the server returns 500 when the limit and/or offset in\npaging are set to None.\n- Adding tests for cleaning the paging parameters.\n\nFixes: bug #1202857\nChange-Id: I769d44530be96ef18728b431acd1e198e8a84219\n'}]",5,37810,f73104ea35b0a88d47e512f723b3e554ce153ac2,15,3,3,7262,,,0,"Fixing NoneType issue with limit and offset

Fixes issue where the server returns 500 when the limit and/or offset in
paging are set to None.
- Adding tests for cleaning the paging parameters.

Fixes: bug #1202857
Change-Id: I769d44530be96ef18728b431acd1e198e8a84219
",git fetch https://review.opendev.org/openstack/barbican refs/changes/10/37810/2 && git format-patch -1 --stdout FETCH_HEAD,['barbican/model/repositories.py'],1,5b202acd2a80c055c2a3bdf0df3db133a1c76397,bug/1202857, offset_arg = offset_arg or 0 limit_arg = limit_arg or CONF.default_limit_paging ,,3,0
openstack%2Fironic~master~Ic27565b03a974a5c9115a1af6003b322be5e4c38,openstack/ironic,master,Ic27565b03a974a5c9115a1af6003b322be5e4c38,"Sync Requirements, remove upper capping of client versions",ABANDONED,2013-07-14 18:53:31.000000000,2013-07-19 21:21:53.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6773}]","[{'number': 1, 'created': '2013-07-14 18:53:31.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/1025298c89619bcd146d5b729a270c933b9b4a2c', 'message': 'Sync Requirements, remove upper capping of client versions\n\nFixes LP Bug #1200214\n\nChange-Id: Ic27565b03a974a5c9115a1af6003b322be5e4c38\n'}]",3,36992,1025298c89619bcd146d5b729a270c933b9b4a2c,5,4,1,6593,,,0,"Sync Requirements, remove upper capping of client versions

Fixes LP Bug #1200214

Change-Id: Ic27565b03a974a5c9115a1af6003b322be5e4c38
",git fetch https://review.opendev.org/openstack/ironic refs/changes/92/36992/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,1025298c89619bcd146d5b729a270c933b9b4a2c,bug/1200214,"hacking>=0.5.6,<0.6testrepository>=0.0.15","hacking>=0.5.3,<0.6testrepository>=0.0.13",5,5
openstack%2Fpython-novaclient~master~If9c21ae4f3cfbeb89569f6e4bd415c2041dc6294,openstack/python-novaclient,master,If9c21ae4f3cfbeb89569f6e4bd415c2041dc6294,Fix backwards-incompatible API change (method signature),MERGED,2013-07-19 13:54:17.000000000,2013-07-19 21:15:39.000000000,2013-07-19 21:15:39.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 739}, {'_account_id': 1501}, {'_account_id': 4978}, {'_account_id': 5293}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-19 13:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/0fab9c212a78cd28274b1e8e6d917562b8682461', 'message': 'Revert ""Allow tenant ID for authentication""\n\nThis reverts commit 02f906bcd6866b24fa0b48d47f573197b17f0753.\n\nThis change contained a backwards-incompatible API change, breaking\nconsumers including Horizon master and stable versions.\n\nChange-Id: If9c21ae4f3cfbeb89569f6e4bd415c2041dc6294\n'}, {'number': 2, 'created': '2013-07-19 13:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/3ad696152eabe01515a037be6d5324739faacb09', 'message': 'Revert ""Allow tenant ID for authentication""\n\nThis reverts commit 02f906bcd6866b24fa0b48d47f573197b17f0753.\n\nThis change contained a backwards-incompatible API change, breaking\nconsumers including Horizon master and stable versions.\n\nFixes bug 1203001\n\nChange-Id: If9c21ae4f3cfbeb89569f6e4bd415c2041dc6294\n'}, {'number': 3, 'created': '2013-07-19 15:41:56.000000000', 'files': ['novaclient/v1_1/client.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/f702c25d4364583d6532bf11b2cce1107994bcce', 'message': 'Fix backwards-incompatible API change (method signature)\n\nproject_id was changed to projectid in a previous changeset.\n\nFixes bug 1203001\n\nChange-Id: If9c21ae4f3cfbeb89569f6e4bd415c2041dc6294\n'}]",0,37903,f702c25d4364583d6532bf11b2cce1107994bcce,25,7,3,4978,,,0,"Fix backwards-incompatible API change (method signature)

project_id was changed to projectid in a previous changeset.

Fixes bug 1203001

Change-Id: If9c21ae4f3cfbeb89569f6e4bd415c2041dc6294
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/03/37903/2 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/test_shell.py', 'novaclient/v1_1/client.py', 'novaclient/client.py', 'novaclient/shell.py']",4,0fab9c212a78cd28274b1e8e6d917562b8682461,bug/1203001," (os_username, os_tenant_name, os_auth_url, args.os_tenant_name, args.os_auth_url, if not os_tenant_name: ""via either --os-tenant-name or "" ""env[OS_TENANT_NAME]"") if not os_tenant_name: ""via either --os-tenant-name or env[OS_TENANT_NAME]"") os_password, os_tenant_name, os_auth_url, insecure,"," parser.add_argument('--os-tenant-id', metavar='<auth-tenant-id>', default=utils.env('OS_TENANT_ID'), help='Defaults to env[OS_TENANT_ID].') (os_username, os_tenant_name, os_tenant_id, os_auth_url, args.os_tenant_name, args.os_tenant_id, args.os_auth_url, if not os_tenant_name and not os_tenant_id: ""or tenant id via --os-tenant-name, "" ""--os-tenant-id, env[OS_TENANT_NAME] "" ""or env[OS_TENANT_ID]"") if not os_tenant_name and not os_tenant_id: ""or tenant id via --os-tenant-name, "" ""--os-tenant-id, env[OS_TENANT_NAME] "" ""or env[OS_TENANT_ID]"") os_password, os_tenant_name, tenant_id=os_tenant_id, auth_url=os_auth_url, insecure=insecure,",21,54
openstack%2Ftripleo-image-elements~master~I77a746a4a5a5409e112e2ef48a100814c42b4868,openstack/tripleo-image-elements,master,I77a746a4a5a5409e112e2ef48a100814c42b4868,Add an element that enables the SNMP daemon.,MERGED,2013-07-19 21:10:58.000000000,2013-07-19 21:10:58.000000000,2013-07-19 21:10:58.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6449}, {'_account_id': 6488}]","[{'number': 6, 'created': '2013-07-19 21:10:58.000000000', 'files': ['elements/snmpd/README.md', 'elements/snmpd/element-deps', 'elements/snmpd/install.d/67-snmpd', 'elements/snmpd/os-apply-config/etc/snmp/snmpd.conf', 'elements/snmpd/os-apply-config/etc/default/snmpd'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6e6c6bbc73652c4fd5b90917ddf8fa0c10392858', 'message': 'Add an element that enables the SNMP daemon.\n\nInstalls and enables the Simple Network Management Protocol (SNMP)\ndaemon. Adding this element will allow for more advanced external\nmonitoring of Nodes from applications like Nagios.\n\nChange-Id: I77a746a4a5a5409e112e2ef48a100814c42b4868\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\n'}, {'number': 5, 'created': '2013-07-19 21:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/98e52c2d65bad4c795ed5ffa6f98d0c0c7f0afb7', 'message': 'Add an element that enables the SNMP daemon.\n\nInstalls and enables the Simple Network Management Protocol (SNMP)\ndaemon. Adding this element will allow for more advanced external\nmonitoring of Nodes from applications like Nagios.\n\nChange-Id: I77a746a4a5a5409e112e2ef48a100814c42b4868\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\n'}, {'number': 4, 'created': '2013-07-19 21:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ce1992068351182ac23c2d17a6f969a3305d9b37', 'message': 'Add element to install Simple Network Management Protocol (SNMP) daemon.\n\nInstalls and enables the SNMP daemon. Adding this element will allow for\nmore advanced external monitoring of Nodes from applications like\nNagios.\n\nChange-Id: I77a746a4a5a5409e112e2ef48a100814c42b4868\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\n'}, {'number': 3, 'created': '2013-07-19 21:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/34530315a4e0099e6f8398a501274d33078c86a2', 'message': 'Add element to install Simple Network Management Protocol (SNMP) daemon.\n\nInstalls and enables the SNMP daemon. Adding this element will allow for\nmore advanced external monitoring of Nodes from applications like\nNagios.\n\nChange-Id: I77a746a4a5a5409e112e2ef48a100814c42b4868\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\n'}, {'number': 2, 'created': '2013-07-19 21:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/dff4b8b5efbdc7071665209f084ebb77352504f5', 'message': 'Add element to install Simple Network Management Protocol (SNMP) daemon.\n\nInstalls and enables the SNMP daemon. Adding this element will allow for\nmore advanced external monitoring of Nodes from applications like\nNagios.\n\nChange-Id: I77a746a4a5a5409e112e2ef48a100814c42b4868\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\n'}, {'number': 1, 'created': '2013-07-19 21:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/20ed2c5392f6901201711ce5c9902a72f4e8b7fb', 'message': 'Add element to install Simple Network Management Protocol (SNMP) daemon.\n\nInstalls and enables the SNMP daemon. Adding this element will allow for\nmore advanced external monitoring of Nodes from applications like\nNagios.\n\nChange-Id: I77a746a4a5a5409e112e2ef48a100814c42b4868\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\n'}]",12,37318,6e6c6bbc73652c4fd5b90917ddf8fa0c10392858,21,4,6,5805,,,0,"Add an element that enables the SNMP daemon.

Installs and enables the Simple Network Management Protocol (SNMP)
daemon. Adding this element will allow for more advanced external
monitoring of Nodes from applications like Nagios.

Change-Id: I77a746a4a5a5409e112e2ef48a100814c42b4868
Authored-by: Chris Krelle <nobodycam@gmail.com>
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/18/37318/6 && git format-patch -1 --stdout FETCH_HEAD,"['elements/snmpd/README.md', 'elements/snmpd/element-deps', 'elements/snmpd/install.d/67-snmpd', 'elements/snmpd/os-apply-config/etc/default/snmpd', 'elements/snmpd/os-apply-config/etc/snmp/snmpd.conf']",5,6e6c6bbc73652c4fd5b90917ddf8fa0c10392858,,"# Listen for connections on all interfaces (both IPv4 *and* IPv6) agentAddress udp:161,udp6:[::1]:161 createUser {{snmp.readonly_user_name}} MD5 ""{{snmp.readonly_user_password}}"" view systemonly included .1.3.6.1.2.1.1 view systemonly included .1.3.6.1.2.1.25.1 rouser authOnlyUser sysLocation Sitting on top of the cloud sysContact Me <me@example.org> sysServices 72 # Process Monitoring proc cron # Disk Monitoring # 10MBs required on root disk, 5% free on /var, 10% free on all other disks includeAllDisks 10% # ACTIVE MONITORING # send SNMPv1 traps trapsink localhost public iquerySecName internalUser rouser internalUser # generate traps on UCD error conditions defaultMonitors yes # generate traps on linkUp/Down linkUpDownNotifications yes # Arbitrary extension commands #extend test1 /bin/echo Hello, cloud! #extend-sh test2 echo Hello, cloud ; echo Hi there ; exit 35 # ""Pass-through"" MIB extension command #pass .1.3.6.1.4.1.8072.2.255 /bin/sh PREFIX/local/passtest #pass .1.3.6.1.4.1.8072.2.255 /usr/bin/perl PREFIX/local/passtest.pl # AgentX Sub-agents # Run as an AgentX master agent master agentx ",,78,0
openstack%2Fpython-openstackclient~master~Icd408c2b34af07f5102f53d3778d8546952a12c5,openstack/python-openstackclient,master,Icd408c2b34af07f5102f53d3778d8546952a12c5,Add aggregate commands,MERGED,2013-07-11 20:46:54.000000000,2013-07-19 20:39:44.000000000,2013-07-19 20:39:44.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}]","[{'number': 1, 'created': '2013-07-11 20:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/2362f0db634629d71510267cee0dc334af42bb96', 'message': 'Add aggregate commands\n\n* Add aggregate: add host, create, delete, list remove host, set, show\n\nBug: 1172032\nBlueprint: nova-client\n\nChange-Id: Icd408c2b34af07f5102f53d3778d8546952a12c5\n'}, {'number': 2, 'created': '2013-07-17 18:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/50c8998eae7d25ed399f234328352bae4bd50f4f', 'message': ""Add aggregate commands\n\n* Add aggregate: add host, create, delete, list, remove host, set, show\n\n* Add list --long option\n* Filter 'availability_zone' from the metadata fields\n* Rename 'metadata' column to 'properties' in all output\n\nBug: 1172032\nBlueprint: nova-client\n\nChange-Id: Icd408c2b34af07f5102f53d3778d8546952a12c5\n""}, {'number': 3, 'created': '2013-07-19 20:37:17.000000000', 'files': ['setup.cfg', 'openstackclient/compute/v2/aggregate.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/2cc996356c438e45a876a6cb51a332d070044c1e', 'message': ""Add aggregate commands\n\n* Add aggregate: add host, create, delete, list, remove host, set, show\n\n* Add list --long option\n* Filter 'availability_zone' from the metadata fields\n* Rename 'metadata' column to 'properties' in all output\n\nBug: 1172032\nBlueprint: nova-client\n\nChange-Id: Icd408c2b34af07f5102f53d3778d8546952a12c5\n""}]",6,36730,2cc996356c438e45a876a6cb51a332d070044c1e,13,3,3,970,,,0,"Add aggregate commands

* Add aggregate: add host, create, delete, list, remove host, set, show

* Add list --long option
* Filter 'availability_zone' from the metadata fields
* Rename 'metadata' column to 'properties' in all output

Bug: 1172032
Blueprint: nova-client

Change-Id: Icd408c2b34af07f5102f53d3778d8546952a12c5
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/30/36730/3 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'openstackclient/compute/v2/aggregate.py']",2,2362f0db634629d71510267cee0dc334af42bb96,bug/1172032,"# Copyright 2013 Nebula Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # """"""Aggregate action implementations"""""" import logging import six from cliff import command from cliff import lister from cliff import show from openstackclient.common import parseractions from openstackclient.common import utils class AddAggregateHost(show.ShowOne): """"""Add host to aggregate"""""" log = logging.getLogger(__name__ + '.AddAggregateHost') def get_parser(self, prog_name): parser = super(AddAggregateHost, self).get_parser(prog_name) parser.add_argument( 'aggregate', metavar='<aggregate>', help='Name or ID of aggregate', ) parser.add_argument( 'host', metavar='<host>', help='Host to add to aggregate', ) return parser def take_action(self, parsed_args): self.log.debug(""take_action(%s)"" % parsed_args) compute_client = self.app.client_manager.compute aggregate = utils.find_resource( compute_client.aggregates, parsed_args.aggregate, ) data = compute_client.aggregates.add_host(aggregate, parsed_args.host) info = {} info.update(data._info) return zip(*sorted(six.iteritems(info))) class CreateAggregate(show.ShowOne): """"""Create a new aggregate"""""" log = logging.getLogger(__name__ + "".CreateAggregate"") def get_parser(self, prog_name): parser = super(CreateAggregate, self).get_parser(prog_name) parser.add_argument( ""name"", metavar=""<name>"", help=""New aggregate name"", ) parser.add_argument( ""--zone"", metavar=""<availability-zone>"", help=""Availability zone name"", ) parser.add_argument( ""--property"", metavar=""<key=value>"", action=parseractions.KeyValueAction, help='Property to add to this aggregate ' '(repeat option to set multiple properties)', ) return parser def take_action(self, parsed_args): self.log.debug(""take_action(%s)"" % parsed_args) compute_client = self.app.client_manager.compute info = {} data = compute_client.aggregates.create( parsed_args.name, parsed_args.zone, ) info.update(data._info) if parsed_args.property: info.update(compute_client.aggregates.set_metadata( data, parsed_args.property, )._info) return zip(*sorted(six.iteritems(info))) class DeleteAggregate(command.Command): """"""Delete an existing aggregate"""""" log = logging.getLogger(__name__ + '.DeleteAggregate') def get_parser(self, prog_name): parser = super(DeleteAggregate, self).get_parser(prog_name) parser.add_argument( 'aggregate', metavar='<aggregate>', help='Name or ID of aggregate to delete', ) return parser def take_action(self, parsed_args): self.log.debug('take_action(%s)' % parsed_args) compute_client = self.app.client_manager.compute data = utils.find_resource( compute_client.aggregates, parsed_args.aggregate, ) compute_client.aggregates.delete(data.id) return class ListAggregate(lister.Lister): """"""List all aggregates"""""" log = logging.getLogger(__name__ + "".ListAggregate"") def take_action(self, parsed_args): self.log.debug(""take_action(%s)"" % parsed_args) compute_client = self.app.client_manager.compute columns = ( ""ID"", ""Name"", ""Availability Zone"", ) data = compute_client.aggregates.list() return (columns, (utils.get_item_properties( s, columns, ) for s in data)) class RemoveAggregateHost(show.ShowOne): """"""Remove host from aggregate"""""" log = logging.getLogger(__name__ + '.RemoveAggregateHost') def get_parser(self, prog_name): parser = super(RemoveAggregateHost, self).get_parser(prog_name) parser.add_argument( 'aggregate', metavar='<aggregate>', help='Name or ID of aggregate', ) parser.add_argument( 'host', metavar='<host>', help='Host to remove from aggregate', ) return parser def take_action(self, parsed_args): self.log.debug(""take_action(%s)"" % parsed_args) compute_client = self.app.client_manager.compute aggregate = utils.find_resource( compute_client.aggregates, parsed_args.aggregate, ) data = compute_client.aggregates.remove_host( aggregate, parsed_args.host, ) info = {} info.update(data._info) return zip(*sorted(six.iteritems(info))) class SetAggregate(show.ShowOne): """"""Set aggregate properties"""""" log = logging.getLogger(__name__ + '.SetAggregate') def get_parser(self, prog_name): parser = super(SetAggregate, self).get_parser(prog_name) parser.add_argument( 'aggregate', metavar='<aggregate>', help='Name or ID of aggregate to display', ) parser.add_argument( '--name', metavar='<new-name>', help='New aggregate name', ) parser.add_argument( ""--zone"", metavar=""<availability-zone>"", help=""Availability zone name"", ) parser.add_argument( ""--property"", metavar=""<key=value>"", action=parseractions.KeyValueAction, help='Property to add/change for this aggregate ' '(repeat option to set multiple properties)', ) return parser def take_action(self, parsed_args): self.log.debug('take_action(%s)' % parsed_args) compute_client = self.app.client_manager.compute aggregate = utils.find_resource( compute_client.aggregates, parsed_args.aggregate, ) info = {} kwargs = {} if parsed_args.name: kwargs['name'] = parsed_args.name if parsed_args.zone: kwargs['availability_zone'] = parsed_args.zone if kwargs: info.update(compute_client.aggregates.update( aggregate, kwargs )._info) if parsed_args.property: info.update(compute_client.aggregates.set_metadata( aggregate, parsed_args.property, )._info) if info: return zip(*sorted(six.iteritems(info))) else: return ({}, {}) class ShowAggregate(show.ShowOne): """"""Show a specific aggregate"""""" log = logging.getLogger(__name__ + '.ShowAggregate') def get_parser(self, prog_name): parser = super(ShowAggregate, self).get_parser(prog_name) parser.add_argument( 'aggregate', metavar='<aggregate>', help='Name or ID of aggregate to display', ) return parser def take_action(self, parsed_args): self.log.debug('take_action(%s)' % parsed_args) compute_client = self.app.client_manager.compute data = utils.find_resource( compute_client.aggregates, parsed_args.aggregate, ) info = {} info.update(data._info) return zip(*sorted(six.iteritems(info))) ",,293,0
openstack%2Fpuppet-keystone~master~I23fe552808d8a959b0dff1c86989cf2aaa04582a,openstack/puppet-keystone,master,I23fe552808d8a959b0dff1c86989cf2aaa04582a,Select keystone endpoint url bases on SSL setting,MERGED,2013-07-17 07:44:37.000000000,2013-07-19 20:36:25.000000000,2013-07-19 20:36:25.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2265}, {'_account_id': 6967}, {'_account_id': 7360}]","[{'number': 1, 'created': '2013-07-17 07:44:37.000000000', 'files': ['lib/puppet/provider/keystone.rb', 'spec/unit/provider/keystone_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a927b2e162f6f805fe08e84b1ad303185f91d108', 'message': ""Select keystone endpoint url bases on SSL setting\n\nWhen keystone is ssl enabled, (by setting ssl/enabled = TRUE in\nkeystone.conf) the keystone auth server is using HTTPS instead of HTTP\nas the protocol. This patch generates the correct endpoint for the\nkeystone service calls.\n\nIn addition, if there is a defined 'admin_endpoint' in keystone.conf,\nthis setting will take precedence.\n\nChange-Id: I23fe552808d8a959b0dff1c86989cf2aaa04582a\n""}]",0,37415,a927b2e162f6f805fe08e84b1ad303185f91d108,10,5,1,7466,,,0,"Select keystone endpoint url bases on SSL setting

When keystone is ssl enabled, (by setting ssl/enabled = TRUE in
keystone.conf) the keystone auth server is using HTTPS instead of HTTP
as the protocol. This patch generates the correct endpoint for the
keystone service calls.

In addition, if there is a defined 'admin_endpoint' in keystone.conf,
this setting will take precedence.

Change-Id: I23fe552808d8a959b0dff1c86989cf2aaa04582a
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/15/37415/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/keystone.rb', 'spec/unit/provider/keystone_spec.rb']",2,a927b2e162f6f805fe08e84b1ad303185f91d108,ssl_endpoint," it 'should use https if ssl is enabled' do mock = {'DEFAULT' => {'bind_host' => '192.168.56.210', 'admin_port' => '35357' }, 'ssl' => {'enable' => 'True'}} Puppet::Util::IniConfig::File.expects(:new).returns(mock) mock.expects(:read).with('/etc/keystone/keystone.conf') klass.get_admin_endpoint.should == 'https://192.168.56.210:35357/v2.0/' end it 'should use http if ssl is disabled' do mock = {'DEFAULT' => {'bind_host' => '192.168.56.210', 'admin_port' => '35357' }, 'ssl' => {'enable' => 'False'}} Puppet::Util::IniConfig::File.expects(:new).returns(mock) mock.expects(:read).with('/etc/keystone/keystone.conf') klass.get_admin_endpoint.should == 'http://192.168.56.210:35357/v2.0/' end it 'should use the defined admin_endpoint if available' do mock = {'DEFAULT' => {'admin_endpoint' => 'https://keystone.example.com/v2.0/' }, 'ssl' => {'enable' => 'False'}} Puppet::Util::IniConfig::File.expects(:new).returns(mock) mock.expects(:read).with('/etc/keystone/keystone.conf') klass.get_admin_endpoint.should == 'https://keystone.example.com/v2.0/' end ",,27,1
openstack%2Fpuppet-swift~master~Ib3db483dfbad97f23ab7ba2068632856b5e00f11,openstack/puppet-swift,master,Ib3db483dfbad97f23ab7ba2068632856b5e00f11,Add configurable log for storage server,MERGED,2013-06-25 07:14:16.000000000,2013-07-19 20:36:23.000000000,2013-07-19 20:36:23.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 2166}, {'_account_id': 2265}, {'_account_id': 6967}, {'_account_id': 8049}]","[{'number': 1, 'created': '2013-06-25 07:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/2cd704820711674563cc5dadae307b9c6f1f69c3', 'message': 'Add configurable log for storage server\n\nThis patch add configurable log for swift account/container/object\nserver service.\nPartially implements blueprint puppet-swift-log-support.\n\nChange-Id: Ib3db483dfbad97f23ab7ba2068632856b5e00f11\n'}, {'number': 4, 'created': '2013-07-05 03:02:17.000000000', 'files': ['templates/object-server.conf.erb', 'spec/defines/swift_storage_server_spec.rb', 'templates/container-server.conf.erb', 'templates/account-server.conf.erb', 'manifests/storage/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/6a0e505ee957fa25a124b07f62d44069deb8ae10', 'message': 'Add configurable log for storage server\n\nThis patch add configurable log for swift account/container/object\nserver service.\nPartially implements blueprint puppet-swift-log-support.\n\nChange-Id: Ib3db483dfbad97f23ab7ba2068632856b5e00f11\n'}, {'number': 2, 'created': '2013-07-05 03:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/a0f5512a6abe975931aaf01a7690becfa6f0a211', 'message': 'Add configurable log for storage server\n\nThis patch add configurable log for swift account/container/object\nserver service.\nPartially implements blueprint puppet-swift-log-support.\n\nChange-Id: Ib3db483dfbad97f23ab7ba2068632856b5e00f11\n'}, {'number': 3, 'created': '2013-07-05 03:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/7b0ce5418e619bdacf93a45fe268cfe5b9f80823', 'message': 'Add configurable log for storage server\n\nThis patch add configurable log for swift account/container/object\nserver service.\nPartially implements blueprint puppet-swift-log-support.\n\nChange-Id: Ib3db483dfbad97f23ab7ba2068632856b5e00f11\n'}]",4,34319,6a0e505ee957fa25a124b07f62d44069deb8ae10,18,6,4,1607,,,0,"Add configurable log for storage server

This patch add configurable log for swift account/container/object
server service.
Partially implements blueprint puppet-swift-log-support.

Change-Id: Ib3db483dfbad97f23ab7ba2068632856b5e00f11
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/19/34319/4 && git format-patch -1 --stdout FETCH_HEAD,"['templates/object-server.conf.erb', 'spec/defines/swift_storage_server_spec.rb', 'templates/container-server.conf.erb', 'templates/account-server.conf.erb', 'manifests/storage/server.pp']",5,2cd704820711674563cc5dadae307b9c6f1f69c3,bp/puppet-swift-log-support," $log_level = ""INFO"", $log_address = ""/dev/log"",",,24,0
openstack%2Fnova~master~I8ca955f6eb11e4b955ece9ec0822cda000b38f20,openstack/nova,master,I8ca955f6eb11e4b955ece9ec0822cda000b38f20,"Ensure dates are dates, not strings",MERGED,2013-07-19 15:01:49.000000000,2013-07-19 20:32:11.000000000,2013-07-19 20:32:09.000000000,"[{'_account_id': 3}, {'_account_id': 475}, {'_account_id': 706}, {'_account_id': 2166}, {'_account_id': 2835}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-19 15:01:49.000000000', 'files': ['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fd308a2c7ad7d523ee58d1783f2e7e7e6ac1e0fc', 'message': 'Ensure dates are dates, not strings\n\nIn DB API we have a check which removes tzdata from dates, however\nin some cases these dates are strings rather than datetime objects.\nThis will detect and correct these instances.\n\nFixes bug 1203069\n\nChange-Id: I8ca955f6eb11e4b955ece9ec0822cda000b38f20\n'}]",0,37921,fd308a2c7ad7d523ee58d1783f2e7e7e6ac1e0fc,14,6,1,706,,,0,"Ensure dates are dates, not strings

In DB API we have a check which removes tzdata from dates, however
in some cases these dates are strings rather than datetime objects.
This will detect and correct these instances.

Fixes bug 1203069

Change-Id: I8ca955f6eb11e4b955ece9ec0822cda000b38f20
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/37921/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,fd308a2c7ad7d523ee58d1783f2e7e7e6ac1e0fc,bug/1203069," if isinstance(values[key], basestring): values[key] = timeutils.parse_strtime(values[key])",,16,0
openstack%2Fdevstack~master~Ifbe3d51b5c89f759a71e904960c5f6cc99c44a5f,openstack/devstack,master,Ifbe3d51b5c89f759a71e904960c5f6cc99c44a5f,Update neutron-vpn-agent path,MERGED,2013-07-16 01:37:45.000000000,2013-07-19 20:32:02.000000000,2013-07-19 20:32:01.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2031}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-16 01:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/b3a6cf128e8437510df8b9d4ce6891579997c6fe', 'message': 'Update neutron-vpn-agent path\n\nFix path as same as lbaas\n\nChange-Id: Ifbe3d51b5c89f759a71e904960c5f6cc99c44a5f\n'}, {'number': 2, 'created': '2013-07-16 18:58:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/cd4c88b21c0ad493f3321ae0540e857e6756f1d8', 'message': 'Update neutron-vpn-agent path\n\nFix path of vpn-agent as same as lbaas\n\nChange-Id: Ifbe3d51b5c89f759a71e904960c5f6cc99c44a5f\n'}, {'number': 3, 'created': '2013-07-16 21:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/64f57940a75632843310d784b723eef0d6a512f0', 'message': 'Update neutron-vpn-agent path\n\nFix path of vpn-agent as same as lbaas\n\nChange-Id: Ifbe3d51b5c89f759a71e904960c5f6cc99c44a5f\n'}, {'number': 4, 'created': '2013-07-17 14:52:40.000000000', 'files': ['lib/neutron', 'lib/neutron_plugins/services/vpn'], 'web_link': 'https://opendev.org/openstack/devstack/commit/584750f996bf0336d5c743634cbb0d2e02e78783', 'message': 'Update neutron-vpn-agent path\n\nFix path of vpn-agent as same as lbaas\n\n- If q-vpn service is enabled, this patch switches the l3-agent to\nvpn-agent\n\nChange-Id: Ifbe3d51b5c89f759a71e904960c5f6cc99c44a5f\n'}]",4,37153,584750f996bf0336d5c743634cbb0d2e02e78783,21,6,4,2031,,,0,"Update neutron-vpn-agent path

Fix path of vpn-agent as same as lbaas

- If q-vpn service is enabled, this patch switches the l3-agent to
vpn-agent

Change-Id: Ifbe3d51b5c89f759a71e904960c5f6cc99c44a5f
",git fetch https://review.opendev.org/openstack/devstack refs/changes/53/37153/4 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/services/vpn'],1,b3a6cf128e8437510df8b9d4ce6891579997c6fe,fixpath,"VPN_BINARY=""$NEUTRON_BIN_DIR/neutron-vpn-agent""","VPN_BINARY=""$NEUTRON_DIR/bin/neutron-vpn-agent""",1,1
openstack%2Fdevstack~master~Ic2f475a9baa6d71a43cd29a6ca777ac972e47b0a,openstack/devstack,master,Ic2f475a9baa6d71a43cd29a6ca777ac972e47b0a,Add mysql support for ceilometer storage backend in devstack,MERGED,2013-07-17 07:38:13.000000000,2013-07-19 20:31:43.000000000,2013-07-19 20:31:43.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5055}]","[{'number': 1, 'created': '2013-07-17 07:38:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ab31e5b01b842ed528f1ecdaa68bc99683429e35', 'message': 'Add mysql support for ceilometer storage backend in devstack\n\nCurrently, devstack only support mongodb as ceilometer storage backend,\nthis patch is to add mysql storage support for ceilometer.\nIf you want to use mysql as backend during developing, you can specify\nCEILOMETER_BACKEND=mysql in localrc file.\nIf you use mongodb, just ignore the parameter.\n\nChange-Id: Ic2f475a9baa6d71a43cd29a6ca777ac972e47b0a\nImplements: blueprint ceilometer-mysql-support\n'}, {'number': 2, 'created': '2013-07-18 01:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6c3ee9042909fc9b73186407db94c523903d955f', 'message': 'Add mysql support for ceilometer storage backend in devstack\n\nCurrently, devstack only support mongodb as ceilometer storage backend,\nthis patch is to add mysql storage support for ceilometer.\nIf you want to use mysql as backend during developing, you can specify\nCEILOMETER_BACKEND=mysql in localrc file.\nIf you use mongodb, just ignore the parameter.\n\nChange-Id: Ic2f475a9baa6d71a43cd29a6ca777ac972e47b0a\nImplements: blueprint ceilometer-mysql-support\n'}, {'number': 3, 'created': '2013-07-18 03:16:12.000000000', 'files': ['lib/ceilometer'], 'web_link': 'https://opendev.org/openstack/devstack/commit/9778b3cb68fc872df089d3272a548d75aad0d8a2', 'message': 'Add mysql support for ceilometer storage backend in devstack\n\nCurrently, devstack only support mongodb as ceilometer storage backend,\nthis patch is to add mysql storage support for ceilometer.\nIf you want to use mysql as backend during developing, you can specify\nCEILOMETER_BACKEND=mysql in localrc file.\nIf you use mongodb, just ignore the parameter.\n\nChange-Id: Ic2f475a9baa6d71a43cd29a6ca777ac972e47b0a\nImplements: blueprint ceilometer-mysql-support\n'}]",3,37413,9778b3cb68fc872df089d3272a548d75aad0d8a2,13,4,3,5055,,,0,"Add mysql support for ceilometer storage backend in devstack

Currently, devstack only support mongodb as ceilometer storage backend,
this patch is to add mysql storage support for ceilometer.
If you want to use mysql as backend during developing, you can specify
CEILOMETER_BACKEND=mysql in localrc file.
If you use mongodb, just ignore the parameter.

Change-Id: Ic2f475a9baa6d71a43cd29a6ca777ac972e47b0a
Implements: blueprint ceilometer-mysql-support
",git fetch https://review.opendev.org/openstack/devstack refs/changes/13/37413/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ceilometer'],1,ab31e5b01b842ed528f1ecdaa68bc99683429e35,bp/ceilometer-mysql-support,"CEILOMETER_BIN_DIR=$(get_python_exec_prefix) # Set up database backend CEILOMETER_BACKEND=${CEILOMETER_BACKEND:-mongodb} if [[ ""$CEILOMETER_BACKEND"" = 'mysql' ]]; then iniset $CEILOMETER_CONF database connection `database_connection_url ceilometer` else iniset $CEILOMETER_CONF database connection mongodb://localhost:27017/ceilometer configure_mongodb cleanup_ceilometer fi if [[ ""$CEILOMETER_BACKEND"" = 'mysql' ]]; then recreate_database ceilometer latin1 $CEILOMETER_BIN_DIR/ceilometer-dbsync fi #screen_it ceilometer-dbsync ""ceilometer-dbsync --config-file $CEILOMETER_CONF""",if [[ -d $CEILOMETER_DIR/bin ]]; then CEILOMETER_BIN_DIR=$CEILOMETER_DIR/bin else CEILOMETER_BIN_DIR=$(get_python_exec_prefix) fi iniset $CEILOMETER_CONF database connection mongodb://localhost:27017/ceilometer configure_mongodb cleanup_ceilometer,16,10
openstack%2Fdevstack~master~I7ce919cddfd6d6175ae67bd864f82e256ebc7090,openstack/devstack,master,I7ce919cddfd6d6175ae67bd864f82e256ebc7090,Use unique build dir for pip installs,MERGED,2013-07-16 04:39:29.000000000,2013-07-19 20:31:37.000000000,2013-07-19 20:31:37.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5803}, {'_account_id': 6473}, {'_account_id': 7118}]","[{'number': 1, 'created': '2013-07-16 04:39:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6044f8c97638198cb3a4391e62798a6bc15a6a3c', 'message': 'Use unique build dir for pip installs\n\nThere is a bug in pip [1] where it will choose to install a package\nfrom an existing build-dir if it exists over the version actually\nrequested.\n\nThus if a prior component has installed a later version of the\npackage, the unpacked code is already in /tmp/$USER-pip-build; it gets\nre-installed and manifests in a confusing error along the lines of\n\n---\n Downloading/unpacking requests>=1.1,<1.2.3\n   (from -r /home/stack//python-cinderclient/requirements.txt (line 5))\n   Running setup.py egg_info for package requests\n   Requested requests>=1.1,<1.2.3 (from -r\n   /home/stack/python-cinderclient/requirements.txt (line 5)),\n    but installing version 1.2.3\n...\n  error: Installed distribution requests 1.2.3 conflicts with\n    requirement requests>=1.1,<1.2.3\n---\n\nI believe pip 1.4 fixes this problem, but it should always be safe to\nspecify a unique build-directory for pip installs to avoid picking up\nold versions.\n\n[1] https://github.com/pypa/pip/issues/709\n\nChange-Id: I7ce919cddfd6d6175ae67bd864f82e256ebc7090\n'}, {'number': 2, 'created': '2013-07-16 06:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/23aa01207cbe9d06c842b88daa3ff0093a815074', 'message': 'Use unique build dir for pip installs\n\nThere is a bug in pip [1] where it will choose to install a package\nfrom an existing build-dir if it exists over the version actually\nrequested.\n\nThus if a prior component has installed a later version of the\npackage, the unpacked code is already in /tmp/$USER-pip-build; it gets\nre-installed and manifests in a confusing error along the lines of\n\n---\n Downloading/unpacking requests>=1.1,<1.2.3\n   (from -r /home/stack//python-cinderclient/requirements.txt (line 5))\n   Running setup.py egg_info for package requests\n   Requested requests>=1.1,<1.2.3 (from -r\n   /home/stack/python-cinderclient/requirements.txt (line 5)),\n    but installing version 1.2.3\n...\n  error: Installed distribution requests 1.2.3 conflicts with\n    requirement requests>=1.1,<1.2.3\n---\n\nI believe pip 1.4 fixes this problem, but it should always be safe to\nspecify a unique build-directory for pip installs to avoid picking up\nold versions.\n\n[1] https://github.com/pypa/pip/issues/709\n\nChange-Id: I7ce919cddfd6d6175ae67bd864f82e256ebc7090\n'}, {'number': 3, 'created': '2013-07-17 06:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/96f5abdf31f3fed48dd4e26fd35b4f477d5dbdd6', 'message': 'Use unique build dir for pip installs\n\nThere is a bug in pip [1] where it will choose to install a package\nfrom an existing build-dir if it exists over the version actually\nrequested.\n\nThus if a prior component has installed a later version of the\npackage, the unpacked code is already in /tmp/$USER-pip-build; it gets\nre-installed and manifests in a confusing error along the lines of\n\n---\n Downloading/unpacking requests>=1.1,<1.2.3\n   (from -r /home/stack//python-cinderclient/requirements.txt (line 5))\n   Running setup.py egg_info for package requests\n   Requested requests>=1.1,<1.2.3 (from -r\n   /home/stack/python-cinderclient/requirements.txt (line 5)),\n    but installing version 1.2.3\n...\n  error: Installed distribution requests 1.2.3 conflicts with\n    requirement requests>=1.1,<1.2.3\n---\n\nI believe pip 1.4 fixes this problem, but it should always be safe to\nspecify a unique build-directory for pip installs to avoid picking up\nold versions.\n\n[1] https://github.com/pypa/pip/issues/709\n\nChange-Id: I7ce919cddfd6d6175ae67bd864f82e256ebc7090\n'}, {'number': 4, 'created': '2013-07-17 10:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/5ffcb8c9782f039c51e19dd7feed834816b087c6', 'message': 'Use unique build dir for pip installs\n\nThere is a bug in pip [1] where it will choose to install a package\nfrom an existing build-dir if it exists over the version actually\nrequested.\n\nThus if a prior component has installed a later version of the\npackage, the unpacked code is already in /tmp/$USER-pip-build; it gets\nre-installed and manifests in a confusing error along the lines of\n\n---\n Downloading/unpacking requests>=1.1,<1.2.3\n   (from -r /home/stack//python-cinderclient/requirements.txt (line 5))\n   Running setup.py egg_info for package requests\n   Requested requests>=1.1,<1.2.3 (from -r\n   /home/stack/python-cinderclient/requirements.txt (line 5)),\n    but installing version 1.2.3\n...\n  error: Installed distribution requests 1.2.3 conflicts with\n    requirement requests>=1.1,<1.2.3\n---\n\nI believe pip 1.4 fixes this problem, but it should always be safe to\nspecify a unique build-directory for pip installs to avoid picking up\nold versions.\n\n[1] https://github.com/pypa/pip/issues/709\n\nChange-Id: I7ce919cddfd6d6175ae67bd864f82e256ebc7090\n'}, {'number': 5, 'created': '2013-07-18 12:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/08a890465fd6c2f65a4306ebe8b84f7ca4e7bd51', 'message': 'Use unique build dir for pip installs\n\nThere is a bug in pip [1] where it will choose to install a package\nfrom an existing build-dir if it exists over the version actually\nrequested.\n\nThus if a prior component has installed a later version of the\npackage, the unpacked code is already in /tmp/$USER-pip-build; it gets\nre-installed and manifests in a confusing error along the lines of\n\n---\n Downloading/unpacking requests>=1.1,<1.2.3\n   (from -r /home/stack//python-cinderclient/requirements.txt (line 5))\n   Running setup.py egg_info for package requests\n   Requested requests>=1.1,<1.2.3 (from -r\n   /home/stack/python-cinderclient/requirements.txt (line 5)),\n    but installing version 1.2.3\n...\n  error: Installed distribution requests 1.2.3 conflicts with\n    requirement requests>=1.1,<1.2.3\n---\n\nI believe pip 1.4 fixes this problem, but it should always be safe to\nspecify a unique build-directory for pip installs to avoid picking up\nold versions.\n\nWe also add a cleanup_tmp function for clearing out anything that\nstack.sh might leave around when un-stacking, and add a catch-all for\nthe pip-build dir.\n\n[1] https://github.com/pypa/pip/issues/709\n\nChange-Id: I7ce919cddfd6d6175ae67bd864f82e256ebc7090\n'}, {'number': 6, 'created': '2013-07-18 23:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/294161e3fee91017e2c671e75ea90ed4fbae556d', 'message': 'Use unique build dir for pip installs\n\nThere is a bug in pip [1] where it will choose to install a package\nfrom an existing build-dir if it exists over the version actually\nrequested.\n\nThus if a prior component has installed a later version of the\npackage, the unpacked code is already in /tmp/$USER-pip-build; it gets\nre-installed and manifests in a confusing error along the lines of\n\n---\n Downloading/unpacking requests>=1.1,<1.2.3\n   (from -r /home/stack//python-cinderclient/requirements.txt (line 5))\n   Running setup.py egg_info for package requests\n   Requested requests>=1.1,<1.2.3 (from -r\n   /home/stack/python-cinderclient/requirements.txt (line 5)),\n    but installing version 1.2.3\n...\n  error: Installed distribution requests 1.2.3 conflicts with\n    requirement requests>=1.1,<1.2.3\n---\n\nI believe pip 1.4 fixes this problem, but it should always be safe to\nspecify a unique build-directory for pip installs to avoid picking up\nold versions.\n\nWe also add a cleanup_tmp function for clearing out anything that\nstack.sh might leave around when un-stacking, and add a catch-all for\nthe pip-build dir.\n\n[1] https://github.com/pypa/pip/issues/709\n\nChange-Id: I7ce919cddfd6d6175ae67bd864f82e256ebc7090\n'}, {'number': 7, 'created': '2013-07-19 00:45:25.000000000', 'files': ['functions', 'unstack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/31dcd3e7ab60855d9664bd0aeb87b79eba94913f', 'message': 'Use unique build dir for pip installs\n\nThere is a bug in pip [1] where it will choose to install a package\nfrom an existing build-dir if it exists over the version actually\nrequested.\n\nThus if a prior component has installed a later version of the\npackage, the unpacked code is already in /tmp/$USER-pip-build; it gets\nre-installed and manifests in a confusing error along the lines of\n\n---\n Downloading/unpacking requests>=1.1,<1.2.3\n   (from -r /home/stack//python-cinderclient/requirements.txt (line 5))\n   Running setup.py egg_info for package requests\n   Requested requests>=1.1,<1.2.3 (from -r\n   /home/stack/python-cinderclient/requirements.txt (line 5)),\n    but installing version 1.2.3\n...\n  error: Installed distribution requests 1.2.3 conflicts with\n    requirement requests>=1.1,<1.2.3\n---\n\nI believe pip 1.4 fixes this problem, but it should always be safe to\nspecify a unique build-directory for pip installs to avoid picking up\nold versions.\n\nWe also add a cleanup_tmp function for clearing out anything that\nstack.sh might leave around when un-stacking, and add a catch-all for\nthe pip-build dir.\n\n[1] https://github.com/pypa/pip/issues/709\n\nChange-Id: I7ce919cddfd6d6175ae67bd864f82e256ebc7090\n'}]",3,37171,31dcd3e7ab60855d9664bd0aeb87b79eba94913f,38,6,7,7118,,,0,"Use unique build dir for pip installs

There is a bug in pip [1] where it will choose to install a package
from an existing build-dir if it exists over the version actually
requested.

Thus if a prior component has installed a later version of the
package, the unpacked code is already in /tmp/$USER-pip-build; it gets
re-installed and manifests in a confusing error along the lines of

---
 Downloading/unpacking requests>=1.1,<1.2.3
   (from -r /home/stack//python-cinderclient/requirements.txt (line 5))
   Running setup.py egg_info for package requests
   Requested requests>=1.1,<1.2.3 (from -r
   /home/stack/python-cinderclient/requirements.txt (line 5)),
    but installing version 1.2.3
...
  error: Installed distribution requests 1.2.3 conflicts with
    requirement requests>=1.1,<1.2.3
---

I believe pip 1.4 fixes this problem, but it should always be safe to
specify a unique build-directory for pip installs to avoid picking up
old versions.

We also add a cleanup_tmp function for clearing out anything that
stack.sh might leave around when un-stacking, and add a catch-all for
the pip-build dir.

[1] https://github.com/pypa/pip/issues/709

Change-Id: I7ce919cddfd6d6175ae67bd864f82e256ebc7090
",git fetch https://review.opendev.org/openstack/devstack refs/changes/71/37171/3 && git format-patch -1 --stdout FETCH_HEAD,['functions'],1,6044f8c97638198cb3a4391e62798a6bc15a6a3c,uniq-pip-build-dir, $CMD_PIP install \ --build=$(mktemp --tmpdir -d pip-build.XXXXX) \ $PIP_MIRROR_OPT $@, $CMD_PIP install $PIP_MIRROR_OPT $@,3,1
openstack%2Fpython-openstackclient~master~I766d40e410e48f05e36e17e567a4f01a9411b40e,openstack/python-openstackclient,master,I766d40e410e48f05e36e17e567a4f01a9411b40e,Add quota commands,MERGED,2013-07-10 21:02:20.000000000,2013-07-19 20:20:17.000000000,2013-07-19 20:20:17.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2472}, {'_account_id': 6482}]","[{'number': 1, 'created': '2013-07-10 21:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/bdf1a18cbe099ad2276349af5a4ad1324a30a05c', 'message': 'Add quota commands\n\n* Add quota set and quota show commands; these work on both\n  the compute and volume APIs\n* Add the --class variation on the above commands\n\nNote: this replaces the existing volume-only quota commands and eliminates quota list\n\nBlueprint: cinder-client\nBug: 1172064\n\nChange-Id: I766d40e410e48f05e36e17e567a4f01a9411b40e\n'}, {'number': 2, 'created': '2013-07-17 20:13:04.000000000', 'files': ['setup.cfg', 'openstackclient/common/quota.py', 'openstackclient/volume/v1/quota.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/87104a28d75bd77df8b7ceb44600cd2b3971b4ae', 'message': 'Add quota commands\n\n* Add quota set and quota show commands; these work on both\n  the compute and volume APIs\n* Add the --class variation on the above commands\n\nNote: this replaces the existing volume-only quota commands and eliminates quota list\n\nBlueprint: cinder-client\nBug: 1172064\n\nChange-Id: I766d40e410e48f05e36e17e567a4f01a9411b40e\n'}]",18,36550,87104a28d75bd77df8b7ceb44600cd2b3971b4ae,11,4,2,970,,,0,"Add quota commands

* Add quota set and quota show commands; these work on both
  the compute and volume APIs
* Add the --class variation on the above commands

Note: this replaces the existing volume-only quota commands and eliminates quota list

Blueprint: cinder-client
Bug: 1172064

Change-Id: I766d40e410e48f05e36e17e567a4f01a9411b40e
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/50/36550/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/shell.py', 'setup.cfg', 'openstackclient/common/quota.py', 'openstackclient/volume/v1/quota.py']",4,bdf1a18cbe099ad2276349af5a4ad1324a30a05c,bug/1172064,,"# Copyright 2012-2013 OpenStack, LLC. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # """"""Volume v1 Quota action implementations"""""" import logging import sys from cliff import command from cliff import show from openstackclient.common import utils class ListQuota(show.ShowOne): """"""List quota command"""""" api = 'volume' log = logging.getLogger(__name__ + '.ListQuota') def get_parser(self, prog_name): parser = super(ListQuota, self).get_parser(prog_name) parser.add_argument( 'tenant', metavar='<tenant>', help='ID of tenant to list the default quotas for') return parser def take_action(self, parsed_args): self.log.debug('take_action(%s)' % parsed_args) volume_client = self.app.client_manager.volume defaults = volume_client.quotas.defaults(parsed_args.tenant) return zip(*sorted(defaults._info.iteritems())) class SetQuota(command.Command): """"""Set quota command"""""" api = 'volume' log = logging.getLogger(__name__ + '.SetQuota') def get_parser(self, prog_name): parser = super(SetQuota, self).get_parser(prog_name) parser.add_argument( 'tenant', metavar='<tenant>', help='ID of tenant to set the quotas for') parser.add_argument( '--volumes', metavar='<new-volumes>', type=int, help='New value for the volumes quota') parser.add_argument( '--gigabytes', metavar='<new-gigabytes>', type=int, help='New value for the gigabytes quota') return parser def take_action(self, parsed_args): self.log.debug('take_action(%s)' % parsed_args) kwargs = {} if parsed_args.volumes: kwargs['volumes'] = parsed_args.volumes if parsed_args.gigabytes: kwargs['gigabytes'] = parsed_args.gigabytes if kwargs == {}: sys.stdout.write(""Quota not updated, no arguments present"") return volume_client = self.app.client_manager.volume volume_client.quotas.update(parsed_args.tenant, parsed_args.volumes, parsed_args.gigabytes) return class ShowQuota(show.ShowOne): """"""Show quota command"""""" api = 'volume' log = logging.getLogger(__name__ + '.ShowQuota') def get_parser(self, prog_name): parser = super(ShowQuota, self).get_parser(prog_name) parser.add_argument( 'tenant', metavar='<tenant>', help='ID of tenant to list the quotas for') return parser def take_action(self, parsed_args): self.log.debug('take_action(%s)' % parsed_args) volume_client = self.app.client_manager.volume quota = utils.find_resource(volume_client.quotas, parsed_args.tenant) return zip(*sorted(quota._info.iteritems())) ",201,118
openstack%2Fpython-openstackclient~master~I032ffa25181aad0fb4689f69cdca5a7adc6e29f1,openstack/python-openstackclient,master,I032ffa25181aad0fb4689f69cdca5a7adc6e29f1,Add list and delete authorizations for oauth commands,MERGED,2013-07-16 19:54:10.000000000,2013-07-19 20:19:45.000000000,2013-07-19 20:19:45.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}]","[{'number': 1, 'created': '2013-07-16 19:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/5e30caa66808e67ed7ee5fd41ff36d24671a3351', 'message': 'Add list and delete authorizations for oauth commands\n\n* List user authorizations\n* Delete user authorization\n* Grouped the commands with oauth prefix\n\nChange-Id: I032ffa25181aad0fb4689f69cdca5a7adc6e29f1\n'}, {'number': 2, 'created': '2013-07-16 20:06:50.000000000', 'files': ['openstackclient/identity/v3/oauth.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6146213e327729a2a48a09de35087ca2be9786e5', 'message': 'Add list and delete authorizations for oauth commands\n\n* List user authorizations\n* Delete user authorization\n* Grouped the commands with oauth prefix\n\nChange-Id: I032ffa25181aad0fb4689f69cdca5a7adc6e29f1\n'}]",0,37315,6146213e327729a2a48a09de35087ca2be9786e5,9,3,2,6482,,,0,"Add list and delete authorizations for oauth commands

* List user authorizations
* Delete user authorization
* Grouped the commands with oauth prefix

Change-Id: I032ffa25181aad0fb4689f69cdca5a7adc6e29f1
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/15/37315/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/identity/v3/oauth.py', 'setup.cfg']",2,5e30caa66808e67ed7ee5fd41ff36d24671a3351,oauth_authz, oauth_access_token_authenticate = openstackclient.identity.v3.oauth:AuthenticateAccessToken oauth_access_token_create = openstackclient.identity.v3.oauth:CreateAccessToken oauth_request_token_authorize = openstackclient.identity.v3.oauth:AuthorizeRequestToken oauth_request_token_create = openstackclient.identity.v3.oauth:CreateRequestToken oauth_authorization_delete = openstackclient.identity.v3.oauth:DeleteUserAuthorization oauth_authorization_list = openstackclient.identity.v3.oauth:ListUserAuthorizations oauth_authorization_show = openstackclient.identity.v3.oauth:ShowAuthorizationPin , access_token_authenticate = openstackclient.identity.v3.oauth:AuthenticateAccessToken access_token_create = openstackclient.identity.v3.oauth:CreateAccessToken request_token_authorize = openstackclient.identity.v3.oauth:AuthorizeRequestToken request_token_create = openstackclient.identity.v3.oauth:CreateRequestToken ,95,7
openstack%2Fhacking~master~I18f8250374ee3b2132ed56be21c7e3eecb60771d,openstack/hacking,master,I18f8250374ee3b2132ed56be21c7e3eecb60771d,Add information about the Google style guide,MERGED,2013-07-14 19:46:07.000000000,2013-07-19 20:17:43.000000000,2013-07-19 20:17:43.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-14 19:46:07.000000000', 'files': ['README.rst', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/hacking/commit/d85cb884a9c76fdedbc346eafd46731475a8296b', 'message': 'Add information about the Google style guide\n\nMany of these checks came from the Google Style Guide, which has\nexcellent reasoning and background. Add links so that people can read\nmore about things that they may think are crazy.\n\nChange-Id: I18f8250374ee3b2132ed56be21c7e3eecb60771d\n'}]",2,36997,d85cb884a9c76fdedbc346eafd46731475a8296b,8,3,1,2,,,0,"Add information about the Google style guide

Many of these checks came from the Google Style Guide, which has
excellent reasoning and background. Add links so that people can read
more about things that they may think are crazy.

Change-Id: I18f8250374ee3b2132ed56be21c7e3eecb60771d
",git fetch https://review.opendev.org/openstack/hacking refs/changes/97/36997/1 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'HACKING.rst']",2,d85cb884a9c76fdedbc346eafd46731475a8296b,,OpenStack Style Guidelines ========================== Futher Reading -------------- http://google-styleguide.googlecode.com/svn/trunk/pyguide.html,OpenStack Style Commandments ============================,17,3
openstack%2Fopenstack-manuals~master~If33c53750c5f2a795fa9d9fa4ae045b426d14d41,openstack/openstack-manuals,master,If33c53750c5f2a795fa9d9fa4ae045b426d14d41,Use proper names instead of code names,MERGED,2013-07-19 15:40:55.000000000,2013-07-19 20:03:42.000000000,2013-07-19 20:03:42.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 964}, {'_account_id': 6772}, {'_account_id': 6850}]","[{'number': 1, 'created': '2013-07-19 15:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/31770b76ec381567eb26cd4bab86ee4f00c869cc', 'message': 'Use proper names instead of code names\n\nAs per:\nhttps://bugs.launchpad.net/openstack-manuals/+bug/1121866\n\nAlso fixes some minor typos\n\nChange-Id: If33c53750c5f2a795fa9d9fa4ae045b426d14d41\n'}, {'number': 2, 'created': '2013-07-19 15:43:32.000000000', 'files': ['doc/src/docbkx/basic-install/src/basic-install_controller-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-quantum.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-dashboard.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-cinder.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-quantum.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-glance.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-operating.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-hypervisor.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-keystone.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-services.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/973b38bdaf3f8e4faddbf9016ca0af139c094dc4', 'message': 'Use proper names instead of code names\n\nAs per:\nhttps://bugs.launchpad.net/openstack-manuals/+bug/1121866\n\nAlso fixes some minor typos\n\nChange-Id: If33c53750c5f2a795fa9d9fa4ae045b426d14d41\n'}]",0,37927,973b38bdaf3f8e4faddbf9016ca0af139c094dc4,10,5,2,6850,,,0,"Use proper names instead of code names

As per:
https://bugs.launchpad.net/openstack-manuals/+bug/1121866

Also fixes some minor typos

Change-Id: If33c53750c5f2a795fa9d9fa4ae045b426d14d41
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/27/37927/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/basic-install/src/basic-install_compute-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-quantum.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-cinder.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-dashboard.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-quantum.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-glance.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-operating.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-hypervisor.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-keystone.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-services.xml']",11,31770b76ec381567eb26cd4bab86ee4f00c869cc,typo-grammer, <title>OpenStack Networking</title> <para>Configure the OpenStack Networking services:</para>, <title>Quantum</title> <para>Configure the Quantum services:</para>,35,34
openstack%2Fpython-zaqarclient~master~Iaec9b5701ab61166daeabc45ec12c576c8723d9c,openstack/python-zaqarclient,master,Iaec9b5701ab61166daeabc45ec12c576c8723d9c,docs(README): add link to design wiki.,MERGED,2013-07-11 16:53:24.000000000,2013-07-19 20:02:18.000000000,2013-07-19 20:02:18.000000000,"[{'_account_id': 3}, {'_account_id': 1267}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6943}, {'_account_id': 7044}, {'_account_id': 7680}, {'_account_id': 8092}]","[{'number': 1, 'created': '2013-07-11 16:53:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/ed0a25d0f3944c51a3b1e4cadd73cd1a16a3a8e9', 'message': ""docs(usage): lay out a vision for client usage\n\nThis change introduces a single document, docs/usage.rst.\n\nThe rationale is to define how operating marconi-client might look\nlike. With a clear enough definition, the public interfaces should\nbe easy to implement.\n\nIt's a lightweight spec that's easy to update.\n\nChange-Id: Iaec9b5701ab61166daeabc45ec12c576c8723d9c\n""}, {'number': 2, 'created': '2013-07-11 22:14:26.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/29f7d446aa3b3f1ae2010878e0e2478ef3dcb3f4', 'message': 'docs(README): add link to design wiki.\n\nMakes it easier to access primary design document for client dev.\n\nChange-Id: Iaec9b5701ab61166daeabc45ec12c576c8723d9c\n'}]",14,36693,29f7d446aa3b3f1ae2010878e0e2478ef3dcb3f4,16,8,2,6944,,,0,"docs(README): add link to design wiki.

Makes it easier to access primary design document for client dev.

Change-Id: Iaec9b5701ab61166daeabc45ec12c576c8723d9c
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/93/36693/2 && git format-patch -1 --stdout FETCH_HEAD,['docs/usage-draft.rst'],1,ed0a25d0f3944c51a3b1e4cadd73cd1a16a3a8e9,usage,"Marconi Client (draft) ********************** This document exists to establish the feel of working with the python Marconi client. It serves as both a vision and a direction for implementors. Check out the `blueprints`_ for more details. If you have questions, reach us at freenode.irc.net #openstack-marconi! **Table of Contents** .. contents:: :local: :depth: 2 :backlinks: none Features ======== * Certificate verification * Reauthentication on token expiration * Async operations * Full coverage of Marconi API * Some validation is performed before requests are sent to Marconi Classes ======= :: Connection: authenticate, establish a connection with the API, make requests, handle headers Client: handles account-wide operations - queue retrieval, API health check, etc. Queue: one queue - gives access to some metadata ops, as well as message handling Message: one message - gives access to properties of message Claim: a collection of messages Error: the base class from which all client errors are defined API Synopsis ============ .. code-block:: http # Home document GET /v1 # Queue Management PUT /v1/queues/{name} # create, update metadata GET /v1/queues{?marker,limit,detailed} GET /v1/queues/{name} GET /v1/queues/{name}/stats DELETE /v1/queues/{name} # Message handling GET /v1/queues/{name}/messages{?marker,limit,echo} GET /v1/queues/{name}/messages/{msg_id}{?claim_id} GET /v1/queues/{name}/messages{?ids,claim_id} POST /v1/queues/{name}/messages DELETE /v1/queues/{name}/messages/{msg_id}{?claim_id} # Claims: claiming sets of messages POST /v1/queues/{name}/claims{?limit} GET /v1/queues/{queue_name}/claims/{claim_id} PATCH /v1/queues/{queue_name}/claims/{claim_id} # update a claim DELETE /v1/queues/{queue_name}/claims/{claim_id} # release a claim # Health checks GET /v1/health HEAD /v1/health Usage ===== Working With a Connection ------------------------- .. code-block:: pycon >>> from marconiclient.common.connection import Connection >>> conn = Connection('tacocat', apikey='my_awesome_key') >>> conn.tenant 123456 >>> conn.username u'tacocat' >>> conn.version u'1.0' >>> conn.token u'1234567654321234543hj2b34j54bj32' >>> conn.expires datetime.datetime(2013, 7, 10, 13, 29, 54, 702873) >>> conn.host u'https://marconi.example.com/v1.0' >>> conn.headers {u'x-auth-token': ..., u'host': ..., u'date': ..., u'accept': ..., u'accept-encoding': ..., u'content-length': ..., u'x-project-id': ...} # Client ID set at the Client level >>> conn.request(Http.GET, headers={u'x-client-id': 100}, data=json.dumps({'my': 'message'}), verify=True) <Response [200]> >>> conn <MarconiConnection user:tacocat expires:2013-07-11T03:28:33.834-05:00> Http.Get is a client-defined Python enumeration. See `flufl.enum`_ and `PEP 435`_ for more information on Python enumerations. Client Operation ---------------- .. code-block:: pycon >>> from marconiclient.core.client import Client >>> client = marconiclient.Client(conn, async=False) >>> client.queues(marker=..., limit=10, detailed=False) <generator object <genexpr> ar 0x7fd3ef1ed730> >>> client.create_queue(name='wot', metadata=json.dumps({'game': 'd2'})) <MarconiQueue [wot]> >>> client.create_queue(name='wot', metadata=json.dumps({'game': 'd2'})) DuplicateQueueError: queue with name 'wot' already exists >>> client.home <HomeDoc ...> # affects all operations for objects acquired from the client >>> client.async False >>> client.healthy # is Marconi alive? True Queue Handling -------------- .. code-block:: pycon >>> queue = next(q for q in client.queues if q.name == 'tacocat') >>> queue.name u'tacocat' >>> queue.stats <QueueStats ...> >>> queue.messages() <generator object <genexpr> ar 0x7fd3ef1ed742> >>> queue.messages(ids=[1024, 1025], claim=27, limit=1) <generator object <genexpr> ar 0x7fd3ef1ed742> >>> queue.post(messages=...) >>> queue.metadata {'a': 1, 'b': 2} >>> queue.set_metadata({'a': 2, ...}) >>> queue.claim(limit=10) <Claim ...> >>> queue.delete() Message Handling ---------------- .. code-block:: pycon >>> message = next(queue.messages(...)) >>> message.age 90 >>> message.ttl 120 >>> message.id u'9y22h21w2h' >>> message.body {u'action': u'win'} >>> message.delete() >>> message.status <EnumValue: Message.Free [value=1]> Claim Management ---------------- .. code-block:: pycon >>> claim = queue.claim(limit=10) # identical to queue message fetch API, with claim id pre-filled >>> claim.messages(...) <generator object <genexpr> ar 0x7fd3ef1ed742> >>> msg = next(claim.messages(...)) >>> msg.status <EnumValue: Message.Claimed [value=2]> >>> claim.id ... >>> claim.patch(ttl=..., grace=...) >>> claim.delete() Error Management ================ The wiki gives a thorough explanation of `Marconi Errors`_. Error handling at the client-level is a matter of transforming responses returned by Marconi into exceptions that are meaningful to users. Here's a quick mock up of error usage at the level of the client: .. code-block:: pycon >> error = marconi.error.ErrorBase() >>> error.title u'...' >>> error.description u'...' >>> error.code 1092 >>> raise error ErrorBase (error.code): error.title error.description .. _blueprints: https://blueprints.launchpad.net/python-marconiclient/ .. _PEP 435: http://www.python.org/dev/peps/pep-0435/ .. _flufl.enum: https://pypi.python.org/pypi/flufl.enum .. _Marconi Errors: https://wiki.openstack.org/wiki/Marconi/specs/api/v1#Errors ",,221,0
openstack%2Fzaqar~master~I8537a585eaf4a836fa080a4caf9c3560f37f693d,openstack/zaqar,master,I8537a585eaf4a836fa080a4caf9c3560f37f693d,Fix Message Tests,MERGED,2013-07-17 01:14:24.000000000,2013-07-19 20:02:15.000000000,2013-07-19 20:02:15.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 7044}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-17 01:14:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/8d262b8ed5884df9adc9d2bd0b2deafbe0d208bf', 'message': 'Fix Message Tests\n\nThis fixes the message tests, to use href for GETs & DELETEs of a\nsingle message. This patch also removes the test dependency on\n/usr/share/dict/words being present.\n\nChange-Id: I8537a585eaf4a836fa080a4caf9c3560f37f693d\n'}, {'number': 2, 'created': '2013-07-17 01:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/310917ba2c76c092deb8d2517df98028499849b9', 'message': 'Fix Message Tests\n\nThis fixes the message tests, to use href for GETs & DELETEs of a\nsingle message. This patch also removes the test dependency on\n/usr/share/dict/words being present.\n\nChange-Id: I8537a585eaf4a836fa080a4caf9c3560f37f693d\n'}, {'number': 3, 'created': '2013-07-17 01:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/22b691da9f86f41310612491ab37272ac9b0f59a', 'message': 'Fix Message Tests\n\nThis fixes the message tests, to use href for GETs & DELETEs of a\nsingle message. This patch also removes the test dependency on\n/usr/share/dict/words being present.\n\nChange-Id: I8537a585eaf4a836fa080a4caf9c3560f37f693d\n'}, {'number': 4, 'created': '2013-07-17 13:34:53.000000000', 'files': ['marconi/tests/system/messages/msgfnlib.py', 'marconi/tests/system/messages/test_messages.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/77c73a5a83efe6118591875c13697f1e9f2044fc', 'message': 'Fix Message Tests\n\nThis fixes the message tests, to use href for GETs & DELETEs of a\nsingle message. This patch also removes the test dependency on\n/usr/share/dict/words being present.\n\nChange-Id: I8537a585eaf4a836fa080a4caf9c3560f37f693d\n'}]",4,37368,77c73a5a83efe6118591875c13697f1e9f2044fc,14,5,4,6971,,,0,"Fix Message Tests

This fixes the message tests, to use href for GETs & DELETEs of a
single message. This patch also removes the test dependency on
/usr/share/dict/words being present.

Change-Id: I8537a585eaf4a836fa080a4caf9c3560f37f693d
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/68/37368/1 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/tests/system/messages/msgfnlib.py', 'marconi/tests/system/messages/test_messages.py']",2,8d262b8ed5884df9adc9d2bd0b2deafbe0d208bf,message_tests," result = http.post(url, self.header, doc) href = result.json()['resources'][0] url = self.cfg.base_server + href result_body = result.json()['body'] result_body = [result.json()[i]['body'] for i in range(len(result.json()))] result = http.get(url, self.header) result = http.get(url, self.header) result = http.get(url, self.header) href = result.json()['resources'][0] url = self.cfg.base_server + href result = http.post(url, self.header, doc)"," result = http.post(url, self.header, doc) location = result.headers['location'] url = self.cfg.base_server + location result_body = result.json()[0]['body'] result_body = [result.json()['messages'][i]['body'] for i in range(len(result.json()['messages']))] result = http.get(url, self.header) result = http.get(url, self.header) result = http.get(url, self.header) location = result.headers['location'] url = self.cfg.base_server + location result = http.post(url, self.header, doc) ",26,17
openstack%2Fzaqar~master~I664988f63264785683219932f65b18353ff46959,openstack/zaqar,master,I664988f63264785683219932f65b18353ff46959,chore: drop unused bulk message support on /queues,MERGED,2013-07-16 21:12:07.000000000,2013-07-19 20:00:42.000000000,2013-07-19 20:00:42.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6943}, {'_account_id': 6944}, {'_account_id': 7044}]","[{'number': 1, 'created': '2013-07-16 21:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/7446ca10d7bc5bf8b5423dd7150db1256035cfc3', 'message': 'chore: drop unused bulk message support on /queues\n\n4dfa19d continued.\n\nChange-Id: I664988f63264785683219932f65b18353ff46959\n'}, {'number': 2, 'created': '2013-07-16 22:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/acc0b207413e112781d157f89c91ef2bce842c29', 'message': 'chore: drop unused bulk message support on /queues\n\n4dfa19d continued.\n\nChange-Id: I664988f63264785683219932f65b18353ff46959\n'}, {'number': 3, 'created': '2013-07-18 14:24:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/9d661055945d3efb8cb2e2232aad477afc9b5a12', 'message': 'chore: drop unused bulk message support on /queues\n\n4dfa19d continued.\n\nChange-Id: I664988f63264785683219932f65b18353ff46959\n'}, {'number': 4, 'created': '2013-07-18 14:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/a305ea34d0f2407d8aaf346b0ad58c97895ce3f5', 'message': 'chore: drop unused bulk message support on /queues\n\n4dfa19d continued.\n\nChange-Id: I664988f63264785683219932f65b18353ff46959\n'}, {'number': 5, 'created': '2013-07-19 17:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/2a3e6b5f1b921c151f3259d9f3f1d9588ec614dd', 'message': 'chore: drop unused bulk message support on /queues\n\n4dfa19d continued.\n\nChange-Id: I664988f63264785683219932f65b18353ff46959\n'}, {'number': 6, 'created': '2013-07-19 19:49:36.000000000', 'files': ['marconi/transport/wsgi/queues.py', 'marconi/tests/transport/wsgi/test_messages.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/bab14bcc6a21fd4ac2a82d7a5e5305daa97945ec', 'message': 'chore: drop unused bulk message support on /queues\n\n4dfa19d continued.\n\nChange-Id: I664988f63264785683219932f65b18353ff46959\n'}]",4,37329,bab14bcc6a21fd4ac2a82d7a5e5305daa97945ec,26,6,6,6943,,,0,"chore: drop unused bulk message support on /queues

4dfa19d continued.

Change-Id: I664988f63264785683219932f65b18353ff46959
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/29/37329/6 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/transport/wsgi/queues.py', 'marconi/tests/transport/wsgi/test_messages.py']",2,7446ca10d7bc5bf8b5423dd7150db1256035cfc3,drop-queues-ids,," def test_bulk_delete(self): query_string = 'ids=1,2' self.simulate_delete(self.queue_path, self.project_id, query_string=query_string) # Bulk delete not supported, the filter is ignored unless # the request is a GET request. self.assertEquals(self.srmock.status, falcon.HTTP_204) ",1,16
openstack%2Fos-collect-config~master~I52093bdd8a4b939ae06cf483535ed5d5a0e273d4,openstack/os-collect-config,master,I52093bdd8a4b939ae06cf483535ed5d5a0e273d4,Use heat-cfntools path hint for cfn.metadata_url,MERGED,2013-07-19 19:57:23.000000000,2013-07-19 19:57:23.000000000,2013-07-19 19:57:23.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 6488}]","[{'number': 4, 'created': '2013-07-19 19:57:23.000000000', 'files': ['os_collect_config/tests/test_cfn.py', 'os_collect_config/cfn.py'], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/4cc2c41bbca86e23d6c9122274cad14eee910902', 'message': 'Use heat-cfntools path hint for cfn.metadata_url\n\nHeat passes this in via cloud-init to assist heat-cfntools in finding the\ncfn metadata server url. This will likely be the primary location used,\nand cfn.metadata_url will be an override.\n\nAlso doing some cleanup, removed unused cfn.EC2_METADATA_URL and\nreordered and regrouped imports.\n\nChange-Id: I52093bdd8a4b939ae06cf483535ed5d5a0e273d4\n'}, {'number': 1, 'created': '2013-07-19 19:57:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/54979284dbc30ce8cfdd2e7eca49bcf5ed8ace91', 'message': 'Use heat-cfntools path hint for cfn.metadata_url.\n\nHeat passes this in via cloud-init to assist heat-cfntools in finding the\ncfn metadata server url. This will likely be the primary location used,\nand cfn.metadata_url will be an override.\n\nAlso doing some cleanup, removed unused cfn.EC2_METADATA_URL and\nreordered and regrouped imports.\n\nChange-Id: I52093bdd8a4b939ae06cf483535ed5d5a0e273d4\n'}, {'number': 2, 'created': '2013-07-19 19:57:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/689dd9f7d834a61f27c03a7ceb1a81d1ad13ff25', 'message': 'Use heat-cfntools path hint for cfn.metadata_url\n\nHeat passes this in via cloud-init to assist heat-cfntools in finding the\ncfn metadata server url. This will likely be the primary location used,\nand cfn.metadata_url will be an override.\n\nAlso doing some cleanup, removed unused cfn.EC2_METADATA_URL and\nreordered and regrouped imports.\n\nChange-Id: I52093bdd8a4b939ae06cf483535ed5d5a0e273d4\n'}, {'number': 3, 'created': '2013-07-19 19:57:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/fbdbfe7817739e6a2f9b37ad88ff61942c0ccd90', 'message': 'Use heat-cfntools path hint for cfn.metadata_url\n\nHeat passes this in via cloud-init to assist heat-cfntools in finding the\ncfn metadata server url. This will likely be the primary location used,\nand cfn.metadata_url will be an override.\n\nAlso doing some cleanup, removed unused cfn.EC2_METADATA_URL and\nreordered and regrouped imports.\n\nChange-Id: I52093bdd8a4b939ae06cf483535ed5d5a0e273d4\n'}]",0,37709,4cc2c41bbca86e23d6c9122274cad14eee910902,15,3,4,6488,,,0,"Use heat-cfntools path hint for cfn.metadata_url

Heat passes this in via cloud-init to assist heat-cfntools in finding the
cfn metadata server url. This will likely be the primary location used,
and cfn.metadata_url will be an override.

Also doing some cleanup, removed unused cfn.EC2_METADATA_URL and
reordered and regrouped imports.

Change-Id: I52093bdd8a4b939ae06cf483535ed5d5a0e273d4
",git fetch https://review.opendev.org/openstack/os-collect-config refs/changes/09/37709/4 && git format-patch -1 --stdout FETCH_HEAD,"['os_collect_config/tests/test_cfn.py', 'os_collect_config/cfn.py']",2,4cc2c41bbca86e23d6c9122274cad14eee910902,OCC-BE-BETTER,"import os cfg.StrOpt('heat-metadata-hint', default='/var/lib/heat-cfntools/cfn-metadata-server', help='Local file to read for metadata url if not explicitly ' ' specified'), if (CONF.cfn.heat_metadata_hint and os.path.exists(CONF.cfn.heat_metadata_hint)): with open(CONF.cfn.heat_metadata_hint) as hint: CONF.cfn.metadata_url = hint.read().strip() else: logger.warn('No metadata_url configured.') raise exc.CfnMetadataNotConfigured",EC2_METADATA_URL = 'http://169.254.169.254/latest/meta-data' logger.warn('No metadata_url configured.') raise exc.CfnMetadataNotConfigured,40,10
openstack%2Fos-collect-config~master~Ibbcbfadffb978f9d8789e1fbc0c0819da06489d3,openstack/os-collect-config,master,Ibbcbfadffb978f9d8789e1fbc0c0819da06489d3,Fixes for hacking 0.6,MERGED,2013-07-19 19:57:22.000000000,2013-07-19 19:57:22.000000000,2013-07-19 19:57:22.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-19 19:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/22fc06a80aad24352537b044a74570633b9bcef0', 'message': 'Add missing Apache 2.0 license header to exc\n\nChange-Id: Ibbcbfadffb978f9d8789e1fbc0c0819da06489d3\n'}, {'number': 3, 'created': '2013-07-19 19:57:22.000000000', 'files': ['os_collect_config/collect.py', 'os_collect_config/exc.py'], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/737fff67c3ed8135329aeddd9b0e0dde186d0e57', 'message': 'Fixes for hacking 0.6\n\n- Add missing License Header to exc.\n- Use python 3 compatible print.\n\nChange-Id: Ibbcbfadffb978f9d8789e1fbc0c0819da06489d3\n'}, {'number': 2, 'created': '2013-07-19 19:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/b10a02044fd130f5543e51d0cdda683f63ece946', 'message': 'Add missing Apache 2.0 license header to exc\n\nChange-Id: Ibbcbfadffb978f9d8789e1fbc0c0819da06489d3\n'}]",0,37944,737fff67c3ed8135329aeddd9b0e0dde186d0e57,9,3,3,6488,,,0,"Fixes for hacking 0.6

- Add missing License Header to exc.
- Use python 3 compatible print.

Change-Id: Ibbcbfadffb978f9d8789e1fbc0c0819da06489d3
",git fetch https://review.opendev.org/openstack/os-collect-config refs/changes/44/37944/1 && git format-patch -1 --stdout FETCH_HEAD,['os_collect_config/exc.py'],1,22fc06a80aad24352537b044a74570633b9bcef0,OCC-BE-BETTER,"# Copyright (c) 2013 Hewlett-Packard Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. ",,16,0
openstack%2Fos-collect-config~master~Ic91f2201d504e9f8e0ada6d34a7d6d94785aec87,openstack/os-collect-config,master,Ic91f2201d504e9f8e0ada6d34a7d6d94785aec87,Run forever if a command is configured,MERGED,2013-07-19 19:57:22.000000000,2013-07-19 19:57:22.000000000,2013-07-19 19:57:22.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-19 19:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/d45c9b0d1a0c88f9bd41a7a65d7a10fb4b27c626', 'message': 'Run forever if a command is configured.\n\nThis makes os-collect-config stay resident and prepares it for a more\nevent based operation when the Heat API is ready for that via longpoll\nor callbacks or something else.\n\nChange-Id: Ic91f2201d504e9f8e0ada6d34a7d6d94785aec87\n'}, {'number': 2, 'created': '2013-07-19 19:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/bcd52cbfe2d9003e9de778c5e37ea3410dfd55bb', 'message': 'Run forever if a command is configured\n\nThis makes os-collect-config stay resident and prepares it for a more\nevent based operation when the Heat API is ready for that via longpoll\nor callbacks or something else.\n\nChange-Id: Ic91f2201d504e9f8e0ada6d34a7d6d94785aec87\n'}, {'number': 3, 'created': '2013-07-19 19:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/d2208940e84b15f06e9dc17154fa011d31ec39a5', 'message': 'Run forever if a command is configured\n\nThis makes os-collect-config stay resident and prepares it for a more\nevent based operation when the Heat API is ready for that via longpoll\nor callbacks or something else.\n\nChange-Id: Ic91f2201d504e9f8e0ada6d34a7d6d94785aec87\n'}, {'number': 4, 'created': '2013-07-19 19:57:22.000000000', 'files': ['os_collect_config/collect.py', 'os_collect_config/tests/test_collect.py'], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/3e2001e5ba023e8bfccee21bd4140e06e294b468', 'message': 'Run forever if a command is configured\n\nThis makes os-collect-config stay resident and prepares it for a more\nevent based operation when the Heat API is ready for that via longpoll\nor callbacks or something else.\n\nChange-Id: Ic91f2201d504e9f8e0ada6d34a7d6d94785aec87\n'}]",0,37618,3e2001e5ba023e8bfccee21bd4140e06e294b468,16,3,4,6488,,,0,"Run forever if a command is configured

This makes os-collect-config stay resident and prepares it for a more
event based operation when the Heat API is ready for that via longpoll
or callbacks or something else.

Change-Id: Ic91f2201d504e9f8e0ada6d34a7d6d94785aec87
",git fetch https://review.opendev.org/openstack/os-collect-config refs/changes/18/37618/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_collect_config/collect.py', 'os_collect_config/tests/test_collect.py']",2,d45c9b0d1a0c88f9bd41a7a65d7a10fb4b27c626,OCC-BE-BETTER," def setUp(self): super(TestCollect, self).setUp() self.useFixture(fixtures.FakeLogger()) # make sure we don't run forever! if '--one-time' not in fake_args: fake_args.append('--one-time') def test_main_sleep(self): class ExpectedException(Exception): pass def fake_sleep(sleep_time): self.assertEquals(10, sleep_time) raise ExpectedException self.useFixture(fixtures.MonkeyPatch('time.sleep', fake_sleep)) try: collect.__main__(['os-collect-config', 'heat_local', '-i', '10', '-c', 'true']) except ExpectedException: pass def test_main_no_sleep_with_no_command(self): def fake_sleep(sleep_time): raise Exception(cfg.CONF.command) self.useFixture(fixtures.MonkeyPatch('time.sleep', fake_sleep)) collect.__main__(['os-collect-config', 'heat_local', '--config-file', '/dev/null', '-i', '10']) ",,66,17
openstack%2Fdiskimage-builder~master~I76a48cf5bdfa8664f0a65d0238fa4da7d80305db,openstack/diskimage-builder,master,I76a48cf5bdfa8664f0a65d0238fa4da7d80305db,Support repo names with multiple '-'s,MERGED,2013-07-19 19:45:42.000000000,2013-07-19 19:45:42.000000000,2013-07-19 19:45:42.000000000,"[{'_account_id': 3}, {'_account_id': 6449}]","[{'number': 1, 'created': '2013-07-19 19:45:42.000000000', 'files': ['elements/source-repositories/extra-data.d/98-source-repositories'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/a4a0523f2b5cac587792f8d53dc7367e75952c08', 'message': ""Support repo names with multiple '-'s\n\nThe search and replace that converted dashes in REPONAME only converted\nthe first dash. They should all be converted.\n\nChange-Id: I76a48cf5bdfa8664f0a65d0238fa4da7d80305db\n""}]",0,37938,a4a0523f2b5cac587792f8d53dc7367e75952c08,5,2,1,1926,,,0,"Support repo names with multiple '-'s

The search and replace that converted dashes in REPONAME only converted
the first dash. They should all be converted.

Change-Id: I76a48cf5bdfa8664f0a65d0238fa4da7d80305db
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/38/37938/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/source-repositories/extra-data.d/98-source-repositories'],1,a4a0523f2b5cac587792f8d53dc7367e75952c08,multi-dash, local REPOTYPE_OVERRIDE=DIB_REPOTYPE_${REPONAME//-/_} local REPOLOCATION_OVERRIDE=DIB_REPOLOCATION_${REPONAME//-/_} local REPOREF_OVERRIDE=DIB_REPOREF_${REPONAME//-/_}, local REPOTYPE_OVERRIDE=DIB_REPOTYPE_${REPONAME/-/_} local REPOLOCATION_OVERRIDE=DIB_REPOLOCATION_${REPONAME/-/_} local REPOREF_OVERRIDE=DIB_REPOREF_${REPONAME/-/_},3,3
openstack%2Fzaqar~master~I43137ef4cff77ead9d5db931907952dc78a67157,openstack/zaqar,master,I43137ef4cff77ead9d5db931907952dc78a67157,Log all transport actions,MERGED,2013-07-16 10:12:02.000000000,2013-07-19 19:42:12.000000000,2013-07-19 19:42:12.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6943}, {'_account_id': 6944}, {'_account_id': 7044}]","[{'number': 1, 'created': '2013-07-16 10:12:02.000000000', 'files': ['marconi/transport/auth.py', 'marconi/transport/wsgi/queues.py', 'marconi/transport/wsgi/messages.py', 'marconi/transport/wsgi/claims.py', 'marconi/bootstrap.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/423af0931c5419ec176122421159f36bfd3a4691', 'message': 'Log all transport actions\n\nThis patch adds debug LOG calls to the transport layer.\n\nImplements blueprint production-logging\n\nChange-Id: I43137ef4cff77ead9d5db931907952dc78a67157\n'}]",0,37207,423af0931c5419ec176122421159f36bfd3a4691,12,6,1,6159,,,0,"Log all transport actions

This patch adds debug LOG calls to the transport layer.

Implements blueprint production-logging

Change-Id: I43137ef4cff77ead9d5db931907952dc78a67157
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/07/37207/1 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/transport/auth.py', 'marconi/transport/wsgi/queues.py', 'marconi/transport/wsgi/messages.py', 'marconi/transport/wsgi/claims.py', 'marconi/bootstrap.py']",5,423af0931c5419ec176122421159f36bfd3a4691,bp/production-logging, LOG.exception(exc) raise exceptions.InvalidDriver(exc) LOG.exception(exc) raise exceptions.InvalidDriver(exc), raise exceptions.InvalidDriver(exc) raise exceptions.InvalidDriver(exc),54,2
openstack%2Fdiskimage-builder~master~Ic37b702ac579bf766bb2204a988fa9468d308abf,openstack/diskimage-builder,master,Ic37b702ac579bf766bb2204a988fa9468d308abf,Set work-dir to cached repository,MERGED,2013-07-19 19:22:08.000000000,2013-07-19 19:22:08.000000000,2013-07-19 19:22:08.000000000,"[{'_account_id': 3}, {'_account_id': 6449}]","[{'number': 1, 'created': '2013-07-19 19:22:08.000000000', 'files': ['elements/source-repositories/extra-data.d/98-source-repositories'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/51216dbd2dbb36ca95e8a18b69300028b0314f4f', 'message': ""Set work-dir to cached repository\n\nsource-repositories does a git reset on the .git directory of cached\nrepositories. But doesn't specify the directory to reset. A working\ndirectory needs to be specified so that the $PWD isn't used.\n\nWithout this change $PWD is polluted with the contents of repositories\nbeing cached.\n\nChange-Id: Ic37b702ac579bf766bb2204a988fa9468d308abf\n""}]",0,37937,51216dbd2dbb36ca95e8a18b69300028b0314f4f,5,2,1,1926,,,0,"Set work-dir to cached repository

source-repositories does a git reset on the .git directory of cached
repositories. But doesn't specify the directory to reset. A working
directory needs to be specified so that the $PWD isn't used.

Without this change $PWD is polluted with the contents of repositories
being cached.

Change-Id: Ic37b702ac579bf766bb2204a988fa9468d308abf
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/37/37937/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/source-repositories/extra-data.d/98-source-repositories'],1,51216dbd2dbb36ca95e8a18b69300028b0314f4f,add-work-dir, git --git-dir=$CACHE_PATH/.git --work-tree=$CACHE_PATH reset --hard origin/master, git --git-dir=$CACHE_PATH/.git reset --hard origin/master,1,1
openstack%2Fdevstack-gate~master~I24144e32f9ba7b279aaec0d3fadcfdf3bc5ef77c,openstack/devstack-gate,master,I24144e32f9ba7b279aaec0d3fadcfdf3bc5ef77c,Grab testr logs even when testr fails.,MERGED,2013-07-18 21:03:34.000000000,2013-07-19 17:55:45.000000000,2013-07-19 17:55:45.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 5263}]","[{'number': 1, 'created': '2013-07-18 21:03:34.000000000', 'files': ['devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/7cb7093b2ef33cc593083e9dca72746975a0f01f', 'message': 'Grab testr logs even when testr fails.\n\n* devstack-vm-gate-wrap.sh:\nDo all testr log processing when we deal with the other logs. Do not\ndepend on other scripts/functions being called to do this. Downstream\nscripts may exit prematurely resulting in a loss of data.\n\n* devstack-vm-gate.sh:\nStop processing testr logs here.\n\nChange-Id: I24144e32f9ba7b279aaec0d3fadcfdf3bc5ef77c\n'}]",0,37776,7cb7093b2ef33cc593083e9dca72746975a0f01f,8,5,1,4146,,,0,"Grab testr logs even when testr fails.

* devstack-vm-gate-wrap.sh:
Do all testr log processing when we deal with the other logs. Do not
depend on other scripts/functions being called to do this. Downstream
scripts may exit prematurely resulting in a loss of data.

* devstack-vm-gate.sh:
Stop processing testr logs here.

Change-Id: I24144e32f9ba7b279aaec0d3fadcfdf3bc5ef77c
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/76/37776/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh']",2,7cb7093b2ef33cc593083e9dca72746975a0f01f,fix-testr-log-capturing, # Process testr artifacts. if [ -f $BASE/new/tempest/.testrepository/0 ]; then sudo cp $BASE/new/tempest/.testrepository/0 $WORKSPACE/subunit_log.txt sudo python /usr/local/jenkins/slave_scripts/subunit2html.py $WORKSPACE/subunit_log.txt $WORKSPACE/testr_results.html sudo gzip -9 $WORKSPACE/subunit_log.txt sudo gzip -9 $WORKSPACE/testr_results.html sudo chown jenkins:jenkins $WORKSPACE/subunit_log.txt.gz $WORKSPACE/testr_results.html.gz sudo chmod a+r $WORKSPACE/subunit_log.txt.gz $WORKSPACE/testr_results.html.gz, #Copy and compress testr_results. if [ -f $BASE/new/tempest/testr_results.html ]; then sudo cp $BASE/new/tempest/testr_results.html $NEWLOGTARGET/ sudo gzip -9 $NEWLOGTARGET/testr_results.html fi #Copy subunit log. if [ -f $BASE/new/tempest/subunit_log.txt ]; then sudo cp $BASE/new/tempest/subunit_log.txt $NEWLOGTARGET/,8,12
openstack%2Ftrove~master~I900ffd2c0b661fb7642fa06c08ee92892eb176f0,openstack/trove,master,I900ffd2c0b661fb7642fa06c08ee92892eb176f0,Added developer documentation for Trove,MERGED,2013-07-17 03:05:14.000000000,2013-07-19 17:43:35.000000000,2013-07-19 17:43:35.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 1375}, {'_account_id': 1925}, {'_account_id': 5293}, {'_account_id': 7092}]","[{'number': 1, 'created': '2013-07-17 03:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/93c0e4a2bdc037780e46adb0f0eadaf836bffac6', 'message': 'Added developer documentation for Trove\n\nAdded initial sphinx/docutils documentation for Trove. Also made\ncorresponding changes to build scripts so that OpenStack CI is able\nto build the Trove developer docs.\n\nFixes blueprint: trove-dev-docs\n\nChange-Id: I900ffd2c0b661fb7642fa06c08ee92892eb176f0\n'}, {'number': 2, 'created': '2013-07-17 03:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/39a1ed0396f0a223abfe76cb95c53a2e430d0056', 'message': 'Added developer documentation for Trove\n\nAdded initial sphinx/docutils documentation for Trove. Also made\ncorresponding changes to setup.cfg so that OpenStack CI is able\nto build the Trove developer docs.\n\nFixes blueprint: trove-dev-docs\n\nChange-Id: I900ffd2c0b661fb7642fa06c08ee92892eb176f0\n'}, {'number': 3, 'created': '2013-07-19 00:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/60fb11523aafefea5d0fffeaec71feb531c7349b', 'message': 'Added developer documentation for Trove\n\nAdded initial sphinx/docutils documentation for Trove. Also made\ncorresponding changes to setup.cfg so that OpenStack CI is able\nto build the Trove developer docs.\n\nFixes blueprint: trove-dev-docs\n\nChange-Id: I900ffd2c0b661fb7642fa06c08ee92892eb176f0\n'}, {'number': 4, 'created': '2013-07-19 00:21:08.000000000', 'files': ['doc/source/dev/install.rst', '.gitignore', 'test-requirements.txt', 'doc/source/_static/nature.css', 'doc/source/_static/tweaks.css', 'doc/source/_static/openstack_logo.png', 'doc/source/conf.py', 'doc/source/index.rst', 'doc/source/_static/default.css', 'doc/source/_theme/theme.conf', 'doc/source/_static/header_bg.jpg', 'doc/source/_static/pygments.css', 'doc/source/_theme/layout.html', 'doc/source/_static/header-line.gif', 'doc/source/_static/basic.css', 'doc/source/_static/jquery.tweet.js', 'setup.cfg', 'doc/source/dev/design.rst'], 'web_link': 'https://opendev.org/openstack/trove/commit/708f3230d009c63ad75b75a0ebe84804c8899793', 'message': 'Added developer documentation for Trove\n\nAdded initial sphinx/docutils documentation for Trove. Also made\ncorresponding changes to setup.cfg so that OpenStack CI is able\nto build the Trove developer docs.\n\nFixes blueprint: trove-dev-docs\n\nChange-Id: I900ffd2c0b661fb7642fa06c08ee92892eb176f0\n'}]",10,37379,708f3230d009c63ad75b75a0ebe84804c8899793,27,6,4,5293,,,0,"Added developer documentation for Trove

Added initial sphinx/docutils documentation for Trove. Also made
corresponding changes to setup.cfg so that OpenStack CI is able
to build the Trove developer docs.

Fixes blueprint: trove-dev-docs

Change-Id: I900ffd2c0b661fb7642fa06c08ee92892eb176f0
",git fetch https://review.opendev.org/openstack/trove refs/changes/79/37379/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/dev/install.rst', '.gitignore', 'test-requirements.txt', 'doc/source/_static/nature.css', 'doc/source/_static/tweaks.css', 'doc/source/_static/openstack_logo.png', 'doc/source/conf.py', 'doc/source/index.rst', 'doc/source/_static/default.css', 'doc/source/_theme/theme.conf', 'doc/source/_static/header_bg.jpg', 'doc/source/_static/pygments.css', 'doc/source/_theme/layout.html', 'doc/source/_static/header-line.gif', 'doc/source/_static/basic.css', 'doc/source/_static/jquery.tweet.js', 'setup.cfg', 'doc/source/dev/design.rst']",18,93c0e4a2bdc037780e46adb0f0eadaf836bffac6,bp/trove-dev-docs,".. _design: ============ Trove Design ============ High Level description ====================== Trove is designed to support a single-tenant database within a Nova instance. There will be no restrictions on how Nova is configured, since Trove interacts with other OpenStack components purely through the API. Trove-api ========= The trove-api service provides a RESTful API that supports JSON and XML to provision and manage Trove instances. * A REST-ful component * Entry point - Trove/bin/trove-api * Uses a WSGI launcher configured by Trove/etc/trove/api-paste.ini * Defines the pipeline of filters; tokenauth, ratelimit, etc. * Defines the app_factory for the troveapp as trove.common.api:app_factory * The API class (a wsgi Router) wires the REST paths to the appropriate Controllers * Implementation of the Controllers are under the relevant module (versions/instance/flavor/limits), in the service.py module * Controllers usually redirect implementation to a class in the models.py module * At this point, an api module of another component (TaskManager, GuestAgent, etc.) is used to send the request onwards through RabbitMQ Trove-taskmanager ================= The trove-taskmanager service does the heavy lifting as far as provisioning instances, managing the lifecycle of instances, and performing operations on the Database instance. * A service that listens on a RabbitMQ topic * Entry point - Trove/bin/trove-taskmanager * Runs as a RpcService configured by Trove/etc/trove/trove-taskmanager.conf.sample which defines trove.taskmanager.manager.Manager as the manager - basically this is the entry point for requests arriving through the queue * As described above, requests for this component are pushed to MQ from another component using the TaskManager's api module using _cast() or _call() (sync/a-sync) and putting the method's name as a parameter * Trove/openstack/common/rpc/dispatcher.py- RpcDispatcher.dispatch() invokes the proper method in the Manager by some equivalent to reflection * The Manager then redirect the handling to an object from the models.py module. It loads an object from the relevant class with the context and instance_id * Actual handling is usually done in the models.py module Trove-guestagent ================ The guestagent is a service that runs within the guest instance, responsible for managing and performing operations on the Database itself. The Guest Agent listens for RPC messages through the message bus and performs the requested operation. * Similar to TaskManager in the sense of running as a service that listens on a RabbitMQ topic * GuestAgent runs on every DB instance, and a dedicated MQ topic is used (identified as the instance's id) * Entry point - Trove/bin/trove-guestagent * Runs as a RpcService configured by Trove/etc/trove/trove-guestagent.conf.sample which defines trove.guestagent.manager.Manager as the manager - basically this is the entry point for requests arriving through the queue * As described above, requests for this component are pushed to MQ from another component using the GuestAgent's api module using _cast() or _call() (sync/a-sync) and putting the method's name as a parameter * Trove/openstack/common/rpc/dispatcher.py- RpcDispatcher.dispatch() invokes the proper method in the Manager by some equivalent to reflection * The Manager then redirect the handling to an object (usually) from the dbaas.py module. * Actual handling is usually done in the dbaas.py module .. Trove - Database as a Service: https://wiki.openstack.org/wiki/Trove ",,1885,0
openstack%2Fpython-keystoneclient~master~Ic8b466a57554018092c31c6d6b3ea62f181d7cef,openstack/python-keystoneclient,master,Ic8b466a57554018092c31c6d6b3ea62f181d7cef,Implement apiclient library,ABANDONED,2013-07-19 17:25:06.000000000,2013-07-19 17:26:46.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-07-19 17:25:06.000000000', 'files': ['tests/auth/__init__.py', 'tests/v3/test_projects.py', 'keystoneclient/v2_0/client.py', 'tests/v3/test_discover.py', 'keystoneclient/v3/client.py', 'keystoneclient/v3/domains.py', 'tests/auth/v2_0/__init__.py', 'keystoneclient/client.py', 'tests/v2_0/test_endpoints.py', 'keystoneclient/v2_0/users.py', 'keystoneclient/base.py', 'keystoneclient/generic/client.py', 'keystoneclient/openstack/common/apiclient/auth/__init__.py', 'openstack-common.conf', 'tests/auth/v3/__init__.py', 'keystoneclient/v2_0/tenants.py', 'tests/auth/v2_0/test_keystone.py', 'tests/fakes.py', 'keystoneclient/v2_0/services.py', 'tests/v3/test_client.py', 'tests/v3/test_groups.py', 'tests/v3/test_users.py', 'tests/v2_0/test_users.py', 'keystoneclient/v3/services.py', 'tests/v2_0/test_tenants.py', 'tests/v2_0/test_roles.py', 'keystoneclient/shell.py', 'keystoneclient/auth/access.py', 'tests/v2_0/test_auth.py', 'tests/v2_0/test_ec2.py', 'tests/v2_0/test_discovery.py', 'keystoneclient/auth/__init__.py', 'tests/utils.py', 'tests/test_http.py', 'keystoneclient/v3/groups.py', 'keystoneclient/openstack/common/gettextutils.py', 'keystoneclient/v2_0/shell.py', 'keystoneclient/v3/projects.py', 'keystoneclient/auth/nova.py', 'tests/v2_0/test_client.py', 'keystoneclient/openstack/common/apiclient/exceptions.py', 'keystoneclient/exceptions.py', 'tests/auth/v2_0/test_service_catalog.py', 'keystoneclient/v3/users.py', 'setup.cfg', 'tests/test_keyring.py', 'keystoneclient/openstack/common/apiclient/fake_client.py', 'tests/v3/test_roles.py', 'tests/auth/test_endpoint.py', 'keystoneclient/openstack/common/apiclient/auth/base.py', 'keystoneclient/v2_0/ec2.py', 'keystoneclient/v3/policies.py', 'keystoneclient/auth/keystone.py', 'keystoneclient/openstack/common/apiclient/client.py', 'keystoneclient/v3/roles.py', 'tests/auth/v2_0/test_access.py', 'tests/test_shell.py', 'keystoneclient/auth/service_catalog.py', 'keystoneclient/v2_0/tokens.py', 'tests/auth/v3/test_access.py', 'tests/v2_0/fakes.py', 'tests/test_https.py', 'tests/test_utils.py', 'keystoneclient/openstack/common/apiclient/base.py', 'keystoneclient/openstack/common/strutils.py', 'tests/v2_0/test_services.py', 'keystoneclient/contrib/bootstrap/shell.py', 'keystoneclient/v3/credentials.py', 'keystoneclient/auth/endpoint.py', 'tests/v3/utils.py', 'keystoneclient/openstack/common/importutils.py', 'tests/test_base.py', 'tests/auth/v3/test_service_catalog.py', 'tests/auth/test_nova.py', 'tests/v2_0/test_shell.py', 'tests/v2_0/test_tokens.py', 'keystoneclient/v3/endpoints.py', 'tests/auth/v3/test_keystone.py', 'keystoneclient/v2_0/endpoints.py', 'keystoneclient/v2_0/roles.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/d7aa3d40542f2519b663d693a1cda601c91a8915', 'message': 'Implement apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy.\n\nThis code partially comes from:\n* python-keystoneclient/keystoneclient/base.py;\n* python-keystoneclient/keystoneclient/access.py;\n* python-novaclient/novaclient/auth_plugin.py;\n* python-novaclient/novaclient/extension.py;\n* python-novaclient/tests/fakes.py.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: Ic8b466a57554018092c31c6d6b3ea62f181d7cef\n'}]",0,37943,d7aa3d40542f2519b663d693a1cda601c91a8915,2,1,1,1267,,,0,"Implement apiclient library

This library can be used in novaclient, keystoneclient,
glanceclient, and other client projects. The library
contains common code and uses python-requests for
HTTP communication.

Features:
* reissue authentication request for expired tokens;
* pluggable authentication;
* rich exceptions hierarchy.

This code partially comes from:
* python-keystoneclient/keystoneclient/base.py;
* python-keystoneclient/keystoneclient/access.py;
* python-novaclient/novaclient/auth_plugin.py;
* python-novaclient/novaclient/extension.py;
* python-novaclient/tests/fakes.py.

Partially implements: blueprint common-client-library

Change-Id: Ic8b466a57554018092c31c6d6b3ea62f181d7cef
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/43/37943/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/auth/__init__.py', 'tests/v3/test_projects.py', 'keystoneclient/v2_0/client.py', 'tests/v3/test_discover.py', 'keystoneclient/v3/client.py', 'keystoneclient/v3/domains.py', 'tests/auth/v2_0/__init__.py', 'keystoneclient/client.py', 'tests/v2_0/test_endpoints.py', 'keystoneclient/v2_0/users.py', 'keystoneclient/base.py', 'keystoneclient/generic/client.py', 'keystoneclient/openstack/common/apiclient/auth/__init__.py', 'openstack-common.conf', 'tests/auth/v3/__init__.py', 'keystoneclient/v2_0/tenants.py', 'tests/auth/v2_0/test_keystone.py', 'tests/fakes.py', 'keystoneclient/v2_0/services.py', 'tests/v3/test_client.py', 'tests/v3/test_groups.py', 'tests/v3/test_users.py', 'tests/v2_0/test_users.py', 'keystoneclient/v3/services.py', 'tests/v2_0/test_tenants.py', 'tests/v2_0/test_roles.py', 'keystoneclient/shell.py', 'keystoneclient/auth/access.py', 'tests/v2_0/test_auth.py', 'tests/v2_0/test_ec2.py', 'tests/v2_0/test_discovery.py', 'keystoneclient/auth/__init__.py', 'tests/utils.py', 'tests/test_http.py', 'keystoneclient/v3/groups.py', 'keystoneclient/openstack/common/gettextutils.py', 'keystoneclient/v2_0/shell.py', 'keystoneclient/v3/projects.py', 'keystoneclient/auth/nova.py', 'tests/v2_0/test_client.py', 'keystoneclient/openstack/common/apiclient/exceptions.py', 'keystoneclient/exceptions.py', 'tests/auth/v2_0/test_service_catalog.py', 'keystoneclient/v3/users.py', 'setup.cfg', 'tests/test_keyring.py', 'keystoneclient/openstack/common/apiclient/fake_client.py', 'tests/v3/test_roles.py', 'tests/auth/test_endpoint.py', 'keystoneclient/openstack/common/apiclient/auth/base.py', 'keystoneclient/v2_0/ec2.py', 'keystoneclient/v3/policies.py', 'keystoneclient/auth/keystone.py', 'keystoneclient/openstack/common/apiclient/client.py', 'keystoneclient/v3/roles.py', 'tests/auth/v2_0/test_access.py', 'tests/test_shell.py', 'keystoneclient/auth/service_catalog.py', 'keystoneclient/v2_0/tokens.py', 'tests/auth/v3/test_access.py', 'tests/v2_0/fakes.py', 'tests/test_https.py', 'tests/test_utils.py', 'keystoneclient/openstack/common/apiclient/base.py', 'keystoneclient/openstack/common/strutils.py', 'tests/v2_0/test_services.py', 'keystoneclient/contrib/bootstrap/shell.py', 'keystoneclient/v3/credentials.py', 'keystoneclient/auth/endpoint.py', 'tests/v3/utils.py', 'keystoneclient/openstack/common/importutils.py', 'tests/test_base.py', 'tests/auth/v3/test_service_catalog.py', 'tests/auth/test_nova.py', 'tests/v2_0/test_shell.py', 'tests/v2_0/test_tokens.py', 'keystoneclient/v3/endpoints.py', 'tests/auth/v3/test_keystone.py', 'keystoneclient/v2_0/endpoints.py', 'keystoneclient/v2_0/roles.py']",80,d7aa3d40542f2519b663d693a1cda601c91a8915,bp/common-client-library,"from keystoneclient.openstack.common.apiclient import base return self._post('/OS-KSADM/roles', params, ""role"") return self._put(route % params, None, ""role"") return self._put(route % (user_id, role_id), None, ""roles"")","from keystoneclient import base return self._create('/OS-KSADM/roles', params, ""role"") return self._update(route % params, None, ""role"") return self._update(route % (user_id, role_id), None, ""roles"")",2885,3018
openstack%2Fpuppet-keystone~master~Ifb0fa261f9f5921cf9fe5b309decceab608d4726,openstack/puppet-keystone,master,Ifb0fa261f9f5921cf9fe5b309decceab608d4726,Remove Unnecessary mysql::server Dependency,MERGED,2013-07-18 22:38:29.000000000,2013-07-19 17:17:02.000000000,2013-07-19 17:17:02.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2265}, {'_account_id': 6967}, {'_account_id': 7360}]","[{'number': 1, 'created': '2013-07-18 22:38:29.000000000', 'files': ['manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/21d91fde33735423f297151d57999381c7c65a0a', 'message': 'Remove Unnecessary mysql::server Dependency\n\nPreviously, the db::mysql class required mysql::server.  This is\nunnecessary since the mysql::db define requires the mysql::config\nclass for db creattion.  Additionally, this prevents users from\nusing a different class such as galera::server to manage\nthe database.\n\nChange-Id: Ifb0fa261f9f5921cf9fe5b309decceab608d4726\n'}]",0,37800,21d91fde33735423f297151d57999381c7c65a0a,10,5,1,6836,,,0,"Remove Unnecessary mysql::server Dependency

Previously, the db::mysql class required mysql::server.  This is
unnecessary since the mysql::db define requires the mysql::config
class for db creattion.  Additionally, this prevents users from
using a different class such as galera::server to manage
the database.

Change-Id: Ifb0fa261f9f5921cf9fe5b309decceab608d4726
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/00/37800/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/db/mysql.pp'],1,21d91fde33735423f297151d57999381c7c65a0a,mysql_galera,, Class['mysql::server'] -> Class['keystone::db::mysql'],0,1
openstack%2Fpuppet-neutron~master~Ief246d868bcee0f6d1eabd873ad90dac56aa1ee6,openstack/puppet-neutron,master,Ief246d868bcee0f6d1eabd873ad90dac56aa1ee6,Remove Unnecessary mysql::server Dependency,MERGED,2013-07-19 17:16:56.000000000,2013-07-19 17:16:56.000000000,2013-07-19 17:16:56.000000000,"[{'_account_id': 3}, {'_account_id': 2265}, {'_account_id': 6967}]","[{'number': 1, 'created': '2013-07-19 17:16:56.000000000', 'files': ['manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/79847489b7971d5c87b4fd12d4e63f4ffb6707ec', 'message': 'Remove Unnecessary mysql::server Dependency\n\nPreviously, the db::mysql class required mysql::server.  This is\nunnecessary since the mysql::db define requires the mysql::config\nclass for db creattion.  Additionally, this prevents users from\nusing a different class such as galera::server to manage\nthe database.\n\nChange-Id: Ief246d868bcee0f6d1eabd873ad90dac56aa1ee6\n'}]",0,37792,79847489b7971d5c87b4fd12d4e63f4ffb6707ec,8,3,1,6836,,,0,"Remove Unnecessary mysql::server Dependency

Previously, the db::mysql class required mysql::server.  This is
unnecessary since the mysql::db define requires the mysql::config
class for db creattion.  Additionally, this prevents users from
using a different class such as galera::server to manage
the database.

Change-Id: Ief246d868bcee0f6d1eabd873ad90dac56aa1ee6
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/92/37792/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/db/mysql.pp'],1,79847489b7971d5c87b4fd12d4e63f4ffb6707ec,mysql_galera,, Class['mysql::server'] -> Class['quantum::db::mysql'] ,0,2
openstack%2Fpuppet-glance~master~I8ee9303eef67657dd2898d910897748a0af5415b,openstack/puppet-glance,master,I8ee9303eef67657dd2898d910897748a0af5415b,Remove Unnecessary mysql::server Dependency,MERGED,2013-07-18 22:14:48.000000000,2013-07-19 17:16:30.000000000,2013-07-19 17:16:30.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2265}, {'_account_id': 6967}, {'_account_id': 7360}]","[{'number': 1, 'created': '2013-07-18 22:14:48.000000000', 'files': ['manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/1121d7dccdc9e01437732496e6d6b0c589774753', 'message': 'Remove Unnecessary mysql::server Dependency\n\nPreviously, the db::mysql class required mysql::server.  This is\nunnecessary since the mysql::db define requires the mysql::config\nclass for db creattion.  Additionally, this prevents users from\nusing a different class such as galera::server to manage\nthe database.\n\nChange-Id: I8ee9303eef67657dd2898d910897748a0af5415b\n'}]",0,37793,1121d7dccdc9e01437732496e6d6b0c589774753,10,5,1,6836,,,0,"Remove Unnecessary mysql::server Dependency

Previously, the db::mysql class required mysql::server.  This is
unnecessary since the mysql::db define requires the mysql::config
class for db creattion.  Additionally, this prevents users from
using a different class such as galera::server to manage
the database.

Change-Id: I8ee9303eef67657dd2898d910897748a0af5415b
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/93/37793/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/db/mysql.pp'],1,1121d7dccdc9e01437732496e6d6b0c589774753,mysql_galera,, Class['mysql::server'] -> Class['glance::db::mysql'],0,1
openstack%2Fpuppet-cinder~master~I9216891e6ec29a8429aad1bb73b7f4fe7f22b2c1,openstack/puppet-cinder,master,I9216891e6ec29a8429aad1bb73b7f4fe7f22b2c1,Remove Unnecessary mysql::server Dependency,MERGED,2013-07-18 22:12:53.000000000,2013-07-19 17:16:30.000000000,2013-07-19 17:16:30.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2265}, {'_account_id': 6967}, {'_account_id': 7360}]","[{'number': 1, 'created': '2013-07-18 22:12:53.000000000', 'files': ['manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/f6d11cb8a703bed2f4f94b692dae2d49b7f83b9a', 'message': 'Remove Unnecessary mysql::server Dependency\n\nPreviously, the db::mysql class required mysql::server.  This is\nunnecessary since the mysql::db define requires the mysql::config\nclass for db creattion.  Additionally, this prevents users from\nusing a different class such as galera::server to manage\nthe database.\n\nChange-Id: I9216891e6ec29a8429aad1bb73b7f4fe7f22b2c1\n'}]",0,37791,f6d11cb8a703bed2f4f94b692dae2d49b7f83b9a,12,5,1,6836,,,0,"Remove Unnecessary mysql::server Dependency

Previously, the db::mysql class required mysql::server.  This is
unnecessary since the mysql::db define requires the mysql::config
class for db creattion.  Additionally, this prevents users from
using a different class such as galera::server to manage
the database.

Change-Id: I9216891e6ec29a8429aad1bb73b7f4fe7f22b2c1
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/91/37791/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/db/mysql.pp'],1,f6d11cb8a703bed2f4f94b692dae2d49b7f83b9a,mysql_galera,, Class['mysql::server'] -> Class['cinder::db::mysql'],0,1
openstack%2Fmurano-deployment~master~Idb8842ef77b94061bc9ccde40a3f60865808a012,openstack/murano-deployment,master,Idb8842ef77b94061bc9ccde40a3f60865808a012,murano-git-install fixes and updates,MERGED,2013-07-19 16:54:28.000000000,2013-07-19 16:58:35.000000000,2013-07-19 16:58:35.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-19 16:54:28.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/ac7f20e903191f9936b22ae959798fb4cb191c97', 'message': 'murano-git-install fixes and updates\n\nChange-Id: Idb8842ef77b94061bc9ccde40a3f60865808a012\n'}]",0,37941,ac7f20e903191f9936b22ae959798fb4cb191c97,5,2,1,7562,,,0,"murano-git-install fixes and updates

Change-Id: Idb8842ef77b94061bc9ccde40a3f60865808a012
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/41/37941/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,ac7f20e903191f9936b22ae959798fb4cb191c97,devbox-script-fix, chmod +x $git_clone_dir/setup*.sh chmod +x $git_clone_dir/setup*.sh 'reinstall') fetch_murano_apps uninstall_murano_apps $murano_components install_murano_apps $murano_components configure_murano restart_murano ;;,,12,0
openstack%2Fzaqar~master~I5cb6194e48c66e40ec7aa9739eb37550d6bf3e2a,openstack/zaqar,master,I5cb6194e48c66e40ec7aa9739eb37550d6bf3e2a,chore: switch to py3 print function,MERGED,2013-07-19 14:31:15.000000000,2013-07-19 16:57:31.000000000,2013-07-19 16:57:31.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6943}, {'_account_id': 6944}, {'_account_id': 6971}, {'_account_id': 7680}, {'_account_id': 8092}]","[{'number': 1, 'created': '2013-07-19 14:31:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0528bfe50573bba3f8e82c656398134b25d6283d', 'message': 'chore: stop flake8 from warn about the py2 print\n\nChange-Id: I5cb6194e48c66e40ec7aa9739eb37550d6bf3e2a\n'}, {'number': 2, 'created': '2013-07-19 14:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0ab1a69a0897fcf7fc35b7d329e7dfe695a5d6a2', 'message': 'chore: stop flake8 from warn about the py2 print\n\nAlso fix other problems due to flake8 upgrades.\n\nChange-Id: I5cb6194e48c66e40ec7aa9739eb37550d6bf3e2a\n'}, {'number': 3, 'created': '2013-07-19 15:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/88e4c898879befec2c17f084f508f4280d81cd55', 'message': 'chore: switch to py3 print function\n\nAlso fix other problems due to flake8 upgrades.\n\nChange-Id: I5cb6194e48c66e40ec7aa9739eb37550d6bf3e2a\n'}, {'number': 4, 'created': '2013-07-19 15:10:51.000000000', 'files': ['marconi/tests/system/messages/msgfnlib.py', 'marconi/tests/system/common/functionlib.py', 'marconi/tests/system/claim/claimfnlib.py', 'marconi/common/cli.py', 'marconi/tests/storage/test_impl_mongodb.py', 'tools/install_venv_common.py', 'marconi/common/decorators.py', 'tools/install_venv.py', 'marconi/tests/system/queue/queuefnlib.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/dddea2747d561b9a583649690e90a365d8afa1ef', 'message': 'chore: switch to py3 print function\n\nAlso fix other problems due to flake8 upgrades.\n\nChange-Id: I5cb6194e48c66e40ec7aa9739eb37550d6bf3e2a\n'}]",0,37915,dddea2747d561b9a583649690e90a365d8afa1ef,17,8,4,6943,,,0,"chore: switch to py3 print function

Also fix other problems due to flake8 upgrades.

Change-Id: I5cb6194e48c66e40ec7aa9739eb37550d6bf3e2a
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/15/37915/3 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0528bfe50573bba3f8e82c656398134b25d6283d,shut-up-flake8,ignore = H233,,1,0
openstack%2Fcinder~master~I590571e52d1c64b6dba7d7e76cd71badd74e51d1,openstack/cinder,master,I590571e52d1c64b6dba7d7e76cd71badd74e51d1,"Clone_image should return dict of vol properties, clone status.",MERGED,2013-07-15 17:13:41.000000000,2013-07-19 16:57:23.000000000,2013-07-19 16:57:22.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2417}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 6094}]","[{'number': 1, 'created': '2013-07-15 17:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5c864f51ae52bac057163363804843ab77335e92', 'message': 'Clone_image should return dict of vol properties, clone status.\n\nThe method will work fine in case of drivers not dependent\non volume properties like provider_location. It will fail to\nrestart in case of nfs drivers and also leave volume created as\nresult of clone_image functionality created in the\nnfs share in dangling state after deletion as provider_location\nis None. This fix requires dict of volume properties, cloned status\nto be returned which facilitates passing back provider_location\nin case of nfs drivers and hence resolves the issue.\n\nbug 1200708\n\nChange-Id: I590571e52d1c64b6dba7d7e76cd71badd74e51d1\n'}, {'number': 2, 'created': '2013-07-15 17:18:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5947f2ac775d3ce14707d6a795134ef690f91e1e', 'message': 'Clone_image should return dict of vol properties, clone status.\n\nThe method will work fine in case of drivers not dependent\non volume properties like provider_location. It will fail to\nrestart in case of nfs drivers and also leave volume created as\nresult of clone_image functionality created in the\nnfs share in dangling state after deletion as provider_location\nis None. This fix requires dict of volume properties, cloned status\nto be returned which facilitates passing back provider_location\nin case of nfs drivers and hence resolves the issue.\n\nbug 1200708\n\nChange-Id: I590571e52d1c64b6dba7d7e76cd71badd74e51d1\n'}, {'number': 3, 'created': '2013-07-15 17:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/de1c119215308f5d10104e65e9bb0fb32f6494ce', 'message': 'Clone_image should return dict of vol properties, clone status.\n\nThe method will work fine in case of drivers not dependent\non volume properties like provider_location. It will fail to\nrestart in case of nfs drivers and also leave volume created as\nresult of clone_image functionality created in the\nnfs share in dangling state after deletion as provider_location\nis None. This fix requires dict of volume properties, cloned status\nto be returned which facilitates passing back provider_location\nin case of nfs drivers and hence resolves the issue.\n\nbug 1200708\n\nChange-Id: I590571e52d1c64b6dba7d7e76cd71badd74e51d1\n'}, {'number': 4, 'created': '2013-07-16 05:57:57.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/volume/manager.py', 'cinder/volume/driver.py', 'cinder/tests/test_rbd.py', 'cinder/volume/drivers/scality.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/632cdeca7923b7a06c3d7537b89a21d1790f230d', 'message': 'Clone_image should return dict of vol properties, clone status.\n\nThe method will work fine in case of drivers not dependent\non volume properties like provider_location. It will fail to\nrestart in case of nfs drivers and also leave volume created as\nresult of clone_image functionality created in the\nnfs share in dangling state after deletion as provider_location\nis None. This fix requires dict of volume properties, cloned status\nto be returned which facilitates passing back provider_location\nin case of nfs drivers and hence resolves the issue.\n\nbug 1200708\n\nChange-Id: I590571e52d1c64b6dba7d7e76cd71badd74e51d1\n'}]",2,37097,632cdeca7923b7a06c3d7537b89a21d1790f230d,16,6,4,6094,,,0,"Clone_image should return dict of vol properties, clone status.

The method will work fine in case of drivers not dependent
on volume properties like provider_location. It will fail to
restart in case of nfs drivers and also leave volume created as
result of clone_image functionality created in the
nfs share in dangling state after deletion as provider_location
is None. This fix requires dict of volume properties, cloned status
to be returned which facilitates passing back provider_location
in case of nfs drivers and hence resolves the issue.

bug 1200708

Change-Id: I590571e52d1c64b6dba7d7e76cd71badd74e51d1
",git fetch https://review.opendev.org/openstack/cinder refs/changes/97/37097/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/rbd.py', 'cinder/volume/manager.py', 'cinder/volume/driver.py', 'cinder/volume/drivers/scality.py', 'cinder/volume/drivers/lvm.py']",5,5c864f51ae52bac057163363804843ab77335e92,bug/1200708," return None, False", return False,11,6
openstack%2Fcinder~master~I7f5804aa94eac29d8c3cec0f8e9ae9339d4e0816,openstack/cinder,master,I7f5804aa94eac29d8c3cec0f8e9ae9339d4e0816,Make Storwize/SVC tests work without simulator.,MERGED,2013-07-18 09:47:59.000000000,2013-07-19 16:57:21.000000000,2013-07-19 16:57:21.000000000,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-07-18 09:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ab38a85361a40ce91acea0c231f089d6c608b911', 'message': 'Make Storwize/SVC tests work without simulator.\n\nMoved to using brick to get connector info and fixed a small bug to get\ntests working on real storage again. Also fixed up simulator to handle\nthe multihostmap case properly.\n\nChange-Id: I7f5804aa94eac29d8c3cec0f8e9ae9339d4e0816\n'}, {'number': 2, 'created': '2013-07-18 10:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/74830cddecfb5354ff8237a463bb1c93ca09d9ff', 'message': 'Make Storwize/SVC tests work without simulator.\n\nMoved to using brick to get connector info and fixed a small bug to get\ntests working on real storage again. Also fixed up simulator to handle\nthe multihostmap case properly.\n\nChange-Id: I7f5804aa94eac29d8c3cec0f8e9ae9339d4e0816\n'}, {'number': 3, 'created': '2013-07-18 14:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7121fdb6d2c8932d138a09016fa6444940bbf1cb', 'message': 'Make Storwize/SVC tests work without simulator.\n\nMoved to using brick to get connector info and fixed a small bug to get\ntests working on real storage again. Also fixed up simulator to handle\nthe multihostmap case properly.\n\nChange-Id: I7f5804aa94eac29d8c3cec0f8e9ae9339d4e0816\n'}, {'number': 4, 'created': '2013-07-18 15:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/844a84eafb00e296eed636add5fcb84308525c77', 'message': 'Make Storwize/SVC tests work without simulator.\n\nMoved to using brick to get connector info and fixed a small bug to get\ntests working on real storage again. Also fixed up simulator to handle\nthe multihostmap case properly.\n\nChange-Id: I7f5804aa94eac29d8c3cec0f8e9ae9339d4e0816\n'}, {'number': 5, 'created': '2013-07-19 13:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4da77dd288808b1fe817aa6e979bc9f9dfe93c2e', 'message': 'Make Storwize/SVC tests work without simulator.\n\nMoved to using brick to get connector info and fixed a small bug to get\ntests working on real storage again. Also fixed up simulator to handle\nthe multihostmap case properly.\n\nChange-Id: I7f5804aa94eac29d8c3cec0f8e9ae9339d4e0816\n'}, {'number': 6, 'created': '2013-07-19 14:33:05.000000000', 'files': ['cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/storwize_svc.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a4e7fa464ae1ccf7e1e780baf3abca1fb10de9fc', 'message': 'Make Storwize/SVC tests work without simulator.\n\nMoved to using brick to get connector info and fixed a small bug to get\ntests working on real storage again. Also fixed up simulator to handle\nthe multihostmap case properly.\n\nChange-Id: I7f5804aa94eac29d8c3cec0f8e9ae9339d4e0816\n'}]",4,37653,a4e7fa464ae1ccf7e1e780baf3abca1fb10de9fc,32,8,6,4355,,,0,"Make Storwize/SVC tests work without simulator.

Moved to using brick to get connector info and fixed a small bug to get
tests working on real storage again. Also fixed up simulator to handle
the multihostmap case properly.

Change-Id: I7f5804aa94eac29d8c3cec0f8e9ae9339d4e0816
",git fetch https://review.opendev.org/openstack/cinder refs/changes/53/37653/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/storwize_svc.py']",2,ab38a85361a40ce91acea0c231f089d6c608b911,svc-test-nosim, elif status == 'stopping' or status == 'preparing':, elif status == 'stopping':,69,67
openstack%2Fnova~master~Ib05538095086ddefdb486c84da506af662ec5c9b,openstack/nova,master,Ib05538095086ddefdb486c84da506af662ec5c9b,Remove locals() from various places.,MERGED,2013-07-16 17:46:11.000000000,2013-07-19 16:57:04.000000000,2013-07-19 16:57:01.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 5046}, {'_account_id': 6072}, {'_account_id': 6172}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-07-16 17:46:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c94537efb19180e4b147d5cecc8b40ca74c86e7', 'message': 'Remove locals() from various places.\n\nfixes bug 1171936\n\nRemove usage of locals() for string formatting\n\nChange-Id: Ib05538095086ddefdb486c84da506af662ec5c9b\n'}, {'number': 2, 'created': '2013-07-16 17:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5520450dc00cec3d6ffec439cb77de2f4ace8be7', 'message': 'Remove locals() from various places.\n\nfixes bug 1171936\n\nRemove usage of locals() for string formatting\n\nChange-Id: Ib05538095086ddefdb486c84da506af662ec5c9b\n'}, {'number': 3, 'created': '2013-07-17 04:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c99c8ade756cac4caa4bf732c10554eb01a53c61', 'message': 'Remove locals() from various places.\n\nfixes bug 1171936\n\nRemove usage of locals() for string formatting\n\nChange-Id: Ib05538095086ddefdb486c84da506af662ec5c9b\n'}, {'number': 4, 'created': '2013-07-17 05:36:46.000000000', 'files': ['nova/objects/base.py', 'nova/storage/linuxscsi.py', 'nova/image/glance.py', 'nova/network/manager.py', 'nova/api/openstack/compute/plugins/v3/quota_sets.py', 'nova/network/linux_net.py', 'nova/version.py', 'nova/cmd/baremetal_deploy_helper.py', 'nova/scheduler/filters/ram_filter.py', 'nova/servicegroup/drivers/mc.py', 'nova/db/sqlalchemy/api.py', 'nova/network/neutronv2/api.py', 'nova/scheduler/filters/core_filter.py', 'nova/utils.py', 'nova/servicegroup/drivers/db.py', 'nova/cells/weights/mute_child.py', 'nova/consoleauth/manager.py', 'nova/cmd/manage.py', 'nova/api/openstack/compute/contrib/quotas.py', 'nova/network/floating_ips.py', 'nova/hooks.py', 'nova/conductor/manager.py', 'nova/quota.py', 'nova/servicegroup/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/20eac6c1df2a0a78d4e29e96607b35930304ca76', 'message': 'Remove locals() from various places.\n\nfixes bug 1171936\n\nRemove usage of locals() for string formatting\n\nChange-Id: Ib05538095086ddefdb486c84da506af662ec5c9b\n'}]",47,37296,20eac6c1df2a0a78d4e29e96607b35930304ca76,25,9,4,6072,,,0,"Remove locals() from various places.

fixes bug 1171936

Remove usage of locals() for string formatting

Change-Id: Ib05538095086ddefdb486c84da506af662ec5c9b
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/37296/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/base.py', 'nova/storage/linuxscsi.py', 'nova/openstack/common/periodic_task.py', 'nova/image/glance.py', 'nova/network/manager.py', 'nova/api/openstack/compute/plugins/v3/quota_sets.py', 'nova/network/linux_net.py', 'nova/openstack/common/notifier/rpc_notifier.py', 'nova/version.py', 'nova/cmd/baremetal_deploy_helper.py', 'nova/scheduler/filters/ram_filter.py', 'nova/servicegroup/drivers/mc.py', 'nova/db/sqlalchemy/api.py', 'nova/network/neutronv2/api.py', 'nova/scheduler/filters/core_filter.py', 'nova/utils.py', 'nova/openstack/common/notifier/rpc_notifier2.py', 'nova/servicegroup/drivers/db.py', 'nova/openstack/common/policy.py', 'nova/cells/weights/mute_child.py', 'nova/consoleauth/manager.py', 'nova/cmd/manage.py', 'nova/api/openstack/compute/contrib/quotas.py', 'nova/network/floating_ips.py', 'nova/hooks.py', 'nova/conductor/manager.py', 'nova/quota.py', 'nova/servicegroup/api.py']",28,4c94537efb19180e4b147d5cecc8b40ca74c86e7,bug/1171936," LOG.debug(msg, {'member_id': member_id, 'group_id': group_id, 'service': service}) LOG.debug(msg, {'member_id': member_id, 'group_id': group_id})"," LOG.debug(msg, locals()) LOG.debug(msg, locals())",88,71
openstack%2Fnova~master~I764e1fc3b9ff20b6eda8f6ec00849f2164de0a49,openstack/nova,master,I764e1fc3b9ff20b6eda8f6ec00849f2164de0a49,Send updated aggregate to compute on add/rm host,MERGED,2013-07-18 10:58:15.000000000,2013-07-19 16:56:43.000000000,2013-07-19 16:56:41.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 6735}]","[{'number': 1, 'created': '2013-07-18 10:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66bae145c39883a3d85e5a3d916db374ef430c4f', 'message': 'Send updated aggregate to compute on add/remove\n\nThe XenAPI driver relies on getting an up-to-date version of the\naggregate during add and remove. This change ensures that happens.\n\nFixes bug 1161619\n\nChange-Id: I764e1fc3b9ff20b6eda8f6ec00849f2164de0a49\n'}, {'number': 2, 'created': '2013-07-18 11:01:29.000000000', 'files': ['nova/tests/compute/test_compute.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/75329ada9859c8d9a5c6d453beb5a16d97023492', 'message': 'Send updated aggregate to compute on add/rm host\n\nThe XenAPI driver relies on getting an up-to-date version of the\naggregate during add_host_to_aggregate and remove_host_from_aggregate\nThis change ensures that happens.\n\nFixes bug 1161619\nChange-Id: I764e1fc3b9ff20b6eda8f6ec00849f2164de0a49\n'}]",0,37660,75329ada9859c8d9a5c6d453beb5a16d97023492,13,6,2,782,,,0,"Send updated aggregate to compute on add/rm host

The XenAPI driver relies on getting an up-to-date version of the
aggregate during add_host_to_aggregate and remove_host_from_aggregate
This change ensures that happens.

Fixes bug 1161619
Change-Id: I764e1fc3b9ff20b6eda8f6ec00849f2164de0a49
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/37660/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/api.py', 'nova/tests/compute/test_compute.py']",2,66bae145c39883a3d85e5a3d916db374ef430c4f,bug/1161619," def fake_add_aggregate_host(*args, **kwargs): hosts = kwargs[""aggregate""][""hosts""] self.assertTrue(fake_host in hosts) self.stubs.Set(self.api.compute_rpcapi, 'add_aggregate_host', fake_add_aggregate_host) host_to_remove = values[fake_zone][0] def fake_remove_aggregate_host(*args, **kwargs): hosts = kwargs[""aggregate""][""hosts""] self.assertFalse(host_to_remove in hosts) self.stubs.Set(self.api.compute_rpcapi, 'remove_aggregate_host', fake_remove_aggregate_host) host_to_remove)", values[fake_zone][0]),20,3
openstack%2Frequirements~master~Id4101fa4fd1c60a6ffef6bef3dcd03522e681231,openstack/requirements,master,Id4101fa4fd1c60a6ffef6bef3dcd03522e681231,Update pip depend to >= 1.0,MERGED,2013-07-15 00:35:56.000000000,2013-07-19 16:47:02.000000000,2013-07-19 16:47:02.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 5545}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-07-15 00:35:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/6a01795a40518256de6866b412d35450d0e4eca2', 'message': 'Update pip depend to >= 1.0\n\nPrecise ships with 1.0 by default. Until we force everyone on to\n1.4, there is no need to express a depend here which is not true.\n\nChange-Id: Id4101fa4fd1c60a6ffef6bef3dcd03522e681231\n'}, {'number': 2, 'created': '2013-07-15 16:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/62811580517d57a5c5165e11c566ce30f360e172', 'message': 'Update pip depend to >= 1.0\n\nPrecise ships with 1.0 by default. Until we force everyone on to\n1.4, there is no need to express a depend here which is not true.\n\nChange-Id: Id4101fa4fd1c60a6ffef6bef3dcd03522e681231\n'}, {'number': 3, 'created': '2013-07-18 15:43:41.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/936e89237e6dfcbb5fa5d2bb3771be8896a5faed', 'message': 'Update pip depend to >= 1.0\n\nPrecise ships with 1.0 by default. Until we force everyone on to\n1.4, there is no need to express a depend here which is not true.\n\nChange-Id: Id4101fa4fd1c60a6ffef6bef3dcd03522e681231\n'}]",1,37003,936e89237e6dfcbb5fa5d2bb3771be8896a5faed,16,7,3,2,,,0,"Update pip depend to >= 1.0

Precise ships with 1.0 by default. Until we force everyone on to
1.4, there is no need to express a depend here which is not true.

Change-Id: Id4101fa4fd1c60a6ffef6bef3dcd03522e681231
",git fetch https://review.opendev.org/openstack/requirements refs/changes/03/37003/3 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6a01795a40518256de6866b412d35450d0e4eca2,36771,pip>=1.0,pip>1.0,1,1
openstack%2Frequirements~master~I6eb5eb8a3d11dd009f94f02da32cf9580ac7333a,openstack/requirements,master,I6eb5eb8a3d11dd009f94f02da32cf9580ac7333a,Update capitalization on all of our requirements,MERGED,2013-07-12 03:32:35.000000000,2013-07-19 16:46:53.000000000,2013-07-19 16:46:52.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-07-12 03:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/c21bba458e5764c701aca62859831081f9926e6a', 'message': 'Update capitalization on all of our requirements\n\nAlthough pip does the right thing, there are various proxies and whatnot\nthat actually can get confused with the case-insensitivity.\n\nMoving forward, we should try to make sure we put things in the files\ncorrectly.\n\nChange-Id: I6eb5eb8a3d11dd009f94f02da32cf9580ac7333a\n'}, {'number': 2, 'created': '2013-07-16 21:36:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/3eafc3354d9f30d09913ce19aec198595cc936c6', 'message': 'Update capitalization on all of our requirements\n\nAlthough pip does the right thing, there are various proxies and whatnot\nthat actually can get confused with the case-insensitivity.\n\nMoving forward, we should try to make sure we put things in the files\ncorrectly.\n\nChange-Id: I6eb5eb8a3d11dd009f94f02da32cf9580ac7333a\n'}, {'number': 3, 'created': '2013-07-18 15:43:41.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/0305e5932f16b4eae2651116c9b6947a16018049', 'message': 'Update capitalization on all of our requirements\n\nAlthough pip does the right thing, there are various proxies and whatnot\nthat actually can get confused with the case-insensitivity.\n\nMoving forward, we should try to make sure we put things in the files\ncorrectly.\n\nChange-Id: I6eb5eb8a3d11dd009f94f02da32cf9580ac7333a\n'}]",1,36771,0305e5932f16b4eae2651116c9b6947a16018049,17,7,3,2,,,0,"Update capitalization on all of our requirements

Although pip does the right thing, there are various proxies and whatnot
that actually can get confused with the case-insensitivity.

Moving forward, we should try to make sure we put things in the files
correctly.

Change-Id: I6eb5eb8a3d11dd009f94f02da32cf9580ac7333a
",git fetch https://review.opendev.org/openstack/requirements refs/changes/71/36771/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,c21bba458e5764c701aca62859831081f9926e6a,36771,Ming>=0.3.4MySQL-pythonWebTest==1.3.3,ming>=0.3.4mysql-pythonwebtest==1.3.3,17,17
openstack%2Frequirements~master~I2189e008fc6ffa8f6787070e0ee78dcdcda5586b,openstack/requirements,master,I2189e008fc6ffa8f6787070e0ee78dcdcda5586b,Allow hacking 0.6.x,MERGED,2013-07-18 23:32:17.000000000,2013-07-19 16:43:37.000000000,2013-07-19 16:43:37.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 5263}]","[{'number': 1, 'created': '2013-07-18 23:32:17.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c568120b6b6daa858cd5ef333fcc54d1faef25b9', 'message': ""Allow hacking 0.6.x\n\nWe have just released hacking 0.6, this change will allow people to use\nit.  Hacking 0.6 introduces several new checks, but each project has a\nsimilar pinning so changing this won't break anything.\n\nChange-Id: I2189e008fc6ffa8f6787070e0ee78dcdcda5586b\n""}]",0,37809,c568120b6b6daa858cd5ef333fcc54d1faef25b9,7,4,1,1849,,,0,"Allow hacking 0.6.x

We have just released hacking 0.6, this change will allow people to use
it.  Hacking 0.6 introduces several new checks, but each project has a
similar pinning so changing this won't break anything.

Change-Id: I2189e008fc6ffa8f6787070e0ee78dcdcda5586b
",git fetch https://review.opendev.org/openstack/requirements refs/changes/09/37809/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,c568120b6b6daa858cd5ef333fcc54d1faef25b9,hacking0.6,"hacking>=0.5.6,<0.7","hacking>=0.5.6,<0.6",1,1
openstack%2Fmurano-deployment~master~I7b679229574a52ac1af1426f9173f71429be2477,openstack/murano-deployment,master,I7b679229574a52ac1af1426f9173f71429be2477,murano-git-install fixes.,MERGED,2013-07-19 16:42:42.000000000,2013-07-19 16:43:19.000000000,2013-07-19 16:43:19.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-19 16:42:42.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/a55439a5bf40373d72c488f448ab2dea8e8f48c1', 'message': 'murano-git-install fixes.\n\nChange-Id: I7b679229574a52ac1af1426f9173f71429be2477\n'}]",0,37936,a55439a5bf40373d72c488f448ab2dea8e8f48c1,5,2,1,7562,,,0,"murano-git-install fixes.

Change-Id: I7b679229574a52ac1af1426f9173f71429be2477
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/36/37936/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,a55439a5bf40373d72c488f448ab2dea8e8f48c1,devbox-script-fix," log ""\n'$app_name' is up-to-date."" log ""***** ***** ***** ***** *****"" log ""***** ***** ***** ***** *****"" done for app_name in $apps_list ; do git_clone_dir=""$git_clone_root/$app_name"" for app_name in $apps_list ; do git_clone_dir=""$git_clone_root/$app_name"" 'fetch') fetch_murano_apps ;; if [ -n ""$apps_list"" ] ; then uninstall_murano_apps $apps_list install_murano_apps $apps_list restart_murano fi", for $app_name in $apps_list ; do for $app_name in $apps_list ; do uninstall_murano_apps $apps_list install_murano_apps $apps_list restart_murano,20,5
openstack%2Frequirements~master~I0939c33cc4356a20b0bfb3adf83c82d5d7d8c3f1,openstack/requirements,master,I0939c33cc4356a20b0bfb3adf83c82d5d7d8c3f1,Upgrade testrepository version dependency,MERGED,2013-07-17 14:41:44.000000000,2013-07-19 16:42:08.000000000,2013-07-19 16:42:08.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1812}, {'_account_id': 4146}]","[{'number': 1, 'created': '2013-07-17 14:41:44.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c8f3e4b0689b51fdd81fc0f13c496bc12e2541e9', 'message': 'Upgrade testrepository version dependency\n\nThis version has full Python 3.3 support and will be used for the\nalready-working py33 targets coming into pbr and oslo.config.\n\nChange-Id: I0939c33cc4356a20b0bfb3adf83c82d5d7d8c3f1\n'}]",0,37486,c8f3e4b0689b51fdd81fc0f13c496bc12e2541e9,7,4,1,1669,,,0,"Upgrade testrepository version dependency

This version has full Python 3.3 support and will be used for the
already-working py33 targets coming into pbr and oslo.config.

Change-Id: I0939c33cc4356a20b0bfb3adf83c82d5d7d8c3f1
",git fetch https://review.opendev.org/openstack/requirements refs/changes/86/37486/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,c8f3e4b0689b51fdd81fc0f13c496bc12e2541e9,jd/update-testrepository,testrepository>=0.0.17,testrepository>=0.0.15,1,1
openstack%2Frequirements~master~I02ffcfe70e8f319f12a7cbcf21aa043fc32b02ad,openstack/requirements,master,I02ffcfe70e8f319f12a7cbcf21aa043fc32b02ad,Allow use of Hacking 0.6,ABANDONED,2013-07-19 15:37:59.000000000,2013-07-19 16:35:08.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-19 15:37:59.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/d752b9d9cdc615e27dad6fef4c6396cfe096f378', 'message': 'Allow use of Hacking 0.6\n\nHacking 0.6 delivers several new checks regarding Python 3.x\ncompatibility, so we want to enable it elsewhere as soon\nas possible.\n\nChange-Id: I02ffcfe70e8f319f12a7cbcf21aa043fc32b02ad\n'}]",0,37926,d752b9d9cdc615e27dad6fef4c6396cfe096f378,3,2,1,6593,,,0,"Allow use of Hacking 0.6

Hacking 0.6 delivers several new checks regarding Python 3.x
compatibility, so we want to enable it elsewhere as soon
as possible.

Change-Id: I02ffcfe70e8f319f12a7cbcf21aa043fc32b02ad
",git fetch https://review.opendev.org/openstack/requirements refs/changes/26/37926/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,d752b9d9cdc615e27dad6fef4c6396cfe096f378,hacking_06,"hacking>=0.5.6,<0.7","hacking>=0.5.6,<0.6",1,1
openstack%2Frequirements~master~I52ab1fa08031a86e72e056f52b12973587c14dc8,openstack/requirements,master,I52ab1fa08031a86e72e056f52b12973587c14dc8,Bump testrepository requirement,ABANDONED,2013-07-19 15:35:46.000000000,2013-07-19 16:33:47.000000000,,"[{'_account_id': 3}, {'_account_id': 1812}]","[{'number': 1, 'created': '2013-07-19 15:35:46.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/73f662c8bbec439626f55e93925cc3361861a0b3', 'message': 'Bump testrepository requirement\n\nFixes compatibility issues with Python 2.6 and Python 3.x\n\nChange-Id: I52ab1fa08031a86e72e056f52b12973587c14dc8\n'}]",0,37925,73f662c8bbec439626f55e93925cc3361861a0b3,3,2,1,6593,,,0,"Bump testrepository requirement

Fixes compatibility issues with Python 2.6 and Python 3.x

Change-Id: I52ab1fa08031a86e72e056f52b12973587c14dc8
",git fetch https://review.opendev.org/openstack/requirements refs/changes/25/37925/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,73f662c8bbec439626f55e93925cc3361861a0b3,testreposi,testrepository>=0.0.17,testrepository>=0.0.15,1,1
openstack%2Fmurano-deployment~master~I3963bc89cda88e4c64b8e33519e77ae524440cf0,openstack/murano-deployment,master,I3963bc89cda88e4c64b8e33519e77ae524440cf0,murano-git-install updated.,MERGED,2013-07-19 16:22:53.000000000,2013-07-19 16:30:55.000000000,2013-07-19 16:30:55.000000000,"[{'_account_id': 3}, {'_account_id': 7613}]","[{'number': 1, 'created': '2013-07-19 16:22:53.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/2f00a3ec5b002638c70eac1b6db38c81bc9563f6', 'message': 'murano-git-install updated.\n\nWorkflow divided into sections.\n\nChange-Id: I3963bc89cda88e4c64b8e33519e77ae524440cf0\n'}]",0,37932,2f00a3ec5b002638c70eac1b6db38c81bc9563f6,5,2,1,7562,,,0,"murano-git-install updated.

Workflow divided into sections.

Change-Id: I3963bc89cda88e4c64b8e33519e77ae524440cf0
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/32/37932/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,2f00a3ec5b002638c70eac1b6db38c81bc9563f6,devbox-script-update,"murano_config_files='/etc/murano-api/murano-api.conf /etc/murano-api/murano-api-paste.ini /etc/murano-conductor/conductor.conf /etc/murano-conductor/conductor-paste.ini' log ""** Creating lab-binding.rc file"" if [ ! -f '/etc/murano-deployment/lab-binding.rc' ] ; then mkdir '/etc/murano-deployment' cat << EOF > /etc/murano-deployment/lab-binding.rc LAB_HOST='' AUTH_URL=""http://$LAB_HOST:5000/v2.0"" ADMIN_USER='' ADMIN_PASSWORD='' RABBITMQ_LOGIN='' RABBITMQ_PASSWORD='' RABBITMQ_VHOST='' EOF fi log ""***** ***** ***** ***** *****"" log ""Now you should configure lab binding settings in"" log "" /etc/murano-deployment/lab-binding.rc"" log ""***** ***** ***** ***** *****"" } function fetch_murano_apps { RETURN='' RETURN=""$RETURN $app_name"" git status RETURN=""$RETURN $app_name""} function install_murano_apps { local apps_list=""$@"" log ""** Installing Murano components '$apps_list'..."" for $app_name in $apps_list ; do log ""** Installing '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh install ;; 'Ubuntu') ""$git_clone_dir""/setup.sh install ;; esac} function uninstall_murano_apps { local apps_list=""$@"" log ""** Uninstalling Murano components '$apps_list'..."" for $app_name in $apps_list ; do log ""** Uninstalling '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh uninstall ;; 'Ubuntu') ""$git_clone_dir""/setup.sh uninstall ;; esac done * help - show help. This is a default action. * prerequisites - install prerequisites for Murano (OpenStack dashboard and other packages) * install - install and configure Murano components. Please be sure that you have prerequisites installed first. * uninstall - uninstall Murano components. * update - fetch changes and reinstall components changed. * configure - configure Murano components. * restart - restart Murano components and Apache servercase $os_version in 'CentOS') murano_config_files=""$murano_config_files /etc/openstack-dashboard/local_settings"" ;; 'Ubuntu') murano_config_files=""$murano_config_files /etc/openstack-dashboard/local_settings.py"" ;; esac configuration_required='' for config_file in $murano_config_files ; do if [ ! -f ""$config_file"" ] ; then log ""! Required config file '$config_file' not exists. Murano should be configured before start."" configuration_required=""$configuration_required $config_file"" fi done fetch_murano_apps install_murano_apps $murano_components configure_murano restart_murano ;; 'uninstall') uninstall_murano_apps $murano_components restart_murano 'update') fetch_murano_apps apps_list=$RETURN uninstall_murano_apps $apps_list install_murano_apps $apps_list restart_murano ;;","murano_config_files='/etc/murano-api/murano-api.conf /etc/murano-api/murano-api-paste.ini /etc/murano-conductor/conductor.conf /etc/murano-conductor/conductor-paste.ini /etc/openstack-dashboard/local_settings'# ""/etc/murano-deployment/lab-binding.rc"" sample ################################################## #LAB_HOST='' # #AUTH_URL=""http://$LAB_HOST:5000/v2.0"" # #ADMIN_USER='' #ADMIN_PASSWORD='' # #RABBITMQ_LOGIN='' #RABBITMQ_PASSWORD='' #RABBITMQ_VHOST='/' ################################################## } function install_murano { configuration_required='false' for config_file in $murano_config_files ; do if [ ! -f ""$config_file"" ] ; then log ""! Required config file '$config_file' not exists. Murano should be configured before start."" configuration_required='true' fi done up_to_date='false' up_to_date='true' up_to_date='false' if [ ""$up_to_date"" == 'false' ] ; then chmod +x ""$git_clone_dir""/setup*.sh log ""* Uninstalling '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh uninstall ;; 'Ubuntu') ""$git_clone_dir""/setup.sh uninstall ;; esac sleep 2 log ""* Installing '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh install ;; 'Ubuntu') ""$git_clone_dir""/setup.sh install ;; esac fi if [ ""$configuration_required"" == 'true' ] ; then log ""One or several configuraiton files were not found before installation was launched."" configure_murano fi restart_murano* help - show help. This is a default action. * install - install and configure Murano components. Please be sure that you have prerequisites installed first. * configure - configure Murano components. * prerequisites - install prerequisites for Murano (OpenStack dashboard and other packages) * restart - restart Murano components and Apache server install_murano",108,62
openstack%2Fmurano-dashboard~master~I9b80b98dc19061654d605f71a22d89c21f8c672b,openstack/murano-dashboard,master,I9b80b98dc19061654d605f71a22d89c21f8c672b,"Deployments, Reports and Last Status implemented",MERGED,2013-07-19 14:19:29.000000000,2013-07-19 16:00:05.000000000,2013-07-19 16:00:05.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-07-19 14:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f55f6c3d6bc99819a1faa943d1dcb83bc348315b', 'message': 'Deployments, Reports and last status implemented\n\nChange-Id: I9b80b98dc19061654d605f71a22d89c21f8c672b\n'}, {'number': 2, 'created': '2013-07-19 14:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/59117ee9369aeb6f2ee09a3ac848eddc5d7f27c3', 'message': 'Deployments, Reports and last status implemented\n\nChange-Id: I9b80b98dc19061654d605f71a22d89c21f8c672b\n'}, {'number': 3, 'created': '2013-07-19 15:45:00.000000000', 'files': ['muranodashboard/panel/views.py', 'muranodashboard/templates/_deployment_reports_page_header.html', 'muranodashboard/panel/api.py', 'muranodashboard/panel/urls.py', 'muranodashboard/templates/_deployments_page_header.html', 'muranodashboard/templates/deployments.html', 'muranodashboard/templates/_deployment_logs.html', 'muranodashboard/panel/tabs.py', 'muranodashboard/templates/deployment_reports.html', 'muranodashboard/panel/tables.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/62550346aae6cf57ff5ac472c4d2b68cf6943382', 'message': 'Deployments, Reports and Last Status implemented\n\nChange-Id: I9b80b98dc19061654d605f71a22d89c21f8c672b\n'}]",0,37910,62550346aae6cf57ff5ac472c4d2b68cf6943382,17,4,3,8127,,,0,"Deployments, Reports and Last Status implemented

Change-Id: I9b80b98dc19061654d605f71a22d89c21f8c672b
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/10/37910/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/panel/views.py', 'muranodashboard/templates/_deployment_reports_page_header.html', 'muranodashboard/panel/api.py', 'muranodashboard/panel/urls.py', 'muranodashboard/templates/_deployments_page_header.html', 'muranodashboard/templates/deployments.html', 'muranodashboard/templates/_deployment_logs.html', 'muranodashboard/panel/tabs.py', 'muranodashboard/templates/deployment_reports.html', 'muranodashboard/panel/tables.py']",10,f55f6c3d6bc99819a1faa943d1dcb83bc348315b,feature-statusFetching,"from consts import STATUS_ID_READY, STATUS_ID_DEPLOYING, \ STATUS_CHOICES, STATUS_DISPLAY_CHOICES, STATUS_ID_NEWclass ShowDeployments(tables.LinkAction): name = 'show_deployments' verbose_name = _('Show Deployments') url = 'horizon:project:murano:deployments' def allowed(self, request, environment): return environment.status != STATUS_ID_NEW EditEnvironment, DeleteEnvironment, ShowDeployments) class ShowDeploymentDetails(tables.LinkAction): name = 'show_deployment_details' verbose_name = _('Show Details') def get_link_url(self, deployment=None): kwargs = {'environment_id': deployment.environment_id, 'deployment_id': deployment.id} return reverse('horizon:project:murano:deployment_details', kwargs=kwargs) def allowed(self, request, environment): return True class DeploymentsTable(tables.DataTable): started = tables.Column('started', verbose_name=_('Time Started')) finished = tables.Column('finished', verbose_name=_('Time Finished')) class Meta: name = 'deployments' verbose_name = _('Deployments') row_actions = (ShowDeploymentDetails,) class EnvConfigTable(tables.DataTable): name = tables.Column('name', verbose_name=_('Name')) _type = tables.Column('type', verbose_name=_('Type')) def get_object_id(self, datum): return datum['id'] class Meta: name = 'environment_configuration' verbose_name = _('Deployed Services')","from consts import STATUS_ID_READY, STATUS_ID_DEPLOYING,\ STATUS_CHOICES, STATUS_DISPLAY_CHOICES EditEnvironment, DeleteEnvironment)",312,26
openstack%2Fnova~master~I6b18f7643ab694f5ff34206b80865c40b1ec2680,openstack/nova,master,I6b18f7643ab694f5ff34206b80865c40b1ec2680,Convert cells to use a transport URL,MERGED,2013-06-14 22:17:08.000000000,2013-07-19 15:55:48.000000000,2013-07-12 21:05:55.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1030}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2835}]","[{'number': 1, 'created': '2013-06-14 22:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/76cf19c4b3fa1764b7621e0457940cadd18a9e25', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly AMQP URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nWIP; still to do:\n\n* Implement database migration\n* Write appropriate migration test\n* Add tests on the temporary parse_transport_url() function\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 2, 'created': '2013-06-18 15:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec6c8e451d79d5790c5494dde0d6c45219efbde1', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly AMQP URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nWIP; still to do:\n\nx Implement database migration\n* Write appropriate migration test\n* Add tests on the temporary parse_transport_url() function\n* Update other tests\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 3, 'created': '2013-06-18 16:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b4cc0bceb61f762c7b06a79de268172028156c1', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly AMQP URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nWIP; still to do:\n\nx Implement database migration\n* Write appropriate migration test\n* Add tests on the temporary parse_transport_url() function\n* Update other tests\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 4, 'created': '2013-06-18 22:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eee27b06b08b73cbb6e96776d863f2b3532addaa', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly AMQP URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nWIP; still to do:\n\nx Implement database migration\n* Write appropriate migration test\n* Add tests on the temporary parse_transport_url() function\n* Update other tests\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 5, 'created': '2013-06-19 15:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9d671c2761c05a3dc7ec91e63c141feb27fbedc', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly AMQP URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nWIP; still to do:\n\nx Implement database migration\n* Write appropriate migration test\n* Add tests on the temporary parse_transport_url() function\nx Update other tests\n* Handle cell create and update in os-cells extension\n? Add API samples for cell create and update\n  - Sort of beyond the purpose of this patch...\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 6, 'created': '2013-06-19 20:38:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78913611f615db1576950a5cd9d580f5d9581abb', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 7, 'created': '2013-06-19 22:18:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f4d1ce6ae4781c2fe5113fdfce75267cccfb8c57', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 8, 'created': '2013-06-24 19:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78eec81ac5d535b094a55d1894c12b200e541e07', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 9, 'created': '2013-06-25 15:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9bfb45f4a6fd1c11b9c0c387479385ded62cbabf', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 10, 'created': '2013-06-25 22:41:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a575849199e3de5adec0f0d27c3d5e100574a3c8', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 11, 'created': '2013-06-25 22:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a7fd9bad0ca4bab074383cd4c8ada2bac3dfade1', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 12, 'created': '2013-06-26 16:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/17d52ba2c459532ed95030195ea2e4fe46b18af4', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 13, 'created': '2013-06-26 22:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6dd10fe2da9623e11a5aa136cf53bbd6218853d8', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 14, 'created': '2013-06-27 20:34:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12f78975a0577743d26fb4f8a0610a95d93a1bcb', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 15, 'created': '2013-06-28 23:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6cf9332599143170e882ace2586d1437d44ed721', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 16, 'created': '2013-06-30 03:01:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c419a2d6afd2c5f98946a700c9b27972e3e1109', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit URLs are recognized, and no auxiliary data is recognized.\nThis cleans up the database table, and will make it easier to move\ncell data out of the database and into the configuration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 17, 'created': '2013-07-10 22:12:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/08efae6b642e84a1c01475f94d052fc8d9e0bccf', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit and qpid URLs are recognized, and no auxiliary data is\nrecognized.  This cleans up the database table, and will make it\neasier to move cell data out of the database and into the\nconfiguration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nDocImpact: None.  Transport URLs are not exposed to deployers in\n           this patch.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 18, 'created': '2013-07-11 22:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38708de1d7957d93db791a568dade0443fab13fb', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit and qpid URLs are recognized, and no auxiliary data is\nrecognized.  This cleans up the database table, and will make it\neasier to move cell data out of the database and into the\nconfiguration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nDocImpact: None.  Transport URLs are not exposed to deployers in\n           this patch.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}, {'number': 19, 'created': '2013-07-12 16:05:58.000000000', 'files': ['nova/tests/cells/fakes.py', 'nova/api/openstack/compute/plugins/v3/cells.py', 'nova/tests/cells/test_cells_rpc_driver.py', 'nova/cells/rpc_driver.py', 'nova/api/openstack/compute/contrib/cells.py', 'nova/db/sqlalchemy/migrate_repo/versions/200_add_transport_url_to_cell.py', 'nova/cmd/manage.py', 'nova/tests/db/test_migrations.py', 'nova/db/sqlalchemy/models.py', 'nova/tests/api/openstack/compute/contrib/test_cells.py', 'nova/cells/state.py', 'nova/tests/api/openstack/compute/plugins/v3/test_cells.py', 'nova/tests/integrated/test_api_samples.py', 'nova/tests/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/51c12f0eea95952a1dc2e77b9fa62dc56f62e488', 'message': 'Convert cells to use a transport URL\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in individual columns in the ""cells"" table\nof the database.  This renders it difficult to specify alternate\ntransports (e.g., 0mq).  Work is currently in progress to add the\nconcept of ""transport URLs,"" but the end goal is to remove this data\nfrom the database entirely and store it in a configuration file.\n\nThis change adds transport URLs to cells in a very limited fashion;\nonly rabbit and qpid URLs are recognized, and no auxiliary data is\nrecognized.  This cleans up the database table, and will make it\neasier to move cell data out of the database and into the\nconfiguration file.\n\nPartially implements blueprint eliminate-clear-passwords-from-cells-table.\n\nDocImpact: None.  Transport URLs are not exposed to deployers in\n           this patch.\n\nChange-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680\n'}]",35,33127,51c12f0eea95952a1dc2e77b9fa62dc56f62e488,89,8,19,679,,,0,"Convert cells to use a transport URL

Cells currently keeps all inter-cell communication data, including
usernames and passwords, in individual columns in the ""cells"" table
of the database.  This renders it difficult to specify alternate
transports (e.g., 0mq).  Work is currently in progress to add the
concept of ""transport URLs,"" but the end goal is to remove this data
from the database entirely and store it in a configuration file.

This change adds transport URLs to cells in a very limited fashion;
only rabbit and qpid URLs are recognized, and no auxiliary data is
recognized.  This cleans up the database table, and will make it
easier to move cell data out of the database and into the
configuration file.

Partially implements blueprint eliminate-clear-passwords-from-cells-table.

DocImpact: None.  Transport URLs are not exposed to deployers in
           this patch.

Change-Id: I6b18f7643ab694f5ff34206b80865c40b1ec2680
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/33127/18 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/models.py', 'nova/cells/state.py', 'nova/cells/rpc_driver.py']",3,76cf19c4b3fa1764b7621e0457940cadd18a9e25,bp/eliminate-clear-passwords-from-cells-table,"import urlparse server_params = parse_transport_url(next_hop.db_info['transport_url']) return dict((k, v) for k, v in server_params.items() if v) def parse_transport_url(url): """""" Parse a transport URL. """""" # TODO(Vek): Use the actual Oslo code, once it lands in # oslo-incubator # First step is to parse the URL parsed = urlparse.urlparse(url) # Make sure we understand the schema if parsed.schema != 'amqp': raise ValueError(_(""Unable to handle non-AMQP transport URLs"")) # Make sure there's not a query string; that could identify # requirements we can't comply with (e.g., ssl), so reject it if # it's present if '?' in parsed.path: raise ValueError(_(""Cannot comply with query string in transport URL"")) # Extract the interesting information from the URL username = parsed.username password = parsed.password virtual_host = parsed.path # Now we have to extract the hostname and port; unfortunately, # urlparse in Python 2.6 doesn't understand IPv6 addresses hostname = parsed.hostname if hostname[0] == '[': # If '@' is present, rfind() finds its position; if it isn't, # rfind() returns -1. Either way, adding 1 gives us the start # location of the host and port... host_start = parsed.netloc.rfind('@') netloc = parsed.netloc[host_start + 1:] # Find the closing ']' and extract the hostname host_end = netloc.find(']') if host_end < 0: # NOTE(Vek): Not translated so it's identical to what # Python 2.7's urlparse.urlparse() raises in this case raise ValueError(""Invalid IPv6 URL"") hostname = netloc[1:host_end] # Now we need the port port_text = netloc[host_end + 1:] port = int(port_text[1:]) if port_text else None else: port = parsed.port # Now that we have what we need, return the information return { 'username': username, 'password': password, 'hostname': hostname, 'port': port, 'virtual_host': virtual_host, }"," param_map = {'username': 'username', 'password': 'password', 'rpc_host': 'hostname', 'rpc_port': 'port', 'rpc_virtual_host': 'virtual_host'} server_params = {} for source, target in param_map.items(): if next_hop.db_info[source]: server_params[target] = next_hop.db_info[source] return server_params",79,21
openstack%2Ftempest~master~I7cd1d0a9b3b87ce15cbfd4b28805e43a691aedd3,openstack/tempest,master,I7cd1d0a9b3b87ce15cbfd4b28805e43a691aedd3,Remove duplicate flaky test.,MERGED,2013-06-16 22:10:47.000000000,2013-07-19 15:27:03.000000000,2013-07-19 15:27:03.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5586}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-06-16 22:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/126a75e60e06fe2c642b01c5e459b0d1edb88f8c', 'message': 'Remove duplicate flaky test.\n\nFixes: bug #1191590\nChange-Id: I7cd1d0a9b3b87ce15cbfd4b28805e43a691aedd3\n'}, {'number': 2, 'created': '2013-06-18 15:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7656a2e5936ab6612660fae6b82dc0aa9f70073f', 'message': 'Remove duplicate flaky test.\n\nFixes: bug #1191590\nChange-Id: I7cd1d0a9b3b87ce15cbfd4b28805e43a691aedd3\n'}, {'number': 3, 'created': '2013-07-18 10:27:01.000000000', 'files': ['tempest/api/compute/images/test_images.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/25e935cfcc5b2fd7eb3104cbe444ab9dee73e31f', 'message': 'Remove duplicate flaky test.\n\nRemove two flaky tests:\n- test_create_image_when_server_is_terminating\n- test_create_image_when_server_is_rebooting\n\nFixes: bug #1191590\nChange-Id: I7cd1d0a9b3b87ce15cbfd4b28805e43a691aedd3\n'}]",0,33211,25e935cfcc5b2fd7eb3104cbe444ab9dee73e31f,48,7,3,1921,,,0,"Remove duplicate flaky test.

Remove two flaky tests:
- test_create_image_when_server_is_terminating
- test_create_image_when_server_is_rebooting

Fixes: bug #1191590
Change-Id: I7cd1d0a9b3b87ce15cbfd4b28805e43a691aedd3
",git fetch https://review.opendev.org/openstack/tempest refs/changes/11/33211/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/images/test_images.py'],1,126a75e60e06fe2c642b01c5e459b0d1edb88f8c,bug/1191590,," @attr(type=['negative', 'gate']) def test_create_image_when_server_is_terminating(self): # Return an error when creating image of server that is terminating resp, server = self.create_server(wait_until='ACTIVE') self.servers_client.delete_server(server['id']) snapshot_name = rand_name('test-snap-') self.assertRaises(exceptions.Duplicate, self.client.create_image, server['id'], snapshot_name) ",0,10
openstack%2Fdesignate~master~I59f29156476f0a11e8ed2f76f02dded2d4c20e34,openstack/designate,master,I59f29156476f0a11e8ed2f76f02dded2d4c20e34,Remove invalid entrypoints,MERGED,2013-07-19 15:03:41.000000000,2013-07-19 15:17:52.000000000,2013-07-19 15:17:52.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}]","[{'number': 1, 'created': '2013-07-19 15:03:41.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/designate/commit/fea304331b19baa5f9613a1ed002de6bb86fd4a3', 'message': 'Remove invalid entrypoints\n\nThese were copyied and pasted from the designateclient package by\nmistake.\n\nChange-Id: I59f29156476f0a11e8ed2f76f02dded2d4c20e34\n'}]",0,37922,fea304331b19baa5f9613a1ed002de6bb86fd4a3,6,3,1,741,,,0,"Remove invalid entrypoints

These were copyied and pasted from the designateclient package by
mistake.

Change-Id: I59f29156476f0a11e8ed2f76f02dded2d4c20e34
",git fetch https://review.opendev.org/openstack/designate refs/changes/22/37922/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,fea304331b19baa5f9613a1ed002de6bb86fd4a3,,,designate.v1.controllers = reports = designate.v1.reports:ReportsController diagnostics = designate.v1.diagnostics:DiagnosticsController domains = designate.v1.domains:DomainsController records = designate.v1.records:RecordsController servers = designate.v1.servers:ServersController ,0,7
openstack%2Ftripleo-image-elements~master~I8b27678bb8495d10b355aa7f6370a4f86f6c957d,openstack/tripleo-image-elements,master,I8b27678bb8495d10b355aa7f6370a4f86f6c957d,Add an os-collect-config element.,MERGED,2013-07-19 15:16:53.000000000,2013-07-19 15:16:53.000000000,2013-07-19 15:16:53.000000000,"[{'_account_id': 3}, {'_account_id': 6449}]","[{'number': 1, 'created': '2013-07-19 15:16:53.000000000', 'files': ['elements/os-collect-config/README.md', 'elements/os-collect-config/install.d/10-os-collect-config', 'elements/os-collect-config/source-repository-os-collect-config', 'elements/os-collect-config/os-apply-config/etc/os-collect-config/os-collect-config.conf', 'elements/os-collect-config/element-deps'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/4512af045df24c43f847fa79c4574b5a4f77ce40', 'message': 'Add an os-collect-config element.\n\nChange-Id: I8b27678bb8495d10b355aa7f6370a4f86f6c957d\n'}]",0,37732,4512af045df24c43f847fa79c4574b5a4f77ce40,5,2,1,6488,,,0,"Add an os-collect-config element.

Change-Id: I8b27678bb8495d10b355aa7f6370a4f86f6c957d
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/32/37732/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/os-collect-config/README.md', 'elements/os-collect-config/install.d/10-os-collect-config', 'elements/os-collect-config/source-repository-os-collect-config', 'elements/os-collect-config/os-apply-config/etc/os-collect-config/os-collect-config.conf', 'elements/os-collect-config/element-deps']",5,4512af045df24c43f847fa79c4574b5a4f77ce40,ELEMENT-OCC,source-repositories ,,102,0
openstack%2Ftripleo-image-elements~master~I853a2f2890fcc0b006fcfc214fb1ca900d03613a,openstack/tripleo-image-elements,master,I853a2f2890fcc0b006fcfc214fb1ca900d03613a,Update postfix element per install instructions.,MERGED,2013-07-19 15:10:44.000000000,2013-07-19 15:10:44.000000000,2013-07-19 15:10:44.000000000,"[{'_account_id': 3}, {'_account_id': 6449}]","[{'number': 1, 'created': '2013-07-19 15:10:44.000000000', 'files': ['elements/postfix/os-refresh-config/post-configure.d/59-postfix'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e9bd8dc94470051a29d0ab5f5dbe9bb1a04397bc', 'message': 'Update postfix element per install instructions.\n\nUpdates postfix element to reload instead of restart. This is called\nfor in the installation instructions. This also fixes a issue with\nthe postfix element where the current restart can fail and cause ORC\npost-install scripts with higher numbers to not run.\n\nChange-Id: I853a2f2890fcc0b006fcfc214fb1ca900d03613a\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\n'}]",0,37804,e9bd8dc94470051a29d0ab5f5dbe9bb1a04397bc,5,2,1,5805,,,0,"Update postfix element per install instructions.

Updates postfix element to reload instead of restart. This is called
for in the installation instructions. This also fixes a issue with
the postfix element where the current restart can fail and cause ORC
post-install scripts with higher numbers to not run.

Change-Id: I853a2f2890fcc0b006fcfc214fb1ca900d03613a
Authored-by: Chris Krelle <nobodycam@gmail.com>
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/04/37804/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/postfix/os-refresh-config/post-configure.d/59-postfix'],1,e9bd8dc94470051a29d0ab5f5dbe9bb1a04397bc,,service postfix reload ,service postfix restart,1,1
openstack%2Fswift~master~I74cc9d2cf2e271a2c45d45cc5ea777189c02eacb,openstack/swift,master,I74cc9d2cf2e271a2c45d45cc5ea777189c02eacb,Remove list comprehension where the result is unused.,MERGED,2013-07-19 13:54:46.000000000,2013-07-19 15:08:25.000000000,2013-07-19 15:08:25.000000000,"[{'_account_id': 3}, {'_account_id': 917}, {'_account_id': 2166}, {'_account_id': 2828}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-07-19 13:54:46.000000000', 'files': ['swift/proxy/controllers/obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/3b1ee1f6a3425bca7f5ae98e4701b02653596946', 'message': 'Remove list comprehension where the result is unused.\n\nUsing a list comprehension here makes the code less\nreadable, and is also slower (since it has to allocate\nand grow a list that is unused).\n\nChange-Id: I74cc9d2cf2e271a2c45d45cc5ea777189c02eacb\n'}]",0,37904,3b1ee1f6a3425bca7f5ae98e4701b02653596946,8,5,1,7680,,,0,"Remove list comprehension where the result is unused.

Using a list comprehension here makes the code less
readable, and is also slower (since it has to allocate
and grow a list that is unused).

Change-Id: I74cc9d2cf2e271a2c45d45cc5ea777189c02eacb
",git fetch https://review.opendev.org/openstack/swift refs/changes/04/37904/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/proxy/controllers/obj.py'],1,3b1ee1f6a3425bca7f5ae98e4701b02653596946,no-list-alloc, for conn in conns: conn.queue.put('0\r\n\r\n'), [conn.queue.put('0\r\n\r\n') for conn in conns],2,1
openstack%2Ftempest~master~I460c48121c26d07eb29f355c07a2059f5e6b24b0,openstack/tempest,master,I460c48121c26d07eb29f355c07a2059f5e6b24b0,Remove unneeded class filter from .testr.conf,MERGED,2013-07-18 21:35:26.000000000,2013-07-19 14:57:01.000000000,2013-07-19 14:57:01.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-18 21:35:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d268a0722c8dfa5304e6232a301b7a0df0185809', 'message': 'Do Not Merge! Test of .testr.conf\n\nChecking the performance delta between hacked .testr.conf and default\n\nChange-Id: I460c48121c26d07eb29f355c07a2059f5e6b24b0\n'}, {'number': 2, 'created': '2013-07-18 22:16:38.000000000', 'files': ['tools/run_test_classes.py', '.testr.conf'], 'web_link': 'https://opendev.org/openstack/tempest/commit/66d317fcb83eda4662d35262d0e6230ed65d3b5c', 'message': 'Remove unneeded class filter from .testr.conf\n\nThis commit removes the unnecessary class filter run_test_classes.py\nand reverts the .testr.conf to the standard format. The class filter\nis not needed when using test grouping.\n\nChange-Id: I460c48121c26d07eb29f355c07a2059f5e6b24b0\n'}]",0,37785,66d317fcb83eda4662d35262d0e6230ed65d3b5c,9,4,2,5196,,,0,"Remove unneeded class filter from .testr.conf

This commit removes the unnecessary class filter run_test_classes.py
and reverts the .testr.conf to the standard format. The class filter
is not needed when using test grouping.

Change-Id: I460c48121c26d07eb29f355c07a2059f5e6b24b0
",git fetch https://review.opendev.org/openstack/tempest refs/changes/85/37785/1 && git format-patch -1 --stdout FETCH_HEAD,['.testr.conf'],1,d268a0722c8dfa5304e6232a301b7a0df0185809,testr-conf-test,test_command=python -m subunit.run discover . $LISTOPT $IDOPTION test_id_option=--load-list $IDFILE test_list_option=--list,test_command=${PYTHON:-python} -m subunit.run $LISTOPT $IDOPTION test_id_option=$(${PYTHON:-python} -m tools/run_test_classes $IDFILE) test_list_option=discover -t ./ ./tempest --list,3,3
openstack%2Frequirements~master~I06513b7169e2895aa3e7eeeea4f6b0b81be1771e,openstack/requirements,master,I06513b7169e2895aa3e7eeeea4f6b0b81be1771e,Nitpick: Always use >= for the lower bound,ABANDONED,2013-07-08 10:16:58.000000000,2013-07-19 14:34:16.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-07-08 10:16:58.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/bb59b696c8ca666c01092b19e9cc86bd66b80b0c', 'message': 'Nitpick: Always use >= for the lower bound\n\nThis helps to scripted evaluation of dependencies.\n\nChange-Id: I06513b7169e2895aa3e7eeeea4f6b0b81be1771e\n'}]",0,36040,bb59b696c8ca666c01092b19e9cc86bd66b80b0c,2,1,1,6593,,,0,"Nitpick: Always use >= for the lower bound

This helps to scripted evaluation of dependencies.

Change-Id: I06513b7169e2895aa3e7eeeea4f6b0b81be1771e
",git fetch https://review.opendev.org/openstack/requirements refs/changes/40/36040/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,bb59b696c8ca666c01092b19e9cc86bd66b80b0c,kombu,kombu>=2.4.8pip>=1.0.1,kombu>2.4.7pip>1.0,2,2
openstack%2Fcinder~master~I1b762c0311a0ac810427ea033f737fd067761b1c,openstack/cinder,master,I1b762c0311a0ac810427ea033f737fd067761b1c,Revert hardening of Storwize/SVC SSH commands.,MERGED,2013-07-19 13:32:35.000000000,2013-07-19 14:27:50.000000000,2013-07-19 14:25:18.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 4355}, {'_account_id': 7593}]","[{'number': 1, 'created': '2013-07-19 13:32:35.000000000', 'files': ['cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/storwize_svc.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/08d749780ec6a8b092507b345f7a89b4661d9d70', 'message': 'Revert hardening of Storwize/SVC SSH commands.\n\nThis reverts commit 6be79a8e3b4607adbbe6a26ee565156cd0fb36b0.\nParamiko expects string commands, not lists.\n\nChange-Id: I1b762c0311a0ac810427ea033f737fd067761b1c\n'}]",0,37898,08d749780ec6a8b092507b345f7a89b4661d9d70,8,4,1,4355,,,0,"Revert hardening of Storwize/SVC SSH commands.

This reverts commit 6be79a8e3b4607adbbe6a26ee565156cd0fb36b0.
Paramiko expects string commands, not lists.

Change-Id: I1b762c0311a0ac810427ea033f737fd067761b1c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/98/37898/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/storwize_svc.py']",2,08d749780ec6a8b092507b345f7a89b4661d9d70,revert-svc-ssh-harden," generator = self._port_conf_generator('svcinfo lsportip') ssh_cmd = 'svcinfo lsnode -delim ! %s' % node['id'] ssh_cmd = 'svcinfo lsmdiskgrp -delim ! -nohdr' ssh_cmd = 'svcinfo lslicense -delim !' ssh_cmd = 'svcinfo lsnode -delim !' ssh_cmd = ('svctask chhost -chapsecret ""%(chap_secret)s"" %(host_name)s' % {'chap_secret': chap_secret, 'host_name': host_name}) ssh_cmd = 'svcinfo lsiscsiauth -delim !' ssh_cmd = 'svcinfo lsfabric -wwpn %s -delim !' % wwpn ssh_cmd = 'svcinfo lshost -delim ! %s' % host ssh_cmd = 'svcinfo lshost -delim !' ssh_cmd = ('svctask mkhost -force %(port1)s -name ""%(host_name)s""' % {'port1': port1, 'host_name': host_name}) ssh_cmd = ('svctask addhostport -force %s %s' % (port, host_name)) ssh_cmd = 'svcinfo lshostvdiskmap -delim ! %s' % host_name ssh_cmd = ('svctask mkvdiskhostmap -host %(host_name)s -scsi ' '%(result_lun)s %(volume_name)s' % {'host_name': host_name, 'result_lun': result_lun, 'volume_name': volume_name}) ssh_cmd = ssh_cmd.replace('mkvdiskhostmap', 'mkvdiskhostmap -force') ssh_cmd = 'svctask rmhost %s ' % host_name cmd = 'svcinfo lsfabric -host %s' % host_name ssh_cmd = 'svctask rmvdiskhostmap -host %s %s' % \ (host_name, vol_name) ssh_cmd = 'svcinfo lsvdisk -bytes -delim ! %s ' % vdisk_name ssh_cmd = 'svcinfo lsvdiskfcmappings -nohdr %s' % vdisk_name autoex = '-autoexpand' if opts['autoexpand'] else '' easytier = '-easytier on' if opts['easytier'] else '-easytier off' ssh_cmd_se_opt = '' else: ssh_cmd_se_opt = ( '-rsize %(rsize)d%% %(autoex)s -warning %(warn)d%%' % {'rsize': opts['rsize'], 'autoex': autoex, 'warn': opts['warning']}) if opts['compression']: ssh_cmd_se_opt = ssh_cmd_se_opt + ' -compressed' else: ssh_cmd_se_opt = ssh_cmd_se_opt + ( ' -grainsize %d' % opts['grainsize']) ssh_cmd = ('svctask mkvdisk -name %(name)s -mdiskgrp %(mdiskgrp)s ' '-iogrp 0 -size %(size)s -unit ' '%(unit)s %(easytier)s %(ssh_cmd_se_opt)s' % {'name': name, 'mdiskgrp': self.configuration.storwize_svc_volpool_name, 'size': size, 'unit': units, 'easytier': easytier, 'ssh_cmd_se_opt': ssh_cmd_se_opt}) copyflag = '' if full_copy else '-copyrate 0' fc_map_cli_cmd = ('svctask mkfcmap -source %(src)s -target %(tgt)s ' '-autodelete %(copyflag)s' % {'src': source, 'tgt': target, 'copyflag': copyflag}) out, err = self._run_ssh('svctask prestartfcmap %s' % fc_map_id) out, err = self._run_ssh('svctask startfcmap %s' % fc_map_id) fc_ls_map_cmd = 'svcinfo lsfcmap -filtervalue id=%s -delim !' % \ fc_map_id ssh_cmd = ('svctask chfcmap -copyrate 50 ' '-autodelete on %s' % map_id) self._run_ssh('svctask stopfcmap %s' % map_id) self._run_ssh('svctask rmfcmap -force %s' % map_id) self._run_ssh('svctask stopfcmap %s' % map_id) self._run_ssh('svctask rmfcmap -force %s' % map_id) self._run_ssh('svctask rmfcmap -force %s' % map_id) forceflag = '-force' if force else '' cmd_params = {'frc': forceflag, 'name': name} ssh_cmd = 'svctask rmvdisk %(frc)s %(name)s' % cmd_params ssh_cmd = 'svcinfo lssystem -delim !' ssh_cmd = 'svcinfo lsmdiskgrp -bytes -delim ! %s' % pool ssh_cmd = '%s -delim !' % cmd ' command %s') % ssh_cmd) % {'cmd': ssh_cmd,"," generator = self._port_conf_generator(['svcinfo', 'lsportip']) ssh_cmd = ['svcinfo', 'lsnode', '-delim', '!', node['id']] ssh_cmd = ['svcinfo', 'lsmdiskgrp', '-delim', '!', '-nohdr'] ssh_cmd = ['svcinfo', 'lslicense', '-delim', '!'] ssh_cmd = ['svcinfo', 'lsnode', '-delim', '!'] ssh_cmd = ['svctask', 'chhost', '-chapsecret', chap_secret, host_name] ssh_cmd = ['svcinfo', 'lsiscsiauth', '-delim', '!'] ssh_cmd = ['svcinfo', 'lsfabric', '-wwpn', wwpn, '-delim', '!'] ssh_cmd = ['svcinfo', 'lshost', '-delim', '!', host] ssh_cmd = ['svcinfo', 'lshost', '-delim', '!'] arg_name, arg_val = port1.split() ssh_cmd = ['svctask', 'mkhost', '-force', arg_name, arg_val, '-name', '""%s""' % host_name] arg_name, arg_val = port.split() ssh_cmd = ['svctask', 'addhostport', '-force', arg_name, arg_val, host_name] ssh_cmd = ['svcinfo', 'lshostvdiskmap', '-delim', '!', host_name] ssh_cmd = ['svctask', 'mkvdiskhostmap', '-host', host_name, '-scsi', result_lun, volume_name] for i in range(len(ssh_cmd)): if ssh_cmd[i] == 'mkvdiskhostmap': ssh_cmd.insert(i + 1, '-force') ssh_cmd = ['svctask', 'rmhost', host_name] cmd = ['svcinfo', 'lsfabric', '-host', host_name] ssh_cmd = ['svctask', 'rmvdiskhostmap', '-host', host_name, vol_name] ssh_cmd = ['svcinfo', 'lsvdisk', '-bytes', '-delim', '!', vdisk_name] ssh_cmd = ['svcinfo', 'lsvdiskfcmappings', '-nohdr', vdisk_name] easytier = 'on' if opts['easytier'] else 'off' ssh_cmd_se_opt = [] else: ssh_cmd_se_opt = ['-rsize', '%s%%' % str(opts['rsize']), '-autoexpand', '-warning', '%s%%' % str(opts['warning'])] if not opts['autoexpand']: ssh_cmd_se_opt.remove('-autoexpand') if opts['compression']: ssh_cmd_se_opt.append('-compressed') else: ssh_cmd_se_opt.extend(['-grainsize', str(opts['grainsize'])]) ssh_cmd = ['svctask', 'mkvdisk', '-name', name, '-mdiskgrp', self.configuration.storwize_svc_volpool_name, '-iogrp', '0', '-size', size, '-unit', units, '-easytier', easytier] + ssh_cmd_se_opt fc_map_cli_cmd = ['svctask', 'mkfcmap', '-source', source, '-target', target, '-autodelete'] if full_copy: fc_map_cli_cmd.extend(['-copyrate', '0']) out, err = self._run_ssh(['svctask', 'prestartfcmap', fc_map_id]) out, err = self._run_ssh(['svctask', 'startfcmap', fc_map_id]) fc_ls_map_cmd = ['svcinfo', 'lsfcmap', '-filtervalue', 'id=%s' % fc_map_id, '-delim', '!'] ssh_cmd = ['svctask', 'chfcmap', '-copyrate', '50', '-autodelete', 'on', map_id] self._run_ssh(['svctask', 'stopfcmap', map_id]) self._run_ssh(['svctask', 'rmfcmap', '-force', map_id]) self._run_ssh(['svctask', 'stopfcmap', map_id]) self._run_ssh(['svctask', 'rmfcmap', '-force', map_id]) self._run_ssh(['svctask', 'rmfcmap', '-force', map_id]) ssh_cmd = ['svctask', 'rmvdisk', '-force', name] if not force: ssh_cmd.remove('-force') ssh_cmd = ['svcinfo', 'lssystem', '-delim', '!'] ssh_cmd = ['svcinfo', 'lsmdiskgrp', '-bytes', '-delim', '!', pool] ssh_cmd = cmd + ['-delim', '!'] ' command %s') % str(ssh_cmd)) % {'cmd': str(ssh_cmd),",74,69
