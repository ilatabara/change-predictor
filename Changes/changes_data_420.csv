id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fpuppet-senlin~master~I96d77730bcf2024cfef133153846f36dec905088,openstack/puppet-senlin,master,I96d77730bcf2024cfef133153846f36dec905088,Use validate_legacy,MERGED,2019-02-23 21:48:53.000000000,2019-02-25 17:52:34.000000000,2019-02-25 17:52:34.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 21:48:53.000000000', 'files': ['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-senlin/commit/b9c9e5b166232caa62ae6dad0055f45e8c971f35', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I96d77730bcf2024cfef133153846f36dec905088\n'}]",0,638872,b9c9e5b166232caa62ae6dad0055f45e8c971f35,7,3,1,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: I96d77730bcf2024cfef133153846f36dec905088
",git fetch https://review.opendev.org/openstack/puppet-senlin refs/changes/72/638872/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp']",4,b9c9e5b166232caa62ae6dad0055f45e8c971f35,validate_legacy," validate_legacy(Hash, 'validate_hash', $policies)", validate_hash($policies),5,5
openstack%2Fpuppet-ceilometer~master~I5d90d45bd4f9555bf13f75ac0ab607b9f5086dca,openstack/puppet-ceilometer,master,I5d90d45bd4f9555bf13f75ac0ab607b9f5086dca,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 22:55:35.000000000,2019-02-25 17:52:27.000000000,2019-02-25 17:52:27.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 22:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/fe3abfafbdad01165abd2b92465795b08e0aa476', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: I5d90d45bd4f9555bf13f75ac0ab607b9f5086dca\n'}, {'number': 2, 'created': '2019-02-23 23:15:08.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-47c5f09cd66eea40.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/5616321fbf4d779ee4c87b8fd8ca62f638fd1d6b', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: I5d90d45bd4f9555bf13f75ac0ab607b9f5086dca\n'}]",0,638884,5616321fbf4d779ee4c87b8fd8ca62f638fd1d6b,9,3,2,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: I5d90d45bd4f9555bf13f75ac0ab607b9f5086dca
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/84/638884/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-47c5f09cd66eea40.yaml'],1,fe3abfafbdad01165abd2b92465795b08e0aa476,release-note-ubuntu-py3,"--- prelude: - | In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,11,0
openstack%2Fpuppet-tacker~master~Id02bd2f28bf4ab2d638f2fd6d8a13fd4eec00187,openstack/puppet-tacker,master,Id02bd2f28bf4ab2d638f2fd6d8a13fd4eec00187,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 23:12:06.000000000,2019-02-25 17:46:56.000000000,2019-02-25 17:46:56.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 23:12:06.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-7df0383f755751df.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-tacker/commit/ebbb51ca2ffbb8505928da8865eb47075c828c77', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: Id02bd2f28bf4ab2d638f2fd6d8a13fd4eec00187\n'}]",0,638913,ebbb51ca2ffbb8505928da8865eb47075c828c77,7,3,1,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: Id02bd2f28bf4ab2d638f2fd6d8a13fd4eec00187
",git fetch https://review.opendev.org/openstack/puppet-tacker refs/changes/13/638913/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-7df0383f755751df.yaml'],1,ebbb51ca2ffbb8505928da8865eb47075c828c77,release-note-ubuntu-py3,"--- prelude: > In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,10,0
openstack%2Fpuppet-tacker~master~If25820ad85e763246d90954a80db86763ed9e9c5,openstack/puppet-tacker,master,If25820ad85e763246d90954a80db86763ed9e9c5,Use validate_legacy,MERGED,2019-02-23 21:59:56.000000000,2019-02-25 17:46:55.000000000,2019-02-25 17:46:55.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 21:59:56.000000000', 'files': ['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tacker/commit/916bbb41e7090f1d4bcb79306e3e432c78c93265', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: If25820ad85e763246d90954a80db86763ed9e9c5\n'}]",0,638874,916bbb41e7090f1d4bcb79306e3e432c78c93265,7,3,1,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: If25820ad85e763246d90954a80db86763ed9e9c5
",git fetch https://review.opendev.org/openstack/puppet-tacker refs/changes/74/638874/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp']",4,916bbb41e7090f1d4bcb79306e3e432c78c93265,validate_legacy," validate_legacy(Hash, 'validate_hash', $policies)", validate_hash($policies),5,5
openstack%2Fpuppet-aodh~master~Ic7ca06e9a244bc196dd42e819ee76c04fee3f9ea,openstack/puppet-aodh,master,Ic7ca06e9a244bc196dd42e819ee76c04fee3f9ea,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 22:54:24.000000000,2019-02-25 17:43:11.000000000,2019-02-25 17:43:11.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 22:54:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/029f598217f71d17d5b17fd091b6e130ab7b685c', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: Ic7ca06e9a244bc196dd42e819ee76c04fee3f9ea\n'}, {'number': 2, 'created': '2019-02-23 23:14:32.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-f90334f338d0bcfb.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/984db8723389049fa8eb6dba3c752375493c6e14', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: Ic7ca06e9a244bc196dd42e819ee76c04fee3f9ea\n'}]",0,638882,984db8723389049fa8eb6dba3c752375493c6e14,9,3,2,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: Ic7ca06e9a244bc196dd42e819ee76c04fee3f9ea
",git fetch https://review.opendev.org/openstack/puppet-aodh refs/changes/82/638882/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-f90334f338d0bcfb.yaml'],1,029f598217f71d17d5b17fd091b6e130ab7b685c,release-note-ubuntu-py3,"--- prelude: - | In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,11,0
openstack%2Fpuppet-aodh~master~I5644b1b2e8c0c90ed1de91631cbfc2cd1a9ddd07,openstack/puppet-aodh,master,I5644b1b2e8c0c90ed1de91631cbfc2cd1a9ddd07,Use validate_legacy,MERGED,2019-02-10 11:52:28.000000000,2019-02-25 17:43:11.000000000,2019-02-25 17:43:11.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-10 11:52:28.000000000', 'files': ['manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/3690af9758412400c361e474c4fe84657fc7e7c7', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I5644b1b2e8c0c90ed1de91631cbfc2cd1a9ddd07\n'}]",0,636046,3690af9758412400c361e474c4fe84657fc7e7c7,9,4,1,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: I5644b1b2e8c0c90ed1de91631cbfc2cd1a9ddd07
",git fetch https://review.opendev.org/openstack/puppet-aodh refs/changes/46/636046/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp']",3,3690af9758412400c361e474c4fe84657fc7e7c7,validate_legacy," validate_legacy(Hash, 'validate_hash', $policies)", validate_hash($policies),4,4
openstack%2Fpuppet-rally~master~Icafdcbfe31d7a56fec041111c4e41bf694b90529,openstack/puppet-rally,master,Icafdcbfe31d7a56fec041111c4e41bf694b90529,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 23:10:46.000000000,2019-02-25 17:43:08.000000000,2019-02-25 17:43:08.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 23:10:46.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-30f3c53dccb0694c.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-rally/commit/d1c06c8dc339cd795dd03eb1575ab97a07f75517', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: Icafdcbfe31d7a56fec041111c4e41bf694b90529\n'}]",0,638910,d1c06c8dc339cd795dd03eb1575ab97a07f75517,7,3,1,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: Icafdcbfe31d7a56fec041111c4e41bf694b90529
",git fetch https://review.opendev.org/openstack/puppet-rally refs/changes/10/638910/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-30f3c53dccb0694c.yaml'],1,d1c06c8dc339cd795dd03eb1575ab97a07f75517,release-note-ubuntu-py3,"--- prelude: > In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,10,0
openstack%2Fpuppet-rally~master~I27f5484b8d1f8568fe3cb40f707a59962c2049cb,openstack/puppet-rally,master,I27f5484b8d1f8568fe3cb40f707a59962c2049cb,Use validate_legacy,MERGED,2019-02-23 21:46:05.000000000,2019-02-25 17:43:07.000000000,2019-02-25 17:43:07.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 21:46:05.000000000', 'files': ['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp'], 'web_link': 'https://opendev.org/openstack/puppet-rally/commit/c0bf5b5fb1f755c6a05c2f6331a0be6307d2d0c1', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I27f5484b8d1f8568fe3cb40f707a59962c2049cb\n'}]",0,638870,c0bf5b5fb1f755c6a05c2f6331a0be6307d2d0c1,7,3,1,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: I27f5484b8d1f8568fe3cb40f707a59962c2049cb
",git fetch https://review.opendev.org/openstack/puppet-rally refs/changes/70/638870/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp']",3,c0bf5b5fb1f755c6a05c2f6331a0be6307d2d0c1,validate_legacy," validate_legacy(Hash, 'validate_hash', $rally_config)", validate_hash($rally_config),4,4
openstack%2Fpuppet-murano~master~I5d1e387b8e000cdac156afc8dbbcef9037e14659,openstack/puppet-murano,master,I5d1e387b8e000cdac156afc8dbbcef9037e14659,Change keystone v2.0 to v3,MERGED,2019-02-24 12:33:56.000000000,2019-02-25 17:42:50.000000000,2019-02-25 17:42:50.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-24 12:33:56.000000000', 'files': ['spec/classes/murano_init_spec.rb', 'spec/classes/murano_cfapi_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/1ad62e6acbc35ac07bd87f88022f481d7b380d79', 'message': 'Change keystone v2.0 to v3\n\nChange-Id: I5d1e387b8e000cdac156afc8dbbcef9037e14659\n'}]",0,638943,1ad62e6acbc35ac07bd87f88022f481d7b380d79,7,3,1,16137,,,0,"Change keystone v2.0 to v3

Change-Id: I5d1e387b8e000cdac156afc8dbbcef9037e14659
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/43/638943/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/murano_init_spec.rb', 'spec/classes/murano_cfapi_spec.rb']",2,1ad62e6acbc35ac07bd87f88022f481d7b380d79,keystone-v3," :auth_url => 'http://127.0.0.1:5000/v3/', it { is_expected.to contain_murano_cfapi_config('cfapi/auth_url').with_value('http://127.0.0.1:5000/v3/') }"," :auth_url => 'http://127.0.0.1:5000/v2.0/', it { is_expected.to contain_murano_cfapi_config('cfapi/auth_url').with_value('http://127.0.0.1:5000/v2.0/') }",4,4
openstack%2Fpuppet-octavia~master~Ibf624c393f6b03a1ab00c98e8694f04aa10dcaaa,openstack/puppet-octavia,master,Ibf624c393f6b03a1ab00c98e8694f04aa10dcaaa,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 23:08:43.000000000,2019-02-25 17:42:50.000000000,2019-02-25 17:42:50.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 23:08:43.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-ff9dcddda18683a6.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/ed586f170a60938256bbc39f336989a26a7c41a3', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: Ibf624c393f6b03a1ab00c98e8694f04aa10dcaaa\n'}]",0,638905,ed586f170a60938256bbc39f336989a26a7c41a3,7,3,1,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: Ibf624c393f6b03a1ab00c98e8694f04aa10dcaaa
",git fetch https://review.opendev.org/openstack/puppet-octavia refs/changes/05/638905/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-ff9dcddda18683a6.yaml'],1,ed586f170a60938256bbc39f336989a26a7c41a3,release-note-ubuntu-py3,"--- prelude: > In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,10,0
openstack%2Fpuppet-octavia~master~I12c38f4e42684b65d55d1d94ca6d6fb4042a6a8b,openstack/puppet-octavia,master,I12c38f4e42684b65d55d1d94ca6d6fb4042a6a8b,Use validate_legacy,MERGED,2019-02-23 21:25:17.000000000,2019-02-25 17:42:49.000000000,2019-02-25 17:42:49.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 21:25:17.000000000', 'files': ['manifests/health_manager.pp', 'manifests/worker.pp', 'manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/9825c437e562e5cf876e7dec9503cc96e15fa411', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I12c38f4e42684b65d55d1d94ca6d6fb4042a6a8b\n'}]",0,638861,9825c437e562e5cf876e7dec9503cc96e15fa411,7,3,1,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: I12c38f4e42684b65d55d1d94ca6d6fb4042a6a8b
",git fetch https://review.opendev.org/openstack/puppet-octavia refs/changes/61/638861/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/health_manager.pp', 'manifests/worker.pp', 'manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp']",6,9825c437e562e5cf876e7dec9503cc96e15fa411,validate_legacy," validate_legacy(Hash, 'validate_hash', $policies)", validate_hash($policies),7,8
openstack%2Foslo.messaging~stable%2Frocky~I0b094f32dec24c70f95ccd509164a14a71fcfc7d,openstack/oslo.messaging,stable/rocky,I0b094f32dec24c70f95ccd509164a14a71fcfc7d,Add release note for amqp library TLS/SSL error,MERGED,2019-02-21 16:50:55.000000000,2019-02-25 17:40:52.000000000,2019-02-25 17:40:51.000000000,"[{'_account_id': 6928}, {'_account_id': 8770}, {'_account_id': 19307}, {'_account_id': 22348}, {'_account_id': 23922}, {'_account_id': 29364}]","[{'number': 1, 'created': '2019-02-21 16:50:55.000000000', 'files': ['releasenotes/notes/amqp-tls-issue-7e6cc523e267f336.yaml'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/693cd964e02002ab28366df08c5b75f396198492', 'message': 'Add release note for amqp library TLS/SSL error\n\nChange-Id: I0b094f32dec24c70f95ccd509164a14a71fcfc7d\nRelated-Bug: #1800957\n'}]",0,638461,693cd964e02002ab28366df08c5b75f396198492,16,6,1,8770,,,0,"Add release note for amqp library TLS/SSL error

Change-Id: I0b094f32dec24c70f95ccd509164a14a71fcfc7d
Related-Bug: #1800957
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/61/638461/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/amqp-tls-issue-7e6cc523e267f336.yaml'],1,693cd964e02002ab28366df08c5b75f396198492,bug/1800957,--- issues: - | A bug in the ``amqp`` python library can cause the connection to the RabbitMQ broker to hang when using SSL/TLS. This results in frequent errors such as this:: MessagingTimeout: Timed out waiting for a reply to message ID ae039d1695984addbfaaef032ce4fda3 (see `bug 1800957 <https://bugs.launchpad.net/oslo.messaging/+bug/1800957>`_). This bug has been fixed in `v2.4.1 of amqp <https://github.com/celery/py-amqp/commit/bf122a05a21a8cc5bca314b0979f32c8026fc66e>`_. It is recommended that deployments using SSL/TLS upgrade the amqp library to v2.4.1 or later. ,,17,0
openstack%2Fpuppet-barbican~master~I5ec5a18637ba55ffce03fa3445bda8c17a1bd486,openstack/puppet-barbican,master,I5ec5a18637ba55ffce03fa3445bda8c17a1bd486,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 22:55:05.000000000,2019-02-25 17:38:53.000000000,2019-02-25 17:38:53.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 22:55:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/a787ec54325fe6cd3cb2fc9de4d3327a39a1d23d', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: I5ec5a18637ba55ffce03fa3445bda8c17a1bd486\n'}, {'number': 2, 'created': '2019-02-23 23:14:50.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-c434af51d53710d5.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/018dd123f12d596d381d48d7348568eeef7e0341', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: I5ec5a18637ba55ffce03fa3445bda8c17a1bd486\n'}]",0,638883,018dd123f12d596d381d48d7348568eeef7e0341,9,3,2,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: I5ec5a18637ba55ffce03fa3445bda8c17a1bd486
",git fetch https://review.opendev.org/openstack/puppet-barbican refs/changes/83/638883/2 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-c434af51d53710d5.yaml'],1,a787ec54325fe6cd3cb2fc9de4d3327a39a1d23d,release-note-ubuntu-py3,"--- prelude: - | In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,11,0
openstack%2Fpuppet-barbican~master~I740270de4abe95be5223db4dbb9ce2ecbe93a7c0,openstack/puppet-barbican,master,I740270de4abe95be5223db4dbb9ce2ecbe93a7c0,Use validate_legacy,MERGED,2019-02-10 12:42:34.000000000,2019-02-25 17:38:52.000000000,2019-02-25 17:38:52.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-10 12:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/57891492bd521148ce9f6ce38d4d5ba4058422e2', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I740270de4abe95be5223db4dbb9ce2ecbe93a7c0\n'}, {'number': 2, 'created': '2019-02-23 09:58:22.000000000', 'files': ['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/ef6070bb90f01f6a83fafd983d53f8cd10c87beb', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I740270de4abe95be5223db4dbb9ce2ecbe93a7c0\n'}]",0,636048,ef6070bb90f01f6a83fafd983d53f8cd10c87beb,10,4,2,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: I740270de4abe95be5223db4dbb9ce2ecbe93a7c0
",git fetch https://review.opendev.org/openstack/puppet-barbican refs/changes/48/636048/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp']",4,57891492bd521148ce9f6ce38d4d5ba4058422e2,validate_legacy," validate_legacy(Hash, 'validate_hash', $policies)", validate_hash($policies),6,6
openstack%2Fpuppet-magnum~master~Icf9daf5525c8b27966e800bbe3c12623607f1d7d,openstack/puppet-magnum,master,Icf9daf5525c8b27966e800bbe3c12623607f1d7d,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 23:04:46.000000000,2019-02-25 17:36:49.000000000,2019-02-25 17:36:49.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 23:04:46.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-577f046d6f07b064.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/0cdb889d701536e4f3a479e2259618af3973dd34', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: Icf9daf5525c8b27966e800bbe3c12623607f1d7d\n'}]",0,638898,0cdb889d701536e4f3a479e2259618af3973dd34,7,3,1,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: Icf9daf5525c8b27966e800bbe3c12623607f1d7d
",git fetch https://review.opendev.org/openstack/puppet-magnum refs/changes/98/638898/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-577f046d6f07b064.yaml'],1,0cdb889d701536e4f3a479e2259618af3973dd34,release-note-ubuntu-py3,"--- prelude: > In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,10,0
openstack%2Fpuppet-magnum~master~Ic0a6cd47029a77c96763f00fe625e21bdb97f3d9,openstack/puppet-magnum,master,Ic0a6cd47029a77c96763f00fe625e21bdb97f3d9,Use validate_legacy,MERGED,2019-02-23 11:35:26.000000000,2019-02-25 17:36:48.000000000,2019-02-25 17:36:48.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 11:35:26.000000000', 'files': ['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/dd1a96a9d6c317916229341facb74fc7e76147f6', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: Ic0a6cd47029a77c96763f00fe625e21bdb97f3d9\n'}]",0,638814,dd1a96a9d6c317916229341facb74fc7e76147f6,7,3,1,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: Ic0a6cd47029a77c96763f00fe625e21bdb97f3d9
",git fetch https://review.opendev.org/openstack/puppet-magnum refs/changes/14/638814/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp']",4,dd1a96a9d6c317916229341facb74fc7e76147f6,validate_legacy," validate_legacy(Hash, 'validate_hash', $policies)", validate_hash($policies),6,6
openstack%2Fpuppet-openstack-cookiecutter~master~I5ef9abcbd4a349495d6cf12d3a4a93b6223b9229,openstack/puppet-openstack-cookiecutter,master,I5ef9abcbd4a349495d6cf12d3a4a93b6223b9229,Use validate_legacy,MERGED,2019-02-10 12:15:30.000000000,2019-02-25 17:32:01.000000000,2019-02-25 17:32:01.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-10 12:15:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-cookiecutter/commit/fbd5afc704e8f3f5072397b9227e60476ae41cbd', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I5ef9abcbd4a349495d6cf12d3a4a93b6223b9229\n'}, {'number': 2, 'created': '2019-02-23 09:57:20.000000000', 'files': ['puppet-{{cookiecutter.project_name}}/manifests/config.pp', 'puppet-{{cookiecutter.project_name}}/manifests/db.pp', 'puppet-{{cookiecutter.project_name}}/manifests/policy.pp', 'puppet-{{cookiecutter.project_name}}/manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-cookiecutter/commit/06b83db6d4ea0710e1536aabdd8cf1d2c4b8dde2', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I5ef9abcbd4a349495d6cf12d3a4a93b6223b9229\n'}]",0,636047,06b83db6d4ea0710e1536aabdd8cf1d2c4b8dde2,10,4,2,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: I5ef9abcbd4a349495d6cf12d3a4a93b6223b9229
",git fetch https://review.opendev.org/openstack/puppet-openstack-cookiecutter refs/changes/47/636047/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet-{{cookiecutter.project_name}}/manifests/config.pp', 'puppet-{{cookiecutter.project_name}}/manifests/db.pp', 'puppet-{{cookiecutter.project_name}}/manifests/policy.pp', 'puppet-{{cookiecutter.project_name}}/manifests/db/mysql.pp']",4,fbd5afc704e8f3f5072397b9227e60476ae41cbd,validate_legacy," validate_legacy(String, 'validate_string', $password)", validate_string($password),5,5
openstack%2Fpuppet-murano~master~I73b1fc88dfa66dd3adc71a4fe85ed57b85ac0837,openstack/puppet-murano,master,I73b1fc88dfa66dd3adc71a4fe85ed57b85ac0837,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 23:07:09.000000000,2019-02-25 17:30:43.000000000,2019-02-25 17:30:43.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 23:07:09.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-9934ae2cee93268a.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/e911621dea6b8d807e49572d42b42a739c3e915e', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: I73b1fc88dfa66dd3adc71a4fe85ed57b85ac0837\n'}]",0,638902,e911621dea6b8d807e49572d42b42a739c3e915e,7,3,1,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: I73b1fc88dfa66dd3adc71a4fe85ed57b85ac0837
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/02/638902/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-9934ae2cee93268a.yaml'],1,e911621dea6b8d807e49572d42b42a739c3e915e,release-note-ubuntu-py3,"--- prelude: > In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,10,0
openstack%2Fpuppet-murano~master~I4da049ff59fd71403f4d00cfad8c5f56041e1e6e,openstack/puppet-murano,master,I4da049ff59fd71403f4d00cfad8c5f56041e1e6e,Use validate_legacy,MERGED,2019-02-23 22:23:19.000000000,2019-02-25 17:30:43.000000000,2019-02-25 17:30:43.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 22:23:19.000000000', 'files': ['manifests/db/postgresql_cfapi.pp', 'manifests/db_cfapi.pp', 'manifests/db/postgresql.pp', 'manifests/db/mysql_cfapi.pp', 'manifests/db.pp', 'manifests/init.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/52f9b4c5f709275a3bb97ccd106ca9ebc9a2bdea', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I4da049ff59fd71403f4d00cfad8c5f56041e1e6e\n'}]",0,638881,52f9b4c5f709275a3bb97ccd106ca9ebc9a2bdea,7,3,1,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: I4da049ff59fd71403f4d00cfad8c5f56041e1e6e
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/81/638881/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db/postgresql_cfapi.pp', 'manifests/db_cfapi.pp', 'manifests/db/mysql_cfapi.pp', 'manifests/db/postgresql.pp', 'manifests/db.pp', 'manifests/init.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp']",9,52f9b4c5f709275a3bb97ccd106ca9ebc9a2bdea,validate_legacy," validate_legacy(Hash, 'validate_hash', $policies)", validate_hash($policies),14,12
openstack%2Fpuppet-monasca~master~I6e75488ea8cfb5cb2be5fdb892355274ab18224b,openstack/puppet-monasca,master,I6e75488ea8cfb5cb2be5fdb892355274ab18224b,Use validate_legacy,MERGED,2019-02-23 11:44:25.000000000,2019-02-25 17:30:38.000000000,2019-02-25 17:30:38.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 11:44:25.000000000', 'files': ['manifests/virtualenv/agent_instance.pp', 'manifests/params.pp', 'manifests/virtualenv/instance.pp', 'manifests/config.pp'], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/c2aa24ac273f1b7addc900919153e382dc9ed30a', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I6e75488ea8cfb5cb2be5fdb892355274ab18224b\n'}]",0,638817,c2aa24ac273f1b7addc900919153e382dc9ed30a,7,3,1,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: I6e75488ea8cfb5cb2be5fdb892355274ab18224b
",git fetch https://review.opendev.org/openstack/puppet-monasca refs/changes/17/638817/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/virtualenv/agent_instance.pp', 'manifests/params.pp', 'manifests/virtualenv/instance.pp', 'manifests/config.pp']",4,c2aa24ac273f1b7addc900919153e382dc9ed30a,validate_legacy," validate_legacy(Hash, 'validate_hash', $monasca_config) validate_legacy(Hash, 'validate_hash', $monasca_ini)", validate_hash($monasca_config) validate_hash($monasca_ini),26,17
openstack%2Fpuppet-qdr~master~Ie05d6e6222224470450637f16691f933085e6520,openstack/puppet-qdr,master,Ie05d6e6222224470450637f16691f933085e6520,Use validate_legacy,MERGED,2019-02-23 21:44:57.000000000,2019-02-25 17:29:51.000000000,2019-02-25 17:29:51.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 21:44:57.000000000', 'files': ['manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-qdr/commit/fd5b7c4ec696df5b45c6c014b626b620859922b6', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: Ie05d6e6222224470450637f16691f933085e6520\n'}]",0,638869,fd5b7c4ec696df5b45c6c014b626b620859922b6,7,3,1,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: Ie05d6e6222224470450637f16691f933085e6520
",git fetch https://review.opendev.org/openstack/puppet-qdr refs/changes/69/638869/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,fd5b7c4ec696df5b45c6c014b626b620859922b6,validate_legacy," validate_legacy(Stdlib::Absolutepath, 'validate_absolute_path', $router_debug_dump) validate_legacy(Stdlib::Absolutepath, 'validate_absolute_path', $router_sasl_path) validate_legacy(String, 'validate_string', $router_sasl_name) validate_legacy(Enum['standalone', 'edge', 'interior'], 'validate_re', $router_mode, ['^(standalone$|edge$|interior$)']) validate_legacy(String, 'validate_string', $router_id) validate_legacy(String, 'validate_string', $listener_addr) validate_legacy(Integer, 'validate_re', $listener_port, ['\d+']) validate_legacy(Enum['yes', 'no'], 'validate_re', $listener_auth_peer, ['^(yes$|no$)']) validate_legacy(String, 'validate_string', $listener_sasl_mech)"," validate_absolute_path($router_debug_dump) validate_absolute_path($router_sasl_path) validate_string($router_sasl_name) validate_re($router_mode,'^(standalone$|edge$|interior$)') validate_string($router_id) validate_string($listener_addr) validate_re($listener_port, '\d+') validate_re($listener_auth_peer,'^(yes$|no$)') validate_string($listener_sasl_mech)",10,9
openstack%2Foslo.versionedobjects~master~I514a0e6d445e9a14e3c0279b4e9bebfa0940337d,openstack/oslo.versionedobjects,master,I514a0e6d445e9a14e3c0279b4e9bebfa0940337d,Allow lists to be generated from any non-string iterable,MERGED,2019-02-16 19:09:03.000000000,2019-02-25 17:29:33.000000000,2019-02-25 17:29:33.000000000,"[{'_account_id': 4257}, {'_account_id': 6928}, {'_account_id': 10980}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-16 19:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.versionedobjects/commit/48a9263640b32532b623b3a75c764420d773d880', 'message': 'Allow lists to be generated from any non-string iterable\n\nThe type check on the list field requires a list, though many\nobjects can be trivially iterated as lists, like sqlalchemy\nlazy query objects. Relax the check slightly to fit a broader\nrange of ""lists"".\n\nChange-Id: I514a0e6d445e9a14e3c0279b4e9bebfa0940337d\n'}, {'number': 2, 'created': '2019-02-18 16:51:32.000000000', 'files': ['oslo_versionedobjects/tests/test_fields.py', 'oslo_versionedobjects/fields.py'], 'web_link': 'https://opendev.org/openstack/oslo.versionedobjects/commit/bc203115b13ed689a7d8626de81093c7b6071c83', 'message': 'Allow lists to be generated from any non-string iterable\n\nThe type check on the list field requires a list, though many\nobjects can be trivially iterated as lists, like sqlalchemy\nlazy query objects. Relax the check slightly to fit a broader\nrange of ""lists"".\n\nChange-Id: I514a0e6d445e9a14e3c0279b4e9bebfa0940337d\n'}]",2,637389,bc203115b13ed689a7d8626de81093c7b6071c83,11,5,2,10980,,,0,"Allow lists to be generated from any non-string iterable

The type check on the list field requires a list, though many
objects can be trivially iterated as lists, like sqlalchemy
lazy query objects. Relax the check slightly to fit a broader
range of ""lists"".

Change-Id: I514a0e6d445e9a14e3c0279b4e9bebfa0940337d
",git fetch https://review.opendev.org/openstack/oslo.versionedobjects refs/changes/89/637389/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_versionedobjects/tests/test_fields.py', 'oslo_versionedobjects/fields.py']",2,48a9263640b32532b623b3a75c764420d773d880,allow-iterables-in-list," if (not (isinstance(value, list) or hasattr(value, '__iter__')) or isinstance(value, six.string_types)):"," if not isinstance(value, list):",38,1
openstack%2Fpuppet-glare~master~I1408c988964614c4cf8e1cb8a03e3a874ef813ca,openstack/puppet-glare,master,I1408c988964614c4cf8e1cb8a03e3a874ef813ca,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 23:01:27.000000000,2019-02-25 17:28:52.000000000,2019-02-25 17:28:52.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 23:01:27.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-9ec9bd0bc2ab6a00.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-glare/commit/f365fd8d5e0550ccd1faf87f5740421f4991e696', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: I1408c988964614c4cf8e1cb8a03e3a874ef813ca\n'}]",0,638892,f365fd8d5e0550ccd1faf87f5740421f4991e696,7,3,1,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: I1408c988964614c4cf8e1cb8a03e3a874ef813ca
",git fetch https://review.opendev.org/openstack/puppet-glare refs/changes/92/638892/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-9ec9bd0bc2ab6a00.yaml'],1,f365fd8d5e0550ccd1faf87f5740421f4991e696,release-note-ubuntu-py3,"--- prelude: > In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,10,0
openstack%2Fpuppet-vitrage~master~I35c19c0cdfec2241d56c3a3ca0ae96388dcdeddc,openstack/puppet-vitrage,master,I35c19c0cdfec2241d56c3a3ca0ae96388dcdeddc,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 23:13:20.000000000,2019-02-25 17:26:04.000000000,2019-02-25 17:26:04.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 23:13:20.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-7f6e78b71b71afbb.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-vitrage/commit/3af0316cf67fd3818c6210c00fdcc13c98cd239b', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: I35c19c0cdfec2241d56c3a3ca0ae96388dcdeddc\n'}]",0,638916,3af0316cf67fd3818c6210c00fdcc13c98cd239b,7,3,1,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: I35c19c0cdfec2241d56c3a3ca0ae96388dcdeddc
",git fetch https://review.opendev.org/openstack/puppet-vitrage refs/changes/16/638916/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-7f6e78b71b71afbb.yaml'],1,3af0316cf67fd3818c6210c00fdcc13c98cd239b,release-note-ubuntu-py3,"--- prelude: > In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,10,0
openstack%2Fpuppet-freezer~master~I4228095d914a94ef46e025c26da480eb520caf5b,openstack/puppet-freezer,master,I4228095d914a94ef46e025c26da480eb520caf5b,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 22:58:53.000000000,2019-02-25 17:25:10.000000000,2019-02-25 17:25:10.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 22:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-freezer/commit/913bccd2831c0bf3e251318cb5c626b07cdd2487', 'message': 'ADd release note about Ubuntu py3 upgrade\n\nChange-Id: I4228095d914a94ef46e025c26da480eb520caf5b\n'}, {'number': 2, 'created': '2019-02-23 23:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-freezer/commit/74643d78c5559b5fd363984ea0b6c33a2cb739bf', 'message': 'ADd release note about Ubuntu py3 upgrade\n\nChange-Id: I4228095d914a94ef46e025c26da480eb520caf5b\n'}, {'number': 3, 'created': '2019-02-24 16:26:45.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-9ff03e7ac67f0df8.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-freezer/commit/89c8c7c6c5bb7ef442391db5de04e35f3209acca', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: I4228095d914a94ef46e025c26da480eb520caf5b\n'}]",0,638890,89c8c7c6c5bb7ef442391db5de04e35f3209acca,11,3,3,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: I4228095d914a94ef46e025c26da480eb520caf5b
",git fetch https://review.opendev.org/openstack/puppet-freezer refs/changes/90/638890/2 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-9ff03e7ac67f0df8.yaml'],1,913bccd2831c0bf3e251318cb5c626b07cdd2487,release-note-ubuntu-py3,"--- prelude: - | In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,11,0
openstack%2Fpuppet-congress~master~Ie131cf519f3377defdc00e27ec81399b869e187f,openstack/puppet-congress,master,Ie131cf519f3377defdc00e27ec81399b869e187f,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 22:57:12.000000000,2019-02-25 17:24:54.000000000,2019-02-25 17:24:54.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 22:57:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-congress/commit/e4a865524398a4761fe205b4fb1f64738bfa2f46', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: Ie131cf519f3377defdc00e27ec81399b869e187f\n'}, {'number': 2, 'created': '2019-02-23 23:15:56.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-89287b4ad32a0739.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-congress/commit/c3e1b868149b81d0d9bd4561cd31785ea910d9f6', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: Ie131cf519f3377defdc00e27ec81399b869e187f\n'}]",0,638887,c3e1b868149b81d0d9bd4561cd31785ea910d9f6,9,3,2,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: Ie131cf519f3377defdc00e27ec81399b869e187f
",git fetch https://review.opendev.org/openstack/puppet-congress refs/changes/87/638887/2 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-89287b4ad32a0739.yaml'],1,e4a865524398a4761fe205b4fb1f64738bfa2f46,release-note-ubuntu-py3,"--- prelude: - | In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,11,0
openstack%2Fironic-inspector~master~I4702ed7372d0e60ed6252879a7496649a0453b84,openstack/ironic-inspector,master,I4702ed7372d0e60ed6252879a7496649a0453b84,Revise driver api for introspection data backend,MERGED,2019-02-19 03:31:36.000000000,2019-02-25 17:24:50.000000000,2019-02-25 17:24:50.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-02-19 03:31:36.000000000', 'files': ['ironic_inspector/process.py', 'ironic_inspector/plugins/introspection_data.py', 'ironic_inspector/test/unit/test_plugins_introspection_data.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/8b2fb384c342c5baa8e045ddbe0e6bbdd27ce89d', 'message': ""Revise driver api for introspection data backend\n\nThe patch revises driver interface for the introspection data\nbackends. Previously getting introspection data supports node\nuuid/name, while saving takes a node_info object, which is not\nconsistent and makes migration tool looks weird if implemented\nbased upon it.\n\nFor the get() interface, actually only uuid will be passed in,\nso it's narrowed down to accept only uuids, logic names will be\nconverted from api level if there is a need.\n\nThe save() interface is changed to accept node uuid instead of\nnode_info, which is consistent with the get() interface.\n\nChange-Id: I4702ed7372d0e60ed6252879a7496649a0453b84\nStory: 1726713\nTask: 11373\n""}]",4,637673,8b2fb384c342c5baa8e045ddbe0e6bbdd27ce89d,11,4,1,24828,,,0,"Revise driver api for introspection data backend

The patch revises driver interface for the introspection data
backends. Previously getting introspection data supports node
uuid/name, while saving takes a node_info object, which is not
consistent and makes migration tool looks weird if implemented
based upon it.

For the get() interface, actually only uuid will be passed in,
so it's narrowed down to accept only uuids, logic names will be
converted from api level if there is a need.

The save() interface is changed to accept node uuid instead of
node_info, which is consistent with the get() interface.

Change-Id: I4702ed7372d0e60ed6252879a7496649a0453b84
Story: 1726713
Task: 11373
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/73/637673/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_inspector/process.py', 'ironic_inspector/plugins/introspection_data.py', 'ironic_inspector/test/unit/test_plugins_introspection_data.py']",3,8b2fb384c342c5baa8e045ddbe0e6bbdd27ce89d,1726713," def _create_node(self): session = db.get_writer_session() with session.begin(): db.Node(uuid=self.node_info.uuid, state=istate.States.starting).save(session) self._create_node() self.driver.save(self.node_info.uuid, self.data) self.driver.save(self.node_info.uuid, self.data)"," self.driver.save(self.node_info, self.data) self.driver.save(self.node_info, self.data)",43,32
openstack%2Fpuppet-zaqar~master~Ia7fdf94022e955af88abbe1329f8bf08278e45c7,openstack/puppet-zaqar,master,Ia7fdf94022e955af88abbe1329f8bf08278e45c7,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 23:14:13.000000000,2019-02-25 17:23:49.000000000,2019-02-25 17:23:49.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 23:14:13.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-e6f4aba55ea1c376.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-zaqar/commit/bd806884c84eccc500b52fb566bcdbf870b32ddd', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: Ia7fdf94022e955af88abbe1329f8bf08278e45c7\n'}]",0,638918,bd806884c84eccc500b52fb566bcdbf870b32ddd,7,3,1,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: Ia7fdf94022e955af88abbe1329f8bf08278e45c7
",git fetch https://review.opendev.org/openstack/puppet-zaqar refs/changes/18/638918/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-e6f4aba55ea1c376.yaml'],1,bd806884c84eccc500b52fb566bcdbf870b32ddd,release-note-ubuntu-py3,"--- prelude: > In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,10,0
openstack%2Fpuppet-congress~master~Ic534a8249e3defc5f33a34580eaba8f478c4755a,openstack/puppet-congress,master,Ic534a8249e3defc5f33a34580eaba8f478c4755a,Use validate_legacy,MERGED,2019-02-10 13:01:22.000000000,2019-02-25 17:23:46.000000000,2019-02-25 17:23:46.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-10 13:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-congress/commit/52a8f84fb51668e67e5370b1d64b5addf234d04a', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: Ic534a8249e3defc5f33a34580eaba8f478c4755a\n'}, {'number': 2, 'created': '2019-02-23 10:01:51.000000000', 'files': ['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-congress/commit/614d13d9699737eac60fb630f14ed60510be2d85', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: Ic534a8249e3defc5f33a34580eaba8f478c4755a\n'}]",0,636054,614d13d9699737eac60fb630f14ed60510be2d85,10,4,2,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: Ic534a8249e3defc5f33a34580eaba8f478c4755a
",git fetch https://review.opendev.org/openstack/puppet-congress refs/changes/54/636054/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp']",4,52a8f84fb51668e67e5370b1d64b5addf234d04a,validate_legacy," validate_legacy(Hash, 'validate_hash', $policies)", validate_hash($policies),6,6
openstack%2Fpuppet-cloudkitty~master~Ie68f54d8053113d7bb065d86c94fd1d108383897,openstack/puppet-cloudkitty,master,Ie68f54d8053113d7bb065d86c94fd1d108383897,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 22:56:37.000000000,2019-02-25 17:23:05.000000000,2019-02-25 17:23:04.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 22:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cloudkitty/commit/dfe3d73d4979924c6a1255e94509ec944f733974', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: Ie68f54d8053113d7bb065d86c94fd1d108383897\n'}, {'number': 2, 'created': '2019-02-23 23:15:38.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-a14bf4e2035ce8f5.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-cloudkitty/commit/e8421dfbb4624843b3369e9ddfc199729978bfb4', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: Ie68f54d8053113d7bb065d86c94fd1d108383897\n'}]",0,638886,e8421dfbb4624843b3369e9ddfc199729978bfb4,9,3,2,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: Ie68f54d8053113d7bb065d86c94fd1d108383897
",git fetch https://review.opendev.org/openstack/puppet-cloudkitty refs/changes/86/638886/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-a14bf4e2035ce8f5.yaml'],1,dfe3d73d4979924c6a1255e94509ec944f733974,release-note-ubuntu-py3,"--- prelude: - | In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,11,0
openstack%2Fpuppet-cloudkitty~master~Ib6f668fed59f8285edafa67f12135fc5032e8f72,openstack/puppet-cloudkitty,master,Ib6f668fed59f8285edafa67f12135fc5032e8f72,Use validate_legacy,MERGED,2019-02-10 12:59:24.000000000,2019-02-25 17:23:04.000000000,2019-02-25 17:23:04.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-10 12:59:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cloudkitty/commit/85ebd6cb7f8cad8231c74772bd21f63e13e655b4', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: Ib6f668fed59f8285edafa67f12135fc5032e8f72\n'}, {'number': 2, 'created': '2019-02-23 10:01:07.000000000', 'files': ['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cloudkitty/commit/457ded9269e76412a3bfb32371733caf655b3fd5', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: Ib6f668fed59f8285edafa67f12135fc5032e8f72\n'}]",0,636053,457ded9269e76412a3bfb32371733caf655b3fd5,10,4,2,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: Ib6f668fed59f8285edafa67f12135fc5032e8f72
",git fetch https://review.opendev.org/openstack/puppet-cloudkitty refs/changes/53/636053/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp']",4,85ebd6cb7f8cad8231c74772bd21f63e13e655b4,validate_legacy," validate_legacy(Hash, 'validate_hash', $policies)", validate_hash($policies),6,6
openstack%2Fpuppet-glare~master~I41d8fc86b439914098a87b4ae6da6c8c672a399d,openstack/puppet-glare,master,I41d8fc86b439914098a87b4ae6da6c8c672a399d,Use validate_legacy,MERGED,2019-02-23 11:00:36.000000000,2019-02-25 17:21:23.000000000,2019-02-25 17:21:23.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 11:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glare/commit/94debaad0fcdee53dcd1bbf9b3e6c308ee524ab7', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I41d8fc86b439914098a87b4ae6da6c8c672a399d\n'}, {'number': 2, 'created': '2019-02-23 13:50:34.000000000', 'files': ['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glare/commit/5bc7e0a115cea9176d9ac239bb8f9f54e9f8ae8f', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I41d8fc86b439914098a87b4ae6da6c8c672a399d\n'}]",0,638808,5bc7e0a115cea9176d9ac239bb8f9f54e9f8ae8f,9,3,2,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: I41d8fc86b439914098a87b4ae6da6c8c672a399d
",git fetch https://review.opendev.org/openstack/puppet-glare refs/changes/08/638808/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp']",4,94debaad0fcdee53dcd1bbf9b3e6c308ee524ab7,validate_legacy," validate_legacy(Hash, 'validate_hash', $policies)", validate_hash($policies),6,6
openstack%2Fpuppet-freezer~master~I62d32faa75928ecca27a10480ce8823aaa03fafb,openstack/puppet-freezer,master,I62d32faa75928ecca27a10480ce8823aaa03fafb,Use validate_legacy,MERGED,2019-02-23 10:49:52.000000000,2019-02-25 17:19:50.000000000,2019-02-25 17:19:50.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 10:49:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-freezer/commit/7921a69e20b52de582114b1be7206c402ba3055d', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I62d32faa75928ecca27a10480ce8823aaa03fafb\n'}, {'number': 2, 'created': '2019-02-23 13:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-freezer/commit/48a40f9076f471a069dd8e268c5a8dacfc4bb681', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I62d32faa75928ecca27a10480ce8823aaa03fafb\n'}, {'number': 3, 'created': '2019-02-23 15:02:14.000000000', 'files': ['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-freezer/commit/e54dc558d7fdc8131018542a94f96fee7a521f28', 'message': 'Use validate_legacy\n\nThis changes all the puppet 3 validate_* functions\nto use the validate_legacy function.\n\nThe validate_legacy function has been available since\nabout three years but require Puppet >= 4.4.0 and since\nthere is Puppet 4.10.12 as latest we should assume people\nare running a fairly new Puppet 4 version.\n\nThis is the first step to then remove all validate function\ncalls and use proper types for parameter as described in spec [1].\n\n[1] https://review.openstack.org/#/c/568929/\n\nChange-Id: I62d32faa75928ecca27a10480ce8823aaa03fafb\n'}]",0,638805,e54dc558d7fdc8131018542a94f96fee7a521f28,11,3,3,16137,,,0,"Use validate_legacy

This changes all the puppet 3 validate_* functions
to use the validate_legacy function.

The validate_legacy function has been available since
about three years but require Puppet >= 4.4.0 and since
there is Puppet 4.10.12 as latest we should assume people
are running a fairly new Puppet 4 version.

This is the first step to then remove all validate function
calls and use proper types for parameter as described in spec [1].

[1] https://review.openstack.org/#/c/568929/

Change-Id: I62d32faa75928ecca27a10480ce8823aaa03fafb
",git fetch https://review.opendev.org/openstack/puppet-freezer refs/changes/05/638805/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db.pp', 'manifests/db/mysql.pp', 'manifests/config.pp', 'manifests/policy.pp']",4,7921a69e20b52de582114b1be7206c402ba3055d,validate_legacy," validate_legacy(Hash, 'validate_hash', $policies)", validate_hash($policies),6,6
openstack%2Fpuppet-swift~master~If4e86e269e379cd5eadd05d82d1d7ff9361ba866,openstack/puppet-swift,master,If4e86e269e379cd5eadd05d82d1d7ff9361ba866,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 23:11:40.000000000,2019-02-25 17:17:32.000000000,2019-02-25 17:17:32.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 23:11:40.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-166e8825549d2981.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/828b55826da729cf43b2763716d8fc03039e36ac', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: If4e86e269e379cd5eadd05d82d1d7ff9361ba866\n'}]",0,638912,828b55826da729cf43b2763716d8fc03039e36ac,7,3,1,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: If4e86e269e379cd5eadd05d82d1d7ff9361ba866
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/12/638912/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-166e8825549d2981.yaml'],1,828b55826da729cf43b2763716d8fc03039e36ac,release-note-ubuntu-py3,"--- prelude: > In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,10,0
openstack%2Fpuppet-nova~master~Id7eecf9184c8298995200f550f7d20a2f5fb66b4,openstack/puppet-nova,master,Id7eecf9184c8298995200f550f7d20a2f5fb66b4,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 23:08:16.000000000,2019-02-25 17:12:01.000000000,2019-02-25 17:12:01.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 23:08:16.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-79c7805cfb29dc0f.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/25062453a3aa95945a6163ee03d859659ec639b2', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: Id7eecf9184c8298995200f550f7d20a2f5fb66b4\n'}]",0,638904,25062453a3aa95945a6163ee03d859659ec639b2,7,3,1,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: Id7eecf9184c8298995200f550f7d20a2f5fb66b4
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/04/638904/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-79c7805cfb29dc0f.yaml'],1,25062453a3aa95945a6163ee03d859659ec639b2,release-note-ubuntu-py3,"--- prelude: > In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,10,0
openstack%2Fnova~master~I8972574b3ab24b23986b21606ac06135ad224b2a,openstack/nova,master,I8972574b3ab24b23986b21606ac06135ad224b2a,"Revert ""Fail to live migration if instance has a NUMA topology""",ABANDONED,2019-02-23 21:44:40.000000000,2019-02-25 17:08:48.000000000,,"[{'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-23 21:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2dd94ac97a3ce70a496a2a5d4233be54019efa96', 'message': 'Revert ""Fail to live migration if instance has a NUMA topology""\n\nThis reverts commit ae2e5650d14a2c81dd397727d67b60f9b8dd0dd7.\n\nNow that we have NUMA live migration support, we can revert this\nworkaround.\n\nConflicts:\nIn nova/api/openstack/compute/migrate_server.py because 3730bd0791\nIn nova/conf/workarounds.py because d6c1f6a103\n\nChange-Id: I8972574b3ab24b23986b21606ac06135ad224b2a\n'}, {'number': 2, 'created': '2019-02-23 21:55:20.000000000', 'files': ['releasenotes/notes/disable-live-migration-with-numa-bc710a1bcde25957.yaml', 'doc/source/common/numa-live-migration-warning.txt', 'nova/conductor/tasks/live_migrate.py', 'nova/api/openstack/compute/migrate_server.py', 'nova/tests/unit/conductor/tasks/test_live_migrate.py', 'doc/source/admin/adv-config.rst', 'nova/tests/unit/api/openstack/compute/admin_only_action_common.py', 'doc/source/admin/configuring-migrations.rst', 'doc/source/user/feature-classification.rst', 'nova/conf/workarounds.py', 'doc/source/admin/cpu-topologies.rst', 'nova/tests/unit/api/openstack/compute/test_migrate_server.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/49a87d6fe332b02e8dca872a8b8d5197c7ba1fb5', 'message': 'Revert ""Fail to live migration if instance has a NUMA topology""\n\nThis reverts commit ae2e5650d14a2c81dd397727d67b60f9b8dd0dd7.\n\nNow that we have NUMA live migration support, we can revert this\nworkaround.\n\nConflicts:\nIn nova/api/openstack/compute/migrate_server.py because 3730bd0791\nIn nova/conf/workarounds.py because d6c1f6a103\n\nChange-Id: I8972574b3ab24b23986b21606ac06135ad224b2a\n'}]",4,638868,49a87d6fe332b02e8dca872a8b8d5197c7ba1fb5,15,9,2,8864,,,0,"Revert ""Fail to live migration if instance has a NUMA topology""

This reverts commit ae2e5650d14a2c81dd397727d67b60f9b8dd0dd7.

Now that we have NUMA live migration support, we can revert this
workaround.

Conflicts:
In nova/api/openstack/compute/migrate_server.py because 3730bd0791
In nova/conf/workarounds.py because d6c1f6a103

Change-Id: I8972574b3ab24b23986b21606ac06135ad224b2a
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/638868/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/disable-live-migration-with-numa-bc710a1bcde25957.yaml', 'doc/source/common/numa-live-migration-warning.txt', 'nova/conductor/tasks/live_migrate.py', 'nova/api/openstack/compute/migrate_server.py', 'nova/tests/unit/conductor/tasks/test_live_migrate.py', 'doc/source/admin/adv-config.rst', 'nova/tests/unit/api/openstack/compute/admin_only_action_common.py', 'doc/source/admin/configuring-migrations.rst', 'doc/source/user/feature-classification.rst', 'nova/conf/workarounds.py', 'doc/source/admin/cpu-topologies.rst', 'nova/tests/unit/api/openstack/compute/test_migrate_server.py']",12,2dd94ac97a3ce70a496a2a5d4233be54019efa96,bp/numa-aware-live-migration," expected_attrs=None, expected_attrs=None, expected_attrs=None, expected_attrs=None,"," expected_attrs=['numa_topology'], expected_attrs=['numa_topology'], expected_attrs=['numa_topology'], expected_attrs=['numa_topology'],",13,180
openstack%2Fpuppet-keystone~master~I185a9c84954ea1489c98401068f1d08ccdde9c9c,openstack/puppet-keystone,master,I185a9c84954ea1489c98401068f1d08ccdde9c9c,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 23:04:18.000000000,2019-02-25 17:08:01.000000000,2019-02-25 17:08:01.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 23:04:18.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-36f43a17c66cd38c.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/92a3bc4dc9697898e92a957a169c948136b0b1b4', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: I185a9c84954ea1489c98401068f1d08ccdde9c9c\n'}]",0,638897,92a3bc4dc9697898e92a957a169c948136b0b1b4,7,3,1,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: I185a9c84954ea1489c98401068f1d08ccdde9c9c
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/97/638897/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-36f43a17c66cd38c.yaml'],1,92a3bc4dc9697898e92a957a169c948136b0b1b4,release-note-ubuntu-py3,"--- prelude: > In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,10,0
openstack%2Fpuppet-ironic~master~I8661abba94285b117eda45484b7e48cb4d7de5ec,openstack/puppet-ironic,master,I8661abba94285b117eda45484b7e48cb4d7de5ec,Change keystone v2.0 url to v3,MERGED,2019-02-24 12:08:30.000000000,2019-02-25 16:44:08.000000000,2019-02-25 16:44:08.000000000,"[{'_account_id': 9414}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-24 12:08:30.000000000', 'files': ['spec/classes/ironic_inspector_spec.rb', 'releasenotes/notes/change-keystone-v3-704852e6e128c60f.yaml', 'manifests/inspector.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/a4055215c6da92068f78c5f46cdfd65ea1e81a36', 'message': 'Change keystone v2.0 url to v3\n\nChange-Id: I8661abba94285b117eda45484b7e48cb4d7de5ec\n'}]",0,638940,a4055215c6da92068f78c5f46cdfd65ea1e81a36,8,4,1,16137,,,0,"Change keystone v2.0 url to v3

Change-Id: I8661abba94285b117eda45484b7e48cb4d7de5ec
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/40/638940/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ironic_inspector_spec.rb', 'releasenotes/notes/change-keystone-v3-704852e6e128c60f.yaml', 'manifests/inspector.pp']",3,a4055215c6da92068f78c5f46cdfd65ea1e81a36,keystone-v3,"# Defautls to 'http://127.0.0.1:5000/v3'# Defautls to 'http://127.0.0.1:5000/v3' $ironic_auth_url = 'http://127.0.0.1:5000/v3', $swift_auth_url = 'http://127.0.0.1:5000/v3',","# Defautls to 'http://127.0.0.1:5000/v2.0'# Defautls to 'http://127.0.0.1:5000/v2.0' $ironic_auth_url = 'http://127.0.0.1:5000/v2.0', $swift_auth_url = 'http://127.0.0.1:5000/v2.0',",16,8
openstack%2Fkolla~master~I72e279e546e93200c714915a430d8f481c51ca20,openstack/kolla,master,I72e279e546e93200c714915a430d8f481c51ca20,Bump prometheus haproxy exporter version,ABANDONED,2019-02-25 15:43:00.000000000,2019-02-25 16:41:13.000000000,,[{'_account_id': 17669}],"[{'number': 1, 'created': '2019-02-25 15:43:00.000000000', 'files': ['docker/prometheus/prometheus-haproxy-exporter/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/3d7b694501be7467f9f9a61d77e9739c5f11b42f', 'message': 'Bump prometheus haproxy exporter version\n\nChange-Id: I72e279e546e93200c714915a430d8f481c51ca20\n'}]",0,639138,3d7b694501be7467f9f9a61d77e9739c5f11b42f,3,1,1,27420,,,0,"Bump prometheus haproxy exporter version

Change-Id: I72e279e546e93200c714915a430d8f481c51ca20
",git fetch https://review.opendev.org/openstack/kolla refs/changes/38/639138/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/prometheus/prometheus-haproxy-exporter/Dockerfile.j2'],1,3d7b694501be7467f9f9a61d77e9739c5f11b42f,,ENV haproxy_exporter_version=0.10.0,ENV haproxy_exporter_version=0.7.1,1,1
openstack%2Fnetworking-midonet~master~I52de37ee7a00e6a808cf1e33b4fdb1b3e462fa0b,openstack/networking-midonet,master,I52de37ee7a00e6a808cf1e33b4fdb1b3e462fa0b,Rename test-requirements to avoid being picked by devstack,MERGED,2019-02-04 07:28:30.000000000,2019-02-25 16:31:52.000000000,2019-02-25 16:31:43.000000000,"[{'_account_id': 156}, {'_account_id': 5367}, {'_account_id': 6854}, {'_account_id': 9925}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-04 07:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/a6b5727796cc63e37ea18284bd12fd83d0b511b3', 'message': 'rename test-requirements to avoid being picked by devstack\n\nChange-Id: I52de37ee7a00e6a808cf1e33b4fdb1b3e462fa0b\n'}, {'number': 2, 'created': '2019-02-04 12:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/3906512333ea8856bc0f496a5c0bc7d87a827649', 'message': 'rename test-requirements to avoid being picked by devstack\n\nChange-Id: I52de37ee7a00e6a808cf1e33b4fdb1b3e462fa0b\n'}, {'number': 3, 'created': '2019-02-05 02:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/f165ca011b455e5de63b69888dc69b814f57232a', 'message': ""Rename test-requirements to avoid being picked by devstack\n\n- Our test-requirements.txt has other neutron subprojects like\n  neutron-fwaas for unit tests.\n- Our devstack plugin uses pip_install to install ourselves.\n- pip_install unconditionally installs requirements from\n  test-requirements.\n\nAs a consequence, during a devstack run we installs neutron-fwaas\netc unconditionally. It isn't desirable because:\n\n- We don't want to install neutron-fwaas etc for our non -full jobs.\n  (Consider DB migration scripts, tempest plugins, etc.)\n- The version in test-requirements.txt might be inappropriate for\n  what we want to install for devstack based jobs.\n\nTo workaround the issue, this commit renames test-requirements.txt\nto avoid being picked by pip_install.\n\ntox-test-requirements.txt and doc/requirements.txt are identical\n(actually a symlink) for now. We can separate and slim them down\na bit later if desirable.\n\nAn alternative is to stop using pip_install. But it might be more\ncomplex than this commit given the amount of code it has.\n\nCloses-Bug: #1814615\nChange-Id: I52de37ee7a00e6a808cf1e33b4fdb1b3e462fa0b\n""}, {'number': 4, 'created': '2019-02-20 05:58:44.000000000', 'files': ['tox-test-requirements.txt', 'tools/install_venv.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/63e17eeb1880f863cbd3e9225833f1d822040863', 'message': ""Rename test-requirements to avoid being picked by devstack\n\n- Our test-requirements.txt has other neutron subprojects like\n  neutron-fwaas for unit tests.\n- Our devstack plugin uses pip_install to install ourselves.\n- pip_install unconditionally installs requirements from\n  test-requirements.\n\nAs a consequence, during a devstack run we installs neutron-fwaas\netc unconditionally. It isn't desirable because:\n\n- We don't want to install neutron-fwaas etc for our non -full jobs.\n  (Consider DB migration scripts, tempest plugins, etc.)\n- The version in test-requirements.txt might be inappropriate for\n  what we want to install for devstack based jobs.\n\nTo workaround the issue, this commit renames test-requirements.txt\nto avoid being picked by pip_install.\n\ntox-test-requirements.txt and doc/requirements.txt are identical\n(actually a symlink) for now. We can separate and slim them down\na bit later if desirable.\n\nAn alternative is to stop using pip_install. But it might be more\ncomplex than this commit given the amount of code it has.\n\nCloses-Bug: #1814615\nChange-Id: I52de37ee7a00e6a808cf1e33b4fdb1b3e462fa0b\n""}]",0,634636,63e17eeb1880f863cbd3e9225833f1d822040863,43,5,4,6854,,,0,"Rename test-requirements to avoid being picked by devstack

- Our test-requirements.txt has other neutron subprojects like
  neutron-fwaas for unit tests.
- Our devstack plugin uses pip_install to install ourselves.
- pip_install unconditionally installs requirements from
  test-requirements.

As a consequence, during a devstack run we installs neutron-fwaas
etc unconditionally. It isn't desirable because:

- We don't want to install neutron-fwaas etc for our non -full jobs.
  (Consider DB migration scripts, tempest plugins, etc.)
- The version in test-requirements.txt might be inappropriate for
  what we want to install for devstack based jobs.

To workaround the issue, this commit renames test-requirements.txt
to avoid being picked by pip_install.

tox-test-requirements.txt and doc/requirements.txt are identical
(actually a symlink) for now. We can separate and slim them down
a bit later if desirable.

An alternative is to stop using pip_install. But it might be more
complex than this commit given the amount of code it has.

Closes-Bug: #1814615
Change-Id: I52de37ee7a00e6a808cf1e33b4fdb1b3e462fa0b
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/36/634636/1 && git format-patch -1 --stdout FETCH_HEAD,"['tox-test-requirements.txt', 'tools/install_venv.py', 'tox.ini']",3,a6b5727796cc63e37ea18284bd12fd83d0b511b3,bug/1814615, -r{toxinidir}/tox-test-requirements.txt -r{toxinidir}/tox-test-requirements.txt, -r{toxinidir}/test-requirements.txt -r{toxinidir}/test-requirements.txt,3,3
openstack%2Foctavia-tempest-plugin~master~I1cf966595bbabd3e33b1e33033dfb6a8b16381f8,openstack/octavia-tempest-plugin,master,I1cf966595bbabd3e33b1e33033dfb6a8b16381f8,Update json module to jsonutils,MERGED,2019-02-21 04:22:47.000000000,2019-02-25 16:29:25.000000000,2019-02-25 16:29:25.000000000,"[{'_account_id': 2245}, {'_account_id': 6469}, {'_account_id': 21691}, {'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2019-02-21 04:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/eac9101dd4b637601ea4300603b7d0d35b69423d', 'message': 'Update json module to jsonutils\n\njson is deprecated, should use oslo_serialization.jsonutils\ninstead.\n\nChange-Id: I1cf966595bbabd3e33b1e33033dfb6a8b16381f8\n'}, {'number': 2, 'created': '2019-02-21 05:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/8c0483f445114897bafaf3f3154fb711d009f85b', 'message': 'Update json module to jsonutils\n\njson is deprecated, should use oslo_serialization.jsonutils\ninstead.\n\nChange-Id: I1cf966595bbabd3e33b1e33033dfb6a8b16381f8\n'}, {'number': 3, 'created': '2019-02-21 11:28:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/8313a2a5ccdf2d26035f83ffe9cdbafdb55971ac', 'message': 'Update json module to jsonutils\n\noslo project provide jsonutils, and octavia use it in many place[1],\nthis PS to update the remained json moudule to oslo jsonutils for\nconsistency.\n\n[1]: https://github.com/openstack/octavia-tempest-plugin/search?utf8=%E2%9C%93&q=jsonutils&type=\n\nChange-Id: I1cf966595bbabd3e33b1e33033dfb6a8b16381f8\n'}, {'number': 4, 'created': '2019-02-22 02:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/894d39a1f2edce81b9ec7a5cb45fd5fb9ef4ecd0', 'message': 'Update json module to jsonutils\n\noslo project provide jsonutils, and octavia use it in many place[1],\nthis PS to update the remained json moudule to oslo jsonutils for\nconsistency.\n\n[1]: https://github.com/openstack/octavia-tempest-plugin/search?utf8=%E2%9C%93&q=jsonutils&type=\n\nChange-Id: I1cf966595bbabd3e33b1e33033dfb6a8b16381f8\n'}, {'number': 5, 'created': '2019-02-25 04:45:29.000000000', 'files': ['requirements.txt', 'octavia_tempest_plugin/services/load_balancer/v2/member_client.py', 'octavia_tempest_plugin/services/load_balancer/v2/amphora_client.py', 'octavia_tempest_plugin/services/load_balancer/v2/base_client.py', 'octavia_tempest_plugin/services/load_balancer/v2/listener_client.py', 'octavia_tempest_plugin/services/load_balancer/v2/loadbalancer_client.py'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/45e6e668233eab28c2e3202c01b0ac66ab7e7e2a', 'message': 'Update json module to jsonutils\n\noslo project provide jsonutils, and octavia use it in many place[1],\nthis PS to update the remained json moudule to oslo jsonutils for\nconsistency.\n\n[1]: https://github.com/openstack/octavia-tempest-plugin/search?utf8=%E2%9C%93&q=jsonutils&type=\n\nChange-Id: I1cf966595bbabd3e33b1e33033dfb6a8b16381f8\n'}]",0,638332,45e6e668233eab28c2e3202c01b0ac66ab7e7e2a,22,5,5,22165,,,0,"Update json module to jsonutils

oslo project provide jsonutils, and octavia use it in many place[1],
this PS to update the remained json moudule to oslo jsonutils for
consistency.

[1]: https://github.com/openstack/octavia-tempest-plugin/search?utf8=%E2%9C%93&q=jsonutils&type=

Change-Id: I1cf966595bbabd3e33b1e33033dfb6a8b16381f8
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/32/638332/4 && git format-patch -1 --stdout FETCH_HEAD,"['octavia_tempest_plugin/services/load_balancer/v2/member_client.py', 'octavia_tempest_plugin/services/load_balancer/v2/amphora_client.py', 'octavia_tempest_plugin/services/load_balancer/v2/base_client.py', 'octavia_tempest_plugin/services/load_balancer/v2/loadbalancer_client.py']",4,eac9101dd4b637601ea4300603b7d0d35b69423d,,from oslo_serialization import jsonutils return jsonutils.loads(body.decode('utf-8'))['stats'] else: return jsonutils.loads(body.decode('utf-8')) return jsonutils.loads(body.decode('utf-8'))['statuses'] else: return jsonutils.loads(body.decode('utf-8')),import json return json.loads(body.decode('utf-8'))['stats'] else: return json.loads(body.decode('utf-8')) return json.loads(body.decode('utf-8'))['statuses'] else: return json.loads(body.decode('utf-8')),22,24
openstack%2Fnova~master~I419336ea845bdd11d02ba098d8a6521a730906fd,openstack/nova,master,I419336ea845bdd11d02ba098d8a6521a730906fd,"Refactor ""networks"" processing in ServersController.create",MERGED,2019-01-28 19:57:01.000000000,2019-02-25 16:25:31.000000000,2019-02-25 16:25:31.000000000,"[{'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-28 19:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/340888a279f5c9d5acac01b083a0b5624f7151d2', 'message': 'Refactor ""networks"" processing in ServersController.create\n\nIn an effort to try and de-clutter the create() method this\nchange refactors the code that processes the ""networks""\nrequest parameter to a separate method.\n\nChange-Id: I419336ea845bdd11d02ba098d8a6521a730906fd\n'}, {'number': 2, 'created': '2019-02-10 20:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b8f5a201d72c3e45938a1eb020c913fa0d51efe', 'message': 'Refactor ""networks"" processing in ServersController.create\n\nIn an effort to try and de-clutter the create() method this\nchange refactors the code that processes the ""networks""\nrequest parameter to a separate method.\n\nChange-Id: I419336ea845bdd11d02ba098d8a6521a730906fd\n'}, {'number': 3, 'created': '2019-02-23 20:06:55.000000000', 'files': ['nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/12d0d3a1ccfabdfb04e2d10b6360c2edadb52f0f', 'message': 'Refactor ""networks"" processing in ServersController.create\n\nIn an effort to try and de-clutter the create() method this\nchange refactors the code that processes the ""networks""\nrequest parameter to a separate method.\n\nChange-Id: I419336ea845bdd11d02ba098d8a6521a730906fd\n'}]",4,633594,12d0d3a1ccfabdfb04e2d10b6360c2edadb52f0f,84,16,3,6873,,,0,"Refactor ""networks"" processing in ServersController.create

In an effort to try and de-clutter the create() method this
change refactors the code that processes the ""networks""
request parameter to a separate method.

Change-Id: I419336ea845bdd11d02ba098d8a6521a730906fd
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/633594/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/servers.py'],1,340888a279f5c9d5acac01b083a0b5624f7151d2,server-create-handler-refactor," def _process_networks_for_create( self, context, target, server_dict, create_kwargs, supports_device_tagging): """"""Processes networks request parameter for server create :param context: The nova auth request context :param target: The target dict for ``context.can`` policy checks :param server_dict: The POST /servers request body ""server"" entry :param create_kwargs: dict that gets populated by this method and passed to nova.comptue.api.API.create() :param supports_device_tagging: True if a suitable microversion was provided for VIF tags during server create, False otherwise :returns: nova.objects.NetworkRequestList if networks were requested, else None :raises: webob.exc.HTTPBadRequest if the request parameters are invalid :raises: nova.exception.Forbidden if a policy check fails """""" requested_networks = server_dict.get('networks', None) if requested_networks is not None: requested_networks = self._get_requested_networks( requested_networks, supports_device_tagging) # Skip policy check for 'create:attach_network' if there is no # network allocation request. if requested_networks and len(requested_networks) and \ not requested_networks.no_allocate: context.can(server_policies.SERVERS % 'create:attach_network', target) create_kwargs['requested_networks'] = requested_networks self._process_networks_for_create( context, target, server_dict, create_kwargs, supports_device_tagging)"," requested_networks = server_dict.get('networks', None) if requested_networks is not None: requested_networks = self._get_requested_networks( requested_networks, supports_device_tagging) # Skip policy check for 'create:attach_network' if there is no # network allocation request. if requested_networks and len(requested_networks) and \ not requested_networks.no_allocate: context.can(server_policies.SERVERS % 'create:attach_network', target) requested_networks=requested_networks,",35,13
openstack%2Fironic~master~I409db4b73a2dedf283107708e7eea105549da867,openstack/ironic,master,I409db4b73a2dedf283107708e7eea105549da867,[trivial] Removing python 3.5 template jobs,MERGED,2019-02-22 11:24:26.000000000,2019-02-25 16:17:49.000000000,2019-02-25 16:17:48.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}, {'_account_id': 28429}]","[{'number': 1, 'created': '2019-02-22 11:24:26.000000000', 'files': ['zuul.d/project.yaml', 'doc/source/contributor/dev-quickstart.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/578805b34b3570bf8dd672ac0e13d8ddd55440b1', 'message': ""[trivial] Removing python 3.5 template jobs\n\nAlso correcting docs as we don't have a py35 environment\n\nChange-Id: I409db4b73a2dedf283107708e7eea105549da867\n""}]",2,638632,578805b34b3570bf8dd672ac0e13d8ddd55440b1,19,8,1,23851,,,0,"[trivial] Removing python 3.5 template jobs

Also correcting docs as we don't have a py35 environment

Change-Id: I409db4b73a2dedf283107708e7eea105549da867
",git fetch https://review.opendev.org/openstack/ironic refs/changes/32/638632/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'doc/source/contributor/dev-quickstart.rst']",2,578805b34b3570bf8dd672ac0e13d8ddd55440b1,python3-first," # to run the py27, py3 unit tests, and the style tests"," # to run the py27, py35 unit tests, and the style tests",1,2
openstack%2Ftripleo-heat-templates~master~If1e6e821aa5ea362cc328dd8d4cf8cafdca238cb,openstack/tripleo-heat-templates,master,If1e6e821aa5ea362cc328dd8d4cf8cafdca238cb,flatten gnocchi services config,ABANDONED,2019-02-21 17:20:22.000000000,2019-02-25 16:17:18.000000000,,"[{'_account_id': 360}, {'_account_id': 20868}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-21 17:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ad3d42a86df17bbf6ebd0f3cc1994bd03cf39caa', 'message': 'flatten gnocchi services config\n\nThis change combines the previous puppet and docker files\ninto a single file that performs the docker service installation\nand configuration.\n\nChange-Id: If1e6e821aa5ea362cc328dd8d4cf8cafdca238cb\n'}, {'number': 2, 'created': '2019-02-21 21:02:16.000000000', 'files': ['deployment/gnocchi/gnocchi-statsd-container-puppet.yaml', 'ci/environments/scenario002-standalone.yaml', 'deployment/gnocchi/gnocchi-metricd-container-puppet.yaml', 'deployment/gnocchi/gnocchi-base.yaml', 'environments/baremetal-services.yaml', 'ci/environments/scenario001-standalone.yaml', 'deployment/gnocchi/gnocchi-api-container-puppet.yaml', 'puppet/services/gnocchi-metricd.yaml', 'environments/services/undercloud-gnocchi.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'environments/services-baremetal/undercloud-gnocchi.yaml', 'puppet/services/gnocchi-api.yaml', 'puppet/services/gnocchi-statsd.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7565c38904149f2b98a73bcc4470e60c277940fe', 'message': 'flatten gnocchi services config\n\nThis change combines the previous puppet and docker files\ninto a single file that performs the docker service installation\nand configuration.\n\nChange-Id: If1e6e821aa5ea362cc328dd8d4cf8cafdca238cb\n'}]",0,638464,7565c38904149f2b98a73bcc4470e60c277940fe,9,4,2,20868,,,0,"flatten gnocchi services config

This change combines the previous puppet and docker files
into a single file that performs the docker service installation
and configuration.

Change-Id: If1e6e821aa5ea362cc328dd8d4cf8cafdca238cb
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/64/638464/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/gnocchi/gnocchi-statsd-container-puppet.yaml', 'ci/environments/scenario002-standalone.yaml', 'deployment/gnocchi/gnocchi-metricd-container-puppet.yaml', 'deployment/gnocchi/gnocchi-base.yaml', 'environments/services/undercloud-gnocchi.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'environments/baremetal-services.yaml', 'environments/services-baremetal/undercloud-gnocchi.yaml', 'ci/environments/scenario001-standalone.yaml', 'deployment/gnocchi/gnocchi-api-container-puppet.yaml']",10,ad3d42a86df17bbf6ebd0f3cc1994bd03cf39caa,bp/services-yaml-flattening," GnocchiPassword: description: The password for the gnocchi service and db account. type: string hidden: true GnocchiBackend: default: swift description: The short name of the Gnocchi backend to use. Should be one of swift, rbd, file or s3. type: string constraints: - allowed_values: ['swift', 'file', 'rbd', 's3'] GnocchiIncomingStorageDriver: default: redis description: Storage driver to use for incoming metric data type: string KeystoneRegion: type: string default: 'regionOne' description: Keystone region for endpoint MonitoringSubscriptionGnocchiApi: default: 'overcloud-gnocchi-api' type: string GnocchiApiPolicies: description: | A hash of policies to configure for Gnocchi API. e.g. { gnocchi-context_is_admin: { key: context_is_admin, value: 'role:admin' } } default: {} type: json GnocchiCorsAllowedOrigin: type: string default: '' description: Indicate whether this resource may be shared with the domain received in the request ""origin"" header. cors_allowed_origin_unset: {equals : [{get_param: GnocchiCorsAllowedOrigin}, '']} type: ../../docker/services/containers-common.yaml GnocchiServiceBase: type: ./gnocchi-base.yaml properties: ServiceData: {get_param: ServiceData} ServiceNetMap: {get_param: ServiceNetMap} DefaultPasswords: {get_param: DefaultPasswords} EndpointMap: {get_param: EndpointMap} RoleName: {get_param: RoleName} RoleParameters: {get_param: RoleParameters} ApacheServiceBase: type: ../../puppet/services/apache.yaml properties: ServiceData: {get_param: ServiceData} ServiceNetMap: {get_param: ServiceNetMap} DefaultPasswords: {get_param: DefaultPasswords} EndpointMap: {get_param: EndpointMap} RoleName: {get_param: RoleName} RoleParameters: {get_param: RoleParameters} EnableInternalTLS: {get_param: EnableInternalTLS} service_name: gnocchi_api monitoring_subscription: {get_param: MonitoringSubscriptionGnocchiApi} - get_attr: [GnocchiServiceBase, role_data, config_settings] - get_attr: [ApacheServiceBase, role_data, config_settings] - if: - cors_allowed_origin_unset - {} - gnocchi::cors::allowed_origin: {get_param: GnocchiCorsAllowedOrigin} gnocchi::api::middlewares: 'oslo_middleware.cors.CORS' - tripleo::gnocchi_api::firewall_rules: '129 gnocchi-api': dport: - 8041 - 13041 gnocchi::api::enabled: true gnocchi::api::enable_proxy_headers_parsing: true gnocchi::api::service_name: 'httpd' gnocchi::policy::policies: {get_param: GnocchiApiPolicies} gnocchi::cors::max_age: 3600 gnocchi::cors::allow_headers: 'Content-Type,Cache-Control,Content-Language,Expires,Last-Modified,Pragma,X-Auth-Token' gnocchi::cors::expose_headers: 'Content-Type,Cache-Control,Content-Language,Expires,Last-Modified,Pragma' gnocchi::cors::allow_methods: 'GET,POST,PUT,DELETE,OPTIONS,PATCH' gnocchi::keystone::authtoken::www_authenticate_uri: {get_param: [EndpointMap, KeystoneInternal, uri_no_suffix]} gnocchi::keystone::authtoken::auth_uri: {get_param: [EndpointMap, KeystoneInternal, uri_no_suffix]} gnocchi::keystone::authtoken::auth_url: {get_param: [EndpointMap, KeystoneInternal, uri_no_suffix]} gnocchi::keystone::authtoken::password: {get_param: GnocchiPassword} gnocchi::keystone::authtoken::project_name: 'service' gnocchi::keystone::authtoken::user_domain_name: 'Default' gnocchi::keystone::authtoken::project_domain_name: 'Default' gnocchi::wsgi::apache::ssl: {get_param: EnableInternalTLS} gnocchi::wsgi::apache::servername: str_replace: template: ""%{hiera('fqdn_$NETWORK')}"" params: $NETWORK: {get_param: [ServiceNetMap, GnocchiApiNetwork]} tripleo::profile::base::gnocchi::api::gnocchi_backend: {get_param: GnocchiBackend} tripleo::profile::base::gnocchi::api::incoming_storage_driver: {get_param: GnocchiIncomingStorageDriver} # NOTE: bind IP is found in hiera replacing the network name with the # local node IP for the given network; replacement examples # (eg. for internal_api): # internal_api -> IP # internal_api_uri -> [IP] # internal_api_subnet - > IP/CIDR gnocchi::wsgi::apache::bind_host: str_replace: template: ""%{hiera('$NETWORK')}"" params: $NETWORK: {get_param: [ServiceNetMap, GnocchiApiNetwork]} gnocchi::wsgi::apache::wsgi_process_display_name: 'gnocchi_wsgi' service_config_settings: fluentd: tripleo_fluentd_groups_gnocchi_api: - gnocchi tripleo_fluentd_sources_gnocchi_api: - {get_param: GnocchiApiLoggingSource} keystone: gnocchi::keystone::auth::admin_url: { get_param: [ EndpointMap, GnocchiAdmin, uri ] } gnocchi::keystone::auth::internal_url: {get_param: [EndpointMap, GnocchiInternal, uri]} gnocchi::keystone::auth::password: {get_param: GnocchiPassword} gnocchi::keystone::auth::public_url: { get_param: [ EndpointMap, GnocchiPublic, uri ] } gnocchi::keystone::auth::region: {get_param: KeystoneRegion} gnocchi::keystone::auth::tenant: 'service' mysql: gnocchi::db::mysql::password: {get_param: GnocchiPassword} gnocchi::db::mysql::user: gnocchi gnocchi::db::mysql::host: {get_param: [EndpointMap, MysqlInternal, host_nobrackets]} gnocchi::db::mysql::dbname: gnocchi gnocchi::db::mysql::allowed_hosts: - '%' - ""%{hiera('mysql_bind_host')}"" step_config: include ::tripleo::profile::base::gnocchi::api get_attr: [ApacheServiceBase, role_data, metadata_settings]"," type: ./containers-common.yaml GnocchiApiPuppetBase: type: ../../puppet/services/gnocchi-api.yaml properties: EndpointMap: {get_param: EndpointMap} ServiceData: {get_param: ServiceData} ServiceNetMap: {get_param: ServiceNetMap} DefaultPasswords: {get_param: DefaultPasswords} RoleName: {get_param: RoleName} RoleParameters: {get_param: RoleParameters} service_name: {get_attr: [GnocchiApiPuppetBase, role_data, service_name]} - get_attr: [GnocchiApiPuppetBase, role_data, config_settings] service_config_settings: map_merge: - get_attr: [GnocchiApiPuppetBase, role_data, service_config_settings] - fluentd: tripleo_fluentd_groups_gnocchi_api: - gnocchi tripleo_fluentd_sources_gnocchi_api: - {get_param: GnocchiApiLoggingSource} step_config: get_attr: [GnocchiApiPuppetBase, role_data, step_config] get_attr: [GnocchiApiPuppetBase, role_data, metadata_settings]",189,56
openstack%2Freleases~master~I6df86c86523d3b4d5d6d9010a600f5d366bbf80f,openstack/releases,master,I6df86c86523d3b4d5d6d9010a600f5d366bbf80f,swift stable backport releases,MERGED,2019-02-20 22:27:01.000000000,2019-02-25 16:03:39.000000000,2019-02-25 16:03:39.000000000,"[{'_account_id': 330}, {'_account_id': 2472}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 15343}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-20 22:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/8cf3211af529ac0223e9a0add1ce9cfcce80d272', 'message': 'swift stable backport releases\n\nChange-Id: I6df86c86523d3b4d5d6d9010a600f5d366bbf80f\n'}, {'number': 2, 'created': '2019-02-20 22:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/d132eec563bfccc2564f0aaea17c29faf7dc0d36', 'message': 'swift stable backport releases\n\nChange-Id: I6df86c86523d3b4d5d6d9010a600f5d366bbf80f\n'}, {'number': 3, 'created': '2019-02-21 22:05:43.000000000', 'files': ['deliverables/queens/swift.yaml', 'deliverables/pike/swift.yaml', 'deliverables/rocky/swift.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/fbb8bada825466966046219b5a48317e9ad486d7', 'message': 'swift stable backport releases\n\nChange-Id: I6df86c86523d3b4d5d6d9010a600f5d366bbf80f\n'}]",1,638281,fbb8bada825466966046219b5a48317e9ad486d7,18,7,3,330,,,0,"swift stable backport releases

Change-Id: I6df86c86523d3b4d5d6d9010a600f5d366bbf80f
",git fetch https://review.opendev.org/openstack/releases refs/changes/81/638281/3 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/ocata/swift.yaml', 'deliverables/queens/swift.yaml', 'deliverables/pike/swift.yaml', 'deliverables/rocky/swift.yaml']",4,8cf3211af529ac0223e9a0add1ce9cfcce80d272,, - version: 2.19.1 projects: - repo: openstack/swift hash: 3d2d954107d676e48acb81069639eed15ead5713,,16,0
openstack%2Fopenstackdocstheme~master~I2123f029b0e49f51ebe6c703354e8063fa6e690a,openstack/openstackdocstheme,master,I2123f029b0e49f51ebe6c703354e8063fa6e690a,Silence! A sequel,MERGED,2019-02-25 15:13:59.000000000,2019-02-25 15:52:12.000000000,2019-02-25 15:52:12.000000000,"[{'_account_id': 6547}, {'_account_id': 20156}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-25 15:13:59.000000000', 'files': ['openstackdocstheme/ext.py'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/e0142fd3f957d471860653a66f9a9a6a7500e953', 'message': ""Silence! A sequel\n\nTurns out there's *even more* stuff bleeting in the logs:\n\n  [openstackdocstheme] other_versions []\n\nSilence these for the same reasons given in change\nI2123f029b0e49f51ebe6c703354e8063fa6e690a.\n\nChange-Id: I2123f029b0e49f51ebe6c703354e8063fa6e690a\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,639125,e0142fd3f957d471860653a66f9a9a6a7500e953,7,3,1,15334,,,0,"Silence! A sequel

Turns out there's *even more* stuff bleeting in the logs:

  [openstackdocstheme] other_versions []

Silence these for the same reasons given in change
I2123f029b0e49f51ebe6c703354e8063fa6e690a.

Change-Id: I2123f029b0e49f51ebe6c703354e8063fa6e690a
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/25/639125/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackdocstheme/ext.py'],1,e0142fd3f957d471860653a66f9a9a6a7500e953,trivial," logger.debug('[openstackdocstheme] other_versions %s', context['other_versions'])"," logger.info('[openstackdocstheme] other_versions %s', context['other_versions'])",2,2
openstack%2Fopenstacksdk~master~I1039ec04f83bb2761727a5dbc56ae8e942fb62b0,openstack/openstacksdk,master,I1039ec04f83bb2761727a5dbc56ae8e942fb62b0,Add image.schema resource,MERGED,2019-02-18 13:31:25.000000000,2019-02-25 15:48:58.000000000,2019-02-25 15:48:58.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-02-18 13:31:25.000000000', 'files': ['openstack/tests/unit/image/v2/test_proxy.py', 'openstack/image/v2/_proxy.py', 'releasenotes/notes/add-image-schema-9c07c2789490718a.yaml', 'openstack/image/v2/schema.py', 'openstack/tests/functional/image/v2/test_image.py', 'openstack/tests/unit/image/v2/test_schema.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/68b4dc6d67693385e190d84a51869e026a5d3ae1', 'message': 'Add image.schema resource\n\nAdd support for fetching schema in image service\n\nChange-Id: I1039ec04f83bb2761727a5dbc56ae8e942fb62b0\n'}]",0,637540,68b4dc6d67693385e190d84a51869e026a5d3ae1,11,4,1,27900,,,0,"Add image.schema resource

Add support for fetching schema in image service

Change-Id: I1039ec04f83bb2761727a5dbc56ae8e942fb62b0
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/40/637540/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/unit/image/v2/test_proxy.py', 'openstack/image/v2/_proxy.py', 'openstack/image/v2/schema.py', 'releasenotes/notes/add-image-schema-9c07c2789490718a.yaml', 'openstack/tests/functional/image/v2/test_image.py', 'openstack/tests/unit/image/v2/test_schema.py']",6,68b4dc6d67693385e190d84a51869e026a5d3ae1,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from openstack.tests.unit import base from openstack.image.v2 import schema IDENTIFIER = 'IDENTIFIER' EXAMPLE = { 'additionalProperties': { 'type': 'string' }, 'links': [ { 'href': '{self}', 'rel': 'self' }, { 'href': '{file}', 'rel': 'enclosure' }, { 'href': '{schema}', 'rel': 'describedby' } ], 'name': 'image', 'properties': { 'architecture': { 'description': 'Operating system architecture', 'is_base': False, 'type': 'string' }, 'visibility': { 'description': 'Scope of image accessibility', 'enum': [ 'public', 'private' ], 'type': 'string' } } } class TestSchema(base.TestCase): def test_basic(self): sot = schema.Schema() self.assertIsNone(sot.resource_key) self.assertIsNone(sot.resources_key) self.assertEqual('/schemas', sot.base_path) self.assertFalse(sot.allow_create) self.assertTrue(sot.allow_fetch) self.assertFalse(sot.allow_commit) self.assertFalse(sot.allow_delete) self.assertFalse(sot.allow_list) def test_make_it(self): sot = schema.Schema(**EXAMPLE) self.assertEqual(EXAMPLE['properties'], sot.properties) self.assertEqual(EXAMPLE['name'], sot.name) self.assertEqual(EXAMPLE['additionalProperties'], sot.additional_properties) ",,186,0
openstack%2Fglance_store~master~Iae860f4db0da99cf8fc564c085cba7b234606751,openstack/glance_store,master,Iae860f4db0da99cf8fc564c085cba7b234606751,add python 3.7 unit test job,MERGED,2019-02-15 18:47:28.000000000,2019-02-25 15:29:30.000000000,2019-02-25 15:29:30.000000000,"[{'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 9303}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-15 18:47:28.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/b5f4d461362df1c8061e78a21e166f2f8785de36', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: Iae860f4db0da99cf8fc564c085cba7b234606751\nStory: #2004073\nTask: #27415\n'}]",0,637251,b5f4d461362df1c8061e78a21e166f2f8785de36,8,4,1,11805,,,0,"add python 3.7 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.7.

See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html

Change-Id: Iae860f4db0da99cf8fc564c085cba7b234606751
Story: #2004073
Task: #27415
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/51/637251/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,b5f4d461362df1c8061e78a21e166f2f8785de36,py37-job, - openstack-python37-jobs,,1,0
openstack%2Foslo.messaging~stable%2Fqueens~I78fdf119a0c30167f0cbb92326402ebb9adcaf06,openstack/oslo.messaging,stable/queens,I78fdf119a0c30167f0cbb92326402ebb9adcaf06,DO NOT MERGE - testing telemetry gate,ABANDONED,2019-02-22 15:26:16.000000000,2019-02-25 14:54:31.000000000,,"[{'_account_id': 6928}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 15:26:16.000000000', 'files': ['oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c8e08716f8c5f8cc04c1f3e73153a5a908e0b7ff', 'message': 'DO NOT MERGE - testing telemetry gate\n\nChange-Id: I78fdf119a0c30167f0cbb92326402ebb9adcaf06\n'}]",0,638688,c8e08716f8c5f8cc04c1f3e73153a5a908e0b7ff,4,2,1,8770,,,0,"DO NOT MERGE - testing telemetry gate

Change-Id: I78fdf119a0c30167f0cbb92326402ebb9adcaf06
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/88/638688/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/impl_rabbit.py'],1,c8e08716f8c5f8cc04c1f3e73153a5a908e0b7ff,NDM-queens-test," help='Connect over SSL. DO NOT MERGE!'),"," help='Connect over SSL.'),",1,1
openstack%2Fcinder~master~I3c6c9e1c50100cfa56dcadf6445729484cdd616d,openstack/cinder,master,I3c6c9e1c50100cfa56dcadf6445729484cdd616d,Allow to use _max qos option together with per_gb,MERGED,2018-12-13 17:12:56.000000000,2019-02-25 14:53:26.000000000,2018-12-19 18:22:50.000000000,"[{'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28619}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-12-13 17:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71c377f0314f953c69492e5fa291cb3fb0a4aec7', 'message': ""Allow to use _max qos option together with per_gb\n\nWith this patch it'll become possible to limit max performance of volume\neven when qos is set per_gb. As a result operator will be able to set\nmin and max options, with per gb increment, until the max value.\n\nChange-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d\n""}, {'number': 2, 'created': '2018-12-14 13:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/27e87aa9c57f9704ec3e779db66191ab39433e37', 'message': ""Allow to use _max qos option together with per_gb\n\nWith this patch it'll become possible to limit max performance of volume\neven when qos is set per_gb. As a result operator will be able to set\nmin and max options, with per gb increment, until the max value.\n\nChange-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d\n""}, {'number': 3, 'created': '2018-12-14 17:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f4c4838c7dd12ba9422ee28a06d4abab28732c14', 'message': ""Allow to use _max qos option together with per_gb\n\nWith this patch it'll become possible to limit max performance of volume\neven when qos is set per_gb. As a result operator will be able to set\nmin and max options, with per gb increment, until the max value.\n\nChange-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d\n""}, {'number': 4, 'created': '2018-12-14 18:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bcf6f3441bebae0ce6b5b9308a1f8ce859e1346a', 'message': ""Allow to use _max qos option together with per_gb\n\nWith this patch it'll become possible to limit max performance of volume\neven when qos is set per_gb. As a result operator will be able to set\nmin and max options, with per gb increment, until the max value.\n\nChange-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d\n""}, {'number': 5, 'created': '2018-12-14 18:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/094cce3ec437d97901c8ace1a8774ff31877d445', 'message': ""Allow to use _max qos option together with per_gb\n\nWith this patch it'll become possible to limit max performance of volume\neven when qos is set per_gb. As a result operator will be able to set\nmin and max options, with per gb increment, until the max value.\n\nChange-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d\n""}, {'number': 6, 'created': '2018-12-14 19:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/85cf3ead0f68f7b8c48e1bd9ccc60b7e050ae8fd', 'message': ""Allow to use _max qos option together with per_gb\n\nWith this patch it'll become possible to limit max performance of volume\neven when qos is set per_gb. As a result operator will be able to set\nmin and max options, with per gb increment, until the max value.\n\nChange-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d\n""}, {'number': 7, 'created': '2018-12-18 17:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0d0c815f9a952a13483624e0813bdf8ee59f21be', 'message': ""Allow to use _max qos option together with per_gb\n\nWith this patch it'll become possible to limit max performance of volume\neven when qos is set per_gb. As a result operator will be able to set\nmin and max options, with per gb increment, until the max value.\n\nChange-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d\n""}, {'number': 8, 'created': '2018-12-18 17:49:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6115de4d61a582128c8d8b1988ec310ced476cc2', 'message': ""Allow to use _max qos option together with per_gb\n\nWith this patch it'll become possible to limit max performance of volume\neven when qos is set per_gb. As a result operator will be able to set\nmin and max options, with per gb increment, until the max value.\n\nChange-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d\n""}, {'number': 9, 'created': '2018-12-18 17:50:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/be92a7500131c1f83ef2a654d7b0bd0751cf25cb', 'message': ""Allow to use _max qos option together with per_gb\n\nWith this patch it'll become possible to limit max performance of volume\neven when qos is set per_gb. As a result operator will be able to set\nmin and max options, with per gb increment, until the max value.\n\nChange-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d\n""}, {'number': 10, 'created': '2018-12-18 23:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8db74b5a3687d14bec963bfdd2210353e236ba37', 'message': ""Allow to use _max qos option together with per_gb\n\nWith this patch it'll become possible to limit max performance of volume\neven when qos is set per_gb. As a result operator will be able to set\nmin and max options, with per gb increment, until the max value.\n\nChange-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d\n""}, {'number': 11, 'created': '2018-12-19 00:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4581a22b303eee90a31a8eceb0a51b4ed75858b8', 'message': ""Allow to use _max qos option together with per_gb\n\nWith this patch it'll become possible to limit max performance of volume\neven when qos is set per_gb. As a result operator will be able to set\nmin and max options, with per gb increment, until the max value.\n\nChange-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d\n""}, {'number': 12, 'created': '2018-12-19 00:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/378c2c2cadd9f472cca97c5237c43f43d82ddfed', 'message': ""Allow to use _max qos option together with per_gb\n\nWith this patch it'll become possible to limit max performance of volume\neven when qos is set per_gb. As a result operator will be able to set\nmin and max options, with per gb increment, until the max value.\n\nChange-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d\n""}, {'number': 13, 'created': '2018-12-19 01:13:05.000000000', 'files': ['cinder/tests/unit/volume/test_connection.py', 'cinder/volume/manager.py', 'doc/source/admin/blockstorage-capacity-based-qos.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ff9154ffcf0d4381502142915b5e0c80db3f5d7', 'message': ""Allow to use _max qos option together with per_gb\n\nWith this patch it'll become possible to limit max performance of volume\neven when qos is set per_gb. As a result operator will be able to set\nmin and max options, with per gb increment, until the max value.\n\nChange-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d\n""}]",3,625058,8ff9154ffcf0d4381502142915b5e0c80db3f5d7,163,40,13,28619,,,0,"Allow to use _max qos option together with per_gb

With this patch it'll become possible to limit max performance of volume
even when qos is set per_gb. As a result operator will be able to set
min and max options, with per gb increment, until the max value.

Change-Id: I3c6c9e1c50100cfa56dcadf6445729484cdd616d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/58/625058/12 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/manager.py'],1,71c377f0314f953c69492e5fa291cb3fb0a4aec7,fix/qos_per_gb_min," option_max = '%s_max' % option maximum_value = int(specs.pop(option_max, 0)) per_gb_value = max(minimum_value, value) if per_gb_value > maximum_value: specs[option] = maximum_value else: specs[option] = per_gb_value"," specs[option] = max(minimum_value, value)",7,1
openstack%2Fgovernance~master~I842e186f113727badfecff78eb37f74c225c1a22,openstack/governance,master,I842e186f113727badfecff78eb37f74c225c1a22,Remove team fragility stats script,MERGED,2019-02-13 19:07:00.000000000,2019-02-25 14:49:53.000000000,2019-02-25 14:49:53.000000000,"[{'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 8099}, {'_account_id': 11655}, {'_account_id': 11904}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-13 19:07:00.000000000', 'files': ['tools/team_fragility.py'], 'web_link': 'https://opendev.org/openstack/governance/commit/186fe85198b87f9c0cea808f095f50af8ced5a90', 'message': 'Remove team fragility stats script\n\nWe no longer provide governance tags focused on team ""fragility"" so\nthe team_fragility.py is fairly irrelevant for us now and its\npresence in this repository may be sending the wrong message. It\nalso relies on Stackalytics which, at the time of writing, is not\nopen source.\n\nChange-Id: I842e186f113727badfecff78eb37f74c225c1a22\n'}]",0,636721,186fe85198b87f9c0cea808f095f50af8ced5a90,14,7,1,5263,,,0,"Remove team fragility stats script

We no longer provide governance tags focused on team ""fragility"" so
the team_fragility.py is fairly irrelevant for us now and its
presence in this repository may be sending the wrong message. It
also relies on Stackalytics which, at the time of writing, is not
open source.

Change-Id: I842e186f113727badfecff78eb37f74c225c1a22
",git fetch https://review.opendev.org/openstack/governance refs/changes/21/636721/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/team_fragility.py'],1,186fe85198b87f9c0cea808f095f50af8ced5a90,formal-vote,,"#!/usr/bin/env python # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import argparse import os import sys import requests import yaml s = requests.session() def fragility(team, series): org_metric = [{'team': team, 'type': 'no activity', 'value': 0, 'name': ''}] eng_metric = [{'team': team, 'type': 'no activity', 'value': 0, 'name': ''}] group = ""%s-group"" % team.lower() org_commits = s.get('http://stackalytics.com/api/' '1.0/stats/companies?metric=commits&release=%s' '&project_type=all&module=%s' % (series, group)).json() total_commits = sum([company['metric'] for company in org_commits['stats']]) if total_commits: # Entity with most commits if org_commits['stats'][0]['name'] == '*independent': # Skip ""independent"" if that is the largest org org_commits['stats'].pop(0) value = float(org_commits['stats'][0]['metric'] / total_commits * 100) org_metric.append({'team': team, 'type': 'org commit %', 'value': value, 'name': org_commits['stats'][0]['name']}) # Core reviews reviews = s.get('http://stackalytics.com/api/' '1.0/stats/engineers?metric=marks&release=%s' '&project_type=all' '&module=%s' % (series, group)).json() companies = {} engineers = [] total_core_reviews = 0 for eng in reviews['stats']: if eng['core'] != 'master': # Skip reviews for non-core reviewers continue engineers.append({'name': eng['name'], 'reviews': eng['metric']}) total_core_reviews += eng['metric'] # Identify company for that core reviewer for stat in s.get('http://stackalytics.com/api/1.0/stats/' 'companies?metric=marks&module=%s&user_id=%s&' 'project_type=all&release=%s' % (group, eng['id'], series)).json()['stats']: company = stat['id'] if company == '*independent': continue if company not in companies: companies[company] = 0 companies[company] += stat['metric'] if companies: # Organization with most core reviews most_core_reviews = max(companies, key=companies.get) v = float(companies[most_core_reviews] / total_core_reviews * 100) org_metric.append({'team': team, 'type': 'org core review %', 'value': v, 'name': most_core_reviews}) if engineers: # Individual with most core reviews eng_most_core = max(engineers, key=lambda key: key['reviews']) v = float(eng_most_core['reviews'] / total_core_reviews * 100) eng_metric.append({'team': team, 'type': 'individual core review %', 'value': v, 'name': eng_most_core['name']}) # Individual with most commits eng_commits = s.get('http://stackalytics.com/api/' '1.0/stats/engineers?metric=commits&release=%s' '&project_type=all&module=%s' % (series, group)).json() value = float(eng_commits['stats'][0]['metric'] / total_commits * 100) eng_metric.append({'team': team, 'type': 'individual commit %', 'value': value, 'name': eng_commits['stats'][0]['name']}) return (max(org_metric, key=lambda key: key['value']), max(eng_metric, key=lambda key: key['value'])) def main(): parser = argparse.ArgumentParser() parser.add_argument('series', help='development cycle to consider') args = parser.parse_args() corpobus = [] engbus = [] filename = os.path.abspath('reference/projects.yaml') with open(filename, 'r') as f: projects = [k for k in yaml.safe_load(f.read())] projects.sort() for project in projects: if project not in ['OpenStackSDK', 'loci']: (org_fragility, eng_fragility) = fragility(project, args.series) corpobus.append(org_fragility) engbus.append(eng_fragility) print('============= Organizational diversity fragility =============') for busfactor in sorted(corpobus, key=lambda key: key['value'], reverse=True): print('%-18s %.1f%% (%s, %s)' % ( busfactor['team'], busfactor['value'], busfactor['name'], busfactor['type'])) print('============= Individual fragility =============') for busfactor in sorted(engbus, key=lambda key: key['value'], reverse=True): print('%-18s %.1f%% (%s, %s)' % ( busfactor['team'], busfactor['value'], busfactor['name'], busfactor['type'])) if __name__ == '__main__': sys.exit(main()) ",0,154
openstack%2Fos-vif~master~Id03be72e22302a0954f3e47c116f389cb4304c03,openstack/os-vif,master,Id03be72e22302a0954f3e47c116f389cb4304c03,remove use of brctl from vif_plug_linux_bridge,MERGED,2019-02-14 04:07:43.000000000,2019-02-25 14:49:36.000000000,2019-02-25 13:41:32.000000000,"[{'_account_id': 7}, {'_account_id': 7166}, {'_account_id': 9732}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 25733}]","[{'number': 1, 'created': '2019-02-14 04:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/abc1846b756861ed947a58e281eed60db5e14c75', 'message': '[WIP] remove use of brctl from vif_plug_linux_bridge\n\n- TODO update unit tests\n- This change replaces calls to brctl with calls\n  to the ip_command interface.\n\nChange-Id: Id03be72e22302a0954f3e47c116f389cb4304c03\nCloses-Bug: #1801919\n'}, {'number': 2, 'created': '2019-02-19 13:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/3b9753d3bd566d11279c8f3fa419c5bf2bdc3182', 'message': 'remove use of brctl from vif_plug_linux_bridge\n\n- This change replaces calls to brctl with calls\n  to the ip_command interface.\n\nChange-Id: Id03be72e22302a0954f3e47c116f389cb4304c03\nCloses-Bug: #1801919\n'}, {'number': 3, 'created': '2019-02-19 22:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/17e1231ce62fb9541cb170f74c3c9674c328fdb2', 'message': 'remove use of brctl from vif_plug_linux_bridge\n\n- This change replaces calls to brctl with calls\n  to the ip_command interface.\n- This change adds a release note for the brctl\n  removal.\nChange-Id: Id03be72e22302a0954f3e47c116f389cb4304c03\nCloses-Bug: #1801919\n'}, {'number': 4, 'created': '2019-02-21 15:16:54.000000000', 'files': ['vif_plug_linux_bridge/tests/unit/test_linux_net.py', 'releasenotes/notes/brctl-removal-a5b0e69b865afa57.yaml', 'vif_plug_linux_bridge/linux_net.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/1f6fed6a69e9fd386e421f3cacae97c11cdd7c75', 'message': 'remove use of brctl from vif_plug_linux_bridge\n\n- This change replaces calls to brctl with calls\n  to the ip_command interface.\n- This change adds a release note for the brctl\n  removal.\n- This change removes the use of tee to disable\n  ipv6 in the linux bridge plugin.\n\nChange-Id: Id03be72e22302a0954f3e47c116f389cb4304c03\nCloses-Bug: #1801919\n'}]",18,636822,1f6fed6a69e9fd386e421f3cacae97c11cdd7c75,22,7,4,11604,,,0,"remove use of brctl from vif_plug_linux_bridge

- This change replaces calls to brctl with calls
  to the ip_command interface.
- This change adds a release note for the brctl
  removal.
- This change removes the use of tee to disable
  ipv6 in the linux bridge plugin.

Change-Id: Id03be72e22302a0954f3e47c116f389cb4304c03
Closes-Bug: #1801919
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/22/636822/3 && git format-patch -1 --stdout FETCH_HEAD,['vif_plug_linux_bridge/linux_net.py'],1,abc1846b756861ed947a58e281eed60db5e14c75,bug/1801919," ip_lib.add(bridge, 'bridge') # TODO(sean-k-mooney): remove use of tee if interface and ip_lib.exists(interface): ip_lib.set(interface, master=bridge, state='up', check_exit_code=[0, 2, 254]) # TODO(sean-k-mooney): investigate deleting all this route # handeling code. The vm tap devices should never have an ip, # this is old nova networks code and i dont think it will ever # be needed in os-vif.","from oslo_utils import excutils try: processutils.execute('brctl', 'addbr', bridge) except Exception: with excutils.save_and_reraise_exception() as ectx: ectx.reraise = not ip_lib.exists(bridge) processutils.execute('brctl', 'setfd', bridge, 0) # processutils.execute('brctl setageing %s 10' % bridge) processutils.execute('brctl', 'stp', bridge, 'off') # (danwent) bridge device MAC address can't be set directly. # instead it inherits the MAC address of the first device on the # bridge, which will either be the vlan interface, or a # physical NIC. if interface: out, err = processutils.execute('brctl', 'addif', bridge, interface, check_exit_code=False) if (err and err != ""device %s is already a member of a bridge; "" ""can't enslave it to bridge %s.\n"" % (interface, bridge)): msg = _('Failed to add interface: %s') % err raise Exception(msg) ip_lib.set(interface, state='up')",9,22
openstack%2Fironic-ui~master~I16662c2685f4f4168b57da249f153d717fdd2d69,openstack/ironic-ui,master,I16662c2685f4f4168b57da249f153d717fdd2d69,add python 3.7 unit test job,MERGED,2019-02-15 18:59:08.000000000,2019-02-25 14:48:36.000000000,2019-02-25 14:48:36.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-15 18:59:08.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/97bdc1823ca8158cddb003d3718c9475897587da', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: I16662c2685f4f4168b57da249f153d717fdd2d69\nStory: #2004073\nTask: #27420\n'}]",0,637260,97bdc1823ca8158cddb003d3718c9475897587da,7,3,1,11805,,,0,"add python 3.7 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.7.

See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html

Change-Id: I16662c2685f4f4168b57da249f153d717fdd2d69
Story: #2004073
Task: #27420
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/60/637260/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,97bdc1823ca8158cddb003d3718c9475897587da,py37-job, - openstack-python37-jobs,,1,0
openstack%2Fpuppet-nova~master~Iadc2970afb65a6b3a1a3241147d042e6b04b0ad2,openstack/puppet-nova,master,Iadc2970afb65a6b3a1a3241147d042e6b04b0ad2,placement: Separate deployment from configuration,MERGED,2019-02-01 20:15:04.000000000,2019-02-25 14:44:02.000000000,2019-02-25 14:44:02.000000000,"[{'_account_id': 10135}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 17216}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-01 20:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/a8e3b34bf4f607fa7f02d8f39ebc3c9ede1f91d4', 'message': 'WIP placement: Seperate deployment and configuration\n\nChange-Id: Iadc2970afb65a6b3a1a3241147d042e6b04b0ad2\n'}, {'number': 2, 'created': '2019-02-01 20:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/76b2566c2897a5ad5d75af9754116d9d6ab832f2', 'message': 'WIP placement: Seperate deployment and configuration\n\nChange-Id: Iadc2970afb65a6b3a1a3241147d042e6b04b0ad2\n'}, {'number': 3, 'created': '2019-02-01 21:31:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/d5aaac9c87efa4e12009e6560d85e20b427c42af', 'message': 'WIP placement: Seperate deployment and configuration\n\nChange-Id: Iadc2970afb65a6b3a1a3241147d042e6b04b0ad2\n'}, {'number': 4, 'created': '2019-02-12 14:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/14c803655df90be9832b724b790a972e25309a2d', 'message': 'placement: Separate deployment from configuration\n\nTo allow for the deprecation and future removal of any Placement service\ndeployment logic from puppet-nova this code first needs to be separated\ninto its own class.\n\nChange-Id: Iadc2970afb65a6b3a1a3241147d042e6b04b0ad2\n'}, {'number': 5, 'created': '2019-02-13 11:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/ae92bd98b1739fb491dfada55674f7d5c1b9c789', 'message': 'placement: Separate deployment from configuration\n\nTo allow for the deprecation and future removal of any Placement service\ndeployment logic from puppet-nova this code first needs to be separated\ninto its own class.\n\nChange-Id: Iadc2970afb65a6b3a1a3241147d042e6b04b0ad2\n'}, {'number': 6, 'created': '2019-02-20 10:56:47.000000000', 'files': ['manifests/placement/service.pp', 'manifests/placement.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/f435ef6f7a3a2dd011a2a6a43630b7167ac6ecf7', 'message': 'placement: Separate deployment from configuration\n\nTo allow for the deprecation and future removal of any Placement service\ndeployment logic from puppet-nova this code first needs to be separated\ninto its own class.\n\nChange-Id: Iadc2970afb65a6b3a1a3241147d042e6b04b0ad2\n'}]",3,634486,f435ef6f7a3a2dd011a2a6a43630b7167ac6ecf7,58,7,6,10135,,,0,"placement: Separate deployment from configuration

To allow for the deprecation and future removal of any Placement service
deployment logic from puppet-nova this code first needs to be separated
into its own class.

Change-Id: Iadc2970afb65a6b3a1a3241147d042e6b04b0ad2
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/86/634486/6 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/placement/config.pp', 'manifests/placement.pp']",2,a8e3b34bf4f607fa7f02d8f39ebc3c9ede1f91d4,placement-deployment-deprecation,"# Class for deploying Placement and configuring [placement] section in nova.conf. class ::nova::placement::config{ password => $password, auth_type => $auth_type, auth_url => $auth_url, region_name => $region_name, valid_interfaces => $valid_interfaces, project_domain_name => $project_domain_name, project_name => $project_name, user_domain_name => $user_domain_name, username => $username, os_interface => $os_interface, }","# Class for configuring [placement] section in nova.conf. if $os_interface { warning('nova::placement::os_interface is deprecated for removal, please use valid_interfaces instead.') } $valid_interfaces_real = pick($os_interface, $valid_interfaces) nova_config { 'placement/auth_type': value => $auth_type; 'placement/auth_url': value => $auth_url; 'placement/password': value => $password, secret => true; 'placement/project_domain_name': value => $project_domain_name; 'placement/project_name': value => $project_name; 'placement/user_domain_name': value => $user_domain_name; 'placement/username': value => $username; 'placement/region_name': value => $region_name; 'placement/valid_interfaces': value => $valid_interfaces_real; } ",101,17
openstack%2Fironic~master~Iaa915ed3aced57153db468d8ccd9d87f9e5728ac,openstack/ironic,master,Iaa915ed3aced57153db468d8ccd9d87f9e5728ac,Update the proliantutils version in documentation,MERGED,2019-02-22 19:19:24.000000000,2019-02-25 14:41:20.000000000,2019-02-25 14:41:20.000000000,"[{'_account_id': 10206}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 11297}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 19:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/41e58a300cf09efb3995d9d3f58efdc1572b8ee7', 'message': 'Update the proliantutils version in documentation\n\nUpdate the proliantutils version from 2.7.1 to 2.8.\n\nstory: #2004950\ntask: #29366\n\nChange-Id: Iaa915ed3aced57153db468d8ccd9d87f9e5728ac\n'}, {'number': 2, 'created': '2019-02-25 04:52:39.000000000', 'files': ['doc/source/admin/drivers/ilo.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b9f7cf59f8fb17daaaae9f5035713aa3680df339', 'message': 'Update the proliantutils version in documentation\n\nUpdate the proliantutils version from 2.7.1 to 2.8.\n\nstory: #2004950\ntask: #29366\n\nChange-Id: Iaa915ed3aced57153db468d8ccd9d87f9e5728ac\n'}]",1,638754,b9f7cf59f8fb17daaaae9f5035713aa3680df339,14,6,2,11297,,,0,"Update the proliantutils version in documentation

Update the proliantutils version from 2.7.1 to 2.8.

story: #2004950
task: #29366

Change-Id: Iaa915ed3aced57153db468d8ccd9d87f9e5728ac
",git fetch https://review.opendev.org/openstack/ironic refs/changes/54/638754/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/drivers/ilo.rst'],1,41e58a300cf09efb3995d9d3f58efdc1572b8ee7,nic_doc, HPE servers from release 2.8. The user would need to delete the ironic, HPE servers from release 2.7.1. The user would need to delete the ironic,1,1
openstack%2Fpuppet-ironic~master~Iad70b968c1a14500d2476aaf9e0e9c645357bc76,openstack/puppet-ironic,master,Iad70b968c1a14500d2476aaf9e0e9c645357bc76,Add release note about Ubuntu py3 upgrade,MERGED,2019-02-23 23:03:51.000000000,2019-02-25 14:29:43.000000000,2019-02-25 14:29:43.000000000,"[{'_account_id': 9414}, {'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 23:03:51.000000000', 'files': ['releasenotes/notes/release-note-ubuntu-py3-aae645e32d4bc5ab.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/41dadb2fe74056111c743d374afd0f560873d99e', 'message': 'Add release note about Ubuntu py3 upgrade\n\nChange-Id: Iad70b968c1a14500d2476aaf9e0e9c645357bc76\n'}]",0,638896,41dadb2fe74056111c743d374afd0f560873d99e,7,3,1,16137,,,0,"Add release note about Ubuntu py3 upgrade

Change-Id: Iad70b968c1a14500d2476aaf9e0e9c645357bc76
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/96/638896/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/release-note-ubuntu-py3-aae645e32d4bc5ab.yaml'],1,41dadb2fe74056111c743d374afd0f560873d99e,release-note-ubuntu-py3,"--- prelude: > In this release Ubuntu has moved all projects that supported it to python3 which means that there will be a lot of changes. The Puppet OpenStack project does not test the upgrade path from python2 to python3 packages so there might be manual steps required when moving to the python3 packages. upgrade: - | Ubuntu packages are now using python3, the upgrade path is not tested by Puppet OpenStack. Manual steps may be required when upgrading. ",,10,0
openstack%2Fsushy-tools~master~I6c31d8b7e52cddb46c56189d177d7f05449b95c4,openstack/sushy-tools,master,I6c31d8b7e52cddb46c56189d177d7f05449b95c4,Switch sushy-tools devstack job to python3,ABANDONED,2018-08-14 19:19:22.000000000,2019-02-25 14:21:24.000000000,,"[{'_account_id': 2472}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-14 19:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/3bc9d4dcec0814ee77e0f6ed732964fc2967bbe6', 'message': 'Switch sushy-tools devstack job to Python3\n\nChange-Id: I6c31d8b7e52cddb46c56189d177d7f05449b95c4\n'}, {'number': 2, 'created': '2018-08-20 19:13:28.000000000', 'files': ['playbooks/legacy/sushy-tools-tempest-dsvm-ironic-ipa-partition-redfish-src/run.yaml', 'playbooks/legacy/sushy-tools-tempest-dsvm-ironic-ipa-partition-redfish-src-python2/post.yaml', 'zuul.d/project.yaml', 'zuul.d/legacy-sushy-tools-jobs.yaml', 'playbooks/legacy/sushy-tools-tempest-dsvm-ironic-ipa-partition-redfish-src-python2/run.yaml'], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/522cf86900cfa48f55b026a4ed158d9751274fd3', 'message': 'Switch sushy-tools devstack job to python3\n\nMakes a copy of the job, and explicitly sets it to be\npython2.\n\nChange-Id: I6c31d8b7e52cddb46c56189d177d7f05449b95c4\n'}]",0,591831,522cf86900cfa48f55b026a4ed158d9751274fd3,11,5,2,11655,,,0,"Switch sushy-tools devstack job to python3

Makes a copy of the job, and explicitly sets it to be
python2.

Change-Id: I6c31d8b7e52cddb46c56189d177d7f05449b95c4
",git fetch https://review.opendev.org/openstack/sushy-tools refs/changes/31/591831/2 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/legacy/sushy-tools-tempest-dsvm-ironic-ipa-partition-redfish-src/run.yaml'],1,3bc9d4dcec0814ee77e0f6ed732964fc2967bbe6,python3-first, export DEVSTACK_GATE_USE_PYTHON3=True,,1,0
openstack%2Fcharm-ceph-fs~master~Iffe4b6edb8b7ab33bfde77f2e8bf12ae8bffac1a,openstack/charm-ceph-fs,master,Iffe4b6edb8b7ab33bfde77f2e8bf12ae8bffac1a,Rebuild to handle Mimic pool tagging requirements,MERGED,2019-02-25 09:55:03.000000000,2019-02-25 14:14:48.000000000,2019-02-25 14:14:48.000000000,"[{'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-25 09:55:03.000000000', 'files': ['rebuild'], 'web_link': 'https://opendev.org/openstack/charm-ceph-fs/commit/67e92e5e26e329ad44d187f8411c9cbd3ab68cff', 'message': 'Rebuild to handle Mimic pool tagging requirements\n\nIn Mimic, CephFS requires that the backing pools\nhave application tags of ""cephfs"" explicitly, and will\nfail to configure on other application pools\n\nChange-Id: Iffe4b6edb8b7ab33bfde77f2e8bf12ae8bffac1a\n'}]",0,639042,67e92e5e26e329ad44d187f8411c9cbd3ab68cff,8,4,1,20634,,,0,"Rebuild to handle Mimic pool tagging requirements

In Mimic, CephFS requires that the backing pools
have application tags of ""cephfs"" explicitly, and will
fail to configure on other application pools

Change-Id: Iffe4b6edb8b7ab33bfde77f2e8bf12ae8bffac1a
",git fetch https://review.opendev.org/openstack/charm-ceph-fs refs/changes/42/639042/1 && git format-patch -1 --stdout FETCH_HEAD,['rebuild'],1,67e92e5e26e329ad44d187f8411c9cbd3ab68cff,,55501b8e-38d8-11e9-a8ad-fb10af1e7610,"# This file is used to trigger rebuilds # when dependencies of the charm change, # but nothing in the charm needs to. # simply change the uuid to something new 85c5499c-1a79-11e9-8864-470f2a69c15e",1,5
openstack%2Fkolla-ansible~master~Id9a6c4c85eeb62d5215abb9d7e9149299d484f0c,openstack/kolla-ansible,master,Id9a6c4c85eeb62d5215abb9d7e9149299d484f0c,baremetal: install docker-ce/upstream on Debian/Ubuntu,ABANDONED,2018-05-14 13:28:25.000000000,2019-02-25 14:02:28.000000000,,"[{'_account_id': 2276}, {'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 21691}, {'_account_id': 22348}, {'_account_id': 27336}]","[{'number': 1, 'created': '2018-05-14 13:28:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b22d606211f379c847579f106e8d297749579b2f', 'message': ""baremetal: install docker-ce/upstream also on aarch64\n\nUpstream provides 'docker-ce' package for arm64 nowadays. So let's use\nthem instead of Linaro ones.\n\nChange-Id: Id9a6c4c85eeb62d5215abb9d7e9149299d484f0c\n""}, {'number': 2, 'created': '2018-10-10 09:14:11.000000000', 'files': ['ansible/roles/baremetal/tasks/pre-install.yml', 'ansible/roles/baremetal/templates/docker_apt_repo.j2', 'ansible/roles/baremetal/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/865e048d9ba4d5dcc6d47315b9d2f3cd8e7b72f1', 'message': ""baremetal: install docker-ce/upstream on Debian/Ubuntu\n\nUpstream provides 'docker-ce' package for both amd64 and arm64 nowadays.\nSo let's use them instead of old Linaro one.\n\nChange-Id: Id9a6c4c85eeb62d5215abb9d7e9149299d484f0c\n""}]",2,568289,865e048d9ba4d5dcc6d47315b9d2f3cd8e7b72f1,15,6,2,24072,,,0,"baremetal: install docker-ce/upstream on Debian/Ubuntu

Upstream provides 'docker-ce' package for both amd64 and arm64 nowadays.
So let's use them instead of old Linaro one.

Change-Id: Id9a6c4c85eeb62d5215abb9d7e9149299d484f0c
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/89/568289/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/baremetal/templates/docker_apt_repo.j2', 'ansible/roles/baremetal/defaults/main.yml']",2,b22d606211f379c847579f106e8d297749579b2f,568289,"docker_apt_url: ""{{ 'https://download.docker.com/linux/debian' }}"" docker_apt_key_file: ""{{ 'gpg' }}"" docker_apt_key_id: ""{{ 'F76221572C52609D' }}""","docker_apt_url: ""{{ 'http://obs.linaro.org/ERP:/17.12/Debian_9' if ansible_architecture == 'aarch64' else 'https://apt.dockerproject.org' }}"" docker_apt_key_file: ""{{ 'Release.key' if ansible_architecture == 'aarch64' else 'gpg' }}"" docker_apt_key_id: ""{{ 'C32DA102AD89C2BE' if ansible_architecture == 'aarch64' else 'F76221572C52609D' }}""",4,8
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I26f97e7fc4da0dd19e1e8a19b3f6a1c1160f7466,openstack/tripleo-heat-templates,stable/queens,I26f97e7fc4da0dd19e1e8a19b3f6a1c1160f7466,[FFU] Make sure group access work correctly with ansible 2.6.,ABANDONED,2019-02-25 10:07:07.000000000,2019-02-25 13:46:21.000000000,,"[{'_account_id': 8297}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-25 10:07:07.000000000', 'files': ['common/deploy-steps.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/757f261495da560024a894bbae29b8ac19890505', 'message': '[FFU] Make sure group access work correctly with ansible 2.6.\n\nHi, with ansible 2.6 we cannot access the groups variable using the\nprevious idiom anymore.  Use a more robust way to access that\nvariable.\n\nCo-Authored-By: ""Lukas Bezdicka <lbezdick@redhat.com>""\nChange-Id: I26f97e7fc4da0dd19e1e8a19b3f6a1c1160f7466\nCloses-bug: #1816422\n(cherry picked from commit a0c3612db836343143b8ebd160710216203dfc8a)\n'}]",0,639046,757f261495da560024a894bbae29b8ac19890505,5,4,1,11166,,,0,"[FFU] Make sure group access work correctly with ansible 2.6.

Hi, with ansible 2.6 we cannot access the groups variable using the
previous idiom anymore.  Use a more robust way to access that
variable.

Co-Authored-By: ""Lukas Bezdicka <lbezdick@redhat.com>""
Change-Id: I26f97e7fc4da0dd19e1e8a19b3f6a1c1160f7466
Closes-bug: #1816422
(cherry picked from commit a0c3612db836343143b8ebd160710216203dfc8a)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/46/639046/1 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps.j2'],1,757f261495da560024a894bbae29b8ac19890505,bug/1816422-stable/rocky-stable/queens, when: tripleo_role_name == '{{role.name}}' and ansible_hostname == groups['{{role.name}}'][0], when: tripleo_role_name == '{{role.name}}' and ansible_hostname == {{role.name}}[0],1,1
openstack%2Ftripleo-heat-templates~stable%2Frocky~I26f97e7fc4da0dd19e1e8a19b3f6a1c1160f7466,openstack/tripleo-heat-templates,stable/rocky,I26f97e7fc4da0dd19e1e8a19b3f6a1c1160f7466,[FFU] Make sure group access work correctly with ansible 2.6.,ABANDONED,2019-02-25 10:06:57.000000000,2019-02-25 13:45:58.000000000,,"[{'_account_id': 8297}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-25 10:06:57.000000000', 'files': ['common/deploy-steps.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/01e7c2befb2a12b42d661b5f420e52d51f3f0e41', 'message': '[FFU] Make sure group access work correctly with ansible 2.6.\n\nHi, with ansible 2.6 we cannot access the groups variable using the\nprevious idiom anymore.  Use a more robust way to access that\nvariable.\n\nCo-Authored-By: ""Lukas Bezdicka <lbezdick@redhat.com>""\nChange-Id: I26f97e7fc4da0dd19e1e8a19b3f6a1c1160f7466\nCloses-bug: #1816422\n(cherry picked from commit a0c3612db836343143b8ebd160710216203dfc8a)\n'}]",0,639045,01e7c2befb2a12b42d661b5f420e52d51f3f0e41,4,2,1,11166,,,0,"[FFU] Make sure group access work correctly with ansible 2.6.

Hi, with ansible 2.6 we cannot access the groups variable using the
previous idiom anymore.  Use a more robust way to access that
variable.

Co-Authored-By: ""Lukas Bezdicka <lbezdick@redhat.com>""
Change-Id: I26f97e7fc4da0dd19e1e8a19b3f6a1c1160f7466
Closes-bug: #1816422
(cherry picked from commit a0c3612db836343143b8ebd160710216203dfc8a)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/45/639045/1 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps.j2'],1,01e7c2befb2a12b42d661b5f420e52d51f3f0e41,bug/1816422-stable/rocky, when: tripleo_role_name == '{{role.name}}' and ansible_hostname == groups['{{role.name}}'][0], when: tripleo_role_name == '{{role.name}}' and ansible_hostname == {{role.name}}[0],1,1
openstack%2Fos-resource-classes~master~Id5557d65f11ed4dee10c8df2a42a4c485bfd65d1,openstack/os-resource-classes,master,Id5557d65f11ed4dee10c8df2a42a4c485bfd65d1,Add normalize_name utility,MERGED,2019-01-31 15:44:40.000000000,2019-02-25 13:45:32.000000000,2019-02-25 13:45:32.000000000,"[{'_account_id': 7}, {'_account_id': 1063}, {'_account_id': 7634}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-31 15:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-resource-classes/commit/547276c8fb351b562d67fda5870a2c70350ac1c1', 'message': 'Add normalize_name utility\n\nThe normalize_name utility provides consumers of os-resource-classes\nwith a way of generating a known-good name for a custom resource class.\nThis is equivalent to the os-traits utility of the same name [1].\n\n[1] https://github.com/openstack/os-traits/blob/9eab06df2f7528d9cc2cdb5ade69ea9d27ceeb99/os_traits/__init__.py#L113\n\nChange-Id: Id5557d65f11ed4dee10c8df2a42a4c485bfd65d1\n'}, {'number': 2, 'created': '2019-01-31 16:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-resource-classes/commit/cb1dc6b3ccf52ea3841af8d39868b049cbb030d3', 'message': 'Add normalize_name utility\n\nThe normalize_name utility provides consumers of os-resource-classes\nwith a way of generating a known-good name for a custom resource class.\nThis is equivalent to the os-traits utility of the same name [1].\n\n[1] https://github.com/openstack/os-traits/blob/9eab06df2f7528d9cc2cdb5ade69ea9d27ceeb99/os_traits/__init__.py#L113\n\nChange-Id: Id5557d65f11ed4dee10c8df2a42a4c485bfd65d1\n'}, {'number': 3, 'created': '2019-02-01 13:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-resource-classes/commit/b859dbbd0a8f5fb600ab49b97f60b996d8160e16', 'message': 'Add normalize_name utility\n\nThe normalize_name utility provides consumers of os-resource-classes\nwith a way of generating a known-good name for a custom resource class.\nThis is equivalent to the os-traits utility of the same name [1].\n\n[1] https://github.com/openstack/os-traits/blob/9eab06df2f7528d9cc2cdb5ade69ea9d27ceeb99/os_traits/__init__.py#L113\n\nChange-Id: Id5557d65f11ed4dee10c8df2a42a4c485bfd65d1\n'}, {'number': 4, 'created': '2019-02-01 14:42:00.000000000', 'files': ['os_resource_classes/__init__.py', 'os_resource_classes/tests/test_os_resource_classes.py'], 'web_link': 'https://opendev.org/openstack/os-resource-classes/commit/2d4672e5f342a4a5aec4ceca885cd7d966134ebb', 'message': 'Add normalize_name utility\n\nThe normalize_name utility provides consumers of os-resource-classes\nwith a way of generating a known-good name for a custom resource class.\nThis is equivalent to the os-traits utility of the same name [1].\n\n[1] https://github.com/openstack/os-traits/blob/9eab06df2f7528d9cc2cdb5ade69ea9d27ceeb99/os_traits/__init__.py#L113\n\nChange-Id: Id5557d65f11ed4dee10c8df2a42a4c485bfd65d1\n'}]",6,634258,2d4672e5f342a4a5aec4ceca885cd7d966134ebb,22,6,4,14070,,,0,"Add normalize_name utility

The normalize_name utility provides consumers of os-resource-classes
with a way of generating a known-good name for a custom resource class.
This is equivalent to the os-traits utility of the same name [1].

[1] https://github.com/openstack/os-traits/blob/9eab06df2f7528d9cc2cdb5ade69ea9d27ceeb99/os_traits/__init__.py#L113

Change-Id: Id5557d65f11ed4dee10c8df2a42a4c485bfd65d1
",git fetch https://review.opendev.org/openstack/os-resource-classes refs/changes/58/634258/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_resource_classes/__init__.py', 'os_resource_classes/tests/test_os_resource_classes.py']",2,547276c8fb351b562d67fda5870a2c70350ac1c1,normalize_name," def test_normalize_name(self): values = [ (""foo"", ""CUSTOM_FOO""), (""VCPU"", ""CUSTOM_VCPU""), (""CUSTOM_BOB"", ""CUSTOM_CUSTOM_BOB""), (""CUSTM_BOB"", ""CUSTOM_CUSTM_BOB""), ] for test_value, expected in values: result = rc.normalize_name(test_value) self.assertEqual(expected, result) def test_normalize_name_bug_1762789(self): """"""The .upper() builtin treats sharp S (\xdf) differently in py2 vs. py3. Make sure normalize_name handles it properly. """""" name = u'Fu\xdfball' self.assertEqual(u'CUSTOM_FU_BALL', rc.normalize_name(name))",,38,0
openstack%2Ftripleo-quickstart-extras~master~I3ac5ae0a0ec3bec9cc6b724416833451014ded19,openstack/tripleo-quickstart-extras,master,I3ac5ae0a0ec3bec9cc6b724416833451014ded19,Send return of tempest init to /dev/null,ABANDONED,2019-02-22 18:26:55.000000000,2019-02-25 13:11:48.000000000,,"[{'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-22 18:26:55.000000000', 'files': ['roles/validate-tempest/templates/configure-tempest.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d11d0f9c3690e93b231c4c480276e3eee1b23de6', 'message': ""Send return of tempest init to /dev/null\n\nThis is an emergencial workaround.\nBarbican and octavia tempest plugins are using same config, so\noslo is complaining about duplicate barbican option.\nSince we are running this in a containerized tempest image, with all\nrpms installed, there's no way right now to remove the package.\n\nChange-Id: I3ac5ae0a0ec3bec9cc6b724416833451014ded19\nRelated-Bug: 1817154\n""}]",1,638740,d11d0f9c3690e93b231c4c480276e3eee1b23de6,26,12,1,8367,,,0,"Send return of tempest init to /dev/null

This is an emergencial workaround.
Barbican and octavia tempest plugins are using same config, so
oslo is complaining about duplicate barbican option.
Since we are running this in a containerized tempest image, with all
rpms installed, there's no way right now to remove the package.

Change-Id: I3ac5ae0a0ec3bec9cc6b724416833451014ded19
Related-Bug: 1817154
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/40/638740/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/templates/configure-tempest.sh.j2'],1,d11d0f9c3690e93b231c4c480276e3eee1b23de6,bug/1817154, # TODO(arxcruz) This is wrong! We should not send the output to /dev/null but # due the lp #1817154 we are doing it. We need to identify where in # octavia-tempest-plugin barbican option is being called and find a proper way # to handle it. {{ tempest_init }} > /dev/null,{{ tempest_init }},6,1
openstack%2Fkolla~master~I27308a2435a4dca572d736f56a02b0bbc8563981,openstack/kolla,master,I27308a2435a4dca572d736f56a02b0bbc8563981,Switch to stestr,MERGED,2018-07-10 11:19:32.000000000,2019-02-25 13:11:23.000000000,2019-02-25 13:11:23.000000000,"[{'_account_id': 24}, {'_account_id': 7488}, {'_account_id': 16282}, {'_account_id': 19316}, {'_account_id': 21691}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23717}, {'_account_id': 23942}, {'_account_id': 24162}, {'_account_id': 25903}, {'_account_id': 26072}, {'_account_id': 27781}, {'_account_id': 28176}]","[{'number': 1, 'created': '2018-07-10 11:19:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c9c41927bd260f6aa89c36b9c06805ed01651451', 'message': ""Switch to stestr\n\nAccording to Openstack summit session [1],\nstestr is maintained project to which all Openstack projects should migrate.\nLet's switch to stestr as other projects have already moved to it.\n\n[1] https://etherpad.openstack.org/p/YVR-python-pti\n\nChange-Id: I27308a2435a4dca572d736f56a02b0bbc8563981\n""}, {'number': 2, 'created': '2018-07-10 11:43:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/82b9e30aa9a0a4fb9d4a17b54d3c2c7cab720365', 'message': ""Switch to stestr\n\nAccording to Openstack summit session [1],\nstestr is maintained project to which all Openstack projects should migrate.\nLet's switch to stestr as other projects have already moved to it.\n\n[1] https://etherpad.openstack.org/p/YVR-python-pti\n\nChange-Id: I27308a2435a4dca572d736f56a02b0bbc8563981\n""}, {'number': 3, 'created': '2018-07-11 00:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0410ecd8f39a52cf3a58989e1605f7c19834f03a', 'message': ""Switch to stestr\n\nAccording to Openstack summit session [1],\nstestr is maintained project to which all Openstack projects should migrate.\nLet's switch to stestr as other projects have already moved to it.\n\n[1] https://etherpad.openstack.org/p/YVR-python-pti\n\nChange-Id: I27308a2435a4dca572d736f56a02b0bbc8563981\n""}, {'number': 4, 'created': '2018-07-11 01:32:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2f7afbaae2f48fe062c97ba1b9201178c6d3dcac', 'message': ""Switch to stestr\n\nAccording to Openstack summit session [1],\nstestr is maintained project to which all Openstack projects should migrate.\nLet's switch to stestr as other projects have already moved to it.\n\n[1] https://etherpad.openstack.org/p/YVR-python-pti\n\nChange-Id: I27308a2435a4dca572d736f56a02b0bbc8563981\n""}, {'number': 5, 'created': '2018-07-18 01:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2837c6fd95ea2aefdb12feb3164670f1bb0f44a1', 'message': ""Switch to stestr\n\nAccording to Openstack summit session [1],\nstestr is maintained project to which all Openstack projects should migrate.\nLet's switch to stestr as other projects have already moved to it.\n\n[1] https://etherpad.openstack.org/p/YVR-python-pti\n\nChange-Id: I27308a2435a4dca572d736f56a02b0bbc8563981\n""}, {'number': 6, 'created': '2018-07-23 06:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0263e08dc9826d6b30ba6e163ecd579940224608', 'message': ""Switch to stestr\n\nAccording to Openstack summit session [1],\nstestr is maintained project to which all Openstack projects should migrate.\nLet's switch to stestr as other projects have already moved to it.\n\n[1] https://etherpad.openstack.org/p/YVR-python-pti\n\nChange-Id: I27308a2435a4dca572d736f56a02b0bbc8563981\n""}, {'number': 7, 'created': '2018-10-31 22:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f0f8e055c86dae4e4e8b7426d87aac782b7b98b5', 'message': ""Switch to stestr\n\nAccording to Openstack summit session [1],\nstestr is maintained project to which all Openstack projects should migrate.\nLet's switch to stestr as other projects have already moved to it.\n\n[1] https://etherpad.openstack.org/p/YVR-python-pti\n\nChange-Id: I27308a2435a4dca572d736f56a02b0bbc8563981\n""}, {'number': 8, 'created': '2018-11-03 19:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ae8ed2c3703cbb495b09b1688e62a2c0bf2d2216', 'message': ""Switch to stestr\n\nAccording to Openstack summit session [1],\nstestr is maintained project to which all Openstack projects should migrate.\nLet's switch to stestr as other projects have already moved to it.\n\n[1] https://etherpad.openstack.org/p/YVR-python-pti\n\nChange-Id: I27308a2435a4dca572d736f56a02b0bbc8563981\n""}, {'number': 9, 'created': '2018-11-18 20:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/143ffa82a427ab9e96a88be9406266ce1c740eed', 'message': ""Switch to stestr\n\nAccording to Openstack summit session [1],\nstestr is maintained project to which all Openstack projects should migrate.\nLet's switch to stestr as other projects have already moved to it.\n\n[1] https://etherpad.openstack.org/p/YVR-python-pti\n\nChange-Id: I27308a2435a4dca572d736f56a02b0bbc8563981\n""}, {'number': 10, 'created': '2019-01-24 05:46:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/5e88df6595e44c1e89cdc65bbc81a147e4acbf3d', 'message': ""Switch to stestr\n\nAccording to Openstack summit session [1],\nstestr is maintained project to which all Openstack projects should migrate.\nLet's switch to stestr as other projects have already moved to it.\n\n[1] https://etherpad.openstack.org/p/YVR-python-pti\n\nChange-Id: I27308a2435a4dca572d736f56a02b0bbc8563981\n""}, {'number': 11, 'created': '2019-01-26 19:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/19ecb7adc46e144df466b56eb14e4794a4aa875e', 'message': ""Switch to stestr\n\nAccording to Openstack summit session [1],\nstestr is maintained project to which all Openstack projects should migrate.\nLet's switch to stestr as other projects have already moved to it.\n\n[1] https://etherpad.openstack.org/p/YVR-python-pti\n\nChange-Id: I27308a2435a4dca572d736f56a02b0bbc8563981\n""}, {'number': 12, 'created': '2019-02-24 19:24:37.000000000', 'files': ['.gitignore', 'test-requirements.txt', '.testr.conf', 'lower-constraints.txt', 'tox.ini', '.stestr.conf'], 'web_link': 'https://opendev.org/openstack/kolla/commit/92d35e9e8c4c437a3199cdde87b2508406bb157d', 'message': ""Switch to stestr\n\nAccording to Openstack summit session [1],\nstestr is maintained project to which all Openstack projects should migrate.\nLet's switch to stestr as other projects have already moved to it.\n\n[1] https://etherpad.openstack.org/p/YVR-python-pti\n\nChange-Id: I27308a2435a4dca572d736f56a02b0bbc8563981\n""}]",12,581322,92d35e9e8c4c437a3199cdde87b2508406bb157d,56,15,12,25903,,,0,"Switch to stestr

According to Openstack summit session [1],
stestr is maintained project to which all Openstack projects should migrate.
Let's switch to stestr as other projects have already moved to it.

[1] https://etherpad.openstack.org/p/YVR-python-pti

Change-Id: I27308a2435a4dca572d736f56a02b0bbc8563981
",git fetch https://review.opendev.org/openstack/kolla refs/changes/22/581322/6 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'test-requirements.txt', '.testr.conf', 'lower-constraints.txt', 'tox.ini', '.stestr.conf']",6,c9c41927bd260f6aa89c36b9c06805ed01651451,stestr,[DEFAULT] test_path=./kolla/tests top_dir=./ ,,14,12
openstack%2Ftempest~master~I4cccab542b3ee3e1fe4d1751665541c850427be6,openstack/tempest,master,I4cccab542b3ee3e1fe4d1751665541c850427be6,Adding DuplicateOptError exception on register_opts,ABANDONED,2019-02-25 10:18:01.000000000,2019-02-25 13:10:12.000000000,,"[{'_account_id': 5803}, {'_account_id': 8175}, {'_account_id': 8556}, {'_account_id': 10459}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-25 10:18:01.000000000', 'files': ['tempest/test_discover/plugins.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c35851475b2c9ee067a207c2427ee3d00545b74e', 'message': ""Adding DuplicateOptError exception on register_opts\n\nThis is just to warn the user that there's a duplicated option.\nUsually, this happen when you have two tempest plugin installed on your\nsystem and both are trying to configure the same option.\nAs an example happening right now, the change\nI7013888f94261d94e1cd4c3167dc84da7125d1da added on octavia tempest\nplugin a verification if barbican is enabled or not, if not, it set the\nservice avialbility to barbican to false, and on barbican when\nregister_opts is called, it fails because the service_available.barbican\nwas already configured to False.\n\nChange-Id: I4cccab542b3ee3e1fe4d1751665541c850427be6\nCloses-Bug: 1817154\n""}]",0,639049,c35851475b2c9ee067a207c2427ee3d00545b74e,5,7,1,8367,,,0,"Adding DuplicateOptError exception on register_opts

This is just to warn the user that there's a duplicated option.
Usually, this happen when you have two tempest plugin installed on your
system and both are trying to configure the same option.
As an example happening right now, the change
I7013888f94261d94e1cd4c3167dc84da7125d1da added on octavia tempest
plugin a verification if barbican is enabled or not, if not, it set the
service avialbility to barbican to false, and on barbican when
register_opts is called, it fails because the service_available.barbican
was already configured to False.

Change-Id: I4cccab542b3ee3e1fe4d1751665541c850427be6
Closes-Bug: 1817154
",git fetch https://review.opendev.org/openstack/tempest refs/changes/49/639049/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/test_discover/plugins.py'],1,c35851475b2c9ee067a207c2427ee3d00545b74e,bug/1817154,"from oslo_config.cfg import DuplicateOptError except DuplicateOptError: LOG.warning('Duplicated option for plugin %s', plug.name)",,3,0
openstack%2Fos-vif~master~I8308e8840e20b0a72d00880c1a7996b4c73f6a83,openstack/os-vif,master,I8308e8840e20b0a72d00880c1a7996b4c73f6a83,remove brctl from vif_plug_ovs,MERGED,2019-02-14 04:07:43.000000000,2019-02-25 13:02:58.000000000,2019-02-25 13:02:57.000000000,"[{'_account_id': 7}, {'_account_id': 7166}, {'_account_id': 9555}, {'_account_id': 9732}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 25733}]","[{'number': 1, 'created': '2019-02-14 04:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/4d2425bfbe0924a721b983f698fd11e21b55fd03', 'message': '[WIP] remove brctl from vif_plug_ovs\n\n- This change extends the ip_command interface set function\n  to accept a master as a parent device for a given interface.\n- This change extends the impl_pyroute2 add function to\n  support creating linux bridges.\n- This change replaces calls to brctl with calls to the ip_command api.\n- TODO update unit tests and add fuctional tests.\n\nChange-Id: I8308e8840e20b0a72d00880c1a7996b4c73f6a83\nPartial-Bug: #1801919\n'}, {'number': 2, 'created': '2019-02-19 11:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/9fef3ec2b14fec8d7d3ac7cf42be41a20f86008c', 'message': '[WIP] remove brctl from vif_plug_ovs\n\n- This change extends the ip_command interface set function\n  to accept a master as a parent device for a given interface.\n- This change extends the impl_pyroute2 add function to\n  support creating linux bridges.\n- This change replaces calls to brctl with calls to the ip_command api.\n\nChange-Id: I8308e8840e20b0a72d00880c1a7996b4c73f6a83\nPartial-Bug: #1801919\n'}, {'number': 3, 'created': '2019-02-19 11:52:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/46edd3849e8400bd9c3facbccbb51bcb73efe619', 'message': 'remove brctl from vif_plug_ovs\n\n- This change extends the ip_command interface set function\n  to accept a master as a parent device for a given interface.\n- This change extends the impl_pyroute2 add function to\n  support creating linux bridges.\n- This change replaces calls to brctl with calls to the ip_command api.\n\nChange-Id: I8308e8840e20b0a72d00880c1a7996b4c73f6a83\nPartial-Bug: #1801919\n'}, {'number': 4, 'created': '2019-02-19 22:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/6e6e7edcf17ea055978f7360330a45a220e379a2', 'message': 'remove brctl from vif_plug_ovs\n\n- This change extends the ip_command interface set function\n  to accept a master as a parent device for a given interface.\n- This change extends the impl_pyroute2 add function to\n  support creating linux bridges.\n- This change replaces calls to brctl with calls to the ip_command api.\n\nChange-Id: I8308e8840e20b0a72d00880c1a7996b4c73f6a83\nPartial-Bug: #1801919\n'}, {'number': 5, 'created': '2019-02-21 15:16:54.000000000', 'files': ['os_vif/internal/command/ip/windows/impl_netifaces.py', 'os_vif/internal/command/ip/linux/impl_pyroute2.py', 'os_vif/tests/unit/internal/command/ip/linux/test_impl_pyroute2.py', 'os_vif/internal/command/ip/ip_command.py', 'vif_plug_ovs/linux_net.py', 'vif_plug_ovs/tests/unit/test_linux_net.py', 'os_vif/tests/functional/internal/command/ip/test_impl_pyroute2.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/5027ce833c6fccaa80b5ddc8544d262c0bf99dbd', 'message': 'remove brctl from vif_plug_ovs\n\n- This change extends the ip_command interface set function\n  to accept a master as a parent device for a given interface.\n- This change extends the impl_pyroute2 add function to\n  support creating linux bridges.\n- This change replaces calls to brctl with calls to the ip_command api.\n- This change removes the use of tee to disable ipv6 in the ovs plugin.\n\nChange-Id: I8308e8840e20b0a72d00880c1a7996b4c73f6a83\nPartial-Bug: #1801919\n'}]",24,636821,5027ce833c6fccaa80b5ddc8544d262c0bf99dbd,28,9,5,11604,,,0,"remove brctl from vif_plug_ovs

- This change extends the ip_command interface set function
  to accept a master as a parent device for a given interface.
- This change extends the impl_pyroute2 add function to
  support creating linux bridges.
- This change replaces calls to brctl with calls to the ip_command api.
- This change removes the use of tee to disable ipv6 in the ovs plugin.

Change-Id: I8308e8840e20b0a72d00880c1a7996b4c73f6a83
Partial-Bug: #1801919
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/21/636821/5 && git format-patch -1 --stdout FETCH_HEAD,"['os_vif/internal/command/ip/linux/impl_pyroute2.py', 'os_vif/internal/command/ip/windows/impl_netifaces.py', 'os_vif/internal/command/ip/ip_command.py', 'vif_plug_ovs/linux_net.py']",4,4d2425bfbe0924a721b983f698fd11e21b55fd03,bug/1801919," ip_lib.add(bridge, 'bridge') # TODO(sean-k-mooney): determine why we do this and # either remove or rewrite to stop using tee. # Note(sean-k-mooney): this will detach all ports on # the bridge before deleting the bridge. ip_lib.delete(bridge, check_exit_code=[0, 2, 254]) # howver it will not set the detached interface down # so we set the dev down if dev is not None and exists. if dev and ip_lib.exists(dev): set_interface_state(dev, ""down"") ip_lib.set(dev, master=bridge)","def interface_in_bridge(bridge, device): """"""Check if an ethernet device belongs to a Linux Bridge."""""" return os.path.exists('/sys/class/net/%(bridge)s/brif/%(device)s' % {'bridge': bridge, 'device': device}) processutils.execute('brctl', 'addbr', bridge) processutils.execute('brctl', 'setfd', bridge, 0) processutils.execute('brctl', 'stp', bridge, 'off') processutils.execute('brctl', 'setageing', bridge, 0) syspath = '/sys/class/net/%s/bridge/multicast_snooping' syspath = syspath % bridge processutils.execute('tee', syspath, process_input='0', check_exit_code=[0, 1]) if interface_in_bridge(bridge, dev): processutils.execute('brctl', 'delif', bridge, dev) ip_lib.set(bridge, state='down') processutils.execute('brctl', 'delbr', bridge) processutils.execute('brctl', 'addif', bridge, dev)",23,23
openstack%2Ftacker~master~If9c36cb260d43bec515a52b93e10f714d063dc92,openstack/tacker,master,If9c36cb260d43bec515a52b93e10f714d063dc92,vnffg-create failed abnormally due to invalid network_src_port_id,MERGED,2019-02-13 12:05:44.000000000,2019-02-25 12:55:31.000000000,2019-02-25 12:55:31.000000000,"[{'_account_id': 18955}, {'_account_id': 19644}, {'_account_id': 20182}, {'_account_id': 22348}, {'_account_id': 26222}, {'_account_id': 27068}]","[{'number': 1, 'created': '2019-02-13 12:05:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/ff62305acf661a0d7357d0f4f3fb219b0d3d5aeb', 'message': 'vnffg-create failed abnormally due to invalid network_src_port_id\n\nWhen create a vnffg with a non-existent network_src_port_id in vnffgd,\ncreate command failed abnormally with ""internal server error"".\nThis patch will handle the issue and raise FlowClassifierPortNotFound\nexception.\n\nChange-Id: If9c36cb260d43bec515a52b93e10f714d063dc92\n'}, {'number': 2, 'created': '2019-02-13 12:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/09a176ce469ae4125dd6f454ab12ce3ee24ec606', 'message': 'vnffg-create failed abnormally due to invalid network_src_port_id\n\nWhen create a vnffg with a non-existent network_src_port_id in vnffgd,\ncreate command failed abnormally with ""internal server error"".\nThis patch will handle the issue and raise FlowClassifierPortNotFound\nexception.\n\nPartially Implements: blueprint improve-return-message\nCloses-bug: #1710633\n\nChange-Id: If9c36cb260d43bec515a52b93e10f714d063dc92\n'}, {'number': 3, 'created': '2019-02-21 10:33:16.000000000', 'files': ['tacker/nfvo/drivers/vim/openstack_driver.py', 'tacker/extensions/nfvo.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/ae8f8c7d9d2d3940959381e1176994d52d9425d2', 'message': 'vnffg-create failed abnormally due to invalid network_src_port_id\n\nWhen create a vnffg with a non-existent network_src_port_id in vnffgd,\ncreate command failed abnormally with ""internal server error"".\nThis patch will handle the issue and raise FlowClassifierPortNotFound\nexception.\n\nPartially Implements: blueprint improve-return-message\nCloses-bug: #1710633\n\nChange-Id: If9c36cb260d43bec515a52b93e10f714d063dc92\n'}]",7,636605,ae8f8c7d9d2d3940959381e1176994d52d9425d2,18,6,3,18955,,,0,"vnffg-create failed abnormally due to invalid network_src_port_id

When create a vnffg with a non-existent network_src_port_id in vnffgd,
create command failed abnormally with ""internal server error"".
This patch will handle the issue and raise FlowClassifierPortNotFound
exception.

Partially Implements: blueprint improve-return-message
Closes-bug: #1710633

Change-Id: If9c36cb260d43bec515a52b93e10f714d063dc92
",git fetch https://review.opendev.org/openstack/tacker refs/changes/05/636605/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/nfvo/drivers/vim/openstack_driver.py', 'tacker/extensions/nfvo.py']",2,ff62305acf661a0d7357d0f4f3fb219b0d3d5aeb,bug/1710633,"class FlowClassifierPortNotFound(exceptions.NotFound): message = _(""%(message)s"") ",,14,6
openstack%2Fmetalsmith~master~I29fd07ae6610f289221a175ed0e2e7ba3842694b,openstack/metalsmith,master,I29fd07ae6610f289221a175ed0e2e7ba3842694b,[DNM] Test using ironic for generating configdrive,ABANDONED,2019-02-25 08:32:24.000000000,2019-02-25 12:32:48.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-25 08:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/metalsmith/commit/f27e005b6f0b47b0cf03b47d733a5afbadd21ab0', 'message': '[DNM] Test omitting configdrive fields\n\nChange-Id: I29fd07ae6610f289221a175ed0e2e7ba3842694b\n'}, {'number': 2, 'created': '2019-02-25 09:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/metalsmith/commit/19e8b31c0105ac7d77d1551bb321c9355ec6a88b', 'message': '[DNM] Test omitting configdrive fields\n\nChange-Id: I29fd07ae6610f289221a175ed0e2e7ba3842694b\n'}, {'number': 3, 'created': '2019-02-25 11:05:03.000000000', 'files': ['metalsmith/_config.py', 'metalsmith/_provisioner.py'], 'web_link': 'https://opendev.org/openstack/metalsmith/commit/b693d8b45591d391fa65e266bc43bafadcb9ffa5', 'message': '[DNM] Test using ironic for generating configdrive\n\nDepends-On: https://review.openstack.org/639050\nChange-Id: I29fd07ae6610f289221a175ed0e2e7ba3842694b\n'}]",0,639030,b693d8b45591d391fa65e266bc43bafadcb9ffa5,6,1,3,10239,,,0,"[DNM] Test using ironic for generating configdrive

Depends-On: https://review.openstack.org/639050
Change-Id: I29fd07ae6610f289221a175ed0e2e7ba3842694b
",git fetch https://review.opendev.org/openstack/metalsmith refs/changes/30/639030/3 && git format-patch -1 --stdout FETCH_HEAD,['metalsmith/_config.py'],1,f27e005b6f0b47b0cf03b47d733a5afbadd21ab0,story/2005083, 'name': node.name}," 'name': node.name, 'hostname': hostname, 'launch_index': 0, 'availability_zone': '', 'files': [], 'meta': {}}",1,6
openstack%2Fkolla-ansible~stable%2Frocky~Ia2f879401e585e6043f69cc5e3ab1a1f72f7f033,openstack/kolla-ansible,stable/rocky,Ia2f879401e585e6043f69cc5e3ab1a1f72f7f033,[prometheus] Enable ceph mgr exporter,MERGED,2019-01-18 19:23:29.000000000,2019-02-25 12:32:00.000000000,2019-02-25 12:32:00.000000000,"[{'_account_id': 1390}, {'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 20301}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 26285}]","[{'number': 1, 'created': '2019-01-18 19:23:29.000000000', 'files': ['releasenotes/notes/prometheus-add-ceph-manager-plugin-7bcde3ec0356e26b.yaml', 'ansible/roles/ceph/tasks/start_mgrs.yml', 'ansible/group_vars/all.yml', 'etc/kolla/globals.yml', 'ansible/roles/prometheus/templates/prometheus.yml.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2cb13e408d7c59fe53c0832f5428b30c327e95df', 'message': '[prometheus] Enable ceph mgr exporter\n\nThis patch enables the ceph mgr prometheus exporter.\n\nIf enable_prometheus_ceph_mgr_exporter is set to true,\nthe ceph mgr prometheus plugin is enabled on the hosts that are part\nof the ceph-mgr group, then the exporter is added into the prometheus-server\nconfiguration file.\n\nChange-Id: Ia2f879401e585e6043f69cc5e3ab1a1f72f7f033\n(cherry picked from commit 9d2770db1107c7c32f278eb150ac01e1985df5cf)\n'}]",0,631871,2cb13e408d7c59fe53c0832f5428b30c327e95df,9,7,1,2276,,,0,"[prometheus] Enable ceph mgr exporter

This patch enables the ceph mgr prometheus exporter.

If enable_prometheus_ceph_mgr_exporter is set to true,
the ceph mgr prometheus plugin is enabled on the hosts that are part
of the ceph-mgr group, then the exporter is added into the prometheus-server
configuration file.

Change-Id: Ia2f879401e585e6043f69cc5e3ab1a1f72f7f033
(cherry picked from commit 9d2770db1107c7c32f278eb150ac01e1985df5cf)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/71/631871/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/prometheus-add-ceph-manager-plugin-7bcde3ec0356e26b.yaml', 'ansible/roles/ceph/tasks/start_mgrs.yml', 'ansible/group_vars/all.yml', 'etc/kolla/globals.yml', 'ansible/roles/prometheus/templates/prometheus.yml.j2']",5,2cb13e408d7c59fe53c0832f5428b30c327e95df,add-ceph-prometheus-stable/rocky,"{% if enable_prometheus_ceph_mgr_exporter | bool %} - job_name: ceph_mgr_exporter honor_labels: true static_configs: - targets: {% for host in groups[""ceph-mgr""] %} - '{{ hostvars[host]['ansible_' + hostvars[host]['api_interface']]['ipv4']['address'] }}:{{ hostvars[host]['prometheus_ceph_mgr_exporter_port'] }}' {% endfor %} {% endif %} ",,25,0
openstack%2Ftripleo-quickstart~master~Id57fa2955c90d6d7632a69821a171d0ea4eca3bd,openstack/tripleo-quickstart,master,Id57fa2955c90d6d7632a69821a171d0ea4eca3bd,[wip]Use action_plugin from role itself,ABANDONED,2019-02-25 09:34:50.000000000,2019-02-25 12:17:06.000000000,,[{'_account_id': 18846}],"[{'number': 1, 'created': '2019-02-25 09:34:50.000000000', 'files': ['ansible.cfg'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/e75514ff50eadaeb117d54d0ac421df7503b0d91', 'message': '[wip]Use action_plugin from role itself\n\nChange-Id: Id57fa2955c90d6d7632a69821a171d0ea4eca3bd\n'}]",0,639038,e75514ff50eadaeb117d54d0ac421df7503b0d91,3,1,1,12393,,,0,"[wip]Use action_plugin from role itself

Change-Id: Id57fa2955c90d6d7632a69821a171d0ea4eca3bd
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/38/639038/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible.cfg'],1,e75514ff50eadaeb117d54d0ac421df7503b0d91,,,action_plugins = /usr/share/ansible/plugins/action:$VIRTUAL_ENV/usr/share/ansible/plugins/action,0,1
openstack%2Fzun~master~Ib8d2dff699a816686be4b1a53bf1463ffce02cdf,openstack/zun,master,Ib8d2dff699a816686be4b1a53bf1463ffce02cdf,Remove sandbox-related logic,MERGED,2019-02-18 23:02:28.000000000,2019-02-25 12:00:42.000000000,2019-02-25 12:00:42.000000000,"[{'_account_id': 21428}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-18 23:02:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/8f27a81a5ab86ccc920c5187fcc217f277d49858', 'message': '[WIP] Remove sandbox-related logic\n\nChange-Id: Ib8d2dff699a816686be4b1a53bf1463ffce02cdf\n'}, {'number': 2, 'created': '2019-02-18 23:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/cd23455d8c265a8608b0924eedbe74c869420b30', 'message': ""Remove sandbox-related logic\n\nThe 'sandbox' code path in compute manager and driver is only\nused to create/delete capsule. After the consolidation of\ncapsule and container code [1][2], the sandbox logic is not\nused anymore. This commit removes these unused code.\n\n[1] https://review.openstack.org/#/c/636070/\n[2] https://review.openstack.org/#/c/633371/\n\nChange-Id: Ib8d2dff699a816686be4b1a53bf1463ffce02cdf\n""}, {'number': 3, 'created': '2019-02-24 19:37:25.000000000', 'files': ['zun/tests/unit/compute/test_compute_manager.py', 'zun/conf/container_driver.py', 'zun/tests/unit/container/fake_driver.py', 'zun/container/driver.py', 'zun/tests/unit/container/docker/test_docker_driver.py', 'zun/tests/unit/objects/test_objects.py', 'zun/network/kuryr_network.py', 'zun/container/docker/driver.py', 'zun/compute/manager.py', 'zun/common/consts.py', 'zun/objects/container.py', 'zun/tests/unit/objects/test_fields.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/9f03c3e9414dd1fa61c92063a8b8fbf4794cc6e5', 'message': ""Remove sandbox-related logic\n\nThe 'sandbox' code path in compute manager and driver is only\nused to create/delete capsule. After the consolidation of\ncapsule and container code [1][2], the sandbox logic is not\nused anymore. This commit removes these unused code.\n\n[1] https://review.openstack.org/#/c/636070/\n[2] https://review.openstack.org/#/c/633371/\n\nChange-Id: Ib8d2dff699a816686be4b1a53bf1463ffce02cdf\n""}]",0,637648,9f03c3e9414dd1fa61c92063a8b8fbf4794cc6e5,9,2,3,11536,,,0,"Remove sandbox-related logic

The 'sandbox' code path in compute manager and driver is only
used to create/delete capsule. After the consolidation of
capsule and container code [1][2], the sandbox logic is not
used anymore. This commit removes these unused code.

[1] https://review.openstack.org/#/c/636070/
[2] https://review.openstack.org/#/c/633371/

Change-Id: Ib8d2dff699a816686be4b1a53bf1463ffce02cdf
",git fetch https://review.opendev.org/openstack/zun refs/changes/48/637648/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/network/kuryr_network.py', 'zun/conf/container_driver.py', 'zun/container/docker/driver.py', 'zun/compute/manager.py', 'zun/container/driver.py', 'zun/common/consts.py', 'zun/objects/container.py']",7,8f27a81a5ab86ccc920c5187fcc217f277d49858,,," def get_sandbox_id(self): if self.meta: return self.meta.get('sandbox_id', None) else: return None def set_sandbox_id(self, sandbox_id): if self.meta is None: self.meta = {'sandbox_id': sandbox_id} else: self.meta['sandbox_id'] = sandbox_id self._changed_fields.add('meta') ",20,228
openstack%2Fzun~master~I776bb2a49c6c599fb9bf4195cbbec4ad77846279,openstack/zun,master,I776bb2a49c6c599fb9bf4195cbbec4ad77846279,Drop capsule data model in DB and objects,MERGED,2019-02-18 20:41:03.000000000,2019-02-25 12:00:41.000000000,2019-02-25 12:00:41.000000000,"[{'_account_id': 11536}, {'_account_id': 21428}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-18 20:41:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/82559966bffba3a7cc32388967448de9fdbe5f05', 'message': 'Drop capsule data model in DB and objects\n\nThe capsule data model has been merged to container by [1].\nThe existing capsule table and object are not used anymore.\n\n[1] https://review.openstack.org/#/c/636070/\n\nChange-Id: I776bb2a49c6c599fb9bf4195cbbec4ad77846279\n'}, {'number': 2, 'created': '2019-02-18 20:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/6f9008925147c1558320ad94f1fc1cf31135c0cc', 'message': 'Drop capsule data model in DB and objects\n\nThe capsule data model has been merged to container by [1].\nThe existing capsule table and object are not used anymore.\n\n[1] https://review.openstack.org/#/c/636070/\n\nChange-Id: I776bb2a49c6c599fb9bf4195cbbec4ad77846279\n'}, {'number': 3, 'created': '2019-02-24 19:37:25.000000000', 'files': ['zun/tests/unit/db/utils.py', 'zun/db/api.py', 'zun/db/sqlalchemy/models.py', 'zun/db/sqlalchemy/api.py', 'zun/tests/unit/db/test_capsule.py', 'zun/db/sqlalchemy/alembic/versions/157a0595e13e_drop_capsule_table.py', 'zun/objects/capsule.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/a18ae456af11d63e3257bdabbbb47421213fe8a9', 'message': 'Drop capsule data model in DB and objects\n\nThe capsule data model has been merged to container by [1].\nThe existing capsule table and object are not used anymore.\n\n[1] https://review.openstack.org/#/c/636070/\n\nChange-Id: I776bb2a49c6c599fb9bf4195cbbec4ad77846279\n'}]",0,637625,a18ae456af11d63e3257bdabbbb47421213fe8a9,12,3,3,11536,,,0,"Drop capsule data model in DB and objects

The capsule data model has been merged to container by [1].
The existing capsule table and object are not used anymore.

[1] https://review.openstack.org/#/c/636070/

Change-Id: I776bb2a49c6c599fb9bf4195cbbec4ad77846279
",git fetch https://review.opendev.org/openstack/zun refs/changes/25/637625/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/tests/unit/db/utils.py', 'zun/db/api.py', 'zun/db/sqlalchemy/models.py', 'zun/db/sqlalchemy/api.py', 'zun/tests/unit/db/test_capsule.py', 'zun/db/sqlalchemy/alembic/versions/157a0595e13e_drop_capsule_table.py', 'zun/objects/capsule.py']",7,82559966bffba3a7cc32388967448de9fdbe5f05,,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_log import log as logging from oslo_versionedobjects import fields from zun.common import exception from zun.db import api as dbapi from zun.objects import base from zun.objects import container from zun.objects import fields as z_fields LOG = logging.getLogger(__name__) _CAPSULE_OPTIONAL_JOINED_FIELD = ['containers'] CAPSULE_OPTIONAL_ATTRS = _CAPSULE_OPTIONAL_JOINED_FIELD @base.ZunObjectRegistry.register class Capsule(base.ZunPersistentObject, base.ZunObject): # Version 1.0: Initial version # Version 1.1: Add host to capsule # Version 1.2: Change the properties of meta_labels # Version 1.3: Add 'Deleting' to ContainerStatus # Version 1.4: Add addresses and volumes_info # Version 1.5: Change the properties of restort_policy # Version 1.6: Change the type of status # Version 1.7: Add initContainers uuids VERSION = '1.7' fields = { 'capsule_version': fields.StringField(nullable=True), 'kind': fields.StringField(nullable=True), 'restart_policy': fields.StringField(nullable=True), 'host_selector': fields.StringField(nullable=True), 'id': fields.IntegerField(), 'uuid': fields.UUIDField(nullable=True), 'project_id': fields.StringField(nullable=True), 'user_id': fields.StringField(nullable=True), 'status': z_fields.CapsuleStatusField(nullable=True), 'status_reason': fields.StringField(nullable=True), 'cpu': fields.FloatField(nullable=True), 'memory': fields.StringField(nullable=True), 'addresses': z_fields.JsonField(nullable=True), # conclude the readable message # 'key': 'value'--> 'time':'message' # wait until zun notify is finished # 'message': fields.DictOfStringsField(nullable=True), 'spec': z_fields.JsonField(nullable=True), 'meta_name': fields.StringField(nullable=True), 'meta_labels': fields.DictOfStringsField(nullable=True), 'containers': fields.ListOfObjectsField('Container', nullable=True), # The list of containers uuids inside the capsule 'containers_uuids': fields.ListOfStringsField(nullable=True), 'init_containers_uuids': fields.ListOfStringsField(nullable=True), 'host': fields.StringField(nullable=True), # volumes_info records the volume and container attached # relationship: # {'<volume-uuid1>': ['<container-uuid1>', '<container-uuid2>'], # '<volume-uuid2>': ['<container-uuid2>', '<container-uuid3>']}, # one container can attach at least one volume, also will support # one volume multiple in the future. 'volumes_info': z_fields.JsonField(nullable=True), } @staticmethod def _from_db_object(capsule, db_capsule): """"""Converts a database entity to a formal object."""""" for field in capsule.fields: if field in CAPSULE_OPTIONAL_ATTRS: continue setattr(capsule, field, db_capsule[field]) capsule.obj_reset_changes() return capsule @staticmethod def _from_db_object_list(db_objects, cls, context): """"""Converts a list of database entities to a list of formal objects."""""" return [Capsule._from_db_object(cls(context), obj) for obj in db_objects] @base.remotable_classmethod def get_by_uuid(cls, context, uuid): """"""Find a capsule based on uuid and return a :class:`Capsule` object. :param uuid: the uuid of a capsule. :param context: Security context :returns: a :class:`Capsule` object. """""" db_capsule = dbapi.get_capsule_by_uuid(context, uuid) capsule = Capsule._from_db_object(cls(context), db_capsule) return capsule @base.remotable_classmethod def get_by_name(cls, context, name): """"""Find a capsule based on name and return a :class:`Capsule` object. :param name: the meta_name of a capsule. :param context: Security context :returns: a :class:`Capsule` object. """""" db_capsule = dbapi.get_capsule_by_meta_name(context, name) capsule = Capsule._from_db_object(cls(context), db_capsule) return capsule @base.remotable_classmethod def list(cls, context, limit=None, marker=None, sort_key=None, sort_dir=None, filters=None): """"""Return a list of Capsule objects. :param context: Security context. :param limit: maximum number of resources to return in a single result. :param marker: pagination marker for large data sets. :param sort_key: column to sort results by. :param sort_dir: direction to sort. ""asc"" or ""desc"". :param filters: filters when list capsules, the filter name could be 'name', 'image', 'project_id', 'user_id', 'memory'. For example, filters={'image': 'nginx'} :returns: a list of :class:`Capsule` object. """""" db_capsules = dbapi.list_capsules( context, limit=limit, marker=marker, sort_key=sort_key, sort_dir=sort_dir, filters=filters) return Capsule._from_db_object_list(db_capsules, cls, context) @base.remotable def create(self, context): """"""Create a Container record in the DB. :param context: Security context. NOTE: This should only be used internally by the indirection_api. Unfortunately, RPC requires context as the first argument, even though we don't use it. A context should be set when instantiating the object, e.g.: Capsule(context) """""" values = self.obj_get_changes() if 'containers' in values: raise exception.ObjectActionError(action='create', reason='containers assigned') db_capsule = dbapi.create_capsule(context, values) self._from_db_object(self, db_capsule) @base.remotable def destroy(self, context=None): """"""Delete the Container from the DB. :param context: Security context. NOTE: This should only be used internally by the indirection_api. Unfortunately, RPC requires context as the first argument, even though we don't use it. A context should be set when instantiating the object, e.g.: Capsule(context) """""" dbapi.destroy_capsule(context, self.uuid) self.obj_reset_changes() @base.remotable def save(self, context=None): """"""Save updates to this Capsule. Updates will be made column by column based on the result of self.what_changed(). :param context: Security context. NOTE: This should only be used internally by the indirection_api. Unfortunately, RPC requires context as the first argument, even though we don't use it. A context should be set when instantiating the object, e.g.: Capsule(context) """""" updates = self.obj_get_changes() if 'containers' in updates: raise exception.ObjectActionError(action='save', reason='containers changed') dbapi.update_capsule(context, self.uuid, updates) self.obj_reset_changes() def as_dict(self): capsule_dict = super(Capsule, self).as_dict() capsule_dict['containers'] = [c.as_dict() for c in self.containers] return capsule_dict def obj_load_attr(self, attrname): if attrname not in CAPSULE_OPTIONAL_ATTRS: raise exception.ObjectActionError( action='obj_load_attr', reason='attribute %s not lazy-loadable' % attrname) if not self._context: raise exception.OrphanedObjectError(method='obj_load_attr', objtype=self.obj_name()) LOG.debug(""Lazy-loading '%(attr)s' on %(name)s uuid %(uuid)s"", {'attr': attrname, 'name': self.obj_name(), 'uuid': self.uuid, }) if attrname == 'containers': self.containers = container.Container.list_by_capsule_id( self._context, self.id) self.obj_reset_changes(fields=[attrname]) ",32,667
openstack%2Fnova~stable%2Frocky~I0390c9ff51f49b063f736ca6ef868a4fa782ede5,openstack/nova,stable/rocky,I0390c9ff51f49b063f736ca6ef868a4fa782ede5,Avoid redundant initialize_connection on source post live migration,MERGED,2019-02-14 10:14:48.000000000,2019-02-25 11:58:33.000000000,2019-02-25 11:58:33.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9373}, {'_account_id': 9555}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-14 10:14:48.000000000', 'files': ['nova/objects/migrate_data.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/virt/libvirt/driver.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/75e0f5a9b18293546db0ddf0fb073854e6704115', 'message': ""Avoid redundant initialize_connection on source post live migration\n\nDuring live migration we update bdm.connection_info for attached volumes\nin pre_live_migration to reflect the new connection on the destination\nnode. This means that after migration completes the BDM no longer has a\nreference to the original connection_info to do the detach on the source\nhost. To address this, change I3dfb75eb added a second call to\ninitialize_connection on the source host to re-fetch the source host\nconnection_info before calling disconnect.\n\nUnfortunately the cinder driver interface does not strictly require that\nmultiple calls to initialize_connection will return consistent results.\nAlthough they normally do in practice, there is at least one cinder\ndriver (delliscsi) which doesn't. This results in a failure to\ndisconnect on the source host post migration.\n\nThis change avoids the issue entirely by fetching the BDMs prior to\nmodification on the destination node. As well as working round this\nspecific issue, it also avoids a redundant cinder call in all cases.\n\nNote that this massively simplifies post_live_migration in the libvirt\ndriver. The complexity removed was concerned with reconstructing the\noriginal connection_info. This required considering the cinder v2 and v3\nuse cases, and reconstructing the multipath_id which was written to\nconnection_info by the libvirt fibrechannel volume connector on\nconnection. These things are not necessary when we just use the original\ndata unmodified.\n\nOther drivers affected are Xenapi and HyperV. Xenapi doesn't touch\nvolumes in post_live_migration, so is unaffected. HyperV did not\npreviously account for differences in connection_info between source and\ndestination, so was likely previously broken. This change should fix it.\n\nNOTE(lyarwood): conflict due to Ibb8c12fb2799bb5ceb9e3d72a2b86dbb4f14451e\nnot being present in stable/rocky.\n\nConflicts:\n        nova/tests/unit/compute/test_compute_mgr.py\n\nCloses-Bug: #1754716\nCloses-Bug: #1814245\nChange-Id: I0390c9ff51f49b063f736ca6ef868a4fa782ede5\n(cherry picked from commit b626c0dc7b113365002e743e6de2aeb40121fc81)\n""}]",0,636895,75e0f5a9b18293546db0ddf0fb073854e6704115,38,11,1,10135,,,0,"Avoid redundant initialize_connection on source post live migration

During live migration we update bdm.connection_info for attached volumes
in pre_live_migration to reflect the new connection on the destination
node. This means that after migration completes the BDM no longer has a
reference to the original connection_info to do the detach on the source
host. To address this, change I3dfb75eb added a second call to
initialize_connection on the source host to re-fetch the source host
connection_info before calling disconnect.

Unfortunately the cinder driver interface does not strictly require that
multiple calls to initialize_connection will return consistent results.
Although they normally do in practice, there is at least one cinder
driver (delliscsi) which doesn't. This results in a failure to
disconnect on the source host post migration.

This change avoids the issue entirely by fetching the BDMs prior to
modification on the destination node. As well as working round this
specific issue, it also avoids a redundant cinder call in all cases.

Note that this massively simplifies post_live_migration in the libvirt
driver. The complexity removed was concerned with reconstructing the
original connection_info. This required considering the cinder v2 and v3
use cases, and reconstructing the multipath_id which was written to
connection_info by the libvirt fibrechannel volume connector on
connection. These things are not necessary when we just use the original
data unmodified.

Other drivers affected are Xenapi and HyperV. Xenapi doesn't touch
volumes in post_live_migration, so is unaffected. HyperV did not
previously account for differences in connection_info between source and
destination, so was likely previously broken. This change should fix it.

NOTE(lyarwood): conflict due to Ibb8c12fb2799bb5ceb9e3d72a2b86dbb4f14451e
not being present in stable/rocky.

Conflicts:
        nova/tests/unit/compute/test_compute_mgr.py

Closes-Bug: #1754716
Closes-Bug: #1814245
Change-Id: I0390c9ff51f49b063f736ca6ef868a4fa782ede5
(cherry picked from commit b626c0dc7b113365002e743e6de2aeb40121fc81)
",git fetch https://review.opendev.org/openstack/nova refs/changes/95/636895/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/migrate_data.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/virt/libvirt/driver.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",6,75e0f5a9b18293546db0ddf0fb073854e6704115,bug/1754716," vol1_conn_info = {'data': {'test_data': mock.sentinel.vol1}, 'serial': 'fake_serial1'} vol2_conn_info = {'data': {'test_data': mock.sentinel.vol2}, 'serial': 'fake_serial2'} bdi = {'block_device_mapping': [ 'connection_info': vol1_conn_info, 'connection_info': vol2_conn_info, @mock.patch.object(driver, 'block_device_info_get_mapping', return_value=bdi['block_device_mapping']) def _test(_disconnect_volume, block_device_info_get_mapping): drvr.post_live_migration(cntx, inst_ref, bdi) block_device_info_get_mapping.assert_called_once_with(bdi) _disconnect_volume.assert_has_calls([ mock.call(cntx, vol1_conn_info, inst_ref), mock.call(cntx, vol2_conn_info, inst_ref)]) "," vol = {'block_device_mapping': [ 'connection_info': { 'data': {'multipath_id': 'dummy1'}, 'serial': 'fake_serial1'}, 'connection_info': { 'data': {}, 'serial': 'fake_serial2'}, def fake_initialize_connection(context, volume_id, connector): return {'data': {}} fake_connector = {'host': 'fake'} with test.nested( mock.patch.object(driver, 'block_device_info_get_mapping', return_value=vol['block_device_mapping']), mock.patch.object(drvr, ""get_volume_connector"", return_value=fake_connector), mock.patch.object(drvr._volume_api, ""initialize_connection"", side_effect=fake_initialize_connection), mock.patch.object(drvr, '_disconnect_volume') ) as (block_device_info_get_mapping, get_volume_connector, initialize_connection, _disconnect_volume): drvr.post_live_migration(cntx, inst_ref, vol) block_device_info_get_mapping.assert_has_calls([ mock.call(vol)]) get_volume_connector.assert_has_calls([ mock.call(inst_ref)]) _disconnect_volume.assert_has_calls([ mock.call(cntx, {'data': {'multipath_id': 'dummy1'}}, inst_ref), mock.call(cntx, {'data': {}}, inst_ref)]) def test_post_live_migration_cinder_v3(self): cntx = context.get_admin_context() drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) instance = fake_instance.fake_instance_obj(cntx, uuid=uuids.instance) vol_id = uuids.volume old_attachment_id = uuids.attachment disk_dev = 'sda' connection_info = { 'data': {'multipath_id': 'dummy1'}, 'serial': vol_id} block_device_mapping = [ {'attachment_id': uuids.attachment, 'mount_device': '/dev/%s' % disk_dev, 'connection_info': connection_info}] old_attachment = { 'connection_info': { 'data': {'multipath_id': 'dummy1'}, 'serial': vol_id}} migrate_data = objects.LibvirtLiveMigrateData( is_shared_block_storage=True, old_vol_attachment_ids={vol_id: old_attachment_id}) @mock.patch.object(drvr._volume_api, 'attachment_get') @mock.patch.object(driver, 'block_device_info_get_mapping') def _test(mock_get_bdms, mock_attachment_get, mock_disconnect): mock_get_bdms.return_value = block_device_mapping mock_attachment_get.return_value = old_attachment drvr.post_live_migration(cntx, instance, None, migrate_data=migrate_data) mock_attachment_get.assert_called_once_with(cntx, old_attachment_id) mock_disconnect.assert_called_once_with(cntx, connection_info, instance)",97,142
openstack%2Ftripleo-quickstart-extras~master~I47b7ebf7c8afe22c4bd7643c855940649f6da52c,openstack/tripleo-quickstart-extras,master,I47b7ebf7c8afe22c4bd7643c855940649f6da52c,Tell people how to ignore their personnal editor temporary files,MERGED,2019-02-20 14:18:42.000000000,2019-02-25 11:45:36.000000000,2019-02-25 11:45:36.000000000,"[{'_account_id': 8449}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-02-20 14:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/71f689ea13ae9ff176f6b9aa04ee108f384842de', 'message': 'Ignore swp files from vim and emacs.\n\nChange-Id: I47b7ebf7c8afe22c4bd7643c855940649f6da52c\n'}, {'number': 2, 'created': '2019-02-22 08:08:25.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/bcd581fcb3649b3604ef2be6a09eaadd521aed12', 'message': ""Tell people how to ignore their personnal editor temporary files\n\nSince https://review.openstack.org/#/c/592520/ editor temporary files\naren't ignore anymore. This comment tells how to do that in order to\navoid future people coming around and wanting to add editor related\nrules in the .gitignore file.\n\nChange-Id: I47b7ebf7c8afe22c4bd7643c855940649f6da52c\n""}]",3,638168,bcd581fcb3649b3604ef2be6a09eaadd521aed12,17,5,2,28223,,,0,"Tell people how to ignore their personnal editor temporary files

Since https://review.openstack.org/#/c/592520/ editor temporary files
aren't ignore anymore. This comment tells how to do that in order to
avoid future people coming around and wanting to add editor related
rules in the .gitignore file.

Change-Id: I47b7ebf7c8afe22c4bd7643c855940649f6da52c
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/68/638168/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,71f689ea13ae9ff176f6b9aa04ee108f384842de,ignore-swp,# Temp files from editory .*.swp *~,,3,0
openstack%2Fneutron-lbaas~master~I767b88d3a70d744e4170325a9f2c2dc36163756b,openstack/neutron-lbaas,master,I767b88d3a70d744e4170325a9f2c2dc36163756b,stop using common db mixin,MERGED,2019-02-07 16:53:57.000000000,2019-02-25 11:28:39.000000000,2019-02-25 11:28:39.000000000,"[{'_account_id': 6579}, {'_account_id': 9008}, {'_account_id': 11628}, {'_account_id': 20363}, {'_account_id': 22348}, {'_account_id': 28748}]","[{'number': 1, 'created': '2019-02-07 16:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/22613d41e4538203e68a5766764e8ce5d6b64e3b', 'message': ""stop using common db mixin methods\n\nAll of the methods of common db mixin are available via neutron-lib\nand the mixin will be removed before long.\nThis patch switches the code over to use neutron-lib's APIs rather\nthan those of the mixin.\n\nChange-Id: I767b88d3a70d744e4170325a9f2c2dc36163756b\n""}, {'number': 2, 'created': '2019-02-11 14:56:21.000000000', 'files': ['neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py', 'neutron_lbaas/drivers/common/agent_driver_base.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/c800a90f2f77a3ae2b01cd2136382f8752beda90', 'message': ""stop using common db mixin\n\nAll of the methods of common db mixin are available via neutron-lib\nand the mixin will be removed before long.\nThis patch switches the code over to use neutron-lib's APIs rather\nthan those of the mixin and stops using common_db_mix for parent\nclasses.\n\nChange-Id: I767b88d3a70d744e4170325a9f2c2dc36163756b\n""}]",0,635570,c800a90f2f77a3ae2b01cd2136382f8752beda90,17,6,2,5367,,,0,"stop using common db mixin

All of the methods of common db mixin are available via neutron-lib
and the mixin will be removed before long.
This patch switches the code over to use neutron-lib's APIs rather
than those of the mixin and stops using common_db_mix for parent
classes.

Change-Id: I767b88d3a70d744e4170325a9f2c2dc36163756b
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/70/635570/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py'],1,22613d41e4538203e68a5766764e8ce5d6b64e3b,bp/neutronlib-decouple-db," query = model_query.get_collection_query(context, model, filters=filters)"," query = self._get_collection_query(context, model, filters=filters)",2,2
openstack%2Fcinder~master~I3f72481442436ddf78c10ab53c161663b05a330a,openstack/cinder,master,I3f72481442436ddf78c10ab53c161663b05a330a,VNX Driver: delete_hba() instead of remove_hba(),MERGED,2019-02-10 15:03:30.000000000,2019-02-25 11:11:54.000000000,2019-02-15 21:06:07.000000000,"[{'_account_id': 4523}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18742}, {'_account_id': 18883}, {'_account_id': 19004}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23601}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27419}, {'_account_id': 28801}, {'_account_id': 29637}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-02-10 15:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e6c003a62a277fb51f3a6115b2750a48c4883719', 'message': ""VNX Driver: delete_hba() instead of remove_hba()\n\nThe storops drivers doesn't have a remove_hba() function,\nit's called delete_hba(). The confusion comes from the fact\nthat storops uses -removeHBA argument when calling\nnaviseccli.\n\nChange-Id: I3f72481442436ddf78c10ab53c161663b05a330a\nCloses-bug: #1813525\n""}, {'number': 2, 'created': '2019-02-11 14:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3a7cf77215a40643933040cb57d2fa7d69fdfa5e', 'message': ""VNX Driver: delete_hba() instead of remove_hba()\n\nThe storops drivers doesn't have a remove_hba() function,\nit's called delete_hba(). The confusion comes from the fact\nthat storops uses -removeHBA argument when calling\nnaviseccli.\n\nChange-Id: I3f72481442436ddf78c10ab53c161663b05a330a\nCloses-bug: #1813525\n""}, {'number': 3, 'created': '2019-02-11 17:03:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1c1bcf6b023b02f2a8e4a5bdfc32fb28ceed3a93', 'message': ""VNX Driver: delete_hba() instead of remove_hba()\n\nThe storops drivers doesn't have a remove_hba() function,\nit's called delete_hba(). The confusion comes from the fact\nthat storops uses -removeHBA argument when calling\nnaviseccli.\n\nChange-Id: I3f72481442436ddf78c10ab53c161663b05a330a\nCloses-bug: #1813525\n""}, {'number': 4, 'created': '2019-02-11 21:49:25.000000000', 'files': ['cinder/tests/unit/volume/drivers/dell_emc/vnx/mocked_vnx.yaml', 'cinder/tests/unit/volume/drivers/dell_emc/vnx/test_adapter.py', 'cinder/volume/drivers/dell_emc/vnx/client.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6145f8583ad1b1b5c631534b1dc05d8bf89c330e', 'message': ""VNX Driver: delete_hba() instead of remove_hba()\n\nThe storops drivers doesn't have a remove_hba() function,\nit's called delete_hba(). The confusion comes from the fact\nthat storops uses -removeHBA argument when calling\nnaviseccli.\n\nChange-Id: I3f72481442436ddf78c10ab53c161663b05a330a\nCloses-bug: #1813525\n""}]",1,636064,6145f8583ad1b1b5c631534b1dc05d8bf89c330e,151,42,4,27419,,,0,"VNX Driver: delete_hba() instead of remove_hba()

The storops drivers doesn't have a remove_hba() function,
it's called delete_hba(). The confusion comes from the fact
that storops uses -removeHBA argument when calling
naviseccli.

Change-Id: I3f72481442436ddf78c10ab53c161663b05a330a
Closes-bug: #1813525
",git fetch https://review.opendev.org/openstack/cinder refs/changes/64/636064/3 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/dell_emc/vnx/client.py'],1,e6c003a62a277fb51f3a6115b2750a48c4883719,bug/1813525, self.vnx.delete_hba(initiator_uid), self.vnx.remove_hba(initiator_uid),1,1
openstack%2Fkolla-ansible~stable%2Fqueens~I0ba207e1d3761da2d6992c5834d4f59e7e1d6628,openstack/kolla-ansible,stable/queens,I0ba207e1d3761da2d6992c5834d4f59e7e1d6628,Add Zun scenario job for ubuntu,MERGED,2019-02-16 03:54:45.000000000,2019-02-25 11:03:52.000000000,2019-02-25 11:03:52.000000000,"[{'_account_id': 11536}, {'_account_id': 14826}, {'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-16 03:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d1997eec493b1797a36f3a1b02dc40879622c736', 'message': ""Add Zun scenario job for ubuntu\n\nIntroduce a job 'kolla-ansible-ubuntu-source-zun' to test kolla\nwith Zun enabled. To reduce CI resource, this job will be triggered\nonly if there are changes on the Zun's ansible roles.\n\nChange-Id: I0ba207e1d3761da2d6992c5834d4f59e7e1d6628\n(cherry picked from commit f57c1aec6cafd0f2b4d6c04c787745b9f2729604)\n""}, {'number': 2, 'created': '2019-02-16 03:55:53.000000000', 'files': ['ansible/roles/zun/templates/zun.conf.j2', '.zuul.yaml', 'tests/templates/globals-default.j2', 'tests/templates/inventory.j2', 'tools/setup_gate.sh'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3e557983069fb88196d3088332d778bafe750849', 'message': ""Add Zun scenario job for ubuntu\n\nIntroduce a job 'kolla-ansible-ubuntu-source-zun' to test kolla\nwith Zun enabled. To reduce CI resource, this job will be triggered\nonly if there are changes on the Zun's ansible roles.\n\nChange-Id: I0ba207e1d3761da2d6992c5834d4f59e7e1d6628\n(cherry picked from commit f57c1aec6cafd0f2b4d6c04c787745b9f2729604)\n(cherry picked from commit a1ce8af398c144dc8e1e621e565fd46abb717c43)\n""}]",0,637353,3e557983069fb88196d3088332d778bafe750849,11,4,2,11536,,,0,"Add Zun scenario job for ubuntu

Introduce a job 'kolla-ansible-ubuntu-source-zun' to test kolla
with Zun enabled. To reduce CI resource, this job will be triggered
only if there are changes on the Zun's ansible roles.

Change-Id: I0ba207e1d3761da2d6992c5834d4f59e7e1d6628
(cherry picked from commit f57c1aec6cafd0f2b4d6c04c787745b9f2729604)
(cherry picked from commit a1ce8af398c144dc8e1e621e565fd46abb717c43)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/53/637353/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/zun/templates/zun.conf.j2', '.zuul.yaml', 'tests/templates/globals-default.j2', 'tests/templates/inventory.j2', 'tools/setup_gate.sh']",5,d1997eec493b1797a36f3a1b02dc40879622c736,," if [[ $ACTION == ""zun"" ]]; then GATE_IMAGES+="",zun,kuryr"" fi if [[ $ACTION == ""zun"" ]]; then sudo -H pip install -U ""python-zunclient"" fi if echo $ACTION | grep -q ""zun""; then openstack --debug appcontainer service list openstack --debug appcontainer host list # TODO(hongbin): Run a Zun container and assert the container becomes # Running fi",,35,1
openstack%2Fkolla~master~I511c248bd009d03cad6811c576dd91a7bb29e203,openstack/kolla,master,I511c248bd009d03cad6811c576dd91a7bb29e203,gnocchi rpm naming cleanup,MERGED,2019-02-06 14:54:19.000000000,2019-02-25 10:57:51.000000000,2019-02-25 10:57:50.000000000,"[{'_account_id': 1669}, {'_account_id': 4264}, {'_account_id': 13039}, {'_account_id': 16282}, {'_account_id': 21691}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23717}, {'_account_id': 23942}, {'_account_id': 24162}, {'_account_id': 26285}, {'_account_id': 28614}]","[{'number': 1, 'created': '2019-02-06 14:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b0c5ac2c00914579dd8e40336ad39d8efdce2254', 'message': 'gnocchi rpm naming cleanup\n\nDuring the Queens cycle the gnocci project was\nmoved out of openstack and so naming changed from\nopenstack-gnocchi-XXX to gnocchi-XXX\n\nJanuary 2018 - I2a07f09c4ad37c661ea222c775c85f02842cbd64\n\nAlso openstack-gnocchi-indexer-sqlalchemy was moved to gnocchi-common\n\n2017 - I7fd7d21b14455f1705e3efce046f7fad8ce027fa\n\nChange-Id: I511c248bd009d03cad6811c576dd91a7bb29e203\n'}, {'number': 2, 'created': '2019-02-14 17:58:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d655c253dc53b8a639fbe276731402df7320b45d', 'message': 'gnocchi rpm naming cleanup\n\nDuring the Queens cycle the gnocci project was\nmoved out of openstack and so naming changed from\nopenstack-gnocchi-XXX to gnocchi-XXX\n\nJanuary 2018 - I2a07f09c4ad37c661ea222c775c85f02842cbd64\n\nAlso openstack-gnocchi-indexer-sqlalchemy was moved to gnocchi-common\n\n2017 - I7fd7d21b14455f1705e3efce046f7fad8ce027fa\n\nChange-Id: I511c248bd009d03cad6811c576dd91a7bb29e203\n'}, {'number': 3, 'created': '2019-02-18 10:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/77accff00478f962e6589a143ba589c2ada3f7f0', 'message': 'gnocchi rpm naming cleanup\n\nDuring the Queens cycle the gnocci project was\nmoved out of openstack and so naming changed from\nopenstack-gnocchi-XXX to gnocchi-XXX\n\nJanuary 2018 - https://review.rdoproject.org/r/#/c/11110/\n\nAlso openstack-gnocchi-indexer-sqlalchemy was moved to gnocchi-common\n\n2017 - https://review.rdoproject.org/r/#/c/10449/\n\nChange-Id: I511c248bd009d03cad6811c576dd91a7bb29e203\n'}, {'number': 4, 'created': '2019-02-18 12:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9b4648877c454ddfd6f1909be09694c38a4cae7f', 'message': 'gnocchi rpm naming cleanup\n\nDuring the Queens cycle the gnocci project was\nmoved out of openstack and so naming changed from\nopenstack-gnocchi-XXX to gnocchi-XXX\n\nJanuary 2018 - https://review.rdoproject.org/r/#/c/11110/\n\nAlso openstack-gnocchi-indexer-sqlalchemy was moved to gnocchi-common\n\n2017 - https://review.rdoproject.org/r/#/c/10449/\n\nChange-Id: I511c248bd009d03cad6811c576dd91a7bb29e203\n'}, {'number': 5, 'created': '2019-02-19 08:39:50.000000000', 'files': ['docker/gnocchi/gnocchi-api/Dockerfile.j2', 'docker/gnocchi/gnocchi-metricd/Dockerfile.j2', 'docker/gnocchi/gnocchi-base/Dockerfile.j2', 'docker/gnocchi/gnocchi-statsd/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/1d208580b101f64887052b2273d6891b944cf06f', 'message': 'gnocchi rpm naming cleanup\n\nDuring the Queens cycle the gnocci project was\nmoved out of openstack and so naming changed from\nopenstack-gnocchi-XXX to gnocchi-XXX\n\nJanuary 2018 - https://review.rdoproject.org/r/#/c/11110/\n\nAlso openstack-gnocchi-indexer-sqlalchemy was moved to gnocchi-common\n\n2017 - https://review.rdoproject.org/r/#/c/10449/\n\nChange-Id: I511c248bd009d03cad6811c576dd91a7bb29e203\n'}]",12,635175,1d208580b101f64887052b2273d6891b944cf06f,39,12,5,16282,,,0,"gnocchi rpm naming cleanup

During the Queens cycle the gnocci project was
moved out of openstack and so naming changed from
openstack-gnocchi-XXX to gnocchi-XXX

January 2018 - https://review.rdoproject.org/r/#/c/11110/

Also openstack-gnocchi-indexer-sqlalchemy was moved to gnocchi-common

2017 - https://review.rdoproject.org/r/#/c/10449/

Change-Id: I511c248bd009d03cad6811c576dd91a7bb29e203
",git fetch https://review.opendev.org/openstack/kolla refs/changes/75/635175/3 && git format-patch -1 --stdout FETCH_HEAD,"['docker/gnocchi/gnocchi-api/Dockerfile.j2', 'docker/gnocchi/gnocchi-base/Dockerfile.j2', 'docker/gnocchi/gnocchi-statsd/Dockerfile.j2']",3,b0c5ac2c00914579dd8e40336ad39d8efdce2254,rename-gnocchi-rpms, {% set gnocchi_statsd_packages = ['gnocchi-statsd'] %}, {% set gnocchi_statsd_packages = ['openstack-gnocchi-statsd'] %},4,4
openstack%2Fsahara-tests~master~I4702f0533ec7a0a5b9285034fae67bd41e14aff6,openstack/sahara-tests,master,I4702f0533ec7a0a5b9285034fae67bd41e14aff6,[DNM] Testing dynamically loading plugins,ABANDONED,2019-01-19 13:59:05.000000000,2019-02-25 10:55:10.000000000,,"[{'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-19 13:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-tests/commit/d8073f79df71092ec5ef184d2cea21d3a4d2f16e', 'message': '[DNM] Testing dynamically loading plugins\n\nChange-Id: I4702f0533ec7a0a5b9285034fae67bd41e14aff6\n'}, {'number': 2, 'created': '2019-01-21 09:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-tests/commit/3b0384bf758bc22886c840cc54745ec72b71d0bf', 'message': '[DNM] Testing dynamically loading plugins\n\nChange-Id: I4702f0533ec7a0a5b9285034fae67bd41e14aff6\n'}, {'number': 3, 'created': '2019-01-21 13:58:01.000000000', 'files': ['.zuul.yaml', 'sahara_tests/scenario/defaults/fake.yaml.mako'], 'web_link': 'https://opendev.org/openstack/sahara-tests/commit/e0f66cc9a8c0c56dd1e03c7df73746f2cb533a03', 'message': '[DNM] Testing dynamically loading plugins\n\nDepends-On: https://review.openstack.org/#/c/631603/\n\nChange-Id: I4702f0533ec7a0a5b9285034fae67bd41e14aff6\n'}]",0,631921,e0f66cc9a8c0c56dd1e03c7df73746f2cb533a03,13,3,3,8932,,,0,"[DNM] Testing dynamically loading plugins

Depends-On: https://review.openstack.org/#/c/631603/

Change-Id: I4702f0533ec7a0a5b9285034fae67bd41e14aff6
",git fetch https://review.opendev.org/openstack/sahara-tests refs/changes/21/631921/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'sahara_tests/scenario/defaults/fake.yaml.mako']",2,d8073f79df71092ec5ef184d2cea21d3a4d2f16e,test_dyn_plugin_load, - oozie,,1,6
openstack%2Fswift~feature%2Flosf~I45b088b621b958bdd66ea9ab80b818482a305c63,openstack/swift,feature/losf,I45b088b621b958bdd66ea9ab80b818482a305c63,Lots Of Small Files - alternate diskfile,MERGED,2019-02-13 09:32:34.000000000,2019-02-25 10:54:17.000000000,2019-02-25 10:54:17.000000000,"[{'_account_id': 4608}, {'_account_id': 22348}, {'_account_id': 25251}]","[{'number': 1, 'created': '2019-02-13 09:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c7623f258a40148c1525630901b07b6e4f61d502', 'message': 'Lots Of Small Files - alternate diskfile\n\nThe ""LOSF"" patch provides swift with an efficient way of storing small\nfiles. The files (objects, if using replication, or fragments if using\nerasure coding) are stored in larger files.\nThey are indexed in a key/value store.\n\nChange-Id: I45b088b621b958bdd66ea9ab80b818482a305c63\n'}, {'number': 2, 'created': '2019-02-18 07:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/292a6bb9a6a5ef5fb0fe05f25e65f3d857918a06', 'message': 'Lots Of Small Files - alternate diskfile\n\nThe ""LOSF"" patch provides swift with an efficient way of storing small\nfiles. The files (objects, if using replication, or fragments if using\nerasure coding) are stored in larger files.\nThey are indexed in a key/value store.\n\nChange-Id: I45b088b621b958bdd66ea9ab80b818482a305c63\n'}, {'number': 3, 'created': '2019-02-18 08:11:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/300537e72f365f3e4ed1f00903ea27ef808031fc', 'message': 'Lots Of Small Files - alternate diskfile\n\nThe ""LOSF"" patch provides swift with an efficient way of storing small\nfiles. The files (objects, if using replication, or fragments if using\nerasure coding) are stored in larger files.\nThey are indexed in a key/value store.\n\nChange-Id: I45b088b621b958bdd66ea9ab80b818482a305c63\n'}, {'number': 4, 'created': '2019-02-18 09:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f30a0472c15a8a6faa4ddb519cee38713cb62465', 'message': 'Lots Of Small Files - alternate diskfile\n\nThe ""LOSF"" patch provides swift with an efficient way of storing small\nfiles. The files (objects, if using replication, or fragments if using\nerasure coding) are stored in larger files.\nThey are indexed in a key/value store.\n\nChange-Id: I45b088b621b958bdd66ea9ab80b818482a305c63\n'}, {'number': 5, 'created': '2019-02-19 17:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9cae2391a8177b3cbc89bb7472ce501c247c4f04', 'message': 'Lots Of Small Files - alternate diskfile\n\nThe ""LOSF"" patch provides swift with an efficient way of storing small\nfiles. The files (objects, if using replication, or fragments if using\nerasure coding) are stored in larger files.\nThey are indexed in a key/value store.\n\nChange-Id: I45b088b621b958bdd66ea9ab80b818482a305c63\n'}, {'number': 6, 'created': '2019-02-20 07:18:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9b7308d439b98d5d3dcef8005b3524581d07a656', 'message': 'Lots Of Small Files - alternate diskfile\n\nThe ""LOSF"" patch provides swift with an efficient way of storing small\nfiles. The files (objects, if using replication, or fragments if using\nerasure coding) are stored in larger files.\nThey are indexed in a key/value store.\n\nChange-Id: I45b088b621b958bdd66ea9ab80b818482a305c63\n'}, {'number': 7, 'created': '2019-02-21 10:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c2d14f4c4438cb7f0a5d0912e77d607a6c07014d', 'message': 'Lots Of Small Files - alternate diskfile\n\nThe ""LOSF"" patch provides swift with an efficient way of storing small\nfiles. The files (objects, if using replication, or fragments if using\nerasure coding) are stored in larger files.\nThey are indexed in a key/value store.\n\nChange-Id: I45b088b621b958bdd66ea9ab80b818482a305c63\n'}, {'number': 8, 'created': '2019-02-25 08:42:37.000000000', 'files': ['swift/obj/meta.proto', 'go/swift-rpc-losf/logging.go', 'go/swift-rpc-losf/rpc_test.go', 'swift/obj/header_pb2_grpc.py', 'bin/swift-object-rpcmanager', 'go/swift-rpc-losf/README.md', 'go/swift-rpc-losf/stats.go', 'swift/obj/meta_pb2.py', 'swift/obj/meta_pb2_grpc.py', 'swift/obj/fmgr_pb2.py', 'bin/swift-mount-losf', 'go/swift-rpc-losf/db.go', 'go/swift-rpc-losf/encoding.go', 'swift/obj/fmgr.proto', 'go/swift-rpc-losf/db_goleveldb.go', 'go/swift-rpc-losf/encoding_test.go', 'swift/obj/migrator.py', 'requirements.txt', 'swift/common/manager.py', 'bin/swift-losf-volume-check', 'go/swift-rpc-losf/proto/fmgr.pb.go', 'swift/obj/objectrpcmanager.py', 'swift/obj/header_pb2.py', 'swift/obj/header.py', 'swift/obj/kvfile.py', 'swift/obj/fmgr_pb2_grpc.py', 'go/swift-rpc-losf/swift.go', 'go/swift-rpc-losf/rpc.go', 'swift/obj/vfile_utils.py', 'go/swift-rpc-losf/utils.go', 'go/swift-rpc-losf/swift_test.go', 'swift/obj/vfile.py', 'go/swift-rpc-losf/main.go', 'swift/obj/rpc_grpc.py', 'setup.cfg', 'go/swift-rpc-losf/db_leveldb.go', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/swift/commit/8c8f4dec21fc0ca25fa455215ed33c0458f3aab3', 'message': 'Lots Of Small Files - alternate diskfile\n\nThe ""LOSF"" patch provides swift with an efficient way of storing small\nfiles. The files (objects, if using replication, or fragments if using\nerasure coding) are stored in larger files.\nThey are indexed in a key/value store.\n\nChange-Id: I45b088b621b958bdd66ea9ab80b818482a305c63\n'}]",3,636578,8c8f4dec21fc0ca25fa455215ed33c0458f3aab3,27,3,8,4608,,,0,"Lots Of Small Files - alternate diskfile

The ""LOSF"" patch provides swift with an efficient way of storing small
files. The files (objects, if using replication, or fragments if using
erasure coding) are stored in larger files.
They are indexed in a key/value store.

Change-Id: I45b088b621b958bdd66ea9ab80b818482a305c63
",git fetch https://review.opendev.org/openstack/swift refs/changes/78/636578/8 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/meta.proto', 'go/swift-rpc-losf/logging.go', 'go/swift-rpc-losf/rpc_test.go', 'swift/obj/header_pb2_grpc.py', 'swift/obj/reconstructor.py', 'bin/swift-object-rpcmanager', 'go/swift-rpc-losf/README.md', 'go/swift-rpc-losf/stats.go', 'swift/obj/meta_pb2.py', 'swift/obj/meta_pb2_grpc.py', 'swift/obj/fmgr_pb2.py', 'bin/swift-mount-losf', 'go/swift-rpc-losf/db.go', 'go/swift-rpc-losf/encoding.go', 'swift/obj/fmgr.proto', 'go/swift-rpc-losf/db_goleveldb.go', 'go/swift-rpc-losf/encoding_test.go', 'swift/obj/migrator.py', 'requirements.txt', 'swift/common/manager.py', 'bin/swift-losf-volume-check', 'go/swift-rpc-losf/proto/fmgr.pb.go', 'swift/obj/objectrpcmanager.py', 'swift/obj/header_pb2.py', 'swift/obj/header.py', 'swift/obj/kvfile.py', 'swift/obj/fmgr_pb2_grpc.py', 'go/swift-rpc-losf/swift.go', 'go/swift-rpc-losf/rpc.go', 'swift/obj/vfile_utils.py', 'go/swift-rpc-losf/utils.go', 'go/swift-rpc-losf/swift_test.go', 'swift/obj/vfile.py', 'go/swift-rpc-losf/main.go', 'swift/obj/rpc_grpc.py', 'setup.cfg', 'go/swift-rpc-losf/db_leveldb.go']",37,c7623f258a40148c1525630901b07b6e4f61d502,losf-feature,"// Copyright (c) 2010-2012 OpenStack Foundation // // Licensed under the Apache License, Version 2.0 (the ""License""); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an ""AS IS"" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or // implied. // See the License for the specific language governing permissions and // limitations under the License. // This implements the KV interface using levigo, which is a golang wrapper around the leveldb C++ library. package main import ( ""github.com/jmhodges/levigo"" ) // levigoDB holds the leveldb handle and options type levigoDB struct { db *levigo.DB ro *levigo.ReadOptions wo *levigo.WriteOptions } // levigoIterator wraps a levelDB iterator. The namespace byte is used to specify which type of // entry (volume, vfile..) it will iterate on. type levigoIterator struct { it *levigo.Iterator namespace byte } // levigoWriteBatch wraps a levigoDB WriteBatch type levigoWriteBatch struct { wb *levigo.WriteBatch ldb *levigoDB } // openLevigoDB Opens or create the DB. // (shoult use an interface?) func openLevigoDB(path string) (*levigoDB, error) { opts := levigo.NewOptions() // filter := levigo.NewBloomFilter(10) // opts.SetFilterPolicy(filter) // That may be useless, since we're supposed to fit in memory ? 10MB for now opts.SetCache(levigo.NewLRUCache(10 * 1048576)) opts.SetCreateIfMissing(true) // This will open or create the DB. A new DB is not marked as clean. It // may have been lost or deleted, while there is data in volumes on-disk. // A new DB will have to be checked and marked as clean. db, err := levigo.Open(path, opts) if err != nil { return nil, err } ro := levigo.NewReadOptions() wo := levigo.NewWriteOptions() ldb := levigoDB{db, ro, wo} return &ldb, nil } // Key value operations // // All operations take a namespace byte to denote the type of object the entry refers to. // Get wraps levigoDB Get func (ldb *levigoDB) Get(namespace byte, key []byte) (value []byte, err error) { db := ldb.db ro := ldb.ro // Prefix the key with a single byte (namespace) buf := make([]byte, len(key)+1) buf[0] = namespace copy(buf[1:], key) value, err = db.Get(ro, buf) return } // Put wraps levigoDB Put func (ldb *levigoDB) Put(namespace byte, key, value []byte) error { db := ldb.db wo := ldb.wo // Prefix the key with a single byte (namespace) buf := make([]byte, len(key)+1) buf[0] = namespace copy(buf[1:], key) return db.Put(wo, buf, value) } // PutSync will write an entry with the ""Sync"" option set func (ldb *levigoDB) PutSync(namespace byte, key, value []byte) error { db := ldb.db wo := levigo.NewWriteOptions() wo.SetSync(true) // Prefix the key with a single byte (namespace) buf := make([]byte, len(key)+1) buf[0] = namespace copy(buf[1:], key) return db.Put(wo, buf, value) } // Close wraps levigoDB Close func (ldb *levigoDB) Close() { ldb.db.Close() } // Delete wraps levigoDB Delete func (ldb *levigoDB) Delete(namespace byte, key []byte) error { db := ldb.db wo := ldb.wo // Prefix the key with a single byte (namespace) buf := make([]byte, len(key)+1) buf[0] = namespace copy(buf[1:], key) return db.Delete(wo, buf) } // NewWriteBatch creates a new WriteBatch func (ldb *levigoDB) NewWriteBatch() WriteBatch { lwb := &levigoWriteBatch{} lwb.wb = levigo.NewWriteBatch() lwb.ldb = ldb return lwb } // Put on a WriteBatch func (lwb *levigoWriteBatch) Put(namespace byte, key, value []byte) { buf := make([]byte, len(key)+1) buf[0] = namespace copy(buf[1:], key) lwb.wb.Put(buf, value) return } // Delete on a WriteBatch func (lwb *levigoWriteBatch) Delete(namespace byte, key []byte) { buf := make([]byte, len(key)+1) buf[0] = namespace copy(buf[1:], key) lwb.wb.Delete(buf) return } // Commit a WriteBatch func (lwb *levigoWriteBatch) Commit() (err error) { db := lwb.ldb.db wo := lwb.ldb.wo wb := lwb.wb err = db.Write(wo, wb) return } // Close a WriteBatch func (lwb *levigoWriteBatch) Close() { wb := lwb.wb wb.Close() } // Iterator functions // // NewIterator creates a new iterator for the given object type (namespace) func (ldb *levigoDB) NewIterator(namespace byte) Iterator { lit := &levigoIterator{} lit.it = ldb.db.NewIterator(ldb.ro) lit.namespace = namespace return lit } // SeekToFirst will seek to the first object of the given type func (lit *levigoIterator) SeekToFirst() { // The ""first key"" is the first one in the iterator's namespace buf := make([]byte, 1) buf[0] = lit.namespace lit.it.Seek(buf) return } // Seek moves the iterator to the position of the key func (lit *levigoIterator) Seek(key []byte) { // Prefix the key with a single byte (namespace) buf := make([]byte, len(key)+1) buf[0] = lit.namespace copy(buf[1:], key) lit.it.Seek(buf) return } // Next moves the iterator to the next key func (lit *levigoIterator) Next() { lit.it.Next() return } // Key returns the key (without the leading namespace byte) func (lit *levigoIterator) Key() (key []byte) { return lit.it.Key()[1:] } // Value returns the value at the current iterator position func (lit *levigoIterator) Value() (key []byte) { return lit.it.Value() } // Valid returns false if we are past the first or last key in the key-value func (lit *levigoIterator) Valid() bool { if lit.it.Valid() && lit.it.Key()[0] == lit.namespace { return true } else { return false } } // Close the iterator func (lit *levigoIterator) Close() { lit.it.Close() return } ",,14472,2
openstack%2Fcinder~master~I807823f3cb44274c3940db55e901d434304a09f5,openstack/cinder,master,I807823f3cb44274c3940db55e901d434304a09f5,Include .inc files in doc8 linting,MERGED,2019-02-19 17:34:26.000000000,2019-02-25 10:46:09.000000000,2019-02-20 04:53:34.000000000,"[{'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 20813}, {'_account_id': 21863}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24921}, {'_account_id': 25678}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29637}]","[{'number': 1, 'created': '2019-02-19 17:34:26.000000000', 'files': ['doc/source/configuration/tables/cinder-fusionio.inc', 'api-ref/source/v3/valid-boolean-values.inc', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b6f9932f9ca128e7c986a9fdd4af92d960a10ce6', 'message': 'Include .inc files in doc8 linting\n\nWe use *.inc files extensively, especially in the api-ref, but these\nfiles are not covered by default with our doc8 validation.\n\nThis adds support for those files and fixes a few issues that were\nidentified after enabling coverage.\n\nChange-Id: I807823f3cb44274c3940db55e901d434304a09f5\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,637949,b6f9932f9ca128e7c986a9fdd4af92d960a10ce6,37,31,1,11904,,,0,"Include .inc files in doc8 linting

We use *.inc files extensively, especially in the api-ref, but these
files are not covered by default with our doc8 validation.

This adds support for those files and fixes a few issues that were
identified after enabling coverage.

Change-Id: I807823f3cb44274c3940db55e901d434304a09f5
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/49/637949/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/v3/valid-boolean-values.inc', 'doc/source/configuration/tables/cinder-fusionio.inc', 'tox.ini']",3,b6f9932f9ca128e7c986a9fdd4af92d960a10ce6,doc8-inc, doc8 --ignore D001 --ignore-path .tox --ignore-path *.egg-info --ignore-path doc/src/api --ignore-path doc/source/drivers.rst --ignore-path doc/build --ignore-path .eggs/*/EGG-INFO/*.txt -e .txt -e .rst -e .inc, doc8 --ignore D001 --ignore-path .tox --ignore-path *.egg-info --ignore-path doc/src/api --ignore-path doc/source/drivers.rst --ignore-path doc/build --ignore-path .eggs/*/EGG-INFO/*.txt -e txt -e rst,61,61
openstack%2Fkolla~stable%2Frocky~Ic5caa8cf0271b21f71f03fd33c35b3c7bc93ccf4,openstack/kolla,stable/rocky,Ic5caa8cf0271b21f71f03fd33c35b3c7bc93ccf4,Use overlay2 in tools/setup_Redhat.sh,MERGED,2019-02-22 18:51:16.000000000,2019-02-25 10:45:38.000000000,2019-02-25 10:45:38.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 23717}, {'_account_id': 23942}]","[{'number': 1, 'created': '2019-02-22 18:51:16.000000000', 'files': ['tools/setup_RedHat.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/482732643866e7e3fe7c8609fd908fc217f3e218', 'message': 'Use overlay2 in tools/setup_Redhat.sh\n\nCurrently CentOS gates use btrfs storage driver and\ncreate /docker device backing btrfs.\n\nThis patch is to sync the gate run with Ubuntu.\n(post-Trusty) does not use btrfs, only overlay2.\n\nChange-Id: Ic5caa8cf0271b21f71f03fd33c35b3c7bc93ccf4\n(cherry picked from commit c50df69045e361a3d1136471b147854684ab1e31)\n'}]",0,638748,482732643866e7e3fe7c8609fd908fc217f3e218,8,4,1,22629,,,0,"Use overlay2 in tools/setup_Redhat.sh

Currently CentOS gates use btrfs storage driver and
create /docker device backing btrfs.

This patch is to sync the gate run with Ubuntu.
(post-Trusty) does not use btrfs, only overlay2.

Change-Id: Ic5caa8cf0271b21f71f03fd33c35b3c7bc93ccf4
(cherry picked from commit c50df69045e361a3d1136471b147854684ab1e31)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/48/638748/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/setup_RedHat.sh'],1,482732643866e7e3fe7c8609fd908fc217f3e218,feature/gate_centos_overlay2-stable/rocky,ExecStart=/usr/bin/dockerd --storage-driver overlay2 --insecure-registry=0.0.0.0/0,"function setup_disk { if [[ -f /etc/nodepool/provider && ! -f /swapfile ]]; then sudo swapoff -a sudo dd if=/dev/zero of=/swapfile bs=1M count=4096 sudo chmod 0600 /swapfile sudo mkswap /swapfile sudo /sbin/swapon /swapfile fi if [ ! -f /docker ]; then sudo dd if=/dev/zero of=/docker bs=1M count=25600 sudo losetup -f /docker DEV=$(losetup -a | awk -F: '/\/docker/ {print $1}') fi # Excerpts from https://github.com/openstack-infra/devstack-gate/blob/dc49f9e6eb18e42c6b175e4e146fa8f3b7633279/functions.sh#L306 if [ -b /dev/xvde ]; then DEV2='/dev/xvde' if mount | grep ${DEV2} > /dev/null; then echo ""*** ${DEV2} appears to already be mounted"" echo ""*** ${DEV2} unmounting and reformating"" sudo umount ${DEV2} fi sudo parted ${DEV2} --script -- mklabel msdos sync sudo partprobe sudo mkfs.ext4 ${DEV2} sudo mount ${DEV2} /mnt sudo find /opt/ -mindepth 1 -maxdepth 1 -exec mv {} /mnt/ \; sudo umount /mnt sudo mount ${DEV2} /opt grep -q ${DEV2} /proc/mounts || exit 1 fi # Format Disks and setup Docker to use BTRFS sudo parted ${DEV} -s -- mklabel msdos sudo rm -rf /var/lib/docker sudo mkdir /var/lib/docker # We want to snapshot the entire docker directory so we have to first create a # subvolume and use that as the root for the docker directory. sudo mkfs.btrfs -f ${DEV} sudo mount ${DEV} /var/lib/docker sudo btrfs subvolume create /var/lib/docker/docker sudo umount /var/lib/docker sudo mount -o noatime,subvol=docker ${DEV} /var/lib/docker } setup_disk ExecStart=/usr/bin/dockerd --storage-driver btrfs --insecure-registry=0.0.0.0/0",1,51
openstack%2Fkolla~master~Id3c67fad507adc7b9f200eced74ecba8fadf70e6,openstack/kolla,master,Id3c67fad507adc7b9f200eced74ecba8fadf70e6,Change some repos from xenial to bionic,MERGED,2019-02-22 19:01:19.000000000,2019-02-25 10:30:47.000000000,2019-02-25 10:30:47.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 23717}]","[{'number': 1, 'created': '2019-02-22 19:01:19.000000000', 'files': ['docker/base/sources.list.ubuntu'], 'web_link': 'https://opendev.org/openstack/kolla/commit/4d189ab98bdba8b3080955865bb98957445595de', 'message': 'Change some repos from xenial to bionic\n\nAt the time of bumping Ubuntu images to bionic, some repos did not have\nbionic versions - so xenial repos were used.\nMost of the repos - apart odl now have a bionic tree - so this patch\nenables them.\n\nChange-Id: Id3c67fad507adc7b9f200eced74ecba8fadf70e6\n'}]",0,638751,4d189ab98bdba8b3080955865bb98957445595de,7,3,1,22629,,,0,"Change some repos from xenial to bionic

At the time of bumping Ubuntu images to bionic, some repos did not have
bionic versions - so xenial repos were used.
Most of the repos - apart odl now have a bionic tree - so this patch
enables them.

Change-Id: Id3c67fad507adc7b9f200eced74ecba8fadf70e6
",git fetch https://review.opendev.org/openstack/kolla refs/changes/51/638751/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/base/sources.list.ubuntu'],1,4d189ab98bdba8b3080955865bb98957445595de,feature/add_bionic_repos,deb http://packages.treasuredata.com/3/ubuntu/bionic/ bionic contribdeb http://ppa.launchpad.net/qpid/released/ubuntu/ bionic maindeb https://packagecloud.io/rabbitmq/rabbitmq-server/ubuntu/ bionic main,deb http://packages.treasuredata.com/2/ubuntu/xenial/ xenial contribdeb http://ppa.launchpad.net/qpid/released/ubuntu/ xenial maindeb https://packagecloud.io/rabbitmq/rabbitmq-server/ubuntu/ xenial main,3,3
openstack%2Frequirements~master~I5bda400f1711247c1ebf411830c429ceaa35ee98,openstack/requirements,master,I5bda400f1711247c1ebf411830c429ceaa35ee98,Updated from generate-constraints,MERGED,2019-02-24 06:14:54.000000000,2019-02-25 10:16:18.000000000,2019-02-25 10:16:18.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-24 06:14:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/0ae7e78b4821d88779614480d1ba1afe582f4ad7', 'message': 'Updated from generate-constraints\n\nChange-Id: I5bda400f1711247c1ebf411830c429ceaa35ee98\n'}, {'number': 2, 'created': '2019-02-25 06:21:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/f6f0ea1b9801ccf2d5fef622b4e84ce5329ef07e', 'message': 'Updated from generate-constraints\n\nChange-Id: I5bda400f1711247c1ebf411830c429ceaa35ee98\n'}, {'number': 3, 'created': '2019-02-25 06:32:02.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e15af630b6dc95c0adcbffe77baa3c9a09b07613', 'message': 'Updated from generate-constraints\n\nChange-Id: I5bda400f1711247c1ebf411830c429ceaa35ee98\nSigned-off-by: Matthew Thode <mthode@mthode.org>\n'}]",0,638928,e15af630b6dc95c0adcbffe77baa3c9a09b07613,10,2,3,11131,,,0,"Updated from generate-constraints

Change-Id: I5bda400f1711247c1ebf411830c429ceaa35ee98
Signed-off-by: Matthew Thode <mthode@mthode.org>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/28/638928/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,0ae7e78b4821d88779614480d1ba1afe582f4ad7,openstack/requirements/constraints/noclob,MarkupSafe===1.1.1tornado===4.5.3;python_version=='3.4' tornado===4.5.3;python_version=='3.5' tornado===4.5.3;python_version=='3.6' tornado===5.1.1;python_version=='2.7'opentracing===2.0.0salt===2018.3.3,MarkupSafe===1.1.0tornado===4.5.3opentracing===1.3.0salt===2018.3.2,7,4
openstack%2Fcharm-nova-cloud-controller~master~I0d44aa361595f777df625d3a4a0f2a0cd2f81660,openstack/charm-nova-cloud-controller,master,I0d44aa361595f777df625d3a4a0f2a0cd2f81660,Release based management of haproxy context,MERGED,2019-02-22 10:37:49.000000000,2019-02-25 10:13:23.000000000,2019-02-25 10:13:23.000000000,"[{'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 10:37:49.000000000', 'files': ['hooks/nova_cc_context.py', 'unit_tests/test_nova_cc_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/aee921b57e5a46c6126306480cd01413d983d89b', 'message': 'Release based management of haproxy context\n\nEnsure that the haproxy context reflects the services associated\nwith the specific release of OpenStack being deployment.\n\n    < kilo: ec2 and s3 services deployed\n    >= ocata: placement service deployed\n\nChange-Id: I0d44aa361595f777df625d3a4a0f2a0cd2f81660\nCloses-Bug: 1811398\n'}]",0,638622,aee921b57e5a46c6126306480cd01413d983d89b,9,4,1,935,,,0,"Release based management of haproxy context

Ensure that the haproxy context reflects the services associated
with the specific release of OpenStack being deployment.

    < kilo: ec2 and s3 services deployed
    >= ocata: placement service deployed

Change-Id: I0d44aa361595f777df625d3a4a0f2a0cd2f81660
Closes-Bug: 1811398
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/22/638622/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/nova_cc_context.py', 'unit_tests/test_nova_cc_contexts.py']",2,aee921b57e5a46c6126306480cd01413d983d89b,bug/1811398, self.os_release.return_value = 'ocata' self.assertTrue('nova-placement-api' in ctxt['service_ports']) self.assertTrue('nova-api-ec2' not in ctxt['service_ports']) self.assertTrue('nova-objectstore' not in ctxt['service_ports']) self.os_release.return_value = 'icehouse' ctxt = context.HAProxyContext()() self.assertTrue('nova-placement-api' not in ctxt['service_ports']) self.assertTrue('nova-api-ec2' in ctxt['service_ports']) self.assertTrue('nova-objectstore' in ctxt['service_ports']) self.os_release.return_value = 'kilo' ctxt = context.HAProxyContext()() self.assertTrue('nova-placement-api' not in ctxt['service_ports']) self.assertTrue('nova-api-ec2' not in ctxt['service_ports']) self.assertTrue('nova-objectstore' not in ctxt['service_ports']),,28,0
openstack%2Fkolla-ansible~stable%2Frocky~I824ff00f6b86aac3eab5dc6fd01728653b4661d1,openstack/kolla-ansible,stable/rocky,I824ff00f6b86aac3eab5dc6fd01728653b4661d1,Fix location of hostdirs for Murano services,MERGED,2019-02-22 11:59:18.000000000,2019-02-25 10:08:30.000000000,2019-02-25 10:08:29.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 23717}]","[{'number': 1, 'created': '2019-02-22 11:59:18.000000000', 'files': ['ansible/roles/murano/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d835e1bfbe31266679a9f440817725a64467b1c4', 'message': 'Fix location of hostdirs for Murano services\n\nUse ""{{ node_config_directory }}/murano-api/"" for `murano-api` and\n""{{ node_config_directory }}/murano-engine/"" for `murano-engine`, so\ncorrect `config.json` are mounted in containers.\n\nChange-Id: I824ff00f6b86aac3eab5dc6fd01728653b4661d1\nCloses-Bug: 1811716\n'}]",0,638640,d835e1bfbe31266679a9f440817725a64467b1c4,7,3,1,25277,,,0,"Fix location of hostdirs for Murano services

Use ""{{ node_config_directory }}/murano-api/"" for `murano-api` and
""{{ node_config_directory }}/murano-engine/"" for `murano-engine`, so
correct `config.json` are mounted in containers.

Change-Id: I824ff00f6b86aac3eab5dc6fd01728653b4661d1
Closes-Bug: 1811716
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/40/638640/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/murano/defaults/main.yml'],1,d835e1bfbe31266679a9f440817725a64467b1c4,bug/1811716-stable/rocky," - ""{{ node_config_directory }}/murano-api/:{{ container_config_directory }}/:ro"" - ""{{ node_config_directory }}/murano-engine/:{{ container_config_directory }}/:ro"""," - ""{{ node_config_directory }}/murano-engine/:{{ container_config_directory }}/:ro"" - ""{{ node_config_directory }}/murano-api/:{{ container_config_directory }}/:ro""",2,2
openstack%2Ftripleo-heat-templates~master~I26f97e7fc4da0dd19e1e8a19b3f6a1c1160f7466,openstack/tripleo-heat-templates,master,I26f97e7fc4da0dd19e1e8a19b3f6a1c1160f7466,[FFU] Make sure group access work correctly with ansible 2.6.,MERGED,2019-02-18 13:43:24.000000000,2019-02-25 10:06:57.000000000,2019-02-20 12:23:15.000000000,"[{'_account_id': 3153}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-18 13:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6acdc45d547857b229d1736b43ae163d32b6ef44', 'message': '[FFU] Make sure group access work correctly with ansible 2.6.\n\nHi, with ansible 2.6 we cannot access the groups variable using the\nprevious idiom anymore.  Use a more robust way to access that\nvariable.\n\nChange-Id: I26f97e7fc4da0dd19e1e8a19b3f6a1c1160f7466\nCloses-bug: #1816422\n'}, {'number': 2, 'created': '2019-02-18 13:55:26.000000000', 'files': ['common/deploy-steps.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a0c3612db836343143b8ebd160710216203dfc8a', 'message': '[FFU] Make sure group access work correctly with ansible 2.6.\n\nHi, with ansible 2.6 we cannot access the groups variable using the\nprevious idiom anymore.  Use a more robust way to access that\nvariable.\n\nCo-Authored-By: ""Lukas Bezdicka <lbezdick@redhat.com>""\nChange-Id: I26f97e7fc4da0dd19e1e8a19b3f6a1c1160f7466\nCloses-bug: #1816422\n'}]",0,637542,a0c3612db836343143b8ebd160710216203dfc8a,10,4,2,8297,,,0,"[FFU] Make sure group access work correctly with ansible 2.6.

Hi, with ansible 2.6 we cannot access the groups variable using the
previous idiom anymore.  Use a more robust way to access that
variable.

Co-Authored-By: ""Lukas Bezdicka <lbezdick@redhat.com>""
Change-Id: I26f97e7fc4da0dd19e1e8a19b3f6a1c1160f7466
Closes-bug: #1816422
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/42/637542/2 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps.j2'],1,6acdc45d547857b229d1736b43ae163d32b6ef44,bug/1816422, when: tripleo_role_name == '{{role.name}}' and ansible_hostname == groups['{{role.name}}'][0], when: tripleo_role_name == '{{role.name}}' and ansible_hostname == {{role.name}}[0],1,1
openstack%2Fcharm-nova-compute~master~I0227c7caad3fd06112d6c30c271271b78f2299af,openstack/charm-nova-compute,master,I0227c7caad3fd06112d6c30c271271b78f2299af,Add /sbin/mkswap to apparmor profile,MERGED,2019-02-22 10:44:22.000000000,2019-02-25 10:06:47.000000000,2019-02-25 10:06:47.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 10:44:22.000000000', 'files': ['templates/usr.bin.nova-compute'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/d75e536c4d15013bfc15d49f8ab44b1ae678e160', 'message': 'Add /sbin/mkswap to apparmor profile\n\nEnsure nova-compute can create swap files for instances to use.\n\nChange-Id: I0227c7caad3fd06112d6c30c271271b78f2299af\nCloses-Bug: 1813226\n'}]",0,638623,d75e536c4d15013bfc15d49f8ab44b1ae678e160,7,3,1,935,,,0,"Add /sbin/mkswap to apparmor profile

Ensure nova-compute can create swap files for instances to use.

Change-Id: I0227c7caad3fd06112d6c30c271271b78f2299af
Closes-Bug: 1813226
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/23/638623/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/usr.bin.nova-compute'],1,d75e536c4d15013bfc15d49f8ab44b1ae678e160,bug/1813226," /sbin/mkswap rix,",,1,0
openstack%2Fcharm-nova-cloud-controller~master~I5293edd77387347f8c012521f4bdeffadc919438,openstack/charm-nova-cloud-controller,master,I5293edd77387347f8c012521f4bdeffadc919438,Fix formatting of vendordata_providers config,MERGED,2019-02-22 10:18:05.000000000,2019-02-25 10:04:37.000000000,2019-02-25 10:04:36.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 10:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/3fba6dce9e9d7fa45ebe45f8347bbf509fd44ad1', 'message': 'Fix formatting of vendordata_providers config\n\nAlign formatting of vendordata_providers configuration for nova\nwith changes in neutron-gateway; values must be strings, delimited\nby a comma.\n\nChange-Id: I5293edd77387347f8c012521f4bdeffadc919438\nCloses-Bug: 1810953\n'}, {'number': 2, 'created': '2019-02-22 10:21:10.000000000', 'files': ['hooks/nova_cc_context.py', 'unit_tests/test_nova_cc_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/d746152fb86c2fa8cf39d1bd4b29ca0f3896393f', 'message': 'Fix formatting of vendordata_providers config\n\nAlign formatting of vendordata_providers configuration for nova\nwith changes in neutron-gateway; values must be strings, delimited\nby a comma.\n\nChange-Id: I5293edd77387347f8c012521f4bdeffadc919438\nCloses-Bug: 1810953\n'}]",0,638618,d746152fb86c2fa8cf39d1bd4b29ca0f3896393f,9,3,2,935,,,0,"Fix formatting of vendordata_providers config

Align formatting of vendordata_providers configuration for nova
with changes in neutron-gateway; values must be strings, delimited
by a comma.

Change-Id: I5293edd77387347f8c012521f4bdeffadc919438
Closes-Bug: 1810953
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/18/638618/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/nova_cc_context.py', 'unit_tests/test_nova_cc_contexts.py']",2,3fba6dce9e9d7fa45ebe45f8347bbf509fd44ad1,bug/1810953," self.assertEqual(ctxt['vendordata_providers'], 'StaticJSON') self.assertEqual(ctxt['vendordata_providers'], 'DynamicJSON') self.assertEqual(ctxt['vendordata_providers'], 'StaticJSON,DynamicJSON')"," self.assertEqual(ctxt['vendordata_providers'], ['StaticJSON']) self.assertEqual(ctxt['vendordata_providers'], ['DynamicJSON']) self.assertEqual(ctxt['vendordata_providers'], ['StaticJSON', 'DynamicJSON'])",7,7
openstack%2Ftripleo-docs~master~I97e4d66ea1c3d93306adc352c8646644ed254286,openstack/tripleo-docs,master,I97e4d66ea1c3d93306adc352c8646644ed254286,Add notes for DCN operational availability modes,MERGED,2019-01-21 13:25:41.000000000,2019-02-25 09:47:03.000000000,2019-02-25 09:47:02.000000000,"[{'_account_id': 6681}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 12398}, {'_account_id': 17823}, {'_account_id': 18002}, {'_account_id': 21129}, {'_account_id': 21908}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23811}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-01-21 13:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/039a1e32009af9740744a5569d75c4e73681557c', 'message': 'Add notes for DCN operational availability modes\n\nChange-Id: I97e4d66ea1c3d93306adc352c8646644ed254286\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 2, 'created': '2019-01-22 13:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/b6396ac5ac98a6cf46d3247785c22e80db0f6852', 'message': 'Add notes for DCN operational availability modes\n\nChange-Id: I97e4d66ea1c3d93306adc352c8646644ed254286\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 3, 'created': '2019-01-22 15:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/361677e7d84505b20993bdea99ed43063d21921f', 'message': 'Add notes for DCN operational availability modes\n\nChange-Id: I97e4d66ea1c3d93306adc352c8646644ed254286\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 4, 'created': '2019-01-30 16:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/2d021c7095e1bccfcf087943605b9a34e00954bf', 'message': 'Add notes for DCN operational availability modes\n\nDocument expectations for negative scenarios and list HA options\navailable for Edge DCN deployments.\n\nChange-Id: I97e4d66ea1c3d93306adc352c8646644ed254286\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 5, 'created': '2019-01-31 15:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/46f52256b2589019b518fdfb00851dc1eb2a81ba', 'message': 'Add notes for DCN operational availability modes\n\nDocument expectations for negative scenarios and list HA options\navailable for Edge DCN deployments.\n\nChange-Id: I97e4d66ea1c3d93306adc352c8646644ed254286\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 6, 'created': '2019-02-05 12:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/2e38d9fb631858e1a407a93cd408dbe07b3c7595', 'message': 'Add notes for DCN operational availability modes\n\nDocument expectations for negative scenarios and list HA options\navailable for Edge DCN deployments.\n\nChange-Id: I97e4d66ea1c3d93306adc352c8646644ed254286\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 7, 'created': '2019-02-05 13:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/ac43ed7cdca1e984fd5db89edbebaa4e6ca672e0', 'message': 'Add notes for DCN operational availability modes\n\nDocument expectations for negative scenarios and list HA options\navailable for Edge DCN deployments.\n\nChange-Id: I97e4d66ea1c3d93306adc352c8646644ed254286\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 8, 'created': '2019-02-07 11:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/f764a3162bdb4ba7c6120670f9334d79a12e6b7a', 'message': 'Add notes for DCN operational availability modes\n\nDocument expectations for negative scenarios and list HA options\navailable for Edge DCN deployments.\n\nChange-Id: I97e4d66ea1c3d93306adc352c8646644ed254286\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 9, 'created': '2019-02-08 10:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/9f7bc5dee2ffdb70541238de09d48e8e8751cc43', 'message': 'Add notes for DCN operational availability modes\n\nDocument expectations for negative scenarios and list HA options\navailable for Edge DCN deployments.\n\nChange-Id: I97e4d66ea1c3d93306adc352c8646644ed254286\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 10, 'created': '2019-02-08 10:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/04f32a9a525e4479ad3223bb4a8a7de8c4375e52', 'message': 'Add notes for DCN operational availability modes\n\nDocument expectations for negative scenarios and list HA options\navailable for Edge DCN deployments.\n\nChange-Id: I97e4d66ea1c3d93306adc352c8646644ed254286\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 11, 'created': '2019-02-19 14:27:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/e1b0790c0bd56e19544da195deff9af4a1719c20', 'message': 'Add notes for DCN operational availability modes\n\nDocument expectations for negative scenarios and list HA options\navailable for Edge DCN deployments.\n\nChange-Id: I97e4d66ea1c3d93306adc352c8646644ed254286\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 12, 'created': '2019-02-19 14:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/4046cfd403f844fe39802b2b852f6c9107b44756', 'message': 'Add notes for DCN operational availability modes\n\nDocument expectations for negative scenarios and list HA options\navailable for Edge DCN deployments.\n\nChange-Id: I97e4d66ea1c3d93306adc352c8646644ed254286\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 13, 'created': '2019-02-20 13:07:27.000000000', 'files': ['doc/source/install/advanced_deployment/distributed_compute_node.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/8f29e59055c358426f9386be36936c0cea8809eb', 'message': 'Add notes for DCN operational availability modes\n\nDocument expectations for negative scenarios and list HA options\navailable for Edge DCN deployments.\n\nChange-Id: I97e4d66ea1c3d93306adc352c8646644ed254286\nCo-authored-by: Dan Sneddon <dsneddon@redhat.com>\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",59,632089,8f29e59055c358426f9386be36936c0cea8809eb,61,12,13,6926,,,0,"Add notes for DCN operational availability modes

Document expectations for negative scenarios and list HA options
available for Edge DCN deployments.

Change-Id: I97e4d66ea1c3d93306adc352c8646644ed254286
Co-authored-by: Dan Sneddon <dsneddon@redhat.com>
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/89/632089/6 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/advanced_deployment/distributed_compute_node.rst'],1,039a1e32009af9740744a5569d75c4e73681557c,631489,".. note:: Note that a failure of the central control plane still affects all of the remote sites. Create, Update or Delete operations cannot be executed locally for such a case. A remote site can only maintain its existing workloads, when there is no uplink available to the central control plane. ",,5,0
openstack%2Ftripleo-docs~master~Ia9a4a67fe1bdef377570544600977d6537c1f9bb,openstack/tripleo-docs,master,Ia9a4a67fe1bdef377570544600977d6537c1f9bb,Document DCN deployment,MERGED,2019-01-17 13:18:46.000000000,2019-02-25 09:47:02.000000000,2019-02-25 09:47:02.000000000,"[{'_account_id': 6926}, {'_account_id': 10873}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23811}]","[{'number': 1, 'created': '2019-01-17 13:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/80eb22f293d0aa04c930291ad547e2f6478bd141', 'message': 'WIP - Document DCN deployment\n\nDocuments DCN deployment using a centralized undercloud.\n\nChange-Id: Ia9a4a67fe1bdef377570544600977d6537c1f9bb\n'}, {'number': 2, 'created': '2019-02-13 18:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/eb5396ab88ea30750b738fd1f9fa926bce141fee', 'message': ""Document DCN deployment\n\nDocuments DCN deployment using a centralized undercloud. This is the\nbeginning of the documentation. The TODO's will be resolved in followup\npatches.\n\nChange-Id: Ia9a4a67fe1bdef377570544600977d6537c1f9bb\n""}, {'number': 3, 'created': '2019-02-19 14:27:22.000000000', 'files': ['doc/source/install/advanced_deployment/features.rst', 'doc/source/install/advanced_deployment/routed_spine_leaf_network.rst', 'doc/source/install/advanced_deployment/distributed_compute_node.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/9b02025e680f97acaa4ed0d016ac9779c77b9139', 'message': ""Document DCN deployment\n\nDocuments DCN deployment using a centralized undercloud. This is the\nbeginning of the documentation. The TODO's will be resolved in followup\npatches.\n\nChange-Id: Ia9a4a67fe1bdef377570544600977d6537c1f9bb\n""}]",13,631489,9b02025e680f97acaa4ed0d016ac9779c77b9139,21,5,3,7144,,,0,"Document DCN deployment

Documents DCN deployment using a centralized undercloud. This is the
beginning of the documentation. The TODO's will be resolved in followup
patches.

Change-Id: Ia9a4a67fe1bdef377570544600977d6537c1f9bb
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/89/631489/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/advanced_deployment/features.rst', 'doc/source/install/advanced_deployment/routed_spine_leaf_network.rst', 'doc/source/install/advanced_deployment/distributed_compute_node.rst']",3,80eb22f293d0aa04c930291ad547e2f6478bd141,631489,".. _distributed_compute_node: Distributed Compute Node deployment =================================== Introduction ------------ Additional groups of compute nodes can be deployed and integrated with existing overcloud deployments. These compute nodes are deployed in separate stacks from the overcloud stack, and they consume some of the stack outputs from the overcloud stack to reuse as configuration data. Deploying these additional nodes in separate stacks provides for separation of management between the overcloud stack and the stacks for additional compute nodes. The stacks can be managed, scaled, and updated separately. Using separate stacks also creates smaller failure domains as there are less baremetal nodes in each invidiual stack. A failure in one baremetal node only requires that management operations to address that failure need only affect the single stack that contains the failed node. A routed spine and leaf networking layout can be used to deploy these additional groups of compute nodes in a distributed nature. Not all nodes need to be co-located at the same physical location or datacenter. See :ref:`routed_spine_leaf_network` for more details. Such an architecture is referred to as ""Distributed Compute Node"" or ""DCN"" for short. Deploying from a centralized undercloud --------------------------------------- The main overcloud stack should be deployed as needed for the desired cloud architecture layout. This stack contains nodes running the control plane and infrastructure services needed for the cloud. For the purposes of this documentation, this stack is referred to as the overcloud stack. The overcloud stack may or may not contain compute nodes. It may be a user requirement that compute services are available within the overcloud stack, however it is not strictly required. Undercloud configuration ^^^^^^^^^^^^^^^^^^^^^^^^ TODO Saving configuration from the overcloud ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Once the overcloud has been deployed, data needs to be retrieved from the overcloud Heat stack and plan to pass as input values into the separate DCN deployment. Extract the needed data from the stack outputs: .. code-block:: bash openstack stack output show standalone EndpointMap --format json \ | jq '{""parameter_defaults"": {""EndpointMapOverride"": .output_value}}' \ > endpoint-map.json openstack stack output show standalone AllNodesConfig --format json \ | jq '{""parameter_defaults"": {""AllNodesExtraMapData"": .output_value}}' \ > all-nodes-extra-map-data.json openstack stack output show standalone HostsEntry -f json \ | jq -r '{""parameter_defaults"":{""ExtraHostFileEntries"": .output_value}}' \ > extra-host-file-entries.json Save the passwords from the plan: .. code-block:: bash openstack object save overcloud plan-environment.yaml python -c ""import yaml; data=yaml.safe_load(open('plan-environment.yaml').read()); print yaml.dump(dict(parameter_defaults=data['passwords']))"" > passwords.yaml .. note:: The `passwords.yaml` generated in the previous command contains sensitive security data such as passwords and TLS certificates that are used in the overcloud deployment. Care should be taken to keep the file as secured as possible. Create an environment file for setting necessary oslo messaging configuration overrides: .. code-block:: bash parameter_defaults: ComputeExtraConfig: oslo_messaging_notify_use_ssl: false oslo_messaging_rpc_use_ssl: false Reusing networks from the overcloud ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ TODO Spine and Leaf configuration ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ TODO Standalone deployment --------------------- TODO ",,107,0
openstack%2Fneutron~master~I2a3ae83194987010fa53c75d9f55233b8554350f,openstack/neutron,master,I2a3ae83194987010fa53c75d9f55233b8554350f,Modify default default_prefixlen of subnetpools,ABANDONED,2019-02-25 08:25:38.000000000,2019-02-25 09:42:56.000000000,,[],"[{'number': 1, 'created': '2019-02-25 08:25:38.000000000', 'files': ['neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/ipam/subnet_alloc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e3089d17a7b9297f910fc3ecd054660f98c6481', 'message': ""Modify default default_prefixlen of subnetpools\n\nUsing a subnetpool whose default_prefixlen isn't specified to\ncreate a subnet,to make it can be allocated,\nthe default_prefixlen is set to be the bigger one\nbetween the min_prefixlen and the min prefixlen of pool_prefixes\nwhen creating subnetpools by default.\n\nChange-Id: I2a3ae83194987010fa53c75d9f55233b8554350f\n""}]",0,639027,6e3089d17a7b9297f910fc3ecd054660f98c6481,3,0,1,29879,,,0,"Modify default default_prefixlen of subnetpools

Using a subnetpool whose default_prefixlen isn't specified to
create a subnet,to make it can be allocated,
the default_prefixlen is set to be the bigger one
between the min_prefixlen and the min prefixlen of pool_prefixes
when creating subnetpools by default.

Change-Id: I2a3ae83194987010fa53c75d9f55233b8554350f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/27/639027/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/ipam/subnet_alloc.py']",2,6e3089d17a7b9297f910fc3ecd054660f98c6481,1816502," def _min_prefixlen_from_cidr(self): prefixlen = [cidr.prefixlen for cidr in self.prefixes] return min(prefixlen) default_def = max(self.min_prefixlen, self._min_prefixlen_from_cidr()) default_def)", self.min_prefixlen),9,3
openstack%2Frpm-packaging~master~Ie09c44902904781a6df3d6e118a265887679260e,openstack/rpm-packaging,master,Ie09c44902904781a6df3d6e118a265887679260e,monasca-api: Drop DB schema files,MERGED,2019-02-25 07:02:08.000000000,2019-02-25 09:06:37.000000000,2019-02-25 09:06:37.000000000,"[{'_account_id': 8482}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-25 07:02:08.000000000', 'files': ['openstack/monasca-api/monasca-api.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1fc67f1bdd7e527f948fcd6ff2631ad05ae58e87', 'message': 'monasca-api: Drop DB schema files\n\nTheses are no longer provided by upstream.\n\nChange-Id: Ie09c44902904781a6df3d6e118a265887679260e\n'}]",0,639019,1fc67f1bdd7e527f948fcd6ff2631ad05ae58e87,9,5,1,7102,,,0,"monasca-api: Drop DB schema files

Theses are no longer provided by upstream.

Change-Id: Ie09c44902904781a6df3d6e118a265887679260e
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/19/639019/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/monasca-api/monasca-api.spec.j2'],1,1fc67f1bdd7e527f948fcd6ff2631ad05ae58e87,,,install -D -m 640 devstack/files/schema/mon_postgresql.sql %{buildroot}%{_usr}/share/%{component}/schema/ install -D -m 640 devstack/files/schema/mon_mysql.sql %{buildroot}%{_usr}/share/%{component}/schema/,0,2
openstack%2Fdiskimage-builder~master~Ic206b8247acce1975409329faa29deccd4f886de,openstack/diskimage-builder,master,Ic206b8247acce1975409329faa29deccd4f886de,update spelling errors,MERGED,2019-01-08 06:31:09.000000000,2019-02-25 08:49:56.000000000,2019-02-25 08:49:56.000000000,"[{'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 29344}]","[{'number': 1, 'created': '2019-01-08 06:31:09.000000000', 'files': ['diskimage_builder/elements/gentoo/finalise.d/99-cleanup', 'diskimage_builder/elements/debootstrap/root.d/08-debootstrap'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/64a8fc7c58c335fe2a178f6c5117776d388a57ff', 'message': 'update spelling errors\n\nChange-Id: Ic206b8247acce1975409329faa29deccd4f886de\n'}]",0,629096,64a8fc7c58c335fe2a178f6c5117776d388a57ff,35,5,1,29558,,,0,"update spelling errors

Change-Id: Ic206b8247acce1975409329faa29deccd4f886de
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/96/629096/1 && git format-patch -1 --stdout FETCH_HEAD,"['diskimage_builder/elements/gentoo/finalise.d/99-cleanup', 'diskimage_builder/elements/debootstrap/root.d/08-debootstrap']",2,64a8fc7c58c335fe2a178f6c5117776d388a57ff,, # Target architecture different from host architecture:, # Target architecture diffrent from host architecture:,2,2
openstack%2Fcinder~master~I372292261125f303d7978cdf0e0224cc8a94b619,openstack/cinder,master,I372292261125f303d7978cdf0e0224cc8a94b619,Huawei driver refactor(3/10),NEW,2019-02-20 03:48:23.000000000,2019-02-25 08:44:06.000000000,,"[{'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 15296}, {'_account_id': 15670}, {'_account_id': 16203}, {'_account_id': 16897}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-02-20 03:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cddf3df4c77f129c430ce6f27fb69c0908000dfd', 'message': ""Huawei driver refactor(3/10)\n\nHuawei driver code is terribly decayed and hard to maintain.\nWe're progressively refactoring total Huawei driver, to make\nthe code more clear, reliable and maintainable.\n\nThis patch mainly optimized the replication.py file and\nthe logic that according to it.\n\nChange-Id: I372292261125f303d7978cdf0e0224cc8a94b619\n""}, {'number': 2, 'created': '2019-02-21 03:29:46.000000000', 'files': ['cinder/volume/drivers/huawei/constants.py', 'cinder/tests/unit/volume/drivers/huawei/test_huawei_drivers.py', 'cinder/volume/drivers/huawei/common.py', 'cinder/volume/drivers/huawei/rest_client.py', 'cinder/volume/drivers/huawei/replication.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/432a7edc6c181d0438e48d292fc53c635d96abec', 'message': ""Huawei driver refactor(3/10)\n\nHuawei driver code is terribly decayed and hard to maintain.\nWe're progressively refactoring total Huawei driver, to make\nthe code more clear, reliable and maintainable.\n\nThis patch mainly optimized the replication.py file and\nthe logic that according to it.\n\nChange-Id: I372292261125f303d7978cdf0e0224cc8a94b619\n""}]",6,638070,432a7edc6c181d0438e48d292fc53c635d96abec,46,21,2,16203,,,0,"Huawei driver refactor(3/10)

Huawei driver code is terribly decayed and hard to maintain.
We're progressively refactoring total Huawei driver, to make
the code more clear, reliable and maintainable.

This patch mainly optimized the replication.py file and
the logic that according to it.

Change-Id: I372292261125f303d7978cdf0e0224cc8a94b619
",git fetch https://review.opendev.org/openstack/cinder refs/changes/70/638070/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/huawei/constants.py', 'cinder/tests/unit/volume/drivers/huawei/test_huawei_drivers.py', 'cinder/volume/drivers/huawei/common.py', 'cinder/volume/drivers/huawei/rest_client.py', 'cinder/volume/drivers/huawei/replication.py']",5,cddf3df4c77f129c430ce6f27fb69c0908000dfd,huawei-driver-refactor-3,"import siximport taskflow.engines from taskflow.patterns import linear_flow from taskflow import task from taskflow.types import failureclass BaseReplicationOp(object): def __init__(self, loc_client, rmt_client): self.loc_client = loc_client self.rmt_client = rmt_client def _wait_until_status(self, rep_id, expect_statuses): def _status_check(): info = self.get_info(rep_id) if info['HEALTHSTATUS'] != constants.REPLICA_HEALTH_STATUS_NORMAL: msg = _('Replication status %s is abnormal.' ) % info['HEALTHSTATUS'] if info['RUNNINGSTATUS'] in expect_statuses: huawei_utils.wait_for_condition(_status_check, constants.DEFAULT_WAIT_INTERVAL, constants.DEFAULT_WAIT_TIMEOUT) def _wait_until_role(self, rep_id, is_primary): def _role_check(): info = self.get_info(rep_id) if info['HEALTHSTATUS'] != constants.REPLICA_HEALTH_STATUS_NORMAL: msg = _('Replication status %s is abnormal.' ) % info['HEALTHSTATUS'] LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) if info['ISPRIMARY'] == is_primary: return True huawei_utils.wait_for_condition(_role_check, constants.DEFAULT_WAIT_INTERVAL, constants.DEFAULT_WAIT_TIMEOUT) def create(self, params): return self._create(params) def delete(self, rep_id): self._delete(rep_id) def sync(self, rep_id, client=None): if not client: client = self.loc_client self._sync(rep_id, client) def split(self, rep_id, rep_info=None): expect_status = (constants.REPLICA_RUNNING_STATUS_SPLIT, constants.REPLICA_RUNNING_STATUS_INTERRUPTED) info = rep_info or self.get_info(rep_id) if (info.get('ISEMPTY') == 'true' or info['RUNNINGSTATUS'] in expect_status): self._split(rep_id) self._wait_until_status(rep_id, expect_status) def switch(self, rep_id): self._switch(rep_id) def unprotect_secondary(self, rep_id): self._unprotect_secondary(rep_id) def protect_secondary(self, rep_id): self._protect_secondary(rep_id) def failover(self, rep_id): """"""Failover replication. Steps: 1. Split replication. 2. Set secondary access readable & writable. 3. Try to switch replication roles. """""" self.split(rep_id) self.unprotect_secondary(rep_id) try: self.switch(rep_id) self._wait_until_role(rep_id, 'true') self.protect_secondary(rep_id) self.sync(rep_id, self.rmt_client) except Exception: LOG.warning('Switch replication %s roles failed, but secondary ' 'is readable&writable now.', rep_id) def failback(self, rep_id): """"""Failback replication. Steps: 1. Switch the role of replication if needed. 2. Sync original secondary data back to original primary. 3. Recover original primary&secondary replication relationship. """""" info = self.get_info(rep_id) self.split(rep_id, info) self.unprotect_secondary(rep_id) # If remote lun is primary, means the previous failover # didn't switch the replication roles, so we need to switch # again to make the original secondary lun primary. if info['ISPRIMARY'] == 'true': self.switch(rep_id) self._wait_until_role(rep_id, 'false') self.protect_secondary(rep_id) self.sync(rep_id) self._wait_until_status( rep_id, (constants.REPLICA_RUNNING_STATUS_NORMAL,)) self.failover(rep_id) class ReplicationPairOp(BaseReplicationOp): def get_info(self, rep_id): return self.rmt_client.get_replication_pair_by_id(rep_id) def _create(self, params): return self.loc_client.create_replication_pair(params) def _delete(self, rep_id): self.loc_client.delete_replication_pair(rep_id) def _sync(self, rep_id, client): client.sync_replication_pair(rep_id) def _split(self, rep_id): self.loc_client.split_replication_pair(rep_id) def _switch(self, rep_id): self.loc_client.switch_replication_pair(rep_id) def _unprotect_secondary(self, rep_id): self.rmt_client.set_replication_pair_second_access( rep_id, constants.REPLICA_SECOND_RW) def _protect_secondary(self, rep_id): self.rmt_client.set_replication_pair_second_access( rep_id, constants.REPLICA_SECOND_RO) class ReplicationGroupOp(BaseReplicationOp): def get_info(self, rep_id): return self.rmt_client.get_replication_group_by_id(rep_id) def _create(self, params): return self.loc_client.create_replication_group(params) def _delete(self, rep_id): self.loc_client.delete_replication_group(rep_id) def _sync(self, rep_id, client): client.sync_replication_group(rep_id) def _split(self, rep_id): self.loc_client.split_replication_group(rep_id) def _switch(self, rep_id): self.loc_client.switch_replication_group(rep_id) def _unprotect_secondary(self, rep_id): self.rmt_client.set_replication_group_second_access( rep_id, constants.REPLICA_SECOND_RW) def _protect_secondary(self, rep_id): self.rmt_client.set_replication_group_second_access( rep_id, constants.REPLICA_SECOND_RO) def add_pair_to_group(self, group_id, pair_id): return self.loc_client.add_pair_to_replication_group( group_id, pair_id) def remove_pair_from_group(self, group_id, pair_id): return self.loc_client.remove_pair_from_replication_group( group_id, pair_id) class _CheckCreateConditionTask(task.Task): default_provides = set(('rmt_dev_id',)) def __init__(self, loc_client, rmt_client, *args, **kwargs): super(_CheckCreateConditionTask, self).__init__(*args, **kwargs) self.loc_client = loc_client self.rmt_client = rmt_client def execute(self): rmt_array = self.rmt_client.get_array_info() rmt_dev = self.loc_client.get_remote_device_by_wwn(rmt_array['wwn']) if not rmt_dev: msg = _(""Remote device %s doesn't exist."") % rmt_array['wwn'] LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) return {'rmt_dev_id': rmt_dev['ID']} class _CreateRemoteLunTask(task.Task): default_provides = set(('remote_lun_id',)) def __init__(self, client, *args, **kwargs): super(_CreateRemoteLunTask, self).__init__(*args, **kwargs) self.client = client def execute(self, lun_params, rmt_pool): pool_id = self.client.get_pool_id(rmt_pool) if not pool_id: msg = _('Remote pool %s for replication not exist.') % rmt_pool LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) lun_params['PARENTID'] = pool_id remote_lun = self.client.create_lun(lun_params) huawei_utils.wait_lun_online(self.client, remote_lun['ID']) return {'remote_lun_id': remote_lun['ID']} def revert(self, result, **kwargs): if isinstance(result, failure.Failure): return self.client.delete_lun(result['remote_lun_id']) class _CreatePairTask(task.Task): default_provides = set(('pair_id',)) def __init__(self, op, *args, **kwargs): super(_CreatePairTask, self).__init__(*args, **kwargs) self.op = op def execute(self, local_lun_id, remote_lun_id, rmt_dev_id, replica_model): params = { ""LOCALRESID"": local_lun_id, ""REMOTEDEVICEID"": rmt_dev_id, ""REMOTERESID"": remote_lun_id, ""REPLICATIONMODEL"": replica_model, ""RECOVERYPOLICY"": '1', ""SPEED"": constants.REPLICA_SPEED, } if replica_model == constants.REPLICA_ASYNC_MODEL: params['SYNCHRONIZETYPE'] = '2' params['TIMINGVAL'] = constants.REPLICA_PERIOD pair_info = self.op.create(params) self.op.sync(pair_info['ID']) return {'pair_id': pair_info['ID']} class ReplicationManager(object): def __init__(self, local_client, rmt_client, configs): self.loc_client = local_client self.rmt_client = rmt_client self.pair_op = ReplicationPairOp(self.loc_client, self.rmt_client) self.group_op = ReplicationGroupOp(self.loc_client, self.rmt_client) self.configs = configs def create_replica(self, local_lun_id, lun_params, replica_model): 3. sync replication pair LOG.info(('Create replication, local lun: %(local_lun_id)s, ' 'replication model: %(model)s.'), {'local_lun_id': local_lun_id, 'model': replica_model}) store_spec = {'local_lun_id': local_lun_id, 'lun_params': lun_params, 'replica_model': replica_model, 'rmt_pool': self.configs['storage_pools'][0], } work_flow = linear_flow.Flow('create_replication') work_flow.add( _CheckCreateConditionTask(self.loc_client, self.rmt_client), _CreateRemoteLunTask(self.rmt_client), _CreatePairTask(self.pair_op), ) engine = taskflow.engines.load(work_flow, store=store_spec) engine.run() return engine.storage.fetch('pair_id') def delete_replica(self, pair_id): LOG.info('Delete replication pair %s.', pair_id) try: pair_info = self.pair_op.get_info(pair_id) except exception.VolumeBackendAPIException as exc: if huawei_utils.is_not_exist_exc(exc): return raise self.pair_op.split(pair_id) self.pair_op.delete(pair_id) self.rmt_client.delete_lun(pair_info['LOCALRESID']) def _pre_fail_check(self, volumes, statuc_check_func): normal_volumes = [] pair_ids = [] group_ids = set() volume_pair_infos = {} for v in volumes: drv_data = huawei_utils.to_dict(v.replication_driver_data) pair_id = drv_data.get('pair_id') if not pair_id: normal_volumes.append(v.id) continue pair_info = self.pair_op.get_info(pair_id) volume_pair_infos[v.id] = pair_info cg_id = pair_info.get('CGID') if cg_id: if cg_id not in group_ids: group_ids.add(cg_id) else: pair_ids.append(pair_id) for pair_info in six.itervalues(volume_pair_infos): if not statuc_check_func(pair_info): msg = _('Replication pair %(id)s is not at the status ' 'failover/failback available, RUNNINGSTATUS: %(run)s, ' 'SECRESDATASTATUS: %(sec)s.' ) % {'id': pair_info['ID'], 'run': pair_info['RUNNINGSTATUS'], 'sec': pair_info['SECRESDATASTATUS']} LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) return normal_volumes, list(group_ids), pair_ids, volume_pair_infos def _fail_op(self, volumes, status_check_func, fail_group_func, fail_pair_func): (normal_volumes, group_ids, pair_ids, volume_pair_infos ) = self._pre_fail_check(volumes, status_check_func) for group in group_ids: fail_group_func(group) for pair in pair_ids: fail_pair_func(pair) volumes_update = [] for v in volumes: if v.id in normal_volumes: LOG.warning(""Volume %s doesn't have replication."", v.id) continue rmt_lun_id = volume_pair_infos[v.id]['LOCALRESID'] rmt_lun_info = self.rmt_client.get_lun_info_by_id(rmt_lun_id) location = huawei_utils.to_string( huawei_lun_id=rmt_lun_id, huawei_lun_wwn=rmt_lun_info['WWN'], huawei_sn=self.rmt_client.device_id, ) volume_update = {'volume_id': v.id} volume_update['updates'] = { 'provider_location': location, } volumes_update.append(volume_update) return volumes_update def failback(self, volumes): """"""Failback volumes to primary storage."""""" def _status_check_func(pair_info): return pair_info['RUNNINGSTATUS'] in ( constants.REPLICA_RUNNING_STATUS_NORMAL, constants.REPLICA_RUNNING_STATUS_SPLIT ) and pair_info['SECRESDATASTATUS'] in ( constants.REPLICA_SECRES_DATA_SYNC, constants.REPLICA_SECRES_DATA_COMPLETE ) return self._fail_op(volumes, _status_check_func, self.group_op.failback, self.pair_op.failback) def failover(self, volumes): """"""Failover volumes to secondary storage."""""" def _status_check_func(pair_info): return pair_info['RUNNINGSTATUS'] in ( constants.REPLICA_RUNNING_STATUS_NORMAL, constants.REPLICA_RUNNING_STATUS_SPLIT, constants.REPLICA_RUNNING_STATUS_INTERRUPTED ) and pair_info['SECRESDATASTATUS'] in ( constants.REPLICA_SECRES_DATA_SYNC, constants.REPLICA_SECRES_DATA_COMPLETE ) return self._fail_op(volumes, _status_check_func, self.group_op.failover, self.pair_op.failover) def create_group(self, group_id, replica_model): LOG.info(""Create replication group %s."", group_id) group_name = huawei_utils.encode_name(group_id) params = {'NAME': group_name, 'DESCRIPTION': group_id, 'RECOVERYPOLICY': '1', 'REPLICATIONMODEL': replica_model, 'SPEED': constants.REPLICA_SPEED} if replica_model == constants.REPLICA_ASYNC_MODEL: params['SYNCHRONIZETYPE'] = '2' params['TIMINGVAL'] = constants.REPLICA_CG_PERIOD group = self.group_op.create(params) return group['ID'] def _add_volumes_to_group(self, group_id, volumes): for volume in volumes: drv_data = huawei_utils.to_dict(volume.replication_driver_data) pair_id = drv_data.get('pair_id') if not pair_id: LOG.warning(""Volume %s doesn't have replication."", volume.id) continue self.pair_op.split(pair_id) self.group_op.add_pair_to_group(group_id, pair_id) def _remove_volumes_from_group(self, group_id, volumes): for volume in volumes: drv_data = huawei_utils.to_dict(volume.replication_driver_data) pair_id = drv_data.get('pair_id') if not pair_id: LOG.warning(""Volume %s doesn't have replication."", volume.id) continue self.group_op.remove_pair_from_group(group_id, pair_id) self.pair_op.sync(pair_id) def delete_group(self, group_id, volumes): LOG.info(""Delete replication group %s."", group_id) group_info = huawei_utils.get_replication_group( self.loc_client, group_id) if not group_info: LOG.warning('Replication group %s to delete not exist.', group_id) return self.group_op.split(group_info['ID'], group_info) self._remove_volumes_from_group(group_info['ID'], volumes) self.group_op.delete(group_info['ID']) def update_group(self, group_id, add_volumes, remove_volumes): LOG.info(""Update replication group %s."", group_id) group_info = huawei_utils.get_replication_group( self.loc_client, group_id) if not group_info: LOG.warning('Replication group %s to update not exist.', group_id) return self.group_op.split(group_info['ID'], group_info) self._add_volumes_to_group(group_info['ID'], add_volumes) self._remove_volumes_from_group(group_info['ID'], remove_volumes) self.group_op.sync(group_info['ID']) def add_replication_to_group(self, group_id, pair_id): group_info = huawei_utils.get_replication_group( self.loc_client, group_id) if not group_info: msg = _('Replication group %s not exist.') % group_id self.group_op.split(group_info['ID'], group_info) self.pair_op.split(pair_id) self.group_op.add_pair_to_group(group_info['ID'], pair_id) self.group_op.sync(group_info['ID'])","import jsonfrom oslo_utils import excutilsclass AbsReplicaOp(object): def __init__(self, client): self.client = client def create(self, **kwargs): pass def delete(self, replica_id): pass def protect_second(self, replica_id): pass def unprotect_second(self, replica_id): pass def sync(self, replica_id): pass def split(self, replica_id): pass def switch(self, replica_id): pass def is_primary(self, replica_info): flag = replica_info.get('ISPRIMARY') if flag and flag.lower() == 'true': return True return False def get_replica_info(self, replica_id): return {} def _is_status(self, status_key, status, replica_info): if type(status) in (list, tuple): return replica_info.get(status_key, '') in status if type(status) is str: return replica_info.get(status_key, '') == status return False def is_running_status(self, status, replica_info): return self._is_status(constants.REPLICA_RUNNING_STATUS_KEY, status, replica_info) def is_health_status(self, status, replica_info): return self._is_status(constants.REPLICA_HEALTH_STATUS_KEY, status, replica_info) class PairOp(AbsReplicaOp): def create(self, local_lun_id, rmt_lun_id, rmt_dev_id, rmt_dev_name, replica_model, speed=constants.REPLICA_SPEED, period=constants.REPLICA_PERIOD, **kwargs): super(PairOp, self).create(**kwargs) params = { ""LOCALRESID"": local_lun_id, ""LOCALRESTYPE"": '11', ""REMOTEDEVICEID"": rmt_dev_id, ""REMOTEDEVICENAME"": rmt_dev_name, ""REMOTERESID"": rmt_lun_id, ""REPLICATIONMODEL"": replica_model, # recovery policy. 1: auto, 2: manual ""RECOVERYPOLICY"": '1', ""SPEED"": speed, } if replica_model == constants.REPLICA_ASYNC_MODEL: # Synchronize type values: # 1, manual # 2, timed wait when synchronization begins # 3, timed wait when synchronization ends params['SYNCHRONIZETYPE'] = '2' params['TIMINGVAL'] = period try: pair_info = self.client.create_pair(params) except Exception as err: msg = _('Create replication pair failed. Error: %s.') % err LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) return pair_info def split(self, pair_id): self.client.split_pair(pair_id) def delete(self, pair_id, force=False): self.client.delete_pair(pair_id, force) def protect_second(self, pair_id): self.client.set_pair_second_access(pair_id, constants.REPLICA_SECOND_RO) def unprotect_second(self, pair_id): self.client.set_pair_second_access(pair_id, constants.REPLICA_SECOND_RW) def sync(self, pair_id): self.client.sync_pair(pair_id) def switch(self, pair_id): self.client.switch_pair(pair_id) def get_replica_info(self, pair_id): return self.client.get_pair_by_id(pair_id) class CGOp(AbsReplicaOp): pass class ReplicaCommonDriver(object): def __init__(self, conf, replica_op): self.conf = conf self.op = replica_op def protect_second(self, replica_id): info = self.op.get_replica_info(replica_id) if info.get('SECRESACCESS') == constants.REPLICA_SECOND_RO: return self.op.protect_second(replica_id) self.wait_second_access(replica_id, constants.REPLICA_SECOND_RO) def unprotect_second(self, replica_id): info = self.op.get_replica_info(replica_id) if info.get('SECRESACCESS') == constants.REPLICA_SECOND_RW: return self.op.unprotect_second(replica_id) self.wait_second_access(replica_id, constants.REPLICA_SECOND_RW) def sync(self, replica_id, wait_complete=False): self.protect_second(replica_id) expect_status = (constants.REPLICA_RUNNING_STATUS_NORMAL, constants.REPLICA_RUNNING_STATUS_SYNC, constants.REPLICA_RUNNING_STATUS_INITIAL_SYNC) info = self.op.get_replica_info(replica_id) # When running status is synchronizing or normal, # it's not necessary to do synchronize again. if (info.get('REPLICATIONMODEL') == constants.REPLICA_SYNC_MODEL and self.op.is_running_status(expect_status, info)): return self.op.sync(replica_id) self.wait_expect_state(replica_id, expect_status) if wait_complete: self.wait_replica_ready(replica_id) def split(self, replica_id): running_status = (constants.REPLICA_RUNNING_STATUS_SPLIT, constants.REPLICA_RUNNING_STATUS_INVALID, constants.REPLICA_RUNNING_STATUS_ERRUPTED) info = self.op.get_replica_info(replica_id) if self.op.is_running_status(running_status, info): return try: self.op.split(replica_id) except Exception as err: LOG.warning('Split replication exception: %s.', err) try: self.wait_expect_state(replica_id, running_status) except Exception as err: msg = _('Split replication failed.') LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def enable(self, replica_id, wait_sync_complete=False): info = self.op.get_replica_info(replica_id) if not self.op.is_primary(info): self.switch(replica_id) self.sync(replica_id) return None def switch(self, replica_id): self.split(replica_id) self.unprotect_second(replica_id) self.op.switch(replica_id) # Wait to be primary def _wait_switch_to_primary(): info = self.op.get_replica_info(replica_id) if self.op.is_primary(info): return True return False interval = constants.DEFAULT_REPLICA_WAIT_INTERVAL timeout = constants.DEFAULT_REPLICA_WAIT_TIMEOUT huawei_utils.wait_for_condition(_wait_switch_to_primary, interval, timeout) def failover(self, replica_id): """"""Failover replication. Purpose: 1. Split replication. 2. Set secondary access read & write. """""" info = self.op.get_replica_info(replica_id) if self.op.is_primary(info): msg = _('We should not do switch over on primary array.') LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) sync_status_set = (constants.REPLICA_RUNNING_STATUS_SYNC, constants.REPLICA_RUNNING_STATUS_INITIAL_SYNC) if self.op.is_running_status(sync_status_set, info): self.wait_replica_ready(replica_id) self.split(replica_id) self.op.unprotect_second(replica_id) def wait_replica_ready(self, replica_id, interval=None, timeout=None): LOG.debug('Wait synchronize complete.') running_status_normal = (constants.REPLICA_RUNNING_STATUS_NORMAL, constants.REPLICA_RUNNING_STATUS_SYNCED) running_status_sync = (constants.REPLICA_RUNNING_STATUS_SYNC, constants.REPLICA_RUNNING_STATUS_INITIAL_SYNC) health_status_normal = constants.REPLICA_HEALTH_STATUS_NORMAL def _replica_ready(): info = self.op.get_replica_info(replica_id) if (self.op.is_running_status(running_status_normal, info) and self.op.is_health_status(health_status_normal, info)): return True if not self.op.is_running_status(running_status_sync, info): msg = (_('Wait synchronize failed. Running status: %s.') % info.get(constants.REPLICA_RUNNING_STATUS_KEY)) return False if not interval: interval = constants.DEFAULT_WAIT_INTERVAL if not timeout: timeout = constants.DEFAULT_WAIT_TIMEOUT huawei_utils.wait_for_condition(_replica_ready, interval, timeout) def wait_second_access(self, replica_id, access_level): def _check_access(): info = self.op.get_replica_info(replica_id) if info.get('SECRESACCESS') == access_level: interval = constants.DEFAULT_REPLICA_WAIT_INTERVAL timeout = constants.DEFAULT_REPLICA_WAIT_TIMEOUT huawei_utils.wait_for_condition(_check_access, interval, timeout) def wait_expect_state(self, replica_id, running_status, health_status=None, interval=None, timeout=None): def _check_state(): info = self.op.get_replica_info(replica_id) if self.op.is_running_status(running_status, info): if (not health_status or self.op.is_health_status(health_status, info)): return True if not interval: interval = constants.DEFAULT_REPLICA_WAIT_INTERVAL if not timeout: timeout = constants.DEFAULT_REPLICA_WAIT_TIMEOUT huawei_utils.wait_for_condition(_check_state, interval, timeout) def get_replication_driver_data(volume): if volume.replication_driver_data: return json.loads(volume.replication_driver_data) return {} def to_string(dict_data): if dict_data: return json.dumps(dict_data) return '' class ReplicaPairManager(object): def __init__(self, local_client, rmt_client, conf): self.local_client = local_client self.rmt_client = rmt_client self.conf = conf # Now just support one remote pool. self.rmt_pool = self.rmt_client.storage_pools[0] self.local_op = PairOp(self.local_client) self.local_driver = ReplicaCommonDriver(self.conf, self.local_op) self.rmt_op = PairOp(self.rmt_client) self.rmt_driver = ReplicaCommonDriver(self.conf, self.rmt_op) def try_get_remote_wwn(self): try: info = self.rmt_client.get_array_info() return info.get('wwn') except Exception as err: LOG.warning('Get remote array wwn failed. Error: %s.', err) return None def get_remote_device_by_wwn(self, wwn): devices = {} try: devices = self.local_client.get_remote_devices() except Exception as err: LOG.warning('Get remote devices failed. Error: %s.', err) for device in devices: if device.get('WWN') == wwn: return device return {} def check_remote_available(self): # We get device wwn in every check time. # If remote array changed, we can run normally. wwn = self.try_get_remote_wwn() if not wwn: return False device = self.get_remote_device_by_wwn(wwn) # Check remote device is available to use. # If array type is replication, 'ARRAYTYPE' == '1'. # If health status is normal, 'HEALTHSTATUS' == '1'. if (device and device.get('ARRAYTYPE') == '1' and device.get('HEALTHSTATUS') == '1' and device.get('RUNNINGSTATUS') == constants.STATUS_RUNNING): return True return False def update_replica_capability(self, stats): is_rmt_dev_available = self.check_remote_available() if not is_rmt_dev_available: LOG.warning('Remote device is unavailable.') return stats for pool in stats['pools']: pool['replication_enabled'] = True pool['replication_type'] = ['sync', 'async'] return stats def get_rmt_dev_info(self): wwn = self.try_get_remote_wwn() if not wwn: return None, None device = self.get_remote_device_by_wwn(wwn) if not device: return None, None return device.get('ID'), device.get('NAME') def build_rmt_lun_params(self, local_lun_info): params = { 'TYPE': '11', 'NAME': local_lun_info['NAME'], 'PARENTTYPE': '216', 'PARENTID': self.rmt_client.get_pool_id(self.rmt_pool), 'DESCRIPTION': local_lun_info['DESCRIPTION'], 'ALLOCTYPE': local_lun_info['ALLOCTYPE'], 'CAPACITY': local_lun_info['CAPACITY'], 'READCACHEPOLICY': self.conf.lun_read_cache_policy, 'WRITECACHEPOLICY': self.conf.lun_write_cache_policy, } if 'WRITEPOLICY' in local_lun_info: params['WRITEPOLICY'] = local_lun_info['WRITEPOLICY'] if 'PREFETCHPOLICY' in local_lun_info: params['PREFETCHPOLICY'] = local_lun_info['PREFETCHPOLICY'] if 'PREFETCHVALUE' in local_lun_info: params['PREFETCHVALUE'] = local_lun_info['PREFETCHVALUE'] if 'DATATRANSFERPOLICY' in local_lun_info: params['DATATRANSFERPOLICY'] = local_lun_info['DATATRANSFERPOLICY'] LOG.debug('Remote lun params: %s.', params) return params def wait_volume_online(self, client, lun_info, interval=None, timeout=None): online_status = constants.STATUS_VOLUME_READY if lun_info.get('RUNNINGSTATUS') == online_status: lun_id = lun_info['ID'] def _wait_online(): info = client.get_lun_info(lun_id) return info.get('RUNNINGSTATUS') == online_status if not interval: interval = constants.DEFAULT_REPLICA_WAIT_INTERVAL if not timeout: timeout = constants.DEFAULT_REPLICA_WAIT_TIMEOUT huawei_utils.wait_for_condition(_wait_online, interval, timeout) def create_rmt_lun(self, local_lun_info): # Create on rmt array. If failed, raise exception. lun_params = self.build_rmt_lun_params(local_lun_info) lun_info = self.rmt_client.create_lun(lun_params) try: self.wait_volume_online(self.rmt_client, lun_info) except exception.VolumeBackendAPIException: with excutils.save_and_reraise_exception(): self.rmt_client.delete_lun(lun_info['ID']) return lun_info def create_replica(self, local_lun_info, replica_model): 3. enable replication pair LOG.debug(('Create replication, local lun info: %(info)s, ' 'replication model: %(model)s.'), {'info': local_lun_info, 'model': replica_model}) local_lun_id = local_lun_info['ID'] self.wait_volume_online(self.local_client, local_lun_info) # step1, create remote lun rmt_lun_info = self.create_rmt_lun(local_lun_info) rmt_lun_id = rmt_lun_info['ID'] # step2, get remote device info rmt_dev_id, rmt_dev_name = self.get_rmt_dev_info() if not rmt_lun_id or not rmt_dev_name: self._delete_rmt_lun(rmt_lun_id) msg = _('Get remote device info failed.') # step3, create replication pair try: pair_info = self.local_op.create(local_lun_id, rmt_lun_id, rmt_dev_id, rmt_dev_name, replica_model) pair_id = pair_info['ID'] except Exception as err: with excutils.save_and_reraise_exception(): LOG.error('Create pair failed. Error: %s.', err) self._delete_rmt_lun(rmt_lun_id) # step4, start sync manually. If replication type is sync, # then wait for sync complete. wait_complete = (replica_model == constants.REPLICA_SYNC_MODEL) try: self.local_driver.sync(pair_id, wait_complete) except Exception as err: with excutils.save_and_reraise_exception(): LOG.error('Start synchronization failed. Error: %s.', err) self._delete_pair(pair_id) self._delete_rmt_lun(rmt_lun_id) model_update = {} driver_data = {'pair_id': pair_id, 'rmt_lun_id': rmt_lun_id, 'rmt_lun_wwn': rmt_lun_info['WWN']} model_update['replication_driver_data'] = to_string(driver_data) model_update['replication_status'] = 'available' LOG.debug('Create replication, return info: %s.', model_update) return model_update def _delete_pair(self, pair_id): if (not pair_id or not self.local_client.check_pair_exist(pair_id)): return self.local_driver.split(pair_id) self.local_op.delete(pair_id) def _delete_rmt_lun(self, lun_id): if lun_id and self.rmt_client.check_lun_exist(lun_id): self.rmt_client.delete_lun(lun_id) def delete_replica(self, volume): """"""Delete replication pair and remote lun. Purpose: 1. delete replication pair 2. delete remote_lun """""" LOG.debug('Delete replication, volume: %s.', volume.id) info = get_replication_driver_data(volume) pair_id = info.get('pair_id') if pair_id: self._delete_pair(pair_id) # Delete remote_lun rmt_lun_id = info.get('rmt_lun_id') if rmt_lun_id: self._delete_rmt_lun(rmt_lun_id) def failback(self, volumes): """"""Failover volumes back to primary backend. The main steps: 1. Switch the role of replication pairs. 2. Copy the second LUN data back to primary LUN. 3. Split replication pairs. 4. Switch the role of replication pairs. 5. Enable replications. """""" volumes_update = [] for v in volumes: v_update = {} v_update['volume_id'] = v.id drv_data = get_replication_driver_data(v) pair_id = drv_data.get('pair_id') if not pair_id: LOG.warning(""No pair id in volume %s."", v.id) v_update['updates'] = {'replication_status': 'error'} volumes_update.append(v_update) continue rmt_lun_id = drv_data.get('rmt_lun_id') if not rmt_lun_id: LOG.warning(""No remote lun id in volume %s."", v.id) v_update['updates'] = {'replication_status': 'error'} volumes_update.append(v_update) continue # Switch replication pair role, and start synchronize. self.local_driver.enable(pair_id) # Wait for synchronize complete. self.local_driver.wait_replica_ready(pair_id) # Split replication pair again self.rmt_driver.failover(pair_id) # Switch replication pair role, and start synchronize. self.rmt_driver.enable(pair_id) local_metadata = huawei_utils.get_volume_private_data(v) new_drv_data = to_string( {'pair_id': pair_id, 'rmt_lun_id': local_metadata.get('huawei_lun_id'), 'rmt_lun_wwn': local_metadata.get('huawei_lun_wwn')}) location = huawei_utils.to_string( huawei_lun_id=rmt_lun_id, huawei_lun_wwn=drv_data.get('rmt_lun_wwn')) v_update['updates'] = {'provider_location': location, 'replication_status': 'available', 'replication_driver_data': new_drv_data} volumes_update.append(v_update) return volumes_update def failover(self, volumes): """"""Failover volumes back to secondary array. Split the replication pairs and make the secondary LUNs R&W. """""" volumes_update = [] for v in volumes: v_update = {} v_update['volume_id'] = v.id drv_data = get_replication_driver_data(v) pair_id = drv_data.get('pair_id') if not pair_id: LOG.warning(""No pair id in volume %s."", v.id) v_update['updates'] = {'replication_status': 'error'} volumes_update.append(v_update) continue rmt_lun_id = drv_data.get('rmt_lun_id') if not rmt_lun_id: LOG.warning(""No remote lun id in volume %s."", v.id) v_update['updates'] = {'replication_status': 'error'} volumes_update.append(v_update) continue self.rmt_driver.failover(pair_id) local_metadata = huawei_utils.get_volume_private_data(v) new_drv_data = to_string( {'pair_id': pair_id, 'rmt_lun_id': local_metadata.get('huawei_lun_id'), 'rmt_lun_wwn': local_metadata.get('huawei_lun_wwn')}) location = huawei_utils.to_string( huawei_lun_id=rmt_lun_id, huawei_lun_wwn=drv_data.get('rmt_lun_wwn')) v_update['updates'] = {'provider_location': location, 'replication_status': 'failed-over', 'replication_driver_data': new_drv_data} volumes_update.append(v_update) return volumes_update def get_replication_opts(opts): if opts.get('replication_type') == 'sync': opts['replication_type'] = constants.REPLICA_SYNC_MODEL else: opts['replication_type'] = constants.REPLICA_ASYNC_MODEL return opts",697,940
openstack%2Fcharm-interface-ceph-mds~master~Iea36466f5038136727b7a6b62578cb3d0f964a6e,openstack/charm-interface-ceph-mds,master,Iea36466f5038136727b7a6b62578cb3d0f964a6e,Set appropriate application tag for pools created,MERGED,2019-02-20 06:52:34.000000000,2019-02-25 08:42:11.000000000,2019-02-25 08:42:11.000000000,"[{'_account_id': 13686}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-20 06:52:34.000000000', 'files': ['.gitignore', 'requires.py'], 'web_link': 'https://opendev.org/openstack/charm-interface-ceph-mds/commit/34a4dcc0ecb6853b816f398d381e03f1ccba098b', 'message': ""Set appropriate application tag for pools created\n\nUse cases are emerging for the Ceph pool application tags. Let's set\nappropriate name for the pools created for CephFS.\n\nChange-Id: Iea36466f5038136727b7a6b62578cb3d0f964a6e\nReference: http://docs.ceph.com/docs/master/rados/operations/pools/#associate-pool-to-application\n""}]",0,638094,34a4dcc0ecb6853b816f398d381e03f1ccba098b,8,4,1,13686,,,0,"Set appropriate application tag for pools created

Use cases are emerging for the Ceph pool application tags. Let's set
appropriate name for the pools created for CephFS.

Change-Id: Iea36466f5038136727b7a6b62578cb3d0f964a6e
Reference: http://docs.ceph.com/docs/master/rados/operations/pools/#associate-pool-to-application
",git fetch https://review.opendev.org/openstack/charm-interface-ceph-mds refs/changes/94/638094/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'requires.py']",2,34a4dcc0ecb6853b816f398d381e03f1ccba098b,app-name," ceph_pool_app_name = 'cephfs' weight=None, app_name=self.ceph_pool_app_name) weight=None, app_name=self.ceph_pool_app_name)", weight=None) weight=None),7,2
openstack%2Fos-brick~master~I384f533c928efd40d27269297f5dd64aa3913fea,openstack/os-brick,master,I384f533c928efd40d27269297f5dd64aa3913fea,drop support for old connector class paths,ABANDONED,2019-02-22 15:04:55.000000000,2019-02-25 08:22:35.000000000,,"[{'_account_id': 10058}, {'_account_id': 10118}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 27710}]","[{'number': 1, 'created': '2019-02-22 15:04:55.000000000', 'files': ['doc/source/reference/os_brick/initiator/connector.rst', 'os_brick/initiator/connector.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/f1c2c64fd0c2a6ff671ee1b909f2236f5a69bc56', 'message': 'drop support for old connector class paths\n\nChange-Id: I384f533c928efd40d27269297f5dd64aa3913fea\n'}]",0,638683,f1c2c64fd0c2a6ff671ee1b909f2236f5a69bc56,16,13,1,29675,,,0,"drop support for old connector class paths

Change-Id: I384f533c928efd40d27269297f5dd64aa3913fea
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/83/638683/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/reference/os_brick/initiator/connector.rst', 'os_brick/initiator/connector.py']",2,f1c2c64fd0c2a6ff671ee1b909f2236f5a69bc56,scaleio-vxflexos-rebrand,,# Create aliases to the old names until 2.0.0 # TODO(smcginnis) Remove this lookup once unit test code is updated to # point to the correct location for item in connector_list: _name = item.split('.')[-1] globals()[_name] = importutils.import_class(item) ,5,13
openstack%2Fdiskimage-builder~master~I52a38c16dbbbe9fa1d4d6b6daffde01f63f664e6,openstack/diskimage-builder,master,I52a38c16dbbbe9fa1d4d6b6daffde01f63f664e6,set rhel minor release,MERGED,2019-02-10 14:54:43.000000000,2019-02-25 08:11:56.000000000,2019-02-25 08:11:56.000000000,"[{'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-10 14:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/5b3d04ab4cd7943a8c0d5f5032d0bc118113e236', 'message': 'set rhel minor release\n\nChange-Id: I52a38c16dbbbe9fa1d4d6b6daffde01f63f664e6\n'}, {'number': 2, 'created': '2019-02-10 15:00:00.000000000', 'files': ['diskimage_builder/elements/rhel-common/pre-install.d/00-rhel-registration', 'diskimage_builder/elements/rhel-common/os-refresh-config/pre-configure.d/06-rhel-registration'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/802dc35a6178ea4fca3ac036da8049d74416fb85', 'message': 'set rhel minor release\n\nChange-Id: I52a38c16dbbbe9fa1d4d6b6daffde01f63f664e6\n'}]",0,636063,802dc35a6178ea4fca3ac036da8049d74416fb85,14,4,2,16690,,,0,"set rhel minor release

Change-Id: I52a38c16dbbbe9fa1d4d6b6daffde01f63f664e6
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/63/636063/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,5b3d04ab4cd7943a8c0d5f5032d0bc118113e236,set-rhel-minor-release,,,0,0
openstack%2Fcharm-percona-cluster~stable%2F18.05~I06d36c13ecc48a942e559d09d94e7813a2254479,openstack/charm-percona-cluster,stable/18.05,I06d36c13ecc48a942e559d09d94e7813a2254479,Use correct SST password in backup action,ABANDONED,2019-02-06 10:29:46.000000000,2019-02-25 08:09:58.000000000,,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 21107}, {'_account_id': 24890}]","[{'number': 1, 'created': '2019-02-06 10:29:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/bf8944e517e424a94c4cec214d1059912e87469d', 'message': 'Use correct SST password in backup action\n\nThe backup action currently retrieves the sst-password from the charm\nconfiguration exclusively, instead of the leader settings where it is\nusually stored when auto-generated.\n\nAlways retrieve the correct SST password using the\npercona_utils._get_password function.\n\nChange-Id: I06d36c13ecc48a942e559d09d94e7813a2254479\n(cherry picked from commit f19a766d430101f68b1b7ed31a8c1c64293afaa7)\n'}, {'number': 2, 'created': '2019-02-22 13:50:36.000000000', 'files': ['actions/actions.py'], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/f0c545bbc528f12f5af4427ea4ffb6613e0772b5', 'message': 'Use correct SST password in backup action\n\nThe backup action currently retrieves the sst-password from the charm\nconfiguration exclusively, instead of the leader settings where it is\nusually stored when auto-generated.\n\nAlways retrieve the correct SST password using the\npercona_utils._get_password function.\n\nChange-Id: I06d36c13ecc48a942e559d09d94e7813a2254479\nCloses-Bug: 1815740\n(cherry pick from commit f19a766d430101f68b1b7ed31a8c1c64293afaa7)\n'}]",0,635124,f0c545bbc528f12f5af4427ea4ffb6613e0772b5,11,4,2,20634,,,0,"Use correct SST password in backup action

The backup action currently retrieves the sst-password from the charm
configuration exclusively, instead of the leader settings where it is
usually stored when auto-generated.

Always retrieve the correct SST password using the
percona_utils._get_password function.

Change-Id: I06d36c13ecc48a942e559d09d94e7813a2254479
Closes-Bug: 1815740
(cherry pick from commit f19a766d430101f68b1b7ed31a8c1c64293afaa7)
",git fetch https://review.opendev.org/openstack/charm-percona-cluster refs/changes/24/635124/1 && git format-patch -1 --stdout FETCH_HEAD,['actions/actions.py'],1,bf8944e517e424a94c4cec214d1059912e87469d,bug/1815740," _get_password, sstpw = _get_password(""sst-password"")"," config, sstpw = config(""sst-password"")",2,2
openstack%2Fneutron-lbaas~master~Ia51a2f22070f495d88cde181382b5751e8a1109f,openstack/neutron-lbaas,master,Ia51a2f22070f495d88cde181382b5751e8a1109f,Misc Python 3.6 fixes,ABANDONED,2018-06-15 13:46:05.000000000,2019-02-25 08:03:08.000000000,,"[{'_account_id': 9008}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-06-15 13:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/a7aa3b3e5ef9d15bbd02cdd612812041779833ce', 'message': 'Improve patching of sys.argv\n\nEnsure that sys.argv is patched with an array; Python 3.6\nenforces more strict type checking on the contents of argv,\nand will throw an exception if presented with a Mock.\n\nChange-Id: Ia51a2f22070f495d88cde181382b5751e8a1109f\n'}, {'number': 2, 'created': '2018-06-18 08:27:42.000000000', 'files': ['neutron_lbaas/tests/unit/agent/test_agent.py', 'neutron_lbaas/drivers/haproxy/jinja_cfg.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/cb612c1a74c158bb91e8f7bee49c747b13b60d27', 'message': 'Misc Python 3.6 fixes\n\nImprove patching of sys.argv\n\nEnsure that sys.argv is patched with an array; Python 3.6\nenforces more strict type checking on the contents of argv,\nand will throw an exception if presented with a Mock.\n\nEnsure list of expected codes is sorted\n\nThe order of the expected codes list for haproxy templates\nis not deterministic under Python 3.6; ensure set of codes\nis sorted for determinism.\n\nChange-Id: Ia51a2f22070f495d88cde181382b5751e8a1109f\n'}]",0,575741,cb612c1a74c158bb91e8f7bee49c747b13b60d27,7,2,2,935,,,0,"Misc Python 3.6 fixes

Improve patching of sys.argv

Ensure that sys.argv is patched with an array; Python 3.6
enforces more strict type checking on the contents of argv,
and will throw an exception if presented with a Mock.

Ensure list of expected codes is sorted

The order of the expected codes list for haproxy templates
is not deterministic under Python 3.6; ensure set of codes
is sorted for determinism.

Change-Id: Ia51a2f22070f495d88cde181382b5751e8a1109f
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/41/575741/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/tests/unit/agent/test_agent.py'],1,a7aa3b3e5ef9d15bbd02cdd612812041779833ce,py36-fixes," mock.patch('sys.argv', []), \"," mock.patch('sys.argv'), \",1,1
openstack%2Fvitrage-tempest-plugin~master~Ie3b80529100d29cfba2c951d776f3a1b9c855403,openstack/vitrage-tempest-plugin,master,Ie3b80529100d29cfba2c951d776f3a1b9c855403,Should not be a list,MERGED,2019-02-24 07:41:15.000000000,2019-02-25 07:28:29.000000000,2019-02-25 07:28:29.000000000,"[{'_account_id': 5689}, {'_account_id': 13861}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-24 07:41:15.000000000', 'files': ['vitrage_tempest_plugin/plugin.py'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/ef5f698e34db436cf92de441ecfc4b7c578c7d4b', 'message': 'Should not be a list\n\nsee @yatin remark https://review.openstack.org/#/c/627016/15\n\nChange-Id: Ie3b80529100d29cfba2c951d776f3a1b9c855403\n'}]",0,638931,ef5f698e34db436cf92de441ecfc4b7c578c7d4b,9,5,1,19134,,,0,"Should not be a list

see @yatin remark https://review.openstack.org/#/c/627016/15

Change-Id: Ie3b80529100d29cfba2c951d776f3a1b9c855403
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/31/638931/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage_tempest_plugin/plugin.py'],1,ef5f698e34db436cf92de441ecfc4b7c578c7d4b,eyalb/plugin, config_rca_service.ServiceAvailableGroup)], [config_rca_service.ServiceAvailableGroup])],1,1
openstack%2Fdiskimage-builder~master~I1af9e84d76bedcb2607717edc6d2abe2920b0584,openstack/diskimage-builder,master,I1af9e84d76bedcb2607717edc6d2abe2920b0584,Fix opensuse 42.3 pip-and-virtualenv,MERGED,2019-02-22 07:05:04.000000000,2019-02-25 07:24:34.000000000,2019-02-25 07:24:34.000000000,"[{'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-22 07:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/0d98324b66cae23b7fe00ff8a0569a8c459e14bc', 'message': '[wip] fix opensuse pip-and-virtualenv\n\nChange-Id: I1af9e84d76bedcb2607717edc6d2abe2920b0584\n'}, {'number': 2, 'created': '2019-02-25 00:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/797cb828e7bc3277fae5b880074accc5db6273cc', 'message': '[wip] fix opensuse pip-and-virtualenv\n\nChange-Id: I1af9e84d76bedcb2607717edc6d2abe2920b0584\n'}, {'number': 3, 'created': '2019-02-25 02:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/cb4b773057aabf1b69409adf3fe618c9059627a6', 'message': '[wip] fix opensuse pip-and-virtualenv\n\nChange-Id: I1af9e84d76bedcb2607717edc6d2abe2920b0584\n'}, {'number': 4, 'created': '2019-02-25 02:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f931ad865fc466accf24452714f1da80ef6c061a', 'message': '[wip] fix opensuse pip-and-virtualenv\n\nChange-Id: I1af9e84d76bedcb2607717edc6d2abe2920b0584\n'}, {'number': 5, 'created': '2019-02-25 03:20:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b9a7973ca0549abf0fb0171fb4e032a2a26ca076', 'message': 'Fix opensuse 42.3 pip-and-virtualenv\n\nRelated to I041a141366099093805e6052b1bbf64efd277e1e, we also need to\nremove this on opensuse.  The files for gate testing are added, but\nthe test is not added to any jobs at this point in the interests of\ngate time.\n\nChange-Id: I1af9e84d76bedcb2607717edc6d2abe2920b0584\n'}, {'number': 6, 'created': '2019-02-25 04:45:40.000000000', 'files': ['diskimage_builder/elements/pip-and-virtualenv/test-elements/source-install-opensuse/element-deps', 'diskimage_builder/elements/pip-and-virtualenv/test-elements/source-install-opensuse/environment.d/10-source-installtype-pip-and-virtualenv', 'diskimage_builder/elements/pip-and-virtualenv/install.d/pip-and-virtualenv-source-install/04-install-pip'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/37dff9738afd245772cf029995476f29e68fb0f0', 'message': 'Fix opensuse 42.3 pip-and-virtualenv\n\nRelated to I041a141366099093805e6052b1bbf64efd277e1e, we also need to\nremove this on opensuse.  The files for gate testing are added, but\nthe test is not added to any jobs at this point in the interests of\ngate time.\n\nChange-Id: I1af9e84d76bedcb2607717edc6d2abe2920b0584\n'}]",2,638594,37dff9738afd245772cf029995476f29e68fb0f0,23,4,6,7118,,,0,"Fix opensuse 42.3 pip-and-virtualenv

Related to I041a141366099093805e6052b1bbf64efd277e1e, we also need to
remove this on opensuse.  The files for gate testing are added, but
the test is not added to any jobs at this point in the interests of
gate time.

Change-Id: I1af9e84d76bedcb2607717edc6d2abe2920b0584
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/94/638594/6 && git format-patch -1 --stdout FETCH_HEAD,"['diskimage_builder/elements/pip-and-virtualenv/test-elements/source-install-opensuse/element-deps', 'diskimage_builder/elements/pip-and-virtualenv/test-elements/source-install-opensuse/environment.d/10-source-installtype-pip-and-virtualenv', '.zuul.d/jobs.yaml', 'diskimage_builder/elements/pip-and-virtualenv/install.d/pip-and-virtualenv-source-install/04-install-pip']",4,0d98324b66cae23b7fe00ff8a0569a8c459e14bc,opensuse-pip-and-virtualenv," # see notes below on this var... _clear_old_files=0 # see notes below _clear_old_files=1 _clear_old_files=1 # This is only necessary on old CentOS and suse -- for complicated # reasons of course. On Fedora, the Python2 virtualenv packages # are *not* distutils based and pip overwrites them correctly. # For python3, pip has changed to not overwrite system packages (a # long standing difference between Debuntu and Fedora), but a # number of tools run with ""python3 -Es"" to isolate themselves to # the package installed versions. So we definitely don't want to if [[ ${_clear_old_files} == 1 ]]; then"," # This is only necessary on CentOS -- for complicated reasons of # course. On Fedora, the Python2 virtualenv packages are *not* # distutils based and pip overwrites them correctly. For python3, # pip has changed to not overwrite system packages (a long # standing difference between Debuntu and Fedora), but a number of # tools run with ""python3 -Es"" to isolate themselves to the # package installed versions. So we definitely don't want to if [[ $DISTRO_NAME =~ (centos|centos7|rhel7) ]]; then",17,8
openstack%2Fvitrage-tempest-plugin~master~I2f453718ff5aeb688ecae48b7b9e409b614da7c2,openstack/vitrage-tempest-plugin,master,I2f453718ff5aeb688ecae48b7b9e409b614da7c2,Fix typo in .stestr.conf,MERGED,2019-02-21 06:24:07.000000000,2019-02-25 07:20:54.000000000,2019-02-25 07:20:54.000000000,"[{'_account_id': 5689}, {'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 06:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/6b8e125c76bdced802cd4b1aa0fb4461864253c7', 'message': 'Fix typo and add vitrage to requirements.txt\n\nThis commit fixes a typo in .stestr.conf and adds vitrage entry into\nrequirements.txt to resolve the dependency.\n\nChange-Id: I2f453718ff5aeb688ecae48b7b9e409b614da7c2\n'}, {'number': 2, 'created': '2019-02-25 01:34:52.000000000', 'files': ['.stestr.conf'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/0e1be3da5c38305bb9f752b0e786afb168a69340', 'message': 'Fix typo in .stestr.conf\n\nThis commit fixes a typo in .stestr.conf.\n\nChange-Id: I2f453718ff5aeb688ecae48b7b9e409b614da7c2\n'}]",2,638343,0e1be3da5c38305bb9f752b0e786afb168a69340,16,4,2,5689,,,0,"Fix typo in .stestr.conf

This commit fixes a typo in .stestr.conf.

Change-Id: I2f453718ff5aeb688ecae48b7b9e409b614da7c2
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/43/638343/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', '.stestr.conf']",2,6b8e125c76bdced802cd4b1aa0fb4461864253c7,tempest-sanity-gate,test_path=./vitrage_tempest_plugin/tests,test_path=./virtage_tempest_plugin/tests,2,1
openstack%2Foctavia~master~Ic832fcd2a5a45993f8414b7514b1a58dcec13de3,openstack/octavia,master,Ic832fcd2a5a45993f8414b7514b1a58dcec13de3,Fix the loss of access to barbican secrets,MERGED,2019-02-18 22:51:35.000000000,2019-02-25 07:08:33.000000000,2019-02-25 06:22:43.000000000,"[{'_account_id': 2245}, {'_account_id': 6469}, {'_account_id': 6579}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-18 22:51:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d6b2a5d3c81f00e2f6e5040967f45ee396399d15', 'message': 'Fix the lose of access to barbican secrets\n\nThe listener delete method could remove access to barbican secrets that\nare used on multiple listeners, in different roles.\nIt is also not thread safe and was un-tested.\nThis patch removes the ""unset_acls"" calls from the listener delete method.\n\nChange-Id: Ic832fcd2a5a45993f8414b7514b1a58dcec13de3\nStory: 2005041\nTask: 29536\n'}, {'number': 2, 'created': '2019-02-18 23:03:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/1aecbe565020744c89660bedb498751912faabe5', 'message': 'Fix the loss of access to barbican secrets\n\nThe listener delete method could remove access to barbican secrets that\nare used on multiple listeners, in different roles.\nIt is also not thread safe and was un-tested.\nThis patch removes the ""unset_acls"" calls from the listener delete method.\n\nChange-Id: Ic832fcd2a5a45993f8414b7514b1a58dcec13de3\nStory: 2005041\nTask: 29536\n'}, {'number': 3, 'created': '2019-02-24 18:57:47.000000000', 'files': ['releasenotes/notes/remove-bbq-unset-acl-e680020de6a9ad3d.yaml', 'octavia/api/v2/controllers/listener.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/72b382b46d3b90f8a50c55ce4f352272116f10fd', 'message': 'Fix the loss of access to barbican secrets\n\nThe listener delete method could remove access to barbican secrets that\nare used on multiple listeners, in different roles.\nIt is also not thread safe and was un-tested.\nThis patch removes the ""unset_acls"" calls from the listener delete method.\n\nChange-Id: Ic832fcd2a5a45993f8414b7514b1a58dcec13de3\nStory: 2005041\nTask: 29536\n'}]",0,637646,72b382b46d3b90f8a50c55ce4f352272116f10fd,21,5,3,11628,,,0,"Fix the loss of access to barbican secrets

The listener delete method could remove access to barbican secrets that
are used on multiple listeners, in different roles.
It is also not thread safe and was un-tested.
This patch removes the ""unset_acls"" calls from the listener delete method.

Change-Id: Ic832fcd2a5a45993f8414b7514b1a58dcec13de3
Story: 2005041
Task: 29536
",git fetch https://review.opendev.org/openstack/octavia refs/changes/46/637646/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia/api/v2/controllers/listener.py'],1,d6b2a5d3c81f00e2f6e5040967f45ee396399d15,,," # Revoke access of octavia service user to certificates tls_refs = [] for sni in db_listener.sni_containers: filters = {'tls_container_id': sni.tls_container_id} snis = self.repositories.sni.get_all(context.session, **filters)[0] if len(snis) == 1: # referred only once, enqueue for access revoking tls_refs.append(sni.tls_container_id) else: blocking_listeners = [s.listener_id for s in snis if s.listener_id != id] LOG.debug(""Listeners %s using TLS ref %s. Access to TLS ref "" ""will not be revoked."", blocking_listeners, sni.tls_container_id) if db_listener.tls_certificate_id: filters = {'tls_certificate_id': db_listener.tls_certificate_id} # Note get_all returns the list and links. We only want the list. listeners = self.repositories.listener.get_all( context.session, show_deleted=False, **filters)[0] if len(listeners) == 1: # referred only once, enqueue for access revoking tls_refs.append(db_listener.tls_certificate_id) else: blocking_listeners = [l.id for l in listeners if l.id != id] LOG.debug(""Listeners %s using TLS ref %s. Access to TLS ref "" ""will not be revoked."", blocking_listeners, db_listener.tls_certificate_id) for ref in tls_refs: try: self.cert_manager.unset_acls(context, ref) except Exception: # certificate may have been removed already pass ",0,39
openstack%2Ftripleo-heat-templates~master~If51e30854fc7ec27b3d12ccda0595ac0ff4b1e20,openstack/tripleo-heat-templates,master,If51e30854fc7ec27b3d12ccda0595ac0ff4b1e20,Podman support in haproxy-public-tls-inject,MERGED,2019-02-20 19:46:00.000000000,2019-02-25 07:06:05.000000000,2019-02-22 05:08:03.000000000,"[{'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-20 19:46:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/07e209910a5ae0aa6d16719c1d73b1560f97ff89', 'message': 'Podman support in haproxy-public-tls-inject\n\nFix a few Ansible tasks where only Docker were supported.\n\nChange-Id: If51e30854fc7ec27b3d12ccda0595ac0ff4b1e20\n'}, {'number': 2, 'created': '2019-02-21 12:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9c8b7770c6edb8ee551294f0bbee6922c82983d0', 'message': 'Podman support in haproxy-public-tls-inject\n\nFix a few Ansible tasks where only Docker were supported.\n\nChange-Id: If51e30854fc7ec27b3d12ccda0595ac0ff4b1e20\n'}, {'number': 3, 'created': '2019-02-21 12:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3ee27557ac2d282c5bc4d8cce15a5abc0f459e84', 'message': 'Podman support in haproxy-public-tls-inject\n\nFix a few Ansible tasks where only Docker were supported.\n\nChange-Id: If51e30854fc7ec27b3d12ccda0595ac0ff4b1e20\n'}, {'number': 4, 'created': '2019-02-21 16:43:58.000000000', 'files': ['deployment/haproxy/haproxy-public-tls-inject.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dbf63314d52c8bfbaccf9543f28ee22942ce7ed0', 'message': 'Podman support in haproxy-public-tls-inject\n\nFix a few Ansible tasks where only Docker were supported.\n\nChange-Id: If51e30854fc7ec27b3d12ccda0595ac0ff4b1e20\n'}]",3,638246,dbf63314d52c8bfbaccf9543f28ee22942ce7ed0,21,5,4,3153,,,0,"Podman support in haproxy-public-tls-inject

Fix a few Ansible tasks where only Docker were supported.

Change-Id: If51e30854fc7ec27b3d12ccda0595ac0ff4b1e20
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/46/638246/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/haproxy/haproxy-public-tls-inject.yaml'],1,07e209910a5ae0aa6d16719c1d73b1560f97ff89,podman/tls, - docker_state.status.ActiveState == 'active' or container_cli == 'podman command: {{{ container_cli }} ps -q -f name=haproxy command: {{ container_cli }} kill --signal=HUP {{container_id.stdout}}, - docker_state.status.ActiveState == 'active' command: docker ps -q -f name=haproxy command: docker kill --signal=HUP {{container_id.stdout}},3,3
openstack%2Frpm-packaging~master~I5129260b79c9af4682f90ee7c92a831470312af2,openstack/rpm-packaging,master,I5129260b79c9af4682f90ee7c92a831470312af2,Add pypi_source macro to RDO for compatibility with Fedora,MERGED,2019-02-21 13:35:38.000000000,2019-02-25 07:01:24.000000000,2019-02-25 07:01:24.000000000,"[{'_account_id': 1955}, {'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 10384}, {'_account_id': 13294}, {'_account_id': 13861}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-21 13:35:38.000000000', 'files': ['openstack/openstack-macros/macros.openstack-rdo', 'openstack/openstack-macros/openstack-macros.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/27ebbfe3385265a0e854e4ba268990b3572c3d74', 'message': ""Add pypi_source macro to RDO for compatibility with Fedora\n\nIn RDO, we use fedora specs to rebuild dependencies. Some deps are\nfailing because of missing pypi_source in CentOS7 so let's add it to\nopenstack-macros in RDO.\n\nChange-Id: I5129260b79c9af4682f90ee7c92a831470312af2\n""}]",1,638420,27ebbfe3385265a0e854e4ba268990b3572c3d74,14,10,1,16312,,,0,"Add pypi_source macro to RDO for compatibility with Fedora

In RDO, we use fedora specs to rebuild dependencies. Some deps are
failing because of missing pypi_source in CentOS7 so let's add it to
openstack-macros in RDO.

Change-Id: I5129260b79c9af4682f90ee7c92a831470312af2
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/20/638420/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/openstack-macros/macros.openstack-rdo', 'openstack/openstack-macros/openstack-macros.spec.j2']",2,27ebbfe3385265a0e854e4ba268990b3572c3d74,,Version: 2019.1.1,Version: 2018.2.7,49,2
openstack%2Fvitrage-tempest-plugin~master~I67706bc233e977915c0bb870499a7df4c8b56837,openstack/vitrage-tempest-plugin,master,I67706bc233e977915c0bb870499a7df4c8b56837,Use register_opt() instead of config.register_opt_group(),ABANDONED,2019-02-25 03:58:01.000000000,2019-02-25 06:33:29.000000000,,"[{'_account_id': 5689}, {'_account_id': 13861}, {'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-25 03:58:01.000000000', 'files': ['vitrage_tempest_plugin/config.py', 'vitrage_tempest_plugin/plugin.py'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/f4154fa33c1cc2d2a1c5bb64c0ae5350f98b8d61', 'message': ""Use register_opt() instead of config.register_opt_group()\n\nThis commit is trying to fix an error when we execute `tempest init`\nwith this tempest plugin. The (weird) error occurs in tempest like\nthis::\n\n  'list' object has no attribute 'dest': AttributeError: 'list' object\n  has no attribute 'dest'\n\nTempest (or the other dependent libraries) should be able to print more\nunderstandable error messages. However, I think this change can resolve\nthis error anyway.\n\nChange-Id: I67706bc233e977915c0bb870499a7df4c8b56837\n""}]",0,639003,f4154fa33c1cc2d2a1c5bb64c0ae5350f98b8d61,8,4,1,5689,,,0,"Use register_opt() instead of config.register_opt_group()

This commit is trying to fix an error when we execute `tempest init`
with this tempest plugin. The (weird) error occurs in tempest like
this::

  'list' object has no attribute 'dest': AttributeError: 'list' object
  has no attribute 'dest'

Tempest (or the other dependent libraries) should be able to print more
understandable error messages. However, I think this change can resolve
this error anyway.

Change-Id: I67706bc233e977915c0bb870499a7df4c8b56837
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/03/639003/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage_tempest_plugin/config.py', 'vitrage_tempest_plugin/plugin.py']",2,f4154fa33c1cc2d2a1c5bb64c0ae5350f98b8d61,tempest-sanity-gate," conf.register_opt(config_rca_service.ServiceAvailableGroup, group='service_available') config_rca_service.RcaServiceGroup)]"," config.register_opt_group(conf, config_rca_service.service_available_group, config_rca_service.ServiceAvailableGroup) config_rca_service.RcaServiceGroup), (config_rca_service.service_available_group.name, [config_rca_service.ServiceAvailableGroup])]",7,13
openstack%2Ftacker-horizon~master~I724265fca08600c4a7d60a6e67dbf86ffaa1f7ba,openstack/tacker-horizon,master,I724265fca08600c4a7d60a6e67dbf86ffaa1f7ba,update python version in setup.cfg,MERGED,2018-11-10 08:15:24.000000000,2019-02-25 06:21:39.000000000,2019-02-25 06:21:39.000000000,"[{'_account_id': 2874}, {'_account_id': 12455}, {'_account_id': 13380}, {'_account_id': 16511}, {'_account_id': 18955}, {'_account_id': 19644}, {'_account_id': 22348}, {'_account_id': 26222}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-11-10 08:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/e963169b6ba6905ea33397cbf2bb3c4e27d24d27', 'message': 'update python version in setup.cfg\n\nChange-Id: I724265fca08600c4a7d60a6e67dbf86ffaa1f7ba\n'}, {'number': 2, 'created': '2019-01-15 10:28:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/e3d45488b614db63b84f418ad394f360673b9d92', 'message': 'update python version in setup.cfg\n\nChange-Id: I724265fca08600c4a7d60a6e67dbf86ffaa1f7ba\n'}, {'number': 3, 'created': '2019-01-31 13:05:58.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/d5b2b3383b0e5daa5c4aba375eff6e39ea2334d0', 'message': 'update python version in setup.cfg\n\nChange-Id: I724265fca08600c4a7d60a6e67dbf86ffaa1f7ba\n'}]",1,617096,d5b2b3383b0e5daa5c4aba375eff6e39ea2334d0,14,9,3,27511,,,0,"update python version in setup.cfg

Change-Id: I724265fca08600c4a7d60a6e67dbf86ffaa1f7ba
",git fetch https://review.opendev.org/openstack/tacker-horizon refs/changes/96/617096/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,e963169b6ba6905ea33397cbf2bb3c4e27d24d27,1110_python_version, Programming Language :: Python :: 3 Programming Language :: Python :: 3.6,,2,0
openstack%2Ffreezer-api~stable%2Fqueens~I8d0be8221a649b49989cc68d89728c48fb52bdab,openstack/freezer-api,stable/queens,I8d0be8221a649b49989cc68d89728c48fb52bdab,when installing from pip python plugin is embedded in the binary,MERGED,2018-10-02 09:10:40.000000000,2019-02-25 06:21:31.000000000,2019-02-25 06:21:31.000000000,"[{'_account_id': 13940}, {'_account_id': 22348}, {'_account_id': 22484}, {'_account_id': 23735}, {'_account_id': 27068}]","[{'number': 1, 'created': '2018-10-02 09:10:40.000000000', 'files': ['devstack/lib/freezer-api'], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/d650977ebeace1498acb417d549f9e6e144fe42f', 'message': 'when installing from pip python plugin is embedded in the binary\n\nso plugin config is not required.\n\nChange-Id: I8d0be8221a649b49989cc68d89728c48fb52bdab\n'}]",0,607133,d650977ebeace1498acb417d549f9e6e144fe42f,15,5,1,23735,,,0,"when installing from pip python plugin is embedded in the binary

so plugin config is not required.

Change-Id: I8d0be8221a649b49989cc68d89728c48fb52bdab
",git fetch https://review.opendev.org/openstack/freezer-api refs/changes/33/607133/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/freezer-api'],1,d650977ebeace1498acb417d549f9e6e144fe42f,,, iniset $FREEZER_API_UWSGI_CONF 'uwsgi' plugins python,0,1
openstack%2Ftempest-stress~master~Ida40bf74452994160501bc7d40e13b9615abebb2,openstack/tempest-stress,master,Ida40bf74452994160501bc7d40e13b9615abebb2,add python 3.7 unit test job,MERGED,2019-02-19 09:06:01.000000000,2019-02-25 06:20:39.000000000,2019-02-25 06:20:39.000000000,"[{'_account_id': 8556}, {'_account_id': 9414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-19 09:06:01.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/tempest-stress/commit/74e784cb9c714924f8cf44d0835ef02764b6cb53', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: Ida40bf74452994160501bc7d40e13b9615abebb2\nStory: #2004073\nTask: #27445\n'}]",0,637748,74e784cb9c714924f8cf44d0835ef02764b6cb53,6,3,1,9414,,,0,"add python 3.7 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.7.

See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html

Change-Id: Ida40bf74452994160501bc7d40e13b9615abebb2
Story: #2004073
Task: #27445
",git fetch https://review.opendev.org/openstack/tempest-stress refs/changes/48/637748/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,74e784cb9c714924f8cf44d0835ef02764b6cb53,py37-job, - openstack-python37-jobs,,1,0
openstack%2Ftacker~master~Idd3da3a259517e1b8612b3c3c129a1f8616403bb,openstack/tacker,master,Idd3da3a259517e1b8612b3c3c129a1f8616403bb,Remove H903 error in source.,MERGED,2019-02-22 10:20:02.000000000,2019-02-25 06:13:17.000000000,2019-02-25 06:13:17.000000000,"[{'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 26222}]","[{'number': 1, 'created': '2019-02-22 10:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/b3eaae9fb91133eaba16d2ffa3453c376ff2eb9b', 'message': 'emove H903 error in sources.\nSome codes use Windows style line endings, this violates H903 error pep8.\nThis patch will convert dos to unix formate.\n\nChange-Id: Idd3da3a259517e1b8612b3c3c129a1f8616403bb\nCloses-Bug: #1817283\n'}, {'number': 2, 'created': '2019-02-22 10:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/40ffb53d18c8210c6fa34308661a9afaf483d350', 'message': 'emove H903 error in sources.\n\nSome codes use Windows style line endings, this violates H903 error pep8.\nThis patch will convert dos to unix formate.\n\nChange-Id: Idd3da3a259517e1b8612b3c3c129a1f8616403bb\nCloses-Bug: #1817283\n'}, {'number': 3, 'created': '2019-02-22 11:10:28.000000000', 'files': ['tacker/vnfm/policy_actions/vdu_autoheal/vdu_autoheal.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/675a3e913c75de548d00cc3eb6fb96d590757f96', 'message': 'Remove H903 error in source.\n\nSome codes use Windows style line endings, this violates H903 error pep8.\nThis patch will convert dos to unix formate.\n\nChange-Id: Idd3da3a259517e1b8612b3c3c129a1f8616403bb\nCloses-Bug: #1817283\n'}]",0,638620,675a3e913c75de548d00cc3eb6fb96d590757f96,9,3,3,18955,,,0,"Remove H903 error in source.

Some codes use Windows style line endings, this violates H903 error pep8.
This patch will convert dos to unix formate.

Change-Id: Idd3da3a259517e1b8612b3c3c129a1f8616403bb
Closes-Bug: #1817283
",git fetch https://review.opendev.org/openstack/tacker refs/changes/20/638620/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/vnfm/policy_actions/vdu_autoheal/vdu_autoheal.py'],1,b3eaae9fb91133eaba16d2ffa3453c376ff2eb9b,bug/1817283,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # from oslo_log import log as logging import yaml from tacker import objects from tacker.vnfm.policy_actions import abstract_action LOG = logging.getLogger(__name__) class VNFActionVduAutoheal(abstract_action.AbstractPolicyAction): def get_type(self): return 'vdu_autoheal' def get_name(self): return 'vdu_autoheal' def get_description(self): return 'Tacker VNF vdu_autoheal policy' def execute_action(self, plugin, context, vnf_dict, args): vdu_name = args.get('vdu_name') if vdu_name is None: LOG.error(""VDU resource of vnf '%s' is not present for "" ""autoheal."" % vnf_dict['id']) return def _get_vdu_resources(): """"""Get all the resources linked to the VDU. Returns: resource list for eg. ['VDU1', CP1] """""" resource_list = [vdu_name] heat_template = yaml.safe_load(vnf_dict['attributes'].get( 'heat_template')) vdu_resources = heat_template['resources'].get(vdu_name) cp_resources = vdu_resources['properties'].get('networks') for resource in cp_resources: resource_list.append(resource['port'].get('get_resource')) return resource_list resource_list = _get_vdu_resources() additional_params = [] for resource in resource_list: additional_paramas_obj = objects.HealVnfAdditionalParams( parameter=resource, cause=[""Unable to reach while monitoring resource: '%s'"" % resource]) additional_params.append(additional_paramas_obj) heal_request_data_obj = objects.HealVnfRequest( cause=(""Failed to monitor VDU resource '%s'"" % vdu_name), additional_params=additional_params) plugin.heal_vnf(context, vnf_dict['id'], heal_request_data_obj)","# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # from oslo_log import log as logging import yaml from tacker import objects from tacker.vnfm.policy_actions import abstract_action LOG = logging.getLogger(__name__) class VNFActionVduAutoheal(abstract_action.AbstractPolicyAction): def get_type(self): return 'vdu_autoheal' def get_name(self): return 'vdu_autoheal' def get_description(self): return 'Tacker VNF vdu_autoheal policy' def execute_action(self, plugin, context, vnf_dict, args): vdu_name = args.get('vdu_name') if vdu_name is None: LOG.error(""VDU resource of vnf '%s' is not present for "" ""autoheal."" % vnf_dict['id']) return def _get_vdu_resources(): """"""Get all the resources linked to the VDU. Returns: resource list for eg. ['VDU1', CP1] """""" resource_list = [vdu_name] heat_template = yaml.safe_load(vnf_dict['attributes'].get( 'heat_template')) vdu_resources = heat_template['resources'].get(vdu_name) cp_resources = vdu_resources['properties'].get('networks') for resource in cp_resources: resource_list.append(resource['port'].get('get_resource')) return resource_list resource_list = _get_vdu_resources() additional_params = [] for resource in resource_list: additional_paramas_obj = objects.HealVnfAdditionalParams( parameter=resource, cause=[""Unable to reach while monitoring resource: '%s'"" % resource]) additional_params.append(additional_paramas_obj) heal_request_data_obj = objects.HealVnfRequest( cause=(""Failed to monitor VDU resource '%s'"" % vdu_name), additional_params=additional_params) plugin.heal_vnf(context, vnf_dict['id'], heal_request_data_obj) ",70,70
openstack%2Fironic~master~I3b4f4faa205e50c1dccb76e21ac54b17342cd486,openstack/ironic,master,I3b4f4faa205e50c1dccb76e21ac54b17342cd486,Follow up to node description,MERGED,2019-02-18 07:49:03.000000000,2019-02-25 06:03:42.000000000,2019-02-25 06:03:42.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 28429}]","[{'number': 1, 'created': '2019-02-18 07:49:03.000000000', 'files': ['doc/source/contributor/webapi-version-history.rst', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/7a6a6bf69a6c3652859ab110c9fb70c270e45f5d', 'message': 'Follow up to node description\n\nThe patch fixes several comments left in the node description patch [1].\n\n[1] https://review.openstack.org/#/c/632673\n\nChange-Id: I3b4f4faa205e50c1dccb76e21ac54b17342cd486\nStory: 2003089\nTask: 23178\n'}]",0,637483,7a6a6bf69a6c3652859ab110c9fb70c270e45f5d,16,7,1,24828,,,0,"Follow up to node description

The patch fixes several comments left in the node description patch [1].

[1] https://review.openstack.org/#/c/632673

Change-Id: I3b4f4faa205e50c1dccb76e21ac54b17342cd486
Story: 2003089
Task: 23178
",git fetch https://review.opendev.org/openstack/ironic refs/changes/83/637483/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/webapi-version-history.rst', 'ironic/api/controllers/v1/node.py']",2,7a6a6bf69a6c3652859ab110c9fb70c270e45f5d,2003089," msg = _(""Cannot create node with description exceeding %s "" msg = _(""Cannot update node with description exceeding %s """," msg = _(""Cannot create node with description exceeds %s "" msg = _(""Cannot create node with description exceeds %s """,3,3
openstack%2Fos-performance-tools~master~I953df9780fdc6a025d1086c42286e5235e0dc56e,openstack/os-performance-tools,master,I953df9780fdc6a025d1086c42286e5235e0dc56e,Update home-page,MERGED,2019-01-11 17:09:15.000000000,2019-02-25 05:36:24.000000000,2019-02-25 05:36:24.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 27078}, {'_account_id': 28543}, {'_account_id': 28614}]","[{'number': 1, 'created': '2019-01-11 17:09:15.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/os-performance-tools/commit/f178a1edc2665b609e2d57f9e6c838130c0b6365', 'message': 'Update home-page\n\nChange-Id: I953df9780fdc6a025d1086c42286e5235e0dc56e\n'}]",0,630342,f178a1edc2665b609e2d57f9e6c838130c0b6365,10,6,1,26297,,,0,"Update home-page

Change-Id: I953df9780fdc6a025d1086c42286e5235e0dc56e
",git fetch https://review.opendev.org/openstack/os-performance-tools refs/changes/42/630342/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,f178a1edc2665b609e2d57f9e6c838130c0b6365,,home-page = https://docs.openstack.org/os-performance-tools/latest/,home-page = http://www.openstack.org/,1,1
openstack%2Freleases~master~I025c029469e3fae85485b87351da9ec487ff5c89,openstack/releases,master,I025c029469e3fae85485b87351da9ec487ff5c89,Add Cycle-Highlights to process.rst,MERGED,2019-02-11 22:36:32.000000000,2019-02-25 05:30:28.000000000,2019-02-25 05:30:28.000000000,"[{'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 16708}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 22:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/2206bf7d8a12a83e642f942a655085f916748847', 'message': 'Add Cycle-Highlights to process.rst\n\nCycle highlights are now a regular part of a release and should\nbe included in the process document so we can promote and\ncollect them in a routine manner.\n\nChange-Id: I025c029469e3fae85485b87351da9ec487ff5c89\n'}, {'number': 2, 'created': '2019-02-13 22:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/c006a64c7d95330b0d85be3bb83aa6c28c3a613b', 'message': 'Add Cycle-Highlights to process.rst\n\nCycle highlights are now a regular part of a release and should\nbe included in the process document so we can promote and\ncollect them in a routine manner.\n\nChange-Id: I025c029469e3fae85485b87351da9ec487ff5c89\n'}, {'number': 3, 'created': '2019-02-14 17:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/bed468133012e919b544075d8792855d1e6ceafa', 'message': 'Add Cycle-Highlights to process.rst\n\nCycle highlights are now a regular part of a release and should\nbe included in the process document so we can promote and\ncollect them in a routine manner.\n\nChange-Id: I025c029469e3fae85485b87351da9ec487ff5c89\n'}, {'number': 4, 'created': '2019-02-14 17:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/0c9de29573f178a2bd6fa8ff88650b95189fd7b7', 'message': 'Add Cycle-Highlights to process.rst\n\nCycle highlights are now a regular part of a release and should\nbe included in the process document so we can promote and\ncollect them in a routine manner.\n\nChange-Id: I025c029469e3fae85485b87351da9ec487ff5c89\n'}, {'number': 5, 'created': '2019-02-14 17:43:45.000000000', 'files': ['doc/source/reference/process.rst'], 'web_link': 'https://opendev.org/openstack/releases/commit/e0731009633bd2c52f885eb79de9302a74d33bd9', 'message': 'Add Cycle-Highlights to process.rst\n\nCycle highlights are now a regular part of a release and should\nbe included in the process document so we can promote and\ncollect them in a routine manner.\n\nChange-Id: I025c029469e3fae85485b87351da9ec487ff5c89\n'}]",7,636231,e0731009633bd2c52f885eb79de9302a74d33bd9,21,7,5,16708,,,0,"Add Cycle-Highlights to process.rst

Cycle highlights are now a regular part of a release and should
be included in the process document so we can promote and
collect them in a routine manner.

Change-Id: I025c029469e3fae85485b87351da9ec487ff5c89
",git fetch https://review.opendev.org/openstack/releases refs/changes/31/636231/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/process.rst'],1,2206bf7d8a12a83e642f942a655085f916748847,cycle_highlights_PROCESS, #. Email openstack-discuss to give PTL's a heads up to start thinking about what they might want to include in their deliverables file as cycle-highlights and that RC1 is the deadline for them. 7. Email a countdown to openstack-discuss to remind PTLs of the RC1 deadline for cycle highlights. 10. Email openstack-discuss list to remind PTLs that cycle-highlights are due this week so that they can be included in release marketing preparations. ,,10,1
openstack%2Foslo.service~master~I6b72272dcc524ebab30324446fdeaeb742eddc81,openstack/oslo.service,master,I6b72272dcc524ebab30324446fdeaeb742eddc81,Update oslo.service to require yappi 1.0 or newer,MERGED,2019-02-21 19:23:13.000000000,2019-02-25 05:27:43.000000000,2019-02-25 05:27:43.000000000,"[{'_account_id': 6928}, {'_account_id': 9796}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 19:23:13.000000000', 'files': ['requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/ca6f839fc49e8e57995d4e107ee3f428f9baa1e3', 'message': 'Update oslo.service to require yappi 1.0 or newer\n\nThe versions of yappi less than 1.0 have a bug[1] that causes it\nto fail to install[2].\nThis patch makes sure oslo.service uses version 1.0 of yappi that\ncontains the fix.\n\n[1] https://github.com/sumerc/yappi/commit/ \\\n    778829f6f77928e4292e6a7dd4dfecf501f9a362\n[2] http://logs.openstack.org/29/637929/2/check/octavia-v2-dsvm-scenario \\\n    4113e77/controller/logs/dib-build/amphora-x64-haproxy.qcow2_log.txt.gz \\\n    #_2019-02-19_17_23_37_112\n\nChange-Id: I6b72272dcc524ebab30324446fdeaeb742eddc81\n'}]",1,638489,ca6f839fc49e8e57995d4e107ee3f428f9baa1e3,8,4,1,11628,,,0,"Update oslo.service to require yappi 1.0 or newer

The versions of yappi less than 1.0 have a bug[1] that causes it
to fail to install[2].
This patch makes sure oslo.service uses version 1.0 of yappi that
contains the fix.

[1] https://github.com/sumerc/yappi/commit/ \
    778829f6f77928e4292e6a7dd4dfecf501f9a362
[2] http://logs.openstack.org/29/637929/2/check/octavia-v2-dsvm-scenario \
    4113e77/controller/logs/dib-build/amphora-x64-haproxy.qcow2_log.txt.gz \
    #_2019-02-19_17_23_37_112

Change-Id: I6b72272dcc524ebab30324446fdeaeb742eddc81
",git fetch https://review.opendev.org/openstack/oslo.service refs/changes/89/638489/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt']",2,ca6f839fc49e8e57995d4e107ee3f428f9baa1e3,,Yappi==1.0,Yappi==0.98,2,2
openstack%2Fproject-config~master~I65f6f601a47dd33e5205ac3530c47a5a58deb5b8,openstack/project-config,master,I65f6f601a47dd33e5205ac3530c47a5a58deb5b8,DIB grafana dashboard small fixes,MERGED,2019-02-25 04:44:35.000000000,2019-02-25 05:18:03.000000000,2019-02-25 05:18:03.000000000,"[{'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-25 04:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5f657bc2869f7c307bca771d6b0b83abacf2e71d', 'message': 'DIB grafana dashboard small fixes\n\nAlias the legend for the build size\n\nA more useful view is -7 days, rather than last week, which starts\nfresh each week.\n\nChange-Id: I65f6f601a47dd33e5205ac3530c47a5a58deb5b8\n'}, {'number': 2, 'created': '2019-02-25 04:59:02.000000000', 'files': ['grafana/nodepool-dib.image.template', 'grafana/nodepool-dib.base.template', 'grafana/nodepool-dib.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/81071e975d1072372ad4ae82da551619a54e4ef2', 'message': 'DIB grafana dashboard small fixes\n\nAlias the legend for the build size\n\nA more useful view is -7 days, rather than last week, which starts\nfresh each week.\n\nChange-Id: I65f6f601a47dd33e5205ac3530c47a5a58deb5b8\n'}]",0,639007,81071e975d1072372ad4ae82da551619a54e4ef2,8,2,2,7118,,,0,"DIB grafana dashboard small fixes

Alias the legend for the build size

A more useful view is -7 days, rather than last week, which starts
fresh each week.

Change-Id: I65f6f601a47dd33e5205ac3530c47a5a58deb5b8
",git fetch https://review.opendev.org/openstack/project-config refs/changes/07/639007/2 && git format-patch -1 --stdout FETCH_HEAD,"['grafana/nodepool-dib.image.template', 'grafana/nodepool-dib.base.template', 'grafana/nodepool-dib.yaml']",3,5f657bc2869f7c307bca771d6b0b83abacf2e71d,dib-grafana-update," from: ""now-7d"" to: ""now"" - target: aliasByNode(stats.gauges.nodepool.dib_image_build.ubuntu-bionic.*.size, 7) - target: aliasByNode(stats.gauges.nodepool.dib_image_build.ubuntu-xenial.*.size, 7) - target: aliasByNode(stats.gauges.nodepool.dib_image_build.ubuntu-trusty.*.size, 7) - target: aliasByNode(stats.gauges.nodepool.dib_image_build.centos-7.*.size, 7) - target: aliasByNode(stats.gauges.nodepool.dib_image_build.fedora-29.*.size, 7) - target: aliasByNode(stats.gauges.nodepool.dib_image_build.debian-stretch.*.size, 7) - target: aliasByNode(stats.gauges.nodepool.dib_image_build.gentoo-17-0-systemd.*.size, 7) - target: aliasByNode(stats.gauges.nodepool.dib_image_build.opensuse-150.*.size, 7) - target: aliasByNode(stats.gauges.nodepool.dib_image_build.opensuse-423.*.size, 7) - target: aliasByNode(stats.gauges.nodepool.dib_image_build.ubuntu-bionic-arm64.*.size, 7) - target: aliasByNode(stats.gauges.nodepool.dib_image_build.ubuntu-xenial-arm64.*.size, 7)"," from: ""now/w"" to: ""now/w"" - target: alias(stats.gauges.nodepool.dib_image_build.ubuntu-bionic.*.size, ""Size"") - target: alias(stats.gauges.nodepool.dib_image_build.ubuntu-xenial.*.size, ""Size"") - target: alias(stats.gauges.nodepool.dib_image_build.ubuntu-trusty.*.size, ""Size"") - target: alias(stats.gauges.nodepool.dib_image_build.centos-7.*.size, ""Size"") - target: alias(stats.gauges.nodepool.dib_image_build.fedora-29.*.size, ""Size"") - target: alias(stats.gauges.nodepool.dib_image_build.debian-stretch.*.size, ""Size"") - target: alias(stats.gauges.nodepool.dib_image_build.gentoo-17-0-systemd.*.size, ""Size"") - target: alias(stats.gauges.nodepool.dib_image_build.opensuse-150.*.size, ""Size"") - target: alias(stats.gauges.nodepool.dib_image_build.opensuse-423.*.size, ""Size"") - target: alias(stats.gauges.nodepool.dib_image_build.ubuntu-bionic-arm64.*.size, ""Size"") - target: alias(stats.gauges.nodepool.dib_image_build.ubuntu-xenial-arm64.*.size, ""Size"")",16,16
openstack%2Fpython-ironicclient~master~Ic3c46901e3d461b0469188ba9fe179e6030dfb37,openstack/python-ironicclient,master,Ic3c46901e3d461b0469188ba9fe179e6030dfb37,[Trivial] Allocation API: fix incorrect parameter description,MERGED,2019-02-22 16:26:39.000000000,2019-02-25 04:32:14.000000000,2019-02-25 04:32:14.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-02-22 16:26:39.000000000', 'files': ['ironicclient/osc/v1/baremetal_allocation.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/fdba8ed994bcbf1b3fc82803ccec49faf505b081', 'message': '[Trivial] Allocation API: fix incorrect parameter description\n\nChange-Id: Ic3c46901e3d461b0469188ba9fe179e6030dfb37\nStory: #2004341\n'}]",0,638702,fdba8ed994bcbf1b3fc82803ccec49faf505b081,8,3,1,10239,,,0,"[Trivial] Allocation API: fix incorrect parameter description

Change-Id: Ic3c46901e3d461b0469188ba9fe179e6030dfb37
Story: #2004341
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/02/638702/1 && git format-patch -1 --stdout FETCH_HEAD,['ironicclient/osc/v1/baremetal_allocation.py'],1,fdba8ed994bcbf1b3fc82803ccec49faf505b081,story/2004341," help=_('Allocation UUID (for example, of the last allocation in '"," help=_('Port group UUID (for example, of the last allocation in '",1,1
openstack%2Fnova~stable%2Fqueens~I57e6285475a31af49a3791c00d5d61deb64438bc,openstack/nova,stable/queens,I57e6285475a31af49a3791c00d5d61deb64438bc,Remove unnecessary redirect,ABANDONED,2018-10-02 23:54:01.000000000,2019-02-25 04:29:43.000000000,,"[{'_account_id': 6873}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-10-02 23:54:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe320e3907289687527689be54b9fd43c0463597', 'message': 'Remove unnecessary redirect\n\nThe cli/nova-idmapshift.html has been removed\nsince Ibce28d20d166da154833376cf51f1877b829925e.\n\nRemove the redirect to cli/nova-idmapshift.html\nbecause it is useless currently.\n\nChange-Id: I57e6285475a31af49a3791c00d5d61deb64438bc\n(cherry picked from commit aaa7d7c10979a96cbff7a0515ab9091f4db1fb1f)\n'}, {'number': 3, 'created': '2018-10-02 23:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f12156d56d6fc21f175102925df964179e89c71', 'message': 'Remove unnecessary redirect\n\nThe cli/nova-idmapshift.html has been removed\nsince Ibce28d20d166da154833376cf51f1877b829925e.\n\nRemove the redirect to cli/nova-idmapshift.html\nbecause it is useless currently.\n\nChange-Id: I57e6285475a31af49a3791c00d5d61deb64438bc\n(cherry picked from commit aaa7d7c10979a96cbff7a0515ab9091f4db1fb1f)\n(cherry picked from commit 25158da6cfa65d9472da1c4585fd4507b7a3c5a4)\n'}, {'number': 4, 'created': '2018-10-15 02:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/35afe706855aa0e53fc07b85047f58a1f1fd4777', 'message': 'Remove unnecessary redirect\n\nThe cli/nova-idmapshift.html has been removed\nsince Ibce28d20d166da154833376cf51f1877b829925e.\n\nRemove the redirect to cli/nova-idmapshift.html\nbecause it is useless currently.\n\nChange-Id: I57e6285475a31af49a3791c00d5d61deb64438bc\n(cherry picked from commit aaa7d7c10979a96cbff7a0515ab9091f4db1fb1f)\n(cherry picked from commit 25158da6cfa65d9472da1c4585fd4507b7a3c5a4)\n'}, {'number': 5, 'created': '2018-10-22 13:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3e186bc1e071f099ea8374b535e10d41f80cb53', 'message': 'Remove unnecessary redirect\n\nThe cli/nova-idmapshift.html has been removed\nsince Ibce28d20d166da154833376cf51f1877b829925e.\n\nRemove the redirect to cli/nova-idmapshift.html\nbecause it is useless currently.\n\nChange-Id: I57e6285475a31af49a3791c00d5d61deb64438bc\n(cherry picked from commit aaa7d7c10979a96cbff7a0515ab9091f4db1fb1f)\n(cherry picked from commit 25158da6cfa65d9472da1c4585fd4507b7a3c5a4)\n'}, {'number': 6, 'created': '2018-12-04 07:57:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0af61af56f41282f7c060c24cb27ed5c358cd4aa', 'message': 'Remove unnecessary redirect\n\nThe cli/nova-idmapshift.html has been removed\nsince Ibce28d20d166da154833376cf51f1877b829925e.\n\nRemove the redirect to cli/nova-idmapshift.html\nbecause it is useless currently.\n\nChange-Id: I57e6285475a31af49a3791c00d5d61deb64438bc\n(cherry picked from commit aaa7d7c10979a96cbff7a0515ab9091f4db1fb1f)\n(cherry picked from commit 25158da6cfa65d9472da1c4585fd4507b7a3c5a4)\n'}, {'number': 7, 'created': '2018-12-25 02:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8be8ea9b29918d206022c9bdaca11e5fabdc7eb2', 'message': 'Remove unnecessary redirect\n\nThe cli/nova-idmapshift.html has been removed\nsince Ibce28d20d166da154833376cf51f1877b829925e.\n\nRemove the redirect to cli/nova-idmapshift.html\nbecause it is useless currently.\n\nChange-Id: I57e6285475a31af49a3791c00d5d61deb64438bc\n(cherry picked from commit aaa7d7c10979a96cbff7a0515ab9091f4db1fb1f)\n(cherry picked from commit 25158da6cfa65d9472da1c4585fd4507b7a3c5a4)\n'}, {'number': 8, 'created': '2019-02-03 03:29:54.000000000', 'files': ['doc/test/redirect-tests.txt', 'doc/source/_extra/.htaccess'], 'web_link': 'https://opendev.org/openstack/nova/commit/27591e67d73b7e63f1fd58fb88ec6c139e89bd4f', 'message': 'Remove unnecessary redirect\n\nThe cli/nova-idmapshift.html has been removed\nsince Ibce28d20d166da154833376cf51f1877b829925e.\n\nRemove the redirect to cli/nova-idmapshift.html\nbecause it is useless currently.\n\nChange-Id: I57e6285475a31af49a3791c00d5d61deb64438bc\n(cherry picked from commit aaa7d7c10979a96cbff7a0515ab9091f4db1fb1f)\n(cherry picked from commit 25158da6cfa65d9472da1c4585fd4507b7a3c5a4)\n'}]",0,607402,27591e67d73b7e63f1fd58fb88ec6c139e89bd4f,28,4,7,7634,,,0,"Remove unnecessary redirect

The cli/nova-idmapshift.html has been removed
since Ibce28d20d166da154833376cf51f1877b829925e.

Remove the redirect to cli/nova-idmapshift.html
because it is useless currently.

Change-Id: I57e6285475a31af49a3791c00d5d61deb64438bc
(cherry picked from commit aaa7d7c10979a96cbff7a0515ab9091f4db1fb1f)
(cherry picked from commit 25158da6cfa65d9472da1c4585fd4507b7a3c5a4)
",git fetch https://review.opendev.org/openstack/nova refs/changes/02/607402/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/test/redirect-tests.txt', 'doc/source/_extra/.htaccess']",2,fe320e3907289687527689be54b9fd43c0463597,remove_unnecessary_redirect,,redirectmatch 301 ^/nova/([^/]+)/man/nova-idmapshift.html$ /nova/$1/cli/nova-idmapshift.html,0,2
openstack%2Foctavia-tempest-plugin~master~I008204d5000c9a2fb4852021f0c759a2490c69b7,openstack/octavia-tempest-plugin,master,I008204d5000c9a2fb4852021f0c759a2490c69b7,Add listener stats service client and API test,MERGED,2019-01-24 21:24:33.000000000,2019-02-25 03:59:16.000000000,2019-02-25 03:59:16.000000000,"[{'_account_id': 2245}, {'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-24 21:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/ddf423e1861b0a0cf5a6fe39d7f3be2d9a7475dc', 'message': 'Add listner stats service client and API test\n\nThis patch adds the listener stats service client and tempest API test.\n\nChange-Id: I008204d5000c9a2fb4852021f0c759a2490c69b7\nStory: 2004853\nTask: 29079\n'}, {'number': 2, 'created': '2019-01-24 22:04:41.000000000', 'files': ['releasenotes/notes/add-listener-stats-api-test-88947cf5e6ae9cae.yaml', 'octavia_tempest_plugin/services/load_balancer/v2/listener_client.py', 'octavia_tempest_plugin/tests/api/v2/test_listener.py'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/69cb566d5acb29c004c4bddae5af98331d1c2eb3', 'message': 'Add listener stats service client and API test\n\nThis patch adds the listener stats service client and tempest API test.\n\nChange-Id: I008204d5000c9a2fb4852021f0c759a2490c69b7\nStory: 2004853\nTask: 29079\n'}]",0,633065,69cb566d5acb29c004c4bddae5af98331d1c2eb3,12,4,2,11628,,,0,"Add listener stats service client and API test

This patch adds the listener stats service client and tempest API test.

Change-Id: I008204d5000c9a2fb4852021f0c759a2490c69b7
Story: 2004853
Task: 29079
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/65/633065/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/add-listener-stats-api-test-88947cf5e6ae9cae.yaml', 'octavia_tempest_plugin/services/load_balancer/v2/listener_client.py', 'octavia_tempest_plugin/tests/api/v2/test_listener.py']",3,ddf423e1861b0a0cf5a6fe39d7f3be2d9a7475dc,," @decorators.idempotent_id('6f14a6c1-945e-43bc-8215-410c8a5edb25') def test_listener_show_stats(self): """"""Tests listener show statistics API. * Create a listener. * Validates that other accounts cannot see the stats for the * listener. * Show listener statistics. * Validate the show reflects the expected values. """""" listener_name = data_utils.rand_name(""lb_member_listener1-stats"") listener_description = data_utils.arbitrary_string(size=255) listener_kwargs = { const.NAME: listener_name, const.DESCRIPTION: listener_description, const.ADMIN_STATE_UP: True, const.PROTOCOL: const.HTTP, const.PROTOCOL_PORT: 81, const.LOADBALANCER_ID: self.lb_id, const.CONNECTION_LIMIT: 200, } listener = self.mem_listener_client.create_listener(**listener_kwargs) self.addCleanup( self.mem_listener_client.cleanup_listener, listener[const.ID], lb_client=self.mem_lb_client, lb_id=self.lb_id) waiters.wait_for_status( self.mem_lb_client.show_loadbalancer, self.lb_id, const.PROVISIONING_STATUS, const.ACTIVE, CONF.load_balancer.build_interval, CONF.load_balancer.build_timeout) listener = waiters.wait_for_status( self.mem_listener_client.show_listener, listener[const.ID], const.PROVISIONING_STATUS, const.ACTIVE, CONF.load_balancer.build_interval, CONF.load_balancer.build_timeout) if not CONF.load_balancer.test_with_noop: listener = waiters.wait_for_status( self.mem_listener_client.show_listener, listener[const.ID], const.OPERATING_STATUS, const.ONLINE, CONF.load_balancer.build_interval, CONF.load_balancer.build_timeout) # Test that a user, without the load balancer member role, cannot # use this command if CONF.load_balancer.RBAC_test_type == const.ADVANCED: self.assertRaises( exceptions.Forbidden, self.os_primary.listener_client.get_listener_stats, listener[const.ID]) # Test that a different user, with the load balancer role, cannot see # the listener stats if not CONF.load_balancer.RBAC_test_type == const.NONE: member2_client = self.os_roles_lb_member2.listener_client self.assertRaises(exceptions.Forbidden, member2_client.get_listener_stats, listener[const.ID]) stats = self.mem_lb_client.get_listener_stats(listener[const.ID]) self.assertEqual(5, len(stats)) self.assertEqual(0, stats[const.ACTIVE_CONNECTIONS]) self.assertEqual(0, stats[const.BYTES_IN]) self.assertEqual(0, stats[const.BYTES_OUT]) self.assertEqual(0, stats[const.REQUEST_ERRORS]) self.assertEqual(0, stats[const.TOTAL_CONNECTIONS])",,129,0
openstack%2Foslo.messaging~stable%2Fpike~I90c172d673084ff0cb0a3dd0fae21a5d62d35286,openstack/oslo.messaging,stable/pike,I90c172d673084ff0cb0a3dd0fae21a5d62d35286,Add release note for amqp library TLS/SSL error,MERGED,2019-02-22 17:55:47.000000000,2019-02-25 03:42:47.000000000,2019-02-25 03:42:47.000000000,"[{'_account_id': 6928}, {'_account_id': 9796}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 17:55:47.000000000', 'files': ['releasenotes/notes/amqp-tls-issue-57c7f6ea894e03d7.yaml'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/3113175443b975d72699b3bbe6fea488c414a3ef', 'message': 'Add release note for amqp library TLS/SSL error\n\nChange-Id: I90c172d673084ff0cb0a3dd0fae21a5d62d35286\nRelated-Bug: #1800957\n'}]",0,638735,3113175443b975d72699b3bbe6fea488c414a3ef,7,3,1,8770,,,0,"Add release note for amqp library TLS/SSL error

Change-Id: I90c172d673084ff0cb0a3dd0fae21a5d62d35286
Related-Bug: #1800957
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/35/638735/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/amqp-tls-issue-57c7f6ea894e03d7.yaml'],1,3113175443b975d72699b3bbe6fea488c414a3ef,bug/1800957,--- issues: - | A bug in the ``amqp`` python library can cause the connection to the RabbitMQ broker to hang when using SSL/TLS. This results in frequent errors such as this:: MessagingTimeout: Timed out waiting for a reply to message ID ae039d1695984addbfaaef032ce4fda3 (see `bug 1800957 <https://bugs.launchpad.net/oslo.messaging/+bug/1800957>`_). This bug has been fixed in `v2.4.1 of amqp <https://github.com/celery/py-amqp/commit/bf122a05a21a8cc5bca314b0979f32c8026fc66e>`_. It is recommended that deployments using SSL/TLS upgrade the amqp library to v2.4.1 or later. ,,17,0
openstack%2Fplacement~master~I4ba5c49df080acaa720c06ff6043f5fff5985899,openstack/placement,master,I4ba5c49df080acaa720c06ff6043f5fff5985899,DEMO: use a set for alloc reqs in _merge_candidates,ABANDONED,2019-02-24 16:00:49.000000000,2019-02-25 03:16:41.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-24 16:00:49.000000000', 'files': ['placement/objects/resource_provider.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/6a771607b0a10da109a516a1f9988f9a07c4926e', 'message': 'DEMO: use a set for alloc reqs in _merge_candidates\n\nChange-Id: I4ba5c49df080acaa720c06ff6043f5fff5985899\n'}]",0,638977,6a771607b0a10da109a516a1f9988f9a07c4926e,3,1,1,14070,,,0,"DEMO: use a set for alloc reqs in _merge_candidates

Change-Id: I4ba5c49df080acaa720c06ff6043f5fff5985899
",git fetch https://review.opendev.org/openstack/placement refs/changes/77/638977/1 && git format-patch -1 --stdout FETCH_HEAD,['placement/objects/resource_provider.py'],1,6a771607b0a10da109a516a1f9988f9a07c4926e,bug/1817458," def __hash__(self): return hash((self.resource_provider.id, self.resource_class, self.amount)) def __hash__(self): return hash(tuple(self.resource_requests)) areqs = set() areqs.add(areq) return list(areqs), psums"," areqs = [] areqs.append(areq) return areqs, psums",11,3
openstack%2Fstackviz~master~Ie6ee0cf7ad69c7f6678a6d700936cbdb7b730943,openstack/stackviz,master,Ie6ee0cf7ad69c7f6678a6d700936cbdb7b730943,"Fix the misspelling of ""register""",MERGED,2019-01-23 08:56:18.000000000,2019-02-25 02:54:56.000000000,2019-02-25 02:54:55.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 27078}]","[{'number': 1, 'created': '2019-01-23 08:56:18.000000000', 'files': ['app/js/directives/timeline.js'], 'web_link': 'https://opendev.org/openstack/stackviz/commit/7538095c9584b041ebdf9bfe86628a97a1df380b', 'message': 'Fix the misspelling of ""register""\n\nChange-Id: Ie6ee0cf7ad69c7f6678a6d700936cbdb7b730943\n'}]",0,632653,7538095c9584b041ebdf9bfe86628a97a1df380b,7,3,1,29721,,,0,"Fix the misspelling of ""register""

Change-Id: Ie6ee0cf7ad69c7f6678a6d700936cbdb7b730943
",git fetch https://review.opendev.org/openstack/stackviz refs/changes/53/632653/1 && git format-patch -1 --stdout FETCH_HEAD,['app/js/directives/timeline.js'],1,7538095c9584b041ebdf9bfe86628a97a1df380b,," * Request an animation frame from the browser, and call all registered"," * Request an animation frame from the browser, and call all regsitered",1,1
openstack%2Fstackviz~master~I6d6c50f31e770876dacf21dee423a238aa121891,openstack/stackviz,master,I6d6c50f31e770876dacf21dee423a238aa121891,fix tox python3 overrides,MERGED,2018-10-03 02:00:40.000000000,2019-02-25 02:54:56.000000000,2019-02-25 02:54:56.000000000,"[{'_account_id': 5689}, {'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 27078}, {'_account_id': 28543}]","[{'number': 1, 'created': '2018-10-03 02:00:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/stackviz/commit/dcf3cd933e9a4bed582b497681a5fb38d527cea7', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: I6d6c50f31e770876dacf21dee423a238aa121891\n'}, {'number': 2, 'created': '2019-01-11 06:09:10.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/stackviz/commit/5a32f82e1ca686c884cc25c66e34311f8391c825', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: I6d6c50f31e770876dacf21dee423a238aa121891\n'}]",0,607446,5a32f82e1ca686c884cc25c66e34311f8391c825,12,6,2,26297,,,0,"fix tox python3 overrides

We want to default to running all tox environments under python 3, so
set the basepython value in each environment.

We do not want to specify a minor version number, because we do not
want to have to update the file every time we upgrade python.

We do not want to set the override once in testenv, because that
breaks the more specific versions used in default environments like
py35 and py36.

Change-Id: I6d6c50f31e770876dacf21dee423a238aa121891
",git fetch https://review.opendev.org/openstack/stackviz refs/changes/46/607446/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,dcf3cd933e9a4bed582b497681a5fb38d527cea7,,basepython = python3,,1,0
openstack%2Ftap-as-a-service~master~Id3bdaee98215017a96f636f0805956e980bcacca,openstack/tap-as-a-service,master,Id3bdaee98215017a96f636f0805956e980bcacca,Change openstack-dev to openstack-discuss,MERGED,2018-12-04 11:41:41.000000000,2019-02-25 02:33:04.000000000,2019-02-25 02:33:04.000000000,"[{'_account_id': 6854}, {'_account_id': 17499}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 26297}, {'_account_id': 28543}, {'_account_id': 28614}, {'_account_id': 28935}]","[{'number': 1, 'created': '2018-12-04 11:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/661c1e999263a2c5f22caae426f2b3edcd6559e5', 'message': 'Change openstack-dev to openstack-discuss\n\nMailinglists have been updated. Openstack-discuss replaces openstack-dev.\n\nChange-Id: Id3bdaee98215017a96f636f0805956e980bcacca\n'}, {'number': 2, 'created': '2019-01-11 06:08:25.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/b6fbb9804fdb23e925b2a24cd1606836e5d06eef', 'message': 'Change openstack-dev to openstack-discuss\n\nMailinglists have been updated. Openstack-discuss replaces openstack-dev.\n\nChange-Id: Id3bdaee98215017a96f636f0805956e980bcacca\n'}]",0,622239,b6fbb9804fdb23e925b2a24cd1606836e5d06eef,18,8,2,26297,,,0,"Change openstack-dev to openstack-discuss

Mailinglists have been updated. Openstack-discuss replaces openstack-dev.

Change-Id: Id3bdaee98215017a96f636f0805956e980bcacca
",git fetch https://review.opendev.org/openstack/tap-as-a-service refs/changes/39/622239/2 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,661c1e999263a2c5f22caae426f2b3edcd6559e5,,author-email = openstack-discuss@lists.openstack.org,author-email = openstack-dev@lists.openstack.org,1,1
openstack%2Fcyborg~master~I35e09416f2f6b267b029376671cb6c255d40c737,openstack/cyborg,master,I35e09416f2f6b267b029376671cb6c255d40c737,Modified the Deployable Object,MERGED,2019-02-22 04:45:53.000000000,2019-02-25 02:26:19.000000000,2019-02-25 02:26:19.000000000,"[{'_account_id': 14131}, {'_account_id': 17813}, {'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 22899}, {'_account_id': 24872}, {'_account_id': 25738}]","[{'number': 1, 'created': '2019-02-22 04:45:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/529df9c911b3cf1196d290822c9280410779e5a3', 'message': 'Modified the Deployable Object\n\nbased on the new DB scheme\n\nChange-Id: I35e09416f2f6b267b029376671cb6c255d40c737\n'}, {'number': 2, 'created': '2019-02-24 19:39:45.000000000', 'files': ['cyborg/conductor/manager.py', 'cyborg/db/sqlalchemy/api.py', 'cyborg/conductor/rpcapi.py', 'cyborg/tests/unit/objects/test_deployable.py', 'cyborg/db/api.py', 'cyborg/tests/unit/fake_device.py', 'cyborg/objects/deployable.py', 'cyborg/tests/unit/objects/test_objects.py', 'cyborg/tests/unit/fake_deployable.py', 'cyborg/tests/unit/db/utils.py'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/e6028de00f7466c82a28329e4302afe46c682386', 'message': 'Modified the Deployable Object\n\nbased on the new DB scheme\n\nChange-Id: I35e09416f2f6b267b029376671cb6c255d40c737\n'}]",2,638580,e6028de00f7466c82a28329e4302afe46c682386,10,7,2,27458,,,0,"Modified the Deployable Object

based on the new DB scheme

Change-Id: I35e09416f2f6b267b029376671cb6c255d40c737
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/80/638580/2 && git format-patch -1 --stdout FETCH_HEAD,"['cyborg/conductor/manager.py', 'cyborg/db/sqlalchemy/api.py', 'cyborg/conductor/rpcapi.py', 'cyborg/tests/unit/objects/test_deployable.py', 'cyborg/db/api.py', 'cyborg/tests/unit/fake_device.py', 'cyborg/objects/deployable.py', 'cyborg/tests/unit/objects/test_objects.py', 'cyborg/tests/unit/fake_deployable.py', 'cyborg/tests/unit/db/utils.py']",10,529df9c911b3cf1196d290822c9280410779e5a3,," 'id': kw.get('id', 1), 'uuid': kw.get('uuid', '10efe63d-dfea-4a37-ad94-4116fba5011'), 'parent_id': kw.get('parent_id', None), 'root_id': kw.get('root_id', 0), 'num_accelerators': kw.get('num_accelerators', 4), 'device_id': kw.get('device_id', 0), 'created_at': kw.get('created_at', None), 'updated_at': kw.get('updated_at', None)"," 'uuid': kw.get('uuid', '10efe63d-dfea-4a37-ad94-4116fba5098'), 'deleted': False, 'parent_uuid': kw.get('parent_uuid', None), 'address': kw.get('address', '00:7f:0b.2'), 'host': kw.get('host', 'host'), 'board': kw.get('board', 'KU115'), 'vendor': kw.get('vendor', 'Xilinx'), 'version': kw.get('version', '1.0'), 'type': kw.get('type', '1.0'), 'interface_type': 'pci', 'assignable': True, 'instance_uuid': None, 'availability': 'Available', 'accelerator_id': kw.get('accelerator_id', 1),",595,103
openstack%2Fcinder~master~I6c2dce7beb1c3f8bb777066f62ced134f763e640,openstack/cinder,master,I6c2dce7beb1c3f8bb777066f62ced134f763e640,Replace 'lvconvert' from rootwrap,MERGED,2019-01-30 18:16:17.000000000,2019-02-25 02:11:03.000000000,2019-02-21 14:43:20.000000000,"[{'_account_id': 24}, {'_account_id': 1736}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29637}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-01-30 18:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/602aff848bc4679f9640c5c1f8e14130bcbce973', 'message': ""Replace 'lvcovert' from rootwrap\n\nUse oslo.privsep to run the lvconvert command.\n\nChange-Id: I6c2dce7beb1c3f8bb777066f62ced134f763e640\nSigned-off-by: Charles Short <chucks@redhat.com>\n""}, {'number': 2, 'created': '2019-01-31 14:30:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c66c7bbe82d6492b9fd858a1d41426870f3fa8d7', 'message': ""Replace 'lvconvert' from rootwrap\n\nUse oslo.privsep to run the lvconvert command.\n\nChange-Id: I6c2dce7beb1c3f8bb777066f62ced134f763e640\nSigned-off-by: Charles Short <chucks@redhat.com>\n""}, {'number': 3, 'created': '2019-02-14 15:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8d42c33cea744ccda0d9bbfaef2d51cecd5da51a', 'message': ""Replace 'lvconvert' from rootwrap\n\nUse oslo.privsep to run the lvconvert command.\n\nChange-Id: I6c2dce7beb1c3f8bb777066f62ced134f763e640\nSigned-off-by: Charles Short <chucks@redhat.com>\n""}, {'number': 4, 'created': '2019-02-17 19:33:39.000000000', 'files': ['cinder/brick/local_dev/lvm.py', 'etc/cinder/rootwrap.d/volume.filters', 'cinder/privsep/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ec6eaa21fd08cb7e6fa950e303a626a99580ec89', 'message': ""Replace 'lvconvert' from rootwrap\n\nUse oslo.privsep to run the lvconvert command.\n\nChange-Id: I6c2dce7beb1c3f8bb777066f62ced134f763e640\nSigned-off-by: Charles Short <chucks@redhat.com>\n""}]",0,634020,ec6eaa21fd08cb7e6fa950e303a626a99580ec89,140,43,4,24,,,0,"Replace 'lvconvert' from rootwrap

Use oslo.privsep to run the lvconvert command.

Change-Id: I6c2dce7beb1c3f8bb777066f62ced134f763e640
Signed-off-by: Charles Short <chucks@redhat.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/20/634020/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/brick/local_dev/lvm.py', 'cinder/privsep/lvm.py']",2,602aff848bc4679f9640c5c1f8e14130bcbce973,," @cinder.privsep.sys_admin_pctxt.entrypoint def lvconvert(vg_name, snapshot_name): processutils.execute( 'lvconvert', '--merge', '%s/%s' % (vg_name, snapshot_name))",,7,3
openstack%2Fhorizon~master~I41ba81b36d19b38bfbcc6fc13b91cddbe0777ad6,openstack/horizon,master,I41ba81b36d19b38bfbcc6fc13b91cddbe0777ad6,Send confirm message for resize or revert_resize operations.,ABANDONED,2019-01-11 06:32:37.000000000,2019-02-25 01:53:19.000000000,,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 27838}, {'_account_id': 28470}]","[{'number': 1, 'created': '2019-01-11 06:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0dec82f744ae03199303ecd837afc71223d05cb0', 'message': ""Send confirm message for resize or revert_resize operations.\n\nWhen user click instance resize/revert button, the tasks will take long time\n  and no response from the webpage. We can give the user confirmation when\n  they click on confirm/revert instance resize, so they don't keep pressing\n  it and see errors.\n\nCloses-Bug: 1811327\n\nChange-Id: I41ba81b36d19b38bfbcc6fc13b91cddbe0777ad6\nSigned-off-by: Yan Chen <yan.chen@intel.com>\n""}, {'number': 2, 'created': '2019-01-14 02:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/16c61ebed0fdbda0717c0fe936e8ce814d14ef92', 'message': ""Send confirm message for resize or revert_resize operations.\n\nWhen user click instance resize/revert button, the tasks will take long time\nand no response from the webpage. We can give the user confirmation when\nthey click on confirm/revert instance resize, so they don't keep pressing\nit and see errors.\n\nCloses-Bug: 1811327\n\nChange-Id: I41ba81b36d19b38bfbcc6fc13b91cddbe0777ad6\nSigned-off-by: Yan Chen <yan.chen@intel.com>\n""}, {'number': 3, 'created': '2019-02-09 08:30:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ca7347a74c6edd722b417e351c0cfa4e1951e0ff', 'message': ""Send confirm message for resize or revert_resize operations.\n\nWhen user click instance resize/revert button, the tasks will take long time\nand no response from the webpage. We can give the user confirmation when\nthey click on confirm/revert instance resize, so they don't keep pressing\nit and see errors.\n\nCloses-Bug: 1811327\n\nChange-Id: I41ba81b36d19b38bfbcc6fc13b91cddbe0777ad6\nSigned-off-by: Yan Chen <yan.chen@intel.com>\n""}, {'number': 4, 'created': '2019-02-13 05:17:34.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/7d3a5405ff32c05affc5c356aef08427db2376a7', 'message': ""Send confirm message for resize or revert_resize operations.\n\nWhen user click instance resize/revert button, the tasks will take long time\nand no response from the webpage. We can give the user confirmation when\nthey click on confirm/revert instance resize, so they don't keep pressing\nit and see errors.\n\nCloses-Bug: 1811327\n\nChange-Id: I41ba81b36d19b38bfbcc6fc13b91cddbe0777ad6\nSigned-off-by: Yan Chen <yan.chen@intel.com>\n""}]",34,630031,7d3a5405ff32c05affc5c356aef08427db2376a7,22,6,4,28470,,,0,"Send confirm message for resize or revert_resize operations.

When user click instance resize/revert button, the tasks will take long time
and no response from the webpage. We can give the user confirmation when
they click on confirm/revert instance resize, so they don't keep pressing
it and see errors.

Closes-Bug: 1811327

Change-Id: I41ba81b36d19b38bfbcc6fc13b91cddbe0777ad6
Signed-off-by: Yan Chen <yan.chen@intel.com>
",git fetch https://review.opendev.org/openstack/horizon refs/changes/31/630031/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/tables.py'],1,0dec82f744ae03199303ecd837afc71223d05cb0,bug/1811327,"from novaclient.exceptions import ClientException try: api.nova.server_confirm_resize(request, instance) messages.success(request, ""Confirmation has been sent to instance"") except ClientException: # Ignore users' multiple requests before refresh # (instance could be in it's next state but not shown here yet) LOG.info(""Ignoring nova exception on ConfirmResize"") pass try: api.nova.server_revert_resize(request, instance) messages.success(request, ""Revert request has been sent to "" ""instance"") except ClientException: # Ignore users' multiple requests before refresh # (instance could be in it's next state but not shown here yet) LOG.info(""Ignoring nova exception on RevertResize"") pass"," api.nova.server_confirm_resize(request, instance) api.nova.server_revert_resize(request, instance)",19,2
openstack%2Fopenstack-helm-infra~master~Iff699adfcdc617b8cd6e7913594bcde02d6f7d42,openstack/openstack-helm-infra,master,Iff699adfcdc617b8cd6e7913594bcde02d6f7d42,[prometheus-node-exporter] Deploy pods on all nodes by default,ABANDONED,2019-01-25 06:32:11.000000000,2019-02-24 23:23:58.000000000,,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-01-25 06:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2e17d0db36a96dd1df9f1991f8a52ec3fdc2b3c8', 'message': '[prometheus-node-exporter] Deploy pods on all nodes by default\n\nBecause node-exporter collects metrics related to baremetals,\nit should be deployed on all nodes. Currently toleration option\nis false by default, node-exporter pods are only depolyed on\ncontrol plane.\n\nChange-Id: Iff699adfcdc617b8cd6e7913594bcde02d6f7d42\nSigned-off-by: Deokjin Kim <deokjin81.kim@samsung.com>\n'}, {'number': 2, 'created': '2019-01-25 06:34:13.000000000', 'files': ['tools/deployment/common/080-node-exporter.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/49e527634adfe17a9809c3ab16afb5382f34a50a', 'message': '[prometheus-node-exporter] Deploy pods on all nodes by default\n\nBecause node-exporter collects metrics related to baremetals,\nit should be deployed on all nodes. Current toleration option\nis false by default, node-exporter pods are only depolyed on\ncontrol plane.\n\nChange-Id: Iff699adfcdc617b8cd6e7913594bcde02d6f7d42\nSigned-off-by: Deokjin Kim <deokjin81.kim@samsung.com>\n'}]",0,633147,49e527634adfe17a9809c3ab16afb5382f34a50a,4,4,2,29828,,,0,"[prometheus-node-exporter] Deploy pods on all nodes by default

Because node-exporter collects metrics related to baremetals,
it should be deployed on all nodes. Current toleration option
is false by default, node-exporter pods are only depolyed on
control plane.

Change-Id: Iff699adfcdc617b8cd6e7913594bcde02d6f7d42
Signed-off-by: Deokjin Kim <deokjin81.kim@samsung.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/47/633147/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/deployment/common/080-node-exporter.sh'],1,2e17d0db36a96dd1df9f1991f8a52ec3fdc2b3c8,prometheus_node_exporter, ./prometheus-node-exporter --namespace=kube-system \ --set pod.tolerations.node_exporter.enabled=true, ./prometheus-node-exporter --namespace=kube-system,2,1
openstack%2Finstack-undercloud~stable%2Fqueens~Ia438625e6e3991a4b9d56cee350477c3186d18f0,openstack/instack-undercloud,stable/queens,Ia438625e6e3991a4b9d56cee350477c3186d18f0,Fix - delete ironic-neutorn-agent queue to allow auto_delete,ABANDONED,2019-02-12 22:15:12.000000000,2019-02-24 22:41:02.000000000,,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-02-12 22:15:12.000000000', 'files': ['instack_undercloud/undercloud.py'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/77513499e542cea5390fd11d4d98f3f586615eaf', 'message': 'Fix - delete ironic-neutorn-agent queue to allow auto_delete\n\nWith the fix for bug: https://storyboard.openstack.org/#!/story/2004933\nthe queues used by ironic-neutron-agent changed to be automatically\ndeleted when there are no consumers.\n\nThe existing queue with auto_delete = false need to be deleted so that\nthe queue can be re-created with auto_delete = true.\n\nRelated-Bug: RHBZ#1669499\nCloses-Bug: #1815675\nChange-Id: Ia438625e6e3991a4b9d56cee350477c3186d18f0\n(cherry picked from commit 0a695fda3e92c8108fabf05234f131ae1cb7c104)\n'}]",2,636451,77513499e542cea5390fd11d4d98f3f586615eaf,6,4,1,24245,,,0,"Fix - delete ironic-neutorn-agent queue to allow auto_delete

With the fix for bug: https://storyboard.openstack.org/#!/story/2004933
the queues used by ironic-neutron-agent changed to be automatically
deleted when there are no consumers.

The existing queue with auto_delete = false need to be deleted so that
the queue can be re-created with auto_delete = true.

Related-Bug: RHBZ#1669499
Closes-Bug: #1815675
Change-Id: Ia438625e6e3991a4b9d56cee350477c3186d18f0
(cherry picked from commit 0a695fda3e92c8108fabf05234f131ae1cb7c104)
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/51/636451/1 && git format-patch -1 --stdout FETCH_HEAD,['instack_undercloud/undercloud.py'],1,77513499e542cea5390fd11d4d98f3f586615eaf,bug/1815675,"def _run_fix_ironic_neutron_agent_queues(rabbit_user, rabbit_passwd): # Delete ironic-neutron-agent-heartbeat.info, it will be recreated # automatically with auto_delete = true. out = _run_command(['rabbitmqadmin', '--host', CONF.local_ip.split('/')[0], '--username', rabbit_user, '--password', rabbit_passwd, 'delete', 'queue', 'name=ironic-neutron-agent-heartbeat.info' ], None, 'rabbitmqadmin') LOG.debug('Queue ironic-neutron-agent-heartbeat.info delete. Result: %s' % out) _run_fix_ironic_neutron_agent_queues( instack_env['UNDERCLOUD_RABBIT_USERNAME'], instack_env['UNDERCLOUD_RABBIT_PASSWORD'])",,14,0
openstack%2Fcinder~stable%2Frocky~Ie24e5a85b54e4734c9b96987cc8ec497aa0ac435,openstack/cinder,stable/rocky,Ie24e5a85b54e4734c9b96987cc8ec497aa0ac435,Fix _per_gb_min usage with _per_gb,MERGED,2018-12-19 00:04:29.000000000,2019-02-24 20:06:56.000000000,2019-01-08 02:03:03.000000000,"[{'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 15670}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28619}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-12-19 00:04:29.000000000', 'files': ['cinder/tests/unit/volume/test_connection.py', 'cinder/volume/manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/43497dc8b18a30baebce58d7e7c97fc2146d34cc', 'message': 'Fix _per_gb_min usage with _per_gb\n\nAs _per_gb_min was a text, it was in many cases larger, than\n_per_gb value. So, situations, when big drives were attached\nwith min iops are now excluded.\n\nChange-Id: Ie24e5a85b54e4734c9b96987cc8ec497aa0ac435\n(cherry picked from commit b9b260a0a8dcf24995aa586dd5f2714326095257)\n'}]",0,626047,43497dc8b18a30baebce58d7e7c97fc2146d34cc,35,20,1,28619,,,0,"Fix _per_gb_min usage with _per_gb

As _per_gb_min was a text, it was in many cases larger, than
_per_gb value. So, situations, when big drives were attached
with min iops are now excluded.

Change-Id: Ie24e5a85b54e4734c9b96987cc8ec497aa0ac435
(cherry picked from commit b9b260a0a8dcf24995aa586dd5f2714326095257)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/47/626047/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/test_connection.py', 'cinder/volume/manager.py']",2,43497dc8b18a30baebce58d7e7c97fc2146d34cc,fix/qos_per_gb_min-stable/rocky," minimum_value = int(specs.pop(option_per_gb_min, 0))"," minimum_value = specs.pop(option_per_gb_min, 0)",9,9
openstack%2Fvitrage~master~I5c7ccece37a26f5148b6d549ea711128d3caa80c,openstack/vitrage,master,I5c7ccece37a26f5148b6d549ea711128d3caa80c,Small bug fix - remove not existing constant usage,MERGED,2019-02-24 09:51:37.000000000,2019-02-24 18:47:47.000000000,2019-02-24 18:47:47.000000000,"[{'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 22348}, {'_account_id': 26339}]","[{'number': 1, 'created': '2019-02-24 09:51:37.000000000', 'files': ['vitrage/entity_graph/processor/processor.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/ca66ef58557075397bd7dde3f5c853f04d040d76', 'message': 'Small bug fix - remove not existing constant usage\n\nChange-Id: I5c7ccece37a26f5148b6d549ea711128d3caa80c\n'}]",0,638933,ca66ef58557075397bd7dde3f5c853f04d040d76,18,4,1,19184,,,0,"Small bug fix - remove not existing constant usage

Change-Id: I5c7ccece37a26f5148b6d549ea711128d3caa80c
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/33/638933/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/entity_graph/processor/processor.py'],1,ca66ef58557075397bd7dde3f5c853f04d040d76,," elif action in [GraphAction.REMOVE_DELETED_ENTITY,"," elif action in [GraphAction.END_MESSAGE, GraphAction.REMOVE_DELETED_ENTITY,",1,2
openstack%2Fkolla-ansible~stable%2Fqueens~I3defe0c38f41d7335e1cbafb75523c3cd44323ee,openstack/kolla-ansible,stable/queens,I3defe0c38f41d7335e1cbafb75523c3cd44323ee,Fix link to Manila Guide,MERGED,2019-02-19 15:58:51.000000000,2019-02-24 16:43:32.000000000,2019-02-24 16:43:32.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 23717}]","[{'number': 1, 'created': '2019-02-19 15:58:51.000000000', 'files': ['doc/source/reference/external-ceph-guide.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9c2181aaf2012a0a062dde37953857a8d171bdde', 'message': 'Fix link to Manila Guide\n\nChange-Id: I3defe0c38f41d7335e1cbafb75523c3cd44323ee\n(cherry picked from commit 6c6759e9a09af90d8ed0b1c56228c28aaf28ad99)\n'}]",0,637920,9c2181aaf2012a0a062dde37953857a8d171bdde,7,3,1,16363,,,0,"Fix link to Manila Guide

Change-Id: I3defe0c38f41d7335e1cbafb75523c3cd44323ee
(cherry picked from commit 6c6759e9a09af90d8ed0b1c56228c28aaf28ad99)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/20/637920/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/external-ceph-guide.rst'],1,9c2181aaf2012a0a062dde37953857a8d171bdde,,"type ``default_share_type``, please see :doc:`Manila in Kolla <manila-guide>`.","type ``default_share_type``, please see: https://docs.openstack.org/kolla-ansible/latest/reference/manila-guide.html",1,2
openstack%2Fkolla-ansible~stable%2Frocky~I3defe0c38f41d7335e1cbafb75523c3cd44323ee,openstack/kolla-ansible,stable/rocky,I3defe0c38f41d7335e1cbafb75523c3cd44323ee,Fix link to Manila Guide,MERGED,2019-02-19 16:03:39.000000000,2019-02-24 16:43:31.000000000,2019-02-24 16:43:31.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 23717}]","[{'number': 1, 'created': '2019-02-19 16:03:39.000000000', 'files': ['doc/source/reference/external-ceph-guide.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f74d7e51167059cd4c65cb248cbb5bcb247be4eb', 'message': 'Fix link to Manila Guide\n\nChange-Id: I3defe0c38f41d7335e1cbafb75523c3cd44323ee\n(cherry picked from commit 6c6759e9a09af90d8ed0b1c56228c28aaf28ad99)\n'}]",0,637922,f74d7e51167059cd4c65cb248cbb5bcb247be4eb,7,3,1,16363,,,0,"Fix link to Manila Guide

Change-Id: I3defe0c38f41d7335e1cbafb75523c3cd44323ee
(cherry picked from commit 6c6759e9a09af90d8ed0b1c56228c28aaf28ad99)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/22/637922/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/external-ceph-guide.rst'],1,f74d7e51167059cd4c65cb248cbb5bcb247be4eb,,"type ``default_share_type``, please see :doc:`Manila in Kolla <manila-guide>`.","type ``default_share_type``, please see `Manila in Kolla <https://docs.openstack.org/kolla-ansible/latest/reference/manila-guide.html>`__.",1,2
openstack%2Fpython-octaviaclient~master~Idf842c6193db0199f575920a853ec9ed996f8556,openstack/python-octaviaclient,master,Idf842c6193db0199f575920a853ec9ed996f8556,Adds loadbalancer amphora configure to OSC,MERGED,2019-01-28 23:59:43.000000000,2019-02-24 15:51:04.000000000,2019-02-24 15:51:04.000000000,"[{'_account_id': 6469}, {'_account_id': 6579}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-28 23:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-octaviaclient/commit/ccd8521eaafbe816afb6cccdc2e5e82dcdabca23', 'message': 'Adds loadbalancer amphora configure to OSC\n\nThis patch adds the ""loadbalancer amphora configure"" command to the\nOpenStack Client for Octavia. It allows the user to refresh the\nconfiguration of a running amphora agent.\n\nChange-Id: Idf842c6193db0199f575920a853ec9ed996f8556\nStory: 1685225\nTask: 29155\n'}, {'number': 2, 'created': '2019-02-24 15:25:50.000000000', 'files': ['octaviaclient/api/v2/octavia.py', 'octaviaclient/tests/unit/osc/v2/test_amphora.py', 'octaviaclient/osc/v2/amphora.py', 'releasenotes/notes/add-amphora-configure-command-cda75053a72c0cdf.yaml', 'octaviaclient/api/constants.py', 'setup.cfg', 'octaviaclient/tests/unit/api/test_octavia.py'], 'web_link': 'https://opendev.org/openstack/python-octaviaclient/commit/bd339e1b0274d1398cdf54c707af59012cc5b605', 'message': 'Adds loadbalancer amphora configure to OSC\n\nThis patch adds the ""loadbalancer amphora configure"" command to the\nOpenStack Client for Octavia. It allows the user to refresh the\nconfiguration of a running amphora agent.\n\nChange-Id: Idf842c6193db0199f575920a853ec9ed996f8556\nStory: 1685225\nTask: 29155\n'}]",0,633626,bd339e1b0274d1398cdf54c707af59012cc5b605,15,5,2,11628,,,0,"Adds loadbalancer amphora configure to OSC

This patch adds the ""loadbalancer amphora configure"" command to the
OpenStack Client for Octavia. It allows the user to refresh the
configuration of a running amphora agent.

Change-Id: Idf842c6193db0199f575920a853ec9ed996f8556
Story: 1685225
Task: 29155
",git fetch https://review.opendev.org/openstack/python-octaviaclient refs/changes/26/633626/1 && git format-patch -1 --stdout FETCH_HEAD,"['octaviaclient/api/v2/octavia.py', 'octaviaclient/tests/unit/osc/v2/test_amphora.py', 'octaviaclient/osc/v2/amphora.py', 'releasenotes/notes/add-amphora-configure-command-cda75053a72c0cdf.yaml', 'octaviaclient/api/constants.py', 'setup.cfg', 'octaviaclient/tests/unit/api/test_octavia.py']",7,ccd8521eaafbe816afb6cccdc2e5e82dcdabca23,amp-update-api," def test_configure_amphora(self): self.requests_mock.register_uri( 'PUT', FAKE_OCTAVIA_URL + 'amphorae/' + FAKE_AMP + '/config', status_code=202, ) ret = self.api.amphora_configure(FAKE_AMP) self.assertEqual(202, ret.status_code) def test_configure_amphora_error(self): self.requests_mock.register_uri( 'PUT', FAKE_OCTAVIA_URL + 'amphorae/' + FAKE_AMP + '/config', text='{""faultstring"": ""%s""}' % self._error_message, status_code=409, ) self.assertRaisesRegex(octavia.OctaviaClientException, self._error_message, self.api.amphora_configure, FAKE_AMP) ",,79,0
openstack%2Fkuryr~master~I1403653c88546f95d60e8d1bf764925a452c1f8b,openstack/kuryr,master,I1403653c88546f95d60e8d1bf764925a452c1f8b,add python 3.7 unit test job,MERGED,2019-02-19 09:06:31.000000000,2019-02-24 15:09:51.000000000,2019-02-24 15:09:51.000000000,"[{'_account_id': 6598}, {'_account_id': 11343}, {'_account_id': 11536}, {'_account_id': 14352}, {'_account_id': 14885}, {'_account_id': 21691}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-19 09:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/40f6a318358cb41dbf36e3b47cfa00207b61745b', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: I1403653c88546f95d60e8d1bf764925a452c1f8b\nStory: #2004073\nTask: #27424\n'}, {'number': 2, 'created': '2019-02-20 02:46:36.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/53e240116bfc081469ba1f7da16c7cb47d00cf4f', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: I1403653c88546f95d60e8d1bf764925a452c1f8b\nStory: #2004073\nTask: #27424\n'}]",0,637770,53e240116bfc081469ba1f7da16c7cb47d00cf4f,12,7,2,9414,,,0,"add python 3.7 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.7.

See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html

Change-Id: I1403653c88546f95d60e8d1bf764925a452c1f8b
Story: #2004073
Task: #27424
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/70/637770/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,40f6a318358cb41dbf36e3b47cfa00207b61745b,py37-job, - openstack-python37-jobs,,1,0
openstack%2Ftempest~master~Ie5ac0576459ffa9ae06251e56c7bcdd3f715efd5,openstack/tempest,master,Ie5ac0576459ffa9ae06251e56c7bcdd3f715efd5,Fix typo,MERGED,2019-02-21 19:50:21.000000000,2019-02-24 13:25:04.000000000,2019-02-23 06:13:08.000000000,"[{'_account_id': 6167}, {'_account_id': 8911}, {'_account_id': 12033}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 23467}]","[{'number': 1, 'created': '2019-02-21 19:50:21.000000000', 'files': ['tempest/lib/common/rest_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1f6cc860ff3f355e776676ef69c38fbc1557739f', 'message': 'Fix typo\n\nChange-Id: Ie5ac0576459ffa9ae06251e56c7bcdd3f715efd5\n'}]",0,638500,1f6cc860ff3f355e776676ef69c38fbc1557739f,11,6,1,23467,,,0,"Fix typo

Change-Id: Ie5ac0576459ffa9ae06251e56c7bcdd3f715efd5
",git fetch https://review.opendev.org/openstack/tempest refs/changes/00/638500/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/lib/common/rest_client.py'],1,1f6cc860ff3f355e776676ef69c38fbc1557739f,, :param str url: the relative url to send the get request to :param str url: the relative url to send the delete request to :param str url: the relative url to send the patch request to :param str url: the relative url to send the put request to :param str url: the relative url to send the head request to :param str url: the relative url to send the copy request to, :param str url: the relative url to send the post request to :param str url: the relative url to send the post request to :param str url: the relative url to send the post request to :param str url: the relative url to send the post request to :param str url: the relative url to send the post request to :param str url: the relative url to send the post request to,6,6
openstack%2Ftrove~master~I2d10e5ff9760c75ae2739a5add7542baf9881207,openstack/trove,master,I2d10e5ff9760c75ae2739a5add7542baf9881207,Skip IP addresses from management networks,MERGED,2019-02-16 10:51:28.000000000,2019-02-24 10:37:29.000000000,2019-02-24 10:37:28.000000000,"[{'_account_id': 5293}, {'_account_id': 6732}, {'_account_id': 13157}, {'_account_id': 13562}, {'_account_id': 22348}, {'_account_id': 22608}, {'_account_id': 22694}, {'_account_id': 22818}, {'_account_id': 24739}, {'_account_id': 24791}, {'_account_id': 25113}, {'_account_id': 26895}, {'_account_id': 28646}, {'_account_id': 28671}, {'_account_id': 28695}, {'_account_id': 29393}]","[{'number': 1, 'created': '2019-02-16 10:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/330c0e7905ebdda242971ccd99386adcf51f5153', 'message': 'Ignore IP addresses in the management networks\n\nWhen management networks(`default_neutron_networks`) is configured, the\nmanagement interface information should be invisible to the end users.\n\nChange-Id: I2d10e5ff9760c75ae2739a5add7542baf9881207\n'}, {'number': 2, 'created': '2019-02-17 19:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/908b73b35bbec4b088a508ea91af281452c7ec2a', 'message': 'Ignore IP addresses in the management networks\n\nWhen management networks(`default_neutron_networks`) is configured, the\nmanagement interface information should be invisible to the end users.\n\nChange-Id: I2d10e5ff9760c75ae2739a5add7542baf9881207\n'}, {'number': 3, 'created': '2019-02-17 21:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ce261ee0d336caabd135b36bac7f9f0eed9fa505', 'message': 'Ignore IP addresses in the management networks\n\nWhen management networks(`default_neutron_networks`) is configured, the\nmanagement interface information should be invisible to the end users.\n\nChange-Id: I2d10e5ff9760c75ae2739a5add7542baf9881207\n'}, {'number': 4, 'created': '2019-02-19 21:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7bfe7c5a1dae6499900de97a5c95c4e74ff63cb1', 'message': 'Ignore IP addresses in the management networks\n\nWhen management networks(`default_neutron_networks`) is configured, the\nmanagement interface information should be invisible to the end users.\n\nChange-Id: I2d10e5ff9760c75ae2739a5add7542baf9881207\n'}, {'number': 5, 'created': '2019-02-20 01:27:59.000000000', 'files': ['trove/common/neutron.py', 'trove/instance/models.py', 'trove/tests/unittests/instance/test_instance_models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/7bf1b2870317934d6d6b7789262ae0de894c8472', 'message': 'Skip IP addresses from management networks\n\nWhen management networks(`default_neutron_networks`) is configured, the\nmanagement interface information should be invisible to the end users.\n\nChange-Id: I2d10e5ff9760c75ae2739a5add7542baf9881207\n'}]",6,637375,7bf1b2870317934d6d6b7789262ae0de894c8472,17,16,5,6732,,,0,"Skip IP addresses from management networks

When management networks(`default_neutron_networks`) is configured, the
management interface information should be invisible to the end users.

Change-Id: I2d10e5ff9760c75ae2739a5add7542baf9881207
",git fetch https://review.opendev.org/openstack/trove refs/changes/75/637375/2 && git format-patch -1 --stdout FETCH_HEAD,"['trove/instance/models.py', 'trove/tests/unittests/instance/test_instance_models.py']",2,330c0e7905ebdda242971ccd99386adcf51f5153,get-instance-ip," @patch('trove.instance.models.create_neutron_client') def test_filter_management_ip_addresses(self, mock_neutron_client): CONF.network_label_regex = '' CONF.default_neutron_networks = ['fake-net-id'] neutron_client = Mock() neutron_client.show_network.return_value = { 'network': {'name': 'public'} } mock_neutron_client.return_value = neutron_client ip = self.instance.get_visible_ip_addresses() neutron_client.show_network.assert_called_once_with('fake-net-id') self.assertEqual(2, len(ip)) self.assertIn('123.123.123.123', ip) self.assertIn('10.123.123.123', ip) ",,38,4
openstack%2Fvitrage-tempest-plugin~master~Id82c7a458642dbcfda0ec6c2e367746a6d2740fb,openstack/vitrage-tempest-plugin,master,Id82c7a458642dbcfda0ec6c2e367746a6d2740fb,remove handle exception,MERGED,2019-02-21 15:00:35.000000000,2019-02-24 08:41:37.000000000,2019-02-24 08:41:36.000000000,"[{'_account_id': 1736}, {'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 15:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/c0b2c20d5c1cdcf771b927c4ba4ea41f1183eede', 'message': 'remove handle exception\n\nits to verbose and we can see the topology in the log\n\nChange-Id: Id82c7a458642dbcfda0ec6c2e367746a6d2740fb\n'}, {'number': 2, 'created': '2019-02-21 15:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/91e73c4ef509c0cc5ec9c93883c813eec214a221', 'message': 'remove handle exception\n\nits too verbose and we can see the topology in the log\n\nChange-Id: Id82c7a458642dbcfda0ec6c2e367746a6d2740fb\n'}, {'number': 3, 'created': '2019-02-21 15:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/330210438e918372da64514004a932d52ab9376c', 'message': 'remove handle exception\n\nits to verbose and we can see the topology in the log\n\nChange-Id: Id82c7a458642dbcfda0ec6c2e367746a6d2740fb\n'}, {'number': 4, 'created': '2019-02-21 15:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/f9abbb5123809a964ced6a26ae772849857baad6', 'message': 'remove handle exception\n\nits too verbose and we can see the topology in the log\n\nChange-Id: Id82c7a458642dbcfda0ec6c2e367746a6d2740fb\n'}, {'number': 5, 'created': '2019-02-24 06:53:18.000000000', 'files': ['vitrage_tempest_plugin/tests/api/templates/test_template.py', 'vitrage_tempest_plugin/tests/api/topology/test_topology.py', 'vitrage_tempest_plugin/tests/datasources/test_static.py', 'vitrage_tempest_plugin/tests/e2e/test_overlapping_actions.py', 'vitrage_tempest_plugin/tests/base.py', 'vitrage_tempest_plugin/tests/datasources/test_neutron.py', 'vitrage_tempest_plugin/tests/datasources/test_nova.py', 'vitrage_tempest_plugin/tests/e2e/test_basic_template_actions.py', 'vitrage_tempest_plugin/tests/e2e/test_basic_actions.py', 'vitrage_tempest_plugin/tests/datasources/test_cinder_volume.py', 'vitrage_tempest_plugin/tests/datasources/test_aodh.py', 'vitrage_tempest_plugin/tests/datasources/test_heat_stack.py', 'vitrage_tempest_plugin/tests/api/rca/test_rca.py', 'vitrage_tempest_plugin/tests/api/resources/test_resources.py', 'vitrage_tempest_plugin/tests/notifiers/test_mistral_notifier.py', 'vitrage_tempest_plugin/tests/resources/mock_datasource/test_3rd_degree_scenarios.py'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/d30f9232ab0c947e568adaff2a9fd473013ba095', 'message': 'remove handle exception\n\nits too verbose and we can see the topology in the log\n\nChange-Id: Id82c7a458642dbcfda0ec6c2e367746a6d2740fb\n'}]",0,638432,d30f9232ab0c947e568adaff2a9fd473013ba095,14,5,5,19134,,,0,"remove handle exception

its too verbose and we can see the topology in the log

Change-Id: Id82c7a458642dbcfda0ec6c2e367746a6d2740fb
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/32/638432/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage_tempest_plugin/tests/api/templates/test_template.py', 'vitrage_tempest_plugin/tests/api/topology/test_topology.py', 'vitrage_tempest_plugin/tests/datasources/test_static.py', 'vitrage_tempest_plugin/tests/e2e/test_overlapping_actions.py', 'vitrage_tempest_plugin/tests/base.py', 'vitrage_tempest_plugin/tests/datasources/test_neutron.py', 'vitrage_tempest_plugin/tests/datasources/test_nova.py', 'vitrage_tempest_plugin/tests/e2e/test_basic_template_actions.py', 'vitrage_tempest_plugin/tests/e2e/test_basic_actions.py', 'vitrage_tempest_plugin/tests/datasources/test_cinder_volume.py', 'vitrage_tempest_plugin/tests/datasources/test_aodh.py', 'vitrage_tempest_plugin/tests/datasources/test_heat_stack.py', 'vitrage_tempest_plugin/tests/api/rca/test_rca.py', 'vitrage_tempest_plugin/tests/api/resources/test_resources.py', 'vitrage_tempest_plugin/tests/notifiers/test_mistral_notifier.py', 'vitrage_tempest_plugin/tests/resources/mock_datasource/test_3rd_degree_scenarios.py']",16,c0b2c20d5c1cdcf771b927c4ba4ea41f1183eede,eyalb/exception," finally: alarm_count = TempestClients.vitrage().alarm.count( all_tenants=True) self.assertEqual( CONF.root_cause_analysis_service.instances_per_host, alarm_count['SEVERE'], 'Each instance should have one SEVERE deduced alarm') self.assertEqual( CONF.root_cause_analysis_service.instances_per_host, alarm_count['CRITICAL'], 'Each instance should have one CRITICAL deduced alarm') expected_rca = [{VertexProperties.VITRAGE_TYPE: 'zabbix'}] * self.\ conf.mock_graph_datasource.zabbix_alarms_per_host expected_rca.extend([{'name': DEDUCED_1}, {'name': DEDUCED_2}]) def check_rca(alarm): rca = TempestClients.vitrage().rca.get(alarm['vitrage_id'], all_tenants=True) try: self._check_rca(rca, expected_rca, alarm) return True except Exception: LOG.exception('check_rca failed') return False # 10 threads calling rca api alarms = TempestClients.vitrage().alarm.list(all_tenants=True, vitrage_id='all') deduced_alarms = g_utils.all_matches( alarms, vitrage_type='vitrage', name=DEDUCED_2) workers = futures.ThreadPoolExecutor(max_workers=10) workers_result = [r for r in workers.map(check_rca, deduced_alarms)] self.assertTrue(all(workers_result)) self.assert_items_equal(g1_nodes, g2_nodes, msg + ""Nodes of each graph are not equal"")"," except Exception as e: self._handle_exception(e) raise except Exception as e: self._handle_exception(e) raise try: alarm_count = TempestClients.vitrage().alarm.count( all_tenants=True) self.assertEqual( CONF.root_cause_analysis_service.instances_per_host, alarm_count['SEVERE'], 'Each instance should have one SEVERE deduced alarm') self.assertEqual( CONF.root_cause_analysis_service.instances_per_host, alarm_count['CRITICAL'], 'Each instance should have one CRITICAL deduced alarm') expected_rca = [{VertexProperties.VITRAGE_TYPE: 'zabbix'}] * self.\ conf.mock_graph_datasource.zabbix_alarms_per_host expected_rca.extend([{'name': DEDUCED_1}, {'name': DEDUCED_2}]) def check_rca(alarm): rca = TempestClients.vitrage().rca.get(alarm['vitrage_id'], all_tenants=True) try: self._check_rca(rca, expected_rca, alarm) return True except Exception as e: LOG.exception('check_rca failed', e) return False # 10 threads calling rca api alarms = TempestClients.vitrage().alarm.list(all_tenants=True, vitrage_id='all') deduced_alarms = g_utils.all_matches( alarms, vitrage_type='vitrage', name=DEDUCED_2) workers = futures.ThreadPoolExecutor(max_workers=10) workers_result = [r for r in workers.map(check_rca, deduced_alarms)] self.assertTrue(all(workers_result)) except Exception as e: v_utils.delete_template(name=TEMPLATE_NAME) self._handle_exception(e) raise self.assertItemsEqual(g1_nodes, g2_nodes, msg + ""Nodes of each graph are not equal"")",136,340
openstack%2Fironic-tempest-plugin~master~Ib83166c2ec2acb8fb6da942374ee626a5a5e28ab,openstack/ironic-tempest-plugin,master,Ib83166c2ec2acb8fb6da942374ee626a5a5e28ab,Test - create BM guests in parallel,ABANDONED,2019-02-22 06:01:19.000000000,2019-02-24 08:26:18.000000000,,"[{'_account_id': 22348}, {'_account_id': 28609}, {'_account_id': 29209}]","[{'number': 1, 'created': '2019-02-22 06:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/d5a289b88deb429389cf8512b5ffdbf83ee4e11f', 'message': 'Test – create BM guests in parallel\nBoot BM guests in parallel, check names+statuses,\nand SSH connectivity to associated floating IPs\n\nChange-Id: Ib83166c2ec2acb8fb6da942374ee626a5a5e28ab\n'}, {'number': 2, 'created': '2019-02-22 07:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/bfd62b3676809241a785d0b066e5d5eecd73f6fe', 'message': 'Test – create BM guests in parallel\nBoot BM guests in parallel, check names+statuses,\nand SSH connectivity to associated floating IPs\n\nChange-Id: Ib83166c2ec2acb8fb6da942374ee626a5a5e28ab\n'}, {'number': 3, 'created': '2019-02-22 12:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/9fcab20a49048e350f3516f8a262936fff3b7904', 'message': 'Test – create BM guests in parallel\nBoot BM guests in parallel, check names+statuses,\nand SSH connectivity to associated floating IPs\n\nChange-Id: Ib83166c2ec2acb8fb6da942374ee626a5a5e28ab\n'}, {'number': 4, 'created': '2019-02-22 14:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/536d9565cfc89b108828781acfc04fc9e5775749', 'message': 'Test – create BM guests in parallel\nBoot BM guests in parallel, check names+statuses,\nand SSH connectivity to associated floating IPs\n\nChange-Id: Ib83166c2ec2acb8fb6da942374ee626a5a5e28ab\n'}, {'number': 5, 'created': '2019-02-22 16:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/094e83befb2a34737771cb8ba1df5b02bf4ed6ce', 'message': 'Test – create BM guests in parallel\nBoot BM guests in parallel, check names+statuses,\nand SSH connectivity to associated floating IPs\n\nChange-Id: Ib83166c2ec2acb8fb6da942374ee626a5a5e28ab\n'}, {'number': 6, 'created': '2019-02-22 18:11:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/1077aca22cabb21237dc62ab93025b8f86d0a873', 'message': 'Test – create BM guests in parallel\n\nBoot BM guests in parallel, check names+statuses,\nand SSH connectivity to associated floating IPs\n\nChange-Id: Ib83166c2ec2acb8fb6da942374ee626a5a5e28ab\n'}, {'number': 7, 'created': '2019-02-22 19:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/e0db3320d9a1b45e95494d1ad65fcf8ac5fabf89', 'message': 'Test create BM guests in parallel\n\nBoot BM guests in parallel, check names+statuses,\nand SSH connectivity to associated floating IPs\n\nChange-Id: Ib83166c2ec2acb8fb6da942374ee626a5a5e28ab\n'}, {'number': 8, 'created': '2019-02-23 05:02:53.000000000', 'files': ['ironic_tempest_plugin/tests/scenario/test_baremetal_advanced_ops.py'], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/9a17554c33e3bc655ac0b43c11ee7d7c0e09c835', 'message': 'Test - create BM guests in parallel\n\nBoot BM guests in parallel, check names+statuses,\nand SSH connectivity to associated floating IPs\n\nChange-Id: Ib83166c2ec2acb8fb6da942374ee626a5a5e28ab\n'}]",3,638585,9a17554c33e3bc655ac0b43c11ee7d7c0e09c835,21,3,8,28609,,,0,"Test - create BM guests in parallel

Boot BM guests in parallel, check names+statuses,
and SSH connectivity to associated floating IPs

Change-Id: Ib83166c2ec2acb8fb6da942374ee626a5a5e28ab
",git fetch https://review.opendev.org/openstack/ironic-tempest-plugin refs/changes/85/638585/4 && git format-patch -1 --stdout FETCH_HEAD,['ironic_tempest_plugin/tests/scenario/test_baremetal_advanced_ops.py'],1,d5a289b88deb429389cf8512b5ffdbf83ee4e11f,advance_tests,"# # Copyright (c) 2015 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.common import utils from tempest import config from tempest.lib.common.utils import data_utils from tempest.lib import decorators from ironic_tempest_plugin import manager from ironic_tempest_plugin.tests.scenario import baremetal_manager import threading CONF = config.CONF class BaremetalMultitenancy(baremetal_manager.BaremetalScenarioTest, manager.NetworkScenarioTest): """"""Check the ability to create BM guests in parallel: * Create a keypair, network, subnet and router for the primary tenant * Boot all available instances (""available_nodes"" value) in parallel * Verify that all instances were created as expected and in ACTIVE status * Verify SSH connectivity for each created instance * Delete instances """""" credentials = ['primary', 'admin'] @classmethod def skip_checks(cls): super(BaremetalMultitenancy, cls).skip_checks() if not CONF.baremetal.use_provision_network: msg = 'Ironic/Neutron tenant isolation is not configured.' raise cls.skipException(msg) if (CONF.baremetal.available_nodes is not None and CONF.baremetal.available_nodes < 2): msg = ('Not enough baremetal nodes, %d configured, test requires ' 'a minimum of 2') % CONF.baremetal.available_nodes raise cls.skipException(msg) def create_tenant_network(self, clients, tenant_cidr): network = self._create_network( networks_client=clients.networks_client, tenant_id=clients.credentials.tenant_id) router = self._get_router( client=clients.routers_client, tenant_id=clients.credentials.tenant_id) result = clients.subnets_client.create_subnet( name=data_utils.rand_name('subnet'), network_id=network['id'], tenant_id=clients.credentials.tenant_id, ip_version=4, cidr=tenant_cidr) subnet = result['subnet'] clients.routers_client.add_router_interface(router['id'], subnet_id=subnet['id']) self.addCleanup(clients.subnets_client.delete_subnet, subnet['id']) self.addCleanup(clients.routers_client.remove_router_interface, router['id'], subnet_id=subnet['id']) return network, subnet, router @decorators.idempotent_id('85e7aa2c-320d-11e9-8f4c-74e5f9e2a801') @utils.services('compute', 'image', 'network') def test_boot_bm_in_parallel(self): tenant_cidr = '10.0.100.0/24' nodes_number = CONF.baremetal.available_nodes # Create keypair, subnet and router keypair = self.create_keypair() network, subnet, router = self.create_tenant_network( self.os_primary, tenant_cidr) # Create list of BM guests to create bm_to_create = [] for node in xrange(0, nodes_number): bm_name = data_utils.rand_name('BM_Primary') bm_to_create.append({'name': bm_name, 'keypair': keypair, 'clients': self.os_primary, 'net_id': network['id']}) # Use previously created list and start to create BM guests # in parallel, lock untill all threads are finished threads = [] for item in bm_to_create: t = threading.Thread(target=self.boot_instance, kwargs=item) threads.append(t) t.start() for t in threads: t.join() # Get information for all created instances created_instances = [] servers = self.os_primary.servers_client.list_servers() for server in servers['servers']: name = server['name'] id = server['id'] instance = self.os_primary.servers_client.show_server(id)['server'] status = instance['status'] f_ip = self.create_floating_ip(instance)['floating_ip_address'] created_instances.append({'name': name, 'status': status, 'floating_ip': f_ip, 'instance': instance}) created_bm_names = [item['name'] for item in created_instances] created_bm_statuses = [item['status'] for item in created_instances] # Check that all BM guests were successfully created for item in bm_to_create: self.assertIn(item['name'], created_bm_names, 'Expected BM node: ' + item['name'] + ' does not exist!') for status in created_bm_statuses: self.assertEqual(status.lower(), 'active', 'Bad status has been detected for' ' created BM guests:\n' + str(created_instances)) # Check connectivity for each created BM guest floating_ips = [item['floating_ip'] for item in created_instances] for ip in floating_ips: self.check_vm_connectivity(ip_address=ip, private_key=keypair['private_key']) # Terminate created instances instances = [item['instance'] for item in created_instances] for instance in instances: self.terminate_instance(instance) ",,140,0
openstack%2Frequirements~master~Ibad4b1dce7ac0fac2280c6c3e360cfa5350d16ec,openstack/requirements,master,Ibad4b1dce7ac0fac2280c6c3e360cfa5350d16ec,Updated from generate-constraints,MERGED,2019-02-23 06:33:56.000000000,2019-02-24 03:25:22.000000000,2019-02-24 03:25:22.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 06:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/216041d3f05098a695cbf2d60c3bb026db6b056a', 'message': 'Updated from generate-constraints\n\nChange-Id: Ibad4b1dce7ac0fac2280c6c3e360cfa5350d16ec\n'}, {'number': 2, 'created': '2019-02-23 06:39:11.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e20b8e2bdc2863c4daac4b47980d10d665b174aa', 'message': 'Updated from generate-constraints\n\nChange-Id: Ibad4b1dce7ac0fac2280c6c3e360cfa5350d16ec\n'}]",0,638798,e20b8e2bdc2863c4daac4b47980d10d665b174aa,12,2,2,11131,,,0,"Updated from generate-constraints

Change-Id: Ibad4b1dce7ac0fac2280c6c3e360cfa5350d16ec
",git fetch https://review.opendev.org/openstack/requirements refs/changes/98/638798/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,216041d3f05098a695cbf2d60c3bb026db6b056a,openstack/requirements/constraints/noclob,websocket-client===0.55.0tornado===4.5.3;python_version=='3.4' tornado===4.5.3;python_version=='3.5' tornado===4.5.3;python_version=='3.6' tornado===5.1.1;python_version=='2.7'py===1.8.0opentracing===2.0.0salt===2018.3.3botocore===1.12.101configparser===3.7.3;python_version=='2.7'virtualenv===16.4.1,websocket-client===0.54.0tornado===4.5.3py===1.7.0opentracing===1.3.0salt===2018.3.2botocore===1.12.99configparser===3.7.1;python_version=='2.7'virtualenv===16.4.0,11,8
openstack%2Fnova~master~I01c108ceb539bb99491ed542c683e36fbf0c2bbe,openstack/nova,master,I01c108ceb539bb99491ed542c683e36fbf0c2bbe,Remove _legacy_dict methods,MERGED,2019-02-11 20:01:56.000000000,2019-02-24 02:23:20.000000000,2019-02-23 00:43:34.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 8864}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-11 20:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e5e2dbcec71a5c48e2d37754f92f938d11ddabf', 'message': 'Remove _legacy_dict methods\n\nThese are left over from the objectification of live migration. We can\nsafely get rid of them.\n\nChange-Id: I01c108ceb539bb99491ed542c683e36fbf0c2bbe\n'}, {'number': 2, 'created': '2019-02-12 03:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d8be425450d90495efe430b1970d8b94b13de54', 'message': ""Remove _legacy_dict methods\n\nThese are left over from the objectification of live migration. We can\nsafely get rid of them. This isn't required for the NUMA live\nmigration series, but the presence of _legacy_dict methods caused unit\ntest failures in subsequent paches because of their failure to handle\nthe changes to LiveMigrateData. Rather than working around that, bite\nthe bullet and remove _legacy_dict altogether.\n\nChange-Id: I01c108ceb539bb99491ed542c683e36fbf0c2bbe\n""}, {'number': 3, 'created': '2019-02-12 03:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/070b3cc1dd5bf2943515e3e06bc5f87affb29041', 'message': ""Remove _legacy_dict methods\n\nThese are left over from the objectification of live migration. We can\nsafely get rid of them. This isn't required for the NUMA live\nmigration series, but the presence of _legacy_dict methods caused unit\ntest failures in subsequent paches because of their failure to handle\nthe changes to LiveMigrateData. Rather than working around that, bite\nthe bullet and remove _legacy_dict altogether.\n\nChange-Id: I01c108ceb539bb99491ed542c683e36fbf0c2bbe\n""}, {'number': 4, 'created': '2019-02-12 14:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3503c630b1f5d0db81bd4c8457e9c5ec0e14d537', 'message': ""Remove _legacy_dict methods\n\nThese are left over from the objectification of live migration. We can\nsafely get rid of them. This isn't required for the NUMA live\nmigration series, but the presence of _legacy_dict methods caused unit\ntest failures in subsequent paches because of their failure to handle\nthe changes to LiveMigrateData. Rather than working around that, bite\nthe bullet and remove _legacy_dict altogether.\n\nChange-Id: I01c108ceb539bb99491ed542c683e36fbf0c2bbe\n""}, {'number': 5, 'created': '2019-02-12 21:37:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/252dfab97bcaa7d086eadc2eb61e6d0d1d381fbb', 'message': ""Remove _legacy_dict methods\n\nThese are left over from the objectification of live migration. We can\nsafely get rid of them. This isn't required for the NUMA live\nmigration series, but the presence of _legacy_dict methods caused unit\ntest failures in subsequent paches because of their failure to handle\nthe changes to LiveMigrateData. Rather than working around that, bite\nthe bullet and remove _legacy_dict altogether.\n\nChange-Id: I01c108ceb539bb99491ed542c683e36fbf0c2bbe\n""}, {'number': 6, 'created': '2019-02-13 23:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd41fd5366a7a3cb61c87cd806eaebe26607b889', 'message': ""Remove _legacy_dict methods\n\nThese are left over from the objectification of live migration. We can\nsafely get rid of them. This isn't required for the NUMA live\nmigration series, but the presence of _legacy_dict methods caused unit\ntest failures in subsequent paches because of their failure to handle\nthe changes to LiveMigrateData. Rather than working around that, bite\nthe bullet and remove _legacy_dict altogether.\n\nChange-Id: I01c108ceb539bb99491ed542c683e36fbf0c2bbe\n""}, {'number': 7, 'created': '2019-02-18 00:39:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47163c365bd986cddd8a9f87abcc1db590a01573', 'message': ""Remove _legacy_dict methods\n\nThese are left over from the objectification of live migration. We can\nsafely get rid of them. This isn't required for the NUMA live\nmigration series, but the presence of _legacy_dict methods caused unit\ntest failures in subsequent paches because of their failure to handle\nthe changes to LiveMigrateData. Rather than working around that, bite\nthe bullet and remove _legacy_dict altogether.\n\nChange-Id: I01c108ceb539bb99491ed542c683e36fbf0c2bbe\n""}, {'number': 8, 'created': '2019-02-21 21:00:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f1b711c0cf92afa8d895ed34aee63dcb1189a18', 'message': ""Remove _legacy_dict methods\n\nThese are left over from the objectification of live migration. We can\nsafely get rid of them. This isn't required for the NUMA live\nmigration series, but the presence of _legacy_dict methods caused unit\ntest failures in subsequent paches because of their failure to handle\nthe changes to LiveMigrateData. Rather than working around that, bite\nthe bullet and remove _legacy_dict altogether.\n\nChange-Id: I01c108ceb539bb99491ed542c683e36fbf0c2bbe\n""}, {'number': 9, 'created': '2019-02-22 12:38:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fcdc5f1a6029e34f9cb4ff92e974134be1272bcc', 'message': ""Remove _legacy_dict methods\n\nThese are left over from the objectification of live migration. We can\nsafely get rid of them. This isn't required for the NUMA live\nmigration series, but the presence of _legacy_dict methods caused unit\ntest failures in subsequent paches because of their failure to handle\nthe changes to LiveMigrateData. Rather than working around that, bite\nthe bullet and remove _legacy_dict altogether.\n\nChange-Id: I01c108ceb539bb99491ed542c683e36fbf0c2bbe\n""}, {'number': 10, 'created': '2019-02-22 17:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e42b6540daabf9d241db19e2c2def99de3434fc', 'message': ""[DERP] Remove _legacy_dict methods\n\nThese are left over from the objectification of live migration. We can\nsafely get rid of them. This isn't required for the NUMA live\nmigration series, but the presence of _legacy_dict methods caused unit\ntest failures in subsequent paches because of their failure to handle\nthe changes to LiveMigrateData. Rather than working around that, bite\nthe bullet and remove _legacy_dict altogether.\n\nChange-Id: I01c108ceb539bb99491ed542c683e36fbf0c2bbe\n""}, {'number': 11, 'created': '2019-02-22 18:33:17.000000000', 'files': ['nova/tests/unit/objects/test_migrate_data.py', 'nova/objects/migrate_data.py', 'nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/xenapi/test_xenapi.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3c13865a56076f140f70db8bc61a94fe30314af4', 'message': ""Remove _legacy_dict methods\n\nThese are left over from the objectification of live migration. We can\nsafely get rid of them. This isn't required for the NUMA live\nmigration series, but the presence of _legacy_dict methods caused unit\ntest failures in subsequent paches because of their failure to handle\nthe changes to LiveMigrateData. Rather than working around that, bite\nthe bullet and remove _legacy_dict altogether.\n\nChange-Id: I01c108ceb539bb99491ed542c683e36fbf0c2bbe\n""}]",7,636210,3c13865a56076f140f70db8bc61a94fe30314af4,105,16,11,8864,,,0,"Remove _legacy_dict methods

These are left over from the objectification of live migration. We can
safely get rid of them. This isn't required for the NUMA live
migration series, but the presence of _legacy_dict methods caused unit
test failures in subsequent paches because of their failure to handle
the changes to LiveMigrateData. Rather than working around that, bite
the bullet and remove _legacy_dict altogether.

Change-Id: I01c108ceb539bb99491ed542c683e36fbf0c2bbe
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/636210/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/migrate_data.py', 'nova/tests/unit/objects/test_migrate_data.py', 'nova/virt/libvirt/driver.py']",3,3e5e2dbcec71a5c48e2d37754f92f938d11ddabf,bp/numa-aware-live-migration,," if not isinstance(dest_check_data, migrate_data_obj.LiveMigrateData): md_obj = objects.LibvirtLiveMigrateData() md_obj.from_legacy_dict(dest_check_data) dest_check_data = md_obj ",0,424
openstack%2Fnova~master~I8c6b6c46b2587ee727653dafadbcb08b99ed7d35,openstack/nova,master,I8c6b6c46b2587ee727653dafadbcb08b99ed7d35,Remove misleading code from _move_operation_alloc_request(),MERGED,2019-02-22 16:21:13.000000000,2019-02-24 02:06:26.000000000,2019-02-24 00:26:58.000000000,"[{'_account_id': 7}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-22 16:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b86ade88a17f3e10fa12adbbc4242485f77a295f', 'message': 'Remove misleading comment from _move_operation_alloc_request()\n\nChange I1c9442eed850a3eb7ac9871fafcb0ae93ba8117c in Pike\nmade the scheduler ""double up"" the old_flavor and new_flavor\nallocations when resizing to the same host. If there were\nOcata computes still in the deployment at the time, which would\nbe normal in Pike for rolling upgrades, the ResourceTracker\nwould overwrite the instance allocations in placement based on\nthe instance.flavor when the update_available_resource periodic\ntask would run.\n\nIf that periodic ran after scheduling but before finish_resize(),\nthe old_flavor would be used to report allocations. If the periodic\nran after finish_resize(), the new_flavor would be used to report\nallocations.\n\nThat Ocata-compute auto-heal code was removed in Rocky with change\nI39d93dbf8552605e34b9f146e3613e6af62a1774, but should have effectively\nbeen vestigial since Queens when nova-compute should be at most N-1 so\nthere should be no Ocata compute services.\n\nThis change removes a misleading Pike-era comment in the\n_move_operation_alloc_request() which sums the allocations for the\nold and new flavor when resizing to the same host since the compute\nservice no longer does what the comment says.\n\nNote that change I1c9442eed850a3eb7ac9871fafcb0ae93ba8117c was\neffectively a change in behavior for resize to the same host\nbecause the scheduler sums the old/new flavor resource allocations\nwhich could result in a false NoValidHost error when in reality\nthe total allocation for the instance is going to be the maximum\nof the resource class allocations between the old and new flavor,\ne.g. if the compute has 8 VCPUs total and the instance is using\n6 VCPUs with the old flavor, and then resized to a new flavor with\n8 VCPUs, the scheduler is trying to ""claim"" 14 VCPUs when really the\ninstance will only use 8 and that causes a NoValidHost error.\nComparing to the pre-Pike scheduling and ResourceTracker.resize_claim\nbehavior for resize to the same host, the scheduler would only filter\non the new flavor resources and the resize_claim would only claim\nbased on the new_flavor resources as well. The update_available_resource\nperiodic would account for old_flavor usage in\n_update_usage_from_migration() after the instance was resized and\nbefore it was confirmed/reverted.\n\nChange-Id: I8c6b6c46b2587ee727653dafadbcb08b99ed7d35\nRelated-Bug: #1790204\n'}, {'number': 2, 'created': '2019-02-22 17:54:39.000000000', 'files': ['nova/scheduler/utils.py', 'nova/tests/unit/scheduler/test_utils.py', 'nova/scheduler/client/report.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4363b10f5b9eaa7be2df36a94b6bbad5f4674c57', 'message': 'Remove misleading code from _move_operation_alloc_request()\n\nChange I1c9442eed850a3eb7ac9871fafcb0ae93ba8117c in Pike\nmade the scheduler ""double up"" the old_flavor and new_flavor\nallocations when resizing to the same host. If there were\nOcata computes still in the deployment at the time, which would\nbe normal in Pike for rolling upgrades, the ResourceTracker\nwould overwrite the instance allocations in placement based on\nthe instance.flavor when the update_available_resource periodic\ntask would run.\n\nIf that periodic ran after scheduling but before finish_resize(),\nthe old_flavor would be used to report allocations. If the periodic\nran after finish_resize(), the new_flavor would be used to report\nallocations.\n\nThat Ocata-compute auto-heal code was removed in Rocky with change\nI39d93dbf8552605e34b9f146e3613e6af62a1774, but should have effectively\nbeen vestigial since Queens when nova-compute should be at most N-1 so\nthere should be no Ocata compute services.\n\nThis change removes the misleading Pike-era code in the\n_move_operation_alloc_request() which sums the allocations for the\nold and new flavor when resizing to the same host since:\n\n1. The compute service no longer does what the comment says.\n2. Since Queens, conductor swaps the instance-held allocations\n   on the source node to the migration record and the\n   _move_operation_alloc_request method is only called if the\n   instance has allocations, which it won\'t during resize. So the\n   only time _move_operation_alloc_request is called now is during\n   an evacuate because conductor doesn\'t do the allocation swap in\n   that case. And since you can\'t evacuate to the same host, the\n   elif block in _move_operation_alloc_request is dead code.\n\nNote that change I1c9442eed850a3eb7ac9871fafcb0ae93ba8117c was\neffectively a change in behavior for resize to the same host\nbecause the scheduler sums the old/new flavor resource allocations\nwhich could result in a false NoValidHost error when in reality\nthe total allocation for the instance is going to be the maximum\nof the resource class allocations between the old and new flavor,\ne.g. if the compute has 8 VCPUs total and the instance is using\n6 VCPUs with the old flavor, and then resized to a new flavor with\n8 VCPUs, the scheduler is trying to ""claim"" 14 VCPUs when really the\ninstance will only use 8 and that causes a NoValidHost error.\nComparing to the pre-Pike scheduling and ResourceTracker.resize_claim\nbehavior for resize to the same host, the scheduler would only filter\non the new flavor resources and the resize_claim would only claim\nbased on the new_flavor resources as well. The update_available_resource\nperiodic would account for old_flavor usage in\n_update_usage_from_migration() after the instance was resized and\nbefore it was confirmed/reverted.\n\nChange-Id: I8c6b6c46b2587ee727653dafadbcb08b99ed7d35\nRelated-Bug: #1790204\n'}]",4,638700,4363b10f5b9eaa7be2df36a94b6bbad5f4674c57,34,13,2,6873,,,0,"Remove misleading code from _move_operation_alloc_request()

Change I1c9442eed850a3eb7ac9871fafcb0ae93ba8117c in Pike
made the scheduler ""double up"" the old_flavor and new_flavor
allocations when resizing to the same host. If there were
Ocata computes still in the deployment at the time, which would
be normal in Pike for rolling upgrades, the ResourceTracker
would overwrite the instance allocations in placement based on
the instance.flavor when the update_available_resource periodic
task would run.

If that periodic ran after scheduling but before finish_resize(),
the old_flavor would be used to report allocations. If the periodic
ran after finish_resize(), the new_flavor would be used to report
allocations.

That Ocata-compute auto-heal code was removed in Rocky with change
I39d93dbf8552605e34b9f146e3613e6af62a1774, but should have effectively
been vestigial since Queens when nova-compute should be at most N-1 so
there should be no Ocata compute services.

This change removes the misleading Pike-era code in the
_move_operation_alloc_request() which sums the allocations for the
old and new flavor when resizing to the same host since:

1. The compute service no longer does what the comment says.
2. Since Queens, conductor swaps the instance-held allocations
   on the source node to the migration record and the
   _move_operation_alloc_request method is only called if the
   instance has allocations, which it won't during resize. So the
   only time _move_operation_alloc_request is called now is during
   an evacuate because conductor doesn't do the allocation swap in
   that case. And since you can't evacuate to the same host, the
   elif block in _move_operation_alloc_request is dead code.

Note that change I1c9442eed850a3eb7ac9871fafcb0ae93ba8117c was
effectively a change in behavior for resize to the same host
because the scheduler sums the old/new flavor resource allocations
which could result in a false NoValidHost error when in reality
the total allocation for the instance is going to be the maximum
of the resource class allocations between the old and new flavor,
e.g. if the compute has 8 VCPUs total and the instance is using
6 VCPUs with the old flavor, and then resized to a new flavor with
8 VCPUs, the scheduler is trying to ""claim"" 14 VCPUs when really the
instance will only use 8 and that causes a NoValidHost error.
Comparing to the pre-Pike scheduling and ResourceTracker.resize_claim
behavior for resize to the same host, the scheduler would only filter
on the new flavor resources and the resize_claim would only claim
based on the new_flavor resources as well. The update_available_resource
periodic would account for old_flavor usage in
_update_usage_from_migration() after the instance was resized and
before it was confirmed/reverted.

Change-Id: I8c6b6c46b2587ee727653dafadbcb08b99ed7d35
Related-Bug: #1790204
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/638700/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/client/report.py'],1,b86ade88a17f3e10fa12adbbc4242485f77a295f,bug/1790204,," # Note that we sum the allocations rather than take the max per # resource class between the current and new allocations because # the compute node/resource tracker is going to adjust for # decrementing any old allocations as necessary, the scheduler # shouldn't make assumptions about that.",0,5
openstack%2Fnova~master~Ic3c2aa23d0197633714df473e2e052f5e260e6b0,openstack/nova,master,Ic3c2aa23d0197633714df473e2e052f5e260e6b0,Log why rescheduling is disabled,MERGED,2019-02-22 16:21:13.000000000,2019-02-24 00:38:46.000000000,2019-02-24 00:13:46.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-22 16:21:13.000000000', 'files': ['nova/scheduler/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e162bcb22ceb7c87924b992ad71a567f1f4c314b', 'message': 'Log why rescheduling is disabled\n\nThe populate_retry() utility method just logs when retries\nare disabled but there are really two conditions when retries\nare disabled, either via configuration or because a host/node\nis being forced. This change expands on the logging to clarify\nwhich condition is disabling the retry.\n\nChange-Id: Ic3c2aa23d0197633714df473e2e052f5e260e6b0\n'}]",1,638699,e162bcb22ceb7c87924b992ad71a567f1f4c314b,34,12,1,6873,,,0,"Log why rescheduling is disabled

The populate_retry() utility method just logs when retries
are disabled but there are really two conditions when retries
are disabled, either via configuration or because a host/node
is being forced. This change expands on the logging to clarify
which condition is disabling the retry.

Change-Id: Ic3c2aa23d0197633714df473e2e052f5e260e6b0
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/638699/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/utils.py'],1,e162bcb22ceb7c87924b992ad71a567f1f4c314b,bug/1790204," if (max_attempts == 1 or len(force_hosts) == 1 or len(force_nodes) == 1): # re-scheduling is disabled, log why if max_attempts == 1: LOG.debug('Re-scheduling is disabled due to ""max_attempts"" config') else: LOG.debug(""Re-scheduling is disabled due to forcing a host (%s) "" ""and/or node (%s)"", force_hosts, force_nodes)", if (max_attempts == 1 or len(force_hosts) == 1 or len(force_nodes) == 1): # re-scheduling is disabled. LOG.debug('Re-scheduling is disabled.'),7,4
openstack%2Fneutron-lib~master~I55a1cb60898ab87ffe137f8c4b0b2f2803bfb219,openstack/neutron-lib,master,I55a1cb60898ab87ffe137f8c4b0b2f2803bfb219,Add RouterNotFoundInRouterFactory exception,MERGED,2018-11-27 15:59:14.000000000,2019-02-24 00:07:10.000000000,2019-02-24 00:07:10.000000000,"[{'_account_id': 1131}, {'_account_id': 5367}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26970}, {'_account_id': 27546}]","[{'number': 1, 'created': '2018-11-27 15:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/2bff3f960c3be91b205f6677fc1dfaccdf7d1f2a', 'message': 'Add RouterNotFoundInRouterFactory excetpion\n\nAdd new exception for l3-agent. It occurs when there is no valid\nrouter_info class which registered in router_factory.\n\nRelated-Bug: #1804634\nChange-Id: I55a1cb60898ab87ffe137f8c4b0b2f2803bfb219\n'}, {'number': 2, 'created': '2018-11-28 15:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/f3dc347aeade8c70ee8ee3be3221341cd58ea8a2', 'message': 'Add RouterNotFoundInRouterFactory exception\n\nAdd new exception for l3-agent. It occurs when there is no valid\nrouter_info class which registered in router_factory.\n\nRelated-Bug: #1804634\nChange-Id: I55a1cb60898ab87ffe137f8c4b0b2f2803bfb219\n'}, {'number': 3, 'created': '2018-11-28 15:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/9d084bad36397e3d9aa44dabc71da577be9eeec9', 'message': 'Add RouterNotFoundInRouterFactory exception\n\nAdd new exception for l3-agent. It occurs when there is no valid\nrouter_info class which registered in router_factory.\n\nRelated-Bug: #1804634\nChange-Id: I55a1cb60898ab87ffe137f8c4b0b2f2803bfb219\n'}, {'number': 4, 'created': '2018-11-28 15:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/b36354739f639438d845e96a6d7dc81d6935a971', 'message': 'Add RouterNotFoundInRouterFactory exception\n\nAdd new exception for l3-agent. It occurs when there is no valid\nrouter_info class which registered in router_factory.\n\nRelated-Bug: #1804634\nChange-Id: I55a1cb60898ab87ffe137f8c4b0b2f2803bfb219\n'}, {'number': 5, 'created': '2018-11-30 12:08:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/c5d5c923ed09b4d86b3c29839f8ca6bc274a2bbb', 'message': 'Add RouterNotFoundInRouterFactory exception\n\nAdd new exception for l3-agent. It occurs when there is no valid\nrouter_info class which registered in router_factory.\n\nRelated-Bug: #1804634\nChange-Id: I55a1cb60898ab87ffe137f8c4b0b2f2803bfb219\n'}, {'number': 6, 'created': '2018-12-04 03:14:15.000000000', 'files': ['neutron_lib/exceptions/l3.py', 'releasenotes/notes/add-router-not-found-in-factory-exception-e2bf9431549ff9b9.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/176c09fa192df4b42570d1478039607108fad6d1', 'message': 'Add RouterNotFoundInRouterFactory exception\n\nAdd new exception for l3-agent. It occurs when there is no valid\nrouter_info class which registered in router_factory.\n\nRelated-Bug: #1804634\nChange-Id: I55a1cb60898ab87ffe137f8c4b0b2f2803bfb219\n'}]",4,620348,176c09fa192df4b42570d1478039607108fad6d1,39,7,6,26970,,,0,"Add RouterNotFoundInRouterFactory exception

Add new exception for l3-agent. It occurs when there is no valid
router_info class which registered in router_factory.

Related-Bug: #1804634
Change-Id: I55a1cb60898ab87ffe137f8c4b0b2f2803bfb219
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/48/620348/6 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lib/exceptions/l3.py'],1,2bff3f960c3be91b205f6677fc1dfaccdf7d1f2a,bug/1804634,"class RouterNotFoundInRouterFactory(exceptions.NeutronException): message = _(""Router '%(router_id)s' with %(features)s could not be found "" ""router factory."") ",,5,0
openstack%2Fzun~master~Id2164788b3bde38e9735a3299f7039f9b4cbb91c,openstack/zun,master,Id2164788b3bde38e9735a3299f7039f9b4cbb91c,Capsule: backward-compatible with legacy API version,MERGED,2019-02-23 18:01:24.000000000,2019-02-23 23:46:25.000000000,2019-02-23 23:46:25.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 18:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/158f17cdf92688d1a3fdd57c6ee46c43c0efba45', 'message': '[WIP] Capsule: support legacy API version\n\nChange-Id: Id2164788b3bde38e9735a3299f7039f9b4cbb91c\n'}, {'number': 2, 'created': '2019-02-23 21:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/26effded183f7da32c8e68b786c91c16a59da6e3', 'message': 'Capsule: backward-compatible with legacy API version\n\nIf users specify API version 1.31 or lower, generate the legacy\nAPI response.\n\nChange-Id: Id2164788b3bde38e9735a3299f7039f9b4cbb91c\n'}, {'number': 3, 'created': '2019-02-23 21:26:23.000000000', 'files': ['zun/api/controllers/v1/capsules.py', 'zun/api/controllers/v1/views/capsules_view.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/b85612662b3d123cfea08f630953162944951e22', 'message': 'Capsule: backward-compatible with legacy API version\n\nIf users specify API version 1.31 or lower, generate the legacy\nAPI response.\n\nChange-Id: Id2164788b3bde38e9735a3299f7039f9b4cbb91c\n'}]",0,638856,b85612662b3d123cfea08f630953162944951e22,9,2,3,11536,,,0,"Capsule: backward-compatible with legacy API version

If users specify API version 1.31 or lower, generate the legacy
API response.

Change-Id: Id2164788b3bde38e9735a3299f7039f9b4cbb91c
",git fetch https://review.opendev.org/openstack/zun refs/changes/56/638856/2 && git format-patch -1 --stdout FETCH_HEAD,"['zun/api/controllers/v1/capsules.py', 'zun/api/controllers/v1/views/capsules_view.py']",2,158f17cdf92688d1a3fdd57c6ee46c43c0efba45,," 'volumes_info', # deprecated 'containers_uuids', # deprecated 'init_containers_uuids', # deprecated 'capsule_version', # deprecated 'meta_name', # deprecated 'meta_labels', # deprecateddef format_capsule(url, capsule, context, legacy_api_version=False): elif key == 'volumes_info': if legacy_api_version: yield(key, {}) else: pass elif key == 'containers_uuids' or key == 'init_containers_uuids': if legacy_api_version: yield(key, []) else: pass elif key == 'capsule_version': if legacy_api_version: yield(key, '') else: pass elif key == 'meta_name': if legacy_api_version: yield(key, capsule.name) else: pass elif key == 'meta_labels': if legacy_api_version: yield(key, capsule.labels) else: pass elif key == 'restart_policy': if legacy_api_version: yield(key, value['Name']) else: yield(key, value)"," 'volumes_info', 'containers_uuids', 'init_containers_uuids', 'capsule_version',def format_capsule(url, capsule, context):",88,15
openstack%2Fpuppet-openstack-integration~master~I452944da1ed954d05ecd0db86b6c0e7163a4e651,openstack/puppet-openstack-integration,master,I452944da1ed954d05ecd0db86b6c0e7163a4e651,Remove chardet workaround,ABANDONED,2019-02-23 21:11:12.000000000,2019-02-23 23:18:26.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-23 21:11:12.000000000', 'files': ['manifests/repos.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/03c865ae9f43b2506866c79b7e5e579b3adf3323', 'message': 'Remove chardet workaround\n\nChange-Id: I452944da1ed954d05ecd0db86b6c0e7163a4e651\n'}]",0,638859,03c865ae9f43b2506866c79b7e5e579b3adf3323,4,2,1,16137,,,0,"Remove chardet workaround

Change-Id: I452944da1ed954d05ecd0db86b6c0e7163a4e651
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/59/638859/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/repos.pp'],1,03c865ae9f43b2506866c79b7e5e579b3adf3323,remove-chardet,," # NOTE(tobias-urdin): The python-requests RPM package has a package dependency # which upstream requests package does not support so it outputs a warning which # messes up output (warning is printed to stdout) an causes some providers that # rely on the stdout output to fail. If you upgrade the python-chardet dependency # to a newer version you are fine, is reported upstream: # https://bugzilla.redhat.com/show_bug.cgi?id=1620221 # This is added here so we have the latest of this package in both integration and # beaker testing. package { 'python-chardet': ensure => 'installed', provider => 'rpm', source => 'http://mirror.centos.org/centos/7/cloud/x86_64/openstack-rocky/python2-chardet-3.0.4-7.el7.noarch.rpm', } ",0,14
openstack%2Fcinder~master~I088e20583d5ae7c565cd0651786d71afcb2e1c67,openstack/cinder,master,I088e20583d5ae7c565cd0651786d71afcb2e1c67,Remove legacy-tempest-dsvm-full-drbd-devstack job,MERGED,2019-02-05 16:28:17.000000000,2019-02-23 22:56:52.000000000,2019-02-23 22:39:34.000000000,"[{'_account_id': 4523}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23601}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 28940}, {'_account_id': 29637}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-02-05 16:28:17.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cb3d52f5dee2616d3c00f016eede378250afa83b', 'message': 'Remove legacy-tempest-dsvm-full-drbd-devstack job\n\nhttps://review.openstack.org/#/c/629061/ deprecated the DRBD driver with\nthe introduction of their newer Linstor driver. Since this is now marked\nas unsupported, we can drop running CI against the old driver.\n\nChange-Id: I088e20583d5ae7c565cd0651786d71afcb2e1c67\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,634969,cb3d52f5dee2616d3c00f016eede378250afa83b,61,38,1,11904,,,0,"Remove legacy-tempest-dsvm-full-drbd-devstack job

https://review.openstack.org/#/c/629061/ deprecated the DRBD driver with
the introduction of their newer Linstor driver. Since this is now marked
as unsupported, we can drop running CI against the old driver.

Change-Id: I088e20583d5ae7c565cd0651786d71afcb2e1c67
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/69/634969/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,cb3d52f5dee2616d3c00f016eede378250afa83b,drdb_deprecated,, - legacy-tempest-dsvm-full-drbd-devstack: voting: false irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^cinder/hacking/.*$ - ^cinder/locale/.*$ - ^cinder/tests/functional.*$ - ^cinder/tests/unit.*$ - ^contrib/block-box.*$ - ^doc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$,0,16
openstack%2Fplacement~master~I47eff6a11f47b16dc76cfe93f3136327c9e410b8,openstack/placement,master,I47eff6a11f47b16dc76cfe93f3136327c9e410b8,Don't use OVO in ResourceClass and ResourceClassList,MERGED,2019-02-14 01:24:07.000000000,2019-02-23 22:39:39.000000000,2019-02-23 22:39:39.000000000,"[{'_account_id': 7}, {'_account_id': 7634}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-14 01:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/39cfe1e8d1512419c79c6fa53815d7d58045de47', 'message': ""WIP: Don't use OVO in ResourceClass and ResourceClassList\n\nThere are some patterns emerging that will need to be cleaned\nup soon. This commit message is a stub.\n\nChange-Id: I47eff6a11f47b16dc76cfe93f3136327c9e410b8\n""}, {'number': 2, 'created': '2019-02-14 12:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/ffd48160ac42addb44031c60ba279d119b432962', 'message': ""Don't use OVO in ResourceClass and ResourceClassList\n\nTurn ResourceClass and ResourceClassList into classical\npython objects.\n\nAs indicated within, there are some shared patterns that\nneed to be dried out that will be fixed somewhere within\nthis stack of changes.\n\nChange-Id: I47eff6a11f47b16dc76cfe93f3136327c9e410b8\n""}, {'number': 3, 'created': '2019-02-15 17:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/778bd096cbc3aa333879d564ea9f30217366ef59', 'message': ""Don't use OVO in ResourceClass and ResourceClassList\n\nTurn ResourceClass and ResourceClassList into classical\npython objects.\n\nAs indicated within, there are some shared patterns that\nneed to be dried out that will be fixed after the end\nof this stack of changes.\n\nChange-Id: I47eff6a11f47b16dc76cfe93f3136327c9e410b8\n""}, {'number': 4, 'created': '2019-02-20 09:59:55.000000000', 'files': ['placement/tests/unit/test_util.py', 'placement/objects/resource_provider.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/e822949b36d979fe7fcb9118b90f8ab7ed1a0726', 'message': ""Don't use OVO in ResourceClass and ResourceClassList\n\nTurn ResourceClass and ResourceClassList into classical\npython objects.\n\nAs indicated within, there are some shared patterns that\nneed to be dried out that will be fixed after the end\nof this stack of changes.\n\nChange-Id: I47eff6a11f47b16dc76cfe93f3136327c9e410b8\n""}]",3,636804,e822949b36d979fe7fcb9118b90f8ab7ed1a0726,15,5,4,11564,,,0,"Don't use OVO in ResourceClass and ResourceClassList

Turn ResourceClass and ResourceClassList into classical
python objects.

As indicated within, there are some shared patterns that
need to be dried out that will be fixed after the end
of this stack of changes.

Change-Id: I47eff6a11f47b16dc76cfe93f3136327c9e410b8
",git fetch https://review.opendev.org/openstack/placement refs/changes/04/636804/3 && git format-patch -1 --stdout FETCH_HEAD,"['placement/tests/unit/test_util.py', 'placement/objects/resource_provider.py']",2,39cfe1e8d1512419c79c6fa53815d7d58045de47,cd/less-ovo,"class ResourceClass(object): def __init__(self, context, id=None, name=None, updated_at=None, created_at=None): self._context = context self.id = id self.name = name self.updated_at = updated_at self.created_at = created_at target.id = source['id'] target.name = source['name'] target.updated_at = source['updated_at'] target.created_at = source['created_at'] if self.id is not None: if not self.name: updates = {} for field in ['name', 'updated_at', 'created_at']: value = getattr(self, field, None) if value: updates[field] = value if self.id is None: if self.id is None: updates = {} for field in ['name', 'updated_at', 'created_at']: value = getattr(self, field, None) if value: updates[field] = valueclass ResourceClassList(object): def __init__(self, objects=None): self.objects = objects or [] def __len__(self): """"""List length is a proxy for truthiness."""""" return len(self.objects) def __getitem__(self, index): return self.objects[index] # FIXME(cdent): There are versions of this that need context # and versions that don't. Unify into a super class. @staticmethod def _set_objects(context, list_obj, item_cls, db_list): for db_item in db_list: list_obj.objects.append(item_cls(context, **db_item)) return list_obj return cls._set_objects(context, cls(), ResourceClass, resource_classes)","@base.VersionedObjectRegistry.register_if(False) class ResourceClass(base.VersionedObject, base.TimestampedObject): fields = { 'id': fields.IntegerField(read_only=True), 'name': fields.StringField(nullable=False), } for field in target.fields: setattr(target, field, source[field]) target.obj_reset_changes() obj.obj_reset_changes() if 'id' in self: if 'name' not in self: updates = self.obj_get_changes() if 'id' not in self: if 'id' not in self: updates = self.obj_get_changes()@base.VersionedObjectRegistry.register_if(False) class ResourceClassList(base.ObjectListBase, base.VersionedObject): fields = { 'objects': fields.ListOfObjectsField('ResourceClass'), } return base.obj_make_list(context, cls(context), ResourceClass, resource_classes)",48,24
openstack%2Fpython-zunclient~master~Ie42a057cb1acbd706cbbcade99e72bfff721f711,openstack/python-zunclient,master,Ie42a057cb1acbd706cbbcade99e72bfff721f711,Fix repository&tag when commit a container,MERGED,2019-01-29 03:33:04.000000000,2019-02-23 21:47:52.000000000,2019-02-23 21:47:52.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-29 03:33:04.000000000', 'files': ['zunclient/common/utils.py'], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/6a243c5d7a9caa757bc388c61ffaefe4f552e406', 'message': 'Fix repository&tag when commit a container\n\nChange-Id: Ie42a057cb1acbd706cbbcade99e72bfff721f711\n'}]",0,633649,6a243c5d7a9caa757bc388c61ffaefe4f552e406,6,2,1,23365,,,0,"Fix repository&tag when commit a container

Change-Id: Ie42a057cb1acbd706cbbcade99e72bfff721f711
",git fetch https://review.opendev.org/openstack/python-zunclient refs/changes/49/633649/1 && git format-patch -1 --stdout FETCH_HEAD,['zunclient/common/utils.py'],1,6a243c5d7a9caa757bc388c61ffaefe4f552e406,, args_list = commit_args.repository.rsplit(':'), args_list = commit_args.repository.split(':'),1,1
openstack%2Fopenstack-helm~master~I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24,openstack/openstack-helm,master,I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24,Add startingDeadlineSeconds field to cronJobs,MERGED,2018-10-11 23:48:15.000000000,2019-02-23 21:18:26.000000000,2019-02-23 21:18:26.000000000,"[{'_account_id': 8898}, {'_account_id': 17119}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 23928}, {'_account_id': 24780}]","[{'number': 1, 'created': '2018-10-11 23:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/09d1fc4cd6a3c2cd4e4f4d893e1509ca0ee07f20', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 2, 'created': '2018-10-15 17:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d124775215ca654c589ac02a7cd48365ac9b4f54', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 3, 'created': '2018-10-17 16:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c458bf18ef0e27733b29fbf1abd3fcb70bfed19b', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 4, 'created': '2018-10-22 19:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/dbbeb0da67b3c297e9343a7e2c1a5eac8180466b', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 5, 'created': '2018-10-24 19:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a77c6c03b12c8d87076d97d9f5740d0a5ecc78b0', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 6, 'created': '2018-10-25 06:23:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6066352e535da40ee269b3e66f4f70e43db58626', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 7, 'created': '2018-10-29 18:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/eb423471f330fdb44b434e61c3a26b22841f22c7', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 8, 'created': '2018-10-31 01:25:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/90a1a51f0786bf32e8ac24c984af8ebfd4f26951', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 9, 'created': '2018-11-26 18:06:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/4984616e4315b13281af9ef4ac9e4990322a42a4', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 10, 'created': '2018-12-11 04:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/33dd24c02070ab07f35efb7b7bf4914457f40c89', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 11, 'created': '2018-12-12 19:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0c6d11e5f4c9f06cb4aacfd1bb35b3f78ce8327a', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 12, 'created': '2019-01-07 19:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/040be94e539da826ec80bd9808b5b1ff6d09a7d7', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 13, 'created': '2019-01-11 19:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/11da063a03d81405ff8cea740bf6a540273844e9', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 14, 'created': '2019-02-02 00:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9b4c74ae3323428b2fadafe1478b10fa514080be', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 15, 'created': '2019-02-04 18:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b8badd3558b734ae45c1366b96cd5b4fa01f05c6', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}, {'number': 16, 'created': '2019-02-20 04:11:05.000000000', 'files': ['heat/values.yaml', 'cinder/values.yaml', 'nova/values.yaml', 'heat/templates/cron-job-engine-cleaner.yaml', 'nova/templates/cron-job-cell-setup.yaml', 'cinder/templates/cron-job-cinder-volume-usage-audit.yaml', 'nova/templates/cron-job-service-cleaner.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/34a092a7f4a8bdd089d9e55d02f2259f86ab54dd', 'message': 'Add startingDeadlineSeconds field to cronJobs\n\nThis patch set adds ""startingDeadlineSeconds"" field to cronJobs.\nWhen the field is not set, the controller counts how many missed\njobs occured from the last scheduled time till now. And if it happends\nmore than 100 time the job will not be scheduled. To avoid this\nthe ""startingDeadlineSeconds"" field should be set to sufficient period\nof time. In this case the controller counts how many missed jobs occured\nduring this period of time. The value of the field should be less than\ntime (in seconds) needed for running >100 jobs (according to schedule).\n\nChange-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24\n'}]",7,609859,34a092a7f4a8bdd089d9e55d02f2259f86ab54dd,63,7,16,17119,,,0,"Add startingDeadlineSeconds field to cronJobs

This patch set adds ""startingDeadlineSeconds"" field to cronJobs.
When the field is not set, the controller counts how many missed
jobs occured from the last scheduled time till now. And if it happends
more than 100 time the job will not be scheduled. To avoid this
the ""startingDeadlineSeconds"" field should be set to sufficient period
of time. In this case the controller counts how many missed jobs occured
during this period of time. The value of the field should be less than
time (in seconds) needed for running >100 jobs (according to schedule).

Change-Id: I3bf7c7077b55ca5a3421052bd0b59b70c9bbcf24
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/59/609859/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/templates/cron-job-engine-cleaner.yaml', 'nova/templates/cron-job-cell-setup.yaml', 'cinder/templates/cron-job-cinder-volume-usage-audit.yaml', 'nova/templates/cron-job-service-cleaner.yaml']",4,09d1fc4cd6a3c2cd4e4f4d893e1509ca0ee07f20,, startingDeadlineSeconds: 600,,4,0
openstack%2Fpython-zunclient~stable%2Fqueens~Iebb3ddb53e5e9d31175e6e7eeb170a66a8630a17,openstack/python-zunclient,stable/queens,Iebb3ddb53e5e9d31175e6e7eeb170a66a8630a17,Avoid empty values in 'nets' options,ABANDONED,2019-02-20 04:44:04.000000000,2019-02-23 21:05:11.000000000,,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-20 04:44:04.000000000', 'files': ['zunclient/common/utils.py', 'zunclient/tests/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/e89a40fd0381ef02e8c7fc6160d0540396179e8e', 'message': ""Avoid empty values in 'nets' options\n\nThe python-zunclient sends the 'nets' parameter to server\nwith empty string. For example:\n* {'network': xxx, 'port': '', 'v4-fixed-ip': '', 'v6-fixed-ip': ''}\n* {'network': '', 'port': xxx, 'v4-fixed-ip': '', 'v6-fixed-ip': ''}\n\nThis patch changes it to:\n* {'network': xxx}\n* {'port': xxx}\n\nThe new form doesn't contain a key with empty string value.\nThis allows a better validation on the server side in the\nfuture.\n\nChange-Id: Iebb3ddb53e5e9d31175e6e7eeb170a66a8630a17\n(cherry picked from commit 4bc01dfb7fc07bc9f20e3f62d2b2f72a15e79081)\n""}]",0,638078,e89a40fd0381ef02e8c7fc6160d0540396179e8e,4,2,1,11536,,,0,"Avoid empty values in 'nets' options

The python-zunclient sends the 'nets' parameter to server
with empty string. For example:
* {'network': xxx, 'port': '', 'v4-fixed-ip': '', 'v6-fixed-ip': ''}
* {'network': '', 'port': xxx, 'v4-fixed-ip': '', 'v6-fixed-ip': ''}

This patch changes it to:
* {'network': xxx}
* {'port': xxx}

The new form doesn't contain a key with empty string value.
This allows a better validation on the server side in the
future.

Change-Id: Iebb3ddb53e5e9d31175e6e7eeb170a66a8630a17
(cherry picked from commit 4bc01dfb7fc07bc9f20e3f62d2b2f72a15e79081)
",git fetch https://review.opendev.org/openstack/python-zunclient refs/changes/78/638078/1 && git format-patch -1 --stdout FETCH_HEAD,"['zunclient/common/utils.py', 'zunclient/tests/unit/common/test_utils.py']",2,e89a40fd0381ef02e8c7fc6160d0540396179e8e,," self.assertEqual([{'network': '1234567', 'v4-fixed-ip': '172.17.0.3'}], result) self.assertEqual([{'port': '1234567', 'v6-fixed-ip': '2001:db8::2'}],"," self.assertEqual([{'network': '1234567', 'v4-fixed-ip': '172.17.0.3', 'port': '', 'v6-fixed-ip': ''}], result) self.assertEqual([{'network': '', 'v4-fixed-ip': '', 'port': '1234567', 'v6-fixed-ip': '2001:db8::2'}],",10,11
openstack%2Fnova~master~I0046131af691e678503c29c0c08be039bbcdc119,openstack/nova,master,I0046131af691e678503c29c0c08be039bbcdc119,[WIP] Drop MoveClaim in rollback_live_migration_at_destination,ABANDONED,2019-02-22 12:38:46.000000000,2019-02-23 20:44:01.000000000,,"[{'_account_id': 5754}, {'_account_id': 8864}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-22 12:38:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3f0469fa2a23bba3255364d5c580b57f66bf10b', 'message': '[WIP] Drop MoveClaim in rollback_live_migration_at_destination\n\nIf a live migration fails, the MoveClaim that was created for it needs\nt be dropped on the destination to make claimed resources available\nagain. Previously, rollback_live_migration_at_destiation() (rlmad from\nnow on) was only called if cleanup was necessary. This patch changes\nrlmad() to always be called. The do_cleanup boolean is instead passed\nas an argument, and the conditional is now checked on the destination\nduring the call, rather than on the source before the call.\n\nImplements: bp/numa-aware-live-migration\nChange-Id: I0046131af691e678503c29c0c08be039bbcdc119\n'}, {'number': 2, 'created': '2019-02-22 17:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95844689795fd5d658b72ec8ed340aa399db8e6e', 'message': '[WIP] Drop MoveClaim in rollback_live_migration_at_destination\n\nIf a live migration fails, the MoveClaim that was created for it needs\nt be dropped on the destination to make claimed resources available\nagain. Previously, rollback_live_migration_at_destiation() (rlmad from\nnow on) was only called if cleanup was necessary. This patch changes\nrlmad() to always be called. The do_cleanup boolean is instead passed\nas an argument, and the conditional is now checked on the destination\nduring the call, rather than on the source before the call.\n\nImplements: bp/numa-aware-live-migration\nChange-Id: I0046131af691e678503c29c0c08be039bbcdc119\n'}, {'number': 3, 'created': '2019-02-22 18:33:17.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5c9d210be5159bca48665f61d79683eea9ae1065', 'message': '[WIP] Drop MoveClaim in rollback_live_migration_at_destination\n\nIf a live migration fails, the MoveClaim that was created for it needs\nt be dropped on the destination to make claimed resources available\nagain. Previously, rollback_live_migration_at_destiation() (rlmad from\nnow on) was only called if cleanup was necessary. This patch changes\nrlmad() to always be called. The do_cleanup boolean is instead passed\nas an argument, and the conditional is now checked on the destination\nduring the call, rather than on the source before the call.\n\nImplements: bp/numa-aware-live-migration\nChange-Id: I0046131af691e678503c29c0c08be039bbcdc119\n'}]",0,638654,5c9d210be5159bca48665f61d79683eea9ae1065,19,8,3,8864,,,0,"[WIP] Drop MoveClaim in rollback_live_migration_at_destination

If a live migration fails, the MoveClaim that was created for it needs
t be dropped on the destination to make claimed resources available
again. Previously, rollback_live_migration_at_destiation() (rlmad from
now on) was only called if cleanup was necessary. This patch changes
rlmad() to always be called. The do_cleanup boolean is instead passed
as an argument, and the conditional is now checked on the destination
during the call, rather than on the source before the call.

Implements: bp/numa-aware-live-migration
Change-Id: I0046131af691e678503c29c0c08be039bbcdc119
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/638654/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,b3f0469fa2a23bba3255364d5c580b57f66bf10b,bp/numa-aware-live-migration," self.compute_rpcapi.rollback_live_migration_at_destination( context, instance, dest, destroy_disks=destroy_disks, migrate_data=migrate_data, do_cleanup=do_cleanup) migrate_data, do_cleanup): """"""Drop the MoveClaim that was created for the live migration, and if necessary clean up the image directory that was created by pre_live_migration. :param do_cleanups: whether to do any cleanup in addition to dropping the MoveClaim. self.rt.drop_move_claim(context, instance, self._get_nodename(instance), instance.flavor, prefix='_old') if do_cleanup: self._do_rollback_live_migration_at_destination(context, instance, destroy_disks, migrate_data) def _do_rollback_live_migration_at_destination(self, context, instance, destroy_disks, migrate_data)"," if do_cleanup: self.compute_rpcapi.rollback_live_migration_at_destination( context, instance, dest, destroy_disks=destroy_disks, migrate_data=migrate_data) migrate_data): """"""Cleaning up image directory that is created pre_live_migration.",19,6
openstack%2Fnova~master~I791ac7dc1630cebbac6abca9d31dc09b3787bc31,openstack/nova,master,I791ac7dc1630cebbac6abca9d31dc09b3787bc31,Cleanup return_reservation_id in ServersController.create,MERGED,2019-01-28 17:08:27.000000000,2019-02-23 20:36:38.000000000,2019-02-23 20:36:38.000000000,"[{'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-28 17:08:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0489c0f70a5e2a111d74c9f81cd1a3b6d2bc934e', 'message': ""Cleanup return_reservation_id in ServersController.create\n\nThe create() method was getting the return_reservation_id\nvalue out of the request body and putting it into the\ncreate_kwargs dict just to pop it off, which is pointless.\n\nThis change simply avoids messing with the create_kwargs\ndict for return_reservation_id but keeps the comment\nabout why we don't pass it through to API.create().\n\nChange-Id: I791ac7dc1630cebbac6abca9d31dc09b3787bc31\n""}, {'number': 2, 'created': '2019-01-28 17:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5593b0a2a5c82635725dfac59124e9203aa2ed50', 'message': 'Cleanup return_reservation_id in ServersController.create\n\nThe create() method was getting the return_reservation_id\nvalue out of the request body and putting it into the\ncreate_kwargs dict just to pop it off, which is pointless.\n\nThis change simply avoids messing with the create_kwargs\ndict for return_reservation_id and moves it to where it\nis used so the comment block is removed since it is no\nlonger helpful.\n\nChange-Id: I791ac7dc1630cebbac6abca9d31dc09b3787bc31\n'}, {'number': 3, 'created': '2019-02-10 20:51:28.000000000', 'files': ['nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c0cd8fe8c1cb217063eacfa8aa3d4d46093c71a0', 'message': 'Cleanup return_reservation_id in ServersController.create\n\nThe create() method was getting the return_reservation_id\nvalue out of the request body and putting it into the\ncreate_kwargs dict just to pop it off, which is pointless.\n\nThis change simply avoids messing with the create_kwargs\ndict for return_reservation_id and moves it to where it\nis used so the comment block is removed since it is no\nlonger helpful.\n\nChange-Id: I791ac7dc1630cebbac6abca9d31dc09b3787bc31\n'}]",1,633560,c0cd8fe8c1cb217063eacfa8aa3d4d46093c71a0,65,16,3,6873,,,0,"Cleanup return_reservation_id in ServersController.create

The create() method was getting the return_reservation_id
value out of the request body and putting it into the
create_kwargs dict just to pop it off, which is pointless.

This change simply avoids messing with the create_kwargs
dict for return_reservation_id and moves it to where it
is used so the comment block is removed since it is no
longer helpful.

Change-Id: I791ac7dc1630cebbac6abca9d31dc09b3787bc31
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/633560/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/servers.py'],1,0489c0f70a5e2a111d74c9f81cd1a3b6d2bc934e,server-create-handler-refactor," # NOTE(cyeoh): Although upper layer can set the value of # return_reservation_id in order to request that a reservation # id be returned to the client instead of the newly created # instance information we do not want to pass this parameter # to the compute create call which always returns both. We use # this flag after the instance create call to determine what # to return to the client return_reservation_id = server_dict.get( 'return_reservation_id', False)"," return_id = server_dict.get('return_reservation_id', False) create_kwargs['return_reservation_id'] = return_id # NOTE(cyeoh): Although upper layer can set the value of # return_reservation_id in order to request that a reservation # id be returned to the client instead of the newly created # instance information we do not want to pass this parameter # to the compute create call which always returns both. We use # this flag after the instance create call to determine what # to return to the client return_reservation_id = create_kwargs.pop('return_reservation_id', False) ",9,12
openstack%2Fhorizon~master~Ia7fe27f0361c6e9a69cdbb574b7a9936f8e2d4df,openstack/horizon,master,Ia7fe27f0361c6e9a69cdbb574b7a9936f8e2d4df,oslo.config>=5.2.0 which is a dependency of horizon requires rfc3986>=1.2.0,ABANDONED,2019-01-22 09:56:02.000000000,2019-02-23 19:32:55.000000000,,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}, {'_account_id': 28637}]","[{'number': 1, 'created': '2019-01-22 09:56:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/913bea37f0fc59389e68248b212cb1d7e7eea2bc', 'message': 'oslo.config>=5.2.0 which is a dependency of kolla-ansible requires rfc3986>=1.2.0\n\nChange-Id: Ia7fe27f0361c6e9a69cdbb574b7a9936f8e2d4df\n'}, {'number': 2, 'created': '2019-01-22 09:58:29.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2e8af982c933d4c6bcb0049332ededba72f46190', 'message': 'oslo.config>=5.2.0 which is a dependency of horizon requires rfc3986>=1.2.0\n\nChange-Id: Ia7fe27f0361c6e9a69cdbb574b7a9936f8e2d4df\n'}]",0,632371,2e8af982c933d4c6bcb0049332ededba72f46190,10,4,2,28637,,,0,"oslo.config>=5.2.0 which is a dependency of horizon requires rfc3986>=1.2.0

Change-Id: Ia7fe27f0361c6e9a69cdbb574b7a9936f8e2d4df
",git fetch https://review.opendev.org/openstack/horizon refs/changes/71/632371/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,913bea37f0fc59389e68248b212cb1d7e7eea2bc,,rfc3986==1.2.0,rfc3986==0.3.1,1,1
openstack%2Fironic-tempest-plugin~master~Idb2d556f4c15ceae9ce597e8e62404916becc150,openstack/ironic-tempest-plugin,master,Idb2d556f4c15ceae9ce597e8e62404916becc150,Test BM to BM or BM to VM on same tenent network,ABANDONED,2019-02-23 16:51:23.000000000,2019-02-23 18:22:11.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-23 16:51:23.000000000', 'files': ['ironic_tempest_plugin/tests/scenario/test_baremetal_single_tenant.py'], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/3d02f31171c72e0d8f9792f33a6db26e893e49c0', 'message': 'Test BM to BM or BM to VM on same tenent network\n\nCheck ""No L2 isolation"" and L3 connectivity between instances.\nThis test will be skipped if Nova is not running.\n\nChange-Id: Idb2d556f4c15ceae9ce597e8e62404916becc150\n'}]",0,638851,3d02f31171c72e0d8f9792f33a6db26e893e49c0,3,1,1,28609,,,0,"Test BM to BM or BM to VM on same tenent network

Check ""No L2 isolation"" and L3 connectivity between instances.
This test will be skipped if Nova is not running.

Change-Id: Idb2d556f4c15ceae9ce597e8e62404916becc150
",git fetch https://review.opendev.org/openstack/ironic-tempest-plugin refs/changes/51/638851/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_tempest_plugin/tests/scenario/test_baremetal_single_tenant.py'],1,3d02f31171c72e0d8f9792f33a6db26e893e49c0,single_tenent,"# # Copyright (c) 2015 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.common import utils from tempest import config from tempest.lib.common.utils import data_utils from tempest.lib import decorators from ironic_tempest_plugin import manager from ironic_tempest_plugin.tests.scenario import baremetal_manager CONF = config.CONF class BaremetalSingleTenant(baremetal_manager.BaremetalScenarioTest, manager.NetworkScenarioTest): """"""Check ""No L2 isolation"" of baremetal and VM instances of same tenant: * Create a keypair, network, subnet and router for the primary tenant * Boot 2 instances in the same tenant's network using the keypair * Associate floating ips to both instances * Verify there is L3 connectivity between instances of same tenant * Verify connectivity between instances floating IP's * Delete both instances """""" credentials = ['primary', 'alt', 'admin'] @classmethod def skip_checks(cls): super(BaremetalSingleTenant, cls).skip_checks() if not CONF.baremetal.use_provision_network: msg = 'Ironic/Neutron tenant isolation is not configured.' raise cls.skipException(msg) if (CONF.baremetal.available_nodes is not None and CONF.baremetal.available_nodes < 2): msg = ('Not enough baremetal nodes, %d configured, test requires ' 'a minimum of 2') % CONF.baremetal.available_nodes raise cls.skipException(msg) def create_tenant_network(self, clients, tenant_cidr): network = self._create_network( networks_client=clients.networks_client, tenant_id=clients.credentials.tenant_id) router = self._get_router( client=clients.routers_client, tenant_id=clients.credentials.tenant_id) result = clients.subnets_client.create_subnet( name=data_utils.rand_name('subnet'), network_id=network['id'], tenant_id=clients.credentials.tenant_id, ip_version=4, cidr=tenant_cidr) subnet = result['subnet'] clients.routers_client.add_router_interface(router['id'], subnet_id=subnet['id']) self.addCleanup(clients.subnets_client.delete_subnet, subnet['id']) self.addCleanup(clients.routers_client.remove_router_interface, router['id'], subnet_id=subnet['id']) return network, subnet, router def verify_l3_connectivity(self, source_ip, private_key, destination_ip, conn_expected=True): remote = self.get_remote_client(source_ip, private_key=private_key) remote.validate_authentication() cmd = 'ping %s -c4 -w4 || exit 0' % destination_ip success_substring = ""64 bytes from %s"" % destination_ip output = remote.exec_command(cmd) if conn_expected: self.assertIn(success_substring, output) else: self.assertNotIn(success_substring, output) def tenancy_check(self, use_vm=False): tenant_cidr = '10.0.100.0/24' keypair = self.create_keypair() network, subnet, router = self.create_tenant_network( self.os_primary, tenant_cidr) instance1, node1 = self.boot_instance( clients=self.os_primary, keypair=keypair, net_id=network['id'], ) fixed_ip1 = instance1['addresses'][network['name']][0]['addr'] floating_ip1 = self.create_floating_ip( instance1, )['floating_ip_address'] self.check_vm_connectivity(ip_address=floating_ip1, private_key=keypair['private_key']) if use_vm: # Create VM on compute node instance2 = self.create_server( clients=self.os_primary, key_name=keypair['name'], flavor=CONF.compute.flavor_ref, networks=[{'uuid': network['id']}] ) else: # Create BM instance2, node2 = self.boot_instance( keypair=keypair, clients=self.os_primary, net_id=network['id'], ) fixed_ip2 = \ instance2['addresses'][network['name']][0]['addr'] floating_ip2 = self.create_floating_ip( instance2, client=self.os_primary.floating_ips_client )['floating_ip_address'] self.check_vm_connectivity( ip_address=floating_ip2, private_key=keypair['private_key']) self.verify_l3_connectivity( floating_ip2, keypair['private_key'], fixed_ip1, conn_expected=True ) self.verify_l3_connectivity( floating_ip1, keypair['private_key'], fixed_ip2, conn_expected=True ) self.verify_l3_connectivity( floating_ip1, keypair['private_key'], floating_ip2, conn_expected=True ) self.terminate_instance( instance=instance2, servers_client=self.os_primary.servers_client) self.terminate_instance(instance=instance1) @decorators.idempotent_id('8fe15552-3788-11e9-b599-74e5f9e2a801') @utils.services('compute', 'image', 'network') def test_baremetal_single_tenant(self): self.tenancy_check() @decorators.idempotent_id('90b3b6be-3788-11e9-b599-74e5f9e2a801') @utils.services('compute', 'image', 'network') def test_baremetal_vm_single_tenant(self): if not CONF.service_available.nova: self.skipTest('Compute service Nova is disabled,' ' VM is required to run this test') self.tenancy_check(use_vm=True) ",,169,0
openstack%2Fopenstack-ansible-os_zun~master~Ia3a8b9227c2803d7acf0a8da358b7d4e6b1eb1c6,openstack/openstack-ansible-os_zun,master,Ia3a8b9227c2803d7acf0a8da358b7d4e6b1eb1c6,Do not ping neutron router during tempest test,ABANDONED,2019-02-22 20:00:51.000000000,2019-02-23 17:28:46.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-22 20:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/02542db7008af3aa4d6ad374e105512cd2fdb79e', 'message': 'Do not ping neutron router during tempest test\n\nThere is no IP address associated with vlan_address, so disable\nthe ping test\n\nChange-Id: Ia3a8b9227c2803d7acf0a8da358b7d4e6b1eb1c6\n'}, {'number': 2, 'created': '2019-02-22 20:50:52.000000000', 'files': ['tests/group_vars/all_containers.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/11a3c40cf5aa49f6b52ec8057baddc94073a97cd', 'message': 'Do not ping neutron router during tempest test\n\nThere is no IP address associated with vlan_address, so disable\nthe ping test\n\nDepends-On: https://review.openstack.org/632131\nChange-Id: Ia3a8b9227c2803d7acf0a8da358b7d4e6b1eb1c6\n'}]",0,638761,11a3c40cf5aa49f6b52ec8057baddc94073a97cd,5,1,2,25023,,,0,"Do not ping neutron router during tempest test

There is no IP address associated with vlan_address, so disable
the ping test

Depends-On: https://review.openstack.org/632131
Change-Id: Ia3a8b9227c2803d7acf0a8da358b7d4e6b1eb1c6
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_zun refs/changes/61/638761/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/group_vars/all_containers.yml'],1,02542db7008af3aa4d6ad374e105512cd2fdb79e,,tempest_network_ping_gateway: False ,,2,0
openstack%2Fmagnum~master~I5a92105f7cfbcabf521150d65f89b14cea62db0f,openstack/magnum,master,I5a92105f7cfbcabf521150d65f89b14cea62db0f,Add python 3.6 unit test job,MERGED,2018-11-08 04:32:36.000000000,2019-02-23 17:13:53.000000000,2019-02-23 17:13:53.000000000,"[{'_account_id': 6484}, {'_account_id': 8064}, {'_account_id': 20498}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-08 04:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a4bce8d2ec87601f5d8f6a376578b41cc56eb6ad', 'message': 'Add python 3.6 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.6 as part of the python3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I5a92105f7cfbcabf521150d65f89b14cea62db0f\n'}, {'number': 2, 'created': '2019-02-23 07:01:36.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/magnum/commit/055384343fc3c23ed6247389e4c41ce803cd187e', 'message': 'Add python 3.6 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.6 as part of the python3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I5a92105f7cfbcabf521150d65f89b14cea62db0f\n'}]",0,616413,055384343fc3c23ed6247389e4c41ce803cd187e,9,4,2,28956,,,0,"Add python 3.6 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.6 as part of the python3-first goal.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I5a92105f7cfbcabf521150d65f89b14cea62db0f
",git fetch https://review.opendev.org/openstack/magnum refs/changes/13/616413/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a4bce8d2ec87601f5d8f6a376578b41cc56eb6ad,py36-first,"envlist = py36,py35,py27,pep8","envlist = py35,py27,pep8",1,1
openstack%2Fplacement~master~I9b3a990d3c635cf09e2016bda0da9cc4fb395873,openstack/placement,master,I9b3a990d3c635cf09e2016bda0da9cc4fb395873,Set timestamps in Allocation objects,MERGED,2019-02-21 06:25:17.000000000,2019-02-23 15:58:19.000000000,2019-02-23 15:58:19.000000000,"[{'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 06:25:17.000000000', 'files': ['placement/tests/unit/objects/test_resource_provider.py', 'placement/objects/resource_provider.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/3375cff2fecf18af626b8b53f18dd9c23b2a4cb8', 'message': ""Set timestamps in Allocation objects\n\nThe following methods return an AllocationList object\nwhich contains a list of Allocation objects that\ndo not have the 'created_at' and 'updated_at' values.\n\n* get_all_by_resource_provider in AllocationList object\n* get_all_by_consumer_id in AllocationList object\n\nIt causes wrong last-modified response headers\nin the following APIs.\n\n* GET /allocations/{consumer_uuid}\n* GET /resource_providers/{uuid}/allocations\n\nSo set the 'created_at' and 'updated_at' values of\nthe Allocation objects in the methods.\n\nChange-Id: I9b3a990d3c635cf09e2016bda0da9cc4fb395873\nCloses-Bug: #1816230\n""}]",0,638344,3375cff2fecf18af626b8b53f18dd9c23b2a4cb8,8,3,1,7634,,,0,"Set timestamps in Allocation objects

The following methods return an AllocationList object
which contains a list of Allocation objects that
do not have the 'created_at' and 'updated_at' values.

* get_all_by_resource_provider in AllocationList object
* get_all_by_consumer_id in AllocationList object

It causes wrong last-modified response headers
in the following APIs.

* GET /allocations/{consumer_uuid}
* GET /resource_providers/{uuid}/allocations

So set the 'created_at' and 'updated_at' values of
the Allocation objects in the methods.

Change-Id: I9b3a990d3c635cf09e2016bda0da9cc4fb395873
Closes-Bug: #1816230
",git fetch https://review.opendev.org/openstack/placement refs/changes/44/638344/1 && git format-patch -1 --stdout FETCH_HEAD,"['placement/tests/unit/objects/test_resource_provider.py', 'placement/objects/resource_provider.py']",2,3375cff2fecf18af626b8b53f18dd9c23b2a4cb8,bug/1816230," allocs.c.created_at, allocs.c.updated_at, used=rec['used'], created_at=rec['created_at'], updated_at=rec['updated_at'])) used=rec['used'], created_at=rec['created_at'], updated_at=rec['updated_at'])", used=rec['used'])) used=rec['used']),62,8
openstack%2Fnova~master~Ia58599f783a915662eb2701ac40e9a5b948621a5,openstack/nova,master,Ia58599f783a915662eb2701ac40e9a5b948621a5,Move finish_resize.(start|end) notifications to helper method,MERGED,2019-02-06 00:34:31.000000000,2019-02-23 14:59:10.000000000,2019-02-23 14:59:09.000000000,"[{'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11604}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-06 00:34:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/05df13e16e175fc54d06036f071901d533c90cdd', 'message': 'Move finish_resize.(start|end) notifications to helper method\n\nThis refactors the finish_resize.start/end notification sending\ncode to a helper method.\n\nChange-Id: Ia58599f783a915662eb2701ac40e9a5b948621a5\n'}, {'number': 2, 'created': '2019-02-07 21:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/abc0a8abd8648d95c7e52ee595173f50a3c42cec', 'message': 'Move finish_resize.(start|end) notifications to helper method\n\nThis refactors the finish_resize.start/end notification sending\ncode to a helper method.\n\nChange-Id: Ia58599f783a915662eb2701ac40e9a5b948621a5\n'}, {'number': 3, 'created': '2019-02-11 19:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb7d312ef73283bb4f332d96eeff68aaa32c982e', 'message': 'Move finish_resize.(start|end) notifications to helper method\n\nThis refactors the finish_resize.start/end notification sending\ncode to a helper method.\n\nChange-Id: Ia58599f783a915662eb2701ac40e9a5b948621a5\n'}, {'number': 4, 'created': '2019-02-12 18:28:20.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f548c91da693aa3ce1b4277c250601f799db9512', 'message': 'Move finish_resize.(start|end) notifications to helper method\n\nThis refactors the finish_resize.start/end notification sending\ncode to a helper method.\n\nChange-Id: Ia58599f783a915662eb2701ac40e9a5b948621a5\n'}]",4,635079,f548c91da693aa3ce1b4277c250601f799db9512,73,16,4,6873,,,0,"Move finish_resize.(start|end) notifications to helper method

This refactors the finish_resize.start/end notification sending
code to a helper method.

Change-Id: Ia58599f783a915662eb2701ac40e9a5b948621a5
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/635079/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,05df13e16e175fc54d06036f071901d533c90cdd,bp/cross-cell-resize," self._send_finish_resize_notifications( context, instance, bdms, network_info, fields.NotificationPhase.START) self._send_finish_resize_notifications( context, instance, bdms, network_info, fields.NotificationPhase.END) def _send_finish_resize_notifications( self, context, instance, bdms, network_info, phase): """"""Send notifications for the finish_resize flow. :param context: nova auth request context :param instance: The instance being resized :param bdms: BlockDeviceMappingList for the BDMs associated with the instance :param network_info: NetworkInfo for the instance info cache of ports :param phase: The phase of the action (NotificationPhase enum, either ``start`` or ``end``) """""" # Send the legacy unversioned notification. context, instance, ""finish_resize.%s"" % phase, # Send the versioned notification. compute_utils.notify_about_instance_action( context, instance, self.host, action=fields.NotificationAction.RESIZE_FINISH, phase=phase, bdms=bdms)"," self._notify_about_instance_usage( context, instance, ""finish_resize.start"", network_info=network_info) compute_utils.notify_about_instance_action(context, instance, self.host, action=fields.NotificationAction.RESIZE_FINISH, phase=fields.NotificationPhase.START, bdms=bdms) context, instance, ""finish_resize.end"", compute_utils.notify_about_instance_action(context, instance, self.host, action=fields.NotificationAction.RESIZE_FINISH, phase=fields.NotificationPhase.END, bdms=bdms)",26,10
openstack%2Fnova~master~Ice3fdbfe091e8e008ab4875a74030a61cd006193,openstack/nova,master,Ice3fdbfe091e8e008ab4875a74030a61cd006193,Refactor bdm handling in ServersController.create method,MERGED,2019-01-28 15:50:50.000000000,2019-02-23 14:59:02.000000000,2019-02-23 14:59:01.000000000,"[{'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-28 15:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bad78b8086247bea40f62ee4755dfb442041250c', 'message': 'Refactor bdm handling in ServersController.create method\n\nThe create() method in ServersController is way too long\nand complicated and should be refactored.\n\nThis change splits out the BDM parameter handling to a helper\nmethod.\n\nChange-Id: Ice3fdbfe091e8e008ab4875a74030a61cd006193\n'}, {'number': 2, 'created': '2019-02-10 20:51:28.000000000', 'files': ['nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/487bed050455047a2a03c4f513f542340659b385', 'message': 'Refactor bdm handling in ServersController.create method\n\nThe create() method in ServersController is way too long\nand complicated and should be refactored.\n\nThis change splits out the BDM parameter handling to a helper\nmethod.\n\nChange-Id: Ice3fdbfe091e8e008ab4875a74030a61cd006193\n'}]",0,633535,487bed050455047a2a03c4f513f542340659b385,60,15,2,6873,,,0,"Refactor bdm handling in ServersController.create method

The create() method in ServersController is way too long
and complicated and should be refactored.

This change splits out the BDM parameter handling to a helper
method.

Change-Id: Ice3fdbfe091e8e008ab4875a74030a61cd006193
",git fetch https://review.opendev.org/openstack/nova refs/changes/35/633535/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/servers.py'],1,bad78b8086247bea40f62ee4755dfb442041250c,server-create-handler-refactor," @staticmethod def _process_bdms_for_create( context, target, server_dict, create_kwargs, supports_device_tagging): """"""Processes block_device_mapping(_v2) req parameters for server create :param context: The nova auth request context :param target: The target dict for ``context.can`` policy checks :param server_dict: The POST /servers request body ""server"" entry :param create_kwargs: dict that gets populated by this method and passed to nova.comptue.api.API.create() :param supports_device_tagging: True if a suitable microversion was provided for bdm tags during server create, False otherwise :raises: webob.exc.HTTPBadRequest if the request parameters are invalid :raises: nova.exception.Forbidden if a policy check fails """""" block_device_mapping_legacy = server_dict.get('block_device_mapping', []) block_device_mapping_v2 = server_dict.get('block_device_mapping_v2', []) if block_device_mapping_legacy and block_device_mapping_v2: expl = _('Using different block_device_mapping syntaxes ' 'is not allowed in the same request.') raise exc.HTTPBadRequest(explanation=expl) if block_device_mapping_legacy: for bdm in block_device_mapping_legacy: if 'delete_on_termination' in bdm: bdm['delete_on_termination'] = strutils.bool_from_string( bdm['delete_on_termination']) create_kwargs[ 'block_device_mapping'] = block_device_mapping_legacy # Sets the legacy_bdm flag if we got a legacy block device mapping. create_kwargs['legacy_bdm'] = True elif block_device_mapping_v2: # Have to check whether --image is given, see bug 1433609 image_href = server_dict.get('imageRef') image_uuid_specified = image_href is not None try: block_device_mapping = [ block_device.BlockDeviceDict.from_api(bdm_dict, image_uuid_specified) for bdm_dict in block_device_mapping_v2] except exception.InvalidBDMFormat as e: raise exc.HTTPBadRequest(explanation=e.format_message()) create_kwargs['block_device_mapping'] = block_device_mapping # Unset the legacy_bdm flag if we got a block device mapping. create_kwargs['legacy_bdm'] = False block_device_mapping = create_kwargs.get(""block_device_mapping"") if block_device_mapping: context.can(server_policies.SERVERS % 'create:attach_volume', target) for bdm in block_device_mapping: if bdm.get('tag', None) and not supports_device_tagging: msg = _('Block device tags are not yet supported.') raise exc.HTTPBadRequest(explanation=msg) self._process_bdms_for_create( context, target, server_dict, create_kwargs, supports_device_tagging)"," block_device_mapping_legacy = server_dict.get('block_device_mapping', []) block_device_mapping_v2 = server_dict.get('block_device_mapping_v2', []) if block_device_mapping_legacy and block_device_mapping_v2: expl = _('Using different block_device_mapping syntaxes ' 'is not allowed in the same request.') raise exc.HTTPBadRequest(explanation=expl) if block_device_mapping_legacy: for bdm in block_device_mapping_legacy: if 'delete_on_termination' in bdm: bdm['delete_on_termination'] = strutils.bool_from_string( bdm['delete_on_termination']) create_kwargs[ 'block_device_mapping'] = block_device_mapping_legacy # Sets the legacy_bdm flag if we got a legacy block device mapping. create_kwargs['legacy_bdm'] = True elif block_device_mapping_v2: # Have to check whether --image is given, see bug 1433609 image_href = server_dict.get('imageRef') image_uuid_specified = image_href is not None try: block_device_mapping = [ block_device.BlockDeviceDict.from_api(bdm_dict, image_uuid_specified) for bdm_dict in block_device_mapping_v2] except exception.InvalidBDMFormat as e: raise exc.HTTPBadRequest(explanation=e.format_message()) create_kwargs['block_device_mapping'] = block_device_mapping # Unset the legacy_bdm flag if we got a block device mapping. create_kwargs['legacy_bdm'] = False block_device_mapping = create_kwargs.get(""block_device_mapping"") if block_device_mapping: context.can(server_policies.SERVERS % 'create:attach_volume', target) for bdm in block_device_mapping: if bdm.get('tag', None) and not supports_device_tagging: msg = _('Block device tags are not yet supported.') raise exc.HTTPBadRequest(explanation=msg)",62,42
openstack%2Fnova~master~I0c764e441993e32aafef0b18049a425c3c832a50,openstack/nova,master,I0c764e441993e32aafef0b18049a425c3c832a50,Fill the RequestGroup mapping during schedule,MERGED,2018-11-22 11:46:23.000000000,2019-02-23 14:25:32.000000000,2019-02-22 05:41:58.000000000,"[{'_account_id': 7}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15554}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-11-22 11:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e85e7954da2885a8f3f6bcbaa0beb2a9395d9132', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nTODO:\n* unit test coverage\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 2, 'created': '2018-11-22 12:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cfd243aca7297b19fe08939a65dd107038f302b5', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nTODO:\n* unit test coverage\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 3, 'created': '2018-11-23 15:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d03a6c962ad32f44fcf8c79015756269f9ded7bd', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 4, 'created': '2018-12-10 09:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb8123a2acda4dfb05fa0b56ccc7558d2c892570', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 5, 'created': '2018-12-14 14:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b153ac1cb5616c39d2bd0ec3626e18c3710e31f', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 6, 'created': '2018-12-18 15:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ab4d89358761fe96a16b0889595e70858a6d4bf', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 7, 'created': '2018-12-19 15:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/21f6a2efc0579efc1b343e331a76b19867cc93fa', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 8, 'created': '2018-12-20 10:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09154205b5166eb5ee186b8bff54530cdc072fe6', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 9, 'created': '2018-12-20 16:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b77a8e44bd46c88b080ca0fca000d123fafe7451', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 10, 'created': '2019-01-14 16:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/00ae1497f32cf8e30c8ffc6f042afb992ce95771', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 11, 'created': '2019-01-24 16:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f1b2edfcc525a081a3b88a92872c99179bb63435', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 12, 'created': '2019-01-26 16:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8213af07f342a6f43778b6bf52f26d4cad814a1e', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 13, 'created': '2019-01-28 14:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab3c01e883a8db5a2d8843552261f18053f4d678', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 14, 'created': '2019-02-05 10:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fcef2be6838914213656c4b608b093c1b5b0e0df', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 15, 'created': '2019-02-06 15:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c56f0830e0f74f67b5c8ffb48b83874dcef6ad9', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 16, 'created': '2019-02-08 01:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c13dd195994abcc4c666eea7b407a1351fdf501', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 17, 'created': '2019-02-12 16:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2db2839be9864f054a430b2013fdc3ba09a4eb69', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 18, 'created': '2019-02-13 10:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/361a6186d12cb4c3616a64cf46dff52c243aebc2', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 19, 'created': '2019-02-15 13:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45029a1ceb8177bf02fd0410c8db2201a749b720', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 20, 'created': '2019-02-15 13:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ab1be728bd51f9214e867845183939dc32c355e', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 21, 'created': '2019-02-18 13:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/509d346f94bd63fdb1d72d0cb0a858b5d3d9d18e', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 22, 'created': '2019-02-18 13:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4555c274762e38958642447ba9dd32b8070a3670', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 23, 'created': '2019-02-20 06:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/643df71a157bbdde07b2a0f7b3aed8d494d67d8b', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 24, 'created': '2019-02-20 06:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/479436f0a46b0bdb153987341f83bbacb868d863', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 25, 'created': '2019-02-20 06:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37202ba8dcb504fed8abb639ce4c7e3ab1cbf449', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 26, 'created': '2019-02-20 08:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/91c6e0cc0194f16e579dfa38d29b19da4671c413', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}, {'number': 27, 'created': '2019-02-21 11:45:01.000000000', 'files': ['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f5d236f868a598f8f241df759c516ec49e3779b0', 'message': 'Fill the RequestGroup mapping during schedule\n\nUse the previously introduced map_requested_resources_to_providers()\nfunction in the RequestSpec during the scheduling of a new server. This\nis done in the conductor becase later when placement will return such mapping\nthis will be the place when that mapping can be moved form the Selection\nobject returned by the scheduler to the RequestSpec.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: I0c764e441993e32aafef0b18049a425c3c832a50\n'}]",39,619528,f5d236f868a598f8f241df759c516ec49e3779b0,274,22,27,9708,,,0,"Fill the RequestGroup mapping during schedule

Use the previously introduced map_requested_resources_to_providers()
function in the RequestSpec during the scheduling of a new server. This
is done in the conductor becase later when placement will return such mapping
this will be the place when that mapping can be moved form the Selection
object returned by the scheduler to the RequestSpec.

blueprint bandwidth-resource-provider

Change-Id: I0c764e441993e32aafef0b18049a425c3c832a50
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/619528/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/conductor/manager.py'],1,e85e7954da2885a8f3f6bcbaa0beb2a9395d9132,bp/bandwidth-resource-provider," def _fill_provider_mapping(self, context, instance_uuid, request_spec): """"""Fills out the request group - resource provider mapping in the request spec. This is a workaround as placement does not return which PR fulfills which granular request group in the allocation candidate request. There is a spec proposing a solution in placement: https://review.openstack.org/#/c/597601/ When that spec is implemented then this function can be replaced with a simpler code that copies the group - RP mapping out from the Selection object returned by the scheduler's select_destinations call. """""" allocs = self.report_client.get_allocations_for_consumer( context, instance_uuid) provider_traits = { rp_uuid: self.report_client._get_provider_traits( context, rp_uuid).traits for rp_uuid in allocs} request_spec.map_requested_resources_to_providers( allocs, provider_traits) try: self._fill_provider_mapping( context, instance.uuid, request_spec) except Exception as exc: with excutils.save_and_reraise_exception(): self._cleanup_build_artifacts(context, exc, instances, build_requests, request_specs, cell_mapping_cache) ",,33,0
openstack%2Ftripleo-ci~master~Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73,openstack/tripleo-ci,master,Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73,Make build-containers job definition reusable,MERGED,2019-02-20 08:54:12.000000000,2019-02-23 14:05:07.000000000,2019-02-23 14:05:07.000000000,"[{'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 28239}]","[{'number': 1, 'created': '2019-02-20 08:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7b2dd5a44a3a435012ec653dbe1a3c0c7e9761c3', 'message': 'Change build-container jobs definition to allow reuse\n\nAllows us to use build-containers-fedora-28 job on rdo and to\nhave periodic jobs that are not affected by the file patterns.\n\nChange-Id: Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73\n'}, {'number': 2, 'created': '2019-02-20 08:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/85b38d6da1eda0ceaa68812b625528a94ee5bc20', 'message': 'Change build-container jobs definition to allow reuse\n\nAllows us to use build-containers-fedora-28 job on rdo and to\nhave periodic jobs that are not affected by the file patterns.\n\nChange-Id: Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73\n'}, {'number': 3, 'created': '2019-02-20 08:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/69ae3f5c51710f8b7f3022180f2b7d3388251f2a', 'message': 'Change build-container jobs definition to allow reuse\n\nAllows us to use build-containers-fedora-28 job on rdo and to\nhave periodic jobs that are not affected by the file patterns.\n\nChange-Id: Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73\n'}, {'number': 4, 'created': '2019-02-20 08:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c3a185fcb9a79d9208583b24fb425d720ffc84a2', 'message': 'Change build-container jobs definition to allow reuse\n\nAllows us to use build-containers-fedora-28 job on rdo and to\nhave periodic jobs that are not affected by the file patterns.\n\nChange-Id: Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73\n'}, {'number': 5, 'created': '2019-02-20 09:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2162081c7562af8d25e478bc115a622d396bc03c', 'message': 'Change build-container jobs definition to allow reuse\n\nAllows us to use build-containers-fedora-28 job on rdo and to\nhave periodic jobs that are not affected by the file patterns.\n\nChange-Id: Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73\n'}, {'number': 6, 'created': '2019-02-20 09:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9cc3b0dea1e8f6bde229fde2763deeede5c265ab', 'message': 'Change build-container jobs definition to allow reuse\n\nAllows us to use build-containers-fedora-28 job on rdo and to\nhave periodic jobs that are not affected by the file patterns.\n\nChange-Id: Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73\n'}, {'number': 7, 'created': '2019-02-20 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f96fd4b85bc06ac9bbd97e69cceb7c263ac14d48', 'message': 'Make build-containers job definition reusable\n\nAllows us to use build-containers-fedora-28 job on rdo that would\ninherit the upstream definition.\n\nAvoid issue that prevented use in periodic jobs due to file-patters.\n\nFrom now on all base jobs that do have file patterns define should have\na `-base-wf` suffix instead of just `-base`, which will mean\n""with-files"", so we can avoid accidental use in periodic jobs.\n\nAdds missing patterns on triple-repos which is used by build-containers\nin order to avoid making changes to it that would break these jobs.\n\nChange-Id: Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73\nNeeded-By: https://review.rdoproject.org/r/#/c/18913/\n'}, {'number': 8, 'created': '2019-02-20 10:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5fb2c4fa53cb773274fd7f8bc891643291dd36d4', 'message': 'Make build-containers job definition reusable\n\nAllows us to use build-containers-fedora-28 job on rdo that would\ninherit the upstream definition.\n\nFrom now on all base jobs that do have file patterns define should have\na `-base-wf` suffix instead of just `-base`, which will mean\n""with-files"", so we can avoid accidental use in periodic jobs.\n\nWe need to use two base jobs because normal jobs do need file\nfilters and periodic ones cannot use them. Luckly, we can parent one\non another to avoid repetition.\n\nAdds missing patterns on triple-repos which is used by build-containers\nin order to avoid making changes to it that would break these jobs.\n\nChange-Id: Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73\nNeeded-By: https://review.rdoproject.org/r/#/c/18913/\n'}, {'number': 9, 'created': '2019-02-20 15:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a49162860c5c982bbcf24ee900f3b105adcbf44f', 'message': 'Make build-containers job definition reusable\n\nAllows us to define build-containers-fedora-28 job on rdo that would\ninherit the upstream definition.\n\nBase jobs that do have file patterns define should have a\n`-base-with-files` suffix instead of just `-base`, so we can avoid\naccidental use in periodic jobs.\n\nAdds missing patterns on triple-repos which is used by build-containers\nin order to avoid making changes to it that would break these jobs.\n\nChange-Id: Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73\nNeeded-By: https://review.rdoproject.org/r/#/c/18913/\nRelated-To: https://storyboard.openstack.org/#!/story/2005040\n'}, {'number': 10, 'created': '2019-02-20 15:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ae693c73cc725ea7319664b31c4d83a8ddabab26', 'message': 'Make build-containers job definition reusable\n\nAllows us to define build-containers-fedora-28 job on rdo that would\ninherit the upstream definition.\n\nBase jobs that do have file patterns define should have a\n`-base-with-files` suffix instead of just `-base`, so we can avoid\naccidental use in periodic jobs.\n\nAdds missing patterns on triple-repos which is used by build-containers\nin order to avoid making changes to it that would break these jobs.\n\nChange-Id: Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73\nNeeded-By: https://review.rdoproject.org/r/#/c/18913/\nRelated-To: https://storyboard.openstack.org/#!/story/2005040\n'}, {'number': 11, 'created': '2019-02-21 14:43:29.000000000', 'files': ['zuul.d/build-containers.yaml', 'zuul.d/base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bf9158538881fdc34bc1c4f39a1e77fac76dfdde', 'message': 'Make build-containers job definition reusable\n\nAllows us to define build-containers-fedora-28 job on rdo that would\ninherit the upstream definition.\n\nBase jobs that do have file patterns define should have a\n`-base-with-files` suffix instead of just `-base`, so we can avoid\naccidental use in periodic jobs.\n\nAdds missing patterns on triple-repos which is used by build-containers\nin order to avoid making changes to it that would break these jobs.\n\nChange-Id: Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73\nNeeded-By: https://review.rdoproject.org/r/#/c/18913/\nRelated-To: https://storyboard.openstack.org/#!/story/2005040\n'}]",10,638108,bf9158538881fdc34bc1c4f39a1e77fac76dfdde,54,12,11,24162,,,0,"Make build-containers job definition reusable

Allows us to define build-containers-fedora-28 job on rdo that would
inherit the upstream definition.

Base jobs that do have file patterns define should have a
`-base-with-files` suffix instead of just `-base`, so we can avoid
accidental use in periodic jobs.

Adds missing patterns on triple-repos which is used by build-containers
in order to avoid making changes to it that would break these jobs.

Change-Id: Ibd0512f1e9bc9c4acb8c0256d1f161bd6d09fe73
Needed-By: https://review.rdoproject.org/r/#/c/18913/
Related-To: https://storyboard.openstack.org/#!/story/2005040
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/08/638108/4 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/build-containers.yaml', 'zuul.d/base.yaml', 'zuul.d/layout.yaml']",3,7b2dd5a44a3a435012ec653dbe1a3c0c7e9761c3,oooq/f28,, templates: - tripleo-standalone-scenarios-full - tripleo-multinode-baremetal-full - tripleo-multinode-container-full - tripleo-multinode-experimental - tripleo-undercloud-jobs - tripleo-multinode-branchful - tripleo-build-containers-jobs,28,8
openstack%2Felection~master~I29b8847a5a7db216f6309b1b560e128839302188,openstack/election,master,I29b8847a5a7db216f6309b1b560e128839302188,Use utils.is_tc_election(),MERGED,2019-02-19 04:39:28.000000000,2019-02-23 13:42:58.000000000,2019-02-23 13:42:58.000000000,"[{'_account_id': 5263}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-19 04:39:28.000000000', 'files': ['openstack_election/cmds/template_emails.py'], 'web_link': 'https://opendev.org/openstack/election/commit/497c79c726082db71941608b950daabd9664b65c', 'message': ""Use utils.is_tc_election()\n\nIt's what it's for after all ;P\n\nChange-Id: I29b8847a5a7db216f6309b1b560e128839302188\n""}]",0,637678,497c79c726082db71941608b950daabd9664b65c,7,3,1,12898,,,0,"Use utils.is_tc_election()

It's what it's for after all ;P

Change-Id: I29b8847a5a7db216f6309b1b560e128839302188
",git fetch https://review.opendev.org/openstack/election refs/changes/78/637678/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_election/cmds/template_emails.py'],1,497c79c726082db71941608b950daabd9664b65c,tools-fix,if utils.is_tc_election():else:,if conf['election_type'] == 'tc':elif conf['election_type'] == 'ptl':,2,2
openstack%2Felection~master~I77b4f930231e6c8930a24e84b67a33490e578d5e,openstack/election,master,I77b4f930231e6c8930a24e84b67a33490e578d5e,Update README for new tools and clean steps no longer needed,MERGED,2019-02-18 05:55:17.000000000,2019-02-23 13:42:57.000000000,2019-02-23 13:42:57.000000000,"[{'_account_id': 5263}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-18 05:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/b364429d978fc31b77a11e4e82a1b864ca4fd6ec', 'message': ""Update README for new tools and clean steps no longer needed\n\nWe now have tools to generate most of the emails we'll need to send.\nDocument how to use them.\n\nWhile there update docs to remove references to adding {tc,ptl}.rst to\nindex.rst.  This is now done auto-magically ;P\n\nChange-Id: I77b4f930231e6c8930a24e84b67a33490e578d5e\n""}, {'number': 2, 'created': '2019-02-19 04:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/f2bd3d299cedc609e06bf5fc040e62569f2b056c', 'message': ""Update README for new tools and clean steps no longer needed\n\nWe now have tools to generate most of the emails we'll need to send.\nDocument how to use them.\n\nWhile there update docs to remove references to adding {tc,ptl}.rst to\nindex.rst.  This is now done auto-magically ;P\n\nChange-Id: I77b4f930231e6c8930a24e84b67a33490e578d5e\n""}, {'number': 3, 'created': '2019-02-19 04:32:11.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/election/commit/5c7ad3f4cdff650d9ba9a9664d217fe8fdeace2a', 'message': ""Update README for new tools and clean steps no longer needed\n\nWe now have tools to generate most of the emails we'll need to send.\nDocument how to use them.\n\nWhile there update docs to remove references to adding {tc,ptl}.rst to\nindex.rst.  This is now done auto-magically ;P\n\nChange-Id: I77b4f930231e6c8930a24e84b67a33490e578d5e\n""}]",1,637457,5c7ad3f4cdff650d9ba9a9664d217fe8fdeace2a,11,3,3,12898,,,0,"Update README for new tools and clean steps no longer needed

We now have tools to generate most of the emails we'll need to send.
Document how to use them.

While there update docs to remove references to adding {tc,ptl}.rst to
index.rst.  This is now done auto-magically ;P

Change-Id: I77b4f930231e6c8930a24e84b67a33490e578d5e
",git fetch https://review.opendev.org/openstack/election refs/changes/57/637457/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,b364429d978fc31b77a11e4e82a1b864ca4fd6ec,tools-fix,"``setup-election-config`` can be used to pick some obvous dates that need to be check by the election offiicals and TC As early as possible but at least a month before election starts: * tox -e venv -- template-emails election_season * tox -e venv -- template-emails nominations_kickoff * tox -evenv -- ci-check-all-candidate-files candidates/release/project/candidates , or* To +Workflow, checks the previous +2 details, find another commits using --limit 5 (optional) * Check candidate list and fix badly generated names through changes to the exception.txt file or requesting the candidate to update thier OSF member profile.* Generate the electorate rolls. This generates the rolls for all project teams even if they aren't going to hold an election. * tox -evenv -- generate-rolls * tox -e venv -- template-emails nominations_last_days * tox -e venv -- template-emails end_nominations * tox -e venv -- template-emails voting_kickoff * tox -e venv -- template-emails voting_last_days * This is doc/source/results/release/announce_ptl.rst generated by building the docs: toc -e docs After doc/source/results/release/ptl.yaml has been created and updated``setup-election-config`` can be used to pick some obvous dates that need to be check by the election offiicals and TC As early as possible but at least a month before election starts: * tox -e venv -- template-emails election_season * tox -e venv -- template-emails nominations_kickoff * tox -e venv -- template-emails nominations_last_days * tox -e venv -- template-emails end_nominations Once the email deadline is reached: * Ask the TC chair to tag the governance repository * Generate the electorate rolls. TC Campaigning -------------- The TC election includes a perido after the candidates are defined befoer the election for candidates to answer question from the community. Open this with * tox -e venv -- template-emails campaigning_kickoff * tox -e venv -- template-emails voting_kickoff * tox -e venv -- template-emails voting_last_days * This is doc/source/results/release/announce_tc.rst generated by building the docs: toc -e docs After doc/source/results/release/tc.yaml has been created and updated* [Optional]Send 'TC Election Statistics'","A month before election starts:* Update index.rst to include ptl.rst* To +Workflow, checks the previous +2 details, find another commits using --limit 5 (optionals) * Check candidate list and fix badly generated names through changes to the exception.txt file When PreferredEmailDeadLine is reached: * Ask the TC chair to tag the governance repository with the tag defined in the configuration.yaml* Update index.rst to comment ptl.rst candidate listA month before election starts: * Update index.rst to include tc.rst instead of ptl.rst When PreferredEmailDeadLine is reached: * Generate ATC rolls, e.g.:* Send 'TC Election Statistics'",47,12
openstack%2Felection~master~Ifcc8a376e7d8d9a79ae7a9191cb2452f8cfbae43,openstack/election,master,Ifcc8a376e7d8d9a79ae7a9191cb2452f8cfbae43,Reduce the differences between TC and PTL elections,MERGED,2019-02-12 00:26:52.000000000,2019-02-23 13:38:41.000000000,2019-02-23 13:38:41.000000000,"[{'_account_id': 5263}, {'_account_id': 12898}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 00:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/a88df9e554391daad7bb71f086f9238f04195584', 'message': 'Reduce the differences between TC and PTL elections\n\nIt turns out that structure of the TC and PTL elections is very similar\nand therefore the template choices are basically the same.  Remove the\noverly complex sub-parser and always use the election_type from the YAML\nconfiguration.\n\nAlso many of the fmt_args where shared, or harmless to share between\neach election type.  pull the similar items out and only adds the items\nspecific to each election type\n\nChange-Id: Ifcc8a376e7d8d9a79ae7a9191cb2452f8cfbae43\n'}, {'number': 2, 'created': '2019-02-18 05:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/3f69c7900b244b08a666e52a2e0ad445c38ea26c', 'message': 'Reduce the differences between TC and PTL elections\n\nIt turns out that structure of the TC and PTL elections is very similar\nand therefore the template choices are basically the same.  Remove the\noverly complex sub-parser and always use the election_type from the YAML\nconfiguration.\n\nAlso many of the fmt_args where shared, or harmless to share between\neach election type.  pull the similar items out and only adds the items\nspecific to each election type\n\nChange-Id: Ifcc8a376e7d8d9a79ae7a9191cb2452f8cfbae43\n'}, {'number': 3, 'created': '2019-02-19 04:24:59.000000000', 'files': ['openstack_election/cmds/template_emails.py'], 'web_link': 'https://opendev.org/openstack/election/commit/bb25c953cc49316ed11d8f9cc0e62290e6c2a209', 'message': 'Reduce the differences between TC and PTL elections\n\nIt turns out that structure of the TC and PTL elections is very similar\nand therefore the template choices are basically the same.  Remove the\noverly complex sub-parser and always use the election_type from the YAML\nconfiguration.\n\nAlso many of the fmt_args where shared, or harmless to share between\neach election type.  pull the similar items out and only adds the items\nspecific to each election type\n\nChange-Id: Ifcc8a376e7d8d9a79ae7a9191cb2452f8cfbae43\n'}]",0,636250,bb25c953cc49316ed11d8f9cc0e62290e6c2a209,12,4,3,12898,,,0,"Reduce the differences between TC and PTL elections

It turns out that structure of the TC and PTL elections is very similar
and therefore the template choices are basically the same.  Remove the
overly complex sub-parser and always use the election_type from the YAML
configuration.

Also many of the fmt_args where shared, or harmless to share between
each election type.  pull the similar items out and only adds the items
specific to each election type

Change-Id: Ifcc8a376e7d8d9a79ae7a9191cb2452f8cfbae43
",git fetch https://review.opendev.org/openstack/election refs/changes/50/636250/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack_election/cmds/template_emails.py'],1,a88df9e554391daad7bb71f086f9238f04195584,tools-fix,"template_names = ['election_season', 'nominations_kickoff', 'nominations_last_days', 'end_nominations', 'voting_kickoff', 'voting_last_days'] fmt_args = dict( email_deadline=conf['timeframe']['email_deadline'], end_release=end_release, future_release=end_release.lower(), last_release=end_release.lower(), leaderless_url=LEADERLESS_URL, reference_url=REFERENCE_URL, release=conf['release'], seats=conf['tc_seats'], start_release=start_release, time_frame=time_frame, ) if conf['election_type'] == 'tc': fmt_args.update(dict( )) template_names += ['campaigning_kickoff'] fmt_args.update(dict( )) print(email_text % (fmt_args)) print(email_text % (fmt_args)) print(email_text % (fmt_args)) print(email_text % (fmt_args)) print(email_text % (fmt_args)) print(email_text % (fmt_args)) print(email_text % (fmt_args)) print(email_text % (fmt_args)) print(email_text % (fmt_args)) print(email_text % (fmt_args)) print(email_text % (fmt_args)) parser.add_argument('template', choices=template_names) func_name = ('%(election_type)s_%(template)s' % (dict(election_type=conf['election_type'], template=args.template)))","if conf['election_type'] == 'tc': tc_fmt_args = dict( seats=conf['tc_seats'], time_frame=time_frame, start_release=start_release, end_release=end_release, last_release=end_release.lower(), reference_url=REFERENCE_URL, future_release=end_release.lower(), release=conf['release'], ) ptl_fmt_args = dict( time_frame=time_frame, start_release=start_release, end_release=end_release, future_release=end_release.lower(), email_deadline=conf['timeframe']['email_deadline'], leaderless_url=LEADERLESS_URL, reference_url=REFERENCE_URL, ) print(email_text % (ptl_fmt_args)) print(email_text % (ptl_fmt_args)) print(email_text % (ptl_fmt_args)) print(email_text % (ptl_fmt_args)) print(email_text % (ptl_fmt_args)) print(email_text % (tc_fmt_args)) print(email_text % (tc_fmt_args)) print(email_text % (tc_fmt_args)) print(email_text % (tc_fmt_args)) print(email_text % (tc_fmt_args)) print(email_text % (tc_fmt_args)) # Use a sub parser so we can have different template choices based on the # election_type cmd_parsers = parser.add_subparsers(dest='election_type', help='Type of election.') parser_ptl = cmd_parsers.add_parser('ptl') parser_ptl.add_argument('template', choices=['election_season', 'nominations_kickoff', 'nominations_last_days', 'end_nominations', 'voting_kickoff', 'voting_last_days']) parser_tc = cmd_parsers.add_parser('tc') parser_tc.add_argument('template', choices=['election_season', 'nominations_kickoff', 'nominations_last_days', 'end_nominations', 'campaigning_kickoff', 'voting_kickoff', 'voting_last_days']) if not args.election_type: parser.print_help(sys.stderr) sys.exit(1) if args.election_type != conf['election_type']: print('Requested %s but repo is currently configured for %s' % (args.election_type, conf['election_type'])) sys.exit(1) func_name = '%(election_type)s_%(template)s' % (args.__dict__)",35,55
openstack%2Felection~master~I7aa96e2acb3eca496dda55ded2faddbb09bdbbd1,openstack/election,master,I7aa96e2acb3eca496dda55ded2faddbb09bdbbd1,Remove functionally identical dictionary keys in PTL format,MERGED,2019-02-12 00:26:52.000000000,2019-02-23 13:38:40.000000000,2019-02-23 13:38:40.000000000,"[{'_account_id': 5263}, {'_account_id': 12898}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 00:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/44df0df45c37a28742a4f9cbe1eba55dc1de1261', 'message': ""Remove functionally identical dictionary keys in PTL format\n\nWhile removing the duplication standardize on 'leaderless' as a term to\ndescibe projects without a defined leader (either a single candidate or\nan election).  Also standardize on 'election' rather than 'poll'\n\nnum_projects_without_candidates and projects_no_candidates are\nfunctionally identical so use a new 'leaderless_count' count instead\n\nprojects_polling and list_of_elections are functionally identical so\npick the latter as it aligns with the new terminology\n\nChange-Id: I7aa96e2acb3eca496dda55ded2faddbb09bdbbd1\n""}, {'number': 2, 'created': '2019-02-18 05:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/5026b8aa384ca79728002c1662c8d73860255db1', 'message': ""Remove functionally identical dictionary keys in PTL format\n\nWhile removing the duplication standardize on 'leaderless' as a term to\ndescibe projects without a defined leader (either a single candidate or\nan election).  Also standardize on 'election' rather than 'poll'\n\nnum_projects_without_candidates and projects_no_candidates are\nfunctionally identical so use a new 'leaderless_count' count instead\n\nprojects_polling and list_of_elections are functionally identical so\npick the latter as it aligns with the new terminology\n\nChange-Id: I7aa96e2acb3eca496dda55ded2faddbb09bdbbd1\n""}, {'number': 3, 'created': '2019-02-19 04:24:59.000000000', 'files': ['openstack_election/cmds/template_emails.py'], 'web_link': 'https://opendev.org/openstack/election/commit/be3149f5699f5f64cfb49f8e5e9bd95acd08da28', 'message': ""Remove functionally identical dictionary keys in PTL format\n\nWhile removing the duplication standardize on 'leaderless' as a term to\ndescibe projects without a defined leader (either a single candidate or\nan election).  Also standardize on 'election' rather than 'poll'\n\nnum_projects_without_candidates and projects_no_candidates are\nfunctionally identical so use a new 'leaderless_count' count instead\n\nprojects_polling and list_of_elections are functionally identical so\npick the latter as it aligns with the new terminology\n\nChange-Id: I7aa96e2acb3eca496dda55ded2faddbb09bdbbd1\n""}]",0,636249,be3149f5699f5f64cfb49f8e5e9bd95acd08da28,12,4,3,12898,,,0,"Remove functionally identical dictionary keys in PTL format

While removing the duplication standardize on 'leaderless' as a term to
descibe projects without a defined leader (either a single candidate or
an election).  Also standardize on 'election' rather than 'poll'

num_projects_without_candidates and projects_no_candidates are
functionally identical so use a new 'leaderless_count' count instead

projects_polling and list_of_elections are functionally identical so
pick the latter as it aligns with the new terminology

Change-Id: I7aa96e2acb3eca496dda55ded2faddbb09bdbbd1
",git fetch https://review.opendev.org/openstack/election refs/changes/49/636249/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_election/cmds/template_emails.py'],1,44df0df45c37a28742a4f9cbe1eba55dc1de1261,tools-fix," leaderless_count=len(stats.without_candidate), list_of_leaderless_projects="", "".join(stats.without_candidate), election_count=len(stats.need_election),This means that with approximately 2 days left, %(leaderless_count)s projects willThere are %(leaderless_count)s projects without candidates, so according to thisprojects will proceed: %(list_of_leaderless_projects)s There are %(election_count)s projects that will have elections: %(list_of_elections)s. The details"," num_projects_without_candidates=len(stats.without_candidate), projects_no_candidates=len(stats.without_candidate), list_projects_no_candidates="", "".join(stats.without_candidate), projects_polling=len(stats.need_election), list_projects_polling="", "".join(stats.need_election),This means that with approximately 2 days left, %(num_projects_without_candidates)s projects willThere are %(projects_no_candidates)s projects without candidates, so according to thisprojects will proceed: %(list_projects_no_candidates)s There are %(projects_polling)s projects that will have elections: %(list_projects_polling)s. The details",7,9
openstack%2Felection~master~I02382a01775717c80412e1329c80edcbd988a680,openstack/election,master,I02382a01775717c80412e1329c80edcbd988a680,Standardize the fmt args between TC and PTL templates,MERGED,2019-02-12 00:26:52.000000000,2019-02-23 13:38:40.000000000,2019-02-23 13:38:39.000000000,"[{'_account_id': 5263}, {'_account_id': 12898}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 00:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/9523d7246f45934df07687a91ebdb603cb36b865', 'message': 'Standardize the fmt args between TC and PTL templates\n\nnom_end_date => end_nominations\nstarting_release => start_release\nending_release => end_release\n\nChange-Id: I02382a01775717c80412e1329c80edcbd988a680\n'}, {'number': 2, 'created': '2019-02-18 05:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/233a6c6678b9d54415dc789807b7308ce84a255c', 'message': 'Standardize the fmt args between TC and PTL templates\n\nnom_end_date => end_nominations\nstarting_release => start_release\nending_release => end_release\n\nChange-Id: I02382a01775717c80412e1329c80edcbd988a680\n'}, {'number': 3, 'created': '2019-02-19 04:24:59.000000000', 'files': ['openstack_election/cmds/template_emails.py'], 'web_link': 'https://opendev.org/openstack/election/commit/0fbf277a8f174dc4b1c3d69f0ae73ba8f06b9104', 'message': 'Standardize the fmt args between TC and PTL templates\n\nnom_end_date => end_nominations\nstarting_release => start_release\nending_release => end_release\n\nChange-Id: I02382a01775717c80412e1329c80edcbd988a680\n'}]",0,636248,0fbf277a8f174dc4b1c3d69f0ae73ba8f06b9104,12,4,3,12898,,,0,"Standardize the fmt args between TC and PTL templates

nom_end_date => end_nominations
starting_release => start_release
ending_release => end_release

Change-Id: I02382a01775717c80412e1329c80edcbd988a680
",git fetch https://review.opendev.org/openstack/election refs/changes/48/636248/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack_election/cmds/template_emails.py'],1,9523d7246f45934df07687a91ebdb603cb36b865,tools-fix," end_nominations=utils.get_event('PTL Nominations')['end_str'], start_release=start_release, end_release=end_release,and will remain open until %(end_nominations)s.team[0] during the %(time_frame)s timeframe (%(start_release)s to %(end_release)s). You must also be an OpenStack(%(start_release)s to %(end_release)s) then you are eligible to vote. You should find your"," nom_end_date=utils.get_event('PTL Nominations')['end_str'], starting_release=start_release, ending_release=end_release,and will remain open until %(nom_end_date)s.team[0] during the %(time_frame)s timeframe (%(starting_release)s to %(ending_release)s). You must also be an OpenStack(%(starting_release)s to %(ending_release)s) then you are eligible to vote. You should find your",6,6
openstack%2Felection~master~Ia068917d8465d199c202b2f5bc5387c6b1fb43c6,openstack/election,master,Ia068917d8465d199c202b2f5bc5387c6b1fb43c6,Add ptl_voting_last_days email template,MERGED,2019-02-12 00:26:52.000000000,2019-02-23 13:38:06.000000000,2019-02-23 13:38:06.000000000,"[{'_account_id': 5263}, {'_account_id': 12898}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 00:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/bd86b18f81758d7b54c4d3efc000f7a5fadd3aa9', 'message': 'Add ptl_voting_last_days email template\n\nChange-Id: Ia068917d8465d199c202b2f5bc5387c6b1fb43c6\n'}, {'number': 2, 'created': '2019-02-18 05:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/907497f49080648a6891ef3b1f912eaa4c2583d3', 'message': 'Add ptl_voting_last_days email template\n\nChange-Id: Ia068917d8465d199c202b2f5bc5387c6b1fb43c6\n'}, {'number': 3, 'created': '2019-02-19 04:24:59.000000000', 'files': ['openstack_election/cmds/template_emails.py'], 'web_link': 'https://opendev.org/openstack/election/commit/7a83d4d675aa705c5c8aadddc8556684a8545460', 'message': 'Add ptl_voting_last_days email template\n\nChange-Id: Ia068917d8465d199c202b2f5bc5387c6b1fb43c6\n'}]",0,636247,7a83d4d675aa705c5c8aadddc8556684a8545460,12,4,3,12898,,,0,"Add ptl_voting_last_days email template

Change-Id: Ia068917d8465d199c202b2f5bc5387c6b1fb43c6
",git fetch https://review.opendev.org/openstack/election refs/changes/47/636247/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_election/cmds/template_emails.py'],1,bd86b18f81758d7b54c4d3efc000f7a5fadd3aa9,tools-fix,"def ptl_voting_last_days():Hello %(list_of_elections)s contributors,You have until %(election_end)s. print(email_text % (ptl_fmt_args)) 'voting_kickoff', 'voting_last_days'])","def ptl_voting_last_days(list_of_elections, election_end):Hello %s contributors,You have until %s. print(email_text % (list_of_elections, election_end)) 'voting_kickoff'])",5,6
openstack%2Felection~master~I1e39836f048b7241d2795ca4c24a2c31af10ec3f,openstack/election,master,I1e39836f048b7241d2795ca4c24a2c31af10ec3f,Add ptl_voting_kickoff email template,MERGED,2019-02-12 00:26:52.000000000,2019-02-23 13:38:04.000000000,2019-02-23 13:38:03.000000000,"[{'_account_id': 5263}, {'_account_id': 12898}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 00:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/358c903beaf82ac646ae67c5542b3d8e6d452d7e', 'message': 'Add ptl_voting_kickoff email template\n\nChange-Id: I1e39836f048b7241d2795ca4c24a2c31af10ec3f\n'}, {'number': 2, 'created': '2019-02-18 05:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/9cc1ff71073e7f8bac78f8414fddcdc913f62028', 'message': 'Add ptl_voting_kickoff email template\n\nChange-Id: I1e39836f048b7241d2795ca4c24a2c31af10ec3f\n'}, {'number': 3, 'created': '2019-02-19 04:24:59.000000000', 'files': ['openstack_election/cmds/template_emails.py'], 'web_link': 'https://opendev.org/openstack/election/commit/3559786f978019de1b221be0fb0ebc0a8e613d6f', 'message': 'Add ptl_voting_kickoff email template\n\nChange-Id: I1e39836f048b7241d2795ca4c24a2c31af10ec3f\n'}]",0,636246,3559786f978019de1b221be0fb0ebc0a8e613d6f,12,4,3,12898,,,0,"Add ptl_voting_kickoff email template

Change-Id: I1e39836f048b7241d2795ca4c24a2c31af10ec3f
",git fetch https://review.opendev.org/openstack/election refs/changes/46/636246/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_election/cmds/template_emails.py'],1,358c903beaf82ac646ae67c5542b3d8e6d452d7e,tools-fix," election_end=utils.get_event('PTL Election')['end_str'], list_of_elections="", "".join(stats.need_election), reference_url=REFERENCE_URL,def ptl_voting_kickoff():cast your vote until %(election_end)s. We are having elections for %(list_of_elections)s.one of the program's projects[0] over the %(time_frame)s timeframe (%(starting_release)s to %(ending_release)s) then you are eligible to vote. You should find yourhttp://governance.openstack.org/election/#%(future_release)s-ptl-candidates %(reference_url)s That is where the ballot has been sent."""""" # noqa print(email_text % (ptl_fmt_args)) 'voting_kickoff'])","def ptl_voting_kickoff(election_end, list_of_elections, time_frame, starting_release, ending_release, future_release):cast your vote until %s. We are having elections for %s.one of the program's projects[0] over the %s timeframe (%s to %s) then you are eligible to vote. You should find yourhttp://governance.openstack.org/election/#%s-ptl-candidates %s That is where the ballot has been sent."""""" print(email_text % (election_end, list_of_elections, time_frame, starting_release, ending_release, future_release, REFERENCE_URL)) ])",13,17
openstack%2Felection~master~Iaf8121320fadc618068f4840379e3406a100ea52,openstack/election,master,Iaf8121320fadc618068f4840379e3406a100ea52,Add ptl_end_nominations email template,MERGED,2019-02-12 00:26:52.000000000,2019-02-23 13:27:49.000000000,2019-02-23 13:27:49.000000000,"[{'_account_id': 5263}, {'_account_id': 12898}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 00:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/50431336bd18e62424f8859a70aeaedf16566bde', 'message': 'Add ptl_end_nominations email template\n\nChange-Id: Iaf8121320fadc618068f4840379e3406a100ea52\n'}, {'number': 2, 'created': '2019-02-18 05:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/cfc020f735c6f01474770a1d38d1de4eedc6e1b6', 'message': 'Add ptl_end_nominations email template\n\nChange-Id: Iaf8121320fadc618068f4840379e3406a100ea52\n'}, {'number': 3, 'created': '2019-02-19 04:24:59.000000000', 'files': ['openstack_election/cmds/template_emails.py'], 'web_link': 'https://opendev.org/openstack/election/commit/77edccc0d7ed47f9367a8b326898a80226dce60b', 'message': 'Add ptl_end_nominations email template\n\nChange-Id: Iaf8121320fadc618068f4840379e3406a100ea52\n'}]",0,636245,77edccc0d7ed47f9367a8b326898a80226dce60b,12,4,3,12898,,,0,"Add ptl_end_nominations email template

Change-Id: Iaf8121320fadc618068f4840379e3406a100ea52
",git fetch https://review.opendev.org/openstack/election refs/changes/45/636245/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_election/cmds/template_emails.py'],1,50431336bd18e62424f8859a70aeaedf16566bde,tools-fix," projects_no_candidates=len(stats.without_candidate), list_projects_no_candidates="", "".join(stats.without_candidate), projects_polling=len(stats.need_election), list_projects_polling="", "".join(stats.need_election),def ptl_end_nominations():There are %(projects_no_candidates)s projects without candidates, so according to thisprojects will proceed: %(list_projects_no_candidates)s There are %(projects_polling)s projects that will have elections: %(list_projects_polling)s. The details[0] http://governance.openstack.org/election/#%(future_release)s-ptl-candidates [1] %(leaderless_url)s"""""" # noqa print(email_text % (ptl_fmt_args)) 'nominations_last_days', 'end_nominations',","def ptl_end_nominations(projects_no_candidates, list_projects_no_candidates, projects_polling, list_projects_polling, future_release):There are %s projects without candidates, so according to thisprojects will proceed: %s There are %s projects that will have elections: %s. The details[0] http://governance.openstack.org/election/#%s-ptl-candidates [1] %s"""""" print(email_text % (projects_no_candidates, list_projects_no_candidates, projects_polling, list_projects_polling, future_release, LEADERLESS_URL)) 'nominations_last_days',",12,15
openstack%2Fopenstack-ansible-os_cinder~master~Ic5707615571e62ba2326e2ad436333bac246c8dd,openstack/openstack-ansible-os_cinder,master,Ic5707615571e62ba2326e2ad436333bac246c8dd,"Fix evaluation of cinder_scheduler_default_filters, remove confusing comment",MERGED,2019-02-20 22:47:53.000000000,2019-02-23 13:19:08.000000000,2019-02-23 13:19:08.000000000,"[{'_account_id': 2463}, {'_account_id': 7353}, {'_account_id': 15993}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28008}]","[{'number': 1, 'created': '2019-02-20 22:47:53.000000000', 'files': ['templates/cinder.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/bcc7f1511ef3d01ddabca9fd6f3fbaa772b12c47', 'message': 'Fix evaluation of cinder_scheduler_default_filters, remove confusing comment\n\nChange I12859167d19b9f40e3378ac08fed094a42f40bc7, merged just today,\nput the evaluation of cinder_scheduler_default_filters inside an\n{% if } block that it wasn\'t meant to be inside. As a consequence,\nthat setting would be ignored more often that it would be\nhonored.\n\nWhat threw me (sorry about that) was that I had tested this patch\non a Queens box, and stubbornly copied into the template on master.\n\nAnd changes I02d2bae8712c0ca223cafb5a43304806c4b83125 and\nIb5a128e82e5251077e341b5f428eb097bcc17590 had left the\ntemplate in a somewhat confusing state: the template had retained the\n""## Cinder API\'s enabled"" comment despite the fact that there were\nno settings left to enable or disable any APIs.\n\nSo, with this change the evaluation of cinder_scheduler_default_filters\ngoes to the right place (i.e. outside the {% if } block), *and*\nthe confusing API comment is removed.\n\nChange-Id: Ic5707615571e62ba2326e2ad436333bac246c8dd\n'}]",0,638285,bcc7f1511ef3d01ddabca9fd6f3fbaa772b12c47,20,6,1,2463,,,0,"Fix evaluation of cinder_scheduler_default_filters, remove confusing comment

Change I12859167d19b9f40e3378ac08fed094a42f40bc7, merged just today,
put the evaluation of cinder_scheduler_default_filters inside an
{% if } block that it wasn't meant to be inside. As a consequence,
that setting would be ignored more often that it would be
honored.

What threw me (sorry about that) was that I had tested this patch
on a Queens box, and stubbornly copied into the template on master.

And changes I02d2bae8712c0ca223cafb5a43304806c4b83125 and
Ib5a128e82e5251077e341b5f428eb097bcc17590 had left the
template in a somewhat confusing state: the template had retained the
""## Cinder API's enabled"" comment despite the fact that there were
no settings left to enable or disable any APIs.

So, with this change the evaluation of cinder_scheduler_default_filters
goes to the right place (i.e. outside the {% if } block), *and*
the confusing API comment is removed.

Change-Id: Ic5707615571e62ba2326e2ad436333bac246c8dd
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/85/638285/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/cinder.conf.j2'],1,bcc7f1511ef3d01ddabca9fd6f3fbaa772b12c47,scheduler-filters,{% if cinder_services['cinder-volume']['group'] in group_names %} {% if cinder_service_backup_program_enabled == true %} ,## Cinder API's enabled {% if cinder_services['cinder-volume']['group'] in group_names %} {% if cinder_service_backup_program_enabled == true %} ,3,4
openstack%2Fnova~stable%2Fqueens~I4b34139a3c5e3e2b7cf7cbe50bdf3da3131b9b1c,openstack/nova,stable/queens,I4b34139a3c5e3e2b7cf7cbe50bdf3da3131b9b1c,Handle unicode characters in migration params,MERGED,2019-02-13 17:01:46.000000000,2019-02-23 13:12:34.000000000,2019-02-23 13:12:33.000000000,"[{'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9373}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 20408}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-13 17:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/554ccf1aff4335a708c72dc7c0248480c170fd8b', 'message': ""Handle unicode characters in migration params\n\nThere can be unicode characters in the params for live migration, for\nexample, the guest domain name in the destination XML. We need to\nconvert those to bytes when we call migrateToURI3 under python2.\n\nThe existing code was just calling str() for this, but that will fail\nwith the error:\n\n  UnicodeEncodeError: 'ascii' codec can't encode characters...\n\nWe need to encode the unicode characters to do conversion.\n\nThe existing unit test wasn't using any unicode characters in its test\ndata, so this scenario wasn't covered.\n\nConflicts:\n\tnova/tests/unit/virt/libvirt/test_guest.py\n\tnova/virt/libvirt/guest.py\n\nCloses-Bug: #1768807\n\nChange-Id: I4b34139a3c5e3e2b7cf7cbe50bdf3da3131b9b1c\n(cherry picked from commit f046d8b54009978a3c83939dc190edbc1ebc09ae)\n(cherry picked from commit 7520d159b5c33757fce398224e053183ff118663)\n""}, {'number': 2, 'created': '2019-02-13 18:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0ad00e6e581b7aaa7dc70eabd7109ad8ddf9168', 'message': ""Handle unicode characters in migration params\n\nThere can be unicode characters in the params for live migration, for\nexample, the guest domain name in the destination XML. We need to\nconvert those to bytes when we call migrateToURI3 under python2.\n\nThe existing code was just calling str() for this, but that will fail\nwith the error:\n\n  UnicodeEncodeError: 'ascii' codec can't encode characters...\n\nWe need to encode the unicode characters to do conversion.\n\nThe existing unit test wasn't using any unicode characters in its test\ndata, so this scenario wasn't covered.\n\nConflicts:\n\tnova/tests/unit/virt/libvirt/test_guest.py\n\tnova/virt/libvirt/guest.py\n\nCloses-Bug: #1768807\n\nChange-Id: I4b34139a3c5e3e2b7cf7cbe50bdf3da3131b9b1c\n(cherry picked from commit f046d8b54009978a3c83939dc190edbc1ebc09ae)\n(cherry picked from commit 7520d159b5c33757fce398224e053183ff118663)\n""}, {'number': 3, 'created': '2019-02-14 14:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5551c08459e115b869cf6efce8343341b4b7232', 'message': ""Handle unicode characters in migration params\n\nThere can be unicode characters in the params for live migration, for\nexample, the guest domain name in the destination XML. We need to\nconvert those to bytes when we call migrateToURI3 under python2.\n\nThe existing code was just calling str() for this, but that will fail\nwith the error:\n\n  UnicodeEncodeError: 'ascii' codec can't encode characters...\n\nWe need to encode the unicode characters to do conversion.\n\nThe existing unit test wasn't using any unicode characters in its test\ndata, so this scenario wasn't covered.\n\nConflicts:\n\tnova/tests/unit/virt/libvirt/test_guest.py\n\tnova/virt/libvirt/guest.py\n\nNOTE(s10): Conflict is caused by Id9ee1feeadf612fa79c3d280cee3a614a74a00a7\nnot being in Queens.\n\nCloses-Bug: #1768807\n\nChange-Id: I4b34139a3c5e3e2b7cf7cbe50bdf3da3131b9b1c\n(cherry picked from commit f046d8b54009978a3c83939dc190edbc1ebc09ae)\n(cherry picked from commit 7520d159b5c33757fce398224e053183ff118663)\n""}, {'number': 4, 'created': '2019-02-14 14:35:15.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_guest.py', 'nova/virt/libvirt/guest.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4c127db2f35329fda5f09be1f968f9a32b8c6836', 'message': ""Handle unicode characters in migration params\n\nThere can be unicode characters in the params for live migration, for\nexample, the guest domain name in the destination XML. We need to\nconvert those to bytes when we call migrateToURI3 under python2.\n\nThe existing code was just calling str() for this, but that will fail\nwith the error:\n\n  UnicodeEncodeError: 'ascii' codec can't encode characters...\n\nWe need to encode the unicode characters to do conversion.\n\nThe existing unit test wasn't using any unicode characters in its test\ndata, so this scenario wasn't covered.\n\nConflicts:\n\tnova/tests/unit/virt/libvirt/test_guest.py\n\tnova/virt/libvirt/guest.py\n\nNOTE(s10): Conflict is caused by Id9ee1feeadf612fa79c3d280cee3a614a74a00a7\nnot being in Queens.\n\nCloses-Bug: #1768807\n\nChange-Id: I4b34139a3c5e3e2b7cf7cbe50bdf3da3131b9b1c\n(cherry picked from commit f046d8b54009978a3c83939dc190edbc1ebc09ae)\n(cherry picked from commit 7520d159b5c33757fce398224e053183ff118663)\n""}]",0,636678,4c127db2f35329fda5f09be1f968f9a32b8c6836,57,14,4,9373,,,0,"Handle unicode characters in migration params

There can be unicode characters in the params for live migration, for
example, the guest domain name in the destination XML. We need to
convert those to bytes when we call migrateToURI3 under python2.

The existing code was just calling str() for this, but that will fail
with the error:

  UnicodeEncodeError: 'ascii' codec can't encode characters...

We need to encode the unicode characters to do conversion.

The existing unit test wasn't using any unicode characters in its test
data, so this scenario wasn't covered.

Conflicts:
	nova/tests/unit/virt/libvirt/test_guest.py
	nova/virt/libvirt/guest.py

NOTE(s10): Conflict is caused by Id9ee1feeadf612fa79c3d280cee3a614a74a00a7
not being in Queens.

Closes-Bug: #1768807

Change-Id: I4b34139a3c5e3e2b7cf7cbe50bdf3da3131b9b1c
(cherry picked from commit f046d8b54009978a3c83939dc190edbc1ebc09ae)
(cherry picked from commit 7520d159b5c33757fce398224e053183ff118663)
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/636678/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/libvirt/test_guest.py', 'nova/virt/libvirt/guest.py']",2,554ccf1aff4335a708c72dc7c0248480c170fd8b,bug/1768807," params = {key: encodeutils.to_utf8(value) if isinstance(value, six.text_type) else value"," params = {key: str(value) if isinstance(value, unicode) else value",7,3
openstack%2Fopenstack-ansible-os_cinder~master~If7637ac750330822e7f5e3cae6a78315bc25031b,openstack/openstack-ansible-os_cinder,master,If7637ac750330822e7f5e3cae6a78315bc25031b,Add cinder_user_pip_packages variable,MERGED,2019-02-20 17:35:08.000000000,2019-02-23 12:46:13.000000000,2019-02-23 12:46:13.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28008}]","[{'number': 1, 'created': '2019-02-20 17:35:08.000000000', 'files': ['tasks/cinder_install_source.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/5307714a8d64f20b374da5af19add93af923647d', 'message': 'Add cinder_user_pip_packages variable\n\nWith this variable, users would be able to extend\nthe list of pip packages in case of needing an\nextra pip package.\n\nCurrently if we need an extra pip package we need\nto override the existing list.\n\nChange-Id: If7637ac750330822e7f5e3cae6a78315bc25031b\n'}]",0,638226,5307714a8d64f20b374da5af19add93af923647d,15,4,1,28008,,,0,"Add cinder_user_pip_packages variable

With this variable, users would be able to extend
the list of pip packages in case of needing an
extra pip package.

Currently if we need an extra pip package we need
to override the existing list.

Change-Id: If7637ac750330822e7f5e3cae6a78315bc25031b
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/26/638226/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/cinder_install_source.yml', 'defaults/main.yml']",2,5307714a8d64f20b374da5af19add93af923647d,user_pip_packages,# Specific pip packages provided by the user cinder_user_pip_packages: [] ,,4,1
openstack%2Fopenstack-ansible-ceph_client~master~Id040de19dbefc820851928c9a3589f20a6b4bd61,openstack/openstack-ansible-ceph_client,master,Id040de19dbefc820851928c9a3589f20a6b4bd61,Use in-repo GPG keys,MERGED,2019-02-13 18:35:11.000000000,2019-02-23 12:32:51.000000000,2019-02-14 14:05:47.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-13 18:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/6f0fd1b65108ab87996ce3a98edd38f993b69855', 'message': 'Use in-repo GPG keys\n\nWe make remote network hits to get the GPG keys which are quite\nunreliable, and apt_key does not support using a proxy properly [1]\nso this change installs them from files inside the role.\n\nThe implementation here is derived from that which was done in the\ngalera_server role in I7ac1a5e3a05aa3d0b4fae86c4a325ef147a9a528.\n\n[1] https://github.com/ansible/ansible/issues/31691\n\nChange-Id: Id040de19dbefc820851928c9a3589f20a6b4bd61\nCloses-Bug: #1815430\n'}, {'number': 2, 'created': '2019-02-13 20:10:30.000000000', 'files': ['files/gpg/460f3994', 'tasks/ceph_preinstall_apt.yml', 'files/gpg/ceph_com_keys_release', 'vars/redhat-7.yml', 'vars/ubuntu.yml', 'releasenotes/notes/use_vendored_gpg_keys-f268bd4f4cb7d105.yaml', 'tasks/ceph_preinstall_yum.yml', 'files/gpg/RPM-GPG-KEY-EPEL-7'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/58be4bd5e31475c9a3f897de04f226880a45f7e1', 'message': 'Use in-repo GPG keys\n\nWe make remote network hits to get the GPG keys which are quite\nunreliable, and apt_key does not support using a proxy properly [1]\nso this change installs them from files inside the role.\n\nThe implementation here is derived from that which was done in the\ngalera_server role in I7ac1a5e3a05aa3d0b4fae86c4a325ef147a9a528.\n\n[1] https://github.com/ansible/ansible/issues/31691\n\nChange-Id: Id040de19dbefc820851928c9a3589f20a6b4bd61\nCloses-Bug: #1815430\n'}]",0,636711,58be4bd5e31475c9a3f897de04f226880a45f7e1,12,3,2,25666,,,0,"Use in-repo GPG keys

We make remote network hits to get the GPG keys which are quite
unreliable, and apt_key does not support using a proxy properly [1]
so this change installs them from files inside the role.

The implementation here is derived from that which was done in the
galera_server role in I7ac1a5e3a05aa3d0b4fae86c4a325ef147a9a528.

[1] https://github.com/ansible/ansible/issues/31691

Change-Id: Id040de19dbefc820851928c9a3589f20a6b4bd61
Closes-Bug: #1815430
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/11/636711/2 && git format-patch -1 --stdout FETCH_HEAD,"['files/gpg/460f3994', 'tasks/ceph_preinstall_apt.yml', 'files/gpg/ceph_com_keys_release', 'vars/redhat-7.yml', 'vars/ubuntu.yml', 'releasenotes/notes/use_vendored_gpg_keys-f268bd4f4cb7d105.yaml', 'tasks/ceph_preinstall_yum.yml', 'files/gpg/RPM-GPG-KEY-EPEL-7']",8,6f0fd1b65108ab87996ce3a98edd38f993b69855,bug/1815430,-----BEGIN PGP PUBLIC KEY BLOCK----- Version: GnuPG v1.4.11 (GNU/Linux) mQINBFKuaIQBEAC1UphXwMqCAarPUH/ZsOFslabeTVO2pDk5YnO96f+rgZB7xArB OSeQk7B90iqSJ85/c72OAn4OXYvT63gfCeXpJs5M7emXkPsNQWWSju99lW+AqSNm jYWhmRlLRGl0OO7gIwj776dIXvcMNFlzSPj00N2xAqjMbjlnV2n2abAE5gq6VpqP vFXVyfrVa/ualogDVmf6h2t4Rdpifq8qTHsHFU3xpCz+T6/dGWKGQ42ZQfTaLnDM jToAsmY0AyevkIbX6iZVtzGvanYpPcWW4X0RDPcpqfFNZk643xI4lsZ+Y2Er9Yu5 S/8x0ly+tmmIokaE0wwbdUu740YTZjCesroYWiRg5zuQ2xfKxJoV5E+Eh+tYwGDJ n6HfWhRgnudRRwvuJ45ztYVtKulKw8QQpd2STWrcQQDJaRWmnMooX/PATTjCBExB 9dkz38Druvk7IkHMtsIqlkAOQMdsX1d3Tov6BE2XDjIG0zFxLduJGbVwc/6rIc95 T055j36Ez0HrjxdpTGOOHxRqMK5m9flFbaxxtDnS7w77WqzW7HjFrD0VeTx2vnjj GqchHEQpfDpFOzb8LTFhgYidyRNUflQY35WLOzLNV+pV3eQ3Jg11UFwelSNLqfQf uFRGc+zcwkNjHh5yPvm9odR1BIfqJ6sKGPGbtPNXo7ERMRypWyRz0zi0twARAQAB tChGZWRvcmEgRVBFTCAoNykgPGVwZWxAZmVkb3JhcHJvamVjdC5vcmc+iQI4BBMB AgAiBQJSrmiEAhsPBgsJCAcDAgYVCAIJCgsEFgIDAQIeAQIXgAAKCRBqL66iNSxk 5cfGD/4spqpsTjtDM7qpytKLHKruZtvuWiqt5RfvT9ww9GUUFMZ4ZZGX4nUXg49q ixDLayWR8ddG/s5kyOi3C0uX/6inzaYyRg+Bh70brqKUK14F1BrrPi29eaKfG+Gu MFtXdBG2a7OtPmw3yuKmq9Epv6B0mP6E5KSdvSRSqJWtGcA6wRS/wDzXJENHp5re 9Ism3CYydpy0GLRA5wo4fPB5uLdUhLEUDvh2KK//fMjja3o0L+SNz8N0aDZyn5Ax CU9RB3EHcTecFgoy5umRj99BZrebR1NO+4gBrivIfdvD4fJNfNBHXwhSH9ACGCNv HnXVjHQF9iHWApKkRIeh8Fr2n5dtfJEF7SEX8GbX7FbsWo29kXMrVgNqHNyDnfAB VoPubgQdtJZJkVZAkaHrMu8AytwT62Q4eNqmJI1aWbZQNI5jWYqc6RKuCK6/F99q thFT9gJO17+yRuL6Uv2/vgzVR1RGdwVLKwlUjGPAjYflpCQwWMAASxiv9uPyYPHc ErSrbRG0wjIfAR3vus1OSOx3xZHZpXFfmQTsDP7zVROLzV98R3JwFAxJ4/xqeON4 vCPFU6OsT3lWQ8w7il5ohY95wmujfr6lk89kEzJdOTzcn7DBbUru33CQMGKZ3Evt RjsC7FDbL017qxS+ZVA/HGkyfiu4cpgV8VUnbql5eAZ+1Ll6Dw== =hdPa -----END PGP PUBLIC KEY BLOCK----- ,,166,51
openstack%2Fneutron~stable%2Focata~Ie291fda7d23a696aaa1160d126a3cf72b08c522f,openstack/neutron,stable/ocata,Ie291fda7d23a696aaa1160d126a3cf72b08c522f,Add new test decorator skip_if_timeout,MERGED,2019-02-20 09:58:01.000000000,2019-02-23 12:04:12.000000000,2019-02-23 12:04:12.000000000,"[{'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-20 09:58:01.000000000', 'files': ['neutron/tests/functional/db/test_migrations.py', 'neutron/tests/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/55daaeca3e94aab0c27b82e59c79f182dd3ec1ea', 'message': 'Add new test decorator skip_if_timeout\n\nIn some cases our db migration tests which run on MySQL are\nfailing with timeout and it happens due to slow VMs on which\njob is running.\nSometimes it may also happen that timeout exception is raised\nin the middle of some sqlalchemy operations and\nsqlalchemy.InterfaceError is raised as last one.\nDetails about this exception can be found in [1].\n\nTo avoid many rechecks because of this reason this patch\nintroduces new decorator which is very similar to ""unstable_test""\nbut will skip test only if one of exceptions mentioned above will\nbe raised.\nIn all other cases it will fail test.\n\nThat should be a bit more safe for us because we will not miss\nsome other failures raised in those tests and will avoid rechecks\nbecause of this ""well-known"" reason described in related bug.\n\n[1] http://sqlalche.me/e/rvf5\n\nConflicts:\n    neutron/tests/functional/db/test_migrations.py\n    neutron/tests/base.py\n\nChange-Id: Ie291fda7d23a696aaa1160d126a3cf72b08c522f\nRelated-Bug: #1687027\n(cherry picked from commit c0fec676723649a0516cf3d4af0dccc0fe832095)\n(cherry picked from commit e6f22ce81c0a1130d45d290b185b736501e6dd1e)\n'}]",0,638121,55daaeca3e94aab0c27b82e59c79f182dd3ec1ea,16,6,1,11975,,,0,"Add new test decorator skip_if_timeout

In some cases our db migration tests which run on MySQL are
failing with timeout and it happens due to slow VMs on which
job is running.
Sometimes it may also happen that timeout exception is raised
in the middle of some sqlalchemy operations and
sqlalchemy.InterfaceError is raised as last one.
Details about this exception can be found in [1].

To avoid many rechecks because of this reason this patch
introduces new decorator which is very similar to ""unstable_test""
but will skip test only if one of exceptions mentioned above will
be raised.
In all other cases it will fail test.

That should be a bit more safe for us because we will not miss
some other failures raised in those tests and will avoid rechecks
because of this ""well-known"" reason described in related bug.

[1] http://sqlalche.me/e/rvf5

Conflicts:
    neutron/tests/functional/db/test_migrations.py
    neutron/tests/base.py

Change-Id: Ie291fda7d23a696aaa1160d126a3cf72b08c522f
Related-Bug: #1687027
(cherry picked from commit c0fec676723649a0516cf3d4af0dccc0fe832095)
(cherry picked from commit e6f22ce81c0a1130d45d290b185b736501e6dd1e)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/21/638121/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/db/test_migrations.py', 'neutron/tests/base.py']",2,55daaeca3e94aab0c27b82e59c79f182dd3ec1ea,bug/1687027-stable/ocata,"from sqlalchemy import exc as sqlalchemy_excdef skip_if_timeout(reason): def decor(f): @functools.wraps(f) def inner(self, *args, **kwargs): try: return f(self, *args, **kwargs) except fixtures.TimeoutException: msg = (""Timeout raised for test %s, skipping it "" ""because of: %s"") % (self.id(), reason) raise self.skipTest(msg) except sqlalchemy_exc.InterfaceError: # In case of db tests very often TimeoutException is reason of # some sqlalchemy InterfaceError exception and that is final # raised exception which needs to be handled msg = (""DB connection broken in test %s. It is very likely "" ""that this happend because of test timeout. "" ""Skipping test because of: %s"") % (self.id(), reason) raise self.skipTest(msg) return inner return decor ",,51,0
openstack%2Fcinder~master~I7781d307d77f1840d05286e9395844ca8b077579,openstack/cinder,master,I7781d307d77f1840d05286e9395844ca8b077579,Remove 'rm' from rootwrap filters,NEW,2019-02-20 15:42:47.000000000,2019-02-23 12:02:50.000000000,,"[{'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 15296}, {'_account_id': 15670}, {'_account_id': 16897}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 26537}, {'_account_id': 28801}]","[{'number': 1, 'created': '2019-02-20 15:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fd3e2eb3c885f28476870bbaa12c4ec220734ced', 'message': ""Remove 'rm' from rootwrap filters\n\nRename the removefile method to remove so\nthat it will remove the file if the path is a directory\nusing unlink, or will remove a directory using shutil.rmtree\nif a directory is found.\n\nUpdate the various drivers to use the privsep instead\nof rootwrap.\n\nChange-Id: I7781d307d77f1840d05286e9395844ca8b077579\nSigned-off-by: Charles Short <chucks@redhat.com>\n""}, {'number': 2, 'created': '2019-02-20 18:33:02.000000000', 'files': ['cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/vzstorage.py', 'cinder/volume/drivers/quobyte.py', 'cinder/volume/drivers/veritas_cnfs.py', 'cinder/volume/targets/nvmet.py', 'cinder/tests/unit/volume/drivers/test_nfs.py', 'etc/cinder/rootwrap.d/volume.filters', 'cinder/tests/unit/volume/drivers/test_gpfs.py', 'cinder/tests/unit/volume/drivers/test_veritas_cnfs.py', 'cinder/privsep/path.py', 'cinder/volume/drivers/netapp/dataontap/nfs_base.py', 'cinder/volume/drivers/tintri.py', 'cinder/volume/drivers/zfssa/zfssanfs.py', 'cinder/tests/unit/volume/drivers/test_quobyte.py', 'cinder/volume/drivers/remotefs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c57c91acc8b73bfbf3b7e8e8203a7fcfebcfb79a', 'message': ""Remove 'rm' from rootwrap filters\n\nRename the removefile method to remove so\nthat it will remove the file if the path is a directory\nusing unlink, or will remove a directory using shutil.rmtree\nif a directory is found.\n\nUpdate the various drivers to use the privsep instead\nof rootwrap.\n\nChange-Id: I7781d307d77f1840d05286e9395844ca8b077579\nSigned-off-by: Charles Short <chucks@redhat.com>\n""}]",0,638184,c57c91acc8b73bfbf3b7e8e8203a7fcfebcfb79a,29,18,2,24,,,0,"Remove 'rm' from rootwrap filters

Rename the removefile method to remove so
that it will remove the file if the path is a directory
using unlink, or will remove a directory using shutil.rmtree
if a directory is found.

Update the various drivers to use the privsep instead
of rootwrap.

Change-Id: I7781d307d77f1840d05286e9395844ca8b077579
Signed-off-by: Charles Short <chucks@redhat.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/84/638184/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/vzstorage.py', 'cinder/volume/drivers/quobyte.py', 'cinder/volume/drivers/veritas_cnfs.py', 'cinder/volume/targets/nvmet.py', 'cinder/tests/unit/volume/drivers/test_nfs.py', 'etc/cinder/rootwrap.d/volume.filters', 'cinder/tests/unit/volume/drivers/test_gpfs.py', 'cinder/tests/unit/volume/drivers/test_veritas_cnfs.py', 'cinder/privsep/path.py', 'cinder/volume/drivers/netapp/dataontap/nfs_base.py', 'cinder/volume/drivers/tintri.py', 'cinder/volume/drivers/zfssa/zfssanfs.py', 'cinder/tests/unit/volume/drivers/test_quobyte.py', 'cinder/volume/drivers/remotefs.py']",15,fd3e2eb3c885f28476870bbaa12c4ec220734ced,,import cinder.privsep.path cinder.privsep.path.remove(path)," self._execute('rm', '-f', path, run_as_root=self._execute_as_root)",78,70
openstack%2Fplacement~master~I822732f2e7eb54c994321ab715e8535882eed803,openstack/placement,master,I822732f2e7eb54c994321ab715e8535882eed803,Don't use OVO in Project object,MERGED,2019-02-14 01:24:07.000000000,2019-02-23 11:09:23.000000000,2019-02-23 07:45:36.000000000,"[{'_account_id': 7}, {'_account_id': 7634}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-14 01:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/bdb10751275e0b67afbd57b685f792250fe9a6bb', 'message': ""Don't use OVO in Project object\n\nThis changes the Project object to be a plain Python object\nwith an explicit __init__.\n\nChange-Id: I822732f2e7eb54c994321ab715e8535882eed803\n""}, {'number': 2, 'created': '2019-02-14 12:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/be304e70c5e51a86ce8a9bbcf7ef1b28d2948687', 'message': ""Don't use OVO in Project object\n\nThis changes the Project object to be a plain Python object\nwith an explicit __init__.\n\nChange-Id: I822732f2e7eb54c994321ab715e8535882eed803\n""}, {'number': 3, 'created': '2019-02-15 17:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/838623a72cd1e57faa08e4ddd939403c4c01637c', 'message': ""Don't use OVO in Project object\n\nThis changes the Project object to be a plain Python object\nwith an explicit __init__.\n\nChange-Id: I822732f2e7eb54c994321ab715e8535882eed803\n""}, {'number': 4, 'created': '2019-02-20 09:59:55.000000000', 'files': ['placement/objects/project.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/6f7342f4e27ceff94a38947fe651d66407e44daa', 'message': ""Don't use OVO in Project object\n\nThis changes the Project object to be a plain Python object\nwith an explicit __init__.\n\nChange-Id: I822732f2e7eb54c994321ab715e8535882eed803\n""}]",2,636802,6f7342f4e27ceff94a38947fe651d66407e44daa,15,4,4,11564,,,0,"Don't use OVO in Project object

This changes the Project object to be a plain Python object
with an explicit __init__.

Change-Id: I822732f2e7eb54c994321ab715e8535882eed803
",git fetch https://review.opendev.org/openstack/placement refs/changes/02/636802/4 && git format-patch -1 --stdout FETCH_HEAD,['placement/objects/project.py'],1,bdb10751275e0b67afbd57b685f792250fe9a6bb,cd/less-ovo,"class Project(object): def __init__(self, context, id=None, external_id=None, updated_at=None, created_at=None): self._context = context self.id = id self.external_id = external_id self.updated_at = updated_at self.created_at = created_at target.id = source['id'] target.external_id = source['external_id'] target.updated_at = source['updated_at'] target.created_at = source['created_at']","from oslo_versionedobjects import base from oslo_versionedobjects import fields@base.VersionedObjectRegistry.register_if(False) class Project(base.VersionedObject): fields = { 'id': fields.IntegerField(read_only=True), 'external_id': fields.StringField(nullable=False), } for field in target.fields: setattr(target, field, source[field]) target.obj_reset_changes()",12,12
openstack%2Fnova-specs~master~Ia9d18ea7bba36424b145a397c37bf750f914c647,openstack/nova-specs,master,Ia9d18ea7bba36424b145a397c37bf750f914c647,Add placement nofications using versionedObjects,ABANDONED,2017-01-23 00:51:24.000000000,2019-02-23 10:55:01.000000000,,"[{'_account_id': 3}, {'_account_id': 8580}, {'_account_id': 9708}, {'_account_id': 11564}]","[{'number': 1, 'created': '2017-01-23 00:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b01cd984dfde944e5a71dade1484875fd85b6084', 'message': 'Add placement nofications using versionedObjects.\n\nFollowing notification will be added -\n\n* placement.resource_provider.create\n* placement.resource_provider.delete\n* placement.resource_provider.aggregate.associate\n* placement.resource_provider.aggregate.disassociate\n* placement.resource_provider.inventory.update\n* placement.allocation.create\n* placement.allocation.delete\n\nChange-Id: Ia9d18ea7bba36424b145a397c37bf750f914c647\nImplements: blueprint placement-notifications\n'}, {'number': 2, 'created': '2017-01-23 02:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9d253a1d6a22d5c8ca51160cde4f0e640433b1a8', 'message': 'Add placement nofications using versionedObjects\n\nFollowing notification will be added -\n\n* placement.resource_provider.create\n* placement.resource_provider.delete\n* placement.resource_provider.aggregate.associate\n* placement.resource_provider.aggregate.disassociate\n* placement.resource_provider.inventory.update\n* placement.allocation.create\n* placement.allocation.delete\n\nChange-Id: Ia9d18ea7bba36424b145a397c37bf750f914c647\nImplements: blueprint placement-notifications\n'}, {'number': 3, 'created': '2017-01-23 02:19:37.000000000', 'files': ['specs/pike/approved/placement-notifications.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6376762cf2810e323b62e74cb7f8585e0a5e047d', 'message': 'Add placement nofications using versionedObjects\n\nFollowing notification will be added -\n\n* placement.resource_provider.create\n* placement.resource_provider.delete\n* placement.resource_provider.aggregate.associate\n* placement.resource_provider.aggregate.disassociate\n* placement.resource_provider.inventory.update\n* placement.allocation.create\n* placement.allocation.delete\n\nChange-Id: Ia9d18ea7bba36424b145a397c37bf750f914c647\nImplements: blueprint placement-notifications\n'}]",27,423872,6376762cf2810e323b62e74cb7f8585e0a5e047d,12,4,3,8580,,,0,"Add placement nofications using versionedObjects

Following notification will be added -

* placement.resource_provider.create
* placement.resource_provider.delete
* placement.resource_provider.aggregate.associate
* placement.resource_provider.aggregate.disassociate
* placement.resource_provider.inventory.update
* placement.allocation.create
* placement.allocation.delete

Change-Id: Ia9d18ea7bba36424b145a397c37bf750f914c647
Implements: blueprint placement-notifications
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/72/423872/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/pike/approved/placement-notifications.rst'],1,b01cd984dfde944e5a71dade1484875fd85b6084,bp/placement-notifications,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================== Notifications on placement operations ================================== https://blueprints.launchpad.net/nova/+spec/placement-notifications Nova currently does not send notifications on resource provider create/delete, aggregrate.associate/disassociate, inventory.update, allocation.create/delete operations. Resource Provider has a set of attributes (id, uuid, name, generation, can_host). I would be useful to receive create, update and delete notofications on any of this information changing, and the payload should contain the same information for create and update as accessible from the API. Problem description =================== The maintainer wants to get the notifications when there are resources added, updated or destroyed. Use Cases ========= As an OpenStack developer, I want to be able to listen to notifications coming from placement about actions. As an OpenStack developer, I want to know what the format of the action notifications are. As an OpenStack developer, I want to be notified whenever: - an action has been created - an action has been finished Proposed change =============== Versioned notifications will be added for the following actions: * placement.resource_provider.create * placement.resource_provider.delete * placement.resource_provider.aggregate.associate * placement.resource_provider.aggregate.disassociate * placement.resource_provider.inventory.update * placement.allocation.create * placement.allocation.delete Alternatives ------------ None Data model impact ----------------- No database schema change is needed. The following new object will be added to Placement for create, update and delete. .. code-block:: python @base.NovaObjectRegistry.register class PlacementNotification(notification.NotificationBase): # Version 1.0: Initial version VERSION = '1.0' fields = { 'payload': fields.ObjectField('PlacementPayload') } @base.NovaObjectRegistry.register class PlacementPayload(notification.NotificationPayloadBase): # Version 1.0: Initial version VERSION = '1.0' fields = { 'id': fields.StringField(), 'name': fields.StringField(nullable=True), 'generation': fields.IntegerField(), 'can_host': fields.IntegerField(), } REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- New Placement notifications will be added using ""versionedObject"". Other end user impact --------------------- None Performance Impact ------------------ Notifications will be emitted if the versioned notification is enabled. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Digambar Work Items ---------- * Add versioned notifications for Placement Dependencies ============ None Testing ======= Besides unit test new functional test cases will be added to cover the new notifications and the tests will assert the validity of the stored notification samples as well. Documentation Impact ==================== None References ========== [1]: Searchlight: http://docs.openstack.org/developer/searchlight/index.html [2]: Versioned notification: http://docs.openstack.org/developer/nova/notifications.html#versioned-notifications ",,154,0
openstack%2Fneutron-lib~master~I88fe8d3fd5ed6a2dafe3602182d595b8875bb15b,openstack/neutron-lib,master,I88fe8d3fd5ed6a2dafe3602182d595b8875bb15b,Add security-group as parameter to RBAC api,MERGED,2019-02-06 21:08:04.000000000,2019-02-23 10:27:15.000000000,2019-02-23 10:27:15.000000000,"[{'_account_id': 4694}, {'_account_id': 5367}, {'_account_id': 10980}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 21:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/e5a11751df10cb1d88344c767342dfbcd02317ac', 'message': 'Add security-group as parameter to RBAC api\n\nDepends-On: https://review.openstack.org/635311\nChange-Id: I88fe8d3fd5ed6a2dafe3602182d595b8875bb15b\n'}, {'number': 2, 'created': '2019-02-14 20:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/388bb02a59e39304ad528131a4dd9c81260cb395', 'message': 'Add security-group as parameter to RBAC api\n\nDepends-On: https://review.openstack.org/635311\nChange-Id: I88fe8d3fd5ed6a2dafe3602182d595b8875bb15b\n'}, {'number': 3, 'created': '2019-02-14 20:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/a974d00daf882750939d07b968b8f04c08a2e8a3', 'message': 'Add security-group as parameter to RBAC api\n\nDepends-On: https://review.openstack.org/635311\nChange-Id: I88fe8d3fd5ed6a2dafe3602182d595b8875bb15b\n'}, {'number': 4, 'created': '2019-02-19 04:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/f556677a72cb1c036310a6f7adbbc57402f4d959', 'message': 'Add security-group as parameter to RBAC api\n\nChange-Id: I88fe8d3fd5ed6a2dafe3602182d595b8875bb15b\n'}, {'number': 5, 'created': '2019-02-19 18:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/25ad0792825f3af63d112a8201637fd9e51250d9', 'message': 'Add security-group as parameter to RBAC api\n\nChange-Id: I88fe8d3fd5ed6a2dafe3602182d595b8875bb15b\n'}, {'number': 6, 'created': '2019-02-21 18:21:57.000000000', 'files': ['neutron_lib/api/definitions/rbac_security_groups.py', 'api-ref/source/v2/parameters.yaml', 'neutron_lib/api/definitions/__init__.py', 'neutron_lib/api/definitions/base.py', 'neutron_lib/tests/unit/api/definitions/test_rbac_security_groups.py', 'api-ref/source/v2/rbac-policy.inc', 'releasenotes/notes/add-rbac-security-groups-2e47acd9eac3a320.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/c0a6d727c85b92ed22f5eda434f4f6576177180d', 'message': 'Add security-group as parameter to RBAC api\n\nPartial-Bug: #1817119\nChange-Id: I88fe8d3fd5ed6a2dafe3602182d595b8875bb15b\n'}]",12,635313,c0a6d727c85b92ed22f5eda434f4f6576177180d,28,5,6,10980,,,0,"Add security-group as parameter to RBAC api

Partial-Bug: #1817119
Change-Id: I88fe8d3fd5ed6a2dafe3602182d595b8875bb15b
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/13/635313/3 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/v2/parameters.yaml'],1,e5a11751df10cb1d88344c767342dfbcd02317ac,bug/1817119," resource. An ``object_type`` of ``network`` returns a network ID, an ``object_type`` of ``qos-policy`` returns a QoS policy ID, and an ``object_type`` of ``security-group`` returns a security group ID. RBAC policy affects. Types include ``qos-policy``, ``network``, or ``security-group``.", resource. An ``object_type`` of ``network`` returns a network ID and an ``object_type`` of ``qos-policy`` returns a QoS policy ID. RBAC policy affects. Types include ``qos-policy`` or ``network``.,5,3
openstack%2Fneutron~stable%2Frocky~Ib494d320e1c2e6cc6daa20255e30291fc2e258e8,openstack/neutron,stable/rocky,Ib494d320e1c2e6cc6daa20255e30291fc2e258e8,Remove a bare raise noticed by the linter,MERGED,2019-01-30 08:39:52.000000000,2019-02-23 10:14:36.000000000,2019-02-23 10:14:36.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9373}, {'_account_id': 10980}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 25618}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-01-30 08:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa33748bf83af3bc3c72a114ffc747ffcfa42339', 'message': ""Remove a bare raise noticed by the linter\n\nThere is a bare raise in a function that is used as an exception\nhandler.  Remove it and have the caller raise inside it's except\nblock instead.\n\nChange-Id: Ib494d320e1c2e6cc6daa20255e30291fc2e258e8\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n(cherry picked from commit a8e8f88cded69d221525f6441b17c747f36a182b)\n""}, {'number': 2, 'created': '2019-01-30 16:25:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bad9e55b067daa6ebbb18b32e8e313ae0e113b23', 'message': ""Remove a bare raise noticed by the linter\n\nThere is a bare raise in a function that is used as an exception\nhandler.  Remove it and have the caller raise inside it's except\nblock instead.\n\nChange-Id: Ib494d320e1c2e6cc6daa20255e30291fc2e258e8\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n(cherry picked from commit a8e8f88cded69d221525f6441b17c747f36a182b)\n""}, {'number': 3, 'created': '2019-01-30 16:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b2ccc6dbe36abd227e7221cd15276772d670623', 'message': ""Remove a bare raise noticed by the linter\n\nThere is a bare raise in a function that is used as an exception\nhandler.  Remove it and have the caller raise inside it's except\nblock instead.\n\nChange-Id: Ib494d320e1c2e6cc6daa20255e30291fc2e258e8\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n(cherry picked from commit a8e8f88cded69d221525f6441b17c747f36a182b)\n""}, {'number': 4, 'created': '2019-01-30 17:16:15.000000000', 'files': ['neutron/privileged/agent/linux/ip_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e6ce6f9639075003198844d07fe9cdc1e041250', 'message': ""Remove a bare raise noticed by the linter\n\nThere is a bare raise in a function that is used as an exception\nhandler.  Remove it and have the caller raise inside it's except\nblock instead.\n\nChange-Id: Ib494d320e1c2e6cc6daa20255e30291fc2e258e8\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n(cherry picked from commit a8e8f88cded69d221525f6441b17c747f36a182b)\n""}]",0,633887,1e6ce6f9639075003198844d07fe9cdc1e041250,30,9,4,9373,,,0,"Remove a bare raise noticed by the linter

There is a bare raise in a function that is used as an exception
handler.  Remove it and have the caller raise inside it's except
block instead.

Change-Id: Ib494d320e1c2e6cc6daa20255e30291fc2e258e8
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
(cherry picked from commit a8e8f88cded69d221525f6441b17c747f36a182b)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/87/633887/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/privileged/agent/linux/ip_lib.py'],1,aa33748bf83af3bc3c72a114ffc747ffcfa42339,python3-first-stable/rocky," if e.code == errno.ENODEV: raise NetworkInterfaceNotFound(device=device, namespace=namespace) if e.code == errno.EOPNOTSUPP: raise InterfaceOperationNotSupported(device=device, namespace=namespace) raise raise raise"," if e.code == errno.ENODEV: raise NetworkInterfaceNotFound(device=device, namespace=namespace) if e.code == errno.EOPNOTSUPP: raise InterfaceOperationNotSupported(device=device, namespace=namespace) raise",8,6
openstack%2Fnova~stable%2Frocky~I44f09aec60b0b18c458f9ba6d8b725db962e9cc7,openstack/nova,stable/rocky,I44f09aec60b0b18c458f9ba6d8b725db962e9cc7,Provide a useful error message when trying to update non-compute services,MERGED,2019-02-14 13:42:06.000000000,2019-02-23 10:13:45.000000000,2019-02-14 23:07:59.000000000,"[{'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-14 13:42:06.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_services.py', 'nova/api/openstack/compute/services.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/315d9fab7aaa6b9835e80f5f56b49b44d382ca1f', 'message': ""Provide a useful error message when trying to update non-compute services\n\nStarting in Pike, we disallowed trying to update (enable/disable/force down)\nnon-nova-compute services because of multi-cell support using host mappings\nto lookup service records, and simply because disabling non-compute services\ndoesn't do anything.\n\nHowever, before microversion 2.53, the error the user gets back is confusing:\n\n  HTTP exception thrown: Host 'p024.domain.com' is not mapped to any cell\n\nThis change provides a useful error message in this case and also changes\nthe 404 response to a 400 response to align with the type of error and the\nbehavior of the 2.53 microversion.\n\nChange-Id: I44f09aec60b0b18c458f9ba6d8b725db962e9cc7\nCloses-Bug: #1805164\n(cherry picked from commit 95cbc35b0bdae0de15569bc35fadbcf970da5b9e)\n""}]",0,636955,315d9fab7aaa6b9835e80f5f56b49b44d382ca1f,12,7,1,6873,,,0,"Provide a useful error message when trying to update non-compute services

Starting in Pike, we disallowed trying to update (enable/disable/force down)
non-nova-compute services because of multi-cell support using host mappings
to lookup service records, and simply because disabling non-compute services
doesn't do anything.

However, before microversion 2.53, the error the user gets back is confusing:

  HTTP exception thrown: Host 'p024.domain.com' is not mapped to any cell

This change provides a useful error message in this case and also changes
the 404 response to a 400 response to align with the type of error and the
behavior of the 2.53 microversion.

Change-Id: I44f09aec60b0b18c458f9ba6d8b725db962e9cc7
Closes-Bug: #1805164
(cherry picked from commit 95cbc35b0bdae0de15569bc35fadbcf970da5b9e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/636955/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_services.py', 'nova/api/openstack/compute/services.py']",2,315d9fab7aaa6b9835e80f5f56b49b44d382ca1f,bug/1805164-stable/rocky," # If the user tried to perform an action # (disable/enable/force down) on a non-nova-compute # service, provide a more useful error message. if binary != 'nova-compute': msg = (_( 'Updating a %(binary)s service is not supported. Only ' 'nova-compute services can be updated.') % {'binary': binary}) raise webob.exc.HTTPBadRequest(explanation=msg) # mapping so you'll get a 400. In this new microversion, we close that"," # mapping so you'll get a 404. In this new microversion, we close that",22,3
openstack%2Fhorizon~master~I8f0cd4ddf36e308221a1d4702b6afed674963e5a,openstack/horizon,master,I8f0cd4ddf36e308221a1d4702b6afed674963e5a,Imported Translations from Zanata,MERGED,2019-02-23 09:00:06.000000000,2019-02-23 10:10:34.000000000,2019-02-23 10:10:34.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-23 09:00:06.000000000', 'files': ['openstack_dashboard/locale/bn_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/kn/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ne/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ta/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mni/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/mr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/as/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pa_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/brx/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mai/LC_MESSAGES/django.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/it/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/it/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/id/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ks/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ur/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/id/LC_MESSAGES/django.po', 'openstack_dashboard/locale/eo/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/gu/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/pt_BR/LC_MESSAGES/releasenotes.po', 'openstack_dashboard/locale/kok/LC_MESSAGES/django.po', 'openstack_dashboard/locale/eo/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2c5afc7f01c398b18f1c04abf79bd200b6aa1cbc', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I8f0cd4ddf36e308221a1d4702b6afed674963e5a\n'}]",0,638802,2c5afc7f01c398b18f1c04abf79bd200b6aa1cbc,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I8f0cd4ddf36e308221a1d4702b6afed674963e5a
",git fetch https://review.opendev.org/openstack/horizon refs/changes/02/638802/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/bn_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/kn/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ne/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ta/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mni/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/mr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/as/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pa_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/brx/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mai/LC_MESSAGES/django.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/it/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/it/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/id/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ks/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ur/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/id/LC_MESSAGES/django.po', 'openstack_dashboard/locale/eo/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/gu/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/pt_BR/LC_MESSAGES/releasenotes.po', 'openstack_dashboard/locale/kok/LC_MESSAGES/django.po', 'openstack_dashboard/locale/eo/LC_MESSAGES/django.po']",50,2c5afc7f01c398b18f1c04abf79bd200b6aa1cbc,zanata/translations,"""POT-Creation-Date: 2019-02-22 16:05+0000\n""","""POT-Creation-Date: 2019-02-14 07:16+0000\n""msgid """" ""Flavor ID should be UUID4 or integer. Leave this field blank or use 'auto' "" ""to set a random UUID4."" msgstr """" ""Variaĵo ID devus esti UUID4 aŭ entjero. Lasu tiun kampon malplena blank aŭ "" ""uzu 'auto' por apliki hazarda UUID4."" ",74,380
openstack%2Fopenstack-ansible~master~I8dad86a57d211cf6c17e540991504c9eb7fb34fe,openstack/openstack-ansible,master,I8dad86a57d211cf6c17e540991504c9eb7fb34fe,Remove all uses of private in include_role,MERGED,2019-02-22 00:25:51.000000000,2019-02-23 10:06:16.000000000,2019-02-23 10:06:16.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:25:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f3c9fb5c3a5c98a0bf57eda0df67c18ae9993c4d', 'message': 'Remove all uses of private in include_role\n\nThis option was never supported by ansible and will never be developed.\nThis change removes the option which will eventually lead to failures in\nfuture versions of ansible.\n\nChange-Id: I8dad86a57d211cf6c17e540991504c9eb7fb34fe\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2019-02-23 05:59:43.000000000', 'files': ['playbooks/common-tasks/rsyslog-client.yml', 'playbooks/healthcheck-infrastructure.yml', 'playbooks/utility-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c5260b4d500add9b47e4298b945735ae5dfbdabc', 'message': 'Remove all uses of private in include_role\n\nThis option was never supported by ansible and will never be developed.\nThis change removes the option which will eventually lead to failures in\nfuture versions of ansible.\n\nChange-Id: I8dad86a57d211cf6c17e540991504c9eb7fb34fe\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638531,c5260b4d500add9b47e4298b945735ae5dfbdabc,22,2,2,7353,,,0,"Remove all uses of private in include_role

This option was never supported by ansible and will never be developed.
This change removes the option which will eventually lead to failures in
future versions of ansible.

Change-Id: I8dad86a57d211cf6c17e540991504c9eb7fb34fe
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/31/638531/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/common-tasks/rsyslog-client.yml', 'playbooks/healthcheck-infrastructure.yml', 'playbooks/containers-nspawn-destroy.yml', 'playbooks/containers-lxc-destroy.yml', 'playbooks/utility-install.yml']",5,f3c9fb5c3a5c98a0bf57eda0df67c18ae9993c4d,fix/private/deprecation,, private: yes,0,7
openstack%2Fnova~master~I194aad7c8e016bad33d51fa39ccab3bf0040d154,openstack/nova,master,I194aad7c8e016bad33d51fa39ccab3bf0040d154,libvirt: Drop MIN_LIBVIRT_PARALLELS_SET_ADMIN_PASSWD,MERGED,2019-01-22 17:18:41.000000000,2019-02-23 09:22:40.000000000,2019-02-23 09:22:39.000000000,"[{'_account_id': 6962}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-22 17:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4ab907de60b6acbe2ae3efe348fe8236240f68e', 'message': 'libvirt: Drop MIN_LIBVIRT_PARALLELS_SET_ADMIN_PASSWD\n\nThe updated minimum required libvirt (3.0.0) and QEMU (2.8.0) for\n""Stein"" matches this now, so we can drop the compatibility code.\n\nAlso remove / fix relevant unit tests.\n\nChange-Id: I194aad7c8e016bad33d51fa39ccab3bf0040d154\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 2, 'created': '2019-02-13 14:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9583995e161b72efbb56f5e4b7e955bfa190bab', 'message': 'libvirt: Drop MIN_LIBVIRT_PARALLELS_SET_ADMIN_PASSWD\n\nThe updated minimum required libvirt (3.0.0) and QEMU (2.8.0) for\n""Stein"" matches this now, so we can drop the compatibility code.\n\nAlso remove / fix relevant unit tests.\n\nChange-Id: I194aad7c8e016bad33d51fa39ccab3bf0040d154\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 3, 'created': '2019-02-13 15:19:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6319fa419c5788b618e6b83ffd89b371c1bd6a83', 'message': 'libvirt: Drop MIN_LIBVIRT_PARALLELS_SET_ADMIN_PASSWD\n\nThe updated minimum required libvirt (3.0.0) and QEMU (2.8.0) for\n""Stein"" matches this now, so we can drop the compatibility code.\n\nAlso remove / fix relevant unit tests.\n\nChange-Id: I194aad7c8e016bad33d51fa39ccab3bf0040d154\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 4, 'created': '2019-02-15 09:24:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d94e9a1d073881407ba523cb81463c84b8a56c33', 'message': 'libvirt: Drop MIN_LIBVIRT_PARALLELS_SET_ADMIN_PASSWD\n\nThe updated minimum required libvirt (3.0.0) and QEMU (2.8.0) for\n""Stein"" matches this now, so we can drop the compatibility code.\n\nAlso remove / fix relevant unit tests.\n\nChange-Id: I194aad7c8e016bad33d51fa39ccab3bf0040d154\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 5, 'created': '2019-02-18 13:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2df38ff22b115615934762f7a2d924d3fcd68c07', 'message': 'libvirt: Drop MIN_LIBVIRT_PARALLELS_SET_ADMIN_PASSWD\n\nThe updated minimum required libvirt (3.0.0) and QEMU (2.8.0) for\n""Stein"" matches this now, so we can drop the compatibility code.\n\nAlso remove / fix relevant unit tests.\n\nChange-Id: I194aad7c8e016bad33d51fa39ccab3bf0040d154\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 6, 'created': '2019-02-18 13:50:18.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fe88d9e2c33af94139dbae896b95dcc45c412798', 'message': 'libvirt: Drop MIN_LIBVIRT_PARALLELS_SET_ADMIN_PASSWD\n\nThe updated minimum required libvirt (3.0.0) and QEMU (2.8.0) for\n""Stein"" matches this now, so we can drop the compatibility code.\n\nAlso remove / fix relevant unit tests.\n\nChange-Id: I194aad7c8e016bad33d51fa39ccab3bf0040d154\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}]",0,632514,fe88d9e2c33af94139dbae896b95dcc45c412798,87,16,6,6962,,,0,"libvirt: Drop MIN_LIBVIRT_PARALLELS_SET_ADMIN_PASSWD

The updated minimum required libvirt (3.0.0) and QEMU (2.8.0) for
""Stein"" matches this now, so we can drop the compatibility code.

Also remove / fix relevant unit tests.

Change-Id: I194aad7c8e016bad33d51fa39ccab3bf0040d154
Signed-off-by: Kashyap Chamarthy <kchamart@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/14/632514/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,a4ab907de60b6acbe2ae3efe348fe8236240f68e,Bump_min_libvirt_and_QEMU_for_Stein,," @mock.patch('nova.utils.get_image_from_system_metadata') @mock.patch.object(host.Host, 'has_min_version', return_value=True) @mock.patch('nova.virt.libvirt.host.Host.get_guest') def test_set_admin_password(self, mock_get_guest, ver, mock_image): self.flags(virt_type='kvm', group='libvirt') instance = objects.Instance(**self.test_instance) mock_image.return_value = {""properties"": { ""hw_qemu_guest_agent"": ""yes""}} mock_guest = mock.Mock(spec=libvirt_guest.Guest) mock_get_guest.return_value = mock_guest drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) drvr.set_admin_password(instance, ""123"") mock_guest.set_user_password.assert_called_once_with(""root"", ""123"") ",1,25
openstack%2Fnova~master~Ic88c0caf6f9de79a6deabc9ec4aa8be1e0ae9307,openstack/nova,master,Ic88c0caf6f9de79a6deabc9ec4aa8be1e0ae9307,libvirt: Rewrite _create_pty_device() to be clearer,MERGED,2019-02-15 09:24:57.000000000,2019-02-23 09:22:23.000000000,2019-02-23 09:22:22.000000000,"[{'_account_id': 6962}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 28454}]","[{'number': 1, 'created': '2019-02-15 09:24:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e3068e11e71d3c56e062cf649064fb13821d0ab', 'message': 'libvirt: Rewrite _create_pty_device() to be clearer\n\nNo tests are added intentionally to demonstrate that this is purely a\nmechanical change to make the code shorter and easier to read.\n\nChange-Id: Ic88c0caf6f9de79a6deabc9ec4aa8be1e0ae9307\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 2, 'created': '2019-02-18 13:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e913ff65b4be5304c5f03e66cd93a83e69a3d393', 'message': 'libvirt: Rewrite _create_pty_device() to be clearer\n\nNo tests are added intentionally to demonstrate that this is purely a\nmechanical change to make the code shorter and easier to read.\n\nChange-Id: Ic88c0caf6f9de79a6deabc9ec4aa8be1e0ae9307\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 3, 'created': '2019-02-18 13:50:18.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/da53afc1d805009eb1a9d1f03bffbe129091c0bc', 'message': 'libvirt: Rewrite _create_pty_device() to be clearer\n\nNo tests are added intentionally to demonstrate that this is purely a\nmechanical change to make the code shorter and easier to read.\n\nChange-Id: Ic88c0caf6f9de79a6deabc9ec4aa8be1e0ae9307\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}]",1,637152,da53afc1d805009eb1a9d1f03bffbe129091c0bc,90,15,3,6962,,,0,"libvirt: Rewrite _create_pty_device() to be clearer

No tests are added intentionally to demonstrate that this is purely a
mechanical change to make the code shorter and easier to read.

Change-Id: Ic88c0caf6f9de79a6deabc9ec4aa8be1e0ae9307
Signed-off-by: Kashyap Chamarthy <kchamart@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/52/637152/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,0e3068e11e71d3c56e062cf649064fb13821d0ab,Bump_min_libvirt_and_QEMU_for_Stein," consolepty = char_dev_cls() consolepty.target_type = target_type consolepty.type = ""pty"" log = vconfig.LibvirtConfigGuestCharDeviceLog() log.file = log_path consolepty.log = log guest_cfg.add_device(consolepty)"," def _create_base_dev(): consolepty = char_dev_cls() consolepty.target_type = target_type consolepty.type = ""pty"" return consolepty def _create_logd_dev(): consolepty = _create_base_dev() log = vconfig.LibvirtConfigGuestCharDeviceLog() log.file = log_path consolepty.log = log return consolepty else: guest_cfg.add_device(_create_logd_dev())",10,14
openstack%2Fplacement~master~I0e0019e34d58ce0375ee2a2495786ee2f48b5b49,openstack/placement,master,I0e0019e34d58ce0375ee2a2495786ee2f48b5b49,Don't use OVO in User object,MERGED,2019-02-14 01:24:07.000000000,2019-02-23 07:45:38.000000000,2019-02-23 07:45:37.000000000,"[{'_account_id': 7}, {'_account_id': 7634}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-14 01:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/87941908e3da5d789966d2d3d13a06c754056bf1', 'message': ""Don't use OVO in User object\n\nThis changes the User object to be a plain Python object\nwith an explicit __init__.\n\nChange-Id: I0e0019e34d58ce0375ee2a2495786ee2f48b5b49\n""}, {'number': 2, 'created': '2019-02-14 12:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/34f09c22fc747da1af6e52ce1f5f7b9440928aaa', 'message': ""Don't use OVO in User object\n\nThis changes the User object to be a plain Python object\nwith an explicit __init__.\n\nChange-Id: I0e0019e34d58ce0375ee2a2495786ee2f48b5b49\n""}, {'number': 3, 'created': '2019-02-15 17:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/218a3413ec2d844768ab3da4d4bcb8dd60c9e31f', 'message': ""Don't use OVO in User object\n\nThis changes the User object to be a plain Python object\nwith an explicit __init__.\n\nChange-Id: I0e0019e34d58ce0375ee2a2495786ee2f48b5b49\n""}, {'number': 4, 'created': '2019-02-20 09:59:55.000000000', 'files': ['placement/objects/user.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/3c8c2d75b4db0645fa423862bea7d70973e54d8e', 'message': ""Don't use OVO in User object\n\nThis changes the User object to be a plain Python object\nwith an explicit __init__.\n\nChange-Id: I0e0019e34d58ce0375ee2a2495786ee2f48b5b49\n""}]",0,636803,3c8c2d75b4db0645fa423862bea7d70973e54d8e,16,5,4,11564,,,0,"Don't use OVO in User object

This changes the User object to be a plain Python object
with an explicit __init__.

Change-Id: I0e0019e34d58ce0375ee2a2495786ee2f48b5b49
",git fetch https://review.opendev.org/openstack/placement refs/changes/03/636803/4 && git format-patch -1 --stdout FETCH_HEAD,['placement/objects/user.py'],1,87941908e3da5d789966d2d3d13a06c754056bf1,cd/less-ovo,"class User(object): def __init__(self, context, id=None, external_id=None, updated_at=None, created_at=None): self._context = context self.id = id self.external_id = external_id self.updated_at = updated_at self.created_at = created_at target.id = source['id'] target.external_id = source['external_id'] target.updated_at = source['updated_at'] target.created_at = source['created_at']","from oslo_versionedobjects import base from oslo_versionedobjects import fields@base.VersionedObjectRegistry.register_if(False) class User(base.VersionedObject): fields = { 'id': fields.IntegerField(read_only=True), 'external_id': fields.StringField(nullable=False), } for field in target.fields: setattr(target, field, source[field]) target.obj_reset_changes()",12,12
openstack%2Fplacement~master~Ibf842714c749095cabb5751206116ca9448d9195,openstack/placement,master,Ibf842714c749095cabb5751206116ca9448d9195,Don't use OVO in Consumer object,MERGED,2019-02-14 01:24:07.000000000,2019-02-23 07:45:36.000000000,2019-02-23 07:45:35.000000000,"[{'_account_id': 7}, {'_account_id': 7634}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-14 01:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/6c366e928bf66994901f2022c3bf7ac592ce35e5', 'message': ""Don't use OVO in Consumer object\n\nTurn Consumer into a classical object by adding an extensive\nan explicit constructor and removing OVO related things.\n\nChange-Id: Ibf842714c749095cabb5751206116ca9448d9195\n""}, {'number': 2, 'created': '2019-02-14 12:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/ab9b4f59d4238b7d00c1700295fe6e876b5b7b0f', 'message': ""Don't use OVO in Consumer object\n\nTurn Consumer into a classical object by adding an extensive\nan explicit constructor and removing OVO related things.\n\nChange-Id: Ibf842714c749095cabb5751206116ca9448d9195\n""}, {'number': 3, 'created': '2019-02-15 17:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/01b572a8394446b09fc1da968d4fe744e3cd5114', 'message': ""Don't use OVO in Consumer object\n\nTurn Consumer into a classical object by adding an extensive\nan explicit constructor and removing OVO related things.\n\nChange-Id: Ibf842714c749095cabb5751206116ca9448d9195\n""}, {'number': 4, 'created': '2019-02-20 09:59:55.000000000', 'files': ['placement/objects/consumer.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/d4c3b8807ecb7c9900d11a5c7ce462f0d9fed7e8', 'message': ""Don't use OVO in Consumer object\n\nTurn Consumer into a classical object by adding an extensive\nan explicit constructor and removing OVO related things.\n\nChange-Id: Ibf842714c749095cabb5751206116ca9448d9195\n""}]",1,636801,d4c3b8807ecb7c9900d11a5c7ce462f0d9fed7e8,14,4,4,11564,,,0,"Don't use OVO in Consumer object

Turn Consumer into a classical object by adding an extensive
an explicit constructor and removing OVO related things.

Change-Id: Ibf842714c749095cabb5751206116ca9448d9195
",git fetch https://review.opendev.org/openstack/placement refs/changes/01/636801/2 && git format-patch -1 --stdout FETCH_HEAD,['placement/objects/consumer.py'],1,6c366e928bf66994901f2022c3bf7ac592ce35e5,cd/less-ovo,"class Consumer(object): def __init__(self, context, id=None, uuid=None, project=None, user=None, generation=None, updated_at=None, created_at=None): self._context = context self.id = id self.uuid = uuid self.project = project self.user = user self.generation = generation self.updated_at = updated_at self.created_at = created_at","from oslo_versionedobjects import base from oslo_versionedobjects import fields@base.VersionedObjectRegistry.register_if(False) class Consumer(base.VersionedObject, base.TimestampedObject): fields = { 'id': fields.IntegerField(read_only=True), 'uuid': fields.UUIDField(nullable=False), 'project': fields.ObjectField('Project', nullable=False), 'user': fields.ObjectField('User', nullable=False), 'generation': fields.IntegerField(nullable=False), } target.obj_reset_changes() self.obj_reset_changes() self.obj_reset_changes()",11,14
openstack%2Fplacement~master~I3edf04d39acc905f736cebda9e81e6b4c7786477,openstack/placement,master,I3edf04d39acc905f736cebda9e81e6b4c7786477,Don't use OVO for Usage and UsageList,MERGED,2019-02-13 17:53:22.000000000,2019-02-23 07:45:35.000000000,2019-02-23 07:45:35.000000000,"[{'_account_id': 7}, {'_account_id': 7634}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-13 17:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/ee971c9c0f6d5d22c75e1821fad9f3e1b908c7ce', 'message': ""Don't use OVO for Usage and UsageList\n\nThis turns the Usage and UsageList classes into classical objects.\nThe main point of interest here is the creation of a _set_objects\nmethod to replace base.obj_make_list. It doesn't essentially the\nsame thing: creates instances of the contained thing (Usage) on\nthe UsageList.\n\nChange-Id: I3edf04d39acc905f736cebda9e81e6b4c7786477\n""}, {'number': 2, 'created': '2019-02-14 01:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/d255abf2bf170700a81fce766646a35e8e7170ef', 'message': ""Don't use OVO for Usage and UsageList\n\nThis turns the Usage and UsageList classes into classical objects.\nThe main point of interest here is the creation of a _set_objects\nmethod to replace base.obj_make_list. It does essentially the\nsame thing: creates instances of the contained thing (Usage) on\nthe UsageList.\n\nChange-Id: I3edf04d39acc905f736cebda9e81e6b4c7786477\n""}, {'number': 3, 'created': '2019-02-14 12:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/2702c58bf779db7f4651b930b01fee1221eb3031', 'message': ""Don't use OVO for Usage and UsageList\n\nThis turns the Usage and UsageList classes into classical objects.\nThe main point of interest here is the creation of a _set_objects\nmethod to replace base.obj_make_list. It does essentially the\nsame thing: creates instances of the contained thing (Usage) on\nthe UsageList.\n\nChange-Id: I3edf04d39acc905f736cebda9e81e6b4c7786477\n""}, {'number': 4, 'created': '2019-02-15 17:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/42715f69cec1e394121e38a9519c1d6b901c569b', 'message': ""Don't use OVO for Usage and UsageList\n\nThis turns the Usage and UsageList classes into classical objects.\nThe main point of interest here is the creation of a _set_objects\nmethod to replace base.obj_make_list. It does essentially the\nsame thing: creates instances of the contained thing (Usage) on\nthe UsageList.\n\nChange-Id: I3edf04d39acc905f736cebda9e81e6b4c7786477\n""}, {'number': 5, 'created': '2019-02-20 09:59:55.000000000', 'files': ['placement/objects/resource_provider.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/1d0933f57c1e7849da2c2bd292ba8e29d768059f', 'message': ""Don't use OVO for Usage and UsageList\n\nThis turns the Usage and UsageList classes into classical objects.\nThe main point of interest here is the creation of a _set_objects\nmethod to replace base.obj_make_list. It does essentially the\nsame thing: creates instances of the contained thing (Usage) on\nthe UsageList.\n\nChange-Id: I3edf04d39acc905f736cebda9e81e6b4c7786477\n""}]",8,636695,1d0933f57c1e7849da2c2bd292ba8e29d768059f,19,5,5,11564,,,0,"Don't use OVO for Usage and UsageList

This turns the Usage and UsageList classes into classical objects.
The main point of interest here is the creation of a _set_objects
method to replace base.obj_make_list. It does essentially the
same thing: creates instances of the contained thing (Usage) on
the UsageList.

Change-Id: I3edf04d39acc905f736cebda9e81e6b4c7786477
",git fetch https://review.opendev.org/openstack/placement refs/changes/95/636695/2 && git format-patch -1 --stdout FETCH_HEAD,['placement/objects/resource_provider.py'],1,ee971c9c0f6d5d22c75e1821fad9f3e1b908c7ce,cd/less-ovo,"class Usage(object): def __init__(self, resource_class=None, resource_class_id=None, usage=0): self.resource_class = resource_class if resource_class_id is not None: self.resource_class = _RC_CACHE.string_from_id(resource_class_id) self.usage = usageclass UsageList(object): def __init__(self, context, objects=None): self.objects = objects or [] def __len__(self): """"""List length is a proxy for truthiness."""""" return len(self.objects) def __getitem__(self, index): return self.objects[index] @staticmethod def _set_objects(list_obj, item_cls, db_list): for db_item in db_list: list_obj.objects.append(item_cls(**db_item)) return list_obj return cls._set_objects(cls(context), Usage, usage_list) return cls._set_objects(cls(context), Usage, usage_list)","@base.VersionedObjectRegistry.register_if(False) class Usage(base.VersionedObject): fields = { 'resource_class': fields.StringField(read_only=True), 'usage': fields.NonNegativeIntegerField(), }@base.VersionedObjectRegistry.register_if(False) class UsageList(base.ObjectListBase, base.VersionedObject): fields = { 'objects': fields.ListOfObjectsField('Usage'), } return base.obj_make_list(context, cls(context), Usage, usage_list) return base.obj_make_list(context, cls(context), Usage, usage_list)",24,13
openstack%2Fplacement~master~I2f82e00f5f409fe95dc27f9ab091dd6c95bfc346,openstack/placement,master,I2f82e00f5f409fe95dc27f9ab091dd6c95bfc346,Don't use OVO for Allocation and AllocationList,MERGED,2019-02-13 17:53:22.000000000,2019-02-23 07:45:34.000000000,2019-02-23 07:45:34.000000000,"[{'_account_id': 7}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-13 17:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/d014f85f2e428e01460d3c7b82acd4eb6bded165', 'message': ""Don't use OVO for Allocation and AllocationList\n\nContinuing the experiment to see the impact of review OVO from\nintermediary (between the HTTP API and the DB) classes in placement.\n\nThis change turns Allocation and AllocationList into classical\nobjects. In the process an unused context field is removed\nfrom creators of Allocations.\n\nChange-Id: I2f82e00f5f409fe95dc27f9ab091dd6c95bfc346\n""}, {'number': 2, 'created': '2019-02-14 01:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/1fbbab11721285f757948db76deb352b3573ae13', 'message': ""Don't use OVO for Allocation and AllocationList\n\nContinuing the experiment to see the impact of review OVO from\nintermediary (between the HTTP API and the DB) classes in placement.\n\nThis change turns Allocation and AllocationList into classical\nobjects. In the process an unused context field is removed\nfrom creators of Allocations.\n\nChange-Id: I2f82e00f5f409fe95dc27f9ab091dd6c95bfc346\n""}, {'number': 3, 'created': '2019-02-14 12:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/66b0e890be9f531742a10edba41dbd9d35207994', 'message': ""Don't use OVO for Allocation and AllocationList\n\nContinuing the experiment to see the impact of review OVO from\nintermediary (between the HTTP API and the DB) classes in placement.\n\nThis change turns Allocation and AllocationList into classical\nobjects. In the process an unused context field is removed\nfrom creators of Allocations.\n\nChange-Id: I2f82e00f5f409fe95dc27f9ab091dd6c95bfc346\n""}, {'number': 4, 'created': '2019-02-15 17:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/34a172174766a671616a1a565c988b5b8a8d2dfe', 'message': ""Don't use OVO for Allocation and AllocationList\n\nContinuing the experiment to see the impact of review OVO from\nintermediary (between the HTTP API and the DB) classes in placement.\n\nThis change turns Allocation and AllocationList into classical\nobjects. In the process an unused context field is removed\nfrom creators of Allocations, of which there are many.\n\nChange-Id: I2f82e00f5f409fe95dc27f9ab091dd6c95bfc346\n""}, {'number': 5, 'created': '2019-02-20 09:59:55.000000000', 'files': ['placement/tests/functional/db/test_base.py', 'placement/tests/functional/db/test_consumer.py', 'placement/tests/functional/db/test_resource_provider.py', 'placement/objects/resource_provider.py', 'placement/tests/functional/db/test_reshape.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/7f7f2f4180c4a84f616e800f2b18ee7d6c6f8565', 'message': ""Don't use OVO for Allocation and AllocationList\n\nContinuing the experiment to see the impact of review OVO from\nintermediary (between the HTTP API and the DB) classes in placement.\n\nThis change turns Allocation and AllocationList into classical\nobjects. In the process an unused context field is removed\nfrom creators of Allocations, of which there are many.\n\nChange-Id: I2f82e00f5f409fe95dc27f9ab091dd6c95bfc346\n""}]",15,636694,7f7f2f4180c4a84f616e800f2b18ee7d6c6f8565,22,4,5,11564,,,0,"Don't use OVO for Allocation and AllocationList

Continuing the experiment to see the impact of review OVO from
intermediary (between the HTTP API and the DB) classes in placement.

This change turns Allocation and AllocationList into classical
objects. In the process an unused context field is removed
from creators of Allocations, of which there are many.

Change-Id: I2f82e00f5f409fe95dc27f9ab091dd6c95bfc346
",git fetch https://review.opendev.org/openstack/placement refs/changes/94/636694/2 && git format-patch -1 --stdout FETCH_HEAD,"['placement/tests/functional/db/test_base.py', 'placement/tests/functional/db/test_resource_provider.py', 'placement/objects/resource_provider.py']",3,d014f85f2e428e01460d3c7b82acd4eb6bded165,cd/less-ovo,"class Allocation(object): def __init__(self, id=None, resource_provider=None, consumer=None, resource_class=None, used=0, updated_at=None, created_at=None): self.id = id self.resource_provider = resource_provider self.resource_class = resource_class self.consumer = consumer self.used = used self.updated_at = updated_at self.created_at = created_atclass AllocationList(object): def __init__(self, context, objects=None): self._context = context self.objects = objects or [] def __len__(self): """"""List length is a proxy for truthiness."""""" return len(self.objects) def __getitem__(self, index): return self.objects[index] id=rec['id'], resource_provider=rp, id=rec['id'],","@base.VersionedObjectRegistry.register_if(False) class Allocation(base.VersionedObject, base.TimestampedObject): fields = { 'id': fields.IntegerField(), 'resource_provider': fields.ObjectField('ResourceProvider'), 'consumer': fields.ObjectField('Consumer', nullable=False), 'resource_class': fields.StringField(), 'used': fields.IntegerField(), }@base.VersionedObjectRegistry.register_if(False) class AllocationList(base.ObjectListBase, base.VersionedObject): fields = { 'objects': fields.ListOfObjectsField('Allocation'), } alloc.obj_reset_changes() context, id=rec['id'], resource_provider=rp, context, id=rec['id'],",28,32
openstack%2Fplacement~master~I765fef25120204ac364e6f9b0343f1bda8ac86fe,openstack/placement,master,I765fef25120204ac364e6f9b0343f1bda8ac86fe,Don't use OVO with allocation candidates,MERGED,2019-02-13 14:00:59.000000000,2019-02-23 07:37:16.000000000,2019-02-23 07:37:15.000000000,"[{'_account_id': 7}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-13 14:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/2b96a2c4179f278c8e5b38e084a0618e6d8320c2', 'message': ""DNM: Don't use OVO with allocation candidates\n\nI did some fairly basic benchmarking a while back which indicated\nthat apart from time spent in the database, the value coercing\nand type checking that happens in OVO and the associate getters\nand setters accounts for a fair bit of time and a rather large\nnumber of the function calls.\n\nThis change is an experiment to see if using (very) basic objects\nwith allocation candidates (and the objects nested within) instead\nof OVO objects is of any use. Use can be defined in a variety of\nways:\n\n* Is more performant\n* Is more maintainable\n* Doesn't remove functionality\n\nDon't know yet, this is just an experiment.\n\nThings to watch out for/question/be aware of:\n\n* None of the objects involved here need a context member. Wherever\n  context is used it is supplied by the callers.\n* Type checking is gone. In this particular context it should matter:\n  there's no external interface to these objects. An argument could\n  be made that the type checking is of use to developers, but we have\n  type checking at both the DB and HTTP API levels (and tests, of\n  course). At the intermediary provided by the objects it might be\n  noise, especially if the performance impact is noticeable.\n* If we wanted to do, this could go further, to named tuples, attrs,\n  a superclass which does the field management, but so far that seems\n  overkill for the classes changed thus far.\n\nChange-Id: I765fef25120204ac364e6f9b0343f1bda8ac86fe\n""}, {'number': 2, 'created': '2019-02-14 01:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/dd5d8edaf66230c28d6f8945183719b5902ba8d3', 'message': ""DNM: Don't use OVO with allocation candidates\n\nI did some fairly basic benchmarking a while back which indicated\nthat apart from time spent in the database, the value coercing\nand type checking that happens in OVO and the associate getters\nand setters accounts for a fair bit of time and a rather large\nnumber of the function calls.\n\nThis change is an experiment to see if using (very) basic objects\nwith allocation candidates (and the objects nested within) instead\nof OVO objects is of any use. Use can be defined in a variety of\nways:\n\n* Is more performant\n* Is more maintainable\n* Doesn't remove functionality\n\nDon't know yet, this is just an experiment.\n\nThings to watch out for/question/be aware of:\n\n* None of the objects involved here need a context member. Wherever\n  context is used it is supplied by the callers.\n* Type checking is gone. In this particular context it shouldn't matter:\n  there's no external interface to these objects. An argument could\n  be made that the type checking is of use to developers, but we have\n  type checking at both the DB and HTTP API levels (and tests, of\n  course). At the intermediary provided by the objects it might be\n  noise, especially if the performance impact is noticeable.\n* If we wanted to do, this could go further, to named tuples, attrs,\n  a superclass which does the field management, but so far that seems\n  overkill for the classes changed thus far.\n\nChange-Id: I765fef25120204ac364e6f9b0343f1bda8ac86fe\n""}, {'number': 3, 'created': '2019-02-14 10:49:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/9b329839b7a49ec2474be7037c65f464d1ecc0f7', 'message': ""DNM: Don't use OVO with allocation candidates\n\nI did some fairly basic benchmarking a while back which indicated\nthat apart from time spent in the database, the value coercing\nand type checking that happens in OVO and the associate getters\nand setters accounts for a fair bit of time and a rather large\nnumber of the function calls.\n\nThis change is an experiment to see if using (very) basic objects\nwith allocation candidates (and the objects nested within) instead\nof OVO objects is of any use. Use can be defined in a variety of\nways:\n\n* Is more performant\n* Is more maintainable\n* Doesn't remove functionality\n\nDon't know yet, this is just an experiment.\n\nThings to watch out for/question/be aware of:\n\n* None of the objects involved here need a context member. Wherever\n  context is used it is supplied by the callers.\n* Type checking is gone. In this particular context it shouldn't matter:\n  there's no external interface to these objects. An argument could\n  be made that the type checking is of use to developers, but we have\n  type checking at both the DB and HTTP API levels (and tests, of\n  course). At the intermediary provided by the objects it might be\n  noise, especially if the performance impact is noticeable.\n* If we wanted to do, this could go further, to named tuples, attrs,\n  a superclass which does the field management, but so far that seems\n  overkill for the classes changed thus far.\n\nChange-Id: I765fef25120204ac364e6f9b0343f1bda8ac86fe\n""}, {'number': 4, 'created': '2019-02-14 12:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/cdb14e5f6564af3e8ab69a1eec134879a9b87f10', 'message': ""DNM: Don't use OVO with allocation candidates\n\nI did some fairly basic benchmarking a while back which indicated\nthat apart from time spent in the database, the value coercing\nand type checking that happens in OVO and the associated getters\nand setters accounts for a fair bit of time and a rather large\nnumber of the function calls.\n\nThis change and its children explores if using (very) basic objects\ninstead of OVO will work and be of any benefit. In this patch,\nallocation candidates and the objects nested within are modified.\n\nBenefit can be defined in a variety of ways:\n\n* Is more performant\n* Is more maintainable\n* Doesn't remove functionality\n\nDon't know yet, this is just an experiment.\n\nThings to watch out for/question/be aware of:\n\n* None of the objects involved here need a context member. Wherever\n  context is used it is supplied by the callers.\n* Type checking is gone. In this particular context it shouldn'tx\n  normally matter: there's no external interface to these objects.\n  An argument could be made that the type checking is of use to\n  developers, but we have type checking at both the DB and HTTP\n  API levels (and tests, of course). At the intermediary\n  provided by the objects it might be noise, especially if the\n  performance impact is noticeable.\n* Type coercing is sometimes important. For example values that\n  are the result of sql query including a func.sum will be\n  presented as a Python Decimal. If this value makes it to the\n  json serializer, json will barf. A change is included here\n  for the 'used' value that shows up in allocation candidate\n  results. Note that this problem doesn't show up in functional\n  tests, just tempest and grenade, because it needs MySQL to\n  happen.\n* If we wanted to do, this could go further, to named tuples, attrs,\n  a superclass which does the field management, but so far that seems\n  overkill for the classes changed thus far.\n\nChange-Id: I765fef25120204ac364e6f9b0343f1bda8ac86fe\n""}, {'number': 5, 'created': '2019-02-15 17:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/b54733af92e94e1b29448662f426dda50331662e', 'message': ""Don't use OVO with allocation candidates\n\nI did some fairly basic benchmarking a while back which indicated\nthat apart from time spent in the database, the value coercing\nand type checking that happens in OVO and the associated getters\nand setters accounts for a fair bit of time and a rather large\nnumber of the function calls.\n\nThis change and its children explores if using (very) basic objects\ninstead of OVO will work and be of any benefit. In this patch,\nallocation candidates and the objects nested within are modified.\n\nBenefit can be defined in a variety of ways:\n\n* Is more performant\n* Is more maintainable\n* Doesn't remove functionality\n\nThings to watch out for/question/be aware of:\n\n* None of the objects involved here need a context member. Wherever\n  context is used it is supplied by the callers.\n* Type checking is gone. In this particular context it shouldn't\n  normally matter: there's no external interface to these objects.\n  An argument could be made that the type checking is of use to\n  developers, but we have type checking at both the DB and HTTP\n  API levels (and tests, of course). At the intermediary\n  provided by the objects it might be noise, especially if the\n  performance impact is noticeable.\n* Type coercing is sometimes important. For example values that\n  are the result of sql query including a func.sum will be\n  presented as a Python Decimal. If this value makes it to the\n  json serializer, json will barf. A change is included here\n  for the 'used' value that shows up in allocation candidate\n  results. Note that this problem doesn't show up in functional\n  tests, just tempest and grenade, because it needs MySQL to\n  happen.\n* If we wanted to do, this could go further, to named tuples, attrs,\n  or a superclass which does the field management, but so far that seems\n  overkill for the classes changed thus far. Sticking simple classes\n  gives us the explicit functionality we want without much in\n  the way of overhead.\n\nPatches following this one change other OVO-based objects. Once they\nare all changed, patterns of commonality will be analysed to drive\nsome refactorings and cleanups to limit duplication.\n\nChange-Id: I765fef25120204ac364e6f9b0343f1bda8ac86fe\n""}, {'number': 6, 'created': '2019-02-20 09:59:55.000000000', 'files': ['placement/tests/unit/objects/test_resource_provider.py', 'placement/objects/resource_provider.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/d51dcaa87c416ea0a69074d2ad4de26d72bbefa1', 'message': ""Don't use OVO with allocation candidates\n\nI did some fairly basic benchmarking a while back which indicated\nthat apart from time spent in the database, the value coercing\nand type checking that happens in OVO and the associated getters\nand setters accounts for a fair bit of time and a rather large\nnumber of the function calls.\n\nThis change and its children explores if using (very) basic objects\ninstead of OVO will work and be of any benefit. In this patch,\nallocation candidates and the objects nested within are modified.\n\nBenefit can be defined in a variety of ways:\n\n* Is more performant\n* Is more maintainable\n* Doesn't remove functionality\n\nThings to watch out for/question/be aware of:\n\n* None of the objects involved here need a context member. Wherever\n  context is used it is supplied by the callers.\n* Type checking is gone. In this particular context it shouldn't\n  normally matter: there's no external interface to these objects.\n  An argument could be made that the type checking is of use to\n  developers, but we have type checking at both the DB and HTTP\n  API levels (and tests, of course). At the intermediary\n  provided by the objects it might be noise, especially if the\n  performance impact is noticeable.\n* Type coercing is sometimes important. For example values that\n  are the result of sql query including a func.sum will be\n  presented as a Python Decimal. If this value makes it to the\n  json serializer, json will barf. A change is included here\n  for the 'used' value that shows up in allocation candidate\n  results. Note that this problem doesn't show up in functional\n  tests, just tempest and grenade, because it needs MySQL to\n  happen.\n* If we wanted to do, this could go further, to named tuples, attrs,\n  or a superclass which does the field management, but so far that seems\n  overkill for the classes changed thus far. Sticking simple classes\n  gives us the explicit functionality we want without much in\n  the way of overhead.\n\nPatches following this one change other OVO-based objects. Once they\nare all changed, patterns of commonality will be analysed to drive\nsome refactorings and cleanups to limit duplication.\n\nChange-Id: I765fef25120204ac364e6f9b0343f1bda8ac86fe\n""}]",22,636631,d51dcaa87c416ea0a69074d2ad4de26d72bbefa1,36,6,6,11564,,,0,"Don't use OVO with allocation candidates

I did some fairly basic benchmarking a while back which indicated
that apart from time spent in the database, the value coercing
and type checking that happens in OVO and the associated getters
and setters accounts for a fair bit of time and a rather large
number of the function calls.

This change and its children explores if using (very) basic objects
instead of OVO will work and be of any benefit. In this patch,
allocation candidates and the objects nested within are modified.

Benefit can be defined in a variety of ways:

* Is more performant
* Is more maintainable
* Doesn't remove functionality

Things to watch out for/question/be aware of:

* None of the objects involved here need a context member. Wherever
  context is used it is supplied by the callers.
* Type checking is gone. In this particular context it shouldn't
  normally matter: there's no external interface to these objects.
  An argument could be made that the type checking is of use to
  developers, but we have type checking at both the DB and HTTP
  API levels (and tests, of course). At the intermediary
  provided by the objects it might be noise, especially if the
  performance impact is noticeable.
* Type coercing is sometimes important. For example values that
  are the result of sql query including a func.sum will be
  presented as a Python Decimal. If this value makes it to the
  json serializer, json will barf. A change is included here
  for the 'used' value that shows up in allocation candidate
  results. Note that this problem doesn't show up in functional
  tests, just tempest and grenade, because it needs MySQL to
  happen.
* If we wanted to do, this could go further, to named tuples, attrs,
  or a superclass which does the field management, but so far that seems
  overkill for the classes changed thus far. Sticking simple classes
  gives us the explicit functionality we want without much in
  the way of overhead.

Patches following this one change other OVO-based objects. Once they
are all changed, patterns of commonality will be analysed to drive
some refactorings and cleanups to limit duplication.

Change-Id: I765fef25120204ac364e6f9b0343f1bda8ac86fe
",git fetch https://review.opendev.org/openstack/placement refs/changes/31/636631/2 && git format-patch -1 --stdout FETCH_HEAD,"['placement/tests/unit/objects/test_resource_provider.py', 'placement/objects/resource_provider.py']",2,2b96a2c4179f278c8e5b38e084a0618e6d8320c2,cd/less-ovo,"class AllocationRequestResource(object): def __init__(self, resource_provider=None, resource_class=None, amount=None): self.resource_provider = resource_provider self.resource_class = resource_class self.amount = amount class AllocationRequest(object): def __init__(self, anchor_root_provider_uuid=None, use_same_provider=None, resource_requests=None): self.anchor_root_provider_uuid = anchor_root_provider_uuid self.use_same_provider = use_same_provider self.resource_requests = resource_requests or [] if self.anchor_root_provider_uuid else '<?>') usp = self.use_same_provider if self.use_same_provider else '<?>' (self.__class__.__name__, anchor, usp,class ProviderSummaryResource(object): def __init__(self, resource_class=None, capacity=None, used=None, max_unit=None): self.resource_class = resource_class self.capacity = capacity self.used = used self.max_unit = max_unit class ProviderSummary(object): def __init__(self, resource_provider=None, resources=None, traits=None): self.resource_provider = resource_provider self.resources = resources or [] self.traits = traits or [] resource_provider=provider, resource_requests=resource_requests, resource_provider=rp_summary.resource_provider, AllocationRequest(resource_requests=list(res_requests),class AllocationCandidates(object): def __init__(self, allocation_requests=None, provider_summaries=None): self.allocation_requests = allocation_requests self.provider_summaries = provider_summaries","@base.VersionedObjectRegistry.register_if(False) class AllocationRequestResource(base.VersionedObject): fields = { 'resource_provider': fields.ObjectField('ResourceProvider'), 'resource_class': fields.StringField(read_only=True), 'amount': fields.NonNegativeIntegerField(), } @base.VersionedObjectRegistry.register_if(False) class AllocationRequest(base.VersionedObject): fields = { 'anchor_root_provider_uuid': fields.UUIDField(), 'use_same_provider': fields.BooleanField(), 'resource_requests': fields.ListOfObjectsField( 'AllocationRequestResource' ), } if 'anchor_root_provider_uuid' in self else '<?>') usp = self.use_same_provider if 'use_same_provider' in self else '<?>' (self.obj_name(), anchor, usp,@base.VersionedObjectRegistry.register_if(False) class ProviderSummaryResource(base.VersionedObject): fields = { 'resource_class': fields.StringField(read_only=True), 'capacity': fields.NonNegativeIntegerField(), 'used': fields.NonNegativeIntegerField(), 'max_unit': fields.NonNegativeIntegerField(), } @base.VersionedObjectRegistry.register_if(False) class ProviderSummary(base.VersionedObject): fields = { 'resource_provider': fields.ObjectField('ResourceProvider'), 'resources': fields.ListOfObjectsField('ProviderSummaryResource'), 'traits': fields.ListOfObjectsField('Trait'), } context, context, ctx, resource_provider=provider, ctx, resource_requests=resource_requests, ctx, resource_provider=rp_summary.resource_provider, AllocationRequest(ctx, resource_requests=list(res_requests),@base.VersionedObjectRegistry.register_if(False) class AllocationCandidates(base.VersionedObject): fields = { 'allocation_requests': fields.ListOfObjectsField('AllocationRequest'), 'provider_summaries': fields.ListOfObjectsField('ProviderSummary'), } context,",37,51
openstack%2Fnova~master~I90845461b2b98c176c7b3b97dd3f47ed604a9bef,openstack/nova,master,I90845461b2b98c176c7b3b97dd3f47ed604a9bef,Follow up for I0c764e441993e32aafef0b18049a425c3c832a50,MERGED,2019-02-21 22:04:38.000000000,2019-02-23 06:26:14.000000000,2019-02-22 14:37:12.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-21 22:04:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b4eee1c946d9e8b7c7885144672b07cda9b8c38b', 'message': 'Follow up for I0c764e441993e32aafef0b18049a425c3c832a50\n\nThis is a follow up for change\nI0c764e441993e32aafef0b18049a425c3c832a50 to address\nreview comments.\n\nThe most important part is the early exit from\n_fill_provider_mapping if request_spec.maps_requested_resources\nreturns False. That is needed to avoid the performance\nimpact of getting allocations and resource provider traits\nper instance and provider. Since this code is currently only\ngoing to be exercised with ports that have resource requests,\nwe want to avoid the extra work for all other server create\nrequests.\n\nPart of blueprint bandwidth-resource-provider\n\nChange-Id: I90845461b2b98c176c7b3b97dd3f47ed604a9bef\n'}, {'number': 2, 'created': '2019-02-22 09:57:19.000000000', 'files': ['nova/objects/request_spec.py', 'nova/tests/functional/test_report_client.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/client/report.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/39ec15f58c0da6e9a6b12e785e72145d2c3cd418', 'message': 'Follow up for I0c764e441993e32aafef0b18049a425c3c832a50\n\nThis is a follow up for change\nI0c764e441993e32aafef0b18049a425c3c832a50 to address\nreview comments.\n\nThe most important part is the early exit from\n_fill_provider_mapping if request_spec.maps_requested_resources\nreturns False. That is needed to avoid the performance\nimpact of getting allocations and resource provider traits\nper instance and provider. Since this code is currently only\ngoing to be exercised with ports that have resource requests,\nwe want to avoid the extra work for all other server create\nrequests.\n\nPart of blueprint bandwidth-resource-provider\n\nChange-Id: I90845461b2b98c176c7b3b97dd3f47ed604a9bef\n'}]",1,638517,39ec15f58c0da6e9a6b12e785e72145d2c3cd418,24,13,2,6873,,,0,"Follow up for I0c764e441993e32aafef0b18049a425c3c832a50

This is a follow up for change
I0c764e441993e32aafef0b18049a425c3c832a50 to address
review comments.

The most important part is the early exit from
_fill_provider_mapping if request_spec.maps_requested_resources
returns False. That is needed to avoid the performance
impact of getting allocations and resource provider traits
per instance and provider. Since this code is currently only
going to be exercised with ports that have resource requests,
we want to avoid the extra work for all other server create
requests.

Part of blueprint bandwidth-resource-provider

Change-Id: I90845461b2b98c176c7b3b97dd3f47ed604a9bef
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/638517/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/request_spec.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/client/report.py', 'nova/conductor/manager.py']",5,b4eee1c946d9e8b7c7885144672b07cda9b8c38b,bp/bandwidth-resource-provider," This is a workaround as placement does not return which RP # Exit early if this request spec does not require mappings. if not request_spec.maps_requested_resources: return # TODO(mriedem): Could we use the Selection.allocation_request here # to get the resource providers rather than making an API call to # placement per instance being scheduled? Granted that is a # PUT /allocations/{consumer_id} *request* payload rather than a # *response* but at least currently they are in the same format and # could make this faster. allocs = self.report_client.get_allocs_for_consumer( context, instance_uuid)['allocations'] if not allocs: # Technically out-of-tree scheduler drivers can still not create # allocations in placement so move on if there are no allocations # for the instance. LOG.debug('No allocations found for instance after scheduling. ' 'Assuming the scheduler driver is not using Placement.', instance_uuid=instance_uuid) return # TODO(mriedem): Short-term we can optimize this by passing a cache by # reference of the RP->traits mapping because if we are processing # a multi-create request we could have the same RPs being used for # multiple instances and avoid duplicate calls. Long-term we could # stash the RP->traits mapping on the Selection object since we can # pull the traits for each provider from the GET /allocation_candidates # response in the scheduler (or leverage the change from the spec # mentioned in the docstring above). provider_traits = { rp_uuid: self.report_client.get_provider_traits( # Now that we have a selected host (which has claimed resource # allocations in the scheduler) for this instance, we may need to # map allocations to resource providers in the request spec. # If anything failed here we need to cleanup and bail out. with excutils.save_and_reraise_exception(): self._cleanup_build_artifacts( context, exc, instances, build_requests, request_specs, block_device_mapping, tags, cell_mapping_cache)"," This is a workaround as placement does not return which PR allocs = self.report_client.get_allocations_for_consumer( context, instance_uuid) provider_traits = { rp_uuid: self.report_client._get_provider_traits( with excutils.save_and_reraise_exception(): self._cleanup_build_artifacts(context, exc, instances, build_requests, request_specs, block_device_mapping, tags, cell_mapping_cache)",94,39
openstack%2Ftempest~master~I47710321d8dfb0345c793e66bd09a5dd1933557b,openstack/tempest,master,I47710321d8dfb0345c793e66bd09a5dd1933557b,Conditionally mark test_attach_detach_volume as slow,MERGED,2019-02-14 19:37:57.000000000,2019-02-23 06:15:23.000000000,2019-02-23 06:15:22.000000000,"[{'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 12033}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2019-02-14 19:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/054dfbf92112194a203589fc507b997df8e9419d', 'message': 'Conditionally mark test_attach_detach_volume as slow\n\nBased on average test times from the last 300 runs\nof the tempest-full job [1] this change marks the\ntest_attach_detach_volume test as slow but only if\nSSH validation is enabled, which it is in tempest-full\nbut might not be in other jobs that run it, for example\nin refstack which uses this test for interoperability\ncertification.\n\n[1] http://paste.openstack.org/show/745114/\n\nChange-Id: I47710321d8dfb0345c793e66bd09a5dd1933557b\nRelated-Bug: #1783405\n'}, {'number': 2, 'created': '2019-02-15 14:01:29.000000000', 'files': ['tempest/api/compute/volumes/test_attach_volume.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/9968315d43bf9fc595d269aafecc78cfdcc06d17', 'message': 'Conditionally mark test_attach_detach_volume as slow\n\nBased on average test times from the last 300 runs\nof the tempest-full job [1] this change marks the\ntest_attach_detach_volume test as slow but only if\nSSH validation is enabled, which it is in tempest-full\nbut might not be in other jobs that run it, for example\nin refstack which uses this test for interoperability\ncertification.\n\n[1] http://paste.openstack.org/show/745114/\n\nChange-Id: I47710321d8dfb0345c793e66bd09a5dd1933557b\nRelated-Bug: #1783405\n'}]",0,637033,9968315d43bf9fc595d269aafecc78cfdcc06d17,15,5,2,6873,,,0,"Conditionally mark test_attach_detach_volume as slow

Based on average test times from the last 300 runs
of the tempest-full job [1] this change marks the
test_attach_detach_volume test as slow but only if
SSH validation is enabled, which it is in tempest-full
but might not be in other jobs that run it, for example
in refstack which uses this test for interoperability
certification.

[1] http://paste.openstack.org/show/745114/

Change-Id: I47710321d8dfb0345c793e66bd09a5dd1933557b
Related-Bug: #1783405
",git fetch https://review.opendev.org/openstack/tempest refs/changes/33/637033/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/volumes/test_attach_volume.py'],1,054dfbf92112194a203589fc507b997df8e9419d,bug/1783405," # This test is conditionally marked slow if SSH validation is enabled. @decorators.attr(type='slow', condition=CONF.validation.run_validation)",,2,0
openstack%2Ftempest~master~I83233854a217b6961e7614d7d9df1b4fc8d5a640,openstack/tempest,master,I83233854a217b6961e7614d7d9df1b4fc8d5a640,Allow decorators.attr to be conditional,MERGED,2019-02-14 19:33:41.000000000,2019-02-23 06:15:20.000000000,2019-02-23 06:15:20.000000000,"[{'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 12033}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2019-02-14 19:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/28bc3cd46a74bd263010ebe983c5f974e7a27a54', 'message': ""Allow decorators.attr to be conditional\n\nThere are cases where we want to conditionally apply an\nattribute to a test function, for example, if SSH validation\nis enabled then a test may run much slower than if it is not.\n\nThis adds a 'condition' kwarg to the attr() decorator which\nbehaves similarly to the 'condition' kwarg on the skip_because()\ndecorator.\n\nChange-Id: I83233854a217b6961e7614d7d9df1b4fc8d5a640\n""}, {'number': 2, 'created': '2019-02-15 14:01:29.000000000', 'files': ['releasenotes/notes/conditional-attr-a8564ec5a70ec840.yaml', 'tempest/lib/decorators.py', 'tempest/tests/lib/test_decorators.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2999963ff8bdfb48d55b5c74b204fef99e4e66ec', 'message': ""Allow decorators.attr to be conditional\n\nThere are cases where we want to conditionally apply an\nattribute to a test function, for example, if SSH validation\nis enabled then a test may run much slower than if it is not.\n\nThis adds a 'condition' kwarg to the attr() decorator which\nbehaves similarly to the 'condition' kwarg on the skip_because()\ndecorator.\n\nChange-Id: I83233854a217b6961e7614d7d9df1b4fc8d5a640\n""}]",0,637032,2999963ff8bdfb48d55b5c74b204fef99e4e66ec,22,5,2,6873,,,0,"Allow decorators.attr to be conditional

There are cases where we want to conditionally apply an
attribute to a test function, for example, if SSH validation
is enabled then a test may run much slower than if it is not.

This adds a 'condition' kwarg to the attr() decorator which
behaves similarly to the 'condition' kwarg on the skip_because()
decorator.

Change-Id: I83233854a217b6961e7614d7d9df1b4fc8d5a640
",git fetch https://review.opendev.org/openstack/tempest refs/changes/32/637032/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/lib/decorators.py', 'tempest/tests/lib/test_decorators.py']",2,28bc3cd46a74bd263010ebe983c5f974e7a27a54,bug/1783405," if 'condition' in decorator_args: if decorator_args['condition']: # The expected attrs should be in the function. self.assertEqual(set(expected_attrs), getattr(foo, '__testtools_attrs')) else: # The expected attrs should not be in the function. self.assertNotIn('__testtools_attrs', foo) else: self.assertEqual(set(expected_attrs), getattr(foo, '__testtools_attrs')) def test_attr_decorator_condition_false(self): self._test_attr_helper(None, type='slow', condition=False) def test_attr_decorator_condition_true(self): self._test_attr_helper(expected_attrs=['slow'], type='slow', condition=True) "," # this is what testtools sets self.assertEqual(getattr(foo, '__testtools_attrs'), set(expected_attrs))",25,3
openstack%2Ftempest~master~Ie8ea1555cc4512bf29dff1e7df592dedfab28c61,openstack/tempest,master,Ie8ea1555cc4512bf29dff1e7df592dedfab28c61,Mark test_server_connectivity_reboot as slow,MERGED,2019-02-14 19:11:59.000000000,2019-02-23 06:15:18.000000000,2019-02-23 06:15:18.000000000,"[{'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 12033}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-14 19:11:59.000000000', 'files': ['tempest/scenario/test_network_advanced_server_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b4763ef57e54c4517de88affb983de1de2f0ac64', 'message': 'Mark test_server_connectivity_reboot as slow\n\nBased on average test run times from the last 300 runs of\nthe tempest-full job [1] the test_server_connectivity_reboot\ntest is third slowest at about 200 seconds. This should not\nbe a surprise given all of the other tests in the same class\nare already marked slow.\n\nThis change marks that test slow like the others which means\nit will be run in the tempest-slow job.\n\n[1] http://paste.openstack.org/show/745114/\n\nChange-Id: Ie8ea1555cc4512bf29dff1e7df592dedfab28c61\nRelated-Bug: #1783405\n'}]",0,637030,b4763ef57e54c4517de88affb983de1de2f0ac64,13,5,1,6873,,,0,"Mark test_server_connectivity_reboot as slow

Based on average test run times from the last 300 runs of
the tempest-full job [1] the test_server_connectivity_reboot
test is third slowest at about 200 seconds. This should not
be a surprise given all of the other tests in the same class
are already marked slow.

This change marks that test slow like the others which means
it will be run in the tempest-slow job.

[1] http://paste.openstack.org/show/745114/

Change-Id: Ie8ea1555cc4512bf29dff1e7df592dedfab28c61
Related-Bug: #1783405
",git fetch https://review.opendev.org/openstack/tempest refs/changes/30/637030/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_network_advanced_server_ops.py'],1,b4763ef57e54c4517de88affb983de1de2f0ac64,bug/1783405, @decorators.attr(type='slow'),,1,0
openstack%2Fopenstack-ansible-os_tempest~master~I8c769b24c41cbe4703336fdadac977c63a9cbef3,openstack/openstack-ansible-os_tempest,master,I8c769b24c41cbe4703336fdadac977c63a9cbef3,Remove the private option from include_role,MERGED,2019-02-22 00:50:18.000000000,2019-02-23 06:14:16.000000000,2019-02-23 06:14:16.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:50:18.000000000', 'files': ['tasks/tempest_install_source.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/c4d586afeafa6cc6419911a245c7b2c1264cabad', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: I8c769b24c41cbe4703336fdadac977c63a9cbef3\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638557,c4d586afeafa6cc6419911a245c7b2c1264cabad,14,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: I8c769b24c41cbe4703336fdadac977c63a9cbef3
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/57/638557/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/tempest_install_source.yml'],1,c4d586afeafa6cc6419911a245c7b2c1264cabad,fix/private/deprecation,, private: yes,0,1
openstack%2Fopenstack-ansible-os_heat~master~I0fe59819c7e2594188e93d7cc482abff74495b8e,openstack/openstack-ansible-os_heat,master,I0fe59819c7e2594188e93d7cc482abff74495b8e,Remove the private option from include_role,MERGED,2019-02-22 00:32:45.000000000,2019-02-23 05:52:35.000000000,2019-02-23 05:52:35.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:32:45.000000000', 'files': ['tasks/main.yml', 'tasks/heat_install_source.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/f393f21d3bf3df35b4eff27dfe506c699114f1c0', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: I0fe59819c7e2594188e93d7cc482abff74495b8e\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638532,f393f21d3bf3df35b4eff27dfe506c699114f1c0,17,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: I0fe59819c7e2594188e93d7cc482abff74495b8e
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/32/638532/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/heat_install_source.yml', 'tasks/main.yml']",2,f393f21d3bf3df35b4eff27dfe506c699114f1c0,fix/private/deprecation,, private: true,0,2
openstack%2Fkolla~master~Ifa4ce62372af3fe75a66b45c8e7cf9ac9f9c2415,openstack/kolla,master,Ifa4ce62372af3fe75a66b45c8e7cf9ac9f9c2415,Remove check for config files to verify MountFlags,MERGED,2016-04-14 05:17:38.000000000,2019-02-23 05:46:56.000000000,2016-04-21 05:43:50.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 4715}, {'_account_id': 7488}, {'_account_id': 11105}, {'_account_id': 13642}, {'_account_id': 13747}, {'_account_id': 16233}, {'_account_id': 19472}]","[{'number': 1, 'created': '2016-04-14 05:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/911b77693d71703a464dcca725c6514253ddf501', 'message': 'check /e/s/s/docker.service.d/kolla.conf in redhat family\n\ncheck ""/etc/systemd/system/docker.service.d/kolla.conf""\ninstead of ""/lib/systemd/system/docker.service"", since\nthe settings in ""/etc/systemd/system/docker.service.d/kolla.conf""\nwill overwrite the settings in ""/lib/systemd/system/docker.service""\n\nChange-Id: Ifa4ce62372af3fe75a66b45c8e7cf9ac9f9c2415\nRelatd-Bug: #1569644\n'}, {'number': 2, 'created': '2016-04-15 15:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/80644fce7752482ca31e41f67c77e14899fcbbd4', 'message': 'check /e/s/s/docker.service.d/kolla.conf in redhat family\n\ncheck ""/etc/systemd/system/docker.service.d/kolla.conf""\ninstead of ""/lib/systemd/system/docker.service"", since\nthe settings in ""/etc/systemd/system/docker.service.d/kolla.conf""\nwill overwrite the settings in ""/lib/systemd/system/docker.service""\n\nChange-Id: Ifa4ce62372af3fe75a66b45c8e7cf9ac9f9c2415\nRelated-Bug: #1569644\n'}, {'number': 3, 'created': '2016-04-17 03:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f645c85caff823eeef27a06e156ad1ddc49cfc9c', 'message': 'Remove check for config files to verify MountFlags\n\nCheck MountFlags option with systemd rather than with\nconfiguration files which can be overriden with\ndifferent ones.\n\nCo-Authored-By: Jeffrey Zhang <jeffrey.zhang@99cloud.net>\nChange-Id: Ifa4ce62372af3fe75a66b45c8e7cf9ac9f9c2415\nRelated-Bug: #1569644\n'}, {'number': 4, 'created': '2016-04-17 03:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e0a4b50a40af3da64fe8ebbe39dfb97184eb88b6', 'message': 'Remove check for config files to verify MountFlags\n\nCheck MountFlags option with systemd rather than with\nconfiguration files which can be overriden with\ndifferent ones.\n\nCo-Authored-By: Jeffrey Zhang <jeffrey.zhang@99cloud.net>\nChange-Id: Ifa4ce62372af3fe75a66b45c8e7cf9ac9f9c2415\nCloses-Bug: #1571281\n'}, {'number': 5, 'created': '2016-04-17 03:24:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b340e1b9670f895cd4d6b420e2b60916b47755c0', 'message': 'Remove check for config files to verify MountFlags\n\nCheck MountFlags option with systemd rather than with\nconfiguration files which can be overriden with\ndifferent ones.\n\nCo-Authored-By: Jeffrey Zhang <jeffrey.zhang@99cloud.net>\nChange-Id: Ifa4ce62372af3fe75a66b45c8e7cf9ac9f9c2415\nCloses-Bug: #1571281\n'}, {'number': 6, 'created': '2016-04-17 04:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/38720903d992decbb6a4d8d6ea254315864cdfe3', 'message': 'Remove check for config files to verify MountFlags\n\nCheck MountFlags option with systemd rather than with\nconfiguration files which can be overriden with\ndifferent ones.\n\nCo-Authored-By: Jeffrey Zhang <jeffrey.zhang@99cloud.net>\nChange-Id: Ifa4ce62372af3fe75a66b45c8e7cf9ac9f9c2415\nCloses-Bug: #1571281\n'}, {'number': 7, 'created': '2016-04-18 04:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/cfc0fbdd3d0f578447a03675599794b87e4fd647', 'message': 'Remove check for config files to verify MountFlags\n\nCheck MountFlags option with systemd rather than with\nconfiguration files which can be overriden with\ndifferent ones.\n\nCo-Authored-By: Jeffrey Zhang <jeffrey.zhang@99cloud.net>\nChange-Id: Ifa4ce62372af3fe75a66b45c8e7cf9ac9f9c2415\nCloses-Bug: #1571281\n'}, {'number': 8, 'created': '2016-04-20 04:45:53.000000000', 'files': ['ansible/roles/prechecks/tasks/service_checks.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/47894bb05f8446d8db645dcd6dc580d5d4ae64d2', 'message': 'Remove check for config files to verify MountFlags\n\nCheck MountFlags option with systemd rather than with\nconfiguration files which can be overriden with\ndifferent ones.\n\nCo-Authored-By: Jeffrey Zhang <jeffrey.zhang@99cloud.net>\nChange-Id: Ifa4ce62372af3fe75a66b45c8e7cf9ac9f9c2415\nCloses-Bug: #1571281\n'}]",2,305611,47894bb05f8446d8db645dcd6dc580d5d4ae64d2,49,9,8,11105,,,0,"Remove check for config files to verify MountFlags

Check MountFlags option with systemd rather than with
configuration files which can be overriden with
different ones.

Co-Authored-By: Jeffrey Zhang <jeffrey.zhang@99cloud.net>
Change-Id: Ifa4ce62372af3fe75a66b45c8e7cf9ac9f9c2415
Closes-Bug: #1571281
",git fetch https://review.opendev.org/openstack/kolla refs/changes/11/305611/2 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/prechecks/tasks/service_checks.yml'],1,911b77693d71703a464dcca725c6514253ddf501,bug/1571281,- name: Checking if 'MountFlags' in /etc/systemd/system/docker.service.d/kolla.conf is set to 'shared' in RedHat family command: cat /etc/systemd/system/docker.service.d/kolla.conf,- name: Checking if 'MountFlags' in /lib/systemd/system/docker.service is set to 'shared' in RedHat family command: cat /lib/systemd/system/docker.service,2,2
openstack%2Fopenstack-ansible-os_keystone~master~Idc55df4d70fb69721158e2b43f21d62ab1e49fee,openstack/openstack-ansible-os_keystone,master,Idc55df4d70fb69721158e2b43f21d62ab1e49fee,Remove the private option from include_role,MERGED,2019-02-22 00:39:53.000000000,2019-02-23 05:37:59.000000000,2019-02-23 05:37:59.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/44b7632444d9394f4a19d9b8dc937811428d297d', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: Idc55df4d70fb69721158e2b43f21d62ab1e49fee\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2019-02-22 14:43:42.000000000', 'files': ['tasks/keystone_uwsgi.yml', 'tasks/keystone_install_source.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/babb87be660c8e601b3919d0dcf59b4e5e91281d', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: Idc55df4d70fb69721158e2b43f21d62ab1e49fee\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638538,babb87be660c8e601b3919d0dcf59b4e5e91281d,14,2,2,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: Idc55df4d70fb69721158e2b43f21d62ab1e49fee
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/38/638538/2 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/keystone_db_setup.yml', 'tasks/keystone_uwsgi.yml', 'tasks/keystone_install_source.yml']",3,44b7632444d9394f4a19d9b8dc937811428d297d,fix/private/deprecation,, private: yes,2,3
openstack%2Fopenstack-ansible-os_nova~master~Ia4185b9af54fbd6e70db3aa37a5799cce44db934,openstack/openstack-ansible-os_nova,master,Ia4185b9af54fbd6e70db3aa37a5799cce44db934,Remove the private option from include_role,MERGED,2019-02-22 00:50:07.000000000,2019-02-23 05:07:26.000000000,2019-02-23 05:07:25.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:50:07.000000000', 'files': ['tasks/main.yml', 'tasks/nova_compute.yml', 'tasks/nova_install_source.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/77a7f2020109c3358f14bd6c5f560222575f3d74', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: Ia4185b9af54fbd6e70db3aa37a5799cce44db934\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638553,77a7f2020109c3358f14bd6c5f560222575f3d74,12,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: Ia4185b9af54fbd6e70db3aa37a5799cce44db934
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/53/638553/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/nova_compute.yml', 'tasks/nova_install_source.yml']",3,77a7f2020109c3358f14bd6c5f560222575f3d74,fix/private/deprecation,, private: yes,0,3
openstack%2Fopenstack-ansible-os_horizon~master~Ib35e88ae10e651917abc764430523ade3bc614c1,openstack/openstack-ansible-os_horizon,master,Ib35e88ae10e651917abc764430523ade3bc614c1,Remove the private option from include_role,MERGED,2019-02-22 00:49:58.000000000,2019-02-23 05:06:09.000000000,2019-02-23 05:06:08.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:49:58.000000000', 'files': ['tasks/horizon_install_source.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/fa3127209c29d57cdbdf69f864528182f1948a1b', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: Ib35e88ae10e651917abc764430523ade3bc614c1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638550,fa3127209c29d57cdbdf69f864528182f1948a1b,15,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: Ib35e88ae10e651917abc764430523ade3bc614c1
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/50/638550/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/horizon_install_source.yml'],1,fa3127209c29d57cdbdf69f864528182f1948a1b,fix/private/deprecation,, private: yes,0,1
openstack%2Fopenstack-ansible-os_cinder~master~I23ad798b251493d75acf1a92f3d5a95d96d02938,openstack/openstack-ansible-os_cinder,master,I23ad798b251493d75acf1a92f3d5a95d96d02938,Remove the private option from include_role,MERGED,2019-02-22 00:39:33.000000000,2019-02-23 05:03:41.000000000,2019-02-23 05:03:41.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:39:33.000000000', 'files': ['tasks/main.yml', 'tasks/cinder_install_source.yml', 'tasks/cinder_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/6e4527aff5c633db6447484f16922ee830113d77', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: I23ad798b251493d75acf1a92f3d5a95d96d02938\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638535,6e4527aff5c633db6447484f16922ee830113d77,16,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: I23ad798b251493d75acf1a92f3d5a95d96d02938
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/35/638535/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/cinder_install_source.yml', 'tasks/cinder_install.yml']",3,6e4527aff5c633db6447484f16922ee830113d77,fix/private/deprecation,, private: true,0,3
openstack%2Fopenstack-ansible-os_keystone~master~I803cd3c62707880e873662ea86590274b2766d21,openstack/openstack-ansible-os_keystone,master,I803cd3c62707880e873662ea86590274b2766d21,Set the user argument in the cron module,MERGED,2019-02-22 02:08:54.000000000,2019-02-23 05:02:14.000000000,2019-02-23 05:02:14.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 02:08:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/7543bae444994b158318b9345dcedc2104ad79ce', 'message': 'Set the user argument in the cron module\n\nThis change sets the user argument in the cron module which is\nrequired in future versions of ansible when the cron_file argument\nis also used.\n\nChange-Id: I803cd3c62707880e873662ea86590274b2766d21\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2019-02-22 02:12:54.000000000', 'files': ['tasks/keystone_credential_create.yml', 'tasks/keystone_uwsgi.yml', 'tasks/keystone_fernet_keys_autorotate.yml', 'tasks/keystone_install_source.yml', 'tasks/keystone_credential_autorotate.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/56eadbfa76c9f5697712731db7d20eb64281b93d', 'message': 'Set the user argument in the cron module\n\nThis change sets the user argument in the cron module which is\nrequired in future versions of ansible when the cron_file argument\nis also used.\n\nFilter deprecations for skipped items have also been fixed.\n\nChange-Id: I803cd3c62707880e873662ea86590274b2766d21\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638573,56eadbfa76c9f5697712731db7d20eb64281b93d,21,2,2,7353,,,0,"Set the user argument in the cron module

This change sets the user argument in the cron module which is
required in future versions of ansible when the cron_file argument
is also used.

Filter deprecations for skipped items have also been fixed.

Change-Id: I803cd3c62707880e873662ea86590274b2766d21
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/73/638573/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/keystone_fernet_keys_autorotate.yml', 'tasks/keystone_credential_autorotate.yml']",2,7543bae444994b158318b9345dcedc2104ad79ce,fix/private/deprecation," user: ""{{ keystone_system_user_name }}""",,2,0
openstack%2Fneutron~master~I429dbbd92a78fdfae3140cae8a397ff10f6d956e,openstack/neutron,master,I429dbbd92a78fdfae3140cae8a397ff10f6d956e,Fix pylint R1714 (consider-using-in) refactor messages,MERGED,2019-02-21 00:46:21.000000000,2019-02-23 04:58:03.000000000,2019-02-23 04:58:03.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9845}, {'_account_id': 10980}, {'_account_id': 13995}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-21 00:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/06206d79b0abc19a4639fe00f9b31411b8bdf834', 'message': ""Fix pylint R1714 (consider-using-in) refactor messages\n\nInstead of checking variables are equal to one of many\nvalues, use a tuple and check if the variable is 'in' it.\nThis is faster and less verbose.\n\nChange-Id: I429dbbd92a78fdfae3140cae8a397ff10f6d956e\n""}, {'number': 2, 'created': '2019-02-21 03:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6c4cabbfb39485d283e01e2c23bd48ceba0478f9', 'message': ""Fix pylint R1714 (consider-using-in) refactor messages\n\nInstead of checking variables are equal to one of many\nvalues, use a tuple and check if the variable is 'in' it.\nThis is faster and less verbose.\n\nChange-Id: I429dbbd92a78fdfae3140cae8a397ff10f6d956e\n""}, {'number': 3, 'created': '2019-02-21 03:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dceadb86c3b4e1d77302a77a5800e397f674aabb', 'message': ""Fix pylint R1714 (consider-using-in) refactor messages\n\nInstead of checking variables are equal to one of many\nvalues, use a tuple and check if the variable is 'in' it.\nThis is faster and less verbose.\n\nChange-Id: I429dbbd92a78fdfae3140cae8a397ff10f6d956e\n""}, {'number': 4, 'created': '2019-02-21 21:11:34.000000000', 'files': ['.pylintrc', 'neutron/cmd/pd_notify.py', 'neutron/objects/port_forwarding.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fba5eb694b0821859719b9ee4e61c36d62eeff20', 'message': ""Fix pylint R1714 (consider-using-in) refactor messages\n\nInstead of checking variables are equal to one of many\nvalues, use a tuple and check if the variable is 'in' it.\nThis is faster and less verbose.\n\nChange-Id: I429dbbd92a78fdfae3140cae8a397ff10f6d956e\n""}]",0,638303,fba5eb694b0821859719b9ee4e61c36d62eeff20,22,8,4,1131,,,0,"Fix pylint R1714 (consider-using-in) refactor messages

Instead of checking variables are equal to one of many
values, use a tuple and check if the variable is 'in' it.
This is faster and less verbose.

Change-Id: I429dbbd92a78fdfae3140cae8a397ff10f6d956e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/03/638303/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/cmd/pd_notify.py', 'neutron/objects/port_forwarding.py', 'neutron/plugins/ml2/plugin.py']",3,06206d79b0abc19a4639fe00f9b31411b8bdf834,pylint-R1714," if event in [events.PRECOMMIT_CREATE, events.PRECOMMIT_DELETE]: elif event in [events.AFTER_CREATE, events.AFTER_DELETE]:", if (event == events.PRECOMMIT_CREATE or event == events.PRECOMMIT_DELETE): elif event == events.AFTER_CREATE or event == events.AFTER_DELETE:,4,5
openstack%2Fopenstack-ansible-os_ceilometer~master~I2e51b92e8bd9416949a124efb248725a223fefd0,openstack/openstack-ansible-os_ceilometer,master,I2e51b92e8bd9416949a124efb248725a223fefd0,Remove the private option from include_role,MERGED,2019-02-22 00:49:45.000000000,2019-02-23 04:54:29.000000000,2019-02-23 04:54:28.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:49:45.000000000', 'files': ['tasks/main.yml', 'tasks/ceilometer_install_source.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/b015c3e82ffa355bd9781ad6d726a0af2ad4e191', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: I2e51b92e8bd9416949a124efb248725a223fefd0\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638547,b015c3e82ffa355bd9781ad6d726a0af2ad4e191,17,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: I2e51b92e8bd9416949a124efb248725a223fefd0
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/47/638547/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/ceilometer_install_source.yml']",2,b015c3e82ffa355bd9781ad6d726a0af2ad4e191,fix/private/deprecation,, private: yes,0,2
openstack%2Fopenstack-ansible-os_glance~master~I011fba2674dc4c6888ba93c0ea90f4d60e4b7657,openstack/openstack-ansible-os_glance,master,I011fba2674dc4c6888ba93c0ea90f4d60e4b7657,Remove the private option from include_role,MERGED,2019-02-22 00:39:40.000000000,2019-02-23 04:54:20.000000000,2019-02-23 04:54:20.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:39:40.000000000', 'files': ['tasks/glance_post_install.yml', 'tasks/glance_install_source.yml', 'tasks/glance_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/c22d786120cf0e31de41f739b3e46e75964864bb', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: I011fba2674dc4c6888ba93c0ea90f4d60e4b7657\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638537,c22d786120cf0e31de41f739b3e46e75964864bb,14,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: I011fba2674dc4c6888ba93c0ea90f4d60e4b7657
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_glance refs/changes/37/638537/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/glance_install_source.yml', 'tasks/glance_post_install.yml', 'tasks/glance_install.yml']",3,c22d786120cf0e31de41f739b3e46e75964864bb,fix/private/deprecation,, private: true,0,3
openstack%2Fopenstack-ansible-os_aodh~master~Ic6d9833c3f801476890ba4313f9ea3860cef155a,openstack/openstack-ansible-os_aodh,master,Ic6d9833c3f801476890ba4313f9ea3860cef155a,Remove the private option from include_role,MERGED,2019-02-22 00:49:39.000000000,2019-02-23 04:53:13.000000000,2019-02-23 04:53:13.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:49:39.000000000', 'files': ['tasks/main.yml', 'tasks/aodh_install_source.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_aodh/commit/35389c78f00bff52933425890a43403a5cbfb1f2', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: Ic6d9833c3f801476890ba4313f9ea3860cef155a\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638545,35389c78f00bff52933425890a43403a5cbfb1f2,25,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: Ic6d9833c3f801476890ba4313f9ea3860cef155a
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_aodh refs/changes/45/638545/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/aodh_install_source.yml']",2,35389c78f00bff52933425890a43403a5cbfb1f2,fix/private/deprecation,, private: yes,0,2
openstack%2Fopenstack-ansible-lxc_hosts~master~Ieb1df06e6581601215851d78fb932a9d1e99e183,openstack/openstack-ansible-lxc_hosts,master,Ieb1df06e6581601215851d78fb932a9d1e99e183,add gentoo support,MERGED,2018-10-06 02:45:24.000000000,2019-02-23 04:35:29.000000000,2019-02-23 04:35:29.000000000,"[{'_account_id': 1004}, {'_account_id': 7353}, {'_account_id': 14288}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-10-06 02:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/58a8eb896893df782740c638204e89e239c0b82c', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 2, 'created': '2018-10-06 03:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/06aaa8cf4cd8db9431c22de5d22f3431a60452aa', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 3, 'created': '2018-10-06 03:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/fefdeef5c6189051124d10abc975e6907d77709d', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 4, 'created': '2018-10-06 03:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/d21198c15d73f0bc256757816ee5e4150efbca24', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 5, 'created': '2018-10-06 04:44:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/f536f95c8fc3c0f74b8ef635564b1381f376a63d', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 6, 'created': '2018-10-06 05:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/8e544331dac2b92887d176068aa747ce3186c065', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 7, 'created': '2018-10-06 05:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/1cad8d5ab6c9b3c04364c819aa6dd97d63217a99', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 8, 'created': '2018-10-06 06:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/f570e1bd89aa881d807826a2ff5fe70f52c3d8f0', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 9, 'created': '2018-10-06 06:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/fa3a9f9fc7bdf56b7baec60abc75517424028fde', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 10, 'created': '2018-10-06 07:23:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/dd04cb7c25b972889dbf23f1318c9ce2e5b6cb96', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 11, 'created': '2018-10-06 07:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/c1b29480cf7e8e97078d4abb1ace9b4c54e3bb5b', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 12, 'created': '2018-10-06 18:29:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/52bed09575904465764fe028a7ea038319ef1c91', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 13, 'created': '2018-10-06 18:56:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/e72ff7ddebf4969a99675ea876ce74b66eb300c8', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 14, 'created': '2018-10-06 19:34:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/c3b1cd68606c9aafc184afb3afe15a3d2d468b59', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 15, 'created': '2018-10-06 20:22:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/de1fd3af0768ceb93974b08d761f8863787ade60', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 16, 'created': '2018-10-06 21:06:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/0680526ae8dc1935f63ed0f42f427a089bcf012e', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 17, 'created': '2018-10-06 21:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/19fa06695595501f0eeb7b1e0f07364115a19704', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 18, 'created': '2018-10-06 21:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/1b6f56c0cafd17c066821d5408bdfa9b0afd176b', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 19, 'created': '2018-10-06 22:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/569b00f85c0b33fde9d2654f7b12fd91ae502e68', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 20, 'created': '2018-10-06 22:55:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/9ecdb5e9b9cc7b27dcfc154ba584c408f7af8974', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 21, 'created': '2018-10-06 23:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/bc1e2fe69c5049a8fa8d99ee6075b927dead8973', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 22, 'created': '2018-10-07 00:06:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/f393d32e59444178d18894ece300c5ffb2c4e3af', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 23, 'created': '2018-10-07 01:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/e7a4cfd80c2718f950f0379db17241876d0233c5', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 24, 'created': '2018-10-07 01:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/c06b59dfb7fbe0b54573ba01d60c631950e113a9', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 25, 'created': '2018-10-07 19:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/f7a1e1b7b2af8489b274a5e1624317702b8c7d6d', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 26, 'created': '2018-10-07 20:30:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/ee156f0ed72b61907c1042bec2d2357f9540bf2b', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 27, 'created': '2018-10-07 20:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/d2e9e2ec72330d3f5dadeb0cb9cc61d5963a9f89', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 28, 'created': '2018-10-07 21:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/3123cc2a3c8b91e9e60c13d73d113cfff53e878d', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 29, 'created': '2018-10-07 22:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/cb7ce1bd43fbf3d689d9e50257b6b2edafcc02de', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 30, 'created': '2018-10-07 22:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/8bbab40e3c90fce30ad05f04a138cb8b44288b9f', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 31, 'created': '2018-10-07 23:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/e953a1057e0c22c502b8a39646d35d86453c406d', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 32, 'created': '2018-10-08 01:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/55da7a5fee32a50e97ab6f57b7df1d0af96cb6ee', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 33, 'created': '2018-10-08 03:43:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/8187d28b10a9305516fd033427db9220cfe067ce', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 34, 'created': '2018-10-08 03:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/4c04f5af459c74f08c6db3fff9534e029cb459d9', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 35, 'created': '2018-10-08 04:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/864f979842984f43d63b0749f3a841036743e8a9', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 36, 'created': '2018-10-08 05:30:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/9daac1cdf21c2e47c337fa792521060bc72f91cf', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 37, 'created': '2018-10-08 17:25:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/ac03925b035943a24ff73a9e5dc562d9cac75dc2', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 38, 'created': '2018-10-08 18:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/44bb935b45f99ded4fc67d083ec3a834a23a7871', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 39, 'created': '2018-10-09 01:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/2933e339a7f5f00523e134bf5a394809f872a1c8', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 40, 'created': '2018-10-09 15:12:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/6ee1f7106ecc025ffe6b2efeb63a46098039fd98', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 41, 'created': '2018-10-09 17:11:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/c9da9b684c9f2f1c3e11a14bfcbac893a265d748', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 42, 'created': '2019-01-22 05:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/5f6b0eda88af8552fae2d50625af79d810daa1e6', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 43, 'created': '2019-01-22 16:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/a5c2c43c06ddf6c3e72ade3414de04aebdca062f', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 44, 'created': '2019-01-22 16:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/65ebf77050c149cafa06f26ba4d88abbb0d2fd49', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 45, 'created': '2019-01-24 19:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/dcc9e1ea361a9d47e05039fa5305366aa5e372af', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 46, 'created': '2019-01-25 01:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/31ffd655f3e0177a195ba9b3b563e9802edc0b44', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 47, 'created': '2019-02-20 00:33:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/54dd7246158a907bcabdd878e1ab9caab1a6479b', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 48, 'created': '2019-02-20 02:41:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/3fbbc7b249d43e11c55348c12aa6ad69b8124d27', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 49, 'created': '2019-02-22 19:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/1da2b4987743e752553d76b8d6f8834187980f5b', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 50, 'created': '2019-02-22 21:17:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/c9d126a5acd50561b704a105f7fa4848a4b441c7', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 51, 'created': '2019-02-23 01:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/a62f47f0203181445785033dff823ab772b18f26', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}, {'number': 52, 'created': '2019-02-23 01:44:08.000000000', 'files': ['templates/lxc-networkd-bridge.network.j2', 'handlers/main.yml', 'defaults/main.yml', 'vars/gentoo-host.yml', 'tasks/lxc_cache_prestage.yml', 'templates/prep-scripts/_container_sys_setup.sh.j2', 'templates/lxc-networkd-bridge.netdev.j2', 'tasks/lxc_net.yml', 'tasks/lxc_install_portage.yml', 'tasks/lxc_cache_preparation_systemd_new.yml', 'tasks/lxc_pre_install.yml', 'templates/prep-scripts/gentoo_systemd_prep.sh.j2', 'tasks/lxc_cache_preparation.yml', 'vars/gentoo.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/32d0a30c353e156282e2fe8b4765e91370a8fb59', 'message': 'add gentoo support\n\nChange-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183\n'}]",6,608393,32d0a30c353e156282e2fe8b4765e91370a8fb59,108,5,52,14288,,,0,"add gentoo support

Change-Id: Ieb1df06e6581601215851d78fb932a9d1e99e183
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/93/608393/51 && git format-patch -1 --stdout FETCH_HEAD,"['templates/lxc-networkd-bridge.netdev.j2', 'tasks/lxc_net.yml', 'templates/lxc-networkd-bridge.network.j2', 'tasks/lxc_pre_install.yml', 'templates/prep-scripts/gentoo_systemd_prep.sh.j2', 'vars/gentoo.yml', 'defaults/main.yml', 'vars/gentoo-host.yml']",8,58a8eb896893df782740c638204e89e239c0b82c,add-gentoo-support,"--- # Copyright 2016, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # Required packages. lxc_hosts_distro_packages: - net-misc/aria2 - net-misc/bridge-utils - sys-fs/btrfs-progs - app-admin/cgmanager - sys-apps/dbus - dev-util/debootstrap - net-dns/dnsmasq - dev-vcs/git - sys-libs/libseccomp - net-firewall/iptables - sys-apps/irqbalance - app-emulation/lxc - app-emulation/lxc-templates - dev-python/python3-lxc - app-arch/xz-utils # Package to remove from the host lxc_hosts_remove_distro_packages: - dnsmasq lxc_xz_bin: xz system_config_dir: ""/etc/conf.d"" systemd_utils_prefix: ""/lib/systemd"" lxc_cached_network_interfaces: - src: ""lxc-networkd-bridge.network.j2"" dest: ""/etc/systemd/network/{{ lxc_net_bridge }}.network"" - src: ""lxc-networkd-bridge.netdev.j2"" dest: ""/etc/systemd/network/{{ lxc_net_bridge }}.netdev"" ",,197,0
openstack%2Fopenstack-ansible-os_neutron~master~Iccf685adfe017382f93b5032bf15dce5ae0de417,openstack/openstack-ansible-os_neutron,master,Iccf685adfe017382f93b5032bf15dce5ae0de417,Remove the private option from include_role,MERGED,2019-02-22 00:50:05.000000000,2019-02-23 04:30:14.000000000,2019-02-23 04:30:14.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-22 00:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/f1ce3ad121d833af0faabd1a3d825373942d0300', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: Iccf685adfe017382f93b5032bf15dce5ae0de417\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2019-02-22 16:20:21.000000000', 'files': ['tasks/main.yml', 'tasks/neutron_install_source.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/5e5a206c01598d4f14b719a4b521ff0de65c1eba', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: Iccf685adfe017382f93b5032bf15dce5ae0de417\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638552,5e5a206c01598d4f14b719a4b521ff0de65c1eba,21,3,2,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: Iccf685adfe017382f93b5032bf15dce5ae0de417
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/52/638552/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/app-ovn.rst', 'tasks/main.yml', 'tasks/neutron_install_source.yml']",3,f1ce3ad121d833af0faabd1a3d825373942d0300,fix/private/deprecation,, private: yes,0,4
openstack%2Fneutron~stable%2Frocky~Ie291fda7d23a696aaa1160d126a3cf72b08c522f,openstack/neutron,stable/rocky,Ie291fda7d23a696aaa1160d126a3cf72b08c522f,Add new test decorator skip_if_timeout,MERGED,2019-02-20 09:55:25.000000000,2019-02-23 03:52:54.000000000,2019-02-23 03:52:54.000000000,"[{'_account_id': 4694}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-20 09:55:25.000000000', 'files': ['neutron/tests/functional/db/test_migrations.py', 'neutron/tests/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e6f22ce81c0a1130d45d290b185b736501e6dd1e', 'message': 'Add new test decorator skip_if_timeout\n\nIn some cases our db migration tests which run on MySQL are\nfailing with timeout and it happens due to slow VMs on which\njob is running.\nSometimes it may also happen that timeout exception is raised\nin the middle of some sqlalchemy operations and\nsqlalchemy.InterfaceError is raised as last one.\nDetails about this exception can be found in [1].\n\nTo avoid many rechecks because of this reason this patch\nintroduces new decorator which is very similar to ""unstable_test""\nbut will skip test only if one of exceptions mentioned above will\nbe raised.\nIn all other cases it will fail test.\n\nThat should be a bit more safe for us because we will not miss\nsome other failures raised in those tests and will avoid rechecks\nbecause of this ""well-known"" reason described in related bug.\n\n[1] http://sqlalche.me/e/rvf5\n\nConflicts:\n    neutron/tests/functional/db/test_migrations.py\n\nChange-Id: Ie291fda7d23a696aaa1160d126a3cf72b08c522f\nRelated-Bug: #1687027\n(cherry picked from commit c0fec676723649a0516cf3d4af0dccc0fe832095)\n'}]",0,638116,e6f22ce81c0a1130d45d290b185b736501e6dd1e,9,4,1,11975,,,0,"Add new test decorator skip_if_timeout

In some cases our db migration tests which run on MySQL are
failing with timeout and it happens due to slow VMs on which
job is running.
Sometimes it may also happen that timeout exception is raised
in the middle of some sqlalchemy operations and
sqlalchemy.InterfaceError is raised as last one.
Details about this exception can be found in [1].

To avoid many rechecks because of this reason this patch
introduces new decorator which is very similar to ""unstable_test""
but will skip test only if one of exceptions mentioned above will
be raised.
In all other cases it will fail test.

That should be a bit more safe for us because we will not miss
some other failures raised in those tests and will avoid rechecks
because of this ""well-known"" reason described in related bug.

[1] http://sqlalche.me/e/rvf5

Conflicts:
    neutron/tests/functional/db/test_migrations.py

Change-Id: Ie291fda7d23a696aaa1160d126a3cf72b08c522f
Related-Bug: #1687027
(cherry picked from commit c0fec676723649a0516cf3d4af0dccc0fe832095)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/16/638116/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/db/test_migrations.py', 'neutron/tests/base.py']",2,e6f22ce81c0a1130d45d290b185b736501e6dd1e,bug/1687027,"from sqlalchemy import exc as sqlalchemy_excdef skip_if_timeout(reason): def decor(f): @functools.wraps(f) def inner(self, *args, **kwargs): try: return f(self, *args, **kwargs) except fixtures.TimeoutException: msg = (""Timeout raised for test %s, skipping it "" ""because of: %s"") % (self.id(), reason) raise self.skipTest(msg) except sqlalchemy_exc.InterfaceError: # In case of db tests very often TimeoutException is reason of # some sqlalchemy InterfaceError exception and that is final # raised exception which needs to be handled msg = (""DB connection broken in test %s. It is very likely "" ""that this happend because of test timeout. "" ""Skipping test because of: %s"") % (self.id(), reason) raise self.skipTest(msg) return inner return decor ",,51,0
openstack%2Fneutron~stable%2Fqueens~Ie291fda7d23a696aaa1160d126a3cf72b08c522f,openstack/neutron,stable/queens,Ie291fda7d23a696aaa1160d126a3cf72b08c522f,Add new test decorator skip_if_timeout,MERGED,2019-02-20 09:55:39.000000000,2019-02-23 03:52:50.000000000,2019-02-23 03:52:49.000000000,"[{'_account_id': 4694}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-20 09:55:39.000000000', 'files': ['neutron/tests/functional/db/test_migrations.py', 'neutron/tests/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8bf3a905e7d05715a913587a9077615a733e5ec1', 'message': 'Add new test decorator skip_if_timeout\n\nIn some cases our db migration tests which run on MySQL are\nfailing with timeout and it happens due to slow VMs on which\njob is running.\nSometimes it may also happen that timeout exception is raised\nin the middle of some sqlalchemy operations and\nsqlalchemy.InterfaceError is raised as last one.\nDetails about this exception can be found in [1].\n\nTo avoid many rechecks because of this reason this patch\nintroduces new decorator which is very similar to ""unstable_test""\nbut will skip test only if one of exceptions mentioned above will\nbe raised.\nIn all other cases it will fail test.\n\nThat should be a bit more safe for us because we will not miss\nsome other failures raised in those tests and will avoid rechecks\nbecause of this ""well-known"" reason described in related bug.\n\n[1] http://sqlalche.me/e/rvf5\n\nConflicts:\n    neutron/tests/functional/db/test_migrations.py\n\nChange-Id: Ie291fda7d23a696aaa1160d126a3cf72b08c522f\nRelated-Bug: #1687027\n(cherry picked from commit c0fec676723649a0516cf3d4af0dccc0fe832095)\n'}]",0,638117,8bf3a905e7d05715a913587a9077615a733e5ec1,8,4,1,11975,,,0,"Add new test decorator skip_if_timeout

In some cases our db migration tests which run on MySQL are
failing with timeout and it happens due to slow VMs on which
job is running.
Sometimes it may also happen that timeout exception is raised
in the middle of some sqlalchemy operations and
sqlalchemy.InterfaceError is raised as last one.
Details about this exception can be found in [1].

To avoid many rechecks because of this reason this patch
introduces new decorator which is very similar to ""unstable_test""
but will skip test only if one of exceptions mentioned above will
be raised.
In all other cases it will fail test.

That should be a bit more safe for us because we will not miss
some other failures raised in those tests and will avoid rechecks
because of this ""well-known"" reason described in related bug.

[1] http://sqlalche.me/e/rvf5

Conflicts:
    neutron/tests/functional/db/test_migrations.py

Change-Id: Ie291fda7d23a696aaa1160d126a3cf72b08c522f
Related-Bug: #1687027
(cherry picked from commit c0fec676723649a0516cf3d4af0dccc0fe832095)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/638117/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/db/test_migrations.py', 'neutron/tests/base.py']",2,8bf3a905e7d05715a913587a9077615a733e5ec1,bug/1687027-stable/queens,"from sqlalchemy import exc as sqlalchemy_excdef skip_if_timeout(reason): def decor(f): @functools.wraps(f) def inner(self, *args, **kwargs): try: return f(self, *args, **kwargs) except fixtures.TimeoutException: msg = (""Timeout raised for test %s, skipping it "" ""because of: %s"") % (self.id(), reason) raise self.skipTest(msg) except sqlalchemy_exc.InterfaceError: # In case of db tests very often TimeoutException is reason of # some sqlalchemy InterfaceError exception and that is final # raised exception which needs to be handled msg = (""DB connection broken in test %s. It is very likely "" ""that this happend because of test timeout. "" ""Skipping test because of: %s"") % (self.id(), reason) raise self.skipTest(msg) return inner return decor ",,51,0
openstack%2Fneutron~stable%2Fpike~Ie291fda7d23a696aaa1160d126a3cf72b08c522f,openstack/neutron,stable/pike,Ie291fda7d23a696aaa1160d126a3cf72b08c522f,Add new test decorator skip_if_timeout,MERGED,2019-02-20 09:57:50.000000000,2019-02-23 03:52:47.000000000,2019-02-23 03:52:47.000000000,"[{'_account_id': 4694}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-20 09:57:50.000000000', 'files': ['neutron/tests/functional/db/test_migrations.py', 'neutron/tests/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8b255a648c381bfcff0623ba97880855c7fa21eb', 'message': 'Add new test decorator skip_if_timeout\n\nIn some cases our db migration tests which run on MySQL are\nfailing with timeout and it happens due to slow VMs on which\njob is running.\nSometimes it may also happen that timeout exception is raised\nin the middle of some sqlalchemy operations and\nsqlalchemy.InterfaceError is raised as last one.\nDetails about this exception can be found in [1].\n\nTo avoid many rechecks because of this reason this patch\nintroduces new decorator which is very similar to ""unstable_test""\nbut will skip test only if one of exceptions mentioned above will\nbe raised.\nIn all other cases it will fail test.\n\nThat should be a bit more safe for us because we will not miss\nsome other failures raised in those tests and will avoid rechecks\nbecause of this ""well-known"" reason described in related bug.\n\n[1] http://sqlalche.me/e/rvf5\n\nConflicts:\n    neutron/tests/functional/db/test_migrations.py\n    neutron/tests/base.py\n\nChange-Id: Ie291fda7d23a696aaa1160d126a3cf72b08c522f\nRelated-Bug: #1687027\n(cherry picked from commit c0fec676723649a0516cf3d4af0dccc0fe832095)\n(cherry picked from commit e6f22ce81c0a1130d45d290b185b736501e6dd1e)\n'}]",0,638120,8b255a648c381bfcff0623ba97880855c7fa21eb,9,4,1,11975,,,0,"Add new test decorator skip_if_timeout

In some cases our db migration tests which run on MySQL are
failing with timeout and it happens due to slow VMs on which
job is running.
Sometimes it may also happen that timeout exception is raised
in the middle of some sqlalchemy operations and
sqlalchemy.InterfaceError is raised as last one.
Details about this exception can be found in [1].

To avoid many rechecks because of this reason this patch
introduces new decorator which is very similar to ""unstable_test""
but will skip test only if one of exceptions mentioned above will
be raised.
In all other cases it will fail test.

That should be a bit more safe for us because we will not miss
some other failures raised in those tests and will avoid rechecks
because of this ""well-known"" reason described in related bug.

[1] http://sqlalche.me/e/rvf5

Conflicts:
    neutron/tests/functional/db/test_migrations.py
    neutron/tests/base.py

Change-Id: Ie291fda7d23a696aaa1160d126a3cf72b08c522f
Related-Bug: #1687027
(cherry picked from commit c0fec676723649a0516cf3d4af0dccc0fe832095)
(cherry picked from commit e6f22ce81c0a1130d45d290b185b736501e6dd1e)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/20/638120/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/db/test_migrations.py', 'neutron/tests/base.py']",2,8b255a648c381bfcff0623ba97880855c7fa21eb,bug/1687027,"from sqlalchemy import exc as sqlalchemy_excdef skip_if_timeout(reason): def decor(f): @functools.wraps(f) def inner(self, *args, **kwargs): try: return f(self, *args, **kwargs) except fixtures.TimeoutException: msg = (""Timeout raised for test %s, skipping it "" ""because of: %s"") % (self.id(), reason) raise self.skipTest(msg) except sqlalchemy_exc.InterfaceError: # In case of db tests very often TimeoutException is reason of # some sqlalchemy InterfaceError exception and that is final # raised exception which needs to be handled msg = (""DB connection broken in test %s. It is very likely "" ""that this happend because of test timeout. "" ""Skipping test because of: %s"") % (self.id(), reason) raise self.skipTest(msg) return inner return decor ",,51,0
openstack%2Fpython-zunclient~master~I57cabf92f6e9c04b64f1ec5ec9ad4bfc7478eb61,openstack/python-zunclient,master,I57cabf92f6e9c04b64f1ec5ec9ad4bfc7478eb61,add python 3.7 unit test job,MERGED,2019-02-19 09:06:33.000000000,2019-02-23 03:40:17.000000000,2019-02-23 03:40:16.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-19 09:06:33.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/507a2b1987a94186f1615c923c4d96cccc800af0', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: I57cabf92f6e9c04b64f1ec5ec9ad4bfc7478eb61\nStory: #2004073\nTask: #27465\n'}]",0,637772,507a2b1987a94186f1615c923c4d96cccc800af0,6,2,1,9414,,,0,"add python 3.7 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.7.

See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html

Change-Id: I57cabf92f6e9c04b64f1ec5ec9ad4bfc7478eb61
Story: #2004073
Task: #27465
",git fetch https://review.opendev.org/openstack/python-zunclient refs/changes/72/637772/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,507a2b1987a94186f1615c923c4d96cccc800af0,py37-job, - openstack-python37-jobs,,1,0
openstack%2Fopenstack-helm-images~master~Ifedd3b41a52b4e9628c1b4ec07176b5e3416dbb7,openstack/openstack-helm-images,master,Ifedd3b41a52b4e9628c1b4ec07176b5e3416dbb7,Added some checks for the case 'requirement' is not part of BUILD_PROJECTS,MERGED,2019-02-15 10:58:36.000000000,2019-02-23 03:12:21.000000000,2019-02-23 03:12:21.000000000,"[{'_account_id': 8898}, {'_account_id': 17068}, {'_account_id': 20466}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-15 10:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/048063323c990aaa7354cde7fe070857558fa01e', 'message': 'Added some checks for the case \'requirement\' is not part of BUILD_PROJECTS\n\nIf requirements is not part of BUILD_PROJECTS, assume it was built already\nbefore and set the REQUIREMENTS_TAGGED_PROJECT_REF according to current project.\nOtherwise there\'d be WHEELS set to something like ""requirements:version--distro""\n\nChange-Id: Ifedd3b41a52b4e9628c1b4ec07176b5e3416dbb7\n'}, {'number': 2, 'created': '2019-02-23 02:00:12.000000000', 'files': ['openstack/loci/build.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/b1d54cb5a3bb1fa5a9db2430e806d7d7b3cfcba9', 'message': 'Added some checks for the case \'requirement\' is not part of BUILD_PROJECTS\n\nIf requirements is not part of BUILD_PROJECTS, assume it was built already\nbefore and set the REQUIREMENTS_TAGGED_PROJECT_REF according to current project.\nOtherwise there\'d be WHEELS set to something like ""requirements:version--distro""\n\nChange-Id: Ifedd3b41a52b4e9628c1b4ec07176b5e3416dbb7\n'}]",0,637168,b1d54cb5a3bb1fa5a9db2430e806d7d7b3cfcba9,10,4,2,9963,,,0,"Added some checks for the case 'requirement' is not part of BUILD_PROJECTS

If requirements is not part of BUILD_PROJECTS, assume it was built already
before and set the REQUIREMENTS_TAGGED_PROJECT_REF according to current project.
Otherwise there'd be WHEELS set to something like ""requirements:version--distro""

Change-Id: Ifedd3b41a52b4e9628c1b4ec07176b5e3416dbb7
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/68/637168/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/loci/build.sh'],1,048063323c990aaa7354cde7fe070857558fa01e,requirements-already-prepared," # If requirements was not part of BUILD_PROJECTS, assume it was # built before and set the project ref based on current project if [[ -z ${REQUIREMENTS_TAGGED_PROJECT_REF} ]]; then REQUIREMENTS_TAGGED_PROJECT_REF=${TAGGED_PROJECT_REF} fi if [[ ""${projects[0]}"" == ""requirements"" ]]; then get_project_image_build_arguments ${projects[0]} eval ""${docker_build_cmd}"" docker push ${tag} unset projects[0] fi"," get_project_image_build_arguments ${projects[0]} eval ""${docker_build_cmd}"" docker push ${tag} unset projects[0]",12,4
openstack%2Fopenstack-helm-infra~master~I0a78d8190fbbae1b300b74ca560d76dedaaf6fc1,openstack/openstack-helm-infra,master,I0a78d8190fbbae1b300b74ca560d76dedaaf6fc1,Remove set -x from exporter scripts and htk s3 user script,MERGED,2019-02-19 20:44:57.000000000,2019-02-23 03:05:31.000000000,2019-02-23 03:05:31.000000000,"[{'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-02-19 20:44:57.000000000', 'files': ['postgresql/templates/monitoring/prometheus/bin/_create-postgresql-exporter-user.sh.tpl', 'mariadb/templates/monitoring/prometheus/bin/_create-mysql-user.sh.tpl', 'helm-toolkit/templates/scripts/_create-s3-user.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/70e576990032638d18e8e05b534b9e77e44dbb84', 'message': 'Remove set -x from exporter scripts and htk s3 user script\n\nThis removes set -x from the templates for the user creation\nscripts for the mariadb and postgresql user templates, and it\nalso removes the set -x from the helm-toolkit job for creating\ns3 users. This prevents sensitive credentials from being\ndisplayed to the console when these scripts are run\n\nChange-Id: I0a78d8190fbbae1b300b74ca560d76dedaaf6fc1\n'}]",0,637999,70e576990032638d18e8e05b534b9e77e44dbb84,7,3,1,17591,,,0,"Remove set -x from exporter scripts and htk s3 user script

This removes set -x from the templates for the user creation
scripts for the mariadb and postgresql user templates, and it
also removes the set -x from the helm-toolkit job for creating
s3 users. This prevents sensitive credentials from being
displayed to the console when these scripts are run

Change-Id: I0a78d8190fbbae1b300b74ca560d76dedaaf6fc1
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/99/637999/1 && git format-patch -1 --stdout FETCH_HEAD,"['postgresql/templates/monitoring/prometheus/bin/_create-postgresql-exporter-user.sh.tpl', 'mariadb/templates/monitoring/prometheus/bin/_create-mysql-user.sh.tpl', 'helm-toolkit/templates/scripts/_create-s3-user.sh.tpl']",3,70e576990032638d18e8e05b534b9e77e44dbb84,update-script-flags,"set -e echo ""Creating s3 user and key pair"" echo ""Current user and key pair exists."" echo ""Updating existing user's key pair""","set -ex echo ""Current key pair exists."" echo ""Updating key pair""",6,5
openstack%2Ftripleo-heat-templates~stable%2Frocky~I65f46056f8a908c60c99d1cee3738344a0bce6b7,openstack/tripleo-heat-templates,stable/rocky,I65f46056f8a908c60c99d1cee3738344a0bce6b7,Handle upper and lower case system uuids,MERGED,2019-02-21 19:25:04.000000000,2019-02-23 02:59:22.000000000,2019-02-23 02:59:22.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-21 19:25:04.000000000', 'files': ['firstboot/os-net-config-mappings.yaml', 'puppet/extraconfig/pre_deploy/per_node.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/759b711b9457a5827cf75e8dcb36e3ca905dec1c', 'message': 'Handle upper and lower case system uuids\n\nWe need to be able to handle when system uuids are upper or lower case\nbecause newer versions of dmidecode have normalized to lower case. Users\nwho were on CentOS/RHEL 7.5 and older may have per-node customizations\nwith upper case which turn lowercase with an update to 7.6. This affects\nhieradata customizations as well as os-net-config mapping files. This\nchange outputs both an upper and lowercase hieradata uuid file to handle\nthe both versions of the UUID. Additionally this change normalizes the\nid comparison for os-net-config mappings to lower case.\n\nChange-Id: I65f46056f8a908c60c99d1cee3738344a0bce6b7\nCloses-Bug: #1816652\n(cherry picked from commit e2a8a494c5abf64ac5ed16e7f2b20edd4535c2d4)\n'}]",0,638491,759b711b9457a5827cf75e8dcb36e3ca905dec1c,12,4,1,14985,,,0,"Handle upper and lower case system uuids

We need to be able to handle when system uuids are upper or lower case
because newer versions of dmidecode have normalized to lower case. Users
who were on CentOS/RHEL 7.5 and older may have per-node customizations
with upper case which turn lowercase with an update to 7.6. This affects
hieradata customizations as well as os-net-config mapping files. This
change outputs both an upper and lowercase hieradata uuid file to handle
the both versions of the UUID. Additionally this change normalizes the
id comparison for os-net-config mappings to lower case.

Change-Id: I65f46056f8a908c60c99d1cee3738344a0bce6b7
Closes-Bug: #1816652
(cherry picked from commit e2a8a494c5abf64ac5ed16e7f2b20edd4535c2d4)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/91/638491/1 && git format-patch -1 --stdout FETCH_HEAD,"['firstboot/os-net-config-mappings.yaml', 'puppet/extraconfig/pre_deploy/per_node.yaml']",2,759b711b9457a5827cf75e8dcb36e3ca905dec1c,bug/1816652-stable/rocky," # thanks to dmidecode 3.1, we have to handle both the upper case # and lower case versions of the UUID from dmidecode. LP#1816652 # upper for dmidecode < 3.1 and lower for dmidecode >= 3.1 node_id_upper=$(echo $node_id | tr '[:lower:]' '[:upper:]') # handle upper case node id LP#1816652 echo $node_lookup | $(get_python) -c "" import json import sys input = sys.stdin.readline() or '{}' cnt = json.loads(input) print json.dumps(cnt.get('${node_id_upper}', {})) "" > /etc/puppet/hieradata/${node_id_upper}.json",,15,2
openstack%2Fneutron~stable%2Frocky~I388391cf697dade1a163d15ab568b33134f7b2d9,openstack/neutron,stable/rocky,I388391cf697dade1a163d15ab568b33134f7b2d9,Switch isolated metadata proxy to bind to 169.254.169.254,MERGED,2019-02-12 10:30:25.000000000,2019-02-23 02:26:28.000000000,2019-02-23 02:26:28.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9732}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-12 10:30:25.000000000', 'files': ['neutron/agent/dhcp/agent.py', 'neutron/agent/l3/dvr_fip_ns.py', 'neutron/agent/l3/ha_router.py', 'neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/linux/ip_lib.py', 'neutron/agent/metadata/driver.py', 'neutron/tests/unit/agent/dhcp/test_agent.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py', 'neutron/agent/linux/dhcp.py', 'neutron/agent/l3/dvr_snat_ns.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/964dd28a95347d22ddf647b56a1866a034b8de61', 'message': 'Switch isolated metadata proxy to bind to 169.254.169.254\n\nCurrently the metadata proxy binds to default 0.0.0.0, which does not\nadd any advantage (metadata requests are not sent to random IP\naddresses), and may allow access to cloud information from\nthird parties.\n\nThis changes the generated configuration to bind to METADATA_DEFAULT_IP\naddress instead.\n\nThis is not enabled in other metadata proxy configuration (in the L3\nagent), as this would require net.ipv4.ip_nonlocal_bind everywhere\n(currently only enabled for DVR) or transparent mode in haproxy (which\nrequires net.ipv4.ip_nonlocal_bind anyway)\n\nChanged set_ip_nonlocal_bind_for_namespace() to support setting the\nvalue in both the given and root namespace correctly, since it was\nonly used from inside the neutron codebase according to codesearch.\n\nChange-Id: I388391cf697dade1a163d15ab568b33134f7b2d9\nCo-Authored-By: Andrey Arapov <andrey.arapov@nixaid.com>\nCloses-Bug: #1745618\n(cherry picked from commit 6124f6029729c3c800287f3f02329901d93ea021)\n'}]",0,636298,964dd28a95347d22ddf647b56a1866a034b8de61,13,7,1,21798,,,0,"Switch isolated metadata proxy to bind to 169.254.169.254

Currently the metadata proxy binds to default 0.0.0.0, which does not
add any advantage (metadata requests are not sent to random IP
addresses), and may allow access to cloud information from
third parties.

This changes the generated configuration to bind to METADATA_DEFAULT_IP
address instead.

This is not enabled in other metadata proxy configuration (in the L3
agent), as this would require net.ipv4.ip_nonlocal_bind everywhere
(currently only enabled for DVR) or transparent mode in haproxy (which
requires net.ipv4.ip_nonlocal_bind anyway)

Changed set_ip_nonlocal_bind_for_namespace() to support setting the
value in both the given and root namespace correctly, since it was
only used from inside the neutron codebase according to codesearch.

Change-Id: I388391cf697dade1a163d15ab568b33134f7b2d9
Co-Authored-By: Andrey Arapov <andrey.arapov@nixaid.com>
Closes-Bug: #1745618
(cherry picked from commit 6124f6029729c3c800287f3f02329901d93ea021)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/98/636298/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/dhcp/agent.py', 'neutron/agent/l3/dvr_fip_ns.py', 'neutron/agent/l3/ha_router.py', 'neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/linux/ip_lib.py', 'neutron/agent/metadata/driver.py', 'neutron/tests/unit/agent/dhcp/test_agent.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py', 'neutron/agent/linux/dhcp.py', 'neutron/agent/l3/dvr_snat_ns.py']",10,964dd28a95347d22ddf647b56a1866a034b8de61,bug/1745618-stable/rocky," ip_lib.set_ip_nonlocal_bind_for_namespace(self.name, 0)", ip_lib.set_ip_nonlocal_bind_for_namespace(self.name),45,28
openstack%2Fcinder~stable%2Fpike~I2c54383a865727d0035a20dcf34d860bde3db4f9,openstack/cinder,stable/pike,I2c54383a865727d0035a20dcf34d860bde3db4f9,RBD: get provisioned capacity using same connection,MERGED,2018-12-18 17:38:24.000000000,2019-02-23 02:13:43.000000000,2019-01-13 18:12:58.000000000,"[{'_account_id': 1736}, {'_account_id': 5997}, {'_account_id': 6593}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 13636}, {'_account_id': 15670}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21976}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 22595}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-12-18 17:38:24.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/tests/unit/volume/drivers/test_rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f2d5a9c312d3d4e35be65641f9947746d388ce94', 'message': 'RBD: get provisioned capacity using same connection\n\nCreating new connection on getting rbd image is significant overhead.\nCollecting provisioned capacity spends most of its time on new\nconnection establishment.\n\nThis patch reuses previously created connection.\n\nChange-Id: I2c54383a865727d0035a20dcf34d860bde3db4f9\nRelated-Bug: #1649956\n(cherry picked from commit a0248f4921e6892459d1535ab98892d94ac32a5b)\n'}]",0,625970,f2d5a9c312d3d4e35be65641f9947746d388ce94,30,23,1,6593,,,0,"RBD: get provisioned capacity using same connection

Creating new connection on getting rbd image is significant overhead.
Collecting provisioned capacity spends most of its time on new
connection establishment.

This patch reuses previously created connection.

Change-Id: I2c54383a865727d0035a20dcf34d860bde3db4f9
Related-Bug: #1649956
(cherry picked from commit a0248f4921e6892459d1535ab98892d94ac32a5b)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/70/625970/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/rbd.py', 'cinder/tests/unit/volume/drivers/test_rbd.py']",2,f2d5a9c312d3d4e35be65641f9947746d388ce94,bug/1649956," def test_rbd_volume_proxy_external_conn(self): mock_driver = mock.Mock(name='driver') mock_driver._connect_to_rados.return_value = (None, None) with driver.RBDVolumeProxy(mock_driver, self.volume_a.name, client='fake_cl', ioctx='fake_io'): mock_driver._connect_to_rados.assert_not_called() mock_driver._disconnect_from_rados.assert_not_called() def test_rbd_volume_proxy_external_conn_no_iocxt(self): mock_driver = mock.Mock(name='driver') mock_driver._connect_to_rados.return_value = ('fake_cl', 'fake_io') with driver.RBDVolumeProxy(mock_driver, self.volume_a.name, client='fake_cl', pool='vol_pool'): mock_driver._connect_to_rados.assert_called_once_with( 'vol_pool', None, None) mock_driver._disconnect_from_rados.assert_called_once_with( 'fake_cl', 'fake_io') def test_rbd_volume_proxy_external_conn_error(self): mock_driver = mock.Mock(name='driver') mock_driver._connect_to_rados.return_value = (None, None) class RBDError(Exception): pass mock_driver.rbd.Error = RBDError mock_driver.rbd.Image.side_effect = RBDError() self.assertRaises(RBDError, driver.RBDVolumeProxy, mock_driver, self.volume_a.name, client='fake_cl', ioctx='fake_io') mock_driver._connect_to_rados.assert_not_called() mock_driver._disconnect_from_rados.assert_not_called() def test_rbd_volume_proxy_conn_error(self): mock_driver = mock.Mock(name='driver') mock_driver._connect_to_rados.return_value = ( 'fake_client', 'fake_ioctx') class RBDError(Exception): pass mock_driver.rbd.Error = RBDError mock_driver.rbd.Image.side_effect = RBDError() self.assertRaises(RBDError, driver.RBDVolumeProxy, mock_driver, self.volume_a.name, pool='fake-volumes') mock_driver._connect_to_rados.assert_called_once_with( 'fake-volumes', None, None) mock_driver._disconnect_from_rados.assert_called_once_with( 'fake_client', 'fake_ioctx') mock.call(self.driver, v, read_only=True, client=client.cluster, ioctx=client.ioctx)"," mock.call(self.driver, v, read_only=True)",80,10
openstack%2Fopenstack-helm-images~master~Ie78addce2e47fc5a799ed287dab200084362af71,openstack/openstack-helm-images,master,Ie78addce2e47fc5a799ed287dab200084362af71,Fix typo in argument name,MERGED,2019-02-20 13:47:13.000000000,2019-02-23 02:13:31.000000000,2019-02-23 02:13:30.000000000,"[{'_account_id': 8898}, {'_account_id': 17068}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 28701}]","[{'number': 1, 'created': '2019-02-20 13:47:13.000000000', 'files': ['libvirt/build.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/41b6402415919c7e174dcf9a78120fd33130f912', 'message': 'Fix typo in argument name\n\nChange-Id: Ie78addce2e47fc5a799ed287dab200084362af71\n'}]",0,638156,41b6402415919c7e174dcf9a78120fd33130f912,9,5,1,9963,,,0,"Fix typo in argument name

Change-Id: Ie78addce2e47fc5a799ed287dab200084362af71
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/56/638156/1 && git format-patch -1 --stdout FETCH_HEAD,['libvirt/build.sh'],1,41b6402415919c7e174dcf9a78120fd33130f912,EXTRA_TAG_INFO,"EXTRA_TAG_INFO=${EXTRA_TAG_INFO:-""-${LIBVIRT_VERSION}""}","EXTRA_TAG_INFO=${EXTRA_TAB_INFO:-""-${LIBVIRT_VERSION}""}",1,1
openstack%2Fneutron~stable%2Fqueens~I388391cf697dade1a163d15ab568b33134f7b2d9,openstack/neutron,stable/queens,I388391cf697dade1a163d15ab568b33134f7b2d9,Switch isolated metadata proxy to bind to 169.254.169.254,MERGED,2019-02-12 10:30:47.000000000,2019-02-23 02:08:43.000000000,2019-02-23 02:08:43.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 13995}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-12 10:30:47.000000000', 'files': ['neutron/agent/dhcp/agent.py', 'neutron/agent/l3/dvr_fip_ns.py', 'neutron/agent/l3/ha_router.py', 'neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/linux/ip_lib.py', 'neutron/agent/metadata/driver.py', 'neutron/tests/unit/agent/dhcp/test_agent.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py', 'neutron/agent/linux/dhcp.py', 'neutron/agent/l3/dvr_snat_ns.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/13d23ba36340023bceaed46c5c13942b64f9e42f', 'message': 'Switch isolated metadata proxy to bind to 169.254.169.254\n\nCurrently the metadata proxy binds to default 0.0.0.0, which does not\nadd any advantage (metadata requests are not sent to random IP\naddresses), and may allow access to cloud information from\nthird parties.\n\nThis changes the generated configuration to bind to METADATA_DEFAULT_IP\naddress instead.\n\nThis is not enabled in other metadata proxy configuration (in the L3\nagent), as this would require net.ipv4.ip_nonlocal_bind everywhere\n(currently only enabled for DVR) or transparent mode in haproxy (which\nrequires net.ipv4.ip_nonlocal_bind anyway)\n\nChanged set_ip_nonlocal_bind_for_namespace() to support setting the\nvalue in both the given and root namespace correctly, since it was\nonly used from inside the neutron codebase according to codesearch.\n\nChange-Id: I388391cf697dade1a163d15ab568b33134f7b2d9\nCo-Authored-By: Andrey Arapov <andrey.arapov@nixaid.com>\nCloses-Bug: #1745618\n(cherry picked from commit 6124f6029729c3c800287f3f02329901d93ea021)\n'}]",0,636299,13d23ba36340023bceaed46c5c13942b64f9e42f,11,7,1,21798,,,0,"Switch isolated metadata proxy to bind to 169.254.169.254

Currently the metadata proxy binds to default 0.0.0.0, which does not
add any advantage (metadata requests are not sent to random IP
addresses), and may allow access to cloud information from
third parties.

This changes the generated configuration to bind to METADATA_DEFAULT_IP
address instead.

This is not enabled in other metadata proxy configuration (in the L3
agent), as this would require net.ipv4.ip_nonlocal_bind everywhere
(currently only enabled for DVR) or transparent mode in haproxy (which
requires net.ipv4.ip_nonlocal_bind anyway)

Changed set_ip_nonlocal_bind_for_namespace() to support setting the
value in both the given and root namespace correctly, since it was
only used from inside the neutron codebase according to codesearch.

Change-Id: I388391cf697dade1a163d15ab568b33134f7b2d9
Co-Authored-By: Andrey Arapov <andrey.arapov@nixaid.com>
Closes-Bug: #1745618
(cherry picked from commit 6124f6029729c3c800287f3f02329901d93ea021)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/99/636299/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/dhcp/agent.py', 'neutron/agent/l3/dvr_fip_ns.py', 'neutron/agent/l3/ha_router.py', 'neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/linux/ip_lib.py', 'neutron/agent/metadata/driver.py', 'neutron/tests/unit/agent/dhcp/test_agent.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py', 'neutron/agent/linux/dhcp.py', 'neutron/agent/l3/dvr_snat_ns.py']",10,13d23ba36340023bceaed46c5c13942b64f9e42f,bug/1745618-stable/queens," ip_lib.set_ip_nonlocal_bind_for_namespace(self.name, 0)", ip_lib.set_ip_nonlocal_bind_for_namespace(self.name),45,28
openstack%2Fswift~master~I5c972749cadf903161456f34371a6f83ebc05eb9,openstack/swift,master,I5c972749cadf903161456f34371a6f83ebc05eb9,s3api: Delete multipart uploads via multi-delete,MERGED,2019-01-04 23:07:21.000000000,2019-02-23 02:08:40.000000000,2019-02-23 02:08:39.000000000,"[{'_account_id': 7233}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 23:07:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e4e68159440cf415404c472bf6baccd341f74c12', 'message': 's3api: Delete multipart uploads via multi-delete\n\nChange-Id: I5c972749cadf903161456f34371a6f83ebc05eb9\n'}, {'number': 2, 'created': '2019-01-04 23:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7cb8b583a756b69d4f57de2c31080780ccef428e', 'message': 's3api: Delete multipart uploads via multi-delete\n\nChange-Id: I5c972749cadf903161456f34371a6f83ebc05eb9\nCloses-Bug: 1810567\n'}, {'number': 3, 'created': '2019-01-07 22:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c5249dac0f65bbe9630b97e20eae7037ac2ac44a', 'message': ""s3api: Delete multipart uploads via multi-delete\n\nWe have code that's *supposed* to do it, but we weren't reading the\nresult of the bulk-delete, so we never actually deleted anything!\n\nChange-Id: I5c972749cadf903161456f34371a6f83ebc05eb9\nCloses-Bug: 1810567\n""}, {'number': 4, 'created': '2019-01-07 23:17:33.000000000', 'files': ['test/unit/common/middleware/s3api/test_multi_delete.py', 'test/functional/s3api/test_multi_upload.py', 'swift/common/middleware/s3api/controllers/multi_delete.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b35fc41184edf8b6d88ccbf5a4e34a7924e9c46a', 'message': ""s3api: Delete multipart uploads via multi-delete\n\nWe have code that's *supposed* to do it, but we weren't reading the\nresult of the bulk-delete, so we never actually deleted anything!\n\nChange-Id: I5c972749cadf903161456f34371a6f83ebc05eb9\nCloses-Bug: 1810567\n""}]",0,628701,b35fc41184edf8b6d88ccbf5a4e34a7924e9c46a,24,3,4,15343,,,0,"s3api: Delete multipart uploads via multi-delete

We have code that's *supposed* to do it, but we weren't reading the
result of the bulk-delete, so we never actually deleted anything!

Change-Id: I5c972749cadf903161456f34371a6f83ebc05eb9
Closes-Bug: 1810567
",git fetch https://review.opendev.org/openstack/swift refs/changes/01/628701/3 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/s3api/test_multi_delete.py', 'test/functional/s3api/test_multi_upload.py', 'swift/common/middleware/s3api/controllers/multi_delete.py']",3,e4e68159440cf415404c472bf6baccd341f74c12,bug/1810567,"import json resp = req.get_response(self.app, method='DELETE', query=query, headers={'Accept': 'application/json'}) # Have to read the response to actually do the SLO delete if query: try: delete_result = json.loads(resp.body) if delete_result['Errors']: # NB: bulk includes 404s in ""Number Not Found"", # not ""Errors"" msg_parts = [delete_result['Response Status']] msg_parts.extend( '%s: %s' % (obj, status) for obj, status in delete_result['Errors']) return key, {'code': 'SLODeleteError', 'message': '\n'.join(msg_parts)} # else, all good except (ValueError, TypeError, KeyError): # Logs get all the gory details self.logger.exception( 'Could not parse SLO delete response: %r', resp.body) # Client gets something more generic return key, {'code': 'SLODeleteError', 'message': 'Unexpected swift response'}"," req.get_response(self.app, method='DELETE', query=query)",57,3
openstack%2Fswift~master~Iac8048ad0e23ffb28b914fe880c4b6538bc41c86,openstack/swift,master,Iac8048ad0e23ffb28b914fe880c4b6538bc41c86,py3:  display help if no subcommand provided to manage-shard-ranges,MERGED,2019-02-21 18:21:55.000000000,2019-02-23 02:08:38.000000000,2019-02-23 02:08:38.000000000,"[{'_account_id': 7233}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 18:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/646882e48cfaabe34b13f223364b9af249fa8141', 'message': ""py3: Flag manage-shard-ranges subcommand as required\n\nThat way we don't traceback when you just provide a DB file.\n\nNote that we also had to name the subparser, or we'd get\n\n    TypeError: sequence item 0: expected str instance, NoneType found\n\nwhen argparse tries to enumerate the missing args.\n\nChange-Id: Iac8048ad0e23ffb28b914fe880c4b6538bc41c86\n""}, {'number': 2, 'created': '2019-02-21 22:36:39.000000000', 'files': ['swift/cli/manage_shard_ranges.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/be3e21582967724f23db6e671f2c29128d39472e', 'message': ""py3:  display help if no subcommand provided to manage-shard-ranges\n\nThat way we don't traceback when you just provide a DB file.\n\nAt some point, py3 switched to having optional subparsers. In py37,\nthey added a kwarg to say whether a subparser is optional or required,\nbut for the sake of earlier versions, we have to check whether it was\nset manually and cannot rely on argparse doing it for us. See also:\n\n- https://bugs.python.org/issue9253\n- https://github.com/python/cpython/commit/aaf6fc0\n- https://bugs.python.org/issue33109\n- https://github.com/python/cpython/commit/8ebf5ce\n\nChange-Id: Iac8048ad0e23ffb28b914fe880c4b6538bc41c86\n""}]",0,638477,be3e21582967724f23db6e671f2c29128d39472e,15,3,2,15343,,,0,"py3:  display help if no subcommand provided to manage-shard-ranges

That way we don't traceback when you just provide a DB file.

At some point, py3 switched to having optional subparsers. In py37,
they added a kwarg to say whether a subparser is optional or required,
but for the sake of earlier versions, we have to check whether it was
set manually and cannot rely on argparse doing it for us. See also:

- https://bugs.python.org/issue9253
- https://github.com/python/cpython/commit/aaf6fc0
- https://bugs.python.org/issue33109
- https://github.com/python/cpython/commit/8ebf5ce

Change-Id: Iac8048ad0e23ffb28b914fe880c4b6538bc41c86
",git fetch https://review.opendev.org/openstack/swift refs/changes/77/638477/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/cli/manage_shard_ranges.py'],1,646882e48cfaabe34b13f223364b9af249fa8141,py3/sharder,"import six subparser_kwargs = { 'dest': 'sub-command', 'title': 'Sub-commands', 'help': 'Sub-command help'} if not six.PY2: # py3 both introduced the required option, # and changed the default behavior to False subparser_kwargs['required'] = True subparsers = parser.add_subparsers(**subparser_kwargs)"," subparsers = parser.add_subparsers( help='Sub-command help', title='Sub-commands')",9,2
openstack%2Fneutron~master~I2766ffe1851e1efa93382a6d4698be0b5d31c96c,openstack/neutron,master,I2766ffe1851e1efa93382a6d4698be0b5d31c96c,Use subnet without dhcp in portforwarding functional tests,MERGED,2019-02-19 09:30:48.000000000,2019-02-23 02:08:35.000000000,2019-02-23 02:08:35.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2019-02-19 09:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/06b04a3c11606c85cc25d7fb59d6ee1392909283', 'message': 'Use subnet without dhcp in portforwarding functional tests\n\nIn functional tests of portforwarding service plugin, there are\nsome new IP addresses from existing subnet used in couple of tests.\nRecently we added specific function which should always find some\nunused IP address to not fail tests because of IP address conflicts.\n\nUnfortunatelly IP allocation of DHCP port is done ""in background""\nwhen port is created and I saw at least once in logs that IP address\nfound by _find_new_ip() method was the same IP which was allocated\nto DHCP port in the meantime.\n\nTo avoid such problems in the future this patch disables dhcp for\nsubnet created in this test module. It is not necessary for this\ntests and will avoid allocating one additional IP address by neutron\nserver.\n\nChange-Id: I2766ffe1851e1efa93382a6d4698be0b5d31c96c\n'}, {'number': 2, 'created': '2019-02-19 13:03:00.000000000', 'files': ['neutron/tests/functional/services/portforwarding/test_port_forwarding.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/56ac61fac008d95df4ede90a30592fd1e1571930', 'message': 'Use subnet without dhcp in portforwarding functional tests\n\nIn functional tests of portforwarding service plugin, there are\nsome new IP addresses from existing subnet used in couple of tests.\nRecently we added specific function which should always find some\nunused IP address to not fail tests because of IP address conflicts.\n\nUnfortunatelly IP allocation of DHCP port is done ""in background""\nwhen port is created and I saw at least once in logs that IP address\nfound by _find_new_ip() method was the same IP which was allocated\nto DHCP port in the meantime.\n\nTo avoid such problems in the future this patch disables dhcp for\nsubnet created in this test module. It is not necessary for this\ntests and will avoid allocating one additional IP address by neutron\nserver.\n\nChange-Id: I2766ffe1851e1efa93382a6d4698be0b5d31c96c\n'}]",0,637802,56ac61fac008d95df4ede90a30592fd1e1571930,49,11,2,11975,,,0,"Use subnet without dhcp in portforwarding functional tests

In functional tests of portforwarding service plugin, there are
some new IP addresses from existing subnet used in couple of tests.
Recently we added specific function which should always find some
unused IP address to not fail tests because of IP address conflicts.

Unfortunatelly IP allocation of DHCP port is done ""in background""
when port is created and I saw at least once in logs that IP address
found by _find_new_ip() method was the same IP which was allocated
to DHCP port in the meantime.

To avoid such problems in the future this patch disables dhcp for
subnet created in this test module. It is not necessary for this
tests and will avoid allocating one additional IP address by neutron
server.

Change-Id: I2766ffe1851e1efa93382a6d4698be0b5d31c96c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/02/637802/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/functional/services/portforwarding/test_port_forwarding.py'],1,06b04a3c11606c85cc25d7fb59d6ee1392909283,fix-portfowarding-functional-test," self.subnet = self._create_subnet( self.fmt, self.net['id'], '10.0.0.0/24', enable_dhcp=False).json['subnet']"," self.subnet = self._create_subnet(self.fmt, self.net['id'], '10.0.0.0/24').json['subnet']",3,2
openstack%2Fnova~master~I1d0a5709f3b5ffe0f417df46f76dd3945a5c565e,openstack/nova,master,I1d0a5709f3b5ffe0f417df46f76dd3945a5c565e,WIP: Don't age swap backing files in the image cache by default,NEW,2019-01-25 14:05:44.000000000,2019-02-23 01:31:13.000000000,,"[{'_account_id': 6873}, {'_account_id': 6962}, {'_account_id': 9008}, {'_account_id': 9555}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-25 14:05:44.000000000', 'files': ['nova/virt/libvirt/imagecache.py', 'nova/virt/imagecache.py', 'nova/conf/workarounds.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ee638403cee0c1ae931dd825b00f6a13048d9e96', 'message': ""WIP: Don't age swap backing files in the image cache by default\n\nTODO: pep8, probably syntax, tests. Everything, basically, but this is\nthe idea.\n\nChange-Id: I1d0a5709f3b5ffe0f417df46f76dd3945a5c565e\nCloses-Bug: #1804262\n""}]",5,633213,ee638403cee0c1ae931dd825b00f6a13048d9e96,12,12,1,9555,,,0,"WIP: Don't age swap backing files in the image cache by default

TODO: pep8, probably syntax, tests. Everything, basically, but this is
the idea.

Change-Id: I1d0a5709f3b5ffe0f417df46f76dd3945a5c565e
Closes-Bug: #1804262
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/633213/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/imagecache.py', 'nova/virt/imagecache.py', 'nova/conf/workarounds.py']",3,ee638403cee0c1ae931dd825b00f6a13048d9e96,bug/1804262," cfg.BoolOpt( 'imagecache_age_swap', default=False, help="""""" Enable the aging of swap backing files in the image cache. This workaround only affects the libvirt and vmwareapi hypervisor drivers. TODO: Write a user-consumable summary of why they probably don't need to re-enable this. Possibly detail a method for a one-off cleanup if required. See: https://bugs.launchpad.net/nova/+bug/1804262 """"""),",,41,17
openstack%2Fkeystone~master~I79564dc99fd65a5609bd548d12a0413ca3ee6b2a,openstack/keystone,master,I79564dc99fd65a5609bd548d12a0413ca3ee6b2a,Update introduction of external services doc,MERGED,2019-02-22 00:53:13.000000000,2019-02-23 00:44:07.000000000,2019-02-23 00:44:07.000000000,"[{'_account_id': 2903}, {'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:53:13.000000000', 'files': ['doc/source/contributor/services.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/4d2a219a3bf58c873c5beed9770167d028d3665b', 'message': 'Update introduction of external services doc\n\nThis document is written for other developers working on OpenStack.\nIts goal is to describe various concepts in a way that other\ndevelopers, who may not be familiar with keystone, can digest and use\neffectively in their projects.\n\nThe introductory paragraph was phrased as if the v3 API just became a\nthing, when it has actually been around for a long time. It also\neluded to underlying implementation details by mentioning paste\npipelines, which we no longer use.\n\nThis commit updates the introduction to be more relevant to the state\nof things today.\n\nChange-Id: I79564dc99fd65a5609bd548d12a0413ca3ee6b2a\n'}]",0,638560,4d2a219a3bf58c873c5beed9770167d028d3665b,7,3,1,5046,,,0,"Update introduction of external services doc

This document is written for other developers working on OpenStack.
Its goal is to describe various concepts in a way that other
developers, who may not be familiar with keystone, can digest and use
effectively in their projects.

The introductory paragraph was phrased as if the v3 API just became a
thing, when it has actually been around for a long time. It also
eluded to underlying implementation details by mentioning paste
pipelines, which we no longer use.

This commit updates the introduction to be more relevant to the state
of things today.

Change-Id: I79564dc99fd65a5609bd548d12a0413ca3ee6b2a
",git fetch https://review.opendev.org/openstack/keystone refs/changes/60/638560/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/services.rst'],1,4d2a219a3bf58c873c5beed9770167d028d3665b,,advantage of the v3 API. The v3 API was introduced as a stable API in the Grizzly release.,"advantage of the v3 API. The v3 API was introduced as a stable API in the Grizzly release and included in the default pipeline ever since. Until recently, its use has been hidden from other services because the ``auth_token`` middleware translated the token format so that both versions look the same. Once the services need to make use of v3 features they need to know about how it works.",2,7
openstack%2Fnova~master~Iff2fca18a779e70deecf8e57279e2daf9bc5529a,openstack/nova,master,Iff2fca18a779e70deecf8e57279e2daf9bc5529a,Fix irrelevant-files for legacy-grenade-dsvm-neutron-multinode-live-migration,MERGED,2019-02-15 17:25:48.000000000,2019-02-23 00:44:00.000000000,2019-02-23 00:43:59.000000000,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-15 17:25:48.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/6d803746de876069f2216208f493787cce52f994', 'message': 'Fix irrelevant-files for legacy-grenade-dsvm-neutron-multinode-live-migration\n\nThe change to irrelevant-files in I902e459093af9b82f9033d58cffcb2a628f5ec39\nmade it such that the job will *only* run on changes to the\nnova/tests/live_migration/ path which was not the intent. This fixes\nthe regex to not run the job on changes to nova/tests/ unless those\nchanges are in the nova/tests/live_migration/ directory.\n\nThis would probably be easier to reason about long-term if the\nnova/tests/live_migration/ directory was moved under nova/gate/\nand then we could just use the standard irrelevant-files list. That\nrefactoring is left for another day though.\n\nChange-Id: Iff2fca18a779e70deecf8e57279e2daf9bc5529a\nCloses-Bug: #1816152\n'}]",2,637231,6d803746de876069f2216208f493787cce52f994,25,13,1,6873,,,0,"Fix irrelevant-files for legacy-grenade-dsvm-neutron-multinode-live-migration

The change to irrelevant-files in I902e459093af9b82f9033d58cffcb2a628f5ec39
made it such that the job will *only* run on changes to the
nova/tests/live_migration/ path which was not the intent. This fixes
the regex to not run the job on changes to nova/tests/ unless those
changes are in the nova/tests/live_migration/ directory.

This would probably be easier to reason about long-term if the
nova/tests/live_migration/ directory was moved under nova/gate/
and then we could just use the standard irrelevant-files list. That
refactoring is left for another day though.

Change-Id: Iff2fca18a779e70deecf8e57279e2daf9bc5529a
Closes-Bug: #1816152
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/637231/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,6d803746de876069f2216208f493787cce52f994,bug/1816152, - ^nova/tests/(?!live_migration/).*$, - ^(?!nova/tests/live_migration/).*$,1,1
openstack%2Fnova~stable%2Frocky~Ie698db56dfab5cdc03826c8ca0e8c60ad5f2cdc9,openstack/nova,stable/rocky,Ie698db56dfab5cdc03826c8ca0e8c60ad5f2cdc9,Fix typo,MERGED,2019-01-25 12:58:10.000000000,2019-02-23 00:43:51.000000000,2019-02-23 00:43:51.000000000,"[{'_account_id': 1063}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 15888}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 28748}]","[{'number': 1, 'created': '2019-01-25 12:58:10.000000000', 'files': ['nova/virt/hardware.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/444d65221cc7a20a73fa38aa1ca41d7957b0198e', 'message': 'Fix typo\n\nChange-Id: Ie698db56dfab5cdc03826c8ca0e8c60ad5f2cdc9\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n(cherry picked from commit 37593defd4c6e87d68725b021c9653ee78150f46)\n'}]",0,633196,444d65221cc7a20a73fa38aa1ca41d7957b0198e,27,11,1,15334,,,0,"Fix typo

Change-Id: Ie698db56dfab5cdc03826c8ca0e8c60ad5f2cdc9
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
(cherry picked from commit 37593defd4c6e87d68725b021c9653ee78150f46)
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/633196/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/hardware.py'],1,444d65221cc7a20a73fa38aa1ca41d7957b0198e,bug/1810977," 'selected pagesize: %d', pagesize)"," 'selectionned pagesize: %d', pagesize)",1,1
openstack%2Fnova~stable%2Fqueens~I6e871311a0fa10beaf601ca6912b4a33ba4094e0,openstack/nova,stable/queens,I6e871311a0fa10beaf601ca6912b4a33ba4094e0,PCI: do not force remove allocated devices,MERGED,2019-02-05 23:29:54.000000000,2019-02-23 00:43:43.000000000,2019-02-23 00:43:42.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9373}, {'_account_id': 10118}, {'_account_id': 11604}, {'_account_id': 14595}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-05 23:29:54.000000000', 'files': ['nova/pci/manager.py', 'nova/tests/unit/pci/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/955ecf26c57d1eeb2463fb342ffb6b6114e6ce24', 'message': 'PCI: do not force remove allocated devices\n\nIn the ocata release the pci_passthrough_whitelist\nwas moved from the [DEFAULT] section of the nova.conf\nto the [pci] section and renamed to passthrough_whitelist.\n\nOn upgrading if the operator chooses to migrate the config\nvalue to the new section it is not uncommon\nto forget to rename the config value.\nSimilarly if an operator is updateing the whitelist and\nmistypes the value it can also lead to the whitelist\nbeing ignored.\n\nAs a result of either error the nova compute agent\nwould delete all database entries for a host regardless of\nif the pci device was in use by an instance. If this occurs\nthe only recorse for an operator is to delete and recreate\nthe guest on that host after correcting the error or manually\nrestore the database to backup or otherwise consistent state.\n\nThis change alters the _set_hvdevs function to not force\nremove allocated or claimed devices if they are no longer\npresent in the pci whitelist.\n\nCloses-Bug: #1633120\nChange-Id: I6e871311a0fa10beaf601ca6912b4a33ba4094e0\n(cherry picked from commit 26c41eccade6412f61f9a8721d853b545061adcc)\n'}]",0,635072,955ecf26c57d1eeb2463fb342ffb6b6114e6ce24,27,9,1,11604,,,0,"PCI: do not force remove allocated devices

In the ocata release the pci_passthrough_whitelist
was moved from the [DEFAULT] section of the nova.conf
to the [pci] section and renamed to passthrough_whitelist.

On upgrading if the operator chooses to migrate the config
value to the new section it is not uncommon
to forget to rename the config value.
Similarly if an operator is updateing the whitelist and
mistypes the value it can also lead to the whitelist
being ignored.

As a result of either error the nova compute agent
would delete all database entries for a host regardless of
if the pci device was in use by an instance. If this occurs
the only recorse for an operator is to delete and recreate
the guest on that host after correcting the error or manually
restore the database to backup or otherwise consistent state.

This change alters the _set_hvdevs function to not force
remove allocated or claimed devices if they are no longer
present in the pci whitelist.

Closes-Bug: #1633120
Change-Id: I6e871311a0fa10beaf601ca6912b4a33ba4094e0
(cherry picked from commit 26c41eccade6412f61f9a8721d853b545061adcc)
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/635072/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/pci/manager.py', 'nova/tests/unit/pci/test_manager.py']",2,955ecf26c57d1eeb2463fb342ffb6b6114e6ce24,bug/1633120," def test_set_hvdev_remove_tree_maintained_with_allocations(self): # Make sure the device tree is properly maintained when there are # devices removed from the system that are allocated to vms. all_devs = fake_db_devs_tree[:] self._create_tracker(all_devs) # we start with 3 devices self.assertEqual( 3, len([dev for dev in self.tracker.pci_devs if dev.status != fields.PciDeviceStatus.REMOVED])) # we then allocate one device pci_requests_obj = self._create_pci_requests_object( [{'count': 1, 'spec': [{'vendor_id': 'v2'}]}]) # NOTE(sean-k-mooney): context, pci request, numa topology claimed_dev = self.tracker.claim_instance( mock.sentinel.context, pci_requests_obj, None)[0] self.tracker._set_hvdevs(all_devs) # and assert that no devices were removed self.assertEqual( 0, len([dev for dev in self.tracker.pci_devs if dev.status == fields.PciDeviceStatus.REMOVED])) # we then try to remove the allocated device from the set reported # by the driver. fake_pci_devs = [dev for dev in all_devs if dev['address'] != claimed_dev.address] with mock.patch(""nova.pci.manager.LOG.warning"") as log: self.tracker._set_hvdevs(fake_pci_devs) log.assert_called_once() args = log.call_args_list[0][0] # args of first call self.assertIn('Unable to remove device with', args[0]) # and assert no devices are removed from the tracker self.assertEqual( 0, len([dev for dev in self.tracker.pci_devs if dev.status == fields.PciDeviceStatus.REMOVED])) # free the device that was allocated and update tracker again self.tracker._free_device(claimed_dev) self.tracker._set_hvdevs(fake_pci_devs) # and assert that one device is removed from the tracker self.assertEqual( 1, len([dev for dev in self.tracker.pci_devs if dev.status == fields.PciDeviceStatus.REMOVED])) ",,77,5
openstack%2Fnova~master~I944d7e9235790cb2a4a21318c029d51012d157b0,openstack/nova,master,I944d7e9235790cb2a4a21318c029d51012d157b0,vmware:add support for the hw_video_ram image property,MERGED,2018-04-25 12:47:35.000000000,2019-02-23 00:43:27.000000000,2019-02-23 00:43:26.000000000,"[{'_account_id': 1653}, {'_account_id': 4690}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 9172}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 27076}, {'_account_id': 28100}]","[{'number': 1, 'created': '2018-04-25 12:47:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9759638ae0ac7fed0ab51b25410e57d1cbe49dbf', 'message': 'Validating video ram against the max video ram allowed\n\nChange-Id: I944d7e9235790cb2a4a21318c029d51012d157b0\n'}, {'number': 2, 'created': '2018-04-26 12:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dab61a887fc5ef1b8d3de11129442da6421ec63b', 'message': 'Validating video ram against the max video ram allowed\n\nChange-Id: I944d7e9235790cb2a4a21318c029d51012d157b0\n'}, {'number': 3, 'created': '2018-04-27 08:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1db58c4c5eeb338184832443d144440019c35b84', 'message': 'vmware:Validation video ram against the max video ram allowed.\n\nAdded create of a video card config spec and validation check\nif the image meta video ram(""hw_video_ram"") is bigger than the\nmaximum allowed ""hw_video:ram_max_mb"" from the flavor.\n\nChange-Id: I944d7e9235790cb2a4a21318c029d51012d157b0\n'}, {'number': 4, 'created': '2018-04-27 11:33:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd24da31db6dcceba8bda6f40aecfa7835ae078e', 'message': 'vmware:Validation video ram against the max video ram allowed.\n\nAdded create of a video card config spec and validation check\nif the image meta video ram(""hw_video_ram"") is bigger than the\nmaximum allowed ""hw_video:ram_max_mb"" from the flavor.\n\nChange-Id: I944d7e9235790cb2a4a21318c029d51012d157b0\n'}, {'number': 5, 'created': '2018-05-02 12:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0af9e4ee8eb6d9817b75b4c543d634a77ac8602', 'message': 'vmware:Validation video ram against the max video ram allowed.\n\nAdded create of a video card config spec and validation check\nif the image meta video ram(""hw_video_ram"") is bigger than the\nmaximum allowed ""hw_video:ram_max_mb"" from the flavor.\n\nChange-Id: I944d7e9235790cb2a4a21318c029d51012d157b0\n'}, {'number': 6, 'created': '2018-05-08 22:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7fb191ad3e7b819f840622efe9148d9a535b9767', 'message': 'vmware:Validation video ram against the max video ram allowed.\n\nAdded create of a video card config spec and validation check\nif the image meta video ram(""hw_video_ram"") is bigger than the\nmaximum allowed ""hw_video:ram_max_mb"" from the flavor.\n\nChange-Id: I944d7e9235790cb2a4a21318c029d51012d157b0\n'}, {'number': 7, 'created': '2018-05-10 08:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/290f56b11b20c2d7a07f373d61cf02412b324e91', 'message': 'vmware:Validation video ram against the max video ram allowed.\n\nAdded create of a video card config spec and validation check\nif the image meta video ram(""hw_video_ram"") is bigger than the\nmaximum allowed ""hw_video:ram_max_mb"" from the flavor.\n\nChange-Id: I944d7e9235790cb2a4a21318c029d51012d157b0\n'}, {'number': 8, 'created': '2018-05-10 10:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/44cba362801562f4e1438b603a753e01eb8aa693', 'message': 'vmware:Validation video ram against the max video ram allowed.\n\nAdded create of a video card config spec and validation check\nif the image meta video ram(""hw_video_ram"") is bigger than the\nmaximum allowed ""hw_video:ram_max_mb"" from the flavor.\n\nChange-Id: I944d7e9235790cb2a4a21318c029d51012d157b0\n'}, {'number': 9, 'created': '2018-05-11 07:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/23f8a97fb7034e0abb41a3e05173c39e1541abaf', 'message': 'vmware:Validation video ram against the max video ram allowed.\n\nAdded create of a video card config spec and validation check\nif the image meta video ram(""hw_video_ram"") is bigger than the\nmaximum allowed ""hw_video:ram_max_mb"" from the flavor.\n\nChange-Id: I944d7e9235790cb2a4a21318c029d51012d157b0\n'}, {'number': 10, 'created': '2018-05-15 07:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ffa642c6c3bc0f727baeb264f39d616952a43b9e', 'message': 'vmware:add support for the hw_video_ram image property\n\nAdded create of a video card config spec and validation check\nif the image meta video ram(""hw_video_ram"") is bigger than the\nmaximum allowed ""hw_video:ram_max_mb"" from the flavor.\n\nChange-Id: I944d7e9235790cb2a4a21318c029d51012d157b0\n'}, {'number': 11, 'created': '2018-12-19 08:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62b3e3fb69ea5e0d08962eb7d28964ac6346258b', 'message': 'vmware:add support for the hw_video_ram image property\n\nAdded create of a video card config spec and validation check\nif the image meta video ram(""hw_video_ram"") is bigger than the\nmaximum allowed ""hw_video:ram_max_mb"" from the flavor.\n\nChange-Id: I944d7e9235790cb2a4a21318c029d51012d157b0\n'}, {'number': 12, 'created': '2018-12-19 15:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51983f9d84dff69135f1b51787455067512e884d', 'message': 'vmware:add support for the hw_video_ram image property\n\nAdded create of a video card config spec and validation check\nif the image meta video ram(""hw_video_ram"") is bigger than the\nmaximum allowed ""hw_video:ram_max_mb"" from the flavor.\n\nChange-Id: I944d7e9235790cb2a4a21318c029d51012d157b0\n'}, {'number': 13, 'created': '2018-12-20 07:39:28.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py', 'doc/source/user/flavors.rst', 'nova/virt/vmwareapi/vm_util.py', 'releasenotes/notes/vmware-add-max-ram-validation-f27f94d4a04aef3a.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/38aa83b7fc53b76f7cef92573da235838629b499', 'message': 'vmware:add support for the hw_video_ram image property\n\nAdded create of a video card config spec and validation check\nif the image meta video ram(""hw_video_ram"") is bigger than the\nmaximum allowed ""hw_video:ram_max_mb"" from the flavor.\n\nChange-Id: I944d7e9235790cb2a4a21318c029d51012d157b0\n'}]",54,564193,38aa83b7fc53b76f7cef92573da235838629b499,207,24,13,28100,,,0,"vmware:add support for the hw_video_ram image property

Added create of a video card config spec and validation check
if the image meta video ram(""hw_video_ram"") is bigger than the
maximum allowed ""hw_video:ram_max_mb"" from the flavor.

Change-Id: I944d7e9235790cb2a4a21318c029d51012d157b0
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/564193/12 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py', 'nova/virt/vmwareapi/vm_util.py']",3,9759638ae0ac7fed0ab51b25410e57d1cbe49dbf,vmware_validate_video_ram," vif_limits=None, firmware=None, hw_video_ram=None): self.hw_video_ram = hw_video_ram virtual_device_config_spec = create_video_card_spec(client_factory, extra_specs) if virtual_device_config_spec: devices.append(virtual_device_config_spec) def create_video_card_spec(client_factory, extra_specs): if extra_specs.hw_video_ram: video_card = client_factory.create('ns0:VirtualMachineVideoCard') video_card.videoRamSizeInKB = extra_specs.hw_video_ram video_card.key = -1 virtual_device_config_spec = client_factory.create('ns0:VirtualDeviceConfigSpec') virtual_device_config_spec.operation = ""add"" virtual_device_config_spec.device = video_card return virtual_device_config_spec"," vif_limits=None, firmware=None):",42,1
openstack%2Fkeystoneauth~master~I36a0b8dd275df8fcee556ed305c34c16a90384e8,openstack/keystoneauth,master,I36a0b8dd275df8fcee556ed305c34c16a90384e8,Expose application credentials in AccessInfoV3,MERGED,2019-02-10 23:51:49.000000000,2019-02-23 00:38:20.000000000,2019-02-23 00:38:20.000000000,"[{'_account_id': 2903}, {'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-10 23:51:49.000000000', 'files': ['keystoneauth1/access/access.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/759a9a5f591d85f9dbd6ae1eed8f1ff1e5799d06', 'message': 'Expose application credentials in AccessInfoV3\n\nSince application credentials are used in some tokens it is important\nto expose those attributes in the AccessInfoV3 object in the same way we\nexpose other token data.\n\nChange-Id: I36a0b8dd275df8fcee556ed305c34c16a90384e8\n'}]",0,636074,759a9a5f591d85f9dbd6ae1eed8f1ff1e5799d06,16,4,1,8482,,,0,"Expose application credentials in AccessInfoV3

Since application credentials are used in some tokens it is important
to expose those attributes in the AccessInfoV3 object in the same way we
expose other token data.

Change-Id: I36a0b8dd275df8fcee556ed305c34c16a90384e8
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/74/636074/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneauth1/access/access.py'],1,759a9a5f591d85f9dbd6ae1eed8f1ff1e5799d06,bp/whitelist-extension-for-app-creds, def application_credential(self): return self._data['token']['application_credential'] @_missingproperty def application_credential_id(self): return self._data['token']['application_credential']['id'] @property,,8,0
openstack%2Fswift~master~I1095262563eff92d6d0a399eb0d5f9d3045becf3,openstack/swift,master,I1095262563eff92d6d0a399eb0d5f9d3045becf3,py3: port versioned_writes,MERGED,2019-02-19 21:07:07.000000000,2019-02-22 23:21:31.000000000,2019-02-22 23:21:31.000000000,"[{'_account_id': 597}, {'_account_id': 7233}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-19 21:07:07.000000000', 'files': ['swift/common/middleware/versioned_writes.py', 'test/unit/common/middleware/test_versioned_writes.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/swift/commit/ce261b12e68bf8a017dad7b11335e7555a270610', 'message': 'py3: port versioned_writes\n\nChange-Id: I1095262563eff92d6d0a399eb0d5f9d3045becf3\n'}]",0,638010,ce261b12e68bf8a017dad7b11335e7555a270610,28,4,1,15343,,,0,"py3: port versioned_writes

Change-Id: I1095262563eff92d6d0a399eb0d5f9d3045becf3
",git fetch https://review.opendev.org/openstack/swift refs/changes/10/638010/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/versioned_writes.py', 'test/unit/common/middleware/test_versioned_writes.py', 'tox.ini']",3,ce261b12e68bf8a017dad7b11335e7555a270610,py3/mw-copy, test/unit/common/middleware/test_versioned_writes.py \,,14,5
openstack%2Fnova~stable%2Fpike~I1a9bdb596f74605ab4613c9cb2574e976aebbd8c,openstack/nova,stable/pike,I1a9bdb596f74605ab4613c9cb2574e976aebbd8c,Create BDMs/tags in cell with instance when over-quota,MERGED,2018-12-09 11:50:24.000000000,2019-02-22 23:21:27.000000000,2019-02-22 23:21:27.000000000,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9373}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-09 11:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7628636b43964d524853d78d9d8b75578e070a97', 'message': 'Create BDMs/tags in cell with instance when over-quota\n\nIf the server create build request fails the quota check\nafter the instance record has been created in a cell, we also\nneed to create the BDMs and tags in that cell so that users\ncan still see the tags on the server and so the API can\nproperly cleanup volume attachments when the server is deleted.\n\nThis change updates _cleanup_build_artifacts to create BDMs\nand tags in the same cell as the instance prior to deleting the\nbuild request and request spec and adjusts the assertions in the\nrelated functional test to show the bug is fixed.\n\nAs for instances that get buried in cell0 due to scheduling\nfailures, the tags are not created there so comments are left\nin those code paths to fix that issue as well, but that can be\ndone separately from this patch.\n\n# Conflicts:\n#\tnova/conductor/manager.py\nNOTE(s10): Conflict is caused by I70b11dd489d222be3d70733355bfe7966df556aa\nnot being in Pike.\n\nChange-Id: I1a9bdb596f74605ab4613c9cb2574e976aebbd8c\nCloses-Bug: #1806064\n(cherry picked from commit 6d0386058b9628bbfcf64abdd707ad87ee19353c)\n(cherry picked from commit 3028d25705bbd54cdf0b7ba13859a809d401fc70)\n(cherry picked from commit 6b535459dc9da9307178e8f8ff394fc8fe60d59c)\n'}, {'number': 2, 'created': '2018-12-09 12:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f0e2a4d8ac7c072cbb3296cca7ca10c87d5d963d', 'message': 'Create BDMs/tags in cell with instance when over-quota\n\nIf the server create build request fails the quota check\nafter the instance record has been created in a cell, we also\nneed to create the BDMs and tags in that cell so that users\ncan still see the tags on the server and so the API can\nproperly cleanup volume attachments when the server is deleted.\n\nThis change updates _cleanup_build_artifacts to create BDMs\nand tags in the same cell as the instance prior to deleting the\nbuild request and request spec and adjusts the assertions in the\nrelated functional test to show the bug is fixed.\n\nAs for instances that get buried in cell0 due to scheduling\nfailures, the tags are not created there so comments are left\nin those code paths to fix that issue as well, but that can be\ndone separately from this patch.\n\n# Conflicts:\n#\tnova/conductor/manager.py\nNOTE(s10): Conflict is caused by I70b11dd489d222be3d70733355bfe7966df556aa\nnot being in Pike.\n\nChange-Id: I1a9bdb596f74605ab4613c9cb2574e976aebbd8c\nCloses-Bug: #1806064\n(cherry picked from commit 6d0386058b9628bbfcf64abdd707ad87ee19353c)\n(cherry picked from commit 3028d25705bbd54cdf0b7ba13859a809d401fc70)\n(cherry picked from commit 6b535459dc9da9307178e8f8ff394fc8fe60d59c)\n'}, {'number': 3, 'created': '2018-12-09 12:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e5ebb0f5bad118fff67ed78f0e2f61ed0e32289b', 'message': 'Create BDMs/tags in cell with instance when over-quota\n\nIf the server create build request fails the quota check\nafter the instance record has been created in a cell, we also\nneed to create the BDMs and tags in that cell so that users\ncan still see the tags on the server and so the API can\nproperly cleanup volume attachments when the server is deleted.\n\nThis change updates _cleanup_build_artifacts to create BDMs\nand tags in the same cell as the instance prior to deleting the\nbuild request and request spec and adjusts the assertions in the\nrelated functional test to show the bug is fixed.\n\nAs for instances that get buried in cell0 due to scheduling\nfailures, the tags are not created there so comments are left\nin those code paths to fix that issue as well, but that can be\ndone separately from this patch.\n\nNOTE(s10): Conflict is caused by I70b11dd489d222be3d70733355bfe7966df556aa\nnot being in Pike.\n\nChange-Id: I1a9bdb596f74605ab4613c9cb2574e976aebbd8c\nCloses-Bug: #1806064\n(cherry picked from commit 6d0386058b9628bbfcf64abdd707ad87ee19353c)\n(cherry picked from commit 3028d25705bbd54cdf0b7ba13859a809d401fc70)\n(cherry picked from commit 6b535459dc9da9307178e8f8ff394fc8fe60d59c)\n'}, {'number': 4, 'created': '2018-12-09 12:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1319b5ac97a2317f92ac34c240c19561574cb7eb', 'message': 'Create BDMs/tags in cell with instance when over-quota\n\nIf the server create build request fails the quota check\nafter the instance record has been created in a cell, we also\nneed to create the BDMs and tags in that cell so that users\ncan still see the tags on the server and so the API can\nproperly cleanup volume attachments when the server is deleted.\n\nThis change updates _cleanup_build_artifacts to create BDMs\nand tags in the same cell as the instance prior to deleting the\nbuild request and request spec and adjusts the assertions in the\nrelated functional test to show the bug is fixed.\n\nAs for instances that get buried in cell0 due to scheduling\nfailures, the tags are not created there so comments are left\nin those code paths to fix that issue as well, but that can be\ndone separately from this patch.\n\n# Conflicts:\n#\tnova/conductor/manager.py\nNOTE(s10): Conflict is caused by I70b11dd489d222be3d70733355bfe7966df556aa\nnot being in Pike.\n\nChange-Id: I1a9bdb596f74605ab4613c9cb2574e976aebbd8c\nCloses-Bug: #1806064\n(cherry picked from commit 6d0386058b9628bbfcf64abdd707ad87ee19353c)\n(cherry picked from commit 3028d25705bbd54cdf0b7ba13859a809d401fc70)\n(cherry picked from commit 6b535459dc9da9307178e8f8ff394fc8fe60d59c)\n'}, {'number': 5, 'created': '2018-12-09 13:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d94ebaaa0664de06e3d265a29d66d7aad647431', 'message': 'Create BDMs/tags in cell with instance when over-quota\n\nIf the server create build request fails the quota check\nafter the instance record has been created in a cell, we also\nneed to create the BDMs and tags in that cell so that users\ncan still see the tags on the server and so the API can\nproperly cleanup volume attachments when the server is deleted.\n\nThis change updates _cleanup_build_artifacts to create BDMs\nand tags in the same cell as the instance prior to deleting the\nbuild request and request spec and adjusts the assertions in the\nrelated functional test to show the bug is fixed.\n\nAs for instances that get buried in cell0 due to scheduling\nfailures, the tags are not created there so comments are left\nin those code paths to fix that issue as well, but that can be\ndone separately from this patch.\n\n# Conflicts:\n#\tnova/conductor/manager.py\nNOTE(s10): Conflict is caused by I70b11dd489d222be3d70733355bfe7966df556aa\nnot being in Pike.\n\nChange-Id: I1a9bdb596f74605ab4613c9cb2574e976aebbd8c\nCloses-Bug: #1806064\n(cherry picked from commit 6d0386058b9628bbfcf64abdd707ad87ee19353c)\n(cherry picked from commit 3028d25705bbd54cdf0b7ba13859a809d401fc70)\n(cherry picked from commit 6b535459dc9da9307178e8f8ff394fc8fe60d59c)\n'}, {'number': 6, 'created': '2018-12-09 15:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0804d651d284a1628babdfd7f4a147ba0bfc8922', 'message': 'Create BDMs/tags in cell with instance when over-quota\n\nIf the server create build request fails the quota check\nafter the instance record has been created in a cell, we also\nneed to create the BDMs and tags in that cell so that users\ncan still see the tags on the server and so the API can\nproperly cleanup volume attachments when the server is deleted.\n\nThis change updates _cleanup_build_artifacts to create BDMs\nand tags in the same cell as the instance prior to deleting the\nbuild request and request spec and adjusts the assertions in the\nrelated functional test to show the bug is fixed.\n\nAs for instances that get buried in cell0 due to scheduling\nfailures, the tags are not created there so comments are left\nin those code paths to fix that issue as well, but that can be\ndone separately from this patch.\n\nNOTE(s10): Conflict is caused by I70b11dd489d222be3d70733355bfe7966df556aa\nnot being in Pike.\n\nChange-Id: I1a9bdb596f74605ab4613c9cb2574e976aebbd8c\nCloses-Bug: #1806064\n(cherry picked from commit 6d0386058b9628bbfcf64abdd707ad87ee19353c)\n(cherry picked from commit 3028d25705bbd54cdf0b7ba13859a809d401fc70)\n(cherry picked from commit 6b535459dc9da9307178e8f8ff394fc8fe60d59c)\n'}, {'number': 7, 'created': '2018-12-09 15:51:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9003558461600722074b7c4d2f05b47508a0329c', 'message': 'Create BDMs/tags in cell with instance when over-quota\n\nIf the server create build request fails the quota check\nafter the instance record has been created in a cell, we also\nneed to create the BDMs and tags in that cell so that users\ncan still see the tags on the server and so the API can\nproperly cleanup volume attachments when the server is deleted.\n\nThis change updates _cleanup_build_artifacts to create BDMs\nand tags in the same cell as the instance prior to deleting the\nbuild request and request spec and adjusts the assertions in the\nrelated functional test to show the bug is fixed.\n\nAs for instances that get buried in cell0 due to scheduling\nfailures, the tags are not created there so comments are left\nin those code paths to fix that issue as well, but that can be\ndone separately from this patch.\n\nNOTE(s10): Conflict is caused by I70b11dd489d222be3d70733355bfe7966df556aa\nnot being in Pike.\n\nChange-Id: I1a9bdb596f74605ab4613c9cb2574e976aebbd8c\nCloses-Bug: #1806064\n(cherry picked from commit 6d0386058b9628bbfcf64abdd707ad87ee19353c)\n(cherry picked from commit 3028d25705bbd54cdf0b7ba13859a809d401fc70)\n(cherry picked from commit 6b535459dc9da9307178e8f8ff394fc8fe60d59c)\n'}, {'number': 8, 'created': '2018-12-09 17:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d872338fdacdea6801fcbcdc91ddca7fc2e79170', 'message': 'Create BDMs/tags in cell with instance when over-quota\n\nIf the server create build request fails the quota check\nafter the instance record has been created in a cell, we also\nneed to create the BDMs and tags in that cell so that users\ncan still see the tags on the server and so the API can\nproperly cleanup volume attachments when the server is deleted.\n\nThis change updates _cleanup_build_artifacts to create BDMs\nand tags in the same cell as the instance prior to deleting the\nbuild request and request spec and adjusts the assertions in the\nrelated functional test to show the bug is fixed.\n\nAs for instances that get buried in cell0 due to scheduling\nfailures, the tags are not created there so comments are left\nin those code paths to fix that issue as well, but that can be\ndone separately from this patch.\n\nNOTE(s10): Conflict is caused by I70b11dd489d222be3d70733355bfe7966df556aa\nnot being in Pike.\n\nChange-Id: I1a9bdb596f74605ab4613c9cb2574e976aebbd8c\nCloses-Bug: #1806064\n(cherry picked from commit 6d0386058b9628bbfcf64abdd707ad87ee19353c)\n(cherry picked from commit 3028d25705bbd54cdf0b7ba13859a809d401fc70)\n(cherry picked from commit 6b535459dc9da9307178e8f8ff394fc8fe60d59c)\n'}, {'number': 9, 'created': '2018-12-11 15:10:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8af9db6a05da895045e60cbd70a80c484d094cfe', 'message': 'Create BDMs/tags in cell with instance when over-quota\n\nIf the server create build request fails the quota check\nafter the instance record has been created in a cell, we also\nneed to create the BDMs and tags in that cell so that users\ncan still see the tags on the server and so the API can\nproperly cleanup volume attachments when the server is deleted.\n\nThis change updates _cleanup_build_artifacts to create BDMs\nand tags in the same cell as the instance prior to deleting the\nbuild request and request spec and adjusts the assertions in the\nrelated functional test to show the bug is fixed.\n\nAs for instances that get buried in cell0 due to scheduling\nfailures, the tags are not created there so comments are left\nin those code paths to fix that issue as well, but that can be\ndone separately from this patch.\n\nNOTE(s10): Conflict is caused by I70b11dd489d222be3d70733355bfe7966df556aa\nnot being in Pike.\n\nChange-Id: I1a9bdb596f74605ab4613c9cb2574e976aebbd8c\nCloses-Bug: #1806064\n(cherry picked from commit 6d0386058b9628bbfcf64abdd707ad87ee19353c)\n(cherry picked from commit 3028d25705bbd54cdf0b7ba13859a809d401fc70)\n(cherry picked from commit 3dd42c2cd658fd3f73b11fbf5e81ccccd748b450)\n'}, {'number': 10, 'created': '2018-12-11 15:10:38.000000000', 'files': ['nova/conductor/manager.py', 'nova/tests/functional/regressions/test_bug_1806064.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3eb9006b3e7e3e9fd296b6c15cceebb36b0495a5', 'message': 'Create BDMs/tags in cell with instance when over-quota\n\nIf the server create build request fails the quota check\nafter the instance record has been created in a cell, we also\nneed to create the BDMs and tags in that cell so that users\ncan still see the tags on the server and so the API can\nproperly cleanup volume attachments when the server is deleted.\n\nThis change updates _cleanup_build_artifacts to create BDMs\nand tags in the same cell as the instance prior to deleting the\nbuild request and request spec and adjusts the assertions in the\nrelated functional test to show the bug is fixed.\n\nAs for instances that get buried in cell0 due to scheduling\nfailures, the tags are not created there so comments are left\nin those code paths to fix that issue as well, but that can be\ndone separately from this patch.\n\nNOTE(s10): Conflict is caused by I70b11dd489d222be3d70733355bfe7966df556aa\nnot being in Pike.\n\nChange-Id: I1a9bdb596f74605ab4613c9cb2574e976aebbd8c\nCloses-Bug: #1806064\n(cherry picked from commit 6d0386058b9628bbfcf64abdd707ad87ee19353c)\n(cherry picked from commit 3028d25705bbd54cdf0b7ba13859a809d401fc70)\n(cherry picked from commit 3dd42c2cd658fd3f73b11fbf5e81ccccd748b450)\n'}]",2,623937,3eb9006b3e7e3e9fd296b6c15cceebb36b0495a5,40,9,10,9373,,,0,"Create BDMs/tags in cell with instance when over-quota

If the server create build request fails the quota check
after the instance record has been created in a cell, we also
need to create the BDMs and tags in that cell so that users
can still see the tags on the server and so the API can
properly cleanup volume attachments when the server is deleted.

This change updates _cleanup_build_artifacts to create BDMs
and tags in the same cell as the instance prior to deleting the
build request and request spec and adjusts the assertions in the
related functional test to show the bug is fixed.

As for instances that get buried in cell0 due to scheduling
failures, the tags are not created there so comments are left
in those code paths to fix that issue as well, but that can be
done separately from this patch.

NOTE(s10): Conflict is caused by I70b11dd489d222be3d70733355bfe7966df556aa
not being in Pike.

Change-Id: I1a9bdb596f74605ab4613c9cb2574e976aebbd8c
Closes-Bug: #1806064
(cherry picked from commit 6d0386058b9628bbfcf64abdd707ad87ee19353c)
(cherry picked from commit 3028d25705bbd54cdf0b7ba13859a809d401fc70)
(cherry picked from commit 3dd42c2cd658fd3f73b11fbf5e81ccccd748b450)
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/623937/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conductor/manager.py', 'nova/tests/functional/regressions/test_bug_1806064.py']",2,7628636b43964d524853d78d9d8b75578e070a97,bug/1806064," # Make sure the BDMs and tags also exist in cell1. bdms = objects.BlockDeviceMappingList.get_by_instance_uuid( cctxt, instance.uuid) self.assertEqual(1, len(bdms), 'BDMs were not created in cell1') tags = objects.TagList.get_by_resource_id(cctxt, instance.uuid) self.assertEqual(1, len(tags), 'Tags were not created in cell1') self.assertEqual(['bfv'], server['tags']) attached_volumes = self.cinder_fixture.volume_ids_for_instance( server['id']) # volume_ids_for_instance is a generator so listify self.assertEqual(0, len(list(attached_volumes)))"," # FIXME(mriedem): This is bug 1806064 where the tags are not created # in cell1 along with the instance when the quota check race failure # occurs. Uncomment once fixed. # self.assertEqual(['bfv'], server['tags']) self.assertEqual([], server['tags']) # FIXME(mriedem): This is bug 1806064 where the volume is not detached # because the related BDM record was not created in cell1 along with # the instance so the API could not ""see"" it. Uncomment once fixed. # self.assertIsNone( # self.cinder_fixture.volume_ids_for_instance(server['id'])) self.assertEqual(volume_id, # volume_ids_for_instance is a generator so listify list(self.cinder_fixture.volume_ids_for_instance( server['id']))[0])",33,15
openstack%2Fswift~master~Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666,openstack/swift,master,Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666,py3: port the container,MERGED,2018-05-24 06:17:32.000000000,2019-02-22 23:07:39.000000000,2019-02-22 23:07:39.000000000,"[{'_account_id': 597}, {'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-05-24 06:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cbbf23f74d00e38825491e6af1080234190cfa0a', 'message': 'Make ShardRanges and its CLI py3-compliant\n\n(1 out of 5 tests works)\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 2, 'created': '2018-05-31 05:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/69ca858cf4cc490e6187e1ef64316e4f8a099f67', 'message': 'Make ShardRanges and its CLI py3-compliant\n\n(3 out of 5 tests work)\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 3, 'created': '2018-06-01 23:13:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/95cffd10fefa0cc084ea1c18f87c300fad1ec611', 'message': 'Make ShardRanges and its CLI py3-compliant\n\n(only fails at test_print_db_info_metadata_with_shard_ranges)\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 4, 'created': '2018-06-04 08:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/97f9f25c05f60e6644db6f6ad06229d7cf96da5a', 'message': 'Make ShardRanges and its CLI py3-compliant\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 5, 'created': '2018-06-06 02:01:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f4d20edd6eaeb2f2aeca3017d78571658b985953', 'message': 'Make ShardRanges and its CLI py3-compliant\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nThis version renames ContainerBroker.path property, mostly for\nthe reason of needing to find out how it was used. Searching\nfor just ""path"" was troublesome. Also, is it really a ""path""?\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 6, 'created': '2018-06-14 08:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0ed397ca00648a0c279c3b888707fe813c4fa000', 'message': 'Make ShardRanges and its CLI py3-compliant\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nThis version renames ContainerBroker.path property, mostly for\nthe reason of needing to find out how it was used. Searching\nfor just ""path"" was troublesome. Also, is it really a ""path""?\n\nWe ended with a couple of places where we encode-decode, through\nlower_str.encode() mostly. It\'s unfortunate.\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 7, 'created': '2018-07-05 04:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f77f66f62a560a8e16622cb47d25c7634585c74c', 'message': 'Make ShardRanges and its CLI py3-compliant\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nThis version renames ContainerBroker.path property, mostly for\nthe reason of needing to find out how it was used. Searching\nfor just ""path"" was troublesome. Also, is it really a ""path""?\n\nWe ended with a couple of places where we encode-decode, through\nlower_str.encode() mostly. It\'s unfortunate.\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 8, 'created': '2018-11-03 14:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ebd5611dd820f2aed69e775365fcd7acf9f04024', 'message': 'Make ShardRanges and its CLI py3-compliant\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nThis version renames ContainerBroker.path property, mostly for\nthe reason of needing to find out how it was used. Searching\nfor just ""path"" was troublesome. Also, is it really a ""path""?\n\nWe ended with a couple of places where we encode-decode, through\nlower_str.encode() mostly. It\'s unfortunate.\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 9, 'created': '2018-11-13 00:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/94f05fab6ab5f6eff195b367e41fd741c6357a86', 'message': 'Make ShardRanges and its CLI py3-compliant\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nThis version renames ContainerBroker.path property, mostly for\nthe reason of needing to find out how it was used. Searching\nfor just ""path"" was troublesome. Also, is it really a ""path""?\n\nWe ended with a couple of places where we encode-decode, through\nlower_str.encode() mostly. It\'s unfortunate.\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 10, 'created': '2018-12-21 03:56:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/27b2ba78220ca841f819c7c9acb1f511f8ac4f8a', 'message': 'py3: adapt ShardRanges and its CLI\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nThis version renames ContainerBroker.path property, mostly for\nthe reason of needing to find out how it was used. Searching\nfor just ""path"" was troublesome. Also, is it really a ""path""?\n\nWe ended with a couple of places where we encode-decode, through\nlower_str.encode() mostly. It\'s unfortunate. The logic is, you\'ve\ngot to use the lower_str(), because it can be a bound, so a plain\nold lower() won\'t do. But then it can come out in unicode, if it\nwere a string, so encode it. If it was a bound, it\'s a null encode.\nA house of cards, all of it, until we retire py2.\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 11, 'created': '2018-12-22 00:22:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/047aeb7797b0e24dbe33338295731c2250feae7d', 'message': 'py3: adapt ShardRanges and its CLI\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nThis version renames ContainerBroker.path property, mostly for\nthe reason of needing to find out how it was used. Searching\nfor just ""path"" was troublesome. Also, is it really a ""path""?\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 12, 'created': '2019-01-24 05:07:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ac8a213367bb274f4f03cc829f5aa6a295071cb7', 'message': 'py3: port the container sharder\n\nThis includes ShardRanges and its CLI. And, the sharder seems like\nthe bottom of the dependency chain. Even container backend needs it.\nAlthough, we did have to change the back-end minimally. There is no\nway around it.\n\nBeware, this does affect some of Python 2 code.\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nThis version renames ContainerBroker.path property, mostly for\nthe reason of needing to find out how it was used. Searching\nfor just ""path"" was troublesome. Also, is it really a ""path""?\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 13, 'created': '2019-01-31 03:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/89faf13c56afcb9f48c270d12c185ce0e29f068a', 'message': 'py3: port the container sharder\n\nThis includes ShardRanges and its CLI. And, the sharder seems like\nthe bottom of the dependency chain. Even container backend needs it.\nAlthough, we did have to change the back-end minimally. There is no\nway around it.\n\nBeware, this does affect some of Python 2 code.\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nThis version renames ContainerBroker.path property, mostly for\nthe reason of needing to find out how it was used. Searching\nfor just ""path"" was troublesome. Also, is it really a ""path""?\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 14, 'created': '2019-02-07 22:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4f2f65567fc8ad875370e998cd19235731f7e791', 'message': 'py3: port the container sharder\n\nThis includes ShardRanges and its CLI. And, the sharder seems like\nthe bottom of the dependency chain. Even container backend needs it.\nAlthough, we did have to change the back-end minimally. There is no\nway around it.\n\nBeware, this does affect some of Python 2 code.\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 15, 'created': '2019-02-16 02:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6ddc037c9972f5d82161f2269b3bd66428e19853', 'message': 'py3: port the container sharder\n\nThis includes ShardRanges and its CLI. And, the sharder seems like\nthe bottom of the dependency chain. Even container backend needs it.\nAlthough, we did have to change the back-end minimally. There is no\nway around it.\n\nBeware, this does affect some of Python 2 code.\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 16, 'created': '2019-02-19 19:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/07f6a1835722179883c6ba33ff3ef3d2e6628e4b', 'message': 'py3: port the container sharder\n\nThis includes ShardRanges and its CLI. And, the sharder seems like\nthe bottom of the dependency chain. Even container backend needs it.\nAlthough, we did have to change the back-end minimally. There is no\nway around it.\n\nBeware, this does affect some of Python 2 code.\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 17, 'created': '2019-02-20 00:33:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0cd331428780fadef53101ed770a6d6f37889cb6', 'message': 'py3: port the container\n\nThis started with ShardRanges and its CLI. The sharder is at the\nbottom of the dependency chain. Even container backend needs it.\nOnce we started tinkering with the sharder, it all snowballed to\ninclude the rest of the container services.\n\nBeware, this does affect some of Python 2 code.\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 18, 'created': '2019-02-20 19:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9881705a14ca2b68d908338ed3ff9a3b8b369d5b', 'message': 'py3: port the container\n\nThis started with ShardRanges and its CLI. The sharder is at the\nbottom of the dependency chain. Even container backend needs it.\nOnce we started tinkering with the sharder, it all snowballed to\ninclude the rest of the container services.\n\nBeware, this does affect some of Python 2 code. Mostly it\'s trivial\nand obviously correct, but needs checking by reviewers.\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}, {'number': 19, 'created': '2019-02-21 03:31:03.000000000', 'files': ['test/unit/cli/test_info.py', 'test/unit/__init__.py', 'test/unit/container/test_sharder.py', 'test/unit/container/test_updater.py', 'test/unit/container/test_server.py', 'test/unit/container/test_backend.py', 'swift/common/db.py', 'swift/container/server.py', 'swift/common/utils.py', 'test/unit/container/test_sync.py', 'swift/cli/manage_shard_ranges.py', 'swift/cli/recon.py', 'test/unit/cli/test_manage_shard_ranges.py', 'swift/container/sharder.py', 'test/unit/container/test_auditor.py', 'test/unit/container/test_reconciler.py', 'swift/container/backend.py', 'tox.ini', 'swift/container/reconciler.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/575538b55b1fccc0fb697ad99cab78c92f6c06b7', 'message': 'py3: port the container\n\nThis started with ShardRanges and its CLI. The sharder is at the\nbottom of the dependency chain. Even container backend needs it.\nOnce we started tinkering with the sharder, it all snowballed to\ninclude the rest of the container services.\n\nBeware, this does affect some of Python 2 code. Mostly it\'s trivial\nand obviously correct, but needs checking by reviewers.\n\nAbout killing the stray ""from __future__ import unicode_literals"":\nwe do not do it in general. The specific problem it caused was\na failure of functional tests because unicode leaked into a field\nthat was supposed to be encoded. It is just too hard to track the\ntypes when rules change from file to file, so off with its head.\n\nChange-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666\n'}]",61,570320,575538b55b1fccc0fb697ad99cab78c92f6c06b7,80,5,19,597,,,0,"py3: port the container

This started with ShardRanges and its CLI. The sharder is at the
bottom of the dependency chain. Even container backend needs it.
Once we started tinkering with the sharder, it all snowballed to
include the rest of the container services.

Beware, this does affect some of Python 2 code. Mostly it's trivial
and obviously correct, but needs checking by reviewers.

About killing the stray ""from __future__ import unicode_literals"":
we do not do it in general. The specific problem it caused was
a failure of functional tests because unicode leaked into a field
that was supposed to be encoded. It is just too hard to track the
types when rules change from file to file, so off with its head.

Change-Id: Iba4e65d0e46d8c1f5a91feb96c2c07f99ca7c666
",git fetch https://review.opendev.org/openstack/swift refs/changes/20/570320/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/utils.py', 'swift/cli/manage_shard_ranges.py', 'test/unit/cli/test_manage_shard_ranges.py', 'swift/container/backend.py']",4,cbbf23f74d00e38825491e6af1080234190cfa0a,py3/sharder," # Seems silly to do the isinstance() dance, because ShardRange # has a defined type for each of the 3: 'name' is always text, # bounds are bytes. But, bounds can also be the min/max type. params.append(self.path.encode('utf-8')) params.append(self.path.encode('utf-8')) ## P3 #fp_ = open(""/tmp/dump"",'a') #fp_.write(""broker._get_shard_range_rows.do_query %s conn %d sql %s params %r\n"" % (""Py2"" if six.PY2 else ""Py3"", id(conn), sql, params)) #fp_.close() ShardRange(row[0].decode('utf-8'), *row[1:])", params.append(self.path) params.append(self.path) ShardRange(*row),36,16
openstack%2Fnova~stable%2Fpike~I21c2189cc1de6b8e4857de77acd9f1ef8b6ea9f6,openstack/nova,stable/pike,I21c2189cc1de6b8e4857de77acd9f1ef8b6ea9f6,Add functional regression test for bug 1806064,MERGED,2018-12-09 11:39:23.000000000,2019-02-22 23:07:34.000000000,2019-02-22 23:07:34.000000000,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 9373}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-09 11:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b76edebabc2f009023934755b77b98fc3a6f5e43', 'message': 'Add functional regression test for bug 1806064\n\nChange I9269ffa2b80e48db96c622d0dc0817738854f602 in Pike\nintroduced a race condition where creating multiple\nservers concurrently can fail the second instances quota\ncheck which happens in conductor after the instance record\nis created in the cell database but its related BDMs and\ntags are not stored in the cell DB. When deleting the\nserver from the API, since the BDMs are not in the cell\ndatabase with the instance, they are not ""seen"" and thus\nthe volume attachments are not deleted and the volume is\norphaned. As for tags, you should be able to see the tags\non the server in ERROR status from the API before deleting\nit.\n\nThis change adds a functional regression test to show both\nthe volume attachment and tag issue when we fail the quota\ncheck in conductor.\n\nChange-Id: I21c2189cc1de6b8e4857de77acd9f1ef8b6ea9f6\nRelated-Bug: #1806064\n(cherry picked from commit 5d514b33e28964b38aeb42a8dd5b93f3fc8ae239)\n(cherry picked from commit 5b7e904126f68a8c9f5250620393dcdee54336d8)\n'}, {'number': 2, 'created': '2018-12-09 11:40:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68e1d3d9bc54ee37f740259127fad5fa78e5de04', 'message': 'Add functional regression test for bug 1806064\n\nChange I9269ffa2b80e48db96c622d0dc0817738854f602 in Pike\nintroduced a race condition where creating multiple\nservers concurrently can fail the second instances quota\ncheck which happens in conductor after the instance record\nis created in the cell database but its related BDMs and\ntags are not stored in the cell DB. When deleting the\nserver from the API, since the BDMs are not in the cell\ndatabase with the instance, they are not ""seen"" and thus\nthe volume attachments are not deleted and the volume is\norphaned. As for tags, you should be able to see the tags\non the server in ERROR status from the API before deleting\nit.\n\nThis change adds a functional regression test to show both\nthe volume attachment and tag issue when we fail the quota\ncheck in conductor.\n\nChange-Id: I21c2189cc1de6b8e4857de77acd9f1ef8b6ea9f6\nRelated-Bug: #1806064\n(cherry picked from commit 5d514b33e28964b38aeb42a8dd5b93f3fc8ae239)\n(cherry picked from commit 5b7e904126f68a8c9f5250620393dcdee54336d8)\n(cherry picked from commit 3f37d0bba46fd7f39265863b227c5fd504fa7864)\n'}, {'number': 3, 'created': '2018-12-09 12:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f62dbb96d8d237d6573364b5a831798160e644a', 'message': 'Add functional regression test for bug 1806064\n\nChange I9269ffa2b80e48db96c622d0dc0817738854f602 in Pike\nintroduced a race condition where creating multiple\nservers concurrently can fail the second instances quota\ncheck which happens in conductor after the instance record\nis created in the cell database but its related BDMs and\ntags are not stored in the cell DB. When deleting the\nserver from the API, since the BDMs are not in the cell\ndatabase with the instance, they are not ""seen"" and thus\nthe volume attachments are not deleted and the volume is\norphaned. As for tags, you should be able to see the tags\non the server in ERROR status from the API before deleting\nit.\n\nThis change adds a functional regression test to show both\nthe volume attachment and tag issue when we fail the quota\ncheck in conductor.\n\nChange-Id: I21c2189cc1de6b8e4857de77acd9f1ef8b6ea9f6\nRelated-Bug: #1806064\n(cherry picked from commit 5d514b33e28964b38aeb42a8dd5b93f3fc8ae239)\n(cherry picked from commit 5b7e904126f68a8c9f5250620393dcdee54336d8)\n(cherry picked from commit 3f37d0bba46fd7f39265863b227c5fd504fa7864)\n'}, {'number': 4, 'created': '2018-12-09 13:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e03806f71c99d6bdd5e74461b87a345359d60b24', 'message': 'Add functional regression test for bug 1806064\n\nChange I9269ffa2b80e48db96c622d0dc0817738854f602 in Pike\nintroduced a race condition where creating multiple\nservers concurrently can fail the second instances quota\ncheck which happens in conductor after the instance record\nis created in the cell database but its related BDMs and\ntags are not stored in the cell DB. When deleting the\nserver from the API, since the BDMs are not in the cell\ndatabase with the instance, they are not ""seen"" and thus\nthe volume attachments are not deleted and the volume is\norphaned. As for tags, you should be able to see the tags\non the server in ERROR status from the API before deleting\nit.\n\nThis change adds a functional regression test to show both\nthe volume attachment and tag issue when we fail the quota\ncheck in conductor.\n\nChange-Id: I21c2189cc1de6b8e4857de77acd9f1ef8b6ea9f6\nRelated-Bug: #1806064\n(cherry picked from commit 5d514b33e28964b38aeb42a8dd5b93f3fc8ae239)\n(cherry picked from commit 5b7e904126f68a8c9f5250620393dcdee54336d8)\n(cherry picked from commit 3f37d0bba46fd7f39265863b227c5fd504fa7864)\n'}, {'number': 5, 'created': '2018-12-09 14:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/20c2653ef0da0c781a1f3ce52cf38d32e02627a7', 'message': 'Add functional regression test for bug 1806064\n\nChange I9269ffa2b80e48db96c622d0dc0817738854f602 in Pike\nintroduced a race condition where creating multiple\nservers concurrently can fail the second instances quota\ncheck which happens in conductor after the instance record\nis created in the cell database but its related BDMs and\ntags are not stored in the cell DB. When deleting the\nserver from the API, since the BDMs are not in the cell\ndatabase with the instance, they are not ""seen"" and thus\nthe volume attachments are not deleted and the volume is\norphaned. As for tags, you should be able to see the tags\non the server in ERROR status from the API before deleting\nit.\n\nThis change adds a functional regression test to show both\nthe volume attachment and tag issue when we fail the quota\ncheck in conductor.\n\nChange-Id: I21c2189cc1de6b8e4857de77acd9f1ef8b6ea9f6\nRelated-Bug: #1806064\n(cherry picked from commit 5d514b33e28964b38aeb42a8dd5b93f3fc8ae239)\n(cherry picked from commit 5b7e904126f68a8c9f5250620393dcdee54336d8)\n(cherry picked from commit 3f37d0bba46fd7f39265863b227c5fd504fa7864)\n'}, {'number': 6, 'created': '2018-12-09 15:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a3e7228ffefe43bf684f3dd9ddd9e440370b1e9', 'message': 'Add functional regression test for bug 1806064\n\nChange I9269ffa2b80e48db96c622d0dc0817738854f602 in Pike\nintroduced a race condition where creating multiple\nservers concurrently can fail the second instances quota\ncheck which happens in conductor after the instance record\nis created in the cell database but its related BDMs and\ntags are not stored in the cell DB. When deleting the\nserver from the API, since the BDMs are not in the cell\ndatabase with the instance, they are not ""seen"" and thus\nthe volume attachments are not deleted and the volume is\norphaned. As for tags, you should be able to see the tags\non the server in ERROR status from the API before deleting\nit.\n\nThis change adds a functional regression test to show both\nthe volume attachment and tag issue when we fail the quota\ncheck in conductor.\n\nNOTE(s10): Three changes has been made in this test for Pike:\n1. CONF.glance.api_servers is mandatory in Pike, so\nnova.tests.unit.image.fake.stub_out_image_service has been added.\n2. CinderFixture is being used instead of CinderFixtureNewAttachFlow\nintroduced in Queens.\n3. volume_ids_for_instance() has been added to the CinderFixture.\n\nChange-Id: I21c2189cc1de6b8e4857de77acd9f1ef8b6ea9f6\nRelated-Bug: #1806064\n(cherry picked from commit 5d514b33e28964b38aeb42a8dd5b93f3fc8ae239)\n(cherry picked from commit 5b7e904126f68a8c9f5250620393dcdee54336d8)\n(cherry picked from commit 3f37d0bba46fd7f39265863b227c5fd504fa7864)\n'}, {'number': 7, 'created': '2018-12-09 15:51:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2eaf3a0ecb0a8bf901128bdb0710d91c08da739a', 'message': 'Add functional regression test for bug 1806064\n\nChange I9269ffa2b80e48db96c622d0dc0817738854f602 in Pike\nintroduced a race condition where creating multiple\nservers concurrently can fail the second instances quota\ncheck which happens in conductor after the instance record\nis created in the cell database but its related BDMs and\ntags are not stored in the cell DB. When deleting the\nserver from the API, since the BDMs are not in the cell\ndatabase with the instance, they are not ""seen"" and thus\nthe volume attachments are not deleted and the volume is\norphaned. As for tags, you should be able to see the tags\non the server in ERROR status from the API before deleting\nit.\n\nThis change adds a functional regression test to show both\nthe volume attachment and tag issue when we fail the quota\ncheck in conductor.\n\nNOTE(s10): Three changes has been made in this test for Pike:\n1. CONF.glance.api_servers is mandatory in Pike, so\nnova.tests.unit.image.fake.stub_out_image_service has been added.\n2. CinderFixture is being used instead of CinderFixtureNewAttachFlow\nintroduced in Queens.\n3. volume_ids_for_instance() has been added to the CinderFixture.\n\nChange-Id: I21c2189cc1de6b8e4857de77acd9f1ef8b6ea9f6\nRelated-Bug: #1806064\n(cherry picked from commit 5d514b33e28964b38aeb42a8dd5b93f3fc8ae239)\n(cherry picked from commit 5b7e904126f68a8c9f5250620393dcdee54336d8)\n(cherry picked from commit 3f37d0bba46fd7f39265863b227c5fd504fa7864)\n'}, {'number': 8, 'created': '2018-12-09 17:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a5ed00e358e268c74697c41e045355e8a983fa7', 'message': 'Add functional regression test for bug 1806064\n\nChange I9269ffa2b80e48db96c622d0dc0817738854f602 in Pike\nintroduced a race condition where creating multiple\nservers concurrently can fail the second instances quota\ncheck which happens in conductor after the instance record\nis created in the cell database but its related BDMs and\ntags are not stored in the cell DB. When deleting the\nserver from the API, since the BDMs are not in the cell\ndatabase with the instance, they are not ""seen"" and thus\nthe volume attachments are not deleted and the volume is\norphaned. As for tags, you should be able to see the tags\non the server in ERROR status from the API before deleting\nit.\n\nThis change adds a functional regression test to show both\nthe volume attachment and tag issue when we fail the quota\ncheck in conductor.\n\nNOTE(s10): Three changes has been made in this test for Pike:\n1. CONF.glance.api_servers is mandatory in Pike, so\nnova.tests.unit.image.fake.stub_out_image_service has been added.\n2. CinderFixture is being used instead of CinderFixtureNewAttachFlow\nintroduced in Queens.\n3. In Pike volume will be in \'attaching\' state without attachment\ncreated, so just check for this state without listing attachments.\n\nChange-Id: I21c2189cc1de6b8e4857de77acd9f1ef8b6ea9f6\nRelated-Bug: #1806064\n(cherry picked from commit 5d514b33e28964b38aeb42a8dd5b93f3fc8ae239)\n(cherry picked from commit 5b7e904126f68a8c9f5250620393dcdee54336d8)\n(cherry picked from commit 3f37d0bba46fd7f39265863b227c5fd504fa7864)\n'}, {'number': 9, 'created': '2018-12-11 15:06:05.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1806064.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6b85dafd87a242b3d312f01eadc9e67376349ba4', 'message': 'Add functional regression test for bug 1806064\n\nChange I9269ffa2b80e48db96c622d0dc0817738854f602 in Pike\nintroduced a race condition where creating multiple\nservers concurrently can fail the second instances quota\ncheck which happens in conductor after the instance record\nis created in the cell database but its related BDMs and\ntags are not stored in the cell DB. When deleting the\nserver from the API, since the BDMs are not in the cell\ndatabase with the instance, they are not ""seen"" and thus\nthe volume attachments are not deleted and the volume is\norphaned. As for tags, you should be able to see the tags\non the server in ERROR status from the API before deleting\nit.\n\nThis change adds a functional regression test to show both\nthe volume attachment and tag issue when we fail the quota\ncheck in conductor.\n\nNOTE(s10): Three changes has been made in this test for Pike:\n1. CONF.glance.api_servers is mandatory in Pike, so\nnova.tests.unit.image.fake.stub_out_image_service has been added.\n2. CinderFixture is being used instead of CinderFixtureNewAttachFlow\nintroduced in Queens.\n3. In Pike volume will be in \'attaching\' state without attachment\ncreated, so just check for this state without listing attachments.\n\nChange-Id: I21c2189cc1de6b8e4857de77acd9f1ef8b6ea9f6\nRelated-Bug: #1806064\n(cherry picked from commit 5d514b33e28964b38aeb42a8dd5b93f3fc8ae239)\n(cherry picked from commit 5b7e904126f68a8c9f5250620393dcdee54336d8)\n(cherry picked from commit 3f37d0bba46fd7f39265863b227c5fd504fa7864)\n'}]",1,623935,6b85dafd87a242b3d312f01eadc9e67376349ba4,36,6,9,9373,,,0,"Add functional regression test for bug 1806064

Change I9269ffa2b80e48db96c622d0dc0817738854f602 in Pike
introduced a race condition where creating multiple
servers concurrently can fail the second instances quota
check which happens in conductor after the instance record
is created in the cell database but its related BDMs and
tags are not stored in the cell DB. When deleting the
server from the API, since the BDMs are not in the cell
database with the instance, they are not ""seen"" and thus
the volume attachments are not deleted and the volume is
orphaned. As for tags, you should be able to see the tags
on the server in ERROR status from the API before deleting
it.

This change adds a functional regression test to show both
the volume attachment and tag issue when we fail the quota
check in conductor.

NOTE(s10): Three changes has been made in this test for Pike:
1. CONF.glance.api_servers is mandatory in Pike, so
nova.tests.unit.image.fake.stub_out_image_service has been added.
2. CinderFixture is being used instead of CinderFixtureNewAttachFlow
introduced in Queens.
3. In Pike volume will be in 'attaching' state without attachment
created, so just check for this state without listing attachments.

Change-Id: I21c2189cc1de6b8e4857de77acd9f1ef8b6ea9f6
Related-Bug: #1806064
(cherry picked from commit 5d514b33e28964b38aeb42a8dd5b93f3fc8ae239)
(cherry picked from commit 5b7e904126f68a8c9f5250620393dcdee54336d8)
(cherry picked from commit 3f37d0bba46fd7f39265863b227c5fd504fa7864)
",git fetch https://review.opendev.org/openstack/nova refs/changes/35/623935/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/regressions/test_bug_1806064.py'],1,b76edebabc2f009023934755b77b98fc3a6f5e43,bug/1806064,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova.compute import utils as compute_utils from nova import context as nova_context from nova import exception from nova import objects from nova import test from nova.tests import fixtures as nova_fixtures from nova.tests.functional import integrated_helpers from nova.tests.unit import policy_fixture class BootFromVolumeOverQuotaRaceDeleteTest( test.TestCase, integrated_helpers.InstanceHelperMixin): """"""Test for regression bug 1806064 introduced in Pike. This is very similar to regression bug 1404867 where reserved/attached volumes during a boot from volume request are not detached while deleting a server that failed to schedule. In this case, scheduling is successful but the late quota check in ComputeTaskManager.schedule_and_build_instances fails. In the case of a scheduling failure, the instance record along with the associated BDMs are created in the cell0 database and that is where the ""local delete"" code in the API finds them to detach the related volumes. In the case of the quota fail race, the instance has already been created in a selected cell but the BDMs records have not been and are thus not ""seen"" during the API local delete and the volumes are left attached to a deleted server. An additional issue, covered in the test here, is that tags provided when creating the server are not retrievable from the API after the late quota check fails. """""" def setUp(self): super(BootFromVolumeOverQuotaRaceDeleteTest, self).setUp() # We need the cinder fixture for boot from volume testing. self.cinder_fixture = self.useFixture( nova_fixtures.CinderFixtureNewAttachFlow(self)) # Use the standard fixtures. self.useFixture(policy_fixture.RealPolicyFixture()) self.useFixture(nova_fixtures.NeutronFixture(self)) self.useFixture(nova_fixtures.PlacementFixture()) self.api = self.useFixture(nova_fixtures.OSAPIFixture( api_version='v2.1')).api # Use microversion 2.52 which allows creating a server with tags. self.api.microversion = '2.52' self.start_service('conductor') self.start_service('scheduler') self.start_service('compute') def test_bfv_quota_race_local_delete(self): # Setup a boot-from-volume request where the API will create a # volume attachment record for the given pre-existing volume. # We also tag the server since tags, like BDMs, should be created in # the cell database along with the instance. volume_id = nova_fixtures.CinderFixtureNewAttachFlow.IMAGE_BACKED_VOL server = { 'server': { 'name': 'test_bfv_quota_race_local_delete', 'flavorRef': self.api.get_flavors()[0]['id'], 'imageRef': '', 'block_device_mapping_v2': [{ 'boot_index': 0, 'source_type': 'volume', 'destination_type': 'volume', 'uuid': volume_id }], 'networks': 'auto', 'tags': ['bfv'] } } # Now we need to stub out the quota check routine so that we can # simulate the race where the initial quota check in the API passes # but fails in conductor once the instance has been created in cell1. original_quota_check = compute_utils.check_num_instances_quota def stub_check_num_instances_quota(_self, context, instance_type, min_count, *args, **kwargs): # Determine where we are in the flow based on whether or not the # min_count is 0 (API will pass 1, conductor will pass 0). if min_count == 0: raise exception.TooManyInstances( 'test_bfv_quota_race_local_delete') # We're checking from the API so perform the original quota check. return original_quota_check( _self, context, instance_type, min_count, *args, **kwargs) self.stub_out('nova.compute.utils.check_num_instances_quota', stub_check_num_instances_quota) server = self.api.post_server(server) server = self._wait_for_state_change(self.api, server, 'ERROR') # At this point, the build request should be gone and the instance # should have been created in cell1. context = nova_context.get_admin_context() self.assertRaises(exception.BuildRequestNotFound, objects.BuildRequest.get_by_instance_uuid, context, server['id']) # The default cell in the functional tests is cell1 but we want to # specifically target cell1 to make sure the instance exists there # and we're not just getting lucky somehow due to the fixture. cell1 = self.cell_mappings[test.CELL1_NAME] with nova_context.target_cell(context, cell1) as cctxt: # This would raise InstanceNotFound if the instance isn't in cell1. instance = objects.Instance.get_by_uuid(cctxt, server['id']) self.assertIsNone(instance.host, 'instance.host should not be set') # Make sure we can still view the tags on the server before it is # deleted. # FIXME(mriedem): This is bug 1806064 where the tags are not created # in cell1 along with the instance when the quota check race failure # occurs. Uncomment once fixed. # self.assertEqual(['bfv'], server['tags']) self.assertEqual([], server['tags']) # Now delete the server which, since it does not have a host, will be # deleted ""locally"" from the API. self.api.delete_server(server['id']) self._wait_until_deleted(server) # The volume should have been detached by the API. # FIXME(mriedem): This is bug 1806064 where the volume is not detached # because the related BDM record was not created in cell1 along with # the instance so the API could not ""see"" it. Uncomment once fixed. # self.assertIsNone( # self.cinder_fixture.volume_ids_for_instance(server['id'])) self.assertEqual(volume_id, # volume_ids_for_instance is a generator so listify list(self.cinder_fixture.volume_ids_for_instance( server['id']))[0]) ",,143,0
openstack%2Fnova~stable%2Fpike~If1c901b974bc7295927b3f033a04eaa6ac36f603,openstack/nova,stable/pike,If1c901b974bc7295927b3f033a04eaa6ac36f603,Not set instance to ERROR if set_admin_password failed,MERGED,2018-10-05 08:09:49.000000000,2019-02-22 23:07:27.000000000,2019-02-22 23:07:27.000000000,"[{'_account_id': 4690}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9373}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-10-05 08:09:49.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/58ed9bc606692c140d1cb315e83795b2e73ade9d', 'message': 'Not set instance to ERROR if set_admin_password failed\n\nIn some cases, an instance will be set to ERROR state when\nset_admin_password failed (some Exception like Forbidden)\nthis is inconsistent to other exceptions and also\nset_admin_password is a sync call from API to compute,\nwe can simply return the error to the upper layer (operator or\nuser) to avoid make user run reset to restore instance\nstatus since no changes to guest at all.\n\nChange-Id: If1c901b974bc7295927b3f033a04eaa6ac36f603\nCloses-Bug: 1757061\n(cherry picked from commit 513f2d3d254e2ffcc5c9eb786bc1c7d52036d392)\n'}]",0,608180,58ed9bc606692c140d1cb315e83795b2e73ade9d,14,9,1,9373,,,0,"Not set instance to ERROR if set_admin_password failed

In some cases, an instance will be set to ERROR state when
set_admin_password failed (some Exception like Forbidden)
this is inconsistent to other exceptions and also
set_admin_password is a sync call from API to compute,
we can simply return the error to the upper layer (operator or
user) to avoid make user run reset to restore instance
status since no changes to guest at all.

Change-Id: If1c901b974bc7295927b3f033a04eaa6ac36f603
Closes-Bug: 1757061
(cherry picked from commit 513f2d3d254e2ffcc5c9eb786bc1c7d52036d392)
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/608180/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py']",2,58ed9bc606692c140d1cb315e83795b2e73ade9d,bug/1757061,," self._set_instance_obj_error_state(context, instance)",2,8
openstack%2Frequirements~master~Ifb13fd66101bce2182f1e90dd127af4a46db3db5,openstack/requirements,master,Ifb13fd66101bce2182f1e90dd127af4a46db3db5,Blacklist Yappi 0.98 and 0.99,MERGED,2019-02-21 19:15:29.000000000,2019-02-22 23:05:17.000000000,2019-02-22 23:05:17.000000000,"[{'_account_id': 11628}, {'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 19:15:29.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/cdae5e372c95603f6dce417ff19524d40774f4a2', 'message': 'Blacklist Yappi 0.98 and 0.99\n\nAs a follow on patch to the upper-constraints update[1], this patch\nblacklists Yappi 0.98 and 0.99 as they have a bug[2] that causes it\nto fail to install.\n\n[1] https://review.openstack.org/638177\n[2] https://github.com/sumerc/yappi/commit/ \\\n    778829f6f77928e4292e6a7dd4dfecf501f9a362\n\nChange-Id: Ifb13fd66101bce2182f1e90dd127af4a46db3db5\n'}]",0,638487,cdae5e372c95603f6dce417ff19524d40774f4a2,13,4,1,11628,,,0,"Blacklist Yappi 0.98 and 0.99

As a follow on patch to the upper-constraints update[1], this patch
blacklists Yappi 0.98 and 0.99 as they have a bug[2] that causes it
to fail to install.

[1] https://review.openstack.org/638177
[2] https://github.com/sumerc/yappi/commit/ \
    778829f6f77928e4292e6a7dd4dfecf501f9a362

Change-Id: Ifb13fd66101bce2182f1e90dd127af4a46db3db5
",git fetch https://review.opendev.org/openstack/requirements refs/changes/87/638487/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,cdae5e372c95603f6dce417ff19524d40774f4a2,,"Yappi!=0.98,!=0.99 # MIT",Yappi # MIT,1,1
openstack%2Fkolla~stable%2Fpike~I0f995df45bf203acc79cc7bd52b9ac51577468da,openstack/kolla,stable/pike,I0f995df45bf203acc79cc7bd52b9ac51577468da,Fix py36 gate job,MERGED,2019-02-15 09:46:53.000000000,2019-02-22 21:48:10.000000000,2019-02-22 21:48:09.000000000,"[{'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}]","[{'number': 1, 'created': '2019-02-15 09:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f5f47f35504ebd8d51dbde8316fa19db136b0bea', 'message': 'Fix py36 gate job\n\npython 3.6 pycache also includes links - so those also\nneed to be removed\n\nDepends-On: https://review.openstack.org/636750\nChange-Id: I0f995df45bf203acc79cc7bd52b9ac51577468da\n(cherry picked from commit a490eef0d5e92a0228656870ebff49bcf26f0472)\n'}, {'number': 2, 'created': '2019-02-15 09:47:31.000000000', 'files': ['tests/templates/template_overrides.j2', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/kolla/commit/88261276da1f6216b027915c23aa4d8faaa51e6f', 'message': 'Fix py36 gate job\n\npython 3.6 pycache also includes links - so those also\nneed to be removed\n\nDepends-On: https://review.openstack.org/636929\nChange-Id: I0f995df45bf203acc79cc7bd52b9ac51577468da\n(cherry picked from commit a490eef0d5e92a0228656870ebff49bcf26f0472)\n'}]",0,637160,88261276da1f6216b027915c23aa4d8faaa51e6f,21,5,2,22629,,,0,"Fix py36 gate job

python 3.6 pycache also includes links - so those also
need to be removed

Depends-On: https://review.openstack.org/636929
Change-Id: I0f995df45bf203acc79cc7bd52b9ac51577468da
(cherry picked from commit a490eef0d5e92a0228656870ebff49bcf26f0472)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/60/637160/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/templates/template_overrides.j2', 'tox.ini']",2,f5f47f35504ebd8d51dbde8316fa19db136b0bea,bug/python_gate-stable/pike," find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete -o -type l -name ""*.py[c|o]"" -delete"," find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete find . -type f -name ""*.py[c|o]"" -delete",17,16
openstack%2Fneutron-tempest-plugin~master~I30443e54d8d286ae5fc8d6d998d8b4258a370fa1,openstack/neutron-tempest-plugin,master,I30443e54d8d286ae5fc8d6d998d8b4258a370fa1,Added test_ports suite and a new test,MERGED,2019-02-19 14:17:28.000000000,2019-02-22 21:45:18.000000000,2019-02-22 21:45:18.000000000,"[{'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26899}]","[{'number': 1, 'created': '2019-02-19 14:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/25a006f0302fd23fe047aa63bc824e23c144a6cd', 'message': 'Added test_ports suite and a new test\n\nNew suite added - test_ports.py.\nNew test added - test_previously_used_port.\nThe new test is making sure that a port is re-useable\nafter being released from an older instance.\n\nChange-Id: I30443e54d8d286ae5fc8d6d998d8b4258a370fa1\n'}, {'number': 2, 'created': '2019-02-19 14:18:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/dd9d49054e1595f0fc26f2237748d75ffa936dfb', 'message': 'Added test_ports suite and a new test\n\nNew suite added - test_ports.py.\nNew test added - test_previously_used_port.\nThe new test is making sure that a port is re-useable\nafter being released from an older instance.\n\nChange-Id: I30443e54d8d286ae5fc8d6d998d8b4258a370fa1\n'}, {'number': 3, 'created': '2019-02-19 14:22:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/44050885f462f286698d5eef3d5989c893fdc842', 'message': 'Added test_ports suite and a new test\n\nNew suite added - test_ports.py.\nNew test added - test_previously_used_port.\nThe new test is making sure that a port is re-useable\nafter being released from an older instance.\n\nChange-Id: I30443e54d8d286ae5fc8d6d998d8b4258a370fa1\n'}, {'number': 4, 'created': '2019-02-20 08:45:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/9a9dfc3f9ce94ea265f0b8be618888bb8f6ce47b', 'message': 'Added test_ports suite and a new test\n\nNew suite added - test_ports.py.\nNew test added - test_previously_used_port.\nThe new test is making sure that a port is re-useable\nafter being released from an older instance.\n\nChange-Id: I30443e54d8d286ae5fc8d6d998d8b4258a370fa1\n'}, {'number': 5, 'created': '2019-02-20 08:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/85e33555e26a28f555b8d6cfe13f06b64d1d7840', 'message': 'Added test_ports suite and a new test\n\nNew suite added - test_ports.py.\nNew test added - test_previously_used_port.\nThe new test is making sure that a port is re-useable\nafter being released from an older instance.\n\nChange-Id: I30443e54d8d286ae5fc8d6d998d8b4258a370fa1\n'}, {'number': 6, 'created': '2019-02-20 09:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/bb5e05465c76b3a4a796077c2a6e1e8151098047', 'message': 'Added test_ports suite and a new test\n\nNew suite added - test_ports.py.\nNew test added - test_previously_used_port.\nThe new test is making sure that a port is re-useable\nafter being released from an older instance.\n\nChange-Id: I30443e54d8d286ae5fc8d6d998d8b4258a370fa1\n'}, {'number': 7, 'created': '2019-02-20 12:22:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/29b54b8c89f5a2a8222bf591413df3a0e20f316a', 'message': 'Added test_ports suite and a new test\n\nNew suite added - test_ports.py.\nNew test added - test_previously_used_port.\nThe new test is making sure that a port is re-useable\nafter being released from an older instance.\n\nChange-Id: I30443e54d8d286ae5fc8d6d998d8b4258a370fa1\n'}, {'number': 8, 'created': '2019-02-20 15:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/17162975db6fb25f8f066552f5de7c75a56418d9', 'message': 'Added test_ports suite and a new test\n\nNew suite added - test_ports.py.\nNew test added - test_previously_used_port.\nThe new test is making sure that a port is re-useable\nafter being released from an older instance.\n\nChange-Id: I30443e54d8d286ae5fc8d6d998d8b4258a370fa1\n'}, {'number': 9, 'created': '2019-02-20 18:56:52.000000000', 'files': ['neutron_tempest_plugin/scenario/test_ports.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/f238ed34afd0c255e309794b403b91044c46fd03', 'message': 'Added test_ports suite and a new test\n\nNew suite added - test_ports.py.\nNew test added - test_previously_used_port.\nThe new test is making sure that a port is re-useable\nafter being released from an older instance.\n\nChange-Id: I30443e54d8d286ae5fc8d6d998d8b4258a370fa1\n'}]",10,637854,f238ed34afd0c255e309794b403b91044c46fd03,29,7,9,26899,,,0,"Added test_ports suite and a new test

New suite added - test_ports.py.
New test added - test_previously_used_port.
The new test is making sure that a port is re-useable
after being released from an older instance.

Change-Id: I30443e54d8d286ae5fc8d6d998d8b4258a370fa1
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/54/637854/6 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/scenario/test_ports.py'],1,25a006f0302fd23fe047aa63bc824e23c144a6cd,add-port-test,"# Copyright 2016 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from neutron_lib import constants from tempest.common import waiters from tempest.lib.common.utils import data_utils from tempest.lib import decorators from neutron_tempest_plugin.common import ssh from neutron_tempest_plugin import config from neutron_tempest_plugin.scenario import base from neutron_tempest_plugin.scenario import constants as const CONF = config.CONF class PortsTest(base.BaseTempestTestCase): @classmethod def resource_setup(cls): super(PortsTest, cls).resource_setup() # setup basic topology for servers we can log into it cls.router = cls.create_router_by_client() cls.keypair = cls.create_keypair() cls.secgroup = cls.create_security_group( name=data_utils.rand_name(""test_port_secgroup"")) cls.create_loginable_secgroup_rule( secgroup_id=cls.secgroup['id']) cls.create_pingable_secgroup_rule( secgroup_id=cls.secgroup['id']) cls.network = cls.create_network() cls.subnet = cls.create_subnet(cls.network) cls.create_router_interface(cls.router['id'], cls.subnet['id']) cls.port = cls.create_port(cls.network, name=data_utils.rand_name(""port""), security_groups=[cls.secgroup['id']]) def _create_instance_with_port(self, port): """"""Create instance for port testing :param security_groups (list): list of security groups :param port (object): the port used """""" servers, fips, server_ssh_clients = ([], [], []) server_args = { 'flavor_ref': CONF.compute.flavor_ref, 'image_ref': CONF.compute.image_ref, 'key_name': self.keypair['name'], 'networks': [{'port': port['id']}] } servers.append(self.create_server(**server_args)) waiters.wait_for_server_status( self.os_primary.servers_client, servers[0]['server']['id'], const.SERVER_STATUS_ACTIVE) fips.append(self.create_floatingip(port=port)) server_ssh_clients.append(ssh.Client( fips[0]['floating_ip_address'], CONF.validation.image_ssh_user, pkey=self.keypair['private_key'])) return server_ssh_clients, fips, servers @decorators.idempotent_id('5500797e-b8c2-4e07-a5e0-89fa4e814965') def test_previously_used_port(self): for i in range(2): _, fips, servers = self._create_instance_with_port( self.port) self.check_connectivity(fips[0]['floating_ip_address'], CONF.validation.image_ssh_user, self.keypair['private_key']) self.os_primary.servers_client.delete_server(servers[0]['server']['id']) self._try_delete_resource(self.delete_floatingip, fips[0])",,83,0
openstack%2Frequirements~master~Ibe228a60c02fc8314d2d13f20e7e6db94e7c0932,openstack/requirements,master,Ibe228a60c02fc8314d2d13f20e7e6db94e7c0932,[DNM] test change,ABANDONED,2019-02-11 14:45:11.000000000,2019-02-22 21:35:52.000000000,,"[{'_account_id': 11604}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 14:45:11.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/10ccee255220644b4abf79f753d68637076232d5', 'message': '[DNM] test change\n\nthis change is intended only to allow testing\nwith os-vif 1.13.1 to evaluate if the neuton\nissue the result for delegating vif pulgin to os\nvif instead of libvirt still exisit.\n\nChange-Id: Ibe228a60c02fc8314d2d13f20e7e6db94e7c0932\n'}]",0,636139,10ccee255220644b4abf79f753d68637076232d5,5,3,1,11604,,,0,"[DNM] test change

this change is intended only to allow testing
with os-vif 1.13.1 to evaluate if the neuton
issue the result for delegating vif pulgin to os
vif instead of libvirt still exisit.

Change-Id: Ibe228a60c02fc8314d2d13f20e7e6db94e7c0932
",git fetch https://review.opendev.org/openstack/requirements refs/changes/39/636139/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,10ccee255220644b4abf79f753d68637076232d5,,os-vif===1.13.1,os-vif===1.14.0,1,1
openstack%2Fcharm-openstack-dashboard~stable%2F18.11~Ic63c3508bbc4af1711490e01ceb13a4c5b6c9838,openstack/charm-openstack-dashboard,stable/18.11,Ic63c3508bbc4af1711490e01ceb13a4c5b6c9838,"Revert ""Use correct certificate when ``os-public-hostname`` configration option is set""",MERGED,2019-02-22 16:30:26.000000000,2019-02-22 21:30:55.000000000,2019-02-22 21:30:55.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 16:30:26.000000000', 'files': ['hooks/horizon_hooks.py', 'unit_tests/test_horizon_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/42cdfb5b475062718e71c74cb4aef73b87f597fb', 'message': 'Revert ""Use correct certificate when ``os-public-hostname`` configration option is set""\n\nThis reverts commit d52307da7c164274d53259417909b146ac256d45.\n\nChange-Id: Ic63c3508bbc4af1711490e01ceb13a4c5b6c9838\n'}]",0,638705,42cdfb5b475062718e71c74cb4aef73b87f597fb,7,4,1,13686,,,0,"Revert ""Use correct certificate when ``os-public-hostname`` configration option is set""

This reverts commit d52307da7c164274d53259417909b146ac256d45.

Change-Id: Ic63c3508bbc4af1711490e01ceb13a4c5b6c9838
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/05/638705/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_hooks.py', 'unit_tests/test_horizon_hooks.py']",2,42cdfb5b475062718e71c74cb4aef73b87f597fb,bug/1816621-stable/18.11,," @patch.object(hooks.os, 'symlink') @patch.object(hooks.os, 'remove') @patch.object(hooks.os.path, 'exists') @patch.object(hooks, 'service_reload') @patch.object(hooks, 'process_certificates') def test_certs_changed(self, _process_certificates, _service_reload, _exists, _remove, _symlink): self._call_hook('certificates-relation-changed') _process_certificates.assert_called_with( 'horizon', None, None, custom_hostname_link='dashboard') self.assertFalse(_symlink.called) self.CONFIGS.write_all.assert_called_with() _service_reload.assert_called_with('apache2') self.enable_ssl.assert_called_with() _process_certificates.reset_mock() self.config.side_effect = None self.config.return_value = 'somehostname' _exists.return_value = True self._call_hook('certificates-relation-changed') _process_certificates.assert_called_with('horizon', None, None) _remove.assert_has_calls([ call('/etc/apache2/ssl/horizon/cert_dashboard'), call('/etc/apache2/ssl/horizon/key_dashboard'), ]) _symlink.assert_has_calls([ call('/etc/apache2/ssl/horizon/cert_somehostname', '/etc/apache2/ssl/horizon/cert_dashboard'), call('/etc/apache2/ssl/horizon/key_somehostname', '/etc/apache2/ssl/horizon/key_dashboard'), ])",2,53
openstack%2Fcharm-openstack-dashboard~stable%2F18.11~I924e8f7dc534bcf17ad20bc5ef2149ef9b9a5a1e,openstack/charm-openstack-dashboard,stable/18.11,I924e8f7dc534bcf17ad20bc5ef2149ef9b9a5a1e,"Revert ""Use correct certificate when os-public...""",ABANDONED,2019-02-22 21:18:42.000000000,2019-02-22 21:21:02.000000000,,[],"[{'number': 1, 'created': '2019-02-22 21:18:42.000000000', 'files': ['hooks/horizon_hooks.py', 'unit_tests/test_horizon_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/ce38e21e0c21e458aa6782b471efa69f024527da', 'message': 'Revert ""Use correct certificate when os-public...""\n\nThis reverts commit d52307da7c164274d53259417909b146ac256d45.\n\nChange-Id: I924e8f7dc534bcf17ad20bc5ef2149ef9b9a5a1e\n'}]",0,638766,ce38e21e0c21e458aa6782b471efa69f024527da,2,0,1,20805,,,0,"Revert ""Use correct certificate when os-public...""

This reverts commit d52307da7c164274d53259417909b146ac256d45.

Change-Id: I924e8f7dc534bcf17ad20bc5ef2149ef9b9a5a1e
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/66/638766/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_hooks.py', 'unit_tests/test_horizon_hooks.py']",2,ce38e21e0c21e458aa6782b471efa69f024527da,,," @patch.object(hooks.os, 'symlink') @patch.object(hooks.os, 'remove') @patch.object(hooks.os.path, 'exists') @patch.object(hooks, 'service_reload') @patch.object(hooks, 'process_certificates') def test_certs_changed(self, _process_certificates, _service_reload, _exists, _remove, _symlink): self._call_hook('certificates-relation-changed') _process_certificates.assert_called_with( 'horizon', None, None, custom_hostname_link='dashboard') self.assertFalse(_symlink.called) self.CONFIGS.write_all.assert_called_with() _service_reload.assert_called_with('apache2') self.enable_ssl.assert_called_with() _process_certificates.reset_mock() self.config.side_effect = None self.config.return_value = 'somehostname' _exists.return_value = True self._call_hook('certificates-relation-changed') _process_certificates.assert_called_with('horizon', None, None) _remove.assert_has_calls([ call('/etc/apache2/ssl/horizon/cert_dashboard'), call('/etc/apache2/ssl/horizon/key_dashboard'), ]) _symlink.assert_has_calls([ call('/etc/apache2/ssl/horizon/cert_somehostname', '/etc/apache2/ssl/horizon/cert_dashboard'), call('/etc/apache2/ssl/horizon/key_somehostname', '/etc/apache2/ssl/horizon/key_dashboard'), ])",2,53
openstack%2Fcinder~master~Ica6ba8f2b169b54c30dbfd0e2b5ab1765a3f8a77,openstack/cinder,master,Ica6ba8f2b169b54c30dbfd0e2b5ab1765a3f8a77,Update the HP MSA and Lenovo driver documentation,MERGED,2018-04-11 05:47:21.000000000,2019-02-22 21:12:48.000000000,2018-05-09 01:22:53.000000000,"[{'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 11904}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13628}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 16422}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22165}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24502}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25677}, {'_account_id': 26537}]","[{'number': 1, 'created': '2018-04-11 05:47:21.000000000', 'files': ['doc/source/configuration/block-storage/drivers/lenovo-driver.rst', 'doc/source/configuration/block-storage/drivers/hp-msa-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a795201ef8c6043fa72e36755671f594c77435b8', 'message': 'Update the HP MSA and Lenovo driver documentation\n\nUpdated the list of supported models for the HP MSA driver.\nImproved the description of the driver-specific options for the\nLenovo and HP MSA drivers.\n\nChange-Id: Ica6ba8f2b169b54c30dbfd0e2b5ab1765a3f8a77\n'}]",0,560266,a795201ef8c6043fa72e36755671f594c77435b8,37,28,1,17042,,,0,"Update the HP MSA and Lenovo driver documentation

Updated the list of supported models for the HP MSA driver.
Improved the description of the driver-specific options for the
Lenovo and HP MSA drivers.

Change-Id: Ica6ba8f2b169b54c30dbfd0e2b5ab1765a3f8a77
",git fetch https://review.opendev.org/openstack/cinder refs/changes/66/560266/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/configuration/block-storage/drivers/lenovo-driver.rst', 'doc/source/configuration/block-storage/drivers/hp-msa-driver.rst']",2,a795201ef8c6043fa72e36755671f594c77435b8,hpmsa-doc-update,"The ``HPMSAFCDriver`` and ``HPMSAISCSIDriver`` Cinder drivers allow the HPE MSA 2050, 1050, 2040, and 1040 arrays to be used for Block Storage in OpenStack deployments.- HPE MSA 2050, 1050, 2040 or 1040 array with: * The rest of the options will be repeated for each storage pool in a given array: ``volume_driver`` specifies the Cinder driver name; ``san_ip`` specifies the IP addresses or host names of the array's management controllers; ``san_login`` and ``san_password`` specify the username and password of an array user account with ``manage`` privileges; and ``hpmsa_iscsi_ips`` specfies the iSCSI IP addresses for the array if using the iSCSI transport protocol. san_ip = 10.1.2.3,10.1.2.4 san_ip = 10.1.2.3,10.1.2.4 san_ip = 10.1.2.3,10.1.2.4 san_ip = 10.1.2.3,10.1.2.4",The ``HPMSAFCDriver`` and ``HPMSAISCSIDriver`` Cinder drivers allow HP MSA 2040 or 1040 arrays to be used for Block Storage in OpenStack deployments.- HP MSA 2040 or 1040 array with: * The rest of the options will be repeated for each storage pool in a given array: the appropriate Cinder driver name; IP address or host name of the array management interface; the username and password of an array user account with ``manage`` privileges; and the iSCSI IP addresses for the array if using the iSCSI transport protocol. san_ip = 10.1.2.3 san_ip = 10.1.2.3 san_ip = 10.1.2.3 san_ip = 10.1.2.3,20,15
openstack%2Fcinder~stable%2Fpike~I93b8afeddae18d098fe926a3219811cc8c8d9b63,openstack/cinder,stable/pike,I93b8afeddae18d098fe926a3219811cc8c8d9b63,Handle rbd.OSError on broken RBD image,MERGED,2018-12-18 17:14:25.000000000,2019-02-22 20:57:10.000000000,2019-01-13 17:56:25.000000000,"[{'_account_id': 1736}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 15670}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21976}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 22595}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28619}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-12-18 17:14:25.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/tests/unit/volume/drivers/test_rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5e4d7e5e986f7a7076632f1cef2c8195fdcc0824', 'message': 'Handle rbd.OSError on broken RBD image\n\nWith Rocky, cinder-volume began to fail again with another error type.\nThis patch adds rbd.OSError type for exception block of\n_get_usage_info method.\n\nChange-Id: I93b8afeddae18d098fe926a3219811cc8c8d9b63\nCloses-Bug: 1698786\n(cherry picked from commit 9e8c45892205e54313cd414a3102aea5b5b199f4)\n(cherry picked from commit 71c99a85a0cc9ad4217428b316a13d3aa19ce1eb)\n(cherry picked from commit 3e174a0c4b574b3f53b5683852756b95c9a112fc)\n'}]",0,625965,5e4d7e5e986f7a7076632f1cef2c8195fdcc0824,24,20,1,6593,,,0,"Handle rbd.OSError on broken RBD image

With Rocky, cinder-volume began to fail again with another error type.
This patch adds rbd.OSError type for exception block of
_get_usage_info method.

Change-Id: I93b8afeddae18d098fe926a3219811cc8c8d9b63
Closes-Bug: 1698786
(cherry picked from commit 9e8c45892205e54313cd414a3102aea5b5b199f4)
(cherry picked from commit 71c99a85a0cc9ad4217428b316a13d3aa19ce1eb)
(cherry picked from commit 3e174a0c4b574b3f53b5683852756b95c9a112fc)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/65/625965/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/rbd.py', 'cinder/tests/unit/volume/drivers/test_rbd.py']",2,5e4d7e5e986f7a7076632f1cef2c8195fdcc0824,bug/1698786,"class MockOSErrorException(MockException): """"""Used as mock for rbd.OSError."""""" volumes = [ 'volume-1', 'non-existent', 'non-existent', 'non-cinder-volume' ] ImageNotFound=MockImageNotFoundException, OSError=MockOSErrorException): self.driver.rbd.OSError,"," volumes = ['volume-1', 'non-existent', 'non-cinder-volume'] ImageNotFound=MockImageNotFoundException):",14,3
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I65f46056f8a908c60c99d1cee3738344a0bce6b7,openstack/tripleo-heat-templates,stable/queens,I65f46056f8a908c60c99d1cee3738344a0bce6b7,Handle upper and lower case system uuids,MERGED,2019-02-21 19:29:29.000000000,2019-02-22 20:47:03.000000000,2019-02-22 20:47:03.000000000,"[{'_account_id': 3153}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-21 19:29:29.000000000', 'files': ['firstboot/os-net-config-mappings.yaml', 'puppet/extraconfig/pre_deploy/per_node.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b87f6a257c6c8c46081d9cdcc63f921e7e1f43c2', 'message': 'Handle upper and lower case system uuids\n\nWe need to be able to handle when system uuids are upper or lower case\nbecause newer versions of dmidecode have normalized to lower case. Users\nwho were on CentOS/RHEL 7.5 and older may have per-node customizations\nwith upper case which turn lowercase with an update to 7.6. This affects\nhieradata customizations as well as os-net-config mapping files. This\nchange outputs both an upper and lowercase hieradata uuid file to handle\nthe both versions of the UUID. Additionally this change normalizes the\nid comparison for os-net-config mappings to lower case.\n\nConflicts:\n\tpuppet/extraconfig/pre_deploy/per_node.yaml\n\nChange-Id: I65f46056f8a908c60c99d1cee3738344a0bce6b7\nCloses-Bug: #1816652\n(cherry picked from commit e2a8a494c5abf64ac5ed16e7f2b20edd4535c2d4)\n'}]",0,638494,b87f6a257c6c8c46081d9cdcc63f921e7e1f43c2,8,4,1,14985,,,0,"Handle upper and lower case system uuids

We need to be able to handle when system uuids are upper or lower case
because newer versions of dmidecode have normalized to lower case. Users
who were on CentOS/RHEL 7.5 and older may have per-node customizations
with upper case which turn lowercase with an update to 7.6. This affects
hieradata customizations as well as os-net-config mapping files. This
change outputs both an upper and lowercase hieradata uuid file to handle
the both versions of the UUID. Additionally this change normalizes the
id comparison for os-net-config mappings to lower case.

Conflicts:
	puppet/extraconfig/pre_deploy/per_node.yaml

Change-Id: I65f46056f8a908c60c99d1cee3738344a0bce6b7
Closes-Bug: #1816652
(cherry picked from commit e2a8a494c5abf64ac5ed16e7f2b20edd4535c2d4)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/94/638494/1 && git format-patch -1 --stdout FETCH_HEAD,"['firstboot/os-net-config-mappings.yaml', 'puppet/extraconfig/pre_deploy/per_node.yaml']",2,b87f6a257c6c8c46081d9cdcc63f921e7e1f43c2,bug/1816652," node_id=$(dmidecode --s system-uuid | awk 'match($0, \ /[0-9A-Fa-f]{8}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{12}/) \ { print substr($0, RSTART, RLENGTH) }' | tr '[:upper:]' '[:lower:]') # thanks to dmidecode 3.1, we have to handle both the upper case # and lower case versions of the UUID from dmidecode. LP#1816652 # upper for dmidecode < 3.1 and lower for dmidecode >= 3.1 node_id_upper=$(echo $node_id | tr '[:lower:]' '[:upper:]') # handle upper case node id LP#1816652 echo $node_lookup | $(get_python) -c "" import json import sys input = sys.stdin.readline() or '{}' cnt = json.loads(input) print json.dumps(cnt.get('${node_id_upper}', {})) "" > /etc/puppet/hieradata/${node_id_upper}.json", node_id=$(dmidecode --s system-uuid | tr '[:upper:]' '[:lower:]'),18,3
openstack%2Fkeystoneauth~master~I0c192b96f01844d4ebce49dc1efc76c193afa6d2,openstack/keystoneauth,master,I0c192b96f01844d4ebce49dc1efc76c193afa6d2,Remove shade jobs,MERGED,2019-02-22 16:28:32.000000000,2019-02-22 20:30:34.000000000,2019-02-22 20:30:34.000000000,"[{'_account_id': 2903}, {'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 16:28:32.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/26b41b2e829df715d8d756f853fc248ee0d4db27', 'message': ""Remove shade jobs\n\nWe're co-gating with openstacksdk, also doing so with shade is a\nbit excessive.\n\nChange-Id: I0c192b96f01844d4ebce49dc1efc76c193afa6d2\n""}]",0,638704,26b41b2e829df715d8d756f853fc248ee0d4db27,7,3,1,2,,,0,"Remove shade jobs

We're co-gating with openstacksdk, also doing so with shade is a
bit excessive.

Change-Id: I0c192b96f01844d4ebce49dc1efc76c193afa6d2
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/04/638704/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,26b41b2e829df715d8d756f853fc248ee0d4db27,,, - shade-functional-tips - shade-tox-tips,0,2
openstack%2Fcinder~master~Ic333973bad33de0443e0e21677768204cc82a706,openstack/cinder,master,Ic333973bad33de0443e0e21677768204cc82a706,Remove 'ploop' from rootwrap,NEW,2019-02-19 14:50:03.000000000,2019-02-22 20:27:19.000000000,,"[{'_account_id': 24}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 16897}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29637}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-02-19 14:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a2a7343c72556da306a4b8322ed9ecdbe3c0107f', 'message': ""Remove 'ploop' from rootwrap\n\nUse olso.privsep instead of rootwrap.\n\nChange-Id: Ic333973bad33de0443e0e21677768204cc82a706\nSigned-off-by: Charles Short <chucks@redhat.com>\n""}, {'number': 2, 'created': '2019-02-19 19:15:19.000000000', 'files': ['etc/cinder/rootwrap.d/volume.filters', 'cinder/tests/unit/backup/drivers/test_backup_tsm.py', 'cinder/privsep/vzstorage.py', 'cinder/tests/unit/volume/drivers/test_vzstorage.py', 'cinder/volume/drivers/vzstorage.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fca06c39236bb00918168f64a37aeb6fcc7e35b8', 'message': ""Remove 'ploop' from rootwrap\n\nUse olso.privsep instead of rootwrap.\n\nChange-Id: Ic333973bad33de0443e0e21677768204cc82a706\nSigned-off-by: Charles Short <chucks@redhat.com>\n""}]",0,637864,fca06c39236bb00918168f64a37aeb6fcc7e35b8,50,27,2,24,,,0,"Remove 'ploop' from rootwrap

Use olso.privsep instead of rootwrap.

Change-Id: Ic333973bad33de0443e0e21677768204cc82a706
Signed-off-by: Charles Short <chucks@redhat.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/64/637864/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/rootwrap.d/volume.filters', 'cinder/tests/unit/backup/drivers/test_backup_tsm.py', 'cinder/privsep/vzstorage.py', 'cinder/tests/unit/volume/drivers/test_vzstorage.py', 'cinder/volume/drivers/vzstorage.py']",5,a2a7343c72556da306a4b8322ed9ecdbe3c0107f,,"import cinder.privsep.vzstorage out, err = cinder.privsep.vzstorage.mount( self.dd_path, self.snaphot_id, self.read_only) cinder.privsep.vzstorage.umount(self.dd_path) return (volume_format or self.configuration.vzstorage_default_volume_format) cinder.privsep.vzstorage.create_ploop( volume_size, os.path.join(volume_path, PLOOP_BASE_DELTA_NAME)) cinder.privsep.vzstorage.ploop_resize(size_gb, volume_path) cinder.privsep.vzstorage.recreate_ploop_desc(image_dir, image_file) cinder.privsep.vzstorage.create_snapshot( snapshot.id, self._get_desc_path(snapshot.volume)) cinder.privsep.vzstorage.delete_snapshot( snapshot.id, self._get_desc_path(snapshot.volume))"," cmd = ['ploop', 'mount', self.dd_path] if self.snapshot_id: cmd.append('-u') cmd.append(self.snapshot_id) if self.read_only: cmd.append('-r') out, err = self.execute(*cmd, run_as_root=True) self.execute('ploop', 'umount', self.dd_path, run_as_root=True) return (volume_format or self.configuration.vzstorage_default_volume_format) self._execute('ploop', 'init', '-s', '%sG' % volume_size, os.path.join(volume_path, PLOOP_BASE_DELTA_NAME), run_as_root=True) self._execute('ploop', 'resize', '-s', '%dG' % size_gb, os.path.join(volume_path, 'DiskDescriptor.xml'), run_as_root=True) self._execute('ploop', 'restore-descriptor', image_dir, image_file) self._execute('ploop', 'snapshot', '-u', '{%s}' % snapshot.id, self._get_desc_path(snapshot.volume), run_as_root=True) self._execute('ploop', 'snapshot-delete', '-u', '{%s}' % snapshot.id, self._get_desc_path(snapshot.volume), run_as_root=True)",102,40
openstack%2Fopenstack-ansible~master~I26f8c9792b6ff1f85b923bcdc4737ac59373ad17,openstack/openstack-ansible,master,I26f8c9792b6ff1f85b923bcdc4737ac59373ad17,add links to readme for release announce script,MERGED,2019-02-22 18:24:13.000000000,2019-02-22 20:25:38.000000000,2019-02-22 20:25:38.000000000,"[{'_account_id': 1004}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-22 18:24:13.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cd45e710d97753562257819db80d318e8a3707de', 'message': 'add links to readme for release announce script\n\nThe release announcement script expects to find links in this format\nin order to include them in emails when announcing new releases.\n\nChange-Id: I26f8c9792b6ff1f85b923bcdc4737ac59373ad17\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,638738,cd45e710d97753562257819db80d318e8a3707de,8,4,1,2472,,,0,"add links to readme for release announce script

The release announcement script expects to find links in this format
in order to include them in emails when announcing new releases.

Change-Id: I26f8c9792b6ff1f85b923bcdc4737ac59373ad17
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/38/638738/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,cd45e710d97753562257819db80d318e8a3707de,readme-links," Resources ######### * License: Apache License, Version 2.0 * Documentation: https://docs.openstack.org/openstack-ansible/latest/ * Source: https://git.openstack.org/cgit/openstack/openstack-ansible * Bugs: https://bugs.launchpad.net/openstack-ansible * Release notes: https://docs.openstack.org/releasenotes/openstack-ansible/",,9,0
openstack%2Foslo.messaging~stable%2Frocky~I3a49e7397df9cd0b2d7eba5747795c3d771dcbea,openstack/oslo.messaging,stable/rocky,I3a49e7397df9cd0b2d7eba5747795c3d771dcbea,Mark telemetry tests nv and remove from gate,MERGED,2019-02-22 14:00:37.000000000,2019-02-22 20:07:33.000000000,2019-02-22 20:07:33.000000000,"[{'_account_id': 6928}, {'_account_id': 8770}, {'_account_id': 20523}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 14:00:37.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/82f9d3063415cd430a56aea1767a782e4b42f563', 'message': 'Mark telemetry tests nv and remove from gate\n\nChange-Id: I3a49e7397df9cd0b2d7eba5747795c3d771dcbea\n(cherry picked from commit f8d0dcf04cef1289234f0bab2b3e35f5fb0e2400)\n'}]",0,638663,82f9d3063415cd430a56aea1767a782e4b42f563,8,4,1,8770,,,0,"Mark telemetry tests nv and remove from gate

Change-Id: I3a49e7397df9cd0b2d7eba5747795c3d771dcbea
(cherry picked from commit f8d0dcf04cef1289234f0bab2b3e35f5fb0e2400)
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/63/638663/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,82f9d3063415cd430a56aea1767a782e4b42f563,telemetry-nv, - oslo.messaging-telemetry-dsvm-integration-rabbit: voting: false, - oslo.messaging-telemetry-dsvm-integration-rabbit - oslo.messaging-telemetry-dsvm-integration-rabbit,2,2
openstack%2Frequirements~master~I0a41c91b935d283ff7ceaa0b4cad13af4333153e,openstack/requirements,master,I0a41c91b935d283ff7ceaa0b4cad13af4333153e,DNM testing jsonschema 3.0.0 pre-release,ABANDONED,2019-01-21 13:53:30.000000000,2019-02-22 20:01:39.000000000,,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-21 13:53:30.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/46ae57c2bb5a99d8c99080ef15b28869c9d2336e', 'message': 'DNM testing jsonschema 3.0.0 pre-release\n\nfor Fedora Rawhide https://bugzilla.redhat.com/show_bug.cgi?id=1605736\n\nChange-Id: I0a41c91b935d283ff7ceaa0b4cad13af4333153e\n'}]",0,632093,46ae57c2bb5a99d8c99080ef15b28869c9d2336e,5,2,1,1955,,,0,"DNM testing jsonschema 3.0.0 pre-release

for Fedora Rawhide https://bugzilla.redhat.com/show_bug.cgi?id=1605736

Change-Id: I0a41c91b935d283ff7ceaa0b4cad13af4333153e
",git fetch https://review.opendev.org/openstack/requirements refs/changes/93/632093/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,46ae57c2bb5a99d8c99080ef15b28869c9d2336e,jsonschema3,jsonschema===3.0.0a5,jsonschema===2.6.0,2,2
openstack%2Fvitrage-tempest-plugin~master~Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57,openstack/vitrage-tempest-plugin,master,Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57,Use Tempest config,MERGED,2018-12-21 22:26:48.000000000,2019-02-22 19:37:04.000000000,2019-02-20 09:04:54.000000000,"[{'_account_id': 1736}, {'_account_id': 19134}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-21 22:26:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/0c552317ae3a721e463682543a559e441c1e026d', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 2, 'created': '2018-12-21 23:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/4892fcf4a3bf3dbacdd37a86f78601911f4c842e', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 3, 'created': '2018-12-22 06:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/f0ab016eb13f6694dff1061ed67b1c1ef99469c3', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 4, 'created': '2018-12-24 14:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/9e4b5db4b02a109175c9690bfa60ed8c37e2c7ef', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 5, 'created': '2019-02-17 18:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/c8837ca6af6e0a8e7c1fcbe871976e8954f50f13', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 6, 'created': '2019-02-17 18:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/6119197482b1017eeb5573438bedd13d6a4b00b5', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 7, 'created': '2019-02-17 18:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/6f7d8d915d4b86fb5771b0cf573e1a9083667ce5', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 8, 'created': '2019-02-17 18:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/b0950f4c57add6183dbd85acced639632558b71c', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 9, 'created': '2019-02-17 19:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/4d50ec62da3090f0d1d7a003a3e97e897913a4f6', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 10, 'created': '2019-02-17 20:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/556625bdf83097db376e2a6b94ee173477368476', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 11, 'created': '2019-02-17 21:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/c014aa36c824c2d7d2d140680ba1752bc6f4cbeb', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 12, 'created': '2019-02-17 22:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/cb7ea0a9e31fbda0d1dce3bc26d68912e801f60d', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 13, 'created': '2019-02-17 23:30:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/75210d74d0df475dad1e0af60f02921df5644867', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 14, 'created': '2019-02-18 14:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/b4084d3127edcb45a97934b4baa5fc4e4d0d20dd', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}, {'number': 15, 'created': '2019-02-19 10:47:42.000000000', 'files': ['devstack/post_test_hook.sh', 'vitrage_tempest_plugin/config.py', 'vitrage_tempest_plugin/plugin.py', 'vitrage_tempest_plugin/tests/resources/mock_datasource/test_3rd_degree_scenarios.py'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/a3771ed1218748e5ba902e174505cc53cab2756b', 'message': 'Use Tempest config\n\nTempest plugins should use tempest config only. This patch changes code\nto read params from tempest config instead of vitrage.\n\nOpenStack clients related code will be fixed in separate patch in scope of\ntask #27631.\n\nChange-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57\nStory: #2004053\nTask: #28634\n'}]",3,627016,a3771ed1218748e5ba902e174505cc53cab2756b,45,4,15,1736,,,0,"Use Tempest config

Tempest plugins should use tempest config only. This patch changes code
to read params from tempest config instead of vitrage.

OpenStack clients related code will be fixed in separate patch in scope of
task #27631.

Change-Id: Iaf91a84cbf7667e443ef21f7ed5ee0036afdba57
Story: #2004053
Task: #28634
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/16/627016/5 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage_tempest_plugin/config.py', 'vitrage_tempest_plugin/plugin.py', 'vitrage_tempest_plugin/tests/resources/mock_datasource/test_3rd_degree_scenarios.py']",3,0c552317ae3a721e463682543a559e441c1e026d,datsource-constants,"from tempest import config CONF = config.CONF time.sleep(4 * CONF.root_cause_analysis_service.snapshots_interval) time.sleep(CONF.root_cause_analysis_service.snapshots_interval) CONF.root_cause_analysis_service.instances_per_host, CONF.root_cause_analysis_service.instances_per_host,"," time.sleep(4 * self.conf.datasources.snapshots_interval) time.sleep(self.conf.datasources.snapshots_interval) self.conf.mock_graph_datasource.instances_per_host, self.conf.mock_graph_datasource.instances_per_host,",27,11
openstack%2Ftripleo-heat-templates~master~Ie6b9e3863abc9d2e2f11440d3cc30a78aaeccad0,openstack/tripleo-heat-templates,master,Ie6b9e3863abc9d2e2f11440d3cc30a78aaeccad0,Change vxlan to geneve for network environment files,MERGED,2019-02-20 20:29:34.000000000,2019-02-22 19:22:09.000000000,2019-02-22 19:22:09.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 10873}, {'_account_id': 11082}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-02-20 20:29:34.000000000', 'files': ['environments/network-environment-v6.j2.yaml', 'environments/network-environment-v6-all.j2.yaml', 'environments/network-environment.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ce0b8929103aa4983e89ccc607c212062b0eee3a', 'message': 'Change vxlan to geneve for network environment files\n\nThe network environment files were still using vxlan as a network type\nwhich is not compatible with OVN deployments.\n\nCloses-Bug: #1816847\nChange-Id: Ie6b9e3863abc9d2e2f11440d3cc30a78aaeccad0\n'}]",0,638253,ce0b8929103aa4983e89ccc607c212062b0eee3a,19,8,1,6681,,,0,"Change vxlan to geneve for network environment files

The network environment files were still using vxlan as a network type
which is not compatible with OVN deployments.

Closes-Bug: #1816847
Change-Id: Ie6b9e3863abc9d2e2f11440d3cc30a78aaeccad0
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/53/638253/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/network-environment-v6.j2.yaml', 'environments/network-environment-v6-all.j2.yaml', 'environments/network-environment.j2.yaml']",3,ce0b8929103aa4983e89ccc607c212062b0eee3a,bug/1816847," NeutronNetworkType: 'geneve,vlan'"," NeutronNetworkType: 'vxlan,vlan' # The tunnel type for the tenant network (vxlan or gre). Set to '' to disable tunneling. NeutronTunnelTypes: 'vxlan'",4,10
openstack%2Fopenstack-ansible-tests~master~Ib8eb3c893f32472f7b99bdb287d2ab6b6d7f1452,openstack/openstack-ansible-tests,master,Ib8eb3c893f32472f7b99bdb287d2ab6b6d7f1452,Set opensuse jobs to non-voting,MERGED,2019-02-22 15:58:29.000000000,2019-02-22 19:14:37.000000000,2019-02-22 19:14:37.000000000,"[{'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 15993}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 15:58:29.000000000', 'files': ['zuul.d/project-templates.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/657dbf8492f023b045e1fefc9a6fde0d3b147409', 'message': 'Set opensuse jobs to non-voting\n\nThere is an ongoing issue with the repositories we use to gate opensuse.\nTo resolve this issue and to unblock our gates, this change sets the\nopensuse jobs to non-voting. This change should be reverted as soon as\nthe repo issues are resolved.\n\nChange-Id: Ib8eb3c893f32472f7b99bdb287d2ab6b6d7f1452\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n'}]",0,638697,657dbf8492f023b045e1fefc9a6fde0d3b147409,11,4,1,7353,,,0,"Set opensuse jobs to non-voting

There is an ongoing issue with the repositories we use to gate opensuse.
To resolve this issue and to unblock our gates, this change sets the
opensuse jobs to non-voting. This change should be reverted as soon as
the repo issues are resolved.

Change-Id: Ib8eb3c893f32472f7b99bdb287d2ab6b6d7f1452
Signed-off-by: cloudnull <kevin@cloudnull.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/97/638697/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project-templates.yaml', 'zuul.d/jobs.yaml']",2,657dbf8492f023b045e1fefc9a6fde0d3b147409,, voting: false voting: false voting: false voting: false voting: false voting: false,,10,3
openstack%2Fironic~master~Ia7b9b5bc485a66215def4a76c6682c47342b86d9,openstack/ironic,master,Ia7b9b5bc485a66215def4a76c6682c47342b86d9,Allocation API: taking over allocations of offline conductors,MERGED,2019-02-19 15:53:44.000000000,2019-02-22 19:10:16.000000000,2019-02-22 19:10:15.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 14629}, {'_account_id': 18320}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 24828}, {'_account_id': 28429}]","[{'number': 1, 'created': '2019-02-19 15:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5ac17cc7122588b6d3636e631b1b000b6982ac8f', 'message': '[WIP] Allocation API: taking over allocations of offline conductors\n\nThis change allows conductors to periodically check and take over\nallocations that were processed by conductors that went offline.\n\nChange-Id: Ia7b9b5bc485a66215def4a76c6682c47342b86d9\nStory: #2004341\nTask: #28474\n'}, {'number': 2, 'created': '2019-02-19 16:37:37.000000000', 'files': ['ironic/tests/unit/db/test_allocations.py', 'ironic/conf/conductor.py', 'ironic/conductor/manager.py', 'ironic/tests/unit/db/test_conductor.py', 'ironic/db/sqlalchemy/api.py', 'ironic/tests/unit/conductor/test_allocations.py', 'ironic/db/api.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/6885c674cbee3454e8cc89ce28af69b55d06d70c', 'message': 'Allocation API: taking over allocations of offline conductors\n\nThis change allows conductors to periodically check and take over\nallocations that were processed by conductors that went offline.\n\nChange-Id: Ia7b9b5bc485a66215def4a76c6682c47342b86d9\nStory: #2004341\nTask: #28474\n'}]",4,637918,6885c674cbee3454e8cc89ce28af69b55d06d70c,29,9,2,10239,,,0,"Allocation API: taking over allocations of offline conductors

This change allows conductors to periodically check and take over
allocations that were processed by conductors that went offline.

Change-Id: Ia7b9b5bc485a66215def4a76c6682c47342b86d9
Story: #2004341
Task: #28474
",git fetch https://review.opendev.org/openstack/ironic refs/changes/18/637918/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/db/test_allocations.py', 'ironic/conf/conductor.py', 'ironic/conductor/manager.py', 'ironic/tests/unit/db/test_conductor.py', 'ironic/db/sqlalchemy/api.py', 'ironic/db/api.py']",6,5ac17cc7122588b6d3636e631b1b000b6982ac8f,story/2004341," def get_offline_conductors(self, field='hostname'): """"""Get a list conductors that are offline (dead). :param field: A field to return, hostname by default. :returns: A list of requested fields of offline conductors. def take_over_allocation(self, allocation_id, old_conductor_id, new_conductor_id): """"""Do a take over for an allocation. The allocation is only updated if the old conductor matches the provided value, thus guarding against races. :param allocation_id: Allocation ID :param old_conductor_id: The conductor ID we expect to be the current ``conductor_affinity`` of the allocation. :param new_conductor_id: The conductor ID of the new ``conductor_affinity``. :returns: True if the take over was successful, False otherwise. :raises: AllocationNotFound """""" @abc.abstractmethod"," def get_offline_conductors(self): """"""Get a list conductor hostnames that are offline (dead). :returns: A list of conductor hostnames.",119,5
openstack%2Fshade~master~Ied27fa1e834d145246815afcb67c59d48669ffb2,openstack/shade,master,Ied27fa1e834d145246815afcb67c59d48669ffb2,Fix dogpile.cache 0.7.0 interaction,MERGED,2019-02-22 16:31:48.000000000,2019-02-22 19:03:28.000000000,2019-02-22 19:03:28.000000000,"[{'_account_id': 2903}, {'_account_id': 3099}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-02-22 16:31:48.000000000', 'files': ['shade/_utils.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/b23000c66017e49615a3226fd7d8682a408aa444', 'message': 'Fix dogpile.cache 0.7.0 interaction\n\nDue to the change in behavior in dogpile.cache > 0.7.0 where bound\nmethods can no longer be passed to the cache_on_arguments decorator,\nopenstackSDK now explicitly provides a non-method wrapper for all\nelements passed to cache_on_arguments. This is handled via an explicit\nno-op decorator. functools.wraps is used to preserve data from the\noriginal method.\n\nNeeded-By: https://review.openstack.org/#/c/624993\nChange-Id: Ied27fa1e834d145246815afcb67c59d48669ffb2\nStory: 2004605\nTask: 28502\n'}]",0,638708,b23000c66017e49615a3226fd7d8682a408aa444,9,5,1,2,,,0,"Fix dogpile.cache 0.7.0 interaction

Due to the change in behavior in dogpile.cache > 0.7.0 where bound
methods can no longer be passed to the cache_on_arguments decorator,
openstackSDK now explicitly provides a non-method wrapper for all
elements passed to cache_on_arguments. This is handled via an explicit
no-op decorator. functools.wraps is used to preserve data from the
original method.

Needed-By: https://review.openstack.org/#/c/624993
Change-Id: Ied27fa1e834d145246815afcb67c59d48669ffb2
Story: 2004605
Task: 28502
",git fetch https://review.opendev.org/openstack/shade refs/changes/08/638708/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/_utils.py'],1,b23000c66017e49615a3226fd7d8682a408aa444,,"import functoolsdef _func_wrap(f): # NOTE(morgan): This extra wrapper is intended to eliminate ever # passing a bound method to dogpile.cache's cache_on_arguments. In # 0.7.0 and later it is impossible to pass bound methods to the # decorator. This was introduced when utilizing the decorate module in # lieu of a direct wrap implementation. @functools.wraps(f) def inner(*args, **kwargs): return f(*args, **kwargs) return inner _func_wrap(func.__get__(obj, type(obj))))"," func.__get__(obj, type(obj)))",14,1
openstack%2Fkolla~master~Ic5caa8cf0271b21f71f03fd33c35b3c7bc93ccf4,openstack/kolla,master,Ic5caa8cf0271b21f71f03fd33c35b3c7bc93ccf4,Use overlay2 in tools/setup_Redhat.sh,MERGED,2019-02-20 20:13:44.000000000,2019-02-22 18:51:27.000000000,2019-02-22 14:21:39.000000000,"[{'_account_id': 13039}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2019-02-20 20:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7a8ba10f0cbf46f5e26d22a4fd83a5492e6e52b7', 'message': '[WIP]: Change Docker Storage driver to overlay2 in tools/setup_Redhat.sh\n\nCurrently CentOS gates use btrfs storage driver and\ncreate /docker device backing btrfs.\n\nThis patch is to sync the gate run with Ubuntu.\n(post-Trusty) does not use btrfs, only overlay2.\n\nChange-Id: Ic5caa8cf0271b21f71f03fd33c35b3c7bc93ccf4\n'}, {'number': 2, 'created': '2019-02-20 20:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9ab9941af4282af839a9204fb977467fc73f7b68', 'message': '[WIP]: Docker overlay2 in tools/setup_Redhat.sh\n\nCurrently CentOS gates use btrfs storage driver and\ncreate /docker device backing btrfs.\n\nThis patch is to sync the gate run with Ubuntu.\n(post-Trusty) does not use btrfs, only overlay2.\n\nChange-Id: Ic5caa8cf0271b21f71f03fd33c35b3c7bc93ccf4\n'}, {'number': 3, 'created': '2019-02-20 20:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/35c003bb7eac2a7386dcbf745e1bdebd587c6cba', 'message': '[WIP]: Docker overlay2 in tools/setup_Redhat.sh\n\nCurrently CentOS gates use btrfs storage driver and\ncreate /docker device backing btrfs.\n\nThis patch is to sync the gate run with Ubuntu.\n(post-Trusty) does not use btrfs, only overlay2.\n\nChange-Id: Ic5caa8cf0271b21f71f03fd33c35b3c7bc93ccf4\n'}, {'number': 4, 'created': '2019-02-21 07:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/60b7ed2d66b048d26d8e16bf0b09cb5cb4143a2b', 'message': '[WIP]: Use overlay2 in tools/setup_Redhat.sh\n\nCurrently CentOS gates use btrfs storage driver and\ncreate /docker device backing btrfs.\n\nThis patch is to sync the gate run with Ubuntu.\n(post-Trusty) does not use btrfs, only overlay2.\n\nChange-Id: Ic5caa8cf0271b21f71f03fd33c35b3c7bc93ccf4\n'}, {'number': 5, 'created': '2019-02-21 07:37:20.000000000', 'files': ['tools/setup_RedHat.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/c50df69045e361a3d1136471b147854684ab1e31', 'message': 'Use overlay2 in tools/setup_Redhat.sh\n\nCurrently CentOS gates use btrfs storage driver and\ncreate /docker device backing btrfs.\n\nThis patch is to sync the gate run with Ubuntu.\n(post-Trusty) does not use btrfs, only overlay2.\n\nChange-Id: Ic5caa8cf0271b21f71f03fd33c35b3c7bc93ccf4\n'}]",0,638250,c50df69045e361a3d1136471b147854684ab1e31,19,4,5,22629,,,0,"Use overlay2 in tools/setup_Redhat.sh

Currently CentOS gates use btrfs storage driver and
create /docker device backing btrfs.

This patch is to sync the gate run with Ubuntu.
(post-Trusty) does not use btrfs, only overlay2.

Change-Id: Ic5caa8cf0271b21f71f03fd33c35b3c7bc93ccf4
",git fetch https://review.opendev.org/openstack/kolla refs/changes/50/638250/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/setup_RedHat.sh'],1,7a8ba10f0cbf46f5e26d22a4fd83a5492e6e52b7,feature/gate_centos_overlay2,ExecStart=/usr/bin/dockerd --storage-driver overlay2 --insecure-registry=0.0.0.0/0,"function setup_disk { if [[ -f /etc/nodepool/provider && ! -f /swapfile ]]; then sudo swapoff -a sudo dd if=/dev/zero of=/swapfile bs=1M count=4096 sudo chmod 0600 /swapfile sudo mkswap /swapfile sudo /sbin/swapon /swapfile fi if [ ! -f /docker ]; then sudo dd if=/dev/zero of=/docker bs=1M count=25600 sudo losetup -f /docker DEV=$(losetup -a | awk -F: '/\/docker/ {print $1}') fi # Format Disks and setup Docker to use BTRFS sudo parted ${DEV} -s -- mklabel msdos sudo rm -rf /var/lib/docker sudo mkdir /var/lib/docker # We want to snapshot the entire docker directory so we have to first create a # subvolume and use that as the root for the docker directory. sudo mkfs.btrfs -f ${DEV} sudo mount ${DEV} /var/lib/docker sudo btrfs subvolume create /var/lib/docker/docker sudo umount /var/lib/docker sudo mount -o noatime,subvol=docker ${DEV} /var/lib/dockersetup_disk ExecStart=/usr/bin/dockerd --storage-driver btrfs --insecure-registry=0.0.0.0/0",1,31
openstack%2Ftripleo-heat-templates~master~I7762af7b824ae0c7303438d48fc35c9f24a00c9c,openstack/tripleo-heat-templates,master,I7762af7b824ae0c7303438d48fc35c9f24a00c9c,Make openshift-ansible working dir owned by tripleo-admin,MERGED,2019-02-19 08:33:55.000000000,2019-02-22 18:48:02.000000000,2019-02-22 18:48:02.000000000,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 13039}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-19 08:33:55.000000000', 'files': ['extraconfig/services/openshift-master.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f2412dacf1c0af1cddc83719d9c1c36c4d7e3449', 'message': ""Make openshift-ansible working dir owned by tripleo-admin\n\nThe openshift-ansible tasks are now invoked with the tripleo-admin\nuser, which doesn't by default have write access to /var/lib/mistral,\nbut it does have sudo access.\n\nThis change makes /var/lib/mistral/<stack>/openshift be owned by the\ntripleo-admin user so that subsequent tasks can write to that\ndirectory.\n\nChange-Id: I7762af7b824ae0c7303438d48fc35c9f24a00c9c\nRelated-Bug: #1813832\n""}]",0,637727,f2412dacf1c0af1cddc83719d9c1c36c4d7e3449,10,5,1,13039,,,0,"Make openshift-ansible working dir owned by tripleo-admin

The openshift-ansible tasks are now invoked with the tripleo-admin
user, which doesn't by default have write access to /var/lib/mistral,
but it does have sudo access.

This change makes /var/lib/mistral/<stack>/openshift be owned by the
tripleo-admin user so that subsequent tasks can write to that
directory.

Change-Id: I7762af7b824ae0c7303438d48fc35c9f24a00c9c
Related-Bug: #1813832
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/27/637727/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/services/openshift-master.yaml'],1,f2412dacf1c0af1cddc83719d9c1c36c4d7e3449,bug/1813832," become: true owner: ""{{ ansible_user }}""",,2,0
openstack%2Fopenstacksdk~master~Ifbb5b57d2dbf501ad17ceacc4ee6237a1d21851e,openstack/openstacksdk,master,Ifbb5b57d2dbf501ad17ceacc4ee6237a1d21851e,Stop mocking method in fwaas test,MERGED,2019-02-02 15:32:22.000000000,2019-02-22 18:25:46.000000000,2019-02-22 18:25:45.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-02-02 15:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9b516e51111b7869be2c9e8500ab6a247767861d', 'message': 'Stop mocking method in fwaas test\n\nFound this while debugging the previous patch. Improve the unit\ntest by not mocking the method but instead doing an additional\nrequests_mock call.\n\nChange-Id: Ifbb5b57d2dbf501ad17ceacc4ee6237a1d21851e\n'}, {'number': 2, 'created': '2019-02-05 19:57:57.000000000', 'files': ['openstack/tests/unit/cloud/test_fwaas.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/1dfd5cde93703e9b312a79094bc324506bae89c9', 'message': 'Stop mocking method in fwaas test\n\nFound this while debugging the previous patch. Improve the unit\ntest by not mocking the method but instead doing an additional\nrequests_mock call.\n\nChange-Id: Ifbb5b57d2dbf501ad17ceacc4ee6237a1d21851e\n'}]",0,634574,1dfd5cde93703e9b312a79094bc324506bae89c9,10,4,2,2,,,0,"Stop mocking method in fwaas test

Found this while debugging the previous patch. Improve the unit
test by not mocking the method but instead doing an additional
requests_mock call.

Change-Id: Ifbb5b57d2dbf501ad17ceacc4ee6237a1d21851e
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/74/634574/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/unit/cloud/test_fwaas.py'],1,9b516e51111b7869be2c9e8500ab6a247767861d,location-everywhere," updated_dict = self._mock_firewall_rule_attrs.copy() updated_dict.update(params) dict( method='GET', uri=self._make_mock_url( 'firewall_rules', self.firewall_rule_name), json={'firewall_rule': self._mock_firewall_rule_attrs}), dict( method='PUT', uri=self._make_mock_url( 'firewall_rules', self.firewall_rule_id), json={'firewall_rule': updated_dict}, validate={ 'json': {'firewall_rule': params}, }) updated_rule = self.cloud.update_firewall_rule( self.firewall_rule_name, filters, **params) self.assertDictEqual(updated, updated_rule)"," _find = self.cloud.network.find_firewall_rule self.cloud.network.find_firewall_rule = Mock( return_value=self.mock_firewall_rule) dict(method='PUT', uri=self._make_mock_url('firewall_rules', self.firewall_rule_id), json={'firewall_rule': updated}) self.assertDictEqual(updated, self.cloud.update_firewall_rule( self.firewall_rule_name, filters, **params)) self.cloud.network.find_firewall_rule.assert_called_once_with( self.firewall_rule_name, ignore_missing=False, **filters) # restore self.cloud.network.find_firewall_rule = _find ",18,15
openstack%2Fopenstacksdk~master~I9fc7ac2a32ac20f173554dcde80eb57713a92f7c,openstack/openstacksdk,master,I9fc7ac2a32ac20f173554dcde80eb57713a92f7c,Rename compute.service.zone to availability_zone,MERGED,2019-02-02 15:32:22.000000000,2019-02-22 18:25:44.000000000,2019-02-22 18:25:44.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-02-02 15:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7cbe82de170c5dac3349f3bc6c64e2858ec22c54', 'message': 'Rename compute.service.zone to availability_zone\n\nWhile zone is less characters, availability_zone is what this is\ncalled across the rest of the codebase, and is what the location\nsystem looks for.\n\nThis is an incompatibility to be taken care of pre-1.0 release.\n\nChange-Id: I9fc7ac2a32ac20f173554dcde80eb57713a92f7c\n'}, {'number': 2, 'created': '2019-02-05 19:57:57.000000000', 'files': ['openstack/compute/v2/service.py', 'releasenotes/notes/compute-service-zone-2b25ec705b0156c4.yaml', 'openstack/tests/unit/compute/v2/test_service.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2be7e0f6f791feda8a53c73e23d0cf04e9daa478', 'message': 'Rename compute.service.zone to availability_zone\n\nWhile zone is less characters, availability_zone is what this is\ncalled across the rest of the codebase, and is what the location\nsystem looks for.\n\nThis is an incompatibility to be taken care of pre-1.0 release.\n\nChange-Id: I9fc7ac2a32ac20f173554dcde80eb57713a92f7c\n'}]",1,634573,2be7e0f6f791feda8a53c73e23d0cf04e9daa478,10,4,2,2,,,0,"Rename compute.service.zone to availability_zone

While zone is less characters, availability_zone is what this is
called across the rest of the codebase, and is what the location
system looks for.

This is an incompatibility to be taken care of pre-1.0 release.

Change-Id: I9fc7ac2a32ac20f173554dcde80eb57713a92f7c
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/73/634573/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/compute/v2/service.py', 'releasenotes/notes/compute-service-zone-2b25ec705b0156c4.yaml', 'openstack/tests/unit/compute/v2/test_service.py']",3,7cbe82de170c5dac3349f3bc6c64e2858ec22c54,location-everywhere," self.assertEqual(EXAMPLE['zone'], sot.availability_zone)"," self.assertEqual(EXAMPLE['zone'], sot.zone)",9,2
openstack%2Fopenstacksdk~master~I48c116bf62d726be8d906c3d232e1ee203347b0a,openstack/openstacksdk,master,I48c116bf62d726be8d906c3d232e1ee203347b0a,Make all resource locations process project_id,MERGED,2019-02-02 15:32:22.000000000,2019-02-22 18:25:43.000000000,2019-02-22 18:25:43.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-02-02 15:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/5701d284d6c4bfc2df5ffec5b3f09c294754d15f', 'message': 'Make all resource locations process project_id\n\nAll resources have a location property now that describes the\nlocation of the object in the cloud, but the majority of that\ninformation is taken directly from the connection that is in\nuse. Some resources contain server-side project_id or availability\nzone information. When those exist, they should override the\nproject_id implied by the connection.\n\nChange-Id: I48c116bf62d726be8d906c3d232e1ee203347b0a\n'}, {'number': 2, 'created': '2019-02-05 19:57:57.000000000', 'files': ['openstack/compute/v2/server.py', 'openstack/resource.py', 'openstack/network/v2/firewall_policy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/5a4ce4567b81081b37179e79edfa374b0862c6d5', 'message': 'Make all resource locations process project_id\n\nAll resources have a location property now that describes the\nlocation of the object in the cloud, but the majority of that\ninformation is taken directly from the connection that is in\nuse. Some resources contain server-side project_id or availability\nzone information. When those exist, they should override the\nproject_id implied by the connection.\n\nChange-Id: I48c116bf62d726be8d906c3d232e1ee203347b0a\n'}]",5,634572,5a4ce4567b81081b37179e79edfa374b0862c6d5,13,4,2,2,,,0,"Make all resource locations process project_id

All resources have a location property now that describes the
location of the object in the cloud, but the majority of that
information is taken directly from the connection that is in
use. Some resources contain server-side project_id or availability
zone information. When those exist, they should override the
project_id implied by the connection.

Change-Id: I48c116bf62d726be8d906c3d232e1ee203347b0a
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/72/634572/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/compute/v2/server.py', 'openstack/resource.py', 'openstack/network/v2/firewall_policy.py']",3,5701d284d6c4bfc2df5ffec5b3f09c294754d15f,location-everywhere, self._update_location(),,17,9
openstack%2Fopenstacksdk~master~I1f9ea83bdc2868f26cf8583cf090ed79f1c8ba94,openstack/openstacksdk,master,I1f9ea83bdc2868f26cf8583cf090ed79f1c8ba94,"handle ""paginated"" argument in test_list properly",MERGED,2019-02-21 11:56:26.000000000,2019-02-22 18:25:42.000000000,2019-02-22 18:25:42.000000000,"[{'_account_id': 2}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 11:56:26.000000000', 'files': ['openstack/tests/unit/test_proxy_base.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/35ccf211977a745138ddfdcf629a22ea787eb677', 'message': 'handle ""paginated"" argument in test_list properly\n\nIf any proxy test is calling test_proxy_base.test_list(..., \npaginated=False) we put paginated into expected_kwargs, but keep it in \nkwargs. Remove it from there\n\nChange-Id: I1f9ea83bdc2868f26cf8583cf090ed79f1c8ba94\n'}]",0,638401,35ccf211977a745138ddfdcf629a22ea787eb677,8,2,1,27900,,,0,"handle ""paginated"" argument in test_list properly

If any proxy test is calling test_proxy_base.test_list(..., 
paginated=False) we put paginated into expected_kwargs, but keep it in 
kwargs. Remove it from there

Change-Id: I1f9ea83bdc2868f26cf8583cf090ed79f1c8ba94
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/01/638401/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/unit/test_proxy_base.py'],1,35ccf211977a745138ddfdcf629a22ea787eb677,," # NOTE(gtema): if base_path is not in expected_kwargs or empty expected_kwargs.update({""paginated"": kwargs.pop('paginated')})"," # NOTE(gtema): if base_path is not in epected_kwargs or empty expected_kwargs.update({""paginated"": kwargs['paginated']})",2,2
openstack%2Ftripleo-common~master~I5f375ab7f60572ffeced6a434c52e50dacf28dad,openstack/tripleo-common,master,I5f375ab7f60572ffeced6a434c52e50dacf28dad,DNM - add --debug to buildah,ABANDONED,2019-02-21 15:01:58.000000000,2019-02-22 17:59:32.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-21 15:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/21f19f7ba7f02f530780efdbb6528a6d4e233a72', 'message': 'DNM - add --debug to buildah\n\nChange-Id: I5f375ab7f60572ffeced6a434c52e50dacf28dad\n'}, {'number': 2, 'created': '2019-02-21 21:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7a7fd72037e2638960ea6b37da89740195305fa9', 'message': 'DNM - add --debug to buildah\n\nChange-Id: I5f375ab7f60572ffeced6a434c52e50dacf28dad\n'}, {'number': 3, 'created': '2019-02-22 14:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ebeab0132724a633f6b98d4694730d51b5439918', 'message': 'DNM - add --debug to buildah\n\nChange-Id: I5f375ab7f60572ffeced6a434c52e50dacf28dad\n'}, {'number': 4, 'created': '2019-02-22 14:13:13.000000000', 'files': ['tripleo_common/image/builder/buildah.py', 'tripleo_common/tests/image/builder/test_buildah.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/57caae53693e8fe3c1f442383cd019b78268c49a', 'message': 'DNM - add --debug to buildah\n\nChange-Id: I5f375ab7f60572ffeced6a434c52e50dacf28dad\n'}]",0,638433,57caae53693e8fe3c1f442383cd019b78268c49a,11,2,4,3153,,,0,"DNM - add --debug to buildah

Change-Id: I5f375ab7f60572ffeced6a434c52e50dacf28dad
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/33/638433/4 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/image/builder/buildah.py', 'tripleo_common/tests/image/builder/test_buildah.py']",2,21f19f7ba7f02f530780efdbb6528a6d4e233a72,debug,"BUILDAH_CMD_BASE = ['sudo', 'buildah', '--debug']","BUILDAH_CMD_BASE = ['sudo', 'buildah']",2,2
openstack%2Ftripleo-common~master~I488018e45c9b411c6ea86b86e815ca961d837eba,openstack/tripleo-common,master,I488018e45c9b411c6ea86b86e815ca961d837eba,buildah/builder: use net=host,ABANDONED,2019-02-22 14:10:51.000000000,2019-02-22 17:59:27.000000000,,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-22 14:10:51.000000000', 'files': ['tripleo_common/image/builder/buildah.py', 'tripleo_common/tests/image/builder/test_buildah.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b74c4b81c7f6a852637caeb0a551c421afd675cb', 'message': 'buildah/builder: use net=host\n\n... so the containers can fetch external networks to pull rpms when\nbuilding.\n\nChange-Id: I488018e45c9b411c6ea86b86e815ca961d837eba\n'}]",0,638667,b74c4b81c7f6a852637caeb0a551c421afd675cb,5,3,1,3153,,,0,"buildah/builder: use net=host

... so the containers can fetch external networks to pull rpms when
building.

Change-Id: I488018e45c9b411c6ea86b86e815ca961d837eba
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/67/638667/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/image/builder/buildah.py', 'tripleo_common/tests/image/builder/test_buildah.py']",2,b74c4b81c7f6a852637caeb0a551c421afd675cb,net/host," buildah_cmd_build = ['bud', '--tls-verify=False', '--network', 'host', '--logfile', logfile, '-t', dest, container_build_path]"," buildah_cmd_build = ['bud', '--tls-verify=False', '--logfile', logfile, '-t', dest, container_build_path]",6,5
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7,openstack/tripleo-heat-templates,stable/queens,I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7,minor update: move VIP before stopping pacemaker on a node,MERGED,2019-02-22 11:09:54.000000000,2019-02-22 17:52:18.000000000,2019-02-22 17:52:18.000000000,"[{'_account_id': 6926}, {'_account_id': 11166}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-22 11:09:54.000000000', 'files': ['puppet/services/pacemaker.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a9d10fdf722990d8258abd3987b1a4f6d81e0300', 'message': ""minor update: move VIP before stopping pacemaker on a node\n\nWhen pacemaker stops, it first stops all pacemaker resources\nmanaged on the node, and stops the pacemaker daemon.\n\nIf the node being stopped is hosting VIP resources, those ones\nmust be restarted elsewhere as soon as possible to avoid long\nservice disruption, but there is currently no constraint defined\nto force that behaviour.\n\nSo what can happen is the VIP resources are stopped, then other\nresources on the hosts are stopped (e.g. rabbit, galera), and only\nwhen there's no more resources pacemaker restarts VIPs elsewhere,\nwhich can lead to a long OpenStack service disruption.\n\nTo avoid unexpected long outage period due to VIP unavailability,\nforce-move the VIPs away from the node before stopping pacemaker.\n\nCloses-Bug: #1815204\nChange-Id: I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7\n(cherry picked from commit 38fb412ac0c76f0ba2b0737699845d9d882fdc2f)\n(cherry picked from commit ded38b744037bc6bffc0b63039933b58ab5e5018)\n""}]",0,638630,a9d10fdf722990d8258abd3987b1a4f6d81e0300,11,6,1,11166,,,0,"minor update: move VIP before stopping pacemaker on a node

When pacemaker stops, it first stops all pacemaker resources
managed on the node, and stops the pacemaker daemon.

If the node being stopped is hosting VIP resources, those ones
must be restarted elsewhere as soon as possible to avoid long
service disruption, but there is currently no constraint defined
to force that behaviour.

So what can happen is the VIP resources are stopped, then other
resources on the hosts are stopped (e.g. rabbit, galera), and only
when there's no more resources pacemaker restarts VIPs elsewhere,
which can lead to a long OpenStack service disruption.

To avoid unexpected long outage period due to VIP unavailability,
force-move the VIPs away from the node before stopping pacemaker.

Closes-Bug: #1815204
Change-Id: I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7
(cherry picked from commit 38fb412ac0c76f0ba2b0737699845d9d882fdc2f)
(cherry picked from commit ded38b744037bc6bffc0b63039933b58ab5e5018)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/30/638630/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/pacemaker.yaml'],1,a9d10fdf722990d8258abd3987b1a4f6d81e0300,bug/1815204," - name: Move virtual IPs to another node before stopping pacemaker when: step|int == 1 shell: | CLUSTER_NODE=$(crm_node -n) echo ""Retrieving all the VIPs which are hosted on this node"" VIPS_TO_MOVE=$(crm_mon --as-xml | xmllint --xpath '//resource[@resource_agent = ""ocf::heartbeat:IPaddr2"" and @role = ""Started"" and @managed = ""true"" and ./node[@name = ""'${CLUSTER_NODE}'""]]/@id' - | sed -e 's/id=//g' -e 's/""//g') for v in ${VIPS_TO_MOVE}; do echo ""Moving VIP $v on another node"" pcs resource move $v --wait=300 done echo ""Removing the location constraints that were created to move the VIPs"" for v in ${VIPS_TO_MOVE}; do echo ""Removing location ban for VIP $v"" ban_id=$(cibadmin --query | xmllint --xpath 'string(//rsc_location[@rsc=""'${v}'"" and @node=""'${CLUSTER_NODE}'"" and @score=""-INFINITY""]/@id)' -) if [ -n ""$ban_id"" ]; then pcs constraint remove ${ban_id} else echo ""Could not retrieve and clear location constraint for VIP $v"" 2>&1 fi done",,20,0
openstack%2Ftripleo-common~stable%2Frocky~I5aba5ba0a800aabe6e662a333e3f0436c1b563a0,openstack/tripleo-common,stable/rocky,I5aba5ba0a800aabe6e662a333e3f0436c1b563a0,Append qemu-img to Mistral executor package list,MERGED,2019-02-21 15:55:15.000000000,2019-02-22 17:52:16.000000000,2019-02-22 17:52:16.000000000,"[{'_account_id': 6681}, {'_account_id': 6796}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-21 15:55:15.000000000', 'files': ['container-images/tripleo_kolla_template_overrides.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/50c9efc9a3a2abcdfe149ab70faff84dc09b857d', 'message': 'Append qemu-img to Mistral executor package list\n\nThe Octavia playbook in tripleo-common and run in Mistral executor fails\nbecause qemu-img is not available. This happens when either the operator\nexplicitly instructs TripleO to convert the amphora qcow2 file to raw\nformat or when Ceph is enabled.\n\nThis patch appends qemu-img to the package list so that the command is\navailable in the mistral-executor container.\n\nConflicts:\n    container-images/tripleo_kolla_template_overrides.j2\n\nCloses-Bug: #1816382\n\nChange-Id: I5aba5ba0a800aabe6e662a333e3f0436c1b563a0\n(cherry picked from commit 0381d6cc370ec6309fb68133c7b7f655364aa837)\n'}]",0,638446,50c9efc9a3a2abcdfe149ab70faff84dc09b857d,9,5,1,6469,,,0,"Append qemu-img to Mistral executor package list

The Octavia playbook in tripleo-common and run in Mistral executor fails
because qemu-img is not available. This happens when either the operator
explicitly instructs TripleO to convert the amphora qcow2 file to raw
format or when Ceph is enabled.

This patch appends qemu-img to the package list so that the command is
available in the mistral-executor container.

Conflicts:
    container-images/tripleo_kolla_template_overrides.j2

Closes-Bug: #1816382

Change-Id: I5aba5ba0a800aabe6e662a333e3f0436c1b563a0
(cherry picked from commit 0381d6cc370ec6309fb68133c7b7f655364aa837)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/46/638446/1 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tripleo_kolla_template_overrides.j2'],1,50c9efc9a3a2abcdfe149ab70faff84dc09b857d,bug/1816382,"{% set mistral_executor_packages_append = ['openstack-tripleo-validations', 'openstack-nova-common', 'docker', 'podman', 'python2-notario', 'qemu-img'] %}","{% set mistral_executor_packages_append = ['openstack-tripleo-validations', 'openstack-nova-common', 'docker', 'podman', 'python2-notario'] %}",1,1
openstack%2Ftripleo-heat-templates~master~Ie2b9f003dc34f2f02a45293d06d6a40c8d5ed8ff,openstack/tripleo-heat-templates,master,Ie2b9f003dc34f2f02a45293d06d6a40c8d5ed8ff,Do not ignore Swift ring changes to trigger container restart,MERGED,2018-11-07 09:08:12.000000000,2019-02-22 17:52:14.000000000,2019-02-22 17:52:14.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 6968}, {'_account_id': 14985}, {'_account_id': 17823}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-11-07 09:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/07d676caed610e93351f2fe985ebcefcea4f1f74', 'message': ""Fix Swift device config update issues\n\nFixes an issue when changing the Swift config (eg. adding new\ndevices). Without this fix rings weren't updated properly and new\nstorage mount points were using the wrong permissions.\n\nCloses-Bug: 1802066\nChange-Id: Ie2b9f003dc34f2f02a45293d06d6a40c8d5ed8ff\n""}, {'number': 2, 'created': '2018-11-07 10:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/64f3e2d750ab756270295d69b1f21cbe81582380', 'message': 'Do not ignore Swift ring changes to trigger container restart\n\nSwift containers need to restart if the rings change. In\nnon-containerized environments this is not required, because the Swift\nprocesses will reload the rings on any changes. However, this does not\nwork within containers, thus a restart is required.\n\nThis also restarts swift_copy_rings and swift_setup_srv container. This\nwill copy the updated ring files and ensure new storage mount points are\nusing the right permissions.\n\nCloses-Bug: 1802066\nChange-Id: Ie2b9f003dc34f2f02a45293d06d6a40c8d5ed8ff\n'}, {'number': 3, 'created': '2018-11-07 10:47:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c186e51736ef401152e79d16d219dbe5528b0b0e', 'message': 'Do not ignore Swift ring changes to trigger container restart\n\nSwift containers need to restart if the rings change. In\nnon-containerized environments this is not required, because the Swift\nprocesses will reload the rings on any changes. However, this does not\nwork within containers, thus a restart is required.\n\nThis also restarts swift_copy_rings and swift_setup_srv container. This\nwill copy the updated ring files and ensure new storage mount points are\nusing the right permissions.\n\nCloses-Bug: 1802066\nRelated-Bug: 1786065\nChange-Id: Ie2b9f003dc34f2f02a45293d06d6a40c8d5ed8ff\n'}, {'number': 4, 'created': '2019-01-17 15:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5388a3262ded279c675a628b6039f1bfcd5da535', 'message': 'Do not ignore Swift ring changes to trigger container restart\n\nSwift containers need to restart if the rings change. In\nnon-containerized environments this is not required, because the Swift\nprocesses will reload the rings on any changes. However, this does not\nwork within containers, thus a restart is required.\n\nThis also restarts swift_copy_rings and swift_setup_srv container. This\nwill copy the updated ring files and ensure new storage mount points are\nusing the right permissions.\n\nCloses-Bug: 1802066\nRelated-Bug: 1786065\nChange-Id: Ie2b9f003dc34f2f02a45293d06d6a40c8d5ed8ff\n'}, {'number': 5, 'created': '2019-02-22 08:48:49.000000000', 'files': ['docker/docker-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b49629f085b5f04be999e0d5697a77e3791f7dcc', 'message': 'Do not ignore Swift ring changes to trigger container restart\n\nSwift containers need to restart if the rings change. In\nnon-containerized environments this is not required, because the Swift\nprocesses will reload the rings on any changes. However, this does not\nwork within containers, thus a restart is required.\n\nThis also restarts swift_copy_rings and swift_setup_srv container. This\nwill copy the updated ring files and ensure new storage mount points are\nusing the right permissions.\n\nCloses-Bug: 1802066\nRelated-Bug: 1786065\nChange-Id: Ie2b9f003dc34f2f02a45293d06d6a40c8d5ed8ff\n'}]",1,616116,b49629f085b5f04be999e0d5697a77e3791f7dcc,30,8,5,6968,,,0,"Do not ignore Swift ring changes to trigger container restart

Swift containers need to restart if the rings change. In
non-containerized environments this is not required, because the Swift
processes will reload the rings on any changes. However, this does not
work within containers, thus a restart is required.

This also restarts swift_copy_rings and swift_setup_srv container. This
will copy the updated ring files and ensure new storage mount points are
using the right permissions.

Closes-Bug: 1802066
Related-Bug: 1786065
Change-Id: Ie2b9f003dc34f2f02a45293d06d6a40c8d5ed8ff
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/16/616116/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/swift-storage.yaml', 'docker/services/swift-ringbuilder.yaml']",2,07d676caed610e93351f2fe985ebcefcea4f1f74,bug/1802066," DeployIdentifier: default: '' type: string description: > Setting this to a unique value will re-run any deployment tasks which perform configuration on a Heat stack-update. environment: # NOTE: this should force this container to re-run on each # update (scale-out, etc.) - list_join: - '' - - 'TRIPLEO_DEPLOY_IDENTIFIER=' - {get_param: DeployIdentifier}",,26,0
openstack%2Fopenstack-ansible-openstack_hosts~master~I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3,openstack/openstack-ansible-openstack_hosts,master,I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3,add gentoo support,MERGED,2018-10-05 17:39:59.000000000,2019-02-22 17:39:46.000000000,2019-02-22 17:39:46.000000000,"[{'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-10-05 17:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/ece1d566eff6679bb8422827acc3324974947b95', 'message': 'add gentoo support\n\nAdds var files and templates needed to support gentoo\n\nChange-Id: I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3\n'}, {'number': 2, 'created': '2018-10-05 19:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/33771d15bd0f08b1007a0da8e3565921bd3bafe7', 'message': 'add gentoo support\n\nAdds var files and templates needed to support gentoo\n\nChange-Id: I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3\n'}, {'number': 3, 'created': '2018-10-05 21:24:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/4caf6c7857eb46764b72335d01649796079813e0', 'message': 'add gentoo support\n\nAdds var files and templates needed to support gentoo\n\nChange-Id: I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3\n'}, {'number': 4, 'created': '2018-10-05 22:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/2660d9ae9dcc0b73553b2bff45d31a6481618b0e', 'message': 'add gentoo support\n\nAdds var files and templates needed to support gentoo\n\nChange-Id: I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3\n'}, {'number': 5, 'created': '2018-10-05 23:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/c893a501cca298a2f6124c3380559f82201032e7', 'message': 'add gentoo support\n\nAdds var files and templates needed to support gentoo\n\nChange-Id: I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3\n'}, {'number': 6, 'created': '2019-01-25 19:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/585ce72b00e874643f94f37dc6f7b8aabc982d07', 'message': 'add gentoo support\n\nAdds var files and templates needed to support gentoo\n\nChange-Id: I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3\n'}, {'number': 7, 'created': '2019-01-25 22:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/036ce500377e959063b9421dd803018ac05c9092', 'message': 'add gentoo support\n\nAdds var files and templates needed to support gentoo\n\nChange-Id: I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3\n'}, {'number': 8, 'created': '2019-01-26 03:51:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/addc58d20c33380345b61e221678a5dfa37b453a', 'message': 'add gentoo support\n\nAdds var files and templates needed to support gentoo\n\nChange-Id: I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3\n'}, {'number': 9, 'created': '2019-01-26 04:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/3e330c14dfe1ed6015eb545c400aecc7083b6da5', 'message': 'add gentoo support\n\nAdds var files and templates needed to support gentoo\n\nChange-Id: I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3\n'}, {'number': 10, 'created': '2019-01-27 03:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/f16831bab890a1b437cdd194e00a6664604c42e6', 'message': 'add gentoo support\n\nAdds var files and templates needed to support gentoo\n\nChange-Id: I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3\n'}, {'number': 11, 'created': '2019-01-27 21:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/5ad6e289b9bdc7c4008a00008c16f965f8b3430e', 'message': 'add gentoo support\n\nAdds var files and templates needed to support gentoo\n\nChange-Id: I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3\n'}, {'number': 12, 'created': '2019-02-20 02:32:48.000000000', 'files': ['run_tests.sh', 'templates/sysstat.cron.gentoo.j2', 'tasks/openstack_hosts_configure_portage.yml', 'vars/gentoo.yml', 'meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/df5391a33cdd7b2ef5b6487d4c8dd0dbce595107', 'message': 'add gentoo support\n\nAdds var files and templates needed to support gentoo\n\nChange-Id: I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3\n'}]",0,608325,df5391a33cdd7b2ef5b6487d4c8dd0dbce595107,33,4,12,14288,,,0,"add gentoo support

Adds var files and templates needed to support gentoo

Change-Id: I4d80dd3e9c1ef5ba5dcd8e62381a5e32f513fbb3
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/25/608325/5 && git format-patch -1 --stdout FETCH_HEAD,"['templates/sysstat.cron.gentoo.j2', 'vars/gentoo.yml', 'meta/main.yml']",3,ece1d566eff6679bb8422827acc3324974947b95,add-gentoo-support, - name: gentoo versions: - all,,110,0
openstack%2Fproject-config~master~I9fb2e44733d152bd14f9568dbc0842eeb0c57269,openstack/project-config,master,I9fb2e44733d152bd14f9568dbc0842eeb0c57269,Remove buildset registry job,MERGED,2019-02-22 16:30:38.000000000,2019-02-22 17:38:29.000000000,2019-02-22 17:38:29.000000000,"[{'_account_id': 2}, {'_account_id': 4146}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 16:30:38.000000000', 'files': ['zuul.d/secrets.yaml', 'playbooks/buildset-registry/post.yaml', 'playbooks/buildset-registry/pre.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2802deeab8c5c651ca2c523a219ca64f68391e1d', 'message': 'Remove buildset registry job\n\nThis is moving to opendev/base-jobs.\n\nChange-Id: I9fb2e44733d152bd14f9568dbc0842eeb0c57269\n'}]",0,638706,2802deeab8c5c651ca2c523a219ca64f68391e1d,8,3,1,1,,,0,"Remove buildset registry job

This is moving to opendev/base-jobs.

Change-Id: I9fb2e44733d152bd14f9568dbc0842eeb0c57269
",git fetch https://review.opendev.org/openstack/project-config refs/changes/06/638706/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/secrets.yaml', 'playbooks/buildset-registry/post.yaml', 'playbooks/buildset-registry/pre.yaml', 'zuul.d/jobs.yaml']",4,2802deeab8c5c651ca2c523a219ca64f68391e1d,registry,, - job: name: openstack-buildset-registry description: | Inherit from this job to get a buildset registry which interacts with the intermediate CI registry to share speculative container images between projects. pre-run: playbooks/buildset-registry/pre.yaml post-run: playbooks/buildset-registry/post.yaml secrets: - secret: opendev-intermediate-registry name: intermediate_registry,0,54
openstack%2Ftripleo-common~master~I88dc36cd501aa8801c1fec8c15605fc8ed9aa82b,openstack/tripleo-common,master,I88dc36cd501aa8801c1fec8c15605fc8ed9aa82b,[DOWNSTREAM ONLY] Remove rsyslog container image,ABANDONED,2019-02-22 17:07:29.000000000,2019-02-22 17:07:47.000000000,,[],"[{'number': 1, 'created': '2019-02-22 17:07:29.000000000', 'files': ['container-images/overcloud_containers.yaml', 'container-images/overcloud_containers.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c440af5ebce09e4a73062823a642d6dbf64a6049', 'message': '[DOWNSTREAM ONLY] Remove rsyslog container image\n\nSee Ib26ab3118e69b71a913b2e81b1e42938e392e5c9 for context.\n\nChange-Id: I88dc36cd501aa8801c1fec8c15605fc8ed9aa82b\n'}]",0,638720,c440af5ebce09e4a73062823a642d6dbf64a6049,2,0,1,3153,,,0,"[DOWNSTREAM ONLY] Remove rsyslog container image

See Ib26ab3118e69b71a913b2e81b1e42938e392e5c9 for context.

Change-Id: I88dc36cd501aa8801c1fec8c15605fc8ed9aa82b
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/20/638720/1 && git format-patch -1 --stdout FETCH_HEAD,"['container-images/overcloud_containers.yaml', 'container-images/overcloud_containers.yaml.j2']",2,c440af5ebce09e4a73062823a642d6dbf64a6049,osp15,,"- imagename: ""{{namespace}}/{{name_prefix}}rsyslog-base{{name_suffix}}:{{tag}}"" image_source: kolla params: - DockerRsyslogSidecarImage - DockerRsyslogSidecarConfigImage services: - OS::TripleO::Services::HAproxy - OS::TripleO::Services::SwiftProxy - OS::TripleO::Services::SwiftStorage ",0,12
openstack%2Ftripleo-common~stable%2Frocky~I294ab0016fda9587b405ef08dba3212b8e46a816,openstack/tripleo-common,stable/rocky,I294ab0016fda9587b405ef08dba3212b8e46a816,Add missing queue_name input parameter for listing validations,MERGED,2019-02-18 08:05:42.000000000,2019-02-22 17:05:32.000000000,2019-02-22 17:05:32.000000000,"[{'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2019-02-18 08:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/53527019fdf2838385a5e1d048cd84d57fc048da', 'message': 'Add missing queue_name input parameter for listing validations\n\nThe list validations workflow does not have defines\nthe queue_name parameter in the input section.\nThus the workflow fails when trying to read that variable.\n\nChange-Id: I294ab0016fda9587b405ef08dba3212b8e46a816\nImplements: blueprint validation-framework\nCloses-bug: 1815725\n(cherry picked from commit 882d9a7695f497efe60f00858be59fd18df56beb)\n'}, {'number': 2, 'created': '2019-02-18 14:31:47.000000000', 'files': ['workbooks/validations.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d91f6d9948bdf758fcab030912062d4f9c7013cf', 'message': 'Add missing queue_name input parameter for listing validations\n\nThe list validations workflow does not have defines\nthe queue_name parameter in the input section.\nThus the workflow fails when trying to read that variable.\n\nChange-Id: I294ab0016fda9587b405ef08dba3212b8e46a816\nImplements: blueprint validation-framework\nCloses-bug: 1815725\n(cherry picked from commit 882d9a7695f497efe60f00858be59fd18df56beb)\n'}]",0,637485,d91f6d9948bdf758fcab030912062d4f9c7013cf,15,4,2,20775,,,0,"Add missing queue_name input parameter for listing validations

The list validations workflow does not have defines
the queue_name parameter in the input section.
Thus the workflow fails when trying to read that variable.

Change-Id: I294ab0016fda9587b405ef08dba3212b8e46a816
Implements: blueprint validation-framework
Closes-bug: 1815725
(cherry picked from commit 882d9a7695f497efe60f00858be59fd18df56beb)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/85/637485/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/validations.yaml'],1,53527019fdf2838385a5e1d048cd84d57fc048da,bp/validation-framework, - plan: overcloud - queue_name: tripleo type: <% execution().name %> execution: <% execution() %>, type: <% execution() %>,4,1
openstack%2Fcastellan~master~I5815cb74394e18b6058f4c5cf69b656d7cc2c43b,openstack/castellan,master,I5815cb74394e18b6058f4c5cf69b656d7cc2c43b,Fix length usage in VaultKeyManager.create_key.,MERGED,2019-02-22 12:54:38.000000000,2019-02-22 16:59:14.000000000,2019-02-22 16:59:14.000000000,"[{'_account_id': 6928}, {'_account_id': 7973}, {'_account_id': 9914}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 12:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/8088d7c7c59ad06b6c6cb921ecdc0c18719a917a', 'message': ""Fix length usage in VaultKeyManager.create_key.\n\nPrevious code was considering length as bytes, but the API contract\nconsiders the length param to be bits so that the considering `km`\nas a VaultKeyManager, the call `km.create_key(ctx, 'aes', 256)` should\ngenerate a 256 bit AES key and not a 2048 bit AES key instead.\n\nChange-Id: I5815cb74394e18b6058f4c5cf69b656d7cc2c43b\nSigned-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>\n""}, {'number': 2, 'created': '2019-02-22 13:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/2d1d4218bfd2526f54fcdf9499452e421bcfa413', 'message': ""Fix length usage in VaultKeyManager.create_key.\n\nPrevious code was considering length as bytes, but the API contract\nconsiders the length param to be bits so that the considering `km`\nas a VaultKeyManager, the call `km.create_key(ctx, 'aes', 256)` should\ngenerate a 256 bit AES key and not a 2048 bit AES key instead.\n\nCloses-Bug: #1817248\nChange-Id: I5815cb74394e18b6058f4c5cf69b656d7cc2c43b\nSigned-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>\n""}, {'number': 3, 'created': '2019-02-22 14:47:01.000000000', 'files': ['releasenotes/notes/fix-vault-create-key-b4340a3067cbd93c.yaml', 'castellan/key_manager/vault_key_manager.py'], 'web_link': 'https://opendev.org/openstack/castellan/commit/9ecd30081aafbd45d4d40fc927aad1a6e18aaa6c', 'message': ""Fix length usage in VaultKeyManager.create_key.\n\nPrevious code was considering length as bytes, but the API contract\nconsiders the length param to be bits so that the considering `km`\nas a VaultKeyManager, the call `km.create_key(ctx, 'AES', 256)` should\ngenerate a 256 bit AES key and not a 2048 bit AES key instead.\n\nCloses-Bug: #1817248\nChange-Id: I5815cb74394e18b6058f4c5cf69b656d7cc2c43b\nSigned-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>\n""}]",0,638658,9ecd30081aafbd45d4d40fc927aad1a6e18aaa6c,13,4,3,27954,,,0,"Fix length usage in VaultKeyManager.create_key.

Previous code was considering length as bytes, but the API contract
considers the length param to be bits so that the considering `km`
as a VaultKeyManager, the call `km.create_key(ctx, 'AES', 256)` should
generate a 256 bit AES key and not a 2048 bit AES key instead.

Closes-Bug: #1817248
Change-Id: I5815cb74394e18b6058f4c5cf69b656d7cc2c43b
Signed-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>
",git fetch https://review.opendev.org/openstack/castellan refs/changes/58/638658/2 && git format-patch -1 --stdout FETCH_HEAD,['castellan/key_manager/vault_key_manager.py'],1,8088d7c7c59ad06b6c6cb921ecdc0c18719a917a,bug/1817248," if length % 8: msg = _(""Length must be multiple of 8."") raise ValueError(msg) key_value = os.urandom((length or 256) // 8) length or 256,"," key_value = os.urandom(length or 32) length or 32,",7,2
openstack%2Fpython-tripleoclient~master~I507d81278097bc3b5e23d53ae35aa26657541bfc,openstack/python-tripleoclient,master,I507d81278097bc3b5e23d53ae35aa26657541bfc,Check proxy env vars,MERGED,2019-02-13 22:41:34.000000000,2019-02-22 16:36:06.000000000,2019-02-22 03:53:52.000000000,"[{'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 9414}, {'_account_id': 11082}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 29222}]","[{'number': 1, 'created': '2019-02-13 22:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f30e95ad0d933cedfe3f3c483aa8468c6d1b3151', 'message': 'Check proxy env vars\n\nIf a user is using http_proxy or https_proxy but is not excluding\nlocalhost from being proxied via the no_proxy var it can lead to a\nfailure when we try and talk to the heat api. This change adds a check\nthat is used for both the standalone tripleo deploy command and\nthe undercloud install to ensure the end user does not hit this\ncondition.\n\nChange-Id: I507d81278097bc3b5e23d53ae35aa26657541bfc\nCloses-Bug: #1815814\n'}, {'number': 2, 'created': '2019-02-13 23:25:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/9f72de5e99424c38f10628f7eca37ca8bb2dfbc9', 'message': 'Check proxy env vars\n\nIf a user is using http_proxy or https_proxy but is not excluding\nlocalhost from being proxied via the no_proxy var it can lead to a\nfailure when we try and talk to the heat api. This change adds a check\nthat is used for both the standalone tripleo deploy command and\nthe undercloud install to ensure the end user does not hit this\ncondition.\n\nChange-Id: I507d81278097bc3b5e23d53ae35aa26657541bfc\nCloses-Bug: #1815814\n'}, {'number': 3, 'created': '2019-02-19 23:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/eb27917d8cf61b6da8ed09cdd6b04b94f324d9d7', 'message': 'Check proxy env vars\n\nIf a user is using http_proxy or https_proxy but is not excluding\nlocalhost from being proxied via the no_proxy var it can lead to a\nfailure when we try and talk to the heat api. This change adds a check\nthat is used for both the standalone tripleo deploy command and\nthe undercloud install to ensure the end user does not hit this\ncondition.\n\nChange-Id: I507d81278097bc3b5e23d53ae35aa26657541bfc\nCloses-Bug: #1815814\n'}, {'number': 4, 'created': '2019-02-19 23:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/1ecf33a9d63fe2c3209cd85c4857a20ae6f362cd', 'message': 'Check proxy env vars\n\nIf a user is using http_proxy or https_proxy but is not excluding\nlocalhost from being proxied via the no_proxy var it can lead to a\nfailure when we try and talk to the heat api. This change adds a check\nthat is used for both the standalone tripleo deploy command and\nthe undercloud install to ensure the end user does not hit this\ncondition.\n\nChange-Id: I507d81278097bc3b5e23d53ae35aa26657541bfc\nCloses-Bug: #1815814\n'}, {'number': 5, 'created': '2019-02-20 16:44:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6169876b7eee3785b9e323b1dd1ef95b6fca6d54', 'message': 'Check proxy env vars\n\nIf a user is using http_proxy or https_proxy but is not excluding\nlocalhost from being proxied via the no_proxy var it can lead to a\nfailure when we try and talk to the heat api. This change adds a check\nthat is used for both the standalone tripleo deploy command and\nthe undercloud install to ensure the end user does not hit this\ncondition.\n\nChange-Id: I507d81278097bc3b5e23d53ae35aa26657541bfc\nCloses-Bug: #1815814\n'}, {'number': 6, 'created': '2019-02-20 19:23:56.000000000', 'files': ['tripleoclient/tests/test_utils.py', 'tripleoclient/v1/tripleo_deploy.py', 'tripleoclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/281e01967620a2a1db1a8ef6de9d3baa18cd636e', 'message': 'Check proxy env vars\n\nIf a user is using http_proxy or https_proxy but is not excluding\nlocalhost from being proxied via the no_proxy var it can lead to a\nfailure when we try and talk to the heat api. This change adds a check\nthat is used for both the standalone tripleo deploy command and\nthe undercloud install to ensure the end user does not hit this\ncondition.\n\nChange-Id: I507d81278097bc3b5e23d53ae35aa26657541bfc\nCloses-Bug: #1815814\n'}]",16,636772,281e01967620a2a1db1a8ef6de9d3baa18cd636e,50,8,6,14985,,,0,"Check proxy env vars

If a user is using http_proxy or https_proxy but is not excluding
localhost from being proxied via the no_proxy var it can lead to a
failure when we try and talk to the heat api. This change adds a check
that is used for both the standalone tripleo deploy command and
the undercloud install to ensure the end user does not hit this
condition.

Change-Id: I507d81278097bc3b5e23d53ae35aa26657541bfc
Closes-Bug: #1815814
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/72/636772/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/test_utils.py', 'tripleoclient/v1/tripleo_deploy.py', 'tripleoclient/utils.py']",3,f30e95ad0d933cedfe3f3c483aa8468c6d1b3151,bug/1815814," def check_env_for_proxy(no_proxy_hosts=['127.0.0.1']): """"""Check env proxy settings :param no_proxy_hosts: array of hosts to check if in no_proxy env var """""" http_proxy = os.environ.get('http_proxy', None) https_proxy = os.environ.get('https_proxy', None) no_proxy = os.environ.get('no_proxy', None) missing_hosts = [] if (http_proxy or https_proxy) and not no_proxy: missing_hosts = [h for h in no_proxy_hosts if h not in no_proxy] if missing_hosts: message = _('http_proxy or https_proxy is set but the following local ' 'addresses ""{}"" may be missing from the no_proxy ' 'environment variable').format(','.join(missing_hosts)) raise RuntimeError(message)",,67,0
openstack%2Freleases~master~I00e1404c86acf0b3d244f1a297c6aabaf9865d79,openstack/releases,master,I00e1404c86acf0b3d244f1a297c6aabaf9865d79,Release OpenStack-Ansible queens/17.1.8,MERGED,2019-02-16 06:27:03.000000000,2019-02-22 16:32:44.000000000,2019-02-22 16:32:44.000000000,"[{'_account_id': 2472}, {'_account_id': 11904}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-16 06:27:03.000000000', 'files': ['deliverables/queens/openstack-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/3234ba3a2cc1a326dd29244f19fa1602e479d7ab', 'message': 'Release OpenStack-Ansible queens/17.1.8\n\nChange-Id: I00e1404c86acf0b3d244f1a297c6aabaf9865d79\n'}]",0,637360,3234ba3a2cc1a326dd29244f19fa1602e479d7ab,11,4,1,17068,,,0,"Release OpenStack-Ansible queens/17.1.8

Change-Id: I00e1404c86acf0b3d244f1a297c6aabaf9865d79
",git fetch https://review.opendev.org/openstack/releases refs/changes/60/637360/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/openstack-ansible.yaml'],1,3234ba3a2cc1a326dd29244f19fa1602e479d7ab,release_osa, - projects: - hash: e5b315ed3c10ad6945bcc2abfa792f01ca60be3a repo: openstack/openstack-ansible version: 17.1.8,,4,0
openstack%2Freleases~master~Id84515622bb8a8a66c82df9f2198ec361fdf311f,openstack/releases,master,Id84515622bb8a8a66c82df9f2198ec361fdf311f,Release OpenStack-Ansible pike/16.0.26,MERGED,2019-02-16 06:33:24.000000000,2019-02-22 16:32:43.000000000,2019-02-22 16:32:43.000000000,"[{'_account_id': 2472}, {'_account_id': 11904}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-16 06:33:24.000000000', 'files': ['deliverables/pike/openstack-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/b1311a7d559f6b9d77aa934b854bef3a3f5b468d', 'message': 'Release OpenStack-Ansible pike/16.0.26\n\nChange-Id: Id84515622bb8a8a66c82df9f2198ec361fdf311f\n'}]",0,637362,b1311a7d559f6b9d77aa934b854bef3a3f5b468d,10,4,1,17068,,,0,"Release OpenStack-Ansible pike/16.0.26

Change-Id: Id84515622bb8a8a66c82df9f2198ec361fdf311f
",git fetch https://review.opendev.org/openstack/releases refs/changes/62/637362/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/pike/openstack-ansible.yaml'],1,b1311a7d559f6b9d77aa934b854bef3a3f5b468d,release_osa, - projects: - hash: 2ea5a43068efff4ecea761af93e36fdd3d0c54a7 repo: openstack/openstack-ansible version: 16.0.26,,4,0
openstack%2Fcharm-openstack-dashboard~stable%2F18.11~I74c17113f431c4c21f638be6abffaeeb693f1462,openstack/charm-openstack-dashboard,stable/18.11,I74c17113f431c4c21f638be6abffaeeb693f1462,Use correct certificate when ``os-public-hostname`` configration option is set,MERGED,2019-02-21 18:22:41.000000000,2019-02-22 16:30:26.000000000,2019-02-22 09:00:15.000000000,"[{'_account_id': 12549}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 18:22:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/84336d8d2feb6f38efcdf88435fd1a06d4f8d7df', 'message': 'Use correct certificate when ``os-public-hostname`` configration option is set\n\nNote that this is a short term kludge/fix, on the long term\nwe should ditch the charm specific ApacheSSLContext and use\nthe common one from charm-helpers with an adapted Apache\nconfig inspired from the ``openstack_https_fronted`` template\n\nChange-Id: I74c17113f431c4c21f638be6abffaeeb693f1462\nCloses-Bug: #1816621\n'}, {'number': 2, 'created': '2019-02-22 08:42:49.000000000', 'files': ['hooks/horizon_hooks.py', 'unit_tests/test_horizon_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/d52307da7c164274d53259417909b146ac256d45', 'message': 'Use correct certificate when ``os-public-hostname`` configration option is set\n\nNote that this is a short term fix, on the long term\nwe should replace the charm specific ApacheSSLContext with\nthe common one from charm-helpers with an adapted Apache\nconfig inspired from the ``openstack_https_fronted`` template.\n\nChange-Id: I74c17113f431c4c21f638be6abffaeeb693f1462\nCloses-Bug: #1816621\n(cherry picked from 256f971c78574f017eb802ab7097231698b96ae0)\n'}]",0,638478,d52307da7c164274d53259417909b146ac256d45,13,5,2,20805,,,0,"Use correct certificate when ``os-public-hostname`` configration option is set

Note that this is a short term fix, on the long term
we should replace the charm specific ApacheSSLContext with
the common one from charm-helpers with an adapted Apache
config inspired from the ``openstack_https_fronted`` template.

Change-Id: I74c17113f431c4c21f638be6abffaeeb693f1462
Closes-Bug: #1816621
(cherry picked from 256f971c78574f017eb802ab7097231698b96ae0)
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/78/638478/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_hooks.py', 'unit_tests/test_horizon_hooks.py']",2,84336d8d2feb6f38efcdf88435fd1a06d4f8d7df,bug/1816621-stable/18.11," @patch.object(hooks.os, 'symlink') @patch.object(hooks.os, 'remove') @patch.object(hooks.os.path, 'exists') @patch.object(hooks, 'service_reload') @patch.object(hooks, 'process_certificates') def test_certs_changed(self, _process_certificates, _service_reload, _exists, _remove, _symlink): self._call_hook('certificates-relation-changed') _process_certificates.assert_called_with( 'horizon', None, None, custom_hostname_link='dashboard') self.assertFalse(_symlink.called) self.CONFIGS.write_all.assert_called_with() _service_reload.assert_called_with('apache2') self.enable_ssl.assert_called_with() _process_certificates.reset_mock() self.config.side_effect = None self.config.return_value = 'somehostname' _exists.return_value = True self._call_hook('certificates-relation-changed') _process_certificates.assert_called_with('horizon', None, None) _remove.assert_has_calls([ call('/etc/apache2/ssl/horizon/cert_dashboard'), call('/etc/apache2/ssl/horizon/key_dashboard'), ]) _symlink.assert_has_calls([ call('/etc/apache2/ssl/horizon/cert_somehostname', '/etc/apache2/ssl/horizon/cert_dashboard'), call('/etc/apache2/ssl/horizon/key_somehostname', '/etc/apache2/ssl/horizon/key_dashboard'), ])",,53,2
openstack%2Fhorizon~master~Ibc8288da55867b63fddbb2b763bfd61377b0e5ad,openstack/horizon,master,Ibc8288da55867b63fddbb2b763bfd61377b0e5ad,"Fix: Volume Snapshot Table ""Project' column info",MERGED,2019-02-19 10:10:34.000000000,2019-02-22 15:55:56.000000000,2019-02-22 15:55:56.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-02-19 10:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d2c905a769f0cd9034aa712068baf447c6328044', 'message': 'Fix: Volume Snapshot Table ""Project\' column info\n\nThis patch fixes Volume Snapshot table \'Project\' column\ninfo.\n\nChange-Id: Ibc8288da55867b63fddbb2b763bfd61377b0e5ad\nCloses-Bug: #1815859\n'}, {'number': 2, 'created': '2019-02-19 12:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b282b49460584dd6dfb1af021df956a8a86aa1a3', 'message': 'Fix: Volume Snapshot Table ""Project\' column info\n\nThis patch fixes Volume Snapshot table \'Project\' column\ninfo.\n\nChange-Id: Ibc8288da55867b63fddbb2b763bfd61377b0e5ad\nCloses-Bug: #1815859\n'}, {'number': 3, 'created': '2019-02-19 14:33:17.000000000', 'files': ['openstack_dashboard/dashboards/admin/snapshots/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b37abb1168964e5694bb55cfbc92ad2e43c6cb54', 'message': 'Fix: Volume Snapshot Table ""Project\' column info\n\nThis patch fixes Volume Snapshot table \'Project\' column\ninfo.\n\nChange-Id: Ibc8288da55867b63fddbb2b763bfd61377b0e5ad\nCloses-Bug: #1815859\n'}]",4,637809,b37abb1168964e5694bb55cfbc92ad2e43c6cb54,16,6,3,29313,,,0,"Fix: Volume Snapshot Table ""Project' column info

This patch fixes Volume Snapshot table 'Project' column
info.

Change-Id: Ibc8288da55867b63fddbb2b763bfd61377b0e5ad
Closes-Bug: #1815859
",git fetch https://review.opendev.org/openstack/horizon refs/changes/09/637809/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/admin/snapshots/views.py'],1,d2c905a769f0cd9034aa712068baf447c6328044,bug/1815859," tenant_id = getattr( snapshot, 'os-extended-snapshot-attributes:project_id', None)"," tenant_id = getattr(volume, 'os-vol-tenant-attr:tenant_id', None)",4,2
openstack%2Ftripleo-common~master~I91a424f3fbe76b8ee518b24b3b7d12e299bb52d1,openstack/tripleo-common,master,I91a424f3fbe76b8ee518b24b3b7d12e299bb52d1,Remove opendaylight container image build from Stein,ABANDONED,2019-02-22 14:13:50.000000000,2019-02-22 15:55:19.000000000,,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 14985}]","[{'number': 1, 'created': '2019-02-22 14:13:50.000000000', 'files': ['container-images/overcloud_containers.yaml', 'container-images/tripleo_kolla_template_overrides.j2', 'container-images/overcloud_containers.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/336167f60eeb3a5784b0227f80cfadb43da87490', 'message': 'Remove opendaylight container image build from Stein\n\nTransient failures on odl mirror affect gate jobs.\nodl can be safely removed from Stein release.\n\nChange-Id: I91a424f3fbe76b8ee518b24b3b7d12e299bb52d1\nCloses-Bug: #1817311\n'}]",0,638668,336167f60eeb3a5784b0227f80cfadb43da87490,2,3,1,8175,,,0,"Remove opendaylight container image build from Stein

Transient failures on odl mirror affect gate jobs.
odl can be safely removed from Stein release.

Change-Id: I91a424f3fbe76b8ee518b24b3b7d12e299bb52d1
Closes-Bug: #1817311
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/68/638668/1 && git format-patch -1 --stdout FETCH_HEAD,"['container-images/overcloud_containers.yaml', 'container-images/tripleo_kolla_template_overrides.j2', 'container-images/overcloud_containers.yaml.j2']",3,336167f60eeb3a5784b0227f80cfadb43da87490,remove-odl,,"{% if neutron_driver == ""odl"" %} - imagename: ""{{namespace}}/{{name_prefix}}neutron-server-opendaylight{{name_suffix}}:{{tag}}"" image_source: kolla params: - DockerNeutronApiImage - DockerNeutronConfigImage services: - OS::TripleO::Services::NeutronApi - OS::TripleO::Services::NeutronDhcpAgent - OS::TripleO::Services::NeutronMetadataAgent - OS::TripleO::Services::NeutronServer - OS::TripleO::Services::OpenDaylightApi {% if neutron_driver == ""odl"" %} - imagename: ""{{namespace}}/{{name_prefix}}opendaylight{{name_suffix}}:{{tag}}"" image_source: kolla params: - DockerOpendaylightApiImage - DockerOpendaylightConfigImage services: - OS::TripleO::Services::OpenDaylightApi {% endif %} ",0,46
openstack%2Fopenstack-ansible-lxc_hosts~master~Iff588cad451320167b92f2d79e4693a1037be966,openstack/openstack-ansible-lxc_hosts,master,Iff588cad451320167b92f2d79e4693a1037be966,Allow containers to remount volumes when needed,MERGED,2019-02-13 21:01:53.000000000,2019-02-22 15:35:33.000000000,2019-02-22 15:35:33.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-13 21:01:53.000000000', 'files': ['templates/lxc-openstack.apparmor.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/1fca76c8d39860c27d8c541a8fe300b427dfb129', 'message': 'Allow containers to remount volumes when needed\n\nThis change allows containers to mount and remount volumes as needed.\nBefore this change, when users had a mounted volume within a container,\nlike in the case of services using NFS or RBD, it was not possible to\nremount a volume within the container runtime. While a user could\nunmount and mount a volume or restart a container, these actions\nresults in service interuption where as a remount would simply\nreload the mounted volume without service interuption.\n\nChange-Id: Iff588cad451320167b92f2d79e4693a1037be966\nCloses-Bug: #1814200\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n'}]",0,636755,1fca76c8d39860c27d8c541a8fe300b427dfb129,6,2,1,7353,,,0,"Allow containers to remount volumes when needed

This change allows containers to mount and remount volumes as needed.
Before this change, when users had a mounted volume within a container,
like in the case of services using NFS or RBD, it was not possible to
remount a volume within the container runtime. While a user could
unmount and mount a volume or restart a container, these actions
results in service interuption where as a remount would simply
reload the mounted volume without service interuption.

Change-Id: Iff588cad451320167b92f2d79e4693a1037be966
Closes-Bug: #1814200
Signed-off-by: cloudnull <kevin@cloudnull.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/55/636755/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/lxc-openstack.apparmor.j2'],1,1fca76c8d39860c27d8c541a8fe300b427dfb129,bug/1814200," mount options=(rw,remount),",,1,0
openstack%2Fcinder~stable%2Fqueens~I93b8afeddae18d098fe926a3219811cc8c8d9b63,openstack/cinder,stable/queens,I93b8afeddae18d098fe926a3219811cc8c8d9b63,Handle rbd.OSError on broken RBD image,MERGED,2018-12-18 17:05:07.000000000,2019-02-22 15:32:05.000000000,2019-01-07 22:17:59.000000000,"[{'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 9236}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 15670}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21976}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28619}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-12-18 17:05:07.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/tests/unit/volume/drivers/test_rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3e174a0c4b574b3f53b5683852756b95c9a112fc', 'message': 'Handle rbd.OSError on broken RBD image\n\nWith Rocky, cinder-volume began to fail again with another error type.\nThis patch adds rbd.OSError type for exception block of\n_get_usage_info method.\n\nChange-Id: I93b8afeddae18d098fe926a3219811cc8c8d9b63\nCloses-Bug: 1698786\n(cherry picked from commit 9e8c45892205e54313cd414a3102aea5b5b199f4)\n(cherry picked from commit 71c99a85a0cc9ad4217428b316a13d3aa19ce1eb)\n'}]",0,625960,3e174a0c4b574b3f53b5683852756b95c9a112fc,23,21,1,6593,,,0,"Handle rbd.OSError on broken RBD image

With Rocky, cinder-volume began to fail again with another error type.
This patch adds rbd.OSError type for exception block of
_get_usage_info method.

Change-Id: I93b8afeddae18d098fe926a3219811cc8c8d9b63
Closes-Bug: 1698786
(cherry picked from commit 9e8c45892205e54313cd414a3102aea5b5b199f4)
(cherry picked from commit 71c99a85a0cc9ad4217428b316a13d3aa19ce1eb)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/60/625960/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/rbd.py', 'cinder/tests/unit/volume/drivers/test_rbd.py']",2,3e174a0c4b574b3f53b5683852756b95c9a112fc,bug/1698786-stable/rocky-stable/queens,"class MockOSErrorException(MockException): """"""Used as mock for rbd.OSError."""""" volumes = [ 'volume-1', 'non-existent', 'non-existent', 'non-cinder-volume' ] ImageNotFound=MockImageNotFoundException, OSError=MockOSErrorException): self.driver.rbd.OSError,"," volumes = ['volume-1', 'non-existent', 'non-cinder-volume'] ImageNotFound=MockImageNotFoundException):",14,3
openstack%2Ftripleo-ci~master~I1eba85e139c2ca298e05d33fc8479fc3572188c8,openstack/tripleo-ci,master,I1eba85e139c2ca298e05d33fc8479fc3572188c8,[WIP] [DNM] Add job to test scenario009 on standalone,ABANDONED,2019-02-07 09:38:14.000000000,2019-02-22 15:28:18.000000000,,"[{'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 13039}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-07 09:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/40d38147b4922a74f407435a38f6a52584a70b36', 'message': '[WIP] add job to test scenario009 on standalone\n\nDepends-On: Ic02c4f84d0bef71a904d42e02e3add08e24c7aee\nChange-Id: I1eba85e139c2ca298e05d33fc8479fc3572188c8\n'}, {'number': 2, 'created': '2019-02-07 16:49:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/aeb04d84f51647030a4ecda76c0b68207d49c43e', 'message': '[WIP] [DNM] Add job to test scenario009 on standalone\n\nDepends-On: https://review.openstack.org/#/c/635208/\nDepends-On: https://review.openstack.org/#/c/635461/\nChange-Id: I1eba85e139c2ca298e05d33fc8479fc3572188c8\n'}, {'number': 3, 'created': '2019-02-07 17:08:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5c0a88c40ea953e2cba672ab768e84b3512ff2e4', 'message': '[WIP] [DNM] Add job to test scenario009 on standalone\n\nDepends-On: https://review.openstack.org/#/c/635208/\nDepends-On: https://review.openstack.org/#/c/635461/\nChange-Id: I1eba85e139c2ca298e05d33fc8479fc3572188c8\n'}, {'number': 4, 'created': '2019-02-08 14:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/24925324d8c55b3ad273141f6b8395a904701f7b', 'message': '[WIP] [DNM] Add job to test scenario009 on standalone\n\nDepends-On: https://review.openstack.org/#/c/635208/\nDepends-On: https://review.openstack.org/#/c/635461/\nChange-Id: I1eba85e139c2ca298e05d33fc8479fc3572188c8\n'}, {'number': 5, 'created': '2019-02-11 19:55:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/004ca96e9fce7bf204d40d316c3dada7e2efd0c3', 'message': '[WIP] [DNM] Add job to test scenario009 on standalone\n\nDepends-On: https://review.openstack.org/#/c/635208/\nDepends-On: https://review.openstack.org/#/c/635461/\nChange-Id: I1eba85e139c2ca298e05d33fc8479fc3572188c8\n'}, {'number': 6, 'created': '2019-02-14 16:06:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9470b8fdfabfeca9cd2e817a85551e5b8de1f4cd', 'message': '[WIP] [DNM] Add job to test scenario009 on standalone\n\nDepends-On: https://review.openstack.org/#/c/635208/\nDepends-On: https://review.openstack.org/#/c/635461/\nChange-Id: I1eba85e139c2ca298e05d33fc8479fc3572188c8\n'}, {'number': 7, 'created': '2019-02-18 00:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f2cd02ede6cdd342bd3dfecc86ba18b43728e70b', 'message': '[WIP] [DNM] Add job to test scenario009 on standalone\n\nDepends-On: https://review.openstack.org/#/c/635208/\nDepends-On: https://review.openstack.org/#/c/635461/\nChange-Id: I1eba85e139c2ca298e05d33fc8479fc3572188c8\n'}, {'number': 8, 'created': '2019-02-18 00:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b4287d17724cf4815c011027d1505f789fce1c2b', 'message': '[WIP] [DNM] Add job to test scenario009 on standalone\n\nDepends-On: https://review.openstack.org/#/c/635208/\nDepends-On: https://review.openstack.org/#/c/635461/\nChange-Id: I1eba85e139c2ca298e05d33fc8479fc3572188c8\n'}, {'number': 9, 'created': '2019-02-18 05:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2c148cc7019afeeb1c8ccbab9aa3e0a00c89f172', 'message': '[WIP] [DNM] Add job to test scenario009 on standalone\n\nDepends-On: https://review.openstack.org/#/c/635208/\nDepends-On: https://review.openstack.org/#/c/635461/\nChange-Id: I1eba85e139c2ca298e05d33fc8479fc3572188c8\n'}, {'number': 10, 'created': '2019-02-19 16:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ebd8d86ee0ef7e189288c0c2a36ebda6837ec6ec', 'message': '[WIP] [DNM] Add job to test scenario009 on standalone\n\nDepends-On: https://review.openstack.org/#/c/635208/\nDepends-On: https://review.openstack.org/#/c/635461/\nChange-Id: I1eba85e139c2ca298e05d33fc8479fc3572188c8\n'}, {'number': 11, 'created': '2019-02-19 21:50:02.000000000', 'files': ['zuul.d/standalone-jobs.yaml', 'zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/19119126649ff81cd4ac3f6a32b233408852d3b3', 'message': '[WIP] [DNM] Add job to test scenario009 on standalone\n\nDepends-On: https://review.openstack.org/#/c/635208/\nDepends-On: https://review.openstack.org/#/c/635461/\nDepends-On: https://review.openstack.org/#/c/638018/\nChange-Id: I1eba85e139c2ca298e05d33fc8479fc3572188c8\n'}]",1,635464,19119126649ff81cd4ac3f6a32b233408852d3b3,63,5,11,10022,,,0,"[WIP] [DNM] Add job to test scenario009 on standalone

Depends-On: https://review.openstack.org/#/c/635208/
Depends-On: https://review.openstack.org/#/c/635461/
Depends-On: https://review.openstack.org/#/c/638018/
Change-Id: I1eba85e139c2ca298e05d33fc8479fc3572188c8
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/64/635464/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/standalone-jobs.yaml'],1,40d38147b4922a74f407435a38f6a52584a70b36,scenario009-standalone, name: tripleo-ci-centos-7-scenario009-standalone voting: true parent: tripleo-ci-base-standalone nodeset: single-centos-7-node branches: ^(?!stable/(newton|ocata|pike|queens|rocky)).*$ vars: featureset: '059' featureset_override: standalone_container_cli: docker standalone_environment_files: - 'environments/low-memory-usage.yaml' - 'ci/environments/scenario009-standalone.yaml' - 'environments/openshift.yaml' - job:,,15,0
openstack%2Ftripleo-ci~master~Idf7f13361a2ff2d5e92732c3cd7b36fe039aa1b8,openstack/tripleo-ci,master,Idf7f13361a2ff2d5e92732c3cd7b36fe039aa1b8,WIP - DNM - Test Scenario009 rocky,ABANDONED,2019-02-18 05:10:37.000000000,2019-02-22 15:27:45.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-18 05:10:37.000000000', 'files': ['zuul.d/standalone-jobs.yaml', 'zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a52e8674c8b6f6102f4368aeaa9cc05fe3478d00', 'message': 'WIP - DNM - Test Scenario009 rocky\n\nChange-Id: Idf7f13361a2ff2d5e92732c3cd7b36fe039aa1b8\nDepends-On: https://review.openstack.org/#/c/637443/\nDepends-On: https://review.openstack.org/#/c/635461/\n'}]",0,637454,a52e8674c8b6f6102f4368aeaa9cc05fe3478d00,4,2,1,9976,,,0,"WIP - DNM - Test Scenario009 rocky

Change-Id: Idf7f13361a2ff2d5e92732c3cd7b36fe039aa1b8
Depends-On: https://review.openstack.org/#/c/637443/
Depends-On: https://review.openstack.org/#/c/635461/
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/54/637454/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/standalone-jobs.yaml', 'zuul.d/layout.yaml']",2,a52e8674c8b6f6102f4368aeaa9cc05fe3478d00,scenario009-standalone-rocky, # templates: # - tripleo-standalone-scenarios-full # - tripleo-multinode-baremetal-full # - tripleo-multinode-container-full # - tripleo-multinode-experimental # - tripleo-undercloud-jobs # - tripleo-multinode-branchful # - tripleo-build-containers-jobs - tripleo-ci-centos-7-scenario009-standalone-rocky, templates: - tripleo-standalone-scenarios-full - tripleo-multinode-baremetal-full - tripleo-multinode-container-full - tripleo-multinode-experimental - tripleo-undercloud-jobs - tripleo-multinode-branchful - tripleo-build-containers-jobs,26,8
openstack%2Ftripleo-heat-templates~stable%2Frocky~Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc,openstack/tripleo-heat-templates,stable/rocky,Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc,[WIP] [DNM] translate scenario009 to standalone,ABANDONED,2019-02-18 00:25:39.000000000,2019-02-22 15:27:35.000000000,,"[{'_account_id': 10022}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-18 00:25:39.000000000', 'files': ['ci/environments/scenario009-standalone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fc691728e4d8c4f9f6f9fdc796a5885b9eff8c66', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}]",0,637443,fc691728e4d8c4f9f6f9fdc796a5885b9eff8c66,3,2,1,9976,,,0,"[WIP] [DNM] translate scenario009 to standalone

Testing scenario009

Change-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/43/637443/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario009-standalone.yaml'],1,fc691728e4d8c4f9f6f9fdc796a5885b9eff8c66,scenario009-standalone-stable/rocky,"resource_registry: OS::TripleO::Services::DisableUnbound: disable-unbound.yaml OS::TripleO::Services::OpenShift::Master: ../../extraconfig/services/openshift-master.yaml OS::TripleO::Services::OpenShift::Worker: ../../extraconfig/services/openshift-worker.yaml OS::TripleO::Services::OpenShift::Infra: ../../extraconfig/services/openshift-infra.yaml parameter_defaults: Debug: true OpenShiftNodeGroupName: 'node-config-all-in-one' OpenShiftGlobalVariables: # NOTE(flaper87): Needed for the gate openshift_disable_check: package_availability,package_version,disk_availability,docker_storage,memory_availability ",,12,0
openstack%2Ftripleo-quickstart-extras~master~Idb0810282d5fe0e34938544502272f980ad58465,openstack/tripleo-quickstart-extras,master,Idb0810282d5fe0e34938544502272f980ad58465,Add v3 project domain settings required for stacks/keypairs,ABANDONED,2018-10-18 16:20:34.000000000,2019-02-22 15:27:21.000000000,,"[{'_account_id': 10873}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-10-18 16:20:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/dbb7d8c16a1be7296ae0cf8f7ab3827fc2d6d537', 'message': 'Add v3 project domain settings required for stacks/keypairs\n\nWith testing upshift, we are required to use the V3 rc file.\nAs such we need to define project domain and project name.\n\nChange-Id: Idb0810282d5fe0e34938544502272f980ad58465\n'}, {'number': 2, 'created': '2018-10-18 18:22:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1e01575a398d04ebe199420e70693377fa7ee0b3', 'message': 'Add v3 project domain settings required for stacks/keypairs\n\nWith testing upshift, we are required to use the V3 rc file.\nAs such we need to define project domain and project name.\n\nChange-Id: Idb0810282d5fe0e34938544502272f980ad58465\n'}, {'number': 3, 'created': '2018-10-18 19:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/3adb3c99e415316b07a40671783cde4194d415b2', 'message': 'Add v3 project domain settings required for stacks/keypairs\n\nWith testing upshift, we are required to use the V3 rc file.\nAs such we need to define project domain and project name.\n\nChange-Id: Idb0810282d5fe0e34938544502272f980ad58465\n'}, {'number': 4, 'created': '2018-10-18 20:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/897d39822152db2a56a989415f2ffa7c291ac30e', 'message': 'Add v3 project domain settings required for stacks/keypairs\n\nWith testing upshift, we are required to use the V3 rc file.\nAs such we need to define project domain and project name.\n\nChange-Id: Idb0810282d5fe0e34938544502272f980ad58465\n'}, {'number': 5, 'created': '2018-10-18 20:20:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e1c0d205471972652c8fe47b9e16439b5cbc9cd0', 'message': 'Add v3 project domain settings required for stacks/keypairs\n\nWith testing upshift, we are required to use the V3 rc file.\nAs such we need to define project domain and project name.\n\nChange-Id: Idb0810282d5fe0e34938544502272f980ad58465\n'}, {'number': 6, 'created': '2018-10-18 20:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/2876277ce8861d6f62055b8d440877c4c3597d3e', 'message': 'Add v3 project domain settings required for stacks/keypairs\n\nWith testing upshift, we are required to use the V3 rc file.\nAs such we need to define project domain and project name.\n\nChange-Id: Idb0810282d5fe0e34938544502272f980ad58465\n'}, {'number': 7, 'created': '2018-10-18 20:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9cde3152d5defd6cd174f70bc1107d3caaa6ce17', 'message': 'Add v3 project domain settings required for stacks/keypairs\n\nWith testing upshift, we are required to use the V3 rc file.\nAs such we need to define project domain and project name.\n\nChange-Id: Idb0810282d5fe0e34938544502272f980ad58465\n'}, {'number': 8, 'created': '2018-10-18 23:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/043ae5e1c428bb59079ffb5a95f035a864d3e3d7', 'message': 'Add v3 project domain settings required for stacks/keypairs\n\nWith testing upshift, we are required to use the V3 rc file.\nAs such we need to define project domain and project name.\n\nChange-Id: Idb0810282d5fe0e34938544502272f980ad58465\n'}, {'number': 9, 'created': '2018-10-23 21:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/3754f3c34c9ade85682fba2a73cd174faa74d85d', 'message': 'Add v3 project domain settings required for stacks/keypairs\n\nWith testing upshift, we are required to use the V3 rc file.\nAs such we need to define project domain and project name.\n\nChange-Id: Idb0810282d5fe0e34938544502272f980ad58465\n'}, {'number': 10, 'created': '2018-10-31 13:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/fbc3d6013eff78a7d716b6a792d1fe8f25b88a9b', 'message': 'Add v3 project domain settings required for stacks/keypairs\n\nWith testing upshift, we are required to use the V3 rc file.\nAs such we need to define project domain and project name.\n\nChange-Id: Idb0810282d5fe0e34938544502272f980ad58465\n'}, {'number': 11, 'created': '2018-11-02 17:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/225590f89d567c5fab7a838e0285734f682e1c39', 'message': 'Add v3 project domain settings required for stacks/keypairs\n\nWith testing upshift, we are required to use the V3 rc file.\nAs such we need to define project domain and project name.\n\nChange-Id: Idb0810282d5fe0e34938544502272f980ad58465\n'}, {'number': 12, 'created': '2018-11-11 17:44:32.000000000', 'files': ['roles/ovb-manage-stack/tasks/ovb-delete-stack.yml', 'roles/ovb-manage-stack/templates/clouds.yaml.j2', 'roles/ovb-manage-stack/tasks/ovb-create-stack.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/2b79458cec85faf81c023c36e742fd3ad10d00d0', 'message': 'Add v3 project domain settings required for stacks/keypairs\n\nWith testing upshift, we are required to use the V3 rc file.\nAs such we need to define project domain and project name.\n\nChange-Id: Idb0810282d5fe0e34938544502272f980ad58465\n'}]",2,611674,2b79458cec85faf81c023c36e742fd3ad10d00d0,35,4,12,9976,,,0,"Add v3 project domain settings required for stacks/keypairs

With testing upshift, we are required to use the V3 rc file.
As such we need to define project domain and project name.

Change-Id: Idb0810282d5fe0e34938544502272f980ad58465
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/74/611674/6 && git format-patch -1 --stdout FETCH_HEAD,"['roles/ovb-manage-stack/tasks/ovb-delete-stack.yml', 'roles/ovb-manage-stack/templates/clouds.yaml.j2', 'roles/ovb-manage-stack/tasks/ovb-create-stack.yml']",3,dbb7d8c16a1be7296ae0cf8f7ab3827fc2d6d537,auth-v3-heat," export OS_USER_DOMAIN_NAME=""{{ os_user_domain_name | default('') }}"";",,3,0
openstack%2Ftripleo-heat-templates~master~Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc,openstack/tripleo-heat-templates,master,Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc,[WIP] [DNM] translate scenario009 to standalone,ABANDONED,2019-02-06 16:30:41.000000000,2019-02-22 15:25:45.000000000,,"[{'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 13039}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-06 16:30:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/13e3070a3859c9cee30c86e14094fc1ed5b57c12', 'message': '[WIP] translate scenario009 to standalone\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 2, 'created': '2019-02-07 16:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b5b2bfc5c0daf6b781bb94368de4426108766c70', 'message': '[WIP] translate scenario009 to standalone\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 3, 'created': '2019-02-07 17:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a9cbe016a46e81ddbf0aa9ee5b37b7c3991e3261', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 4, 'created': '2019-02-08 14:23:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3af5797afac6e9f5654253104b858bfb754531d1', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 5, 'created': '2019-02-11 13:35:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6bab1615fc772abf5fc2c640b1ff839b6143936b', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 6, 'created': '2019-02-11 18:00:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/77f0cda773788ae7cc5b2244108002a7311afb7b', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 7, 'created': '2019-02-11 19:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fa032aff368d8cdeea504cb76c65b03d82c57431', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 8, 'created': '2019-02-11 22:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0c792cbfc4ee58f7c9c5ed201f4a0a1d371ecd65', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 9, 'created': '2019-02-11 22:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/02cdceecb276cd4970ef1bf7602e77e35a0d2f9c', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 10, 'created': '2019-02-12 14:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/77d1ebb82ba1ca03c446f50b87797691cfb3771e', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 11, 'created': '2019-02-12 14:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9076e8e7fe70bc3dd4aa22da23950a1b1ee222fe', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 12, 'created': '2019-02-14 16:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9a5f2986a128cd7b29edac4a042553512150d247', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 13, 'created': '2019-02-14 19:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a6c68e8858b019b9dc9a2e9a7b15c6f8a5ef65d6', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 14, 'created': '2019-02-15 15:20:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3a27162fe38010ce759e8f910f5f5b7a4d61cf7a', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 15, 'created': '2019-02-15 18:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ee0c9a9c6116f09b58398ce9ae35e743366a9f73', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 16, 'created': '2019-02-18 00:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9b528c19276a3f0b36736e345e7ca1e53085aaa6', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 17, 'created': '2019-02-18 05:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a5321b34b9f5eb942ed5831fa9138f958bf62f7f', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 18, 'created': '2019-02-18 15:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/040dc10e4c81e112eeb2df2f1456ceb5db72fc3a', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}, {'number': 19, 'created': '2019-02-19 16:33:45.000000000', 'files': ['ci/environments/scenario009-standalone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f7f9615dd98ca23d146aa205cf29b4054116963d', 'message': '[WIP] [DNM] translate scenario009 to standalone\n\nTesting scenario009\n\nChange-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc\n'}]",3,635208,f7f9615dd98ca23d146aa205cf29b4054116963d,45,5,19,10022,,,0,"[WIP] [DNM] translate scenario009 to standalone

Testing scenario009

Change-Id: Id1e65c4f19c027cc52ecf320f2ec285ec9cbe9fc
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/08/635208/13 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario009-standalone.yaml'],1,13e3070a3859c9cee30c86e14094fc1ed5b57c12,scenario009-standalone,"resource_registry: OS::TripleO::Services::DisableUnbound: disable-unbound.yaml OS::TripleO::Controller::Net::SoftwareConfig: ../common/net-config-multinode.yaml OS::TripleO::Compute::Net::SoftwareConfig: ../common/net-config-multinode.yaml OS::TripleO::Services::OpenShift::Master: ../../extraconfig/services/openshift-master.yaml OS::TripleO::Services::OpenShift::Worker: ../../extraconfig/services/openshift-worker.yaml OS::TripleO::Services::OpenShift::Infra: ../../extraconfig/services/openshift-infra.yaml parameter_defaults: Debug: true OpenShiftNodeGroupName: 'node-config-all-in-one' OpenShiftGlobalVariables: # NOTE(flaper87): Needed for the gate openshift_disable_check: package_availability,package_version,disk_availability,docker_storage,memory_availability ",,17,0
openstack%2Ftripleo-quickstart~master~Ic02c4f84d0bef71a904d42e02e3add08e24c7aee,openstack/tripleo-quickstart,master,Ic02c4f84d0bef71a904d42e02e3add08e24c7aee,[WIP] [DNM] Add featureset openshift on standalone,ABANDONED,2019-02-07 09:35:54.000000000,2019-02-22 15:25:25.000000000,,"[{'_account_id': 9976}, {'_account_id': 13039}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-07 09:35:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/3ecc1253d2a20e7b67c531f90865ee475f36fcca', 'message': '[WIP] Add featureset openshift on standalone\n\nChange-Id: Ic02c4f84d0bef71a904d42e02e3add08e24c7aee\n'}, {'number': 2, 'created': '2019-02-07 16:47:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/59dd715b0fd1189e8a3998ae3837839f3d2ac0f9', 'message': '[WIP] Add featureset openshift on standalone\n\nChange-Id: Ic02c4f84d0bef71a904d42e02e3add08e24c7aee\n'}, {'number': 3, 'created': '2019-02-07 17:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/983d270de688af0a3766f2fbf94889d4ff1b7ff4', 'message': '[WIP] [DNM] Add featureset openshift on standalone\n\nTesting scenario009\n\nChange-Id: Ic02c4f84d0bef71a904d42e02e3add08e24c7aee\n'}, {'number': 4, 'created': '2019-02-08 14:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/4f8ffb65faabe2307ecb9a881d87b8edb0d0edda', 'message': '[WIP] [DNM] Add featureset openshift on standalone\n\nTesting scenario009\n\nChange-Id: Ic02c4f84d0bef71a904d42e02e3add08e24c7aee\n'}, {'number': 5, 'created': '2019-02-11 13:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/02074d6d9cdbc2df7abc2e061788b38b6b1bff09', 'message': '[WIP] [DNM] Add featureset openshift on standalone\n\nTesting scenario009\n\nChange-Id: Ic02c4f84d0bef71a904d42e02e3add08e24c7aee\n'}, {'number': 6, 'created': '2019-02-11 19:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/bc66ce2ee0e005af692c86448bc7a70008eaa50b', 'message': '[WIP] [DNM] Add featureset openshift on standalone\n\nTesting scenario009\n\nChange-Id: Ic02c4f84d0bef71a904d42e02e3add08e24c7aee\n'}, {'number': 7, 'created': '2019-02-14 16:06:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/677b866ed2f7f1fd83b39dd265f6e2b260bb5d16', 'message': '[WIP] [DNM] Add featureset openshift on standalone\n\nTesting scenario009\n\nChange-Id: Ic02c4f84d0bef71a904d42e02e3add08e24c7aee\n'}, {'number': 8, 'created': '2019-02-14 22:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/71476b09c8599c023993d1c1b3a57cb4ce4f854d', 'message': '[WIP] [DNM] Add featureset openshift on standalone\n\nTesting scenario009\n\nChange-Id: Ic02c4f84d0bef71a904d42e02e3add08e24c7aee\n'}, {'number': 9, 'created': '2019-02-15 14:23:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/8e9e1b4193de07ca3d30d21b8633010a05a3da2c', 'message': '[WIP] [DNM] Add featureset openshift on standalone\n\nTesting scenario009\n\nChange-Id: Ic02c4f84d0bef71a904d42e02e3add08e24c7aee\n'}, {'number': 10, 'created': '2019-02-19 13:48:09.000000000', 'files': ['zuul.d/layout.yaml', 'config/general_config/featureset059.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/b5b373a4e55da9da55cb427515633c0d25d818e3', 'message': '[WIP] [DNM] Add featureset openshift on standalone\n\nTesting scenario009\n\nChange-Id: Ic02c4f84d0bef71a904d42e02e3add08e24c7aee\n'}]",0,635461,b5b373a4e55da9da55cb427515633c0d25d818e3,39,5,10,10022,,,0,"[WIP] [DNM] Add featureset openshift on standalone

Testing scenario009

Change-Id: Ic02c4f84d0bef71a904d42e02e3add08e24c7aee
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/61/635461/5 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset059.yml'],1,3ecc1253d2a20e7b67c531f90865ee475f36fcca,scenario009-standalone,"# Featureset to test openshift with standalone deployed_server: true network_isolation: false enable_pacemaker: false overcloud_ipv6: false containerized_undercloud: true containerized_overcloud: true # This enables TLS for the undercloud which will also make haproxy bind to the # configured public-vip and admin-vip. undercloud_generate_service_certificate: false undercloud_enable_validations: false # This enables the deployment of the overcloud with SSL. ssl_overcloud: false # Centos Virt-SIG repo for atomic package add_repos: # NOTE(trown) The atomic package from centos-extras does not work for # us but its version is higher than the one from the virt-sig. Hence, # using priorities to ensure we get the virt-sig package. - type: package pkg_name: yum-plugin-priorities - type: generic reponame: quickstart-centos-paas filename: quickstart-centos-paas.repo baseurl: https://cbs.centos.org/repos/paas7-openshift-origin311-candidate/x86_64/os/ - type: generic reponame: quickstart-centos-virt-container filename: quickstart-centos-virt-container.repo baseurl: https://cbs.centos.org/repos/virt7-container-common-candidate/x86_64/os/ includepkgs: - atomic priority: 1 extra_args: '' container_args: >- {% if release in ['pike','queens'] -%} -e {{ overcloud_templates_path }}/environments/docker.yaml {%- endif -%} {% if release in ['ocata', 'pike', 'queens', 'rocky'] %} -e {{ working_dir }}/containers-default-parameters.yaml {% else %} -e {{ working_dir }}/containers-prepare-parameter.yaml {% endif %} -e {{ overcloud_templates_path }}/environments/openshift.yaml # NOTE(mandre) use container images mirrored on the dockerhub to take advantage # of the proxy setup by openstack infra docker_openshift_etcd_namespace: docker.io/{{ docker_registry_namespace }} docker_openshift_cluster_monitoring_namespace: docker.io/tripleomaster docker_openshift_cluster_monitoring_image: coreos-cluster-monitoring-operator docker_openshift_configmap_reload_namespace: docker.io/tripleomaster docker_openshift_configmap_reload_image: coreos-configmap-reload docker_openshift_prometheus_operator_namespace: docker.io/tripleomaster docker_openshift_prometheus_operator_image: coreos-prometheus-operator docker_openshift_prometheus_config_reload_namespace: docker.io/tripleomaster docker_openshift_prometheus_config_reload_image: coreos-prometheus-config-reloader docker_openshift_kube_rbac_proxy_namespace: docker.io/tripleomaster docker_openshift_kube_rbac_proxy_image: coreos-kube-rbac-proxy docker_openshift_kube_state_metrics_namespace: docker.io/tripleomaster docker_openshift_kube_state_metrics_image: coreos-kube-state-metrics deploy_steps_ansible_workflow: true config_download_args: >- -e {{ working_dir }}/config-download.yaml --disable-validations --verbose # If `run_tempest` is `true`, run tempests tests, otherwise do not # run them. tempest_config: false test_ping: false run_tempest: false ",,77,0
openstack%2Fgovernance~master~Ib50f4978db8057d05255bbcf144ac5adee0c1fef,openstack/governance,master,Ib50f4978db8057d05255bbcf144ac5adee0c1fef,Clarify TC goal-setting role,MERGED,2019-02-14 12:52:42.000000000,2019-02-22 15:20:40.000000000,2019-02-22 15:20:40.000000000,"[{'_account_id': 1736}, {'_account_id': 2472}, {'_account_id': 4257}, {'_account_id': 8099}, {'_account_id': 8556}, {'_account_id': 11564}, {'_account_id': 11655}, {'_account_id': 11904}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-14 12:52:42.000000000', 'files': ['reference/role-of-the-tc.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/da5556c526e48e7436bfc8d7c83fd7fa7d513e41', 'message': ""Clarify TC goal-setting role\n\nCurrent language did not make it clear enough that it is\npart of the TC's role to paint desirable, achievable goals\nfor our community as a whole, beyond just per-cycle release\ngoals.\n\nChange-Id: Ib50f4978db8057d05255bbcf144ac5adee0c1fef\n""}]",0,636948,da5556c526e48e7436bfc8d7c83fd7fa7d513e41,17,10,1,308,,,0,"Clarify TC goal-setting role

Current language did not make it clear enough that it is
part of the TC's role to paint desirable, achievable goals
for our community as a whole, beyond just per-cycle release
goals.

Change-Id: Ib50f4978db8057d05255bbcf144ac5adee0c1fef
",git fetch https://review.opendev.org/openstack/governance refs/changes/48/636948/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/role-of-the-tc.rst'],1,da5556c526e48e7436bfc8d7c83fd7fa7d513e41,formal-vote,"Defining global technical goals ===============================back, consider OpenStack as ""one platform"" that users and operators choose to leverage, and define reasonable technical goals for the OpenStack community as a whole. This includes looking at gaps between established project teams, driving a common user experience (common operational behavior, limited dependencies, base quality levels, minimum feature set...), pushing cross-project initiatives and influencing its general direction. One way to achieve that is through the definition of OpenStack :doc:`release goals <../goals/index>`.","Encouraging a unified OpenStack experience ==========================================back and consider OpenStack as ""one platform"" that users and operators choose to leverage. This includes looking at gaps between established project teams, driving a common user experience (common operational behavior, limited dependencies, base quality levels, minimum feature set...), pushing cross-project initiatives and influencing its general direction. One way to achieve that is through the definition of OpenStack :doc:`release goals <../goals/index>`. ",10,10
openstack%2Fopenstack-ansible-rabbitmq_server~master~I707a4eef58dd14ef5bc0161af15e20bb0c4bf977,openstack/openstack-ansible-rabbitmq_server,master,I707a4eef58dd14ef5bc0161af15e20bb0c4bf977,Remove the private option from include_role,MERGED,2019-02-22 00:50:24.000000000,2019-02-22 15:19:16.000000000,2019-02-22 15:19:15.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:50:24.000000000', 'files': ['tasks/install_apt.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/6c9c9aedf0dbc12236624e704b180ec1d0461292', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: I707a4eef58dd14ef5bc0161af15e20bb0c4bf977\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638559,6c9c9aedf0dbc12236624e704b180ec1d0461292,6,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: I707a4eef58dd14ef5bc0161af15e20bb0c4bf977
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/59/638559/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/install_apt.yml'],1,6c9c9aedf0dbc12236624e704b180ec1d0461292,fix/private/deprecation,, private: true,0,1
openstack%2Fopenstackdocstheme~master~I246cf11b851522722ee6a385b09fafd5363d244a,openstack/openstackdocstheme,master,I246cf11b851522722ee6a385b09fafd5363d244a,Silence!,MERGED,2019-02-22 14:48:21.000000000,2019-02-22 15:15:24.000000000,2019-02-22 15:15:24.000000000,"[{'_account_id': 6547}, {'_account_id': 10607}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 14:48:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/aadfe6556cae2b73acef68d03f20f6a748dc1c20', 'message': ""Silence!\n\nMy docs builds are suddenly full of messages like so:\n\n  [openstackdocstheme] Last updated for ??? is 2018-02-05 15:15:34\n\nWe should log when things go wrong - not when they're working as\nexpected. Drop this down to 'debug' level, hence hiding it except where\nnecessary.\n\nChange-Id: I246cf11b851522722ee6a385b09fafd5363d244a\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2019-02-22 14:48:58.000000000', 'files': ['openstackdocstheme/page_context.py'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/a9710dc5de8c65626d44ba874a96101f7090ccaf', 'message': ""Silence!\n\nMy docs builds are suddenly full of messages like so:\n\n  [openstackdocstheme] Last updated for ??? is 2018-02-05 15:15:34\n\nWe should log when things go wrong - not when they're working as\nexpected. Drop this down to 'debug' level, hence hiding it except where\nnecessary.\n\nChange-Id: I246cf11b851522722ee6a385b09fafd5363d244a\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,638675,a9710dc5de8c65626d44ba874a96101f7090ccaf,8,3,2,15334,,,0,"Silence!

My docs builds are suddenly full of messages like so:

  [openstackdocstheme] Last updated for ??? is 2018-02-05 15:15:34

We should log when things go wrong - not when they're working as
expected. Drop this down to 'debug' level, hence hiding it except where
necessary.

Change-Id: I246cf11b851522722ee6a385b09fafd5363d244a
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/75/638675/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackdocstheme/page_context.py'],1,aadfe6556cae2b73acef68d03f20f6a748dc1c20,silence, LOG.debug(, LOG.info(,1,1
openstack%2Ftripleo-heat-templates~master~I0aa1174992f6f049f1e64faea6d88e377d357bad,openstack/tripleo-heat-templates,master,I0aa1174992f6f049f1e64faea6d88e377d357bad,Don't look for primary_role ips in AllNodesValidationConfig,MERGED,2019-02-21 15:31:10.000000000,2019-02-22 15:14:36.000000000,2019-02-22 15:14:36.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-02-21 15:31:10.000000000', 'files': ['overcloud.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/95362173c2659e4f70d3cb4190d6512aee1d11ca', 'message': ""Don't look for primary_role ips in AllNodesValidationConfig\n\nWe changed the AllNodesValidationConfig to be role specific.\nHowever, we still use primary_role_name ips.\n\nChange-Id: I0aa1174992f6f049f1e64faea6d88e377d357bad\nCloses-Bug: #1817087\n""}]",0,638440,95362173c2659e4f70d3cb4190d6512aee1d11ca,12,5,1,8833,,,0,"Don't look for primary_role ips in AllNodesValidationConfig

We changed the AllNodesValidationConfig to be role specific.
However, we still use primary_role_name ips.

Change-Id: I0aa1174992f6f049f1e64faea6d88e377d357bad
Closes-Bug: #1817087
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/40/638440/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud.j2.yaml'],1,95362173c2659e4f70d3cb4190d6512aee1d11ca,bug/1817087," data: {get_attr: [{{role.name}}, ip_address]} data: {get_attr: [{{role.name}}, {{network.name_lower}}_ip_address]}"," data: {get_attr: [{{primary_role_name}}, ip_address]} data: {get_attr: [{{primary_role_name}}, {{network.name_lower}}_ip_address]}",2,2
openstack%2Foctavia-tempest-plugin~master~I1de7dfad3a430403a57514d30c62c579dc58f53e,openstack/octavia-tempest-plugin,master,I1de7dfad3a430403a57514d30c62c579dc58f53e,Update default provider to amphora,ABANDONED,2018-12-05 10:16:12.000000000,2019-02-22 15:07:10.000000000,,"[{'_account_id': 6469}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-05 10:16:12.000000000', 'files': ['octavia_tempest_plugin/config.py'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/2c7f4c505ceaa3c61c1a1f47865d3be1ed50fb2c', 'message': 'Update default provider to amphora\n\nThe introduction of provider drivers [1] deprecated the provider\n""octavia"" in favor of ""amphora"" via an alias. This patch updates the\ndefault provider driver to ""amphora"".\n\n[1] Change-Id I90dc39e5e9d7d5839913dc2dbf187d935ee2b8b5\n\nChange-Id: I1de7dfad3a430403a57514d30c62c579dc58f53e\n'}]",0,622917,2c7f4c505ceaa3c61c1a1f47865d3be1ed50fb2c,4,2,1,6469,,,0,"Update default provider to amphora

The introduction of provider drivers [1] deprecated the provider
""octavia"" in favor of ""amphora"" via an alias. This patch updates the
default provider driver to ""amphora"".

[1] Change-Id I90dc39e5e9d7d5839913dc2dbf187d935ee2b8b5

Change-Id: I1de7dfad3a430403a57514d30c62c579dc58f53e
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/17/622917/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia_tempest_plugin/config.py'],1,2c7f4c505ceaa3c61c1a1f47865d3be1ed50fb2c,," default='amphora',"," default='octavia',",1,1
openstack%2Fkeystone~master~Ia04323d7fa23cb8170e4e8426cae7a12ba7bf286,openstack/keystone,master,Ia04323d7fa23cb8170e4e8426cae7a12ba7bf286,Reuse common system role definitions for roles API,MERGED,2018-12-18 21:50:23.000000000,2019-02-22 15:00:22.000000000,2019-02-22 15:00:22.000000000,"[{'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-18 21:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3cf8510b6a3d60bd90a5e4bff45a5714c4be2a1e', 'message': 'Reuse common system role definitions for roles API\n\nWe recently merged some changes that define common system roles in\nbase.py. This commit reuses them for readable role operations.\n\nChange-Id: Ia04323d7fa23cb8170e4e8426cae7a12ba7bf286\n'}, {'number': 2, 'created': '2019-01-08 20:49:52.000000000', 'files': ['keystone/common/policies/role.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d437365444c58acba7e0bf2ef19a1fd82946c3f6', 'message': 'Reuse common system role definitions for roles API\n\nWe recently merged some changes that define common system roles in\nbase.py. This commit reuses them for readable role operations.\n\nChange-Id: Ia04323d7fa23cb8170e4e8426cae7a12ba7bf286\n'}]",0,626023,d437365444c58acba7e0bf2ef19a1fd82946c3f6,11,3,2,5046,,,0,"Reuse common system role definitions for roles API

We recently merged some changes that define common system roles in
base.py. This commit reuses them for readable role operations.

Change-Id: Ia04323d7fa23cb8170e4e8426cae7a12ba7bf286
",git fetch https://review.opendev.org/openstack/keystone refs/changes/23/626023/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/policies/role.py'],1,3cf8510b6a3d60bd90a5e4bff45a5714c4be2a1e,implement-default-roles," check_str=base.SYSTEM_READER, check_str=base.SYSTEM_READER,"," check_str='role:reader', check_str='role:reader',",2,2
openstack%2Ftripleo-heat-templates~stable%2Frocky~I3b9f0650cfa1024ef0d03741cd41b64ac0c258c3,openstack/tripleo-heat-templates,stable/rocky,I3b9f0650cfa1024ef0d03741cd41b64ac0c258c3,certmonger: Don't restart haproxy on cert renewal,MERGED,2019-02-22 08:46:06.000000000,2019-02-22 14:57:20.000000000,2019-02-22 14:57:20.000000000,"[{'_account_id': 10873}, {'_account_id': 17216}, {'_account_id': 17823}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-22 08:46:06.000000000', 'files': ['puppet/services/haproxy-public-tls-certmonger.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/82a648fcccef72f00b1ff273bac27904dcd4c2df', 'message': ""certmonger: Don't restart haproxy on cert renewal\n\nThis is not needed for the external cert. Reloading is enough.\n\nChange-Id: I3b9f0650cfa1024ef0d03741cd41b64ac0c258c3\nRelated-Bug: #1811401\n(cherry picked from commit 4cfa7c066fbb60303fd5287c38eb59ffa2a298ae)\n""}]",0,638604,82a648fcccef72f00b1ff273bac27904dcd4c2df,11,6,1,14250,,,0,"certmonger: Don't restart haproxy on cert renewal

This is not needed for the external cert. Reloading is enough.

Change-Id: I3b9f0650cfa1024ef0d03741cd41b64ac0c258c3
Related-Bug: #1811401
(cherry picked from commit 4cfa7c066fbb60303fd5287c38eb59ffa2a298ae)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/04/638604/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/haproxy-public-tls-certmonger.yaml'],1,82a648fcccef72f00b1ff273bac27904dcd4c2df,certmonger_post_save," postsave_cmd: ""/usr/bin/certmonger-haproxy-refresh.sh reload external"""," postsave_cmd: ""/usr/bin/certmonger-haproxy-refresh.sh restart external""",1,1
openstack%2Fkolla~master~I147385a3da15878121c0a436b5c26ba100e9802d,openstack/kolla,master,I147385a3da15878121c0a436b5c26ba100e9802d,"debian/ubuntu: drop mysql compat stuff, unify on openssl 1.1",MERGED,2018-12-14 11:30:50.000000000,2019-02-22 14:53:30.000000000,2019-02-22 14:53:30.000000000,"[{'_account_id': 8871}, {'_account_id': 13039}, {'_account_id': 14826}, {'_account_id': 16282}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23717}, {'_account_id': 24072}]","[{'number': 1, 'created': '2018-12-14 11:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2e790abf27851f4806caa08938d1a9db8568f9c8', 'message': ""debian/ubuntu: drop mysql compat stuff, unify on openssl 1.1\n\nNow with Ubuntu 'bionic' being used we can drop\nlibmysqlclient-compat-dev package use and just go with mariadb packages\ndirectly.\n\nAlso move to OpenSSL 1.1 for both distributions.\n\nChange-Id: I147385a3da15878121c0a436b5c26ba100e9802d\n""}, {'number': 2, 'created': '2019-02-19 12:54:38.000000000', 'files': ['docker/openstack-base/Dockerfile.j2', 'docker/kolla-toolbox/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/ba6d7540f6f2a779c03b7319158a89ae0fb04ec8', 'message': ""debian/ubuntu: drop mysql compat stuff, unify on openssl 1.1\n\nNow with Ubuntu 'bionic' being used we can drop\nlibmysqlclient-compat-dev package use and just go with mariadb packages\ndirectly.\n\nAlso move to OpenSSL 1.1 for both distributions.\n\nChange-Id: I147385a3da15878121c0a436b5c26ba100e9802d\n""}]",0,625219,ba6d7540f6f2a779c03b7319158a89ae0fb04ec8,23,9,2,24072,,,0,"debian/ubuntu: drop mysql compat stuff, unify on openssl 1.1

Now with Ubuntu 'bionic' being used we can drop
libmysqlclient-compat-dev package use and just go with mariadb packages
directly.

Also move to OpenSSL 1.1 for both distributions.

Change-Id: I147385a3da15878121c0a436b5c26ba100e9802d
",git fetch https://review.opendev.org/openstack/kolla refs/changes/19/625219/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/openstack-base/Dockerfile.j2', 'docker/kolla-toolbox/Dockerfile.j2']",2,2e790abf27851f4806caa08938d1a9db8568f9c8,625298," 'libmariadbclient-dev',", {% if base_arch == 'aarch64' and base_distro == 'ubuntu' %} {% set kolla_toolbox_packages = kolla_toolbox_packages + [ 'libmysqlclient-dev' ] %} {% else %} {% set kolla_toolbox_packages = kolla_toolbox_packages + [ 'libmariadbclient-dev' ] %} {% endif %} # Debian/stretch ships libmysqlclient.so in separate package {% if base_distro == 'debian' %} {% set kolla_toolbox_packages = kolla_toolbox_packages + [ 'libmariadbclient-dev-compat' ] %} {% endif %} ,3,39
openstack%2Fcharm-glance~stable%2F18.11~Iaaea4907ce4ef9d1e17b8ef9719e8bb0e0001946,openstack/charm-glance,stable/18.11,Iaaea4907ce4ef9d1e17b8ef9719e8bb0e0001946,upgrade: preserve glance-registry for Queens,MERGED,2019-02-22 11:36:07.000000000,2019-02-22 14:53:05.000000000,2019-02-22 14:53:05.000000000,"[{'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 11:36:07.000000000', 'files': ['hooks/glance_utils.py', 'unit_tests/test_glance_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/c71044ca0b36285ad790fec45e0ff9c7d7e0866b', 'message': 'upgrade: preserve glance-registry for Queens\n\nThe glance-registry daemon was deprecated at Queens, but was still\ninstalled for the Queens charm release; ensure that any re-install\nof paste.ini files accomodates this as part of the charm upgrade\nprocess, resolving issues with glance-registry not running due to\nmissing paste configuration files.\n\nChange-Id: Iaaea4907ce4ef9d1e17b8ef9719e8bb0e0001946\nCloses-Bug: 1812972\n(cherry picked from commit c24e2cf4230550741ab057eb891e9b12d6741b64)\n'}]",0,638634,c71044ca0b36285ad790fec45e0ff9c7d7e0866b,9,4,1,935,,,0,"upgrade: preserve glance-registry for Queens

The glance-registry daemon was deprecated at Queens, but was still
installed for the Queens charm release; ensure that any re-install
of paste.ini files accomodates this as part of the charm upgrade
process, resolving issues with glance-registry not running due to
missing paste configuration files.

Change-Id: Iaaea4907ce4ef9d1e17b8ef9719e8bb0e0001946
Closes-Bug: 1812972
(cherry picked from commit c24e2cf4230550741ab057eb891e9b12d6741b64)
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/34/638634/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/glance_utils.py', 'unit_tests/test_glance_utils.py']",2,c71044ca0b36285ad790fec45e0ff9c7d7e0866b,bug/1812972," packages=['glance-api', 'glance-registry'],"," packages=['glance-api'],",4,5
openstack%2Ftripleo-quickstart-extras~master~I5349d25636133b99e8df107c8939fe9218519286,openstack/tripleo-quickstart-extras,master,I5349d25636133b99e8df107c8939fe9218519286,Add note to zuul reproducer readme about the ssh key (-m PEM),ABANDONED,2019-02-20 12:44:25.000000000,2019-02-22 14:46:00.000000000,,"[{'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-20 12:44:25.000000000', 'files': ['roles/create-zuul-based-reproducer/templates/README-reproducer-zuul-based-quickstart.html.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/11aea368dec60390f991fa7b40b0303556008fa1', 'message': 'Add note to zuul reproducer readme about the ssh key (-m PEM)\n\nAdd note in README about the keys created for the reproducer\nhttps://github.com/paramiko/paramiko/issues/1015\n\nChange-Id: I5349d25636133b99e8df107c8939fe9218519286\n'}]",4,638140,11aea368dec60390f991fa7b40b0303556008fa1,9,8,1,8449,,,0,"Add note to zuul reproducer readme about the ssh key (-m PEM)

Add note in README about the keys created for the reproducer
https://github.com/paramiko/paramiko/issues/1015

Change-Id: I5349d25636133b99e8df107c8939fe9218519286
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/40/638140/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/create-zuul-based-reproducer/templates/README-reproducer-zuul-based-quickstart.html.j2'],1,11aea368dec60390f991fa7b40b0303556008fa1,,"Note: until <a href=""https://github.com/paramiko/paramiko/issues/1015"">this paramiko issue </a> is fixed, you must include <code>-m PEM</code> to your key generation options, for example <code>ssh-keygen -m PEM -t rsa</code> <li>Check that you have access to the publicly shared nodepool images: There should be one image called <code>upstream-infra-centos-7</code> for CentOS 7, and one called <code>upstream-infra-fedora-28</code> for Fedora 28.</li>","<li>Check that you have access to the publicly shared nodepool images: There should be one image for CentOS 7, and one for Fedora 28.</li>",5,1
openstack%2Fkolla~master~Ibe4c459d60f1143c76657588ed9c0081bda92239,openstack/kolla,master,Ibe4c459d60f1143c76657588ed9c0081bda92239,nova: Only install OVMF on EL 7 when installing from source,MERGED,2019-02-21 12:03:14.000000000,2019-02-22 14:21:42.000000000,2019-02-22 14:21:42.000000000,"[{'_account_id': 13039}, {'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 12:03:14.000000000', 'files': ['docker/nova/nova-base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/cbcd2efe71c5ab447fba9b0a5b4dd5f1b2c18b2e', 'message': 'nova: Only install OVMF on EL 7 when installing from source\n\nThis use case was missed in Ic8f865ed9cfc89056991ce4fa50a99c4937af33b.\n\nChange-Id: Ibe4c459d60f1143c76657588ed9c0081bda92239\n'}]",0,638402,cbcd2efe71c5ab447fba9b0a5b4dd5f1b2c18b2e,7,3,1,10135,,,0,"nova: Only install OVMF on EL 7 when installing from source

This use case was missed in Ic8f865ed9cfc89056991ce4fa50a99c4937af33b.

Change-Id: Ibe4c459d60f1143c76657588ed9c0081bda92239
",git fetch https://review.opendev.org/openstack/kolla refs/changes/02/638402/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/nova/nova-base/Dockerfile.j2'],1,cbcd2efe71c5ab447fba9b0a5b4dd5f1b2c18b2e,," {% if base_distro in ['centos', 'oraclelinux', 'rhel'] and base_distro_tag.startswith('7') %} {% set nova_base_packages = nova_base_packages + [ 'OVMF' ] %} {% endif %} {% if base_distro in ['centos', 'oraclelinux', 'rhel'] and base_distro_tag.startswith('7') %} {% set nova_base_packages = nova_base_packages + [ 'AAVMF' ] %} {% endif %}", {% set nova_base_packages = nova_base_packages + [ 'OVMF' ] %} {% set nova_base_packages = nova_base_packages + [ 'AAVMF' ] %},10,6
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I3b9f0650cfa1024ef0d03741cd41b64ac0c258c3,openstack/tripleo-heat-templates,stable/queens,I3b9f0650cfa1024ef0d03741cd41b64ac0c258c3,certmonger: Don't restart haproxy on cert renewal,MERGED,2019-02-22 08:52:35.000000000,2019-02-22 14:09:10.000000000,2019-02-22 14:09:09.000000000,"[{'_account_id': 10873}, {'_account_id': 17216}, {'_account_id': 17823}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-22 08:52:35.000000000', 'files': ['puppet/services/haproxy-public-tls-certmonger.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f10d3c3d547153f3a6d6f469ff3c896a77729044', 'message': ""certmonger: Don't restart haproxy on cert renewal\n\nThis is not needed for the external cert. Reloading is enough.\n\nChange-Id: I3b9f0650cfa1024ef0d03741cd41b64ac0c258c3\nRelated-Bug: #1811401\n(cherry picked from commit 4cfa7c066fbb60303fd5287c38eb59ffa2a298ae)\n""}]",0,638607,f10d3c3d547153f3a6d6f469ff3c896a77729044,11,6,1,14250,,,0,"certmonger: Don't restart haproxy on cert renewal

This is not needed for the external cert. Reloading is enough.

Change-Id: I3b9f0650cfa1024ef0d03741cd41b64ac0c258c3
Related-Bug: #1811401
(cherry picked from commit 4cfa7c066fbb60303fd5287c38eb59ffa2a298ae)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/07/638607/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/haproxy-public-tls-certmonger.yaml'],1,f10d3c3d547153f3a6d6f469ff3c896a77729044,certmonger_post_save," postsave_cmd: ""/usr/bin/certmonger-haproxy-refresh.sh reload external"""," postsave_cmd: ""/usr/bin/certmonger-haproxy-refresh.sh restart external""",1,1
openstack%2Freleases~master~I1487b953c9c44c3d61c87282e36f1b6a654dd044,openstack/releases,master,I1487b953c9c44c3d61c87282e36f1b6a654dd044,release telemetry-tempest-plugin 0.2.0,MERGED,2019-02-20 09:57:05.000000000,2019-02-22 14:04:54.000000000,2019-02-22 14:04:54.000000000,"[{'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 11904}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-20 09:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/20826cbe1017e6fb652aed16a33c49aec2983864', 'message': 'release telemetry-tempest-plugin 0.2.0\n\nIt contains critical fixes for telemetry integration tests and is\nneeded in order to pass the tests.\n\nChange-Id: I1487b953c9c44c3d61c87282e36f1b6a654dd044\n'}, {'number': 2, 'created': '2019-02-20 16:02:24.000000000', 'files': ['deliverables/rocky/telemetry-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/222c7dbb6b5866bef9f032565c0547e754587115', 'message': 'release telemetry-tempest-plugin 0.2.0\n\nIt contains critical fixes for telemetry integration tests and is\nneeded in order to pass the tests.\n\nChange-Id: I1487b953c9c44c3d61c87282e36f1b6a654dd044\n'}]",1,638118,222c7dbb6b5866bef9f032565c0547e754587115,15,6,2,12393,,,0,"release telemetry-tempest-plugin 0.2.0

It contains critical fixes for telemetry integration tests and is
needed in order to pass the tests.

Change-Id: I1487b953c9c44c3d61c87282e36f1b6a654dd044
",git fetch https://review.opendev.org/openstack/releases refs/changes/18/638118/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/rocky/telemetry-tempest-plugin.yaml'],1,20826cbe1017e6fb652aed16a33c49aec2983864,telemetry, - projects: - hash: 7f0e315a78df17d981ed86ebddf87759cd97eedf repo: openstack/telemetry-tempest-plugin version: 0.2.0 flags: - forced,,6,0
openstack%2Freleases~master~I4eb64ec4156ee4c5bf639c15724619dc886e9ee2,openstack/releases,master,I4eb64ec4156ee4c5bf639c15724619dc886e9ee2,Release 9.1.0 for tripleo-ipsec,MERGED,2019-02-21 16:57:29.000000000,2019-02-22 13:53:15.000000000,2019-02-22 13:53:15.000000000,"[{'_account_id': 2472}, {'_account_id': 11904}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 16:57:29.000000000', 'files': ['deliverables/stein/tripleo-ipsec.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/0af400c94764ac75ea777281f98b7719c7d24540', 'message': 'Release 9.1.0 for tripleo-ipsec\n\nChange-Id: I4eb64ec4156ee4c5bf639c15724619dc886e9ee2\n'}]",0,638463,0af400c94764ac75ea777281f98b7719c7d24540,7,4,1,10873,,,0,"Release 9.1.0 for tripleo-ipsec

Change-Id: I4eb64ec4156ee4c5bf639c15724619dc886e9ee2
",git fetch https://review.opendev.org/openstack/releases refs/changes/63/638463/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/stein/tripleo-ipsec.yaml'],1,0af400c94764ac75ea777281f98b7719c7d24540,ipsec-release,releases: - projects: - hash: f60ad6c2010e9a65a993fbda9a35bf2a656c73d7 repo: openstack/tripleo-ipsec version: 9.1.0,,5,0
openstack%2Freleases~master~Id355ca258075fd158cdf5bdbc1a361864765d8ba,openstack/releases,master,Id355ca258075fd158cdf5bdbc1a361864765d8ba,Release telemetry-tempest-plugin 0.0.1 for queens,ABANDONED,2019-02-20 16:09:27.000000000,2019-02-22 13:52:54.000000000,,"[{'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-20 16:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/529ef646e0a4535f17f95ffed34252769656eb7e', 'message': 'Release telemetry-tempest-plugin 0.2.0 for queens\n\nSince this release contains critical fixes for telemetry\nintegration which got broken during tempest plugin migration and\nalso avoids pinning in RDO side.\n\nChange-Id: Id355ca258075fd158cdf5bdbc1a361864765d8ba\n'}, {'number': 2, 'created': '2019-02-20 16:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/aeb732b78494facaa05553c0b8a4a9655b4fe6ac', 'message': 'Release telemetry-tempest-plugin 0.0.1 for queens\n\nSince this release contains critical fixes for telemetry\nintegration which got broken during tempest plugin migration and\nalso avoids pinning in RDO side.\n\nkeeping the version 0.0.1 for queens as 0.1.0 and 0.2.0 is already\nused for other releases.\n\nChange-Id: Id355ca258075fd158cdf5bdbc1a361864765d8ba\n'}, {'number': 3, 'created': '2019-02-21 13:17:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/8daf37cda4ca57bbfffdd3d19c66d7a4b26bde46', 'message': 'Release telemetry-tempest-plugin 0.0.1 for queens\n\nSince this release contains critical fixes for telemetry\nintegration which got broken during tempest plugin migration and\nalso avoids pinning in RDO side.\n\nkeeping the version 0.0.1 for queens as 0.1.0 and 0.2.0 is already\nused for other releases.\n\nMoving it under deliverables/_independent in order to publish it\n\nChange-Id: Id355ca258075fd158cdf5bdbc1a361864765d8ba\n'}, {'number': 4, 'created': '2019-02-21 16:32:11.000000000', 'files': ['deliverables/_independent/telemetry-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/b1fc4df30831188d0bb470a7a9fec9cc3f3a1054', 'message': 'Release telemetry-tempest-plugin 0.0.1 for queens\n\nSince this release contains critical fixes for telemetry\nintegration which got broken during tempest plugin migration and\nalso avoids pinning in RDO side.\n\nkeeping the version 0.0.1 for queens as 0.1.0 and 0.2.0 is already\nused for other releases.\n\nMoving it under deliverables/_independent in order to publish it\n\nChange-Id: Id355ca258075fd158cdf5bdbc1a361864765d8ba\n'}]",1,638191,b1fc4df30831188d0bb470a7a9fec9cc3f3a1054,13,4,4,12393,,,0,"Release telemetry-tempest-plugin 0.0.1 for queens

Since this release contains critical fixes for telemetry
integration which got broken during tempest plugin migration and
also avoids pinning in RDO side.

keeping the version 0.0.1 for queens as 0.1.0 and 0.2.0 is already
used for other releases.

Moving it under deliverables/_independent in order to publish it

Change-Id: Id355ca258075fd158cdf5bdbc1a361864765d8ba
",git fetch https://review.opendev.org/openstack/releases refs/changes/91/638191/4 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/telemetry-tempest-plugin.yaml'],1,529ef646e0a4535f17f95ffed34252769656eb7e,telemetry_queens,--- launchpad: ceilometer include-pypi-link: no release-model: cycle-with-intermediary release-type: python-pypi releases: - projects: - hash: 7f0e315a78df17d981ed86ebddf87759cd97eedf repo: openstack/telemetry-tempest-plugin version: 0.2.0 repository-settings: openstack/telemetry-tempest-plugin: tarball-base: telemetry_tempest_plugin team: Telemetry type: tempest-plugin ,,15,0
openstack%2Ftripleo-heat-templates~stable%2Frocky~Ie39f753494d87b7cfab28d92fc6783db012cc10f,openstack/tripleo-heat-templates,stable/rocky,Ie39f753494d87b7cfab28d92fc6783db012cc10f,Upgrades: Ensure idempotency of pacemaker services,MERGED,2019-02-21 10:29:40.000000000,2019-02-22 13:46:47.000000000,2019-02-22 13:46:47.000000000,"[{'_account_id': 8042}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2019-02-21 10:29:40.000000000', 'files': ['docker/services/pacemaker/cinder-volume.yaml', 'docker/services/pacemaker/cinder-backup.yaml', 'docker/services/pacemaker/manila-share.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f56814ebe92f4f8a6e66984d8f612d3d6962b491', 'message': 'Upgrades: Ensure idempotency of pacemaker services\n\nThe fact is_bootstrap_node has to be always present regardless the\nstate of containerization of the service.\n\nChange-Id: Ie39f753494d87b7cfab28d92fc6783db012cc10f\nResolves: rhbz#1652205\nCloses-Bug: #1804488\n(cherry picked from commit a3a7099a37663eaee15828c08b14f1212534de03)\n'}]",1,638384,f56814ebe92f4f8a6e66984d8f612d3d6962b491,9,5,1,11166,,,0,"Upgrades: Ensure idempotency of pacemaker services

The fact is_bootstrap_node has to be always present regardless the
state of containerization of the service.

Change-Id: Ie39f753494d87b7cfab28d92fc6783db012cc10f
Resolves: rhbz#1652205
Closes-Bug: #1804488
(cherry picked from commit a3a7099a37663eaee15828c08b14f1212534de03)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/84/638384/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/pacemaker/cinder-volume.yaml', 'docker/services/pacemaker/cinder-backup.yaml', 'docker/services/pacemaker/manila-share.yaml']",3,f56814ebe92f4f8a6e66984d8f612d3d6962b491,bug/1804488, - name: Manila-Share baremetal to container upgrade tasks when: - step|int == 1 - not manila_share_containerized|bool block:, - name: Manila-Share baremetal to container upgrade tasks when: - step|int == 1 - not manila_share_containerized|bool block:,15,15
openstack%2Fnova~stable%2Fqueens~I779a17afade78997ab084909a9e6a46b0f91f055,openstack/nova,stable/queens,I779a17afade78997ab084909a9e6a46b0f91f055,tox: Don't write byte code (maybe),MERGED,2019-02-14 10:46:39.000000000,2019-02-22 13:46:41.000000000,2019-02-22 13:46:41.000000000,"[{'_account_id': 6873}, {'_account_id': 10135}, {'_account_id': 14070}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-14 10:46:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/df24e3b9c8b93ae49f3d639f18d0494f2445041c', 'message': ""tox: Don't write byte code (maybe)\n\nIn tox versions after 3.0.0rc1 [1], setting the environment variable\nPYTHONDONTWRITEBYTECODE will cause tox not to write .pyc files, which\nmeans you don't have to delete them, which makes things faster.\n\nIn older tox versions, the env var is ignored.\n\nIf we bump the minimum tox version to something later than 3.0.0rc1, we\ncan remove the commands that find and remove .pyc files.\n\nConflicts:\n\ttox.ini\n\nNOTE(stephenfin): Conflict is due to a number of unrelated changes made\nduring Rocky, such as Idda28f153d5054efc885ef2bde0989841df29cd3.\n\n[1] https://github.com/tox-dev/tox/commit/336f4f6bd8b53223f940fc5cfc43b1bbd78d4699\n\nChange-Id: I779a17afade78997ab084909a9e6a46b0f91f055\n(cherry picked from commit 590a2b6bbf71294d187d7082cc302069797db029)\n(cherry picked from commit 99f0c4c0144a551f0fa7f3a8847327660e5ccb89)\n""}]",0,636918,df24e3b9c8b93ae49f3d639f18d0494f2445041c,11,6,1,15334,,,0,"tox: Don't write byte code (maybe)

In tox versions after 3.0.0rc1 [1], setting the environment variable
PYTHONDONTWRITEBYTECODE will cause tox not to write .pyc files, which
means you don't have to delete them, which makes things faster.

In older tox versions, the env var is ignored.

If we bump the minimum tox version to something later than 3.0.0rc1, we
can remove the commands that find and remove .pyc files.

Conflicts:
	tox.ini

NOTE(stephenfin): Conflict is due to a number of unrelated changes made
during Rocky, such as Idda28f153d5054efc885ef2bde0989841df29cd3.

[1] https://github.com/tox-dev/tox/commit/336f4f6bd8b53223f940fc5cfc43b1bbd78d4699

Change-Id: I779a17afade78997ab084909a9e6a46b0f91f055
(cherry picked from commit 590a2b6bbf71294d187d7082cc302069797db029)
(cherry picked from commit 99f0c4c0144a551f0fa7f3a8847327660e5ccb89)
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/636918/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,df24e3b9c8b93ae49f3d639f18d0494f2445041c,PYTHONDONTWRITEBYTECODE, # NOTE(efried): This is only effective in tox versions after 3.0.0rc1 # https://github.com/tox-dev/tox/commit/336f4f6bd8b53223f940fc5cfc43b1bbd78d4699 PYTHONDONTWRITEBYTECODE=1,,3,0
openstack%2Fnova~stable%2Fqueens~I6915b7deca20eabb88c231b287586c64cdcf3646,openstack/nova,stable/queens,I6915b7deca20eabb88c231b287586c64cdcf3646,Migrate nova v2.0 legacy job to zuulv3,MERGED,2018-11-28 11:47:43.000000000,2019-02-22 13:46:32.000000000,2019-02-22 13:46:32.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 8556}, {'_account_id': 9373}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-11-28 11:47:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/318c3b937f35128c22ddba09ad0c1b8083842d66', 'message': 'Migrate nova v2.0 legacy job to zuulv3\n\nThis commit migrate the legacy-tempest-dsvm-nova-v20-api\njob to zullv3 native with new job - tempest-nova-v2-api\n\nChange-Id: I6915b7deca20eabb88c231b287586c64cdcf3646\n(cherry picked from commit f7a4ba969abdeb6b307ca4052da317b7c0b2ec3f)\n'}, {'number': 2, 'created': '2018-11-28 12:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9f7b14d60c8fa22e3827e9900f53ad4f8fc9ef5', 'message': 'Migrate nova v2.0 legacy job to zuulv3\n\nThis commit migrate the legacy-tempest-dsvm-nova-v20-api\njob to zullv3 native with new job - tempest-nova-v2-api\n\nConflicts:\n      .zuul.yaml\n\nThe conflict is due to Ife046b91c96dd300e8c46125b75623d8e12b8da3\n\nChange-Id: I6915b7deca20eabb88c231b287586c64cdcf3646\n(cherry picked from commit f7a4ba969abdeb6b307ca4052da317b7c0b2ec3f)\n'}, {'number': 3, 'created': '2019-01-25 08:36:21.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/2e3f30ac4de35d3ca19531bcd8480c5497963278', 'message': 'Migrate nova v2.0 legacy job to zuulv3\n\nThis commit migrate the legacy-tempest-dsvm-nova-v20-api\njob to zullv3 native with new job - tempest-nova-v2-api\n\nConflicts:\n      .zuul.yaml\n\nThe conflict is due to Ife046b91c96dd300e8c46125b75623d8e12b8da3\n\nChange-Id: I6915b7deca20eabb88c231b287586c64cdcf3646\n(cherry picked from commit f7a4ba969abdeb6b307ca4052da317b7c0b2ec3f)\n'}]",0,620578,2e3f30ac4de35d3ca19531bcd8480c5497963278,37,12,3,8556,,,0,"Migrate nova v2.0 legacy job to zuulv3

This commit migrate the legacy-tempest-dsvm-nova-v20-api
job to zullv3 native with new job - tempest-nova-v2-api

Conflicts:
      .zuul.yaml

The conflict is due to Ife046b91c96dd300e8c46125b75623d8e12b8da3

Change-Id: I6915b7deca20eabb88c231b287586c64cdcf3646
(cherry picked from commit f7a4ba969abdeb6b307ca4052da317b7c0b2ec3f)
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/620578/3 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,318c3b937f35128c22ddba09ad0c1b8083842d66,zuulv3-nova,- job: name: tempest-nova-v2-api parent: devstack-tempest branches: - master description: | This job runs the Tempest compute tests against v2.0 endpoint. Former names for this job was: * legacy-tempest-dsvm-nova-v20-api vars: tox_envlist: all tempest_test_regex: api.*compute devstack_localrc: TEMPEST_COMPUTE_TYPE: compute_legacy - tempest-nova-v2-api:, - legacy-tempest-dsvm-nova-v20-api:,16,1
openstack%2Fpython-tripleoclient~master~I40ee028366222f38f5ba1db58d171f98be75d009,openstack/python-tripleoclient,master,I40ee028366222f38f5ba1db58d171f98be75d009,Remove execution from workflow message send,MERGED,2019-01-15 13:18:23.000000000,2019-02-22 13:20:13.000000000,2019-02-22 13:20:13.000000000,"[{'_account_id': 7509}, {'_account_id': 9712}, {'_account_id': 10873}, {'_account_id': 11082}, {'_account_id': 14985}, {'_account_id': 15895}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-15 13:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6a8cd4b2cb8f13821e032096a6f85e29f9d54ac1', 'message': 'WIP Remove execution from workflow message send\n\nSerializing all the execution in a message can make the message too big.\nThis change was done in tripleo-common. this supports that change\n\nChange-Id: I40ee028366222f38f5ba1db58d171f98be75d009\nDepends-on: I010ea5d732aba97a554e868f62a19e6fdaee8889\n'}, {'number': 2, 'created': '2019-01-16 09:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/114de04d7e83c31677aa9e3af5091611d9943604', 'message': 'Remove execution from workflow message send\n\nSerializing all the execution in a message can make the message too big.\nThis change was done in tripleo-common. this supports that change\nThis change still supports the old format and is backwards compatible.\n\nChange-Id: I40ee028366222f38f5ba1db58d171f98be75d009\nDepends-on: I010ea5d732aba97a554e868f62a19e6fdaee8889\n'}, {'number': 3, 'created': '2019-01-17 08:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b93c24857a8318e60226c88d359860a7305b96ac', 'message': 'Remove execution from workflow message send\n\nSerializing all the execution in a message can make the message too big.\nThis change was done in tripleo-common. this supports that change\nThis change still supports the old format and is backwards compatible.\n\nPartial-Bug: #1812172\nChange-Id: I40ee028366222f38f5ba1db58d171f98be75d009\n'}, {'number': 4, 'created': '2019-01-21 08:26:25.000000000', 'files': ['tripleoclient/tests/v1/test_overcloud_plan_roles.py', 'tripleoclient/tests/v1/test_overcloud_plan.py', 'tripleoclient/tests/workflows/test_parameters.py', 'tripleoclient/tests/workflows/test_baremetal.py', 'tripleoclient/tests/workflows/test_base.py', 'tripleoclient/workflows/base.py', 'tripleoclient/tests/v1/overcloud_node/test_overcloud_node.py', 'tripleoclient/tests/test_plugin.py', 'tripleoclient/tests/workflows/test_plan_management.py', 'tripleoclient/tests/fakes.py', 'tripleoclient/tests/v1/test_overcloud_raid.py', 'tripleoclient/tests/test_overcloud_credentials.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/cad7916ce8d21295992c2efe0e18657c6e56604d', 'message': 'Remove execution from workflow message send\n\nSerializing all the execution in a message can make the message too big.\nThis change was done in tripleo-common. this supports that change\nThis change still supports the old format and is backwards compatible.\n\nPartial-Bug: #1812172\nChange-Id: I40ee028366222f38f5ba1db58d171f98be75d009\n'}]",13,630970,cad7916ce8d21295992c2efe0e18657c6e56604d,29,8,4,15895,,,0,"Remove execution from workflow message send

Serializing all the execution in a message can make the message too big.
This change was done in tripleo-common. this supports that change
This change still supports the old format and is backwards compatible.

Partial-Bug: #1812172
Change-Id: I40ee028366222f38f5ba1db58d171f98be75d009
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/70/630970/4 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/workflows/base.py'],1,6a8cd4b2cb8f13821e032096a6f85e29f9d54ac1,bug/1812172," if payload['execution_id'] != execution.id and \ payload.get('root_execution_id', '') != \ if payload['execution_id'] != execution.id:"," if payload['execution']['id'] != execution.id and \ payload['execution'].get('root_execution_id', '') != \ if payload['execution']['id'] != execution.id:",3,3
openstack%2Felection~master~I7dd2872418c1e65dabdd19f599724b9356a6d209,openstack/election,master,I7dd2872418c1e65dabdd19f599724b9356a6d209,Remove myself as an election official,MERGED,2019-02-22 05:12:43.000000000,2019-02-22 13:17:37.000000000,2019-02-22 13:17:37.000000000,"[{'_account_id': 5263}, {'_account_id': 12898}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 05:12:43.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/election/commit/6d41814a33d3e14be962f062baf560a87d632df2', 'message': ""Remove myself as an election official\n\nI find myself somewhat unexpectedly in a position that creates a\nconflict of interest with being an election official.  I'll resign for\nnow and see what the future holds\n\nChange-Id: I7dd2872418c1e65dabdd19f599724b9356a6d209\n""}]",0,638582,6d41814a33d3e14be962f062baf560a87d632df2,8,4,1,12898,,,0,"Remove myself as an election official

I find myself somewhat unexpectedly in a position that creates a
conflict of interest with being an election official.  I'll resign for
now and see what the future holds

Change-Id: I7dd2872418c1e65dabdd19f599724b9356a6d209
",git fetch https://review.opendev.org/openstack/election refs/changes/82/638582/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,6d41814a33d3e14be962f062baf560a87d632df2,no-more-tonyb,,"* Tony Breeds (tonyb), tony at bakeyournoodle dot com",0,1
openstack%2Fproject-config~master~I359cba6880db8a52fff803727da265fe9552bb96,openstack/project-config,master,I359cba6880db8a52fff803727da265fe9552bb96,Add publish to pypi job for stackviz,ABANDONED,2019-02-22 07:38:42.000000000,2019-02-22 12:46:15.000000000,,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 07:38:42.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/01939afa342b6216e3a62a21eda1080b8c77ec03', 'message': 'Add publish to pypi job for stackviz\n\nChange-Id: I359cba6880db8a52fff803727da265fe9552bb96\n'}]",0,638602,01939afa342b6216e3a62a21eda1080b8c77ec03,4,2,1,12393,,,0,"Add publish to pypi job for stackviz

Change-Id: I359cba6880db8a52fff803727da265fe9552bb96
",git fetch https://review.opendev.org/openstack/project-config refs/changes/02/638602/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,01939afa342b6216e3a62a21eda1080b8c77ec03,, name: openstack/stackviz templates: - publish-to-pypi - project:,,5,0
openstack%2Fstackviz~master~I2444d4ee615fa93ae6f3e304f221224221f9949c,openstack/stackviz,master,I2444d4ee615fa93ae6f3e304f221224221f9949c,Remove legacy stackviz pypi job and switch to publish to pypi,ABANDONED,2019-02-22 07:33:09.000000000,2019-02-22 12:46:11.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-22 07:33:09.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/stackviz/commit/cbdc76960f0d97ab9c7b745f07dfa561ffc8d7ac', 'message': 'Remove legacy stackviz pypi job and switch to publish to pypi\n\nChange-Id: I2444d4ee615fa93ae6f3e304f221224221f9949c\n'}]",0,638600,cbdc76960f0d97ab9c7b745f07dfa561ffc8d7ac,3,1,1,12393,,,0,"Remove legacy stackviz pypi job and switch to publish to pypi

Change-Id: I2444d4ee615fa93ae6f3e304f221224221f9949c
",git fetch https://review.opendev.org/openstack/stackviz refs/changes/00/638600/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,cbdc76960f0d97ab9c7b745f07dfa561ffc8d7ac,,, periodic: jobs: - legacy-periodic-package-stackviz-element,0,3
openstack%2Fopenstack-zuul-jobs~master~I864bd11683d78424f06cff26f432e24b83aa7649,openstack/openstack-zuul-jobs,master,I864bd11683d78424f06cff26f432e24b83aa7649,Remove periodic-package-stackviz-element job,ABANDONED,2019-02-22 07:23:33.000000000,2019-02-22 12:46:08.000000000,,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 07:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/9f5fb81d7b2328feaae043dbd3e731e641d09d6a', 'message': 'Remove periodic-package-stackviz-element job\n\nCurrently there are two tarballs getting published related to\nstackviz.\nhttp://tarballs.openstack.org/package-stackviz-element/ and\nhttp://tarballs.openstack.org/stackviz/\nFirst one is the correct tarball and second one has missing\nhtml files. but the namespace is not correct\nand in order to have a correct tarball, we are removing the\nlegacy jobs and moving it to a single job under\npublish-to-pypi.\n\nChange-Id: I864bd11683d78424f06cff26f432e24b83aa7649\n'}, {'number': 2, 'created': '2019-02-22 07:34:07.000000000', 'files': ['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/periodic-package-stackviz-element/run.yaml', 'playbooks/legacy/periodic-package-stackviz-element/post.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/1584e524ed592d702606545dfb8c5ac386bb5a97', 'message': 'Remove periodic-package-stackviz-element job\n\nCurrently there are two tarballs getting published related to\nstackviz.\nhttp://tarballs.openstack.org/package-stackviz-element/ and\nhttp://tarballs.openstack.org/stackviz/\nFirst one is the correct tarball and second one has missing\nhtml files. but the namespace is not correct\nand in order to have a correct tarball, we are removing the\nlegacy jobs and moving it to a single job under\npublish-to-pypi.\n\nDepends-on: https://review.openstack.org/#/c/638600/\nChange-Id: I864bd11683d78424f06cff26f432e24b83aa7649\n'}]",0,638598,1584e524ed592d702606545dfb8c5ac386bb5a97,6,2,2,12393,,,0,"Remove periodic-package-stackviz-element job

Currently there are two tarballs getting published related to
stackviz.
http://tarballs.openstack.org/package-stackviz-element/ and
http://tarballs.openstack.org/stackviz/
First one is the correct tarball and second one has missing
html files. but the namespace is not correct
and in order to have a correct tarball, we are removing the
legacy jobs and moving it to a single job under
publish-to-pypi.

Depends-on: https://review.openstack.org/#/c/638600/
Change-Id: I864bd11683d78424f06cff26f432e24b83aa7649
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/98/638598/2 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/periodic-package-stackviz-element/run.yaml', 'playbooks/legacy/periodic-package-stackviz-element/post.yaml']",3,9f5fb81d7b2328feaae043dbd3e731e641d09d6a,stackviz_tarball,,- hosts: primary tasks: - name: Ensure artifacts directory exists file: path: '{{ zuul.executor.work_root }}/artifacts' state: directory delegate_to: localhost - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.work_root }}/artifacts/' mode: pull copy_links: true verify_host: true rsync_opts: - --include=/dist/*.tar.gz - --include=*/ - --exclude=* - --prune-empty-dirs ,0,90
openstack%2Fcharm-ceilometer~stable%2F18.11~I5b55f31adcf2b069ff51e387a416f9f1ac4099f8,openstack/charm-ceilometer,stable/18.11,I5b55f31adcf2b069ff51e387a416f9f1ac4099f8,Make event_sink publisher configurable,MERGED,2019-02-20 08:51:43.000000000,2019-02-22 12:22:33.000000000,2019-02-22 12:22:33.000000000,"[{'_account_id': 6737}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-20 08:51:43.000000000', 'files': ['unit_tests/test_ceilometer_contexts.py', 'templates/queens/event_pipeline.yaml', 'config.yaml', 'lib/ceilometer_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-ceilometer/commit/b03fe9696d316bfa47d7f416c9671c1f50ef64f8', 'message': 'Make event_sink publisher configurable\n\nThe charm currently configures events to be published to\nrabbit on both the config.event_topic (event.sample queue)\nand alarm topic but as of Queens Ceilometer no longer\nconsumes event.sample. This patch makes the event_sink\npublishers configurable and defaults to publishing to\naodh to retain backwards compatibility.\n\nChange-Id: I5b55f31adcf2b069ff51e387a416f9f1ac4099f8\nPartial-Bug: #1676586\n(cherry picked from commit d398cdff364ba07a7f18f59417bb4f3af5cccbc3)\n'}]",0,638107,b03fe9696d316bfa47d7f416c9671c1f50ef64f8,11,4,1,6737,,,0,"Make event_sink publisher configurable

The charm currently configures events to be published to
rabbit on both the config.event_topic (event.sample queue)
and alarm topic but as of Queens Ceilometer no longer
consumes event.sample. This patch makes the event_sink
publishers configurable and defaults to publishing to
aodh to retain backwards compatibility.

Change-Id: I5b55f31adcf2b069ff51e387a416f9f1ac4099f8
Partial-Bug: #1676586
(cherry picked from commit d398cdff364ba07a7f18f59417bb4f3af5cccbc3)
",git fetch https://review.opendev.org/openstack/charm-ceilometer refs/changes/07/638107/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_ceilometer_contexts.py', 'templates/queens/event_pipeline.yaml', 'config.yaml', 'lib/ceilometer_contexts.py']",4,b03fe9696d316bfa47d7f416c9671c1f50ef64f8,bug/1676586," log, INFO, WARNING, get_os_codename_package, release = get_os_codename_package('ceilometer-common', fatal=False) ctxt['event_sink_publisher'] = None if CompareOpenStackReleases(release) >= 'queens': # NOTE: see bug LP 1676586 if config('events-publisher') == ""aodh"": ctxt['event_sink_publisher'] = 'notifier://?topic=alarm.all' elif config('events-publisher') == ""gnocchi"": if relation_ids('metric-service'): ctxt['event_sink_publisher'] = 'gnocchi://' else: log(""Unable to configure event publisher '{}' since "" ""no gnocchi relation found"". format(config('events-publisher')), level=INFO) elif config('events-publisher') == """": log(""Not configuring any event publishers"", level=INFO) else: log(""Invalid event publisher config provided '{}'. Not "" ""configuring any event publishers"". format(config('events-publisher')), level=WARNING) ",,137,11
openstack%2Ftripleo-heat-templates~stable%2Frocky~I27cbc8fa13f23651ec5b22e71dba157c2aa1db5b,openstack/tripleo-heat-templates,stable/rocky,I27cbc8fa13f23651ec5b22e71dba157c2aa1db5b,Add CertmongerUser role to OVB defaults,MERGED,2019-02-21 10:19:18.000000000,2019-02-22 12:20:23.000000000,2019-02-22 12:20:23.000000000,"[{'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 14250}, {'_account_id': 17216}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-21 10:19:18.000000000', 'files': ['ci/environments/ovb-ha.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3e5484c619b1ea502a6b1dbadc767bd3ff18a63b', 'message': 'Add CertmongerUser role to OVB defaults\n\nConflicts:\n      ci/environments/ovb-ha.yaml\n\nChange-Id: I27cbc8fa13f23651ec5b22e71dba157c2aa1db5b\n(cherry picked from commit 8b69c6b584ea5a9c81e5e7880e6de22613421cc1)\n'}]",0,638378,3e5484c619b1ea502a6b1dbadc767bd3ff18a63b,12,6,1,10873,,,0,"Add CertmongerUser role to OVB defaults

Conflicts:
      ci/environments/ovb-ha.yaml

Change-Id: I27cbc8fa13f23651ec5b22e71dba157c2aa1db5b
(cherry picked from commit 8b69c6b584ea5a9c81e5e7880e6de22613421cc1)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/78/638378/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/ovb-ha.yaml'],1,3e5484c619b1ea502a6b1dbadc767bd3ff18a63b,backport-certmonger-ci, - OS::TripleO::Services::CertmongerUser - OS::TripleO::Services::CertmongerUser,,2,0
openstack%2Fnetworking-ovn~master~I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf,openstack/networking-ovn,master,I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf,Add support for Member Batch Update,MERGED,2018-09-26 07:14:12.000000000,2019-02-22 12:07:13.000000000,2019-02-22 12:07:12.000000000,"[{'_account_id': 5756}, {'_account_id': 6773}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 10237}, {'_account_id': 17776}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 23858}]","[{'number': 1, 'created': '2018-09-26 07:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/ff6e4b4f11b96bd5e902fdf7f3ff19d5e9f027f1', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 2, 'created': '2018-11-14 10:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e516c7e2ff349363e4107d73a4342e0d89fad657', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 3, 'created': '2018-11-15 10:49:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/8657e38a3c58b1a98512b1748e1f68e380e97757', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 4, 'created': '2018-11-26 11:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/0cc635ea2b104eadcf9d655075c6473640b173bc', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 5, 'created': '2018-11-29 07:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/dd605727c1d99b4afaaa090b5ccf34a3fa33b0dc', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 6, 'created': '2018-11-29 08:09:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/26903781a5d6117069d0266557d6dabd7f008b59', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 7, 'created': '2018-11-29 09:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/4410f63fb0f4183885aece387d5fd8fe7ffe08b8', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 8, 'created': '2018-12-05 08:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e5db248b2b95a057f433c1395bc5a5547fcc2e4c', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\nloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 9, 'created': '2018-12-05 08:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/208a6b666a891dd5475a81412a7489512d0aeb3e', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 10, 'created': '2018-12-06 11:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/570afe8bccec4b1965829772671acc35d0d08934', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 11, 'created': '2018-12-12 08:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/8b737281a2fdc191a9b800bd96c4a0795495a4e4', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 12, 'created': '2018-12-21 06:21:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/1179be4c9d7677403202e9668ff48584e32124a5', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 13, 'created': '2019-01-14 14:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/be0007bb61b3170e5d16ce9a385ae5686ac124f2', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 14, 'created': '2019-01-17 07:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b48903b809445f27faac3e147d40f4c82caa9ef4', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 15, 'created': '2019-01-17 10:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/7c037bc5b31bf679443ffefa8dda375ffd843dda', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 16, 'created': '2019-01-17 16:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/6bb96ba6b50f274788f6713f350637a69a305d3b', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 17, 'created': '2019-01-18 10:10:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/349b6dea807e888c9088425f4fb41f49b5d2a85e', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 18, 'created': '2019-01-21 10:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/4a47099c7aabfe9e8ccfeca2c52fd75f30fdf2e1', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 19, 'created': '2019-01-21 10:09:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/5b4d36c29ff025abc7ec5511d1273aeb4b157df6', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 20, 'created': '2019-01-21 13:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/fdcfbc15b0745925c9ceed099404fa61bbc2bc93', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 21, 'created': '2019-02-18 06:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/cee74e7a85bd8c41d26af48db1f2f53439def2b5', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 22, 'created': '2019-02-21 06:36:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/35dab4a1648047deadf64bf22d4dd9b8f9e771e6', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}, {'number': 23, 'created': '2019-02-21 09:54:26.000000000', 'files': ['networking_ovn/octavia/ovn_driver.py', 'networking_ovn/tests/functional/octavia/test_ovn_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e89a8a25633117c2bed2fd87a2451a571d33cb62', 'message': 'Add support for Member Batch Update\n\nCurrently the member batch update is not in supported in the same\nmanner as is expected by Octavia.\nThis patch fixes the same.\n\nCloses-Bug: #1806844\nChange-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf\n'}]",68,605343,e89a8a25633117c2bed2fd87a2451a571d33cb62,83,9,23,17776,,,0,"Add support for Member Batch Update

Currently the member batch update is not in supported in the same
manner as is expected by Octavia.
This patch fixes the same.

Closes-Bug: #1806844
Change-Id: I8678392b953b92f1dd6cd5d44c1d5bcee6cc92bf
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/43/605343/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/octavia/ovn_driver.py'],1,ff6e4b4f11b96bd5e902fdf7f3ff19d5e9f027f1,bug/1806844,"REQ_TYPE_MEMBER_BATCH_UPDATE = 'member_batch_update'LB_EXT_IDS_MEMBER_PREFIX = 'member_' REQ_TYPE_MEMBER_BATCH_UPDATE: self.member_batch_update, LOG.exception('Exception during pool update') member_info = LB_EXT_IDS_MEMBER_PREFIX + member['id'] + ""-"" member_info += member['address'] + "":"" + str(member['protocol_port']) member_info = LB_EXT_IDS_MEMBER_PREFIX + member['id'] + ""-"" member_info += member['address'] + "":"" + str(member['protocol_port']) def member_batch_update(self, member): pool_id = member['pool_id'] pool_key = self._get_pool_key(pool_id) ovn_lb = self._find_ovn_lb_with_pool_key(pool_key) if not ovn_lb: pool_key = self._get_pool_key(member['pool_id'], is_enabled=False) ovn_lb = self._find_ovn_lb_with_pool_key(pool_key) external_ids = dict(ovn_lb.external_ids) existing_members = external_ids[pool_key] if not existing_members: # Matches scenario where pool has no member self.member_create(member) else: for mem_info in existing_members.split(','): addr_port = member['address'] + "":"" + member['protocol_port'] if addr_port == mem_info.split('-')[1]: self.member_update(member) else: request_info = {'id': mem_info.split('-')[0], 'address': mem_info.split( '-')[1].split(':')[0], 'protocol_port': mem_info.split( '-')[1].split(':')[1], 'pool_id': pool_id} request = {'type': REQ_TYPE_MEMBER_DELETE, 'info': request_info} self.member_delete(request) # As per https://developer.openstack.org/api-ref/ # load-balancer/v2/index.html#batch-update-members, # existing members are matched based on address/port combination. LOG.debug(""Called Member Batch Update"") skipped_members = '' for member in members: if member.monitor_address or member.monitor_port: skipped_members += member.member_id continue admin_state_up = member.admin_state_up if isinstance(admin_state_up, o_datamodels.UnsetType): admin_state_up = True request_info = {'id': member.member_id, 'address': member.address, 'protocol_port': member.protocol_port, 'pool_id': member.pool_id, 'subnet_id': member.subnet_id, 'admin_state_up': admin_state_up} request = {'type': REQ_TYPE_MEMBER_BATCH_UPDATE, 'info': request_info} self._ovn_helper.add_request(request) if skipped_members != '': msg = _('OVN provider does not support monitor options, ' 'so following members skipped: %s') % skipped_members raise driver_exceptions.UnsupportedOptionError( user_fault_string=msg, operator_fault_string=msg)"," LOG.exception('Exception during pool delete') member_info = member['address'] + "":"" + str( member['protocol_port']) member_info = member['address'] + "":"" + str( member['protocol_port']) for member in members: self.member_update(member, member)",63,6
openstack%2Fkolla-ansible~master~I824ff00f6b86aac3eab5dc6fd01728653b4661d1,openstack/kolla-ansible,master,I824ff00f6b86aac3eab5dc6fd01728653b4661d1,Fix location of hostdirs for Murano services,MERGED,2019-02-20 14:54:58.000000000,2019-02-22 11:59:18.000000000,2019-02-22 11:53:13.000000000,"[{'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 21691}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 28239}]","[{'number': 1, 'created': '2019-02-20 14:54:58.000000000', 'files': ['ansible/roles/murano/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ff28cf5069598b6d0c4dc5ce95d29f988d751354', 'message': 'Fix location of hostdirs for Murano services\n\nUse ""{{ node_config_directory }}/murano-api/"" for `murano-api` and\n""{{ node_config_directory }}/murano-engine/"" for `murano-engine`, so\ncorrect `config.json` are mounted in containers.\n\nChange-Id: I824ff00f6b86aac3eab5dc6fd01728653b4661d1\nCloses-Bug: 1811716\n'}]",0,638176,ff28cf5069598b6d0c4dc5ce95d29f988d751354,15,6,1,25277,,,0,"Fix location of hostdirs for Murano services

Use ""{{ node_config_directory }}/murano-api/"" for `murano-api` and
""{{ node_config_directory }}/murano-engine/"" for `murano-engine`, so
correct `config.json` are mounted in containers.

Change-Id: I824ff00f6b86aac3eab5dc6fd01728653b4661d1
Closes-Bug: 1811716
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/76/638176/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/murano/defaults/main.yml'],1,ff28cf5069598b6d0c4dc5ce95d29f988d751354,bug/1811716," - ""{{ node_config_directory }}/murano-api/:{{ container_config_directory }}/:ro"" - ""{{ node_config_directory }}/murano-engine/:{{ container_config_directory }}/:ro"""," - ""{{ node_config_directory }}/murano-engine/:{{ container_config_directory }}/:ro"" - ""{{ node_config_directory }}/murano-api/:{{ container_config_directory }}/:ro""",2,2
openstack%2Fpython-ironicclient~master~Ib97ee888c4a7b6dfa38934f02372284aa4c781a0,openstack/python-ironicclient,master,Ib97ee888c4a7b6dfa38934f02372284aa4c781a0,Allocation API: client API and CLI,MERGED,2019-02-12 15:25:15.000000000,2019-02-22 11:50:04.000000000,2019-02-22 11:50:04.000000000,"[{'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 14826}, {'_account_id': 18320}, {'_account_id': 22348}, {'_account_id': 24828}, {'_account_id': 26340}]","[{'number': 1, 'created': '2019-02-12 15:25:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/f0f18cf9d210ff6786397d8c399468d3e3cdd4c9', 'message': '[WIP] Allocation API: client API and CLI\n\nChange-Id: Ib97ee888c4a7b6dfa38934f02372284aa4c781a0\nStory: #2004341\nTask: #28028\n'}, {'number': 2, 'created': '2019-02-12 16:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/79f655cc58347a901ae981bc0d7c996673f91f7c', 'message': 'Allocation API: client API and CLI\n\nAdds the Python API to create/list/view/delete allocations, as well\nas the OpenStackClient commands.\n\nChange-Id: Ib97ee888c4a7b6dfa38934f02372284aa4c781a0\nStory: #2004341\nTask: #28028\n'}, {'number': 3, 'created': '2019-02-12 16:47:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/f5db12771bbe7617be3e29a58e4b800ee1385b14', 'message': 'Allocation API: client API and CLI\n\nAdds the Python API to create/list/view/delete allocations, as well\nas the OpenStackClient commands.\n\nChange-Id: Ib97ee888c4a7b6dfa38934f02372284aa4c781a0\nStory: #2004341\nTask: #28028\n'}, {'number': 4, 'created': '2019-02-12 16:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/9babebb0a07fb3024cb17c6bb43b4bde4866482e', 'message': 'Allocation API: client API and CLI\n\nAdds the Python API to create/list/view/delete allocations, as well\nas the OpenStackClient commands.\n\nChange-Id: Ib97ee888c4a7b6dfa38934f02372284aa4c781a0\nStory: #2004341\nTask: #28028\n'}, {'number': 5, 'created': '2019-02-15 10:27:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/7618e9f81ec21fdfe1a4033862bd49a8838650a7', 'message': 'Allocation API: client API and CLI\n\nAdds the Python API to create/list/view/delete allocations, as well\nas the OpenStackClient commands.\n\nChange-Id: Ib97ee888c4a7b6dfa38934f02372284aa4c781a0\nStory: #2004341\nTask: #28028\n'}, {'number': 6, 'created': '2019-02-15 12:54:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/a00cbb5a7668b1e68c2964c79f7758f767746b5e', 'message': 'Allocation API: client API and CLI\n\nAdds the Python API to create/list/view/delete allocations, as well\nas the OpenStackClient commands.\n\nChange-Id: Ib97ee888c4a7b6dfa38934f02372284aa4c781a0\nStory: #2004341\nTask: #28028\n'}, {'number': 7, 'created': '2019-02-16 14:55:31.000000000', 'files': ['ironicclient/tests/unit/osc/v1/fakes.py', 'ironicclient/v1/node.py', 'ironicclient/tests/unit/v1/test_node_shell.py', 'ironicclient/tests/unit/v1/test_allocation.py', 'releasenotes/notes/allocation-api-5f13082a8b36d788.yaml', 'doc/source/cli/osc/v1/index.rst', 'ironicclient/v1/resource_fields.py', 'ironicclient/osc/v1/baremetal_allocation.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_node.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_allocation.py', 'ironicclient/v1/allocation.py', 'ironicclient/tests/functional/osc/v1/base.py', 'ironicclient/v1/client.py', 'setup.cfg', 'ironicclient/common/utils.py', 'ironicclient/tests/functional/osc/v1/test_baremetal_allocation.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/e0708a16efa48d872a9f088af856809f523f03dc', 'message': 'Allocation API: client API and CLI\n\nAdds the Python API to create/list/view/delete allocations, as well\nas the OpenStackClient commands.\n\nChange-Id: Ib97ee888c4a7b6dfa38934f02372284aa4c781a0\nStory: #2004341\nTask: #28028\n'}]",25,636354,e0708a16efa48d872a9f088af856809f523f03dc,27,8,7,10239,,,0,"Allocation API: client API and CLI

Adds the Python API to create/list/view/delete allocations, as well
as the OpenStackClient commands.

Change-Id: Ib97ee888c4a7b6dfa38934f02372284aa4c781a0
Story: #2004341
Task: #28028
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/54/636354/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/v1/node.py', 'ironicclient/tests/unit/v1/test_allocation.py', 'ironicclient/v1/allocation.py', 'ironicclient/common/utils.py']",4,f0f18cf9d210ff6786397d8c399468d3e3cdd4c9,story/2004341,"import time def poll(timeout, poll_interval, poll_delay_function, timeout_message): if not isinstance(timeout, (int, float)) or timeout < 0: raise ValueError(_('Timeout must be a non-negative number')) threshold = time.time() + timeout poll_delay_function = (time.sleep if poll_delay_function is None else poll_delay_function) if not callable(poll_delay_function): raise TypeError(_('poll_delay_function must be callable')) count = 0 while not timeout or time.time() < threshold: yield count poll_delay_function(poll_interval) count += 1 raise exc.StateTransitionTimeout(timeout_message)",,498,17
openstack%2Frequirements~master~I6292cdc97051b7f742aa8d9d8d987fc6ed9e707c,openstack/requirements,master,I6292cdc97051b7f742aa8d9d8d987fc6ed9e707c,Updated from generate-constraints,MERGED,2019-02-20 06:26:10.000000000,2019-02-22 11:49:38.000000000,2019-02-22 11:49:38.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-20 06:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4edd3ced8ede993224c40ab97f44582b76a560d6', 'message': 'Updated from generate-constraints\n\nChange-Id: I6292cdc97051b7f742aa8d9d8d987fc6ed9e707c\n'}, {'number': 2, 'created': '2019-02-21 06:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/7b4d96dffdf69f5eb013929062177df2fc90f4eb', 'message': 'Updated from generate-constraints\n\nChange-Id: I6292cdc97051b7f742aa8d9d8d987fc6ed9e707c\n'}, {'number': 3, 'created': '2019-02-21 06:47:58.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5d06d110acf4d58ef8612d188bc908fb9c4a74ea', 'message': 'Updated from generate-constraints\n\nChange-Id: I6292cdc97051b7f742aa8d9d8d987fc6ed9e707c\n'}]",0,638091,5d06d110acf4d58ef8612d188bc908fb9c4a74ea,16,2,3,11131,,,0,"Updated from generate-constraints

Change-Id: I6292cdc97051b7f742aa8d9d8d987fc6ed9e707c
",git fetch https://review.opendev.org/openstack/requirements refs/changes/91/638091/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,4edd3ced8ede993224c40ab97f44582b76a560d6,openstack/requirements/constraints/noclob,google-auth===1.6.3tornado===4.5.3;python_version=='3.4' tornado===4.5.3;python_version=='3.5' tornado===4.5.3;python_version=='3.6' tornado===5.1.1;python_version=='2.7'prometheus-client===0.6.0cassandra-driver===3.17.0opentracing===2.0.0salt===2018.3.3botocore===1.12.98pyzmq===18.0.0,google-auth===1.6.2tornado===4.5.3prometheus-client===0.5.0cassandra-driver===3.16.0opentracing===1.3.0salt===2018.3.2botocore===1.12.97pyzmq===17.1.2,11,8
openstack%2Fpython-freezerclient~master~I6938f835b62222f3ca71e554cda0854edc1ed4d7,openstack/python-freezerclient,master,I6938f835b62222f3ca71e554cda0854edc1ed4d7,Update json module to jsonutils,MERGED,2019-02-21 06:12:29.000000000,2019-02-22 11:47:18.000000000,2019-02-22 11:47:18.000000000,"[{'_account_id': 13940}, {'_account_id': 22348}, {'_account_id': 22484}]","[{'number': 1, 'created': '2019-02-21 06:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/710009a0caf099f44eb2c8e1b161ec74499026d4', 'message': 'Update json module to jsonutils\n\njson is deprecated, should use oslo_serialization.jsonutils\ninstead.\n\nChange-Id: I6938f835b62222f3ca71e554cda0854edc1ed4d7\n'}, {'number': 2, 'created': '2019-02-21 09:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/4e5ad5dacd4dacf00dee91e50e2117dbf98b2a2f', 'message': 'Update json module to jsonutils\n\njson is deprecated, should use oslo_serialization.jsonutils\ninstead.\n\nChange-Id: I6938f835b62222f3ca71e554cda0854edc1ed4d7\n'}, {'number': 3, 'created': '2019-02-21 11:00:26.000000000', 'files': ['freezerclient/v2/managers/sessions.py', 'freezerclient/v2/managers/jobs.py', 'freezerclient/tests/unit/v1/test_client_sessions.py', 'freezerclient/v1/managers/sessions.py', 'lower-constraints.txt', 'freezerclient/utils.py', 'freezerclient/tests/unit/v1/test_client_jobs.py', 'freezerclient/v1/managers/actions.py', 'freezerclient/exceptions.py', 'freezerclient/v1/managers/clients.py', 'freezerclient/tests/unit/v2/test_client_sessions.py', 'requirements.txt', 'freezerclient/tests/unit/v2/test_client_jobs.py', 'freezerclient/v2/managers/backups.py', 'freezerclient/v1/managers/jobs.py', 'freezerclient/v2/managers/actions.py', 'freezerclient/v2/managers/clients.py', 'freezerclient/v1/managers/backups.py'], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/a53f33c88f822daec5ee42bf0c5c867f1699b21f', 'message': 'Update json module to jsonutils\n\noslo project provide jsonutils, and the others project use it now,\nthis PS to update json moudule to oslo jsonutils for consistency.\n\nChange-Id: I6938f835b62222f3ca71e554cda0854edc1ed4d7\n'}]",0,638340,a53f33c88f822daec5ee42bf0c5c867f1699b21f,11,3,3,27781,,,0,"Update json module to jsonutils

oslo project provide jsonutils, and the others project use it now,
this PS to update json moudule to oslo jsonutils for consistency.

Change-Id: I6938f835b62222f3ca71e554cda0854edc1ed4d7
",git fetch https://review.opendev.org/openstack/python-freezerclient refs/changes/40/638340/1 && git format-patch -1 --stdout FETCH_HEAD,"['freezerclient/v2/managers/sessions.py', 'freezerclient/v2/managers/jobs.py', 'freezerclient/tests/unit/v1/test_client_sessions.py', 'freezerclient/v1/managers/sessions.py', 'freezerclient/utils.py', 'freezerclient/tests/unit/v1/test_client_jobs.py', 'freezerclient/v1/managers/actions.py', 'freezerclient/exceptions.py', 'freezerclient/v1/managers/clients.py', 'freezerclient/tests/unit/v2/test_client_sessions.py', 'requirements.txt', 'freezerclient/tests/unit/v2/test_client_jobs.py', 'freezerclient/v2/managers/backups.py', 'freezerclient/v1/managers/jobs.py', 'freezerclient/v2/managers/actions.py', 'freezerclient/v2/managers/clients.py', 'freezerclient/v1/managers/backups.py']",17,710009a0caf099f44eb2c8e1b161ec74499026d4,,from oslo_serialization import jsonutils as json ,import json,31,16
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I054c563dca42024b13022f70ec329db050021df2,openstack/tripleo-heat-templates,stable/queens,I054c563dca42024b13022f70ec329db050021df2,[Queens only] Ensure redhat-subscription is installed in overcloud nodes.,ABANDONED,2019-02-21 13:10:40.000000000,2019-02-22 11:44:39.000000000,,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2019-02-21 13:10:40.000000000', 'files': ['common/deploy-steps.j2', 'extraconfig/services/rhsm.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c9a1e9f3eb585457e88ac0603e40ddb0adeb1cad', 'message': '[Queens only] Ensure redhat-subscription is installed in overcloud nodes.\n\nAs in Queens we can deploy with config-download or without, we still\nneed to ensure that the host_prep_tasks are executed when config-download\nis not used. The problem with it is that the ansible tasks are being\nrun locally in the overcloud node via a SoftwareDeployment heat resource.\nAs one the host_prep_tasks in rhsm service make use of the ansible-role-\nredhat-subscription manager role, we need to ensure it will be installed\nbefore the playbook is run. Also, the role needs to be dynamically imported\nvia include_role because otherwise Ansible will check if the role exists\nbefore running anything, which will make the SoftwareDeployment resource\nfail.\n\nChange-Id: I054c563dca42024b13022f70ec329db050021df2\n'}]",1,638415,c9a1e9f3eb585457e88ac0603e40ddb0adeb1cad,6,4,1,26343,,,0,"[Queens only] Ensure redhat-subscription is installed in overcloud nodes.

As in Queens we can deploy with config-download or without, we still
need to ensure that the host_prep_tasks are executed when config-download
is not used. The problem with it is that the ansible tasks are being
run locally in the overcloud node via a SoftwareDeployment heat resource.
As one the host_prep_tasks in rhsm service make use of the ansible-role-
redhat-subscription manager role, we need to ensure it will be installed
before the playbook is run. Also, the role needs to be dynamically imported
via include_role because otherwise Ansible will check if the role exists
before running anything, which will make the SoftwareDeployment resource
fail.

Change-Id: I054c563dca42024b13022f70ec329db050021df2
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/15/638415/1 && git format-patch -1 --stdout FETCH_HEAD,"['common/deploy-steps.j2', 'extraconfig/services/rhsm.yaml']",2,c9a1e9f3eb585457e88ac0603e40ddb0adeb1cad,, include_role:, import_role:,6,1
openstack%2Fmagnum~stable%2Fqueens~I97f3e53b4b43648a4896193fb4ce469dbf42c611,openstack/magnum,stable/queens,I97f3e53b4b43648a4896193fb4ce469dbf42c611,Rename scripts,MERGED,2019-01-16 15:16:39.000000000,2019-02-22 11:20:40.000000000,2019-02-22 11:20:39.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2019-01-16 15:16:39.000000000', 'files': ['magnum/drivers/k8s_fedora_atomic_v1/templates/kubeminion.yaml', 'magnum/drivers/k8s_fedora_ironic_v1/templates/kubemaster.yaml', 'magnum/drivers/k8s_fedora_ironic_v1/templates/kubeminion_software_configs.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/flannel-service.sh', 'magnum/drivers/common/templates/kubernetes/fragments/enable-prometheus-monitoring.sh', 'magnum/drivers/common/templates/kubernetes/fragments/write-flannel-config.sh', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubemaster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/enable-ingress-controller.sh', 'magnum/drivers/common/templates/kubernetes/fragments/enable-ingress-traefik.sh', 'magnum/drivers/common/templates/kubernetes/fragments/enable-cert-api-manager.sh', 'magnum/drivers/common/templates/kubernetes/fragments/flannel-config-service.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/013dbdbced4827a424a82ff050642b8f162186d8', 'message': 'Rename scripts\n\nScripts are the core of Magnum for COE deployment. To be more\nclear and consistent, two changes proposed in this patch:\n\n1. Rename network related script to xxx-flannel-xxx given they\nare all for flannel and now we have calico driver.\n\n2. Adding .sh for some scripts to be consistent with others.\n\nChange-Id: I97f3e53b4b43648a4896193fb4ce469dbf42c611\n(cherry picked from commit cff48231684d2c75a553804668e3b2c2a78ec2ac)\n'}]",0,631246,013dbdbced4827a424a82ff050642b8f162186d8,9,4,1,28022,,,0,"Rename scripts

Scripts are the core of Magnum for COE deployment. To be more
clear and consistent, two changes proposed in this patch:

1. Rename network related script to xxx-flannel-xxx given they
are all for flannel and now we have calico driver.

2. Adding .sh for some scripts to be consistent with others.

Change-Id: I97f3e53b4b43648a4896193fb4ce469dbf42c611
(cherry picked from commit cff48231684d2c75a553804668e3b2c2a78ec2ac)
",git fetch https://review.opendev.org/openstack/magnum refs/changes/46/631246/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/k8s_fedora_atomic_v1/templates/kubeminion.yaml', 'magnum/drivers/k8s_fedora_ironic_v1/templates/kubemaster.yaml', 'magnum/drivers/k8s_fedora_ironic_v1/templates/kubeminion_software_configs.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/flannel-service.sh', 'magnum/drivers/common/templates/kubernetes/fragments/enable-prometheus-monitoring.sh', 'magnum/drivers/common/templates/kubernetes/fragments/write-flannel-config.sh', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubemaster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/enable-ingress-controller.sh', 'magnum/drivers/common/templates/kubernetes/fragments/enable-ingress-traefik.sh', 'magnum/drivers/common/templates/kubernetes/fragments/enable-cert-api-manager.sh', 'magnum/drivers/common/templates/kubernetes/fragments/flannel-config-service.sh']",11,013dbdbced4827a424a82ff050642b8f162186d8,queens-rename,,,26,26
openstack%2Fmanila~stable%2Fqueens~I0e4baaaca5046f9c0ee32cf3de78133f743fd66d,openstack/manila,stable/queens,I0e4baaaca5046f9c0ee32cf3de78133f743fd66d,DNM: Run ubuntu xenial ceph jobs,ABANDONED,2019-02-06 12:13:29.000000000,2019-02-22 11:15:26.000000000,,"[{'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-02-06 12:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3437bda7e6c2b55c6c76e80c6a972a16f9e01cb6', 'message': 'Run ubuntu xenial ceph jobs\n\nMatch our other jobs on stable/rocky and pick up the\nshaman repos we need for required ceph_volume library\nchanges.\n\nDepends-on: https://review.openstack.org/#/c/634299\nChange-Id: I0e4baaaca5046f9c0ee32cf3de78133f743fd66d\n(cherry picked from commit 095a542f92f8d0ba46e62b51ef073e3e0d6b09ea)\n'}, {'number': 2, 'created': '2019-02-06 15:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/41f4c9bdc0072a8ada889722f762acf6fd78fe9f', 'message': 'Run ubuntu xenial ceph jobs\n\nMatch our other jobs on stable/queens and pick up the\nshaman repos we need for required ceph_volume library\nchanges.\n\nDepends-on: https://review.openstack.org/#/c/634299\nChange-Id: I0e4baaaca5046f9c0ee32cf3de78133f743fd66d\n(cherry picked from commit 095a542f92f8d0ba46e62b51ef073e3e0d6b09ea)\n'}, {'number': 3, 'created': '2019-02-06 20:35:08.000000000', 'files': ['playbooks/legacy/manila-tempest-minimal-dsvm-cephfs-native/run.yaml', 'playbooks/legacy/manila-tempest-minimal-dsvm-cephfs-nfs/post.yaml', 'playbooks/legacy/manila-tempest-minimal-dsvm-cephfs-native/post.yaml', '.zuul.yaml', 'playbooks/legacy/manila-tempest-minimal-dsvm-cephfs-nfs/run.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/c24a8269f16850db3dfd590226ccad323e64a00f', 'message': 'DNM: Run ubuntu xenial ceph jobs\n\nMatch our other jobs on stable/queens and pick up the\nshaman repos we need for required ceph_volume library\nchanges.\n\nChange-Id: I0e4baaaca5046f9c0ee32cf3de78133f743fd66d\n(cherry picked from commit 095a542f92f8d0ba46e62b51ef073e3e0d6b09ea)\n'}]",2,635142,c24a8269f16850db3dfd590226ccad323e64a00f,15,7,3,9003,,,0,"DNM: Run ubuntu xenial ceph jobs

Match our other jobs on stable/queens and pick up the
shaman repos we need for required ceph_volume library
changes.

Change-Id: I0e4baaaca5046f9c0ee32cf3de78133f743fd66d
(cherry picked from commit 095a542f92f8d0ba46e62b51ef073e3e0d6b09ea)
",git fetch https://review.opendev.org/openstack/manila refs/changes/42/635142/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/legacy/manila-tempest-minimal-dsvm-cephfs-native/run.yaml', 'playbooks/legacy/manila-tempest-minimal-dsvm-cephfs-nfs/post.yaml', 'playbooks/legacy/manila-tempest-minimal-dsvm-cephfs-native/post.yaml', '.zuul.yaml', 'playbooks/legacy/manila-tempest-minimal-dsvm-cephfs-nfs/run.yaml']",5,3437bda7e6c2b55c6c76e80c6a972a16f9e01cb6,,"- hosts: all name: legacy-manila-tempest-minimal-dsvm-cephfs-nfs-ubuntu-bionic tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x cat > clonemap.yaml << EOF clonemap: - name: openstack-infra/devstack-gate dest: devstack-gate EOF /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \ git://git.openstack.org \ openstack-infra/devstack-gate executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x cat << 'EOF' >>""/tmp/dg-local.conf"" [[local|localrc]] enable_plugin manila git://git.openstack.org/openstack/manila enable_plugin devstack-plugin-ceph git://git.openstack.org/openstack/devstack-plugin-ceph # Enable CephFS as the backend for Manila. ENABLE_CEPH_MANILA=True # Disable Ceph as the storage backend for Nova. ENABLE_CEPH_NOVA=False # Disable Ceph as the storage backend for Glance. ENABLE_CEPH_GLANCE=False # Disable Ceph as the storage backend for Cinder. ENABLE_CEPH_CINDER=False # Disable Ceph as the storage backend for Cinder backup. ENABLE_CEPH_C_BAK=False # Set native or NFS variant of ceph driver MANILA_CEPH_DRIVER=cephfsnfs EOF executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x export PYTHONUNBUFFERED=true export DEVSTACK_GATE_NEUTRON=1 export ENABLED_SERVICES=tempest export PROJECTS=""openstack/devstack-plugin-ceph $PROJECTS"" export DEVSTACK_PROJECT_FROM_GIT=""python-manilaclient"" export KEEP_LOCALRC=1 export PROJECTS=""openstack/manila-tempest-plugin $PROJECTS"" OVERRIDE_ENABLED_SERVICES=key,mysql,rabbit,tempest export OVERRIDE_ENABLED_SERVICES function pre_test_hook { # Configure Manila with a CephFS Native or NFS driver backend. # Refer to job-template pre_test_hook for more details on the # arguments. source $BASE/new/devstack-plugin-ceph/manila/pre_test_hook.sh \ false cephfsnfs singlebackend } export -f pre_test_hook function post_test_hook { # Configure and run Tempest API tests on Manila with a # CephFSNative driver backend. # Refer to job-template post_test_hook for more details on the # arguments. source $BASE/new/devstack-plugin-ceph/manila/post_test_hook.sh \ singlebackend cephfsnfs api } export -f post_test_hook cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",,255,2
openstack%2Ftripleo-heat-templates~stable%2Frocky~I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7,openstack/tripleo-heat-templates,stable/rocky,I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7,minor update: move VIP before stopping pacemaker on a node,MERGED,2019-02-14 10:08:16.000000000,2019-02-22 11:09:54.000000000,2019-02-19 14:27:06.000000000,"[{'_account_id': 3153}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-14 10:08:16.000000000', 'files': ['puppet/services/pacemaker.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ded38b744037bc6bffc0b63039933b58ab5e5018', 'message': ""minor update: move VIP before stopping pacemaker on a node\n\nWhen pacemaker stops, it first stops all pacemaker resources\nmanaged on the node, and stops the pacemaker daemon.\n\nIf the node being stopped is hosting VIP resources, those ones\nmust be restarted elsewhere as soon as possible to avoid long\nservice disruption, but there is currently no constraint defined\nto force that behaviour.\n\nSo what can happen is the VIP resources are stopped, then other\nresources on the hosts are stopped (e.g. rabbit, galera), and only\nwhen there's no more resources pacemaker restarts VIPs elsewhere,\nwhich can lead to a long OpenStack service disruption.\n\nTo avoid unexpected long outage period due to VIP unavailability,\nforce-move the VIPs away from the node before stopping pacemaker.\n\nCloses-Bug: #1815204\nChange-Id: I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7\n(cherry picked from commit 38fb412ac0c76f0ba2b0737699845d9d882fdc2f)\n""}]",0,636891,ded38b744037bc6bffc0b63039933b58ab5e5018,16,5,1,20172,,,0,"minor update: move VIP before stopping pacemaker on a node

When pacemaker stops, it first stops all pacemaker resources
managed on the node, and stops the pacemaker daemon.

If the node being stopped is hosting VIP resources, those ones
must be restarted elsewhere as soon as possible to avoid long
service disruption, but there is currently no constraint defined
to force that behaviour.

So what can happen is the VIP resources are stopped, then other
resources on the hosts are stopped (e.g. rabbit, galera), and only
when there's no more resources pacemaker restarts VIPs elsewhere,
which can lead to a long OpenStack service disruption.

To avoid unexpected long outage period due to VIP unavailability,
force-move the VIPs away from the node before stopping pacemaker.

Closes-Bug: #1815204
Change-Id: I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7
(cherry picked from commit 38fb412ac0c76f0ba2b0737699845d9d882fdc2f)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/91/636891/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/pacemaker.yaml'],1,ded38b744037bc6bffc0b63039933b58ab5e5018,bug/1815204," - name: Move virtual IPs to another node before stopping pacemaker when: step|int == 1 shell: | CLUSTER_NODE=$(crm_node -n) echo ""Retrieving all the VIPs which are hosted on this node"" VIPS_TO_MOVE=$(crm_mon --as-xml | xmllint --xpath '//resource[@resource_agent = ""ocf::heartbeat:IPaddr2"" and @role = ""Started"" and @managed = ""true"" and ./node[@name = ""'${CLUSTER_NODE}'""]]/@id' - | sed -e 's/id=//g' -e 's/""//g') for v in ${VIPS_TO_MOVE}; do echo ""Moving VIP $v on another node"" pcs resource move $v --wait=300 done echo ""Removing the location constraints that were created to move the VIPs"" for v in ${VIPS_TO_MOVE}; do echo ""Removing location ban for VIP $v"" ban_id=$(cibadmin --query | xmllint --xpath 'string(//rsc_location[@rsc=""'${v}'"" and @node=""'${CLUSTER_NODE}'"" and @score=""-INFINITY""]/@id)' -) if [ -n ""$ban_id"" ]; then pcs constraint remove ${ban_id} else echo ""Could not retrieve and clear location constraint for VIP $v"" 2>&1 fi done",,20,0
openstack%2Fcinder~master~I4a205c0e1040d743d94c900318fd3b6edfe667ef,openstack/cinder,master,I4a205c0e1040d743d94c900318fd3b6edfe667ef,REST connector for Brocade zone driver,MERGED,2018-11-10 08:45:42.000000000,2019-02-22 11:00:58.000000000,2019-02-19 16:44:25.000000000,"[{'_account_id': 1736}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 8757}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 17042}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29637}, {'_account_id': 29716}]","[{'number': 1, 'created': '2018-11-10 08:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f87cf84e4c01888c4ac1ca53267dc5206dedaee0', 'message': 'REST connector for Brocade zone driver\n\nAdd REST connector for switches with firmware\nFOS 8.2.1 and greater.\n\nChange-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef\n'}, {'number': 2, 'created': '2018-11-29 10:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/38ac4fc670e26d8d594170fdf3b7dace03212bbe', 'message': 'REST connector for Brocade zone driver\n\nAdd REST connector for switches with firmware\nFOS 8.2.1 and greater.\n\nChange-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef\n'}, {'number': 3, 'created': '2018-11-29 10:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1f8767c8c4ba03d63a7386c690ca9586d8d5fe65', 'message': 'REST connector for Brocade zone driver\n\nAdd REST connector for switches with firmware\nFOS 8.2.1 and greater.\n\nChange-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef\n'}, {'number': 4, 'created': '2018-12-06 23:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dcf5d5d11985d71c4301c6b25a676cdfbb287872', 'message': 'REST connector for Brocade zone driver\n\nAdd REST connector for switches with firmware\nFOS 8.2.1 and greater.\n\nChange-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef\n'}, {'number': 5, 'created': '2018-12-07 20:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a0b85ccd772064b0b13aa824fdebabf5241df6c4', 'message': 'REST connector for Brocade zone driver\n\nAdd REST connector for switches with firmware\nFOS 8.2.1 and greater.\n\nChange-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef\n'}, {'number': 6, 'created': '2018-12-08 09:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/129368f64530a63a7d217deeb7ccf9693c168d04', 'message': 'REST connector for Brocade zone driver\n\nAdd REST connector for switches with firmware\nFOS 8.2.1 and greater.\n\nChange-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef\n'}, {'number': 7, 'created': '2018-12-14 23:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bb018dfb9361118cd6efdc1235b9176d71403e7c', 'message': 'REST connector for Brocade zone driver\n\nAdd REST connector for switches with firmware\nFOS 8.2.1 and greater.\n\nChange-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef\n'}, {'number': 8, 'created': '2018-12-19 22:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/27b6c9d9b07f424f515c77094d8cca5ccccf4c4b', 'message': 'REST connector for Brocade zone driver\n\nAdd REST connector for switches with firmware\nFOS 8.2.1 and greater.\n\nChange-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef\n'}, {'number': 9, 'created': '2018-12-20 08:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e9852e03e0be87f46bfe312ec5136f8ad0fc5f18', 'message': 'REST connector for Brocade zone driver\n\nAdd REST connector for switches with firmware\nFOS 8.2.1 and greater.\n\nChange-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef\n'}, {'number': 10, 'created': '2019-02-05 23:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ce3549bf07e012e367521d897bd69d3f83fd62ce', 'message': 'REST connector for Brocade zone driver\n\nAdd REST connector for switches with firmware\nFOS 8.2.1 and greater.\n\nChange-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef\n'}, {'number': 11, 'created': '2019-02-09 09:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7b8773f7982a9812ab39f5f72d1d6153dffe5123', 'message': 'REST connector for Brocade zone driver\n\nAdd REST connector for switches with firmware\nFOS 8.2.1 and greater.\n\nChange-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef\n'}, {'number': 12, 'created': '2019-02-12 22:55:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ffa9159401f30042857725bad7d90773340754cb', 'message': 'REST connector for Brocade zone driver\n\nAdd REST connector for switches with firmware\nFOS 8.2.1 and greater.\n\nChange-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef\n'}, {'number': 13, 'created': '2019-02-18 09:08:03.000000000', 'files': ['cinder/zonemanager/drivers/brocade/brcd_fc_zone_connector_factory.py', 'cinder/zonemanager/drivers/brocade/brcd_fabric_opts.py', 'cinder/zonemanager/drivers/brocade/fc_zone_constants.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'doc/source/configuration/block-storage/fc-zoning.rst', 'cinder/zonemanager/drivers/brocade/rest_constants.py', 'cinder/zonemanager/drivers/brocade/brcd_rest_fc_zone_client.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_san_lookup_service.py', 'cinder/exception.py', 'cinder/zonemanager/drivers/brocade/brcd_http_fc_zone_client.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cad1dcb5f2be620a41825967245eca5bbe31d3da', 'message': 'REST connector for Brocade zone driver\n\nAdd REST connector for switches with firmware\nFOS 8.2.1 and greater.\n\nChange-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef\n'}]",21,617100,cad1dcb5f2be620a41825967245eca5bbe31d3da,333,50,13,8757,,,0,"REST connector for Brocade zone driver

Add REST connector for switches with firmware
FOS 8.2.1 and greater.

Change-Id: I4a205c0e1040d743d94c900318fd3b6edfe667ef
",git fetch https://review.opendev.org/openstack/cinder refs/changes/00/617100/6 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/zonemanager/drivers/brocade/brcd_fc_zone_connector_factory.py', 'cinder/zonemanager/drivers/brocade/fc_zone_constants.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/zonemanager/drivers/brocade/rest_constants.py', 'cinder/zonemanager/drivers/brocade/brcd_rest_fc_zone_client.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_san_lookup_service.py']",6,f87cf84e4c01888c4ac1ca53267dc5206dedaee0,brcd_rest_connector," msg = _(""Connection failed """," msg = _(""SSH connection failed """,405,7
openstack%2Ftripleo-specs~master~Ifa36b59c81e6757f1bdb258c477723e883a4f30b,openstack/tripleo-specs,master,Ifa36b59c81e6757f1bdb258c477723e883a4f30b,Amend Validation Framework Spec,MERGED,2019-02-12 08:52:59.000000000,2019-02-22 11:00:44.000000000,2019-02-22 11:00:44.000000000,"[{'_account_id': 3153}, {'_account_id': 11491}, {'_account_id': 17888}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-02-12 08:52:59.000000000', 'files': ['specs/stein/validation-framework.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/0d319b1b2eca1f9f2c3e382b95bf48ae9f4aa9c1', 'message': 'Amend Validation Framework Spec\n\nFollowing discussions and meetings, the following change has to be\ndone in order to get a clean code:\n- validations should be presented as roles, not playbooks\n- current existing playbooks should be migrated to roles\n- in order to keep the mistral compatibility, playbooks will be\n  created and just include the roles\n\nChange-Id: Ifa36b59c81e6757f1bdb258c477723e883a4f30b\n'}]",0,636283,0d319b1b2eca1f9f2c3e382b95bf48ae9f4aa9c1,12,6,1,28223,,,0,"Amend Validation Framework Spec

Following discussions and meetings, the following change has to be
done in order to get a clean code:
- validations should be presented as roles, not playbooks
- current existing playbooks should be migrated to roles
- in order to keep the mistral compatibility, playbooks will be
  created and just include the roles

Change-Id: Ifa36b59c81e6757f1bdb258c477723e883a4f30b
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/83/636283/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/stein/validation-framework.rst'],1,0d319b1b2eca1f9f2c3e382b95bf48ae9f4aa9c1,bp/validation-framework," * ``--extra-roles``: path to a local directory containing validation roles maintained by the operator, or swift directory containing extra validation roles.The ``--extra-roles`` must support both local path and remote swiftThe validations should be in the form of Ansible roles, in order to bevalidate the role before running it (ensuring there are metadata, output,We might also create some dedicated roles in order to make a kind ofAlso, in order to avoid Mistral modification, playbooks including validation roles will be created. In the end, all the default validation roles should be in one and only oneregarding the roles content, format and outputs should be created. For instance, a role should contain a description, a ""human readable error* Implement the undercloud_preflight validations as Ansible roles."," * ``--extra-playbooks``: path to a local directory containing validation playbook maintained by the operator, or swift directory containing extra validation playbooks.The ``--extra-playbooks`` must support both local path and remote swiftThe validations should be in the form of Ansible playbook, in order to bevalidate the playbook before running it (ensuring there are metadata, output,We might also create some dedicated playbooks in order to make a kind ofIn the end, all the default validation playbooks should be in one and only oneregarding the playbooks content, format and outputs should be created. For instance, a playbook should contain a description, a ""human readable error* Implement the undercloud_preflight validations as Ansible playbook.",14,11
openstack%2Fcharm-openstack-dashboard~master~Icc990448d2c7469c5253d04ad43371d01d5580d9,openstack/charm-openstack-dashboard,master,Icc990448d2c7469c5253d04ad43371d01d5580d9,Use common ApacheSSLContext,MERGED,2019-02-22 08:42:16.000000000,2019-02-22 11:00:14.000000000,2019-02-22 11:00:13.000000000,"[{'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 08:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/fe9578b7b0627c636c311f01f29dfbc663a8a89c', 'message': 'Use common ApacheSSLContext\n\nRemove the custom ApacheSSLContext class and use the common\none from ``charmhelpers.contrib.openstack`` instead.\n\nUpdate ``default-ssl`` template so we can make use of multiple\nendpoints with SNI.\n\nChange-Id: Icc990448d2c7469c5253d04ad43371d01d5580d9\nRelated-Bug: ##1816621\n'}, {'number': 2, 'created': '2019-02-22 09:58:40.000000000', 'files': ['hooks/horizon_contexts.py', 'charmhelpers/contrib/openstack/ip.py', 'hooks/horizon_hooks.py', 'templates/default-ssl', 'unit_tests/test_horizon_contexts.py', 'charmhelpers/contrib/openstack/context.py', 'unit_tests/test_horizon_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/19915f6806a053bf8c25cc589b5964058dc7bfe2', 'message': 'Use common ApacheSSLContext\n\nRemove the custom ApacheSSLContext class and use the common\none from ``charmhelpers.contrib.openstack`` instead.\n\nUpdate ``default-ssl`` template so we can make use of multiple\nendpoints with SNI.\n\nSync required changes to charm-helpers.\n\nChange-Id: Icc990448d2c7469c5253d04ad43371d01d5580d9\nRelated-Bug: #1816621\n'}]",0,638603,19915f6806a053bf8c25cc589b5964058dc7bfe2,11,4,2,13686,,,0,"Use common ApacheSSLContext

Remove the custom ApacheSSLContext class and use the common
one from ``charmhelpers.contrib.openstack`` instead.

Update ``default-ssl`` template so we can make use of multiple
endpoints with SNI.

Sync required changes to charm-helpers.

Change-Id: Icc990448d2c7469c5253d04ad43371d01d5580d9
Related-Bug: #1816621
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/03/638603/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_contexts.py', 'hooks/horizon_hooks.py', 'templates/default-ssl', 'unit_tests/test_horizon_contexts.py', 'unit_tests/test_horizon_hooks.py']",5,fe9578b7b0627c636c311f01f29dfbc663a8a89c,bug/1816621," def test_certs_changed(self, _process_certificates, _service_reload): 'horizon', None, None)"," @patch.object(hooks.os, 'symlink') @patch.object(hooks.os, 'remove') @patch.object(hooks.os.path, 'exists') def test_certs_changed(self, _process_certificates, _service_reload, _exists, _remove, _symlink): 'horizon', None, None, custom_hostname_link='dashboard') self.assertFalse(_symlink.called) _process_certificates.reset_mock() self.config.side_effect = None self.config.return_value = 'somehostname' _exists.return_value = True self._call_hook('certificates-relation-changed') _process_certificates.assert_called_with('horizon', None, None) _remove.assert_has_calls([ call('/etc/apache2/ssl/horizon/cert_dashboard'), call('/etc/apache2/ssl/horizon/key_dashboard'), ]) _symlink.assert_has_calls([ call('/etc/apache2/ssl/horizon/cert_somehostname', '/etc/apache2/ssl/horizon/cert_dashboard'), call('/etc/apache2/ssl/horizon/key_somehostname', '/etc/apache2/ssl/horizon/key_dashboard'), ])",65,177
openstack%2Ftripleo-ui~master~I4ed19b880a2d9ceda64787f3db34cfa986a30815,openstack/tripleo-ui,master,I4ed19b880a2d9ceda64787f3db34cfa986a30815,Imported Translations from Zanata,MERGED,2018-12-14 06:49:04.000000000,2019-02-22 10:34:43.000000000,2019-02-22 10:34:42.000000000,"[{'_account_id': 1736}, {'_account_id': 10112}, {'_account_id': 14985}, {'_account_id': 17888}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-14 06:49:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/fcef7de89c0d637da09108bb71655b148d5fac45', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I4ed19b880a2d9ceda64787f3db34cfa986a30815\n'}, {'number': 2, 'created': '2019-01-25 06:26:25.000000000', 'files': ['i18n/locales/en-GB.json', 'i18n/locales/es.json'], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/797b588292c1a52b8b6fc998f8b2d8d9903536d3', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I4ed19b880a2d9ceda64787f3db34cfa986a30815\n'}]",0,625159,797b588292c1a52b8b6fc998f8b2d8d9903536d3,12,5,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I4ed19b880a2d9ceda64787f3db34cfa986a30815
",git fetch https://review.opendev.org/openstack/tripleo-ui refs/changes/59/625159/1 && git format-patch -1 --stdout FETCH_HEAD,['i18n/locales/en-GB.json'],1,fcef7de89c0d637da09108bb71655b148d5fac45,zanata/translations," ""ContainerImagePrepareParameterForm.yamlSyntaxError"": ""Invalid Yaml Syntax:"", ""ContainerImagePrepareParameterFormActions.back"": ""Back"", ""ContainerImagesActions.configureImagesFailed"": ""Generating container images configuration failed"", ""ContainerImagesPrepareForm.generatingConfiguration"": ""Generating container images configuration..."", ""ContainerImagesPrepareForm.namePrefixDescription"": ""Container image name prefix"", ""ContainerImagesPrepareForm.namePrefixLabel"": ""Name Prefix"", ""ContainerImagesPrepareForm.nameSuffixDescription"": ""Container image name suffix"", ""ContainerImagesPrepareForm.nameSuffixLabel"": ""Name Suffix"", ""ContainerImagesPrepareForm.namespaceDescription"": ""Namespace of the remote registry from which the container images will be pulled during deployment."", ""ContainerImagesPrepareForm.namespaceInvalid"": ""Provide a valid registry address and images namespace"", ""ContainerImagesPrepareForm.namespaceLabel"": ""Registry Namespace"", ""ContainerImagesPrepareForm.pushDestinationDescription"": ""By specifying a Push Destination, the required images will be copied from provided namespace to this registry. As part of the undercloud install, an image registry is configured on port 8787. This can be used to increase reliability of image pulls, and minimise overall network transfers. Alternatively it is possible to explicitly specify the registry to push the images to."", ""ContainerImagesPrepareForm.pushDestinationValidationMessage"": ""Please enter a valid IPv4 address and port"", ""ContainerImagesPrepareForm.tagDescription"": ""Tag representing the latest image version."", ""ContainerImagesPrepareForm.tagFromLabelDescription"": ""Provide a label to discover the versioned tag for images. Some build pipelines have a versioned tag which can only be discovered via a combination of labels. For this case, a template format can be specified instead, e.g. {labelExample}. If you want these parameters to have the actual tag instead of the discovered tag, this entry can be omitted."", ""ContainerImagesPrepareForm.tagLabel"": ""Tag"", ""ContainerImagesPrepareFormActions.next"": ""Next"", ""ContainerImagesPrepareFormActions.reset"": ""Reset to Defaults"", ""ContainerImagesWizard.configureImages"": ""Configure Images"", ""ContainerImagesWizard.loadingData"": ""Loading configuration..."", ""ContainerImagesWizard.review"": ""Review Configuration"", ""PushDestinationInput.pushDestinationOptionCustom"": ""Specify custom registry"", ""PushDestinationInput.pushDestinationOptionFalse"": ""Don't push images"", ""PushDestinationInput.pushDestinationOptionTrue"": ""Push to Undercloud registry"","," ""ContainerImagePrepareParameterForm.yamlSyntaxError"": """", ""ContainerImagePrepareParameterFormActions.back"": """", ""ContainerImagesActions.configureImagesFailed"": """", ""ContainerImagesPrepareForm.generatingConfiguration"": """", ""ContainerImagesPrepareForm.namePrefixDescription"": """", ""ContainerImagesPrepareForm.namePrefixLabel"": """", ""ContainerImagesPrepareForm.nameSuffixDescription"": """", ""ContainerImagesPrepareForm.nameSuffixLabel"": """", ""ContainerImagesPrepareForm.namespaceDescription"": """", ""ContainerImagesPrepareForm.namespaceInvalid"": """", ""ContainerImagesPrepareForm.namespaceLabel"": """", ""ContainerImagesPrepareForm.pushDestinationDescription"": """", ""ContainerImagesPrepareForm.pushDestinationValidationMessage"": """", ""ContainerImagesPrepareForm.tagDescription"": """", ""ContainerImagesPrepareForm.tagFromLabelDescription"": """", ""ContainerImagesPrepareForm.tagLabel"": """", ""ContainerImagesPrepareFormActions.next"": """", ""ContainerImagesPrepareFormActions.reset"": """", ""ContainerImagesWizard.configureImages"": """", ""ContainerImagesWizard.loadingData"": """", ""ContainerImagesWizard.review"": """", ""PushDestinationInput.pushDestinationOptionCustom"": """", ""PushDestinationInput.pushDestinationOptionFalse"": """", ""PushDestinationInput.pushDestinationOptionTrue"": """",",24,24
openstack%2Ftripleo-ui~stable%2Frocky~Ic6fc3e4e69810fccf331d3f90a3a8425aa50a693,openstack/tripleo-ui,stable/rocky,Ic6fc3e4e69810fccf331d3f90a3a8425aa50a693,Imported Translations from Zanata,MERGED,2018-12-14 06:48:25.000000000,2019-02-22 10:34:43.000000000,2019-02-22 10:34:43.000000000,"[{'_account_id': 1736}, {'_account_id': 10112}, {'_account_id': 11904}, {'_account_id': 14985}, {'_account_id': 17888}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-14 06:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/0ee0f409209be181c514cfeeab1e52bd137b64b9', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ic6fc3e4e69810fccf331d3f90a3a8425aa50a693\n'}, {'number': 2, 'created': '2018-12-16 06:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/516d43550173d1f473fe7568449f5a65d2260895', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ic6fc3e4e69810fccf331d3f90a3a8425aa50a693\n'}, {'number': 3, 'created': '2018-12-19 07:03:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/1c34d33bb554e75b47c88e95e63a7e730ec0a894', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ic6fc3e4e69810fccf331d3f90a3a8425aa50a693\n'}, {'number': 4, 'created': '2019-01-25 06:18:00.000000000', 'files': ['i18n/locales/en-GB.json', 'i18n/locales/de.json', 'i18n/locales/zh-CN.json', 'i18n/locales/es.json', 'i18n/locales/ja.json', 'i18n/locales/id.json'], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/9bddbeed0beb2aa985db00df4cf3ed278e448824', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ic6fc3e4e69810fccf331d3f90a3a8425aa50a693\n'}]",0,625158,9bddbeed0beb2aa985db00df4cf3ed278e448824,20,6,4,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ic6fc3e4e69810fccf331d3f90a3a8425aa50a693
",git fetch https://review.opendev.org/openstack/tripleo-ui refs/changes/58/625158/4 && git format-patch -1 --stdout FETCH_HEAD,"['i18n/locales/en-GB.json', 'i18n/locales/de.json', 'i18n/locales/es.json', 'i18n/locales/zh-CN.json', 'i18n/locales/ja.json', 'i18n/locales/id.json']",6,0ee0f409209be181c514cfeeab1e52bd137b64b9,zanata/translations," ""ContainerImagesActions.configureImagesFailed"": """", ""ContainerImagesPrepareForm.generatingConfiguration"": """", ""ContainerImagesPrepareForm.namePrefixDescription"": """", ""ContainerImagesPrepareForm.namePrefixLabel"": """", ""ContainerImagesPrepareForm.nameSuffixDescription"": """", ""ContainerImagesPrepareForm.nameSuffixLabel"": """", ""ContainerImagesPrepareForm.namespaceDescription"": """", ""ContainerImagesPrepareForm.namespaceInvalid"": """", ""ContainerImagesPrepareForm.namespaceLabel"": """", ""ContainerImagesPrepareForm.pushDestinationDescription"": """", ""ContainerImagesPrepareForm.pushDestinationLabel"": """", ""ContainerImagesPrepareForm.pushDestinationUndercloud"": """", ""ContainerImagesPrepareForm.pushDestinationValidationMessage"": """", ""ContainerImagesPrepareForm.tagDescription"": """", ""ContainerImagesPrepareForm.tagFromLabelDescription"": """", ""ContainerImagesPrepareForm.tagFromLabelLabel"": """", ""ContainerImagesPrepareForm.tagLabel"": """", ""ContainerImagesPrepareFormActions.reset"": """", ""ContainerImagesWizard.back"": """", ""ContainerImagesWizard.cancel"": ""Cancel"", ""ContainerImagesWizard.close"": ""Close"", ""ContainerImagesWizard.configureImages"": """", ""ContainerImagesWizard.loadingData"": """", ""ContainerImagesWizard.next"": """", ""ContainerImagesWizard.review"": """", ""ContainerImagesWizard.save"": ""Save Changes"", ""ContainerImagesWizard.title"": """", ""PushDestinationInput.pushDestinationOptionCustom"": """", ""PushDestinationInput.pushDestinationOptionFalse"": """", ""PushDestinationInput.pushDestinationOptionTrue"": """",",,189,9
openstack%2Fnova~master~Id7827fe8dc27112e342dc25c902c8dbc25f63b94,openstack/nova,master,Id7827fe8dc27112e342dc25c902c8dbc25f63b94,Calculate RequestGroup resource provider mapping,MERGED,2018-11-07 16:42:07.000000000,2019-02-22 10:28:21.000000000,2019-02-21 19:18:32.000000000,"[{'_account_id': 7}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15554}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 21672}, {'_account_id': 21813}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-11-07 16:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2754427f598268a49764cdb589efaa09bbaacab7', 'message': ""Calculate port_id rp_uuid mapping for binding\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nThis patch introduce a code in neutronv2 that is capable of generate\nthe mapping based on the ports of an instance, the placement allocation\nof the instance, and the provider summary of the RPs in the allocation.\n\nNote: The current algorithm is a gready, best effort algorithm that\nprovides such mapping in the simple cases only.\n\nSubsequent patches will integrate this code into the port bindig\nprocess.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 2, 'created': '2018-11-09 14:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a7fbecd7b72be6bc2c16633ad098423f3cf1e6c9', 'message': ""Calculate port_id rp_uuid mapping for binding\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nThis patch introduce a code in neutronv2 that is capable of generate\nthe mapping based on the ports of an instance, the placement allocation\nof the instance, and the provider summary of the RPs in the allocation.\n\nNote: The current algorithm is a gready, best effort algorithm that\nprovides such mapping in the simple cases only.\n\nSubsequent patches will integrate this code into the port bindig\nprocess.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 3, 'created': '2018-11-09 16:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca40b83c76150ebcba11784770578515b2d64627', 'message': ""Calculate port_id rp_uuid mapping for binding\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nThis patch introduce a code in neutronv2 that is capable of generate\nthe mapping based on the ports of an instance, the placement allocation\nof the instance, and the provider summary of the RPs in the allocation.\n\nNote: The current algorithm is a gready, best effort algorithm that\nprovides such mapping in the simple cases only.\n\nSubsequent patches will integrate this code into the port bindig\nprocess.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 4, 'created': '2018-11-14 10:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba5b1c66f6930dfa712249ec0eccca557002753b', 'message': ""Calculate port_id rp_uuid mapping for binding\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nThis patch introduce a code in neutronv2 that is capable of generate\nthe mapping based on the ports of an instance, the placement allocation\nof the instance, and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the port bindig\nprocess.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 5, 'created': '2018-11-14 13:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f540b3b02318c9d2658a3feb270b9021539d713f', 'message': ""Calculate port_id rp_uuid mapping for binding\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nThis patch introduce a code in neutronv2 that is capable of generate\nthe mapping based on the ports of an instance, the placement allocation\nof the instance, and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the port bindig\nprocess.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 6, 'created': '2018-11-18 12:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/69f2e957df7374a7d8bfbd30ebecfed940e17a2f', 'message': ""Calculate port_id rp_uuid mapping for binding\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nThis patch introduce a code in neutronv2 that is capable of generate\nthe mapping based on the ports of an instance, the placement allocation\nof the instance, and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the port bindig\nprocess.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 7, 'created': '2018-11-22 11:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee6ec133e6fe8740c7c0608ea32f663505266f75', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 8, 'created': '2018-11-22 12:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd6b8618d95fa577bc9ef51fe2abbc2ac8a1e06a', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 9, 'created': '2018-11-23 15:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d2c2624e869bab7912daf69babd09c9df0db755', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 10, 'created': '2018-12-10 09:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1428760ae6c55d537247d62d8da52ce81e99043c', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 11, 'created': '2018-12-14 14:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ad946bf5ffbed87b30c37f3a21b828cc45698ac', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 12, 'created': '2018-12-18 15:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1b7e8fcec081816bc2f67153f1ab24c0e87b9a64', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 13, 'created': '2018-12-19 15:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf93ebdc3d205cced5877989902b668cee7d5f5a', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 14, 'created': '2018-12-20 10:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9155cbc16b68be013ceaa3a253664d57a66b2e2b', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 15, 'created': '2018-12-20 16:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a122be54762e90ea0063dab067da5811b849945f', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 16, 'created': '2019-01-14 16:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6cda873704eb1514ff97a17fc67877747b1cf090', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 17, 'created': '2019-01-24 16:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11600dfcc84488b467d12baed979a0fea3da9fed', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 18, 'created': '2019-01-26 16:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d835f92f8073efd5db17c93bc9af26806d3aa984', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 19, 'created': '2019-01-28 14:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a75e70bd2d9507948b2e39e8d4f29992c8ad12bf', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 20, 'created': '2019-02-05 10:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7492c638335dc9efae0425a745acf235908e2a7d', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 21, 'created': '2019-02-06 15:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/647974f6614d0fce5d39871294eb7145c80bea6e', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 22, 'created': '2019-02-08 01:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba8a8e4cd31f982f167660c8f59f8172ba9db878', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 23, 'created': '2019-02-12 16:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2ba72e88cab86b2ab72aace9fd96c77fcb1d012', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 24, 'created': '2019-02-13 10:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/34deb5a903ed1ad924b9cd7aecb6bb0a79bf07a3', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 25, 'created': '2019-02-15 13:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84df5a347ac805ee28f3da9e23405b477c40408f', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 26, 'created': '2019-02-15 13:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/695dfc59f2adea9995c138a9694e6f4368fbf185', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 27, 'created': '2019-02-18 13:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0837e382fdb4228c94c9c448eb43f8a6bc676667', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 28, 'created': '2019-02-18 13:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/514107737a6440db64873edd4cdb765fe727b4ff', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 29, 'created': '2019-02-20 06:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad2f609be9f13329e76d0d2917617c9bc1c6d87c', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 30, 'created': '2019-02-20 06:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/004c63011f8ffab39f8a3cf263405b8d81a9ed52', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 31, 'created': '2019-02-20 06:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71e2a28b5a8a3a45778214c95a53a052ef3c4721', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 32, 'created': '2019-02-20 08:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a8b0956f6a5e9ca2be4388129de7ca9728cc27b', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}, {'number': 33, 'created': '2019-02-21 11:45:01.000000000', 'files': ['nova/objects/request_spec.py', 'nova/tests/unit/objects/test_request_spec.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2fc904acf6d13fed8f81a9dbb88a1bfce06287da', 'message': ""Calculate RequestGroup resource provider mapping\n\nIf the port, provided in the server create request, has requested\nresources then nova needs to communicate the resource allocation it\nmade during the scheduling to neutron.\n\nAs a single neutron port's resource request is included in the\nallocation candidate query as a separate request group therefore the\nalloction for a port will come from a single RP. Neutron expects that\nthis single RP uuid is communicated during the binding of the port in\nthe binding_profile.\n\nEach Neutron port's resource request is represented as a RequestGroup in\nthe RequestSpec.\n\nThis patch introduces a code in RequestSpec to map RequestGroups to\nresource providers in a generic way, base on the resource requests and\nrequired traits in the groups, the overall allocation made for the\nRequestSpec and the provider summary of the RPs in the allocation.\n\nSubsequent patches will integrate this code into the server create code\npath to create the mapping, then change the port binding code path to\nuse this mapping to communicate the resource provider of the port in the\nbinding profile.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94\n""}]",86,616239,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,367,22,33,9708,,,0,"Calculate RequestGroup resource provider mapping

If the port, provided in the server create request, has requested
resources then nova needs to communicate the resource allocation it
made during the scheduling to neutron.

As a single neutron port's resource request is included in the
allocation candidate query as a separate request group therefore the
alloction for a port will come from a single RP. Neutron expects that
this single RP uuid is communicated during the binding of the port in
the binding_profile.

Each Neutron port's resource request is represented as a RequestGroup in
the RequestSpec.

This patch introduces a code in RequestSpec to map RequestGroups to
resource providers in a generic way, base on the resource requests and
required traits in the groups, the overall allocation made for the
RequestSpec and the provider summary of the RPs in the allocation.

Subsequent patches will integrate this code into the server create code
path to create the mapping, then change the port binding code path to
use this mapping to communicate the resource provider of the port in the
binding profile.

blueprint bandwidth-resource-provider

Change-Id: Id7827fe8dc27112e342dc25c902c8dbc25f63b94
",git fetch https://review.opendev.org/openstack/nova refs/changes/39/616239/28 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/neutronv2/api.py'],1,2754427f598268a49764cdb589efaa09bbaacab7,bp/bandwidth-resource-provider," def _get_resource_provider_for_port_request(self, allocations, resource_request): for rp, allocation in allocations.items(): # we return the first RP from the placement allocations that # provides enough resources for the request if all(allocation['resources'].get(rc, 0) >= amount for rc, amount in resource_request.items()): return rp raise ValueError('No matching allocation found for resource request %s' ' in allocations %s' % (str(resource_request), str(allocations))) def _consume_port_allocation_from_allocations(self, rp, port_allocation, allocations): original_allocation = allocations[rp]['resources'] for rc, amount in port_allocation.items(): original_allocation[rc] -= amount def get_resource_providers_for_ports(self, context, requested_networks, placement_allocations): """"""Return the resource provider for each port resource request. :param context: The request context. :param requested_networks: A NetworkRequestList object containing the ports, networks and fixed IPs requested for the instance :param placement_allocations: The overall allocation made by the scheduler based on the port's resource request :return: A dict with port_id: resource_provider_uuid mappings for each port that has resource request. Or raises an exception if the mapping is ambiguous. """""" # Note(gibi): It can only do a best effort matching between the port # resource request and the RPs in the allocation the scheduler made. It # cannot do a proper mapping as we don't have information about the # traits of the RPs in the allocation. Also it is a greedy algorithm so # it selects the first matching RP even if there is multiple an even if # selecting the first RP means that a later port will not fit into the # remaining allocation. if not requested_networks: return {} neutron = get_client(context, admin=True) port_providers = {} for network_request in requested_networks: if network_request.port_id: port = neutron.show_port(network_request.port_id, fields=['resource_request'])['port'] resource_request = port.get('resource_request', None) if resource_request: resource_request = resource_request['resources'] rp = self._get_resource_provider_for_port_request( placement_allocations, resource_request) port_providers[network_request.port_id] = rp self._consume_port_allocation_from_allocations( rp, resource_request, placement_allocations) return port_providers ",,60,0
openstack%2Fcharm-vault~master~I9989c708a6385c728fa1fa9cff955efd70854774,openstack/charm-vault,master,I9989c708a6385c728fa1fa9cff955efd70854774,Move interface assessement earlier in assess status,MERGED,2019-02-22 09:32:31.000000000,2019-02-22 10:17:26.000000000,2019-02-22 10:17:26.000000000,"[{'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 09:32:31.000000000', 'files': ['unit_tests/test_reactive_vault_handlers.py', 'src/reactive/vault_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/e4411326d89592599e74bdd36a63a20ef608aa30', 'message': 'Move interface assessement earlier in assess status\n\nEnsure that interface state is assessed early in the assess_status\nfunction so that missing or incomplete interfaces are detected\ncorrectly, rather than the units just reporting a blocked status.\n\nChange-Id: I9989c708a6385c728fa1fa9cff955efd70854774\nCloses-Bug: 1811617\n'}]",0,638612,e4411326d89592599e74bdd36a63a20ef608aa30,7,3,1,935,,,0,"Move interface assessement earlier in assess status

Ensure that interface state is assessed early in the assess_status
function so that missing or incomplete interfaces are detected
correctly, rather than the units just reporting a blocked status.

Change-Id: I9989c708a6385c728fa1fa9cff955efd70854774
Closes-Bug: 1811617
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/12/638612/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_reactive_vault_handlers.py', 'src/reactive/vault_handlers.py']",2,e4411326d89592599e74bdd36a63a20ef608aa30,bug/1811617," _missing_interfaces = [] _incomplete_interfaces = [] _assess_interface_groups(REQUIRED_INTERFACES, optional=False, missing_interfaces=_missing_interfaces, incomplete_interfaces=_incomplete_interfaces) _assess_interface_groups(OPTIONAL_INTERFACES, optional=True, missing_interfaces=_missing_interfaces, incomplete_interfaces=_incomplete_interfaces) if _missing_interfaces or _incomplete_interfaces: state = 'blocked' if _missing_interfaces else 'waiting' status_set(state, ', '.join(_missing_interfaces + _incomplete_interfaces)) return "," _missing_interfaces = [] _incomplete_interfaces = [] _assess_interface_groups(REQUIRED_INTERFACES, optional=False, missing_interfaces=_missing_interfaces, incomplete_interfaces=_incomplete_interfaces) _assess_interface_groups(OPTIONAL_INTERFACES, optional=True, missing_interfaces=_missing_interfaces, incomplete_interfaces=_incomplete_interfaces) if _missing_interfaces or _incomplete_interfaces: state = 'blocked' if _missing_interfaces else 'waiting' status_set(state, ', '.join(_missing_interfaces + _incomplete_interfaces)) return ",25,19
openstack%2Fnetworking-baremetal~stable%2Fqueens~Iebb92beff9c4e16581a07b16ccdfbbeba3176543,openstack/networking-baremetal,stable/queens,Iebb92beff9c4e16581a07b16ccdfbbeba3176543,Rename agent queue - fixes broken minor update,MERGED,2019-02-20 09:33:56.000000000,2019-02-22 10:11:00.000000000,2019-02-22 10:11:00.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-02-20 09:33:56.000000000', 'files': ['networking_baremetal/agent/ironic_neutron_agent.py', 'releasenotes/notes/agent-notification-auto-delete-queues-a3782fbeea2b57b1.yaml'], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/3c655a9aca64ac6b875d5b840b325f1b12b22afc', 'message': 'Rename agent queue - fixes broken minor update\n\nWhen fixing the original issue the auto_delete policy for\nthe queue was changed to auto_delete = true. Changeing\nthe policy for an existing queue with auto_delete = fales\nis not allowed, thus the queue had to be deleted to allow\nit to be recreated with the new auto_delete policy.\n\nBy changeing the name of the queue, we can restart the\nagent after applying update and not have to delete the old\nqueue.\n\nNOTE: This changes the existing release notes, it is still\n      recommended to delete the old queue. But it is no\n      longer required to allow the agent to be restarted\n      with the fix.\n\nChange-Id: Iebb92beff9c4e16581a07b16ccdfbbeba3176543\nStory: 2004938\nTask: 29532\n(cherry picked from commit 83bfd778197361df04d1f4cceb9b9b6201a223e1)\n'}]",0,638114,3c655a9aca64ac6b875d5b840b325f1b12b22afc,15,4,1,24245,,,0,"Rename agent queue - fixes broken minor update

When fixing the original issue the auto_delete policy for
the queue was changed to auto_delete = true. Changeing
the policy for an existing queue with auto_delete = fales
is not allowed, thus the queue had to be deleted to allow
it to be recreated with the new auto_delete policy.

By changeing the name of the queue, we can restart the
agent after applying update and not have to delete the old
queue.

NOTE: This changes the existing release notes, it is still
      recommended to delete the old queue. But it is no
      longer required to allow the agent to be restarted
      with the fix.

Change-Id: Iebb92beff9c4e16581a07b16ccdfbbeba3176543
Story: 2004938
Task: 29532
(cherry picked from commit 83bfd778197361df04d1f4cceb9b9b6201a223e1)
",git fetch https://review.opendev.org/openstack/networking-baremetal refs/changes/14/638114/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_baremetal/agent/ironic_neutron_agent.py', 'releasenotes/notes/agent-notification-auto-delete-queues-a3782fbeea2b57b1.yaml']",2,3c655a9aca64ac6b875d5b840b325f1b12b22afc,story/2004938," oslo.messaging notification queues are now renamed and created with ``amqp_auto_delete=true``. When upgrading the agent old queues should be deleted to free up message broker resources. Previous queue that can be deleted are named ``ironic-neutron-agent-heartbeat.info``. There may also be queues with uuid of previous agent instances as name, these can also safely be deleted. (Look in the agent logs for relevant agent uuids)."," oslo.messaging notification queues are now created with ``amqp_auto_delete=true``. When upgrading the agent old queues must be deleted prior to starting the ``ironic-neutron-agent`` service again after the update. _(If the old queues were created with ``amqp_auto_delete=false``, the agent will not be able to start when the old queues still exist.)_ .. Warning:: Old queues must be deleted when updating to a version with this fix. Please refer to the upgrade section of the releasenotes for details. ",11,14
openstack%2Fopenstack-manuals~master~I3c4b12d95624fbfe4b2c2db535e381b6bce5d511,openstack/openstack-manuals,master,I3c4b12d95624fbfe4b2c2db535e381b6bce5d511,trivial: Fix indentation,MERGED,2019-02-21 15:09:08.000000000,2019-02-22 10:03:17.000000000,2019-02-22 10:03:16.000000000,"[{'_account_id': 20156}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 15:09:08.000000000', 'files': ['www/static/common/css/search.css', 'www/static/common/css/deprecated-badge.css'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1c1fdcbd7accc42c8330893c4fa59cd47156350f', 'message': 'trivial: Fix indentation\n\nThis was all over the shop. Fix it.\n\nChange-Id: I3c4b12d95624fbfe4b2c2db535e381b6bce5d511\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",0,638435,1c1fdcbd7accc42c8330893c4fa59cd47156350f,6,2,1,15334,,,0,"trivial: Fix indentation

This was all over the shop. Fix it.

Change-Id: I3c4b12d95624fbfe4b2c2db535e381b6bce5d511
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/35/638435/1 && git format-patch -1 --stdout FETCH_HEAD,"['www/static/common/css/search.css', 'www/static/common/css/deprecated-badge.css']",2,1c1fdcbd7accc42c8330893c4fa59cd47156350f,trivial," padding: 5px; box-shadow: 0px 1px 1px 0px rgba(0, 0, 0, 0.46); -webkit-font-smoothing: subpixel-antialiased; text-decoration: none; position: relative; margin-top: 8px; display: inline-block; margin-top: 0px; } text-align: left; } text-decoration: underline; position: fixed; top: 0; left: 0; right: 0; z-index: 1000; display: inline-block; float: right; display: none; font-size: 0.9em; display: inline-block; color: #000000 !important; color: #000000 !important; color: white !important; .deprecated-badge .deprecated-badge-close-button{ left:97%; }"," padding: 5px; box-shadow: 0px 1px 1px 0px rgba(0, 0, 0, 0.46); -webkit-font-smoothing: subpixel-antialiased; text-decoration: none; position: relative; margin-top: 8px; display: inline-block; margin-top: 0px; } text-align: left; } text-decoration: underline; position: fixed; top: 0; left: 0; right: 0; z-index: 1000; display: inline-block; float: right; display: none; font-size: 0.9em; display: inline-block; color: #000000 !important; color: #000000 !important; color: white !important; .deprecated-badge .deprecated-badge-close-button{ left:97%; }",35,34
openstack%2Fopenstack-manuals~master~I8dbf54ff90164b2c2945ba74fee4bcf51eaecabb,openstack/openstack-manuals,master,I8dbf54ff90164b2c2945ba74fee4bcf51eaecabb,"Use white'ish text for ""eol"", ""obsolete"" deprecated badges",MERGED,2019-02-21 15:09:08.000000000,2019-02-22 10:01:51.000000000,2019-02-22 10:01:51.000000000,"[{'_account_id': 6547}, {'_account_id': 10607}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 15:09:08.000000000', 'files': ['www/static/common/css/deprecated-badge.css'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/48a16b0b4b38bcf1d61138e25a73df881e01d468', 'message': 'Use white\'ish text for ""eol"", ""obsolete"" deprecated badges\n\nThe deprecated badge (which should really be called version banner or\nsomething, given that it\'s not really a ""badge"" and appears for\nnon-deprecated releases too) is a simple div with some text, a close\nbutton, and a Bootstrap dropdowns [1] to switch between versions.\nThis div has three classes, \'deprecated-badge\', \'fixed\', and\n\'deprecated-badge-X\', where \'X\' is the series status (i.e.\n\'deprecated-badge-current\').\n\nWe were setting the background color of the div using the\n\'.deprecated-badge\' selector and then overriding this using the\nversion-specific class selector. This background color was inherited by\nthe dropdown.\n\nThis had the end result of giving a unique color to the overall div for\ndifferent releases but the dropdown, which wasn\'t being overridden on a\nper-version basis, stayed the same, yielding a consistent blue dropdown\nregardless of the background.\n\nWe fix this by setting the background-color attributes on the dropdown\nbuttons explicitly, removing the background-color from the\n\'deprecated-badge\' class. While we\'re at it, we also fix the text color\nfor the main div, so that we\'re not trying to read dark blue text on a\ndark red background.\n\n[1] https://getbootstrap.com/docs/4.0/components/dropdowns/\n\nChange-Id: I8dbf54ff90164b2c2945ba74fee4bcf51eaecabb\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",0,638434,48a16b0b4b38bcf1d61138e25a73df881e01d468,7,3,1,15334,,,0,"Use white'ish text for ""eol"", ""obsolete"" deprecated badges

The deprecated badge (which should really be called version banner or
something, given that it's not really a ""badge"" and appears for
non-deprecated releases too) is a simple div with some text, a close
button, and a Bootstrap dropdowns [1] to switch between versions.
This div has three classes, 'deprecated-badge', 'fixed', and
'deprecated-badge-X', where 'X' is the series status (i.e.
'deprecated-badge-current').

We were setting the background color of the div using the
'.deprecated-badge' selector and then overriding this using the
version-specific class selector. This background color was inherited by
the dropdown.

This had the end result of giving a unique color to the overall div for
different releases but the dropdown, which wasn't being overridden on a
per-version basis, stayed the same, yielding a consistent blue dropdown
regardless of the background.

We fix this by setting the background-color attributes on the dropdown
buttons explicitly, removing the background-color from the
'deprecated-badge' class. While we're at it, we also fix the text color
for the main div, so that we're not trying to read dark blue text on a
dark red background.

[1] https://getbootstrap.com/docs/4.0/components/dropdowns/

Change-Id: I8dbf54ff90164b2c2945ba74fee4bcf51eaecabb
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/34/638434/1 && git format-patch -1 --stdout FETCH_HEAD,['www/static/common/css/deprecated-badge.css'],1,48a16b0b4b38bcf1d61138e25a73df881e01d468,trivial,".deprecated-badge-obsolete, .deprecated-badge-eol { background: #b33a3a; } .deprecated-badge-obsolete a, .deprecated-badge-obsolete p, .deprecated-badge-eol a, .deprecated-badge-eol p {.deprecated-badge-obsolete .docs-dropdown, .deprecated-badge-eol .docs-dropdown { background: #922f2f; } .deprecated-badge-maintained, .deprecated-badge-development { background: #eaeaea; } .deprecated-badge-maintained .docs-dropdown, .deprecated-badge-development .docs-dropdown { background: #cfcfcf; } .deprecated-badge-development a, .deprecated-badge-development p, .deprecated-badge-maintained a, .deprecated-badge-maintained p { /* use default */ } .deprecated-badge-current { background: #30739c; } .deprecated-badge-current .docs-dropdown { background: #2a4e68; } .deprecated-badge-current a, .deprecated-badge-current p { color: #edf2f7;"," background: #2A4E68;.deprecated-badge-obsolete { background: #b33a3a !important; } .deprecated-badge-eol { background: #b33a3a !important; } .deprecated-badge-current { background: #30739C !important; } .deprecated-badge-maintained { background: #eaeaea !important; } .deprecated-badge-development { background: #eaeaea !important; } .deprecated-badge-development a, .deprecated-badge-development p { } .deprecated-badge-maintained a, .deprecated-badge-maintained p { } .deprecated-badge-current a, .deprecated-badge-current p {.deprecated-badge .container { ",38,29
openstack%2Foctavia~master~I6309c764334eb527bef39fb93740c4d7c8a98398,openstack/octavia,master,I6309c764334eb527bef39fb93740c4d7c8a98398,db: patch alembic migrations for postgresql,NEW,2018-12-17 11:24:59.000000000,2019-02-22 09:47:18.000000000,,"[{'_account_id': 7249}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 27056}]","[{'number': 1, 'created': '2018-12-17 11:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8d3fcbf1057f20a54d76985a676ebfca33204396', 'message': ""db: patch alembic migrations for postgresql\n\nSome alembic migrations contain MySQL specific key names, which break\nmigrations on PostgreSQL. MySQL relies on the type_='primary' option to\nuse the PRIMARY index name, so update the index names to the ones\nPostgreSQL chooses automatically.\n\nThe proper solution is to have an explicit name for all indices, but\nthis can only be done easily at the beginning.\n\nThis modifies existing migrations, because they cannot applied on\nPostgreSQL at all in their current state. On MySQL these migrations\nshould have the same effect as before.\n\nChange-Id: I6309c764334eb527bef39fb93740c4d7c8a98398\nSigned-off-by: Sven Wegener <sven.wegener@inovex.de>\n""}, {'number': 2, 'created': '2018-12-17 13:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/abb36b876aeb786ca796a621f2bc87658a0c2281', 'message': ""db: patch alembic migrations for postgresql\n\nSome alembic migrations contain MySQL specific key names, which break\nmigrations on PostgreSQL. MySQL relies on the type_='primary' option to\nuse the PRIMARY index name, so update the index names to the ones\nPostgreSQL chooses automatically.\n\nThe proper solution is to have an explicit name for all indices, but\nthis can only be done easily at the beginning.\n\nThis modifies existing migrations, because they cannot applied on\nPostgreSQL at all in their current state. On MySQL these migrations\nshould have the same effect as before.\n\nChange-Id: I6309c764334eb527bef39fb93740c4d7c8a98398\nSigned-off-by: Sven Wegener <sven.wegener@inovex.de>\n""}, {'number': 3, 'created': '2019-01-17 08:55:17.000000000', 'files': ['octavia/db/migration/alembic_migrations/versions/9bf4d21caaea_adding_amphora_id_to_listener_.py', 'octavia/db/migration/alembic_migrations/versions/fac584114642_.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/e5bfc113385dcc943c69e99d036eb42e5575eaef', 'message': ""db: patch alembic migrations for postgresql\n\nSome alembic migrations contain MySQL specific key names, which break\nmigrations on PostgreSQL. MySQL relies on the type_='primary' option to\nuse the PRIMARY index name, so update the index names to the ones\nPostgreSQL chooses automatically.\n\nThe proper solution is to have an explicit name for all indices, but\nthis can only be done easily at the beginning.\n\nThis modifies existing migrations, because they cannot be applied on\nPostgreSQL at all in their current state. On MySQL these migrations\nshould have the same effect as before.\n\nChange-Id: I6309c764334eb527bef39fb93740c4d7c8a98398\nSigned-off-by: Sven Wegener <sven.wegener@inovex.de>\n""}]",5,625557,e5bfc113385dcc943c69e99d036eb42e5575eaef,9,4,3,27056,,,0,"db: patch alembic migrations for postgresql

Some alembic migrations contain MySQL specific key names, which break
migrations on PostgreSQL. MySQL relies on the type_='primary' option to
use the PRIMARY index name, so update the index names to the ones
PostgreSQL chooses automatically.

The proper solution is to have an explicit name for all indices, but
this can only be done easily at the beginning.

This modifies existing migrations, because they cannot be applied on
PostgreSQL at all in their current state. On MySQL these migrations
should have the same effect as before.

Change-Id: I6309c764334eb527bef39fb93740c4d7c8a98398
Signed-off-by: Sven Wegener <sven.wegener@inovex.de>
",git fetch https://review.opendev.org/openstack/octavia refs/changes/57/625557/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/db/migration/alembic_migrations/versions/9bf4d21caaea_adding_amphora_id_to_listener_.py', 'octavia/db/migration/alembic_migrations/versions/fac584114642_.py']",2,8d3fcbf1057f20a54d76985a676ebfca33204396,alembic-postgresql," op.alter_column(""health_monitor"", ""id"", existing_type=sa.String(length=36), nullable=False) op.drop_constraint(""health_monitor_pkey"", ""health_monitor"", type_=""primary"") op.create_primary_key(""health_monitor_pkey"", ""health_monitor"", [""id""])"," op.execute(""ALTER TABLE health_monitor MODIFY id varchar(36) NOT NULL"") op.execute(""ALTER TABLE health_monitor DROP PRIMARY KEY,"" ""ADD PRIMARY KEY(id);"")",5,4
openstack%2Fopenstack-ansible-haproxy_server~master~I1db5932c559b5e04d330c114164869dd43c1cbb2,openstack/openstack-ansible-haproxy_server,master,I1db5932c559b5e04d330c114164869dd43c1cbb2,Add 'absent' service state,MERGED,2018-09-17 14:51:16.000000000,2019-02-22 09:47:11.000000000,2018-10-25 12:35:11.000000000,"[{'_account_id': 6816}, {'_account_id': 13095}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2018-09-17 14:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-haproxy_server/commit/b68f854e3aa37a8f81af0377cda07b84553c72e2', 'message': ""Add 'absent' service state\n\nAllow deprecation of haproxy endpoints by setting the state of the\nservice to 'absent'.\n\nChange-Id: I1db5932c559b5e04d330c114164869dd43c1cbb2\n""}, {'number': 2, 'created': '2018-09-17 14:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-haproxy_server/commit/30ebc18fa16644851dd4df43f7f58963ee95e953', 'message': ""Add 'absent' service state\n\nAllow deprecation of haproxy endpoints by setting the state of the\nservice to 'absent'.\n\nChange-Id: I1db5932c559b5e04d330c114164869dd43c1cbb2\n""}, {'number': 3, 'created': '2018-09-17 14:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-haproxy_server/commit/74b89a7b117219b2883742e835e5e5604a580088', 'message': ""Add 'absent' service state\n\nAllow deprecation of haproxy endpoints by setting the state of the\nservice to 'absent'.\n\nChange-Id: I1db5932c559b5e04d330c114164869dd43c1cbb2\n""}, {'number': 4, 'created': '2018-09-17 16:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-haproxy_server/commit/2835eb2db9df6cb3ed11073f1cab90c66409b531', 'message': ""Add 'absent' service state\n\nAllow deprecation of haproxy endpoints by setting the state of the\nservice to 'absent'.\n\nChange-Id: I1db5932c559b5e04d330c114164869dd43c1cbb2\n""}, {'number': 5, 'created': '2018-09-17 17:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-haproxy_server/commit/149bd21750fddbf920cdac6cadb8f2b4267bc869', 'message': ""Add 'absent' service state\n\nAllow deprecation of haproxy endpoints by setting the state of the\nservice to 'absent'.\n\nChange-Id: I1db5932c559b5e04d330c114164869dd43c1cbb2\n""}, {'number': 6, 'created': '2018-10-08 13:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-haproxy_server/commit/40f07f5304926e574bb26b4f0f9648d0b2969d29', 'message': ""Add 'absent' service state\n\nAllow deprecation of haproxy endpoints by setting the state of the\nservice to 'absent'.\n\nChange-Id: I1db5932c559b5e04d330c114164869dd43c1cbb2\n""}, {'number': 7, 'created': '2018-10-08 13:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-haproxy_server/commit/1524f0db2fdc2307a49900dd15a54f16304caf56', 'message': ""Add 'absent' service state\n\nAllow deprecation of haproxy endpoints by setting the state of the\nservice to 'absent'. It will also now clean up any config files\nwhen there are no backends, or the service is disabled.\n\nChange-Id: I1db5932c559b5e04d330c114164869dd43c1cbb2\n""}, {'number': 8, 'created': '2018-10-08 14:11:17.000000000', 'files': ['tests/test.yml', 'tasks/haproxy_service_config.yml', 'defaults/main.yml', 'tests/test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-haproxy_server/commit/972ebbe5db3b5e340176640129b4dc7923ead8aa', 'message': ""Add 'absent' service state\n\nAllow deprecation of haproxy endpoints by setting the state of the\nservice to 'absent'. It will also now clean up any config files\nwhen there are no backends, or the service is disabled.\n\nChange-Id: I1db5932c559b5e04d330c114164869dd43c1cbb2\n""}]",0,603158,972ebbe5db3b5e340176640129b4dc7923ead8aa,19,4,8,17799,,,0,"Add 'absent' service state

Allow deprecation of haproxy endpoints by setting the state of the
service to 'absent'. It will also now clean up any config files
when there are no backends, or the service is disabled.

Change-Id: I1db5932c559b5e04d330c114164869dd43c1cbb2
",git fetch https://review.opendev.org/openstack/openstack-ansible-haproxy_server refs/changes/58/603158/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test.yml', 'tasks/haproxy_service_config.yml', 'tests/test-vars.yml']",3,b68f854e3aa37a8f81af0377cda07b84553c72e2,absent-service, - service: haproxy_service_name: test_absent_service haproxy_port: 65535 haproxy_absent_services: - service: haproxy_service_name: test_absent_service state: absent,,26,0
openstack%2Fkolla-ansible~master~I7bcce56a2138eeadcabac79dd07c8dba1c5af644,openstack/kolla-ansible,master,I7bcce56a2138eeadcabac79dd07c8dba1c5af644,Allow nova services to use independent hostnames,MERGED,2018-12-18 14:45:26.000000000,2019-02-22 09:03:17.000000000,2019-02-22 09:03:17.000000000,"[{'_account_id': 10343}, {'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 21691}, {'_account_id': 22348}, {'_account_id': 23717}]","[{'number': 1, 'created': '2018-12-18 14:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/05eedeadb734f6c7a716dfb20762e929ea354c76', 'message': 'Allow nova services to use independent hostnames\n\nThis allows nova service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* nova_internal_fqdn\n* nova_external_fqdn\n* placement_internal_fqdn\n* placement_external_fqdn\n* nova_novncproxy_fqdn\n* nova_spicehtml5proxy_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nChange-Id: I7bcce56a2138eeadcabac79dd07c8dba1c5af644\nImplements: blueprint service-hostnames\n'}, {'number': 2, 'created': '2018-12-18 16:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a009d77bc85e3f9c640ac8d6277ac8188ed07342', 'message': 'Allow nova services to use independent hostnames\n\nThis allows nova service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* nova_internal_fqdn\n* nova_external_fqdn\n* placement_internal_fqdn\n* placement_external_fqdn\n* nova_novncproxy_fqdn\n* nova_spicehtml5proxy_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* nova_api_listen_port\n* nova_metadata_listen_port\n* nova_novncproxy_listen_port\n* nova_spicehtml5proxy_listen_port\n* nova_serialproxy_listen_port\n* placement_api_listen_port\n\nThese default to <service>_port, e.g. nova_api_port, for backward\ncompatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I7bcce56a2138eeadcabac79dd07c8dba1c5af644\nImplements: blueprint service-hostnames\n'}, {'number': 3, 'created': '2018-12-18 19:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/79675891b4d0628fb1694e1eefd41ea84d294cd8', 'message': 'Allow nova services to use independent hostnames\n\nThis allows nova service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* nova_internal_fqdn\n* nova_external_fqdn\n* placement_internal_fqdn\n* placement_external_fqdn\n* nova_novncproxy_fqdn\n* nova_spicehtml5proxy_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* nova_api_listen_port\n* nova_metadata_listen_port\n* nova_novncproxy_listen_port\n* nova_spicehtml5proxy_listen_port\n* nova_serialproxy_listen_port\n* placement_api_listen_port\n\nThese default to <service>_port, e.g. nova_api_port, for backward\ncompatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I7bcce56a2138eeadcabac79dd07c8dba1c5af644\nImplements: blueprint service-hostnames\n'}, {'number': 4, 'created': '2018-12-18 19:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/98af8ed07bf843b494c98f90d8f0e8ffcf39e794', 'message': 'Allow nova services to use independent hostnames\n\nThis allows nova service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* nova_internal_fqdn\n* nova_external_fqdn\n* placement_internal_fqdn\n* placement_external_fqdn\n* nova_novncproxy_fqdn\n* nova_spicehtml5proxy_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* nova_api_listen_port\n* nova_metadata_listen_port\n* nova_novncproxy_listen_port\n* nova_spicehtml5proxy_listen_port\n* nova_serialproxy_listen_port\n* placement_api_listen_port\n\nThese default to <service>_port, e.g. nova_api_port, for backward\ncompatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I7bcce56a2138eeadcabac79dd07c8dba1c5af644\nImplements: blueprint service-hostnames\n'}, {'number': 5, 'created': '2018-12-20 18:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/724d634d3e6a866bbc7ffc2d08e8d5e98ecc3c91', 'message': 'Allow nova services to use independent hostnames\n\nThis allows nova service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* nova_internal_fqdn\n* nova_external_fqdn\n* placement_internal_fqdn\n* placement_external_fqdn\n* nova_novncproxy_fqdn\n* nova_spicehtml5proxy_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* nova_api_listen_port\n* nova_metadata_listen_port\n* nova_novncproxy_listen_port\n* nova_spicehtml5proxy_listen_port\n* nova_serialproxy_listen_port\n* placement_api_listen_port\n\nThese default to <service>_port, e.g. nova_api_port, for backward\ncompatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I7bcce56a2138eeadcabac79dd07c8dba1c5af644\nImplements: blueprint service-hostnames\n'}, {'number': 6, 'created': '2018-12-26 16:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/da4558fb226b14c36c225a15a7382fe87588e74e', 'message': 'Allow nova services to use independent hostnames\n\nThis allows nova service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* nova_internal_fqdn\n* nova_external_fqdn\n* placement_internal_fqdn\n* placement_external_fqdn\n* nova_novncproxy_fqdn\n* nova_spicehtml5proxy_fqdn\n* nova_serialproxy_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* nova_api_listen_port\n* nova_metadata_listen_port\n* nova_novncproxy_listen_port\n* nova_spicehtml5proxy_listen_port\n* nova_serialproxy_listen_port\n* placement_api_listen_port\n\nThese default to <service>_port, e.g. nova_api_port, for backward\ncompatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I7bcce56a2138eeadcabac79dd07c8dba1c5af644\nImplements: blueprint service-hostnames\n'}, {'number': 7, 'created': '2018-12-27 17:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ccaa77472d6bd58a0738d5064cf2942c92d22ad7', 'message': 'Allow nova services to use independent hostnames\n\nThis allows nova service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* nova_internal_fqdn\n* nova_external_fqdn\n* placement_internal_fqdn\n* placement_external_fqdn\n* nova_novncproxy_fqdn\n* nova_spicehtml5proxy_fqdn\n* nova_serialproxy_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* nova_api_listen_port\n* nova_metadata_listen_port\n* nova_novncproxy_listen_port\n* nova_spicehtml5proxy_listen_port\n* nova_serialproxy_listen_port\n* placement_api_listen_port\n\nThese default to <service>_port, e.g. nova_api_port, for backward\ncompatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I7bcce56a2138eeadcabac79dd07c8dba1c5af644\nImplements: blueprint service-hostnames\n'}, {'number': 8, 'created': '2018-12-27 20:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/20c803d9235d9fd3952bb271da93536ec6a69265', 'message': 'Allow nova services to use independent hostnames\n\nThis allows nova service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* nova_internal_fqdn\n* nova_external_fqdn\n* placement_internal_fqdn\n* placement_external_fqdn\n* nova_novncproxy_fqdn\n* nova_spicehtml5proxy_fqdn\n* nova_serialproxy_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* nova_api_listen_port\n* nova_metadata_listen_port\n* nova_novncproxy_listen_port\n* nova_spicehtml5proxy_listen_port\n* nova_serialproxy_listen_port\n* placement_api_listen_port\n\nThese default to <service>_port, e.g. nova_api_port, for backward\ncompatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I7bcce56a2138eeadcabac79dd07c8dba1c5af644\nImplements: blueprint service-hostnames\n'}, {'number': 9, 'created': '2019-02-08 15:30:14.000000000', 'files': ['ansible/roles/nova/templates/nova.conf.j2', 'ansible/roles/nova/tasks/precheck.yml', 'ansible/roles/neutron/templates/metadata_agent.ini.j2', 'ansible/roles/nova/templates/placement-api-wsgi.conf.j2', 'ansible/group_vars/all.yml', 'ansible/roles/nova/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/51c9e1b6338d6f1ab05040e7ed92b051c0a0411b', 'message': 'Allow nova services to use independent hostnames\n\nThis allows nova service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* nova_internal_fqdn\n* nova_external_fqdn\n* placement_internal_fqdn\n* placement_external_fqdn\n* nova_novncproxy_fqdn\n* nova_spicehtml5proxy_fqdn\n* nova_serialproxy_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* nova_api_listen_port\n* nova_metadata_listen_port\n* nova_novncproxy_listen_port\n* nova_spicehtml5proxy_listen_port\n* nova_serialproxy_listen_port\n* placement_api_listen_port\n\nThese default to <service>_port, e.g. nova_api_port, for backward\ncompatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I7bcce56a2138eeadcabac79dd07c8dba1c5af644\nImplements: blueprint service-hostnames\n'}]",10,625933,51c9e1b6338d6f1ab05040e7ed92b051c0a0411b,33,6,9,10343,,,0,"Allow nova services to use independent hostnames

This allows nova service endpoints to use custom hostnames, and adds the
following variables:

* nova_internal_fqdn
* nova_external_fqdn
* placement_internal_fqdn
* placement_external_fqdn
* nova_novncproxy_fqdn
* nova_spicehtml5proxy_fqdn
* nova_serialproxy_fqdn

These default to the old values of kolla_internal_fqdn or
kolla_external_fqdn.

This also adds the following variables:

* nova_api_listen_port
* nova_metadata_listen_port
* nova_novncproxy_listen_port
* nova_spicehtml5proxy_listen_port
* nova_serialproxy_listen_port
* placement_api_listen_port

These default to <service>_port, e.g. nova_api_port, for backward
compatibility.

These options allow the user to differentiate between the port the
service listens on, and the port the service is reachable on. This is
useful for external load balancers which live on the same host as the
service itself.

Change-Id: I7bcce56a2138eeadcabac79dd07c8dba1c5af644
Implements: blueprint service-hostnames
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/33/625933/7 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/nova/templates/nova.conf.j2', 'ansible/roles/neutron/templates/metadata_agent.ini.j2', 'ansible/roles/nova/defaults/main.yml']",3,05eedeadb734f6c7a716dfb20762e929ea354c76,bp/service-hostnames,"nova_internal_fqdn: ""{{ kolla_internal_fqdn }}"" nova_external_fqdn: ""{{ kolla_external_fqdn }}"" placement_internal_fqdn: ""{{ kolla_internal_fqdn }}"" placement_external_fqdn: ""{{ kolla_external_fqdn }}"" nova_novncproxy_fqdn: ""{{ kolla_external_fqdn }}"" nova_spicehtml5proxy_fqdn: ""{{ kolla_external_fqdn }}"" nova_legacy_admin_endpoint: ""{{ admin_protocol }}://{{ nova_internal_fqdn }}:{{ nova_api_port }}/v2/%(tenant_id)s"" nova_legacy_internal_endpoint: ""{{ internal_protocol }}://{{ nova_internal_fqdn }}:{{ nova_api_port }}/v2/%(tenant_id)s"" nova_legacy_public_endpoint: ""{{ public_protocol }}://{{ nova_external_fqdn }}:{{ nova_api_port }}/v2/%(tenant_id)s"" nova_admin_endpoint: ""{{ admin_protocol }}://{{ nova_internal_fqdn }}:{{ nova_api_port }}/v2.1/%(tenant_id)s"" nova_internal_endpoint: ""{{ internal_protocol }}://{{ nova_internal_fqdn }}:{{ nova_api_port }}/v2.1/%(tenant_id)s"" nova_public_endpoint: ""{{ public_protocol }}://{{ nova_external_fqdn }}:{{ nova_api_port }}/v2.1/%(tenant_id)s"" placement_admin_endpoint: ""{{ admin_protocol }}://{{ placement_internal_fqdn }}:{{ placement_api_port }}"" placement_internal_endpoint: ""{{ internal_protocol }}://{{ placement_internal_fqdn }}:{{ placement_api_port }}"" placement_public_endpoint: ""{{ public_protocol }}://{{ placement_external_fqdn }}:{{ placement_api_port }}""","nova_legacy_admin_endpoint: ""{{ admin_protocol }}://{{ kolla_internal_fqdn }}:{{ nova_api_port }}/v2/%(tenant_id)s"" nova_legacy_internal_endpoint: ""{{ internal_protocol }}://{{ kolla_internal_fqdn }}:{{ nova_api_port }}/v2/%(tenant_id)s"" nova_legacy_public_endpoint: ""{{ public_protocol }}://{{ kolla_external_fqdn }}:{{ nova_api_port }}/v2/%(tenant_id)s"" nova_admin_endpoint: ""{{ admin_protocol }}://{{ kolla_internal_fqdn }}:{{ nova_api_port }}/v2.1/%(tenant_id)s"" nova_internal_endpoint: ""{{ internal_protocol }}://{{ kolla_internal_fqdn }}:{{ nova_api_port }}/v2.1/%(tenant_id)s"" nova_public_endpoint: ""{{ public_protocol }}://{{ kolla_external_fqdn }}:{{ nova_api_port }}/v2.1/%(tenant_id)s"" placement_admin_endpoint: ""{{ admin_protocol }}://{{ kolla_internal_fqdn }}:{{ placement_api_port }}"" placement_internal_endpoint: ""{{ internal_protocol }}://{{ kolla_internal_fqdn }}:{{ placement_api_port }}"" placement_public_endpoint: ""{{ public_protocol }}://{{ kolla_external_fqdn }}:{{ placement_api_port }}""",19,12
openstack%2Fkolla-ansible~master~Iebd98acf03418817d3707c4a117771b73da80166,openstack/kolla-ansible,master,Iebd98acf03418817d3707c4a117771b73da80166,Add haproxy stats to gate logs,MERGED,2019-02-21 10:04:13.000000000,2019-02-22 09:03:16.000000000,2019-02-22 09:03:16.000000000,"[{'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 21691}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 10:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a648bb71ca478c77cced6ed08133c1536c7a26fe', 'message': 'Add haproxy stats to gate logs\n\nChange-Id: Iebd98acf03418817d3707c4a117771b73da80166\n'}, {'number': 2, 'created': '2019-02-21 11:56:05.000000000', 'files': ['tests/get_logs.sh'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3f01c7c7cd2d482153d46d4448c6a329bd89951a', 'message': 'Add haproxy stats to gate logs\n\nChange-Id: Iebd98acf03418817d3707c4a117771b73da80166\n'}]",0,638376,3f01c7c7cd2d482153d46d4448c6a329bd89951a,10,4,2,22629,,,0,"Add haproxy stats to gate logs

Change-Id: Iebd98acf03418817d3707c4a117771b73da80166
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/76/638376/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/get_logs.sh'],1,a648bb71ca478c77cced6ed08133c1536c7a26fe,feature/gate_add_haproxy_stats," # haproxy related logs if [[ $(docker ps --filter name=haproxy --format ""{{.Names}}"") ]]; then mkdir -p ${LOG_DIR}/kolla/haproxy docker exec haproxy bash -c 'echo show stat | socat stdio /var/lib/kolla/haproxy/haproxy.sock' > ${LOG_DIR}/kolla/haproxy/stats.txt fi ",,6,0
openstack%2Fkolla-ansible~master~I0718fca08ea116db926b348e3e6e3bc2373db1fb,openstack/kolla-ansible,master,I0718fca08ea116db926b348e3e6e3bc2373db1fb,Make Kafka maintenance easier,MERGED,2019-02-19 11:15:56.000000000,2019-02-22 09:03:15.000000000,2019-02-22 09:03:14.000000000,"[{'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 21691}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-19 11:15:56.000000000', 'files': ['ansible/roles/kafka/templates/kafka.server.properties.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/10ec566f56f8b19c6ca44423dbda974f0b03604e', 'message': 'Make Kafka maintenance easier\n\nThis commit enables two settings which are useful when restarting a Kafka node\nas part of a cluster. The first supports moving partitions for which a node\nbeing restarting is the leader to another broker, and the second supports\nautomatically rebalancing partitions when the node rejoins the cluster. See\nthe documentation for more details:\n\nhttps://kafka.apache.org/10/documentation.html#basic_ops_restarting\n\nChange-Id: I0718fca08ea116db926b348e3e6e3bc2373db1fb\n'}]",0,637821,10ec566f56f8b19c6ca44423dbda974f0b03604e,8,4,1,17669,,,0,"Make Kafka maintenance easier

This commit enables two settings which are useful when restarting a Kafka node
as part of a cluster. The first supports moving partitions for which a node
being restarting is the leader to another broker, and the second supports
automatically rebalancing partitions when the node rejoins the cluster. See
the documentation for more details:

https://kafka.apache.org/10/documentation.html#basic_ops_restarting

Change-Id: I0718fca08ea116db926b348e3e6e3bc2373db1fb
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/21/637821/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/kafka/templates/kafka.server.properties.j2'],1,10ec566f56f8b19c6ca44423dbda974f0b03604e,,controlled.shutdown.enable=true auto.leader.rebalance.enable=true,,2,0
openstack%2Fkolla-ansible~master~I00decfe94607845ef0eae9bec631a0e729aac3fa,openstack/kolla-ansible,master,I00decfe94607845ef0eae9bec631a0e729aac3fa,Parse Monasca Log API timestamps correctly,MERGED,2019-02-19 14:07:03.000000000,2019-02-22 09:03:14.000000000,2019-02-22 09:03:14.000000000,"[{'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 21691}, {'_account_id': 22348}, {'_account_id': 28239}]","[{'number': 1, 'created': '2019-02-19 14:07:03.000000000', 'files': ['ansible/roles/monasca/templates/monasca-log-transformer/log-transformer.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e2ed302312aee1db8dc22acdd0609d168664bd6f', 'message': 'Parse Monasca Log API timestamps correctly\n\nBy parsing the creation_time timestamp in Logstash, Elasticsearch\ncan parse it correctly. This closes a bug where the creation_time\ntimestamp was shown as a date shortly after the epoch (1970) when\nviewed in Kibana.\n\nCloses-Bug: #1816585\n\nChange-Id: I00decfe94607845ef0eae9bec631a0e729aac3fa\n'}]",0,637850,e2ed302312aee1db8dc22acdd0609d168664bd6f,9,5,1,17669,,,0,"Parse Monasca Log API timestamps correctly

By parsing the creation_time timestamp in Logstash, Elasticsearch
can parse it correctly. This closes a bug where the creation_time
timestamp was shown as a date shortly after the epoch (1970) when
viewed in Kibana.

Closes-Bug: #1816585

Change-Id: I00decfe94607845ef0eae9bec631a0e729aac3fa
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/50/637850/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/monasca/templates/monasca-log-transformer/log-transformer.conf.j2'],1,e2ed302312aee1db8dc22acdd0609d168664bd6f,bug/1816585," # Monasca Log API adds a timestamp when it processes a log entry. This # timestamp needs to be converted from seconds since the epoch for # Elasticsearch to parse it correctly. Here we make that conversion. date { match => [""creation_time"", ""UNIX""] target => ""creation_time"" } ",,8,0
openstack%2Fcharm-openstack-dashboard~master~I2ac03b406cc8b787424747c0bfeeedffd7712c9f,openstack/charm-openstack-dashboard,master,I2ac03b406cc8b787424747c0bfeeedffd7712c9f,Make DROPDOWN_MAX_ITEMS configurable,MERGED,2019-02-21 18:07:21.000000000,2019-02-22 08:27:05.000000000,2019-02-22 08:27:05.000000000,"[{'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 18:07:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/305b3f46db0ee47e7f6d4e84319b5308e5df5d51', 'message': 'Make DROPDOWN_MAX_ITEMS configurable by new option dropdown-max-items\n\nThis change implements a new option dropdown-max-items, that\nsets the DROPDOWN_MAX_ITEMS of horizon.\n\nChange-Id: I2ac03b406cc8b787424747c0bfeeedffd7712c9f\n'}, {'number': 2, 'created': '2019-02-21 18:36:50.000000000', 'files': ['hooks/horizon_contexts.py', 'templates/newton/local_settings.py', 'templates/mitaka/local_settings.py', 'unit_tests/test_horizon_contexts.py', 'config.yaml', 'templates/ocata/local_settings.py', 'templates/liberty/local_settings.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/fd9fe985362d82b274319730b40cb8a8ab425705', 'message': 'Make DROPDOWN_MAX_ITEMS configurable\n\nThis change implements a new option dropdown-max-items, that\nsets the DROPDOWN_MAX_ITEMS of horizon.\n\nChange-Id: I2ac03b406cc8b787424747c0bfeeedffd7712c9f\n'}]",0,638473,fd9fe985362d82b274319730b40cb8a8ab425705,9,3,2,29260,,,0,"Make DROPDOWN_MAX_ITEMS configurable

This change implements a new option dropdown-max-items, that
sets the DROPDOWN_MAX_ITEMS of horizon.

Change-Id: I2ac03b406cc8b787424747c0bfeeedffd7712c9f
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/73/638473/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_contexts.py', 'templates/newton/local_settings.py', 'templates/mitaka/local_settings.py', 'unit_tests/test_horizon_contexts.py', 'config.yaml', 'templates/ocata/local_settings.py', 'templates/liberty/local_settings.py']",7,305b3f46db0ee47e7f6d4e84319b5308e5df5d51,maxdropdownitems,DROPDOWN_MAX_ITEMS = {{ dropdown_max_items }},DROPDOWN_MAX_ITEMS = 30,25,5
openstack%2Fneutron-tempest-plugin~master~Ib0fe7d58f6ffc8e986da02aa1c4f2bf5b947ebda,openstack/neutron-tempest-plugin,master,Ib0fe7d58f6ffc8e986da02aa1c4f2bf5b947ebda,Remove test_update_sg_rule_bumps_sg_revision test,ABANDONED,2019-02-04 06:59:48.000000000,2019-02-22 08:26:22.000000000,,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 8788}, {'_account_id': 9531}, {'_account_id': 10267}, {'_account_id': 10980}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-04 06:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/d7c6ed7c24042db53b4dcd943e520169a9b8ec47', 'message': ""Remove test_update_sg_rule_bumps_sg_revision test\n\nChange [1] is removing revises_on_change from SecurityGroupRule,\ni.e updating security group rule won't update standardattribute\nfor security group, hence we need to remove this test.\n\n[1] https://review.openstack.org/#/c/632479/\n\nChange-Id: Ib0fe7d58f6ffc8e986da02aa1c4f2bf5b947ebda\n""}, {'number': 2, 'created': '2019-02-04 10:12:10.000000000', 'files': ['neutron_tempest_plugin/api/test_revisions.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/1af6097fc91004b10b9a9821f1de8573ce8640f8', 'message': ""Remove test_update_sg_rule_bumps_sg_revision test\n\nChange [1] is removing revises_on_change from SecurityGroupRule,\ni.e updating security group rule won't update standardattribute\nfor security group, hence we need to remove this test.\n\n[1] https://review.openstack.org/#/c/632479/\n\nChange-Id: Ib0fe7d58f6ffc8e986da02aa1c4f2bf5b947ebda\n""}]",0,634632,1af6097fc91004b10b9a9821f1de8573ce8640f8,13,9,2,10267,,,0,"Remove test_update_sg_rule_bumps_sg_revision test

Change [1] is removing revises_on_change from SecurityGroupRule,
i.e updating security group rule won't update standardattribute
for security group, hence we need to remove this test.

[1] https://review.openstack.org/#/c/632479/

Change-Id: Ib0fe7d58f6ffc8e986da02aa1c4f2bf5b947ebda
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/32/634632/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/api/test_revisions.py'],1,d7c6ed7c24042db53b4dcd943e520169a9b8ec47,revises_on_change,," @decorators.idempotent_id('29c7ab2b-d1d8-425d-8cec-fcf632960f22') @utils.requires_ext(extension=""security-group"", service=""network"") def test_update_sg_rule_bumps_sg_revision(self): security_group = self.create_security_group() security_group_rule = self.create_security_group_rule( security_group=security_group, protocol=constants.PROTO_NAME_TCP, direction=constants.INGRESS_DIRECTION, port_range_min=60, port_range_max=70) updated_security_group = self.client.show_security_group( security_group['id'])['security_group'] self.assertGreater(updated_security_group['revision_number'], security_group['revision_number']) self.client.delete_security_group_rule(security_group_rule['id']) updated_security_group2 = self.client.show_security_group( security_group['id'])['security_group'] self.assertGreater(updated_security_group2['revision_number'], updated_security_group['revision_number']) ",0,22
openstack%2Fvitrage~master~Icb93de7faa92678e2107373d0ffe24ae2970a1af,openstack/vitrage,master,Icb93de7faa92678e2107373d0ffe24ae2970a1af,Remove end messages,MERGED,2019-02-18 14:18:48.000000000,2019-02-22 08:07:46.000000000,2019-02-22 08:07:46.000000000,"[{'_account_id': 1736}, {'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}, {'_account_id': 26339}, {'_account_id': 29383}]","[{'number': 1, 'created': '2019-02-18 14:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/bc0b71c8eb51eb612de8b30419b34bbcdb10bd92', 'message': 'WIP - remove end messages\n\nChange-Id: Icb93de7faa92678e2107373d0ffe24ae2970a1af\n'}, {'number': 2, 'created': '2019-02-19 07:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/657ee5ed1212b4665078c19a6c634f506d667f3b', 'message': 'Remove end messages\n\nDatasource end messages previously used to notify the processor\nthat get_all finished successfully. Are no longer used and are removed.\n\nStory: 2005042\nTask: 29539\nChange-Id: Icb93de7faa92678e2107373d0ffe24ae2970a1af\n'}, {'number': 3, 'created': '2019-02-20 13:09:12.000000000', 'files': ['releasenotes/notes/remove_end_messages-e92e7b41a52c61cf.yaml', 'vitrage/common/constants.py', 'vitrage/tests/functional/entity_graph/consistency/test_consistency.py', 'vitrage/entity_graph/consistency/__init__.py', 'vitrage/entity_graph/processor/processor.py', 'vitrage/tests/unit/datasources/static/test_static_driver.py', 'vitrage/datasources/driver_base.py', 'vitrage/datasources/transformer_base.py', 'vitrage/entity_graph/consistency/consistency_enforcer.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/552cad20491755c51f5fcb4e7b11ca95c66b3437', 'message': 'Remove end messages\n\nDatasource end messages previously used to notify the processor\nthat get_all finished successfully. Are no longer used and are removed.\n\nStory: 2005042\nTask: 29539\nChange-Id: Icb93de7faa92678e2107373d0ffe24ae2970a1af\n'}]",14,637553,552cad20491755c51f5fcb4e7b11ca95c66b3437,40,7,3,19184,,,0,"Remove end messages

Datasource end messages previously used to notify the processor
that get_all finished successfully. Are no longer used and are removed.

Story: 2005042
Task: 29539
Change-Id: Icb93de7faa92678e2107373d0ffe24ae2970a1af
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/53/637553/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/common/constants.py', 'vitrage/tests/functional/entity_graph/consistency/test_consistency.py', 'vitrage/entity_graph/consistency/__init__.py', 'vitrage/entity_graph/processor/processor.py', 'vitrage/tests/unit/datasources/static/test_static_driver.py', 'vitrage/datasources/driver_base.py', 'vitrage/datasources/transformer_base.py', 'vitrage/entity_graph/consistency/consistency_enforcer.py']",8,bc0b71c8eb51eb612de8b30419b34bbcdb10bd92,idan_hefetz/end_messages_removal,,"import time def _wait_for_action(self, function): count_retries = 0 while True: if count_retries >= \ self.conf.consistency.initialization_max_retries: return False if function(): return True count_retries += 1 time.sleep(self.conf.consistency.initialization_interval) ",17,76
openstack%2Fnova~master~Ie2d8a5bb057b62d0b57c61d7ec2f34f01208bcfd,openstack/nova,master,Ie2d8a5bb057b62d0b57c61d7ec2f34f01208bcfd,"* Progress_watermark is design for progress_timeout, and progress_timeout   is design for stuck of libvirt no matter progress_watermark is lesser than   data_remaining or greater than data_remaining.",ABANDONED,2016-09-22 07:49:32.000000000,2019-02-22 08:01:54.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 9891}, {'_account_id': 10118}, {'_account_id': 12299}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 19760}, {'_account_id': 26458}]","[{'number': 1, 'created': '2016-09-22 07:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1392fcb90f6bf738e5f370c9bd6ee86b0c01fb9a', 'message': ""* Progress_watermark is design for progress_timeout, and progress_timeout\n  is design for stuck of libvirt no matter progress_watermark is lesser than\n  data_remaining or greater than data_remaining.\n\n* When progress_watermark > data_remaining, it's meat that libvirtd has begin LM\n\n* When progress_watermark < data_remaining, it's meat that libvirtd has begin\n  next iteration of LM\n\n* When progress_watermark != data_remaning, it's meat that libvirtd has not\n  begin LM. there is be some problem with libvirtd, like libvirtd stuch or\n  network unreachable to dest host and so on.\n\n* Take progress_watermark initial to 0 instead of None,\n  because it's pointless to write progress_watermark == None of progress_watermark == 0.\n\nChange-Id: Ie2d8a5bb057b62d0b57c61d7ec2f34f01208bcfd\nCloses-Bug: #1625487\n""}, {'number': 2, 'created': '2016-09-22 08:06:05.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/01806972e918b47a2b3f61a5f6695161ed728629', 'message': ""* Progress_watermark is design for progress_timeout, and progress_timeout\n  is design for stuck of libvirt no matter progress_watermark is lesser than\n  data_remaining or greater than data_remaining.\n\n* When progress_watermark > data_remaining, it's meat that libvirtd has begin LM\n\n* When progress_watermark < data_remaining, it's meat that libvirtd has begin\n  next iteration of LM\n\n* When progress_watermark != data_remaning, it's meat that libvirtd has not\n  begin LM. there is be some problem with libvirtd, like libvirtd stuch or\n  network unreachable to dest host and so on.\n\n* Take progress_watermark initial to 0 instead of None,\n  because it's pointless to write progress_watermark == None of progress_watermark == 0.\n\nChange-Id: Ie2d8a5bb057b62d0b57c61d7ec2f34f01208bcfd\nCloses-Bug: #1625487\n""}]",3,374587,01806972e918b47a2b3f61a5f6695161ed728629,27,14,2,19760,,,0,"* Progress_watermark is design for progress_timeout, and progress_timeout
  is design for stuck of libvirt no matter progress_watermark is lesser than
  data_remaining or greater than data_remaining.

* When progress_watermark > data_remaining, it's meat that libvirtd has begin LM

* When progress_watermark < data_remaining, it's meat that libvirtd has begin
  next iteration of LM

* When progress_watermark != data_remaning, it's meat that libvirtd has not
  begin LM. there is be some problem with libvirtd, like libvirtd stuch or
  network unreachable to dest host and so on.

* Take progress_watermark initial to 0 instead of None,
  because it's pointless to write progress_watermark == None of progress_watermark == 0.

Change-Id: Ie2d8a5bb057b62d0b57c61d7ec2f34f01208bcfd
Closes-Bug: #1625487
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/374587/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,1392fcb90f6bf738e5f370c9bd6ee86b0c01fb9a,bug/1625487, progress_watermark = 0 if ((progress_watermark == 0) or (progress_watermark != info.data_remaining)):, progress_watermark = None if ((progress_watermark is None) or (progress_watermark == 0) or (progress_watermark > info.data_remaining)):,3,4
openstack%2Fglance_store~master~I6a89042fae63bf5c9096a6bee6774aebf3f5864b,openstack/glance_store,master,I6a89042fae63bf5c9096a6bee6774aebf3f5864b,Fix python3 compatibility of rbd get_fsid,MERGED,2019-02-06 17:39:36.000000000,2019-02-22 07:51:30.000000000,2019-02-22 07:51:30.000000000,"[{'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 17:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/b19c4200a7490ca86653ffe8653c9823e1ad803b', 'message': 'Fix python3 compatibility\n\nIn python3 conn.get_fsid() is represented as binary.\nThis patch is fixing this.\n\nChange-Id: I6a89042fae63bf5c9096a6bee6774aebf3f5864b\n'}, {'number': 2, 'created': '2019-02-20 09:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/65eaf20d98534ee1175591935d4ad8811047dd72', 'message': 'Fix python3 compatibility\n\nIn python3 conn.get_fsid() is represented as binary.\nBecause of this, direct_url is corrupted in DB.\nThis patch is fixing this. More informations in\nclosing bug.\n\nCloses-Bug: #1816721\n\nChange-Id: I6a89042fae63bf5c9096a6bee6774aebf3f5864b\n'}, {'number': 3, 'created': '2019-02-20 10:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/0ef61b8cd843c48c97d6f7e6d683427a1041be8f', 'message': 'Fix python3 compatibility\n\nIn python3 conn.get_fsid() is represented as binary.\nBecause of this, direct_url is corrupted in DB.\nThis patch is fixing this. More informations in\nclosing bug.\n\nCloses-Bug: #1816721\n\nChange-Id: I6a89042fae63bf5c9096a6bee6774aebf3f5864b\n'}, {'number': 4, 'created': '2019-02-20 12:37:50.000000000', 'files': ['glance_store/_drivers/rbd.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/9c73370358c02fc7f308d88f4563f22969a42c96', 'message': 'Fix python3 compatibility of rbd get_fsid\n\nIn python3 conn.get_fsid() is represented as binary.\nBecause of this, direct_url is corrupted in DB.\nThis patch is fixing this. More informations in\nclosing bug.\n\nCloses-Bug: #1816721\n\nChange-Id: I6a89042fae63bf5c9096a6bee6774aebf3f5864b\n'}]",1,635230,9c73370358c02fc7f308d88f4563f22969a42c96,14,3,4,27339,,,0,"Fix python3 compatibility of rbd get_fsid

In python3 conn.get_fsid() is represented as binary.
Because of this, direct_url is corrupted in DB.
This patch is fixing this. More informations in
closing bug.

Closes-Bug: #1816721

Change-Id: I6a89042fae63bf5c9096a6bee6774aebf3f5864b
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/30/635230/4 && git format-patch -1 --stdout FETCH_HEAD,['glance_store/_drivers/rbd.py'],1,b19c4200a7490ca86653ffe8653c9823e1ad803b,bug/1816721,from oslo_utils import encodeutils fsid = encodeutils.safe_decode(conn.get_fsid()), fsid = conn.get_fsid(),2,1
openstack%2Fproject-config~master~Ifc274f049381cacead030e4baac460a7697c20cc,openstack/project-config,master,Ifc274f049381cacead030e4baac460a7697c20cc,Remove tox-py35-on-zuul from zuul-jobs,MERGED,2019-02-21 22:59:43.000000000,2019-02-22 07:26:30.000000000,2019-02-22 07:26:29.000000000,"[{'_account_id': 2}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 22:59:43.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b1dca9f9dafee356c06cca830c2278232af43d17', 'message': ""Remove tox-py35-on-zuul from zuul-jobs\n\nWe now have some real usage of tox on this repo itself, so the\nself-testing of the tox environment we got from running this job\nis now supplied by that.  The tox-py35-on-zuul job takes a while\nto run and is sometimes flaky, so remove it so that it doesn't\nact as an unecessary blocker.\n\nChange-Id: Ifc274f049381cacead030e4baac460a7697c20cc\n""}]",0,638525,b1dca9f9dafee356c06cca830c2278232af43d17,7,3,1,1,,,0,"Remove tox-py35-on-zuul from zuul-jobs

We now have some real usage of tox on this repo itself, so the
self-testing of the tox environment we got from running this job
is now supplied by that.  The tox-py35-on-zuul job takes a while
to run and is sometimes flaky, so remove it so that it doesn't
act as an unecessary blocker.

Change-Id: Ifc274f049381cacead030e4baac460a7697c20cc
",git fetch https://review.opendev.org/openstack/project-config refs/changes/25/638525/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,b1dca9f9dafee356c06cca830c2278232af43d17,,, - tox-py35-on-zuul - tox-py35-on-zuul,0,2
openstack%2Fmistral~stable%2Frocky~I297054f052b79143b2d0882286fb3e22d19c70c5,openstack/mistral,stable/rocky,I297054f052b79143b2d0882286fb3e22d19c70c5,Release note for fixing event-engines HA,MERGED,2019-02-21 17:56:45.000000000,2019-02-22 07:07:55.000000000,2019-02-22 07:07:55.000000000,"[{'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 17:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/121bceacc2d77c7a717bf4abc526625fb4cdb077', 'message': 'Release note for fixing event-engines HA\n\nAdd missing release note for https://review.openstack.org/#/c/548044/\n\nChange-Id: I297054f052b79143b2d0882286fb3e22d19c70c5\n(cherry picked from commit ed7c351d0b38633ef56112ad87251b2d22873a93)\n'}, {'number': 2, 'created': '2019-02-21 17:57:12.000000000', 'files': ['releasenotes/notes/fix-event-engines-ha-cc78f341095cdabf.yaml'], 'web_link': 'https://opendev.org/openstack/mistral/commit/fa0c4f128f05a0b71b7951d3fc296cb3fb16c08b', 'message': 'Release note for fixing event-engines HA\n\nAdd missing release note for https://review.openstack.org/#/c/548044/\n\nChange-Id: I297054f052b79143b2d0882286fb3e22d19c70c5\n(cherry picked from commit ed7c351d0b38633ef56112ad87251b2d22873a93)\n'}]",0,638468,fa0c4f128f05a0b71b7951d3fc296cb3fb16c08b,9,3,2,9373,,,0,"Release note for fixing event-engines HA

Add missing release note for https://review.openstack.org/#/c/548044/

Change-Id: I297054f052b79143b2d0882286fb3e22d19c70c5
(cherry picked from commit ed7c351d0b38633ef56112ad87251b2d22873a93)
",git fetch https://review.opendev.org/openstack/mistral refs/changes/68/638468/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/fix-event-engines-ha-cc78f341095cdabf.yaml'],1,121bceacc2d77c7a717bf4abc526625fb4cdb077,bug/1715848,--- fixes: - | [`bug 1715848 <https://bugs.launchpad.net/mistral/+bug/1715848>`_] Fixed a bug that prevents event-engines to work correctly in HA. ,,5,0
openstack%2Fmistral~stable%2Frocky~Ia37831a03993f5a1bf980d62344d25377062788d,openstack/mistral,stable/rocky,Ia37831a03993f5a1bf980d62344d25377062788d,[Event-engine] Allow event_engine to work in HA,MERGED,2018-12-09 11:49:35.000000000,2019-02-22 07:07:54.000000000,2019-02-22 07:07:54.000000000,"[{'_account_id': 5575}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9373}, {'_account_id': 9712}, {'_account_id': 21970}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-09 11:49:35.000000000', 'files': ['mistral/rpc/kombu/kombu_client.py', 'mistral/tests/unit/api/v2/test_event_trigger.py', 'mistral/rpc/base.py', 'mistral/event_engine/default_event_engine.py', 'mistral/services/triggers.py', 'mistral/rpc/oslo/oslo_client.py', 'mistral/rpc/clients.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/ec06ccf65a69fdfe95f2f669591ff2a4a3aca7cc', 'message': '[Event-engine] Allow event_engine to work in HA\n\nA previous patch allows to make multiple event_engines to listen\nto a single queue, but the RPC calls on CRUD are still synchronous\n\nThis patch modifies the calls and broadcasts them on all the event\nengines allow them to modify each independent listeners.\n\nCloses-Bug: #1715848\nChange-Id: Ia37831a03993f5a1bf980d62344d25377062788d\n(cherry picked from commit defff0877392400e572dca772d24b2c6fe49dca1)\n'}]",0,623936,ec06ccf65a69fdfe95f2f669591ff2a4a3aca7cc,12,7,1,9373,,,0,"[Event-engine] Allow event_engine to work in HA

A previous patch allows to make multiple event_engines to listen
to a single queue, but the RPC calls on CRUD are still synchronous

This patch modifies the calls and broadcasts them on all the event
engines allow them to modify each independent listeners.

Closes-Bug: #1715848
Change-Id: Ia37831a03993f5a1bf980d62344d25377062788d
(cherry picked from commit defff0877392400e572dca772d24b2c6fe49dca1)
",git fetch https://review.opendev.org/openstack/mistral refs/changes/36/623936/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/rpc/kombu/kombu_client.py', 'mistral/tests/unit/api/v2/test_event_trigger.py', 'mistral/rpc/base.py', 'mistral/event_engine/default_event_engine.py', 'mistral/services/triggers.py', 'mistral/rpc/oslo/oslo_client.py', 'mistral/rpc/clients.py']",7,ec06ccf65a69fdfe95f2f669591ff2a4a3aca7cc,bug/1715848," return self._client.async_call( events=events, fanout=True, return self._client.async_call( events=events, fanout=True, return self._client.async_call( fanout=True,", return self._client.sync_call( events=events return self._client.sync_call( events=events return self._client.sync_call(,28,18
openstack%2Fnetworking-baremetal~stable%2Fqueens~I7b3e0db64b7b7d3372e5ca24cea88b4b897651be,openstack/networking-baremetal,stable/queens,I7b3e0db64b7b7d3372e5ca24cea88b4b897651be,Ensure notifications are consumed from non-pool queue,MERGED,2019-02-08 09:29:48.000000000,2019-02-22 06:44:09.000000000,2019-02-22 06:44:09.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-02-08 09:29:48.000000000', 'files': ['releasenotes/notes/fix-member-manager-notification-queue-not-consumed-449738d4fd799634.yaml', 'networking_baremetal/agent/ironic_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/42ff79e661b6d5e06c5a093eb50d244de8b708c7', 'message': ""Ensure notifications are consumed from non-pool queue\n\nWhen using oslo.messaging notifications and all listeners\nare using a pool. The messages published to the default\nnotification queue is never consumed, only the pool queues\nare consumed. The queue that is not consumed keep growing\nand is using more and more RAM on the system where the\nmessage broker is running.\n\nAlso prefix the pool names so that it's easier for someone\nlooking at queues in the messaging backend to identify the\nsource.\n\nConflicts:\n\tnetworking_baremetal/agent/ironic_neutron_agent.py\n\nRelated-Bug: #1814544\nStory: 2004938\nTask: 29405\nChange-Id: I7b3e0db64b7b7d3372e5ca24cea88b4b897651be\n(cherry picked from commit 9da983270343bea89c18804767b1532c39c59622)\n""}]",0,635724,42ff79e661b6d5e06c5a093eb50d244de8b708c7,13,5,1,24245,,,0,"Ensure notifications are consumed from non-pool queue

When using oslo.messaging notifications and all listeners
are using a pool. The messages published to the default
notification queue is never consumed, only the pool queues
are consumed. The queue that is not consumed keep growing
and is using more and more RAM on the system where the
message broker is running.

Also prefix the pool names so that it's easier for someone
looking at queues in the messaging backend to identify the
source.

Conflicts:
	networking_baremetal/agent/ironic_neutron_agent.py

Related-Bug: #1814544
Story: 2004938
Task: 29405
Change-Id: I7b3e0db64b7b7d3372e5ca24cea88b4b897651be
(cherry picked from commit 9da983270343bea89c18804767b1532c39c59622)
",git fetch https://review.opendev.org/openstack/networking-baremetal refs/changes/24/635724/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fix-member-manager-notification-queue-not-consumed-449738d4fd799634.yaml', 'networking_baremetal/agent/ironic_neutron_agent.py']",2,42ff79e661b6d5e06c5a093eb50d244de8b708c7,story/2004938," # Note(hjensas): We need to have listener consuming the non-pool queue. # See bug: https://bugs.launchpad.net/oslo.messaging/+bug/1814544 self.listener = _set_up_listener(self.transport, None) self.pool_listener = _set_up_listener(self.transport, '-'.join( ['ironic-neutron-agent-heartbeat-pool', self.agent_id])) self.pool_listener.start()"," self.listener = _set_up_listener(self.transport, self.agent_id)",19,1
openstack%2Frequirements~master~I965d2585c5658d8c9e195ca5c26ca37946be46ac,openstack/requirements,master,I965d2585c5658d8c9e195ca5c26ca37946be46ac,Updated from generate-constraints,ABANDONED,2019-02-22 06:27:41.000000000,2019-02-22 06:29:18.000000000,,[],"[{'number': 1, 'created': '2019-02-22 06:27:41.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f19993fabd9ab646e74ee89ce52093b2117ef27f', 'message': 'Updated from generate-constraints\n\nChange-Id: I965d2585c5658d8c9e195ca5c26ca37946be46ac\n'}]",0,638588,f19993fabd9ab646e74ee89ce52093b2117ef27f,2,0,1,11131,,,0,"Updated from generate-constraints

Change-Id: I965d2585c5658d8c9e195ca5c26ca37946be46ac
",git fetch https://review.opendev.org/openstack/requirements refs/changes/88/638588/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,f19993fabd9ab646e74ee89ce52093b2117ef27f,openstack/requirements/constraints,google-auth===1.6.3tornado===4.5.3;python_version=='3.4' tornado===4.5.3;python_version=='3.5' tornado===4.5.3;python_version=='3.6' tornado===5.1.1;python_version=='2.7'prometheus-client===0.6.0cassandra-driver===3.17.0py===1.8.0opentracing===2.0.0salt===2018.3.3botocore===1.12.100pyzmq===18.0.0,google-auth===1.6.2tornado===4.5.3prometheus-client===0.5.0cassandra-driver===3.16.0py===1.7.0opentracing===1.3.0salt===2018.3.2botocore===1.12.97pyzmq===17.1.2,12,9
openstack%2Fkeystone~master~I83c8dde52984273fa8add94bec406386b7662346,openstack/keystone,master,I83c8dde52984273fa8add94bec406386b7662346,[WIP] implement domain reader for role_assignments,ABANDONED,2019-01-21 14:35:25.000000000,2019-02-22 06:16:21.000000000,,"[{'_account_id': 13478}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-21 14:35:25.000000000', 'files': ['keystone/tests/unit/protection/v3/test_assignment.py', 'keystone/common/policies/role_assignment.py', 'keystone/api/role_assignments.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/05e9b832af252e7cd5f685448fb35878f6f0dde7', 'message': '[WIP] implement domain reader for role_assignments\n\nThis change adds tests cases for the default roles\nkeystone supports at install time. It also modifies\nthe policies for the role_assignments API to be more\nself-service by properly checking for various scopes.\n\nSubsequent patches will be uploaded for\nproject reader\n\nChange-Id: I83c8dde52984273fa8add94bec406386b7662346\n'}]",0,632101,05e9b832af252e7cd5f685448fb35878f6f0dde7,3,2,1,27621,,,0,"[WIP] implement domain reader for role_assignments

This change adds tests cases for the default roles
keystone supports at install time. It also modifies
the policies for the role_assignments API to be more
self-service by properly checking for various scopes.

Subsequent patches will be uploaded for
project reader

Change-Id: I83c8dde52984273fa8add94bec406386b7662346
",git fetch https://review.opendev.org/openstack/keystone refs/changes/01/632101/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/protection/v3/test_assignment.py', 'keystone/common/policies/role_assignment.py', 'keystone/api/role_assignments.py']",3,05e9b832af252e7cd5f685448fb35878f6f0dde7,domain_role_assignments," target = {} if 'scope.domain.id' in flask.request.args: domain_id = flask.request.args['scope.domain.id'] if domain_id: target['domain'] = PROVIDERS.resource_api.get_domain( domain_id) ENFORCER.enforce_call( action='identity:list_role_assignments', filters=filters, target_attr=target)"," ENFORCER.enforce_call(action='identity:list_role_assignments', filters=filters)",97,33
openstack%2Fansible-role-python_venv_build~master~I877924f1e8884fcf5ea031f0f8cb48b93f989353,openstack/ansible-role-python_venv_build,master,I877924f1e8884fcf5ea031f0f8cb48b93f989353,Remove the private option from include_role,MERGED,2019-02-22 00:50:22.000000000,2019-02-22 06:15:04.000000000,2019-02-22 06:15:03.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:50:22.000000000', 'files': ['tests/test.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/b48a02d5313773cfd996c24c7ea0c6e01f2cd4b6', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: I877924f1e8884fcf5ea031f0f8cb48b93f989353\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638558,b48a02d5313773cfd996c24c7ea0c6e01f2cd4b6,6,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: I877924f1e8884fcf5ea031f0f8cb48b93f989353
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/ansible-role-python_venv_build refs/changes/58/638558/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test.yml'],1,b48a02d5313773cfd996c24c7ea0c6e01f2cd4b6,fix/private/deprecation,, private: yes private: yes,0,2
openstack%2Ftap-as-a-service~master~I54b0861b3ee208346788618d5037f095cbac7e8e,openstack/tap-as-a-service,master,I54b0861b3ee208346788618d5037f095cbac7e8e,"Fix  Bug1521873 https://bugs.launchpad.net/tap-as-a-service/+bug/1521873 move the attributes ""port_id"" in Tap Services and ""source_port"" in Tap Flow to ""port"" attribute, as that is the default nomenclature used across Neutron",ABANDONED,2019-02-19 09:00:33.000000000,2019-02-22 06:02:20.000000000,,"[{'_account_id': 6854}, {'_account_id': 22348}, {'_account_id': 28164}]","[{'number': 1, 'created': '2019-02-19 09:00:33.000000000', 'files': ['neutron_taas/tests/unit/taas_client/test_cli20_tapservice.py', 'neutron_taas/taas_client/tapservice.py', 'neutron_taas/extensions/taas.py', 'neutron_taas/taas_client/tapflow.py', 'neutron_taas/db/taas_db.py', 'neutron_taas/tests/unit/extensions/test_taas.py', 'neutron_taas/db/migration/taas_init_ops.py', 'neutron_taas/services/taas/taas_plugin.py', 'neutron_taas/tests/unit/taas_client/test_cli20_tapflow.py', 'neutron_taas/tests/unit/services/taas/test_taas_plugin.py', 'neutron_taas/services/taas/service_drivers/taas_rpc.py', 'neutron_taas/tests/tempest_plugin/tests/api/test_taas.py', 'neutron_taas/tests/unit/db/test_taas_db.py'], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/f52afbbba9d50b87977829ddca4e8aa7116d33c6', 'message': 'Fix  Bug1521873\nhttps://bugs.launchpad.net/tap-as-a-service/+bug/1521873\nmove the attributes ""port_id"" in Tap Services and ""source_port"" in Tap Flow to ""port"" attribute,\nas that is the default nomenclature used across Neutron\n\nChange-Id: I54b0861b3ee208346788618d5037f095cbac7e8e\n'}]",0,637736,f52afbbba9d50b87977829ddca4e8aa7116d33c6,5,3,1,28164,,,0,"Fix  Bug1521873
https://bugs.launchpad.net/tap-as-a-service/+bug/1521873
move the attributes ""port_id"" in Tap Services and ""source_port"" in Tap Flow to ""port"" attribute,
as that is the default nomenclature used across Neutron

Change-Id: I54b0861b3ee208346788618d5037f095cbac7e8e
",git fetch https://review.opendev.org/openstack/tap-as-a-service refs/changes/36/637736/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_taas/tests/unit/taas_client/test_cli20_tapservice.py', 'neutron_taas/taas_client/tapservice.py', 'neutron_taas/extensions/taas.py', 'neutron_taas/taas_client/tapflow.py', 'neutron_taas/db/taas_db.py', 'neutron_taas/tests/unit/extensions/test_taas.py', 'neutron_taas/db/migration/taas_init_ops.py', 'neutron_taas/services/taas/taas_plugin.py', 'neutron_taas/tests/unit/taas_client/test_cli20_tapflow.py', 'neutron_taas/tests/unit/services/taas/test_taas_plugin.py', 'neutron_taas/services/taas/service_drivers/taas_rpc.py', 'neutron_taas/tests/tempest_plugin/tests/api/test_taas.py', 'neutron_taas/tests/unit/db/test_taas_db.py']",13,f52afbbba9d50b87977829ddca4e8aa7116d33c6,bug/1521873," def _get_tap_service_data(self, name='ts-1', port=None): port_id = port or _uuid() ""port"": port_id}} direction='BOTH', port=None): source_port = port or _uuid() ""port"": source_port, data = self._get_tap_service_data(name=name, port=port_id) self.assertEqual(port_id, result['port']) port=tf_source_port, self.assertEqual(tf_source_port, tf['port'])"," def _get_tap_service_data(self, name='ts-1', port_id=None): port_id = port_id or _uuid() ""port_id"": port_id}} direction='BOTH', source_port=None): source_port = source_port or _uuid() ""source_port"": source_port, data = self._get_tap_service_data(name=name, port_id=port_id) self.assertEqual(port_id, result['port_id']) source_port=tf_source_port, self.assertEqual(tf_source_port, tf['source_port'])",55,55
openstack%2Fopenstack-ansible-os_magnum~master~I05554a6454308a25d1c50a58e34303821fcad273,openstack/openstack-ansible-os_magnum,master,I05554a6454308a25d1c50a58e34303821fcad273,Remove the private option from include_role,MERGED,2019-02-22 00:39:55.000000000,2019-02-22 05:57:42.000000000,2019-02-22 05:57:42.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:39:55.000000000', 'files': ['tasks/main.yml', 'tasks/magnum_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/ba232fdadde99581cf289a0a2a545041af821ced', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: I05554a6454308a25d1c50a58e34303821fcad273\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638539,ba232fdadde99581cf289a0a2a545041af821ced,6,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: I05554a6454308a25d1c50a58e34303821fcad273
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/39/638539/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/magnum_install.yml']",2,ba232fdadde99581cf289a0a2a545041af821ced,fix/private/deprecation,, private: yes,0,2
openstack%2Fmasakari-specs~master~I466ef0b323140c936d8c83b5c206b15030a683c7,openstack/masakari-specs,master,I466ef0b323140c936d8c83b5c206b15030a683c7,fix tox python3 overrides,MERGED,2018-09-29 23:50:49.000000000,2019-02-22 05:48:06.000000000,2019-02-22 05:48:06.000000000,"[{'_account_id': 8716}, {'_account_id': 22348}, {'_account_id': 27153}, {'_account_id': 28935}]","[{'number': 1, 'created': '2018-09-29 23:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari-specs/commit/647cfa5eaaaf3f374716171e3d27fa13c8570f62', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: I466ef0b323140c936d8c83b5c206b15030a683c7\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}, {'number': 2, 'created': '2019-02-13 09:30:50.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/masakari-specs/commit/b600eba7b75ce9356937489c1674c8e755735af1', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: I466ef0b323140c936d8c83b5c206b15030a683c7\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,606654,b600eba7b75ce9356937489c1674c8e755735af1,10,4,2,2472,,,0,"fix tox python3 overrides

We want to default to running all tox environments under python 3, so
set the basepython value in each environment.

We do not want to specify a minor version number, because we do not
want to have to update the file every time we upgrade python.

We do not want to set the override once in testenv, because that
breaks the more specific versions used in default environments like
py35 and py36.

Change-Id: I466ef0b323140c936d8c83b5c206b15030a683c7
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/masakari-specs refs/changes/54/606654/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,647cfa5eaaaf3f374716171e3d27fa13c8570f62,python3-first,basepython = python3basepython = python3,,2,0
openstack%2Fswift~master~If47d09e8e8c09b9f50451f93d5b0803aa58743a7,openstack/swift,master,If47d09e8e8c09b9f50451f93d5b0803aa58743a7,py3: port some more middleware tests,MERGED,2019-02-20 23:02:58.000000000,2019-02-22 05:42:13.000000000,2019-02-22 05:42:13.000000000,"[{'_account_id': 597}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-20 23:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6fb7abf71c680b6f6d05c57d72a6084ded047acf', 'message': 'py3: port some more middleware tests\n\n  * name_check\n  * quotas\n  * ratelimit\n  * read_only\n  * recon\n\nNote that the middlewares themselves seem to be fine.\n\nFix proxy-logging for PEP-0479.\n\nChange-Id: If47d09e8e8c09b9f50451f93d5b0803aa58743a7\n'}, {'number': 2, 'created': '2019-02-21 17:44:32.000000000', 'files': ['swift/common/middleware/proxy_logging.py', 'test/unit/common/middleware/test_name_check.py', 'test/unit/common/middleware/test_quotas.py', 'test/unit/common/middleware/test_read_only.py', 'test/unit/common/middleware/test_recon.py', 'test/unit/common/middleware/test_ratelimit.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/swift/commit/b4e47007655e97625d1a88dad1a9f5501340658e', 'message': 'py3: port some more middleware tests\n\n  * name_check\n  * quotas\n  * ratelimit\n  * read_only\n  * recon\n\nNote that the middlewares themselves seem to be fine.\n\nFix proxy-logging for PEP-0479.\n\nChange-Id: If47d09e8e8c09b9f50451f93d5b0803aa58743a7\n'}]",1,638287,b4e47007655e97625d1a88dad1a9f5501340658e,10,3,2,15343,,,0,"py3: port some more middleware tests

  * name_check
  * quotas
  * ratelimit
  * read_only
  * recon

Note that the middlewares themselves seem to be fine.

Fix proxy-logging for PEP-0479.

Change-Id: If47d09e8e8c09b9f50451f93d5b0803aa58743a7
",git fetch https://review.opendev.org/openstack/swift refs/changes/87/638287/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/proxy_logging.py', 'test/unit/common/middleware/test_name_check.py', 'test/unit/common/middleware/test_quotas.py', 'test/unit/common/middleware/test_read_only.py', 'test/unit/common/middleware/test_recon.py', 'test/unit/common/middleware/test_ratelimit.py', 'tox.ini']",7,6fb7abf71c680b6f6d05c57d72a6084ded047acf,, test/unit/common/middleware/test_name_check.py \ test/unit/common/middleware/test_quotas.py \ test/unit/common/middleware/test_ratelimit.py \ test/unit/common/middleware/test_read_only.py \ test/unit/common/middleware/test_recon.py \ test/unit/common/test_*.py \, test/unit/common/test_base_storage_server.py \ test/unit/common/test_bufferedhttp.py \ test/unit/common/test_constraints.py \ test/unit/common/test_container_sync_realms.py \ test/unit/common/test_daemon.py \ test/unit/common/test_db.py \ test/unit/common/test_db_replicator.py \ test/unit/common/test_direct_client.py \ test/unit/common/test_exceptions.py \ test/unit/common/test_header_key_dict.py \ test/unit/common/test_internal_client.py \ test/unit/common/test_linkat.py \ test/unit/common/test_manager.py \ test/unit/common/test_memcached.py \ test/unit/common/test_request_helpers.py \ test/unit/common/test_splice.py \ test/unit/common/test_storage_policy.py \ test/unit/common/test_swob.py \ test/unit/common/test_utils.py \ test/unit/common/test_wsgi.py \,86,91
openstack%2Fnova~stable%2Frocky~I342b9b12ec869431c3abad75eb8194c34151a281,openstack/nova,stable/rocky,I342b9b12ec869431c3abad75eb8194c34151a281,Don't emit warning when ironic properties are zero,MERGED,2018-10-08 05:41:05.000000000,2019-02-22 05:42:07.000000000,2019-02-22 05:42:06.000000000,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 11904}, {'_account_id': 14826}, {'_account_id': 15888}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-10-08 05:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/00a2947e24a7f9c9b5e410bf9d748af5e4d4551b', 'message': ""Don't emit warning when ironic properties are zero\n\nIf an ironic node is registered without either of the 'memory_mb' or\n'cpus' properties, the following warning messages are seen in the\nnova-compute logs:\n\nWarning, memory usage is 0 for <instance> on baremetal node <node>.\nWarning, number of cpus is 0 for <instance> on baremetal node <node>.\n\nAs of the Rocky release [1], the standard compute resources (VCPU,\nMEMORY_MB, DISK_GB) are not registered with placement for ironic nodes.\nThey were not required to be set since the Pike release, but still this\nwarning is emitted.\n\nThis change removes these warning messages.\n\nBackport: rocky, queens, pike\n\n[1] https://review.openstack.org/#/c/565841/\n\nChange-Id: I342b9b12ec869431c3abad75eb8194c34151a281\nCloses-Bug: #1794773\n""}, {'number': 2, 'created': '2018-10-09 14:46:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3b35d1ca0af64dd4249a7da3701be75c8923622e', 'message': ""Don't emit warning when ironic properties are zero\n\nIf an ironic node is registered without either of the 'memory_mb' or\n'cpus' properties, the following warning messages are seen in the\nnova-compute logs:\n\nWarning, memory usage is 0 for <instance> on baremetal node <node>.\nWarning, number of cpus is 0 for <instance> on baremetal node <node>.\n\nAs of the Rocky release [1], the standard compute resources (VCPU,\nMEMORY_MB, DISK_GB) are not registered with placement for ironic nodes.\nThey were not required to be set since the Pike release, but still this\nwarning is emitted.\n\nThis change removes these warning messages.\n\nBackport: rocky, queens, pike\n\n[1] https://review.openstack.org/#/c/565841/\n\nChange-Id: I342b9b12ec869431c3abad75eb8194c34151a281\nCloses-Bug: #1794773\n(cherry picked from commit 63b9c88386998bc584786ecb8ea7a2aae971a384)\n""}, {'number': 3, 'created': '2019-02-11 10:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6dea38cb5828cb76294aa844a9ee52f8973cee16', 'message': ""Don't emit warning when ironic properties are zero\n\nIf an ironic node is registered without either of the 'memory_mb' or\n'cpus' properties, the following warning messages are seen in the\nnova-compute logs:\n\nWarning, memory usage is 0 for <instance> on baremetal node <node>.\nWarning, number of cpus is 0 for <instance> on baremetal node <node>.\n\nAs of the Rocky release [1], the standard compute resources (VCPU,\nMEMORY_MB, DISK_GB) are not registered with placement for ironic nodes.\nThey were not required to be set since the Pike release, but still this\nwarning is emitted.\n\nThis change removes these warning messages.\n\nBackport: rocky, queens, pike\n\n[1] https://review.openstack.org/#/c/565841/\n\nChange-Id: I342b9b12ec869431c3abad75eb8194c34151a281\nCloses-Bug: #1794773\n(cherry picked from commit 63b9c88386998bc584786ecb8ea7a2aae971a384)\n""}, {'number': 4, 'created': '2019-02-21 16:09:03.000000000', 'files': ['nova/virt/ironic/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0794345ecd1d61efb7a0d321eb32844d2dd684d0', 'message': 'Don\'t emit warning when ironic properties are zero\n\nIf an ironic node is registered without either of the \'memory_mb\' or\n\'cpus\' properties, the following warning messages are seen in the\nnova-compute logs:\n\nWarning, memory usage is 0 for <instance> on baremetal node <node>.\nWarning, number of cpus is 0 for <instance> on baremetal node <node>.\n\nAs of the Stein release [1], the standard compute resources (VCPU,\nMEMORY_MB, DISK_GB) are not registered with placement for ironic nodes.\nThey were not required to be set since the Pike release, but still this\nwarning is emitted.\n\nThis change removes these warning messages.\n\nBackport: rocky, queens, pike\n\n[1] https://review.openstack.org/#/c/565841/\n\nNOTE(mriedem): The original commit message on this change incorrectly\nsaid that [1] was made in Rocky but it was actually made in Stein.\nThe important part is that the ""memory_mb"" and ""cpus"" properties on\nthe node could be 0 since Pike and if they are 0, it just means\nthat the related standard resource class inventory is not reported\nto the placement service and thus the warnings are noise.\n\nChange-Id: I342b9b12ec869431c3abad75eb8194c34151a281\nCloses-Bug: #1794773\n(cherry picked from commit 63b9c88386998bc584786ecb8ea7a2aae971a384)\n'}]",4,608573,0794345ecd1d61efb7a0d321eb32844d2dd684d0,45,12,4,10135,,,0,"Don't emit warning when ironic properties are zero

If an ironic node is registered without either of the 'memory_mb' or
'cpus' properties, the following warning messages are seen in the
nova-compute logs:

Warning, memory usage is 0 for <instance> on baremetal node <node>.
Warning, number of cpus is 0 for <instance> on baremetal node <node>.

As of the Stein release [1], the standard compute resources (VCPU,
MEMORY_MB, DISK_GB) are not registered with placement for ironic nodes.
They were not required to be set since the Pike release, but still this
warning is emitted.

This change removes these warning messages.

Backport: rocky, queens, pike

[1] https://review.openstack.org/#/c/565841/

NOTE(mriedem): The original commit message on this change incorrectly
said that [1] was made in Rocky but it was actually made in Stein.
The important part is that the ""memory_mb"" and ""cpus"" properties on
the node could be 0 since Pike and if they are 0, it just means
that the related standard resource class inventory is not reported
to the placement service and thus the warnings are noise.

Change-Id: I342b9b12ec869431c3abad75eb8194c34151a281
Closes-Bug: #1794773
(cherry picked from commit 63b9c88386998bc584786ecb8ea7a2aae971a384)
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/608573/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/ironic/driver.py'],1,00a2947e24a7f9c9b5e410bf9d748af5e4d4551b,bug/1794773,," properties = self._parse_node_properties(node) memory_kib = properties['memory_mb'] * 1024 if memory_kib == 0: LOG.warning(""Warning, memory usage is 0 for "" ""%(instance)s on baremetal node %(node)s."", {'instance': instance.uuid, 'node': instance.node}) num_cpu = properties['cpus'] if num_cpu == 0: LOG.warning(""Warning, number of cpus is 0 for "" ""%(instance)s on baremetal node %(node)s."", {'instance': instance.uuid, 'node': instance.node}) ",0,15
openstack%2Fproject-config~master~I5dee06347c0cd4faaad7f1800416b704eb10d117,openstack/project-config,master,I5dee06347c0cd4faaad7f1800416b704eb10d117,Add nodepool-dib dashboard,MERGED,2019-02-21 03:36:44.000000000,2019-02-22 05:26:01.000000000,2019-02-22 05:26:01.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 03:36:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/cc17385f791157bc0f50a522714dbac370892479', 'message': 'Add nodepool-dib dashboard\n\nThis is a dashboard to track nodepool dib status.  We generate it\nclient side as it seems easier and leads to a suitable layout.\n\nChange-Id: I5dee06347c0cd4faaad7f1800416b704eb10d117\n'}, {'number': 2, 'created': '2019-02-21 08:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/12ce4796c0d89c7dc9856215f454017ef9700c15', 'message': 'Add nodepool-dib dashboard\n\nThis is a dashboard to track nodepool dib status.  We generate it\nclient side as it seems easier and leads to a suitable layout.\n\nDepends-On: https://review.openstack.org/638288\nChange-Id: I5dee06347c0cd4faaad7f1800416b704eb10d117\n'}, {'number': 3, 'created': '2019-02-21 20:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/c42468ee7389e765d3ea9b31bb007ccacbca3421', 'message': 'Add nodepool-dib dashboard\n\nThis is a dashboard to track nodepool dib status.  We generate it\nclient side as it seems easier and leads to a suitable layout.\n\nDepends-On: https://review.openstack.org/638288\nChange-Id: I5dee06347c0cd4faaad7f1800416b704eb10d117\n'}, {'number': 4, 'created': '2019-02-22 02:40:30.000000000', 'files': ['grafana/nodepool-dib.image.template', 'grafana/nodepool-dib.base.template', 'grafana/create-nodepool-dib.sh', 'grafana/nodepool-dib.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c8582e4d26237b26076ec9598e55b88d22bb2b58', 'message': 'Add nodepool-dib dashboard\n\nThis is a dashboard to track nodepool dib status.  We generate it\nclient side as it seems easier and leads to a suitable layout.\n\nDepends-On: https://review.openstack.org/638288\nChange-Id: I5dee06347c0cd4faaad7f1800416b704eb10d117\n'}]",1,638325,c8582e4d26237b26076ec9598e55b88d22bb2b58,14,3,4,7118,,,0,"Add nodepool-dib dashboard

This is a dashboard to track nodepool dib status.  We generate it
client side as it seems easier and leads to a suitable layout.

Depends-On: https://review.openstack.org/638288
Change-Id: I5dee06347c0cd4faaad7f1800416b704eb10d117
",git fetch https://review.opendev.org/openstack/project-config refs/changes/25/638325/1 && git format-patch -1 --stdout FETCH_HEAD,"['grafana/nodepool-dib.image.template', 'grafana/nodepool-dib.base.template', 'grafana/create-dib.sh', 'grafana/nodepool-dib.yaml']",4,cc17385f791157bc0f50a522714dbac370892479,dib-image-size,"# # NOTE: This file is autogenerated. Use ./create-dib.sh to # recreate it # dashboard: title: 'Nodepool: DIB Image Builds' rows: - title: Description height: 100px panels: - title: Description content: | **This dashboard is managed by [Grafyaml](http://docs.openstack.org/infra/system-config/grafyaml.html).** If you would like to make changes to this dashboard, please see the grafana directory in [project-config](https://git.openstack.org/cgit/openstack-infra/project-config/tree/grafana/afs.yaml). type: text # AUTOGENERATED : Ubuntu Bionic - title: Ubuntu Bionic showTitle: true height: 200px panels: - title: qcow2 build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-bionic.qcow2.rc"" valueFontSize: ""50%"" - title: vhd build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-bionic.vhd.rc"" valueFontSize: ""50%"" - title: raw build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-bionic.raw.rc"" valueFontSize: ""50%"" - title: Image size type: graph span: 3 yaxes: - format: decbytes min: 0 - format: decbytes min: 0 targets: - target: aliasByNode(stats.gauges.nodepool.dib_image_build.ubuntu-bionic.*.size, 5) refId: A - title: Build duration type: graph span: 3 yaxes: - format: ms min: 0 - format: ms min: 0 targets: - target: aliasByNode(keepLastValue(stats.timers.nodepool.dib_image_build.ubuntu-bionic.*.duration.mean, 'None'), 5) refId: A # AUTOGENERATED : Ubuntu Xenial - title: Ubuntu Xenial showTitle: true height: 200px panels: - title: qcow2 build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-xenial.qcow2.rc"" valueFontSize: ""50%"" - title: vhd build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-xenial.vhd.rc"" valueFontSize: ""50%"" - title: raw build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-xenial.raw.rc"" valueFontSize: ""50%"" - title: Image size type: graph span: 3 yaxes: - format: decbytes min: 0 - format: decbytes min: 0 targets: - target: aliasByNode(stats.gauges.nodepool.dib_image_build.ubuntu-xenial.*.size, 5) refId: A - title: Build duration type: graph span: 3 yaxes: - format: ms min: 0 - format: ms min: 0 targets: - target: aliasByNode(keepLastValue(stats.timers.nodepool.dib_image_build.ubuntu-xenial.*.duration.mean, 'None'), 5) refId: A # AUTOGENERATED : Ubuntu Trusty - title: Ubuntu Trusty showTitle: true height: 200px panels: - title: qcow2 build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-trusty.qcow2.rc"" valueFontSize: ""50%"" - title: vhd build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-trusty.vhd.rc"" valueFontSize: ""50%"" - title: raw build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-trusty.raw.rc"" valueFontSize: ""50%"" - title: Image size type: graph span: 3 yaxes: - format: decbytes min: 0 - format: decbytes min: 0 targets: - target: aliasByNode(stats.gauges.nodepool.dib_image_build.ubuntu-trusty.*.size, 5) refId: A - title: Build duration type: graph span: 3 yaxes: - format: ms min: 0 - format: ms min: 0 targets: - target: aliasByNode(keepLastValue(stats.timers.nodepool.dib_image_build.ubuntu-trusty.*.duration.mean, 'None'), 5) refId: A # AUTOGENERATED : Centos 7 - title: Centos 7 showTitle: true height: 200px panels: - title: qcow2 build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.centos-7.qcow2.rc"" valueFontSize: ""50%"" - title: vhd build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.centos-7.vhd.rc"" valueFontSize: ""50%"" - title: raw build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.centos-7.raw.rc"" valueFontSize: ""50%"" - title: Image size type: graph span: 3 yaxes: - format: decbytes min: 0 - format: decbytes min: 0 targets: - target: aliasByNode(stats.gauges.nodepool.dib_image_build.centos-7.*.size, 5) refId: A - title: Build duration type: graph span: 3 yaxes: - format: ms min: 0 - format: ms min: 0 targets: - target: aliasByNode(keepLastValue(stats.timers.nodepool.dib_image_build.centos-7.*.duration.mean, 'None'), 5) refId: A # AUTOGENERATED : Fedora 29 - title: Fedora 29 showTitle: true height: 200px panels: - title: qcow2 build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.fedora-29.qcow2.rc"" valueFontSize: ""50%"" - title: vhd build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.fedora-29.vhd.rc"" valueFontSize: ""50%"" - title: raw build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.fedora-29.raw.rc"" valueFontSize: ""50%"" - title: Image size type: graph span: 3 yaxes: - format: decbytes min: 0 - format: decbytes min: 0 targets: - target: aliasByNode(stats.gauges.nodepool.dib_image_build.fedora-29.*.size, 5) refId: A - title: Build duration type: graph span: 3 yaxes: - format: ms min: 0 - format: ms min: 0 targets: - target: aliasByNode(keepLastValue(stats.timers.nodepool.dib_image_build.fedora-29.*.duration.mean, 'None'), 5) refId: A # AUTOGENERATED : Debian Stretch - title: Debian Stretch showTitle: true height: 200px panels: - title: qcow2 build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.debian-stretch.qcow2.rc"" valueFontSize: ""50%"" - title: vhd build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.debian-stretch.vhd.rc"" valueFontSize: ""50%"" - title: raw build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.debian-stretch.raw.rc"" valueFontSize: ""50%"" - title: Image size type: graph span: 3 yaxes: - format: decbytes min: 0 - format: decbytes min: 0 targets: - target: aliasByNode(stats.gauges.nodepool.dib_image_build.debian-stretch.*.size, 5) refId: A - title: Build duration type: graph span: 3 yaxes: - format: ms min: 0 - format: ms min: 0 targets: - target: aliasByNode(keepLastValue(stats.timers.nodepool.dib_image_build.debian-stretch.*.duration.mean, 'None'), 5) refId: A # AUTOGENERATED : Gentoo - title: Gentoo showTitle: true height: 200px panels: - title: qcow2 build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.gentoo-17-0-systemd.qcow2.rc"" valueFontSize: ""50%"" - title: vhd build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.gentoo-17-0-systemd.vhd.rc"" valueFontSize: ""50%"" - title: raw build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.gentoo-17-0-systemd.raw.rc"" valueFontSize: ""50%"" - title: Image size type: graph span: 3 yaxes: - format: decbytes min: 0 - format: decbytes min: 0 targets: - target: aliasByNode(stats.gauges.nodepool.dib_image_build.gentoo-17-0-systemd.*.size, 5) refId: A - title: Build duration type: graph span: 3 yaxes: - format: ms min: 0 - format: ms min: 0 targets: - target: aliasByNode(keepLastValue(stats.timers.nodepool.dib_image_build.gentoo-17-0-systemd.*.duration.mean, 'None'), 5) refId: A # AUTOGENERATED : OpenSUSE 150 - title: OpenSUSE 150 showTitle: true height: 200px panels: - title: qcow2 build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.opensuse-150.qcow2.rc"" valueFontSize: ""50%"" - title: vhd build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.opensuse-150.vhd.rc"" valueFontSize: ""50%"" - title: raw build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.opensuse-150.raw.rc"" valueFontSize: ""50%"" - title: Image size type: graph span: 3 yaxes: - format: decbytes min: 0 - format: decbytes min: 0 targets: - target: aliasByNode(stats.gauges.nodepool.dib_image_build.opensuse-150.*.size, 5) refId: A - title: Build duration type: graph span: 3 yaxes: - format: ms min: 0 - format: ms min: 0 targets: - target: aliasByNode(keepLastValue(stats.timers.nodepool.dib_image_build.opensuse-150.*.duration.mean, 'None'), 5) refId: A # AUTOGENERATED : OpenSUSE 423 - title: OpenSUSE 423 showTitle: true height: 200px panels: - title: qcow2 build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.opensuse-423.qcow2.rc"" valueFontSize: ""50%"" - title: vhd build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.opensuse-423.vhd.rc"" valueFontSize: ""50%"" - title: raw build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.opensuse-423.raw.rc"" valueFontSize: ""50%"" - title: Image size type: graph span: 3 yaxes: - format: decbytes min: 0 - format: decbytes min: 0 targets: - target: aliasByNode(stats.gauges.nodepool.dib_image_build.opensuse-423.*.size, 5) refId: A - title: Build duration type: graph span: 3 yaxes: - format: ms min: 0 - format: ms min: 0 targets: - target: aliasByNode(keepLastValue(stats.timers.nodepool.dib_image_build.opensuse-423.*.duration.mean, 'None'), 5) refId: A # AUTOGENERATED : Ubuntu Bionic arm64 - title: Ubuntu Bionic arm64 showTitle: true height: 200px panels: - title: qcow2 build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-bionic-arm64.qcow2.rc"" valueFontSize: ""50%"" - title: vhd build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-bionic-arm64.vhd.rc"" valueFontSize: ""50%"" - title: raw build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-bionic-arm64.raw.rc"" valueFontSize: ""50%"" - title: Image size type: graph span: 3 yaxes: - format: decbytes min: 0 - format: decbytes min: 0 targets: - target: aliasByNode(stats.gauges.nodepool.dib_image_build.ubuntu-bionic-arm64.*.size, 5) refId: A - title: Build duration type: graph span: 3 yaxes: - format: ms min: 0 - format: ms min: 0 targets: - target: aliasByNode(keepLastValue(stats.timers.nodepool.dib_image_build.ubuntu-bionic-arm64.*.duration.mean, 'None'), 5) refId: A # AUTOGENERATED : Ubuntu Xenial arm64 - title: Ubuntu Xenial arm64 showTitle: true height: 200px panels: - title: qcow2 build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-xenial-arm64.qcow2.rc"" valueFontSize: ""50%"" - title: vhd build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-xenial-arm64.vhd.rc"" valueFontSize: ""50%"" - title: raw build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-xenial-arm64.raw.rc"" valueFontSize: ""50%"" - title: Image size type: graph span: 3 yaxes: - format: decbytes min: 0 - format: decbytes min: 0 targets: - target: aliasByNode(stats.gauges.nodepool.dib_image_build.ubuntu-xenial-arm64.*.size, 5) refId: A - title: Build duration type: graph span: 3 yaxes: - format: ms min: 0 - format: ms min: 0 targets: - target: aliasByNode(keepLastValue(stats.timers.nodepool.dib_image_build.ubuntu-xenial-arm64.*.duration.mean, 'None'), 5) refId: A ",,953,0
openstack%2Fopenstack-ansible-os_barbican~master~I1d5ab64a2038c14db9e4d321b498d782719438c8,openstack/openstack-ansible-os_barbican,master,I1d5ab64a2038c14db9e4d321b498d782719438c8,Remove the private option from include_role,MERGED,2019-02-22 00:49:41.000000000,2019-02-22 05:11:54.000000000,2019-02-22 05:11:54.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:49:41.000000000', 'files': ['tasks/main.yml', 'tasks/barbican_install_source.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/7049773f7ab8cc13fb29ce0e0159bac6b06c6efa', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: I1d5ab64a2038c14db9e4d321b498d782719438c8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638546,7049773f7ab8cc13fb29ce0e0159bac6b06c6efa,10,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: I1d5ab64a2038c14db9e4d321b498d782719438c8
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_barbican refs/changes/46/638546/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/barbican_install_source.yml']",2,7049773f7ab8cc13fb29ce0e0159bac6b06c6efa,fix/private/deprecation,, private: yes,0,2
openstack%2Fopenstack-ansible-os_gnocchi~master~I419cdf1a38f6fc8431934b3fe112ffaf8776aaac,openstack/openstack-ansible-os_gnocchi,master,I419cdf1a38f6fc8431934b3fe112ffaf8776aaac,Remove the private option from include_role,MERGED,2019-02-22 00:49:54.000000000,2019-02-22 05:08:45.000000000,2019-02-22 05:08:45.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:49:54.000000000', 'files': ['tasks/main.yml', 'tasks/gnocchi_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_gnocchi/commit/1e9d2791ee818eeb83463a643e4a846907c6c469', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: I419cdf1a38f6fc8431934b3fe112ffaf8776aaac\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638549,1e9d2791ee818eeb83463a643e4a846907c6c469,8,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: I419cdf1a38f6fc8431934b3fe112ffaf8776aaac
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_gnocchi refs/changes/49/638549/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/gnocchi_install.yml']",2,1e9d2791ee818eeb83463a643e4a846907c6c469,fix/private/deprecation,, private: yes,0,2
openstack%2Fzun~master~Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d,openstack/zun,master,Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d,Consolidate Container and Capsule in compute,MERGED,2019-01-26 23:51:08.000000000,2019-02-22 04:58:20.000000000,2019-02-22 04:58:20.000000000,"[{'_account_id': 11536}, {'_account_id': 21428}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-26 23:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/420c04da8a9541370e3a96e5b22ee88da648efa1', 'message': '[NOT READY FOR REVIEW][POC] Refactor capsule workflow\n\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 2, 'created': '2019-01-27 17:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/7b61221183a77277600c5a327ef4756d3b2c1d3a', 'message': '[NOT READY FOR REVIEW][POC] Refactor capsule workflow\n\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 3, 'created': '2019-01-27 18:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/2d4de1e90381fc0201490a1c58c21f6c77ff78e4', 'message': '[NOT READY FOR REVIEW][POC] Refactor capsule workflow\n\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 4, 'created': '2019-01-27 22:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/b01ffc56e1bafb92243207d8d2ed1c06fd3a094d', 'message': '[NOT READY FOR REVIEW][POC] Refactor capsule workflow\n\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 5, 'created': '2019-01-28 01:03:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/b85debe31dfe7f4429eba2aae367a7a3437e321e', 'message': '[NOT READY FOR REVIEW][POC] Refactor capsule workflow\n\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 6, 'created': '2019-02-09 22:49:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/a3917ef108dedb3eebaef34256840e48e3951920', 'message': '[NOT READY FOR REVIEW][POC] Refactor capsule workflow\n\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 7, 'created': '2019-02-10 00:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/f5a5a906f1c751f03863402d2d0e7205f5d529d1', 'message': '[NOT READY FOR REVIEW][POC] Refactor capsule workflow\n\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 8, 'created': '2019-02-10 00:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/51c342cdfec4f6ddda91996ec03661507e734eb4', 'message': '[NOT READY FOR REVIEW][POC] Refactor capsule workflow\n\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 9, 'created': '2019-02-10 17:17:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/9b7e5e964062e8faed183096d68f6d26371336e8', 'message': '[NOT READY FOR REVIEW][POC] Refactor capsule workflow\n\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 10, 'created': '2019-02-10 19:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/24463ea35794f06bdb41086eb9fecdebaf396827', 'message': '[NOT READY FOR REVIEW][POC] Refactor capsule workflow\n\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 11, 'created': '2019-02-10 20:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/9a7a86995e5cf1a74a171ced609267ff522e1465', 'message': '[WIP][POC] Refactor capsule workflow\n\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 12, 'created': '2019-02-13 02:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/25b596965cc4842744d9cb22bee409f42c7f226b', 'message': '[WIP] Refactor capsule workflow\n\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 13, 'created': '2019-02-13 03:16:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/8efe4b85a205a75785788c65a3fbfe42a1cb1db2', 'message': '[WIP] Consolidate Container and Capsule in compute\n\nIn before, create/delete Capsule has its own RPC api and compute\nmanager implementation. The code is largely duplicated with\nthe Container equivalent. In fact, the code duplication leads\nto bugs or missing features and it is hard to maintain.\n\nThis commit refactor the compute node implementation for capsule.\nFirst, the capsule RPC API is removed and the controller will\nuse the container RPC for create/delete capsule in compute node.\nSecond, the capsule implementation is removed from compute manager.\nInstead, we will reuse the container implementation for capsule.\nThird, we introduce capsule operation in container driver.\nThe capsule-specific logic will be implemented by different drivers.\n\nAfter this patch, all existing container features (i.e. resource\ntracking and claiming, asynchronized delete, etc.) will be available\nfor capsule immediately. In long term, the common implementation\nfor capsule and container will be easier to maintain.\n\nCloses-Bug: #1801649\nCloses-Bug: #1777273\nPartial-Bug: #1762902\nPartial-Bug: #1751193\nPartial-Bug: #1748825\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 14, 'created': '2019-02-16 17:44:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/c54d03e4336c97acb3bb7eb14ad3ef53486f0690', 'message': '[WIP] Consolidate Container and Capsule in compute\n\nIn before, create/delete Capsule has its own RPC api and compute\nmanager implementation. The code is largely duplicated with\nthe Container equivalent. In fact, the code duplication leads\nto bugs or missing features and it is hard to maintain.\n\nThis commit refactor the compute node implementation for capsule.\nFirst, the capsule RPC API is removed and the controller will\nuse the container RPC for create/delete capsule in compute node.\nSecond, the capsule implementation is removed from compute manager.\nInstead, we will reuse the container implementation for capsule.\nThird, we introduce capsule operation in container driver.\nThe capsule-specific logic will be implemented by different drivers.\n\nAfter this patch, all existing container features (i.e. resource\ntracking and claiming, asynchronized delete, etc.) will be available\nfor capsule immediately. In long term, the common implementation\nfor capsule and container will be easier to maintain.\n\nCloses-Bug: #1801649\nCloses-Bug: #1777273\nPartial-Bug: #1762902\nPartial-Bug: #1751193\nPartial-Bug: #1748825\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 15, 'created': '2019-02-16 18:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/51ab92a86b6aeb44c17cb44bcd21fdf162d5ba84', 'message': '[WIP] Consolidate Container and Capsule in compute\n\nIn before, create/delete Capsule has its own RPC api and compute\nmanager implementation. The code is largely duplicated with\nthe Container equivalent. In fact, the code duplication leads\nto bugs or missing features and it is hard to maintain.\n\nThis commit refactor the compute node implementation for capsule.\nFirst, the capsule RPC API is removed and the controller will\nuse the container RPC for create/delete capsule in compute node.\nSecond, the capsule implementation is removed from compute manager.\nInstead, we will reuse the container implementation for capsule.\nThird, we introduce capsule operation in container driver.\nThe capsule-specific logic will be implemented by different drivers.\n\nAfter this patch, all existing container features (i.e. resource\ntracking and claiming, asynchronized delete, etc.) will be available\nfor capsule immediately. In long term, the common implementation\nfor capsule and container will be easier to maintain.\n\nCloses-Bug: #1801649\nCloses-Bug: #1777273\nPartial-Bug: #1762902\nPartial-Bug: #1751193\nPartial-Bug: #1748825\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 16, 'created': '2019-02-16 20:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/c16515b61751ee440f651dc5e12de8c240f4201f', 'message': 'Consolidate Container and Capsule in compute\n\nIn before, create/delete Capsule has its own RPC api and compute\nmanager implementation. The code is largely duplicated with\nthe Container equivalent. In fact, the code duplication leads\nto bugs or missing features and it is hard to maintain.\n\nThis commit refactor the compute node implementation for capsule.\nFirst, the capsule RPC API is removed and the controller will\nuse the container RPC for create/delete capsule in compute node.\nSecond, the capsule implementation is removed from compute manager.\nInstead, we will reuse the container implementation for capsule.\nThird, we introduce capsule operation in container driver.\nThe capsule-specific logic will be implemented by different drivers.\n\nAfter this patch, all existing container features (i.e. resource\ntracking and claiming, asynchronized delete, etc.) will be available\nfor capsule immediately. In long term, the common implementation\nfor capsule and container will be easier to maintain.\n\nCloses-Bug: #1801649\nCloses-Bug: #1777273\nPartial-Bug: #1762902\nPartial-Bug: #1751193\nPartial-Bug: #1748825\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 17, 'created': '2019-02-16 22:25:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/2150e2c4708cb140d24e7cd08b765376d00b240c', 'message': 'Consolidate Container and Capsule in compute\n\nIn before, create/delete Capsule has its own RPC api and compute\nmanager implementation. The code is largely duplicated with\nthe Container equivalent. In fact, the code duplication leads\nto bugs or missing features and it is hard to maintain.\n\nThis commit refactor the compute node implementation for capsule.\nFirst, the capsule RPC API is removed and the controller will\nuse the container RPC for create/delete capsule in compute node.\nSecond, the capsule implementation is removed from compute manager.\nInstead, we will reuse the container implementation for capsule.\nThird, we introduce capsule operation in container driver.\nThe capsule-specific logic will be implemented by different drivers.\n\nAfter this patch, all existing container features (i.e. resource\ntracking and claiming, asynchronized delete, etc.) will be available\nfor capsule immediately. In long term, the common implementation\nfor capsule and container will be easier to maintain.\n\nCloses-Bug: #1801649\nCloses-Bug: #1777273\nPartial-Bug: #1762902\nPartial-Bug: #1751193\nPartial-Bug: #1748825\nDepends-On: https://review.openstack.org/#/c/637394/\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 18, 'created': '2019-02-18 00:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/9bd3d756344e90b0f6586e7dc68dbb9fa2a292b8', 'message': 'Consolidate Container and Capsule in compute\n\nIn before, create/delete Capsule has its own RPC api and compute\nmanager implementation. The code is largely duplicated with\nthe Container equivalent. In fact, the code duplication leads\nto bugs or missing features and it is hard to maintain.\n\nThis commit refactor the compute node implementation for capsule.\nFirst, the capsule RPC API is removed and the controller will\nuse the container RPC for create/delete capsule in compute node.\nSecond, the capsule implementation is removed from compute manager.\nInstead, we will reuse the container implementation for capsule.\nThird, we introduce capsule operation in container driver.\nThe capsule-specific logic will be implemented by different drivers.\n\nAfter this patch, all existing container features (i.e. resource\ntracking and claiming, asynchronized delete, etc.) will be available\nfor capsule immediately. In long term, the common implementation\nfor capsule and container will be easier to maintain.\n\nCloses-Bug: #1801649\nCloses-Bug: #1777273\nPartial-Bug: #1762902\nPartial-Bug: #1751193\nPartial-Bug: #1748825\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 19, 'created': '2019-02-18 20:41:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/4bf8c12a5552f4982f80e5bc19ad32e29ebe10e1', 'message': 'Consolidate Container and Capsule in compute\n\nIn before, create/delete Capsule has its own RPC api and compute\nmanager implementation. The code is largely duplicated with\nthe Container equivalent. In fact, the code duplication leads\nto bugs or missing features and it is hard to maintain.\n\nThis commit refactor the compute node implementation for capsule.\nFirst, the capsule RPC API is removed and the controller will\nuse the container RPC for create/delete capsule in compute node.\nSecond, the capsule implementation is removed from compute manager.\nInstead, we will reuse the container implementation for capsule.\nThird, we introduce capsule operation in container driver.\nThe capsule-specific logic will be implemented by different drivers.\n\nAfter this patch, all existing container features (i.e. resource\ntracking and claiming, asynchronized delete, etc.) will be available\nfor capsule immediately. In long term, the common implementation\nfor capsule and container will be easier to maintain.\n\nCloses-Bug: #1801649\nCloses-Bug: #1777273\nPartial-Bug: #1762902\nPartial-Bug: #1751193\nPartial-Bug: #1748825\nDepends-On: https://review.openstack.org/#/c/637394/\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}, {'number': 20, 'created': '2019-02-18 20:44:58.000000000', 'files': ['zun/compute/api.py', '.zuul.yaml', 'zun/container/driver.py', 'zun/tests/unit/api/controllers/v1/test_capsules.py', 'zun/api/rest_api_version_history.rst', 'zun/tests/unit/compute/test_compute_api.py', 'zun/tests/unit/api/base.py', 'zun/compute/rpcapi.py', 'zun/api/controllers/v1/capsules.py', 'zun/container/docker/driver.py', 'zun/tests/unit/api/controllers/test_root.py', 'zun/compute/manager.py', 'zun/api/controllers/versions.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/d0a7940981bb123bfc12d4ed2d24a4bf50e513e4', 'message': 'Consolidate Container and Capsule in compute\n\nIn before, create/delete Capsule has its own RPC api and compute\nmanager implementation. The code is largely duplicated with\nthe Container equivalent. In fact, the code duplication leads\nto bugs or missing features and it is hard to maintain.\n\nThis commit refactor the compute node implementation for capsule.\nFirst, the capsule RPC API is removed and the controller will\nuse the container RPC for create/delete capsule in compute node.\nSecond, the capsule implementation is removed from compute manager.\nInstead, we will reuse the container implementation for capsule.\nThird, we introduce capsule operation in container driver.\nThe capsule-specific logic will be implemented by different drivers.\n\nAfter this patch, all existing container features (i.e. resource\ntracking and claiming, asynchronized delete, etc.) will be available\nfor capsule immediately. In long term, the common implementation\nfor capsule and container will be easier to maintain.\n\nCloses-Bug: #1801649\nCloses-Bug: #1777273\nPartial-Bug: #1762902\nPartial-Bug: #1751193\nPartial-Bug: #1748825\nChange-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d\n'}]",0,633371,d0a7940981bb123bfc12d4ed2d24a4bf50e513e4,40,3,20,11536,,,0,"Consolidate Container and Capsule in compute

In before, create/delete Capsule has its own RPC api and compute
manager implementation. The code is largely duplicated with
the Container equivalent. In fact, the code duplication leads
to bugs or missing features and it is hard to maintain.

This commit refactor the compute node implementation for capsule.
First, the capsule RPC API is removed and the controller will
use the container RPC for create/delete capsule in compute node.
Second, the capsule implementation is removed from compute manager.
Instead, we will reuse the container implementation for capsule.
Third, we introduce capsule operation in container driver.
The capsule-specific logic will be implemented by different drivers.

After this patch, all existing container features (i.e. resource
tracking and claiming, asynchronized delete, etc.) will be available
for capsule immediately. In long term, the common implementation
for capsule and container will be easier to maintain.

Closes-Bug: #1801649
Closes-Bug: #1777273
Partial-Bug: #1762902
Partial-Bug: #1751193
Partial-Bug: #1748825
Change-Id: Ie1d806738fcd945a4f370bdfc7fa8fb5fb815e8d
",git fetch https://review.opendev.org/openstack/zun refs/changes/71/633371/6 && git format-patch -1 --stdout FETCH_HEAD,"['zun/compute/manager.py', 'zun/container/driver.py']",2,420c04da8a9541370e3a96e5b22ee88da648efa1,bug/1801649," def create_capsule(self, context, capsule, **kwargs): raise NotImplementedError() def delete_capsule(self, context, capsule, **kwargs): raise NotImplementedError() def update_capsules_states(self, context, capsules, manager): raise NotImplementedError()",,166,144
openstack%2Fopenstacksdk~master~I0bb0327c854abbd9dc02818d900706905130efae,openstack/openstacksdk,master,I0bb0327c854abbd9dc02818d900706905130efae,Fix syntax error with exception handling,MERGED,2019-02-22 01:14:24.000000000,2019-02-22 04:56:49.000000000,2019-02-22 04:56:49.000000000,"[{'_account_id': 2}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 01:14:24.000000000', 'files': ['openstack/config/vendors/__init__.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/41f8ac16d03d30ca45fb1d2e28cc01c75d8ebf04', 'message': ""Fix syntax error with exception handling\n\nThis would results in:\n\n  ValueError: unexpected '{' in field name\n\nChange-Id: I0bb0327c854abbd9dc02818d900706905130efae\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}]",0,638564,41f8ac16d03d30ca45fb1d2e28cc01c75d8ebf04,6,2,1,4162,,,0,"Fix syntax error with exception handling

This would results in:

  ValueError: unexpected '{' in field name

Change-Id: I0bb0327c854abbd9dc02818d900706905130efae
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/64/638564/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/config/vendors/__init__.py'],1,41f8ac16d03d30ca45fb1d2e28cc01c75d8ebf04,," "" {status_code} {reason}"".format("," "" ({status_code) {reason}"".format(",1,1
openstack%2Fos-vif~master~Ide8ffcc99a05edf15ce511b1bd4a9b1552dad5d1,openstack/os-vif,master,Ide8ffcc99a05edf15ce511b1bd4a9b1552dad5d1,"Add function ""has_table_columns"" to OVSDB implementation API",MERGED,2019-02-05 16:11:28.000000000,2019-02-22 04:54:13.000000000,2019-02-22 04:54:13.000000000,"[{'_account_id': 7}, {'_account_id': 7634}, {'_account_id': 11604}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-05 16:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/06f8a67772d4d6edf0f6142163268a0ffb63febe', 'message': 'Retrieve the table schema using ovsdb-client command\n\nChange-Id: Ide8ffcc99a05edf15ce511b1bd4a9b1552dad5d1\nCloses-Bug: #1814577\n'}, {'number': 2, 'created': '2019-02-05 16:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/1c5c608359d603a1281374075cf4bc32a224270e', 'message': 'Retrieve the table schema using ovsdb-client command\n\nChange-Id: Ide8ffcc99a05edf15ce511b1bd4a9b1552dad5d1\nCloses-Bug: #1814577\n'}, {'number': 3, 'created': '2019-02-05 16:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/95dde3780b76fab1b375abdc6eb4c2f00aa5513d', 'message': 'Retrieve the table schema using ovsdb-client command\n\nChange-Id: Ide8ffcc99a05edf15ce511b1bd4a9b1552dad5d1\nCloses-Bug: #1814577\n'}, {'number': 4, 'created': '2019-02-21 12:44:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/0706f0696888930f561a9fbfe42e10bed409085b', 'message': 'Add function ""has_table_columns"" to OVSDB implementation API\n\nChange-Id: Ide8ffcc99a05edf15ce511b1bd4a9b1552dad5d1\nCloses-Bug: #1814577\n'}, {'number': 5, 'created': '2019-02-21 12:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/ea7aa33abd822421c8886621ffd72d26e4163bf9', 'message': 'Add function ""has_table_columns"" to OVSDB implementation API\n\nChange-Id: Ide8ffcc99a05edf15ce511b1bd4a9b1552dad5d1\nCloses-Bug: #1814577\n'}, {'number': 6, 'created': '2019-02-21 13:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/3c7589ff1b0cc899256b131acf41fc5312c054c1', 'message': 'Add function ""has_table_columns"" to OVSDB implementation API\n\nChange-Id: Ide8ffcc99a05edf15ce511b1bd4a9b1552dad5d1\nCloses-Bug: #1814577\n'}, {'number': 7, 'created': '2019-02-21 14:11:24.000000000', 'files': ['vif_plug_ovs/ovsdb/api.py', 'vif_plug_ovs/ovsdb/ovsdb_lib.py', 'vif_plug_ovs/ovsdb/impl_vsctl.py', 'vif_plug_ovs/tests/unit/ovsdb/test_ovsdb_lib.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/0c6a21c06406ca942c92e39a4a2b3fab61fefb60', 'message': 'Add function ""has_table_columns"" to OVSDB implementation API\n\nChange-Id: Ide8ffcc99a05edf15ce511b1bd4a9b1552dad5d1\nCloses-Bug: #1814577\n'}]",11,634967,0c6a21c06406ca942c92e39a4a2b3fab61fefb60,27,5,7,16688,,,0,"Add function ""has_table_columns"" to OVSDB implementation API

Change-Id: Ide8ffcc99a05edf15ce511b1bd4a9b1552dad5d1
Closes-Bug: #1814577
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/67/634967/5 && git format-patch -1 --stdout FETCH_HEAD,"['vif_plug_ovs/ovsdb/ovsdb_lib.py', 'vif_plug_ovs/ovsdb/impl_vsctl.py', 'vif_plug_ovs/tests/unit/ovsdb/test_ovsdb_lib.py']",3,06f8a67772d4d6edf0f6142163268a0ffb63febe,bug/1814577," self.mock_get_table_schema = mock.patch.object( self.br.ovsdb, 'get_table_schema').start() def test_get_table_columns(self): self.mock_get_table_schema.return_value = { 'data': [['statistics', {}], ['mac', {}]], 'headings': ['Column', 'Type'] } columns = self.br.get_table_columns('AnyTable') self.assertEqual(['statistics', 'mac'], columns)",,47,1
openstack%2Fopenstack-ansible-os_trove~master~Ia682b9fdeef6d29546c5996bd7bf2978ae6f0ef3,openstack/openstack-ansible-os_trove,master,Ia682b9fdeef6d29546c5996bd7bf2978ae6f0ef3,Remove the private option from include_role,MERGED,2019-02-22 00:40:19.000000000,2019-02-22 04:51:13.000000000,2019-02-22 04:51:12.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:40:19.000000000', 'files': ['tasks/main.yml', 'tasks/trove_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_trove/commit/8a7b586848ad41eb94633d8bd4614a77202ed1d5', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: Ia682b9fdeef6d29546c5996bd7bf2978ae6f0ef3\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638542,8a7b586848ad41eb94633d8bd4614a77202ed1d5,10,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: Ia682b9fdeef6d29546c5996bd7bf2978ae6f0ef3
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_trove refs/changes/42/638542/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/trove_install.yml']",2,8a7b586848ad41eb94633d8bd4614a77202ed1d5,fix/private/deprecation,, private: yes,0,2
openstack%2Fkeystone~master~Ia75d792a497b2f3932ada5352245508e54b55768,openstack/keystone,master,Ia75d792a497b2f3932ada5352245508e54b55768,Add service tests for system member role,MERGED,2018-11-21 15:49:23.000000000,2019-02-22 04:26:06.000000000,2019-02-22 04:26:06.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-21 15:49:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a6ff2939f2b80561d9b664f151e695a2b6de18a9', 'message': 'Update service policies for system member\n\nThe service policies were not taking the default roles work we did\nlast release into account. This commit changes the default policies\nto rely on the ``member`` role for updating services. Subsequent\npatches will incorporate:\n\n - system admin\n - domains users\n - project users\n\nChange-Id: Ia75d792a497b2f3932ada5352245508e54b55768\nRelated-Bug: 1804462\nRelated-Bug: 1804463\n'}, {'number': 2, 'created': '2018-11-28 15:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d238273cd8a31e6d7033112876308b2a6237f2c3', 'message': 'Update service policies for system member\n\nThe service policies were not taking the default roles work we did\nlast release into account. This commit changes the default policies\nto rely on the ``member`` role for updating services. Subsequent\npatches will incorporate:\n\n - system admin\n - domains users\n - project users\n\nChange-Id: Ia75d792a497b2f3932ada5352245508e54b55768\nRelated-Bug: 1804462\nRelated-Bug: 1804463\n'}, {'number': 3, 'created': '2018-11-30 22:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/99761354215545bce58b4c9770ea80140c1ce155', 'message': 'Add service tests for system member role\n\nFrom keystone-perspective, the ``member`` and ``reader`` roles are\neffectively the same, isolating writeable service operations to the\n``admin`` role.\n\nThis commit adds explicit testing to make sure the ``member`` role\nis allowed to perform readable and not writable service operations.\nSubsequent patches will incorporate:\n\n - system admin functionality\n - testing for domain users\n - testing for project users\n\nChange-Id: Ia75d792a497b2f3932ada5352245508e54b55768\nRelated-Bug: 1804462\nRelated-Bug: 1804463\n'}, {'number': 4, 'created': '2018-12-19 20:02:08.000000000', 'files': ['keystone/tests/unit/protection/v3/test_services.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/94d02c22ee07b2af97ee79bf2f5311cfbcbf5d8a', 'message': 'Add service tests for system member role\n\nFrom keystone-perspective, the ``member`` and ``reader`` roles are\neffectively the same, isolating writeable service operations to the\n``admin`` role.\n\nThis commit adds explicit testing to make sure the ``member`` role\nis allowed to perform readable and not writable service operations.\nSubsequent patches will incorporate:\n\n - system admin functionality\n - testing for domain users\n - testing for project users\n\nChange-Id: Ia75d792a497b2f3932ada5352245508e54b55768\nRelated-Bug: 1804462\nRelated-Bug: 1804463\n'}]",0,619278,94d02c22ee07b2af97ee79bf2f5311cfbcbf5d8a,18,4,4,5046,,,0,"Add service tests for system member role

From keystone-perspective, the ``member`` and ``reader`` roles are
effectively the same, isolating writeable service operations to the
``admin`` role.

This commit adds explicit testing to make sure the ``member`` role
is allowed to perform readable and not writable service operations.
Subsequent patches will incorporate:

 - system admin functionality
 - testing for domain users
 - testing for project users

Change-Id: Ia75d792a497b2f3932ada5352245508e54b55768
Related-Bug: 1804462
Related-Bug: 1804463
",git fetch https://review.opendev.org/openstack/keystone refs/changes/78/619278/4 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/policies/service.py', 'keystone/tests/unit/protection/v3/test_services.py']",2,a6ff2939f2b80561d9b664f151e695a2b6de18a9,implement-default-roles,"class _SystemUserServiceTests(object): def test_user_can_list_services(self): expected_service_ids = [] for _ in range(2): s = unit.new_service_ref() service = PROVIDERS.catalog_api.create_service(s['id'], s) expected_service_ids.append(service['id']) with self.test_client() as c: r = c.get('/v3/services', headers=self.headers) actual_service_ids = [] for service in r.json['services']: actual_service_ids.append(service['id']) for service_id in expected_service_ids: self.assertIn(service_id, actual_service_ids) def test_user_can_get_a_service(self): service = unit.new_service_ref() service = PROVIDERS.catalog_api.create_service(service['id'], service) with self.test_client() as c: r = c.get('/v3/services/%s' % service['id'], headers=self.headers) self.assertEqual(r.json['service']['id'], service['id']) common_auth.AuthTestMixin, _SystemUserServiceTests): def test_user_cannot_delete_services(self): c.delete( '/v3/services/%s' % service['id'], headers=self.headers, expected_status_code=http_client.FORBIDDEN ) class SystemMemberTests(base_classes.TestCaseWithBootstrap, common_auth.AuthTestMixin, _SystemUserServiceTests): def setUp(self): super(SystemMemberTests, self).setUp() self.loadapp() self.useFixture(ksfixtures.Policy(self.config_fixture)) self.config_fixture.config(group='oslo_policy', enforce_scope=True) system_member = unit.new_user_ref( domain_id=CONF.identity.default_domain_id ) self.user_id = PROVIDERS.identity_api.create_user( system_member )['id'] PROVIDERS.assignment_api.create_system_grant_for_user( self.user_id, self.bootstrapper.member_role_id ) auth = self.build_authentication_request( user_id=self.user_id, password=system_member['password'], system=True ) # Grab a token using the persona we're testing and prepare headers # for requests we'll be making in the tests. with self.test_client() as c: r = c.post('/v3/auth/tokens', json=auth) self.token_id = r.headers['X-Subject-Token'] self.headers = {'X-Auth-Token': self.token_id} def test_user_cannot_create_services(self): create = { 'service': { 'type': uuid.uuid4().hex, 'name': uuid.uuid4().hex, } } with self.test_client() as c: c.post( '/v3/services', json=create, headers=self.headers, expected_status_code=http_client.FORBIDDEN ) def test_user_can_update_services(self): service = unit.new_service_ref() service = PROVIDERS.catalog_api.create_service(service['id'], service) update = {'service': {'description': uuid.uuid4().hex}} with self.test_client() as c: c.patch( '/v3/services/%s' % service['id'], json=update, headers=self.headers )"," common_auth.AuthTestMixin): def test_user_can_list_services(self): expected_service_ids = [] for _ in range(2): s = unit.new_service_ref() service = PROVIDERS.catalog_api.create_service(s['id'], s) expected_service_ids.append(service['id']) with self.test_client() as c: r = c.get('/v3/services', headers=self.headers) actual_service_ids = [] for service in r.json['services']: actual_service_ids.append(service['id']) for service_id in expected_service_ids: self.assertIn(service_id, actual_service_ids) def test_user_can_get_a_service(self): r = c.get('/v3/services/%s' % service['id'], headers=self.headers) self.assertEqual(r.json['service']['id'], service['id'])",103,23
openstack%2Fkeystone~master~I5f4de1358de2e086b01b0ecb7cf7e636311f5ab2,openstack/keystone,master,I5f4de1358de2e086b01b0ecb7cf7e636311f5ab2,Update service policies for system reader,MERGED,2018-11-21 15:49:23.000000000,2019-02-22 04:26:04.000000000,2019-02-22 04:26:04.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-21 15:49:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f3571d9f85657e5a7a8eda85fc64103d276f8597', 'message': 'Update service policies for system reader\n\nThe service policies were not taking the default roles work we did\nlast release into account. This commit changes the default policies\nto rely on the ``reader`` role for get and list services. Subsequent\npatches will incorporate:\n\n - system member\n - system admin\n - domain users\n - project users\n\nChange-Id: I5f4de1358de2e086b01b0ecb7cf7e636311f5ab2\nRelated-Bug: 1804462\nRelated-Bug: 1804463\n'}, {'number': 2, 'created': '2018-11-28 15:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ec18aef4f57125b724ab42c67f5eec35b4767e36', 'message': 'Update service policies for system reader\n\nThe service policies were not taking the default roles work we did\nlast release into account. This commit changes the default policies\nto rely on the ``reader`` role for get and list services. Subsequent\npatches will incorporate:\n\n - system member\n - system admin\n - domain users\n - project users\n\nChange-Id: I5f4de1358de2e086b01b0ecb7cf7e636311f5ab2\nRelated-Bug: 1804462\nRelated-Bug: 1804463\n'}, {'number': 3, 'created': '2018-11-30 22:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cf55f0670c724a57ae2042b88c9ec80c00f98723', 'message': 'Update service policies for system reader\n\nThe service policies were not taking the default roles work we did\nlast release into account. This commit changes the default policies\nto rely on the ``reader`` role for get and list services. Subsequent\npatches will incorporate:\n\n - system member test coverage\n - system admin functionality\n - domain user test coverage\n - project user test coverage\n\nChange-Id: I5f4de1358de2e086b01b0ecb7cf7e636311f5ab2\nRelated-Bug: 1804462\nRelated-Bug: 1804463\n'}, {'number': 4, 'created': '2018-12-19 20:02:08.000000000', 'files': ['keystone/common/policies/service.py', 'keystone/tests/unit/protection/v3/test_services.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ae926e67185e22865d0d2a00ec0722e1119dc509', 'message': 'Update service policies for system reader\n\nThe service policies were not taking the default roles work we did\nlast release into account. This commit changes the default policies\nto rely on the ``reader`` role for get and list services. Subsequent\npatches will incorporate:\n\n - system member test coverage\n - system admin functionality\n - domain user test coverage\n - project user test coverage\n\nChange-Id: I5f4de1358de2e086b01b0ecb7cf7e636311f5ab2\nRelated-Bug: 1804462\nRelated-Bug: 1804463\n'}]",0,619277,ae926e67185e22865d0d2a00ec0722e1119dc509,19,4,4,5046,,,0,"Update service policies for system reader

The service policies were not taking the default roles work we did
last release into account. This commit changes the default policies
to rely on the ``reader`` role for get and list services. Subsequent
patches will incorporate:

 - system member test coverage
 - system admin functionality
 - domain user test coverage
 - project user test coverage

Change-Id: I5f4de1358de2e086b01b0ecb7cf7e636311f5ab2
Related-Bug: 1804462
Related-Bug: 1804463
",git fetch https://review.opendev.org/openstack/keystone refs/changes/77/619277/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/policies/service.py', 'keystone/tests/unit/protection/v3/test_services.py']",2,f3571d9f85657e5a7a8eda85fc64103d276f8597,implement-default-roles,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from six.moves import http_client from keystone.common import provider_api import keystone.conf from keystone.tests.common import auth as common_auth from keystone.tests import unit from keystone.tests.unit import base_classes from keystone.tests.unit import ksfixtures CONF = keystone.conf.CONF PROVIDERS = provider_api.ProviderAPIs class SystemReaderTests(base_classes.TestCaseWithBootstrap, common_auth.AuthTestMixin): def setUp(self): super(SystemReaderTests, self).setUp() self.loadapp() self.useFixture(ksfixtures.Policy(self.config_fixture)) self.config_fixture.config(group='oslo_policy', enforce_scope=True) system_reader = unit.new_user_ref( domain_id=CONF.identity.default_domain_id ) self.user_id = PROVIDERS.identity_api.create_user( system_reader )['id'] PROVIDERS.assignment_api.create_system_grant_for_user( self.user_id, self.bootstrapper.reader_role_id ) auth = self.build_authentication_request( user_id=self.user_id, password=system_reader['password'], system=True ) # Grab a token using the persona we're testing and prepare headers # for requests we'll be making in the tests. with self.test_client() as c: r = c.post('/v3/auth/tokens', json=auth) self.token_id = r.headers['X-Subject-Token'] self.headers = {'X-Auth-Token': self.token_id} def test_user_cannot_create_services(self): create = { 'service': { 'type': uuid.uuid4().hex, 'name': uuid.uuid4().hex, } } with self.test_client() as c: c.post( '/v3/services', json=create, headers=self.headers, expected_status_code=http_client.FORBIDDEN ) def test_user_cannot_update_services(self): service = unit.new_service_ref() service = PROVIDERS.catalog_api.create_service(service['id'], service) update = {'service': {'description': uuid.uuid4().hex}} with self.test_client() as c: c.patch( '/v3/services/%s' % service['id'], json=update, headers=self.headers, expected_status_code=http_client.FORBIDDEN ) def test_user_can_list_services(self): expected_service_ids = [] for _ in range(2): s = unit.new_service_ref() service = PROVIDERS.catalog_api.create_service(s['id'], s) expected_service_ids.append(service['id']) with self.test_client() as c: r = c.get('/v3/services', headers=self.headers) actual_service_ids = [] for service in r.json['services']: actual_service_ids.append(service['id']) for service_id in expected_service_ids: self.assertIn(service_id, actual_service_ids) def test_user_can_get_a_service(self): service = unit.new_service_ref() service = PROVIDERS.catalog_api.create_service(service['id'], service) with self.test_client() as c: r = c.get('/v3/services/%s' % service['id'], headers=self.headers) self.assertEqual(r.json['service']['id'], service['id']) def test_user_cannot_delete_services(self): service = unit.new_service_ref() service = PROVIDERS.catalog_api.create_service(service['id'], service) with self.test_client() as c: c.delete( '/v3/services/%s' % service['id'], headers=self.headers, expected_status_code=http_client.FORBIDDEN ) ",,147,4
openstack%2Fkeystone~master~I883beed7c9b731ec69d169702b03652c98307f85,openstack/keystone,master,I883beed7c9b731ec69d169702b03652c98307f85,Address follow-up comments in contributor guide for specs,MERGED,2019-02-18 15:17:11.000000000,2019-02-22 03:53:50.000000000,2019-02-22 03:53:50.000000000,"[{'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-02-18 15:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b87a00f7b802594049eb110ebfd18ca56c020118', 'message': 'Address follow-up comments in contributor guide for specs\n\nWe recently merged a document for describing how to write\nspecifications and open bug reports to track feature work:\n\n  I5dbf6f81058de3f2a64a95e4cf34a1279a49c5dd\n\nThis commit addresses some follow on comments from the initial review,\nnamely:\n\n  * removes copyright dates\n  * reorders opening RFE bugs before proposing specs to be consistent\n    with the specification template\n  * fixes links to be more descriptive\n  * clarifies some details on the spec writing process\n\nChange-Id: I883beed7c9b731ec69d169702b03652c98307f85\n'}, {'number': 2, 'created': '2019-02-19 20:26:29.000000000', 'files': ['doc/source/contributor/proposing-features.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3111b8b9bbe0c9d29dc64e634eac457307f6583f', 'message': 'Address follow-up comments in contributor guide for specs\n\nWe recently merged a document for describing how to write\nspecifications and open bug reports to track feature work:\n\n  I5dbf6f81058de3f2a64a95e4cf34a1279a49c5dd\n\nThis commit addresses some follow on comments from the initial review,\nnamely:\n\n  * removes copyright dates\n  * reorders opening RFE bugs before proposing specs to be consistent\n    with the specification template\n  * fixes links to be more descriptive\n  * clarifies some details on the spec writing process\n\nChange-Id: I883beed7c9b731ec69d169702b03652c98307f85\n'}]",2,637567,3111b8b9bbe0c9d29dc64e634eac457307f6583f,11,4,2,5046,,,0,"Address follow-up comments in contributor guide for specs

We recently merged a document for describing how to write
specifications and open bug reports to track feature work:

  I5dbf6f81058de3f2a64a95e4cf34a1279a49c5dd

This commit addresses some follow on comments from the initial review,
namely:

  * removes copyright dates
  * reorders opening RFE bugs before proposing specs to be consistent
    with the specification template
  * fixes links to be more descriptive
  * clarifies some details on the spec writing process

Change-Id: I883beed7c9b731ec69d169702b03652c98307f85
",git fetch https://review.opendev.org/openstack/keystone refs/changes/67/637567/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/proposing-features.rst'],1,b87a00f7b802594049eb110ebfd18ca56c020118,637567,"using bug reports and specifications. We publish the contents of the `keystone-specs repository <http://git.openstack.org/cgit/openstack/keystone-specs>`_ at `specs.openstack.org <https://specs.openstack.org/openstack/keystone-specs/>`_. RFE Bug Reports =============== All code, documentation, and tests implementing a feature should be tracked. To do this, we use Launchpad bug reports. We use bug reports because the OpenStack review infrastructure has existing tooling that groups patches based on commit message syntax. When you propose a patch that is related to a bug or a feature, the OpenStack Infrastructure bot automatically links the patch as a comment in the bug report. Comments are also immutable, allowing us to track long-running initiatives without losing context. To create an RFE bug report, file a bug against the appropriate project. For example, if we were to create an RFE bug report for supporting a new Foobar API within keystone, we'd `open <https://bugs.launchpad.net/keystone/+filebug>`_ that RFE against the keystone project. The title should start with ""RFE: "", followed by a snippet of the feature or enhancement. For example, ""RFE: Implement a foobar API"". The description should be short. Since we use specifications for details, we don't need to duplicate information in the body of the bug report. After you create the bug, you can tag it with the ""rfe"" tag, which helps people filter feature work from other bug reports. Finally, if your specification has already merged, be sure to include a link to it as a comment. If it hasn't, you can propose, or re-propose, your specification with ``Partial-Bug:`` followed by the bug number, at the bottom of your commit message. The OpenStack Infrastructure bot automatically updates the RFE bug report you just created with a link to the proposed specification. The specification template explains how to link to RFE bug reports, which should prompt you to open your RFE bug prior to proposing your specification. If your feature is broken up into multiple commits, make sure to include ``Partial-Bug`` in your commit messages. Additionally, use ``Closes-Bug`` in the last commit implementing the feature. This process ensures all patches written for a feature are tracked in the bug report, making it easier to audit. If you miss the opportunity to use the ``Closes-Bug`` tag and your feature work is complete, set the bug status to ""Fix Committed"".details of your feature, don't hesitate to add one. Do not remove sections from the template that do not apply to your specification. Instead, simply explain why your proposed change doesn't have an impact on that aspect of the template. Propose your specification for review when you're ready for feedback:"," Copyright 2011-2012 OpenStack Foundation All Rights Reserved. using specifications and bug reports. You can find the repository `here <http://git.openstack.org/cgit/openstack/keystone-specs>`_. We publish the contents at `specs.openstack.org <http://specs.openstack.org/openstack/keystone-specs/>`_.details of your feature, don't hesitate to add one. Propose your specification for review when you're ready for feedback: RFE Bug Reports =============== Once a specification is approved, we need to track the work to implement it. To do this, we use Launchpad bug reports. We use bug reports because the OpenStack review infrastructure has existing tooling that groups patches based on commit message syntax. When you propose a patch that is related to a bug or a feature, the OpenStack Infrastructure bot automatically links the patch as a comment in the bug report. Comments are also immutable, allowing us to track long-running initiatives without losing context. To create an RFE bug report, file a bug against the appropriate project. For example, if we were to create an RFE bug report for the example specification we wrote for keystone above, we'd `open <https://bugs.launchpad.net/keystone/+filebug>`_ that RFE against the keystone project. The title should start with ""RFE: "", followed by a snippet of the feature or enhancement. For example, ""RFE: Implement a foobar API"". The description should be short. Since we use specifications for details, we don't need to duplicate information in the body of the bug report. After you create the bug, you can tag it with the ""rfe"" tag, which helps people filter feature work from other bug reports. Finally, if your specification has already merged, be sure to include a link to it as a comment. If it hasn't, you can re-propose your specification with ``Partial-Bug:`` followed by the bug number, at the bottom of your commit message. The OpenStack Infrastructure bot automatically updates your RFE bug report with a link to the proposed specification. If your feature is broken up into multiple commits, make sure to include ``Partial-Bug`` in your commit messages. Additionally, use ``Closes-Bug`` in the last commit implementing the feature. This process ensures all patches written for a feature are tracked in the bug report, making it easier to audit. If you miss the opportunity to use the ``Closes-Bug`` tag and your feature work is complete, set the bug status to ""Fix Committed"".",43,42
openstack%2Fkeystone~master~If4a7547738e40c100330272a0fa587cf444174d0,openstack/keystone,master,If4a7547738e40c100330272a0fa587cf444174d0,Add tests for project users interacting with idps,MERGED,2018-11-21 22:30:23.000000000,2019-02-22 03:53:22.000000000,2019-02-22 03:53:22.000000000,"[{'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2018-11-21 22:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4351e5e0faeb645ce82dfe43587744fbbff52928', 'message': 'Add tests for project users interacting with idps\n\nThis commit introduces some tests that show how project users\nare expected to behave with the federated identity provider API.\nA subsequent patch will clean up the now obsolete policies in the\npolicy.v3cloudsample.json file.\n\nChange-Id: If4a7547738e40c100330272a0fa587cf444174d0\nRelated-Bug: 1804517\n'}, {'number': 2, 'created': '2018-11-28 15:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e5052e4beaaa469ed4f8b40e3cde16f49aad3a57', 'message': 'Add tests for project users interacting with idps\n\nThis commit introduces some tests that show how project users\nare expected to behave with the federated identity provider API.\nA subsequent patch will clean up the now obsolete policies in the\npolicy.v3cloudsample.json file.\n\nChange-Id: If4a7547738e40c100330272a0fa587cf444174d0\nRelated-Bug: 1804517\n'}, {'number': 3, 'created': '2018-11-30 20:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e6be869fbc3dafbf662dc1ba61968484c7dd8511', 'message': 'Add tests for project users interacting with idps\n\nThis commit introduces some tests that show how project users\nare expected to behave with the federated identity provider API.\nA subsequent patch will clean up the now obsolete policies in the\npolicy.v3cloudsample.json file.\n\nChange-Id: If4a7547738e40c100330272a0fa587cf444174d0\nRelated-Bug: 1804517\n'}, {'number': 4, 'created': '2018-12-18 23:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/79b20433919f00bd8d80ef5dbcb5df20876064da', 'message': 'Add tests for project users interacting with idps\n\nThis commit introduces some tests that show how project users\nare expected to behave with the federated identity provider API.\nA subsequent patch will clean up the now obsolete policies in the\npolicy.v3cloudsample.json file.\n\nChange-Id: If4a7547738e40c100330272a0fa587cf444174d0\nRelated-Bug: 1804517\n'}, {'number': 5, 'created': '2019-01-08 22:16:06.000000000', 'files': ['keystone/tests/unit/protection/v3/test_identity_providers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/774da554ea9ef2aaefa5ed5558bc857a9d5a0be9', 'message': 'Add tests for project users interacting with idps\n\nThis commit introduces some tests that show how project users\nare expected to behave with the federated identity provider API.\nA subsequent patch will clean up the now obsolete policies in the\npolicy.v3cloudsample.json file.\n\nChange-Id: If4a7547738e40c100330272a0fa587cf444174d0\nRelated-Bug: 1804517\n'}]",0,619375,774da554ea9ef2aaefa5ed5558bc857a9d5a0be9,17,4,5,5046,,,0,"Add tests for project users interacting with idps

This commit introduces some tests that show how project users
are expected to behave with the federated identity provider API.
A subsequent patch will clean up the now obsolete policies in the
policy.v3cloudsample.json file.

Change-Id: If4a7547738e40c100330272a0fa587cf444174d0
Related-Bug: 1804517
",git fetch https://review.opendev.org/openstack/keystone refs/changes/75/619375/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/protection/v3/test_identity_providers.py'],1,4351e5e0faeb645ce82dfe43587744fbbff52928,implement-default-roles," class ProjectUserTests(base_classes.TestCaseWithBootstrap, common_auth.AuthTestMixin, _DomainAndProjectUserIdentityProviderTests): def setUp(self): super(ProjectUserTests, self).setUp() self.loadapp() self.useFixture(ksfixtures.Policy(self.config_fixture)) self.config_fixture.config(group='oslo_policy', enforce_scope=True) self.user_id = self.bootstrapper.admin_user_id auth = self.build_authentication_request( user_id=self.user_id, password=self.bootstrapper.admin_password, project_id=self.bootstrapper.project_id ) # Grab a token using the persona we're testing and prepare headers # for requests we'll be making in the tests. with self.test_client() as c: r = c.post('/v3/auth/tokens', json=auth) self.token_id = r.headers['X-Subject-Token'] self.headers = {'X-Auth-Token': self.token_id}",,25,0
openstack%2Fkeystone~master~Ie48c8001aec9ef8f3e2d7540d7dd7e8e2231c811,openstack/keystone,master,Ie48c8001aec9ef8f3e2d7540d7dd7e8e2231c811,Add tests for domain users interacting with idps,MERGED,2018-11-21 22:30:23.000000000,2019-02-22 03:53:18.000000000,2019-02-22 03:53:18.000000000,"[{'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2018-11-21 22:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1625f9a2f516af02b13a3457a98eb28b7f00bcff', 'message': 'Add tests for domain users interacting with idps\n\nThis commit introduces some tests that show how domain users are\nexpected to behave with the federated identity provider API. A\nsubsequent patch will do the same for project users.\n\nChange-Id: Ie48c8001aec9ef8f3e2d7540d7dd7e8e2231c811\nRelated-Bug: 1804517\n'}, {'number': 2, 'created': '2018-11-28 15:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ff89bc477ccdb64f5ec6a7437e5f818000905771', 'message': 'Add tests for domain users interacting with idps\n\nThis commit introduces some tests that show how domain users are\nexpected to behave with the federated identity provider API. A\nsubsequent patch will do the same for project users.\n\nChange-Id: Ie48c8001aec9ef8f3e2d7540d7dd7e8e2231c811\nRelated-Bug: 1804517\n'}, {'number': 3, 'created': '2018-11-30 20:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/61f44f3e7ec5e79a72b3fbd78c23d056d9afa197', 'message': 'Add tests for domain users interacting with idps\n\nThis commit introduces some tests that show how domain users are\nexpected to behave with the federated identity provider API. A\nsubsequent patch will do the same for project users.\n\nChange-Id: Ie48c8001aec9ef8f3e2d7540d7dd7e8e2231c811\nRelated-Bug: 1804517\n'}, {'number': 4, 'created': '2018-12-18 23:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/25c8e4aba86b7bf5db23148d3a011e49f041d456', 'message': 'Add tests for domain users interacting with idps\n\nThis commit introduces some tests that show how domain users are\nexpected to behave with the federated identity provider API. A\nsubsequent patch will do the same for project users.\n\nChange-Id: Ie48c8001aec9ef8f3e2d7540d7dd7e8e2231c811\nRelated-Bug: 1804517\n'}, {'number': 5, 'created': '2019-01-08 22:16:06.000000000', 'files': ['keystone/tests/unit/protection/v3/test_identity_providers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/caf147ad0c3ebe0153f4c90c8d3cf43616ccf92b', 'message': 'Add tests for domain users interacting with idps\n\nThis commit introduces some tests that show how domain users are\nexpected to behave with the federated identity provider API. A\nsubsequent patch will do the same for project users.\n\nChange-Id: Ie48c8001aec9ef8f3e2d7540d7dd7e8e2231c811\nRelated-Bug: 1804517\n'}]",0,619374,caf147ad0c3ebe0153f4c90c8d3cf43616ccf92b,17,4,5,5046,,,0,"Add tests for domain users interacting with idps

This commit introduces some tests that show how domain users are
expected to behave with the federated identity provider API. A
subsequent patch will do the same for project users.

Change-Id: Ie48c8001aec9ef8f3e2d7540d7dd7e8e2231c811
Related-Bug: 1804517
",git fetch https://review.opendev.org/openstack/keystone refs/changes/74/619374/5 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/protection/v3/test_identity_providers.py'],1,1625f9a2f516af02b13a3457a98eb28b7f00bcff,implement-default-roles,"class _DomainAndProjectUserIdentityProviderTests(object): def test_user_cannot_create_identity_providers(self): create = {'identity_provider': {'remote_ids': [uuid.uuid4().hex]}} with self.test_client() as c: c.put( '/v3/OS-FEDERATION/identity_providers/%s' % uuid.uuid4().hex, json=create, headers=self.headers, expected_status_code=http_client.FORBIDDEN ) def test_user_cannot_update_identity_providers(self): idp = PROVIDERS.federation_api.create_idp( uuid.uuid4().hex, unit.new_identity_provider_ref() ) update = {'identity_provider': {'enabled': False}} with self.test_client() as c: c.patch( '/v3/OS-FEDERATION/identity_providers/%s' % idp['id'], json=update, headers=self.headers, expected_status_code=http_client.FORBIDDEN ) def test_user_cannot_list_identity_providers(self): PROVIDERS.federation_api.create_idp( uuid.uuid4().hex, unit.new_identity_provider_ref() ) with self.test_client() as c: c.get( '/v3/OS-FEDERATION/identity_providers', headers=self.headers, expected_status_code=http_client.FORBIDDEN ) def test_user_cannot_get_an_identity_provider(self): idp = PROVIDERS.federation_api.create_idp( uuid.uuid4().hex, unit.new_identity_provider_ref() ) with self.test_client() as c: c.get( '/v3/OS-FEDERATION/identity_providers/%s' % idp['id'], headers=self.headers, expected_status_code=http_client.FORBIDDEN ) def test_user_cannot_delete_identity_providers(self): idp = PROVIDERS.federation_api.create_idp( uuid.uuid4().hex, unit.new_identity_provider_ref() ) with self.test_client() as c: c.delete( '/v3/OS-FEDERATION/identity_providers/%s' % idp['id'], headers=self.headers, expected_status_code=http_client.FORBIDDEN ) class DomainUserTests(base_classes.TestCaseWithBootstrap, common_auth.AuthTestMixin, _DomainAndProjectUserIdentityProviderTests): def setUp(self): super(DomainUserTests, self).setUp() self.loadapp() self.useFixture(ksfixtures.Policy(self.config_fixture)) self.config_fixture.config(group='oslo_policy', enforce_scope=True) domain = PROVIDERS.resource_api.create_domain( uuid.uuid4().hex, unit.new_domain_ref() ) self.domain_id = domain['id'] domain_admin = unit.new_user_ref(domain_id=self.domain_id) self.user_id = PROVIDERS.identity_api.create_user(domain_admin)['id'] PROVIDERS.assignment_api.create_grant( self.bootstrapper.admin_role_id, user_id=self.user_id, domain_id=self.domain_id ) auth = self.build_authentication_request( user_id=self.user_id, password=domain_admin['password'], domain_id=self.domain_id ) # Grab a token using the persona we're testing and prepare headers # for requests we'll be making in the tests. with self.test_client() as c: r = c.post('/v3/auth/tokens', json=auth) self.token_id = r.headers['X-Subject-Token'] self.headers = {'X-Auth-Token': self.token_id}",,97,0
openstack%2Fneutron~master~Iba94d73eeb65fb21f5d098afe0fbe4348dbea850,openstack/neutron,master,Iba94d73eeb65fb21f5d098afe0fbe4348dbea850,Bump pylint version to one that supports python3.7,MERGED,2019-02-20 06:48:33.000000000,2019-02-22 03:53:13.000000000,2019-02-22 03:53:13.000000000,"[{'_account_id': 1131}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10980}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-20 06:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a8b1015be0ff76a9080a3234f9562e272af76a88', 'message': 'Bump pylint version to one that supports python3.7\n\nThe listed revision no longer supports python2, but afaik, we are\nalways running under python3 for those tests anyway.\n\nChange-Id: Iba94d73eeb65fb21f5d098afe0fbe4348dbea850\n'}, {'number': 2, 'created': '2019-02-20 06:56:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f684ffd5d2594904e481da031948053cbf36aa8', 'message': 'Bump pylint version to one that supports python3.7\n\nThe listed revision no longer supports python2, but afaik, we are\nalways running under python3 for those tests anyway.\n\nChange-Id: Iba94d73eeb65fb21f5d098afe0fbe4348dbea850\n'}, {'number': 3, 'created': '2019-02-20 19:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/64713ab0336e4385b48dbad0e924249477708836', 'message': 'Bump pylint version to one that supports python3.7\n\nThe listed revision no longer supports python2, but afaik, we are\nalways running under python3 for those tests anyway.\n\nChange-Id: Iba94d73eeb65fb21f5d098afe0fbe4348dbea850\n'}, {'number': 4, 'created': '2019-02-20 21:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/597f005210d46994dd2059e5d398caf1ae1ecb55', 'message': 'Bump pylint version to one that supports python3.7\n\nThe listed revision no longer supports python2, but afaik, we are\nalways running under python3 for those tests anyway.\n\nChange-Id: Iba94d73eeb65fb21f5d098afe0fbe4348dbea850\n'}, {'number': 5, 'created': '2019-02-20 22:11:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6993574a40d9c3d1821fae7fd8227b3869f60d90', 'message': 'Bump pylint version to one that supports python3.7\n\nThe listed revision no longer supports python2, but afaik, we are\nalways running under python3 for those tests anyway.\n\nChange-Id: Iba94d73eeb65fb21f5d098afe0fbe4348dbea850\n'}, {'number': 6, 'created': '2019-02-21 13:22:30.000000000', 'files': ['neutron/objects/rbac_db.py', '.pylintrc', 'test-requirements.txt', 'neutron/db/db_base_plugin_v2.py', 'neutron/agent/l3/dvr_local_router.py', 'neutron/agent/l3/router_info.py', 'lower-constraints.txt', 'neutron/extensions/quotasv2_detail.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e208c30140cfe06fa4f123589985e57c246223d', 'message': 'Bump pylint version to one that supports python3.7\n\nThe listed revision no longer supports python2, but afaik, we are\nalways running under python3 for those tests anyway.\n\nChange-Id: Iba94d73eeb65fb21f5d098afe0fbe4348dbea850\n'}]",4,638093,7e208c30140cfe06fa4f123589985e57c246223d,29,9,6,10980,,,0,"Bump pylint version to one that supports python3.7

The listed revision no longer supports python2, but afaik, we are
always running under python3 for those tests anyway.

Change-Id: Iba94d73eeb65fb21f5d098afe0fbe4348dbea850
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/638093/4 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'lower-constraints.txt']",2,a8b1015be0ff76a9080a3234f9562e272af76a88,pylint-py37,pylint==2.0.0,pylint==1.9.2,2,2
openstack%2Fkeystone~master~I6d6a19d95d8970362993c83e70cf23c989ae45e3,openstack/keystone,master,I6d6a19d95d8970362993c83e70cf23c989ae45e3,Update idp policies for system admin,MERGED,2018-11-21 22:30:23.000000000,2019-02-22 03:53:08.000000000,2019-02-22 03:53:08.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-21 22:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/424115fef328eb84b3d997c27b252d45858bcd93', 'message': 'Update idp policies for system admin\n\nThis change makes the policy definitions for admin idp operations\nconsistent with the other idp policies. Subsequent patches will\nincorporate:\n\n - domain users\n - project users\n\n Related-Bug: 1804517\n Closes-Bug: 1804516\n\nChange-Id: I6d6a19d95d8970362993c83e70cf23c989ae45e3\n'}, {'number': 2, 'created': '2018-11-28 15:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/583c0bcd6eee71cbd24199ed3067fe86bc28fae1', 'message': 'Update idp policies for system admin\n\nThis change makes the policy definitions for admin idp operations\nconsistent with the other idp policies. Subsequent patches will\nincorporate:\n\n - domain users\n - project users\n\n Related-Bug: 1804517\n Closes-Bug: 1804516\n\nChange-Id: I6d6a19d95d8970362993c83e70cf23c989ae45e3\n'}, {'number': 3, 'created': '2018-11-30 20:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6356f948cce022814a3368d3858544b67d7fe6ca', 'message': 'Update idp policies for system admin\n\nThis change makes the policy definitions for admin idp operations\nconsistent with the other idp policies. Subsequent patches will\nincorporate:\n\n - domain users test coverage\n - project users test coverage\n\n Related-Bug: 1804517\n Closes-Bug: 1804516\n\nChange-Id: I6d6a19d95d8970362993c83e70cf23c989ae45e3\n'}, {'number': 4, 'created': '2018-12-18 23:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/97e0ba804857d96a1e6eefdd85e82f739062819e', 'message': 'Update idp policies for system admin\n\nThis change makes the policy definitions for admin idp operations\nconsistent with the other idp policies. Subsequent patches will\nincorporate:\n\n - domain users test coverage\n - project users test coverage\n\n Related-Bug: 1804517\n Closes-Bug: 1804516\n\nChange-Id: I6d6a19d95d8970362993c83e70cf23c989ae45e3\n'}, {'number': 5, 'created': '2019-01-08 22:16:06.000000000', 'files': ['keystone/tests/unit/protection/v3/test_identity_providers.py', 'releasenotes/notes/bug-1804516-24b0b10ed6fe0589.yaml', 'keystone/common/policies/identity_provider.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a4c5d804395f20d0c8832ae6ed9a7594926bf981', 'message': 'Update idp policies for system admin\n\nThis change makes the policy definitions for admin idp operations\nconsistent with the other idp policies. Subsequent patches will\nincorporate:\n\n - domain users test coverage\n - project users test coverage\n\n Related-Bug: 1804517\n Closes-Bug: 1804516\n\nChange-Id: I6d6a19d95d8970362993c83e70cf23c989ae45e3\n'}]",2,619373,a4c5d804395f20d0c8832ae6ed9a7594926bf981,20,4,5,5046,,,0,"Update idp policies for system admin

This change makes the policy definitions for admin idp operations
consistent with the other idp policies. Subsequent patches will
incorporate:

 - domain users test coverage
 - project users test coverage

 Related-Bug: 1804517
 Closes-Bug: 1804516

Change-Id: I6d6a19d95d8970362993c83e70cf23c989ae45e3
",git fetch https://review.opendev.org/openstack/keystone refs/changes/73/619373/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/protection/v3/test_identity_providers.py', 'releasenotes/notes/bug-1804516-24b0b10ed6fe0589.yaml', 'keystone/common/policies/identity_provider.py']",3,424115fef328eb84b3d997c27b252d45858bcd93,implement-default-roles,"deprecated_create_idp = policy.DeprecatedRule( name=base.IDENTITY % 'create_identity_providers', check_str=base.RULE_ADMIN_REQUIRED ) deprecated_delete_idp = policy.DeprecatedRule( name=base.IDENTITY % 'delete_identity_providers', check_str=base.RULE_ADMIN_REQUIRED ) 'method': 'PUT'}], deprecated_rule=deprecated_create_idp, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.STEIN), 'method': 'DELETE'}], deprecated_rule=deprecated_delete_idp, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.STEIN),"," 'method': 'PUT'}]), 'method': 'DELETE'}])",101,2
openstack%2Fkeystone~master~If1700c53674ad98b54f572a73b5d4350c7837ab6,openstack/keystone,master,If1700c53674ad98b54f572a73b5d4350c7837ab6,Add JWS token provider documentation,MERGED,2019-01-29 21:36:39.000000000,2019-02-22 03:53:06.000000000,2019-02-22 03:53:05.000000000,"[{'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 15054}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-01-29 21:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/164d7631eb71f8bfdd1368fd840f0daab4713ebb', 'message': 'Add JWS token provider documentation\n\nbp json-web-tokens\n\nChange-Id: If1700c53674ad98b54f572a73b5d4350c7837ab6\n'}, {'number': 2, 'created': '2019-01-30 17:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/10f7125dc54af21aebbd2d7a1c3e1f01a002d6d2', 'message': 'Add JWS token provider documentation\n\nAdd documentation that advertise support for JWS tokens.\n\nbp json-web-tokens\n\nChange-Id: If1700c53674ad98b54f572a73b5d4350c7837ab6\n'}, {'number': 3, 'created': '2019-01-31 21:33:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/93d0a1e6e3ec9a9bfc1553acc7c537c2fef73445', 'message': 'Add JWS token provider documentation\n\nAdd documentation that advertise support for JWS tokens.\n\nbp json-web-tokens\n\nChange-Id: If1700c53674ad98b54f572a73b5d4350c7837ab6\n'}, {'number': 4, 'created': '2019-02-04 18:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/822c7a8144a00398786584de8c96e3c663609a1d', 'message': 'Add JWS token provider documentation\n\nAdd documentation that advertise support for JWS tokens.\n\nbp json-web-tokens\n\nChange-Id: If1700c53674ad98b54f572a73b5d4350c7837ab6\n'}, {'number': 5, 'created': '2019-02-18 12:30:33.000000000', 'files': ['doc/source/admin/tokens-overview.rst', 'doc/source/admin/token-provider.rst', 'doc/source/admin/token-support-matrix.ini', 'doc/source/admin/tokens.rst', 'doc/source/admin/jws-key-rotation.rst', 'releasenotes/notes/bp-json-web-tokens-37ce3bcd1356cf1b.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/950e7d1f6d5fa0e01a9080e886924d47d6e3e47e', 'message': 'Add JWS token provider documentation\n\nAdd documentation that advertise support for JWS tokens.\n\nbp json-web-tokens\n\nChange-Id: If1700c53674ad98b54f572a73b5d4350c7837ab6\n'}]",4,633831,950e7d1f6d5fa0e01a9080e886924d47d6e3e47e,21,6,5,5046,,,0,"Add JWS token provider documentation

Add documentation that advertise support for JWS tokens.

bp json-web-tokens

Change-Id: If1700c53674ad98b54f572a73b5d4350c7837ab6
",git fetch https://review.opendev.org/openstack/keystone refs/changes/31/633831/5 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/tokens-overview.rst', 'doc/source/admin/token-provider.rst', 'doc/source/admin/token-support-matrix.ini', 'doc/source/admin/tokens.rst', 'doc/source/admin/jws-key-rotation.rst']",5,164d7631eb71f8bfdd1368fd840f0daab4713ebb,bp/json-web-tokens,"================ JWS key rotation ================ The JWS token provider issues tokens using asymmetric signing. This document attempts to describe how to manage key pairs in a deployment of keystone nodes that need to validate tokens issued by one another. The inherent benefit of using asymmetric keys is that each keystone server generates it's own key pair. The private key is used to sign tokens. Anyone with access to the public key has the ability to verify the token signature. This is a critical step in validating tokens across a cluster of keystone nodes. It is necessary for operators to sync public keys for all keystone nodes in the deployment. Each keystone server will need a corresponding public key for every other node in the deployment. This only applies to public keys. Private keys should never leave the server they are generated from or for. Initial setup ------------- Before a deployment of keystone servers can issue JWT tokens, each server must set ``keystone.conf [token] provider = jws``. Additionally, each API server must have its own asymmetric key pair either generated manually or using ``keystone-manage jws_setup``. If you're generated the key pairs manually, they must be usable with the ``ES256`` JSON Web Algorithm (`JWA`). Next, the public key from each API server must be propagated to every other keystone API server in the deployment. Ensure the private key used to signed JWS tokens is readable by the process running keystone and available in the ``keystone.conf [jws_tokens] private_key_repository`` location. Keystone will automatically use a key named ``private.pem`` to sign tokens and ignore all other keys in the repository. To validate tokens, keystone will iterate all available public keys in ``keystone.conf [jws_tokens] public_key_repository``. At a minimum, this repository needs to have the corresponding public key to the ``private.pem`` key found in ``keystone.conf [jws_tokens] private_key_repository``. .. _`JWA`: https://tools.ietf.org/html/rfc7518 Continued operations -------------------- Depending on the security requirements for your deployment, you might need to rotate out an existing key pair. To do so without prematurely invalidating tokens due to validation issues, follow these steps: 1. Generate a new asymmetric key pair for a given keystone API server 2. Copy or sync the newly generated public key to the public key repositories of all other keystone API servers 3. Copy the new private key to the private key repository on the API server you're performing the rotation on and make sure it's named ``private.pem``, at this point the server will start signing tokens with the new private key and all other keystone API servers will be able to validate those tokens since they already have a copy of the public key from step #2 4. At this point, you must wait until the last tokens signed with the old private key have expired before you can remove the old corresponding public keys from each keystone API server, note this should be a minimum of ``keystone.conf [token] expiration`` 5. Once you're confident all tokens signed with the old private key are expired, it is safe to remove the old corresponding public key from each API server in the deployment, which is important in case the original private key was compromised and prevents attackers from using it craft their own tokens ",,122,2
openstack%2Fkeystone~master~Ie16110894348a83e3a80cba4649e6cccdc3c84b1,openstack/keystone,master,Ie16110894348a83e3a80cba4649e6cccdc3c84b1,Implement JWS token provider,MERGED,2018-10-31 15:26:04.000000000,2019-02-22 03:53:02.000000000,2019-02-22 03:53:02.000000000,"[{'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 15054}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2018-10-31 15:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/209d2cae65aa037588dfc0fab5d76c3b9f534eca', 'message': 'Implement scaffolding for JWT provider\n\nThis commit introduces a class that will implement the JWT provider\nfunctionality. This functionality will be exposed to end users in a\nsubsequent patch that wires up the necessary configuartion options\nand creates a JWT-specific entry point.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 2, 'created': '2018-10-31 16:17:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c577715b3645655904990f974bbb718ec3b316e6', 'message': 'Implement scaffolding for JWT provider\n\nThis commit introduces a class that will implement the JWT provider\nfunctionality. This functionality will be exposed to end users in a\nsubsequent patch that wires up the necessary configuartion options\nand creates a JWT-specific entry point.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 3, 'created': '2018-10-31 21:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c64d65faf1e61d63a422960d2be97897a86b423b', 'message': 'Implement scaffolding for JWT provider\n\nThis commit introduces a class that will implement the JWT provider\nfunctionality. This functionality will be exposed to end users in a\nsubsequent patch that wires up the necessary configuartion options\nand creates a JWT-specific entry point.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 4, 'created': '2018-11-01 16:42:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ebfa114456f86dd0712b29dcfa7f7e3efae7556f', 'message': 'Implement scaffolding for JWT provider\n\nThis commit introduces a class that will implement the JWT provider\nfunctionality. This functionality will be exposed to end users in a\nsubsequent patch that wires up the necessary configuartion options\nand creates a JWT-specific entry point.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 5, 'created': '2018-11-02 21:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/83fc502ae269a583173720e35dd42cc425ef4fd6', 'message': 'Implement JSON Web Token provider\n\nThis commit introduces a class that will implement the JWT provider\nfunctionality.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 6, 'created': '2018-11-08 16:10:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/aa2712379159d17e758c9944de66ca79bef3e50a', 'message': 'Implement JSON Web Token provider\n\nThis commit introduces a class that will implement the JWT provider\nfunctionality.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 7, 'created': '2018-11-08 18:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d61a94c216e2f31101a81b4b0208eb904e430ec8', 'message': 'Implement JSON Web Token provider\n\nThis commit introduces a class that will implement the JWT provider\nfunctionality.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 8, 'created': '2019-01-21 18:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/33a91a7517d26c713cdc6ea03b76eacce1c153e4', 'message': 'Implement JWS token provider\n\nThis commit introduces a class that implements the JWS token provider\nfunctionality.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 9, 'created': '2019-01-21 18:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7ea151006660b43925e7a5446cd34e1ad9a9839e', 'message': 'Implement JWS token provider\n\nThis commit introduces a class that implements the JWS token provider\nfunctionality.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 10, 'created': '2019-01-22 15:42:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0e9f296eb366552b144fea689526dd37f3b20ca7', 'message': 'Implement JWS token provider\n\nThis commit introduces a class that implements the JWS token provider\nfunctionality.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 11, 'created': '2019-01-29 19:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5c001d9d22b45506cba7d75ae5afd191f29332a2', 'message': 'Implement JWS token provider\n\nThis commit introduces a class that implements the JWS token provider\nfunctionality.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 12, 'created': '2019-01-30 17:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/92c3672b145370c5d5b57c3dfc4de43054c966cf', 'message': 'Implement JWS token provider\n\nThis commit introduces a class that implements the JWS token provider\nfunctionality.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 13, 'created': '2019-01-31 21:33:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/98b83d463dece62f428ad6e7ca88b7f7e20fdd03', 'message': 'Implement JWS token provider\n\nThis commit introduces a class that implements the JWS token provider\nfunctionality.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 14, 'created': '2019-02-04 18:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/404c3d751f93e018a2b2527970378dcaf3d22892', 'message': 'Implement JWS token provider\n\nThis commit introduces a class that implements the JWS token provider\nfunctionality.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 15, 'created': '2019-02-07 23:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c73c1e8412b370376528d8e7e8a6d9b464b07b43', 'message': 'Implement JWS token provider\n\nThis commit introduces a class that implements the JWS token provider\nfunctionality.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}, {'number': 16, 'created': '2019-02-11 15:26:15.000000000', 'files': ['keystone/tests/unit/test_v3_federation.py', 'keystone/tests/unit/test_v3_auth.py', 'keystone/token/providers/jws/core.py', 'keystone/tests/unit/token/test_jws_provider.py', 'keystone/token/providers/jws/__init__.py', 'setup.cfg', 'keystone/conf/token.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/96adccd0ec0398251268f9ae89732005e340035c', 'message': 'Implement JWS token provider\n\nThis commit introduces a class that implements the JWS token provider\nfunctionality.\n\nbp json-web-tokens\n\nChange-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1\n'}]",56,614549,96adccd0ec0398251268f9ae89732005e340035c,76,6,16,5046,,,0,"Implement JWS token provider

This commit introduces a class that implements the JWS token provider
functionality.

bp json-web-tokens

Change-Id: Ie16110894348a83e3a80cba4649e6cccdc3c84b1
",git fetch https://review.opendev.org/openstack/keystone refs/changes/49/614549/10 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/providers/jwt/__init__.py', 'keystone/token/providers/jwt/core.py', 'keystone/tests/unit/token/test_jwt_provider.py']",3,209d2cae65aa037588dfc0fab5d76c3b9f534eca,bp/json-web-tokens,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from keystone.common import provider_api import keystone.conf from keystone import exception from keystone.tests import unit from keystone.tests.unit import ksfixtures from keystone.token.providers import jwt CONF = keystone.conf.CONF PROVIDERS = provider_api.ProviderAPIs class TestJWTProvider(unit.TestCase): def setUp(self): super(TestJWTProvider, self).setUp() self.config_fixture.config(group='token', provider='jwt') self.useFixture(ksfixtures.JWTKeyRepository(self.config_fixture)) self.provider = jwt.Provider() def test_invalid_token_raises_token_not_found(self): token_id = uuid.uuid4().hex self.assertRaises( exception.TokenNotFound, self.provider.validate_token, token_id ) ",,108,0
openstack%2Fnova~stable%2Fpike~I5b52ff81f74ae7cb11e6f012ab7e53cfc6821486,openstack/nova,stable/pike,I5b52ff81f74ae7cb11e6f012ab7e53cfc6821486,De-dupe subnet IDs when calling neutron /subnets API,MERGED,2019-01-22 14:44:01.000000000,2019-02-22 03:35:06.000000000,2019-02-22 03:35:06.000000000,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-22 14:44:01.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2c464b084006866cb31a289971a36b55eada2355', 'message': 'De-dupe subnet IDs when calling neutron /subnets API\n\nIn the _get_subnets_from_port method, we call the neutron /subnets API\nto list subnets filtered by subnet IDs. We get the subnet IDs by\niterating all of the fixed IPs for the instance and sending the list of\ncorresponding subnet IDs. The python-neutronclient sends the list of\nsubnet IDs as a query string in the URI. When an instance has a large\nnumber of interfaces attached, the list of subnet IDs can be too long\nfor the URI, resulting in a RequestURITooLong error from neutronclient.\n\nThis de-dupes the subnet IDs before calling neutron, to handle the case\nwhere an instance has a large number of interfaces attached, but many\nof them are on the same subnet.\n\nCloses-Bug: #1796074\n\nChange-Id: I5b52ff81f74ae7cb11e6f012ab7e53cfc6821486\n(cherry picked from commit ab5fc6870260d3b3c3bce90a7123c17816bf0093)\n(cherry picked from commit 057a05dbbd7e4b9aea0aaa52f4bf6c1089f079be)\n(cherry picked from commit 346c8feb5837b33b3759c7faaba486715e32b685)\n'}]",0,632480,2c464b084006866cb31a289971a36b55eada2355,11,7,1,17685,,,0,"De-dupe subnet IDs when calling neutron /subnets API

In the _get_subnets_from_port method, we call the neutron /subnets API
to list subnets filtered by subnet IDs. We get the subnet IDs by
iterating all of the fixed IPs for the instance and sending the list of
corresponding subnet IDs. The python-neutronclient sends the list of
subnet IDs as a query string in the URI. When an instance has a large
number of interfaces attached, the list of subnet IDs can be too long
for the URI, resulting in a RequestURITooLong error from neutronclient.

This de-dupes the subnet IDs before calling neutron, to handle the case
where an instance has a large number of interfaces attached, but many
of them are on the same subnet.

Closes-Bug: #1796074

Change-Id: I5b52ff81f74ae7cb11e6f012ab7e53cfc6821486
(cherry picked from commit ab5fc6870260d3b3c3bce90a7123c17816bf0093)
(cherry picked from commit 057a05dbbd7e4b9aea0aaa52f4bf6c1089f079be)
(cherry picked from commit 346c8feb5837b33b3759c7faaba486715e32b685)
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/632480/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py']",2,2c464b084006866cb31a289971a36b55eada2355,bug/1796074," # add another IP on the same subnet and verify the subnet is deduped port_data['fixed_ips'].append({'ip_address': '10.0.1.3', 'subnet_id': 'my_subid1'})",,4,1
openstack%2Fnova~stable%2Fpike~Iba6e698e826d1a1898fde5cc999592f5821e3ebc,openstack/nova,stable/pike,Iba6e698e826d1a1898fde5cc999592f5821e3ebc,Fix destination_type attribute in the bdm_v2 documentation,MERGED,2018-12-21 10:53:03.000000000,2019-02-22 03:34:57.000000000,2019-02-22 03:34:57.000000000,"[{'_account_id': 5575}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-21 10:53:03.000000000', 'files': ['doc/source/user/block-device-mapping.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/953eff39857494ed9e6c39d09fc2e4ba0578a3bd', 'message': 'Fix destination_type attribute in the bdm_v2 documentation\n\nAll the clients using block device mapping are using the attribute\ndestination_type and the documentation points to dest_type instead.\n\nChange-Id: Iba6e698e826d1a1898fde5cc999592f5821e3ebc\nCo-Authored-By: David Moreno Garcia <david.mogar@gmail.com>\nCloses-Bug: #1808358\n(cherry picked from commit 984e45544eabc5fa6b2a1c65e77c5605664b3cdf)\n'}]",0,626876,953eff39857494ed9e6c39d09fc2e4ba0578a3bd,10,5,1,15334,,,0,"Fix destination_type attribute in the bdm_v2 documentation

All the clients using block device mapping are using the attribute
destination_type and the documentation points to dest_type instead.

Change-Id: Iba6e698e826d1a1898fde5cc999592f5821e3ebc
Co-Authored-By: David Moreno Garcia <david.mogar@gmail.com>
Closes-Bug: #1808358
(cherry picked from commit 984e45544eabc5fa6b2a1c65e77c5605664b3cdf)
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/626876/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/block-device-mapping.rst'],1,953eff39857494ed9e6c39d09fc2e4ba0578a3bd,bug/1808358,* destination_type - this can have one of the following values:Valid source / destination combinations ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Combination of the ``source_type`` and ``destination_type`` will define the,* dest_type - this can have one of the following values:Valid source / dest combinations ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Combination of the ``source_type`` and ``dest_type`` will define the,4,4
openstack%2Fneutron~master~I82a2c3ea76195b10880cf37bf2229341b995b0ae,openstack/neutron,master,I82a2c3ea76195b10880cf37bf2229341b995b0ae,Use pyroute2 to check vlan/vxlan in use,MERGED,2019-02-12 10:07:00.000000000,2019-02-22 03:34:51.000000000,2019-02-22 03:34:51.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-12 10:07:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c71a0e7eced97bb887ad892cbbcf086d2a4c08b4', 'message': 'Use pyroute2 to check vlan/vxlan in use\n\nNow ip_lib.get_devices_info function is implemented using pyroute2,\n""vlan_in_use"" and ""vxlan_in_use"" can make use of it.\n\nChange-Id: I82a2c3ea76195b10880cf37bf2229341b995b0ae\nCloses-Bug: #1815498\n'}, {'number': 2, 'created': '2019-02-12 12:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7f4094dfa09514921112b417fa163486b6970058', 'message': 'Use pyroute2 to check vlan/vxlan in use\n\nNow ip_lib.get_devices_info function is implemented using pyroute2,\n""vlan_in_use"" and ""vxlan_in_use"" can make use of it.\n\nChange-Id: I82a2c3ea76195b10880cf37bf2229341b995b0ae\nCloses-Bug: #1815498\n'}, {'number': 3, 'created': '2019-02-13 15:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/178d59cec62891312323a6bb7a3e79d9838268d4', 'message': 'Use pyroute2 to check vlan/vxlan in use\n\nNow ip_lib.get_devices_info function is implemented using pyroute2,\n""vlan_in_use"" and ""vxlan_in_use"" can make use of it.\n\nChange-Id: I82a2c3ea76195b10880cf37bf2229341b995b0ae\nCloses-Bug: #1815498\n'}, {'number': 4, 'created': '2019-02-13 19:04:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1ddf3b790ef247b5e4ec5b05d6f08f1bc4af4f41', 'message': 'Use pyroute2 to check vlan/vxlan in use\n\nNow ip_lib.get_devices_info function is implemented using pyroute2,\n""vlan_in_use"" and ""vxlan_in_use"" can make use of it.\n\nChange-Id: I82a2c3ea76195b10880cf37bf2229341b995b0ae\nCloses-Bug: #1815498\n'}, {'number': 5, 'created': '2019-02-19 07:28:23.000000000', 'files': ['neutron/tests/functional/agent/linux/test_ip_lib.py', 'neutron/agent/linux/ip_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cd31eae33d2e613c178e277af36dc6a9924d597a', 'message': 'Use pyroute2 to check vlan/vxlan in use\n\nNow ip_lib.get_devices_info function is implemented using pyroute2,\n""vlan_in_use"" and ""vxlan_in_use"" can make use of it.\n\nChange-Id: I82a2c3ea76195b10880cf37bf2229341b995b0ae\nCloses-Bug: #1815498\n'}]",0,636296,cd31eae33d2e613c178e277af36dc6a9924d597a,59,8,5,16688,,,0,"Use pyroute2 to check vlan/vxlan in use

Now ip_lib.get_devices_info function is implemented using pyroute2,
""vlan_in_use"" and ""vxlan_in_use"" can make use of it.

Change-Id: I82a2c3ea76195b10880cf37bf2229341b995b0ae
Closes-Bug: #1815498
",git fetch https://review.opendev.org/openstack/neutron refs/changes/96/636296/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/agent/linux/test_ip_lib.py', 'neutron/agent/linux/ip_lib.py']",2,c71a0e7eced97bb887ad892cbbcf086d2a4c08b4,bug/1815498, interfaces = get_devices_info(namespace) vlans = {interface.get('vlan_id') for interface in interfaces if interface.get('vlan_id')} return segmentation_id in vlans interfaces = get_devices_info(namespace) vxlans = {interface.get('vxlan_id') for interface in interfaces if interface.get('vxlan_id')} return segmentation_id in vxlans," ip_wrapper = IPWrapper(namespace=namespace) interfaces = ip_wrapper.netns.execute([""ip"", ""-d"", ""link"", ""list""], check_exit_code=True) return '802.1Q id %s ' % segmentation_id in interfaces ip_wrapper = IPWrapper(namespace=namespace) interfaces = ip_wrapper.netns.execute([""ip"", ""-d"", ""link"", ""list""], check_exit_code=True) return 'vxlan id %s ' % segmentation_id in interfaces",20,8
openstack%2Fopenstack-ansible-os_cinder~master~I59d7dd0c3ab9a8ae68dc8438866b158abfbad9a9,openstack/openstack-ansible-os_cinder,master,I59d7dd0c3ab9a8ae68dc8438866b158abfbad9a9,cinder-volume: rbd driver set backend_host value,MERGED,2018-12-07 13:36:34.000000000,2019-02-22 03:33:01.000000000,2019-02-22 03:33:01.000000000,"[{'_account_id': 1736}, {'_account_id': 7353}, {'_account_id': 10068}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 29638}]","[{'number': 1, 'created': '2018-12-07 13:36:34.000000000', 'files': ['templates/cinder.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/8b86eb7a9d49700ba4307b6f98fdad40f7bd338e', 'message': 'cinder-volume: rbd driver set backend_host value\n\nCloses-Bug #1807384\n\nChange-Id: I59d7dd0c3ab9a8ae68dc8438866b158abfbad9a9\n'}]",0,623490,8b86eb7a9d49700ba4307b6f98fdad40f7bd338e,13,6,1,29638,,,0,"cinder-volume: rbd driver set backend_host value

Closes-Bug #1807384

Change-Id: I59d7dd0c3ab9a8ae68dc8438866b158abfbad9a9
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/90/623490/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/cinder.conf.j2'],1,8b86eb7a9d49700ba4307b6f98fdad40f7bd338e,bug/1807384,"{% if key == ""volume_driver"" and value == ""cinder.volume.drivers.rbd.RBDDriver"" %} backend_host=""rbd:volumes"" {% endif %}",,3,0
openstack%2Fnova~stable%2Fqueens~Iba6e698e826d1a1898fde5cc999592f5821e3ebc,openstack/nova,stable/queens,Iba6e698e826d1a1898fde5cc999592f5821e3ebc,Fix destination_type attribute in the bdm_v2 documentation,MERGED,2018-12-21 10:52:53.000000000,2019-02-22 03:16:54.000000000,2019-02-22 03:16:54.000000000,"[{'_account_id': 5575}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-21 10:52:53.000000000', 'files': ['doc/source/user/block-device-mapping.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/14e69e0591cb05da7e916b42cf77baf75c0bdd87', 'message': 'Fix destination_type attribute in the bdm_v2 documentation\n\nAll the clients using block device mapping are using the attribute\ndestination_type and the documentation points to dest_type instead.\n\nChange-Id: Iba6e698e826d1a1898fde5cc999592f5821e3ebc\nCo-Authored-By: David Moreno Garcia <david.mogar@gmail.com>\nCloses-Bug: #1808358\n(cherry picked from commit 984e45544eabc5fa6b2a1c65e77c5605664b3cdf)\n'}]",1,626875,14e69e0591cb05da7e916b42cf77baf75c0bdd87,11,5,1,15334,,,0,"Fix destination_type attribute in the bdm_v2 documentation

All the clients using block device mapping are using the attribute
destination_type and the documentation points to dest_type instead.

Change-Id: Iba6e698e826d1a1898fde5cc999592f5821e3ebc
Co-Authored-By: David Moreno Garcia <david.mogar@gmail.com>
Closes-Bug: #1808358
(cherry picked from commit 984e45544eabc5fa6b2a1c65e77c5605664b3cdf)
",git fetch https://review.opendev.org/openstack/nova refs/changes/75/626875/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/block-device-mapping.rst'],1,14e69e0591cb05da7e916b42cf77baf75c0bdd87,bug/1808358,* destination_type - this can have one of the following values:Valid source / destination combinations ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Combination of the ``source_type`` and ``destination_type`` will define the,* dest_type - this can have one of the following values:Valid source / dest combinations ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Combination of the ``source_type`` and ``dest_type`` will define the,4,4
openstack%2Fneutron~master~Ib5cad35d5261ab9391f82a22440338d852894a1d,openstack/neutron,master,Ib5cad35d5261ab9391f82a22440338d852894a1d,Retrieve the device info in trunk_plumber using pyroute2,MERGED,2019-01-30 11:22:05.000000000,2019-02-22 03:16:49.000000000,2019-02-22 03:16:49.000000000,"[{'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-01-30 11:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/10f5dd6d55917917841b595e5d48be3bf05be0aa', 'message': ""Retrieve the device info in trunk_plumber using pyroute2\n\nIPWrapper.get_devices_info(), implemented using pyroute2, retrieves the\ndevice information including the VLAN tag and the parent name and index.\n\nThis patch replaces Plumber._get_vlan_children() shell 'ip' commands in\nfavor of this method.\n\nChange-Id: Ib5cad35d5261ab9391f82a22440338d852894a1d\nCloses-Bug: #1804274\n""}, {'number': 2, 'created': '2019-01-30 18:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/11f07e4dffa7a1b5b41ccb6e46d19f041347473a', 'message': ""Retrieve the device info in trunk_plumber using pyroute2\n\nIPWrapper.get_devices_info(), implemented using pyroute2, retrieves the\ndevice information including the VLAN tag and the parent name and index.\n\nThis patch replaces Plumber._get_vlan_children() shell 'ip' commands in\nfavor of this method.\n\nChange-Id: Ib5cad35d5261ab9391f82a22440338d852894a1d\nCloses-Bug: #1804274\n""}, {'number': 3, 'created': '2019-01-31 18:00:34.000000000', 'files': ['neutron/tests/unit/services/trunk/drivers/linuxbridge/agent/test_trunk_plumber.py', 'neutron/services/trunk/drivers/linuxbridge/agent/trunk_plumber.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4fb8b3fe4e234472b0b0fd6e141eb4035cb0f577', 'message': ""Retrieve the device info in trunk_plumber using pyroute2\n\nIPWrapper.get_devices_info(), implemented using pyroute2, retrieves the\ndevice information including the VLAN tag and the parent name and index.\n\nThis patch replaces Plumber._get_vlan_children() shell 'ip' commands in\nfavor of this method.\n\nChange-Id: Ib5cad35d5261ab9391f82a22440338d852894a1d\nCloses-Bug: #1804274\n""}]",4,633918,4fb8b3fe4e234472b0b0fd6e141eb4035cb0f577,21,5,3,16688,,,0,"Retrieve the device info in trunk_plumber using pyroute2

IPWrapper.get_devices_info(), implemented using pyroute2, retrieves the
device information including the VLAN tag and the parent name and index.

This patch replaces Plumber._get_vlan_children() shell 'ip' commands in
favor of this method.

Change-Id: Ib5cad35d5261ab9391f82a22440338d852894a1d
Closes-Bug: #1804274
",git fetch https://review.opendev.org/openstack/neutron refs/changes/18/633918/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/services/trunk/drivers/linuxbridge/agent/test_trunk_plumber.py', 'neutron/services/trunk/drivers/linuxbridge/agent/trunk_plumber.py']",2,10f5dd6d55917917841b595e5d48be3bf05be0aa,bug/1804274," devices = ip_wrapper.get_devices_info() return {(device['name'], device['vlan_id']) for device in devices if device.get('kind') == 'vlan' and device.get('parent_name') == dev}"," # TODO(kevinbenton): move into ip-lib after privsep stuff settles output = ip_wrapper.netns.execute([""ip"", ""-d"", ""link"", ""list""], check_exit_code=True) return {(i.devname, i.vlan_tag) for i in _iter_output_by_interface(output) if i.parent_devname == dev} def _iter_output_by_interface(output): interface = [] for line in output.splitlines(): if not line.startswith(' '): # no space indicates new interface info interface_str = ' '.join(interface) if interface_str.strip(): yield _InterfaceInfo(interface_str) interface = [] interface.append(line) if interface: yield _InterfaceInfo(' '.join(interface)) class _InterfaceInfo(object): def __init__(self, line): try: name_section = line.split(': ')[1] except IndexError: name_section = None LOG.warning(""Bad interface line: %s"", line) if not name_section or '@' not in name_section: self.devname = name_section self.parent_devname = self.vlan_tag = None else: self.devname, parent = name_section.split('@') m = re.match(r'.*802\.1Q id (\d+).*', line) self.vlan_tag = int(m.group(1)) if m else None # we only care about parent interfaces if it's a vlan sub-interface self.parent_devname = parent if self.vlan_tag is not None else None def __repr__(self): return ('_InterfaceInfo(devname=%s, parent=%s, vlan=%s)' % (self.devname, self.parent_devname, self.vlan_tag))",36,101
openstack%2Fopenstack-ansible~stable%2Fqueens~Ifd348ddd9c21526f5b523963dd1fd247edd6b109,openstack/openstack-ansible,stable/queens,Ifd348ddd9c21526f5b523963dd1fd247edd6b109,Dynamic inventory backup corruption fix,MERGED,2019-02-20 23:10:38.000000000,2019-02-22 03:16:02.000000000,2019-02-22 03:16:02.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-20 23:10:38.000000000', 'files': ['osa_toolkit/filesystem.py', 'osa_toolkit/generate.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c7fbe594d0bdddedddb2aa2977b1ad1e7bdbe5b3', 'message': 'Dynamic inventory backup corruption fix\n\nWhen multiple users and process are accessing the dynamic inventory\nthe inventory backup and json can get corrupted. This change checks\nfor inventory modifictions and only saves if needed. The backup\nis also moved to right before the actual save.\n\nChange-Id: Ifd348ddd9c21526f5b523963dd1fd247edd6b109\nCloses-Bug: #1750233\n'}]",0,638291,c7fbe594d0bdddedddb2aa2977b1ad1e7bdbe5b3,7,3,1,21714,,,0,"Dynamic inventory backup corruption fix

When multiple users and process are accessing the dynamic inventory
the inventory backup and json can get corrupted. This change checks
for inventory modifictions and only saves if needed. The backup
is also moved to right before the actual save.

Change-Id: Ifd348ddd9c21526f5b523963dd1fd247edd6b109
Closes-Bug: #1750233
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/91/638291/1 && git format-patch -1 --stdout FETCH_HEAD,"['osa_toolkit/filesystem.py', 'osa_toolkit/generate.py']",2,c7fbe594d0bdddedddb2aa2977b1ad1e7bdbe5b3,bug/1750233-stable/queens,"import copy # Make a deep copy for change comparison orig_inventory = copy.deepcopy(inventory) # Save new dynamic inventory only if modified if orig_inventory != inventory: logger.debug(""Saving modified inventory"") filesys.save_inventory(inventory_json, inv_path)"," # Save new dynamic inventory filesys.save_inventory(inventory_json, inv_path)",12,3
openstack%2Ftripleo-common~master~Ibe9c046ed9172dd0bc276c6400496392b2c69dda,openstack/tripleo-common,master,Ibe9c046ed9172dd0bc276c6400496392b2c69dda,Improve retry behaviour of _copy_layer_registry_to_registry,MERGED,2019-02-20 21:02:13.000000000,2019-02-22 03:12:39.000000000,2019-02-22 03:12:39.000000000,"[{'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-20 21:02:13.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/67a3c4d8b31e6cac256012df65c36dcf3542e129', 'message': 'Improve retry behaviour of _copy_layer_registry_to_registry\n\nThere are failures occuring in CI which result in missing layers after\na registry->registry transfer.\n\nA job.exception() check is added to ensure the whole image transfer\nfails if a single layer fails.\n\n_copy_layer_registry_to_registry now retries on IOError. This is\nthe parent class of RequestException, and could plausably be raised\nduring a layer transfer.\n\nChange-Id: Ibe9c046ed9172dd0bc276c6400496392b2c69dda\nPartial-Bug: #1815576\n'}]",0,638266,67a3c4d8b31e6cac256012df65c36dcf3542e129,14,4,1,4571,,,0,"Improve retry behaviour of _copy_layer_registry_to_registry

There are failures occuring in CI which result in missing layers after
a registry->registry transfer.

A job.exception() check is added to ensure the whole image transfer
fails if a single layer fails.

_copy_layer_registry_to_registry now retries on IOError. This is
the parent class of RequestException, and could plausably be raised
during a layer transfer.

Change-Id: Ibe9c046ed9172dd0bc276c6400496392b2c69dda
Partial-Bug: #1815576
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/66/638266/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,67a3c4d8b31e6cac256012df65c36dcf3542e129,bug/1815576, IOError e = job.exception() if e: raise e, requests.exceptions.RequestException,4,1
openstack%2Fopenstack-helm-infra~master~If787abd7711a02313b6a2acae8a888b5609f27df,openstack/openstack-helm-infra,master,If787abd7711a02313b6a2acae8a888b5609f27df,Fix for absent link packages in ceph deployment shell,MERGED,2019-02-18 17:27:23.000000000,2019-02-22 03:04:27.000000000,2019-02-22 03:04:27.000000000,"[{'_account_id': 1523}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 29268}]","[{'number': 1, 'created': '2019-02-18 17:27:23.000000000', 'files': ['tools/deployment/multinode/030-ceph.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b7a96ca8c9f98bc15d3d8eed8d8f7e25c865566b', 'message': 'Fix for absent link packages in ceph deployment shell\n\nThere is no ""make {package}"" line in 030-ceph.sh file.\nIt causes a failure to execute the shell script.\n\nChange-Id: If787abd7711a02313b6a2acae8a888b5609f27df\n'}]",0,637592,b7a96ca8c9f98bc15d3d8eed8d8f7e25c865566b,16,5,1,1523,,,0,"Fix for absent link packages in ceph deployment shell

There is no ""make {package}"" line in 030-ceph.sh file.
It causes a failure to execute the shell script.

Change-Id: If787abd7711a02313b6a2acae8a888b5609f27df
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/92/637592/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/deployment/multinode/030-ceph.sh'],1,b7a96ca8c9f98bc15d3d8eed8d8f7e25c865566b,fix-absent-lint-package-in-ceph,#NOTE: Lint and package chart make ceph-mon make ceph-osd make ceph-client make ceph-provisioners ,,6,0
openstack%2Fopenstack-ansible-os_congress~master~Id03e7e34f735f5c6129fcc1fb837a7b5c973bd84,openstack/openstack-ansible-os_congress,master,Id03e7e34f735f5c6129fcc1fb837a7b5c973bd84,Remove the private option from include_role,MERGED,2019-02-22 00:49:49.000000000,2019-02-22 03:04:26.000000000,2019-02-22 03:04:26.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:49:49.000000000', 'files': ['tasks/main.yml', 'tasks/congress_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_congress/commit/ae0620f4c60412b62340b45d59f19378d8119003', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: Id03e7e34f735f5c6129fcc1fb837a7b5c973bd84\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638548,ae0620f4c60412b62340b45d59f19378d8119003,6,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: Id03e7e34f735f5c6129fcc1fb837a7b5c973bd84
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_congress refs/changes/48/638548/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/congress_install.yml']",2,ae0620f4c60412b62340b45d59f19378d8119003,fix/private/deprecation,, private: yes,0,2
openstack%2Fneutron~master~I35ba7664335026ca2a4d361d93fbf784bf0ffe5c,openstack/neutron,master,I35ba7664335026ca2a4d361d93fbf784bf0ffe5c,Add job from openstacksdk to avoid regressing,MERGED,2019-02-21 10:52:19.000000000,2019-02-22 03:00:21.000000000,2019-02-22 03:00:21.000000000,"[{'_account_id': 2}, {'_account_id': 1131}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-21 10:52:19.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3f38c58cffddf7f2763455cce9d0ebf875230994', 'message': ""Add job from openstacksdk to avoid regressing\n\nAs seen in [0], openstacksdk uses a scenario for testing that isn't\ncurrently covered by Neutron's own testing. Add a job from their stack\nto be run on all patches, but make it non-voting to start with.\n\n[0] https://bugs.launchpad.net/neutron/+bug/1816771\n\nChange-Id: I35ba7664335026ca2a4d361d93fbf784bf0ffe5c\nRelated-Bug: 1816771\nRelated-Bug: 1817045\n""}]",0,638391,3f38c58cffddf7f2763455cce9d0ebf875230994,14,9,1,13252,,,0,"Add job from openstacksdk to avoid regressing

As seen in [0], openstacksdk uses a scenario for testing that isn't
currently covered by Neutron's own testing. Add a job from their stack
to be run on all patches, but make it non-voting to start with.

[0] https://bugs.launchpad.net/neutron/+bug/1816771

Change-Id: I35ba7664335026ca2a4d361d93fbf784bf0ffe5c
Related-Bug: 1816771
Related-Bug: 1817045
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/638391/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,3f38c58cffddf7f2763455cce9d0ebf875230994,bug/1816771, - openstacksdk-functional-devstack-networking: voting: false,,2,0
openstack%2Fopenstack-ansible-nspawn_hosts~master~I1b7649481d2f9fbd25164a28cd10972a63143747,openstack/openstack-ansible-nspawn_hosts,master,I1b7649481d2f9fbd25164a28cd10972a63143747,Remove the private option from include_role,MERGED,2019-02-22 00:49:38.000000000,2019-02-22 02:46:23.000000000,2019-02-22 02:46:22.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:49:38.000000000', 'files': ['tasks/nspawn_volume.yml', 'tasks/nspawn_networking.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-nspawn_hosts/commit/fae866ea721ca0b615b9f7e2300fa0b9cf03814e', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: I1b7649481d2f9fbd25164a28cd10972a63143747\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638544,fae866ea721ca0b615b9f7e2300fa0b9cf03814e,6,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: I1b7649481d2f9fbd25164a28cd10972a63143747
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-nspawn_hosts refs/changes/44/638544/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/nspawn_volume.yml', 'tasks/nspawn_networking.yml']",2,fae866ea721ca0b615b9f7e2300fa0b9cf03814e,fix/private/deprecation,, private: true private: true private: true,0,5
openstack%2Fopenstack-ansible-os_designate~master~Idbdf22251060dcd7e9852551a895b928ad415ce6,openstack/openstack-ansible-os_designate,master,Idbdf22251060dcd7e9852551a895b928ad415ce6,Remove the private option from include_role,MERGED,2019-02-22 00:39:38.000000000,2019-02-22 02:46:19.000000000,2019-02-22 02:46:19.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:39:38.000000000', 'files': ['tasks/main.yml', 'tasks/designate_install_source.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_designate/commit/98ef1fa530c33394ee4cd9d1e0006493f1bdca86', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: Idbdf22251060dcd7e9852551a895b928ad415ce6\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638536,98ef1fa530c33394ee4cd9d1e0006493f1bdca86,6,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: Idbdf22251060dcd7e9852551a895b928ad415ce6
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_designate refs/changes/36/638536/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/designate_install_source.yml']",2,98ef1fa530c33394ee4cd9d1e0006493f1bdca86,fix/private/deprecation,, private: yes,0,2
openstack%2Fpython-swiftclient~master~Ifc3bfeff4038c93d8c8cf2c9d7814c3003e73504,openstack/python-swiftclient,master,Ifc3bfeff4038c93d8c8cf2c9d7814c3003e73504,Update hacking version,MERGED,2018-12-28 15:05:42.000000000,2019-02-22 02:45:59.000000000,2019-02-22 02:45:58.000000000,"[{'_account_id': 15343}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2018-12-28 15:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/4fd6c0a3bd85e1ab9d9b99f7a6ef291bd0eabbba', 'message': 'Update hacking version\n\nChange-Id: Ifc3bfeff4038c93d8c8cf2c9d7814c3003e73504\n'}, {'number': 2, 'created': '2019-01-03 02:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/06ca2c3ce282106bf0ef8970ab0c09566e6c5836', 'message': 'Update hacking version\n\n1. update hacking version to latest\n2. fix pep8 failed\n\nChange-Id: Ifc3bfeff4038c93d8c8cf2c9d7814c3003e73504\n'}, {'number': 3, 'created': '2019-01-03 02:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/d7549fde5048dfab15ed042424f5ffd10bbc57d9', 'message': 'Update hacking version\n\n1. update hacking version to latest\n2. fix pep8 failed\n\nChange-Id: Ifc3bfeff4038c93d8c8cf2c9d7814c3003e73504\n'}, {'number': 4, 'created': '2019-01-03 05:09:37.000000000', 'files': ['swiftclient/shell.py', 'test-requirements.txt', 'tests/unit/test_shell.py', 'swiftclient/client.py', 'swiftclient/service.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/2ff36fde575fa6987ee5954f526ad6c9460633a5', 'message': 'Update hacking version\n\n1. update hacking version to latest\n2. fix pep8 failed\n\nChange-Id: Ifc3bfeff4038c93d8c8cf2c9d7814c3003e73504\n'}]",1,627724,2ff36fde575fa6987ee5954f526ad6c9460633a5,14,4,4,21691,,,0,"Update hacking version

1. update hacking version to latest
2. fix pep8 failed

Change-Id: Ifc3bfeff4038c93d8c8cf2c9d7814c3003e73504
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/24/627724/4 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,4fd6c0a3bd85e1ab9d9b99f7a6ef291bd0eabbba,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking<0.11,>=0.10.0",1,1
openstack%2Fopenstack-ansible-os_rally~master~Ia62dd42dddde672eca1852e01f60818f4836f10c,openstack/openstack-ansible-os_rally,master,Ia62dd42dddde672eca1852e01f60818f4836f10c,Remove the private option from include_role,MERGED,2019-02-22 00:50:11.000000000,2019-02-22 02:42:19.000000000,2019-02-22 02:42:19.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:50:11.000000000', 'files': ['tasks/rally_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_rally/commit/3b22dd2b0babc8a745cfcbbb83e514aac4774265', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: Ia62dd42dddde672eca1852e01f60818f4836f10c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638555,3b22dd2b0babc8a745cfcbbb83e514aac4774265,6,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: Ia62dd42dddde672eca1852e01f60818f4836f10c
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_rally refs/changes/55/638555/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/rally_install.yml'],1,3b22dd2b0babc8a745cfcbbb83e514aac4774265,fix/private/deprecation,, private: yes,0,1
openstack%2Fopenstack-ansible-galera_server~stable%2Fqueens~I3e102377630d9c8ea5c9e3ea03cae3975a05dbb8,openstack/openstack-ansible-galera_server,stable/queens,I3e102377630d9c8ea5c9e3ea03cae3975a05dbb8,Iterate over list of values of PPC packages dict,MERGED,2019-02-19 11:41:01.000000000,2019-02-22 02:38:39.000000000,2019-02-22 02:38:39.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-19 11:41:01.000000000', 'files': ['tasks/galera_install_download_extra_packages.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/85f7b2c1afb312a8bd0a8602d9b5032d4c59953e', 'message': 'Iterate over list of values of PPC packages dict\n\nCurrently as we are iterating over a higher level dictionary\nand it is not possible to access the item.value.url attribute\ndirectly.\n\nAlternatively, we could get the values that is a list and\nthen iterate over that list to get properly the url and\nchecksum variables.\n\nAlso, we are not iterating over the dictionary we alternatively change\nthe item.key to galera_server_percona_distro_packages_alt_arch.keys()[0]\nthat produces the result as item.key.\n\nChange-Id: I3e102377630d9c8ea5c9e3ea03cae3975a05dbb8\nCloses-Bug: #1815902\n(cherry picked from commit 36d95a112da30d60847108946b433c376b4e77cc)\n'}]",0,637826,85f7b2c1afb312a8bd0a8602d9b5032d4c59953e,7,3,1,28008,,,0,"Iterate over list of values of PPC packages dict

Currently as we are iterating over a higher level dictionary
and it is not possible to access the item.value.url attribute
directly.

Alternatively, we could get the values that is a list and
then iterate over that list to get properly the url and
checksum variables.

Also, we are not iterating over the dictionary we alternatively change
the item.key to galera_server_percona_distro_packages_alt_arch.keys()[0]
that produces the result as item.key.

Change-Id: I3e102377630d9c8ea5c9e3ea03cae3975a05dbb8
Closes-Bug: #1815902
(cherry picked from commit 36d95a112da30d60847108946b433c376b4e77cc)
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/26/637826/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/galera_install_download_extra_packages.yml'],1,85f7b2c1afb312a8bd0a8602d9b5032d4c59953e,bug/1815902-stable/queens," url: ""{{ item.url }}"" dest: ""{{ galera_server_extra_package_path }}/{{ galera_server_percona_distro_packages_alt_arch.keys()[0] }}/"" checksum: ""{{ item.checksum | default(omit) }}"" force: ""{{ item.checksum is not defined }}"" with_items: ""{{ galera_server_percona_distro_packages_alt_arch.values() | flatten | list }}"""," url: ""{{ item.value.url }}"" dest: ""{{ galera_server_extra_package_path }}/{{ item.key }}/"" checksum: ""{{ item.value.checksum | default(omit) }}"" force: ""{{ item.value.checksum is not defined }}"" with_dict: ""{{ galera_server_percona_distro_packages_alt_arch }}""",5,5
openstack%2Fopenstack-ansible-galera_server~stable%2Frocky~I3e102377630d9c8ea5c9e3ea03cae3975a05dbb8,openstack/openstack-ansible-galera_server,stable/rocky,I3e102377630d9c8ea5c9e3ea03cae3975a05dbb8,Iterate over list of values of PPC packages dict,MERGED,2019-02-19 11:39:54.000000000,2019-02-22 02:36:54.000000000,2019-02-22 02:36:54.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-19 11:39:54.000000000', 'files': ['tasks/galera_install_download_extra_packages.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/714c3473592b0b7a513815ed5361d5d59a576e31', 'message': 'Iterate over list of values of PPC packages dict\n\nCurrently as we are iterating over a higher level dictionary\nand it is not possible to access the item.value.url attribute\ndirectly.\n\nAlternatively, we could get the values that is a list and\nthen iterate over that list to get properly the url and\nchecksum variables.\n\nAlso, we are not iterating over the dictionary we alternatively change\nthe item.key to galera_server_percona_distro_packages_alt_arch.keys()[0]\nthat produces the result as item.key.\n\nChange-Id: I3e102377630d9c8ea5c9e3ea03cae3975a05dbb8\nCloses-Bug: #1815902\n(cherry picked from commit 36d95a112da30d60847108946b433c376b4e77cc)\n'}]",0,637825,714c3473592b0b7a513815ed5361d5d59a576e31,7,3,1,28008,,,0,"Iterate over list of values of PPC packages dict

Currently as we are iterating over a higher level dictionary
and it is not possible to access the item.value.url attribute
directly.

Alternatively, we could get the values that is a list and
then iterate over that list to get properly the url and
checksum variables.

Also, we are not iterating over the dictionary we alternatively change
the item.key to galera_server_percona_distro_packages_alt_arch.keys()[0]
that produces the result as item.key.

Change-Id: I3e102377630d9c8ea5c9e3ea03cae3975a05dbb8
Closes-Bug: #1815902
(cherry picked from commit 36d95a112da30d60847108946b433c376b4e77cc)
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/25/637825/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/galera_install_download_extra_packages.yml'],1,714c3473592b0b7a513815ed5361d5d59a576e31,bug/1815902-stable/rocky," url: ""{{ item.url }}"" dest: ""{{ galera_server_extra_package_path }}/{{ galera_server_percona_distro_packages_alt_arch.keys()[0] }}/"" checksum: ""{{ item.checksum | default(omit) }}"" force: ""{{ item.checksum is not defined }}"" with_items: ""{{ galera_server_percona_distro_packages_alt_arch.values() | flatten | list }}"""," url: ""{{ item.value.url }}"" dest: ""{{ galera_server_extra_package_path }}/{{ item.key }}/"" checksum: ""{{ item.value.checksum | default(omit) }}"" force: ""{{ item.value.checksum is not defined }}"" with_dict: ""{{ galera_server_percona_distro_packages_alt_arch }}""",5,5
openstack%2Fopenstacksdk~master~I32b3f6a92b7ee67d7092ce833f881613d6d46867,openstack/openstacksdk,master,I32b3f6a92b7ee67d7092ce833f881613d6d46867,Add support for bodyless commits,MERGED,2019-02-02 13:38:06.000000000,2019-02-22 02:31:12.000000000,2019-02-22 02:31:12.000000000,"[{'_account_id': 2}, {'_account_id': 3099}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-02-02 13:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/72945dc2af2fd0f0f2d95d264938b8516743856e', 'message': ""Add support for bodyless commits\n\nAdd a flag that can be used for things like the load balancer action\nobjects that don't have a body but are just a URL that needs to be\nhit.\n\nChange-Id: I32b3f6a92b7ee67d7092ce833f881613d6d46867\n""}, {'number': 2, 'created': '2019-02-02 18:51:07.000000000', 'files': ['openstack/load_balancer/v2/load_balancer.py', 'openstack/resource.py', 'openstack/load_balancer/v2/amphora.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/96c823c99f747530c505f97157a55b5de123f820', 'message': ""Add support for bodyless commits\n\nAdd a flag that can be used for things like the load balancer action\nobjects that don't have a body but are just a URL that needs to be\nhit.\n\nChange-Id: I32b3f6a92b7ee67d7092ce833f881613d6d46867\n""}]",0,634558,96c823c99f747530c505f97157a55b5de123f820,12,5,2,2,,,0,"Add support for bodyless commits

Add a flag that can be used for things like the load balancer action
objects that don't have a body but are just a URL that needs to be
hit.

Change-Id: I32b3f6a92b7ee67d7092ce833f881613d6d46867
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/58/634558/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/load_balancer/v2/load_balancer.py', 'openstack/resource.py', 'openstack/load_balancer/v2/amphora.py']",3,72945dc2af2fd0f0f2d95d264938b8516743856e,bodyless-commit," allow_empty_commit = True # The default _update code path also has no return super(AmphoraConfig, self).commit( session, base_path=base_path, has_body=False) allow_empty_commit = True # The default _update code path also has no return super(AmphoraFailover, self).commit( session, base_path=base_path, has_body=False)"," # The parent commit method assumes there is a header or body change, # which we do not have here. The default _update code path also has no kwargs = {} request = self._prepare_request(prepend_key=False, base_path=base_path, **kwargs) session = self._get_session(session) kwargs = {} microversion = self._get_microversion_for(session, 'commit') response = session.put(request.url, json=request.body, headers=request.headers, microversion=microversion, **kwargs) self.microversion = microversion self._translate_response(response, has_body=False) return self # The parent commit method assumes there is a header or body change, # which we do not have here. The default _update code path also has no kwargs = {} request = self._prepare_request(prepend_key=False, base_path=base_path, **kwargs) session = self._get_session(session) kwargs = {} microversion = self._get_microversion_for(session, 'commit') response = session.put(request.url, json=request.body, headers=request.headers, microversion=microversion, **kwargs) self.microversion = microversion self._translate_response(response, has_body=False) return self",19,46
openstack%2Fopenstack-ansible-nspawn_container_create~master~I7678c1a5de07cda066dcf1e24684300fef56e0ba,openstack/openstack-ansible-nspawn_container_create,master,I7678c1a5de07cda066dcf1e24684300fef56e0ba,Remove the private option from include_role,MERGED,2019-02-22 00:49:36.000000000,2019-02-22 02:30:45.000000000,2019-02-22 02:30:45.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-22 00:49:36.000000000', 'files': ['tasks/main.yml', 'tests/test-nspawn-host-setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-nspawn_container_create/commit/3279aed459731f995005282d8b67fc1fa31f5268', 'message': 'Remove the private option from include_role\n\nThe private option on include role was never implemented and\nwill no longer be developed. This change removes the option\nso ansible no longer raises a deprecation warning.\n\nChange-Id: I7678c1a5de07cda066dcf1e24684300fef56e0ba\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,638543,3279aed459731f995005282d8b67fc1fa31f5268,6,2,1,7353,,,0,"Remove the private option from include_role

The private option on include role was never implemented and
will no longer be developed. This change removes the option
so ansible no longer raises a deprecation warning.

Change-Id: I7678c1a5de07cda066dcf1e24684300fef56e0ba
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-nspawn_container_create refs/changes/43/638543/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tests/test-nspawn-host-setup.yml']",2,3279aed459731f995005282d8b67fc1fa31f5268,fix/private/deprecation,, private: true private: true,0,3
openstack%2Fopenstacksdk~master~Id5a2ab45c2600a52415387b81369d371b6182578,openstack/openstacksdk,master,Id5a2ab45c2600a52415387b81369d371b6182578,Add Octavia (load_balancer) amphora API,MERGED,2019-02-02 03:12:51.000000000,2019-02-22 02:15:07.000000000,2019-02-22 02:15:07.000000000,"[{'_account_id': 2}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-02-02 03:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/56716ceb425d4375fc3e1daf27e7a018368b09ad', 'message': 'Add Octavia (load_balancer) amphora API\n\nThis patch adds the Octavia (load_balancer) amphora API support.\n\nChange-Id: Id5a2ab45c2600a52415387b81369d371b6182578\n'}, {'number': 2, 'created': '2019-02-02 18:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/53924a70052ddc1bb5449cca6eda11efa247c2b5', 'message': 'Add Octavia (load_balancer) amphora API\n\nThis patch adds the Octavia (load_balancer) amphora API support.\n\nDepends-On: https://review.openstack.org/#/c/632842/\nChange-Id: Id5a2ab45c2600a52415387b81369d371b6182578\n'}, {'number': 3, 'created': '2019-02-02 18:44:01.000000000', 'files': ['openstack/tests/functional/load_balancer/v2/test_load_balancer.py', 'doc/source/user/resources/load_balancer/index.rst', 'openstack/load_balancer/v2/_proxy.py', 'doc/source/user/proxies/load_balancer_v2.rst', 'doc/source/user/resources/load_balancer/v2/amphora.rst', 'openstack/load_balancer/v2/amphora.py', 'releasenotes/notes/add-octavia-amphora-api-7f3586f6a4f31de4.yaml', 'openstack/tests/unit/load_balancer/test_amphora.py', 'openstack/tests/unit/load_balancer/test_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/1249d5fd26fe87cdf85451ce34858f4dd3c945b2', 'message': 'Add Octavia (load_balancer) amphora API\n\nThis patch adds the Octavia (load_balancer) amphora API support.\n\nDepends-On: https://review.openstack.org/#/c/632842/\nChange-Id: Id5a2ab45c2600a52415387b81369d371b6182578\n'}]",1,634538,1249d5fd26fe87cdf85451ce34858f4dd3c945b2,18,4,3,11628,,,0,"Add Octavia (load_balancer) amphora API

This patch adds the Octavia (load_balancer) amphora API support.

Depends-On: https://review.openstack.org/#/c/632842/
Change-Id: Id5a2ab45c2600a52415387b81369d371b6182578
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/38/634538/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/functional/load_balancer/v2/test_load_balancer.py', 'doc/source/user/resources/load_balancer/index.rst', 'openstack/load_balancer/v2/_proxy.py', 'doc/source/user/proxies/load_balancer_v2.rst', 'doc/source/user/resources/load_balancer/v2/amphora.rst', 'openstack/load_balancer/v2/amphora.py', 'releasenotes/notes/add-octavia-amphora-api-7f3586f6a4f31de4.yaml', 'openstack/tests/unit/load_balancer/test_amphora.py', 'openstack/tests/unit/load_balancer/test_proxy.py']",9,56716ceb425d4375fc3e1daf27e7a018368b09ad,octavia-amphora,"from openstack.load_balancer.v2 import amphora AMPHORA_ID = uuid.uuid4() def test_amphorae(self): self.verify_list(self.proxy.amphorae, amphora.Amphora) def test_amphora_get(self): self.verify_get(self.proxy.get_amphora, amphora.Amphora) def test_amphora_find(self): self.verify_find(self.proxy.find_amphora, amphora.Amphora) def test_amphora_configure(self): self.verify_update(self.proxy.configure_amphora, amphora.AmphoraConfig, value=[self.AMPHORA_ID], expected_args=[], expected_kwargs={'amphora_id': self.AMPHORA_ID}) def test_amphora_failover(self): self.verify_update(self.proxy.failover_amphora, amphora.AmphoraFailover, value=[self.AMPHORA_ID], expected_args=[], expected_kwargs={'amphora_id': self.AMPHORA_ID})",,440,0
openstack%2Fnetworking-baremetal~stable%2Fqueens~Ie51d0a0b02ed5ea336f3280d84d77cf8fec90ccb,openstack/networking-baremetal,stable/queens,Ie51d0a0b02ed5ea336f3280d84d77cf8fec90ccb,Set amqp_auto_delete=true for notifications transport.,MERGED,2019-02-07 13:39:54.000000000,2019-02-22 02:02:05.000000000,2019-02-22 02:02:05.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-02-07 13:39:54.000000000', 'files': ['networking_baremetal/agent/ironic_neutron_agent.py', 'networking_baremetal/tests/unit/ironic_agent/test_ironic_agent.py', 'releasenotes/notes/agent-notification-auto-delete-queues-a3782fbeea2b57b1.yaml'], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/bf8ec8f9d72657252e2c4a03c2bac4c97ad26d48', 'message': 'Set amqp_auto_delete=true for notifications transport.\n\nironic-neutron-agent uses oslo.messaing notifications\nto manage the hash ring members. Each listener uses a\npool, to ensure all instances of the agent recived\nnotifications from all other isntances of the agent.\n\nThe pool used is a random uuid that is generated on\nstartup, and on restart a new uuid is generated.\n\nIn the messaging backend each pool creates a separate\nqueue. When the agent is restarted this queue is not\nremoved, and since the uuid is regenerated for the\nrestarted agent the messaging backend keep publishing\nmessages to the ""old-uuid"" queue as well as the\n""new-uuid"" queue. The problem is that the ""old-uuid""\nqueue is no longer consumed, so it continues to grow\nand cause high RAM usage in the message broker\nback-end.\n\nTo fix this set the queues to auto_delete so that\nthey are deleted automatically when no consumers are\nactive.\n\nStory: 2004933\nTask: 29322\nChange-Id: Ie51d0a0b02ed5ea336f3280d84d77cf8fec90ccb\n(cherry picked from commit 00c2f2346ad1bcf7179ce1bc304b764f4ebc4cdf)\n'}]",2,635509,bf8ec8f9d72657252e2c4a03c2bac4c97ad26d48,21,5,1,24245,,,0,"Set amqp_auto_delete=true for notifications transport.

ironic-neutron-agent uses oslo.messaing notifications
to manage the hash ring members. Each listener uses a
pool, to ensure all instances of the agent recived
notifications from all other isntances of the agent.

The pool used is a random uuid that is generated on
startup, and on restart a new uuid is generated.

In the messaging backend each pool creates a separate
queue. When the agent is restarted this queue is not
removed, and since the uuid is regenerated for the
restarted agent the messaging backend keep publishing
messages to the ""old-uuid"" queue as well as the
""new-uuid"" queue. The problem is that the ""old-uuid""
queue is no longer consumed, so it continues to grow
and cause high RAM usage in the message broker
back-end.

To fix this set the queues to auto_delete so that
they are deleted automatically when no consumers are
active.

Story: 2004933
Task: 29322
Change-Id: Ie51d0a0b02ed5ea336f3280d84d77cf8fec90ccb
(cherry picked from commit 00c2f2346ad1bcf7179ce1bc304b764f4ebc4cdf)
",git fetch https://review.opendev.org/openstack/networking-baremetal refs/changes/09/635509/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_baremetal/agent/ironic_neutron_agent.py', 'networking_baremetal/tests/unit/ironic_agent/test_ironic_agent.py', 'releasenotes/notes/agent-notification-auto-delete-queues-a3782fbeea2b57b1.yaml']",3,bf8ec8f9d72657252e2c4a03c2bac4c97ad26d48,story/2004933,"--- upgrade: - | To fix `bug: 2004933 <https://storyboard.openstack.org/#!/story/2004933>`_ oslo.messaging notification queues are now created with ``amqp_auto_delete=true``. When upgrading the agent old queues must be deleted prior to starting the ``ironic-neutron-agent`` service again after the update. _(If the old queues were created with ``amqp_auto_delete=false``, the agent will not be able to start when the old queues still exist.)_ On rabbitmq queues can be deleted via the web console. For example with curl:: curl -i -u username:password \ -H ""content-type:application/json"" -XDELETE \ http://<host>:<web-port>/api/queues/<vhost>/<queue-name> Another example with vhost: '/' deleting the ironic-neutron-agent-heartbeat.info queue:: curl -i -u username:password \ -H ""content-type:application/json"" \ -XDELETE \ http://172.20.0.1:15672/api/queues/%2F/ironic-neutron-agent-heartbeat.info .. Note:: In the example above the vhost is ``/``. To ensure the vhost is correctly encoded the use of ``%2F``, instead of ``/`` is required. fixes: - | Fixes an issue where old oslo.messaging notification pool queues remained in the broker without any consumer after agent restart. The notification queues will now be created with ``amqp_auto_delete=true``. See `bug: 2004933 <https://storyboard.openstack.org/#!/story/2004933>`_. .. Warning:: Old queues must be deleted when updating to a version with this fix. Please refer to the upgrade section of the releasenotes for details. ",,73,3
openstack%2Ffreezer-api~master~Ifbf7b16e7c81dc0f85b07b77599ab4e404f2cdd4,openstack/freezer-api,master,Ifbf7b16e7c81dc0f85b07b77599ab4e404f2cdd4,Update json module to jsonutils,MERGED,2019-02-21 06:15:24.000000000,2019-02-22 01:32:55.000000000,2019-02-22 01:32:55.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}, {'_account_id': 22484}]","[{'number': 1, 'created': '2019-02-21 06:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/4ad63b96b0e3994531d789324c5f8e538dd5b28d', 'message': 'Update json module to jsonutils\n\njson is deprecated, should use oslo_serialization.jsonutils\ninstead.\n\nChange-Id: Ifbf7b16e7c81dc0f85b07b77599ab4e404f2cdd4\n'}, {'number': 2, 'created': '2019-02-21 09:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/7eaba4ccd45367559f112daf4b3bb9daf8d9861e', 'message': 'Update json module to jsonutils\n\njson is deprecated, should use oslo_serialization.jsonutils\ninstead.\n\nChange-Id: Ifbf7b16e7c81dc0f85b07b77599ab4e404f2cdd4\n'}, {'number': 3, 'created': '2019-02-21 11:00:56.000000000', 'files': ['freezer_api/api/versions.py', 'freezer_api/tests/unit/v1/test_jobs.py', 'freezer_api/tests/unit/v1/test_homedoc.py', 'freezer_api/api/common/middleware.py', 'freezer_api/cmd/manage.py', 'freezer_api/api/v2/homedoc.py', 'requirements.txt', 'freezer_api/api/v1/homedoc.py', 'freezer_api/tests/unit/v2/test_homedoc.py', 'freezer_api/api/common/resource.py', 'freezer_api/tests/unit/test_versions.py', 'freezer_api/tests/unit/v2/test_jobs.py'], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/a350b44b1be03cc7b9d198a736118261b4547d35', 'message': 'Update json module to jsonutils\n\noslo project provide jsonutils, and the others project use it now,\nthis PS to update json moudule to oslo jsonutils for consistency.\n\nChange-Id: Ifbf7b16e7c81dc0f85b07b77599ab4e404f2cdd4\n'}]",0,638341,a350b44b1be03cc7b9d198a736118261b4547d35,13,3,3,27781,,,0,"Update json module to jsonutils

oslo project provide jsonutils, and the others project use it now,
this PS to update json moudule to oslo jsonutils for consistency.

Change-Id: Ifbf7b16e7c81dc0f85b07b77599ab4e404f2cdd4
",git fetch https://review.opendev.org/openstack/freezer-api refs/changes/41/638341/1 && git format-patch -1 --stdout FETCH_HEAD,"['freezer_api/api/v1/homedoc.py', 'freezer_api/api/versions.py', 'freezer_api/tests/unit/v1/test_jobs.py', 'freezer_api/tests/unit/v2/test_homedoc.py', 'freezer_api/tests/unit/v1/test_homedoc.py', 'freezer_api/api/common/middleware.py', 'freezer_api/cmd/manage.py', 'freezer_api/api/v2/homedoc.py', 'freezer_api/api/common/resource.py', 'freezer_api/tests/unit/test_versions.py', 'freezer_api/tests/unit/v2/test_jobs.py']",11,4ad63b96b0e3994531d789324c5f8e538dd5b28d,,from oslo_serialization import jsonutils as json ,import json,17,16
openstack%2Foslo.messaging~master~I3335ccb01667d22a181d99d4d53d7356005d72ad,openstack/oslo.messaging,master,I3335ccb01667d22a181d99d4d53d7356005d72ad,Change python3.5 job to python3.7 job on Stein+,MERGED,2018-10-12 17:07:37.000000000,2019-02-22 01:23:52.000000000,2019-02-22 01:23:52.000000000,"[{'_account_id': 24}, {'_account_id': 8770}, {'_account_id': 11805}, {'_account_id': 15334}, {'_account_id': 20523}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-10-12 17:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a5ff5ad94d21a6c94e25f1810c04261110839398', 'message': 'Change python3.5 job to python3.7 job on Stein+\n\npython3.5 was the only supported python3 version on Xenial, now that we have\nBionic Beaver nodes that support python3.7, lets switch to testing with\npython3.7 in addition with python3.6 in Stein and beyond.\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135632.html\n\nChange-Id: I3335ccb01667d22a181d99d4d53d7356005d72ad\nSigned-off-by: Charles Short <chucks@redhat.com>\n'}, {'number': 2, 'created': '2018-10-15 13:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d217d4fe05ffc9753750bc786b2d2b0d5f515a7e', 'message': 'Change python3.5 job to python3.7 job on Stein+\n\npython3.5 was the only supported python3 version on Xenial, now that we have\nBionic Beaver nodes that support python3.7, lets switch to testing with\npython3.7 in addition with python3.6 in Stein and beyond.\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135632.html\n\nChange-Id: I3335ccb01667d22a181d99d4d53d7356005d72ad\nSigned-off-by: Charles Short <chucks@redhat.com>\nStory: #2004073\nTask: #27440\n'}, {'number': 3, 'created': '2019-02-14 10:28:20.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/fa2a3e4fcc9e2f83850fa01dd99f61cf4fb62a26', 'message': 'Change python3.5 job to python3.7 job on Stein+\n\npython3.5 was the only supported python3 version on Xenial, now that we have\nBionic Beaver nodes that support python3.7, lets switch to testing with\npython3.7 in addition with python3.6 in Stein and beyond.\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135632.html\n\nChange-Id: I3335ccb01667d22a181d99d4d53d7356005d72ad\nSigned-off-by: Charles Short <chucks@redhat.com>\nStory: #2004073\nTask: #27440\n'}]",0,610118,fa2a3e4fcc9e2f83850fa01dd99f61cf4fb62a26,20,6,3,24,,,0,"Change python3.5 job to python3.7 job on Stein+

python3.5 was the only supported python3 version on Xenial, now that we have
Bionic Beaver nodes that support python3.7, lets switch to testing with
python3.7 in addition with python3.6 in Stein and beyond.
See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135632.html

Change-Id: I3335ccb01667d22a181d99d4d53d7356005d72ad
Signed-off-by: Charles Short <chucks@redhat.com>
Story: #2004073
Task: #27440
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/18/610118/3 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'tox.ini']",2,a5ff5ad94d21a6c94e25f1810c04261110839398,py37-job,"envlist = py37,py27,pep8","envlist = py35,py27,pep8",2,2
openstack%2Fnova~master~I78ed924a802307a992ff90e61ae7ff07c2cc39d1,openstack/nova,master,I78ed924a802307a992ff90e61ae7ff07c2cc39d1,API microversion 2.69: Handles Down Cells Documentation,MERGED,2019-02-06 12:41:52.000000000,2019-02-22 01:09:54.000000000,2019-02-21 00:29:00.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 26936}]","[{'number': 1, 'created': '2019-02-06 12:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec58b0d39ba844cfcab23ca830417dae90404f54', 'message': 'API microversion 2.68: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.68.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 2, 'created': '2019-02-07 09:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/018a30825cd1b97c12953d0f623235da8c0c1b5f', 'message': 'API microversion 2.68: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.68.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 3, 'created': '2019-02-07 12:32:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8d425d9d302b8d89088eff50eeb97291923a396', 'message': 'API microversion 2.68: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.68.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 4, 'created': '2019-02-07 13:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f4365b134f8035e57da0a2cd328b7aef7075546', 'message': 'API microversion 2.68: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.68.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 5, 'created': '2019-02-08 12:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c154d9eb45bab08b61b6fe11d6fa68d877277d74', 'message': 'API microversion 2.68: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.68.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 6, 'created': '2019-02-08 14:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62d0c236e741717c91f1336a7763e50ea4d0d9fe', 'message': 'API microversion 2.68: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.68.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 7, 'created': '2019-02-08 21:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc10a4067c2fa8202be15feddeb953c065052ef8', 'message': 'API microversion 2.68: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.68.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 8, 'created': '2019-02-08 21:29:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c906f52216cf381856e32819b78155fcc1e0ccbb', 'message': 'API microversion 2.68: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.68.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 9, 'created': '2019-02-12 17:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/72ac97a1cebeacd36465496d1b2940dbb80f88f4', 'message': 'API microversion 2.69: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.69.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 10, 'created': '2019-02-13 13:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f383fe2a88a69ad987926b8c8441c582eab4237', 'message': 'API microversion 2.69: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.69.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 11, 'created': '2019-02-13 13:13:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/402135862539f6af2a01d48bfd4b425f3b309ca2', 'message': 'API microversion 2.69: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.69.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 12, 'created': '2019-02-14 19:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2885a2f4269d0f4b4364b5c795a7f6738aaee726', 'message': 'API microversion 2.69: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.69.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 13, 'created': '2019-02-15 13:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1843894477177656ab1e91eb0ceb9009f46d57c6', 'message': 'API microversion 2.69: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.69.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 14, 'created': '2019-02-15 19:35:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b89745de2fae52b971bcbe45f204dfe232ad862', 'message': 'API microversion 2.69: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.69.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 15, 'created': '2019-02-15 19:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd96e0aefd3a9865b13a7c4aa88c98b4e6e8b012', 'message': 'API microversion 2.69: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.69.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 16, 'created': '2019-02-18 10:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac574f35d49ff3f34a1676329ab0e5152661d768', 'message': 'API microversion 2.69: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.69.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 17, 'created': '2019-02-18 14:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1bfe04684c271e83636bcdaae363daefadd0cb9f', 'message': 'API microversion 2.69: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.69.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 18, 'created': '2019-02-20 14:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d998a5bf56890152e5e679e7c980cd14a3007791', 'message': 'API microversion 2.69: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.69.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 19, 'created': '2019-02-20 16:22:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95365900f9b40c640e9bc45694f0e0f2f5d710c6', 'message': 'API microversion 2.69: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.69.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}, {'number': 20, 'created': '2019-02-20 18:11:10.000000000', 'files': ['api-guide/source/server_concepts.rst', 'doc/source/user/cells.rst', 'api-guide/source/index.rst', 'api-ref/source/os-services.inc', 'nova/conf/api.py', 'nova/api/openstack/compute/rest_api_version_history.rst', 'api-guide/source/down_cells.rst', 'releasenotes/notes/bp-handling-down-cell-10f76145d767300c.yaml', 'api-ref/source/servers.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/833af5c9bf6178e7c7a7dc4ed9db4f9ae7533cd8', 'message': 'API microversion 2.69: Handles Down Cells Documentation\n\nThis patch adds the documentation around the work regarding\nhandling down cells that was introduced in v2.69.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1\n'}]",65,635147,833af5c9bf6178e7c7a7dc4ed9db4f9ae7533cd8,152,16,20,26936,,,0,"API microversion 2.69: Handles Down Cells Documentation

This patch adds the documentation around the work regarding
handling down cells that was introduced in v2.69.

Related to blueprint handling-down-cell

Change-Id: I78ed924a802307a992ff90e61ae7ff07c2cc39d1
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/635147/18 && git format-patch -1 --stdout FETCH_HEAD,"['api-guide/source/server_concepts.rst', 'doc/source/user/cells.rst', 'api-guide/source/index.rst', 'api-ref/source/os-services.inc', 'nova/api/openstack/compute/rest_api_version_history.rst', 'api-guide/source/down_cells.rst', 'releasenotes/notes/bp-handling-down-cell-10f76145d767300c.yaml', 'api-ref/source/servers.inc']",8,ec58b0d39ba844cfcab23ca830417dae90404f54,bp/handling-down-cell,".. note:: Starting with microversion 2.68 if server details cannot be loaded due to a transient condition in the deployment like infrastructure failure, the response body for those unavailable servers will be missing keys. See `handling down cells <https://developer.openstack.org/api-guide/compute/down_cells.html>`__ section of the Compute API guide for more information on the keys that would be returned in the partial constructs. .. note:: Starting with microversion 2.68 if server details cannot be loaded due to a transient condition in the deployment like infrastructure failure, the response body for those unavailable servers will be missing keys. See `handling down cells <https://developer.openstack.org/api-guide/compute/down_cells.html>`__ section of the Compute API guide for more information on the keys that would be returned in the partial constructs. .. note:: Starting with microversion 2.68 if the server detail cannot be loaded due to a transient condition in the deployment like infrastructure failure, the response body for the unavailable server will be missing keys. See `handling down cells <http://developer.openstack.org/api-guide/compute/down_cells.html>`__ section of the Compute API guide for more information on the keys that would be returned in the partial constructs. ",,218,2
openstack%2Fnetworking-baremetal~stable%2Frocky~Iebb92beff9c4e16581a07b16ccdfbbeba3176543,openstack/networking-baremetal,stable/rocky,Iebb92beff9c4e16581a07b16ccdfbbeba3176543,Rename agent queue - fixes broken minor update,MERGED,2019-02-20 08:35:14.000000000,2019-02-22 00:33:04.000000000,2019-02-22 00:33:04.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-02-20 08:35:14.000000000', 'files': ['networking_baremetal/agent/ironic_neutron_agent.py', 'releasenotes/notes/agent-notification-auto-delete-queues-a3782fbeea2b57b1.yaml'], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/a0236872041babd84e6b7e3cd7eca558e746e602', 'message': 'Rename agent queue - fixes broken minor update\n\nWhen fixing the original issue the auto_delete policy for\nthe queue was changed to auto_delete = true. Changeing\nthe policy for an existing queue with auto_delete = fales\nis not allowed, thus the queue had to be deleted to allow\nit to be recreated with the new auto_delete policy.\n\nBy changeing the name of the queue, we can restart the\nagent after applying update and not have to delete the old\nqueue.\n\nNOTE: This changes the existing release notes, it is still\n      recommended to delete the old queue. But it is no\n      longer required to allow the agent to be restarted\n      with the fix.\n\nChange-Id: Iebb92beff9c4e16581a07b16ccdfbbeba3176543\nStory: 2004938\nTask: 29532\n(cherry picked from commit 83bfd778197361df04d1f4cceb9b9b6201a223e1)\n'}]",0,638104,a0236872041babd84e6b7e3cd7eca558e746e602,17,4,1,24245,,,0,"Rename agent queue - fixes broken minor update

When fixing the original issue the auto_delete policy for
the queue was changed to auto_delete = true. Changeing
the policy for an existing queue with auto_delete = fales
is not allowed, thus the queue had to be deleted to allow
it to be recreated with the new auto_delete policy.

By changeing the name of the queue, we can restart the
agent after applying update and not have to delete the old
queue.

NOTE: This changes the existing release notes, it is still
      recommended to delete the old queue. But it is no
      longer required to allow the agent to be restarted
      with the fix.

Change-Id: Iebb92beff9c4e16581a07b16ccdfbbeba3176543
Story: 2004938
Task: 29532
(cherry picked from commit 83bfd778197361df04d1f4cceb9b9b6201a223e1)
",git fetch https://review.opendev.org/openstack/networking-baremetal refs/changes/04/638104/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_baremetal/agent/ironic_neutron_agent.py', 'releasenotes/notes/agent-notification-auto-delete-queues-a3782fbeea2b57b1.yaml']",2,a0236872041babd84e6b7e3cd7eca558e746e602,story/2004938," oslo.messaging notification queues are now renamed and created with ``amqp_auto_delete=true``. When upgrading the agent old queues should be deleted to free up message broker resources. Previous queue that can be deleted are named ``ironic-neutron-agent-heartbeat.info``. There may also be queues with uuid of previous agent instances as name, these can also safely be deleted. (Look in the agent logs for relevant agent uuids)."," oslo.messaging notification queues are now created with ``amqp_auto_delete=true``. When upgrading the agent old queues must be deleted prior to starting the ``ironic-neutron-agent`` service again after the update. _(If the old queues were created with ``amqp_auto_delete=false``, the agent will not be able to start when the old queues still exist.)_ .. Warning:: Old queues must be deleted when updating to a version with this fix. Please refer to the upgrade section of the releasenotes for details. ",11,14
openstack%2Fnova~stable%2Fqueens~Ifaf596a8572637f843f47daf5adce394b0365676,openstack/nova,stable/queens,Ifaf596a8572637f843f47daf5adce394b0365676,Note the aggregate allocation ratio restriction in scheduler docs,MERGED,2018-12-07 16:56:49.000000000,2019-02-22 00:14:00.000000000,2019-02-22 00:14:00.000000000,"[{'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-07 16:56:49.000000000', 'files': ['doc/source/admin/configuration/schedulers.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/5c7638bab40bd6cfdbc199527d3a8c86bde40897', 'message': 'Note the aggregate allocation ratio restriction in scheduler docs\n\nThis borrows from the release note in change\nI01f20f275bbd5451ace5c1e6f41ab38d488dae4e to document the\nregression, introduced in Ocata, where allocation ratio settings\nin the aggregate core/ram/disk filters are not honored because\nof placement being used by the FilterScheduler.\n\nWhile there is related work going on around this in\nblueprint initial-allocation-ratios and\nblueprint placement-aggregate-allocation-ratios, it is still\na limitation in the current code base and needs to be called\nout in the docs.\n\nChange-Id: Ifaf596a8572637f843f47daf5adce394b0365676\nRelated-Bug: #1804125\n(cherry picked from commit d65c18a0a9f02e6d37f2b87ff61f1740c8bfc867)\n(cherry picked from commit 899b4ca5a248eba252d3c89e373f8a787d68749c)\n'}]",0,623547,5c7638bab40bd6cfdbc199527d3a8c86bde40897,9,5,1,6873,,,0,"Note the aggregate allocation ratio restriction in scheduler docs

This borrows from the release note in change
I01f20f275bbd5451ace5c1e6f41ab38d488dae4e to document the
regression, introduced in Ocata, where allocation ratio settings
in the aggregate core/ram/disk filters are not honored because
of placement being used by the FilterScheduler.

While there is related work going on around this in
blueprint initial-allocation-ratios and
blueprint placement-aggregate-allocation-ratios, it is still
a limitation in the current code base and needs to be called
out in the docs.

Change-Id: Ifaf596a8572637f843f47daf5adce394b0365676
Related-Bug: #1804125
(cherry picked from commit d65c18a0a9f02e6d37f2b87ff61f1740c8bfc867)
(cherry picked from commit 899b4ca5a248eba252d3c89e373f8a787d68749c)
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/623547/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/configuration/schedulers.rst'],1,5c7638bab40bd6cfdbc199527d3a8c86bde40897,bug/1804125,"Note the ``cpu_allocation_ratio`` :ref:`bug 1804125 <bug-1804125>` restriction. Note the ``disk_allocation_ratio`` :ref:`bug 1804125 <bug-1804125>` restriction. Note the ``ram_allocation_ratio`` :ref:`bug 1804125 <bug-1804125>` restriction. .. _bug-1804125: .. note:: Regarding the `AggregateCoreFilter`_, `AggregateDiskFilter`_ and `AggregateRamFilter`_, starting in 15.0.0 (Ocata) there is a behavior change where aggregate-based overcommit ratios will no longer be honored during scheduling for the FilterScheduler. Instead, overcommit values must be set on a per-compute-node basis in the Nova configuration files. If you have been relying on per-aggregate overcommit, during your upgrade, you must change to using per-compute-node overcommit ratios in order for your scheduling behavior to stay consistent. Otherwise, you may notice increased NoValidHost scheduling failures as the aggregate-based overcommit is no longer being considered. See `bug 1804125 <https://bugs.launchpad.net/nova/+bug/1804125>`_ for more details. ",,24,0
openstack%2Fcharm-glance~master~I0d8e7409b8eb4e5e403455db03d73020f741afc4,openstack/charm-glance,master,I0d8e7409b8eb4e5e403455db03d73020f741afc4,Implement new option: filesystem-store-datadir,MERGED,2019-02-19 18:40:52.000000000,2019-02-22 00:02:53.000000000,2019-02-22 00:02:53.000000000,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-19 18:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/b82215104a618c52dbf19f92ffafc5335bfc0eae', 'message': 'Implement new option: filesystem-store-datadir\n\nThis change implements a new option in config.yaml that can be used\nto change the location of the images store on the filesystem.\n\nChange-Id: I0d8e7409b8eb4e5e403455db03d73020f741afc4\nCloses-Bug: #1657165\n'}, {'number': 2, 'created': '2019-02-21 12:41:35.000000000', 'files': ['templates/kilo/glance-api.conf', 'hooks/glance_contexts.py', 'unit_tests/test_glance_contexts.py', 'config.yaml', 'templates/mitaka/glance-api.conf', 'templates/icehouse/glance-api.conf', 'templates/juno/glance-api.conf'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/6e6b492485e5eaf85a3277ff8567c3c2c5a344b4', 'message': 'Implement new option: filesystem-store-datadir\n\nThis change implements a new option in config.yaml that can be used\nto change the location of the images store on the filesystem.\n\nChange-Id: I0d8e7409b8eb4e5e403455db03d73020f741afc4\nCloses-Bug: #1657165\n'}]",2,637966,6e6b492485e5eaf85a3277ff8567c3c2c5a344b4,13,3,2,29625,,,0,"Implement new option: filesystem-store-datadir

This change implements a new option in config.yaml that can be used
to change the location of the images store on the filesystem.

Change-Id: I0d8e7409b8eb4e5e403455db03d73020f741afc4
Closes-Bug: #1657165
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/66/637966/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/kilo/glance-api.conf', 'hooks/glance_contexts.py', 'unit_tests/test_glance_contexts.py', 'config.yaml', 'templates/mitaka/glance-api.conf', 'templates/icehouse/glance-api.conf', 'templates/juno/glance-api.conf']",7,b82215104a618c52dbf19f92ffafc5335bfc0eae,bug/1657165,{%- if filesystem_store_datadir %} filesystem_store_datadir = {{ filesystem_store_datadir }} {% else -%}{% endif -%},,44,1
openstack%2Fopenstacksdk~master~If786149c9d411b715740f893b6263b1bb47ba54f,openstack/openstacksdk,master,If786149c9d411b715740f893b6263b1bb47ba54f,Add Octavia (load_balancer) flavor API,MERGED,2019-02-02 00:42:09.000000000,2019-02-21 23:52:53.000000000,2019-02-21 23:52:53.000000000,"[{'_account_id': 2}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-02-02 00:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0cfc110a364974cb0c17dc7ca6d50f42630d1b8c', 'message': 'Add Octavia (load_balancer) flavor API\n\nThis patch adds the Octavia (load_balancer) flavor API support.\n\nChange-Id: If786149c9d411b715740f893b6263b1bb47ba54f\n'}, {'number': 2, 'created': '2019-02-02 18:42:34.000000000', 'files': ['openstack/tests/functional/load_balancer/v2/test_load_balancer.py', 'releasenotes/notes/add-load-balancer-flavor-api-d2598e30347a19fc.yaml', 'doc/source/user/resources/load_balancer/index.rst', 'openstack/load_balancer/v2/_proxy.py', 'doc/source/user/proxies/load_balancer_v2.rst', 'openstack/load_balancer/v2/flavor.py', 'doc/source/user/resources/load_balancer/v2/flavor.rst', 'openstack/tests/unit/load_balancer/test_flavor.py', 'openstack/tests/unit/load_balancer/test_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/85f1e4c7f18e010a24f82d86c26c42257a5c392c', 'message': 'Add Octavia (load_balancer) flavor API\n\nThis patch adds the Octavia (load_balancer) flavor API support.\n\nChange-Id: If786149c9d411b715740f893b6263b1bb47ba54f\n'}]",2,634532,85f1e4c7f18e010a24f82d86c26c42257a5c392c,16,4,2,11628,,,0,"Add Octavia (load_balancer) flavor API

This patch adds the Octavia (load_balancer) flavor API support.

Change-Id: If786149c9d411b715740f893b6263b1bb47ba54f
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/32/634532/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/functional/load_balancer/v2/test_load_balancer.py', 'releasenotes/notes/add-load-balancer-flavor-api-d2598e30347a19fc.yaml', 'doc/source/user/resources/load_balancer/index.rst', 'openstack/load_balancer/v2/_proxy.py', 'doc/source/user/proxies/load_balancer_v2.rst', 'openstack/load_balancer/v2/flavor.py', 'doc/source/user/resources/load_balancer/v2/flavor.rst', 'openstack/tests/unit/load_balancer/test_flavor.py', 'openstack/tests/unit/load_balancer/test_proxy.py']",9,0cfc110a364974cb0c17dc7ca6d50f42630d1b8c,octavia-flavor,"from openstack.load_balancer.v2 import flavor def test_flavors(self): self.verify_list(self.proxy.flavors, flavor.Flavor) def test_flavor_get(self): self.verify_get(self.proxy.get_flavor, flavor.Flavor) def test_flavor_create(self): self.verify_create(self.proxy.create_flavor, flavor.Flavor) def test_flavor_delete(self): self.verify_delete(self.proxy.delete_flavor, flavor.Flavor, True) def test_flavor_find(self): self.verify_find(self.proxy.find_flavor, flavor.Flavor) def test_flavor_update(self): self.verify_update(self.proxy.update_flavor, flavor.Flavor)",,268,1
openstack%2Fopenstacksdk~master~I1358d89b07917726451bf311c1323e57f381f853,openstack/openstacksdk,master,I1358d89b07917726451bf311c1323e57f381f853,Add Octavia (load_balancer) flavor profile API,MERGED,2019-02-01 23:47:11.000000000,2019-02-21 23:52:51.000000000,2019-02-21 23:52:51.000000000,"[{'_account_id': 2}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-02-01 23:47:11.000000000', 'files': ['doc/source/user/resources/load_balancer/v2/flavor_profile.rst', 'openstack/tests/functional/load_balancer/v2/test_load_balancer.py', 'openstack/load_balancer/v2/flavor_profile.py', 'openstack/tests/unit/load_balancer/test_flavor_profile.py', 'doc/source/user/resources/load_balancer/index.rst', 'openstack/load_balancer/v2/_proxy.py', 'doc/source/user/proxies/load_balancer_v2.rst', 'releasenotes/notes/add-load-balancer-flavor-profile-api-e5a15157563eb75f.yaml', 'openstack/tests/unit/load_balancer/test_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/1b884947bc7d1be4500cf515abe8528ba2af0bef', 'message': 'Add Octavia (load_balancer) flavor profile API\n\nThis patch adds the Octavia (load_balancer) flavor profile API support.\n\nChange-Id: I1358d89b07917726451bf311c1323e57f381f853\n'}]",2,634518,1b884947bc7d1be4500cf515abe8528ba2af0bef,14,3,1,11628,,,0,"Add Octavia (load_balancer) flavor profile API

This patch adds the Octavia (load_balancer) flavor profile API support.

Change-Id: I1358d89b07917726451bf311c1323e57f381f853
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/18/634518/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/resources/load_balancer/v2/flavor_profile.rst', 'openstack/tests/functional/load_balancer/v2/test_load_balancer.py', 'openstack/load_balancer/v2/flavor_profile.py', 'doc/source/user/resources/load_balancer/index.rst', 'openstack/tests/unit/load_balancer/test_flavor_profile.py', 'openstack/load_balancer/v2/_proxy.py', 'doc/source/user/proxies/load_balancer_v2.rst', 'releasenotes/notes/add-load-balancer-flavor-profile-api-e5a15157563eb75f.yaml', 'openstack/tests/unit/load_balancer/test_proxy.py']",9,1b884947bc7d1be4500cf515abe8528ba2af0bef,octavia-flavor-profile,"from openstack.load_balancer.v2 import flavor_profile def test_flavor_profiles(self): self.verify_list(self.proxy.flavor_profiles, flavor_profile.FlavorProfile) def test_flavor_profile_get(self): self.verify_get(self.proxy.get_flavor_profile, flavor_profile.FlavorProfile) def test_flavor_profile_create(self): self.verify_create(self.proxy.create_flavor_profile, flavor_profile.FlavorProfile) def test_flavor_profile_delete(self): self.verify_delete(self.proxy.delete_flavor_profile, flavor_profile.FlavorProfile, True) def test_flavor_profile_find(self): self.verify_find(self.proxy.find_flavor_profile, flavor_profile.FlavorProfile) def test_flavor_profile_update(self): self.verify_update(self.proxy.update_flavor_profile, flavor_profile.FlavorProfile)",,280,0
openstack%2Fopenstacksdk~master~Ieb8e2d2fc592d69eca9c8cf36f726a35db1cda22,openstack/openstacksdk,master,Ieb8e2d2fc592d69eca9c8cf36f726a35db1cda22,Add Octavia (load_balancer) provider API support,MERGED,2019-02-01 20:39:06.000000000,2019-02-21 23:52:49.000000000,2019-02-21 23:52:49.000000000,"[{'_account_id': 2}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-02-01 20:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/75ccd90e2dac3e3d6b9b4c46664666744e242ab0', 'message': 'Add Octavia (load_balancer) provider API support\n\nThis patch adds the Octavia (load_balancer) provider API support.\nSpecifically: providers and provider_flavor_capabilities\n\nChange-Id: Ieb8e2d2fc592d69eca9c8cf36f726a35db1cda22\n'}, {'number': 2, 'created': '2019-02-01 22:34:48.000000000', 'files': ['openstack/tests/functional/load_balancer/v2/test_load_balancer.py', 'openstack/tests/unit/load_balancer/test_provider.py', 'doc/source/user/resources/load_balancer/index.rst', 'openstack/load_balancer/v2/provider.py', 'openstack/load_balancer/v2/_proxy.py', 'doc/source/user/proxies/load_balancer_v2.rst', 'releasenotes/notes/add-load-balancer-provider-api-08bcfb72ddf5b247.yaml', 'doc/source/user/resources/load_balancer/v2/provider.rst', 'openstack/tests/unit/load_balancer/test_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b27f0c579e53e81095c2b3fe353d047192afef89', 'message': 'Add Octavia (load_balancer) provider API support\n\nThis patch adds the Octavia (load_balancer) provider API support.\nSpecifically: providers and provider_flavor_capabilities\n\nChange-Id: Ieb8e2d2fc592d69eca9c8cf36f726a35db1cda22\n'}]",2,634488,b27f0c579e53e81095c2b3fe353d047192afef89,15,3,2,11628,,,0,"Add Octavia (load_balancer) provider API support

This patch adds the Octavia (load_balancer) provider API support.
Specifically: providers and provider_flavor_capabilities

Change-Id: Ieb8e2d2fc592d69eca9c8cf36f726a35db1cda22
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/88/634488/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/functional/load_balancer/v2/test_load_balancer.py', 'openstack/tests/unit/load_balancer/test_provider.py', 'doc/source/user/resources/load_balancer/index.rst', 'openstack/load_balancer/v2/provider.py', 'openstack/load_balancer/v2/_proxy.py', 'doc/source/user/proxies/load_balancer_v2.rst', 'releasenotes/notes/add-load-balancer-provider-api-08bcfb72ddf5b247.yaml', 'doc/source/user/resources/load_balancer/v2/provider.rst']",8,75ccd90e2dac3e3d6b9b4c46664666744e242ab0,octavia-provider,openstack.load_balancer.v2.provider =================================== .. automodule:: openstack.load_balancer.v2.provider The Provider Class ------------------ The ``Provider`` class inherits from :class:`~openstack.resource.Resource`. .. autoclass:: openstack.load_balancer.v2.provider.Provider :members: The Provider Flavor Capabilities Class -------------------------------------- The ``ProviderFlavorCapabilities`` class inherits from :class:`~openstack.resource.Resource`. .. autoclass:: openstack.load_balancer.v2.provider.ProviderFlavorCapabilities :members: ,,194,0
openstack%2Fopenstacksdk~master~I7384351a5b59b2d68d6a45c543449815adfe52f2,openstack/openstacksdk,master,I7384351a5b59b2d68d6a45c543449815adfe52f2,Add Octavia (load_balancer) load balancer failover,MERGED,2019-01-30 16:46:44.000000000,2019-02-21 23:03:48.000000000,2019-02-21 23:03:47.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-01-30 16:46:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a609d8d0f21c446ddce2275a9e229b37412011b8', 'message': 'Add Octavia (load_balancer) load balancer failover\n\nThis patch adds a Octavia (load_balancer) load balancer failover method.\n\nChange-Id: I7384351a5b59b2d68d6a45c543449815adfe52f2\n'}, {'number': 2, 'created': '2019-01-30 17:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/cfc9165de8bb7162e080eb89b3eb2d0706385e6b', 'message': 'Add Octavia (load_balancer) load balancer failover\n\nThis patch adds a Octavia (load_balancer) load balancer failover method.\n\nChange-Id: I7384351a5b59b2d68d6a45c543449815adfe52f2\n'}, {'number': 3, 'created': '2019-01-30 17:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7b73fe240c75476b96a9d2b106dd38b29b55a3bf', 'message': 'Add Octavia (load_balancer) load balancer failover\n\nThis patch adds a Octavia (load_balancer) load balancer failover method.\n\nChange-Id: I7384351a5b59b2d68d6a45c543449815adfe52f2\n'}, {'number': 4, 'created': '2019-01-30 23:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/5d3e6572f365791adad6207e365c577fbde2973c', 'message': 'Add Octavia (load_balancer) load balancer failover\n\nThis patch adds a Octavia (load_balancer) load balancer failover method.\n\nChange-Id: I7384351a5b59b2d68d6a45c543449815adfe52f2\n'}, {'number': 5, 'created': '2019-02-01 17:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/fbfd702b55256a22fb053652cdaa61df0023508c', 'message': 'Add Octavia (load_balancer) load balancer failover\n\nThis patch adds a Octavia (load_balancer) load balancer failover method.\n\nChange-Id: I7384351a5b59b2d68d6a45c543449815adfe52f2\n'}, {'number': 6, 'created': '2019-02-01 18:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e1acde70d6b4bcecefc5799f72f9ff24a828c35d', 'message': 'Add Octavia (load_balancer) load balancer failover\n\nThis patch adds a Octavia (load_balancer) load balancer failover method.\n\nDepends-On: https://review.openstack.org/634344\nChange-Id: I7384351a5b59b2d68d6a45c543449815adfe52f2\n'}, {'number': 7, 'created': '2019-02-01 18:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/eaa14ee8428860120feb32fbc13bfbd195467942', 'message': 'Add Octavia (load_balancer) load balancer failover\n\nThis patch adds a Octavia (load_balancer) load balancer failover method.\n\nDepends-On: https://review.openstack.org/634344\nChange-Id: I7384351a5b59b2d68d6a45c543449815adfe52f2\n'}, {'number': 8, 'created': '2019-02-01 18:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/af5e1ecb6fd31daa14076f306c28164c6fa1782a', 'message': 'Add Octavia (load_balancer) load balancer failover\n\nThis patch adds a Octavia (load_balancer) load balancer failover method.\n\nIt also corrects the resource documentation for the Octavia stats resource\nclasses.\n\nDepends-On: https://review.openstack.org/634344\nChange-Id: I7384351a5b59b2d68d6a45c543449815adfe52f2\n'}, {'number': 9, 'created': '2019-02-01 20:16:52.000000000', 'files': ['openstack/tests/functional/load_balancer/v2/test_load_balancer.py', 'doc/source/user/resources/load_balancer/v2/listener.rst', 'doc/source/user/resources/load_balancer/v2/load_balancer.rst', 'openstack/load_balancer/v2/load_balancer.py', 'openstack/tests/unit/load_balancer/test_load_balancer.py', 'openstack/load_balancer/v2/_proxy.py', 'doc/source/user/proxies/load_balancer_v2.rst', 'releasenotes/notes/add-octavia-lb-failover-9a34c9577d78ad34.yaml', 'openstack/tests/unit/load_balancer/test_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/41d6d33339d430a5ed033837dd844a36d251129c', 'message': 'Add Octavia (load_balancer) load balancer failover\n\nThis patch adds a Octavia (load_balancer) load balancer failover method.\n\nIt also corrects the resource documentation for the Octavia stats resource\nclasses.\n\nDepends-On: https://review.openstack.org/634344\nChange-Id: I7384351a5b59b2d68d6a45c543449815adfe52f2\n'}]",7,634010,41d6d33339d430a5ed033837dd844a36d251129c,28,5,9,11628,,,0,"Add Octavia (load_balancer) load balancer failover

This patch adds a Octavia (load_balancer) load balancer failover method.

It also corrects the resource documentation for the Octavia stats resource
classes.

Depends-On: https://review.openstack.org/634344
Change-Id: I7384351a5b59b2d68d6a45c543449815adfe52f2
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/10/634010/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/functional/load_balancer/v2/test_load_balancer.py', 'openstack/load_balancer/v2/load_balancer.py', 'openstack/tests/unit/load_balancer/test_load_balancer.py', 'openstack/load_balancer/v2/_proxy.py', 'releasenotes/notes/add-octavia-lb-failover-9a34c9577d78ad34.yaml', 'openstack/tests/unit/load_balancer/test_proxy.py']",6,a609d8d0f21c446ddce2275a9e229b37412011b8,octavia-lb-failover," def test_load_balancer_failover(self): self.verify_update(self.proxy.failover_load_balancer, lb.LoadBalancerFailover) ",,47,0
openstack%2Fnetworking-ovn~stable%2Frocky~Ic04fcbe332adf030ab0ee3aad3a94ad874b18c9a,openstack/networking-ovn,stable/rocky,Ic04fcbe332adf030ab0ee3aad3a94ad874b18c9a,Clean MAC_Binding entries when (dis)associating a FIP,MERGED,2018-11-21 15:14:23.000000000,2019-02-21 23:00:34.000000000,2019-02-21 23:00:34.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2018-11-21 15:14:23.000000000', 'files': ['networking_ovn/tests/functional/test_ovsdb_monitor.py', 'networking_ovn/ml2/mech_driver.py', 'networking_ovn/ovsdb/ovsdb_monitor.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/2b9f2461a379fdb31c9326a30ff923d1f3e1d2e8', 'message': ""Clean MAC_Binding entries when (dis)associating a FIP\n\nWhen a FIP is assigned to a port, it may happen that it was\npreviously used by another FIP or gateway port and an entry\nin MAC_Binding table exits. If that's the case, the ARP\nresponder will answer with the wrong MAC address and the FIP\nwill then be unreachable.\n\nIn order to be on the safe side, this patch is deleting all\nMAC_Binding entries upon association or disassociation of a\nFIP as a workaround. The proper way to fix this should be\nmaking ovn-northd or ovn-controller clearing/updating the\nstale entries upon new NAT rules creation.\n\nDetails about the bug reported in OVS ML at [0].\n\n[0] https://mail.openvswitch.org/pipermail/ovs-discuss/2018-October/047604.html\n\nChange-Id: Ic04fcbe332adf030ab0ee3aad3a94ad874b18c9a\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n(cherry picked from commit 5181f1106ff839d08152623c25c9a5f6797aa2d7)\n""}]",0,619268,2b9f2461a379fdb31c9326a30ff923d1f3e1d2e8,49,6,1,23804,,,0,"Clean MAC_Binding entries when (dis)associating a FIP

When a FIP is assigned to a port, it may happen that it was
previously used by another FIP or gateway port and an entry
in MAC_Binding table exits. If that's the case, the ARP
responder will answer with the wrong MAC address and the FIP
will then be unreachable.

In order to be on the safe side, this patch is deleting all
MAC_Binding entries upon association or disassociation of a
FIP as a workaround. The proper way to fix this should be
making ovn-northd or ovn-controller clearing/updating the
stale entries upon new NAT rules creation.

Details about the bug reported in OVS ML at [0].

[0] https://mail.openvswitch.org/pipermail/ovs-discuss/2018-October/047604.html

Change-Id: Ic04fcbe332adf030ab0ee3aad3a94ad874b18c9a
Signed-off-by: Daniel Alvarez <dalvarez@redhat.com>
(cherry picked from commit 5181f1106ff839d08152623c25c9a5f6797aa2d7)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/68/619268/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/ml2/mech_driver.py', 'networking_ovn/tests/functional/test_ovsdb_monitor.py', 'networking_ovn/ovsdb/ovsdb_monitor.py']",3,2b9f2461a379fdb31c9326a30ff923d1f3e1d2e8,613584-stable/rocky,"class FIPAddDeleteEvent(row_event.RowEvent): """"""Row event - NAT 'dnat_and_snat' entry added or deleted This happens when a FIP is created or removed. """""" def __init__(self, driver): self.driver = driver table = 'NAT' events = (self.ROW_CREATE, self.ROW_DELETE) super(FIPAddDeleteEvent, self).__init__( events, table, (('type', '=', 'dnat_and_snat'),)) self.event_name = 'FIPAddDeleteEvent' def run(self, event, row, old): # When a FIP is added or deleted, we will delete all entries in the # MAC_Binding table of SB OVSDB corresponding to that IP Address. # TODO(dalvarez): Remove this workaround once fixed in core OVN: # https://mail.openvswitch.org/pipermail/ovs-discuss/2018-October/047604.html self.driver.delete_mac_binding_entries(row.external_ip) self._fip_create_delete_event = FIPAddDeleteEvent(driver) self._lsp_update_down_event, self._fip_create_delete_event]) helper.register_table('MAC_Binding')", self._lsp_update_down_event]),135,1
openstack%2Ftripleo-quickstart-extras~master~Id544c86273131c160a84e8f6bb8cdfef757d7da1,openstack/tripleo-quickstart-extras,master,Id544c86273131c160a84e8f6bb8cdfef757d7da1,standalone: enable debug on container image build,MERGED,2019-02-20 18:32:22.000000000,2019-02-21 22:51:34.000000000,2019-02-21 22:51:34.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-20 18:32:22.000000000', 'files': ['roles/standalone-upgrade/templates/standalone_config.yaml.j2', 'roles/standalone/templates/standalone_config.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/cb5269e42f8ecf9a1d0d08c0d8cb7bc214846952', 'message': 'standalone: enable debug on container image build\n\nVery useful to have the container image builds logs, as such as we\nenabled Debug by default.\n\nChange-Id: Id544c86273131c160a84e8f6bb8cdfef757d7da1\n'}]",0,638234,cb5269e42f8ecf9a1d0d08c0d8cb7bc214846952,13,6,1,3153,,,0,"standalone: enable debug on container image build

Very useful to have the container image builds logs, as such as we
enabled Debug by default.

Change-Id: Id544c86273131c160a84e8f6bb8cdfef757d7da1
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/34/638234/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/standalone-upgrade/templates/standalone_config.yaml.j2', 'roles/standalone/templates/standalone_config.yaml.j2']",2,cb5269e42f8ecf9a1d0d08c0d8cb7bc214846952,image/debug, ContainerImagePrepareDebug: true,,2,0
openstack%2Ftripleo-quickstart-extras~master~Iacb4dd3cd3229ff9d68749c01c8f89af3460d51d,openstack/tripleo-quickstart-extras,master,Iacb4dd3cd3229ff9d68749c01c8f89af3460d51d,ensure pip is updated in reproducer,MERGED,2019-02-19 21:35:16.000000000,2019-02-21 22:51:33.000000000,2019-02-21 22:51:32.000000000,"[{'_account_id': 8175}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-19 21:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f07d3f42b90098b1e52a6afbe7443d221d6ac988', 'message': 'ensure pip is updated in reproducer\n\nepel installs an older version of pip.\nThe older version of pip installs openstacksdk==.013\nhowever is unable to import the library.  The\nupdated version of pip resolves this issue.\n\nChange-Id: Iacb4dd3cd3229ff9d68749c01c8f89af3460d51d\n'}, {'number': 2, 'created': '2019-02-19 21:39:22.000000000', 'files': ['roles/create-zuul-based-reproducer/templates/reproducer-zuul-based-quickstart.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/2db357c5283ef9d2bd5e72fdc39357913f6d16d0', 'message': 'ensure pip is updated in reproducer\n\nepel installs an older version of pip.\nThe older version of pip installs openstacksdk==.013\nhowever is unable to import the library.  The\nupdated version of pip resolves this issue.\n\nChange-Id: Iacb4dd3cd3229ff9d68749c01c8f89af3460d51d\n'}]",0,638016,2db357c5283ef9d2bd5e72fdc39357913f6d16d0,23,6,2,9592,,,0,"ensure pip is updated in reproducer

epel installs an older version of pip.
The older version of pip installs openstacksdk==.013
however is unable to import the library.  The
updated version of pip resolves this issue.

Change-Id: Iacb4dd3cd3229ff9d68749c01c8f89af3460d51d
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/16/638016/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/create-zuul-based-reproducer/templates/reproducer-zuul-based-quickstart.sh.j2'],1,f07d3f42b90098b1e52a6afbe7443d221d6ac988,,# Ensure pip is updated pip install --upgrade pip,,2,0
openstack%2Fvitrage~master~I8a2186d5d6ca3789c87819a308039243f112d3fe,openstack/vitrage,master,I8a2186d5d6ca3789c87819a308039243f112d3fe,no need to create list,MERGED,2019-02-20 11:59:37.000000000,2019-02-21 22:49:21.000000000,2019-02-21 22:49:21.000000000,"[{'_account_id': 1736}, {'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 22348}, {'_account_id': 29383}]","[{'number': 1, 'created': '2019-02-20 11:59:37.000000000', 'files': ['vitrage/graph/driver/networkx_graph.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/c7860c06160a739df911c574da78fd173aaca5ac', 'message': 'no need to create list\n\nfilter can work both on iterable and sequence also for loop\ncopy is done during iteration so no need for list also\n\nChange-Id: I8a2186d5d6ca3789c87819a308039243f112d3fe\n'}]",0,638137,c7860c06160a739df911c574da78fd173aaca5ac,22,5,1,19134,,,0,"no need to create list

filter can work both on iterable and sequence also for loop
copy is done during iteration so no need for list also

Change-Id: I8a2186d5d6ca3789c87819a308039243f112d3fe
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/37/638137/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/graph/driver/networkx_graph.py'],1,c7860c06160a739df911c574da78fd173aaca5ac,eyalb/iter," items = filter(check_vertex, self._g.nodes(data=True)) for node, node_data in self._g.nodes(data=True):"," items = filter(check_vertex, list(self._g.nodes(data=True))) for node, node_data in list(self._g.nodes(data=True)):",2,2
openstack%2Ftripleo-ci~master~I2cb8aac75314d1babcec319836aa79313270b679,openstack/tripleo-ci,master,I2cb8aac75314d1babcec319836aa79313270b679,kolla-build: remove quotes in namespace config,MERGED,2019-02-21 13:26:44.000000000,2019-02-21 22:49:00.000000000,2019-02-21 22:49:00.000000000,"[{'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-21 13:26:44.000000000', 'files': ['playbooks/tripleo-buildcontainers/templates/kolla-build.conf.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/33f0539043437fa27919e0bb03034e1da35db4e0', 'message': ""kolla-build: remove quotes in namespace config\n\nWe don't want quotes in inifile.\n\nChange-Id: I2cb8aac75314d1babcec319836aa79313270b679\n""}]",0,638419,33f0539043437fa27919e0bb03034e1da35db4e0,8,4,1,3153,,,0,"kolla-build: remove quotes in namespace config

We don't want quotes in inifile.

Change-Id: I2cb8aac75314d1babcec319836aa79313270b679
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/19/638419/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/tripleo-buildcontainers/templates/kolla-build.conf.j2'],1,33f0539043437fa27919e0bb03034e1da35db4e0,namespace,"namespace=tripleomasternamespace={{ ci_branch | replace(""/"", """") }}","namespace='tripleomaster'namespace='{{ ci_branch | replace(""/"", """") }}'",2,2
openstack%2Ftripleo-quickstart-extras~master~Ieb99209e89e8b0c0cf26783cbf4e5fe72157600b,openstack/tripleo-quickstart-extras,master,Ieb99209e89e8b0c0cf26783cbf4e5fe72157600b,Re-enable neutron-tempest-plugin scenario tests,MERGED,2019-02-06 13:21:29.000000000,2019-02-21 22:48:59.000000000,2019-02-21 22:48:59.000000000,"[{'_account_id': 1131}, {'_account_id': 8367}, {'_account_id': 9592}, {'_account_id': 10022}, {'_account_id': 12393}, {'_account_id': 18846}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-06 13:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8f44d8ec0b8a10eb7a4fc7da8384c9dd0d2b1ff4', 'message': ""Re-enable neutron-tempest-plugin scenario tests\n\nThese tests should be stable by now, let's re-enable them.\n\nChange-Id: Ieb99209e89e8b0c0cf26783cbf4e5fe72157600b\nRelated-bug: #1737940\n""}, {'number': 2, 'created': '2019-02-11 16:26:55.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip_master.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/fe62dcc603e19c4776d86e803ab463ace371801c', 'message': ""Re-enable neutron-tempest-plugin scenario tests\n\nThese tests should be stable by now, let's re-enable them.\n\nChange-Id: Ieb99209e89e8b0c0cf26783cbf4e5fe72157600b\nRelated-bug: #1737940\n""}]",0,635152,fe62dcc603e19c4776d86e803ab463ace371801c,28,9,2,1131,,,0,"Re-enable neutron-tempest-plugin scenario tests

These tests should be stable by now, let's re-enable them.

Change-Id: Ieb99209e89e8b0c0cf26783cbf4e5fe72157600b
Related-bug: #1737940
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/52/635152/2 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip_master.yml'],1,8f44d8ec0b8a10eb7a4fc7da8384c9dd0d2b1ff4,bug/1737940,, - test: 'neutron_tempest_plugin.scenario' reason: 'Neutron Tempest plugin scenario tests are not yet stable.' lp: 'https://launchpad.net/bugs/1737940',0,3
openstack%2Ftripleo-quickstart-extras~master~I907c5a6a892596204c04c239886a6f83b19de18c,openstack/tripleo-quickstart-extras,master,I907c5a6a892596204c04c239886a6f83b19de18c,Run dstat prior deploying to standalone,MERGED,2019-02-20 13:56:21.000000000,2019-02-21 22:48:58.000000000,2019-02-21 22:48:58.000000000,"[{'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-20 13:56:21.000000000', 'files': ['roles/standalone/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c8c239157ebcf7a1f1a1045ec1d701992e1eb88b', 'message': 'Run dstat prior deploying to standalone\n\ndstat will help to find out the load and it will help to\nfigure out at what time the load is max in order to troubleshoot\ntimedout issue.\n\nChange-Id: I907c5a6a892596204c04c239886a6f83b19de18c\n'}]",0,638159,c8c239157ebcf7a1f1a1045ec1d701992e1eb88b,19,7,1,12393,,,0,"Run dstat prior deploying to standalone

dstat will help to find out the load and it will help to
figure out at what time the load is max in order to troubleshoot
timedout issue.

Change-Id: I907c5a6a892596204c04c239886a6f83b19de18c
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/59/638159/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/standalone/tasks/main.yml'],1,c8c239157ebcf7a1f1a1045ec1d701992e1eb88b,dstat,- name: Run dstat on the standalone prior to standalone deploy include_role: name: validate-perf ,,4,0
openstack%2Ftripleo-common~master~Ie0213819e97d5239978bcef5f06657804bc3ef3d,openstack/tripleo-common,master,Ie0213819e97d5239978bcef5f06657804bc3ef3d,kolla_builder: don't build template mapping when not needed,MERGED,2019-02-19 00:52:07.000000000,2019-02-21 22:48:57.000000000,2019-02-21 22:48:56.000000000,"[{'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-19 00:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ca48d0b2f0e39588874add280628d7c9998f6e44', 'message': ""kolla_builder: switch CONTAINER_IMAGES_DEFAULTS to {} by default\n\ncontainer_images_template_inputs static method requires\nCONTAINER_IMAGES_DEFAULTS to be a dictionnary so defining None by\ndefault can be problematic for unit tests.\nLet's just set an empty dictionnary {} by default.\n\nChange-Id: Ie0213819e97d5239978bcef5f06657804bc3ef3d\n""}, {'number': 2, 'created': '2019-02-20 17:11:34.000000000', 'files': ['tripleo_common/image/kolla_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b38b4184bad5b42e3392aef5e119e5e6bdbfb049', 'message': ""kolla_builder: don't build template mapping when not needed\n\nWhen CONTAINER_IMAGES_DEFAULTS is empty, we don't need to build\nthe template mapping.\n\nChange-Id: Ie0213819e97d5239978bcef5f06657804bc3ef3d\n""}]",1,637652,b38b4184bad5b42e3392aef5e119e5e6bdbfb049,20,5,2,3153,,,0,"kolla_builder: don't build template mapping when not needed

When CONTAINER_IMAGES_DEFAULTS is empty, we don't need to build
the template mapping.

Change-Id: Ie0213819e97d5239978bcef5f06657804bc3ef3d
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/52/637652/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/kolla_builder.py'],1,ca48d0b2f0e39588874add280628d7c9998f6e44,unit,CONTAINER_IMAGES_DEFAULTS = {},CONTAINER_IMAGES_DEFAULTS = None,1,1
openstack%2Ftripleo-common~master~Ida068cbbd57b5be5fad91c33a0fa51e422034835,openstack/tripleo-common,master,Ida068cbbd57b5be5fad91c33a0fa51e422034835,image_uploader: conditionally import docker,MERGED,2019-02-20 19:01:27.000000000,2019-02-21 22:48:55.000000000,2019-02-21 22:48:55.000000000,"[{'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-20 19:01:27.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/853b22d8dec74408397618532f3afc7209883794', 'message': ""image_uploader: conditionally import docker\n\nDocker is deprecated in Stein cycle, so we need to pass if Docker isn't\ninstalled. Also removing the load of old module if new one failed, it'\nsnot needed anymore.\n\nChange-Id: Ida068cbbd57b5be5fad91c33a0fa51e422034835\n""}]",0,638238,853b22d8dec74408397618532f3afc7209883794,10,5,1,3153,,,0,"image_uploader: conditionally import docker

Docker is deprecated in Stein cycle, so we need to pass if Docker isn't
installed. Also removing the load of old module if new one failed, it'
snot needed anymore.

Change-Id: Ida068cbbd57b5be5fad91c33a0fa51e422034835
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/38/638238/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,853b22d8dec74408397618532f3afc7209883794,docker,# Docker in TripleO is deprecated in Stein try: import docker pass ,import docker try: from docker import Client,4,2
openstack%2Ftripleo-quickstart~master~Ifbc5a232345448aa1cead2d42af95669b31c318b,openstack/tripleo-quickstart,master,Ifbc5a232345448aa1cead2d42af95669b31c318b,Fix freeipa role for quickstart,MERGED,2019-02-21 00:49:28.000000000,2019-02-21 22:30:47.000000000,2019-02-21 22:30:47.000000000,"[{'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-21 00:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/f9172e1f70f00752e5b27a6cb7672841449da506', 'message': 'WIP: fix freeipa role for quickstart\n\nChange-Id: Ifbc5a232345448aa1cead2d42af95669b31c318b\n'}, {'number': 2, 'created': '2019-02-21 10:36:24.000000000', 'files': ['roles/tripleo-inventory/templates/ssh_config.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/275361c63beb5fa210305ebc974c41b24ef0696d', 'message': 'Fix freeipa role for quickstart\n\nadding supplemental vm was broken by patches for OVB,\nthis patch fixes it\n\nChange-Id: Ifbc5a232345448aa1cead2d42af95669b31c318b\n'}]",0,638306,275361c63beb5fa210305ebc974c41b24ef0696d,13,5,2,10969,,,0,"Fix freeipa role for quickstart

adding supplemental vm was broken by patches for OVB,
this patch fixes it

Change-Id: Ifbc5a232345448aa1cead2d42af95669b31c318b
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/06/638306/2 && git format-patch -1 --stdout FETCH_HEAD,['roles/tripleo-inventory/templates/ssh_config.j2'],1,f9172e1f70f00752e5b27a6cb7672841449da506,fixipa,{% if deploy_supplemental_node|bool and (supplemental_node_ip_private is defined or supplemental_node_ip is defined) %} Hostname {{ supplemental_node_ip_private|default(supplemental_node_ip) }},{% if deploy_supplemental_node|bool and supplemental_node_ip_private is defined %} Hostname {{ supplemental_node_ip_private }},2,2
openstack%2Ftripleo-heat-templates~master~I4272797a40ee61842fe29b2e177d432c27fb47c3,openstack/tripleo-heat-templates,master,I4272797a40ee61842fe29b2e177d432c27fb47c3,Add specific upgrade hiera data file.,MERGED,2019-01-15 17:10:23.000000000,2019-02-21 22:30:45.000000000,2019-02-21 22:30:44.000000000,"[{'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 18575}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-15 17:10:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c0078882e95790362c04508b3b2e7da36725c6af', 'message': '[WIP] Hook in a place in hiera for upgrade to add varibles.\n\nDuring upgrade we need to provides hiera variable that will override\nthe cluster member definition.\n\nChange-Id: I4272797a40ee61842fe29b2e177d432c27fb47c3\nDepends-On: https://review.openstack.org/#/c/630956/\nImplements: blueprint upgrades-with-os\n'}, {'number': 2, 'created': '2019-01-17 12:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ca7256ac94e458e3a7d83654ff494ee2611d25ec', 'message': '[WIP] Hook in a place in hiera for upgrade to add varibles.\n\nDuring upgrade we need to provides hiera variable that will override\nthe cluster member definition.\n\nChange-Id: I4272797a40ee61842fe29b2e177d432c27fb47c3\nImplements: blueprint upgrades-with-os\n'}, {'number': 3, 'created': '2019-01-17 13:13:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e1175f9129a17eb7ca2b4fcbe21776b5ae292024', 'message': 'Hook in a place in hiera for upgrade to add varibles.\n\nDuring upgrade we need to provides hiera variable that will override\nthe cluster member definition.\n\nChange-Id: I4272797a40ee61842fe29b2e177d432c27fb47c3\nImplements: blueprint upgrades-with-os\n'}, {'number': 4, 'created': '2019-01-17 17:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/faef4a175bd818fd83cec8c98cce0b9fbbcdf25b', 'message': 'Hook in a place in hiera for upgrade to add varibles.\n\nDuring upgrade we need to provides hiera variable that will override\nthe cluster member definition.\n\nChange-Id: I4272797a40ee61842fe29b2e177d432c27fb47c3\nImplements: blueprint upgrades-with-os\n'}, {'number': 5, 'created': '2019-01-17 17:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0246b831b20f1c4882024184d197bd26463a6ae4', 'message': 'Hook in a place in hiera for upgrade to add varibles.\n\nDuring upgrade we need to provides hiera variable that will override\nthe cluster member definition.\n\nChange-Id: I4272797a40ee61842fe29b2e177d432c27fb47c3\nImplements: blueprint upgrades-with-os\n'}, {'number': 6, 'created': '2019-01-18 15:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bcfc8f68ac70fe67c81408236cfe4f6f6d87d2bf', 'message': 'Hook in a place in hiera for upgrade to add varibles.\n\nDuring upgrade we need to provides hiera variable that will override\nthe cluster member definition.\n\nChange-Id: I4272797a40ee61842fe29b2e177d432c27fb47c3\nImplements: blueprint upgrades-with-os\n'}, {'number': 7, 'created': '2019-01-22 13:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/af5caed24db64d6440dc8e424bb1ba39962bbcd9', 'message': 'Hook in a place in hiera for upgrade to add varibles.\n\nDuring upgrade we need to provides hiera variable that will override\nthe cluster member definition.\n\nChange-Id: I4272797a40ee61842fe29b2e177d432c27fb47c3\nImplements: blueprint upgrades-with-os\n'}, {'number': 8, 'created': '2019-02-18 09:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eef51141d716be63b3e48640c55c74db50ec53ce', 'message': 'Hook in a place in hiera for upgrade to add varibles.\n\nDuring upgrade we need to provides hiera variable that will override\nthe cluster member definition.\n\nChange-Id: I4272797a40ee61842fe29b2e177d432c27fb47c3\nImplements: blueprint upgrades-with-os\n'}, {'number': 9, 'created': '2019-02-18 09:37:42.000000000', 'files': ['releasenotes/notes/Add-upgrade-specific-hiera-file-7a41a23017a545b9.yaml', 'puppet/role.role.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b99c0ce8a7bd6d7ff3d18fdd81236e865097ebe7', 'message': 'Add specific upgrade hiera data file.\n\nDuring upgrade we need to provides hiera variable that will override\nthe cluster member definition.\n\nChange-Id: I4272797a40ee61842fe29b2e177d432c27fb47c3\nImplements: blueprint upgrades-with-os\n'}]",2,631025,b99c0ce8a7bd6d7ff3d18fdd81236e865097ebe7,31,6,9,8297,,,0,"Add specific upgrade hiera data file.

During upgrade we need to provides hiera variable that will override
the cluster member definition.

Change-Id: I4272797a40ee61842fe29b2e177d432c27fb47c3
Implements: blueprint upgrades-with-os
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/25/631025/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/role.role.j2.yaml'],1,c0078882e95790362c04508b3b2e7da36725c6af,bp/upgrades-with-os, # Special variable for upgrade - upgrade,,2,0
openstack%2Fpython-cinderclient~master~Ib4de058af6b636d06ac360fe448b432e8e7733ad,openstack/python-cinderclient,master,Ib4de058af6b636d06ac360fe448b432e8e7733ad,Fix bash_completion cache path,MERGED,2019-02-20 15:18:38.000000000,2019-02-21 22:17:53.000000000,2019-02-21 22:17:53.000000000,"[{'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-20 15:18:38.000000000', 'files': ['tools/cinder.bash_completion'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/7ee806f218cb22972a60d4e38ba1a4078e383f60', 'message': 'Fix bash_completion cache path\n\nIn change 4cf62cf3 we started writing the\ncache to ~/.cache/cinderclient/ - this script\nneeds to read from there.\n\nRelated-Bug: #1712835\n\nChange-Id: Ib4de058af6b636d06ac360fe448b432e8e7733ad\n'}]",0,638179,7ee806f218cb22972a60d4e38ba1a4078e383f60,7,3,1,4523,,,0,"Fix bash_completion cache path

In change 4cf62cf3 we started writing the
cache to ~/.cache/cinderclient/ - this script
needs to read from there.

Related-Bug: #1712835

Change-Id: Ib4de058af6b636d06ac360fe448b432e8e7733ad
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/79/638179/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/cinder.bash_completion'],1,7ee806f218cb22972a60d4e38ba1a4078e383f60,bug/1712835, COMPLETION_CACHE=~/.cache/cinderclient/*/*-cache, COMPLETION_CACHE=~/.cinderclient/*/*-cache,1,1
openstack%2Finstack-undercloud~stable%2Focata~Iae706a6995c1bd374aa9e5afc7c19edffb3e24d8,openstack/instack-undercloud,stable/ocata,Iae706a6995c1bd374aa9e5afc7c19edffb3e24d8,Install python-panko client,ABANDONED,2018-11-26 21:40:51.000000000,2019-02-21 22:12:52.000000000,,"[{'_account_id': 6924}, {'_account_id': 7144}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28504}]","[{'number': 1, 'created': '2018-11-26 21:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/786f917e16394f8f8868fa23c1d6f85638f2d6e3', 'message': 'Install python-panko client\n\nFix to install python-pankoclient on the\nUndercloud.\n\nChange-Id: Iae706a6995c1bd374aa9e5afc7c19edffb3e24d8\nCloses-Bug: #1805194\n'}, {'number': 2, 'created': '2019-01-25 19:13:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/0b44a9ad741403404989b9a6e3f337851c544c9d', 'message': 'Install python-panko client\n\nFix to install python-pankoclient on the\nUndercloud.\n\nChange-Id: Iae706a6995c1bd374aa9e5afc7c19edffb3e24d8\nCloses-Bug: #1805194\n'}, {'number': 3, 'created': '2019-02-21 18:09:44.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.pp'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/64333439e4889b7f222382f219e1ad264663bac6', 'message': 'Install python-panko client\n\nFix to install python-pankoclient on the\nUndercloud.\n\nChange-Id: Iae706a6995c1bd374aa9e5afc7c19edffb3e24d8\nCloses-Bug: #1805194\n'}]",0,620166,64333439e4889b7f222382f219e1ad264663bac6,29,7,3,28504,,,0,"Install python-panko client

Fix to install python-pankoclient on the
Undercloud.

Change-Id: Iae706a6995c1bd374aa9e5afc7c19edffb3e24d8
Closes-Bug: #1805194
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/66/620166/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.pp'],1,786f917e16394f8f8868fa23c1d6f85638f2d6e3,bug/1805194, include ::panko::client,,1,0
openstack%2Fqinling~master~Ic93b46c604891496155a1bd4b97cc050a1b0cbf0,openstack/qinling,master,Ic93b46c604891496155a1bd4b97cc050a1b0cbf0,add python 3.7 unit test job,MERGED,2019-02-18 07:08:31.000000000,2019-02-21 22:06:47.000000000,2019-02-21 22:06:47.000000000,"[{'_account_id': 6732}, {'_account_id': 9414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-18 07:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qinling/commit/3c7064ab74fdf191fbd6fd5b319952a61d97c6e8', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: Ic93b46c604891496155a1bd4b97cc050a1b0cbf0\n'}, {'number': 2, 'created': '2019-02-19 03:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qinling/commit/645b5c0f9bac22543df115c8cb5fbfd225f6de18', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: Ic93b46c604891496155a1bd4b97cc050a1b0cbf0\nStory: #2004073\nTask: #27444\n'}, {'number': 3, 'created': '2019-02-21 09:23:12.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/qinling/commit/756b3dfcde38f7394c36fb2c310874ac28320b07', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: Ic93b46c604891496155a1bd4b97cc050a1b0cbf0\nStory: #2004073\nTask: #27444\n'}]",0,637470,756b3dfcde38f7394c36fb2c310874ac28320b07,24,3,3,9414,,,0,"add python 3.7 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.7.

See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html

Change-Id: Ic93b46c604891496155a1bd4b97cc050a1b0cbf0
Story: #2004073
Task: #27444
",git fetch https://review.opendev.org/openstack/qinling refs/changes/70/637470/3 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,3c7064ab74fdf191fbd6fd5b319952a61d97c6e8,py37-job, - openstack-python37-jobs,,1,0
openstack%2Fopenstack-helm~master~Ib99a16b6252b15d9f138417485731ec401cb8f81,openstack/openstack-helm,master,Ib99a16b6252b15d9f138417485731ec401cb8f81,enable_proxy_headers_parsing to various services.,MERGED,2019-02-20 19:30:27.000000000,2019-02-21 22:06:34.000000000,2019-02-21 22:06:33.000000000,"[{'_account_id': 7769}, {'_account_id': 8863}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 22636}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-02-20 19:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/177a7313650fa2fe0585ec93dfa8a1d461286851', 'message': 'Heat: Add enable_proxy_headers_parsing to config file\n\nAdding this parameter will allow forwarding messages with htpps.\n\nChange-Id: Ib99a16b6252b15d9f138417485731ec401cb8f81\n'}, {'number': 2, 'created': '2019-02-20 19:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/035960128fe80dad13a9dad6fd79250dd6c10f9b', 'message': 'Heat: Add enable_proxy_headers_parsing to config file\n\nAdding this parameter allows proper handling to resource links in \nresponse using API services behind https proxy.\n\nChange-Id: Ib99a16b6252b15d9f138417485731ec401cb8f81\n'}, {'number': 3, 'created': '2019-02-20 19:52:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/4eceb16f892996e610dbc001d075bc03ab33045d', 'message': 'Heat: Add enable_proxy_headers_parsing to config file\n\nAdding this parameter allows processig and setting of the request \nenvironment correctly for any request behind a proxy which includes \nnot only the protocol but also the remote client address and http_host.\n\nChange-Id: Ib99a16b6252b15d9f138417485731ec401cb8f81\n'}, {'number': 4, 'created': '2019-02-20 22:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f9e3d50fac15815bb0377f9b54657f7c450d549d', 'message': 'enable_proxy_headers_parsing to various services.\n\nAdding this parameter to Nova, Cinder, Heat and Neutron config.\nAdding this parameter allows proper handling to resource links\nin response using API services behind https proxy.\n\nChange-Id: Ib99a16b6252b15d9f138417485731ec401cb8f81\n'}, {'number': 5, 'created': '2019-02-20 22:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6292690ceed9ba06fc98b7eb717f3b0fb6737840', 'message': 'enable_proxy_headers_parsing to various services.\n\nAdding this parameter to Nova, Cinder, Heat and Neutron config.\nAdding this parameter allows proper handling to resource links\nin response using API services behind https proxy.\n\nChange-Id: Ib99a16b6252b15d9f138417485731ec401cb8f81\n'}, {'number': 6, 'created': '2019-02-21 15:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/169c0f344f397e04c771687d8ac5626b99ac13a3', 'message': 'enable_proxy_headers_parsing to various services.\n\nAdding this parameter to Nova, Cinder, Heat, Glance,and Neutron\nconfig. Adding this parameter allows proper handling to resource\nlinks in response using API services behind https proxy.\n\nChange-Id: Ib99a16b6252b15d9f138417485731ec401cb8f81\n'}, {'number': 7, 'created': '2019-02-21 15:01:48.000000000', 'files': ['heat/values.yaml', 'cinder/values.yaml', 'neutron/values.yaml', 'glance/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/93658c75ece9704d835e4a6a0ba5be3ae435035b', 'message': 'enable_proxy_headers_parsing to various services.\n\nAdding this parameter to Cinder, Heat, Glance,and Neutron\nconfig. Adding this parameter allows proper handling to resource\nlinks in response using API services behind https proxy.\n\nChange-Id: Ib99a16b6252b15d9f138417485731ec401cb8f81\n'}]",4,638244,93658c75ece9704d835e4a6a0ba5be3ae435035b,32,6,7,24780,,,0,"enable_proxy_headers_parsing to various services.

Adding this parameter to Cinder, Heat, Glance,and Neutron
config. Adding this parameter allows proper handling to resource
links in response using API services behind https proxy.

Change-Id: Ib99a16b6252b15d9f138417485731ec401cb8f81
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/44/638244/7 && git format-patch -1 --stdout FETCH_HEAD,['heat/values.yaml'],1,177a7313650fa2fe0585ec93dfa8a1d461286851,, oslo_middleware: enable_proxy_headers_parsing: true,,2,0
openstack%2Fopenstack-manuals~master~I1f92c84c3faae6420adff2b267feaef54ddcc454,openstack/openstack-manuals,master,I1f92c84c3faae6420adff2b267feaef54ddcc454,Enable has_install_guide for the Placement project,MERGED,2019-01-04 02:21:57.000000000,2019-02-21 21:45:25.000000000,2019-02-21 21:45:25.000000000,"[{'_account_id': 6547}, {'_account_id': 7634}, {'_account_id': 10607}, {'_account_id': 11564}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 02:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1b7400510485f9ef8051768be11aaf704c6f8227', 'message': 'Enable has_install_guide for the Placement project\n\nThe index page of the install guide has been added\nin the Placement project\nsince I2f7bcd8efabc628bd27e3a9ce74e277a9e37fb69.\nSo enable the has_install_guide flag for the Placement project.\n\nDepends-On: https://review.openstack.org/628220/\nChange-Id: I1f92c84c3faae6420adff2b267feaef54ddcc454\n'}, {'number': 2, 'created': '2019-02-21 13:36:48.000000000', 'files': ['www/project-data/latest.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ab4b3f8b449c279b153c6121456b6bc83e776d99', 'message': 'Enable has_install_guide for the Placement project\n\nThe index page of the install guide has been added\nin the Placement project\nsince I2f7bcd8efabc628bd27e3a9ce74e277a9e37fb69.\nSo enable the has_install_guide flag for the Placement project.\n\nDepends-On: https://review.openstack.org/628220/\nChange-Id: I1f92c84c3faae6420adff2b267feaef54ddcc454\n'}]",0,628324,ab4b3f8b449c279b153c6121456b6bc83e776d99,17,5,2,7634,,,0,"Enable has_install_guide for the Placement project

The index page of the install guide has been added
in the Placement project
since I2f7bcd8efabc628bd27e3a9ce74e277a9e37fb69.
So enable the has_install_guide flag for the Placement project.

Depends-On: https://review.openstack.org/628220/
Change-Id: I1f92c84c3faae6420adff2b267feaef54ddcc454
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/24/628324/1 && git format-patch -1 --stdout FETCH_HEAD,['www/project-data/latest.yaml'],1,1b7400510485f9ef8051768be11aaf704c6f8227,update_placement, has_install_guide: true,# install/index.html does not exist currently. # Therefore disable has_install_guide for now. # has_install_guide: true,1,3
openstack%2Fnetworking-baremetal~stable%2Frocky~I7b3e0db64b7b7d3372e5ca24cea88b4b897651be,openstack/networking-baremetal,stable/rocky,I7b3e0db64b7b7d3372e5ca24cea88b4b897651be,Ensure notifications are consumed from non-pool queue,MERGED,2019-02-08 09:09:32.000000000,2019-02-21 21:02:03.000000000,2019-02-21 21:02:03.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-02-08 09:09:32.000000000', 'files': ['releasenotes/notes/fix-member-manager-notification-queue-not-consumed-449738d4fd799634.yaml', 'networking_baremetal/agent/ironic_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/13596556374cdcc1cd480f5e78a37ef6da7cb801', 'message': ""Ensure notifications are consumed from non-pool queue\n\nWhen using oslo.messaging notifications and all listeners\nare using a pool. The messages published to the default\nnotification queue is never consumed, only the pool queues\nare consumed. The queue that is not consumed keep growing\nand is using more and more RAM on the system where the\nmessage broker is running.\n\nAlso prefix the pool names so that it's easier for someone\nlooking at queues in the messaging backend to identify the\nsource.\n\nRelated-Bug: #1814544\nStory: 2004938\nTask: 29404\nChange-Id: I7b3e0db64b7b7d3372e5ca24cea88b4b897651be\n(cherry picked from commit 9da983270343bea89c18804767b1532c39c59622)\n""}]",0,635721,13596556374cdcc1cd480f5e78a37ef6da7cb801,22,4,1,24245,,,0,"Ensure notifications are consumed from non-pool queue

When using oslo.messaging notifications and all listeners
are using a pool. The messages published to the default
notification queue is never consumed, only the pool queues
are consumed. The queue that is not consumed keep growing
and is using more and more RAM on the system where the
message broker is running.

Also prefix the pool names so that it's easier for someone
looking at queues in the messaging backend to identify the
source.

Related-Bug: #1814544
Story: 2004938
Task: 29404
Change-Id: I7b3e0db64b7b7d3372e5ca24cea88b4b897651be
(cherry picked from commit 9da983270343bea89c18804767b1532c39c59622)
",git fetch https://review.opendev.org/openstack/networking-baremetal refs/changes/21/635721/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fix-member-manager-notification-queue-not-consumed-449738d4fd799634.yaml', 'networking_baremetal/agent/ironic_neutron_agent.py']",2,13596556374cdcc1cd480f5e78a37ef6da7cb801,story/2004938," # Note(hjensas): We need to have listener consuming the non-pool queue. # See bug: https://bugs.launchpad.net/oslo.messaging/+bug/1814544 self.listener = _set_up_listener(self.transport, None) self.pool_listener = _set_up_listener(self.transport, '-'.join( ['ironic-neutron-agent-heartbeat-pool', self.agent_id])) self.pool_listener.start()"," self.listener = _set_up_listener(self.transport, self.agent_id)",19,1
openstack%2Fneutron~master~I2045d7ff0a36a28311c09c667b2841487dd81d71,openstack/neutron,master,I2045d7ff0a36a28311c09c667b2841487dd81d71,Improve security group rule create performance,ABANDONED,2019-01-21 14:24:31.000000000,2019-02-21 20:54:01.000000000,,"[{'_account_id': 1131}, {'_account_id': 9373}, {'_account_id': 9531}, {'_account_id': 9845}, {'_account_id': 10061}, {'_account_id': 10267}, {'_account_id': 10385}, {'_account_id': 10980}, {'_account_id': 11816}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 16845}, {'_account_id': 22348}, {'_account_id': 24245}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2019-01-21 14:24:31.000000000', 'files': ['neutron/db/securitygroups_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/01a0b3db7aca239596cc01116bbd4e19838d24f9', 'message': 'Improve security group rule create performance\n\n[1] says serializing the method with lockutils improves the API\nperformance. When tried that on security group rule create, by creating\n300 security group rules asynchronously, max time taken for the API to\nfinish was 51 seconds[2] comapred to 390 seconds[3] taken for the API\nwithout this change. Also all the 300 calls were succesful with this\npatch, whereas some were failing with the existing code.\n\n[1] https://review.openstack.org/#/c/534449/\n[2] http://paste.openstack.org/show/743043/\n[3] http://paste.openstack.org/show/743042/\n\nChange-Id: I2045d7ff0a36a28311c09c667b2841487dd81d71\n'}]",2,632098,01a0b3db7aca239596cc01116bbd4e19838d24f9,22,18,1,10267,,,0,"Improve security group rule create performance

[1] says serializing the method with lockutils improves the API
performance. When tried that on security group rule create, by creating
300 security group rules asynchronously, max time taken for the API to
finish was 51 seconds[2] comapred to 390 seconds[3] taken for the API
without this change. Also all the 300 calls were succesful with this
patch, whereas some were failing with the existing code.

[1] https://review.openstack.org/#/c/534449/
[2] http://paste.openstack.org/show/743043/
[3] http://paste.openstack.org/show/743042/

Change-Id: I2045d7ff0a36a28311c09c667b2841487dd81d71
",git fetch https://review.opendev.org/openstack/neutron refs/changes/98/632098/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/securitygroups_db.py'],1,01a0b3db7aca239596cc01116bbd4e19838d24f9,,from oslo_concurrency import lockutils @lockutils.synchronized('create_security_group_rule_bulk') @lockutils.synchronized('create_security_group_rule_bulk_native') @lockutils.synchronized('create_security_group_rule'),,4,0
openstack%2Fneutron~master~I822656f305fa08c590e2bfbc377cd60d1820ca90,openstack/neutron,master,I822656f305fa08c590e2bfbc377cd60d1820ca90,Remove revises_on_change from SecurityGroupRule,ABANDONED,2019-01-22 14:42:46.000000000,2019-02-21 20:52:49.000000000,,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 8788}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 10267}, {'_account_id': 10385}, {'_account_id': 10980}, {'_account_id': 11816}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 20251}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 26622}, {'_account_id': 27419}]","[{'number': 1, 'created': '2019-01-22 14:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/44df8cdc1254b5e0daa3cd7c4947d047934b40d2', 'message': 'Remove revises_on_change from SecurityGroupRule\n\nBecause of this attribute, revision number in standardattribute table\nupdated for security group when trying to create security group rule.\nWhen many simultaneous requests issued to creatse security groups rule\nfor the same security group, this update is failing sometimes and\nthe transaction is retried. Because of this we are seeing increase in\nnumber of DB connections and API response taking huge time and some\ntimes even failing. After removing this, agents are still able to\nprocess and apply security group rules correctly.\n\nI have tested on devstack setup with defaults for DB max_pool_size and\nmax_overflow and with 6 neutron api_workers and 6 keystone workers.\nWhen I tried to create 300 security group rules for same security group,\nwithout this patch, mysqld connections went to 280 and was using above\n200 connections most of the time and max time taken for the API was\n300 seconds (many API calls were taking 300 seconds and some calls were\nfailing). With this patch, DB connections went to 200 but came back to\n70 soon and was remaining in 70s for the API calls. All calls were\nsuccesful and also max response time taken was 30 seconds.\n\nChange-Id: I822656f305fa08c590e2bfbc377cd60d1820ca90\n'}, {'number': 2, 'created': '2019-02-04 09:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/06d3da4eed975b3eaa3df51139e41938e80bc0d5', 'message': 'Remove revises_on_change from SecurityGroupRule\n\nBecause of this attribute, revision number in standardattribute table\nupdated for security group when trying to create security group rule.\nWhen many simultaneous requests issued to creatse security groups rule\nfor the same security group, this update is failing sometimes and\nthe transaction is retried. Because of this we are seeing increase in\nnumber of DB connections and API response taking huge time and some\ntimes even failing. After removing this, agents are still able to\nprocess and apply security group rules correctly.\n\nI have tested on devstack setup with defaults for DB max_pool_size and\nmax_overflow and with 6 neutron api_workers and 6 keystone workers.\nWhen I tried to create 300 security group rules for same security group,\nwithout this patch, mysqld connections went to 280 and was using above\n200 connections most of the time and max time taken for the API was\n300 seconds (many API calls were taking 300 seconds and some calls were\nfailing). With this patch, DB connections went to 200 but came back to\n70 soon and was remaining in 70s for the API calls. All calls were\nsuccesful and also max response time taken was 30 seconds.\n\nRemoving some tests which were added in below changes\nhttps://review.openstack.org/#/c/303966/\nhttps://review.openstack.org/#/c/409976/\n\nDepends-On: Ib0fe7d58f6ffc8e986da02aa1c4f2bf5b947ebda\nChange-Id: I822656f305fa08c590e2bfbc377cd60d1820ca90\n'}, {'number': 3, 'created': '2019-02-04 15:46:21.000000000', 'files': ['neutron/db/models/securitygroup.py', 'neutron/tests/unit/services/revisions/test_revision_plugin.py', 'neutron/tests/unit/db/test_standard_attr.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/176da1a8707d5d2df19143c336a43bd5cdc0b607', 'message': 'Remove revises_on_change from SecurityGroupRule\n\nBecause of this attribute, revision number in standardattribute table\nupdated for security group when trying to create security group rule.\nWhen many simultaneous requests issued to creatse security groups rule\nfor the same security group, this update is failing sometimes and\nthe transaction is retried. Because of this we are seeing increase in\nnumber of DB connections and API response taking huge time and some\ntimes even failing. After removing this, agents are still able to\nprocess and apply security group rules correctly.\n\nI have tested on devstack setup with defaults for DB max_pool_size and\nmax_overflow and with 6 neutron api_workers and 6 keystone workers.\nWhen I tried to create 300 security group rules for same security group,\nwithout this patch, mysqld connections went to 280 and was using above\n200 connections most of the time and max time taken for the API was\n300 seconds (many API calls were taking 300 seconds and some calls were\nfailing). With this patch, DB connections went to 200 but came back to\n70 soon and was remaining in 70s for the API calls. All calls were\nsuccesful and also max response time taken was 30 seconds.\n\nRemoving some tests which were added in below changes\nhttps://review.openstack.org/#/c/303966/\nhttps://review.openstack.org/#/c/409976/\n\nDepends-On: https://review.openstack.org/#/c/634632/\nChange-Id: I822656f305fa08c590e2bfbc377cd60d1820ca90\n'}]",2,632479,176da1a8707d5d2df19143c336a43bd5cdc0b607,47,18,3,10267,,,0,"Remove revises_on_change from SecurityGroupRule

Because of this attribute, revision number in standardattribute table
updated for security group when trying to create security group rule.
When many simultaneous requests issued to creatse security groups rule
for the same security group, this update is failing sometimes and
the transaction is retried. Because of this we are seeing increase in
number of DB connections and API response taking huge time and some
times even failing. After removing this, agents are still able to
process and apply security group rules correctly.

I have tested on devstack setup with defaults for DB max_pool_size and
max_overflow and with 6 neutron api_workers and 6 keystone workers.
When I tried to create 300 security group rules for same security group,
without this patch, mysqld connections went to 280 and was using above
200 connections most of the time and max time taken for the API was
300 seconds (many API calls were taking 300 seconds and some calls were
failing). With this patch, DB connections went to 200 but came back to
70 soon and was remaining in 70s for the API calls. All calls were
succesful and also max response time taken was 30 seconds.

Removing some tests which were added in below changes
https://review.openstack.org/#/c/303966/
https://review.openstack.org/#/c/409976/

Depends-On: https://review.openstack.org/#/c/634632/
Change-Id: I822656f305fa08c590e2bfbc377cd60d1820ca90
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/632479/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/models/securitygroup.py'],1,44df8cdc1254b5e0daa3cd7c4947d047934b40d2,revises_on_change,," revises_on_change = ('security_group', )",0,1
openstack%2Fnova~stable%2Frocky~I779a17afade78997ab084909a9e6a46b0f91f055,openstack/nova,stable/rocky,I779a17afade78997ab084909a9e6a46b0f91f055,tox: Don't write byte code (maybe),MERGED,2019-02-14 10:40:26.000000000,2019-02-21 20:52:35.000000000,2019-02-21 20:52:35.000000000,"[{'_account_id': 6873}, {'_account_id': 10135}, {'_account_id': 14070}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-14 10:40:26.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/99f0c4c0144a551f0fa7f3a8847327660e5ccb89', 'message': ""tox: Don't write byte code (maybe)\n\nIn tox versions after 3.0.0rc1 [1], setting the environment variable\nPYTHONDONTWRITEBYTECODE will cause tox not to write .pyc files, which\nmeans you don't have to delete them, which makes things faster.\n\nIn older tox versions, the env var is ignored.\n\nIf we bump the minimum tox version to something later than 3.0.0rc1, we\ncan remove the commands that find and remove .pyc files.\n\n[1] https://github.com/tox-dev/tox/commit/336f4f6bd8b53223f940fc5cfc43b1bbd78d4699\n\nChange-Id: I779a17afade78997ab084909a9e6a46b0f91f055\n(cherry picked from commit 590a2b6bbf71294d187d7082cc302069797db029)\n""}]",0,636917,99f0c4c0144a551f0fa7f3a8847327660e5ccb89,10,6,1,15334,,,0,"tox: Don't write byte code (maybe)

In tox versions after 3.0.0rc1 [1], setting the environment variable
PYTHONDONTWRITEBYTECODE will cause tox not to write .pyc files, which
means you don't have to delete them, which makes things faster.

In older tox versions, the env var is ignored.

If we bump the minimum tox version to something later than 3.0.0rc1, we
can remove the commands that find and remove .pyc files.

[1] https://github.com/tox-dev/tox/commit/336f4f6bd8b53223f940fc5cfc43b1bbd78d4699

Change-Id: I779a17afade78997ab084909a9e6a46b0f91f055
(cherry picked from commit 590a2b6bbf71294d187d7082cc302069797db029)
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/636917/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,99f0c4c0144a551f0fa7f3a8847327660e5ccb89,PYTHONDONTWRITEBYTECODE, # NOTE(efried): This is only effective in tox versions after 3.0.0rc1 # https://github.com/tox-dev/tox/commit/336f4f6bd8b53223f940fc5cfc43b1bbd78d4699 PYTHONDONTWRITEBYTECODE=1,,3,0
openstack%2Fnova~stable%2Fqueens~Ibbdcec1c9c5b897eb6dab993ece0535f307025ab,openstack/nova,stable/queens,Ibbdcec1c9c5b897eb6dab993ece0535f307025ab,Fix a missing policy in test policy data,MERGED,2019-02-15 02:07:35.000000000,2019-02-21 20:52:28.000000000,2019-02-21 20:52:28.000000000,"[{'_account_id': 6873}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-15 02:07:35.000000000', 'files': ['nova/tests/unit/fake_policy.py', 'nova/tests/unit/api/openstack/compute/test_flavor_manage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b176013b7b18194c9dc7869fe30da0bedf2ea5d6', 'message': ""Fix a missing policy in test policy data\n\nAdd the 'os_compute_api:os-flavor-manage:update'\nin the test policy data in nova/tests/unit/fake_policy.py.\nIt should have been added in\nIb16b0de82f9f9492f5cacf646dc3165a0849d75e.\n\nTrivialFix\nChange-Id: Ibbdcec1c9c5b897eb6dab993ece0535f307025ab\n(cherry picked from commit 72028ff8b9aaac5dcabbca9e2897f45ce0d94b62)\n(cherry picked from commit a4017aaa53815989f45c8f3df1d20fb2c471b14d)\n""}]",0,637112,b176013b7b18194c9dc7869fe30da0bedf2ea5d6,9,4,1,7634,,,0,"Fix a missing policy in test policy data

Add the 'os_compute_api:os-flavor-manage:update'
in the test policy data in nova/tests/unit/fake_policy.py.
It should have been added in
Ib16b0de82f9f9492f5cacf646dc3165a0849d75e.

TrivialFix
Change-Id: Ibbdcec1c9c5b897eb6dab993ece0535f307025ab
(cherry picked from commit 72028ff8b9aaac5dcabbca9e2897f45ce0d94b62)
(cherry picked from commit a4017aaa53815989f45c8f3df1d20fb2c471b14d)
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/637112/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/fake_policy.py', 'nova/tests/unit/api/openstack/compute/test_flavor_manage.py']",2,b176013b7b18194c9dc7869fe30da0bedf2ea5d6,fix_missing_policy," """"""Tests that trying to update a flavor as a non-admin fails. rule_name = ""os_compute_api:os-flavor-manage:update"" self.policy.set_rules({rule_name: ""is_admin:True""})"," """"""Tests that trying to update a flavor as a non-admin fails due to the default policy.",4,2
openstack%2Fopenstacksdk~master~I1ab56bff65b28ad0b441b598f2c15e97d87df6d7,openstack/openstacksdk,master,I1ab56bff65b28ad0b441b598f2c15e97d87df6d7,Add image attributes from v2.7,MERGED,2019-02-18 13:00:27.000000000,2019-02-21 20:50:20.000000000,2019-02-21 20:50:20.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-02-18 13:00:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8957d58184accf3b16dbc8eb56fcb1e2aa135171', 'message': 'Add image attributes from v2.7\n\nAdd new image attributes added with APIv2.7:\n- os_hidden (hide from list)\n- os_hash_algo\n- os_hash_value\n\nChange-Id: I1ab56bff65b28ad0b441b598f2c15e97d87df6d7\n'}, {'number': 2, 'created': '2019-02-19 12:20:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/1ac69e0075fa55c6910fc3ff9fafcd5eb2a70748', 'message': 'Add image attributes from v2.7\n\nAdd new image attributes added with APIv2.7:\n- os_hidden (hide from list)\n- os_hash_algo\n- os_hash_value\n\nChange-Id: I1ab56bff65b28ad0b441b598f2c15e97d87df6d7\n'}, {'number': 3, 'created': '2019-02-19 13:59:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0b14f4b0b129ce57bf7c5edf6d50280524e2ed1f', 'message': 'Add image attributes from v2.7\n\nAdd new image attributes added with APIv2.7:\n- os_hidden (hide from list)\n- os_hash_algo\n- os_hash_value\n\nChange-Id: I1ab56bff65b28ad0b441b598f2c15e97d87df6d7\n'}, {'number': 4, 'created': '2019-02-19 18:49:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/981bad1702228805061171ef07faedae4415f6e6', 'message': 'Add image attributes from v2.7\n\nAdd new image attributes added with APIv2.7:\n- os_hidden (hide from list)\n- os_hash_algo\n- os_hash_value\n\nChange-Id: I1ab56bff65b28ad0b441b598f2c15e97d87df6d7\n'}, {'number': 5, 'created': '2019-02-19 20:20:25.000000000', 'files': ['openstack/image/v2/image.py', 'openstack/tests/unit/image/v2/test_image.py', 'releasenotes/notes/add-image-attributes-05b820a85cd09806.yaml'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/11a5952933119e9878875b0e9c9395ae29c511af', 'message': 'Add image attributes from v2.7\n\nAdd new image attributes added with APIv2.7:\n- os_hidden (hide from list)\n- os_hash_algo\n- os_hash_value\n\nChange-Id: I1ab56bff65b28ad0b441b598f2c15e97d87df6d7\n'}]",8,637538,11a5952933119e9878875b0e9c9395ae29c511af,19,4,5,27900,,,0,"Add image attributes from v2.7

Add new image attributes added with APIv2.7:
- os_hidden (hide from list)
- os_hash_algo
- os_hash_value

Change-Id: I1ab56bff65b28ad0b441b598f2c15e97d87df6d7
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/38/637538/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/image/v2/image.py', 'openstack/tests/unit/image/v2/test_image.py', 'releasenotes/notes/add-image-attributes-05b820a85cd09806.yaml']",3,8957d58184accf3b16dbc8eb56fcb1e2aa135171,637538,"--- features: - Add image attributes os_hidden, os_hash_algo, os_hash_value ",,42,3
openstack%2Fmanila~master~I5b77911353436a9b2ffd7464c663e6992da692ab,openstack/manila,master,I5b77911353436a9b2ffd7464c663e6992da692ab,[CI] Always use tls-proxy on tempest jobs,ABANDONED,2019-02-21 04:53:40.000000000,2019-02-21 20:47:45.000000000,,"[{'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-02-21 04:53:40.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/2734bb07f7b633c75031c531c472a4b878c3c2fc', 'message': '[CI] Always use tls-proxy on tempest jobs\n\nThis is already the default in the base zuul\njobs that are being used everywhere.\n\nChange-Id: I5b77911353436a9b2ffd7464c663e6992da692ab\nRelated-Bug: #1816836\n'}]",0,638335,2734bb07f7b633c75031c531c472a4b878c3c2fc,8,6,1,16643,,,0,"[CI] Always use tls-proxy on tempest jobs

This is already the default in the base zuul
jobs that are being used everywhere.

Change-Id: I5b77911353436a9b2ffd7464c663e6992da692ab
Related-Bug: #1816836
",git fetch https://review.opendev.org/openstack/manila refs/changes/35/638335/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,2734bb07f7b633c75031c531c472a4b878c3c2fc,bug/1816836, vars: devstack_localrc: tls-proxy: true,,3,0
openstack%2Fcharm-deployment-guide~master~I796424a9dbde6c6cb4610825ca3d14582517e115,openstack/charm-deployment-guide,master,I796424a9dbde6c6cb4610825ca3d14582517e115,A small change to README,ABANDONED,2019-02-19 08:53:48.000000000,2019-02-21 20:29:48.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-19 08:53:48.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/e55d204c85551f1f91416d42f55f2edd34e29009', 'message': 'A small change to README\n\nChange-Id: I796424a9dbde6c6cb4610825ca3d14582517e115\n'}]",0,637733,e55d204c85551f1f91416d42f55f2edd34e29009,4,1,1,29889,,,0,"A small change to README

Change-Id: I796424a9dbde6c6cb4610825ca3d14582517e115
",git fetch https://review.opendev.org/openstack/charm-deployment-guide refs/changes/33/637733/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,e55d204c85551f1f91416d42f55f2edd34e29009,change-readme,on how to submit changes!,on how to submit changes.,1,1
openstack%2Fpython-tripleoclient~master~Ic39e665b241aed74347be5eaf24fb291035d5658,openstack/python-tripleoclient,master,Ic39e665b241aed74347be5eaf24fb291035d5658,Deprecate docker config options,MERGED,2019-02-20 19:18:02.000000000,2019-02-21 20:29:16.000000000,2019-02-21 20:29:16.000000000,"[{'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 11082}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-20 19:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/5858b5ff5c605f046655adfeaf1b01cc3de563c0', 'message': 'Deprecate docker config options\n\nThe docker_bip, docker_insecure_registries and docker_registry_mirrors\nhave been deprecated. docker_bip will be removed in later versions.\ndocker_insecure_registries has been renamed to\ncontainer_insecure_regiestries. docker_registry_mirrors has been renamed\nto container_registry_mirrors.\n\nChange-Id: Ic39e665b241aed74347be5eaf24fb291035d5658\nRelated-Blueprint: podman-support\n'}, {'number': 2, 'created': '2019-02-20 19:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/dc7514b46a0da09014d9f8849317c6adec3d28a0', 'message': 'Deprecate docker config options\n\nThe docker_bip, docker_insecure_registries and docker_registry_mirror\nhave been deprecated. docker_bip will be removed in later versions.\ndocker_insecure_registries has been renamed to\ncontainer_insecure_regiestries. docker_registry_mirror has been renamed\nto container_registry_mirror.\n\nChange-Id: Ic39e665b241aed74347be5eaf24fb291035d5658\nRelated-Blueprint: podman-support\n'}, {'number': 3, 'created': '2019-02-20 19:20:17.000000000', 'files': ['releasenotes/notes/deprecate-docker-config-options-ebf403648b096929.yaml', 'tripleoclient/config/undercloud.py', 'tripleoclient/config/standalone.py', 'tripleoclient/v1/undercloud_config.py', 'tripleoclient/tests/config/test_config_standalone.py', 'tripleoclient/tests/config/test_config_undercloud.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/96c9a5e7b81c7478b2787292f631f28aab851ddd', 'message': 'Deprecate docker config options\n\nThe docker_bip, docker_insecure_registries and docker_registry_mirror\nhave been deprecated. docker_bip will be removed in later versions.\ndocker_insecure_registries has been renamed to\ncontainer_insecure_regiestries. docker_registry_mirror has been renamed\nto container_registry_mirror.\n\nChange-Id: Ic39e665b241aed74347be5eaf24fb291035d5658\nRelated-Blueprint: podman-support\n'}]",0,638243,96c9a5e7b81c7478b2787292f631f28aab851ddd,15,5,3,14985,,,0,"Deprecate docker config options

The docker_bip, docker_insecure_registries and docker_registry_mirror
have been deprecated. docker_bip will be removed in later versions.
docker_insecure_registries has been renamed to
container_insecure_regiestries. docker_registry_mirror has been renamed
to container_registry_mirror.

Change-Id: Ic39e665b241aed74347be5eaf24fb291035d5658
Related-Blueprint: podman-support
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/43/638243/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/deprecate-docker-config-options-ebf403648b096929.yaml', 'tripleoclient/config/undercloud.py', 'tripleoclient/config/standalone.py', 'tripleoclient/v1/undercloud_config.py', 'tripleoclient/tests/config/test_config_standalone.py', 'tripleoclient/tests/config/test_config_undercloud.py']",6,5858b5ff5c605f046655adfeaf1b01cc3de563c0,bp/podman-support," 'container_insecure_registries', 'container_registry_mirror', 'container_insecure_registries', 'container_registry_mirror',"," 'docker_insecure_registries', 'docker_registry_mirror', 'docker_insecure_registries', 'docker_registry_mirror',",31,17
openstack%2Fsenlin~master~I04d57f4deb2f9f46aba1d9d4a566cb90dbe74d96,openstack/senlin,master,I04d57f4deb2f9f46aba1d9d4a566cb90dbe74d96,Fix node delete with lifecycle hook bug,MERGED,2019-02-19 22:47:21.000000000,2019-02-21 20:28:07.000000000,2019-02-21 20:28:07.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 25674}, {'_account_id': 27224}]","[{'number': 1, 'created': '2019-02-19 22:47:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/d645d73733e4976e2062186a77c9a5c284ba256b', 'message': 'Fix node delete with lifecycle hook bug\n\nCreate copy of child node list and remove nodes from the original child\nlist if a node does not need to enter waiting lifecycle completion\nbecause it is not found or not in ACTIVE state.\n\nChange-Id: I04d57f4deb2f9f46aba1d9d4a566cb90dbe74d96\nCloses-Bug: #1816677\n'}, {'number': 2, 'created': '2019-02-20 00:35:31.000000000', 'files': ['senlin/engine/actions/cluster_action.py', 'senlin/tests/unit/engine/actions/test_delete.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/3e70333a65dd168c2c4a4d8839d2980e54152697', 'message': 'Fix node delete with lifecycle hook bug\n\nCreate copy of child node list and remove nodes from the original child\nlist if a node does not need to enter waiting lifecycle completion\nbecause it is not found or not in ACTIVE state.\n\nChange-Id: I04d57f4deb2f9f46aba1d9d4a566cb90dbe74d96\nCloses-Bug: #1816677\n'}]",2,638035,3e70333a65dd168c2c4a4d8839d2980e54152697,11,4,2,27224,,,0,"Fix node delete with lifecycle hook bug

Create copy of child node list and remove nodes from the original child
list if a node does not need to enter waiting lifecycle completion
because it is not found or not in ACTIVE state.

Change-Id: I04d57f4deb2f9f46aba1d9d4a566cb90dbe74d96
Closes-Bug: #1816677
",git fetch https://review.opendev.org/openstack/senlin refs/changes/35/638035/2 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/actions/cluster_action.py', 'senlin/tests/unit/engine/actions/test_delete.py']",2,d645d73733e4976e2062186a77c9a5c284ba256b,bug/1816677," node2 = mock.Mock(status=consts.NS_ACTIVE, id='NODE_2', physical_id=""nova-server-1"") mock.call(action.context, 'NODE_ACTION_1', {'status': 'READY', 'owner': None}), mock.call(action.context, 'NODE_ACTION_2', 'owner': 'OWNER_ID'}) mock_post.assert_called_once_with('NODE_ACTION_2', 'NODE_2', node2.physical_id,"," physical_id=""nova-server-1"") node2 = mock.Mock(status=consts.NS_ACTIVE, id='NODE_2', mock.call(action.context, 'NODE_ACTION_1', 'owner': 'OWNER_ID'}), mock.call(action.context, 'NODE_ACTION_2', {'status': 'READY', 'owner': None}) mock_post.assert_called_once_with('NODE_ACTION_1', 'NODE_1', node1.physical_id,",9,9
openstack%2Ftripleo-heat-templates~master~I415608afde402744ee3b32176368ef16e70191e8,openstack/tripleo-heat-templates,master,I415608afde402744ee3b32176368ef16e70191e8,DNM: Testing a tripleo-common fix,ABANDONED,2019-02-01 15:47:52.000000000,2019-02-21 20:03:35.000000000,,"[{'_account_id': 6681}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-01 15:47:52.000000000', 'files': ['docker/services/octavia-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/56646b9e5cac88206e90f94290d9bcd03259e855', 'message': 'DNM: Testing a tripleo-common fix\n\nDepends-On: I3cb1918d94ab56fc96663ae3db6015bcd5c9c547\nChange-Id: I415608afde402744ee3b32176368ef16e70191e8\n'}]",0,634440,56646b9e5cac88206e90f94290d9bcd03259e855,4,2,1,6681,,,0,"DNM: Testing a tripleo-common fix

Depends-On: I3cb1918d94ab56fc96663ae3db6015bcd5c9c547
Change-Id: I415608afde402744ee3b32176368ef16e70191e8
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/40/634440/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/octavia-api.yaml'],1,56646b9e5cac88206e90f94290d9bcd03259e855,," Dummy: type: string default: ""do not merge""",,3,0
openstack%2Ftripleo-common~master~I410f8fa38bdd380cfa174f9c210a3f221ab3e804,openstack/tripleo-common,master,I410f8fa38bdd380cfa174f9c210a3f221ab3e804,WIP: move amphora glance image upload to an overcloud node,ABANDONED,2018-10-17 14:47:30.000000000,2019-02-21 20:03:22.000000000,,"[{'_account_id': 6469}, {'_account_id': 6681}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-10-17 14:47:30.000000000', 'files': ['playbooks/roles/octavia-overcloud-config/tasks/main.yml', 'playbooks/roles/octavia-undercloud/tasks/main.yml', 'playbooks/roles/octavia-overcloud-config/tasks/image_mgmt.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/289639f2d45c1217ef55f36cbddc57a81c5bf3f3', 'message': 'WIP: move amphora glance image upload to an overcloud node\n\nSince moving to containerized undercloud, the deployment does not work\nwith RPM based amphora installs since mistral is in a container. This\npatch moves the amphora image management from running on the undercloud\nnode to running on the overcloud.\n\n(needs bug report)\n\nChange-Id: I410f8fa38bdd380cfa174f9c210a3f221ab3e804\n'}]",0,611342,289639f2d45c1217ef55f36cbddc57a81c5bf3f3,5,4,1,6681,,,0,"WIP: move amphora glance image upload to an overcloud node

Since moving to containerized undercloud, the deployment does not work
with RPM based amphora installs since mistral is in a container. This
patch moves the amphora image management from running on the undercloud
node to running on the overcloud.

(needs bug report)

Change-Id: I410f8fa38bdd380cfa174f9c210a3f221ab3e804
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/42/611342/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/octavia-overcloud-config/tasks/main.yml', 'playbooks/roles/octavia-undercloud/tasks/main.yml', 'playbooks/roles/octavia-overcloud-config/tasks/image_mgmt.yml']",3,289639f2d45c1217ef55f36cbddc57a81c5bf3f3,,,,31,31
openstack%2Fpython-cinderclient~master~I2944ce54a304cb91f456c6c53daf2f083017c929,openstack/python-cinderclient,master,I2944ce54a304cb91f456c6c53daf2f083017c929,Add dependency on requests lib,MERGED,2019-02-07 15:56:49.000000000,2019-02-21 20:01:36.000000000,2019-02-21 20:01:36.000000000,"[{'_account_id': 4523}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2019-02-07 15:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/4ef6b203764f595c8e21f9025eeb8cb651cd79d4', 'message': 'Add dependency on requests lib\n\ncinderclient uses the requests library.\n\nChange-Id: I2944ce54a304cb91f456c6c53daf2f083017c929\n'}, {'number': 2, 'created': '2019-02-13 14:58:05.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/a952c550b3d2b89cb4107e71842133a9a5574aeb', 'message': 'Add dependency on requests lib\n\ncinderclient uses the requests library.\n\nChange-Id: I2944ce54a304cb91f456c6c53daf2f083017c929\n'}]",3,635549,a952c550b3d2b89cb4107e71842133a9a5574aeb,19,4,2,4523,,,0,"Add dependency on requests lib

cinderclient uses the requests library.

Change-Id: I2944ce54a304cb91f456c6c53daf2f083017c929
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/49/635549/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4ef6b203764f595c8e21f9025eeb8cb651cd79d4,,requests!=2.20.0 # Apache-2.0,,1,0
openstack%2Fopenstack-ansible-os_tempest~master~I2ab1757e07ffc607d15b15e30a5ecbc4c1ac37c7,openstack/openstack-ansible-os_tempest,master,I2ab1757e07ffc607d15b15e30a5ecbc4c1ac37c7,Fix redhat iputtils,MERGED,2019-02-21 15:46:22.000000000,2019-02-21 19:28:15.000000000,2019-02-21 19:28:15.000000000,"[{'_account_id': 7353}, {'_account_id': 15993}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 15:46:22.000000000', 'files': ['vars/redhat-7.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/09028aae5e8edd089ed883cf8a12106cb5e90cc0', 'message': 'Fix redhat iputtils\n\niputils was put in the wrong location.\n\nChange-Id: I2ab1757e07ffc607d15b15e30a5ecbc4c1ac37c7\n'}]",0,638444,09028aae5e8edd089ed883cf8a12106cb5e90cc0,7,3,1,21314,,,0,"Fix redhat iputtils

iputils was put in the wrong location.

Change-Id: I2ab1757e07ffc607d15b15e30a5ecbc4c1ac37c7
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/44/638444/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/redhat-7.yml'],1,09028aae5e8edd089ed883cf8a12106cb5e90cc0,fix-redhat-iputils, - iputils, - iputils,1,1
openstack%2Fmonasca-api~master~I134a55610abe0cabc31881cee7c22b705d9e40ff,openstack/monasca-api,master,I134a55610abe0cabc31881cee7c22b705d9e40ff,Update default docker monasca-api conf,MERGED,2019-02-20 12:42:50.000000000,2019-02-21 19:25:57.000000000,2019-02-21 19:25:57.000000000,"[{'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2019-02-20 12:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/9e3fdd4d0bf19b33da61043859c6e066ead70a77', 'message': 'Update default docker monasca-api conf\n\nSynchronise with default output from tox genconfig.\n\nChange-Id: I134a55610abe0cabc31881cee7c22b705d9e40ff\n'}, {'number': 2, 'created': '2019-02-20 13:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/e8734e9fa3133f77c0561f572c0cd8302e5cc53d', 'message': 'Update default docker monasca-api conf\n\nSynchronise with default output from tox genconfig.\n\nChange-Id: I134a55610abe0cabc31881cee7c22b705d9e40ff\n'}, {'number': 3, 'created': '2019-02-20 14:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/51f73ea39d0e02900675f2c7537adea02ff841f0', 'message': 'Update default docker monasca-api conf\n\nSynchronise with default output from tox genconfig. Bring improvements\nfrom monasca/monasca-docker repository.\n\nChange-Id: I134a55610abe0cabc31881cee7c22b705d9e40ff\n'}, {'number': 4, 'created': '2019-02-21 08:47:05.000000000', 'files': ['docker/Dockerfile', 'docker/README.rst', 'docker/monasca-api.conf.j2'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/189056a5016a6fc2c4578947966db0887715a9ad', 'message': 'Update default docker monasca-api conf\n\nSynchronise with default output from tox genconfig. Bring improvements\nfrom monasca/monasca-docker repository.\n\nChange-Id: I134a55610abe0cabc31881cee7c22b705d9e40ff\n'}]",0,638139,189056a5016a6fc2c4578947966db0887715a9ad,11,2,4,21922,,,0,"Update default docker monasca-api conf

Synchronise with default output from tox genconfig. Bring improvements
from monasca/monasca-docker repository.

Change-Id: I134a55610abe0cabc31881cee7c22b705d9e40ff
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/39/638139/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/monasca-api.conf.j2'],1,9e3fdd4d0bf19b33da61043859c6e066ead70a77,docker,"# # This option has a sample default set, which means that # its actual default value may vary from the one documented # below. #region = RegionOne# Log output to Windows Event Log (boolean value) #use_eventlog = false # The amount of time before the log files are rotated. This option is ignored # unless log_rotation_type is setto ""interval"" (integer value) #log_rotate_interval = 1 # Rotation interval type. The time of the last file change (or the time when # the service was started) is used when scheduling the next rotation (string # value) # Possible values: # Seconds - <No description provided> # Minutes - <No description provided> # Hours - <No description provided> # Days - <No description provided> # Weekday - <No description provided> # Midnight - <No description provided> #log_rotate_interval_type = days # Maximum number of rotated log files (integer value) #max_logfile_count = 30 # Log file maximum size in MB. This option is ignored if ""log_rotation_type"" is # not set to ""size"" (integer value) #max_logfile_size_mb = 200 # Log rotation type (string value) # Possible values: # interval - Rotate logs at predefined time intervals. # size - Rotate logs once they reach a predefined size. # none - Do not rotate log files. #log_rotation_type = none #default_log_levels = amqp=WARN,amqplib=WARN,boto=WARN,qpid=WARN,sqlalchemy=WARN,suds=INFO,oslo.messaging=INFO,oslo_messaging=INFO,iso8601=WARN,requests.packages.urllib3.connectionpool=WARN,urllib3.connectionpool=WARN,websocket=WARN,requests.packages.urllib3.util.retry=WARN,urllib3.util.retry=WARN,keystonemiddleware=WARN,routes.middleware=WARN,stevedore=WARN,taskflow=WARN,keystoneauth=WARN,oslo.cache=INFO,oslo_policy=INFO,dogpile.core.dogpile=INFO[keystone_authtoken] auth_url = {{ KEYSTONE_IDENTITY_URI }} username = {{ KEYSTONE_ADMIN_USER }} password = {{ KEYSTONE_ADMIN_PASSWORD }} user_domain_name = Default project_name = {{ KEYSTONE_ADMIN_TENANT }} project_domain_name = Default # # From keystonemiddleware.auth_token # # Complete ""public"" Identity API endpoint. This endpoint should not be an # ""admin"" endpoint, as it should be accessible by all end users. # Unauthenticated clients are redirected to this endpoint to authenticate. # Although this endpoint should ideally be unversioned, client support in the # wild varies. If you're using a versioned v2 endpoint here, then this should # *not* be the same endpoint the service user utilizes for validating tokens, # because normal end users may not be able to reach that endpoint (string # value) # Deprecated group/name - [keystone_authtoken]/auth_uri www_authenticate_uri = {{ KEYSTONE_AUTH_URI }} # DEPRECATED: Complete ""public"" Identity API endpoint. This endpoint should not # be an ""admin"" endpoint, as it should be accessible by all end users. # Unauthenticated clients are redirected to this endpoint to authenticate. # Although this endpoint should ideally be unversioned, client support in the # wild varies. If you're using a versioned v2 endpoint here, then this should # *not* be the same endpoint the service user utilizes for validating tokens, # because normal end users may not be able to reach that endpoint. This option # is deprecated in favor of www_authenticate_uri and will be removed in the S # release (string value) # This option is deprecated for removal since Queens. # Its value may be silently ignored in the future. # Reason: The auth_uri option is deprecated in favor of www_authenticate_uri # and will be removed in the S release. #auth_uri = <None> # API version of the admin Identity API endpoint (string value) #auth_version = <None> # Do not handle authorization requests within the middleware, but delegate the # authorization decision to downstream WSGI components (boolean value) #delay_auth_decision = false # Request timeout value for communicating with Identity API server (integer # value) #http_connect_timeout = <None> # How many times are we trying to reconnect when communicating with Identity # API Server (integer value) #http_request_max_retries = 3 # Request environment key where the Swift cache object is stored. When # auth_token middleware is deployed with a Swift cache, use this option to have # the middleware share a caching backend with swift. Otherwise, use the # ``memcached_servers`` option instead (string value) #cache = <None> # Required if identity server requires client certificate (string value) #certfile = <None> # Required if identity server requires client certificate (string value) #keyfile = <None> # A PEM encoded Certificate Authority to use when verifying HTTPs connections. # Defaults to system CAs (string value) #cafile = <None> # Verify HTTPS connections (boolean value) insecure = {{ KEYSTONE_INSECURE }} # The region in which the identity server can be found (string value) {% if KEYSTONE_REGION_NAME is defined %} region_name = {{ KEYSTONE_REGION_NAME }} {% endif %} # DEPRECATED: Directory used to cache files related to PKI tokens. This option # has been deprecated in the Ocata release and will be removed in the P release # (string value) # This option is deprecated for removal since Ocata. # Its value may be silently ignored in the future. # Reason: PKI token format is no longer supported. #signing_dir = <None> # Optionally specify a list of memcached server(s) to use for caching. If left # undefined, tokens will instead be cached in-process (list value) # Deprecated group/name - [keystone_authtoken]/memcache_servers memcached_servers = {{ MEMCACHED_URI }} # In order to prevent excessive effort spent validating tokens, the middleware # caches previously-seen tokens for a configurable duration (in seconds). Set # to -1 to disable caching completely (integer value) #token_cache_time = 300 # DEPRECATED: Determines the frequency at which the list of revoked tokens is # retrieved from the Identity service (in seconds). A high number of revocation # events combined with a low cache duration may significantly reduce # performance. Only valid for PKI tokens. This option has been deprecated in # the Ocata release and will be removed in the P release (integer value) # This option is deprecated for removal since Ocata. # Its value may be silently ignored in the future. # Reason: PKI token format is no longer supported. #revocation_cache_time = 10 # (Optional) If defined, indicate whether token data should be authenticated or # authenticated and encrypted. If MAC, token data is authenticated (with HMAC) # in the cache. If ENCRYPT, token data is encrypted and authenticated in the # cache. If the value is not one of these options or empty, auth_token will # raise an exception on initialization (string value) # Possible values: # None - <No description provided> # MAC - <No description provided> # ENCRYPT - <No description provided> #memcache_security_strategy = None # (Optional, mandatory if memcache_security_strategy is defined) This string is # used for key derivation (string value) #memcache_secret_key = <None> # (Optional) Number of seconds memcached server is considered dead before it is # tried again (integer value) #memcache_pool_dead_retry = 300 # (Optional) Maximum total number of open connections to every memcached server # (integer value) #memcache_pool_maxsize = 10 # (Optional) Socket timeout in seconds for communicating with a memcached # server (integer value) #memcache_pool_socket_timeout = 3 # (Optional) Number of seconds a connection to memcached is held unused in the # pool before it is closed (integer value) #memcache_pool_unused_timeout = 60 # (Optional) Number of seconds that an operation will wait to get a memcached # client connection from the pool (integer value) #memcache_pool_conn_get_timeout = 10 # (Optional) Use the advanced (eventlet safe) memcached client pool. The # advanced pool will only work under python 2.x (boolean value) #memcache_use_advanced_pool = false # (Optional) Indicate whether to set the X-Service-Catalog header. If False, # middleware will not ask for service catalog on token validation and will not # set the X-Service-Catalog header (boolean value) #include_service_catalog = true # Used to control the use and type of token binding. Can be set to: ""disabled"" # to not check token binding. ""permissive"" (default) to validate binding # information if the bind type is of a form known to the server and ignore it # if not. ""strict"" like ""permissive"" but if the bind type is unknown the token # will be rejected. ""required"" any form of token binding is needed to be # allowed. Finally the name of a binding method that must be present in tokens # (string value) #enforce_token_bind = permissive # DEPRECATED: If true, the revocation list will be checked for cached tokens. # This requires that PKI tokens are configured on the identity server (boolean # value) # This option is deprecated for removal since Ocata. # Its value may be silently ignored in the future. # Reason: PKI token format is no longer supported. #check_revocations_for_cached = false # DEPRECATED: Hash algorithms to use for hashing PKI tokens. This may be a # single algorithm or multiple. The algorithms are those supported by Python # standard hashlib.new(). The hashes will be tried in the order given, so put # the preferred one first for performance. The result of the first hash will be # stored in the cache. This will typically be set to multiple values only while # migrating from a less secure algorithm to a more secure one. Once all the old # tokens are expired this option should be set to a single value for better # performance (list value) # This option is deprecated for removal since Ocata. # Its value may be silently ignored in the future. # Reason: PKI token format is no longer supported. #hash_algorithms = md5 # A choice of roles that must be present in a service token. Service tokens are # allowed to request that an expired token can be used and so this check should # tightly control that only actual services should be sending this token. Roles # here are applied as an ANY check so any role in this list must be present. # For backwards compatibility reasons this currently only affects the # allow_expired check (list value) #service_token_roles = service # For backwards compatibility reasons we must let valid service tokens pass # that don't pass the service_token_roles check as valid. Setting this true # will become the default in a future release and should be enabled if possible # (boolean value) service_token_roles_required = true # Authentication type to load (string value) # Deprecated group/name - [keystone_authtoken]/auth_plugin auth_type = password # Config Section from which to load plugin specific options (string value) #auth_section = <None> ","region = useast#default_log_levels = amqp=WARN,amqplib=WARN,boto=WARN,qpid=WARN,sqlalchemy=WARN,suds=INFO,oslo.messaging=INFO,oslo_messaging=INFO,iso8601=WARN,requests.packages.urllib3.connectionpool=WARN,urllib3.connectionpool=WARN,websocket=WARN,requests.packages.urllib3.util.retry=WARN,urllib3.util.retry=WARN,keystonemiddleware=WARN,routes.middleware=WARN,stevedore=WARN,taskflow=WARN,keystoneauth=WARN,oslo.cache=INFO,dogpile.core.dogpile=INFO# From monasca_api # # DEPRECATED: # The SQLAlchemy connection string to use to connect to the database # (string value) # This option is deprecated for removal since 1.6.0. # Its value may be silently ignored in the future. # Reason: Please use database.connection option,database.url is scheduled for # removal in Pike release #url = $database.connection # [dispatcher] driver = v2_reference [keystone_authtoken] auth_type = password auth_url = {{ KEYSTONE_IDENTITY_URI }} auth_uri = {{ KEYSTONE_AUTH_URI }} username = {{ KEYSTONE_ADMIN_USER }} password = {{ KEYSTONE_ADMIN_PASSWORD }} user_domain_name = Default project_name = {{ KEYSTONE_ADMIN_TENANT }} project_domain_name = Default service_token_roles_required = true memcached_servers = {{ MEMCACHED_URI }} insecure = false cafile = certfile = keyfile =",241,34
openstack%2Ftripleo-heat-templates~master~I65f46056f8a908c60c99d1cee3738344a0bce6b7,openstack/tripleo-heat-templates,master,I65f46056f8a908c60c99d1cee3738344a0bce6b7,Handle upper and lower case system uuids,MERGED,2019-02-19 19:54:52.000000000,2019-02-21 19:25:04.000000000,2019-02-21 18:36:12.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 6926}, {'_account_id': 12398}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-19 19:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/824d53e8af0f073952e3e6b366389be772c62a30', 'message': 'Handle upper and lower case system uuids\n\nWe need to be able to handle when system uuids are upper or lower case\nbecause newer versions of dmidecode have normalized to lower case. Users\nwho were on CentOS/RHEL 7.5 and older may have per-node customizations\nwith upper case which turn lowercase with an update to 7.6. This affects\nhieradata customizations as well as os-net-config mapping files. This\nchange outputs both an upper and lowercase hieradata uuid file to handle\nthe both versions of the UUID. Additionally this change checks if\nsystem-uuid is used in the os-net-config mapping and matches on either\nupper or lower case.\n\nChange-Id: I65f46056f8a908c60c99d1cee3738344a0bce6b7\nCloses-Bug: #1816652\n'}, {'number': 2, 'created': '2019-02-19 19:56:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9c6a6e972890bf4f21856fb4207f76dae674d3c5', 'message': 'Handle upper and lower case system uuids\n\nWe need to be able to handle when system uuids are upper or lower case\nbecause newer versions of dmidecode have normalized to lower case. Users\nwho were on CentOS/RHEL 7.5 and older may have per-node customizations\nwith upper case which turn lowercase with an update to 7.6. This affects\nhieradata customizations as well as os-net-config mapping files. This\nchange outputs both an upper and lowercase hieradata uuid file to handle\nthe both versions of the UUID. Additionally this change normalizes the\nid comparison for os-net-config mappings to lower case.\n\nChange-Id: I65f46056f8a908c60c99d1cee3738344a0bce6b7\nCloses-Bug: #1816652\n'}, {'number': 3, 'created': '2019-02-19 19:59:01.000000000', 'files': ['firstboot/os-net-config-mappings.yaml', 'puppet/extraconfig/pre_deploy/per_node.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e2a8a494c5abf64ac5ed16e7f2b20edd4535c2d4', 'message': 'Handle upper and lower case system uuids\n\nWe need to be able to handle when system uuids are upper or lower case\nbecause newer versions of dmidecode have normalized to lower case. Users\nwho were on CentOS/RHEL 7.5 and older may have per-node customizations\nwith upper case which turn lowercase with an update to 7.6. This affects\nhieradata customizations as well as os-net-config mapping files. This\nchange outputs both an upper and lowercase hieradata uuid file to handle\nthe both versions of the UUID. Additionally this change normalizes the\nid comparison for os-net-config mappings to lower case.\n\nChange-Id: I65f46056f8a908c60c99d1cee3738344a0bce6b7\nCloses-Bug: #1816652\n'}]",2,637984,e2a8a494c5abf64ac5ed16e7f2b20edd4535c2d4,17,8,3,14985,,,0,"Handle upper and lower case system uuids

We need to be able to handle when system uuids are upper or lower case
because newer versions of dmidecode have normalized to lower case. Users
who were on CentOS/RHEL 7.5 and older may have per-node customizations
with upper case which turn lowercase with an update to 7.6. This affects
hieradata customizations as well as os-net-config mapping files. This
change outputs both an upper and lowercase hieradata uuid file to handle
the both versions of the UUID. Additionally this change normalizes the
id comparison for os-net-config mappings to lower case.

Change-Id: I65f46056f8a908c60c99d1cee3738344a0bce6b7
Closes-Bug: #1816652
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/84/637984/1 && git format-patch -1 --stdout FETCH_HEAD,"['firstboot/os-net-config-mappings.yaml', 'puppet/extraconfig/pre_deploy/per_node.yaml']",2,824d53e8af0f073952e3e6b366389be772c62a30,bug/1816652," # thanks to dmidecode 3.1, we have to handle both the upper case # and lower case versions of the UUID from dmidecode. LP#1816652 # upper for dmidecode < 3.1 and lower for dmidecode >= 3.1 node_id_upper=$(echo $node_id | tr '[:lower:]' '[:upper:]') # handle upper case node id LP#1816652 cp /etc/puppet/hieradata/${node_id}.json /etc/puppet/heiradata/${node_id_upper}.json",,9,2
openstack%2Fnova~stable%2Frocky~Ibbdcec1c9c5b897eb6dab993ece0535f307025ab,openstack/nova,stable/rocky,Ibbdcec1c9c5b897eb6dab993ece0535f307025ab,Fix a missing policy in test policy data,MERGED,2019-02-15 02:03:50.000000000,2019-02-21 19:18:44.000000000,2019-02-21 19:18:44.000000000,"[{'_account_id': 6873}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-15 02:03:50.000000000', 'files': ['nova/tests/unit/fake_policy.py', 'nova/tests/unit/api/openstack/compute/test_flavor_manage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a4017aaa53815989f45c8f3df1d20fb2c471b14d', 'message': ""Fix a missing policy in test policy data\n\nAdd the 'os_compute_api:os-flavor-manage:update'\nin the test policy data in nova/tests/unit/fake_policy.py.\nIt should have been added in\nIb16b0de82f9f9492f5cacf646dc3165a0849d75e.\n\nTrivialFix\nChange-Id: Ibbdcec1c9c5b897eb6dab993ece0535f307025ab\n(cherry picked from commit 72028ff8b9aaac5dcabbca9e2897f45ce0d94b62)\n""}]",0,637085,a4017aaa53815989f45c8f3df1d20fb2c471b14d,9,4,1,7634,,,0,"Fix a missing policy in test policy data

Add the 'os_compute_api:os-flavor-manage:update'
in the test policy data in nova/tests/unit/fake_policy.py.
It should have been added in
Ib16b0de82f9f9492f5cacf646dc3165a0849d75e.

TrivialFix
Change-Id: Ibbdcec1c9c5b897eb6dab993ece0535f307025ab
(cherry picked from commit 72028ff8b9aaac5dcabbca9e2897f45ce0d94b62)
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/637085/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/fake_policy.py', 'nova/tests/unit/api/openstack/compute/test_flavor_manage.py']",2,a4017aaa53815989f45c8f3df1d20fb2c471b14d,fix_missing_policy," """"""Tests that trying to update a flavor as a non-admin fails. rule_name = ""os_compute_api:os-flavor-manage:update"" self.policy.set_rules({rule_name: ""is_admin:True""})"," """"""Tests that trying to update a flavor as a non-admin fails due to the default policy.",4,2
openstack%2Frequirements~master~Ic312f69b665b44f285fe08a026fec3e1ca5dc65b,openstack/requirements,master,Ic312f69b665b44f285fe08a026fec3e1ca5dc65b,Blacklist oslo.service 1.37.0,ABANDONED,2019-02-19 20:35:00.000000000,2019-02-21 19:16:36.000000000,,"[{'_account_id': 6928}, {'_account_id': 11628}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-19 20:35:00.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b08c695b6e9c8845dcafb8092c2fc946036534e0', 'message': 'Blacklist oslo.service 1.37.0\n\noslo.service 1.37.0 introduced[1] yappi 0.99 (recently added to g-r[2]) to\nthe requirements.txt. Unfortunately this version of yappi has a known\nbug[3] that is causing job failures[4].\n\nThis patch will blacklist the 1.37.0 version of oslo.service.\n\n[1] http://lists.openstack.org/pipermail/release-announce/2019-February/ \\\n    006465.html\n[2] https://github.com/openstack/requirements/commit/ \\\n    d9797f1dd667ad4bfea67bd6db1d2c016826a1e1\n[3] https://github.com/sumerc/yappi/commit/ \\\n    778829f6f77928e4292e6a7dd4dfecf501f9a362\n[4] http://logs.openstack.org/29/637929/2/check/octavia-v2-dsvm-scenario/ \\\n    4113e77/controller/logs/dib-build/amphora-x64-haproxy.qcow2_log.txt.gz \\\n    #_2019-02-19_17_23_37_112\n\nChange-Id: Ic312f69b665b44f285fe08a026fec3e1ca5dc65b\n'}]",0,637994,b08c695b6e9c8845dcafb8092c2fc946036534e0,9,4,1,11628,,,0,"Blacklist oslo.service 1.37.0

oslo.service 1.37.0 introduced[1] yappi 0.99 (recently added to g-r[2]) to
the requirements.txt. Unfortunately this version of yappi has a known
bug[3] that is causing job failures[4].

This patch will blacklist the 1.37.0 version of oslo.service.

[1] http://lists.openstack.org/pipermail/release-announce/2019-February/ \
    006465.html
[2] https://github.com/openstack/requirements/commit/ \
    d9797f1dd667ad4bfea67bd6db1d2c016826a1e1
[3] https://github.com/sumerc/yappi/commit/ \
    778829f6f77928e4292e6a7dd4dfecf501f9a362
[4] http://logs.openstack.org/29/637929/2/check/octavia-v2-dsvm-scenario/ \
    4113e77/controller/logs/dib-build/amphora-x64-haproxy.qcow2_log.txt.gz \
    #_2019-02-19_17_23_37_112

Change-Id: Ic312f69b665b44f285fe08a026fec3e1ca5dc65b
",git fetch https://review.opendev.org/openstack/requirements refs/changes/94/637994/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,b08c695b6e9c8845dcafb8092c2fc946036534e0,,oslo.service===1.36.0,oslo.service===1.37.0,2,2
openstack%2Fkayobe~master~Ia2de07abc7c58040f99766adb950c477800ea56d,openstack/kayobe,master,Ia2de07abc7c58040f99766adb950c477800ea56d,Run yamllint on etc/kayobe during pep8 tox env,MERGED,2019-02-14 12:17:39.000000000,2019-02-21 19:13:26.000000000,2019-02-21 19:13:26.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 28048}]","[{'number': 1, 'created': '2019-02-14 12:17:39.000000000', 'files': ['.yamllint', 'test-requirements.txt', 'etc/kayobe/seed-hypervisor.yml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/4d52ee0cdf569ed3e30310cf36268419a0f4c40f', 'message': 'Run yamllint on etc/kayobe during pep8 tox env\n\nWe run yamllint with the same configuration in kayobe-config, so we\nshould catch issues here before they are synchronised.\n\nChange-Id: Ia2de07abc7c58040f99766adb950c477800ea56d\n'}]",0,636940,4d52ee0cdf569ed3e30310cf36268419a0f4c40f,7,3,1,14826,,,0,"Run yamllint on etc/kayobe during pep8 tox env

We run yamllint with the same configuration in kayobe-config, so we
should catch issues here before they are synchronised.

Change-Id: Ia2de07abc7c58040f99766adb950c477800ea56d
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/40/636940/1 && git format-patch -1 --stdout FETCH_HEAD,"['.yamllint', 'test-requirements.txt', 'etc/kayobe/seed-hypervisor.yml', 'tox.ini']",4,4d52ee0cdf569ed3e30310cf36268419a0f4c40f,yamllint, yamllint etc/kayobe,,16,1
openstack%2Fneutron~master~Ie6e6cc1bbbe50ff7cfad4e8033e48711569ea020,openstack/neutron,master,Ie6e6cc1bbbe50ff7cfad4e8033e48711569ea020,Avoid loading same service plugin more than once,MERGED,2019-02-21 10:20:04.000000000,2019-02-21 19:05:48.000000000,2019-02-21 19:05:48.000000000,"[{'_account_id': 2}, {'_account_id': 4694}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10239}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2019-02-21 10:20:04.000000000', 'files': ['neutron/manager.py', 'neutron/tests/unit/test_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d802fad8a92625005597ebda4931b0bbe13418e9', 'message': ""Avoid loading same service plugin more than once\n\nIn patch [1] requirement that only each service plugin\ncan be loaded only once was removed.\nUnfortunatelly it is not possible that same service plugin\nwill be instantiate more than once because it may reqister some\ncallbacks or other things which can't be duplicated.\n\nSo this patch adds mechanism which will ensure that each service\nplugin class is instantiate only once and reused if necessary.\n\n[1] https://review.openstack.org/#/c/626561/\n\nCloses-Bug: #1816771\n\nChange-Id: Ie6e6cc1bbbe50ff7cfad4e8033e48711569ea020\n""}]",5,638380,d802fad8a92625005597ebda4931b0bbe13418e9,16,12,1,11975,,,0,"Avoid loading same service plugin more than once

In patch [1] requirement that only each service plugin
can be loaded only once was removed.
Unfortunatelly it is not possible that same service plugin
will be instantiate more than once because it may reqister some
callbacks or other things which can't be duplicated.

So this patch adds mechanism which will ensure that each service
plugin class is instantiate only once and reused if necessary.

[1] https://review.openstack.org/#/c/626561/

Closes-Bug: #1816771

Change-Id: Ie6e6cc1bbbe50ff7cfad4e8033e48711569ea020
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/638380/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/manager.py', 'neutron/tests/unit/test_manager.py']",2,d802fad8a92625005597ebda4931b0bbe13418e9,bug/1816771,"import mock with mock.patch( ""neutron.tests.unit.dummy_plugin.DummyServicePlugin.__init__"", return_value=None ) as dummy_init_mock, mock.patch( ""neutron.tests.unit.dummy_plugin."" ""DummyWithRequireServicePlugin.__init__"", return_value=None ) as dummy_with_require_init_mock: manager.NeutronManager.get_instance() plugins = directory.get_plugins() # ensure that DUMMY and DUMMY_REQIURE was instantiate only once: self.assertEqual(1, dummy_init_mock.call_count) self.assertEqual(1, dummy_with_require_init_mock.call_count) with mock.patch( ""neutron.tests.unit.dummy_plugin.DummyServicePlugin.__init__"", return_value=None ) as dummy_init_mock, mock.patch( ""neutron.tests.unit.dummy_plugin."" ""DummyWithRequireServicePlugin.__init__"", return_value=None ) as dummy_with_require_init_mock: manager.NeutronManager.get_instance() plugins = directory.get_plugins() # ensure that DUMMY and DUMMY_REQIURE was instantiate only once: self.assertEqual(1, dummy_init_mock.call_count) self.assertEqual(1, dummy_with_require_init_mock.call_count) with mock.patch( ""neutron.tests.unit.dummy_plugin.DummyServicePlugin.__init__"", return_value=None ) as dummy_init_mock, mock.patch( ""neutron.tests.unit.dummy_plugin."" ""DummyWithRequireServicePlugin.__init__"", return_value=None ) as dummy_with_require_init_mock: manager.NeutronManager.get_instance() plugins = directory.get_plugins() # ensure that DUMMY and DUMMY_REQIURE was instantiate only once: self.assertEqual(1, dummy_init_mock.call_count) self.assertEqual(1, dummy_with_require_init_mock.call_count)", manager.NeutronManager.get_instance() plugins = directory.get_plugins() manager.NeutronManager.get_instance() plugins = directory.get_plugins() manager.NeutronManager.get_instance() plugins = directory.get_plugins(),49,7
openstack%2Fmanila~master~Ie1fd4ddb4448c05559a31098302f84367fe6ed52,openstack/manila,master,Ie1fd4ddb4448c05559a31098302f84367fe6ed52,Include .inc files in doc8 linting,MERGED,2019-02-19 18:02:13.000000000,2019-02-21 19:03:07.000000000,2019-02-21 17:07:24.000000000,"[{'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 14384}, {'_account_id': 16643}, {'_account_id': 20695}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 26968}, {'_account_id': 27615}]","[{'number': 1, 'created': '2019-02-19 18:02:13.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/manila/commit/1e07a3e694be6aef2173a02a6d3de4f41365ade3', 'message': ""Include .inc files in doc8 linting\n\nThis issue was recently seen in cinder when the gate failed\nto detect trailing whitespaces in '.inc' files.\nAs seen, manila was also prone to such issues but thankfully\nno error was found in '.inc' after running against doc8.\nIt still seems important to include it in the testing to avoid\nfuture similar issues.\n\nChange-Id: Ie1fd4ddb4448c05559a31098302f84367fe6ed52\n""}]",0,637957,1e07a3e694be6aef2173a02a6d3de4f41365ade3,25,12,1,27615,,,0,"Include .inc files in doc8 linting

This issue was recently seen in cinder when the gate failed
to detect trailing whitespaces in '.inc' files.
As seen, manila was also prone to such issues but thankfully
no error was found in '.inc' after running against doc8.
It still seems important to include it in the testing to avoid
future similar issues.

Change-Id: Ie1fd4ddb4448c05559a31098302f84367fe6ed52
",git fetch https://review.opendev.org/openstack/manila refs/changes/57/637957/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,1e07a3e694be6aef2173a02a6d3de4f41365ade3,, doc8 --ignore D001 --ignore-path .tox --ignore-path doc/build --ignore-path manila.egg-info -e .txt -e .rst -e .inc, doc8 --ignore D001 --ignore-path .tox --ignore-path doc/build --ignore-path manila.egg-info -e txt -e rst,1,1
openstack%2Foslo.messaging~master~If8370c0c83312d675bde837f768ae40ec3603972,openstack/oslo.messaging,master,If8370c0c83312d675bde837f768ae40ec3603972,Kafka driver deployment guide,MERGED,2018-10-15 17:58:21.000000000,2019-02-21 18:59:53.000000000,2019-02-21 18:59:53.000000000,"[{'_account_id': 8770}, {'_account_id': 15334}, {'_account_id': 20523}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-10-15 17:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/cb7477e20f4480e0da26e88600a4c08ef342c327', 'message': 'Kafka driver deployment guide\n\nDepends-On: Idfb9fe3700d882c8285c6dc56b0620951178eba2\nChange-Id: If8370c0c83312d675bde837f768ae40ec3603972\n'}, {'number': 2, 'created': '2018-10-29 13:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/16b50f00e1f35d8ae497b995d7d91accd9ca6ee1', 'message': 'Kafka driver deployment guide\n\nDepends-On: Idfb9fe3700d882c8285c6dc56b0620951178eba2\nChange-Id: If8370c0c83312d675bde837f768ae40ec3603972\n'}, {'number': 3, 'created': '2018-12-10 12:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/bf82aec04d4eca8b8f13a67a01c7d9e38fb138e6', 'message': 'Kafka driver deployment guide\n\nDepends-On: Idfb9fe3700d882c8285c6dc56b0620951178eba2\nChange-Id: If8370c0c83312d675bde837f768ae40ec3603972\n'}, {'number': 4, 'created': '2018-12-10 15:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/17fa6084fdf395d308af8824753b19dfe0921c21', 'message': 'Kafka driver deployment guide\n\nDepends-On: Idfb9fe3700d882c8285c6dc56b0620951178eba2\nChange-Id: If8370c0c83312d675bde837f768ae40ec3603972\n'}, {'number': 5, 'created': '2019-01-14 16:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/cfac2c711f9d0138c98ca1d933721543bbb3edca', 'message': 'Kafka driver deployment guide\n\nDepends-On: Idfb9fe3700d882c8285c6dc56b0620951178eba2\nChange-Id: If8370c0c83312d675bde837f768ae40ec3603972\n'}, {'number': 6, 'created': '2019-01-23 13:27:44.000000000', 'files': ['doc/source/admin/index.rst', 'oslo_messaging/_drivers/impl_kafka.py', 'doc/source/admin/kafka.rst'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/0953fa17593af1cda67760e32b49f14e7405dd85', 'message': 'Kafka driver deployment guide\n\nDepends-On: Idfb9fe3700d882c8285c6dc56b0620951178eba2\nChange-Id: If8370c0c83312d675bde837f768ae40ec3603972\n'}]",63,610676,0953fa17593af1cda67760e32b49f14e7405dd85,30,4,6,20523,,,0,"Kafka driver deployment guide

Depends-On: Idfb9fe3700d882c8285c6dc56b0620951178eba2
Change-Id: If8370c0c83312d675bde837f768ae40ec3603972
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/76/610676/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/index.rst', 'oslo_messaging/_drivers/impl_kafka.py', 'doc/source/admin/Kafka.rst']",3,cb7477e20f4480e0da26e88600a4c08ef342c327,kafka-docs,"----------------------------- Kafka Driver Deployment Guide ----------------------------- .. currentmodule:: oslo_messaging ============ Introduction ============ The Kafka Driver is an experimental messaging transport backend in oslo.messaging. The driver maps the base oslo.messaging capabilities for Notification message exchange onto V2.0 of the Apache Kafka distributed streaming platform. More detail regarding the Apache Kafka server is available from the `Apache Kafka website`_ .. _Apache Kafka website: https://kafka.apache.org/ More detail regarding the driver's implementation is available from the `adding kafka driver specification`_ and the `update kafka driver specification`_ . .. _adding kafka driver specification: https://git.openstack.org/cgit/openstack/oslo-specs/tree/specs/liberty/adding-kafka-support.rst .. _update kafka driver specification: https://git.openstack.org/cgit/openstack/oslo-specs/tree/specs/queens/update-kafka-support.rst ======== Overview ======== The Kafka driver is **only** supports use for sending and receiving oslo.messaging Notifications. Communications between the driver and Kafka server backend uses a `binary protocol over TCP`_ that defines all APIs as request response message pairs. The Kafka driver integrates a `Python client based on Librdkafka`_ for full protocol support and utilizes the Producer API to publish notification messages and the Consumer API for notification listener subscriptions. .. _binary protocol over TCP: https://kafka.apache.org/protocol.html .. _Python client based on Librdkafka: https://github.com/confluentinc/confluent-kafka-python The driver is able to work with a single instance of a Kafka server or a clustered Kafka server deployment. Hybrid Messaging Deployment --------------------------- Oslo.messaging provides a mechanism to configure separate backends for RPC and Notification communications. This is supported through the definition of separate RPC and Notification `transport urls`_ in the service configuration. When the Kafka driver is deployed for oslo.messaging notifications, a separate driver and messaging backend must be deployed for RPC communications. For these hybrid messaging configurations, either the `rabbit`_ or `amqp`_ drivers can be deployed for oslo.messaging RPC. .. _transport urls: https://docs.openstack.org/oslo.messaging/latest/reference/transport.html .. _rabbit: https://docs.openstack.org/oslo.messaging/latest/admin/drivers.html#rabbit .. _amqp: https://docs.openstack.org/oslo.messaging/latest/admin/AMQP1.0.html Topics and vhost Support ------------------------ The Kafka topic is the feed name to which records are published. Topics in Kafka are multi-subscriber such that a topic can have zero, one or many consumers that subscribe to the data written to it. In oslo.messaging, a notification listener subscribes to a topic in a supplied target that is directly mapped by the driver to the Kafka topic. The Kafka server architecture does not natively support vhosts. In order to support the presence of a vhost in the transport url provided to the driver, the topic created on the Kafka server will be appended with the virtual host name. This creates a unique topic per for virtual host but **note well** there is otherwise no access control or isolation provided by the Kafka server. Listener Pools -------------- The Kafka driver provides support for listener pools. This capability is realized by mapping the listener pool name to a Kafka server *consumer group* name. Each record published to a topic will be delivered to one consumer instance within each subscribing pool (e.g. consumer group). If a listener pool name is not assigned to the notification listener, a single default consumer group will be used by the Kafka driver and all listeners will be assigned to that group and the messages will effectively be load balanced across the competing listener instances. Synchronous Commit ------------------ A primary functional difference between a Kafka server and a classic broker queue is that the offset or position of the message read from the commit log is controlled by the listener (e.g. consumer). The driver will advance the offset it maintains linearly as it reads message records from the server. To ensure that duplicate messages are not generated during downtime or communication interruption, the driver will *synchronously* commit the consumed messages prior to the notification listener dispatch. Due to this, the driver does not support the re-queue operation and the driver can not replay messages from a Kafka partition. ============= Prerequisites ============= Protocol Engine --------------- The Kafka driver is only supported for use as a notification driver for sending and receiving notifications via oslo.messaging. Communications between the driver and Kafka server backend uses a `binary protocol over TCP`_ that defines all APIs as request response message pairs. .. _binary protocol over TCP: https://kafka.apache.org/protocol.html In order to run the driver the confluent-kafka python client must be intalled. The Kafka driver integrates a `Python client based on Librdkafka`_ for full protocol support and utilizes the Producer API to publish notification messages and the Consumer API for notification listener subscriptions. .. _Python client based on Librdkafka: https://github.com/confluentinc/confluent-kafka-python Source packages for the `confluent-kafka library`_ are available via PyPI. .. _confluent-kafka library: https://pypi.org/project/confluent-kafka/ Since the Kafka driver is an optional extension to Oslo.Messaging these packages are not installed by default. Use the 'kafka' extras tag when installing Oslo.Messaging in order to pull in these extra packages: :: python -m pip install oslo.messaging[kafka] ============= Configuration ============= Transport URL Enable -------------------- In oslo.messaging, the transport_url parameters define the OpenStack service backends for RPC and Notify. The url is of the form: transport://user:pass@host1:port[,hostN:portN]/virtual_host Where the transport value specifies the rpc or notification backend as one of amqp, rabbit, **kafka**, etc. To specify and enable the Kafka driver for Notify, in the section [NOTIFICATIONS] of the service configuration file, specify the 'transport_url' parameter: :: [NOTIFICATIONS] transport_url = kafka://username:password@kafkahostname:9092 Note, that if a 'transport_url' parameter is not specified in the [NOTIFICATIONS] section, the [DEFAULT] transport_url will be used for both RPC and Notify backends. Driver Options -------------- It is recommended that the default configuration options provided by the Kafka driver be used. The configuration options can be modified in the oslo_messaging_kafka section of the service configuration file. Consumer Options ^^^^^^^^^^^^^^^^ #. kafka_max_fetch_bytes: Initial maximum number of byters per topic+partition to request when fetching messages from the broker. #. kafka_consumer_timeout: Consumer polling interval timeout #. consumer_group: The default client group identifier. #. enable_auto_commit: Indicator to perform asynchrounous consumer message commits. #. max_poll_records: The maximum number of messages to terurn per consume/poll operation. Producer Options ^^^^^^^^^^^^^^^^ #. producer_batch_timeout: Delay (ms) to wait for messages in the producer queue to accumulate before constructing message sets to transmit to broker #. producer_batch_size: The maximum number of messages batched into one message set Security Options ^^^^^^^^^^^^^^^^ In section [oslo_messaging_kafka]: #. security_protocol: The protocol used to communicate with the Kafka bokers. #. sasl_mechanisms: SASL mechanism to use for authenticaion. Current driver support is for PLAIN only. #. ssl_cafile: A file containing the trusted Certificate Authority's digital certificate (in PEM format). This certificate is used to authenticate the messaging backend. ================ DevStack Support ================ The plugin for the Kafka oslo.messaging driver is supported by DevStack. As the Kafka driver can only be deployed for notifications, the plugin suports the deployment of several message bus configurations. In local.conf [localrc] section, the `devstack-plugin-kafka`_ plugin repository must be enabled. For example: :: [[local|localrc]] enable_plugin kafka https://git.openstack.org/openstack/devstack-plugin-kafka Set the Kafka and Scala version and location variables if needed for the configuration :: KAFKA_VERSION=2.0.0 KAFKA_BASEURL=http://www.apache.org/dist/kafka SCALA_VERSION=2.12 SCALA_BASEURL=http://www.scala-lang.org/riles/archive The **RPC_** and **NOTIFY_** variables will define the message bus configuration that will be used. The hybrid configurations will allow for the *rabbit* and *amqp* drivers to be used for the RPC transports while the *kafka* driver will be used for the Notify transport. The setting of the service variables will select which messaging intermdiary is enabled for the configuration: +------------+--------------------+--------------------+ | | RPC | NOTIFY | | +-----------+--------+-----------+--------+ | | SERVICE | PORT | SERVICE | PORT | +------------+-----------+--------+-----------+--------+ | Config 1 | rabbit | 5672 | kafka | 9092 | +------------+-----------+--------+-----------+--------+ | Config 1 | amqp | 5672 | kafka | 9092 | +------------+-----------+--------+-----------+--------+ .. _devstack-plugin-kafka: https://github.com/openstack/devstack-plugin-kafka.git ",,270,2
openstack%2Fironic-python-agent~stable%2Fqueens~I7635a197eb000650e919fac386b38ac15ef17041,openstack/ironic-python-agent,stable/queens,I7635a197eb000650e919fac386b38ac15ef17041,Refuse secure erase if ATA command does not work,MERGED,2019-02-21 09:12:29.000000000,2019-02-21 18:58:02.000000000,2019-02-21 18:58:01.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-02-21 09:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/0fe16929470d629c5887b3c02d2e82a4c217a9b9', 'message': ""Refuse secure erase if ATA command does not work\n\nAdds dependency upon smartmontools's binary smartctl to\nquery the block devices via ATA mode which fails on pass-thru\nbuses such as ATA over SCSI and ATA over USB, in an effort\nto prevent the initiation of ATA secure erase with one\nof these interfaces in place which may render the disk\nunreachable after security options are enabled for\nATA Secure Erase or upon the Secure Erase command being\nsent to the Hard Disk.\n\nConflicts:\n\tDockerfile\n\nChange-Id: I7635a197eb000650e919fac386b38ac15ef17041\nStory: #2002546\nTask: #22109\nDepends-On: Ibbfd168844524d91927bdd6e67d973e0bd519bf2\n(cherry picked from commit aef703b87995cc33087c972492c8b8723a76677e)\n""}, {'number': 2, 'created': '2019-02-21 10:35:29.000000000', 'files': ['ironic_python_agent/hardware.py', 'Dockerfile', 'imagebuild/tinyipa/build_files/finalreqs.lst', 'releasenotes/notes/adds-smartctl-ata-check-to-secure-erase-caebba4f25821575.yaml', 'ironic_python_agent/tests/unit/test_hardware.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/085c5be2021de639fd7c68be3c2b62ac3d1e494c', 'message': ""Refuse secure erase if ATA command does not work\n\nAdds dependency upon smartmontools's binary smartctl to\nquery the block devices via ATA mode which fails on pass-thru\nbuses such as ATA over SCSI and ATA over USB, in an effort\nto prevent the initiation of ATA secure erase with one\nof these interfaces in place which may render the disk\nunreachable after security options are enabled for\nATA Secure Erase or upon the Secure Erase command being\nsent to the Hard Disk.\n\nConflicts:\n\tDockerfile\n\nChange-Id: I7635a197eb000650e919fac386b38ac15ef17041\nStory: #2002546\nTask: #22109\nDepends-On: Ibbfd168844524d91927bdd6e67d973e0bd519bf2\n(cherry picked from commit aef703b87995cc33087c972492c8b8723a76677e)\n""}]",0,638369,085c5be2021de639fd7c68be3c2b62ac3d1e494c,13,4,2,10239,,,0,"Refuse secure erase if ATA command does not work

Adds dependency upon smartmontools's binary smartctl to
query the block devices via ATA mode which fails on pass-thru
buses such as ATA over SCSI and ATA over USB, in an effort
to prevent the initiation of ATA secure erase with one
of these interfaces in place which may render the disk
unreachable after security options are enabled for
ATA Secure Erase or upon the Secure Erase command being
sent to the Hard Disk.

Conflicts:
	Dockerfile

Change-Id: I7635a197eb000650e919fac386b38ac15ef17041
Story: #2002546
Task: #22109
Depends-On: Ibbfd168844524d91927bdd6e67d973e0bd519bf2
(cherry picked from commit aef703b87995cc33087c972492c8b8723a76677e)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/69/638369/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/hardware.py', 'Dockerfile', 'imagebuild/tinyipa/build_files/finalreqs.lst', 'releasenotes/notes/adds-smartctl-ata-check-to-secure-erase-caebba4f25821575.yaml', 'ironic_python_agent/tests/unit/test_hardware.py']",5,0fe16929470d629c5887b3c02d2e82a4c217a9b9,bz/1679174,"SMARTCTL_NORMAL_OUTPUT = ("""""" smartctl 6.2 2017-02-27 r4394 [x86_64-linux-3.10.0-693.21.1.el7.x86_64] (local build) Copyright (C) 2002-13, Bruce Allen, Christian Franke, www.smartmontools.org ATA Security is: Disabled, NOT FROZEN [SEC1] """""") # noqa SMARTCTL_UNAVAILABLE_OUTPUT = ("""""" smartctl 6.2 2017-02-27 r4394 [x86_64-linux-3.10.0-693.21.1.el7.x86_64] (local build) Copyright (C) 2002-13, Bruce Allen, Christian Franke, www.smartmontools.org ATA Security is: Unavailable """""") # noqa (SMARTCTL_NORMAL_OUTPUT, ''), mock.call('smartctl', '-d', 'ata', '/dev/sda', '-g', 'security', check_exit_code=[0, 127]), mock.call('hdparm', '--user-master', 'u', '--security-set-pass', 'NULL', '/dev/sda'), mock.call('hdparm', '--user-master', 'u', '--security-erase', 'NULL', '/dev/sda'), mock.call('hdparm', '-I', '/dev/sda'), ]) @mock.patch.object(utils, 'execute', autospec=True) def test_erase_block_device_ata_success_no_smartctl(self, mocked_execute): mocked_execute.side_effect = [ (create_hdparm_info( supported=True, enabled=False, frozen=False, enhanced_erase=False), ''), OSError('boom'), ('', ''), ('', ''), (create_hdparm_info( supported=True, enabled=False, frozen=False, enhanced_erase=False), ''), ] block_device = hardware.BlockDevice('/dev/sda', 'big', 1073741824, True) self.hardware.erase_block_device(self.node, block_device) mocked_execute.assert_has_calls([ mock.call('hdparm', '-I', '/dev/sda'), mock.call('smartctl', '-d', 'ata', '/dev/sda', '-g', 'security', check_exit_code=[0, 127]), (SMARTCTL_UNAVAILABLE_OUTPUT, ''), mock.call('smartctl', '-d', 'ata', '/dev/sda', '-g', 'security', check_exit_code=[0, 127]), (SMARTCTL_UNAVAILABLE_OUTPUT, ''), mock.call('smartctl', '-d', 'ata', '/dev/sda', '-g', 'security', check_exit_code=[0, 127]), mock.call('shred', '--force', '--zero', '--verbose', '--iterations', '1', '/dev/sda') ]) @mock.patch.object(utils, 'execute', autospec=True) def test_erase_block_device_smartctl_unsupported_shred(self, mocked_execute): hdparm_output = create_hdparm_info( supported=True, enabled=False, frozen=False, enhanced_erase=False) mocked_execute.side_effect = [ (hdparm_output, ''), (SMARTCTL_UNAVAILABLE_OUTPUT, ''), (SHRED_OUTPUT_1_ITERATION_ZERO_TRUE, '') ] block_device = hardware.BlockDevice('/dev/sda', 'big', 1073741824, True) self.hardware.erase_block_device(self.node, block_device) mocked_execute.assert_has_calls([ mock.call('hdparm', '-I', '/dev/sda'), mock.call('smartctl', '-d', 'ata', '/dev/sda', '-g', 'security', check_exit_code=[0, 127]), mock.call('shred', '--force', '--zero', '--verbose', '--iterations', '1', '/dev/sda') ]) @mock.patch.object(utils, 'execute', autospec=True) def test_erase_block_device_smartctl_fails_security_fallback_to_shred( self, mocked_execute): hdparm_output = create_hdparm_info( supported=True, enabled=False, frozen=False, enhanced_erase=False) mocked_execute.side_effect = [ (hdparm_output, ''), processutils.ProcessExecutionError(), (SHRED_OUTPUT_1_ITERATION_ZERO_TRUE, '') ] block_device = hardware.BlockDevice('/dev/sda', 'big', 1073741824, True) self.hardware.erase_block_device(self.node, block_device) mocked_execute.assert_has_calls([ mock.call('hdparm', '-I', '/dev/sda'), mock.call('smartctl', '-d', 'ata', '/dev/sda', '-g', 'security', check_exit_code=[0, 127]), (SMARTCTL_NORMAL_OUTPUT, ''), mock.call('smartctl', '-d', 'ata', '/dev/sda', '-g', 'security', check_exit_code=[0, 127]), (SMARTCTL_UNAVAILABLE_OUTPUT, ''), mock.call('smartctl', '-d', 'ata', '/dev/sda', '-g', 'security', check_exit_code=[0, 127]), (SMARTCTL_NORMAL_OUTPUT, ''), (SMARTCTL_NORMAL_OUTPUT, ''), (SMARTCTL_NORMAL_OUTPUT, ''), (SMARTCTL_NORMAL_OUTPUT, ''), (SMARTCTL_NORMAL_OUTPUT, ''), (SMARTCTL_NORMAL_OUTPUT, ''), (hdparm_output, ''), (SMARTCTL_NORMAL_OUTPUT, '') (SMARTCTL_NORMAL_OUTPUT, ''), (SMARTCTL_NORMAL_OUTPUT, ''), (SMARTCTL_NORMAL_OUTPUT, ''),"," (hdparm_output, '')",164,2
openstack%2Fironic-python-agent~stable%2Fqueens~I32e1d962fbbb4a305d5dbebea92ac48ebd9b67ca,openstack/ironic-python-agent,stable/queens,I32e1d962fbbb4a305d5dbebea92ac48ebd9b67ca,Try to unlock failed device before proceeding,MERGED,2019-02-21 09:12:29.000000000,2019-02-21 18:57:57.000000000,2019-02-21 18:57:57.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-02-21 09:12:29.000000000', 'files': ['ironic_python_agent/hardware.py', 'ironic_python_agent/tests/unit/test_hardware.py', 'releasenotes/notes/attempts-ata-disk-unlock-897d76c494ec2976.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/6be0e4f72c992e889ffc73b787c35de740df157e', 'message': 'Try to unlock failed device before proceeding\n\nWhen a hard error has occured with secure erase,\nwe should attempt an unlock of the device becuase\nthe current mode can prevent disk IO. This may upset\nsome things like raid controllers even if they are\nin a pass-through mode.\n\nChange-Id: I32e1d962fbbb4a305d5dbebea92ac48ebd9b67ca\nStory: #2002546\nTask: #22107\n(cherry picked from commit 0f7b5a0896cf1b3080b7679278ff97a8dff0be80)\n'}]",0,638368,6be0e4f72c992e889ffc73b787c35de740df157e,11,4,1,10239,,,0,"Try to unlock failed device before proceeding

When a hard error has occured with secure erase,
we should attempt an unlock of the device becuase
the current mode can prevent disk IO. This may upset
some things like raid controllers even if they are
in a pass-through mode.

Change-Id: I32e1d962fbbb4a305d5dbebea92ac48ebd9b67ca
Story: #2002546
Task: #22107
(cherry picked from commit 0f7b5a0896cf1b3080b7679278ff97a8dff0be80)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/68/638368/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/hardware.py', 'ironic_python_agent/tests/unit/test_hardware.py', 'releasenotes/notes/attempts-ata-disk-unlock-897d76c494ec2976.yaml']",3,6be0e4f72c992e889ffc73b787c35de740df157e,bz/1679174,"--- fixes: - | Fixes the ATA Secure Erase logic to attempt an immediate unlock in the event of a failed attempt to Secure Erase. This is required to permit fallback to make use of the ``shred`` disk utility. In the event that an ATA Secure Erase operation fails during cleaning, the disk will be write locked. In this case, the disk must be explicitly unlocked. This should also prevent failures where an ATA Secure Erase operation fails with a pass-through disk controller, which may prevent the disk from being available after a reboot operation. For additional information, please see `story 2002546 <https://storyboard.openstack.org/#!/story/2002546>`_. ",,53,22
openstack%2Ftripleo-heat-templates~master~Idc35bdfad126f21280444ebffaa5017e73ba8368,openstack/tripleo-heat-templates,master,Idc35bdfad126f21280444ebffaa5017e73ba8368,Deprecate xinetd service management,MERGED,2019-02-14 19:47:20.000000000,2019-02-21 18:55:15.000000000,2019-02-21 18:55:15.000000000,"[{'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-14 19:47:20.000000000', 'files': ['releasenotes/notes/deprecate-xinetd-service.yaml-d7594bf8a7b714e2.yaml', 'roles/ControllerNoCeph.yaml', 'docker/services/xinetd.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'roles_data.yaml', 'roles/Controller.yaml', 'roles_data_undercloud.yaml', 'roles/Undercloud.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/78f1901da4717901bf49ffc3bda321c1650aba19', 'message': 'Deprecate xinetd service management\n\nWe stopped managing this service with the switch containers. This change\nstarts the removal and deprecated the TripleO management of the service.\n\nChange-Id: Idc35bdfad126f21280444ebffaa5017e73ba8368\n'}]",0,637035,78f1901da4717901bf49ffc3bda321c1650aba19,8,4,1,14985,,,0,"Deprecate xinetd service management

We stopped managing this service with the switch containers. This change
starts the removal and deprecated the TripleO management of the service.

Change-Id: Idc35bdfad126f21280444ebffaa5017e73ba8368
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/35/637035/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/deprecate-xinetd-service.yaml-d7594bf8a7b714e2.yaml', 'roles/ControllerNoCeph.yaml', 'docker/services/xinetd.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'roles/Controller.yaml', 'roles_data.yaml', 'roles_data_undercloud.yaml', 'roles/Undercloud.yaml']",8,78f1901da4717901bf49ffc3bda321c1650aba19,cleaup-xinetd,, - OS::TripleO::Services::Xinetd,8,65
openstack%2Ftripleo-heat-templates~stable%2Frocky~I0ff266d12a652b6cbe49fcbe87046302c872f56c,openstack/tripleo-heat-templates,stable/rocky,I0ff266d12a652b6cbe49fcbe87046302c872f56c,Add missing RoleParameters and ServiceNames,MERGED,2019-02-20 14:14:20.000000000,2019-02-21 18:55:14.000000000,2019-02-21 18:55:14.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-20 14:14:20.000000000', 'files': ['extraconfig/pre_network/config_then_reboot.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0a39efefe61d8866efff27f7cb32e1fed7ec17cd', 'message': 'Add missing RoleParameters and ServiceNames\n\nRoleParamters and ServiceNames are required parameters for\nPreNetworkConfig\n\nChange-Id: I0ff266d12a652b6cbe49fcbe87046302c872f56c\nCloses-Bug: #1816450\n(cherry picked from commit 703bf1c050204fea033408f1f07ddf112fb5ea62)\n'}]",0,638163,0a39efefe61d8866efff27f7cb32e1fed7ec17cd,10,4,1,14985,,,0,"Add missing RoleParameters and ServiceNames

RoleParamters and ServiceNames are required parameters for
PreNetworkConfig

Change-Id: I0ff266d12a652b6cbe49fcbe87046302c872f56c
Closes-Bug: #1816450
(cherry picked from commit 703bf1c050204fea033408f1f07ddf112fb5ea62)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/63/638163/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/pre_network/config_then_reboot.yaml'],1,0a39efefe61d8866efff27f7cb32e1fed7ec17cd,bug/1816450-stable/rocky, RoleParameters: type: json description: Parameters specific to the role default: {} ServiceNames: type: comma_delimited_list default: [],,7,0
openstack%2Fopenstack-ansible-os_cinder~stable%2Fqueens~Ie31a7e2917a188027db49ac51e6a77ee39a9abf0,openstack/openstack-ansible-os_cinder,stable/queens,Ie31a7e2917a188027db49ac51e6a77ee39a9abf0,"cinder.conf: add [nova] section, override interface defaults",MERGED,2019-02-20 16:33:23.000000000,2019-02-21 18:38:18.000000000,2019-02-21 18:38:18.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-20 16:33:23.000000000', 'files': ['templates/cinder.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/25e09dd8ee5cd312726b268e7936b0077072f513', 'message': 'cinder.conf: add [nova] section, override interface defaults\n\nTo the best of my knowledge, the [nova] section in cinder.conf\nis only ever used if the Cinder scheduler is acting as a Nova client\nwhen the operator has enabled the InstanceLocalityFilter.\n\nPer https://docs.openstack.org/cinder/latest/configuration/block-storage/samples/cinder.conf.html,\nCinder defaults to using the public Nova endpoint when using the\nNova API. This is contrary to OSA precedent, where services\nnormally use internal endpoints for service-to-service API requests.\n\nWhen enabling the InstanceLocalityFilter in combination with Cinder\ntalking to the public Nova endpoint, this can create a very confusing\nsituation, particularly in pre-production clusters: if the public\nendpoint has a self-signed SSL certificate, and Cinder is not\nexplicitly configured not to verify certificates, then this creates\na whole load of connection errors.\n\nThus, in order to follow POLA, configure the [nova] section to use\nthe internal endpoint, and (in case the internal endpoint does\nuse HTTPS) honor the keystone_service_internaluri_insecure setting,\nas for other services.\n\nChange-Id: Ie31a7e2917a188027db49ac51e6a77ee39a9abf0\n(cherry picked from commit 8c436038e383122490bde41543f0a57421504638)\n'}]",0,638206,25e09dd8ee5cd312726b268e7936b0077072f513,7,3,1,2463,,,0,"cinder.conf: add [nova] section, override interface defaults

To the best of my knowledge, the [nova] section in cinder.conf
is only ever used if the Cinder scheduler is acting as a Nova client
when the operator has enabled the InstanceLocalityFilter.

Per https://docs.openstack.org/cinder/latest/configuration/block-storage/samples/cinder.conf.html,
Cinder defaults to using the public Nova endpoint when using the
Nova API. This is contrary to OSA precedent, where services
normally use internal endpoints for service-to-service API requests.

When enabling the InstanceLocalityFilter in combination with Cinder
talking to the public Nova endpoint, this can create a very confusing
situation, particularly in pre-production clusters: if the public
endpoint has a self-signed SSL certificate, and Cinder is not
explicitly configured not to verify certificates, then this creates
a whole load of connection errors.

Thus, in order to follow POLA, configure the [nova] section to use
the internal endpoint, and (in case the internal endpoint does
use HTTPS) honor the keystone_service_internaluri_insecure setting,
as for other services.

Change-Id: Ie31a7e2917a188027db49ac51e6a77ee39a9abf0
(cherry picked from commit 8c436038e383122490bde41543f0a57421504638)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/06/638206/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/cinder.conf.j2'],1,25e09dd8ee5cd312726b268e7936b0077072f513,nova-internal-interface-queens, [nova] interface = internal insecure = {{ keystone_service_internaluri_insecure | bool }},,4,0
openstack%2Fopenstack-ansible-os_cinder~stable%2Frocky~Ie31a7e2917a188027db49ac51e6a77ee39a9abf0,openstack/openstack-ansible-os_cinder,stable/rocky,Ie31a7e2917a188027db49ac51e6a77ee39a9abf0,"cinder.conf: add [nova] section, override interface defaults",MERGED,2019-02-20 16:32:51.000000000,2019-02-21 18:38:18.000000000,2019-02-21 18:38:18.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-20 16:32:51.000000000', 'files': ['templates/cinder.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/debe7c8931c828d566f90787fe4dd0d98838843b', 'message': 'cinder.conf: add [nova] section, override interface defaults\n\nTo the best of my knowledge, the [nova] section in cinder.conf\nis only ever used if the Cinder scheduler is acting as a Nova client\nwhen the operator has enabled the InstanceLocalityFilter.\n\nPer https://docs.openstack.org/cinder/latest/configuration/block-storage/samples/cinder.conf.html,\nCinder defaults to using the public Nova endpoint when using the\nNova API. This is contrary to OSA precedent, where services\nnormally use internal endpoints for service-to-service API requests.\n\nWhen enabling the InstanceLocalityFilter in combination with Cinder\ntalking to the public Nova endpoint, this can create a very confusing\nsituation, particularly in pre-production clusters: if the public\nendpoint has a self-signed SSL certificate, and Cinder is not\nexplicitly configured not to verify certificates, then this creates\na whole load of connection errors.\n\nThus, in order to follow POLA, configure the [nova] section to use\nthe internal endpoint, and (in case the internal endpoint does\nuse HTTPS) honor the keystone_service_internaluri_insecure setting,\nas for other services.\n\nChange-Id: Ie31a7e2917a188027db49ac51e6a77ee39a9abf0\n(cherry picked from commit 8c436038e383122490bde41543f0a57421504638)\n'}]",0,638205,debe7c8931c828d566f90787fe4dd0d98838843b,7,3,1,2463,,,0,"cinder.conf: add [nova] section, override interface defaults

To the best of my knowledge, the [nova] section in cinder.conf
is only ever used if the Cinder scheduler is acting as a Nova client
when the operator has enabled the InstanceLocalityFilter.

Per https://docs.openstack.org/cinder/latest/configuration/block-storage/samples/cinder.conf.html,
Cinder defaults to using the public Nova endpoint when using the
Nova API. This is contrary to OSA precedent, where services
normally use internal endpoints for service-to-service API requests.

When enabling the InstanceLocalityFilter in combination with Cinder
talking to the public Nova endpoint, this can create a very confusing
situation, particularly in pre-production clusters: if the public
endpoint has a self-signed SSL certificate, and Cinder is not
explicitly configured not to verify certificates, then this creates
a whole load of connection errors.

Thus, in order to follow POLA, configure the [nova] section to use
the internal endpoint, and (in case the internal endpoint does
use HTTPS) honor the keystone_service_internaluri_insecure setting,
as for other services.

Change-Id: Ie31a7e2917a188027db49ac51e6a77ee39a9abf0
(cherry picked from commit 8c436038e383122490bde41543f0a57421504638)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/05/638205/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/cinder.conf.j2'],1,debe7c8931c828d566f90787fe4dd0d98838843b,nova-internal-interface-rocky, [nova] interface = internal insecure = {{ keystone_service_internaluri_insecure | bool }},,4,0
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I0ff266d12a652b6cbe49fcbe87046302c872f56c,openstack/tripleo-heat-templates,stable/queens,I0ff266d12a652b6cbe49fcbe87046302c872f56c,Add missing RoleParameters and ServiceNames,MERGED,2019-02-20 14:14:28.000000000,2019-02-21 18:36:14.000000000,2019-02-21 18:36:14.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-20 14:14:28.000000000', 'files': ['extraconfig/pre_network/config_then_reboot.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b6ebb07c7ba3f420fd7bc94ded3eb9f9d56201ed', 'message': 'Add missing RoleParameters and ServiceNames\n\nRoleParamters and ServiceNames are required parameters for\nPreNetworkConfig\n\nChange-Id: I0ff266d12a652b6cbe49fcbe87046302c872f56c\nCloses-Bug: #1816450\n(cherry picked from commit 703bf1c050204fea033408f1f07ddf112fb5ea62)\n'}]",0,638164,b6ebb07c7ba3f420fd7bc94ded3eb9f9d56201ed,7,3,1,14985,,,0,"Add missing RoleParameters and ServiceNames

RoleParamters and ServiceNames are required parameters for
PreNetworkConfig

Change-Id: I0ff266d12a652b6cbe49fcbe87046302c872f56c
Closes-Bug: #1816450
(cherry picked from commit 703bf1c050204fea033408f1f07ddf112fb5ea62)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/64/638164/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/pre_network/config_then_reboot.yaml'],1,b6ebb07c7ba3f420fd7bc94ded3eb9f9d56201ed,bug/1816450-stable/queens, RoleParameters: type: json description: Parameters specific to the role default: {} ServiceNames: type: comma_delimited_list default: [],,7,0
openstack%2Fironic-python-agent~master~I69edcd2c0356bc1577e2a5974b004585b37469ca,openstack/ironic-python-agent,master,I69edcd2c0356bc1577e2a5974b004585b37469ca,Move to zuulv3,MERGED,2019-01-30 19:46:22.000000000,2019-02-21 18:32:58.000000000,2019-02-21 18:32:58.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-30 19:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/271be08e90b958c6c7ca7d8f3ec93b1f70a063b9', 'message': '[WIP] Move to zuulv3\n\nChange-Id: I69edcd2c0356bc1577e2a5974b004585b37469ca\n'}, {'number': 2, 'created': '2019-02-08 10:50:19.000000000', 'files': ['playbooks/legacy/ipa-tempest-dsvm-partition-ipmi-iscsi-tinyipa-python3/post.yaml', 'zuul.d/ironic-python-agent-jobs.yaml', 'playbooks/legacy/ipa-tempest-dsvm-partition-bios-ipmi-iscsi-tinyipa256-src/post.yaml', 'playbooks/legacy/ipa-tempest-dsvm-partition-bios-ipmi-iscsi-tinyipa256-src/run.yaml', 'zuul.d/legacy-ironic-jobs.yaml', 'playbooks/legacy/ipa-tempest-dsvm-partition-ipmi-iscsi-tinyipa-python3/run.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/884e79ae8382178965bd43d6ce6d7792b0edf164', 'message': 'Move to zuulv3\n\nDepends-On: https://review.openstack.org/#/c/630100/\nChange-Id: I69edcd2c0356bc1577e2a5974b004585b37469ca\n'}]",0,634038,884e79ae8382178965bd43d6ce6d7792b0edf164,20,4,2,15519,,,0,"Move to zuulv3

Depends-On: https://review.openstack.org/#/c/630100/
Change-Id: I69edcd2c0356bc1577e2a5974b004585b37469ca
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/38/634038/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/ironic-python-agent-jobs.yaml'],1,271be08e90b958c6c7ca7d8f3ec93b1f70a063b9,zuulv3_ironic,,,0,0
openstack%2Fcharm-openstack-dashboard~master~I74c17113f431c4c21f638be6abffaeeb693f1462,openstack/charm-openstack-dashboard,master,I74c17113f431c4c21f638be6abffaeeb693f1462,Use correct certificate when ``os-public-hostname`` configration option is set,MERGED,2019-02-21 15:45:18.000000000,2019-02-21 18:30:23.000000000,2019-02-21 18:30:23.000000000,"[{'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 15:45:18.000000000', 'files': ['hooks/horizon_hooks.py', 'unit_tests/test_horizon_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/256f971c78574f017eb802ab7097231698b96ae0', 'message': 'Use correct certificate when ``os-public-hostname`` configration option is set\n\nNote that this is a short term kludge/fix, on the long term\nwe should ditch the charm specific ApacheSSLContext and use\nthe common one from charm-helpers with an adapted Apache\nconfig inspired from the ``openstack_https_fronted`` template\n\nChange-Id: I74c17113f431c4c21f638be6abffaeeb693f1462\nCloses-Bug: #1816621\n'}]",0,638443,256f971c78574f017eb802ab7097231698b96ae0,10,4,1,13686,,,0,"Use correct certificate when ``os-public-hostname`` configration option is set

Note that this is a short term kludge/fix, on the long term
we should ditch the charm specific ApacheSSLContext and use
the common one from charm-helpers with an adapted Apache
config inspired from the ``openstack_https_fronted`` template

Change-Id: I74c17113f431c4c21f638be6abffaeeb693f1462
Closes-Bug: #1816621
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/43/638443/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_hooks.py', 'unit_tests/test_horizon_hooks.py']",2,256f971c78574f017eb802ab7097231698b96ae0,bug/1816621," @patch.object(hooks.os, 'symlink') @patch.object(hooks.os, 'remove') @patch.object(hooks.os.path, 'exists') @patch.object(hooks, 'service_reload') @patch.object(hooks, 'process_certificates') def test_certs_changed(self, _process_certificates, _service_reload, _exists, _remove, _symlink): self._call_hook('certificates-relation-changed') _process_certificates.assert_called_with( 'horizon', None, None, custom_hostname_link='dashboard') self.assertFalse(_symlink.called) self.CONFIGS.write_all.assert_called_with() _service_reload.assert_called_with('apache2') self.enable_ssl.assert_called_with() _process_certificates.reset_mock() self.config.side_effect = None self.config.return_value = 'somehostname' _exists.return_value = True self._call_hook('certificates-relation-changed') _process_certificates.assert_called_with('horizon', None, None) _remove.assert_has_calls([ call('/etc/apache2/ssl/horizon/cert_dashboard'), call('/etc/apache2/ssl/horizon/key_dashboard'), ]) _symlink.assert_has_calls([ call('/etc/apache2/ssl/horizon/cert_somehostname', '/etc/apache2/ssl/horizon/cert_dashboard'), call('/etc/apache2/ssl/horizon/key_somehostname', '/etc/apache2/ssl/horizon/key_dashboard'), ])",,53,2
openstack%2Fnova~stable%2Fpike~Ibfe5500c4fbac91e4f5bec492d7ad89f69957f2a,openstack/nova,stable/pike,Ibfe5500c4fbac91e4f5bec492d7ad89f69957f2a,Manage Compute services in nova manual typos,ABANDONED,2019-02-15 12:58:37.000000000,2019-02-21 18:10:46.000000000,,"[{'_account_id': 7634}, {'_account_id': 15888}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-15 12:58:37.000000000', 'files': ['doc/source/admin/services.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/13b9729a642ee2c40e4c78ec6bf66bfc5d037dac', 'message': 'Manage Compute services in nova manual typos\n\n Command openstack compute service set typos\n  As IS :  --disable --disable-reason trial log nova nova-compute\n  To Be :  --disable --disable-reason ""trial log"" nova nova-compute\n\nRelated Bugs:#1815167\n\nChange-Id: Ibfe5500c4fbac91e4f5bec492d7ad89f69957f2a\n'}]",0,637178,13b9729a642ee2c40e4c78ec6bf66bfc5d037dac,7,5,1,22290,,,0,"Manage Compute services in nova manual typos

 Command openstack compute service set typos
  As IS :  --disable --disable-reason trial log nova nova-compute
  To Be :  --disable --disable-reason ""trial log"" nova nova-compute

Related Bugs:#1815167

Change-Id: Ibfe5500c4fbac91e4f5bec492d7ad89f69957f2a
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/637178/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/services.rst'],1,13b9729a642ee2c40e4c78ec6bf66bfc5d037dac,," $ openstack compute service set --disable --disable-reason ""trial log"" nova nova-compute", $ openstack compute service set --disable --disable-reason trial log nova nova-compute,1,1
openstack%2Fnova~master~Iaf58d702b1619a66f97553cf2e47eb8c85166bf6,openstack/nova,master,Iaf58d702b1619a66f97553cf2e47eb8c85166bf6,"Correct examples in ""Manage Compute services"" documentation",MERGED,2017-09-04 13:50:35.000000000,2019-02-21 18:10:30.000000000,2017-09-04 15:26:24.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 5754}, {'_account_id': 15751}]","[{'number': 1, 'created': '2017-09-04 13:50:35.000000000', 'files': ['doc/source/admin/services.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/be221ecb0f6d09980052abfd867633a47b42e83e', 'message': 'Correct examples in ""Manage Compute services"" documentation\n\n* ""compute service set"" command requires a host, not a zone\n* the --disable-reason flag\'s argument has to be quoted\n\nChange-Id: Iaf58d702b1619a66f97553cf2e47eb8c85166bf6\n'}]",0,500551,be221ecb0f6d09980052abfd867633a47b42e83e,13,4,1,10239,,,0,"Correct examples in ""Manage Compute services"" documentation

* ""compute service set"" command requires a host, not a zone
* the --disable-reason flag's argument has to be quoted

Change-Id: Iaf58d702b1619a66f97553cf2e47eb8c85166bf6
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/500551/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/services.rst'],1,be221ecb0f6d09980052abfd867633a47b42e83e,services-docs," $ openstack compute service set --disable --disable-reason ""trial log"" compute nova-compute $ openstack compute service set --enable compute nova-compute", $ openstack compute service set --disable --disable-reason trial log nova nova-compute $ openstack compute service set --enable nova nova-compute,2,2
openstack%2Fopenstack-ansible-os_heat~master~I9aea9f42c476ff3c6f2355a0afb21be4eea57b69,openstack/openstack-ansible-os_heat,master,I9aea9f42c476ff3c6f2355a0afb21be4eea57b69,Add heat_user_pip_packages variable,MERGED,2019-02-20 17:49:18.000000000,2019-02-21 18:08:11.000000000,2019-02-21 18:08:11.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-20 17:49:18.000000000', 'files': ['tasks/heat_install_source.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/d94ca42619989cdefaf2f4b96382d0809e57825e', 'message': 'Add heat_user_pip_packages variable\n\nWith this variable, users would be able to extend\nthe list of pip packages in case of needing an\nextra pip package.\n\nCurrently if we need an extra pip package we need\nto override the existing list.\n\nChange-Id: I9aea9f42c476ff3c6f2355a0afb21be4eea57b69\n'}]",0,638230,d94ca42619989cdefaf2f4b96382d0809e57825e,7,3,1,28008,,,0,"Add heat_user_pip_packages variable

With this variable, users would be able to extend
the list of pip packages in case of needing an
extra pip package.

Currently if we need an extra pip package we need
to override the existing list.

Change-Id: I9aea9f42c476ff3c6f2355a0afb21be4eea57b69
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/30/638230/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/heat_install_source.yml', 'defaults/main.yml']",2,d94ca42619989cdefaf2f4b96382d0809e57825e,user_pip_packages,# Specific pip packages provided by the user heat_user_pip_packages: [] ,,4,1
openstack%2Fneutron~master~I8b84a359f83133014b3d4414aafc10e6b7c6a876,openstack/neutron,master,I8b84a359f83133014b3d4414aafc10e6b7c6a876,Modify api and rpc default number of workers,MERGED,2019-02-12 16:01:34.000000000,2019-02-21 18:00:43.000000000,2019-02-21 18:00:43.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10980}, {'_account_id': 11975}, {'_account_id': 12860}, {'_account_id': 13995}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2019-02-12 16:01:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3cd27af5dc824b981c9e48a459b0fc5d18debe4c', 'message': 'Modify api and rpc default number of workers\n\n- Limit number of api workers to roughly using half of system\n  RAM. Spawning a bunch, just to have the OOM killer nuke them\n  regularly is not useful.\n- Bump the rpc_workers default to half of the api_workers.\n  A default of 1 falls behind on any reasonably sized node.\n\nChange-Id: I8b84a359f83133014b3d4414aafc10e6b7c6a876\nCloses-bug: #1815629\n'}, {'number': 2, 'created': '2019-02-12 17:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1287c5f666b1d9387046d2823fe9d8edd101d2cf', 'message': 'Modify api and rpc default number of workers\n\n- Limit number of api workers to roughly using half of system\n  RAM. Spawning a bunch, just to have the OOM killer nuke them\n  regularly is not useful.\n- Bump the rpc_workers default to half of the api_workers.\n  A default of 1 falls behind on any reasonably sized node.\n\nChange-Id: I8b84a359f83133014b3d4414aafc10e6b7c6a876\nCloses-bug: #1815629\n'}, {'number': 3, 'created': '2019-02-12 17:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/124638179a7a5b9b2f3ef8fbe501aee2193896d1', 'message': 'Modify api and rpc default number of workers\n\n- Limit number of api workers to roughly using half of system\n  RAM. Spawning a bunch, just to have the OOM killer nuke them\n  regularly is not useful.\n- Bump the rpc_workers default to half of the api_workers.\n  A default of 1 falls behind on any reasonably sized node.\n\nChange-Id: I8b84a359f83133014b3d4414aafc10e6b7c6a876\nCloses-bug: #1815629\n'}, {'number': 4, 'created': '2019-02-12 20:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f106940628fbbabe89c3c4d5467ebeb41eee3420', 'message': 'Modify api and rpc default number of workers\n\n- Limit number of api workers to roughly using half of system\n  RAM. Spawning a bunch, just to have the OOM killer nuke them\n  regularly is not useful.\n- Bump the rpc_workers default to half of the api_workers.\n  A default of 1 falls behind on any reasonably sized node.\n\nChange-Id: I8b84a359f83133014b3d4414aafc10e6b7c6a876\nCloses-bug: #1815629\n'}, {'number': 5, 'created': '2019-02-15 04:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/91b399e15104827bdf1a08da5380c9f62b0b4e57', 'message': 'Modify api and rpc default number of workers\n\n- Limit number of api workers to roughly using half of system\n  RAM. Spawning a bunch, just to have the OOM killer nuke them\n  regularly is not useful.\n- Bump the rpc_workers default to half of the api_workers.\n  A default of 1 falls behind on any reasonably sized node.\n\nChange-Id: I8b84a359f83133014b3d4414aafc10e6b7c6a876\nCloses-bug: #1815629\n'}, {'number': 6, 'created': '2019-02-15 18:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9327c5c78f3835696b6681f0ce084a2df5e1c7a4', 'message': 'Modify api and rpc default number of workers\n\n- Limit number of api workers to roughly using half of system\n  RAM. Spawning a bunch, just to have the OOM killer nuke them\n  regularly is not useful.\n- Bump the rpc_workers default to half of the api_workers.\n  A default of 1 falls behind on any reasonably sized node.\n\nChange-Id: I8b84a359f83133014b3d4414aafc10e6b7c6a876\nCloses-bug: #1815629\n'}, {'number': 7, 'created': '2019-02-16 02:10:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4967f5a3b5b56f60fb1846f7786369bb2de48ce6', 'message': 'Modify api and rpc default number of workers\n\n- Limit number of api workers to roughly using half of system\n  RAM. Spawning a bunch, just to have the OOM killer nuke them\n  regularly is not useful.\n- Bump the rpc_workers default to half of the api_workers.\n  A default of 1 falls behind on any reasonably sized node.\n\nChange-Id: I8b84a359f83133014b3d4414aafc10e6b7c6a876\nCloses-bug: #1815629\n'}, {'number': 8, 'created': '2019-02-18 06:43:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3a4a2b4b26fa1cf653d08d1ab1b0822f8560ae3', 'message': 'Modify api and rpc default number of workers\n\n- Limit number of api workers to roughly using half of system\n  RAM. Spawning a bunch, just to have the OOM killer nuke them\n  regularly is not useful.\n- Bump the rpc_workers default to half of the api_workers.\n  A default of 1 falls behind on any reasonably sized node.\n\nChange-Id: I8b84a359f83133014b3d4414aafc10e6b7c6a876\nCloses-bug: #1815629\n'}, {'number': 9, 'created': '2019-02-19 17:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b50e8909dbfb7b74b006ed8701436dd5649293d', 'message': 'Modify api and rpc default number of workers\n\n- Limit number of api workers to roughly using half of system\n  RAM. Spawning a bunch, just to have the OOM killer nuke them\n  regularly is not useful.\n- Bump the rpc_workers default to half of the api_workers.\n  A default of 1 falls behind on any reasonably sized node.\n\nChange-Id: I8b84a359f83133014b3d4414aafc10e6b7c6a876\nCloses-bug: #1815629\n'}, {'number': 10, 'created': '2019-02-19 18:34:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dda25c3ee9f75024b2eeacd890b2d4103b8930cd', 'message': 'Modify api and rpc default number of workers\n\n- Limit number of api workers to roughly using half of system\n  RAM. Spawning a bunch, just to have the OOM killer nuke them\n  regularly is not useful.\n- Bump the rpc_workers default to half of the api_workers.\n  A default of 1 falls behind on any reasonably sized node.\n\nChange-Id: I8b84a359f83133014b3d4414aafc10e6b7c6a876\nCloses-bug: #1815629\n'}, {'number': 11, 'created': '2019-02-19 20:24:18.000000000', 'files': ['neutron/cmd/upgrade_checks/checks.py', 'neutron/conf/service.py', 'releasenotes/notes/modify_api_rpc_worker_defaults-1acd62728b2b55fa.yaml', 'neutron/cmd/status.py', 'neutron/service.py', 'neutron/tests/unit/test_service.py', 'neutron/tests/functional/test_service.py', 'doc/source/admin/config-wsgi.rst', 'neutron/tests/unit/cmd/upgrade_checks/test_checks.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e09b25b964dde82caf5f5159d25810b6f8ebd3c', 'message': 'Modify api and rpc default number of workers\n\n- Limit number of api workers to roughly using half of system\n  RAM. Spawning a bunch, just to have the OOM killer nuke them\n  regularly is not useful.\n- Bump the rpc_workers default to half of the api_workers.\n  A default of 1 falls behind on any reasonably sized node.\n\nChange-Id: I8b84a359f83133014b3d4414aafc10e6b7c6a876\nCloses-bug: #1815629\n'}]",49,636363,7e09b25b964dde82caf5f5159d25810b6f8ebd3c,85,15,11,10980,,,0,"Modify api and rpc default number of workers

- Limit number of api workers to roughly using half of system
  RAM. Spawning a bunch, just to have the OOM killer nuke them
  regularly is not useful.
- Bump the rpc_workers default to half of the api_workers.
  A default of 1 falls behind on any reasonably sized node.

Change-Id: I8b84a359f83133014b3d4414aafc10e6b7c6a876
Closes-bug: #1815629
",git fetch https://review.opendev.org/openstack/neutron refs/changes/63/636363/8 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/conf/service.py', 'neutron/service.py', 'neutron/tests/unit/test_service.py']",3,3cd27af5dc824b981c9e48a459b0fc5d18debe4c,bug/1815629,"class TestServiceHelpers(base.BaseTestCase): def test_get_workers(self): self.assertGreaterEqual(service._get_worker_count(), 1) self.worker_count = mock.patch( 'neutron.service._get_worker_count' self._test_api_workers(None, self.worker_count)"," self.processor_count = mock.patch( 'oslo_concurrency.processutils.get_worker_count' self._test_api_workers(None, self.processor_count)",40,7
openstack%2Fmistral~master~I297054f052b79143b2d0882286fb3e22d19c70c5,openstack/mistral,master,I297054f052b79143b2d0882286fb3e22d19c70c5,Release note for fixing event-engines HA,MERGED,2019-02-15 10:56:12.000000000,2019-02-21 17:56:45.000000000,2019-02-20 13:01:37.000000000,"[{'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 15895}, {'_account_id': 18955}, {'_account_id': 21970}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-15 10:56:12.000000000', 'files': ['releasenotes/notes/fix-event-engines-ha-cc78f341095cdabf.yaml'], 'web_link': 'https://opendev.org/openstack/mistral/commit/ed7c351d0b38633ef56112ad87251b2d22873a93', 'message': 'Release note for fixing event-engines HA\n\nAdd missing release note for https://review.openstack.org/#/c/548044/\n\nChange-Id: I297054f052b79143b2d0882286fb3e22d19c70c5\n'}]",0,637167,ed7c351d0b38633ef56112ad87251b2d22873a93,10,6,1,9373,,,0,"Release note for fixing event-engines HA

Add missing release note for https://review.openstack.org/#/c/548044/

Change-Id: I297054f052b79143b2d0882286fb3e22d19c70c5
",git fetch https://review.opendev.org/openstack/mistral refs/changes/67/637167/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/fix-event-engines-ha-cc78f341095cdabf.yaml'],1,ed7c351d0b38633ef56112ad87251b2d22873a93,bug/1715848,--- fixes: - | [`bug 1715848 <https://bugs.launchpad.net/mistral/+bug/1715848>`_] Fixed a bug that prevents event-engines to work correctly in HA. ,,5,0
openstack%2Fopenstack-ansible-os_horizon~master~I9b41af83b473a19a3097e4754c17928b23b968d5,openstack/openstack-ansible-os_horizon,master,I9b41af83b473a19a3097e4754c17928b23b968d5,Add horizon_user_pip_packages variable,MERGED,2019-02-20 19:03:36.000000000,2019-02-21 17:51:12.000000000,2019-02-21 17:51:12.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-20 19:03:36.000000000', 'files': ['tasks/horizon_install_source.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/554c6bd1fe73184712ecd11d1f26d0ec967c5f4b', 'message': 'Add horizon_user_pip_packages variable\n\nWith this variable, users would be able to extend\nthe list of pip packages in case of needing an\nextra pip package.\n\nCurrently if we need an extra pip package we need\nto override the existing list.\n\nChange-Id: I9b41af83b473a19a3097e4754c17928b23b968d5\n'}]",0,638239,554c6bd1fe73184712ecd11d1f26d0ec967c5f4b,7,3,1,28008,,,0,"Add horizon_user_pip_packages variable

With this variable, users would be able to extend
the list of pip packages in case of needing an
extra pip package.

Currently if we need an extra pip package we need
to override the existing list.

Change-Id: I9b41af83b473a19a3097e4754c17928b23b968d5
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/39/638239/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/horizon_install_source.yml', 'defaults/main.yml']",2,554c6bd1fe73184712ecd11d1f26d0ec967c5f4b,user_pip_packages,# Specific pip packages provided by the user horizon_user_pip_packages: [] ,,4,1
openstack%2Fnetworking-ovn~stable%2Frocky~I1cb4cd3dd2bf3be1e0beb4f2cc89a89fcf803f70,openstack/networking-ovn,stable/rocky,I1cb4cd3dd2bf3be1e0beb4f2cc89a89fcf803f70,Add IPv6 default route to OVN Logical Router,MERGED,2019-02-18 15:37:46.000000000,2019-02-21 17:33:59.000000000,2019-02-21 17:33:59.000000000,"[{'_account_id': 6773}, {'_account_id': 10237}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-02-18 15:37:46.000000000', 'files': ['networking_ovn/common/ovn_client.py', 'networking_ovn/common/utils.py', 'networking_ovn/tests/functional/test_ovn_db_sync.py', 'networking_ovn/ovn_db_sync.py', 'networking_ovn/tests/unit/test_ovn_db_sync.py', 'networking_ovn/tests/unit/l3/test_l3_ovn.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/1c8da1eb83ee9943a965dabbb47be0f355709060', 'message': ""Add IPv6 default route to OVN Logical Router\n\nPrior to this patch, only IPv4 subnets were accounted to install\nstatic routes on Logical Routers when setting a external gateway.\nThis is a problem if the public network has an IPv6 subnet as\ninstances won't get a default route.\n\nChange-Id: I1cb4cd3dd2bf3be1e0beb4f2cc89a89fcf803f70\nCloses-Bug: #1808753\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n(cherry picked from commit ed5f25bb37de68688930d80dae7eb0cf447de70c)\n""}]",0,637570,1c8da1eb83ee9943a965dabbb47be0f355709060,12,5,1,23804,,,0,"Add IPv6 default route to OVN Logical Router

Prior to this patch, only IPv4 subnets were accounted to install
static routes on Logical Routers when setting a external gateway.
This is a problem if the public network has an IPv6 subnet as
instances won't get a default route.

Change-Id: I1cb4cd3dd2bf3be1e0beb4f2cc89a89fcf803f70
Closes-Bug: #1808753
Signed-off-by: Daniel Alvarez <dalvarez@redhat.com>
(cherry picked from commit ed5f25bb37de68688930d80dae7eb0cf447de70c)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/70/637570/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/common/ovn_client.py', 'networking_ovn/common/utils.py', 'networking_ovn/tests/functional/test_ovn_db_sync.py', 'networking_ovn/ovn_db_sync.py', 'networking_ovn/tests/unit/l3/test_l3_ovn.py', 'networking_ovn/tests/unit/test_ovn_db_sync.py']",6,1c8da1eb83ee9943a965dabbb47be0f355709060,bug/1808753-stable/rocky,"from neutron_lib import constants as const 'r1': [ovn_client.GW_INFO(router_ip='90.0.0.2', gateway_ip='90.0.0.1', network_id='', subnet_id='', ip_version=4, ip_prefix=const.IPv4_ANY)], 'r2': [ovn_client.GW_INFO(router_ip='100.0.0.2', gateway_ip='100.0.0.1', network_id='', subnet_id='', ip_version=4, ip_prefix=const.IPv4_ANY)] }.get(router['id'], [])"," 'r1': ovn_client.GW_INFO(router_ip='90.0.0.2', gateway_ip='90.0.0.1', network_id='', subnet_id=''), 'r2': ovn_client.GW_INFO(router_ip='100.0.0.2', gateway_ip='100.0.0.1', network_id='', subnet_id='') }.get(router['id'], ovn_client.GW_INFO('', '', '', ''))",129,84
openstack%2Fopenstack-ansible-os_keystone~master~If2a01309f37c585cdd6a7d8d1f6d893e0707626a,openstack/openstack-ansible-os_keystone,master,If2a01309f37c585cdd6a7d8d1f6d893e0707626a,Add keystone_user_pip_packages variable,MERGED,2019-02-20 18:03:09.000000000,2019-02-21 17:26:09.000000000,2019-02-21 17:26:09.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-20 18:03:09.000000000', 'files': ['tasks/keystone_install_source.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/8d815f9a9163a19ce63e14015f23aa1f3cd83a75', 'message': 'Add keystone_user_pip_packages variable\n\nWith this variable, users would be able to extend\nthe list of pip packages in case of needing an\nextra pip package.\n\nCurrently if we need an extra pip package we need\nto override the existing list.\n\nChange-Id: If2a01309f37c585cdd6a7d8d1f6d893e0707626a\n'}]",0,638233,8d815f9a9163a19ce63e14015f23aa1f3cd83a75,7,3,1,28008,,,0,"Add keystone_user_pip_packages variable

With this variable, users would be able to extend
the list of pip packages in case of needing an
extra pip package.

Currently if we need an extra pip package we need
to override the existing list.

Change-Id: If2a01309f37c585cdd6a7d8d1f6d893e0707626a
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/33/638233/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/keystone_install_source.yml', 'defaults/main.yml']",2,8d815f9a9163a19ce63e14015f23aa1f3cd83a75,user_pip_packages,# Specific pip packages provided by the user keystone_user_pip_packages: [] ,,4,1
openstack%2Fcinder~stable%2Fqueens~I0ad0c530c93a9494e1a3048e557360b38c4a125b,openstack/cinder,stable/queens,I0ad0c530c93a9494e1a3048e557360b38c4a125b,VMAX Driver - VMAX OS Upgrade Bug,MERGED,2018-12-18 15:15:49.000000000,2019-02-21 17:22:36.000000000,2019-01-07 17:35:39.000000000,"[{'_account_id': 7198}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 15670}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21976}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23601}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 26561}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-12-18 15:15:49.000000000', 'files': ['cinder/volume/drivers/dell_emc/vmax/masking.py', 'cinder/volume/drivers/dell_emc/vmax/fc.py', 'cinder/volume/drivers/dell_emc/vmax/provision.py', 'cinder/volume/drivers/dell_emc/vmax/rest.py', 'releasenotes/notes/bug-1790141-vmax-powermaxos-upgrade-fix-4c76186cfca66790.yaml', 'cinder/tests/unit/volume/drivers/dell_emc/vmax/test_vmax.py', 'cinder/volume/drivers/dell_emc/vmax/iscsi.py', 'cinder/volume/drivers/dell_emc/vmax/common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4818a540c3e8a96ad3478333a072582ba256ee9a', 'message': 'VMAX Driver - VMAX OS Upgrade Bug\n\nWorkload support was dropped in ucode 5978. If a VMAX All Flash\narray is upgraded to 5978 or greater and existing volume types\nleveraged workload e.g. DSS, DSS_REP, OLTP and OLTP_REP,\nattaching and detaching will no longer work and the volume type\nwill be unusable.\n\nChange-Id: I0ad0c530c93a9494e1a3048e557360b38c4a125b\nCloses-Bug: #1790141\n(cherry picked from commit 546faf0cd5fa86dadec3a04765e5592f1a1305ab)\n'}]",0,625939,4818a540c3e8a96ad3478333a072582ba256ee9a,26,22,1,12670,,,0,"VMAX Driver - VMAX OS Upgrade Bug

Workload support was dropped in ucode 5978. If a VMAX All Flash
array is upgraded to 5978 or greater and existing volume types
leveraged workload e.g. DSS, DSS_REP, OLTP and OLTP_REP,
attaching and detaching will no longer work and the volume type
will be unusable.

Change-Id: I0ad0c530c93a9494e1a3048e557360b38c4a125b
Closes-Bug: #1790141
(cherry picked from commit 546faf0cd5fa86dadec3a04765e5592f1a1305ab)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/39/625939/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/dell_emc/vmax/masking.py', 'cinder/volume/drivers/dell_emc/vmax/fc.py', 'cinder/volume/drivers/dell_emc/vmax/provision.py', 'cinder/volume/drivers/dell_emc/vmax/rest.py', 'releasenotes/notes/bug-1790141-vmax-powermaxos-upgrade-fix-4c76186cfca66790.yaml', 'cinder/tests/unit/volume/drivers/dell_emc/vmax/test_vmax.py', 'cinder/volume/drivers/dell_emc/vmax/common.py', 'cinder/volume/drivers/dell_emc/vmax/iscsi.py']",8,4818a540c3e8a96ad3478333a072582ba256ee9a,bug/1790141," - Fix for HyperMax OS Upgrade Bug (bug #1790141) VERSION = ""3.1.1"""," VERSION = ""3.1.0""",285,52
openstack%2Fcharm-vault~stable%2F18.11~Ifac75028897d22c277750a747f79d4dfedb4f987,openstack/charm-vault,stable/18.11,Ifac75028897d22c277750a747f79d4dfedb4f987,Fix disable and re-enable of PKI secrets engine,MERGED,2019-02-20 15:37:08.000000000,2019-02-21 17:14:24.000000000,2019-02-21 17:14:24.000000000,"[{'_account_id': 935}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}, {'_account_id': 29191}]","[{'number': 1, 'created': '2019-02-20 15:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/4198931230c8f291e2a17798b2c664b19de37df3', 'message': 'Fix disable and re-enable of PKI secrets engine\n\nSeveral flags were not being managed properly, and certs were not being\nre-issued when PKI was re-enabled.\n\nFixes [lp:1813180](https://bugs.launchpad.net/vault-charm/+bug/1813180)\n\nChange-Id: Ifac75028897d22c277750a747f79d4dfedb4f987\n(cherry picked from commit 3b947315200f295651eed07f5ca80a65abca459e)\n'}, {'number': 2, 'created': '2019-02-21 08:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/3d2bd8071267088f93f83b389a662f84561ae4d3', 'message': 'Fix disable and re-enable of PKI secrets engine\n\nSeveral flags were not being managed properly, and certs were not being\nre-issued when PKI was re-enabled.\n\nFixes [lp:1813180](https://bugs.launchpad.net/vault-charm/+bug/1813180)\n\nChange-Id: Ifac75028897d22c277750a747f79d4dfedb4f987\n(cherry picked from commit 3b947315200f295651eed07f5ca80a65abca459e)\n'}, {'number': 3, 'created': '2019-02-21 09:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/5d0a2f15394c954f72540bfa0108852e657f282a', 'message': 'Fix disable and re-enable of PKI secrets engine\n\nSeveral flags were not being managed properly, and certs were not being\nre-issued when PKI was re-enabled.\n\nConflicts:\n  src/actions/actions.py\n    Conflicts in pload_signed_csr() and generate_root_ca() from\n    (8f490507bce678c9a2d79bff5efb04a852f19118) which i decided to not\n    backport because of the number of changes included which is not\n    reasonable to have in stable.\n\nFixes [lp:1813180](https://bugs.launchpad.net/vault-charm/+bug/1813180)\n\nChange-Id: Ifac75028897d22c277750a747f79d4dfedb4f987\n(cherry picked from commit 3b947315200f295651eed07f5ca80a65abca459e)\n'}, {'number': 4, 'created': '2019-02-21 09:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/7031e5d203cb0151bc90887136d27a06c04c9280', 'message': 'Fix disable and re-enable of PKI secrets engine\n\nSeveral flags were not being managed properly, and certs were not being\nre-issued when PKI was re-enabled.\n\nConflicts:\n  src/actions/actions.py\n    Conflicts in pload_signed_csr() and generate_root_ca() from\n    (8f490507bce678c9a2d79bff5efb04a852f19118) which I decided to not\n    backport because of the number of changes included which are not\n    reasonable to have in stable.\n\nFixes [lp:1813180](https://bugs.launchpad.net/vault-charm/+bug/1813180)\n\nChange-Id: Ifac75028897d22c277750a747f79d4dfedb4f987\n(cherry picked from commit 3b947315200f295651eed07f5ca80a65abca459e)\n'}, {'number': 5, 'created': '2019-02-21 13:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/c071d32ba50a01c4db74fc768de869f5d86056dd', 'message': 'Fix disable and re-enable of PKI secrets engine\n\nSeveral flags were not being managed properly, and certs were not being\nre-issued when PKI was re-enabled.\n\nConflicts:\n  src/actions/actions.py\n    Conflicts in pload_signed_csr() and generate_root_ca() from\n    (8f490507bce678c9a2d79bff5efb04a852f19118) which I decided to not\n    backport because of the number of changes included which are not\n    reasonable to have in stable.\n\nCloses-Bug: 1813180\nChange-Id: Ifac75028897d22c277750a747f79d4dfedb4f987\n(cherry picked from commit 3b947315200f295651eed07f5ca80a65abca459e)\n'}, {'number': 6, 'created': '2019-02-21 13:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/7563858e11bac14e8720d8b0d65848746cb8c292', 'message': 'Fix disable and re-enable of PKI secrets engine\n\nSeveral flags were not being managed properly, and certs were not being\nre-issued when PKI was re-enabled.\n\nConflicts:\n  src/actions/actions.py\n    Conflicts in pload_signed_csr() and generate_root_ca() from\n    (8f490507bce678c9a2d79bff5efb04a852f19118) which I decided to not\n    backport because of the number of changes included which are not\n    reasonable to have in stable.\n\nCloses-Bug: #1816738\nCloses-Bug: #1813180\nChange-Id: Ifac75028897d22c277750a747f79d4dfedb4f987\n(cherry picked from commit 3b947315200f295651eed07f5ca80a65abca459e)\n'}, {'number': 7, 'created': '2019-02-21 14:20:13.000000000', 'files': ['src/lib/charm/vault_pki.py', 'src/actions/actions.py', 'src/reactive/vault_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/ef54d898da6b2fb8d006128608e8713c074f58db', 'message': 'Fix disable and re-enable of PKI secrets engine\n\nSeveral flags were not being managed properly, and certs were not being\nre-issued when PKI was re-enabled.\n\nConflicts:\n  src/actions/actions.py\n    Conflicts in pload_signed_csr() and generate_root_ca() from\n    (8f490507bce678c9a2d79bff5efb04a852f19118) The order of the patches\n    changed which brings small conflicts\n\nCloses-Bug: #1813180\nChange-Id: Ifac75028897d22c277750a747f79d4dfedb4f987\n(cherry picked from commit 3b947315200f295651eed07f5ca80a65abca459e)\n'}]",1,638182,ef54d898da6b2fb8d006128608e8713c074f58db,35,6,7,7730,,,0,"Fix disable and re-enable of PKI secrets engine

Several flags were not being managed properly, and certs were not being
re-issued when PKI was re-enabled.

Conflicts:
  src/actions/actions.py
    Conflicts in pload_signed_csr() and generate_root_ca() from
    (8f490507bce678c9a2d79bff5efb04a852f19118) The order of the patches
    changed which brings small conflicts

Closes-Bug: #1813180
Change-Id: Ifac75028897d22c277750a747f79d4dfedb4f987
(cherry picked from commit 3b947315200f295651eed07f5ca80a65abca459e)
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/82/638182/3 && git format-patch -1 --stdout FETCH_HEAD,"['src/lib/charm/vault_pki.py', 'src/actions/actions.py', 'src/reactive/vault_handlers.py']",3,4198931230c8f291e2a17798b2c664b19de37df3,bug/1813180,"@when_not('charm.vault.ca.ready', 'charm.vault.ca.auto-generated') set_flag('charm.vault.ca.auto-generated') 'charm.vault.ca.ready', 'certificates.available') tls = endpoint_from_flag('certificates.available')",@when_not('charm.vault.ca.ready') 'charm.vault.ca.ready') tls = endpoint_from_flag('certificates.certs.requested'),28,6
openstack%2Fnetworking-ovn~stable%2Frocky~I6c77623bd199bcbb3f4ad46a7fee3b2fac325790,openstack/networking-ovn,stable/rocky,I6c77623bd199bcbb3f4ad46a7fee3b2fac325790,"Fix unbound ""mac"" variable",MERGED,2019-02-20 13:41:20.000000000,2019-02-21 17:09:45.000000000,2019-02-21 17:09:45.000000000,"[{'_account_id': 6773}, {'_account_id': 17776}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-02-20 13:41:20.000000000', 'files': ['networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ml2/mech_driver.py', 'networking_ovn/tests/unit/fakes.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f1cbf8a4624c48e1a494feb266e335b12db47d04', 'message': 'Fix unbound ""mac"" variable\n\nThere\'s a DEBUG trace which is using a non existent variable in\nthat scope and that caused a failure when DEBUG level was enabled.\n\nCloses-Bug: #1816031\nChange-Id: I6c77623bd199bcbb3f4ad46a7fee3b2fac325790\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\nCo-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit a61907e6e2851b2e5c33793a727838b5ca00d330)\n'}]",0,638153,f1cbf8a4624c48e1a494feb266e335b12db47d04,11,5,1,6773,,,0,"Fix unbound ""mac"" variable

There's a DEBUG trace which is using a non existent variable in
that scope and that caused a failure when DEBUG level was enabled.

Closes-Bug: #1816031
Change-Id: I6c77623bd199bcbb3f4ad46a7fee3b2fac325790
Signed-off-by: Daniel Alvarez <dalvarez@redhat.com>
Co-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>
(cherry picked from commit a61907e6e2851b2e5c33793a727838b5ca00d330)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/53/638153/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ml2/mech_driver.py', 'networking_ovn/tests/unit/fakes.py']",3,f1cbf8a4624c48e1a494feb266e335b12db47d04,bug/1816031, self.db_find = mock.Mock() self.db_set = mock.Mock() self.db_clear = mock.Mock(),,36,1
openstack%2Fcharm-neutron-api~master~I27e193be1ede492440d9cf762b3447e09cdce0f3,openstack/charm-neutron-api,master,I27e193be1ede492440d9cf762b3447e09cdce0f3,Allow multiple config files for neutron plugin,ABANDONED,2019-02-01 00:27:48.000000000,2019-02-21 17:03:11.000000000,,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-01 00:27:48.000000000', 'files': ['hooks/neutron_api_utils.py', 'unit_tests/test_neutron_api_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/64f5e92fdec7fb194053f6b65c8a3175b77e805a', 'message': 'Allow multiple config files for neutron plugin\n\nThere are times a third party SDN may require more than one\nconfiguration file for a neutron-plugin. For example:\nplugins/ml2/ml2_conf.ini and plugins/vendor/vendor.ini.\n\nMake the resource map handle a list of configuration files when\nconfigured in the neutron-plugin.\n\nChange-Id: I27e193be1ede492440d9cf762b3447e09cdce0f3\n'}]",0,634355,64f5e92fdec7fb194053f6b65c8a3175b77e805a,7,3,1,20805,,,0,"Allow multiple config files for neutron plugin

There are times a third party SDN may require more than one
configuration file for a neutron-plugin. For example:
plugins/ml2/ml2_conf.ini and plugins/vendor/vendor.ini.

Make the resource map handle a list of configuration files when
configured in the neutron-plugin.

Change-Id: I27e193be1ede492440d9cf762b3447e09cdce0f3
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/55/634355/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/neutron_api_utils.py', 'unit_tests/test_neutron_api_utils.py']",2,64f5e92fdec7fb194053f6b65c8a3175b77e805a,multiple-config-files," 'multi': { 'config': ['/etc/neutron/plugins/ml2/ml2_conf.ini', '/etc/neutron/plugins/nuage/nuage_plugin.ini'], 'driver': 'neutron.plugins.ml2.plugin.Ml2Plugin', 'contexts': [], 'services': [], 'packages': [], 'server_packages': ['neutron-server', 'neutron-plugin-nuage'], 'server_services': ['neutron-server'] }, @patch.object(nutils, 'manage_plugin') @patch('os.path.exists') def test_resource_map_single_conf(self, _path_exists, _manage_plugin): self.os_release.return_value = 'mitaka' _path_exists.return_value = False _manage_plugin.return_value = True _single_conf_file = '/etc/neutron/plugins/ml2/ml2_conf.ini' _map = nutils.resource_map() self.assertTrue(_single_conf_file in _map.keys()) @patch.object(nutils, 'manage_plugin') @patch('os.path.exists') def test_resource_map_multi_conf(self, _path_exists, _manage_plugin): self.os_release.return_value = 'mitaka' _path_exists.return_value = False _manage_plugin.return_value = True _multi_conf_files = ['/etc/neutron/plugins/ml2/ml2_conf.ini', '/etc/neutron/plugins/nuage/nuage_plugin.ini'] self.config.side_effect = self.test_config.get self.test_config.set('neutron-plugin', 'multi') _map = nutils.resource_map() for _file in _multi_conf_files: self.assertTrue(_file in _map.keys()) ",,48,6
openstack%2Ftripleo-quickstart~master~I82bac53cd0ecc9f7c2227e16f33309e4c045b2f0,openstack/tripleo-quickstart,master,I82bac53cd0ecc9f7c2227e16f33309e4c045b2f0,"Skip the creation of virtbmc when overcloud_nodes=""""",ABANDONED,2018-06-19 08:47:36.000000000,2019-02-21 16:36:36.000000000,,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8871}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 22954}, {'_account_id': 23181}, {'_account_id': 24752}]","[{'number': 1, 'created': '2018-06-19 08:47:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/d01d2b3c3993fcaba91222451f456e82cefd608a', 'message': 'Skip the creation of virtbmc when overcloud_nodes=""""\n\nWhen overcloud_nodes="""" you need to skip to task\nregarding virtual BMCs, the creation and the\nstarting.\n\nCloses-Bug: #1777609\nChange-Id: I82bac53cd0ecc9f7c2227e16f33309e4c045b2f0\n'}, {'number': 2, 'created': '2018-06-20 15:29:48.000000000', 'files': ['roles/virtbmc/tasks/configure-vbmc.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/a8de93a52e92510e10dd69ae85a26d50024f8194', 'message': 'Skip the creation of virtbmc when overcloud_nodes=""""\n\nWhen overcloud_nodes="""" you need to skip to task\nregarding virtual BMCs, the creation and the\nstarting.\n\nCloses-Bug: #1777609\nChange-Id: I82bac53cd0ecc9f7c2227e16f33309e4c045b2f0\n'}]",3,576429,a8de93a52e92510e10dd69ae85a26d50024f8194,28,10,2,22954,,,0,"Skip the creation of virtbmc when overcloud_nodes=""""

When overcloud_nodes="""" you need to skip to task
regarding virtual BMCs, the creation and the
starting.

Closes-Bug: #1777609
Change-Id: I82bac53cd0ecc9f7c2227e16f33309e4c045b2f0
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/29/576429/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/virtbmc/tasks/configure-vbmc.yml'],1,d01d2b3c3993fcaba91222451f456e82cefd608a,bug/1777609," when: - release not in ['liberty', 'mitaka', 'newton'] - overcloud_nodes|list|length > 0 when: - release not in ['liberty', 'mitaka', 'newton'] - overcloud_nodes|list|length > 0"," when: release not in ['liberty', 'mitaka', 'newton'] when: release not in ['liberty', 'mitaka', 'newton']",6,2
openstack%2Fironic-tempest-plugin~master~If1c61a4d40f83a8b15462ec7890267b9254b03d7,openstack/ironic-tempest-plugin,master,If1c61a4d40f83a8b15462ec7890267b9254b03d7,DNM - Test,ABANDONED,2019-02-18 14:16:42.000000000,2019-02-21 16:32:30.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-18 14:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/97bb27468fe92daf9083fc783ff4514cbec0aa5a', 'message': 'DNM - Test\n\nChange-Id: If1c61a4d40f83a8b15462ec7890267b9254b03d7\n'}, {'number': 2, 'created': '2019-02-18 15:30:55.000000000', 'files': ['zuul.d/stable-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/581f923831061795b01711b4d4bd62f3861ce31e', 'message': 'DNM - Test\n\nDepends-On: https://review.openstack.org/#/c/635822/\nChange-Id: If1c61a4d40f83a8b15462ec7890267b9254b03d7\n'}]",0,637552,581f923831061795b01711b4d4bd62f3861ce31e,5,1,2,15519,,,0,"DNM - Test

Depends-On: https://review.openstack.org/#/c/635822/
Change-Id: If1c61a4d40f83a8b15462ec7890267b9254b03d7
",git fetch https://review.opendev.org/openstack/ironic-tempest-plugin refs/changes/52/637552/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/stable-jobs.yaml'],1,97bb27468fe92daf9083fc783ff4514cbec0aa5a,test_rocky, description: actual,,1,0
openstack%2Fnova~stable%2Frocky~I28876cfbfaed4e2330df08ab0d1b09d19647b2a7,openstack/nova,stable/rocky,I28876cfbfaed4e2330df08ab0d1b09d19647b2a7,Add alloc cands test with nested and aggregates,ABANDONED,2018-10-03 02:36:20.000000000,2019-02-21 16:30:57.000000000,,"[{'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 25625}]","[{'number': 1, 'created': '2018-10-03 02:36:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8b1f276a26d57dba832486e9184d90c11b8fa34', 'message': 'Fix aggregate members in nested alloc candidates\n\nWhen placement picks up allocation candidates, the aggregates of\nnested providers were assumed as the same as root providers. This\nmeans that the `GET /allocation_candidates API` ignored the\naggregates on the nested providers. This could result in the lack\nof allocation candidates when an aggregate is on a nested provider\nbut the aggregate is not on its root provider and the aggregate is\nspecified in the API by the `member_of` query parameter.\n\nThis patch fixes the bug changing it to consider the aggregates\nnot only on root rps but also on the nested rp itself and adds\na release note for this.\n\nThis is a backport from the following two patches on master of the\nextracted placement project.\n\n  - https://review.openstack.org/#/c/602638\n  - https://review.openstack.org/#/c/602639\n\nChange-Id: I28876cfbfaed4e2330df08ab0d1b09d19647b2a7\nCloses-Bug: #1792503\n'}, {'number': 2, 'created': '2018-10-09 10:02:37.000000000', 'files': ['nova/tests/functional/api/openstack/placement/fixtures/gabbits.py', 'nova/tests/functional/api/openstack/placement/gabbits/allocation-candidates-bug-1792503.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/a71bd00341ea5331b98393c658fb624da2fa14d7', 'message': 'Add alloc cands test with nested and aggregates\n\nWhen placement picks up allocation candidates, the aggregates of\nnested providers are assumed as the same as root providers. This\nmeans it ignores the aggregates of the nested provider itself.\nThis could result in the lack of allocation candidates when an\naggregate on a nested provider but not on the root has been\nspecified in the `member_of` query parameter.\n\nThis patch adds test cases for the bug. The fix is done in a\nfollow up.\n\nThis is a backport from the following patch on master of the\nextracted placement project.\n\n  - https://review.openstack.org/#/c/602638\n\nChange-Id: I28876cfbfaed4e2330df08ab0d1b09d19647b2a7\nCloses-Bug: #1792503\n'}]",5,607454,a71bd00341ea5331b98393c658fb624da2fa14d7,15,8,2,25625,,,0,"Add alloc cands test with nested and aggregates

When placement picks up allocation candidates, the aggregates of
nested providers are assumed as the same as root providers. This
means it ignores the aggregates of the nested provider itself.
This could result in the lack of allocation candidates when an
aggregate on a nested provider but not on the root has been
specified in the `member_of` query parameter.

This patch adds test cases for the bug. The fix is done in a
follow up.

This is a backport from the following patch on master of the
extracted placement project.

  - https://review.openstack.org/#/c/602638

Change-Id: I28876cfbfaed4e2330df08ab0d1b09d19647b2a7
Closes-Bug: #1792503
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/607454/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/placement/objects/resource_provider.py', 'nova/tests/functional/api/openstack/placement/fixtures/gabbits.py', 'placement-api-ref/source/parameters.yaml', 'releasenotes/notes/bug-1792503-member-of-5c10df94caf3bd08.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/allocation-candidates-bug-1792503.yaml']",5,b8b1f276a26d57dba832486e9184d90c11b8fa34,bug/1792503,"# Tests of allocation candidates API fixtures: - NUMAAggregateFixture defaults: request_headers: x-auth-token: admin accept: application/json openstack-api-version: placement 1.29 tests: - name: get allocation candidates without aggregate GET: /allocation_candidates?resources=VCPU:1 response_json_paths: $.allocation_requests.`len`: 4 $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA1_2_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_1_UUID']""].resources.VCPU: 1 - name: get allocation candidates with aggregate A GET: /allocation_candidates?resources=VCPU:1&member_of=$ENVIRON['AGGA_UUID'] response_json_paths: # Aggregate A is on the root rps (both cn1 and cn2) so it spans on the # whole tree. We have full allocations here. $.allocation_requests.`len`: 4 $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA1_2_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_2_UUID']""].resources.VCPU: 1 - name: get allocation candidates with aggregate B GET: /allocation_candidates?resources=VCPU:1&member_of=$ENVIRON['AGGB_UUID'] response_json_paths: # Aggregate B is on the root of cn2 so it spans on the # whole tree including rps of NUMA2_1 and NUMA2_2. $.allocation_requests.`len`: 2 $.allocation_requests..allocations[""$ENVIRON['NUMA2_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_2_UUID']""].resources.VCPU: 1 - name: get allocation candidates with aggregate C GET: /allocation_candidates?resources=VCPU:1&member_of=$ENVIRON['AGGC_UUID'] response_json_paths: # Aggregate C is *NOT* on the root, so we should get only NUMA1_1 # here that is only the rp in aggregate C. $.allocation_requests.`len`: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 - name: get allocation candidates with shared storage GET: /allocation_candidates?resources=VCPU:1,DISK_GB:1000 response_json_paths: # Since `members_of` query parameter is not specified, sharing rp 1 is # being shared with the *whole* trees of CN1 and CN2. Sharing rp 2 is # being shared with the *whole* tree of CN1. # As a result, there should be 6 allocation candidates: # [ # (numa1-1, ss1), (numa1-2, ss1), (numa2-1, ss1), (numa2-2, ss1), # (numa1-1, ss2), # ] $.allocation_requests.`len`: 6 $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: [1, 1] $.allocation_requests..allocations[""$ENVIRON['NUMA1_2_UUID']""].resources.VCPU: [1, 1] $.allocation_requests..allocations[""$ENVIRON['NUMA2_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_2_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['SS1_UUID']""].resources.DISK_GB: [1000, 1000, 1000, 1000] $.allocation_requests..allocations[""$ENVIRON['SS2_UUID']""].resources.DISK_GB: [1000, 1000] - name: get allocation candidates with shared storage with aggregate A GET: /allocation_candidates?resources=VCPU:1,DISK_GB:1000&member_of=$ENVIRON['AGGA_UUID'] response_json_paths: $.allocation_requests.`len`: 4 # Since aggregate A is specified, which is on the root CN1, sharing # rp 1 can be allocation candidates with the *whole* trees in CN1. # Sharing rp 2 can't in the allocation candidates since it is not # under aggregate A but under aggregate C. # As a result, there should be 4 allocation candidates: # [ # (numa1-1, ss1), (numa1-2, ss1), (numa2-1, ss1), (numa2-2, ss1) # ] $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA1_2_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_2_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['SS1_UUID']""].resources.DISK_GB: [1000, 1000, 1000, 1000] - name: get allocation candidates with shared storage with aggregate B GET: /allocation_candidates?resources=VCPU:1,DISK_GB:1000&member_of=$ENVIRON['AGGB_UUID'] response_json_paths: # We don't have shared disk in aggregate B. $.allocation_requests.`len`: 0 - name: get allocation candidates with shared storage with aggregate C GET: /allocation_candidates?resources=VCPU:1,DISK_GB:1000&member_of=$ENVIRON['AGGC_UUID'] response_json_paths: # Since aggregate C is specified, which is on *non-root*, NUMA1_1, # sharing provider 2 is not shared with the whole tree. It is shared # with rps only with aggregate C for their own (opposite to not on root). # As a result, there should be 1 allocation candidate: # [ # (numa1-1, ss2), # ] $.allocation_requests.`len`: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['SS2_UUID']""].resources.DISK_GB: 1000 ",,227,7
openstack%2Fnova~stable%2Frocky~Ib6fd2899340679421416801f7a1f72ce4ded884b,openstack/nova,stable/rocky,Ib6fd2899340679421416801f7a1f72ce4ded884b,Fix aggregate members in nested alloc candidates,ABANDONED,2018-10-09 10:02:37.000000000,2019-02-21 16:30:38.000000000,,"[{'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 11904}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 25625}]","[{'number': 1, 'created': '2018-10-09 10:02:37.000000000', 'files': ['nova/api/openstack/placement/objects/resource_provider.py', 'placement-api-ref/source/parameters.yaml', 'releasenotes/notes/bug-1792503-member-of-5c10df94caf3bd08.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/allocation-candidates-bug-1792503.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/b4c7831b7891188cd915199f5fc9210690248b0e', 'message': 'Fix aggregate members in nested alloc candidates\n\nWhen placement picks up allocation candidates, the aggregates of\nnested providers were assumed as the same as root providers. This\nmeans that the `GET /allocation_candidates API` ignored the\naggregates on the nested providers. This could result in the lack\nof allocation candidates when an aggregate is on a nested provider\nbut the aggregate is not on its root provider and the aggregate is\nspecified in the API by the `member_of` query parameter.\n\nThis patch fixes the bug changing it to consider the aggregates\nnot only on root rps but also on the nested rp itself and adds\na release note for this.\n\nThis is a backport from the following patch on master of the\nextracted placement project.\n\n  - https://review.openstack.org/#/c/602639\n\nChange-Id: Ib6fd2899340679421416801f7a1f72ce4ded884b\nCloses-Bug: #1792503\n'}]",0,608903,b4c7831b7891188cd915199f5fc9210690248b0e,13,10,1,25625,,,0,"Fix aggregate members in nested alloc candidates

When placement picks up allocation candidates, the aggregates of
nested providers were assumed as the same as root providers. This
means that the `GET /allocation_candidates API` ignored the
aggregates on the nested providers. This could result in the lack
of allocation candidates when an aggregate is on a nested provider
but the aggregate is not on its root provider and the aggregate is
specified in the API by the `member_of` query parameter.

This patch fixes the bug changing it to consider the aggregates
not only on root rps but also on the nested rp itself and adds
a release note for this.

This is a backport from the following patch on master of the
extracted placement project.

  - https://review.openstack.org/#/c/602639

Change-Id: Ib6fd2899340679421416801f7a1f72ce4ded884b
Closes-Bug: #1792503
",git fetch https://review.opendev.org/openstack/nova refs/changes/03/608903/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/placement/objects/resource_provider.py', 'placement-api-ref/source/parameters.yaml', 'releasenotes/notes/bug-1792503-member-of-5c10df94caf3bd08.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/allocation-candidates-bug-1792503.yaml']",4,b4c7831b7891188cd915199f5fc9210690248b0e,bug/1792503," $.allocation_requests.`len`: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 $.allocation_requests.`len`: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['SS2_UUID']""].resources.DISK_GB: 1000"," # --------------------- # Bug#1792503: It lacks allocation candidates when an aggregate on the # nested rp but not on the root rp has been specified in # the `member_of` query parameter. # --------------------- # $.allocation_requests.`len`: 1 # $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 $.allocation_requests.`len`: 0 # --------------------- # Bug#1792503: It lacks allocation candidates when an aggregate on the # nested rp but not on the root rp has been specified in # the `member_of` query parameter. # --------------------- # $.allocation_requests.`len`: 1 # $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 # $.allocation_requests..allocations[""$ENVIRON['SS2_UUID']""].resources.DISK_GB: 1000 $.allocation_requests.`len`: 0",47,24
openstack%2Fcharm-keystone~master~I6db8d006ceac7b61e69f547682c5a49d876cfec6,openstack/charm-keystone,master,I6db8d006ceac7b61e69f547682c5a49d876cfec6,Fix issue with crontab enablement,MERGED,2019-02-21 15:00:33.000000000,2019-02-21 16:20:58.000000000,2019-02-21 16:20:57.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 15:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/b427100ed5c2d9b09785f936930bcc675f38aa00', 'message': 'Switch contexts to use juju leadership\n\nThe token flush and token rotate crontabs are re-written when the\nleader unit changes inline with Juju leadership management.\n\nAlign contexts used to generate crontabs with Juju leadership\nstatus, rather than corosync/pacemaker.\n\nChange-Id: I6db8d006ceac7b61e69f547682c5a49d876cfec6\nCloses-Bug: 1816807\n'}, {'number': 2, 'created': '2019-02-21 15:11:39.000000000', 'files': ['unit_tests/test_keystone_contexts.py', '.pydevproject', 'hooks/keystone_context.py'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/1a07a7e65731ee2585818f998638ad71d91662a0', 'message': ""Fix issue with crontab enablement\n\nThe token flush and token rotate crontabs are re-written when the\nleader unit changes inline with Juju leadership management.\n\nAlign contexts used to generate crontabs with Juju leadership\nstatus, rather than corosync/pacemaker.\n\nCorrect use of OpenStackCompareReleases to ensure that releases\nbetween ocata and queens don't automatically enable fernet\ntoken behaviour.\n\nChange-Id: I6db8d006ceac7b61e69f547682c5a49d876cfec6\nCloses-Bug: 1816807\n""}]",0,638431,1a07a7e65731ee2585818f998638ad71d91662a0,10,3,2,935,,,0,"Fix issue with crontab enablement

The token flush and token rotate crontabs are re-written when the
leader unit changes inline with Juju leadership management.

Align contexts used to generate crontabs with Juju leadership
status, rather than corosync/pacemaker.

Correct use of OpenStackCompareReleases to ensure that releases
between ocata and queens don't automatically enable fernet
token behaviour.

Change-Id: I6db8d006ceac7b61e69f547682c5a49d876cfec6
Closes-Bug: 1816807
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/31/638431/1 && git format-patch -1 --stdout FETCH_HEAD,"['.pydevproject', 'unit_tests/test_keystone_contexts.py', 'hooks/keystone_context.py']",3,b427100ed5c2d9b09785f936930bcc675f38aa00,bug/1816807," is_leader, 'token_flush': (not fernet_enabled() and is_leader()) 'enabled': (fernet_enabled() and is_leader()),"," DC_RESOURCE_NAME, is_elected_leader, 'token_flush': (not fernet_enabled() and is_elected_leader(DC_RESOURCE_NAME)) 'enabled': (fernet_enabled() and is_elected_leader(DC_RESOURCE_NAME)),",22,20
openstack%2Fcharm-vault~stable%2F18.11~I6a771090e320404c605d2170c7915c3c22a3ea2c,openstack/charm-vault,stable/18.11,I6a771090e320404c605d2170c7915c3c22a3ea2c,Correct key name for PKI backend TTL,MERGED,2019-02-20 15:37:08.000000000,2019-02-21 16:20:14.000000000,2019-02-21 16:20:14.000000000,"[{'_account_id': 935}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-20 15:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/8f490507bce678c9a2d79bff5efb04a852f19118', 'message': ""Correct key name for PKI backend TTL\n\nSwitch max-lease-ttl -> max_lease_ttl inline with Vault API\ndocs to ensure that certs can be issued for more than 30 days.\n\nExisting deployments with PKI enabled will be re-tuned to\nset max_lease_ttl to 10 years, correcting any existing PKI\nenablement.\n\nCertificates must be re-issued to use the TTL as provided\nduring upload of the signed CSR for an Intermediate certificate.\n\nFor deploys using the internally signed Root CA, the root\nCA must be re-generated using the 'disable-pki' and\n'generate-root-ca' actions.\n\nChange-Id: I6a771090e320404c605d2170c7915c3c22a3ea2c\nCloses-Bug: 1788945\n(cherry picked from commit 6f043bb7ca8710dd7c1746297b6f98f743c3499a)\n""}, {'number': 2, 'created': '2019-02-21 14:20:13.000000000', 'files': ['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/actions/actions.py', 'src/tests/tests.yaml', 'src/reactive/vault_handlers.py', 'unit_tests/test_lib_charm_vault_pki.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/8f8e4bbef4f525599d5ae65922b24da9358a07ef', 'message': ""Correct key name for PKI backend TTL\n\nSwitch max-lease-ttl -> max_lease_ttl inline with Vault API\ndocs to ensure that certs can be issued for more than 30 days.\n\nExisting deployments with PKI enabled will be re-tuned to\nset max_lease_ttl to 10 years, correcting any existing PKI\nenablement.\n\nCertificates must be re-issued to use the TTL as provided\nduring upload of the signed CSR for an Intermediate certificate.\n\nFor deploys using the internally signed Root CA, the root\nCA must be re-generated using the 'disable-pki' and\n'generate-root-ca' actions.\n\nChange-Id: I6a771090e320404c605d2170c7915c3c22a3ea2c\nCloses-Bug: 1788945\n(cherry picked from commit 6f043bb7ca8710dd7c1746297b6f98f743c3499a)\n""}]",0,638181,8f8e4bbef4f525599d5ae65922b24da9358a07ef,15,4,2,7730,,,0,"Correct key name for PKI backend TTL

Switch max-lease-ttl -> max_lease_ttl inline with Vault API
docs to ensure that certs can be issued for more than 30 days.

Existing deployments with PKI enabled will be re-tuned to
set max_lease_ttl to 10 years, correcting any existing PKI
enablement.

Certificates must be re-issued to use the TTL as provided
during upload of the signed CSR for an Intermediate certificate.

For deploys using the internally signed Root CA, the root
CA must be re-generated using the 'disable-pki' and
'generate-root-ca' actions.

Change-Id: I6a771090e320404c605d2170c7915c3c22a3ea2c
Closes-Bug: 1788945
(cherry picked from commit 6f043bb7ca8710dd7c1746297b6f98f743c3499a)
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/81/638181/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/actions/actions.py', 'src/reactive/vault_handlers.py', 'src/tests/tests.yaml', 'unit_tests/test_lib_charm_vault_pki.py']",6,8f490507bce678c9a2d79bff5efb04a852f19118,bug/1813180," config={'max_lease_ttl': 42}, config={'max_lease_ttl': '87600h'}, @patch.object(vault_pki.vault, 'get_local_client') @patch.object(vault_pki.vault, 'is_backend_mounted') def test_tune_secret_backend(self, is_backend_mounted, get_local_client): is_backend_mounted.return_value = True mock_client = mock.MagicMock() get_local_client.return_value = mock_client vault_pki.tune_pki_backend(ttl='3456h') is_backend_mounted.assert_called_with(mock_client, vault_pki.CHARM_PKI_MP) mock_client.tune_secret_backend.assert_called_with( backend_type='pki', mount_point=vault_pki.CHARM_PKI_MP, max_lease_ttl='3456h' )"," config={'max-lease-ttl': 42}, config={'max-lease-ttl': '87600h'},",56,4
openstack%2Fcharm-vault~stable%2F18.11~If6153377cd516ed8121e09da627905036128a6ec,openstack/charm-vault,stable/18.11,If6153377cd516ed8121e09da627905036128a6ec,Improve Vault startup handling,MERGED,2019-02-21 08:58:53.000000000,2019-02-21 16:18:25.000000000,2019-02-21 16:18:25.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 29191}]","[{'number': 1, 'created': '2019-02-21 08:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/d9c9268eeace35723b425a7f92315bda356cb1fe', 'message': 'Improve Vault startup handling\n\nThe `@when_file_changed` decorator is not considered reliable.\nAdditionally, the way it was being used led to a race condition where\nthe Vault service might never get started. This also detects and reports\nin a better way if Vault fails to start.\n\nChange-Id: If6153377cd516ed8121e09da627905036128a6ec\n(cherry picked from commit 102b222fcec550d7b30eb10583887fa212c61eff)\n'}, {'number': 2, 'created': '2019-02-21 09:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/6264007ea3367fec2c885a0e0b25ba58dbbaba19', 'message': 'Improve Vault startup handling\n\nThe `@when_file_changed` decorator is not considered reliable.\nAdditionally, the way it was being used led to a race condition where\nthe Vault service might never get started. This also detects and reports\nin a better way if Vault fails to start.\n\nConflicts:\n  unit_tests/test_reactive_vault_handlers.py\n    A test_tune_pki_backend() test was introduced by\n    (6f043bb7ca8710dd7c1746297b6f98f743c3499a). I decided to now\n    backport that change since it includes to much changes and some\n    need actions from operators (see: genereate-root-ca)\n\nChange-Id: If6153377cd516ed8121e09da627905036128a6ec\n(cherry picked from commit 102b222fcec550d7b30eb10583887fa212c61eff)\n'}, {'number': 3, 'created': '2019-02-21 09:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/6e99793a8f6f15cc3ffb05b6487725ed1a07192e', 'message': 'Improve Vault startup handling\n\nThe `@when_file_changed` decorator is not considered reliable.\nAdditionally, the way it was being used led to a race condition where\nthe Vault service might never get started. This also detects and reports\nin a better way if Vault fails to start.\n\nConflicts:\n  unit_tests/test_reactive_vault_handlers.py\n    A test_tune_pki_backend() test was introduced by\n    (6f043bb7ca8710dd7c1746297b6f98f743c3499a). I decided to not\n    backport this change since it includes too many changes and some\n    need actions from operators (see: genereate-root-ca)\n\nChange-Id: If6153377cd516ed8121e09da627905036128a6ec\n(cherry picked from commit 102b222fcec550d7b30eb10583887fa212c61eff)\n'}, {'number': 4, 'created': '2019-02-21 13:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/9dbd6769a4501b7394185a38c170990d24079f41', 'message': 'Improve Vault startup handling\n\nThe `@when_file_changed` decorator is not considered reliable.\nAdditionally, the way it was being used led to a race condition where\nthe Vault service might never get started. This also detects and reports\nin a better way if Vault fails to start.\n\nConflicts:\n  unit_tests/test_reactive_vault_handlers.py\n    A test_tune_pki_backend() test was introduced by\n    (6f043bb7ca8710dd7c1746297b6f98f743c3499a). I decided to not\n    backport this change since it includes too many changes and some\n    need actions from operators (see: genereate-root-ca)\n\nRelated-To: 1813180\nChange-Id: If6153377cd516ed8121e09da627905036128a6ec\n(cherry picked from commit 102b222fcec550d7b30eb10583887fa212c61eff)\n'}, {'number': 5, 'created': '2019-02-21 14:20:13.000000000', 'files': ['unit_tests/test_reactive_vault_handlers.py', 'src/tox.ini', 'src/reactive/vault_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/1d10e93ea132e5c43acfcccb2d3a6756e2541659', 'message': 'Improve Vault startup handling\n\nThe `@when_file_changed` decorator is not considered reliable.\nAdditionally, the way it was being used led to a race condition where\nthe Vault service might never get started. This also detects and reports\nin a better way if Vault fails to start.\n\nConflicts:\n  unit_tests/test_reactive_vault_handlers.py\n    A test_tune_pki_backend() test was introduced by\n    (6f043bb7ca8710dd7c1746297b6f98f743c3499a). But because of the\n    race condition in CI I had to change the order of the patches and\n    put that one at the bottom.\n\nChange-Id: If6153377cd516ed8121e09da627905036128a6ec\n(cherry picked from commit 102b222fcec550d7b30eb10583887fa212c61eff)\n'}]",0,638366,1d10e93ea132e5c43acfcccb2d3a6756e2541659,18,4,5,7730,,,0,"Improve Vault startup handling

The `@when_file_changed` decorator is not considered reliable.
Additionally, the way it was being used led to a race condition where
the Vault service might never get started. This also detects and reports
in a better way if Vault fails to start.

Conflicts:
  unit_tests/test_reactive_vault_handlers.py
    A test_tune_pki_backend() test was introduced by
    (6f043bb7ca8710dd7c1746297b6f98f743c3499a). But because of the
    race condition in CI I had to change the order of the patches and
    put that one at the bottom.

Change-Id: If6153377cd516ed8121e09da627905036128a6ec
(cherry picked from commit 102b222fcec550d7b30eb10583887fa212c61eff)
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/66/638366/3 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_reactive_vault_handlers.py', 'src/tox.ini', 'src/reactive/vault_handlers.py']",3,d9c9268eeace35723b425a7f92315bda356cb1fe,bug/1813180,"import traceback any_file_changed, if any_file_changed([VAULT_CONFIG, VAULT_SYSTEMD_CONFIG]): # force a restart if config has changed clear_flag('started')@when('configured') @when_not('started') def start_vault(): # start or restart vault @tenacity.retry(wait=tenacity.wait_exponential(multiplier=1, max=10), stop=tenacity.stop_after_attempt(10), retry=tenacity.retry_if_result(lambda b: not b)) def _check_vault_running(): return service_running('vault') if _check_vault_running(): set_flag('started') clear_flag('failed.to.start') if config('totally-unsecure-auto-unlock'): vault.prepare_vault() else: set_flag('failed.to.start') if is_flag_set('failed.to.start'): status_set(""blocked"", ""Vault failed to start; check journalctl -u vault"") return try: health = vault.get_vault_health() except Exception: log(traceback.format_exc(), level=ERROR) status_set('blocked', 'Vault health check failed') return"," when_file_changed,@when_file_changed(VAULT_CONFIG, VAULT_SYSTEMD_CONFIG) def file_change_auto_unlock_mode(): log(""Calling opportunistic_restart"", level=DEBUG) if config('totally-unsecure-auto-unlock'): vault.prepare_vault() health = vault.get_vault_health()",53,7
openstack%2Fsushy-tools~master~I4b8710a54ef86876f1e84352ffd48d8aa02be657,openstack/sushy-tools,master,I4b8710a54ef86876f1e84352ffd48d8aa02be657,Move to zuulv3,MERGED,2019-01-28 10:41:27.000000000,2019-02-21 16:16:39.000000000,2019-02-21 16:16:39.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 26340}]","[{'number': 1, 'created': '2019-01-28 10:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/792b6432ff7c31371b065c6c3cb98369b77328e2', 'message': 'Move to zuulv3\n\nChange sushy-tools job to zuulv3\n\nChange-Id: I4b8710a54ef86876f1e84352ffd48d8aa02be657\n'}, {'number': 2, 'created': '2019-01-28 12:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/b369cf7721b667f51b6141005371d3cf9631ec87', 'message': 'Move to zuulv3\n\nChange sushy-tools job to zuulv3\n\nChange-Id: I4b8710a54ef86876f1e84352ffd48d8aa02be657\n'}, {'number': 3, 'created': '2019-02-08 10:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/86ee8487df69a40213a21924e3bf444f75f67005', 'message': 'Move to zuulv3\n\nChange sushy-tools job to zuulv3 and use ironic-base job\n\nDepends-On: https://review.openstack.org/#/c/630100/\nChange-Id: I4b8710a54ef86876f1e84352ffd48d8aa02be657\n'}, {'number': 4, 'created': '2019-02-14 10:03:40.000000000', 'files': ['playbooks/legacy/sushy-tools-tempest-dsvm-ironic-ipa-partition-redfish-src/run.yaml', 'zuul.d/sushy-tools-jobs.yaml', 'zuul.d/project.yaml', 'zuul.d/legacy-sushy-tools-jobs.yaml', 'playbooks/legacy/sushy-tools-tempest-dsvm-ironic-ipa-partition-redfish-src/post.yaml'], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/2709e7b74d97ca3afc33147d65574bc7a2db0f0f', 'message': 'Move to zuulv3\n\nChange sushy-tools job to zuulv3 and use ironic-base job\n\nChange-Id: I4b8710a54ef86876f1e84352ffd48d8aa02be657\n'}]",12,633473,2709e7b74d97ca3afc33147d65574bc7a2db0f0f,19,5,4,15519,,,0,"Move to zuulv3

Change sushy-tools job to zuulv3 and use ironic-base job

Change-Id: I4b8710a54ef86876f1e84352ffd48d8aa02be657
",git fetch https://review.opendev.org/openstack/sushy-tools refs/changes/73/633473/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/legacy/sushy-tools-tempest-dsvm-ironic-ipa-partition-redfish-src/run.yaml', 'zuul.d/project.yaml', 'zuul.d/sushy-tools-jobs.yaml', 'zuul.d/legacy-sushy-tools-jobs.yaml', 'playbooks/legacy/sushy-tools-tempest-dsvm-ironic-ipa-partition-redfish-src/post.yaml']",5,792b6432ff7c31371b065c6c3cb98369b77328e2,zuulv3,,- hosts: primary tasks: - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=/logs/** - --include=*/ - --exclude=* - --prune-empty-dirs ,89,180
openstack%2Fpython-novaclient~master~I007d9a68309b0d3aa85a4edf5026043154d4f42a,openstack/python-novaclient,master,I007d9a68309b0d3aa85a4edf5026043154d4f42a,API microversion 2.69: Handles Down Cells,MERGED,2018-07-02 13:49:58.000000000,2019-02-21 16:11:32.000000000,2019-02-21 16:11:32.000000000,"[{'_account_id': 679}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 22348}, {'_account_id': 26936}]","[{'number': 1, 'created': '2018-07-02 13:49:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/cd2a286b3e1aac2a040516ca6c1b33478a659b00', 'message': '[WIP/POC] Client changes for down cell\n\nThis patch explicitly points out the change needed in those\ncases where the server response has the flavor key missing.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I007d9a68309b0d3aa85a4edf5026043154d4f42a\n'}, {'number': 2, 'created': '2018-08-14 09:44:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/49192023cd93aa87e42a0dea321f3966264eaa2f', 'message': '[WIP/POC] Client changes for down cell\n\nThis patch explicitly points out the change needed in those\ncases where the server response has the flavor key missing.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I007d9a68309b0d3aa85a4edf5026043154d4f42a\n'}, {'number': 3, 'created': '2018-08-14 13:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/aecb3aaece6d7a5316e08e6769016283d106969a', 'message': 'Client changes for handling-down-cell with microversion bump\n\nThis patch explicitly points out the change needed while\nforming the detailed lists for embedded flavor information.\nIn those cases where the server response for nova list\nhas the flavor key missing for the instances in the down cell,\nthe servers will be skipped.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I007d9a68309b0d3aa85a4edf5026043154d4f42a\n'}, {'number': 4, 'created': '2018-12-10 17:53:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/7183ac235ed1af487899159b29efcf74201ed63e', 'message': 'API microversion 2.68: Handles Down Cells\n\nThis patch explicitly points out the change needed while\nforming the detailed lists for embedded flavor information.\nIn those cases where the server response for nova list\nhas the flavor key missing for the instances in the down cell,\nthe servers will be skipped.\n\nDepends-On: https://review.openstack.org/591657/\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I007d9a68309b0d3aa85a4edf5026043154d4f42a\n'}, {'number': 5, 'created': '2019-02-12 23:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/00c87623a29e539b2f67db73ffc6dbba22c9ec52', 'message': 'API microversion 2.69: Handles Down Cells\n\nThis patch explicitly points out the change needed while\nforming the detailed lists for embedded flavor information.\nIn those cases where the server response for nova list\nhas the flavor key missing for the instances in the down cell,\nthe servers will be skipped.\n\nDepends-On: https://review.openstack.org/591657/\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I007d9a68309b0d3aa85a4edf5026043154d4f42a\n'}, {'number': 6, 'created': '2019-02-12 23:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/0a6dfa112bee27188479439c0881ec482399bd57', 'message': 'API microversion 2.69: Handles Down Cells\n\nThis patch explicitly points out the change needed while\nforming the detailed lists for embedded flavor information.\nIn those cases where the server response for nova list\nhas the flavor key missing for the instances in the down cell,\nthe servers will be skipped.\n\nDepends-On: https://review.openstack.org/591657/\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I007d9a68309b0d3aa85a4edf5026043154d4f42a\n'}, {'number': 7, 'created': '2019-02-15 19:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/53643cd91b4d5f8fcbea1a0d161f54969e04a7e5', 'message': 'API microversion 2.69: Handles Down Cells\n\nThis patch explicitly points out the change needed while\nforming the detailed lists for embedded flavor information.\nIn those cases where the server response for nova list\nhas the flavor key missing for the instances in the down cell,\nthe servers will be skipped.\n\nDepends-On: https://review.openstack.org/591657/\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I007d9a68309b0d3aa85a4edf5026043154d4f42a\n'}, {'number': 8, 'created': '2019-02-18 13:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/ebc455b5c04928eeccf737608f75d9efb1f27eea', 'message': 'API microversion 2.69: Handles Down Cells\n\nThis patch explicitly points out the change needed while\nforming the detailed lists for embedded flavor information.\nIn those cases where the server response for nova list\nhas the flavor key missing for the instances in the down cell,\nthe servers will be skipped.\n\nDepends-On: https://review.openstack.org/591657/\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I007d9a68309b0d3aa85a4edf5026043154d4f42a\n'}, {'number': 9, 'created': '2019-02-18 18:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/4cf3af931b6ce702b9957737891e02716055057a', 'message': 'API microversion 2.69: Handles Down Cells\n\nThis patch explicitly points out the change needed while\nforming the detailed lists for embedded flavor information.\nIn those cases where the server response for nova list\nhas the flavor key missing for the instances in the down cell,\nthe servers will be skipped.\n\nDepends-On: https://review.openstack.org/591657/\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I007d9a68309b0d3aa85a4edf5026043154d4f42a\n'}, {'number': 10, 'created': '2019-02-20 16:58:50.000000000', 'files': ['novaclient/tests/unit/v2/fakes.py', 'novaclient/v2/shell.py', 'novaclient/__init__.py', 'releasenotes/notes/bp-handling-down-cell-728cdb1efd1ea75b.yaml', 'doc/source/cli/nova.rst', 'novaclient/tests/unit/v2/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/14a45183ee9558281fd38a60471adf5db55637c8', 'message': 'API microversion 2.69: Handles Down Cells\n\nThis patch explicitly points out the change needed while\nforming the detailed lists for embedded flavor information.\nIn those cases where the server response for nova list\nhas the flavor key missing for the instances in the down cell,\nthe servers will be skipped.\n\nDepends-On: https://review.openstack.org/591657/\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I007d9a68309b0d3aa85a4edf5026043154d4f42a\n'}]",34,579563,14a45183ee9558281fd38a60471adf5db55637c8,46,5,10,26936,,,0,"API microversion 2.69: Handles Down Cells

This patch explicitly points out the change needed while
forming the detailed lists for embedded flavor information.
In those cases where the server response for nova list
has the flavor key missing for the instances in the down cell,
the servers will be skipped.

Depends-On: https://review.openstack.org/591657/

Related to blueprint handling-down-cell

Change-Id: I007d9a68309b0d3aa85a4edf5026043154d4f42a
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/63/579563/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/v2/shell.py', 'novaclient/__init__.py']",2,cd2a286b3e1aac2a040516ca6c1b33478a659b00,bp/handling-down-cell,"API_MAX_VERSION = api_versions.APIVersion(""2.64"")","API_MAX_VERSION = api_versions.APIVersion(""2.63"")",7,2
openstack%2Fpython-novaclient~master~I2e9b3c6a256509c045966035da24d58628f1b33b,openstack/python-novaclient,master,I2e9b3c6a256509c045966035da24d58628f1b33b,Make Server.networks use a predictable sort order,MERGED,2019-02-20 16:58:50.000000000,2019-02-21 16:11:30.000000000,2019-02-21 16:11:30.000000000,"[{'_account_id': 679}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 22348}, {'_account_id': 26936}]","[{'number': 1, 'created': '2019-02-20 16:58:50.000000000', 'files': ['novaclient/v2/servers.py', 'releasenotes/notes/server-networks-sorted-1d3a7f1c1f88e846.yaml', 'novaclient/tests/unit/v2/test_servers.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/874b03068f1682cb0fe94d59f64e858b1514308d', 'message': 'Make Server.networks use a predictable sort order\n\nThis changes the Server.networks property method to return\nan OrderedDict where the keys (network labels) are sorted\nwhich will allow for a predictable sort order on the resulting\nnetworks attached to a Server resource.\n\nThis affects the output of ""nova list"" and ""nova show"" commands\nso a simple release note is added to mention the change.\n\nChange-Id: I2e9b3c6a256509c045966035da24d58628f1b33b\n'}]",3,638214,874b03068f1682cb0fe94d59f64e858b1514308d,21,5,1,6873,,,0,"Make Server.networks use a predictable sort order

This changes the Server.networks property method to return
an OrderedDict where the keys (network labels) are sorted
which will allow for a predictable sort order on the resulting
networks attached to a Server resource.

This affects the output of ""nova list"" and ""nova show"" commands
so a simple release note is added to mention the change.

Change-Id: I2e9b3c6a256509c045966035da24d58628f1b33b
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/14/638214/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/v2/servers.py', 'releasenotes/notes/server-networks-sorted-1d3a7f1c1f88e846.yaml', 'novaclient/tests/unit/v2/test_servers.py']",3,874b03068f1682cb0fe94d59f64e858b1514308d,bp/handling-down-cell," # The networks should be sorted. networks = server.networks self.assertEqual(2, len(networks)) labels = list(networks) # returns the dict keys self.assertEqual('private', labels[0]) self.assertEqual('public', labels[1])",,22,2
openstack%2Fcharm-nova-cloud-controller~master~I345b56e347b63650ee3df07773ccb2e333610355,openstack/charm-nova-cloud-controller,master,I345b56e347b63650ee3df07773ccb2e333610355,Implement new option: enable_new_services,MERGED,2019-02-19 14:16:24.000000000,2019-02-21 16:09:09.000000000,2019-02-21 16:09:09.000000000,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-19 14:16:24.000000000', 'files': ['templates/liberty/nova.conf', 'templates/juno/nova.conf', 'templates/pike/nova.conf', 'config.yaml', 'hooks/nova_cc_context.py', 'templates/icehouse/nova.conf', 'unit_tests/test_nova_cc_contexts.py', 'templates/rocky/nova.conf', 'templates/newton/nova.conf', 'templates/ocata/nova.conf', 'templates/kilo/nova.conf', 'templates/mitaka/nova.conf'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/5f21ea7124882f9f3ef4654d6b4421531d229b41', 'message': 'Implement new option: enable_new_services\n\nThis change implements a new option in config.yaml that allows\nservices to come up disabled and be manually enabled later.\n\nChange-Id: I345b56e347b63650ee3df07773ccb2e333610355\nCloses-Bug: #1758776\n'}]",0,637853,5f21ea7124882f9f3ef4654d6b4421531d229b41,10,3,1,29625,,,0,"Implement new option: enable_new_services

This change implements a new option in config.yaml that allows
services to come up disabled and be manually enabled later.

Change-Id: I345b56e347b63650ee3df07773ccb2e333610355
Closes-Bug: #1758776
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/53/637853/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/liberty/nova.conf', 'templates/juno/nova.conf', 'templates/pike/nova.conf', 'config.yaml', 'hooks/nova_cc_context.py', 'templates/icehouse/nova.conf', 'unit_tests/test_nova_cc_contexts.py', 'templates/rocky/nova.conf', 'templates/newton/nova.conf', 'templates/ocata/nova.conf', 'templates/kilo/nova.conf', 'templates/mitaka/nova.conf']",12,5f21ea7124882f9f3ef4654d6b4421531d229b41,bug/1758776,enable_new_services = {{ enable_new_services }},,30,2
openstack%2Fopenstack-virtual-baremetal~master~If2cf598bf062452f78c717b178cb3a294df08a8a,openstack/openstack-virtual-baremetal,master,If2cf598bf062452f78c717b178cb3a294df08a8a,Make relative import py2/3 compatible,ABANDONED,2019-01-28 16:40:32.000000000,2019-02-21 16:08:58.000000000,,"[{'_account_id': 6928}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-01-28 16:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-virtual-baremetal/commit/106e7953cc6080b33861e6c627710a2d8817ba5c', 'message': 'Make relative import py2/3 compatible\n\n9e7ee5dd5c399fb6edeee771d9027846c4bdd1b6 made the import work in\nunit tests, but not when run in actual use. This change makes the\nrelative import explicit which will work in both versions and both\nenvironments.\n\nChange-Id: If2cf598bf062452f78c717b178cb3a294df08a8a\n'}, {'number': 2, 'created': '2019-01-28 16:59:31.000000000', 'files': ['openstack_virtual_baremetal/deploy.py'], 'web_link': 'https://opendev.org/openstack/openstack-virtual-baremetal/commit/babc1a8bf7a1c7267c991f95910adc1240ea7828', 'message': 'Make relative import py2/3 compatible\n\n9e7ee5dd5c399fb6edeee771d9027846c4bdd1b6 made the import work in\nunit tests, but not when run in actual use. This change makes the\nrelative import explicit which will work in both versions and both\nenvironments.\n\n\nChange-Id: If2cf598bf062452f78c717b178cb3a294df08a8a\n'}]",0,633550,babc1a8bf7a1c7267c991f95910adc1240ea7828,8,4,2,6928,,,0,"Make relative import py2/3 compatible

9e7ee5dd5c399fb6edeee771d9027846c4bdd1b6 made the import work in
unit tests, but not when run in actual use. This change makes the
relative import explicit which will work in both versions and both
environments.


Change-Id: If2cf598bf062452f78c717b178cb3a294df08a8a
",git fetch https://review.opendev.org/openstack/openstack-virtual-baremetal refs/changes/50/633550/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_virtual_baremetal/deploy.py'],1,106e7953cc6080b33861e6c627710a2d8817ba5c,,from . import auth,from openstack_virtual_baremetal import auth,1,1
openstack%2Foslo-specs~master~Iabe22dca0a913d942b9f325e93630f6fd4c26fb7,openstack/oslo-specs,master,Iabe22dca0a913d942b9f325e93630f6fd4c26fb7,Add co-owned library exception to feature freeze policy,ABANDONED,2019-02-18 17:06:57.000000000,2019-02-21 16:08:32.000000000,,"[{'_account_id': 6928}, {'_account_id': 8770}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-18 17:06:57.000000000', 'files': ['specs/policy/feature-freeze.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/e65ff452f85da7d280fa99a05763706ae87b6352', 'message': ""Add co-owned library exception to feature freeze policy\n\nCo-owned libraries generally function a bit differently from the\nusual oslo.* libraries. Specifically, they are non-client libraries\nand should observe the regular feature freeze for that type of library.\nThere isn't a need for the additional adoption time for features in\nthese libraries so the reasoning behind the Oslo feature freeze date\ndoesn't apply.\n\nThis change adds an exception to the feature freeze policy to reflect\nthe above logic.\n\nChange-Id: Iabe22dca0a913d942b9f325e93630f6fd4c26fb7\n""}]",0,637588,e65ff452f85da7d280fa99a05763706ae87b6352,4,3,1,6928,,,0,"Add co-owned library exception to feature freeze policy

Co-owned libraries generally function a bit differently from the
usual oslo.* libraries. Specifically, they are non-client libraries
and should observe the regular feature freeze for that type of library.
There isn't a need for the additional adoption time for features in
these libraries so the reasoning behind the Oslo feature freeze date
doesn't apply.

This change adds an exception to the feature freeze policy to reflect
the above logic.

Change-Id: Iabe22dca0a913d942b9f325e93630f6fd4c26fb7
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/88/637588/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/policy/feature-freeze.rst'],1,e65ff452f85da7d280fa99a05763706ae87b6352,ff-co-owned,"It will also not apply to any co-owned libraries (e.g. pycadf or castellan, which are co-owned with the Keystone and Barbican teams respectively). Most, if not all, of these libraries function more as non-client libraries than as Oslo-specific libraries and thus don't need the additional adoption time allowed by this policy. ",,6,0
openstack%2Ftripleo-common~master~I465bcf9358bf85dd8e7f4bd199b5dcee703b8ab4,openstack/tripleo-common,master,I465bcf9358bf85dd8e7f4bd199b5dcee703b8ab4,image-serve: redirect root to /v2,MERGED,2019-02-16 22:37:13.000000000,2019-02-21 16:08:31.000000000,2019-02-21 16:08:31.000000000,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 6926}, {'_account_id': 13039}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-16 22:37:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2c334fe2c1972ac4567fcc78fe9d44d8c02ced0f', 'message': ""image-serve: redirect root to /v2\n\nNobody needs to see the default apache page, let's just redirect to v2\nso operators aren't confused.\n\nChange-Id: I465bcf9358bf85dd8e7f4bd199b5dcee703b8ab4\n""}, {'number': 2, 'created': '2019-02-18 13:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7a1b7368da8a36a8634d68850db2b4f3fdf73e99', 'message': ""image-serve: redirect root to /v2\n\nNobody needs to see the default apache page, let's just redirect to v2\nso operators aren't confused.\n\nChange-Id: I465bcf9358bf85dd8e7f4bd199b5dcee703b8ab4\n""}, {'number': 3, 'created': '2019-02-18 13:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9b93525a0da679f2c704e6090a49081c75390042', 'message': ""image-serve: redirect root to /v2\n\nNobody needs to see the default apache page, let's just redirect to v2\nso operators aren't confused.\n\nChange-Id: I465bcf9358bf85dd8e7f4bd199b5dcee703b8ab4\n""}, {'number': 4, 'created': '2019-02-20 13:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b6a6a867f646f6d147275b00cb7352753d83847b', 'message': ""image-serve: redirect root to /v2\n\nNobody needs to see the default apache page, let's just redirect to v2\nso operators aren't confused.\n\nChange-Id: I465bcf9358bf85dd8e7f4bd199b5dcee703b8ab4\n""}, {'number': 5, 'created': '2019-02-21 09:56:46.000000000', 'files': ['roles/tripleo-image-serve/templates/image-serve.conf.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/bd24d3069ceeedfc315ddc39bcb57b0e78647400', 'message': ""image-serve: redirect root to /v2\n\nNobody needs to see the default apache page, let's just redirect to v2\nso operators aren't confused.\n\nChange-Id: I465bcf9358bf85dd8e7f4bd199b5dcee703b8ab4\n""}]",1,637404,bd24d3069ceeedfc315ddc39bcb57b0e78647400,41,7,5,3153,,,0,"image-serve: redirect root to /v2

Nobody needs to see the default apache page, let's just redirect to v2
so operators aren't confused.

Change-Id: I465bcf9358bf85dd8e7f4bd199b5dcee703b8ab4
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/04/637404/4 && git format-patch -1 --stdout FETCH_HEAD,['roles/tripleo-image-serve/templates/image-serve.conf.j2'],1,2c334fe2c1972ac4567fcc78fe9d44d8c02ced0f,image, RedirectMatch ^/$ /v2,,1,0
openstack%2Ftripleo-heat-templates~master~Id9ec9cbe9f879c2f437b234742118763d6d0f535,openstack/tripleo-heat-templates,master,Id9ec9cbe9f879c2f437b234742118763d6d0f535,Deprecate Docker,MERGED,2019-02-19 15:44:41.000000000,2019-02-21 16:08:29.000000000,2019-02-21 16:08:29.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-19 15:44:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c55d0a1f05232af16e8d87ec10a5f2c86cc2acc7', 'message': 'Deprecate Docker\n\nDocker is deprecated in Stein and will be removed in Train.\nIt is being replaced by Podman and Buildah.\n\nblueprint podman-support\nChange-Id: Id9ec9cbe9f879c2f437b234742118763d6d0f535\n'}, {'number': 2, 'created': '2019-02-19 23:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ea25c20496ff3bdcdb35edf8bbb7b942dcf0a778', 'message': 'Deprecate Docker\n\nDocker is deprecated in Stein and will be removed in Train.\nIt is being replaced by Podman and Buildah.\n\nblueprint podman-support\nChange-Id: Id9ec9cbe9f879c2f437b234742118763d6d0f535\n'}, {'number': 3, 'created': '2019-02-20 13:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/189c10ad877975d24ce3aaa8383486e7e7c6168e', 'message': 'Deprecate Docker\n\nDocker is deprecated in Stein and will be removed in Train.\nIt is being replaced by Podman and Buildah.\n\nblueprint podman-support\nChange-Id: Id9ec9cbe9f879c2f437b234742118763d6d0f535\n'}, {'number': 4, 'created': '2019-02-20 21:58:28.000000000', 'files': ['environments/docker-uc-light.yaml', 'environments/kubernetes.yaml', 'environments/docker.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'environments/openshift.yaml', 'releasenotes/notes/deprecate_docker_all-40eb568c9234a3d8.yaml', 'deployment/deprecated/docker/docker-registry-baremetal-ansible.yaml', 'deployment/deprecated/docker/docker-baremetal-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/26a3d4336cfc6764e24877e3b5ae02a5e072f5a2', 'message': 'Deprecate Docker\n\nDocker is deprecated in Stein and will be removed in Train.\nIt is being replaced by Podman and Buildah.\n\nblueprint podman-support\nChange-Id: Id9ec9cbe9f879c2f437b234742118763d6d0f535\n'}]",0,637915,26a3d4336cfc6764e24877e3b5ae02a5e072f5a2,20,5,4,3153,,,0,"Deprecate Docker

Docker is deprecated in Stein and will be removed in Train.
It is being replaced by Podman and Buildah.

blueprint podman-support
Change-Id: Id9ec9cbe9f879c2f437b234742118763d6d0f535
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/15/637915/4 && git format-patch -1 --stdout FETCH_HEAD,"['environments/docker-uc-light.yaml', 'environments/docker.yaml', 'environments/kubernetes.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'environments/openshift.yaml', 'releasenotes/notes/deprecate_docker_all-40eb568c9234a3d8.yaml', 'deployment/deprecated/docker/docker-baremetal-ansible.yaml', 'deployment/deprecated/docker/docker-registry-baremetal-ansible.yaml']",8,c55d0a1f05232af16e8d87ec10a5f2c86cc2acc7,bp/podman-support,,,10,5
openstack%2Ftripleo-heat-templates~master~Id6c927d9c0db024875032f04228047d029c0696d,openstack/tripleo-heat-templates,master,Id6c927d9c0db024875032f04228047d029c0696d,Create deployment/deprecated directory,MERGED,2019-02-19 15:28:56.000000000,2019-02-21 16:08:27.000000000,2019-02-21 16:08:27.000000000,"[{'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27427}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-02-19 15:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/14ebefe6dd53669a53d65e56894f833b1c83feff', 'message': ""Create deployment/deprecated directory\n\nIt's not easy to find which services are deprecated, so let's create a\ndirectory: deployment/deprecated and put the services in there.\n\nThis patch:\n- creates the directory and a README\n- moves already deprecated services into that directory\n- update all references to these services to point to the right files\n\nChange-Id: Id6c927d9c0db024875032f04228047d029c0696d\n""}, {'number': 2, 'created': '2019-02-19 23:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f07962104a67693de103e2d72b1b17d8dcdc32fd', 'message': ""Create deployment/deprecated directory\n\nIt's not easy to find which services are deprecated, so let's create a\ndirectory: deployment/deprecated and put the services in there.\n\nThis patch:\n- creates the directory and a README\n- moves already deprecated services into that directory\n- update all references to these services to point to the right files\n\nChange-Id: Id6c927d9c0db024875032f04228047d029c0696d\n""}, {'number': 3, 'created': '2019-02-20 13:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0e5f6dac91753786a487b3376ad2f49a05d5260c', 'message': ""Create deployment/deprecated directory\n\nIt's not easy to find which services are deprecated, so let's create a\ndirectory: deployment/deprecated and put the services in there.\n\nThis patch:\n- creates the directory and a README\n- moves already deprecated services into that directory\n- update all references to these services to point to the right files\n\nChange-Id: Id6c927d9c0db024875032f04228047d029c0696d\n""}, {'number': 4, 'created': '2019-02-20 21:58:08.000000000', 'files': ['deployment/deprecated/logging/fluentd-config.yaml', 'deployment/deprecated/monitoring/sensu-client-container-puppet.yaml', 'ci/environments/scenario001-multinode-containers.yaml', 'ci/environments/scenario002-standalone.yaml', 'environments/services/fluentd.yaml', 'environments/baremetal-services.yaml', 'environments/services-baremetal/fluentd.yaml', 'ci/environments/scenario001-standalone.yaml', 'ci/environments/scenario002-multinode-containers.yaml', 'environments/services/sensu-client.yaml', 'ci/environments/scenario004-standalone.yaml', 'deployment/deprecated/panko/panko-api-container-puppet.yaml', 'environments/logging-environment.yaml', 'deployment/deprecated/monitoring/sensu-base.yaml', 'deployment/deprecated/logging/fluentd-container-puppet.yaml', 'environments/monitoring-environment.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'deployment/deprecated/README.rst', 'environments/computealt.yaml', 'environments/services/undercloud-panko.yaml', 'environments/services-baremetal/undercloud-panko.yaml', 'environments/services-baremetal/sensu-client.yaml', 'releasenotes/notes/deprecated_services-172a1ae6348e6c52.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/72aa2dfc0ac93c9a1ccaa434d8ad8f4519b61083', 'message': ""Create deployment/deprecated directory\n\nIt's not easy to find which services are deprecated, so let's create a\ndirectory: deployment/deprecated and put the services in there.\n\nThis patch:\n- creates the directory and a README\n- moves already deprecated services into that directory\n- update all references to these services to point to the right files\n\nChange-Id: Id6c927d9c0db024875032f04228047d029c0696d\n""}]",0,637890,72aa2dfc0ac93c9a1ccaa434d8ad8f4519b61083,26,7,4,3153,,,0,"Create deployment/deprecated directory

It's not easy to find which services are deprecated, so let's create a
directory: deployment/deprecated and put the services in there.

This patch:
- creates the directory and a README
- moves already deprecated services into that directory
- update all references to these services to point to the right files

Change-Id: Id6c927d9c0db024875032f04228047d029c0696d
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/90/637890/4 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/deprecated/logging/fluentd-config.yaml', 'deployment/deprecated/monitoring/sensu-client-container-puppet.yaml', 'ci/environments/scenario001-multinode-containers.yaml', 'ci/environments/scenario002-standalone.yaml', 'environments/services/fluentd.yaml', 'environments/baremetal-services.yaml', 'environments/services-baremetal/fluentd.yaml', 'ci/environments/scenario001-standalone.yaml', 'ci/environments/scenario002-multinode-containers.yaml', 'environments/services/sensu-client.yaml', 'ci/environments/scenario004-standalone.yaml', 'deployment/deprecated/panko/panko-api-container-puppet.yaml', 'environments/logging-environment.yaml', 'deployment/deprecated/monitoring/sensu-base.yaml', 'deployment/deprecated/logging/fluentd-container-puppet.yaml', 'environments/monitoring-environment.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'deployment/deprecated/README.rst', 'environments/computealt.yaml', 'environments/services/undercloud-panko.yaml', 'environments/services-baremetal/undercloud-panko.yaml', 'environments/services-baremetal/sensu-client.yaml', 'releasenotes/notes/deprecated_services-172a1ae6348e6c52.yaml']",23,14ebefe6dd53669a53d65e56894f833b1c83feff,deprecated,--- features: - | Deprecated services now live in deployment/deprecated directory. ,,37,23
openstack%2Ftripleo-heat-templates~stable%2Frocky~I3ac3d9baf51c7a9e13d20985fbe47cd5404eb88d,openstack/tripleo-heat-templates,stable/rocky,I3ac3d9baf51c7a9e13d20985fbe47cd5404eb88d,FFWD: Introduce workaround for neutron cisco plugin,MERGED,2018-11-22 09:10:01.000000000,2019-02-21 16:08:25.000000000,2019-02-21 16:08:25.000000000,"[{'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-11-22 09:10:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6a289651b916d9f5d97270e945f97594d1aeac97', 'message': 'FFWD: Introduce workaround for neutron cisco plugin\n\nNeutron cisco plugin package update is not triggered by update of\nneutron package. If this plugin is enabled the neutron db sync\nwill fail unless we update python-networking-cisco package.\n\nChange-Id: I3ac3d9baf51c7a9e13d20985fbe47cd5404eb88d\nResolves: rhbz#1652209\nCloses-bug: #1804494\n(cherry picked from commit 4e8c2faf36d94257760b5d07195e1d90fefbc2c4)\n'}, {'number': 2, 'created': '2019-02-18 14:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e6b94962245325f56bb88f89d25cedb3fb6c3d3c', 'message': 'FFWD: Introduce workaround for neutron cisco plugin\n\nNeutron cisco plugin package update is not triggered by update of\nneutron package. If this plugin is enabled the neutron db sync\nwill fail unless we update python-networking-cisco package.\n\nChange-Id: I3ac3d9baf51c7a9e13d20985fbe47cd5404eb88d\nResolves: rhbz#1652209\nCloses-bug: #1804494\n(cherry picked from commit 4e8c2faf36d94257760b5d07195e1d90fefbc2c4)\n'}, {'number': 3, 'created': '2019-02-21 09:39:56.000000000', 'files': ['docker/services/neutron-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5e725bf58d71942e507b58742939245ec5dce155', 'message': 'FFWD: Introduce workaround for neutron cisco plugin\n\nNeutron cisco plugin package update is not triggered by update of\nneutron package. If this plugin is enabled the neutron db sync\nwill fail unless we update python-networking-cisco package.\n\nChange-Id: I3ac3d9baf51c7a9e13d20985fbe47cd5404eb88d\nResolves: rhbz#1652209\nCloses-bug: #1804494\n(cherry picked from commit 4e8c2faf36d94257760b5d07195e1d90fefbc2c4)\n'}]",1,619484,5e725bf58d71942e507b58742939245ec5dce155,18,6,3,11166,,,0,"FFWD: Introduce workaround for neutron cisco plugin

Neutron cisco plugin package update is not triggered by update of
neutron package. If this plugin is enabled the neutron db sync
will fail unless we update python-networking-cisco package.

Change-Id: I3ac3d9baf51c7a9e13d20985fbe47cd5404eb88d
Resolves: rhbz#1652209
Closes-bug: #1804494
(cherry picked from commit 4e8c2faf36d94257760b5d07195e1d90fefbc2c4)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/84/619484/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/neutron-api.yaml'],1,6a289651b916d9f5d97270e945f97594d1aeac97,bug/1804494, - name: Networking cisco db sync workaround package: name=python-networking-cisco state=latest,,2,0
openstack%2Fironic-python-agent~stable%2Fqueens~Ic24b706a04ff6c08d750b9e3d79eb79eab2952ad,openstack/ironic-python-agent,stable/queens,Ic24b706a04ff6c08d750b9e3d79eb79eab2952ad,rework ATA secure erase,MERGED,2019-02-21 09:12:29.000000000,2019-02-21 15:57:25.000000000,2019-02-21 15:57:25.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 24245}, {'_account_id': 28048}]","[{'number': 1, 'created': '2019-02-21 09:12:29.000000000', 'files': ['ironic_python_agent/hardware.py', 'ironic_python_agent/tests/unit/test_hardware.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/66c1202e63255a815996b38bb3fb7ae13ac5ad01', 'message': 'rework ATA secure erase\n\nhdparm versions prior to 9.51 interpret the value, NULL, as a\npassword with string value: ""NULL"".\n\nExample output of hdparm with NULL password:\n\n    [root@localhost ~]# hdparm --user-master u --security-unlock NULL /dev/sda\n    security_password=""NULL""\n\n    /dev/sda:\n    Issuing SECURITY_UNLOCK command, password=""NULL"", user=user\n    SECURITY_UNLOCK: Input/output error\n\nExample output of hdparm with """" as password:\n\n    [root@localhost ~]# hdparm --user-master u --security-unlock """" /dev/sda\n    security_password=""""\n\n    /dev/sda:\n     Issuing SECURITY_UNLOCK command, password="""", user=user\n\nNote the values of security_password in the output above. The output\nwas observed on a CentOS 7 system, which ships hdparm 9.43 in the\noffical repositories.\n\nThis change attempts to unlock the drive with the empty string if an\nunlock with NULL was unsucessful.\n\nIssuing a security-unlock will cause a state transition from SEC4\n(security enabled, locked, not frozen) to SEC5 (security enabled,\nunlocked, not frozen). In order to check that a password unlock attempt\nwas successful it makes sense to check that the drive is in the unlocked\nstate (a necessary condition for SEC5). Only after all unlock attempts\nfail, do we consider the drive out of our control.\n\nThe conditions to check the drive is in the right state have been\nadjusted to ensure that the drive is in the SEC5 state prior to issuing\na secure erase. Previously, on the ""recovery from previous fail"" path,\nthe security state was asserted to be ""not enabled"" after an unlock -\nthis could never have been the case.\n\nA good overview of the ATA security states can be found here:\n\n  http://www.admin-magazine.com/Archive/2014/19/Using-the-ATA-security-features-of-modern-hard-disks-and-SSDs\n\nChange-Id: Ic24b706a04ff6c08d750b9e3d79eb79eab2952ad\nStory: 2001762\nTask: 12161\nStory: 2001763\nTask: 12162\n(cherry picked from commit aaf76e2cfb88c6cae50c8b46c65edce0a30e6a8f)\n'}]",0,638367,66c1202e63255a815996b38bb3fb7ae13ac5ad01,9,5,1,10239,,,0,"rework ATA secure erase

hdparm versions prior to 9.51 interpret the value, NULL, as a
password with string value: ""NULL"".

Example output of hdparm with NULL password:

    [root@localhost ~]# hdparm --user-master u --security-unlock NULL /dev/sda
    security_password=""NULL""

    /dev/sda:
    Issuing SECURITY_UNLOCK command, password=""NULL"", user=user
    SECURITY_UNLOCK: Input/output error

Example output of hdparm with """" as password:

    [root@localhost ~]# hdparm --user-master u --security-unlock """" /dev/sda
    security_password=""""

    /dev/sda:
     Issuing SECURITY_UNLOCK command, password="""", user=user

Note the values of security_password in the output above. The output
was observed on a CentOS 7 system, which ships hdparm 9.43 in the
offical repositories.

This change attempts to unlock the drive with the empty string if an
unlock with NULL was unsucessful.

Issuing a security-unlock will cause a state transition from SEC4
(security enabled, locked, not frozen) to SEC5 (security enabled,
unlocked, not frozen). In order to check that a password unlock attempt
was successful it makes sense to check that the drive is in the unlocked
state (a necessary condition for SEC5). Only after all unlock attempts
fail, do we consider the drive out of our control.

The conditions to check the drive is in the right state have been
adjusted to ensure that the drive is in the SEC5 state prior to issuing
a secure erase. Previously, on the ""recovery from previous fail"" path,
the security state was asserted to be ""not enabled"" after an unlock -
this could never have been the case.

A good overview of the ATA security states can be found here:

  http://www.admin-magazine.com/Archive/2014/19/Using-the-ATA-security-features-of-modern-hard-disks-and-SSDs

Change-Id: Ic24b706a04ff6c08d750b9e3d79eb79eab2952ad
Story: 2001762
Task: 12161
Story: 2001763
Task: 12162
(cherry picked from commit aaf76e2cfb88c6cae50c8b46c65edce0a30e6a8f)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/67/638367/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/hardware.py', 'ironic_python_agent/tests/unit/test_hardware.py']",2,66c1202e63255a815996b38bb3fb7ae13ac5ad01,bz/1679174," '\t%(locked)s\n' @mock.patch.object(utils, 'execute', autospec=True) def test_erase_block_device_ata_security_unlock_fallback_pass( self, mocked_execute): hdparm_output = create_hdparm_info( supported=True, enabled=True, locked=True ) hdparm_output_unlocked = create_hdparm_info( supported=True, enabled=True, frozen=False, enhanced_erase=False) hdparm_output_not_enabled = create_hdparm_info( supported=True, enabled=False, frozen=False, enhanced_erase=False) mocked_execute.side_effect = [ (hdparm_output, ''), processutils.ProcessExecutionError(), # NULL fails to unlock (hdparm_output, ''), # recheck security lines None, # security unlock with """" (hdparm_output_unlocked, ''), '', (hdparm_output_not_enabled, '') ] block_device = hardware.BlockDevice('/dev/sda', 'big', 1073741824, True) self.hardware.erase_block_device(self.node, block_device) mocked_execute.assert_any_call('hdparm', '--user-master', 'u', '--security-unlock', '', '/dev/sda') # Tests that an exception is thrown if all of the recovery passwords # fail to unlock the device without throwing exception supported=True, enabled=True, locked=True) (hdparm_output, ''), None, (hdparm_output, ''), None, mocked_execute.assert_any_call('hdparm', '--user-master', 'u', '--security-unlock', '', '/dev/sda') mocked_execute.assert_any_call('hdparm', '--user-master', 'u', '--security-unlock', 'NULL', '/dev/sda') supported=True, enabled=True, locked=True) # test that an exception is thrown when security unlock fails with # ProcessExecutionError supported=True, enabled=True, locked=True) processutils.ProcessExecutionError(), (hdparm_output, ''), processutils.ProcessExecutionError(), (hdparm_output, ''), mocked_execute.assert_any_call('hdparm', '--user-master', 'u', '--security-unlock', '', '/dev/sda') mocked_execute.assert_any_call('hdparm', '--user-master', 'u', '--security-unlock', 'NULL', '/dev/sda') # Exception on security erase '', # security-set-pass processutils.ProcessExecutionError() # security-erasedef create_hdparm_info(supported=False, enabled=False, locked=False, frozen=False, enhanced_erase=False): 'locked': '\tlocked', update_values(values, locked, 'locked')"," '\tnot\tlocked\n' supported=True, enabled=True, frozen=False, enhanced_erase=False) supported=True, enabled=True, frozen=False, enhanced_erase=False) supported=True, enabled=True, frozen=False, enhanced_erase=False) processutils.ProcessExecutionError() supported=True, enabled=True, frozen=False, enhanced_erase=False) hdparm_output_not_enabled = create_hdparm_info( '', (hdparm_output_not_enabled, ''), '', supported=True, enabled=True, frozen=False, enhanced_erase=False) hdparm_output_not_enabled = create_hdparm_info( '', (hdparm_output_not_enabled, ''), '', processutils.ProcessExecutionError()def create_hdparm_info(supported=False, enabled=False, frozen=False, enhanced_erase=False):",106,48
openstack%2Fhorizon~master~If00d156a7a56ed699425b35ac60314c3a8cd049c,openstack/horizon,master,If00d156a7a56ed699425b35ac60314c3a8cd049c,Add volume-group snapshot for admin panel,MERGED,2019-01-28 18:43:18.000000000,2019-02-21 15:53:12.000000000,2019-02-21 15:53:12.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-01-28 18:43:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6297bdd41e948b884a593619596bc279ced6ae5a', 'message': 'Add volume-group snapshot for admin panel\n\nThis commit allow admin to list/show and delete volume-group snapshots\nusing horizon dashboard.\n\nPartially-Implements blueprint cinder-generic-volume-groups\n\nChange-Id: If00d156a7a56ed699425b35ac60314c3a8cd049c\n'}, {'number': 2, 'created': '2019-01-30 09:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7ef779ec8e0e877cd3a26b534156ec05a89fae0e', 'message': 'Add volume-group snapshot for admin panel\n\nThis commit allow admin to list/show and delete volume-group snapshots\nusing horizon dashboard.\n\nPartially-Implements blueprint cinder-generic-volume-groups\n\nChange-Id: If00d156a7a56ed699425b35ac60314c3a8cd049c\n'}, {'number': 3, 'created': '2019-01-30 16:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/81645e41b52bb3daf1fc3c7af716849178def291', 'message': 'Add volume-group snapshot for admin panel\n\nThis commit allow admin to list/show and delete volume-group snapshots\nusing horizon dashboard.\n\nPartially-Implements blueprint cinder-generic-volume-groups\n\nChange-Id: If00d156a7a56ed699425b35ac60314c3a8cd049c\n'}, {'number': 4, 'created': '2019-01-31 05:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4072716f8124cf0788fefc0908ee90b3280a46e3', 'message': 'Add volume-group snapshot for admin panel\n\nThis commit allow admin to list/show and delete volume-group snapshots\nusing horizon dashboard.\n\nPartially-Implements blueprint cinder-generic-volume-groups\n\nChange-Id: If00d156a7a56ed699425b35ac60314c3a8cd049c\n'}, {'number': 5, 'created': '2019-02-12 16:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/88ed241f89b8c2f80ee40c8dc0e0e912ede305fe', 'message': 'Add volume-group snapshot for admin panel\n\nThis commit allow admin to list/show and delete volume-group snapshots\nusing horizon dashboard.\n\nPartially-Implements blueprint cinder-generic-volume-groups\n\nChange-Id: If00d156a7a56ed699425b35ac60314c3a8cd049c\n'}, {'number': 6, 'created': '2019-02-15 06:41:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1c18936f970e9daf8031b681e41de3e3719532fd', 'message': 'Add volume-group snapshot for admin panel\n\nThis commit allow admin to list/show and delete volume-group snapshots\nusing horizon dashboard.\n\nPartially-Implements blueprint cinder-generic-volume-groups\n\nChange-Id: If00d156a7a56ed699425b35ac60314c3a8cd049c\n'}, {'number': 7, 'created': '2019-02-15 08:02:58.000000000', 'files': ['openstack_dashboard/dashboards/admin/vg_snapshots/tabs.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/panel.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/views.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/tests.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/__init__.py', 'openstack_dashboard/enabled/_2260_admin_vg_snapshots.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/tables.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/urls.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/templates/vg_snapshots/_detail_overview.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9497a23723eaee9b4ce1ff46a47d0c468c6f2181', 'message': 'Add volume-group snapshot for admin panel\n\nThis commit allow admin to list/show and delete volume-group snapshots\nusing horizon dashboard.\n\nPartially-Implements blueprint cinder-generic-volume-groups\n\nChange-Id: If00d156a7a56ed699425b35ac60314c3a8cd049c\n'}]",22,633581,9497a23723eaee9b4ce1ff46a47d0c468c6f2181,38,6,7,29313,,,0,"Add volume-group snapshot for admin panel

This commit allow admin to list/show and delete volume-group snapshots
using horizon dashboard.

Partially-Implements blueprint cinder-generic-volume-groups

Change-Id: If00d156a7a56ed699425b35ac60314c3a8cd049c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/81/633581/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/vg_snapshots/tabs.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/panel.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/views.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/tests.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/__init__.py', 'openstack_dashboard/enabled/_2260_admin_vg_snapshots.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/tables.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/urls.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/templates/vg_snapshots/_detail_overview.html']",9,6297bdd41e948b884a593619596bc279ced6ae5a,bp/cinder-generic-volume-groups,"{% load i18n sizeformat parse_date %} <div class=""detail""> <dl class=""dl-horizontal""> <dt>{% trans ""Name"" %}</dt> <dd data-display=""{{ vg_snapshot.name|default:vg_snapshot.id }}"">{{ vg_snapshot.name }}</dd> <dt>{% trans ""ID"" %}</dt> <dd>{{ vg_snapshot.id }}</dd> {% if vg_snapshot.description %} <dt>{% trans ""Description"" %}</dt> <dd>{{ vg_snapshot.description }}</dd> {% endif %} <dt>{% trans ""Status"" %}</dt> <dd>{{ vg_snapshot.status|capfirst }}</dd> <dt>{% trans ""Group"" %}</dt> <dd> <a href=""{% url 'horizon:admin:volume_groups:detail' vg_snapshot.group_id %}""> {% if vg_snapshot.vg_name %} {{ vg_snapshot.vg_name }} {% else %} {{ vg_snapshot.group_id }} {% endif %} </a> </dd> <dt>{% trans ""Group Type"" %}</dt> <dd>{{ vg_snapshot.group_type_id }}</dd> <dt>{% trans ""Created"" %}</dt> <dd>{{ vg_snapshot.created_at|parse_isotime }}</dd> </dl> <h4>{% trans ""Snapshot Volume Types"" %}</h4> <hr class=""header_rule""> <dl class=""dl-horizontal""> {% for vol_type_names in vg_snapshot.volume_type_names %} <dd>{{ vol_type_names }}</dd> {% endfor %} </dl> <h4>{% trans ""Snapshot Volumes"" %}</h4> <hr class=""header_rule""> <dl class=""dl-horizontal""> {% for vol_names in vg_snapshot.volume_names %} <dd>{{ vol_names }}</dd> {% empty %} <dd> <em>{% trans ""No assigned volumes"" %}</em> </dd> {% endfor %} </dl> </div> ",,380,0
openstack%2Fironic-python-agent~master~Ib4c42985a19205528a0a84224d5532d329fc8ddb,openstack/ironic-python-agent,master,Ib4c42985a19205528a0a84224d5532d329fc8ddb,[WIP] Build tinyipa with python3,ABANDONED,2017-08-18 17:24:49.000000000,2019-02-21 15:39:57.000000000,,"[{'_account_id': 3}, {'_account_id': 6637}, {'_account_id': 8871}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 14760}, {'_account_id': 15519}, {'_account_id': 19593}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2017-08-18 17:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/82b9f66cf4b49eb621e7b44cd38e8ce4b2f9fc6c', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 2, 'created': '2017-08-29 21:37:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/6520ebfa9099adc80ee79d24ac11341d52092bb9', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 3, 'created': '2017-08-31 23:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/186b9b127641f1d91db4a15c6d0ab4542b69553d', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 4, 'created': '2017-09-07 18:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/74b8bb578090d734be371f0628a76640d72d1119', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 5, 'created': '2017-09-27 21:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/4c3f23de19298fb044e32c0258283c3a83b000b1', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 6, 'created': '2017-09-27 21:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/82fdb04a0a643138d780110b229fec26b3a3f4f7', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 7, 'created': '2017-09-28 00:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/c87fc8443803c3e5c05d160be76c4201f6434563', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 8, 'created': '2017-09-28 01:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b7af70a133f673d44c80d46aa3f42a08bced44e4', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 9, 'created': '2017-09-28 04:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/c56ebd23c3caf57e36e540ec2b4fe7574a0b365c', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 10, 'created': '2017-09-28 05:35:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/7dda41baa81fa4861a80f6be91033a259f848a12', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 11, 'created': '2017-10-02 16:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/e3e056a3511824953c767b929ffd0e55aae81cb0', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 12, 'created': '2017-10-03 00:47:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/67d49c71847e15d91bd667ed3b4b6997194057bd', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 13, 'created': '2017-10-04 20:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/ecb417aa3732b67ff13969b8145a4856dbc19db0', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 14, 'created': '2017-10-07 00:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/0856cb8dd2cd6c03435ad9d097ae7b8c26162172', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 15, 'created': '2017-10-10 00:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/cd973877c5aaa38bc4c96455e53d17230119b888', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 16, 'created': '2017-10-20 02:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/2a087d22775833b9138015e4f92c1dc596a5b8f5', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 17, 'created': '2017-10-25 18:39:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/29a250a490203c26874fc97761878afe39f52ff6', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 18, 'created': '2017-10-25 21:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/481589600b04fd9e7da28e8954fd030aec31a479', 'message': 'Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 19, 'created': '2017-10-30 22:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b188d5bcc11d6de4f366e4e0c97f409c916cf23b', 'message': '[WIP] Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 20, 'created': '2017-10-31 18:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/03723899d821d51a74b1362a2d8a4c722edc8569', 'message': '[WIP] Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 21, 'created': '2017-10-31 21:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/05e6be5dd25186691c82c58747b1e49c9de45cb3', 'message': '[WIP] Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 22, 'created': '2017-11-08 19:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/cac06b3e4581118eddf8543e82f798524b0f96b8', 'message': '[WIP] Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nDepends-On: Ib05e3332f032c1c14ae2cee02015614fc171cb32\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 23, 'created': '2017-11-21 00:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/dd1b67867d0990c8229cbedf508a2e3845b2e831', 'message': '[WIP] Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 24, 'created': '2019-01-21 16:36:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/2ed5fb18a3be6c38bb1c86cc35d14d3eef8a324d', 'message': '[WIP] Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 25, 'created': '2019-01-22 10:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/5ff3cf770dd90a2d2652b624145112610c65ace2', 'message': '[WIP] Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 26, 'created': '2019-01-22 12:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/d42e0c74e32de948b7d32b81d6c99c2ca7ab4fb2', 'message': '[WIP] Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 27, 'created': '2019-01-23 14:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/aae232d563a65e43ff6fbdf73ee5a6dc058b878e', 'message': '[WIP] Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 28, 'created': '2019-01-23 14:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/7b70fee5dd41cc37e5f3f5c6addd8041e31ae007', 'message': '[WIP] Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 29, 'created': '2019-01-23 16:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/9e18542a0d20d1a2f139da80914acefba415a2a1', 'message': '[WIP] Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 30, 'created': '2019-01-24 08:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/ccf959d337a934e18f7ebb2dd3541a882b56e9ae', 'message': '[WIP] Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}, {'number': 31, 'created': '2019-01-24 14:34:51.000000000', 'files': ['imagebuild/tinyipa/build_files/finalreqs.lst', 'imagebuild/tinyipa/build-tinyipa.sh', 'imagebuild/tinyipa/build_files/finalreqs_python3.lst', 'imagebuild/tinyipa/build_files/reqs_python3.lst', 'imagebuild/tinyipa/finalise-tinyipa.sh', 'imagebuild/tinyipa/build_files/buildreqs.lst', 'zuul.d/ironic-jobs.yaml', 'imagebuild/tinyipa/build_files/fakeuname8', 'imagebuild/tinyipa/build_files/finalreqs_python2.lst', 'imagebuild/tinyipa/build_files/fakeuname7', 'imagebuild/tinyipa/build_files/reqs_python2.lst', 'releasenotes/notes/add-support-for-py3-01e3fc53a5dd98ec.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/28da5b517c8b52d9f07c936b856d6a9496787e96', 'message': '[WIP] Build tinyipa with python3\n\nThe patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to\ninclude python3.tcz and python3-dev.tcz. Patch also updates\nbuild scripts to switch to python3.\n\nChange-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb\n'}]",27,495385,28da5b517c8b52d9f07c936b856d6a9496787e96,109,10,31,19593,,,0,"[WIP] Build tinyipa with python3

The patch updates ``buildreqs.lst`` and ``finalreqs.lst`` to
include python3.tcz and python3-dev.tcz. Patch also updates
build scripts to switch to python3.

Change-Id: Ib4c42985a19205528a0a84224d5532d329fc8ddb
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/85/495385/30 && git format-patch -1 --stdout FETCH_HEAD,"['imagebuild/tinyipa/build_files/finalreqs.lst', 'imagebuild/tinyipa/build_files/buildreqs.lst']",2,82b9f66cf4b49eb621e7b44cd38e8ce4b2f9fc6c,bug/495385,python3.tcz python3-dev.tcz,python.tcz python-dev.tcz,3,2
openstack%2Fsahara-dashboard~master~I311203779bd3e6c6660cfe1b84e89c7dc0825c98,openstack/sahara-dashboard,master,I311203779bd3e6c6660cfe1b84e89c7dc0825c98,Native Zuul v3 dashboard-integration test,MERGED,2018-02-09 18:30:36.000000000,2019-02-21 15:34:49.000000000,2019-02-21 15:34:49.000000000,"[{'_account_id': 1736}, {'_account_id': 6547}, {'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 22348}, {'_account_id': 23078}]","[{'number': 1, 'created': '2018-02-09 18:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/5440d2560857794702f032a3f7780dfe0ea931ed', 'message': 'WIP Native dashboard-integration test\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 2, 'created': '2018-02-12 09:42:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/e3c785c4ad2b0356303bfb1891896d1faefbc5d5', 'message': 'WIP Native dashboard-integration test\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 3, 'created': '2018-02-12 11:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/46e3796c63ff7c82abc045bc47930978f50014c8', 'message': 'WIP Native dashboard-integration test\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 4, 'created': '2018-02-12 12:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/fa95a94df3eb9b4ec3fcf9f13ccffffbe18d0c63', 'message': 'WIP Native dashboard-integration test\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 5, 'created': '2018-02-12 15:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/dd2db2ee2eca0ccd102d8a2bc25e2338057fcebe', 'message': 'WIP Native dashboard-integration test\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 6, 'created': '2018-02-12 16:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/0ea5e75210403b0e4db7c8fbb95b5805166ab7bd', 'message': 'WIP Native dashboard-integration test\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 7, 'created': '2018-02-12 18:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/9ce330392a4d35b1fde0d8789c586c0487f2513a', 'message': 'WIP Native dashboard-integration test\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 8, 'created': '2018-02-13 11:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/92122d8057d29eff9c198c3aae9d414e2bd7b123', 'message': 'WIP Native dashboard-integration test\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 9, 'created': '2018-02-13 16:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/edf31ff0af9b90d8b32977dce49a98698dd3324c', 'message': 'WIP Native dashboard-integration test\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 10, 'created': '2018-02-13 17:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/814ec1b7c92448d613a6a733f68816455b122c77', 'message': 'WIP Native dashboard-integration test\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 11, 'created': '2018-02-13 18:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/02a23ceea73c806358d7efe3e95b09a1f31f89ec', 'message': 'WIP Native dashboard-integration test\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 12, 'created': '2018-03-08 15:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/badc3ee0446db4f7a17d8b66c9d2044ad177e62f', 'message': 'WIP Native dashboard-integration test\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 13, 'created': '2018-04-04 17:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/4fdcf2747dc20c4a1a6f6dfc2a66b58679b52103', 'message': 'WIP Native dashboard-integration test\n\nStory: 2001686\nTask: 8662\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 14, 'created': '2018-07-09 18:03:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/2cf734be72c0ceeaf2a43887be6b714953a68263', 'message': 'WIP Native dashboard-integration test\n\nStory: 2001686\nTask: 8662\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 15, 'created': '2018-08-18 12:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/cd01fb6e2e8b7f8d5f6fc1dc95f4a50b2e71f4e4', 'message': 'Native dashboard-integration test\n\nThe test is failing right now, but apart the increased time\nat least the tests are executed.\n\nStory: 2001686\nTask: 8662\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 16, 'created': '2018-08-21 15:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/a955f62222159fb8f1d09651f9d93910b41d1eba', 'message': 'Native dashboard-integration test\n\nThe test is failing right now, but apart the increased time\nat least the tests are executed.\n\nStory: 2001686\nTask: 8662\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 17, 'created': '2018-08-21 15:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/957d80a952a9b3d65aa5badeea1bb2944e437519', 'message': 'Native dashboard-integration test\n\nThe test is failing right now, but apart the increased time\nat least the tests are executed.\n\nStory: 2001686\nTask: 8662\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 18, 'created': '2019-02-05 00:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/62f5bec972721faf2c8884633c237a11a4d2d9e1', 'message': 'Native dashboard-integration test\n\nThe test is failing right now, but apart the increased time\nat least the tests are executed.\n\nStory: 2001686\nTask: 8662\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 19, 'created': '2019-02-05 09:19:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/4c93e8d3266fb62beaa223a96e11456a148255bc', 'message': 'Native dashboard-integration test\n\nThe test is failing right now, but apart the increased time\nat least the tests are executed.\n\nStory: 2001686\nTask: 8662\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 20, 'created': '2019-02-05 10:55:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/a03ac7ffe23c5bbf6dccb6f8f77adde507fe30ee', 'message': 'Native Zuul v3 dashboard-integration test\n\n- create a native Zuul v3 job;\n- install libav-utils on dpkg systems to capture the test execution;\n- adapt to the changes in OverviewPage:\n  * go_to_system_flavorspage -> go_to_admin_compute_flavorspage\n  * go_to_compute_imagespage -> go_to_project_compute_imagespage\n\nThe job is failing right now, but apart the increased running time,\nat least the tests are now executed.\n\nStory: 2001686\nTask: 8662\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 21, 'created': '2019-02-05 13:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/bb4872ad83be1b93b692b4333729e43919556deb', 'message': 'Native Zuul v3 dashboard-integration test\n\n- create a native Zuul v3 job;\n- install libav-utils on dpkg systems and enable the capture\n  of the video;\n- adapt to the changes in OverviewPage:\n  * go_to_system_flavorspage -> go_to_admin_compute_flavorspage\n  * go_to_compute_imagespage -> go_to_project_compute_imagespage\n\nThe job is failing right now, but apart the increased running time,\nat least the tests are now executed.\n\nStory: 2001686\nTask: 8662\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}, {'number': 22, 'created': '2019-02-20 23:48:24.000000000', 'files': ['playbooks/sahara-dashboard-integration/pre.yaml', 'roles/post-devstack-sahara-ui-integration/files/fake_config.json', '.zuul.yaml', 'roles/post-devstack-sahara-ui-integration/tasks/main.yaml', 'roles/setup-sahara-ui-integration/tasks/main.yaml', 'playbooks/sahara-dashboard-integration/run.yaml', 'roles/setup-sahara-ui-integration/files/legacy_panels.conf', 'bindep.txt', 'roles/post-devstack-sahara-ui-integration/defaults/main.yaml', 'sahara_dashboard/test/integration_tests/tests/test_sahara_image_registry.py', 'roles/setup-sahara-ui-integration/defaults/main.yaml', 'sahara_dashboard/test/integration_tests/tests/test_crud.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/bd66017874e995de8251b5bcc367913e622fe95f', 'message': 'Native Zuul v3 dashboard-integration test\n\n- create a native Zuul v3 job, and move it to experimental\n  until it works;\n- install libav-utils on dpkg systems and enable the capture\n  of the video;\n- adapt to the changes in OverviewPage:\n  * go_to_system_flavorspage -> go_to_admin_compute_flavorspage\n  * go_to_compute_imagespage -> go_to_project_compute_imagespage\n\nThe job is failing right now, but apart the increased running time,\nat least the tests are now executed.\n\nStory: 2001686\nTask: 8662\n\nChange-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98\n'}]",0,542970,bd66017874e995de8251b5bcc367913e622fe95f,57,6,22,10459,,,0,"Native Zuul v3 dashboard-integration test

- create a native Zuul v3 job, and move it to experimental
  until it works;
- install libav-utils on dpkg systems and enable the capture
  of the video;
- adapt to the changes in OverviewPage:
  * go_to_system_flavorspage -> go_to_admin_compute_flavorspage
  * go_to_compute_imagespage -> go_to_project_compute_imagespage

The job is failing right now, but apart the increased running time,
at least the tests are now executed.

Story: 2001686
Task: 8662

Change-Id: I311203779bd3e6c6660cfe1b84e89c7dc0825c98
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/70/542970/15 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/sahara-dashboard-integration.yaml', '.zuul.yaml', 'roles/setup-sahara-ui-integration/files/fake_config.json', 'roles/setup-sahara-ui-integration/tasks/main.yaml', 'playbooks/sahara-dashboard-integration-pre.yaml', 'roles/setup-sahara-ui-integration/defaults/main.yaml', 'tox.ini', 'roles/setup-sahara-ui-integration/files/legacy_panels.conf']",8,5440d2560857794702f032a3f7780dfe0ea931ed,zuulv3-nativefull,[image] panel_type=legacy [flavors] panel_type=legacy ,,92,0
openstack%2Fopenstack-ansible~stable%2Frocky~Id700dafc266735937b47d84fa62fed679d2d6fa3,openstack/openstack-ansible,stable/rocky,Id700dafc266735937b47d84fa62fed679d2d6fa3,Bump version to 18.1.5,ABANDONED,2019-02-16 06:21:59.000000000,2019-02-21 15:13:41.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-16 06:21:59.000000000', 'files': ['inventory/group_vars/all/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/63341d14fde91c4fae08c5ba35dff7bcd3522812', 'message': 'Bump version to 18.1.5\n\nDepends-On: https://review.openstack.org/637358\nChange-Id: Id700dafc266735937b47d84fa62fed679d2d6fa3\n'}]",0,637359,63341d14fde91c4fae08c5ba35dff7bcd3522812,3,1,1,17068,,,0,"Bump version to 18.1.5

Depends-On: https://review.openstack.org/637358
Change-Id: Id700dafc266735937b47d84fa62fed679d2d6fa3
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/59/637359/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/all/all.yml'],1,63341d14fde91c4fae08c5ba35dff7bcd3522812,release_osa,openstack_release: 18.1.5,openstack_release: 18.1.4,1,1
openstack%2Fopenstack-ansible~stable%2Fqueens~I1c89bd1f4c7c5855b319d00d279b0294820ed9f4,openstack/openstack-ansible,stable/queens,I1c89bd1f4c7c5855b319d00d279b0294820ed9f4,Bump version to 17.1.9,ABANDONED,2019-02-16 06:28:11.000000000,2019-02-21 15:13:28.000000000,,"[{'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-16 06:28:11.000000000', 'files': ['inventory/group_vars/all/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/65086cf05ef2c9173dda93513c18dfa59f9322b8', 'message': 'Bump version to 17.1.9\n\nDepends-On: https://review.openstack.org/637360\nChange-Id: I1c89bd1f4c7c5855b319d00d279b0294820ed9f4\n'}]",0,637361,65086cf05ef2c9173dda93513c18dfa59f9322b8,5,2,1,17068,,,0,"Bump version to 17.1.9

Depends-On: https://review.openstack.org/637360
Change-Id: I1c89bd1f4c7c5855b319d00d279b0294820ed9f4
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/61/637361/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/all/all.yml'],1,65086cf05ef2c9173dda93513c18dfa59f9322b8,release_osa,openstack_release: 17.1.9,openstack_release: 17.1.8,1,1
openstack%2Fopenstack-ansible~stable%2Fpike~I329903a21e36bc4e9ac13cbb99d3fd31569310b5,openstack/openstack-ansible,stable/pike,I329903a21e36bc4e9ac13cbb99d3fd31569310b5,Bump version to 16.0.27,ABANDONED,2019-02-16 06:34:31.000000000,2019-02-21 15:13:17.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-16 06:34:31.000000000', 'files': ['group_vars/all/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c0310a82431817d530eed4747349834a089aaf6d', 'message': 'Bump version to 16.0.27\n\nDepends-On: https://review.openstack.org/637362\nChange-Id: I329903a21e36bc4e9ac13cbb99d3fd31569310b5\n'}]",0,637363,c0310a82431817d530eed4747349834a089aaf6d,3,1,1,17068,,,0,"Bump version to 16.0.27

Depends-On: https://review.openstack.org/637362
Change-Id: I329903a21e36bc4e9ac13cbb99d3fd31569310b5
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/63/637363/1 && git format-patch -1 --stdout FETCH_HEAD,['group_vars/all/all.yml'],1,c0310a82431817d530eed4747349834a089aaf6d,release_osa,openstack_release: 16.0.27,openstack_release: 16.0.26,1,1
openstack%2Fpatrole~master~I6be6db7011c296b5eba6164eaa82d53fe3b7d202,openstack/patrole,master,I6be6db7011c296b5eba6164eaa82d53fe3b7d202,add python 3.7 unit test job,MERGED,2019-02-19 09:07:02.000000000,2019-02-21 15:09:47.000000000,2019-02-21 15:09:47.000000000,"[{'_account_id': 8911}, {'_account_id': 9414}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2019-02-19 09:07:02.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/patrole/commit/198ac02ce29eafec5615af13c96e84aaad54a7cb', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: I6be6db7011c296b5eba6164eaa82d53fe3b7d202\nStory: #2004073\nTask: #27445\n'}]",0,637792,198ac02ce29eafec5615af13c96e84aaad54a7cb,10,4,1,9414,,,0,"add python 3.7 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.7.

See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html

Change-Id: I6be6db7011c296b5eba6164eaa82d53fe3b7d202
Story: #2004073
Task: #27445
",git fetch https://review.opendev.org/openstack/patrole refs/changes/92/637792/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,198ac02ce29eafec5615af13c96e84aaad54a7cb,py37-job, - openstack-python37-jobs,,1,0
openstack%2Fos-vif~master~Ib7b0cca596c0cad8095ef18243b94ada2587d1cd,openstack/os-vif,master,Ib7b0cca596c0cad8095ef18243b94ada2587d1cd,Clean up versioned object backlevelling code,MERGED,2019-01-15 13:48:00.000000000,2019-02-21 14:48:36.000000000,2019-02-21 14:48:36.000000000,"[{'_account_id': 7}, {'_account_id': 7634}, {'_account_id': 9732}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 25733}]","[{'number': 1, 'created': '2019-01-15 13:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/988748b0d6314503d69dd5db99d1e76186453b83', 'message': 'Clean up versioned object backlevelling code\n\nChange-Id: Ib7b0cca596c0cad8095ef18243b94ada2587d1cd\n'}, {'number': 2, 'created': '2019-01-15 15:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/07ae52021ca051b8aed07c93e91f90378070dc13', 'message': 'Clean up versioned object backlevelling code\n\nThe backlevelling code for the VIF objects have a number of sharp edges.\nThis commit changes the layout of the obj_make_compatible methods to conform\nto the following pattern:\n\n  # For the following version history:\n  # Version 1.0: Initial Release\n  # Version 1.1: Added member_one_one\n  # Version 1.2: Base Class version increased to 1.1 from 1.0\n  # Version 1.3: Added member_one_three\n  # Version 1.4: Base Class version increased to 1.2 from 1.1\n\n  0. use versionutils to calculate target_tuple\n  1. Remove added members from the primitive:\n     - if target_tuple < (1, 1) and \'member_one_one\' in primitive:\n           del primitive[\'member_one_one\']\n     - if target_tuple < (1, 3) and \'member_one_three\' in primitive:\n           del primitive[\'member_one_three\']\n  2. Call the parent method explicitly when the parent class caused a version\n     bump in this object:\n     - if target_tuple < (1, 2):\n           super(MyClass, self).obj_make_compatible(primitive, ""1.0"")\n     - elif target_tuple < (1, 4):\n           super(MyClass, self).obj_make_compatible(primitive, ""1.1"")\n  3. Finally, if the parent class did not cause a version bump, call it\n     with the unchanged parameters:\n     - else:\n           super(MyClass, self).obj_make_compatible(primitive, target_version)\n\nChange-Id: Ib7b0cca596c0cad8095ef18243b94ada2587d1cd\nSigned-off-by: Jan Gutter <jan.gutter@netronome.com>\nblueprint: generic-os-vif-offloads\n'}, {'number': 3, 'created': '2019-01-15 16:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/f072ad2d053bc010ef45729e7d6e1c2ab6009278', 'message': 'Clean up versioned object backlevelling code\n\nThe backlevelling code for the VIF objects have a number of sharp edges.\nThis commit changes the layout of the obj_make_compatible methods to conform\nto the following pattern:\n\n  # For the following version history:\n  # Version 1.0: Initial Release\n  # Version 1.1: Added member_one_one\n  # Version 1.2: Base Class version increased to 1.1 from 1.0\n  # Version 1.3: Added member_one_three\n  # Version 1.4: Base Class version increased to 1.2 from 1.1\n\n  0. use versionutils to calculate target_tuple\n  1. Remove added members from the primitive:\n     - if target_tuple < (1, 1) and \'member_one_one\' in primitive:\n           del primitive[\'member_one_one\']\n     - if target_tuple < (1, 3) and \'member_one_three\' in primitive:\n           del primitive[\'member_one_three\']\n  2. Call the parent method explicitly when the parent class caused a version\n     bump in this object:\n     - if target_tuple < (1, 2):\n           super(MyClass, self).obj_make_compatible(primitive, ""1.0"")\n     - elif target_tuple < (1, 4):\n           super(MyClass, self).obj_make_compatible(primitive, ""1.1"")\n  3. Finally, if the parent class did not cause a version bump, call it\n     with the unchanged parameters:\n     - else:\n           super(MyClass, self).obj_make_compatible(primitive, target_version)\n\nChange-Id: Ib7b0cca596c0cad8095ef18243b94ada2587d1cd\nSigned-off-by: Jan Gutter <jan.gutter@netronome.com>\nblueprint: generic-os-vif-offloads\n'}, {'number': 4, 'created': '2019-02-19 14:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/1d357d8c78af10ccc49e5d5892fd0c3886181098', 'message': ""Clean up versioned object backlevelling code\n\nThe backlevelling code for the VIF objects have a number of sharp edges.\nThis commit changes the layout of the obj_make_compatible methods to conform\nto a fixed pattern.\n\nGiven the following version history:\n\n # Version 1.0: Initial Release based on ParentClass 1.0\n # Version 1.1: Added member_one_one\n # Version 1.2: ParentClass version increased to 1.1 from 1.0\n # Version 1.3: Added member_one_three\n # Version 1.4: ParentClass version increased to 1.2 from 1.1\n # Version 1.5: Added member_one_five\n\nUse the following pattern for obj_make_compatible():\n\n 0. use versionutils to calculate target_version\n\n 1. Remove added members from the primitive in reverse order:\n    - if target_version < (1, 5) and 'member_one_five' in primitive:\n          del primitive['member_one_five']\n    - if target_version < (1, 3) and 'member_one_three' in primitive:\n          del primitive['member_one_three']\n    - if target_version < (1, 1) and 'member_one_one' in primitive:\n          del primitive['member_one_one']\n\n 2. Call the parent method explicitly when the parent class caused a version\n    bump in this object, in the following if/elif tree:\n    - if target_version < (1, 2):\n          super(MyClass, self).obj_make_compatible(primitive, '1.0')\n    - elif target_version < (1, 4):\n          super(MyClass, self).obj_make_compatible(primitive, '1.1')\n\n 3. Finally, if target_version is recent enough, call the parent method with\n    the current version of the parent class:\n    - else:\n          super(MyClass, self).obj_make_compatible(primitive, '1.2')\n\nThis pattern has been documented in: https://review.openstack.org/632321/\n\nChange-Id: Ib7b0cca596c0cad8095ef18243b94ada2587d1cd\nSigned-off-by: Jan Gutter <jan.gutter@netronome.com>\nblueprint: generic-os-vif-offloads\n""}, {'number': 5, 'created': '2019-02-21 11:07:33.000000000', 'files': ['os_vif/objects/network.py', 'os_vif/objects/vif.py', 'os_vif/objects/host_info.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/c90081bb949a73f3bd6ba66868a06feac1b128d8', 'message': ""Clean up versioned object backlevelling code\n\nThe backlevelling code for the VIF objects have a number of sharp edges.\nThis commit changes the layout of the obj_make_compatible methods to conform\nto a fixed pattern.\n\nGiven the following version history:\n\n # Version 1.0: Initial Release based on ParentClass 1.0\n # Version 1.1: Added member_one_one\n # Version 1.2: ParentClass version increased to 1.1 from 1.0\n # Version 1.3: Added member_one_three\n # Version 1.4: ParentClass version increased to 1.2 from 1.1\n # Version 1.5: Added member_one_five\n\nUse the following pattern for obj_make_compatible():\n\n 0. use versionutils to calculate target_version\n\n 1. Remove added members from the primitive in reverse order:\n    - if target_version < (1, 5) and 'member_one_five' in primitive:\n          del primitive['member_one_five']\n    - if target_version < (1, 3) and 'member_one_three' in primitive:\n          del primitive['member_one_three']\n    - if target_version < (1, 1) and 'member_one_one' in primitive:\n          del primitive['member_one_one']\n\n 2. Call the parent method explicitly when the parent class caused a version\n    bump in this object, in the following if/elif tree:\n    - if target_version < (1, 2):\n          super(MyClass, self).obj_make_compatible(primitive, '1.0')\n    - elif target_version < (1, 4):\n          super(MyClass, self).obj_make_compatible(primitive, '1.1')\n\n 3. Finally, if target_version is recent enough, call the parent method with\n    the current version of the parent class:\n    - else:\n          super(MyClass, self).obj_make_compatible(primitive, '1.2')\n\nThis pattern has been documented in: https://review.openstack.org/632321/\n\nChange-Id: Ib7b0cca596c0cad8095ef18243b94ada2587d1cd\nSigned-off-by: Jan Gutter <jan.gutter@netronome.com>\nblueprint: generic-os-vif-offloads\n""}]",8,630976,c90081bb949a73f3bd6ba66868a06feac1b128d8,24,7,5,25733,,,0,"Clean up versioned object backlevelling code

The backlevelling code for the VIF objects have a number of sharp edges.
This commit changes the layout of the obj_make_compatible methods to conform
to a fixed pattern.

Given the following version history:

 # Version 1.0: Initial Release based on ParentClass 1.0
 # Version 1.1: Added member_one_one
 # Version 1.2: ParentClass version increased to 1.1 from 1.0
 # Version 1.3: Added member_one_three
 # Version 1.4: ParentClass version increased to 1.2 from 1.1
 # Version 1.5: Added member_one_five

Use the following pattern for obj_make_compatible():

 0. use versionutils to calculate target_version

 1. Remove added members from the primitive in reverse order:
    - if target_version < (1, 5) and 'member_one_five' in primitive:
          del primitive['member_one_five']
    - if target_version < (1, 3) and 'member_one_three' in primitive:
          del primitive['member_one_three']
    - if target_version < (1, 1) and 'member_one_one' in primitive:
          del primitive['member_one_one']

 2. Call the parent method explicitly when the parent class caused a version
    bump in this object, in the following if/elif tree:
    - if target_version < (1, 2):
          super(MyClass, self).obj_make_compatible(primitive, '1.0')
    - elif target_version < (1, 4):
          super(MyClass, self).obj_make_compatible(primitive, '1.1')

 3. Finally, if target_version is recent enough, call the parent method with
    the current version of the parent class:
    - else:
          super(MyClass, self).obj_make_compatible(primitive, '1.2')

This pattern has been documented in: https://review.openstack.org/632321/

Change-Id: Ib7b0cca596c0cad8095ef18243b94ada2587d1cd
Signed-off-by: Jan Gutter <jan.gutter@netronome.com>
blueprint: generic-os-vif-offloads
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/76/630976/4 && git format-patch -1 --stdout FETCH_HEAD,[],0,988748b0d6314503d69dd5db99d1e76186453b83,docs,,,0,0
openstack%2Fmagnum~master~If65474b6dc1d436d31f37e4966f3c7ba9838ccf1,openstack/magnum,master,If65474b6dc1d436d31f37e4966f3c7ba9838ccf1,[Docs] Add storyboard link and remove bp and bug link.,ABANDONED,2018-08-20 04:01:06.000000000,2019-02-21 14:37:19.000000000,,"[{'_account_id': 13861}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28706}]","[{'number': 1, 'created': '2018-08-20 04:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/03215c697d1521d7a30af98d69932c784f73fc66', 'message': '[Docs] Update the bug link\n\nChange the bug link from launchpad to storyboard. There is nothing\nin https://bugs.launchpad.net/magnum.\n\nChange-Id: If65474b6dc1d436d31f37e4966f3c7ba9838ccf1\n'}, {'number': 2, 'created': '2018-08-20 08:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/8bf2888726d16fcfb8210c9671b47e6433640b07', 'message': '[Docs] Add storyboard link and remove bug link.\n\nRemove the bug link because here is nothing in\nhttps://bugs.launchpad.net/magnum.\nAdd storyboard link.\n\nChange-Id: If65474b6dc1d436d31f37e4966f3c7ba9838ccf1\n'}, {'number': 3, 'created': '2018-09-10 08:56:19.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/249aaede8a0831bc70c15ea6031a943e4af0624a', 'message': '[Docs] Add storyboard link and remove bp and bug link.\n\nRemove the bp and bug link because here is nothing in\nhttps://bugs.launchpad.net/magnum.\nAdd storyboard link.\n\nChange-Id: If65474b6dc1d436d31f37e4966f3c7ba9838ccf1\n'}]",2,593480,249aaede8a0831bc70c15ea6031a943e4af0624a,9,4,3,28706,,,0,"[Docs] Add storyboard link and remove bp and bug link.

Remove the bp and bug link because here is nothing in
https://bugs.launchpad.net/magnum.
Add storyboard link.

Change-Id: If65474b6dc1d436d31f37e4966f3c7ba9838ccf1
",git fetch https://review.opendev.org/openstack/magnum refs/changes/80/593480/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,03215c697d1521d7a30af98d69932c784f73fc66,bp/and,* **Bugs:** https://storyboard.openstack.org/#!/project/1032,* **Bugs:** http://bugs.launchpad.net/magnum,1,1
openstack%2Fvitrage-tempest-plugin~master~I9f1a8a8a7a9316684b4206667e430fafdde5d4e0,openstack/vitrage-tempest-plugin,master,I9f1a8a8a7a9316684b4206667e430fafdde5d4e0,trying to remove vitrage dependency,MERGED,2019-02-20 13:40:48.000000000,2019-02-21 14:32:22.000000000,2019-02-21 14:32:22.000000000,"[{'_account_id': 1736}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-20 13:40:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/4a4930dbbbd7f864aa327ca3b593f6cfc3a99d90', 'message': 'trying to remove vitrage dependency\n\nChange-Id: I9f1a8a8a7a9316684b4206667e430fafdde5d4e0\n'}, {'number': 2, 'created': '2019-02-20 13:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/dea2dca5cfec1671f0ec65be830805e3c2ecaec9', 'message': 'trying to remove vitrage dependency\n\nChange-Id: I9f1a8a8a7a9316684b4206667e430fafdde5d4e0\n'}, {'number': 3, 'created': '2019-02-21 08:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/d4fe5c211554a8db98e9b81979653c66e2041172', 'message': 'trying to remove vitrage dependency\n\nChange-Id: I9f1a8a8a7a9316684b4206667e430fafdde5d4e0\n'}, {'number': 4, 'created': '2019-02-21 08:46:10.000000000', 'files': ['vitrage_tempest_plugin/tests/common/vitrage_utils.py', 'vitrage_tempest_plugin/tests/base.py', 'vitrage_tempest_plugin/tests/resources/mock_datasource/test_3rd_degree_scenarios.py'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/0484154f34c1d97d116f2b64c369a7352b38f5b4', 'message': 'trying to remove vitrage dependency\n\nChange-Id: I9f1a8a8a7a9316684b4206667e430fafdde5d4e0\n'}]",1,638152,0484154f34c1d97d116f2b64c369a7352b38f5b4,14,4,4,19134,,,0,"trying to remove vitrage dependency

Change-Id: I9f1a8a8a7a9316684b4206667e430fafdde5d4e0
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/52/638152/4 && git format-patch -1 --stdout FETCH_HEAD,['vitrage_tempest_plugin/tests/resources/mock_datasource/test_3rd_degree_scenarios.py'],1,4a4930dbbbd7f864aa327ca3b593f6cfc3a99d90,eyalb/dependency," g1_nodes = set(g1['nodes']) g1_links = set(g1['links']) g2_nodes = set(g2['nodes']) g2_links = set(g1['links']) to_remove = {'vitrage_sample_timestamp', 'update_timestamp', 'graph_index'} self._remove_keys_from_dicts(g1_nodes, g2_nodes, to_remove) self.assert_set_equal(g1_nodes, g2_nodes, msg + ""Nodes of each graph are not equal"") self.assert_set_equal(g1_links, g2_links, ""Edges of each graph are not equal"") def _remove_keys_from_dicts(self, dictionaries1, dictionaries2, keys_to_remove): self._delete_keys_from_dict(dictionaries1, keys_to_remove) self._delete_keys_from_dict(dictionaries2, keys_to_remove) @staticmethod def _delete_keys_from_dict(dictionaries, keys_to_remove): for dictionary in dictionaries: for key in keys_to_remove: if key in dictionary: del dictionary[key]"," g1 = v_utils.topology_to_graph(g1) g2 = v_utils.topology_to_graph(g2) g1_nodes = g1._g.node g1_edges = g1._g.adj g2_nodes = g2._g.node g2_edges = g2._g.adj self.assertEqual(g1.num_vertices(), g2.num_vertices(), msg + "" Two graphs have different amount of nodes"") self.assertEqual(g1.num_edges(), g2.num_edges(), msg + ""Two graphs have different amount of edges"") for n_id in g1_nodes: g1_node = g1_nodes.get(n_id) del g1_node['vitrage_sample_timestamp'] del g1_node['update_timestamp'] if 'graph_index' in g1_node: del g1_node['graph_index'] g2_node = g2_nodes.get(n_id) del g2_node['vitrage_sample_timestamp'] del g2_node['update_timestamp'] if 'graph_index' in g2_node: del g2_node['graph_index'] self.assert_dict_equal(g1_nodes.get(n_id), g2_nodes.get(n_id), msg + ""Nodes of each graph are not equal"") for e_source_id in g1_edges: self.assert_dict_equal(dict(g1_edges.get(e_source_id)), dict(g2_edges.get(e_source_id)), ""Edges of each graph are not equal"")",27,28
openstack%2Fcinder~master~I4178f8273fd50b947e3bbaabc9628f8b05fc5b31,openstack/cinder,master,I4178f8273fd50b947e3bbaabc9628f8b05fc5b31,Remove vgc-cluster,MERGED,2018-12-21 13:55:26.000000000,2019-02-21 14:27:59.000000000,2019-02-21 14:27:59.000000000,"[{'_account_id': 1736}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 20722}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}]","[{'number': 1, 'created': '2018-12-21 13:55:26.000000000', 'files': ['etc/cinder/rootwrap.d/volume.filters'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6c261d81d0ab9c21b2792beac96c8abd34f50772', 'message': 'Remove vgc-cluster\n\nRemvoe vgc-cluster command from rootwrap filers.\n\nChange-Id: I4178f8273fd50b947e3bbaabc9628f8b05fc5b31\nSigned-off-by: Charles Short <chucks@redhat.com>\n'}]",0,626899,6c261d81d0ab9c21b2792beac96c8abd34f50772,35,30,1,24,,,0,"Remove vgc-cluster

Remvoe vgc-cluster command from rootwrap filers.

Change-Id: I4178f8273fd50b947e3bbaabc9628f8b05fc5b31
Signed-off-by: Charles Short <chucks@redhat.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/99/626899/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/cinder/rootwrap.d/volume.filters'],1,6c261d81d0ab9c21b2792beac96c8abd34f50772,,,"# cinder/volume/drivers/hgst.py vgc-cluster: CommandFilter, vgc-cluster, root ",0,3
openstack%2Fcinder~master~I4f305429ec2baac8556b59e72292f06524370c17,openstack/cinder,master,I4f305429ec2baac8556b59e72292f06524370c17,Switch tempest-slow to be run on python 3,MERGED,2019-01-31 11:19:21.000000000,2019-02-21 14:24:30.000000000,2019-02-21 14:24:29.000000000,"[{'_account_id': 8556}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 11975}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29637}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-01-31 11:19:21.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e362b80c6a1a6fcdc182a352ce9b797f37bbda61', 'message': 'Switch tempest-slow to be run on python 3\n\nThis patch switches tempest-slow to new\ntempest-slow-py3 job.\n\nFor coverage of tempest-slow tests on py2,\nTempest check pipeline will continue running\nthis job on check pipeline. As this tempest-slow\njob is not from integrated gate template, it is\nok to run only py3 job on project side.\n\nDepends-On: https://review.openstack.org/633983\nChange-Id: I4f305429ec2baac8556b59e72292f06524370c17\n'}]",1,634205,e362b80c6a1a6fcdc182a352ce9b797f37bbda61,106,37,1,8556,,,0,"Switch tempest-slow to be run on python 3

This patch switches tempest-slow to new
tempest-slow-py3 job.

For coverage of tempest-slow tests on py2,
Tempest check pipeline will continue running
this job on check pipeline. As this tempest-slow
job is not from integrated gate template, it is
ok to run only py3 job on project side.

Depends-On: https://review.openstack.org/633983
Change-Id: I4f305429ec2baac8556b59e72292f06524370c17
",git fetch https://review.opendev.org/openstack/cinder refs/changes/05/634205/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,e362b80c6a1a6fcdc182a352ce9b797f37bbda61,, - tempest-slow-py3:, - tempest-slow:,1,1
openstack%2Fkeystone~master~I1e1117deabadaba26ea8e833a06180529e1e0a4b,openstack/keystone,master,I1e1117deabadaba26ea8e833a06180529e1e0a4b,Deprecate cache_on_issue configuration option,MERGED,2019-02-07 23:02:55.000000000,2019-02-21 14:24:28.000000000,2019-02-21 14:24:27.000000000,"[{'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 11589}, {'_account_id': 13063}, {'_account_id': 15054}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-02-07 23:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c1e71059f8e3200caff55ea34060a9c2dfd88021', 'message': ""Clarify cache_on_issue configuration option help text\n\nThe help text for ``keystone.conf [token] cache_on_issue`` claimed\nthat it only cached tokens if global caching was enabled through\noslo.cache and if ``keystone.conf [token] caching = True``. However,\nthe actual implementation doesn't check if ``keystone.conf [token]\ncaching = True`` at all. Even if token caching is disabled, tokens will\nbe cached when they are issued.\n\nThis commit updates the help text of the cache_on_issue configuration\noption to accurately describe what it does.\n\nWe should consider if we want this to be the behavior we want or if\nkeystone should not cache_on_issue if token caching is disabled.\n\nChange-Id: I1e1117deabadaba26ea8e833a06180529e1e0a4b\n""}, {'number': 2, 'created': '2019-02-07 23:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/335fa0b44d879236de2bcadc4203148167f9f048', 'message': ""Clarify cache_on_issue configuration option help text\n\nThe help text for ``keystone.conf [token] cache_on_issue`` claimed\nthat it only cached tokens if global caching was enabled through\noslo.cache and if ``keystone.conf [token] caching = True``. However,\nthe actual implementation doesn't check if ``keystone.conf [token]\ncaching = True`` at all. Even if token caching is disabled, tokens will\nbe cached when they are issued.\n\nThis commit updates the help text of the cache_on_issue configuration\noption to accurately describe what it does.\n\nWe should consider if we want this to be the behavior we want or if\nkeystone should not cache_on_issue if token caching is disabled.\n\nChange-Id: I1e1117deabadaba26ea8e833a06180529e1e0a4b\n""}, {'number': 3, 'created': '2019-02-18 17:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e84c47b33ae4e855ef352cc69397197965ca26c8', 'message': ""Deprecate cache_on_issue configuration option\n\nKeystone already supports a global caching toggle and an option to\nconfigure token caching explicitly. Having a third option to enable\npre-cached tokens is redundant, creates unnecessary complexity that\nbleeds through to operators, and causes weird behaviors if token\ncaching is disabled and pre-caching is not.\n\nThis commit deprecates the cache_on_issue configuration option in\nfavor of just using ``keystone.conf [token] caching`` option instead.\nThis commit also attempts to clarify the help text so that it\ndescribes the relationship between the various caching options, even\nif it is short-lived.\n\nThe help text for ``keystone.conf [token] cache_on_issue`` claimed\nthat it only cached tokens if global caching was enabled through\noslo.cache and if ``keystone.conf [token] caching = True``. However,\nthe actual implementation doesn't check if ``keystone.conf [token]\ncaching = True`` at all. Even if token caching is disabled, tokens\nwill be cached when they are issued.\n\nChange-Id: I1e1117deabadaba26ea8e833a06180529e1e0a4b\n""}, {'number': 4, 'created': '2019-02-18 17:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7963cf032e5bd20728847626b963fec7a724a79b', 'message': ""Deprecate cache_on_issue configuration option\n\nKeystone already supports a global caching toggle and an option to\nconfigure token caching explicitly. Having a third option to enable\npre-cached tokens is redundant, creates unnecessary complexity that\nbleeds through to operators, and causes weird behaviors if token\ncaching is disabled and pre-caching is not.\n\nThis commit deprecates the cache_on_issue configuration option in\nfavor of just using ``keystone.conf [token] caching`` option instead.\nThis commit also attempts to clarify the help text so that it\ndescribes the relationship between the various caching options, even\nif it is short-lived.\n\nThe help text for ``keystone.conf [token] cache_on_issue`` claimed\nthat it only cached tokens if global caching was enabled through\noslo.cache and if ``keystone.conf [token] caching = True``. However,\nthe actual implementation doesn't check if ``keystone.conf [token]\ncaching = True`` at all. Even if token caching is disabled, tokens\nwill be cached when they are issued.\n\nChange-Id: I1e1117deabadaba26ea8e833a06180529e1e0a4b\n""}, {'number': 5, 'created': '2019-02-18 17:32:23.000000000', 'files': ['keystone/token/provider.py', 'keystone/conf/token.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ebad027f21e9fc7f3420a700f22cb2ef422d6645', 'message': ""Deprecate cache_on_issue configuration option\n\nKeystone already supports a global caching toggle and an option to\nconfigure token caching explicitly. Having a third option to enable\npre-cached tokens is redundant, creates unnecessary complexity that\nbleeds through to operators, and causes weird behaviors if token\ncaching is disabled and pre-caching is not.\n\nThis commit deprecates the cache_on_issue configuration option in\nfavor of just using ``keystone.conf [token] caching`` option instead.\nThis commit also attempts to clarify the help text so that it\ndescribes the relationship between the various caching options, even\nif it is short-lived.\n\nThe help text for ``keystone.conf [token] cache_on_issue`` claimed\nthat it only cached tokens if global caching was enabled through\noslo.cache and if ``keystone.conf [token] caching = True``. However,\nthe actual implementation doesn't check if ``keystone.conf [token]\ncaching = True`` at all. Even if token caching is disabled, tokens\nwill be cached when they are issued.\n\nChange-Id: I1e1117deabadaba26ea8e833a06180529e1e0a4b\n""}]",9,635690,ebad027f21e9fc7f3420a700f22cb2ef422d6645,24,8,5,5046,,,0,"Deprecate cache_on_issue configuration option

Keystone already supports a global caching toggle and an option to
configure token caching explicitly. Having a third option to enable
pre-cached tokens is redundant, creates unnecessary complexity that
bleeds through to operators, and causes weird behaviors if token
caching is disabled and pre-caching is not.

This commit deprecates the cache_on_issue configuration option in
favor of just using ``keystone.conf [token] caching`` option instead.
This commit also attempts to clarify the help text so that it
describes the relationship between the various caching options, even
if it is short-lived.

The help text for ``keystone.conf [token] cache_on_issue`` claimed
that it only cached tokens if global caching was enabled through
oslo.cache and if ``keystone.conf [token] caching = True``. However,
the actual implementation doesn't check if ``keystone.conf [token]
caching = True`` at all. Even if token caching is disabled, tokens
will be cached when they are issued.

Change-Id: I1e1117deabadaba26ea8e833a06180529e1e0a4b
",git fetch https://review.opendev.org/openstack/keystone refs/changes/90/635690/4 && git format-patch -1 --stdout FETCH_HEAD,['keystone/conf/token.py'],1,c1e71059f8e3200caff55ea34060a9c2dfd88021,,effect unless global caching is enabled and will still cache tokens even if `[token] caching = False`.,effect unless global caching and token caching are enabled.,2,1
openstack%2Ftripleo-heat-templates~master~Ia9e29453c5f25b07fd81eed4fa08ce0b183215e6,openstack/tripleo-heat-templates,master,Ia9e29453c5f25b07fd81eed4fa08ce0b183215e6,Add environment enabling memcached for cache and authtoken,ABANDONED,2019-02-21 14:21:34.000000000,2019-02-21 14:23:26.000000000,,[],"[{'number': 1, 'created': '2019-02-21 14:21:34.000000000', 'files': ['puppet/all-nodes-config.j2.yaml', 'deployment/swift/swift-proxy-container-puppet.yaml', 'environments/memcached_servers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e35aacdd8c2c54bfa00dd0dc77cf358311488105', 'message': 'Add environment enabling memcached for cache and authtoken\n\nIf user wants they should be able to enable memcached even if it\ncan bring stability issues with HA.\n\nCo-Authored-By: Harry Rybacki <hrybacki@redhat.com>\nCo-Authored-By: Juan Antonio Osorio Robles <jaosorior@redhat.com>\nDepends-On: I4f204cf6622ae11c800cd66e88e905a58d7fdd4e\nChange-Id: Ia9e29453c5f25b07fd81eed4fa08ce0b183215e6\n'}]",0,638424,e35aacdd8c2c54bfa00dd0dc77cf358311488105,2,0,1,11166,,,0,"Add environment enabling memcached for cache and authtoken

If user wants they should be able to enable memcached even if it
can bring stability issues with HA.

Co-Authored-By: Harry Rybacki <hrybacki@redhat.com>
Co-Authored-By: Juan Antonio Osorio Robles <jaosorior@redhat.com>
Depends-On: I4f204cf6622ae11c800cd66e88e905a58d7fdd4e
Change-Id: Ia9e29453c5f25b07fd81eed4fa08ce0b183215e6
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/24/638424/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/all-nodes-config.j2.yaml', 'deployment/swift/swift-proxy-container-puppet.yaml', 'environments/memcached_servers.yaml']",3,e35aacdd8c2c54bfa00dd0dc77cf358311488105,,"# Environment file used to enable memcached caching # WARNING: python-memcached library used by oslo_cache is # not safe for multi node setups. In case of # outage of one memcached server you might hit # performance issues or increased case misses. # parameter_defaults: ExtraConfig: aodh::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" aodh::keystone::authtoken::memcache_pool_conn_get_timeout: 1 aodh::keystone::authtoken::memcache_pool_dead_retry: 600 aodh::keystone::authtoken::memcache_pool_socket_timeout: 1 aodh::keystone::authtoken::memcache_pool_unused_timeout: 10 cinder::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" cinder::keystone::authtoken::memcache_pool_conn_get_timeout: 1 cinder::keystone::authtoken::memcache_pool_dead_retry: 600 cinder::keystone::authtoken::memcache_pool_socket_timeout: 1 cinder::keystone::authtoken::memcache_pool_unused_timeout: 10 glance::api::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" glance::api::authtoken::memcache_pool_conn_get_timeout: 1 glance::api::authtoken::memcache_pool_dead_retry: 600 glance::api::authtoken::memcache_pool_socket_timeout: 1 glance::api::authtoken::memcache_pool_unused_timeout: 10 heat::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" heat::keystone::authtoken::memcache_pool_conn_get_timeout: 1 heat::keystone::authtoken::memcache_pool_dead_retry: 600 heat::keystone::authtoken::memcache_pool_socket_timeout: 1 heat::keystone::authtoken::memcache_pool_unused_timeout: 10 heat::cache::enabled: true heat::cache::backend: 'oslo_cache.memcache_pool' heat::cache::memcache_servers: ""%{hiera('memcached_servers')}"" heat::cache::memcache_dead_retry: 600 heat::cache::memcache_socket_timeout: 1 heat::cache::memcache_pool_unused_timeout: 10 heat::cache::memcache_pool_connection_get_timeout: 1 ironic::api::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" ironic::api::authtoken::memcache_pool_conn_get_timeout: 1 ironic::api::authtoken::memcache_pool_dead_retry: 600 ironic::api::authtoken::memcache_pool_socket_timeout: 1 ironic::api::authtoken::memcache_pool_unused_timeout: 10 ironic::inspector::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" ironic::inspector::authtoken::memcache_pool_conn_get_timeout: 1 ironic::inspector::authtoken::memcache_pool_dead_retry: 600 ironic::inspector::authtoken::memcache_pool_socket_timeout: 1 ironic::inspector::authtoken::memcache_pool_unused_timeout: 10 keystone::cache_memcache_servers: ""%{hiera('memcached_servers')}"" keystone::memcache_dead_retry: 600 keystone::memcache_socket_timeout: 1 keystone::memcache_pool_unused_timeout: 10 keystone::memcache_pool_connection_get_timeout: 1 keystone::cache_enabled: true keystone::cache_backend: 'oslo_cache.memcache_pool' manila::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" manila::keystone::authtoken::memcache_pool_conn_get_timeout: 1 manila::keystone::authtoken::memcache_pool_dead_retry: 600 manila::keystone::authtoken::memcache_pool_socket_timeout: 1 manila::keystone::authtoken::memcache_pool_unused_timeout: 10 manila::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" manila::keystone::authtoken::memcache_pool_conn_get_timeout: 1 manila::keystone::authtoken::memcache_pool_dead_retry: 600 manila::keystone::authtoken::memcache_pool_socket_timeout: 1 manila::keystone::authtoken::memcache_pool_unused_timeout: 10 mistral::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" mistral::keystone::authtoken::memcache_pool_conn_get_timeout: 1 mistral::keystone::authtoken::memcache_pool_dead_retry: 600 mistral::keystone::authtoken::memcache_pool_socket_timeout: 1 mistral::keystone::authtoken::memcache_pool_unused_timeout: 10 neutron::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" neutron::keystone::authtoken::memcache_pool_conn_get_timeout: 1 neutron::keystone::authtoken::memcache_pool_dead_retry: 600 neutron::keystone::authtoken::memcache_pool_socket_timeout: 1 neutron::keystone::authtoken::memcache_pool_unused_timeout: 10 nova::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" nova::keystone::authtoken::memcache_pool_conn_get_timeout: 1 nova::keystone::authtoken::memcache_pool_dead_retry: 600 nova::keystone::authtoken::memcache_pool_socket_timeout: 1 nova::keystone::authtoken::memcache_pool_unused_timeout: 10 panko::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" panko::keystone::authtoken::memcache_pool_conn_get_timeout: 1 panko::keystone::authtoken::memcache_pool_dead_retry: 600 panko::keystone::authtoken::memcache_pool_socket_timeout: 1 panko::keystone::authtoken::memcache_pool_unused_timeout: 10 sahara::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" sahara::keystone::authtoken::memcache_pool_conn_get_timeout: 1 sahara::keystone::authtoken::memcache_pool_dead_retry: 600 sahara::keystone::authtoken::memcache_pool_socket_timeout: 1 sahara::keystone::authtoken::memcache_pool_unused_timeout: 10 swift::proxy::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" swift::proxy::authtoken::memcache_pool_conn_get_timeout: 1 swift::proxy::authtoken::memcache_pool_dead_retry: 600 swift::proxy::authtoken::memcache_pool_socket_timeout: 1 swift::proxy::authtoken::memcache_pool_unused_timeout: 10 tacker::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" tacker::keystone::authtoken::memcache_pool_conn_get_timeout: 1 tacker::keystone::authtoken::memcache_pool_dead_retry: 600 tacker::keystone::authtoken::memcache_pool_socket_timeout: 1 tacker::keystone::authtoken::memcache_pool_unused_timeout: 10 zaqar::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" zaqar::keystone::authtoken::memcache_pool_conn_get_timeout: 1 zaqar::keystone::authtoken::memcache_pool_dead_retry: 600 zaqar::keystone::authtoken::memcache_pool_socket_timeout: 1 zaqar::keystone::authtoken::memcache_pool_unused_timeout: 10 designate::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" designate::keystone::authtoken::memcache_pool_conn_get_timeout: 1 designate::keystone::authtoken::memcache_pool_dead_retry: 600 designate::keystone::authtoken::memcache_pool_socket_timeout: 1 designate::keystone::authtoken::memcache_pool_unused_timeout: 10 nova::metadata::novajoin::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" nova::metadata::novajoin::authtoken::memcache_pool_conn_get_timeout: 1 nova::metadata::novajoin::authtoken::memcache_pool_dead_retry: 600 nova::metadata::novajoin::authtoken::memcache_pool_socket_timeout: 1 nova::metadata::novajoin::authtoken::memcache_pool_unused_timeout: 10 barbican::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" barbican::keystone::authtoken::memcache_pool_conn_get_timeout: 1 barbican::keystone::authtoken::memcache_pool_dead_retry: 600 barbican::keystone::authtoken::memcache_pool_socket_timeout: 1 barbican::keystone::authtoken::memcache_pool_unused_timeout: 10 ceilometer::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" ceilometer::keystone::authtoken::memcache_pool_conn_get_timeout: 1 ceilometer::keystone::authtoken::memcache_pool_dead_retry: 600 ceilometer::keystone::authtoken::memcache_pool_socket_timeout: 1 ceilometer::keystone::authtoken::memcache_pool_unused_timeout: 10 congress::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" congress::keystone::authtoken::memcache_pool_conn_get_timeout: 1 congress::keystone::authtoken::memcache_pool_dead_retry: 600 congress::keystone::authtoken::memcache_pool_socket_timeout: 1 congress::keystone::authtoken::memcache_pool_unused_timeout: 10 designate::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" designate::keystone::authtoken::memcache_pool_conn_get_timeout: 1 designate::keystone::authtoken::memcache_pool_dead_retry: 600 designate::keystone::authtoken::memcache_pool_socket_timeout: 1 designate::keystone::authtoken::memcache_pool_unused_timeout: 10 ec2api::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" ec2api::keystone::authtoken::memcache_pool_conn_get_timeout: 1 ec2api::keystone::authtoken::memcache_pool_dead_retry: 600 ec2api::keystone::authtoken::memcache_pool_socket_timeout: 1 ec2api::keystone::authtoken::memcache_pool_unused_timeout: 10 gnocchi::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" gnocchi::keystone::authtoken::memcache_pool_conn_get_timeout: 1 gnocchi::keystone::authtoken::memcache_pool_dead_retry: 600 gnocchi::keystone::authtoken::memcache_pool_socket_timeout: 1 gnocchi::keystone::authtoken::memcache_pool_unused_timeout: 10 nova::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" nova::keystone::authtoken::memcache_pool_conn_get_timeout: 1 nova::keystone::authtoken::memcache_pool_dead_retry: 600 nova::keystone::authtoken::memcache_pool_socket_timeout: 1 nova::keystone::authtoken::memcache_pool_unused_timeout: 10 nova::cache::enabled: true nova::cache::backend: 'oslo_cache.memcache_pool' nova::cache::memcache_servers: ""%{hiera('memcached_servers')}"" nova::cache::memcache_dead_retry: 600 nova::cache::memcache_socket_timeout: 1 nova::cache::memcache_pool_unused_timeout: 10 nova::cache::memcache_pool_connection_get_timeout: 1 nova::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" nova::keystone::authtoken::memcache_pool_conn_get_timeout: 1 nova::keystone::authtoken::memcache_pool_dead_retry: 600 nova::keystone::authtoken::memcache_pool_socket_timeout: 1 nova::keystone::authtoken::memcache_pool_unused_timeout: 10 octavia::keystone::authtoken::memcached_servers: ""%{hiera('memcached_servers')}"" octavia::keystone::authtoken::memcache_pool_conn_get_timeout: 1 octavia::keystone::authtoken::memcache_pool_dead_retry: 600 octavia::keystone::authtoken::memcache_pool_socket_timeout: 1 octavia::keystone::authtoken::memcache_pool_unused_timeout: 10 ",,170,0
openstack%2Ftripleo-quickstart~master~I7ea2fd6170d65658a76c92c72e03eb2764f0925a,openstack/tripleo-quickstart,master,I7ea2fd6170d65658a76c92c72e03eb2764f0925a,DNM: test ci ovb,ABANDONED,2019-02-19 09:26:46.000000000,2019-02-21 14:23:08.000000000,,"[{'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-19 09:26:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/2126394c1853e2255b26d9d72cc712ed2f29b1c5', 'message': 'DNM: test ci ovb\n\nDepends-On: https://review.openstack.org/#/c/637616/\nDepends-On: https://review.openstack.org/#/c/637584/\n\nChange-Id: I7ea2fd6170d65658a76c92c72e03eb2764f0925a\n'}, {'number': 2, 'created': '2019-02-19 14:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/6070dadfa9b32e853346b3cbea6699354d8993de', 'message': 'DNM: test ci ovb\n\nDepends-On: https://review.openstack.org/#/c/637616/\nDepends-On: https://review.openstack.org/#/c/637584/\n\nChange-Id: I7ea2fd6170d65658a76c92c72e03eb2764f0925a\n'}, {'number': 3, 'created': '2019-02-19 14:19:07.000000000', 'files': ['config/general_config/featureset039.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/f232c0d10f236d660f6e50f115385d19eab361c6', 'message': 'DNM: test ci ovb\n\nChange-Id: I7ea2fd6170d65658a76c92c72e03eb2764f0925a\n'}]",0,637800,f232c0d10f236d660f6e50f115385d19eab361c6,10,3,3,10969,,,0,"DNM: test ci ovb

Change-Id: I7ea2fd6170d65658a76c92c72e03eb2764f0925a
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/00/637800/1 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset039.yml'],1,2126394c1853e2255b26d9d72cc712ed2f29b1c5,testfipa,# test,,1,1
openstack%2Fpuppet-tripleo~master~I1a4c8975b1bd39009df0cca3fbd4322facc66559,openstack/puppet-tripleo,master,I1a4c8975b1bd39009df0cca3fbd4322facc66559,DNM: test jobs in pt,ABANDONED,2019-02-20 13:16:46.000000000,2019-02-21 14:22:13.000000000,,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-20 13:16:46.000000000', 'files': ['manifests/network/os_net_config.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/83b2d4ae1ffcab8bb1d1039ac4bd3603c439cd8b', 'message': 'DNM: test jobs in pt\n\nChange-Id: I1a4c8975b1bd39009df0cca3fbd4322facc66559\n'}]",0,638148,83b2d4ae1ffcab8bb1d1039ac4bd3603c439cd8b,6,3,1,10969,,,0,"DNM: test jobs in pt

Change-Id: I1a4c8975b1bd39009df0cca3fbd4322facc66559
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/48/638148/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/network/os_net_config.pp'],1,83b2d4ae1ffcab8bb1d1039ac4bd3603c439cd8b,,# test,,1,0
openstack%2Fnova~master~Ib8becc39ce76847652d3538c3334cc3514ba7a33,openstack/nova,master,Ib8becc39ce76847652d3538c3334cc3514ba7a33,Fix typo in initial_disk_allocation_ratio release note,MERGED,2019-02-20 19:35:42.000000000,2019-02-21 14:21:11.000000000,2019-02-21 00:28:49.000000000,"[{'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 9008}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-20 19:35:42.000000000', 'files': ['releasenotes/notes/add_initial_allocation_ratio-2d2666d62426a4bf.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/945e7cb2a476258229ba94754c159ff966726459', 'message': 'Fix typo in initial_disk_allocation_ratio release note\n\nChange-Id: Ib8becc39ce76847652d3538c3334cc3514ba7a33\nCloses-Bug: #1816831\n'}]",0,638245,945e7cb2a476258229ba94754c159ff966726459,13,8,1,6873,,,0,"Fix typo in initial_disk_allocation_ratio release note

Change-Id: Ib8becc39ce76847652d3538c3334cc3514ba7a33
Closes-Bug: #1816831
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/638245/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/add_initial_allocation_ratio-2d2666d62426a4bf.yaml'],1,945e7cb2a476258229ba94754c159ff966726459,bug/1816831, - initial_disk_allocation_ratio with default value 1.0, - initial_ram_allocation_ratio with default value 1.0,1,1
openstack%2Fcharm-ceph-radosgw~master~I5c944d806ef458a82234dcc413cdd5ba34be7c18,openstack/charm-ceph-radosgw,master,I5c944d806ef458a82234dcc413cdd5ba34be7c18,Set appropriate application tag for pools created,MERGED,2019-02-20 05:53:30.000000000,2019-02-21 14:19:48.000000000,2019-02-21 14:19:48.000000000,"[{'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-20 05:53:30.000000000', 'files': ['hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/ceph_rgw.py', 'unit_tests/test_ceph.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/09703c286b879b746d9b104028ee9f408d828e1b', 'message': ""Set appropriate application tag for pools created\n\nUse cases are emerging for the Ceph pool application tags.  Let's\nset appropriate name for the pools created for RadosGW\n\nReference:\nhttp://docs.ceph.com/docs/master/rados/operations/pools/#associate-pool-to-application\n\nSync charm-helpers.\n\nChange-Id: I5c944d806ef458a82234dcc413cdd5ba34be7c18\n""}]",0,638084,09703c286b879b746d9b104028ee9f408d828e1b,10,5,1,13686,,,0,"Set appropriate application tag for pools created

Use cases are emerging for the Ceph pool application tags.  Let's
set appropriate name for the pools created for RadosGW

Reference:
http://docs.ceph.com/docs/master/rados/operations/pools/#associate-pool-to-application

Sync charm-helpers.

Change-Id: I5c944d806ef458a82234dcc413cdd5ba34be7c18
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/84/638084/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/ceph_rgw.py', 'unit_tests/test_ceph.py']",3,09703c286b879b746d9b104028ee9f408d828e1b,app-name," group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw')], group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw'), group='objects', app_name='rgw')],"," group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects')], group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects'), group='objects')],",86,71
openstack%2Fopenstack-helm-infra~master~I56bcd77f38adb3763d35f46443c1403816d1dcea,openstack/openstack-helm-infra,master,I56bcd77f38adb3763d35f46443c1403816d1dcea,[CEPH] Use civetweb by default for RGW with keystone,MERGED,2019-02-19 16:44:59.000000000,2019-02-21 14:16:22.000000000,2019-02-21 14:16:22.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 24165}, {'_account_id': 26628}, {'_account_id': 29268}]","[{'number': 1, 'created': '2019-02-19 16:44:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/887b20dfd91d3039a9538bf432f7133ec4f89810', 'message': '[CEPH] Increase the sleep time for the Swift/RGW gate job\n\nFrom time to time the gates will fail due to ingress not having\nenough time to configure. Increase the sleep from 60s to 120s to\ntry and mitigate this behavior.\n\nChange-Id: I56bcd77f38adb3763d35f46443c1403816d1dcea\n'}, {'number': 2, 'created': '2019-02-19 19:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9e53d1f750fceb2a5d88e558e1b16e84b4b05103', 'message': '[CEPH] Increase the sleep time for the Swift/RGW gate job\n\nFrom time to time the gates will fail due to ingress not having\nenough time to configure. Increase the sleep from 60s to 120s to\ntry and mitigate this behavior.\n\nChange-Id: I56bcd77f38adb3763d35f46443c1403816d1dcea\n'}, {'number': 3, 'created': '2019-02-20 20:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/fbb5dd5a661fd13cb1507b394c6f712acbf76939', 'message': '[CEPH] Use civetweb by default for RGW with keystone\n\nCurrently there is a bug in the beast code that makes it fail\nduring the initial lookup for a keystone user map. For the time\nbeing we will continue to use civetweb when keystone is present\nuntil this issue is resolved.\n\nChange-Id: I56bcd77f38adb3763d35f46443c1403816d1dcea\n'}, {'number': 4, 'created': '2019-02-20 21:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e76044c1d277260cfccda685b1d3132ca5d532ef', 'message': '[CEPH] Use civetweb by default for RGW with keystone\n\nCurrently there is a bug in the beast code that makes it fail\nduring the initial lookup for a keystone user map. For the time\nbeing we will continue to use civetweb when keystone is present\nuntil this issue is resolved.\n\nChange-Id: I56bcd77f38adb3763d35f46443c1403816d1dcea\n'}, {'number': 5, 'created': '2019-02-20 21:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bf5a95a5ef77f07ffa596d9a770ee54bcc8e9de9', 'message': '[CEPH] Use civetweb by default for RGW with keystone\n\nCurrently there is a bug in the beast code that makes it fail\nduring the initial lookup for a keystone user map. For the time\nbeing we will continue to use civetweb when keystone is present\nuntil this issue is resolved.\n\nChange-Id: I56bcd77f38adb3763d35f46443c1403816d1dcea\n'}, {'number': 6, 'created': '2019-02-21 02:10:35.000000000', 'files': ['ceph-rgw/templates/bin/rgw/_init.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/aad0394963e6916afc715c8289604349442675f7', 'message': '[CEPH] Use civetweb by default for RGW with keystone\n\nCurrently there is a bug in the beast code that makes it fail\nduring the initial lookup for a keystone user map. For the time\nbeing we will continue to use civetweb when keystone is present\nuntil this issue is resolved.\n\nChange-Id: I56bcd77f38adb3763d35f46443c1403816d1dcea\n'}]",1,637932,aad0394963e6916afc715c8289604349442675f7,25,7,6,29268,,,0,"[CEPH] Use civetweb by default for RGW with keystone

Currently there is a bug in the beast code that makes it fail
during the initial lookup for a keystone user map. For the time
being we will continue to use civetweb when keystone is present
until this issue is resolved.

Change-Id: I56bcd77f38adb3763d35f46443c1403816d1dcea
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/32/637932/6 && git format-patch -1 --stdout FETCH_HEAD,['tools/deployment/openstack-support/100-ceph-radosgateway.sh'],1,887b20dfd91d3039a9538bf432f7133ec4f89810,rgw_timeout_fix, #NOTE(portdirect): Wait for ingress controller to update rules and restart Nginx sleep 120,sleep 60 #NOTE(portdirect): Wait for ingress controller to update rules and restart Nginx,3,1
openstack%2Fneutron-lib~master~I212d1e5b2bf3d744488199f6aafcbdb4d0129099,openstack/neutron-lib,master,I212d1e5b2bf3d744488199f6aafcbdb4d0129099,Extend method with context for segment ranges,ABANDONED,2019-02-14 17:33:02.000000000,2019-02-21 14:09:43.000000000,,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 5367}, {'_account_id': 9531}, {'_account_id': 10980}, {'_account_id': 11975}, {'_account_id': 15070}, {'_account_id': 22348}, {'_account_id': 25437}, {'_account_id': 27654}, {'_account_id': 28373}, {'_account_id': 28439}, {'_account_id': 28550}]","[{'number': 1, 'created': '2019-02-14 17:33:02.000000000', 'files': ['releasenotes/notes/extend-validate-provider-segment-method-with-context-cb71ede6e674cccb.yaml', 'neutron_lib/plugins/ml2/api.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/68d4814c1f6b73521f2c4780a6c4fc4adaa1b751', 'message': 'Extend method with context for segment ranges\n\nThis patch extends the ML2 type driver abstract method\n``validate_provider_segment`` with ``context`` to support getting\nnetwork segment ranges from DB when network-segment-range extension is\nloaded.\n\nCo-authored-by: Allain Legacy <Allain.legacy@windriver.com>\n\nNeeded-by: https://review.openstack.org/624709\nPartially-implements: blueprint network-segment-range-management\nChange-Id: I212d1e5b2bf3d744488199f6aafcbdb4d0129099\n'}]",3,637015,68d4814c1f6b73521f2c4780a6c4fc4adaa1b751,8,13,1,28373,,,0,"Extend method with context for segment ranges

This patch extends the ML2 type driver abstract method
``validate_provider_segment`` with ``context`` to support getting
network segment ranges from DB when network-segment-range extension is
loaded.

Co-authored-by: Allain Legacy <Allain.legacy@windriver.com>

Needed-by: https://review.openstack.org/624709
Partially-implements: blueprint network-segment-range-management
Change-Id: I212d1e5b2bf3d744488199f6aafcbdb4d0129099
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/15/637015/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/extend-validate-provider-segment-method-with-context-cb71ede6e674cccb.yaml', 'neutron_lib/plugins/ml2/api.py']",2,68d4814c1f6b73521f2c4780a6c4fc4adaa1b751,bp/network-segment-range-management," def validate_provider_segment(self, segment, context=None): :param context: instance of neutron context with DB session if not None"," def validate_provider_segment(self, segment):",7,1
openstack%2Fcharm-ceph-radosgw~master~I7bfc016baf99188ba5a36f663145eeff465d25e8,openstack/charm-ceph-radosgw,master,I7bfc016baf99188ba5a36f663145eeff465d25e8,Switch auth order for s3 authentication,MERGED,2019-02-21 13:19:24.000000000,2019-02-21 14:02:19.000000000,2019-02-21 14:02:19.000000000,"[{'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 13:19:24.000000000', 'files': ['templates/ceph.conf'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/3e54b570b1124354704bd5c35c93dce6d260a479', 'message': 'Switch auth order for s3 authentication\n\nWhen deploying the RGW in multi-site configurations, communication\nbetween sites is authenticated using S3 credentials managed within\nRGW.  In the event that keystone authentication is in use this\ngenerates a large number of s3 authentication attempts to keystone\nwhich will always fail.\n\nSwitch the default order to check local auth first and then fallback\nto external.\n\nChange-Id: I7bfc016baf99188ba5a36f663145eeff465d25e8\n'}]",0,638418,3e54b570b1124354704bd5c35c93dce6d260a479,7,3,1,935,,,0,"Switch auth order for s3 authentication

When deploying the RGW in multi-site configurations, communication
between sites is authenticated using S3 credentials managed within
RGW.  In the event that keystone authentication is in use this
generates a large number of s3 authentication attempts to keystone
which will always fail.

Switch the default order to check local auth first and then fallback
to external.

Change-Id: I7bfc016baf99188ba5a36f663145eeff465d25e8
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/18/638418/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/ceph.conf'],1,3e54b570b1124354704bd5c35c93dce6d260a479,switch-s3-auth-order,"rgw s3 auth order = local, external",,1,0
openstack%2Fmonasca-persister~master~Ie8d1df43ecb232db015bcda843f9cdf9c2fd8fc8,openstack/monasca-persister,master,Ie8d1df43ecb232db015bcda843f9cdf9c2fd8fc8,first commit,ABANDONED,2019-02-21 12:49:49.000000000,2019-02-21 14:00:17.000000000,,"[{'_account_id': 10068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 12:49:49.000000000', 'files': ['test.a'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/447bb1f61e2655f0a4abad3efe34eb297a8d2d95', 'message': 'first commit\n\nChange-Id: Ie8d1df43ecb232db015bcda843f9cdf9c2fd8fc8\n'}]",0,638411,447bb1f61e2655f0a4abad3efe34eb297a8d2d95,4,2,1,29970,,,0,"first commit

Change-Id: Ie8d1df43ecb232db015bcda843f9cdf9c2fd8fc8
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/11/638411/1 && git format-patch -1 --stdout FETCH_HEAD,['test.a'],1,447bb1f61e2655f0a4abad3efe34eb297a8d2d95,testbranch,first pr ,,1,0
openstack%2Frally-openstack~master~I612a41c6f9d68c6a36a38c500212d5b87acc7799,openstack/rally-openstack,master,I612a41c6f9d68c6a36a38c500212d5b87acc7799,Use OctaviaBase class from utils,MERGED,2019-02-12 21:54:39.000000000,2019-02-21 13:49:41.000000000,2019-02-21 13:49:41.000000000,"[{'_account_id': 24}, {'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 21:54:39.000000000', 'files': ['rally_openstack/scenarios/octavia/loadbalancers.py'], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/3998f928c77f8250d0f3ff04e3168936c4155407', 'message': 'Use OctaviaBase class from utils\n\nThis commit makes loadbalancers.py use the octavia base class\nthat has been defined in utils instead of redefining it. Also,\nan unused import has been removed.\n\nChange-Id: I612a41c6f9d68c6a36a38c500212d5b87acc7799\n'}]",0,636446,3998f928c77f8250d0f3ff04e3168936c4155407,11,3,1,16845,,,0,"Use OctaviaBase class from utils

This commit makes loadbalancers.py use the octavia base class
that has been defined in utils instead of redefining it. Also,
an unused import has been removed.

Change-Id: I612a41c6f9d68c6a36a38c500212d5b87acc7799
",git fetch https://review.opendev.org/openstack/rally-openstack refs/changes/46/636446/1 && git format-patch -1 --stdout FETCH_HEAD,['rally_openstack/scenarios/octavia/loadbalancers.py'],1,3998f928c77f8250d0f3ff04e3168936c4155407,octaviabase,from rally_openstack.scenarios.octavia import utils as octavia_utilsclass CreateAndListLoadbalancers(octavia_utils.OctaviaBase):class CreateAndDeleteLoadbalancers(octavia_utils.OctaviaBase):class CreateAndUpdateLoadBalancers(octavia_utils.OctaviaBase):class CreateAndShowStatsLoadBalancers(octavia_utils.OctaviaBase):class CreateAndShowLoadBalancers(octavia_utils.OctaviaBase):,"from rally_openstack.services.loadbalancer import octaviaclass OctaviaBase(scenario.OpenStackScenario): """"""Base class for Octavia scenarios with basic atomic actions."""""" def __init__(self, context=None, admin_clients=None, clients=None): super(OctaviaBase, self).__init__(context, admin_clients, clients) self.octavia = octavia.Octavia( self._clients, name_generator=self.generate_random_name, atomic_inst=self.atomic_actions()) class CreateAndListLoadbalancers(OctaviaBase):class CreateAndDeleteLoadbalancers(OctaviaBase):class CreateAndUpdateLoadBalancers(OctaviaBase):class CreateAndShowStatsLoadBalancers(OctaviaBase):class CreateAndShowLoadBalancers(OctaviaBase):",6,16
openstack%2Fnetworking-odl~master~Ia297caea97114bf23e3f463d71a367a17163c15f,openstack/networking-odl,master,Ia297caea97114bf23e3f463d71a367a17163c15f,Change openstack-dev to openstack-discuss,MERGED,2018-12-04 18:18:11.000000000,2019-02-21 13:47:16.000000000,2019-02-21 13:47:16.000000000,"[{'_account_id': 17120}, {'_account_id': 17499}, {'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 26297}, {'_account_id': 26507}, {'_account_id': 28935}, {'_account_id': 29233}, {'_account_id': 29344}]","[{'number': 1, 'created': '2018-12-04 18:18:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/4b11702520f4f3b86301f781d21a2a073da79cc6', 'message': 'Change openstack-dev to openstack-discuss\n\nMailinglists have been updated. Openstack-discuss replaces openstack-dev.\n\nChange-Id: Ia297caea97114bf23e3f463d71a367a17163c15f\n'}, {'number': 2, 'created': '2019-01-10 12:12:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/dfa50282a47ef2a11008e4414066040911c8fd53', 'message': 'Change openstack-dev to openstack-discuss\n\nMailinglists have been updated. Openstack-discuss replaces openstack-dev.\n\nChange-Id: Ia297caea97114bf23e3f463d71a367a17163c15f\n'}, {'number': 3, 'created': '2019-01-11 06:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/56733b169e0384cdf5d5c4469e271180a46812cf', 'message': 'Change openstack-dev to openstack-discuss\n\nMailinglists have been updated. Openstack-discuss replaces openstack-dev.\n\nChange-Id: Ia297caea97114bf23e3f463d71a367a17163c15f\n'}, {'number': 4, 'created': '2019-01-13 11:20:28.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/2535cb447151c9553eec4f4b0357ce3a032d88b1', 'message': 'Change openstack-dev to openstack-discuss\n\nMailinglists have been updated. Openstack-discuss replaces openstack-dev.\n\nChange-Id: Ia297caea97114bf23e3f463d71a367a17163c15f\n'}]",0,622512,2535cb447151c9553eec4f4b0357ce3a032d88b1,30,9,4,28543,,,0,"Change openstack-dev to openstack-discuss

Mailinglists have been updated. Openstack-discuss replaces openstack-dev.

Change-Id: Ia297caea97114bf23e3f463d71a367a17163c15f
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/12/622512/4 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,4b11702520f4f3b86301f781d21a2a073da79cc6,,author-email = openstack-discuss@lists.openstack.org,author-email = openstack-dev@lists.openstack.org,1,1
openstack%2Fvitrage-tempest-plugin~master~I20385f03f0524c764915b319c4c4bc748cdfe3e2,openstack/vitrage-tempest-plugin,master,I20385f03f0524c764915b319c4c4bc748cdfe3e2,add new constants,MERGED,2019-02-20 11:31:03.000000000,2019-02-21 13:40:33.000000000,2019-02-21 13:40:33.000000000,"[{'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-20 11:31:03.000000000', 'files': ['vitrage_tempest_plugin/tests/common/constants.py', 'vitrage_tempest_plugin/tests/api/rca/base.py'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/91d34a481d75f4790fe3765e8ca0433290cefcae', 'message': 'add new constants\n\nadd constants to decouple vitrage dependency\n\nChange-Id: I20385f03f0524c764915b319c4c4bc748cdfe3e2\n'}]",0,638135,91d34a481d75f4790fe3765e8ca0433290cefcae,7,3,1,19134,,,0,"add new constants

add constants to decouple vitrage dependency

Change-Id: I20385f03f0524c764915b319c4c4bc748cdfe3e2
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/35/638135/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage_tempest_plugin/tests/common/constants.py', 'vitrage_tempest_plugin/tests/api/rca/base.py']",2,91d34a481d75f4790fe3765e8ca0433290cefcae,eyalb/constants,from vitrage_tempest_plugin.tests.common.constants \ import OperationalAlarmSeverity from vitrage_tempest_plugin.tests.common.constants \ import OperationalResourceState,from vitrage.entity_graph.mappings.operational_alarm_severity \ import OperationalAlarmSeverity from vitrage.entity_graph.mappings.operational_resource_state \ import OperationalResourceState,21,4
openstack%2Fnetworking-odl~master~Ia04ef9ec55bcf3d130f7d11056d5e31b02adcc40,openstack/networking-odl,master,Ia04ef9ec55bcf3d130f7d11056d5e31b02adcc40,Remove unused ryu from lower constraints,MERGED,2019-01-08 10:29:58.000000000,2019-02-21 13:39:08.000000000,2019-02-21 13:39:08.000000000,"[{'_account_id': 333}, {'_account_id': 2888}, {'_account_id': 5367}, {'_account_id': 7921}, {'_account_id': 9361}, {'_account_id': 12021}, {'_account_id': 17120}, {'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 25416}, {'_account_id': 26507}, {'_account_id': 29233}, {'_account_id': 29399}]","[{'number': 1, 'created': '2019-01-08 10:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/caf2f4e08c4f87ceaf962c6309b4f2331b9d01b7', 'message': 'Change in lower constraints for ryu\n\nThis is added due to change in external dependencies.\n\nChange-Id: Ia04ef9ec55bcf3d130f7d11056d5e31b02adcc40\nSigned-off-by: Ashik Alias <ashik.alias@ericsson.com>\n'}, {'number': 2, 'created': '2019-01-11 11:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/0d32e74b8bac18993a277572415da2d4148a140a', 'message': 'Change in lower constraints for ryu\n\nThis is added due to change in external dependencies.\n\nChange-Id: Ia04ef9ec55bcf3d130f7d11056d5e31b02adcc40\nSigned-off-by: Ashik Alias <ashik.alias@ericsson.com>\n'}, {'number': 3, 'created': '2019-01-11 11:19:56.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/42772ef8977f4504304225641c3cb07eb8f15e9c', 'message': 'Remove unused ryu from lower constraints\n\nThis will remove ryu from lower-constraints.\nryu is no longer used.\n\nChange-Id: Ia04ef9ec55bcf3d130f7d11056d5e31b02adcc40\nSigned-off-by: Ashik Alias <ashik.alias@ericsson.com>\n'}]",2,629136,42772ef8977f4504304225641c3cb07eb8f15e9c,19,13,3,29233,,,0,"Remove unused ryu from lower constraints

This will remove ryu from lower-constraints.
ryu is no longer used.

Change-Id: Ia04ef9ec55bcf3d130f7d11056d5e31b02adcc40
Signed-off-by: Ashik Alias <ashik.alias@ericsson.com>
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/36/629136/2 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,caf2f4e08c4f87ceaf962c6309b4f2331b9d01b7,,ryu==4.24,ryu==4.23,1,1
