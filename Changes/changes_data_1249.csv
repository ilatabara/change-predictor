id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fswift~master~I82359c87a0919d71693e49ecf08e0f1eedc9d18e,openstack/swift,master,I82359c87a0919d71693e49ecf08e0f1eedc9d18e,Fix bug with expirer and unicode,MERGED,2014-10-10 16:41:41.000000000,2014-10-20 20:16:25.000000000,2014-10-20 20:16:24.000000000,"[{'_account_id': 3}, {'_account_id': 995}, {'_account_id': 2622}, {'_account_id': 7847}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-10-10 16:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/02ee1a8faaddbe5aa8f43f127398669f631fd6f5', 'message': ""Fix bug with expirer and unicode\n\nLooks like I wasn't careful enough last time i fixed this bug- this\nis basically the same deal, just further down the line. What happens\nwithout this bug fix is you upload a object with a unicode name and\na x-delete-after header and when it does expire the customer object\ngets removed but the expirer marker object doesn't.\n\nChange-Id: I82359c87a0919d71693e49ecf08e0f1eedc9d18e\n""}, {'number': 2, 'created': '2014-10-10 21:39:55.000000000', 'files': ['test/unit/obj/test_expirer.py', 'swift/obj/expirer.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/a79682f2389e5ae5e6f40d37f23383ac977ca2a8', 'message': ""Fix bug with expirer and unicode\n\nLooks like I wasn't careful enough last time i fixed this bug- this\nis basically the same deal, just further down the line. What happens\nwithout this bug fix is you upload a object with a unicode name and\na x-delete-after header and when it does expire the customer object\ngets removed but the expirer marker object doesn't.\n\nChange-Id: I82359c87a0919d71693e49ecf08e0f1eedc9d18e\n""}]",0,127594,a79682f2389e5ae5e6f40d37f23383ac977ca2a8,13,5,2,995,,,0,"Fix bug with expirer and unicode

Looks like I wasn't careful enough last time i fixed this bug- this
is basically the same deal, just further down the line. What happens
without this bug fix is you upload a object with a unicode name and
a x-delete-after header and when it does expire the customer object
gets removed but the expirer marker object doesn't.

Change-Id: I82359c87a0919d71693e49ecf08e0f1eedc9d18e
",git fetch https://review.opendev.org/openstack/swift refs/changes/94/127594/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_expirer.py', 'swift/obj/expirer.py']",2,02ee1a8faaddbe5aa8f43f127398669f631fd6f5,expirer_bug_dos," container = str(c['name']) hashlib.md5('%s/%s' % (container, obj))."," container = c['name'] hashlib.md5('%s/%s' % (str(container), obj)).",10,11
openstack%2Fkolla~master~I1621f15cf1ec502418b454300645b46bc796dc8b,openstack/kolla,master,I1621f15cf1ec502418b454300645b46bc796dc8b,Use hostPort to lock 1 nova-compute/nova-network per node,MERGED,2014-10-19 20:27:54.000000000,2014-10-20 20:10:33.000000000,2014-10-20 20:10:33.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 5792}]","[{'number': 1, 'created': '2014-10-19 20:27:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b58e4ceaf5df5df6054034ee9ff20ce95f5d8174', 'message': 'Use hostPort to lock 1 nova-compute/nova-network per node\n\nKubernetes does not have a horizontal scaling feature that works per\nnode.  A workaround is to use hostPort to cause the scheduler not to schedule\nseveral replicationController replicas to each node.  By doing so, only one\nnova-compute is launched per node up to a total of 6 nodes which is the most\nwe can generate in testing.\n\nChange-Id: I1621f15cf1ec502418b454300645b46bc796dc8b\n'}, {'number': 2, 'created': '2014-10-20 17:19:03.000000000', 'files': ['k8s/replication/nova-compute-replication.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/f2c3719506e6ec0174fe7671ae5610faccedbcb9', 'message': 'Use hostPort to lock 1 nova-compute/nova-network per node\n\nKubernetes does not have a horizontal scaling feature that works per\nnode.  A workaround is to use hostPort to cause the scheduler not to schedule\nseveral replicationController replicas to each node.  By doing so, only one\nnova-compute is launched per node up to a total of 6 nodes which is the most\nwe can generate in testing.\n\nChange-Id: I1621f15cf1ec502418b454300645b46bc796dc8b\n'}]",0,129488,f2c3719506e6ec0174fe7671ae5610faccedbcb9,9,3,2,2834,,,0,"Use hostPort to lock 1 nova-compute/nova-network per node

Kubernetes does not have a horizontal scaling feature that works per
node.  A workaround is to use hostPort to cause the scheduler not to schedule
several replicationController replicas to each node.  By doing so, only one
nova-compute is launched per node up to a total of 6 nodes which is the most
we can generate in testing.

Change-Id: I1621f15cf1ec502418b454300645b46bc796dc8b
",git fetch https://review.opendev.org/openstack/kolla refs/changes/88/129488/1 && git format-patch -1 --stdout FETCH_HEAD,['k8s/replication/nova-compute-replication.yaml'],1,b58e4ceaf5df5df6054034ee9ff20ce95f5d8174,, ports: - containerPort: 12000 hostPort: 12000 image: kollaglue/fedora-rdo-nova-network ports: - containerPort: 12001 hostPort: 12001 replicas: 6, image: kollaglue/fedora-rdo-nova-libvirt ports: - containerPort: 16509 replicas: 1,7,3
openstack%2Fmonasca-api~master~I9c41569e05ff7d1839af3c904d4e4ae78334ff6a,openstack/monasca-api,master,I9c41569e05ff7d1839af3c904d4e4ae78334ff6a,Update alarm expression documentation,MERGED,2014-10-20 19:48:49.000000000,2014-10-20 20:02:15.000000000,2014-10-20 20:02:15.000000000,"[{'_account_id': 3}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-10-20 19:48:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/7a22ebd341a6585b8c4a9096bb07a6482f63171a', 'message': 'Update alarm expression documentation\n\nChange-Id: I9c41569e05ff7d1839af3c904d4e4ae78334ff6a\n'}, {'number': 2, 'created': '2014-10-20 19:51:19.000000000', 'files': ['docs/monasca-api-spec.md'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/33066e410733776f1b2c67310e0e8953e2b7baf7', 'message': 'Update alarm expression documentation\n\nChange-Id: I9c41569e05ff7d1839af3c904d4e4ae78334ff6a\n'}]",0,129713,33066e410733776f1b2c67310e0e8953e2b7baf7,8,2,2,12512,,,0,"Update alarm expression documentation

Change-Id: I9c41569e05ff7d1839af3c904d4e4ae78334ff6a
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/13/129713/2 && git format-patch -1 --stdout FETCH_HEAD,['docs/monasca-api-spec.md'],1,7a22ebd341a6585b8c4a9096bb07a6482f63171a,,"At the highest level, you have an expression, which is made up of one or more subexpressions, joined by boolean logic. Parenthesis can be used for separators. In a BNF style format where items enclosed in [] are optional: | function '(' metric [',' period] ')' relational_operator threshold_value ['times' periods]? ``` relational_operator : 'min' | 'max' | 'sum' | 'count' | 'avg' ``` ","At the highest level, you have an expression, which is made up of one or more subexpressions, joined by boolean logic. Parenthesis can be used for separators. In a BNF style format: | function '(' metric ',' period ')' relational_operator threshold_value ('times' periods)? ",7,2
openstack%2Freviewstats~master~Ia30bb9df45b1a8f8345ff8de184e61a878912449,openstack/reviewstats,master,Ia30bb9df45b1a8f8345ff8de184e61a878912449,Sync the infra subprojects to the governance list,MERGED,2014-10-18 20:45:53.000000000,2014-10-20 20:02:04.000000000,2014-10-20 20:02:04.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-10-18 20:45:53.000000000', 'files': ['projects/infra.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/b1a954f450f8d96794684926d135de98e441effc', 'message': 'Sync the infra subprojects to the governance list\n\nThis updates the list of subprojects in projects/infra.json with the\nlist of projects belonging to the Infra program according to\nreference/programs.yaml in the openstack/governance repo.\n\nChange-Id: Ia30bb9df45b1a8f8345ff8de184e61a878912449\n'}]",0,129440,b1a954f450f8d96794684926d135de98e441effc,7,4,1,5263,,,0,"Sync the infra subprojects to the governance list

This updates the list of subprojects in projects/infra.json with the
list of projects belonging to the Infra program according to
reference/programs.yaml in the openstack/governance repo.

Change-Id: Ia30bb9df45b1a8f8345ff8de184e61a878912449
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/40/129440/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/infra.json'],1,b1a954f450f8d96794684926d135de98e441effc,," ""openstack-dev/openstack-nose"", ""openstack-infra/bugdaystats"", ""openstack-infra/elastic-recheck"", ""openstack-infra/gerrit-powered-agenda"", ""openstack-infra/groups-static-pages"", ""openstack-infra/infra-manual"", ""openstack-infra/infra-specs"", ""openstack-infra/project-config"", ""openstack-infra/puppet-storyboard"", ""openstack-infra/puppet-yum"", ""openstack-infra/puppet-zuul"", ""openstack-infra/subunit2sql"", ""openstack-infra/system-config"", ""openstack-infra/tripleo-ci"", ""openstack-infra/zuul-packaging"", ""openstack/openstack-planet"""," ""openstack-infra/config"", ""openstack-infra/release-tools"", ""openstack-infra/zuul-packaging""",16,3
openstack%2Fkeystonemiddleware~master~I77c5432d4d7a31422c75f9d675ec0e15f6c1164d,openstack/keystonemiddleware,master,I77c5432d4d7a31422c75f9d675ec0e15f6c1164d,Remove HTTP_X_STORAGE_TOKEN doc,MERGED,2014-10-09 00:11:48.000000000,2014-10-20 19:44:01.000000000,2014-10-20 19:44:01.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 6537}, {'_account_id': 8978}]","[{'number': 1, 'created': '2014-10-09 00:11:48.000000000', 'files': ['keystonemiddleware/auth_token.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/e9477a5b0b61aa5fa9f2f9b7b106f5642506b9e7', 'message': ""Remove HTTP_X_STORAGE_TOKEN doc\n\nThis header isn't referenced in the code so remove it from the\ndocumentation.\n\nChange-Id: I77c5432d4d7a31422c75f9d675ec0e15f6c1164d\n""}]",0,127083,e9477a5b0b61aa5fa9f2f9b7b106f5642506b9e7,11,7,1,6486,,,0,"Remove HTTP_X_STORAGE_TOKEN doc

This header isn't referenced in the code so remove it from the
documentation.

Change-Id: I77c5432d4d7a31422c75f9d675ec0e15f6c1164d
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/83/127083/1 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token.py'],1,e9477a5b0b61aa5fa9f2f9b7b106f5642506b9e7,cleanup_doc,,HTTP_X_STORAGE_TOKEN The client token being passed in (legacy Rackspace use) to support swift/cloud files ,0,4
openstack%2Fkeystonemiddleware~master~I495bc332230f75e579e03c1b6f8feba49a26e5bf,openstack/keystonemiddleware,master,I495bc332230f75e579e03c1b6f8feba49a26e5bf,Fix reference to middleware architecture doc,MERGED,2014-10-08 23:40:20.000000000,2014-10-20 19:43:58.000000000,2014-10-20 19:43:57.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6537}, {'_account_id': 8978}]","[{'number': 1, 'created': '2014-10-08 23:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/a1b3e7dd39355090c5a69131e02497990f7f8f22', 'message': 'Fix reference to middleware architecture doc\n\nThe auth_token docstring was referencing the middleware architecture\ndoc in keystoneclient. Updated to the new location.\n\nChange-Id: I495bc332230f75e579e03c1b6f8feba49a26e5bf\n'}, {'number': 2, 'created': '2014-10-09 00:05:16.000000000', 'files': ['keystonemiddleware/auth_token.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/91ff5d1d932f285cf25ada0b04d2752a0c6532b7', 'message': 'Fix reference to middleware architecture doc\n\nThe auth_token docstring was referencing the middleware architecture\ndoc in keystoneclient. Updated to the new location.\n\nChange-Id: I495bc332230f75e579e03c1b6f8feba49a26e5bf\n'}]",0,127078,91ff5d1d932f285cf25ada0b04d2752a0c6532b7,11,6,2,6486,,,0,"Fix reference to middleware architecture doc

The auth_token docstring was referencing the middleware architecture
doc in keystoneclient. Updated to the new location.

Change-Id: I495bc332230f75e579e03c1b6f8feba49a26e5bf
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/78/127078/1 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token.py'],1,a1b3e7dd39355090c5a69131e02497990f7f8f22,fix_doc_ref,Refer to: http://docs.openstack.org/developer/keystonemiddleware/,Refer to: http://docs.openstack.org/developer/python-keystoneclient/,1,1
openstack%2Fos-cloud-config~master~Ic8f356d2d67324c0b2ccaa8a7b2cf7752635f68b,openstack/os-cloud-config,master,Ic8f356d2d67324c0b2ccaa8a7b2cf7752635f68b,Put a cap on our cyclomatic complexity,MERGED,2014-10-20 16:10:50.000000000,2014-10-20 19:43:45.000000000,2014-10-20 19:43:45.000000000,"[{'_account_id': 3}, {'_account_id': 8399}, {'_account_id': 8688}]","[{'number': 1, 'created': '2014-10-20 16:10:50.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/97d6b61c4573141c1064132ecac733db10808e64', 'message': 'Put a cap on our cyclomatic complexity\n\nflake8 supports cyclomatic complexity checking, so lets use it. Our\ncurrent worst offender is register_ironic_node (which I kind of agree\nwith) so setting our cap to 14 which is one higher than this.\n\nChange-Id: Ic8f356d2d67324c0b2ccaa8a7b2cf7752635f68b\n'}]",0,129656,97d6b61c4573141c1064132ecac733db10808e64,8,3,1,10035,,,0,"Put a cap on our cyclomatic complexity

flake8 supports cyclomatic complexity checking, so lets use it. Our
current worst offender is register_ironic_node (which I kind of agree
with) so setting our cap to 14 which is one higher than this.

Change-Id: Ic8f356d2d67324c0b2ccaa8a7b2cf7752635f68b
",git fetch https://review.opendev.org/openstack/os-cloud-config refs/changes/56/129656/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,97d6b61c4573141c1064132ecac733db10808e64,feature/cyclomatic-complexity-cap,max-complexity=14,,1,0
openstack%2Ftelemetry-specs~master~Iecf73ae3f009bebf327c7253337b12f15e746e4b,openstack/telemetry-specs,master,Iecf73ae3f009bebf327c7253337b12f15e746e4b,dedicated event database,MERGED,2014-10-03 15:25:14.000000000,2014-10-20 19:42:10.000000000,2014-10-20 19:42:10.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 7336}, {'_account_id': 9562}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-10-03 15:25:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/d7e48a1c2104aad885ce35a12f23a4f83635ac65', 'message': 'dedicated event database\n\nChange-Id: Iecf73ae3f009bebf327c7253337b12f15e746e4b\n'}, {'number': 2, 'created': '2014-10-03 15:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/ee3415e0f578c8b0e841ee3e12cee9c38d1559b4', 'message': 'dedicated event database\n\nChange-Id: Iecf73ae3f009bebf327c7253337b12f15e746e4b\n'}, {'number': 3, 'created': '2014-10-03 15:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/73f3450a0e83d1b4100df596cadd72c773c32857', 'message': 'dedicated event database\n\nChange-Id: Iecf73ae3f009bebf327c7253337b12f15e746e4b\n'}, {'number': 4, 'created': '2014-10-06 14:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/a13e308b1f298d2ae98db0ae7d73f39344add563', 'message': 'dedicated event database\n\nChange-Id: Iecf73ae3f009bebf327c7253337b12f15e746e4b\n'}, {'number': 5, 'created': '2014-10-06 19:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/93fae502e79869b1e0a58aed3384abed9091bc3e', 'message': 'dedicated event database\n\nChange-Id: Iecf73ae3f009bebf327c7253337b12f15e746e4b\n'}, {'number': 6, 'created': '2014-10-08 20:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/68c5a17729baa4b5145f99b388e9f31b480bc5da', 'message': 'dedicated event database\n\nChange-Id: Iecf73ae3f009bebf327c7253337b12f15e746e4b\n'}, {'number': 7, 'created': '2014-10-20 19:17:48.000000000', 'files': ['specs/kilo/dedicated-event-db.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/077692678de2e2c8b2350fd0134337378e2e6e3f', 'message': 'dedicated event database\n\nChange-Id: Iecf73ae3f009bebf327c7253337b12f15e746e4b\n'}]",16,125994,077692678de2e2c8b2350fd0134337378e2e6e3f,32,9,7,6537,,,0,"dedicated event database

Change-Id: Iecf73ae3f009bebf327c7253337b12f15e746e4b
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/94/125994/7 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/dedicated-event-db.rst'],1,d7e48a1c2104aad885ce35a12f23a4f83635ac65,dedicated-event-db,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Dedicated Event Database ========================================== https://blueprints.launchpad.net/ceilometer/+spec/dedicated-event-db Event data is designed to be a Problem description =================== Currently, metering and event data coexists on the same database. While related, there's a logical separation in the the metering and event models where the data in each model has it's own unique data and structure; the metering model can be best described as a time series while the event model is closer to an entity attribute model. As the models are different in what they capture, it makes sense that deployers may choose to different storage drivers to store each data set. Proposed change =============== Similar to the work done to split alarming into it's own database, this blueprint is to move all event related data to it's own database. Alternatives ------------ Continue on as status quo. Data model impact ----------------- None, the model remains the same. REST API impact --------------- None, the api will remain the same. The only change is the api will now read from events database when event api is called. Security impact --------------- None. Pipeline impact --------------- None. Other end user impact --------------------- The end user will now be able to store event data in a different database from metering data. Alternatively, they can continue on as how Ceilometer currently functions and store event and metering data in the same database. Performance/Scalability Impacts ------------------------------- This will probably improve scalability as it allows deployers to split event and metering data so a single database is not flooded by disconnected data sets. Other deployer impact --------------------- A config option to specify an event database is added:: [database] metering_connection=hbase:// alarm_connection=sqlite:// *event_connection=mongodb://* Developer impact ---------------- Future event related work should be done in event submodule. Implementation ============== Assignee(s) ----------- Primary assignee: chungg Ongoing maintainer: chungg Work Items ---------- * Move event models to event submodule * Add support for event_connection option and create framework for drivers in event submodule * Move over event related code for each driver from storage module to event submodule Future lifecycle ================ There is common code shared between alarm, event, and metering backends which can be refactored. Dependencies ============ None Testing ======= Existing testing should be sufficient. The only additional tests required are test the ability to define separate backends for each data set (alarm, event, metering) and to ensure the capabilities of each backend return the correct set of capabilities. Documentation Impact ==================== We need to update docs to highlight how to enable event specific backend. References ========== dedicated alarm database blueprint: https://blueprints.launchpad.net/ceilometer/+spec/dedicated-alarm-database ",,137,0
openstack%2Fglance-specs~master~Iaf86baa25ceeebb25a2027db0496000836b72ea6,openstack/glance-specs,master,Iaf86baa25ceeebb25a2027db0496000836b72ea6,remove unused index.rst,ABANDONED,2014-10-20 19:37:23.000000000,2014-10-20 19:39:34.000000000,,[],"[{'number': 1, 'created': '2014-10-20 19:37:23.000000000', 'files': ['specs/index.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/da0fa63965b2ec79878b48eea74e25967f197cca', 'message': 'remove unused index.rst\n\nChange-Id: Iaf86baa25ceeebb25a2027db0496000836b72ea6\n'}]",0,129709,da0fa63965b2ec79878b48eea74e25967f197cca,2,0,1,2472,,,0,"remove unused index.rst

Change-Id: Iaf86baa25ceeebb25a2027db0496000836b72ea6
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/09/129709/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/index.rst'],1,da0fa63965b2ec79878b48eea74e25967f197cca,rss-feed,,================ Specifications ================ .. toctree:: :glob: :maxdepth: 1 juno/index kilo/index ,0,10
openstack%2Ftempest~master~I50ffdcbc8a8f4830ba9c274af4c908e96467dad5,openstack/tempest,master,I50ffdcbc8a8f4830ba9c274af4c908e96467dad5,Remove PYTHONHASHSEED=0 from tox pep8 job,MERGED,2014-10-16 18:33:51.000000000,2014-10-20 19:36:22.000000000,2014-10-20 19:36:21.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 7350}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-16 18:33:51.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest/commit/edcb24c85864c3fd61def8462998bbdd62acce16', 'message': 'Remove PYTHONHASHSEED=0 from tox pep8 job\n\nTempest has moved to new oslo-config-generator and this bug\nworkaround is no longer needed.\n\nChange-Id: I50ffdcbc8a8f4830ba9c274af4c908e96467dad5\nCloses-Bug: 1365136\n'}]",0,129016,edcb24c85864c3fd61def8462998bbdd62acce16,9,5,1,9349,,,0,"Remove PYTHONHASHSEED=0 from tox pep8 job

Tempest has moved to new oslo-config-generator and this bug
workaround is no longer needed.

Change-Id: I50ffdcbc8a8f4830ba9c274af4c908e96467dad5
Closes-Bug: 1365136
",git fetch https://review.opendev.org/openstack/tempest refs/changes/16/129016/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,edcb24c85864c3fd61def8462998bbdd62acce16,bug/1365136,,setenv = PYTHONHASHSEED=0,0,1
openstack%2Fnova~master~I5117ca58ad28888e24c16251aa5e92084ead97ca,openstack/nova,master,I5117ca58ad28888e24c16251aa5e92084ead97ca,Put a cap on our cyclomatic complexity,MERGED,2014-10-17 04:06:04.000000000,2014-10-20 19:35:22.000000000,2014-10-20 19:35:19.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 679}, {'_account_id': 1063}, {'_account_id': 5170}, {'_account_id': 8125}, {'_account_id': 8688}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-17 04:06:04.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/95681b98f73bea96e53a23cecad3b93bddf1c2b7', 'message': ""Put a cap on our cyclomatic complexity\n\nflake8 has support for cyclomatic complexity (Mccabe) currently our\nworst offender has a complexity of 67 (25 is considered very bad). So\nset our max-complexity to 68 so we at least don't make things any worse.\n\nThis is the first step in bringing this number down to 25 or so.\n\nhttps://github.com/flintwork/mccabe\n\nChange-Id: I5117ca58ad28888e24c16251aa5e92084ead97ca\n""}]",0,129125,95681b98f73bea96e53a23cecad3b93bddf1c2b7,16,11,1,1849,,,0,"Put a cap on our cyclomatic complexity

flake8 has support for cyclomatic complexity (Mccabe) currently our
worst offender has a complexity of 67 (25 is considered very bad). So
set our max-complexity to 68 so we at least don't make things any worse.

This is the first step in bringing this number down to 25 or so.

https://github.com/flintwork/mccabe

Change-Id: I5117ca58ad28888e24c16251aa5e92084ead97ca
",git fetch https://review.opendev.org/openstack/nova refs/changes/25/129125/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,95681b98f73bea96e53a23cecad3b93bddf1c2b7,complexity,# 67 is currently the most complex thing we have # TODO(jogo): get this number down to 25 or so max-complexity=68,,3,0
openstack%2Fmonasca-agent~master~I23781a1ba552ef2551e6ff1caea21dd8f515d73d,openstack/monasca-agent,master,I23781a1ba552ef2551e6ff1caea21dd8f515d73d,Add support for VM monitoring,MERGED,2014-10-03 20:54:30.000000000,2014-10-20 19:24:54.000000000,2014-10-20 19:24:54.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 12108}, {'_account_id': 12443}]","[{'number': 1, 'created': '2014-10-03 20:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/aa3a8af9b4b8731f86c135fa2fa0d6c2d0f4a2e7', 'message': 'Add support for VM monitoring\n\nThis patch gives the Monasca Agent the ability to monitor virtual\nmachines (VMs) provisioned under Nova.  It bundles Ceilometer\'s\nvirtualization inspector to gather the actual metrics, includes a\nmonasca-setup plugin, and adds cross-tenant support.  The latter\nenables the Agent to submit metrics on behalf of a different\ntenant/project, giving the VM\'s owner a set of metrics without each\nVM having to run its own Agent.  This plugin collects two sets of\nmeasurements per metric: one for the VM\'s owner (in-cloud) and for\nthe Operations team (infrastructure).  They differ in the following\nways:\n- Operations metric names are prefixed with ""vm."" in order to group VM\n  and overcloud metrics separately\n- Operations metrics include ""tenant_id"" as a dimension\n- Operations metrics include ""cloud_tier"" dimension with the value\n  ""overcloud""\n- The ""hostname"" dimension for Operations contains the name of the\n  compute server; for the tenant, ""hostname"" is the name of the VM\n\nThe metrics gathered by this plugin include:\n- Disk I/O: read/write operations/bytes per second\n- Disk I/O: errors per second\n- Network I/O: in/out packets/bytes per second\n- CPU utilization as a percentage of CPU time over polling time\n\nChange-Id: I23781a1ba552ef2551e6ff1caea21dd8f515d73d\n'}, {'number': 2, 'created': '2014-10-15 19:06:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/1b5ae556f2d0b7c0d830221992f4ca13e874bc37', 'message': 'Add support for VM monitoring\n\nThis patch gives the Monasca Agent the ability to monitor virtual\nmachines (VMs) provisioned under Nova.  It bundles Ceilometer\'s\nvirtualization inspector to gather the actual metrics, includes a\nmonasca-setup plugin, and adds cross-tenant support.  The latter\nenables the Agent to submit metrics on behalf of a different\ntenant/project, giving the VM\'s owner a set of metrics without each\nVM having to run its own Agent.  This plugin collects two sets of\nmeasurements per metric: one for the VM\'s owner (in-cloud) and for\nthe Operations team (infrastructure).  They differ in the following\nways:\n- Operations metric names are prefixed with ""vm."" in order to group VM\n  and overcloud metrics separately\n- Operations metrics include ""tenant_id"" as a dimension\n- Operations metrics include ""cloud_tier"" dimension with the value\n  ""overcloud""\n- The ""hostname"" dimension for Operations contains the name of the\n  compute server; for the tenant, ""hostname"" is the name of the VM\n\nThe metrics gathered by this plugin include:\n- Disk I/O: read/write operations/bytes per second\n- Disk I/O: errors per second\n- Network I/O: in/out packets/bytes per second\n- CPU utilization as a percentage of CPU time over polling time\n\nChange-Id: I23781a1ba552ef2551e6ff1caea21dd8f515d73d\n'}, {'number': 3, 'created': '2014-10-15 19:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/bf3a30e075d9d616622e84713a2cfc195f9c486e', 'message': 'Add support for VM monitoring\n\nThis patch gives the Monasca Agent the ability to monitor virtual\nmachines (VMs) provisioned under Nova.  It bundles Ceilometer\'s\nvirtualization inspector to gather the actual metrics, includes a\nmonasca-setup plugin, and adds cross-tenant support.  The latter\nenables the Agent to submit metrics on behalf of a different\ntenant/project, giving the VM\'s owner a set of metrics without each\nVM having to run its own Agent.  This plugin collects two sets of\nmeasurements per metric: one for the VM\'s owner (in-cloud) and for\nthe Operations team (infrastructure).  They differ in the following\nways:\n- Operations metric names are prefixed with ""vm."" in order to group VM\n  and overcloud metrics separately\n- Operations metrics include ""tenant_id"" as a dimension\n- Operations metrics include ""cloud_tier"" dimension with the value\n  ""overcloud""\n- The ""hostname"" dimension for Operations contains the name of the\n  compute server; for the tenant, ""hostname"" is the name of the VM\n\nThe metrics gathered by this plugin include:\n- Disk I/O: read/write operations/bytes per second\n- Disk I/O: errors per second\n- Network I/O: in/out packets/bytes per second\n- CPU utilization as a percentage of CPU time over polling time\n\nChange-Id: I23781a1ba552ef2551e6ff1caea21dd8f515d73d\n'}, {'number': 4, 'created': '2014-10-17 16:58:10.000000000', 'files': ['monagent/collector/virt/libvirt/__init__.py', 'monagent/collector/virt/libvirt/inspector.py', 'monagent/collector/virt/xenapi/__init__.py', 'monagent/collector/virt/hyperv/utilsv2.py', 'monagent/collector/checks/system/unix.py', 'monagent/collector/checks/collector.py', 'monagent/collector/virt/inspector.py', 'monagent/collector/virt/__init__.py', 'monagent/collector/virt/vmware/inspector.py', 'README.md', 'monsetup/detection/plugins/libvirt.py', 'monagent/collector/virt/xenapi/inspector.py', 'monagent/common/metrics.py', 'monagent/forwarder/api/mon.py', 'monagent/common/aggregator.py', 'monagent/collector/virt/vmware/vsphere_operations.py', 'monagent/collector/virt/hyperv/__init__.py', 'monagent/collector/checks/check.py', 'monagent/collector/virt/hyperv/inspector.py', 'monagent/collector/virt/vmware/__init__.py', 'setup.cfg', 'monsetup/main.py', 'monagent/collector/checks_d/libvirt.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/3734c3805bbf324b254335ba45de00d20d129247', 'message': 'Add support for VM monitoring\n\nThis patch gives the Monasca Agent the ability to monitor virtual\nmachines (VMs) provisioned under Nova.  It bundles Ceilometer\'s\nvirtualization inspector to gather the actual metrics, includes a\nmonasca-setup plugin, and adds cross-tenant support.  The latter\nenables the Agent to submit metrics on behalf of a different\ntenant/project, giving the VM\'s owner a set of metrics without each\nVM having to run its own Agent.  This plugin collects two sets of\nmeasurements per metric: one for the VM\'s owner (in-cloud) and for\nthe Operations team (infrastructure).  They differ in the following\nways:\n- Operations metric names are prefixed with ""vm."" in order to group VM\n  and overcloud metrics separately\n- Operations metrics include ""tenant_id"" as a dimension\n- Operations metrics include ""cloud_tier"" dimension with the value\n  ""overcloud""\n- The ""hostname"" dimension for Operations contains the name of the\n  compute server; for the tenant, ""hostname"" is the name of the VM\n\nThe metrics gathered by this plugin include:\n- Disk I/O: read/write operations/bytes per second\n- Disk I/O: errors per second\n- Network I/O: in/out packets/bytes per second\n- CPU utilization as a percentage of CPU time over polling time\n\nChange-Id: I23781a1ba552ef2551e6ff1caea21dd8f515d73d\n'}]",17,126068,3734c3805bbf324b254335ba45de00d20d129247,17,4,4,12443,,,0,"Add support for VM monitoring

This patch gives the Monasca Agent the ability to monitor virtual
machines (VMs) provisioned under Nova.  It bundles Ceilometer's
virtualization inspector to gather the actual metrics, includes a
monasca-setup plugin, and adds cross-tenant support.  The latter
enables the Agent to submit metrics on behalf of a different
tenant/project, giving the VM's owner a set of metrics without each
VM having to run its own Agent.  This plugin collects two sets of
measurements per metric: one for the VM's owner (in-cloud) and for
the Operations team (infrastructure).  They differ in the following
ways:
- Operations metric names are prefixed with ""vm."" in order to group VM
  and overcloud metrics separately
- Operations metrics include ""tenant_id"" as a dimension
- Operations metrics include ""cloud_tier"" dimension with the value
  ""overcloud""
- The ""hostname"" dimension for Operations contains the name of the
  compute server; for the tenant, ""hostname"" is the name of the VM

The metrics gathered by this plugin include:
- Disk I/O: read/write operations/bytes per second
- Disk I/O: errors per second
- Network I/O: in/out packets/bytes per second
- CPU utilization as a percentage of CPU time over polling time

Change-Id: I23781a1ba552ef2551e6ff1caea21dd8f515d73d
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/68/126068/4 && git format-patch -1 --stdout FETCH_HEAD,"['monagent/collector/virt/libvirt/__init__.py', 'monagent/collector/virt/libvirt/inspector.py', 'monagent/collector/virt/xenapi/__init__.py', 'monagent/collector/virt/hyperv/utilsv2.py', 'monagent/collector/checks/system/unix.py', 'monagent/collector/checks/collector.py', 'monagent/collector/virt/inspector.py', 'monagent/collector/virt/__init__.py', 'monagent/collector/virt/vmware/inspector.py', 'monsetup/detection/plugins/libvirt.py', 'monagent/collector/virt/xenapi/inspector.py', 'monagent/common/metrics.py', 'monagent/forwarder/api/mon.py', 'monagent/common/aggregator.py', 'monagent/collector/virt/vmware/vsphere_operations.py', 'monagent/collector/virt/hyperv/__init__.py', 'monagent/collector/checks/check.py', 'monagent/collector/virt/hyperv/inspector.py', 'monagent/collector/virt/vmware/__init__.py', 'setup.cfg', 'monsetup/main.py', 'monagent/collector/checks_d/libvirt.py']",22,aa3a8af9b4b8731f86c135fa2fa0d6c2d0f4a2e7,feature/libvirt-agent-plugin,"#!/bin/env python """"""Monasca Agent interface for libvirt metrics"""""" import os import time import yaml from monagent.collector.virt import inspector from monagent.collector.checks import AgentCheck class LibvirtCheck(AgentCheck): """"""Inherit Agent class and gather libvirt metrics"""""" def __init__(self, name, init_config, agent_config): AgentCheck.__init__(self, name, init_config, agent_config) self.instance_cache_file = ""{}/{}"".format(self.init_config.get('cache_dir'), 'libvirt_instances.yaml') self.metric_cache_file = ""{}/{}"".format(self.init_config.get('cache_dir'), 'libvirt_metrics.yaml') def _update_instance_cache(self): """"""Collect instance_id, project_id, and AZ for all instance UUIDs """""" from novaclient.v3 import client id_cache = {} # Get a list of all instances from the Nova API nova_client = client.Client(self.init_config.get('admin_user'), self.init_config.get('admin_password'), self.init_config.get('admin_tenant_name'), self.init_config.get('identity_uri'), service_type=""compute"") instances = nova_client.servers.list(search_opts={'all_tenants': 1}) for instance in instances: if instance.__getattr__('OS-SRV-USG:terminated_at') is not None: # Skip deleted instances continue inst_name = instance.__getattr__('OS-EXT-SRV-ATTR:instance_name') inst_az = instance.__getattr__('OS-EXT-AZ:availability_zone') id_cache[inst_name] = {'instance_uuid': instance.id, 'hostname': instance.name, 'zone': inst_az, 'tenant_id': instance.tenant_id} id_cache['last_update'] = int(time.time()) # Write the updated cache with open(self.instance_cache_file, 'w') as cache_yaml: yaml.safe_dump(id_cache, cache_yaml) os.chmod(self.instance_cache_file, 0600) return id_cache def _load_instance_cache(self): """"""Load the cache if instance names to IDs. If the cache does not yet exist, return an empty one. """""" instance_cache = {} try: with open(self.instance_cache_file, 'r') as cache_yaml: instance_cache = yaml.safe_load(cache_yaml) # Is it time to refresh this data? time_diff = time.time() - instance_cache['last_update'] if time_diff > self.init_config.get('nova_refresh'): self._update_instance_cache() except IOError: # The file may not exist yet, and that's OK. Build it now. instance_cache = self._update_instance_cache() pass return instance_cache def _load_metric_cache(self): """"""Load the counter metrics from the previous collection iteration """""" metric_cache = {} try: with open(self.metric_cache_file, 'r') as cache_yaml: metric_cache = yaml.safe_load(cache_yaml) except IOError: # The file may not exist yet. pass return metric_cache def _update_metric_cache(self, metric_cache): with open(self.metric_cache_file, 'w') as cache_yaml: yaml.safe_dump(metric_cache, cache_yaml) os.chmod(self.metric_cache_file, 0600) def check(self, instance): """"""Gather VM metrics for each instance"""""" # Load metric cache metric_cache = self._load_metric_cache() # Load the nova-obtained instance data cache instance_cache = self._load_instance_cache() # Build dimensions for both the customer and for operations dims_base = {'service': 'compute', 'component': 'vm'} insp = inspector.get_hypervisor_inspector() for inst in insp.inspect_instances(): # Verify that this instance exists in the cache. Add if necessary. if inst.name not in instance_cache: instance_cache = self._update_instance_cache() if inst.name not in metric_cache: metric_cache[inst.name] = {} # Build customer dimensions dims_customer = dims_base.copy() dims_customer['resource_id'] = instance_cache.get(inst.name)['instance_uuid'] dims_customer['zone'] = instance_cache.get(inst.name)['zone'] # Add dimensions that would be helpful for operations dims_operations = dims_customer.copy() dims_operations['tenant_id'] = instance_cache.get(inst.name)['tenant_id'] dims_operations['cloud_tier'] = 'overcloud' # CPU utilization percentage sample_time = float(""{:9f}"".format(time.time())) if 'cpu.time' in metric_cache[inst.name]: # I have a prior value, so calculate the rate & push the metric cpu_diff = insp.inspect_cpus(inst.name).time - metric_cache[inst.name]['cpu.time']['value'] time_diff = sample_time - float(metric_cache[inst.name]['cpu.time']['timestamp']) # Convert time_diff to nanoseconds, and calculate percentage rate = (cpu_diff / (time_diff * 1000000000)) * 100 self.gauge('cpu.utilization_perc', int(round(rate, 0)), dimensions=dims_customer, delegated_tenant=instance_cache.get(inst.name)['tenant_id'], hostname=instance_cache.get(inst.name)['hostname']) self.gauge('vm.cpu.utilization_perc', int(round(rate, 0)), dimensions=dims_operations) metric_cache[inst.name]['cpu.time'] = {'timestamp': sample_time, 'value': insp.inspect_cpus(inst.name).time} # Disk utilization for disk in insp.inspect_disks(inst.name): sample_time = int(time.time()) disk_dimensions = {'device': disk[0].device} for metric in disk[1]._fields: metric_name = ""io.{}"".format(metric) if metric_name not in metric_cache[inst.name]: metric_cache[inst.name][metric_name] = {} value = int(disk[1].__getattribute__(metric)) if disk[0].device in metric_cache[inst.name][metric_name]: time_diff = sample_time - metric_cache[inst.name][metric_name][disk[0].device]['timestamp'] val_diff = value - metric_cache[inst.name][metric_name][disk[0].device]['value'] # Change the metric name to a rate, ie. ""io.read_requests"" # gets converted to ""io.read_ops_sec"" rate_name = ""{}_sec"".format(metric_name.replace('requests', 'ops')) # Customer this_dimensions = disk_dimensions.copy() this_dimensions.update(dims_customer) self.gauge(rate_name, val_diff, dimensions=this_dimensions, delegated_tenant=instance_cache.get(inst.name)['tenant_id'], hostname=instance_cache.get(inst.name)['hostname']) # Operations (metric name prefixed with ""vm."" this_dimensions = disk_dimensions.copy() this_dimensions.update(dims_operations) self.gauge(""vm.{}"".format(rate_name), val_diff, dimensions=this_dimensions) # Save this metric to the cache metric_cache[inst.name][metric_name][disk[0].device] = { 'timestamp': sample_time, 'value': value} # Network utilization for vnic in insp.inspect_vnics(inst.name): sample_time = int(time.time()) vnic_dimensions = {'device': vnic[0].name} for metric in vnic[1]._fields: metric_name = ""net.{}"".format(metric) if metric_name not in metric_cache[inst.name]: metric_cache[inst.name][metric_name] = {} value = int(vnic[1].__getattribute__(metric)) if vnic[0].name in metric_cache[inst.name][metric_name]: time_diff = sample_time - metric_cache[inst.name][metric_name][vnic[0].name]['timestamp'] val_diff = value - metric_cache[inst.name][metric_name][vnic[0].name]['value'] # Change the metric name to a rate, ie. ""net.rx_bytes"" # gets converted to ""net.rx_bytes_sec"" rate_name = metric_name.replace(""$"", ""_sec"") # Rename ""tx"" to ""out"" and ""rx"" to ""in"" rate_name = rate_name.replace(""tx"", ""out"") rate_name = rate_name.replace(""rx"", ""in"") # Customer this_dimensions = vnic_dimensions.copy() this_dimensions.update(dims_customer) self.gauge(rate_name, val_diff, dimensions=this_dimensions, delegated_tenant=instance_cache.get(inst.name)['tenant_id'], hostname=instance_cache.get(inst.name)['hostname']) # Operations (metric name prefixed with ""vm."" this_dimensions = vnic_dimensions.copy() this_dimensions.update(dims_operations) self.gauge(""vm.{}"".format(rate_name), val_diff, dimensions=this_dimensions) # Save this metric to the cache metric_cache[inst.name][metric_name][vnic[0].name] = { 'timestamp': sample_time, 'value': value} # Save these metrics for the next collector invocation self._update_metric_cache(metric_cache) ",,1697,58
openstack%2Fmonasca-api~master~I508172851f3baefe7464d6b4d10a1afeb4d84341,openstack/monasca-api,master,I508172851f3baefe7464d6b4d10a1afeb4d84341,Simplify list comprehension logic,MERGED,2014-10-20 19:16:31.000000000,2014-10-20 19:18:12.000000000,2014-10-20 19:18:12.000000000,"[{'_account_id': 3}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-10-20 19:16:31.000000000', 'files': ['monasca/common/repositories/influxdb/metrics_repository.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/bb6dbe7799fbe951563df8edcfb23fb32afb4e3a', 'message': 'Simplify list comprehension logic\n\nChange-Id: I508172851f3baefe7464d6b4d10a1afeb4d84341\n'}]",0,129707,bb6dbe7799fbe951563df8edcfb23fb32afb4e3a,6,2,1,12512,,,0,"Simplify list comprehension logic

Change-Id: I508172851f3baefe7464d6b4d10a1afeb4d84341
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/07/129707/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca/common/repositories/influxdb/metrics_repository.py'],1,bb6dbe7799fbe951563df8edcfb23fb32afb4e3a,," fmtd_pts_list_list = [[strftime(""%Y-%m-%dT%H:%M:%SZ"", gmtime(pts_list[0]))] + pts_list[1:] for pts_list in serie['points']]"," # format the utc date in the points. fmtd_pts_list_list = [] for pts_list in serie['points']: # time is always the first point. the rest of the points # are statistics. just pass the statistics thru unchanged. fmtd_pts_list = ([strftime(""%Y-%m-%dT%H:%M:%SZ"", gmtime(pts_list[0]))] + pts_list[1:]) fmtd_pts_list_list.append(fmtd_pts_list)",3,9
openstack%2Fgrenade~stable%2Fjuno~I6a7c9af8da7e7c67de8abc31e2adc79244a6552f,openstack/grenade,stable/juno,I6a7c9af8da7e7c67de8abc31e2adc79244a6552f,Set defaults for stable/juno,MERGED,2014-10-20 15:35:53.000000000,2014-10-20 19:17:29.000000000,2014-10-20 19:17:28.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5196}]","[{'number': 1, 'created': '2014-10-20 15:35:53.000000000', 'files': ['grenaderc', '.gitreview'], 'web_link': 'https://opendev.org/openstack/grenade/commit/06574481641d3119fbda3c941900a302a22e75c0', 'message': 'Set defaults for stable/juno\n\nChange-Id: I6a7c9af8da7e7c67de8abc31e2adc79244a6552f\n'}]",0,129645,06574481641d3119fbda3c941900a302a22e75c0,7,3,1,970,,,0,"Set defaults for stable/juno

Change-Id: I6a7c9af8da7e7c67de8abc31e2adc79244a6552f
",git fetch https://review.opendev.org/openstack/grenade refs/changes/45/129645/1 && git format-patch -1 --stdout FETCH_HEAD,"['grenaderc', '.gitreview']",2,06574481641d3119fbda3c941900a302a22e75c0,,defaultbranch=stable/juno,,2,2
openstack%2Ftelemetry-specs~master~I61480425d8690aa17fa11450b4ad1d73e3c8d804,openstack/telemetry-specs,master,I61480425d8690aa17fa11450b4ad1d73e3c8d804,Adds memory stats meter to libvirt inspector,MERGED,2014-10-20 09:00:49.000000000,2014-10-20 19:16:00.000000000,2014-10-20 19:16:00.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 8276}, {'_account_id': 9562}]","[{'number': 1, 'created': '2014-10-20 09:00:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/98e26c223899973ffc9403f35e0997358f1d199c', 'message': ""Adds memory stats meter to libvirt inspector\n\nUses libvirt 'virDomainMemoryStats' to retrive the memory\nthat is used by domain, implements 'inspect_memory_usage'\nfunction in libvirt inspector.\n\nblueprint libvirt-memory-utilization-inspector\n\nChange-Id: I61480425d8690aa17fa11450b4ad1d73e3c8d804\n""}, {'number': 2, 'created': '2014-10-20 10:59:39.000000000', 'files': ['specs/kilo/libvirt-memory-utilization-inspector.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/bd07dcc5efe3bcbdad0a68a7127c5d7a361704a7', 'message': ""Adds memory stats meter to libvirt inspector\n\nUses libvirt 'virDomainMemoryStats' to retrive the memory\nthat is used by domain, implements 'inspect_memory_usage'\nfunction in libvirt inspector.\n\nblueprint libvirt-memory-utilization-inspector\n\nChange-Id: I61480425d8690aa17fa11450b4ad1d73e3c8d804\n""}]",8,129553,bd07dcc5efe3bcbdad0a68a7127c5d7a361704a7,11,4,2,8276,,,0,"Adds memory stats meter to libvirt inspector

Uses libvirt 'virDomainMemoryStats' to retrive the memory
that is used by domain, implements 'inspect_memory_usage'
function in libvirt inspector.

blueprint libvirt-memory-utilization-inspector

Change-Id: I61480425d8690aa17fa11450b4ad1d73e3c8d804
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/53/129553/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/libvirt-memory-utilization-inspector.rst'],1,98e26c223899973ffc9403f35e0997358f1d199c,bp/libvirt-memory-utilization-inspector,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================== Adds memory utilization meter to libvirt inspector ================================================== https://blueprints.launchpad.net/ceilometer/+spec/libvirt-memory-utilization-inspector Memory usage statistics is not implemented in libvirt inspector. We can get memory stats of the instance from libvirt API 'virDomainMemoryStats' in order to add memory usage meter to libvirt inspector. Problem description =================== Memory usage of instance is very important data in telemetry, but now it is not implemented in libvirt inspector. Adds memory usage statistics to libvirt, so that the user can get the data on the performance of the instance. Proposed change =============== Implements the method 'inspect_memory_usage' of LibvirtInspector, fetches the memory stats data from libvirt API 'virDomainMemoryStats', used memory is calculated by the available and unused memory. The libvirt API 'virDomainMemoryStats' maybe raise an exception if the method is not supported by libvirt, refer to 'Dependencies' section, catches the exception and translates that into an empty data of memory stats. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Pipeline impact --------------- None Other end user impact --------------------- User need to prepare suitable balloon driver in image, particularly for windows guests, most modern Linuxes have it built in. Booting instance will be successful without image balloon driver, just can't get guest memory usage meter. Performance/Scalability Impacts ------------------------------- None Other deployer impact --------------------- None. By default, the memory statistical feature is enabled in Nova, refer to [1], we just fetch and collect the data from libvirt API. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: <kiwik-chenrui> Work Items ---------- * Implements the method 'inspect_memory_usage' of LibvirtInspector. * Adds relate unit tests. * Updates ceilometer measurements document. Future lifecycle ================ Once this feature enabled, need test and bug fixing in next 2 releases to avoid regression. Dependencies ============ * libvirt 1.1.1+ * qemu 1.5+ * guest driver that supports memory balloon stats Testing ======= Unit tests are sufficient since only data fetching need test. Documentation Impact ==================== The added metrics will need to be documented in the `measurements section`_. .. _measurements section: http://docs.openstack.org/developer/ceilometer/measurements.html References ========== * [1] https://blueprints.launchpad.net/nova/+spec/enabled-qemu-memballoon-stats * [2] http://libvirt.org/html/libvirt-libvirt.html#virDomainMemoryStats ",,135,0
openstack%2Fkeystone~master~I47cb13bac97e9144ef004977942b9eaa50a17b39,openstack/keystone,master,I47cb13bac97e9144ef004977942b9eaa50a17b39,Add max-complexity to pep8 for Keystone,MERGED,2014-10-17 06:14:25.000000000,2014-10-20 18:22:11.000000000,2014-10-20 18:22:10.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8978}]","[{'number': 1, 'created': '2014-10-17 06:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a6693693b91ab3606ba5d32358f57deeeaa364aa', 'message': ""Add max-complexity to pep8 for Keystone\n\nThe current highest complexity is 23, set the maximum complexity for flake8\nto 24. This should help to keep code simple and maintainable. It should be\npossible to reduce the maximum complexity to something closer to 20 with\nrelatively small efforts.\n\nkeystone.common.sql.migrate_repo.versions.039_grant_to_assignment:\n    'downgrade_assignment_table' is complexity of 21\n\nkeystone.token.controllers: 'Auth._authenticate_token' is complexity of 23\n\nChange-Id: I47cb13bac97e9144ef004977942b9eaa50a17b39\n""}, {'number': 2, 'created': '2014-10-17 06:16:30.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/7662e0d799dd5e99bfa9cff069459e17c11ad29d', 'message': ""Add max-complexity to pep8 for Keystone\n\nThe current highest complexity is 23, set the maximum complexity\nfor flake8 to 24. This should help to keep code simple and\nmaintainable. It should be possible to reduce the maximum\ncomplexity to something closer to 20 with relatively small efforts.\n\nkeystone.common.sql.migrate_repo.versions.039_grant_to_assignment:\n    'downgrade_assignment_table' is complexity of 21\n\nkeystone.token.controllers:\n    'Auth._authenticate_token' is complexity of 23\n\nChange-Id: I47cb13bac97e9144ef004977942b9eaa50a17b39\n""}]",0,129143,7662e0d799dd5e99bfa9cff069459e17c11ad29d,14,7,2,2903,,,0,"Add max-complexity to pep8 for Keystone

The current highest complexity is 23, set the maximum complexity
for flake8 to 24. This should help to keep code simple and
maintainable. It should be possible to reduce the maximum
complexity to something closer to 20 with relatively small efforts.

keystone.common.sql.migrate_repo.versions.039_grant_to_assignment:
    'downgrade_assignment_table' is complexity of 21

keystone.token.controllers:
    'Auth._authenticate_token' is complexity of 23

Change-Id: I47cb13bac97e9144ef004977942b9eaa50a17b39
",git fetch https://review.opendev.org/openstack/keystone refs/changes/43/129143/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a6693693b91ab3606ba5d32358f57deeeaa364aa,max-complexity-flake8,max-complexity=25,,1,0
openstack%2Fhorizon~master~I7060e2f7b710efa18b36adca07a03c15e30e5c6e,openstack/horizon,master,I7060e2f7b710efa18b36adca07a03c15e30e5c6e,Advance filtering for context selection,ABANDONED,2014-09-16 01:03:03.000000000,2014-10-20 18:11:58.000000000,,"[{'_account_id': 3}, {'_account_id': 8040}, {'_account_id': 9576}]","[{'number': 1, 'created': '2014-09-16 01:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1b0febb4c67095f9e5ecbbc452ff7b2dfdf8c558', 'message': 'Advance filtering for context selection\n\nChange-Id: I7060e2f7b710efa18b36adca07a03c15e30e5c6e\nImplements: blueprint context-selection\n'}, {'number': 2, 'created': '2014-09-16 02:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/fa23602f411be7866058435a0edb554f3348bdf4', 'message': 'Advance filtering for context selection\n\nChange-Id: I7060e2f7b710efa18b36adca07a03c15e30e5c6e\nImplements: blueprint context-selection'}, {'number': 3, 'created': '2014-09-16 06:57:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/24165e47eb4df242f8d24bb8d294610be6652d2a', 'message': 'Advance filtering for context selection\n\nChange-Id: I7060e2f7b710efa18b36adca07a03c15e30e5c6e\nImplements: blueprint context-selection'}, {'number': 4, 'created': '2014-09-16 06:59:26.000000000', 'files': ['openstack_dashboard/dashboards/settings/scope/templates/scope/_domain_filter.html', 'openstack_dashboard/dashboards/settings/scope/urls.py', 'openstack_dashboard/dashboards/settings/scope/views.py', 'openstack_dashboard/dashboards/settings/scope/templates/scope/_project_filter.html', 'openstack_dashboard/dashboards/settings/scope/templates/scope/_region_filter.html', 'openstack_dashboard/templates/_header.html', 'openstack_dashboard/dashboards/settings/dashboard.py', 'openstack_dashboard/dashboards/settings/scope/__init__.py', 'openstack_dashboard/dashboards/settings/scope/forms.py', 'openstack_dashboard/dashboards/settings/scope/panel.py', 'openstack_dashboard/static/dashboard/scss/_context_selection.scss', 'openstack_dashboard/static/dashboard/scss/horizon.scss', 'openstack_dashboard/dashboards/settings/scope/templates/scope/filters.html', 'openstack_dashboard/dashboards/settings/scope/templates/scope/_filters.html', 'openstack_dashboard/dashboards/settings/scope/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/07b6e515bf847812f1dabe7678c96cf7f6d8c546', 'message': 'Advance filtering for context selection\n\nChange-Id: I7060e2f7b710efa18b36adca07a03c15e30e5c6e\nImplements: blueprint context-selection'}]",0,121724,07b6e515bf847812f1dabe7678c96cf7f6d8c546,13,3,4,9576,,,0,"Advance filtering for context selection

Change-Id: I7060e2f7b710efa18b36adca07a03c15e30e5c6e
Implements: blueprint context-selection",git fetch https://review.opendev.org/openstack/horizon refs/changes/24/121724/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/settings/context/panel.py', 'openstack_dashboard/dashboards/settings/dashboard.py', 'horizon/static/horizon/js/horizon.forms.js', 'openstack_dashboard/dashboards/settings/context/__init__.py', 'openstack_dashboard/dashboards/settings/context/templates/context/_settings.html', 'openstack_dashboard/dashboards/settings/context/views.py', 'openstack_dashboard/dashboards/settings/context/tests.py', 'openstack_dashboard/dashboards/settings/context/urls.py', 'openstack_dashboard/dashboards/settings/context/forms.py', 'openstack_dashboard/templates/_header.html', 'openstack_dashboard/dashboards/settings/context/templates/context/settings.html']",11,1b0febb4c67095f9e5ecbbc452ff7b2dfdf8c558,bp/context-selection,"{% extends 'base.html' %} {% load i18n %} {% block title %}{% trans ""Context Settings"" %}{% endblock %} {% block page_header %} {% include ""horizon/common/_page_header.html"" with title=_(""Context Settings"") %} {% endblock page_header %} {% block main %} {% include ""settings/context/_settings.html"" %} {% endblock %} ",,348,4
openstack%2Ftraining-guides~master~I581c7168571fb2ecc0e7b488d39c85b3a9b94eab,openstack/training-guides,master,I581c7168571fb2ecc0e7b488d39c85b3a9b94eab,Updated from openstack-manuals,MERGED,2014-10-17 12:38:48.000000000,2014-10-20 18:03:32.000000000,2014-10-20 18:03:31.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-10-17 12:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/4977bba792a4f3d404b2251a3217791e31cc8f51', 'message': 'Updated from openstack-manuals\n\nChange-Id: I581c7168571fb2ecc0e7b488d39c85b3a9b94eab\n'}, {'number': 2, 'created': '2014-10-18 09:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/18c2d5a2b44959b40d60e09e0dcba1568ed39b40', 'message': 'Updated from openstack-manuals\n\nChange-Id: I581c7168571fb2ecc0e7b488d39c85b3a9b94eab\n'}, {'number': 3, 'created': '2014-10-20 06:38:14.000000000', 'files': ['doc/glossary/locale/ja.po', 'doc/glossary/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/fdb5ae598e70de2f8429d6a645a5803ef3287b4d', 'message': 'Updated from openstack-manuals\n\nChange-Id: I581c7168571fb2ecc0e7b488d39c85b3a9b94eab\n'}]",0,129228,fdb5ae598e70de2f8429d6a645a5803ef3287b4d,15,4,3,11131,,,0,"Updated from openstack-manuals

Change-Id: I581c7168571fb2ecc0e7b488d39c85b3a9b94eab
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/28/129228/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/glossary-terms.xml'],1,4977bba792a4f3d404b2251a3217791e31cc8f51,openstack/openstack-manuals," <glossterm>federated identity</glossterm> <indexterm class=""singular""> <primary>federated identity</primary> </indexterm> <glossdef> <para>A method to establish trusts between identity providers and the OpenStack cloud.</para> </glossdef> </glossentry> <glossentry> <glossterm>identity provider</glossterm> <indexterm class=""singular""> <primary>identity provider</primary> <secondary>basics of</secondary> </indexterm> <glossdef> <para>A directory service, which allows users to login with a user name and password. It is a typical source of authentication tokens.</para> </glossdef> </glossentry> <glossentry> <glossterm>SAML assertion</glossterm> <indexterm class=""singular""> <primary>SAML assertion</primary> </indexterm> <glossdef> <para>Contains information about a user as provided by the identity provider. It is an indication that a user has been authenticated.</para> </glossdef> </glossentry> <glossentry> <glossterm>service provider</glossterm> <indexterm class=""singular""> <primary>service provider</primary> </indexterm> <glossdef> <para>A system that provides services to other system entities. In case of federated identity, OpenStack Identity is the service provider.</para> </glossdef> </glossentry> <glossentry>",,51,0
openstack%2Fproject-config~master~Ice4423fdd3128869fa644f1e603721370230dfad,openstack/project-config,master,Ice4423fdd3128869fa644f1e603721370230dfad,Explicitly set -nv ironic jobs non-voting,ABANDONED,2014-10-17 18:19:07.000000000,2014-10-20 18:02:31.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}]","[{'number': 1, 'created': '2014-10-17 18:19:07.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cbe1e19bfde7d72c02aec1f5ec8089fc03e1eefb', 'message': ""Explicitly set -nv ironic jobs non-voting\n\nA previous commit to avoid running these jobs against icehouse removed\nthe application of 'voting: false' to the -nv jobs, causing them to\nvote where they shouldn't.  This adds it back by explicitly applying it\nto those jobs via regex.\n\nChange-Id: Ice4423fdd3128869fa644f1e603721370230dfad\n""}]",0,129348,cbe1e19bfde7d72c02aec1f5ec8089fc03e1eefb,4,2,1,1420,,,0,"Explicitly set -nv ironic jobs non-voting

A previous commit to avoid running these jobs against icehouse removed
the application of 'voting: false' to the -nv jobs, causing them to
vote where they shouldn't.  This adds it back by explicitly applying it
to those jobs via regex.

Change-Id: Ice4423fdd3128869fa644f1e603721370230dfad
",git fetch https://review.opendev.org/openstack/project-config refs/changes/48/129348/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,cbe1e19bfde7d72c02aec1f5ec8089fc03e1eefb,, - name: ^(gate|check)-tempest-dsvm-ironic-pxe_ssh.*-nv$ voting: false,,2,0
openstack%2Fproject-config~master~I379a5e6c566e8ac207c70089f3251eff6afe3379,openstack/project-config,master,I379a5e6c566e8ac207c70089f3251eff6afe3379,remove non-standard-reqs flag from check-tempest-dsvm-f20-docker,MERGED,2014-10-17 13:42:02.000000000,2014-10-20 18:01:36.000000000,2014-10-20 18:01:35.000000000,"[{'_account_id': 3}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-17 13:42:02.000000000', 'files': ['jenkins/jobs/nova-docker.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a7a832213a1850f4a65218148f558fae606df9fd', 'message': 'remove non-standard-reqs flag from check-tempest-dsvm-f20-docker\n\nIntroduced a flag in I1fb4d58a36c9a12f87527f4fb551f4b664c386bd, this\ndoes not work when we set it from here. So this review removes the\nNON_STANDARD_REQS flag. The reason it does not work is that\ndevstack runs stack.sh with sudo and the environment variable is not\npassed down into the process.\n\nChange-Id: I379a5e6c566e8ac207c70089f3251eff6afe3379\n'}]",0,129252,a7a832213a1850f4a65218148f558fae606df9fd,7,3,1,5638,,,0,"remove non-standard-reqs flag from check-tempest-dsvm-f20-docker

Introduced a flag in I1fb4d58a36c9a12f87527f4fb551f4b664c386bd, this
does not work when we set it from here. So this review removes the
NON_STANDARD_REQS flag. The reason it does not work is that
devstack runs stack.sh with sudo and the environment variable is not
passed down into the process.

Change-Id: I379a5e6c566e8ac207c70089f3251eff6afe3379
",git fetch https://review.opendev.org/openstack/project-config refs/changes/52/129252/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/nova-docker.yaml'],1,a7a832213a1850f4a65218148f558fae606df9fd,,, export NON_STANDARD_REQS=1,0,1
openstack%2Fglance~master~Ia7765151ebb00cdf01e96cf39f3242899d358772,openstack/glance,master,Ia7765151ebb00cdf01e96cf39f3242899d358772,Remove eventlet_hub option,MERGED,2014-06-20 13:26:02.000000000,2014-10-20 17:52:20.000000000,2014-10-20 17:52:19.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 616}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2537}, {'_account_id': 2813}, {'_account_id': 6159}, {'_account_id': 6493}, {'_account_id': 8127}, {'_account_id': 8158}, {'_account_id': 8871}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-20 13:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7754f9c40b3228c5f690ba16db72f76cc14ed0f6', 'message': ""Remove eventlet_hub option\n\nThe option has a default value that is not portable, and therefore the\ntest fails on OS like Darwin. There's actually no need to specify any\nhub – no other OpenStack projects as that option – as Eventlet is smart\nenough to pick the best implementation available anyway.\n\nAlso remove a useless cleanup() call in the failing test as the\nstart_servers() method already does a cleanup itself.\n\nChange-Id: Ia7765151ebb00cdf01e96cf39f3242899d358772\n""}, {'number': 2, 'created': '2014-07-25 21:32:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f296a30261580f8ba967375ffd99d23f0656b117', 'message': ""Remove eventlet_hub option\n\nThe option has a default value that is not portable, and therefore the\ntest fails on OS like Darwin. There's actually no need to specify any\nhub – no other OpenStack projects as that option – as Eventlet is smart\nenough to pick the best implementation available anyway.\n\nAlso remove a useless cleanup() call in the failing test as the\nstart_servers() method already does a cleanup itself.\n\nChange-Id: Ia7765151ebb00cdf01e96cf39f3242899d358772\n""}, {'number': 3, 'created': '2014-08-01 12:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/eb98267f2975e836d2f6137f1ac6d4177b99783b', 'message': ""Remove eventlet_hub option\n\nThe option has a default value that is not portable, and therefore the\ntest fails on OS like Darwin. There's actually no need to specify any\nhub – no other OpenStack projects as that option – as Eventlet is smart\nenough to pick the best implementation available anyway.\n\nAlso remove a useless cleanup() call in the failing test as the\nstart_servers() method already does a cleanup itself.\n\nChange-Id: Ia7765151ebb00cdf01e96cf39f3242899d358772\n""}, {'number': 4, 'created': '2014-08-04 14:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a2b5a73578d1fba6c1ba9292df14ea6b3d241923', 'message': ""Remove eventlet_hub option\n\nThe option has a default value that is not portable, and therefore the\ntest fails on OS like Darwin. There's actually no need to specify any\nhub – no other OpenStack projects as that option – as Eventlet is smart\nenough to pick the best implementation available anyway.\n\nAlso remove a useless cleanup() call in the failing test as the\nstart_servers() method already does a cleanup itself.\n\nChange-Id: Ia7765151ebb00cdf01e96cf39f3242899d358772\n""}, {'number': 5, 'created': '2014-08-19 08:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b0ee0559037676bcb54192ea8e61716ebcd0a17f', 'message': ""Remove eventlet_hub option\n\nThe option has a default value that is not portable, and therefore the\ntest fails on OS like Darwin. There's actually no need to specify any\nhub – no other OpenStack projects as that option – as Eventlet is smart\nenough to pick the best implementation available anyway.\n\nAlso remove a useless cleanup() call in the failing test as the\nstart_servers() method already does a cleanup itself.\n\nChange-Id: Ia7765151ebb00cdf01e96cf39f3242899d358772\n""}, {'number': 6, 'created': '2014-08-25 13:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b64dd4cfb859b875a366dc50094787366e93ffbd', 'message': ""Remove eventlet_hub option\n\nThe option has a default value that is not portable, and therefore the\ntest fails on OS like Darwin. There's actually no need to specify any\nhub – no other OpenStack projects as that option – as in theory Eventlet\nis smart enough to pick the best implementation available anyway.\n\nHowever, since Glance only works with poll or select as a hub, let's try\nthem in that order. That avoids a user selecting things like 'epolls'\nand expecting Glance to work, whereas it would fail.\n\nAlso remove a useless cleanup() call in the failing test as the\nstart_servers() method already does a cleanup itself.\n\nChange-Id: Ia7765151ebb00cdf01e96cf39f3242899d358772\n""}, {'number': 7, 'created': '2014-08-25 15:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d0986430b43852873cf20b937373b838b9fe7c1c', 'message': ""Remove eventlet_hub option\n\nThe option has a default value that is not portable, and therefore the\ntest fails on OS like Darwin. There's actually no need to specify any\nhub – no other OpenStack projects as that option – as in theory Eventlet\nis smart enough to pick the best implementation available anyway.\n\nHowever, since Glance only works with poll or select as a hub, let's try\nthem in that order. That avoids a user selecting things like 'epolls'\nand expecting Glance to work, whereas it would fail.\n\nAlso remove a useless cleanup() call in the failing test as the\nstart_servers() method already does a cleanup itself.\n\nChange-Id: Ia7765151ebb00cdf01e96cf39f3242899d358772\n""}, {'number': 8, 'created': '2014-08-27 12:05:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a7f19f4e2cccf219f8f28b7a31eb0a7587bcbb36', 'message': ""Remove eventlet_hub option\n\nThe option has a default value that is not portable, and therefore the\ntest fails on OS like Darwin. There's actually no need to specify any\nhub – no other OpenStack projects as that option – as in theory Eventlet\nis smart enough to pick the best implementation available anyway.\n\nHowever, since Glance only works with poll or select as a hub, let's try\nthem in that order. That avoids a user selecting things like 'epolls'\nand expecting Glance to work, whereas it would fail.\n\nAlso remove a useless cleanup() call in the failing test as the\nstart_servers() method already does a cleanup itself.\n\nChange-Id: Ia7765151ebb00cdf01e96cf39f3242899d358772\n""}, {'number': 9, 'created': '2014-10-20 13:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/245b6dc1ef4a522363609a6f09fefc7fca776ed3', 'message': ""Remove eventlet_hub option\n\nThe option has a default value that is not portable, and therefore the\ntest fails on OS like Darwin. There's actually no need to specify any\nhub – no other OpenStack projects as that option – as in theory Eventlet\nis smart enough to pick the best implementation available anyway.\n\nHowever, since Glance only works with poll or select as a hub, let's try\nthem in that order. That avoids a user selecting things like 'epolls'\nand expecting Glance to work, whereas it would fail.\n\nAlso remove a useless cleanup() call in the failing test as the\nstart_servers() method already does a cleanup itself.\n\nChange-Id: Ia7765151ebb00cdf01e96cf39f3242899d358772\n""}, {'number': 10, 'created': '2014-10-20 15:02:49.000000000', 'files': ['glance/tests/functional/v1/test_multiprocessing.py', 'glance/common/wsgi.py', 'glance/tests/unit/test_opts.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/9bb7ec57fb6b983fc19943556fa30715ff0750dc', 'message': ""Remove eventlet_hub option\n\nThe option has a default value that is not portable, and therefore the\ntest fails on OS like Darwin. There's actually no need to specify any\nhub – no other OpenStack projects as that option – as in theory Eventlet\nis smart enough to pick the best implementation available anyway.\n\nHowever, since Glance only works with poll or select as a hub, let's try\nthem in that order. That avoids a user selecting things like 'epolls'\nand expecting Glance to work, whereas it would fail.\n\nAlso remove a useless cleanup() call in the failing test as the\nstart_servers() method already does a cleanup itself.\n\nChange-Id: Ia7765151ebb00cdf01e96cf39f3242899d358772\n""}]",2,101548,9bb7ec57fb6b983fc19943556fa30715ff0750dc,60,14,10,1669,,,0,"Remove eventlet_hub option

The option has a default value that is not portable, and therefore the
test fails on OS like Darwin. There's actually no need to specify any
hub – no other OpenStack projects as that option – as in theory Eventlet
is smart enough to pick the best implementation available anyway.

However, since Glance only works with poll or select as a hub, let's try
them in that order. That avoids a user selecting things like 'epolls'
and expecting Glance to work, whereas it would fail.

Also remove a useless cleanup() call in the failing test as the
start_servers() method already does a cleanup itself.

Change-Id: Ia7765151ebb00cdf01e96cf39f3242899d358772
",git fetch https://review.opendev.org/openstack/glance refs/changes/48/101548/4 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/functional/v1/test_multiprocessing.py', 'glance/common/wsgi.py']",2,7754f9c40b3228c5f690ba16db72f76cc14ed0f6,jd/fix-test-darwin,," cfg.StrOpt('eventlet_hub', default='poll', help=_('Name of eventlet hub to use. Traditionally, we have ' 'only supported \'poll\', however \'selects\' may be ' 'appropriate for some platforms. See ' 'http://eventlet.net/doc/hubs.html for more details.')), try: eventlet.hubs.use_hub(cfg.CONF.eventlet_hub) except Exception: msg = _(""eventlet '%s' hub is not available on this platform"") raise exception.WorkerCreationFailure( reason=msg % cfg.CONF.eventlet_hub)",0,13
openstack%2Fpython-novaclient~master~I4cf246e3ec932ba0d2391eb8bcb793b28b005b4c,openstack/python-novaclient,master,I4cf246e3ec932ba0d2391eb8bcb793b28b005b4c,Enable check for E121,MERGED,2014-09-19 23:03:14.000000000,2014-10-20 17:46:49.000000000,2014-09-25 09:15:27.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-09-19 23:03:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/6687adb02b4304cc4e4e28531f00bb641299cc10', 'message': 'Remove aliases for `args` and `env` in utils\n\nThis patch removes aliases in `novaclient.utils` and starts using\n`args` and `env` from novaclient.openstack.common.cliutils directly.\n\nChange-Id: I4cf246e3ec932ba0d2391eb8bcb793b28b005b4c\n'}, {'number': 2, 'created': '2014-09-19 23:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/9261ba536a4e26408ec397a761d31a2f826f794a', 'message': 'Remove aliases for `args` and `env` in utils\n\nThis patch removes aliases in `novaclient.utils` and starts using\n`args` and `env` from novaclient.openstack.common.cliutils directly.\n\nChange-Id: I4cf246e3ec932ba0d2391eb8bcb793b28b005b4c\n'}, {'number': 3, 'created': '2014-09-19 23:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/231fd69be2dc91e2db8f80f414d036afcc6903a0', 'message': 'Remove aliases for `args` and `env` in utils\n\nThis patch removes aliases in `novaclient.utils` and starts using\n`args` and `env` from novaclient.openstack.common.cliutils directly.\n\nChange-Id: I4cf246e3ec932ba0d2391eb8bcb793b28b005b4c\n'}, {'number': 4, 'created': '2014-09-22 07:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/57e1cf955a005145b96fd2faef9cccf58c435176', 'message': 'Remove aliases for `args` and `env` in utils\n\nThis patch removes aliases in `novaclient.utils` and starts using\n`args` and `env` from novaclient.openstack.common.cliutils directly.\n\nChange-Id: I4cf246e3ec932ba0d2391eb8bcb793b28b005b4c\n'}, {'number': 5, 'created': '2014-09-22 21:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/1e1d8cf988ae7cf44b86d55f785d0c7712c8f8af', 'message': 'Remove aliases for `args` and `env` in utils\n\nThis patch removes aliases in `novaclient.utils` and starts using\n`args` and `env` from novaclient.openstack.common.cliutils directly.\n\nChange-Id: I4cf246e3ec932ba0d2391eb8bcb793b28b005b4c\n'}, {'number': 6, 'created': '2014-09-22 22:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/b0c7098b39e96647ab8ca6d42b6fa418fd6834b8', 'message': 'Unify whitespaces while using utils.arg\n\nChange-Id: I4cf246e3ec932ba0d2391eb8bcb793b28b005b4c\n'}, {'number': 7, 'created': '2014-09-24 16:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/ed47a785d372627d0cc92c4223357ed00a1eb830', 'message': 'Unify whitespaces while using utils.arg\n\nChange-Id: I4cf246e3ec932ba0d2391eb8bcb793b28b005b4c\n'}, {'number': 8, 'created': '2014-09-24 16:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/52cd5633f599d64862af7cf88372d67007f512bf', 'message': 'Enable check for pep8:E12\n\n10 errors fixed for E121\n15 errors fixed for E122\n25 errors fixed for E123\n12 errors fixed for E124\n82 errors fixed for E126\n64 errors fixed for E127\n1661 errors fixed for E128\n12 errors fixed for E129\n\nChange-Id: I4cf246e3ec932ba0d2391eb8bcb793b28b005b4c\n'}, {'number': 9, 'created': '2014-09-24 18:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/36c14e743a4985a9fdef9eecae6f4c35021d50d0', 'message': 'Enable check for pep8:E12\n\n10 errors fixed for E121\n15 errors fixed for E122\n25 errors fixed for E123\n12 errors fixed for E124\n82 errors fixed for E126\n64 errors fixed for E127\n1661 errors fixed for E128\n12 errors fixed for E129\n\nChange-Id: I4cf246e3ec932ba0d2391eb8bcb793b28b005b4c\n'}, {'number': 10, 'created': '2014-09-24 19:44:39.000000000', 'files': ['novaclient/tests/test_shell.py', 'novaclient/tests/v1_1/fakes.py', 'novaclient/v3/servers.py', 'novaclient/v1_1/servers.py', 'novaclient/tests/fixture_data/floatingips.py', 'novaclient/tests/v1_1/test_hypervisors.py', 'tox.ini', 'novaclient/tests/fixture_data/certs.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/7fc1588dfda6edcb68aee2ff40e7475f9a6e400b', 'message': 'Enable check for E121\n\nE121 continuation line under-indented for hanging indent\n\nChange-Id: I4cf246e3ec932ba0d2391eb8bcb793b28b005b4c\n'}]",25,122888,7fc1588dfda6edcb68aee2ff40e7475f9a6e400b,40,5,10,9545,,,0,"Enable check for E121

E121 continuation line under-indented for hanging indent

Change-Id: I4cf246e3ec932ba0d2391eb8bcb793b28b005b4c
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/88/122888/10 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/v1_1/contrib/instance_action.py', 'novaclient/v1_1/contrib/migrations.py', 'novaclient/v1_1/contrib/cells.py', 'novaclient/v1_1/shell.py', 'novaclient/utils.py', 'novaclient/v1_1/contrib/baremetal.py', 'novaclient/v1_1/contrib/host_evacuate.py', 'novaclient/client.py', 'novaclient/shell.py', 'novaclient/v3/shell.py', 'novaclient/v1_1/contrib/host_servers_migrate.py', 'novaclient/v1_1/contrib/metadata_extensions.py', 'novaclient/v1_1/contrib/deferred_delete.py', 'novaclient/v1_1/contrib/tenant_networks.py']",14,6687adb02b4304cc4e4e28531f00bb641299cc10,enable_e12,"from novaclient.openstack.common import cliutils@cliutils.arg('network_id', metavar='<network_id>', help='ID of network')@cliutils.arg('label', metavar='<network_label>', help=_('Network label (ex. my_new_network)')) @cliutils.arg('cidr', metavar='<cidr>', help=_('IP block to allocate from (ex. 172.16.0.0/24 or 2001:DB8::/64)'))@cliutils.arg('network_id', metavar='<network_id>', help='ID of network')","@utils.arg('network_id', metavar='<network_id>', help='ID of network')@utils.arg('label', metavar='<network_label>', help=_('Network label (ex. my_new_network)')) @utils.arg('cidr', metavar='<cidr>', help=_('IP block to allocate from (ex. 172.16.0.0/24 or ' '2001:DB8::/64)'))@utils.arg('network_id', metavar='<network_id>', help='ID of network')",1445,1349
openstack%2Fnova~master~I184985573b20144717ac40f1f3c26709030d5a03,openstack/nova,master,I184985573b20144717ac40f1f3c26709030d5a03,Adjust audit logs to avoid negative disk info,MERGED,2014-08-11 18:46:32.000000000,2014-10-20 17:39:56.000000000,2014-10-20 17:39:35.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11929}]","[{'number': 1, 'created': '2014-08-11 18:46:32.000000000', 'files': ['nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d2ab9079ada5135598a89aa65f3ef8b63bf28003', 'message': 'Adjust audit logs to avoid negative disk info\n\nWhen requesting more disk than is available, the audit\nlogs will report negative values. This may confuse the\nuser or make him/her think the tracking is innaccurate.\n\nThis patch seeks to remove any confusion. It is in the\nsame vein as https://review.openstack.org/#/c/93261/\nwhich addresses the same issue in regards to cpu and\nmemory audit logs.\n\nChange-Id: I184985573b20144717ac40f1f3c26709030d5a03\nCloses-bug: #1350542\n'}]",0,113342,d2ab9079ada5135598a89aa65f3ef8b63bf28003,24,12,1,11929,,,0,"Adjust audit logs to avoid negative disk info

When requesting more disk than is available, the audit
logs will report negative values. This may confuse the
user or make him/her think the tracking is innaccurate.

This patch seeks to remove any confusion. It is in the
same vein as https://review.openstack.org/#/c/93261/
which addresses the same issue in regards to cpu and
memory audit logs.

Change-Id: I184985573b20144717ac40f1f3c26709030d5a03
Closes-bug: #1350542
",git fetch https://review.opendev.org/openstack/nova refs/changes/42/113342/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/resource_tracker.py'],1,d2ab9079ada5135598a89aa65f3ef8b63bf28003,mjturek/1350542," LOG.audit(_(""Total physical disk (GB): %(pdisk)s, "" ""total allocated virtual disk (GB): %(vdisk)s""), {'pdisk': resources['local_gb'], 'vdisk': resources['local_gb_used']})"," LOG.audit(_(""Free disk (GB): %s"") % resources['free_disk_gb'])",4,1
openstack%2Ftraining-guides~master~Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b,openstack/training-guides,master,Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b,Adds test scripts for upstream training content,ABANDONED,2014-10-06 10:00:28.000000000,2014-10-20 17:38:37.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6923}, {'_account_id': 7007}, {'_account_id': 9178}, {'_account_id': 11109}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-10-06 10:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/3b64385822479c0cfe471ce4d4db3ef52e6027d1', 'message': 'Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\n    $ tox -e upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n'}, {'number': 2, 'created': '2014-10-06 13:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/e12c1c5a55611b2c537b86639cad6df8d6fff337', 'message': 'Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\n    $ tox -e upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n'}, {'number': 3, 'created': '2014-10-06 13:42:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/134057190e491cd2cde639da4896f7b3e509a320', 'message': 'Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\n    $ tox -e upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n'}, {'number': 4, 'created': '2014-10-06 13:43:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/60f18234a6b6ee709c3108877ec93e214636b35a', 'message': 'Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\n    $ tox -e check-upstream-content\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n'}, {'number': 5, 'created': '2014-10-06 13:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/baa6c2b1c16c3cd4811b540b1d854136a60984f7', 'message': 'Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\n    $ tox -e check-upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n'}, {'number': 6, 'created': '2014-10-06 14:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/2577e4be61685565a9470fc4d2d775fcbdb9e4fe', 'message': 'Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\n    $ tox -e check-upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n'}, {'number': 7, 'created': '2014-10-06 16:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/365a5f833f88b7f17496e6fc22e85667854427ac', 'message': 'Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\n    $ tox -e check-upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n'}, {'number': 8, 'created': '2014-10-06 16:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/35375f957b24e04076cdf9024dc6f4047f68e676', 'message': 'Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\n    $ tox -e check-upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n'}, {'number': 9, 'created': '2014-10-06 16:34:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/125e076250de37b6c5ef280154504ba4a1ea0f5f', 'message': 'Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\n    $ tox -e check-upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n'}, {'number': 10, 'created': '2014-10-08 11:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/e950f1b30a08e26e999e576c57cefb1fd8db8597', 'message': 'Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\n    $ tox -e check-upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n'}, {'number': 11, 'created': '2014-10-08 12:39:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/8fc60834fdf6de3f6b7d8d037e2e2c438b009573', 'message': 'Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\n    $ tox -e check-upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n'}, {'number': 12, 'created': '2014-10-08 19:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/6a2225a4d97c8c97024219200b88a0399be9cf1c', 'message': 'Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\n    $ tox -e check-upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n'}, {'number': 13, 'created': '2014-10-10 09:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/035e9a42081d9bf7c8d0615e382d5179ee6ba099', 'message': ""Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\nIf you want to use tox to run the script, please add 'landslide' and\n'weasyprint' to the test-requirements.txt file.\n\n    $ tox -e check-upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n""}, {'number': 14, 'created': '2014-10-12 08:26:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/8733758ee5d096d184e21d2a7629fa3cf245ae42', 'message': ""Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\nIf you want to use tox to run the script, please add 'landslide' and\n'weasyprint' to the test-requirements.txt file.\n\n    $ tox -e check-upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n""}, {'number': 15, 'created': '2014-10-12 08:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/aa104d73459fce4dd62a1a1a8984ad3c4bb25c49', 'message': ""Adds test scripts for upstream training content\n\nThis patch introduces some basic test scripts for upstream training\ncontent which can be invoked via. tox\n\nIf you want to use tox to run the script, please add 'landslide' and\n'weasyprint' to the test-requirements.txt file.\n\n    $ tox -e check-upstream-training\n\nI will also push the patch in openstack-infra for making this test run\nas silent check on jenkins. The upcoming patches should make it\ncompletely automated.\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n""}, {'number': 16, 'created': '2014-10-12 13:37:42.000000000', 'files': ['tools/build-rst-slides', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/2e5a762b626d4ad5f2a6d50f967400d5d21c26ef', 'message': ""Adds test scripts for upstream training content\n\nThis patch introduces a script for converting slides from upstream training\ninto HTML and PDF files. It can be invoked directly or via tox.\n\nIf you want to use tox to run the script, please add 'landslide' and\n'weasyprint' to the test-requirements.txt file.\n\n    $ tox -e check-upstream-training\n\nChange-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b\n""}]",17,126246,2e5a762b626d4ad5f2a6d50f967400d5d21c26ef,44,7,16,7007,,,0,"Adds test scripts for upstream training content

This patch introduces a script for converting slides from upstream training
into HTML and PDF files. It can be invoked directly or via tox.

If you want to use tox to run the script, please add 'landslide' and
'weasyprint' to the test-requirements.txt file.

    $ tox -e check-upstream-training

Change-Id: Ib0d7aa625bc7b58e75c3b33b894371856fceaf2b
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/46/126246/12 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tools/test_upstream-training', 'tox.ini', 'tools/wkhtml2pdf']",4,3b64385822479c0cfe471ce4d4db3ef52e6027d1,tg_tools,sudo apt-get install -y openssl build-essential xorg libssl-dev wget http://wkhtmltopdf.googlecode.com/files/wkhtmltopdf-0.10.0_rc2-static-amd64.tar.bz2 tar xvjf wkhtmltopdf-0.10.0_rc2-static-amd64.tar.bz2 export wkhtmltopdf=${current_dir}/wkhtmltopdf-amd64 echo 'Cleaning Up' rm -r *.tar.bz2 ,,158,2
openstack%2Ftraining-guides~master~If7861fe192c8a3ace65a49dbafd875fa5bd1a83e,openstack/training-guides,master,If7861fe192c8a3ace65a49dbafd875fa5bd1a83e,Updates test-requirements for upstream training,ABANDONED,2014-10-08 11:49:39.000000000,2014-10-20 17:38:14.000000000,,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-10-08 11:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/ddeef55e40fe100387b8a164824df1d54a7593e6', 'message': 'Updates test-requirements for upstream training\n\nUpdates to the test-requirements file should be carried out only\nafter merging them in global requirements. This patch should not be\nmerged till it is verified and updated with global requirements.\n\nChange-Id: If7861fe192c8a3ace65a49dbafd875fa5bd1a83e\n'}, {'number': 2, 'created': '2014-10-10 10:04:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/81998b9dd3a8e2f426b0f65d8ec36ff1b63f9e6b', 'message': 'Updates test-requirements for upstream training\n\nAdds landslide and weasyprint as dependencies to test-requirements.txt for tox to be able to build pdf and html files in upstream training contents. To generate the pdf and html files from rst the script build-rst-slides script will be invoked and requires the given python packages. \n\nChange-Id: If7861fe192c8a3ace65a49dbafd875fa5bd1a83e\n'}, {'number': 3, 'created': '2014-10-10 10:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/e44623da7b82b937a8dfbab19298e7831ac17b9c', 'message': 'Updates test-requirements for upstream training\n\nAdds landslide and weasyprint as dependencies to test-requirements.txt\nfor tox to be able to build pdf and html files in upstream training\ncontents. To generate the pdf and html files from rst the script\nbuild-rst-slides script will be invoked and requires the given python\npackages. \n\nChange-Id: If7861fe192c8a3ace65a49dbafd875fa5bd1a83e\n'}, {'number': 4, 'created': '2014-10-16 12:20:43.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/3af0fe1976fb2069290ebeaac67f117f24e06fe7', 'message': 'Updates test-requirements for upstream training\n\nAdds landslide and weasyprint as dependencies to test-requirements.txt\nfor tox to be able to build pdf and html files in upstream training\ncontents. To generate the pdf and html files from rst the script\nbuild-rst-slides script will be invoked and requires the given python\npackages.\n\nChange-Id: If7861fe192c8a3ace65a49dbafd875fa5bd1a83e\n'}]",0,126877,3af0fe1976fb2069290ebeaac67f117f24e06fe7,13,3,4,7007,,,0,"Updates test-requirements for upstream training

Adds landslide and weasyprint as dependencies to test-requirements.txt
for tox to be able to build pdf and html files in upstream training
contents. To generate the pdf and html files from rst the script
build-rst-slides script will be invoked and requires the given python
packages.

Change-Id: If7861fe192c8a3ace65a49dbafd875fa5bd1a83e
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/77/126877/4 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ddeef55e40fe100387b8a164824df1d54a7593e6,update_test_requirements,jinja2 pygments>=1.6 markdown>=2.5 docutils>=0.12 landslide==1.1.1 weasyprint==0.23,,6,0
openstack%2Fheat~master~I356fbe0042f24aba78fba5deebe7fa645a035d96,openstack/heat,master,I356fbe0042f24aba78fba5deebe7fa645a035d96,"Don't shadow local variables ""resource""",MERGED,2014-10-17 02:32:25.000000000,2014-10-20 17:37:31.000000000,2014-10-20 17:37:30.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 6577}, {'_account_id': 6610}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 8289}]","[{'number': 1, 'created': '2014-10-17 02:32:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4f8844942f80454cc09175caff962e38a3feee55', 'message': 'Don\'t shadow local variables ""resource""\n\nWe could rename the local variables, but it\'s just as easy to not\nuse the resource module.\n\nChange-Id: I356fbe0042f24aba78fba5deebe7fa645a035d96\n'}, {'number': 2, 'created': '2014-10-20 12:24:37.000000000', 'files': ['heat/engine/service.py', 'heat/tests/test_instance_group.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a2a2bb407bbf48c3a5c03fd79f6dc7eda9d67607', 'message': 'Don\'t shadow local variables ""resource""\n\nWe could rename the local variables, but it\'s just as easy to not\nuse the resource module. Since the functions are not used, remove them.\n\nChange-Id: I356fbe0042f24aba78fba5deebe7fa645a035d96\n'}]",0,129111,a2a2bb407bbf48c3a5c03fd79f6dc7eda9d67607,16,7,2,4715,,,0,"Don't shadow local variables ""resource""

We could rename the local variables, but it's just as easy to not
use the resource module. Since the functions are not used, remove them.

Change-Id: I356fbe0042f24aba78fba5deebe7fa645a035d96
",git fetch https://review.opendev.org/openstack/heat refs/changes/11/129111/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/service.py'],1,4f8844942f80454cc09175caff962e38a3feee55,no-shadow, return resources.global_env().get_types(support_status) resource_class = resources.global_env().get_class(type_name) return resources.global_env().get_class( type_name).resource_to_template(type_name),from heat.engine import resource return resource.get_types(support_status) resource_class = resource.get_class(type_name) return \ resource.get_class(type_name).resource_to_template(type_name),4,5
openstack%2Frequirements~master~Iec27132141265bf4308ad22bb0750f146c18bb21,openstack/requirements,master,Iec27132141265bf4308ad22bb0750f146c18bb21,Update training guides requirements,ABANDONED,2014-10-10 09:59:41.000000000,2014-10-20 17:36:52.000000000,,"[{'_account_id': 3}, {'_account_id': 287}, {'_account_id': 2472}, {'_account_id': 6923}, {'_account_id': 7007}]","[{'number': 1, 'created': '2014-10-10 09:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4e15bd2ddd68193bfba61d23f1f632817a4fccc0', 'message': 'Update training guides requirements\n\nAdds landslide and weasyprint for generating html and pdf files from\nrst files.\n\nChange-Id: Iec27132141265bf4308ad22bb0750f146c18bb21\n'}, {'number': 2, 'created': '2014-10-16 17:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/3eaec0cbb4365364963e65e672d39c5620cfd5d3', 'message': 'Update training guides requirements\n\nAdds landslide and weasyprint for generating html and pdf files from\nrst files.\n\nChange-Id: Iec27132141265bf4308ad22bb0750f146c18bb21\n'}, {'number': 3, 'created': '2014-10-16 17:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/fe7d8a75a255349557612650baab23e80218bd36', 'message': 'Update training guides requirements\n\nAdds landslide and weasyprint for generating html and pdf files from\nrst files. Training guides requires landslide for generating HTML5 presentations and weasyprint is used for generating the HTML5 presentations from html to pdf format.\n\nChange-Id: Iec27132141265bf4308ad22bb0750f146c18bb21\n'}, {'number': 4, 'created': '2014-10-16 17:37:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/dc76d12af0b31882dc198113a921af0157bd8d01', 'message': 'Update training guides requirements\n\nAdds landslide and weasyprint for generating html and pdf files from\nrst files. Training guides requires landslide for generating HTML5\npresentations and weasyprint is used for generating the HTML5\npresentations from html to pdf format.\n\nChange-Id: Iec27132141265bf4308ad22bb0750f146c18bb21\n'}, {'number': 5, 'created': '2014-10-16 17:48:00.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5f6cc2a2a956bd9073603cdad218af5e99b099be', 'message': 'Update training guides requirements\n\nAdds landslide and weasyprint for generating html and pdf files from\nrst files. Training guides requires landslide for generating HTML5\npresentations and weasyprint is used for generating the HTML5\npresentations from html to pdf format.\n\nThis is required for building upstream-training content present under\ntraining-guides project.\n\nChange-Id: Iec27132141265bf4308ad22bb0750f146c18bb21\n'}]",2,127472,5f6cc2a2a956bd9073603cdad218af5e99b099be,15,5,5,7007,,,0,"Update training guides requirements

Adds landslide and weasyprint for generating html and pdf files from
rst files. Training guides requires landslide for generating HTML5
presentations and weasyprint is used for generating the HTML5
presentations from html to pdf format.

This is required for building upstream-training content present under
training-guides project.

Change-Id: Iec27132141265bf4308ad22bb0750f146c18bb21
",git fetch https://review.opendev.org/openstack/requirements refs/changes/72/127472/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,4e15bd2ddd68193bfba61d23f1f632817a4fccc0,127472,landslide>=1.1.1weasyptin>=0.23,,2,0
openstack%2Fnova~master~I003979bb3796e870890e220cf4b046e51581a373,openstack/nova,master,I003979bb3796e870890e220cf4b046e51581a373,XenAPI: Inform XAPI who is connecting to it,MERGED,2014-10-13 11:45:12.000000000,2014-10-20 17:36:32.000000000,2014-10-20 17:36:29.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 5441}, {'_account_id': 6735}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-13 11:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b53bfe17d5139d211591f5828e93108bdfd05fa9', 'message': ""XenAPI: Inform XAPI who is connecting to it\n\nXenServer supports an 'originator' being passed to the login function\nThis originator is very useful in identifying how XAPI is being used\nand, when there is a problem, which software package issued which\ncommands\n\nChange-Id: I003979bb3796e870890e220cf4b046e51581a373\n""}, {'number': 2, 'created': '2014-10-13 16:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f2265968442b8f1bc0d1df28733b05bab44fc5d', 'message': ""XenAPI: Inform XAPI who is connecting to it\n\nXenServer supports an 'originator' being passed to the login function\nThis originator is very useful in identifying how XAPI is being used\nand, when there is a problem, which software package issued which\ncommands\n\nChange-Id: I003979bb3796e870890e220cf4b046e51581a373\n""}, {'number': 3, 'created': '2014-10-14 09:40:24.000000000', 'files': ['nova/virt/xenapi/client/session.py', 'nova/tests/virt/xenapi/client/test_session.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/41c453314e87e5ecc9ca8d142be41cdfb9abed5c', 'message': ""XenAPI: Inform XAPI who is connecting to it\n\nXenServer supports an 'originator' being passed to the login function\nThis originator is very useful in identifying how XAPI is being used\nand, when there is a problem, which software package issued which\ncommands\n\nChange-Id: I003979bb3796e870890e220cf4b046e51581a373\n""}]",4,127941,41c453314e87e5ecc9ca8d142be41cdfb9abed5c,24,10,3,6735,,,0,"XenAPI: Inform XAPI who is connecting to it

XenServer supports an 'originator' being passed to the login function
This originator is very useful in identifying how XAPI is being used
and, when there is a problem, which software package issued which
commands

Change-Id: I003979bb3796e870890e220cf4b046e51581a373
",git fetch https://review.opendev.org/openstack/nova refs/changes/41/127941/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/xenapi/client/session.py'],1,b53bfe17d5139d211591f5828e93108bdfd05fa9,," session.login_with_password(user, pw, '', 'OpenStack') session.login_with_password(user, pw, '', 'OpenStack') session.login_with_password(user, pw, '', 'OpenStack')"," session.login_with_password(user, pw) session.login_with_password(user, pw) session.login_with_password(user, pw)",3,3
openstack%2Fkeystonemiddleware~master~I53075cc04d0ccea543f8e657279534208ed03058,openstack/keystonemiddleware,master,I53075cc04d0ccea543f8e657279534208ed03058,Changing the value type of http_connect_timeout,MERGED,2014-10-07 12:22:44.000000000,2014-10-20 17:34:44.000000000,2014-10-20 17:34:44.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 8871}, {'_account_id': 9101}]","[{'number': 1, 'created': '2014-10-07 12:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/3a8f6cefb58160e6a92ff14076c2587d3db6952d', 'message': ""Changing the value type definition of http_connect_timeout from Bool to Int\n\nThe value type of http_connect_timeout definition is changed from Bool to\nInt value. Python treats a value more than 1 as True but oslo config\ndefines Boolean values as 'true, '1', 'yes' and 'on'. So http_connect_timeout\nis only configured 1 or None.\n\nChange-Id: I53075cc04d0ccea543f8e657279534208ed03058\nCloses-bug: #11368545\n""}, {'number': 2, 'created': '2014-10-10 12:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/8901cf4097355084a30a3ada1516222c46216cbb', 'message': ""Changing the value type definition of http_connect_timeout from Bool to Int\n\nThe value type of http_connect_timeout definition is changed from Bool to\nInt value. Python treats a value more than 1 as True but oslo config\ndefines Boolean values as 'true, '1', 'yes' and 'on'. So http_connect_timeout\nis only configured 1 or None.\n\nChange-Id: I53075cc04d0ccea543f8e657279534208ed03058\nCloses-bug: #1368545\n""}, {'number': 3, 'created': '2014-10-14 12:30:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/aa147005e4410589ca5f5ff87a363b51a82e4d56', 'message': ""hanging the value type of http_connect_timeout\n\nThe value type of http_connect_timeout definition\nis changed from Bool to Int value. Python treats\na value more than 1 as True but oslo config defines\nBoolean values as 'true, '1', 'yes' and 'on'.\nSo http_connect_timeout is only configured 1 or None.\n\nChange-Id: I53075cc04d0ccea543f8e657279534208ed03058\nCloses-bug: #1368545\n""}, {'number': 4, 'created': '2014-10-20 12:11:02.000000000', 'files': ['keystonemiddleware/auth_token.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/c1eef68186ede3cc0bf521e34056489abea7fcd1', 'message': ""Changing the value type of http_connect_timeout\n\nThe value type of http_connect_timeout definition\nis changed from Bool to Int value. Python treats\na value more than 1 as True but oslo config defines\nBoolean values as 'true, '1', 'yes' and 'on'.\nSo http_connect_timeout is only configured 1 or None.\n\nChange-Id: I53075cc04d0ccea543f8e657279534208ed03058\nCloses-bug: #1368545\n""}]",1,126543,c1eef68186ede3cc0bf521e34056489abea7fcd1,18,5,4,8878,,,0,"Changing the value type of http_connect_timeout

The value type of http_connect_timeout definition
is changed from Bool to Int value. Python treats
a value more than 1 as True but oslo config defines
Boolean values as 'true, '1', 'yes' and 'on'.
So http_connect_timeout is only configured 1 or None.

Change-Id: I53075cc04d0ccea543f8e657279534208ed03058
Closes-bug: #1368545
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/43/126543/4 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token.py'],1,3a8f6cefb58160e6a92ff14076c2587d3db6952d,bug/1368545," cfg.IntOpt('http_connect_timeout',"," cfg.BoolOpt('http_connect_timeout',",1,1
openstack%2Fkeystone~master~I5385a086210e415a14b0ed1605c9ded50a280ad2,openstack/keystone,master,I5385a086210e415a14b0ed1605c9ded50a280ad2,Remove unused ec2 driver option,MERGED,2014-09-29 17:15:06.000000000,2014-10-20 17:34:20.000000000,2014-10-20 17:34:20.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6486}, {'_account_id': 9101}]","[{'number': 1, 'created': '2014-09-29 17:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9f721f8f2c2bb4507d2ba329c36c19d6c564416d', 'message': 'Remove unused ec2 driver option\n\nRemove the unused ec2 driver option from the config. This option\nis unused since the credential backend is used for the ec2 contrib\nextension.\n\nChange-Id: I5385a086210e415a14b0ed1605c9ded50a280ad2\n'}, {'number': 2, 'created': '2014-09-29 17:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d663fe88eeff498b38b161c4d09cf056c1fcfc08', 'message': 'Remove unused ec2 driver option\n\nRemove the unused ec2 driver option from the config. This option\nis unused since the credential backend is used for the ec2 contrib\nextension.\n\nChange-Id: I5385a086210e415a14b0ed1605c9ded50a280ad2\n'}, {'number': 3, 'created': '2014-10-13 21:16:31.000000000', 'files': ['etc/keystone.conf.sample', 'keystone/tests/core.py', 'keystone/common/config.py', 'doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/fd57a12b0bbe82f714046397d695c1cc570237b2', 'message': 'Remove unused ec2 driver option\n\nRemove the unused ec2 driver option from the config. This option\nis unused since the credential backend is used for the ec2 contrib\nextension.\n\nChange-Id: I5385a086210e415a14b0ed1605c9ded50a280ad2\n'}]",0,124810,fd57a12b0bbe82f714046397d695c1cc570237b2,20,6,3,2903,,,0,"Remove unused ec2 driver option

Remove the unused ec2 driver option from the config. This option
is unused since the credential backend is used for the ec2 contrib
extension.

Change-Id: I5385a086210e415a14b0ed1605c9ded50a280ad2
",git fetch https://review.opendev.org/openstack/keystone refs/changes/10/124810/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/common/config.py']",2,9f721f8f2c2bb4507d2ba329c36c19d6c564416d,,," 'ec2': [ cfg.StrOpt('driver', default='keystone.contrib.ec2.backends.kvs.Ec2', help='EC2Credential backend driver.'), ],",0,15
openstack%2Fdevstack~master~I0831e8308205c116d8e3bb8b43be7f0dd6fa0c0a,openstack/devstack,master,I0831e8308205c116d8e3bb8b43be7f0dd6fa0c0a,Compile Horizon message catalogs during stack.sh,MERGED,2014-10-15 10:50:30.000000000,2014-10-20 17:33:56.000000000,2014-10-20 17:33:55.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 970}, {'_account_id': 7118}, {'_account_id': 7350}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-15 10:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/24fa2b0c3e2fda82b4e6884ca687d5f129cd1e1f', 'message': 'Compile Horizon message catalogs during stack.sh\n\nRecently compiled message catalogs (mo files) were removed\nin Horizon and django_openstack_auth repositories.\nWe need to compile message catalogs to make translations\navailable for Horizon users. It is useful for developers too.\n\nChange-Id: I0831e8308205c116d8e3bb8b43be7f0dd6fa0c0a\n'}, {'number': 2, 'created': '2014-10-15 13:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/05b97e8bc46a552b84b20e3935cc1ee3a3b47fdc', 'message': 'Compile Horizon message catalogs during stack.sh\n\nRecently compiled message catalogs (mo files) were removed\nin Horizon and django_openstack_auth repositories.\nWe need to compile message catalogs to make translations\navailable for Horizon users. It is useful for developers too.\n\nChange-Id: I0831e8308205c116d8e3bb8b43be7f0dd6fa0c0a\n'}, {'number': 3, 'created': '2014-10-15 17:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f0aa6812cb3c5712e8c3c9c37f64a0a0b374ad55', 'message': 'Compile Horizon message catalogs during stack.sh\n\nRecently compiled message catalogs (mo files) were removed\nin Horizon and django_openstack_auth repositories.\nWe need to compile message catalogs to make translations\navailable for Horizon users. It is useful for developers too.\n\nChange-Id: I0831e8308205c116d8e3bb8b43be7f0dd6fa0c0a\n'}, {'number': 4, 'created': '2014-10-17 21:40:23.000000000', 'files': ['files/rpms/general', 'files/apts/general', 'lib/horizon'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6518c0b88ea52e93513fa34dd63eeb4596875212', 'message': 'Compile Horizon message catalogs during stack.sh\n\nRecently compiled message catalogs (mo files) were removed\nin Horizon and django_openstack_auth repositories.\nWe need to compile message catalogs to make translations\navailable for Horizon users. It is useful for developers too.\n\nChange-Id: I0831e8308205c116d8e3bb8b43be7f0dd6fa0c0a\n'}]",4,128601,6518c0b88ea52e93513fa34dd63eeb4596875212,34,7,4,841,,,0,"Compile Horizon message catalogs during stack.sh

Recently compiled message catalogs (mo files) were removed
in Horizon and django_openstack_auth repositories.
We need to compile message catalogs to make translations
available for Horizon users. It is useful for developers too.

Change-Id: I0831e8308205c116d8e3bb8b43be7f0dd6fa0c0a
",git fetch https://review.opendev.org/openstack/devstack refs/changes/01/128601/4 && git format-patch -1 --stdout FETCH_HEAD,"['files/apts/general', 'lib/horizon']",2,24fa2b0c3e2fda82b4e6884ca687d5f129cd1e1f,horizon-compile-catalog," # Compile message catalogs. # Horizon is installed as develop mode, so we can compile here. # Message catalog compilation is handled by Django admin script, # so compiling them after the installation avoids Django installation twice. pushd $HORIZON_DIR ./run_tests.sh -N --compilemessages popd # Compile message catalogs before installation _prepare_message_catalog_compilation pushd $HORIZONAUTH_DIR python setup.py compile_catalog popd # NOTE: It can be moved to common functions, but it is only used by compilation # of django_openstack_auth catalogs at the moment. function _prepare_message_catalog_compilation { local babel_package=$(cat $REQUIREMENTS_DIR/global-requirements.txt | grep ^Babel) pip_install ""$babel_package"" } ",,23,0
openstack%2Fhorizon~stable%2Ficehouse~I1e59f2bf6633a34cfe9230aa028f345e5fa70f94,openstack/horizon,stable/icehouse,I1e59f2bf6633a34cfe9230aa028f345e5fa70f94,Update WSGI app creation to be compatible with Django 1.7,MERGED,2014-10-17 12:31:57.000000000,2014-10-20 17:33:45.000000000,2014-10-20 17:33:45.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 7213}, {'_account_id': 9317}, {'_account_id': 10442}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-10-17 12:31:57.000000000', 'files': ['openstack_dashboard/wsgi/django.wsgi'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e5a9037d2ff5f2fbd5bde8e073e90b8d290994d3', 'message': ""Update WSGI app creation to be compatible with Django 1.7\n\nThis resolves the following error when trying to run Horizon:\n\nAppRegistryNotReady: The translation infrastructure cannot be\ninitialized before the apps registry is ready. Check that you don't\nmake non-lazy gettext calls at import time.\n\nand is backwards-compatible with our currently supported versions (back\nto 1.4).\n\nChange-Id: I1e59f2bf6633a34cfe9230aa028f345e5fa70f94\nCloses-Bug: #1382023\n(cherry picked from commit 686af384c201148c3aebcfbf18b2527587d70ea4)\n""}]",0,129222,e5a9037d2ff5f2fbd5bde8e073e90b8d290994d3,17,10,1,4978,,,0,"Update WSGI app creation to be compatible with Django 1.7

This resolves the following error when trying to run Horizon:

AppRegistryNotReady: The translation infrastructure cannot be
initialized before the apps registry is ready. Check that you don't
make non-lazy gettext calls at import time.

and is backwards-compatible with our currently supported versions (back
to 1.4).

Change-Id: I1e59f2bf6633a34cfe9230aa028f345e5fa70f94
Closes-Bug: #1382023
(cherry picked from commit 686af384c201148c3aebcfbf18b2527587d70ea4)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/22/129222/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/wsgi/django.wsgi'],1,e5a9037d2ff5f2fbd5bde8e073e90b8d290994d3,bug/1382023,from django.core.wsgi import get_wsgi_applicationapplication = get_wsgi_application(),import django.core.handlers.wsgiapplication = django.core.handlers.wsgi.WSGIHandler() ,2,3
openstack%2Ffuel-library~master~I620fe47748a15b4e6a6a87f832d604d19c0dd42e,openstack/fuel-library,master,I620fe47748a15b4e6a6a87f832d604d19c0dd42e,Fix specs for ceilometer,MERGED,2014-10-20 15:03:07.000000000,2014-10-20 17:29:16.000000000,2014-10-20 16:46:54.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13343}]","[{'number': 1, 'created': '2014-10-20 15:03:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c040341eb72098768c6e9386d3266feabb85cb84', 'message': 'Fix specs for ceilometer\n\nBackposring bugfix from upstream.\n\nUpstream-Bug: 1353844\nUpstream fix change-id: If64f1ea641c5d99c0adf2104a308c2d5442c3324\n\nChange-Id: I620fe47748a15b4e6a6a87f832d604d19c0dd42e\nCloses-bug: 1383337\n'}, {'number': 2, 'created': '2014-10-20 15:04:30.000000000', 'files': ['deployment/puppet/ceilometer/spec/classes/ceilometer_agent_notification_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d1beae25dc5f372656bf176bff68ed0ef3a45853', 'message': 'Fix specs for ceilometer\n\nBackporting bugfix from upstream.\n\nUpstream-Bug: 1353844\nUpstream fix change-id: If64f1ea641c5d99c0adf2104a308c2d5442c3324\n\nChange-Id: I620fe47748a15b4e6a6a87f832d604d19c0dd42e\nCloses-bug: 1383337\n'}]",0,129640,d1beae25dc5f372656bf176bff68ed0ef3a45853,16,6,2,9387,,,0,"Fix specs for ceilometer

Backporting bugfix from upstream.

Upstream-Bug: 1353844
Upstream fix change-id: If64f1ea641c5d99c0adf2104a308c2d5442c3324

Change-Id: I620fe47748a15b4e6a6a87f832d604d19c0dd42e
Closes-bug: 1383337
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/40/129640/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/ceilometer/spec/classes/ceilometer_agent_notification_spec.rb'],1,c040341eb72098768c6e9386d3266feabb85cb84,bug/1353844," { :agent_notification_package_name => 'openstack-ceilometer-notification', :agent_notification_service_name => 'openstack-ceilometer-notification' }"," { :agent_notification_package_name => 'openstack-ceilometer-collector', :agent_notification_service_name => 'openstack-ceilometer-agent-notification' }",2,2
openstack%2Fsahara~master~I04906af72b3e69dcb1a286096b35768ce1483f1c,openstack/sahara,master,I04906af72b3e69dcb1a286096b35768ce1483f1c,Fix parallel testing EDP jobs for Fedora and CentOS images,MERGED,2014-10-17 10:02:18.000000000,2014-10-20 17:28:55.000000000,2014-10-20 17:28:55.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-17 10:02:18.000000000', 'files': ['sahara/tests/integration/tests/gating/test_vanilla_two_gating.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4e9f1ca819c06bc8ad6013066c4a9995df07ba7d', 'message': 'Fix parallel testing EDP jobs for Fedora and CentOS images\n\nChange-Id: I04906af72b3e69dcb1a286096b35768ce1483f1c\n'}]",0,129194,4e9f1ca819c06bc8ad6013066c4a9995df07ba7d,22,6,1,7710,,,0,"Fix parallel testing EDP jobs for Fedora and CentOS images

Change-Id: I04906af72b3e69dcb1a286096b35768ce1483f1c
",git fetch https://review.opendev.org/openstack/sahara refs/changes/94/129194/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/tests/integration/tests/gating/test_vanilla_two_gating.py'],1,4e9f1ca819c06bc8ad6013066c4a9995df07ba7d,fix-vanilla-dib-tests," 'yarn.scheduler.maximum-allocation-mb': 1024, 'yarn.nodemanager.vmem-check-enabled': False", 'yarn.scheduler.maximum-allocation-mb': 1024,2,1
openstack%2Ftrove~master~I2395e3a65efd1a8b9ec494fd59a0e2ee2009f59a,openstack/trove,master,I2395e3a65efd1a8b9ec494fd59a0e2ee2009f59a,Miscellaneous Cluster Fixes,MERGED,2014-09-05 00:08:30.000000000,2014-10-20 17:28:29.000000000,2014-10-20 17:28:29.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9683}]","[{'number': 1, 'created': '2014-09-05 00:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6685a2016c87ce65b156ffa51d8c6b527d0a8df6', 'message': 'Miscellaneous Cluster Fixes\n\naddresses a few minor issues raised after clusters was merged.\n\nChange-Id: I2395e3a65efd1a8b9ec494fd59a0e2ee2009f59a\nCloses-Bug: #1365767\n'}, {'number': 2, 'created': '2014-09-05 20:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/019c79f2f3d2bbd30c0a903d89c5ab3fa4252541', 'message': 'Miscellaneous Cluster Fixes\n\naddresses a few minor issues raised after clusters was merged.\n\nChange-Id: I2395e3a65efd1a8b9ec494fd59a0e2ee2009f59a\nCloses-Bug: #1365767\n'}, {'number': 3, 'created': '2014-09-05 20:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f6803d7de7ca22b70824856c09a658a4469dda02', 'message': 'Miscellaneous Cluster Fixes\n\naddresses a few minor issues raised after clusters was merged.\n\nChange-Id: I2395e3a65efd1a8b9ec494fd59a0e2ee2009f59a\nCloses-Bug: #1365767\n'}, {'number': 4, 'created': '2014-09-05 22:39:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3983f595d4459216487e14d05d95f3636ba21386', 'message': 'Miscellaneous Cluster Fixes\n\naddresses a few minor issues raised after clusters was merged.\n\nChange-Id: I2395e3a65efd1a8b9ec494fd59a0e2ee2009f59a\nCloses-Bug: #1365767\n'}, {'number': 5, 'created': '2014-09-08 19:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/264c1a2376887933f1b6d8141c8f23412f0f42ba', 'message': 'Miscellaneous Cluster Fixes\n\naddresses a few minor issues raised after clusters was merged.\n\nChange-Id: I2395e3a65efd1a8b9ec494fd59a0e2ee2009f59a\nCloses-Bug: #1365767\n'}, {'number': 6, 'created': '2014-09-09 08:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f9e97003096dfe6de1e3bab07b670027e8826557', 'message': 'Miscellaneous Cluster Fixes\n\naddresses a few minor issues raised after clusters was merged.\n\nChange-Id: I2395e3a65efd1a8b9ec494fd59a0e2ee2009f59a\nCloses-Bug: #1365767\n'}, {'number': 7, 'created': '2014-09-11 22:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/78c152a4e6d3b63c88fc1fb2cc8118bb620feb29', 'message': 'Miscellaneous Cluster Fixes\n\naddresses a few minor issues raised after clusters was merged.\n\nChange-Id: I2395e3a65efd1a8b9ec494fd59a0e2ee2009f59a\nCloses-Bug: #1365767\n'}, {'number': 8, 'created': '2014-10-03 17:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/87204aa7b458807e292379c7c9bedc45eceeb65b', 'message': 'Miscellaneous Cluster Fixes\n\naddresses a few minor issues raised after clusters was merged.\n\nChange-Id: I2395e3a65efd1a8b9ec494fd59a0e2ee2009f59a\nCloses-Bug: #1365767\n'}, {'number': 9, 'created': '2014-10-14 17:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8941c7780f66ec555cf27ebd17f7c48c672b94f9', 'message': 'Miscellaneous Cluster Fixes\n\naddresses a few minor issues raised after clusters was merged.\n\nChange-Id: I2395e3a65efd1a8b9ec494fd59a0e2ee2009f59a\nCloses-Bug: #1365767\n'}, {'number': 10, 'created': '2014-10-15 19:07:12.000000000', 'files': ['trove/common/exception.py', 'trove/guestagent/datastore/mongodb/manager.py', 'trove/common/strategies/mongodb/taskmanager.py', 'trove/cluster/service.py', 'trove/taskmanager/models.py', 'trove/tests/unittests/guestagent/test_mongodb_cluster_manager.py', 'trove/tests/unittests/cluster/test_cluster_controller.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/7b2e5fb9f9df5962d1ef23b8a99ce4d23cdaf250', 'message': 'Miscellaneous Cluster Fixes\n\naddresses a few minor issues raised after clusters was merged.\n\nChange-Id: I2395e3a65efd1a8b9ec494fd59a0e2ee2009f59a\nCloses-Bug: #1365767\n'}]",3,119259,7b2e5fb9f9df5962d1ef23b8a99ce4d23cdaf250,60,7,10,8214,,,0,"Miscellaneous Cluster Fixes

addresses a few minor issues raised after clusters was merged.

Change-Id: I2395e3a65efd1a8b9ec494fd59a0e2ee2009f59a
Closes-Bug: #1365767
",git fetch https://review.opendev.org/openstack/trove refs/changes/59/119259/8 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/exception.py', 'trove/guestagent/datastore/mongodb/service.py', 'trove/guestagent/datastore/mongodb/manager.py', 'trove/common/strategies/mongodb/taskmanager.py', 'trove/instance/models.py', 'trove/taskmanager/models.py']",6,6685a2016c87ce65b156ffa51d8c6b527d0a8df6,bug/1365767," LOG.debug(""Entering guest_prepare"")","# TODO(amcreynolds): add NotifyMixin + ConfigurationMixin-like functionality # TODO(amcreynolds): need to find a way to merge cluster_config # TODO(amcreynolds): into config_contents LOG.info(_(""Entering guest_prepare""))",25,22
openstack%2Fgnocchi~master~Ia028a8cc7badc4e03cf27e3d146f26f989bfc540,openstack/gnocchi,master,Ia028a8cc7badc4e03cf27e3d146f26f989bfc540,"Limit Pecan version, fix Pandas usage",MERGED,2014-10-20 13:13:48.000000000,2014-10-20 17:19:29.000000000,2014-10-20 17:19:28.000000000,"[{'_account_id': 3}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-10-20 13:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/64485c480ec2e76db5b5efb93200e7fadcdac99f', 'message': 'Limite Pecan version\n\nIn order to bypass bug fixed in https://review.openstack.org/#/c/129602/\n\nChange-Id: Ia028a8cc7badc4e03cf27e3d146f26f989bfc540\n'}, {'number': 2, 'created': '2014-10-20 15:24:25.000000000', 'files': ['gnocchi/rest/__init__.py', 'requirements.txt', 'gnocchi/tests/test_storage.py', 'gnocchi/carbonara.py', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a8c0292b68501dd6c1e17d448a64bd47e7574dba', 'message': ""Limit Pecan version, fix Pandas usage\n\nIn order to bypass bug fixed in\nhttps://review.openstack.org/#/c/129602/, we limit Pecan to version\nbefore 0.8.\n\nAlso, let's fix get_measure() usage by passing datetime object directly\nto get_measure() rather than random string. We validate them in the API\nlike the rest of timestamp objects.\n\nChange-Id: Ia028a8cc7badc4e03cf27e3d146f26f989bfc540\n""}]",0,129605,a8c0292b68501dd6c1e17d448a64bd47e7574dba,9,2,2,1669,,,0,"Limit Pecan version, fix Pandas usage

In order to bypass bug fixed in
https://review.openstack.org/#/c/129602/, we limit Pecan to version
before 0.8.

Also, let's fix get_measure() usage by passing datetime object directly
to get_measure() rather than random string. We validate them in the API
like the rest of timestamp objects.

Change-Id: Ia028a8cc7badc4e03cf27e3d146f26f989bfc540
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/05/129605/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,64485c480ec2e76db5b5efb93200e7fadcdac99f,jd/limit-pecan,pecan<0.8,pecan,1,1
openstack%2Fnova~master~Iab4d63200653a4320c91dc1356091ff9d961cafd,openstack/nova,master,Iab4d63200653a4320c91dc1356091ff9d961cafd,Minor refactor of _setup_instance_group(),MERGED,2014-10-13 19:20:04.000000000,2014-10-20 17:19:13.000000000,2014-10-20 17:19:10.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2271}, {'_account_id': 5441}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-13 19:20:04.000000000', 'files': ['nova/scheduler/filter_scheduler.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0eb7f36cfc1cdb65bbb482d3760961e417ccd2d8', 'message': 'Minor refactor of _setup_instance_group()\n\nThis patch is a minor refactoring of the _setup_instance_group()\nmethod in the filter scheduler.  The majority of the method was inside\nof a conditional.  This primarily reverses that and reduces the\nnesting depth used.  There should be no functional changes at all in\nthis patch.\n\nChange-Id: Iab4d63200653a4320c91dc1356091ff9d961cafd\nRelated-bug: #1379451\n'}]",0,128056,0eb7f36cfc1cdb65bbb482d3760961e417ccd2d8,14,9,1,1561,,,0,"Minor refactor of _setup_instance_group()

This patch is a minor refactoring of the _setup_instance_group()
method in the filter scheduler.  The majority of the method was inside
of a conditional.  This primarily reverses that and reduces the
nesting depth used.  There should be no functional changes at all in
this patch.

Change-Id: Iab4d63200653a4320c91dc1356091ff9d961cafd
Related-bug: #1379451
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/128056/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/filter_scheduler.py'],1,0eb7f36cfc1cdb65bbb482d3760961e417ccd2d8,bug/1379451," """"""Update filter_properties with server group info. :returns: True if filter_properties has been updated, False if not. """""" if not group_hint: return False group = objects.InstanceGroup.get_by_hint(context, group_hint) policies = set(('anti-affinity', 'affinity')) if not any((policy in policies) for policy in group.policies): return False if ('affinity' in group.policies and not self._supports_affinity): msg = _(""ServerGroupAffinityFilter not configured"") LOG.error(msg) raise exception.NoValidHost(reason=msg) if ('anti-affinity' in group.policies and not self._supports_anti_affinity): msg = _(""ServerGroupAntiAffinityFilter not configured"") LOG.error(msg) raise exception.NoValidHost(reason=msg) filter_properties.setdefault('group_hosts', set()) user_hosts = set(filter_properties['group_hosts']) group_hosts = set(group.get_hosts(context)) filter_properties['group_hosts'] = user_hosts | group_hosts filter_properties['group_policies'] = group.policies return True"," update_group_hosts = False if group_hint: group = objects.InstanceGroup.get_by_hint(context, group_hint) policies = set(('anti-affinity', 'affinity')) if any((policy in policies) for policy in group.policies): if ('affinity' in group.policies and not self._supports_affinity): msg = _(""ServerGroupAffinityFilter not configured"") LOG.error(msg) raise exception.NoValidHost(reason=msg) if ('anti-affinity' in group.policies and not self._supports_anti_affinity): msg = _(""ServerGroupAntiAffinityFilter not configured"") LOG.error(msg) raise exception.NoValidHost(reason=msg) update_group_hosts = True filter_properties.setdefault('group_hosts', set()) user_hosts = set(filter_properties['group_hosts']) group_hosts = set(group.get_hosts(context)) filter_properties['group_hosts'] = user_hosts | group_hosts filter_properties['group_policies'] = group.policies return update_group_hosts",30,22
openstack%2Fnova~master~Ic0181e241471ad817284209e6a1093a438962bf1,openstack/nova,master,Ic0181e241471ad817284209e6a1093a438962bf1,add InstanceGroup.get_by_instance_uuid,MERGED,2014-10-13 19:20:04.000000000,2014-10-20 17:18:54.000000000,2014-10-20 17:18:51.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 5441}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-13 19:20:04.000000000', 'files': ['nova/tests/objects/test_objects.py', 'nova/objects/instance_group.py', 'nova/tests/objects/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f0624f4446326c3c93611bca12544202096ed2fe', 'message': ""add InstanceGroup.get_by_instance_uuid\n\nAdd a new method to the InstanceGroup object that lets you get a group\nby an instance UUID.  Right now Nova only lets you have an instance in\na single group, so that's why this is a method of InstanceGroup and\nnot InstanceGroupList.\n\nChange-Id: Ic0181e241471ad817284209e6a1093a438962bf1\nRelated-bug: #1379451\n""}]",1,128055,f0624f4446326c3c93611bca12544202096ed2fe,13,9,1,1561,,,0,"add InstanceGroup.get_by_instance_uuid

Add a new method to the InstanceGroup object that lets you get a group
by an instance UUID.  Right now Nova only lets you have an instance in
a single group, so that's why this is a method of InstanceGroup and
not InstanceGroupList.

Change-Id: Ic0181e241471ad817284209e6a1093a438962bf1
Related-bug: #1379451
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/128055/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/objects/test_objects.py', 'nova/objects/instance_group.py', 'nova/tests/objects/test_instance_group.py']",3,f0624f4446326c3c93611bca12544202096ed2fe,bug/1379451," def test_get_by_instance_uuid(self): values = self._get_default_values() policies = ['policy1', 'policy2'] members = ['instance_id1', 'instance_id2'] db_result = self._create_instance_group(self.context, values, policies=policies, members=members) obj_result = instance_group.InstanceGroup.get_by_instance_uuid( self.context, 'instance_id1') self.assertEqual(obj_result.uuid, db_result.uuid) ",,23,4
openstack%2Fheat~master~Icb468b4e3033ae28aa47045fdc18fdcd83f264dc,openstack/heat,master,Icb468b4e3033ae28aa47045fdc18fdcd83f264dc,Add support_status to SoftwareDeployments,MERGED,2014-10-20 00:28:12.000000000,2014-10-20 17:18:41.000000000,2014-10-20 17:18:39.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 8289}]","[{'number': 1, 'created': '2014-10-20 00:28:12.000000000', 'files': ['heat/engine/resources/software_config/software_deployment.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a1037cb19cef356d0500e3569e0f6f3b2f8a999f', 'message': 'Add support_status to SoftwareDeployments\n\nChange-Id: Icb468b4e3033ae28aa47045fdc18fdcd83f264dc\nCloses-Bug: #1383064\n'}]",0,129495,a1037cb19cef356d0500e3569e0f6f3b2f8a999f,9,4,1,4571,,,0,"Add support_status to SoftwareDeployments

Change-Id: Icb468b4e3033ae28aa47045fdc18fdcd83f264dc
Closes-Bug: #1383064
",git fetch https://review.opendev.org/openstack/heat refs/changes/95/129495/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/software_config/software_deployment.py'],1,a1037cb19cef356d0500e3569e0f6f3b2f8a999f,bug/1383064, support_status = support.SupportStatus(version='2014.2') ,,2,0
openstack%2Fheat~master~I9f4579cf55fc697470dd8803553d7968e22a6bec,openstack/heat,master,I9f4579cf55fc697470dd8803553d7968e22a6bec,Catch correct exception for Cinder api version detection,MERGED,2014-10-17 19:39:50.000000000,2014-10-20 17:17:53.000000000,2014-10-20 17:17:52.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 6698}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7404}, {'_account_id': 7634}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 12561}]","[{'number': 1, 'created': '2014-10-17 19:39:50.000000000', 'files': ['heat/engine/clients/os/cinder.py', 'heat/tests/fakes.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/59085e2d6678be4368169e3dba29c3407bf9c519', 'message': 'Catch correct exception for Cinder api version detection\n\nCatch the EndpointNotFound exception raised by Keystone rather\nthan the one thrown by Cinder since keystoneclient raises keystone\nexceptions and not cinder exceptions. Also update the fake\nkeystone client to mirror this behavior.\n\nChange-Id: I9f4579cf55fc697470dd8803553d7968e22a6bec\nCloses-Bug: #1382659\n'}]",2,129365,59085e2d6678be4368169e3dba29c3407bf9c519,16,11,1,7256,,,0,"Catch correct exception for Cinder api version detection

Catch the EndpointNotFound exception raised by Keystone rather
than the one thrown by Cinder since keystoneclient raises keystone
exceptions and not cinder exceptions. Also update the fake
keystone client to mirror this behavior.

Change-Id: I9f4579cf55fc697470dd8803553d7968e22a6bec
Closes-Bug: #1382659
",git fetch https://review.opendev.org/openstack/heat refs/changes/65/129365/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/clients/os/cinder.py', 'heat/tests/fakes.py']",2,59085e2d6678be4368169e3dba29c3407bf9c519,bug/1382659,"from keystoneclient import exceptions # keystone client throws keystone exceptions, not cinder # exceptions. raise exceptions.EndpointNotFound()",from cinderclient import exceptions as cinder_exceptions raise cinder_exceptions.EndpointNotFound(),7,4
openstack%2Fneutron~master~I5a0cc44ba62faf15d6fe3730a9532a3826647820,openstack/neutron,master,I5a0cc44ba62faf15d6fe3730a9532a3826647820,ofagent: Ignore unknown l2pop entry removals,MERGED,2014-08-15 06:18:36.000000000,2014-10-20 17:17:39.000000000,2014-10-20 17:17:37.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 333}, {'_account_id': 2031}, {'_account_id': 2888}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8213}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12737}, {'_account_id': 13263}]","[{'number': 1, 'created': '2014-08-15 06:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f349b0fbeb558b60a778d23555646d2077a998f8', 'message': 'ofagent: Ignore unknown l2pop entry removals\n\nl2pop can send us entry removal without the corresponding entry addtion.\nGracefully ignore it instead of crashing.\n\nCloses-Bug: #1357198\nChange-Id: I5a0cc44ba62faf15d6fe3730a9532a3826647820\n'}, {'number': 2, 'created': '2014-08-15 06:19:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e5834157514da3302febf363bb0bcd3b0b3f4fa1', 'message': 'ofagent: Ignore unknown l2pop entry removals\n\nl2pop can send us entry removal without the corresponding addition.\nGracefully ignore it instead of crashing.\n\nCloses-Bug: #1357198\nChange-Id: I5a0cc44ba62faf15d6fe3730a9532a3826647820\n'}, {'number': 3, 'created': '2014-08-31 11:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/76363fd425e1a43f2d2c81fda4e3b5d01bb1da5c', 'message': 'ofagent: Ignore unknown l2pop entry removals\n\nl2pop can send us entry removal without the corresponding addition.\nGracefully ignore it instead of crashing.\n\nCloses-Bug: #1357198\nChange-Id: I5a0cc44ba62faf15d6fe3730a9532a3826647820\n'}, {'number': 4, 'created': '2014-09-01 22:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e1cab7af751037af2ac1cc8aec8ce48466dd4fc', 'message': 'ofagent: Ignore unknown l2pop entry removals\n\nl2pop can send us entry removal without the corresponding addition.\nGracefully ignore it instead of crashing.\n\nCloses-Bug: #1357198\nChange-Id: I5a0cc44ba62faf15d6fe3730a9532a3826647820\n'}, {'number': 5, 'created': '2014-09-02 05:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/004aa387f5d0a47e88eb540b1e14b0b565f9ba49', 'message': 'ofagent: Ignore unknown l2pop entry removals\n\nl2pop can send us entry removal without the corresponding addition.\nGracefully ignore it instead of crashing.\n\nCloses-Bug: #1357198\nChange-Id: I5a0cc44ba62faf15d6fe3730a9532a3826647820\n'}, {'number': 6, 'created': '2014-09-12 13:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3a211e67f858adc60697451929fe18be67dba46b', 'message': 'ofagent: Ignore unknown l2pop entry removals\n\nl2pop can send us entry removal without the corresponding addition.\nGracefully ignore it instead of crashing.\n\nCloses-Bug: #1357198\nChange-Id: I5a0cc44ba62faf15d6fe3730a9532a3826647820\n'}, {'number': 7, 'created': '2014-09-12 15:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/68dce72826c157309a4255912a1444e858077b00', 'message': 'ofagent: Ignore unknown l2pop entry removals\n\nl2pop can send us entry removal without the corresponding addition.\nGracefully ignore it instead of crashing.\n\nCloses-Bug: #1357198\nChange-Id: I5a0cc44ba62faf15d6fe3730a9532a3826647820\n'}, {'number': 8, 'created': '2014-09-16 06:46:07.000000000', 'files': ['neutron/plugins/ofagent/agent/arp_lib.py', 'neutron/tests/unit/ofagent/test_arp_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd5c73450da908d95724e20eb3be09bc936cb551', 'message': 'ofagent: Ignore unknown l2pop entry removals\n\nl2pop can send us entry removal without the corresponding addition.\nGracefully ignore it instead of crashing.\n\nCloses-Bug: #1357198\nChange-Id: I5a0cc44ba62faf15d6fe3730a9532a3826647820\n'}]",8,114443,dd5c73450da908d95724e20eb3be09bc936cb551,196,35,8,6854,,,0,"ofagent: Ignore unknown l2pop entry removals

l2pop can send us entry removal without the corresponding addition.
Gracefully ignore it instead of crashing.

Closes-Bug: #1357198
Change-Id: I5a0cc44ba62faf15d6fe3730a9532a3826647820
",git fetch https://review.opendev.org/openstack/neutron refs/changes/43/114443/8 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ofagent/agent/arp_lib.py', 'neutron/tests/unit/ofagent/test_arp_lib.py']",2,f349b0fbeb558b60a778d23555646d2077a998f8,bug/1357198,"import copy def test_del_arp_table_entry_unknown_network(self): self.arplib._arp_tbl = { ""foo"": {""bar"": ""baz""}, } orig = copy.deepcopy(self.arplib._arp_tbl) self.arplib.del_arp_table_entry(""hoge"", ""fuga"") self.assertEqual(orig, self.arplib._arp_tbl) def test_del_arp_table_entry_unknown_ip(self): self.arplib._arp_tbl = { ""foo"": {""bar"": ""baz""}, } orig = copy.deepcopy(self.arplib._arp_tbl) self.arplib.del_arp_table_entry(""foo"", ""fuga"") self.assertEqual(orig, self.arplib._arp_tbl) ",,23,1
openstack%2Fmonasca-api~master~I0bbcac412ffcaab36bdab32fbb8474bc407811f6,openstack/monasca-api,master,I0bbcac412ffcaab36bdab32fbb8474bc407811f6,Fix alarm expression documentation,MERGED,2014-10-20 16:38:05.000000000,2014-10-20 17:15:37.000000000,2014-10-20 17:15:37.000000000,"[{'_account_id': 3}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-10-20 16:38:05.000000000', 'files': ['docs/monasca-api-spec.md'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/0e1cae011bb11548419e31b81e2374570d17b74f', 'message': 'Fix alarm expression documentation\n\nChange-Id: I0bbcac412ffcaab36bdab32fbb8474bc407811f6\n'}]",0,129670,0e1cae011bb11548419e31b81e2374570d17b74f,6,2,1,12512,,,0,"Fix alarm expression documentation

Change-Id: I0bbcac412ffcaab36bdab32fbb8474bc407811f6
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/70/129670/1 && git format-patch -1 --stdout FETCH_HEAD,['docs/monasca-api-spec.md'],1,0e1cae011bb11548419e31b81e2374570d17b74f,, | subexpression logical_operator expression``` logical_operator : 'and' | '&&' | 'or' | '||' ```` , | expression logical_operator expression,9,1
openstack%2Fneutron~master~Icf079c42adeca14ef84ec57dc45a5930fde8786d,openstack/neutron,master,Icf079c42adeca14ef84ec57dc45a5930fde8786d,Compare subnet length as well when deleting DHCP entry,MERGED,2014-08-28 04:49:35.000000000,2014-10-20 17:13:08.000000000,2014-10-20 17:13:06.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 7249}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10624}, {'_account_id': 11279}, {'_account_id': 12040}, {'_account_id': 12737}, {'_account_id': 13263}]","[{'number': 1, 'created': '2014-08-28 04:49:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f43b1a229f03a79134987ccd953396a5cd08ee0', 'message': 'Compare subnet length as well when deleting DHCP entry\n\nWhen searching for the DHCP subnet entry to delete, the existing code\ncompares only the subnet prefix and ignores subnet length.  This could\ndelete the wrong entry/entries if nested subnets are present.\n\nChange-Id: Icf079c42adeca14ef84ec57dc45a5930fde8786d\nCloses-Bug: #1362416\n'}, {'number': 2, 'created': '2014-08-29 13:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/13806c17ed06c28f7a2409e366ea41d3368987b5', 'message': 'Compare subnet length as well when deleting DHCP entry\n\nWhen searching for the DHCP subnet entry to delete, the existing code\ncompares only the subnet prefix and ignores subnet length.  This could\ndelete the wrong entry/entries if nested subnets are present.\n\nChange-Id: Icf079c42adeca14ef84ec57dc45a5930fde8786d\nCloses-Bug: #1362416\n'}, {'number': 3, 'created': '2014-08-31 12:33:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c8cced01c211dd553447966ca5d60af516b9eae4', 'message': 'Compare subnet length as well when deleting DHCP entry\n\nWhen searching for the DHCP subnet entry to delete, the existing code\ncompares only the subnet prefix and ignores subnet length.  This could\ndelete the wrong entry/entries if nested subnets are present.\n\nChange-Id: Icf079c42adeca14ef84ec57dc45a5930fde8786d\nCloses-Bug: #1362416\n'}, {'number': 4, 'created': '2014-09-03 05:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/436df394bda4eca9eb73b771c848b424484448a6', 'message': 'Compare subnet length as well when deleting DHCP entry\n\nWhen searching for the DHCP subnet entry to delete, the existing code\ncompares only the subnet prefix and ignores subnet length.  This could\ndelete the wrong entry/entries if nested subnets are present.\n\nChange-Id: Icf079c42adeca14ef84ec57dc45a5930fde8786d\nCloses-Bug: #1362416\n'}, {'number': 5, 'created': '2014-09-08 01:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/45ef51f796cc12bba780adf0cd4f8a03822fb3aa', 'message': 'Compare subnet length as well when deleting DHCP entry\n\nWhen searching for the DHCP subnet entry to delete, the existing code\ncompares only the subnet prefix and ignores subnet length.  This could\ndelete the wrong entry/entries if nested subnets are present.\n\nChange-Id: Icf079c42adeca14ef84ec57dc45a5930fde8786d\nCloses-Bug: #1362416\n'}, {'number': 6, 'created': '2014-09-15 03:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f52878a76d97a946e6cca5bf1a0980a06cbd1d7e', 'message': 'Compare subnet length as well when deleting DHCP entry\n\nWhen searching for the DHCP subnet entry to delete, the existing code\ncompares only the subnet prefix and ignores subnet length.  This could\ndelete the wrong entry/entries if nested subnets are present.\n\nChange-Id: Icf079c42adeca14ef84ec57dc45a5930fde8786d\nCloses-Bug: #1362416\n'}, {'number': 7, 'created': '2014-10-03 05:14:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d41df2293da15667810c93dd598573d037a70f94', 'message': 'Compare subnet length as well when deleting DHCP entry\n\nWhen searching for the DHCP subnet entry to delete, the existing code\ncompares only the subnet prefix and ignores subnet length.  This could\ndelete the wrong entry/entries if nested subnets are present.\n\nChange-Id: Icf079c42adeca14ef84ec57dc45a5930fde8786d\nCloses-Bug: #1362416\n'}, {'number': 8, 'created': '2014-10-12 09:03:19.000000000', 'files': ['neutron/tests/unit/midonet/test_midonet_lib.py', 'neutron/plugins/midonet/midonet_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/648063881ebfbb54a362ef32d58263fc0f20981c', 'message': 'Compare subnet length as well when deleting DHCP entry\n\nWhen searching for the DHCP subnet entry to delete, the existing code\ncompares only the subnet prefix and ignores subnet length.  This could\ndelete the wrong entry/entries if nested subnets are present.\n\nChange-Id: Icf079c42adeca14ef84ec57dc45a5930fde8786d\nCloses-Bug: #1362416\n'}]",0,117415,648063881ebfbb54a362ef32d58263fc0f20981c,217,33,8,11279,,,0,"Compare subnet length as well when deleting DHCP entry

When searching for the DHCP subnet entry to delete, the existing code
compares only the subnet prefix and ignores subnet length.  This could
delete the wrong entry/entries if nested subnets are present.

Change-Id: Icf079c42adeca14ef84ec57dc45a5930fde8786d
Closes-Bug: #1362416
",git fetch https://review.opendev.org/openstack/neutron refs/changes/15/117415/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/midonet/midonet_lib.py', 'neutron/tests/unit/midonet/test_midonet_lib.py']",2,5f43b1a229f03a79134987ccd953396a5cd08ee0,remove-unused," subnet1 = mock.Mock() subnet1.get_subnet_prefix.return_value = ""10.0.0.0"" subnet1.get_subnet_length.return_value = ""16"" subnet2 = mock.Mock() subnet2.get_subnet_prefix.return_value = ""10.0.0.0"" subnet2.get_subnet_length.return_value = ""24"" subnets = mock.MagicMock(return_value=[subnet1, subnet2]) self.assertFalse(subnet1.delete.called) subnet2.delete.assert_called_once_with()"," subnet = mock.Mock() subnet.get_subnet_prefix.return_value = ""10.0.0.0"" subnets = mock.MagicMock(return_value=[subnet]) subnet.assert_has_calls([mock.call.get_subnet_prefix(), mock.call.delete()])",11,6
openstack%2Fneutron~master~Ife4298e0bb29ec15404fafe4b48545bd65e038e3,openstack/neutron,master,Ife4298e0bb29ec15404fafe4b48545bd65e038e3,Drop sslutils and versionutils modules,MERGED,2014-10-10 18:51:22.000000000,2014-10-20 17:09:17.000000000,2014-10-20 17:09:16.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5948}, {'_account_id': 6502}, {'_account_id': 6659}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-10 18:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a8e8adb6b1e3b40079562d7f92d8f313c6c5e077', 'message': ""Drop sslutils module\n\nThe module is not used since when we've switched to oslo.messaging.\n\nChange-Id: Ife4298e0bb29ec15404fafe4b48545bd65e038e3\n""}, {'number': 2, 'created': '2014-10-10 18:54:16.000000000', 'files': ['neutron/openstack/common/versionutils.py', 'neutron/openstack/common/sslutils.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/neutron/commit/652052860f0572ce1a3e8db56a58e08aca8d9195', 'message': ""Drop sslutils and versionutils modules\n\nThe modules are not used since when we've switched to oslo.messaging.\n\nChange-Id: Ife4298e0bb29ec15404fafe4b48545bd65e038e3\n""}]",0,127626,652052860f0572ce1a3e8db56a58e08aca8d9195,45,25,2,9656,,,0,"Drop sslutils and versionutils modules

The modules are not used since when we've switched to oslo.messaging.

Change-Id: Ife4298e0bb29ec15404fafe4b48545bd65e038e3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/26/127626/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/openstack/common/sslutils.py', 'openstack-common.conf']",2,a8e8adb6b1e3b40079562d7f92d8f313c6c5e077,sslutils,,module=sslutils,0,99
openstack%2Fneutron~master~I617e9fedf8a8c5e95c6067b716c83778d4d8cc7e,openstack/neutron,master,I617e9fedf8a8c5e95c6067b716c83778d4d8cc7e,ofagent: Drop log level of tenant-triggerable events,MERGED,2014-09-21 22:49:32.000000000,2014-10-20 17:04:46.000000000,2014-10-20 17:04:45.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 333}, {'_account_id': 2031}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 6854}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12040}, {'_account_id': 12444}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-09-21 22:49:32.000000000', 'files': ['neutron/plugins/ofagent/agent/arp_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d1f1722e0edb63c73b60c80abafa63749349cd8e', 'message': 'ofagent: Drop log level of tenant-triggerable events\n\nTo prevent evil tenants from flooding logs.\n\nCloses-Bug: #1372196\nChange-Id: I617e9fedf8a8c5e95c6067b716c83778d4d8cc7e\n'}]",0,123022,d1f1722e0edb63c73b60c80abafa63749349cd8e,46,26,1,6854,,,0,"ofagent: Drop log level of tenant-triggerable events

To prevent evil tenants from flooding logs.

Closes-Bug: #1372196
Change-Id: I617e9fedf8a8c5e95c6067b716c83778d4d8cc7e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/22/123022/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ofagent/agent/arp_lib.py'],1,d1f1722e0edb63c73b60c80abafa63749349cd8e,bug/1365255," LOG.debug(""Unparsable packet: got exception %s"", e) LOG.debug(""packet-in dpid %(dpid)s in_port %(port)s pkt %(pkt)s"", {'dpid': dpid_lib.dpid_to_str(datapath.id), 'port': port, 'pkt': pkt}) LOG.debug(""drop non-ethernet packet"") LOG.debug(""drop non-arp packet"")"," LOG.info(_LI(""Unparsable packet: got exception %s""), e) LOG.info(_LI(""packet-in dpid %(dpid)s in_port %(port)s pkt %(pkt)s""), {'dpid': dpid_lib.dpid_to_str(datapath.id), 'port': port, 'pkt': pkt}) LOG.info(_LI(""drop non-ethernet packet"")) LOG.info(_LI(""drop non-arp packet""))",6,6
openstack%2Fironic-specs~master~Ic062d265dce75e284c47ad90d2adb4cdca6134f0,openstack/ironic-specs,master,Ic062d265dce75e284c47ad90d2adb4cdca6134f0,Delete the placeholder file: example.rst,MERGED,2014-10-20 16:33:28.000000000,2014-10-20 16:59:19.000000000,2014-10-20 16:59:19.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 10342}]","[{'number': 1, 'created': '2014-10-20 16:33:28.000000000', 'files': ['specs/kilo/example.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/eca9014902218d45e0e1ad93a000ce50d05920be', 'message': 'Delete the placeholder file: example.rst\n\nexample.rst was a placeholder, because we needed specs/kilo to\nexist for people submitting specs. Now that we have an approved spec,\nthe kilo directory exists.\n\nSee https://review.openstack.org/127047 for more information as to\nwhy example.rst was there in the first place.\n\nChange-Id: Ic062d265dce75e284c47ad90d2adb4cdca6134f0\n'}]",0,129665,eca9014902218d45e0e1ad93a000ce50d05920be,8,4,1,6618,,,0,"Delete the placeholder file: example.rst

example.rst was a placeholder, because we needed specs/kilo to
exist for people submitting specs. Now that we have an approved spec,
the kilo directory exists.

See https://review.openstack.org/127047 for more information as to
why example.rst was there in the first place.

Change-Id: Ic062d265dce75e284c47ad90d2adb4cdca6134f0
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/65/129665/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/example.rst'],1,eca9014902218d45e0e1ad93a000ce50d05920be,remove-example,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Example Spec - The title of your blueprint ========================================== NOTE(rloo). This is a temporary file, as a placeholder so that we can get the specs/kilo directory to work. Remove this after we have a real spec approved. Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/ironic/+spec/example Introduction paragraph -- start here. Why are we doing anything? This should be a single paragraph of prose that operators can understand. Some notes about using this template: * Your spec should be in ReSTructured text, like this template. * Please wrap text at 79 columns. * The filename in the git repository should match the launchpad URL, for example a URL of: https://blueprints.launchpad.net/ironic/+spec/awesome-thing should be named awesome-thing.rst * Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None * For help with syntax, see http://sphinx-doc.org/rest.html * To test out your formatting, build the docs using tox, or see: http://rst.ninjs.org * If you would like to provide a diagram with your spec, ascii diagrams are required. http://asciiflow.com/ is a very nice tool to assist with making ascii diagrams. The reason for this is that the tool used to review specs is based purely on plain text. Plain text will allow review to proceed without having to look at additional files which can not be viewed in gerrit. It will also allow inline feedback on the diagram itself. Problem description =================== A detailed description of the problem: * For a new feature this might be use cases. Ensure you are clear about the actors in each use case: End User, Admin User, Deployer, or another Service * For a major reworking of something existing it would describe the problems in that feature that are being addressed. Proposed change =============== Here is where you cover the change you propose to make in detail. How do you propose to solve this problem? If this is one part of a larger effort make it clear where this piece ends. In other words, what is the scope of this effort? If you are unsure whether this proposal is aligned with the project's mission and scope, stop here and get feedback from the ironic-drivers and ironic-core teams before fleshing out all the details below. Alternatives ------------ What other ways could we do this thing? Has someone else done this thing in another project? In another language? Why aren't we using those? This doesn't have to be a full literature review, but it should demonstrate that thought has been put into why the proposed solution is an appropriate one. Data model impact ----------------- Changes which require modifications to the data model often have a wider impact on the system. The community often has strong opinions on how the data model should be evolved, from both a functional and performance perspective. It is therefore important to capture and gain agreement as early as possible on any proposed changes to the data model. Questions which need to be addressed by this section include: * What new data objects and/or database schema changes is this going to require? * What database migrations will accompany this change? * How will the initial set of new data objects be generated? For example, if you need to take into account existing instances, or modify other existing data, describe how that will work. REST API impact --------------- Each API method which is either added or changed should have the following * Specification for the method * A description of what the method does, suitable for use in user documentation. * Method type (POST/PUT/GET/DELETE/PATCH) * Normal http response code(s) * Expected error http response code(s) * A description for each possible error code should be included. Describe semantic errors which can cause it, such as inconsistent parameters supplied to the method, or when a resource is not in an appropriate state for the request to succeed. Errors caused by syntactic problems covered by the JSON schema defintion do not need to be included. * URL for the resource * Parameters which can be passed via the url, including data types * JSON schema definition for the body data if allowed * JSON schema definition for the response data if any * Example use case including typical API samples for both data supplied by the caller and the response * Discuss any policy changes, and discuss what things a deployer needs to think about when defining their policy. * Is a corresponding change in the client library and CLI necessary? * Is this change discoverable by clients? Not all clients will upgrade at the same time, so this change must work with older clients without breaking them. Note that the schema should be defined as restrictively as possible. Parameters which are required should be marked as such and only under exceptional circumstances should additional parameters which are not defined in the schema be permitted. Use of free-form JSON dicts should only be permitted where necessary to allow divergence in the drivers. In such case, the drivers must expose the expected content of the JSON dict and an ability to validate it. Reuse of existing predefined parameter types is highly encouraged. RPC API impact -------------- Changes which affect the RPC API should be listed here. For example: * What are the changes, if any, to existing API calls? * What new API calls are being added? Will these be using cast() or call()? * ironic-api and ironic-conductor services must be upgradable independently. What is the upgrade process for rolling this change out to an existing deployment? Driver API impact ----------------- Changes which affect the driver API have a direct effect on all drivers, and often have a wider impact on the system. There are several things to consider in this section. * Is it a change to a ""core"" or ""common"" API? * Can all drivers support it initially, or is it specific to a particular vendor's hardware? * How will it be tested in the gate and in third-party CI systems? * If adding a new interface, explain the intended scope of the proposed interface, what functionality it enables, why it is needed, and whether it is supported by current drivers. * If adding or changing a method on an existing interface, the impact on existing drivers should be explored. * Will the new interface or method need to be invoked when the hash ring rebalances, for example to rebuild local state on a new conductor service? * How does this affect upgrades? Third-party drivers could be updated independently from this change, and care must be taken not to break backwards-compatibility within our Driver API. Nova driver impact ------------------ Chances are, if this change affects the REST or Driver APIs, it will also affect the Nova driver in some way. If this requires a functional change in Nova, chances are the Nova team will require a spec to discuss the changes to their project as well. Provide a link to that here, or a justification for why that is not needed. Questions which need to be addressed in this section include: * What is the impact on Nova? * If this change is enabling new functionality exposed via Nova, this section should cite the relevant components within other Nova drivers that alraedy implement this. * Ironic and Nova services must be upgradable independently. If the change affects existing functionality of the nova.virt.ironic driver, how will an upgrade be performed? How will it be tested? Security impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or credentials? * Does this change affect the accessibility of hardware managed by Ironic? * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? * Does this change involve cryptography or hashing? * Does this change require the use of sudo or any elevated privileges? * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. For more detailed guidance, please see the OpenStack Security Guidelines as a reference (https://wiki.openstack.org/wiki/Security/Guidelines). These guidelines are a work in progress and are designed to help you identify security best practices. For further information, feel free to reach out to the OpenStack Security Group at openstack-security@lists.openstack.org. Other end user impact --------------------- Aside from the API, are there other ways a user will interact with this feature? * Does this change have an impact on python-ironicclient? What does the user interface there look like? * Will this require changes in the Horizon panel, or any other OpenStack project? Scalability impact ------------------ Describe any potential scalability impact on the system, for example any increase in network, RPC, or database traffic, or whether the feature requires synchronization across multiple services. Examples of things to consider here include: * Additional network calls to internal or external services. * Additional disk or network traffic that will be required by the feature. * Any change in the number of physical nodes which can be managed by each conductor service. Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A periodic task might look like a small addition, but all periodic tasks run in a single thread so a periodic task that takes a long time to run will have an effect on the timing of other periodic tasks. * A small change in a utility function or a commonly used decorator can have a large impact on performance. * Calls which result in one or more database queries (whether in the api or conductor services) can have a profound impact on performance when called in critical sections of the code. * Will the change include any TaskManager locking, and if so what considerations are there on holding the lock? * How will the new code be affected if the hash ring rebalances while it is running? Other deployer impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example, a flag that other hardware drivers might want to implement as well)? Are the default values appropriate for production? Provide an explanation of why these defaults are reasonable. * Is this a change that takes immediate effect after it's merged, or is it something that has to be explicitly enabled? * If this change adds a new service that deployers will be requried to run, how would it be deployed? Describe the expected topology, for example, what network connectivity the new service would need, what service(s) it would interact with, how many should run relative to the size of the deployment, and so on. * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we were to change the directory that PXE boot files were stored in, how would we update existing boot files created before the change landed? Would we require deployers to manually move them? Is there a special case in the code, which would be removed after some deprecation period? Would we require operators to delete and recreate all instances in order to perform the upgrade? Developer impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the driver API, discussion of how other drivers would implement the feature is required. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Include specific references to specs and/or blueprints in Ironic, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Ironic, document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? * Does this feature target specific hardware? If so, is it a common standard (eg IPMI) or a vendor-specific implementation (eg iLO)? Testing ======= Please discuss how the change will be tested. We especially want to know what tempest tests will be added. It is assumed that unit test coverage will be added so that doesn't need to be mentioned explicitly, but discussion of why you think unit tests are sufficient and we don't need to add more tempest tests would need to be included. Is this untestable in gate given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc)? Upgrades and Backwards Compatibility ==================================== Care must be taken to support our users by not breaking backwards compatibility with either REST API or Driver API changes. * If your proposal includes any changes to the REST API, describe how existing clients will continue to function when interacting with an upgraded API server. * If your proposal includes any changes to the Driver API, describe how existing driver implementations will continue to function when loaded by a conductor running with the new driver base class. * Describe what testing you will be adding to ensure that backwards compatibility is maintained. * If deprecating an existing feature or API, describe the deprecation plan, and for how long compatibility will be maintained. Documentation Impact ==================== What is the impact on the docs team of this change? Some changes might require donating resources to the docs team to have the documentation updated. Don't repeat details discussed above, but please reference them here. References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) * Anything else you feel it is worthwhile to refer to ",0,442
openstack%2Fdiskimage-builder~master~I22349b909c6d74cd57ff8073183309ffa024b777,openstack/diskimage-builder,master,I22349b909c6d74cd57ff8073183309ffa024b777,Install all binaries located in bin,ABANDONED,2014-10-08 09:29:49.000000000,2014-10-20 16:58:52.000000000,,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-10-08 09:29:49.000000000', 'files': ['bin/disk-image-create', 'elements/dpkg/pre-install.d/01-dpkg-install-bin', 'elements/opensuse/pre-install.d/01-opensuse-install-bin', 'elements/base/bin/dib-init-system', 'elements/base/bin/dib-first-boot', 'elements/base/pre-install.d/04-dib-init-system', 'elements/rpm-distro/pre-install.d/01-rpm-distro-install-bin'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/44622f5062210e0b52aa16c83d4b646d28e0fbcd', 'message': 'Install all binaries located in bin\n\nUntil now, there were some elements which installed everything\nlocated in the bin directory, which other elements depended on.\nTake this logic out of those elements and made it a general rule.\n\nChange-Id: I22349b909c6d74cd57ff8073183309ffa024b777\nCloses-Bug: 1378710\n'}]",0,126848,44622f5062210e0b52aa16c83d4b646d28e0fbcd,6,3,1,1726,,,0,"Install all binaries located in bin

Until now, there were some elements which installed everything
located in the bin directory, which other elements depended on.
Take this logic out of those elements and made it a general rule.

Change-Id: I22349b909c6d74cd57ff8073183309ffa024b777
Closes-Bug: 1378710
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/48/126848/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/disk-image-create', 'elements/dpkg/pre-install.d/01-dpkg-install-bin', 'elements/opensuse/pre-install.d/01-opensuse-install-bin', 'elements/base/bin/dib-init-system', 'elements/base/bin/dib-first-boot', 'elements/base/pre-install.d/04-dib-init-system', 'elements/rpm-distro/pre-install.d/01-rpm-distro-install-bin']",7,44622f5062210e0b52aa16c83d4b646d28e0fbcd,bug/1378710,,#!/bin/bash set -eu set -o pipefail install -m 0755 -o root -g root $(dirname $0)/../bin/* /usr/local/bin ,2,24
openstack%2Fkeystone-specs~master~I58e1efc0d1d9e4197d96b5e36828e23f74bb906b,openstack/keystone-specs,master,I58e1efc0d1d9e4197d96b5e36828e23f74bb906b,Enable tests on non-SQLite databases,MERGED,2014-10-06 17:40:14.000000000,2014-10-20 16:42:00.000000000,2014-10-20 16:41:59.000000000,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-10-06 17:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/ba973525a217954cb2f4587bde63e14f115d558b', 'message': 'Enable tests on non-SQLite database\n\nChange-Id: I58e1efc0d1d9e4197d96b5e36828e23f74bb906b\nImplements: bp tests-on-rdbmses\n'}, {'number': 2, 'created': '2014-10-06 17:47:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/1daeeb17e7b85b8d7a2506eb63bfbf261a9b5e27', 'message': 'Enable tests on non-SQLite database\n\nChange-Id: I58e1efc0d1d9e4197d96b5e36828e23f74bb906b\nImplements: bp tests-on-rdbmses\n'}, {'number': 3, 'created': '2014-10-06 18:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/f48a0808e81b9435cfcac2df9b53cc488a651b80', 'message': 'Enable tests on non-SQLite databases\n\nChange-Id: I58e1efc0d1d9e4197d96b5e36828e23f74bb906b\nImplements: bp tests-on-rdbmses\n'}, {'number': 4, 'created': '2014-10-06 18:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/aa3c4d142cfb231c1d9ad2ef65639b966b5da34e', 'message': 'Enable tests on non-SQLite databases\n\nChange-Id: I58e1efc0d1d9e4197d96b5e36828e23f74bb906b\nImplements: bp tests-on-rdbmses\n'}, {'number': 5, 'created': '2014-10-13 17:02:53.000000000', 'files': ['specs/kilo/tests-on-rdbmses.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/9f6edf49333cf75f97be87da157926b7b6a49198', 'message': 'Enable tests on non-SQLite databases\n\nChange-Id: I58e1efc0d1d9e4197d96b5e36828e23f74bb906b\nImplements: bp tests-on-rdbmses\n'}]",11,126370,9f6edf49333cf75f97be87da157926b7b6a49198,21,7,5,7725,,,0,"Enable tests on non-SQLite databases

Change-Id: I58e1efc0d1d9e4197d96b5e36828e23f74bb906b
Implements: bp tests-on-rdbmses
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/70/126370/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/tests-on-rdbmses.rst'],1,ba973525a217954cb2f4587bde63e14f115d558b,bp/tests-on-rdbmses,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================== Fix Tests To Run On non-SQLite Databases ======================================== `bp tests-on-rdbmses <https://blueprints.launchpad.net/keystone/ +spec/tests-on-rdbmses` Problem Description =================== Keystone tests currently will only run on SQLite. There are many reasons to run the tests on other database:: * by default SQLite doesn't enforce foreign keys * most implements will use another database like MySQL or PostgreSQL * every few months somebody asks how to make it work Proposed Change =============== 1. Fix the tests to respect foreign keys. We currently have tests that can't work in a database where foreign keys are enforced. 2. Fix any other bugs that pop up when running on another database. This maybe very big or very small. It's hard to tell without actually starting. 3. Make SQLite enforce foreign keys to prevent bugs from slipping by developers that don't run tests against a non-SQLite database. Alternatives ------------ There are really no alternatives as this primarily just fixes the broken tests. At the patch level there may be alternative implementations possible, but that is out of the scope of this proposal. Security Impact --------------- None. This is just about changing the way that tests are written and executed. Notifications Impact -------------------- None. This is just about changing the way that tests are written and executed. Other End User Impact --------------------- None. This is just about changing the way that tests are written and executed. Performance Impact ------------------ None. This is just about changing the way that tests are written and executed. Other Deployer Impact --------------------- None. This is just about changing the way that tests are written and executed. Developer Impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the driver API, discussion of how other backends would implement the feature is required. Implementation ============== Assignee(s) ----------- Primary assignee: dstanek Work Items ---------- TBD Dependencies ============ None. Documentation Impact ==================== None. This is just about changing the way that tests are written and executed. References ========== None. ",,107,0
openstack%2Ftripleo-image-elements~master~I55c7dbd0aefbb075a0a0d84b5e0ec057834bde19,openstack/tripleo-image-elements,master,I55c7dbd0aefbb075a0a0d84b5e0ec057834bde19,Migrate geard to svc-map,MERGED,2014-10-16 22:00:10.000000000,2014-10-20 16:35:17.000000000,2014-10-20 16:35:17.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4330}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-10-16 22:00:10.000000000', 'files': ['elements/geard/svc-map', 'elements/geard/install.d/44-geard'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/66c8f79dbb316a40b843facb37533394cb72fea0', 'message': 'Migrate geard to svc-map\n\nThis patch migrates the geard element from map-services to svc-map\nby adding the -a option to appropriate os-svc-* calls and adding\na svc-map file.\n\nChange-Id: I55c7dbd0aefbb075a0a0d84b5e0ec057834bde19\n'}]",0,129073,66c8f79dbb316a40b843facb37533394cb72fea0,11,4,1,8532,,,0,"Migrate geard to svc-map

This patch migrates the geard element from map-services to svc-map
by adding the -a option to appropriate os-svc-* calls and adding
a svc-map file.

Change-Id: I55c7dbd0aefbb075a0a0d84b5e0ec057834bde19
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/73/129073/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/geard/svc-map', 'elements/geard/install.d/44-geard']",2,66c8f79dbb316a40b843facb37533394cb72fea0,migrate-geard-svc-map,os-svc-daemon -an geard -u gear -c geard -- -d os-svc-enable -an geard,os-svc-daemon -n geard -u gear -c geard -- -d os-svc-enable -n geard,5,2
openstack%2Ftripleo-image-elements~master~I6859e4309cc73127ac389de70c829ac59afcfd91,openstack/tripleo-image-elements,master,I6859e4309cc73127ac389de70c829ac59afcfd91,Add missing packages to tempest element,MERGED,2014-10-08 22:34:03.000000000,2014-10-20 16:33:00.000000000,2014-10-20 16:32:58.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4220}, {'_account_id': 8532}, {'_account_id': 9453}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-10-08 22:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/668306dac6c6330a599a0fef24dc3251e609f28e', 'message': 'Add missing packages to tempest element\n\nAttempts to use this element failed due to missing the\nfollowing packages:\nlibssl-dev libffi-dev\n\nAdding these packages to the element fixes any issues encountered.\n\nChange-Id: I6859e4309cc73127ac389de70c829ac59afcfd91\nCloses-Bug: #1379047\n'}, {'number': 2, 'created': '2014-10-14 19:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/147862bcb82b39a288137a0ab8a0741d6aab365c', 'message': 'Add missing packages to tempest element\n\nAttempts to use this element failed due to missing the\nfollowing packages:\nlibssl-dev libffi-dev\n\nThis patch adds the packages to the element, including\npkg-map installs and map files.\n\nChange-Id: I6859e4309cc73127ac389de70c829ac59afcfd91\nCloses-Bug: #1379047\n'}, {'number': 3, 'created': '2014-10-17 18:14:09.000000000', 'files': ['elements/tempest/element-deps', 'elements/tempest/pkg-map', 'elements/tempest/install.d/51-tempest'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8e0b828fc2cf27ee2fc8714062158a50fbba5089', 'message': 'Add missing packages to tempest element\n\nAttempts to use this element failed due to missing the\nfollowing packages:\nlibssl-dev libffi-dev\n\nThis patch adds the packages to the element, including\npkg-map installs and map files.\n\nAlso changing shell called in init.d/51-tempest to be /bin/bash.\n\nChange-Id: I6859e4309cc73127ac389de70c829ac59afcfd91\nCloses-Bug: #1379047\n'}]",2,127055,8e0b828fc2cf27ee2fc8714062158a50fbba5089,20,6,3,4220,,,0,"Add missing packages to tempest element

Attempts to use this element failed due to missing the
following packages:
libssl-dev libffi-dev

This patch adds the packages to the element, including
pkg-map installs and map files.

Also changing shell called in init.d/51-tempest to be /bin/bash.

Change-Id: I6859e4309cc73127ac389de70c829ac59afcfd91
Closes-Bug: #1379047
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/55/127055/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/tempest/install.d/51-tempest'],1,668306dac6c6330a599a0fef24dc3251e609f28e,bug/1379047,install-packages augeas-tools libffi-dev libssl-dev,install-packages augeas-tools,1,1
openstack%2Fironic-specs~master~I784573bcb07f9ea77338492f54303c54842fb032,openstack/ironic-specs,master,I784573bcb07f9ea77338492f54303c54842fb032,Add maintenance reason field,MERGED,2014-10-20 14:13:58.000000000,2014-10-20 16:32:22.000000000,2014-10-20 16:25:30.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 10342}]","[{'number': 1, 'created': '2014-10-20 14:13:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/6fc248d2bf3f46a19539941359cd603051868c0e', 'message': 'Add maintenance reason field\n\nThis spec adds a `maintenance_reason` field and some associated\nthings for managing it.\n\nChange-Id: I784573bcb07f9ea77338492f54303c54842fb032\n'}, {'number': 2, 'created': '2014-10-20 15:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/388bca38812a53b85078a0dba8a3218601a3727e', 'message': 'Add maintenance reason field\n\nThis spec adds a `maintenance_reason` field and some associated\nthings for managing it.\n\nChange-Id: I784573bcb07f9ea77338492f54303c54842fb032\n'}, {'number': 3, 'created': '2014-10-20 15:44:06.000000000', 'files': ['specs/kilo/maintenance-reason.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/2158f51d5a3de65091a64013eeebfa9832112f69', 'message': 'Add maintenance reason field\n\nThis spec adds a `maintenance_reason` field and some associated\nthings for managing it.\n\nChange-Id: I784573bcb07f9ea77338492f54303c54842fb032\n'}]",9,129629,2158f51d5a3de65091a64013eeebfa9832112f69,18,6,3,10343,,,0,"Add maintenance reason field

This spec adds a `maintenance_reason` field and some associated
things for managing it.

Change-Id: I784573bcb07f9ea77338492f54303c54842fb032
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/29/129629/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/maintenance-reason.rst'],1,6fc248d2bf3f46a19539941359cd603051868c0e,bp/maintenance-reason,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================ Add maintenance reason field ============================ https://blueprints.launchpad.net/ironic/+spec/maintenance-reason When a node is put into maintenance (manually or automatically), Ironic and the operator should know why. Problem description =================== Ironic has the ability to mark a node in ""maintenance"" mode, to be ignored for the purposes of scheduling and verifying state. However: * When Ironic automatically puts a node into maintenance mode, it sets the reason in the `last_error` field, which may get overwritten by other tasks later. * When an operator manually puts a node into maintenance mode, they have no method to show why it was put into maintenance, for other operators or to remind themselves later. Proposed change =============== The following should be enough to solve this problem: * A `maintenance_reason` field should be added to the nodes table, as the canonical place to store the reason the node was put into maintenance mode. * A new API endpoint should be added to more easily manage maintenance mode. This endpoint can toggle maintenance mode on or off, with an optional reason for 'on', and clearing the reason when toggled 'off'. Alternatives ------------ Alternatively, operators could store this in another system, such as a CMDB. While I think this would be fine, this would not allow for Ironic to automatically set a maintenance reason when putting a node into maintenance mode. Work would need to be done to make Ironic notify the operator or integrate with the other system; and possibly cause the operator to do manual work to put the reason in the other system. Data model impact ----------------- This will add a `maintenance_reason` field to the `node` table, with an accompanying database migration. This field will default to NULL, which will also be the value when the node is not in maintenance mode, or there is no reason. REST API impact --------------- One new endpoint will be added, with two methods: * PUT /v1/nodes/<uuid>/maintenance * Puts a node into maintenance mode, with an optional reason. * Method type: PUT * Normal response code: 202 * Expected errors: * 404 if the node with <uuid> does not exist. * 400 if a conductor for the node's driver cannot be found. * URL: /v1/nodes/<uuid>/maintenance * URL parameters: None. * JSON body: {""reason"": ""Some reason.""}, or {} or empty for no reason. * Response body is empty if successful. * DELETE /v1/nodes/<uuid>/maintenance * Takes a node out of maintenance mode and clears the reason. * Method type: DELETE * Normal response code: 202 * Expected errors: * 404 if the node with <uuid> does not exist. * 400 if a conductor for the node's driver cannot be found. * URL: /v1/nodes/<uuid>/maintenance * URL parameters: None. * JSON body: None. * Response body is empty if successful. The `maintenance_reason` field should be added to the node details API. RPC API impact -------------- None. Driver API impact ----------------- None. Nova driver impact ------------------ None. Security impact --------------- None. Other end user impact --------------------- Support for this will be added in python-ironicclient. The CLI will look like: * `ironic node-set-maintenance-mode on ""Some reason.""` * `ironic node-set-maintenance-mode off` Scalability impact ------------------ None. Performance Impact ------------------ None. Other deployer impact --------------------- Deployers may wish to start using this feature when it is deployed; however there should be no impact otherwise. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: jroll Other contributors: lucasagomes Work Items ---------- * Add `maintenance_reason` to the nodes table with a migration. * Set `maintenance_reason` when automatically setting maintenance mode. * Add the new API endpoints. * Add client support for the new API endpoints. * Add Tempest tests for the new API endpoints. Dependencies ============ None. Testing ======= Tempest tests should be added for the new API endpoints. Upgrades and Backwards Compatibility ==================================== This change will be backwards compatible with existing clients, as they may still use the node.update call to set maintenance on or off. Documentation Impact ==================== The new API endpoints and client methods should be documented. References ========== None. ",,219,0
openstack%2Fopenstack-manuals~master~Ib222dc1a1919e3e3f55e694426d25fbefb9e3cbe,openstack/openstack-manuals,master,Ib222dc1a1919e3e3f55e694426d25fbefb9e3cbe,Add workaround for Ubuntu Cloud archive,MERGED,2014-10-20 15:09:45.000000000,2014-10-20 16:28:57.000000000,2014-10-20 16:28:57.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 3114}, {'_account_id': 6843}, {'_account_id': 9515}, {'_account_id': 12402}]","[{'number': 1, 'created': '2014-10-20 15:09:45.000000000', 'files': ['doc/install-guide/section_basics-packages.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9a50e10b3737368776f72ccd3788d30862b85cc6', 'message': ""Add workaround for Ubuntu Cloud archive\n\nI added a workaround for the Ubuntu Cloud archive repository\nbecause the 'add-apt-repository' method does not contain\ninformation about Juno packages.\n\nChange-Id: Ib222dc1a1919e3e3f55e694426d25fbefb9e3cbe\nCloses-Bug: #1362521\n""}]",0,129642,9a50e10b3737368776f72ccd3788d30862b85cc6,10,6,1,9515,,,0,"Add workaround for Ubuntu Cloud archive

I added a workaround for the Ubuntu Cloud archive repository
because the 'add-apt-repository' method does not contain
information about Juno packages.

Change-Id: Ib222dc1a1919e3e3f55e694426d25fbefb9e3cbe
Closes-Bug: #1362521
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/42/129642/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_basics-packages.xml'],1,9a50e10b3737368776f72ccd3788d30862b85cc6,bug/1362521," <procedure os=""ubuntu""> <title>To enable the OpenStack repository</title> <step> <para>Create and edit the <filename>/etc/apt/sources.list.d/ubuntu-cloud-archive-juno-trusty.list</filename> file and add the following to it:</para> <programlisting language=""ini"">deb http://ubuntu-cloud.archive.canonical.com/ubuntu trusty-updates/juno main</programlisting> </step> <step> <para>Install the Ubuntu Cloud archive repository keyring:</para> <screen><prompt>#</prompt> <userinput>apt-get install ubuntu-cloud-keyring</userinput></screen> </step> </procedure>"," <procedure os=""ubuntu""> <title>To enable the OpenStack repository</title> <step> <para>Enable the Ubuntu Cloud archive repository:</para> <screen><prompt>#</prompt> <userinput>add-apt-repository cloud-archive:juno</userinput></screen> </step> </procedure>",13,7
openstack%2Fmanila~master~I12aa1c725aa4bb52a9aa46e9c3d2b303839de48b,openstack/manila,master,I12aa1c725aa4bb52a9aa46e9c3d2b303839de48b,Use oslo.i18n,MERGED,2014-10-16 19:38:59.000000000,2014-10-20 16:18:53.000000000,2014-10-20 16:18:52.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6547}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-10-16 19:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b6ec478e7743b1bd32bb9f8ff6daf664a53a54e5', 'message': ""Use oslo.i18n\n\noslo.i18n provides the i18n function that were provided by\noslo-incubator's gettextutils module\n\nImport _ where needed, oslo.i18n deprecated the builtin method.\n\nCloses-Bug: #1382187\nChange-Id: I12aa1c725aa4bb52a9aa46e9c3d2b303839de48b\n""}, {'number': 2, 'created': '2014-10-17 06:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2a593baea34c25059581f3cf146964dea80c9a7e', 'message': ""Use oslo.i18n\n\noslo.i18n provides the i18n function that were provided by\noslo-incubator's gettextutils module\n\nImport _ where needed, oslo.i18n deprecated the builtin method.\n\nCloses-Bug: #1382187\nChange-Id: I12aa1c725aa4bb52a9aa46e9c3d2b303839de48b\n""}, {'number': 3, 'created': '2014-10-17 18:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/d2e4b27fe87c4007ebe7c7bccb0a60067572a727', 'message': ""Use oslo.i18n\n\noslo.i18n provides the i18n function that were provided by\noslo-incubator's gettextutils module\n\nImport _ where needed, oslo.i18n deprecated the builtin method.\n\nUse six.text_type instead of str for exceptions to allow lazy\ntranslations with oslo.i18n.\n\nCloses-Bug: #1382187\nChange-Id: I12aa1c725aa4bb52a9aa46e9c3d2b303839de48b\n""}, {'number': 4, 'created': '2014-10-17 18:54:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/cdf96fc3ed43b1f946ac789cabe2e1c596320405', 'message': ""Use oslo.i18n\n\noslo.i18n provides the i18n function that were provided by\noslo-incubator's gettextutils module\n\nImport _ where needed, oslo.i18n deprecated the builtin method.\n\nUse six.text_type instead of str for exceptions to allow lazy\ntranslations with oslo.i18n.\n\nCloses-Bug: #1382187\nChange-Id: I12aa1c725aa4bb52a9aa46e9c3d2b303839de48b\n""}, {'number': 5, 'created': '2014-10-18 18:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/da4fd5ec553164f4e477fe415bcfe3be7cefb6f7', 'message': ""Use oslo.i18n\n\noslo.i18n provides the i18n function that were provided by\noslo-incubator's gettextutils module\n\nImport _ where needed, oslo.i18n deprecated the builtin method.\n\nCloses-Bug: #1382187\nChange-Id: I12aa1c725aa4bb52a9aa46e9c3d2b303839de48b\n""}, {'number': 6, 'created': '2014-10-19 17:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f716dc4bab69366673d42d208f7c9b9969495802', 'message': ""Use oslo.i18n\n\noslo.i18n provides the i18n function that were provided by\noslo-incubator's gettextutils module\n\nImport _ where needed, oslo.i18n deprecated the builtin method.\n\nCloses-Bug: #1382187\nChange-Id: I12aa1c725aa4bb52a9aa46e9c3d2b303839de48b\n""}, {'number': 7, 'created': '2014-10-19 17:08:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/fb753ad7aca2f0aae5d12c379b42f8a4540d8d1f', 'message': ""Use oslo.i18n\n\noslo.i18n provides the i18n function that were provided by\noslo-incubator's gettextutils module\n\nImport _ where needed, oslo.i18n deprecated the builtin method.\n\nCloses-Bug: #1382187\nChange-Id: I12aa1c725aa4bb52a9aa46e9c3d2b303839de48b\n""}, {'number': 8, 'created': '2014-10-19 17:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0eb0d752ca62d1a9d0839f7a90e0b4379544e874', 'message': ""Use oslo.i18n\n\noslo.i18n provides the i18n function that were provided by\noslo-incubator's gettextutils module\n\nImport _ where needed, oslo.i18n deprecated the builtin method.\n\nCloses-Bug: #1382187\nChange-Id: I12aa1c725aa4bb52a9aa46e9c3d2b303839de48b\n""}, {'number': 9, 'created': '2014-10-19 17:21:53.000000000', 'files': ['manila/api/openstack/__init__.py', 'manila/api/openstack/volume/__init__.py', 'manila/i18n.py', 'manila/network/neutron/api.py', 'manila/scheduler/scheduler_options.py', 'manila/api/v1/security_service.py', 'manila/api/openstack/wsgi.py', 'manila/share/drivers/service_instance.py', 'manila/api/sizelimit.py', 'manila/scheduler/filters/capacity_filter.py', 'manila/share/drivers/netapp/api.py', 'openstack-common.conf', 'manila/share/drivers/emc/plugins/vnx/connection.py', 'manila/scheduler/chance.py', 'manila/utils.py', 'manila/api/contrib/types_extra_specs.py', 'manila/api/common.py', 'manila/api/contrib/share_actions.py', 'manila/api/v1/limits.py', 'manila/api/v1/share_servers.py', 'manila/api/v1/share_networks.py', 'manila/api/auth.py', 'manila/context.py', 'manila/network/linux/ip_lib.py', 'manila/share/drivers/netapp/cluster_mode.py', 'manila/api/middleware/fault.py', 'manila/api/v1/share_metadata.py', 'manila/wsgi.py', 'manila/api/middleware/sizelimit.py', 'manila/share/drivers/generic.py', 'manila/tests/db/migrations/alembic/test_migration.py', 'tox.ini', 'manila/api/openstack/urlmap.py', 'manila/share/drivers/glusterfs_native.py', 'manila/api/v1/volume_types.py', 'manila/network/linux/interface.py', 'manila/api/extensions.py', 'manila/api/v1/shares.py', 'bin/manila-api', 'bin/manila-manage', 'manila/scheduler/filter_scheduler.py', 'manila/scheduler/manager.py', 'manila/scheduler/host_manager.py', 'manila/api/v1/share_snapshots.py', 'manila/service.py', 'manila/db/sqlalchemy/api.py', 'manila/volume/cinder.py', 'bin/manila-scheduler', 'manila/share/manager.py', 'manila/share/volume_types.py', 'manila/api/contrib/quotas.py', 'manila/share/drivers/glusterfs.py', 'manila/share/drivers/emc/plugins/vnx/xml_api_parser.py', 'manila/api/xmlutil.py', 'manila/share/drivers/emc/plugins/vnx/helper.py', 'manila/share/driver.py', 'manila/common/config.py', 'manila/api/middleware/auth.py', 'manila/network/linux/ovs_lib.py', 'bin/manila-all', 'manila/scheduler/simple.py', 'manila/share/api.py', 'manila/scheduler/driver.py', 'manila/api/openstack/volume/versions.py', 'manila/tests/integrated/api/client.py', 'manila/db/migrations/alembic/versions/162a3e673105_manila_init.py', 'manila/manager.py', 'manila/quota.py', 'manila/exception.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/7b659fc4e0536f4242c13ed9dd011f093e943a25', 'message': ""Use oslo.i18n\n\noslo.i18n provides the i18n function that were provided by\noslo-incubator's gettextutils module\n\nImport _ where needed, oslo.i18n deprecated the builtin method.\n\nCloses-Bug: #1382187\nChange-Id: I12aa1c725aa4bb52a9aa46e9c3d2b303839de48b\n""}]",3,129030,7b659fc4e0536f4242c13ed9dd011f093e943a25,31,4,9,6547,,,0,"Use oslo.i18n

oslo.i18n provides the i18n function that were provided by
oslo-incubator's gettextutils module

Import _ where needed, oslo.i18n deprecated the builtin method.

Closes-Bug: #1382187
Change-Id: I12aa1c725aa4bb52a9aa46e9c3d2b303839de48b
",git fetch https://review.opendev.org/openstack/manila refs/changes/30/129030/9 && git format-patch -1 --stdout FETCH_HEAD,"['manila/api/openstack/__init__.py', 'manila/api/openstack/volume/__init__.py', 'manila/network/neutron/api.py', 'manila/scheduler/scheduler_options.py', 'manila/api/v1/security_service.py', 'manila/api/openstack/wsgi.py', 'manila/share/drivers/service_instance.py', 'manila/api/sizelimit.py', 'manila/scheduler/filters/capacity_filter.py', 'manila/share/drivers/netapp/api.py', 'openstack-common.conf', 'manila/share/drivers/emc/plugins/vnx/connection.py', 'manila/scheduler/chance.py', 'manila/utils.py', 'manila/api/contrib/types_extra_specs.py', 'manila/api/common.py', 'manila/api/contrib/share_actions.py', 'manila/api/v1/limits.py', 'manila/api/v1/share_servers.py', 'manila/api/v1/share_networks.py', 'manila/context.py', 'manila/network/linux/ip_lib.py', 'manila/share/drivers/netapp/cluster_mode.py', 'manila/api/middleware/fault.py', 'manila/api/v1/share_metadata.py', 'manila/wsgi.py', 'manila/api/middleware/sizelimit.py', 'manila/share/drivers/generic.py', 'tox.ini', 'manila/api/openstack/urlmap.py', 'manila/share/drivers/glusterfs_native.py', 'manila/api/v1/volume_types.py', 'manila/network/linux/interface.py', 'manila/api/extensions.py', 'manila/api/v1/shares.py', 'bin/manila-api', 'bin/manila-manage', 'manila/scheduler/filter_scheduler.py', 'manila/scheduler/manager.py', 'manila/scheduler/host_manager.py', 'manila/api/v1/share_snapshots.py', 'manila/service.py', 'manila/db/sqlalchemy/api.py', 'manila/volume/cinder.py', 'bin/manila-scheduler', 'manila/share/manager.py', 'manila/share/volume_types.py', 'manila/api/contrib/quotas.py', 'manila/share/drivers/glusterfs.py', 'manila/share/drivers/emc/plugins/vnx/xml_api_parser.py', 'manila/api/xmlutil.py', 'manila/share/drivers/emc/plugins/vnx/helper.py', 'manila/share/driver.py', 'manila/common/config.py', 'manila/api/middleware/auth.py', 'manila/network/linux/ovs_lib.py', 'bin/manila-all', 'manila/scheduler/simple.py', 'manila/share/api.py', 'manila/scheduler/driver.py', 'manila/api/openstack/volume/versions.py', 'manila/tests/integrated/api/client.py', 'manila/db/migrations/alembic/versions/162a3e673105_manila_init.py', 'manila/manager.py', 'manila/quota.py', 'manila/exception.py']",66,b6ec478e7743b1bd32bb9f8ff6daf664a53a54e5,bug/1382187,from manila.i18n import _,,76,9
openstack%2Fheat~master~Id8bc84de48d65b7c05531571502d4fbdad5cc02f,openstack/heat,master,Id8bc84de48d65b7c05531571502d4fbdad5cc02f,Swap trusts delegated from from heat_stack_owner to _member_,ABANDONED,2014-09-05 16:54:39.000000000,2014-10-20 16:18:02.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-09-05 16:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/db1a6968b307655e31a938544e4eaf0111a190c9', 'message': ""Swap trusts delegated from from heat_stack_owner to _member_\n\nCurrently, we require users to have a special role, specific to heat,\nwhich is defaulted to heat_stack_owner.  This can cause confusion if\nfolks don't know new users need this role, and it's not really serving\nany functional purpose (it's just needed because you have to delegate\nat least one role via the trust).\n\nSo, instead, we can use the default _member_ role, which is created\nfor default project membership by keystone when creating users.\n\nThis should mean in most circumstances users can be created and use\nheat without any additional configuration, since they should already\nhave the _member_ role.\n\nThere is residual confusion re Member vs _member_, but according to\nthe information I can find, e.g bug #1330132 and the keystone.conf\nmember_role_name option, _member_ is the right default to use.\n\nDeployers are still of course free to modify the heat.conf option to\nsuit their local policies if needed, this should just make things\na little easier for people dealing with default OpenStack installs.\n\nChange-Id: Id8bc84de48d65b7c05531571502d4fbdad5cc02f\nRelated-Bug: #1306665\n""}, {'number': 2, 'created': '2014-09-17 15:04:33.000000000', 'files': ['etc/heat/heat.conf.sample', 'heat/tests/test_heatclient.py', 'heat/common/config.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9281ce44ab2bb19d39062341283b691e7113fed0', 'message': ""Swap trusts delegated from from heat_stack_owner to _member_\n\nCurrently, we require users to have a special role, specific to heat,\nwhich is defaulted to heat_stack_owner.  This can cause confusion if\nfolks don't know new users need this role, and it's not really serving\nany functional purpose (it's just needed because you have to delegate\nat least one role via the trust).\n\nSo, instead, we can use the default _member_ role, which is created\nfor default project membership by keystone when creating users.\n\nThis should mean in most circumstances users can be created and use\nheat without any additional configuration, since they should already\nhave the _member_ role.\n\nThere is residual confusion re Member vs _member_, but according to\nthe information I can find, e.g bug #1330132 and the keystone.conf\nmember_role_name option, _member_ is the right default to use.\n\nDeployers are still of course free to modify the heat.conf option to\nsuit their local policies if needed, this should just make things\na little easier for people dealing with default OpenStack installs.\n\nChange-Id: Id8bc84de48d65b7c05531571502d4fbdad5cc02f\nRelated-Bug: #1306665\n""}]",0,119415,9281ce44ab2bb19d39062341283b691e7113fed0,14,3,2,4328,,,0,"Swap trusts delegated from from heat_stack_owner to _member_

Currently, we require users to have a special role, specific to heat,
which is defaulted to heat_stack_owner.  This can cause confusion if
folks don't know new users need this role, and it's not really serving
any functional purpose (it's just needed because you have to delegate
at least one role via the trust).

So, instead, we can use the default _member_ role, which is created
for default project membership by keystone when creating users.

This should mean in most circumstances users can be created and use
heat without any additional configuration, since they should already
have the _member_ role.

There is residual confusion re Member vs _member_, but according to
the information I can find, e.g bug #1330132 and the keystone.conf
member_role_name option, _member_ is the right default to use.

Deployers are still of course free to modify the heat.conf option to
suit their local policies if needed, this should just make things
a little easier for people dealing with default OpenStack installs.

Change-Id: Id8bc84de48d65b7c05531571502d4fbdad5cc02f
Related-Bug: #1306665
",git fetch https://review.opendev.org/openstack/heat refs/changes/15/119415/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/heat/heat.conf.sample', 'heat/tests/test_heatclient.py', 'heat/common/config.py']",3,db1a6968b307655e31a938544e4eaf0111a190c9,bug/1330132," default=['_member_'],"," default=['heat_stack_owner'],",7,7
openstack%2Ftripleo-image-elements~master~I86a79ea1075ea2a6a567a78d628ab8a47f53ddd4,openstack/tripleo-image-elements,master,I86a79ea1075ea2a6a567a78d628ab8a47f53ddd4,SELinux: Fix /mnt/state/var/log/keepalived context,MERGED,2014-10-15 21:37:23.000000000,2014-10-20 16:05:17.000000000,2014-10-20 16:05:17.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-10-15 21:37:23.000000000', 'files': ['elements/keepalived/os-refresh-config/configure.d/20-keepalived-selinux'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/97c42d76c4f07fd90b3e1474181c29f664edb9e4', 'message': 'SELinux: Fix /mnt/state/var/log/keepalived context\n\nThe default context mnt_t is incorrect. It should be var_log_t.\n\nBug: 1381770\nChange-Id: I86a79ea1075ea2a6a567a78d628ab8a47f53ddd4\n'}]",0,128769,97c42d76c4f07fd90b3e1474181c29f664edb9e4,8,3,1,7471,,,0,"SELinux: Fix /mnt/state/var/log/keepalived context

The default context mnt_t is incorrect. It should be var_log_t.

Bug: 1381770
Change-Id: I86a79ea1075ea2a6a567a78d628ab8a47f53ddd4
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/69/128769/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/keepalived/os-refresh-config/configure.d/20-keepalived-selinux'],1,97c42d76c4f07fd90b3e1474181c29f664edb9e4,bug/1381770," # Allow keepalived to load kernel modules # https://bugs.launchpad.net/tripleo/+bug/1342872 semanage fcontext -a -t var_log_t ""/mnt/state/var/log/keepalived(/.*)?"" restorecon -Rv /mnt/state/var/log/keepalived",# Allow keepalived to load kernel modules # https://bugs.launchpad.net/tripleo/+bug/1342872,5,2
openstack%2Fcookbook-openstack-ops-database~master~I31a202ed1dc5c8a6ddea25f4ff3aca50e795798b,openstack/cookbook-openstack-ops-database,master,I31a202ed1dc5c8a6ddea25f4ff3aca50e795798b,Cleanup cookbook contact info,MERGED,2014-10-14 15:16:47.000000000,2014-10-20 16:05:11.000000000,2014-10-20 16:05:11.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 7128}, {'_account_id': 12196}, {'_account_id': 12323}]","[{'number': 1, 'created': '2014-10-14 15:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-database/commit/4ac8a1b49fffd9000d28a84006e19092b718088f', 'message': 'Cleanup cookbook contact info\n\n* Consistent email across cookbooks\n* Add Contributor.md to help out new folks\n* Fix broken link in Testing.md\n* Readme tweaks\n\nChange-Id: I31a202ed1dc5c8a6ddea25f4ff3aca50e795798b\nPartial-Bug: #1342735\n'}, {'number': 2, 'created': '2014-10-16 17:30:57.000000000', 'files': ['TESTING.md', 'CONTRIBUTING.md', 'CHANGELOG.md', 'metadata.rb', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-database/commit/5af34f8e2988ae54a0530d43a7cd285f3f6d7174', 'message': 'Cleanup cookbook contact info\n\n* Consistent email across cookbooks\n* Add Contributor.md to help out new folks\n* Fix broken link in Testing.md\n* Readme tweaks\n\nChange-Id: I31a202ed1dc5c8a6ddea25f4ff3aca50e795798b\nPartial-Bug: #1342735\n'}]",3,128331,5af34f8e2988ae54a0530d43a7cd285f3f6d7174,16,6,2,7128,,,0,"Cleanup cookbook contact info

* Consistent email across cookbooks
* Add Contributor.md to help out new folks
* Fix broken link in Testing.md
* Readme tweaks

Change-Id: I31a202ed1dc5c8a6ddea25f4ff3aca50e795798b
Partial-Bug: #1342735
",git fetch https://review.opendev.org/openstack/cookbook-openstack-ops-database refs/changes/31/128331/1 && git format-patch -1 --stdout FETCH_HEAD,"['TESTING.md', 'CONTRIBUTING.md', 'recipes/mysql-server.rb', 'CHANGELOG.md', 'metadata.rb', 'README.md']",6,4ac8a1b49fffd9000d28a84006e19092b718088f,bug/1342735,"* mysql-chef_gem| **Author** | Mark Vanderwiel (<vanderwl@us.ibm.com>) || **Copyright** | Copyright (c) 2014, IBM, Corp. |",,44,5
openstack%2Fcookbook-openstack-ops-messaging~master~Iab95e2dc8cd28b4a45574cf8883f1626dc332db0,openstack/cookbook-openstack-ops-messaging,master,Iab95e2dc8cd28b4a45574cf8883f1626dc332db0,No need to push our rabbit user/pass to rabbit cookbook,MERGED,2014-10-15 06:56:04.000000000,2014-10-20 16:04:47.000000000,2014-10-20 16:04:47.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}, {'_account_id': 8112}, {'_account_id': 8410}]","[{'number': 1, 'created': '2014-10-15 06:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-messaging/commit/497758792954c7aaf9fd702d265528fcd19b8040', 'message': 'Remove rabbitmq default user and pass configuration\n\nConfiguring rabbitmq default password with clear test is insecure,\nso remove it.\n\nChange-Id: Iab95e2dc8cd28b4a45574cf8883f1626dc332db0\nCloses-Bug: #1381343\n'}, {'number': 2, 'created': '2014-10-15 07:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-messaging/commit/50c2a44fa0ee65ca71481271d45d61bbffcdfd7e', 'message': 'Remove rabbitmq default user and pass configuration\n\nConfiguring rabbitmq default password with clear test is insecure,\nso remove it.\n\nChange-Id: Iab95e2dc8cd28b4a45574cf8883f1626dc332db0\nCloses-Bug: #1381343\n'}, {'number': 3, 'created': '2014-10-16 06:15:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-messaging/commit/902f92deb3a668523d3bec3b7257741429bcdeba', 'message': 'No need to push our rabbit user/pass to rabbit cookbook\n\nBecause the rabbit user/pass is stored in internal user database,\nno need to push them to rabbit cookbook and expose them in config file.\nAnd configuring rabbitmq default password with clear test is insecure,\nso remove it.\n\nChange-Id: Iab95e2dc8cd28b4a45574cf8883f1626dc332db0\nCloses-Bug: #1381343\n'}, {'number': 4, 'created': '2014-10-17 01:42:43.000000000', 'files': ['recipes/rabbitmq-server.rb', 'CHANGELOG.md', 'spec/rabbitmq-server_spec.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-messaging/commit/0b087d93f34f57c6d992b6ab3fd9d8bef41bd2b2', 'message': 'No need to push our rabbit user/pass to rabbit cookbook\n\nBecause the rabbit user/pass is stored in internal user database,\nno need to push them to rabbit cookbook and expose them in config file.\nAnd configuring rabbitmq default password with clear test is insecure,\nso remove it.\n\nChange-Id: Iab95e2dc8cd28b4a45574cf8883f1626dc332db0\nCloses-Bug: #1381343\n'}]",5,128570,0b087d93f34f57c6d992b6ab3fd9d8bef41bd2b2,23,5,4,8112,,,0,"No need to push our rabbit user/pass to rabbit cookbook

Because the rabbit user/pass is stored in internal user database,
no need to push them to rabbit cookbook and expose them in config file.
And configuring rabbitmq default password with clear test is insecure,
so remove it.

Change-Id: Iab95e2dc8cd28b4a45574cf8883f1626dc332db0
Closes-Bug: #1381343
",git fetch https://review.opendev.org/openstack/cookbook-openstack-ops-messaging refs/changes/70/128570/2 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/rabbitmq-server.rb', 'spec/spec_helper.rb', 'CHANGELOG.md', 'spec/rabbitmq-server_spec.rb']",4,497758792954c7aaf9fd702d265528fcd19b8040,bug/1381343,, expect(chef_run.node['rabbitmq']['default_user']).to eq('guest') expect(chef_run.node['rabbitmq']['default_pass']).to eq('rabbit-pass'),1,7
openstack%2Fcookbook-openstack-identity~master~Iab81c5e20aca2e7af2ea27c1c4c8a01dc40240ac,openstack/cookbook-openstack-identity,master,Iab81c5e20aca2e7af2ea27c1c4c8a01dc40240ac,Allow API pipeline to be settable in keystone-paste.ini,MERGED,2014-10-16 10:03:46.000000000,2014-10-20 16:04:16.000000000,2014-10-20 16:04:14.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-10-16 10:03:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/a8f25333e304b8d92503f8ca5eee9b97f5985e96', 'message': 'Allow API pipeline to be settable in keystone-paste.ini\n\nChange server recipe and template to allow the pipeline of\npublic_api, admin_api, api_v3 to be set.\n\nChange-Id: Iab81c5e20aca2e7af2ea27c1c4c8a01dc40240ac\nCloses-Bug: #1358142\n'}, {'number': 2, 'created': '2014-10-17 06:03:30.000000000', 'files': ['templates/default/keystone-paste.ini.erb', 'attributes/default.rb', 'spec/server_spec.rb', 'CHANGELOG.md', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/e0934e976901f87122c81875b392d36e0beea9cc', 'message': 'Allow API pipeline to be settable in keystone-paste.ini\n\nChange server recipe and template to allow the pipeline of\npublic_api, admin_api, api_v3 to be set.\n\nChange-Id: Iab81c5e20aca2e7af2ea27c1c4c8a01dc40240ac\nCloses-Bug: #1358142\n'}]",0,128866,e0934e976901f87122c81875b392d36e0beea9cc,10,4,2,13647,,,0,"Allow API pipeline to be settable in keystone-paste.ini

Change server recipe and template to allow the pipeline of
public_api, admin_api, api_v3 to be set.

Change-Id: Iab81c5e20aca2e7af2ea27c1c4c8a01dc40240ac
Closes-Bug: #1358142
",git fetch https://review.opendev.org/openstack/cookbook-openstack-identity refs/changes/66/128866/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/default/keystone-paste.ini.erb', 'attributes/default.rb', 'spec/server_spec.rb', 'CHANGELOG.md', 'README.md']",5,a8f25333e304b8d92503f8ca5eee9b97f5985e96,yicong,* `openstack['identity']['pipeline']['public_api']` - Pipeline of identity public api * `openstack['identity']['pipeline']['admin_api']` - Pipeline of identity admin api * `openstack['identity']['pipeline']['api_v3']` - Pipeline of identity V3 api,,33,4
openstack%2Fnova~master~I131b414e58e9338b39e94ec73a839991e75952b8,openstack/nova,master,I131b414e58e9338b39e94ec73a839991e75952b8,VMware: Support spawn VM with multiple disks,ABANDONED,2014-09-19 21:38:52.000000000,2014-10-20 16:01:13.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8412}, {'_account_id': 8759}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-19 21:38:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cfb8199c91d5a9b82c49912135e3f241c89b5ee1', 'message': ""VMware: Support spawn VM with multiple disks\n\nThe VMware driver spawn contains logic to check whether\na block device mapping is provided or not. This branching will either\ntrigger the logic to boot from an image or to use the volume provided\nas the root disk.\nHowever, this implementation doesn't handle the case where the user\nwants to boot from an image and attach volumes at the same time.\nThis patch addresses this issue by checking whether the instance\ncontains an image reference.\nIf an image reference is provided: we boot from image, and potentially\nwe\ncan add block device mappings to the VM created. Otherwise, we use\nthe volume provided as the root disk.\n\nCloses-Bug: #1271966\n\nChange-Id: I131b414e58e9338b39e94ec73a839991e75952b8\n""}, {'number': 2, 'created': '2014-10-13 21:25:01.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_vmops.py', 'nova/tests/virt/vmwareapi/test_driver_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fa8d5808bf4929b0503547ce97cb319659927b6f', 'message': ""VMware: Support spawn VM with multiple disks\n\nThe VMware driver spawn contains logic to check whether\na block device mapping is provided or not. This branching will either\ntrigger the logic to boot from an image or to use the volume provided\nas the root disk.\nHowever, this implementation doesn't handle the case where the user\nwants to boot from an image and attach volumes at the same time.\nThis patch addresses this issue by checking whether the instance\ncontains an image reference.\nIf an image reference is provided: we boot from image, and potentially\nwe\ncan add block device mappings to the VM created. Otherwise, we use\nthe volume provided as the root disk.\n\nCloses-Bug: #1271966\n\nChange-Id: I131b414e58e9338b39e94ec73a839991e75952b8\n""}]",8,122872,fa8d5808bf4929b0503547ce97cb319659927b6f,22,10,2,8759,,,0,"VMware: Support spawn VM with multiple disks

The VMware driver spawn contains logic to check whether
a block device mapping is provided or not. This branching will either
trigger the logic to boot from an image or to use the volume provided
as the root disk.
However, this implementation doesn't handle the case where the user
wants to boot from an image and attach volumes at the same time.
This patch addresses this issue by checking whether the instance
contains an image reference.
If an image reference is provided: we boot from image, and potentially
we
can add block device mappings to the VM created. Otherwise, we use
the volume provided as the root disk.

Closes-Bug: #1271966

Change-Id: I131b414e58e9338b39e94ec73a839991e75952b8
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/122872/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_vmops.py', 'nova/tests/virt/vmwareapi/test_driver_api.py']",3,cfb8199c91d5a9b82c49912135e3f241c89b5ee1,bug/1271966," instance_type='m1.large', powered_on=True, ephemeral=None, block_device_info=None): block_device_info=block_device_info) def _spawn_volume_vmdk(self, vc_support=False): """"""Test that we can spawn using the VMDK volume as the root disk."""""" self._create_instance(set_image_ref=False) 'attach_root_volume') volumeops.VMwareVolumeOps.attach_root_volume(connection_info, self.instance, mox.IgnoreArg(), mox.IgnoreArg()) def test_spawn_volume_vmdk(self): self._spawn_volume_vmdk() def test_spawn_volume_iscsi(self): """"""Test that we can spawn using the ISCSI volume as the root disk."""""" self._create_instance(set_image_ref=False) def test_spawn_vm_and_attach_volume_iscsi(self): """"""Test we can spawn a VM from an image and attach a ISCSI volume."""""" self._create_instance() self.mox.StubOutWithMock(block_device, 'volume_in_mapping') self.mox.StubOutWithMock(v_driver, 'block_device_info_get_mapping') conn_info = self._test_vmdk_connection_info('iscsi') mp = 'vda' bdm = [{'connection_info': conn_info, 'mount_device': mp}] v_driver.block_device_info_get_mapping( mox.IgnoreArg()).AndReturn(bdm) self.mox.StubOutWithMock(volumeops.VMwareVolumeOps, 'attach_volume') volumeops.VMwareVolumeOps.attach_volume(conn_info, mox.IgnoreArg(), mp) self.mox.ReplayAll() block_device_info = {'block_device_mapping': bdm} self._create_vm(block_device_info=block_device_info) def test_spawn_vm_and_attach_volume_vmdk(self): """"""Test we can spawn a VM from an image and attach a VMDK volume."""""" self._create_instance() self.mox.StubOutWithMock(block_device, 'volume_in_mapping') self.mox.StubOutWithMock(v_driver, 'block_device_info_get_mapping') conn_info = self._test_vmdk_connection_info('vmdk') mp = 'vda' bdm = [{'connection_info': conn_info, 'mount_device': mp}] v_driver.block_device_info_get_mapping( mox.IgnoreArg()).AndReturn(bdm) self.mox.StubOutWithMock(volumeops.VMwareVolumeOps, 'attach_volume') volumeops.VMwareVolumeOps.attach_volume(conn_info, mox.IgnoreArg(), mp) self.mox.ReplayAll() block_device_info = {'block_device_mapping': bdm} self._create_vm(block_device_info=block_device_info)"," instance_type='m1.large', powered_on=True): block_device_info=None) def _spawn_attach_volume_vmdk(self, set_image_ref=True, vc_support=False): self._create_instance(set_image_ref=set_image_ref) 'attach_volume') volumeops.VMwareVolumeOps.attach_volume(connection_info, self.instance, mox.IgnoreArg()) def test_spawn_attach_volume_vmdk(self): self._spawn_attach_volume_vmdk(vc_support=True) def test_spawn_attach_volume_vmdk_no_image_ref(self): self._spawn_attach_volume_vmdk(set_image_ref=False, vc_support=True)",86,34
openstack%2Fopenstack-chef-repo~master~I3ecf2b07f1ac6d54943fed7b2fbf85a049fe3092,openstack/openstack-chef-repo,master,I3ecf2b07f1ac6d54943fed7b2fbf85a049fe3092,Rename zero_demo Chef environment to zero-demo,MERGED,2014-10-20 06:16:13.000000000,2014-10-20 15:54:34.000000000,2014-10-20 15:54:33.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-10-20 06:16:13.000000000', 'files': ['environments/zero-demo.json', 'README.md'], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/3751246a20ad4ce863c6f85ad8cd50def9701b61', 'message': 'Rename zero_demo Chef environment to zero-demo\n\nFrom the other environment file, the convention seems to be dashes\ninstead of underscores in Chef names.  This patches matches the\nobject name with the filename for the zero-demo environment.\n\nChange-Id: I3ecf2b07f1ac6d54943fed7b2fbf85a049fe3092\n'}]",0,129522,3751246a20ad4ce863c6f85ad8cd50def9701b61,7,3,1,6769,,,0,"Rename zero_demo Chef environment to zero-demo

From the other environment file, the convention seems to be dashes
instead of underscores in Chef names.  This patches matches the
object name with the filename for the zero-demo environment.

Change-Id: I3ecf2b07f1ac6d54943fed7b2fbf85a049fe3092
",git fetch https://review.opendev.org/openstack/openstack-chef-repo refs/changes/22/129522/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/zero-demo.json', 'README.md']",2,3751246a20ad4ce863c6f85ad8cd50def9701b61,sync-zero-demo-env-name," ""name"": ""zero-demo"",chef-client -z -E zero-demo"," ""name"": ""zero_demo"",chef-client -z -E zero_demo",3,3
openstack%2Fopenstack-chef-repo~master~Ib0ef1e140970a33483dabaf2caec2b873e0762aa,openstack/openstack-chef-repo,master,Ib0ef1e140970a33483dabaf2caec2b873e0762aa,Fix syntax error in zero-demo environment file,MERGED,2014-10-20 05:49:24.000000000,2014-10-20 15:54:27.000000000,2014-10-20 15:54:26.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-10-20 05:49:24.000000000', 'files': ['environments/zero-demo.json', 'README.md'], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/33f4c5126507cee6aa403fa02975dee0be9e2bdf', 'message': 'Fix syntax error in zero-demo environment file\n\nChange-Id: Ib0ef1e140970a33483dabaf2caec2b873e0762aa\n'}]",0,129518,33f4c5126507cee6aa403fa02975dee0be9e2bdf,7,3,1,6769,,,0,"Fix syntax error in zero-demo environment file

Change-Id: Ib0ef1e140970a33483dabaf2caec2b873e0762aa
",git fetch https://review.opendev.org/openstack/openstack-chef-repo refs/changes/18/129518/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/zero-demo.json', 'README.md']",2,33f4c5126507cee6aa403fa02975dee0be9e2bdf,fix-zero-demo-json-syntax,, },0,2
openstack%2Fneutron~master~I3bfcaff2620b368d807e9468bb7abc01d6471661,openstack/neutron,master,I3bfcaff2620b368d807e9468bb7abc01d6471661,Updated fileutils and its dependencies,MERGED,2014-10-14 13:42:22.000000000,2014-10-20 15:54:13.000000000,2014-10-20 15:54:12.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6537}, {'_account_id': 6854}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-14 13:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cf93a0fcfb77773731f6715e81fcddef141b8e31', 'message': ""Updated fileutils and its dependencies\n\nThis is to avoid fileutils dependency on excutils that are now moved to\noslo.utils.\n\nThe following changes are included:\n\n* neutron/openstack/common/__init__.py\n  6b048e79e88122f09697d2b194cf266ef267bf9c Let oslotest manage the six.move setting for mox\n\n * neutron/openstack/common/_i18n.py\n  9ce1d96fb2e075fcd5b9ddbee728c0ee49d2be56 Fix i18n import\n  5d40e1431ea0f42d088e44d776264b141ac0947b Remove code that moved to oslo.i18n\n\n * neutron/openstack/common/fileutils.py\n  6ff6b4b4a5253c7a99e7e57c1997b992f5cc3b42 Switch oslo-incubator to use oslo.utils and remove old modules\n  2b966f94de7367b5d0915d8e301b9b0e78d8c831 Fix deletion of cached file for policy enforcer\n  9c88dc31ed0dc0a3af3c49835b7bc009f6873d0c file_open: fixed docstring to refer to open() instead of file()\n  6c7407b9d246bcf6773a8b21feaea4b03f1e33ba fileutils: port to Python 3\n  fcf517d72cb81f972fad20caa9ff0341e9b4aa9c Update oslo log messages with translation domains\n\n * neutron/openstack/common/log.py\n  6c706c5 Delete graduated serialization files\n  5d40e14 Remove code that moved to oslo.i18n\n  6ff6b4b Switch oslo-incubator to use oslo.utils and remove old modules\n  aa74411 log: add missing space in error message\n  037dee0 Set stevedore log level to WARN by default\n  37c0091 Add unicode coercion of logged messages to ContextFormatter\n  6614413 Correct coercion of logged message to unicode\n  1188d88 Except socket.error if syslog isn't running\n  ac995be Fix E126 pep8 errors\n  631f880 Set keystonemiddleware and routes.middleware to log on WARN level\n  726d00a Adjust oslo logging to provide adapter is enabled for\n  433fa0b Make logging_context_format_string optional in log.set_defaults\n  ac92c06 Add default log level for websocket\n  5fd77eb Ability to customize default_log_levels for each project\n  4d9328c Python 3: enable tests/unit/test_log.py\n\nChange-Id: I3bfcaff2620b368d807e9468bb7abc01d6471661\n""}, {'number': 2, 'created': '2014-10-14 15:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/677140942b3e9956d53108e1b96db196d25910a6', 'message': ""Updated fileutils and its dependencies\n\nThis is to avoid fileutils dependency on excutils that are now moved to\noslo.utils.\n\nThe following changes are included:\n\n* neutron/openstack/common/__init__.py\n  6b048e7 Let oslotest manage the six.move setting for mox\n\n * neutron/openstack/common/_i18n.py\n  9ce1d96 Fix i18n import\n  5d40e14 Remove code that moved to oslo.i18n\n\n * neutron/openstack/common/fileutils.py\n  6ff6b4b Switch oslo-incubator to use oslo.utils and remove old modules\n  2b966f9 Fix deletion of cached file for policy enforcer\n  9c88dc3 file_open: fixed docstring to refer to open() instead of file()\n  6c7407b fileutils: port to Python 3\n  fcf517d Update oslo log messages with translation domains\n\n * neutron/openstack/common/log.py\n  6c706c5 Delete graduated serialization files\n  5d40e14 Remove code that moved to oslo.i18n\n  6ff6b4b Switch oslo-incubator to use oslo.utils and remove old modules\n  aa74411 log: add missing space in error message\n  037dee0 Set stevedore log level to WARN by default\n  37c0091 Add unicode coercion of logged messages to ContextFormatter\n  6614413 Correct coercion of logged message to unicode\n  1188d88 Except socket.error if syslog isn't running\n  ac995be Fix E126 pep8 errors\n  631f880 Set keystonemiddleware and routes.middleware to log on WARN level\n  726d00a Adjust oslo logging to provide adapter is enabled for\n  433fa0b Make logging_context_format_string optional in log.set_defaults\n  ac92c06 Add default log level for websocket\n  5fd77eb Ability to customize default_log_levels for each project\n  4d9328c Python 3: enable tests/unit/test_log.py\n\nChange-Id: I3bfcaff2620b368d807e9468bb7abc01d6471661\n""}, {'number': 3, 'created': '2014-10-14 17:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f194c808860dcdce31ccacd0db12a9abb5d955bc', 'message': ""Updated fileutils and its dependencies\n\nThis is to avoid fileutils dependency on excutils that are now moved to\noslo.utils.\n\nThe following changes are included:\n\n* neutron/openstack/common/__init__.py\n  6b048e7 Let oslotest manage the six.move setting for mox\n\n * neutron/openstack/common/_i18n.py\n  9ce1d96 Fix i18n import\n  5d40e14 Remove code that moved to oslo.i18n\n\n * neutron/openstack/common/fileutils.py\n  6ff6b4b Switch oslo-incubator to use oslo.utils and remove old modules\n  2b966f9 Fix deletion of cached file for policy enforcer\n  9c88dc3 file_open: fixed docstring to refer to open() instead of file()\n  6c7407b fileutils: port to Python 3\n  fcf517d Update oslo log messages with translation domains\n\n * neutron/openstack/common/log.py\n  6c706c5 Delete graduated serialization files\n  5d40e14 Remove code that moved to oslo.i18n\n  6ff6b4b Switch oslo-incubator to use oslo.utils and remove old modules\n  aa74411 log: add missing space in error message\n  037dee0 Set stevedore log level to WARN by default\n  37c0091 Add unicode coercion of logged messages to ContextFormatter\n  6614413 Correct coercion of logged message to unicode\n  1188d88 Except socket.error if syslog isn't running\n  ac995be Fix E126 pep8 errors\n  631f880 Set keystonemiddleware and routes.middleware to log on WARN level\n  726d00a Adjust oslo logging to provide adapter is enabled for\n  433fa0b Make logging_context_format_string optional in log.set_defaults\n  ac92c06 Add default log level for websocket\n  5fd77eb Ability to customize default_log_levels for each project\n  4d9328c Python 3: enable tests/unit/test_log.py\n\nChange-Id: I3bfcaff2620b368d807e9468bb7abc01d6471661\n""}, {'number': 4, 'created': '2014-10-17 07:57:42.000000000', 'files': ['requirements.txt', 'neutron/openstack/common/_i18n.py', 'neutron/openstack/common/log.py', 'neutron/openstack/common/fileutils.py', 'neutron/openstack/common/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c1bc6ffad8b93490df36a049bf7be0d6da0ce2b0', 'message': ""Updated fileutils and its dependencies\n\nThis is to avoid fileutils dependency on excutils that are now moved to\noslo.utils.\n\nThe following changes are included:\n\n* neutron/openstack/common/__init__.py\n  6b048e7 Let oslotest manage the six.move setting for mox\n\n * neutron/openstack/common/_i18n.py\n  9ce1d96 Fix i18n import\n  5d40e14 Remove code that moved to oslo.i18n\n\n * neutron/openstack/common/fileutils.py\n  6ff6b4b Switch oslo-incubator to use oslo.utils and remove old modules\n  2b966f9 Fix deletion of cached file for policy enforcer\n  9c88dc3 file_open: fixed docstring to refer to open() instead of file()\n  6c7407b fileutils: port to Python 3\n  fcf517d Update oslo log messages with translation domains\n\n * neutron/openstack/common/log.py\n  6c706c5 Delete graduated serialization files\n  5d40e14 Remove code that moved to oslo.i18n\n  6ff6b4b Switch oslo-incubator to use oslo.utils and remove old modules\n  aa74411 log: add missing space in error message\n  037dee0 Set stevedore log level to WARN by default\n  37c0091 Add unicode coercion of logged messages to ContextFormatter\n  6614413 Correct coercion of logged message to unicode\n  1188d88 Except socket.error if syslog isn't running\n  ac995be Fix E126 pep8 errors\n  631f880 Set keystonemiddleware and routes.middleware to log on WARN level\n  726d00a Adjust oslo logging to provide adapter is enabled for\n  433fa0b Make logging_context_format_string optional in log.set_defaults\n  ac92c06 Add default log level for websocket\n  5fd77eb Ability to customize default_log_levels for each project\n  4d9328c Python 3: enable tests/unit/test_log.py\n  cb5a804 Move `mask_password` to strutils\n\nNote: cb5a804 is partially included; that's ok because we don't use the\nmoved function in Neutron.\n\nChange-Id: I3bfcaff2620b368d807e9468bb7abc01d6471661\n""}]",4,128284,c1bc6ffad8b93490df36a049bf7be0d6da0ce2b0,96,27,4,9656,,,0,"Updated fileutils and its dependencies

This is to avoid fileutils dependency on excutils that are now moved to
oslo.utils.

The following changes are included:

* neutron/openstack/common/__init__.py
  6b048e7 Let oslotest manage the six.move setting for mox

 * neutron/openstack/common/_i18n.py
  9ce1d96 Fix i18n import
  5d40e14 Remove code that moved to oslo.i18n

 * neutron/openstack/common/fileutils.py
  6ff6b4b Switch oslo-incubator to use oslo.utils and remove old modules
  2b966f9 Fix deletion of cached file for policy enforcer
  9c88dc3 file_open: fixed docstring to refer to open() instead of file()
  6c7407b fileutils: port to Python 3
  fcf517d Update oslo log messages with translation domains

 * neutron/openstack/common/log.py
  6c706c5 Delete graduated serialization files
  5d40e14 Remove code that moved to oslo.i18n
  6ff6b4b Switch oslo-incubator to use oslo.utils and remove old modules
  aa74411 log: add missing space in error message
  037dee0 Set stevedore log level to WARN by default
  37c0091 Add unicode coercion of logged messages to ContextFormatter
  6614413 Correct coercion of logged message to unicode
  1188d88 Except socket.error if syslog isn't running
  ac995be Fix E126 pep8 errors
  631f880 Set keystonemiddleware and routes.middleware to log on WARN level
  726d00a Adjust oslo logging to provide adapter is enabled for
  433fa0b Make logging_context_format_string optional in log.set_defaults
  ac92c06 Add default log level for websocket
  5fd77eb Ability to customize default_log_levels for each project
  4d9328c Python 3: enable tests/unit/test_log.py
  cb5a804 Move `mask_password` to strutils

Note: cb5a804 is partially included; that's ok because we don't use the
moved function in Neutron.

Change-Id: I3bfcaff2620b368d807e9468bb7abc01d6471661
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/128284/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'neutron/openstack/common/_i18n.py', 'neutron/openstack/common/log.py', 'neutron/openstack/common/fileutils.py', 'neutron/openstack/common/__init__.py']",5,cf93a0fcfb77773731f6715e81fcddef141b8e31,oslo.utils,,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import six six.add_move(six.MovedModule('mox', 'mox', 'mox3.mox')) ",131,117
openstack%2Fceilometer~master~I00d6b194dab0026558376e2fb052ff7b094dff32,openstack/ceilometer,master,I00d6b194dab0026558376e2fb052ff7b094dff32,Edits assert methods,MERGED,2014-10-20 11:42:28.000000000,2014-10-20 15:53:18.000000000,2014-10-20 15:53:18.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 10987}, {'_account_id': 13518}]","[{'number': 1, 'created': '2014-10-20 11:42:28.000000000', 'files': ['ceilometer/tests/api/v2/test_list_resources_scenarios.py', 'ceilometer/tests/storage/test_storage_scenarios.py', 'ceilometer/tests/agentbase.py', 'ceilometer/tests/objectstore/test_swift.py', 'ceilometer/tests/publisher/test_file.py', 'ceilometer/tests/api/v2/test_statistics_scenarios.py', 'ceilometer/tests/alarm/partition/test_coordination.py', 'ceilometer/tests/api/v2/test_alarm_scenarios.py', 'ceilometer/tests/compute/virt/vmware/test_inspector.py', 'ceilometer/tests/ipmi/platform/test_ipmi_sensor.py', 'ceilometer/tests/api/v2/test_event_scenarios.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/adb635b5cae17cb8a9e9305a765216a45277e76f', 'message': 'Edits assert methods\n\nMakes changes to the following files:\n  tests/agentbase.py\n  tests/alarm/partition/test_coordination.py\n  tests/api/v2/test_alarm_scenarios.py\n  tests/api/v2/test_event_scenarios.py\n  tests/api/v2/test_list_resources_scenarios.py\n  tests/api/v2/test_statistics_scenarios.py\n  tests/compute/virt/vmware/test_inspector.py\n  tests/ipmi/platform/test_ipmi_sensor.py\n  tests/objectstore/test_swift.py\n  tests/publisher/test_file.py\n  tests/storage/test_storage_scenarios.py\n\nReplaces assertTrue(a in b) with assertIn(a, b).\n\nChange-Id: I00d6b194dab0026558376e2fb052ff7b094dff32\n'}]",0,129581,adb635b5cae17cb8a9e9305a765216a45277e76f,8,5,1,13518,,,0,"Edits assert methods

Makes changes to the following files:
  tests/agentbase.py
  tests/alarm/partition/test_coordination.py
  tests/api/v2/test_alarm_scenarios.py
  tests/api/v2/test_event_scenarios.py
  tests/api/v2/test_list_resources_scenarios.py
  tests/api/v2/test_statistics_scenarios.py
  tests/compute/virt/vmware/test_inspector.py
  tests/ipmi/platform/test_ipmi_sensor.py
  tests/objectstore/test_swift.py
  tests/publisher/test_file.py
  tests/storage/test_storage_scenarios.py

Replaces assertTrue(a in b) with assertIn(a, b).

Change-Id: I00d6b194dab0026558376e2fb052ff7b094dff32
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/81/129581/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/api/v2/test_list_resources_scenarios.py', 'ceilometer/tests/agentbase.py', 'ceilometer/tests/storage/test_storage_scenarios.py', 'ceilometer/tests/objectstore/test_swift.py', 'ceilometer/tests/publisher/test_file.py', 'ceilometer/tests/api/v2/test_statistics_scenarios.py', 'ceilometer/tests/alarm/partition/test_coordination.py', 'ceilometer/tests/api/v2/test_alarm_scenarios.py', 'ceilometer/tests/compute/virt/vmware/test_inspector.py', 'ceilometer/tests/ipmi/platform/test_ipmi_sensor.py', 'ceilometer/tests/api/v2/test_event_scenarios.py']",11,adb635b5cae17cb8a9e9305a765216a45277e76f,assert_fixing_5," self.assertIn(event_type, data) self.assertIn(event['event_type'], ['Foo', 'Bar', 'Zoo']) self.assertIn(trait_name, map(lambda x: x['name'], event['traits']))"," self.assertTrue(event_type in data) self.assertTrue(event['event_type'] in ['Foo', 'Bar', 'Zoo']) self.assertTrue(trait_name in map(lambda x: x['name'], event['traits']))",36,36
openstack%2Fdjango_openstack_auth~master~I62b6ba45a8ffe56344a6af56c97aa6928ff18ef7,openstack/django_openstack_auth,master,I62b6ba45a8ffe56344a6af56c97aa6928ff18ef7,"Revert ""Redirect the user if they're already logged in""",ABANDONED,2014-10-20 14:38:37.000000000,2014-10-20 15:52:40.000000000,,[],"[{'number': 1, 'created': '2014-10-20 14:38:37.000000000', 'files': ['openstack_auth/tests/tests.py', 'openstack_auth/views.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/4cc56a3b175480f5ee234ce9e565a3a7c0ee0f83', 'message': 'Revert ""Redirect the user if they\'re already logged in""\n\nThis reverts commit ee41e31b9a2f98128d35ad4d76cb81e124fb46ea.\nRelated-Bug: #1381413\nConflicts:\n\topenstack_auth/tests/tests.py\n\topenstack_auth/views.py\n\nChange-Id: I62b6ba45a8ffe56344a6af56c97aa6928ff18ef7\n'}]",0,129633,4cc56a3b175480f5ee234ce9e565a3a7c0ee0f83,2,0,1,12355,,,0,"Revert ""Redirect the user if they're already logged in""

This reverts commit ee41e31b9a2f98128d35ad4d76cb81e124fb46ea.
Related-Bug: #1381413
Conflicts:
	openstack_auth/tests/tests.py
	openstack_auth/views.py

Change-Id: I62b6ba45a8ffe56344a6af56c97aa6928ff18ef7
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/33/129633/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_auth/tests/tests.py', 'openstack_auth/views.py']",2,4cc56a3b175480f5ee234ce9e565a3a7c0ee0f83,bug/1381413,," # If the user is already authenticated, redirect them to the # dashboard straight away, unless the 'next' parameter is set as it # usually indicates requesting access to a page that requires different # permissions. if (request.user.is_authenticated() and auth.REDIRECT_FIELD_NAME not in request.GET and auth.REDIRECT_FIELD_NAME not in request.POST): return shortcuts.redirect(settings.LOGIN_REDIRECT_URL) regions = dict(getattr(settings, ""AVAILABLE_REGIONS"", [])) region = request.GET.get('region') if region in regions: request.session['region_endpoint'] = region request.session['region_name'] = regions[region] ",1,37
openstack%2Fdjango_openstack_auth~master~I5bab2e48c9d0cb1650400eacb3679d31836a8003,openstack/django_openstack_auth,master,I5bab2e48c9d0cb1650400eacb3679d31836a8003,Switch Region dropdown,ABANDONED,2014-10-10 15:04:18.000000000,2014-10-20 15:52:21.000000000,,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 8040}, {'_account_id': 8871}, {'_account_id': 12355}]","[{'number': 1, 'created': '2014-10-10 15:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/915da224dae5b69bb4958b703e49a16e2bbf35f4', 'message': 'Multi-region management from Horizon requires endless authentications\n\nChange-Id: I5bab2e48c9d0cb1650400eacb3679d31836a8003\nCloses-Bug: #1332726\n'}, {'number': 2, 'created': '2014-10-13 08:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/acedd7351c8bbaac963392f50da8b21d7f0af374', 'message': 'Multi-region management from Horizon requires endless authentications\n\nChange-Id: I5bab2e48c9d0cb1650400eacb3679d31836a8003\nCloses-Bug: #1332726\n'}, {'number': 3, 'created': '2014-10-14 13:03:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/f8c8f0f0f34a51ecf2c2a8bbab798d32a9f3fab4', 'message': 'Multi-region management from Horizon requires endless authentications\n\nChange-Id: I5bab2e48c9d0cb1650400eacb3679d31836a8003\nCloses-Bug: #1332726\n'}, {'number': 4, 'created': '2014-10-16 09:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/8e42ec1387da82cf3b019d752eaddb4191f66e69', 'message': 'Switch Region dropdown\n\nFixed switch region dropdown\n\nChange-Id: I5bab2e48c9d0cb1650400eacb3679d31836a8003\nCloses-Bug: #1381413\n'}, {'number': 5, 'created': '2014-10-17 09:57:10.000000000', 'files': ['openstack_auth/views.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/cb8e47a2a77b88b2a1930e0bf7124ce4220be2d0', 'message': 'Switch Region dropdown\n\nFixed switch region dropdown\nFor this to work -- we need  dependence from \nthis patch https://review.openstack.org/#/c/127547/\n\nChange-Id: I5bab2e48c9d0cb1650400eacb3679d31836a8003\nCloses-Bug: #1381413\n'}]",1,127547,cb8e47a2a77b88b2a1930e0bf7124ce4220be2d0,21,5,5,12355,,,0,"Switch Region dropdown

Fixed switch region dropdown
For this to work -- we need  dependence from 
this patch https://review.openstack.org/#/c/127547/

Change-Id: I5bab2e48c9d0cb1650400eacb3679d31836a8003
Closes-Bug: #1381413
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/47/127547/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_auth/views.py', 'openstack_auth/urls.py']",2,915da224dae5b69bb4958b703e49a16e2bbf35f4,bug/1381413," url(r'^switch_services_region/$', 'switch_region',"," url(r'^switch_services_region/(?P<region_name>[^/]+)/$', 'switch_region',",10,6
openstack%2Fneutron~master~Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc,openstack/neutron,master,Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc,Reduce security group db calls to neutron server,MERGED,2014-09-05 08:13:49.000000000,2014-10-20 15:49:59.000000000,2014-10-20 15:49:57.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 333}, {'_account_id': 1653}, {'_account_id': 1970}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 6524}, {'_account_id': 6598}, {'_account_id': 6659}, {'_account_id': 7148}, {'_account_id': 7183}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8213}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9705}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9970}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 11825}, {'_account_id': 12040}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-09-05 08:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/993024e0e583994863c2724931843da35bad296b', 'message': 'Avoid impose security groups db calls to neutron-server under Noopfirewall driver\n\nWithin ovs agent daemon loop, prepare_devices_filter will impose heavy workloads\nto neutron server in order to retrieve the security groups message to apply firewall\nrules. If agent configuration with Noopfirewall driver or security group disabled,\nthere is no need for loading the rules from server and refreshing the firewalls.\nThis will reduce the db calls and improve performance for neutron server in this case.\n\nChange-Id: Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc\nCloses-Bug: #1365806\n'}, {'number': 2, 'created': '2014-09-08 01:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6eb8f800027e960926d9d07186d98f53b4a95c42', 'message': 'Reduce security group db calls to neutron server\n\nWithin ovs agent daemon loop, prepare_devices_filter will impose heavy workloads\nto neutron server in order to retrieve the security groups message to apply firewall\nrules. If agent configuration with Noopfirewall driver or security group disabled,\nthere is no need for loading the rules from server and refreshing the firewalls.\nThis will reduce the db calls and improve performance for neutron server in this case.\n\nChange-Id: Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc\nCloses-Bug: #1365806\n'}, {'number': 3, 'created': '2014-09-09 09:08:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/95c03c9f0c6c8a79eb09b3b58695bd6d7509fa3f', 'message': 'Reduce security group db calls to neutron server\n\nWithin ovs agent daemon loop, prepare_devices_filter will impose heavy workloads\nto neutron server in order to retrieve the security groups message to apply firewall\nrules. If agent configuration with Noopfirewall driver or security group disabled,\nthere is no need for loading the rules from server and refreshing the firewalls.\nThis will reduce the db calls and improve performance for neutron server in this case.\n\nChange-Id: Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc\nCloses-Bug: #1365806\n'}, {'number': 4, 'created': '2014-09-12 03:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a7d823ddb18ee670db2a0c4ca4d31cf7229e8e2', 'message': 'Reduce security group db calls to neutron server\n\nWithin ovs agent daemon loop, prepare_devices_filter will impose heavy workloads\nto neutron server in order to retrieve the security groups message to apply firewall\nrules. If agent configuration with Noopfirewall driver or security group disabled,\nthere is no need for loading the rules from server and refreshing the firewalls.\nThis will reduce the db calls and improve performance for neutron server in this case.\n\nChange-Id: Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc\nCloses-Bug: #1365806\n'}, {'number': 5, 'created': '2014-09-12 04:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9273063348064f1b71571dfa17f123b49a7465a7', 'message': 'Reduce security group db calls to neutron server\n\nWithin ovs agent daemon loop, prepare_devices_filter will impose heavy workloads\nto neutron server in order to retrieve the security groups message to apply firewall\nrules. If agent configuration with Noopfirewall driver or security group disabled,\nthere is no need for loading the rules from server and refreshing the firewalls.\nThis will reduce the db calls and improve performance for neutron server in this case.\n\nChange-Id: Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc\nCloses-Bug: #1365806\n'}, {'number': 6, 'created': '2014-09-15 01:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/44453e68052be9cd70abcfe3c569d4b53d4144d2', 'message': 'Reduce security group db calls to neutron server\n\nWithin ovs agent daemon loop, prepare_devices_filter will impose heavy workloads\nto neutron server in order to retrieve the security groups message to apply firewall\nrules. If agent configuration with Noopfirewall driver or security group disabled,\nthere is no need for loading the rules from server and refreshing the firewalls.\nThis will reduce the db calls and improve performance for neutron server in this case.\n\nChange-Id: Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc\nCloses-Bug: #1365806\n'}, {'number': 7, 'created': '2014-09-17 08:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc2c7e292f6e06258592a4c67adc7d16e55c9529', 'message': 'Reduce security group db calls to neutron server\n\nWithin ovs agent daemon loop, prepare_devices_filter will impose heavy workloads\nto neutron server in order to retrieve the security groups message to apply firewall\nrules. If agent configuration with Noopfirewall driver or security group disabled,\nthere is no need for loading the rules from server and refreshing the firewalls.\nThis will reduce the db calls and improve performance for neutron server in this case.\n\nChange-Id: Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc\nCloses-Bug: #1365806\n'}, {'number': 8, 'created': '2014-09-26 05:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee1870d6ce94f71b6979b42eca32ed79868a51c8', 'message': 'Reduce security group db calls to neutron server\n\nWithin ovs agent daemon loop, prepare_devices_filter will impose heavy workloads\nto neutron server in order to retrieve the security groups message to apply\nfirewall rules. If agent is configured to use Noopfirewall driver or security\ngroups are disabled, there is no need for loading the rules from server and\nrefreshing the firewalls. This will reduce the number of db calls and improve\nperformance for neutron server in this case.\n\nChange-Id: Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc\nCloses-Bug: #1365806\n'}, {'number': 9, 'created': '2014-10-08 01:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/961eccfa7290a3b3470eecdb57156e0ad82068b5', 'message': 'Reduce security group db calls to neutron server\n\nWithin ovs agent daemon loop, prepare_devices_filter will impose heavy workloads\nto neutron server in order to retrieve the security groups message to apply\nfirewall rules. If agent is configured to use Noopfirewall driver or security\ngroups are disabled, there is no need for loading the rules from server and\nrefreshing the firewalls. This will reduce the number of db calls and improve\nperformance for neutron server in this case.\n\nChange-Id: Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc\nCloses-Bug: #1365806\n'}, {'number': 10, 'created': '2014-10-09 09:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f65369397b5a07b8576d39e5d830f747e6eafd2d', 'message': 'Reduce security group db calls to neutron server\n\nWithin ovs agent daemon loop, prepare_devices_filter will impose heavy workloads\nto neutron server in order to retrieve the security groups message to apply\nfirewall rules. If agent is configured to use Noopfirewall driver or security\ngroups are disabled, there is no need for loading the rules from server and\nrefreshing the firewalls. This will reduce the number of db calls and improve\nperformance for neutron server in this case.\n\nChange-Id: Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc\nCloses-Bug: #1365806\n'}, {'number': 11, 'created': '2014-10-11 09:59:48.000000000', 'files': ['neutron/tests/unit/test_security_groups_rpc.py', 'neutron/agent/securitygroups_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/524981cce05a9b365036c0a1e9810036936d3d5b', 'message': 'Reduce security group db calls to neutron server\n\nWithin ovs agent daemon loop, prepare_devices_filter will impose heavy workloads\nto neutron server in order to retrieve the security groups message to apply\nfirewall rules. If agent is configured to use Noopfirewall driver or security\ngroups are disabled, there is no need for loading the rules from server and\nrefreshing the firewalls. This will reduce the number of db calls and improve\nperformance for neutron server in this case.\n\nChange-Id: Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc\nCloses-Bug: #1365806\n'}]",31,119313,524981cce05a9b365036c0a1e9810036936d3d5b,326,42,11,7148,,,0,"Reduce security group db calls to neutron server

Within ovs agent daemon loop, prepare_devices_filter will impose heavy workloads
to neutron server in order to retrieve the security groups message to apply
firewall rules. If agent is configured to use Noopfirewall driver or security
groups are disabled, there is no need for loading the rules from server and
refreshing the firewalls. This will reduce the number of db calls and improve
performance for neutron server in this case.

Change-Id: Id244aab3cac37fc6ed3dc05cbee91cdf9e34d9cc
Closes-Bug: #1365806
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/119313/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/securitygroups_rpc.py'],1,993024e0e583994863c2724931843da35bad296b,bug/1365806,"from neutron.agent import firewall if isinstance(self.firewall, firewall.NoopFirewallDriver) or ( not is_firewall_enabled()): return",,4,0
openstack%2Fkolla~master~I6f787a432ffb9cae404f915ac5228ddcb88e877c,openstack/kolla,master,I6f787a432ffb9cae404f915ac5228ddcb88e877c,Fixes k8s neutron pod image source and formatting,MERGED,2014-10-17 23:38:18.000000000,2014-10-20 15:44:38.000000000,2014-10-20 15:44:38.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}]","[{'number': 1, 'created': '2014-10-17 23:38:18.000000000', 'files': ['k8s/pod/neutron-controller-pod.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/3ae22f65ea0f04b0a49a81f81af96e5a9646d46f', 'message': 'Fixes k8s neutron pod image source and formatting\n\nPreviously, the k8s neutron pod was pulling the image from\ndanehans instead of kollaglue. Additionally, the formatting was\nincorrect causing kube not to pull the image at all.\n\nChange-Id: I6f787a432ffb9cae404f915ac5228ddcb88e877c\n'}]",0,129400,3ae22f65ea0f04b0a49a81f81af96e5a9646d46f,7,3,1,6836,,,0,"Fixes k8s neutron pod image source and formatting

Previously, the k8s neutron pod was pulling the image from
danehans instead of kollaglue. Additionally, the formatting was
incorrect causing kube not to pull the image at all.

Change-Id: I6f787a432ffb9cae404f915ac5228ddcb88e877c
",git fetch https://review.opendev.org/openstack/kolla refs/changes/00/129400/1 && git format-patch -1 --stdout FETCH_HEAD,['k8s/pod/neutron-controller-pod.yaml'],1,3ae22f65ea0f04b0a49a81f81af96e5a9646d46f,neutron_image_fix, - name: neutron-server env: - name: DB_ROOT_PASSWORD value: password - name: NEUTRON_DB_PASSWORD value: password - name: NEUTRON_KEYSTONE_PASSWORD value: password - name: KEYSTONE_ADMIN_TOKEN value: ADMINTOKEN - name: NOVA_ADMIN_PASSWORD value: kolla image: kollaglue/fedora-rdo-neutron-server ports: - containerPort: 9696 volumeMounts: - name: neutron-data mountPath: /var/lib/neutron, env: - name: DB_ROOT_PASSWORD value: password - name: NEUTRON_DB_PASSWORD value: password - name: NEUTRON_KEYSTONE_PASSWORD value: password - name: KEYSTONE_ADMIN_TOKEN value: ADMINTOKEN - name: NOVA_ADMIN_PASSWORD value: kolla image: danehans/fedora-rdo-neutron-server name: neutron-server ports: - containerPort: 9696 volumeMounts: - name: neutron-data mountPath: /var/lib/neutron,18,18
openstack%2Fneutron~master~Ic3754818f84064d2c8da04914826fc912437b2f0,openstack/neutron,master,Ic3754818f84064d2c8da04914826fc912437b2f0,l3_agent: avoid name conflict with context,MERGED,2014-10-16 06:37:10.000000000,2014-10-20 15:43:38.000000000,2014-10-20 15:43:37.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6502}, {'_account_id': 6854}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13426}]","[{'number': 1, 'created': '2014-10-16 06:37:10.000000000', 'files': ['neutron/agent/l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ffcb30c4fbee334f9903d2719418bc6aa9d7721c', 'message': 'l3_agent: avoid name conflict with context\n\nmodule name, context, conflicts with argument name in many place in\nl3_agent. In order to avoid such conflict, import context as n_context\nfollowing Neutron practice.\n\nChange-Id: Ic3754818f84064d2c8da04914826fc912437b2f0\nCloses-Bug: #1381900\n'}]",0,128836,ffcb30c4fbee334f9903d2719418bc6aa9d7721c,27,23,1,333,,,0,"l3_agent: avoid name conflict with context

module name, context, conflicts with argument name in many place in
l3_agent. In order to avoid such conflict, import context as n_context
following Neutron practice.

Change-Id: Ic3754818f84064d2c8da04914826fc912437b2f0
Closes-Bug: #1381900
",git fetch https://review.opendev.org/openstack/neutron refs/changes/36/128836/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3_agent.py'],1,ffcb30c4fbee334f9903d2719418bc6aa9d7721c,bug/1381900,from neutron import context as n_context self.context = n_context.get_admin_context_without_session(),from neutron import context self.context = context.get_admin_context_without_session(),2,2
openstack%2Fhorizon~master~I1f02fd386a9b6836fb95433d9cb819af4f267d6c,openstack/horizon,master,I1f02fd386a9b6836fb95433d9cb819af4f267d6c,Do not override user-defined Device Size,MERGED,2014-09-29 14:07:23.000000000,2014-10-20 15:40:45.000000000,2014-10-20 15:40:44.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2455}, {'_account_id': 4264}, {'_account_id': 6635}, {'_account_id': 6637}, {'_account_id': 6638}, {'_account_id': 6914}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 10295}, {'_account_id': 11881}, {'_account_id': 12826}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-09-29 14:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/dd69afd22c40db63374f37d1d1651d588867fcf6', 'message': 'Do not override user-defined Device Size\n\nThis change introduces a flag which identifies whether or not the\nuser has manually set the Device Size field when launching an\ninstance with a new volume. If the user has made a change then the\nvalue will not be overridden by the logic that sets the Device Size\nbased on the selected image/flavor unless the user-defined value is\ntoo small.\n\nChange-Id: I1f02fd386a9b6836fb95433d9cb819af4f267d6c\nCloses-bug: 1370080\n'}, {'number': 2, 'created': '2014-09-30 11:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ff091d7bf8d47375b233ce788dd1306696be778d', 'message': 'Do not override user-defined Device Size\n\nThis change introduces a flag which identifies whether or not the\nuser has manually set the Device Size field when launching an\ninstance with a new volume. If the user has made a change then the\nvalue will not be overridden by the logic that sets the Device Size\nbased on the selected image/flavor unless the user-defined value is\ntoo small.\n\nChange-Id: I1f02fd386a9b6836fb95433d9cb819af4f267d6c\nCloses-bug: 1370080\n'}, {'number': 3, 'created': '2014-10-03 10:36:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/91b6e06559d30f769ac23f57e3033524d07cf39c', 'message': 'Do not override user-defined Device Size\n\nThis change introduces a flag which identifies whether or not the\nuser has manually set the Device Size field when launching an\ninstance with a new volume. If the user has made a change then the\nvalue will not be overridden by the logic that sets the Device Size\nbased on the selected image/flavor unless the user-defined value is\ntoo small.\n\nChange-Id: I1f02fd386a9b6836fb95433d9cb819af4f267d6c\nCloses-bug: 1370080\n'}, {'number': 4, 'created': '2014-10-06 11:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6ec0b85baaa036c1fb7620364ab29b25dcf9162a', 'message': 'Do not override user-defined Device Size\n\nThis change introduces a flag which identifies whether or not the\nuser has manually set the Device Size field when launching an\ninstance with a new volume. If the user has made a change then the\nvalue will not be overridden by the logic that sets the Device Size\nbased on the selected image/flavor unless the user-defined value is\ntoo small.\n\nChange-Id: I1f02fd386a9b6836fb95433d9cb819af4f267d6c\nCloses-bug: 1370080\n'}, {'number': 5, 'created': '2014-10-09 13:00:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/81fe8af55852373e237ca41518b1b8da86683c1b', 'message': 'Do not override user-defined Device Size\n\nThis change introduces a flag which identifies whether or not the\nuser has manually set the Device Size field when launching an\ninstance with a new volume. If the user has made a change then the\nvalue will not be overridden by the logic that sets the Device Size\nbased on the selected image/flavor unless the user-defined value is\ntoo small.\n\nChange-Id: I1f02fd386a9b6836fb95433d9cb819af4f267d6c\nCloses-bug: 1370080\n'}, {'number': 6, 'created': '2014-10-13 20:19:23.000000000', 'files': ['horizon/static/horizon/js/horizon.instances.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/59af5f5c5a1da71103103e86463dcfb1d0e9e913', 'message': 'Do not override user-defined Device Size\n\nThis change introduces a flag which identifies whether or not the\nuser has manually set the Device Size field when launching an\ninstance with a new volume. If the user has made a change then the\nvalue will not be overridden by the logic that sets the Device Size\nbased on the selected image/flavor unless the user-defined value is\ntoo small.\n\nChange-Id: I1f02fd386a9b6836fb95433d9cb819af4f267d6c\nCloses-bug: 1370080\n'}]",4,124750,59af5f5c5a1da71103103e86463dcfb1d0e9e913,46,17,6,6635,,,0,"Do not override user-defined Device Size

This change introduces a flag which identifies whether or not the
user has manually set the Device Size field when launching an
instance with a new volume. If the user has made a change then the
value will not be overridden by the logic that sets the Device Size
based on the selected image/flavor unless the user-defined value is
too small.

Change-Id: I1f02fd386a9b6836fb95433d9cb819af4f267d6c
Closes-bug: 1370080
",git fetch https://review.opendev.org/openstack/horizon refs/changes/50/124750/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.instances.js'],1,dd69afd22c40db63374f37d1d1651d588867fcf6,bug/1370080," user_volume_size: false, if (image !== undefined) { if (image.min_disk > volume_size) { // If the user has manually changed the volume size, do not override // unless user entered value is too small. if (horizon.instances.user_volume_size) { var user_value = $(""#id_volume_size"").val(); if (user_value > volume_size) { volume_size = user_value; } } if (volume_size < 1) { $(document).on('input', '.workflow #id_volume_size', function (evt) { horizon.instances.user_volume_size = true; }); ", if(image !== undefined) { if(image.min_disk > volume_size) { if(volume_size < 1) {,17,3
openstack%2Fpython-neutronclient~master~I4806c99ba95ba586decb99fdd5a0dce11b2d88b8,openstack/python-neutronclient,master,I4806c99ba95ba586decb99fdd5a0dce11b2d88b8,Updated from global requirements,MERGED,2014-10-07 19:17:22.000000000,2014-10-20 15:40:42.000000000,2014-10-20 15:40:41.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 6854}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-10-07 19:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/39a7efdc060b9d62bffb5cec627556665a32cc53', 'message': 'Updated from global requirements\n\nChange-Id: I4806c99ba95ba586decb99fdd5a0dce11b2d88b8\n'}, {'number': 2, 'created': '2014-10-10 20:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/6687af39cc3edb1788bcb2693a94f6874322f4a8', 'message': 'Updated from global requirements\n\nChange-Id: I4806c99ba95ba586decb99fdd5a0dce11b2d88b8\n'}, {'number': 3, 'created': '2014-10-11 15:56:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/288438f35b19a19796e6e88bac3c70a6b079316a', 'message': 'Updated from global requirements\n\nChange-Id: I4806c99ba95ba586decb99fdd5a0dce11b2d88b8\n'}, {'number': 4, 'created': '2014-10-11 22:37:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f3b872b14e1be8ad1901299cf734be75ff254579', 'message': 'Updated from global requirements\n\nChange-Id: I4806c99ba95ba586decb99fdd5a0dce11b2d88b8\n'}, {'number': 5, 'created': '2014-10-13 18:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/9f5c3b070458eb244255980d8f19e5eb595d2455', 'message': 'Updated from global requirements\n\nChange-Id: I4806c99ba95ba586decb99fdd5a0dce11b2d88b8\n'}, {'number': 6, 'created': '2014-10-13 23:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/550efacad3a10c53c36acb5459b7867e4e1c6951', 'message': 'Updated from global requirements\n\nChange-Id: I4806c99ba95ba586decb99fdd5a0dce11b2d88b8\n'}, {'number': 7, 'created': '2014-10-15 23:46:47.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/d81222764fd3e5ef9ace9a8bd2c9ef613501ce08', 'message': 'Updated from global requirements\n\nChange-Id: I4806c99ba95ba586decb99fdd5a0dce11b2d88b8\n'}]",0,126680,d81222764fd3e5ef9ace9a8bd2c9ef613501ce08,34,5,7,11131,,,0,"Updated from global requirements

Change-Id: I4806c99ba95ba586decb99fdd5a0dce11b2d88b8
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/80/126680/5 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,39a7efdc060b9d62bffb5cec627556665a32cc53,openstack/requirements,"requests>=2.2.0,!=2.4.0","requests>=1.2.1,!=2.4.0",1,1
openstack%2Fpython-neutronclient~master~Ie4897264793a34c1fd5f64e7ca4f285f3b2d4504,openstack/python-neutronclient,master,Ie4897264793a34c1fd5f64e7ca4f285f3b2d4504,Fix E113 hacking check,MERGED,2014-10-06 10:12:53.000000000,2014-10-20 15:40:29.000000000,2014-10-20 15:40:29.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 5950}, {'_account_id': 6854}, {'_account_id': 7505}]","[{'number': 1, 'created': '2014-10-06 10:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f12322a6ab0a3f1b949069e4adb317ae07eaa79f', 'message': 'Fix E113 hacking check\n\nRemove E113 from the ignored check and fix them. Just one of them raised.\n\nChange-Id: Ie4897264793a34c1fd5f64e7ca4f285f3b2d4504\n'}, {'number': 2, 'created': '2014-10-09 10:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/12d648fe456ca8e786ea1ea2c857d12ed15467cd', 'message': 'Fix E113 hacking check\n\nRemove E113 from the ignored check and fix them. Just one of them raised.\n\nChange-Id: Ie4897264793a34c1fd5f64e7ca4f285f3b2d4504\n'}, {'number': 3, 'created': '2014-10-20 07:35:08.000000000', 'files': ['neutronclient/neutron/v2_0/__init__.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/d046a959460251c597158152b908f11353feff62', 'message': 'Fix E113 hacking check\n\nRemove E113 from the ignored check and fix them. Just one of them raised.\n\nChange-Id: Ie4897264793a34c1fd5f64e7ca4f285f3b2d4504\n'}]",6,126251,d046a959460251c597158152b908f11353feff62,20,6,3,7505,,,0,"Fix E113 hacking check

Remove E113 from the ignored check and fix them. Just one of them raised.

Change-Id: Ie4897264793a34c1fd5f64e7ca4f285f3b2d4504
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/51/126251/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/neutron/v2_0/__init__.py', 'tox.ini']",2,f12322a6ab0a3f1b949069e4adb317ae07eaa79f,hacking-update,"ignore = E125,E128,E129,E265,H302,H307,H405","# E113 unexpected indentationignore = E113,E125,E128,E129,E265,H302,H307,H405",1,5
openstack%2Fmanila~master~Ie26c2b90503f130f69444cfb51bf5cef8f592f98,openstack/manila,master,Ie26c2b90503f130f69444cfb51bf5cef8f592f98,Use six instead of str for exceptions,MERGED,2014-10-18 18:16:56.000000000,2014-10-20 15:37:40.000000000,2014-10-20 15:37:39.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-10-18 18:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/05c4de39e7d2c5cee6398c05167bb199d9ea7bc1', 'message': 'Use six instead of str for exceptions\n\nUse six.text_type instead of str for exceptions to allow lazy\ntranslations with oslo.i18n.\n\nChange-Id: Ie26c2b90503f130f69444cfb51bf5cef8f592f98\n'}, {'number': 2, 'created': '2014-10-19 17:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/5c4e8b9cd7498d358c3de7a3b71fd5e54c1988a4', 'message': 'Use six instead of str for exceptions\n\nUse six.text_type instead of str for exceptions to allow lazy\ntranslations with oslo.i18n.\n\nRemove in manila/api/v1/share_networks.py the unneeded msg assignment.\n\nChange-Id: Ie26c2b90503f130f69444cfb51bf5cef8f592f98\n'}, {'number': 3, 'created': '2014-10-19 17:17:38.000000000', 'files': ['manila/network/linux/ip_lib.py', 'manila/api/v1/share_servers.py', 'manila/api/v1/shares.py', 'manila/api/contrib/types_manage.py', 'manila/tests/api/v1/test_limits.py', 'manila/api/v1/share_networks.py', 'manila/utils.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/732ccbc6615bfa3fdabcedb3e49d1ddb2255e997', 'message': 'Use six instead of str for exceptions\n\nUse six.text_type instead of str for exceptions to allow lazy\ntranslations with oslo.i18n.\n\nRemove some unneeded msg assignment.\n\nChange-Id: Ie26c2b90503f130f69444cfb51bf5cef8f592f98\n'}]",0,129436,732ccbc6615bfa3fdabcedb3e49d1ddb2255e997,10,4,3,6547,,,0,"Use six instead of str for exceptions

Use six.text_type instead of str for exceptions to allow lazy
translations with oslo.i18n.

Remove some unneeded msg assignment.

Change-Id: Ie26c2b90503f130f69444cfb51bf5cef8f592f98
",git fetch https://review.opendev.org/openstack/manila refs/changes/36/129436/2 && git format-patch -1 --stdout FETCH_HEAD,"['manila/network/linux/ip_lib.py', 'manila/api/contrib/types_manage.py', 'manila/api/v1/share_servers.py', 'manila/tests/api/v1/test_limits.py', 'manila/utils.py']",5,05c4de39e7d2c5cee6398c05167bb199d9ea7bc1,bug/1382187,"import six LOG.debug('Could not remove tmpdir: %s', six.text_type(e))"," LOG.debug('Could not remove tmpdir: %s', str(e))",15,10
openstack%2Fneutron~master~I560c34c6fe1c5425469ccdf9b8b4905c123d496d,openstack/neutron,master,I560c34c6fe1c5425469ccdf9b8b4905c123d496d,Schema enhancement to support MultiSegment Network,MERGED,2014-06-30 13:51:55.000000000,2014-10-20 15:36:17.000000000,2014-10-20 15:30:54.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1689}, {'_account_id': 1923}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 5217}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7007}, {'_account_id': 7249}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8911}, {'_account_id': 9008}, {'_account_id': 9361}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10068}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10237}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10571}, {'_account_id': 10692}, {'_account_id': 11614}, {'_account_id': 12040}, {'_account_id': 12711}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-06-30 13:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e6f521711cc0fdae22f32cb44116c16762b25050', 'message': 'Introduced a new field in ml2_network_segments table\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 2, 'created': '2014-08-05 14:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dfa97ee42846eca0290fff1c09b4e880c03e0d16', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\nImplements: blueprint enhancement-in-schema-of-ml2-network-segment\n-table-for-multi-segment-network\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 3, 'created': '2014-08-05 15:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/80b8c38fc5a654901f8f5411527be185c180e8fd', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\nImplements: blueprint schema-enhancement-to-support-multisegment-network\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 4, 'created': '2014-08-06 13:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/20e5b138edef576c8268f29a046673059aaad44b', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\nImplements: blueprint schema-enhancement-to-support-multisegment-network\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 5, 'created': '2014-08-16 23:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a1b79ea4bbb18fa2500b5a79e7d767e1116ec2d2', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\nImplements: blueprint schema-enhancement-to-support-multisegment-network\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 6, 'created': '2014-08-17 09:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f6ed6f4eae7e715ececf2cd4e0a38c2100b11bdc', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\nImplements: blueprint schema-enhancement-to-support-multisegment-network\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 7, 'created': '2014-08-18 10:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dcf5a2cd49135e2ed9ef96ad51c0c681771bb5b2', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\nImplements: blueprint schema-enhancement-to-support-multisegment-network\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 8, 'created': '2014-08-18 13:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5050516f0b0e446bba5be401a8d21aca2690483e', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\n\nImplements: blueprint schema-enhancement-to-support-multisegment-network\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 9, 'created': '2014-08-19 07:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c821a32a53f9cfaa02c5a61bf3ef91e52c8c32ab', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 10, 'created': '2014-08-19 09:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/57dd62b7626bd67839738cb43600054dec0584f8', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 11, 'created': '2014-08-19 12:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3f68fe0349c285e9b91eccc4944523497dc3ecb5', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 12, 'created': '2014-08-21 09:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/849836876226fe120dbc199ee2df9e46a6c71caf', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 13, 'created': '2014-08-25 13:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/de45b3c50b8abd216f66c72f3696b0353cd0542a', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 14, 'created': '2014-09-21 16:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/329605ee21dd1a7effa6cb5fb9f57b109a09b797', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 15, 'created': '2014-09-24 17:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ef8b498dc67bc841feab7fd02a03fe34b7351b09', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 16, 'created': '2014-09-26 11:46:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/910cf9901cdf72d17a93d3369568f9dcd32c2baa', 'message': ""Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nSolution:\nWe need to add another field named 'segment_index' in\n'ml2_network_segment' table containing a numeric position index.\nWith segment_index field we can retrieve the segments in the\norder in which user created.\n\nCloses-Bug: #1224978\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n""}, {'number': 17, 'created': '2014-10-01 08:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c06610024e62707582c5aa2f9aaa0d161161f536', 'message': 'Schema enhancement to support MultiSegment Network\n\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nCloses-Bug: #1224978\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n'}, {'number': 18, 'created': '2014-10-01 08:29:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9a4ed0161d41c922ff6715fd79e9d4bf2221ebbd', 'message': ""Schema enhancement to support MultiSegment Network\n\nDescription:\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nSolution:\nWe need to add another field named 'segment_index' in\n'ml2_network_segment' table containing a numeric position index.\nWith segment_index field we can retrieve the segments in the\norder in which user created.\n\nCloses-Bug: #1224978\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n""}, {'number': 19, 'created': '2014-10-11 15:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/994827ab2f9bffa5de489ad6edad9991bc6a28a1', 'message': ""Schema enhancement to support MultiSegment Network\n\nDescription:\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nSolution:\nWe need to add another field named 'segment_index' in\n'ml2_network_segment' table containing a numeric position index.\nWith segment_index field we can retrieve the segments in the\norder in which user created.\n\nCloses-Bug: #1224978\nCloses-Bug: #1377346\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n""}, {'number': 20, 'created': '2014-10-11 15:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2bbcb58fc585d074220db1c0773ae2eca9b0d380', 'message': ""Schema enhancement to support MultiSegment Network\n\nDescription:\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nSolution:\nWe need to add another field named 'segment_index' in\n'ml2_network_segment' table containing a numeric position index.\nWith segment_index field we can retrieve the segments in the\norder in which user created.\n\nCloses-Bug: #1224978\nCloses-Bug: #1377346\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n""}, {'number': 21, 'created': '2014-10-15 11:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7502aa0227bfdf34b2ee0b72fd282377676f3358', 'message': ""Schema enhancement to support MultiSegment Network\n\nDescription:\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nSolution:\nWe need to add another field named 'segment_index' in\n'ml2_network_segment' table containing a numeric position index.\nWith segment_index field we can retrieve the segments in the\norder in which user created.\n\nCloses-Bug: #1224978\nCloses-Bug: #1377346\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n""}, {'number': 22, 'created': '2014-10-19 19:59:18.000000000', 'files': ['neutron/plugins/ml2/managers.py', 'neutron/db/migration/alembic_migrations/versions/1f71e54a85e7_ml2_net_seg_model.py', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/plugins/ml2/models.py', 'neutron/plugins/ml2/db.py', 'neutron/db/migration/alembic_migrations/versions/HEAD'], 'web_link': 'https://opendev.org/openstack/neutron/commit/db5e370b0d68c3e71626c99941fe487059b3cf88', 'message': ""Schema enhancement to support MultiSegment Network\n\nDescription:\nCurrently, there is nothing in the schema that ensures segments\nfor a network are returned in the same order they were specified\nwhen the network was created, or even in a deterministic order.\n\nSolution:\nWe need to add another field named 'segment_index' in\n'ml2_network_segment' table containing a numeric position index.\nWith segment_index field we can retrieve the segments in the\norder in which user created.\n\nThis patch set also fixes ML2 invalid unit test case in\ntest_create_network_multiprovider().\n\nCloses-Bug: #1224978\nCloses-Bug: #1377346\n\nChange-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d\n""}]",95,103546,db5e370b0d68c3e71626c99941fe487059b3cf88,599,50,22,10370,,,0,"Schema enhancement to support MultiSegment Network

Description:
Currently, there is nothing in the schema that ensures segments
for a network are returned in the same order they were specified
when the network was created, or even in a deterministic order.

Solution:
We need to add another field named 'segment_index' in
'ml2_network_segment' table containing a numeric position index.
With segment_index field we can retrieve the segments in the
order in which user created.

This patch set also fixes ML2 invalid unit test case in
test_create_network_multiprovider().

Closes-Bug: #1224978
Closes-Bug: #1377346

Change-Id: I560c34c6fe1c5425469ccdf9b8b4905c123d496d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/46/103546/17 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/models.py', 'neutron/plugins/ml2/db.py', 'neutron/plugins/ml2/plugin.py']",3,e6f521711cc0fdae22f32cb44116c16762b25050,bug/1224978," segment_order = 1 db.add_network_segment(session, network_id, segment, segment_order) segment_order += 1 db.add_network_segment(session, network_id, segment, segment_order)"," db.add_network_segment(session, network_id, segment) db.add_network_segment(session, network_id, segment)",12,5
openstack%2Fironic~master~I5b7c61c608fb32d7e35acfcd3f4bf5fec7c05b62,openstack/ironic,master,I5b7c61c608fb32d7e35acfcd3f4bf5fec7c05b62,Add SNMP driver for Aten PDU's,MERGED,2014-10-17 09:05:53.000000000,2014-10-20 15:35:47.000000000,2014-10-20 15:35:46.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6773}, {'_account_id': 10068}, {'_account_id': 10239}, {'_account_id': 12081}, {'_account_id': 12356}]","[{'number': 1, 'created': '2014-10-17 09:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/75eed4e1d64f4fd3ac03dffe01402c38897b071f', 'message': ""Add driver for supports Aten PDU's\n\nChange-Id: I5b7c61c608fb32d7e35acfcd3f4bf5fec7c05b62\n""}, {'number': 2, 'created': '2014-10-20 09:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6eebca8a8beafc2dff5da7b0828497d4df999ad0', 'message': 'Closes-Bug: #1383162\n\nChange-Id: I5b7c61c608fb32d7e35acfcd3f4bf5fec7c05b62\n'}, {'number': 3, 'created': '2014-10-20 09:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4a1541ef3a38af2b9dbb0b293403a3b32aae6575', 'message': ""Add SNMP driver for Aten PDU's. Closes-Bug: #1383162\n\nChange-Id: I5b7c61c608fb32d7e35acfcd3f4bf5fec7c05b62\n""}, {'number': 4, 'created': '2014-10-20 10:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bc2179b4dfc8b72db175d2ebbfe6d2a7ded088c3', 'message': ""Add SNMP driver for Aten PDU's.\n\nCloses-Bug: #1383162\n\nChange-Id: I5b7c61c608fb32d7e35acfcd3f4bf5fec7c05b62\n""}, {'number': 5, 'created': '2014-10-20 12:32:22.000000000', 'files': ['ironic/tests/drivers/test_snmp.py', 'ironic/drivers/modules/snmp.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c36bb4f4a6b645f7e41d38b9e17a1016f4bc87e0', 'message': ""Add SNMP driver for Aten PDU's\n\nCloses-Bug: #1383162\n\nChange-Id: I5b7c61c608fb32d7e35acfcd3f4bf5fec7c05b62\n""}]",3,129174,c36bb4f4a6b645f7e41d38b9e17a1016f4bc87e0,32,7,5,13122,,,0,"Add SNMP driver for Aten PDU's

Closes-Bug: #1383162

Change-Id: I5b7c61c608fb32d7e35acfcd3f4bf5fec7c05b62
",git fetch https://review.opendev.org/openstack/ironic refs/changes/74/129174/4 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/snmp.py'],1,75eed4e1d64f4fd3ac03dffe01402c38897b071f,bug/1383162,"class SNMPDriverAten(SNMPDriverSimple): """"""SNMP driver class for Aten PDU devices. SNMP objects for Aten PDU: 1.3.6.1.4.1.21317.1.3.2.2.2.2 Outlet Power Values: 1=Off, 2=On, 3=Pending, 4=Reset """""" oid_device = (21317, 1, 3, 2, 2, 2, 2) value_power_on = 2 value_power_off = 1 def _snmp_oid(self): """"""Return the OID of the power state object. :returns: Power state object OID as a tuple of integers. """""" outlet = int(self.snmp_info['outlet']) return self.oid_enterprise + self.oid_device + (outlet, 0,) 'aten': SNMPDriverAten,",,21,0
openstack%2Fpuppet-nova~stable%2Ficehouse~I38c5f6a40efe905cf5bf78ddf07008a56ac0ac1f,openstack/puppet-nova,stable/icehouse,I38c5f6a40efe905cf5bf78ddf07008a56ac0ac1f,Release 4.2.0,MERGED,2014-10-16 22:15:54.000000000,2014-10-20 15:33:52.000000000,2014-10-20 15:33:51.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-10-16 22:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/d23bd6008c112ceb1a4c9c831af2842bcfdcbe76', 'message': 'Release 4.2.0\n\nChanges:\n - Added option to configure libvirt service name via class parameters\n - Added support for multiple SSL APIs\n - Added option to configure os_region_name in the nova config\n - Corrected resource dependencies on the nova user\n - Fixed os version fact comparison for RedHat-based operating systems\n   for specifying service provider\n\nChange-Id: I38c5f6a40efe905cf5bf78ddf07008a56ac0ac1f\n'}, {'number': 2, 'created': '2014-10-16 22:52:16.000000000', 'files': ['Modulefile', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/da6af916f51f20c279f0451f866b3942a0f6a8b6', 'message': 'Release 4.2.0\n\nChanges:\n - Added option to configure libvirt service name via class parameters\n - Added support for multiple SSL APIs\n - Added option to configure os_region_name in the nova config\n - Corrected resource dependencies on the nova user\n - Fixed os version fact comparison for RedHat-based operating systems\n   for specifying service provider\n - Fixed ssl parameter requirements when using kombu and rabbit\n - Added class for extended logging options\n\nChange-Id: I38c5f6a40efe905cf5bf78ddf07008a56ac0ac1f\n'}]",0,129082,da6af916f51f20c279f0451f866b3942a0f6a8b6,8,3,2,8482,,,0,"Release 4.2.0

Changes:
 - Added option to configure libvirt service name via class parameters
 - Added support for multiple SSL APIs
 - Added option to configure os_region_name in the nova config
 - Corrected resource dependencies on the nova user
 - Fixed os version fact comparison for RedHat-based operating systems
   for specifying service provider
 - Fixed ssl parameter requirements when using kombu and rabbit
 - Added class for extended logging options

Change-Id: I38c5f6a40efe905cf5bf78ddf07008a56ac0ac1f
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/82/129082/2 && git format-patch -1 --stdout FETCH_HEAD,"['Modulefile', 'README.md']",2,d23bd6008c112ceb1a4c9c831af2842bcfdcbe76,stable/icehouse-release,4.2.0 - 2014.1.0 - Icehouse**4.2.0** * Added option to configure libvirt service name via class parameters * Added support for multiple SSL APIs * Added option to configure os_region_name in the nova config * Corrected resource dependencies on the nova user * Fixed os version fact comparison for RedHat-based operating systems for specifying service provider ,4.0.0 - 2014.1.0 - Icehouse,12,2
openstack%2Fmonasca-common~master~Ie03c862a14ec3a9b0c117bd9a802ee2b9b815cc7,openstack/monasca-common,master,Ie03c862a14ec3a9b0c117bd9a802ee2b9b815cc7,Allow the topology to be rebuilt if needed,MERGED,2014-10-20 04:42:59.000000000,2014-10-20 15:33:46.000000000,2014-10-20 15:33:46.000000000,"[{'_account_id': 3}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-10-20 04:42:59.000000000', 'files': ['java/monasca-common-streaming/src/test/java/monasca/common/streaming/storm/TopologyTestCase.java'], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/a49ab9f9b0b34cd8bb67c53474f0300ae84632fc', 'message': 'Allow the topology to be rebuilt if needed\n\nChange-Id: Ie03c862a14ec3a9b0c117bd9a802ee2b9b815cc7\n'}]",0,129516,a49ab9f9b0b34cd8bb67c53474f0300ae84632fc,6,2,1,11809,,,0,"Allow the topology to be rebuilt if needed

Change-Id: Ie03c862a14ec3a9b0c117bd9a802ee2b9b815cc7
",git fetch https://review.opendev.org/openstack/monasca-common refs/changes/16/129516/1 && git format-patch -1 --stdout FETCH_HEAD,['java/monasca-common-streaming/src/test/java/monasca/common/streaming/storm/TopologyTestCase.java'],1,a49ab9f9b0b34cd8bb67c53474f0300ae84632fc,, if (cluster != null) { cluster.killTopology(TEST_TOPOLOGY_NAME); cluster.shutdown(); cluster = null; }, cluster.killTopology(TEST_TOPOLOGY_NAME); cluster.shutdown();,5,2
openstack%2Fpuppet-keystone~master~Ida18439353d4083e968cbe9ae81479ea65650076,openstack/puppet-keystone,master,Ida18439353d4083e968cbe9ae81479ea65650076,Switch to new Juno defaults,MERGED,2014-10-13 20:32:24.000000000,2014-10-20 15:29:58.000000000,2014-10-20 15:29:57.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8482}]","[{'number': 1, 'created': '2014-10-13 20:32:24.000000000', 'files': ['manifests/logging.pp', 'spec/classes/keystone_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/7ddfea27830e96eacf9d026c622bdbac0da43e41', 'message': 'Switch to new Juno defaults\n\nThere are some new default config file values for Juno so switch to\nthem. This commit does not include the LDAP deprecations which is\ncontained in a different commit.\n\nChange-Id: Ida18439353d4083e968cbe9ae81479ea65650076\nCloses-Bug: #1380767\n'}]",0,128091,7ddfea27830e96eacf9d026c622bdbac0da43e41,8,3,1,9500,,,0,"Switch to new Juno defaults

There are some new default config file values for Juno so switch to
them. This commit does not include the LDAP deprecations which is
contained in a different commit.

Change-Id: Ida18439353d4083e968cbe9ae81479ea65650076
Closes-Bug: #1380767
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/91/128091/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/logging.pp', 'spec/classes/keystone_spec.rb', 'manifests/init.pp']",3,7ddfea27830e96eacf9d026c622bdbac0da43e41,new_defaults,"# Optional. Defaults to 'keystone.token.persistence.backends.sql.Token' $token_driver = 'keystone.token.persistence.backends.sql.Token',","# Optional. Defaults to 'keystone.token.backends.sql.Token' $token_driver = 'keystone.token.backends.sql.Token',",10,7
openstack%2Fpuppet-heat~stable%2Ficehouse~Idf72e0b818141af893d9d1bfa00c46ff562a0da1,openstack/puppet-heat,stable/icehouse,Idf72e0b818141af893d9d1bfa00c46ff562a0da1,Release 4.2.0,MERGED,2014-10-16 22:14:03.000000000,2014-10-20 15:24:02.000000000,2014-10-20 15:24:01.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-10-16 22:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/1266fb49911a072246cfb20770cf4d5c321777b6', 'message': 'Release 4.2.0\n\nChanges:\n- Added ability to hide secret type parameters from logs\n- Fixed database resource relationships\n\nChange-Id: Idf72e0b818141af893d9d1bfa00c46ff562a0da1\n'}, {'number': 2, 'created': '2014-10-20 02:54:28.000000000', 'files': ['Modulefile', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/ef85d5a34f0c3c925820782358b25f36b9087692', 'message': 'Release 4.2.0\n\nChanges:\n- Added ability to hide secret type parameters from logs\n- Fixed database resource relationships\n- Added class for extended logging options\n- Fixed ssl parameter requirements when using kombu and rabbit\n\nChange-Id: Idf72e0b818141af893d9d1bfa00c46ff562a0da1\n'}]",0,129078,ef85d5a34f0c3c925820782358b25f36b9087692,12,4,2,8482,,,0,"Release 4.2.0

Changes:
- Added ability to hide secret type parameters from logs
- Fixed database resource relationships
- Added class for extended logging options
- Fixed ssl parameter requirements when using kombu and rabbit

Change-Id: Idf72e0b818141af893d9d1bfa00c46ff562a0da1
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/78/129078/1 && git format-patch -1 --stdout FETCH_HEAD,"['Modulefile', 'README.md']",2,1266fb49911a072246cfb20770cf4d5c321777b6,stable/icehouse-release,4.2.0 - 2014.1.0 - Icehouse**4.2.0** * Added ability to hide secret type parameters from logs * Fixed database resource relationships ,4.0.0 - 2014.1.0 - Icehouse,7,2
openstack%2Fproject-config~master~Ic3bc5fa2642aeaabee5d4c1e0c3764baed811a5d,openstack/project-config,master,Ic3bc5fa2642aeaabee5d4c1e0c3764baed811a5d,Translation download: Update all existing translations,MERGED,2014-10-15 08:54:43.000000000,2014-10-20 15:19:10.000000000,2014-10-20 15:19:10.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 841}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-10-15 08:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/c70f7e4a7665daf4f49260fdb7805c609719f407', 'message': 'Translation download: Update all existing translations\n\nDownload translations for all languages that are in the repo.\n\nthis avoids the situation that a file gets downloaded with 75 %\ntranslations and then not updated as contents changed and translations\ndo not catch up.\n\nChange-Id: Ic3bc5fa2642aeaabee5d4c1e0c3764baed811a5d\n'}, {'number': 2, 'created': '2014-10-15 11:39:31.000000000', 'files': ['jenkins/scripts/propose_translation_update_django_openstack_auth.sh', 'jenkins/scripts/propose_translation_update.sh', 'jenkins/scripts/propose_translation_update_manuals.sh', 'jenkins/scripts/propose_translation_update_horizon.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a3f7d0caa7edd9f2bb35b558c07ead97bab181a9', 'message': 'Translation download: Update all existing translations\n\nDownload translations for all languages that are in the repo.\n\nthis avoids the situation that a file gets downloaded with 75 %\ntranslations and then not updated as contents changed and translations\ndo not catch up.\n\nChange-Id: Ic3bc5fa2642aeaabee5d4c1e0c3764baed811a5d\n'}]",3,128579,a3f7d0caa7edd9f2bb35b558c07ead97bab181a9,16,7,2,6547,,,0,"Translation download: Update all existing translations

Download translations for all languages that are in the repo.

this avoids the situation that a file gets downloaded with 75 %
translations and then not updated as contents changed and translations
do not catch up.

Change-Id: Ic3bc5fa2642aeaabee5d4c1e0c3764baed811a5d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/79/128579/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/scripts/propose_translation_update_django_openstack_auth.sh', 'jenkins/scripts/propose_translation_update.sh', 'jenkins/scripts/propose_translation_update_manuals.sh', 'jenkins/scripts/propose_translation_update_horizon.sh']",4,c70f7e4a7665daf4f49260fdb7805c609719f407,download-all,# Download new files that are at least 75 % translated. # Also downloads updates for existing files that are at least 75 % # translated.# Pull upstream translations of all downloaded files but do not # download new files. tx pull -f ,# Pull upstream translations of files that are at least 75 % # translated,28,6
openstack%2Fproject-config~master~I99ca932f9fdb63d2a01969f804eadd670a7d6bcb,openstack/project-config,master,I99ca932f9fdb63d2a01969f804eadd670a7d6bcb,python-congressclient: Enable Voting for python34,MERGED,2014-10-10 04:37:09.000000000,2014-10-20 15:15:16.000000000,2014-10-20 15:15:15.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-10-10 04:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a6c7d6d1fdb7403da034c9fe47ea5ad18de086a6', 'message': 'python-congressclient: Enable Voting for python34\n\nNow that python-congressclient can pass the python34 gate we make it voting!\n\nChange-Id: I99ca932f9fdb63d2a01969f804eadd670a7d6bcb\n'}, {'number': 2, 'created': '2014-10-15 19:36:55.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/44cf2889c9c097963fae546adc27ed5ec0b9c223', 'message': 'python-congressclient: Enable Voting for python34\n\nNow that python-congressclient can pass the python34 gate we make it voting!\n\nChange-Id: I99ca932f9fdb63d2a01969f804eadd670a7d6bcb\n'}]",0,127408,44cf2889c9c097963fae546adc27ed5ec0b9c223,12,6,2,4395,,,0,"python-congressclient: Enable Voting for python34

Now that python-congressclient can pass the python34 gate we make it voting!

Change-Id: I99ca932f9fdb63d2a01969f804eadd670a7d6bcb
",git fetch https://review.opendev.org/openstack/project-config refs/changes/08/127408/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,a6c7d6d1fdb7403da034c9fe47ea5ad18de086a6,,, - name: gate-python-congressclient-python34 voting: false,0,2
openstack%2Fpuppet-swift~master~I74e4d3a7bc11cd194fc33a1bbb70f07836ea5d32,openstack/puppet-swift,master,I74e4d3a7bc11cd194fc33a1bbb70f07836ea5d32,Update stdlib dependency to 4.x,MERGED,2014-09-22 22:45:42.000000000,2014-10-20 15:13:39.000000000,2014-10-20 15:13:38.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6554}, {'_account_id': 6758}, {'_account_id': 7155}]","[{'number': 1, 'created': '2014-09-22 22:45:42.000000000', 'files': ['Modulefile'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/1591f769bad144948b23c0e4a62537b2a75306c0', 'message': 'Update stdlib dependency to 4.x\n\npuppetlabs/stdlib 4.x is backwards compatible with 3.x and still tested\non Puppet 2.7. Updating stdlib to 4.x allows modules to use newer\nfunctions without breaking older functionality.\n\nChange-Id: I74e4d3a7bc11cd194fc33a1bbb70f07836ea5d32\n'}]",0,123276,1591f769bad144948b23c0e4a62537b2a75306c0,11,5,1,8482,,,0,"Update stdlib dependency to 4.x

puppetlabs/stdlib 4.x is backwards compatible with 3.x and still tested
on Puppet 2.7. Updating stdlib to 4.x allows modules to use newer
functions without breaking older functionality.

Change-Id: I74e4d3a7bc11cd194fc33a1bbb70f07836ea5d32
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/76/123276/1 && git format-patch -1 --stdout FETCH_HEAD,['Modulefile'],1,1591f769bad144948b23c0e4a62537b2a75306c0,stdlib,"dependency 'puppetlabs/stdlib', '>=4.0.0 <5.0.0'","dependency 'puppetlabs/stdlib', '>=3.2.0'",1,1
openstack%2Fproject-config~master~I1b884e5101aedea10b51a26fb0c7c89f77dc4a17,openstack/project-config,master,I1b884e5101aedea10b51a26fb0c7c89f77dc4a17,Add link to translation proposals,MERGED,2014-10-15 06:50:11.000000000,2014-10-20 15:12:28.000000000,2014-10-20 15:12:28.000000000,"[{'_account_id': 3}, {'_account_id': 6316}, {'_account_id': 6786}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-10-15 06:50:11.000000000', 'files': ['jenkins/scripts/common_translation_update.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b3441ee6adea19c93ae178939a858b8772f0db79', 'message': ""Add link to translation proposals\n\nAdd simple link to our workflow page to inform people what's going on.\n\nChange-Id: I1b884e5101aedea10b51a26fb0c7c89f77dc4a17\n""}]",0,128569,b3441ee6adea19c93ae178939a858b8772f0db79,9,4,1,6547,,,0,"Add link to translation proposals

Add simple link to our workflow page to inform people what's going on.

Change-Id: I1b884e5101aedea10b51a26fb0c7c89f77dc4a17
",git fetch https://review.opendev.org/openstack/project-config refs/changes/69/128569/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/scripts/common_translation_update.sh'],1,b3441ee6adea19c93ae178939a858b8772f0db79,add-translation-link, read -d '' COMMIT_MSG <<EOF Imported Translations from Transifex For more information about this automatic import see: https://wiki.openstack.org/wiki/Translations/Infrastructure EOFFor more information about this automatic import see: https://wiki.openstack.org/wiki/Translations/Infrastructure ," COMMIT_MSG=""Imported Translations from Transifex""",9,1
openstack%2Fproject-config~master~I70a4b56639805f17d0802fa602b88bb774b64bd8,openstack/project-config,master,I70a4b56639805f17d0802fa602b88bb774b64bd8,Add translation checks for training-guides,MERGED,2014-10-14 18:24:50.000000000,2014-10-20 15:08:41.000000000,2014-10-20 15:08:40.000000000,"[{'_account_id': 3}, {'_account_id': 6316}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-10-14 18:24:50.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/514f68233be9a92b0dc819d4abf140f84d268d2a', 'message': 'Add translation checks for training-guides\n\nThere is now a first translation for the training-guides in Japanese, so\nwe can run the check jobs for translations.\n\nUse openstack-doc-translation template and remove jobs that are part of\nthe template.\n\nChange-Id: I70a4b56639805f17d0802fa602b88bb774b64bd8\n'}]",0,128392,514f68233be9a92b0dc819d4abf140f84d268d2a,8,3,1,6547,,,0,"Add translation checks for training-guides

There is now a first translation for the training-guides in Japanese, so
we can run the check jobs for translations.

Use openstack-doc-translation template and remove jobs that are part of
the template.

Change-Id: I70a4b56639805f17d0802fa602b88bb774b64bd8
",git fetch https://review.opendev.org/openstack/project-config refs/changes/92/128392/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,514f68233be9a92b0dc819d4abf140f84d268d2a,translation-tests-training, - name: openstack-doc-translation, - training-guides-manuals-upstream-translation-update periodic: - training-guides-manuals-propose-translation-update,1,3
openstack%2Fproject-config~master~I73d21bdc7af961c39ac50f17c30f754409f31660,openstack/project-config,master,I73d21bdc7af961c39ac50f17c30f754409f31660,Build docs for openstack/governance,MERGED,2014-10-02 21:32:31.000000000,2014-10-20 15:08:19.000000000,2014-10-20 15:08:18.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 964}, {'_account_id': 1849}, {'_account_id': 2472}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-10-02 21:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/fd17ca54db78a56a32c5212c67cc72bce6efbe4d', 'message': ""Build docs for openstack/governance\n\nAdd a check job to build versions of the docs to make reviews easier\n(some of the output is generated by sphinx extensions). We still need to\npublish the results somewhere when we're done.\n\nChange-Id: I73d21bdc7af961c39ac50f17c30f754409f31660\n""}, {'number': 2, 'created': '2014-10-02 21:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/277367d4d15e36e01d5b97b6ad8430d6465470c1', 'message': ""Build docs for openstack/governance\n\nAdd a check job to build versions of the docs to make reviews easier\n(some of the output is generated by sphinx extensions). We still need to\npublish the results somewhere when we're done.\n\nChange-Id: I73d21bdc7af961c39ac50f17c30f754409f31660\n""}, {'number': 3, 'created': '2014-10-02 21:42:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9f3d01ee2dd5df0729093c1150589fb800d74953', 'message': ""Build docs for openstack/governance\n\nAdd a check job to build versions of the docs to make reviews easier\n(some of the output is generated by sphinx extensions). We still need to\npublish the results somewhere when we're done.\n\nChange-Id: I73d21bdc7af961c39ac50f17c30f754409f31660\n""}, {'number': 4, 'created': '2014-10-02 21:45:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/237a3fb5466c5f2fb589943ab0b002b34ad2276a', 'message': ""Build docs for openstack/governance\n\nAdd a check job to build versions of the docs to make reviews easier\n(some of the output is generated by sphinx extensions). We still need to\npublish the results somewhere when we're done.\n\nChange-Id: I73d21bdc7af961c39ac50f17c30f754409f31660\n""}, {'number': 5, 'created': '2014-10-07 12:37:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b50667990f086715d2a0a0b12aca5b17582fe54a', 'message': ""Build docs for openstack/governance\n\nAdd a check job to build versions of the docs to make reviews easier\n(some of the output is generated by sphinx extensions). We still need to\npublish the results somewhere when we're done.\n\nChange-Id: I73d21bdc7af961c39ac50f17c30f754409f31660\n""}, {'number': 6, 'created': '2014-10-07 14:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/66f948499096304e9c755a8e043cd41059f3a4b0', 'message': ""Build docs for openstack/governance\n\nAdd a check job to build versions of the docs to make reviews easier\n(some of the output is generated by sphinx extensions). We still need to\npublish the results somewhere when we're done.\n\nChange-Id: I73d21bdc7af961c39ac50f17c30f754409f31660\n""}, {'number': 7, 'created': '2014-10-07 18:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/062c7e4906d1c7f4ee993d1e28fee553d4e80bd2', 'message': ""Build docs for openstack/governance\n\nAdd a check job to build versions of the docs to make reviews easier\n(some of the output is generated by sphinx extensions). We still need to\npublish the results somewhere when we're done.\n\nChange-Id: I73d21bdc7af961c39ac50f17c30f754409f31660\n""}, {'number': 8, 'created': '2014-10-14 17:48:18.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b7943d621e9811830cc85f521c70b1fc0f8257eb', 'message': ""Build docs for openstack/governance\n\nAdd a check job to build versions of the docs to make reviews easier\n(some of the output is generated by sphinx extensions). We still need to\npublish the results somewhere when we're done.\n\nChange-Id: I73d21bdc7af961c39ac50f17c30f754409f31660\n""}]",8,125796,b7943d621e9811830cc85f521c70b1fc0f8257eb,37,9,8,2472,,,0,"Build docs for openstack/governance

Add a check job to build versions of the docs to make reviews easier
(some of the output is generated by sphinx extensions). We still need to
publish the results somewhere when we're done.

Change-Id: I73d21bdc7af961c39ac50f17c30f754409f31660
",git fetch https://review.opendev.org/openstack/project-config refs/changes/96/125796/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,fd17ca54db78a56a32c5212c67cc72bce6efbe4d,governance-docs, - name: just-docs check: - 'gate-{name}-docs' - name: just-docs, - name: noop-jobs,5,1
openstack%2Fproject-config~master~I749d7b2584a4f9dd992745555757250a9519c1fe,openstack/project-config,master,I749d7b2584a4f9dd992745555757250a9519c1fe,Setup translation jobs for openstackclient,MERGED,2014-10-14 11:26:00.000000000,2014-10-20 15:01:42.000000000,2014-10-20 15:01:41.000000000,"[{'_account_id': 3}, {'_account_id': 6316}, {'_account_id': 6482}, {'_account_id': 6609}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-10-14 11:26:00.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/68284f7cff43582118d52b7c548bf0c53645fbff', 'message': 'Setup translation jobs for openstackclient\n\nSetup the usual translation jobs.\n\nTransifex has been setup for this, python-openstackclient is also\nprepared.\n\nChange-Id: I749d7b2584a4f9dd992745555757250a9519c1fe\n'}]",0,128245,68284f7cff43582118d52b7c548bf0c53645fbff,10,5,1,6547,,,0,"Setup translation jobs for openstackclient

Setup the usual translation jobs.

Transifex has been setup for this, python-openstackclient is also
prepared.

Change-Id: I749d7b2584a4f9dd992745555757250a9519c1fe
",git fetch https://review.opendev.org/openstack/project-config refs/changes/45/128245/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,68284f7cff43582118d52b7c548bf0c53645fbff,translate-python-openstackclient, - name: translation-jobs,,2,0
openstack%2Fheat~master~Ibbd4be0ad14952bf19d337559a08279c27dbd2b9,openstack/heat,master,Ibbd4be0ad14952bf19d337559a08279c27dbd2b9,Further split autoscaling code,ABANDONED,2014-09-23 15:30:02.000000000,2014-10-20 14:47:42.000000000,,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-09-23 15:30:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4df2abfcc520f94490626408f9a716b5c2e9f882', 'message': 'Further split autoscaling code\n\nThis patch further splits the autoscaling-group and instance-group\nimplementation into separate modules.\n\nChange-Id: Ibbd4be0ad14952bf19d337559a08279c27dbd2b9\nImplements: partial-blueprint reorg-asg-code\n'}, {'number': 2, 'created': '2014-09-23 15:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/118713c1ce7e82cc9d9159686746cd4818699fff', 'message': 'Further split autoscaling code\n\nThis patch further splits the autoscaling-group and instance-group\nimplementation into separate modules.\n\nChange-Id: Ibbd4be0ad14952bf19d337559a08279c27dbd2b9\nImplements: partial-blueprint reorg-asg-code\n'}, {'number': 3, 'created': '2014-09-29 11:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/005ea29f1e355d9c9f4aaffdfd46628f5722615c', 'message': 'Further split autoscaling code\n\nThis patch further splits the autoscaling-group and instance-group\nimplementation into separate modules.\n\nChange-Id: Ibbd4be0ad14952bf19d337559a08279c27dbd2b9\nImplements: partial-blueprint reorg-asg-code\n'}, {'number': 4, 'created': '2014-09-30 15:46:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4be8f8ce363541ce3ea0264532b1eb0e065ba5dd', 'message': 'Further split autoscaling code\n\nThis patch further splits the autoscaling-group and instance-group\nimplementation into separate modules.\n\nChange-Id: Ibbd4be0ad14952bf19d337559a08279c27dbd2b9\nImplements: partial-blueprint reorg-asg-code\n'}, {'number': 5, 'created': '2014-10-06 12:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/754676bbbf79ea6de591b015e75d3b8aeba37eca', 'message': 'Further split autoscaling code\n\nThis patch further splits the autoscaling-group and instance-group\nimplementation into separate modules.\n\nChange-Id: Ibbd4be0ad14952bf19d337559a08279c27dbd2b9\nImplements: partial-blueprint reorg-asg-code\n'}, {'number': 6, 'created': '2014-10-08 07:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e6bcb9d793dfe5282d8ec6afd7b982bbb9fb7ea3', 'message': 'Further split autoscaling code\n\nThis patch further splits the autoscaling-group and instance-group\nimplementation into separate modules.\n\nChange-Id: Ibbd4be0ad14952bf19d337559a08279c27dbd2b9\nImplements: partial-blueprint reorg-asg-code\n'}, {'number': 7, 'created': '2014-10-08 08:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a80cbf0f989a71eb7ee5c37a3783b50a45041c21', 'message': 'Further split autoscaling code\n\nThis patch further splits the autoscaling-group and instance-group\nimplementation into separate modules.\n\nChange-Id: Ibbd4be0ad14952bf19d337559a08279c27dbd2b9\nImplements: partial-blueprint reorg-asg-code\n'}, {'number': 8, 'created': '2014-10-09 05:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4192f2f764e50ca1cf1cbbc6288a36a14beb4ead', 'message': 'Further split autoscaling code\n\nThis patch further splits the autoscaling-group and instance-group\nimplementation into separate modules.\n\nChange-Id: Ibbd4be0ad14952bf19d337559a08279c27dbd2b9\nImplements: partial-blueprint reorg-asg-code\n'}, {'number': 9, 'created': '2014-10-11 06:16:18.000000000', 'files': ['heat/engine/resources/openstack/autoscaling_group.py', 'heat/engine/resources/autoscaling.py', 'heat/engine/resources/aws/autoscaling_group.py', 'heat/tests/autoscaling/test_new_capacity.py', 'heat/tests/test_notifications.py', 'heat/tests/test_heat_autoscaling_group.py', 'heat/engine/resources/instance_group.py', 'heat/tests/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f497dbc3f657b5fa09ff067b4bfe73ffe66859c1', 'message': 'Further split autoscaling code\n\nThis patch further splits the autoscaling-group and instance-group\nimplementation into separate modules.\n\nChange-Id: Ibbd4be0ad14952bf19d337559a08279c27dbd2b9\nImplements: partial-blueprint reorg-asg-code\n'}]",1,123481,f497dbc3f657b5fa09ff067b4bfe73ffe66859c1,41,7,9,8246,,,0,"Further split autoscaling code

This patch further splits the autoscaling-group and instance-group
implementation into separate modules.

Change-Id: Ibbd4be0ad14952bf19d337559a08279c27dbd2b9
Implements: partial-blueprint reorg-asg-code
",git fetch https://review.opendev.org/openstack/heat refs/changes/81/123481/9 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/autoscaling_group.py', 'heat/engine/resources/autoscaling.py', 'heat/engine/resources/aws/autoscaling_group.py', 'heat/tests/test_autoscaling.py', 'heat/tests/test_notifications.py', 'heat/engine/resources/instance_group.py']",6,4df2abfcc520f94490626408f9a716b5c2e9f882,bp/reorg-asg-code,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy from heat.common import environment_format from heat.common import exception from heat.common import timeutils as iso8601utils from heat.engine import attributes from heat.engine import function from heat.engine import properties from heat.engine.resources import resource_group from heat.engine import rsrc_defn from heat.engine import scheduler from heat.openstack.common import log as logging from heat.scaling import template LOG = logging.getLogger(__name__) (SCALED_RESOURCE_TYPE,) = ('OS::Heat::ScaledResource',) class InstanceGroup(resource_group.ResourceGroup): PROPERTIES = ( AVAILABILITY_ZONES, LAUNCH_CONFIGURATION_NAME, SIZE, LOAD_BALANCER_NAMES, TAGS, ) = ( 'AvailabilityZones', 'LaunchConfigurationName', 'Size', 'LoadBalancerNames', 'Tags', ) _TAG_KEYS = ( TAG_KEY, TAG_VALUE, ) = ( 'Key', 'Value', ) _ROLLING_UPDATE_SCHEMA_KEYS = ( MIN_INSTANCES_IN_SERVICE, MAX_BATCH_SIZE, PAUSE_TIME ) = ( 'MinInstancesInService', 'MaxBatchSize', 'PauseTime' ) _UPDATE_POLICY_SCHEMA_KEYS = (ROLLING_UPDATE,) = ('RollingUpdate',) ATTRIBUTES = ( INSTANCE_LIST, ) = ( 'InstanceList', ) properties_schema = { AVAILABILITY_ZONES: properties.Schema( properties.Schema.LIST, _('Not Implemented.'), required=True ), LAUNCH_CONFIGURATION_NAME: properties.Schema( properties.Schema.STRING, _('Name of LaunchConfiguration resource.'), required=True, update_allowed=True ), SIZE: properties.Schema( properties.Schema.INTEGER, _('Desired number of instances.'), required=True, update_allowed=True ), LOAD_BALANCER_NAMES: properties.Schema( properties.Schema.LIST, _('List of LoadBalancer resources.') ), TAGS: properties.Schema( properties.Schema.LIST, _('Tags to attach to this group.'), schema=properties.Schema( properties.Schema.MAP, schema={ TAG_KEY: properties.Schema( properties.Schema.STRING, required=True ), TAG_VALUE: properties.Schema( properties.Schema.STRING, required=True ), }, ) ), } attributes_schema = { INSTANCE_LIST: attributes.Schema( _(""A comma-delimited list of server ip addresses. "" ""(Heat extension)."") ), } rolling_update_schema = { MIN_INSTANCES_IN_SERVICE: properties.Schema(properties.Schema.NUMBER, default=0), MAX_BATCH_SIZE: properties.Schema(properties.Schema.NUMBER, default=1), PAUSE_TIME: properties.Schema(properties.Schema.STRING, default='PT0S') } update_policy_schema = { ROLLING_UPDATE: properties.Schema(properties.Schema.MAP, schema=rolling_update_schema) } def __init__(self, name, json_snippet, stack): """""" UpdatePolicy is currently only specific to InstanceGroup and AutoScalingGroup. Therefore, init is overridden to parse for the UpdatePolicy. """""" super(InstanceGroup, self).__init__(name, json_snippet, stack) self.update_policy = self.t.update_policy(self.update_policy_schema, self.context) def validate(self): """""" Add validation for update_policy """""" super(InstanceGroup, self).validate() if self.update_policy: self.update_policy.validate() policy_name = self.update_policy_schema.keys()[0] if self.update_policy[policy_name]: pause_time = self.update_policy[policy_name][self.PAUSE_TIME] if iso8601utils.parse_isoduration(pause_time) > 3600: raise ValueError('Maximum PauseTime is 1 hour.') def get_instance_names(self): """"""Get a list of resource names of the instances in this InstanceGroup. Failed resources will be ignored. """""" return [r.name for r in self.get_instances()] def get_instances(self): """"""Get a list of all the instance resources managed by this group. Sort the list of instances first by created_time then by name. """""" resources = [] if self.nested(): resources = [resource for resource in self.nested().itervalues() if resource.status != resource.FAILED] return sorted(resources, key=lambda r: (r.created_time, r.name)) def handle_create(self): """"""Create a nested stack and add the initial resources to it."""""" num_instances = self.properties[self.SIZE] initial_template = self._create_template(num_instances) return self.create_with_template(initial_template) def check_create_complete(self, task): """""" When stack creation is done, update the load balancer. If any instances failed to be created, delete them. """""" done = super(InstanceGroup, self).check_create_complete(task) if done: self._lb_reload() return done def handle_update(self, json_snippet, tmpl_diff, prop_diff): """""" If Properties has changed, update self.properties, so we get the new values during any subsequent adjustment. """""" if tmpl_diff: # parse update policy if 'UpdatePolicy' in tmpl_diff: up = json_snippet.update_policy(self.update_policy_schema, self.context) self.update_policy = up if prop_diff: self.properties = json_snippet.properties(self.properties_schema, self.context) # Replace instances first if launch configuration has changed self._try_rolling_update(prop_diff) # Get the current capacity, we may need to adjust if # Size has changed if self.SIZE in prop_diff: inst_list = self.get_instances() if len(inst_list) != self.properties[self.SIZE]: self.resize(self.properties[self.SIZE]) def _tags(self): """""" Make sure that we add a tag that Ceilometer can pick up. These need to be prepended with 'metering.'. """""" tags = self.properties.get(self.TAGS) or [] for t in tags: if t[self.TAG_KEY].startswith('metering.'): # the user has added one, don't add another. return tags return tags + [{self.TAG_KEY: 'metering.groupname', self.TAG_VALUE: self.FnGetRefId()}] def handle_delete(self): return self.delete_nested() def _get_instance_props(self, conf): props = function.resolve(conf.properties.data) props['Tags'] = self._tags() return props def _get_instance_definition(self): conf_refid = self.properties[self.LAUNCH_CONFIGURATION_NAME] conf = self.stack.resource_by_refid(conf_refid) props = self._get_instance_props(conf) return rsrc_defn.ResourceDefinition(None, SCALED_RESOURCE_TYPE, props, conf.t.metadata()) def _get_instance_templates(self): """"""Get templates for resource instances."""""" return [(instance.name, instance.t) for instance in self.get_instances()] def _create_template(self, num_instances, num_replace=0, template_version=('HeatTemplateFormatVersion', '2012-12-12')): """""" Create a template to represent autoscaled instances. Also see heat.scaling.template.resource_templates. """""" instance_definition = self._get_instance_definition() old_resources = self._get_instance_templates() definitions = template.resource_templates( old_resources, instance_definition, num_instances, num_replace) return template.make_template(definitions, version=template_version) def _try_rolling_update(self, prop_diff): if (self.update_policy[self.ROLLING_UPDATE] and self.LAUNCH_CONFIGURATION_NAME in prop_diff): policy = self.update_policy[self.ROLLING_UPDATE] pause_sec = iso8601utils.parse_isoduration(policy[self.PAUSE_TIME]) self._replace(policy[self.MIN_INSTANCES_IN_SERVICE], policy[self.MAX_BATCH_SIZE], pause_sec) def _replace(self, min_in_service, batch_size, pause_sec): """""" Replace the instances in the group using updated launch configuration """""" def changing_instances(tmpl): instances = self.get_instances() current = set((i.name, i.t) for i in instances) updated = set(tmpl.resource_definitions(self.nested()).items()) # includes instances to be updated and deleted affected = set(k for k, v in current ^ updated) return set(i.FnGetRefId() for i in instances if i.name in affected) def pause_between_batch(): while True: try: yield except scheduler.Timeout: return capacity = len(self.nested()) if self.nested() else 0 efft_bat_sz = min(batch_size, capacity) efft_min_sz = min(min_in_service, capacity) batch_cnt = (capacity + efft_bat_sz - 1) // efft_bat_sz if pause_sec * (batch_cnt - 1) >= self.stack.timeout_secs(): raise ValueError('The current UpdatePolicy will result ' 'in stack update timeout.') # effective capacity includes temporary capacity added to accommodate # the minimum number of instances in service during update efft_capacity = max(capacity - efft_bat_sz, efft_min_sz) + efft_bat_sz try: remainder = capacity while remainder > 0 or efft_capacity > capacity: if capacity - remainder >= efft_min_sz: efft_capacity = capacity template = self._create_template(efft_capacity, efft_bat_sz) self._lb_reload(exclude=changing_instances(template)) updater = self.update_with_template(template) updater.run_to_completion() self.check_update_complete(updater) remainder -= efft_bat_sz if remainder > 0 and pause_sec > 0: self._lb_reload() waiter = scheduler.TaskRunner(pause_between_batch) waiter(timeout=pause_sec) finally: self._lb_reload() def resize(self, new_capacity): """""" Resize the instance group to the new capacity. When shrinking, the oldest instances will be removed. """""" new_template = self._create_template(new_capacity) try: updater = self.update_with_template(new_template) updater.run_to_completion() self.check_update_complete(updater) finally: # Reload the LB in any case, so it's only pointing at healthy # nodes. self._lb_reload() def _lb_reload(self, exclude=None): ''' Notify the LoadBalancer to reload its config to include the changes in instances we have just made. This must be done after activation (instance in ACTIVE state), otherwise the instances' IP addresses may not be available. ''' exclude = exclude or [] if self.properties[self.LOAD_BALANCER_NAMES]: id_list = [inst.FnGetRefId() for inst in self.get_instances() if inst.FnGetRefId() not in exclude] for lb in self.properties[self.LOAD_BALANCER_NAMES]: lb_resource = self.stack[lb] props = copy.copy(lb_resource.properties.data) if 'Instances' in lb_resource.properties_schema: props['Instances'] = id_list elif 'members' in lb_resource.properties_schema: props['members'] = id_list else: raise exception.Error( _(""Unsupported resource '%s' in LoadBalancerNames"") % (lb,)) lb_defn = rsrc_defn.ResourceDefinition( lb_resource.name, lb_resource.type(), props, lb_resource.t.get('Metadata'), deletion_policy=lb_resource.t.get('DeletionPolicy')) scheduler.TaskRunner(lb_resource.update, lb_defn)() def FnGetRefId(self): return self.physical_resource_name_or_FnGetRefId() def FnGetAtt(self, key, *path): ''' heat extension: ""InstanceList"" returns comma delimited list of server ip addresses. ''' if key == self.INSTANCE_LIST: return u','.join(inst.FnGetAtt('PublicIp') for inst in self.get_instances()) or None def child_template(self): num_instances = int(self.properties[self.SIZE]) return self._create_template(num_instances) def child_params(self): """"""Return the environment for the nested stack."""""" return { environment_format.PARAMETERS: {}, environment_format.RESOURCE_REGISTRY: { SCALED_RESOURCE_TYPE: 'AWS::EC2::Instance', }, } def resource_mapping(): return { 'OS::Heat::InstanceGroup': InstanceGroup, } ",,915,859
openstack%2Ftripleo-heat-templates~master~Ied9978efe76ed9c6078a10bc1a736d7ae93f3ffc,openstack/tripleo-heat-templates,master,Ied9978efe76ed9c6078a10bc1a736d7ae93f3ffc,Add ExtraConfig param to storage templates,ABANDONED,2014-10-17 12:59:15.000000000,2014-10-20 14:44:42.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-10-17 12:59:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f53c3509e896fa121b70e8cbe4f1f5ee072a46cf', 'message': 'Add ExtraConfig param to storage templates\n\nThis patch extends the ExtraConfig parameters to the storage nodes\nwhen using tuskar-api to deploy an overcloud.\n\nChange-Id: Ied9978efe76ed9c6078a10bc1a736d7ae93f3ffc\n'}, {'number': 2, 'created': '2014-10-17 14:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/79fd6514816494a31117c2ffdaa047a51393e3ba', 'message': 'Add ExtraConfig param to storage templates\n\nThis patch extends the ExtraConfig parameters to the storage nodes\nwhen using tuskar-api to deploy an overcloud.\n\nChange-Id: Ied9978efe76ed9c6078a10bc1a736d7ae93f3ffc\n'}, {'number': 3, 'created': '2014-10-17 17:34:32.000000000', 'files': ['swift-storage.yaml', 'cinder-storage.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bccfeed5ddef00071adcae9e2bbe3000d27ad5d1', 'message': 'Add ExtraConfig param to storage templates\n\nThis patch extends the ExtraConfig parameters to the storage nodes\nwhen using tuskar-api to deploy an overcloud.\n\nChange-Id: Ied9978efe76ed9c6078a10bc1a736d7ae93f3ffc\n'}]",0,129234,bccfeed5ddef00071adcae9e2bbe3000d27ad5d1,9,1,3,8532,,,0,"Add ExtraConfig param to storage templates

This patch extends the ExtraConfig parameters to the storage nodes
when using tuskar-api to deploy an overcloud.

Change-Id: Ied9978efe76ed9c6078a10bc1a736d7ae93f3ffc
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/34/129234/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift-storage.yaml', 'cinder-storage.yaml']",2,f53c3509e896fa121b70e8cbe4f1f5ee072a46cf,extraconfig-params-for-storage," ExtraConfig: default: {} description: | Additional configuration to inject into the cluster. The JSON should have the following structure: {""FILEKEY"": {""config"": [{""section"": ""SECTIONNAME"", ""values"": [{""option"": ""OPTIONNAME"", ""value"": ""VALUENAME"" } ] } ] } } For instance: {""nova"": {""config"": [{""section"": ""default"", ""values"": [{""option"": ""force_config_drive"", ""value"": ""always"" } ] }, {""section"": ""cells"", ""values"": [{""option"": ""driver"", ""value"": ""nova.cells.rpc_driver.CellsRPCDriver"" } ] } ] } } type: json",,76,0
openstack%2Fneutron~master~I6470356b601e2fcf74c7e0a6df438cef7099e9fe,openstack/neutron,master,I6470356b601e2fcf74c7e0a6df438cef7099e9fe,Refactor _make_subnet_dict to avoid issuing unnecessary queries,MERGED,2014-09-28 18:06:14.000000000,2014-10-20 14:25:45.000000000,2014-10-20 14:25:43.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 2031}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-09-28 18:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d93818abbb599a1036930ae9d7999dd11da0102', 'message': 'Refactor _make_subnet_dict to avoid issuing unnecessary queries\n\nOnly query for related attributes if no filters are provided\nor if those attributes are included in filters.\n\nAs a result, particular scenarios like restarting DHCP agent\ncould benefit from improved server-side performance.\n\nChange-Id: I6470356b601e2fcf74c7e0a6df438cef7099e9fe\nCloses-Bug: #1374044\n'}, {'number': 2, 'created': '2014-09-29 01:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff8a051669c93277658bc51e6d69393178cbe51e', 'message': 'Refactor _make_subnet_dict to avoid issuing unnecessary queries\n\nOnly query for related attributes if no filters are provided\nor if those attributes are included in filters.\n\nAs a result, particular scenarios like restarting DHCP agent\ncould benefit from improved server-side performance.\n\nChange-Id: I6470356b601e2fcf74c7e0a6df438cef7099e9fe\nCloses-Bug: #1374044\n'}, {'number': 3, 'created': '2014-10-15 07:08:34.000000000', 'files': ['neutron/db/models_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/acfcb523b15fbd9ccc509e4366e4a141a66d4783', 'message': 'Refactor _make_subnet_dict to avoid issuing unnecessary queries\n\nUse joined loads for attributes dns_nameservers and host_routes.\n\nAs a result, particular scenarios like restarting DHCP agent\ncould benefit from improved server-side performance.\n\nChange-Id: I6470356b601e2fcf74c7e0a6df438cef7099e9fe\nCloses-Bug: #1374044\n'}]",5,124641,acfcb523b15fbd9ccc509e4366e4a141a66d4783,82,34,3,6072,,,0,"Refactor _make_subnet_dict to avoid issuing unnecessary queries

Use joined loads for attributes dns_nameservers and host_routes.

As a result, particular scenarios like restarting DHCP agent
could benefit from improved server-side performance.

Change-Id: I6470356b601e2fcf74c7e0a6df438cef7099e9fe
Closes-Bug: #1374044
",git fetch https://review.opendev.org/openstack/neutron refs/changes/41/124641/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/db_base_plugin_v2.py'],1,0d93818abbb599a1036930ae9d7999dd11da0102,bug/1374044," # avoid issuing db queries if corresponding fields are filtered if not fields or 'allocation_pools' in fields: res['allocation_pools'] = [{'start': pool['first_ip'], 'end': pool['last_ip']} for pool in subnet['allocation_pools']] if not fields or 'dns_nameservers' in fields: res['dns_nameservers'] = [dns['address'] for dns in subnet['dns_nameservers']] if not fields or 'host_routes' in fields: res['host_routes'] = [{'destination': route['destination'], 'nexthop': route['nexthop']} for route in subnet['routes']]"," 'allocation_pools': [{'start': pool['first_ip'], 'end': pool['last_ip']} for pool in subnet['allocation_pools']], 'dns_nameservers': [dns['address'] for dns in subnet['dns_nameservers']], 'host_routes': [{'destination': route['destination'], 'nexthop': route['nexthop']} for route in subnet['routes']],",12,8
openstack%2Fceilometer~master~I1368f975bfe82162b36eeb0d27f225648f77f327,openstack/ceilometer,master,I1368f975bfe82162b36eeb0d27f225648f77f327,Demo potential service denial via coordination,ABANDONED,2014-10-08 21:37:30.000000000,2014-10-20 14:22:58.000000000,,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-10-08 21:37:30.000000000', 'files': ['bin/ceilometer-coordination-inspect.py', 'ceilometer/agent.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9ab1325b2544197092ee38784da6a0f46d49e210', 'message': ""Demo potential service denial via coordination\n\nWhen using coordination it is possible to maliciously join a group and\nsend a heartbeat, be partitioned resources, but do no work. Other\nworkers in the same group will receive fewer resources, sometimes as\nlow as 0.\n\nThis changeset includes changes which allow a demo, download it,\nstart up a ceilometer enabled devstack and:\n\n* Change ceilometer.conf to add:\n\n    [coordination]\n    backend_url = memcached://localhost\n\n    [compute]\n    workload_partitioning = True\n\n* Change pipeline.yaml's interval to something 60 seconds or less\n\n* boot several instances (I used ten)\n* run several compute agents with the following start up (so\n  debugging messages are visible)\n\n    /usr/bin/ceilometer-agent-compute 2>&1 |grep '####'\n\n* run this new inspector thing I created to verify that the expected\n  number of agents are in the expected group:\n\n    bin/ceilometer-coordination-inspect.py compute-`hostname`\n\n* run the inspector again to fake regular additions (with heartbeat)\n  to the group (new processes are forked every 5 seconds or so):\n\n    bin/ceilometer-coordination-inspect.py --fake compute-`hostname`\n\nThat last will carry on running, adding new members to the group and\ndisplaying the full membership list.\n\nEach time the real compute agents do discovery they will show as having\nfewer resources to work with. Those resources they do not have are\nnot being polled.\n\nI've only tried this so far with memcached, where it would be\nexpected to be like this because there's no auth and we're not using\nopaque keys. Presumably there is at least some documenting we want\nto do here (to control access to memcached or at least explain the\nrisk), and perhaps some implementation of auth for the zookeeper\nbackend.\n\nChange-Id: I1368f975bfe82162b36eeb0d27f225648f77f327\n""}]",1,127032,9ab1325b2544197092ee38784da6a0f46d49e210,8,4,1,11564,,,0,"Demo potential service denial via coordination

When using coordination it is possible to maliciously join a group and
send a heartbeat, be partitioned resources, but do no work. Other
workers in the same group will receive fewer resources, sometimes as
low as 0.

This changeset includes changes which allow a demo, download it,
start up a ceilometer enabled devstack and:

* Change ceilometer.conf to add:

    [coordination]
    backend_url = memcached://localhost

    [compute]
    workload_partitioning = True

* Change pipeline.yaml's interval to something 60 seconds or less

* boot several instances (I used ten)
* run several compute agents with the following start up (so
  debugging messages are visible)

    /usr/bin/ceilometer-agent-compute 2>&1 |grep '####'

* run this new inspector thing I created to verify that the expected
  number of agents are in the expected group:

    bin/ceilometer-coordination-inspect.py compute-`hostname`

* run the inspector again to fake regular additions (with heartbeat)
  to the group (new processes are forked every 5 seconds or so):

    bin/ceilometer-coordination-inspect.py --fake compute-`hostname`

That last will carry on running, adding new members to the group and
displaying the full membership list.

Each time the real compute agents do discovery they will show as having
fewer resources to work with. Those resources they do not have are
not being polled.

I've only tried this so far with memcached, where it would be
expected to be like this because there's no auth and we're not using
opaque keys. Presumably there is at least some documenting we want
to do here (to control access to memcached or at least explain the
risk), and perhaps some implementation of auth for the zookeeper
backend.

Change-Id: I1368f975bfe82162b36eeb0d27f225648f77f327
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/32/127032/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/ceilometer-coordination-inspect.py', 'ceilometer/agent.py']",2,9ab1325b2544197092ee38784da6a0f46d49e210,cd/inspect-coordination, LOG.debug('#### DISCOVERED RESOURCES %s\n' % len(discovered)) LOG.debug('#### DISCOVER ID %s\n' % self.construct_group_id(discoverer.group_id)) LOG.debug('#### PARTITIONED RESOURCES %s\n' % len(partitioned)) LOG.debug('#### LEN RESOURCES %s\n' % len(resources)),,78,0
openstack%2Ftempest~master~Ie0ee0a94449eaf322db1d4440e74d5a8feee2c25,openstack/tempest,master,Ie0ee0a94449eaf322db1d4440e74d5a8feee2c25,WIP Enable deep confirmation of telemetry samples,ABANDONED,2014-08-27 14:38:30.000000000,2014-10-20 14:22:04.000000000,,"[{'_account_id': 3}, {'_account_id': 10385}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-08-27 14:38:30.000000000', 'files': ['tempest/cmd/javelin.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8d80b7f244cc4aead5d561b19ef2753d47d42dce', 'message': 'WIP Enable deep confirmation of telemetry samples\n\nThis patchset preserves for future reference a set of changes that\nallows confirmation that metering still works after an upgrade and\nthat the new upgrade service has successfully been able to get\nsamples from the newly run processes.\n\nThe parent included this functionality but it was considered a bit\ntoo intrusive (see below) and extensive to be included in a normal\njavelin run. This code can be mined for future reference if needed.\n\nThis change requires that javelin have access to the BASE_RELEASE\nand SAVE_DIR environment variables from a grenade run. This requires\na change in grenade.sh. The change makes it possible to get at the\ntimestamp on the datadump file for any project. That timestamp can\nthen be used as a fixed point in time against which to make\ncomparisons with sample timestamps.\n\nChange-Id: Ie0ee0a94449eaf322db1d4440e74d5a8feee2c25\n'}]",0,117259,8d80b7f244cc4aead5d561b19ef2753d47d42dce,8,3,1,11564,,,0,"WIP Enable deep confirmation of telemetry samples

This patchset preserves for future reference a set of changes that
allows confirmation that metering still works after an upgrade and
that the new upgrade service has successfully been able to get
samples from the newly run processes.

The parent included this functionality but it was considered a bit
too intrusive (see below) and extensive to be included in a normal
javelin run. This code can be mined for future reference if needed.

This change requires that javelin have access to the BASE_RELEASE
and SAVE_DIR environment variables from a grenade run. This requires
a change in grenade.sh. The change makes it possible to get at the
timestamp on the datadump file for any project. That timestamp can
then be used as a fixed point in time against which to make
comparisons with sample timestamps.

Change-Id: Ie0ee0a94449eaf322db1d4440e74d5a8feee2c25
",git fetch https://review.opendev.org/openstack/tempest refs/changes/59/117259/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cmd/javelin.py'],1,8d80b7f244cc4aead5d561b19ef2753d47d42dce,cd/javelin-telemetry-resource-deep," # confirm oldest sample if OPTS.mode == 'check': self._confirm_polled_samples(server, body) def _confirm_polled_samples(self, server, samples): """"""Confirm existence of post upgrade telemetry samples."""""" pollings, _ = self._separate_telemetry_samples(samples) self.assertTrue(len(pollings) >= 1, 'require >=1 polling') newest_sample = pollings[0] newest_timestamp = timeutils.normalize_time( timeutils.parse_isotime(newest_sample['timestamp'])) datadump_timestamp = self._get_datadump_timestamp('ceilometer') self.assertTrue( newest_timestamp > datadump_timestamp, 'newest timestamp should be newer than database dump' ) self.assertEqual(server['name'], newest_sample['resource_metadata']['display_name']) @staticmethod def _get_datadump_timestamp(project_name): """"""Create a timestamp from a project's data dump. This can be useful in generating a solid point in time between the BASE and TARGET runs. """""" datadump_file = os.path.join( os.environ['SAVE_DIR'], '$(project)s.sql.%(release)s' % dict( project=project_name, release=os.environ['BASE_RELEASE'])) # NOTE(chdent): This is unfortunate. Perhaps the dump # file should not be given a format associated name? if not os.path.isfile(datadump_file): datadump_file = datadump_file.replace('.sql.', '-dump.') # If the file does not exist we will error out here. That's # what we want. return datetime.datetime.utcfromtimestamp( os.path.getmtime(datadump_file)) @staticmethod def _separate_telemetry_samples(body): """"""Separate a collection of samples into pollings and notifications. """""" # Notifications have an event_type. A for loop is used to avoid # traversing the samples twice and have readable code pollings = [] notifications = [] for sample in body: if 'event_type' not in sample['resource_metadata']: pollings.append(sample) else: notifications.append(sample) return pollings, notifications ",,54,0
openstack%2Ffuel-web~master~Id1ef1650cf47c8e5fd7e844362b3fb41afad8fdd,openstack/fuel-web,master,Id1ef1650cf47c8e5fd7e844362b3fb41afad8fdd,Changed order of calls to register new nodes,MERGED,2014-05-15 12:38:56.000000000,2014-10-20 14:12:28.000000000,2014-06-23 09:55:23.000000000,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11082}]","[{'number': 1, 'created': '2014-05-15 12:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/36dcc49a85b26e93fc275359fd10de690c320b31', 'message': 'Changed order of calls to register new nodes\n\nModified agent to checking if node was before registered\n\nChange-Id: Id1ef1650cf47c8e5fd7e844362b3fb41afad8fdd\nCloses-Bug:: #1305017\n'}, {'number': 2, 'created': '2014-05-16 08:58:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2ae306a470daa3cc8e1079a5a1c31e5e61427abe', 'message': 'Changed order of calls to register new nodes\n\nModified agent to checking if node was before registered, based on existence\nof nailgun_uid file. If file exist, only put is call, in other case when we\ntry made post (if call was succes-201 or node exist 409, we call put method)\n\nChange-Id: Id1ef1650cf47c8e5fd7e844362b3fb41afad8fdd\nCloses-Bug:: #1305017\n'}, {'number': 3, 'created': '2014-05-16 09:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/629abd4ffa0c98a761e241634c27cdb0e9ee2047', 'message': 'Changed order of calls to register new nodes\n\nModified agent to checking if node was before registered, based on existence\nof nailgun_uid file. If file exist, only put is call, in other case when we\ntry made post (if call was succes-201 or node exist 409, we call put method)\n\nChange-Id: Id1ef1650cf47c8e5fd7e844362b3fb41afad8fdd\nCloses-Bug:: #1305017\n'}, {'number': 4, 'created': '2014-05-16 09:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/39098410621ec35522a3855fbf77309c81c01be9', 'message': 'Changed order of calls to register new nodes\n\nModified agent to checking if node was before registered, based on existence\nof nailgun_uid file. If file exist, only put is call, in other case when we\ntry made post (if call was succes-201 or node exist 409, we call put method)\n\nChange-Id: Id1ef1650cf47c8e5fd7e844362b3fb41afad8fdd\nCloses-Bug:: #1305017\n'}, {'number': 5, 'created': '2014-05-16 12:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e0ee7c4cfde68e267f1d221470fa6164efe16032', 'message': 'Changed order of calls to register new nodes\n\nModified agent to checking if node was before registered, based on existence\nof nailgun_uid file. If file exist, only put is call, in other case when we\ntry made post (if call was succes-201 or node exist 409, we call put method)\n\nChange-Id: Id1ef1650cf47c8e5fd7e844362b3fb41afad8fdd\nCloses-Bug: #1305017\n'}, {'number': 6, 'created': '2014-05-29 08:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/baff1a57891a8747bef18d2b3b6d990760698da6', 'message': 'Changed order of calls to register new nodes\n\nModified agent to checking if node was before registered, based on existence\nof nailgun_uid file. If file exist, only put is call, in other case when we\ntry made post (if call was succes-201 or node exist 409, we call put method)\n\nChange-Id: Id1ef1650cf47c8e5fd7e844362b3fb41afad8fdd\nCloses-Bug:: #1305017\n'}, {'number': 7, 'created': '2014-05-29 08:21:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f9b6b6c628efbe3005c66a42c31c1b4dd35f75a5', 'message': 'Changed order of calls to register new nodes\n\nModified agent to checking if node was before registered, based on existence\nof nailgun_uid file. If file exist, only put is call, in other case when we\ntry made post (if call was succes-201 or node exist 409, we call put method)\n\nChange-Id: Id1ef1650cf47c8e5fd7e844362b3fb41afad8fdd\nCloses-Bug: #1305017\n'}, {'number': 8, 'created': '2014-05-29 09:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b5610f85730fee699777cae82c55d3ae19d46fd4', 'message': 'Changed order of calls to register new nodes\n\nModified agent to checking if node was before registered, based on existence\nof nailgun_uid file. If file exist, only put is call, in other case when we\ntry made post (if call was succes-201 or node exist 409, we call put method)\n\nChange-Id: Id1ef1650cf47c8e5fd7e844362b3fb41afad8fdd\nCloses-Bug:: #1305017\n'}, {'number': 9, 'created': '2014-05-29 09:28:35.000000000', 'files': ['bin/agent'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/779afd8882b119f7fc4eb69b3edd3e9efd63b42d', 'message': 'Changed order of calls to register new nodes\n\nModified agent to checking if node was before registered, based on existence\nof nailgun_uid file. If file exist, only put is call, in other case when we\ntry made post (if call was succes-201 or node exist 409, we call put method)\n\nChange-Id: Id1ef1650cf47c8e5fd7e844362b3fb41afad8fdd\nCloses-Bug: #1305017\n'}]",13,93711,779afd8882b119f7fc4eb69b3edd3e9efd63b42d,77,9,9,11082,,,0,"Changed order of calls to register new nodes

Modified agent to checking if node was before registered, based on existence
of nailgun_uid file. If file exist, only put is call, in other case when we
try made post (if call was succes-201 or node exist 409, we call put method)

Change-Id: Id1ef1650cf47c8e5fd7e844362b3fb41afad8fdd
Closes-Bug: #1305017
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/11/93711/9 && git format-patch -1 --stdout FETCH_HEAD,['bin/agent'],1,36dcc49a85b26e93fc275359fd10de690c320b31,bg/1305017,"def check_file_content(filename) if File.exist?(filename) File.open(filename, 'r') do |fo| text = fo.read end else text = '' end return text end prev_nailgun_id = check_file_content('/etc/nailgun_uid') if prev_nailgun_id != '' put_res = agent.put if put_res.status == 200 new_id = JSON.parse(put_res.body)['id'] else logger.error put_res.body exit 1 end else new_id = JSON.parse(post_res.body)['id'] elsif post_res.status == 409 put_res = agent.put if put_res.status == 200 new_id = JSON.parse(put_res.body)['id'] else logger.error put_res.body exit 1 end"," put_res = agent.put # nailgun returns 'Invalid MAC specified' for unregistered nodes if [404, 400].include? put_res.status new_id = JSON.parse(post_res.body)[0]['id'] elsif put_res.status == 200 new_id = JSON.parse(put_res.body)['id'] else logger.error put_res.body exit 1",30,9
openstack%2Fhorizon~master~Ib2bf65791899a3c69087749d3a5fcf5061568b5d,openstack/horizon,master,Ib2bf65791899a3c69087749d3a5fcf5061568b5d,Remove string concatenation related to volume attachment,MERGED,2014-10-18 23:18:44.000000000,2014-10-20 14:12:07.000000000,2014-10-20 14:12:06.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 7213}, {'_account_id': 9317}]","[{'number': 1, 'created': '2014-10-18 23:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/32afbe321575a793fa342061625df4956464ba3e', 'message': 'Remove string concatenation related to volume attachment\n\nTranslatable string ""on"" is a part of string concatenation\nand it makes difficult to translate it properly.\n\nChange-Id: Ib2bf65791899a3c69087749d3a5fcf5061568b5d\nCloses-Bug: #1382874\n'}, {'number': 2, 'created': '2014-10-19 20:52:02.000000000', 'files': ['openstack_dashboard/dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html', 'openstack_dashboard/dashboards/project/instances/templates/instances/_detail_overview.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1eb0a6a711930f6deb6f807cf30e85baca671c33', 'message': 'Remove string concatenation related to volume attachment\n\nTranslatable string ""on"" is a part of string concatenation\nand it makes difficult to translate it properly.\n\nChange-Id: Ib2bf65791899a3c69087749d3a5fcf5061568b5d\nCloses-Bug: #1382874\n'}]",3,129448,1eb0a6a711930f6deb6f807cf30e85baca671c33,17,6,2,841,,,0,"Remove string concatenation related to volume attachment

Translatable string ""on"" is a part of string concatenation
and it makes difficult to translate it properly.

Change-Id: Ib2bf65791899a3c69087749d3a5fcf5061568b5d
Closes-Bug: #1382874
",git fetch https://review.opendev.org/openstack/horizon refs/changes/48/129448/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html', 'openstack_dashboard/dashboards/project/instances/templates/instances/_detail_overview.html']",2,32afbe321575a793fa342061625df4956464ba3e,bug/1382874, {% url 'horizon:project:volumes:volumes:detail' volume.id as volume_url %} {% blocktrans with volume_label=volume.name|default:volume.id volume_device=volume.device %} <a href={{ volume_url }}>{{ volume_label }}</a> on {{ volume_device }} {% endblocktrans %}," <a href=""{% url 'horizon:project:volumes:volumes:detail' volume.id %}""> {% if volume.name %} {{ volume.name }} {% else %} {{ volume.id }} {% endif %} </a> <span> {% trans ""on"" %} {{ volume.device }}</span>",8,11
openstack%2Fproject-config~master~I6a47291ed6440e97bd68d7d87ef98172537a4707,openstack/project-config,master,I6a47291ed6440e97bd68d7d87ef98172537a4707,Create zvm-driver project on StackForge,MERGED,2014-10-20 02:46:05.000000000,2014-10-20 14:00:00.000000000,2014-10-20 14:00:00.000000000,"[{'_account_id': 3}, {'_account_id': 5930}, {'_account_id': 6062}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-10-20 02:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5b30475fd3de39507dff0fe856fbbe007f1f8b88', 'message': 'Create zvm-driver project on StackForge\n\nThis project will have a set of drivers to integrate zvm into\nOpenStack.\n\nChange-Id: I6a47291ed6440e97bd68d7d87ef98172537a4707\n'}, {'number': 2, 'created': '2014-10-20 07:23:43.000000000', 'files': ['gerrit/acls/stackforge/zvm-driver.config', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/503d8d5bc1cebe0f3633b0c10e091526efcc88eb', 'message': 'Create zvm-driver project on StackForge\n\nThis project will have a set of drivers to integrate zvm into\nOpenStack.\n\nChange-Id: I6a47291ed6440e97bd68d7d87ef98172537a4707\n'}]",2,129506,503d8d5bc1cebe0f3633b0c10e091526efcc88eb,13,5,2,5930,,,0,"Create zvm-driver project on StackForge

This project will have a set of drivers to integrate zvm into
OpenStack.

Change-Id: I6a47291ed6440e97bd68d7d87ef98172537a4707
",git fetch https://review.opendev.org/openstack/project-config refs/changes/06/129506/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/stackforge/zvm-driver.config', 'gerrit/projects.yaml', 'zuul/layout.yaml']",3,5b30475fd3de39507dff0fe856fbbe007f1f8b88,create-zvm-driver, - name: stackforge/zvm-driver template: - name: merge-check - name: noop-jobs,,22,0
openstack%2Ffuel-stats~master~I2ec40a9904899a72f62c1f29b58ccbe0a1d6a02d,openstack/fuel-stats,master,I2ec40a9904899a72f62c1f29b58ccbe0a1d6a02d,Action logs payload collection added,MERGED,2014-10-14 09:20:58.000000000,2014-10-20 13:57:56.000000000,2014-10-20 13:57:56.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10959}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-10-14 09:20:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-stats/commit/17a669baf566f39c063e5336da717b43a5dc444e', 'message': ""Action logs payload collection added\n\nField 'body' added to 'action_logs' table with its processing in handler\n\nBlueprint: send-anon-usage\n\nChange-Id: I2ec40a9904899a72f62c1f29b58ccbe0a1d6a02d\n""}, {'number': 2, 'created': '2014-10-14 09:49:27.000000000', 'files': ['collector/collector/api/db/migrations/versions/558f628a238_collector_db_schema.py', 'collector/collector/test/resources/test_action_logs.py', 'collector/collector/api/resources/action_logs.py', 'collector/collector/api/schemas/action_logs.json', 'collector/collector/api/db/model.py'], 'web_link': 'https://opendev.org/openstack/fuel-stats/commit/96b6bc7c0bf4bbb81944103473388857f27542da', 'message': ""Action logs payload collection added\n\nField 'body' is added to 'action_logs' table with its processing in handler.\n'body' contains action log record, its structure is checked with json scheme.\n\nBlueprint: send-anon-usage\n\nChange-Id: I2ec40a9904899a72f62c1f29b58ccbe0a1d6a02d\n""}]",2,128215,96b6bc7c0bf4bbb81944103473388857f27542da,16,7,2,8392,,,0,"Action logs payload collection added

Field 'body' is added to 'action_logs' table with its processing in handler.
'body' contains action log record, its structure is checked with json scheme.

Blueprint: send-anon-usage

Change-Id: I2ec40a9904899a72f62c1f29b58ccbe0a1d6a02d
",git fetch https://review.opendev.org/openstack/fuel-stats refs/changes/15/128215/2 && git format-patch -1 --stdout FETCH_HEAD,"['collector/collector/api/db/migrations/versions/558f628a238_collector_db_schema.py', 'collector/collector/api/resources/action_logs.py', 'collector/collector/api/schemas/action_logs.json', 'collector/collector/api/db/model.py']",4,17a669baf566f39c063e5336da717b43a5dc444e,bp/send-anon-usage," body = db.Column(db.Text, nullable=False)",,22,1
openstack%2Ffuel-library~master~Ie2b62d2b96ee9ca9d4ced15d038979561899e910,openstack/fuel-library,master,Ie2b62d2b96ee9ca9d4ced15d038979561899e910,Rename parameter 'tag' to 'vlan_tag' in l23network module,MERGED,2014-07-21 15:47:39.000000000,2014-10-20 13:57:00.000000000,2014-10-20 13:57:00.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8392}, {'_account_id': 8786}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}, {'_account_id': 11827}]","[{'number': 1, 'created': '2014-07-21 15:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0bc6dd229e3881b0a73356053d8b84c3907bda73', 'message': ""Rename parameter 'tag' to 'vlan_tag' in l23network module\n\nIn puppet >3.0 word 'tag' is reserved, so it have to be\nrenamed.\n\nChange-Id: Ie2b62d2b96ee9ca9d4ced15d038979561899e910\nCloses-Bug: 1305600\n""}, {'number': 2, 'created': '2014-07-23 09:08:43.000000000', 'files': ['deployment/puppet/l23network/lib/puppet/type/l2_ovs_bond.rb', 'deployment/puppet/l23network/lib/puppet/type/l2_ovs_patch.rb', 'deployment/puppet/l23network/lib/puppet/provider/l2_ovs_port/ovs.rb', 'deployment/puppet/l23network/manifests/l2/bond.pp', 'deployment/puppet/l23network/lib/puppet/type/l2_ovs_port.rb', 'deployment/puppet/l23network/lib/puppet/provider/l2_ovs_bond/ovs.rb', 'deployment/puppet/l23network/manifests/l2/patch.pp', 'deployment/puppet/l23network/manifests/l2/port.pp', 'deployment/puppet/l23network/lib/puppet/provider/l2_ovs_patch/ovs.rb', 'deployment/puppet/l23network/README.md', 'deployment/puppet/l23network/lib/puppet/parser/functions/generate_network_config.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/54a43a3ab34ecfc113b010b53ce77aa952b327d7', 'message': ""Rename parameter 'tag' to 'vlan_tag' in l23network module\n\nIn puppet >3.0 word 'tag' is reserved, so it have to be\nrenamed.\n\nChange-Id: Ie2b62d2b96ee9ca9d4ced15d038979561899e910\nCloses-Bug: 1305600\n""}]",2,108414,54a43a3ab34ecfc113b010b53ce77aa952b327d7,26,10,2,11827,,,0,"Rename parameter 'tag' to 'vlan_tag' in l23network module

In puppet >3.0 word 'tag' is reserved, so it have to be
renamed.

Change-Id: Ie2b62d2b96ee9ca9d4ced15d038979561899e910
Closes-Bug: 1305600
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/14/108414/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/l23network/lib/puppet/type/l2_ovs_bond.rb', 'deployment/puppet/l23network/lib/puppet/provider/l2_ovs_port/ovs.rb', 'deployment/puppet/l23network/lib/puppet/type/l2_ovs_port.rb', 'deployment/puppet/l23network/manifests/l2/bond.pp', 'deployment/puppet/l23network/lib/puppet/provider/l2_ovs_bond/ovs.rb', 'deployment/puppet/l23network/manifests/l2/port.pp', 'deployment/puppet/l23network/README.md', 'deployment/puppet/l23network/lib/puppet/parser/functions/generate_network_config.rb']",8,0bc6dd229e3881b0a73356053d8b84c3907bda73,bug/1305600," :vlan_tag => 0, :vlan_tag => 0,"," :tag => 0, :tag => 0,",16,16
openstack%2Fhorizon~master~Ide0e461d598b0d623192a5b2455a0ad3340c5683,openstack/horizon,master,Ide0e461d598b0d623192a5b2455a0ad3340c5683,Create buttons in network topology respect quotas,MERGED,2014-09-10 16:50:17.000000000,2014-10-20 13:53:24.000000000,2014-10-20 13:53:23.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2455}, {'_account_id': 6635}, {'_account_id': 6637}, {'_account_id': 6638}, {'_account_id': 7213}, {'_account_id': 9317}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 11592}, {'_account_id': 12355}, {'_account_id': 12826}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-09-10 16:50:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d5875e6cbf7ba71baa3745e806dd319f4d18b13e', 'message': 'Create buttons in network topology respect quotas\n\nNetwork topology create (networks, routers, instances) buttons should respect\nquotas and the buttons should show feedback if the quota is exceeded.\n\nChange-Id: Ide0e461d598b0d623192a5b2455a0ad3340c5683\nCloses-bug: 1367678\n'}, {'number': 2, 'created': '2014-09-11 12:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d41ccab3aee8e264f36ecf93aea9eaeb69b44a6c', 'message': 'Create buttons in network topology respect quotas\n\nNetwork topology create (networks, routers, instances) buttons should respect\nquotas and the buttons should show feedback if the quota is exceeded.\n\nChange-Id: Ide0e461d598b0d623192a5b2455a0ad3340c5683\nCloses-bug: 1367678\n'}, {'number': 3, 'created': '2014-09-11 12:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/669c33d3fb2e043f8b5c59a80f7c6fe7607a41ed', 'message': 'Create buttons in network topology respect quotas\n\nNetwork topology create (networks, routers, instances) buttons should respect\nquotas and the buttons should show feedback if the quota is exceeded.\n\nChange-Id: Ide0e461d598b0d623192a5b2455a0ad3340c5683\nCloses-bug: 1367678\n'}, {'number': 4, 'created': '2014-09-15 14:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5e1d37e88bc239247810362e723e56eac6d8b625', 'message': 'Create buttons in network topology respect quotas\n\nNetwork topology create (networks, routers, instances) buttons should respect\nquotas and the buttons should show feedback if the quota is exceeded.\n\nChange-Id: Ide0e461d598b0d623192a5b2455a0ad3340c5683\nCloses-bug: 1367678\n'}, {'number': 5, 'created': '2014-10-14 20:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1b1e7d71d451f457b6ab07499a78539d7011b6cb', 'message': 'Create buttons in network topology respect quotas\n\nNetwork topology create (networks, routers, instances) buttons should respect\nquotas and the buttons should show feedback if the quota is exceeded.\n\nChange-Id: Ide0e461d598b0d623192a5b2455a0ad3340c5683\nCloses-bug: 1367678\n'}, {'number': 6, 'created': '2014-10-20 11:12:07.000000000', 'files': ['openstack_dashboard/dashboards/project/network_topology/views.py', 'openstack_dashboard/dashboards/project/network_topology/templates/network_topology/index.html', 'openstack_dashboard/dashboards/project/network_topology/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/7081e14fbbf6e8c7efae061329105a3d063a3c67', 'message': 'Create buttons in network topology respect quotas\n\nNetwork topology create (networks, routers, instances) buttons should respect\nquotas and the buttons should show feedback if the quota is exceeded.\n\nChange-Id: Ide0e461d598b0d623192a5b2455a0ad3340c5683\nCloses-bug: 1367678\n'}]",21,120482,7081e14fbbf6e8c7efae061329105a3d063a3c67,51,15,6,6638,,,0,"Create buttons in network topology respect quotas

Network topology create (networks, routers, instances) buttons should respect
quotas and the buttons should show feedback if the quota is exceeded.

Change-Id: Ide0e461d598b0d623192a5b2455a0ad3340c5683
Closes-bug: 1367678
",git fetch https://review.opendev.org/openstack/horizon refs/changes/82/120482/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/network_topology/views.py', 'openstack_dashboard/dashboards/project/network_topology/templates/network_topology/index.html']",2,d5875e6cbf7ba71baa3745e806dd319f4d18b13e,bug/1367678," {% if instance_quota_exceeded %} <a href=""{% url 'horizon:project:network_topology:launchinstance' %}"" id=""instances__action_launch"" class=""btn btn-default btn-sm btn-launch ajax-modal disabled""><span class=""glyphicon glyphicon-cloud-upload""></span> {%trans ""Launch Instance (Quota exceeded)"" %}</a> {% else %} <a href=""{% url 'horizon:project:network_topology:launchinstance' %}"" id=""instances__action_launch"" class=""btn btn-default btn-sm btn-launch ajax-modal""><span class=""glyphicon glyphicon-cloud-upload""></span> {%trans ""Launch Instance"" %}</a> {% endif %} {% if network_quota_exceeded %} <a href=""{% url 'horizon:project:network_topology:createnetwork' %}"" id=""networks__action_create"" class=""btn btn-default btn-sm ajax-modal disabled""><span class=""glyphicon glyphicon-plus""></span> {%trans ""Create Network (Quota exceeded)"" %}</a> {% else %} <a href=""{% url 'horizon:project:network_topology:createnetwork' %}"" id=""networks__action_create"" class=""btn btn-default btn-sm ajax-modal""><span class=""glyphicon glyphicon-plus""></span> {%trans ""Create Network"" %}</a> {% endif %} {% if router_quota_exceeded %} <a href=""{% url 'horizon:project:network_topology:createrouter' %}"" id=""Routers__action_create"" class=""btn btn-default btn-sm ajax-modal disabled""><span class=""glyphicon glyphicon-plus""></span> {%trans ""Create Router (Quota exceeded)"" %}</a> {% else %} <a href=""{% url 'horizon:project:network_topology:createrouter' %}"" id=""Routers__action_create"" class=""btn btn-default btn-sm ajax-modal""><span class=""glyphicon glyphicon-plus""></span> {%trans ""Create Router"" %}</a> {% endif %}"," <a href=""{% url 'horizon:project:network_topology:launchinstance' %}"" id=""instances__action_launch"" class=""btn btn-default btn-sm btn-launch ajax-modal""><span class=""glyphicon glyphicon-cloud-upload""></span> {%trans ""Launch Instance"" %}</a> <a href=""{% url 'horizon:project:network_topology:createnetwork' %}"" id=""networks__action_create"" class=""btn btn-default btn-sm ajax-modal""><span class=""glyphicon glyphicon-plus""></span> {%trans ""Create Network"" %}</a> <a href=""{% url 'horizon:project:network_topology:createrouter' %}"" id=""Routers__action_create"" class=""btn btn-default btn-sm ajax-modal""><span class=""glyphicon glyphicon-plus""></span> {%trans ""Create Router"" %}</a>",79,3
openstack%2Fproject-config~master~Id425d2b6f3e3a4969565ee19fd0f8f2853b09b03,openstack/project-config,master,Id425d2b6f3e3a4969565ee19fd0f8f2853b09b03,Update stackforge/magnetodb acls,MERGED,2014-10-17 14:10:55.000000000,2014-10-20 13:51:22.000000000,2014-10-20 13:51:22.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-10-17 14:10:55.000000000', 'files': ['gerrit/acls/stackforge/magnetodb.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/d89dc187f5d4889eaac1f9034968cd940eaa8d14', 'message': 'Update stackforge/magnetodb acls\n\nAdded rights for creating branches\n\nChange-Id: Id425d2b6f3e3a4969565ee19fd0f8f2853b09b03\n'}]",0,129269,d89dc187f5d4889eaac1f9034968cd940eaa8d14,8,4,1,8188,,,0,"Update stackforge/magnetodb acls

Added rights for creating branches

Change-Id: Id425d2b6f3e3a4969565ee19fd0f8f2853b09b03
",git fetch https://review.opendev.org/openstack/project-config refs/changes/69/129269/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/stackforge/magnetodb.config'],1,d89dc187f5d4889eaac1f9034968cd940eaa8d14,update-magnetodb-acl,"[access ""refs/*""] create = group magnetodb-release ",,3,0
openstack%2Fkeystone~master~I2986e12daea3edf50f299af5927d2a05278e82f7,openstack/keystone,master,I2986e12daea3edf50f299af5927d2a05278e82f7,Use newer python-ldap paging control API,MERGED,2014-10-15 22:46:00.000000000,2014-10-20 13:36:05.000000000,2014-10-20 13:36:04.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1313}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 9098}, {'_account_id': 9500}]","[{'number': 1, 'created': '2014-10-15 22:46:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/57f23a3d292d7f16f1a22330462b7ca069ccef6b', 'message': 'Use newer python-ldap paging control API\n\nThe API for using the LDAP simple paged results control changed\nbetween python-ldap version 2.3 and 2.4. Our current implementation\nfails with an AttributeError when trying to use paging with version\n2.4 of python-ldap.\n\nThis patch detects the capabilities of the underlying python-ldap\nversion and uses the newer API in versions of python-ldap that have\nremoved the older API.\n\nChange-Id: I2986e12daea3edf50f299af5927d2a05278e82f7\nCloses-bug: #1381768\n'}, {'number': 2, 'created': '2014-10-16 00:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a95720d1f4c3a9fbac192aaa21e32e74bf815ed2', 'message': 'Use newer python-ldap paging control API\n\nThe API for using the LDAP simple paged results control changed\nbetween python-ldap version 2.3 and 2.4. Our current implementation\nfails with an AttributeError when trying to use paging with version\n2.4 of python-ldap.\n\nThis patch detects the capabilities of the underlying python-ldap\nversion and uses the newer API in versions of python-ldap that have\nremoved the older API.\n\nChange-Id: I2986e12daea3edf50f299af5927d2a05278e82f7\nCloses-bug: #1381768\n'}, {'number': 3, 'created': '2014-10-16 02:21:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/53888f7787fe98d50bd7ec46ef15fc3581255574', 'message': 'Use newer python-ldap paging control API\n\nThe API for using the LDAP simple paged results control changed\nbetween python-ldap version 2.3 and 2.4. Our current implementation\nfails with an AttributeError when trying to use paging with version\n2.4 of python-ldap.\n\nThis patch detects the capabilities of the underlying python-ldap\nversion and uses the newer API in versions of python-ldap that have\nremoved the older API.\n\nChange-Id: I2986e12daea3edf50f299af5927d2a05278e82f7\nCloses-bug: #1381768\n'}, {'number': 4, 'created': '2014-10-16 02:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/88a7b6720a6a553dcc92c9bf4ddd45872a06562d', 'message': 'Use newer python-ldap paging control API\n\nThe API for using the LDAP simple paged results control changed\nbetween python-ldap version 2.3 and 2.4. Our current implementation\nfails with an AttributeError when trying to use paging with version\n2.4 of python-ldap.\n\nThis patch detects the capabilities of the underlying python-ldap\nversion and uses the newer API in versions of python-ldap that have\nremoved the older API.\n\nChange-Id: I2986e12daea3edf50f299af5927d2a05278e82f7\nCloses-bug: #1381768\n'}, {'number': 5, 'created': '2014-10-16 04:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c0d2b0cea4a2ac5bc531907ebb976a523b6657ac', 'message': 'Use newer python-ldap paging control API\n\nThe API for using the LDAP simple paged results control changed\nbetween python-ldap version 2.3 and 2.4. Our current implementation\nfails with an AttributeError when trying to use paging with version\n2.4 of python-ldap.\n\nThis patch detects the capabilities of the underlying python-ldap\nversion and uses the newer API in versions of python-ldap that have\nremoved the older API.\n\nChange-Id: I2986e12daea3edf50f299af5927d2a05278e82f7\nCloses-bug: #1381768\n'}, {'number': 6, 'created': '2014-10-20 03:14:53.000000000', 'files': ['keystone/tests/unit/common/test_ldap.py', 'keystone/common/ldap/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1be4a15454e6917571bc937e3bb3589e8f79bc55', 'message': 'Use newer python-ldap paging control API\n\nThe API for using the LDAP simple paged results control changed\nbetween python-ldap version 2.3 and 2.4. Our current implementation\nfails with an AttributeError when trying to use paging with version\n2.4 of python-ldap.\n\nThis patch detects the capabilities of the underlying python-ldap\nversion and uses the newer API in versions of python-ldap that have\nremoved the older API.\n\nChange-Id: I2986e12daea3edf50f299af5927d2a05278e82f7\nCloses-bug: #1381768\n'}]",12,128782,1be4a15454e6917571bc937e3bb3589e8f79bc55,25,15,6,9098,,,0,"Use newer python-ldap paging control API

The API for using the LDAP simple paged results control changed
between python-ldap version 2.3 and 2.4. Our current implementation
fails with an AttributeError when trying to use paging with version
2.4 of python-ldap.

This patch detects the capabilities of the underlying python-ldap
version and uses the newer API in versions of python-ldap that have
removed the older API.

Change-Id: I2986e12daea3edf50f299af5927d2a05278e82f7
Closes-bug: #1381768
",git fetch https://review.opendev.org/openstack/keystone refs/changes/82/128782/5 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/ldap/core.py'],1,57f23a3d292d7f16f1a22330462b7ca069ccef6b,bug/1381768," # The API for the simple paged results control changed between # python-ldap 2.3 and 2.4. We need to detect the capabilities # of the python-ldap version we are using. if hasattr(ldap, 'LDAP_CONTROL_PAGE_OID'): lc = ldap.controls.SimplePagedResultsControl( controlType=ldap.LDAP_CONTROL_PAGE_OID, criticality=True, controlValue=(self.page_size, '')) page_ctrl_oid = ldap.LDAP_CONTROL_PAGE_OID else: lc = ldap.controls.SimplePagedResultsControl( criticality=True, size=self.page_size, cookie='') page_ctrl_oid = ldap.controls.SimplePagedResultsControl.controlType if c.controlType == page_ctrl_oid]"," lc = ldap.controls.SimplePagedResultsControl( controlType=ldap.LDAP_CONTROL_PAGE_OID, criticality=True, controlValue=(self.page_size, '')) if c.controlType == ldap.LDAP_CONTROL_PAGE_OID]",17,5
openstack%2Fglance~master~I08b9b6594efb4edce33c2424a2a20d570a6dc9a8,openstack/glance,master,I08b9b6594efb4edce33c2424a2a20d570a6dc9a8,Remove useless strutils,ABANDONED,2014-10-20 08:37:06.000000000,2014-10-20 13:30:26.000000000,,"[{'_account_id': 3}, {'_account_id': 6549}]","[{'number': 1, 'created': '2014-10-20 08:37:06.000000000', 'files': ['openstack-common.conf', 'glance/openstack/common/strutils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/c2b293902d25053c8a7b2412d2c377016ec9ea20', 'message': 'Remove useless strutils\n\nChange-Id: I08b9b6594efb4edce33c2424a2a20d570a6dc9a8\n'}]",0,129549,c2b293902d25053c8a7b2412d2c377016ec9ea20,4,2,1,1669,,,0,"Remove useless strutils

Change-Id: I08b9b6594efb4edce33c2424a2a20d570a6dc9a8
",git fetch https://review.opendev.org/openstack/glance refs/changes/49/129549/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack-common.conf', 'glance/openstack/common/strutils.py']",2,c2b293902d25053c8a7b2412d2c377016ec9ea20,jd/update-oslo,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" System-level utilities and helper functions. """""" import math import re import sys import unicodedata import six from glance.openstack.common.gettextutils import _ UNIT_PREFIX_EXPONENT = { 'k': 1, 'K': 1, 'Ki': 1, 'M': 2, 'Mi': 2, 'G': 3, 'Gi': 3, 'T': 4, 'Ti': 4, } UNIT_SYSTEM_INFO = { 'IEC': (1024, re.compile(r'(^[-+]?\d*\.?\d+)([KMGT]i?)?(b|bit|B)$')), 'SI': (1000, re.compile(r'(^[-+]?\d*\.?\d+)([kMGT])?(b|bit|B)$')), } TRUE_STRINGS = ('1', 't', 'true', 'on', 'y', 'yes') FALSE_STRINGS = ('0', 'f', 'false', 'off', 'n', 'no') SLUGIFY_STRIP_RE = re.compile(r""[^\w\s-]"") SLUGIFY_HYPHENATE_RE = re.compile(r""[-\s]+"") def int_from_bool_as_string(subject): """"""Interpret a string as a boolean and return either 1 or 0. Any string value in: ('True', 'true', 'On', 'on', '1') is interpreted as a boolean True. Useful for JSON-decoded stuff and config file parsing """""" return bool_from_string(subject) and 1 or 0 def bool_from_string(subject, strict=False, default=False): """"""Interpret a string as a boolean. A case-insensitive match is performed such that strings matching 't', 'true', 'on', 'y', 'yes', or '1' are considered True and, when `strict=False`, anything else returns the value specified by 'default'. Useful for JSON-decoded stuff and config file parsing. If `strict=True`, unrecognized values, including None, will raise a ValueError which is useful when parsing values passed in from an API call. Strings yielding False are 'f', 'false', 'off', 'n', 'no', or '0'. """""" if not isinstance(subject, six.string_types): subject = six.text_type(subject) lowered = subject.strip().lower() if lowered in TRUE_STRINGS: return True elif lowered in FALSE_STRINGS: return False elif strict: acceptable = ', '.join( ""'%s'"" % s for s in sorted(TRUE_STRINGS + FALSE_STRINGS)) msg = _(""Unrecognized value '%(val)s', acceptable values are:"" "" %(acceptable)s"") % {'val': subject, 'acceptable': acceptable} raise ValueError(msg) else: return default def safe_decode(text, incoming=None, errors='strict'): """"""Decodes incoming text/bytes string using `incoming` if they're not already unicode. :param incoming: Text's current encoding :param errors: Errors handling policy. See here for valid values http://docs.python.org/2/library/codecs.html :returns: text or a unicode `incoming` encoded representation of it. :raises TypeError: If text is not an instance of str """""" if not isinstance(text, (six.string_types, six.binary_type)): raise TypeError(""%s can't be decoded"" % type(text)) if isinstance(text, six.text_type): return text if not incoming: incoming = (sys.stdin.encoding or sys.getdefaultencoding()) try: return text.decode(incoming, errors) except UnicodeDecodeError: # Note(flaper87) If we get here, it means that # sys.stdin.encoding / sys.getdefaultencoding # didn't return a suitable encoding to decode # text. This happens mostly when global LANG # var is not set correctly and there's no # default encoding. In this case, most likely # python will use ASCII or ANSI encoders as # default encodings but they won't be capable # of decoding non-ASCII characters. # # Also, UTF-8 is being used since it's an ASCII # extension. return text.decode('utf-8', errors) def safe_encode(text, incoming=None, encoding='utf-8', errors='strict'): """"""Encodes incoming text/bytes string using `encoding`. If incoming is not specified, text is expected to be encoded with current python's default encoding. (`sys.getdefaultencoding`) :param incoming: Text's current encoding :param encoding: Expected encoding for text (Default UTF-8) :param errors: Errors handling policy. See here for valid values http://docs.python.org/2/library/codecs.html :returns: text or a bytestring `encoding` encoded representation of it. :raises TypeError: If text is not an instance of str """""" if not isinstance(text, (six.string_types, six.binary_type)): raise TypeError(""%s can't be encoded"" % type(text)) if not incoming: incoming = (sys.stdin.encoding or sys.getdefaultencoding()) if isinstance(text, six.text_type): return text.encode(encoding, errors) elif text and encoding != incoming: # Decode text before encoding it with `encoding` text = safe_decode(text, incoming, errors) return text.encode(encoding, errors) else: return text def string_to_bytes(text, unit_system='IEC', return_int=False): """"""Converts a string into an float representation of bytes. The units supported for IEC :: Kb(it), Kib(it), Mb(it), Mib(it), Gb(it), Gib(it), Tb(it), Tib(it) KB, KiB, MB, MiB, GB, GiB, TB, TiB The units supported for SI :: kb(it), Mb(it), Gb(it), Tb(it) kB, MB, GB, TB Note that the SI unit system does not support capital letter 'K' :param text: String input for bytes size conversion. :param unit_system: Unit system for byte size conversion. :param return_int: If True, returns integer representation of text in bytes. (default: decimal) :returns: Numerical representation of text in bytes. :raises ValueError: If text has an invalid value. """""" try: base, reg_ex = UNIT_SYSTEM_INFO[unit_system] except KeyError: msg = _('Invalid unit system: ""%s""') % unit_system raise ValueError(msg) match = reg_ex.match(text) if match: magnitude = float(match.group(1)) unit_prefix = match.group(2) if match.group(3) in ['b', 'bit']: magnitude /= 8 else: msg = _('Invalid string format: %s') % text raise ValueError(msg) if not unit_prefix: res = magnitude else: res = magnitude * pow(base, UNIT_PREFIX_EXPONENT[unit_prefix]) if return_int: return int(math.ceil(res)) return res def to_slug(value, incoming=None, errors=""strict""): """"""Normalize string. Convert to lowercase, remove non-word characters, and convert spaces to hyphens. Inspired by Django's `slugify` filter. :param value: Text to slugify :param incoming: Text's current encoding :param errors: Errors handling policy. See here for valid values http://docs.python.org/2/library/codecs.html :returns: slugified unicode representation of `value` :raises TypeError: If text is not an instance of str """""" value = safe_decode(value, incoming, errors) # NOTE(aababilov): no need to use safe_(encode|decode) here: # encodings are always ""ascii"", error handling is always ""ignore"" # and types are always known (first: unicode; second: str) value = unicodedata.normalize(""NFKD"", value).encode( ""ascii"", ""ignore"").decode(""ascii"") value = SLUGIFY_STRIP_RE.sub("""", value).strip().lower() return SLUGIFY_HYPHENATE_RE.sub(""-"", value) ",0,240
openstack%2Fapi-site~master~If3b24b6de5815e5adfdc9720d885077e56ee086c,openstack/api-site,master,If3b24b6de5815e5adfdc9720d885077e56ee086c,Removes XML samples from Compute API v2.1,MERGED,2014-09-25 17:03:53.000000000,2014-10-20 13:26:44.000000000,2014-10-20 13:26:44.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-09-25 17:03:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/cc592bb5b05449b25600c5dadfa892696243407a', 'message': 'Removes XML samples from Compute API v2.1\n\n- WIP: still working on extensions\n\nChange-Id: If3b24b6de5815e5adfdc9720d885077e56ee086c\nCloses-bug: 1373974\n'}, {'number': 2, 'created': '2014-09-25 18:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/4b6df6243b3fadd30e48e3e5e12dc316ada5566e', 'message': 'Removes XML samples from Compute API v2.1\n\n- WIP: still working on extensions\n\nChange-Id: If3b24b6de5815e5adfdc9720d885077e56ee086c\nCloses-bug: 1373974\n'}, {'number': 3, 'created': '2014-09-25 18:28:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/14f6843eedc5bf754b6237d5755bd766ecc627fc', 'message': 'Removes XML samples from Compute API v2.1\n\n- WIP: still working on building\n\nChange-Id: If3b24b6de5815e5adfdc9720d885077e56ee086c\nCloses-bug: 1373974\n'}, {'number': 4, 'created': '2014-09-25 22:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/82710549cc603bf3ec63b5d6fb582c0ae8418394', 'message': 'Removes XML samples from Compute API v2.1\n\n- WIP: still working on building\n\nChange-Id: If3b24b6de5815e5adfdc9720d885077e56ee086c\nCloses-bug: 1373974\n'}, {'number': 5, 'created': '2014-10-14 21:30:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/df1b87636d1edf242cfa390694607674c72912c5', 'message': 'Removes XML samples from Compute API v2.1\n\n- WIP: still working on building\n\nChange-Id: If3b24b6de5815e5adfdc9720d885077e56ee086c\nCloses-bug: 1373974\n'}, {'number': 6, 'created': '2014-10-15 17:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/25e19f854e77e7566a0c03ca293a7b7bb37b24b5', 'message': 'Removes XML samples from Compute API v2.1\n\nChange-Id: If3b24b6de5815e5adfdc9720d885077e56ee086c\nCloses-bug: 1373974\n'}, {'number': 7, 'created': '2014-10-15 19:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/c207551d55bc9268b049dc0ad549b789d98e7846', 'message': 'Removes XML samples from Compute API v2.1\n\nChange-Id: If3b24b6de5815e5adfdc9720d885077e56ee086c\nCloses-bug: 1373974\n'}, {'number': 8, 'created': '2014-10-16 20:33:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/2eecd77a8bcc0e1d8a139bc29be6eaed1d32ad5f', 'message': 'Removes XML samples from Compute API v2.1\n\nChange-Id: If3b24b6de5815e5adfdc9720d885077e56ee086c\nCloses-bug: 1373974\n'}, {'number': 9, 'created': '2014-10-17 20:09:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/02f345f631d379970225eefca0d4668d4cc4aaf2', 'message': 'Removes XML samples from Compute API v2.1\n\nChange-Id: If3b24b6de5815e5adfdc9720d885077e56ee086c\nCloses-bug: 1373974\n'}, {'number': 10, 'created': '2014-10-17 21:27:58.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-evacuate/server-evacuate-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-server-attributes/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-agents/agent-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-ips/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-server-attributes/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-security-groups/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-user-data/userdata-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-action-rebuild.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-status/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-add-tenant-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-flavors-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/host-get-shutdown.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-remove-tenant-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-instance-usage-audit-log/inst-usage-audit-log-index-with-before-get-resp.xml', 'api-ref/src/docbkx/ch_compute-v2.1.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregates-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/consoles/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-metadata-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-instance-usage-audit-log-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-extended-availability-zone-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-cells/cells-capacities-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-migrate.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/limits/limit-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-usage/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-deferred-delete-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/service-disable-put-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/all_extensions/servers-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-backup-server.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-rescue.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/servers-details-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-availability-zone/availability-zone-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregates-add-host-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-pci/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-server-attributes/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-usage/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-pci/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-pci/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-create-image.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-status/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-remote-consoles/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/servers-details-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-server-attributes/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-metadata/server-metadata-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-status/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-class-sets/quota-classes-update-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/user-quotas-update-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-put-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-availability-zone/availability-zone-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-status/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-agents/agent-update-put-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-flavor-rxtx/flavor-rxtx-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/quotas-update-force-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-agents/agents-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-simple-tenant-usage-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-ips/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-class-sets/quota-classes-update-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-attach-interfaces/attach-interfaces-show-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-remote-consoles/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-shelve/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-evacuate-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-config-drive-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-remove-host-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-class-sets/quota-classes-show-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/consoles/consoles-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-limits-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/quotas-update-force-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-flavor-manage-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-cells/cells-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-flavor-rxtx/flavor-rxtx-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/compute-versions-response.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregates-metadata-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-extra-specs/flavor-extra-specs-update-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-cells-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/quotas-update-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-reboot.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/service-enable-put-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-availability-zone/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-uptime-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-agents/agent-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavors/flavors-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-availability-zone/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-flavor-rxtx/flavor-rxtx-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/all_extensions/servers-details-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-deferred-delete/restore-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-shelve/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-metadata/server-metadata-all-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-deferred-delete/force-delete-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-availability-zone/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/service-disable-log-put-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-unrescue-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-versions-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-get-resp-unrescue.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-config-drive/servers-config-drive-details-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-manage/flavor-create-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/keypairs/keypairs-import-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hide-server-addresses/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-hypervisors-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/service-disable-log-put-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/servers-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/quotas-show-defaults-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-metadata/server-metadata-all-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-simple-tenant-usage/simple-tenant-usage-get.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-flavor-access-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-metadata/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/host-get-startup.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-create-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-server-usage-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/all_extensions/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-add-tenant-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/keypairs/keypairs-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-revert-resize.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-resize-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-rebuild-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-remove-tenant-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-attach-interfaces/attach-interfaces-create-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-quota-sets-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavors/flavors-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-extra-specs/flavor-extra-specs-create-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/keypairs/keypairs-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/version-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/services-list-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-statistics-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/extension-info/extensions-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-multinic/multinic-remove-fixed-ip-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/quotas-update-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/host-put-maintenance-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-get-resp-rescue.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-password/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-unlock-server.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-simple-tenant-usage/simple-tenant-usage-get-specific.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/consoles/consoles-list-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-show-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/detach-volume-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-rescue-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-aggregates-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/keypairs/keypairs-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-resize.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/attach-volume-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-ips/server-ips-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hide-server-addresses/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-action-rebuild-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-security-groups/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-flavor-rxtx-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-resume.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-cells/cells-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/list-servers-detail-get.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-pause.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-deferred-delete/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-remote-consoles/get-spice-console-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/hosts-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/all_extensions/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-multinic/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/host-put-maintenance-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-manage/flavor-create-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-confirm-resize.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-extended-server-attributes-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-evacuate/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-console-output/console-output-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/host-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-diagnostics/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/service-enable-put-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-console-output/console-output-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-update-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-put-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-shelve/os-shelve.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-extra-specs/flavor-extra-specs-update-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-extra-specs/flavor-extra-specs-create-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-create-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-extended-status-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavors/flavor-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-reset-network.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-attach-interfaces/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-availability-zone/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-extra-specs/flavor-extra-specs-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hide-server-addresses/servers-details-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-evacuate/server-evacuate-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-instance-actions/instance-actions-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/quotas-show-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-remote-consoles/get-vnc-console-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-config-drive/server-config-drive-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/swap-volume-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-action-rebuild-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/extension-info/extensions-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-availability-zone/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/consoles/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-instance-actions/instance-action-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hide-server-addresses/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-usage/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-add-host-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-multinic/multinic-add-fixed-ip-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-search-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-diagnostics/server-diagnostics-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-agents/agent-update-put-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-scheduler-hints/scheduler-hints-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-password/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregates-remove-host-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-update-put-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/keypairs/keypairs-import-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-config-drive/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-rebuild.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-remote-consoles-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/user-quotas-update-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-attach-interfaces/attach-interfaces-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-update-put-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-update-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-instance-actions-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-hosts-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-lock-server.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-migrations/migrations-get.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-metadata/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-diagnostics/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-extensions-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-config-drive/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-ips/server-ips-network-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-action-rebuild-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-attach-interfaces/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-simple-tenant-usage/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-show-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-agents-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-console-output/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-certificates-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-certificates/certificate-create-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/service-disable-put-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-password/admin-password-change-password.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-attach-interfaces/attach-interfaces-create-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-usage/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-flavorspecs-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/user-quotas-show-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-availability-zone/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-remote-consoles/get-vnc-console-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-admin-actions-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-inject-network-info.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-pci/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-migrations-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hide-server-addresses/servers-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-quota-class-sets-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/host-get-reboot.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-simple-tenant-usage/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-evacuate/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-metadata/server-metadata-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-live-migrate.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-cells/cells-list-empty-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-scheduler-hints/scheduler-hints-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/all_extensions/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-user-data/userdata-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-security-groups/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-instance-usage-audit-log/inst-usage-audit-log-index-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-extra-specs/flavor-extra-specs-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-multinic-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-reset-server-state.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-flavor-rxtx/flavor-rxtx-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-suspend.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-console-output/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-deferred-delete/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-unpause.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregates-list-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-servers-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-multinic/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-security-groups/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-remote-consoles/get-spice-console-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-certificates/certificate-get-root-resp.xml'], 'web_link': 'https://opendev.org/openstack/api-site/commit/e647ec0e7e318abbba10d5ab11c8b720edd37fae', 'message': 'Removes XML samples from Compute API v2.1\n\nChange-Id: If3b24b6de5815e5adfdc9720d885077e56ee086c\nCloses-bug: 1373974\n'}]",2,124113,e647ec0e7e318abbba10d5ab11c8b720edd37fae,31,4,10,964,,,0,"Removes XML samples from Compute API v2.1

Change-Id: If3b24b6de5815e5adfdc9720d885077e56ee086c
Closes-bug: 1373974
",git fetch https://review.opendev.org/openstack/api-site refs/changes/13/124113/8 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-evacuate/server-evacuate-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-server-attributes/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-agents/agent-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-ips/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-server-attributes/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-security-groups/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-user-data/userdata-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-action-rebuild.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-status/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-add-tenant-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/host-get-shutdown.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-remove-tenant-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-instance-usage-audit-log/inst-usage-audit-log-index-with-before-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregates-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/consoles/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-metadata-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-cells/cells-capacities-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-migrate.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/limits/limit-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-usage/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/service-disable-put-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/all_extensions/servers-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-backup-server.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-rescue.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/servers-details-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-availability-zone/availability-zone-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregates-add-host-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-pci/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-server-attributes/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-usage/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-pci/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-pci/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-create-image.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-status/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-remote-consoles/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/servers-details-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-server-attributes/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-metadata/server-metadata-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-status/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-class-sets/quota-classes-update-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/user-quotas-update-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-put-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-availability-zone/availability-zone-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-status/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-agents/agent-update-put-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-flavor-rxtx/flavor-rxtx-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/quotas-update-force-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-agents/agents-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-ips/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-class-sets/quota-classes-update-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-attach-interfaces/attach-interfaces-show-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-remote-consoles/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-shelve/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-remove-host-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-class-sets/quota-classes-show-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/consoles/consoles-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/quotas-update-force-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-cells/cells-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-flavor-rxtx/flavor-rxtx-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/compute-versions-response.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregates-metadata-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-extra-specs/flavor-extra-specs-update-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/quotas-update-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-reboot.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/service-enable-put-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-availability-zone/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-uptime-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-agents/agent-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavors/flavors-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-availability-zone/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-flavor-rxtx/flavor-rxtx-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/all_extensions/servers-details-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-deferred-delete/restore-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-shelve/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-metadata/server-metadata-all-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-deferred-delete/force-delete-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-availability-zone/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/service-disable-log-put-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-unrescue-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-get-resp-unrescue.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-config-drive/servers-config-drive-details-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-manage/flavor-create-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/keypairs/keypairs-import-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hide-server-addresses/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/service-disable-log-put-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/servers-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/quotas-show-defaults-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-metadata/server-metadata-all-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-simple-tenant-usage/simple-tenant-usage-get.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-metadata/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/host-get-startup.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-create-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/all_extensions/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-add-tenant-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/keypairs/keypairs-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-revert-resize.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-resize-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-rebuild-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-remove-tenant-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-attach-interfaces/attach-interfaces-create-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavors/flavors-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-extra-specs/flavor-extra-specs-create-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/keypairs/keypairs-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/version-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/services-list-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-statistics-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/extension-info/extensions-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-multinic/multinic-remove-fixed-ip-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/quotas-update-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/host-put-maintenance-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-get-resp-rescue.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-password/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-unlock-server.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-simple-tenant-usage/simple-tenant-usage-get-specific.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/consoles/consoles-list-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-show-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/detach-volume-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-rescue-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/keypairs/keypairs-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-resize.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/attach-volume-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-ips/server-ips-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hide-server-addresses/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-action-rebuild-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-security-groups/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-resume.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-cells/cells-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/list-servers-detail-get.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-pause.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-deferred-delete/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-remote-consoles/get-spice-console-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/hosts-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/all_extensions/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-multinic/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/host-put-maintenance-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-manage/flavor-create-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-confirm-resize.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-evacuate/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-console-output/console-output-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/host-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-diagnostics/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/service-enable-put-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-console-output/console-output-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-update-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-put-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-shelve/os-shelve.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-extra-specs/flavor-extra-specs-update-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-extra-specs/flavor-extra-specs-create-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-create-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavors/flavor-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-reset-network.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-attach-interfaces/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-availability-zone/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-extra-specs/flavor-extra-specs-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hide-server-addresses/servers-details-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-evacuate/server-evacuate-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-instance-actions/instance-actions-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/quotas-show-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-remote-consoles/get-vnc-console-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-config-drive/server-config-drive-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/swap-volume-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-access-ips/server-action-rebuild-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/extension-info/extensions-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-availability-zone/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/consoles/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-instance-actions/instance-action-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hide-server-addresses/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-usage/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-add-host-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-multinic/multinic-add-fixed-ip-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-search-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-diagnostics/server-diagnostics-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-agents/agent-update-put-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-scheduler-hints/scheduler-hints-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-password/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregates-remove-host-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-update-put-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/keypairs/keypairs-import-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-config-drive/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/servers/server-action-rebuild.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/user-quotas-update-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-attach-interfaces/attach-interfaces-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-update-put-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-update-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-lock-server.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-migrations/migrations-get.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-metadata/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-diagnostics/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-config-drive/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-ips/server-ips-network-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-action-rebuild-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-attach-interfaces/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-simple-tenant-usage/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-show-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-console-output/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-certificates/certificate-create-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-services/service-disable-put-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-password/admin-password-change-password.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-attach-interfaces/attach-interfaces-create-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-server-usage/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-quota-sets/user-quotas-show-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-availability-zone/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-remote-consoles/get-vnc-console-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-inject-network-info.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-pci/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hide-server-addresses/servers-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hosts/host-get-reboot.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-simple-tenant-usage/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-evacuate/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/server-metadata/server-metadata-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-live-migrate.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-cells/cells-list-empty-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-scheduler-hints/scheduler-hints-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/all_extensions/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-access/flavor-access-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-user-data/userdata-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-security-groups/server-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/servers-detail-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-instance-usage-audit-log/inst-usage-audit-log-index-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-rescue/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/flavor-extra-specs/flavor-extra-specs-list-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-extended-volumes/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-reset-server-state.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-flavor-rxtx/flavor-rxtx-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-suspend.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-console-output/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-deferred-delete/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/admin-actions-unpause.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-admin-actions/server-post-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregate-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-aggregates/aggregates-list-get-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-hypervisors/hypervisors-servers-resp.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-multinic/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-security-groups/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-remote-consoles/get-spice-console-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-certificates/certificate-get-root-resp.xml']",254,cc592bb5b05449b25600c5dadfa892696243407a,bug/1373974,,"<?xml version='1.0' encoding='UTF-8'?> <certificate private_key=""None"" data=""-----BEGIN CERTIFICATE-----&#10;MIICyzCCAjSgAwIBAgIJAJ8zSIxUp/m4MA0GCSqGSIb3DQEBBAUAME4xEjAQBgNV&#10;BAoTCU5PVkEgUk9PVDEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzETMBEGA1UECBMK&#10;Q2FsaWZvcm5pYTELMAkGA1UEBhMCVVMwHhcNMTIxMDE3MDEzMzM5WhcNMTMxMDE3&#10;MDEzMzM5WjBOMRIwEAYDVQQKEwlOT1ZBIFJPT1QxFjAUBgNVBAcTDU1vdW50YWlu&#10;IFZpZXcxEzARBgNVBAgTCkNhbGlmb3JuaWExCzAJBgNVBAYTAlVTMIGfMA0GCSqG&#10;SIb3DQEBAQUAA4GNADCBiQKBgQDXW4QfQQxJG4MqurqK8nU/Lge0mfNKxXj/Gwvg&#10;2sQVwxzmKfoxih8Nn6yt0yHMNjhoji1UoWI03TXUnPZRAZmsypGKZeBd7Y1ZOCPB&#10;XGZVGrQm+PB2kZU+3cD8fVKcueMLLeZ+LRt5d0njnoKhc5xjqMlfFPimHMba4OL6&#10;TnYzPQIDAQABo4GwMIGtMAwGA1UdEwQFMAMBAf8wHQYDVR0OBBYEFKyoKu4SMOFM&#10;gx5Ec7p0nrCkabvxMH4GA1UdIwR3MHWAFKyoKu4SMOFMgx5Ec7p0nrCkabvxoVKk&#10;UDBOMRIwEAYDVQQKEwlOT1ZBIFJPT1QxFjAUBgNVBAcTDU1vdW50YWluIFZpZXcx&#10;EzARBgNVBAgTCkNhbGlmb3JuaWExCzAJBgNVBAYTAlVTggkAnzNIjFSn+bgwDQYJ&#10;KoZIhvcNAQEEBQADgYEAXuvXlu1o/SVvykSLhHW8QiAY00yzN/eDzYmZGomgiuoO&#10;/x+ayVzbrz1UWZnBD+lC4hll2iELSmf22LjLoF+s/9NyPqHxGL3FrfatBkndaiF8&#10;Ax/TMEyCPl7IQWi+3zzatqOKHSHiG7a9SGn/7o2aNTIWKVulfy5GvmbBjBM/0UE=&#10;-----END CERTIFICATE-----&#10;""/>",13,2578
openstack%2Fsecurity-doc~master~I630b68d650f22b8ea32225abb68e24fce5dce2c7,openstack/security-doc,master,I630b68d650f22b8ea32225abb68e24fce5dce2c7,"Fix bug 1344295, rearranging sentence structure for clarity",ABANDONED,2014-10-20 08:34:52.000000000,2014-10-20 13:24:17.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-20 08:34:52.000000000', 'files': ['security-guide/section_security-services-for-instances.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/b8e6fbb5458dd0beda650ee4b5b9666474b7384d', 'message': 'Fix bug 1344295, rearranging sentence structure for clarity\n\nChange-Id: I630b68d650f22b8ea32225abb68e24fce5dce2c7\n'}]",0,129546,b8e6fbb5458dd0beda650ee4b5b9666474b7384d,4,2,1,13631,,,0,"Fix bug 1344295, rearranging sentence structure for clarity

Change-Id: I630b68d650f22b8ea32225abb68e24fce5dce2c7
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/46/129546/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/section_security-services-for-instances.xml'],1,b8e6fbb5458dd0beda650ee4b5b9666474b7384d,bug/1344295," <para>In a cloud environment, users work with either pre-installed images or images they upload themselves. In both cases, users should be able to ensure the image they are utilizing has not been tampered with. This requires a method of validation – such as a checksum for the known good image – as well as verification of a running instance. While there are current best practices around these actions there are also several gaps in the process.</para>"," <para>With regards to images, users will be working with pre-installed images or images that they upload themselves. In both cases, users will want to ensure that the image they are ultimately running has not been tampered with. This requires some source of truth such as a checksum for the known good version of an image as well as verification of the running image. This section describes the current best practices around image handling, while also calling out some of the existing gaps in this space.</para>",1,1
openstack%2Fsecurity-doc~master~Ib540788b2f7cf3f254092c55fbd15720813d54a3,openstack/security-doc,master,Ib540788b2f7cf3f254092c55fbd15720813d54a3,"Fix bug 1344295, rearranging senctence structure for clarity",ABANDONED,2014-10-20 08:26:01.000000000,2014-10-20 13:23:54.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-20 08:26:01.000000000', 'files': ['security-guide/section_security-services-for-instances.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/e7b87ae9b126680534e0d2666e9ef008e9d3ee8e', 'message': 'Fix bug 1344295, rearranging senctence structure for clarity\n\nChange-Id: Ib540788b2f7cf3f254092c55fbd15720813d54a3\n'}]",0,129543,e7b87ae9b126680534e0d2666e9ef008e9d3ee8e,4,2,1,13631,,,0,"Fix bug 1344295, rearranging senctence structure for clarity

Change-Id: Ib540788b2f7cf3f254092c55fbd15720813d54a3
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/43/129543/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/section_security-services-for-instances.xml'],1,e7b87ae9b126680534e0d2666e9ef008e9d3ee8e,bug/1344295," <para>In a cloud environment, users work with either pre-installed images or images they upload themselves. In both cases, users should be able to ensure the image they are utilizing has not been tampered with. This requires a method of validation – such as a checksum for the known good image – as well as verification of a running instance. While there are current best practices around these actions there are also several gaps in the process.</para>"," <para>With regards to images, users will be working with pre-installed images or images that they upload themselves. In both cases, users will want to ensure that the image they are ultimately running has not been tampered with. This requires some source of truth such as a checksum for the known good version of an image as well as verification of the running image. This section describes the current best practices around image handling, while also calling out some of the existing gaps in this space.</para>",1,1
openstack%2Ffuel-library~master~I4da8070143e401f7a9246e72eda35e601b8c6386,openstack/fuel-library,master,I4da8070143e401f7a9246e72eda35e601b8c6386,Increase settings for dnsmasq and sysctl,MERGED,2014-10-17 10:58:56.000000000,2014-10-20 13:13:02.000000000,2014-10-20 13:13:01.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8084}, {'_account_id': 8786}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 9546}, {'_account_id': 9705}, {'_account_id': 12867}]","[{'number': 1, 'created': '2014-10-17 10:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/be561b01522ff25933c42b486bf9a17a2c9b60df', 'message': 'Increase settings for dnsmasq and sysctl\n\n* Make a new variable dhcp_lease_max. It increases the number of\n  available leases from 1000 to 1800. It allows to provision nodes on\n  scale, when Debian Installer or Anaconda looses IP in the middle of\n  install.\n* Make a new variable lease_time. It increases the default lease size\n  to 120m, up from the default 60m.\n* Add cache-size to dnsmasq template. dnsmasq will keep more entries in\n  case.\n* Increased neighbour table on master node to keep more ARP requests\n  that come in parallel once deployment is started. This change also\n  removes unneed broadcast traffic. New values are:\n  net.ipv4.neigh.default.gc_thresh1 = 256\n  net.ipv4.neigh.default.gc_thresh2 = 1024\n  net.ipv4.neigh.default.gc_thresh3 = 2048\n* Fix linting for server.pp\n\nRelated-Bug: #1376680\nRelated-Bug: #1379917\nRelated-Bug: 1381997\nblueprint 100-nodes-support\nDocImpact\n\nChange-Id: I4da8070143e401f7a9246e72eda35e601b8c6386\n'}, {'number': 2, 'created': '2014-10-17 11:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8a698f11def4b5262d507b74dc4fe82ef3a33bfa', 'message': 'Increase settings for dnsmasq and sysctl\n\n* Make a new variable dhcp_lease_max. It increases the number of\n  available leases from 1000 to 1800. It allows to provision nodes on\n  scale, when Debian Installer or Anaconda looses IP in the middle of\n  install.\n* Make a new variable lease_time. It increases the default lease size\n  to 120m, up from the default 60m.\n* Add cache-size to dnsmasq template. dnsmasq will keep more entries in\n  case.\n* Increased neighbour table on master node to keep more ARP requests\n  that come in parallel once deployment is started. This change also\n  removes unneed broadcast traffic. New values are:\n  net.ipv4.neigh.default.gc_thresh1 = 256\n  net.ipv4.neigh.default.gc_thresh2 = 1024\n  net.ipv4.neigh.default.gc_thresh3 = 2048\n* Fix linting for server.pp\n\nRelated-Bug: #1376680\nRelated-Bug: #1379917\nRelated-Bug: #1381997\nblueprint 100-nodes-support\nDocImpact\n\nChange-Id: I4da8070143e401f7a9246e72eda35e601b8c6386\n'}, {'number': 3, 'created': '2014-10-20 09:59:35.000000000', 'files': ['deployment/puppet/cobbler/manifests/server.pp', 'deployment/puppet/cobbler/templates/dnsmasq.template.erb', 'deployment/puppet/nailgun/manifests/host.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3070f3fa3c6d1b227242fd2a00a7babfc73424f5', 'message': 'Increase settings for dnsmasq and sysctl\n\n* Make a new variable dhcp_lease_max. It increases the number of\n  available leases from 1000 to 1800. It allows to provision nodes on\n  scale, when Debian Installer or Anaconda looses IP in the middle of\n  install.\n* Make a new variable lease_time. It increases the default lease size\n  to 120m, up from the default 60m.\n* Add cache-size to dnsmasq template. dnsmasq will keep more entries in\n  case.\n* Increased neighbour table on master node to keep more ARP requests\n  that come in parallel once deployment is started. This change also\n  removes unneed broadcast traffic. New values are:\n  net.ipv4.neigh.default.gc_thresh1 = 256\n  net.ipv4.neigh.default.gc_thresh2 = 1024\n  net.ipv4.neigh.default.gc_thresh3 = 2048\n* Fix linting\n\nRelated-Bug: #1376680\nRelated-Bug: #1379917\nRelated-Bug: #1381997\nblueprint 100-nodes-support\nDocImpact\n\nChange-Id: I4da8070143e401f7a9246e72eda35e601b8c6386\n'}]",13,129203,3070f3fa3c6d1b227242fd2a00a7babfc73424f5,31,11,3,11090,,,0,"Increase settings for dnsmasq and sysctl

* Make a new variable dhcp_lease_max. It increases the number of
  available leases from 1000 to 1800. It allows to provision nodes on
  scale, when Debian Installer or Anaconda looses IP in the middle of
  install.
* Make a new variable lease_time. It increases the default lease size
  to 120m, up from the default 60m.
* Add cache-size to dnsmasq template. dnsmasq will keep more entries in
  case.
* Increased neighbour table on master node to keep more ARP requests
  that come in parallel once deployment is started. This change also
  removes unneed broadcast traffic. New values are:
  net.ipv4.neigh.default.gc_thresh1 = 256
  net.ipv4.neigh.default.gc_thresh2 = 1024
  net.ipv4.neigh.default.gc_thresh3 = 2048
* Fix linting

Related-Bug: #1376680
Related-Bug: #1379917
Related-Bug: #1381997
blueprint 100-nodes-support
DocImpact

Change-Id: I4da8070143e401f7a9246e72eda35e601b8c6386
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/03/129203/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/cobbler/manifests/server.pp', 'deployment/puppet/cobbler/templates/dnsmasq.template.erb', 'deployment/puppet/nailgun/manifests/host.pp']",3,be561b01522ff25933c42b486bf9a17a2c9b60df,bp/100-nodes-support," owner => 'root', owner => 'root', file { ""/etc/dhcp/dhcp-enter-hooks"": content => template(""nailgun/dhcp-enter-hooks.erb""), owner => 'root', group => 'root', mode => '0755', } file { ""/etc/resolv.conf"": content => template(""nailgun/resolv.conf.erb""), owner => 'root', group => 'root', mode => '0644', sysctl::value{'kernel.printk': value => '4 1 1 7'} #Increase values for neighbour table sysctl::value{'net.ipv4.neigh.default.gc_thresh1': value => '256'} sysctl::value{'net.ipv4.neigh.default.gc_thresh2': value => '1024'} sysctl::value{'net.ipv4.neigh.default.gc_thresh3': value => '2048'}"," owner => 'root', owner => 'root', file { ""/etc/dhcp/dhcp-enter-hooks"": content => template(""nailgun/dhcp-enter-hooks.erb""), owner => 'root', group => 'root', mode => '0755', } file { ""/etc/resolv.conf"": content => template(""nailgun/resolv.conf.erb""), owner => 'root', group => 'root', mode => '0644', sysctl::value{'kernel.printk': value=>'4 1 1 7'}",98,73
openstack%2Ftraining-guides~master~Ia242681aaed1878f4195f6eed14902e5d62a2659,openstack/training-guides,master,Ia242681aaed1878f4195f6eed14902e5d62a2659,changes to section_vm-provisioning-walk-through,MERGED,2014-10-16 22:26:25.000000000,2014-10-20 12:56:41.000000000,2014-10-20 12:56:40.000000000,"[{'_account_id': 3}, {'_account_id': 11109}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-10-16 22:26:25.000000000', 'files': ['doc/training-guides/common/section_vm-provisioning-walk-through.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/902ed6c6a60b0f952d43ac89c8293b2dbb8ca19e', 'message': 'changes to section_vm-provisioning-walk-through\n\nchanged maybe to may be\nadded a before public IP address\nfixed sentence, removed And\nchanged interfaces plural to interface\n\nChange-Id: Ia242681aaed1878f4195f6eed14902e5d62a2659\n'}]",0,129084,902ed6c6a60b0f952d43ac89c8293b2dbb8ca19e,7,3,1,9382,,,0,"changes to section_vm-provisioning-walk-through

changed maybe to may be
added a before public IP address
fixed sentence, removed And
changed interfaces plural to interface

Change-Id: Ia242681aaed1878f4195f6eed14902e5d62a2659
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/84/129084/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/common/section_vm-provisioning-walk-through.xml'],1,902ed6c6a60b0f952d43ac89c8293b2dbb8ca19e,section_vm-prov-walk-through," instances. Any number of instances may be started from the same <para>When starting an instance, a set of virtual resources known <para>Additional resources such as persistent volume storage and a <para>Once the instance has served its purpose and is deleted, released. The image remains unchanged the command-line interface or the OpenStack dashboard.", instances. Any number of instances maybe started from the same <para>When starting an instance a set of virtual resources known <para>Additional resources such as persistent volume storage and <para>Once the instance has served its purpose and is deleted released. And of course the image has remained unchanged the command-line interfaces or the OpenStack dashboard.,6,6
openstack%2Ffuel-library~master~I6432f1a980491e15f558a7903a1c7404c7548866,openstack/fuel-library,master,I6432f1a980491e15f558a7903a1c7404c7548866,Add waiting for Neutron-API are ready for answer.,MERGED,2014-10-17 14:32:48.000000000,2014-10-20 12:48:16.000000000,2014-10-20 12:48:16.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7604}, {'_account_id': 8776}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13343}]","[{'number': 1, 'created': '2014-10-17 14:32:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ca7d1091a44f359d647c688903cd24118fdcce21', 'message': 'Add waiting for Neutron-API are ready for answer.\n\nChange-Id: I6432f1a980491e15f558a7903a1c7404c7548866\nCloses-bug: #1382525\n'}, {'number': 2, 'created': '2014-10-17 16:37:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4c893727d8407ff505db13a35593a530203e8110', 'message': 'Add waiting for Neutron-API are ready for answer.\n\nChange-Id: I6432f1a980491e15f558a7903a1c7404c7548866\nCloses-bug: #1382525\n'}, {'number': 3, 'created': '2014-10-18 08:53:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4f70f43897b968e456e5d482edefed0178e508bd', 'message': 'Add waiting for Neutron-API are ready for answer.\n\nChange-Id: I6432f1a980491e15f558a7903a1c7404c7548866\nCloses-bug: #1382525\n'}, {'number': 4, 'created': '2014-10-18 19:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/17ee79fe8ed15d44a1fe095102d65fbb301018b4', 'message': 'Add waiting for Neutron-API are ready for answer.\n\nChange-Id: I6432f1a980491e15f558a7903a1c7404c7548866\nCloses-bug: #1382525\n'}, {'number': 5, 'created': '2014-10-18 19:56:45.000000000', 'files': ['deployment/puppet/neutron/manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8045d484a0551694eea4d1342f70a608d4f299ad', 'message': 'Add waiting for Neutron-API are ready for answer.\n\nChange-Id: I6432f1a980491e15f558a7903a1c7404c7548866\nCloses-bug: #1382525\n'}]",1,129279,8045d484a0551694eea4d1342f70a608d4f299ad,40,7,5,7468,,,0,"Add waiting for Neutron-API are ready for answer.

Change-Id: I6432f1a980491e15f558a7903a1c7404c7548866
Closes-bug: #1382525
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/79/129279/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/neutron/manifests/server.pp'],1,ca7d1091a44f359d647c688903cd24118fdcce21,bug/1382525," # In Juno Neutron API ready for answer not yet when server starts. exec {'waiting-for-neutron-api': tries => 30, try_sleep => 4, command => ""bash -c \""source /root/openrc ; neutron net-list\"" 2>&1 > /dev/null"", path => '/usr/sbin:/usr/bin:/sbin:/bin' } Service['neutron-server'] -> Exec['waiting-for-neutron-api'] Exec['waiting-for-neutron-api'] -> Anchor['neutron-api-up'] Exec['waiting-for-neutron-api'] -> Service<| title == 'neutron-dhcp-service' |> Exec['waiting-for-neutron-api'] -> Service<| title == 'neutron-l3' |> Exec['waiting-for-neutron-api'] -> Service<| title == 'neutron-metadata-agent' |> # it's not a mistake, for pacemakered Exec['waiting-for-neutron-api'] -> Service<| title == 'p_neutron-metadata-agent' |> # and not services -- names are different Exec['waiting-for-neutron-api'] -> Service<| title == 'neutron-ovs-agent-service' |> Exec['waiting-for-neutron-api'] -> Neutron_net<||> Exec['waiting-for-neutron-api'] -> Neutron_subnet<||> Exec['waiting-for-neutron-api'] -> Neutron_router<||> ",,18,0
openstack%2Fsahara~stable%2Ficehouse~I617f393c2d075fb1ad47e38b05d6fcf86e358a58,openstack/sahara,stable/icehouse,I617f393c2d075fb1ad47e38b05d6fcf86e358a58,Bump version for the next stable release,MERGED,2014-10-20 10:43:45.000000000,2014-10-20 12:43:28.000000000,2014-10-20 12:43:27.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-10-20 10:43:45.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/sahara/commit/9315699249a1fbd474baebaaf50002fad956ef99', 'message': 'Bump version for the next stable release\n\nChange-Id: I617f393c2d075fb1ad47e38b05d6fcf86e358a58\n'}]",0,129566,9315699249a1fbd474baebaaf50002fad956ef99,7,3,1,6786,,,0,"Bump version for the next stable release

Change-Id: I617f393c2d075fb1ad47e38b05d6fcf86e358a58
",git fetch https://review.opendev.org/openstack/sahara refs/changes/66/129566/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,9315699249a1fbd474baebaaf50002fad956ef99,,version = 2014.1.4,version = 2014.1.2,1,1
openstack%2Ftripleo-image-elements~master~Ie13bf0f7a972ed7f69623c9a661065b46441c3e9,openstack/tripleo-image-elements,master,Ie13bf0f7a972ed7f69623c9a661065b46441c3e9,Use Percona Packages for Ubuntu and Debian,MERGED,2014-04-24 16:13:35.000000000,2014-10-20 12:42:47.000000000,2014-10-20 12:42:46.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 741}, {'_account_id': 951}, {'_account_id': 1605}, {'_account_id': 1726}, {'_account_id': 1872}, {'_account_id': 4190}, {'_account_id': 4220}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 6969}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 9268}, {'_account_id': 9369}, {'_account_id': 9667}, {'_account_id': 10035}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-04-24 16:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/24058b66b2c1d663c3391efc1750caf249fb7b19', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with ubuntu.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 2, 'created': '2014-04-25 11:43:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/b19764d48ad0e1db348afa8866045bf1c11cef28', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with ubuntu.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 3, 'created': '2014-04-30 13:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8e21e32991e43dd1e325f178c23e1cdf84b2b415', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with ubuntu.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 4, 'created': '2014-05-02 11:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/2280d5010011c2a62f8056b9515f24d90b8f0ad1', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with ubuntu.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 5, 'created': '2014-05-02 15:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/316c5580a69569e06183b4f2faced00fcef6d95e', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with ubuntu.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 6, 'created': '2014-05-11 14:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ce680c674be400313e86d9312bc5cff7a5abb8e0', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with ubuntu and Debian.\n\nSet DIB_PERCONA_INSTALL:\n\n     PACKAGE  - pull packages from percona repo\n     PACKAGE_MIRROR - pull packages from mirror\n\ndefault (unset) is the existing install from tarball.\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 7, 'created': '2014-05-27 13:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1d9854051b6a82c3bbedabff37a0bfbdffd16dea', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with ubuntu and Debian.\n\nSet DIB_PERCONA_INSTALL:\n\n     PACKAGE  - pull packages from percona repo\n     PACKAGE_MIRROR - pull packages from mirror\n\ndefault (unset) is the existing install from tarball.\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 8, 'created': '2014-05-30 09:56:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f90f05b49bd2e370b65a0ba260c70c6241a5d78c', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with ubuntu and Debian.\n\nSet DIB_PERCONA_INSTALL:\n\n     PACKAGE  - pull packages from percona repo\n     PACKAGE_MIRROR - pull packages from mirror\n\ndefault (unset) is the existing install from tarball.\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 9, 'created': '2014-06-05 10:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5512a073ddd697a5b19d4c6f1b85c3760f060b7b', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 10, 'created': '2014-06-05 10:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/c1e340c3c7fbd4b37daeb6c8f6bb39e5f0fdb61f', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 11, 'created': '2014-06-05 10:43:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/88abefb8583496b0a5128f94668ee4e4853e0f7c', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 12, 'created': '2014-06-06 10:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/3786daddd61a69ad430a99f1bf8313f38f6a0a4e', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 13, 'created': '2014-06-09 13:19:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5e79526e829d7d65ce8e45f7e191f22677dcb1a1', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 14, 'created': '2014-06-09 14:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1df0075515bdbf6d8b762920574a2a4323f41620', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 15, 'created': '2014-06-09 15:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/2b596dc15f9861abca4dfbd99f070d599df33219', 'message': 'Use Percona Packages for Ubuntu\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 16, 'created': '2014-06-10 15:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/590d506e1ba9a8bbab0ad88cfce4a321eb388943', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 17, 'created': '2014-06-13 11:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/59a36f1a034d645510fcc864d4a10f7e2752d8de', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 18, 'created': '2014-06-13 16:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/139b9438441f906f7081b8d8b0035af23c0fd8a0', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 19, 'created': '2014-06-18 17:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/79a0e304d543c7a1b03020dda85dfe37561ce8cd', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 20, 'created': '2014-06-27 10:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/4f52c60d0e832d604798709926494f6ed0296830', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 21, 'created': '2014-06-27 11:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/385dd4f4ada1e37884114be8a5b9a3c2d4b9255b', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 22, 'created': '2014-07-01 15:03:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/7b40b89e1796a759ca0f0f419e05cf4cc37fcce6', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 23, 'created': '2014-07-02 17:11:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/4d5ffcf35b4e403dfd949a6ba02efcd908101326', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 24, 'created': '2014-07-10 09:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/77fc971782d0e24529b24239741bed5de6889d4f', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 25, 'created': '2014-07-23 19:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/74ad895e9746a69d1953ee85b884d00803decbec', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 26, 'created': '2014-07-23 19:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/54352e18e2469e532bba1878a720ea8b52a7e5e1', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\n( If the packages are available in a local mirror\nSet DIB_PERCONA_INSTALL to PACKAGE_MIRROR which\nwill assume the packages are available in a mirror\ninstead of the percona repo)\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 27, 'created': '2014-07-24 17:53:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/3cb8bf43ee5bae7cb56b887e54b6ab797b2fd7cd', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 28, 'created': '2014-07-24 19:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/d860deab0c791870a7c639d36a5504ea9a3d09ce', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 29, 'created': '2014-07-24 21:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/47c0b74cfa00e692231a878e98d3483aac26ed3b', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 30, 'created': '2014-08-07 10:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/d2309e616370a5b25d350df64ae822aa8ed2669e', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 31, 'created': '2014-08-07 10:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1a9835806f4d3b6ad55d0ce17153a0471e0e7335', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 32, 'created': '2014-08-08 11:32:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5f6326a2db523f473fec279298836f6d9684b543', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball, starting with Ubuntu and Debian.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 33, 'created': '2014-08-14 15:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/7e331eaba0b1f7d343cbfe866b292f69ab1c6ffe', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball for Ubuntu and Debian.\n\nThis pulls the packages in from the Ubuntu repository. The minimum requirement\nfor the Percona packages is trusty.\n\nThis element currently will not work on Fedora and checks for it but Fedora\nuses the Mariadb element to provide a MySQL HA solution instead.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 34, 'created': '2014-08-15 07:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f59064c3980c4ed11942def48c37cfe1ac998a65', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball for Ubuntu and Debian.\n\nThis pulls the packages in from the Ubuntu repository. The minimum requirement\nfor the Percona packages is trusty.\n\nThis element currently will not work on Fedora and checks for it but Fedora\nuses the Mariadb element to provide a MySQL HA solution instead.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 35, 'created': '2014-10-07 11:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/21e5aa57a9a8ee13e478a2ad4c9d4fc6bf8bac10', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball for Ubuntu and Debian.\n\nThis pulls the packages in from the Ubuntu repository. The minimum requirement\nfor the Percona packages is trusty.\n\nThis element currently will not work on Fedora and checks for it but Fedora\nuses the Mariadb element to provide a MySQL HA solution instead.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 36, 'created': '2014-10-09 12:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/75b4cbe01a901e4f248291570567dc44805eb5dc', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball for Ubuntu and Debian.\n\nThis pulls the packages in from the Ubuntu repository. The minimum requirement\nfor the Percona packages is trusty.\n\nThis element currently will not work on Fedora and checks for it but Fedora\nuses the Mariadb element to provide a MySQL HA solution instead.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}, {'number': 37, 'created': '2014-10-16 11:48:34.000000000', 'files': ['elements/mysql/README.md', 'elements/mysql/os-refresh-config/configure.d/52-mysql-init', 'elements/mysql/environment.d/20-percona', 'elements/mysql/install.d/10-mysql', 'elements/mysql/source-repository-mysql'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/00e50a2e186f2d34e01e96f8999e62e9409b8846', 'message': 'Use Percona Packages for Ubuntu and Debian\n\nAdjust the install of Percona XtraDB Cluster to use Percona Packages\ninstead of a Percona tarball for Ubuntu and Debian.\n\nThis pulls the packages in from the Ubuntu repository. The minimum requirement\nfor the Percona packages is trusty.\n\nThis element currently will not work on Fedora and checks for it but Fedora\nuses the Mariadb element to provide a MySQL HA solution instead.\n\nChange-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n'}]",86,90134,00e50a2e186f2d34e01e96f8999e62e9409b8846,309,19,37,1872,,,0,"Use Percona Packages for Ubuntu and Debian

Adjust the install of Percona XtraDB Cluster to use Percona Packages
instead of a Percona tarball for Ubuntu and Debian.

This pulls the packages in from the Ubuntu repository. The minimum requirement
for the Percona packages is trusty.

This element currently will not work on Fedora and checks for it but Fedora
uses the Mariadb element to provide a MySQL HA solution instead.

Change-Id: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/34/90134/33 && git format-patch -1 --stdout FETCH_HEAD,"['elements/mysql/os-refresh-config/configure.d/51-mysql-init', 'elements/mysql/pre-install.d/05-mysql', 'elements/mysql/install.d/10-mysql']",3,24058b66b2c1d663c3391efc1750caf249fb7b19,bug90134,"DISTRO=`lsb_release -si` || true if [[ ""Ubuntu"" =~ ""$DISTRO"" ]]; then cat > /etc/apt/preferences.d/percona <<EOF Package: libmysqlclient18 Pin: origin repo.percona.com Pin-Priority: 1001 EOF install-packages --force-yes libmysqlclient18 libdbd-mysql-perl install-packages percona-xtrabackup percona-xtradb-cluster-common-5.5 percona-xtradb-cluster-server-5.5 percona-xtradb-cluster-client-5.5 percona-xtradb-cluster-galera-2.x else install-packages libaio1 pv rsync percona_pkgdir=Percona-XtraDB-Cluster Adapted from mysql ref manual http://dev.mysql.com/doc/refman/5.6/en/binary-installation.html groupadd mysql useradd -r -g mysql mysql cd /usr/local ln -s /usr/local/$percona_pkgdir mysql cd mysql chown -R mysql:mysql . install -o root -g root -m 0755 support-files/mysql.server /etc/init.d/mysql install -o root -g root -m 0755 bin/mysql /usr/local/bin install -o root -g root -m 0755 bin/mysqld /usr/local/bin sed -i -e 's,^#\!/bin/sh$,#\!/bin/bash,' /etc/init.d/mysql sed -i -e 's,^basedir=$,basedir=/usr/local/mysql,' /etc/init.d/mysql fiif [[ ""Ubuntu"" =~ ""$DISTRO"" ]]; then # When installing from packages binary log files are created which may not # match the configuration we want, remove these and they will be created if [ -e /var/lib/mysql/ib_logfile0 ] && [ -e /var/lib/mysql/ib_logfile1 ] ; then sizelog0=$(( $(stat -c '%s' /var/lib/mysql/ib_logfile0)/1024/1024 ))M sizelog1=$(( $(stat -c '%s' /var/lib/mysql/ib_logfile1)/1024/1024 ))M innodb_log_file_size=$(grep innodb_log_file_size /etc/mysql/my.cnf |awk '{print $3}') if [ ""$sizelog0"" != ""$innodb_log_file_size"" ] || [ ""$sizelog1"" != ""$innodb_log_file_size"" ] ; then rm -rf /var/lib/mysql/ib_logfile0 /var/lib/mysql/ib_logfile1 fi fi fi","install-packages libaio1 pv rsync percona_pkgdir=Percona-XtraDB-Cluster # Adapted from mysql ref manual # http://dev.mysql.com/doc/refman/5.6/en/binary-installation.html groupadd mysql useradd -r -g mysql mysql cd /usr/local ln -s /usr/local/$percona_pkgdir mysql cd mysql chown -R mysql:mysql . install -o root -g root -m 0755 support-files/mysql.server /etc/init.d/mysql install -o root -g root -m 0755 bin/mysql /usr/local/bin install -o root -g root -m 0755 bin/mysqld /usr/local/bin sed -i -e 's,^#\!/bin/sh$,#\!/bin/bash,' /etc/init.d/mysql sed -i -e 's,^basedir=$,basedir=/usr/local/mysql,' /etc/init.d/mysqlDISTRO=`lsb_release -si` || true",98,19
openstack%2Ffuel-web~master~If420f3141eb5a357f010f6ef0b4def0e5a7874bd,openstack/fuel-web,master,If420f3141eb5a357f010f6ef0b4def0e5a7874bd,HTTP requests monitoring middleware added,MERGED,2014-09-22 16:21:25.000000000,2014-10-20 12:25:23.000000000,2014-10-20 11:40:42.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8789}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11081}, {'_account_id': 11082}, {'_account_id': 11577}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-09-22 16:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7139d835877442f93f06b803f779db10cd711bdf', 'message': 'HTTP requests monitoring middleware added\n\nAdded middleware for collection data from http requests.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 2, 'created': '2014-09-23 15:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d0125dddb8a07b8d3f1af01e5b2eaf15eff4e3e0', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 3, 'created': '2014-09-24 14:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d46ee9c1fad165f343a988eab8ce058236f7b994', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 4, 'created': '2014-09-25 15:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5b1c4a699875592d027b2ee3bba9e09a8c739935', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 5, 'created': '2014-09-26 15:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/21569653e231b3c97f186d8c63ec8a77bc1c11cb', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 6, 'created': '2014-09-26 16:32:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fab6a1f01d25e3046dad3614909a8d7cac43d565', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 7, 'created': '2014-09-29 13:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4c538c2f9b7642c33567237d4c7b60436c2e6507', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 8, 'created': '2014-10-02 15:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e64bc0a9b441e730d7ff8b1e5464bd1392e9a74e', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 9, 'created': '2014-10-03 15:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/20bcb435cd636c1499bd04db41992ff2ed86ef17', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 10, 'created': '2014-10-06 15:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e0c536968798e821eac44d5b5919293de2ee287a', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 11, 'created': '2014-10-07 09:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/72f6f4d26a742ccd9f63c7e5fdc7feb2719f26fc', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 12, 'created': '2014-10-07 15:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/158d50285918b7a46ff50d5c25509cdd58ee4a31', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 13, 'created': '2014-10-10 09:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a2385bcf85405452e7b555f9083472da7a6e1af0', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 14, 'created': '2014-10-10 15:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/30472d18c6e6f1e664b1d3e5f0db6868b3db42c8', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 15, 'created': '2014-10-14 10:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6cb54c3cb5fa2a5038c8db6217fc434afdd36900', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 16, 'created': '2014-10-14 12:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1ff3c0247681025cde0990522fab8b874fa3f52d', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 17, 'created': '2014-10-14 14:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2c42b67f3d654cb58c31963adc1bc13c47661a82', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 18, 'created': '2014-10-15 12:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/deac05ef78d03d6c9bfadb5e7a38bfb31c990ede', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 19, 'created': '2014-10-15 13:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b6f1354cb2a9376246e36e279f0242d5d9d1504a', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 20, 'created': '2014-10-16 13:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2af35cb189687bb6ed5c1dc20dcf65cd3863bb44', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 21, 'created': '2014-10-16 15:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/61957af09fa1fe46bda07f6ef117dca7796278f1', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 22, 'created': '2014-10-17 08:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e380920503fe25990a85ac3d5b779d30f7863f78', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}, {'number': 23, 'created': '2014-10-17 15:39:43.000000000', 'files': ['nailgun/nailgun/db/sqlalchemy/models/__init__.py', 'nailgun/nailgun/db/sqlalchemy/models/action_logs.py', 'nailgun/nailgun/consts.py', 'nailgun/nailgun/middleware/connection_monitor.py', 'nailgun/nailgun/test/unit/test_middleware_utils.py', 'nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_6_0.py', 'nailgun/nailgun/middleware/utils.py', 'nailgun/nailgun/app.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5d58f3e0f082a50f634257896897371e2f9ff08c', 'message': 'HTTP requests monitoring middleware added\n\nNew wsgi middleware was added to middleware stack of main webpy\napplication. The middleware is a class which implements logic for\ncollecting info from requests and responses, forming appropriate data\nstructure and dumps it to db for further usage.\n\nChange-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd\nImplements: blueprint send-anon-usage\n'}]",85,123169,5d58f3e0f082a50f634257896897371e2f9ff08c,157,12,23,8931,,,0,"HTTP requests monitoring middleware added

New wsgi middleware was added to middleware stack of main webpy
application. The middleware is a class which implements logic for
collecting info from requests and responses, forming appropriate data
structure and dumps it to db for further usage.

Change-Id: If420f3141eb5a357f010f6ef0b4def0e5a7874bd
Implements: blueprint send-anon-usage
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/69/123169/20 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/db/sqlalchemy/models/action_logs.py', 'nailgun/nailgun/middleware/connection_monitor.py', 'nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_6_0.py', 'nailgun/nailgun/middleware/utils.py', 'nailgun/nailgun/app.py']",5,7139d835877442f93f06b803f779db10cd711bdf,bp/send-anon-usage,"from nailgun.middleware.connection_monitor import ConnectionMonitorMiddleware ConnectionMonitorMiddleware,",,188,0
openstack%2Ffuel-specs~master~I5d98cdcdc54c1683ab21be8859a668db53eb9d79,openstack/fuel-specs,master,I5d98cdcdc54c1683ab21be8859a668db53eb9d79,Fuel master access control improvements,MERGED,2014-09-02 09:39:01.000000000,2014-10-20 12:15:04.000000000,2014-10-20 12:15:03.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6719}, {'_account_id': 6794}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8735}, {'_account_id': 8749}, {'_account_id': 8954}, {'_account_id': 9546}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 11969}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-09-02 09:39:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/c595e802a886734fa17caff59b252f46a9bfe484', 'message': 'Fuel master access control improvements\n\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 2, 'created': '2014-09-03 15:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/a17a1e690d17f65f1b6bd1f9c0d1d5c8940ec357', 'message': 'Fuel master access control improvements\n\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 3, 'created': '2014-09-04 12:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/a3e8be558f28b1ca67551b6049366eb67bae82c5', 'message': 'Fuel master access control improvements\n\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 4, 'created': '2014-09-09 14:13:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/2f34b5c23a981cef3f737b8eacb7af3fad6c7876', 'message': 'Fuel master access control improvements\n\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 5, 'created': '2014-09-15 23:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/4cabb698fdce22ec516f1390dcecd3a47acddf38', 'message': 'Fuel master access control improvements\n\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 6, 'created': '2014-09-15 23:46:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/a1defa2aeb76ef16b1d0ea32be4d44e5a2877190', 'message': 'Fuel master access control improvements\n\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 7, 'created': '2014-09-15 23:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/f34480f4f7130a38c6a9bf809aad406335a57e16', 'message': 'Fuel master access control improvements\n\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 8, 'created': '2014-09-16 00:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/e9e89638f8a570466d6c286111cc87dda528852a', 'message': 'Fuel master access control improvements\n\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 9, 'created': '2014-09-16 17:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/85add82c5ef2b53c53d3f35abafcd7baa7fc6ff0', 'message': 'Fuel master access control improvements\n\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 10, 'created': '2014-09-17 00:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/c5dd2e11458a5b102b868452a1028869a3b8a528', 'message': 'Fuel master access control improvements\n\nBlueprint: access-control-master-node-improvments\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 11, 'created': '2014-09-18 01:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/f4da63a51952f06848c84486f525af00e31ce97c', 'message': 'Fuel master access control improvements\n\nBlueprint: access-control-master-node-improvments\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 12, 'created': '2014-09-18 01:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/35a2c9dc94fa665b253be7f91135aa3d5cb38c21', 'message': 'Fuel master access control improvements\n\nBlueprint: access-control-master-node-improvments\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 13, 'created': '2014-09-19 18:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/a0ca534b58f2a6749cd07640b702d9a57eb9bce6', 'message': 'Fuel master access control improvements\n\nBlueprint: access-control-master-node-improvments\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 14, 'created': '2014-09-22 16:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/e039b717633f2455efa27fe9fcf20493186d2b6c', 'message': 'Fuel master access control improvements\n\nBlueprint: access-control-master-node-improvments\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 15, 'created': '2014-09-24 20:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/5a0b6a82ac98710ab6d31a9937e4dde3142470af', 'message': 'Fuel master access control improvements\n\nBlueprint: access-control-master-node-improvments\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 16, 'created': '2014-09-30 08:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/87cf475d0a269d21dd46306c3d97fa7e811deedc', 'message': 'Fuel master access control improvements\n\nBlueprint: access-control-master-node-improvments\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 17, 'created': '2014-09-30 08:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/f2b4144d0d08a4589091246ce095c1ebec7b1208', 'message': 'Fuel master access control improvements\n\nBlueprint: access-control-master-node-improvments\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 18, 'created': '2014-10-07 13:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/76af860762ef45783c87899b841767c903509bb3', 'message': 'Fuel master access control improvements\n\nBlueprint: access-control-master-node-improvments\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}, {'number': 19, 'created': '2014-10-08 12:05:10.000000000', 'files': ['specs/6.0/access-control-master-node-improvments.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/2e794e71acdb27516032a81f5e4750631d826292', 'message': 'Fuel master access control improvements\n\nBlueprint: access-control-master-node-improvments\nChange-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79\n'}]",54,118284,2e794e71acdb27516032a81f5e4750631d826292,79,14,19,8954,,,0,"Fuel master access control improvements

Blueprint: access-control-master-node-improvments
Change-Id: I5d98cdcdc54c1683ab21be8859a668db53eb9d79
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/84/118284/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'specs/6.0/access-control-master-node-improvments.rst']",2,c595e802a886734fa17caff59b252f46a9bfe484,bp/access-control-master-node-improvments,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Fuel master access control improvements ========================================== https://blueprints.launchpad.net/fuel/+spec/access-control-master-node-improvments In 5.1 release cycle fuel master node access control was introduced. In next release some configuration tunning is required to make it easier to use and upgrade. Problem description =================== With current implementation we have following problems: * each request is validated using keystone admin token. This method is depracted * there is no system user so it's hard to run queries from scripts i.e during upgrade * Outdated tokens are not cleaned which in long term may lead to run out of space * all requests are using HTTP protocol and are not protected so all passwords and tokens are sent in plain text * no cookies support so some GET requests from UI can not be validated Proposed change =============== * Create user with admin role which will be used to authenticate requests and during upgrade. * Create cron script which deletes outdated tokens * Use HTTPS to connect to master node(this may require new blueprint) * Add support for cookies, which also will allow to test API from browser Alternatives ------------ None Data model impact ----------------- There will be new user in keystone database. REST API impact --------------- All API requests will be encrypted using HTTPS. Upgrade impact -------------- System user should be created during master node upgrade. Security impact --------------- Using HTTPS and not using admin token will increase master node security. Notifications impact -------------------- None Other end user impact --------------------- If we use self signed certificates for SSL user will get warning on the browser. Performance Impact ------------------ HTTPS may add some latency but it shouldn't be a problem. Other deployer impact --------------------- None Developer impact ---------------- When cookies support is added developer will be able to test API from browser. Implementation ============== Assignee(s) ----------- Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- TBD Dependencies ============ None Testing ======= TBD Documentation Impact ==================== HTTPS change should be described References ========== None ",,148,0
openstack%2Ffuel-library~master~I31fc5f168b68f102e210810e80bcbd9a2419c726,openstack/fuel-library,master,I31fc5f168b68f102e210810e80bcbd9a2419c726,Del unused parameter in monit::process,MERGED,2014-10-14 12:30:49.000000000,2014-10-20 12:14:43.000000000,2014-10-20 12:14:42.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8971}, {'_account_id': 9387}]","[{'number': 1, 'created': '2014-10-14 12:30:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4c5c66d3059ade66dcdb2cbfc986d971a5e5fb39', 'message': 'Del unused parameter in monit::process\n\nServicep parameter is unused and should be\ndeleted.\n\nRelated blueprint pacemaker-improvements\n\nChange-Id: I31fc5f168b68f102e210810e80bcbd9a2419c726\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2014-10-20 09:21:00.000000000', 'files': ['deployment/puppet/monit/manifests/process.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/631f77c5fa49039890028419ab8e4b4f7d8c9708', 'message': 'Del unused parameter in monit::process\n\nServicep parameter is unused and should be\ndeleted\n\nRelated blueprint pacemaker-improvements\n\nChange-Id: I31fc5f168b68f102e210810e80bcbd9a2419c726\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,128254,631f77c5fa49039890028419ab8e4b4f7d8c9708,19,5,2,6926,,,0,"Del unused parameter in monit::process

Servicep parameter is unused and should be
deleted

Related blueprint pacemaker-improvements

Change-Id: I31fc5f168b68f102e210810e80bcbd9a2419c726
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/54/128254/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/monit/manifests/process.pp'],1,4c5c66d3059ade66dcdb2cbfc986d971a5e5fb39,bp/pacemaker-improvements,, $servicep = $::monit::params::servicep,0,1
openstack%2Factivity-board~master~I80d1d9adc036c11d8ebcc2e5226c65b4e987030e,openstack/activity-board,master,I80d1d9adc036c11d8ebcc2e5226c65b4e987030e,Fix merge conflict in commit with message:,MERGED,2014-10-11 16:51:45.000000000,2014-10-20 12:04:38.000000000,2014-10-20 12:04:38.000000000,"[{'_account_id': 3}, {'_account_id': 8000}, {'_account_id': 8710}]","[{'number': 1, 'created': '2014-10-11 16:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/activity-board/commit/20f4b2bd6fc3fe2541bcb7c8467d4ec35783b09c', 'message': 'Add filterbar styles missing\n\nChange-Id: I80d1d9adc036c11d8ebcc2e5226c65b4e987030e\n'}, {'number': 2, 'created': '2014-10-11 17:00:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/activity-board/commit/127beff321d41da7906649961be7e24c0756c07f', 'message': 'Add filterbar styles missing\n\nChange-Id: I80d1d9adc036c11d8ebcc2e5226c65b4e987030e\n'}, {'number': 3, 'created': '2014-10-12 15:19:44.000000000', 'files': ['browser/css/custom.css'], 'web_link': 'https://opendev.org/openstack/activity-board/commit/7bc83f9e12ce97751712ff83d8eb19a52ded9700', 'message': 'Fix merge conflict in commit with message:\n\nAdd filterbar styles missing\n\nChange-Id: I80d1d9adc036c11d8ebcc2e5226c65b4e987030e\n'}]",0,127806,7bc83f9e12ce97751712ff83d8eb19a52ded9700,17,3,3,8710,,,0,"Fix merge conflict in commit with message:

Add filterbar styles missing

Change-Id: I80d1d9adc036c11d8ebcc2e5226c65b4e987030e
",git fetch https://review.opendev.org/openstack/activity-board refs/changes/06/127806/1 && git format-patch -1 --stdout FETCH_HEAD,['browser/css/custom.css'],1,20f4b2bd6fc3fe2541bcb7c8467d4ec35783b09c,filterbar, float: left;.container-fluid {{/*.breadcrumb {/*.breadcrumbtitle >li > a {.breadcrumbtitle >li > a:hover {.ol {.FilterItemMicrodashText {/*.navbar-default .navbar-brand {.navbar-default .navbar-brand:hover {.navbar-default {.navbar-fixed-top {.navbar-default .navbar-toggle {.well{a {.navbar-default .navbar-brand {.navbar-default .navbar-brand:hover {.navbar-default {.navbar-default {.breadcrumbtitle >li > a {.breadcrumbtitle >li > a:hover {/* watch out! filterbar should be part of master! */ .filterbar { background-color: #F5F5F5; border-radius: 4px; list-style: none outside none; margin-bottom: 20px; padding: 8px 15px; } .filterbar > li { display: inline-block; } , float: left; .container-fluid { { /*.breadcrumb { /*.breadcrumbtitle >li > a { .breadcrumbtitle >li > a:hover { .ol { .FilterItemMicrodashText { /*.navbar-default .navbar-brand { .navbar-default .navbar-brand:hover { .navbar-default { .navbar-fixed-top { .navbar-default .navbar-toggle { .well{ a { .navbar-default .navbar-brand { .navbar-default .navbar-brand:hover { .navbar-default { .navbar-default { .breadcrumbtitle >li > a { .breadcrumbtitle >li > a:hover { ,33,21
openstack%2Ffuel-library~master~I238652e0a42fc3e15fd6cf7416343fb900336784,openstack/fuel-library,master,I238652e0a42fc3e15fd6cf7416343fb900336784,Add host_uuid to libvirtd.conf,MERGED,2014-10-15 13:12:16.000000000,2014-10-20 11:57:07.000000000,2014-10-20 11:57:07.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13344}]","[{'number': 1, 'created': '2014-10-15 13:12:16.000000000', 'files': ['deployment/puppet/openstack/manifests/compute.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/63636d115190ec1b07ee8ea77906fd6bd2f4c576', 'message': 'Add host_uuid to libvirtd.conf\n\nAdd host_uuid generated by uuidgen to libvirtd.conf\n\nChange-Id: I238652e0a42fc3e15fd6cf7416343fb900336784\nCloses-Bug: 1378962\n'}]",6,128640,63636d115190ec1b07ee8ea77906fd6bd2f4c576,30,9,1,13344,,,0,"Add host_uuid to libvirtd.conf

Add host_uuid generated by uuidgen to libvirtd.conf

Change-Id: I238652e0a42fc3e15fd6cf7416343fb900336784
Closes-Bug: 1378962
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/40/128640/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/compute.pp'],1,63636d115190ec1b07ee8ea77906fd6bd2f4c576,bug/1378962," $host_uuid=generate('/bin/sh', '-c', ""uuidgen"") augeas { 'libvirt-conf-uuid': context => '/files/etc/libvirt/libvirtd.conf', changes => [ ""set host_uuid $host_uuid"", ], onlyif => ""match /files/etc/libvirt/libvirtd.conf/host_uuid size == 0"", notify => Service['libvirt'], } ",,11,0
openstack%2Ffuel-web~master~Icf40bdb84785f64e9e43025d69482451c8de6ea4,openstack/fuel-web,master,Icf40bdb84785f64e9e43025d69482451c8de6ea4,Nailgun object interface for ActionLog added,MERGED,2014-09-24 14:59:53.000000000,2014-10-20 11:44:10.000000000,2014-10-20 11:44:10.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8789}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11081}, {'_account_id': 11082}, {'_account_id': 11577}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-09-24 14:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5ed924f7175293e410596251b7606c2f07992fb5', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 2, 'created': '2014-09-25 15:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7c69e6463e3862bb7fe638cedd3fd26c06db3d67', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 3, 'created': '2014-09-26 15:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ece9bab0d51e8b26b272ff2890f2f98cdd352419', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 4, 'created': '2014-09-26 16:32:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5187663523ff9ab3936ceea6ed4c91a4d70a1bfe', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 5, 'created': '2014-09-29 13:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4bc45dc86d33d7e82fcd0131d58aae011dd259d8', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 6, 'created': '2014-09-29 14:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/449221219b817fa45bb2808f2500604d21d5bb7a', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 7, 'created': '2014-10-02 15:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/76f98784c1ad8fb0ddb2782e0b80406c6064bda9', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 8, 'created': '2014-10-03 15:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6f00a0f4658f4efc370c42a446a2ca448345684b', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 9, 'created': '2014-10-06 15:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7639ff5cf6c0858096b910b37936eb86f9007da4', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 10, 'created': '2014-10-07 09:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ad9def1b11194ff8f559cae6440a61362828e6c9', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 11, 'created': '2014-10-07 15:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/44dcb72eba6c1666c0c53884851d210e84c1e476', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 12, 'created': '2014-10-10 09:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/10af711e7650b7dcea85bff302d06a56285ad26d', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 13, 'created': '2014-10-10 15:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0955fe8aefae16808649de139d869942024ca7d1', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 14, 'created': '2014-10-14 10:56:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a518779cc7d908e990747310ab2936fac0f04530', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 15, 'created': '2014-10-14 12:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f3a172cec1eab0ebe4bd2e9d39f65661d75002e4', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 16, 'created': '2014-10-14 14:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9dbed931d5967eda95d6e5fd44316e1a267b1c9a', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 17, 'created': '2014-10-15 12:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e40f6615ca21e240552cb0edf5ee92c993d9c320', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 18, 'created': '2014-10-15 13:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4c8d519450d17ecc1dcc3806f051d29727f3f39a', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 19, 'created': '2014-10-16 13:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1e209e1d16137aa29b6fbd1bdf8d2077eb21bf2c', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 20, 'created': '2014-10-16 15:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e31534d644dbc067f79644d0c50330f1fa0e4b69', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 21, 'created': '2014-10-17 08:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9f76ebd8a2804a64712c0056f682a85f04a88c2b', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}, {'number': 22, 'created': '2014-10-17 15:39:43.000000000', 'files': ['nailgun/nailgun/objects/serializers/action_log.py', 'nailgun/nailgun/objects/__init__.py', 'nailgun/nailgun/objects/action_log.py', 'nailgun/nailgun/test/unit/test_objects.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/63dd9e6673142b56d290ac8dc3862093ad65745f', 'message': 'Nailgun object interface for ActionLog added\n\nSingle and collection objects for ActionLog entity added to nailgun\nobjects system. It needed for further utilization by logic which sends\nthis data to collector service.\n\nJSONSchema for aforementioned entity defined.\n\nUnit tests updated.\n\nChange-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4\nImplements: blueprint send-anon-usage\n'}]",19,123753,63dd9e6673142b56d290ac8dc3862093ad65745f,140,12,22,8931,,,0,"Nailgun object interface for ActionLog added

Single and collection objects for ActionLog entity added to nailgun
objects system. It needed for further utilization by logic which sends
this data to collector service.

JSONSchema for aforementioned entity defined.

Unit tests updated.

Change-Id: Icf40bdb84785f64e9e43025d69482451c8de6ea4
Implements: blueprint send-anon-usage
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/53/123753/21 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/db/sqlalchemy/models/__init__.py', 'nailgun/nailgun/objects/serializers/action_log.py', 'nailgun/nailgun/objects/__init__.py', 'nailgun/nailgun/objects/action_log.py', 'nailgun/nailgun/test/unit/test_objects.py']",5,5ed924f7175293e410596251b7606c2f07992fb5,bp/send-anon-usage,"import datetime import hashlib import json import jsonschema from nailgun.db.sqlalchemy.models import ActionLogs class TestActionLogObject(BaseIntegrationTest): def _create_log_entry(self): actor_id = hashlib.sha256('actionlog_test').hexdigest() start_time = datetime.datetime.now() end_time = start_time + datetime.timedelta(hours=1) action_logs_kwargs = { 'actor_id': actor_id, 'action_group': 'test_group', 'action_name': 'test_action_one', 'request_data': { 'url': 'some/test/url', 'message': None, 'data': {}, 'http_method': 'DELETE' }, 'response_data': { 'message': None, 'data': {}, 'status': '200 OK' }, 'start_timestamp': start_time, 'end_timestamp': end_time } return ActionLogs(**action_logs_kwargs) def test_validate_json_schema(self): al = self._create_log_entry() self.db.add(al) self.db.flush() instance_to_validate = json.loads(objects.ActionLog.to_json(al)) self.assertNotRaises(jsonschema.ValidationError, jsonschema.validate, instance_to_validate, objects.ActionLog.schema) self.db.delete(al) self.db.commit()",,147,0
openstack%2Fpython-designateclient~master~I25dcaf2a35b40e3243c121434a49bc83a5f01957,openstack/python-designateclient,master,I25dcaf2a35b40e3243c121434a49bc83a5f01957,Fixes pypi tarball not delivering Apache 2.0 LICENSE file,MERGED,2014-10-17 16:35:48.000000000,2014-10-20 11:42:48.000000000,2014-10-20 11:42:47.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-10-17 16:35:48.000000000', 'files': ['setup.cfg', 'LICENSE'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/484fc8f3a1e01ffb8975917b300062a1808b8bd6', 'message': 'Fixes pypi tarball not delivering Apache 2.0 LICENSE file\n\nChange-Id: I25dcaf2a35b40e3243c121434a49bc83a5f01957\nCloses-Bug: #1332625\n'}]",0,129324,484fc8f3a1e01ffb8975917b300062a1808b8bd6,7,3,1,13291,,,0,"Fixes pypi tarball not delivering Apache 2.0 LICENSE file

Change-Id: I25dcaf2a35b40e3243c121434a49bc83a5f01957
Closes-Bug: #1332625
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/24/129324/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'LICENSE']",2,484fc8f3a1e01ffb8975917b300062a1808b8bd6,fix-bug-1332625," Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. ""License"" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. ""Licensor"" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. ""Legal Entity"" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, ""control"" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. ""You"" (or ""Your"") shall mean an individual or Legal Entity exercising permissions granted by this License. ""Source"" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. ""Object"" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. ""Work"" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). ""Derivative Works"" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. ""Contribution"" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, ""submitted"" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as ""Not a Contribution."" ""Contributor"" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a ""NOTICE"" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. ",,178,1
openstack%2Fpython-designateclient~master~I01e1cf7f97a72b78d4c26543b73910ac6a90e145,openstack/python-designateclient,master,I01e1cf7f97a72b78d4c26543b73910ac6a90e145,Fixes homepage in metadata and internal docs,MERGED,2014-10-16 13:06:52.000000000,2014-10-20 11:42:42.000000000,2014-10-20 11:42:42.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}, {'_account_id': 13291}]","[{'number': 1, 'created': '2014-10-16 13:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/1de6879b866a92673011cf242bd13b14f4baf959', 'message': '* Correct homepage in package metadata file\n* Correct launchpad & GitHub home in contributing.rst\n\nChange-Id: I01e1cf7f97a72b78d4c26543b73910ac6a90e145\nCloses-Bug: #1332626\n'}, {'number': 2, 'created': '2014-10-18 05:22:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/957eeb58e0dda3a3b4ceefcf9d0bf31b23dbba32', 'message': 'Fixes homepage in metadata and internal docs\n* Correct homepage in package metadata file\n* Correct launchpad & GitHub home in contributing.rst\n\nChange-Id: I01e1cf7f97a72b78d4c26543b73910ac6a90e145\nCloses-Bug: #1332626\n'}, {'number': 3, 'created': '2014-10-18 05:29:27.000000000', 'files': ['doc/source/contributing.rst', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/332ea6fc279c3e038a5fcb7663aab89e337363cd', 'message': 'Fixes homepage in metadata and internal docs\n\n* Correct homepage in package metadata file\n* Correct launchpad & GitHub home in contributing.rst\n\nChange-Id: I01e1cf7f97a72b78d4c26543b73910ac6a90e145\nCloses-Bug: #1332626\n'}]",0,128912,332ea6fc279c3e038a5fcb7663aab89e337363cd,12,4,3,13291,,,0,"Fixes homepage in metadata and internal docs

* Correct homepage in package metadata file
* Correct launchpad & GitHub home in contributing.rst

Change-Id: I01e1cf7f97a72b78d4c26543b73910ac6a90e145
Closes-Bug: #1332626
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/12/128912/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributing.rst', 'setup.cfg']",2,1de6879b866a92673011cf242bd13b14f4baf959,fix-bug-1332626,home-page = https://launchpad.net/python-designateclient,home-page = https://launchpad.net/python-designateclientclient,4,4
openstack%2Fsahara~master~Ife13065cce0213984eed6f909e89dabb15ecbd44,openstack/sahara,master,Ife13065cce0213984eed6f909e89dabb15ecbd44,Fix old style class declaration,MERGED,2014-10-20 02:15:55.000000000,2014-10-20 11:40:05.000000000,2014-10-20 11:40:04.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 9740}, {'_account_id': 10068}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-10-20 02:15:55.000000000', 'files': ['sahara/tests/unit/service/test_volumes.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/8d00a87c4056a7cd0a88321c5ab3bbee6ed0b208', 'message': 'Fix old style class declaration\n\nUse new style (inherit from `object`) instead of old style class declaration\n\nChange-Id: Ife13065cce0213984eed6f909e89dabb15ecbd44\nCloses-Bug: #1380723\n'}]",0,129500,8d00a87c4056a7cd0a88321c5ab3bbee6ed0b208,15,7,1,9740,,,0,"Fix old style class declaration

Use new style (inherit from `object`) instead of old style class declaration

Change-Id: Ife13065cce0213984eed6f909e89dabb15ecbd44
Closes-Bug: #1380723
",git fetch https://review.opendev.org/openstack/sahara refs/changes/00/129500/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/tests/unit/service/test_volumes.py'],1,8d00a87c4056a7cd0a88321c5ab3bbee6ed0b208,Bug1380723, class Instance(object):, class Instance:,1,1
openstack%2Fheat~master~I81bc3bf753843f521ccb8a96b9a40a6f82ca8d92,openstack/heat,master,I81bc3bf753843f521ccb8a96b9a40a6f82ca8d92,Do not match subnets if no networks defined,MERGED,2014-10-14 00:49:23.000000000,2014-10-20 11:39:57.000000000,2014-10-20 11:39:56.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 7256}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-10-14 00:49:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8d7992d849013a9f4e425b03a557a6da27626fd7', 'message': ""Do not match subnets if no networks defined\n\nServer will now skip looking for subnets on shared networks\nif the server doesn't have any networks defined. Added tests\nto verify existing behavior as well as to guard regression.\n\nChange-Id: I81bc3bf753843f521ccb8a96b9a40a6f82ca8d92\nCloses-Bug: #1380846\n""}, {'number': 2, 'created': '2014-10-14 00:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a931acee1ba0d12f0abef27f4825c92bc8bd086b', 'message': ""Do not match subnets if no networks defined\n\nServer will now skip looking for subnets on shared networks\nif the server doesn't have any networks defined. Added tests\nto verify existing behavior as well as to guard regression.\n\nChange-Id: I81bc3bf753843f521ccb8a96b9a40a6f82ca8d92\nCloses-Bug: #1380846\n""}, {'number': 3, 'created': '2014-10-14 16:40:47.000000000', 'files': ['heat/engine/resources/server.py', 'heat/tests/test_server.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/e0551487313e738eb83e586b32f44e0ddd7b8899', 'message': ""Do not match subnets if no networks defined\n\nServer will now skip looking for subnets on shared networks\nif the server doesn't have any networks defined. Added tests\nto verify existing behavior as well as to guard regression.\n\nChange-Id: I81bc3bf753843f521ccb8a96b9a40a6f82ca8d92\nCloses-Bug: #1380846\n""}]",3,128146,e0551487313e738eb83e586b32f44e0ddd7b8899,21,9,3,7256,,,0,"Do not match subnets if no networks defined

Server will now skip looking for subnets on shared networks
if the server doesn't have any networks defined. Added tests
to verify existing behavior as well as to guard regression.

Change-Id: I81bc3bf753843f521ccb8a96b9a40a6f82ca8d92
Closes-Bug: #1380846
",git fetch https://review.opendev.org/openstack/heat refs/changes/46/128146/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/server.py', 'heat/tests/test_server.py']",2,8d7992d849013a9f4e425b03a557a6da27626fd7,bug/1380846,"subnet_template = ''' heat_template_version: 2013-05-23 resources: server: type: OS::Nova::Server properties: image: F17-x86_64-gold flavor: m1.large networks: - { uuid: 12345 } subnet: type: OS::Neutron::Subnet properties: network: 12345 ''' no_subnet_template = ''' heat_template_version: 2013-05-23 resources: server: type: OS::Nova::Server properties: image: F17-x86_64-gold flavor: m1.large subnet: type: OS::Neutron::Subnet properties: network: 12345 ''' def _setup_test_stack(self, stack_name, test_templ=wp_template): t = template_format.parse(test_templ) def test_subnet_dependency(self): template, stack = self._setup_test_stack('subnet-test', subnet_template) server_rsrc = stack['server'] subnet_rsrc = stack['subnet'] deps = [] server_rsrc.add_dependencies(deps) self.assertEqual(4, len(deps)) self.assertEqual(subnet_rsrc, deps[3]) def test_subnet_nodeps(self): template, stack = self._setup_test_stack('subnet-test', no_subnet_template) server_rsrc = stack['server'] subnet_rsrc = stack['subnet'] deps = [] server_rsrc.add_dependencies(deps) self.assertEqual(2, len(deps)) self.assertNotIn(subnet_rsrc, deps) "," def _setup_test_stack(self, stack_name): t = template_format.parse(wp_template)",64,14
openstack%2Fnova~master~I7745af7e22164a96af800ae796bda077e49bf291,openstack/nova,master,I7745af7e22164a96af800ae796bda077e49bf291,Xen: Attempt to find and cleanup orphaned SR during delete,MERGED,2014-09-10 18:07:10.000000000,2014-10-20 11:39:24.000000000,2014-10-20 11:39:21.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6735}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 11642}]","[{'number': 1, 'created': '2014-09-10 18:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d979d30e7d7ea10dd5ef3996cd803b4ec4bf5c82', 'message': ""WIP Xen: Attempt to find and cleanup orphaned SR on delete\n\nBefore some patches merged to better handle failures to boot an instance\nfrom a volume it was possible to have an attached volume with an SR and\nplugged PBD but no VM.  And the destroy method in xenapi short circuits\nif no VM is present because everything is looked up from there in order\nto be cleaned up.\n\nThis adds a check to see if a volume is supposed to be attached during\ndestroy if no VM is present and attempts to look it up via the SR uuid\nand clean it up.\n\nI would like to say that this patch is unnecessary, as it's sort of\nhackish, but it's possible that some deployments have instances in this\nstate and this will allow them to cleanup without manually running\ncommands on the hypervisor.\n\nSoliciting feedback while tests are being written.\n\nChange-Id: I7745af7e22164a96af800ae796bda077e49bf291\n""}, {'number': 2, 'created': '2014-09-10 20:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8fc022808766270d88598c9ecbc9e614b3d661cc', 'message': ""Xen: Attempt to find and cleanup orphaned SR during delete\n\nBefore some patches merged to better handle failures to boot an instance\nfrom a volume it was possible to have an attached volume with an SR and\nplugged PBD but no VM.  And the destroy method in xenapi short circuits\nif no VM is present because everything is looked up from there in order\nto be cleaned up.\n\nThis adds a check to see if a volume is supposed to be attached during\ndestroy if no VM is present and attempts to look it up via the SR uuid\nand clean it up.\n\nI would like to say that this patch is unnecessary, as it's sort of\nhackish, but it's possible that some deployments have instances in this\nstate and this will allow them to cleanup without manually running\ncommands on the hypervisor.\n\nCloses-bug: #1367918\nChange-Id: I7745af7e22164a96af800ae796bda077e49bf291\n""}, {'number': 3, 'created': '2014-09-11 15:07:35.000000000', 'files': ['nova/virt/xenapi/vmops.py', 'nova/tests/virt/xenapi/test_vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ba49c5eb387d841d40f81f57d5cefbb00c835bff', 'message': ""Xen: Attempt to find and cleanup orphaned SR during delete\n\nBefore some patches merged to better handle failures to boot an instance\nfrom a volume it was possible to have an attached volume with an SR and\nplugged PBD but no VM.  And the destroy method in xenapi short circuits\nif no VM is present because everything is looked up from there in order\nto be cleaned up.\n\nThis adds a check to see if a volume is supposed to be attached during\ndestroy if no VM is present and attempts to look it up via the SR uuid\nand clean it up.\n\nI would like to say that this patch is unnecessary, as it's sort of\nhackish, but it's possible that some deployments have instances in this\nstate and this will allow them to cleanup without manually running\ncommands on the hypervisor.\n\nCloses-bug: #1367918\nChange-Id: I7745af7e22164a96af800ae796bda077e49bf291\n""}]",5,120500,ba49c5eb387d841d40f81f57d5cefbb00c835bff,28,11,3,5441,,,0,"Xen: Attempt to find and cleanup orphaned SR during delete

Before some patches merged to better handle failures to boot an instance
from a volume it was possible to have an attached volume with an SR and
plugged PBD but no VM.  And the destroy method in xenapi short circuits
if no VM is present because everything is looked up from there in order
to be cleaned up.

This adds a check to see if a volume is supposed to be attached during
destroy if no VM is present and attempts to look it up via the SR uuid
and clean it up.

I would like to say that this patch is unnecessary, as it's sort of
hackish, but it's possible that some deployments have instances in this
state and this will allow them to cleanup without manually running
commands on the hypervisor.

Closes-bug: #1367918
Change-Id: I7745af7e22164a96af800ae796bda077e49bf291
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/120500/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/xenapi/vmops.py'],1,d979d30e7d7ea10dd5ef3996cd803b4ec4bf5c82,bug/1367918," # NOTE(alaski): `block_device_info` is used to determine if there's a # volume still attached if the VM is not present. destroy_disks=destroy_disks, block_device_info=block_device_info) destroy_disks=True, block_device_info=None): # NOTE(alaski): There should not be a block device mapping here, # but if there is it very likely means there was an error cleaning # it up previously and there is now an orphaned sr/pbd. This will # prevent both volume and instance deletes from completing. bdms = block_device_info['block_device_mapping'] or [] if not bdms: return for bdm in bdms: volume_id = bdm['connection_info']['data']['volume_id'] sr_uuid = 'FA15E-D15C-%s' % volume_id sr_ref = None try: sr_ref = volume_utils.find_sr_by_uuid(self._session, sr_uuid) except: LOG.exception('Failed to find an SR for volume: %s' % volume_id, instance=instance) try: if sr_ref: volume_utils.forget_sr(self._session, sr_ref) else: LOG.error('Volume %s is associated with the instance ' 'but no SR was found for it' % volume_id, instance=instance) except: LOG.exception('Failed to forget the SR for volume: %s' % volume_id, instance=instance)", destroy_disks=destroy_disks) destroy_disks=True):,33,2
openstack%2Fsahara~master~I7d03b553212b9bc4fef74f9c8a99958827dc8a54,openstack/sahara,master,I7d03b553212b9bc4fef74f9c8a99958827dc8a54,Small refactoring of get_by_id methods,MERGED,2014-10-16 12:06:34.000000000,2014-10-20 11:39:13.000000000,2014-10-20 11:39:12.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-16 12:06:34.000000000', 'files': ['sahara/plugins/vanilla/v1_2_1/versionhandler.py', 'sahara/tests/unit/conductor/test_api.py', 'sahara/service/direct_engine.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/e6566d9125e36bb1cfd09b1a6b8e00de0da03e54', 'message': 'Small refactoring of get_by_id methods\n\n* Only single invocation of this function left in utils.general\n* Removed unused _find_by_id in direct.py\n\nChange-Id: I7d03b553212b9bc4fef74f9c8a99958827dc8a54\n'}]",0,128898,e6566d9125e36bb1cfd09b1a6b8e00de0da03e54,14,7,1,7125,,,0,"Small refactoring of get_by_id methods

* Only single invocation of this function left in utils.general
* Removed unused _find_by_id in direct.py

Change-Id: I7d03b553212b9bc4fef74f9c8a99958827dc8a54
",git fetch https://review.opendev.org/openstack/sahara refs/changes/98/128898/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/vanilla/v1_2_1/versionhandler.py', 'sahara/tests/unit/conductor/test_api.py', 'sahara/service/direct_engine.py']",3,e6566d9125e36bb1cfd09b1a6b8e00de0da03e54,refactoring,," def _find_by_id(self, lst, id): for obj in lst: if obj.id == id: return obj return None ",4,24
openstack%2Ftrove~master~I4bb290d8de6253d65b7877c743bb288ee2bce536,openstack/trove,master,I4bb290d8de6253d65b7877c743bb288ee2bce536,Increase test rate limit to avoid rate limit error,MERGED,2014-10-02 12:21:19.000000000,2014-10-20 11:39:08.000000000,2014-10-20 11:39:07.000000000,"[{'_account_id': 3}, {'_account_id': 4463}, {'_account_id': 5293}, {'_account_id': 6162}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9749}]","[{'number': 1, 'created': '2014-10-02 12:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c68f972b86f27d80f1ad9adea27aa57241bd6f01', 'message': ""Increase test rate limit to avoid rate limit error\n\nThe current rate limit is 200 requests per minute. I'm getting\nconsistent tox failures as the machine is exceeding this rate. The fix\nimpacts only test code and adjusts the limit and a test that has a\nhard-coded reference to the old limit.\n\nChange-Id: I4bb290d8de6253d65b7877c743bb288ee2bce536\nCloses-Bug: #1376689\n""}, {'number': 2, 'created': '2014-10-02 12:22:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5dd50d869c1696c78fac2a6f576d28b46f10ffee', 'message': ""Increase test rate limit to avoid rate limit error\n\nThe current rate limit is 200 requests per minute. I'm getting\nconsistent tox failures as the machine is exceeding this rate. The fix\nimpacts only test code and adjusts the limit and a test that has a\nhard-coded reference to the old limit. Why 500 you may ask? Because\n600 worked and 450 failed consistently with the rate limit error.\n\nChange-Id: I4bb290d8de6253d65b7877c743bb288ee2bce536\nCloses-Bug: #1376689\n""}, {'number': 3, 'created': '2014-10-08 16:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8ff08cc2501985025043b30b197bb97a6c89f046', 'message': ""Increase test rate limit to avoid rate limit error\n\nThe current rate limit is 200 requests per minute. I'm getting\nconsistent tox failures as the machine is exceeding this rate. The fix\nimpacts only test code and adjusts the limit and a test that has a\nhard-coded reference to the old limit. Why 500 you may ask? Because\n600 worked and 450 failed consistently with the rate limit error.\n\nIn addition, the change addresses the fact that some test\nconfiguration values are duplicated in the test; the change makes the\ntest reference the configuration value.\n\nChange-Id: I4bb290d8de6253d65b7877c743bb288ee2bce536\nCloses-Bug: #1376689\nCloses-Bug: #1378932\n""}, {'number': 4, 'created': '2014-10-14 14:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f2a9ebce26b936c8113d4da487f364766015d80c', 'message': ""Increase test rate limit to avoid rate limit error\n\nThe current rate limit is 200 requests per minute. I'm getting\nconsistent tox failures as the machine is exceeding this rate. The fix\nimpacts only test code and adjusts the limit and a test that has a\nhard-coded reference to the old limit. Why 500 you may ask? Because\n600 worked and 450 failed consistently with the rate limit error.\n\nIn addition, the change addresses the fact that some test\nconfiguration values are duplicated in the test; the change makes the\ntest reference the configuration value.\n\nChange-Id: I4bb290d8de6253d65b7877c743bb288ee2bce536\nCloses-Bug: #1376689\nCloses-Bug: #1378932\n""}, {'number': 5, 'created': '2014-10-15 17:24:46.000000000', 'files': ['trove/tests/api/limits.py', 'etc/trove/trove.conf.test'], 'web_link': 'https://opendev.org/openstack/trove/commit/a67c0ca7030362c35ea8dd183229bc73173cf60b', 'message': ""Increase test rate limit to avoid rate limit error\n\nThe current rate limit is 200 requests per minute. I'm getting\nconsistent tox failures as the machine is exceeding this rate. The fix\nimpacts only test code and adjusts the limit and a test that has a\nhard-coded reference to the old limit. Why 500 you may ask? Because\n600 worked and 450 failed consistently with the rate limit error.\n\nIn addition, the change addresses the fact that some test\nconfiguration values are duplicated in the test; the change makes the\ntest reference the configuration value.\n\nChange-Id: I4bb290d8de6253d65b7877c743bb288ee2bce536\nCloses-Bug: #1376689\nCloses-Bug: #1378932\n""}]",2,125611,a67c0ca7030362c35ea8dd183229bc73173cf60b,35,9,5,9664,,,0,"Increase test rate limit to avoid rate limit error

The current rate limit is 200 requests per minute. I'm getting
consistent tox failures as the machine is exceeding this rate. The fix
impacts only test code and adjusts the limit and a test that has a
hard-coded reference to the old limit. Why 500 you may ask? Because
600 worked and 450 failed consistently with the rate limit error.

In addition, the change addresses the fact that some test
configuration values are duplicated in the test; the change makes the
test reference the configuration value.

Change-Id: I4bb290d8de6253d65b7877c743bb288ee2bce536
Closes-Bug: #1376689
Closes-Bug: #1378932
",git fetch https://review.opendev.org/openstack/trove refs/changes/11/125611/4 && git format-patch -1 --stdout FETCH_HEAD,"['trove/tests/api/limits.py', 'etc/trove/trove.conf.test']",2,c68f972b86f27d80f1ad9adea27aa57241bd6f01,bugs/bug-1376689,http_get_rate = 500 http_post_rate = 500 http_put_rate = 500 http_delete_rate = 500,http_get_rate = 200 http_post_rate = 200 http_put_rate = 200 http_delete_rate = 200,5,5
openstack%2Fnova~master~I373001e0ef0e4fe4ab900d399756f27101cfe5c8,openstack/nova,master,I373001e0ef0e4fe4ab900d399756f27101cfe5c8,Pass block device info in pre_live_migration,MERGED,2014-10-02 08:54:12.000000000,2014-10-20 11:38:54.000000000,2014-10-20 11:38:51.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 8122}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-02 08:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9a7d99104e5f738d3d18d8b4ad01c06871399c7', 'message': 'Pass block device info in pre_live_migration\n\nIn case of block migration, this adds block device information to the\ndisk information handled by pre_live_migration, so that at least in the\ncase of libvirt no spurious files are created corresponding to volumes.\n\nChange-Id: I373001e0ef0e4fe4ab900d399756f27101cfe5c8\nCloses-Bug: 1376586\n'}, {'number': 2, 'created': '2014-10-13 08:02:36.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8489e4a2d100fa34f49a044f1973a163a4bfb8e5', 'message': 'Pass block device info in pre_live_migration\n\nIn case of block migration, this adds block device information to the\ndisk information handled by pre_live_migration, so that at least in the\ncase of libvirt no spurious files are created corresponding to volumes.\n\nCo-Authored-By: florent.flament@cloudwatt.com\nChange-Id: I373001e0ef0e4fe4ab900d399756f27101cfe5c8\nCloses-Bug: 1376586\n'}]",0,125574,8489e4a2d100fa34f49a044f1973a163a4bfb8e5,24,11,2,7385,,,0,"Pass block device info in pre_live_migration

In case of block migration, this adds block device information to the
disk information handled by pre_live_migration, so that at least in the
case of libvirt no spurious files are created corresponding to volumes.

Co-Authored-By: florent.flament@cloudwatt.com
Change-Id: I373001e0ef0e4fe4ab900d399756f27101cfe5c8
Closes-Bug: 1376586
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/125574/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",2,f9a7d99104e5f738d3d18d8b4ad01c06871399c7,bug/1376586," block_device_info = { 'swap': None, 'ephemerals': [], 'block_device_mapping': []} instance.name, block_device_info=block_device_info).AndReturn('fake_disk') instance.uuid).MultipleTimes().AndReturn(fake_bdms)", instance.name).AndReturn('fake_disk') instance.uuid).AndReturn(fake_bdms),9,3
openstack%2Fnova~master~If57d2b8a24b2f6ed3d90a1357e89782194df013c,openstack/nova,master,If57d2b8a24b2f6ed3d90a1357e89782194df013c,Add Quota roll back for deallocate fix ip in nova-network,MERGED,2014-02-26 02:29:41.000000000,2014-10-20 11:38:35.000000000,2014-10-20 11:38:33.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 4601}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 6062}, {'_account_id': 6450}, {'_account_id': 6873}, {'_account_id': 8163}, {'_account_id': 8247}, {'_account_id': 8412}, {'_account_id': 8430}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-02-26 02:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/280c56e86dd39e417737233141a7c2a37de63251', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 2, 'created': '2014-02-26 04:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/649ea8a6ad2c0d2836762c52358e5b2c69076e3c', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 3, 'created': '2014-04-09 07:35:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/147765915562545d6e22967794c7b3c7be143138', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 4, 'created': '2014-04-09 08:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66522547a1a0d49a3e0bc6e323ccb787775edd87', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 5, 'created': '2014-05-13 05:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24f4e7d90be18860f7f79219096c8b1e63a8c3e6', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 6, 'created': '2014-06-17 10:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/648a5f72c91f02289660b2e62e40cdf9bccf1d65', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 7, 'created': '2014-06-19 02:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e72eaa78208c6cabc0996c6354834892d9c0764', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 8, 'created': '2014-07-23 02:19:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b298da595527e5677099cc6534035ea7428c5833', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 9, 'created': '2014-07-23 02:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a22261dcba4a7c459637d82faa2233fa8153f690', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 10, 'created': '2014-07-30 08:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f47c9a53cfda267ec32db62801daa444e7af16f9', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 11, 'created': '2014-07-31 06:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/330beece03a5d6b4ef086fbc279d95f8402017d6', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 12, 'created': '2014-09-16 07:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9408aec5b7727cb97a7804272243901d9ca15ceb', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 13, 'created': '2014-09-18 08:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/30e5e89438963c61ef4ce3cca89af7c6f0d55f82', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 14, 'created': '2014-09-19 06:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1fd3efe0b0a79c6b09037d3c72ca1bfeaa1ec261', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 15, 'created': '2014-09-22 07:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac9324b49bb91b13628ae69fc3970b26390bd181', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 16, 'created': '2014-10-10 13:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7da9c2f1fb484f45cb93361b8966000def1ba1aa', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 17, 'created': '2014-10-10 15:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c7ae1e055b54d9eeb097fdb31379f141db6ffbfe', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}, {'number': 18, 'created': '2014-10-14 12:47:25.000000000', 'files': ['nova/network/manager.py', 'nova/tests/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/635c5b611ae765bca3a888b1fcabe6bf0027c948', 'message': 'Add Quota roll back for deallocate fix ip in nova-network\n\nin nova-network, deallocate_fixed_ip function reserve quota\nfirst then do deallocate operations if any operation failed,\nthe quota reserve operation need to be rollback.\n\nChange-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c\nCloses-Bug: #1284930\n'}]",43,76413,635c5b611ae765bca3a888b1fcabe6bf0027c948,198,18,18,6062,,,0,"Add Quota roll back for deallocate fix ip in nova-network

in nova-network, deallocate_fixed_ip function reserve quota
first then do deallocate operations if any operation failed,
the quota reserve operation need to be rollback.

Change-Id: If57d2b8a24b2f6ed3d90a1357e89782194df013c
Closes-Bug: #1284930
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/76413/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/manager.py'],1,280c56e86dd39e417737233141a7c2a37de63251,bug/1284930," try: self._do_trigger_security_group_members_refresh_for_instance( instance_uuid) if self._validate_instance_zone_for_dns_domain(context, instance): for n in self.instance_dns_manager.get_entries_by_address( address, self.instance_dns_domain): self.instance_dns_manager.delete_entry(n, self.instance_dns_domain) fixed_ip_ref.allocated = False fixed_ip_ref.virtual_interface_id = None fixed_ip_ref.save() if teardown: network = fixed_ip_ref.network if CONF.force_dhcp_release: dev = self.driver.get_dev(network) # NOTE(vish): The below errors should never happen, but # there may be a race condition that is causing # them per # https://code.launchpad.net/bugs/968457, # so we log an error to help track down # the possible race. msg = _(""Unable to release %s because vif doesn't exist."") if not vif_id: LOG.error(msg % address) return vif = vif_obj.VirtualInterface.get_by_id(context, vif_id) if not vif: LOG.error(msg % address) return # NOTE(cfb): Call teardown before release_dhcp to ensure # that the IP can't be re-leased after a release # packet is sent. self._teardown_network_on_host(context, network) # NOTE(vish): This forces a packet so that the # release_fixed_ip # callback will get called by nova-dhcpbridge. self.driver.release_dhcp(dev, address, vif.address) # NOTE(yufang521247): This is probably a failed dhcp # fixed ip. # DHCPRELEASE packet sent to dnsmasq would not trigger # dhcp-bridge to run. Thus it is better to disassociate # such fixed ip here. fixed_ip_ref = fixed_ip_obj.FixedIP.get_by_address( context, address) if (instance_uuid == fixed_ip_ref.instance_uuid and not fixed_ip_ref.leased): fixed_ip_ref.disassociate() else: # We can't try to free the IP address so just call teardown self._teardown_network_on_host(context, network) except Exception: with excutils.save_and_reraise_exception(): if reservations: self.quotas.rollback(context, reservations)"," self._do_trigger_security_group_members_refresh_for_instance( instance_uuid) if self._validate_instance_zone_for_dns_domain(context, instance): for n in self.instance_dns_manager.get_entries_by_address(address, self.instance_dns_domain): self.instance_dns_manager.delete_entry(n, self.instance_dns_domain) fixed_ip_ref.allocated = False fixed_ip_ref.virtual_interface_id = None fixed_ip_ref.save() if teardown: network = fixed_ip_ref.network if CONF.force_dhcp_release: dev = self.driver.get_dev(network) # NOTE(vish): The below errors should never happen, but there # may be a race condition that is causing them per # https://code.launchpad.net/bugs/968457, so we log # an error to help track down the possible race. msg = _(""Unable to release %s because vif doesn't exist."") if not vif_id: LOG.error(msg % address) return vif = vif_obj.VirtualInterface.get_by_id(context, vif_id) if not vif: LOG.error(msg % address) return # NOTE(cfb): Call teardown before release_dhcp to ensure # that the IP can't be re-leased after a release # packet is sent. self._teardown_network_on_host(context, network) # NOTE(vish): This forces a packet so that the release_fixed_ip # callback will get called by nova-dhcpbridge. self.driver.release_dhcp(dev, address, vif.address) # NOTE(yufang521247): This is probably a failed dhcp fixed ip. # DHCPRELEASE packet sent to dnsmasq would not trigger # dhcp-bridge to run. Thus it is better to disassociate such # fixed ip here. fixed_ip_ref = fixed_ip_obj.FixedIP.get_by_address( context, address) if (instance_uuid == fixed_ip_ref.instance_uuid and not fixed_ip_ref.leased): fixed_ip_ref.disassociate() else: # We can't try to free the IP address so just call teardown self._teardown_network_on_host(context, network)",54,45
openstack%2Fdesignate~master~Iddb14f07479bb171318e58704e15b4bccbe29a5a,openstack/designate,master,Iddb14f07479bb171318e58704e15b4bccbe29a5a,Enforce all Object attributes are private or well defined,MERGED,2014-10-14 13:41:20.000000000,2014-10-20 11:38:22.000000000,2014-10-20 11:38:21.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8130}]","[{'number': 1, 'created': '2014-10-14 13:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/df3646c6d2cadf4ceb2bdb3450c790a378d112ed', 'message': 'Enforce all Object attributes are private or well defined\n\nChange-Id: Iddb14f07479bb171318e58704e15b4bccbe29a5a\n'}, {'number': 2, 'created': '2014-10-15 11:48:15.000000000', 'files': ['designate/objects/base.py', 'designate/tests/test_objects/test_base.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/aafb12963cfe03d0c4f84f12dc1a1b5ce02d6c04', 'message': 'Enforce all Object attributes are private or well defined\n\nChange-Id: Iddb14f07479bb171318e58704e15b4bccbe29a5a\n'}]",4,128282,aafb12963cfe03d0c4f84f12dc1a1b5ce02d6c04,12,5,2,741,,,0,"Enforce all Object attributes are private or well defined

Change-Id: Iddb14f07479bb171318e58704e15b4bccbe29a5a
",git fetch https://review.opendev.org/openstack/designate refs/changes/82/128282/2 && git format-patch -1 --stdout FETCH_HEAD,"['designate/objects/base.py', 'designate/tests/test_objects/test_base.py']",2,df3646c6d2cadf4ceb2bdb3450c790a378d112ed,128282," self.assertEqual('MyID', obj.id) self.assertEqual('MyName', obj.name)"," self.assertEqual('MyID', obj._id) self.assertEqual('MyName', obj._name)",15,3
openstack%2Fdiskimage-builder~master~I0de63bee6ad79733d6711478c707a9b41593e85f,openstack/diskimage-builder,master,I0de63bee6ad79733d6711478c707a9b41593e85f,Allow source-repositories to be disabled completely,MERGED,2014-10-15 16:26:44.000000000,2014-10-20 11:35:41.000000000,2014-10-20 11:35:40.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4330}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-10-15 16:26:44.000000000', 'files': ['elements/redhat-common/pre-install.d/02-lsb', 'elements/source-repositories/README.md', 'elements/source-repositories/extra-data.d/98-source-repositories'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/0eccd2808cdec5fd95dcb044edf9db348f47d1b8', 'message': 'Allow source-repositories to be disabled completely\n\nIn our official image builds we are only allowed to use resources\nthat are ""blessed"" by the build system.  This means that external\nthings like git repos and tar files are not allowed.  Currently,\neven in offline mode source-repositories expects those things to\nbe available in the cache, so we need a way to disable it entirely.\n\nThis change adds an environment variable NO_SOURCE_REPOSITORIES\nthat does so.  It can be set in an environment.d script so elements\nthat might rely on a source repository will know it\'s not available.\nThe 02-lsb script in redhat-common is one such example and is\nupdated to handle this case.\n\nChange-Id: I0de63bee6ad79733d6711478c707a9b41593e85f\n'}]",0,128695,0eccd2808cdec5fd95dcb044edf9db348f47d1b8,11,4,1,6928,,,0,"Allow source-repositories to be disabled completely

In our official image builds we are only allowed to use resources
that are ""blessed"" by the build system.  This means that external
things like git repos and tar files are not allowed.  Currently,
even in offline mode source-repositories expects those things to
be available in the cache, so we need a way to disable it entirely.

This change adds an environment variable NO_SOURCE_REPOSITORIES
that does so.  It can be set in an environment.d script so elements
that might rely on a source repository will know it's not available.
The 02-lsb script in redhat-common is one such example and is
updated to handle this case.

Change-Id: I0de63bee6ad79733d6711478c707a9b41593e85f
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/95/128695/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/redhat-common/pre-install.d/02-lsb', 'elements/source-repositories/README.md', 'elements/source-repositories/extra-data.d/98-source-repositories']",3,0eccd2808cdec5fd95dcb044edf9db348f47d1b8,no-source-repos,"# Don't provide any source repositories in environments where they are not allowed if [ -n ""${NO_SOURCE_REPOSITORIES:-}"" ]; then exit 0 fi ",,14,1
openstack%2Fpython-heatclient~master~I682f3c192e46bd50236b10a337f0b129c4b02eb8,openstack/python-heatclient,master,I682f3c192e46bd50236b10a337f0b129c4b02eb8,Put a cap on our cyclomatic complexity,MERGED,2014-10-17 04:35:04.000000000,2014-10-20 11:32:49.000000000,2014-10-20 11:32:49.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 8289}, {'_account_id': 12321}]","[{'number': 1, 'created': '2014-10-17 04:35:04.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/d78711e82f383a93ba601e59654dd3ef99df04ad', 'message': 'Put a cap on our cyclomatic complexity\n\nflake8 has support for cyclomatic complexity (Mccabe) currently our\nworst offender has a complexity of 18 (25 is considered very bad). So\nset our max-complexity to 20 so we keep our complexity in a great shape.\n\nhttps://github.com/flintwork/mccabe\n\nChange-Id: I682f3c192e46bd50236b10a337f0b129c4b02eb8\n'}]",0,129128,d78711e82f383a93ba601e59654dd3ef99df04ad,10,5,1,4715,,,0,"Put a cap on our cyclomatic complexity

flake8 has support for cyclomatic complexity (Mccabe) currently our
worst offender has a complexity of 18 (25 is considered very bad). So
set our max-complexity to 20 so we keep our complexity in a great shape.

https://github.com/flintwork/mccabe

Change-Id: I682f3c192e46bd50236b10a337f0b129c4b02eb8
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/28/129128/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d78711e82f383a93ba601e59654dd3ef99df04ad,,max-complexity=20,,1,0
openstack%2Fheat~master~I528b305a970abfa75d2a44c7a8787d09ac5602a5,openstack/heat,master,I528b305a970abfa75d2a44c7a8787d09ac5602a5,Imported Translations from Transifex,MERGED,2014-10-14 07:14:16.000000000,2014-10-20 11:32:41.000000000,2014-10-20 11:32:40.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6547}, {'_account_id': 6577}, {'_account_id': 9542}, {'_account_id': 12321}]","[{'number': 1, 'created': '2014-10-14 07:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3615f10ad78868477a7cadc36804e07b3aa6ea64', 'message': 'Imported Translations from Transifex\n\nChange-Id: I528b305a970abfa75d2a44c7a8787d09ac5602a5\n'}, {'number': 2, 'created': '2014-10-15 06:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fd3fb555aaa3a1b9bf0efda55a3cd8bb274c5eb2', 'message': 'Imported Translations from Transifex\n\nChange-Id: I528b305a970abfa75d2a44c7a8787d09ac5602a5\n'}, {'number': 3, 'created': '2014-10-16 07:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/792f4212492f10d89e95151b587ee8898553daa4', 'message': 'Imported Translations from Transifex\n\nChange-Id: I528b305a970abfa75d2a44c7a8787d09ac5602a5\n'}, {'number': 4, 'created': '2014-10-17 06:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4b7e8aa288390571c1655795f44da1cf99a61b45', 'message': 'Imported Translations from Transifex\n\nChange-Id: I528b305a970abfa75d2a44c7a8787d09ac5602a5\n'}, {'number': 5, 'created': '2014-10-18 06:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5d138dc65504c52942a51cd175606a31460742c4', 'message': 'Imported Translations from Transifex\n\nChange-Id: I528b305a970abfa75d2a44c7a8787d09ac5602a5\n'}, {'number': 6, 'created': '2014-10-19 06:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/48294c3c7cefc41675507fd6832c4ff89a4bacb1', 'message': 'Imported Translations from Transifex\n\nChange-Id: I528b305a970abfa75d2a44c7a8787d09ac5602a5\n'}, {'number': 7, 'created': '2014-10-20 06:02:18.000000000', 'files': ['heat/locale/pt_BR/LC_MESSAGES/heat-log-error.po', 'heat/locale/vi_VN/LC_MESSAGES/heat-log-error.po', 'heat/locale/heat.pot', 'heat/locale/vi_VN/LC_MESSAGES/heat-log-info.po', 'heat/locale/heat-log-info.pot', 'heat/locale/de/LC_MESSAGES/heat-log-info.po', 'heat/locale/de/LC_MESSAGES/heat-log-error.po', 'heat/locale/it/LC_MESSAGES/heat-log-info.po', 'heat/locale/en_AU/LC_MESSAGES/heat-log-info.po', 'heat/locale/zh_CN/LC_MESSAGES/heat-log-error.po', 'heat/locale/ja/LC_MESSAGES/heat-log-error.po', 'heat/locale/es/LC_MESSAGES/heat-log-info.po', 'heat/locale/zh_TW/LC_MESSAGES/heat-log-error.po', 'heat/locale/ko_KR/LC_MESSAGES/heat-log-error.po', 'heat/locale/en_AU/LC_MESSAGES/heat-log-error.po', 'heat/locale/fr/LC_MESSAGES/heat-log-error.po', 'heat/locale/heat-log-warning.pot', 'heat/locale/pt_BR/LC_MESSAGES/heat-log-info.po', 'heat/locale/heat-log-error.pot', 'heat/locale/it/LC_MESSAGES/heat-log-error.po', 'heat/locale/te_IN/LC_MESSAGES/heat-log-info.po', 'heat/locale/en_GB/LC_MESSAGES/heat-log-info.po', 'heat/locale/en_GB/LC_MESSAGES/heat-log-error.po', 'heat/locale/es/LC_MESSAGES/heat-log-error.po', 'heat/locale/fr/LC_MESSAGES/heat-log-info.po'], 'web_link': 'https://opendev.org/openstack/heat/commit/d50620916c166de26814f1f3d07701a28a43be87', 'message': 'Imported Translations from Transifex\n\nChange-Id: I528b305a970abfa75d2a44c7a8787d09ac5602a5\n'}]",0,128188,d50620916c166de26814f1f3d07701a28a43be87,31,6,7,11131,,,0,"Imported Translations from Transifex

Change-Id: I528b305a970abfa75d2a44c7a8787d09ac5602a5
",git fetch https://review.opendev.org/openstack/heat refs/changes/88/128188/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/locale/ko_KR/LC_MESSAGES/heat-log-error.po', 'heat/locale/heat.pot', 'heat/locale/ko_KR/LC_MESSAGES/heat-log-info.po']",3,3615f10ad78868477a7cadc36804e07b3aa6ea64,transifex/translations,"# Translations template for heat. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the heat project. # # Translators: # Mario Cho <hephaex@gmail.com>, 2014 msgid """" msgstr """" ""Project-Id-Version: Heat\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-10-14 07:13+0000\n"" ""PO-Revision-Date: 2014-10-14 04:10+0000\n"" ""Last-Translator: Mario Cho <hephaex@gmail.com>\n"" ""Language-Team: Korean (Korea) (http://www.transifex.com/projects/p/heat/"" ""language/ko_KR/)\n"" ""Language: ko_KR\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=1; plural=0;\n"" #: heat/api/aws/ec2token.py:141 msgid ""Checking AWS credentials.."" msgstr ""AWS 자격을 확인하세요."" #: heat/api/aws/ec2token.py:148 msgid ""No AWS Signature found."" msgstr ""AWS 인식을 찾을 수 없습니다. "" #: heat/api/aws/ec2token.py:156 msgid ""No AWSAccessKeyId/Authorization Credential"" msgstr ""AWSAccessKeyId/인증 이 없습니다. "" #: heat/api/aws/ec2token.py:159 msgid ""AWS credentials found, checking against keystone."" msgstr "" keystone 을 검사하여 AWS credentials 발견했습니다."" #: heat/api/aws/ec2token.py:187 #, python-format msgid ""Authenticating with %s"" msgstr ""%s 인증"" #: heat/api/aws/ec2token.py:195 msgid ""AWS authentication successful."" msgstr ""AWS 인증 성공."" #: heat/api/aws/ec2token.py:197 msgid ""AWS authentication failure."" msgstr ""AWS 인증 실패."" #: heat/api/cfn/v1/stacks.py:439 msgid ""validate_template"" msgstr ""validate_template"" #: heat/common/urlfetch.py:44 #, python-format msgid ""Fetching data from %s"" msgstr ""%s 데이터를 가져옴."" #: heat/openstack/common/eventlet_backdoor.py:140 #, python-format msgid ""Eventlet backdoor listening on %(port)s for process %(pid)d"" msgstr ""Eventlet 백도어는 프로세스 %(pid)d 일 동안 %(port)s에서 수신"" #: heat/openstack/common/lockutils.py:83 #, python-format msgid ""Created lock path: %s"" msgstr ""생성된 lock path: %s"" #: heat/openstack/common/lockutils.py:250 #, python-format msgid ""Failed to remove file %(file)s"" msgstr ""%(file)s 화일 제거 실패."" #: heat/openstack/common/service.py:176 #, python-format msgid ""Caught %s, exiting"" msgstr ""%s 발견, 종료 중"" #: heat/openstack/common/service.py:240 msgid ""Parent process has died unexpectedly, exiting"" msgstr ""상위 프로세스가 예기치 않게 정지했습니다. 종료 중"" #: heat/openstack/common/service.py:271 #, python-format msgid ""Child caught %s, exiting"" msgstr ""자식으로 된 %s가 존재함."" #: heat/openstack/common/service.py:310 msgid ""Forking too fast, sleeping"" msgstr ""포크가 너무 빠름. 정지 중"" #: heat/openstack/common/service.py:329 #, python-format msgid ""Started child %d"" msgstr ""%d 하위를 시작했음"" #: heat/openstack/common/service.py:339 #, python-format msgid ""Starting %d workers"" msgstr ""%d 작업자 시작 중"" #: heat/openstack/common/service.py:356 #, python-format msgid ""Child %(pid)d killed by signal %(sig)d"" msgstr ""%(pid)d 하위가 %(sig)d 신호에 의해 강제 종료됨"" #: heat/openstack/common/service.py:360 #, python-format msgid ""Child %(pid)s exited with status %(code)d"" msgstr ""%(pid)s 하위가 %(code)d 상태와 함께 종료했음"" #: heat/openstack/common/service.py:399 #, python-format msgid ""Caught %s, stopping children"" msgstr ""%s 발견, 하위 중지 중"" #: heat/openstack/common/service.py:408 msgid ""Wait called after thread killed. Cleaning up."" msgstr ""쓰레드가 죽기를 기다려서, 지웁니다. "" #: heat/openstack/common/service.py:424 #, python-format msgid ""Waiting on %d children to exit"" msgstr ""%d 하위에서 종료하기를 대기 중임"" ",,1196,923
openstack%2Fnova-specs~master~I82bb43b33aa65ccccaa58cd0429160b27559fdbd,openstack/nova-specs,master,I82bb43b33aa65ccccaa58cd0429160b27559fdbd,Add Parallels Cloud Server support into virt/libvirt driver,ABANDONED,2014-10-16 16:23:31.000000000,2014-10-20 11:25:00.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}]","[{'number': 1, 'created': '2014-10-16 16:23:31.000000000', 'files': ['specs/kilo/pcs-support.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/cbecc00548553b12d71e57734c84903f863003d2', 'message': 'Add Parallels Cloud Server support into virt/libvirt driver\n\nThis specification proposes to implement modification in\nvirt/libvirt driver to support Parallels Cloud Server\n(http://www.parallels.com/products/pcs/).\n\nChange-Id: I82bb43b33aa65ccccaa58cd0429160b27559fdbd\n'}]",0,128990,cbecc00548553b12d71e57734c84903f863003d2,3,2,1,12661,,,0,"Add Parallels Cloud Server support into virt/libvirt driver

This specification proposes to implement modification in
virt/libvirt driver to support Parallels Cloud Server
(http://www.parallels.com/products/pcs/).

Change-Id: I82bb43b33aa65ccccaa58cd0429160b27559fdbd
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/90/128990/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/pcs-support.rst'],1,cbecc00548553b12d71e57734c84903f863003d2,,"===================================================== Parallels Cloud Server support in nova/libvirt driver ===================================================== https://blueprints.launchpad.net/nova/+spec/pcs-support This specification is intended to describe process of extending nova/libvirt driver in order to support Parallels Cloud Server [1] Problem description =================== Parallels Cloud Server (PCS) is a virtualization solution product, which enables service providers to use container and hypervisor virtualization technology via the same management tools and API. Though PCS is supported by libvirt it is absent in OpenStack for now due to not only specific demand related to compute node deployment but also different disk image format implied by usage of Parallels disk loopback block device [2], domains configuration and supported features. Proposed change =============== To make PCS be supported by OpenStack we need to modify a bit nova/libvirt driver mostly regarding a new type of virtualization processing. The end user will be able to configure nova to use PCS by setting libvirt.virt_type option to either to ""vzct"" - for containers or ""vzhyp"" for hypervisor based instances. Also as a native disk format for both VMs and containers in PCS is ploop [2] to get best performance user will need to configure glance-api configuration to support PCS ploop format. nova.conf extract example: [libvirt] ... virt_type = vzct images_type = ploop ... glance-api.conf extract example: ... disk_formats=ami,ari,aki,vhd,vmdk,raw,qcow2,vdi,iso,ploop ... Alternatives ------------ The alternate way is to implement a separate PCS nova driver like this one[3], which was implemented in terms of PCS + OpenStack proof of concept. pros: * There is no middle layer between OpenStack and PCS as pcs-nova-driver uses native PCS's python API. * Changes in pcs-nova-driver will not affect nova/libvirt's code. cons: * Yet another nova driver * It is out-of-tree driver Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- Compute nodes available for ""vzct"" or ""vzhyp"" type of instances have to be deployed with the help of PCS installer. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: dguryanov Other contributors: burluka mnestratov Work Items ---------- * Enhance libvirt driver to support new virt_type value. * Add support of new disk image format in glance * Implement all the functionality necessary to support PCS in libvirt driver * To be specified Dependencies ============ None Testing ======= Testing in the gate will be provided by currently being established Parallels CI testing system. Documentation Impact ==================== New type of virtualization provider should be noticed and host deployment pre-requisites such as the need to have PCS installed on compute nodes. References ========== [1] Parallels Cloud Server http://www.parallels.com/products/pcs [2] Ploop block device http://openvz.org/Ploop [3] PCS nova driver https://github.com/parallels/pcs-nova-driver ",,142,0
openstack%2Fsahara-image-elements~stable%2Ficehouse~I52967022dc2d0f6201d8e9cb5b8373d471eee032,openstack/sahara-image-elements,stable/icehouse,I52967022dc2d0f6201d8e9cb5b8373d471eee032,Bump version for the next stable release,MERGED,2014-10-20 10:44:34.000000000,2014-10-20 11:18:04.000000000,2014-10-20 11:18:03.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-10-20 10:44:34.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/9ca2d5cc00634ddcd3760ee27ece5169bfe7b382', 'message': 'Bump version for the next stable release\n\nChange-Id: I52967022dc2d0f6201d8e9cb5b8373d471eee032\n'}]",0,129568,9ca2d5cc00634ddcd3760ee27ece5169bfe7b382,7,3,1,6786,,,0,"Bump version for the next stable release

Change-Id: I52967022dc2d0f6201d8e9cb5b8373d471eee032
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/68/129568/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,9ca2d5cc00634ddcd3760ee27ece5169bfe7b382,,version = 2014.1.4,version = 2014.1.2,1,1
openstack%2Fsahara-extra~stable%2Ficehouse~Iaebdcf6664787a124e7453eb6f86d7dea2f8bf69,openstack/sahara-extra,stable/icehouse,Iaebdcf6664787a124e7453eb6f86d7dea2f8bf69,Bump version for the next stable release,MERGED,2014-10-20 10:44:33.000000000,2014-10-20 11:16:40.000000000,2014-10-20 11:16:40.000000000,"[{'_account_id': 3}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-10-20 10:44:33.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/sahara-extra/commit/470001745cd569eb11ee1b59e183399dc72015ea', 'message': 'Bump version for the next stable release\n\nChange-Id: Iaebdcf6664787a124e7453eb6f86d7dea2f8bf69\n'}]",0,129567,470001745cd569eb11ee1b59e183399dc72015ea,6,2,1,6786,,,0,"Bump version for the next stable release

Change-Id: Iaebdcf6664787a124e7453eb6f86d7dea2f8bf69
",git fetch https://review.opendev.org/openstack/sahara-extra refs/changes/67/129567/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,470001745cd569eb11ee1b59e183399dc72015ea,,version = 2014.1.4,version = 2014.1.2,1,1
openstack%2Fsahara-dashboard~stable%2Ficehouse~I690bfd1ed97f37746c446a382cb8ca8548744214,openstack/sahara-dashboard,stable/icehouse,I690bfd1ed97f37746c446a382cb8ca8548744214,Bump version for the next stable release,MERGED,2014-10-20 10:41:58.000000000,2014-10-20 11:15:01.000000000,2014-10-20 11:15:00.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-10-20 10:41:58.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/5a0c640aeb9db9185a60e7f03f0d3071fe32ab8c', 'message': 'Bump version for the next stable release\n\nChange-Id: I690bfd1ed97f37746c446a382cb8ca8548744214\n'}]",0,129565,5a0c640aeb9db9185a60e7f03f0d3071fe32ab8c,8,3,1,6786,,,0,"Bump version for the next stable release

Change-Id: I690bfd1ed97f37746c446a382cb8ca8548744214
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/65/129565/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,5a0c640aeb9db9185a60e7f03f0d3071fe32ab8c,,version = 2014.1.4,version = 2014.1.2,1,1
openstack%2Fdiskimage-builder~master~Ic2c46835b27c9319f7a889ffd0ccf3f5ccc1f0cd,openstack/diskimage-builder,master,Ic2c46835b27c9319f7a889ffd0ccf3f5ccc1f0cd,Avoid overwritting of hooks,MERGED,2014-10-08 10:54:43.000000000,2014-10-20 11:04:07.000000000,2014-10-20 11:04:06.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 1926}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-10-08 10:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/5736558355b23b588f22de081ca8ac42f84faea1', 'message': ""Avoid overwritting of hooks\n\nUntil now there was a possibility for two elements to install hooks\nwith the same name, so one of them was overwritten. Change logic to\ncopy the hooks and fail in case one with the same name exists.\n\nAlso, instead of copy the whole element into the temporary hook dir,\njust copy the '*.d' and 'bin' dirs.\n\nChange-Id: Ic2c46835b27c9319f7a889ffd0ccf3f5ccc1f0cd\nCloses-Bug: 1251952\n""}, {'number': 2, 'created': '2014-10-08 15:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/d3b758646bfe30ba69467fc76ea5298da52b59e3', 'message': ""Avoid overwritting of hooks\n\nUntil now there was a possibility for two elements to install hooks\nwith the same name, so one of them was overwritten. Change logic to\ncopy the hooks and fail in case one with the same name exists.\n\nAlso, instead of copy the whole element into the temporary hook dir,\njust copy the '*.d' and 'bin' dirs.\n\nChange-Id: Ic2c46835b27c9319f7a889ffd0ccf3f5ccc1f0cd\nCloses-Bug: 1251952\n""}, {'number': 3, 'created': '2014-10-09 09:44:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/219b3e7c1c700be43fefe7911dcffe21ddd70d27', 'message': ""Avoid overwritting of hooks\n\nUntil now there was a possibility for two elements to install hooks\nwith the same name, so one of them was overwritten. Change logic to\ncopy the hooks and fail in case one with the same name exists.\n\nAlso, instead of copy the whole element into the temporary hook dir,\njust copy the '*.d' and 'bin' dirs.\n\nChange-Id: Ic2c46835b27c9319f7a889ffd0ccf3f5ccc1f0cd\nCloses-Bug: 1251952\n""}, {'number': 4, 'created': '2014-10-16 11:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ce92c18638019e6ee7c57fd3b51a715b80ffe7b9', 'message': 'Avoid overwritting of hooks\n\nUntil now there was a possibility for two elements to install hooks\nwith the same name, so one of them was overwritten. Change logic to\ncopy the hooks and fail in case one with the same name exists.\n\nChange-Id: Ic2c46835b27c9319f7a889ffd0ccf3f5ccc1f0cd\nCloses-Bug: 1251952\n'}, {'number': 5, 'created': '2014-10-17 08:17:35.000000000', 'files': ['lib/common-functions'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/88271757a51a9ea991eda169244a568a5b80d857', 'message': 'Avoid overwritting of hooks\n\nUntil now there was a possibility for two elements to install hooks\nwith the same name, so one of them was overwritten. Change logic to\ncopy the hooks and fail in case one with the same name exists.\n\nChange-Id: Ic2c46835b27c9319f7a889ffd0ccf3f5ccc1f0cd\nCloses-Bug: 1251952\n'}]",1,126869,88271757a51a9ea991eda169244a568a5b80d857,26,4,5,1726,,,0,"Avoid overwritting of hooks

Until now there was a possibility for two elements to install hooks
with the same name, so one of them was overwritten. Change logic to
copy the hooks and fail in case one with the same name exists.

Change-Id: Ic2c46835b27c9319f7a889ffd0ccf3f5ccc1f0cd
Closes-Bug: 1251952
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/69/126869/4 && git format-patch -1 --stdout FETCH_HEAD,['lib/common-functions'],1,5736558355b23b588f22de081ca8ac42f84faea1,bug/1251952,"function copy_hooks_not_overwrite () { _DIR=$(basename $1) test -d $TMP_HOOKS_PATH/$_DIR && mkdir $TMP_HOOKS_PATH/$_DIR for _HOOK in $(ls $1); do if [ ! -f $TMP_HOOKS_PATH/$_DIR/$_HOOK ]; then cp -t $TMP_HOOKS_PATH/$_DIR -a $1/$_HOOK else echo ""There is a duplicated hook in your elements: $_HOOK' exit 1 fi done } for _DIR in $(find $dir/$_ELEMENT -maxdepth 1 -type d -name '*.d'); do copy_hooks_not_overwrite $_DIR done copy_hooks_not_overwrite $dir/$_ELEMENT/bin", cp -t $TMP_HOOKS_PATH -a $dir/$_ELEMENT/* ;,17,1
openstack%2Fdiskimage-builder~master~I144c8993fe040169f440bd4f7a428fdbe3d745cf,openstack/diskimage-builder,master,I144c8993fe040169f440bd4f7a428fdbe3d745cf,Enable dracut deploy ramdisks,MERGED,2014-07-07 20:48:17.000000000,2014-10-20 11:03:55.000000000,2014-10-20 11:03:54.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6928}, {'_account_id': 8688}]","[{'number': 1, 'created': '2014-07-07 20:48:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/3d9b78f56bb732017753a1f0ae171d0765c1b00c', 'message': ""WIP: Use dracut for building ramdisks\n\nSuper rough WIP demonstrating what has to be done to build our\ndeploy ramdisks with dracut.  In theory should pass the f20\novercloud job, almost certainly won't work on Ubuntu right now\ndue to my use of Fedora package names.\n\nChange-Id: I144c8993fe040169f440bd4f7a428fdbe3d745cf\n""}, {'number': 2, 'created': '2014-07-22 18:14:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/35e593177df93ac29828185a5b2247f600e5d1de', 'message': ""WIP: Use dracut for building ramdisks\n\nSuper rough WIP demonstrating what has to be done to build our\ndeploy ramdisks with dracut.  In theory should pass the f20\novercloud job, almost certainly won't work on Ubuntu right now\ndue to my use of Fedora package names.\n\nThere have also been some changes merged recently to support DHCP\nin our ramdisks, which I believe dracut will already handle, but we\nwill need to verify that it continues working.\n\nChange-Id: I144c8993fe040169f440bd4f7a428fdbe3d745cf\n""}, {'number': 3, 'created': '2014-08-20 23:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c8c90f30d1b238109570601edc2197ada651b3d9', 'message': ""Enable dracut deploy ramdisks\n\nAllow the use of dracut for building deploy ramdisks.  This\nfactors out the common functionality between this new element\nand the existing ramdisk element so they can coexist.\n\nThe element builds dracut from source on Ubuntu because the\nUbuntu dracut package is broken and very old, so it can't be\ninstalled properly and causes a number of other issues that\nare fixed by using a newer version of Dracut.\n\nThis initial version should work in virtualized environments.\nFurther validation of its suitability for real baremetal\ndeployments will need to be done in the future, but this should\nbe sufficient to enable that work.\n\nRegarding Dracut specifically, in order to limit the changes\nneeded in the existing scripts this element continues to use a\ncut down version of the /init script that we were building for the\nexisting ramdisk.  However, instead of running it as pid 0 it is\nrun as a Dracut pre-mount hook.  This allows Dracut to set up all\nof the hardware and system bits, while falling early enough in the\nDracut sequence to complete the deployment before Dracut would try\nto boot off the hard disk.\n\nChange-Id: I144c8993fe040169f440bd4f7a428fdbe3d745cf\n""}, {'number': 4, 'created': '2014-08-21 22:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/bbb2a1609773d53ae02d29a0319e19a3e6620d4b', 'message': ""Enable dracut deploy ramdisks\n\nAllow the use of dracut for building deploy ramdisks.  This\nfactors out the common functionality between this new element\nand the existing ramdisk element so they can coexist.\n\nThe element builds dracut from source on Ubuntu because the\nUbuntu dracut package is broken and very old, so it can't be\ninstalled properly and causes a number of other issues that\nare fixed by using a newer version of Dracut.\n\nThis initial version should work in virtualized environments.\nFurther validation of its suitability for real baremetal\ndeployments will need to be done in the future, but this should\nbe sufficient to enable that work.\n\nRegarding Dracut specifically, in order to limit the changes\nneeded in the existing scripts this element continues to use a\ncut down version of the /init script that we were building for the\nexisting ramdisk.  However, instead of running it as pid 0 it is\nrun as a Dracut pre-mount hook.  This allows Dracut to set up all\nof the hardware and system bits, while falling early enough in the\nDracut sequence to complete the deployment before Dracut would try\nto boot off the hard disk.\n\nChange-Id: I144c8993fe040169f440bd4f7a428fdbe3d745cf\n""}, {'number': 5, 'created': '2014-08-26 16:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b26630d60a82b2452c7a1689f854d8c9a870024d', 'message': ""Enable dracut deploy ramdisks\n\nAllow the use of dracut for building deploy ramdisks.  This\nfactors out the common functionality between this new element\nand the existing ramdisk element so they can coexist.\n\nThe element builds dracut from source on Ubuntu because the\nUbuntu dracut package is broken and very old, so it can't be\ninstalled properly and causes a number of other issues that\nare fixed by using a newer version of Dracut.\n\nThis initial version should work in virtualized environments.\nFurther validation of its suitability for real baremetal\ndeployments will need to be done in the future, but this should\nbe sufficient to enable that work.\n\nRegarding Dracut specifically, in order to limit the changes\nneeded in the existing scripts this element continues to use a\ncut down version of the /init script that we were building for the\nexisting ramdisk.  However, instead of running it as pid 0 it is\nrun as a Dracut pre-mount hook.  This allows Dracut to set up all\nof the hardware and system bits, while falling early enough in the\nDracut sequence to complete the deployment before Dracut would try\nto boot off the hard disk.\n\nChange-Id: I144c8993fe040169f440bd4f7a428fdbe3d745cf\n""}, {'number': 6, 'created': '2014-09-17 21:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ab9be52058a50da0934541683426d9980c121a74', 'message': ""Enable dracut deploy ramdisks\n\nAllow the use of dracut for building deploy ramdisks.  This\nfactors out the common functionality between this new element\nand the existing ramdisk element so they can coexist.\n\nThe element builds dracut from source on Ubuntu because the\nUbuntu dracut package is broken and very old, so it can't be\ninstalled properly and causes a number of other issues that\nare fixed by using a newer version of Dracut.\n\nThis initial version should work in virtualized environments.\nFurther validation of its suitability for real baremetal\ndeployments will need to be done in the future, but this should\nbe sufficient to enable that work.\n\nRegarding Dracut specifically, in order to limit the changes\nneeded in the existing scripts this element continues to use a\ncut down version of the /init script that we were building for the\nexisting ramdisk.  However, instead of running it as pid 0 it is\nrun as a Dracut pre-mount hook.  This allows Dracut to set up all\nof the hardware and system bits, while falling early enough in the\nDracut sequence to complete the deployment before Dracut would try\nto boot off the hard disk.\n\nChange-Id: I144c8993fe040169f440bd4f7a428fdbe3d745cf\n""}, {'number': 7, 'created': '2014-09-26 00:34:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/19cea702c46c0d312a8db219b2ef90756ebe5ac5', 'message': ""Enable dracut deploy ramdisks\n\nThe element builds dracut from source on Ubuntu because the\nUbuntu dracut package is broken and very old, so it can't be\ninstalled properly and causes a number of other issues that\nare fixed by using a newer version of Dracut.\n\nThis initial version should work in virtualized environments.\nFurther validation of its suitability for real baremetal\ndeployments will need to be done in the future, but this should\nbe sufficient to enable that work.\n\nRegarding Dracut specifically, in order to limit the changes\nneeded in the existing scripts this element continues to use a\ncut down version of the /init script that we were building for the\nexisting ramdisk.  However, instead of running it as pid 0 it is\nrun as a Dracut pre-mount hook.  This allows Dracut to set up all\nof the hardware and system bits, while falling early enough in the\nDracut sequence to complete the deployment before Dracut would try\nto boot off the hard disk.\n\nbp tripleo-juno-dracut-ramdisks\nChange-Id: I144c8993fe040169f440bd4f7a428fdbe3d745cf\n""}, {'number': 8, 'created': '2014-09-29 23:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/4a16a5f9cb70eea3ff18ad700df427ce8780745c', 'message': ""Enable dracut deploy ramdisks\n\nThe element builds dracut from source on Ubuntu because the\nUbuntu dracut package is broken and very old, so it can't be\ninstalled properly and causes a number of other issues that\nare fixed by using a newer version of Dracut.\n\nThis initial version should work in virtualized environments.\nFurther validation of its suitability for real baremetal\ndeployments will need to be done in the future, but this should\nbe sufficient to enable that work.\n\nRegarding Dracut specifically, in order to limit the changes\nneeded in the existing scripts this element continues to use a\ncut down version of the /init script that we were building for the\nexisting ramdisk.  However, instead of running it as pid 0 it is\nrun as a Dracut pre-mount hook.  This allows Dracut to set up all\nof the hardware and system bits, while falling early enough in the\nDracut sequence to complete the deployment before Dracut would try\nto boot off the hard disk.\n\nbp tripleo-juno-dracut-ramdisks\nChange-Id: I144c8993fe040169f440bd4f7a428fdbe3d745cf\n""}, {'number': 9, 'created': '2014-09-30 19:18:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/a2659151ae4e1ba62ee51c39bd0da35fe8cd17fa', 'message': ""Enable dracut deploy ramdisks\n\nThe element builds dracut from source on Ubuntu because the\nUbuntu dracut package is broken and very old, so it can't be\ninstalled properly and causes a number of other issues that\nare fixed by using a newer version of Dracut.\n\nThis initial version should work in virtualized environments.\nFurther validation of its suitability for real baremetal\ndeployments will need to be done in the future, but this should\nbe sufficient to enable that work.\n\nRegarding Dracut specifically, in order to limit the changes\nneeded in the existing scripts this element continues to use a\ncut down version of the /init script that we were building for the\nexisting ramdisk.  However, instead of running it as pid 0 it is\nrun as a Dracut pre-mount hook.  This allows Dracut to set up all\nof the hardware and system bits, while falling early enough in the\nDracut sequence to complete the deployment before Dracut would try\nto boot off the hard disk.\n\nbp tripleo-juno-dracut-ramdisks\nChange-Id: I144c8993fe040169f440bd4f7a428fdbe3d745cf\n""}, {'number': 10, 'created': '2014-10-08 21:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/9607c8bba30fbd0c2bb23ad220dba9c512dfdd11', 'message': ""Enable dracut deploy ramdisks\n\nThe element builds dracut from source on Ubuntu because the\nUbuntu dracut package is broken and very old, so it can't be\ninstalled properly and causes a number of other issues that\nare fixed by using a newer version of Dracut.\n\nThis initial version should work in virtualized environments.\nFurther validation of its suitability for real baremetal\ndeployments will need to be done in the future, but this should\nbe sufficient to enable that work.\n\nRegarding Dracut specifically, in order to limit the changes\nneeded in the existing scripts this element continues to use a\ncut down version of the /init script that we were building for the\nexisting ramdisk.  However, instead of running it as pid 0 it is\nrun as a Dracut pre-mount hook.  This allows Dracut to set up all\nof the hardware and system bits, while falling early enough in the\nDracut sequence to complete the deployment before Dracut would try\nto boot off the hard disk.\n\nbp tripleo-juno-dracut-ramdisks\nChange-Id: I144c8993fe040169f440bd4f7a428fdbe3d745cf\n""}, {'number': 11, 'created': '2014-10-10 15:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/6bc52adaa75011248bd42b064a9231a97c2cd131', 'message': ""Enable dracut deploy ramdisks\n\nThe element builds dracut from source on Ubuntu because the\nUbuntu dracut package is broken and very old, so it can't be\ninstalled properly and causes a number of other issues that\nare fixed by using a newer version of Dracut.\n\nThis initial version should work in virtualized environments.\nFurther validation of its suitability for real baremetal\ndeployments will need to be done in the future, but this should\nbe sufficient to enable that work.\n\nRegarding Dracut specifically, in order to limit the changes\nneeded in the existing scripts this element continues to use a\ncut down version of the /init script that we were building for the\nexisting ramdisk.  However, instead of running it as pid 0 it is\nrun as a Dracut pre-mount hook.  This allows Dracut to set up all\nof the hardware and system bits, while falling early enough in the\nDracut sequence to complete the deployment before Dracut would try\nto boot off the hard disk.\n\nbp tripleo-juno-dracut-ramdisks\nChange-Id: I144c8993fe040169f440bd4f7a428fdbe3d745cf\n""}, {'number': 12, 'created': '2014-10-17 21:38:17.000000000', 'files': ['bin/disk-image-create', 'elements/deploy-ironic/init.d/80-deploy-ironic', 'elements/dracut-ramdisk/environment.d/10-dracut-version.bash', 'lib/common-functions', 'elements/dracut-ramdisk/element-deps', 'elements/dracut-ramdisk/post-install.d/99-build-dracut-ramdisk', 'lib/ramdisk-defaults', 'elements/dracut-ramdisk/install.d/20-install-dracut-deps', 'elements/dracut-ramdisk/source-repository-dracut', 'lib/ramdisk-functions', 'elements/dracut-ramdisk/README.md', 'elements/dracut-ramdisk/extra-data.d/scripts/module/module-setup.sh', 'elements/dracut-ramdisk/pkg-map', 'elements/dracut-ramdisk/extra-data.d/scripts/module/deploy-cmdline.sh'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/eed30adc4870e2fd787e4cf3903ddb7d79c86e23', 'message': ""Enable dracut deploy ramdisks\n\nThe element builds dracut from source on Ubuntu because the\nUbuntu dracut package is broken and very old, so it can't be\ninstalled properly and causes a number of other issues that\nare fixed by using a newer version of Dracut.\n\nThis initial version should work in virtualized environments.\nFurther validation of its suitability for real baremetal\ndeployments will need to be done in the future, but this should\nbe sufficient to enable that work.\n\nRegarding Dracut specifically, in order to limit the changes\nneeded in the existing scripts this element continues to use a\ncut down version of the /init script that we were building for the\nexisting ramdisk.  However, instead of running it as pid 0 it is\nrun as a Dracut pre-mount hook.  This allows Dracut to set up all\nof the hardware and system bits, while falling early enough in the\nDracut sequence to complete the deployment before Dracut would try\nto boot off the hard disk.\n\nbp tripleo-juno-dracut-ramdisks\nChange-Id: I144c8993fe040169f440bd4f7a428fdbe3d745cf\n""}]",26,105275,eed30adc4870e2fd787e4cf3903ddb7d79c86e23,76,4,12,6928,,,0,"Enable dracut deploy ramdisks

The element builds dracut from source on Ubuntu because the
Ubuntu dracut package is broken and very old, so it can't be
installed properly and causes a number of other issues that
are fixed by using a newer version of Dracut.

This initial version should work in virtualized environments.
Further validation of its suitability for real baremetal
deployments will need to be done in the future, but this should
be sufficient to enable that work.

Regarding Dracut specifically, in order to limit the changes
needed in the existing scripts this element continues to use a
cut down version of the /init script that we were building for the
existing ramdisk.  However, instead of running it as pid 0 it is
run as a Dracut pre-mount hook.  This allows Dracut to set up all
of the hardware and system bits, while falling early enough in the
Dracut sequence to complete the deployment before Dracut would try
to boot off the hard disk.

bp tripleo-juno-dracut-ramdisks
Change-Id: I144c8993fe040169f440bd4f7a428fdbe3d745cf
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/75/105275/4 && git format-patch -1 --stdout FETCH_HEAD,"['elements/ramdisk/install.d/20-install-dhcp-client', 'elements/ramdisk/extra-data.d/scripts/init', 'elements/ramdisk/init.d/02-start-network', 'lib/ramdisk-functions', 'elements/ramdisk/extra-data.d/scripts/module/deploy-cmdline.sh', 'elements/ramdisk/extra-data.d/scripts/module/module-setup.sh', 'elements/ramdisk/post-install.d/99-build-ramdisk']",7,3d9b78f56bb732017753a1f0ae171d0765c1b00c,bp/tripleo-juno-dracut-ramdisks,"MODULE=""$_LIB/scripts/module""cp -r $MODULE /usr/lib/dracut/modules.d/80deploy-ramdisk cp $TMP_MOUNT_PATH/init /usr/lib/dracut/modules.d/80deploy-ramdisk/init.sh dracut -N --install 'tail head awk ifconfig cut expr route ping tgtd tgtadm nc wget' \ --kernel-cmdline ""rd.shell rdinitdebug rd.neednet=1"" \ --include $TMP_MOUNT_PATH/init-func /init-func \ --kver ${KERNEL_VERSION} \ --add-drivers ""virtio virtio_net virtio_blk"" \ /tmp/ramdisk",create_ramdisk_base populate_lib populate_busyboxpopulate_udev finalise_image save_image /tmp/ramdisk,51,105
openstack%2Ffreezer~master~I88c9d922c51a43c1722268d4dbed77e594e089aa,openstack/freezer,master,I88c9d922c51a43c1722268d4dbed77e594e089aa,Fixed bug launchpad #1382809 to manage token expired,MERGED,2014-10-18 20:39:21.000000000,2014-10-20 10:47:59.000000000,2014-10-20 10:47:59.000000000,"[{'_account_id': 3}, {'_account_id': 1054}, {'_account_id': 1207}, {'_account_id': 6780}, {'_account_id': 9074}, {'_account_id': 12211}, {'_account_id': 12629}]","[{'number': 1, 'created': '2014-10-18 20:39:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/47c5b20df773e6220701c7bdd11e017a94d4b273', 'message': ""Fixed bug launchpad #1382809 to manage token expired\n\nCurrenntly Freezer handle token refresh when uploading data segments,\nbut there's a but in the file backup.py in the lines ~130 and ~178,\nas the client object used to upload the tar meta data and the\nswift manifest can be expried is it not use used the client object\nrefreshed during the segments upload\n\nlaunchpad: https://bugs.launchpad.net/freezer/+bug/1382809\n\nChange-Id: I88c9d922c51a43c1722268d4dbed77e594e089aa\n""}, {'number': 2, 'created': '2014-10-19 21:52:17.000000000', 'files': ['freezer/backup.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/425dc3506b32625ba29d638514051dddc253354d', 'message': ""Fixed bug launchpad #1382809 to manage token expired\n\nCurrenntly Freezer handle token refresh when uploading data segments,\nbut there's a bug in the file backup.py in the lines ~130 and ~178.\nThe client object called to upload the tar meta data and the\nswift manifest, can  be expired as it is initialized before\nthe segments upload process.\n\nlaunchpad: https://bugs.launchpad.net/freezer/+bug/1382809\n\nChange-Id: I88c9d922c51a43c1722268d4dbed77e594e089aa\n""}]",1,129439,425dc3506b32625ba29d638514051dddc253354d,10,7,2,11151,,,0,"Fixed bug launchpad #1382809 to manage token expired

Currenntly Freezer handle token refresh when uploading data segments,
but there's a bug in the file backup.py in the lines ~130 and ~178.
The client object called to upload the tar meta data and the
swift manifest, can  be expired as it is initialized before
the segments upload process.

launchpad: https://bugs.launchpad.net/freezer/+bug/1382809

Change-Id: I88c9d922c51a43c1722268d4dbed77e594e089aa
",git fetch https://review.opendev.org/openstack/freezer refs/changes/39/129439/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/backup.py'],1,47c5b20df773e6220701c7bdd11e017a94d4b273,master,"from freezer.swift import add_object, manifest_upload, get_client # Request a new auth client in case the current token # is expired before uploading tar meta data or the swift manifest backup_opt_dict = get_client(backup_opt_dict) backup_opt_dict.sw_connector.put_object(","from freezer.swift import add_object, manifest_upload # Extract some values from arguments that will be used later on # Initialize swift client object, generate container segments name # and extract backup name sw_connector = backup_opt_dict.sw_connector sw_connector.put_object(",7,7
openstack%2Frally~master~I2e0518a3189b4bb6c04187a346dfb5c846c293dc,openstack/rally,master,I2e0518a3189b4bb6c04187a346dfb5c846c293dc,Add detailed description for rally commands,MERGED,2014-09-29 22:24:11.000000000,2014-10-20 10:44:41.000000000,2014-10-20 10:44:41.000000000,"[{'_account_id': 3}, {'_account_id': 6124}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 9545}, {'_account_id': 9601}]","[{'number': 1, 'created': '2014-09-29 22:24:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d88940ec78ebd8df0e66beb45a42f71a12c42503', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 2, 'created': '2014-09-30 01:26:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a1d9ba2882988bfd270629b66a54859aa7ade73a', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 3, 'created': '2014-09-30 17:41:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1db718c4918435ae2ccfbee2bcfdc9f2dd1d0c09', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 4, 'created': '2014-10-01 02:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2dc6c77d8e98dd1be37bba08f3f4edb64840b41a', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 5, 'created': '2014-10-02 04:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/781ebb55d8c3931e4bc93daf0bcc162381ca88b4', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 6, 'created': '2014-10-02 15:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/921bd584313554a8a1b795b131d921cf63847e84', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 7, 'created': '2014-10-03 15:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/745ccb068491e474d7c890f7e5956f0116b116e4', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 8, 'created': '2014-10-03 15:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/323ee15e0bc35a6891f19d3377b17b0f6bc58db0', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 9, 'created': '2014-10-03 23:58:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5973556f90f6d1dac0594e3bde63e16d7f8c45cf', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 10, 'created': '2014-10-05 04:26:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5eb73b3a0476479c937558025ed8cffc2d4f0e8d', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 11, 'created': '2014-10-06 06:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/785bc2a4c5a8d3728340b00635aa8108be13ad20', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 12, 'created': '2014-10-09 13:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b4da67c7ba49362753e87c111cc4bfe722dba352', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 13, 'created': '2014-10-09 14:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a0f5c4f0988742192b902901bb35b0f8a2a133ac', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 14, 'created': '2014-10-10 15:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ab6dae3a72c30025189a4d999fb781dabc56caa0', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 15, 'created': '2014-10-10 19:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5abc9353191fceff43635a770d231a20a4ce771e', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 16, 'created': '2014-10-13 09:47:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0f758fcf5b00d16492f54fba0a6fb6a9919b45cb', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 17, 'created': '2014-10-14 21:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7174a2792ba50dfdb5b57e26bb10ad4afc3ec123', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 18, 'created': '2014-10-15 15:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b4788c85086fd30f3b488f652df85a0f11136869', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}, {'number': 19, 'created': '2014-10-17 10:10:18.000000000', 'files': ['rally/cmd/commands/verify.py', 'rally/cmd/commands/deployment.py', 'rally/cmd/commands/show.py', 'rally/cmd/commands/task.py', 'rally/cmd/commands/use.py', 'rally/cmd/cliutils.py', 'rally/cmd/commands/info.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/41b58c118aa2d7553ccc753f614debd0504bae35', 'message': 'Add detailed description for rally commands\n\nCommands affected:\n  deployment, task, use, verify, info, show\n\nThis descrition available by -h flag.\n\nChange-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc\n'}]",50,124910,41b58c118aa2d7553ccc753f614debd0504bae35,86,7,19,9601,,,0,"Add detailed description for rally commands

Commands affected:
  deployment, task, use, verify, info, show

This descrition available by -h flag.

Change-Id: I2e0518a3189b4bb6c04187a346dfb5c846c293dc
",git fetch https://review.opendev.org/openstack/rally refs/changes/10/124910/19 && git format-patch -1 --stdout FETCH_HEAD,"['rally/cmd/commands/verify.py', 'rally/cmd/commands/deployment.py', 'rally/cmd/commands/show.py', 'rally/cmd/commands/task.py', 'rally/cmd/cliutils.py', 'rally/cmd/commands/use.py', 'rally/cmd/commands/info.py']",7,d88940ec78ebd8df0e66beb45a42f71a12c42503,cli_help," """"""This command allow you to get quick doc of scenarios groups, scenarios, deployment engines and server providers. """"""",,62,2
openstack%2Fheat~master~I871a2da21a227c2d23de91842e680d27e9d19cfc,openstack/heat,master,I871a2da21a227c2d23de91842e680d27e9d19cfc,Remove oslo excutils,ABANDONED,2014-10-14 13:18:41.000000000,2014-10-20 10:33:19.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-10-14 13:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f37bac87cdd470b3755d05e9a536bbcc37b4bcc2', 'message': ""Remove oslo excutils\n\nRemove the openstack/common/excutils.py file as it's not specified\nin openstack-common.conf and is now deprecated (removed actually)\nin oslo-incubator in favor of oslo.utils.\n\nChange-Id: I871a2da21a227c2d23de91842e680d27e9d19cfc\nPartial-Bug: #1380629\n""}, {'number': 2, 'created': '2014-10-14 20:22:07.000000000', 'files': ['heat/openstack/common/excutils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/55cf624cebbe5d2aceb4205239153f1d9cd8c55b', 'message': ""Remove oslo excutils\n\nRemove the openstack/common/excutils.py file as it's not specified\nin openstack-common.conf and is now deprecated (removed actually)\nin oslo-incubator in favor of oslo.utils.\n\nChange-Id: I871a2da21a227c2d23de91842e680d27e9d19cfc\nPartial-Bug: #1380629\n""}]",0,128271,55cf624cebbe5d2aceb4205239153f1d9cd8c55b,7,1,2,4328,,,0,"Remove oslo excutils

Remove the openstack/common/excutils.py file as it's not specified
in openstack-common.conf and is now deprecated (removed actually)
in oslo-incubator in favor of oslo.utils.

Change-Id: I871a2da21a227c2d23de91842e680d27e9d19cfc
Partial-Bug: #1380629
",git fetch https://review.opendev.org/openstack/heat refs/changes/71/128271/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/openstack/common/excutils.py'],1,f37bac87cdd470b3755d05e9a536bbcc37b4bcc2,bug/1380629_2,,"# Copyright 2011 OpenStack Foundation. # Copyright 2012, Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Exception related utilities. """""" import logging import sys import time import traceback import six from heat.openstack.common.gettextutils import _LE class save_and_reraise_exception(object): """"""Save current exception, run some code and then re-raise. In some cases the exception context can be cleared, resulting in None being attempted to be re-raised after an exception handler is run. This can happen when eventlet switches greenthreads or when running an exception handler, code raises and catches an exception. In both cases the exception context will be cleared. To work around this, we save the exception state, run handler code, and then re-raise the original exception. If another exception occurs, the saved exception is logged and the new exception is re-raised. In some cases the caller may not want to re-raise the exception, and for those circumstances this context provides a reraise flag that can be used to suppress the exception. For example:: except Exception: with save_and_reraise_exception() as ctxt: decide_if_need_reraise() if not should_be_reraised: ctxt.reraise = False If another exception occurs and reraise flag is False, the saved exception will not be logged. If the caller wants to raise new exception during exception handling he/she sets reraise to False initially with an ability to set it back to True if needed:: except Exception: with save_and_reraise_exception(reraise=False) as ctxt: [if statements to determine whether to raise a new exception] # Not raising a new exception, so reraise ctxt.reraise = True """""" def __init__(self, reraise=True): self.reraise = reraise def __enter__(self): self.type_, self.value, self.tb, = sys.exc_info() return self def __exit__(self, exc_type, exc_val, exc_tb): if exc_type is not None: if self.reraise: logging.error(_LE('Original exception being dropped: %s'), traceback.format_exception(self.type_, self.value, self.tb)) return False if self.reraise: six.reraise(self.type_, self.value, self.tb) def forever_retry_uncaught_exceptions(infunc): def inner_func(*args, **kwargs): last_log_time = 0 last_exc_message = None exc_count = 0 while True: try: return infunc(*args, **kwargs) except Exception as exc: this_exc_message = six.u(str(exc)) if this_exc_message == last_exc_message: exc_count += 1 else: exc_count = 1 # Do not log any more frequently than once a minute unless # the exception message changes cur_time = int(time.time()) if (cur_time - last_log_time > 60 or this_exc_message != last_exc_message): logging.exception( _LE('Unexpected exception occurred %d time(s)... ' 'retrying.') % exc_count) last_log_time = cur_time last_exc_message = this_exc_message exc_count = 0 # This should be a very rare event. In case it isn't, do # a sleep. time.sleep(1) return inner_func ",0,113
openstack%2Fheat~master~I273e672a479eca98a32668dadf3242efa9f9f9be,openstack/heat,master,I273e672a479eca98a32668dadf3242efa9f9f9be,ResourceGroup add remove_id to remove_policies,ABANDONED,2014-10-16 20:07:43.000000000,2014-10-20 10:32:39.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 7193}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-10-16 20:07:43.000000000', 'files': ['heat/engine/resources/resource_group.py', 'heat/tests/test_resource_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/68dc12087ec56652dbd754007b43a9910a697eae', 'message': 'ResourceGroup add remove_id to remove_policies\n\nChange-Id: I273e672a479eca98a32668dadf3242efa9f9f9be\n'}]",0,129035,68dc12087ec56652dbd754007b43a9910a697eae,11,4,1,4328,,,0,"ResourceGroup add remove_id to remove_policies

Change-Id: I273e672a479eca98a32668dadf3242efa9f9f9be
",git fetch https://review.opendev.org/openstack/heat refs/changes/35/129035/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/resource_group.py', 'heat/tests/test_resource_group.py']",2,68dc12087ec56652dbd754007b43a9910a697eae,bp/autoscaling-parameters," def test_update_remove_id(self): """"""Test update specifying victims."""""" resg = self._create_dummy_stack() self.assertEqual(2, len(resg.nested())) resource_names = [r.name for r in resg.nested().iter_resources()] self.assertEqual(['0', '1'], sorted(resource_names)) # Update to remove a specific resource ID without affecting the size # we should remove resource 0 and build a replacement r_id = resg.nested()['0'].FnGetRefId() self.assertIsNotNone(r_id) print ""SHDEBUG r_id=%s"" % r_id reduce_snip = copy.deepcopy(resg.t) reduce_snip['Properties']['count'] = 2 reduce_snip['Properties']['remove_policies'] = [{'remove_id': [r_id]}] scheduler.TaskRunner(resg.update, reduce_snip)() self.assertEqual((resg.UPDATE, resg.COMPLETE), resg.state) self.assertEqual((resg.UPDATE, resg.COMPLETE), resg.nested().state) self.assertEqual(2, len(resg.nested())) resource_names = [r.name for r in resg.nested().iter_resources()] self.assertEqual(['1', '2'], sorted(resource_names)) self.assertIsNone(resg.nested().resource_by_refid(r_id)) # We now should not do anything on subsequent updates # FIXME(shardy): need to modify the resource so we don't delete ""2"" reduce_snip = copy.deepcopy(resg.t) del(reduce_snip['Properties']['remove_policies']) scheduler.TaskRunner(resg.update, reduce_snip)() self.assertEqual((resg.UPDATE, resg.COMPLETE), resg.state) self.assertEqual((resg.UPDATE, resg.COMPLETE), resg.nested().state) self.assertEqual(2, len(resg.nested())) resource_names = [r.name for r in resg.nested().iter_resources()] self.assertEqual(['1', '2'], sorted(resource_names)) self.assertIsNone(resg.nested().resource_by_refid(r_id)) ",,51,2
openstack%2Fheat~master~Ic90093ab80d9d3e27c257ea1a5cc393e09ebc7ee,openstack/heat,master,Ic90093ab80d9d3e27c257ea1a5cc393e09ebc7ee,Put a cap on our cyclomatic complexity,MERGED,2014-10-17 04:20:48.000000000,2014-10-20 10:27:45.000000000,2014-10-20 10:27:44.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 8289}, {'_account_id': 8328}, {'_account_id': 12321}]","[{'number': 1, 'created': '2014-10-17 04:20:48.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/heat/commit/ed65470992c4c79e94e4d861cea32fca206574de', 'message': ""Put a cap on our cyclomatic complexity\n\nflake8 has support for cyclomatic complexity (Mccabe) currently our\nworst offender has a complexity of 28 (25 is considered very bad). So\nset our max-complexity to 29 so we at least don't make things any worse.\n\nThis is the first step in bringing this number down to 20 or so.\n\nhttps://github.com/flintwork/mccabe\n\nChange-Id: Ic90093ab80d9d3e27c257ea1a5cc393e09ebc7ee\n""}]",0,129126,ed65470992c4c79e94e4d861cea32fca206574de,12,7,1,4715,,,0,"Put a cap on our cyclomatic complexity

flake8 has support for cyclomatic complexity (Mccabe) currently our
worst offender has a complexity of 28 (25 is considered very bad). So
set our max-complexity to 29 so we at least don't make things any worse.

This is the first step in bringing this number down to 20 or so.

https://github.com/flintwork/mccabe

Change-Id: Ic90093ab80d9d3e27c257ea1a5cc393e09ebc7ee
",git fetch https://review.opendev.org/openstack/heat refs/changes/26/129126/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ed65470992c4c79e94e4d861cea32fca206574de,complexity-check,# 28 is currently the most complex thing we have # TODO(asalkeld): get this number down to 20 max-complexity=29,,3,0
openstack%2Fneutron~master~I32cd4a0bc6799ce77cea13188676308e3e641d19,openstack/neutron,master,I32cd4a0bc6799ce77cea13188676308e3e641d19,Optimize query in _select_dhcp_ips_for_network_ids,MERGED,2014-10-17 14:11:10.000000000,2014-10-20 10:27:30.000000000,2014-10-20 10:27:29.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-17 14:11:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a52caaf5e26917f1245cb39719730e8513d6e181', 'message': 'Optimize query in _select_dhcp_ips_for_network_ids\n\nOnly query the DB for relevant columns instead of\nall of the port columns.\n\nPartial-Bug: #1373851\nChange-Id: I32cd4a0bc6799ce77cea13188676308e3e641d19\n'}, {'number': 2, 'created': '2014-10-17 20:52:47.000000000', 'files': ['neutron/db/securitygroups_rpc_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d430a7f2e903dda06d8d75d6abcd63423c4c0a1', 'message': 'Optimize query in _select_dhcp_ips_for_network_ids\n\nOnly query the DB for relevant columns instead of\nall of the port columns.\n\nPartial-Bug: #1373851\nChange-Id: I32cd4a0bc6799ce77cea13188676308e3e641d19\n'}]",0,129270,8d430a7f2e903dda06d8d75d6abcd63423c4c0a1,46,23,2,7787,,,0,"Optimize query in _select_dhcp_ips_for_network_ids

Only query the DB for relevant columns instead of
all of the port columns.

Partial-Bug: #1373851
Change-Id: I32cd4a0bc6799ce77cea13188676308e3e641d19
",git fetch https://review.opendev.org/openstack/neutron refs/changes/70/129270/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/securitygroups_rpc_base.py'],1,a52caaf5e26917f1245cb39719730e8513d6e181,bug/1373851," query = context.session.query(models_v2.Port.mac_address, models_v2.Port.network_id, for mac_address, network_id, ip in query: if ip not in ips[network_id]: ips[network_id].append(ip)"," query = context.session.query(models_v2.Port, for port, ip in query: if ip not in ips[port['network_id']]: ips[port['network_id']].append(ip)",5,4
openstack%2Ftrove~master~I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7,openstack/trove,master,I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7,Logging audit for guestagent/redis,MERGED,2014-07-17 19:19:06.000000000,2014-10-20 10:19:10.000000000,2014-10-20 10:19:09.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 4463}, {'_account_id': 5293}, {'_account_id': 5390}, {'_account_id': 6268}, {'_account_id': 6547}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9664}, {'_account_id': 10215}, {'_account_id': 10295}, {'_account_id': 10725}]","[{'number': 1, 'created': '2014-07-17 19:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/664e88d4ac8351e6c97eafc8d4b720e9870a0e45', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 2, 'created': '2014-07-21 00:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/bdfd06bf0a9fac7de30288767e9f85d0de30a932', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 3, 'created': '2014-07-21 14:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/736ecb36c266baa149a69a43ad2fb82837f8c128', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 4, 'created': '2014-07-21 16:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1a0e460636501cc084ce85fe2e092c14f612193a', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 5, 'created': '2014-07-21 16:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e41c6a8190b0e2cb86f996a42e4d4165d7fef1fc', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 6, 'created': '2014-07-22 21:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/568f030a76efe88ea703c58937ea348d93274d4e', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 7, 'created': '2014-07-23 16:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d507f69d1ac9779749fe66ace16cf56a27141d2f', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 8, 'created': '2014-07-31 17:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b22d0ccd5a682a08dc80e5fc13c5bb575eaa29c8', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 9, 'created': '2014-08-05 19:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5f1f9eb97a1cbc1c3e39117027effc0844db1bea', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 10, 'created': '2014-08-24 02:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7901443e4c45b1a35eeaac8c74d0eb0503d14b34', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 11, 'created': '2014-08-26 01:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/500fd3bc37e6ce1df72cbd7f9b559f12779f17b7', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 12, 'created': '2014-09-03 10:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b980031dbb566664af5fe2e4bdc81206d096c6b4', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 13, 'created': '2014-09-07 20:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d2e6e7572bf7bd811761eb697a08e71db4dacd80', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 14, 'created': '2014-09-09 14:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/10510aa205e4f2948681def2337fb357f9864ba8', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 15, 'created': '2014-09-26 16:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ea4ce3cf7b0afb4213b06cf05d4d1d74cdb70de4', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 16, 'created': '2014-10-01 17:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/18fdd27119de8eca3e19b7e41e60d15d968ce4f5', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 17, 'created': '2014-10-06 17:24:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/139d5266d173073919f151ebc0cbe18f96ade70e', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 18, 'created': '2014-10-08 17:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d3a305428912c46ed7f4a246e67531c2765409ca', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 19, 'created': '2014-10-14 14:23:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/dd4c21b9d99b46d2d0eeb0e3781707859392b4ec', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 20, 'created': '2014-10-14 19:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/9a7f7026845fc790e432e03d0f8fb2b974d569c2', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 21, 'created': '2014-10-14 23:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d07c4e66b978b940929f225b48f92f4a5e316da9', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}, {'number': 22, 'created': '2014-10-15 19:25:56.000000000', 'files': ['trove/guestagent/datastore/redis/manager.py', 'trove/guestagent/datastore/redis/service.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/5b0f26aac261eb5cd5bc81f687f2175ff84097c0', 'message': 'Logging audit for guestagent/redis\n\nAdjust logging to conform to logging standards.\nCleaned up a few messages that were unclear and changed some\nLOG.info messages to LOG.debug\n\nChange-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7\nPartial-Bug: #1324206\n'}]",43,107805,5b0f26aac261eb5cd5bc81f687f2175ff84097c0,213,15,22,9664,,,0,"Logging audit for guestagent/redis

Adjust logging to conform to logging standards.
Cleaned up a few messages that were unclear and changed some
LOG.info messages to LOG.debug

Change-Id: I3570dddf0ba7c576b4cf9cb6affa55335fd23ac7
Partial-Bug: #1324206
",git fetch https://review.opendev.org/openstack/trove refs/changes/05/107805/5 && git format-patch -1 --stdout FETCH_HEAD,"['trove/guestagent/datastore/redis/manager.py', 'trove/guestagent/datastore/redis/service.py']",2,664e88d4ac8351e6c97eafc8d4b720e9870a0e45,bugs/bug-1324206-guestagent-redis," LOG.debug('Password is set running ping with password.') LOG.debug('Password not set running ping without password.') except exception.ProcessExecutionError as err: LOG.error(_('Process execution error on redis-cli (%s).') % err) LOG.info(_('Redis Status is BLOCKED.')) LOG.info(_('Redis Status is CRASHED.')) LOG.info(_('Redis Status is SHUTDOWN.')) LOG.info(_('Preparing Guest as Redis Server.')) if not packager.pkg_is_installed(packages): LOG.info(_('Installing Redis.')) LOG.info(_('Redis install_if_needed complete.')) LOG.debug('Installing redis server.') msg = ""Creating %s."" % system.REDIS_CONF_DIR LOG.debug('Finished installing redis server.') LOG.info(_('Stopping redis.')) LOG.error(_('Could not stop Redis')) LOG.info(_('Starting redis with conf changes.')) LOG.info(_(""Resetting configuration."")) LOG.info(_(""Starting redis."")) LOG.error(_(""Start up of redis failed.""))"," LOG.info(_('Password is set running ping with password')) LOG.info(_('Password not set running ping without password')) except exception.ProcessExecutionError: LOG.error(_('Process execution error on redis-cli')) LOG.info(_('Service Status is BLOCKED.')) LOG.info(_('Service Status is CRASHED.')) LOG.info(_('Service Status is SHUTDOWN.')) LOG.info(_('Preparing Guest as Redis Server')) if not packager.pkg_is_installed(packages): LOG.info(_('Installing Redis')) LOG.info(_('Dbaas install_if_needed complete')) LOG.debug('Installing redis server') msg = ""Creating %s"" % system.REDIS_CONF_DIR LOG.debug('Finished installing redis server') LOG.info(_('Stopping redis...')) LOG.error(_('Could not stop Redis!')) LOG.info(_('Starting redis with conf changes...')) LOG.info(_(""Resetting configuration"")) LOG.info(_(""Starting redis..."")) LOG.error(_(""Start up of redis failed!""))",38,19
openstack%2Ffuel-main~master~Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6,openstack/fuel-main,master,Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6,Add rpm/deb specs for python-tasklib package,MERGED,2014-09-05 14:19:57.000000000,2014-10-20 10:16:37.000000000,2014-10-20 10:16:37.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9582}, {'_account_id': 10474}, {'_account_id': 10836}]","[{'number': 1, 'created': '2014-09-05 14:19:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ddb505222a5972301da3dfbb3ef785c1f1bc9597', 'message': 'Add rpm spec for python-tasklib package\n\n- add python-tasklib spec\n- add python-tasklib to requirements-rpm\n- add python-tasklib to bootstrap image\n\nPartially implements blueprint packages-for-fuel-tacklib\n\nChange-Id: Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6\n'}, {'number': 2, 'created': '2014-09-08 07:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6824b2392faf94a773683228241965b150c66840', 'message': 'Add rpm spec for python-tasklib package\n\n- add python-tasklib spec\n- add python-tasklib to requirements-rpm\n- add python-tasklib to bootstrap image\n\nPartially implements blueprint packages-for-fuel-tacklib\n\nChange-Id: Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6\n'}, {'number': 3, 'created': '2014-09-08 09:29:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1cd4b4adf4018fcd68740c7396b6c05c7f6577c5', 'message': 'Add rpm spec for python-tasklib package\n\n- add python-tasklib spec\n- add python-tasklib to requirements-rpm\n- add python-tasklib to bootstrap image\n\nPartially implements blueprint packages-for-fuel-tacklib\n\nChange-Id: Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6\n'}, {'number': 4, 'created': '2014-09-30 10:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f69103a837a877cc68d5934ee9ae27eeb11cfb2f', 'message': 'Add rpm spec for python-tasklib package\n\n- add python-tasklib spec\n- add python-tasklib to requirements-rpm\n- add python-tasklib to bootstrap image\n\nPartially implements blueprint packages-for-fuel-tacklib\n\nChange-Id: Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6\n'}, {'number': 5, 'created': '2014-09-30 10:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1ea3ebf1ca612a32d499f9dd99a83ee18b2afe02', 'message': 'Add rpm/deb specs for python-tasklib package\n\n- add python-tasklib spec\n- add python-tasklib to requirements-rpm\n- add python-tasklib to bootstrap image\n\nPartially implements blueprint packages-for-fuel-tacklib\n\nChange-Id: Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6'}, {'number': 6, 'created': '2014-10-03 12:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6ba5a62557049588535a5ed588737ee9fe7340ac', 'message': 'Add rpm/deb specs for python-tasklib package\n\n- add python-tasklib spec\n- add python-tasklib to requirements-rpm\n- add python-tasklib to bootstrap image\n- add packing and installing of tasks and roles\n\nPartially implements blueprint packages-for-fuel-tacklib\n\nChange-Id: Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6\n'}, {'number': 7, 'created': '2014-10-03 16:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c46db489af0f25e3faab1992ee7319ccd920b630', 'message': 'Add rpm/deb specs for python-tasklib package\n\n- add python-tasklib spec\n- add python-tasklib to requirements-rpm\n- add python-tasklib to bootstrap image\n- add packing and installing of tasks and roles\n\nPartially implements blueprint packages-for-fuel-tacklib\n\nChange-Id: Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6\n'}, {'number': 8, 'created': '2014-10-06 09:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c892bdfece0f93ee0ce312c7bf21ca538a86bec2', 'message': 'Add rpm/deb specs for python-tasklib package\n\n- add python-tasklib spec\n- add python-tasklib to requirements-rpm\n- add python-tasklib to bootstrap image\n- add packing and installing of tasks and roles\n\nPartially implements blueprint packages-for-fuel-tacklib\n\nChange-Id: Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6\n'}, {'number': 9, 'created': '2014-10-06 10:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5ebd70f89e73acbe082c520796f90a0fd32630de', 'message': 'Add rpm/deb specs for python-tasklib package\n\n- add python-tasklib spec\n- add python-tasklib to requirements-rpm\n- add python-tasklib to bootstrap image\n- add packing and installing of tasks and roles\n\nPartially implements blueprint packages-for-fuel-tacklib\n\nChange-Id: Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6\n'}, {'number': 10, 'created': '2014-10-07 18:27:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b36a43f8574d79c5b7152107731b968c3bce8eca', 'message': 'Add rpm/deb specs for python-tasklib package\n\n- add python-tasklib spec\n- add python-tasklib to requirements-rpm\n- add python-tasklib to bootstrap image\n- add packing and installing of tasks and roles\n\nPartially implements blueprint packages-for-fuel-tacklib\n\nChange-Id: Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6\n'}, {'number': 11, 'created': '2014-10-16 10:10:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4271f5c081588552ad7af87fe64ef43c7030df23', 'message': 'Add rpm/deb specs for python-tasklib package\n\n- add python-tasklib spec\n- add python-tasklib to requirements-rpm\n- add python-tasklib to bootstrap image\n- add packing and installing of tasks and roles\n\nPartially implements blueprint packages-for-fuel-tacklib\n\nChange-Id: Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6\n'}, {'number': 12, 'created': '2014-10-16 10:10:50.000000000', 'files': ['packages/deb/specs/python-tasklib/debian/control', 'packages/deb/specs/python-tasklib/debian/changelog', 'packages/deb/specs/python-tasklib/debian/compat', 'bootstrap/module.mk', 'packages/deb/specs/python-tasklib/debian/rules', 'packages/rpm/specs/python-tasklib.spec', 'packages/deb/specs/python-tasklib/debian/source/format', 'packages/rpm/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8b337291fa79255eae0d8216bc08af8c90ef97fe', 'message': 'Add rpm/deb specs for python-tasklib package\n\n- add python-tasklib spec\n- add python-tasklib to requirements-rpm\n- add python-tasklib to bootstrap image\n\nPartially implements blueprint packages-for-fuel-tacklib\n\nChange-Id: Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6'}]",0,119383,8b337291fa79255eae0d8216bc08af8c90ef97fe,66,8,12,8907,,,0,"Add rpm/deb specs for python-tasklib package

- add python-tasklib spec
- add python-tasklib to requirements-rpm
- add python-tasklib to bootstrap image

Partially implements blueprint packages-for-fuel-tacklib

Change-Id: Ic808a2bce79c2d912b25cc87ac2bed8bdb005bc6",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/83/119383/8 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-rpm.txt', 'bootstrap/module.mk', 'packages/rpm/specs/python-tasklib.spec', 'packages/rpm/module.mk']",4,ddb505222a5972301da3dfbb3ef785c1f1bc9597,bp/packages-for-fuel-tacklib,"$(eval $(call prepare_python_source,python-tasklib,tasklib-0.1.tar.gz,$(BUILD_DIR)/repos/nailgun/tasklib))$(eval $(call build_rpm,python-tasklib))",,44,1
openstack%2Fpylockfile~master~I8a999cc044d3687cc410b56b1db490e38b9b9a50,openstack/pylockfile,master,I8a999cc044d3687cc410b56b1db490e38b9b9a50,The version of sphinx being brought in is broken,MERGED,2014-10-17 23:44:31.000000000,2014-10-20 10:14:15.000000000,2014-10-20 10:14:15.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-10-17 23:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pylockfile/commit/bb76b46875c93e9e03a7ddf5866fa0546ac90d19', 'message': 'The version of sphinx being brought in is broken\n\nChange-Id: I8a999cc044d3687cc410b56b1db490e38b9b9a50\n'}, {'number': 2, 'created': '2014-10-17 23:46:14.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/pylockfile/commit/af3b2bd120877fe996ff4723ffb4bff06a43d692', 'message': ""The version of sphinx being brought in is broken\n\nThe global requirements repo has blocked 1.3b1, so\nin order for pylockfile builds to stop failing so\nshould we. In the future we should investigate why\nthe requirements aren't syncing for this repo.\n\nChange-Id: I8a999cc044d3687cc410b56b1db490e38b9b9a50\n""}]",0,129401,af3b2bd120877fe996ff4723ffb4bff06a43d692,7,2,2,1297,,,0,"The version of sphinx being brought in is broken

The global requirements repo has blocked 1.3b1, so
in order for pylockfile builds to stop failing so
should we. In the future we should investigate why
the requirements aren't syncing for this repo.

Change-Id: I8a999cc044d3687cc410b56b1db490e38b9b9a50
",git fetch https://review.opendev.org/openstack/pylockfile refs/changes/01/129401/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,bb76b46875c93e9e03a7ddf5866fa0546ac90d19,,"sphinx>=1.1.2,!=1.2.0,!=1.3b1,<1.3","sphinx>=1.1.2,!=1.2.0,<1.3",1,1
openstack%2Ftripleo-heat-templates~master~I7074a8f7d406adaa56e55013b10bd520fcacfcf6,openstack/tripleo-heat-templates,master,I7074a8f7d406adaa56e55013b10bd520fcacfcf6,Passthrough{Specific} and allNodesConfig for BlockStorage nodes,MERGED,2014-08-05 16:44:58.000000000,2014-10-20 10:07:19.000000000,2014-10-20 10:07:19.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 4330}, {'_account_id': 6796}, {'_account_id': 7471}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 8688}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-08-05 16:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f920b6c524917103f6706087efa25051329c7d69', 'message': 'Add support for Passtrough and allNodesConfig to BS nodes\n\nChange-Id: I7074a8f7d406adaa56e55013b10bd520fcacfcf6\n'}, {'number': 2, 'created': '2014-08-07 23:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dcd96e5f1d44535fc17d63e414e3dee29ea29c4d', 'message': 'Add support for Passtrough and allNodesConfig to BS nodes\n\nChange-Id: I7074a8f7d406adaa56e55013b10bd520fcacfcf6\n'}, {'number': 3, 'created': '2014-08-12 18:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/60e5ab28f79e8b9442597471aaf202ba4ba8c0be', 'message': 'Passthrough and allNodesConfig for BlockStorage nodes\n\nChange-Id: I7074a8f7d406adaa56e55013b10bd520fcacfcf6\n'}, {'number': 4, 'created': '2014-08-12 18:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/861eacb64c20fd8d5b76caaf78f2ac736b3871f8', 'message': 'Passthrough and allNodesConfig for BlockStorage nodes\n\nChange-Id: I7074a8f7d406adaa56e55013b10bd520fcacfcf6\n'}, {'number': 5, 'created': '2014-08-14 17:25:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1ffb27ada71a0373e4a8d65e15963ab542ff98be', 'message': 'Passthrough and allNodesConfig for BlockStorage nodes\n\nChange-Id: I7074a8f7d406adaa56e55013b10bd520fcacfcf6\n'}, {'number': 6, 'created': '2014-08-18 19:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/29e74d9d8feff62dede7892f31eff9ae330f3841', 'message': 'Passthrough and allNodesConfig for BlockStorage nodes\n\nChange-Id: I7074a8f7d406adaa56e55013b10bd520fcacfcf6\n'}, {'number': 7, 'created': '2014-09-17 14:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/26ae48f5d7568b30cb364c550d485c600f15f949', 'message': 'Passthrough and allNodesConfig for BlockStorage nodes\n\nChange-Id: I7074a8f7d406adaa56e55013b10bd520fcacfcf6\n'}, {'number': 8, 'created': '2014-10-09 15:44:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/333f5eeec9fb5b42aec7280f92dbdddc6cbc0189', 'message': 'Passthrough and allNodesConfig for BlockStorage nodes\n\nChange-Id: I7074a8f7d406adaa56e55013b10bd520fcacfcf6\n'}, {'number': 9, 'created': '2014-10-14 09:27:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bbf838e98fd15f8f13ec995cd368ca43b8f787ef', 'message': 'Passthrough{Specific} and allNodesConfig for BlockStorage nodes\n\nChange-Id: I7074a8f7d406adaa56e55013b10bd520fcacfcf6\n'}, {'number': 10, 'created': '2014-10-17 13:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/71005b3db8cd42212f28c258962a9d2645e08e06', 'message': 'Passthrough{Specific} and allNodesConfig for BlockStorage nodes\n\nPurpose of this change is to allow passthrough of *specific values*\nfor *same key* to particular the BlockStorage nodes. Same\nbehaviour is already implemented for controllers and computes.\n\nChange-Id: I7074a8f7d406adaa56e55013b10bd520fcacfcf6\n'}, {'number': 11, 'created': '2014-10-17 13:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/893bb150a5b480bdda4356251c5b04fb0deac040', 'message': 'Passthrough{Specific} and allNodesConfig for BlockStorage nodes\n\nPurpose of this change is to allow passthrough of *specific values*\nfor *same key* in particular to BlockStorage nodes. Same\nbehaviour is already implemented for controllers and computes.\n\nChange-Id: I7074a8f7d406adaa56e55013b10bd520fcacfcf6\n'}, {'number': 12, 'created': '2014-10-17 15:16:19.000000000', 'files': ['block-storage.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/34df5f9af988adda1d4ac162b35a998bbebf2c0b', 'message': 'Passthrough{Specific} and allNodesConfig for BlockStorage nodes\n\nPurpose of this change is to allow passthrough of *specific values*\nfor *same key* in particular to BlockStorage nodes. Same\nbehaviour is already implemented for controllers and computes.\n\nChange-Id: I7074a8f7d406adaa56e55013b10bd520fcacfcf6\n'}]",11,112075,34df5f9af988adda1d4ac162b35a998bbebf2c0b,79,9,12,6796,,,0,"Passthrough{Specific} and allNodesConfig for BlockStorage nodes

Purpose of this change is to allow passthrough of *specific values*
for *same key* in particular to BlockStorage nodes. Same
behaviour is already implemented for controllers and computes.

Change-Id: I7074a8f7d406adaa56e55013b10bd520fcacfcf6
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/75/112075/4 && git format-patch -1 --stdout FETCH_HEAD,['block-storage.yaml'],1,f920b6c524917103f6706087efa25051329c7d69,passthrough, BlockStorage0AllNodesDeployment: depends_on: [BlockStorage0Passthrough] type: OS::Heat::StructuredDeployment properties: config: {get_param: AllNodesConfig} server: {get_resource: BlockStorage0} BlockStorage0Passthrough: depends_on: [BlockStorage0Deployment] type: OS::Heat::StructuredDeployment properties: config: {get_resource: BlockStoragePassthrough} server: {get_resource: BlockStorage0} signal_transport: NO_SIGNAL input_values: passthrough_config: {get_param: ExtraConfig},,15,0
openstack%2Ftripleo-image-elements~master~I13ad6055ebfe46d25dc1bf598eaabafb6ac6bb5a,openstack/tripleo-image-elements,master,I13ad6055ebfe46d25dc1bf598eaabafb6ac6bb5a,Migrate from map-services to svc-map,MERGED,2014-10-16 21:49:03.000000000,2014-10-20 09:55:04.000000000,2014-10-20 09:55:04.000000000,"[{'_account_id': 3}, {'_account_id': 4330}, {'_account_id': 8399}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-10-16 21:49:03.000000000', 'files': ['elements/collectl/element-deps', 'elements/collectl/install.d/85-collectl', 'elements/collectl/svc-map'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/aa6994cacf5b430ed7e7c7b79a87c6154ba822e7', 'message': 'Migrate from map-services to svc-map\n\nThis patch migrates the collectl element from map-services to\nsvc-map by adding the -a option to os-svc-enable and adding a\nsvc-map file.\n\nChange-Id: I13ad6055ebfe46d25dc1bf598eaabafb6ac6bb5a\n'}]",0,129066,aa6994cacf5b430ed7e7c7b79a87c6154ba822e7,15,4,1,8532,,,0,"Migrate from map-services to svc-map

This patch migrates the collectl element from map-services to
svc-map by adding the -a option to os-svc-enable and adding a
svc-map file.

Change-Id: I13ad6055ebfe46d25dc1bf598eaabafb6ac6bb5a
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/66/129066/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/collectl/element-deps', 'elements/collectl/install.d/85-collectl', 'elements/collectl/svc-map']",3,aa6994cacf5b430ed7e7c7b79a87c6154ba822e7,migrate-collectl-svc-map,collectl: default: collectl ,,4,1
openstack%2Fironic~master~I66e84ac3341882ae72796cc9536f20773142267f,openstack/ironic,master,I66e84ac3341882ae72796cc9536f20773142267f,Update node-validate error messages,MERGED,2014-10-16 09:49:47.000000000,2014-10-20 09:40:35.000000000,2014-10-20 09:40:34.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 10239}, {'_account_id': 11278}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-10-16 09:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/553a785c5fb204c63439be8ec3f33db1ebe31471', 'message': 'Update node-validate error messages\n\nUpon executing node-validate upon a node in Ironic, the\nerror message/reason is provided without any clear instruction\nas to where the missing parameters are supposed to be defined.\n\nThis fix proposes to update the error messages to specify where\nthe information is missing.\n\nChange-Id: I66e84ac3341882ae72796cc9536f20773142267f\nCloses-Bug: #1379911\n'}, {'number': 2, 'created': '2014-10-17 04:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8720a8cddf37e01ac5a07d8ed0f34ba5a941addb', 'message': 'Update node-validate error messages\n\nUpon executing node-validate upon a node in Ironic, the\nerror message/reason is provided without any clear instruction\nas to where the missing parameters are supposed to be defined.\n\nThis fix proposes to update the error messages to specify where\nthe information is missing.\n\nChange-Id: I66e84ac3341882ae72796cc9536f20773142267f\nCloses-Bug: #1379911\n'}, {'number': 3, 'created': '2014-10-20 03:44:31.000000000', 'files': ['ironic/drivers/modules/deploy_utils.py', 'ironic/drivers/modules/iscsi_deploy.py', 'ironic/drivers/modules/ilo/deploy.py', 'ironic/drivers/modules/pxe.py', 'ironic/drivers/modules/snmp.py', 'ironic/drivers/modules/seamicro.py', 'ironic/drivers/modules/iboot.py', 'ironic/drivers/modules/ssh.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/drivers/modules/ipminative.py', 'ironic/tests/drivers/ilo/test_deploy.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b961823774c3ee53dfb9ad16bc5e109e757d3de8', 'message': 'Update node-validate error messages\n\nUpon executing node-validate upon a node in Ironic, the\nerror message/reason is provided without any clear instruction\nas to where the missing parameters are supposed to be defined.\n\nThis fix proposes to update the error messages to specify where\nthe information is missing.\n\nChange-Id: I66e84ac3341882ae72796cc9536f20773142267f\nCloses-Bug: #1379911\n'}]",20,128862,b961823774c3ee53dfb9ad16bc5e109e757d3de8,28,7,3,11278,,,0,"Update node-validate error messages

Upon executing node-validate upon a node in Ironic, the
error message/reason is provided without any clear instruction
as to where the missing parameters are supposed to be defined.

This fix proposes to update the error messages to specify where
the information is missing.

Change-Id: I66e84ac3341882ae72796cc9536f20773142267f
Closes-Bug: #1379911
",git fetch https://review.opendev.org/openstack/ironic refs/changes/62/128862/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/deploy_utils.py', 'ironic/drivers/modules/iscsi_deploy.py', 'ironic/drivers/modules/snmp.py', 'ironic/drivers/modules/seamicro.py', 'ironic/drivers/modules/iboot.py', 'ironic/drivers/modules/ssh.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/drivers/modules/ipminative.py']",8,553a785c5fb204c63439be8ec3f33db1ebe31471,bug-validate," ""Missing IPMI credentials in node's driver_info. The following"" ""info is not supplied to IPMI driver: %s."") % missing_info)"," ""The following IPMI credentials are not supplied"" "" to IPMI driver: %s."" ) % missing_info)",24,17
openstack%2Ftraining-guides~master~Ia178faabd7e3f15750be432ae94df43143756a3e,openstack/training-guides,master,Ia178faabd7e3f15750be432ae94df43143756a3e,small change to section_brief-overview,MERGED,2014-10-16 21:45:54.000000000,2014-10-20 09:34:34.000000000,2014-10-20 09:34:33.000000000,"[{'_account_id': 3}, {'_account_id': 11109}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-10-16 21:45:54.000000000', 'files': ['doc/training-guides/common/section_brief-overview.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/b74fe21d8de59a966008aaa602f96b9ea0c17dd2', 'message': 'small change to section_brief-overview\n\nremoved . after feature rich\n\nChange-Id: Ia178faabd7e3f15750be432ae94df43143756a3e\n'}]",0,129064,b74fe21d8de59a966008aaa602f96b9ea0c17dd2,7,3,1,9382,,,0,"small change to section_brief-overview

removed . after feature rich

Change-Id: Ia178faabd7e3f15750be432ae94df43143756a3e
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/64/129064/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/common/section_brief-overview.xml'],1,b74fe21d8de59a966008aaa602f96b9ea0c17dd2,brief_overview, <para>feature rich</para>, <para>feature rich.</para>,1,1
openstack%2Ftraining-guides~master~Icaa5a92e1f3685c6aa5626b3d37044219757ed20,openstack/training-guides,master,Icaa5a92e1f3685c6aa5626b3d37044219757ed20,changes to lab_virtualbox_basics,MERGED,2014-10-16 21:37:54.000000000,2014-10-20 09:34:28.000000000,2014-10-20 09:34:27.000000000,"[{'_account_id': 3}, {'_account_id': 11109}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-10-16 21:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/89d5fc0e7c8ab7590641c967f6eb69da882163f3', 'message': 'changes to lab_virtualbox_basics\n\nremoved , after LTS\nchanged to Prerequisites (plural)\nchanged IceHouse to Kilo\nchanged of to for\nchanged multi node to have a hyphen\nchanged a to an before x86\nadded an before i5\nadded “a” before positive result\nadded the before same\nadded the in a few places where necessary\nRemoved (not necessary)\nremoved “unless know what you are doing”\nadded “unless you are an advanced user”\n\nChange-Id: Icaa5a92e1f3685c6aa5626b3d37044219757ed20\n'}, {'number': 2, 'created': '2014-10-17 13:50:53.000000000', 'files': ['doc/training-guides/basic-install-guide/lab_virtualbox-basics.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/aad7b42e3b425e8be05f2af0727f7fc594169234', 'message': 'changes to lab_virtualbox_basics\n\nremoved , after LTS\nchanged to Prerequisites (plural)\nchanged of to for\nchanged multi node to have a hyphen\nchanged a to an before x86\nadded an before i5\nadded “a” before positive result\nadded the before same\nadded the in a few places where necessary\nRemoved (not necessary)\nremoved “unless know what you are doing”\nadded “unless you are an advanced user”\n\nChange-Id: Icaa5a92e1f3685c6aa5626b3d37044219757ed20\n'}]",2,129063,aad7b42e3b425e8be05f2af0727f7fc594169234,10,3,2,9382,,,0,"changes to lab_virtualbox_basics

removed , after LTS
changed to Prerequisites (plural)
changed of to for
changed multi node to have a hyphen
changed a to an before x86
added an before i5
added “a” before positive result
added the before same
added the in a few places where necessary
Removed (not necessary)
removed “unless know what you are doing”
added “unless you are an advanced user”

Change-Id: Icaa5a92e1f3685c6aa5626b3d37044219757ed20
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/63/129063/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/basic-install-guide/lab_virtualbox-basics.xml'],1,89d5fc0e7c8ab7590641c967f6eb69da882163f3,vboxbasics," <para><guilabel>Prerequisites:</guilabel></para> <para>Operating Systems - It is recommended to use Ubuntu Server 14.04 LTS <note><para>Older Ubuntu versions may not support Kilo. Ubuntu Server 12.04 will support Kilo but is out of scope for this book. will deploy OpenStack multi-node using OVS as the network <note><para>You need an x86 image for VM's if kvm-ok fails, even <para>If you have an i5 or i7 2nd gen processor you can have VT your OpenStack nodes (which are in turn VM's) will give a hypervisors). The rest of the configurations remain the same except remote terminal, which is not possible directly on the VM.</para> also use SFTP or install FTPD on both the HOST and the VM's.</para> <para>During the installation of the operating systems you will be except for the packages that are mentioned below, unless you are <note><para>Install the SSH server are not required and may come in the way of the OpenStack packages - like DNS servers etc. (unless you are an advanced user).</para> <para>Create a new virtual machine, with the minimum RAM as"," <para><guilabel>Prerequisite:</guilabel></para> <para>Operating Systems - It is recommended to use Ubuntu Server 14.04 LTS, <note><para>Older Ubuntu versions may not support Icehouse. Ubuntu Server 12.04 will support Icehouse but is out of scope of this book. will deploy OpenStack multi node using OVS as the network <note><para>You need a x86 image for VM's if kvm-ok fails, even <para>If you have i5 or i7 2nd gen processor you can have VT your OpenStack nodes (which are in turn VM's) will give hypervisors). The rest of the configurations remain same except remote terminal, which is not possible directly on VM.</para> also use SFTP or install FTPD on both HOST and VM's.</para> <para>During installation of the operating systems you will be except for the packages that are mentioned below unless you are <note><para>Install SSH server are not required and may come in the way of OpenStack packages - like DNS servers etc. (not necessary). Unless you know what you are doing.</para> <para>Create a new virtual machine, minimum RAM is",17,18
openstack%2Ftraining-guides~master~Ic5d4c3c959d37fda0d57009f282be1238388cc59,openstack/training-guides,master,Ic5d4c3c959d37fda0d57009f282be1238388cc59,Scale images in the upstream-training guide,MERGED,2014-10-17 04:31:11.000000000,2014-10-20 09:34:18.000000000,2014-10-20 09:34:17.000000000,"[{'_account_id': 3}, {'_account_id': 2064}, {'_account_id': 9382}, {'_account_id': 11109}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-10-17 04:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/b58630faa375d46a412e84d5822fc58891f423a1', 'message': ""Scale images in the upstream-training guide\n\nMost images that exceeded the slide area were too wide.  These were\nfixed by adding a 'max-width: 100%' CSS rule.  Release cycle images in\nthe 01-release-cycle.rst presentation were too tall because the\ntwo-column layout was not preserved when the presentation was converted\nfrom the ODP source document.  This change restores the two-column\nlayout.  The images now scale appropriately across a variety of operating\nsystems and browsers.\n\nChange-Id: Ic5d4c3c959d37fda0d57009f282be1238388cc59\n""}, {'number': 2, 'created': '2014-10-20 03:58:16.000000000', 'files': ['doc/upstream-training/01-release-cycle.rst', 'doc/upstream-training/theme/css/print.css', 'doc/upstream-training/theme/css/screen.css'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/eabb53076a49855adcdb70b0661f52271f236666', 'message': ""Scale images in the upstream-training guide\n\nMost images that exceeded the slide area were too wide.  These were\nfixed by adding a 'max-width: 100%' CSS rule.  Release cycle images in\nthe 01-release-cycle.rst presentation were too tall because the\ntwo-column layout was not preserved when the presentation was converted\nfrom the ODP source document.  This change restores the two-column\nlayout.  The images now scale appropriately across a variety of\noperating systems and browsers.  The print.css changes were tested with\nthe print rendering engines of Firefox and Chrome.\n\nChange-Id: Ic5d4c3c959d37fda0d57009f282be1238388cc59\n""}]",2,129127,eabb53076a49855adcdb70b0661f52271f236666,13,5,2,9041,,,0,"Scale images in the upstream-training guide

Most images that exceeded the slide area were too wide.  These were
fixed by adding a 'max-width: 100%' CSS rule.  Release cycle images in
the 01-release-cycle.rst presentation were too tall because the
two-column layout was not preserved when the presentation was converted
from the ODP source document.  This change restores the two-column
layout.  The images now scale appropriately across a variety of
operating systems and browsers.  The print.css changes were tested with
the print rendering engines of Firefox and Chrome.

Change-Id: Ic5d4c3c959d37fda0d57009f282be1238388cc59
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/27/129127/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/upstream-training/01-release-cycle.rst', 'doc/upstream-training/theme/css/screen.css']",2,b58630faa375d46a412e84d5822fc58891f423a1,upstream-image-autoscale,img { display: block; margin: auto; max-width: 100%; max-height: 100%} .colleft { float: left; max-width: 48%; padding: 0; } .colright { float: right; max-width: 48%; padding: 0; } .releasecycle { float: right; max-width: 48%; height: 600px; padding: 0; },img { display: block; margin: auto; },38,2
openstack%2Ftrove~master~I25c3b0906191afdc587f5ddd5777b3185dc080d4,openstack/trove,master,I25c3b0906191afdc587f5ddd5777b3185dc080d4,Allow users the ability to update an instance name,MERGED,2014-05-07 20:43:42.000000000,2014-10-20 09:10:30.000000000,2014-10-20 09:10:29.000000000,"[{'_account_id': 3}, {'_account_id': 1925}, {'_account_id': 2559}, {'_account_id': 4240}, {'_account_id': 4463}, {'_account_id': 5293}, {'_account_id': 5367}, {'_account_id': 5390}, {'_account_id': 7092}, {'_account_id': 7796}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9664}, {'_account_id': 9683}, {'_account_id': 9746}, {'_account_id': 10215}, {'_account_id': 11428}, {'_account_id': 11606}]","[{'number': 1, 'created': '2014-05-07 20:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4dd3c3992a5c8d90cdd086b11b4f4451c760ca39', 'message': 'Allow users the ability to update the instance name\n\nThis review introduces a new PATCH call for updating instance\nname and configurations. The long term plan is to deprecate PUT\nin favor of PATCH.\n\nRelated to bp update-instance-name\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 2, 'created': '2014-05-08 16:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c2c302212dd3000b3f0c91e765200246a782aafa', 'message': 'Allow users the ability to update the instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 3, 'created': '2014-05-19 15:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b5a762516647d273f5a00ff70a77b6a1d9586084', 'message': 'Allow users the ability to update the instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 4, 'created': '2014-05-27 03:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/2039b5c60e705b2eeafc1550339f3ddcc72065ec', 'message': 'Allow users the ability to update the instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 5, 'created': '2014-06-23 14:20:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/467bf3fcf2f7d3c5f9b303ef2f84f0474491a346', 'message': 'Allow users the ability to update the instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 6, 'created': '2014-06-23 17:53:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/de5d7fb4f5e0fc7975aea1ddf9a134149bea827a', 'message': 'Allow users the ability to update the instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 7, 'created': '2014-06-23 21:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ff815ca5de6947dc5db0dc6cbf292ec2469c450e', 'message': 'Allow users the ability to update the instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 8, 'created': '2014-06-24 12:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8f5f3864b6fd4fd77775f2f196e60fb0e6eb110c', 'message': 'Allow users the ability to update the instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 9, 'created': '2014-06-24 13:30:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/17dff88ec25218d53426c8f0df8c0d41c0f4b29d', 'message': 'Allow users the ability to update the instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 10, 'created': '2014-07-01 14:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b6490a57a58602802e133f57ade25927095af60b', 'message': 'Allow users the ability to update the instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 11, 'created': '2014-07-02 13:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/afe01137d9cc3b4b505ea7b31bd2b37dbd8598fb', 'message': 'Allow users the ability to update the instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 12, 'created': '2014-07-28 14:04:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/bf22b185d967dc050aff598c4dbd6a67e3a27648', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 13, 'created': '2014-07-28 15:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/fbcb5b665fe29763e3a935630e735314759f268b', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 14, 'created': '2014-08-01 22:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3c3949d986112430dcaa0e0d01752de6c32ae8a7', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 15, 'created': '2014-08-04 14:55:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0fc9031d50550ab7a50732dc7492d2492046404f', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 16, 'created': '2014-08-26 19:27:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0c565dfe76c1c68e3100ee39bf79255320131958', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 17, 'created': '2014-09-02 16:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a205c9baf9ba7f8ec074c02fb3104266f66866bd', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 18, 'created': '2014-09-02 19:24:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5687c8333bc34adb3ed95e9adb432c5b95b76957', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 19, 'created': '2014-09-03 21:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1a1d1b2e019fcccc407a4840ea7b948bb2b47c22', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 20, 'created': '2014-09-08 15:31:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/dee035223be2927bb4ac1598fdb04d04e55daac6', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 21, 'created': '2014-09-08 21:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/570b797a1899aab5a63876dc344259f1242d0ea8', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 22, 'created': '2014-09-11 12:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3bd8c754a586c181e6620a90efe17e19ce9f9fe5', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 23, 'created': '2014-09-11 16:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a47d392d2365f5e041e9dadbd6e70d85e1848d35', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint update-instance-name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 24, 'created': '2014-09-13 22:52:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b7397ef92488b6839c008bf2ace2eccccc6d4801', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint Allow users the ability to update the instance name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 25, 'created': '2014-09-14 05:02:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8c6c91569509df3c30e7b3c35561cc40eac09a72', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint Allow users the ability to update the instance name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 26, 'created': '2014-10-13 18:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/dfb931680ae06a2c1787ca5696b362f5fcf6d7cb', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint Allow users the ability to update the instance name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 27, 'created': '2014-10-14 18:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8ed3d32e626a761d66e6516700cfdc113663d624', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint Allow users the ability to update the instance name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 28, 'created': '2014-10-14 20:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/50c099b55e9db67b2e68898d59b5f8b8b5751952', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint Allow users the ability to update the instance name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 29, 'created': '2014-10-15 22:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/878fa4917670fa1de3469844313cc0ef6961b027', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint Allow users the ability to update the instance name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 30, 'created': '2014-10-17 17:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ed2037f0a539398d2571a2770c92b677d8a3ae5b', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint Allow users the ability to update the instance name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}, {'number': 31, 'created': '2014-10-17 19:31:04.000000000', 'files': ['trove/instance/models.py', 'trove/taskmanager/models.py', 'trove/common/apischema.py', 'trove/instance/service.py', 'trove/tests/api/instances.py', 'trove/tests/api/configurations.py', 'trove/tests/config.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/2fe147c66e9a64abda15b5a6e162a6d4b3a04554', 'message': 'Allow users the ability to update an instance name\n\nCurrently the users do not have the ability to rename an\ninstance. The current PUT call, does not allow the user\nto modify individual attributes of the instance.\nHence this review introduces a new PATCH call for updating\ninstance name and/or configurations.\nThe long term plan is to deprecate PUT in favor of PATCH.\n\nImplements: blueprint Allow users the ability to update the instance name\nAuthor: Iccha Sethi <iccha.sethi@rackspace.com>\nCo-Authored-By: Theron Voran <theron.voran@rackspace.com>\nCo-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>\n\nChange-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4\n'}]",92,92701,2fe147c66e9a64abda15b5a6e162a6d4b3a04554,295,19,31,4463,,,0,"Allow users the ability to update an instance name

Currently the users do not have the ability to rename an
instance. The current PUT call, does not allow the user
to modify individual attributes of the instance.
Hence this review introduces a new PATCH call for updating
instance name and/or configurations.
The long term plan is to deprecate PUT in favor of PATCH.

Implements: blueprint Allow users the ability to update the instance name
Author: Iccha Sethi <iccha.sethi@rackspace.com>
Co-Authored-By: Theron Voran <theron.voran@rackspace.com>
Co-Authored-By: Riddhi Shah <ridhi.j.shah@gmail.com>

Change-Id: I25c3b0906191afdc587f5ddd5777b3185dc080d4
",git fetch https://review.opendev.org/openstack/trove refs/changes/01/92701/26 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/api.py', 'trove/instance/service.py', 'trove/tests/api/instances.py', 'trove/tests/api/configurations.py']",4,4dd3c3992a5c8d90cdd086b11b4f4451c760ca39,bp/Allow," @test def test_assign_configuration_to_valid_instance_using_patch(self): # test assigning a configuration to an instance print(""instance_info.id: %s"" % instance_info.id) print(""configuration_info: %s"" % configuration_info) print(""configuration_info.id: %s"" % configuration_info.id) config_id = configuration_info.id instance_info.dbaas.instances.edit(instance_info.id, configuration=config_id) resp, body = instance_info.dbaas.client.last_response assert_equal(resp.status, 204) @test def test_assign_config_and_name_to_instance_using_patch(self): # test assigning a configuration and name to an instance new_name = 'new_name' print(""instance_info.id: %s"" % instance_info.id) print(""configuration_info: %s"" % configuration_info) print(""configuration_info.id: %s"" % configuration_info.id) print(""instance name:%s"" % instance_info.name) print(""instance new name:%s"" % new_name) config_id = configuration_info.id instance_info.dbaas.instances.edit(instance_info.id, configuration=config_id, name=new_name) resp, body = instance_info.dbaas.client.last_response assert_equal(resp.status, 204) def test_assign_configuration_to_instance_with_config_using_patch(self): # test assigning a configuration to an instance that # already has an assigned configuration config_id = configuration_info.id assert_raises(exceptions.BadRequest, instance_info.dbaas.instances.edit, instance_info.id, configuration=config_id) @test(depends_on=[test_assign_configuration_to_valid_instance]) @test(depends_on=[test_assign_configuration_to_valid_instance_using_patch]) @time_out(10) def test_get_configuration_details_from_instance_using_patch(self): # validate that the configuraiton was applied correctly to the instance inst = instance_info.dbaas.instances.get(instance_info.id) configuration_id = inst.configuration['id'] assert_not_equal(None, inst.configuration['id']) _test_configuration_is_applied_to_instance(instance_info, configuration_id) @test(depends_on=[test_assign_config_and_name_to_instance_using_patch]) @time_out(10) def test_get_config_details_and_name_from_instance_using_patch(self): # validate that the configuraiton was applied correctly to the instance inst = instance_info.dbaas.instances.get(instance_info.id) configuration_id = inst.configuration['id'] assert_not_equal(None, inst.configuration['id']) _test_configuration_is_applied_to_instance(instance_info, configuration_id) assert_equal(inst.name, 'new_name') ",,125,0
openstack%2Fhorizon~master~I7e65f7ae4790ddee25793561f37e494ac2f817b0,openstack/horizon,master,I7e65f7ae4790ddee25793561f37e494ac2f817b0,Imported Translations from Transifex,MERGED,2014-10-20 06:05:43.000000000,2014-10-20 09:03:17.000000000,2014-10-20 09:03:16.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 6914}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-10-20 06:05:43.000000000', 'files': ['openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/cdb54f3b4523134170083a607ad09d5967917302', 'message': 'Imported Translations from Transifex\n\nChange-Id: I7e65f7ae4790ddee25793561f37e494ac2f817b0\n'}]",0,129520,cdb54f3b4523134170083a607ad09d5967917302,9,4,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I7e65f7ae4790ddee25793561f37e494ac2f817b0
",git fetch https://review.opendev.org/openstack/horizon refs/changes/20/129520/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/djangojs.po']",3,cdb54f3b4523134170083a607ad09d5967917302,transifex/translations,"""POT-Creation-Date: 2014-10-19 13:33-0500\n"" ""PO-Revision-Date: 2014-10-19 11:00+0000\n"" ""Last-Translator: Akihiro Motoki <amotoki@gmail.com>\n""msgstr ""インタフェースの削除""msgstr ""コンソールを開く""msgstr ""ルーターの削除""msgstr ""ルーターの詳細の表示""msgstr ""インスタンスの終了""msgstr ""インスタンスの詳細の表示""","""POT-Creation-Date: 2014-10-18 20:37-0500\n"" ""PO-Revision-Date: 2014-10-18 14:31+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",22,22
openstack%2Fpython-ironicclient~master~I8b2661c7ff5298c12740cb0d31908a1817ec0463,openstack/python-ironicclient,master,I8b2661c7ff5298c12740cb0d31908a1817ec0463,Switch to oslo.i18n,ABANDONED,2014-10-20 08:06:41.000000000,2014-10-20 08:54:18.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-10-20 08:06:41.000000000', 'files': ['ironicclient/openstack/common/strutils.py', 'ironicclient/openstack/common/cliutils.py', 'requirements.txt', 'ironicclient/common/i18n.py', 'ironicclient/openstack/common/gettextutils.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/b25c1eb75a64d0e7e916d650641e3aff8ad99af5', 'message': 'Switch to oslo.i18n\n\nThe incubator gettextutils module has been deleted because it\ngraduated to oslo.i18n.\n\nChange-Id: I8b2661c7ff5298c12740cb0d31908a1817ec0463\n'}]",0,129540,b25c1eb75a64d0e7e916d650641e3aff8ad99af5,4,1,1,12385,,,0,"Switch to oslo.i18n

The incubator gettextutils module has been deleted because it
graduated to oslo.i18n.

Change-Id: I8b2661c7ff5298c12740cb0d31908a1817ec0463
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/40/129540/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/openstack/common/strutils.py', 'ironicclient/openstack/common/cliutils.py', 'requirements.txt', 'ironicclient/common/i18n.py', 'ironicclient/openstack/common/gettextutils.py', 'openstack-common.conf']",6,b25c1eb75a64d0e7e916d650641e3aff8ad99af5,switch-to-oslo-i18n,,module=gettextutils,38,416
openstack%2Fironic~master~I994994e1e8ec4760b677a4ab613ee059c5787900,openstack/ironic,master,I994994e1e8ec4760b677a4ab613ee059c5787900,Continue heartbeating after DB connection failure,MERGED,2014-10-17 15:35:27.000000000,2014-10-20 08:53:30.000000000,2014-10-20 08:53:29.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 10239}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-10-17 15:35:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/556dc4ad418174a5e82120b62263aa65d70d7611', 'message': 'Continue heartbeating after DB connection failure\n\nIf the conductor cannot connect to the database to heartbeat,\nit should retry on the next heartbeat instead of the heartbeat\nthread dying.\n\nPartial-Bug: 1382589\n\nChange-Id: I994994e1e8ec4760b677a4ab613ee059c5787900\n'}, {'number': 2, 'created': '2014-10-17 15:36:30.000000000', 'files': ['ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/2cba7f557abfe2525913ef4ae1310e1d1e23f96c', 'message': 'Continue heartbeating after DB connection failure\n\nIf the conductor cannot connect to the database to heartbeat,\nit should retry on the next heartbeat instead of the heartbeat\nthread dying.\n\nPartial-Bug: 1382589\n\nChange-Id: I994994e1e8ec4760b677a4ab613ee059c5787900\n'}]",0,129301,2cba7f557abfe2525913ef4ae1310e1d1e23f96c,12,4,2,10343,,,0,"Continue heartbeating after DB connection failure

If the conductor cannot connect to the database to heartbeat,
it should retry on the next heartbeat instead of the heartbeat
thread dying.

Partial-Bug: 1382589

Change-Id: I994994e1e8ec4760b677a4ab613ee059c5787900
",git fetch https://review.opendev.org/openstack/ironic refs/changes/01/129301/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py']",2,556dc4ad418174a5e82120b62263aa65d70d7611,bug/1382589,from oslo.db import exception as db_exception try: self.dbapi.touch_conductor(self.host) except db_exception.DBConnectionError: LOG.warning(_LW('Conductor could not connect to database ' 'while heartbeating.')), self.dbapi.touch_conductor(self.host),21,1
openstack%2Fironic~master~I99fa26f763ab456d3428951d6a729098a73cf9ef,openstack/ironic,master,I99fa26f763ab456d3428951d6a729098a73cf9ef,Put a cap on our cyclomatic complexity,MERGED,2014-10-17 05:38:20.000000000,2014-10-20 08:51:43.000000000,2014-10-20 08:51:42.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 8106}, {'_account_id': 8125}, {'_account_id': 10239}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-10-17 05:38:20.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic/commit/3fba6a946806b0684d4a49ef2ef165edbdeec816', 'message': ""Put a cap on our cyclomatic complexity\n\nFlake8 has support for McCabe cyclomatic complexity.  Ironic's\nmost complex code is at 16 right now, so cap this at 17 to make\nsure we don't start writing more complex code than what we already\nhave today.\n\nNova is doing similar: https://review.openstack.org/#/c/129125\n\nChange-Id: I99fa26f763ab456d3428951d6a729098a73cf9ef\n""}]",0,129132,3fba6a946806b0684d4a49ef2ef165edbdeec816,16,6,1,8125,,,0,"Put a cap on our cyclomatic complexity

Flake8 has support for McCabe cyclomatic complexity.  Ironic's
most complex code is at 16 right now, so cap this at 17 to make
sure we don't start writing more complex code than what we already
have today.

Nova is doing similar: https://review.openstack.org/#/c/129125

Change-Id: I99fa26f763ab456d3428951d6a729098a73cf9ef
",git fetch https://review.opendev.org/openstack/ironic refs/changes/32/129132/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,3fba6a946806b0684d4a49ef2ef165edbdeec816,mccabe-complexity-cap,max-complexity=17,,1,0
openstack%2Fceilometer~master~I01e683569d9b8116f2dbadbf8fe4cb0024625178,openstack/ceilometer,master,I01e683569d9b8116f2dbadbf8fe4cb0024625178,Edits assert methods,MERGED,2014-10-19 21:35:01.000000000,2014-10-20 08:51:35.000000000,2014-10-20 08:51:34.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 8052}]","[{'number': 1, 'created': '2014-10-19 21:35:01.000000000', 'files': ['ceilometer/tests/network/services/test_lbaas.py', 'ceilometer/tests/network/services/test_fwaas.py', 'ceilometer/tests/network/services/test_vpnaas.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9aeed3b97cdc90b8c4db3b64356bb013e29ae698', 'message': 'Edits assert methods\n\nMakes changes to 3 files:\ntests/network/services/test_fwaas.py\ntests/network/services/test_lbaas.py\ntests/network/services/test_vpnaas.py\n\nReplaces assertTrue(a not in b) with assertNotIn(a, b),\nand assertTrue(a in b) with assertIn(a, b).\n\nChange-Id: I01e683569d9b8116f2dbadbf8fe4cb0024625178\n'}]",0,129489,9aeed3b97cdc90b8c4db3b64356bb013e29ae698,7,3,1,13518,,,0,"Edits assert methods

Makes changes to 3 files:
tests/network/services/test_fwaas.py
tests/network/services/test_lbaas.py
tests/network/services/test_vpnaas.py

Replaces assertTrue(a not in b) with assertNotIn(a, b),
and assertTrue(a in b) with assertIn(a, b).

Change-Id: I01e683569d9b8116f2dbadbf8fe4cb0024625178
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/89/129489/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/network/services/test_lbaas.py', 'ceilometer/tests/network/services/test_fwaas.py', 'ceilometer/tests/network/services/test_vpnaas.py']",3,9aeed3b97cdc90b8c4db3b64356bb013e29ae698,assert_fixing_4," self.assertNotIn(vpn, discovered_vpns) else: self.assertIn(vpn, discovered_vpns)", self.assertTrue(vpn not in discovered_vpns) else: self.assertTrue(vpn in discovered_vpns),10,10
openstack%2Fceilometer~master~Idcd258bb6be4aebef5bcfc91cedb91cb14c69950,openstack/ceilometer,master,Idcd258bb6be4aebef5bcfc91cedb91cb14c69950,Edits assert methods,MERGED,2014-10-19 18:22:21.000000000,2014-10-20 08:51:27.000000000,2014-10-20 08:51:26.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 8052}]","[{'number': 1, 'created': '2014-10-19 18:22:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/140cdf06d2b29c80d36752a1d247dbbe29461dc4', 'message': 'Edits assert methods.\n\nMakes changes to\ntests/ipmi/platform/test_intel_node_manager.py.\n\nChanges assertTrue(variable, {}) on\nassertEqual({}, variable), where\nvariable is temperature and power.\n\nChange-Id: Idcd258bb6be4aebef5bcfc91cedb91cb14c69950\n'}, {'number': 2, 'created': '2014-10-19 21:05:00.000000000', 'files': ['ceilometer/tests/ipmi/platform/test_intel_node_manager.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3bd0846513bb5eeab081ee6b4ebb6d28ee7fc4ba', 'message': ""Edits assert methods\n\nMakes changes to\ntests/ipmi/platform/test_intel_node_manager.py.\n\nReplaces assertTrue(variable, {}) with\nassertEqual({}, 'variable'), where\n'variable' is temperature and power.\n\nChange-Id: Idcd258bb6be4aebef5bcfc91cedb91cb14c69950\n""}]",0,129482,3bd0846513bb5eeab081ee6b4ebb6d28ee7fc4ba,9,3,2,13518,,,0,"Edits assert methods

Makes changes to
tests/ipmi/platform/test_intel_node_manager.py.

Replaces assertTrue(variable, {}) with
assertEqual({}, 'variable'), where
'variable' is temperature and power.

Change-Id: Idcd258bb6be4aebef5bcfc91cedb91cb14c69950
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/82/129482/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/ipmi/platform/test_intel_node_manager.py'],1,140cdf06d2b29c80d36752a1d247dbbe29461dc4,assert_fixing_2," self.assertEqual({}, power) self.assertEqual({}, temperature)", self.assertTrue(power == {}) self.assertTrue(temperature == {}),2,2
openstack%2Fceilometer~master~I9a333ce08719462aa53ed8762b87b81d5769154c,openstack/ceilometer,master,I9a333ce08719462aa53ed8762b87b81d5769154c,Edits assert methods,MERGED,2014-10-19 18:54:23.000000000,2014-10-20 08:51:19.000000000,2014-10-20 08:51:19.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 8052}]","[{'number': 1, 'created': '2014-10-19 18:54:23.000000000', 'files': ['ceilometer/tests/ipmi/platform/test_ipmi_sensor.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1a0974b4546297a793f9fe0aac10f301c7011329', 'message': 'Edits assert methods\n\nMakes changes to\ntests/ipmi/platform/test_ipmi_sensor.py.\n\nReplaces assertTrue(sensors == {}) with\nassertEqual({}, sensors).\n\nChange-Id: I9a333ce08719462aa53ed8762b87b81d5769154c\n'}]",0,129486,1a0974b4546297a793f9fe0aac10f301c7011329,7,3,1,13518,,,0,"Edits assert methods

Makes changes to
tests/ipmi/platform/test_ipmi_sensor.py.

Replaces assertTrue(sensors == {}) with
assertEqual({}, sensors).

Change-Id: I9a333ce08719462aa53ed8762b87b81d5769154c
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/86/129486/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/ipmi/platform/test_ipmi_sensor.py'],1,1a0974b4546297a793f9fe0aac10f301c7011329,assert_fixing_3," self.assertEqual({}, sensors) self.assertEqual({}, sensors) self.assertEqual({}, sensors) self.assertEqual({}, sensors)", self.assertTrue(sensors == {}) self.assertTrue(sensors == {}) self.assertTrue(sensors == {}) self.assertTrue(sensors == {}),4,4
openstack%2Fneutron~master~I0fba9c9623898ee52590207ebbb728503bb59a5b,openstack/neutron,master,I0fba9c9623898ee52590207ebbb728503bb59a5b,Only fetch port_id from SG binding table,MERGED,2014-10-17 14:04:59.000000000,2014-10-20 08:48:58.000000000,2014-10-20 08:48:57.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-17 14:04:59.000000000', 'files': ['neutron/db/securitygroups_rpc_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6acadab5eb8b7b627e097a638d8486bef59a7f30', 'message': 'Only fetch port_id from SG binding table\n\nChange a query to only retrieve the port_id instead of\nevery column from the row of security group binding info.\n\nPartial-Bug: #1373851\nChange-Id: I0fba9c9623898ee52590207ebbb728503bb59a5b\n'}]",0,129264,6acadab5eb8b7b627e097a638d8486bef59a7f30,29,25,1,7787,,,0,"Only fetch port_id from SG binding table

Change a query to only retrieve the port_id instead of
every column from the row of security group binding info.

Partial-Bug: #1373851
Change-Id: I0fba9c9623898ee52590207ebbb728503bb59a5b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/64/129264/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/securitygroups_rpc_base.py'],1,6acadab5eb8b7b627e097a638d8486bef59a7f30,bug/1373851," for (port_id, rule_in_db) in rules_in_db: query = context.session.query(sg_binding_port, for (port_id, rule_in_db) in rules_in_db:"," for (binding, rule_in_db) in rules_in_db: port_id = binding['port_id'] query = context.session.query(sg_db.SecurityGroupPortBinding, for (binding, rule_in_db) in rules_in_db: port_id = binding['port_id']",3,5
openstack%2Fceilometer~master~Iafa437bcd2408845ba6b443474fcf838eae109e4,openstack/ceilometer,master,Iafa437bcd2408845ba6b443474fcf838eae109e4,Edits assert method,MERGED,2014-10-19 16:49:19.000000000,2014-10-20 08:48:27.000000000,2014-10-20 08:48:26.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 8052}]","[{'number': 1, 'created': '2014-10-19 16:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/378e15c32038717de5afedb98b88d5110f058c5e', 'message': 'Edits assert method.\n\nReplaces assertEqual(None, s.user_id)\nassertIsNone(s.user_id).\n\nChange-Id: Iafa437bcd2408845ba6b443474fcf838eae109e4\n'}, {'number': 2, 'created': '2014-10-19 18:33:59.000000000', 'files': ['ceilometer/tests/hardware/pollsters/test_util.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6358e4153cb470f3d7b68c84d41a2ee69fa4c77b', 'message': 'Edits assert method\n\nMakes changes in assert method in\ntests/hardware/pollsters/test_util.py.\n\nReplaces assertEqual(None, s.user_id)\non assertIsNone(s.user_id).\n\nChange-Id: Iafa437bcd2408845ba6b443474fcf838eae109e4\n'}]",0,129474,6358e4153cb470f3d7b68c84d41a2ee69fa4c77b,9,3,2,13518,,,0,"Edits assert method

Makes changes in assert method in
tests/hardware/pollsters/test_util.py.

Replaces assertEqual(None, s.user_id)
on assertIsNone(s.user_id).

Change-Id: Iafa437bcd2408845ba6b443474fcf838eae109e4
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/74/129474/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/hardware/pollsters/test_util.py'],1,378e15c32038717de5afedb98b88d5110f058c5e,test_util_bug, self.assertIsNone(s.user_id)," self.assertEqual(None, s.user_id)",1,1
openstack%2Fsahara-image-elements~master~I4529a55d1f5aa131951c27a2c7599507e750b18a,openstack/sahara-image-elements,master,I4529a55d1f5aa131951c27a2c7599507e750b18a,Add Hue support to Cloudera plugin,MERGED,2014-10-16 12:59:38.000000000,2014-10-20 08:39:26.000000000,2014-10-20 06:14:18.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7732}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-16 12:59:38.000000000', 'files': ['elements/hadoop-cloudera/install.d/50-install-cloudera'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/915b58b6aedea84bffcc596b35546c2f9b4b2988', 'message': ""Add Hue support to Cloudera plugin\n\nChanges:\n* sorting list of packages\n* add 'hue' package\n\npartially implements bp: cdh-hue-support\n\nChange-Id: I4529a55d1f5aa131951c27a2c7599507e750b18a\n""}]",0,128910,915b58b6aedea84bffcc596b35546c2f9b4b2988,13,6,1,7710,,,0,"Add Hue support to Cloudera plugin

Changes:
* sorting list of packages
* add 'hue' package

partially implements bp: cdh-hue-support

Change-Id: I4529a55d1f5aa131951c27a2c7599507e750b18a
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/10/128910/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/hadoop-cloudera/install.d/50-install-cloudera'],1,915b58b6aedea84bffcc596b35546c2f9b4b2988,bp/cdh-hue-support,install-packages \ cloudera-manager-agent \ cloudera-manager-daemons \ cloudera-manager-server \ cloudera-manager-server-db-2 \ hadoop-hdfs-datanode \ hadoop-hdfs-namenode \ hadoop-hdfs-secondarynamenode \ hadoop-mapreduce \ hadoop-mapreduce-historyserver \ hadoop-yarn-nodemanager \ hadoop-yarn-resourcemanager \ hive-metastore \ hive-server2 \ hue \ oozie \ oracle-j2sdk1.7,install-packages cloudera-manager-agent \ cloudera-manager-daemons \ oracle-j2sdk1.7 \ cloudera-manager-server \ cloudera-manager-server-db-2 \ hadoop-hdfs-namenode \ hadoop-hdfs-secondarynamenode \ hadoop-hdfs-datanode \ hadoop-yarn-resourcemanager \ hadoop-yarn-nodemanager \ hadoop-mapreduce \ hadoop-mapreduce-historyserver \ oozie \ hive-metastore \ hive-server2,17,15
openstack%2Foslo-incubator~master~Ibcf4e734a3d36b04266fae9b6d18cf3b10c4537a,openstack/oslo-incubator,master,Ibcf4e734a3d36b04266fae9b6d18cf3b10c4537a,Minor fixes in policy module,MERGED,2014-10-17 09:15:34.000000000,2014-10-20 08:15:34.000000000,2014-10-20 08:15:33.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-10-17 09:15:34.000000000', 'files': ['openstack/common/policy.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/9e8b9f61cfd263e3164f7a6b363fc39e6e63a396', 'message': 'Minor fixes in policy module\n\nChange-Id: Ibcf4e734a3d36b04266fae9b6d18cf3b10c4537a\n'}]",0,129180,9e8b9f61cfd263e3164f7a6b363fc39e6e63a396,6,2,1,9656,,,0,"Minor fixes in policy module

Change-Id: Ibcf4e734a3d36b04266fae9b6d18cf3b10c4537a
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/80/129180/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/policy.py'],1,9e8b9f61cfd263e3164f7a6b363fc39e6e63a396,, help=_('Directories where policy configuration files are ' Any remaining arguments passed to enforce() (both, help=_('The directories of policy configuration files is ' Any remaining arguments passed to check() (both,2,2
openstack%2Ftempest~master~I490f3c7eb66e74f4185588870f9b2b44b54bd64b,openstack/tempest,master,I490f3c7eb66e74f4185588870f9b2b44b54bd64b,Port  API Tests Enhancements,MERGED,2014-07-16 09:36:34.000000000,2014-10-20 08:09:34.000000000,2014-10-20 08:09:33.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 8576}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11670}, {'_account_id': 11671}]","[{'number': 1, 'created': '2014-07-16 09:36:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e42d4c6ab4ed8b50b6fa550d0490d203070cac53', 'message': 'Port  API Tests Enhancements\n\nAdd test to update port with security group\n   -Create a port without security group\n   -Create security group\n   -Update the port with the secuirty group\n   -Validate that security group attribute of the port is updated successfully\n\nAdd test to update port with two security group\n   -Create a port without security group\n   -Create two security group\n   -Update the port with both secuirty group\n   -Validate that both the security groups are updated in the port  successfully\n\nChange-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b\n'}, {'number': 2, 'created': '2014-07-16 10:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3e22f8995afc6373f51f62d2eb058c36a00f12e2', 'message': 'Port  API Tests Enhancements\n\nAdd test to update port with security group\n   -Create a port without security group\n   -Create security group\n   -Update the port with the secuirty group\n   -Validate that security group attribute of the port is updated successfully\n\nAdd test to update port with two security group\n   -Create a port without security group\n   -Create two security group\n   -Update the port with both secuirty group\n   -Validate that both the security groups are updated in the port  successfully\n\nChange-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b\n'}, {'number': 3, 'created': '2014-07-17 10:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d4def014b050829e57099a17abb6150dfd4ea62a', 'message': 'Port  API Tests Enhancements\n\nAdd test to update port with security group\n   -Create a port without security group\n   -Create security group\n   -Update the port with the secuirty group\n   -Validate that security group attribute of the port is updated successfully\n\nAdd test to update port with two security group\n   -Create a port without security group\n   -Create two security group\n   -Update the port with both secuirty group\n   -Validate that both the security groups are updated in the port  successfully\n\nChange-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b\n'}, {'number': 4, 'created': '2014-07-17 20:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4f8ef538cbcd975d352d9126c63a06b97fbf2983', 'message': 'Port  API Tests Enhancements\n\nAdd test to update port with security group\n   -Create a port without security group\n   -Create security group\n   -Update the port with the secuirty group\n   -Validate that security group attribute of the port is updated successfully\n\nAdd test to update port with two security group\n   -Create a port without security group\n   -Create two security group\n   -Update the port with both secuirty group\n   -Validate that both the security groups are updated in the port  successfully\n\nChange-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b\n'}, {'number': 5, 'created': '2014-07-18 03:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6e0adb955ef9784febe3ad77eacbd91c7f1b64c4', 'message': 'Port  API Tests Enhancements\n\nAdd test to update port with security group\n   -Create a port without security group\n   -Create security group\n   -Update the port with the secuirty group\n   -Validate that security group attribute of the port is updated successfully\n\nAdd test to update port with two security group\n   -Create a port without security group\n   -Create two security group\n   -Update the port with both secuirty group\n   -Validate that both the security groups are updated in the port  successfully\n\nChange-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b\n'}, {'number': 6, 'created': '2014-07-19 05:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4e761b639a1a2ccd05a5043e121ca2b9cbd96b06', 'message': 'Port  API Tests Enhancements\n\nAdd function to update port with security groups\n   -Function take list of security groups name\n    as parameter\n   -Create security group based on the names in\n    the parameter\n   -Create a port without security group\n   -Update the port with the security group\n   -Verify that security groups are updated in\n     the port  successfully\n\nAdd a test to update the port with security group\n    -Call the update port with security groups\n     function with one name of security group\n\nAdd a test to update the port with two security\ngroup\n   -Call the update port with security groups\n    function with two names of security groups\n\nChange-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b\n'}, {'number': 7, 'created': '2014-07-21 09:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3049af43f561c420b58a9934df646a0da360efca', 'message': 'Port  API Tests Enhancements\n\nAdd function to update port with security groups\n   -Function take list of security groups name\n    as parameter\n   -Create security group based on the names in\n    the parameter\n   -Create a port without security group\n   -Update the port with the security group\n   -Verify that security groups are updated in\n     the port  successfully\n\nAdd a test to update the port with security group\n    -Call the update port with security groups\n     function with one name of security group\n\nAdd a test to update the port with two security\ngroup\n   -Call the update port with security groups\n    function with two names of security groups\n\nChange-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b\n'}, {'number': 8, 'created': '2014-07-21 13:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b404391076ebeef5a64e8807d2329ddabdec8eba', 'message': 'Port  API Tests Enhancements\n\nAdd function to update port with security groups\n   -Function take list of security groups name\n    as parameter\n   -Create security group based on the names in\n    the parameter\n   -Create a port without security group\n   -Update the port with the security group\n   -Verify that security groups are updated in\n     the port  successfully\n\nAdd a test to update the port with security group\n    -Call the update port with security groups\n     function with one name of security group\n\nAdd a test to update the port with two security\ngroup\n   -Call the update port with security groups\n    function with two names of security groups\n\nChange-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b\n'}, {'number': 9, 'created': '2014-07-21 18:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8c68533b0da9aa2e49ae7357dee49eba178c2ce6', 'message': 'Port  API Tests Enhancements\n\nAdd function to update port with security groups\n   -Function take list of security groups name\n    as parameter\n   -Create security group based on the names in\n    the parameter\n   -Create a port without security group\n   -Update the port with the security group\n   -Verify that security groups are updated in\n     the port  successfully\n\nAdd a test to update the port with security group\n    -Call the update port with security groups\n     function with one name of security group\n\nAdd a test to update the port with two security\ngroup\n   -Call the update port with security groups\n    function with two names of security groups\n\nChange-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b\n'}, {'number': 10, 'created': '2014-08-18 10:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5d8957c71eeb140bc68744426d98b31cfcf5f93e', 'message': 'Port  API Tests Enhancements\n\nAdd function to update port with security groups\n   -Function take list of security groups name\n    as parameter\n   -Create security group based on the names in\n    the parameter\n   -Create a port without security group\n   -Update the port with the security group\n   -Verify that security groups are updated in\n     the port  successfully\n\nAdd a test to update the port with security group\n    -Call the update port with security groups\n     function with one name of security group\n\nAdd a test to update the port with two security\ngroup\n   -Call the update port with security groups\n    function with two names of security groups\n\nChange-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b\n'}, {'number': 11, 'created': '2014-08-19 18:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/83b61807f24e80bde53bfeb4abdd89f73df72723', 'message': 'Port  API Tests Enhancements\n\nAdd function to update port with security groups\n   -Function take list of security groups name\n    as parameter\n   -Create security group based on the names in\n    the parameter\n   -Create a port without security group\n   -Update the port with the security group\n   -Verify that security groups are updated in\n     the port  successfully\n\nAdd a test to update the port with security group\n    -Call the update port with security groups\n     function with one name of security group\n\nAdd a test to update the port with two security\ngroup\n   -Call the update port with security groups\n    function with two names of security groups\n\nChange-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b\n'}, {'number': 12, 'created': '2014-08-20 14:21:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/533c3275b32af1eb07f68a4b135c4ae488a8a387', 'message': 'Port  API Tests Enhancements\n\nAdd function to update port with security groups\n   -Function take list of security groups name\n    as parameter\n   -Create security group based on the names in\n    the parameter\n   -Create a port without security group\n   -Update the port with the security group\n   -Verify that security groups are updated in\n     the port  successfully\n\nAdd a test to update the port with security group\n    -Call the update port with security groups\n     function with one name of security group\n\nAdd a test to update the port with two security\ngroup\n   -Call the update port with security groups\n    function with two names of security groups\n\nChange-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b\n'}, {'number': 13, 'created': '2014-10-09 14:01:29.000000000', 'files': ['tempest/services/network/xml/network_client.py', 'tempest/api/network/test_ports.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/dba59f9a5c4abd17fff766bf74a865f0fbe76e9a', 'message': 'Port  API Tests Enhancements\n\nAdd function to update port with security groups\n   -Function take list of security groups name\n    as parameter\n   -Create security group based on the names in\n    the parameter\n   -Create a port without security group\n   -Update the port with the security group\n   -Verify that security groups are updated in\n     the port  successfully\n\nAdd a test to update the port with security group\n    -Call the update port with security groups\n     function with one name of security group\n\nAdd a test to update the port with two security\ngroup\n   -Call the update port with security groups\n    function with two names of security groups\n\nChange-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b\n'}]",59,107277,dba59f9a5c4abd17fff766bf74a865f0fbe76e9a,167,15,13,11671,,,0,"Port  API Tests Enhancements

Add function to update port with security groups
   -Function take list of security groups name
    as parameter
   -Create security group based on the names in
    the parameter
   -Create a port without security group
   -Update the port with the security group
   -Verify that security groups are updated in
     the port  successfully

Add a test to update the port with security group
    -Call the update port with security groups
     function with one name of security group

Add a test to update the port with two security
group
   -Call the update port with security groups
    function with two names of security groups

Change-Id: I490f3c7eb66e74f4185588870f9b2b44b54bd64b
",git fetch https://review.opendev.org/openstack/tempest refs/changes/77/107277/13 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/network/xml/network_client.py', 'tempest/api/network/test_ports.py']",2,e42d4c6ab4ed8b50b6fa550d0490d203070cac53,Port-API-Test-Enhancement," @test.attr(type='smoke') def test_update_port_with_security_group(self): post_body = {""network_id"": self.network['id']} resp, body = self.admin_client.create_port(**post_body) self.assertEqual('201', resp['status']) port = body['port'] # Create a security group name = data_utils.rand_name('secgroup-') resp, group_create_body = self.admin_client.create_security_group( name=name) security_group = group_create_body['security_group'] self.assertEqual('201', resp['status']) security_group_list = list() security_group_list.append(group_create_body['security_group']['id']) update_body = {""security_groups"": security_group_list} # Update the port with security group resp, body = self.admin_client.update_port( port['id'], **update_body) # Verify the security group updated to port self.addCleanup(self.admin_client.delete_security_group, security_group['id']) self.assertEqual('200', resp['status']) resp, body = self.admin_client.show_port(port['id']) self.assertEqual('200', resp['status']) port_show = body['port'] self.assertEqual(port_show['security_groups'], security_group_list) self.addCleanup(self.admin_client.delete_port, port['id']) self.assertEqual('200', resp['status']) @test.attr(type='smoke') def test_update_port_with_second_security_group(self): # Update port with two security group post_body = {""network_id"": self.network['id']} resp, body = self.admin_client.create_port(**post_body) self.assertEqual('201', resp['status']) port = body['port'] # Create a security group i = 0 security_group_list = list() # Create Two security Group while i < 2: name = data_utils.rand_name('secgroup-') resp, group_create_body = self.admin_client.create_security_group( name=name) self.assertEqual('201', resp['status']) security_group_list.append(group_create_body['security_group'] ['id']) i = i + 1 update_body = {""security_groups"": security_group_list} # Update the port with two security group resp, body = self.admin_client.update_port( port['id'], **update_body) # Verify the security group updated to port resp, body = self.admin_client.show_port(port['id']) self.assertEqual('200', resp['status']) port_show = body['port'] self.assertIn(port_show['security_groups'][0], security_group_list) self.addCleanup(self.admin_client.delete_security_group, port_show['security_groups'][0]) self.assertIn(port_show['security_groups'][1], security_group_list) self.addCleanup(self.admin_client.delete_security_group, port_show['security_groups'][1]) self.addCleanup(self.admin_client.delete_port, port['id']) self.assertEqual('200', resp['status']) ",,68,1
openstack%2Ftripleo-image-elements~master~I2081a945375fe0b8a72de3396b0d862f72b50928,openstack/tripleo-image-elements,master,I2081a945375fe0b8a72de3396b0d862f72b50928,Migrates corosync element to svc-map,MERGED,2014-10-16 21:56:35.000000000,2014-10-20 07:47:07.000000000,2014-10-20 07:47:07.000000000,"[{'_account_id': 3}, {'_account_id': 4330}, {'_account_id': 7582}]","[{'number': 1, 'created': '2014-10-16 21:56:35.000000000', 'files': ['elements/corosync/svc-map', 'elements/corosync/os-refresh-config/post-configure.d/14-corosync'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/7f6308afd68b70776e3abb860f6abe09644ae0b2', 'message': 'Migrates corosync element to svc-map\n\nThis patch migrates the corosync element from map-services to\nsvc-map by adding a svc-map file and the -a option to os-svc-enable.\n\nChange-Id: I2081a945375fe0b8a72de3396b0d862f72b50928\n'}]",0,129072,7f6308afd68b70776e3abb860f6abe09644ae0b2,8,3,1,8532,,,0,"Migrates corosync element to svc-map

This patch migrates the corosync element from map-services to
svc-map by adding a svc-map file and the -a option to os-svc-enable.

Change-Id: I2081a945375fe0b8a72de3396b0d862f72b50928
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/72/129072/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/corosync/svc-map', 'elements/corosync/os-refresh-config/post-configure.d/14-corosync']",2,7f6308afd68b70776e3abb860f6abe09644ae0b2,migrate-corosync-svc-map,os-svc-enable -an corosync os-svc-restart -an corosync,os-svc-enable -n corosync os-svc-restart -n corosync,4,2
openstack%2Ffuel-library~master~I56e5d682150773bd16245220c7d7577495f791f6,openstack/fuel-library,master,I56e5d682150773bd16245220c7d7577495f791f6,Fix amqp port for nova-compute OCF (vmware),ABANDONED,2014-10-17 16:03:29.000000000,2014-10-20 07:46:34.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11427}, {'_account_id': 13343}]","[{'number': 1, 'created': '2014-10-17 16:03:29.000000000', 'files': ['deployment/puppet/vmware/files/ocf/nova-compute'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2db2d9611ad6648f188cc895d32dab2a977c5d8e', 'message': 'Fix amqp port for nova-compute OCF (vmware)\n\nCloses-bug: #1382601\n\nChange-Id: I56e5d682150773bd16245220c7d7577495f791f6\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,129312,2db2d9611ad6648f188cc895d32dab2a977c5d8e,10,7,1,6926,,,0,"Fix amqp port for nova-compute OCF (vmware)

Closes-bug: #1382601

Change-Id: I56e5d682150773bd16245220c7d7577495f791f6
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/12/129312/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/vmware/files/ocf/nova-compute'],1,2db2d9611ad6648f188cc895d32dab2a977c5d8e,fix1382601,"OCF_RESKEY_amqp_server_port_default=""5673""","OCF_RESKEY_amqp_server_port_default=""5672""",1,1
openstack%2Ftripleo-image-elements~master~Id1b8d8ff6d55d74f38b19d89f76001f374c55393,openstack/tripleo-image-elements,master,Id1b8d8ff6d55d74f38b19d89f76001f374c55393,Add SSL PKI properties for keystone,MERGED,2014-10-16 21:05:03.000000000,2014-10-20 07:41:02.000000000,2014-10-20 07:41:02.000000000,"[{'_account_id': 3}, {'_account_id': 7582}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-10-16 21:05:03.000000000', 'files': ['elements/keystone/os-apply-config/mnt/state/etc/keystone/ssl/private/signing_key.pem', 'elements/keystone/os-apply-config/mnt/state/etc/keystone/ssl/certs/signing_cert.pem'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/705e53bf1bfd654ab40595a91cf14dc7b45a8fad', 'message': 'Add SSL PKI properties for keystone\n\nTo implement the SSL PKI spec we need to use property names that can be\ngeneralized to all services. Adding new properties to support this for\nthe keystone ssl cert and cert key, while still supporting the old\nproperties for backwards compatibility.\n\nChange-Id: Id1b8d8ff6d55d74f38b19d89f76001f374c55393\n'}]",0,129049,705e53bf1bfd654ab40595a91cf14dc7b45a8fad,8,3,1,10035,,,0,"Add SSL PKI properties for keystone

To implement the SSL PKI spec we need to use property names that can be
generalized to all services. Adding new properties to support this for
the keystone ssl cert and cert key, while still supporting the old
properties for backwards compatibility.

Change-Id: Id1b8d8ff6d55d74f38b19d89f76001f374c55393
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/49/129049/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/keystone/os-apply-config/mnt/state/etc/keystone/ssl/private/signing_key.pem', 'elements/keystone/os-apply-config/mnt/state/etc/keystone/ssl/certs/signing_cert.pem']",2,705e53bf1bfd654ab40595a91cf14dc7b45a8fad,feature/keystone-ssl-pki,{{#keystone.ssl.certificate}}{{.}}{{/keystone.ssl.certificate}}{{^keystone.ssl.certificate}}{{keystone.signing_certificate}}{{/keystone.ssl.certificate}},{{keystone.signing_certificate}},2,2
openstack%2Fsahara-image-elements~master~Iddd387d3929fae9310f9128c84470d7de737d4c9,openstack/sahara-image-elements,master,Iddd387d3929fae9310f9128c84470d7de737d4c9,Add Hive support to Cloudera plugin,MERGED,2014-10-10 12:16:30.000000000,2014-10-20 07:32:26.000000000,2014-10-20 06:14:11.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-10 12:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/cbaa299d38eb2a5a16602a2554f4d7cbf6a97ec6', 'message': 'Add Hive support to Cloudera plugin\n\npartially implements bp: cdh-hive-support\n\nChange-Id: Iddd387d3929fae9310f9128c84470d7de737d4c9\n'}, {'number': 2, 'created': '2014-10-16 12:59:38.000000000', 'files': ['elements/hadoop-cloudera/install.d/50-install-cloudera'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/a615a6529422127cf38041f2727f5669de23e40e', 'message': 'Add Hive support to Cloudera plugin\n\npartially implements bp: cdh-hive-support\n\nChange-Id: Iddd387d3929fae9310f9128c84470d7de737d4c9\n'}]",0,127504,a615a6529422127cf38041f2727f5669de23e40e,38,9,2,7710,,,0,"Add Hive support to Cloudera plugin

partially implements bp: cdh-hive-support

Change-Id: Iddd387d3929fae9310f9128c84470d7de737d4c9
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/04/127504/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/hadoop-cloudera/install.d/50-install-cloudera'],1,cbaa299d38eb2a5a16602a2554f4d7cbf6a97ec6,bp/cdh-hue-support,oozie \ hive-metastore \ hive-server2,oozie,3,1
openstack%2Fmistral~master~Ib43d2237ebb0f8ef9f8d18e70182d7cc5f2f0828,openstack/mistral,master,Ib43d2237ebb0f8ef9f8d18e70182d7cc5f2f0828,Add documentation - part 3,MERGED,2014-10-07 07:22:56.000000000,2014-10-20 07:29:19.000000000,2014-10-20 07:29:19.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-10-07 07:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/65ec9e44fd0591fe5e4baa5446f98a7d1331063f', 'message': 'Add documentation - part 3\n\nDocument REST v2 with autodocs\n\nChange-Id: Ib43d2237ebb0f8ef9f8d18e70182d7cc5f2f0828'}, {'number': 2, 'created': '2014-10-17 03:46:05.000000000', 'files': ['mistral/api/controllers/v2/action.py', 'doc/source/developer/webapi/v2.rst', 'doc/source/conf.py', 'mistral/api/controllers/v2/workbook.py', 'doc/README.md', 'mistral/api/controllers/v2/execution.py', 'mistral/api/controllers/v2/task.py', 'mistral/api/controllers/v2/workflow.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/b8390eb84d6c7fd6e241038829b6ab337ab9b8ab', 'message': 'Add documentation - part 3\n\nDocument REST v2 with autodocs\n\nChange-Id: Ib43d2237ebb0f8ef9f8d18e70182d7cc5f2f0828\n'}]",1,126481,b8390eb84d6c7fd6e241038829b6ab337ab9b8ab,17,4,2,9432,,,0,"Add documentation - part 3

Document REST v2 with autodocs

Change-Id: Ib43d2237ebb0f8ef9f8d18e70182d7cc5f2f0828
",git fetch https://review.opendev.org/openstack/mistral refs/changes/81/126481/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/api/controllers/v2/action.py', 'doc/source/dsl/dsl_v1.rst', 'doc/source/dsl/index.rst', 'doc/source/conf.py', 'mistral/api/controllers/v2/workbook.py', 'mistral/api/controllers/v2/task.py', 'mistral/api/controllers/v2/workflow.py', 'doc/source/img/Mistral_reverse_workflow.png', 'doc/source/dsl/dsl_v2.rst', 'doc/source/img/Mistral_workbook_namespacing.png', 'doc/source/developer/webapi/v2.rst', 'doc/README.md', 'mistral/api/controllers/v2/execution.py', 'doc/source/img/Mistral_direct_workflow.png']",14,65ec9e44fd0591fe5e4baa5446f98a7d1331063f,update-docs,,,1277,13
openstack%2Ffuel-library~stable%2F5.1~I46c6bf3c83ada4273eaa05530e80886ebac7e75f,openstack/fuel-library,stable/5.1,I46c6bf3c83ada4273eaa05530e80886ebac7e75f,Fix blocking reject rule for rabbit ocf,MERGED,2014-10-14 14:28:08.000000000,2014-10-20 07:25:09.000000000,2014-10-20 07:25:09.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 8971}, {'_account_id': 9387}]","[{'number': 1, 'created': '2014-10-14 14:28:08.000000000', 'files': ['deployment/puppet/nova/files/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9be38a613486eb115050d8d165ce212d4a185f35', 'message': 'Fix blocking reject rule for rabbit ocf\n\n* Make RMQ unblock call safe (remove all discovered RMQ\n  blocking rules, if there are many of them).\n* Use unblock safe call prior to the blocking one.\n* Make block call idempotent and add 5 retries for iptables.\n* Add info log messages about block/unblock actions. Notify\n  if RMQ blocking rule cannot be added for some strange reason.\n\nPartial-bug: #1373569\nCloses-bug: #1375824\n\nChange-Id: I46c6bf3c83ada4273eaa05530e80886ebac7e75f\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,128305,9be38a613486eb115050d8d165ce212d4a185f35,12,6,1,6926,,,0,"Fix blocking reject rule for rabbit ocf

* Make RMQ unblock call safe (remove all discovered RMQ
  blocking rules, if there are many of them).
* Use unblock safe call prior to the blocking one.
* Make block call idempotent and add 5 retries for iptables.
* Add info log messages about block/unblock actions. Notify
  if RMQ blocking rule cannot be added for some strange reason.

Partial-bug: #1373569
Closes-bug: #1375824

Change-Id: I46c6bf3c83ada4273eaa05530e80886ebac7e75f
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/05/128305/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nova/files/ocf/rabbitmq'],1,9be38a613486eb115050d8d165ce212d4a185f35,fix1373569_5.1," # do not add temporary RMQ blocking rule, if it is already exist # otherwise, try to add a blocking rule with max of 5 retries tries=5 until $(iptables -nvL | grep -q 'temporary RMQ block') || [[ $tries -eq 0 ]]; do ((tries--)) iptables -I INPUT -p tcp -m tcp --dport ${OCF_RESKEY_node_port} -m state --state NEW,RELATED,ESTABLISHED \ -m comment --comment 'temporary RMQ block' -j REJECT --reject-with tcp-reset sleep 1 done if [ $tries -eq 0 ]; then return $OCF_ERR_GENERIC else return $OCF_SUCCESS fi } # remove all temporary RMQ blocking rules, if there are more than one exist for i in $(iptables -nvL --line-numbers | awk '/temporary RMQ block/ {print $1}'); do iptables -D INPUT -p tcp -m tcp --dport ${OCF_RESKEY_node_port} -m state --state NEW,RELATED,ESTABLISHED \ -m comment --comment 'temporary RMQ block' -j REJECT --reject-with tcp-reset done # Safe-unblock the rules, if there are any unblock_client_access # Apply the blocking rule if [[ $? == $OCF_SUCCESS ]]; then ocf_log info ""${LH} blocked access to RMQ port"" else ocf_log err ""${LH} cannot block access to RMQ port!"" return $OCF_ERR_GENERIC fi ocf_log info ""${LH} unblocked access to RMQ port"" ocf_log info ""${LH} unblocked access to RMQ port"" ocf_log info ""${LH} unblocked access to RMQ port"""," iptables -I INPUT -p tcp -m tcp --dport ${OCF_RESKEY_node_port} -m state --state NEW,RELATED,ESTABLISHED -m comment --comment 'temporary RMQ block' -j REJECT --reject-with tcp-reset } iptables -D INPUT -p tcp -m tcp --dport ${OCF_RESKEY_node_port} -m state --state NEW,RELATED,ESTABLISHED -m comment --comment 'temporary RMQ block' -j REJECT --reject-with tcp-reset",32,4
openstack%2Fos-cloud-config~master~Ib1339d0dd60c5fb4669bb10c5543e5155e86fe1f,openstack/os-cloud-config,master,Ib1339d0dd60c5fb4669bb10c5543e5155e86fe1f,Add support for injecting extra-specs into flavors,MERGED,2014-09-23 06:30:33.000000000,2014-10-20 07:16:04.000000000,2014-10-20 07:16:04.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 1726}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 9712}, {'_account_id': 12385}]","[{'number': 1, 'created': '2014-09-23 06:30:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/0745ce66dc90d870f736d0725a9c21750d3dcfd4', 'message': 'Add support for injecting extra-specs into flavors\n\nBuilding on the ability to create flavors to describe the hardware\nyour cloud has available, we need the ability to inject extra_specs\ninto the flavors when they are created to save operators having to\ndo so by hand.\n\nChange-Id: Ib1339d0dd60c5fb4669bb10c5543e5155e86fe1f\n'}, {'number': 2, 'created': '2014-10-07 05:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/7514a76b505731f127e39cc7a53dc05da8a0b2d9', 'message': 'Add support for injecting extra-specs into flavors\n\nBuilding on the ability to create flavors to describe the hardware\nyour cloud has available, we need the ability to inject extra_specs\ninto the flavors when they are created to save operators having to\ndo so by hand.\n\nChange-Id: Ib1339d0dd60c5fb4669bb10c5543e5155e86fe1f\n'}, {'number': 3, 'created': '2014-10-14 06:14:25.000000000', 'files': ['doc/source/usage.rst', 'os_cloud_config/tests/test_flavors.py', 'os_cloud_config/flavors.py'], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/3b07b96a06e379b85f912b4923d882a9f577787a', 'message': 'Add support for injecting extra-specs into flavors\n\nBuilding on the ability to create flavors to describe the hardware\nyour cloud has available, we need the ability to inject extra_specs\ninto the flavors when they are created to save operators having to\ndo so by hand.\n\nChange-Id: Ib1339d0dd60c5fb4669bb10c5543e5155e86fe1f\n'}]",0,123345,3b07b96a06e379b85f912b4923d882a9f577787a,26,8,3,9369,,,0,"Add support for injecting extra-specs into flavors

Building on the ability to create flavors to describe the hardware
your cloud has available, we need the ability to inject extra_specs
into the flavors when they are created to save operators having to
do so by hand.

Change-Id: Ib1339d0dd60c5fb4669bb10c5543e5155e86fe1f
",git fetch https://review.opendev.org/openstack/os-cloud-config refs/changes/45/123345/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/usage.rst', 'os_cloud_config/tests/test_flavors.py', 'os_cloud_config/flavors.py']",3,0745ce66dc90d870f736d0725a9c21750d3dcfd4,flavors-extra-specs, if flavor_desc.get('extra_specs'): flavor_metadata.update(flavor_desc['extra_specs']),,31,0
openstack%2Fnova~master~Ia1f4a6752668ddb73ebb8faf525b58a28d183754,openstack/nova,master,Ia1f4a6752668ddb73ebb8faf525b58a28d183754,Add notification for server group operations,MERGED,2014-07-18 10:11:02.000000000,2014-10-20 07:06:43.000000000,2014-10-16 23:17:16.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 688}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6772}, {'_account_id': 6873}, {'_account_id': 7494}, {'_account_id': 7641}, {'_account_id': 7664}, {'_account_id': 8247}, {'_account_id': 8264}, {'_account_id': 8531}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9282}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-07-18 10:11:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5bf423c363ba6fd064dd0038e3a574789863690c', 'message': 'Add notification for server group operations\n\nCurrently, there is no notification when create/update/delete\nserver groups, this caused some 3rd party client cannot know\nwhen those operations are finished.\n\nThe fix was adding notifications for those operations.\n\nChange-Id: Ia1f4a6752668ddb73ebb8faf525b58a28d183754\nCloses-Bug: #1343200\n'}, {'number': 2, 'created': '2014-07-23 07:17:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06b83e99e98ad2f9b9a14d5fc7fe381a989fdd8e', 'message': 'Add notification for server group operations\n\nCurrently, there is no notification when create/update/delete\nserver groups, this caused some 3rd party client cannot know\nwhen those operations are finished.\n\nThe fix was adding notifications for those operations.\n\nChange-Id: Ia1f4a6752668ddb73ebb8faf525b58a28d183754\nCloses-Bug: #1343200\n'}, {'number': 3, 'created': '2014-07-30 02:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0bceaa78001cf06d8cc554e316eea6a84aba71fc', 'message': 'Add notification for server group operations\n\nCurrently, there is no notification when create/update/delete\nserver groups, this caused some 3rd party client cannot know\nwhen those operations are finished.\n\nThe fix was adding notifications for those operations.\n\nDocImpact\nThe wiki page https://wiki.openstack.org/wiki/SystemUsageData\nneeds to be updated once this patch was merged.\n\nChange-Id: Ia1f4a6752668ddb73ebb8faf525b58a28d183754\nCloses-Bug: #1343200\n'}, {'number': 4, 'created': '2014-07-30 05:29:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4eeff2e7646208385e7ec0fd97f5ebf0e34400eb', 'message': 'Add notification for server group operations\n\nCurrently, there is no notification when create/update/delete\nserver groups, this caused some 3rd party client cannot know\nwhen those operations are finished.\n\nThe fix was adding notifications for those operations.\n\nDocImpact\nThe wiki page https://wiki.openstack.org/wiki/SystemUsageData\nneeds to be updated once this patch was merged.\n\nChange-Id: Ia1f4a6752668ddb73ebb8faf525b58a28d183754\nCloses-Bug: #1343200\n'}, {'number': 5, 'created': '2014-08-24 10:32:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/781f24ae0e7402c19f942442a92900d3c8b5b7d6', 'message': 'Add notification for server group operations\n\nCurrently, there is no notification when create/update/delete\nserver groups, this caused some 3rd party client cannot know\nwhen those operations are finished.\n\nThe fix was adding notifications for those operations.\n\nDocImpact\nThe wiki page https://wiki.openstack.org/wiki/SystemUsageData\nneeds to be updated once this patch was merged.\n\nChange-Id: Ia1f4a6752668ddb73ebb8faf525b58a28d183754\nCloses-Bug: #1343200\n'}, {'number': 6, 'created': '2014-09-14 03:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a2fd0327c872f7a92487f59b286f7b5914ee07c1', 'message': 'Add notification for server group operations\n\nCurrently, there is no notification when create/update/delete\nserver groups, this caused some 3rd party client cannot know\nwhen those operations are finished.\n\nThe fix was adding notifications for those operations.\n\nDocImpact\nThe wiki page https://wiki.openstack.org/wiki/SystemUsageData\nneeds to be updated once this patch was merged.\n\nChange-Id: Ia1f4a6752668ddb73ebb8faf525b58a28d183754\nCloses-Bug: #1343200\n'}, {'number': 7, 'created': '2014-09-18 02:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eeaa79c194975c66a3baffb819b10ba991ce9328', 'message': 'Add notification for server group operations\n\nCurrently, there is no notification when create/update/delete\nserver groups, this caused some 3rd party client cannot know\nwhen those operations are finished.\n\nThe fix was adding notifications for those operations.\n\nDocImpact\nThe wiki page https://wiki.openstack.org/wiki/SystemUsageData\nneeds to be updated once this patch was merged.\n\nChange-Id: Ia1f4a6752668ddb73ebb8faf525b58a28d183754\nCloses-Bug: #1343200\n'}, {'number': 8, 'created': '2014-09-19 02:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83c64383a4f5e29217c8bc05547463f1d5224b9d', 'message': 'Add notification for server group operations\n\nCurrently, there is no notification when create/update/delete\nserver groups, this caused some 3rd party client cannot know\nwhen those operations are finished.\n\nThe fix was adding notifications for those operations.\n\nDocImpact\nThe wiki page https://wiki.openstack.org/wiki/SystemUsageData\nneeds to be updated once this patch was merged.\n\nChange-Id: Ia1f4a6752668ddb73ebb8faf525b58a28d183754\nCloses-Bug: #1343200\n'}, {'number': 9, 'created': '2014-10-15 09:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b4b4c3af77ae6f33255894ea872da3d9a4f56368', 'message': 'Add notification for server group operations\n\nCurrently, there is no notification when create/update/delete\nserver groups, this caused some 3rd party client cannot know\nwhen those operations are finished.\n\nThe fix was adding notifications for those operations.\n\nDocImpact\nThe wiki page https://wiki.openstack.org/wiki/SystemUsageData\nneeds to be updated once this patch was merged.\n\nChange-Id: Ia1f4a6752668ddb73ebb8faf525b58a28d183754\nCloses-Bug: #1343200\n'}, {'number': 10, 'created': '2014-10-16 05:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c2c4e27cb22a76f5e3439921413c15799c920c47', 'message': 'Add notification for server group operations\n\nCurrently, there is no notification when create/update/delete\nserver groups, this caused some 3rd party client cannot know\nwhen those operations are finished.\n\nThe fix was adding notifications for those operations.\n\nDocImpact\nThe wiki page https://wiki.openstack.org/wiki/SystemUsageData\nneeds to be updated once this patch was merged.\n\nChange-Id: Ia1f4a6752668ddb73ebb8faf525b58a28d183754\nCloses-Bug: #1343200\n'}, {'number': 11, 'created': '2014-10-16 19:09:10.000000000', 'files': ['nova/tests/objects/test_objects.py', 'nova/objects/instance_group.py', 'nova/tests/objects/test_instance_group.py', 'nova/tests/compute/test_compute.py', 'nova/compute/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/daf278c0c8b6cc917b84f514fec65758adf17028', 'message': 'Add notification for server group operations\n\nCurrently, there is no notification when create/update/delete\nserver groups, this caused some 3rd party client cannot know\nwhen those operations are finished.\n\nThe fix was adding notifications for those operations.\n\nDocImpact\nThe wiki page https://wiki.openstack.org/wiki/SystemUsageData\nneeds to be updated once this patch was merged.\n\nChange-Id: Ia1f4a6752668ddb73ebb8faf525b58a28d183754\nCloses-Bug: #1343200\n'}]",35,107954,daf278c0c8b6cc917b84f514fec65758adf17028,146,22,11,7494,,,0,"Add notification for server group operations

Currently, there is no notification when create/update/delete
server groups, this caused some 3rd party client cannot know
when those operations are finished.

The fix was adding notifications for those operations.

DocImpact
The wiki page https://wiki.openstack.org/wiki/SystemUsageData
needs to be updated once this patch was merged.

Change-Id: Ia1f4a6752668ddb73ebb8faf525b58a28d183754
Closes-Bug: #1343200
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/107954/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/instance_group.py', 'nova/tests/objects/test_instance_group.py', 'nova/tests/compute/test_compute.py', 'nova/compute/utils.py']",4,5bf423c363ba6fd064dd0038e3a574789863690c,bug/1343200,"def notify_about_server_group_update(context, event_suffix, sg_payload): """"""Send a notification about server group update. :param event_suffix: Event type like ""create.start"" or ""create.end"" :param sg_payload: payload for server group update """""" sg_identifier = sg_payload.get('server_group_id', None) if not sg_identifier: sg_identifier = sg_payload.get('name', None) if not sg_identifier: LOG.debug(""No server group id or name specified for this "" ""notification and it will be ignored"") return notifier = rpc.get_notifier(service='servergroup', host=sg_identifier) notifier.info(context, 'servergroup.%s' % event_suffix, sg_payload) ",,87,0
openstack%2Fsahara~master~I28badef2ff345e56f914ea679b7d34871db8e9e4,openstack/sahara,master,I28badef2ff345e56f914ea679b7d34871db8e9e4,MapR FS datasource,MERGED,2014-08-21 15:39:20.000000000,2014-10-20 06:56:18.000000000,2014-10-20 06:56:17.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 12693}]","[{'number': 1, 'created': '2014-08-21 15:39:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c619e706656658dcbb7d3fd76bc4da7e48a0dd5f', 'message': 'MapR FS datasource\n\nChange-Id: I28badef2ff345e56f914ea679b7d34871db8e9e4\nImplements: blueprint maprfs-datasource\n'}, {'number': 2, 'created': '2014-09-02 11:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/740599bf4fc7c0b9e898c86b03dd5f85818dc1c7', 'message': 'MapR FS datasource\n\nChange-Id: I28badef2ff345e56f914ea679b7d34871db8e9e4\nImplements: blueprint maprfs-datasource\n'}, {'number': 3, 'created': '2014-10-02 18:19:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/22267480099b0f8a0f4507ff177c1c7b04bfbb5c', 'message': 'MapR FS datasource\n\nChange-Id: I28badef2ff345e56f914ea679b7d34871db8e9e4\nImplements: blueprint maprfs-datasource\n'}, {'number': 4, 'created': '2014-10-13 15:06:20.000000000', 'files': ['sahara/service/validations/edp/data_source.py', 'sahara/service/validations/edp/base.py', 'sahara/tests/unit/service/validation/edp/test_data_source.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/f72702694f42745aee774d40ac1137291157ebd9', 'message': 'MapR FS datasource\n\nChange-Id: I28badef2ff345e56f914ea679b7d34871db8e9e4\nImplements: blueprint maprfs-datasource\n'}]",4,116017,f72702694f42745aee774d40ac1137291157ebd9,67,11,4,12693,,,0,"MapR FS datasource

Change-Id: I28badef2ff345e56f914ea679b7d34871db8e9e4
Implements: blueprint maprfs-datasource
",git fetch https://review.opendev.org/openstack/sahara refs/changes/17/116017/4 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/validations/edp/base.py', 'sahara/service/validations/edp/data_source.py']",2,c619e706656658dcbb7d3fd76bc4da7e48a0dd5f,bp/maprfs-datasource," if ""maprfs"" == data[""type""]: _check_maprfs_data_source_create(data) def _check_maprfs_data_source_create(data): if len(data['url']) == 0: raise ex.InvalidException(""MapR FS url must not be empty"") url = urlparse.urlparse(data['url']) if url.scheme: if url.scheme != ""maprfs"": raise ex.InvalidException(""URL scheme must be 'maprfs'"")",,13,1
openstack%2Fha-guide~master~I87ab93220d7d97ab0bc3ee41a5f5468fad0d8fe9,openstack/ha-guide,master,I87ab93220d7d97ab0bc3ee41a5f5468fad0d8fe9,Updated from openstack-manuals,MERGED,2014-10-18 09:21:20.000000000,2014-10-20 06:52:05.000000000,2014-10-20 06:52:04.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-18 09:21:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/03fa141a81b166b99cebe69a241fb31b342d1d7a', 'message': 'Updated from openstack-manuals\n\nChange-Id: I87ab93220d7d97ab0bc3ee41a5f5468fad0d8fe9\n'}, {'number': 2, 'created': '2014-10-20 06:38:01.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/c9ed0d4a1217fc057d769f83bf8feea425252f6a', 'message': 'Updated from openstack-manuals\n\nChange-Id: I87ab93220d7d97ab0bc3ee41a5f5468fad0d8fe9\n'}]",0,129425,c9ed0d4a1217fc057d769f83bf8feea425252f6a,8,2,2,11131,,,0,"Updated from openstack-manuals

Change-Id: I87ab93220d7d97ab0bc3ee41a5f5468fad0d8fe9
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/25/129425/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,03fa141a81b166b99cebe69a241fb31b342d1d7a,openstack/openstack-manuals,"""POT-Creation-Date: 2014-10-17 12:39+0000\n"" ""PO-Revision-Date: 2014-10-17 12:36+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""#: ./doc/glossary/glossary-terms.xml4986(see)#: ./doc/glossary/glossary-terms.xml3298(secondary) #: ./doc/glossary/glossary-terms.xml3941(secondary) #: ./doc/glossary/glossary-terms.xml3993(secondary) #: ./doc/glossary/glossary-terms.xml4112(secondary) #: ./doc/glossary/glossary-terms.xml4329(secondary) #: ./doc/glossary/glossary-terms.xml4494(secondary) #: ./doc/glossary/glossary-terms.xml4512(secondary) #: ./doc/glossary/glossary-terms.xml5023(secondary) #: ./doc/glossary/glossary-terms.xml5371(secondary) #: ./doc/glossary/glossary-terms.xml5624(secondary) #: ./doc/glossary/glossary-terms.xml5740(secondary) #: ./doc/glossary/glossary-terms.xml6097(secondary) #: ./doc/glossary/glossary-terms.xml6282(secondary) #: ./doc/glossary/glossary-terms.xml6373(secondary) #: ./doc/glossary/glossary-terms.xml6945(secondary) #: ./doc/glossary/glossary-terms.xml7048(secondary) #: ./doc/glossary/glossary-terms.xml7092(secondary) #: ./doc/glossary/glossary-terms.xml7383(secondary) #: ./doc/glossary/glossary-terms.xml7426(secondary)#: ./doc/glossary/glossary-terms.xml3571(primary) #: ./doc/glossary/glossary-terms.xml8157(primary)#: ./doc/glossary/glossary-terms.xml6486(primary)#: ./doc/glossary/glossary-terms.xml6468(primary) #: ./doc/glossary/glossary-terms.xml6900(primary) #: ./doc/glossary/glossary-terms.xml7381(primary) #: ./doc/glossary/glossary-terms.xml7410(primary) #: ./doc/glossary/glossary-terms.xml8607(primary)#: ./doc/glossary/glossary-terms.xml6077(primary)#: ./doc/glossary/glossary-terms.xml6027(para) #: ./doc/glossary/glossary-terms.xml6856(para) #: ./doc/glossary/glossary-terms.xml7924(para)#: ./doc/glossary/glossary-terms.xml5706(secondary)#: ./doc/glossary/glossary-terms.xml5035(primary) #: ./doc/glossary/glossary-terms.xml5738(primary) #: ./doc/glossary/glossary-terms.xml5752(primary) #: ./doc/glossary/glossary-terms.xml5766(primary) #: ./doc/glossary/glossary-terms.xml5781(primary) #: ./doc/glossary/glossary-terms.xml5794(primary) #: ./doc/glossary/glossary-terms.xml5808(primary) #: ./doc/glossary/glossary-terms.xml5822(primary) #: ./doc/glossary/glossary-terms.xml5877(primary) #: ./doc/glossary/glossary-terms.xml7351(primary)#: ./doc/glossary/glossary-terms.xml3845(secondary) #: ./doc/glossary/glossary-terms.xml3975(secondary) #: ./doc/glossary/glossary-terms.xml4055(secondary) #: ./doc/glossary/glossary-terms.xml4070(secondary) #: ./doc/glossary/glossary-terms.xml5986(secondary) #: ./doc/glossary/glossary-terms.xml6821(secondary)#: ./doc/glossary/glossary-terms.xml5671(see)#: ./doc/glossary/glossary-terms.xml4909(para) #: ./doc/glossary/glossary-terms.xml8417(para) #: ./doc/glossary/glossary-terms.xml8650(para) #: ./doc/glossary/glossary-terms.xml8880(para) #: ./doc/glossary/glossary-terms.xml8981(para) #: ./doc/glossary/glossary-terms.xml9008(para)#: ./doc/glossary/glossary-terms.xml8302(primary)msgid ""federated identity"" msgstr """" #: ./doc/glossary/glossary-terms.xml3242(para) msgid """" ""A method to establish trusts between identity providers and the OpenStack "" ""cloud."" msgstr """" #: ./doc/glossary/glossary-terms.xml3248(glossterm) #: ./doc/glossary/glossary-terms.xml3250(primary)#: ./doc/glossary/glossary-terms.xml3254(para)#: ./doc/glossary/glossary-terms.xml3259(glossterm) #: ./doc/glossary/glossary-terms.xml3261(primary)#: ./doc/glossary/glossary-terms.xml3265(para)#: ./doc/glossary/glossary-terms.xml3271(glossterm) #: ./doc/glossary/glossary-terms.xml3273(primary)#: ./doc/glossary/glossary-terms.xml3277(para)#: ./doc/glossary/glossary-terms.xml3282(glossterm) #: ./doc/glossary/glossary-terms.xml3284(primary)#: ./doc/glossary/glossary-terms.xml3288(para)#: ./doc/glossary/glossary-terms.xml3294(glossterm)#: ./doc/glossary/glossary-terms.xml3296(primary) #: ./doc/glossary/glossary-terms.xml4284(primary)#: ./doc/glossary/glossary-terms.xml3302(para)#: ./doc/glossary/glossary-terms.xml3308(glossterm)#: ./doc/glossary/glossary-terms.xml3310(primary)#: ./doc/glossary/glossary-terms.xml3314(para)#: ./doc/glossary/glossary-terms.xml3321(glossterm) #: ./doc/glossary/glossary-terms.xml3323(primary)#: ./doc/glossary/glossary-terms.xml3327(para)#: ./doc/glossary/glossary-terms.xml3333(glossterm)#: ./doc/glossary/glossary-terms.xml3335(primary) #: ./doc/glossary/glossary-terms.xml3430(primary) #: ./doc/glossary/glossary-terms.xml4510(primary) #: ./doc/glossary/glossary-terms.xml6331(primary) #: ./doc/glossary/glossary-terms.xml6520(primary) #: ./doc/glossary/glossary-terms.xml7554(primary) #: ./doc/glossary/glossary-terms.xml7782(primary)#: ./doc/glossary/glossary-terms.xml3337(secondary)#: ./doc/glossary/glossary-terms.xml3340(primary)#: ./doc/glossary/glossary-terms.xml3344(para)#: ./doc/glossary/glossary-terms.xml3352(glossterm) #: ./doc/glossary/glossary-terms.xml3354(primary)#: ./doc/glossary/glossary-terms.xml3358(para)#: ./doc/glossary/glossary-terms.xml3365(glossterm) #: ./doc/glossary/glossary-terms.xml3367(primary)#: ./doc/glossary/glossary-terms.xml3371(para)#: ./doc/glossary/glossary-terms.xml3378(glossterm) #: ./doc/glossary/glossary-terms.xml3380(primary)#: ./doc/glossary/glossary-terms.xml3384(para)#: ./doc/glossary/glossary-terms.xml3393(glossterm) #: ./doc/glossary/glossary-terms.xml3395(primary)#: ./doc/glossary/glossary-terms.xml3399(para)#: ./doc/glossary/glossary-terms.xml3405(glossterm) #: ./doc/glossary/glossary-terms.xml3407(primary)#: ./doc/glossary/glossary-terms.xml3411(para)#: ./doc/glossary/glossary-terms.xml3416(glossterm) #: ./doc/glossary/glossary-terms.xml3418(primary)#: ./doc/glossary/glossary-terms.xml3422(para)#: ./doc/glossary/glossary-terms.xml3428(glossterm) #: ./doc/glossary/glossary-terms.xml3435(primary)#: ./doc/glossary/glossary-terms.xml3432(secondary)#: ./doc/glossary/glossary-terms.xml3439(para)#: ./doc/glossary/glossary-terms.xml3448(glossterm) #: ./doc/glossary/glossary-terms.xml3450(primary)#: ./doc/glossary/glossary-terms.xml3454(para)#: ./doc/glossary/glossary-terms.xml3459(para)#: ./doc/glossary/glossary-terms.xml3467(glossterm) #: ./doc/glossary/glossary-terms.xml3469(primary)#: ./doc/glossary/glossary-terms.xml3473(para)#: ./doc/glossary/glossary-terms.xml3479(glossterm)#: ./doc/glossary/glossary-terms.xml3481(primary)#: ./doc/glossary/glossary-terms.xml3485(para)#: ./doc/glossary/glossary-terms.xml3494(title)#: ./doc/glossary/glossary-terms.xml3497(glossterm) #: ./doc/glossary/glossary-terms.xml3499(primary)#: ./doc/glossary/glossary-terms.xml3503(para)#: ./doc/glossary/glossary-terms.xml3509(glossterm) #: ./doc/glossary/glossary-terms.xml3511(primary)#: ./doc/glossary/glossary-terms.xml3514(para)#: ./doc/glossary/glossary-terms.xml3521(glossterm) #: ./doc/glossary/glossary-terms.xml3523(primary)#: ./doc/glossary/glossary-terms.xml3526(para)#: ./doc/glossary/glossary-terms.xml3533(glossterm) #: ./doc/glossary/glossary-terms.xml3543(primary) #: ./doc/glossary/glossary-terms.xml3558(primary)#: ./doc/glossary/glossary-terms.xml3536(para)#: ./doc/glossary/glossary-terms.xml3541(glossterm) #: ./doc/glossary/glossary-terms.xml3545(secondary)#: ./doc/glossary/glossary-terms.xml3549(para)#: ./doc/glossary/glossary-terms.xml3556(glossterm) #: ./doc/glossary/glossary-terms.xml3560(secondary)#: ./doc/glossary/glossary-terms.xml3564(para)#: ./doc/glossary/glossary-terms.xml3569(glossterm) #: ./doc/glossary/glossary-terms.xml3573(secondary) #: ./doc/glossary/glossary-terms.xml3576(primary)#: ./doc/glossary/glossary-terms.xml3580(para)#: ./doc/glossary/glossary-terms.xml3586(glossterm) #: ./doc/glossary/glossary-terms.xml3588(primary)#: ./doc/glossary/glossary-terms.xml3592(para)#: ./doc/glossary/glossary-terms.xml3598(glossterm) #: ./doc/glossary/glossary-terms.xml3600(primary)#: ./doc/glossary/glossary-terms.xml3604(para)#: ./doc/glossary/glossary-terms.xml3611(glossterm) #: ./doc/glossary/glossary-terms.xml3613(primary)#: ./doc/glossary/glossary-terms.xml3617(para)#: ./doc/glossary/glossary-terms.xml3623(glossterm) #: ./doc/glossary/glossary-terms.xml3625(primary)#: ./doc/glossary/glossary-terms.xml3629(para)#: ./doc/glossary/glossary-terms.xml3635(glossterm) #: ./doc/glossary/glossary-terms.xml3637(primary)#: ./doc/glossary/glossary-terms.xml3641(para)#: ./doc/glossary/glossary-terms.xml3648(glossterm) #: ./doc/glossary/glossary-terms.xml3650(primary)#: ./doc/glossary/glossary-terms.xml3654(para)#: ./doc/glossary/glossary-terms.xml3662(glossterm) #: ./doc/glossary/glossary-terms.xml3664(primary)#: ./doc/glossary/glossary-terms.xml3668(para)#: ./doc/glossary/glossary-terms.xml3677(title)#: ./doc/glossary/glossary-terms.xml3680(glossterm) #: ./doc/glossary/glossary-terms.xml3682(primary)#: ./doc/glossary/glossary-terms.xml3686(para)#: ./doc/glossary/glossary-terms.xml3692(glossterm) #: ./doc/glossary/glossary-terms.xml3694(primary)#: ./doc/glossary/glossary-terms.xml3698(para)#: ./doc/glossary/glossary-terms.xml3704(glossterm) #: ./doc/glossary/glossary-terms.xml3706(primary)#: ./doc/glossary/glossary-terms.xml3710(para)#: ./doc/glossary/glossary-terms.xml3717(glossterm) #: ./doc/glossary/glossary-terms.xml3719(primary)#: ./doc/glossary/glossary-terms.xml3723(para)#: ./doc/glossary/glossary-terms.xml3730(glossterm) #: ./doc/glossary/glossary-terms.xml3732(primary)#: ./doc/glossary/glossary-terms.xml3736(para)#: ./doc/glossary/glossary-terms.xml3742(glossterm) #: ./doc/glossary/glossary-terms.xml3744(primary) #: ./doc/glossary/glossary-terms.xml7756(see)#: ./doc/glossary/glossary-terms.xml3748(para)#: ./doc/glossary/glossary-terms.xml3753(glossterm) #: ./doc/glossary/glossary-terms.xml3755(primary)#: ./doc/glossary/glossary-terms.xml3759(para)#: ./doc/glossary/glossary-terms.xml3769(glossterm) #: ./doc/glossary/glossary-terms.xml3771(primary)#: ./doc/glossary/glossary-terms.xml3775(para)#: ./doc/glossary/glossary-terms.xml3786(glossterm)#: ./doc/glossary/glossary-terms.xml3789(para)#: ./doc/glossary/glossary-terms.xml3795(glossterm)#: ./doc/glossary/glossary-terms.xml3797(primary)#: ./doc/glossary/glossary-terms.xml3801(para)#: ./doc/glossary/glossary-terms.xml3806(glossterm)#: ./doc/glossary/glossary-terms.xml3808(primary)#: ./doc/glossary/glossary-terms.xml3812(para)#: ./doc/glossary/glossary-terms.xml3817(glossterm) #: ./doc/glossary/glossary-terms.xml3819(primary)#: ./doc/glossary/glossary-terms.xml3823(para)#: ./doc/glossary/glossary-terms.xml3829(glossterm) #: ./doc/glossary/glossary-terms.xml3831(primary)#: ./doc/glossary/glossary-terms.xml3835(para)#: ./doc/glossary/glossary-terms.xml3841(glossterm)#: ./doc/glossary/glossary-terms.xml3843(primary)#: ./doc/glossary/glossary-terms.xml3849(para)#: ./doc/glossary/glossary-terms.xml3859(glossterm)#: ./doc/glossary/glossary-terms.xml3861(primary)#: ./doc/glossary/glossary-terms.xml3865(para)#: ./doc/glossary/glossary-terms.xml3876(glossterm) #: ./doc/glossary/glossary-terms.xml3878(primary)#: ./doc/glossary/glossary-terms.xml3882(para)#: ./doc/glossary/glossary-terms.xml3894(glossterm) #: ./doc/glossary/glossary-terms.xml3896(primary)#: ./doc/glossary/glossary-terms.xml3900(para)#: ./doc/glossary/glossary-terms.xml3905(glossterm) #: ./doc/glossary/glossary-terms.xml3907(primary)#: ./doc/glossary/glossary-terms.xml3911(para)#: ./doc/glossary/glossary-terms.xml3918(glossterm)#: ./doc/glossary/glossary-terms.xml3921(para)#: ./doc/glossary/glossary-terms.xml3927(glossterm)#: ./doc/glossary/glossary-terms.xml3930(para)#: ./doc/glossary/glossary-terms.xml3937(glossterm)#: ./doc/glossary/glossary-terms.xml3939(primary) #: ./doc/glossary/glossary-terms.xml3953(primary)#: ./doc/glossary/glossary-terms.xml3945(para)#: ./doc/glossary/glossary-terms.xml3951(glossterm)#: ./doc/glossary/glossary-terms.xml3955(secondary)#: ./doc/glossary/glossary-terms.xml3959(para)#: ./doc/glossary/glossary-terms.xml3968(title)#: ./doc/glossary/glossary-terms.xml3971(glossterm)#: ./doc/glossary/glossary-terms.xml3973(primary)#: ./doc/glossary/glossary-terms.xml3979(para)#: ./doc/glossary/glossary-terms.xml3989(glossterm) #: ./doc/glossary/glossary-terms.xml3991(primary)#: ./doc/glossary/glossary-terms.xml3997(para)#: ./doc/glossary/glossary-terms.xml4004(glossterm)#: ./doc/glossary/glossary-terms.xml4006(primary)#: ./doc/glossary/glossary-terms.xml4010(para)#: ./doc/glossary/glossary-terms.xml4018(glossterm) #: ./doc/glossary/glossary-terms.xml4020(primary)#: ./doc/glossary/glossary-terms.xml4024(para)#: ./doc/glossary/glossary-terms.xml4030(glossterm)#: ./doc/glossary/glossary-terms.xml4033(para)#: ./doc/glossary/glossary-terms.xml4038(glossterm) #: ./doc/glossary/glossary-terms.xml4042(secondary)#: ./doc/glossary/glossary-terms.xml4040(primary) #: ./doc/glossary/glossary-terms.xml4066(glossterm) #: ./doc/glossary/glossary-terms.xml4068(primary) #: ./doc/glossary/glossary-terms.xml4085(primary) #: ./doc/glossary/glossary-terms.xml4156(primary)#: ./doc/glossary/glossary-terms.xml4046(para)#: ./doc/glossary/glossary-terms.xml4052(glossterm) #: ./doc/glossary/glossary-terms.xml4054(primary) msgid ""identity provider"" msgstr """" #: ./doc/glossary/glossary-terms.xml4059(para) msgid """" ""A directory service, which allows users to login with a user name and "" ""password. It is a typical source of authentication tokens."" msgstr """" #: ./doc/glossary/glossary-terms.xml4074(para)#: ./doc/glossary/glossary-terms.xml4083(glossterm) #: ./doc/glossary/glossary-terms.xml4087(secondary)#: ./doc/glossary/glossary-terms.xml4091(para)#: ./doc/glossary/glossary-terms.xml4097(glossterm)#: ./doc/glossary/glossary-terms.xml4099(primary)#: ./doc/glossary/glossary-terms.xml4103(para)#: ./doc/glossary/glossary-terms.xml4108(glossterm)#: ./doc/glossary/glossary-terms.xml4110(primary)#: ./doc/glossary/glossary-terms.xml4116(para)#: ./doc/glossary/glossary-terms.xml4125(glossterm)#: ./doc/glossary/glossary-terms.xml4127(primary) #: ./doc/glossary/glossary-terms.xml4141(primary) #: ./doc/glossary/glossary-terms.xml4170(primary) #: ./doc/glossary/glossary-terms.xml4184(primary) #: ./doc/glossary/glossary-terms.xml4198(primary) #: ./doc/glossary/glossary-terms.xml4210(glossterm) #: ./doc/glossary/glossary-terms.xml4230(primary) #: ./doc/glossary/glossary-terms.xml4244(primary) #: ./doc/glossary/glossary-terms.xml4258(primary) #: ./doc/glossary/glossary-terms.xml6503(primary)#: ./doc/glossary/glossary-terms.xml4129(secondary) #: ./doc/glossary/glossary-terms.xml4220(glossterm)#: ./doc/glossary/glossary-terms.xml4133(para)#: ./doc/glossary/glossary-terms.xml4139(glossterm) #: ./doc/glossary/glossary-terms.xml4143(secondary)#: ./doc/glossary/glossary-terms.xml4147(para)#: ./doc/glossary/glossary-terms.xml4154(glossterm) #: ./doc/glossary/glossary-terms.xml4158(secondary)#: ./doc/glossary/glossary-terms.xml4162(para)#: ./doc/glossary/glossary-terms.xml4168(glossterm) #: ./doc/glossary/glossary-terms.xml4172(secondary)#: ./doc/glossary/glossary-terms.xml4176(para) #: ./doc/glossary/glossary-terms.xml5121(para)#: ./doc/glossary/glossary-terms.xml4182(glossterm) #: ./doc/glossary/glossary-terms.xml4186(secondary)#: ./doc/glossary/glossary-terms.xml4190(para)#: ./doc/glossary/glossary-terms.xml4196(glossterm) #: ./doc/glossary/glossary-terms.xml4200(secondary)#: ./doc/glossary/glossary-terms.xml4204(para)#: ./doc/glossary/glossary-terms.xml4213(para)#: ./doc/glossary/glossary-terms.xml4223(para)#: ./doc/glossary/glossary-terms.xml4228(glossterm) #: ./doc/glossary/glossary-terms.xml4232(secondary)#: ./doc/glossary/glossary-terms.xml4236(para)#: ./doc/glossary/glossary-terms.xml4242(glossterm) #: ./doc/glossary/glossary-terms.xml4246(secondary)#: ./doc/glossary/glossary-terms.xml4250(para)#: ./doc/glossary/glossary-terms.xml4256(glossterm) #: ./doc/glossary/glossary-terms.xml4260(secondary)#: ./doc/glossary/glossary-terms.xml4264(para)#: ./doc/glossary/glossary-terms.xml4270(glossterm)#: ./doc/glossary/glossary-terms.xml4272(primary)#: ./doc/glossary/glossary-terms.xml4276(para)#: ./doc/glossary/glossary-terms.xml4282(glossterm) #: ./doc/glossary/glossary-terms.xml4286(secondary) #: ./doc/glossary/glossary-terms.xml4289(primary)#: ./doc/glossary/glossary-terms.xml4293(para)#: ./doc/glossary/glossary-terms.xml4299(glossterm) #: ./doc/glossary/glossary-terms.xml4301(primary)#: ./doc/glossary/glossary-terms.xml4304(para)#: ./doc/glossary/glossary-terms.xml4313(glossterm) #: ./doc/glossary/glossary-terms.xml4315(primary)#: ./doc/glossary/glossary-terms.xml4319(para)#: ./doc/glossary/glossary-terms.xml4325(glossterm)#: ./doc/glossary/glossary-terms.xml4327(primary) #: ./doc/glossary/glossary-terms.xml4341(primary) #: ./doc/glossary/glossary-terms.xml4354(primary) #: ./doc/glossary/glossary-terms.xml4378(primary) #: ./doc/glossary/glossary-terms.xml4393(primary) #: ./doc/glossary/glossary-terms.xml4406(primary)#: ./doc/glossary/glossary-terms.xml4333(para)#: ./doc/glossary/glossary-terms.xml4339(glossterm) #: ./doc/glossary/glossary-terms.xml4343(secondary)#: ./doc/glossary/glossary-terms.xml4347(para)#: ./doc/glossary/glossary-terms.xml4352(glossterm) #: ./doc/glossary/glossary-terms.xml4356(secondary)#: ./doc/glossary/glossary-terms.xml4360(para)#: ./doc/glossary/glossary-terms.xml4365(glossterm) #: ./doc/glossary/glossary-terms.xml4367(primary)#: ./doc/glossary/glossary-terms.xml4370(para)#: ./doc/glossary/glossary-terms.xml4376(glossterm) #: ./doc/glossary/glossary-terms.xml4380(secondary)#: ./doc/glossary/glossary-terms.xml4384(para)#: ./doc/glossary/glossary-terms.xml4391(glossterm) #: ./doc/glossary/glossary-terms.xml4395(secondary)#: ./doc/glossary/glossary-terms.xml4399(para)#: ./doc/glossary/glossary-terms.xml4404(glossterm) #: ./doc/glossary/glossary-terms.xml4408(secondary)#: ./doc/glossary/glossary-terms.xml4412(para) #: ./doc/glossary/glossary-terms.xml7416(para)#: ./doc/glossary/glossary-terms.xml4418(glossterm) #: ./doc/glossary/glossary-terms.xml4420(primary)#: ./doc/glossary/glossary-terms.xml4424(para)#: ./doc/glossary/glossary-terms.xml4430(glossterm) #: ./doc/glossary/glossary-terms.xml4432(primary)#: ./doc/glossary/glossary-terms.xml4436(para)#: ./doc/glossary/glossary-terms.xml4442(glossterm) #: ./doc/glossary/glossary-terms.xml4444(primary)#: ./doc/glossary/glossary-terms.xml4448(para)#: ./doc/glossary/glossary-terms.xml4454(glossterm) #: ./doc/glossary/glossary-terms.xml4456(primary)#: ./doc/glossary/glossary-terms.xml4460(para)#: ./doc/glossary/glossary-terms.xml4466(glossterm) #: ./doc/glossary/glossary-terms.xml4468(primary)#: ./doc/glossary/glossary-terms.xml4472(para)#: ./doc/glossary/glossary-terms.xml4478(glossterm) #: ./doc/glossary/glossary-terms.xml4480(primary)#: ./doc/glossary/glossary-terms.xml4484(para)#: ./doc/glossary/glossary-terms.xml4490(glossterm) #: ./doc/glossary/glossary-terms.xml4492(primary)#: ./doc/glossary/glossary-terms.xml4498(para)#: ./doc/glossary/glossary-terms.xml4508(glossterm)#: ./doc/glossary/glossary-terms.xml4516(para)#: ./doc/glossary/glossary-terms.xml4523(glossterm) #: ./doc/glossary/glossary-terms.xml4525(primary)#: ./doc/glossary/glossary-terms.xml4529(para)#: ./doc/glossary/glossary-terms.xml4536(glossterm)#: ./doc/glossary/glossary-terms.xml4538(primary)#: ./doc/glossary/glossary-terms.xml4542(para)#: ./doc/glossary/glossary-terms.xml4547(glossterm)#: ./doc/glossary/glossary-terms.xml4549(primary)#: ./doc/glossary/glossary-terms.xml4553(para)#: ./doc/glossary/glossary-terms.xml4564(glossterm) #: ./doc/glossary/glossary-terms.xml4566(primary)#: ./doc/glossary/glossary-terms.xml4570(para)#: ./doc/glossary/glossary-terms.xml4578(glossterm) #: ./doc/glossary/glossary-terms.xml4580(primary)#: ./doc/glossary/glossary-terms.xml4584(para)#: ./doc/glossary/glossary-terms.xml4592(glossterm) #: ./doc/glossary/glossary-terms.xml4594(primary)#: ./doc/glossary/glossary-terms.xml4598(para)#: ./doc/glossary/glossary-terms.xml4609(glossterm)#: ./doc/glossary/glossary-terms.xml4611(primary)#: ./doc/glossary/glossary-terms.xml4615(para)#: ./doc/glossary/glossary-terms.xml4621(glossterm)#: ./doc/glossary/glossary-terms.xml4623(primary)#: ./doc/glossary/glossary-terms.xml4627(para) #: ./doc/glossary/glossary-terms.xml6601(para) #: ./doc/glossary/glossary-terms.xml8474(para) #: ./doc/glossary/glossary-terms.xml8486(para) #: ./doc/glossary/glossary-terms.xml8694(para)#: ./doc/glossary/glossary-terms.xml4633(glossterm) #: ./doc/glossary/glossary-terms.xml4635(primary)#: ./doc/glossary/glossary-terms.xml4639(para)#: ./doc/glossary/glossary-terms.xml4648(title)#: ./doc/glossary/glossary-terms.xml4651(glossterm) #: ./doc/glossary/glossary-terms.xml4653(primary)#: ./doc/glossary/glossary-terms.xml4657(para)#: ./doc/glossary/glossary-terms.xml4663(glossterm) #: ./doc/glossary/glossary-terms.xml4665(primary)#: ./doc/glossary/glossary-terms.xml4669(para)#: ./doc/glossary/glossary-terms.xml4674(glossterm) #: ./doc/glossary/glossary-terms.xml4676(primary)#: ./doc/glossary/glossary-terms.xml4680(para)#: ./doc/glossary/glossary-terms.xml4685(glossterm) #: ./doc/glossary/glossary-terms.xml4687(primary)#: ./doc/glossary/glossary-terms.xml4691(para)#: ./doc/glossary/glossary-terms.xml4697(glossterm) #: ./doc/glossary/glossary-terms.xml4699(primary)#: ./doc/glossary/glossary-terms.xml4703(para)#: ./doc/glossary/glossary-terms.xml4709(glossterm) #: ./doc/glossary/glossary-terms.xml4711(primary)#: ./doc/glossary/glossary-terms.xml4715(para)#: ./doc/glossary/glossary-terms.xml4725(title)#: ./doc/glossary/glossary-terms.xml4728(glossterm)#: ./doc/glossary/glossary-terms.xml4730(primary)#: ./doc/glossary/glossary-terms.xml4734(para)#: ./doc/glossary/glossary-terms.xml4746(glossterm) #: ./doc/glossary/glossary-terms.xml4748(primary)#: ./doc/glossary/glossary-terms.xml4752(para)#: ./doc/glossary/glossary-terms.xml4757(glossterm) #: ./doc/glossary/glossary-terms.xml4759(primary)#: ./doc/glossary/glossary-terms.xml4763(para)#: ./doc/glossary/glossary-terms.xml4769(glossterm) #: ./doc/glossary/glossary-terms.xml4771(primary)#: ./doc/glossary/glossary-terms.xml4775(para)#: ./doc/glossary/glossary-terms.xml4788(title)#: ./doc/glossary/glossary-terms.xml4791(glossterm) #: ./doc/glossary/glossary-terms.xml4793(primary)#: ./doc/glossary/glossary-terms.xml4797(para)#: ./doc/glossary/glossary-terms.xml4802(glossterm) #: ./doc/glossary/glossary-terms.xml4804(primary)#: ./doc/glossary/glossary-terms.xml4808(para)#: ./doc/glossary/glossary-terms.xml4813(glossterm) #: ./doc/glossary/glossary-terms.xml4815(primary)#: ./doc/glossary/glossary-terms.xml4819(para)#: ./doc/glossary/glossary-terms.xml4829(glossterm) #: ./doc/glossary/glossary-terms.xml4831(primary)#: ./doc/glossary/glossary-terms.xml4835(para)#: ./doc/glossary/glossary-terms.xml4844(glossterm) #: ./doc/glossary/glossary-terms.xml4846(primary)#: ./doc/glossary/glossary-terms.xml4850(para)#: ./doc/glossary/glossary-terms.xml4856(glossterm) #: ./doc/glossary/glossary-terms.xml4858(primary)#: ./doc/glossary/glossary-terms.xml4862(para)#: ./doc/glossary/glossary-terms.xml4868(glossterm) #: ./doc/glossary/glossary-terms.xml4870(primary)#: ./doc/glossary/glossary-terms.xml4874(para)#: ./doc/glossary/glossary-terms.xml4880(glossterm)#: ./doc/glossary/glossary-terms.xml4883(para)#: ./doc/glossary/glossary-terms.xml4889(glossterm)#: ./doc/glossary/glossary-terms.xml4891(primary)#: ./doc/glossary/glossary-terms.xml4893(secondary) #: ./doc/glossary/glossary-terms.xml5961(secondary)#: ./doc/glossary/glossary-terms.xml4897(para)#: ./doc/glossary/glossary-terms.xml4903(glossterm) #: ./doc/glossary/glossary-terms.xml4905(primary)#: ./doc/glossary/glossary-terms.xml4914(glossterm) #: ./doc/glossary/glossary-terms.xml4916(primary)#: ./doc/glossary/glossary-terms.xml4920(para)#: ./doc/glossary/glossary-terms.xml4927(glossterm)#: ./doc/glossary/glossary-terms.xml4930(para)#: ./doc/glossary/glossary-terms.xml4938(glossterm) #: ./doc/glossary/glossary-terms.xml4940(primary)#: ./doc/glossary/glossary-terms.xml4944(para)#: ./doc/glossary/glossary-terms.xml4950(glossterm) #: ./doc/glossary/glossary-terms.xml4953(primary)#: ./doc/glossary/glossary-terms.xml4957(para)#: ./doc/glossary/glossary-terms.xml4963(glossterm) #: ./doc/glossary/glossary-terms.xml4965(primary)#: ./doc/glossary/glossary-terms.xml4969(para)#: ./doc/glossary/glossary-terms.xml4979(title)#: ./doc/glossary/glossary-terms.xml4982(glossterm) #: ./doc/glossary/glossary-terms.xml4984(primary)#: ./doc/glossary/glossary-terms.xml4990(para)#: ./doc/glossary/glossary-terms.xml4995(glossterm) #: ./doc/glossary/glossary-terms.xml4997(primary)#: ./doc/glossary/glossary-terms.xml5001(para)#: ./doc/glossary/glossary-terms.xml5007(glossterm) #: ./doc/glossary/glossary-terms.xml5009(primary)#: ./doc/glossary/glossary-terms.xml5013(para)#: ./doc/glossary/glossary-terms.xml5019(glossterm)#: ./doc/glossary/glossary-terms.xml5021(primary) #: ./doc/glossary/glossary-terms.xml5040(primary)#: ./doc/glossary/glossary-terms.xml5027(para)#: ./doc/glossary/glossary-terms.xml5033(glossterm)#: ./doc/glossary/glossary-terms.xml5037(secondary) #: ./doc/glossary/glossary-terms.xml5042(secondary)#: ./doc/glossary/glossary-terms.xml5046(para)#: ./doc/glossary/glossary-terms.xml5052(glossterm) #: ./doc/glossary/glossary-terms.xml5054(primary)#: ./doc/glossary/glossary-terms.xml5058(para)#: ./doc/glossary/glossary-terms.xml5064(glossterm) #: ./doc/glossary/glossary-terms.xml5066(primary)#: ./doc/glossary/glossary-terms.xml5070(para)#: ./doc/glossary/glossary-terms.xml5076(glossterm) #: ./doc/glossary/glossary-terms.xml5078(primary)#: ./doc/glossary/glossary-terms.xml5082(para)#: ./doc/glossary/glossary-terms.xml5091(glossterm) #: ./doc/glossary/glossary-terms.xml5093(primary)#: ./doc/glossary/glossary-terms.xml5097(para)#: ./doc/glossary/glossary-terms.xml5103(glossterm) #: ./doc/glossary/glossary-terms.xml5105(primary)#: ./doc/glossary/glossary-terms.xml5109(para)#: ./doc/glossary/glossary-terms.xml5115(glossterm)#: ./doc/glossary/glossary-terms.xml5117(primary)#: ./doc/glossary/glossary-terms.xml5127(glossterm) #: ./doc/glossary/glossary-terms.xml5129(primary)#: ./doc/glossary/glossary-terms.xml5133(para)#: ./doc/glossary/glossary-terms.xml5139(glossterm) #: ./doc/glossary/glossary-terms.xml5141(primary)#: ./doc/glossary/glossary-terms.xml5145(para)#: ./doc/glossary/glossary-terms.xml5153(glossterm)#: ./doc/glossary/glossary-terms.xml5155(primary)#: ./doc/glossary/glossary-terms.xml5159(para)#: ./doc/glossary/glossary-terms.xml5165(glossterm) #: ./doc/glossary/glossary-terms.xml5167(primary)#: ./doc/glossary/glossary-terms.xml5171(para)#: ./doc/glossary/glossary-terms.xml5177(glossterm) #: ./doc/glossary/glossary-terms.xml5179(primary)#: ./doc/glossary/glossary-terms.xml5183(para)#: ./doc/glossary/glossary-terms.xml5189(glossterm) #: ./doc/glossary/glossary-terms.xml5191(primary)#: ./doc/glossary/glossary-terms.xml5195(para)#: ./doc/glossary/glossary-terms.xml5201(glossterm) #: ./doc/glossary/glossary-terms.xml5203(primary)#: ./doc/glossary/glossary-terms.xml5207(para)#: ./doc/glossary/glossary-terms.xml5212(glossterm) #: ./doc/glossary/glossary-terms.xml5214(primary)#: ./doc/glossary/glossary-terms.xml5218(para)#: ./doc/glossary/glossary-terms.xml5224(glossterm) #: ./doc/glossary/glossary-terms.xml5226(primary)#: ./doc/glossary/glossary-terms.xml5230(para)#: ./doc/glossary/glossary-terms.xml5238(glossterm)#: ./doc/glossary/glossary-terms.xml5241(para)#: ./doc/glossary/glossary-terms.xml5247(glossterm) #: ./doc/glossary/glossary-terms.xml5250(primary)#: ./doc/glossary/glossary-terms.xml5254(para)#: ./doc/glossary/glossary-terms.xml5260(glossterm) #: ./doc/glossary/glossary-terms.xml5262(primary)#: ./doc/glossary/glossary-terms.xml5266(para)#: ./doc/glossary/glossary-terms.xml5272(glossterm) #: ./doc/glossary/glossary-terms.xml5274(primary)#: ./doc/glossary/glossary-terms.xml5278(para)#: ./doc/glossary/glossary-terms.xml5284(glossterm) #: ./doc/glossary/glossary-terms.xml5286(primary)#: ./doc/glossary/glossary-terms.xml5290(para)#: ./doc/glossary/glossary-terms.xml5297(glossterm) #: ./doc/glossary/glossary-terms.xml5299(primary)#: ./doc/glossary/glossary-terms.xml5303(para)#: ./doc/glossary/glossary-terms.xml5312(title)#: ./doc/glossary/glossary-terms.xml5315(glossterm) #: ./doc/glossary/glossary-terms.xml5317(primary)#: ./doc/glossary/glossary-terms.xml5321(para)#: ./doc/glossary/glossary-terms.xml5329(glossterm) #: ./doc/glossary/glossary-terms.xml5331(primary)#: ./doc/glossary/glossary-terms.xml5335(para)#: ./doc/glossary/glossary-terms.xml5341(glossterm) #: ./doc/glossary/glossary-terms.xml5343(primary)#: ./doc/glossary/glossary-terms.xml5347(para)#: ./doc/glossary/glossary-terms.xml5354(glossterm) #: ./doc/glossary/glossary-terms.xml5356(primary)#: ./doc/glossary/glossary-terms.xml5360(para)#: ./doc/glossary/glossary-terms.xml5367(glossterm)#: ./doc/glossary/glossary-terms.xml5369(primary) #: ./doc/glossary/glossary-terms.xml5385(primary) #: ./doc/glossary/glossary-terms.xml5399(primary) #: ./doc/glossary/glossary-terms.xml5414(primary) #: ./doc/glossary/glossary-terms.xml5428(primary) #: ./doc/glossary/glossary-terms.xml5442(primary) #: ./doc/glossary/glossary-terms.xml5456(primary) #: ./doc/glossary/glossary-terms.xml5469(primary) #: ./doc/glossary/glossary-terms.xml5483(primary) #: ./doc/glossary/glossary-terms.xml5497(primary) #: ./doc/glossary/glossary-terms.xml5511(primary) #: ./doc/glossary/glossary-terms.xml6348(primary) #: ./doc/glossary/glossary-terms.xml6548(primary) #: ./doc/glossary/glossary-terms.xml8521(primary) #: ./doc/glossary/glossary-terms.xml8669(primary)#: ./doc/glossary/glossary-terms.xml5375(para)#: ./doc/glossary/glossary-terms.xml5383(glossterm) #: ./doc/glossary/glossary-terms.xml5387(secondary)#: ./doc/glossary/glossary-terms.xml5391(para)#: ./doc/glossary/glossary-terms.xml5397(glossterm)#: ./doc/glossary/glossary-terms.xml5401(secondary)#: ./doc/glossary/glossary-terms.xml5405(para)#: ./doc/glossary/glossary-terms.xml5412(glossterm) #: ./doc/glossary/glossary-terms.xml5416(secondary)#: ./doc/glossary/glossary-terms.xml5420(para)#: ./doc/glossary/glossary-terms.xml5426(glossterm)#: ./doc/glossary/glossary-terms.xml5430(secondary)#: ./doc/glossary/glossary-terms.xml5434(para)#: ./doc/glossary/glossary-terms.xml5440(glossterm)#: ./doc/glossary/glossary-terms.xml5444(secondary)#: ./doc/glossary/glossary-terms.xml5448(para)#: ./doc/glossary/glossary-terms.xml5454(glossterm)#: ./doc/glossary/glossary-terms.xml5458(secondary)#: ./doc/glossary/glossary-terms.xml5462(para)#: ./doc/glossary/glossary-terms.xml5467(glossterm)#: ./doc/glossary/glossary-terms.xml5471(secondary)#: ./doc/glossary/glossary-terms.xml5475(para)#: ./doc/glossary/glossary-terms.xml5481(glossterm) #: ./doc/glossary/glossary-terms.xml5485(secondary)#: ./doc/glossary/glossary-terms.xml5489(para)#: ./doc/glossary/glossary-terms.xml5495(glossterm) #: ./doc/glossary/glossary-terms.xml5499(secondary)#: ./doc/glossary/glossary-terms.xml5503(para)#: ./doc/glossary/glossary-terms.xml5509(glossterm)#: ./doc/glossary/glossary-terms.xml5513(secondary)#: ./doc/glossary/glossary-terms.xml5517(para)#: ./doc/glossary/glossary-terms.xml5524(glossterm)#: ./doc/glossary/glossary-terms.xml5527(para)#: ./doc/glossary/glossary-terms.xml5534(glossterm) #: ./doc/glossary/glossary-terms.xml5536(primary) #: ./doc/glossary/glossary-terms.xml5559(secondary)#: ./doc/glossary/glossary-terms.xml5540(para)#: ./doc/glossary/glossary-terms.xml5546(glossterm) #: ./doc/glossary/glossary-terms.xml5557(primary) #: ./doc/glossary/glossary-terms.xml5570(primary) #: ./doc/glossary/glossary-terms.xml5584(primary)#: ./doc/glossary/glossary-terms.xml5549(para)#: ./doc/glossary/glossary-terms.xml5555(glossterm)#: ./doc/glossary/glossary-terms.xml5563(para)#: ./doc/glossary/glossary-terms.xml5568(glossterm) #: ./doc/glossary/glossary-terms.xml5572(secondary)#: ./doc/glossary/glossary-terms.xml5576(para)#: ./doc/glossary/glossary-terms.xml5582(glossterm) #: ./doc/glossary/glossary-terms.xml5586(secondary)#: ./doc/glossary/glossary-terms.xml5590(para)#: ./doc/glossary/glossary-terms.xml5597(glossterm) #: ./doc/glossary/glossary-terms.xml5599(primary)#: ./doc/glossary/glossary-terms.xml5603(para)#: ./doc/glossary/glossary-terms.xml5608(glossterm) #: ./doc/glossary/glossary-terms.xml5610(primary)#: ./doc/glossary/glossary-terms.xml5614(para)#: ./doc/glossary/glossary-terms.xml5620(glossterm)#: ./doc/glossary/glossary-terms.xml5622(primary) #: ./doc/glossary/glossary-terms.xml6452(primary) #: ./doc/glossary/glossary-terms.xml7822(primary) #: ./doc/glossary/glossary-terms.xml8022(primary)#: ./doc/glossary/glossary-terms.xml5628(para)#: ./doc/glossary/glossary-terms.xml5633(glossterm)#: ./doc/glossary/glossary-terms.xml5635(primary) #: ./doc/glossary/glossary-terms.xml5652(primary) #: ./doc/glossary/glossary-terms.xml6174(primary) #: ./doc/glossary/glossary-terms.xml8285(primary)#: ./doc/glossary/glossary-terms.xml5637(secondary) #: ./doc/glossary/glossary-terms.xml5640(primary) #: ./doc/glossary/glossary-terms.xml8265(see)#: ./doc/glossary/glossary-terms.xml5644(para)#: ./doc/glossary/glossary-terms.xml5650(glossterm) #: ./doc/glossary/glossary-terms.xml5657(primary)#: ./doc/glossary/glossary-terms.xml5654(secondary)#: ./doc/glossary/glossary-terms.xml5661(para)#: ./doc/glossary/glossary-terms.xml5667(glossterm) #: ./doc/glossary/glossary-terms.xml5669(primary)#: ./doc/glossary/glossary-terms.xml5675(para)#: ./doc/glossary/glossary-terms.xml5680(glossterm) #: ./doc/glossary/glossary-terms.xml5682(primary)#: ./doc/glossary/glossary-terms.xml5686(para)#: ./doc/glossary/glossary-terms.xml5694(glossterm) #: ./doc/glossary/glossary-terms.xml5704(primary) #: ./doc/glossary/glossary-terms.xml5717(primary)#: ./doc/glossary/glossary-terms.xml5697(para)#: ./doc/glossary/glossary-terms.xml5702(glossterm)#: ./doc/glossary/glossary-terms.xml5710(para)#: ./doc/glossary/glossary-terms.xml5715(glossterm) #: ./doc/glossary/glossary-terms.xml5719(secondary)#: ./doc/glossary/glossary-terms.xml5723(para)#: ./doc/glossary/glossary-terms.xml5733(title)#: ./doc/glossary/glossary-terms.xml5736(glossterm)#: ./doc/glossary/glossary-terms.xml5744(para)#: ./doc/glossary/glossary-terms.xml5750(glossterm)#: ./doc/glossary/glossary-terms.xml5754(secondary)#: ./doc/glossary/glossary-terms.xml5758(para)#: ./doc/glossary/glossary-terms.xml5764(glossterm) #: ./doc/glossary/glossary-terms.xml5768(secondary)#: ./doc/glossary/glossary-terms.xml5772(para)#: ./doc/glossary/glossary-terms.xml5779(glossterm) #: ./doc/glossary/glossary-terms.xml5783(secondary)#: ./doc/glossary/glossary-terms.xml5787(para)#: ./doc/glossary/glossary-terms.xml5792(glossterm) #: ./doc/glossary/glossary-terms.xml5796(secondary)#: ./doc/glossary/glossary-terms.xml5800(para)#: ./doc/glossary/glossary-terms.xml5806(glossterm)#: ./doc/glossary/glossary-terms.xml5810(secondary)#: ./doc/glossary/glossary-terms.xml5814(para)#: ./doc/glossary/glossary-terms.xml5820(glossterm)#: ./doc/glossary/glossary-terms.xml5824(secondary)#: ./doc/glossary/glossary-terms.xml5828(para)#: ./doc/glossary/glossary-terms.xml5834(glossterm) #: ./doc/glossary/glossary-terms.xml5851(primary) #: ./doc/glossary/glossary-terms.xml5864(primary)#: ./doc/glossary/glossary-terms.xml5837(para)#: ./doc/glossary/glossary-terms.xml5844(glossterm) #: ./doc/glossary/glossary-terms.xml5848(secondary) #: ./doc/glossary/glossary-terms.xml5853(secondary)#: ./doc/glossary/glossary-terms.xml5846(primary) #: ./doc/glossary/glossary-terms.xml7966(glossterm) #: ./doc/glossary/glossary-terms.xml7989(primary) #: ./doc/glossary/glossary-terms.xml8003(primary) #: ./doc/glossary/glossary-terms.xml8027(primary)#: ./doc/glossary/glossary-terms.xml5857(para)#: ./doc/glossary/glossary-terms.xml5862(glossterm) #: ./doc/glossary/glossary-terms.xml5866(secondary)#: ./doc/glossary/glossary-terms.xml5870(para)#: ./doc/glossary/glossary-terms.xml5875(glossterm) #: ./doc/glossary/glossary-terms.xml5879(secondary)#: ./doc/glossary/glossary-terms.xml5883(para)#: ./doc/glossary/glossary-terms.xml5889(glossterm) #: ./doc/glossary/glossary-terms.xml5891(primary)#: ./doc/glossary/glossary-terms.xml5895(para)#: ./doc/glossary/glossary-terms.xml5901(glossterm) #: ./doc/glossary/glossary-terms.xml5904(primary)#: ./doc/glossary/glossary-terms.xml5908(para)#: ./doc/glossary/glossary-terms.xml5914(glossterm) #: ./doc/glossary/glossary-terms.xml5916(primary)#: ./doc/glossary/glossary-terms.xml5920(para)#: ./doc/glossary/glossary-terms.xml5925(glossterm) #: ./doc/glossary/glossary-terms.xml5927(primary) #: ./doc/glossary/glossary-terms.xml5959(primary)#: ./doc/glossary/glossary-terms.xml5931(para)#: ./doc/glossary/glossary-terms.xml5943(glossterm) #: ./doc/glossary/glossary-terms.xml5945(primary)#: ./doc/glossary/glossary-terms.xml5949(para)#: ./doc/glossary/glossary-terms.xml5957(glossterm)#: ./doc/glossary/glossary-terms.xml5965(para)#: ./doc/glossary/glossary-terms.xml5970(glossterm) #: ./doc/glossary/glossary-terms.xml5972(primary)#: ./doc/glossary/glossary-terms.xml5976(para)#: ./doc/glossary/glossary-terms.xml5982(glossterm) #: ./doc/glossary/glossary-terms.xml5984(primary) #: ./doc/glossary/glossary-terms.xml6002(primary)#: ./doc/glossary/glossary-terms.xml5990(para)#: ./doc/glossary/glossary-terms.xml6000(glossterm)#: ./doc/glossary/glossary-terms.xml6003(secondary)#: ./doc/glossary/glossary-terms.xml6007(para)#: ./doc/glossary/glossary-terms.xml6021(glossterm) #: ./doc/glossary/glossary-terms.xml6023(primary)#: ./doc/glossary/glossary-terms.xml6032(glossterm) #: ./doc/glossary/glossary-terms.xml6034(primary)#: ./doc/glossary/glossary-terms.xml6038(para)#: ./doc/glossary/glossary-terms.xml6044(glossterm) #: ./doc/glossary/glossary-terms.xml6046(primary)#: ./doc/glossary/glossary-terms.xml6050(para)#: ./doc/glossary/glossary-terms.xml6057(glossterm)#: ./doc/glossary/glossary-terms.xml6059(primary)#: ./doc/glossary/glossary-terms.xml6063(para)#: ./doc/glossary/glossary-terms.xml6072(title)#: ./doc/glossary/glossary-terms.xml6075(glossterm)#: ./doc/glossary/glossary-terms.xml6079(secondary) #: ./doc/glossary/glossary-terms.xml6082(primary)#: ./doc/glossary/glossary-terms.xml6086(para)#: ./doc/glossary/glossary-terms.xml6093(glossterm)#: ./doc/glossary/glossary-terms.xml6095(primary) #: ./doc/glossary/glossary-terms.xml6110(primary) #: ./doc/glossary/glossary-terms.xml6124(primary)#: ./doc/glossary/glossary-terms.xml6101(para)#: ./doc/glossary/glossary-terms.xml6108(glossterm) #: ./doc/glossary/glossary-terms.xml6112(secondary)#: ./doc/glossary/glossary-terms.xml6116(para)#: ./doc/glossary/glossary-terms.xml6122(glossterm)#: ./doc/glossary/glossary-terms.xml6126(secondary)#: ./doc/glossary/glossary-terms.xml6130(para)#: ./doc/glossary/glossary-terms.xml6136(glossterm) #: ./doc/glossary/glossary-terms.xml6138(primary)#: ./doc/glossary/glossary-terms.xml6142(para)#: ./doc/glossary/glossary-terms.xml6148(glossterm) #: ./doc/glossary/glossary-terms.xml6150(primary)#: ./doc/glossary/glossary-terms.xml6154(para)#: ./doc/glossary/glossary-terms.xml6160(glossterm) #: ./doc/glossary/glossary-terms.xml6162(primary)#: ./doc/glossary/glossary-terms.xml6166(para)#: ./doc/glossary/glossary-terms.xml6172(glossterm)#: ./doc/glossary/glossary-terms.xml6176(secondary) #: ./doc/glossary/glossary-terms.xml6179(primary)#: ./doc/glossary/glossary-terms.xml6183(para)#: ./doc/glossary/glossary-terms.xml6189(glossterm) #: ./doc/glossary/glossary-terms.xml6191(primary)#: ./doc/glossary/glossary-terms.xml6195(para)#: ./doc/glossary/glossary-terms.xml6200(glossterm) #: ./doc/glossary/glossary-terms.xml6202(primary)#: ./doc/glossary/glossary-terms.xml6206(para)#: ./doc/glossary/glossary-terms.xml6212(glossterm) #: ./doc/glossary/glossary-terms.xml6214(primary)#: ./doc/glossary/glossary-terms.xml6218(para)#: ./doc/glossary/glossary-terms.xml6227(glossterm)#: ./doc/glossary/glossary-terms.xml6229(primary)#: ./doc/glossary/glossary-terms.xml6233(para)#: ./doc/glossary/glossary-terms.xml6239(glossterm) #: ./doc/glossary/glossary-terms.xml6241(primary)#: ./doc/glossary/glossary-terms.xml6245(para)#: ./doc/glossary/glossary-terms.xml6251(glossterm) #: ./doc/glossary/glossary-terms.xml6253(primary)#: ./doc/glossary/glossary-terms.xml6257(para)#: ./doc/glossary/glossary-terms.xml6266(glossterm) #: ./doc/glossary/glossary-terms.xml6268(primary)#: ./doc/glossary/glossary-terms.xml6272(para)#: ./doc/glossary/glossary-terms.xml6278(glossterm)#: ./doc/glossary/glossary-terms.xml6280(primary) #: ./doc/glossary/glossary-terms.xml6294(primary) #: ./doc/glossary/glossary-terms.xml8577(primary)#: ./doc/glossary/glossary-terms.xml6286(para)#: ./doc/glossary/glossary-terms.xml6292(glossterm) #: ./doc/glossary/glossary-terms.xml6296(secondary)#: ./doc/glossary/glossary-terms.xml6300(para)#: ./doc/glossary/glossary-terms.xml6305(glossterm)#: ./doc/glossary/glossary-terms.xml6307(primary)#: ./doc/glossary/glossary-terms.xml6311(para)#: ./doc/glossary/glossary-terms.xml6317(glossterm) #: ./doc/glossary/glossary-terms.xml6319(primary)#: ./doc/glossary/glossary-terms.xml6323(para)#: ./doc/glossary/glossary-terms.xml6329(glossterm) #: ./doc/glossary/glossary-terms.xml6336(primary)#: ./doc/glossary/glossary-terms.xml6333(secondary)#: ./doc/glossary/glossary-terms.xml6340(para)#: ./doc/glossary/glossary-terms.xml6346(glossterm)#: ./doc/glossary/glossary-terms.xml6350(secondary) #: ./doc/glossary/glossary-terms.xml6353(primary)#: ./doc/glossary/glossary-terms.xml6357(para)#: ./doc/glossary/glossary-terms.xml6369(glossterm)#: ./doc/glossary/glossary-terms.xml6371(primary) #: ./doc/glossary/glossary-terms.xml6385(primary) #: ./doc/glossary/glossary-terms.xml6399(primary)#: ./doc/glossary/glossary-terms.xml6377(para)#: ./doc/glossary/glossary-terms.xml6383(glossterm) #: ./doc/glossary/glossary-terms.xml6387(secondary)#: ./doc/glossary/glossary-terms.xml6391(para)#: ./doc/glossary/glossary-terms.xml6397(glossterm) #: ./doc/glossary/glossary-terms.xml6401(secondary)#: ./doc/glossary/glossary-terms.xml6405(para)#: ./doc/glossary/glossary-terms.xml6410(glossterm) #: ./doc/glossary/glossary-terms.xml6412(primary)#: ./doc/glossary/glossary-terms.xml6416(para)#: ./doc/glossary/glossary-terms.xml6423(glossterm) #: ./doc/glossary/glossary-terms.xml6425(primary)#: ./doc/glossary/glossary-terms.xml6429(para)#: ./doc/glossary/glossary-terms.xml6438(glossterm) #: ./doc/glossary/glossary-terms.xml6440(primary)#: ./doc/glossary/glossary-terms.xml6444(para)#: ./doc/glossary/glossary-terms.xml6450(glossterm)#: ./doc/glossary/glossary-terms.xml6454(secondary) #: ./doc/glossary/glossary-terms.xml6457(primary)#: ./doc/glossary/glossary-terms.xml6461(para)#: ./doc/glossary/glossary-terms.xml6466(glossterm)#: ./doc/glossary/glossary-terms.xml6470(secondary) #: ./doc/glossary/glossary-terms.xml6473(primary)#: ./doc/glossary/glossary-terms.xml6477(para)#: ./doc/glossary/glossary-terms.xml6484(glossterm) #: ./doc/glossary/glossary-terms.xml6491(primary)#: ./doc/glossary/glossary-terms.xml6488(secondary)#: ./doc/glossary/glossary-terms.xml6495(para)#: ./doc/glossary/glossary-terms.xml6501(glossterm) #: ./doc/glossary/glossary-terms.xml6508(primary)#: ./doc/glossary/glossary-terms.xml6505(secondary)#: ./doc/glossary/glossary-terms.xml6512(para)#: ./doc/glossary/glossary-terms.xml6518(glossterm) #: ./doc/glossary/glossary-terms.xml6525(primary)#: ./doc/glossary/glossary-terms.xml6522(secondary) #: ./doc/glossary/glossary-terms.xml6550(secondary)#: ./doc/glossary/glossary-terms.xml6529(para)#: ./doc/glossary/glossary-terms.xml6534(glossterm) #: ./doc/glossary/glossary-terms.xml6536(primary)#: ./doc/glossary/glossary-terms.xml6540(para)#: ./doc/glossary/glossary-terms.xml6546(glossterm) #: ./doc/glossary/glossary-terms.xml6553(primary)#: ./doc/glossary/glossary-terms.xml6557(para)#: ./doc/glossary/glossary-terms.xml6566(glossterm) #: ./doc/glossary/glossary-terms.xml6568(primary)#: ./doc/glossary/glossary-terms.xml6572(para)#: ./doc/glossary/glossary-terms.xml6578(glossterm) #: ./doc/glossary/glossary-terms.xml6580(primary)#: ./doc/glossary/glossary-terms.xml6584(para)#: ./doc/glossary/glossary-terms.xml6592(title)#: ./doc/glossary/glossary-terms.xml6595(glossterm) #: ./doc/glossary/glossary-terms.xml6597(primary)#: ./doc/glossary/glossary-terms.xml6607(glossterm) #: ./doc/glossary/glossary-terms.xml6609(primary)#: ./doc/glossary/glossary-terms.xml6613(para)#: ./doc/glossary/glossary-terms.xml6619(glossterm) #: ./doc/glossary/glossary-terms.xml6621(primary)#: ./doc/glossary/glossary-terms.xml6625(para)#: ./doc/glossary/glossary-terms.xml6632(glossterm) #: ./doc/glossary/glossary-terms.xml6634(primary)#: ./doc/glossary/glossary-terms.xml6638(para)#: ./doc/glossary/glossary-terms.xml6641(para)#: ./doc/glossary/glossary-terms.xml6647(glossterm)#: ./doc/glossary/glossary-terms.xml6649(primary)#: ./doc/glossary/glossary-terms.xml6653(para)#: ./doc/glossary/glossary-terms.xml6662(title)#: ./doc/glossary/glossary-terms.xml6665(glossterm) #: ./doc/glossary/glossary-terms.xml6667(primary)#: ./doc/glossary/glossary-terms.xml6671(para)#: ./doc/glossary/glossary-terms.xml6676(glossterm) #: ./doc/glossary/glossary-terms.xml6678(primary)#: ./doc/glossary/glossary-terms.xml6682(para)#: ./doc/glossary/glossary-terms.xml6688(glossterm) #: ./doc/glossary/glossary-terms.xml6690(primary)#: ./doc/glossary/glossary-terms.xml6694(para)#: ./doc/glossary/glossary-terms.xml6700(glossterm) #: ./doc/glossary/glossary-terms.xml6702(primary)#: ./doc/glossary/glossary-terms.xml6706(para)#: ./doc/glossary/glossary-terms.xml6713(glossterm) #: ./doc/glossary/glossary-terms.xml6715(primary)#: ./doc/glossary/glossary-terms.xml6719(para)#: ./doc/glossary/glossary-terms.xml6725(glossterm) #: ./doc/glossary/glossary-terms.xml6727(primary)#: ./doc/glossary/glossary-terms.xml6731(para)#: ./doc/glossary/glossary-terms.xml6739(glossterm)#: ./doc/glossary/glossary-terms.xml6741(primary)#: ./doc/glossary/glossary-terms.xml6745(para)#: ./doc/glossary/glossary-terms.xml6751(glossterm)#: ./doc/glossary/glossary-terms.xml6753(primary)#: ./doc/glossary/glossary-terms.xml6757(para)#: ./doc/glossary/glossary-terms.xml6763(glossterm)#: ./doc/glossary/glossary-terms.xml6765(primary)#: ./doc/glossary/glossary-terms.xml6769(para)#: ./doc/glossary/glossary-terms.xml6776(glossterm) #: ./doc/glossary/glossary-terms.xml6778(primary) #: ./doc/glossary/glossary-terms.xml7672(primary)#: ./doc/glossary/glossary-terms.xml6780(secondary) #: ./doc/glossary/glossary-terms.xml7674(secondary)#: ./doc/glossary/glossary-terms.xml6784(para)#: ./doc/glossary/glossary-terms.xml6794(glossterm)#: ./doc/glossary/glossary-terms.xml6796(primary)#: ./doc/glossary/glossary-terms.xml6800(para)#: ./doc/glossary/glossary-terms.xml6806(glossterm) #: ./doc/glossary/glossary-terms.xml6808(primary)#: ./doc/glossary/glossary-terms.xml6812(para)#: ./doc/glossary/glossary-terms.xml6817(glossterm)#: ./doc/glossary/glossary-terms.xml6819(primary) #: ./doc/glossary/glossary-terms.xml6838(primary)#: ./doc/glossary/glossary-terms.xml6825(para)#: ./doc/glossary/glossary-terms.xml6836(glossterm)#: ./doc/glossary/glossary-terms.xml6840(secondary)#: ./doc/glossary/glossary-terms.xml6844(para)#: ./doc/glossary/glossary-terms.xml6850(glossterm) #: ./doc/glossary/glossary-terms.xml6852(primary)#: ./doc/glossary/glossary-terms.xml6861(glossterm) #: ./doc/glossary/glossary-terms.xml6863(primary)#: ./doc/glossary/glossary-terms.xml6867(para)#: ./doc/glossary/glossary-terms.xml6872(glossterm) #: ./doc/glossary/glossary-terms.xml6874(primary)#: ./doc/glossary/glossary-terms.xml6878(para)#: ./doc/glossary/glossary-terms.xml6885(glossterm) #: ./doc/glossary/glossary-terms.xml6887(primary)#: ./doc/glossary/glossary-terms.xml6889(see)#: ./doc/glossary/glossary-terms.xml6893(para)#: ./doc/glossary/glossary-terms.xml6898(glossterm)#: ./doc/glossary/glossary-terms.xml6902(secondary) #: ./doc/glossary/glossary-terms.xml6905(primary)#: ./doc/glossary/glossary-terms.xml6909(para)#: ./doc/glossary/glossary-terms.xml6915(glossterm) #: ./doc/glossary/glossary-terms.xml6918(primary)#: ./doc/glossary/glossary-terms.xml6923(para)#: ./doc/glossary/glossary-terms.xml6929(glossterm) #: ./doc/glossary/glossary-terms.xml6931(primary)#: ./doc/glossary/glossary-terms.xml6935(para)#: ./doc/glossary/glossary-terms.xml6941(glossterm)#: ./doc/glossary/glossary-terms.xml6943(primary) #: ./doc/glossary/glossary-terms.xml6958(primary) #: ./doc/glossary/glossary-terms.xml6970(glossterm) #: ./doc/glossary/glossary-terms.xml6981(primary)#: ./doc/glossary/glossary-terms.xml6949(para)#: ./doc/glossary/glossary-terms.xml6956(glossterm) #: ./doc/glossary/glossary-terms.xml6960(secondary)#: ./doc/glossary/glossary-terms.xml6964(para)#: ./doc/glossary/glossary-terms.xml6973(para)#: ./doc/glossary/glossary-terms.xml6979(glossterm)#: ./doc/glossary/glossary-terms.xml6983(secondary)#: ./doc/glossary/glossary-terms.xml6987(para)#: ./doc/glossary/glossary-terms.xml6993(glossterm)#: ./doc/glossary/glossary-terms.xml6995(primary)#: ./doc/glossary/glossary-terms.xml6999(para)#: ./doc/glossary/glossary-terms.xml7004(glossterm)#: ./doc/glossary/glossary-terms.xml7006(primary)#: ./doc/glossary/glossary-terms.xml7010(para)#: ./doc/glossary/glossary-terms.xml7017(glossterm)#: ./doc/glossary/glossary-terms.xml7019(primary)#: ./doc/glossary/glossary-terms.xml7023(para)#: ./doc/glossary/glossary-terms.xml7031(glossterm)#: ./doc/glossary/glossary-terms.xml7033(primary)#: ./doc/glossary/glossary-terms.xml7037(para)#: ./doc/glossary/glossary-terms.xml7044(glossterm)#: ./doc/glossary/glossary-terms.xml7046(primary) #: ./doc/glossary/glossary-terms.xml7061(primary)#: ./doc/glossary/glossary-terms.xml7052(para)#: ./doc/glossary/glossary-terms.xml7059(glossterm)#: ./doc/glossary/glossary-terms.xml7063(secondary)#: ./doc/glossary/glossary-terms.xml7067(para)#: ./doc/glossary/glossary-terms.xml7074(glossterm) #: ./doc/glossary/glossary-terms.xml7076(primary)#: ./doc/glossary/glossary-terms.xml7080(para)#: ./doc/glossary/glossary-terms.xml7088(glossterm)#: ./doc/glossary/glossary-terms.xml7090(primary) #: ./doc/glossary/glossary-terms.xml7105(primary)#: ./doc/glossary/glossary-terms.xml7096(para)#: ./doc/glossary/glossary-terms.xml7103(glossterm) #: ./doc/glossary/glossary-terms.xml7107(secondary)#: ./doc/glossary/glossary-terms.xml7111(para)#: ./doc/glossary/glossary-terms.xml7116(glossterm) #: ./doc/glossary/glossary-terms.xml7118(primary)#: ./doc/glossary/glossary-terms.xml7122(para)#: ./doc/glossary/glossary-terms.xml7128(glossterm) #: ./doc/glossary/glossary-terms.xml7135(primary)#: ./doc/glossary/glossary-terms.xml7130(primary) #: ./doc/glossary/glossary-terms.xml7715(primary)#: ./doc/glossary/glossary-terms.xml7132(secondary)#: ./doc/glossary/glossary-terms.xml7139(para)#: ./doc/glossary/glossary-terms.xml7145(glossterm) #: ./doc/glossary/glossary-terms.xml7147(primary)#: ./doc/glossary/glossary-terms.xml7151(para)#: ./doc/glossary/glossary-terms.xml7157(glossterm)#: ./doc/glossary/glossary-terms.xml7159(primary)#: ./doc/glossary/glossary-terms.xml7163(para)#: ./doc/glossary/glossary-terms.xml7170(glossterm)#: ./doc/glossary/glossary-terms.xml7172(primary)#: ./doc/glossary/glossary-terms.xml7174(secondary) #: ./doc/glossary/glossary-terms.xml7177(primary)#: ./doc/glossary/glossary-terms.xml7181(para)#: ./doc/glossary/glossary-terms.xml7188(glossterm) #: ./doc/glossary/glossary-terms.xml7190(primary)#: ./doc/glossary/glossary-terms.xml7194(para)#: ./doc/glossary/glossary-terms.xml7199(glossterm)#: ./doc/glossary/glossary-terms.xml7201(primary)#: ./doc/glossary/glossary-terms.xml7205(para)#: ./doc/glossary/glossary-terms.xml7211(glossterm)#: ./doc/glossary/glossary-terms.xml7214(para)#: ./doc/glossary/glossary-terms.xml7220(glossterm) #: ./doc/glossary/glossary-terms.xml7222(primary)#: ./doc/glossary/glossary-terms.xml7226(para)#: ./doc/glossary/glossary-terms.xml7235(title)#: ./doc/glossary/glossary-terms.xml7238(glossterm)#: ./doc/glossary/glossary-terms.xml7240(primary)#: ./doc/glossary/glossary-terms.xml7244(para)#: ./doc/glossary/glossary-terms.xml7251(glossterm) #: ./doc/glossary/glossary-terms.xml7253(primary)#: ./doc/glossary/glossary-terms.xml7257(para)#: ./doc/glossary/glossary-terms.xml7263(glossterm) #: ./doc/glossary/glossary-terms.xml7265(primary) msgid ""SAML assertion"" msgstr """" #: ./doc/glossary/glossary-terms.xml7269(para) msgid """" ""Contains information about a user as provided by the identity provider. It "" ""is an indication that a user has been authenticated."" msgstr """" #: ./doc/glossary/glossary-terms.xml7275(glossterm) #: ./doc/glossary/glossary-terms.xml7277(primary)#: ./doc/glossary/glossary-terms.xml7281(para)#: ./doc/glossary/glossary-terms.xml7288(glossterm)#: ./doc/glossary/glossary-terms.xml7290(primary)#: ./doc/glossary/glossary-terms.xml7294(para)#: ./doc/glossary/glossary-terms.xml7300(glossterm)#: ./doc/glossary/glossary-terms.xml7302(primary)#: ./doc/glossary/glossary-terms.xml7306(para)#: ./doc/glossary/glossary-terms.xml7312(glossterm)#: ./doc/glossary/glossary-terms.xml7314(primary)#: ./doc/glossary/glossary-terms.xml7318(para)#: ./doc/glossary/glossary-terms.xml7324(glossterm) #: ./doc/glossary/glossary-terms.xml7326(primary)#: ./doc/glossary/glossary-terms.xml7330(para)#: ./doc/glossary/glossary-terms.xml7337(glossterm)#: ./doc/glossary/glossary-terms.xml7339(primary)#: ./doc/glossary/glossary-terms.xml7343(para)#: ./doc/glossary/glossary-terms.xml7349(glossterm)#: ./doc/glossary/glossary-terms.xml7353(secondary) #: ./doc/glossary/glossary-terms.xml7356(primary)#: ./doc/glossary/glossary-terms.xml7360(para)#: ./doc/glossary/glossary-terms.xml7367(glossterm) #: ./doc/glossary/glossary-terms.xml7369(primary)#: ./doc/glossary/glossary-terms.xml7373(para)#: ./doc/glossary/glossary-terms.xml7379(glossterm)#: ./doc/glossary/glossary-terms.xml7387(para)#: ./doc/glossary/glossary-terms.xml7391(para)#: ./doc/glossary/glossary-terms.xml7397(glossterm) #: ./doc/glossary/glossary-terms.xml7399(primary)#: ./doc/glossary/glossary-terms.xml7403(para)#: ./doc/glossary/glossary-terms.xml7408(glossterm) #: ./doc/glossary/glossary-terms.xml7412(secondary)#: ./doc/glossary/glossary-terms.xml7422(glossterm)#: ./doc/glossary/glossary-terms.xml7424(primary)#: ./doc/glossary/glossary-terms.xml7430(para)#: ./doc/glossary/glossary-terms.xml7437(glossterm) #: ./doc/glossary/glossary-terms.xml7439(primary)#: ./doc/glossary/glossary-terms.xml7443(para)#: ./doc/glossary/glossary-terms.xml7448(glossterm) #: ./doc/glossary/glossary-terms.xml7450(primary)#: ./doc/glossary/glossary-terms.xml7454(para)#: ./doc/glossary/glossary-terms.xml7460(glossterm) #: ./doc/glossary/glossary-terms.xml7462(primary) msgid ""service provider"" msgstr """" #: ./doc/glossary/glossary-terms.xml7466(para) msgid """" ""A system that provides services to other system entities. In case of "" ""federated identity, OpenStack Identity is the service provider."" msgstr """" #: ./doc/glossary/glossary-terms.xml7473(glossterm) #: ./doc/glossary/glossary-terms.xml7475(primary)#: ./doc/glossary/glossary-terms.xml7479(para)#: ./doc/glossary/glossary-terms.xml7485(glossterm) #: ./doc/glossary/glossary-terms.xml7487(primary)#: ./doc/glossary/glossary-terms.xml7491(para)#: ./doc/glossary/glossary-terms.xml7497(glossterm) #: ./doc/glossary/glossary-terms.xml7499(primary)#: ./doc/glossary/glossary-terms.xml7503(para)#: ./doc/glossary/glossary-terms.xml7509(glossterm) #: ./doc/glossary/glossary-terms.xml7513(secondary)#: ./doc/glossary/glossary-terms.xml7511(primary) #: ./doc/glossary/glossary-terms.xml7525(primary) #: ./doc/glossary/glossary-terms.xml7540(primary)#: ./doc/glossary/glossary-terms.xml7517(para)#: ./doc/glossary/glossary-terms.xml7523(glossterm) #: ./doc/glossary/glossary-terms.xml7527(secondary)#: ./doc/glossary/glossary-terms.xml7531(para)#: ./doc/glossary/glossary-terms.xml7538(glossterm) #: ./doc/glossary/glossary-terms.xml7542(secondary)#: ./doc/glossary/glossary-terms.xml7546(para)#: ./doc/glossary/glossary-terms.xml7552(glossterm) #: ./doc/glossary/glossary-terms.xml7559(primary)#: ./doc/glossary/glossary-terms.xml7556(secondary)#: ./doc/glossary/glossary-terms.xml7563(para)#: ./doc/glossary/glossary-terms.xml7576(glossterm)#: ./doc/glossary/glossary-terms.xml7578(primary)#: ./doc/glossary/glossary-terms.xml7582(para)#: ./doc/glossary/glossary-terms.xml7591(glossterm) #: ./doc/glossary/glossary-terms.xml7593(primary)#: ./doc/glossary/glossary-terms.xml7597(para)#: ./doc/glossary/glossary-terms.xml7603(glossterm) #: ./doc/glossary/glossary-terms.xml7605(primary)#: ./doc/glossary/glossary-terms.xml7609(para)#: ./doc/glossary/glossary-terms.xml7615(glossterm) #: ./doc/glossary/glossary-terms.xml7618(primary)#: ./doc/glossary/glossary-terms.xml7622(para)#: ./doc/glossary/glossary-terms.xml7628(glossterm) #: ./doc/glossary/glossary-terms.xml7631(primary)#: ./doc/glossary/glossary-terms.xml7635(para)#: ./doc/glossary/glossary-terms.xml7645(glossterm) #: ./doc/glossary/glossary-terms.xml7647(primary)#: ./doc/glossary/glossary-terms.xml7651(para)#: ./doc/glossary/glossary-terms.xml7657(glossterm) #: ./doc/glossary/glossary-terms.xml7659(primary)#: ./doc/glossary/glossary-terms.xml7663(para)#: ./doc/glossary/glossary-terms.xml7670(glossterm) #: ./doc/glossary/glossary-terms.xml7677(primary)#: ./doc/glossary/glossary-terms.xml7681(para)#: ./doc/glossary/glossary-terms.xml7687(glossterm) #: ./doc/glossary/glossary-terms.xml7689(primary)#: ./doc/glossary/glossary-terms.xml7693(para)#: ./doc/glossary/glossary-terms.xml7699(glossterm)#: ./doc/glossary/glossary-terms.xml7701(primary)#: ./doc/glossary/glossary-terms.xml7706(para)#: ./doc/glossary/glossary-terms.xml7713(glossterm) #: ./doc/glossary/glossary-terms.xml7720(primary)#: ./doc/glossary/glossary-terms.xml7717(secondary)#: ./doc/glossary/glossary-terms.xml7724(para)#: ./doc/glossary/glossary-terms.xml7730(glossterm) #: ./doc/glossary/glossary-terms.xml7732(primary)#: ./doc/glossary/glossary-terms.xml7736(para)#: ./doc/glossary/glossary-terms.xml7741(glossterm) #: ./doc/glossary/glossary-terms.xml7743(primary)#: ./doc/glossary/glossary-terms.xml7747(para)#: ./doc/glossary/glossary-terms.xml7753(glossterm) #: ./doc/glossary/glossary-terms.xml7755(primary)#: ./doc/glossary/glossary-terms.xml7760(para)#: ./doc/glossary/glossary-terms.xml7768(glossterm) #: ./doc/glossary/glossary-terms.xml7770(primary)#: ./doc/glossary/glossary-terms.xml7774(para)#: ./doc/glossary/glossary-terms.xml7780(glossterm)#: ./doc/glossary/glossary-terms.xml7784(secondary)#: ./doc/glossary/glossary-terms.xml7787(primary)#: ./doc/glossary/glossary-terms.xml7791(para)#: ./doc/glossary/glossary-terms.xml7796(glossterm) #: ./doc/glossary/glossary-terms.xml7798(primary)#: ./doc/glossary/glossary-terms.xml7802(para)#: ./doc/glossary/glossary-terms.xml7808(glossterm) #: ./doc/glossary/glossary-terms.xml7810(primary)#: ./doc/glossary/glossary-terms.xml7814(para)#: ./doc/glossary/glossary-terms.xml7820(glossterm) #: ./doc/glossary/glossary-terms.xml7827(primary)#: ./doc/glossary/glossary-terms.xml7824(secondary)#: ./doc/glossary/glossary-terms.xml7831(para)#: ./doc/glossary/glossary-terms.xml7838(glossterm) #: ./doc/glossary/glossary-terms.xml7842(secondary)#: ./doc/glossary/glossary-terms.xml7840(primary) #: ./doc/glossary/glossary-terms.xml7854(primary) #: ./doc/glossary/glossary-terms.xml7868(primary) #: ./doc/glossary/glossary-terms.xml8017(primary)#: ./doc/glossary/glossary-terms.xml7846(para)#: ./doc/glossary/glossary-terms.xml7852(glossterm) #: ./doc/glossary/glossary-terms.xml7856(secondary)#: ./doc/glossary/glossary-terms.xml7860(para)#: ./doc/glossary/glossary-terms.xml7866(glossterm) #: ./doc/glossary/glossary-terms.xml7870(secondary)#: ./doc/glossary/glossary-terms.xml7874(para)#: ./doc/glossary/glossary-terms.xml7880(glossterm) #: ./doc/glossary/glossary-terms.xml7882(primary)#: ./doc/glossary/glossary-terms.xml7886(para)#: ./doc/glossary/glossary-terms.xml7892(glossterm)#: ./doc/glossary/glossary-terms.xml7894(primary)#: ./doc/glossary/glossary-terms.xml7898(para)#: ./doc/glossary/glossary-terms.xml7906(glossterm) #: ./doc/glossary/glossary-terms.xml7908(primary)#: ./doc/glossary/glossary-terms.xml7912(para)#: ./doc/glossary/glossary-terms.xml7917(glossterm) #: ./doc/glossary/glossary-terms.xml7920(primary)#: ./doc/glossary/glossary-terms.xml7929(glossterm)#: ./doc/glossary/glossary-terms.xml7931(primary)#: ./doc/glossary/glossary-terms.xml7935(para)#: ./doc/glossary/glossary-terms.xml7941(glossterm)#: ./doc/glossary/glossary-terms.xml7943(primary)#: ./doc/glossary/glossary-terms.xml7947(para)#: ./doc/glossary/glossary-terms.xml7953(glossterm) #: ./doc/glossary/glossary-terms.xml7955(primary)#: ./doc/glossary/glossary-terms.xml7959(para)#: ./doc/glossary/glossary-terms.xml7969(para)#: ./doc/glossary/glossary-terms.xml7975(glossterm) #: ./doc/glossary/glossary-terms.xml7977(primary)#: ./doc/glossary/glossary-terms.xml7981(para)#: ./doc/glossary/glossary-terms.xml7987(glossterm) #: ./doc/glossary/glossary-terms.xml7991(secondary)#: ./doc/glossary/glossary-terms.xml7995(para)#: ./doc/glossary/glossary-terms.xml8001(glossterm) #: ./doc/glossary/glossary-terms.xml8005(secondary)#: ./doc/glossary/glossary-terms.xml8009(para)#: ./doc/glossary/glossary-terms.xml8015(glossterm)#: ./doc/glossary/glossary-terms.xml8019(secondary) #: ./doc/glossary/glossary-terms.xml8024(secondary) #: ./doc/glossary/glossary-terms.xml8029(secondary)#: ./doc/glossary/glossary-terms.xml8033(para)#: ./doc/glossary/glossary-terms.xml8039(glossterm) #: ./doc/glossary/glossary-terms.xml8041(primary)#: ./doc/glossary/glossary-terms.xml8045(para)#: ./doc/glossary/glossary-terms.xml8051(glossterm) #: ./doc/glossary/glossary-terms.xml8053(primary)#: ./doc/glossary/glossary-terms.xml8057(para)#: ./doc/glossary/glossary-terms.xml8064(glossterm) #: ./doc/glossary/glossary-terms.xml8066(primary)#: ./doc/glossary/glossary-terms.xml8070(para)#: ./doc/glossary/glossary-terms.xml8080(title)#: ./doc/glossary/glossary-terms.xml8083(glossterm) #: ./doc/glossary/glossary-terms.xml8085(primary)#: ./doc/glossary/glossary-terms.xml8089(para)#: ./doc/glossary/glossary-terms.xml8096(glossterm) #: ./doc/glossary/glossary-terms.xml8098(primary)#: ./doc/glossary/glossary-terms.xml8102(para)#: ./doc/glossary/glossary-terms.xml8109(glossterm) #: ./doc/glossary/glossary-terms.xml8111(primary)#: ./doc/glossary/glossary-terms.xml8115(para)#: ./doc/glossary/glossary-terms.xml8121(glossterm) #: ./doc/glossary/glossary-terms.xml8123(primary)#: ./doc/glossary/glossary-terms.xml8127(para)#: ./doc/glossary/glossary-terms.xml8133(glossterm) #: ./doc/glossary/glossary-terms.xml8144(primary) #: ./doc/glossary/glossary-terms.xml8162(primary) #: ./doc/glossary/glossary-terms.xml8176(primary)#: ./doc/glossary/glossary-terms.xml8136(para)#: ./doc/glossary/glossary-terms.xml8142(glossterm) #: ./doc/glossary/glossary-terms.xml8146(secondary)#: ./doc/glossary/glossary-terms.xml8150(para)#: ./doc/glossary/glossary-terms.xml8155(glossterm) #: ./doc/glossary/glossary-terms.xml8159(secondary) #: ./doc/glossary/glossary-terms.xml8164(secondary)#: ./doc/glossary/glossary-terms.xml8168(para)#: ./doc/glossary/glossary-terms.xml8174(glossterm) #: ./doc/glossary/glossary-terms.xml8178(secondary)#: ./doc/glossary/glossary-terms.xml8182(para)#: ./doc/glossary/glossary-terms.xml8188(glossterm)#: ./doc/glossary/glossary-terms.xml8190(primary)#: ./doc/glossary/glossary-terms.xml8194(para)#: ./doc/glossary/glossary-terms.xml8200(glossterm) #: ./doc/glossary/glossary-terms.xml8202(primary)#: ./doc/glossary/glossary-terms.xml8206(para)#: ./doc/glossary/glossary-terms.xml8212(glossterm) #: ./doc/glossary/glossary-terms.xml8214(primary)#: ./doc/glossary/glossary-terms.xml8217(para)#: ./doc/glossary/glossary-terms.xml8225(glossterm) #: ./doc/glossary/glossary-terms.xml8227(primary)#: ./doc/glossary/glossary-terms.xml8231(para)#: ./doc/glossary/glossary-terms.xml8237(glossterm) #: ./doc/glossary/glossary-terms.xml8239(primary)#: ./doc/glossary/glossary-terms.xml8243(para)#: ./doc/glossary/glossary-terms.xml8249(glossterm)#: ./doc/glossary/glossary-terms.xml8251(primary)#: ./doc/glossary/glossary-terms.xml8255(para)#: ./doc/glossary/glossary-terms.xml8261(glossterm)#: ./doc/glossary/glossary-terms.xml8263(primary)#: ./doc/glossary/glossary-terms.xml8269(para)#: ./doc/glossary/glossary-terms.xml8274(glossterm)#: ./doc/glossary/glossary-terms.xml8277(para)#: ./doc/glossary/glossary-terms.xml8283(glossterm)#: ./doc/glossary/glossary-terms.xml8287(secondary) #: ./doc/glossary/glossary-terms.xml8290(primary)#: ./doc/glossary/glossary-terms.xml8294(para)#: ./doc/glossary/glossary-terms.xml8300(glossterm)#: ./doc/glossary/glossary-terms.xml8304(secondary) #: ./doc/glossary/glossary-terms.xml8307(primary)#: ./doc/glossary/glossary-terms.xml8311(para)#: ./doc/glossary/glossary-terms.xml8316(glossterm) #: ./doc/glossary/glossary-terms.xml8318(primary)#: ./doc/glossary/glossary-terms.xml8322(para)#: ./doc/glossary/glossary-terms.xml8330(glossterm) #: ./doc/glossary/glossary-terms.xml8332(primary)#: ./doc/glossary/glossary-terms.xml8336(para)#: ./doc/glossary/glossary-terms.xml8345(title)#: ./doc/glossary/glossary-terms.xml8348(glossterm) #: ./doc/glossary/glossary-terms.xml8350(primary)#: ./doc/glossary/glossary-terms.xml8354(para)#: ./doc/glossary/glossary-terms.xml8359(glossterm) #: ./doc/glossary/glossary-terms.xml8361(primary)#: ./doc/glossary/glossary-terms.xml8365(para)#: ./doc/glossary/glossary-terms.xml8370(glossterm)#: ./doc/glossary/glossary-terms.xml8372(primary)#: ./doc/glossary/glossary-terms.xml8376(para)#: ./doc/glossary/glossary-terms.xml8382(glossterm)#: ./doc/glossary/glossary-terms.xml8384(primary)#: ./doc/glossary/glossary-terms.xml8388(para)#: ./doc/glossary/glossary-terms.xml8395(glossterm) #: ./doc/glossary/glossary-terms.xml8397(primary)#: ./doc/glossary/glossary-terms.xml8401(para)#: ./doc/glossary/glossary-terms.xml8411(glossterm) #: ./doc/glossary/glossary-terms.xml8413(primary)#: ./doc/glossary/glossary-terms.xml8425(title)#: ./doc/glossary/glossary-terms.xml8428(glossterm) #: ./doc/glossary/glossary-terms.xml8430(primary)#: ./doc/glossary/glossary-terms.xml8434(para)#: ./doc/glossary/glossary-terms.xml8439(glossterm) #: ./doc/glossary/glossary-terms.xml8441(primary)#: ./doc/glossary/glossary-terms.xml8445(para)#: ./doc/glossary/glossary-terms.xml8455(glossterm) #: ./doc/glossary/glossary-terms.xml8458(primary)#: ./doc/glossary/glossary-terms.xml8462(para)#: ./doc/glossary/glossary-terms.xml8468(glossterm) #: ./doc/glossary/glossary-terms.xml8470(primary)#: ./doc/glossary/glossary-terms.xml8480(glossterm) #: ./doc/glossary/glossary-terms.xml8482(primary)#: ./doc/glossary/glossary-terms.xml8492(glossterm) #: ./doc/glossary/glossary-terms.xml8494(primary)#: ./doc/glossary/glossary-terms.xml8498(para)#: ./doc/glossary/glossary-terms.xml8506(glossterm) #: ./doc/glossary/glossary-terms.xml8508(primary)#: ./doc/glossary/glossary-terms.xml8512(para)#: ./doc/glossary/glossary-terms.xml8519(glossterm) #: ./doc/glossary/glossary-terms.xml8526(primary)#: ./doc/glossary/glossary-terms.xml8523(secondary) #: ./doc/glossary/glossary-terms.xml8579(secondary) #: ./doc/glossary/glossary-terms.xml8609(secondary)#: ./doc/glossary/glossary-terms.xml8530(para)#: ./doc/glossary/glossary-terms.xml8535(glossterm) #: ./doc/glossary/glossary-terms.xml8537(primary)#: ./doc/glossary/glossary-terms.xml8541(para)#: ./doc/glossary/glossary-terms.xml8550(glossterm) #: ./doc/glossary/glossary-terms.xml8552(primary)#: ./doc/glossary/glossary-terms.xml8556(para)#: ./doc/glossary/glossary-terms.xml8562(glossterm) #: ./doc/glossary/glossary-terms.xml8564(primary)#: ./doc/glossary/glossary-terms.xml8568(para)#: ./doc/glossary/glossary-terms.xml8575(glossterm) #: ./doc/glossary/glossary-terms.xml8582(primary)#: ./doc/glossary/glossary-terms.xml8586(para)#: ./doc/glossary/glossary-terms.xml8592(glossterm) #: ./doc/glossary/glossary-terms.xml8594(primary)#: ./doc/glossary/glossary-terms.xml8598(para)#: ./doc/glossary/glossary-terms.xml8605(glossterm)#: ./doc/glossary/glossary-terms.xml8612(primary)#: ./doc/glossary/glossary-terms.xml8616(para)#: ./doc/glossary/glossary-terms.xml8621(glossterm) #: ./doc/glossary/glossary-terms.xml8623(primary)#: ./doc/glossary/glossary-terms.xml8627(para)#: ./doc/glossary/glossary-terms.xml8633(glossterm) #: ./doc/glossary/glossary-terms.xml8635(primary)#: ./doc/glossary/glossary-terms.xml8639(para)#: ./doc/glossary/glossary-terms.xml8644(glossterm) #: ./doc/glossary/glossary-terms.xml8646(primary)#: ./doc/glossary/glossary-terms.xml8655(glossterm) #: ./doc/glossary/glossary-terms.xml8657(primary)#: ./doc/glossary/glossary-terms.xml8661(para)#: ./doc/glossary/glossary-terms.xml8667(glossterm) #: ./doc/glossary/glossary-terms.xml8674(primary)#: ./doc/glossary/glossary-terms.xml8671(secondary)#: ./doc/glossary/glossary-terms.xml8678(para)#: ./doc/glossary/glossary-terms.xml8688(glossterm) #: ./doc/glossary/glossary-terms.xml8690(primary)#: ./doc/glossary/glossary-terms.xml8700(glossterm) #: ./doc/glossary/glossary-terms.xml8702(primary)#: ./doc/glossary/glossary-terms.xml8706(para)#: ./doc/glossary/glossary-terms.xml8711(glossterm) #: ./doc/glossary/glossary-terms.xml8713(primary)#: ./doc/glossary/glossary-terms.xml8717(para)#: ./doc/glossary/glossary-terms.xml8723(glossterm) #: ./doc/glossary/glossary-terms.xml8725(primary)#: ./doc/glossary/glossary-terms.xml8729(para)#: ./doc/glossary/glossary-terms.xml8734(glossterm)#: ./doc/glossary/glossary-terms.xml8737(para)#: ./doc/glossary/glossary-terms.xml8742(glossterm) #: ./doc/glossary/glossary-terms.xml8744(primary)#: ./doc/glossary/glossary-terms.xml8748(para)#: ./doc/glossary/glossary-terms.xml8754(glossterm) #: ./doc/glossary/glossary-terms.xml8766(primary) #: ./doc/glossary/glossary-terms.xml8779(primary) #: ./doc/glossary/glossary-terms.xml8793(primary) #: ./doc/glossary/glossary-terms.xml8806(primary) #: ./doc/glossary/glossary-terms.xml8820(primary) #: ./doc/glossary/glossary-terms.xml8834(primary) #: ./doc/glossary/glossary-terms.xml8848(primary)#: ./doc/glossary/glossary-terms.xml8757(para)#: ./doc/glossary/glossary-terms.xml8764(glossterm) #: ./doc/glossary/glossary-terms.xml8768(secondary)#: ./doc/glossary/glossary-terms.xml8772(para)#: ./doc/glossary/glossary-terms.xml8777(glossterm) #: ./doc/glossary/glossary-terms.xml8781(secondary)#: ./doc/glossary/glossary-terms.xml8785(para)#: ./doc/glossary/glossary-terms.xml8791(glossterm) #: ./doc/glossary/glossary-terms.xml8795(secondary)#: ./doc/glossary/glossary-terms.xml8799(para)#: ./doc/glossary/glossary-terms.xml8804(glossterm) #: ./doc/glossary/glossary-terms.xml8808(secondary)#: ./doc/glossary/glossary-terms.xml8812(para)#: ./doc/glossary/glossary-terms.xml8818(glossterm) #: ./doc/glossary/glossary-terms.xml8822(secondary)#: ./doc/glossary/glossary-terms.xml8826(para)#: ./doc/glossary/glossary-terms.xml8832(glossterm) #: ./doc/glossary/glossary-terms.xml8836(secondary)#: ./doc/glossary/glossary-terms.xml8840(para)#: ./doc/glossary/glossary-terms.xml8846(glossterm) #: ./doc/glossary/glossary-terms.xml8850(secondary)#: ./doc/glossary/glossary-terms.xml8854(para)#: ./doc/glossary/glossary-terms.xml8860(glossterm)#: ./doc/glossary/glossary-terms.xml8862(primary)#: ./doc/glossary/glossary-terms.xml8866(para)#: ./doc/glossary/glossary-terms.xml8874(glossterm) #: ./doc/glossary/glossary-terms.xml8876(primary)#: ./doc/glossary/glossary-terms.xml8888(title)#: ./doc/glossary/glossary-terms.xml8891(glossterm) #: ./doc/glossary/glossary-terms.xml8893(primary)#: ./doc/glossary/glossary-terms.xml8897(para)#: ./doc/glossary/glossary-terms.xml8904(glossterm) #: ./doc/glossary/glossary-terms.xml8906(primary)#: ./doc/glossary/glossary-terms.xml8910(para)#: ./doc/glossary/glossary-terms.xml8916(glossterm) #: ./doc/glossary/glossary-terms.xml8918(primary)#: ./doc/glossary/glossary-terms.xml8922(para)#: ./doc/glossary/glossary-terms.xml8928(glossterm)#: ./doc/glossary/glossary-terms.xml8930(primary)#: ./doc/glossary/glossary-terms.xml8934(para)#: ./doc/glossary/glossary-terms.xml8945(title)#: ./doc/glossary/glossary-terms.xml8948(glossterm) #: ./doc/glossary/glossary-terms.xml8950(primary)#: ./doc/glossary/glossary-terms.xml8954(para)#: ./doc/glossary/glossary-terms.xml8964(glossterm) #: ./doc/glossary/glossary-terms.xml8975(primary) #: ./doc/glossary/glossary-terms.xml8988(primary) #: ./doc/glossary/glossary-terms.xml9002(primary)#: ./doc/glossary/glossary-terms.xml8967(para)#: ./doc/glossary/glossary-terms.xml8973(glossterm) #: ./doc/glossary/glossary-terms.xml8977(secondary)#: ./doc/glossary/glossary-terms.xml8986(glossterm) #: ./doc/glossary/glossary-terms.xml8990(secondary)#: ./doc/glossary/glossary-terms.xml8994(para)#: ./doc/glossary/glossary-terms.xml9000(glossterm)#: ./doc/glossary/glossary-terms.xml9004(secondary)#: ./doc/glossary/glossary-terms.xml9016(title)#: ./doc/glossary/glossary-terms.xml9030(title)#: ./doc/glossary/glossary-terms.xml9033(glossterm) #: ./doc/glossary/glossary-terms.xml9035(primary)#: ./doc/glossary/glossary-terms.xml9039(para)#: ./doc/glossary/glossary-terms.xml9045(glossterm) #: ./doc/glossary/glossary-terms.xml9047(primary)#: ./doc/glossary/glossary-terms.xml9051(para)","""POT-Creation-Date: 2014-10-11 02:09+0000\n"" ""PO-Revision-Date: 2014-10-11 03:10+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""#: ./doc/glossary/glossary-terms.xml4960(see)#: ./doc/glossary/glossary-terms.xml3286(secondary) #: ./doc/glossary/glossary-terms.xml3929(secondary) #: ./doc/glossary/glossary-terms.xml3981(secondary) #: ./doc/glossary/glossary-terms.xml4086(secondary) #: ./doc/glossary/glossary-terms.xml4303(secondary) #: ./doc/glossary/glossary-terms.xml4468(secondary) #: ./doc/glossary/glossary-terms.xml4486(secondary) #: ./doc/glossary/glossary-terms.xml4997(secondary) #: ./doc/glossary/glossary-terms.xml5345(secondary) #: ./doc/glossary/glossary-terms.xml5598(secondary) #: ./doc/glossary/glossary-terms.xml5714(secondary) #: ./doc/glossary/glossary-terms.xml6071(secondary) #: ./doc/glossary/glossary-terms.xml6256(secondary) #: ./doc/glossary/glossary-terms.xml6347(secondary) #: ./doc/glossary/glossary-terms.xml6919(secondary) #: ./doc/glossary/glossary-terms.xml7022(secondary) #: ./doc/glossary/glossary-terms.xml7066(secondary) #: ./doc/glossary/glossary-terms.xml7345(secondary) #: ./doc/glossary/glossary-terms.xml7388(secondary)#: ./doc/glossary/glossary-terms.xml3559(primary) #: ./doc/glossary/glossary-terms.xml8106(primary)#: ./doc/glossary/glossary-terms.xml6460(primary)#: ./doc/glossary/glossary-terms.xml6442(primary) #: ./doc/glossary/glossary-terms.xml6874(primary) #: ./doc/glossary/glossary-terms.xml7343(primary) #: ./doc/glossary/glossary-terms.xml7372(primary) #: ./doc/glossary/glossary-terms.xml8556(primary)#: ./doc/glossary/glossary-terms.xml6051(primary)#: ./doc/glossary/glossary-terms.xml6001(para) #: ./doc/glossary/glossary-terms.xml6830(para) #: ./doc/glossary/glossary-terms.xml7873(para)#: ./doc/glossary/glossary-terms.xml5680(secondary)#: ./doc/glossary/glossary-terms.xml5009(primary) #: ./doc/glossary/glossary-terms.xml5712(primary) #: ./doc/glossary/glossary-terms.xml5726(primary) #: ./doc/glossary/glossary-terms.xml5740(primary) #: ./doc/glossary/glossary-terms.xml5755(primary) #: ./doc/glossary/glossary-terms.xml5768(primary) #: ./doc/glossary/glossary-terms.xml5782(primary) #: ./doc/glossary/glossary-terms.xml5796(primary) #: ./doc/glossary/glossary-terms.xml5851(primary) #: ./doc/glossary/glossary-terms.xml7313(primary)#: ./doc/glossary/glossary-terms.xml3833(secondary) #: ./doc/glossary/glossary-terms.xml3963(secondary) #: ./doc/glossary/glossary-terms.xml4044(secondary) #: ./doc/glossary/glossary-terms.xml5960(secondary) #: ./doc/glossary/glossary-terms.xml6795(secondary)#: ./doc/glossary/glossary-terms.xml5645(see)#: ./doc/glossary/glossary-terms.xml4883(para) #: ./doc/glossary/glossary-terms.xml8366(para) #: ./doc/glossary/glossary-terms.xml8599(para) #: ./doc/glossary/glossary-terms.xml8829(para) #: ./doc/glossary/glossary-terms.xml8930(para) #: ./doc/glossary/glossary-terms.xml8957(para)#: ./doc/glossary/glossary-terms.xml8251(primary)#: ./doc/glossary/glossary-terms.xml3242(para)#: ./doc/glossary/glossary-terms.xml3247(glossterm) #: ./doc/glossary/glossary-terms.xml3249(primary)#: ./doc/glossary/glossary-terms.xml3253(para)#: ./doc/glossary/glossary-terms.xml3259(glossterm) #: ./doc/glossary/glossary-terms.xml3261(primary)#: ./doc/glossary/glossary-terms.xml3265(para)#: ./doc/glossary/glossary-terms.xml3270(glossterm) #: ./doc/glossary/glossary-terms.xml3272(primary)#: ./doc/glossary/glossary-terms.xml3276(para)#: ./doc/glossary/glossary-terms.xml3282(glossterm)#: ./doc/glossary/glossary-terms.xml3284(primary) #: ./doc/glossary/glossary-terms.xml4258(primary)#: ./doc/glossary/glossary-terms.xml3290(para)#: ./doc/glossary/glossary-terms.xml3296(glossterm)#: ./doc/glossary/glossary-terms.xml3298(primary)#: ./doc/glossary/glossary-terms.xml3302(para)#: ./doc/glossary/glossary-terms.xml3309(glossterm) #: ./doc/glossary/glossary-terms.xml3311(primary)#: ./doc/glossary/glossary-terms.xml3315(para)#: ./doc/glossary/glossary-terms.xml3321(glossterm)#: ./doc/glossary/glossary-terms.xml3323(primary) #: ./doc/glossary/glossary-terms.xml3418(primary) #: ./doc/glossary/glossary-terms.xml4484(primary) #: ./doc/glossary/glossary-terms.xml6305(primary) #: ./doc/glossary/glossary-terms.xml6494(primary) #: ./doc/glossary/glossary-terms.xml7503(primary) #: ./doc/glossary/glossary-terms.xml7731(primary)#: ./doc/glossary/glossary-terms.xml3325(secondary)#: ./doc/glossary/glossary-terms.xml3328(primary)#: ./doc/glossary/glossary-terms.xml3332(para)#: ./doc/glossary/glossary-terms.xml3340(glossterm) #: ./doc/glossary/glossary-terms.xml3342(primary)#: ./doc/glossary/glossary-terms.xml3346(para)#: ./doc/glossary/glossary-terms.xml3353(glossterm) #: ./doc/glossary/glossary-terms.xml3355(primary)#: ./doc/glossary/glossary-terms.xml3359(para)#: ./doc/glossary/glossary-terms.xml3366(glossterm) #: ./doc/glossary/glossary-terms.xml3368(primary)#: ./doc/glossary/glossary-terms.xml3372(para)#: ./doc/glossary/glossary-terms.xml3381(glossterm) #: ./doc/glossary/glossary-terms.xml3383(primary)#: ./doc/glossary/glossary-terms.xml3387(para)#: ./doc/glossary/glossary-terms.xml3393(glossterm) #: ./doc/glossary/glossary-terms.xml3395(primary)#: ./doc/glossary/glossary-terms.xml3399(para)#: ./doc/glossary/glossary-terms.xml3404(glossterm) #: ./doc/glossary/glossary-terms.xml3406(primary)#: ./doc/glossary/glossary-terms.xml3410(para)#: ./doc/glossary/glossary-terms.xml3416(glossterm) #: ./doc/glossary/glossary-terms.xml3423(primary)#: ./doc/glossary/glossary-terms.xml3420(secondary)#: ./doc/glossary/glossary-terms.xml3427(para)#: ./doc/glossary/glossary-terms.xml3436(glossterm) #: ./doc/glossary/glossary-terms.xml3438(primary)#: ./doc/glossary/glossary-terms.xml3442(para)#: ./doc/glossary/glossary-terms.xml3447(para)#: ./doc/glossary/glossary-terms.xml3455(glossterm) #: ./doc/glossary/glossary-terms.xml3457(primary)#: ./doc/glossary/glossary-terms.xml3461(para)#: ./doc/glossary/glossary-terms.xml3467(glossterm)#: ./doc/glossary/glossary-terms.xml3469(primary)#: ./doc/glossary/glossary-terms.xml3473(para)#: ./doc/glossary/glossary-terms.xml3482(title)#: ./doc/glossary/glossary-terms.xml3485(glossterm) #: ./doc/glossary/glossary-terms.xml3487(primary)#: ./doc/glossary/glossary-terms.xml3491(para)#: ./doc/glossary/glossary-terms.xml3497(glossterm) #: ./doc/glossary/glossary-terms.xml3499(primary)#: ./doc/glossary/glossary-terms.xml3502(para)#: ./doc/glossary/glossary-terms.xml3509(glossterm) #: ./doc/glossary/glossary-terms.xml3511(primary)#: ./doc/glossary/glossary-terms.xml3514(para)#: ./doc/glossary/glossary-terms.xml3521(glossterm) #: ./doc/glossary/glossary-terms.xml3531(primary) #: ./doc/glossary/glossary-terms.xml3546(primary)#: ./doc/glossary/glossary-terms.xml3524(para)#: ./doc/glossary/glossary-terms.xml3529(glossterm) #: ./doc/glossary/glossary-terms.xml3533(secondary)#: ./doc/glossary/glossary-terms.xml3537(para)#: ./doc/glossary/glossary-terms.xml3544(glossterm) #: ./doc/glossary/glossary-terms.xml3548(secondary)#: ./doc/glossary/glossary-terms.xml3552(para)#: ./doc/glossary/glossary-terms.xml3557(glossterm) #: ./doc/glossary/glossary-terms.xml3561(secondary) #: ./doc/glossary/glossary-terms.xml3564(primary)#: ./doc/glossary/glossary-terms.xml3568(para)#: ./doc/glossary/glossary-terms.xml3574(glossterm) #: ./doc/glossary/glossary-terms.xml3576(primary)#: ./doc/glossary/glossary-terms.xml3580(para)#: ./doc/glossary/glossary-terms.xml3586(glossterm) #: ./doc/glossary/glossary-terms.xml3588(primary)#: ./doc/glossary/glossary-terms.xml3592(para)#: ./doc/glossary/glossary-terms.xml3599(glossterm) #: ./doc/glossary/glossary-terms.xml3601(primary)#: ./doc/glossary/glossary-terms.xml3605(para)#: ./doc/glossary/glossary-terms.xml3611(glossterm) #: ./doc/glossary/glossary-terms.xml3613(primary)#: ./doc/glossary/glossary-terms.xml3617(para)#: ./doc/glossary/glossary-terms.xml3623(glossterm) #: ./doc/glossary/glossary-terms.xml3625(primary)#: ./doc/glossary/glossary-terms.xml3629(para)#: ./doc/glossary/glossary-terms.xml3636(glossterm) #: ./doc/glossary/glossary-terms.xml3638(primary)#: ./doc/glossary/glossary-terms.xml3642(para)#: ./doc/glossary/glossary-terms.xml3650(glossterm) #: ./doc/glossary/glossary-terms.xml3652(primary)#: ./doc/glossary/glossary-terms.xml3656(para)#: ./doc/glossary/glossary-terms.xml3665(title)#: ./doc/glossary/glossary-terms.xml3668(glossterm) #: ./doc/glossary/glossary-terms.xml3670(primary)#: ./doc/glossary/glossary-terms.xml3674(para)#: ./doc/glossary/glossary-terms.xml3680(glossterm) #: ./doc/glossary/glossary-terms.xml3682(primary)#: ./doc/glossary/glossary-terms.xml3686(para)#: ./doc/glossary/glossary-terms.xml3692(glossterm) #: ./doc/glossary/glossary-terms.xml3694(primary)#: ./doc/glossary/glossary-terms.xml3698(para)#: ./doc/glossary/glossary-terms.xml3705(glossterm) #: ./doc/glossary/glossary-terms.xml3707(primary)#: ./doc/glossary/glossary-terms.xml3711(para)#: ./doc/glossary/glossary-terms.xml3718(glossterm) #: ./doc/glossary/glossary-terms.xml3720(primary)#: ./doc/glossary/glossary-terms.xml3724(para)#: ./doc/glossary/glossary-terms.xml3730(glossterm) #: ./doc/glossary/glossary-terms.xml3732(primary) #: ./doc/glossary/glossary-terms.xml7705(see)#: ./doc/glossary/glossary-terms.xml3736(para)#: ./doc/glossary/glossary-terms.xml3741(glossterm) #: ./doc/glossary/glossary-terms.xml3743(primary)#: ./doc/glossary/glossary-terms.xml3747(para)#: ./doc/glossary/glossary-terms.xml3757(glossterm) #: ./doc/glossary/glossary-terms.xml3759(primary)#: ./doc/glossary/glossary-terms.xml3763(para)#: ./doc/glossary/glossary-terms.xml3774(glossterm)#: ./doc/glossary/glossary-terms.xml3777(para)#: ./doc/glossary/glossary-terms.xml3783(glossterm)#: ./doc/glossary/glossary-terms.xml3785(primary)#: ./doc/glossary/glossary-terms.xml3789(para)#: ./doc/glossary/glossary-terms.xml3794(glossterm)#: ./doc/glossary/glossary-terms.xml3796(primary)#: ./doc/glossary/glossary-terms.xml3800(para)#: ./doc/glossary/glossary-terms.xml3805(glossterm) #: ./doc/glossary/glossary-terms.xml3807(primary)#: ./doc/glossary/glossary-terms.xml3811(para)#: ./doc/glossary/glossary-terms.xml3817(glossterm) #: ./doc/glossary/glossary-terms.xml3819(primary)#: ./doc/glossary/glossary-terms.xml3823(para)#: ./doc/glossary/glossary-terms.xml3829(glossterm)#: ./doc/glossary/glossary-terms.xml3831(primary)#: ./doc/glossary/glossary-terms.xml3837(para)#: ./doc/glossary/glossary-terms.xml3847(glossterm)#: ./doc/glossary/glossary-terms.xml3849(primary)#: ./doc/glossary/glossary-terms.xml3853(para)#: ./doc/glossary/glossary-terms.xml3864(glossterm) #: ./doc/glossary/glossary-terms.xml3866(primary)#: ./doc/glossary/glossary-terms.xml3870(para)#: ./doc/glossary/glossary-terms.xml3882(glossterm) #: ./doc/glossary/glossary-terms.xml3884(primary)#: ./doc/glossary/glossary-terms.xml3888(para)#: ./doc/glossary/glossary-terms.xml3893(glossterm) #: ./doc/glossary/glossary-terms.xml3895(primary)#: ./doc/glossary/glossary-terms.xml3899(para)#: ./doc/glossary/glossary-terms.xml3906(glossterm)#: ./doc/glossary/glossary-terms.xml3909(para)#: ./doc/glossary/glossary-terms.xml3915(glossterm)#: ./doc/glossary/glossary-terms.xml3918(para)#: ./doc/glossary/glossary-terms.xml3925(glossterm)#: ./doc/glossary/glossary-terms.xml3927(primary) #: ./doc/glossary/glossary-terms.xml3941(primary)#: ./doc/glossary/glossary-terms.xml3933(para)#: ./doc/glossary/glossary-terms.xml3939(glossterm)#: ./doc/glossary/glossary-terms.xml3943(secondary)#: ./doc/glossary/glossary-terms.xml3947(para)#: ./doc/glossary/glossary-terms.xml3956(title)#: ./doc/glossary/glossary-terms.xml3959(glossterm)#: ./doc/glossary/glossary-terms.xml3961(primary)#: ./doc/glossary/glossary-terms.xml3967(para)#: ./doc/glossary/glossary-terms.xml3977(glossterm) #: ./doc/glossary/glossary-terms.xml3979(primary)#: ./doc/glossary/glossary-terms.xml3985(para)#: ./doc/glossary/glossary-terms.xml3992(glossterm)#: ./doc/glossary/glossary-terms.xml3994(primary)#: ./doc/glossary/glossary-terms.xml3998(para)#: ./doc/glossary/glossary-terms.xml4006(glossterm) #: ./doc/glossary/glossary-terms.xml4008(primary)#: ./doc/glossary/glossary-terms.xml4012(para)#: ./doc/glossary/glossary-terms.xml4018(glossterm)#: ./doc/glossary/glossary-terms.xml4021(para)#: ./doc/glossary/glossary-terms.xml4026(glossterm) #: ./doc/glossary/glossary-terms.xml4030(secondary)#: ./doc/glossary/glossary-terms.xml4028(primary) #: ./doc/glossary/glossary-terms.xml4040(glossterm) #: ./doc/glossary/glossary-terms.xml4042(primary) #: ./doc/glossary/glossary-terms.xml4059(primary) #: ./doc/glossary/glossary-terms.xml4130(primary)#: ./doc/glossary/glossary-terms.xml4034(para)#: ./doc/glossary/glossary-terms.xml4048(para)#: ./doc/glossary/glossary-terms.xml4057(glossterm) #: ./doc/glossary/glossary-terms.xml4061(secondary)#: ./doc/glossary/glossary-terms.xml4065(para)#: ./doc/glossary/glossary-terms.xml4071(glossterm)#: ./doc/glossary/glossary-terms.xml4073(primary)#: ./doc/glossary/glossary-terms.xml4077(para)#: ./doc/glossary/glossary-terms.xml4082(glossterm)#: ./doc/glossary/glossary-terms.xml4084(primary)#: ./doc/glossary/glossary-terms.xml4090(para)#: ./doc/glossary/glossary-terms.xml4099(glossterm)#: ./doc/glossary/glossary-terms.xml4101(primary) #: ./doc/glossary/glossary-terms.xml4115(primary) #: ./doc/glossary/glossary-terms.xml4144(primary) #: ./doc/glossary/glossary-terms.xml4158(primary) #: ./doc/glossary/glossary-terms.xml4172(primary) #: ./doc/glossary/glossary-terms.xml4184(glossterm) #: ./doc/glossary/glossary-terms.xml4204(primary) #: ./doc/glossary/glossary-terms.xml4218(primary) #: ./doc/glossary/glossary-terms.xml4232(primary) #: ./doc/glossary/glossary-terms.xml6477(primary)#: ./doc/glossary/glossary-terms.xml4103(secondary) #: ./doc/glossary/glossary-terms.xml4194(glossterm)#: ./doc/glossary/glossary-terms.xml4107(para)#: ./doc/glossary/glossary-terms.xml4113(glossterm) #: ./doc/glossary/glossary-terms.xml4117(secondary)#: ./doc/glossary/glossary-terms.xml4121(para)#: ./doc/glossary/glossary-terms.xml4128(glossterm) #: ./doc/glossary/glossary-terms.xml4132(secondary)#: ./doc/glossary/glossary-terms.xml4136(para)#: ./doc/glossary/glossary-terms.xml4142(glossterm) #: ./doc/glossary/glossary-terms.xml4146(secondary)#: ./doc/glossary/glossary-terms.xml4150(para) #: ./doc/glossary/glossary-terms.xml5095(para)#: ./doc/glossary/glossary-terms.xml4156(glossterm) #: ./doc/glossary/glossary-terms.xml4160(secondary)#: ./doc/glossary/glossary-terms.xml4164(para)#: ./doc/glossary/glossary-terms.xml4170(glossterm) #: ./doc/glossary/glossary-terms.xml4174(secondary)#: ./doc/glossary/glossary-terms.xml4178(para)#: ./doc/glossary/glossary-terms.xml4187(para)#: ./doc/glossary/glossary-terms.xml4197(para)#: ./doc/glossary/glossary-terms.xml4202(glossterm) #: ./doc/glossary/glossary-terms.xml4206(secondary)#: ./doc/glossary/glossary-terms.xml4210(para)#: ./doc/glossary/glossary-terms.xml4216(glossterm) #: ./doc/glossary/glossary-terms.xml4220(secondary)#: ./doc/glossary/glossary-terms.xml4224(para)#: ./doc/glossary/glossary-terms.xml4230(glossterm) #: ./doc/glossary/glossary-terms.xml4234(secondary)#: ./doc/glossary/glossary-terms.xml4238(para)#: ./doc/glossary/glossary-terms.xml4244(glossterm)#: ./doc/glossary/glossary-terms.xml4246(primary)#: ./doc/glossary/glossary-terms.xml4250(para)#: ./doc/glossary/glossary-terms.xml4256(glossterm) #: ./doc/glossary/glossary-terms.xml4260(secondary) #: ./doc/glossary/glossary-terms.xml4263(primary)#: ./doc/glossary/glossary-terms.xml4267(para)#: ./doc/glossary/glossary-terms.xml4273(glossterm) #: ./doc/glossary/glossary-terms.xml4275(primary)#: ./doc/glossary/glossary-terms.xml4278(para)#: ./doc/glossary/glossary-terms.xml4287(glossterm) #: ./doc/glossary/glossary-terms.xml4289(primary)#: ./doc/glossary/glossary-terms.xml4293(para)#: ./doc/glossary/glossary-terms.xml4299(glossterm)#: ./doc/glossary/glossary-terms.xml4301(primary) #: ./doc/glossary/glossary-terms.xml4315(primary) #: ./doc/glossary/glossary-terms.xml4328(primary) #: ./doc/glossary/glossary-terms.xml4352(primary) #: ./doc/glossary/glossary-terms.xml4367(primary) #: ./doc/glossary/glossary-terms.xml4380(primary)#: ./doc/glossary/glossary-terms.xml4307(para)#: ./doc/glossary/glossary-terms.xml4313(glossterm) #: ./doc/glossary/glossary-terms.xml4317(secondary)#: ./doc/glossary/glossary-terms.xml4321(para)#: ./doc/glossary/glossary-terms.xml4326(glossterm) #: ./doc/glossary/glossary-terms.xml4330(secondary)#: ./doc/glossary/glossary-terms.xml4334(para)#: ./doc/glossary/glossary-terms.xml4339(glossterm) #: ./doc/glossary/glossary-terms.xml4341(primary)#: ./doc/glossary/glossary-terms.xml4344(para)#: ./doc/glossary/glossary-terms.xml4350(glossterm) #: ./doc/glossary/glossary-terms.xml4354(secondary)#: ./doc/glossary/glossary-terms.xml4358(para)#: ./doc/glossary/glossary-terms.xml4365(glossterm) #: ./doc/glossary/glossary-terms.xml4369(secondary)#: ./doc/glossary/glossary-terms.xml4373(para)#: ./doc/glossary/glossary-terms.xml4378(glossterm) #: ./doc/glossary/glossary-terms.xml4382(secondary)#: ./doc/glossary/glossary-terms.xml4386(para) #: ./doc/glossary/glossary-terms.xml7378(para)#: ./doc/glossary/glossary-terms.xml4392(glossterm) #: ./doc/glossary/glossary-terms.xml4394(primary)#: ./doc/glossary/glossary-terms.xml4398(para)#: ./doc/glossary/glossary-terms.xml4404(glossterm) #: ./doc/glossary/glossary-terms.xml4406(primary)#: ./doc/glossary/glossary-terms.xml4410(para)#: ./doc/glossary/glossary-terms.xml4416(glossterm) #: ./doc/glossary/glossary-terms.xml4418(primary)#: ./doc/glossary/glossary-terms.xml4422(para)#: ./doc/glossary/glossary-terms.xml4428(glossterm) #: ./doc/glossary/glossary-terms.xml4430(primary)#: ./doc/glossary/glossary-terms.xml4434(para)#: ./doc/glossary/glossary-terms.xml4440(glossterm) #: ./doc/glossary/glossary-terms.xml4442(primary)#: ./doc/glossary/glossary-terms.xml4446(para)#: ./doc/glossary/glossary-terms.xml4452(glossterm) #: ./doc/glossary/glossary-terms.xml4454(primary)#: ./doc/glossary/glossary-terms.xml4458(para)#: ./doc/glossary/glossary-terms.xml4464(glossterm) #: ./doc/glossary/glossary-terms.xml4466(primary)#: ./doc/glossary/glossary-terms.xml4472(para)#: ./doc/glossary/glossary-terms.xml4482(glossterm)#: ./doc/glossary/glossary-terms.xml4490(para)#: ./doc/glossary/glossary-terms.xml4497(glossterm) #: ./doc/glossary/glossary-terms.xml4499(primary)#: ./doc/glossary/glossary-terms.xml4503(para)#: ./doc/glossary/glossary-terms.xml4510(glossterm)#: ./doc/glossary/glossary-terms.xml4512(primary)#: ./doc/glossary/glossary-terms.xml4516(para)#: ./doc/glossary/glossary-terms.xml4521(glossterm)#: ./doc/glossary/glossary-terms.xml4523(primary)#: ./doc/glossary/glossary-terms.xml4527(para)#: ./doc/glossary/glossary-terms.xml4538(glossterm) #: ./doc/glossary/glossary-terms.xml4540(primary)#: ./doc/glossary/glossary-terms.xml4544(para)#: ./doc/glossary/glossary-terms.xml4552(glossterm) #: ./doc/glossary/glossary-terms.xml4554(primary)#: ./doc/glossary/glossary-terms.xml4558(para)#: ./doc/glossary/glossary-terms.xml4566(glossterm) #: ./doc/glossary/glossary-terms.xml4568(primary)#: ./doc/glossary/glossary-terms.xml4572(para)#: ./doc/glossary/glossary-terms.xml4583(glossterm)#: ./doc/glossary/glossary-terms.xml4585(primary)#: ./doc/glossary/glossary-terms.xml4589(para)#: ./doc/glossary/glossary-terms.xml4595(glossterm)#: ./doc/glossary/glossary-terms.xml4597(primary)#: ./doc/glossary/glossary-terms.xml4601(para) #: ./doc/glossary/glossary-terms.xml6575(para) #: ./doc/glossary/glossary-terms.xml8423(para) #: ./doc/glossary/glossary-terms.xml8435(para) #: ./doc/glossary/glossary-terms.xml8643(para)#: ./doc/glossary/glossary-terms.xml4607(glossterm) #: ./doc/glossary/glossary-terms.xml4609(primary)#: ./doc/glossary/glossary-terms.xml4613(para)#: ./doc/glossary/glossary-terms.xml4622(title)#: ./doc/glossary/glossary-terms.xml4625(glossterm) #: ./doc/glossary/glossary-terms.xml4627(primary)#: ./doc/glossary/glossary-terms.xml4631(para)#: ./doc/glossary/glossary-terms.xml4637(glossterm) #: ./doc/glossary/glossary-terms.xml4639(primary)#: ./doc/glossary/glossary-terms.xml4643(para)#: ./doc/glossary/glossary-terms.xml4648(glossterm) #: ./doc/glossary/glossary-terms.xml4650(primary)#: ./doc/glossary/glossary-terms.xml4654(para)#: ./doc/glossary/glossary-terms.xml4659(glossterm) #: ./doc/glossary/glossary-terms.xml4661(primary)#: ./doc/glossary/glossary-terms.xml4665(para)#: ./doc/glossary/glossary-terms.xml4671(glossterm) #: ./doc/glossary/glossary-terms.xml4673(primary)#: ./doc/glossary/glossary-terms.xml4677(para)#: ./doc/glossary/glossary-terms.xml4683(glossterm) #: ./doc/glossary/glossary-terms.xml4685(primary)#: ./doc/glossary/glossary-terms.xml4689(para)#: ./doc/glossary/glossary-terms.xml4699(title)#: ./doc/glossary/glossary-terms.xml4702(glossterm)#: ./doc/glossary/glossary-terms.xml4704(primary)#: ./doc/glossary/glossary-terms.xml4708(para)#: ./doc/glossary/glossary-terms.xml4720(glossterm) #: ./doc/glossary/glossary-terms.xml4722(primary)#: ./doc/glossary/glossary-terms.xml4726(para)#: ./doc/glossary/glossary-terms.xml4731(glossterm) #: ./doc/glossary/glossary-terms.xml4733(primary)#: ./doc/glossary/glossary-terms.xml4737(para)#: ./doc/glossary/glossary-terms.xml4743(glossterm) #: ./doc/glossary/glossary-terms.xml4745(primary)#: ./doc/glossary/glossary-terms.xml4749(para)#: ./doc/glossary/glossary-terms.xml4762(title)#: ./doc/glossary/glossary-terms.xml4765(glossterm) #: ./doc/glossary/glossary-terms.xml4767(primary)#: ./doc/glossary/glossary-terms.xml4771(para)#: ./doc/glossary/glossary-terms.xml4776(glossterm) #: ./doc/glossary/glossary-terms.xml4778(primary)#: ./doc/glossary/glossary-terms.xml4782(para)#: ./doc/glossary/glossary-terms.xml4787(glossterm) #: ./doc/glossary/glossary-terms.xml4789(primary)#: ./doc/glossary/glossary-terms.xml4793(para)#: ./doc/glossary/glossary-terms.xml4803(glossterm) #: ./doc/glossary/glossary-terms.xml4805(primary)#: ./doc/glossary/glossary-terms.xml4809(para)#: ./doc/glossary/glossary-terms.xml4818(glossterm) #: ./doc/glossary/glossary-terms.xml4820(primary)#: ./doc/glossary/glossary-terms.xml4824(para)#: ./doc/glossary/glossary-terms.xml4830(glossterm) #: ./doc/glossary/glossary-terms.xml4832(primary)#: ./doc/glossary/glossary-terms.xml4836(para)#: ./doc/glossary/glossary-terms.xml4842(glossterm) #: ./doc/glossary/glossary-terms.xml4844(primary)#: ./doc/glossary/glossary-terms.xml4848(para)#: ./doc/glossary/glossary-terms.xml4854(glossterm)#: ./doc/glossary/glossary-terms.xml4857(para)#: ./doc/glossary/glossary-terms.xml4863(glossterm)#: ./doc/glossary/glossary-terms.xml4865(primary)#: ./doc/glossary/glossary-terms.xml4867(secondary) #: ./doc/glossary/glossary-terms.xml5935(secondary)#: ./doc/glossary/glossary-terms.xml4871(para)#: ./doc/glossary/glossary-terms.xml4877(glossterm) #: ./doc/glossary/glossary-terms.xml4879(primary)#: ./doc/glossary/glossary-terms.xml4888(glossterm) #: ./doc/glossary/glossary-terms.xml4890(primary)#: ./doc/glossary/glossary-terms.xml4894(para)#: ./doc/glossary/glossary-terms.xml4901(glossterm)#: ./doc/glossary/glossary-terms.xml4904(para)#: ./doc/glossary/glossary-terms.xml4912(glossterm) #: ./doc/glossary/glossary-terms.xml4914(primary)#: ./doc/glossary/glossary-terms.xml4918(para)#: ./doc/glossary/glossary-terms.xml4924(glossterm) #: ./doc/glossary/glossary-terms.xml4927(primary)#: ./doc/glossary/glossary-terms.xml4931(para)#: ./doc/glossary/glossary-terms.xml4937(glossterm) #: ./doc/glossary/glossary-terms.xml4939(primary)#: ./doc/glossary/glossary-terms.xml4943(para)#: ./doc/glossary/glossary-terms.xml4953(title)#: ./doc/glossary/glossary-terms.xml4956(glossterm) #: ./doc/glossary/glossary-terms.xml4958(primary)#: ./doc/glossary/glossary-terms.xml4964(para)#: ./doc/glossary/glossary-terms.xml4969(glossterm) #: ./doc/glossary/glossary-terms.xml4971(primary)#: ./doc/glossary/glossary-terms.xml4975(para)#: ./doc/glossary/glossary-terms.xml4981(glossterm) #: ./doc/glossary/glossary-terms.xml4983(primary)#: ./doc/glossary/glossary-terms.xml4987(para)#: ./doc/glossary/glossary-terms.xml4993(glossterm)#: ./doc/glossary/glossary-terms.xml4995(primary) #: ./doc/glossary/glossary-terms.xml5014(primary)#: ./doc/glossary/glossary-terms.xml5001(para)#: ./doc/glossary/glossary-terms.xml5007(glossterm)#: ./doc/glossary/glossary-terms.xml5011(secondary) #: ./doc/glossary/glossary-terms.xml5016(secondary)#: ./doc/glossary/glossary-terms.xml5020(para)#: ./doc/glossary/glossary-terms.xml5026(glossterm) #: ./doc/glossary/glossary-terms.xml5028(primary)#: ./doc/glossary/glossary-terms.xml5032(para)#: ./doc/glossary/glossary-terms.xml5038(glossterm) #: ./doc/glossary/glossary-terms.xml5040(primary)#: ./doc/glossary/glossary-terms.xml5044(para)#: ./doc/glossary/glossary-terms.xml5050(glossterm) #: ./doc/glossary/glossary-terms.xml5052(primary)#: ./doc/glossary/glossary-terms.xml5056(para)#: ./doc/glossary/glossary-terms.xml5065(glossterm) #: ./doc/glossary/glossary-terms.xml5067(primary)#: ./doc/glossary/glossary-terms.xml5071(para)#: ./doc/glossary/glossary-terms.xml5077(glossterm) #: ./doc/glossary/glossary-terms.xml5079(primary)#: ./doc/glossary/glossary-terms.xml5083(para)#: ./doc/glossary/glossary-terms.xml5089(glossterm)#: ./doc/glossary/glossary-terms.xml5091(primary)#: ./doc/glossary/glossary-terms.xml5101(glossterm) #: ./doc/glossary/glossary-terms.xml5103(primary)#: ./doc/glossary/glossary-terms.xml5107(para)#: ./doc/glossary/glossary-terms.xml5113(glossterm) #: ./doc/glossary/glossary-terms.xml5115(primary)#: ./doc/glossary/glossary-terms.xml5119(para)#: ./doc/glossary/glossary-terms.xml5127(glossterm)#: ./doc/glossary/glossary-terms.xml5129(primary)#: ./doc/glossary/glossary-terms.xml5133(para)#: ./doc/glossary/glossary-terms.xml5139(glossterm) #: ./doc/glossary/glossary-terms.xml5141(primary)#: ./doc/glossary/glossary-terms.xml5145(para)#: ./doc/glossary/glossary-terms.xml5151(glossterm) #: ./doc/glossary/glossary-terms.xml5153(primary)#: ./doc/glossary/glossary-terms.xml5157(para)#: ./doc/glossary/glossary-terms.xml5163(glossterm) #: ./doc/glossary/glossary-terms.xml5165(primary)#: ./doc/glossary/glossary-terms.xml5169(para)#: ./doc/glossary/glossary-terms.xml5175(glossterm) #: ./doc/glossary/glossary-terms.xml5177(primary)#: ./doc/glossary/glossary-terms.xml5181(para)#: ./doc/glossary/glossary-terms.xml5186(glossterm) #: ./doc/glossary/glossary-terms.xml5188(primary)#: ./doc/glossary/glossary-terms.xml5192(para)#: ./doc/glossary/glossary-terms.xml5198(glossterm) #: ./doc/glossary/glossary-terms.xml5200(primary)#: ./doc/glossary/glossary-terms.xml5204(para)#: ./doc/glossary/glossary-terms.xml5212(glossterm)#: ./doc/glossary/glossary-terms.xml5215(para)#: ./doc/glossary/glossary-terms.xml5221(glossterm) #: ./doc/glossary/glossary-terms.xml5224(primary)#: ./doc/glossary/glossary-terms.xml5228(para)#: ./doc/glossary/glossary-terms.xml5234(glossterm) #: ./doc/glossary/glossary-terms.xml5236(primary)#: ./doc/glossary/glossary-terms.xml5240(para)#: ./doc/glossary/glossary-terms.xml5246(glossterm) #: ./doc/glossary/glossary-terms.xml5248(primary)#: ./doc/glossary/glossary-terms.xml5252(para)#: ./doc/glossary/glossary-terms.xml5258(glossterm) #: ./doc/glossary/glossary-terms.xml5260(primary)#: ./doc/glossary/glossary-terms.xml5264(para)#: ./doc/glossary/glossary-terms.xml5271(glossterm) #: ./doc/glossary/glossary-terms.xml5273(primary)#: ./doc/glossary/glossary-terms.xml5277(para)#: ./doc/glossary/glossary-terms.xml5286(title)#: ./doc/glossary/glossary-terms.xml5289(glossterm) #: ./doc/glossary/glossary-terms.xml5291(primary)#: ./doc/glossary/glossary-terms.xml5295(para)#: ./doc/glossary/glossary-terms.xml5303(glossterm) #: ./doc/glossary/glossary-terms.xml5305(primary)#: ./doc/glossary/glossary-terms.xml5309(para)#: ./doc/glossary/glossary-terms.xml5315(glossterm) #: ./doc/glossary/glossary-terms.xml5317(primary)#: ./doc/glossary/glossary-terms.xml5321(para)#: ./doc/glossary/glossary-terms.xml5328(glossterm) #: ./doc/glossary/glossary-terms.xml5330(primary)#: ./doc/glossary/glossary-terms.xml5334(para)#: ./doc/glossary/glossary-terms.xml5341(glossterm)#: ./doc/glossary/glossary-terms.xml5343(primary) #: ./doc/glossary/glossary-terms.xml5359(primary) #: ./doc/glossary/glossary-terms.xml5373(primary) #: ./doc/glossary/glossary-terms.xml5388(primary) #: ./doc/glossary/glossary-terms.xml5402(primary) #: ./doc/glossary/glossary-terms.xml5416(primary) #: ./doc/glossary/glossary-terms.xml5430(primary) #: ./doc/glossary/glossary-terms.xml5443(primary) #: ./doc/glossary/glossary-terms.xml5457(primary) #: ./doc/glossary/glossary-terms.xml5471(primary) #: ./doc/glossary/glossary-terms.xml5485(primary) #: ./doc/glossary/glossary-terms.xml6322(primary) #: ./doc/glossary/glossary-terms.xml6522(primary) #: ./doc/glossary/glossary-terms.xml8470(primary) #: ./doc/glossary/glossary-terms.xml8618(primary)#: ./doc/glossary/glossary-terms.xml5349(para)#: ./doc/glossary/glossary-terms.xml5357(glossterm) #: ./doc/glossary/glossary-terms.xml5361(secondary)#: ./doc/glossary/glossary-terms.xml5365(para)#: ./doc/glossary/glossary-terms.xml5371(glossterm)#: ./doc/glossary/glossary-terms.xml5375(secondary)#: ./doc/glossary/glossary-terms.xml5379(para)#: ./doc/glossary/glossary-terms.xml5386(glossterm) #: ./doc/glossary/glossary-terms.xml5390(secondary)#: ./doc/glossary/glossary-terms.xml5394(para)#: ./doc/glossary/glossary-terms.xml5400(glossterm)#: ./doc/glossary/glossary-terms.xml5404(secondary)#: ./doc/glossary/glossary-terms.xml5408(para)#: ./doc/glossary/glossary-terms.xml5414(glossterm)#: ./doc/glossary/glossary-terms.xml5418(secondary)#: ./doc/glossary/glossary-terms.xml5422(para)#: ./doc/glossary/glossary-terms.xml5428(glossterm)#: ./doc/glossary/glossary-terms.xml5432(secondary)#: ./doc/glossary/glossary-terms.xml5436(para)#: ./doc/glossary/glossary-terms.xml5441(glossterm)#: ./doc/glossary/glossary-terms.xml5445(secondary)#: ./doc/glossary/glossary-terms.xml5449(para)#: ./doc/glossary/glossary-terms.xml5455(glossterm) #: ./doc/glossary/glossary-terms.xml5459(secondary)#: ./doc/glossary/glossary-terms.xml5463(para)#: ./doc/glossary/glossary-terms.xml5469(glossterm) #: ./doc/glossary/glossary-terms.xml5473(secondary)#: ./doc/glossary/glossary-terms.xml5477(para)#: ./doc/glossary/glossary-terms.xml5483(glossterm)#: ./doc/glossary/glossary-terms.xml5487(secondary)#: ./doc/glossary/glossary-terms.xml5491(para)#: ./doc/glossary/glossary-terms.xml5498(glossterm)#: ./doc/glossary/glossary-terms.xml5501(para)#: ./doc/glossary/glossary-terms.xml5508(glossterm) #: ./doc/glossary/glossary-terms.xml5510(primary) #: ./doc/glossary/glossary-terms.xml5533(secondary)#: ./doc/glossary/glossary-terms.xml5514(para)#: ./doc/glossary/glossary-terms.xml5520(glossterm) #: ./doc/glossary/glossary-terms.xml5531(primary) #: ./doc/glossary/glossary-terms.xml5544(primary) #: ./doc/glossary/glossary-terms.xml5558(primary)#: ./doc/glossary/glossary-terms.xml5523(para)#: ./doc/glossary/glossary-terms.xml5529(glossterm)#: ./doc/glossary/glossary-terms.xml5537(para)#: ./doc/glossary/glossary-terms.xml5542(glossterm) #: ./doc/glossary/glossary-terms.xml5546(secondary)#: ./doc/glossary/glossary-terms.xml5550(para)#: ./doc/glossary/glossary-terms.xml5556(glossterm) #: ./doc/glossary/glossary-terms.xml5560(secondary)#: ./doc/glossary/glossary-terms.xml5564(para)#: ./doc/glossary/glossary-terms.xml5571(glossterm) #: ./doc/glossary/glossary-terms.xml5573(primary)#: ./doc/glossary/glossary-terms.xml5577(para)#: ./doc/glossary/glossary-terms.xml5582(glossterm) #: ./doc/glossary/glossary-terms.xml5584(primary)#: ./doc/glossary/glossary-terms.xml5588(para)#: ./doc/glossary/glossary-terms.xml5594(glossterm)#: ./doc/glossary/glossary-terms.xml5596(primary) #: ./doc/glossary/glossary-terms.xml6426(primary) #: ./doc/glossary/glossary-terms.xml7771(primary) #: ./doc/glossary/glossary-terms.xml7971(primary)#: ./doc/glossary/glossary-terms.xml5602(para)#: ./doc/glossary/glossary-terms.xml5607(glossterm)#: ./doc/glossary/glossary-terms.xml5609(primary) #: ./doc/glossary/glossary-terms.xml5626(primary) #: ./doc/glossary/glossary-terms.xml6148(primary) #: ./doc/glossary/glossary-terms.xml8234(primary)#: ./doc/glossary/glossary-terms.xml5611(secondary) #: ./doc/glossary/glossary-terms.xml5614(primary) #: ./doc/glossary/glossary-terms.xml8214(see)#: ./doc/glossary/glossary-terms.xml5618(para)#: ./doc/glossary/glossary-terms.xml5624(glossterm) #: ./doc/glossary/glossary-terms.xml5631(primary)#: ./doc/glossary/glossary-terms.xml5628(secondary)#: ./doc/glossary/glossary-terms.xml5635(para)#: ./doc/glossary/glossary-terms.xml5641(glossterm) #: ./doc/glossary/glossary-terms.xml5643(primary)#: ./doc/glossary/glossary-terms.xml5649(para)#: ./doc/glossary/glossary-terms.xml5654(glossterm) #: ./doc/glossary/glossary-terms.xml5656(primary)#: ./doc/glossary/glossary-terms.xml5660(para)#: ./doc/glossary/glossary-terms.xml5668(glossterm) #: ./doc/glossary/glossary-terms.xml5678(primary) #: ./doc/glossary/glossary-terms.xml5691(primary)#: ./doc/glossary/glossary-terms.xml5671(para)#: ./doc/glossary/glossary-terms.xml5676(glossterm)#: ./doc/glossary/glossary-terms.xml5684(para)#: ./doc/glossary/glossary-terms.xml5689(glossterm) #: ./doc/glossary/glossary-terms.xml5693(secondary)#: ./doc/glossary/glossary-terms.xml5697(para)#: ./doc/glossary/glossary-terms.xml5707(title)#: ./doc/glossary/glossary-terms.xml5710(glossterm)#: ./doc/glossary/glossary-terms.xml5718(para)#: ./doc/glossary/glossary-terms.xml5724(glossterm)#: ./doc/glossary/glossary-terms.xml5728(secondary)#: ./doc/glossary/glossary-terms.xml5732(para)#: ./doc/glossary/glossary-terms.xml5738(glossterm) #: ./doc/glossary/glossary-terms.xml5742(secondary)#: ./doc/glossary/glossary-terms.xml5746(para)#: ./doc/glossary/glossary-terms.xml5753(glossterm) #: ./doc/glossary/glossary-terms.xml5757(secondary)#: ./doc/glossary/glossary-terms.xml5761(para)#: ./doc/glossary/glossary-terms.xml5766(glossterm) #: ./doc/glossary/glossary-terms.xml5770(secondary)#: ./doc/glossary/glossary-terms.xml5774(para)#: ./doc/glossary/glossary-terms.xml5780(glossterm)#: ./doc/glossary/glossary-terms.xml5784(secondary)#: ./doc/glossary/glossary-terms.xml5788(para)#: ./doc/glossary/glossary-terms.xml5794(glossterm)#: ./doc/glossary/glossary-terms.xml5798(secondary)#: ./doc/glossary/glossary-terms.xml5802(para)#: ./doc/glossary/glossary-terms.xml5808(glossterm) #: ./doc/glossary/glossary-terms.xml5825(primary) #: ./doc/glossary/glossary-terms.xml5838(primary)#: ./doc/glossary/glossary-terms.xml5811(para)#: ./doc/glossary/glossary-terms.xml5818(glossterm) #: ./doc/glossary/glossary-terms.xml5822(secondary) #: ./doc/glossary/glossary-terms.xml5827(secondary)#: ./doc/glossary/glossary-terms.xml5820(primary) #: ./doc/glossary/glossary-terms.xml7915(glossterm) #: ./doc/glossary/glossary-terms.xml7938(primary) #: ./doc/glossary/glossary-terms.xml7952(primary) #: ./doc/glossary/glossary-terms.xml7976(primary)#: ./doc/glossary/glossary-terms.xml5831(para)#: ./doc/glossary/glossary-terms.xml5836(glossterm) #: ./doc/glossary/glossary-terms.xml5840(secondary)#: ./doc/glossary/glossary-terms.xml5844(para)#: ./doc/glossary/glossary-terms.xml5849(glossterm) #: ./doc/glossary/glossary-terms.xml5853(secondary)#: ./doc/glossary/glossary-terms.xml5857(para)#: ./doc/glossary/glossary-terms.xml5863(glossterm) #: ./doc/glossary/glossary-terms.xml5865(primary)#: ./doc/glossary/glossary-terms.xml5869(para)#: ./doc/glossary/glossary-terms.xml5875(glossterm) #: ./doc/glossary/glossary-terms.xml5878(primary)#: ./doc/glossary/glossary-terms.xml5882(para)#: ./doc/glossary/glossary-terms.xml5888(glossterm) #: ./doc/glossary/glossary-terms.xml5890(primary)#: ./doc/glossary/glossary-terms.xml5894(para)#: ./doc/glossary/glossary-terms.xml5899(glossterm) #: ./doc/glossary/glossary-terms.xml5901(primary) #: ./doc/glossary/glossary-terms.xml5933(primary)#: ./doc/glossary/glossary-terms.xml5905(para)#: ./doc/glossary/glossary-terms.xml5917(glossterm) #: ./doc/glossary/glossary-terms.xml5919(primary)#: ./doc/glossary/glossary-terms.xml5923(para)#: ./doc/glossary/glossary-terms.xml5931(glossterm)#: ./doc/glossary/glossary-terms.xml5939(para)#: ./doc/glossary/glossary-terms.xml5944(glossterm) #: ./doc/glossary/glossary-terms.xml5946(primary)#: ./doc/glossary/glossary-terms.xml5950(para)#: ./doc/glossary/glossary-terms.xml5956(glossterm) #: ./doc/glossary/glossary-terms.xml5958(primary) #: ./doc/glossary/glossary-terms.xml5976(primary)#: ./doc/glossary/glossary-terms.xml5964(para)#: ./doc/glossary/glossary-terms.xml5974(glossterm)#: ./doc/glossary/glossary-terms.xml5977(secondary)#: ./doc/glossary/glossary-terms.xml5981(para)#: ./doc/glossary/glossary-terms.xml5995(glossterm) #: ./doc/glossary/glossary-terms.xml5997(primary)#: ./doc/glossary/glossary-terms.xml6006(glossterm) #: ./doc/glossary/glossary-terms.xml6008(primary)#: ./doc/glossary/glossary-terms.xml6012(para)#: ./doc/glossary/glossary-terms.xml6018(glossterm) #: ./doc/glossary/glossary-terms.xml6020(primary)#: ./doc/glossary/glossary-terms.xml6024(para)#: ./doc/glossary/glossary-terms.xml6031(glossterm)#: ./doc/glossary/glossary-terms.xml6033(primary)#: ./doc/glossary/glossary-terms.xml6037(para)#: ./doc/glossary/glossary-terms.xml6046(title)#: ./doc/glossary/glossary-terms.xml6049(glossterm)#: ./doc/glossary/glossary-terms.xml6053(secondary) #: ./doc/glossary/glossary-terms.xml6056(primary)#: ./doc/glossary/glossary-terms.xml6060(para)#: ./doc/glossary/glossary-terms.xml6067(glossterm)#: ./doc/glossary/glossary-terms.xml6069(primary) #: ./doc/glossary/glossary-terms.xml6084(primary) #: ./doc/glossary/glossary-terms.xml6098(primary)#: ./doc/glossary/glossary-terms.xml6075(para)#: ./doc/glossary/glossary-terms.xml6082(glossterm) #: ./doc/glossary/glossary-terms.xml6086(secondary)#: ./doc/glossary/glossary-terms.xml6090(para)#: ./doc/glossary/glossary-terms.xml6096(glossterm)#: ./doc/glossary/glossary-terms.xml6100(secondary)#: ./doc/glossary/glossary-terms.xml6104(para)#: ./doc/glossary/glossary-terms.xml6110(glossterm) #: ./doc/glossary/glossary-terms.xml6112(primary)#: ./doc/glossary/glossary-terms.xml6116(para)#: ./doc/glossary/glossary-terms.xml6122(glossterm) #: ./doc/glossary/glossary-terms.xml6124(primary)#: ./doc/glossary/glossary-terms.xml6128(para)#: ./doc/glossary/glossary-terms.xml6134(glossterm) #: ./doc/glossary/glossary-terms.xml6136(primary)#: ./doc/glossary/glossary-terms.xml6140(para)#: ./doc/glossary/glossary-terms.xml6146(glossterm)#: ./doc/glossary/glossary-terms.xml6150(secondary) #: ./doc/glossary/glossary-terms.xml6153(primary)#: ./doc/glossary/glossary-terms.xml6157(para)#: ./doc/glossary/glossary-terms.xml6163(glossterm) #: ./doc/glossary/glossary-terms.xml6165(primary)#: ./doc/glossary/glossary-terms.xml6169(para)#: ./doc/glossary/glossary-terms.xml6174(glossterm) #: ./doc/glossary/glossary-terms.xml6176(primary)#: ./doc/glossary/glossary-terms.xml6180(para)#: ./doc/glossary/glossary-terms.xml6186(glossterm) #: ./doc/glossary/glossary-terms.xml6188(primary)#: ./doc/glossary/glossary-terms.xml6192(para)#: ./doc/glossary/glossary-terms.xml6201(glossterm)#: ./doc/glossary/glossary-terms.xml6203(primary)#: ./doc/glossary/glossary-terms.xml6207(para)#: ./doc/glossary/glossary-terms.xml6213(glossterm) #: ./doc/glossary/glossary-terms.xml6215(primary)#: ./doc/glossary/glossary-terms.xml6219(para)#: ./doc/glossary/glossary-terms.xml6225(glossterm) #: ./doc/glossary/glossary-terms.xml6227(primary)#: ./doc/glossary/glossary-terms.xml6231(para)#: ./doc/glossary/glossary-terms.xml6240(glossterm) #: ./doc/glossary/glossary-terms.xml6242(primary)#: ./doc/glossary/glossary-terms.xml6246(para)#: ./doc/glossary/glossary-terms.xml6252(glossterm)#: ./doc/glossary/glossary-terms.xml6254(primary) #: ./doc/glossary/glossary-terms.xml6268(primary) #: ./doc/glossary/glossary-terms.xml8526(primary)#: ./doc/glossary/glossary-terms.xml6260(para)#: ./doc/glossary/glossary-terms.xml6266(glossterm) #: ./doc/glossary/glossary-terms.xml6270(secondary)#: ./doc/glossary/glossary-terms.xml6274(para)#: ./doc/glossary/glossary-terms.xml6279(glossterm)#: ./doc/glossary/glossary-terms.xml6281(primary)#: ./doc/glossary/glossary-terms.xml6285(para)#: ./doc/glossary/glossary-terms.xml6291(glossterm) #: ./doc/glossary/glossary-terms.xml6293(primary)#: ./doc/glossary/glossary-terms.xml6297(para)#: ./doc/glossary/glossary-terms.xml6303(glossterm) #: ./doc/glossary/glossary-terms.xml6310(primary)#: ./doc/glossary/glossary-terms.xml6307(secondary)#: ./doc/glossary/glossary-terms.xml6314(para)#: ./doc/glossary/glossary-terms.xml6320(glossterm)#: ./doc/glossary/glossary-terms.xml6324(secondary) #: ./doc/glossary/glossary-terms.xml6327(primary)#: ./doc/glossary/glossary-terms.xml6331(para)#: ./doc/glossary/glossary-terms.xml6343(glossterm)#: ./doc/glossary/glossary-terms.xml6345(primary) #: ./doc/glossary/glossary-terms.xml6359(primary) #: ./doc/glossary/glossary-terms.xml6373(primary)#: ./doc/glossary/glossary-terms.xml6351(para)#: ./doc/glossary/glossary-terms.xml6357(glossterm) #: ./doc/glossary/glossary-terms.xml6361(secondary)#: ./doc/glossary/glossary-terms.xml6365(para)#: ./doc/glossary/glossary-terms.xml6371(glossterm) #: ./doc/glossary/glossary-terms.xml6375(secondary)#: ./doc/glossary/glossary-terms.xml6379(para)#: ./doc/glossary/glossary-terms.xml6384(glossterm) #: ./doc/glossary/glossary-terms.xml6386(primary)#: ./doc/glossary/glossary-terms.xml6390(para)#: ./doc/glossary/glossary-terms.xml6397(glossterm) #: ./doc/glossary/glossary-terms.xml6399(primary)#: ./doc/glossary/glossary-terms.xml6403(para)#: ./doc/glossary/glossary-terms.xml6412(glossterm) #: ./doc/glossary/glossary-terms.xml6414(primary)#: ./doc/glossary/glossary-terms.xml6418(para)#: ./doc/glossary/glossary-terms.xml6424(glossterm)#: ./doc/glossary/glossary-terms.xml6428(secondary) #: ./doc/glossary/glossary-terms.xml6431(primary)#: ./doc/glossary/glossary-terms.xml6435(para)#: ./doc/glossary/glossary-terms.xml6440(glossterm)#: ./doc/glossary/glossary-terms.xml6444(secondary) #: ./doc/glossary/glossary-terms.xml6447(primary)#: ./doc/glossary/glossary-terms.xml6451(para)#: ./doc/glossary/glossary-terms.xml6458(glossterm) #: ./doc/glossary/glossary-terms.xml6465(primary)#: ./doc/glossary/glossary-terms.xml6462(secondary)#: ./doc/glossary/glossary-terms.xml6469(para)#: ./doc/glossary/glossary-terms.xml6475(glossterm) #: ./doc/glossary/glossary-terms.xml6482(primary)#: ./doc/glossary/glossary-terms.xml6479(secondary)#: ./doc/glossary/glossary-terms.xml6486(para)#: ./doc/glossary/glossary-terms.xml6492(glossterm) #: ./doc/glossary/glossary-terms.xml6499(primary)#: ./doc/glossary/glossary-terms.xml6496(secondary) #: ./doc/glossary/glossary-terms.xml6524(secondary)#: ./doc/glossary/glossary-terms.xml6503(para)#: ./doc/glossary/glossary-terms.xml6508(glossterm) #: ./doc/glossary/glossary-terms.xml6510(primary)#: ./doc/glossary/glossary-terms.xml6514(para)#: ./doc/glossary/glossary-terms.xml6520(glossterm) #: ./doc/glossary/glossary-terms.xml6527(primary)#: ./doc/glossary/glossary-terms.xml6531(para)#: ./doc/glossary/glossary-terms.xml6540(glossterm) #: ./doc/glossary/glossary-terms.xml6542(primary)#: ./doc/glossary/glossary-terms.xml6546(para)#: ./doc/glossary/glossary-terms.xml6552(glossterm) #: ./doc/glossary/glossary-terms.xml6554(primary)#: ./doc/glossary/glossary-terms.xml6558(para)#: ./doc/glossary/glossary-terms.xml6566(title)#: ./doc/glossary/glossary-terms.xml6569(glossterm) #: ./doc/glossary/glossary-terms.xml6571(primary)#: ./doc/glossary/glossary-terms.xml6581(glossterm) #: ./doc/glossary/glossary-terms.xml6583(primary)#: ./doc/glossary/glossary-terms.xml6587(para)#: ./doc/glossary/glossary-terms.xml6593(glossterm) #: ./doc/glossary/glossary-terms.xml6595(primary)#: ./doc/glossary/glossary-terms.xml6599(para)#: ./doc/glossary/glossary-terms.xml6606(glossterm) #: ./doc/glossary/glossary-terms.xml6608(primary)#: ./doc/glossary/glossary-terms.xml6612(para)#: ./doc/glossary/glossary-terms.xml6615(para)#: ./doc/glossary/glossary-terms.xml6621(glossterm)#: ./doc/glossary/glossary-terms.xml6623(primary)#: ./doc/glossary/glossary-terms.xml6627(para)#: ./doc/glossary/glossary-terms.xml6636(title)#: ./doc/glossary/glossary-terms.xml6639(glossterm) #: ./doc/glossary/glossary-terms.xml6641(primary)#: ./doc/glossary/glossary-terms.xml6645(para)#: ./doc/glossary/glossary-terms.xml6650(glossterm) #: ./doc/glossary/glossary-terms.xml6652(primary)#: ./doc/glossary/glossary-terms.xml6656(para)#: ./doc/glossary/glossary-terms.xml6662(glossterm) #: ./doc/glossary/glossary-terms.xml6664(primary)#: ./doc/glossary/glossary-terms.xml6668(para)#: ./doc/glossary/glossary-terms.xml6674(glossterm) #: ./doc/glossary/glossary-terms.xml6676(primary)#: ./doc/glossary/glossary-terms.xml6680(para)#: ./doc/glossary/glossary-terms.xml6687(glossterm) #: ./doc/glossary/glossary-terms.xml6689(primary)#: ./doc/glossary/glossary-terms.xml6693(para)#: ./doc/glossary/glossary-terms.xml6699(glossterm) #: ./doc/glossary/glossary-terms.xml6701(primary)#: ./doc/glossary/glossary-terms.xml6705(para)#: ./doc/glossary/glossary-terms.xml6713(glossterm)#: ./doc/glossary/glossary-terms.xml6715(primary)#: ./doc/glossary/glossary-terms.xml6719(para)#: ./doc/glossary/glossary-terms.xml6725(glossterm)#: ./doc/glossary/glossary-terms.xml6727(primary)#: ./doc/glossary/glossary-terms.xml6731(para)#: ./doc/glossary/glossary-terms.xml6737(glossterm)#: ./doc/glossary/glossary-terms.xml6739(primary)#: ./doc/glossary/glossary-terms.xml6743(para)#: ./doc/glossary/glossary-terms.xml6750(glossterm) #: ./doc/glossary/glossary-terms.xml6752(primary) #: ./doc/glossary/glossary-terms.xml7621(primary)#: ./doc/glossary/glossary-terms.xml6754(secondary) #: ./doc/glossary/glossary-terms.xml7623(secondary)#: ./doc/glossary/glossary-terms.xml6758(para)#: ./doc/glossary/glossary-terms.xml6768(glossterm)#: ./doc/glossary/glossary-terms.xml6770(primary)#: ./doc/glossary/glossary-terms.xml6774(para)#: ./doc/glossary/glossary-terms.xml6780(glossterm) #: ./doc/glossary/glossary-terms.xml6782(primary)#: ./doc/glossary/glossary-terms.xml6786(para)#: ./doc/glossary/glossary-terms.xml6791(glossterm)#: ./doc/glossary/glossary-terms.xml6793(primary) #: ./doc/glossary/glossary-terms.xml6812(primary)#: ./doc/glossary/glossary-terms.xml6799(para)#: ./doc/glossary/glossary-terms.xml6810(glossterm)#: ./doc/glossary/glossary-terms.xml6814(secondary)#: ./doc/glossary/glossary-terms.xml6818(para)#: ./doc/glossary/glossary-terms.xml6824(glossterm) #: ./doc/glossary/glossary-terms.xml6826(primary)#: ./doc/glossary/glossary-terms.xml6835(glossterm) #: ./doc/glossary/glossary-terms.xml6837(primary)#: ./doc/glossary/glossary-terms.xml6841(para)#: ./doc/glossary/glossary-terms.xml6846(glossterm) #: ./doc/glossary/glossary-terms.xml6848(primary)#: ./doc/glossary/glossary-terms.xml6852(para)#: ./doc/glossary/glossary-terms.xml6859(glossterm) #: ./doc/glossary/glossary-terms.xml6861(primary)#: ./doc/glossary/glossary-terms.xml6863(see)#: ./doc/glossary/glossary-terms.xml6867(para)#: ./doc/glossary/glossary-terms.xml6872(glossterm)#: ./doc/glossary/glossary-terms.xml6876(secondary) #: ./doc/glossary/glossary-terms.xml6879(primary)#: ./doc/glossary/glossary-terms.xml6883(para)#: ./doc/glossary/glossary-terms.xml6889(glossterm) #: ./doc/glossary/glossary-terms.xml6892(primary)#: ./doc/glossary/glossary-terms.xml6897(para)#: ./doc/glossary/glossary-terms.xml6903(glossterm) #: ./doc/glossary/glossary-terms.xml6905(primary)#: ./doc/glossary/glossary-terms.xml6909(para)#: ./doc/glossary/glossary-terms.xml6915(glossterm)#: ./doc/glossary/glossary-terms.xml6917(primary) #: ./doc/glossary/glossary-terms.xml6932(primary) #: ./doc/glossary/glossary-terms.xml6944(glossterm) #: ./doc/glossary/glossary-terms.xml6955(primary)#: ./doc/glossary/glossary-terms.xml6923(para)#: ./doc/glossary/glossary-terms.xml6930(glossterm) #: ./doc/glossary/glossary-terms.xml6934(secondary)#: ./doc/glossary/glossary-terms.xml6938(para)#: ./doc/glossary/glossary-terms.xml6947(para)#: ./doc/glossary/glossary-terms.xml6953(glossterm)#: ./doc/glossary/glossary-terms.xml6957(secondary)#: ./doc/glossary/glossary-terms.xml6961(para)#: ./doc/glossary/glossary-terms.xml6967(glossterm)#: ./doc/glossary/glossary-terms.xml6969(primary)#: ./doc/glossary/glossary-terms.xml6973(para)#: ./doc/glossary/glossary-terms.xml6978(glossterm)#: ./doc/glossary/glossary-terms.xml6980(primary)#: ./doc/glossary/glossary-terms.xml6984(para)#: ./doc/glossary/glossary-terms.xml6991(glossterm)#: ./doc/glossary/glossary-terms.xml6993(primary)#: ./doc/glossary/glossary-terms.xml6997(para)#: ./doc/glossary/glossary-terms.xml7005(glossterm)#: ./doc/glossary/glossary-terms.xml7007(primary)#: ./doc/glossary/glossary-terms.xml7011(para)#: ./doc/glossary/glossary-terms.xml7018(glossterm)#: ./doc/glossary/glossary-terms.xml7020(primary) #: ./doc/glossary/glossary-terms.xml7035(primary)#: ./doc/glossary/glossary-terms.xml7026(para)#: ./doc/glossary/glossary-terms.xml7033(glossterm)#: ./doc/glossary/glossary-terms.xml7037(secondary)#: ./doc/glossary/glossary-terms.xml7041(para)#: ./doc/glossary/glossary-terms.xml7048(glossterm) #: ./doc/glossary/glossary-terms.xml7050(primary)#: ./doc/glossary/glossary-terms.xml7054(para)#: ./doc/glossary/glossary-terms.xml7062(glossterm)#: ./doc/glossary/glossary-terms.xml7064(primary) #: ./doc/glossary/glossary-terms.xml7079(primary)#: ./doc/glossary/glossary-terms.xml7070(para)#: ./doc/glossary/glossary-terms.xml7077(glossterm) #: ./doc/glossary/glossary-terms.xml7081(secondary)#: ./doc/glossary/glossary-terms.xml7085(para)#: ./doc/glossary/glossary-terms.xml7090(glossterm) #: ./doc/glossary/glossary-terms.xml7092(primary)#: ./doc/glossary/glossary-terms.xml7096(para)#: ./doc/glossary/glossary-terms.xml7102(glossterm) #: ./doc/glossary/glossary-terms.xml7109(primary)#: ./doc/glossary/glossary-terms.xml7104(primary) #: ./doc/glossary/glossary-terms.xml7664(primary)#: ./doc/glossary/glossary-terms.xml7106(secondary)#: ./doc/glossary/glossary-terms.xml7113(para)#: ./doc/glossary/glossary-terms.xml7119(glossterm) #: ./doc/glossary/glossary-terms.xml7121(primary)#: ./doc/glossary/glossary-terms.xml7125(para)#: ./doc/glossary/glossary-terms.xml7131(glossterm)#: ./doc/glossary/glossary-terms.xml7133(primary)#: ./doc/glossary/glossary-terms.xml7137(para)#: ./doc/glossary/glossary-terms.xml7144(glossterm)#: ./doc/glossary/glossary-terms.xml7146(primary)#: ./doc/glossary/glossary-terms.xml7148(secondary) #: ./doc/glossary/glossary-terms.xml7151(primary)#: ./doc/glossary/glossary-terms.xml7155(para)#: ./doc/glossary/glossary-terms.xml7162(glossterm) #: ./doc/glossary/glossary-terms.xml7164(primary)#: ./doc/glossary/glossary-terms.xml7168(para)#: ./doc/glossary/glossary-terms.xml7173(glossterm)#: ./doc/glossary/glossary-terms.xml7175(primary)#: ./doc/glossary/glossary-terms.xml7179(para)#: ./doc/glossary/glossary-terms.xml7185(glossterm)#: ./doc/glossary/glossary-terms.xml7188(para)#: ./doc/glossary/glossary-terms.xml7194(glossterm) #: ./doc/glossary/glossary-terms.xml7196(primary)#: ./doc/glossary/glossary-terms.xml7200(para)#: ./doc/glossary/glossary-terms.xml7209(title)#: ./doc/glossary/glossary-terms.xml7212(glossterm)#: ./doc/glossary/glossary-terms.xml7214(primary)#: ./doc/glossary/glossary-terms.xml7218(para)#: ./doc/glossary/glossary-terms.xml7225(glossterm) #: ./doc/glossary/glossary-terms.xml7227(primary)#: ./doc/glossary/glossary-terms.xml7231(para)#: ./doc/glossary/glossary-terms.xml7237(glossterm) #: ./doc/glossary/glossary-terms.xml7239(primary)#: ./doc/glossary/glossary-terms.xml7243(para)#: ./doc/glossary/glossary-terms.xml7250(glossterm)#: ./doc/glossary/glossary-terms.xml7252(primary)#: ./doc/glossary/glossary-terms.xml7256(para)#: ./doc/glossary/glossary-terms.xml7262(glossterm)#: ./doc/glossary/glossary-terms.xml7264(primary)#: ./doc/glossary/glossary-terms.xml7268(para)#: ./doc/glossary/glossary-terms.xml7274(glossterm)#: ./doc/glossary/glossary-terms.xml7276(primary)#: ./doc/glossary/glossary-terms.xml7280(para)#: ./doc/glossary/glossary-terms.xml7286(glossterm) #: ./doc/glossary/glossary-terms.xml7288(primary)#: ./doc/glossary/glossary-terms.xml7292(para)#: ./doc/glossary/glossary-terms.xml7299(glossterm)#: ./doc/glossary/glossary-terms.xml7301(primary)#: ./doc/glossary/glossary-terms.xml7305(para)#: ./doc/glossary/glossary-terms.xml7311(glossterm)#: ./doc/glossary/glossary-terms.xml7315(secondary) #: ./doc/glossary/glossary-terms.xml7318(primary)#: ./doc/glossary/glossary-terms.xml7322(para)#: ./doc/glossary/glossary-terms.xml7329(glossterm) #: ./doc/glossary/glossary-terms.xml7331(primary)#: ./doc/glossary/glossary-terms.xml7335(para)#: ./doc/glossary/glossary-terms.xml7341(glossterm)#: ./doc/glossary/glossary-terms.xml7349(para)#: ./doc/glossary/glossary-terms.xml7353(para)#: ./doc/glossary/glossary-terms.xml7359(glossterm) #: ./doc/glossary/glossary-terms.xml7361(primary)#: ./doc/glossary/glossary-terms.xml7365(para)#: ./doc/glossary/glossary-terms.xml7370(glossterm) #: ./doc/glossary/glossary-terms.xml7374(secondary)#: ./doc/glossary/glossary-terms.xml7384(glossterm)#: ./doc/glossary/glossary-terms.xml7386(primary)#: ./doc/glossary/glossary-terms.xml7392(para)#: ./doc/glossary/glossary-terms.xml7399(glossterm) #: ./doc/glossary/glossary-terms.xml7401(primary)#: ./doc/glossary/glossary-terms.xml7405(para)#: ./doc/glossary/glossary-terms.xml7410(glossterm) #: ./doc/glossary/glossary-terms.xml7412(primary)#: ./doc/glossary/glossary-terms.xml7416(para)#: ./doc/glossary/glossary-terms.xml7422(glossterm) #: ./doc/glossary/glossary-terms.xml7424(primary)#: ./doc/glossary/glossary-terms.xml7428(para)#: ./doc/glossary/glossary-terms.xml7434(glossterm) #: ./doc/glossary/glossary-terms.xml7436(primary)#: ./doc/glossary/glossary-terms.xml7440(para)#: ./doc/glossary/glossary-terms.xml7446(glossterm) #: ./doc/glossary/glossary-terms.xml7448(primary)#: ./doc/glossary/glossary-terms.xml7452(para)#: ./doc/glossary/glossary-terms.xml7458(glossterm) #: ./doc/glossary/glossary-terms.xml7462(secondary)#: ./doc/glossary/glossary-terms.xml7460(primary) #: ./doc/glossary/glossary-terms.xml7474(primary) #: ./doc/glossary/glossary-terms.xml7489(primary)#: ./doc/glossary/glossary-terms.xml7466(para)#: ./doc/glossary/glossary-terms.xml7472(glossterm) #: ./doc/glossary/glossary-terms.xml7476(secondary)#: ./doc/glossary/glossary-terms.xml7480(para)#: ./doc/glossary/glossary-terms.xml7487(glossterm) #: ./doc/glossary/glossary-terms.xml7491(secondary)#: ./doc/glossary/glossary-terms.xml7495(para)#: ./doc/glossary/glossary-terms.xml7501(glossterm) #: ./doc/glossary/glossary-terms.xml7508(primary)#: ./doc/glossary/glossary-terms.xml7505(secondary)#: ./doc/glossary/glossary-terms.xml7512(para)#: ./doc/glossary/glossary-terms.xml7525(glossterm)#: ./doc/glossary/glossary-terms.xml7527(primary)#: ./doc/glossary/glossary-terms.xml7531(para)#: ./doc/glossary/glossary-terms.xml7540(glossterm) #: ./doc/glossary/glossary-terms.xml7542(primary)#: ./doc/glossary/glossary-terms.xml7546(para)#: ./doc/glossary/glossary-terms.xml7552(glossterm) #: ./doc/glossary/glossary-terms.xml7554(primary)#: ./doc/glossary/glossary-terms.xml7558(para)#: ./doc/glossary/glossary-terms.xml7564(glossterm) #: ./doc/glossary/glossary-terms.xml7567(primary)#: ./doc/glossary/glossary-terms.xml7571(para)#: ./doc/glossary/glossary-terms.xml7577(glossterm) #: ./doc/glossary/glossary-terms.xml7580(primary)#: ./doc/glossary/glossary-terms.xml7584(para)#: ./doc/glossary/glossary-terms.xml7594(glossterm) #: ./doc/glossary/glossary-terms.xml7596(primary)#: ./doc/glossary/glossary-terms.xml7600(para)#: ./doc/glossary/glossary-terms.xml7606(glossterm) #: ./doc/glossary/glossary-terms.xml7608(primary)#: ./doc/glossary/glossary-terms.xml7612(para)#: ./doc/glossary/glossary-terms.xml7619(glossterm) #: ./doc/glossary/glossary-terms.xml7626(primary)#: ./doc/glossary/glossary-terms.xml7630(para)#: ./doc/glossary/glossary-terms.xml7636(glossterm) #: ./doc/glossary/glossary-terms.xml7638(primary)#: ./doc/glossary/glossary-terms.xml7642(para)#: ./doc/glossary/glossary-terms.xml7648(glossterm)#: ./doc/glossary/glossary-terms.xml7650(primary)#: ./doc/glossary/glossary-terms.xml7655(para)#: ./doc/glossary/glossary-terms.xml7662(glossterm) #: ./doc/glossary/glossary-terms.xml7669(primary)#: ./doc/glossary/glossary-terms.xml7666(secondary)#: ./doc/glossary/glossary-terms.xml7673(para)#: ./doc/glossary/glossary-terms.xml7679(glossterm) #: ./doc/glossary/glossary-terms.xml7681(primary)#: ./doc/glossary/glossary-terms.xml7685(para)#: ./doc/glossary/glossary-terms.xml7690(glossterm) #: ./doc/glossary/glossary-terms.xml7692(primary)#: ./doc/glossary/glossary-terms.xml7696(para)#: ./doc/glossary/glossary-terms.xml7702(glossterm) #: ./doc/glossary/glossary-terms.xml7704(primary)#: ./doc/glossary/glossary-terms.xml7709(para)#: ./doc/glossary/glossary-terms.xml7717(glossterm) #: ./doc/glossary/glossary-terms.xml7719(primary)#: ./doc/glossary/glossary-terms.xml7723(para)#: ./doc/glossary/glossary-terms.xml7729(glossterm)#: ./doc/glossary/glossary-terms.xml7733(secondary)#: ./doc/glossary/glossary-terms.xml7736(primary)#: ./doc/glossary/glossary-terms.xml7740(para)#: ./doc/glossary/glossary-terms.xml7745(glossterm) #: ./doc/glossary/glossary-terms.xml7747(primary)#: ./doc/glossary/glossary-terms.xml7751(para)#: ./doc/glossary/glossary-terms.xml7757(glossterm) #: ./doc/glossary/glossary-terms.xml7759(primary)#: ./doc/glossary/glossary-terms.xml7763(para)#: ./doc/glossary/glossary-terms.xml7769(glossterm) #: ./doc/glossary/glossary-terms.xml7776(primary)#: ./doc/glossary/glossary-terms.xml7773(secondary)#: ./doc/glossary/glossary-terms.xml7780(para)#: ./doc/glossary/glossary-terms.xml7787(glossterm) #: ./doc/glossary/glossary-terms.xml7791(secondary)#: ./doc/glossary/glossary-terms.xml7789(primary) #: ./doc/glossary/glossary-terms.xml7803(primary) #: ./doc/glossary/glossary-terms.xml7817(primary) #: ./doc/glossary/glossary-terms.xml7966(primary)#: ./doc/glossary/glossary-terms.xml7795(para)#: ./doc/glossary/glossary-terms.xml7801(glossterm) #: ./doc/glossary/glossary-terms.xml7805(secondary)#: ./doc/glossary/glossary-terms.xml7809(para)#: ./doc/glossary/glossary-terms.xml7815(glossterm) #: ./doc/glossary/glossary-terms.xml7819(secondary)#: ./doc/glossary/glossary-terms.xml7823(para)#: ./doc/glossary/glossary-terms.xml7829(glossterm) #: ./doc/glossary/glossary-terms.xml7831(primary)#: ./doc/glossary/glossary-terms.xml7835(para)#: ./doc/glossary/glossary-terms.xml7841(glossterm)#: ./doc/glossary/glossary-terms.xml7843(primary)#: ./doc/glossary/glossary-terms.xml7847(para)#: ./doc/glossary/glossary-terms.xml7855(glossterm) #: ./doc/glossary/glossary-terms.xml7857(primary)#: ./doc/glossary/glossary-terms.xml7861(para)#: ./doc/glossary/glossary-terms.xml7866(glossterm) #: ./doc/glossary/glossary-terms.xml7869(primary)#: ./doc/glossary/glossary-terms.xml7878(glossterm)#: ./doc/glossary/glossary-terms.xml7880(primary)#: ./doc/glossary/glossary-terms.xml7884(para)#: ./doc/glossary/glossary-terms.xml7890(glossterm)#: ./doc/glossary/glossary-terms.xml7892(primary)#: ./doc/glossary/glossary-terms.xml7896(para)#: ./doc/glossary/glossary-terms.xml7902(glossterm) #: ./doc/glossary/glossary-terms.xml7904(primary)#: ./doc/glossary/glossary-terms.xml7908(para)#: ./doc/glossary/glossary-terms.xml7918(para)#: ./doc/glossary/glossary-terms.xml7924(glossterm) #: ./doc/glossary/glossary-terms.xml7926(primary)#: ./doc/glossary/glossary-terms.xml7930(para)#: ./doc/glossary/glossary-terms.xml7936(glossterm) #: ./doc/glossary/glossary-terms.xml7940(secondary)#: ./doc/glossary/glossary-terms.xml7944(para)#: ./doc/glossary/glossary-terms.xml7950(glossterm) #: ./doc/glossary/glossary-terms.xml7954(secondary)#: ./doc/glossary/glossary-terms.xml7958(para)#: ./doc/glossary/glossary-terms.xml7964(glossterm)#: ./doc/glossary/glossary-terms.xml7968(secondary) #: ./doc/glossary/glossary-terms.xml7973(secondary) #: ./doc/glossary/glossary-terms.xml7978(secondary)#: ./doc/glossary/glossary-terms.xml7982(para)#: ./doc/glossary/glossary-terms.xml7988(glossterm) #: ./doc/glossary/glossary-terms.xml7990(primary)#: ./doc/glossary/glossary-terms.xml7994(para)#: ./doc/glossary/glossary-terms.xml8000(glossterm) #: ./doc/glossary/glossary-terms.xml8002(primary)#: ./doc/glossary/glossary-terms.xml8006(para)#: ./doc/glossary/glossary-terms.xml8013(glossterm) #: ./doc/glossary/glossary-terms.xml8015(primary)#: ./doc/glossary/glossary-terms.xml8019(para)#: ./doc/glossary/glossary-terms.xml8029(title)#: ./doc/glossary/glossary-terms.xml8032(glossterm) #: ./doc/glossary/glossary-terms.xml8034(primary)#: ./doc/glossary/glossary-terms.xml8038(para)#: ./doc/glossary/glossary-terms.xml8045(glossterm) #: ./doc/glossary/glossary-terms.xml8047(primary)#: ./doc/glossary/glossary-terms.xml8051(para)#: ./doc/glossary/glossary-terms.xml8058(glossterm) #: ./doc/glossary/glossary-terms.xml8060(primary)#: ./doc/glossary/glossary-terms.xml8064(para)#: ./doc/glossary/glossary-terms.xml8070(glossterm) #: ./doc/glossary/glossary-terms.xml8072(primary)#: ./doc/glossary/glossary-terms.xml8076(para)#: ./doc/glossary/glossary-terms.xml8082(glossterm) #: ./doc/glossary/glossary-terms.xml8093(primary) #: ./doc/glossary/glossary-terms.xml8111(primary) #: ./doc/glossary/glossary-terms.xml8125(primary)#: ./doc/glossary/glossary-terms.xml8085(para)#: ./doc/glossary/glossary-terms.xml8091(glossterm) #: ./doc/glossary/glossary-terms.xml8095(secondary)#: ./doc/glossary/glossary-terms.xml8099(para)#: ./doc/glossary/glossary-terms.xml8104(glossterm) #: ./doc/glossary/glossary-terms.xml8108(secondary) #: ./doc/glossary/glossary-terms.xml8113(secondary)#: ./doc/glossary/glossary-terms.xml8117(para)#: ./doc/glossary/glossary-terms.xml8123(glossterm) #: ./doc/glossary/glossary-terms.xml8127(secondary)#: ./doc/glossary/glossary-terms.xml8131(para)#: ./doc/glossary/glossary-terms.xml8137(glossterm)#: ./doc/glossary/glossary-terms.xml8139(primary)#: ./doc/glossary/glossary-terms.xml8143(para)#: ./doc/glossary/glossary-terms.xml8149(glossterm) #: ./doc/glossary/glossary-terms.xml8151(primary)#: ./doc/glossary/glossary-terms.xml8155(para)#: ./doc/glossary/glossary-terms.xml8161(glossterm) #: ./doc/glossary/glossary-terms.xml8163(primary)#: ./doc/glossary/glossary-terms.xml8166(para)#: ./doc/glossary/glossary-terms.xml8174(glossterm) #: ./doc/glossary/glossary-terms.xml8176(primary)#: ./doc/glossary/glossary-terms.xml8180(para)#: ./doc/glossary/glossary-terms.xml8186(glossterm) #: ./doc/glossary/glossary-terms.xml8188(primary)#: ./doc/glossary/glossary-terms.xml8192(para)#: ./doc/glossary/glossary-terms.xml8198(glossterm)#: ./doc/glossary/glossary-terms.xml8200(primary)#: ./doc/glossary/glossary-terms.xml8204(para)#: ./doc/glossary/glossary-terms.xml8210(glossterm)#: ./doc/glossary/glossary-terms.xml8212(primary)#: ./doc/glossary/glossary-terms.xml8218(para)#: ./doc/glossary/glossary-terms.xml8223(glossterm)#: ./doc/glossary/glossary-terms.xml8226(para)#: ./doc/glossary/glossary-terms.xml8232(glossterm)#: ./doc/glossary/glossary-terms.xml8236(secondary) #: ./doc/glossary/glossary-terms.xml8239(primary)#: ./doc/glossary/glossary-terms.xml8243(para)#: ./doc/glossary/glossary-terms.xml8249(glossterm)#: ./doc/glossary/glossary-terms.xml8253(secondary) #: ./doc/glossary/glossary-terms.xml8256(primary)#: ./doc/glossary/glossary-terms.xml8260(para)#: ./doc/glossary/glossary-terms.xml8265(glossterm) #: ./doc/glossary/glossary-terms.xml8267(primary)#: ./doc/glossary/glossary-terms.xml8271(para)#: ./doc/glossary/glossary-terms.xml8279(glossterm) #: ./doc/glossary/glossary-terms.xml8281(primary)#: ./doc/glossary/glossary-terms.xml8285(para)#: ./doc/glossary/glossary-terms.xml8294(title)#: ./doc/glossary/glossary-terms.xml8297(glossterm) #: ./doc/glossary/glossary-terms.xml8299(primary)#: ./doc/glossary/glossary-terms.xml8303(para)#: ./doc/glossary/glossary-terms.xml8308(glossterm) #: ./doc/glossary/glossary-terms.xml8310(primary)#: ./doc/glossary/glossary-terms.xml8314(para)#: ./doc/glossary/glossary-terms.xml8319(glossterm)#: ./doc/glossary/glossary-terms.xml8321(primary)#: ./doc/glossary/glossary-terms.xml8325(para)#: ./doc/glossary/glossary-terms.xml8331(glossterm)#: ./doc/glossary/glossary-terms.xml8333(primary)#: ./doc/glossary/glossary-terms.xml8337(para)#: ./doc/glossary/glossary-terms.xml8344(glossterm) #: ./doc/glossary/glossary-terms.xml8346(primary)#: ./doc/glossary/glossary-terms.xml8350(para)#: ./doc/glossary/glossary-terms.xml8360(glossterm) #: ./doc/glossary/glossary-terms.xml8362(primary)#: ./doc/glossary/glossary-terms.xml8374(title)#: ./doc/glossary/glossary-terms.xml8377(glossterm) #: ./doc/glossary/glossary-terms.xml8379(primary)#: ./doc/glossary/glossary-terms.xml8383(para)#: ./doc/glossary/glossary-terms.xml8388(glossterm) #: ./doc/glossary/glossary-terms.xml8390(primary)#: ./doc/glossary/glossary-terms.xml8394(para)#: ./doc/glossary/glossary-terms.xml8404(glossterm) #: ./doc/glossary/glossary-terms.xml8407(primary)#: ./doc/glossary/glossary-terms.xml8411(para)#: ./doc/glossary/glossary-terms.xml8417(glossterm) #: ./doc/glossary/glossary-terms.xml8419(primary)#: ./doc/glossary/glossary-terms.xml8429(glossterm) #: ./doc/glossary/glossary-terms.xml8431(primary)#: ./doc/glossary/glossary-terms.xml8441(glossterm) #: ./doc/glossary/glossary-terms.xml8443(primary)#: ./doc/glossary/glossary-terms.xml8447(para)#: ./doc/glossary/glossary-terms.xml8455(glossterm) #: ./doc/glossary/glossary-terms.xml8457(primary)#: ./doc/glossary/glossary-terms.xml8461(para)#: ./doc/glossary/glossary-terms.xml8468(glossterm) #: ./doc/glossary/glossary-terms.xml8475(primary)#: ./doc/glossary/glossary-terms.xml8472(secondary) #: ./doc/glossary/glossary-terms.xml8528(secondary) #: ./doc/glossary/glossary-terms.xml8558(secondary)#: ./doc/glossary/glossary-terms.xml8479(para)#: ./doc/glossary/glossary-terms.xml8484(glossterm) #: ./doc/glossary/glossary-terms.xml8486(primary)#: ./doc/glossary/glossary-terms.xml8490(para)#: ./doc/glossary/glossary-terms.xml8499(glossterm) #: ./doc/glossary/glossary-terms.xml8501(primary)#: ./doc/glossary/glossary-terms.xml8505(para)#: ./doc/glossary/glossary-terms.xml8511(glossterm) #: ./doc/glossary/glossary-terms.xml8513(primary)#: ./doc/glossary/glossary-terms.xml8517(para)#: ./doc/glossary/glossary-terms.xml8524(glossterm) #: ./doc/glossary/glossary-terms.xml8531(primary)#: ./doc/glossary/glossary-terms.xml8535(para)#: ./doc/glossary/glossary-terms.xml8541(glossterm) #: ./doc/glossary/glossary-terms.xml8543(primary)#: ./doc/glossary/glossary-terms.xml8547(para)#: ./doc/glossary/glossary-terms.xml8554(glossterm)#: ./doc/glossary/glossary-terms.xml8561(primary)#: ./doc/glossary/glossary-terms.xml8565(para)#: ./doc/glossary/glossary-terms.xml8570(glossterm) #: ./doc/glossary/glossary-terms.xml8572(primary)#: ./doc/glossary/glossary-terms.xml8576(para)#: ./doc/glossary/glossary-terms.xml8582(glossterm) #: ./doc/glossary/glossary-terms.xml8584(primary)#: ./doc/glossary/glossary-terms.xml8588(para)#: ./doc/glossary/glossary-terms.xml8593(glossterm) #: ./doc/glossary/glossary-terms.xml8595(primary)#: ./doc/glossary/glossary-terms.xml8604(glossterm) #: ./doc/glossary/glossary-terms.xml8606(primary)#: ./doc/glossary/glossary-terms.xml8610(para)#: ./doc/glossary/glossary-terms.xml8616(glossterm) #: ./doc/glossary/glossary-terms.xml8623(primary)#: ./doc/glossary/glossary-terms.xml8620(secondary)#: ./doc/glossary/glossary-terms.xml8627(para)#: ./doc/glossary/glossary-terms.xml8637(glossterm) #: ./doc/glossary/glossary-terms.xml8639(primary)#: ./doc/glossary/glossary-terms.xml8649(glossterm) #: ./doc/glossary/glossary-terms.xml8651(primary)#: ./doc/glossary/glossary-terms.xml8655(para)#: ./doc/glossary/glossary-terms.xml8660(glossterm) #: ./doc/glossary/glossary-terms.xml8662(primary)#: ./doc/glossary/glossary-terms.xml8666(para)#: ./doc/glossary/glossary-terms.xml8672(glossterm) #: ./doc/glossary/glossary-terms.xml8674(primary)#: ./doc/glossary/glossary-terms.xml8678(para)#: ./doc/glossary/glossary-terms.xml8683(glossterm)#: ./doc/glossary/glossary-terms.xml8686(para)#: ./doc/glossary/glossary-terms.xml8691(glossterm) #: ./doc/glossary/glossary-terms.xml8693(primary)#: ./doc/glossary/glossary-terms.xml8697(para)#: ./doc/glossary/glossary-terms.xml8703(glossterm) #: ./doc/glossary/glossary-terms.xml8715(primary) #: ./doc/glossary/glossary-terms.xml8728(primary) #: ./doc/glossary/glossary-terms.xml8742(primary) #: ./doc/glossary/glossary-terms.xml8755(primary) #: ./doc/glossary/glossary-terms.xml8769(primary) #: ./doc/glossary/glossary-terms.xml8783(primary) #: ./doc/glossary/glossary-terms.xml8797(primary)#: ./doc/glossary/glossary-terms.xml8706(para)#: ./doc/glossary/glossary-terms.xml8713(glossterm) #: ./doc/glossary/glossary-terms.xml8717(secondary)#: ./doc/glossary/glossary-terms.xml8721(para)#: ./doc/glossary/glossary-terms.xml8726(glossterm) #: ./doc/glossary/glossary-terms.xml8730(secondary)#: ./doc/glossary/glossary-terms.xml8734(para)#: ./doc/glossary/glossary-terms.xml8740(glossterm) #: ./doc/glossary/glossary-terms.xml8744(secondary)#: ./doc/glossary/glossary-terms.xml8748(para)#: ./doc/glossary/glossary-terms.xml8753(glossterm) #: ./doc/glossary/glossary-terms.xml8757(secondary)#: ./doc/glossary/glossary-terms.xml8761(para)#: ./doc/glossary/glossary-terms.xml8767(glossterm) #: ./doc/glossary/glossary-terms.xml8771(secondary)#: ./doc/glossary/glossary-terms.xml8775(para)#: ./doc/glossary/glossary-terms.xml8781(glossterm) #: ./doc/glossary/glossary-terms.xml8785(secondary)#: ./doc/glossary/glossary-terms.xml8789(para)#: ./doc/glossary/glossary-terms.xml8795(glossterm) #: ./doc/glossary/glossary-terms.xml8799(secondary)#: ./doc/glossary/glossary-terms.xml8803(para)#: ./doc/glossary/glossary-terms.xml8809(glossterm)#: ./doc/glossary/glossary-terms.xml8811(primary)#: ./doc/glossary/glossary-terms.xml8815(para)#: ./doc/glossary/glossary-terms.xml8823(glossterm) #: ./doc/glossary/glossary-terms.xml8825(primary)#: ./doc/glossary/glossary-terms.xml8837(title)#: ./doc/glossary/glossary-terms.xml8840(glossterm) #: ./doc/glossary/glossary-terms.xml8842(primary)#: ./doc/glossary/glossary-terms.xml8846(para)#: ./doc/glossary/glossary-terms.xml8853(glossterm) #: ./doc/glossary/glossary-terms.xml8855(primary)#: ./doc/glossary/glossary-terms.xml8859(para)#: ./doc/glossary/glossary-terms.xml8865(glossterm) #: ./doc/glossary/glossary-terms.xml8867(primary)#: ./doc/glossary/glossary-terms.xml8871(para)#: ./doc/glossary/glossary-terms.xml8877(glossterm)#: ./doc/glossary/glossary-terms.xml8879(primary)#: ./doc/glossary/glossary-terms.xml8883(para)#: ./doc/glossary/glossary-terms.xml8894(title)#: ./doc/glossary/glossary-terms.xml8897(glossterm) #: ./doc/glossary/glossary-terms.xml8899(primary)#: ./doc/glossary/glossary-terms.xml8903(para)#: ./doc/glossary/glossary-terms.xml8913(glossterm) #: ./doc/glossary/glossary-terms.xml8924(primary) #: ./doc/glossary/glossary-terms.xml8937(primary) #: ./doc/glossary/glossary-terms.xml8951(primary)#: ./doc/glossary/glossary-terms.xml8916(para)#: ./doc/glossary/glossary-terms.xml8922(glossterm) #: ./doc/glossary/glossary-terms.xml8926(secondary)#: ./doc/glossary/glossary-terms.xml8935(glossterm) #: ./doc/glossary/glossary-terms.xml8939(secondary)#: ./doc/glossary/glossary-terms.xml8943(para)#: ./doc/glossary/glossary-terms.xml8949(glossterm)#: ./doc/glossary/glossary-terms.xml8953(secondary)#: ./doc/glossary/glossary-terms.xml8965(title)#: ./doc/glossary/glossary-terms.xml8979(title)#: ./doc/glossary/glossary-terms.xml8982(glossterm) #: ./doc/glossary/glossary-terms.xml8984(primary)#: ./doc/glossary/glossary-terms.xml8988(para)#: ./doc/glossary/glossary-terms.xml8994(glossterm) #: ./doc/glossary/glossary-terms.xml8996(primary)#: ./doc/glossary/glossary-terms.xml9000(para)",1504,1459
openstack%2Fsecurity-doc~master~Ic6266e4e901d008f9f4d3bb350750f0d1f376545,openstack/security-doc,master,Ic6266e4e901d008f9f4d3bb350750f0d1f376545,Updated from openstack-manuals,MERGED,2014-10-18 09:21:29.000000000,2014-10-20 06:51:54.000000000,2014-10-20 06:51:54.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-18 09:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/bc329e547c2da4ed1c21badce182e376049a5cfd', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ic6266e4e901d008f9f4d3bb350750f0d1f376545\n'}, {'number': 2, 'created': '2014-10-20 06:38:09.000000000', 'files': ['glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/22e5d56bcf7924b27f54d8ee084f350cb6b61808', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ic6266e4e901d008f9f4d3bb350750f0d1f376545\n'}]",0,129427,22e5d56bcf7924b27f54d8ee084f350cb6b61808,10,2,2,11131,,,0,"Updated from openstack-manuals

Change-Id: Ic6266e4e901d008f9f4d3bb350750f0d1f376545
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/27/129427/1 && git format-patch -1 --stdout FETCH_HEAD,['glossary/locale/ja.po'],1,bc329e547c2da4ed1c21badce182e376049a5cfd,openstack/openstack-manuals,"""POT-Creation-Date: 2014-10-17 12:39+0000\n"" ""PO-Revision-Date: 2014-10-17 12:36+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""#: ./doc/glossary/glossary-terms.xml4986(see)#: ./doc/glossary/glossary-terms.xml3298(secondary) #: ./doc/glossary/glossary-terms.xml3941(secondary) #: ./doc/glossary/glossary-terms.xml3993(secondary) #: ./doc/glossary/glossary-terms.xml4112(secondary) #: ./doc/glossary/glossary-terms.xml4329(secondary) #: ./doc/glossary/glossary-terms.xml4494(secondary) #: ./doc/glossary/glossary-terms.xml4512(secondary) #: ./doc/glossary/glossary-terms.xml5023(secondary) #: ./doc/glossary/glossary-terms.xml5371(secondary) #: ./doc/glossary/glossary-terms.xml5624(secondary) #: ./doc/glossary/glossary-terms.xml5740(secondary) #: ./doc/glossary/glossary-terms.xml6097(secondary) #: ./doc/glossary/glossary-terms.xml6282(secondary) #: ./doc/glossary/glossary-terms.xml6373(secondary) #: ./doc/glossary/glossary-terms.xml6945(secondary) #: ./doc/glossary/glossary-terms.xml7048(secondary) #: ./doc/glossary/glossary-terms.xml7092(secondary) #: ./doc/glossary/glossary-terms.xml7383(secondary) #: ./doc/glossary/glossary-terms.xml7426(secondary)#: ./doc/glossary/glossary-terms.xml3571(primary) #: ./doc/glossary/glossary-terms.xml8157(primary)#: ./doc/glossary/glossary-terms.xml6486(primary)#: ./doc/glossary/glossary-terms.xml6468(primary) #: ./doc/glossary/glossary-terms.xml6900(primary) #: ./doc/glossary/glossary-terms.xml7381(primary) #: ./doc/glossary/glossary-terms.xml7410(primary) #: ./doc/glossary/glossary-terms.xml8607(primary)#: ./doc/glossary/glossary-terms.xml6077(primary)#: ./doc/glossary/glossary-terms.xml6027(para) #: ./doc/glossary/glossary-terms.xml6856(para) #: ./doc/glossary/glossary-terms.xml7924(para)#: ./doc/glossary/glossary-terms.xml5706(secondary)#: ./doc/glossary/glossary-terms.xml5035(primary) #: ./doc/glossary/glossary-terms.xml5738(primary) #: ./doc/glossary/glossary-terms.xml5752(primary) #: ./doc/glossary/glossary-terms.xml5766(primary) #: ./doc/glossary/glossary-terms.xml5781(primary) #: ./doc/glossary/glossary-terms.xml5794(primary) #: ./doc/glossary/glossary-terms.xml5808(primary) #: ./doc/glossary/glossary-terms.xml5822(primary) #: ./doc/glossary/glossary-terms.xml5877(primary) #: ./doc/glossary/glossary-terms.xml7351(primary)#: ./doc/glossary/glossary-terms.xml3845(secondary) #: ./doc/glossary/glossary-terms.xml3975(secondary) #: ./doc/glossary/glossary-terms.xml4055(secondary) #: ./doc/glossary/glossary-terms.xml4070(secondary) #: ./doc/glossary/glossary-terms.xml5986(secondary) #: ./doc/glossary/glossary-terms.xml6821(secondary)#: ./doc/glossary/glossary-terms.xml5671(see)#: ./doc/glossary/glossary-terms.xml4909(para) #: ./doc/glossary/glossary-terms.xml8417(para) #: ./doc/glossary/glossary-terms.xml8650(para) #: ./doc/glossary/glossary-terms.xml8880(para) #: ./doc/glossary/glossary-terms.xml8981(para) #: ./doc/glossary/glossary-terms.xml9008(para)#: ./doc/glossary/glossary-terms.xml8302(primary)msgid ""federated identity"" msgstr """" #: ./doc/glossary/glossary-terms.xml3242(para) msgid """" ""A method to establish trusts between identity providers and the OpenStack "" ""cloud."" msgstr """" #: ./doc/glossary/glossary-terms.xml3248(glossterm) #: ./doc/glossary/glossary-terms.xml3250(primary)#: ./doc/glossary/glossary-terms.xml3254(para)#: ./doc/glossary/glossary-terms.xml3259(glossterm) #: ./doc/glossary/glossary-terms.xml3261(primary)#: ./doc/glossary/glossary-terms.xml3265(para)#: ./doc/glossary/glossary-terms.xml3271(glossterm) #: ./doc/glossary/glossary-terms.xml3273(primary)#: ./doc/glossary/glossary-terms.xml3277(para)#: ./doc/glossary/glossary-terms.xml3282(glossterm) #: ./doc/glossary/glossary-terms.xml3284(primary)#: ./doc/glossary/glossary-terms.xml3288(para)#: ./doc/glossary/glossary-terms.xml3294(glossterm)#: ./doc/glossary/glossary-terms.xml3296(primary) #: ./doc/glossary/glossary-terms.xml4284(primary)#: ./doc/glossary/glossary-terms.xml3302(para)#: ./doc/glossary/glossary-terms.xml3308(glossterm)#: ./doc/glossary/glossary-terms.xml3310(primary)#: ./doc/glossary/glossary-terms.xml3314(para)#: ./doc/glossary/glossary-terms.xml3321(glossterm) #: ./doc/glossary/glossary-terms.xml3323(primary)#: ./doc/glossary/glossary-terms.xml3327(para)#: ./doc/glossary/glossary-terms.xml3333(glossterm)#: ./doc/glossary/glossary-terms.xml3335(primary) #: ./doc/glossary/glossary-terms.xml3430(primary) #: ./doc/glossary/glossary-terms.xml4510(primary) #: ./doc/glossary/glossary-terms.xml6331(primary) #: ./doc/glossary/glossary-terms.xml6520(primary) #: ./doc/glossary/glossary-terms.xml7554(primary) #: ./doc/glossary/glossary-terms.xml7782(primary)#: ./doc/glossary/glossary-terms.xml3337(secondary)#: ./doc/glossary/glossary-terms.xml3340(primary)#: ./doc/glossary/glossary-terms.xml3344(para)#: ./doc/glossary/glossary-terms.xml3352(glossterm) #: ./doc/glossary/glossary-terms.xml3354(primary)#: ./doc/glossary/glossary-terms.xml3358(para)#: ./doc/glossary/glossary-terms.xml3365(glossterm) #: ./doc/glossary/glossary-terms.xml3367(primary)#: ./doc/glossary/glossary-terms.xml3371(para)#: ./doc/glossary/glossary-terms.xml3378(glossterm) #: ./doc/glossary/glossary-terms.xml3380(primary)#: ./doc/glossary/glossary-terms.xml3384(para)#: ./doc/glossary/glossary-terms.xml3393(glossterm) #: ./doc/glossary/glossary-terms.xml3395(primary)#: ./doc/glossary/glossary-terms.xml3399(para)#: ./doc/glossary/glossary-terms.xml3405(glossterm) #: ./doc/glossary/glossary-terms.xml3407(primary)#: ./doc/glossary/glossary-terms.xml3411(para)#: ./doc/glossary/glossary-terms.xml3416(glossterm) #: ./doc/glossary/glossary-terms.xml3418(primary)#: ./doc/glossary/glossary-terms.xml3422(para)#: ./doc/glossary/glossary-terms.xml3428(glossterm) #: ./doc/glossary/glossary-terms.xml3435(primary)#: ./doc/glossary/glossary-terms.xml3432(secondary)#: ./doc/glossary/glossary-terms.xml3439(para)#: ./doc/glossary/glossary-terms.xml3448(glossterm) #: ./doc/glossary/glossary-terms.xml3450(primary)#: ./doc/glossary/glossary-terms.xml3454(para)#: ./doc/glossary/glossary-terms.xml3459(para)#: ./doc/glossary/glossary-terms.xml3467(glossterm) #: ./doc/glossary/glossary-terms.xml3469(primary)#: ./doc/glossary/glossary-terms.xml3473(para)#: ./doc/glossary/glossary-terms.xml3479(glossterm)#: ./doc/glossary/glossary-terms.xml3481(primary)#: ./doc/glossary/glossary-terms.xml3485(para)#: ./doc/glossary/glossary-terms.xml3494(title)#: ./doc/glossary/glossary-terms.xml3497(glossterm) #: ./doc/glossary/glossary-terms.xml3499(primary)#: ./doc/glossary/glossary-terms.xml3503(para)#: ./doc/glossary/glossary-terms.xml3509(glossterm) #: ./doc/glossary/glossary-terms.xml3511(primary)#: ./doc/glossary/glossary-terms.xml3514(para)#: ./doc/glossary/glossary-terms.xml3521(glossterm) #: ./doc/glossary/glossary-terms.xml3523(primary)#: ./doc/glossary/glossary-terms.xml3526(para)#: ./doc/glossary/glossary-terms.xml3533(glossterm) #: ./doc/glossary/glossary-terms.xml3543(primary) #: ./doc/glossary/glossary-terms.xml3558(primary)#: ./doc/glossary/glossary-terms.xml3536(para)#: ./doc/glossary/glossary-terms.xml3541(glossterm) #: ./doc/glossary/glossary-terms.xml3545(secondary)#: ./doc/glossary/glossary-terms.xml3549(para)#: ./doc/glossary/glossary-terms.xml3556(glossterm) #: ./doc/glossary/glossary-terms.xml3560(secondary)#: ./doc/glossary/glossary-terms.xml3564(para)#: ./doc/glossary/glossary-terms.xml3569(glossterm) #: ./doc/glossary/glossary-terms.xml3573(secondary) #: ./doc/glossary/glossary-terms.xml3576(primary)#: ./doc/glossary/glossary-terms.xml3580(para)#: ./doc/glossary/glossary-terms.xml3586(glossterm) #: ./doc/glossary/glossary-terms.xml3588(primary)#: ./doc/glossary/glossary-terms.xml3592(para)#: ./doc/glossary/glossary-terms.xml3598(glossterm) #: ./doc/glossary/glossary-terms.xml3600(primary)#: ./doc/glossary/glossary-terms.xml3604(para)#: ./doc/glossary/glossary-terms.xml3611(glossterm) #: ./doc/glossary/glossary-terms.xml3613(primary)#: ./doc/glossary/glossary-terms.xml3617(para)#: ./doc/glossary/glossary-terms.xml3623(glossterm) #: ./doc/glossary/glossary-terms.xml3625(primary)#: ./doc/glossary/glossary-terms.xml3629(para)#: ./doc/glossary/glossary-terms.xml3635(glossterm) #: ./doc/glossary/glossary-terms.xml3637(primary)#: ./doc/glossary/glossary-terms.xml3641(para)#: ./doc/glossary/glossary-terms.xml3648(glossterm) #: ./doc/glossary/glossary-terms.xml3650(primary)#: ./doc/glossary/glossary-terms.xml3654(para)#: ./doc/glossary/glossary-terms.xml3662(glossterm) #: ./doc/glossary/glossary-terms.xml3664(primary)#: ./doc/glossary/glossary-terms.xml3668(para)#: ./doc/glossary/glossary-terms.xml3677(title)#: ./doc/glossary/glossary-terms.xml3680(glossterm) #: ./doc/glossary/glossary-terms.xml3682(primary)#: ./doc/glossary/glossary-terms.xml3686(para)#: ./doc/glossary/glossary-terms.xml3692(glossterm) #: ./doc/glossary/glossary-terms.xml3694(primary)#: ./doc/glossary/glossary-terms.xml3698(para)#: ./doc/glossary/glossary-terms.xml3704(glossterm) #: ./doc/glossary/glossary-terms.xml3706(primary)#: ./doc/glossary/glossary-terms.xml3710(para)#: ./doc/glossary/glossary-terms.xml3717(glossterm) #: ./doc/glossary/glossary-terms.xml3719(primary)#: ./doc/glossary/glossary-terms.xml3723(para)#: ./doc/glossary/glossary-terms.xml3730(glossterm) #: ./doc/glossary/glossary-terms.xml3732(primary)#: ./doc/glossary/glossary-terms.xml3736(para)#: ./doc/glossary/glossary-terms.xml3742(glossterm) #: ./doc/glossary/glossary-terms.xml3744(primary) #: ./doc/glossary/glossary-terms.xml7756(see)#: ./doc/glossary/glossary-terms.xml3748(para)#: ./doc/glossary/glossary-terms.xml3753(glossterm) #: ./doc/glossary/glossary-terms.xml3755(primary)#: ./doc/glossary/glossary-terms.xml3759(para)#: ./doc/glossary/glossary-terms.xml3769(glossterm) #: ./doc/glossary/glossary-terms.xml3771(primary)#: ./doc/glossary/glossary-terms.xml3775(para)#: ./doc/glossary/glossary-terms.xml3786(glossterm)#: ./doc/glossary/glossary-terms.xml3789(para)#: ./doc/glossary/glossary-terms.xml3795(glossterm)#: ./doc/glossary/glossary-terms.xml3797(primary)#: ./doc/glossary/glossary-terms.xml3801(para)#: ./doc/glossary/glossary-terms.xml3806(glossterm)#: ./doc/glossary/glossary-terms.xml3808(primary)#: ./doc/glossary/glossary-terms.xml3812(para)#: ./doc/glossary/glossary-terms.xml3817(glossterm) #: ./doc/glossary/glossary-terms.xml3819(primary)#: ./doc/glossary/glossary-terms.xml3823(para)#: ./doc/glossary/glossary-terms.xml3829(glossterm) #: ./doc/glossary/glossary-terms.xml3831(primary)#: ./doc/glossary/glossary-terms.xml3835(para)#: ./doc/glossary/glossary-terms.xml3841(glossterm)#: ./doc/glossary/glossary-terms.xml3843(primary)#: ./doc/glossary/glossary-terms.xml3849(para)#: ./doc/glossary/glossary-terms.xml3859(glossterm)#: ./doc/glossary/glossary-terms.xml3861(primary)#: ./doc/glossary/glossary-terms.xml3865(para)#: ./doc/glossary/glossary-terms.xml3876(glossterm) #: ./doc/glossary/glossary-terms.xml3878(primary)#: ./doc/glossary/glossary-terms.xml3882(para)#: ./doc/glossary/glossary-terms.xml3894(glossterm) #: ./doc/glossary/glossary-terms.xml3896(primary)#: ./doc/glossary/glossary-terms.xml3900(para)#: ./doc/glossary/glossary-terms.xml3905(glossterm) #: ./doc/glossary/glossary-terms.xml3907(primary)#: ./doc/glossary/glossary-terms.xml3911(para)#: ./doc/glossary/glossary-terms.xml3918(glossterm)#: ./doc/glossary/glossary-terms.xml3921(para)#: ./doc/glossary/glossary-terms.xml3927(glossterm)#: ./doc/glossary/glossary-terms.xml3930(para)#: ./doc/glossary/glossary-terms.xml3937(glossterm)#: ./doc/glossary/glossary-terms.xml3939(primary) #: ./doc/glossary/glossary-terms.xml3953(primary)#: ./doc/glossary/glossary-terms.xml3945(para)#: ./doc/glossary/glossary-terms.xml3951(glossterm)#: ./doc/glossary/glossary-terms.xml3955(secondary)#: ./doc/glossary/glossary-terms.xml3959(para)#: ./doc/glossary/glossary-terms.xml3968(title)#: ./doc/glossary/glossary-terms.xml3971(glossterm)#: ./doc/glossary/glossary-terms.xml3973(primary)#: ./doc/glossary/glossary-terms.xml3979(para)#: ./doc/glossary/glossary-terms.xml3989(glossterm) #: ./doc/glossary/glossary-terms.xml3991(primary)#: ./doc/glossary/glossary-terms.xml3997(para)#: ./doc/glossary/glossary-terms.xml4004(glossterm)#: ./doc/glossary/glossary-terms.xml4006(primary)#: ./doc/glossary/glossary-terms.xml4010(para)#: ./doc/glossary/glossary-terms.xml4018(glossterm) #: ./doc/glossary/glossary-terms.xml4020(primary)#: ./doc/glossary/glossary-terms.xml4024(para)#: ./doc/glossary/glossary-terms.xml4030(glossterm)#: ./doc/glossary/glossary-terms.xml4033(para)#: ./doc/glossary/glossary-terms.xml4038(glossterm) #: ./doc/glossary/glossary-terms.xml4042(secondary)#: ./doc/glossary/glossary-terms.xml4040(primary) #: ./doc/glossary/glossary-terms.xml4066(glossterm) #: ./doc/glossary/glossary-terms.xml4068(primary) #: ./doc/glossary/glossary-terms.xml4085(primary) #: ./doc/glossary/glossary-terms.xml4156(primary)#: ./doc/glossary/glossary-terms.xml4046(para)#: ./doc/glossary/glossary-terms.xml4052(glossterm) #: ./doc/glossary/glossary-terms.xml4054(primary) msgid ""identity provider"" msgstr """" #: ./doc/glossary/glossary-terms.xml4059(para) msgid """" ""A directory service, which allows users to login with a user name and "" ""password. It is a typical source of authentication tokens."" msgstr """" #: ./doc/glossary/glossary-terms.xml4074(para)#: ./doc/glossary/glossary-terms.xml4083(glossterm) #: ./doc/glossary/glossary-terms.xml4087(secondary)#: ./doc/glossary/glossary-terms.xml4091(para)#: ./doc/glossary/glossary-terms.xml4097(glossterm)#: ./doc/glossary/glossary-terms.xml4099(primary)#: ./doc/glossary/glossary-terms.xml4103(para)#: ./doc/glossary/glossary-terms.xml4108(glossterm)#: ./doc/glossary/glossary-terms.xml4110(primary)#: ./doc/glossary/glossary-terms.xml4116(para)#: ./doc/glossary/glossary-terms.xml4125(glossterm)#: ./doc/glossary/glossary-terms.xml4127(primary) #: ./doc/glossary/glossary-terms.xml4141(primary) #: ./doc/glossary/glossary-terms.xml4170(primary) #: ./doc/glossary/glossary-terms.xml4184(primary) #: ./doc/glossary/glossary-terms.xml4198(primary) #: ./doc/glossary/glossary-terms.xml4210(glossterm) #: ./doc/glossary/glossary-terms.xml4230(primary) #: ./doc/glossary/glossary-terms.xml4244(primary) #: ./doc/glossary/glossary-terms.xml4258(primary) #: ./doc/glossary/glossary-terms.xml6503(primary)#: ./doc/glossary/glossary-terms.xml4129(secondary) #: ./doc/glossary/glossary-terms.xml4220(glossterm)#: ./doc/glossary/glossary-terms.xml4133(para)#: ./doc/glossary/glossary-terms.xml4139(glossterm) #: ./doc/glossary/glossary-terms.xml4143(secondary)#: ./doc/glossary/glossary-terms.xml4147(para)#: ./doc/glossary/glossary-terms.xml4154(glossterm) #: ./doc/glossary/glossary-terms.xml4158(secondary)#: ./doc/glossary/glossary-terms.xml4162(para)#: ./doc/glossary/glossary-terms.xml4168(glossterm) #: ./doc/glossary/glossary-terms.xml4172(secondary)#: ./doc/glossary/glossary-terms.xml4176(para) #: ./doc/glossary/glossary-terms.xml5121(para)#: ./doc/glossary/glossary-terms.xml4182(glossterm) #: ./doc/glossary/glossary-terms.xml4186(secondary)#: ./doc/glossary/glossary-terms.xml4190(para)#: ./doc/glossary/glossary-terms.xml4196(glossterm) #: ./doc/glossary/glossary-terms.xml4200(secondary)#: ./doc/glossary/glossary-terms.xml4204(para)#: ./doc/glossary/glossary-terms.xml4213(para)#: ./doc/glossary/glossary-terms.xml4223(para)#: ./doc/glossary/glossary-terms.xml4228(glossterm) #: ./doc/glossary/glossary-terms.xml4232(secondary)#: ./doc/glossary/glossary-terms.xml4236(para)#: ./doc/glossary/glossary-terms.xml4242(glossterm) #: ./doc/glossary/glossary-terms.xml4246(secondary)#: ./doc/glossary/glossary-terms.xml4250(para)#: ./doc/glossary/glossary-terms.xml4256(glossterm) #: ./doc/glossary/glossary-terms.xml4260(secondary)#: ./doc/glossary/glossary-terms.xml4264(para)#: ./doc/glossary/glossary-terms.xml4270(glossterm)#: ./doc/glossary/glossary-terms.xml4272(primary)#: ./doc/glossary/glossary-terms.xml4276(para)#: ./doc/glossary/glossary-terms.xml4282(glossterm) #: ./doc/glossary/glossary-terms.xml4286(secondary) #: ./doc/glossary/glossary-terms.xml4289(primary)#: ./doc/glossary/glossary-terms.xml4293(para)#: ./doc/glossary/glossary-terms.xml4299(glossterm) #: ./doc/glossary/glossary-terms.xml4301(primary)#: ./doc/glossary/glossary-terms.xml4304(para)#: ./doc/glossary/glossary-terms.xml4313(glossterm) #: ./doc/glossary/glossary-terms.xml4315(primary)#: ./doc/glossary/glossary-terms.xml4319(para)#: ./doc/glossary/glossary-terms.xml4325(glossterm)#: ./doc/glossary/glossary-terms.xml4327(primary) #: ./doc/glossary/glossary-terms.xml4341(primary) #: ./doc/glossary/glossary-terms.xml4354(primary) #: ./doc/glossary/glossary-terms.xml4378(primary) #: ./doc/glossary/glossary-terms.xml4393(primary) #: ./doc/glossary/glossary-terms.xml4406(primary)#: ./doc/glossary/glossary-terms.xml4333(para)#: ./doc/glossary/glossary-terms.xml4339(glossterm) #: ./doc/glossary/glossary-terms.xml4343(secondary)#: ./doc/glossary/glossary-terms.xml4347(para)#: ./doc/glossary/glossary-terms.xml4352(glossterm) #: ./doc/glossary/glossary-terms.xml4356(secondary)#: ./doc/glossary/glossary-terms.xml4360(para)#: ./doc/glossary/glossary-terms.xml4365(glossterm) #: ./doc/glossary/glossary-terms.xml4367(primary)#: ./doc/glossary/glossary-terms.xml4370(para)#: ./doc/glossary/glossary-terms.xml4376(glossterm) #: ./doc/glossary/glossary-terms.xml4380(secondary)#: ./doc/glossary/glossary-terms.xml4384(para)#: ./doc/glossary/glossary-terms.xml4391(glossterm) #: ./doc/glossary/glossary-terms.xml4395(secondary)#: ./doc/glossary/glossary-terms.xml4399(para)#: ./doc/glossary/glossary-terms.xml4404(glossterm) #: ./doc/glossary/glossary-terms.xml4408(secondary)#: ./doc/glossary/glossary-terms.xml4412(para) #: ./doc/glossary/glossary-terms.xml7416(para)#: ./doc/glossary/glossary-terms.xml4418(glossterm) #: ./doc/glossary/glossary-terms.xml4420(primary)#: ./doc/glossary/glossary-terms.xml4424(para)#: ./doc/glossary/glossary-terms.xml4430(glossterm) #: ./doc/glossary/glossary-terms.xml4432(primary)#: ./doc/glossary/glossary-terms.xml4436(para)#: ./doc/glossary/glossary-terms.xml4442(glossterm) #: ./doc/glossary/glossary-terms.xml4444(primary)#: ./doc/glossary/glossary-terms.xml4448(para)#: ./doc/glossary/glossary-terms.xml4454(glossterm) #: ./doc/glossary/glossary-terms.xml4456(primary)#: ./doc/glossary/glossary-terms.xml4460(para)#: ./doc/glossary/glossary-terms.xml4466(glossterm) #: ./doc/glossary/glossary-terms.xml4468(primary)#: ./doc/glossary/glossary-terms.xml4472(para)#: ./doc/glossary/glossary-terms.xml4478(glossterm) #: ./doc/glossary/glossary-terms.xml4480(primary)#: ./doc/glossary/glossary-terms.xml4484(para)#: ./doc/glossary/glossary-terms.xml4490(glossterm) #: ./doc/glossary/glossary-terms.xml4492(primary)#: ./doc/glossary/glossary-terms.xml4498(para)#: ./doc/glossary/glossary-terms.xml4508(glossterm)#: ./doc/glossary/glossary-terms.xml4516(para)#: ./doc/glossary/glossary-terms.xml4523(glossterm) #: ./doc/glossary/glossary-terms.xml4525(primary)#: ./doc/glossary/glossary-terms.xml4529(para)#: ./doc/glossary/glossary-terms.xml4536(glossterm)#: ./doc/glossary/glossary-terms.xml4538(primary)#: ./doc/glossary/glossary-terms.xml4542(para)#: ./doc/glossary/glossary-terms.xml4547(glossterm)#: ./doc/glossary/glossary-terms.xml4549(primary)#: ./doc/glossary/glossary-terms.xml4553(para)#: ./doc/glossary/glossary-terms.xml4564(glossterm) #: ./doc/glossary/glossary-terms.xml4566(primary)#: ./doc/glossary/glossary-terms.xml4570(para)#: ./doc/glossary/glossary-terms.xml4578(glossterm) #: ./doc/glossary/glossary-terms.xml4580(primary)#: ./doc/glossary/glossary-terms.xml4584(para)#: ./doc/glossary/glossary-terms.xml4592(glossterm) #: ./doc/glossary/glossary-terms.xml4594(primary)#: ./doc/glossary/glossary-terms.xml4598(para)#: ./doc/glossary/glossary-terms.xml4609(glossterm)#: ./doc/glossary/glossary-terms.xml4611(primary)#: ./doc/glossary/glossary-terms.xml4615(para)#: ./doc/glossary/glossary-terms.xml4621(glossterm)#: ./doc/glossary/glossary-terms.xml4623(primary)#: ./doc/glossary/glossary-terms.xml4627(para) #: ./doc/glossary/glossary-terms.xml6601(para) #: ./doc/glossary/glossary-terms.xml8474(para) #: ./doc/glossary/glossary-terms.xml8486(para) #: ./doc/glossary/glossary-terms.xml8694(para)#: ./doc/glossary/glossary-terms.xml4633(glossterm) #: ./doc/glossary/glossary-terms.xml4635(primary)#: ./doc/glossary/glossary-terms.xml4639(para)#: ./doc/glossary/glossary-terms.xml4648(title)#: ./doc/glossary/glossary-terms.xml4651(glossterm) #: ./doc/glossary/glossary-terms.xml4653(primary)#: ./doc/glossary/glossary-terms.xml4657(para)#: ./doc/glossary/glossary-terms.xml4663(glossterm) #: ./doc/glossary/glossary-terms.xml4665(primary)#: ./doc/glossary/glossary-terms.xml4669(para)#: ./doc/glossary/glossary-terms.xml4674(glossterm) #: ./doc/glossary/glossary-terms.xml4676(primary)#: ./doc/glossary/glossary-terms.xml4680(para)#: ./doc/glossary/glossary-terms.xml4685(glossterm) #: ./doc/glossary/glossary-terms.xml4687(primary)#: ./doc/glossary/glossary-terms.xml4691(para)#: ./doc/glossary/glossary-terms.xml4697(glossterm) #: ./doc/glossary/glossary-terms.xml4699(primary)#: ./doc/glossary/glossary-terms.xml4703(para)#: ./doc/glossary/glossary-terms.xml4709(glossterm) #: ./doc/glossary/glossary-terms.xml4711(primary)#: ./doc/glossary/glossary-terms.xml4715(para)#: ./doc/glossary/glossary-terms.xml4725(title)#: ./doc/glossary/glossary-terms.xml4728(glossterm)#: ./doc/glossary/glossary-terms.xml4730(primary)#: ./doc/glossary/glossary-terms.xml4734(para)#: ./doc/glossary/glossary-terms.xml4746(glossterm) #: ./doc/glossary/glossary-terms.xml4748(primary)#: ./doc/glossary/glossary-terms.xml4752(para)#: ./doc/glossary/glossary-terms.xml4757(glossterm) #: ./doc/glossary/glossary-terms.xml4759(primary)#: ./doc/glossary/glossary-terms.xml4763(para)#: ./doc/glossary/glossary-terms.xml4769(glossterm) #: ./doc/glossary/glossary-terms.xml4771(primary)#: ./doc/glossary/glossary-terms.xml4775(para)#: ./doc/glossary/glossary-terms.xml4788(title)#: ./doc/glossary/glossary-terms.xml4791(glossterm) #: ./doc/glossary/glossary-terms.xml4793(primary)#: ./doc/glossary/glossary-terms.xml4797(para)#: ./doc/glossary/glossary-terms.xml4802(glossterm) #: ./doc/glossary/glossary-terms.xml4804(primary)#: ./doc/glossary/glossary-terms.xml4808(para)#: ./doc/glossary/glossary-terms.xml4813(glossterm) #: ./doc/glossary/glossary-terms.xml4815(primary)#: ./doc/glossary/glossary-terms.xml4819(para)#: ./doc/glossary/glossary-terms.xml4829(glossterm) #: ./doc/glossary/glossary-terms.xml4831(primary)#: ./doc/glossary/glossary-terms.xml4835(para)#: ./doc/glossary/glossary-terms.xml4844(glossterm) #: ./doc/glossary/glossary-terms.xml4846(primary)#: ./doc/glossary/glossary-terms.xml4850(para)#: ./doc/glossary/glossary-terms.xml4856(glossterm) #: ./doc/glossary/glossary-terms.xml4858(primary)#: ./doc/glossary/glossary-terms.xml4862(para)#: ./doc/glossary/glossary-terms.xml4868(glossterm) #: ./doc/glossary/glossary-terms.xml4870(primary)#: ./doc/glossary/glossary-terms.xml4874(para)#: ./doc/glossary/glossary-terms.xml4880(glossterm)#: ./doc/glossary/glossary-terms.xml4883(para)#: ./doc/glossary/glossary-terms.xml4889(glossterm)#: ./doc/glossary/glossary-terms.xml4891(primary)#: ./doc/glossary/glossary-terms.xml4893(secondary) #: ./doc/glossary/glossary-terms.xml5961(secondary)#: ./doc/glossary/glossary-terms.xml4897(para)#: ./doc/glossary/glossary-terms.xml4903(glossterm) #: ./doc/glossary/glossary-terms.xml4905(primary)#: ./doc/glossary/glossary-terms.xml4914(glossterm) #: ./doc/glossary/glossary-terms.xml4916(primary)#: ./doc/glossary/glossary-terms.xml4920(para)#: ./doc/glossary/glossary-terms.xml4927(glossterm)#: ./doc/glossary/glossary-terms.xml4930(para)#: ./doc/glossary/glossary-terms.xml4938(glossterm) #: ./doc/glossary/glossary-terms.xml4940(primary)#: ./doc/glossary/glossary-terms.xml4944(para)#: ./doc/glossary/glossary-terms.xml4950(glossterm) #: ./doc/glossary/glossary-terms.xml4953(primary)#: ./doc/glossary/glossary-terms.xml4957(para)#: ./doc/glossary/glossary-terms.xml4963(glossterm) #: ./doc/glossary/glossary-terms.xml4965(primary)#: ./doc/glossary/glossary-terms.xml4969(para)#: ./doc/glossary/glossary-terms.xml4979(title)#: ./doc/glossary/glossary-terms.xml4982(glossterm) #: ./doc/glossary/glossary-terms.xml4984(primary)#: ./doc/glossary/glossary-terms.xml4990(para)#: ./doc/glossary/glossary-terms.xml4995(glossterm) #: ./doc/glossary/glossary-terms.xml4997(primary)#: ./doc/glossary/glossary-terms.xml5001(para)#: ./doc/glossary/glossary-terms.xml5007(glossterm) #: ./doc/glossary/glossary-terms.xml5009(primary)#: ./doc/glossary/glossary-terms.xml5013(para)#: ./doc/glossary/glossary-terms.xml5019(glossterm)#: ./doc/glossary/glossary-terms.xml5021(primary) #: ./doc/glossary/glossary-terms.xml5040(primary)#: ./doc/glossary/glossary-terms.xml5027(para)#: ./doc/glossary/glossary-terms.xml5033(glossterm)#: ./doc/glossary/glossary-terms.xml5037(secondary) #: ./doc/glossary/glossary-terms.xml5042(secondary)#: ./doc/glossary/glossary-terms.xml5046(para)#: ./doc/glossary/glossary-terms.xml5052(glossterm) #: ./doc/glossary/glossary-terms.xml5054(primary)#: ./doc/glossary/glossary-terms.xml5058(para)#: ./doc/glossary/glossary-terms.xml5064(glossterm) #: ./doc/glossary/glossary-terms.xml5066(primary)#: ./doc/glossary/glossary-terms.xml5070(para)#: ./doc/glossary/glossary-terms.xml5076(glossterm) #: ./doc/glossary/glossary-terms.xml5078(primary)#: ./doc/glossary/glossary-terms.xml5082(para)#: ./doc/glossary/glossary-terms.xml5091(glossterm) #: ./doc/glossary/glossary-terms.xml5093(primary)#: ./doc/glossary/glossary-terms.xml5097(para)#: ./doc/glossary/glossary-terms.xml5103(glossterm) #: ./doc/glossary/glossary-terms.xml5105(primary)#: ./doc/glossary/glossary-terms.xml5109(para)#: ./doc/glossary/glossary-terms.xml5115(glossterm)#: ./doc/glossary/glossary-terms.xml5117(primary)#: ./doc/glossary/glossary-terms.xml5127(glossterm) #: ./doc/glossary/glossary-terms.xml5129(primary)#: ./doc/glossary/glossary-terms.xml5133(para)#: ./doc/glossary/glossary-terms.xml5139(glossterm) #: ./doc/glossary/glossary-terms.xml5141(primary)#: ./doc/glossary/glossary-terms.xml5145(para)#: ./doc/glossary/glossary-terms.xml5153(glossterm)#: ./doc/glossary/glossary-terms.xml5155(primary)#: ./doc/glossary/glossary-terms.xml5159(para)#: ./doc/glossary/glossary-terms.xml5165(glossterm) #: ./doc/glossary/glossary-terms.xml5167(primary)#: ./doc/glossary/glossary-terms.xml5171(para)#: ./doc/glossary/glossary-terms.xml5177(glossterm) #: ./doc/glossary/glossary-terms.xml5179(primary)#: ./doc/glossary/glossary-terms.xml5183(para)#: ./doc/glossary/glossary-terms.xml5189(glossterm) #: ./doc/glossary/glossary-terms.xml5191(primary)#: ./doc/glossary/glossary-terms.xml5195(para)#: ./doc/glossary/glossary-terms.xml5201(glossterm) #: ./doc/glossary/glossary-terms.xml5203(primary)#: ./doc/glossary/glossary-terms.xml5207(para)#: ./doc/glossary/glossary-terms.xml5212(glossterm) #: ./doc/glossary/glossary-terms.xml5214(primary)#: ./doc/glossary/glossary-terms.xml5218(para)#: ./doc/glossary/glossary-terms.xml5224(glossterm) #: ./doc/glossary/glossary-terms.xml5226(primary)#: ./doc/glossary/glossary-terms.xml5230(para)#: ./doc/glossary/glossary-terms.xml5238(glossterm)#: ./doc/glossary/glossary-terms.xml5241(para)#: ./doc/glossary/glossary-terms.xml5247(glossterm) #: ./doc/glossary/glossary-terms.xml5250(primary)#: ./doc/glossary/glossary-terms.xml5254(para)#: ./doc/glossary/glossary-terms.xml5260(glossterm) #: ./doc/glossary/glossary-terms.xml5262(primary)#: ./doc/glossary/glossary-terms.xml5266(para)#: ./doc/glossary/glossary-terms.xml5272(glossterm) #: ./doc/glossary/glossary-terms.xml5274(primary)#: ./doc/glossary/glossary-terms.xml5278(para)#: ./doc/glossary/glossary-terms.xml5284(glossterm) #: ./doc/glossary/glossary-terms.xml5286(primary)#: ./doc/glossary/glossary-terms.xml5290(para)#: ./doc/glossary/glossary-terms.xml5297(glossterm) #: ./doc/glossary/glossary-terms.xml5299(primary)#: ./doc/glossary/glossary-terms.xml5303(para)#: ./doc/glossary/glossary-terms.xml5312(title)#: ./doc/glossary/glossary-terms.xml5315(glossterm) #: ./doc/glossary/glossary-terms.xml5317(primary)#: ./doc/glossary/glossary-terms.xml5321(para)#: ./doc/glossary/glossary-terms.xml5329(glossterm) #: ./doc/glossary/glossary-terms.xml5331(primary)#: ./doc/glossary/glossary-terms.xml5335(para)#: ./doc/glossary/glossary-terms.xml5341(glossterm) #: ./doc/glossary/glossary-terms.xml5343(primary)#: ./doc/glossary/glossary-terms.xml5347(para)#: ./doc/glossary/glossary-terms.xml5354(glossterm) #: ./doc/glossary/glossary-terms.xml5356(primary)#: ./doc/glossary/glossary-terms.xml5360(para)#: ./doc/glossary/glossary-terms.xml5367(glossterm)#: ./doc/glossary/glossary-terms.xml5369(primary) #: ./doc/glossary/glossary-terms.xml5385(primary) #: ./doc/glossary/glossary-terms.xml5399(primary) #: ./doc/glossary/glossary-terms.xml5414(primary) #: ./doc/glossary/glossary-terms.xml5428(primary) #: ./doc/glossary/glossary-terms.xml5442(primary) #: ./doc/glossary/glossary-terms.xml5456(primary) #: ./doc/glossary/glossary-terms.xml5469(primary) #: ./doc/glossary/glossary-terms.xml5483(primary) #: ./doc/glossary/glossary-terms.xml5497(primary) #: ./doc/glossary/glossary-terms.xml5511(primary) #: ./doc/glossary/glossary-terms.xml6348(primary) #: ./doc/glossary/glossary-terms.xml6548(primary) #: ./doc/glossary/glossary-terms.xml8521(primary) #: ./doc/glossary/glossary-terms.xml8669(primary)#: ./doc/glossary/glossary-terms.xml5375(para)#: ./doc/glossary/glossary-terms.xml5383(glossterm) #: ./doc/glossary/glossary-terms.xml5387(secondary)#: ./doc/glossary/glossary-terms.xml5391(para)#: ./doc/glossary/glossary-terms.xml5397(glossterm)#: ./doc/glossary/glossary-terms.xml5401(secondary)#: ./doc/glossary/glossary-terms.xml5405(para)#: ./doc/glossary/glossary-terms.xml5412(glossterm) #: ./doc/glossary/glossary-terms.xml5416(secondary)#: ./doc/glossary/glossary-terms.xml5420(para)#: ./doc/glossary/glossary-terms.xml5426(glossterm)#: ./doc/glossary/glossary-terms.xml5430(secondary)#: ./doc/glossary/glossary-terms.xml5434(para)#: ./doc/glossary/glossary-terms.xml5440(glossterm)#: ./doc/glossary/glossary-terms.xml5444(secondary)#: ./doc/glossary/glossary-terms.xml5448(para)#: ./doc/glossary/glossary-terms.xml5454(glossterm)#: ./doc/glossary/glossary-terms.xml5458(secondary)#: ./doc/glossary/glossary-terms.xml5462(para)#: ./doc/glossary/glossary-terms.xml5467(glossterm)#: ./doc/glossary/glossary-terms.xml5471(secondary)#: ./doc/glossary/glossary-terms.xml5475(para)#: ./doc/glossary/glossary-terms.xml5481(glossterm) #: ./doc/glossary/glossary-terms.xml5485(secondary)#: ./doc/glossary/glossary-terms.xml5489(para)#: ./doc/glossary/glossary-terms.xml5495(glossterm) #: ./doc/glossary/glossary-terms.xml5499(secondary)#: ./doc/glossary/glossary-terms.xml5503(para)#: ./doc/glossary/glossary-terms.xml5509(glossterm)#: ./doc/glossary/glossary-terms.xml5513(secondary)#: ./doc/glossary/glossary-terms.xml5517(para)#: ./doc/glossary/glossary-terms.xml5524(glossterm)#: ./doc/glossary/glossary-terms.xml5527(para)#: ./doc/glossary/glossary-terms.xml5534(glossterm) #: ./doc/glossary/glossary-terms.xml5536(primary) #: ./doc/glossary/glossary-terms.xml5559(secondary)#: ./doc/glossary/glossary-terms.xml5540(para)#: ./doc/glossary/glossary-terms.xml5546(glossterm) #: ./doc/glossary/glossary-terms.xml5557(primary) #: ./doc/glossary/glossary-terms.xml5570(primary) #: ./doc/glossary/glossary-terms.xml5584(primary)#: ./doc/glossary/glossary-terms.xml5549(para)#: ./doc/glossary/glossary-terms.xml5555(glossterm)#: ./doc/glossary/glossary-terms.xml5563(para)#: ./doc/glossary/glossary-terms.xml5568(glossterm) #: ./doc/glossary/glossary-terms.xml5572(secondary)#: ./doc/glossary/glossary-terms.xml5576(para)#: ./doc/glossary/glossary-terms.xml5582(glossterm) #: ./doc/glossary/glossary-terms.xml5586(secondary)#: ./doc/glossary/glossary-terms.xml5590(para)#: ./doc/glossary/glossary-terms.xml5597(glossterm) #: ./doc/glossary/glossary-terms.xml5599(primary)#: ./doc/glossary/glossary-terms.xml5603(para)#: ./doc/glossary/glossary-terms.xml5608(glossterm) #: ./doc/glossary/glossary-terms.xml5610(primary)#: ./doc/glossary/glossary-terms.xml5614(para)#: ./doc/glossary/glossary-terms.xml5620(glossterm)#: ./doc/glossary/glossary-terms.xml5622(primary) #: ./doc/glossary/glossary-terms.xml6452(primary) #: ./doc/glossary/glossary-terms.xml7822(primary) #: ./doc/glossary/glossary-terms.xml8022(primary)#: ./doc/glossary/glossary-terms.xml5628(para)#: ./doc/glossary/glossary-terms.xml5633(glossterm)#: ./doc/glossary/glossary-terms.xml5635(primary) #: ./doc/glossary/glossary-terms.xml5652(primary) #: ./doc/glossary/glossary-terms.xml6174(primary) #: ./doc/glossary/glossary-terms.xml8285(primary)#: ./doc/glossary/glossary-terms.xml5637(secondary) #: ./doc/glossary/glossary-terms.xml5640(primary) #: ./doc/glossary/glossary-terms.xml8265(see)#: ./doc/glossary/glossary-terms.xml5644(para)#: ./doc/glossary/glossary-terms.xml5650(glossterm) #: ./doc/glossary/glossary-terms.xml5657(primary)#: ./doc/glossary/glossary-terms.xml5654(secondary)#: ./doc/glossary/glossary-terms.xml5661(para)#: ./doc/glossary/glossary-terms.xml5667(glossterm) #: ./doc/glossary/glossary-terms.xml5669(primary)#: ./doc/glossary/glossary-terms.xml5675(para)#: ./doc/glossary/glossary-terms.xml5680(glossterm) #: ./doc/glossary/glossary-terms.xml5682(primary)#: ./doc/glossary/glossary-terms.xml5686(para)#: ./doc/glossary/glossary-terms.xml5694(glossterm) #: ./doc/glossary/glossary-terms.xml5704(primary) #: ./doc/glossary/glossary-terms.xml5717(primary)#: ./doc/glossary/glossary-terms.xml5697(para)#: ./doc/glossary/glossary-terms.xml5702(glossterm)#: ./doc/glossary/glossary-terms.xml5710(para)#: ./doc/glossary/glossary-terms.xml5715(glossterm) #: ./doc/glossary/glossary-terms.xml5719(secondary)#: ./doc/glossary/glossary-terms.xml5723(para)#: ./doc/glossary/glossary-terms.xml5733(title)#: ./doc/glossary/glossary-terms.xml5736(glossterm)#: ./doc/glossary/glossary-terms.xml5744(para)#: ./doc/glossary/glossary-terms.xml5750(glossterm)#: ./doc/glossary/glossary-terms.xml5754(secondary)#: ./doc/glossary/glossary-terms.xml5758(para)#: ./doc/glossary/glossary-terms.xml5764(glossterm) #: ./doc/glossary/glossary-terms.xml5768(secondary)#: ./doc/glossary/glossary-terms.xml5772(para)#: ./doc/glossary/glossary-terms.xml5779(glossterm) #: ./doc/glossary/glossary-terms.xml5783(secondary)#: ./doc/glossary/glossary-terms.xml5787(para)#: ./doc/glossary/glossary-terms.xml5792(glossterm) #: ./doc/glossary/glossary-terms.xml5796(secondary)#: ./doc/glossary/glossary-terms.xml5800(para)#: ./doc/glossary/glossary-terms.xml5806(glossterm)#: ./doc/glossary/glossary-terms.xml5810(secondary)#: ./doc/glossary/glossary-terms.xml5814(para)#: ./doc/glossary/glossary-terms.xml5820(glossterm)#: ./doc/glossary/glossary-terms.xml5824(secondary)#: ./doc/glossary/glossary-terms.xml5828(para)#: ./doc/glossary/glossary-terms.xml5834(glossterm) #: ./doc/glossary/glossary-terms.xml5851(primary) #: ./doc/glossary/glossary-terms.xml5864(primary)#: ./doc/glossary/glossary-terms.xml5837(para)#: ./doc/glossary/glossary-terms.xml5844(glossterm) #: ./doc/glossary/glossary-terms.xml5848(secondary) #: ./doc/glossary/glossary-terms.xml5853(secondary)#: ./doc/glossary/glossary-terms.xml5846(primary) #: ./doc/glossary/glossary-terms.xml7966(glossterm) #: ./doc/glossary/glossary-terms.xml7989(primary) #: ./doc/glossary/glossary-terms.xml8003(primary) #: ./doc/glossary/glossary-terms.xml8027(primary)#: ./doc/glossary/glossary-terms.xml5857(para)#: ./doc/glossary/glossary-terms.xml5862(glossterm) #: ./doc/glossary/glossary-terms.xml5866(secondary)#: ./doc/glossary/glossary-terms.xml5870(para)#: ./doc/glossary/glossary-terms.xml5875(glossterm) #: ./doc/glossary/glossary-terms.xml5879(secondary)#: ./doc/glossary/glossary-terms.xml5883(para)#: ./doc/glossary/glossary-terms.xml5889(glossterm) #: ./doc/glossary/glossary-terms.xml5891(primary)#: ./doc/glossary/glossary-terms.xml5895(para)#: ./doc/glossary/glossary-terms.xml5901(glossterm) #: ./doc/glossary/glossary-terms.xml5904(primary)#: ./doc/glossary/glossary-terms.xml5908(para)#: ./doc/glossary/glossary-terms.xml5914(glossterm) #: ./doc/glossary/glossary-terms.xml5916(primary)#: ./doc/glossary/glossary-terms.xml5920(para)#: ./doc/glossary/glossary-terms.xml5925(glossterm) #: ./doc/glossary/glossary-terms.xml5927(primary) #: ./doc/glossary/glossary-terms.xml5959(primary)#: ./doc/glossary/glossary-terms.xml5931(para)#: ./doc/glossary/glossary-terms.xml5943(glossterm) #: ./doc/glossary/glossary-terms.xml5945(primary)#: ./doc/glossary/glossary-terms.xml5949(para)#: ./doc/glossary/glossary-terms.xml5957(glossterm)#: ./doc/glossary/glossary-terms.xml5965(para)#: ./doc/glossary/glossary-terms.xml5970(glossterm) #: ./doc/glossary/glossary-terms.xml5972(primary)#: ./doc/glossary/glossary-terms.xml5976(para)#: ./doc/glossary/glossary-terms.xml5982(glossterm) #: ./doc/glossary/glossary-terms.xml5984(primary) #: ./doc/glossary/glossary-terms.xml6002(primary)#: ./doc/glossary/glossary-terms.xml5990(para)#: ./doc/glossary/glossary-terms.xml6000(glossterm)#: ./doc/glossary/glossary-terms.xml6003(secondary)#: ./doc/glossary/glossary-terms.xml6007(para)#: ./doc/glossary/glossary-terms.xml6021(glossterm) #: ./doc/glossary/glossary-terms.xml6023(primary)#: ./doc/glossary/glossary-terms.xml6032(glossterm) #: ./doc/glossary/glossary-terms.xml6034(primary)#: ./doc/glossary/glossary-terms.xml6038(para)#: ./doc/glossary/glossary-terms.xml6044(glossterm) #: ./doc/glossary/glossary-terms.xml6046(primary)#: ./doc/glossary/glossary-terms.xml6050(para)#: ./doc/glossary/glossary-terms.xml6057(glossterm)#: ./doc/glossary/glossary-terms.xml6059(primary)#: ./doc/glossary/glossary-terms.xml6063(para)#: ./doc/glossary/glossary-terms.xml6072(title)#: ./doc/glossary/glossary-terms.xml6075(glossterm)#: ./doc/glossary/glossary-terms.xml6079(secondary) #: ./doc/glossary/glossary-terms.xml6082(primary)#: ./doc/glossary/glossary-terms.xml6086(para)#: ./doc/glossary/glossary-terms.xml6093(glossterm)#: ./doc/glossary/glossary-terms.xml6095(primary) #: ./doc/glossary/glossary-terms.xml6110(primary) #: ./doc/glossary/glossary-terms.xml6124(primary)#: ./doc/glossary/glossary-terms.xml6101(para)#: ./doc/glossary/glossary-terms.xml6108(glossterm) #: ./doc/glossary/glossary-terms.xml6112(secondary)#: ./doc/glossary/glossary-terms.xml6116(para)#: ./doc/glossary/glossary-terms.xml6122(glossterm)#: ./doc/glossary/glossary-terms.xml6126(secondary)#: ./doc/glossary/glossary-terms.xml6130(para)#: ./doc/glossary/glossary-terms.xml6136(glossterm) #: ./doc/glossary/glossary-terms.xml6138(primary)#: ./doc/glossary/glossary-terms.xml6142(para)#: ./doc/glossary/glossary-terms.xml6148(glossterm) #: ./doc/glossary/glossary-terms.xml6150(primary)#: ./doc/glossary/glossary-terms.xml6154(para)#: ./doc/glossary/glossary-terms.xml6160(glossterm) #: ./doc/glossary/glossary-terms.xml6162(primary)#: ./doc/glossary/glossary-terms.xml6166(para)#: ./doc/glossary/glossary-terms.xml6172(glossterm)#: ./doc/glossary/glossary-terms.xml6176(secondary) #: ./doc/glossary/glossary-terms.xml6179(primary)#: ./doc/glossary/glossary-terms.xml6183(para)#: ./doc/glossary/glossary-terms.xml6189(glossterm) #: ./doc/glossary/glossary-terms.xml6191(primary)#: ./doc/glossary/glossary-terms.xml6195(para)#: ./doc/glossary/glossary-terms.xml6200(glossterm) #: ./doc/glossary/glossary-terms.xml6202(primary)#: ./doc/glossary/glossary-terms.xml6206(para)#: ./doc/glossary/glossary-terms.xml6212(glossterm) #: ./doc/glossary/glossary-terms.xml6214(primary)#: ./doc/glossary/glossary-terms.xml6218(para)#: ./doc/glossary/glossary-terms.xml6227(glossterm)#: ./doc/glossary/glossary-terms.xml6229(primary)#: ./doc/glossary/glossary-terms.xml6233(para)#: ./doc/glossary/glossary-terms.xml6239(glossterm) #: ./doc/glossary/glossary-terms.xml6241(primary)#: ./doc/glossary/glossary-terms.xml6245(para)#: ./doc/glossary/glossary-terms.xml6251(glossterm) #: ./doc/glossary/glossary-terms.xml6253(primary)#: ./doc/glossary/glossary-terms.xml6257(para)#: ./doc/glossary/glossary-terms.xml6266(glossterm) #: ./doc/glossary/glossary-terms.xml6268(primary)#: ./doc/glossary/glossary-terms.xml6272(para)#: ./doc/glossary/glossary-terms.xml6278(glossterm)#: ./doc/glossary/glossary-terms.xml6280(primary) #: ./doc/glossary/glossary-terms.xml6294(primary) #: ./doc/glossary/glossary-terms.xml8577(primary)#: ./doc/glossary/glossary-terms.xml6286(para)#: ./doc/glossary/glossary-terms.xml6292(glossterm) #: ./doc/glossary/glossary-terms.xml6296(secondary)#: ./doc/glossary/glossary-terms.xml6300(para)#: ./doc/glossary/glossary-terms.xml6305(glossterm)#: ./doc/glossary/glossary-terms.xml6307(primary)#: ./doc/glossary/glossary-terms.xml6311(para)#: ./doc/glossary/glossary-terms.xml6317(glossterm) #: ./doc/glossary/glossary-terms.xml6319(primary)#: ./doc/glossary/glossary-terms.xml6323(para)#: ./doc/glossary/glossary-terms.xml6329(glossterm) #: ./doc/glossary/glossary-terms.xml6336(primary)#: ./doc/glossary/glossary-terms.xml6333(secondary)#: ./doc/glossary/glossary-terms.xml6340(para)#: ./doc/glossary/glossary-terms.xml6346(glossterm)#: ./doc/glossary/glossary-terms.xml6350(secondary) #: ./doc/glossary/glossary-terms.xml6353(primary)#: ./doc/glossary/glossary-terms.xml6357(para)#: ./doc/glossary/glossary-terms.xml6369(glossterm)#: ./doc/glossary/glossary-terms.xml6371(primary) #: ./doc/glossary/glossary-terms.xml6385(primary) #: ./doc/glossary/glossary-terms.xml6399(primary)#: ./doc/glossary/glossary-terms.xml6377(para)#: ./doc/glossary/glossary-terms.xml6383(glossterm) #: ./doc/glossary/glossary-terms.xml6387(secondary)#: ./doc/glossary/glossary-terms.xml6391(para)#: ./doc/glossary/glossary-terms.xml6397(glossterm) #: ./doc/glossary/glossary-terms.xml6401(secondary)#: ./doc/glossary/glossary-terms.xml6405(para)#: ./doc/glossary/glossary-terms.xml6410(glossterm) #: ./doc/glossary/glossary-terms.xml6412(primary)#: ./doc/glossary/glossary-terms.xml6416(para)#: ./doc/glossary/glossary-terms.xml6423(glossterm) #: ./doc/glossary/glossary-terms.xml6425(primary)#: ./doc/glossary/glossary-terms.xml6429(para)#: ./doc/glossary/glossary-terms.xml6438(glossterm) #: ./doc/glossary/glossary-terms.xml6440(primary)#: ./doc/glossary/glossary-terms.xml6444(para)#: ./doc/glossary/glossary-terms.xml6450(glossterm)#: ./doc/glossary/glossary-terms.xml6454(secondary) #: ./doc/glossary/glossary-terms.xml6457(primary)#: ./doc/glossary/glossary-terms.xml6461(para)#: ./doc/glossary/glossary-terms.xml6466(glossterm)#: ./doc/glossary/glossary-terms.xml6470(secondary) #: ./doc/glossary/glossary-terms.xml6473(primary)#: ./doc/glossary/glossary-terms.xml6477(para)#: ./doc/glossary/glossary-terms.xml6484(glossterm) #: ./doc/glossary/glossary-terms.xml6491(primary)#: ./doc/glossary/glossary-terms.xml6488(secondary)#: ./doc/glossary/glossary-terms.xml6495(para)#: ./doc/glossary/glossary-terms.xml6501(glossterm) #: ./doc/glossary/glossary-terms.xml6508(primary)#: ./doc/glossary/glossary-terms.xml6505(secondary)#: ./doc/glossary/glossary-terms.xml6512(para)#: ./doc/glossary/glossary-terms.xml6518(glossterm) #: ./doc/glossary/glossary-terms.xml6525(primary)#: ./doc/glossary/glossary-terms.xml6522(secondary) #: ./doc/glossary/glossary-terms.xml6550(secondary)#: ./doc/glossary/glossary-terms.xml6529(para)#: ./doc/glossary/glossary-terms.xml6534(glossterm) #: ./doc/glossary/glossary-terms.xml6536(primary)#: ./doc/glossary/glossary-terms.xml6540(para)#: ./doc/glossary/glossary-terms.xml6546(glossterm) #: ./doc/glossary/glossary-terms.xml6553(primary)#: ./doc/glossary/glossary-terms.xml6557(para)#: ./doc/glossary/glossary-terms.xml6566(glossterm) #: ./doc/glossary/glossary-terms.xml6568(primary)#: ./doc/glossary/glossary-terms.xml6572(para)#: ./doc/glossary/glossary-terms.xml6578(glossterm) #: ./doc/glossary/glossary-terms.xml6580(primary)#: ./doc/glossary/glossary-terms.xml6584(para)#: ./doc/glossary/glossary-terms.xml6592(title)#: ./doc/glossary/glossary-terms.xml6595(glossterm) #: ./doc/glossary/glossary-terms.xml6597(primary)#: ./doc/glossary/glossary-terms.xml6607(glossterm) #: ./doc/glossary/glossary-terms.xml6609(primary)#: ./doc/glossary/glossary-terms.xml6613(para)#: ./doc/glossary/glossary-terms.xml6619(glossterm) #: ./doc/glossary/glossary-terms.xml6621(primary)#: ./doc/glossary/glossary-terms.xml6625(para)#: ./doc/glossary/glossary-terms.xml6632(glossterm) #: ./doc/glossary/glossary-terms.xml6634(primary)#: ./doc/glossary/glossary-terms.xml6638(para)#: ./doc/glossary/glossary-terms.xml6641(para)#: ./doc/glossary/glossary-terms.xml6647(glossterm)#: ./doc/glossary/glossary-terms.xml6649(primary)#: ./doc/glossary/glossary-terms.xml6653(para)#: ./doc/glossary/glossary-terms.xml6662(title)#: ./doc/glossary/glossary-terms.xml6665(glossterm) #: ./doc/glossary/glossary-terms.xml6667(primary)#: ./doc/glossary/glossary-terms.xml6671(para)#: ./doc/glossary/glossary-terms.xml6676(glossterm) #: ./doc/glossary/glossary-terms.xml6678(primary)#: ./doc/glossary/glossary-terms.xml6682(para)#: ./doc/glossary/glossary-terms.xml6688(glossterm) #: ./doc/glossary/glossary-terms.xml6690(primary)#: ./doc/glossary/glossary-terms.xml6694(para)#: ./doc/glossary/glossary-terms.xml6700(glossterm) #: ./doc/glossary/glossary-terms.xml6702(primary)#: ./doc/glossary/glossary-terms.xml6706(para)#: ./doc/glossary/glossary-terms.xml6713(glossterm) #: ./doc/glossary/glossary-terms.xml6715(primary)#: ./doc/glossary/glossary-terms.xml6719(para)#: ./doc/glossary/glossary-terms.xml6725(glossterm) #: ./doc/glossary/glossary-terms.xml6727(primary)#: ./doc/glossary/glossary-terms.xml6731(para)#: ./doc/glossary/glossary-terms.xml6739(glossterm)#: ./doc/glossary/glossary-terms.xml6741(primary)#: ./doc/glossary/glossary-terms.xml6745(para)#: ./doc/glossary/glossary-terms.xml6751(glossterm)#: ./doc/glossary/glossary-terms.xml6753(primary)#: ./doc/glossary/glossary-terms.xml6757(para)#: ./doc/glossary/glossary-terms.xml6763(glossterm)#: ./doc/glossary/glossary-terms.xml6765(primary)#: ./doc/glossary/glossary-terms.xml6769(para)#: ./doc/glossary/glossary-terms.xml6776(glossterm) #: ./doc/glossary/glossary-terms.xml6778(primary) #: ./doc/glossary/glossary-terms.xml7672(primary)#: ./doc/glossary/glossary-terms.xml6780(secondary) #: ./doc/glossary/glossary-terms.xml7674(secondary)#: ./doc/glossary/glossary-terms.xml6784(para)#: ./doc/glossary/glossary-terms.xml6794(glossterm)#: ./doc/glossary/glossary-terms.xml6796(primary)#: ./doc/glossary/glossary-terms.xml6800(para)#: ./doc/glossary/glossary-terms.xml6806(glossterm) #: ./doc/glossary/glossary-terms.xml6808(primary)#: ./doc/glossary/glossary-terms.xml6812(para)#: ./doc/glossary/glossary-terms.xml6817(glossterm)#: ./doc/glossary/glossary-terms.xml6819(primary) #: ./doc/glossary/glossary-terms.xml6838(primary)#: ./doc/glossary/glossary-terms.xml6825(para)#: ./doc/glossary/glossary-terms.xml6836(glossterm)#: ./doc/glossary/glossary-terms.xml6840(secondary)#: ./doc/glossary/glossary-terms.xml6844(para)#: ./doc/glossary/glossary-terms.xml6850(glossterm) #: ./doc/glossary/glossary-terms.xml6852(primary)#: ./doc/glossary/glossary-terms.xml6861(glossterm) #: ./doc/glossary/glossary-terms.xml6863(primary)#: ./doc/glossary/glossary-terms.xml6867(para)#: ./doc/glossary/glossary-terms.xml6872(glossterm) #: ./doc/glossary/glossary-terms.xml6874(primary)#: ./doc/glossary/glossary-terms.xml6878(para)#: ./doc/glossary/glossary-terms.xml6885(glossterm) #: ./doc/glossary/glossary-terms.xml6887(primary)#: ./doc/glossary/glossary-terms.xml6889(see)#: ./doc/glossary/glossary-terms.xml6893(para)#: ./doc/glossary/glossary-terms.xml6898(glossterm)#: ./doc/glossary/glossary-terms.xml6902(secondary) #: ./doc/glossary/glossary-terms.xml6905(primary)#: ./doc/glossary/glossary-terms.xml6909(para)#: ./doc/glossary/glossary-terms.xml6915(glossterm) #: ./doc/glossary/glossary-terms.xml6918(primary)#: ./doc/glossary/glossary-terms.xml6923(para)#: ./doc/glossary/glossary-terms.xml6929(glossterm) #: ./doc/glossary/glossary-terms.xml6931(primary)#: ./doc/glossary/glossary-terms.xml6935(para)#: ./doc/glossary/glossary-terms.xml6941(glossterm)#: ./doc/glossary/glossary-terms.xml6943(primary) #: ./doc/glossary/glossary-terms.xml6958(primary) #: ./doc/glossary/glossary-terms.xml6970(glossterm) #: ./doc/glossary/glossary-terms.xml6981(primary)#: ./doc/glossary/glossary-terms.xml6949(para)#: ./doc/glossary/glossary-terms.xml6956(glossterm) #: ./doc/glossary/glossary-terms.xml6960(secondary)#: ./doc/glossary/glossary-terms.xml6964(para)#: ./doc/glossary/glossary-terms.xml6973(para)#: ./doc/glossary/glossary-terms.xml6979(glossterm)#: ./doc/glossary/glossary-terms.xml6983(secondary)#: ./doc/glossary/glossary-terms.xml6987(para)#: ./doc/glossary/glossary-terms.xml6993(glossterm)#: ./doc/glossary/glossary-terms.xml6995(primary)#: ./doc/glossary/glossary-terms.xml6999(para)#: ./doc/glossary/glossary-terms.xml7004(glossterm)#: ./doc/glossary/glossary-terms.xml7006(primary)#: ./doc/glossary/glossary-terms.xml7010(para)#: ./doc/glossary/glossary-terms.xml7017(glossterm)#: ./doc/glossary/glossary-terms.xml7019(primary)#: ./doc/glossary/glossary-terms.xml7023(para)#: ./doc/glossary/glossary-terms.xml7031(glossterm)#: ./doc/glossary/glossary-terms.xml7033(primary)#: ./doc/glossary/glossary-terms.xml7037(para)#: ./doc/glossary/glossary-terms.xml7044(glossterm)#: ./doc/glossary/glossary-terms.xml7046(primary) #: ./doc/glossary/glossary-terms.xml7061(primary)#: ./doc/glossary/glossary-terms.xml7052(para)#: ./doc/glossary/glossary-terms.xml7059(glossterm)#: ./doc/glossary/glossary-terms.xml7063(secondary)#: ./doc/glossary/glossary-terms.xml7067(para)#: ./doc/glossary/glossary-terms.xml7074(glossterm) #: ./doc/glossary/glossary-terms.xml7076(primary)#: ./doc/glossary/glossary-terms.xml7080(para)#: ./doc/glossary/glossary-terms.xml7088(glossterm)#: ./doc/glossary/glossary-terms.xml7090(primary) #: ./doc/glossary/glossary-terms.xml7105(primary)#: ./doc/glossary/glossary-terms.xml7096(para)#: ./doc/glossary/glossary-terms.xml7103(glossterm) #: ./doc/glossary/glossary-terms.xml7107(secondary)#: ./doc/glossary/glossary-terms.xml7111(para)#: ./doc/glossary/glossary-terms.xml7116(glossterm) #: ./doc/glossary/glossary-terms.xml7118(primary)#: ./doc/glossary/glossary-terms.xml7122(para)#: ./doc/glossary/glossary-terms.xml7128(glossterm) #: ./doc/glossary/glossary-terms.xml7135(primary)#: ./doc/glossary/glossary-terms.xml7130(primary) #: ./doc/glossary/glossary-terms.xml7715(primary)#: ./doc/glossary/glossary-terms.xml7132(secondary)#: ./doc/glossary/glossary-terms.xml7139(para)#: ./doc/glossary/glossary-terms.xml7145(glossterm) #: ./doc/glossary/glossary-terms.xml7147(primary)#: ./doc/glossary/glossary-terms.xml7151(para)#: ./doc/glossary/glossary-terms.xml7157(glossterm)#: ./doc/glossary/glossary-terms.xml7159(primary)#: ./doc/glossary/glossary-terms.xml7163(para)#: ./doc/glossary/glossary-terms.xml7170(glossterm)#: ./doc/glossary/glossary-terms.xml7172(primary)#: ./doc/glossary/glossary-terms.xml7174(secondary) #: ./doc/glossary/glossary-terms.xml7177(primary)#: ./doc/glossary/glossary-terms.xml7181(para)#: ./doc/glossary/glossary-terms.xml7188(glossterm) #: ./doc/glossary/glossary-terms.xml7190(primary)#: ./doc/glossary/glossary-terms.xml7194(para)#: ./doc/glossary/glossary-terms.xml7199(glossterm)#: ./doc/glossary/glossary-terms.xml7201(primary)#: ./doc/glossary/glossary-terms.xml7205(para)#: ./doc/glossary/glossary-terms.xml7211(glossterm)#: ./doc/glossary/glossary-terms.xml7214(para)#: ./doc/glossary/glossary-terms.xml7220(glossterm) #: ./doc/glossary/glossary-terms.xml7222(primary)#: ./doc/glossary/glossary-terms.xml7226(para)#: ./doc/glossary/glossary-terms.xml7235(title)#: ./doc/glossary/glossary-terms.xml7238(glossterm)#: ./doc/glossary/glossary-terms.xml7240(primary)#: ./doc/glossary/glossary-terms.xml7244(para)#: ./doc/glossary/glossary-terms.xml7251(glossterm) #: ./doc/glossary/glossary-terms.xml7253(primary)#: ./doc/glossary/glossary-terms.xml7257(para)#: ./doc/glossary/glossary-terms.xml7263(glossterm) #: ./doc/glossary/glossary-terms.xml7265(primary) msgid ""SAML assertion"" msgstr """" #: ./doc/glossary/glossary-terms.xml7269(para) msgid """" ""Contains information about a user as provided by the identity provider. It "" ""is an indication that a user has been authenticated."" msgstr """" #: ./doc/glossary/glossary-terms.xml7275(glossterm) #: ./doc/glossary/glossary-terms.xml7277(primary)#: ./doc/glossary/glossary-terms.xml7281(para)#: ./doc/glossary/glossary-terms.xml7288(glossterm)#: ./doc/glossary/glossary-terms.xml7290(primary)#: ./doc/glossary/glossary-terms.xml7294(para)#: ./doc/glossary/glossary-terms.xml7300(glossterm)#: ./doc/glossary/glossary-terms.xml7302(primary)#: ./doc/glossary/glossary-terms.xml7306(para)#: ./doc/glossary/glossary-terms.xml7312(glossterm)#: ./doc/glossary/glossary-terms.xml7314(primary)#: ./doc/glossary/glossary-terms.xml7318(para)#: ./doc/glossary/glossary-terms.xml7324(glossterm) #: ./doc/glossary/glossary-terms.xml7326(primary)#: ./doc/glossary/glossary-terms.xml7330(para)#: ./doc/glossary/glossary-terms.xml7337(glossterm)#: ./doc/glossary/glossary-terms.xml7339(primary)#: ./doc/glossary/glossary-terms.xml7343(para)#: ./doc/glossary/glossary-terms.xml7349(glossterm)#: ./doc/glossary/glossary-terms.xml7353(secondary) #: ./doc/glossary/glossary-terms.xml7356(primary)#: ./doc/glossary/glossary-terms.xml7360(para)#: ./doc/glossary/glossary-terms.xml7367(glossterm) #: ./doc/glossary/glossary-terms.xml7369(primary)#: ./doc/glossary/glossary-terms.xml7373(para)#: ./doc/glossary/glossary-terms.xml7379(glossterm)#: ./doc/glossary/glossary-terms.xml7387(para)#: ./doc/glossary/glossary-terms.xml7391(para)#: ./doc/glossary/glossary-terms.xml7397(glossterm) #: ./doc/glossary/glossary-terms.xml7399(primary)#: ./doc/glossary/glossary-terms.xml7403(para)#: ./doc/glossary/glossary-terms.xml7408(glossterm) #: ./doc/glossary/glossary-terms.xml7412(secondary)#: ./doc/glossary/glossary-terms.xml7422(glossterm)#: ./doc/glossary/glossary-terms.xml7424(primary)#: ./doc/glossary/glossary-terms.xml7430(para)#: ./doc/glossary/glossary-terms.xml7437(glossterm) #: ./doc/glossary/glossary-terms.xml7439(primary)#: ./doc/glossary/glossary-terms.xml7443(para)#: ./doc/glossary/glossary-terms.xml7448(glossterm) #: ./doc/glossary/glossary-terms.xml7450(primary)#: ./doc/glossary/glossary-terms.xml7454(para)#: ./doc/glossary/glossary-terms.xml7460(glossterm) #: ./doc/glossary/glossary-terms.xml7462(primary) msgid ""service provider"" msgstr """" #: ./doc/glossary/glossary-terms.xml7466(para) msgid """" ""A system that provides services to other system entities. In case of "" ""federated identity, OpenStack Identity is the service provider."" msgstr """" #: ./doc/glossary/glossary-terms.xml7473(glossterm) #: ./doc/glossary/glossary-terms.xml7475(primary)#: ./doc/glossary/glossary-terms.xml7479(para)#: ./doc/glossary/glossary-terms.xml7485(glossterm) #: ./doc/glossary/glossary-terms.xml7487(primary)#: ./doc/glossary/glossary-terms.xml7491(para)#: ./doc/glossary/glossary-terms.xml7497(glossterm) #: ./doc/glossary/glossary-terms.xml7499(primary)#: ./doc/glossary/glossary-terms.xml7503(para)#: ./doc/glossary/glossary-terms.xml7509(glossterm) #: ./doc/glossary/glossary-terms.xml7513(secondary)#: ./doc/glossary/glossary-terms.xml7511(primary) #: ./doc/glossary/glossary-terms.xml7525(primary) #: ./doc/glossary/glossary-terms.xml7540(primary)#: ./doc/glossary/glossary-terms.xml7517(para)#: ./doc/glossary/glossary-terms.xml7523(glossterm) #: ./doc/glossary/glossary-terms.xml7527(secondary)#: ./doc/glossary/glossary-terms.xml7531(para)#: ./doc/glossary/glossary-terms.xml7538(glossterm) #: ./doc/glossary/glossary-terms.xml7542(secondary)#: ./doc/glossary/glossary-terms.xml7546(para)#: ./doc/glossary/glossary-terms.xml7552(glossterm) #: ./doc/glossary/glossary-terms.xml7559(primary)#: ./doc/glossary/glossary-terms.xml7556(secondary)#: ./doc/glossary/glossary-terms.xml7563(para)#: ./doc/glossary/glossary-terms.xml7576(glossterm)#: ./doc/glossary/glossary-terms.xml7578(primary)#: ./doc/glossary/glossary-terms.xml7582(para)#: ./doc/glossary/glossary-terms.xml7591(glossterm) #: ./doc/glossary/glossary-terms.xml7593(primary)#: ./doc/glossary/glossary-terms.xml7597(para)#: ./doc/glossary/glossary-terms.xml7603(glossterm) #: ./doc/glossary/glossary-terms.xml7605(primary)#: ./doc/glossary/glossary-terms.xml7609(para)#: ./doc/glossary/glossary-terms.xml7615(glossterm) #: ./doc/glossary/glossary-terms.xml7618(primary)#: ./doc/glossary/glossary-terms.xml7622(para)#: ./doc/glossary/glossary-terms.xml7628(glossterm) #: ./doc/glossary/glossary-terms.xml7631(primary)#: ./doc/glossary/glossary-terms.xml7635(para)#: ./doc/glossary/glossary-terms.xml7645(glossterm) #: ./doc/glossary/glossary-terms.xml7647(primary)#: ./doc/glossary/glossary-terms.xml7651(para)#: ./doc/glossary/glossary-terms.xml7657(glossterm) #: ./doc/glossary/glossary-terms.xml7659(primary)#: ./doc/glossary/glossary-terms.xml7663(para)#: ./doc/glossary/glossary-terms.xml7670(glossterm) #: ./doc/glossary/glossary-terms.xml7677(primary)#: ./doc/glossary/glossary-terms.xml7681(para)#: ./doc/glossary/glossary-terms.xml7687(glossterm) #: ./doc/glossary/glossary-terms.xml7689(primary)#: ./doc/glossary/glossary-terms.xml7693(para)#: ./doc/glossary/glossary-terms.xml7699(glossterm)#: ./doc/glossary/glossary-terms.xml7701(primary)#: ./doc/glossary/glossary-terms.xml7706(para)#: ./doc/glossary/glossary-terms.xml7713(glossterm) #: ./doc/glossary/glossary-terms.xml7720(primary)#: ./doc/glossary/glossary-terms.xml7717(secondary)#: ./doc/glossary/glossary-terms.xml7724(para)#: ./doc/glossary/glossary-terms.xml7730(glossterm) #: ./doc/glossary/glossary-terms.xml7732(primary)#: ./doc/glossary/glossary-terms.xml7736(para)#: ./doc/glossary/glossary-terms.xml7741(glossterm) #: ./doc/glossary/glossary-terms.xml7743(primary)#: ./doc/glossary/glossary-terms.xml7747(para)#: ./doc/glossary/glossary-terms.xml7753(glossterm) #: ./doc/glossary/glossary-terms.xml7755(primary)#: ./doc/glossary/glossary-terms.xml7760(para)#: ./doc/glossary/glossary-terms.xml7768(glossterm) #: ./doc/glossary/glossary-terms.xml7770(primary)#: ./doc/glossary/glossary-terms.xml7774(para)#: ./doc/glossary/glossary-terms.xml7780(glossterm)#: ./doc/glossary/glossary-terms.xml7784(secondary)#: ./doc/glossary/glossary-terms.xml7787(primary)#: ./doc/glossary/glossary-terms.xml7791(para)#: ./doc/glossary/glossary-terms.xml7796(glossterm) #: ./doc/glossary/glossary-terms.xml7798(primary)#: ./doc/glossary/glossary-terms.xml7802(para)#: ./doc/glossary/glossary-terms.xml7808(glossterm) #: ./doc/glossary/glossary-terms.xml7810(primary)#: ./doc/glossary/glossary-terms.xml7814(para)#: ./doc/glossary/glossary-terms.xml7820(glossterm) #: ./doc/glossary/glossary-terms.xml7827(primary)#: ./doc/glossary/glossary-terms.xml7824(secondary)#: ./doc/glossary/glossary-terms.xml7831(para)#: ./doc/glossary/glossary-terms.xml7838(glossterm) #: ./doc/glossary/glossary-terms.xml7842(secondary)#: ./doc/glossary/glossary-terms.xml7840(primary) #: ./doc/glossary/glossary-terms.xml7854(primary) #: ./doc/glossary/glossary-terms.xml7868(primary) #: ./doc/glossary/glossary-terms.xml8017(primary)#: ./doc/glossary/glossary-terms.xml7846(para)#: ./doc/glossary/glossary-terms.xml7852(glossterm) #: ./doc/glossary/glossary-terms.xml7856(secondary)#: ./doc/glossary/glossary-terms.xml7860(para)#: ./doc/glossary/glossary-terms.xml7866(glossterm) #: ./doc/glossary/glossary-terms.xml7870(secondary)#: ./doc/glossary/glossary-terms.xml7874(para)#: ./doc/glossary/glossary-terms.xml7880(glossterm) #: ./doc/glossary/glossary-terms.xml7882(primary)#: ./doc/glossary/glossary-terms.xml7886(para)#: ./doc/glossary/glossary-terms.xml7892(glossterm)#: ./doc/glossary/glossary-terms.xml7894(primary)#: ./doc/glossary/glossary-terms.xml7898(para)#: ./doc/glossary/glossary-terms.xml7906(glossterm) #: ./doc/glossary/glossary-terms.xml7908(primary)#: ./doc/glossary/glossary-terms.xml7912(para)#: ./doc/glossary/glossary-terms.xml7917(glossterm) #: ./doc/glossary/glossary-terms.xml7920(primary)#: ./doc/glossary/glossary-terms.xml7929(glossterm)#: ./doc/glossary/glossary-terms.xml7931(primary)#: ./doc/glossary/glossary-terms.xml7935(para)#: ./doc/glossary/glossary-terms.xml7941(glossterm)#: ./doc/glossary/glossary-terms.xml7943(primary)#: ./doc/glossary/glossary-terms.xml7947(para)#: ./doc/glossary/glossary-terms.xml7953(glossterm) #: ./doc/glossary/glossary-terms.xml7955(primary)#: ./doc/glossary/glossary-terms.xml7959(para)#: ./doc/glossary/glossary-terms.xml7969(para)#: ./doc/glossary/glossary-terms.xml7975(glossterm) #: ./doc/glossary/glossary-terms.xml7977(primary)#: ./doc/glossary/glossary-terms.xml7981(para)#: ./doc/glossary/glossary-terms.xml7987(glossterm) #: ./doc/glossary/glossary-terms.xml7991(secondary)#: ./doc/glossary/glossary-terms.xml7995(para)#: ./doc/glossary/glossary-terms.xml8001(glossterm) #: ./doc/glossary/glossary-terms.xml8005(secondary)#: ./doc/glossary/glossary-terms.xml8009(para)#: ./doc/glossary/glossary-terms.xml8015(glossterm)#: ./doc/glossary/glossary-terms.xml8019(secondary) #: ./doc/glossary/glossary-terms.xml8024(secondary) #: ./doc/glossary/glossary-terms.xml8029(secondary)#: ./doc/glossary/glossary-terms.xml8033(para)#: ./doc/glossary/glossary-terms.xml8039(glossterm) #: ./doc/glossary/glossary-terms.xml8041(primary)#: ./doc/glossary/glossary-terms.xml8045(para)#: ./doc/glossary/glossary-terms.xml8051(glossterm) #: ./doc/glossary/glossary-terms.xml8053(primary)#: ./doc/glossary/glossary-terms.xml8057(para)#: ./doc/glossary/glossary-terms.xml8064(glossterm) #: ./doc/glossary/glossary-terms.xml8066(primary)#: ./doc/glossary/glossary-terms.xml8070(para)#: ./doc/glossary/glossary-terms.xml8080(title)#: ./doc/glossary/glossary-terms.xml8083(glossterm) #: ./doc/glossary/glossary-terms.xml8085(primary)#: ./doc/glossary/glossary-terms.xml8089(para)#: ./doc/glossary/glossary-terms.xml8096(glossterm) #: ./doc/glossary/glossary-terms.xml8098(primary)#: ./doc/glossary/glossary-terms.xml8102(para)#: ./doc/glossary/glossary-terms.xml8109(glossterm) #: ./doc/glossary/glossary-terms.xml8111(primary)#: ./doc/glossary/glossary-terms.xml8115(para)#: ./doc/glossary/glossary-terms.xml8121(glossterm) #: ./doc/glossary/glossary-terms.xml8123(primary)#: ./doc/glossary/glossary-terms.xml8127(para)#: ./doc/glossary/glossary-terms.xml8133(glossterm) #: ./doc/glossary/glossary-terms.xml8144(primary) #: ./doc/glossary/glossary-terms.xml8162(primary) #: ./doc/glossary/glossary-terms.xml8176(primary)#: ./doc/glossary/glossary-terms.xml8136(para)#: ./doc/glossary/glossary-terms.xml8142(glossterm) #: ./doc/glossary/glossary-terms.xml8146(secondary)#: ./doc/glossary/glossary-terms.xml8150(para)#: ./doc/glossary/glossary-terms.xml8155(glossterm) #: ./doc/glossary/glossary-terms.xml8159(secondary) #: ./doc/glossary/glossary-terms.xml8164(secondary)#: ./doc/glossary/glossary-terms.xml8168(para)#: ./doc/glossary/glossary-terms.xml8174(glossterm) #: ./doc/glossary/glossary-terms.xml8178(secondary)#: ./doc/glossary/glossary-terms.xml8182(para)#: ./doc/glossary/glossary-terms.xml8188(glossterm)#: ./doc/glossary/glossary-terms.xml8190(primary)#: ./doc/glossary/glossary-terms.xml8194(para)#: ./doc/glossary/glossary-terms.xml8200(glossterm) #: ./doc/glossary/glossary-terms.xml8202(primary)#: ./doc/glossary/glossary-terms.xml8206(para)#: ./doc/glossary/glossary-terms.xml8212(glossterm) #: ./doc/glossary/glossary-terms.xml8214(primary)#: ./doc/glossary/glossary-terms.xml8217(para)#: ./doc/glossary/glossary-terms.xml8225(glossterm) #: ./doc/glossary/glossary-terms.xml8227(primary)#: ./doc/glossary/glossary-terms.xml8231(para)#: ./doc/glossary/glossary-terms.xml8237(glossterm) #: ./doc/glossary/glossary-terms.xml8239(primary)#: ./doc/glossary/glossary-terms.xml8243(para)#: ./doc/glossary/glossary-terms.xml8249(glossterm)#: ./doc/glossary/glossary-terms.xml8251(primary)#: ./doc/glossary/glossary-terms.xml8255(para)#: ./doc/glossary/glossary-terms.xml8261(glossterm)#: ./doc/glossary/glossary-terms.xml8263(primary)#: ./doc/glossary/glossary-terms.xml8269(para)#: ./doc/glossary/glossary-terms.xml8274(glossterm)#: ./doc/glossary/glossary-terms.xml8277(para)#: ./doc/glossary/glossary-terms.xml8283(glossterm)#: ./doc/glossary/glossary-terms.xml8287(secondary) #: ./doc/glossary/glossary-terms.xml8290(primary)#: ./doc/glossary/glossary-terms.xml8294(para)#: ./doc/glossary/glossary-terms.xml8300(glossterm)#: ./doc/glossary/glossary-terms.xml8304(secondary) #: ./doc/glossary/glossary-terms.xml8307(primary)#: ./doc/glossary/glossary-terms.xml8311(para)#: ./doc/glossary/glossary-terms.xml8316(glossterm) #: ./doc/glossary/glossary-terms.xml8318(primary)#: ./doc/glossary/glossary-terms.xml8322(para)#: ./doc/glossary/glossary-terms.xml8330(glossterm) #: ./doc/glossary/glossary-terms.xml8332(primary)#: ./doc/glossary/glossary-terms.xml8336(para)#: ./doc/glossary/glossary-terms.xml8345(title)#: ./doc/glossary/glossary-terms.xml8348(glossterm) #: ./doc/glossary/glossary-terms.xml8350(primary)#: ./doc/glossary/glossary-terms.xml8354(para)#: ./doc/glossary/glossary-terms.xml8359(glossterm) #: ./doc/glossary/glossary-terms.xml8361(primary)#: ./doc/glossary/glossary-terms.xml8365(para)#: ./doc/glossary/glossary-terms.xml8370(glossterm)#: ./doc/glossary/glossary-terms.xml8372(primary)#: ./doc/glossary/glossary-terms.xml8376(para)#: ./doc/glossary/glossary-terms.xml8382(glossterm)#: ./doc/glossary/glossary-terms.xml8384(primary)#: ./doc/glossary/glossary-terms.xml8388(para)#: ./doc/glossary/glossary-terms.xml8395(glossterm) #: ./doc/glossary/glossary-terms.xml8397(primary)#: ./doc/glossary/glossary-terms.xml8401(para)#: ./doc/glossary/glossary-terms.xml8411(glossterm) #: ./doc/glossary/glossary-terms.xml8413(primary)#: ./doc/glossary/glossary-terms.xml8425(title)#: ./doc/glossary/glossary-terms.xml8428(glossterm) #: ./doc/glossary/glossary-terms.xml8430(primary)#: ./doc/glossary/glossary-terms.xml8434(para)#: ./doc/glossary/glossary-terms.xml8439(glossterm) #: ./doc/glossary/glossary-terms.xml8441(primary)#: ./doc/glossary/glossary-terms.xml8445(para)#: ./doc/glossary/glossary-terms.xml8455(glossterm) #: ./doc/glossary/glossary-terms.xml8458(primary)#: ./doc/glossary/glossary-terms.xml8462(para)#: ./doc/glossary/glossary-terms.xml8468(glossterm) #: ./doc/glossary/glossary-terms.xml8470(primary)#: ./doc/glossary/glossary-terms.xml8480(glossterm) #: ./doc/glossary/glossary-terms.xml8482(primary)#: ./doc/glossary/glossary-terms.xml8492(glossterm) #: ./doc/glossary/glossary-terms.xml8494(primary)#: ./doc/glossary/glossary-terms.xml8498(para)#: ./doc/glossary/glossary-terms.xml8506(glossterm) #: ./doc/glossary/glossary-terms.xml8508(primary)#: ./doc/glossary/glossary-terms.xml8512(para)#: ./doc/glossary/glossary-terms.xml8519(glossterm) #: ./doc/glossary/glossary-terms.xml8526(primary)#: ./doc/glossary/glossary-terms.xml8523(secondary) #: ./doc/glossary/glossary-terms.xml8579(secondary) #: ./doc/glossary/glossary-terms.xml8609(secondary)#: ./doc/glossary/glossary-terms.xml8530(para)#: ./doc/glossary/glossary-terms.xml8535(glossterm) #: ./doc/glossary/glossary-terms.xml8537(primary)#: ./doc/glossary/glossary-terms.xml8541(para)#: ./doc/glossary/glossary-terms.xml8550(glossterm) #: ./doc/glossary/glossary-terms.xml8552(primary)#: ./doc/glossary/glossary-terms.xml8556(para)#: ./doc/glossary/glossary-terms.xml8562(glossterm) #: ./doc/glossary/glossary-terms.xml8564(primary)#: ./doc/glossary/glossary-terms.xml8568(para)#: ./doc/glossary/glossary-terms.xml8575(glossterm) #: ./doc/glossary/glossary-terms.xml8582(primary)#: ./doc/glossary/glossary-terms.xml8586(para)#: ./doc/glossary/glossary-terms.xml8592(glossterm) #: ./doc/glossary/glossary-terms.xml8594(primary)#: ./doc/glossary/glossary-terms.xml8598(para)#: ./doc/glossary/glossary-terms.xml8605(glossterm)#: ./doc/glossary/glossary-terms.xml8612(primary)#: ./doc/glossary/glossary-terms.xml8616(para)#: ./doc/glossary/glossary-terms.xml8621(glossterm) #: ./doc/glossary/glossary-terms.xml8623(primary)#: ./doc/glossary/glossary-terms.xml8627(para)#: ./doc/glossary/glossary-terms.xml8633(glossterm) #: ./doc/glossary/glossary-terms.xml8635(primary)#: ./doc/glossary/glossary-terms.xml8639(para)#: ./doc/glossary/glossary-terms.xml8644(glossterm) #: ./doc/glossary/glossary-terms.xml8646(primary)#: ./doc/glossary/glossary-terms.xml8655(glossterm) #: ./doc/glossary/glossary-terms.xml8657(primary)#: ./doc/glossary/glossary-terms.xml8661(para)#: ./doc/glossary/glossary-terms.xml8667(glossterm) #: ./doc/glossary/glossary-terms.xml8674(primary)#: ./doc/glossary/glossary-terms.xml8671(secondary)#: ./doc/glossary/glossary-terms.xml8678(para)#: ./doc/glossary/glossary-terms.xml8688(glossterm) #: ./doc/glossary/glossary-terms.xml8690(primary)#: ./doc/glossary/glossary-terms.xml8700(glossterm) #: ./doc/glossary/glossary-terms.xml8702(primary)#: ./doc/glossary/glossary-terms.xml8706(para)#: ./doc/glossary/glossary-terms.xml8711(glossterm) #: ./doc/glossary/glossary-terms.xml8713(primary)#: ./doc/glossary/glossary-terms.xml8717(para)#: ./doc/glossary/glossary-terms.xml8723(glossterm) #: ./doc/glossary/glossary-terms.xml8725(primary)#: ./doc/glossary/glossary-terms.xml8729(para)#: ./doc/glossary/glossary-terms.xml8734(glossterm)#: ./doc/glossary/glossary-terms.xml8737(para)#: ./doc/glossary/glossary-terms.xml8742(glossterm) #: ./doc/glossary/glossary-terms.xml8744(primary)#: ./doc/glossary/glossary-terms.xml8748(para)#: ./doc/glossary/glossary-terms.xml8754(glossterm) #: ./doc/glossary/glossary-terms.xml8766(primary) #: ./doc/glossary/glossary-terms.xml8779(primary) #: ./doc/glossary/glossary-terms.xml8793(primary) #: ./doc/glossary/glossary-terms.xml8806(primary) #: ./doc/glossary/glossary-terms.xml8820(primary) #: ./doc/glossary/glossary-terms.xml8834(primary) #: ./doc/glossary/glossary-terms.xml8848(primary)#: ./doc/glossary/glossary-terms.xml8757(para)#: ./doc/glossary/glossary-terms.xml8764(glossterm) #: ./doc/glossary/glossary-terms.xml8768(secondary)#: ./doc/glossary/glossary-terms.xml8772(para)#: ./doc/glossary/glossary-terms.xml8777(glossterm) #: ./doc/glossary/glossary-terms.xml8781(secondary)#: ./doc/glossary/glossary-terms.xml8785(para)#: ./doc/glossary/glossary-terms.xml8791(glossterm) #: ./doc/glossary/glossary-terms.xml8795(secondary)#: ./doc/glossary/glossary-terms.xml8799(para)#: ./doc/glossary/glossary-terms.xml8804(glossterm) #: ./doc/glossary/glossary-terms.xml8808(secondary)#: ./doc/glossary/glossary-terms.xml8812(para)#: ./doc/glossary/glossary-terms.xml8818(glossterm) #: ./doc/glossary/glossary-terms.xml8822(secondary)#: ./doc/glossary/glossary-terms.xml8826(para)#: ./doc/glossary/glossary-terms.xml8832(glossterm) #: ./doc/glossary/glossary-terms.xml8836(secondary)#: ./doc/glossary/glossary-terms.xml8840(para)#: ./doc/glossary/glossary-terms.xml8846(glossterm) #: ./doc/glossary/glossary-terms.xml8850(secondary)#: ./doc/glossary/glossary-terms.xml8854(para)#: ./doc/glossary/glossary-terms.xml8860(glossterm)#: ./doc/glossary/glossary-terms.xml8862(primary)#: ./doc/glossary/glossary-terms.xml8866(para)#: ./doc/glossary/glossary-terms.xml8874(glossterm) #: ./doc/glossary/glossary-terms.xml8876(primary)#: ./doc/glossary/glossary-terms.xml8888(title)#: ./doc/glossary/glossary-terms.xml8891(glossterm) #: ./doc/glossary/glossary-terms.xml8893(primary)#: ./doc/glossary/glossary-terms.xml8897(para)#: ./doc/glossary/glossary-terms.xml8904(glossterm) #: ./doc/glossary/glossary-terms.xml8906(primary)#: ./doc/glossary/glossary-terms.xml8910(para)#: ./doc/glossary/glossary-terms.xml8916(glossterm) #: ./doc/glossary/glossary-terms.xml8918(primary)#: ./doc/glossary/glossary-terms.xml8922(para)#: ./doc/glossary/glossary-terms.xml8928(glossterm)#: ./doc/glossary/glossary-terms.xml8930(primary)#: ./doc/glossary/glossary-terms.xml8934(para)#: ./doc/glossary/glossary-terms.xml8945(title)#: ./doc/glossary/glossary-terms.xml8948(glossterm) #: ./doc/glossary/glossary-terms.xml8950(primary)#: ./doc/glossary/glossary-terms.xml8954(para)#: ./doc/glossary/glossary-terms.xml8964(glossterm) #: ./doc/glossary/glossary-terms.xml8975(primary) #: ./doc/glossary/glossary-terms.xml8988(primary) #: ./doc/glossary/glossary-terms.xml9002(primary)#: ./doc/glossary/glossary-terms.xml8967(para)#: ./doc/glossary/glossary-terms.xml8973(glossterm) #: ./doc/glossary/glossary-terms.xml8977(secondary)#: ./doc/glossary/glossary-terms.xml8986(glossterm) #: ./doc/glossary/glossary-terms.xml8990(secondary)#: ./doc/glossary/glossary-terms.xml8994(para)#: ./doc/glossary/glossary-terms.xml9000(glossterm)#: ./doc/glossary/glossary-terms.xml9004(secondary)#: ./doc/glossary/glossary-terms.xml9016(title)#: ./doc/glossary/glossary-terms.xml9030(title)#: ./doc/glossary/glossary-terms.xml9033(glossterm) #: ./doc/glossary/glossary-terms.xml9035(primary)#: ./doc/glossary/glossary-terms.xml9039(para)#: ./doc/glossary/glossary-terms.xml9045(glossterm) #: ./doc/glossary/glossary-terms.xml9047(primary)#: ./doc/glossary/glossary-terms.xml9051(para)","""POT-Creation-Date: 2014-10-11 02:09+0000\n"" ""PO-Revision-Date: 2014-10-11 03:10+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""#: ./doc/glossary/glossary-terms.xml4960(see)#: ./doc/glossary/glossary-terms.xml3286(secondary) #: ./doc/glossary/glossary-terms.xml3929(secondary) #: ./doc/glossary/glossary-terms.xml3981(secondary) #: ./doc/glossary/glossary-terms.xml4086(secondary) #: ./doc/glossary/glossary-terms.xml4303(secondary) #: ./doc/glossary/glossary-terms.xml4468(secondary) #: ./doc/glossary/glossary-terms.xml4486(secondary) #: ./doc/glossary/glossary-terms.xml4997(secondary) #: ./doc/glossary/glossary-terms.xml5345(secondary) #: ./doc/glossary/glossary-terms.xml5598(secondary) #: ./doc/glossary/glossary-terms.xml5714(secondary) #: ./doc/glossary/glossary-terms.xml6071(secondary) #: ./doc/glossary/glossary-terms.xml6256(secondary) #: ./doc/glossary/glossary-terms.xml6347(secondary) #: ./doc/glossary/glossary-terms.xml6919(secondary) #: ./doc/glossary/glossary-terms.xml7022(secondary) #: ./doc/glossary/glossary-terms.xml7066(secondary) #: ./doc/glossary/glossary-terms.xml7345(secondary) #: ./doc/glossary/glossary-terms.xml7388(secondary)#: ./doc/glossary/glossary-terms.xml3559(primary) #: ./doc/glossary/glossary-terms.xml8106(primary)#: ./doc/glossary/glossary-terms.xml6460(primary)#: ./doc/glossary/glossary-terms.xml6442(primary) #: ./doc/glossary/glossary-terms.xml6874(primary) #: ./doc/glossary/glossary-terms.xml7343(primary) #: ./doc/glossary/glossary-terms.xml7372(primary) #: ./doc/glossary/glossary-terms.xml8556(primary)#: ./doc/glossary/glossary-terms.xml6051(primary)#: ./doc/glossary/glossary-terms.xml6001(para) #: ./doc/glossary/glossary-terms.xml6830(para) #: ./doc/glossary/glossary-terms.xml7873(para)#: ./doc/glossary/glossary-terms.xml5680(secondary)#: ./doc/glossary/glossary-terms.xml5009(primary) #: ./doc/glossary/glossary-terms.xml5712(primary) #: ./doc/glossary/glossary-terms.xml5726(primary) #: ./doc/glossary/glossary-terms.xml5740(primary) #: ./doc/glossary/glossary-terms.xml5755(primary) #: ./doc/glossary/glossary-terms.xml5768(primary) #: ./doc/glossary/glossary-terms.xml5782(primary) #: ./doc/glossary/glossary-terms.xml5796(primary) #: ./doc/glossary/glossary-terms.xml5851(primary) #: ./doc/glossary/glossary-terms.xml7313(primary)#: ./doc/glossary/glossary-terms.xml3833(secondary) #: ./doc/glossary/glossary-terms.xml3963(secondary) #: ./doc/glossary/glossary-terms.xml4044(secondary) #: ./doc/glossary/glossary-terms.xml5960(secondary) #: ./doc/glossary/glossary-terms.xml6795(secondary)#: ./doc/glossary/glossary-terms.xml5645(see)#: ./doc/glossary/glossary-terms.xml4883(para) #: ./doc/glossary/glossary-terms.xml8366(para) #: ./doc/glossary/glossary-terms.xml8599(para) #: ./doc/glossary/glossary-terms.xml8829(para) #: ./doc/glossary/glossary-terms.xml8930(para) #: ./doc/glossary/glossary-terms.xml8957(para)#: ./doc/glossary/glossary-terms.xml8251(primary)#: ./doc/glossary/glossary-terms.xml3242(para)#: ./doc/glossary/glossary-terms.xml3247(glossterm) #: ./doc/glossary/glossary-terms.xml3249(primary)#: ./doc/glossary/glossary-terms.xml3253(para)#: ./doc/glossary/glossary-terms.xml3259(glossterm) #: ./doc/glossary/glossary-terms.xml3261(primary)#: ./doc/glossary/glossary-terms.xml3265(para)#: ./doc/glossary/glossary-terms.xml3270(glossterm) #: ./doc/glossary/glossary-terms.xml3272(primary)#: ./doc/glossary/glossary-terms.xml3276(para)#: ./doc/glossary/glossary-terms.xml3282(glossterm)#: ./doc/glossary/glossary-terms.xml3284(primary) #: ./doc/glossary/glossary-terms.xml4258(primary)#: ./doc/glossary/glossary-terms.xml3290(para)#: ./doc/glossary/glossary-terms.xml3296(glossterm)#: ./doc/glossary/glossary-terms.xml3298(primary)#: ./doc/glossary/glossary-terms.xml3302(para)#: ./doc/glossary/glossary-terms.xml3309(glossterm) #: ./doc/glossary/glossary-terms.xml3311(primary)#: ./doc/glossary/glossary-terms.xml3315(para)#: ./doc/glossary/glossary-terms.xml3321(glossterm)#: ./doc/glossary/glossary-terms.xml3323(primary) #: ./doc/glossary/glossary-terms.xml3418(primary) #: ./doc/glossary/glossary-terms.xml4484(primary) #: ./doc/glossary/glossary-terms.xml6305(primary) #: ./doc/glossary/glossary-terms.xml6494(primary) #: ./doc/glossary/glossary-terms.xml7503(primary) #: ./doc/glossary/glossary-terms.xml7731(primary)#: ./doc/glossary/glossary-terms.xml3325(secondary)#: ./doc/glossary/glossary-terms.xml3328(primary)#: ./doc/glossary/glossary-terms.xml3332(para)#: ./doc/glossary/glossary-terms.xml3340(glossterm) #: ./doc/glossary/glossary-terms.xml3342(primary)#: ./doc/glossary/glossary-terms.xml3346(para)#: ./doc/glossary/glossary-terms.xml3353(glossterm) #: ./doc/glossary/glossary-terms.xml3355(primary)#: ./doc/glossary/glossary-terms.xml3359(para)#: ./doc/glossary/glossary-terms.xml3366(glossterm) #: ./doc/glossary/glossary-terms.xml3368(primary)#: ./doc/glossary/glossary-terms.xml3372(para)#: ./doc/glossary/glossary-terms.xml3381(glossterm) #: ./doc/glossary/glossary-terms.xml3383(primary)#: ./doc/glossary/glossary-terms.xml3387(para)#: ./doc/glossary/glossary-terms.xml3393(glossterm) #: ./doc/glossary/glossary-terms.xml3395(primary)#: ./doc/glossary/glossary-terms.xml3399(para)#: ./doc/glossary/glossary-terms.xml3404(glossterm) #: ./doc/glossary/glossary-terms.xml3406(primary)#: ./doc/glossary/glossary-terms.xml3410(para)#: ./doc/glossary/glossary-terms.xml3416(glossterm) #: ./doc/glossary/glossary-terms.xml3423(primary)#: ./doc/glossary/glossary-terms.xml3420(secondary)#: ./doc/glossary/glossary-terms.xml3427(para)#: ./doc/glossary/glossary-terms.xml3436(glossterm) #: ./doc/glossary/glossary-terms.xml3438(primary)#: ./doc/glossary/glossary-terms.xml3442(para)#: ./doc/glossary/glossary-terms.xml3447(para)#: ./doc/glossary/glossary-terms.xml3455(glossterm) #: ./doc/glossary/glossary-terms.xml3457(primary)#: ./doc/glossary/glossary-terms.xml3461(para)#: ./doc/glossary/glossary-terms.xml3467(glossterm)#: ./doc/glossary/glossary-terms.xml3469(primary)#: ./doc/glossary/glossary-terms.xml3473(para)#: ./doc/glossary/glossary-terms.xml3482(title)#: ./doc/glossary/glossary-terms.xml3485(glossterm) #: ./doc/glossary/glossary-terms.xml3487(primary)#: ./doc/glossary/glossary-terms.xml3491(para)#: ./doc/glossary/glossary-terms.xml3497(glossterm) #: ./doc/glossary/glossary-terms.xml3499(primary)#: ./doc/glossary/glossary-terms.xml3502(para)#: ./doc/glossary/glossary-terms.xml3509(glossterm) #: ./doc/glossary/glossary-terms.xml3511(primary)#: ./doc/glossary/glossary-terms.xml3514(para)#: ./doc/glossary/glossary-terms.xml3521(glossterm) #: ./doc/glossary/glossary-terms.xml3531(primary) #: ./doc/glossary/glossary-terms.xml3546(primary)#: ./doc/glossary/glossary-terms.xml3524(para)#: ./doc/glossary/glossary-terms.xml3529(glossterm) #: ./doc/glossary/glossary-terms.xml3533(secondary)#: ./doc/glossary/glossary-terms.xml3537(para)#: ./doc/glossary/glossary-terms.xml3544(glossterm) #: ./doc/glossary/glossary-terms.xml3548(secondary)#: ./doc/glossary/glossary-terms.xml3552(para)#: ./doc/glossary/glossary-terms.xml3557(glossterm) #: ./doc/glossary/glossary-terms.xml3561(secondary) #: ./doc/glossary/glossary-terms.xml3564(primary)#: ./doc/glossary/glossary-terms.xml3568(para)#: ./doc/glossary/glossary-terms.xml3574(glossterm) #: ./doc/glossary/glossary-terms.xml3576(primary)#: ./doc/glossary/glossary-terms.xml3580(para)#: ./doc/glossary/glossary-terms.xml3586(glossterm) #: ./doc/glossary/glossary-terms.xml3588(primary)#: ./doc/glossary/glossary-terms.xml3592(para)#: ./doc/glossary/glossary-terms.xml3599(glossterm) #: ./doc/glossary/glossary-terms.xml3601(primary)#: ./doc/glossary/glossary-terms.xml3605(para)#: ./doc/glossary/glossary-terms.xml3611(glossterm) #: ./doc/glossary/glossary-terms.xml3613(primary)#: ./doc/glossary/glossary-terms.xml3617(para)#: ./doc/glossary/glossary-terms.xml3623(glossterm) #: ./doc/glossary/glossary-terms.xml3625(primary)#: ./doc/glossary/glossary-terms.xml3629(para)#: ./doc/glossary/glossary-terms.xml3636(glossterm) #: ./doc/glossary/glossary-terms.xml3638(primary)#: ./doc/glossary/glossary-terms.xml3642(para)#: ./doc/glossary/glossary-terms.xml3650(glossterm) #: ./doc/glossary/glossary-terms.xml3652(primary)#: ./doc/glossary/glossary-terms.xml3656(para)#: ./doc/glossary/glossary-terms.xml3665(title)#: ./doc/glossary/glossary-terms.xml3668(glossterm) #: ./doc/glossary/glossary-terms.xml3670(primary)#: ./doc/glossary/glossary-terms.xml3674(para)#: ./doc/glossary/glossary-terms.xml3680(glossterm) #: ./doc/glossary/glossary-terms.xml3682(primary)#: ./doc/glossary/glossary-terms.xml3686(para)#: ./doc/glossary/glossary-terms.xml3692(glossterm) #: ./doc/glossary/glossary-terms.xml3694(primary)#: ./doc/glossary/glossary-terms.xml3698(para)#: ./doc/glossary/glossary-terms.xml3705(glossterm) #: ./doc/glossary/glossary-terms.xml3707(primary)#: ./doc/glossary/glossary-terms.xml3711(para)#: ./doc/glossary/glossary-terms.xml3718(glossterm) #: ./doc/glossary/glossary-terms.xml3720(primary)#: ./doc/glossary/glossary-terms.xml3724(para)#: ./doc/glossary/glossary-terms.xml3730(glossterm) #: ./doc/glossary/glossary-terms.xml3732(primary) #: ./doc/glossary/glossary-terms.xml7705(see)#: ./doc/glossary/glossary-terms.xml3736(para)#: ./doc/glossary/glossary-terms.xml3741(glossterm) #: ./doc/glossary/glossary-terms.xml3743(primary)#: ./doc/glossary/glossary-terms.xml3747(para)#: ./doc/glossary/glossary-terms.xml3757(glossterm) #: ./doc/glossary/glossary-terms.xml3759(primary)#: ./doc/glossary/glossary-terms.xml3763(para)#: ./doc/glossary/glossary-terms.xml3774(glossterm)#: ./doc/glossary/glossary-terms.xml3777(para)#: ./doc/glossary/glossary-terms.xml3783(glossterm)#: ./doc/glossary/glossary-terms.xml3785(primary)#: ./doc/glossary/glossary-terms.xml3789(para)#: ./doc/glossary/glossary-terms.xml3794(glossterm)#: ./doc/glossary/glossary-terms.xml3796(primary)#: ./doc/glossary/glossary-terms.xml3800(para)#: ./doc/glossary/glossary-terms.xml3805(glossterm) #: ./doc/glossary/glossary-terms.xml3807(primary)#: ./doc/glossary/glossary-terms.xml3811(para)#: ./doc/glossary/glossary-terms.xml3817(glossterm) #: ./doc/glossary/glossary-terms.xml3819(primary)#: ./doc/glossary/glossary-terms.xml3823(para)#: ./doc/glossary/glossary-terms.xml3829(glossterm)#: ./doc/glossary/glossary-terms.xml3831(primary)#: ./doc/glossary/glossary-terms.xml3837(para)#: ./doc/glossary/glossary-terms.xml3847(glossterm)#: ./doc/glossary/glossary-terms.xml3849(primary)#: ./doc/glossary/glossary-terms.xml3853(para)#: ./doc/glossary/glossary-terms.xml3864(glossterm) #: ./doc/glossary/glossary-terms.xml3866(primary)#: ./doc/glossary/glossary-terms.xml3870(para)#: ./doc/glossary/glossary-terms.xml3882(glossterm) #: ./doc/glossary/glossary-terms.xml3884(primary)#: ./doc/glossary/glossary-terms.xml3888(para)#: ./doc/glossary/glossary-terms.xml3893(glossterm) #: ./doc/glossary/glossary-terms.xml3895(primary)#: ./doc/glossary/glossary-terms.xml3899(para)#: ./doc/glossary/glossary-terms.xml3906(glossterm)#: ./doc/glossary/glossary-terms.xml3909(para)#: ./doc/glossary/glossary-terms.xml3915(glossterm)#: ./doc/glossary/glossary-terms.xml3918(para)#: ./doc/glossary/glossary-terms.xml3925(glossterm)#: ./doc/glossary/glossary-terms.xml3927(primary) #: ./doc/glossary/glossary-terms.xml3941(primary)#: ./doc/glossary/glossary-terms.xml3933(para)#: ./doc/glossary/glossary-terms.xml3939(glossterm)#: ./doc/glossary/glossary-terms.xml3943(secondary)#: ./doc/glossary/glossary-terms.xml3947(para)#: ./doc/glossary/glossary-terms.xml3956(title)#: ./doc/glossary/glossary-terms.xml3959(glossterm)#: ./doc/glossary/glossary-terms.xml3961(primary)#: ./doc/glossary/glossary-terms.xml3967(para)#: ./doc/glossary/glossary-terms.xml3977(glossterm) #: ./doc/glossary/glossary-terms.xml3979(primary)#: ./doc/glossary/glossary-terms.xml3985(para)#: ./doc/glossary/glossary-terms.xml3992(glossterm)#: ./doc/glossary/glossary-terms.xml3994(primary)#: ./doc/glossary/glossary-terms.xml3998(para)#: ./doc/glossary/glossary-terms.xml4006(glossterm) #: ./doc/glossary/glossary-terms.xml4008(primary)#: ./doc/glossary/glossary-terms.xml4012(para)#: ./doc/glossary/glossary-terms.xml4018(glossterm)#: ./doc/glossary/glossary-terms.xml4021(para)#: ./doc/glossary/glossary-terms.xml4026(glossterm) #: ./doc/glossary/glossary-terms.xml4030(secondary)#: ./doc/glossary/glossary-terms.xml4028(primary) #: ./doc/glossary/glossary-terms.xml4040(glossterm) #: ./doc/glossary/glossary-terms.xml4042(primary) #: ./doc/glossary/glossary-terms.xml4059(primary) #: ./doc/glossary/glossary-terms.xml4130(primary)#: ./doc/glossary/glossary-terms.xml4034(para)#: ./doc/glossary/glossary-terms.xml4048(para)#: ./doc/glossary/glossary-terms.xml4057(glossterm) #: ./doc/glossary/glossary-terms.xml4061(secondary)#: ./doc/glossary/glossary-terms.xml4065(para)#: ./doc/glossary/glossary-terms.xml4071(glossterm)#: ./doc/glossary/glossary-terms.xml4073(primary)#: ./doc/glossary/glossary-terms.xml4077(para)#: ./doc/glossary/glossary-terms.xml4082(glossterm)#: ./doc/glossary/glossary-terms.xml4084(primary)#: ./doc/glossary/glossary-terms.xml4090(para)#: ./doc/glossary/glossary-terms.xml4099(glossterm)#: ./doc/glossary/glossary-terms.xml4101(primary) #: ./doc/glossary/glossary-terms.xml4115(primary) #: ./doc/glossary/glossary-terms.xml4144(primary) #: ./doc/glossary/glossary-terms.xml4158(primary) #: ./doc/glossary/glossary-terms.xml4172(primary) #: ./doc/glossary/glossary-terms.xml4184(glossterm) #: ./doc/glossary/glossary-terms.xml4204(primary) #: ./doc/glossary/glossary-terms.xml4218(primary) #: ./doc/glossary/glossary-terms.xml4232(primary) #: ./doc/glossary/glossary-terms.xml6477(primary)#: ./doc/glossary/glossary-terms.xml4103(secondary) #: ./doc/glossary/glossary-terms.xml4194(glossterm)#: ./doc/glossary/glossary-terms.xml4107(para)#: ./doc/glossary/glossary-terms.xml4113(glossterm) #: ./doc/glossary/glossary-terms.xml4117(secondary)#: ./doc/glossary/glossary-terms.xml4121(para)#: ./doc/glossary/glossary-terms.xml4128(glossterm) #: ./doc/glossary/glossary-terms.xml4132(secondary)#: ./doc/glossary/glossary-terms.xml4136(para)#: ./doc/glossary/glossary-terms.xml4142(glossterm) #: ./doc/glossary/glossary-terms.xml4146(secondary)#: ./doc/glossary/glossary-terms.xml4150(para) #: ./doc/glossary/glossary-terms.xml5095(para)#: ./doc/glossary/glossary-terms.xml4156(glossterm) #: ./doc/glossary/glossary-terms.xml4160(secondary)#: ./doc/glossary/glossary-terms.xml4164(para)#: ./doc/glossary/glossary-terms.xml4170(glossterm) #: ./doc/glossary/glossary-terms.xml4174(secondary)#: ./doc/glossary/glossary-terms.xml4178(para)#: ./doc/glossary/glossary-terms.xml4187(para)#: ./doc/glossary/glossary-terms.xml4197(para)#: ./doc/glossary/glossary-terms.xml4202(glossterm) #: ./doc/glossary/glossary-terms.xml4206(secondary)#: ./doc/glossary/glossary-terms.xml4210(para)#: ./doc/glossary/glossary-terms.xml4216(glossterm) #: ./doc/glossary/glossary-terms.xml4220(secondary)#: ./doc/glossary/glossary-terms.xml4224(para)#: ./doc/glossary/glossary-terms.xml4230(glossterm) #: ./doc/glossary/glossary-terms.xml4234(secondary)#: ./doc/glossary/glossary-terms.xml4238(para)#: ./doc/glossary/glossary-terms.xml4244(glossterm)#: ./doc/glossary/glossary-terms.xml4246(primary)#: ./doc/glossary/glossary-terms.xml4250(para)#: ./doc/glossary/glossary-terms.xml4256(glossterm) #: ./doc/glossary/glossary-terms.xml4260(secondary) #: ./doc/glossary/glossary-terms.xml4263(primary)#: ./doc/glossary/glossary-terms.xml4267(para)#: ./doc/glossary/glossary-terms.xml4273(glossterm) #: ./doc/glossary/glossary-terms.xml4275(primary)#: ./doc/glossary/glossary-terms.xml4278(para)#: ./doc/glossary/glossary-terms.xml4287(glossterm) #: ./doc/glossary/glossary-terms.xml4289(primary)#: ./doc/glossary/glossary-terms.xml4293(para)#: ./doc/glossary/glossary-terms.xml4299(glossterm)#: ./doc/glossary/glossary-terms.xml4301(primary) #: ./doc/glossary/glossary-terms.xml4315(primary) #: ./doc/glossary/glossary-terms.xml4328(primary) #: ./doc/glossary/glossary-terms.xml4352(primary) #: ./doc/glossary/glossary-terms.xml4367(primary) #: ./doc/glossary/glossary-terms.xml4380(primary)#: ./doc/glossary/glossary-terms.xml4307(para)#: ./doc/glossary/glossary-terms.xml4313(glossterm) #: ./doc/glossary/glossary-terms.xml4317(secondary)#: ./doc/glossary/glossary-terms.xml4321(para)#: ./doc/glossary/glossary-terms.xml4326(glossterm) #: ./doc/glossary/glossary-terms.xml4330(secondary)#: ./doc/glossary/glossary-terms.xml4334(para)#: ./doc/glossary/glossary-terms.xml4339(glossterm) #: ./doc/glossary/glossary-terms.xml4341(primary)#: ./doc/glossary/glossary-terms.xml4344(para)#: ./doc/glossary/glossary-terms.xml4350(glossterm) #: ./doc/glossary/glossary-terms.xml4354(secondary)#: ./doc/glossary/glossary-terms.xml4358(para)#: ./doc/glossary/glossary-terms.xml4365(glossterm) #: ./doc/glossary/glossary-terms.xml4369(secondary)#: ./doc/glossary/glossary-terms.xml4373(para)#: ./doc/glossary/glossary-terms.xml4378(glossterm) #: ./doc/glossary/glossary-terms.xml4382(secondary)#: ./doc/glossary/glossary-terms.xml4386(para) #: ./doc/glossary/glossary-terms.xml7378(para)#: ./doc/glossary/glossary-terms.xml4392(glossterm) #: ./doc/glossary/glossary-terms.xml4394(primary)#: ./doc/glossary/glossary-terms.xml4398(para)#: ./doc/glossary/glossary-terms.xml4404(glossterm) #: ./doc/glossary/glossary-terms.xml4406(primary)#: ./doc/glossary/glossary-terms.xml4410(para)#: ./doc/glossary/glossary-terms.xml4416(glossterm) #: ./doc/glossary/glossary-terms.xml4418(primary)#: ./doc/glossary/glossary-terms.xml4422(para)#: ./doc/glossary/glossary-terms.xml4428(glossterm) #: ./doc/glossary/glossary-terms.xml4430(primary)#: ./doc/glossary/glossary-terms.xml4434(para)#: ./doc/glossary/glossary-terms.xml4440(glossterm) #: ./doc/glossary/glossary-terms.xml4442(primary)#: ./doc/glossary/glossary-terms.xml4446(para)#: ./doc/glossary/glossary-terms.xml4452(glossterm) #: ./doc/glossary/glossary-terms.xml4454(primary)#: ./doc/glossary/glossary-terms.xml4458(para)#: ./doc/glossary/glossary-terms.xml4464(glossterm) #: ./doc/glossary/glossary-terms.xml4466(primary)#: ./doc/glossary/glossary-terms.xml4472(para)#: ./doc/glossary/glossary-terms.xml4482(glossterm)#: ./doc/glossary/glossary-terms.xml4490(para)#: ./doc/glossary/glossary-terms.xml4497(glossterm) #: ./doc/glossary/glossary-terms.xml4499(primary)#: ./doc/glossary/glossary-terms.xml4503(para)#: ./doc/glossary/glossary-terms.xml4510(glossterm)#: ./doc/glossary/glossary-terms.xml4512(primary)#: ./doc/glossary/glossary-terms.xml4516(para)#: ./doc/glossary/glossary-terms.xml4521(glossterm)#: ./doc/glossary/glossary-terms.xml4523(primary)#: ./doc/glossary/glossary-terms.xml4527(para)#: ./doc/glossary/glossary-terms.xml4538(glossterm) #: ./doc/glossary/glossary-terms.xml4540(primary)#: ./doc/glossary/glossary-terms.xml4544(para)#: ./doc/glossary/glossary-terms.xml4552(glossterm) #: ./doc/glossary/glossary-terms.xml4554(primary)#: ./doc/glossary/glossary-terms.xml4558(para)#: ./doc/glossary/glossary-terms.xml4566(glossterm) #: ./doc/glossary/glossary-terms.xml4568(primary)#: ./doc/glossary/glossary-terms.xml4572(para)#: ./doc/glossary/glossary-terms.xml4583(glossterm)#: ./doc/glossary/glossary-terms.xml4585(primary)#: ./doc/glossary/glossary-terms.xml4589(para)#: ./doc/glossary/glossary-terms.xml4595(glossterm)#: ./doc/glossary/glossary-terms.xml4597(primary)#: ./doc/glossary/glossary-terms.xml4601(para) #: ./doc/glossary/glossary-terms.xml6575(para) #: ./doc/glossary/glossary-terms.xml8423(para) #: ./doc/glossary/glossary-terms.xml8435(para) #: ./doc/glossary/glossary-terms.xml8643(para)#: ./doc/glossary/glossary-terms.xml4607(glossterm) #: ./doc/glossary/glossary-terms.xml4609(primary)#: ./doc/glossary/glossary-terms.xml4613(para)#: ./doc/glossary/glossary-terms.xml4622(title)#: ./doc/glossary/glossary-terms.xml4625(glossterm) #: ./doc/glossary/glossary-terms.xml4627(primary)#: ./doc/glossary/glossary-terms.xml4631(para)#: ./doc/glossary/glossary-terms.xml4637(glossterm) #: ./doc/glossary/glossary-terms.xml4639(primary)#: ./doc/glossary/glossary-terms.xml4643(para)#: ./doc/glossary/glossary-terms.xml4648(glossterm) #: ./doc/glossary/glossary-terms.xml4650(primary)#: ./doc/glossary/glossary-terms.xml4654(para)#: ./doc/glossary/glossary-terms.xml4659(glossterm) #: ./doc/glossary/glossary-terms.xml4661(primary)#: ./doc/glossary/glossary-terms.xml4665(para)#: ./doc/glossary/glossary-terms.xml4671(glossterm) #: ./doc/glossary/glossary-terms.xml4673(primary)#: ./doc/glossary/glossary-terms.xml4677(para)#: ./doc/glossary/glossary-terms.xml4683(glossterm) #: ./doc/glossary/glossary-terms.xml4685(primary)#: ./doc/glossary/glossary-terms.xml4689(para)#: ./doc/glossary/glossary-terms.xml4699(title)#: ./doc/glossary/glossary-terms.xml4702(glossterm)#: ./doc/glossary/glossary-terms.xml4704(primary)#: ./doc/glossary/glossary-terms.xml4708(para)#: ./doc/glossary/glossary-terms.xml4720(glossterm) #: ./doc/glossary/glossary-terms.xml4722(primary)#: ./doc/glossary/glossary-terms.xml4726(para)#: ./doc/glossary/glossary-terms.xml4731(glossterm) #: ./doc/glossary/glossary-terms.xml4733(primary)#: ./doc/glossary/glossary-terms.xml4737(para)#: ./doc/glossary/glossary-terms.xml4743(glossterm) #: ./doc/glossary/glossary-terms.xml4745(primary)#: ./doc/glossary/glossary-terms.xml4749(para)#: ./doc/glossary/glossary-terms.xml4762(title)#: ./doc/glossary/glossary-terms.xml4765(glossterm) #: ./doc/glossary/glossary-terms.xml4767(primary)#: ./doc/glossary/glossary-terms.xml4771(para)#: ./doc/glossary/glossary-terms.xml4776(glossterm) #: ./doc/glossary/glossary-terms.xml4778(primary)#: ./doc/glossary/glossary-terms.xml4782(para)#: ./doc/glossary/glossary-terms.xml4787(glossterm) #: ./doc/glossary/glossary-terms.xml4789(primary)#: ./doc/glossary/glossary-terms.xml4793(para)#: ./doc/glossary/glossary-terms.xml4803(glossterm) #: ./doc/glossary/glossary-terms.xml4805(primary)#: ./doc/glossary/glossary-terms.xml4809(para)#: ./doc/glossary/glossary-terms.xml4818(glossterm) #: ./doc/glossary/glossary-terms.xml4820(primary)#: ./doc/glossary/glossary-terms.xml4824(para)#: ./doc/glossary/glossary-terms.xml4830(glossterm) #: ./doc/glossary/glossary-terms.xml4832(primary)#: ./doc/glossary/glossary-terms.xml4836(para)#: ./doc/glossary/glossary-terms.xml4842(glossterm) #: ./doc/glossary/glossary-terms.xml4844(primary)#: ./doc/glossary/glossary-terms.xml4848(para)#: ./doc/glossary/glossary-terms.xml4854(glossterm)#: ./doc/glossary/glossary-terms.xml4857(para)#: ./doc/glossary/glossary-terms.xml4863(glossterm)#: ./doc/glossary/glossary-terms.xml4865(primary)#: ./doc/glossary/glossary-terms.xml4867(secondary) #: ./doc/glossary/glossary-terms.xml5935(secondary)#: ./doc/glossary/glossary-terms.xml4871(para)#: ./doc/glossary/glossary-terms.xml4877(glossterm) #: ./doc/glossary/glossary-terms.xml4879(primary)#: ./doc/glossary/glossary-terms.xml4888(glossterm) #: ./doc/glossary/glossary-terms.xml4890(primary)#: ./doc/glossary/glossary-terms.xml4894(para)#: ./doc/glossary/glossary-terms.xml4901(glossterm)#: ./doc/glossary/glossary-terms.xml4904(para)#: ./doc/glossary/glossary-terms.xml4912(glossterm) #: ./doc/glossary/glossary-terms.xml4914(primary)#: ./doc/glossary/glossary-terms.xml4918(para)#: ./doc/glossary/glossary-terms.xml4924(glossterm) #: ./doc/glossary/glossary-terms.xml4927(primary)#: ./doc/glossary/glossary-terms.xml4931(para)#: ./doc/glossary/glossary-terms.xml4937(glossterm) #: ./doc/glossary/glossary-terms.xml4939(primary)#: ./doc/glossary/glossary-terms.xml4943(para)#: ./doc/glossary/glossary-terms.xml4953(title)#: ./doc/glossary/glossary-terms.xml4956(glossterm) #: ./doc/glossary/glossary-terms.xml4958(primary)#: ./doc/glossary/glossary-terms.xml4964(para)#: ./doc/glossary/glossary-terms.xml4969(glossterm) #: ./doc/glossary/glossary-terms.xml4971(primary)#: ./doc/glossary/glossary-terms.xml4975(para)#: ./doc/glossary/glossary-terms.xml4981(glossterm) #: ./doc/glossary/glossary-terms.xml4983(primary)#: ./doc/glossary/glossary-terms.xml4987(para)#: ./doc/glossary/glossary-terms.xml4993(glossterm)#: ./doc/glossary/glossary-terms.xml4995(primary) #: ./doc/glossary/glossary-terms.xml5014(primary)#: ./doc/glossary/glossary-terms.xml5001(para)#: ./doc/glossary/glossary-terms.xml5007(glossterm)#: ./doc/glossary/glossary-terms.xml5011(secondary) #: ./doc/glossary/glossary-terms.xml5016(secondary)#: ./doc/glossary/glossary-terms.xml5020(para)#: ./doc/glossary/glossary-terms.xml5026(glossterm) #: ./doc/glossary/glossary-terms.xml5028(primary)#: ./doc/glossary/glossary-terms.xml5032(para)#: ./doc/glossary/glossary-terms.xml5038(glossterm) #: ./doc/glossary/glossary-terms.xml5040(primary)#: ./doc/glossary/glossary-terms.xml5044(para)#: ./doc/glossary/glossary-terms.xml5050(glossterm) #: ./doc/glossary/glossary-terms.xml5052(primary)#: ./doc/glossary/glossary-terms.xml5056(para)#: ./doc/glossary/glossary-terms.xml5065(glossterm) #: ./doc/glossary/glossary-terms.xml5067(primary)#: ./doc/glossary/glossary-terms.xml5071(para)#: ./doc/glossary/glossary-terms.xml5077(glossterm) #: ./doc/glossary/glossary-terms.xml5079(primary)#: ./doc/glossary/glossary-terms.xml5083(para)#: ./doc/glossary/glossary-terms.xml5089(glossterm)#: ./doc/glossary/glossary-terms.xml5091(primary)#: ./doc/glossary/glossary-terms.xml5101(glossterm) #: ./doc/glossary/glossary-terms.xml5103(primary)#: ./doc/glossary/glossary-terms.xml5107(para)#: ./doc/glossary/glossary-terms.xml5113(glossterm) #: ./doc/glossary/glossary-terms.xml5115(primary)#: ./doc/glossary/glossary-terms.xml5119(para)#: ./doc/glossary/glossary-terms.xml5127(glossterm)#: ./doc/glossary/glossary-terms.xml5129(primary)#: ./doc/glossary/glossary-terms.xml5133(para)#: ./doc/glossary/glossary-terms.xml5139(glossterm) #: ./doc/glossary/glossary-terms.xml5141(primary)#: ./doc/glossary/glossary-terms.xml5145(para)#: ./doc/glossary/glossary-terms.xml5151(glossterm) #: ./doc/glossary/glossary-terms.xml5153(primary)#: ./doc/glossary/glossary-terms.xml5157(para)#: ./doc/glossary/glossary-terms.xml5163(glossterm) #: ./doc/glossary/glossary-terms.xml5165(primary)#: ./doc/glossary/glossary-terms.xml5169(para)#: ./doc/glossary/glossary-terms.xml5175(glossterm) #: ./doc/glossary/glossary-terms.xml5177(primary)#: ./doc/glossary/glossary-terms.xml5181(para)#: ./doc/glossary/glossary-terms.xml5186(glossterm) #: ./doc/glossary/glossary-terms.xml5188(primary)#: ./doc/glossary/glossary-terms.xml5192(para)#: ./doc/glossary/glossary-terms.xml5198(glossterm) #: ./doc/glossary/glossary-terms.xml5200(primary)#: ./doc/glossary/glossary-terms.xml5204(para)#: ./doc/glossary/glossary-terms.xml5212(glossterm)#: ./doc/glossary/glossary-terms.xml5215(para)#: ./doc/glossary/glossary-terms.xml5221(glossterm) #: ./doc/glossary/glossary-terms.xml5224(primary)#: ./doc/glossary/glossary-terms.xml5228(para)#: ./doc/glossary/glossary-terms.xml5234(glossterm) #: ./doc/glossary/glossary-terms.xml5236(primary)#: ./doc/glossary/glossary-terms.xml5240(para)#: ./doc/glossary/glossary-terms.xml5246(glossterm) #: ./doc/glossary/glossary-terms.xml5248(primary)#: ./doc/glossary/glossary-terms.xml5252(para)#: ./doc/glossary/glossary-terms.xml5258(glossterm) #: ./doc/glossary/glossary-terms.xml5260(primary)#: ./doc/glossary/glossary-terms.xml5264(para)#: ./doc/glossary/glossary-terms.xml5271(glossterm) #: ./doc/glossary/glossary-terms.xml5273(primary)#: ./doc/glossary/glossary-terms.xml5277(para)#: ./doc/glossary/glossary-terms.xml5286(title)#: ./doc/glossary/glossary-terms.xml5289(glossterm) #: ./doc/glossary/glossary-terms.xml5291(primary)#: ./doc/glossary/glossary-terms.xml5295(para)#: ./doc/glossary/glossary-terms.xml5303(glossterm) #: ./doc/glossary/glossary-terms.xml5305(primary)#: ./doc/glossary/glossary-terms.xml5309(para)#: ./doc/glossary/glossary-terms.xml5315(glossterm) #: ./doc/glossary/glossary-terms.xml5317(primary)#: ./doc/glossary/glossary-terms.xml5321(para)#: ./doc/glossary/glossary-terms.xml5328(glossterm) #: ./doc/glossary/glossary-terms.xml5330(primary)#: ./doc/glossary/glossary-terms.xml5334(para)#: ./doc/glossary/glossary-terms.xml5341(glossterm)#: ./doc/glossary/glossary-terms.xml5343(primary) #: ./doc/glossary/glossary-terms.xml5359(primary) #: ./doc/glossary/glossary-terms.xml5373(primary) #: ./doc/glossary/glossary-terms.xml5388(primary) #: ./doc/glossary/glossary-terms.xml5402(primary) #: ./doc/glossary/glossary-terms.xml5416(primary) #: ./doc/glossary/glossary-terms.xml5430(primary) #: ./doc/glossary/glossary-terms.xml5443(primary) #: ./doc/glossary/glossary-terms.xml5457(primary) #: ./doc/glossary/glossary-terms.xml5471(primary) #: ./doc/glossary/glossary-terms.xml5485(primary) #: ./doc/glossary/glossary-terms.xml6322(primary) #: ./doc/glossary/glossary-terms.xml6522(primary) #: ./doc/glossary/glossary-terms.xml8470(primary) #: ./doc/glossary/glossary-terms.xml8618(primary)#: ./doc/glossary/glossary-terms.xml5349(para)#: ./doc/glossary/glossary-terms.xml5357(glossterm) #: ./doc/glossary/glossary-terms.xml5361(secondary)#: ./doc/glossary/glossary-terms.xml5365(para)#: ./doc/glossary/glossary-terms.xml5371(glossterm)#: ./doc/glossary/glossary-terms.xml5375(secondary)#: ./doc/glossary/glossary-terms.xml5379(para)#: ./doc/glossary/glossary-terms.xml5386(glossterm) #: ./doc/glossary/glossary-terms.xml5390(secondary)#: ./doc/glossary/glossary-terms.xml5394(para)#: ./doc/glossary/glossary-terms.xml5400(glossterm)#: ./doc/glossary/glossary-terms.xml5404(secondary)#: ./doc/glossary/glossary-terms.xml5408(para)#: ./doc/glossary/glossary-terms.xml5414(glossterm)#: ./doc/glossary/glossary-terms.xml5418(secondary)#: ./doc/glossary/glossary-terms.xml5422(para)#: ./doc/glossary/glossary-terms.xml5428(glossterm)#: ./doc/glossary/glossary-terms.xml5432(secondary)#: ./doc/glossary/glossary-terms.xml5436(para)#: ./doc/glossary/glossary-terms.xml5441(glossterm)#: ./doc/glossary/glossary-terms.xml5445(secondary)#: ./doc/glossary/glossary-terms.xml5449(para)#: ./doc/glossary/glossary-terms.xml5455(glossterm) #: ./doc/glossary/glossary-terms.xml5459(secondary)#: ./doc/glossary/glossary-terms.xml5463(para)#: ./doc/glossary/glossary-terms.xml5469(glossterm) #: ./doc/glossary/glossary-terms.xml5473(secondary)#: ./doc/glossary/glossary-terms.xml5477(para)#: ./doc/glossary/glossary-terms.xml5483(glossterm)#: ./doc/glossary/glossary-terms.xml5487(secondary)#: ./doc/glossary/glossary-terms.xml5491(para)#: ./doc/glossary/glossary-terms.xml5498(glossterm)#: ./doc/glossary/glossary-terms.xml5501(para)#: ./doc/glossary/glossary-terms.xml5508(glossterm) #: ./doc/glossary/glossary-terms.xml5510(primary) #: ./doc/glossary/glossary-terms.xml5533(secondary)#: ./doc/glossary/glossary-terms.xml5514(para)#: ./doc/glossary/glossary-terms.xml5520(glossterm) #: ./doc/glossary/glossary-terms.xml5531(primary) #: ./doc/glossary/glossary-terms.xml5544(primary) #: ./doc/glossary/glossary-terms.xml5558(primary)#: ./doc/glossary/glossary-terms.xml5523(para)#: ./doc/glossary/glossary-terms.xml5529(glossterm)#: ./doc/glossary/glossary-terms.xml5537(para)#: ./doc/glossary/glossary-terms.xml5542(glossterm) #: ./doc/glossary/glossary-terms.xml5546(secondary)#: ./doc/glossary/glossary-terms.xml5550(para)#: ./doc/glossary/glossary-terms.xml5556(glossterm) #: ./doc/glossary/glossary-terms.xml5560(secondary)#: ./doc/glossary/glossary-terms.xml5564(para)#: ./doc/glossary/glossary-terms.xml5571(glossterm) #: ./doc/glossary/glossary-terms.xml5573(primary)#: ./doc/glossary/glossary-terms.xml5577(para)#: ./doc/glossary/glossary-terms.xml5582(glossterm) #: ./doc/glossary/glossary-terms.xml5584(primary)#: ./doc/glossary/glossary-terms.xml5588(para)#: ./doc/glossary/glossary-terms.xml5594(glossterm)#: ./doc/glossary/glossary-terms.xml5596(primary) #: ./doc/glossary/glossary-terms.xml6426(primary) #: ./doc/glossary/glossary-terms.xml7771(primary) #: ./doc/glossary/glossary-terms.xml7971(primary)#: ./doc/glossary/glossary-terms.xml5602(para)#: ./doc/glossary/glossary-terms.xml5607(glossterm)#: ./doc/glossary/glossary-terms.xml5609(primary) #: ./doc/glossary/glossary-terms.xml5626(primary) #: ./doc/glossary/glossary-terms.xml6148(primary) #: ./doc/glossary/glossary-terms.xml8234(primary)#: ./doc/glossary/glossary-terms.xml5611(secondary) #: ./doc/glossary/glossary-terms.xml5614(primary) #: ./doc/glossary/glossary-terms.xml8214(see)#: ./doc/glossary/glossary-terms.xml5618(para)#: ./doc/glossary/glossary-terms.xml5624(glossterm) #: ./doc/glossary/glossary-terms.xml5631(primary)#: ./doc/glossary/glossary-terms.xml5628(secondary)#: ./doc/glossary/glossary-terms.xml5635(para)#: ./doc/glossary/glossary-terms.xml5641(glossterm) #: ./doc/glossary/glossary-terms.xml5643(primary)#: ./doc/glossary/glossary-terms.xml5649(para)#: ./doc/glossary/glossary-terms.xml5654(glossterm) #: ./doc/glossary/glossary-terms.xml5656(primary)#: ./doc/glossary/glossary-terms.xml5660(para)#: ./doc/glossary/glossary-terms.xml5668(glossterm) #: ./doc/glossary/glossary-terms.xml5678(primary) #: ./doc/glossary/glossary-terms.xml5691(primary)#: ./doc/glossary/glossary-terms.xml5671(para)#: ./doc/glossary/glossary-terms.xml5676(glossterm)#: ./doc/glossary/glossary-terms.xml5684(para)#: ./doc/glossary/glossary-terms.xml5689(glossterm) #: ./doc/glossary/glossary-terms.xml5693(secondary)#: ./doc/glossary/glossary-terms.xml5697(para)#: ./doc/glossary/glossary-terms.xml5707(title)#: ./doc/glossary/glossary-terms.xml5710(glossterm)#: ./doc/glossary/glossary-terms.xml5718(para)#: ./doc/glossary/glossary-terms.xml5724(glossterm)#: ./doc/glossary/glossary-terms.xml5728(secondary)#: ./doc/glossary/glossary-terms.xml5732(para)#: ./doc/glossary/glossary-terms.xml5738(glossterm) #: ./doc/glossary/glossary-terms.xml5742(secondary)#: ./doc/glossary/glossary-terms.xml5746(para)#: ./doc/glossary/glossary-terms.xml5753(glossterm) #: ./doc/glossary/glossary-terms.xml5757(secondary)#: ./doc/glossary/glossary-terms.xml5761(para)#: ./doc/glossary/glossary-terms.xml5766(glossterm) #: ./doc/glossary/glossary-terms.xml5770(secondary)#: ./doc/glossary/glossary-terms.xml5774(para)#: ./doc/glossary/glossary-terms.xml5780(glossterm)#: ./doc/glossary/glossary-terms.xml5784(secondary)#: ./doc/glossary/glossary-terms.xml5788(para)#: ./doc/glossary/glossary-terms.xml5794(glossterm)#: ./doc/glossary/glossary-terms.xml5798(secondary)#: ./doc/glossary/glossary-terms.xml5802(para)#: ./doc/glossary/glossary-terms.xml5808(glossterm) #: ./doc/glossary/glossary-terms.xml5825(primary) #: ./doc/glossary/glossary-terms.xml5838(primary)#: ./doc/glossary/glossary-terms.xml5811(para)#: ./doc/glossary/glossary-terms.xml5818(glossterm) #: ./doc/glossary/glossary-terms.xml5822(secondary) #: ./doc/glossary/glossary-terms.xml5827(secondary)#: ./doc/glossary/glossary-terms.xml5820(primary) #: ./doc/glossary/glossary-terms.xml7915(glossterm) #: ./doc/glossary/glossary-terms.xml7938(primary) #: ./doc/glossary/glossary-terms.xml7952(primary) #: ./doc/glossary/glossary-terms.xml7976(primary)#: ./doc/glossary/glossary-terms.xml5831(para)#: ./doc/glossary/glossary-terms.xml5836(glossterm) #: ./doc/glossary/glossary-terms.xml5840(secondary)#: ./doc/glossary/glossary-terms.xml5844(para)#: ./doc/glossary/glossary-terms.xml5849(glossterm) #: ./doc/glossary/glossary-terms.xml5853(secondary)#: ./doc/glossary/glossary-terms.xml5857(para)#: ./doc/glossary/glossary-terms.xml5863(glossterm) #: ./doc/glossary/glossary-terms.xml5865(primary)#: ./doc/glossary/glossary-terms.xml5869(para)#: ./doc/glossary/glossary-terms.xml5875(glossterm) #: ./doc/glossary/glossary-terms.xml5878(primary)#: ./doc/glossary/glossary-terms.xml5882(para)#: ./doc/glossary/glossary-terms.xml5888(glossterm) #: ./doc/glossary/glossary-terms.xml5890(primary)#: ./doc/glossary/glossary-terms.xml5894(para)#: ./doc/glossary/glossary-terms.xml5899(glossterm) #: ./doc/glossary/glossary-terms.xml5901(primary) #: ./doc/glossary/glossary-terms.xml5933(primary)#: ./doc/glossary/glossary-terms.xml5905(para)#: ./doc/glossary/glossary-terms.xml5917(glossterm) #: ./doc/glossary/glossary-terms.xml5919(primary)#: ./doc/glossary/glossary-terms.xml5923(para)#: ./doc/glossary/glossary-terms.xml5931(glossterm)#: ./doc/glossary/glossary-terms.xml5939(para)#: ./doc/glossary/glossary-terms.xml5944(glossterm) #: ./doc/glossary/glossary-terms.xml5946(primary)#: ./doc/glossary/glossary-terms.xml5950(para)#: ./doc/glossary/glossary-terms.xml5956(glossterm) #: ./doc/glossary/glossary-terms.xml5958(primary) #: ./doc/glossary/glossary-terms.xml5976(primary)#: ./doc/glossary/glossary-terms.xml5964(para)#: ./doc/glossary/glossary-terms.xml5974(glossterm)#: ./doc/glossary/glossary-terms.xml5977(secondary)#: ./doc/glossary/glossary-terms.xml5981(para)#: ./doc/glossary/glossary-terms.xml5995(glossterm) #: ./doc/glossary/glossary-terms.xml5997(primary)#: ./doc/glossary/glossary-terms.xml6006(glossterm) #: ./doc/glossary/glossary-terms.xml6008(primary)#: ./doc/glossary/glossary-terms.xml6012(para)#: ./doc/glossary/glossary-terms.xml6018(glossterm) #: ./doc/glossary/glossary-terms.xml6020(primary)#: ./doc/glossary/glossary-terms.xml6024(para)#: ./doc/glossary/glossary-terms.xml6031(glossterm)#: ./doc/glossary/glossary-terms.xml6033(primary)#: ./doc/glossary/glossary-terms.xml6037(para)#: ./doc/glossary/glossary-terms.xml6046(title)#: ./doc/glossary/glossary-terms.xml6049(glossterm)#: ./doc/glossary/glossary-terms.xml6053(secondary) #: ./doc/glossary/glossary-terms.xml6056(primary)#: ./doc/glossary/glossary-terms.xml6060(para)#: ./doc/glossary/glossary-terms.xml6067(glossterm)#: ./doc/glossary/glossary-terms.xml6069(primary) #: ./doc/glossary/glossary-terms.xml6084(primary) #: ./doc/glossary/glossary-terms.xml6098(primary)#: ./doc/glossary/glossary-terms.xml6075(para)#: ./doc/glossary/glossary-terms.xml6082(glossterm) #: ./doc/glossary/glossary-terms.xml6086(secondary)#: ./doc/glossary/glossary-terms.xml6090(para)#: ./doc/glossary/glossary-terms.xml6096(glossterm)#: ./doc/glossary/glossary-terms.xml6100(secondary)#: ./doc/glossary/glossary-terms.xml6104(para)#: ./doc/glossary/glossary-terms.xml6110(glossterm) #: ./doc/glossary/glossary-terms.xml6112(primary)#: ./doc/glossary/glossary-terms.xml6116(para)#: ./doc/glossary/glossary-terms.xml6122(glossterm) #: ./doc/glossary/glossary-terms.xml6124(primary)#: ./doc/glossary/glossary-terms.xml6128(para)#: ./doc/glossary/glossary-terms.xml6134(glossterm) #: ./doc/glossary/glossary-terms.xml6136(primary)#: ./doc/glossary/glossary-terms.xml6140(para)#: ./doc/glossary/glossary-terms.xml6146(glossterm)#: ./doc/glossary/glossary-terms.xml6150(secondary) #: ./doc/glossary/glossary-terms.xml6153(primary)#: ./doc/glossary/glossary-terms.xml6157(para)#: ./doc/glossary/glossary-terms.xml6163(glossterm) #: ./doc/glossary/glossary-terms.xml6165(primary)#: ./doc/glossary/glossary-terms.xml6169(para)#: ./doc/glossary/glossary-terms.xml6174(glossterm) #: ./doc/glossary/glossary-terms.xml6176(primary)#: ./doc/glossary/glossary-terms.xml6180(para)#: ./doc/glossary/glossary-terms.xml6186(glossterm) #: ./doc/glossary/glossary-terms.xml6188(primary)#: ./doc/glossary/glossary-terms.xml6192(para)#: ./doc/glossary/glossary-terms.xml6201(glossterm)#: ./doc/glossary/glossary-terms.xml6203(primary)#: ./doc/glossary/glossary-terms.xml6207(para)#: ./doc/glossary/glossary-terms.xml6213(glossterm) #: ./doc/glossary/glossary-terms.xml6215(primary)#: ./doc/glossary/glossary-terms.xml6219(para)#: ./doc/glossary/glossary-terms.xml6225(glossterm) #: ./doc/glossary/glossary-terms.xml6227(primary)#: ./doc/glossary/glossary-terms.xml6231(para)#: ./doc/glossary/glossary-terms.xml6240(glossterm) #: ./doc/glossary/glossary-terms.xml6242(primary)#: ./doc/glossary/glossary-terms.xml6246(para)#: ./doc/glossary/glossary-terms.xml6252(glossterm)#: ./doc/glossary/glossary-terms.xml6254(primary) #: ./doc/glossary/glossary-terms.xml6268(primary) #: ./doc/glossary/glossary-terms.xml8526(primary)#: ./doc/glossary/glossary-terms.xml6260(para)#: ./doc/glossary/glossary-terms.xml6266(glossterm) #: ./doc/glossary/glossary-terms.xml6270(secondary)#: ./doc/glossary/glossary-terms.xml6274(para)#: ./doc/glossary/glossary-terms.xml6279(glossterm)#: ./doc/glossary/glossary-terms.xml6281(primary)#: ./doc/glossary/glossary-terms.xml6285(para)#: ./doc/glossary/glossary-terms.xml6291(glossterm) #: ./doc/glossary/glossary-terms.xml6293(primary)#: ./doc/glossary/glossary-terms.xml6297(para)#: ./doc/glossary/glossary-terms.xml6303(glossterm) #: ./doc/glossary/glossary-terms.xml6310(primary)#: ./doc/glossary/glossary-terms.xml6307(secondary)#: ./doc/glossary/glossary-terms.xml6314(para)#: ./doc/glossary/glossary-terms.xml6320(glossterm)#: ./doc/glossary/glossary-terms.xml6324(secondary) #: ./doc/glossary/glossary-terms.xml6327(primary)#: ./doc/glossary/glossary-terms.xml6331(para)#: ./doc/glossary/glossary-terms.xml6343(glossterm)#: ./doc/glossary/glossary-terms.xml6345(primary) #: ./doc/glossary/glossary-terms.xml6359(primary) #: ./doc/glossary/glossary-terms.xml6373(primary)#: ./doc/glossary/glossary-terms.xml6351(para)#: ./doc/glossary/glossary-terms.xml6357(glossterm) #: ./doc/glossary/glossary-terms.xml6361(secondary)#: ./doc/glossary/glossary-terms.xml6365(para)#: ./doc/glossary/glossary-terms.xml6371(glossterm) #: ./doc/glossary/glossary-terms.xml6375(secondary)#: ./doc/glossary/glossary-terms.xml6379(para)#: ./doc/glossary/glossary-terms.xml6384(glossterm) #: ./doc/glossary/glossary-terms.xml6386(primary)#: ./doc/glossary/glossary-terms.xml6390(para)#: ./doc/glossary/glossary-terms.xml6397(glossterm) #: ./doc/glossary/glossary-terms.xml6399(primary)#: ./doc/glossary/glossary-terms.xml6403(para)#: ./doc/glossary/glossary-terms.xml6412(glossterm) #: ./doc/glossary/glossary-terms.xml6414(primary)#: ./doc/glossary/glossary-terms.xml6418(para)#: ./doc/glossary/glossary-terms.xml6424(glossterm)#: ./doc/glossary/glossary-terms.xml6428(secondary) #: ./doc/glossary/glossary-terms.xml6431(primary)#: ./doc/glossary/glossary-terms.xml6435(para)#: ./doc/glossary/glossary-terms.xml6440(glossterm)#: ./doc/glossary/glossary-terms.xml6444(secondary) #: ./doc/glossary/glossary-terms.xml6447(primary)#: ./doc/glossary/glossary-terms.xml6451(para)#: ./doc/glossary/glossary-terms.xml6458(glossterm) #: ./doc/glossary/glossary-terms.xml6465(primary)#: ./doc/glossary/glossary-terms.xml6462(secondary)#: ./doc/glossary/glossary-terms.xml6469(para)#: ./doc/glossary/glossary-terms.xml6475(glossterm) #: ./doc/glossary/glossary-terms.xml6482(primary)#: ./doc/glossary/glossary-terms.xml6479(secondary)#: ./doc/glossary/glossary-terms.xml6486(para)#: ./doc/glossary/glossary-terms.xml6492(glossterm) #: ./doc/glossary/glossary-terms.xml6499(primary)#: ./doc/glossary/glossary-terms.xml6496(secondary) #: ./doc/glossary/glossary-terms.xml6524(secondary)#: ./doc/glossary/glossary-terms.xml6503(para)#: ./doc/glossary/glossary-terms.xml6508(glossterm) #: ./doc/glossary/glossary-terms.xml6510(primary)#: ./doc/glossary/glossary-terms.xml6514(para)#: ./doc/glossary/glossary-terms.xml6520(glossterm) #: ./doc/glossary/glossary-terms.xml6527(primary)#: ./doc/glossary/glossary-terms.xml6531(para)#: ./doc/glossary/glossary-terms.xml6540(glossterm) #: ./doc/glossary/glossary-terms.xml6542(primary)#: ./doc/glossary/glossary-terms.xml6546(para)#: ./doc/glossary/glossary-terms.xml6552(glossterm) #: ./doc/glossary/glossary-terms.xml6554(primary)#: ./doc/glossary/glossary-terms.xml6558(para)#: ./doc/glossary/glossary-terms.xml6566(title)#: ./doc/glossary/glossary-terms.xml6569(glossterm) #: ./doc/glossary/glossary-terms.xml6571(primary)#: ./doc/glossary/glossary-terms.xml6581(glossterm) #: ./doc/glossary/glossary-terms.xml6583(primary)#: ./doc/glossary/glossary-terms.xml6587(para)#: ./doc/glossary/glossary-terms.xml6593(glossterm) #: ./doc/glossary/glossary-terms.xml6595(primary)#: ./doc/glossary/glossary-terms.xml6599(para)#: ./doc/glossary/glossary-terms.xml6606(glossterm) #: ./doc/glossary/glossary-terms.xml6608(primary)#: ./doc/glossary/glossary-terms.xml6612(para)#: ./doc/glossary/glossary-terms.xml6615(para)#: ./doc/glossary/glossary-terms.xml6621(glossterm)#: ./doc/glossary/glossary-terms.xml6623(primary)#: ./doc/glossary/glossary-terms.xml6627(para)#: ./doc/glossary/glossary-terms.xml6636(title)#: ./doc/glossary/glossary-terms.xml6639(glossterm) #: ./doc/glossary/glossary-terms.xml6641(primary)#: ./doc/glossary/glossary-terms.xml6645(para)#: ./doc/glossary/glossary-terms.xml6650(glossterm) #: ./doc/glossary/glossary-terms.xml6652(primary)#: ./doc/glossary/glossary-terms.xml6656(para)#: ./doc/glossary/glossary-terms.xml6662(glossterm) #: ./doc/glossary/glossary-terms.xml6664(primary)#: ./doc/glossary/glossary-terms.xml6668(para)#: ./doc/glossary/glossary-terms.xml6674(glossterm) #: ./doc/glossary/glossary-terms.xml6676(primary)#: ./doc/glossary/glossary-terms.xml6680(para)#: ./doc/glossary/glossary-terms.xml6687(glossterm) #: ./doc/glossary/glossary-terms.xml6689(primary)#: ./doc/glossary/glossary-terms.xml6693(para)#: ./doc/glossary/glossary-terms.xml6699(glossterm) #: ./doc/glossary/glossary-terms.xml6701(primary)#: ./doc/glossary/glossary-terms.xml6705(para)#: ./doc/glossary/glossary-terms.xml6713(glossterm)#: ./doc/glossary/glossary-terms.xml6715(primary)#: ./doc/glossary/glossary-terms.xml6719(para)#: ./doc/glossary/glossary-terms.xml6725(glossterm)#: ./doc/glossary/glossary-terms.xml6727(primary)#: ./doc/glossary/glossary-terms.xml6731(para)#: ./doc/glossary/glossary-terms.xml6737(glossterm)#: ./doc/glossary/glossary-terms.xml6739(primary)#: ./doc/glossary/glossary-terms.xml6743(para)#: ./doc/glossary/glossary-terms.xml6750(glossterm) #: ./doc/glossary/glossary-terms.xml6752(primary) #: ./doc/glossary/glossary-terms.xml7621(primary)#: ./doc/glossary/glossary-terms.xml6754(secondary) #: ./doc/glossary/glossary-terms.xml7623(secondary)#: ./doc/glossary/glossary-terms.xml6758(para)#: ./doc/glossary/glossary-terms.xml6768(glossterm)#: ./doc/glossary/glossary-terms.xml6770(primary)#: ./doc/glossary/glossary-terms.xml6774(para)#: ./doc/glossary/glossary-terms.xml6780(glossterm) #: ./doc/glossary/glossary-terms.xml6782(primary)#: ./doc/glossary/glossary-terms.xml6786(para)#: ./doc/glossary/glossary-terms.xml6791(glossterm)#: ./doc/glossary/glossary-terms.xml6793(primary) #: ./doc/glossary/glossary-terms.xml6812(primary)#: ./doc/glossary/glossary-terms.xml6799(para)#: ./doc/glossary/glossary-terms.xml6810(glossterm)#: ./doc/glossary/glossary-terms.xml6814(secondary)#: ./doc/glossary/glossary-terms.xml6818(para)#: ./doc/glossary/glossary-terms.xml6824(glossterm) #: ./doc/glossary/glossary-terms.xml6826(primary)#: ./doc/glossary/glossary-terms.xml6835(glossterm) #: ./doc/glossary/glossary-terms.xml6837(primary)#: ./doc/glossary/glossary-terms.xml6841(para)#: ./doc/glossary/glossary-terms.xml6846(glossterm) #: ./doc/glossary/glossary-terms.xml6848(primary)#: ./doc/glossary/glossary-terms.xml6852(para)#: ./doc/glossary/glossary-terms.xml6859(glossterm) #: ./doc/glossary/glossary-terms.xml6861(primary)#: ./doc/glossary/glossary-terms.xml6863(see)#: ./doc/glossary/glossary-terms.xml6867(para)#: ./doc/glossary/glossary-terms.xml6872(glossterm)#: ./doc/glossary/glossary-terms.xml6876(secondary) #: ./doc/glossary/glossary-terms.xml6879(primary)#: ./doc/glossary/glossary-terms.xml6883(para)#: ./doc/glossary/glossary-terms.xml6889(glossterm) #: ./doc/glossary/glossary-terms.xml6892(primary)#: ./doc/glossary/glossary-terms.xml6897(para)#: ./doc/glossary/glossary-terms.xml6903(glossterm) #: ./doc/glossary/glossary-terms.xml6905(primary)#: ./doc/glossary/glossary-terms.xml6909(para)#: ./doc/glossary/glossary-terms.xml6915(glossterm)#: ./doc/glossary/glossary-terms.xml6917(primary) #: ./doc/glossary/glossary-terms.xml6932(primary) #: ./doc/glossary/glossary-terms.xml6944(glossterm) #: ./doc/glossary/glossary-terms.xml6955(primary)#: ./doc/glossary/glossary-terms.xml6923(para)#: ./doc/glossary/glossary-terms.xml6930(glossterm) #: ./doc/glossary/glossary-terms.xml6934(secondary)#: ./doc/glossary/glossary-terms.xml6938(para)#: ./doc/glossary/glossary-terms.xml6947(para)#: ./doc/glossary/glossary-terms.xml6953(glossterm)#: ./doc/glossary/glossary-terms.xml6957(secondary)#: ./doc/glossary/glossary-terms.xml6961(para)#: ./doc/glossary/glossary-terms.xml6967(glossterm)#: ./doc/glossary/glossary-terms.xml6969(primary)#: ./doc/glossary/glossary-terms.xml6973(para)#: ./doc/glossary/glossary-terms.xml6978(glossterm)#: ./doc/glossary/glossary-terms.xml6980(primary)#: ./doc/glossary/glossary-terms.xml6984(para)#: ./doc/glossary/glossary-terms.xml6991(glossterm)#: ./doc/glossary/glossary-terms.xml6993(primary)#: ./doc/glossary/glossary-terms.xml6997(para)#: ./doc/glossary/glossary-terms.xml7005(glossterm)#: ./doc/glossary/glossary-terms.xml7007(primary)#: ./doc/glossary/glossary-terms.xml7011(para)#: ./doc/glossary/glossary-terms.xml7018(glossterm)#: ./doc/glossary/glossary-terms.xml7020(primary) #: ./doc/glossary/glossary-terms.xml7035(primary)#: ./doc/glossary/glossary-terms.xml7026(para)#: ./doc/glossary/glossary-terms.xml7033(glossterm)#: ./doc/glossary/glossary-terms.xml7037(secondary)#: ./doc/glossary/glossary-terms.xml7041(para)#: ./doc/glossary/glossary-terms.xml7048(glossterm) #: ./doc/glossary/glossary-terms.xml7050(primary)#: ./doc/glossary/glossary-terms.xml7054(para)#: ./doc/glossary/glossary-terms.xml7062(glossterm)#: ./doc/glossary/glossary-terms.xml7064(primary) #: ./doc/glossary/glossary-terms.xml7079(primary)#: ./doc/glossary/glossary-terms.xml7070(para)#: ./doc/glossary/glossary-terms.xml7077(glossterm) #: ./doc/glossary/glossary-terms.xml7081(secondary)#: ./doc/glossary/glossary-terms.xml7085(para)#: ./doc/glossary/glossary-terms.xml7090(glossterm) #: ./doc/glossary/glossary-terms.xml7092(primary)#: ./doc/glossary/glossary-terms.xml7096(para)#: ./doc/glossary/glossary-terms.xml7102(glossterm) #: ./doc/glossary/glossary-terms.xml7109(primary)#: ./doc/glossary/glossary-terms.xml7104(primary) #: ./doc/glossary/glossary-terms.xml7664(primary)#: ./doc/glossary/glossary-terms.xml7106(secondary)#: ./doc/glossary/glossary-terms.xml7113(para)#: ./doc/glossary/glossary-terms.xml7119(glossterm) #: ./doc/glossary/glossary-terms.xml7121(primary)#: ./doc/glossary/glossary-terms.xml7125(para)#: ./doc/glossary/glossary-terms.xml7131(glossterm)#: ./doc/glossary/glossary-terms.xml7133(primary)#: ./doc/glossary/glossary-terms.xml7137(para)#: ./doc/glossary/glossary-terms.xml7144(glossterm)#: ./doc/glossary/glossary-terms.xml7146(primary)#: ./doc/glossary/glossary-terms.xml7148(secondary) #: ./doc/glossary/glossary-terms.xml7151(primary)#: ./doc/glossary/glossary-terms.xml7155(para)#: ./doc/glossary/glossary-terms.xml7162(glossterm) #: ./doc/glossary/glossary-terms.xml7164(primary)#: ./doc/glossary/glossary-terms.xml7168(para)#: ./doc/glossary/glossary-terms.xml7173(glossterm)#: ./doc/glossary/glossary-terms.xml7175(primary)#: ./doc/glossary/glossary-terms.xml7179(para)#: ./doc/glossary/glossary-terms.xml7185(glossterm)#: ./doc/glossary/glossary-terms.xml7188(para)#: ./doc/glossary/glossary-terms.xml7194(glossterm) #: ./doc/glossary/glossary-terms.xml7196(primary)#: ./doc/glossary/glossary-terms.xml7200(para)#: ./doc/glossary/glossary-terms.xml7209(title)#: ./doc/glossary/glossary-terms.xml7212(glossterm)#: ./doc/glossary/glossary-terms.xml7214(primary)#: ./doc/glossary/glossary-terms.xml7218(para)#: ./doc/glossary/glossary-terms.xml7225(glossterm) #: ./doc/glossary/glossary-terms.xml7227(primary)#: ./doc/glossary/glossary-terms.xml7231(para)#: ./doc/glossary/glossary-terms.xml7237(glossterm) #: ./doc/glossary/glossary-terms.xml7239(primary)#: ./doc/glossary/glossary-terms.xml7243(para)#: ./doc/glossary/glossary-terms.xml7250(glossterm)#: ./doc/glossary/glossary-terms.xml7252(primary)#: ./doc/glossary/glossary-terms.xml7256(para)#: ./doc/glossary/glossary-terms.xml7262(glossterm)#: ./doc/glossary/glossary-terms.xml7264(primary)#: ./doc/glossary/glossary-terms.xml7268(para)#: ./doc/glossary/glossary-terms.xml7274(glossterm)#: ./doc/glossary/glossary-terms.xml7276(primary)#: ./doc/glossary/glossary-terms.xml7280(para)#: ./doc/glossary/glossary-terms.xml7286(glossterm) #: ./doc/glossary/glossary-terms.xml7288(primary)#: ./doc/glossary/glossary-terms.xml7292(para)#: ./doc/glossary/glossary-terms.xml7299(glossterm)#: ./doc/glossary/glossary-terms.xml7301(primary)#: ./doc/glossary/glossary-terms.xml7305(para)#: ./doc/glossary/glossary-terms.xml7311(glossterm)#: ./doc/glossary/glossary-terms.xml7315(secondary) #: ./doc/glossary/glossary-terms.xml7318(primary)#: ./doc/glossary/glossary-terms.xml7322(para)#: ./doc/glossary/glossary-terms.xml7329(glossterm) #: ./doc/glossary/glossary-terms.xml7331(primary)#: ./doc/glossary/glossary-terms.xml7335(para)#: ./doc/glossary/glossary-terms.xml7341(glossterm)#: ./doc/glossary/glossary-terms.xml7349(para)#: ./doc/glossary/glossary-terms.xml7353(para)#: ./doc/glossary/glossary-terms.xml7359(glossterm) #: ./doc/glossary/glossary-terms.xml7361(primary)#: ./doc/glossary/glossary-terms.xml7365(para)#: ./doc/glossary/glossary-terms.xml7370(glossterm) #: ./doc/glossary/glossary-terms.xml7374(secondary)#: ./doc/glossary/glossary-terms.xml7384(glossterm)#: ./doc/glossary/glossary-terms.xml7386(primary)#: ./doc/glossary/glossary-terms.xml7392(para)#: ./doc/glossary/glossary-terms.xml7399(glossterm) #: ./doc/glossary/glossary-terms.xml7401(primary)#: ./doc/glossary/glossary-terms.xml7405(para)#: ./doc/glossary/glossary-terms.xml7410(glossterm) #: ./doc/glossary/glossary-terms.xml7412(primary)#: ./doc/glossary/glossary-terms.xml7416(para)#: ./doc/glossary/glossary-terms.xml7422(glossterm) #: ./doc/glossary/glossary-terms.xml7424(primary)#: ./doc/glossary/glossary-terms.xml7428(para)#: ./doc/glossary/glossary-terms.xml7434(glossterm) #: ./doc/glossary/glossary-terms.xml7436(primary)#: ./doc/glossary/glossary-terms.xml7440(para)#: ./doc/glossary/glossary-terms.xml7446(glossterm) #: ./doc/glossary/glossary-terms.xml7448(primary)#: ./doc/glossary/glossary-terms.xml7452(para)#: ./doc/glossary/glossary-terms.xml7458(glossterm) #: ./doc/glossary/glossary-terms.xml7462(secondary)#: ./doc/glossary/glossary-terms.xml7460(primary) #: ./doc/glossary/glossary-terms.xml7474(primary) #: ./doc/glossary/glossary-terms.xml7489(primary)#: ./doc/glossary/glossary-terms.xml7466(para)#: ./doc/glossary/glossary-terms.xml7472(glossterm) #: ./doc/glossary/glossary-terms.xml7476(secondary)#: ./doc/glossary/glossary-terms.xml7480(para)#: ./doc/glossary/glossary-terms.xml7487(glossterm) #: ./doc/glossary/glossary-terms.xml7491(secondary)#: ./doc/glossary/glossary-terms.xml7495(para)#: ./doc/glossary/glossary-terms.xml7501(glossterm) #: ./doc/glossary/glossary-terms.xml7508(primary)#: ./doc/glossary/glossary-terms.xml7505(secondary)#: ./doc/glossary/glossary-terms.xml7512(para)#: ./doc/glossary/glossary-terms.xml7525(glossterm)#: ./doc/glossary/glossary-terms.xml7527(primary)#: ./doc/glossary/glossary-terms.xml7531(para)#: ./doc/glossary/glossary-terms.xml7540(glossterm) #: ./doc/glossary/glossary-terms.xml7542(primary)#: ./doc/glossary/glossary-terms.xml7546(para)#: ./doc/glossary/glossary-terms.xml7552(glossterm) #: ./doc/glossary/glossary-terms.xml7554(primary)#: ./doc/glossary/glossary-terms.xml7558(para)#: ./doc/glossary/glossary-terms.xml7564(glossterm) #: ./doc/glossary/glossary-terms.xml7567(primary)#: ./doc/glossary/glossary-terms.xml7571(para)#: ./doc/glossary/glossary-terms.xml7577(glossterm) #: ./doc/glossary/glossary-terms.xml7580(primary)#: ./doc/glossary/glossary-terms.xml7584(para)#: ./doc/glossary/glossary-terms.xml7594(glossterm) #: ./doc/glossary/glossary-terms.xml7596(primary)#: ./doc/glossary/glossary-terms.xml7600(para)#: ./doc/glossary/glossary-terms.xml7606(glossterm) #: ./doc/glossary/glossary-terms.xml7608(primary)#: ./doc/glossary/glossary-terms.xml7612(para)#: ./doc/glossary/glossary-terms.xml7619(glossterm) #: ./doc/glossary/glossary-terms.xml7626(primary)#: ./doc/glossary/glossary-terms.xml7630(para)#: ./doc/glossary/glossary-terms.xml7636(glossterm) #: ./doc/glossary/glossary-terms.xml7638(primary)#: ./doc/glossary/glossary-terms.xml7642(para)#: ./doc/glossary/glossary-terms.xml7648(glossterm)#: ./doc/glossary/glossary-terms.xml7650(primary)#: ./doc/glossary/glossary-terms.xml7655(para)#: ./doc/glossary/glossary-terms.xml7662(glossterm) #: ./doc/glossary/glossary-terms.xml7669(primary)#: ./doc/glossary/glossary-terms.xml7666(secondary)#: ./doc/glossary/glossary-terms.xml7673(para)#: ./doc/glossary/glossary-terms.xml7679(glossterm) #: ./doc/glossary/glossary-terms.xml7681(primary)#: ./doc/glossary/glossary-terms.xml7685(para)#: ./doc/glossary/glossary-terms.xml7690(glossterm) #: ./doc/glossary/glossary-terms.xml7692(primary)#: ./doc/glossary/glossary-terms.xml7696(para)#: ./doc/glossary/glossary-terms.xml7702(glossterm) #: ./doc/glossary/glossary-terms.xml7704(primary)#: ./doc/glossary/glossary-terms.xml7709(para)#: ./doc/glossary/glossary-terms.xml7717(glossterm) #: ./doc/glossary/glossary-terms.xml7719(primary)#: ./doc/glossary/glossary-terms.xml7723(para)#: ./doc/glossary/glossary-terms.xml7729(glossterm)#: ./doc/glossary/glossary-terms.xml7733(secondary)#: ./doc/glossary/glossary-terms.xml7736(primary)#: ./doc/glossary/glossary-terms.xml7740(para)#: ./doc/glossary/glossary-terms.xml7745(glossterm) #: ./doc/glossary/glossary-terms.xml7747(primary)#: ./doc/glossary/glossary-terms.xml7751(para)#: ./doc/glossary/glossary-terms.xml7757(glossterm) #: ./doc/glossary/glossary-terms.xml7759(primary)#: ./doc/glossary/glossary-terms.xml7763(para)#: ./doc/glossary/glossary-terms.xml7769(glossterm) #: ./doc/glossary/glossary-terms.xml7776(primary)#: ./doc/glossary/glossary-terms.xml7773(secondary)#: ./doc/glossary/glossary-terms.xml7780(para)#: ./doc/glossary/glossary-terms.xml7787(glossterm) #: ./doc/glossary/glossary-terms.xml7791(secondary)#: ./doc/glossary/glossary-terms.xml7789(primary) #: ./doc/glossary/glossary-terms.xml7803(primary) #: ./doc/glossary/glossary-terms.xml7817(primary) #: ./doc/glossary/glossary-terms.xml7966(primary)#: ./doc/glossary/glossary-terms.xml7795(para)#: ./doc/glossary/glossary-terms.xml7801(glossterm) #: ./doc/glossary/glossary-terms.xml7805(secondary)#: ./doc/glossary/glossary-terms.xml7809(para)#: ./doc/glossary/glossary-terms.xml7815(glossterm) #: ./doc/glossary/glossary-terms.xml7819(secondary)#: ./doc/glossary/glossary-terms.xml7823(para)#: ./doc/glossary/glossary-terms.xml7829(glossterm) #: ./doc/glossary/glossary-terms.xml7831(primary)#: ./doc/glossary/glossary-terms.xml7835(para)#: ./doc/glossary/glossary-terms.xml7841(glossterm)#: ./doc/glossary/glossary-terms.xml7843(primary)#: ./doc/glossary/glossary-terms.xml7847(para)#: ./doc/glossary/glossary-terms.xml7855(glossterm) #: ./doc/glossary/glossary-terms.xml7857(primary)#: ./doc/glossary/glossary-terms.xml7861(para)#: ./doc/glossary/glossary-terms.xml7866(glossterm) #: ./doc/glossary/glossary-terms.xml7869(primary)#: ./doc/glossary/glossary-terms.xml7878(glossterm)#: ./doc/glossary/glossary-terms.xml7880(primary)#: ./doc/glossary/glossary-terms.xml7884(para)#: ./doc/glossary/glossary-terms.xml7890(glossterm)#: ./doc/glossary/glossary-terms.xml7892(primary)#: ./doc/glossary/glossary-terms.xml7896(para)#: ./doc/glossary/glossary-terms.xml7902(glossterm) #: ./doc/glossary/glossary-terms.xml7904(primary)#: ./doc/glossary/glossary-terms.xml7908(para)#: ./doc/glossary/glossary-terms.xml7918(para)#: ./doc/glossary/glossary-terms.xml7924(glossterm) #: ./doc/glossary/glossary-terms.xml7926(primary)#: ./doc/glossary/glossary-terms.xml7930(para)#: ./doc/glossary/glossary-terms.xml7936(glossterm) #: ./doc/glossary/glossary-terms.xml7940(secondary)#: ./doc/glossary/glossary-terms.xml7944(para)#: ./doc/glossary/glossary-terms.xml7950(glossterm) #: ./doc/glossary/glossary-terms.xml7954(secondary)#: ./doc/glossary/glossary-terms.xml7958(para)#: ./doc/glossary/glossary-terms.xml7964(glossterm)#: ./doc/glossary/glossary-terms.xml7968(secondary) #: ./doc/glossary/glossary-terms.xml7973(secondary) #: ./doc/glossary/glossary-terms.xml7978(secondary)#: ./doc/glossary/glossary-terms.xml7982(para)#: ./doc/glossary/glossary-terms.xml7988(glossterm) #: ./doc/glossary/glossary-terms.xml7990(primary)#: ./doc/glossary/glossary-terms.xml7994(para)#: ./doc/glossary/glossary-terms.xml8000(glossterm) #: ./doc/glossary/glossary-terms.xml8002(primary)#: ./doc/glossary/glossary-terms.xml8006(para)#: ./doc/glossary/glossary-terms.xml8013(glossterm) #: ./doc/glossary/glossary-terms.xml8015(primary)#: ./doc/glossary/glossary-terms.xml8019(para)#: ./doc/glossary/glossary-terms.xml8029(title)#: ./doc/glossary/glossary-terms.xml8032(glossterm) #: ./doc/glossary/glossary-terms.xml8034(primary)#: ./doc/glossary/glossary-terms.xml8038(para)#: ./doc/glossary/glossary-terms.xml8045(glossterm) #: ./doc/glossary/glossary-terms.xml8047(primary)#: ./doc/glossary/glossary-terms.xml8051(para)#: ./doc/glossary/glossary-terms.xml8058(glossterm) #: ./doc/glossary/glossary-terms.xml8060(primary)#: ./doc/glossary/glossary-terms.xml8064(para)#: ./doc/glossary/glossary-terms.xml8070(glossterm) #: ./doc/glossary/glossary-terms.xml8072(primary)#: ./doc/glossary/glossary-terms.xml8076(para)#: ./doc/glossary/glossary-terms.xml8082(glossterm) #: ./doc/glossary/glossary-terms.xml8093(primary) #: ./doc/glossary/glossary-terms.xml8111(primary) #: ./doc/glossary/glossary-terms.xml8125(primary)#: ./doc/glossary/glossary-terms.xml8085(para)#: ./doc/glossary/glossary-terms.xml8091(glossterm) #: ./doc/glossary/glossary-terms.xml8095(secondary)#: ./doc/glossary/glossary-terms.xml8099(para)#: ./doc/glossary/glossary-terms.xml8104(glossterm) #: ./doc/glossary/glossary-terms.xml8108(secondary) #: ./doc/glossary/glossary-terms.xml8113(secondary)#: ./doc/glossary/glossary-terms.xml8117(para)#: ./doc/glossary/glossary-terms.xml8123(glossterm) #: ./doc/glossary/glossary-terms.xml8127(secondary)#: ./doc/glossary/glossary-terms.xml8131(para)#: ./doc/glossary/glossary-terms.xml8137(glossterm)#: ./doc/glossary/glossary-terms.xml8139(primary)#: ./doc/glossary/glossary-terms.xml8143(para)#: ./doc/glossary/glossary-terms.xml8149(glossterm) #: ./doc/glossary/glossary-terms.xml8151(primary)#: ./doc/glossary/glossary-terms.xml8155(para)#: ./doc/glossary/glossary-terms.xml8161(glossterm) #: ./doc/glossary/glossary-terms.xml8163(primary)#: ./doc/glossary/glossary-terms.xml8166(para)#: ./doc/glossary/glossary-terms.xml8174(glossterm) #: ./doc/glossary/glossary-terms.xml8176(primary)#: ./doc/glossary/glossary-terms.xml8180(para)#: ./doc/glossary/glossary-terms.xml8186(glossterm) #: ./doc/glossary/glossary-terms.xml8188(primary)#: ./doc/glossary/glossary-terms.xml8192(para)#: ./doc/glossary/glossary-terms.xml8198(glossterm)#: ./doc/glossary/glossary-terms.xml8200(primary)#: ./doc/glossary/glossary-terms.xml8204(para)#: ./doc/glossary/glossary-terms.xml8210(glossterm)#: ./doc/glossary/glossary-terms.xml8212(primary)#: ./doc/glossary/glossary-terms.xml8218(para)#: ./doc/glossary/glossary-terms.xml8223(glossterm)#: ./doc/glossary/glossary-terms.xml8226(para)#: ./doc/glossary/glossary-terms.xml8232(glossterm)#: ./doc/glossary/glossary-terms.xml8236(secondary) #: ./doc/glossary/glossary-terms.xml8239(primary)#: ./doc/glossary/glossary-terms.xml8243(para)#: ./doc/glossary/glossary-terms.xml8249(glossterm)#: ./doc/glossary/glossary-terms.xml8253(secondary) #: ./doc/glossary/glossary-terms.xml8256(primary)#: ./doc/glossary/glossary-terms.xml8260(para)#: ./doc/glossary/glossary-terms.xml8265(glossterm) #: ./doc/glossary/glossary-terms.xml8267(primary)#: ./doc/glossary/glossary-terms.xml8271(para)#: ./doc/glossary/glossary-terms.xml8279(glossterm) #: ./doc/glossary/glossary-terms.xml8281(primary)#: ./doc/glossary/glossary-terms.xml8285(para)#: ./doc/glossary/glossary-terms.xml8294(title)#: ./doc/glossary/glossary-terms.xml8297(glossterm) #: ./doc/glossary/glossary-terms.xml8299(primary)#: ./doc/glossary/glossary-terms.xml8303(para)#: ./doc/glossary/glossary-terms.xml8308(glossterm) #: ./doc/glossary/glossary-terms.xml8310(primary)#: ./doc/glossary/glossary-terms.xml8314(para)#: ./doc/glossary/glossary-terms.xml8319(glossterm)#: ./doc/glossary/glossary-terms.xml8321(primary)#: ./doc/glossary/glossary-terms.xml8325(para)#: ./doc/glossary/glossary-terms.xml8331(glossterm)#: ./doc/glossary/glossary-terms.xml8333(primary)#: ./doc/glossary/glossary-terms.xml8337(para)#: ./doc/glossary/glossary-terms.xml8344(glossterm) #: ./doc/glossary/glossary-terms.xml8346(primary)#: ./doc/glossary/glossary-terms.xml8350(para)#: ./doc/glossary/glossary-terms.xml8360(glossterm) #: ./doc/glossary/glossary-terms.xml8362(primary)#: ./doc/glossary/glossary-terms.xml8374(title)#: ./doc/glossary/glossary-terms.xml8377(glossterm) #: ./doc/glossary/glossary-terms.xml8379(primary)#: ./doc/glossary/glossary-terms.xml8383(para)#: ./doc/glossary/glossary-terms.xml8388(glossterm) #: ./doc/glossary/glossary-terms.xml8390(primary)#: ./doc/glossary/glossary-terms.xml8394(para)#: ./doc/glossary/glossary-terms.xml8404(glossterm) #: ./doc/glossary/glossary-terms.xml8407(primary)#: ./doc/glossary/glossary-terms.xml8411(para)#: ./doc/glossary/glossary-terms.xml8417(glossterm) #: ./doc/glossary/glossary-terms.xml8419(primary)#: ./doc/glossary/glossary-terms.xml8429(glossterm) #: ./doc/glossary/glossary-terms.xml8431(primary)#: ./doc/glossary/glossary-terms.xml8441(glossterm) #: ./doc/glossary/glossary-terms.xml8443(primary)#: ./doc/glossary/glossary-terms.xml8447(para)#: ./doc/glossary/glossary-terms.xml8455(glossterm) #: ./doc/glossary/glossary-terms.xml8457(primary)#: ./doc/glossary/glossary-terms.xml8461(para)#: ./doc/glossary/glossary-terms.xml8468(glossterm) #: ./doc/glossary/glossary-terms.xml8475(primary)#: ./doc/glossary/glossary-terms.xml8472(secondary) #: ./doc/glossary/glossary-terms.xml8528(secondary) #: ./doc/glossary/glossary-terms.xml8558(secondary)#: ./doc/glossary/glossary-terms.xml8479(para)#: ./doc/glossary/glossary-terms.xml8484(glossterm) #: ./doc/glossary/glossary-terms.xml8486(primary)#: ./doc/glossary/glossary-terms.xml8490(para)#: ./doc/glossary/glossary-terms.xml8499(glossterm) #: ./doc/glossary/glossary-terms.xml8501(primary)#: ./doc/glossary/glossary-terms.xml8505(para)#: ./doc/glossary/glossary-terms.xml8511(glossterm) #: ./doc/glossary/glossary-terms.xml8513(primary)#: ./doc/glossary/glossary-terms.xml8517(para)#: ./doc/glossary/glossary-terms.xml8524(glossterm) #: ./doc/glossary/glossary-terms.xml8531(primary)#: ./doc/glossary/glossary-terms.xml8535(para)#: ./doc/glossary/glossary-terms.xml8541(glossterm) #: ./doc/glossary/glossary-terms.xml8543(primary)#: ./doc/glossary/glossary-terms.xml8547(para)#: ./doc/glossary/glossary-terms.xml8554(glossterm)#: ./doc/glossary/glossary-terms.xml8561(primary)#: ./doc/glossary/glossary-terms.xml8565(para)#: ./doc/glossary/glossary-terms.xml8570(glossterm) #: ./doc/glossary/glossary-terms.xml8572(primary)#: ./doc/glossary/glossary-terms.xml8576(para)#: ./doc/glossary/glossary-terms.xml8582(glossterm) #: ./doc/glossary/glossary-terms.xml8584(primary)#: ./doc/glossary/glossary-terms.xml8588(para)#: ./doc/glossary/glossary-terms.xml8593(glossterm) #: ./doc/glossary/glossary-terms.xml8595(primary)#: ./doc/glossary/glossary-terms.xml8604(glossterm) #: ./doc/glossary/glossary-terms.xml8606(primary)#: ./doc/glossary/glossary-terms.xml8610(para)#: ./doc/glossary/glossary-terms.xml8616(glossterm) #: ./doc/glossary/glossary-terms.xml8623(primary)#: ./doc/glossary/glossary-terms.xml8620(secondary)#: ./doc/glossary/glossary-terms.xml8627(para)#: ./doc/glossary/glossary-terms.xml8637(glossterm) #: ./doc/glossary/glossary-terms.xml8639(primary)#: ./doc/glossary/glossary-terms.xml8649(glossterm) #: ./doc/glossary/glossary-terms.xml8651(primary)#: ./doc/glossary/glossary-terms.xml8655(para)#: ./doc/glossary/glossary-terms.xml8660(glossterm) #: ./doc/glossary/glossary-terms.xml8662(primary)#: ./doc/glossary/glossary-terms.xml8666(para)#: ./doc/glossary/glossary-terms.xml8672(glossterm) #: ./doc/glossary/glossary-terms.xml8674(primary)#: ./doc/glossary/glossary-terms.xml8678(para)#: ./doc/glossary/glossary-terms.xml8683(glossterm)#: ./doc/glossary/glossary-terms.xml8686(para)#: ./doc/glossary/glossary-terms.xml8691(glossterm) #: ./doc/glossary/glossary-terms.xml8693(primary)#: ./doc/glossary/glossary-terms.xml8697(para)#: ./doc/glossary/glossary-terms.xml8703(glossterm) #: ./doc/glossary/glossary-terms.xml8715(primary) #: ./doc/glossary/glossary-terms.xml8728(primary) #: ./doc/glossary/glossary-terms.xml8742(primary) #: ./doc/glossary/glossary-terms.xml8755(primary) #: ./doc/glossary/glossary-terms.xml8769(primary) #: ./doc/glossary/glossary-terms.xml8783(primary) #: ./doc/glossary/glossary-terms.xml8797(primary)#: ./doc/glossary/glossary-terms.xml8706(para)#: ./doc/glossary/glossary-terms.xml8713(glossterm) #: ./doc/glossary/glossary-terms.xml8717(secondary)#: ./doc/glossary/glossary-terms.xml8721(para)#: ./doc/glossary/glossary-terms.xml8726(glossterm) #: ./doc/glossary/glossary-terms.xml8730(secondary)#: ./doc/glossary/glossary-terms.xml8734(para)#: ./doc/glossary/glossary-terms.xml8740(glossterm) #: ./doc/glossary/glossary-terms.xml8744(secondary)#: ./doc/glossary/glossary-terms.xml8748(para)#: ./doc/glossary/glossary-terms.xml8753(glossterm) #: ./doc/glossary/glossary-terms.xml8757(secondary)#: ./doc/glossary/glossary-terms.xml8761(para)#: ./doc/glossary/glossary-terms.xml8767(glossterm) #: ./doc/glossary/glossary-terms.xml8771(secondary)#: ./doc/glossary/glossary-terms.xml8775(para)#: ./doc/glossary/glossary-terms.xml8781(glossterm) #: ./doc/glossary/glossary-terms.xml8785(secondary)#: ./doc/glossary/glossary-terms.xml8789(para)#: ./doc/glossary/glossary-terms.xml8795(glossterm) #: ./doc/glossary/glossary-terms.xml8799(secondary)#: ./doc/glossary/glossary-terms.xml8803(para)#: ./doc/glossary/glossary-terms.xml8809(glossterm)#: ./doc/glossary/glossary-terms.xml8811(primary)#: ./doc/glossary/glossary-terms.xml8815(para)#: ./doc/glossary/glossary-terms.xml8823(glossterm) #: ./doc/glossary/glossary-terms.xml8825(primary)#: ./doc/glossary/glossary-terms.xml8837(title)#: ./doc/glossary/glossary-terms.xml8840(glossterm) #: ./doc/glossary/glossary-terms.xml8842(primary)#: ./doc/glossary/glossary-terms.xml8846(para)#: ./doc/glossary/glossary-terms.xml8853(glossterm) #: ./doc/glossary/glossary-terms.xml8855(primary)#: ./doc/glossary/glossary-terms.xml8859(para)#: ./doc/glossary/glossary-terms.xml8865(glossterm) #: ./doc/glossary/glossary-terms.xml8867(primary)#: ./doc/glossary/glossary-terms.xml8871(para)#: ./doc/glossary/glossary-terms.xml8877(glossterm)#: ./doc/glossary/glossary-terms.xml8879(primary)#: ./doc/glossary/glossary-terms.xml8883(para)#: ./doc/glossary/glossary-terms.xml8894(title)#: ./doc/glossary/glossary-terms.xml8897(glossterm) #: ./doc/glossary/glossary-terms.xml8899(primary)#: ./doc/glossary/glossary-terms.xml8903(para)#: ./doc/glossary/glossary-terms.xml8913(glossterm) #: ./doc/glossary/glossary-terms.xml8924(primary) #: ./doc/glossary/glossary-terms.xml8937(primary) #: ./doc/glossary/glossary-terms.xml8951(primary)#: ./doc/glossary/glossary-terms.xml8916(para)#: ./doc/glossary/glossary-terms.xml8922(glossterm) #: ./doc/glossary/glossary-terms.xml8926(secondary)#: ./doc/glossary/glossary-terms.xml8935(glossterm) #: ./doc/glossary/glossary-terms.xml8939(secondary)#: ./doc/glossary/glossary-terms.xml8943(para)#: ./doc/glossary/glossary-terms.xml8949(glossterm)#: ./doc/glossary/glossary-terms.xml8953(secondary)#: ./doc/glossary/glossary-terms.xml8965(title)#: ./doc/glossary/glossary-terms.xml8979(title)#: ./doc/glossary/glossary-terms.xml8982(glossterm) #: ./doc/glossary/glossary-terms.xml8984(primary)#: ./doc/glossary/glossary-terms.xml8988(para)#: ./doc/glossary/glossary-terms.xml8994(glossterm) #: ./doc/glossary/glossary-terms.xml8996(primary)#: ./doc/glossary/glossary-terms.xml9000(para)",1504,1459
openstack%2Foperations-guide~master~I91937e516a19da75972c7b27b54b8463a7350599,openstack/operations-guide,master,I91937e516a19da75972c7b27b54b8463a7350599,Updated from openstack-manuals,MERGED,2014-10-18 09:21:26.000000000,2014-10-20 06:51:23.000000000,2014-10-20 06:51:23.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-18 09:21:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/0735f60c396b0de54f5b722befa6dd03bd466506', 'message': 'Updated from openstack-manuals\n\nChange-Id: I91937e516a19da75972c7b27b54b8463a7350599\n'}, {'number': 2, 'created': '2014-10-20 06:38:06.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/3a049b6be93f42799fa5ab032047f0e6d7fa4222', 'message': 'Updated from openstack-manuals\n\nChange-Id: I91937e516a19da75972c7b27b54b8463a7350599\n'}]",0,129426,3a049b6be93f42799fa5ab032047f0e6d7fa4222,8,2,2,11131,,,0,"Updated from openstack-manuals

Change-Id: I91937e516a19da75972c7b27b54b8463a7350599
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/26/129426/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,0735f60c396b0de54f5b722befa6dd03bd466506,openstack/openstack-manuals,"""POT-Creation-Date: 2014-10-17 12:39+0000\n"" ""PO-Revision-Date: 2014-10-17 12:36+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""#: ./doc/glossary/glossary-terms.xml4986(see)#: ./doc/glossary/glossary-terms.xml3298(secondary) #: ./doc/glossary/glossary-terms.xml3941(secondary) #: ./doc/glossary/glossary-terms.xml3993(secondary) #: ./doc/glossary/glossary-terms.xml4112(secondary) #: ./doc/glossary/glossary-terms.xml4329(secondary) #: ./doc/glossary/glossary-terms.xml4494(secondary) #: ./doc/glossary/glossary-terms.xml4512(secondary) #: ./doc/glossary/glossary-terms.xml5023(secondary) #: ./doc/glossary/glossary-terms.xml5371(secondary) #: ./doc/glossary/glossary-terms.xml5624(secondary) #: ./doc/glossary/glossary-terms.xml5740(secondary) #: ./doc/glossary/glossary-terms.xml6097(secondary) #: ./doc/glossary/glossary-terms.xml6282(secondary) #: ./doc/glossary/glossary-terms.xml6373(secondary) #: ./doc/glossary/glossary-terms.xml6945(secondary) #: ./doc/glossary/glossary-terms.xml7048(secondary) #: ./doc/glossary/glossary-terms.xml7092(secondary) #: ./doc/glossary/glossary-terms.xml7383(secondary) #: ./doc/glossary/glossary-terms.xml7426(secondary)#: ./doc/glossary/glossary-terms.xml3571(primary) #: ./doc/glossary/glossary-terms.xml8157(primary)#: ./doc/glossary/glossary-terms.xml6486(primary)#: ./doc/glossary/glossary-terms.xml6468(primary) #: ./doc/glossary/glossary-terms.xml6900(primary) #: ./doc/glossary/glossary-terms.xml7381(primary) #: ./doc/glossary/glossary-terms.xml7410(primary) #: ./doc/glossary/glossary-terms.xml8607(primary)#: ./doc/glossary/glossary-terms.xml6077(primary)#: ./doc/glossary/glossary-terms.xml6027(para) #: ./doc/glossary/glossary-terms.xml6856(para) #: ./doc/glossary/glossary-terms.xml7924(para)#: ./doc/glossary/glossary-terms.xml5706(secondary)#: ./doc/glossary/glossary-terms.xml5035(primary) #: ./doc/glossary/glossary-terms.xml5738(primary) #: ./doc/glossary/glossary-terms.xml5752(primary) #: ./doc/glossary/glossary-terms.xml5766(primary) #: ./doc/glossary/glossary-terms.xml5781(primary) #: ./doc/glossary/glossary-terms.xml5794(primary) #: ./doc/glossary/glossary-terms.xml5808(primary) #: ./doc/glossary/glossary-terms.xml5822(primary) #: ./doc/glossary/glossary-terms.xml5877(primary) #: ./doc/glossary/glossary-terms.xml7351(primary)#: ./doc/glossary/glossary-terms.xml3845(secondary) #: ./doc/glossary/glossary-terms.xml3975(secondary) #: ./doc/glossary/glossary-terms.xml4055(secondary) #: ./doc/glossary/glossary-terms.xml4070(secondary) #: ./doc/glossary/glossary-terms.xml5986(secondary) #: ./doc/glossary/glossary-terms.xml6821(secondary)#: ./doc/glossary/glossary-terms.xml5671(see)#: ./doc/glossary/glossary-terms.xml4909(para) #: ./doc/glossary/glossary-terms.xml8417(para) #: ./doc/glossary/glossary-terms.xml8650(para) #: ./doc/glossary/glossary-terms.xml8880(para) #: ./doc/glossary/glossary-terms.xml8981(para) #: ./doc/glossary/glossary-terms.xml9008(para)#: ./doc/glossary/glossary-terms.xml8302(primary)msgid ""federated identity"" msgstr """" #: ./doc/glossary/glossary-terms.xml3242(para) msgid """" ""A method to establish trusts between identity providers and the OpenStack "" ""cloud."" msgstr """" #: ./doc/glossary/glossary-terms.xml3248(glossterm) #: ./doc/glossary/glossary-terms.xml3250(primary)#: ./doc/glossary/glossary-terms.xml3254(para)#: ./doc/glossary/glossary-terms.xml3259(glossterm) #: ./doc/glossary/glossary-terms.xml3261(primary)#: ./doc/glossary/glossary-terms.xml3265(para)#: ./doc/glossary/glossary-terms.xml3271(glossterm) #: ./doc/glossary/glossary-terms.xml3273(primary)#: ./doc/glossary/glossary-terms.xml3277(para)#: ./doc/glossary/glossary-terms.xml3282(glossterm) #: ./doc/glossary/glossary-terms.xml3284(primary)#: ./doc/glossary/glossary-terms.xml3288(para)#: ./doc/glossary/glossary-terms.xml3294(glossterm)#: ./doc/glossary/glossary-terms.xml3296(primary) #: ./doc/glossary/glossary-terms.xml4284(primary)#: ./doc/glossary/glossary-terms.xml3302(para)#: ./doc/glossary/glossary-terms.xml3308(glossterm)#: ./doc/glossary/glossary-terms.xml3310(primary)#: ./doc/glossary/glossary-terms.xml3314(para)#: ./doc/glossary/glossary-terms.xml3321(glossterm) #: ./doc/glossary/glossary-terms.xml3323(primary)#: ./doc/glossary/glossary-terms.xml3327(para)#: ./doc/glossary/glossary-terms.xml3333(glossterm)#: ./doc/glossary/glossary-terms.xml3335(primary) #: ./doc/glossary/glossary-terms.xml3430(primary) #: ./doc/glossary/glossary-terms.xml4510(primary) #: ./doc/glossary/glossary-terms.xml6331(primary) #: ./doc/glossary/glossary-terms.xml6520(primary) #: ./doc/glossary/glossary-terms.xml7554(primary) #: ./doc/glossary/glossary-terms.xml7782(primary)#: ./doc/glossary/glossary-terms.xml3337(secondary)#: ./doc/glossary/glossary-terms.xml3340(primary)#: ./doc/glossary/glossary-terms.xml3344(para)#: ./doc/glossary/glossary-terms.xml3352(glossterm) #: ./doc/glossary/glossary-terms.xml3354(primary)#: ./doc/glossary/glossary-terms.xml3358(para)#: ./doc/glossary/glossary-terms.xml3365(glossterm) #: ./doc/glossary/glossary-terms.xml3367(primary)#: ./doc/glossary/glossary-terms.xml3371(para)#: ./doc/glossary/glossary-terms.xml3378(glossterm) #: ./doc/glossary/glossary-terms.xml3380(primary)#: ./doc/glossary/glossary-terms.xml3384(para)#: ./doc/glossary/glossary-terms.xml3393(glossterm) #: ./doc/glossary/glossary-terms.xml3395(primary)#: ./doc/glossary/glossary-terms.xml3399(para)#: ./doc/glossary/glossary-terms.xml3405(glossterm) #: ./doc/glossary/glossary-terms.xml3407(primary)#: ./doc/glossary/glossary-terms.xml3411(para)#: ./doc/glossary/glossary-terms.xml3416(glossterm) #: ./doc/glossary/glossary-terms.xml3418(primary)#: ./doc/glossary/glossary-terms.xml3422(para)#: ./doc/glossary/glossary-terms.xml3428(glossterm) #: ./doc/glossary/glossary-terms.xml3435(primary)#: ./doc/glossary/glossary-terms.xml3432(secondary)#: ./doc/glossary/glossary-terms.xml3439(para)#: ./doc/glossary/glossary-terms.xml3448(glossterm) #: ./doc/glossary/glossary-terms.xml3450(primary)#: ./doc/glossary/glossary-terms.xml3454(para)#: ./doc/glossary/glossary-terms.xml3459(para)#: ./doc/glossary/glossary-terms.xml3467(glossterm) #: ./doc/glossary/glossary-terms.xml3469(primary)#: ./doc/glossary/glossary-terms.xml3473(para)#: ./doc/glossary/glossary-terms.xml3479(glossterm)#: ./doc/glossary/glossary-terms.xml3481(primary)#: ./doc/glossary/glossary-terms.xml3485(para)#: ./doc/glossary/glossary-terms.xml3494(title)#: ./doc/glossary/glossary-terms.xml3497(glossterm) #: ./doc/glossary/glossary-terms.xml3499(primary)#: ./doc/glossary/glossary-terms.xml3503(para)#: ./doc/glossary/glossary-terms.xml3509(glossterm) #: ./doc/glossary/glossary-terms.xml3511(primary)#: ./doc/glossary/glossary-terms.xml3514(para)#: ./doc/glossary/glossary-terms.xml3521(glossterm) #: ./doc/glossary/glossary-terms.xml3523(primary)#: ./doc/glossary/glossary-terms.xml3526(para)#: ./doc/glossary/glossary-terms.xml3533(glossterm) #: ./doc/glossary/glossary-terms.xml3543(primary) #: ./doc/glossary/glossary-terms.xml3558(primary)#: ./doc/glossary/glossary-terms.xml3536(para)#: ./doc/glossary/glossary-terms.xml3541(glossterm) #: ./doc/glossary/glossary-terms.xml3545(secondary)#: ./doc/glossary/glossary-terms.xml3549(para)#: ./doc/glossary/glossary-terms.xml3556(glossterm) #: ./doc/glossary/glossary-terms.xml3560(secondary)#: ./doc/glossary/glossary-terms.xml3564(para)#: ./doc/glossary/glossary-terms.xml3569(glossterm) #: ./doc/glossary/glossary-terms.xml3573(secondary) #: ./doc/glossary/glossary-terms.xml3576(primary)#: ./doc/glossary/glossary-terms.xml3580(para)#: ./doc/glossary/glossary-terms.xml3586(glossterm) #: ./doc/glossary/glossary-terms.xml3588(primary)#: ./doc/glossary/glossary-terms.xml3592(para)#: ./doc/glossary/glossary-terms.xml3598(glossterm) #: ./doc/glossary/glossary-terms.xml3600(primary)#: ./doc/glossary/glossary-terms.xml3604(para)#: ./doc/glossary/glossary-terms.xml3611(glossterm) #: ./doc/glossary/glossary-terms.xml3613(primary)#: ./doc/glossary/glossary-terms.xml3617(para)#: ./doc/glossary/glossary-terms.xml3623(glossterm) #: ./doc/glossary/glossary-terms.xml3625(primary)#: ./doc/glossary/glossary-terms.xml3629(para)#: ./doc/glossary/glossary-terms.xml3635(glossterm) #: ./doc/glossary/glossary-terms.xml3637(primary)#: ./doc/glossary/glossary-terms.xml3641(para)#: ./doc/glossary/glossary-terms.xml3648(glossterm) #: ./doc/glossary/glossary-terms.xml3650(primary)#: ./doc/glossary/glossary-terms.xml3654(para)#: ./doc/glossary/glossary-terms.xml3662(glossterm) #: ./doc/glossary/glossary-terms.xml3664(primary)#: ./doc/glossary/glossary-terms.xml3668(para)#: ./doc/glossary/glossary-terms.xml3677(title)#: ./doc/glossary/glossary-terms.xml3680(glossterm) #: ./doc/glossary/glossary-terms.xml3682(primary)#: ./doc/glossary/glossary-terms.xml3686(para)#: ./doc/glossary/glossary-terms.xml3692(glossterm) #: ./doc/glossary/glossary-terms.xml3694(primary)#: ./doc/glossary/glossary-terms.xml3698(para)#: ./doc/glossary/glossary-terms.xml3704(glossterm) #: ./doc/glossary/glossary-terms.xml3706(primary)#: ./doc/glossary/glossary-terms.xml3710(para)#: ./doc/glossary/glossary-terms.xml3717(glossterm) #: ./doc/glossary/glossary-terms.xml3719(primary)#: ./doc/glossary/glossary-terms.xml3723(para)#: ./doc/glossary/glossary-terms.xml3730(glossterm) #: ./doc/glossary/glossary-terms.xml3732(primary)#: ./doc/glossary/glossary-terms.xml3736(para)#: ./doc/glossary/glossary-terms.xml3742(glossterm) #: ./doc/glossary/glossary-terms.xml3744(primary) #: ./doc/glossary/glossary-terms.xml7756(see)#: ./doc/glossary/glossary-terms.xml3748(para)#: ./doc/glossary/glossary-terms.xml3753(glossterm) #: ./doc/glossary/glossary-terms.xml3755(primary)#: ./doc/glossary/glossary-terms.xml3759(para)#: ./doc/glossary/glossary-terms.xml3769(glossterm) #: ./doc/glossary/glossary-terms.xml3771(primary)#: ./doc/glossary/glossary-terms.xml3775(para)#: ./doc/glossary/glossary-terms.xml3786(glossterm)#: ./doc/glossary/glossary-terms.xml3789(para)#: ./doc/glossary/glossary-terms.xml3795(glossterm)#: ./doc/glossary/glossary-terms.xml3797(primary)#: ./doc/glossary/glossary-terms.xml3801(para)#: ./doc/glossary/glossary-terms.xml3806(glossterm)#: ./doc/glossary/glossary-terms.xml3808(primary)#: ./doc/glossary/glossary-terms.xml3812(para)#: ./doc/glossary/glossary-terms.xml3817(glossterm) #: ./doc/glossary/glossary-terms.xml3819(primary)#: ./doc/glossary/glossary-terms.xml3823(para)#: ./doc/glossary/glossary-terms.xml3829(glossterm) #: ./doc/glossary/glossary-terms.xml3831(primary)#: ./doc/glossary/glossary-terms.xml3835(para)#: ./doc/glossary/glossary-terms.xml3841(glossterm)#: ./doc/glossary/glossary-terms.xml3843(primary)#: ./doc/glossary/glossary-terms.xml3849(para)#: ./doc/glossary/glossary-terms.xml3859(glossterm)#: ./doc/glossary/glossary-terms.xml3861(primary)#: ./doc/glossary/glossary-terms.xml3865(para)#: ./doc/glossary/glossary-terms.xml3876(glossterm) #: ./doc/glossary/glossary-terms.xml3878(primary)#: ./doc/glossary/glossary-terms.xml3882(para)#: ./doc/glossary/glossary-terms.xml3894(glossterm) #: ./doc/glossary/glossary-terms.xml3896(primary)#: ./doc/glossary/glossary-terms.xml3900(para)#: ./doc/glossary/glossary-terms.xml3905(glossterm) #: ./doc/glossary/glossary-terms.xml3907(primary)#: ./doc/glossary/glossary-terms.xml3911(para)#: ./doc/glossary/glossary-terms.xml3918(glossterm)#: ./doc/glossary/glossary-terms.xml3921(para)#: ./doc/glossary/glossary-terms.xml3927(glossterm)#: ./doc/glossary/glossary-terms.xml3930(para)#: ./doc/glossary/glossary-terms.xml3937(glossterm)#: ./doc/glossary/glossary-terms.xml3939(primary) #: ./doc/glossary/glossary-terms.xml3953(primary)#: ./doc/glossary/glossary-terms.xml3945(para)#: ./doc/glossary/glossary-terms.xml3951(glossterm)#: ./doc/glossary/glossary-terms.xml3955(secondary)#: ./doc/glossary/glossary-terms.xml3959(para)#: ./doc/glossary/glossary-terms.xml3968(title)#: ./doc/glossary/glossary-terms.xml3971(glossterm)#: ./doc/glossary/glossary-terms.xml3973(primary)#: ./doc/glossary/glossary-terms.xml3979(para)#: ./doc/glossary/glossary-terms.xml3989(glossterm) #: ./doc/glossary/glossary-terms.xml3991(primary)#: ./doc/glossary/glossary-terms.xml3997(para)#: ./doc/glossary/glossary-terms.xml4004(glossterm)#: ./doc/glossary/glossary-terms.xml4006(primary)#: ./doc/glossary/glossary-terms.xml4010(para)#: ./doc/glossary/glossary-terms.xml4018(glossterm) #: ./doc/glossary/glossary-terms.xml4020(primary)#: ./doc/glossary/glossary-terms.xml4024(para)#: ./doc/glossary/glossary-terms.xml4030(glossterm)#: ./doc/glossary/glossary-terms.xml4033(para)#: ./doc/glossary/glossary-terms.xml4038(glossterm) #: ./doc/glossary/glossary-terms.xml4042(secondary)#: ./doc/glossary/glossary-terms.xml4040(primary) #: ./doc/glossary/glossary-terms.xml4066(glossterm) #: ./doc/glossary/glossary-terms.xml4068(primary) #: ./doc/glossary/glossary-terms.xml4085(primary) #: ./doc/glossary/glossary-terms.xml4156(primary)#: ./doc/glossary/glossary-terms.xml4046(para)#: ./doc/glossary/glossary-terms.xml4052(glossterm) #: ./doc/glossary/glossary-terms.xml4054(primary) msgid ""identity provider"" msgstr """" #: ./doc/glossary/glossary-terms.xml4059(para) msgid """" ""A directory service, which allows users to login with a user name and "" ""password. It is a typical source of authentication tokens."" msgstr """" #: ./doc/glossary/glossary-terms.xml4074(para)#: ./doc/glossary/glossary-terms.xml4083(glossterm) #: ./doc/glossary/glossary-terms.xml4087(secondary)#: ./doc/glossary/glossary-terms.xml4091(para)#: ./doc/glossary/glossary-terms.xml4097(glossterm)#: ./doc/glossary/glossary-terms.xml4099(primary)#: ./doc/glossary/glossary-terms.xml4103(para)#: ./doc/glossary/glossary-terms.xml4108(glossterm)#: ./doc/glossary/glossary-terms.xml4110(primary)#: ./doc/glossary/glossary-terms.xml4116(para)#: ./doc/glossary/glossary-terms.xml4125(glossterm)#: ./doc/glossary/glossary-terms.xml4127(primary) #: ./doc/glossary/glossary-terms.xml4141(primary) #: ./doc/glossary/glossary-terms.xml4170(primary) #: ./doc/glossary/glossary-terms.xml4184(primary) #: ./doc/glossary/glossary-terms.xml4198(primary) #: ./doc/glossary/glossary-terms.xml4210(glossterm) #: ./doc/glossary/glossary-terms.xml4230(primary) #: ./doc/glossary/glossary-terms.xml4244(primary) #: ./doc/glossary/glossary-terms.xml4258(primary) #: ./doc/glossary/glossary-terms.xml6503(primary)#: ./doc/glossary/glossary-terms.xml4129(secondary) #: ./doc/glossary/glossary-terms.xml4220(glossterm)#: ./doc/glossary/glossary-terms.xml4133(para)#: ./doc/glossary/glossary-terms.xml4139(glossterm) #: ./doc/glossary/glossary-terms.xml4143(secondary)#: ./doc/glossary/glossary-terms.xml4147(para)#: ./doc/glossary/glossary-terms.xml4154(glossterm) #: ./doc/glossary/glossary-terms.xml4158(secondary)#: ./doc/glossary/glossary-terms.xml4162(para)#: ./doc/glossary/glossary-terms.xml4168(glossterm) #: ./doc/glossary/glossary-terms.xml4172(secondary)#: ./doc/glossary/glossary-terms.xml4176(para) #: ./doc/glossary/glossary-terms.xml5121(para)#: ./doc/glossary/glossary-terms.xml4182(glossterm) #: ./doc/glossary/glossary-terms.xml4186(secondary)#: ./doc/glossary/glossary-terms.xml4190(para)#: ./doc/glossary/glossary-terms.xml4196(glossterm) #: ./doc/glossary/glossary-terms.xml4200(secondary)#: ./doc/glossary/glossary-terms.xml4204(para)#: ./doc/glossary/glossary-terms.xml4213(para)#: ./doc/glossary/glossary-terms.xml4223(para)#: ./doc/glossary/glossary-terms.xml4228(glossterm) #: ./doc/glossary/glossary-terms.xml4232(secondary)#: ./doc/glossary/glossary-terms.xml4236(para)#: ./doc/glossary/glossary-terms.xml4242(glossterm) #: ./doc/glossary/glossary-terms.xml4246(secondary)#: ./doc/glossary/glossary-terms.xml4250(para)#: ./doc/glossary/glossary-terms.xml4256(glossterm) #: ./doc/glossary/glossary-terms.xml4260(secondary)#: ./doc/glossary/glossary-terms.xml4264(para)#: ./doc/glossary/glossary-terms.xml4270(glossterm)#: ./doc/glossary/glossary-terms.xml4272(primary)#: ./doc/glossary/glossary-terms.xml4276(para)#: ./doc/glossary/glossary-terms.xml4282(glossterm) #: ./doc/glossary/glossary-terms.xml4286(secondary) #: ./doc/glossary/glossary-terms.xml4289(primary)#: ./doc/glossary/glossary-terms.xml4293(para)#: ./doc/glossary/glossary-terms.xml4299(glossterm) #: ./doc/glossary/glossary-terms.xml4301(primary)#: ./doc/glossary/glossary-terms.xml4304(para)#: ./doc/glossary/glossary-terms.xml4313(glossterm) #: ./doc/glossary/glossary-terms.xml4315(primary)#: ./doc/glossary/glossary-terms.xml4319(para)#: ./doc/glossary/glossary-terms.xml4325(glossterm)#: ./doc/glossary/glossary-terms.xml4327(primary) #: ./doc/glossary/glossary-terms.xml4341(primary) #: ./doc/glossary/glossary-terms.xml4354(primary) #: ./doc/glossary/glossary-terms.xml4378(primary) #: ./doc/glossary/glossary-terms.xml4393(primary) #: ./doc/glossary/glossary-terms.xml4406(primary)#: ./doc/glossary/glossary-terms.xml4333(para)#: ./doc/glossary/glossary-terms.xml4339(glossterm) #: ./doc/glossary/glossary-terms.xml4343(secondary)#: ./doc/glossary/glossary-terms.xml4347(para)#: ./doc/glossary/glossary-terms.xml4352(glossterm) #: ./doc/glossary/glossary-terms.xml4356(secondary)#: ./doc/glossary/glossary-terms.xml4360(para)#: ./doc/glossary/glossary-terms.xml4365(glossterm) #: ./doc/glossary/glossary-terms.xml4367(primary)#: ./doc/glossary/glossary-terms.xml4370(para)#: ./doc/glossary/glossary-terms.xml4376(glossterm) #: ./doc/glossary/glossary-terms.xml4380(secondary)#: ./doc/glossary/glossary-terms.xml4384(para)#: ./doc/glossary/glossary-terms.xml4391(glossterm) #: ./doc/glossary/glossary-terms.xml4395(secondary)#: ./doc/glossary/glossary-terms.xml4399(para)#: ./doc/glossary/glossary-terms.xml4404(glossterm) #: ./doc/glossary/glossary-terms.xml4408(secondary)#: ./doc/glossary/glossary-terms.xml4412(para) #: ./doc/glossary/glossary-terms.xml7416(para)#: ./doc/glossary/glossary-terms.xml4418(glossterm) #: ./doc/glossary/glossary-terms.xml4420(primary)#: ./doc/glossary/glossary-terms.xml4424(para)#: ./doc/glossary/glossary-terms.xml4430(glossterm) #: ./doc/glossary/glossary-terms.xml4432(primary)#: ./doc/glossary/glossary-terms.xml4436(para)#: ./doc/glossary/glossary-terms.xml4442(glossterm) #: ./doc/glossary/glossary-terms.xml4444(primary)#: ./doc/glossary/glossary-terms.xml4448(para)#: ./doc/glossary/glossary-terms.xml4454(glossterm) #: ./doc/glossary/glossary-terms.xml4456(primary)#: ./doc/glossary/glossary-terms.xml4460(para)#: ./doc/glossary/glossary-terms.xml4466(glossterm) #: ./doc/glossary/glossary-terms.xml4468(primary)#: ./doc/glossary/glossary-terms.xml4472(para)#: ./doc/glossary/glossary-terms.xml4478(glossterm) #: ./doc/glossary/glossary-terms.xml4480(primary)#: ./doc/glossary/glossary-terms.xml4484(para)#: ./doc/glossary/glossary-terms.xml4490(glossterm) #: ./doc/glossary/glossary-terms.xml4492(primary)#: ./doc/glossary/glossary-terms.xml4498(para)#: ./doc/glossary/glossary-terms.xml4508(glossterm)#: ./doc/glossary/glossary-terms.xml4516(para)#: ./doc/glossary/glossary-terms.xml4523(glossterm) #: ./doc/glossary/glossary-terms.xml4525(primary)#: ./doc/glossary/glossary-terms.xml4529(para)#: ./doc/glossary/glossary-terms.xml4536(glossterm)#: ./doc/glossary/glossary-terms.xml4538(primary)#: ./doc/glossary/glossary-terms.xml4542(para)#: ./doc/glossary/glossary-terms.xml4547(glossterm)#: ./doc/glossary/glossary-terms.xml4549(primary)#: ./doc/glossary/glossary-terms.xml4553(para)#: ./doc/glossary/glossary-terms.xml4564(glossterm) #: ./doc/glossary/glossary-terms.xml4566(primary)#: ./doc/glossary/glossary-terms.xml4570(para)#: ./doc/glossary/glossary-terms.xml4578(glossterm) #: ./doc/glossary/glossary-terms.xml4580(primary)#: ./doc/glossary/glossary-terms.xml4584(para)#: ./doc/glossary/glossary-terms.xml4592(glossterm) #: ./doc/glossary/glossary-terms.xml4594(primary)#: ./doc/glossary/glossary-terms.xml4598(para)#: ./doc/glossary/glossary-terms.xml4609(glossterm)#: ./doc/glossary/glossary-terms.xml4611(primary)#: ./doc/glossary/glossary-terms.xml4615(para)#: ./doc/glossary/glossary-terms.xml4621(glossterm)#: ./doc/glossary/glossary-terms.xml4623(primary)#: ./doc/glossary/glossary-terms.xml4627(para) #: ./doc/glossary/glossary-terms.xml6601(para) #: ./doc/glossary/glossary-terms.xml8474(para) #: ./doc/glossary/glossary-terms.xml8486(para) #: ./doc/glossary/glossary-terms.xml8694(para)#: ./doc/glossary/glossary-terms.xml4633(glossterm) #: ./doc/glossary/glossary-terms.xml4635(primary)#: ./doc/glossary/glossary-terms.xml4639(para)#: ./doc/glossary/glossary-terms.xml4648(title)#: ./doc/glossary/glossary-terms.xml4651(glossterm) #: ./doc/glossary/glossary-terms.xml4653(primary)#: ./doc/glossary/glossary-terms.xml4657(para)#: ./doc/glossary/glossary-terms.xml4663(glossterm) #: ./doc/glossary/glossary-terms.xml4665(primary)#: ./doc/glossary/glossary-terms.xml4669(para)#: ./doc/glossary/glossary-terms.xml4674(glossterm) #: ./doc/glossary/glossary-terms.xml4676(primary)#: ./doc/glossary/glossary-terms.xml4680(para)#: ./doc/glossary/glossary-terms.xml4685(glossterm) #: ./doc/glossary/glossary-terms.xml4687(primary)#: ./doc/glossary/glossary-terms.xml4691(para)#: ./doc/glossary/glossary-terms.xml4697(glossterm) #: ./doc/glossary/glossary-terms.xml4699(primary)#: ./doc/glossary/glossary-terms.xml4703(para)#: ./doc/glossary/glossary-terms.xml4709(glossterm) #: ./doc/glossary/glossary-terms.xml4711(primary)#: ./doc/glossary/glossary-terms.xml4715(para)#: ./doc/glossary/glossary-terms.xml4725(title)#: ./doc/glossary/glossary-terms.xml4728(glossterm)#: ./doc/glossary/glossary-terms.xml4730(primary)#: ./doc/glossary/glossary-terms.xml4734(para)#: ./doc/glossary/glossary-terms.xml4746(glossterm) #: ./doc/glossary/glossary-terms.xml4748(primary)#: ./doc/glossary/glossary-terms.xml4752(para)#: ./doc/glossary/glossary-terms.xml4757(glossterm) #: ./doc/glossary/glossary-terms.xml4759(primary)#: ./doc/glossary/glossary-terms.xml4763(para)#: ./doc/glossary/glossary-terms.xml4769(glossterm) #: ./doc/glossary/glossary-terms.xml4771(primary)#: ./doc/glossary/glossary-terms.xml4775(para)#: ./doc/glossary/glossary-terms.xml4788(title)#: ./doc/glossary/glossary-terms.xml4791(glossterm) #: ./doc/glossary/glossary-terms.xml4793(primary)#: ./doc/glossary/glossary-terms.xml4797(para)#: ./doc/glossary/glossary-terms.xml4802(glossterm) #: ./doc/glossary/glossary-terms.xml4804(primary)#: ./doc/glossary/glossary-terms.xml4808(para)#: ./doc/glossary/glossary-terms.xml4813(glossterm) #: ./doc/glossary/glossary-terms.xml4815(primary)#: ./doc/glossary/glossary-terms.xml4819(para)#: ./doc/glossary/glossary-terms.xml4829(glossterm) #: ./doc/glossary/glossary-terms.xml4831(primary)#: ./doc/glossary/glossary-terms.xml4835(para)#: ./doc/glossary/glossary-terms.xml4844(glossterm) #: ./doc/glossary/glossary-terms.xml4846(primary)#: ./doc/glossary/glossary-terms.xml4850(para)#: ./doc/glossary/glossary-terms.xml4856(glossterm) #: ./doc/glossary/glossary-terms.xml4858(primary)#: ./doc/glossary/glossary-terms.xml4862(para)#: ./doc/glossary/glossary-terms.xml4868(glossterm) #: ./doc/glossary/glossary-terms.xml4870(primary)#: ./doc/glossary/glossary-terms.xml4874(para)#: ./doc/glossary/glossary-terms.xml4880(glossterm)#: ./doc/glossary/glossary-terms.xml4883(para)#: ./doc/glossary/glossary-terms.xml4889(glossterm)#: ./doc/glossary/glossary-terms.xml4891(primary)#: ./doc/glossary/glossary-terms.xml4893(secondary) #: ./doc/glossary/glossary-terms.xml5961(secondary)#: ./doc/glossary/glossary-terms.xml4897(para)#: ./doc/glossary/glossary-terms.xml4903(glossterm) #: ./doc/glossary/glossary-terms.xml4905(primary)#: ./doc/glossary/glossary-terms.xml4914(glossterm) #: ./doc/glossary/glossary-terms.xml4916(primary)#: ./doc/glossary/glossary-terms.xml4920(para)#: ./doc/glossary/glossary-terms.xml4927(glossterm)#: ./doc/glossary/glossary-terms.xml4930(para)#: ./doc/glossary/glossary-terms.xml4938(glossterm) #: ./doc/glossary/glossary-terms.xml4940(primary)#: ./doc/glossary/glossary-terms.xml4944(para)#: ./doc/glossary/glossary-terms.xml4950(glossterm) #: ./doc/glossary/glossary-terms.xml4953(primary)#: ./doc/glossary/glossary-terms.xml4957(para)#: ./doc/glossary/glossary-terms.xml4963(glossterm) #: ./doc/glossary/glossary-terms.xml4965(primary)#: ./doc/glossary/glossary-terms.xml4969(para)#: ./doc/glossary/glossary-terms.xml4979(title)#: ./doc/glossary/glossary-terms.xml4982(glossterm) #: ./doc/glossary/glossary-terms.xml4984(primary)#: ./doc/glossary/glossary-terms.xml4990(para)#: ./doc/glossary/glossary-terms.xml4995(glossterm) #: ./doc/glossary/glossary-terms.xml4997(primary)#: ./doc/glossary/glossary-terms.xml5001(para)#: ./doc/glossary/glossary-terms.xml5007(glossterm) #: ./doc/glossary/glossary-terms.xml5009(primary)#: ./doc/glossary/glossary-terms.xml5013(para)#: ./doc/glossary/glossary-terms.xml5019(glossterm)#: ./doc/glossary/glossary-terms.xml5021(primary) #: ./doc/glossary/glossary-terms.xml5040(primary)#: ./doc/glossary/glossary-terms.xml5027(para)#: ./doc/glossary/glossary-terms.xml5033(glossterm)#: ./doc/glossary/glossary-terms.xml5037(secondary) #: ./doc/glossary/glossary-terms.xml5042(secondary)#: ./doc/glossary/glossary-terms.xml5046(para)#: ./doc/glossary/glossary-terms.xml5052(glossterm) #: ./doc/glossary/glossary-terms.xml5054(primary)#: ./doc/glossary/glossary-terms.xml5058(para)#: ./doc/glossary/glossary-terms.xml5064(glossterm) #: ./doc/glossary/glossary-terms.xml5066(primary)#: ./doc/glossary/glossary-terms.xml5070(para)#: ./doc/glossary/glossary-terms.xml5076(glossterm) #: ./doc/glossary/glossary-terms.xml5078(primary)#: ./doc/glossary/glossary-terms.xml5082(para)#: ./doc/glossary/glossary-terms.xml5091(glossterm) #: ./doc/glossary/glossary-terms.xml5093(primary)#: ./doc/glossary/glossary-terms.xml5097(para)#: ./doc/glossary/glossary-terms.xml5103(glossterm) #: ./doc/glossary/glossary-terms.xml5105(primary)#: ./doc/glossary/glossary-terms.xml5109(para)#: ./doc/glossary/glossary-terms.xml5115(glossterm)#: ./doc/glossary/glossary-terms.xml5117(primary)#: ./doc/glossary/glossary-terms.xml5127(glossterm) #: ./doc/glossary/glossary-terms.xml5129(primary)#: ./doc/glossary/glossary-terms.xml5133(para)#: ./doc/glossary/glossary-terms.xml5139(glossterm) #: ./doc/glossary/glossary-terms.xml5141(primary)#: ./doc/glossary/glossary-terms.xml5145(para)#: ./doc/glossary/glossary-terms.xml5153(glossterm)#: ./doc/glossary/glossary-terms.xml5155(primary)#: ./doc/glossary/glossary-terms.xml5159(para)#: ./doc/glossary/glossary-terms.xml5165(glossterm) #: ./doc/glossary/glossary-terms.xml5167(primary)#: ./doc/glossary/glossary-terms.xml5171(para)#: ./doc/glossary/glossary-terms.xml5177(glossterm) #: ./doc/glossary/glossary-terms.xml5179(primary)#: ./doc/glossary/glossary-terms.xml5183(para)#: ./doc/glossary/glossary-terms.xml5189(glossterm) #: ./doc/glossary/glossary-terms.xml5191(primary)#: ./doc/glossary/glossary-terms.xml5195(para)#: ./doc/glossary/glossary-terms.xml5201(glossterm) #: ./doc/glossary/glossary-terms.xml5203(primary)#: ./doc/glossary/glossary-terms.xml5207(para)#: ./doc/glossary/glossary-terms.xml5212(glossterm) #: ./doc/glossary/glossary-terms.xml5214(primary)#: ./doc/glossary/glossary-terms.xml5218(para)#: ./doc/glossary/glossary-terms.xml5224(glossterm) #: ./doc/glossary/glossary-terms.xml5226(primary)#: ./doc/glossary/glossary-terms.xml5230(para)#: ./doc/glossary/glossary-terms.xml5238(glossterm)#: ./doc/glossary/glossary-terms.xml5241(para)#: ./doc/glossary/glossary-terms.xml5247(glossterm) #: ./doc/glossary/glossary-terms.xml5250(primary)#: ./doc/glossary/glossary-terms.xml5254(para)#: ./doc/glossary/glossary-terms.xml5260(glossterm) #: ./doc/glossary/glossary-terms.xml5262(primary)#: ./doc/glossary/glossary-terms.xml5266(para)#: ./doc/glossary/glossary-terms.xml5272(glossterm) #: ./doc/glossary/glossary-terms.xml5274(primary)#: ./doc/glossary/glossary-terms.xml5278(para)#: ./doc/glossary/glossary-terms.xml5284(glossterm) #: ./doc/glossary/glossary-terms.xml5286(primary)#: ./doc/glossary/glossary-terms.xml5290(para)#: ./doc/glossary/glossary-terms.xml5297(glossterm) #: ./doc/glossary/glossary-terms.xml5299(primary)#: ./doc/glossary/glossary-terms.xml5303(para)#: ./doc/glossary/glossary-terms.xml5312(title)#: ./doc/glossary/glossary-terms.xml5315(glossterm) #: ./doc/glossary/glossary-terms.xml5317(primary)#: ./doc/glossary/glossary-terms.xml5321(para)#: ./doc/glossary/glossary-terms.xml5329(glossterm) #: ./doc/glossary/glossary-terms.xml5331(primary)#: ./doc/glossary/glossary-terms.xml5335(para)#: ./doc/glossary/glossary-terms.xml5341(glossterm) #: ./doc/glossary/glossary-terms.xml5343(primary)#: ./doc/glossary/glossary-terms.xml5347(para)#: ./doc/glossary/glossary-terms.xml5354(glossterm) #: ./doc/glossary/glossary-terms.xml5356(primary)#: ./doc/glossary/glossary-terms.xml5360(para)#: ./doc/glossary/glossary-terms.xml5367(glossterm)#: ./doc/glossary/glossary-terms.xml5369(primary) #: ./doc/glossary/glossary-terms.xml5385(primary) #: ./doc/glossary/glossary-terms.xml5399(primary) #: ./doc/glossary/glossary-terms.xml5414(primary) #: ./doc/glossary/glossary-terms.xml5428(primary) #: ./doc/glossary/glossary-terms.xml5442(primary) #: ./doc/glossary/glossary-terms.xml5456(primary) #: ./doc/glossary/glossary-terms.xml5469(primary) #: ./doc/glossary/glossary-terms.xml5483(primary) #: ./doc/glossary/glossary-terms.xml5497(primary) #: ./doc/glossary/glossary-terms.xml5511(primary) #: ./doc/glossary/glossary-terms.xml6348(primary) #: ./doc/glossary/glossary-terms.xml6548(primary) #: ./doc/glossary/glossary-terms.xml8521(primary) #: ./doc/glossary/glossary-terms.xml8669(primary)#: ./doc/glossary/glossary-terms.xml5375(para)#: ./doc/glossary/glossary-terms.xml5383(glossterm) #: ./doc/glossary/glossary-terms.xml5387(secondary)#: ./doc/glossary/glossary-terms.xml5391(para)#: ./doc/glossary/glossary-terms.xml5397(glossterm)#: ./doc/glossary/glossary-terms.xml5401(secondary)#: ./doc/glossary/glossary-terms.xml5405(para)#: ./doc/glossary/glossary-terms.xml5412(glossterm) #: ./doc/glossary/glossary-terms.xml5416(secondary)#: ./doc/glossary/glossary-terms.xml5420(para)#: ./doc/glossary/glossary-terms.xml5426(glossterm)#: ./doc/glossary/glossary-terms.xml5430(secondary)#: ./doc/glossary/glossary-terms.xml5434(para)#: ./doc/glossary/glossary-terms.xml5440(glossterm)#: ./doc/glossary/glossary-terms.xml5444(secondary)#: ./doc/glossary/glossary-terms.xml5448(para)#: ./doc/glossary/glossary-terms.xml5454(glossterm)#: ./doc/glossary/glossary-terms.xml5458(secondary)#: ./doc/glossary/glossary-terms.xml5462(para)#: ./doc/glossary/glossary-terms.xml5467(glossterm)#: ./doc/glossary/glossary-terms.xml5471(secondary)#: ./doc/glossary/glossary-terms.xml5475(para)#: ./doc/glossary/glossary-terms.xml5481(glossterm) #: ./doc/glossary/glossary-terms.xml5485(secondary)#: ./doc/glossary/glossary-terms.xml5489(para)#: ./doc/glossary/glossary-terms.xml5495(glossterm) #: ./doc/glossary/glossary-terms.xml5499(secondary)#: ./doc/glossary/glossary-terms.xml5503(para)#: ./doc/glossary/glossary-terms.xml5509(glossterm)#: ./doc/glossary/glossary-terms.xml5513(secondary)#: ./doc/glossary/glossary-terms.xml5517(para)#: ./doc/glossary/glossary-terms.xml5524(glossterm)#: ./doc/glossary/glossary-terms.xml5527(para)#: ./doc/glossary/glossary-terms.xml5534(glossterm) #: ./doc/glossary/glossary-terms.xml5536(primary) #: ./doc/glossary/glossary-terms.xml5559(secondary)#: ./doc/glossary/glossary-terms.xml5540(para)#: ./doc/glossary/glossary-terms.xml5546(glossterm) #: ./doc/glossary/glossary-terms.xml5557(primary) #: ./doc/glossary/glossary-terms.xml5570(primary) #: ./doc/glossary/glossary-terms.xml5584(primary)#: ./doc/glossary/glossary-terms.xml5549(para)#: ./doc/glossary/glossary-terms.xml5555(glossterm)#: ./doc/glossary/glossary-terms.xml5563(para)#: ./doc/glossary/glossary-terms.xml5568(glossterm) #: ./doc/glossary/glossary-terms.xml5572(secondary)#: ./doc/glossary/glossary-terms.xml5576(para)#: ./doc/glossary/glossary-terms.xml5582(glossterm) #: ./doc/glossary/glossary-terms.xml5586(secondary)#: ./doc/glossary/glossary-terms.xml5590(para)#: ./doc/glossary/glossary-terms.xml5597(glossterm) #: ./doc/glossary/glossary-terms.xml5599(primary)#: ./doc/glossary/glossary-terms.xml5603(para)#: ./doc/glossary/glossary-terms.xml5608(glossterm) #: ./doc/glossary/glossary-terms.xml5610(primary)#: ./doc/glossary/glossary-terms.xml5614(para)#: ./doc/glossary/glossary-terms.xml5620(glossterm)#: ./doc/glossary/glossary-terms.xml5622(primary) #: ./doc/glossary/glossary-terms.xml6452(primary) #: ./doc/glossary/glossary-terms.xml7822(primary) #: ./doc/glossary/glossary-terms.xml8022(primary)#: ./doc/glossary/glossary-terms.xml5628(para)#: ./doc/glossary/glossary-terms.xml5633(glossterm)#: ./doc/glossary/glossary-terms.xml5635(primary) #: ./doc/glossary/glossary-terms.xml5652(primary) #: ./doc/glossary/glossary-terms.xml6174(primary) #: ./doc/glossary/glossary-terms.xml8285(primary)#: ./doc/glossary/glossary-terms.xml5637(secondary) #: ./doc/glossary/glossary-terms.xml5640(primary) #: ./doc/glossary/glossary-terms.xml8265(see)#: ./doc/glossary/glossary-terms.xml5644(para)#: ./doc/glossary/glossary-terms.xml5650(glossterm) #: ./doc/glossary/glossary-terms.xml5657(primary)#: ./doc/glossary/glossary-terms.xml5654(secondary)#: ./doc/glossary/glossary-terms.xml5661(para)#: ./doc/glossary/glossary-terms.xml5667(glossterm) #: ./doc/glossary/glossary-terms.xml5669(primary)#: ./doc/glossary/glossary-terms.xml5675(para)#: ./doc/glossary/glossary-terms.xml5680(glossterm) #: ./doc/glossary/glossary-terms.xml5682(primary)#: ./doc/glossary/glossary-terms.xml5686(para)#: ./doc/glossary/glossary-terms.xml5694(glossterm) #: ./doc/glossary/glossary-terms.xml5704(primary) #: ./doc/glossary/glossary-terms.xml5717(primary)#: ./doc/glossary/glossary-terms.xml5697(para)#: ./doc/glossary/glossary-terms.xml5702(glossterm)#: ./doc/glossary/glossary-terms.xml5710(para)#: ./doc/glossary/glossary-terms.xml5715(glossterm) #: ./doc/glossary/glossary-terms.xml5719(secondary)#: ./doc/glossary/glossary-terms.xml5723(para)#: ./doc/glossary/glossary-terms.xml5733(title)#: ./doc/glossary/glossary-terms.xml5736(glossterm)#: ./doc/glossary/glossary-terms.xml5744(para)#: ./doc/glossary/glossary-terms.xml5750(glossterm)#: ./doc/glossary/glossary-terms.xml5754(secondary)#: ./doc/glossary/glossary-terms.xml5758(para)#: ./doc/glossary/glossary-terms.xml5764(glossterm) #: ./doc/glossary/glossary-terms.xml5768(secondary)#: ./doc/glossary/glossary-terms.xml5772(para)#: ./doc/glossary/glossary-terms.xml5779(glossterm) #: ./doc/glossary/glossary-terms.xml5783(secondary)#: ./doc/glossary/glossary-terms.xml5787(para)#: ./doc/glossary/glossary-terms.xml5792(glossterm) #: ./doc/glossary/glossary-terms.xml5796(secondary)#: ./doc/glossary/glossary-terms.xml5800(para)#: ./doc/glossary/glossary-terms.xml5806(glossterm)#: ./doc/glossary/glossary-terms.xml5810(secondary)#: ./doc/glossary/glossary-terms.xml5814(para)#: ./doc/glossary/glossary-terms.xml5820(glossterm)#: ./doc/glossary/glossary-terms.xml5824(secondary)#: ./doc/glossary/glossary-terms.xml5828(para)#: ./doc/glossary/glossary-terms.xml5834(glossterm) #: ./doc/glossary/glossary-terms.xml5851(primary) #: ./doc/glossary/glossary-terms.xml5864(primary)#: ./doc/glossary/glossary-terms.xml5837(para)#: ./doc/glossary/glossary-terms.xml5844(glossterm) #: ./doc/glossary/glossary-terms.xml5848(secondary) #: ./doc/glossary/glossary-terms.xml5853(secondary)#: ./doc/glossary/glossary-terms.xml5846(primary) #: ./doc/glossary/glossary-terms.xml7966(glossterm) #: ./doc/glossary/glossary-terms.xml7989(primary) #: ./doc/glossary/glossary-terms.xml8003(primary) #: ./doc/glossary/glossary-terms.xml8027(primary)#: ./doc/glossary/glossary-terms.xml5857(para)#: ./doc/glossary/glossary-terms.xml5862(glossterm) #: ./doc/glossary/glossary-terms.xml5866(secondary)#: ./doc/glossary/glossary-terms.xml5870(para)#: ./doc/glossary/glossary-terms.xml5875(glossterm) #: ./doc/glossary/glossary-terms.xml5879(secondary)#: ./doc/glossary/glossary-terms.xml5883(para)#: ./doc/glossary/glossary-terms.xml5889(glossterm) #: ./doc/glossary/glossary-terms.xml5891(primary)#: ./doc/glossary/glossary-terms.xml5895(para)#: ./doc/glossary/glossary-terms.xml5901(glossterm) #: ./doc/glossary/glossary-terms.xml5904(primary)#: ./doc/glossary/glossary-terms.xml5908(para)#: ./doc/glossary/glossary-terms.xml5914(glossterm) #: ./doc/glossary/glossary-terms.xml5916(primary)#: ./doc/glossary/glossary-terms.xml5920(para)#: ./doc/glossary/glossary-terms.xml5925(glossterm) #: ./doc/glossary/glossary-terms.xml5927(primary) #: ./doc/glossary/glossary-terms.xml5959(primary)#: ./doc/glossary/glossary-terms.xml5931(para)#: ./doc/glossary/glossary-terms.xml5943(glossterm) #: ./doc/glossary/glossary-terms.xml5945(primary)#: ./doc/glossary/glossary-terms.xml5949(para)#: ./doc/glossary/glossary-terms.xml5957(glossterm)#: ./doc/glossary/glossary-terms.xml5965(para)#: ./doc/glossary/glossary-terms.xml5970(glossterm) #: ./doc/glossary/glossary-terms.xml5972(primary)#: ./doc/glossary/glossary-terms.xml5976(para)#: ./doc/glossary/glossary-terms.xml5982(glossterm) #: ./doc/glossary/glossary-terms.xml5984(primary) #: ./doc/glossary/glossary-terms.xml6002(primary)#: ./doc/glossary/glossary-terms.xml5990(para)#: ./doc/glossary/glossary-terms.xml6000(glossterm)#: ./doc/glossary/glossary-terms.xml6003(secondary)#: ./doc/glossary/glossary-terms.xml6007(para)#: ./doc/glossary/glossary-terms.xml6021(glossterm) #: ./doc/glossary/glossary-terms.xml6023(primary)#: ./doc/glossary/glossary-terms.xml6032(glossterm) #: ./doc/glossary/glossary-terms.xml6034(primary)#: ./doc/glossary/glossary-terms.xml6038(para)#: ./doc/glossary/glossary-terms.xml6044(glossterm) #: ./doc/glossary/glossary-terms.xml6046(primary)#: ./doc/glossary/glossary-terms.xml6050(para)#: ./doc/glossary/glossary-terms.xml6057(glossterm)#: ./doc/glossary/glossary-terms.xml6059(primary)#: ./doc/glossary/glossary-terms.xml6063(para)#: ./doc/glossary/glossary-terms.xml6072(title)#: ./doc/glossary/glossary-terms.xml6075(glossterm)#: ./doc/glossary/glossary-terms.xml6079(secondary) #: ./doc/glossary/glossary-terms.xml6082(primary)#: ./doc/glossary/glossary-terms.xml6086(para)#: ./doc/glossary/glossary-terms.xml6093(glossterm)#: ./doc/glossary/glossary-terms.xml6095(primary) #: ./doc/glossary/glossary-terms.xml6110(primary) #: ./doc/glossary/glossary-terms.xml6124(primary)#: ./doc/glossary/glossary-terms.xml6101(para)#: ./doc/glossary/glossary-terms.xml6108(glossterm) #: ./doc/glossary/glossary-terms.xml6112(secondary)#: ./doc/glossary/glossary-terms.xml6116(para)#: ./doc/glossary/glossary-terms.xml6122(glossterm)#: ./doc/glossary/glossary-terms.xml6126(secondary)#: ./doc/glossary/glossary-terms.xml6130(para)#: ./doc/glossary/glossary-terms.xml6136(glossterm) #: ./doc/glossary/glossary-terms.xml6138(primary)#: ./doc/glossary/glossary-terms.xml6142(para)#: ./doc/glossary/glossary-terms.xml6148(glossterm) #: ./doc/glossary/glossary-terms.xml6150(primary)#: ./doc/glossary/glossary-terms.xml6154(para)#: ./doc/glossary/glossary-terms.xml6160(glossterm) #: ./doc/glossary/glossary-terms.xml6162(primary)#: ./doc/glossary/glossary-terms.xml6166(para)#: ./doc/glossary/glossary-terms.xml6172(glossterm)#: ./doc/glossary/glossary-terms.xml6176(secondary) #: ./doc/glossary/glossary-terms.xml6179(primary)#: ./doc/glossary/glossary-terms.xml6183(para)#: ./doc/glossary/glossary-terms.xml6189(glossterm) #: ./doc/glossary/glossary-terms.xml6191(primary)#: ./doc/glossary/glossary-terms.xml6195(para)#: ./doc/glossary/glossary-terms.xml6200(glossterm) #: ./doc/glossary/glossary-terms.xml6202(primary)#: ./doc/glossary/glossary-terms.xml6206(para)#: ./doc/glossary/glossary-terms.xml6212(glossterm) #: ./doc/glossary/glossary-terms.xml6214(primary)#: ./doc/glossary/glossary-terms.xml6218(para)#: ./doc/glossary/glossary-terms.xml6227(glossterm)#: ./doc/glossary/glossary-terms.xml6229(primary)#: ./doc/glossary/glossary-terms.xml6233(para)#: ./doc/glossary/glossary-terms.xml6239(glossterm) #: ./doc/glossary/glossary-terms.xml6241(primary)#: ./doc/glossary/glossary-terms.xml6245(para)#: ./doc/glossary/glossary-terms.xml6251(glossterm) #: ./doc/glossary/glossary-terms.xml6253(primary)#: ./doc/glossary/glossary-terms.xml6257(para)#: ./doc/glossary/glossary-terms.xml6266(glossterm) #: ./doc/glossary/glossary-terms.xml6268(primary)#: ./doc/glossary/glossary-terms.xml6272(para)#: ./doc/glossary/glossary-terms.xml6278(glossterm)#: ./doc/glossary/glossary-terms.xml6280(primary) #: ./doc/glossary/glossary-terms.xml6294(primary) #: ./doc/glossary/glossary-terms.xml8577(primary)#: ./doc/glossary/glossary-terms.xml6286(para)#: ./doc/glossary/glossary-terms.xml6292(glossterm) #: ./doc/glossary/glossary-terms.xml6296(secondary)#: ./doc/glossary/glossary-terms.xml6300(para)#: ./doc/glossary/glossary-terms.xml6305(glossterm)#: ./doc/glossary/glossary-terms.xml6307(primary)#: ./doc/glossary/glossary-terms.xml6311(para)#: ./doc/glossary/glossary-terms.xml6317(glossterm) #: ./doc/glossary/glossary-terms.xml6319(primary)#: ./doc/glossary/glossary-terms.xml6323(para)#: ./doc/glossary/glossary-terms.xml6329(glossterm) #: ./doc/glossary/glossary-terms.xml6336(primary)#: ./doc/glossary/glossary-terms.xml6333(secondary)#: ./doc/glossary/glossary-terms.xml6340(para)#: ./doc/glossary/glossary-terms.xml6346(glossterm)#: ./doc/glossary/glossary-terms.xml6350(secondary) #: ./doc/glossary/glossary-terms.xml6353(primary)#: ./doc/glossary/glossary-terms.xml6357(para)#: ./doc/glossary/glossary-terms.xml6369(glossterm)#: ./doc/glossary/glossary-terms.xml6371(primary) #: ./doc/glossary/glossary-terms.xml6385(primary) #: ./doc/glossary/glossary-terms.xml6399(primary)#: ./doc/glossary/glossary-terms.xml6377(para)#: ./doc/glossary/glossary-terms.xml6383(glossterm) #: ./doc/glossary/glossary-terms.xml6387(secondary)#: ./doc/glossary/glossary-terms.xml6391(para)#: ./doc/glossary/glossary-terms.xml6397(glossterm) #: ./doc/glossary/glossary-terms.xml6401(secondary)#: ./doc/glossary/glossary-terms.xml6405(para)#: ./doc/glossary/glossary-terms.xml6410(glossterm) #: ./doc/glossary/glossary-terms.xml6412(primary)#: ./doc/glossary/glossary-terms.xml6416(para)#: ./doc/glossary/glossary-terms.xml6423(glossterm) #: ./doc/glossary/glossary-terms.xml6425(primary)#: ./doc/glossary/glossary-terms.xml6429(para)#: ./doc/glossary/glossary-terms.xml6438(glossterm) #: ./doc/glossary/glossary-terms.xml6440(primary)#: ./doc/glossary/glossary-terms.xml6444(para)#: ./doc/glossary/glossary-terms.xml6450(glossterm)#: ./doc/glossary/glossary-terms.xml6454(secondary) #: ./doc/glossary/glossary-terms.xml6457(primary)#: ./doc/glossary/glossary-terms.xml6461(para)#: ./doc/glossary/glossary-terms.xml6466(glossterm)#: ./doc/glossary/glossary-terms.xml6470(secondary) #: ./doc/glossary/glossary-terms.xml6473(primary)#: ./doc/glossary/glossary-terms.xml6477(para)#: ./doc/glossary/glossary-terms.xml6484(glossterm) #: ./doc/glossary/glossary-terms.xml6491(primary)#: ./doc/glossary/glossary-terms.xml6488(secondary)#: ./doc/glossary/glossary-terms.xml6495(para)#: ./doc/glossary/glossary-terms.xml6501(glossterm) #: ./doc/glossary/glossary-terms.xml6508(primary)#: ./doc/glossary/glossary-terms.xml6505(secondary)#: ./doc/glossary/glossary-terms.xml6512(para)#: ./doc/glossary/glossary-terms.xml6518(glossterm) #: ./doc/glossary/glossary-terms.xml6525(primary)#: ./doc/glossary/glossary-terms.xml6522(secondary) #: ./doc/glossary/glossary-terms.xml6550(secondary)#: ./doc/glossary/glossary-terms.xml6529(para)#: ./doc/glossary/glossary-terms.xml6534(glossterm) #: ./doc/glossary/glossary-terms.xml6536(primary)#: ./doc/glossary/glossary-terms.xml6540(para)#: ./doc/glossary/glossary-terms.xml6546(glossterm) #: ./doc/glossary/glossary-terms.xml6553(primary)#: ./doc/glossary/glossary-terms.xml6557(para)#: ./doc/glossary/glossary-terms.xml6566(glossterm) #: ./doc/glossary/glossary-terms.xml6568(primary)#: ./doc/glossary/glossary-terms.xml6572(para)#: ./doc/glossary/glossary-terms.xml6578(glossterm) #: ./doc/glossary/glossary-terms.xml6580(primary)#: ./doc/glossary/glossary-terms.xml6584(para)#: ./doc/glossary/glossary-terms.xml6592(title)#: ./doc/glossary/glossary-terms.xml6595(glossterm) #: ./doc/glossary/glossary-terms.xml6597(primary)#: ./doc/glossary/glossary-terms.xml6607(glossterm) #: ./doc/glossary/glossary-terms.xml6609(primary)#: ./doc/glossary/glossary-terms.xml6613(para)#: ./doc/glossary/glossary-terms.xml6619(glossterm) #: ./doc/glossary/glossary-terms.xml6621(primary)#: ./doc/glossary/glossary-terms.xml6625(para)#: ./doc/glossary/glossary-terms.xml6632(glossterm) #: ./doc/glossary/glossary-terms.xml6634(primary)#: ./doc/glossary/glossary-terms.xml6638(para)#: ./doc/glossary/glossary-terms.xml6641(para)#: ./doc/glossary/glossary-terms.xml6647(glossterm)#: ./doc/glossary/glossary-terms.xml6649(primary)#: ./doc/glossary/glossary-terms.xml6653(para)#: ./doc/glossary/glossary-terms.xml6662(title)#: ./doc/glossary/glossary-terms.xml6665(glossterm) #: ./doc/glossary/glossary-terms.xml6667(primary)#: ./doc/glossary/glossary-terms.xml6671(para)#: ./doc/glossary/glossary-terms.xml6676(glossterm) #: ./doc/glossary/glossary-terms.xml6678(primary)#: ./doc/glossary/glossary-terms.xml6682(para)#: ./doc/glossary/glossary-terms.xml6688(glossterm) #: ./doc/glossary/glossary-terms.xml6690(primary)#: ./doc/glossary/glossary-terms.xml6694(para)#: ./doc/glossary/glossary-terms.xml6700(glossterm) #: ./doc/glossary/glossary-terms.xml6702(primary)#: ./doc/glossary/glossary-terms.xml6706(para)#: ./doc/glossary/glossary-terms.xml6713(glossterm) #: ./doc/glossary/glossary-terms.xml6715(primary)#: ./doc/glossary/glossary-terms.xml6719(para)#: ./doc/glossary/glossary-terms.xml6725(glossterm) #: ./doc/glossary/glossary-terms.xml6727(primary)#: ./doc/glossary/glossary-terms.xml6731(para)#: ./doc/glossary/glossary-terms.xml6739(glossterm)#: ./doc/glossary/glossary-terms.xml6741(primary)#: ./doc/glossary/glossary-terms.xml6745(para)#: ./doc/glossary/glossary-terms.xml6751(glossterm)#: ./doc/glossary/glossary-terms.xml6753(primary)#: ./doc/glossary/glossary-terms.xml6757(para)#: ./doc/glossary/glossary-terms.xml6763(glossterm)#: ./doc/glossary/glossary-terms.xml6765(primary)#: ./doc/glossary/glossary-terms.xml6769(para)#: ./doc/glossary/glossary-terms.xml6776(glossterm) #: ./doc/glossary/glossary-terms.xml6778(primary) #: ./doc/glossary/glossary-terms.xml7672(primary)#: ./doc/glossary/glossary-terms.xml6780(secondary) #: ./doc/glossary/glossary-terms.xml7674(secondary)#: ./doc/glossary/glossary-terms.xml6784(para)#: ./doc/glossary/glossary-terms.xml6794(glossterm)#: ./doc/glossary/glossary-terms.xml6796(primary)#: ./doc/glossary/glossary-terms.xml6800(para)#: ./doc/glossary/glossary-terms.xml6806(glossterm) #: ./doc/glossary/glossary-terms.xml6808(primary)#: ./doc/glossary/glossary-terms.xml6812(para)#: ./doc/glossary/glossary-terms.xml6817(glossterm)#: ./doc/glossary/glossary-terms.xml6819(primary) #: ./doc/glossary/glossary-terms.xml6838(primary)#: ./doc/glossary/glossary-terms.xml6825(para)#: ./doc/glossary/glossary-terms.xml6836(glossterm)#: ./doc/glossary/glossary-terms.xml6840(secondary)#: ./doc/glossary/glossary-terms.xml6844(para)#: ./doc/glossary/glossary-terms.xml6850(glossterm) #: ./doc/glossary/glossary-terms.xml6852(primary)#: ./doc/glossary/glossary-terms.xml6861(glossterm) #: ./doc/glossary/glossary-terms.xml6863(primary)#: ./doc/glossary/glossary-terms.xml6867(para)#: ./doc/glossary/glossary-terms.xml6872(glossterm) #: ./doc/glossary/glossary-terms.xml6874(primary)#: ./doc/glossary/glossary-terms.xml6878(para)#: ./doc/glossary/glossary-terms.xml6885(glossterm) #: ./doc/glossary/glossary-terms.xml6887(primary)#: ./doc/glossary/glossary-terms.xml6889(see)#: ./doc/glossary/glossary-terms.xml6893(para)#: ./doc/glossary/glossary-terms.xml6898(glossterm)#: ./doc/glossary/glossary-terms.xml6902(secondary) #: ./doc/glossary/glossary-terms.xml6905(primary)#: ./doc/glossary/glossary-terms.xml6909(para)#: ./doc/glossary/glossary-terms.xml6915(glossterm) #: ./doc/glossary/glossary-terms.xml6918(primary)#: ./doc/glossary/glossary-terms.xml6923(para)#: ./doc/glossary/glossary-terms.xml6929(glossterm) #: ./doc/glossary/glossary-terms.xml6931(primary)#: ./doc/glossary/glossary-terms.xml6935(para)#: ./doc/glossary/glossary-terms.xml6941(glossterm)#: ./doc/glossary/glossary-terms.xml6943(primary) #: ./doc/glossary/glossary-terms.xml6958(primary) #: ./doc/glossary/glossary-terms.xml6970(glossterm) #: ./doc/glossary/glossary-terms.xml6981(primary)#: ./doc/glossary/glossary-terms.xml6949(para)#: ./doc/glossary/glossary-terms.xml6956(glossterm) #: ./doc/glossary/glossary-terms.xml6960(secondary)#: ./doc/glossary/glossary-terms.xml6964(para)#: ./doc/glossary/glossary-terms.xml6973(para)#: ./doc/glossary/glossary-terms.xml6979(glossterm)#: ./doc/glossary/glossary-terms.xml6983(secondary)#: ./doc/glossary/glossary-terms.xml6987(para)#: ./doc/glossary/glossary-terms.xml6993(glossterm)#: ./doc/glossary/glossary-terms.xml6995(primary)#: ./doc/glossary/glossary-terms.xml6999(para)#: ./doc/glossary/glossary-terms.xml7004(glossterm)#: ./doc/glossary/glossary-terms.xml7006(primary)#: ./doc/glossary/glossary-terms.xml7010(para)#: ./doc/glossary/glossary-terms.xml7017(glossterm)#: ./doc/glossary/glossary-terms.xml7019(primary)#: ./doc/glossary/glossary-terms.xml7023(para)#: ./doc/glossary/glossary-terms.xml7031(glossterm)#: ./doc/glossary/glossary-terms.xml7033(primary)#: ./doc/glossary/glossary-terms.xml7037(para)#: ./doc/glossary/glossary-terms.xml7044(glossterm)#: ./doc/glossary/glossary-terms.xml7046(primary) #: ./doc/glossary/glossary-terms.xml7061(primary)#: ./doc/glossary/glossary-terms.xml7052(para)#: ./doc/glossary/glossary-terms.xml7059(glossterm)#: ./doc/glossary/glossary-terms.xml7063(secondary)#: ./doc/glossary/glossary-terms.xml7067(para)#: ./doc/glossary/glossary-terms.xml7074(glossterm) #: ./doc/glossary/glossary-terms.xml7076(primary)#: ./doc/glossary/glossary-terms.xml7080(para)#: ./doc/glossary/glossary-terms.xml7088(glossterm)#: ./doc/glossary/glossary-terms.xml7090(primary) #: ./doc/glossary/glossary-terms.xml7105(primary)#: ./doc/glossary/glossary-terms.xml7096(para)#: ./doc/glossary/glossary-terms.xml7103(glossterm) #: ./doc/glossary/glossary-terms.xml7107(secondary)#: ./doc/glossary/glossary-terms.xml7111(para)#: ./doc/glossary/glossary-terms.xml7116(glossterm) #: ./doc/glossary/glossary-terms.xml7118(primary)#: ./doc/glossary/glossary-terms.xml7122(para)#: ./doc/glossary/glossary-terms.xml7128(glossterm) #: ./doc/glossary/glossary-terms.xml7135(primary)#: ./doc/glossary/glossary-terms.xml7130(primary) #: ./doc/glossary/glossary-terms.xml7715(primary)#: ./doc/glossary/glossary-terms.xml7132(secondary)#: ./doc/glossary/glossary-terms.xml7139(para)#: ./doc/glossary/glossary-terms.xml7145(glossterm) #: ./doc/glossary/glossary-terms.xml7147(primary)#: ./doc/glossary/glossary-terms.xml7151(para)#: ./doc/glossary/glossary-terms.xml7157(glossterm)#: ./doc/glossary/glossary-terms.xml7159(primary)#: ./doc/glossary/glossary-terms.xml7163(para)#: ./doc/glossary/glossary-terms.xml7170(glossterm)#: ./doc/glossary/glossary-terms.xml7172(primary)#: ./doc/glossary/glossary-terms.xml7174(secondary) #: ./doc/glossary/glossary-terms.xml7177(primary)#: ./doc/glossary/glossary-terms.xml7181(para)#: ./doc/glossary/glossary-terms.xml7188(glossterm) #: ./doc/glossary/glossary-terms.xml7190(primary)#: ./doc/glossary/glossary-terms.xml7194(para)#: ./doc/glossary/glossary-terms.xml7199(glossterm)#: ./doc/glossary/glossary-terms.xml7201(primary)#: ./doc/glossary/glossary-terms.xml7205(para)#: ./doc/glossary/glossary-terms.xml7211(glossterm)#: ./doc/glossary/glossary-terms.xml7214(para)#: ./doc/glossary/glossary-terms.xml7220(glossterm) #: ./doc/glossary/glossary-terms.xml7222(primary)#: ./doc/glossary/glossary-terms.xml7226(para)#: ./doc/glossary/glossary-terms.xml7235(title)#: ./doc/glossary/glossary-terms.xml7238(glossterm)#: ./doc/glossary/glossary-terms.xml7240(primary)#: ./doc/glossary/glossary-terms.xml7244(para)#: ./doc/glossary/glossary-terms.xml7251(glossterm) #: ./doc/glossary/glossary-terms.xml7253(primary)#: ./doc/glossary/glossary-terms.xml7257(para)#: ./doc/glossary/glossary-terms.xml7263(glossterm) #: ./doc/glossary/glossary-terms.xml7265(primary) msgid ""SAML assertion"" msgstr """" #: ./doc/glossary/glossary-terms.xml7269(para) msgid """" ""Contains information about a user as provided by the identity provider. It "" ""is an indication that a user has been authenticated."" msgstr """" #: ./doc/glossary/glossary-terms.xml7275(glossterm) #: ./doc/glossary/glossary-terms.xml7277(primary)#: ./doc/glossary/glossary-terms.xml7281(para)#: ./doc/glossary/glossary-terms.xml7288(glossterm)#: ./doc/glossary/glossary-terms.xml7290(primary)#: ./doc/glossary/glossary-terms.xml7294(para)#: ./doc/glossary/glossary-terms.xml7300(glossterm)#: ./doc/glossary/glossary-terms.xml7302(primary)#: ./doc/glossary/glossary-terms.xml7306(para)#: ./doc/glossary/glossary-terms.xml7312(glossterm)#: ./doc/glossary/glossary-terms.xml7314(primary)#: ./doc/glossary/glossary-terms.xml7318(para)#: ./doc/glossary/glossary-terms.xml7324(glossterm) #: ./doc/glossary/glossary-terms.xml7326(primary)#: ./doc/glossary/glossary-terms.xml7330(para)#: ./doc/glossary/glossary-terms.xml7337(glossterm)#: ./doc/glossary/glossary-terms.xml7339(primary)#: ./doc/glossary/glossary-terms.xml7343(para)#: ./doc/glossary/glossary-terms.xml7349(glossterm)#: ./doc/glossary/glossary-terms.xml7353(secondary) #: ./doc/glossary/glossary-terms.xml7356(primary)#: ./doc/glossary/glossary-terms.xml7360(para)#: ./doc/glossary/glossary-terms.xml7367(glossterm) #: ./doc/glossary/glossary-terms.xml7369(primary)#: ./doc/glossary/glossary-terms.xml7373(para)#: ./doc/glossary/glossary-terms.xml7379(glossterm)#: ./doc/glossary/glossary-terms.xml7387(para)#: ./doc/glossary/glossary-terms.xml7391(para)#: ./doc/glossary/glossary-terms.xml7397(glossterm) #: ./doc/glossary/glossary-terms.xml7399(primary)#: ./doc/glossary/glossary-terms.xml7403(para)#: ./doc/glossary/glossary-terms.xml7408(glossterm) #: ./doc/glossary/glossary-terms.xml7412(secondary)#: ./doc/glossary/glossary-terms.xml7422(glossterm)#: ./doc/glossary/glossary-terms.xml7424(primary)#: ./doc/glossary/glossary-terms.xml7430(para)#: ./doc/glossary/glossary-terms.xml7437(glossterm) #: ./doc/glossary/glossary-terms.xml7439(primary)#: ./doc/glossary/glossary-terms.xml7443(para)#: ./doc/glossary/glossary-terms.xml7448(glossterm) #: ./doc/glossary/glossary-terms.xml7450(primary)#: ./doc/glossary/glossary-terms.xml7454(para)#: ./doc/glossary/glossary-terms.xml7460(glossterm) #: ./doc/glossary/glossary-terms.xml7462(primary) msgid ""service provider"" msgstr """" #: ./doc/glossary/glossary-terms.xml7466(para) msgid """" ""A system that provides services to other system entities. In case of "" ""federated identity, OpenStack Identity is the service provider."" msgstr """" #: ./doc/glossary/glossary-terms.xml7473(glossterm) #: ./doc/glossary/glossary-terms.xml7475(primary)#: ./doc/glossary/glossary-terms.xml7479(para)#: ./doc/glossary/glossary-terms.xml7485(glossterm) #: ./doc/glossary/glossary-terms.xml7487(primary)#: ./doc/glossary/glossary-terms.xml7491(para)#: ./doc/glossary/glossary-terms.xml7497(glossterm) #: ./doc/glossary/glossary-terms.xml7499(primary)#: ./doc/glossary/glossary-terms.xml7503(para)#: ./doc/glossary/glossary-terms.xml7509(glossterm) #: ./doc/glossary/glossary-terms.xml7513(secondary)#: ./doc/glossary/glossary-terms.xml7511(primary) #: ./doc/glossary/glossary-terms.xml7525(primary) #: ./doc/glossary/glossary-terms.xml7540(primary)#: ./doc/glossary/glossary-terms.xml7517(para)#: ./doc/glossary/glossary-terms.xml7523(glossterm) #: ./doc/glossary/glossary-terms.xml7527(secondary)#: ./doc/glossary/glossary-terms.xml7531(para)#: ./doc/glossary/glossary-terms.xml7538(glossterm) #: ./doc/glossary/glossary-terms.xml7542(secondary)#: ./doc/glossary/glossary-terms.xml7546(para)#: ./doc/glossary/glossary-terms.xml7552(glossterm) #: ./doc/glossary/glossary-terms.xml7559(primary)#: ./doc/glossary/glossary-terms.xml7556(secondary)#: ./doc/glossary/glossary-terms.xml7563(para)#: ./doc/glossary/glossary-terms.xml7576(glossterm)#: ./doc/glossary/glossary-terms.xml7578(primary)#: ./doc/glossary/glossary-terms.xml7582(para)#: ./doc/glossary/glossary-terms.xml7591(glossterm) #: ./doc/glossary/glossary-terms.xml7593(primary)#: ./doc/glossary/glossary-terms.xml7597(para)#: ./doc/glossary/glossary-terms.xml7603(glossterm) #: ./doc/glossary/glossary-terms.xml7605(primary)#: ./doc/glossary/glossary-terms.xml7609(para)#: ./doc/glossary/glossary-terms.xml7615(glossterm) #: ./doc/glossary/glossary-terms.xml7618(primary)#: ./doc/glossary/glossary-terms.xml7622(para)#: ./doc/glossary/glossary-terms.xml7628(glossterm) #: ./doc/glossary/glossary-terms.xml7631(primary)#: ./doc/glossary/glossary-terms.xml7635(para)#: ./doc/glossary/glossary-terms.xml7645(glossterm) #: ./doc/glossary/glossary-terms.xml7647(primary)#: ./doc/glossary/glossary-terms.xml7651(para)#: ./doc/glossary/glossary-terms.xml7657(glossterm) #: ./doc/glossary/glossary-terms.xml7659(primary)#: ./doc/glossary/glossary-terms.xml7663(para)#: ./doc/glossary/glossary-terms.xml7670(glossterm) #: ./doc/glossary/glossary-terms.xml7677(primary)#: ./doc/glossary/glossary-terms.xml7681(para)#: ./doc/glossary/glossary-terms.xml7687(glossterm) #: ./doc/glossary/glossary-terms.xml7689(primary)#: ./doc/glossary/glossary-terms.xml7693(para)#: ./doc/glossary/glossary-terms.xml7699(glossterm)#: ./doc/glossary/glossary-terms.xml7701(primary)#: ./doc/glossary/glossary-terms.xml7706(para)#: ./doc/glossary/glossary-terms.xml7713(glossterm) #: ./doc/glossary/glossary-terms.xml7720(primary)#: ./doc/glossary/glossary-terms.xml7717(secondary)#: ./doc/glossary/glossary-terms.xml7724(para)#: ./doc/glossary/glossary-terms.xml7730(glossterm) #: ./doc/glossary/glossary-terms.xml7732(primary)#: ./doc/glossary/glossary-terms.xml7736(para)#: ./doc/glossary/glossary-terms.xml7741(glossterm) #: ./doc/glossary/glossary-terms.xml7743(primary)#: ./doc/glossary/glossary-terms.xml7747(para)#: ./doc/glossary/glossary-terms.xml7753(glossterm) #: ./doc/glossary/glossary-terms.xml7755(primary)#: ./doc/glossary/glossary-terms.xml7760(para)#: ./doc/glossary/glossary-terms.xml7768(glossterm) #: ./doc/glossary/glossary-terms.xml7770(primary)#: ./doc/glossary/glossary-terms.xml7774(para)#: ./doc/glossary/glossary-terms.xml7780(glossterm)#: ./doc/glossary/glossary-terms.xml7784(secondary)#: ./doc/glossary/glossary-terms.xml7787(primary)#: ./doc/glossary/glossary-terms.xml7791(para)#: ./doc/glossary/glossary-terms.xml7796(glossterm) #: ./doc/glossary/glossary-terms.xml7798(primary)#: ./doc/glossary/glossary-terms.xml7802(para)#: ./doc/glossary/glossary-terms.xml7808(glossterm) #: ./doc/glossary/glossary-terms.xml7810(primary)#: ./doc/glossary/glossary-terms.xml7814(para)#: ./doc/glossary/glossary-terms.xml7820(glossterm) #: ./doc/glossary/glossary-terms.xml7827(primary)#: ./doc/glossary/glossary-terms.xml7824(secondary)#: ./doc/glossary/glossary-terms.xml7831(para)#: ./doc/glossary/glossary-terms.xml7838(glossterm) #: ./doc/glossary/glossary-terms.xml7842(secondary)#: ./doc/glossary/glossary-terms.xml7840(primary) #: ./doc/glossary/glossary-terms.xml7854(primary) #: ./doc/glossary/glossary-terms.xml7868(primary) #: ./doc/glossary/glossary-terms.xml8017(primary)#: ./doc/glossary/glossary-terms.xml7846(para)#: ./doc/glossary/glossary-terms.xml7852(glossterm) #: ./doc/glossary/glossary-terms.xml7856(secondary)#: ./doc/glossary/glossary-terms.xml7860(para)#: ./doc/glossary/glossary-terms.xml7866(glossterm) #: ./doc/glossary/glossary-terms.xml7870(secondary)#: ./doc/glossary/glossary-terms.xml7874(para)#: ./doc/glossary/glossary-terms.xml7880(glossterm) #: ./doc/glossary/glossary-terms.xml7882(primary)#: ./doc/glossary/glossary-terms.xml7886(para)#: ./doc/glossary/glossary-terms.xml7892(glossterm)#: ./doc/glossary/glossary-terms.xml7894(primary)#: ./doc/glossary/glossary-terms.xml7898(para)#: ./doc/glossary/glossary-terms.xml7906(glossterm) #: ./doc/glossary/glossary-terms.xml7908(primary)#: ./doc/glossary/glossary-terms.xml7912(para)#: ./doc/glossary/glossary-terms.xml7917(glossterm) #: ./doc/glossary/glossary-terms.xml7920(primary)#: ./doc/glossary/glossary-terms.xml7929(glossterm)#: ./doc/glossary/glossary-terms.xml7931(primary)#: ./doc/glossary/glossary-terms.xml7935(para)#: ./doc/glossary/glossary-terms.xml7941(glossterm)#: ./doc/glossary/glossary-terms.xml7943(primary)#: ./doc/glossary/glossary-terms.xml7947(para)#: ./doc/glossary/glossary-terms.xml7953(glossterm) #: ./doc/glossary/glossary-terms.xml7955(primary)#: ./doc/glossary/glossary-terms.xml7959(para)#: ./doc/glossary/glossary-terms.xml7969(para)#: ./doc/glossary/glossary-terms.xml7975(glossterm) #: ./doc/glossary/glossary-terms.xml7977(primary)#: ./doc/glossary/glossary-terms.xml7981(para)#: ./doc/glossary/glossary-terms.xml7987(glossterm) #: ./doc/glossary/glossary-terms.xml7991(secondary)#: ./doc/glossary/glossary-terms.xml7995(para)#: ./doc/glossary/glossary-terms.xml8001(glossterm) #: ./doc/glossary/glossary-terms.xml8005(secondary)#: ./doc/glossary/glossary-terms.xml8009(para)#: ./doc/glossary/glossary-terms.xml8015(glossterm)#: ./doc/glossary/glossary-terms.xml8019(secondary) #: ./doc/glossary/glossary-terms.xml8024(secondary) #: ./doc/glossary/glossary-terms.xml8029(secondary)#: ./doc/glossary/glossary-terms.xml8033(para)#: ./doc/glossary/glossary-terms.xml8039(glossterm) #: ./doc/glossary/glossary-terms.xml8041(primary)#: ./doc/glossary/glossary-terms.xml8045(para)#: ./doc/glossary/glossary-terms.xml8051(glossterm) #: ./doc/glossary/glossary-terms.xml8053(primary)#: ./doc/glossary/glossary-terms.xml8057(para)#: ./doc/glossary/glossary-terms.xml8064(glossterm) #: ./doc/glossary/glossary-terms.xml8066(primary)#: ./doc/glossary/glossary-terms.xml8070(para)#: ./doc/glossary/glossary-terms.xml8080(title)#: ./doc/glossary/glossary-terms.xml8083(glossterm) #: ./doc/glossary/glossary-terms.xml8085(primary)#: ./doc/glossary/glossary-terms.xml8089(para)#: ./doc/glossary/glossary-terms.xml8096(glossterm) #: ./doc/glossary/glossary-terms.xml8098(primary)#: ./doc/glossary/glossary-terms.xml8102(para)#: ./doc/glossary/glossary-terms.xml8109(glossterm) #: ./doc/glossary/glossary-terms.xml8111(primary)#: ./doc/glossary/glossary-terms.xml8115(para)#: ./doc/glossary/glossary-terms.xml8121(glossterm) #: ./doc/glossary/glossary-terms.xml8123(primary)#: ./doc/glossary/glossary-terms.xml8127(para)#: ./doc/glossary/glossary-terms.xml8133(glossterm) #: ./doc/glossary/glossary-terms.xml8144(primary) #: ./doc/glossary/glossary-terms.xml8162(primary) #: ./doc/glossary/glossary-terms.xml8176(primary)#: ./doc/glossary/glossary-terms.xml8136(para)#: ./doc/glossary/glossary-terms.xml8142(glossterm) #: ./doc/glossary/glossary-terms.xml8146(secondary)#: ./doc/glossary/glossary-terms.xml8150(para)#: ./doc/glossary/glossary-terms.xml8155(glossterm) #: ./doc/glossary/glossary-terms.xml8159(secondary) #: ./doc/glossary/glossary-terms.xml8164(secondary)#: ./doc/glossary/glossary-terms.xml8168(para)#: ./doc/glossary/glossary-terms.xml8174(glossterm) #: ./doc/glossary/glossary-terms.xml8178(secondary)#: ./doc/glossary/glossary-terms.xml8182(para)#: ./doc/glossary/glossary-terms.xml8188(glossterm)#: ./doc/glossary/glossary-terms.xml8190(primary)#: ./doc/glossary/glossary-terms.xml8194(para)#: ./doc/glossary/glossary-terms.xml8200(glossterm) #: ./doc/glossary/glossary-terms.xml8202(primary)#: ./doc/glossary/glossary-terms.xml8206(para)#: ./doc/glossary/glossary-terms.xml8212(glossterm) #: ./doc/glossary/glossary-terms.xml8214(primary)#: ./doc/glossary/glossary-terms.xml8217(para)#: ./doc/glossary/glossary-terms.xml8225(glossterm) #: ./doc/glossary/glossary-terms.xml8227(primary)#: ./doc/glossary/glossary-terms.xml8231(para)#: ./doc/glossary/glossary-terms.xml8237(glossterm) #: ./doc/glossary/glossary-terms.xml8239(primary)#: ./doc/glossary/glossary-terms.xml8243(para)#: ./doc/glossary/glossary-terms.xml8249(glossterm)#: ./doc/glossary/glossary-terms.xml8251(primary)#: ./doc/glossary/glossary-terms.xml8255(para)#: ./doc/glossary/glossary-terms.xml8261(glossterm)#: ./doc/glossary/glossary-terms.xml8263(primary)#: ./doc/glossary/glossary-terms.xml8269(para)#: ./doc/glossary/glossary-terms.xml8274(glossterm)#: ./doc/glossary/glossary-terms.xml8277(para)#: ./doc/glossary/glossary-terms.xml8283(glossterm)#: ./doc/glossary/glossary-terms.xml8287(secondary) #: ./doc/glossary/glossary-terms.xml8290(primary)#: ./doc/glossary/glossary-terms.xml8294(para)#: ./doc/glossary/glossary-terms.xml8300(glossterm)#: ./doc/glossary/glossary-terms.xml8304(secondary) #: ./doc/glossary/glossary-terms.xml8307(primary)#: ./doc/glossary/glossary-terms.xml8311(para)#: ./doc/glossary/glossary-terms.xml8316(glossterm) #: ./doc/glossary/glossary-terms.xml8318(primary)#: ./doc/glossary/glossary-terms.xml8322(para)#: ./doc/glossary/glossary-terms.xml8330(glossterm) #: ./doc/glossary/glossary-terms.xml8332(primary)#: ./doc/glossary/glossary-terms.xml8336(para)#: ./doc/glossary/glossary-terms.xml8345(title)#: ./doc/glossary/glossary-terms.xml8348(glossterm) #: ./doc/glossary/glossary-terms.xml8350(primary)#: ./doc/glossary/glossary-terms.xml8354(para)#: ./doc/glossary/glossary-terms.xml8359(glossterm) #: ./doc/glossary/glossary-terms.xml8361(primary)#: ./doc/glossary/glossary-terms.xml8365(para)#: ./doc/glossary/glossary-terms.xml8370(glossterm)#: ./doc/glossary/glossary-terms.xml8372(primary)#: ./doc/glossary/glossary-terms.xml8376(para)#: ./doc/glossary/glossary-terms.xml8382(glossterm)#: ./doc/glossary/glossary-terms.xml8384(primary)#: ./doc/glossary/glossary-terms.xml8388(para)#: ./doc/glossary/glossary-terms.xml8395(glossterm) #: ./doc/glossary/glossary-terms.xml8397(primary)#: ./doc/glossary/glossary-terms.xml8401(para)#: ./doc/glossary/glossary-terms.xml8411(glossterm) #: ./doc/glossary/glossary-terms.xml8413(primary)#: ./doc/glossary/glossary-terms.xml8425(title)#: ./doc/glossary/glossary-terms.xml8428(glossterm) #: ./doc/glossary/glossary-terms.xml8430(primary)#: ./doc/glossary/glossary-terms.xml8434(para)#: ./doc/glossary/glossary-terms.xml8439(glossterm) #: ./doc/glossary/glossary-terms.xml8441(primary)#: ./doc/glossary/glossary-terms.xml8445(para)#: ./doc/glossary/glossary-terms.xml8455(glossterm) #: ./doc/glossary/glossary-terms.xml8458(primary)#: ./doc/glossary/glossary-terms.xml8462(para)#: ./doc/glossary/glossary-terms.xml8468(glossterm) #: ./doc/glossary/glossary-terms.xml8470(primary)#: ./doc/glossary/glossary-terms.xml8480(glossterm) #: ./doc/glossary/glossary-terms.xml8482(primary)#: ./doc/glossary/glossary-terms.xml8492(glossterm) #: ./doc/glossary/glossary-terms.xml8494(primary)#: ./doc/glossary/glossary-terms.xml8498(para)#: ./doc/glossary/glossary-terms.xml8506(glossterm) #: ./doc/glossary/glossary-terms.xml8508(primary)#: ./doc/glossary/glossary-terms.xml8512(para)#: ./doc/glossary/glossary-terms.xml8519(glossterm) #: ./doc/glossary/glossary-terms.xml8526(primary)#: ./doc/glossary/glossary-terms.xml8523(secondary) #: ./doc/glossary/glossary-terms.xml8579(secondary) #: ./doc/glossary/glossary-terms.xml8609(secondary)#: ./doc/glossary/glossary-terms.xml8530(para)#: ./doc/glossary/glossary-terms.xml8535(glossterm) #: ./doc/glossary/glossary-terms.xml8537(primary)#: ./doc/glossary/glossary-terms.xml8541(para)#: ./doc/glossary/glossary-terms.xml8550(glossterm) #: ./doc/glossary/glossary-terms.xml8552(primary)#: ./doc/glossary/glossary-terms.xml8556(para)#: ./doc/glossary/glossary-terms.xml8562(glossterm) #: ./doc/glossary/glossary-terms.xml8564(primary)#: ./doc/glossary/glossary-terms.xml8568(para)#: ./doc/glossary/glossary-terms.xml8575(glossterm) #: ./doc/glossary/glossary-terms.xml8582(primary)#: ./doc/glossary/glossary-terms.xml8586(para)#: ./doc/glossary/glossary-terms.xml8592(glossterm) #: ./doc/glossary/glossary-terms.xml8594(primary)#: ./doc/glossary/glossary-terms.xml8598(para)#: ./doc/glossary/glossary-terms.xml8605(glossterm)#: ./doc/glossary/glossary-terms.xml8612(primary)#: ./doc/glossary/glossary-terms.xml8616(para)#: ./doc/glossary/glossary-terms.xml8621(glossterm) #: ./doc/glossary/glossary-terms.xml8623(primary)#: ./doc/glossary/glossary-terms.xml8627(para)#: ./doc/glossary/glossary-terms.xml8633(glossterm) #: ./doc/glossary/glossary-terms.xml8635(primary)#: ./doc/glossary/glossary-terms.xml8639(para)#: ./doc/glossary/glossary-terms.xml8644(glossterm) #: ./doc/glossary/glossary-terms.xml8646(primary)#: ./doc/glossary/glossary-terms.xml8655(glossterm) #: ./doc/glossary/glossary-terms.xml8657(primary)#: ./doc/glossary/glossary-terms.xml8661(para)#: ./doc/glossary/glossary-terms.xml8667(glossterm) #: ./doc/glossary/glossary-terms.xml8674(primary)#: ./doc/glossary/glossary-terms.xml8671(secondary)#: ./doc/glossary/glossary-terms.xml8678(para)#: ./doc/glossary/glossary-terms.xml8688(glossterm) #: ./doc/glossary/glossary-terms.xml8690(primary)#: ./doc/glossary/glossary-terms.xml8700(glossterm) #: ./doc/glossary/glossary-terms.xml8702(primary)#: ./doc/glossary/glossary-terms.xml8706(para)#: ./doc/glossary/glossary-terms.xml8711(glossterm) #: ./doc/glossary/glossary-terms.xml8713(primary)#: ./doc/glossary/glossary-terms.xml8717(para)#: ./doc/glossary/glossary-terms.xml8723(glossterm) #: ./doc/glossary/glossary-terms.xml8725(primary)#: ./doc/glossary/glossary-terms.xml8729(para)#: ./doc/glossary/glossary-terms.xml8734(glossterm)#: ./doc/glossary/glossary-terms.xml8737(para)#: ./doc/glossary/glossary-terms.xml8742(glossterm) #: ./doc/glossary/glossary-terms.xml8744(primary)#: ./doc/glossary/glossary-terms.xml8748(para)#: ./doc/glossary/glossary-terms.xml8754(glossterm) #: ./doc/glossary/glossary-terms.xml8766(primary) #: ./doc/glossary/glossary-terms.xml8779(primary) #: ./doc/glossary/glossary-terms.xml8793(primary) #: ./doc/glossary/glossary-terms.xml8806(primary) #: ./doc/glossary/glossary-terms.xml8820(primary) #: ./doc/glossary/glossary-terms.xml8834(primary) #: ./doc/glossary/glossary-terms.xml8848(primary)#: ./doc/glossary/glossary-terms.xml8757(para)#: ./doc/glossary/glossary-terms.xml8764(glossterm) #: ./doc/glossary/glossary-terms.xml8768(secondary)#: ./doc/glossary/glossary-terms.xml8772(para)#: ./doc/glossary/glossary-terms.xml8777(glossterm) #: ./doc/glossary/glossary-terms.xml8781(secondary)#: ./doc/glossary/glossary-terms.xml8785(para)#: ./doc/glossary/glossary-terms.xml8791(glossterm) #: ./doc/glossary/glossary-terms.xml8795(secondary)#: ./doc/glossary/glossary-terms.xml8799(para)#: ./doc/glossary/glossary-terms.xml8804(glossterm) #: ./doc/glossary/glossary-terms.xml8808(secondary)#: ./doc/glossary/glossary-terms.xml8812(para)#: ./doc/glossary/glossary-terms.xml8818(glossterm) #: ./doc/glossary/glossary-terms.xml8822(secondary)#: ./doc/glossary/glossary-terms.xml8826(para)#: ./doc/glossary/glossary-terms.xml8832(glossterm) #: ./doc/glossary/glossary-terms.xml8836(secondary)#: ./doc/glossary/glossary-terms.xml8840(para)#: ./doc/glossary/glossary-terms.xml8846(glossterm) #: ./doc/glossary/glossary-terms.xml8850(secondary)#: ./doc/glossary/glossary-terms.xml8854(para)#: ./doc/glossary/glossary-terms.xml8860(glossterm)#: ./doc/glossary/glossary-terms.xml8862(primary)#: ./doc/glossary/glossary-terms.xml8866(para)#: ./doc/glossary/glossary-terms.xml8874(glossterm) #: ./doc/glossary/glossary-terms.xml8876(primary)#: ./doc/glossary/glossary-terms.xml8888(title)#: ./doc/glossary/glossary-terms.xml8891(glossterm) #: ./doc/glossary/glossary-terms.xml8893(primary)#: ./doc/glossary/glossary-terms.xml8897(para)#: ./doc/glossary/glossary-terms.xml8904(glossterm) #: ./doc/glossary/glossary-terms.xml8906(primary)#: ./doc/glossary/glossary-terms.xml8910(para)#: ./doc/glossary/glossary-terms.xml8916(glossterm) #: ./doc/glossary/glossary-terms.xml8918(primary)#: ./doc/glossary/glossary-terms.xml8922(para)#: ./doc/glossary/glossary-terms.xml8928(glossterm)#: ./doc/glossary/glossary-terms.xml8930(primary)#: ./doc/glossary/glossary-terms.xml8934(para)#: ./doc/glossary/glossary-terms.xml8945(title)#: ./doc/glossary/glossary-terms.xml8948(glossterm) #: ./doc/glossary/glossary-terms.xml8950(primary)#: ./doc/glossary/glossary-terms.xml8954(para)#: ./doc/glossary/glossary-terms.xml8964(glossterm) #: ./doc/glossary/glossary-terms.xml8975(primary) #: ./doc/glossary/glossary-terms.xml8988(primary) #: ./doc/glossary/glossary-terms.xml9002(primary)#: ./doc/glossary/glossary-terms.xml8967(para)#: ./doc/glossary/glossary-terms.xml8973(glossterm) #: ./doc/glossary/glossary-terms.xml8977(secondary)#: ./doc/glossary/glossary-terms.xml8986(glossterm) #: ./doc/glossary/glossary-terms.xml8990(secondary)#: ./doc/glossary/glossary-terms.xml8994(para)#: ./doc/glossary/glossary-terms.xml9000(glossterm)#: ./doc/glossary/glossary-terms.xml9004(secondary)#: ./doc/glossary/glossary-terms.xml9016(title)#: ./doc/glossary/glossary-terms.xml9030(title)#: ./doc/glossary/glossary-terms.xml9033(glossterm) #: ./doc/glossary/glossary-terms.xml9035(primary)#: ./doc/glossary/glossary-terms.xml9039(para)#: ./doc/glossary/glossary-terms.xml9045(glossterm) #: ./doc/glossary/glossary-terms.xml9047(primary)#: ./doc/glossary/glossary-terms.xml9051(para)","""POT-Creation-Date: 2014-10-11 02:09+0000\n"" ""PO-Revision-Date: 2014-10-11 03:10+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""#: ./doc/glossary/glossary-terms.xml4960(see)#: ./doc/glossary/glossary-terms.xml3286(secondary) #: ./doc/glossary/glossary-terms.xml3929(secondary) #: ./doc/glossary/glossary-terms.xml3981(secondary) #: ./doc/glossary/glossary-terms.xml4086(secondary) #: ./doc/glossary/glossary-terms.xml4303(secondary) #: ./doc/glossary/glossary-terms.xml4468(secondary) #: ./doc/glossary/glossary-terms.xml4486(secondary) #: ./doc/glossary/glossary-terms.xml4997(secondary) #: ./doc/glossary/glossary-terms.xml5345(secondary) #: ./doc/glossary/glossary-terms.xml5598(secondary) #: ./doc/glossary/glossary-terms.xml5714(secondary) #: ./doc/glossary/glossary-terms.xml6071(secondary) #: ./doc/glossary/glossary-terms.xml6256(secondary) #: ./doc/glossary/glossary-terms.xml6347(secondary) #: ./doc/glossary/glossary-terms.xml6919(secondary) #: ./doc/glossary/glossary-terms.xml7022(secondary) #: ./doc/glossary/glossary-terms.xml7066(secondary) #: ./doc/glossary/glossary-terms.xml7345(secondary) #: ./doc/glossary/glossary-terms.xml7388(secondary)#: ./doc/glossary/glossary-terms.xml3559(primary) #: ./doc/glossary/glossary-terms.xml8106(primary)#: ./doc/glossary/glossary-terms.xml6460(primary)#: ./doc/glossary/glossary-terms.xml6442(primary) #: ./doc/glossary/glossary-terms.xml6874(primary) #: ./doc/glossary/glossary-terms.xml7343(primary) #: ./doc/glossary/glossary-terms.xml7372(primary) #: ./doc/glossary/glossary-terms.xml8556(primary)#: ./doc/glossary/glossary-terms.xml6051(primary)#: ./doc/glossary/glossary-terms.xml6001(para) #: ./doc/glossary/glossary-terms.xml6830(para) #: ./doc/glossary/glossary-terms.xml7873(para)#: ./doc/glossary/glossary-terms.xml5680(secondary)#: ./doc/glossary/glossary-terms.xml5009(primary) #: ./doc/glossary/glossary-terms.xml5712(primary) #: ./doc/glossary/glossary-terms.xml5726(primary) #: ./doc/glossary/glossary-terms.xml5740(primary) #: ./doc/glossary/glossary-terms.xml5755(primary) #: ./doc/glossary/glossary-terms.xml5768(primary) #: ./doc/glossary/glossary-terms.xml5782(primary) #: ./doc/glossary/glossary-terms.xml5796(primary) #: ./doc/glossary/glossary-terms.xml5851(primary) #: ./doc/glossary/glossary-terms.xml7313(primary)#: ./doc/glossary/glossary-terms.xml3833(secondary) #: ./doc/glossary/glossary-terms.xml3963(secondary) #: ./doc/glossary/glossary-terms.xml4044(secondary) #: ./doc/glossary/glossary-terms.xml5960(secondary) #: ./doc/glossary/glossary-terms.xml6795(secondary)#: ./doc/glossary/glossary-terms.xml5645(see)#: ./doc/glossary/glossary-terms.xml4883(para) #: ./doc/glossary/glossary-terms.xml8366(para) #: ./doc/glossary/glossary-terms.xml8599(para) #: ./doc/glossary/glossary-terms.xml8829(para) #: ./doc/glossary/glossary-terms.xml8930(para) #: ./doc/glossary/glossary-terms.xml8957(para)#: ./doc/glossary/glossary-terms.xml8251(primary)#: ./doc/glossary/glossary-terms.xml3242(para)#: ./doc/glossary/glossary-terms.xml3247(glossterm) #: ./doc/glossary/glossary-terms.xml3249(primary)#: ./doc/glossary/glossary-terms.xml3253(para)#: ./doc/glossary/glossary-terms.xml3259(glossterm) #: ./doc/glossary/glossary-terms.xml3261(primary)#: ./doc/glossary/glossary-terms.xml3265(para)#: ./doc/glossary/glossary-terms.xml3270(glossterm) #: ./doc/glossary/glossary-terms.xml3272(primary)#: ./doc/glossary/glossary-terms.xml3276(para)#: ./doc/glossary/glossary-terms.xml3282(glossterm)#: ./doc/glossary/glossary-terms.xml3284(primary) #: ./doc/glossary/glossary-terms.xml4258(primary)#: ./doc/glossary/glossary-terms.xml3290(para)#: ./doc/glossary/glossary-terms.xml3296(glossterm)#: ./doc/glossary/glossary-terms.xml3298(primary)#: ./doc/glossary/glossary-terms.xml3302(para)#: ./doc/glossary/glossary-terms.xml3309(glossterm) #: ./doc/glossary/glossary-terms.xml3311(primary)#: ./doc/glossary/glossary-terms.xml3315(para)#: ./doc/glossary/glossary-terms.xml3321(glossterm)#: ./doc/glossary/glossary-terms.xml3323(primary) #: ./doc/glossary/glossary-terms.xml3418(primary) #: ./doc/glossary/glossary-terms.xml4484(primary) #: ./doc/glossary/glossary-terms.xml6305(primary) #: ./doc/glossary/glossary-terms.xml6494(primary) #: ./doc/glossary/glossary-terms.xml7503(primary) #: ./doc/glossary/glossary-terms.xml7731(primary)#: ./doc/glossary/glossary-terms.xml3325(secondary)#: ./doc/glossary/glossary-terms.xml3328(primary)#: ./doc/glossary/glossary-terms.xml3332(para)#: ./doc/glossary/glossary-terms.xml3340(glossterm) #: ./doc/glossary/glossary-terms.xml3342(primary)#: ./doc/glossary/glossary-terms.xml3346(para)#: ./doc/glossary/glossary-terms.xml3353(glossterm) #: ./doc/glossary/glossary-terms.xml3355(primary)#: ./doc/glossary/glossary-terms.xml3359(para)#: ./doc/glossary/glossary-terms.xml3366(glossterm) #: ./doc/glossary/glossary-terms.xml3368(primary)#: ./doc/glossary/glossary-terms.xml3372(para)#: ./doc/glossary/glossary-terms.xml3381(glossterm) #: ./doc/glossary/glossary-terms.xml3383(primary)#: ./doc/glossary/glossary-terms.xml3387(para)#: ./doc/glossary/glossary-terms.xml3393(glossterm) #: ./doc/glossary/glossary-terms.xml3395(primary)#: ./doc/glossary/glossary-terms.xml3399(para)#: ./doc/glossary/glossary-terms.xml3404(glossterm) #: ./doc/glossary/glossary-terms.xml3406(primary)#: ./doc/glossary/glossary-terms.xml3410(para)#: ./doc/glossary/glossary-terms.xml3416(glossterm) #: ./doc/glossary/glossary-terms.xml3423(primary)#: ./doc/glossary/glossary-terms.xml3420(secondary)#: ./doc/glossary/glossary-terms.xml3427(para)#: ./doc/glossary/glossary-terms.xml3436(glossterm) #: ./doc/glossary/glossary-terms.xml3438(primary)#: ./doc/glossary/glossary-terms.xml3442(para)#: ./doc/glossary/glossary-terms.xml3447(para)#: ./doc/glossary/glossary-terms.xml3455(glossterm) #: ./doc/glossary/glossary-terms.xml3457(primary)#: ./doc/glossary/glossary-terms.xml3461(para)#: ./doc/glossary/glossary-terms.xml3467(glossterm)#: ./doc/glossary/glossary-terms.xml3469(primary)#: ./doc/glossary/glossary-terms.xml3473(para)#: ./doc/glossary/glossary-terms.xml3482(title)#: ./doc/glossary/glossary-terms.xml3485(glossterm) #: ./doc/glossary/glossary-terms.xml3487(primary)#: ./doc/glossary/glossary-terms.xml3491(para)#: ./doc/glossary/glossary-terms.xml3497(glossterm) #: ./doc/glossary/glossary-terms.xml3499(primary)#: ./doc/glossary/glossary-terms.xml3502(para)#: ./doc/glossary/glossary-terms.xml3509(glossterm) #: ./doc/glossary/glossary-terms.xml3511(primary)#: ./doc/glossary/glossary-terms.xml3514(para)#: ./doc/glossary/glossary-terms.xml3521(glossterm) #: ./doc/glossary/glossary-terms.xml3531(primary) #: ./doc/glossary/glossary-terms.xml3546(primary)#: ./doc/glossary/glossary-terms.xml3524(para)#: ./doc/glossary/glossary-terms.xml3529(glossterm) #: ./doc/glossary/glossary-terms.xml3533(secondary)#: ./doc/glossary/glossary-terms.xml3537(para)#: ./doc/glossary/glossary-terms.xml3544(glossterm) #: ./doc/glossary/glossary-terms.xml3548(secondary)#: ./doc/glossary/glossary-terms.xml3552(para)#: ./doc/glossary/glossary-terms.xml3557(glossterm) #: ./doc/glossary/glossary-terms.xml3561(secondary) #: ./doc/glossary/glossary-terms.xml3564(primary)#: ./doc/glossary/glossary-terms.xml3568(para)#: ./doc/glossary/glossary-terms.xml3574(glossterm) #: ./doc/glossary/glossary-terms.xml3576(primary)#: ./doc/glossary/glossary-terms.xml3580(para)#: ./doc/glossary/glossary-terms.xml3586(glossterm) #: ./doc/glossary/glossary-terms.xml3588(primary)#: ./doc/glossary/glossary-terms.xml3592(para)#: ./doc/glossary/glossary-terms.xml3599(glossterm) #: ./doc/glossary/glossary-terms.xml3601(primary)#: ./doc/glossary/glossary-terms.xml3605(para)#: ./doc/glossary/glossary-terms.xml3611(glossterm) #: ./doc/glossary/glossary-terms.xml3613(primary)#: ./doc/glossary/glossary-terms.xml3617(para)#: ./doc/glossary/glossary-terms.xml3623(glossterm) #: ./doc/glossary/glossary-terms.xml3625(primary)#: ./doc/glossary/glossary-terms.xml3629(para)#: ./doc/glossary/glossary-terms.xml3636(glossterm) #: ./doc/glossary/glossary-terms.xml3638(primary)#: ./doc/glossary/glossary-terms.xml3642(para)#: ./doc/glossary/glossary-terms.xml3650(glossterm) #: ./doc/glossary/glossary-terms.xml3652(primary)#: ./doc/glossary/glossary-terms.xml3656(para)#: ./doc/glossary/glossary-terms.xml3665(title)#: ./doc/glossary/glossary-terms.xml3668(glossterm) #: ./doc/glossary/glossary-terms.xml3670(primary)#: ./doc/glossary/glossary-terms.xml3674(para)#: ./doc/glossary/glossary-terms.xml3680(glossterm) #: ./doc/glossary/glossary-terms.xml3682(primary)#: ./doc/glossary/glossary-terms.xml3686(para)#: ./doc/glossary/glossary-terms.xml3692(glossterm) #: ./doc/glossary/glossary-terms.xml3694(primary)#: ./doc/glossary/glossary-terms.xml3698(para)#: ./doc/glossary/glossary-terms.xml3705(glossterm) #: ./doc/glossary/glossary-terms.xml3707(primary)#: ./doc/glossary/glossary-terms.xml3711(para)#: ./doc/glossary/glossary-terms.xml3718(glossterm) #: ./doc/glossary/glossary-terms.xml3720(primary)#: ./doc/glossary/glossary-terms.xml3724(para)#: ./doc/glossary/glossary-terms.xml3730(glossterm) #: ./doc/glossary/glossary-terms.xml3732(primary) #: ./doc/glossary/glossary-terms.xml7705(see)#: ./doc/glossary/glossary-terms.xml3736(para)#: ./doc/glossary/glossary-terms.xml3741(glossterm) #: ./doc/glossary/glossary-terms.xml3743(primary)#: ./doc/glossary/glossary-terms.xml3747(para)#: ./doc/glossary/glossary-terms.xml3757(glossterm) #: ./doc/glossary/glossary-terms.xml3759(primary)#: ./doc/glossary/glossary-terms.xml3763(para)#: ./doc/glossary/glossary-terms.xml3774(glossterm)#: ./doc/glossary/glossary-terms.xml3777(para)#: ./doc/glossary/glossary-terms.xml3783(glossterm)#: ./doc/glossary/glossary-terms.xml3785(primary)#: ./doc/glossary/glossary-terms.xml3789(para)#: ./doc/glossary/glossary-terms.xml3794(glossterm)#: ./doc/glossary/glossary-terms.xml3796(primary)#: ./doc/glossary/glossary-terms.xml3800(para)#: ./doc/glossary/glossary-terms.xml3805(glossterm) #: ./doc/glossary/glossary-terms.xml3807(primary)#: ./doc/glossary/glossary-terms.xml3811(para)#: ./doc/glossary/glossary-terms.xml3817(glossterm) #: ./doc/glossary/glossary-terms.xml3819(primary)#: ./doc/glossary/glossary-terms.xml3823(para)#: ./doc/glossary/glossary-terms.xml3829(glossterm)#: ./doc/glossary/glossary-terms.xml3831(primary)#: ./doc/glossary/glossary-terms.xml3837(para)#: ./doc/glossary/glossary-terms.xml3847(glossterm)#: ./doc/glossary/glossary-terms.xml3849(primary)#: ./doc/glossary/glossary-terms.xml3853(para)#: ./doc/glossary/glossary-terms.xml3864(glossterm) #: ./doc/glossary/glossary-terms.xml3866(primary)#: ./doc/glossary/glossary-terms.xml3870(para)#: ./doc/glossary/glossary-terms.xml3882(glossterm) #: ./doc/glossary/glossary-terms.xml3884(primary)#: ./doc/glossary/glossary-terms.xml3888(para)#: ./doc/glossary/glossary-terms.xml3893(glossterm) #: ./doc/glossary/glossary-terms.xml3895(primary)#: ./doc/glossary/glossary-terms.xml3899(para)#: ./doc/glossary/glossary-terms.xml3906(glossterm)#: ./doc/glossary/glossary-terms.xml3909(para)#: ./doc/glossary/glossary-terms.xml3915(glossterm)#: ./doc/glossary/glossary-terms.xml3918(para)#: ./doc/glossary/glossary-terms.xml3925(glossterm)#: ./doc/glossary/glossary-terms.xml3927(primary) #: ./doc/glossary/glossary-terms.xml3941(primary)#: ./doc/glossary/glossary-terms.xml3933(para)#: ./doc/glossary/glossary-terms.xml3939(glossterm)#: ./doc/glossary/glossary-terms.xml3943(secondary)#: ./doc/glossary/glossary-terms.xml3947(para)#: ./doc/glossary/glossary-terms.xml3956(title)#: ./doc/glossary/glossary-terms.xml3959(glossterm)#: ./doc/glossary/glossary-terms.xml3961(primary)#: ./doc/glossary/glossary-terms.xml3967(para)#: ./doc/glossary/glossary-terms.xml3977(glossterm) #: ./doc/glossary/glossary-terms.xml3979(primary)#: ./doc/glossary/glossary-terms.xml3985(para)#: ./doc/glossary/glossary-terms.xml3992(glossterm)#: ./doc/glossary/glossary-terms.xml3994(primary)#: ./doc/glossary/glossary-terms.xml3998(para)#: ./doc/glossary/glossary-terms.xml4006(glossterm) #: ./doc/glossary/glossary-terms.xml4008(primary)#: ./doc/glossary/glossary-terms.xml4012(para)#: ./doc/glossary/glossary-terms.xml4018(glossterm)#: ./doc/glossary/glossary-terms.xml4021(para)#: ./doc/glossary/glossary-terms.xml4026(glossterm) #: ./doc/glossary/glossary-terms.xml4030(secondary)#: ./doc/glossary/glossary-terms.xml4028(primary) #: ./doc/glossary/glossary-terms.xml4040(glossterm) #: ./doc/glossary/glossary-terms.xml4042(primary) #: ./doc/glossary/glossary-terms.xml4059(primary) #: ./doc/glossary/glossary-terms.xml4130(primary)#: ./doc/glossary/glossary-terms.xml4034(para)#: ./doc/glossary/glossary-terms.xml4048(para)#: ./doc/glossary/glossary-terms.xml4057(glossterm) #: ./doc/glossary/glossary-terms.xml4061(secondary)#: ./doc/glossary/glossary-terms.xml4065(para)#: ./doc/glossary/glossary-terms.xml4071(glossterm)#: ./doc/glossary/glossary-terms.xml4073(primary)#: ./doc/glossary/glossary-terms.xml4077(para)#: ./doc/glossary/glossary-terms.xml4082(glossterm)#: ./doc/glossary/glossary-terms.xml4084(primary)#: ./doc/glossary/glossary-terms.xml4090(para)#: ./doc/glossary/glossary-terms.xml4099(glossterm)#: ./doc/glossary/glossary-terms.xml4101(primary) #: ./doc/glossary/glossary-terms.xml4115(primary) #: ./doc/glossary/glossary-terms.xml4144(primary) #: ./doc/glossary/glossary-terms.xml4158(primary) #: ./doc/glossary/glossary-terms.xml4172(primary) #: ./doc/glossary/glossary-terms.xml4184(glossterm) #: ./doc/glossary/glossary-terms.xml4204(primary) #: ./doc/glossary/glossary-terms.xml4218(primary) #: ./doc/glossary/glossary-terms.xml4232(primary) #: ./doc/glossary/glossary-terms.xml6477(primary)#: ./doc/glossary/glossary-terms.xml4103(secondary) #: ./doc/glossary/glossary-terms.xml4194(glossterm)#: ./doc/glossary/glossary-terms.xml4107(para)#: ./doc/glossary/glossary-terms.xml4113(glossterm) #: ./doc/glossary/glossary-terms.xml4117(secondary)#: ./doc/glossary/glossary-terms.xml4121(para)#: ./doc/glossary/glossary-terms.xml4128(glossterm) #: ./doc/glossary/glossary-terms.xml4132(secondary)#: ./doc/glossary/glossary-terms.xml4136(para)#: ./doc/glossary/glossary-terms.xml4142(glossterm) #: ./doc/glossary/glossary-terms.xml4146(secondary)#: ./doc/glossary/glossary-terms.xml4150(para) #: ./doc/glossary/glossary-terms.xml5095(para)#: ./doc/glossary/glossary-terms.xml4156(glossterm) #: ./doc/glossary/glossary-terms.xml4160(secondary)#: ./doc/glossary/glossary-terms.xml4164(para)#: ./doc/glossary/glossary-terms.xml4170(glossterm) #: ./doc/glossary/glossary-terms.xml4174(secondary)#: ./doc/glossary/glossary-terms.xml4178(para)#: ./doc/glossary/glossary-terms.xml4187(para)#: ./doc/glossary/glossary-terms.xml4197(para)#: ./doc/glossary/glossary-terms.xml4202(glossterm) #: ./doc/glossary/glossary-terms.xml4206(secondary)#: ./doc/glossary/glossary-terms.xml4210(para)#: ./doc/glossary/glossary-terms.xml4216(glossterm) #: ./doc/glossary/glossary-terms.xml4220(secondary)#: ./doc/glossary/glossary-terms.xml4224(para)#: ./doc/glossary/glossary-terms.xml4230(glossterm) #: ./doc/glossary/glossary-terms.xml4234(secondary)#: ./doc/glossary/glossary-terms.xml4238(para)#: ./doc/glossary/glossary-terms.xml4244(glossterm)#: ./doc/glossary/glossary-terms.xml4246(primary)#: ./doc/glossary/glossary-terms.xml4250(para)#: ./doc/glossary/glossary-terms.xml4256(glossterm) #: ./doc/glossary/glossary-terms.xml4260(secondary) #: ./doc/glossary/glossary-terms.xml4263(primary)#: ./doc/glossary/glossary-terms.xml4267(para)#: ./doc/glossary/glossary-terms.xml4273(glossterm) #: ./doc/glossary/glossary-terms.xml4275(primary)#: ./doc/glossary/glossary-terms.xml4278(para)#: ./doc/glossary/glossary-terms.xml4287(glossterm) #: ./doc/glossary/glossary-terms.xml4289(primary)#: ./doc/glossary/glossary-terms.xml4293(para)#: ./doc/glossary/glossary-terms.xml4299(glossterm)#: ./doc/glossary/glossary-terms.xml4301(primary) #: ./doc/glossary/glossary-terms.xml4315(primary) #: ./doc/glossary/glossary-terms.xml4328(primary) #: ./doc/glossary/glossary-terms.xml4352(primary) #: ./doc/glossary/glossary-terms.xml4367(primary) #: ./doc/glossary/glossary-terms.xml4380(primary)#: ./doc/glossary/glossary-terms.xml4307(para)#: ./doc/glossary/glossary-terms.xml4313(glossterm) #: ./doc/glossary/glossary-terms.xml4317(secondary)#: ./doc/glossary/glossary-terms.xml4321(para)#: ./doc/glossary/glossary-terms.xml4326(glossterm) #: ./doc/glossary/glossary-terms.xml4330(secondary)#: ./doc/glossary/glossary-terms.xml4334(para)#: ./doc/glossary/glossary-terms.xml4339(glossterm) #: ./doc/glossary/glossary-terms.xml4341(primary)#: ./doc/glossary/glossary-terms.xml4344(para)#: ./doc/glossary/glossary-terms.xml4350(glossterm) #: ./doc/glossary/glossary-terms.xml4354(secondary)#: ./doc/glossary/glossary-terms.xml4358(para)#: ./doc/glossary/glossary-terms.xml4365(glossterm) #: ./doc/glossary/glossary-terms.xml4369(secondary)#: ./doc/glossary/glossary-terms.xml4373(para)#: ./doc/glossary/glossary-terms.xml4378(glossterm) #: ./doc/glossary/glossary-terms.xml4382(secondary)#: ./doc/glossary/glossary-terms.xml4386(para) #: ./doc/glossary/glossary-terms.xml7378(para)#: ./doc/glossary/glossary-terms.xml4392(glossterm) #: ./doc/glossary/glossary-terms.xml4394(primary)#: ./doc/glossary/glossary-terms.xml4398(para)#: ./doc/glossary/glossary-terms.xml4404(glossterm) #: ./doc/glossary/glossary-terms.xml4406(primary)#: ./doc/glossary/glossary-terms.xml4410(para)#: ./doc/glossary/glossary-terms.xml4416(glossterm) #: ./doc/glossary/glossary-terms.xml4418(primary)#: ./doc/glossary/glossary-terms.xml4422(para)#: ./doc/glossary/glossary-terms.xml4428(glossterm) #: ./doc/glossary/glossary-terms.xml4430(primary)#: ./doc/glossary/glossary-terms.xml4434(para)#: ./doc/glossary/glossary-terms.xml4440(glossterm) #: ./doc/glossary/glossary-terms.xml4442(primary)#: ./doc/glossary/glossary-terms.xml4446(para)#: ./doc/glossary/glossary-terms.xml4452(glossterm) #: ./doc/glossary/glossary-terms.xml4454(primary)#: ./doc/glossary/glossary-terms.xml4458(para)#: ./doc/glossary/glossary-terms.xml4464(glossterm) #: ./doc/glossary/glossary-terms.xml4466(primary)#: ./doc/glossary/glossary-terms.xml4472(para)#: ./doc/glossary/glossary-terms.xml4482(glossterm)#: ./doc/glossary/glossary-terms.xml4490(para)#: ./doc/glossary/glossary-terms.xml4497(glossterm) #: ./doc/glossary/glossary-terms.xml4499(primary)#: ./doc/glossary/glossary-terms.xml4503(para)#: ./doc/glossary/glossary-terms.xml4510(glossterm)#: ./doc/glossary/glossary-terms.xml4512(primary)#: ./doc/glossary/glossary-terms.xml4516(para)#: ./doc/glossary/glossary-terms.xml4521(glossterm)#: ./doc/glossary/glossary-terms.xml4523(primary)#: ./doc/glossary/glossary-terms.xml4527(para)#: ./doc/glossary/glossary-terms.xml4538(glossterm) #: ./doc/glossary/glossary-terms.xml4540(primary)#: ./doc/glossary/glossary-terms.xml4544(para)#: ./doc/glossary/glossary-terms.xml4552(glossterm) #: ./doc/glossary/glossary-terms.xml4554(primary)#: ./doc/glossary/glossary-terms.xml4558(para)#: ./doc/glossary/glossary-terms.xml4566(glossterm) #: ./doc/glossary/glossary-terms.xml4568(primary)#: ./doc/glossary/glossary-terms.xml4572(para)#: ./doc/glossary/glossary-terms.xml4583(glossterm)#: ./doc/glossary/glossary-terms.xml4585(primary)#: ./doc/glossary/glossary-terms.xml4589(para)#: ./doc/glossary/glossary-terms.xml4595(glossterm)#: ./doc/glossary/glossary-terms.xml4597(primary)#: ./doc/glossary/glossary-terms.xml4601(para) #: ./doc/glossary/glossary-terms.xml6575(para) #: ./doc/glossary/glossary-terms.xml8423(para) #: ./doc/glossary/glossary-terms.xml8435(para) #: ./doc/glossary/glossary-terms.xml8643(para)#: ./doc/glossary/glossary-terms.xml4607(glossterm) #: ./doc/glossary/glossary-terms.xml4609(primary)#: ./doc/glossary/glossary-terms.xml4613(para)#: ./doc/glossary/glossary-terms.xml4622(title)#: ./doc/glossary/glossary-terms.xml4625(glossterm) #: ./doc/glossary/glossary-terms.xml4627(primary)#: ./doc/glossary/glossary-terms.xml4631(para)#: ./doc/glossary/glossary-terms.xml4637(glossterm) #: ./doc/glossary/glossary-terms.xml4639(primary)#: ./doc/glossary/glossary-terms.xml4643(para)#: ./doc/glossary/glossary-terms.xml4648(glossterm) #: ./doc/glossary/glossary-terms.xml4650(primary)#: ./doc/glossary/glossary-terms.xml4654(para)#: ./doc/glossary/glossary-terms.xml4659(glossterm) #: ./doc/glossary/glossary-terms.xml4661(primary)#: ./doc/glossary/glossary-terms.xml4665(para)#: ./doc/glossary/glossary-terms.xml4671(glossterm) #: ./doc/glossary/glossary-terms.xml4673(primary)#: ./doc/glossary/glossary-terms.xml4677(para)#: ./doc/glossary/glossary-terms.xml4683(glossterm) #: ./doc/glossary/glossary-terms.xml4685(primary)#: ./doc/glossary/glossary-terms.xml4689(para)#: ./doc/glossary/glossary-terms.xml4699(title)#: ./doc/glossary/glossary-terms.xml4702(glossterm)#: ./doc/glossary/glossary-terms.xml4704(primary)#: ./doc/glossary/glossary-terms.xml4708(para)#: ./doc/glossary/glossary-terms.xml4720(glossterm) #: ./doc/glossary/glossary-terms.xml4722(primary)#: ./doc/glossary/glossary-terms.xml4726(para)#: ./doc/glossary/glossary-terms.xml4731(glossterm) #: ./doc/glossary/glossary-terms.xml4733(primary)#: ./doc/glossary/glossary-terms.xml4737(para)#: ./doc/glossary/glossary-terms.xml4743(glossterm) #: ./doc/glossary/glossary-terms.xml4745(primary)#: ./doc/glossary/glossary-terms.xml4749(para)#: ./doc/glossary/glossary-terms.xml4762(title)#: ./doc/glossary/glossary-terms.xml4765(glossterm) #: ./doc/glossary/glossary-terms.xml4767(primary)#: ./doc/glossary/glossary-terms.xml4771(para)#: ./doc/glossary/glossary-terms.xml4776(glossterm) #: ./doc/glossary/glossary-terms.xml4778(primary)#: ./doc/glossary/glossary-terms.xml4782(para)#: ./doc/glossary/glossary-terms.xml4787(glossterm) #: ./doc/glossary/glossary-terms.xml4789(primary)#: ./doc/glossary/glossary-terms.xml4793(para)#: ./doc/glossary/glossary-terms.xml4803(glossterm) #: ./doc/glossary/glossary-terms.xml4805(primary)#: ./doc/glossary/glossary-terms.xml4809(para)#: ./doc/glossary/glossary-terms.xml4818(glossterm) #: ./doc/glossary/glossary-terms.xml4820(primary)#: ./doc/glossary/glossary-terms.xml4824(para)#: ./doc/glossary/glossary-terms.xml4830(glossterm) #: ./doc/glossary/glossary-terms.xml4832(primary)#: ./doc/glossary/glossary-terms.xml4836(para)#: ./doc/glossary/glossary-terms.xml4842(glossterm) #: ./doc/glossary/glossary-terms.xml4844(primary)#: ./doc/glossary/glossary-terms.xml4848(para)#: ./doc/glossary/glossary-terms.xml4854(glossterm)#: ./doc/glossary/glossary-terms.xml4857(para)#: ./doc/glossary/glossary-terms.xml4863(glossterm)#: ./doc/glossary/glossary-terms.xml4865(primary)#: ./doc/glossary/glossary-terms.xml4867(secondary) #: ./doc/glossary/glossary-terms.xml5935(secondary)#: ./doc/glossary/glossary-terms.xml4871(para)#: ./doc/glossary/glossary-terms.xml4877(glossterm) #: ./doc/glossary/glossary-terms.xml4879(primary)#: ./doc/glossary/glossary-terms.xml4888(glossterm) #: ./doc/glossary/glossary-terms.xml4890(primary)#: ./doc/glossary/glossary-terms.xml4894(para)#: ./doc/glossary/glossary-terms.xml4901(glossterm)#: ./doc/glossary/glossary-terms.xml4904(para)#: ./doc/glossary/glossary-terms.xml4912(glossterm) #: ./doc/glossary/glossary-terms.xml4914(primary)#: ./doc/glossary/glossary-terms.xml4918(para)#: ./doc/glossary/glossary-terms.xml4924(glossterm) #: ./doc/glossary/glossary-terms.xml4927(primary)#: ./doc/glossary/glossary-terms.xml4931(para)#: ./doc/glossary/glossary-terms.xml4937(glossterm) #: ./doc/glossary/glossary-terms.xml4939(primary)#: ./doc/glossary/glossary-terms.xml4943(para)#: ./doc/glossary/glossary-terms.xml4953(title)#: ./doc/glossary/glossary-terms.xml4956(glossterm) #: ./doc/glossary/glossary-terms.xml4958(primary)#: ./doc/glossary/glossary-terms.xml4964(para)#: ./doc/glossary/glossary-terms.xml4969(glossterm) #: ./doc/glossary/glossary-terms.xml4971(primary)#: ./doc/glossary/glossary-terms.xml4975(para)#: ./doc/glossary/glossary-terms.xml4981(glossterm) #: ./doc/glossary/glossary-terms.xml4983(primary)#: ./doc/glossary/glossary-terms.xml4987(para)#: ./doc/glossary/glossary-terms.xml4993(glossterm)#: ./doc/glossary/glossary-terms.xml4995(primary) #: ./doc/glossary/glossary-terms.xml5014(primary)#: ./doc/glossary/glossary-terms.xml5001(para)#: ./doc/glossary/glossary-terms.xml5007(glossterm)#: ./doc/glossary/glossary-terms.xml5011(secondary) #: ./doc/glossary/glossary-terms.xml5016(secondary)#: ./doc/glossary/glossary-terms.xml5020(para)#: ./doc/glossary/glossary-terms.xml5026(glossterm) #: ./doc/glossary/glossary-terms.xml5028(primary)#: ./doc/glossary/glossary-terms.xml5032(para)#: ./doc/glossary/glossary-terms.xml5038(glossterm) #: ./doc/glossary/glossary-terms.xml5040(primary)#: ./doc/glossary/glossary-terms.xml5044(para)#: ./doc/glossary/glossary-terms.xml5050(glossterm) #: ./doc/glossary/glossary-terms.xml5052(primary)#: ./doc/glossary/glossary-terms.xml5056(para)#: ./doc/glossary/glossary-terms.xml5065(glossterm) #: ./doc/glossary/glossary-terms.xml5067(primary)#: ./doc/glossary/glossary-terms.xml5071(para)#: ./doc/glossary/glossary-terms.xml5077(glossterm) #: ./doc/glossary/glossary-terms.xml5079(primary)#: ./doc/glossary/glossary-terms.xml5083(para)#: ./doc/glossary/glossary-terms.xml5089(glossterm)#: ./doc/glossary/glossary-terms.xml5091(primary)#: ./doc/glossary/glossary-terms.xml5101(glossterm) #: ./doc/glossary/glossary-terms.xml5103(primary)#: ./doc/glossary/glossary-terms.xml5107(para)#: ./doc/glossary/glossary-terms.xml5113(glossterm) #: ./doc/glossary/glossary-terms.xml5115(primary)#: ./doc/glossary/glossary-terms.xml5119(para)#: ./doc/glossary/glossary-terms.xml5127(glossterm)#: ./doc/glossary/glossary-terms.xml5129(primary)#: ./doc/glossary/glossary-terms.xml5133(para)#: ./doc/glossary/glossary-terms.xml5139(glossterm) #: ./doc/glossary/glossary-terms.xml5141(primary)#: ./doc/glossary/glossary-terms.xml5145(para)#: ./doc/glossary/glossary-terms.xml5151(glossterm) #: ./doc/glossary/glossary-terms.xml5153(primary)#: ./doc/glossary/glossary-terms.xml5157(para)#: ./doc/glossary/glossary-terms.xml5163(glossterm) #: ./doc/glossary/glossary-terms.xml5165(primary)#: ./doc/glossary/glossary-terms.xml5169(para)#: ./doc/glossary/glossary-terms.xml5175(glossterm) #: ./doc/glossary/glossary-terms.xml5177(primary)#: ./doc/glossary/glossary-terms.xml5181(para)#: ./doc/glossary/glossary-terms.xml5186(glossterm) #: ./doc/glossary/glossary-terms.xml5188(primary)#: ./doc/glossary/glossary-terms.xml5192(para)#: ./doc/glossary/glossary-terms.xml5198(glossterm) #: ./doc/glossary/glossary-terms.xml5200(primary)#: ./doc/glossary/glossary-terms.xml5204(para)#: ./doc/glossary/glossary-terms.xml5212(glossterm)#: ./doc/glossary/glossary-terms.xml5215(para)#: ./doc/glossary/glossary-terms.xml5221(glossterm) #: ./doc/glossary/glossary-terms.xml5224(primary)#: ./doc/glossary/glossary-terms.xml5228(para)#: ./doc/glossary/glossary-terms.xml5234(glossterm) #: ./doc/glossary/glossary-terms.xml5236(primary)#: ./doc/glossary/glossary-terms.xml5240(para)#: ./doc/glossary/glossary-terms.xml5246(glossterm) #: ./doc/glossary/glossary-terms.xml5248(primary)#: ./doc/glossary/glossary-terms.xml5252(para)#: ./doc/glossary/glossary-terms.xml5258(glossterm) #: ./doc/glossary/glossary-terms.xml5260(primary)#: ./doc/glossary/glossary-terms.xml5264(para)#: ./doc/glossary/glossary-terms.xml5271(glossterm) #: ./doc/glossary/glossary-terms.xml5273(primary)#: ./doc/glossary/glossary-terms.xml5277(para)#: ./doc/glossary/glossary-terms.xml5286(title)#: ./doc/glossary/glossary-terms.xml5289(glossterm) #: ./doc/glossary/glossary-terms.xml5291(primary)#: ./doc/glossary/glossary-terms.xml5295(para)#: ./doc/glossary/glossary-terms.xml5303(glossterm) #: ./doc/glossary/glossary-terms.xml5305(primary)#: ./doc/glossary/glossary-terms.xml5309(para)#: ./doc/glossary/glossary-terms.xml5315(glossterm) #: ./doc/glossary/glossary-terms.xml5317(primary)#: ./doc/glossary/glossary-terms.xml5321(para)#: ./doc/glossary/glossary-terms.xml5328(glossterm) #: ./doc/glossary/glossary-terms.xml5330(primary)#: ./doc/glossary/glossary-terms.xml5334(para)#: ./doc/glossary/glossary-terms.xml5341(glossterm)#: ./doc/glossary/glossary-terms.xml5343(primary) #: ./doc/glossary/glossary-terms.xml5359(primary) #: ./doc/glossary/glossary-terms.xml5373(primary) #: ./doc/glossary/glossary-terms.xml5388(primary) #: ./doc/glossary/glossary-terms.xml5402(primary) #: ./doc/glossary/glossary-terms.xml5416(primary) #: ./doc/glossary/glossary-terms.xml5430(primary) #: ./doc/glossary/glossary-terms.xml5443(primary) #: ./doc/glossary/glossary-terms.xml5457(primary) #: ./doc/glossary/glossary-terms.xml5471(primary) #: ./doc/glossary/glossary-terms.xml5485(primary) #: ./doc/glossary/glossary-terms.xml6322(primary) #: ./doc/glossary/glossary-terms.xml6522(primary) #: ./doc/glossary/glossary-terms.xml8470(primary) #: ./doc/glossary/glossary-terms.xml8618(primary)#: ./doc/glossary/glossary-terms.xml5349(para)#: ./doc/glossary/glossary-terms.xml5357(glossterm) #: ./doc/glossary/glossary-terms.xml5361(secondary)#: ./doc/glossary/glossary-terms.xml5365(para)#: ./doc/glossary/glossary-terms.xml5371(glossterm)#: ./doc/glossary/glossary-terms.xml5375(secondary)#: ./doc/glossary/glossary-terms.xml5379(para)#: ./doc/glossary/glossary-terms.xml5386(glossterm) #: ./doc/glossary/glossary-terms.xml5390(secondary)#: ./doc/glossary/glossary-terms.xml5394(para)#: ./doc/glossary/glossary-terms.xml5400(glossterm)#: ./doc/glossary/glossary-terms.xml5404(secondary)#: ./doc/glossary/glossary-terms.xml5408(para)#: ./doc/glossary/glossary-terms.xml5414(glossterm)#: ./doc/glossary/glossary-terms.xml5418(secondary)#: ./doc/glossary/glossary-terms.xml5422(para)#: ./doc/glossary/glossary-terms.xml5428(glossterm)#: ./doc/glossary/glossary-terms.xml5432(secondary)#: ./doc/glossary/glossary-terms.xml5436(para)#: ./doc/glossary/glossary-terms.xml5441(glossterm)#: ./doc/glossary/glossary-terms.xml5445(secondary)#: ./doc/glossary/glossary-terms.xml5449(para)#: ./doc/glossary/glossary-terms.xml5455(glossterm) #: ./doc/glossary/glossary-terms.xml5459(secondary)#: ./doc/glossary/glossary-terms.xml5463(para)#: ./doc/glossary/glossary-terms.xml5469(glossterm) #: ./doc/glossary/glossary-terms.xml5473(secondary)#: ./doc/glossary/glossary-terms.xml5477(para)#: ./doc/glossary/glossary-terms.xml5483(glossterm)#: ./doc/glossary/glossary-terms.xml5487(secondary)#: ./doc/glossary/glossary-terms.xml5491(para)#: ./doc/glossary/glossary-terms.xml5498(glossterm)#: ./doc/glossary/glossary-terms.xml5501(para)#: ./doc/glossary/glossary-terms.xml5508(glossterm) #: ./doc/glossary/glossary-terms.xml5510(primary) #: ./doc/glossary/glossary-terms.xml5533(secondary)#: ./doc/glossary/glossary-terms.xml5514(para)#: ./doc/glossary/glossary-terms.xml5520(glossterm) #: ./doc/glossary/glossary-terms.xml5531(primary) #: ./doc/glossary/glossary-terms.xml5544(primary) #: ./doc/glossary/glossary-terms.xml5558(primary)#: ./doc/glossary/glossary-terms.xml5523(para)#: ./doc/glossary/glossary-terms.xml5529(glossterm)#: ./doc/glossary/glossary-terms.xml5537(para)#: ./doc/glossary/glossary-terms.xml5542(glossterm) #: ./doc/glossary/glossary-terms.xml5546(secondary)#: ./doc/glossary/glossary-terms.xml5550(para)#: ./doc/glossary/glossary-terms.xml5556(glossterm) #: ./doc/glossary/glossary-terms.xml5560(secondary)#: ./doc/glossary/glossary-terms.xml5564(para)#: ./doc/glossary/glossary-terms.xml5571(glossterm) #: ./doc/glossary/glossary-terms.xml5573(primary)#: ./doc/glossary/glossary-terms.xml5577(para)#: ./doc/glossary/glossary-terms.xml5582(glossterm) #: ./doc/glossary/glossary-terms.xml5584(primary)#: ./doc/glossary/glossary-terms.xml5588(para)#: ./doc/glossary/glossary-terms.xml5594(glossterm)#: ./doc/glossary/glossary-terms.xml5596(primary) #: ./doc/glossary/glossary-terms.xml6426(primary) #: ./doc/glossary/glossary-terms.xml7771(primary) #: ./doc/glossary/glossary-terms.xml7971(primary)#: ./doc/glossary/glossary-terms.xml5602(para)#: ./doc/glossary/glossary-terms.xml5607(glossterm)#: ./doc/glossary/glossary-terms.xml5609(primary) #: ./doc/glossary/glossary-terms.xml5626(primary) #: ./doc/glossary/glossary-terms.xml6148(primary) #: ./doc/glossary/glossary-terms.xml8234(primary)#: ./doc/glossary/glossary-terms.xml5611(secondary) #: ./doc/glossary/glossary-terms.xml5614(primary) #: ./doc/glossary/glossary-terms.xml8214(see)#: ./doc/glossary/glossary-terms.xml5618(para)#: ./doc/glossary/glossary-terms.xml5624(glossterm) #: ./doc/glossary/glossary-terms.xml5631(primary)#: ./doc/glossary/glossary-terms.xml5628(secondary)#: ./doc/glossary/glossary-terms.xml5635(para)#: ./doc/glossary/glossary-terms.xml5641(glossterm) #: ./doc/glossary/glossary-terms.xml5643(primary)#: ./doc/glossary/glossary-terms.xml5649(para)#: ./doc/glossary/glossary-terms.xml5654(glossterm) #: ./doc/glossary/glossary-terms.xml5656(primary)#: ./doc/glossary/glossary-terms.xml5660(para)#: ./doc/glossary/glossary-terms.xml5668(glossterm) #: ./doc/glossary/glossary-terms.xml5678(primary) #: ./doc/glossary/glossary-terms.xml5691(primary)#: ./doc/glossary/glossary-terms.xml5671(para)#: ./doc/glossary/glossary-terms.xml5676(glossterm)#: ./doc/glossary/glossary-terms.xml5684(para)#: ./doc/glossary/glossary-terms.xml5689(glossterm) #: ./doc/glossary/glossary-terms.xml5693(secondary)#: ./doc/glossary/glossary-terms.xml5697(para)#: ./doc/glossary/glossary-terms.xml5707(title)#: ./doc/glossary/glossary-terms.xml5710(glossterm)#: ./doc/glossary/glossary-terms.xml5718(para)#: ./doc/glossary/glossary-terms.xml5724(glossterm)#: ./doc/glossary/glossary-terms.xml5728(secondary)#: ./doc/glossary/glossary-terms.xml5732(para)#: ./doc/glossary/glossary-terms.xml5738(glossterm) #: ./doc/glossary/glossary-terms.xml5742(secondary)#: ./doc/glossary/glossary-terms.xml5746(para)#: ./doc/glossary/glossary-terms.xml5753(glossterm) #: ./doc/glossary/glossary-terms.xml5757(secondary)#: ./doc/glossary/glossary-terms.xml5761(para)#: ./doc/glossary/glossary-terms.xml5766(glossterm) #: ./doc/glossary/glossary-terms.xml5770(secondary)#: ./doc/glossary/glossary-terms.xml5774(para)#: ./doc/glossary/glossary-terms.xml5780(glossterm)#: ./doc/glossary/glossary-terms.xml5784(secondary)#: ./doc/glossary/glossary-terms.xml5788(para)#: ./doc/glossary/glossary-terms.xml5794(glossterm)#: ./doc/glossary/glossary-terms.xml5798(secondary)#: ./doc/glossary/glossary-terms.xml5802(para)#: ./doc/glossary/glossary-terms.xml5808(glossterm) #: ./doc/glossary/glossary-terms.xml5825(primary) #: ./doc/glossary/glossary-terms.xml5838(primary)#: ./doc/glossary/glossary-terms.xml5811(para)#: ./doc/glossary/glossary-terms.xml5818(glossterm) #: ./doc/glossary/glossary-terms.xml5822(secondary) #: ./doc/glossary/glossary-terms.xml5827(secondary)#: ./doc/glossary/glossary-terms.xml5820(primary) #: ./doc/glossary/glossary-terms.xml7915(glossterm) #: ./doc/glossary/glossary-terms.xml7938(primary) #: ./doc/glossary/glossary-terms.xml7952(primary) #: ./doc/glossary/glossary-terms.xml7976(primary)#: ./doc/glossary/glossary-terms.xml5831(para)#: ./doc/glossary/glossary-terms.xml5836(glossterm) #: ./doc/glossary/glossary-terms.xml5840(secondary)#: ./doc/glossary/glossary-terms.xml5844(para)#: ./doc/glossary/glossary-terms.xml5849(glossterm) #: ./doc/glossary/glossary-terms.xml5853(secondary)#: ./doc/glossary/glossary-terms.xml5857(para)#: ./doc/glossary/glossary-terms.xml5863(glossterm) #: ./doc/glossary/glossary-terms.xml5865(primary)#: ./doc/glossary/glossary-terms.xml5869(para)#: ./doc/glossary/glossary-terms.xml5875(glossterm) #: ./doc/glossary/glossary-terms.xml5878(primary)#: ./doc/glossary/glossary-terms.xml5882(para)#: ./doc/glossary/glossary-terms.xml5888(glossterm) #: ./doc/glossary/glossary-terms.xml5890(primary)#: ./doc/glossary/glossary-terms.xml5894(para)#: ./doc/glossary/glossary-terms.xml5899(glossterm) #: ./doc/glossary/glossary-terms.xml5901(primary) #: ./doc/glossary/glossary-terms.xml5933(primary)#: ./doc/glossary/glossary-terms.xml5905(para)#: ./doc/glossary/glossary-terms.xml5917(glossterm) #: ./doc/glossary/glossary-terms.xml5919(primary)#: ./doc/glossary/glossary-terms.xml5923(para)#: ./doc/glossary/glossary-terms.xml5931(glossterm)#: ./doc/glossary/glossary-terms.xml5939(para)#: ./doc/glossary/glossary-terms.xml5944(glossterm) #: ./doc/glossary/glossary-terms.xml5946(primary)#: ./doc/glossary/glossary-terms.xml5950(para)#: ./doc/glossary/glossary-terms.xml5956(glossterm) #: ./doc/glossary/glossary-terms.xml5958(primary) #: ./doc/glossary/glossary-terms.xml5976(primary)#: ./doc/glossary/glossary-terms.xml5964(para)#: ./doc/glossary/glossary-terms.xml5974(glossterm)#: ./doc/glossary/glossary-terms.xml5977(secondary)#: ./doc/glossary/glossary-terms.xml5981(para)#: ./doc/glossary/glossary-terms.xml5995(glossterm) #: ./doc/glossary/glossary-terms.xml5997(primary)#: ./doc/glossary/glossary-terms.xml6006(glossterm) #: ./doc/glossary/glossary-terms.xml6008(primary)#: ./doc/glossary/glossary-terms.xml6012(para)#: ./doc/glossary/glossary-terms.xml6018(glossterm) #: ./doc/glossary/glossary-terms.xml6020(primary)#: ./doc/glossary/glossary-terms.xml6024(para)#: ./doc/glossary/glossary-terms.xml6031(glossterm)#: ./doc/glossary/glossary-terms.xml6033(primary)#: ./doc/glossary/glossary-terms.xml6037(para)#: ./doc/glossary/glossary-terms.xml6046(title)#: ./doc/glossary/glossary-terms.xml6049(glossterm)#: ./doc/glossary/glossary-terms.xml6053(secondary) #: ./doc/glossary/glossary-terms.xml6056(primary)#: ./doc/glossary/glossary-terms.xml6060(para)#: ./doc/glossary/glossary-terms.xml6067(glossterm)#: ./doc/glossary/glossary-terms.xml6069(primary) #: ./doc/glossary/glossary-terms.xml6084(primary) #: ./doc/glossary/glossary-terms.xml6098(primary)#: ./doc/glossary/glossary-terms.xml6075(para)#: ./doc/glossary/glossary-terms.xml6082(glossterm) #: ./doc/glossary/glossary-terms.xml6086(secondary)#: ./doc/glossary/glossary-terms.xml6090(para)#: ./doc/glossary/glossary-terms.xml6096(glossterm)#: ./doc/glossary/glossary-terms.xml6100(secondary)#: ./doc/glossary/glossary-terms.xml6104(para)#: ./doc/glossary/glossary-terms.xml6110(glossterm) #: ./doc/glossary/glossary-terms.xml6112(primary)#: ./doc/glossary/glossary-terms.xml6116(para)#: ./doc/glossary/glossary-terms.xml6122(glossterm) #: ./doc/glossary/glossary-terms.xml6124(primary)#: ./doc/glossary/glossary-terms.xml6128(para)#: ./doc/glossary/glossary-terms.xml6134(glossterm) #: ./doc/glossary/glossary-terms.xml6136(primary)#: ./doc/glossary/glossary-terms.xml6140(para)#: ./doc/glossary/glossary-terms.xml6146(glossterm)#: ./doc/glossary/glossary-terms.xml6150(secondary) #: ./doc/glossary/glossary-terms.xml6153(primary)#: ./doc/glossary/glossary-terms.xml6157(para)#: ./doc/glossary/glossary-terms.xml6163(glossterm) #: ./doc/glossary/glossary-terms.xml6165(primary)#: ./doc/glossary/glossary-terms.xml6169(para)#: ./doc/glossary/glossary-terms.xml6174(glossterm) #: ./doc/glossary/glossary-terms.xml6176(primary)#: ./doc/glossary/glossary-terms.xml6180(para)#: ./doc/glossary/glossary-terms.xml6186(glossterm) #: ./doc/glossary/glossary-terms.xml6188(primary)#: ./doc/glossary/glossary-terms.xml6192(para)#: ./doc/glossary/glossary-terms.xml6201(glossterm)#: ./doc/glossary/glossary-terms.xml6203(primary)#: ./doc/glossary/glossary-terms.xml6207(para)#: ./doc/glossary/glossary-terms.xml6213(glossterm) #: ./doc/glossary/glossary-terms.xml6215(primary)#: ./doc/glossary/glossary-terms.xml6219(para)#: ./doc/glossary/glossary-terms.xml6225(glossterm) #: ./doc/glossary/glossary-terms.xml6227(primary)#: ./doc/glossary/glossary-terms.xml6231(para)#: ./doc/glossary/glossary-terms.xml6240(glossterm) #: ./doc/glossary/glossary-terms.xml6242(primary)#: ./doc/glossary/glossary-terms.xml6246(para)#: ./doc/glossary/glossary-terms.xml6252(glossterm)#: ./doc/glossary/glossary-terms.xml6254(primary) #: ./doc/glossary/glossary-terms.xml6268(primary) #: ./doc/glossary/glossary-terms.xml8526(primary)#: ./doc/glossary/glossary-terms.xml6260(para)#: ./doc/glossary/glossary-terms.xml6266(glossterm) #: ./doc/glossary/glossary-terms.xml6270(secondary)#: ./doc/glossary/glossary-terms.xml6274(para)#: ./doc/glossary/glossary-terms.xml6279(glossterm)#: ./doc/glossary/glossary-terms.xml6281(primary)#: ./doc/glossary/glossary-terms.xml6285(para)#: ./doc/glossary/glossary-terms.xml6291(glossterm) #: ./doc/glossary/glossary-terms.xml6293(primary)#: ./doc/glossary/glossary-terms.xml6297(para)#: ./doc/glossary/glossary-terms.xml6303(glossterm) #: ./doc/glossary/glossary-terms.xml6310(primary)#: ./doc/glossary/glossary-terms.xml6307(secondary)#: ./doc/glossary/glossary-terms.xml6314(para)#: ./doc/glossary/glossary-terms.xml6320(glossterm)#: ./doc/glossary/glossary-terms.xml6324(secondary) #: ./doc/glossary/glossary-terms.xml6327(primary)#: ./doc/glossary/glossary-terms.xml6331(para)#: ./doc/glossary/glossary-terms.xml6343(glossterm)#: ./doc/glossary/glossary-terms.xml6345(primary) #: ./doc/glossary/glossary-terms.xml6359(primary) #: ./doc/glossary/glossary-terms.xml6373(primary)#: ./doc/glossary/glossary-terms.xml6351(para)#: ./doc/glossary/glossary-terms.xml6357(glossterm) #: ./doc/glossary/glossary-terms.xml6361(secondary)#: ./doc/glossary/glossary-terms.xml6365(para)#: ./doc/glossary/glossary-terms.xml6371(glossterm) #: ./doc/glossary/glossary-terms.xml6375(secondary)#: ./doc/glossary/glossary-terms.xml6379(para)#: ./doc/glossary/glossary-terms.xml6384(glossterm) #: ./doc/glossary/glossary-terms.xml6386(primary)#: ./doc/glossary/glossary-terms.xml6390(para)#: ./doc/glossary/glossary-terms.xml6397(glossterm) #: ./doc/glossary/glossary-terms.xml6399(primary)#: ./doc/glossary/glossary-terms.xml6403(para)#: ./doc/glossary/glossary-terms.xml6412(glossterm) #: ./doc/glossary/glossary-terms.xml6414(primary)#: ./doc/glossary/glossary-terms.xml6418(para)#: ./doc/glossary/glossary-terms.xml6424(glossterm)#: ./doc/glossary/glossary-terms.xml6428(secondary) #: ./doc/glossary/glossary-terms.xml6431(primary)#: ./doc/glossary/glossary-terms.xml6435(para)#: ./doc/glossary/glossary-terms.xml6440(glossterm)#: ./doc/glossary/glossary-terms.xml6444(secondary) #: ./doc/glossary/glossary-terms.xml6447(primary)#: ./doc/glossary/glossary-terms.xml6451(para)#: ./doc/glossary/glossary-terms.xml6458(glossterm) #: ./doc/glossary/glossary-terms.xml6465(primary)#: ./doc/glossary/glossary-terms.xml6462(secondary)#: ./doc/glossary/glossary-terms.xml6469(para)#: ./doc/glossary/glossary-terms.xml6475(glossterm) #: ./doc/glossary/glossary-terms.xml6482(primary)#: ./doc/glossary/glossary-terms.xml6479(secondary)#: ./doc/glossary/glossary-terms.xml6486(para)#: ./doc/glossary/glossary-terms.xml6492(glossterm) #: ./doc/glossary/glossary-terms.xml6499(primary)#: ./doc/glossary/glossary-terms.xml6496(secondary) #: ./doc/glossary/glossary-terms.xml6524(secondary)#: ./doc/glossary/glossary-terms.xml6503(para)#: ./doc/glossary/glossary-terms.xml6508(glossterm) #: ./doc/glossary/glossary-terms.xml6510(primary)#: ./doc/glossary/glossary-terms.xml6514(para)#: ./doc/glossary/glossary-terms.xml6520(glossterm) #: ./doc/glossary/glossary-terms.xml6527(primary)#: ./doc/glossary/glossary-terms.xml6531(para)#: ./doc/glossary/glossary-terms.xml6540(glossterm) #: ./doc/glossary/glossary-terms.xml6542(primary)#: ./doc/glossary/glossary-terms.xml6546(para)#: ./doc/glossary/glossary-terms.xml6552(glossterm) #: ./doc/glossary/glossary-terms.xml6554(primary)#: ./doc/glossary/glossary-terms.xml6558(para)#: ./doc/glossary/glossary-terms.xml6566(title)#: ./doc/glossary/glossary-terms.xml6569(glossterm) #: ./doc/glossary/glossary-terms.xml6571(primary)#: ./doc/glossary/glossary-terms.xml6581(glossterm) #: ./doc/glossary/glossary-terms.xml6583(primary)#: ./doc/glossary/glossary-terms.xml6587(para)#: ./doc/glossary/glossary-terms.xml6593(glossterm) #: ./doc/glossary/glossary-terms.xml6595(primary)#: ./doc/glossary/glossary-terms.xml6599(para)#: ./doc/glossary/glossary-terms.xml6606(glossterm) #: ./doc/glossary/glossary-terms.xml6608(primary)#: ./doc/glossary/glossary-terms.xml6612(para)#: ./doc/glossary/glossary-terms.xml6615(para)#: ./doc/glossary/glossary-terms.xml6621(glossterm)#: ./doc/glossary/glossary-terms.xml6623(primary)#: ./doc/glossary/glossary-terms.xml6627(para)#: ./doc/glossary/glossary-terms.xml6636(title)#: ./doc/glossary/glossary-terms.xml6639(glossterm) #: ./doc/glossary/glossary-terms.xml6641(primary)#: ./doc/glossary/glossary-terms.xml6645(para)#: ./doc/glossary/glossary-terms.xml6650(glossterm) #: ./doc/glossary/glossary-terms.xml6652(primary)#: ./doc/glossary/glossary-terms.xml6656(para)#: ./doc/glossary/glossary-terms.xml6662(glossterm) #: ./doc/glossary/glossary-terms.xml6664(primary)#: ./doc/glossary/glossary-terms.xml6668(para)#: ./doc/glossary/glossary-terms.xml6674(glossterm) #: ./doc/glossary/glossary-terms.xml6676(primary)#: ./doc/glossary/glossary-terms.xml6680(para)#: ./doc/glossary/glossary-terms.xml6687(glossterm) #: ./doc/glossary/glossary-terms.xml6689(primary)#: ./doc/glossary/glossary-terms.xml6693(para)#: ./doc/glossary/glossary-terms.xml6699(glossterm) #: ./doc/glossary/glossary-terms.xml6701(primary)#: ./doc/glossary/glossary-terms.xml6705(para)#: ./doc/glossary/glossary-terms.xml6713(glossterm)#: ./doc/glossary/glossary-terms.xml6715(primary)#: ./doc/glossary/glossary-terms.xml6719(para)#: ./doc/glossary/glossary-terms.xml6725(glossterm)#: ./doc/glossary/glossary-terms.xml6727(primary)#: ./doc/glossary/glossary-terms.xml6731(para)#: ./doc/glossary/glossary-terms.xml6737(glossterm)#: ./doc/glossary/glossary-terms.xml6739(primary)#: ./doc/glossary/glossary-terms.xml6743(para)#: ./doc/glossary/glossary-terms.xml6750(glossterm) #: ./doc/glossary/glossary-terms.xml6752(primary) #: ./doc/glossary/glossary-terms.xml7621(primary)#: ./doc/glossary/glossary-terms.xml6754(secondary) #: ./doc/glossary/glossary-terms.xml7623(secondary)#: ./doc/glossary/glossary-terms.xml6758(para)#: ./doc/glossary/glossary-terms.xml6768(glossterm)#: ./doc/glossary/glossary-terms.xml6770(primary)#: ./doc/glossary/glossary-terms.xml6774(para)#: ./doc/glossary/glossary-terms.xml6780(glossterm) #: ./doc/glossary/glossary-terms.xml6782(primary)#: ./doc/glossary/glossary-terms.xml6786(para)#: ./doc/glossary/glossary-terms.xml6791(glossterm)#: ./doc/glossary/glossary-terms.xml6793(primary) #: ./doc/glossary/glossary-terms.xml6812(primary)#: ./doc/glossary/glossary-terms.xml6799(para)#: ./doc/glossary/glossary-terms.xml6810(glossterm)#: ./doc/glossary/glossary-terms.xml6814(secondary)#: ./doc/glossary/glossary-terms.xml6818(para)#: ./doc/glossary/glossary-terms.xml6824(glossterm) #: ./doc/glossary/glossary-terms.xml6826(primary)#: ./doc/glossary/glossary-terms.xml6835(glossterm) #: ./doc/glossary/glossary-terms.xml6837(primary)#: ./doc/glossary/glossary-terms.xml6841(para)#: ./doc/glossary/glossary-terms.xml6846(glossterm) #: ./doc/glossary/glossary-terms.xml6848(primary)#: ./doc/glossary/glossary-terms.xml6852(para)#: ./doc/glossary/glossary-terms.xml6859(glossterm) #: ./doc/glossary/glossary-terms.xml6861(primary)#: ./doc/glossary/glossary-terms.xml6863(see)#: ./doc/glossary/glossary-terms.xml6867(para)#: ./doc/glossary/glossary-terms.xml6872(glossterm)#: ./doc/glossary/glossary-terms.xml6876(secondary) #: ./doc/glossary/glossary-terms.xml6879(primary)#: ./doc/glossary/glossary-terms.xml6883(para)#: ./doc/glossary/glossary-terms.xml6889(glossterm) #: ./doc/glossary/glossary-terms.xml6892(primary)#: ./doc/glossary/glossary-terms.xml6897(para)#: ./doc/glossary/glossary-terms.xml6903(glossterm) #: ./doc/glossary/glossary-terms.xml6905(primary)#: ./doc/glossary/glossary-terms.xml6909(para)#: ./doc/glossary/glossary-terms.xml6915(glossterm)#: ./doc/glossary/glossary-terms.xml6917(primary) #: ./doc/glossary/glossary-terms.xml6932(primary) #: ./doc/glossary/glossary-terms.xml6944(glossterm) #: ./doc/glossary/glossary-terms.xml6955(primary)#: ./doc/glossary/glossary-terms.xml6923(para)#: ./doc/glossary/glossary-terms.xml6930(glossterm) #: ./doc/glossary/glossary-terms.xml6934(secondary)#: ./doc/glossary/glossary-terms.xml6938(para)#: ./doc/glossary/glossary-terms.xml6947(para)#: ./doc/glossary/glossary-terms.xml6953(glossterm)#: ./doc/glossary/glossary-terms.xml6957(secondary)#: ./doc/glossary/glossary-terms.xml6961(para)#: ./doc/glossary/glossary-terms.xml6967(glossterm)#: ./doc/glossary/glossary-terms.xml6969(primary)#: ./doc/glossary/glossary-terms.xml6973(para)#: ./doc/glossary/glossary-terms.xml6978(glossterm)#: ./doc/glossary/glossary-terms.xml6980(primary)#: ./doc/glossary/glossary-terms.xml6984(para)#: ./doc/glossary/glossary-terms.xml6991(glossterm)#: ./doc/glossary/glossary-terms.xml6993(primary)#: ./doc/glossary/glossary-terms.xml6997(para)#: ./doc/glossary/glossary-terms.xml7005(glossterm)#: ./doc/glossary/glossary-terms.xml7007(primary)#: ./doc/glossary/glossary-terms.xml7011(para)#: ./doc/glossary/glossary-terms.xml7018(glossterm)#: ./doc/glossary/glossary-terms.xml7020(primary) #: ./doc/glossary/glossary-terms.xml7035(primary)#: ./doc/glossary/glossary-terms.xml7026(para)#: ./doc/glossary/glossary-terms.xml7033(glossterm)#: ./doc/glossary/glossary-terms.xml7037(secondary)#: ./doc/glossary/glossary-terms.xml7041(para)#: ./doc/glossary/glossary-terms.xml7048(glossterm) #: ./doc/glossary/glossary-terms.xml7050(primary)#: ./doc/glossary/glossary-terms.xml7054(para)#: ./doc/glossary/glossary-terms.xml7062(glossterm)#: ./doc/glossary/glossary-terms.xml7064(primary) #: ./doc/glossary/glossary-terms.xml7079(primary)#: ./doc/glossary/glossary-terms.xml7070(para)#: ./doc/glossary/glossary-terms.xml7077(glossterm) #: ./doc/glossary/glossary-terms.xml7081(secondary)#: ./doc/glossary/glossary-terms.xml7085(para)#: ./doc/glossary/glossary-terms.xml7090(glossterm) #: ./doc/glossary/glossary-terms.xml7092(primary)#: ./doc/glossary/glossary-terms.xml7096(para)#: ./doc/glossary/glossary-terms.xml7102(glossterm) #: ./doc/glossary/glossary-terms.xml7109(primary)#: ./doc/glossary/glossary-terms.xml7104(primary) #: ./doc/glossary/glossary-terms.xml7664(primary)#: ./doc/glossary/glossary-terms.xml7106(secondary)#: ./doc/glossary/glossary-terms.xml7113(para)#: ./doc/glossary/glossary-terms.xml7119(glossterm) #: ./doc/glossary/glossary-terms.xml7121(primary)#: ./doc/glossary/glossary-terms.xml7125(para)#: ./doc/glossary/glossary-terms.xml7131(glossterm)#: ./doc/glossary/glossary-terms.xml7133(primary)#: ./doc/glossary/glossary-terms.xml7137(para)#: ./doc/glossary/glossary-terms.xml7144(glossterm)#: ./doc/glossary/glossary-terms.xml7146(primary)#: ./doc/glossary/glossary-terms.xml7148(secondary) #: ./doc/glossary/glossary-terms.xml7151(primary)#: ./doc/glossary/glossary-terms.xml7155(para)#: ./doc/glossary/glossary-terms.xml7162(glossterm) #: ./doc/glossary/glossary-terms.xml7164(primary)#: ./doc/glossary/glossary-terms.xml7168(para)#: ./doc/glossary/glossary-terms.xml7173(glossterm)#: ./doc/glossary/glossary-terms.xml7175(primary)#: ./doc/glossary/glossary-terms.xml7179(para)#: ./doc/glossary/glossary-terms.xml7185(glossterm)#: ./doc/glossary/glossary-terms.xml7188(para)#: ./doc/glossary/glossary-terms.xml7194(glossterm) #: ./doc/glossary/glossary-terms.xml7196(primary)#: ./doc/glossary/glossary-terms.xml7200(para)#: ./doc/glossary/glossary-terms.xml7209(title)#: ./doc/glossary/glossary-terms.xml7212(glossterm)#: ./doc/glossary/glossary-terms.xml7214(primary)#: ./doc/glossary/glossary-terms.xml7218(para)#: ./doc/glossary/glossary-terms.xml7225(glossterm) #: ./doc/glossary/glossary-terms.xml7227(primary)#: ./doc/glossary/glossary-terms.xml7231(para)#: ./doc/glossary/glossary-terms.xml7237(glossterm) #: ./doc/glossary/glossary-terms.xml7239(primary)#: ./doc/glossary/glossary-terms.xml7243(para)#: ./doc/glossary/glossary-terms.xml7250(glossterm)#: ./doc/glossary/glossary-terms.xml7252(primary)#: ./doc/glossary/glossary-terms.xml7256(para)#: ./doc/glossary/glossary-terms.xml7262(glossterm)#: ./doc/glossary/glossary-terms.xml7264(primary)#: ./doc/glossary/glossary-terms.xml7268(para)#: ./doc/glossary/glossary-terms.xml7274(glossterm)#: ./doc/glossary/glossary-terms.xml7276(primary)#: ./doc/glossary/glossary-terms.xml7280(para)#: ./doc/glossary/glossary-terms.xml7286(glossterm) #: ./doc/glossary/glossary-terms.xml7288(primary)#: ./doc/glossary/glossary-terms.xml7292(para)#: ./doc/glossary/glossary-terms.xml7299(glossterm)#: ./doc/glossary/glossary-terms.xml7301(primary)#: ./doc/glossary/glossary-terms.xml7305(para)#: ./doc/glossary/glossary-terms.xml7311(glossterm)#: ./doc/glossary/glossary-terms.xml7315(secondary) #: ./doc/glossary/glossary-terms.xml7318(primary)#: ./doc/glossary/glossary-terms.xml7322(para)#: ./doc/glossary/glossary-terms.xml7329(glossterm) #: ./doc/glossary/glossary-terms.xml7331(primary)#: ./doc/glossary/glossary-terms.xml7335(para)#: ./doc/glossary/glossary-terms.xml7341(glossterm)#: ./doc/glossary/glossary-terms.xml7349(para)#: ./doc/glossary/glossary-terms.xml7353(para)#: ./doc/glossary/glossary-terms.xml7359(glossterm) #: ./doc/glossary/glossary-terms.xml7361(primary)#: ./doc/glossary/glossary-terms.xml7365(para)#: ./doc/glossary/glossary-terms.xml7370(glossterm) #: ./doc/glossary/glossary-terms.xml7374(secondary)#: ./doc/glossary/glossary-terms.xml7384(glossterm)#: ./doc/glossary/glossary-terms.xml7386(primary)#: ./doc/glossary/glossary-terms.xml7392(para)#: ./doc/glossary/glossary-terms.xml7399(glossterm) #: ./doc/glossary/glossary-terms.xml7401(primary)#: ./doc/glossary/glossary-terms.xml7405(para)#: ./doc/glossary/glossary-terms.xml7410(glossterm) #: ./doc/glossary/glossary-terms.xml7412(primary)#: ./doc/glossary/glossary-terms.xml7416(para)#: ./doc/glossary/glossary-terms.xml7422(glossterm) #: ./doc/glossary/glossary-terms.xml7424(primary)#: ./doc/glossary/glossary-terms.xml7428(para)#: ./doc/glossary/glossary-terms.xml7434(glossterm) #: ./doc/glossary/glossary-terms.xml7436(primary)#: ./doc/glossary/glossary-terms.xml7440(para)#: ./doc/glossary/glossary-terms.xml7446(glossterm) #: ./doc/glossary/glossary-terms.xml7448(primary)#: ./doc/glossary/glossary-terms.xml7452(para)#: ./doc/glossary/glossary-terms.xml7458(glossterm) #: ./doc/glossary/glossary-terms.xml7462(secondary)#: ./doc/glossary/glossary-terms.xml7460(primary) #: ./doc/glossary/glossary-terms.xml7474(primary) #: ./doc/glossary/glossary-terms.xml7489(primary)#: ./doc/glossary/glossary-terms.xml7466(para)#: ./doc/glossary/glossary-terms.xml7472(glossterm) #: ./doc/glossary/glossary-terms.xml7476(secondary)#: ./doc/glossary/glossary-terms.xml7480(para)#: ./doc/glossary/glossary-terms.xml7487(glossterm) #: ./doc/glossary/glossary-terms.xml7491(secondary)#: ./doc/glossary/glossary-terms.xml7495(para)#: ./doc/glossary/glossary-terms.xml7501(glossterm) #: ./doc/glossary/glossary-terms.xml7508(primary)#: ./doc/glossary/glossary-terms.xml7505(secondary)#: ./doc/glossary/glossary-terms.xml7512(para)#: ./doc/glossary/glossary-terms.xml7525(glossterm)#: ./doc/glossary/glossary-terms.xml7527(primary)#: ./doc/glossary/glossary-terms.xml7531(para)#: ./doc/glossary/glossary-terms.xml7540(glossterm) #: ./doc/glossary/glossary-terms.xml7542(primary)#: ./doc/glossary/glossary-terms.xml7546(para)#: ./doc/glossary/glossary-terms.xml7552(glossterm) #: ./doc/glossary/glossary-terms.xml7554(primary)#: ./doc/glossary/glossary-terms.xml7558(para)#: ./doc/glossary/glossary-terms.xml7564(glossterm) #: ./doc/glossary/glossary-terms.xml7567(primary)#: ./doc/glossary/glossary-terms.xml7571(para)#: ./doc/glossary/glossary-terms.xml7577(glossterm) #: ./doc/glossary/glossary-terms.xml7580(primary)#: ./doc/glossary/glossary-terms.xml7584(para)#: ./doc/glossary/glossary-terms.xml7594(glossterm) #: ./doc/glossary/glossary-terms.xml7596(primary)#: ./doc/glossary/glossary-terms.xml7600(para)#: ./doc/glossary/glossary-terms.xml7606(glossterm) #: ./doc/glossary/glossary-terms.xml7608(primary)#: ./doc/glossary/glossary-terms.xml7612(para)#: ./doc/glossary/glossary-terms.xml7619(glossterm) #: ./doc/glossary/glossary-terms.xml7626(primary)#: ./doc/glossary/glossary-terms.xml7630(para)#: ./doc/glossary/glossary-terms.xml7636(glossterm) #: ./doc/glossary/glossary-terms.xml7638(primary)#: ./doc/glossary/glossary-terms.xml7642(para)#: ./doc/glossary/glossary-terms.xml7648(glossterm)#: ./doc/glossary/glossary-terms.xml7650(primary)#: ./doc/glossary/glossary-terms.xml7655(para)#: ./doc/glossary/glossary-terms.xml7662(glossterm) #: ./doc/glossary/glossary-terms.xml7669(primary)#: ./doc/glossary/glossary-terms.xml7666(secondary)#: ./doc/glossary/glossary-terms.xml7673(para)#: ./doc/glossary/glossary-terms.xml7679(glossterm) #: ./doc/glossary/glossary-terms.xml7681(primary)#: ./doc/glossary/glossary-terms.xml7685(para)#: ./doc/glossary/glossary-terms.xml7690(glossterm) #: ./doc/glossary/glossary-terms.xml7692(primary)#: ./doc/glossary/glossary-terms.xml7696(para)#: ./doc/glossary/glossary-terms.xml7702(glossterm) #: ./doc/glossary/glossary-terms.xml7704(primary)#: ./doc/glossary/glossary-terms.xml7709(para)#: ./doc/glossary/glossary-terms.xml7717(glossterm) #: ./doc/glossary/glossary-terms.xml7719(primary)#: ./doc/glossary/glossary-terms.xml7723(para)#: ./doc/glossary/glossary-terms.xml7729(glossterm)#: ./doc/glossary/glossary-terms.xml7733(secondary)#: ./doc/glossary/glossary-terms.xml7736(primary)#: ./doc/glossary/glossary-terms.xml7740(para)#: ./doc/glossary/glossary-terms.xml7745(glossterm) #: ./doc/glossary/glossary-terms.xml7747(primary)#: ./doc/glossary/glossary-terms.xml7751(para)#: ./doc/glossary/glossary-terms.xml7757(glossterm) #: ./doc/glossary/glossary-terms.xml7759(primary)#: ./doc/glossary/glossary-terms.xml7763(para)#: ./doc/glossary/glossary-terms.xml7769(glossterm) #: ./doc/glossary/glossary-terms.xml7776(primary)#: ./doc/glossary/glossary-terms.xml7773(secondary)#: ./doc/glossary/glossary-terms.xml7780(para)#: ./doc/glossary/glossary-terms.xml7787(glossterm) #: ./doc/glossary/glossary-terms.xml7791(secondary)#: ./doc/glossary/glossary-terms.xml7789(primary) #: ./doc/glossary/glossary-terms.xml7803(primary) #: ./doc/glossary/glossary-terms.xml7817(primary) #: ./doc/glossary/glossary-terms.xml7966(primary)#: ./doc/glossary/glossary-terms.xml7795(para)#: ./doc/glossary/glossary-terms.xml7801(glossterm) #: ./doc/glossary/glossary-terms.xml7805(secondary)#: ./doc/glossary/glossary-terms.xml7809(para)#: ./doc/glossary/glossary-terms.xml7815(glossterm) #: ./doc/glossary/glossary-terms.xml7819(secondary)#: ./doc/glossary/glossary-terms.xml7823(para)#: ./doc/glossary/glossary-terms.xml7829(glossterm) #: ./doc/glossary/glossary-terms.xml7831(primary)#: ./doc/glossary/glossary-terms.xml7835(para)#: ./doc/glossary/glossary-terms.xml7841(glossterm)#: ./doc/glossary/glossary-terms.xml7843(primary)#: ./doc/glossary/glossary-terms.xml7847(para)#: ./doc/glossary/glossary-terms.xml7855(glossterm) #: ./doc/glossary/glossary-terms.xml7857(primary)#: ./doc/glossary/glossary-terms.xml7861(para)#: ./doc/glossary/glossary-terms.xml7866(glossterm) #: ./doc/glossary/glossary-terms.xml7869(primary)#: ./doc/glossary/glossary-terms.xml7878(glossterm)#: ./doc/glossary/glossary-terms.xml7880(primary)#: ./doc/glossary/glossary-terms.xml7884(para)#: ./doc/glossary/glossary-terms.xml7890(glossterm)#: ./doc/glossary/glossary-terms.xml7892(primary)#: ./doc/glossary/glossary-terms.xml7896(para)#: ./doc/glossary/glossary-terms.xml7902(glossterm) #: ./doc/glossary/glossary-terms.xml7904(primary)#: ./doc/glossary/glossary-terms.xml7908(para)#: ./doc/glossary/glossary-terms.xml7918(para)#: ./doc/glossary/glossary-terms.xml7924(glossterm) #: ./doc/glossary/glossary-terms.xml7926(primary)#: ./doc/glossary/glossary-terms.xml7930(para)#: ./doc/glossary/glossary-terms.xml7936(glossterm) #: ./doc/glossary/glossary-terms.xml7940(secondary)#: ./doc/glossary/glossary-terms.xml7944(para)#: ./doc/glossary/glossary-terms.xml7950(glossterm) #: ./doc/glossary/glossary-terms.xml7954(secondary)#: ./doc/glossary/glossary-terms.xml7958(para)#: ./doc/glossary/glossary-terms.xml7964(glossterm)#: ./doc/glossary/glossary-terms.xml7968(secondary) #: ./doc/glossary/glossary-terms.xml7973(secondary) #: ./doc/glossary/glossary-terms.xml7978(secondary)#: ./doc/glossary/glossary-terms.xml7982(para)#: ./doc/glossary/glossary-terms.xml7988(glossterm) #: ./doc/glossary/glossary-terms.xml7990(primary)#: ./doc/glossary/glossary-terms.xml7994(para)#: ./doc/glossary/glossary-terms.xml8000(glossterm) #: ./doc/glossary/glossary-terms.xml8002(primary)#: ./doc/glossary/glossary-terms.xml8006(para)#: ./doc/glossary/glossary-terms.xml8013(glossterm) #: ./doc/glossary/glossary-terms.xml8015(primary)#: ./doc/glossary/glossary-terms.xml8019(para)#: ./doc/glossary/glossary-terms.xml8029(title)#: ./doc/glossary/glossary-terms.xml8032(glossterm) #: ./doc/glossary/glossary-terms.xml8034(primary)#: ./doc/glossary/glossary-terms.xml8038(para)#: ./doc/glossary/glossary-terms.xml8045(glossterm) #: ./doc/glossary/glossary-terms.xml8047(primary)#: ./doc/glossary/glossary-terms.xml8051(para)#: ./doc/glossary/glossary-terms.xml8058(glossterm) #: ./doc/glossary/glossary-terms.xml8060(primary)#: ./doc/glossary/glossary-terms.xml8064(para)#: ./doc/glossary/glossary-terms.xml8070(glossterm) #: ./doc/glossary/glossary-terms.xml8072(primary)#: ./doc/glossary/glossary-terms.xml8076(para)#: ./doc/glossary/glossary-terms.xml8082(glossterm) #: ./doc/glossary/glossary-terms.xml8093(primary) #: ./doc/glossary/glossary-terms.xml8111(primary) #: ./doc/glossary/glossary-terms.xml8125(primary)#: ./doc/glossary/glossary-terms.xml8085(para)#: ./doc/glossary/glossary-terms.xml8091(glossterm) #: ./doc/glossary/glossary-terms.xml8095(secondary)#: ./doc/glossary/glossary-terms.xml8099(para)#: ./doc/glossary/glossary-terms.xml8104(glossterm) #: ./doc/glossary/glossary-terms.xml8108(secondary) #: ./doc/glossary/glossary-terms.xml8113(secondary)#: ./doc/glossary/glossary-terms.xml8117(para)#: ./doc/glossary/glossary-terms.xml8123(glossterm) #: ./doc/glossary/glossary-terms.xml8127(secondary)#: ./doc/glossary/glossary-terms.xml8131(para)#: ./doc/glossary/glossary-terms.xml8137(glossterm)#: ./doc/glossary/glossary-terms.xml8139(primary)#: ./doc/glossary/glossary-terms.xml8143(para)#: ./doc/glossary/glossary-terms.xml8149(glossterm) #: ./doc/glossary/glossary-terms.xml8151(primary)#: ./doc/glossary/glossary-terms.xml8155(para)#: ./doc/glossary/glossary-terms.xml8161(glossterm) #: ./doc/glossary/glossary-terms.xml8163(primary)#: ./doc/glossary/glossary-terms.xml8166(para)#: ./doc/glossary/glossary-terms.xml8174(glossterm) #: ./doc/glossary/glossary-terms.xml8176(primary)#: ./doc/glossary/glossary-terms.xml8180(para)#: ./doc/glossary/glossary-terms.xml8186(glossterm) #: ./doc/glossary/glossary-terms.xml8188(primary)#: ./doc/glossary/glossary-terms.xml8192(para)#: ./doc/glossary/glossary-terms.xml8198(glossterm)#: ./doc/glossary/glossary-terms.xml8200(primary)#: ./doc/glossary/glossary-terms.xml8204(para)#: ./doc/glossary/glossary-terms.xml8210(glossterm)#: ./doc/glossary/glossary-terms.xml8212(primary)#: ./doc/glossary/glossary-terms.xml8218(para)#: ./doc/glossary/glossary-terms.xml8223(glossterm)#: ./doc/glossary/glossary-terms.xml8226(para)#: ./doc/glossary/glossary-terms.xml8232(glossterm)#: ./doc/glossary/glossary-terms.xml8236(secondary) #: ./doc/glossary/glossary-terms.xml8239(primary)#: ./doc/glossary/glossary-terms.xml8243(para)#: ./doc/glossary/glossary-terms.xml8249(glossterm)#: ./doc/glossary/glossary-terms.xml8253(secondary) #: ./doc/glossary/glossary-terms.xml8256(primary)#: ./doc/glossary/glossary-terms.xml8260(para)#: ./doc/glossary/glossary-terms.xml8265(glossterm) #: ./doc/glossary/glossary-terms.xml8267(primary)#: ./doc/glossary/glossary-terms.xml8271(para)#: ./doc/glossary/glossary-terms.xml8279(glossterm) #: ./doc/glossary/glossary-terms.xml8281(primary)#: ./doc/glossary/glossary-terms.xml8285(para)#: ./doc/glossary/glossary-terms.xml8294(title)#: ./doc/glossary/glossary-terms.xml8297(glossterm) #: ./doc/glossary/glossary-terms.xml8299(primary)#: ./doc/glossary/glossary-terms.xml8303(para)#: ./doc/glossary/glossary-terms.xml8308(glossterm) #: ./doc/glossary/glossary-terms.xml8310(primary)#: ./doc/glossary/glossary-terms.xml8314(para)#: ./doc/glossary/glossary-terms.xml8319(glossterm)#: ./doc/glossary/glossary-terms.xml8321(primary)#: ./doc/glossary/glossary-terms.xml8325(para)#: ./doc/glossary/glossary-terms.xml8331(glossterm)#: ./doc/glossary/glossary-terms.xml8333(primary)#: ./doc/glossary/glossary-terms.xml8337(para)#: ./doc/glossary/glossary-terms.xml8344(glossterm) #: ./doc/glossary/glossary-terms.xml8346(primary)#: ./doc/glossary/glossary-terms.xml8350(para)#: ./doc/glossary/glossary-terms.xml8360(glossterm) #: ./doc/glossary/glossary-terms.xml8362(primary)#: ./doc/glossary/glossary-terms.xml8374(title)#: ./doc/glossary/glossary-terms.xml8377(glossterm) #: ./doc/glossary/glossary-terms.xml8379(primary)#: ./doc/glossary/glossary-terms.xml8383(para)#: ./doc/glossary/glossary-terms.xml8388(glossterm) #: ./doc/glossary/glossary-terms.xml8390(primary)#: ./doc/glossary/glossary-terms.xml8394(para)#: ./doc/glossary/glossary-terms.xml8404(glossterm) #: ./doc/glossary/glossary-terms.xml8407(primary)#: ./doc/glossary/glossary-terms.xml8411(para)#: ./doc/glossary/glossary-terms.xml8417(glossterm) #: ./doc/glossary/glossary-terms.xml8419(primary)#: ./doc/glossary/glossary-terms.xml8429(glossterm) #: ./doc/glossary/glossary-terms.xml8431(primary)#: ./doc/glossary/glossary-terms.xml8441(glossterm) #: ./doc/glossary/glossary-terms.xml8443(primary)#: ./doc/glossary/glossary-terms.xml8447(para)#: ./doc/glossary/glossary-terms.xml8455(glossterm) #: ./doc/glossary/glossary-terms.xml8457(primary)#: ./doc/glossary/glossary-terms.xml8461(para)#: ./doc/glossary/glossary-terms.xml8468(glossterm) #: ./doc/glossary/glossary-terms.xml8475(primary)#: ./doc/glossary/glossary-terms.xml8472(secondary) #: ./doc/glossary/glossary-terms.xml8528(secondary) #: ./doc/glossary/glossary-terms.xml8558(secondary)#: ./doc/glossary/glossary-terms.xml8479(para)#: ./doc/glossary/glossary-terms.xml8484(glossterm) #: ./doc/glossary/glossary-terms.xml8486(primary)#: ./doc/glossary/glossary-terms.xml8490(para)#: ./doc/glossary/glossary-terms.xml8499(glossterm) #: ./doc/glossary/glossary-terms.xml8501(primary)#: ./doc/glossary/glossary-terms.xml8505(para)#: ./doc/glossary/glossary-terms.xml8511(glossterm) #: ./doc/glossary/glossary-terms.xml8513(primary)#: ./doc/glossary/glossary-terms.xml8517(para)#: ./doc/glossary/glossary-terms.xml8524(glossterm) #: ./doc/glossary/glossary-terms.xml8531(primary)#: ./doc/glossary/glossary-terms.xml8535(para)#: ./doc/glossary/glossary-terms.xml8541(glossterm) #: ./doc/glossary/glossary-terms.xml8543(primary)#: ./doc/glossary/glossary-terms.xml8547(para)#: ./doc/glossary/glossary-terms.xml8554(glossterm)#: ./doc/glossary/glossary-terms.xml8561(primary)#: ./doc/glossary/glossary-terms.xml8565(para)#: ./doc/glossary/glossary-terms.xml8570(glossterm) #: ./doc/glossary/glossary-terms.xml8572(primary)#: ./doc/glossary/glossary-terms.xml8576(para)#: ./doc/glossary/glossary-terms.xml8582(glossterm) #: ./doc/glossary/glossary-terms.xml8584(primary)#: ./doc/glossary/glossary-terms.xml8588(para)#: ./doc/glossary/glossary-terms.xml8593(glossterm) #: ./doc/glossary/glossary-terms.xml8595(primary)#: ./doc/glossary/glossary-terms.xml8604(glossterm) #: ./doc/glossary/glossary-terms.xml8606(primary)#: ./doc/glossary/glossary-terms.xml8610(para)#: ./doc/glossary/glossary-terms.xml8616(glossterm) #: ./doc/glossary/glossary-terms.xml8623(primary)#: ./doc/glossary/glossary-terms.xml8620(secondary)#: ./doc/glossary/glossary-terms.xml8627(para)#: ./doc/glossary/glossary-terms.xml8637(glossterm) #: ./doc/glossary/glossary-terms.xml8639(primary)#: ./doc/glossary/glossary-terms.xml8649(glossterm) #: ./doc/glossary/glossary-terms.xml8651(primary)#: ./doc/glossary/glossary-terms.xml8655(para)#: ./doc/glossary/glossary-terms.xml8660(glossterm) #: ./doc/glossary/glossary-terms.xml8662(primary)#: ./doc/glossary/glossary-terms.xml8666(para)#: ./doc/glossary/glossary-terms.xml8672(glossterm) #: ./doc/glossary/glossary-terms.xml8674(primary)#: ./doc/glossary/glossary-terms.xml8678(para)#: ./doc/glossary/glossary-terms.xml8683(glossterm)#: ./doc/glossary/glossary-terms.xml8686(para)#: ./doc/glossary/glossary-terms.xml8691(glossterm) #: ./doc/glossary/glossary-terms.xml8693(primary)#: ./doc/glossary/glossary-terms.xml8697(para)#: ./doc/glossary/glossary-terms.xml8703(glossterm) #: ./doc/glossary/glossary-terms.xml8715(primary) #: ./doc/glossary/glossary-terms.xml8728(primary) #: ./doc/glossary/glossary-terms.xml8742(primary) #: ./doc/glossary/glossary-terms.xml8755(primary) #: ./doc/glossary/glossary-terms.xml8769(primary) #: ./doc/glossary/glossary-terms.xml8783(primary) #: ./doc/glossary/glossary-terms.xml8797(primary)#: ./doc/glossary/glossary-terms.xml8706(para)#: ./doc/glossary/glossary-terms.xml8713(glossterm) #: ./doc/glossary/glossary-terms.xml8717(secondary)#: ./doc/glossary/glossary-terms.xml8721(para)#: ./doc/glossary/glossary-terms.xml8726(glossterm) #: ./doc/glossary/glossary-terms.xml8730(secondary)#: ./doc/glossary/glossary-terms.xml8734(para)#: ./doc/glossary/glossary-terms.xml8740(glossterm) #: ./doc/glossary/glossary-terms.xml8744(secondary)#: ./doc/glossary/glossary-terms.xml8748(para)#: ./doc/glossary/glossary-terms.xml8753(glossterm) #: ./doc/glossary/glossary-terms.xml8757(secondary)#: ./doc/glossary/glossary-terms.xml8761(para)#: ./doc/glossary/glossary-terms.xml8767(glossterm) #: ./doc/glossary/glossary-terms.xml8771(secondary)#: ./doc/glossary/glossary-terms.xml8775(para)#: ./doc/glossary/glossary-terms.xml8781(glossterm) #: ./doc/glossary/glossary-terms.xml8785(secondary)#: ./doc/glossary/glossary-terms.xml8789(para)#: ./doc/glossary/glossary-terms.xml8795(glossterm) #: ./doc/glossary/glossary-terms.xml8799(secondary)#: ./doc/glossary/glossary-terms.xml8803(para)#: ./doc/glossary/glossary-terms.xml8809(glossterm)#: ./doc/glossary/glossary-terms.xml8811(primary)#: ./doc/glossary/glossary-terms.xml8815(para)#: ./doc/glossary/glossary-terms.xml8823(glossterm) #: ./doc/glossary/glossary-terms.xml8825(primary)#: ./doc/glossary/glossary-terms.xml8837(title)#: ./doc/glossary/glossary-terms.xml8840(glossterm) #: ./doc/glossary/glossary-terms.xml8842(primary)#: ./doc/glossary/glossary-terms.xml8846(para)#: ./doc/glossary/glossary-terms.xml8853(glossterm) #: ./doc/glossary/glossary-terms.xml8855(primary)#: ./doc/glossary/glossary-terms.xml8859(para)#: ./doc/glossary/glossary-terms.xml8865(glossterm) #: ./doc/glossary/glossary-terms.xml8867(primary)#: ./doc/glossary/glossary-terms.xml8871(para)#: ./doc/glossary/glossary-terms.xml8877(glossterm)#: ./doc/glossary/glossary-terms.xml8879(primary)#: ./doc/glossary/glossary-terms.xml8883(para)#: ./doc/glossary/glossary-terms.xml8894(title)#: ./doc/glossary/glossary-terms.xml8897(glossterm) #: ./doc/glossary/glossary-terms.xml8899(primary)#: ./doc/glossary/glossary-terms.xml8903(para)#: ./doc/glossary/glossary-terms.xml8913(glossterm) #: ./doc/glossary/glossary-terms.xml8924(primary) #: ./doc/glossary/glossary-terms.xml8937(primary) #: ./doc/glossary/glossary-terms.xml8951(primary)#: ./doc/glossary/glossary-terms.xml8916(para)#: ./doc/glossary/glossary-terms.xml8922(glossterm) #: ./doc/glossary/glossary-terms.xml8926(secondary)#: ./doc/glossary/glossary-terms.xml8935(glossterm) #: ./doc/glossary/glossary-terms.xml8939(secondary)#: ./doc/glossary/glossary-terms.xml8943(para)#: ./doc/glossary/glossary-terms.xml8949(glossterm)#: ./doc/glossary/glossary-terms.xml8953(secondary)#: ./doc/glossary/glossary-terms.xml8965(title)#: ./doc/glossary/glossary-terms.xml8979(title)#: ./doc/glossary/glossary-terms.xml8982(glossterm) #: ./doc/glossary/glossary-terms.xml8984(primary)#: ./doc/glossary/glossary-terms.xml8988(para)#: ./doc/glossary/glossary-terms.xml8994(glossterm) #: ./doc/glossary/glossary-terms.xml8996(primary)#: ./doc/glossary/glossary-terms.xml9000(para)",1504,1459
openstack%2Fsahara~master~Ifa4d05f140d22600694c6532494462724c08b0e9,openstack/sahara,master,Ifa4d05f140d22600694c6532494462724c08b0e9,Fix quickstart guide,MERGED,2014-10-17 17:43:23.000000000,2014-10-20 06:50:27.000000000,2014-10-20 06:50:25.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 7710}]","[{'number': 1, 'created': '2014-10-17 17:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a761ba939257934cb88aff675a345191804500e5', 'message': 'Fix command line arguments for image-register and image-add-tag commands in quickstart guide\n\nChange-Id: Ifa4d05f140d22600694c6532494462724c08b0e9\n'}, {'number': 2, 'created': '2014-10-17 18:50:10.000000000', 'files': ['doc/source/devref/quickstart.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/024fa0525e8c74a6bbeace58689fa8f49c9d3f33', 'message': 'Fix quickstart guide\n\n* Fixes command line arguments for image-register and image-add-tag commands in quickstart guide\n\nChange-Id: Ifa4d05f140d22600694c6532494462724c08b0e9\n'}]",0,129339,024fa0525e8c74a6bbeace58689fa8f49c9d3f33,16,5,2,1976,,,0,"Fix quickstart guide

* Fixes command line arguments for image-register and image-add-tag commands in quickstart guide

Change-Id: Ifa4d05f140d22600694c6532494462724c08b0e9
",git fetch https://review.opendev.org/openstack/sahara refs/changes/39/129339/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/quickstart.rst'],1,a761ba939257934cb88aff675a345191804500e5,quickstart, $ sahara image-register --id $IMAGE_ID --username ubuntu $ sahara image-add-tag --id $IMAGE_ID --tag vanilla $ sahara image-add-tag --id $IMAGE_ID --tag 1.2.1, $ sahara image-register --image-id $IMAGE_ID --username ubuntu $ sahara image-add-tag --image-id $IMAGE_ID --tag vanilla $ sahara image-add-tag --image-id $IMAGE_ID --tag 1.2.1,3,3
openstack%2Fmanila~master~I88aedc07cacbae9eb34ca78a0205e2294cba3e63,openstack/manila,master,I88aedc07cacbae9eb34ca78a0205e2294cba3e63,Use strutils from oslo.utils,ABANDONED,2014-10-19 18:10:27.000000000,2014-10-20 06:47:05.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-10-19 18:10:27.000000000', 'files': ['openstack-common.conf', 'manila/api/contrib/quotas.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/ddc612c81e4e180ff5a626ebb6e616cab0028b83', 'message': 'Use strutils from oslo.utils\n\nRemove deprecated strutils from oslo-incubator and use version from\noslo.utils instead.\n\nDoes not remove the module yet since other oslo common code needs\nthe in-tree version, we first need to sync oslo-incubator.\n\nChange-Id: I88aedc07cacbae9eb34ca78a0205e2294cba3e63\nPartial-Bug: #1382189\n'}]",0,129480,ddc612c81e4e180ff5a626ebb6e616cab0028b83,3,1,1,6547,,,0,"Use strutils from oslo.utils

Remove deprecated strutils from oslo-incubator and use version from
oslo.utils instead.

Does not remove the module yet since other oslo common code needs
the in-tree version, we first need to sync oslo-incubator.

Change-Id: I88aedc07cacbae9eb34ca78a0205e2294cba3e63
Partial-Bug: #1382189
",git fetch https://review.opendev.org/openstack/manila refs/changes/80/129480/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack-common.conf', 'manila/api/contrib/quotas.py']",2,ddc612c81e4e180ff5a626ebb6e616cab0028b83,bug/1382189,from oslo.utils import strutils,from manila.openstack.common import strutils,2,1
openstack%2Fmanila~master~I3bf366c5266c51c66da562e1badc7c35d25f3f76,openstack/manila,master,I3bf366c5266c51c66da562e1badc7c35d25f3f76,Use timeutils from oslo.utils,ABANDONED,2014-10-19 18:10:27.000000000,2014-10-20 06:46:30.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-10-19 18:10:27.000000000', 'files': ['manila/db/sqlalchemy/models.py', 'manila/tests/test_quota.py', 'manila/scheduler/scheduler_options.py', 'manila/scheduler/host_manager.py', 'manila/tests/scheduler/test_host_manager.py', 'manila/share/drivers/emc/plugins/vnx/utils.py', 'manila/tests/api/v1/test_volume_types.py', 'manila/tests/scheduler/test_scheduler.py', 'manila/context.py', 'manila/tests/share/test_api.py', 'manila/share/api.py', 'manila/db/sqlalchemy/api.py', 'manila/scheduler/driver.py', 'manila/test.py', 'manila/tests/api/contrib/test_services.py', 'manila/tests/test_utils.py', 'manila/share/manager.py', 'manila/tests/api/fakes.py', 'openstack-common.conf', 'manila/api/views/limits.py', 'manila/quota.py', 'manila/utils.py', 'manila/tests/scheduler/fakes.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/439c3ccbf4cea4a34a4b65fb49d663163e34b992', 'message': 'Use timeutils from oslo.utils\n\nRemove deprecated strutils from oslo-incubator and use version from\noslo.utils instead.\n\nDoes not remove the module yet since other oslo common code needs\nthe in-tree version, we first need to sync oslo-incubator.\n\nPartial-Bug: #1382189\n\nChange-Id: I3bf366c5266c51c66da562e1badc7c35d25f3f76\n'}]",0,129481,439c3ccbf4cea4a34a4b65fb49d663163e34b992,3,1,1,6547,,,0,"Use timeutils from oslo.utils

Remove deprecated strutils from oslo-incubator and use version from
oslo.utils instead.

Does not remove the module yet since other oslo common code needs
the in-tree version, we first need to sync oslo-incubator.

Partial-Bug: #1382189

Change-Id: I3bf366c5266c51c66da562e1badc7c35d25f3f76
",git fetch https://review.opendev.org/openstack/manila refs/changes/81/129481/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/db/sqlalchemy/models.py', 'manila/tests/test_quota.py', 'manila/scheduler/scheduler_options.py', 'manila/scheduler/host_manager.py', 'manila/tests/scheduler/test_host_manager.py', 'manila/share/drivers/emc/plugins/vnx/utils.py', 'manila/tests/api/v1/test_volume_types.py', 'manila/tests/scheduler/test_scheduler.py', 'manila/context.py', 'manila/tests/share/test_api.py', 'manila/share/api.py', 'manila/db/sqlalchemy/api.py', 'manila/scheduler/driver.py', 'manila/test.py', 'manila/tests/api/contrib/test_services.py', 'manila/tests/test_utils.py', 'manila/share/manager.py', 'manila/tests/api/fakes.py', 'openstack-common.conf', 'manila/api/views/limits.py', 'manila/quota.py', 'manila/utils.py', 'manila/tests/scheduler/fakes.py']",23,439c3ccbf4cea4a34a4b65fb49d663163e34b992,bug/1382189,from oslo.utils import timeutils,from manila.openstack.common import timeutils,24,23
openstack%2Fmanila~master~I4cddbfb11a0ef6b4a13487491324b51e6c9ddb0b,openstack/manila,master,I4cddbfb11a0ef6b4a13487491324b51e6c9ddb0b,Use excutils from oslo.utils,ABANDONED,2014-10-19 17:29:12.000000000,2014-10-20 06:46:20.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-10-19 17:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/810a93c2b3bcbd1c3a54c601adc8b0ba53e8a2db', 'message': 'Use excutils from oslo.utils\n\nRemove excutils from oslo-incubator and use version from oslo.utils\ninstead.\n\nChange-Id: I4cddbfb11a0ef6b4a13487491324b51e6c9ddb0b\nPartial-Bug: #1382189\n'}, {'number': 2, 'created': '2014-10-19 18:21:21.000000000', 'files': ['manila/openstack/common/excutils.py', 'manila/share/api.py', 'manila/share/drivers/netapp/cluster_mode.py', 'manila/share/manager.py', 'openstack-common.conf', 'manila/scheduler/manager.py', 'manila/share/drivers/generic.py', 'manila/openstack/common/fileutils.py', 'manila/share/drivers/emc/plugins/vnx/connection.py', 'manila/utils.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/5a3d5abd56c05b35c3e3d80489948c72a3db66d1', 'message': 'Use excutils from oslo.utils\n\nRemove excutils from oslo-incubator and use version from oslo.utils\ninstead.\n\nChange-Id: I4cddbfb11a0ef6b4a13487491324b51e6c9ddb0b\nPartial-Bug: #1382189\n'}]",0,129477,5a3d5abd56c05b35c3e3d80489948c72a3db66d1,5,1,2,6547,,,0,"Use excutils from oslo.utils

Remove excutils from oslo-incubator and use version from oslo.utils
instead.

Change-Id: I4cddbfb11a0ef6b4a13487491324b51e6c9ddb0b
Partial-Bug: #1382189
",git fetch https://review.opendev.org/openstack/manila refs/changes/77/129477/2 && git format-patch -1 --stdout FETCH_HEAD,"['manila/openstack/common/excutils.py', 'manila/share/api.py', 'manila/share/drivers/netapp/cluster_mode.py', 'manila/share/manager.py', 'openstack-common.conf', 'manila/scheduler/manager.py', 'manila/share/drivers/generic.py', 'manila/openstack/common/fileutils.py', 'manila/share/drivers/emc/plugins/vnx/connection.py', 'manila/utils.py']",10,810a93c2b3bcbd1c3a54c601adc8b0ba53e8a2db,bug/1382189,from oslo.utils import excutils,from manila.openstack.common import excutils,9,122
openstack%2Fmanila~master~I833ac6a378e6c33a61c2cd68ff974c3d287b5295,openstack/manila,master,I833ac6a378e6c33a61c2cd68ff974c3d287b5295,Use importutils from oslo.utils,ABANDONED,2014-10-19 17:36:13.000000000,2014-10-20 06:46:05.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-10-19 17:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e83cc6176c1d1a7ce40156250d5c2a114aff98d9', 'message': 'Use importutils from oslo.utils\n\nRemove deprecated importutils from oslo-incubator and use version from\noslo.utils instead.\n\nChange-Id: I833ac6a378e6c33a61c2cd68ff974c3d287b5295\nPartial-Bug: 1382189\n'}, {'number': 2, 'created': '2014-10-19 18:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0f637ec34ec5f8bd07776f7998a26b1c897b0e8b', 'message': 'Use importutils from oslo.utils\n\nRemove deprecated importutils from oslo-incubator and use version from\noslo.utils instead.\n\nChange-Id: I833ac6a378e6c33a61c2cd68ff974c3d287b5295\nPartial-Bug: 1382189\n'}, {'number': 3, 'created': '2014-10-19 18:45:07.000000000', 'files': ['manila/api/v1/limits.py', 'manila/api/extensions.py', 'manila/scheduler/manager.py', 'manila/share/drivers/service_instance.py', 'manila/db/base.py', 'manila/service.py', 'manila/scheduler/driver.py', 'manila/tests/test_manager.py', 'manila/share/manager.py', 'openstack-common.conf', 'manila/share/drivers/generic.py', 'manila/quota.py', 'manila/tests/share/test_manager.py', 'manila/utils.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/90a9f7d926d1d2e11917fca8f483bcc5642b85ef', 'message': 'Use importutils from oslo.utils\n\nRemove deprecated importutils from oslo-incubator and use version from\noslo.utils instead.\n\nDoes not remove the module yet since other oslo common code needs\nthe in-tree version, we first need to sync oslo-incubator.\n\nChange-Id: I833ac6a378e6c33a61c2cd68ff974c3d287b5295\nPartial-Bug: #1382189\n'}]",0,129478,90a9f7d926d1d2e11917fca8f483bcc5642b85ef,7,1,3,6547,,,0,"Use importutils from oslo.utils

Remove deprecated importutils from oslo-incubator and use version from
oslo.utils instead.

Does not remove the module yet since other oslo common code needs
the in-tree version, we first need to sync oslo-incubator.

Change-Id: I833ac6a378e6c33a61c2cd68ff974c3d287b5295
Partial-Bug: #1382189
",git fetch https://review.opendev.org/openstack/manila refs/changes/78/129478/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/openstack/common/config/generator.py', 'manila/api/v1/limits.py', 'manila/openstack/common/log.py', 'manila/api/extensions.py', 'manila/openstack/common/jsonutils.py', 'manila/scheduler/manager.py', 'manila/openstack/common/importutils.py', 'manila/share/drivers/service_instance.py', 'manila/db/base.py', 'manila/service.py', 'manila/scheduler/driver.py', 'manila/tests/test_manager.py', 'manila/share/manager.py', 'openstack-common.conf', 'manila/share/drivers/generic.py', 'manila/openstack/common/service.py', 'manila/quota.py', 'manila/tests/share/test_manager.py', 'manila/utils.py']",19,e83cc6176c1d1a7ce40156250d5c2a114aff98d9,bug/1382189,from oslo.utils import importutils,from manila.openstack.common import importutils,17,93
openstack%2Fglance~master~I106f679be96bd39167337c4e27f4046f90d7d7ff,openstack/glance,master,I106f679be96bd39167337c4e27f4046f90d7d7ff,Glance scrubber should page thru images from registry,MERGED,2014-10-14 00:10:20.000000000,2014-10-20 06:44:59.000000000,2014-10-20 06:44:58.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 5347}, {'_account_id': 6493}, {'_account_id': 6549}, {'_account_id': 8158}, {'_account_id': 8759}]","[{'number': 1, 'created': '2014-10-14 00:10:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/48ef607d49197c6bdb389e507b5dfb482e2a9ae3', 'message': ""Glance scrubber should page thru images from registry\n\nIf the registry is limited in it's page size when returning the\nlist of images, the scrubber will only receive the first page.\nThis patch enables the scrubber to retrieve all the pages of\nimages.\n\nCloses-Bug 1280343\n\nChange-Id: I106f679be96bd39167337c4e27f4046f90d7d7ff\n""}, {'number': 2, 'created': '2014-10-14 00:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/306deb5ec0e4ec9c371e00494bfc6f0f051fb485', 'message': ""Glance scrubber should page thru images from registry\n\nIf the registry is limited in it's page size when returning the\nlist of images, the scrubber will only receive the first page.\nThis patch enables the scrubber to retrieve all the pages of\nimages.\n\nChange-Id: I106f679be96bd39167337c4e27f4046f90d7d7ff\nCloses-Bug: 1280343\n""}, {'number': 3, 'created': '2014-10-15 18:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fabe0a6dd54dd3de203ff2512dbf4509a6a6206d', 'message': ""Glance scrubber should page thru images from registry\n\nIf the registry is limited in it's page size when returning the\nlist of images, the scrubber will only receive the first page.\nThis patch enables the scrubber to retrieve all the pages of\nimages.\n\nChange-Id: I106f679be96bd39167337c4e27f4046f90d7d7ff\nCloses-Bug: 1280343\n""}, {'number': 4, 'created': '2014-10-16 15:46:56.000000000', 'files': ['glance/tests/unit/test_scrubber.py', 'glance/scrubber.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/d4658117e394971661b15b4bce8ecd3a4e1e5b8f', 'message': ""Glance scrubber should page thru images from registry\n\nIf the registry is limited in it's page size when returning the\nlist of images, the scrubber will only receive the first page.\nThis patch enables the scrubber to retrieve all the pages of\nimages.\n\nThe new tests are implemented with mock rather than mox. There\nis another patch (https://review.openstack.org/#/c/111995) to\nconvert the existing code in test_scrubber to use mock.\n\nChange-Id: I106f679be96bd39167337c4e27f4046f90d7d7ff\nCloses-Bug: 1280343\n""}]",0,128142,d4658117e394971661b15b4bce8ecd3a4e1e5b8f,26,8,4,5347,,,0,"Glance scrubber should page thru images from registry

If the registry is limited in it's page size when returning the
list of images, the scrubber will only receive the first page.
This patch enables the scrubber to retrieve all the pages of
images.

The new tests are implemented with mock rather than mox. There
is another patch (https://review.openstack.org/#/c/111995) to
convert the existing code in test_scrubber to use mock.

Change-Id: I106f679be96bd39167337c4e27f4046f90d7d7ff
Closes-Bug: 1280343
",git fetch https://review.opendev.org/openstack/glance refs/changes/42/128142/3 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/test_scrubber.py', 'glance/scrubber.py']",2,48ef607d49197c6bdb389e507b5dfb482e2a9ae3,bug/1280343," def _get_all_images(self): """"""Return all appropriate images, paging if needed. :retval The list of images to be scrubbed """""" filters = {'deleted': True, 'is_public': 'none', 'status': 'pending_delete'} images = self.registry.get_images_detailed(filters=filters) if len(images) > 0: marker = images[-1]['id'] while True: batch = self.registry.get_images_detailed(filters=filters, marker=marker) if len(batch) == 0: break images.extend(batch) marker = images[-1]['id'] return images for image in self._get_all_images():"," filters = {'deleted': True, 'is_public': 'none', 'status': 'pending_delete'} for image in self.registry.get_images_detailed(filters=filters):",97,4
openstack%2Fopenstack-manuals~master~I194a872ae977b6683b253830967594e2fa776338,openstack/openstack-manuals,master,I194a872ae977b6683b253830967594e2fa776338,Imported Translations from Transifex,MERGED,2014-10-20 06:12:30.000000000,2014-10-20 06:36:02.000000000,2014-10-20 06:36:01.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-20 06:12:30.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/install-guide/locale/ja.po', 'doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9dde80698bb41d471a79cc8cd9c71b3177f48e4a', 'message': 'Imported Translations from Transifex\n\nChange-Id: I194a872ae977b6683b253830967594e2fa776338\n'}]",0,129521,9dde80698bb41d471a79cc8cd9c71b3177f48e4a,6,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I194a872ae977b6683b253830967594e2fa776338
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/21/129521/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/install-guide/locale/ja.po', 'doc/glossary/locale/ja.po']",3,9dde80698bb41d471a79cc8cd9c71b3177f48e4a,transifex/translations,"""POT-Creation-Date: 2014-10-19 10:13+0000\n"" ""PO-Revision-Date: 2014-10-20 06:10+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""msgstr ""アクティブ/アクティブ設定""msgstr ""アクティブ/パッシブ設定""msgstr ""セル""msgstr ""セルマネージャー""msgstr ""認証局 (Compute)""msgstr ""クラウドコントローラー""msgstr ""クラウドの全体状況を表す Compute コンポーネント群。キュー経由で、Identity の認証、Object Storage、ノード/ストレージワーカーなどのサービスと通信する。""msgstr ""クラウドコントローラーノード""msgstr ""カスタマー""msgstr ""データ""msgstr ""割り当て解除""msgstr ""割り当て解除, 定義""msgstr ""Floating IP アドレスと固定 IP アドレスの関連付けを解除する処理。この関連付けが解除されると、Floating IP はアドレスプールに戻されます。""msgstr ""カプセル化""msgstr ""Image Service によりサポートされる仮想マシンイメージのコンテナー形式。""msgstr ""境界ファイアウォール機能を提供する Networking 拡張。""msgstr ""異なるネットワーク間でネットワーク通信を中継する、IP アドレス。一般的にはルーターに割り当てられる。""msgstr ""generic receive offload (GRO)""msgstr ""generic routing encapsulation (GRE)""msgstr ""イーサネット内でトンネルされる SCSI ディスクプロトコル。Compute、Object Storage、Image Service によりサポートされる。""msgstr ""Image Service によりサポートされる、仮想マシンイメージディスク形式の 1 つ。""msgstr ""Web ページを構築するために使用されるスクリプト言語。""msgstr ""ネットワークアドレス変換 (NAT)""msgstr ""IP アドレス情報を転送中に変更する処理。Compute と Networking によりサポートされる。""msgstr ""Networking 内の各ネットワークセグメントに割り当てられる一意な ID。ネットワーク UUID と同じ。""msgstr ""ネットワークノード""msgstr ""ネットワークワーカーデーモンを実行するコンピュートノードすべて。""msgstr ""Networking における仮想の分離された OSI L-2 サブネットを表す。""msgstr ""Networking のネットワーク<phrase role=\""keep-together\"">セグメント</phrase>の一意な ID。""msgstr ""ネットワークワーカー""msgstr ""コンピュートサービスを提供する OpenStack プロジェクト。""msgstr ""Nova API""msgstr ""オブジェクトオーディター""msgstr ""Object Storage オブジェクト用の一意な ID。""msgstr ""オブジェクトレプリケーター""msgstr ""オブジェクトサーバー""msgstr ""オブジェクトの管理に責任を持つ Object Storage のコンポーネント。""msgstr ""Open vSwitch (OVS) エージェント""msgstr ""Open vSwitch neutron プラグイン""msgstr ""Networking で Open vSwitch のサポートを提供する。""msgstr ""オープンソース LDAP サーバー。Compute と Identity によりサポートされる。""msgstr ""プラグイン, 定義""msgstr ""プールメンバー""msgstr ""raw 形式""msgstr ""レコード""msgstr ""静的""msgstr ""静的 IP アドレス""msgstr ""IP ネットワークの論理分割。""msgstr ""スワップ, 定義""msgstr "" ""msgstr ""swawth""msgstr ""swift ストレージノード""msgstr ""ユーザー, 定義""msgstr ""各 Networking VIF に割り当てられる一意な ID。""msgstr ""Networking 内の L2 ネットワークセグメント。""msgstr ""仮想ネットワーク""msgstr ""Neutron における VMware NSX サポートを提供する。""","""POT-Creation-Date: 2014-10-17 12:39+0000\n"" ""PO-Revision-Date: 2014-10-17 12:36+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",920,916
openstack%2Ftaskflow~master~Ic689f15744c6fcd840a69d886d989d51eae5bcd0,openstack/taskflow,master,Ic689f15744c6fcd840a69d886d989d51eae5bcd0,Rework pieces of the task listener/watcher capability,ABANDONED,2014-10-09 02:27:22.000000000,2014-10-20 06:12:07.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-10-09 02:27:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7779afb8c0fa4d8405dedafea0d9af6f0c89edb3', 'message': 'Rework pieces of the task listener capability\n\nCreate and use a helper object that contains the associated\nlistener data and store these objects instead the raw handlers\nin the tasks listener registry. Also expose the trigger() method\ndirectly so that engines of different types can more easily\nfire off a tasks associated event listeners. Also to make it easier\nto introspect what are a tasks associated listeners and events provide\na listeners_iter read-only function that can be used to iterate over\nthe registered (event, listener) pairs that are registered with a\ntask.\n\nChange-Id: Ic689f15744c6fcd840a69d886d989d51eae5bcd0\n'}, {'number': 2, 'created': '2014-10-09 04:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c01476a05f5a7e4f7283bae87f4094c3592db596', 'message': 'Rework pieces of the task listener capability\n\nCreate and use a helper object that contains the associated\nlistener data and store these objects instead the raw handlers\nin the tasks listener registry. Also expose the trigger() method\ndirectly so that engines of different types can more easily\nfire off a tasks associated event listeners. Also to make it easier\nto introspect what are a tasks associated listeners and events provide\na listeners_iter read-only function that can be used to iterate over\nthe registered (event, listener) pairs that are registered with a\ntask.\n\nChange-Id: Ic689f15744c6fcd840a69d886d989d51eae5bcd0\n'}, {'number': 3, 'created': '2014-10-09 06:42:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/67500590556be29c566ac5942ba4a4c36f93b5d2', 'message': 'Rework pieces of the task listener capability\n\nCreate and use a helper object that contains the associated\nlistener data and store these objects instead the raw handlers\nin the tasks listener registry. Also expose the trigger() method\ndirectly so that engines of different types can more easily\nfire off a tasks associated event listeners. Also to make it easier\nto introspect what are a tasks associated listeners and events provide\na listeners_iter read-only function that can be used to iterate over\nthe registered (event, listener) pairs that are registered with a\ntask.\n\nChange-Id: Ic689f15744c6fcd840a69d886d989d51eae5bcd0\n'}, {'number': 4, 'created': '2014-10-09 06:53:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5a05368e622e0137c211d0ec15f1af1481828302', 'message': 'Rework pieces of the task listener capability\n\nCreate and use a helper object that contains the associated\nlistener data and store these objects instead the raw handlers\nin the tasks listener registry. Also expose the trigger() method\ndirectly so that engines of different types can more easily\nfire off a tasks associated event listeners. Also to make it easier\nto introspect what are a tasks associated listeners and events provide\na listeners_iter read-only function that can be used to iterate over\nthe registered (event, listener) pairs that are registered with a\ntask.\n\nChange-Id: Ic689f15744c6fcd840a69d886d989d51eae5bcd0\n'}, {'number': 5, 'created': '2014-10-09 19:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0b72d4d31fe51345feb09cccae6bf2eb29704ea6', 'message': 'Rework pieces of the task listener/watcher capability\n\nCreate and use a helper object that contains the associated\nwatcher data & callback and store these objects instead the raw\ncallbacks in the tasks watcher registry.\n\nAlso expose the trigger() method directly so that engines of\ndifferent types can more easily fire off a tasks associated event\nlisteners.\n\nAlso to make it easier to introspect what are a tasks associated\nwatchers and events are provide a watchers() read-only function that\ncan be used to introspect the registered (event, watcher) pairs that\nare registered with a task.\n\nChange-Id: Ic689f15744c6fcd840a69d886d989d51eae5bcd0\n'}, {'number': 6, 'created': '2014-10-12 18:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/253f6d1463b2675c1906500865593660030b4bbd', 'message': 'Rework pieces of the task listener/watcher capability\n\nCreate and use a helper object that contains the associated\nwatcher data & callback and store these objects instead the raw\ncallbacks in the tasks watcher registry.\n\nAlso expose the trigger() method directly so that engines of\ndifferent types can more easily fire off a tasks associated event\nlisteners.\n\nAlso to make it easier to introspect what are a tasks associated\nwatchers and events are provide a watchers() read-only function that\ncan be used to introspect the registered (event, watcher) pairs that\nare registered with a task.\n\nPart of blueprint process-executor\n\nChange-Id: Ic689f15744c6fcd840a69d886d989d51eae5bcd0\n'}, {'number': 7, 'created': '2014-10-13 00:07:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/481a595cb1a8981c9c5a075bee4ae310e2143e0f', 'message': 'Rework pieces of the task listener/watcher capability\n\nCreate and use a helper object that contains the associated\nwatcher data & callback and store these objects instead the raw\ncallbacks in the tasks watcher registry.\n\nAlso expose the trigger() method directly so that engines of\ndifferent types can more easily fire off a tasks associated event\nlisteners.\n\nAlso to make it easier to introspect what are a tasks associated\nwatchers and events are provide a watchers() read-only function that\ncan be used to introspect the registered (event, watcher) pairs that\nare registered with a task.\n\nPart of blueprint process-executor\n\nChange-Id: Ic689f15744c6fcd840a69d886d989d51eae5bcd0\n'}, {'number': 8, 'created': '2014-10-13 00:18:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6110f75677dfff442ed27ceab825435bce9f42a7', 'message': 'Rework pieces of the task listener/watcher capability\n\nCreate and use a helper object that contains the associated\nwatcher data & callback and store these objects instead the raw\ncallbacks in the tasks watcher registry.\n\nAlso expose the trigger() method directly so that engines of\ndifferent types can more easily fire off a tasks associated event\nlisteners.\n\nAlso to make it easier to introspect what are a tasks associated\nwatchers and events are provide a watchers() read-only function that\ncan be used to introspect the registered (event, watcher) pairs that\nare registered with a task.\n\nPart of blueprint process-executor\n\nChange-Id: Ic689f15744c6fcd840a69d886d989d51eae5bcd0\n'}, {'number': 9, 'created': '2014-10-17 01:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0c815c5ca110c5f9d52fe3eaadfe900a51e0f762', 'message': 'Rework pieces of the task listener/watcher capability\n\nCreate and use a helper object that contains the associated\nwatcher data & callback and store these objects instead the raw\ncallbacks in the tasks watcher registry.\n\nAlso expose the trigger() method directly so that engines of\ndifferent types can more easily fire off a tasks associated event\nlisteners.\n\nAlso to make it easier to introspect what are a tasks associated\nwatchers and events are provide a watchers() read-only function that\ncan be used to introspect the registered (event, watcher) pairs that\nare registered with a task.\n\nPart of blueprint process-executor\n\nChange-Id: Ic689f15744c6fcd840a69d886d989d51eae5bcd0\n'}, {'number': 10, 'created': '2014-10-19 03:58:05.000000000', 'files': ['taskflow/task.py', 'taskflow/engines/action_engine/executor.py', 'taskflow/tests/unit/test_progress.py', 'taskflow/tests/unit/test_task.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/204c38da96ae5ccd2426e5ca672f10e079973ef9', 'message': 'Rework pieces of the task listener/watcher capability\n\nCreate and use a helper object that contains the associated\nwatcher data & callback and store these objects instead the raw\ncallbacks in the tasks watcher registry.\n\nAlso expose the trigger() method directly so that engines of\ndifferent types can more easily fire off a tasks associated event\nlisteners.\n\nAlso to make it easier to introspect what are a tasks associated\nwatchers and events are provide a watchers() read-only function that\ncan be used to introspect the registered (event, watcher) pairs that\nare registered with a task.\n\nPart of blueprint process-executor\n\nChange-Id: Ic689f15744c6fcd840a69d886d989d51eae5bcd0\n'}]",0,127114,204c38da96ae5ccd2426e5ca672f10e079973ef9,23,1,10,1297,,,0,"Rework pieces of the task listener/watcher capability

Create and use a helper object that contains the associated
watcher data & callback and store these objects instead the raw
callbacks in the tasks watcher registry.

Also expose the trigger() method directly so that engines of
different types can more easily fire off a tasks associated event
listeners.

Also to make it easier to introspect what are a tasks associated
watchers and events are provide a watchers() read-only function that
can be used to introspect the registered (event, watcher) pairs that
are registered with a task.

Part of blueprint process-executor

Change-Id: Ic689f15744c6fcd840a69d886d989d51eae5bcd0
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/14/127114/5 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/task.py', 'taskflow/tests/unit/test_task.py']",2,7779afb8c0fa4d8405dedafea0d9af6f0c89edb3,bp/process-executor," listeners = dict(task.listeners_iter()) mock.ANY, listeners['update_progress'], self.assertEqual(len(list(task.listeners_iter())), 0) self.assertEqual(len(list(task.listeners_iter())), 0) self.assertEqual(len(list(task.listeners_iter())), 0) self.assertEqual(len(list(task.listeners_iter())), 1) self.assertEqual(len(list(task.listeners_iter())), 0) self.assertEqual(len(list(task.listeners_iter())), 0) self.assertEqual(len(list(task.listeners_iter())), 0) self.assertTrue(task.bind('update_progress', handler1)) self.assertEqual(len(list(task.listeners_iter())), 1) self.assertEqual(len(list(task.listeners_iter())), 1) def test_null_bind(self): handler1 = None task = MyTask() self.assertFalse(task.bind('update_progress', handler1)) self.assertEqual(len(list(task.listeners_iter())), 0)"," mock.ANY, reflection.get_callable_name(progress_callback), self.assertEqual(len(task._events_listeners), 0) self.assertEqual(len(task._events_listeners), 0) self.assertEqual(len(task._events_listeners), 0) self.assertEqual(len(task._events_listeners), 1) self.assertEqual(len(task._events_listeners), 0) self.assertEqual(len(task._events_listeners), 0) self.assertEqual(len(task._events_listeners), 0) task.bind('update_progress', handler1) self.assertEqual(len(task._events_listeners), 1) self.assertEqual(len(task._events_listeners), 1)",79,36
openstack%2Foslo-incubator~master~I4063f6a09c1b0923b0b465c3b9639ed234ab650c,openstack/oslo-incubator,master,I4063f6a09c1b0923b0b465c3b9639ed234ab650c,rpc module cleanup issue,ABANDONED,2014-06-27 08:09:36.000000000,2014-10-20 06:10:27.000000000,,"[{'_account_id': 3}, {'_account_id': 1011}, {'_account_id': 2472}, {'_account_id': 7725}, {'_account_id': 8300}, {'_account_id': 9303}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-06-27 08:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/2b4ca9801ad751c5dcc095e1961fa75c0e1dca44', 'message': 'rpc module cleanup issue\n\nrpc.cleanup method is not reachable due to wrong import of rpc module.\nIn nova and cinder services rpc module is present in base package,\nwhereas service module is trying to import it from openstack common\npackage.\n\nAlso rpc cleanup method should not be called while restarting the\nservice, ideally cleanup task should be done only while exiting\nfrom the service. In case of SIGHUP signal, service gets restarted\nand tries to cleanup the rpc which is not required.\n\nModified update.py to handle rpc import from base package.\n\nChange-Id: I4063f6a09c1b0923b0b465c3b9639ed234ab650c\nCloses-Bug: #1334661\n'}, {'number': 2, 'created': '2014-08-01 12:13:16.000000000', 'files': ['openstack/common/service.py', 'update.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/cd146fabb7f7701d571b5ebe8eb5b9bbcd9b482b', 'message': 'rpc module cleanup issue\n\nrpc.cleanup method is not reachable due to wrong import of rpc module.\nIn nova and cinder services rpc module is present in base package,\nwhereas service module is trying to import it from openstack common\npackage.\n\nAlso rpc cleanup method should not be called while restarting the\nservice, ideally cleanup task should be done only while exiting\nfrom the service. In case of SIGHUP signal, service gets restarted\nand tries to cleanup the rpc which is not required.\n\nModified update.py to handle rpc import from base package.\n\nChange-Id: I4063f6a09c1b0923b0b465c3b9639ed234ab650c\nCloses-Bug: #1334661\n'}]",1,103049,cd146fabb7f7701d571b5ebe8eb5b9bbcd9b482b,19,7,2,8300,,,0,"rpc module cleanup issue

rpc.cleanup method is not reachable due to wrong import of rpc module.
In nova and cinder services rpc module is present in base package,
whereas service module is trying to import it from openstack common
package.

Also rpc cleanup method should not be called while restarting the
service, ideally cleanup task should be done only while exiting
from the service. In case of SIGHUP signal, service gets restarted
and tries to cleanup the rpc which is not required.

Modified update.py to handle rpc import from base package.

Change-Id: I4063f6a09c1b0923b0b465c3b9639ed234ab650c
Closes-Bug: #1334661
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/49/103049/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/service.py', 'update.py']",2,2b4ca9801ad751c5dcc095e1961fa75c0e1dca44,bug/1334661," # For nova and cinder rpc module is present in base package replacements.append(('\'rpc\'', '' + base + '.rpc')) ",,22,7
openstack%2Ftrove~master~I2109db07de5fea9caf342ec112bd0fef47d827ee,openstack/trove,master,I2109db07de5fea9caf342ec112bd0fef47d827ee,Imports troveclient.compat.client as module,ABANDONED,2014-01-13 16:27:04.000000000,2014-10-20 05:51:18.000000000,,"[{'_account_id': 3}, {'_account_id': 1925}, {'_account_id': 7092}, {'_account_id': 7806}, {'_account_id': 8415}]","[{'number': 1, 'created': '2014-01-13 16:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/bd30ff07e70b4dce30224f26ab0a9c490e723e8a', 'message': 'Imports troveclient.compat.client as module\n\nReasons:\n- Currently it is imported as ""from troveclient.compat import Dbaas"",\n  because of this, there is needed a ""# noqa"" import statement in\n  troveclient.compat\n\nChanges:\n- Imports troveclient.compat.client as a module\n\nChange-Id: I2109db07de5fea9caf342ec112bd0fef47d827ee\nCloses-Bug: #1268602\n'}, {'number': 2, 'created': '2014-01-13 16:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d8dc54cd29143fb66b9bfe8d428fad4597343482', 'message': 'Imports troveclient.compat.client as module\n\nReasons:\n- Currently it is imported as ""from troveclient.compat import Dbaas"",\n  because of this, there is needed a ""# noqa"" import statement in\n  troveclient.compat\n\nChanges:\n- Imports troveclient.compat.client as a module.\n\nDependency:\n- This is needed by https://review.openstack.org/#/c/66331/\n\nChange-Id: I2109db07de5fea9caf342ec112bd0fef47d827ee\nCloses-Bug: #1268602\n'}, {'number': 3, 'created': '2014-10-20 04:40:04.000000000', 'files': ['trove/tests/util/__init__.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/36d35bdbb0d23187a7ace85c7b3de0fb94157ddf', 'message': 'Imports troveclient.compat.client as module\n\nReasons:\n- Currently it is imported as ""from troveclient.compat import Dbaas"",\n  because of this, there is needed a ""# noqa"" import statement in\n  troveclient.compat\n\nChanges:\n- Imports troveclient.compat.client as a module.\n\nDependency:\n- This is needed by https://review.openstack.org/#/c/66331/\n\nChange-Id: I2109db07de5fea9caf342ec112bd0fef47d827ee\nCloses-Bug: #1268602\n'}]",0,66362,36d35bdbb0d23187a7ace85c7b3de0fb94157ddf,21,5,3,7806,,,0,"Imports troveclient.compat.client as module

Reasons:
- Currently it is imported as ""from troveclient.compat import Dbaas"",
  because of this, there is needed a ""# noqa"" import statement in
  troveclient.compat

Changes:
- Imports troveclient.compat.client as a module.

Dependency:
- This is needed by https://review.openstack.org/#/c/66331/

Change-Id: I2109db07de5fea9caf342ec112bd0fef47d827ee
Closes-Bug: #1268602
",git fetch https://review.opendev.org/openstack/trove refs/changes/62/66362/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/tests/util/__init__.py'],1,bd30ff07e70b4dce30224f26ab0a9c490e723e8a,,"from troveclient.compat import client as TroveClient dbaas = TroveClient.Dbaas(user.auth_user, user.auth_key, tenant=user.tenant, auth_url=auth_url, **kwargs)","from troveclient.compat import Dbaas dbaas = Dbaas(user.auth_user, user.auth_key, tenant=user.tenant, auth_url=auth_url, **kwargs)",3,3
openstack%2Fpython-keystoneclient~master~I1cf846ec56865a9979f628f5c77d2bb689e10ffe,openstack/python-keystoneclient,master,I1cf846ec56865a9979f628f5c77d2bb689e10ffe,"Set install_venv_common as a script, not a module",ABANDONED,2014-10-14 21:55:29.000000000,2014-10-20 05:24:00.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 13140}]","[{'number': 1, 'created': '2014-10-14 21:55:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/168254645dfc5761ac3a05e82f1c519e741a0748', 'message': ""Set install_venv_common as a script, not a module\n\ninstall_venv_common is not a module in oslo-incubator, but it's a\nscript, so let's call it that.\n\nChange-Id: I1cf846ec56865a9979f628f5c77d2bb689e10ffe\n""}, {'number': 2, 'created': '2014-10-15 04:28:22.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/7eb01b86798631ea31244f689679c3d8c3c50083', 'message': ""Set install_venv_common as a script, not a module\n\ninstall_venv_common is not a module in oslo-incubator, but it's a\nscript, so let's call it that.\n\nChange-Id: I1cf846ec56865a9979f628f5c77d2bb689e10ffe\n""}]",0,128455,7eb01b86798631ea31244f689679c3d8c3c50083,9,6,2,6482,,,0,"Set install_venv_common as a script, not a module

install_venv_common is not a module in oslo-incubator, but it's a
script, so let's call it that.

Change-Id: I1cf846ec56865a9979f628f5c77d2bb689e10ffe
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/55/128455/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,168254645dfc5761ac3a05e82f1c519e741a0748,venv,script=tools/install_venv_common.py ,module=install_venv_common,2,1
openstack%2Fpython-troveclient~master~Ia5f8c567c00c5a2a3ad893ee47f926e1e87b0693,openstack/python-troveclient,master,Ia5f8c567c00c5a2a3ad893ee47f926e1e87b0693,Removes unused imports,ABANDONED,2014-01-13 13:47:49.000000000,2014-10-20 04:44:48.000000000,,"[{'_account_id': 3}, {'_account_id': 1925}, {'_account_id': 7092}, {'_account_id': 7806}, {'_account_id': 8415}]","[{'number': 1, 'created': '2014-01-13 13:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/1dd46cb5b8a319fc74653ecc3f65a2dc099ffa18', 'message': 'Removes unused imports\n\nReasons:\n- Unused imports are present in the troveclient code.\n- These were still left, probably because of a # noqa with them.\n\nChanges:\n- Removed unused imports.\n\nChange-Id: Ia5f8c567c00c5a2a3ad893ee47f926e1e87b0693\n'}, {'number': 2, 'created': '2014-01-13 13:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/4c0c863e1ac9822798c7e594a60d13cfb0571423', 'message': 'Removes unused imports\n\nReasons:\n- Unused imports are present in the troveclient code.\n- These were still left, probably because of a # noqa with them.\n\nChanges:\n- Removed unused imports.\n\nChange-Id: Ia5f8c567c00c5a2a3ad893ee47f926e1e87b0693\n'}, {'number': 3, 'created': '2014-01-13 13:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/d6693a90a3e13ef0ab0f2335c6e8eddf100ad4f2', 'message': 'Removes unused imports\n\nReasons:\n- Unused imports are present in the troveclient code.\n- These were still left, probably because of a # noqa with them.\n\nChanges:\n- Removed unused imports.\n\nChange-Id: Ia5f8c567c00c5a2a3ad893ee47f926e1e87b0693\nCloses-Bug: #1268602\n'}, {'number': 4, 'created': '2014-01-13 16:29:06.000000000', 'files': ['troveclient/openstack/common/strutils.py', 'troveclient/tests/test_utils.py', 'troveclient/compat/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/6bf20e1acd0430477fd380cf4ec463dd01a79982', 'message': 'Removes unused imports\n\nReasons:\n- Unused imports are present in the troveclient code.\n- These were still left, probably because of a # noqa with them.\n\nChanges:\n- Removed unused imports.\n\nDependency:\n- This patchset is dependent on a patchet in trove:\n  https://review.openstack.org/#/c/66362/\n\nChange-Id: Ia5f8c567c00c5a2a3ad893ee47f926e1e87b0693\nCloses-Bug: #1268602\n'}]",2,66331,6bf20e1acd0430477fd380cf4ec463dd01a79982,19,5,4,7806,,,0,"Removes unused imports

Reasons:
- Unused imports are present in the troveclient code.
- These were still left, probably because of a # noqa with them.

Changes:
- Removed unused imports.

Dependency:
- This patchset is dependent on a patchet in trove:
  https://review.openstack.org/#/c/66362/

Change-Id: Ia5f8c567c00c5a2a3ad893ee47f926e1e87b0693
Closes-Bug: #1268602
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/31/66331/4 && git format-patch -1 --stdout FETCH_HEAD,"['troveclient/openstack/common/strutils.py', 'troveclient/tests/test_utils.py', 'troveclient/compat/__init__.py']",3,1dd46cb5b8a319fc74653ecc3f65a2dc099ffa18,bug/1268602,, from troveclient.v1.accounts import Accounts # noqa from troveclient.v1.databases import Databases # noqa from troveclient.v1.flavors import Flavors # noqa from troveclient.v1.instances import Instances # noqa from troveclient.v1.hosts import Hosts # noqa from troveclient.v1.management import Management # noqa from troveclient.v1.management import RootHistory # noqa from troveclient.v1.management import MgmtFlavors # noqa from troveclient.v1.root import Root # noqa from troveclient.v1.storage import StorageInfo # noqa from troveclient.v1.users import Users # noqa from troveclient.compat.versions import Versions # noqa from troveclient.v1.diagnostics import DiagnosticsInterrogator # noqa from troveclient.v1.diagnostics import HwInfoInterrogator # noqa from troveclient.compat.client import Dbaas # noqa from troveclient.compat.client import TroveHTTPClient # noqa,0,21
openstack%2Fpython-mistralclient~master~I90ef7f9722539bc8697fd50a801dbb89fff580e2,openstack/python-mistralclient,master,I90ef7f9722539bc8697fd50a801dbb89fff580e2,Work toward Python 3.4 support and testing,MERGED,2014-09-03 20:32:18.000000000,2014-10-20 03:39:07.000000000,2014-10-20 03:39:07.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-09-03 20:32:18.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/d1921e9661a9fbe7328e20b394732ca3dd61b69b', 'message': 'Work toward Python 3.4 support and testing\n\nChange-Id: I90ef7f9722539bc8697fd50a801dbb89fff580e2\n'}]",0,118833,d1921e9661a9fbe7328e20b394732ca3dd61b69b,9,5,1,5263,,,0,"Work toward Python 3.4 support and testing

Change-Id: I90ef7f9722539bc8697fd50a801dbb89fff580e2
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/33/118833/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d1921e9661a9fbe7328e20b394732ca3dd61b69b,py34,"envlist = py26,py27,py33,py34,pep8","envlist = py26,py27,py33,pep8",1,1
openstack%2Fpython-ceilometerclient~master~I979aca09917f20991ccdc7d4c5d1612fcd1f24c0,openstack/python-ceilometerclient,master,I979aca09917f20991ccdc7d4c5d1612fcd1f24c0,Add CONTRIBUTING.rst,MERGED,2014-07-01 06:47:52.000000000,2014-10-20 03:37:43.000000000,2014-10-20 03:37:43.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 6763}, {'_account_id': 8871}, {'_account_id': 10987}, {'_account_id': 12015}]","[{'number': 1, 'created': '2014-07-01 06:47:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/c472a82e59eeb95c765b10548276385c112c2884', 'message': 'Add CONTRIBUTING.rst\n\nThere is no CONTRIBUTING.rst file, so i add it.\n\nChange-Id: I979aca09917f20991ccdc7d4c5d1612fcd1f24c0\n'}, {'number': 2, 'created': '2014-07-01 07:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/aa8998dadecbded88d9ff78bdef301cdad64ee69', 'message': 'Add CONTRIBUTING.rst\n\nThere is no CONTRIBUTING.rst file, so i add it.\n\nChange-Id: I979aca09917f20991ccdc7d4c5d1612fcd1f24c0\n'}, {'number': 3, 'created': '2014-07-14 17:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/f57b61de73e886b6498a8a4b6807d835b713fa2f', 'message': 'Add CONTRIBUTING.rst\n\nThere is no CONTRIBUTING.rst file, the patch will add it.\n\nChange-Id: I979aca09917f20991ccdc7d4c5d1612fcd1f24c0\n'}, {'number': 4, 'created': '2014-10-17 10:49:29.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/fc7f55ba2a3967d341d2b9a24f61173a6f01a1b8', 'message': 'Add CONTRIBUTING.rst\n\nThere is no CONTRIBUTING.rst file, the patch will add it.\n\nChange-Id: I979aca09917f20991ccdc7d4c5d1612fcd1f24c0\n'}]",2,103751,fc7f55ba2a3967d341d2b9a24f61173a6f01a1b8,46,10,4,6763,,,0,"Add CONTRIBUTING.rst

There is no CONTRIBUTING.rst file, the patch will add it.

Change-Id: I979aca09917f20991ccdc7d4c5d1612fcd1f24c0
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/51/103751/2 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,c472a82e59eeb95c765b10548276385c112c2884,add_contributing_rst,"If you would like to contribute to the development of OpenStack, you must follow the steps in documented at: http://wiki.openstack.org/HowToContribute#If_you.27re_a_developer Once those steps have been completed, changes to OpenStack should be submitted for review via the Gerrit tool, following the workflow documented at: http://wiki.openstack.org/GerritWorkflow Pull requests submitted through GitHub will be ignored. Bugs should be filed on Launchpad, not GitHub: https://bugs.launchpad.net/python-ceilometerclient ",,16,0
openstack%2Fmistral~master~I6aa11e0795752532d9333aba3062c0acf0f8de7c,openstack/mistral,master,I6aa11e0795752532d9333aba3062c0acf0f8de7c,Add distributed execution to mistral,ABANDONED,2014-06-20 11:39:55.000000000,2014-10-20 03:35:54.000000000,,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 8824}, {'_account_id': 8907}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-06-20 11:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/88bde9860119085c711df6b9cf1f55603e3e631b', 'message': 'Add distributed execution to mistral\n\n- added DistributedEngine\n- added DistributedExecutorClient\n\nrelies on targets parameters to run task on specific node\n\npatch is mostly to test things, additionally need to cover:\n\n1. DistributedExecutor shouldnot use database\n2. Changes to DistributedEngine will be required\n3. better way to manage task targets\n\nChange-Id: I6aa11e0795752532d9333aba3062c0acf0f8de7c\n'}, {'number': 2, 'created': '2014-06-23 08:26:01.000000000', 'files': ['mistral/engine/executor.py', 'mistral/engine/drivers/default/engine.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/mistral/commit/1387ef90e86eb1dab7dbfb9daa31d1689284e410', 'message': 'Add distributed execution to mistral\n\n- added DistributedEngine\n- added DistributedExecutorClient\n\nrelies on targets parameters to run task on specific node\n\npatch is mostly to test things, additionally need to cover:\n\n1. DistributedExecutor shouldnot use database\n2. Changes to DistributedEngine will be required\n3. better way to manage task targets\n\nChange-Id: I6aa11e0795752532d9333aba3062c0acf0f8de7c\n'}]",0,101487,1387ef90e86eb1dab7dbfb9daa31d1689284e410,12,7,2,8907,,,0,"Add distributed execution to mistral

- added DistributedEngine
- added DistributedExecutorClient

relies on targets parameters to run task on specific node

patch is mostly to test things, additionally need to cover:

1. DistributedExecutor shouldnot use database
2. Changes to DistributedEngine will be required
3. better way to manage task targets

Change-Id: I6aa11e0795752532d9333aba3062c0acf0f8de7c
",git fetch https://review.opendev.org/openstack/mistral refs/changes/87/101487/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/engine/executor.py', 'mistral/engine/drivers/default/engine.py', 'setup.cfg']",3,88bde9860119085c711df6b9cf1f55603e3e631b,distributed_execution, distributed = mistral.engine.drivers.default.engine:DistributedEngine,,34,0
openstack%2Fpuppet-glance~master~I0a24cd24ddf3e0b1fab94e693a2fac847cc7271c,openstack/puppet-glance,master,I0a24cd24ddf3e0b1fab94e693a2fac847cc7271c,Run the `glance` CLI tool with appropriate region name,MERGED,2014-09-30 23:33:57.000000000,2014-10-20 03:26:00.000000000,2014-10-20 03:26:00.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 2265}, {'_account_id': 3153}, {'_account_id': 9500}, {'_account_id': 13413}]","[{'number': 1, 'created': '2014-09-30 23:33:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/a1dffeee033519b178ca9d3e6363136c1291a1f8', 'message': 'Run the `glance` CLI tool with appropriate region name\n\nThis is pretty important in situations where Keystone contains information about\nmultiple regions. The holding assumption is that the glance::image etc are used\nfor image upload for the current region.\n\nChange-Id: I0a24cd24ddf3e0b1fab94e693a2fac847cc7271c\n'}, {'number': 2, 'created': '2014-09-30 23:35:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/c340dc6eb80e408783bf67f46c51faf2d22f2b60', 'message': 'Run the `glance` CLI tool with appropriate region name\n\nThis is pretty important in situations where Keystone contains information about\nmultiple regions. The holding assumption is that the glance::image etc are used\nfor image upload for the current region.\n\nChange-Id: I0a24cd24ddf3e0b1fab94e693a2fac847cc7271c\n'}, {'number': 3, 'created': '2014-10-01 00:29:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/3362d9767b06cf5923b3d48360a9493ee4ad7300', 'message': 'Run the `glance` CLI tool with appropriate region name\n\nThis is pretty important in situations where Keystone contains information about\nmultiple regions. The holding assumption is that the glance::image etc are used\nfor image upload for the current region.\n\nChange-Id: I0a24cd24ddf3e0b1fab94e693a2fac847cc7271c\n'}, {'number': 4, 'created': '2014-10-03 20:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/4bd13b3e9bac37ecd877038f3b78bf271f8f36b8', 'message': 'Run the `glance` CLI tool with appropriate region name\n\nThis is pretty important in situations where Keystone contains information about\nmultiple regions. The holding assumption is that the glance::image etc are used\nfor image upload for the current region.\n\nChange-Id: I0a24cd24ddf3e0b1fab94e693a2fac847cc7271c\n'}, {'number': 5, 'created': '2014-10-09 14:28:18.000000000', 'files': ['spec/unit/provider/glance_spec.rb', 'lib/puppet/provider/glance.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/abd028a5f6b0e5e139cb53678482299b8c55b0d3', 'message': 'Run the `glance` CLI tool with appropriate region name\n\nThis is pretty important in situations where Keystone contains information about\nmultiple regions. The holding assumption is that the glance::image etc are used\nfor image upload for the current region.\n\nChange-Id: I0a24cd24ddf3e0b1fab94e693a2fac847cc7271c\n'}]",0,125231,abd028a5f6b0e5e139cb53678482299b8c55b0d3,17,6,5,13413,,,0,"Run the `glance` CLI tool with appropriate region name

This is pretty important in situations where Keystone contains information about
multiple regions. The holding assumption is that the glance::image etc are used
for image upload for the current region.

Change-Id: I0a24cd24ddf3e0b1fab94e693a2fac847cc7271c
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/31/125231/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/glance_spec.rb', 'lib/puppet/provider/glance.rb']",2,a1dffeee033519b178ca9d3e6363136c1291a1f8,," glance_file['keystone_authtoken']['admin_password'] and glance_file['DEFAULT']['os_region_name'] g['os_region_name'] = glance_file['DEFAULT']['os_region_name'].strip remove_warnings(glance('-T', g['admin_tenant_name'], '-I', g['admin_user'], '-K', g['admin_password'], '--os-region-name', g['os_region_name'], '-N', auth_endpoint, args)) remove_warnings(glance('-T', g['admin_tenant_name'], '-I', g['admin_user'], '-K', g['admin_password'], '--os-region-name', g['os_region_name'], '-N', auth_endpoint, args)) command = ""glance -T #{g['admin_tenant_name']} -I #{g['admin_user']} -K #{g['admin_password']} --os-region-name #{g['os_region_name']} -N #{auth_endpoint} #{args.join(' ')}"""," glance_file['keystone_authtoken']['admin_password'] remove_warnings(glance('-T', g['admin_tenant_name'], '-I', g['admin_user'], '-K', g['admin_password'], '-N', auth_endpoint, args)) remove_warnings(glance('-T', g['admin_tenant_name'], '-I', g['admin_user'], '-K', g['admin_password'], '-N', auth_endpoint, args)) command = ""glance -T #{g['admin_tenant_name']} -I #{g['admin_user']} -K #{g['admin_password']} -N #{auth_endpoint} #{args.join(' ')}""",12,4
openstack%2Fnova~master~I8c2ba52cffbcf9be50fd0e2f7b2bb1da8089e324,openstack/nova,master,I8c2ba52cffbcf9be50fd0e2f7b2bb1da8089e324,Remove obsolete vmware/esx tools,MERGED,2014-10-05 02:34:56.000000000,2014-10-20 03:16:13.000000000,2014-10-20 03:16:10.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 5638}, {'_account_id': 7400}, {'_account_id': 8412}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-05 02:34:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/29d789a88faa7649ff38209d766d763663c25bcd', 'message': 'Remove obsolete vmware/esx tools\n\nChange-Id: I8c2ba52cffbcf9be50fd0e2f7b2bb1da8089e324\n'}, {'number': 2, 'created': '2014-10-07 12:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e92f5a6e66b20d5a2d6d5ceb620000521186c8dc', 'message': 'Remove obsolete vmware/esx tools\n\nChange-Id: I8c2ba52cffbcf9be50fd0e2f7b2bb1da8089e324\n'}, {'number': 3, 'created': '2014-10-07 20:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/755830e642a801340bd1642566fdd87ca19eb22c', 'message': 'Remove obsolete vmware/esx tools\n\nOur Docs have updated information in and the README is stale.\nhttps://review.openstack.org/126172\n\nChange-Id: I8c2ba52cffbcf9be50fd0e2f7b2bb1da8089e324\n'}, {'number': 4, 'created': '2014-10-07 20:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/43984d3e42164bc1035994db960fb1a1b32f668d', 'message': 'Remove obsolete vmware/esx tools\n\nOur Docs have updated information in and the README is stale.\nhttps://review.openstack.org/126172\n\nThe guest_tool.py was once used a long time ago to setup \nnetworking by pulling information from esx and setting \nthe OS details in the VM. This is no longer used or needed as\nwe have better tools now to do the same.\n\nChange-Id: I8c2ba52cffbcf9be50fd0e2f7b2bb1da8089e324\n'}, {'number': 5, 'created': '2014-10-08 13:52:58.000000000', 'files': ['tools/esx/guest_tool.py', 'tools/vmwareapi/README.firewall'], 'web_link': 'https://opendev.org/openstack/nova/commit/3ef4f63ea7a55d56d297a82f0dc9532122d9711c', 'message': 'Remove obsolete vmware/esx tools\n\nOur Docs have updated information in and the README is stale.\nhttp://docs.openstack.org/trunk/config-reference/content/vmware.html#vmware-prereqs\n\nThe guest_tool.py was once used a long time ago to setup\nnetworking by pulling information from esx and setting\nthe OS details in the VM. This is no longer used or needed as\nwe have better ways to do the same using config drive or metadata service\nhttp://docs.openstack.org/trunk/config-reference/content/vmware.html#VMware_networking\nhttp://docs.openstack.org/user-guide/content/config-drive.html\nhttp://cloudinit.readthedocs.org/en/latest/topics/datasources.html#config-drive\n\nChange-Id: I8c2ba52cffbcf9be50fd0e2f7b2bb1da8089e324\n'}]",4,126172,3ef4f63ea7a55d56d297a82f0dc9532122d9711c,29,9,5,5638,,,0,"Remove obsolete vmware/esx tools

Our Docs have updated information in and the README is stale.
http://docs.openstack.org/trunk/config-reference/content/vmware.html#vmware-prereqs

The guest_tool.py was once used a long time ago to setup
networking by pulling information from esx and setting
the OS details in the VM. This is no longer used or needed as
we have better ways to do the same using config drive or metadata service
http://docs.openstack.org/trunk/config-reference/content/vmware.html#VMware_networking
http://docs.openstack.org/user-guide/content/config-drive.html
http://cloudinit.readthedocs.org/en/latest/topics/datasources.html#config-drive

Change-Id: I8c2ba52cffbcf9be50fd0e2f7b2bb1da8089e324
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/126172/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/esx/guest_tool.py', 'tools/vmwareapi/README.firewall']",2,29d789a88faa7649ff38209d766d763663c25bcd,,,"To open VNC ports on your ESX host, use the openstackvncfirewall.zip file from the following github repo git clone https://github.com/openstack-vmwareapi-team/Tools.git ",0,405
openstack%2Fnova-specs~master~Ie7dd7ed3550ab5a76d502ae9fdbd5566c0537813,openstack/nova-specs,master,Ie7dd7ed3550ab5a76d502ae9fdbd5566c0537813,Add proposed specs from the Juno cycle,ABANDONED,2014-09-30 00:17:25.000000000,2014-10-20 02:51:23.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}]","[{'number': 1, 'created': '2014-09-30 00:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a7eed1ca92c92b1cd0c0c5862d4d7a9b5315c06c', 'message': ""Add proposed specs from the Juno cycle\n\nAdd proposed specs from the Juno cycle. I've done this because I\nworry about the case where a future developer wants to pick up\nsomething dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic.\n\nFor spec filenames where there was more than one review which\nproposed adding that file, I have added -proposal-[12345] to the\nend of the filename.\n\nChange-Id: Ie7dd7ed3550ab5a76d502ae9fdbd5566c0537813\n""}, {'number': 2, 'created': '2014-09-30 00:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/800ba16b65f7b8dc8b97c2cefb392eb46900653e', 'message': ""Add proposed specs from the Juno cycle\n\nAdd proposed specs from the Juno cycle. I've done this because I\nworry about the case where a future developer wants to pick up\nsomething dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic.\n\nFor spec filenames where there was more than one review which\nproposed adding that file, I have added -proposal-[12345] to the\nend of the filename.\n\nChange-Id: Ie7dd7ed3550ab5a76d502ae9fdbd5566c0537813\n""}, {'number': 3, 'created': '2014-10-06 20:51:48.000000000', 'files': ['specs/juno/proposed/horizontally-scalable-scheduling.rst', 'specs/juno/proposed/emc-sdc-libvirt-driver.rst', 'specs/juno/proposed/multi-attach-volume.rst', 'specs/juno/proposed/hyper-v-rescue.rst', 'specs/juno/proposed/restrict-instance-migration.rst', 'specs/juno/proposed/add-support-for-cpu-hotadd.rst', 'specs/juno/proposed/thunderboost-proposal-2.rst', 'specs/juno/proposed/extends-nova-hypervisor.rst', 'specs/juno/proposed/nova-api-policy.rst', 'specs/juno/proposed/transfer-instance-ownership.rst', 'specs/juno/proposed/validate-targethost-live-migration.rst', 'specs/juno/proposed/metadata-service-callbacks.rst', 'specs/juno/proposed/instance-tasks-api.rst', 'specs/juno/proposed/nova-ephemeral-cinder.rst', 'specs/juno/proposed/gpfs-instance-store.rst', 'specs/juno/proposed/libvirt-smbfs-volume-support.rst', 'specs/juno/proposed/nova-api-extension-to-list-available-resources.rst', 'specs/juno/proposed/no-db-scheduler.rst', 'specs/juno/proposed/soft-affinity-for-server-group.rst', 'specs/juno/proposed/nova-vmware-vcdriver-nfs-image-copy.rst', 'specs/juno/proposed/rootwrap-daemon-mode.rst', 'specs/juno/proposed/hyper-v-remotefx.rst', 'specs/juno/proposed/pcs-support.rst', 'specs/juno/proposed/add-useful-metrics.rst', 'specs/juno/proposed/host-servers-live-migrate.rst', 'specs/juno/proposed/separated-policy-rule-v3-api.rst', 'specs/juno/proposed/libvirt-separate-virt-types-to-classes.rst', 'specs/juno/proposed/standardize-client-params.rst', 'specs/juno/proposed/add-delete-node-to-nova-manage.rst', 'specs/juno/proposed/add-support-for-cinder-scheduler-hints.rst', 'specs/juno/proposed/encrypted-live-migration-nova.rst', 'specs/juno/proposed/default-quotas.rst', 'specs/juno/proposed/policy-based-scheduing-engine.rst', 'specs/juno/proposed/nova-compute-multi-backend-support.rst', 'specs/juno/proposed/domain-quota-driver-v3-api.rst', 'specs/juno/proposed/synchronous-read-support.rst', 'specs/juno/proposed/incremental-instance-snapshot.rst', 'specs/juno/proposed/v2-api-detailed-quotas.rst', 'specs/juno/proposed/vnc-configurable-share-policy.rst', 'specs/juno/proposed/refactor-virt-capabilities.rst', 'specs/juno/proposed/virtio-scsi-settings.rst', 'specs/juno/proposed/nested-quota-driver-api-proposal-2.rst', 'specs/juno/proposed/remove-fakelibvirt.rst', 'specs/juno/proposed/slow-queries.rst', 'specs/juno/proposed/libvirt-storpool-volume-attach.rst', 'specs/juno/proposed/configure-tcp-keepalive.rst', 'specs/juno/proposed/flavor-cpu-overcommit.rst', 'specs/juno/proposed/ec2-volume-type.rst', 'specs/juno/proposed/flavor-quota-memory.rst', 'specs/juno/proposed/common-nova-metadata-cache.rst', 'specs/juno/proposed/scheduler-host-az-caching.rst', 'specs/juno/proposed/vcpus-in-api.rst', 'specs/juno/proposed/isolate-scheduler-db.rst', 'specs/juno/proposed/solver-scheduler.rst', 'specs/juno/proposed/usb-redirection.rst', 'specs/juno/proposed/periodic-heartbeat.rst', 'specs/juno/proposed/spot-instances.rst', 'specs/juno/proposed/associate-lru-fixed-ip-address.rst', 'specs/juno/proposed/idempotentcy-client-token.rst', 'specs/juno/proposed/lock-free-quota-management.rst', 'specs/juno/proposed/image-upload-module-plugin.rst', 'specs/juno/proposed/vm-cpu-pinning-support.rst', 'specs/juno/proposed/domain-quota-manage-commands.rst', 'specs/juno/proposed/ec2-volume-filtering.rst', 'specs/juno/proposed/vmware-encrypt-vcenter-passwords-proposal-2.rst', 'specs/juno/proposed/get-lock-status-of-instance.rst', 'specs/juno/proposed/cache-qos-monitoring.rst', 'specs/juno/proposed/vmware-vm-ref-refactor.rst', 'specs/juno/proposed/dynamic-adjust-disk-qos.rst', 'specs/juno/proposed/monitoring-ip-availability-proposal-3.rst', 'specs/juno/proposed/tenant-aggregate-exclusive-filter.rst', 'specs/juno/proposed/image-precacher.rst', 'specs/juno/proposed/usb-passthrough-proposal-2.rst', 'doc/source/index.rst', 'specs/juno/proposed/auto-disable-and-enable-hypervisor.rst', 'specs/juno/proposed/isnot-operator.rst', 'specs/juno/proposed/lvm-driver-for-shared-storage.rst', 'specs/juno/proposed/api-microversions.rst', 'specs/juno/proposed/support-keystone-v3-api.rst', 'specs/juno/proposed/add-force-detach-to-nova.rst', 'specs/juno/proposed/get-floatingip-by-all-tenants.rst', 'specs/juno/proposed/action-type-aware-scheduling.rst', 'specs/juno/proposed/add-delete-on-termination-option.rst', 'specs/juno/proposed/log-translation-hints.rst', 'specs/juno/proposed/audit-compute-node-on-controller-recovery.rst', 'specs/juno/proposed/server_http_proxy.rst', 'specs/juno/proposed/domain-quota-driver-api.rst', 'tests/test_titles.py', 'specs/juno/proposed/add-extra-specs-to-flavor-calls.rst', 'specs/juno/proposed/nic-state-aware-scheduling.rst', 'README.rst', 'specs/juno/proposed/keypair-x509-certificates.rst', 'specs/juno/proposed/server-snapshot-support.rst', 'specs/juno/proposed/virt-image-transfer-layer.rst', 'specs/juno/proposed/message-in-update-notifications.rst', 'specs/juno/proposed/change-instances-ownership-proposal-2.rst', 'specs/juno/proposed/cpu-allocation-per-flavor.rst', 'specs/juno/proposed/instance-boot.rst', 'specs/juno/proposed/use-glance-v2-api.rst', 'specs/juno/proposed/add-an-index-column-to-nova-list.rst', 'specs/juno/proposed/libvirt-hugepage.rst', 'specs/juno/proposed/neutron-migration.rst', 'specs/juno/proposed/new-libvirt-volume-driver-for-Huawei-SDSHypervisor.rst', 'specs/juno/proposed/pci-device-capability-aware-scheduling.rst', 'specs/juno/proposed/monitoring-ip-availability-proposal-1.rst', 'specs/juno/proposed/migrate-non-active-instances.rst', 'specs/juno/proposed/thunderboost-proposal-3.rst', 'specs/juno/proposed/add-ironic-boot-mode-filters.rst', 'specs/juno/proposed/log-guidelines.rst', 'specs/juno/proposed/freebsd-compute-node.rst', 'specs/juno/proposed/datastore-image-cache-update-improvements.rst', 'specs/juno/proposed/enchancement-virtio-scsi-support-for-volume.rst', 'specs/juno/proposed/vmware-resource-pool-enablement.rst', 'specs/juno/proposed/set-vm-swapfile-location.rst', 'specs/juno/proposed/metadata-service-network-info.rst', 'specs/juno/proposed/nodename-in-pci-device.rst', 'specs/juno/proposed/simultaneous-server-group.rst', 'specs/juno/proposed/no-downward-resize.rst', 'specs/juno/proposed/pci-hotplug-juno.rst', 'specs/juno/proposed/hyper-v-host-power-actions.rst', 'specs/juno/proposed/libvirt-ovs-use-usvhost.rst', 'specs/juno/proposed/restrict-image-types.rst', 'specs/juno/proposed/host-metric-hook.rst', 'specs/juno/proposed/libvirt-support-tpm-passthrough.rst', 'specs/juno/proposed/nested-quota-driver-api-proposal-1.rst', 'specs/juno/proposed/usb-passthrough-with-usb-controller.rst', 'specs/juno/proposed/add-transport-support-to-iscsi.rst', 'specs/juno/proposed/data-transfer-plugin.rst', 'specs/juno/proposed/shelf-snapshot-selection.rst', 'specs/juno/proposed/v3-api-neutron-network-support.rst', 'specs/juno/proposed/db-sync-models-with-migrations.rst', 'specs/juno/proposed/add-usb-controller.rst', 'specs/juno/proposed/pci-extra-info.rst', 'specs/juno/proposed/compute-node-metrics-api.rst', 'specs/juno/proposed/default-quota-flavor.rst', 'specs/juno/proposed/validate-tenant-user-with-keystone.rst', 'specs/juno/proposed/hot-resize.rst', 'specs/juno/proposed/per-flavor-quotas.rst', 'specs/juno/proposed/schedule-available-node-return.rst', 'specs/juno/proposed/deprecate-baremetal-driver.rst', 'specs/juno/proposed/libvirt-multiple-image-backends.rst', 'specs/juno/proposed/api-microversions-alt.rst', 'specs/juno/proposed/projects-to-aggregate.rst', 'specs/juno/proposed/use-configdrive-with-ironic.rst', 'specs/juno/proposed/cold-migrations-to-conductor-final.rst', 'specs/juno/proposed/virt-properties-object.rst', 'specs/juno/proposed/Audit-compute-node-on-controller-recovery.png', 'specs/juno/proposed/separate-stats-from-periodic-task.rst', 'specs/juno/proposed/docker-hypervisor-plugin.rst', 'specs/juno/proposed/hyper-v-generation-2-vms.rst', 'specs/juno/proposed/online-schema-changes.rst', 'specs/juno/proposed/ram-as-percentage.rst', 'specs/juno/proposed/nested-quota-driver-api-proposal-3.rst', 'specs/juno/proposed/extension-level-policy-as-default-v3-api.rst', 'specs/juno/proposed/dynamic-logging.rst', 'specs/juno/proposed/instance-level-snapshots.rst', 'specs/juno/proposed/storage-optimization-for-multi-datastore-clusters.rst', 'specs/juno/proposed/username-in-nova-list-for-admin-purpose.rst', 'specs/juno/proposed/default-schedule-zones.rst', 'specs/juno/proposed/online-volume-extend-extension.rst', 'specs/juno/proposed/add-utilization-based-weighers.rst', 'specs/juno/proposed/only-allow-admins-to-do-local-delete.rst', 'specs/juno/proposed/vmware-clone-image-handler.rst', 'specs/juno/proposed/libvirt-linux-net-refactor-for-freebsd.rst', 'specs/juno/proposed/compute-image-precache.rst', 'specs/juno/proposed/add-app-lock.rst', 'specs/juno/proposed/add-tags-for-os-resources.rst', 'specs/juno/proposed/user-project-metadata.rst', 'specs/juno/proposed/normalize-scheduler-weights-2.rst', 'specs/juno/proposed/console-tls-mode.rst', 'specs/juno/proposed/generate-vmstates-graph.rst', 'specs/juno/proposed/quota-state-management.rst', 'specs/juno/proposed/exclude-cbs-in-snapshot.rst', 'specs/juno/proposed/hyper-v-smbfs-volume-support.rst', 'specs/juno/proposed/no-migration-resize.rst', 'specs/juno/proposed/usb-hot-plug.rst', 'specs/juno/proposed/use-physical-cdrom.rst', 'specs/juno/proposed/internal-dns-resolution.rst', 'specs/juno/proposed/vmware-encrypt-vcenter-passwords-proposal-1.rst', 'specs/juno/proposed/usb-passthrough-proposal-1.rst', 'specs/juno/proposed/pxe-boot-instance.rst', 'specs/juno/proposed/cinder-events.rst', 'specs/juno/proposed/thunderboost-proposal-1.rst', 'specs/juno/proposed/monitoring-ip-availability-proposal-2.rst', 'specs/juno/proposed/specify-number-of-cores-per-socket.rst', 'specs/juno/proposed/change-instances-ownership-proposal-1.rst', 'specs/juno/proposed/persist-scheduler-hints.rst', 'specs/juno/proposed/dnsmasq-options-config.rst', 'specs/juno/proposed/creating-hyperv-ha-instances.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e647877e03bf040124ce43f11dc577467cc51f8b', 'message': ""Add proposed specs from the Juno cycle\n\nAdd proposed specs from the Juno cycle. I've done this because I\nworry about the case where a future developer wants to pick up\nsomething dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic.\n\nFor spec filenames where there was more than one review which\nproposed adding that file, I have added -proposal-[12345] to the\nend of the filename.\n\nChange-Id: Ie7dd7ed3550ab5a76d502ae9fdbd5566c0537813\n""}]",0,124930,e647877e03bf040124ce43f11dc577467cc51f8b,9,2,3,2271,,,0,"Add proposed specs from the Juno cycle

Add proposed specs from the Juno cycle. I've done this because I
worry about the case where a future developer wants to pick up
something dropped by a previous developer, but has trouble
finding previous proposed specifications on the topic.

For spec filenames where there was more than one review which
proposed adding that file, I have added -proposal-[12345] to the
end of the filename.

Change-Id: Ie7dd7ed3550ab5a76d502ae9fdbd5566c0537813
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/30/124930/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/juno/proposed/horizontally-scalable-scheduling.rst', 'specs/juno/proposed/emc-sdc-libvirt-driver.rst', 'specs/juno/proposed/multi-attach-volume.rst', 'specs/juno/proposed/hyper-v-rescue.rst', 'specs/juno/proposed/restrict-instance-migration.rst', 'specs/juno/proposed/add-support-for-cpu-hotadd.rst', 'specs/juno/proposed/thunderboost-proposal-2.rst', 'specs/juno/proposed/extends-nova-hypervisor.rst', 'specs/juno/proposed/nova-api-policy.rst', 'specs/juno/proposed/transfer-instance-ownership.rst', 'specs/juno/proposed/validate-targethost-live-migration.rst', 'specs/juno/proposed/metadata-service-callbacks.rst', 'specs/juno/proposed/instance-tasks-api.rst', 'specs/juno/proposed/nova-ephemeral-cinder.rst', 'specs/juno/proposed/gpfs-instance-store.rst', 'specs/juno/proposed/libvirt-smbfs-volume-support.rst', 'specs/juno/proposed/nova-api-extension-to-list-available-resources.rst', 'specs/juno/proposed/no-db-scheduler.rst', 'specs/juno/proposed/soft-affinity-for-server-group.rst', 'specs/juno/proposed/nova-vmware-vcdriver-nfs-image-copy.rst', 'specs/juno/proposed/rootwrap-daemon-mode.rst', 'specs/juno/proposed/hyper-v-remotefx.rst', 'specs/juno/proposed/pcs-support.rst', 'specs/juno/proposed/add-useful-metrics.rst', 'specs/juno/proposed/host-servers-live-migrate.rst', 'specs/juno/proposed/separated-policy-rule-v3-api.rst', 'specs/juno/proposed/libvirt-separate-virt-types-to-classes.rst', 'specs/juno/proposed/standardize-client-params.rst', 'specs/juno/proposed/add-delete-node-to-nova-manage.rst', 'specs/juno/proposed/add-support-for-cinder-scheduler-hints.rst', 'specs/juno/proposed/encrypted-live-migration-nova.rst', 'specs/juno/proposed/default-quotas.rst', 'specs/juno/proposed/policy-based-scheduing-engine.rst', 'specs/juno/proposed/nova-compute-multi-backend-support.rst', 'specs/juno/proposed/domain-quota-driver-v3-api.rst', 'specs/juno/proposed/synchronous-read-support.rst', 'specs/juno/proposed/incremental-instance-snapshot.rst', 'specs/juno/proposed/v2-api-detailed-quotas.rst', 'specs/juno/proposed/vnc-configurable-share-policy.rst', 'specs/juno/proposed/refactor-virt-capabilities.rst', 'specs/juno/proposed/virtio-scsi-settings.rst', 'specs/juno/proposed/nested-quota-driver-api-proposal-2.rst', 'specs/juno/proposed/remove-fakelibvirt.rst', 'specs/juno/proposed/slow-queries.rst', 'specs/juno/proposed/libvirt-storpool-volume-attach.rst', 'specs/juno/proposed/configure-tcp-keepalive.rst', 'specs/juno/proposed/flavor-cpu-overcommit.rst', 'specs/juno/proposed/ec2-volume-type.rst', 'specs/juno/proposed/flavor-quota-memory.rst', 'specs/juno/proposed/common-nova-metadata-cache.rst', 'specs/juno/proposed/scheduler-host-az-caching.rst', 'specs/juno/proposed/vcpus-in-api.rst', 'specs/juno/proposed/isolate-scheduler-db.rst', 'specs/juno/proposed/solver-scheduler.rst', 'specs/juno/proposed/usb-redirection.rst', 'specs/juno/proposed/periodic-heartbeat.rst', 'specs/juno/proposed/spot-instances.rst', 'specs/juno/proposed/associate-lru-fixed-ip-address.rst', 'specs/juno/proposed/idempotentcy-client-token.rst', 'specs/juno/proposed/lock-free-quota-management.rst', 'specs/juno/proposed/image-upload-module-plugin.rst', 'specs/juno/proposed/vm-cpu-pinning-support.rst', 'specs/juno/proposed/domain-quota-manage-commands.rst', 'specs/juno/proposed/ec2-volume-filtering.rst', 'specs/juno/proposed/vmware-encrypt-vcenter-passwords-proposal-2.rst', 'specs/juno/proposed/get-lock-status-of-instance.rst', 'specs/juno/proposed/cache-qos-monitoring.rst', 'specs/juno/proposed/vmware-vm-ref-refactor.rst', 'specs/juno/proposed/dynamic-adjust-disk-qos.rst', 'specs/juno/proposed/monitoring-ip-availability-proposal-3.rst', 'specs/juno/proposed/tenant-aggregate-exclusive-filter.rst', 'specs/juno/proposed/image-precacher.rst', 'specs/juno/proposed/usb-passthrough-proposal-2.rst', 'specs/juno/proposed/auto-disable-and-enable-hypervisor.rst', 'specs/juno/proposed/isnot-operator.rst', 'specs/juno/proposed/lvm-driver-for-shared-storage.rst', 'specs/juno/proposed/api-microversions.rst', 'specs/juno/proposed/support-keystone-v3-api.rst', 'specs/juno/proposed/add-force-detach-to-nova.rst', 'specs/juno/proposed/get-floatingip-by-all-tenants.rst', 'specs/juno/proposed/action-type-aware-scheduling.rst', 'specs/juno/proposed/add-delete-on-termination-option.rst', 'specs/juno/proposed/log-translation-hints.rst', 'specs/juno/proposed/audit-compute-node-on-controller-recovery.rst', 'specs/juno/proposed/server_http_proxy.rst', 'specs/juno/proposed/domain-quota-driver-api.rst', 'tests/test_titles.py', 'specs/juno/proposed/add-extra-specs-to-flavor-calls.rst', 'specs/juno/proposed/nic-state-aware-scheduling.rst', 'specs/juno/proposed/keypair-x509-certificates.rst', 'specs/juno/proposed/server-snapshot-support.rst', 'specs/juno/proposed/virt-image-transfer-layer.rst', 'specs/juno/proposed/message-in-update-notifications.rst', 'specs/juno/proposed/change-instances-ownership-proposal-2.rst', 'specs/juno/proposed/cpu-allocation-per-flavor.rst', 'specs/juno/proposed/instance-boot.rst', 'specs/juno/proposed/use-glance-v2-api.rst', 'specs/juno/proposed/add-an-index-column-to-nova-list.rst', 'specs/juno/proposed/libvirt-hugepage.rst', 'specs/juno/proposed/neutron-migration.rst', 'specs/juno/proposed/new-libvirt-volume-driver-for-Huawei-SDSHypervisor.rst', 'specs/juno/proposed/pci-device-capability-aware-scheduling.rst', 'specs/juno/proposed/monitoring-ip-availability-proposal-1.rst', 'specs/juno/proposed/migrate-non-active-instances.rst', 'specs/juno/proposed/thunderboost-proposal-3.rst', 'specs/juno/proposed/add-ironic-boot-mode-filters.rst', 'specs/juno/proposed/log-guidelines.rst', 'specs/juno/proposed/freebsd-compute-node.rst', 'specs/juno/proposed/datastore-image-cache-update-improvements.rst', 'specs/juno/proposed/enchancement-virtio-scsi-support-for-volume.rst', 'specs/juno/proposed/vmware-resource-pool-enablement.rst', 'specs/juno/proposed/set-vm-swapfile-location.rst', 'specs/juno/proposed/metadata-service-network-info.rst', 'specs/juno/proposed/nodename-in-pci-device.rst', 'specs/juno/proposed/simultaneous-server-group.rst', 'specs/juno/proposed/no-downward-resize.rst', 'specs/juno/proposed/pci-hotplug-juno.rst', 'specs/juno/proposed/hyper-v-host-power-actions.rst', 'specs/juno/proposed/libvirt-ovs-use-usvhost.rst', 'specs/juno/proposed/restrict-image-types.rst', 'specs/juno/proposed/host-metric-hook.rst', 'specs/juno/proposed/libvirt-support-tpm-passthrough.rst', 'specs/juno/proposed/nested-quota-driver-api-proposal-1.rst', 'specs/juno/proposed/usb-passthrough-with-usb-controller.rst', 'specs/juno/proposed/add-transport-support-to-iscsi.rst', 'specs/juno/proposed/data-transfer-plugin.rst', 'specs/juno/proposed/shelf-snapshot-selection.rst', 'specs/juno/proposed/v3-api-neutron-network-support.rst', 'specs/juno/proposed/db-sync-models-with-migrations.rst', 'specs/juno/proposed/add-usb-controller.rst', 'specs/juno/proposed/pci-extra-info.rst', 'specs/juno/proposed/compute-node-metrics-api.rst', 'specs/juno/proposed/default-quota-flavor.rst', 'specs/juno/proposed/validate-tenant-user-with-keystone.rst', 'specs/juno/proposed/hot-resize.rst', 'specs/juno/proposed/per-flavor-quotas.rst', 'specs/juno/proposed/schedule-available-node-return.rst', 'specs/juno/proposed/deprecate-baremetal-driver.rst', 'specs/juno/proposed/libvirt-multiple-image-backends.rst', 'specs/juno/proposed/api-microversions-alt.rst', 'specs/juno/proposed/projects-to-aggregate.rst', 'specs/juno/proposed/use-configdrive-with-ironic.rst', 'specs/juno/proposed/cold-migrations-to-conductor-final.rst', 'specs/juno/proposed/virt-properties-object.rst', 'specs/juno/proposed/Audit-compute-node-on-controller-recovery.png', 'specs/juno/proposed/separate-stats-from-periodic-task.rst', 'specs/juno/proposed/docker-hypervisor-plugin.rst', 'specs/juno/proposed/hyper-v-generation-2-vms.rst', 'specs/juno/proposed/online-schema-changes.rst', 'specs/juno/proposed/ram-as-percentage.rst', 'specs/juno/proposed/nested-quota-driver-api-proposal-3.rst', 'specs/juno/proposed/extension-level-policy-as-default-v3-api.rst', 'specs/juno/proposed/dynamic-logging.rst', 'specs/juno/proposed/instance-level-snapshots.rst', 'specs/juno/proposed/storage-optimization-for-multi-datastore-clusters.rst', 'specs/juno/proposed/username-in-nova-list-for-admin-purpose.rst', 'specs/juno/proposed/default-schedule-zones.rst', 'specs/juno/proposed/online-volume-extend-extension.rst', 'specs/juno/proposed/add-utilization-based-weighers.rst', 'specs/juno/proposed/only-allow-admins-to-do-local-delete.rst', 'specs/juno/proposed/vmware-clone-image-handler.rst', 'specs/juno/proposed/libvirt-linux-net-refactor-for-freebsd.rst', 'specs/juno/proposed/compute-image-precache.rst', 'specs/juno/proposed/add-app-lock.rst', 'specs/juno/proposed/add-tags-for-os-resources.rst', 'specs/juno/proposed/user-project-metadata.rst', 'specs/juno/proposed/normalize-scheduler-weights-2.rst', 'specs/juno/proposed/console-tls-mode.rst', 'specs/juno/proposed/generate-vmstates-graph.rst', 'specs/juno/proposed/quota-state-management.rst', 'specs/juno/proposed/exclude-cbs-in-snapshot.rst', 'specs/juno/proposed/hyper-v-smbfs-volume-support.rst', 'specs/juno/proposed/no-migration-resize.rst', 'specs/juno/proposed/usb-hot-plug.rst', 'specs/juno/proposed/use-physical-cdrom.rst', 'specs/juno/proposed/internal-dns-resolution.rst', 'specs/juno/proposed/vmware-encrypt-vcenter-passwords-proposal-1.rst', 'specs/juno/proposed/usb-passthrough-proposal-1.rst', 'specs/juno/proposed/pxe-boot-instance.rst', 'specs/juno/proposed/cinder-events.rst', 'specs/juno/proposed/thunderboost-proposal-1.rst', 'specs/juno/proposed/monitoring-ip-availability-proposal-2.rst', 'specs/juno/proposed/specify-number-of-cores-per-socket.rst', 'specs/juno/proposed/change-instances-ownership-proposal-1.rst', 'specs/juno/proposed/persist-scheduler-hints.rst', 'specs/juno/proposed/dnsmasq-options-config.rst', 'specs/juno/proposed/creating-hyperv-ha-instances.rst']",187,a7eed1ca92c92b1cd0c0c5862d4d7a9b5315c06c,archive-juno-proposals,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================================================== HyperV nova driver enhancement to create highly available instances =================================================================== https://blueprints.launchpad.net/nova/+spec/creating-hyperv-ha-instances This blueprint creating-hyperv-ha-instances allows creating of highly available instances in a HyperV hosts that are in a failover cluster. Highly available virtual machines are defined by the the document http://technet.microsoft.com/en-us/library/cc967323.aspx as 'Highly available virtual machines, also known as HAVMs, can easily be migrated to a different virtual machine host in a failover cluster to provide continuing service when their current host needs maintenance. If their current host fails, the HAVMs automatically migrate to a different host in the cluster through a process known as failover.' The following whitepaper provides more details. Failover Clustering in Windows Server 2008 R2 - Whitepaper Problem description =================== Existing HyperV nova driver does not provide the benefits available on HyperV hosts configured in a failover cluster and therefore when a host in the cluster fails the instance is not available to the user. Proposed change =============== Add support to configure high availability for an instance in the HyperV nova driver. This is done by modifying the instance creation steps in the following way * 1. Create instances on shared storage * 2. Configure the instance as highly available Also, the image cache should also be created on the shared storage A new boolean config option failover_clustering will be added. When the option is set to true, the proposed changes take effect. The user can override the config on a per instance basis by specifying the property hyperv_ha as false Alternatives for implementation of the proposed change * 1. Using the config option approach the existing driver behaviour can be modified without adding a new driver deriving from the existing driver. However with this approach, the implementation will have conditional switch since WMI calls to get cluster data are done using a different namespace and classes. * 2. Create a new driver that derives from the existing driver. Only override the methods that require changes. It is proposed to using alternative 1 described above since the changes are limited to spawn method. Configuration requirements that have to be met by the HyperV host for HA to work correctly (Ref: http://technet.microsoft.com/en-us/library/cc742396.aspx) Networking - All nodes in the same cluster must use the same name for the virtual network that provides external networking for the virtual machines. Processor - If the nodes in the cluster use different processor versions, make sure that the virtual machine is configured for processor compatibility. Security - All nodes in the cluster must use the same authorization policy. Storage - Must use shared storage that is supported by both the Failover Clustering feature and Hyper-V. Alternatives ------------ * 1. A single driver manages all the hosts in the cluster. The problem with this is the server hosting the nova-compute should always be available. To make this work the nova-compute service must be made a clustered service. * 2. The nova-compute runs in a VM that is hosted in a host in the cluster. This VM is configured as a highly available VM. The drawback of this approach is that the remote WMI are slow and therefore will impact the performance of the driver. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Instance deployments will have additional WMI calls done to detect the shared storage. However since the image cache is on the shared storage, the number of downloads from glance is reduced. Earlier each host has its own cache and therefore needed to download its own copy. Other deployer impact --------------------- None Developer impact ---------------- * This change only impacts the HyperV nova driver. Other drivers will not be impacted due to this change. Implementation ============== The connections are done to the root/MSCluster namespace First, the HA resource group of the VMs disk is obtained using the query ASSOCIATORS OF {MSCluster_Resource.Name=insert_disk_name_here} where ResultRole = GroupComponent ResultClass = MSCluster_ResourceGroup If its not part of a group a new group can be created using CreateGroup The resource is created using the CreateResource method The resource is brough online using BringOnline method Assignee(s) ----------- Primary assignee: kiran-kumar-vaddi Other contributors: Work Items ---------- * Modify the code the selects the location to spawn an instance to select only shared storage (Cluster Shared Volumes) * Enable HA on the instance before starting the instance * The image cache must be on shared storage Dependencies ============ None Testing ======= The unit tests will be modified to test the branches introduced by the above work items Documentation Impact ==================== A new boolean config option failover_clustering will be added. When the option is set to true, the instances are configured as highly available instances. The user can override the config on a per instance basis by specifying the property hyperv_ha as false. References ========== Failover Clusters in Windows Server 2008 R2 http://technet.microsoft.com/en-us/library/ff182338(v=ws.10).aspx Failover Clustering Overview (Win 2012 and Win 2012 R2) http://technet.microsoft.com/en-us/library/hh831579.aspx",,36011,0
openstack%2Fpuppet-nova~master~Id5c49cc11a4112c27621c72a7b2e6fcaf9da6aef,openstack/puppet-nova,master,Id5c49cc11a4112c27621c72a7b2e6fcaf9da6aef,Fix RedHat service provider conditional,MERGED,2014-10-16 05:56:50.000000000,2014-10-20 02:43:06.000000000,2014-10-20 00:38:11.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-10-16 05:56:50.000000000', 'files': ['manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/9a5a540738f887f87886ae4f9f52d5ade1b26bc7', 'message': ""Fix RedHat service provider conditional\n\nWithout this patch, params.pp conditionally uses 'RedHat' as a matching\ncondition to $::operatingsystem for two different cases, and will match\non the first case. This is a problem because it will prevent the proper\nservice provider from being assigned on RedHat operating systems with\nmajor version < 7. This patch removes RedHat from the first case so that\nRedHat operating systems will match on the second case and assign the\ninit service provider if the major version is < 7.\n\nChange-Id: Id5c49cc11a4112c27621c72a7b2e6fcaf9da6aef\n""}]",0,128834,9a5a540738f887f87886ae4f9f52d5ade1b26bc7,9,4,1,8482,,,0,"Fix RedHat service provider conditional

Without this patch, params.pp conditionally uses 'RedHat' as a matching
condition to $::operatingsystem for two different cases, and will match
on the first case. This is a problem because it will prevent the proper
service provider from being assigned on RedHat operating systems with
major version < 7. This patch removes RedHat from the first case so that
RedHat operating systems will match on the second case and assign the
init service provider if the major version is < 7.

Change-Id: Id5c49cc11a4112c27621c72a7b2e6fcaf9da6aef
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/34/128834/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/params.pp'],1,9a5a540738f887f87886ae4f9f52d5ade1b26bc7,, 'Fedora': {," 'Fedora', 'RedHat': {",1,1
openstack%2Fpuppet-nova~master~I2a43c43e4d9d16446fb000ff3a7644d815be478c,openstack/puppet-nova,master,I2a43c43e4d9d16446fb000ff3a7644d815be478c,fixtures: Fix puppet-mysql fixture branch,MERGED,2014-09-27 09:42:06.000000000,2014-10-20 01:55:09.000000000,2014-10-20 01:55:08.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}]","[{'number': 1, 'created': '2014-09-27 09:42:06.000000000', 'files': ['.fixtures.yml'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/caa645dcb65ea7b24950615a37bf9a5e2a51ac46', 'message': ""fixtures: Fix puppet-mysql fixture branch\n\nThe remote branch origin/2.x doesn't exist for puppetlabs-mysql module\n\nChange-Id: I2a43c43e4d9d16446fb000ff3a7644d815be478c\n""}]",0,124582,caa645dcb65ea7b24950615a37bf9a5e2a51ac46,7,3,1,7155,,,0,"fixtures: Fix puppet-mysql fixture branch

The remote branch origin/2.x doesn't exist for puppetlabs-mysql module

Change-Id: I2a43c43e4d9d16446fb000ff3a7644d815be478c
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/82/124582/1 && git format-patch -1 --stdout FETCH_HEAD,['.fixtures.yml'],1,caa645dcb65ea7b24950615a37bf9a5e2a51ac46,fixtures, ref: 'origin/2.2.x', ref: 'origin/2.x',1,1
openstack%2Fpuppet-keystone~master~Ie327b8ca4f0f8026582530a9aefe5f0d184f92e2,openstack/puppet-keystone,master,Ie327b8ca4f0f8026582530a9aefe5f0d184f92e2,Add more config options for pki signing,MERGED,2014-10-16 17:30:11.000000000,2014-10-20 01:52:25.000000000,2014-10-20 01:52:25.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-10-16 17:30:11.000000000', 'files': ['spec/classes/keystone_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/14590637f26401a3531bcbd49b634e2d311681c3', 'message': 'Add more config options for pki signing\n\n* add config signing/cert_subject\n* add config signing/key_size\n* use default values from keystone\n\nChange-Id: Ie327b8ca4f0f8026582530a9aefe5f0d184f92e2\n'}]",0,129003,14590637f26401a3531bcbd49b634e2d311681c3,7,3,1,10536,,,0,"Add more config options for pki signing

* add config signing/cert_subject
* add config signing/key_size
* use default values from keystone

Change-Id: Ie327b8ca4f0f8026582530a9aefe5f0d184f92e2
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/03/129003/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_spec.rb', 'manifests/init.pp']",2,14590637f26401a3531bcbd49b634e2d311681c3,add_key_size,"# [*signing_cert_subject*] # (optional) Certificate subject (auto generated certificate) for token signing. # Defaults to '/C=US/ST=Unset/L=Unset/O=Unset/CN=www.example.com' # # [*signing_key_size*] # (optional) Key size (in bits) for token signing cert (auto generated certificate) # Defaults to 2048 # $signing_cert_subject = '/C=US/ST=Unset/L=Unset/O=Unset/CN=www.example.com', $signing_key_size = 2048, 'signing/certfile': value => $signing_certfile; 'signing/keyfile': value => $signing_keyfile; 'signing/ca_certs': value => $signing_ca_certs; 'signing/ca_key': value => $signing_ca_key; 'signing/cert_subject': value => $signing_cert_subject; 'signing/key_size': value => $signing_key_size;", 'signing/certfile': value => $signing_certfile; 'signing/keyfile': value => $signing_keyfile; 'signing/ca_certs': value => $signing_ca_certs; 'signing/ca_key': value => $signing_ca_key;,50,18
openstack%2Fpuppet-glance~stable%2Ficehouse~I97cd3cea46a4d9225d25d833477cb931abeb70a5,openstack/puppet-glance,stable/icehouse,I97cd3cea46a4d9225d25d833477cb931abeb70a5,Release 4.2.0,MERGED,2014-10-16 22:13:18.000000000,2014-10-20 01:47:35.000000000,2014-10-20 00:35:46.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-10-16 22:13:18.000000000', 'files': ['Modulefile', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/b8d2ee72a43025e5b1a0201c65072746c8b9ce05', 'message': 'Release 4.2.0\n\nChanges:\n- Added ability to hide secret type parameters from logs\n\nChange-Id: I97cd3cea46a4d9225d25d833477cb931abeb70a5\n'}]",0,129077,b8d2ee72a43025e5b1a0201c65072746c8b9ce05,7,4,1,8482,,,0,"Release 4.2.0

Changes:
- Added ability to hide secret type parameters from logs

Change-Id: I97cd3cea46a4d9225d25d833477cb931abeb70a5
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/77/129077/1 && git format-patch -1 --stdout FETCH_HEAD,"['Modulefile', 'README.md']",2,b8d2ee72a43025e5b1a0201c65072746c8b9ce05,stable/icehouse-release,4.2.0 - 2014.1.0 - Icehouse**4.2.0** * Added ability to hide secret type parameters from logs ,4.0.0 - 2014.1.0 - Icehouse,6,2
openstack%2Fpuppet-cinder~stable%2Ficehouse~Iba8d63574624551fbcb5b7718e4d799ec9fd7c27,openstack/puppet-cinder,stable/icehouse,Iba8d63574624551fbcb5b7718e4d799ec9fd7c27,Release 4.2.0,MERGED,2014-10-16 22:12:40.000000000,2014-10-20 01:47:34.000000000,2014-10-20 00:29:43.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-10-16 22:12:40.000000000', 'files': ['Modulefile', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/60181504a7c6ffc6cde90f2fa5c607dfbb8f9342', 'message': 'Release 4.2.0\n\nChanges:\n- Added parameters to set cinder volume driver\n- Added class for extended logging options\n- Added option to specify endpoint protocol\n- Fixed cinder type path issues\n- Added option to specify cinder volume path\n- Fixed targetcli package dependency on target service\n- Fixed os version fact comparison for RedHat-based operating systems\n  for specifying service provider\n- Added option to configure os_region_name in the cinder config\n\nChange-Id: Iba8d63574624551fbcb5b7718e4d799ec9fd7c27\n'}]",0,129076,60181504a7c6ffc6cde90f2fa5c607dfbb8f9342,7,4,1,8482,,,0,"Release 4.2.0

Changes:
- Added parameters to set cinder volume driver
- Added class for extended logging options
- Added option to specify endpoint protocol
- Fixed cinder type path issues
- Added option to specify cinder volume path
- Fixed targetcli package dependency on target service
- Fixed os version fact comparison for RedHat-based operating systems
  for specifying service provider
- Added option to configure os_region_name in the cinder config

Change-Id: Iba8d63574624551fbcb5b7718e4d799ec9fd7c27
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/76/129076/1 && git format-patch -1 --stdout FETCH_HEAD,"['Modulefile', 'README.md']",2,60181504a7c6ffc6cde90f2fa5c607dfbb8f9342,stable/icehouse-release,4.2.0 - 2014.1.0 - Icehouse**4.2.0** * Added parameters to set cinder volume driver * Added class for extended logging options * Added option to specify endpoint protocol * Fixed cinder type path issues * Added option to specify cinder volume path * Fixed targetcli package dependency on target service * Fixed os version fact comparison for RedHat-based operating systems for specifying service provider * Added option to configure os_region_name in the cinder config ,4.0.0 - 2014.1.0 - Icehouse,14,2
openstack%2Fpuppet-ceilometer~stable%2Ficehouse~I5c8e77ef57925464db765a9c94376c8cf0790ec6,openstack/puppet-ceilometer,stable/icehouse,I5c8e77ef57925464db765a9c94376c8cf0790ec6,Release 4.2.0,MERGED,2014-10-16 22:11:50.000000000,2014-10-20 01:47:34.000000000,2014-10-20 00:27:42.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-10-16 22:11:50.000000000', 'files': ['Modulefile', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/a8ad6b74420ae228ea635a0d3a97d6ceaa7cc25a', 'message': 'Release 4.2.0\n\nChanges:\n- Fixed dependency on nova-common package\n- Added new class for extended logging options\n- Fixed ssl parameter requirements for kombu and rabbit\n- Fixed mysql_grant call\n- Fixed ceilometer-collecter service relationships when service is disabled\n\nChange-Id: I5c8e77ef57925464db765a9c94376c8cf0790ec6\n'}]",0,129075,a8ad6b74420ae228ea635a0d3a97d6ceaa7cc25a,8,4,1,8482,,,0,"Release 4.2.0

Changes:
- Fixed dependency on nova-common package
- Added new class for extended logging options
- Fixed ssl parameter requirements for kombu and rabbit
- Fixed mysql_grant call
- Fixed ceilometer-collecter service relationships when service is disabled

Change-Id: I5c8e77ef57925464db765a9c94376c8cf0790ec6
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/75/129075/1 && git format-patch -1 --stdout FETCH_HEAD,"['Modulefile', 'README.md']",2,a8ad6b74420ae228ea635a0d3a97d6ceaa7cc25a,stable/icehouse-release,4.2.0 - 2014.1.0 - Icehouse** 4.2.0 ** * Fixed dependency on nova-common package * Added new class for extended logging options * Fixed ssl parameter requirements for kombu and rabbit * Fixed mysql_grant call * Fixed ceilometer-collecter service relationships when service is disabled ,4.0.0 - 2014.1.0 - Icehouse,11,2
openstack%2Fpuppet-neutron~stable%2Ficehouse~I72ae1dbae93167f2984fbfc82e7c3ffda3cb6409,openstack/puppet-neutron,stable/icehouse,I72ae1dbae93167f2984fbfc82e7c3ffda3cb6409,Release 4.3.0,MERGED,2014-10-16 22:15:29.000000000,2014-10-20 01:33:13.000000000,2014-10-20 01:33:13.000000000,"[{'_account_id': 3}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 8482}]","[{'number': 1, 'created': '2014-10-16 22:15:29.000000000', 'files': ['Modulefile', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/fb9028f121e63a59c32dbcd59e86fc0bf43a4bb6', 'message': 'Release 4.3.0\n\n- Added parameter to specify number of RPC workers to spawn\n- Added ability to manage Neutron ML2 plugin\n- Fixed ssl parameter requirements when using kombu and rabbit\n- Added ability to hide secret neutron configs from logs and fixed password leaking\n- Added neutron plugin config file specification in neutron-server config\n- Fixed installation of ML2 plugin on Ubuntu\n- Added support for Cisco ML2 Mech Driver\n- Fixed quotas parameters in neutron config\n- Added parameter to configure dhcp_agent_notification in neutron config\n- Added class for linuxbridge support\n- Fixed neutron-server restart\n- Undeprecated enable_security_group parameter\n\nChange-Id: I72ae1dbae93167f2984fbfc82e7c3ffda3cb6409\n'}]",0,129081,fb9028f121e63a59c32dbcd59e86fc0bf43a4bb6,9,4,1,8482,,,0,"Release 4.3.0

- Added parameter to specify number of RPC workers to spawn
- Added ability to manage Neutron ML2 plugin
- Fixed ssl parameter requirements when using kombu and rabbit
- Added ability to hide secret neutron configs from logs and fixed password leaking
- Added neutron plugin config file specification in neutron-server config
- Fixed installation of ML2 plugin on Ubuntu
- Added support for Cisco ML2 Mech Driver
- Fixed quotas parameters in neutron config
- Added parameter to configure dhcp_agent_notification in neutron config
- Added class for linuxbridge support
- Fixed neutron-server restart
- Undeprecated enable_security_group parameter

Change-Id: I72ae1dbae93167f2984fbfc82e7c3ffda3cb6409
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/81/129081/1 && git format-patch -1 --stdout FETCH_HEAD,"['Modulefile', 'README.md']",2,fb9028f121e63a59c32dbcd59e86fc0bf43a4bb6,stable/icehouse-release,4.3.0 - 2014.1.0 - Icehouse**4.3.0** * Added parameter to specify number of RPC workers to spawn * Added ability to manage Neutron ML2 plugin * Fixed ssl parameter requirements when using kombu and rabbit * Added ability to hide secret neutron configs from logs and fixed password leaking * Added neutron plugin config file specification in neutron-server config * Fixed installation of ML2 plugin on Ubuntu * Added support for Cisco ML2 Mech Driver * Fixed quotas parameters in neutron config * Added parameter to configure dhcp_agent_notification in neutron config * Added class for linuxbridge support * Fixed neutron-server restart * Undeprecated enable_security_group parameter ,4.0.0 - 2014.1.0 - Icehouse,17,2
openstack%2Fkeystone~master~Ib861ac8c9fbb613f8030cc25970f6ddc285d4c3b,openstack/keystone,master,Ib861ac8c9fbb613f8030cc25970f6ddc285d4c3b,Remove check_password() in identity.backend.ldap,MERGED,2014-10-17 01:15:51.000000000,2014-10-20 01:19:25.000000000,2014-10-20 01:19:24.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 6486}, {'_account_id': 9098}]","[{'number': 1, 'created': '2014-10-17 01:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/99b64fc9de90bb0e807329bf254acff99bd0f384', 'message': 'Remove check_password() in identity.backend.ldap\n\nPassword check is handled directly to ldap. This method is\nnot used at all.\n\nChange-Id: Ib861ac8c9fbb613f8030cc25970f6ddc285d4c3b\n'}, {'number': 2, 'created': '2014-10-17 02:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2ae31744d60698cd6463c7359d3983e19c86a632', 'message': 'Remove check_password() in identity.backend.ldap\n\nPassword check is handled directly to ldap. This method is\nnot used at all.\n\nChange-Id: Ib861ac8c9fbb613f8030cc25970f6ddc285d4c3b\n'}, {'number': 3, 'created': '2014-10-17 02:28:09.000000000', 'files': ['keystone/identity/backends/sql.py', 'keystone/identity/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/8fb62f7b0edff8aecd12f4a3eaffe742b29a40db', 'message': 'Remove check_password() in identity.backend.ldap\n\nPassword check is handled directly to ldap. This method is\nnot used at all.\n\nChange-Id: Ib861ac8c9fbb613f8030cc25970f6ddc285d4c3b\n'}]",0,129103,8fb62f7b0edff8aecd12f4a3eaffe742b29a40db,13,4,3,1941,,,0,"Remove check_password() in identity.backend.ldap

Password check is handled directly to ldap. This method is
not used at all.

Change-Id: Ib861ac8c9fbb613f8030cc25970f6ddc285d4c3b
",git fetch https://review.opendev.org/openstack/keystone refs/changes/03/129103/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/identity/backends/ldap.py'],1,99b64fc9de90bb0e807329bf254acff99bd0f384,identity_ldap_cleanup,," def check_password(self, user_id, password): user = self.get(user_id) return utils.check_password(password, user.password) ",0,4
openstack%2Fpuppet-keystone~stable%2Ficehouse~If8c279cf544e1886428432c2feb4bdd2303e5185,openstack/puppet-keystone,stable/icehouse,If8c279cf544e1886428432c2feb4bdd2303e5185,Release 4.2.0,MERGED,2014-10-16 22:15:03.000000000,2014-10-20 01:05:21.000000000,2014-10-20 01:05:21.000000000,"[{'_account_id': 3}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 8482}]","[{'number': 1, 'created': '2014-10-16 22:15:03.000000000', 'files': ['Modulefile', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a46d1260e09c545453df7cf53f9118f1e0982536', 'message': 'Release 4.2.0\n\nChanges:\n- Added class for extended logging options\n- Fixed rabbit password leaking\n- Added parameters to set tenant descriptions\n- Fixed keystone user authorization error handling\n\nChange-Id: If8c279cf544e1886428432c2feb4bdd2303e5185\n'}]",0,129080,a46d1260e09c545453df7cf53f9118f1e0982536,9,4,1,8482,,,0,"Release 4.2.0

Changes:
- Added class for extended logging options
- Fixed rabbit password leaking
- Added parameters to set tenant descriptions
- Fixed keystone user authorization error handling

Change-Id: If8c279cf544e1886428432c2feb4bdd2303e5185
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/80/129080/1 && git format-patch -1 --stdout FETCH_HEAD,"['Modulefile', 'README.md']",2,a46d1260e09c545453df7cf53f9118f1e0982536,stable/icehouse-release,4.2.0 - 2014.1.0 - Icehouse**4.2.0** * Added class for extended logging options * Fixed rabbit password leaking * Added parameters to set tenant descriptions * Fixed keystone user authorization error handling ,4.0.0 - 2014.1.0 - Icehouse,9,2
openstack%2Fpython-keystoneclient~master~Ibebc28aa0697879b00437c5efe31e1c0d7c4c29d,openstack/python-keystoneclient,master,Ibebc28aa0697879b00437c5efe31e1c0d7c4c29d,Fix mappings.Mapping docstring,MERGED,2014-10-15 11:43:40.000000000,2014-10-20 00:51:26.000000000,2014-10-20 00:51:25.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7186}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 11022}]","[{'number': 1, 'created': '2014-10-15 11:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/28d518f937ea59747b71fed24bc3f93c16a79c99', 'message': 'Fix mappings.Mapping docstring\n\nRules examples in ``create`` and ``update`` methods should be list of\nrules, as this is what should be passed as an argument.\n\nChange-Id: Ibebc28aa0697879b00437c5efe31e1c0d7c4c29d\n'}, {'number': 2, 'created': '2014-10-16 06:49:14.000000000', 'files': ['keystoneclient/v3/contrib/federation/mappings.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/d5ec4f725030538d44ecf914e48e12e1ee7bfa78', 'message': 'Fix mappings.Mapping docstring\n\nRules examples in ``create`` and ``update`` methods should be list of\nrules, as this is what should be passed as an argument.\n\nChange-Id: Ibebc28aa0697879b00437c5efe31e1c0d7c4c29d\n'}]",7,128615,d5ec4f725030538d44ecf914e48e12e1ee7bfa78,15,9,2,8978,,,0,"Fix mappings.Mapping docstring

Rules examples in ``create`` and ``update`` methods should be list of
rules, as this is what should be passed as an argument.

Change-Id: Ibebc28aa0697879b00437c5efe31e1c0d7c4c29d
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/15/128615/2 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/v3/contrib/federation/mappings.py'],1,28d518f937ea59747b71fed24bc3f93c16a79c99,mapping_docs," :param rules: a JSON dictionary with list of mapping rules. Example of the ``rules`` parameter:: [ { ""local"": [ { ""group"": { ""id"": ""0cd5e9"" } } ], ""remote"": [ { ""type"": ""orgPersonType"", ""not_any_of"": [ ""Contractor"", ""Guest"" ] } ] } ] :param rules: a JSON dictionary with a list of mapping rules. Example of the ``rules`` parameter:: [ { ""local"": [ { ""group"": { ""id"": ""0cd5e9"" } } ], ""remote"": [ { ""type"": ""orgPersonType"", ""not_any_of"": [ ""Contractor"", ""Guest"" ] } ] } ]"," :param rules: a JSON dictionary with list a list of mapping rules. Example of the ``rules``:: { ""mapping"": { ""rules"": [ { ""local"": [ { ""group"": { ""id"": ""0cd5e9"" } } ], ""remote"": [ { ""type"": ""orgPersonType"", ""not_any_of"": [ ""Contractor"", ""Guest"" ] } ] } ] } } :param rules: a JSON dictionary with list a list of mapping rules. Example of the ``rules``:: { ""mapping"": { ""rules"": [ { ""local"": [ { ""group"": { ""id"": ""0cd5e9"" } } ], ""remote"": [ { ""type"": ""orgPersonType"", ""not_any_of"": [ ""Contractor"", ""Guest"" ] } ] } ] } }",45,54
openstack%2Fpython-openstackclient~master~I006a5b8c3a399ad38873cf6eaa8578965cf493ce,openstack/python-openstackclient,master,I006a5b8c3a399ad38873cf6eaa8578965cf493ce,client should not change os_url,ABANDONED,2014-10-17 08:18:24.000000000,2014-10-20 00:46:11.000000000,,"[{'_account_id': 3}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-10-17 08:18:24.000000000', 'files': ['openstackclient/image/client.py', 'openstackclient/shell.py', 'openstackclient/network/client.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/470ffde05af2ea331f15bbd258a40e114d424da8', 'message': 'client should not change os_url\n\nThe os_url only can be specified by user, the client should not change\nit. And, different service has diffrent endpoint, the change does not\nmake any sense.\n\nChange-Id: I006a5b8c3a399ad38873cf6eaa8578965cf493ce\n'}]",3,129160,470ffde05af2ea331f15bbd258a40e114d424da8,4,2,1,9101,,,0,"client should not change os_url

The os_url only can be specified by user, the client should not change
it. And, different service has diffrent endpoint, the change does not
make any sense.

Change-Id: I006a5b8c3a399ad38873cf6eaa8578965cf493ce
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/60/129160/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/image/client.py', 'openstackclient/shell.py', 'openstackclient/network/client.py']",3,470ffde05af2ea331f15bbd258a40e114d424da8,url," if instance._url: endpoint = instance._url else: endpoint = instance.get_endpoint_for_service_type( endpoint_url=endpoint,"," if not instance._url: instance._url = instance.get_endpoint_for_service_type( endpoint_url=instance._url,",14,7
openstack%2Fpython-openstackclient~master~Ia742c62ad6605b57a43f433bc3cc700a18775d4f,openstack/python-openstackclient,master,Ia742c62ad6605b57a43f433bc3cc700a18775d4f,enable region option for 'object_store' and 'image' service,ABANDONED,2014-10-17 06:58:15.000000000,2014-10-20 00:46:01.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-10-17 06:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/5de38abec21e32a554c119997e504fc380f19b55', 'message': ""enable region name option for 'object_store' and 'image' service\n\nChange-Id: Ia742c62ad6605b57a43f433bc3cc700a18775d4f\n""}, {'number': 2, 'created': '2014-10-17 06:59:17.000000000', 'files': ['openstackclient/image/client.py', 'openstackclient/object/client.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/1965c29b77e6ad01447af3b0d9bd091faee77b0e', 'message': ""enable region option for 'object_store' and 'image' service\n\nChange-Id: Ia742c62ad6605b57a43f433bc3cc700a18775d4f\n""}]",1,129150,1965c29b77e6ad01447af3b0d9bd091faee77b0e,8,4,2,9101,,,0,"enable region option for 'object_store' and 'image' service

Change-Id: Ia742c62ad6605b57a43f433bc3cc700a18775d4f
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/50/129150/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/image/client.py', 'openstackclient/object/client.py']",2,5de38abec21e32a554c119997e504fc380f19b55,endpoint," endpoint = instance.get_endpoint_for_service_type( 'object-store', region_name=instance._region_name)"," endpoint = instance.get_endpoint_for_service_type(""object-store"")",4,2
openstack%2Fpuppet-horizon~stable%2Ficehouse~Icba9aad7c21da0ae6ec77a25bccd6018211e8632,openstack/puppet-horizon,stable/icehouse,Icba9aad7c21da0ae6ec77a25bccd6018211e8632,Release 4.2.0,MERGED,2014-10-16 22:14:32.000000000,2014-10-20 00:39:05.000000000,2014-10-20 00:39:04.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-10-16 22:14:32.000000000', 'files': ['Modulefile', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/0504a12a34084bc5c94842da3d42aa2f434e38be', 'message': 'Release 4.2.0\n\nChanges:\n- Added parameters to configure ALLOWED_HOSTS in settings_local.y and\n  ServerAlias in apache, no longer requiring these values to be the fqdn\n- Fixed removal of vhost conf file\n- Added support for secure cookies\n\nChange-Id: Icba9aad7c21da0ae6ec77a25bccd6018211e8632\n'}]",1,129079,0504a12a34084bc5c94842da3d42aa2f434e38be,8,4,1,8482,,,0,"Release 4.2.0

Changes:
- Added parameters to configure ALLOWED_HOSTS in settings_local.y and
  ServerAlias in apache, no longer requiring these values to be the fqdn
- Fixed removal of vhost conf file
- Added support for secure cookies

Change-Id: Icba9aad7c21da0ae6ec77a25bccd6018211e8632
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/79/129079/1 && git format-patch -1 --stdout FETCH_HEAD,"['Modulefile', 'README.md']",2,0504a12a34084bc5c94842da3d42aa2f434e38be,stable/icehouse-release,"4.2.0 - 2014.1.0 - Icehouse**4.2.0** * Added parameters to configure ALLOWED_HOSTS in settings_local.y and ServerAlias in apache, no longer requiring these values to be the fqdn * Fixed removal of vhost conf file * Added support for secure cookies ",4.0.0 - 2014.1.0 - Icehouse,9,2
openstack%2Fheat-specs~master~Ib676e51a022fbe947901bb30d5d096e9f9aa316c,openstack/heat-specs,master,Ib676e51a022fbe947901bb30d5d096e9f9aa316c,heat-manage service list,MERGED,2014-09-19 03:38:24.000000000,2014-10-20 00:37:11.000000000,2014-10-20 00:37:10.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 6899}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 10487}]","[{'number': 1, 'created': '2014-09-19 03:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/610b96cf7ac50e5a205fbac46e521505d7c870d9', 'message': 'heat-manage service list\n\nAdds the service list capability to the heat-manage\ncommand to provide required details about heat-engine\ndeployed on a given cloud environment.\n\nChange-Id: Ib676e51a022fbe947901bb30d5d096e9f9aa316c\n'}, {'number': 2, 'created': '2014-09-22 03:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/7c2a7ed317d20c035e4ef6bbfb8bb454c13e9e27', 'message': 'heat-manage service list\n\nAdds the service list capability to the heat-manage\ncommand to provide required details about heat-engine\ndeployed on a given cloud environment.\n\nChange-Id: Ib676e51a022fbe947901bb30d5d096e9f9aa316c\n'}, {'number': 3, 'created': '2014-09-22 03:48:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/82d53039e7c149baa5966b0e5d5022408723b262', 'message': 'heat-manage service list\n\nAdds the service list capability to the heat-manage\ncommand to provide required details about heat-engine\ndeployed on a given cloud environment.\n\nChange-Id: Ib676e51a022fbe947901bb30d5d096e9f9aa316c\n'}, {'number': 4, 'created': '2014-09-23 09:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/28d6ddbc6de76b249df129d66c37b7730a6239e7', 'message': ""heat-manage service list\n\nAdds the service list capability to the heat-manage\ncommand to provide required details about heat-engine\ndeployed on a given cloud environment.\n\nIt also enable the same functioanlity in command line\ninterface 'heat service-list'\n\nChange-Id: Ib676e51a022fbe947901bb30d5d096e9f9aa316c\n""}, {'number': 5, 'created': '2014-09-26 04:39:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/123a11a363573c5cca78b526cbfe4b41d8b2faff', 'message': ""heat-manage service list\n\nAdds the service list capability to the heat-manage\ncommand to provide required details about heat-engine\ndeployed on a given cloud environment.\n\nIt also enable the same functioanlity in command line\ninterface 'heat service-list'\n\nChange-Id: Ib676e51a022fbe947901bb30d5d096e9f9aa316c\n""}, {'number': 6, 'created': '2014-09-27 06:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/409aceec6563e41b711d927721c57879bdb24cdf', 'message': ""heat-manage service list\n\nAdds the service list capability to the heat-manage\ncommand to provide required details about heat-engine\ndeployed on a given cloud environment.\n\nIt also enable the same functioanlity in command line\ninterface 'heat service-list'\n\nChange-Id: Ib676e51a022fbe947901bb30d5d096e9f9aa316c\n""}, {'number': 7, 'created': '2014-10-08 10:07:41.000000000', 'files': ['specs/kilo/heat-manage-service-list.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/d63eddefbf3138b2f24f24ef2682fcc108e615a0', 'message': ""heat-manage service list\n\nAdds the service list capability to the heat-manage\ncommand to provide required details about heat-engine\ndeployed on a given cloud environment.\n\nIt also enable the same functioanlity in command line\ninterface 'heat service-list'\n\nChange-Id: Ib676e51a022fbe947901bb30d5d096e9f9aa316c\n""}]",25,122597,d63eddefbf3138b2f24f24ef2682fcc108e615a0,37,8,7,10487,,,0,"heat-manage service list

Adds the service list capability to the heat-manage
command to provide required details about heat-engine
deployed on a given cloud environment.

It also enable the same functioanlity in command line
interface 'heat service-list'

Change-Id: Ib676e51a022fbe947901bb30d5d096e9f9aa316c
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/97/122597/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/heat-manage-service-list.rst'],1,610b96cf7ac50e5a205fbac46e521505d7c870d9,heat-manage-service-list,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================== Heat-manage service list ======================== https://blueprints.launchpad.net/heat/+spec/heat-manage-service-list Adds the ability to heat-manage command to list the running status of heat-engines deployed in a given cloud environment. Problem description =================== In a given enterprise cloud environment, Heat to support horizontal scaling, multiple heat-engines will be deployed and executed. Once these engines are deployed on multiple hosts, there is no way an admin can find these heat engines details like * what is the node on which heat engine is running, * what is and its running status. * How long the heat-engines are running successfully. Proposed change =============== Heat already provides heat-manage command to take care of the database syncing and archiving. As part of this blue print, 'service list' is added to provide the following details: * Heat-engine node details * Heat-engine running status * Heat-engine host (message queue) * Heat-engine last updated time of running status. Alternatives ------------ No alternative exist today. Implementation ============== Assignee(s) ----------- Kanagaraj Manickam (kanagaraj-manickam) Milestones ---------- Target Milestone for completion: Kilo-1 Work Items ---------- * Add required db migration script to add the new table 'Services' * Add 'Service' model in the sqlalchemy and required db api * Update the heat-engine service for updating the db at given periodic interval * Add 'service list' to heat.cmd.manage and it required help * Add required test cases Dependencies ============ None ",,69,0
openstack%2Fneutron~master~Ifb0a1a38e33f9073a78658ca578fbd2a42747724,openstack/neutron,master,Ifb0a1a38e33f9073a78658ca578fbd2a42747724,Add pylint tox environment and disable all existing warnings,MERGED,2014-08-20 03:44:48.000000000,2014-10-19 23:54:36.000000000,2014-10-18 08:57:58.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 2031}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6695}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8411}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10624}, {'_account_id': 10692}, {'_account_id': 11279}, {'_account_id': 12040}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-20 03:44:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4211c47fee696b772d5f51e57a72b28801ec5e6b', 'message': 'Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n'}, {'number': 2, 'created': '2014-08-25 00:25:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9bf184c59ee14948d7f127e6cc6ac065c83e539a', 'message': 'Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n'}, {'number': 3, 'created': '2014-08-27 01:11:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cc8b628dbd799414bb7d7703f1f0bc0d222a40d7', 'message': 'Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n'}, {'number': 4, 'created': '2014-08-27 01:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3af2f4e056369bfeabc8de719faf06e3eae2b3c7', 'message': 'Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n'}, {'number': 5, 'created': '2014-08-29 01:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b8c1f9219d9c761acf28cdeadf93d138cb6bbcfe', 'message': 'Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n'}, {'number': 6, 'created': '2014-08-29 13:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cc91b8cb25c9838c4acc766c4ffceec034d69043', 'message': 'Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n'}, {'number': 7, 'created': '2014-08-31 12:33:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b125a458c4f488d81fedf5b94c731583b0bf24e', 'message': 'Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n'}, {'number': 8, 'created': '2014-09-03 05:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eabe7daf41935d160942bf22ad93c9c2c669256d', 'message': 'Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n'}, {'number': 9, 'created': '2014-09-04 07:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e132a96fd1b8d4d900627f93179c8a713edcd818', 'message': 'Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n'}, {'number': 10, 'created': '2014-09-04 22:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fbc0de47c6c28dc45a63eea8619e45f239615fb0', 'message': 'Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n'}, {'number': 11, 'created': '2014-09-08 01:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/985413a2d93ce662104eba6f09f93f41e23fdf92', 'message': 'Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n'}, {'number': 12, 'created': '2014-09-09 05:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/376076379468be81e1d34ca0eb07fc64d664f4d3', 'message': ""Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nThis change also includes a few ultra-trivial syntax cleanups where it\nallowed the check to be immediately enabled for the rest of the\ncodebase:\n\n- Added missing trailing newlines in several files\n  (db/migration/__init__.py, nuage/{nuagedb,syncmanager,common/config}.py)\n- Renamed self to cls in @classmethods\n  (cisco/db/l3/device_handling_db.py)\n- Removed whitespace around '=' in a kwarg\n  (cisco/db/l3/device_handling_db.py, cisco/db/n1kv_db_v2.py)\n- Updated deprecated pylint 'disable-msg' directive to newer 'disable'\n  (cisco/extensions/qos.py)\n- File-specific disable for too-many-format-args pending further\n  investigation of alternatives\n  (ml2/drivers/arista/arista_l3_driver.py)\n- Import module rather than object and avoid long line\n  (services/l3_router/l3_arista.py)\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n""}, {'number': 13, 'created': '2014-09-15 03:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d7743f2ba317ce6a68a68bca4080a23c3b1b1ae3', 'message': ""Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nThis change also includes a few ultra-trivial syntax cleanups where it\nallowed the check to be immediately enabled for the rest of the\ncodebase:\n\n- Added missing trailing newlines in several files\n  (db/migration/__init__.py, nuage/{nuagedb,syncmanager,common/config}.py)\n- Renamed self to cls in @classmethods\n  (cisco/db/l3/device_handling_db.py)\n- Removed whitespace around '=' in a kwarg\n  (cisco/db/l3/device_handling_db.py, cisco/db/n1kv_db_v2.py)\n- Updated deprecated pylint 'disable-msg' directive to newer 'disable'\n  (cisco/extensions/qos.py)\n- File-specific disable for too-many-format-args pending further\n  investigation of alternatives\n  (ml2/drivers/arista/arista_l3_driver.py)\n- Import module rather than object and avoid long line\n  (services/l3_router/l3_arista.py)\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n""}, {'number': 14, 'created': '2014-09-22 00:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca41608b3bc47622e280527623e3e9f70f1418e9', 'message': ""Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nThis change also includes a few ultra-trivial syntax cleanups where it\nallowed the check to be immediately enabled for the rest of the\ncodebase:\n\n- Added missing trailing newlines in several files\n  (db/migration/__init__.py, nuage/{nuagedb,syncmanager,common/config}.py)\n- Renamed self to cls in @classmethods\n  (cisco/db/l3/device_handling_db.py)\n- Removed whitespace around '=' in a kwarg\n  (cisco/db/l3/device_handling_db.py, cisco/db/n1kv_db_v2.py)\n- Updated deprecated pylint 'disable-msg' directive to newer 'disable'\n  (cisco/extensions/qos.py)\n- File-specific disable for too-many-format-args pending further\n  investigation of alternatives\n  (ml2/drivers/arista/arista_l3_driver.py)\n- Import module rather than object and avoid long line\n  (services/l3_router/l3_arista.py)\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n""}, {'number': 15, 'created': '2014-10-03 05:14:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/095a4a8bb7ac8c02de7cd0e2b5560146170c7748', 'message': ""Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nThis change also includes a few ultra-trivial syntax cleanups where it\nallowed the check to be immediately enabled for the rest of the\ncodebase:\n\n- Added missing trailing newlines in several files\n  (db/migration/__init__.py, nuage/{nuagedb,syncmanager,common/config}.py)\n- Renamed self to cls in @classmethods\n  (cisco/db/l3/device_handling_db.py)\n- Removed whitespace around '=' in a kwarg\n  (cisco/db/l3/device_handling_db.py, cisco/db/n1kv_db_v2.py)\n- Updated deprecated pylint 'disable-msg' directive to newer 'disable'\n  (cisco/extensions/qos.py)\n- File-specific disable for too-many-format-args pending further\n  investigation of alternatives\n  (ml2/drivers/arista/arista_l3_driver.py)\n- Import module rather than object and avoid long line\n  (services/l3_router/l3_arista.py)\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n""}, {'number': 16, 'created': '2014-10-12 09:03:19.000000000', 'files': ['neutron/plugins/cisco/extensions/qos.py', '.pylintrc', 'neutron/plugins/ml2/drivers/arista/arista_l3_driver.py', 'neutron/plugins/cisco/db/l3/device_handling_db.py', 'tox.ini', 'neutron/plugins/cisco/db/n1kv_db_v2.py', 'neutron/services/l3_router/l3_arista.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/542f5cc6277c6d66bb1f603e174f1254e823f2c9', 'message': ""Add pylint tox environment and disable all existing warnings\n\npylintrc update disables all warnings that currently trigger on neutron\ncode.  The rough plan is to slowly re-enable warning categories as we\nclean up code in question.\n\nThis change also includes a few ultra-trivial syntax cleanups where it\nallowed the check to be immediately enabled for the rest of the\ncodebase:\n\n- Added missing trailing newlines in several files\n  (db/migration/__init__.py, nuage/{nuagedb,syncmanager,common/config}.py)\n- Renamed self to cls in @classmethods\n  (cisco/db/l3/device_handling_db.py)\n- Removed whitespace around '=' in a kwarg\n  (cisco/db/l3/device_handling_db.py, cisco/db/n1kv_db_v2.py)\n- Updated deprecated pylint 'disable-msg' directive to newer 'disable'\n  (cisco/extensions/qos.py)\n- File-specific disable for too-many-format-args pending further\n  investigation of alternatives\n  (ml2/drivers/arista/arista_l3_driver.py)\n- Import module rather than object and avoid long line\n  (services/l3_router/l3_arista.py)\n\nChange-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724\n""}]",21,115486,542f5cc6277c6d66bb1f603e174f1254e823f2c9,451,43,16,11279,,,0,"Add pylint tox environment and disable all existing warnings

pylintrc update disables all warnings that currently trigger on neutron
code.  The rough plan is to slowly re-enable warning categories as we
clean up code in question.

This change also includes a few ultra-trivial syntax cleanups where it
allowed the check to be immediately enabled for the rest of the
codebase:

- Added missing trailing newlines in several files
  (db/migration/__init__.py, nuage/{nuagedb,syncmanager,common/config}.py)
- Renamed self to cls in @classmethods
  (cisco/db/l3/device_handling_db.py)
- Removed whitespace around '=' in a kwarg
  (cisco/db/l3/device_handling_db.py, cisco/db/n1kv_db_v2.py)
- Updated deprecated pylint 'disable-msg' directive to newer 'disable'
  (cisco/extensions/qos.py)
- File-specific disable for too-many-format-args pending further
  investigation of alternatives
  (ml2/drivers/arista/arista_l3_driver.py)
- Import module rather than object and avoid long line
  (services/l3_router/l3_arista.py)

Change-Id: Ifb0a1a38e33f9073a78658ca578fbd2a42747724
",git fetch https://review.opendev.org/openstack/neutron refs/changes/86/115486/16 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/cisco/extensions/qos.py', '.pylintrc', 'neutron/openstack/common/jsonutils.py', 'tox.ini']",4,4211c47fee696b772d5f51e57a72b28801ec5e6b,remove-unused,[testenv:pylint] deps = {[testenv]deps} pylint commands = pylint --rcfile=.pylintrc --output-format=colorized neutron {posargs} ,,127,17
openstack%2Fhorizon~master~Ic46eb32713fc2c43dd41251181f9c7be3caec958,openstack/horizon,master,Ic46eb32713fc2c43dd41251181f9c7be3caec958,Imported Translations from Transifex,MERGED,2014-10-19 06:05:04.000000000,2014-10-19 22:04:17.000000000,2014-10-19 22:04:16.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 7213}, {'_account_id': 9576}]","[{'number': 1, 'created': '2014-10-19 06:05:04.000000000', 'files': ['horizon/locale/ja/LC_MESSAGES/django.po', 'horizon/locale/pt/LC_MESSAGES/djangojs.po', 'horizon/locale/de/LC_MESSAGES/djangojs.po', 'horizon/locale/en_GB/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'horizon/locale/cs/LC_MESSAGES/django.po', 'horizon/locale/id/LC_MESSAGES/djangojs.po', 'horizon/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'horizon/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'horizon/locale/he/LC_MESSAGES/djangojs.po', 'horizon/locale/tr_TR/LC_MESSAGES/django.po', 'horizon/locale/en_AU/LC_MESSAGES/django.po', 'horizon/locale/en_GB/LC_MESSAGES/django.po', 'horizon/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'horizon/locale/en_AU/LC_MESSAGES/djangojs.po', 'horizon/locale/fr/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'horizon/locale/zh_CN/LC_MESSAGES/djangojs.po', 'horizon/locale/sr/LC_MESSAGES/djangojs.po', 'horizon/locale/ja/LC_MESSAGES/djangojs.po', 'horizon/locale/ko_KR/LC_MESSAGES/django.po', 'horizon/locale/pt_BR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'horizon/locale/pt/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'horizon/locale/es/LC_MESSAGES/django.po', 'horizon/locale/hi/LC_MESSAGES/django.po', 'horizon/locale/pa_IN/LC_MESSAGES/djangojs.po', 'horizon/locale/pl_PL/LC_MESSAGES/django.po', 'horizon/locale/pa_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'horizon/locale/zh_TW/LC_MESSAGES/django.po', 'horizon/locale/zh_TW/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'horizon/locale/pl_PL/LC_MESSAGES/djangojs.po', 'horizon/locale/ru/LC_MESSAGES/django.po', 'horizon/locale/ko_KR/LC_MESSAGES/djangojs.po', 'horizon/locale/en/LC_MESSAGES/djangojs.po', 'horizon/locale/hi/LC_MESSAGES/djangojs.po', 'horizon/locale/ru/LC_MESSAGES/djangojs.po', 'horizon/locale/es/LC_MESSAGES/djangojs.po', 'horizon/locale/fil/LC_MESSAGES/django.po', 'horizon/locale/nl_NL/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'horizon/locale/id/LC_MESSAGES/django.po', 'horizon/locale/tr_TR/LC_MESSAGES/djangojs.po', 'horizon/locale/sr/LC_MESSAGES/django.po', 'horizon/locale/de/LC_MESSAGES/django.po', 'horizon/locale/cs/LC_MESSAGES/djangojs.po', 'horizon/locale/pt_BR/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/fa160a5e1a8249761899b5538329fca391cfbbaf', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic46eb32713fc2c43dd41251181f9c7be3caec958\n'}]",0,129461,fa160a5e1a8249761899b5538329fca391cfbbaf,21,4,1,11131,,,0,"Imported Translations from Transifex

Change-Id: Ic46eb32713fc2c43dd41251181f9c7be3caec958
",git fetch https://review.opendev.org/openstack/horizon refs/changes/61/129461/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/locale/ja/LC_MESSAGES/django.po', 'horizon/locale/pt/LC_MESSAGES/djangojs.po', 'horizon/locale/de/LC_MESSAGES/djangojs.po', 'horizon/locale/en_GB/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'horizon/locale/cs/LC_MESSAGES/django.po', 'horizon/locale/id/LC_MESSAGES/djangojs.po', 'horizon/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'horizon/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'horizon/locale/he/LC_MESSAGES/djangojs.po', 'horizon/locale/tr_TR/LC_MESSAGES/django.po', 'horizon/locale/en_AU/LC_MESSAGES/django.po', 'horizon/locale/en_GB/LC_MESSAGES/django.po', 'horizon/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'horizon/locale/en_AU/LC_MESSAGES/djangojs.po', 'horizon/locale/fr/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'horizon/locale/zh_CN/LC_MESSAGES/djangojs.po', 'horizon/locale/sr/LC_MESSAGES/djangojs.po', 'horizon/locale/ja/LC_MESSAGES/djangojs.po', 'horizon/locale/ko_KR/LC_MESSAGES/django.po', 'horizon/locale/pt_BR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'horizon/locale/pt/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'horizon/locale/es/LC_MESSAGES/django.po', 'horizon/locale/hi/LC_MESSAGES/django.po', 'horizon/locale/pa_IN/LC_MESSAGES/djangojs.po', 'horizon/locale/pl_PL/LC_MESSAGES/django.po', 'horizon/locale/pa_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'horizon/locale/zh_TW/LC_MESSAGES/django.po', 'horizon/locale/zh_TW/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'horizon/locale/pl_PL/LC_MESSAGES/djangojs.po', 'horizon/locale/ru/LC_MESSAGES/django.po', 'horizon/locale/ko_KR/LC_MESSAGES/djangojs.po', 'horizon/locale/en/LC_MESSAGES/djangojs.po', 'horizon/locale/hi/LC_MESSAGES/djangojs.po', 'horizon/locale/ru/LC_MESSAGES/djangojs.po', 'horizon/locale/es/LC_MESSAGES/djangojs.po', 'horizon/locale/fil/LC_MESSAGES/django.po', 'horizon/locale/nl_NL/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'horizon/locale/id/LC_MESSAGES/django.po', 'horizon/locale/tr_TR/LC_MESSAGES/djangojs.po', 'horizon/locale/sr/LC_MESSAGES/django.po', 'horizon/locale/de/LC_MESSAGES/django.po', 'horizon/locale/cs/LC_MESSAGES/djangojs.po', 'horizon/locale/pt_BR/LC_MESSAGES/django.po']",57,fa160a5e1a8249761899b5538329fca391cfbbaf,transifex/translations,"""POT-Creation-Date: 2014-10-18 20:37-0500\n"" ""PO-Revision-Date: 2014-10-19 01:37+0000\n""#: tables/actions.py:758#: tables/actions.py:760#: tables/actions.py:788 tables/base.py:1543#: tables/actions.py:817#: tables/actions.py:824#: tables/actions.py:830#: tables/actions.py:900#: tables/actions.py:902#: tables/actions.py:933#: tables/actions.py:934#: tables/base.py:1302#: tables/base.py:1459#: templates/horizon/common/_formset_table_row.html:15msgid ""0 Bytes"" msgstr """"","""POT-Creation-Date: 2014-10-14 23:28-0500\n"" ""PO-Revision-Date: 2014-10-14 07:54+0000\n""#: tables/actions.py:756#: tables/actions.py:758#: tables/actions.py:786 tables/base.py:1545#: tables/actions.py:815#: tables/actions.py:822#: tables/actions.py:828#: tables/actions.py:898#: tables/actions.py:900#: tables/actions.py:931#: tables/actions.py:932#: tables/base.py:1304#: tables/base.py:1461#: templates/horizon/common/_formset_table_row.html:14msgid ""0 bytes"" msgstr ""0 bytes""",1566,1038
openstack%2Fheat-templates~master~I667ef6923a2ccf8fbefc53aa2bb3485297bc7ee1,openstack/heat-templates,master,I667ef6923a2ccf8fbefc53aa2bb3485297bc7ee1,encode characters which can be in puppet manifests,ABANDONED,2014-10-17 13:54:56.000000000,2014-10-19 21:38:01.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7193}]","[{'number': 1, 'created': '2014-10-17 13:54:56.000000000', 'files': ['hot/software-config/elements/heat-config-puppet/install.d/hook-puppet.py'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/83b5b2734df2b049ab7913e89f59bb477f5d7109', 'message': ""encode characters which can be in puppet manifests\n\nUpdates the puppet software-config hook so that it incodes\nthe 'config' manifest via 'utf-8'. This resolves possible\nUnicodeEncodeError exceptions which can occur when using\na manifest that pulls in a puppet manifest with UTF-8 characters.\n\nChange-Id: I667ef6923a2ccf8fbefc53aa2bb3485297bc7ee1\n""}]",1,129257,83b5b2734df2b049ab7913e89f59bb477f5d7109,5,4,1,360,,,0,"encode characters which can be in puppet manifests

Updates the puppet software-config hook so that it incodes
the 'config' manifest via 'utf-8'. This resolves possible
UnicodeEncodeError exceptions which can occur when using
a manifest that pulls in a puppet manifest with UTF-8 characters.

Change-Id: I667ef6923a2ccf8fbefc53aa2bb3485297bc7ee1
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/57/129257/1 && git format-patch -1 --stdout FETCH_HEAD,['hot/software-config/elements/heat-config-puppet/install.d/hook-puppet.py'],1,83b5b2734df2b049ab7913e89f59bb477f5d7109,puppet-encoding-issue," f.write(c.get('config', '').encode('utf-8'))"," f.write(c.get('config', ''))",1,1
openstack%2Fheat-templates~master~I6f9135ad646ec4996c1c012ff11f7929404ecc3e,openstack/heat-templates,master,I6f9135ad646ec4996c1c012ff11f7929404ecc3e,Use utf-8 encoding when writing config scripts,MERGED,2014-10-16 12:47:43.000000000,2014-10-19 21:37:41.000000000,2014-10-19 21:37:41.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 12321}]","[{'number': 1, 'created': '2014-10-16 12:47:43.000000000', 'files': ['hot/software-config/elements/heat-config-ansible/install.d/hook-ansible.py', 'hot/software-config/elements/heat-config-puppet/install.d/hook-puppet.py', 'hot/software-config/elements/heat-config-script/install.d/hook-script.py', 'hot/software-config/elements/heat-config-salt/install.d/hook-salt.py'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/7bbb87ec110208e88220ebf0b3d5df59ed7e9821', 'message': ""Use utf-8 encoding when writing config scripts\n\nChange from default encoding 'ascii' to 'utf-8' encoding when writing\nconfig scripts (stored in Heat software config's 'config' attribute).\nThe default ascii encoding causes issues when config scripts include\nspecial characters.\n\nChange-Id: I6f9135ad646ec4996c1c012ff11f7929404ecc3e\nCloses-Bug: #1382031\n""}]",0,128907,7bbb87ec110208e88220ebf0b3d5df59ed7e9821,7,4,1,7193,,,0,"Use utf-8 encoding when writing config scripts

Change from default encoding 'ascii' to 'utf-8' encoding when writing
config scripts (stored in Heat software config's 'config' attribute).
The default ascii encoding causes issues when config scripts include
special characters.

Change-Id: I6f9135ad646ec4996c1c012ff11f7929404ecc3e
Closes-Bug: #1382031
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/07/128907/1 && git format-patch -1 --stdout FETCH_HEAD,"['hot/software-config/elements/heat-config-ansible/install.d/hook-ansible.py', 'hot/software-config/elements/heat-config-puppet/install.d/hook-puppet.py', 'hot/software-config/elements/heat-config-script/install.d/hook-script.py', 'hot/software-config/elements/heat-config-salt/install.d/hook-salt.py']",4,7bbb87ec110208e88220ebf0b3d5df59ed7e9821,bug/1382031, f.write(yaml_config.encode('utf-8')), f.write(yaml_config),4,4
openstack%2Fheat-specs~master~Ib58d8372de1d4ba91ff5a7203773629f8c835c95,openstack/heat-specs,master,Ib58d8372de1d4ba91ff5a7203773629f8c835c95,Heat functional tests,MERGED,2014-07-29 00:31:39.000000000,2014-10-19 21:29:43.000000000,2014-10-19 21:29:43.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}]","[{'number': 1, 'created': '2014-07-29 00:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/21c673aef7cb174a9b5c66fd21d71bd2f9245682', 'message': 'Heat functional tests\n\nExisting tempest orchestration scenario tests need to be moved into the heat\nrepository in a way which requires no dependency on the tempest code, and\nwhich can be done with minimal development effort.\n\nThe heat gate needs to switch over to running the heat functional tests,\nas well as whatever orchestration tests remain in tempest.\n\nChange-Id: Ib58d8372de1d4ba91ff5a7203773629f8c835c95\n'}, {'number': 2, 'created': '2014-08-03 21:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/eb3d24eed3bff4b4a95f8be3456dd933b0672d51', 'message': 'Heat functional tests\n\nExisting tempest orchestration scenario tests need to be moved into the heat\nrepository in a way which requires no dependency on the tempest code, and\nwhich can be done with minimal development effort.\n\nThe heat gate needs to switch over to running the heat functional tests,\nas well as whatever orchestration tests remain in tempest.\n\nChange-Id: Ib58d8372de1d4ba91ff5a7203773629f8c835c95\n'}, {'number': 3, 'created': '2014-08-24 21:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/5bf407fbc0ad5feb224dd3f05b7a695af9bb4ca8', 'message': 'Heat functional tests\n\nExisting tempest orchestration scenario tests need to be moved into the heat\nrepository in a way which requires no dependency on the tempest code, and\nwhich can be done with minimal development effort.\n\nThe heat gate needs to switch over to running the heat functional tests,\nas well as whatever orchestration tests remain in tempest.\n\nChange-Id: Ib58d8372de1d4ba91ff5a7203773629f8c835c95\n'}, {'number': 4, 'created': '2014-10-19 20:35:57.000000000', 'files': ['specs/kilo/functional-tests.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/2642d6325e19f4dbafc22c01445d9082a51f5044', 'message': 'Heat functional tests\n\nExisting tempest orchestration scenario tests need to be moved into the heat\nrepository in a way which requires no dependency on the tempest code, and\nwhich can be done with minimal development effort.\n\nThe heat gate needs to switch over to running the heat functional tests,\nas well as whatever orchestration tests remain in tempest.\n\nChange-Id: Ib58d8372de1d4ba91ff5a7203773629f8c835c95\n'}]",12,110171,2642d6325e19f4dbafc22c01445d9082a51f5044,34,7,4,4571,,,0,"Heat functional tests

Existing tempest orchestration scenario tests need to be moved into the heat
repository in a way which requires no dependency on the tempest code, and
which can be done with minimal development effort.

The heat gate needs to switch over to running the heat functional tests,
as well as whatever orchestration tests remain in tempest.

Change-Id: Ib58d8372de1d4ba91ff5a7203773629f8c835c95
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/71/110171/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/functional-tests.rst'],1,21c673aef7cb174a9b5c66fd21d71bd2f9245682,bp/functional-tests,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/heat/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ==================================================================== Make tempest orchestration scenario tests the heat functional tests ==================================================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/heat/+spec/functional-tests Having all OpenStack functional tests in tempest is no longer scalable, so heat functional tests need to live in the heat repository. Problem description =================== Existing tempest orchestration scenario tests need to be moved into the heat repository in a way which requires no dependency on the tempest code, and which can be done with minimal development effort. The heat gate needs to switch over to running the heat functional tests, as well as whatever orchestration tests remain in tempest. Proposed change =============== The proposed plan for this work will be: * Forklift tempest.scenario.orchestration into heat.tests.functional * Copy and modify any supporting tempest code into heat.tests.functional to make it possible for the tests to run * Replace configuration loaded from tempest.conf with a solution which initially requires no configuration file, specifically: * Tests will be run with credentials sourced from the environment, which heatclient does by default anyway * Configuration which refers to cloud resources will hard-code values which correspond to values set up by devstack, and tests will be skipped (or alternative code paths invoked) if cloud resources with those names do not exist. This applies to configuration values: image_ref, keypair_name, instance_type, network_for_ssh * build_timeout will be given a default value which is overridable from an environment variable * Tests can be tagged as functional tests, but a unit test run could run functional tests too as long as credentials are set in the environment. If there are no credentials set in the environment, all functional tests can be skipped * Modify devstack, devstack-gate and openstack-infra/config to check and gate on the heat functional tests. This job will replace the current heat-slow job * Ensure there are no tempest.api.orchestration tests running in the heat-slow job, specifically: * Do not tag test_nova_keypair_resources as a slow test * Modify test_neutron_resources to run with cirros, or rewrite it as a functional test * Delete the heat-slow job, and tests in tempest.scenario.orchestration Alternatives ------------ The following alternative design points could be considered: * A dedicated conf file to replace the current tempest.conf, or read test configuration values from heat.conf * Failing tests instead of skipping for missing credentials or required cloud resources * Modifying tox.ini to filter out functional tests on a unit test run instead of skipping based on current environment Implementation ============== Assignee(s) ----------- Primary assignee: Steve Baker <sbaker@redhat.com> Milestones ---------- Target Milestone for completion: Juno-3, but work can continue during feature freeze Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * devstack ",,106,0
openstack%2Fnova~master~Iccf7c71d357df0c967f8745c56dcd41219f4ca87,openstack/nova,master,Iccf7c71d357df0c967f8745c56dcd41219f4ca87,libvirt: convert mox to mock in test_utils,MERGED,2014-10-02 13:12:19.000000000,2014-10-19 21:12:34.000000000,2014-10-19 21:12:31.000000000,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 7746}, {'_account_id': 9008}, {'_account_id': 9545}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-02 13:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ca598eb4aabe8c837a39e28d7c475e649dda75b', 'message': 'libvirt: convert mox to mock in test_utils\n\nCommit 73066aff1b4c80f09a1340ab5d70b3b4f2983c0b created a new\nfile called test_utils. This was a good place to change\nall mox usage to mock.\n\nChange-Id: Iccf7c71d357df0c967f8745c56dcd41219f4ca87\n'}, {'number': 2, 'created': '2014-10-02 13:13:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bfe2d6d60ecb1ab5004843b1b0118143651cb553', 'message': 'libvirt: convert mox to mock in test_utils\n\nCommit 73066aff1b4c80f09a1340ab5d70b3b4f2983c0b created a new\nfile called test_utils. This was a good place to change\nall mox usage to mock.\n\nChange-Id: Iccf7c71d357df0c967f8745c56dcd41219f4ca87\n'}, {'number': 3, 'created': '2014-10-02 15:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4505630c422141f0a1c163f8f37f97d181a3dbba', 'message': 'libvirt: convert mox to mock in test_utils\n\nCommit 73066aff1b4c80f09a1340ab5d70b3b4f2983c0b created a new\nfile called test_utils. This was a good place to change\nall mox usage to mock.\n\nChange-Id: Iccf7c71d357df0c967f8745c56dcd41219f4ca87\n'}, {'number': 4, 'created': '2014-10-03 12:39:03.000000000', 'files': ['nova/tests/virt/libvirt/test_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/022a843db299d7e827321b66260c010cf2ea363e', 'message': 'libvirt: convert mox to mock in test_utils\n\nCommit 73066aff1b4c80f09a1340ab5d70b3b4f2983c0b created a new\nfile called test_utils. This was a good place to change\nall mox usage to mock.\n\nChange-Id: Iccf7c71d357df0c967f8745c56dcd41219f4ca87\n'}]",15,125626,022a843db299d7e827321b66260c010cf2ea363e,29,12,4,1653,,,0,"libvirt: convert mox to mock in test_utils

Commit 73066aff1b4c80f09a1340ab5d70b3b4f2983c0b created a new
file called test_utils. This was a good place to change
all mox usage to mock.

Change-Id: Iccf7c71d357df0c967f8745c56dcd41219f4ca87
",git fetch https://review.opendev.org/openstack/nova refs/changes/26/125626/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/test_utils.py'],1,7ca598eb4aabe8c837a39e28d7c475e649dda75b,libvirt-mox-mock-utils,"# Copyrigh 2012 NTT Data. All Rights Reserved. @mock.patch('os.path.exists') @mock.patch('nova.utils.execute') def test_get_disk_type(self, _mock_execute, _mock_exists): _mock_execute.return_value = (example_output, '') _mock_execute.assert_called_once_with('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path) _mock_exists.assert_called_once_with(path) self.assertEqual('raw', disk_type) @mock.patch('os.path.exists') def test_disk_type(self, _mock_exists): with mock.patch('nova.utils.execute', return_value=(output, '')) as _mock_execute: d_type = libvirt_utils.get_disk_type(path) _mock_execute.assert_called_once_with( 'env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path) self.assertEqual(f, d_type) @mock.patch('os.path.exists') @mock.patch('nova.utils.execute') def test_disk_backing(self, _mock_execute, _mock_exists): _mock_execute.return_value = (output, '') _mock_execute.assert_called_once_with('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path) _mock_exists.assert_called_once_with(path) def _test_disk_size(self, _mock_execute, path, expected_size): d_size = libvirt_utils.get_disk_size(path) self.assertEqual(expected_size, d_size) _mock_execute.assert_called_once_with('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path) @mock.patch('os.path.exists') def test_disk_size(self, _mock_exists): with mock.patch('nova.utils.execute', return_value=(output, '')) as _mock_execute: self._test_disk_size(_mock_execute, path, i) with mock.patch('nova.utils.execute', return_value=(output, '')) as _mock_execute: self._test_disk_size(_mock_execute, path, i) @mock.patch('os.path.exists') @mock.patch('nova.utils.execute') def test_qemu_info_canon(self, _mock_execute, _mock_exists): _mock_execute.return_value = (example_output, '') _mock_execute.assert_called_once_with('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path) _mock_exists.assert_called_once_with(path) @mock.patch('os.path.exists') @mock.patch('nova.utils.execute') def test_qemu_info_canon2(self, _mock_execute, _mock_exists): _mock_execute.return_value = (example_output, '') _mock_execute.assert_called_once_with('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path) _mock_exists.assert_called_once_with(path) @mock.patch('os.path.exists') @mock.patch('nova.utils.execute') def test_qemu_backing_file_actual(self, _mock_execute, _mock_exists): _mock_execute.return_value = (example_output, '') _mock_execute.assert_called_once_with('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path) _mock_exists.assert_called_once_with(path) @mock.patch('os.path.exists') @mock.patch('nova.utils.execute') def test_qemu_info_convert(self, _mock_execute, _mock_exists): _mock_execute.return_value = (example_output, '') image_info = images.qemu_img_info(path) _mock_execute.assert_called_once_with('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path) _mock_exists.assert_called_once_with(path) @mock.patch('os.path.exists') @mock.patch('nova.utils.execute') def test_qemu_info_snaps(self, _mock_execute, _mock_exists): _mock_execute.return_value = (example_output, '') _mock_execute.assert_called_once_with('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path) _mock_exists.assert_called_once_with(path) @mock.patch('nova.utils.execute') def test_create_image(self, _mock_execute): expected_args = [(('qemu-img', 'create', '-f', 'raw', '/some/path', '10G'),), (('qemu-img', 'create', '-f', 'qcow2', '/some/stuff', '1234567891234'),)] self.assertEqual(expected_args, _mock_execute.call_args_list) @mock.patch('os.path.exists') @mock.patch('nova.utils.execute') def test_create_cow_image(self, _mock_execute, _mock_exists): _mock_execute.return_value = ('stdout', None) expected_args = [(('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', '/some/path'),), (('qemu-img', 'create', '-f', 'qcow2', '-o', 'backing_file=/some/path', '/the/new/cow'),)] self.assertEqual(expected_args, _mock_execute.call_args_list) @mock.patch('os.path.exists') @mock.patch('nova.utils.execute') def test_get_disk_size(self, _mock_execute, _mock_exists): path = '/some/path' example_output = """"""image: 00000001disk size: 4.4M """""" _mock_execute.return_value = (example_output, '') self.assertEqual(4592640, disk.get_disk_size('/some/path')) _mock_execute.assert_called_once_with('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path) _mock_exists.assert_called_once_with(path) def _do_test_extract_snapshot(self, _mock_execute, dest_format='raw', out_format='raw'): _mock_execute.assert_called_once_with( 'qemu-img', 'convert', '-f', 'qcow2', '-O', out_format, '/path/to/disk/image', '/extracted/snap') @mock.patch.object(utils, 'execute') def test_extract_snapshot_raw(self, _mock_execute): self._do_test_extract_snapshot(_mock_execute) @mock.patch.object(utils, 'execute') def test_extract_snapshot_iso(self, _mock_execute): self._do_test_extract_snapshot(_mock_execute, dest_format='iso') @mock.patch.object(utils, 'execute') def test_extract_snapshot_qcow2(self, _mock_execute): self._do_test_extract_snapshot(_mock_execute, dest_format='qcow2', out_format='qcow2') @mock.patch('nova.virt.images.fetch_to_raw') def test_fetch_image(self, _mock_images): _mock_images.assert_called_once_with( context, image_id, target, user_id, project_id, max_size=0)","# Copyright 2012 NTT Data. All Rights Reserved. def test_get_disk_type(self): self.mox.StubOutWithMock(os.path, 'exists') self.mox.StubOutWithMock(utils, 'execute') os.path.exists(path).AndReturn(True) utils.execute('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path).AndReturn((example_output, '')) self.mox.ReplayAll() self.assertEqual(disk_type, 'raw') def test_disk_type(self): self.mox.StubOutWithMock(os.path, 'exists') self.mox.StubOutWithMock(utils, 'execute') os.path.exists(path).AndReturn(True) utils.execute('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path).AndReturn((output, '')) self.mox.ReplayAll() d_type = libvirt_utils.get_disk_type(path) self.assertEqual(f, d_type) self.mox.UnsetStubs() def test_disk_backing(self): self.mox.StubOutWithMock(os.path, 'exists') self.mox.StubOutWithMock(utils, 'execute') os.path.exists(path).AndReturn(True) utils.execute('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path).AndReturn((output, '')) self.mox.ReplayAll() def test_disk_size(self): self.mox.StubOutWithMock(os.path, 'exists') self.mox.StubOutWithMock(utils, 'execute') os.path.exists(path).AndReturn(True) utils.execute('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path).AndReturn((output, '')) self.mox.ReplayAll() d_size = libvirt_utils.get_disk_size(path) self.assertEqual(i, d_size) self.mox.UnsetStubs() self.mox.StubOutWithMock(os.path, 'exists') self.mox.StubOutWithMock(utils, 'execute') os.path.exists(path).AndReturn(True) utils.execute('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path).AndReturn((output, '')) self.mox.ReplayAll() d_size = libvirt_utils.get_disk_size(path) self.assertEqual(i, d_size) self.mox.UnsetStubs() def test_qemu_info_canon(self): self.mox.StubOutWithMock(os.path, 'exists') self.mox.StubOutWithMock(utils, 'execute') os.path.exists(path).AndReturn(True) utils.execute('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path).AndReturn((example_output, '')) self.mox.ReplayAll() def test_qemu_info_canon2(self): self.mox.StubOutWithMock(os.path, 'exists') self.mox.StubOutWithMock(utils, 'execute') os.path.exists(path).AndReturn(True) utils.execute('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path).AndReturn((example_output, '')) self.mox.ReplayAll() def test_qemu_backing_file_actual(self): self.mox.StubOutWithMock(os.path, 'exists') self.mox.StubOutWithMock(utils, 'execute') os.path.exists(path).AndReturn(True) utils.execute('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path).AndReturn((example_output, '')) self.mox.ReplayAll() def test_qemu_info_convert(self): self.mox.StubOutWithMock(os.path, 'exists') self.mox.StubOutWithMock(utils, 'execute') os.path.exists(path).AndReturn(True) utils.execute('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path).AndReturn((example_output, '')) self.mox.ReplayAll() def test_qemu_info_snaps(self): self.mox.StubOutWithMock(os.path, 'exists') self.mox.StubOutWithMock(utils, 'execute') os.path.exists(path).AndReturn(True) utils.execute('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', path).AndReturn((example_output, '')) self.mox.ReplayAll() def test_create_image(self): self.mox.StubOutWithMock(utils, 'execute') utils.execute('qemu-img', 'create', '-f', 'raw', '/some/path', '10G') utils.execute('qemu-img', 'create', '-f', 'qcow2', '/some/stuff', '1234567891234') # Start test self.mox.ReplayAll() def test_create_cow_image(self): self.mox.StubOutWithMock(os.path, 'exists') self.mox.StubOutWithMock(utils, 'execute') rval = ('stdout', None) os.path.exists('/some/path').AndReturn(True) utils.execute('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', '/some/path').AndReturn(rval) utils.execute('qemu-img', 'create', '-f', 'qcow2', '-o', 'backing_file=/some/path', '/the/new/cow') # Start test self.mox.ReplayAll() def test_get_disk_size(self): self.mox.StubOutWithMock(os.path, 'exists') self.mox.StubOutWithMock(utils, 'execute') os.path.exists('/some/path').AndReturn(True) utils.execute('env', 'LC_ALL=C', 'LANG=C', 'qemu-img', 'info', '/some/path').AndReturn(('''image: 00000001disk size: 4.4M''', '')) # Start test self.mox.ReplayAll() self.assertEqual(disk.get_disk_size('/some/path'), 4592640) def _do_test_extract_snapshot(self, dest_format='raw', out_format='raw'): self.mox.StubOutWithMock(utils, 'execute') utils.execute('qemu-img', 'convert', '-f', 'qcow2', '-O', out_format, '/path/to/disk/image', '/extracted/snap') # Start test self.mox.ReplayAll() def test_extract_snapshot_raw(self): self._do_test_extract_snapshot() def test_extract_snapshot_iso(self): self._do_test_extract_snapshot(dest_format='iso') def test_extract_snapshot_qcow2(self): self._do_test_extract_snapshot(dest_format='qcow2', out_format='qcow2') def test_fetch_image(self): self.mox.StubOutWithMock(images, 'fetch_to_raw') images.fetch_to_raw(context, image_id, target, user_id, project_id, max_size=0) self.mox.ReplayAll()",126,131
openstack%2Fpuppet-trove~master~If0bae23c536461edba3da08da4bb17cc09676b0b,openstack/puppet-trove,master,If0bae23c536461edba3da08da4bb17cc09676b0b,keystone/auth: Fix puppetdoc typos,MERGED,2014-10-06 15:58:38.000000000,2014-10-19 21:05:52.000000000,2014-10-19 21:05:52.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-10-06 15:58:38.000000000', 'files': ['manifests/keystone/auth.pp'], 'web_link': 'https://opendev.org/openstack/puppet-trove/commit/eda9844c01b2b007c91140443c13dba58bd5a5a1', 'message': 'keystone/auth: Fix puppetdoc typos\n\nUpdate puppetdoc to reference on Trove instead of Neutron\n\nChange-Id: If0bae23c536461edba3da08da4bb17cc09676b0b\n'}]",0,126334,eda9844c01b2b007c91140443c13dba58bd5a5a1,7,3,1,7155,,,0,"keystone/auth: Fix puppetdoc typos

Update puppetdoc to reference on Trove instead of Neutron

Change-Id: If0bae23c536461edba3da08da4bb17cc09676b0b
",git fetch https://review.opendev.org/openstack/puppet-trove refs/changes/34/126334/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/keystone/auth.pp'],1,eda9844c01b2b007c91140443c13dba58bd5a5a1,fix-doc,# (required) Password for Trove user.# Username for Trove service. Defaults to 'trove'.# Email for Trove user. Defaults to 'trove@localhost'.# Tenant for Trove user. Defaults to 'services'.# Should Trove endpoint be configured? Defaults to 'true'.,# (required) Password for Neutron user.# Username for Neutron service. Defaults to 'trove'.# Email for Neutron user. Defaults to 'trove@localhost'.# Tenant for Neutron user. Defaults to 'services'.# Should Neutron endpoint be configured? Defaults to 'true'.,5,5
openstack%2Fkolla~master~I906f87986f9df3cb7e46169d163a4b3caf0d91bb,openstack/kolla,master,I906f87986f9df3cb7e46169d163a4b3caf0d91bb,Change from using Neutron to Nova flat networking,ABANDONED,2014-10-17 18:12:51.000000000,2014-10-19 20:29:14.000000000,,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 8745}]","[{'number': 1, 'created': '2014-10-17 18:12:51.000000000', 'files': ['docker/nova-controller/nova-ctr-base/config-nova-controller.sh', 'docker/nova-compute/nova-compute/config-nova-compute.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/f7b319c8c8ed6877078953c01aed9f61d67af52e', 'message': ""Change from using Neutron to Nova flat networking\n\nNeutron isn't ready, so use Nova flat networking in the meantime.\n\nChange-Id: I906f87986f9df3cb7e46169d163a4b3caf0d91bb\n""}]",4,129346,f7b319c8c8ed6877078953c01aed9f61d67af52e,7,3,1,2834,,,0,"Change from using Neutron to Nova flat networking

Neutron isn't ready, so use Nova flat networking in the meantime.

Change-Id: I906f87986f9df3cb7e46169d163a4b3caf0d91bb
",git fetch https://review.opendev.org/openstack/kolla refs/changes/46/129346/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/nova-controller/nova-ctr-base/config-nova-controller.sh', 'docker/nova-compute/nova-compute/config-nova-compute.sh']",2,f7b319c8c8ed6877078953c01aed9f61d67af52e,,"#crudini --set $cfg DEFAULT service_neutron_metadata_proxy True #crudini --set $cfg DEFAULT neutron_default_tenant_id default#crudini --set $cfg DEFAULT network_api_class nova.network.neutronv2.api.APIcrudini --set $cfg libvirt virt_type qemucrudini --set $cfg DEFAULT flat_network_bridge br100 crudini --set $cfg DEFAULT public_interface em1 crudini --set $cfg DEFAULT network_manager nova.network.manager.FlatDHCPManager crudini --set $cfg DEFAULT firewall_driver nova.virt.libvirt.firewall.IptablesF crudini --set $cfg DEFAULT fixed_range """" crudini --set $cfg DEFAULT force_dhcp_release True crudini --set $cfg DEFAULT dhcpbridge_flagfile /etc/nova/nova.conf ",crudini --set $cfg DEFAULT service_neutron_metadata_proxy True crudini --set $cfg DEFAULT neutron_default_tenant_id defaultcrudini --set $cfg DEFAULT network_api_class nova.network.neutronv2.api.APIcrudini --set $cfg libvirt virt_type kvm,24,8
openstack%2Fcinder~master~I14871985a2a916834122f849238f05b75726bc1a,openstack/cinder,master,I14871985a2a916834122f849238f05b75726bc1a,Fix LVM iSCSI driver tgtadm CHAP authentication,MERGED,2014-10-14 23:30:47.000000000,2014-10-19 20:04:26.000000000,2014-10-15 04:49:46.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 9008}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12369}]","[{'number': 1, 'created': '2014-10-14 23:30:47.000000000', 'files': ['cinder/brick/iscsi/iscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e3563891545c801726d227f752cf99488ed5c7dd', 'message': ""Fix LVM iSCSI driver tgtadm CHAP authentication\n\nCurrently CHAP Authentication in LVM iSCSI driver with tgtadm does not work.\nThis is because the tgtadm helper creates the target configuration file\nwith an 'IncomingUser' entry, which is ignored by tgtd.\nThis patch fixes it to 'incominguser'.\n\nChange-Id: I14871985a2a916834122f849238f05b75726bc1a\nCloses-Bug: #1329214\n""}]",0,128478,e3563891545c801726d227f752cf99488ed5c7dd,10,6,1,9176,,,0,"Fix LVM iSCSI driver tgtadm CHAP authentication

Currently CHAP Authentication in LVM iSCSI driver with tgtadm does not work.
This is because the tgtadm helper creates the target configuration file
with an 'IncomingUser' entry, which is ignored by tgtd.
This patch fixes it to 'incominguser'.

Change-Id: I14871985a2a916834122f849238f05b75726bc1a
Closes-Bug: #1329214
",git fetch https://review.opendev.org/openstack/cinder refs/changes/78/128478/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/brick/iscsi/iscsi.py'],1,e3563891545c801726d227f752cf99488ed5c7dd,," chap_str = re.sub('^IncomingUser ', 'incominguser ', chap_auth) path, chap_str,"," path, chap_auth,",2,1
openstack%2Fhorizon~master~I3c30b5ec9e22f0ac709d147443cae02b359d7c36,openstack/horizon,master,I3c30b5ec9e22f0ac709d147443cae02b359d7c36,Dropdown Actions For Database Details Page,MERGED,2014-10-19 06:56:08.000000000,2014-10-19 18:25:52.000000000,2014-10-19 18:25:51.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2455}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-10-19 06:56:08.000000000', 'files': ['openstack_dashboard/dashboards/project/databases/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/6ea7e5e103dd3726d0571e87894285b69038d4aa', 'message': 'Dropdown Actions For Database Details Page\n\nadds dropdown actions to the database/trove details page. this was\nmissed in Ic09385d19b417b256cbc51d044d66ecbb54c7d52, aka\nblueprint detail-pages-ia .\n\nChange-Id: I3c30b5ec9e22f0ac709d147443cae02b359d7c36\nCloses-Bug: #1382918\n'}]",0,129463,6ea7e5e103dd3726d0571e87894285b69038d4aa,10,4,1,8214,,,0,"Dropdown Actions For Database Details Page

adds dropdown actions to the database/trove details page. this was
missed in Ic09385d19b417b256cbc51d044d66ecbb54c7d52, aka
blueprint detail-pages-ia .

Change-Id: I3c30b5ec9e22f0ac709d147443cae02b359d7c36
Closes-Bug: #1382918
",git fetch https://review.opendev.org/openstack/horizon refs/changes/63/129463/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/databases/views.py'],1,6ea7e5e103dd3726d0571e87894285b69038d4aa,bug/1382918," instance = self.get_data() table = tables.InstancesTable(self.request) context[""instance""] = instance context[""url""] = self.get_redirect_url() context[""actions""] = table.render_row_actions(instance) exceptions.handle(self.request, msg, redirect=self.get_redirect_url()) @staticmethod def get_redirect_url(): return reverse('horizon:project:databases:index') "," context[""instance""] = self.get_data() redirect = reverse('horizon:project:databases:index') exceptions.handle(self.request, msg, redirect=redirect)",11,3
openstack%2Fhorizon~master~I58cc20972aac221012f248e8135151b1243dae35,openstack/horizon,master,I58cc20972aac221012f248e8135151b1243dae35,Add max-complexity to pep8 for Horizon,MERGED,2014-10-19 01:58:10.000000000,2014-10-19 18:24:42.000000000,2014-10-19 18:24:41.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2455}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-10-19 01:58:10.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5304e145595baaa92ed6c45b7630bdaf01ef7c93', 'message': ""Add max-complexity to pep8 for Horizon\n\nPicked this up from Keystone. It sounds like a good defense to have from\nfurther making our code more complex.\n\nThe current highest complexity is 32, set the maximum complexity\nfor flake8 to 33. This should help to keep code simple and\nmaintainable. It should be possible to reduce the maximum\ncomplexity to something closer to 20 with relatively small efforts.\n\nopenstack_dashboard.dashboards.identity.projects.workflows:\n    'UpdateProject.handle' is complexity of 32\nopenstack_dashboard.dashboards.project.access_and_security.security_groups.forms:\n    'AddRule.clean' is complexity of 20\nopenstack_dashboard.dashboards.project.instances.workflows.create_instance:\n    'SetInstanceDetailsAction.clean' is complexity of 26\nhorizon.exceptions:\n    'handle' is complexity of 24\n\nChange-Id: I58cc20972aac221012f248e8135151b1243dae35\n""}]",0,129453,5304e145595baaa92ed6c45b7630bdaf01ef7c93,9,4,1,1941,,,0,"Add max-complexity to pep8 for Horizon

Picked this up from Keystone. It sounds like a good defense to have from
further making our code more complex.

The current highest complexity is 32, set the maximum complexity
for flake8 to 33. This should help to keep code simple and
maintainable. It should be possible to reduce the maximum
complexity to something closer to 20 with relatively small efforts.

openstack_dashboard.dashboards.identity.projects.workflows:
    'UpdateProject.handle' is complexity of 32
openstack_dashboard.dashboards.project.access_and_security.security_groups.forms:
    'AddRule.clean' is complexity of 20
openstack_dashboard.dashboards.project.instances.workflows.create_instance:
    'SetInstanceDetailsAction.clean' is complexity of 26
horizon.exceptions:
    'handle' is complexity of 24

Change-Id: I58cc20972aac221012f248e8135151b1243dae35
",git fetch https://review.opendev.org/openstack/horizon refs/changes/53/129453/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,5304e145595baaa92ed6c45b7630bdaf01ef7c93,max-complexity-flake8,max-complexity=33,,1,0
openstack%2Foperations-guide~master~I8b5461ba24b86de33a644c549d88d21ce99e5746,openstack/operations-guide,master,I8b5461ba24b86de33a644c549d88d21ce99e5746,"Fix typo: ""buy"" -> ""by""",MERGED,2014-10-19 12:44:11.000000000,2014-10-19 17:27:50.000000000,2014-10-19 17:27:49.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-10-19 12:44:11.000000000', 'files': ['doc/openstack-ops/ch_ops_network_troubleshooting.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/3efe44986be120c07dce62867e0391c80309e771', 'message': 'Fix typo: ""buy"" -> ""by""\n\nChange-Id: I8b5461ba24b86de33a644c549d88d21ce99e5746\n'}]",0,129470,3efe44986be120c07dce62867e0391c80309e771,7,3,1,4727,,,0,"Fix typo: ""buy"" -> ""by""

Change-Id: I8b5461ba24b86de33a644c549d88d21ce99e5746
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/70/129470/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/ch_ops_network_troubleshooting.xml'],1,3efe44986be120c07dce62867e0391c80309e771,bug/1382962, their UUIDs can be obtained by running <literal>neutron, their UUIDs can be obtained buy running <literal>neutron,1,1
openstack%2Fha-guide~master~Ie634885c8e1af1198fe1f3257723fc4a9a5a5620,openstack/ha-guide,master,Ie634885c8e1af1198fe1f3257723fc4a9a5a5620,Imported Translations from Transifex,MERGED,2014-10-19 06:00:06.000000000,2014-10-19 17:25:38.000000000,2014-10-19 17:25:38.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-19 06:00:06.000000000', 'files': ['doc/high-availability-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/c5a84dab4cac229fe142770481c38db312a11a3d', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ie634885c8e1af1198fe1f3257723fc4a9a5a5620\n'}]",0,129460,c5a84dab4cac229fe142770481c38db312a11a3d,6,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: Ie634885c8e1af1198fe1f3257723fc4a9a5a5620
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/60/129460/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/high-availability-guide/locale/ja.po'],1,c5a84dab4cac229fe142770481c38db312a11a3d,transifex/translations,"""POT-Creation-Date: 2014-10-18 09:19+0000\n"" ""PO-Revision-Date: 2014-10-19 04:50+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""msgstr ""システム停止時間""msgstr ""データ損失""msgstr ""<package>pacemaker</package> (crm シェルを別途ダウンロードする必要があるかもしれないことに注意してください。)""msgstr ""<package>fence-agents</package> (Fedora のみ。他のすべてのディストリビューションは、<package>cluster-glue</package> からフェンスエージェントを使用します。)""msgstr ""<placeholder-1/> ユーティリティーは、Corosync クラスターメンバー一覧を出力するために使用できます。""msgstr ""これで、HA クラスターを構築しています。<literal>rabbit2</literal> から、これらのコマンドを実行します。""","""POT-Creation-Date: 2014-10-17 13:08+0000\n"" ""PO-Revision-Date: 2014-10-17 09:12+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",9,9
openstack%2Fhorizon~master~I0ee2a8c80347ba0026b2dd9cf2f1797e02a580c1,openstack/horizon,master,I0ee2a8c80347ba0026b2dd9cf2f1797e02a580c1,add missing semicolon in networktopology,MERGED,2014-10-18 16:45:22.000000000,2014-10-19 12:45:52.000000000,2014-10-19 12:45:51.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-10-18 16:45:22.000000000', 'files': ['horizon/static/horizon/js/horizon.networktopology.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/863fa952509e24f4544667dd47e3df6b5b42c432', 'message': 'add missing semicolon in networktopology\n\nAdd in the missing semicolon identified by jshint.\n\nChange-Id: I0ee2a8c80347ba0026b2dd9cf2f1797e02a580c1\nCloses-Bug: #1382825\n'}]",0,129432,863fa952509e24f4544667dd47e3df6b5b42c432,9,4,1,9981,,,0,"add missing semicolon in networktopology

Add in the missing semicolon identified by jshint.

Change-Id: I0ee2a8c80347ba0026b2dd9cf2f1797e02a580c1
Closes-Bug: #1382825
",git fetch https://review.opendev.org/openstack/horizon refs/changes/32/129432/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.networktopology.js'],1,863fa952509e24f4544667dd47e3df6b5b42c432,bug/1382825," html_data.view_details_label = gettext(""View Instance Details"");"," html_data.view_details_label = gettext(""View Instance Details"")",1,1
openstack%2Ftempest~master~Ia84d487c1b57c2fdce9d87905bf717c76adf6879,openstack/tempest,master,Ia84d487c1b57c2fdce9d87905bf717c76adf6879,update downstream gitreview,ABANDONED,2014-10-19 11:16:54.000000000,2014-10-19 11:17:16.000000000,,[],"[{'number': 1, 'created': '2014-10-19 11:16:54.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6590fb5c554495e722a8093f83f06ee690f930f4', 'message': 'update downstream gitreview\n\nChange-Id: Ia84d487c1b57c2fdce9d87905bf717c76adf6879\n'}]",0,129469,6590fb5c554495e722a8093f83f06ee690f930f4,2,0,1,8576,,,0,"update downstream gitreview

Change-Id: Ia84d487c1b57c2fdce9d87905bf717c76adf6879
",git fetch https://review.opendev.org/openstack/tempest refs/changes/69/129469/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,6590fb5c554495e722a8093f83f06ee690f930f4,downstream_test,host=review.gerrithub.ioproject=redhat-openstack/tempest,host=review.openstack.orgproject=openstack/tempest.git,2,2
openstack%2Fopenstack-manuals~master~Iaa404ee7b3fcbc0a14450cab6ae378f698890d7d,openstack/openstack-manuals,master,Iaa404ee7b3fcbc0a14450cab6ae378f698890d7d,Improve install guide cinder chapter,MERGED,2014-10-18 02:16:13.000000000,2014-10-19 10:12:24.000000000,2014-10-19 10:12:23.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-10-18 02:16:13.000000000', 'files': ['doc/install-guide/section_cinder-node.xml', 'doc/install-guide/section_cinder-controller-node.xml', 'doc/install-guide/ch_cinder.xml', 'doc/install-guide/section_cinder-verify.xml', 'doc/install-guide/section_cinder-storage-node.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/07dc1fcc3796259e1b73c63d1a0ae0365bd8c1b9', 'message': ""Improve install guide cinder chapter\n\nI improved the cinder chapter of the installation guide\nas follows:\n\n1) Renamed storage node files, titles, and XML IDs to\n   conform with standards.\n2) Rewrote introductory content to increase depth.\n3) Clarified requirements for controller and storage nodes.\n4) Added steps to configure storage node operating system\n   prior to installing the volume service.\n5) Rewrote LVM filter content because the original content\n   was vague and confusing.\n6) Added more command output.\n7) Added 'cinder list' command to verify section.\n\nI eventually want to restructure the architecture and basic\nenvironment content to integrate organization and configuration\nof optional nodes. Adding steps to configure the storage node\noperating in this chapter temporarily fills a void.\n\nChange-Id: Iaa404ee7b3fcbc0a14450cab6ae378f698890d7d\nImplements: blueprint installation-guide-improvements\n""}]",1,129411,07dc1fcc3796259e1b73c63d1a0ae0365bd8c1b9,8,4,1,9515,,,0,"Improve install guide cinder chapter

I improved the cinder chapter of the installation guide
as follows:

1) Renamed storage node files, titles, and XML IDs to
   conform with standards.
2) Rewrote introductory content to increase depth.
3) Clarified requirements for controller and storage nodes.
4) Added steps to configure storage node operating system
   prior to installing the volume service.
5) Rewrote LVM filter content because the original content
   was vague and confusing.
6) Added more command output.
7) Added 'cinder list' command to verify section.

I eventually want to restructure the architecture and basic
environment content to integrate organization and configuration
of optional nodes. Adding steps to configure the storage node
operating in this chapter temporarily fills a void.

Change-Id: Iaa404ee7b3fcbc0a14450cab6ae378f698890d7d
Implements: blueprint installation-guide-improvements
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/11/129411/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/section_cinder-node.xml', 'doc/install-guide/section_cinder-controller-node.xml', 'doc/install-guide/ch_cinder.xml', 'doc/install-guide/section_cinder-storage-node.xml', 'doc/install-guide/section_cinder-verify.xml']",5,07dc1fcc3796259e1b73c63d1a0ae0365bd8c1b9,bp/installation-guide-improvements, <para>Source the <literal>admin</literal> credentials to gain access to admin-only CLI commands:</para> <screen><prompt>$</prompt> <userinput>source admin-openrc.sh</userinput></screen> </step> <step> <para>List service components to verify successful launch of each process:</para> <screen><prompt>$</prompt> <userinput>cinder service-list</userinput> <computeroutput>+------------------+------------+------+---------+-------+----------------------------+-----------------+ | Binary | Host | Zone | Status | State | Updated_at | Disabled Reason | +------------------+------------+------+---------+-------+----------------------------+-----------------+ | cinder-scheduler | controller | nova | enabled | up | 2014-10-18T01:30:54.000000 | None | | cinder-volume | block1 | nova | enabled | up | 2014-10-18T01:30:57.000000 | None | +------------------+------------+------+---------+-------+----------------------------+-----------------+</computeroutput></screen> </step> <step> the following steps as a non-administrative tenant:</para>, these steps as a non-administrative tenant:</para>,325,288
openstack%2Fopenstack-manuals~master~Iffd9219a90dbb288f9064cc05689e532956f4971,openstack/openstack-manuals,master,Iffd9219a90dbb288f9064cc05689e532956f4971,Get the config files in the juno git branch,MERGED,2014-10-15 11:14:04.000000000,2014-10-19 10:08:16.000000000,2014-10-19 10:08:14.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 6843}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-10-15 11:14:04.000000000', 'files': ['doc/config-reference/block-storage/section_block-storage-sample-configuration-files.xml', 'doc/config-reference/ch_objectstorageconfigure.xml', 'doc/config-reference/image-service/section_image-service-sample-configuration-files.xml', 'doc/config-reference/compute/section_compute-sample-configuration-files.xml', 'doc/config-reference/identity/section_keystone-sample-conf-files.xml', 'doc/config-reference/networking/section_networking-sample-configuration-files.xml', 'doc/config-reference/telemetry/section_telemetry-sample-configuration-files.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/77c1158b24c05d3c1dffdb43f556a7dc61d65128', 'message': 'Get the config files in the juno git branch\n\nChange-Id: Iffd9219a90dbb288f9064cc05689e532956f4971\n'}]",0,128607,77c1158b24c05d3c1dffdb43f556a7dc61d65128,13,5,1,7923,,,0,"Get the config files in the juno git branch

Change-Id: Iffd9219a90dbb288f9064cc05689e532956f4971
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/07/128607/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/block-storage/section_block-storage-sample-configuration-files.xml', 'doc/config-reference/ch_objectstorageconfigure.xml', 'doc/config-reference/image-service/section_image-service-sample-configuration-files.xml', 'doc/config-reference/compute/section_compute-sample-configuration-files.xml', 'doc/config-reference/identity/section_keystone-sample-conf-files.xml', 'doc/config-reference/networking/section_networking-sample-configuration-files.xml', 'doc/config-reference/telemetry/section_telemetry-sample-configuration-files.xml']",7,77c1158b24c05d3c1dffdb43f556a7dc61d65128,juno-git," <programlisting language=""ini""><xi:include parse=""text"" href=""http://git.openstack.org/cgit/openstack/ceilometer/plain/etc/ceilometer/event_definitions.yaml?h=stable/juno""/></programlisting> <programlisting language=""ini""><xi:include parse=""text"" href=""http://git.openstack.org/cgit/openstack/ceilometer/plain/etc/ceilometer/pipeline.yaml?h=stable/juno""/></programlisting> <programlisting language=""json""><xi:include parse=""text"" href=""http://git.openstack.org/cgit/openstack/ceilometer/plain/etc/ceilometer/policy.json?h=stable/juno""/></programlisting>"," <programlisting language=""ini""><xi:include parse=""text"" href=""http://git.openstack.org/cgit/openstack/ceilometer/plain/etc/ceilometer/event_definitions.yaml?h=stable/icehouse""/></programlisting> <programlisting language=""ini""><xi:include parse=""text"" href=""http://git.openstack.org/cgit/openstack/ceilometer/plain/etc/ceilometer/pipeline.yaml?h=stable/icehouse""/></programlisting> <programlisting language=""json""><xi:include parse=""text"" href=""http://git.openstack.org/cgit/openstack/ceilometer/plain/etc/ceilometer/policy.json?h=stable/icehouse""/></programlisting>",34,34
openstack%2Fopenstack-manuals~master~I5d32c57b0e00de25fdf9a527cae45107106ebdfb,openstack/openstack-manuals,master,I5d32c57b0e00de25fdf9a527cae45107106ebdfb,Imported Translations from Transifex,MERGED,2014-10-19 06:11:18.000000000,2014-10-19 10:00:04.000000000,2014-10-19 10:00:03.000000000,"[{'_account_id': 3}, {'_account_id': 167}]","[{'number': 1, 'created': '2014-10-19 06:11:18.000000000', 'files': ['doc/user-guide/locale/ja.po', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/user-guide-admin/locale/ja.po', 'doc/image-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4eb7c9c21f916617e678bcafbd736bc95ffb4f69', 'message': 'Imported Translations from Transifex\n\nChange-Id: I5d32c57b0e00de25fdf9a527cae45107106ebdfb\n'}]",0,129462,4eb7c9c21f916617e678bcafbd736bc95ffb4f69,6,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I5d32c57b0e00de25fdf9a527cae45107106ebdfb
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/62/129462/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/locale/ja.po', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/user-guide-admin/locale/ja.po', 'doc/image-guide/locale/ja.po']",5,4eb7c9c21f916617e678bcafbd736bc95ffb4f69,transifex/translations,"""POT-Creation-Date: 2014-10-18 09:20+0000\n"" ""PO-Revision-Date: 2014-10-18 13:30+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""msgstr ""2014-10-15""msgstr ""Juno 向けの微修正。""msgstr ""これをサポートするための最も簡単な方法は、イメージに以下をインストールすることです。""msgstr ""<link href=\""https://launchpad.net/cloud-utils\"">cloud-utils</link> パッケージ。パーティションを拡張するための <placeholder-1/> ツールを含みます。""msgstr ""Ubuntu、Debian、Fedora の場合、<link href=\""https://launchpad.net/cloud-initramfs-tools\"">cloud-initramfs-growroot</link> パッケージ。最初に起動するルートパーティションの容量を変更できます。""msgstr ""CentOS、RHEL の場合、<package>cloud-initramfs-growroot</package> パッケージ。""msgstr ""<link href=\""https://launchpad.net/cloud-init\"">cloud-init</link> パッケージ。""msgstr ""これらのパッケージをインストールすると、このイメージは、起動時にルートパーティションの容量変更を実行できるようになります。例えば、<filename>/etc/rc.local</filename> にあります。これらのパッケージは、Ubuntu や Debian のパッケージリポジトリーにあります。また、Fedora、RHEL、CentOS、Scientific Linux のゲストの場合、EPEL リポジトリーにあります。""msgstr ""イメージは、SSH 公開鍵に加えて、<link href=\""http://docs.openstack.org/user-guide/content/inserting_userdata.html\"">インスタンスに提供されるユーザーデータ</link>など、OpenStack からの追加情報を必要とするかもしれません。これは、イメージの起動時に、ユーザーが指定するものです。例えば、インスタンスの起動時に、ホスト名を設定したいかもしれません。または、スクリプトのようなユーザーデータの内容を起動時に実行できるよう、イメージを設定したいかもしれません。""msgstr ""メタデータサービス、または、<link href=\""http://docs.openstack.org/user-guide/content/config-drive.html\"">コンフィグドライブへのメタデータの保存</link>により、この情報にアクセスできます。OpenStack メタデータサービスは、Amazon EC2 メタデータサービスの 2009-04-04 版と互換性があるので、ユーザーデータの取得に関する詳細は、<link href=\""http://docs.amazonwebservices.com/AWSEC2/2009-04-04/UserGuide/AESDG-chapter-instancedata.html\"">Using Instance Metadata</link> にある Amazon EC2 ドキュメントを参照してください。""","""POT-Creation-Date: 2014-10-17 12:39+0000\n"" ""PO-Revision-Date: 2014-10-17 09:11+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",57,57
openstack%2Fneutron~master~I8b11303cc5384b4e93e2320c43e16fa343b363a7,openstack/neutron,master,I8b11303cc5384b4e93e2320c43e16fa343b363a7,Require port_id and port args to update_dhcp_port,ABANDONED,2014-10-16 10:00:56.000000000,2014-10-19 09:17:37.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10237}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-16 10:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c216f825618acada93f09148f70e6198a4fd4f56', 'message': ""Set default if port is not passed into function\n\nIn the update_dhcp_port function in the dhcp_rpc module\nthe port is extracted from kwargs and is always assumed\nto be a dictionary. However, if it's not present, it will\nbe None and throw a TypeError.\n\nThis fix isn't that important because current callers provide\nthe port. This code was originally part of a larger fix that\nturned out to be a duplicate of a fix already in master. This\nwas the only difference.\n\nRelated-Bug: #1378508\nRelated-Bug: #1381938\nChange-Id: I8b11303cc5384b4e93e2320c43e16fa343b363a7\n""}, {'number': 2, 'created': '2014-10-16 10:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/640444d5430e21095c16cc56ef4388d12a409259', 'message': ""Set default if port is not passed into function\n\nIn the update_dhcp_port function in the dhcp_rpc module\nthe port is extracted from kwargs and is always assumed\nto be a dictionary. However, if it's not present, it will\nbe None and throw a TypeError.\n\nThis fix isn't that important because current callers provide\nthe port. This code was originally part of a larger fix that\nturned out to be a duplicate of a fix already in master. This\nwas the only difference.\n\nRelated-Bug: #1378508\nRelated-Bug: #1381938\nChange-Id: I8b11303cc5384b4e93e2320c43e16fa343b363a7\n""}, {'number': 3, 'created': '2014-10-17 21:35:25.000000000', 'files': ['neutron/api/rpc/handlers/dhcp_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4e84af751d86edb0fee3e918085a1ffc9db027f1', 'message': ""Require port_id and port args to update_dhcp_port\n\nThe update_dhcp_port function currently uses **kwargs\nto extract the arguments it uses. This doesn't really\nmake sense since it doesn't pass them onto another\nfunction and the port_id and port arguments are required\nto do anything useful.\n\nThe port is extracted from kwargs and is always assumed\nto be a dictionary. However, if it's not present, it will\nbe None and throw a TypeError.\n\nThis patch just removes kwargs and uses a real argument\ndefinition in the funcion to remove possible strange\ncases (e.g. no port_id or port) and to make it easier to\nreason about.\n\nThis fix isn't that important because current callers provide\nthe necessary information. This code was originally part of a\nlarger fix that turned out to be a duplicate of a fix already\nin master. Handling of these kwargs was the only difference.\n\nRelated-Bug: #1378508\nRelated-Bug: #1381938\nChange-Id: I8b11303cc5384b4e93e2320c43e16fa343b363a7\n""}]",4,128864,4e84af751d86edb0fee3e918085a1ffc9db027f1,59,23,3,7787,,,0,"Require port_id and port args to update_dhcp_port

The update_dhcp_port function currently uses **kwargs
to extract the arguments it uses. This doesn't really
make sense since it doesn't pass them onto another
function and the port_id and port arguments are required
to do anything useful.

The port is extracted from kwargs and is always assumed
to be a dictionary. However, if it's not present, it will
be None and throw a TypeError.

This patch just removes kwargs and uses a real argument
definition in the funcion to remove possible strange
cases (e.g. no port_id or port) and to make it easier to
reason about.

This fix isn't that important because current callers provide
the necessary information. This code was originally part of a
larger fix that turned out to be a duplicate of a fix already
in master. Handling of these kwargs was the only difference.

Related-Bug: #1378508
Related-Bug: #1381938
Change-Id: I8b11303cc5384b4e93e2320c43e16fa343b363a7
",git fetch https://review.opendev.org/openstack/neutron refs/changes/64/128864/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/api/rpc/handlers/dhcp_rpc.py'],1,c216f825618acada93f09148f70e6198a4fd4f56,bug/1378508," port = kwargs.get('port', {})", port = kwargs.get('port'),1,1
openstack%2Fnova~master~I85a0ae3ad283253c7a4e71218f645f9ebe67bee2,openstack/nova,master,I85a0ae3ad283253c7a4e71218f645f9ebe67bee2,Network: add in missing translation hints,ABANDONED,2014-10-19 04:58:47.000000000,2014-10-19 08:52:24.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}]","[{'number': 1, 'created': '2014-10-19 04:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f2cfc349012635b7978a88de9d12a8152a7aa04', 'message': 'Network: add in missing translation hints\n\nAdd in some missing translation hints. There are for errors\nand warnings.\n\nChange-Id: I85a0ae3ad283253c7a4e71218f645f9ebe67bee2\n'}, {'number': 2, 'created': '2014-10-19 06:56:34.000000000', 'files': ['nova/network/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9775ec479d479c4eb19d79dd77394be1f0451056', 'message': 'Network: add in missing translation hints\n\nAdd in some missing translation hints. There are for errors\nand warnings.\n\nChange-Id: I85a0ae3ad283253c7a4e71218f645f9ebe67bee2\n'}]",0,129457,9775ec479d479c4eb19d79dd77394be1f0451056,15,7,2,1653,,,0,"Network: add in missing translation hints

Add in some missing translation hints. There are for errors
and warnings.

Change-Id: I85a0ae3ad283253c7a4e71218f645f9ebe67bee2
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/129457/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/manager.py'],1,4f2cfc349012635b7978a88de9d12a8152a7aa04,error-translation," msg = _LE(""Unable to release %s because vif doesn't exist."") oversize_msg = _LW("," msg = _(""Unable to release %s because vif doesn't exist."") oversize_msg = _(",2,2
openstack%2Ftempest~master~I74261baac4fbf121826808ef55dfed960422b964,openstack/tempest,master,I74261baac4fbf121826808ef55dfed960422b964,glance add image with duplicate id,ABANDONED,2014-09-04 18:30:49.000000000,2014-10-19 08:21:45.000000000,,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 360}, {'_account_id': 455}, {'_account_id': 616}, {'_account_id': 706}, {'_account_id': 792}, {'_account_id': 1132}, {'_account_id': 2284}, {'_account_id': 2537}, {'_account_id': 4463}, {'_account_id': 6159}, {'_account_id': 6167}, {'_account_id': 6484}, {'_account_id': 6493}, {'_account_id': 6549}, {'_account_id': 8759}, {'_account_id': 10385}, {'_account_id': 11075}]","[{'number': 1, 'created': '2014-09-04 18:30:49.000000000', 'files': ['tempest/api/image/v2/test_images_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f8f64d62edf2ea50beee05bc037de6fbffe57c3e', 'message': 'glance add image with duplicate id\n\nChange-Id: I74261baac4fbf121826808ef55dfed960422b964\n'}]",4,119162,f8f64d62edf2ea50beee05bc037de6fbffe57c3e,11,19,1,11075,,,0,"glance add image with duplicate id

Change-Id: I74261baac4fbf121826808ef55dfed960422b964
",git fetch https://review.opendev.org/openstack/tempest refs/changes/62/119162/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/image/v2/test_images_negative.py'],1,f8f64d62edf2ea50beee05bc037de6fbffe57c3e,learn_tempest," @test.attr(type=['negative', 'gate']) def test_create_duplicate_image_id(self): _, body = self.client.create_image(name='test', container_format='bare', disk_format='raw') image_id = body['id'] self.assertRaises(exceptions.ServerFault, self.client.create_image, name='test', id=image_id, container_format='bare', disk_format='raw')",,10,0
openstack%2Ftaskflow~master~Ie5500eaa7f4425edb604b2dd13a15f82909a673b,openstack/taskflow,master,Ie5500eaa7f4425edb604b2dd13a15f82909a673b,Add a futures type that can unify our future functionality,MERGED,2014-08-24 03:35:50.000000000,2014-10-19 07:22:08.000000000,2014-10-19 07:22:07.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-08-24 03:35:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/beb1e55668e05206dfec3bae2b6b69d11f4af2c6', 'message': 'Add a futures type that can be augmented with async/future types (WIP)\n\nTo start add a thread pool executor that captures the futures metrics\nthat it creates and provides these back to the users of that executor.\nIt also supports restart() so that it is not needed to create a new\nexecutor everytime a shutdown executor is used...\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 2, 'created': '2014-08-24 03:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5018fb8dfbac0254bde00eec8cf42547e5dfc216', 'message': 'Add a futures type that can be augmented with async/future types (WIP)\n\nTo start add a thread pool executor that captures the futures metrics\nthat it creates and provides these back to the users of that executor.\nIt also supports restart() so that it is not needed to create a new\nexecutor everytime a shutdown executor is used...\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 3, 'created': '2014-08-24 03:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9be5f81491eeabf299df407ce777154572fb352f', 'message': 'Add a futures type that can be augmented with async/future types (WIP)\n\nTo start add a thread pool executor that captures the futures metrics\nthat it creates and provides these back to the users of that executor.\nIt also supports restart() so that it is not needed to create a new\nexecutor everytime a shutdown executor is used...\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 4, 'created': '2014-08-24 04:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cb67e1ddd2a240c4de6f133ad13c0ebad221e0ae', 'message': 'Add a futures type that can be augmented with async/future types (WIP)\n\nTo start add a thread pool executor that captures the futures metrics\nthat it creates and provides these back to the users of that executor.\nIt also supports restart() so that it is not needed to create a new\nexecutor everytime a shutdown executor is used...\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 5, 'created': '2014-08-24 04:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d4c0cfe9d2bf16b4cc1b07ee07067be41f645bfb', 'message': 'Add a futures type that can be augmented with async/future types (WIP)\n\nTo start add a thread pool executor that captures the futures metrics\nthat it creates and provides these back to the users of that executor.\nIt also supports restart() so that it is not needed to create a new\nexecutor everytime a shutdown executor is used...\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 6, 'created': '2014-08-24 07:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c585e31ad175c8c1aca8d5ca1ccb17fcce1010b7', 'message': 'Add a futures type that can be augmented with async/future types (WIP)\n\nTo start add a thread pool executor that captures the futures metrics\nthat it creates and provides these back to the users of that executor.\nIt also supports restart() so that it is not needed to create a new\nexecutor everytime a shutdown executor is used...\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 7, 'created': '2014-08-24 19:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/54c3031be9c291088cd3738a1a7a4dcb41030ea2', 'message': 'Add a futures type that can be augmented with async/future types (WIP)\n\nTo start add a thread pool executor that captures the futures metrics\nthat it creates and provides these back to the users of that executor.\nIt also supports restart() so that it is not needed to create a new\nexecutor everytime a shutdown executor is used...\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 8, 'created': '2014-08-25 23:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6472e5a86ba6e22039b932e6e36202c1ffb6f44e', 'message': 'Add a futures type that can contain most of our future functionality\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 9, 'created': '2014-08-26 02:45:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0130af8bfb97c29748d8ca4664a47b2b72fe0f4a', 'message': 'Add a futures type that can contain most of our future functionality\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 10, 'created': '2014-08-28 23:14:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f4ecb35c0fb7834d3f96834aaeb075e6835323f8', 'message': 'Add a futures type that can contain our future functionality\n\n- Move the currently existing green future executor and associated\n  code to a new futures types module so that it can be accessed from\n  this new location (TODO: deprecate the old location and link the\n  old to the new for one release so that we can remove the old link\n  in N + 1 release).\n- Create and use a new thread pool future executor that along with\n  a new future derivative can accumulate (if this is desired) the futures\n  lifetime metrics which can be very useful to know for applications using\n  executors.\n- Unifies the API that the new thread pool future executor and the\n  green thread pool future executor provide so there usage is as\n  seamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 11, 'created': '2014-08-30 00:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0f473fd70a9b83f1d4da2aac80cf8dfe5eba8f58', 'message': 'Add a futures type that can contain our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nCreate and use a new thread pool future executor that along with\na new future derivative can accumulate (if this is desired) the futures\nlifetime metrics which can be very useful to know for applications using\nexecutors.\n\nUnifies the API that the new thread pool future executor and the\ngreen thread pool future executor provide so there usage is as\nseamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 12, 'created': '2014-09-04 01:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b8b1aa5f66c1c33f165495a878abe583732a1285', 'message': 'Add a futures type that can contain our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nCreate and use a new thread pool future executor that along with\na new future derivative can accumulate (if this is desired) the futures\nlifetime metrics which can be very useful to know for applications using\nexecutors.\n\nUnifies the API that the new thread pool future executor and the\ngreen thread pool future executor provide so there usage is as\nseamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 13, 'created': '2014-09-04 22:48:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7b8e97f1250d5587afbd1a6915adf72a8b0d0792', 'message': 'Add a futures type that can contain our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nCreate and use a new thread pool future executor that along with\na new future derivative can accumulate (if this is desired) the futures\nlifetime metrics which can be very useful to know for applications using\nexecutors.\n\nUnifies the API that the new thread pool future executor and the\ngreen thread pool future executor provide so there usage is as\nseamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 14, 'created': '2014-09-05 00:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5004b62e967258d3ea5640986ce9aeb351961b52', 'message': 'Add a futures type that can contain our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nCreate and use a new thread pool future executor that along with\na new future derivative can accumulate (if this is desired) the futures\nlifetime metrics which can be very useful to know for applications using\nexecutors.\n\nUnifies the API that the new thread pool future executor and the\ngreen thread pool future executor provide so there usage is as\nseamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 15, 'created': '2014-09-06 23:58:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a50278459fd30917e15a62e3fb6b2290cfc11083', 'message': 'Add a futures type that can contain our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nCreate and use a new thread pool future executor that along with\na new future derivative can accumulate (if this is desired) the futures\nlifetime metrics which can be very useful to know for applications using\nexecutors.\n\nUnifies the API that the new thread pool future executor and the\ngreen thread pool future executor provide so there usage is as\nseamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 16, 'created': '2014-09-09 00:53:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e14c05262f0f4ba6f45054be079d55bc61988936', 'message': 'Add a futures type that can contain our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nThis unifies the API that the new thread pool future executor and\nthe green thread pool future executor provide so there usage is as\nseamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 17, 'created': '2014-09-16 03:58:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/bef37ce6284935dc6626badcc8dc0ecb5fd5832b', 'message': 'Add a futures type that can unify our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nThis unifies the API that the existing pool future executors and\nthe green thread pool future executor provide so there usage is as\nseamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 18, 'created': '2014-09-21 05:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/230e870a3d2ae70a8ac93cfc4d7a679d923f8fe5', 'message': 'Add a futures type that can unify our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nThis unifies the API that the existing pool (thread or process) future\nexecutors and the green thread pool future executor, and the newly added\nsynchronous executor (replacing the previous `make_completed_future`\nfunction) provide so there usage is as seamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 19, 'created': '2014-09-21 06:57:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b01582c1b5da303825833b9cb75f3eecd69ab1c7', 'message': 'Add a futures type that can unify our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nThis unifies the API that the existing pool (thread or process) future\nexecutors and the green thread pool future executor, and the newly added\nsynchronous executor (replacing the previous `make_completed_future`\nfunction) provide so there usage is as seamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 20, 'created': '2014-09-21 14:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c972527afd29d49368addc8f11330b9e9e9e4a89', 'message': 'Add a futures type that can unify our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nThis unifies the API that the existing pool (thread or process) future\nexecutors and the green thread pool future executor, and the newly added\nsynchronous executor (replacing the previous `make_completed_future`\nfunction) provide so there usage is as seamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 21, 'created': '2014-09-22 05:17:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f46764135aff8f0f9fb9322fcb3ab000a2fa2e0d', 'message': 'Add a futures type that can unify our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nThis unifies the API that the existing pool (thread or process) future\nexecutors and the green thread pool future executor, and the newly added\nsynchronous executor (replacing the previous `make_completed_future`\nfunction) provide so there usage is as seamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 22, 'created': '2014-09-22 23:45:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/512ae1590532ede171100dc4714b0a39b0b84c6e', 'message': 'Add a futures type that can unify our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nThis unifies the API that the existing pool (thread or process) future\nexecutors and the green thread pool future executor, and the newly added\nsynchronous executor (replacing the previous `make_completed_future`\nfunction) provide so there usage is as seamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 23, 'created': '2014-10-18 19:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a4f7f3e2daf9cf9b1d5e05c48ef4142e3128ab3b', 'message': 'Add a futures type that can unify our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nThis unifies the API that the existing pool (thread or process) future\nexecutors and the green thread pool future executor, and the newly added\nsynchronous executor (replacing the previous `make_completed_future`\nfunction) provide so there usage is as seamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}, {'number': 24, 'created': '2014-10-19 03:24:38.000000000', 'files': ['taskflow/tests/unit/test_utils_async_utils.py', 'taskflow/utils/async_utils.py', 'taskflow/tests/unit/test_futures.py', 'taskflow/tests/unit/test_green_executor.py', 'taskflow/persistence/backends/impl_sqlalchemy.py', 'doc/source/types.rst', 'taskflow/engines/action_engine/executor.py', 'taskflow/types/futures.py', 'taskflow/utils/eventlet_utils.py', 'taskflow/tests/unit/test_engines.py', 'taskflow/examples/resume_vm_boot.py', 'taskflow/engines/action_engine/retry_action.py', 'taskflow/tests/unit/test_suspend_flow.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b014fc7d48969bd6812a11a5a0342c9324108876', 'message': 'Add a futures type that can unify our future functionality\n\nMove the currently existing green future executor and associated\ncode to a new futures types module so that it can be accessed from\nthis new location (TODO: deprecate the old location and link the\nold to the new for one release so that we can remove the old link\nin N + 1 release).\n\nThis unifies the API that the existing pool (thread or process) future\nexecutors and the green thread pool future executor, and the newly added\nsynchronous executor (replacing the previous `make_completed_future`\nfunction) provide so there usage is as seamless as possible.\n\nPart of blueprint top-level-types\n\nChange-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b\n'}]",0,116489,b014fc7d48969bd6812a11a5a0342c9324108876,75,3,24,1297,,,0,"Add a futures type that can unify our future functionality

Move the currently existing green future executor and associated
code to a new futures types module so that it can be accessed from
this new location (TODO: deprecate the old location and link the
old to the new for one release so that we can remove the old link
in N + 1 release).

This unifies the API that the existing pool (thread or process) future
executors and the green thread pool future executor, and the newly added
synchronous executor (replacing the previous `make_completed_future`
function) provide so there usage is as seamless as possible.

Part of blueprint top-level-types

Change-Id: Ie5500eaa7f4425edb604b2dd13a15f82909a673b
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/89/116489/21 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/types/futures.py'],1,beb1e55668e05206dfec3bae2b6b69d11f4af2c6,bp/top-level-types,"# -*- coding: utf-8 -*- # Copyright (C) 2014 Yahoo! Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import collections import functools from concurrent.futures import _base from concurrent.futures import thread as _thread from taskflow.utils import misc class FutureMetric(object): """"""Metrics about a futures lifecycle."""""" __slots__ = ['created', 'cancelled', 'started', 'finished'] def __init__(self, created=None): if created is None: self.created = misc.wallclock() else: self.created = created self.cancelled = None self.started = None self.finished = None @property def duration(self): if self.cancelled is not None: return max(0.0, self.cancelled - self.created) if self.started is None or self.finished is None: return None else: return max(0.0, self.finished - self.started) def copy(self): m = FutureMetric(created=self.created) m.cancelled = self.cancelled m.started = self.started m.finished = self.finished return m def __repr__(self): return 'FutureMetric(duration=%s)' % self.duration class Future(_base.Future): """"""A future that contains metrics about its own lifecycle."""""" def __init__(self): super(Future, self).__init__() self._metric = FutureMetric() @property def metric(self): return self._metric.copy() def cancel(self): with self._condition: if self._state not in [_base.RUNNING, _base.FINISHED, _base.CANCELLED, _base.CANCELLED_AND_NOTIFIED]: self._metric.cancelled = misc.wallclock() return super(Future, self).cancel() def set_exception(self, exception): with self._condition: self._metric.finished = misc.wallclock() super(Future, self).set_exception(exception) def set_result(self, result): with self._condition: self._metric.finished = misc.wallclock() super(Future, self).set_result(result) def set_running_or_notify_cancel(self): with self._condition: if self._state == _base.PENDING: self._metric.started = misc.wallclock() return super(Future, self).set_running_or_notify_cancel() class FutureMetrics(object): """"""A holder of many future metrics + useful properties/functions."""""" def __init__(self): self._gathered = collections.deque() def clear(self): # Populate a new one so that existing iterations or existing # captures do not run into concurrent modifications errors... self._gathered = collections.deque() def __iter__(self): for m in self._gathered: yield m def __getitem__(self, index): return self._gathered[index] def __len__(self): return len(self._gathered) def __repr__(self): return 'FutureMetrics(gathered=%s)' % len(self._gathered) @classmethod def capture(cls, metrics, fut): metrics._gathered.append(fut.metric) @property def average_run_time(self): total_durations = 0 count = 0 for m in self._gathered: if m.duration is None: continue total_durations += m.duration count += 1 if count: return total_durations / count else: return None @property def average_wait_time(self): total_waits = 0 count = 0 for m in self._gathered: if m.cancelled is not None: total_waits += max(0.0, m.cancelled - m.created) count += 1 elif m.started is not None: total_waits += max(0.0, m.started - m.created) count += 1 if count: return total_waits / count else: return None class ThreadPoolExecutor(_thread.ThreadPoolExecutor): """"""A thread pool executor derivative that tracks future lifecycles."""""" def __init__(self, max_workers, capturing=False): super(ThreadPoolExecutor, self).__init__(max_workers) self._metrics = FutureMetrics() self._capturing = capturing @property def metrics(self): return self._metrics @property def capturing(self): return self._capturing def restart(self, wait=True): self.shutdown(wait=wait) with self._shutdown_lock: if self._shutdown: self._threads.clear() self._shutdown = False def submit(self, fn, *args, **kwargs): with self._shutdown_lock: if self._shutdown: raise RuntimeError('cannot schedule new futures after' ' shutdown') f = Future() if self._capturing: cb = functools.partial(self._metrics.capture, self._metrics) f.add_done_callback(cb) w = _thread._WorkItem(f, fn, args, kwargs) self._work_queue.put(w) self._adjust_thread_count() return f ",,190,0
openstack%2Fcinder~master~I1fc673d0c01c41faa98292d5813d4471b455d712,openstack/cinder,master,I1fc673d0c01c41faa98292d5813d4471b455d712,Improve Cinder API internal cache interface,MERGED,2014-08-19 21:18:30.000000000,2014-10-19 06:28:54.000000000,2014-10-19 06:28:53.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 5538}, {'_account_id': 6491}, {'_account_id': 7156}, {'_account_id': 9751}, {'_account_id': 11811}]","[{'number': 1, 'created': '2014-08-19 21:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3f739591a30a74486a4b59789475011eecd9957a', 'message': ""Improve Cinder API internal cache interface\n\nImprove the internal caching system used by the API layer\nby borrowing the implementation used by Nova.\n\nUnlike the previous implementation, this new interface makes it clear\nwhich resource types are added or retrieved from the cache.\n\nThis change also adds other resources to the cache:\n- backups\n- snapshots\n- volume types\n\nIt's now possible to remove database access those extensions:\n- extended_snapshot_attributes\n- volume_host_attribute\n- volume_mig_status_attribute\n- volume_tenant_attribute\n\nCloses-bug: #1358524\nChange-Id: I1fc673d0c01c41faa98292d5813d4471b455d712\n""}, {'number': 2, 'created': '2014-08-19 21:22:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7e02d8fba1dd1f606436d80a56ded2eeb18569a5', 'message': ""Improve Cinder API internal cache interface\n\nImprove the internal caching system used by the API layer\nby borrowing the implementation used by Nova.\n\nUnlike the previous implementation, this new interface makes it clear\nwhich resource types are added or retrieved from the cache.\n\nThis change also adds other resources to the cache:\n- backups\n- snapshots\n- volume types\n\nIt's now possible to remove database access those extensions:\n- extended_snapshot_attributes\n- volume_host_attribute\n- volume_mig_status_attribute\n- volume_tenant_attribute\n\nCloses-bug: #1358524\nChange-Id: I1fc673d0c01c41faa98292d5813d4471b455d712\n""}, {'number': 3, 'created': '2014-08-20 19:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1c8725bbbe4960312bfb448bbfe7f129a109bbb5', 'message': ""Improve Cinder API internal cache interface\n\nImprove the internal caching system used by the API layer\nby borrowing the implementation used by Nova.\n\nUnlike the previous implementation, this new interface makes it clear\nwhich resource types are added or retrieved from the cache.\n\nThis change also adds other resources to the cache:\n- backups\n- snapshots\n- volume types\n\nIt's now possible to remove database access those extensions:\n- extended_snapshot_attributes\n- volume_host_attribute\n- volume_mig_status_attribute\n- volume_tenant_attribute\n\nCloses-bug: #1358524\nChange-Id: I1fc673d0c01c41faa98292d5813d4471b455d712\n""}, {'number': 4, 'created': '2014-08-20 19:50:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3a6e6033709c09767ba9f593f9c1e329eb9b8b6b', 'message': ""Improve Cinder API internal cache interface\n\nImprove the internal caching system used by the API layer\nby borrowing the implementation used by Nova.\n\nUnlike the previous implementation, this new interface makes it clear\nwhich resource types are added or retrieved from the cache.\n\nThis change also adds other resources to the cache:\n- backups\n- snapshots\n- volume types\n\nIt's now possible to remove database access those extensions:\n- extended_snapshot_attributes\n- volume_host_attribute\n- volume_mig_status_attribute\n- volume_tenant_attribute\n\nCloses-bug: #1358524\nChange-Id: I1fc673d0c01c41faa98292d5813d4471b455d712\n""}, {'number': 5, 'created': '2014-08-21 13:08:52.000000000', 'files': ['cinder/api/v1/volumes.py', 'cinder/api/contrib/volume_mig_status_attribute.py', 'cinder/tests/api/openstack/test_wsgi.py', 'cinder/api/v2/volumes.py', 'cinder/api/contrib/backups.py', 'cinder/api/contrib/extended_snapshot_attributes.py', 'cinder/api/contrib/volume_host_attribute.py', 'cinder/api/contrib/volume_tenant_attribute.py', 'cinder/tests/api/contrib/test_extended_snapshot_attributes.py', 'cinder/api/v2/snapshots.py', 'cinder/api/openstack/wsgi.py', 'cinder/api/v1/snapshots.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4aeb7256ef4cc75bae4ff9258a5bcf6092b3c834', 'message': ""Improve Cinder API internal cache interface\n\nImprove the internal caching system used by the API layer\nby borrowing the implementation used by Nova.\n\nUnlike the previous implementation, this new interface makes it clear\nwhich resource types are added or retrieved from the cache.\n\nThis change also adds other resources to the cache:\n- backups\n- snapshots\n- volume types\n\nIt's now possible to remove database access those extensions:\n- extended_snapshot_attributes\n- volume_host_attribute\n- volume_mig_status_attribute\n- volume_tenant_attribute\n\nCloses-bug: #1358524\nChange-Id: I1fc673d0c01c41faa98292d5813d4471b455d712\n""}]",1,115404,4aeb7256ef4cc75bae4ff9258a5bcf6092b3c834,23,9,5,7156,,,0,"Improve Cinder API internal cache interface

Improve the internal caching system used by the API layer
by borrowing the implementation used by Nova.

Unlike the previous implementation, this new interface makes it clear
which resource types are added or retrieved from the cache.

This change also adds other resources to the cache:
- backups
- snapshots
- volume types

It's now possible to remove database access those extensions:
- extended_snapshot_attributes
- volume_host_attribute
- volume_mig_status_attribute
- volume_tenant_attribute

Closes-bug: #1358524
Change-Id: I1fc673d0c01c41faa98292d5813d4471b455d712
",git fetch https://review.opendev.org/openstack/cinder refs/changes/04/115404/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/v1/volumes.py', 'cinder/api/contrib/volume_mig_status_attribute.py', 'cinder/tests/api/openstack/test_wsgi.py', 'cinder/api/v2/volumes.py', 'cinder/api/contrib/backups.py', 'cinder/api/contrib/extended_snapshot_attributes.py', 'cinder/api/contrib/volume_host_attribute.py', 'cinder/api/contrib/volume_tenant_attribute.py', 'cinder/tests/api/contrib/test_extended_snapshot_attributes.py', 'cinder/api/v2/snapshots.py', 'cinder/api/openstack/wsgi.py', 'cinder/api/v1/snapshots.py']",12,3f739591a30a74486a4b59789475011eecd9957a,bug/1358524," snapshot = self.volume_api.get_snapshot(context, id) req.cache_db_snapshot(snapshot) return {'snapshot': _translate_snapshot_detail_view(context, snapshot)} req.cache_db_snapshots(snapshots) req.cache_db_snapshot(new_snapshot) req.cache_db_snapshot(snapshot)"," vol = self.volume_api.get_snapshot(context, id) return {'snapshot': _translate_snapshot_detail_view(context, vol)}",146,60
openstack%2Fcinder~master~Icc1b5f2ccf0b630c1e655f5e6abf4e25ee30afc4,openstack/cinder,master,Icc1b5f2ccf0b630c1e655f5e6abf4e25ee30afc4,Turn on Flake-8 Complexity Checking,MERGED,2014-10-17 04:46:48.000000000,2014-10-19 05:15:59.000000000,2014-10-19 05:15:58.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 8247}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 12017}, {'_account_id': 12369}]","[{'number': 1, 'created': '2014-10-17 04:46:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/af264c6b00d5ffa665dd8237eec42a551c795973', 'message': 'Turn on Flake-8 Complexity Checking\n\nFlake8 provides the ability to measure code complexity. There are\na lot of modules in Cinder that are considered ""too complex"", the\nworst being ""cinder/tests/test_huawei_hvs.py:110:1:"" with a complexity\nranking of 59.\n\nLet\'s cap that as our highest allowed complexity for now, and as\nwe fix these up drop the max allowed value in tox.ini.\n\nSee flake8.readthedocs for more info on flake8 and McCabe complexity\nchecking.\n\nChange-Id: Icc1b5f2ccf0b630c1e655f5e6abf4e25ee30afc4\n'}, {'number': 2, 'created': '2014-10-17 14:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8173ceaab6294302fd5089c795ef76c9ca01c801', 'message': 'Turn on Flake-8 Complexity Checking\n\nFlake8 provides the ability to measure code complexity. There are\na lot of modules in Cinder that are considered ""too complex"", the\nworst being ""cinder/tests/test_huawei_hvs.py:110:1:"" with a complexity\nranking of 59.\n\nLet\'s cap that as our highest allowed complexity for now, and as\nwe fix these up drop the max allowed value in tox.ini.\n\nSee flake8.readthedocs for more info on flake8 and McCabe complexity\nchecking.\n\nChange-Id: Icc1b5f2ccf0b630c1e655f5e6abf4e25ee30afc4\n'}, {'number': 3, 'created': '2014-10-17 19:55:18.000000000', 'files': ['cinder/tests/test_huawei_hvs.py', 'cinder/tests/test_netapp.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fc6c7285cd363cc634f258b69001a7911425778b', 'message': 'Turn on Flake-8 Complexity Checking\n\nFlake8 provides the ability to measure code complexity. There are\na lot of modules in Cinder that are considered ""too complex"", the\nworst being ""cinder/tests/test_huawei_hvs.py:110:1:"" with a complexity\nranking of 59.\n\nThere\'s some outlyers at the higher end here, but the majority of the\ncode checks in at under 30, so let\'s make that our threshold and ignore\nthe two offenders that are above that for now.\n\nGranted this may or may not be valuable, but it doesn\'t hurt to try it\nand if we all hate it or find there\'s no value but it makes life difficult\nwe can always turn it back off.\n\nSee flake8.readthedocs for more info on flake8 and McCabe complexity\nchecking.\n\nChange-Id: Icc1b5f2ccf0b630c1e655f5e6abf4e25ee30afc4\n'}]",1,129129,fc6c7285cd363cc634f258b69001a7911425778b,21,11,3,2243,,,0,"Turn on Flake-8 Complexity Checking

Flake8 provides the ability to measure code complexity. There are
a lot of modules in Cinder that are considered ""too complex"", the
worst being ""cinder/tests/test_huawei_hvs.py:110:1:"" with a complexity
ranking of 59.

There's some outlyers at the higher end here, but the majority of the
code checks in at under 30, so let's make that our threshold and ignore
the two offenders that are above that for now.

Granted this may or may not be valuable, but it doesn't hurt to try it
and if we all hate it or find there's no value but it makes life difficult
we can always turn it back off.

See flake8.readthedocs for more info on flake8 and McCabe complexity
checking.

Change-Id: Icc1b5f2ccf0b630c1e655f5e6abf4e25ee30afc4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/29/129129/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,af264c6b00d5ffa665dd8237eec42a551c795973,add_check_for_complexity,max-complexity=59,,1,0
openstack%2Ftempest~master~I756b6dff596ead6661dbdfbd7116e52c1ad755bd,openstack/tempest,master,I756b6dff596ead6661dbdfbd7116e52c1ad755bd,Test volume snapshots with multi backend setup,ABANDONED,2014-10-06 10:54:15.000000000,2014-10-19 04:55:18.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 7350}, {'_account_id': 10385}, {'_account_id': 11075}]","[{'number': 1, 'created': '2014-10-06 10:54:15.000000000', 'files': ['tempest/api/volume/admin/test_multi_backend_snapshot_actions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/221fd13f800c87daa28e061de336a66818cf9fe3', 'message': 'Test volume snapshots with multi backend setup\n\nChange-Id: I756b6dff596ead6661dbdfbd7116e52c1ad755bd\n'}]",0,126256,221fd13f800c87daa28e061de336a66818cf9fe3,9,13,1,11075,,,0,"Test volume snapshots with multi backend setup

Change-Id: I756b6dff596ead6661dbdfbd7116e52c1ad755bd
",git fetch https://review.opendev.org/openstack/tempest refs/changes/56/126256/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/volume/admin/test_multi_backend_snapshot_actions.py'],1,221fd13f800c87daa28e061de336a66818cf9fe3,multi-backend,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.api.volume import base from tempest.common.utils import data_utils from tempest import config from tempest.openstack.common import log as logging from tempest import test CONF = config.CONF LOG = logging.getLogger(__name__) class SnapshotsActionsMultiBackendTest(base.BaseVolumeV1AdminTest): _interface = ""json"" @classmethod def resource_setup(cls): # Create snapshots per volume backend. # Keep all volumes and snapshot in list for tests usage # each test uses existing snapshot, created from two different backend super(SnapshotsActionsMultiBackendTest, cls).resource_setup() if not CONF.volume_feature_enabled.multi_backend: raise cls.skipException(""Cinder multi-backend feature disabled"") # backend name from configuration file cls.backend1_name = CONF.volume.backend1_name cls.backend2_name = CONF.volume.backend2_name # volume and snapshot clients cls.admin_volume_client = cls.os_adm.volumes_client cls.admin_snapshots_client = cls.os_adm.snapshots_client # list to keep all volume_id and snapshot_id for tests usage cls.volume_type_id_list = [] cls.volume_id_list = [] cls.snapshot_id_list = [] # Volume/Type creation (uses volume_backend_name) cls._create_type_and_volume(cls.backend1_name) if cls.backend1_name != cls.backend2_name: # Volume/Type creation (uses backend2_name) cls._create_type_and_volume(cls.backend2_name) # Create shared snapshots per backend name for tests for volume_id in cls.volume_id_list: snap_name = data_utils.rand_name(cls.__name__ + '-Snapshot-') _, snapshot = cls.admin_snapshots_client.create_snapshot( volume_id, display_name=snap_name) cls.admin_snapshots_client.wait_for_snapshot_status( snapshot['id'], 'available') cls.snapshot_id_list.append(snapshot['id']) @classmethod def _create_type_and_volume(cls, backend_name_key): # Volume/Type creation type_name = data_utils.rand_name('Type') vol_name = data_utils.rand_name('Volume') spec_key_without_prefix = ""volume_backend_name"" extra_specs = {spec_key_without_prefix: backend_name_key} _, volume_type = cls.client.create_volume_type( type_name, extra_specs=extra_specs) cls.volume_type_id_list.append(volume_type['id']) _, volume = cls.admin_volume_client.create_volume( size=1, display_name=vol_name, volume_type=type_name) cls.volume_id_list.append(volume['id']) cls.admin_volume_client.wait_for_volume_status( volume['id'], 'available') def _reset_snapshot_status(self, snapshot_id, status): # Reset the snapshot status _, body = self.admin_snapshots_client.reset_snapshot_status( snapshot_id, status) return _, body @classmethod def resource_cleanup(cls): # snapshot deletion snapshot_id_l = getattr(cls, 'snapshot_id_list', []) for snapshot_id in snapshot_id_l: cls.admin_snapshots_client.delete_snapshot(snapshot_id) cls.admin_snapshots_client.wait_for_resource_deletion(snapshot_id) # volumes deletion volume_list = getattr(cls, 'volume_id_list', []) for volume_id in volume_list: cls.admin_volume_client.delete_volume(volume_id) cls.admin_volume_client.wait_for_resource_deletion(volume_id) # volume types deletion volume_type_list = getattr(cls, 'volume_type_id_list', []) for volume_type_id in volume_type_list: cls.client.delete_volume_type(volume_type_id) super(SnapshotsActionsMultiBackendTest, cls).resource_cleanup() @test.attr(type='gate') def test_reset_snapshot_status(self): # Reset snapshot status to creating status = 'creating' for snapshot_id in self.snapshot_id_list: _, body = self.admin_snapshots_client.\ reset_snapshot_status(snapshot_id, status) _, snapshot_get \ = self.admin_snapshots_client.get_snapshot(snapshot_id) self.assertEqual(status, snapshot_get['status']) self._reset_snapshot_status(snapshot_id, 'available') ",,110,0
openstack%2Ftaskflow~master~Iab0580ebe7534b5d432567f8fc3bb5696f62f134,openstack/taskflow,master,Iab0580ebe7534b5d432567f8fc3bb5696f62f134,Ensure that failure objects are pickleable,ABANDONED,2014-09-16 02:53:06.000000000,2014-10-19 04:35:45.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-09-16 02:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2366f29944aec22dcbc6cc55a001c007400b8a78', 'message': 'Ensure that failure objects a pickleable\n\nSince a child process may have a failure and return a failure\nobject across the parent <-> child process channel we need to\nmake sure failures are pickleable so that they can be sent and\nreceived without blowing up (especially when trying to pickle\na failures traceback reference).\n\nChange-Id: Iab0580ebe7534b5d432567f8fc3bb5696f62f134\n'}, {'number': 2, 'created': '2014-09-16 02:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c52b10c7a180d3ea8842035d2846dd3ff84a2d70', 'message': 'Ensure that failure objects are pickleable\n\nSince a child process may have a failure and return a failure\nobject across the parent <-> child process channel we need to\nmake sure failures are pickleable so that they can be sent and\nreceived without blowing up (especially when trying to pickle\na failures traceback reference).\n\nChange-Id: Iab0580ebe7534b5d432567f8fc3bb5696f62f134\n'}, {'number': 3, 'created': '2014-09-16 03:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dbdd95695ed5ecbb0a0af3b0c2fb924205575ceb', 'message': 'Ensure that failure objects are pickleable\n\nSince a child process may have a failure and return a failure\nobject across the parent <-> child process channel we need to\nmake sure failures are pickleable so that they can be sent and\nreceived without blowing up (especially when trying to pickle\na failures traceback reference).\n\nChange-Id: Iab0580ebe7534b5d432567f8fc3bb5696f62f134\n'}, {'number': 4, 'created': '2014-09-16 19:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c36de3b894d9b70d1d348e82d914d37a23eb3f9b', 'message': 'Ensure that failure objects are pickleable\n\nSince a child process may have a failure and return a failure\nobject across the parent <-> child process channel we need to\nmake sure failures are pickleable so that they can be sent and\nreceived without blowing up (especially when trying to pickle\na failures traceback reference).\n\nChange-Id: Iab0580ebe7534b5d432567f8fc3bb5696f62f134\n'}, {'number': 5, 'created': '2014-09-16 19:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0d094b89c311198526047d762a9cfa3c9a961dae', 'message': 'Ensure that failure objects are pickleable\n\nSince a child process may have a failure and return a failure\nobject across the parent <-> child process channel we need to\nmake sure failures are pickleable so that they can be sent and\nreceived without blowing up (especially when trying to pickle\na failures traceback reference).\n\nChange-Id: Iab0580ebe7534b5d432567f8fc3bb5696f62f134\n'}, {'number': 6, 'created': '2014-09-16 19:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/69017af8ae98e99aa7d75a355cd0dfb240eb3375', 'message': 'Ensure that failure objects are pickleable\n\nSince a child process may have a failure and return a failure\nobject across the parent <-> child process channel we need to\nmake sure failures are pickleable so that they can be sent and\nreceived without blowing up (especially when trying to pickle\na failures traceback reference).\n\nChange-Id: Iab0580ebe7534b5d432567f8fc3bb5696f62f134\n'}, {'number': 7, 'created': '2014-09-19 05:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b8133880eda71125afe64edcf89da59482675870', 'message': 'Ensure that failure objects are pickleable\n\nSince a child process may have a failure and return a failure\nobject across the parent <-> child process channel we need to\nmake sure failures are pickleable so that they can be sent and\nreceived without blowing up (especially when trying to pickle\na failures traceback reference).\n\nChange-Id: Iab0580ebe7534b5d432567f8fc3bb5696f62f134\n'}, {'number': 8, 'created': '2014-09-19 20:59:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8dfc601c2b76dc329248be2f95b69863d2b52150', 'message': 'Ensure that failure objects are pickleable\n\nSince a child process may have a failure and return a failure\nobject across the parent <-> child process channel we need to\nmake sure failures are pickleable so that they can be sent and\nreceived without blowing up (especially when trying to pickle\na failures traceback reference).\n\nChange-Id: Iab0580ebe7534b5d432567f8fc3bb5696f62f134\n'}, {'number': 9, 'created': '2014-09-23 03:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/931a58ad8e894bae0b8ae302c3c9fd1f9c39a732', 'message': 'Ensure that failure objects are pickleable\n\nSince a child process may have a failure and return a failure\nobject across the parent <-> child process channel we need to\nmake sure failures are pickleable so that they can be sent and\nreceived without blowing up (especially when trying to pickle\na failures traceback reference).\n\nChange-Id: Iab0580ebe7534b5d432567f8fc3bb5696f62f134\n'}, {'number': 10, 'created': '2014-09-26 20:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9f3fe9a089daf2adb305498e082e553ee4c3878b', 'message': 'Ensure that failure objects are pickleable\n\nSince a child process may have a failure and return a failure\nobject across the parent <-> child process channel we need to\nmake sure failures are pickleable so that they can be sent and\nreceived without blowing up (especially when trying to pickle\na failures traceback reference).\n\nChange-Id: Iab0580ebe7534b5d432567f8fc3bb5696f62f134\n'}, {'number': 11, 'created': '2014-10-15 01:16:47.000000000', 'files': ['taskflow/utils/misc.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f0bde95cf630ea4702dc894d9e58f28069b46ed3', 'message': 'Ensure that failure objects are pickleable\n\nSince a child process may have a failure and return a failure\nobject across the parent <-> child process channel we need to\nmake sure failures are pickleable so that they can be sent and\nreceived without blowing up (especially when trying to pickle\na failures traceback reference).\n\nChange-Id: Iab0580ebe7534b5d432567f8fc3bb5696f62f134\n'}]",0,121735,f0bde95cf630ea4702dc894d9e58f28069b46ed3,27,3,11,1297,,,0,"Ensure that failure objects are pickleable

Since a child process may have a failure and return a failure
object across the parent <-> child process channel we need to
make sure failures are pickleable so that they can be sent and
received without blowing up (especially when trying to pickle
a failures traceback reference).

Change-Id: Iab0580ebe7534b5d432567f8fc3bb5696f62f134
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/35/121735/11 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/utils/misc.py'],1,2366f29944aec22dcbc6cc55a001c007400b8a78,," def __getstate__(self): dct = self.to_dict() del dct['version'] if self._exc_info: # Avoids 'TypeError: can't pickle traceback objects' dct['exc_info'] = self._exc_info[0:2] return dct def __setstate__(self, dct): self._exception_str = dct['exception_str'] self._traceback_str = dct['traceback_str'] self._exc_type_names = dct['exc_type_names'] if 'exc_info' in dct: # Tracebacks can't be serialized/deserialized, but since we # provide a traceback string (and more) this should be # acceptable... self._exc_info = tuple(dct['exc_info']) + (None,) else: self._exc_info = None ",,20,0
openstack%2Ftaskflow~master~I6499353dc2f84d7f732fba5d4553b1cc73bab48e,openstack/taskflow,master,I6499353dc2f84d7f732fba5d4553b1cc73bab48e,Just use the natural module name instead of aliasing to tt,ABANDONED,2014-09-04 19:43:29.000000000,2014-10-19 03:49:29.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-09-04 19:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/bd2c37206aaaed335f3f134cadf8f70773ee2eea', 'message': 'Just use the natural module name instead of aliasing to tt\n\nTo make it easier to mock and figure out what this module is\nlet us just rename it to its natural name instead of an aliased\nname where it makes sense to do so.\n\nChange-Id: I6499353dc2f84d7f732fba5d4553b1cc73bab48e\n'}, {'number': 2, 'created': '2014-09-09 02:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b1d7f878fd31bec218ae11cbad8f1c3c23147c0f', 'message': 'Just use the natural module name instead of aliasing to tt\n\nTo make it easier to mock and figure out what this module is\nlet us just rename it to its natural name instead of an aliased\nname where it makes sense to do so.\n\nChange-Id: I6499353dc2f84d7f732fba5d4553b1cc73bab48e\n'}, {'number': 3, 'created': '2014-09-15 17:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9fc31a05e6f3ac054c26de1a2aa873a16fc055c6', 'message': 'Just use the natural module name instead of aliasing to tt\n\nTo make it easier to mock and figure out what this module is\nlet us just rename it to its natural name instead of an aliased\nname where it makes sense to do so.\n\nChange-Id: I6499353dc2f84d7f732fba5d4553b1cc73bab48e\n'}, {'number': 4, 'created': '2014-09-20 16:02:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2bbe2eeb800808d112e50ae55cc1cffb5fe9565c', 'message': 'Just use the natural module name instead of aliasing to tt\n\nTo make it easier to mock and figure out what this module is\nlet us just rename it to its natural name instead of an aliased\nname where it makes sense to do so.\n\nChange-Id: I6499353dc2f84d7f732fba5d4553b1cc73bab48e\n'}, {'number': 5, 'created': '2014-09-26 19:41:41.000000000', 'files': ['taskflow/conductors/single_threaded.py', 'taskflow/engines/worker_based/executor.py', 'taskflow/listeners/timing.py', 'taskflow/jobs/backends/impl_zookeeper.py', 'taskflow/tests/unit/test_types.py', 'taskflow/types/latch.py', 'taskflow/engines/worker_based/protocol.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e31f8372ce5baee717a69acd3a84c3903423638e', 'message': 'Just use the natural module name instead of aliasing to tt\n\nTo make it easier to mock and figure out what this module is\nlet us just rename it to its natural name instead of an aliased\nname where it makes sense to do so.\n\nChange-Id: I6499353dc2f84d7f732fba5d4553b1cc73bab48e\n'}]",2,119186,e31f8372ce5baee717a69acd3a84c3903423638e,17,3,5,1297,,,0,"Just use the natural module name instead of aliasing to tt

To make it easier to mock and figure out what this module is
let us just rename it to its natural name instead of an aliased
name where it makes sense to do so.

Change-Id: I6499353dc2f84d7f732fba5d4553b1cc73bab48e
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/86/119186/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/conductors/single_threaded.py', 'taskflow/engines/worker_based/executor.py', 'taskflow/listeners/timing.py', 'taskflow/jobs/backends/impl_zookeeper.py', 'taskflow/tests/unit/test_types.py', 'taskflow/types/latch.py', 'taskflow/engines/worker_based/protocol.py']",7,bd2c37206aaaed335f3f134cadf8f70773ee2eea,,from taskflow.types import timing self._watch = timing.StopWatch(duration=timeout).start(),from taskflow.types import timing as tt self._watch = tt.StopWatch(duration=timeout).start(),24,22
openstack%2Fpython-manilaclient~master~I8afc230eb82f3c3591fb11638e6911094b50baf8,openstack/python-manilaclient,master,I8afc230eb82f3c3591fb11638e6911094b50baf8,Add new filters for 'security-service-list' command,MERGED,2014-10-06 08:55:30.000000000,2014-10-19 03:03:32.000000000,2014-10-19 03:03:32.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7331}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-10-06 08:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/ed4135b06b8670b308d9abe721082c4023409217', 'message': ""Add new filters for 'security-service-list' command\n\nAdd filtering by following options:\n- share network\n- name\n- type\n- user\n- dns-ip\n- server\n- domain\n\nAdd information about share networks to output if\n'--detailed' options is enabled.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8afc230eb82f3c3591fb11638e6911094b50baf8\n""}, {'number': 2, 'created': '2014-10-09 07:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/4743c28f3337c7ca8ee9fcc9f5ea23150020242f', 'message': ""Add new filters for 'security-service-list' command\n\nAdd filtering by following options:\n- share network\n- name\n- type\n- user\n- dns-ip\n- server\n- domain\n\nAdd information about share networks to output if\n'--detailed' options is enabled.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8afc230eb82f3c3591fb11638e6911094b50baf8\n""}, {'number': 3, 'created': '2014-10-09 07:29:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/88bde564cf3f8d424bd255f9d4d2ba11336738fa', 'message': ""Add new filters for 'security-service-list' command\n\nAdd filtering by following options:\n- share network\n- name\n- type\n- user\n- dns-ip\n- server\n- domain\n\nAdd information about share networks to output if\n'--detailed' options is enabled.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8afc230eb82f3c3591fb11638e6911094b50baf8\n""}, {'number': 4, 'created': '2014-10-15 08:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/19d0a8e93e659e10dbb280e14e5df807573d1602', 'message': ""Add new filters for 'security-service-list' command\n\nAdd filtering by following options:\n- share network\n- name\n- type\n- user\n- dns-ip\n- server\n- domain\n\nAdd information about share networks to output if\n'--detailed' options is enabled.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8afc230eb82f3c3591fb11638e6911094b50baf8\n""}, {'number': 5, 'created': '2014-10-16 07:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/47019b5a2fcc53267940ea1ce4e7855d6d824f81', 'message': ""Add new filters for 'security-service-list' command\n\nAdd filtering by following options:\n- share network\n- name\n- type\n- user\n- dns-ip\n- server\n- domain\n\nAdd information about share networks to output if\n'--detailed' options is enabled.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8afc230eb82f3c3591fb11638e6911094b50baf8\n""}, {'number': 6, 'created': '2014-10-17 13:15:40.000000000', 'files': ['tests/v1/test_shell.py', 'manilaclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/d931e8c33bb486bc28821851e56fbd66a69fb605', 'message': ""Add new filters for 'security-service-list' command\n\nAdd filtering by following options:\n- share network\n- name\n- type\n- user\n- dns-ip\n- server\n- domain\n\nAdd information about share networks to output if\n'--detailed' options is enabled.\n\nAdd '--offset' and '--limit' options to specify start point\nof security services listing and number of security services to show.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8afc230eb82f3c3591fb11638e6911094b50baf8\n""}]",7,126240,d931e8c33bb486bc28821851e56fbd66a69fb605,22,5,6,7331,,,0,"Add new filters for 'security-service-list' command

Add filtering by following options:
- share network
- name
- type
- user
- dns-ip
- server
- domain

Add information about share networks to output if
'--detailed' options is enabled.

Add '--offset' and '--limit' options to specify start point
of security services listing and number of security services to show.

Implements bp improve-security-service-list-filtering

Change-Id: I8afc230eb82f3c3591fb11638e6911094b50baf8
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/40/126240/3 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/utils.py', 'manilaclient/v1/shell.py']",2,ed4135b06b8670b308d9abe721082c4023409217,bp/improve-security-service-list-filtering,"@cliutils.arg( '--share-network', metavar='<share_network>', default=None, help='Filter results by share network id or name.') @cliutils.arg( '--name', metavar='<name>', default=None, help='Filter results by name.') @cliutils.arg( '--type', metavar='<type>', default=None, help='Filter results by type.') @cliutils.arg( '--user', metavar='<user>', default=None, help='Filter results by user or group used by tenant.') @cliutils.arg( '--dns-ip', metavar='<dns_ip>', default=None, help=""Filter results by DNS IP address used inside tenant's network."") @cliutils.arg( '--server', metavar='<server>', default=None, help=""Filter results by security service IP address or hostname."") @cliutils.arg( '--domain', metavar='<domain>', default=None, help=""Filter results by domain."") @cliutils.arg( '--detailed', dest='detailed', nargs='?', type=bool, const=True, default=False, help=""Show detailed information about filtered security services."") 'name': args.name, 'type': args.type, 'user': args.user, 'dns_ip': args.dns_ip, 'server': args.server, 'domain': args.domain, } if args.share_network: search_opts['share_network_id'] = _find_share_network( cs, args.share_network).id security_services = cs.security_services.list(search_opts=search_opts, detailed=args.detailed) if args.detailed: fields.append('share_networks')", } security_services = cs.security_services.list(search_opts=search_opts),58,1
openstack%2Fpython-swiftclient~master~I9515203c969a1bba38dd909412355080383905f9,openstack/python-swiftclient,master,I9515203c969a1bba38dd909412355080383905f9,Fix the info command with --insecure,MERGED,2014-10-17 19:39:35.000000000,2014-10-19 03:00:39.000000000,2014-10-19 03:00:38.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 7479}]","[{'number': 1, 'created': '2014-10-17 19:39:35.000000000', 'files': ['swiftclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/b27ca7c0c0a57d5b25f1b658237eb8930d70af8f', 'message': 'Fix the info command with --insecure\n\nWe forgot to propagate options into http_connection() for the info\naka capabilities command. Fix is to use the proper helper.\n\nFixes bug: 1381866\n\nChange-Id: I9515203c969a1bba38dd909412355080383905f9\n'}]",0,129364,b27ca7c0c0a57d5b25f1b658237eb8930d70af8f,9,3,1,597,,,0,"Fix the info command with --insecure

We forgot to propagate options into http_connection() for the info
aka capabilities command. Fix is to use the proper helper.

Fixes bug: 1381866

Change-Id: I9515203c969a1bba38dd909412355080383905f9
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/64/129364/1 && git format-patch -1 --stdout FETCH_HEAD,['swiftclient/client.py'],1,b27ca7c0c0a57d5b25f1b658237eb8930d70af8f,bug/1381866," def http_connection(self, url=None): return http_connection(url if url else self.url, http_conn = self.http_connection(url)"," def http_connection(self): return http_connection(self.url, http_conn = http_connection(url, ssl_compression=self.ssl_compression)",3,3
openstack%2Ftaskflow~master~I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f,openstack/taskflow,master,I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f,Use and verify event and latch wait() return using timeouts,MERGED,2014-09-02 20:13:52.000000000,2014-10-19 02:53:48.000000000,2014-10-19 02:53:47.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-09-02 20:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a4ee861da4f8136d3b3d7b2247a525a3a4cd34f2', 'message': 'Use and verify event and latch waited for values with timeouts\n\nInstead of blocking up the whole test suite when a latch or\nevent was not decremented to its desired value (or not set for\nan event) we should use a reasonably high value that we use\nwhen waiting for those actions to occur and verify that when those\nwait() functions return that we have reached the desired state and\nif not either raise an exception or stop further testing.\n\nFixes bug 1363739\n\nChange-Id: I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f\n'}, {'number': 2, 'created': '2014-09-03 01:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/421f653cad70f153b2783fb408b5a95735bfcb30', 'message': 'Use and verify event and latch waited for values with timeouts\n\nInstead of blocking up the whole test suite when a latch or\nevent was not decremented to its desired value (or not set for\nan event) we should use a reasonably high value that we use\nwhen waiting for those actions to occur and verify that when those\nwait() functions return that we have reached the desired state and\nif not either raise an exception or stop further testing.\n\nFixes bug 1363739\n\nChange-Id: I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f\n'}, {'number': 4, 'created': '2014-09-07 00:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/72f97a30cf47b2e67acf7996865ab0e93c088f3b', 'message': 'Use and verify event and latch waited for values with timeouts\n\nInstead of blocking up the whole test suite when a latch or\nevent was not decremented to its desired value (or not set for\nan event) we should use a reasonably high value that we use\nwhen waiting for those actions to occur and verify that when those\nwait() functions return that we have reached the desired state and\nif not either raise an exception or stop further testing.\n\nFixes bug 1363739\n\nChange-Id: I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f\n'}, {'number': 5, 'created': '2014-09-07 00:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ab94f862c9ea6b17e04f8fdada64c93897fdd46e', 'message': 'Use and verify event and latch waited for values with timeouts\n\nInstead of blocking up the whole test suite when a latch or\nevent was not decremented to its desired value (or not set for\nan event) we should use a reasonably high value that we use\nwhen waiting for those actions to occur and verify that when those\nwait() functions return that we have reached the desired state and\nif not either raise an exception or stop further testing.\n\nFixes bug 1363739\n\nChange-Id: I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f\n'}, {'number': 6, 'created': '2014-09-09 02:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e29afe39cd386dfcef2276066f30d5fb8b6f4bea', 'message': 'Use and verify event and latch waited for values with timeouts\n\nInstead of blocking up the whole test suite when a latch or\nevent was not decremented to its desired value (or not set for\nan event) we should use a reasonably high value that we use\nwhen waiting for those actions to occur and verify that when those\nwait() functions return that we have reached the desired state and\nif not either raise an exception or stop further testing.\n\nFixes bug 1363739\n\nChange-Id: I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f\n'}, {'number': 7, 'created': '2014-09-09 18:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/012a94410792b4d6273359710e67ea5c9f812c45', 'message': 'Use and verify event and latch waited for values with timeouts\n\nInstead of blocking up the whole test suite when a latch or\nevent was not decremented to its desired value (or not set for\nan event) we should use a reasonably high value that we use\nwhen waiting for those actions to occur and verify that when those\nwait() functions return that we have reached the desired state and\nif not either raise an exception or stop further testing.\n\nFixes bug 1363739\n\nChange-Id: I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f\n'}, {'number': 8, 'created': '2014-09-23 01:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/987a69849819297b84e3413ed7b3a1f630307590', 'message': 'Use and verify event and latch wait() return using timeouts\n\nInstead of blocking up the whole test suite when a latch or\nevent was not decremented to its desired value (or not set for\nan event) we should use a reasonably high value that we use\nwhen waiting for those actions to occur and verify that when those\nwait() functions return that we have reached the desired state and\nif not either raise an exception or stop further testing.\n\nFixes bug 1363739\n\nChange-Id: I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f\n'}, {'number': 9, 'created': '2014-09-23 01:30:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/53268e30c555f402068c34da1121bb7cf79beda6', 'message': 'Use and verify event and latch wait() return using timeouts\n\nInstead of blocking up the whole test suite when a latch or\nevent was not decremented to its desired value (or not set for\nan event) we should use a reasonably high value that we use\nwhen waiting for those actions to occur and verify that when those\nwait() functions return that we have reached the desired state and\nif not either raise an exception or stop further testing.\n\nFixes bug 1363739\n\nChange-Id: I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f\n'}, {'number': 10, 'created': '2014-09-28 04:10:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/32b09d4a5197e3e57bcfd5da5b706546b9f971b9', 'message': 'Use and verify event and latch wait() return using timeouts\n\nInstead of blocking up the whole test suite when a latch or\nevent was not decremented to its desired value (or not set for\nan event) we should use a reasonably high value that we use\nwhen waiting for those actions to occur and verify that when those\nwait() functions return that we have reached the desired state and\nif not either raise an exception or stop further testing.\n\nFixes bug 1363739\n\nChange-Id: I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f\n'}, {'number': 11, 'created': '2014-10-19 00:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9ccc408efc6e2070fd24ee947e5f055bbd110aba', 'message': 'Use and verify event and latch wait() return using timeouts\n\nInstead of blocking up the whole test suite when a latch or\nevent was not decremented to its desired value (or not set for\nan event) we should use a reasonably high value that we use\nwhen waiting for those actions to occur and verify that when those\nwait() functions return that we have reached the desired state and\nif not either raise an exception or stop further testing.\n\nFixes bug 1363739\n\nChange-Id: I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f\n'}, {'number': 12, 'created': '2014-10-19 00:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/78f6cb75c6ae5f018bce23846e42ac21e25e3a2f', 'message': 'Use and verify event and latch wait() return using timeouts\n\nInstead of blocking up the whole test suite when a latch or\nevent was not decremented to its desired value (or not set for\nan event) we should use a reasonably high value that we use\nwhen waiting for those actions to occur and verify that when those\nwait() functions return that we have reached the desired state and\nif not either raise an exception or stop further testing.\n\nFixes bug 1363739\n\nChange-Id: I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f\n'}, {'number': 13, 'created': '2014-10-19 00:53:57.000000000', 'files': ['taskflow/conductors/single_threaded.py', 'taskflow/engines/worker_based/proxy.py', 'taskflow/tests/unit/conductor/test_conductor.py', 'taskflow/types/timing.py', 'taskflow/tests/unit/jobs/base.py', 'taskflow/utils/threading_utils.py', 'taskflow/tests/unit/worker_based/test_executor.py', 'taskflow/tests/unit/worker_based/test_message_pump.py', 'taskflow/tests/utils.py', 'taskflow/tests/unit/test_utils_lock_utils.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7ca631356efd943bf8e246a6a907653a70a35771', 'message': 'Use and verify event and latch wait() return using timeouts\n\nInstead of blocking up the whole test suite when a latch or\nevent was not decremented to its desired value (or not set for\nan event) we should use a reasonably high value that we use\nwhen waiting for those actions to occur and verify that when those\nwait() functions return that we have reached the desired state and\nif not either raise an exception or stop further testing.\n\nFixes bug 1363739\n\nChange-Id: I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f\n'}]",0,118460,7ca631356efd943bf8e246a6a907653a70a35771,31,3,12,1297,,,0,"Use and verify event and latch wait() return using timeouts

Instead of blocking up the whole test suite when a latch or
event was not decremented to its desired value (or not set for
an event) we should use a reasonably high value that we use
when waiting for those actions to occur and verify that when those
wait() functions return that we have reached the desired state and
if not either raise an exception or stop further testing.

Fixes bug 1363739

Change-Id: I8b40282ac2db9cabd48b0b65c8a2a49610d77c4f
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/60/118460/13 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/tests/unit/conductor/test_conductor.py', 'taskflow/tests/unit/jobs/base.py', 'taskflow/tests/unit/worker_based/test_executor.py', 'taskflow/tests/unit/worker_based/test_message_pump.py', 'taskflow/tests/utils.py', 'taskflow/tests/unit/test_utils_lock_utils.py', 'taskflow/types/latch.py']",7,a4ee861da4f8136d3b3d7b2247a525a3a4cd34f2,bug/1363739,from taskflow.types import timing w = timing.StopWatch(timeout).start(),from taskflow.types import timing as tt w = tt.StopWatch(timeout).start(),65,42
openstack%2Fmanila~master~I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559,openstack/manila,master,I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559,Add new search options for security service,MERGED,2014-10-02 08:28:10.000000000,2014-10-19 02:53:34.000000000,2014-10-19 02:53:33.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 6529}, {'_account_id': 7331}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-10-02 08:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/94f23572c9a02f7ddd9b0c68fc5426ac08e36098', 'message': 'Add new search options for security service\n\nWe can filter security services only by status, name, id and type now.\n\nAdd new search options:\n    user,\n    server,\n    dns_ip,\n    domain\nto _get_security_services in SecurityServiceController.\n\nAdd unit test for filtering secutiry services.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559\n'}, {'number': 2, 'created': '2014-10-06 07:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/8b44c1d0ab4e7631eda9154d84a2a9e0959ba698', 'message': ""Add new search options for security service\n\nWe can filter security services only by status, name, id and type now.\n\nAdd new search options:\n    user,\n    server,\n    dns_ip,\n    domain\nto _get_security_services in SecurityServiceController to be able to filter\nsecurity services by these fields.\n\nAllow of filtering security services by share network id.\n\nAdd information about share networks to result if 'detailed' mode enabled.\n\nAdd unit test for filtering secutiry services.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559\n""}, {'number': 3, 'created': '2014-10-07 07:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/157c1795c339aa0aa1d29a55fba0fea97858ac00', 'message': ""Add new search options for security service\n\nWe can filter security services only by status, name, id and type now.\n\nAdd new search options:\n    user,\n    server,\n    dns_ip,\n    domain\nto _get_security_services in SecurityServiceController to be able to filter\nsecurity services by these fields.\n\nAllow filtering security services by share network id.\n\nAdd information about share networks to result if 'detailed' mode enabled.\n\nAdd unit test for filtering security services.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559\n""}, {'number': 4, 'created': '2014-10-07 07:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/15c5017c57222c1dceab5a276c0fb0f4f6c27d55', 'message': ""Add new search options for security service\n\nWe can filter security services only by status, name, id and type now.\n\nAdd new search options:\n    user,\n    server,\n    dns_ip,\n    domain\nto _get_security_services in SecurityServiceController to be able to filter\nsecurity services by these fields.\n\nAllow filtering security services by share network id.\n\nAdd information about share networks to result if 'detailed' mode enabled.\n\nAdd unit test for filtering security services.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559\n""}, {'number': 5, 'created': '2014-10-07 08:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f5e34431fe463f169231ac86e7440c78e74bc78a', 'message': ""Add new search options for security service\n\nWe can filter security services only by status, name, id and type now.\n\nAdd new search options:\n    user,\n    server,\n    dns_ip,\n    domain\nto _get_security_services in SecurityServiceController to be able to filter\nsecurity services by these fields.\n\nAllow filtering security services by share network id.\n\nAdd information about share networks to result if 'detailed' mode enabled.\n\nAdd unit test for filtering security services.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559\n""}, {'number': 6, 'created': '2014-10-08 07:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/8b703328c871b8e941aa95cd2a5cb6574f28fe95', 'message': ""Add new search options for security service\n\nWe can filter security services only by status, name, id and type now.\n\nAdd new search options:\n    user,\n    server,\n    dns_ip,\n    domain\nto _get_security_services in SecurityServiceController to be able to filter\nsecurity services by these fields.\n\nAllow filtering security services by share network id.\n\nAdd information about share networks to result if 'detailed' mode enabled.\n\nAdd unit test for filtering security services.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559\n""}, {'number': 7, 'created': '2014-10-08 08:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0a8e20f553040c4e4a621957a72d99054791ecb0', 'message': ""Add new search options for security service\n\nWe can filter security services only by status, name, id and type now.\n\nAdd new search options:\n    user,\n    server,\n    dns_ip,\n    domain\nto _get_security_services in SecurityServiceController to be able to filter\nsecurity services by these fields.\n\nAllow filtering security services by share network id.\n\nAdd information about share networks to result if 'detailed' mode enabled.\n\nAdd unit test for filtering security services.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559\n""}, {'number': 8, 'created': '2014-10-13 08:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2733d864c914d909d9a5b56e311ee391a6a07605', 'message': ""Add new search options for security service\n\nWe can filter security services only by status, name, id and type now.\n\nAdd new search options:\n    user,\n    server,\n    dns_ip,\n    domain\nto _get_security_services in SecurityServiceController to be able to filter\nsecurity services by these fields.\n\nAllow filtering security services by share network id.\n\nAdd information about share networks to result if 'detailed' mode enabled.\n\nAdd unit and tempest tests for filtering security services.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559\n""}, {'number': 9, 'created': '2014-10-15 06:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e5b12edd0df446daa41ca37ff923b7ff5f487f4c', 'message': ""Add new search options for security service\n\nWe can filter security services only by status, name, id and type now.\n\nAdd new search options:\n    user,\n    server,\n    dns_ip,\n    domain\nto _get_security_services in SecurityServiceController to be able to filter\nsecurity services by these fields.\n\nAllow filtering security services by share network id.\n\nAdd information about share networks to result if 'detailed' mode enabled.\n\nAdd unit and tempest tests for filtering security services.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559\n""}, {'number': 10, 'created': '2014-10-15 07:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0ab523771bd4e924371d16c816fef15895b7c149', 'message': ""Add new search options for security service\n\nWe can filter security services only by status, name, id and type now.\n\nAdd new search options:\n    user,\n    server,\n    dns_ip,\n    domain\nto _get_security_services in SecurityServiceController to be able to filter\nsecurity services by these fields.\n\nAllow filtering security services by share network id.\n\nAdd information about share networks to result if 'detailed' mode enabled.\n\nAdd unit and tempest tests for filtering security services.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559\n""}, {'number': 11, 'created': '2014-10-16 07:18:17.000000000', 'files': ['contrib/tempest/tempest/api/share/admin/test_security_services.py', 'contrib/tempest/tempest/services/share/json/shares_client.py', 'etc/manila/policy.json', 'contrib/tempest/tempest/api/share/test_security_services_negative.py', 'manila/tests/policy.json', 'manila/api/v1/security_service.py', 'contrib/tempest/tempest/api/share/test_security_services.py', 'manila/tests/api/v1/test_security_service.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/f3289eb6103b8def1a925d08357985b14860ea86', 'message': ""Add new search options for security service\n\nWe can filter security services only by status, name, id and type now.\n\nAdd new search options:\n    user,\n    server,\n    dns_ip,\n    domain\nto _get_security_services in SecurityServiceController to be able to filter\nsecurity services by these fields.\n\nAllow filtering security services by share network id.\n\nAdd information about share networks to result if 'detailed' mode enabled.\n\nAdd unit and tempest tests for filtering security services.\n\nImplements bp improve-security-service-list-filtering\n\nChange-Id: I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559\n""}]",20,125569,f3289eb6103b8def1a925d08357985b14860ea86,39,6,11,7331,,,0,"Add new search options for security service

We can filter security services only by status, name, id and type now.

Add new search options:
    user,
    server,
    dns_ip,
    domain
to _get_security_services in SecurityServiceController to be able to filter
security services by these fields.

Allow filtering security services by share network id.

Add information about share networks to result if 'detailed' mode enabled.

Add unit and tempest tests for filtering security services.

Implements bp improve-security-service-list-filtering

Change-Id: I8b3845c2d705188ec1dc0db33c1e20c8e6c5e559
",git fetch https://review.opendev.org/openstack/manila refs/changes/69/125569/7 && git format-patch -1 --stdout FETCH_HEAD,"['manila/api/v1/security_service.py', 'manila/tests/api/v1/test_security_service.py']",2,94f23572c9a02f7ddd9b0c68fc5426ac08e36098,bp/improve-security-service-list-filtering," @mock.patch.object(db, 'security_service_get_all_by_project', mock.Mock()) def test_security_service_list_filter(self): ss = self.security_service.copy() ss['name'] = 'ss-ldap' ss['id'] = 2 db.security_service_get_all_by_project.return_value = [ self.security_service, ss, ] req = fakes.HTTPRequest.blank('/security-services?name=fake-name') res_dict = self.controller.index(req) expected = { 'security_services': [{ 'id': self.security_service['id'], 'name': self.security_service['name'], 'type': self.security_service['type'], 'status': self.security_service['status'] }, ] } self.assertEqual(expected, res_dict)",,23,1
openstack%2Ftaskflow~master~Ic7617057338e0c63775cf38a24643cff6e454950,openstack/taskflow,master,Ic7617057338e0c63775cf38a24643cff6e454950,Deprecate `engine_conf` and prefer `engine` instead,MERGED,2014-09-17 05:51:12.000000000,2014-10-19 01:43:09.000000000,2014-10-19 01:43:07.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-09-17 05:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5112803048a5c9670985d66fad19414062f8d102', 'message': 'Depreciate `engine_conf` and prefer `engine` instead (WIP)\n\nTo avoid having one set of options coming from `engine_conf`\nand another set of options coming from `kwargs` and another set\ncoming from `engine_conf` if it is a URI just start to shift\ntoward `engine_conf` being depreciated and `engine` being a string\ntype only (or a URI with additional query parameters) and having\nany additional **kwargs that are provided just get merged into the\nfinal engine options.\n\nThis adds a new helper function that handles all these various\noptions and adds in a keyword argument `engine` that will be shifted\nto in a future version (in that future version we can also then\nremove the `engine_conf` and just stick to a smaller set of option\nmechanisms).\n\nChange-Id: Ic7617057338e0c63775cf38a24643cff6e454950\n'}, {'number': 2, 'created': '2014-09-17 07:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b05f0b23d3bf9855b983df55283e331bb53a8463', 'message': 'Depreciate `engine_conf` and prefer `engine` instead (WIP)\n\nTo avoid having one set of options coming from `engine_conf`\nand another set of options coming from `kwargs` and another set\ncoming from `engine_conf` if it is a URI just start to shift\ntoward `engine_conf` being depreciated and `engine` being a string\ntype only (or a URI with additional query parameters) and having\nany additional **kwargs that are provided just get merged into the\nfinal engine options.\n\nThis adds a new helper function that handles all these various\noptions and adds in a keyword argument `engine` that will be shifted\nto in a future version (in that future version we can also then\nremove the `engine_conf` and just stick to a smaller set of option\nmechanisms).\n\nChange-Id: Ic7617057338e0c63775cf38a24643cff6e454950\n'}, {'number': 3, 'created': '2014-09-17 19:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/078f05de6d64003f7b1581c5e83dfb505d47b33f', 'message': 'Deprecate `engine_conf` and prefer `engine` instead\n\nTo avoid having one set of options coming from `engine_conf`\nand another set of options coming from `kwargs` and another set\ncoming from `engine_conf` if it is a URI just start to shift\ntoward `engine_conf` being deprecated and `engine` being a string\ntype only (or a URI with additional query parameters) and having\nany additional **kwargs that are provided just get merged into the\nfinal engine options.\n\nThis adds a new helper function that handles all these various\noptions and adds in a keyword argument `engine` that will be shifted\nto in a future version (in that future version we can also then\nremove the `engine_conf` and just stick to a smaller set of option\nmechanisms). It also adjusts all examples to use this new and more\neasier to understand format and adjusts tests, conductor interface\nto use this new more easily understandable style of getting an engine.\n\nChange-Id: Ic7617057338e0c63775cf38a24643cff6e454950\n'}, {'number': 4, 'created': '2014-09-17 19:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b3131e474a5681aa49913fba7e5eeb518c327742', 'message': 'Deprecate `engine_conf` and prefer `engine` instead\n\nTo avoid having one set of options coming from `engine_conf`\nand another set of options coming from `kwargs` and another set\ncoming from `engine_conf` if it is a URI just start to shift\ntoward `engine_conf` being deprecated and `engine` being a string\ntype only (or a URI with additional query parameters) and having\nany additional **kwargs that are provided just get merged into the\nfinal engine options.\n\nThis adds a new helper function that handles all these various\noptions and adds in a keyword argument `engine` that will be shifted\nto in a future version (in that future version we can also then\nremove the `engine_conf` and just stick to a smaller set of option\nmechanisms).\n\nIt also adjusts all examples to use this new and more easier to\nunderstand format and adjusts tests, conductor interface to use\nthis new more easily understandable style of getting an engine.\n\nChange-Id: Ic7617057338e0c63775cf38a24643cff6e454950\n'}, {'number': 5, 'created': '2014-09-17 19:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a5f5e50f48de973a11b39640e51295b998cddc7d', 'message': 'Deprecate `engine_conf` and prefer `engine` instead\n\nTo avoid having one set of options coming from `engine_conf`\nand another set of options coming from `kwargs` and another set\ncoming from `engine_conf` if it is a URI just start to shift\ntoward `engine_conf` being deprecated and `engine` being a string\ntype only (or a URI with additional query parameters) and having\nany additional **kwargs that are provided just get merged into the\nfinal engine options.\n\nThis adds a new helper function that handles all these various\noptions and adds in a keyword argument `engine` that will be shifted\nto in a future version (in that future version we can also then\nremove the `engine_conf` and just stick to a smaller set of option\nmechanisms).\n\nIt also adjusts all examples to use this new and more easier to\nunderstand format and adjusts tests, conductor interface to use\nthis new more easily understandable style of getting an engine.\n\nChange-Id: Ic7617057338e0c63775cf38a24643cff6e454950\n'}, {'number': 6, 'created': '2014-09-17 21:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6ebf59202783acfb52183c91aa67d9b09d4c529a', 'message': 'Deprecate `engine_conf` and prefer `engine` instead\n\nTo avoid having one set of options coming from `engine_conf`\nand another set of options coming from `kwargs` and another set\ncoming from `engine_conf` if it is a URI just start to shift\ntoward `engine_conf` being deprecated and `engine` being a string\ntype only (or a URI with additional query parameters) and having\nany additional **kwargs that are provided just get merged into the\nfinal engine options.\n\nThis adds a new helper function that handles all these various\noptions and adds in a keyword argument `engine` that will be shifted\nto in a future version (in that future version we can also then\nremove the `engine_conf` and just stick to a smaller set of option\nmechanisms).\n\nIt also adjusts all examples to use this new and more easier to\nunderstand format and adjusts tests, conductor interface to use\nthis new more easily understandable style of getting an engine.\n\nChange-Id: Ic7617057338e0c63775cf38a24643cff6e454950\n'}, {'number': 7, 'created': '2014-09-17 22:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e6972d43bd9c795b67437bd623bdcc79479eea1b', 'message': 'Deprecate `engine_conf` and prefer `engine` instead\n\nTo avoid having one set of options coming from `engine_conf`\nand another set of options coming from `kwargs` and another set\ncoming from `engine_conf` if it is a URI just start to shift\ntoward `engine_conf` being deprecated and `engine` being a string\ntype only (or a URI with additional query parameters) and having\nany additional **kwargs that are provided just get merged into the\nfinal engine options.\n\nThis adds a new helper function that handles all these various\noptions and adds in a keyword argument `engine` that will be shifted\nto in a future version (in that future version we can also then\nremove the `engine_conf` and just stick to a smaller set of option\nmechanisms).\n\nIt also adjusts all examples to use this new and more easier to\nunderstand format and adjusts tests, conductor interface to use\nthis new more easily understandable style of getting an engine.\n\nChange-Id: Ic7617057338e0c63775cf38a24643cff6e454950\n'}, {'number': 8, 'created': '2014-09-23 03:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3da39c8dd7f6fbe9f8e4453e2d9b9b2b79cb5487', 'message': 'Deprecate `engine_conf` and prefer `engine` instead\n\nTo avoid having one set of options coming from `engine_conf`\nand another set of options coming from `kwargs` and another set\ncoming from `engine_conf` if it is a URI just start to shift\ntoward `engine_conf` being deprecated and `engine` being a string\ntype only (or a URI with additional query parameters) and having\nany additional **kwargs that are provided just get merged into the\nfinal engine options.\n\nThis adds a new helper function that handles all these various\noptions and adds in a keyword argument `engine` that will be shifted\nto in a future version (in that future version we can also then\nremove the `engine_conf` and just stick to a smaller set of option\nmechanisms).\n\nIt also adjusts all examples to use this new and more easier to\nunderstand format and adjusts tests, conductor interface to use\nthis new more easily understandable style of getting an engine.\n\nChange-Id: Ic7617057338e0c63775cf38a24643cff6e454950\n'}, {'number': 9, 'created': '2014-09-25 18:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ca1849693895533285b076f75f84edd1df70de6d', 'message': 'Deprecate `engine_conf` and prefer `engine` instead\n\nTo avoid having one set of options coming from `engine_conf`\nand another set of options coming from `kwargs` and another set\ncoming from `engine_conf` if it is a URI just start to shift\ntoward `engine_conf` being deprecated and `engine` being a string\ntype only (or a URI with additional query parameters) and having\nany additional **kwargs that are provided just get merged into the\nfinal engine options.\n\nThis adds a new helper function that handles all these various\noptions and adds in a keyword argument `engine` that will be shifted\nto in a future version (in that future version we can also then\nremove the `engine_conf` and just stick to a smaller set of option\nmechanisms).\n\nIt also adjusts all examples to use this new and more easier to\nunderstand format and adjusts tests, conductor interface to use\nthis new more easily understandable style of getting an engine.\n\nChange-Id: Ic7617057338e0c63775cf38a24643cff6e454950\n'}, {'number': 10, 'created': '2014-10-18 20:28:56.000000000', 'files': ['taskflow/engines/base.py', 'doc/source/workers.rst', 'taskflow/examples/delayed_return.py', 'taskflow/examples/create_parallel_volume.py', 'taskflow/examples/wrapped_exception.py', 'taskflow/examples/graph_flow.py', 'taskflow/engines/worker_based/engine.py', 'taskflow/examples/resume_vm_boot.py', 'taskflow/tests/unit/test_arguments_passing.py', 'taskflow/engines/helpers.py', 'taskflow/examples/calculate_in_parallel.py', 'taskflow/tests/unit/test_suspend_flow.py', 'taskflow/examples/wbe_simple_linear.py', 'taskflow/conductors/single_threaded.py', 'taskflow/examples/fake_billing.py', 'taskflow/tests/unit/test_retries.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/conductors/base.py', 'taskflow/examples/persistence_example.py', 'taskflow/tests/unit/conductor/test_conductor.py', 'doc/source/engines.rst', 'taskflow/tests/unit/test_engines.py', 'taskflow/examples/resume_volume_create.py', 'taskflow/tests/unit/test_engine_helpers.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d433a5323ff4fbf1d973ca7605ac62819c19039a', 'message': 'Deprecate `engine_conf` and prefer `engine` instead\n\nTo avoid having one set of options coming from `engine_conf`\nand another set of options coming from `kwargs` and another set\ncoming from `engine_conf` if it is a URI just start to shift\ntoward `engine_conf` being deprecated and `engine` being a string\ntype only (or a URI with additional query parameters) and having\nany additional **kwargs that are provided just get merged into the\nfinal engine options.\n\nThis adds a new helper function that handles all these various\noptions and adds in a keyword argument `engine` that will be shifted\nto in a future version (in that future version we can also then\nremove the `engine_conf` and just stick to a smaller set of option\nmechanisms).\n\nIt also adjusts all examples to use this new and more easier to\nunderstand format and adjusts tests, conductor interface to use\nthis new more easily understandable style of getting an engine.\n\nChange-Id: Ic7617057338e0c63775cf38a24643cff6e454950\n'}]",0,122065,d433a5323ff4fbf1d973ca7605ac62819c19039a,35,3,10,1297,,,0,"Deprecate `engine_conf` and prefer `engine` instead

To avoid having one set of options coming from `engine_conf`
and another set of options coming from `kwargs` and another set
coming from `engine_conf` if it is a URI just start to shift
toward `engine_conf` being deprecated and `engine` being a string
type only (or a URI with additional query parameters) and having
any additional **kwargs that are provided just get merged into the
final engine options.

This adds a new helper function that handles all these various
options and adds in a keyword argument `engine` that will be shifted
to in a future version (in that future version we can also then
remove the `engine_conf` and just stick to a smaller set of option
mechanisms).

It also adjusts all examples to use this new and more easier to
understand format and adjusts tests, conductor interface to use
this new more easily understandable style of getting an engine.

Change-Id: Ic7617057338e0c63775cf38a24643cff6e454950
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/65/122065/10 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/worker_based/engine.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/engines/base.py', 'taskflow/engines/helpers.py']",4,5112803048a5c9670985d66fad19414062f8d102,simpler-options,"import warningsENGINE_DEFAULT = 'default' def _extract_engine(**kwargs): options = {} kind = kwargs.pop('engine', None) engine_conf = kwargs.pop('engine_conf', None) if engine_conf: warnings.warn(""Using the 'engine_conf' argument is"" "" depreciated and will be removed in the next version,"" "" please use the 'engine' argument instead."", DeprecationWarning) if isinstance(engine_conf, six.string_types): kind = engine_conf else: options.update(engine_conf) kind = options.pop('engine', None) if not kind: kind = ENGINE_DEFAULT # See if it's a URI and if so, extract any further options... try: pieces = misc.parse_uri(kind) except (TypeError, ValueError): pass else: kind = pieces['scheme'] options = misc.merge_uri(pieces, options.copy()) # Merge in any leftover kwargs into the options, this makes it so that # the provided **kwargs override any URI or engine_conf specific options. options.update(kwargs) return (kind, options) engine_conf=None, backend=None, namespace=ENGINES_NAMESPACE, engine=ENGINE_DEFAULT, **kwargs): This function creates and prepares engine to run the flow. All that is left is to run the engine with engines ``run()`` method. Which engine to load is specified via the ``engine`` parameter. It can be a string that names the engine type to use, or a string that is a URI with a scheme that names the engine type to use and further options contained in the URI's query parameters. taskflow.persistence.backends.fetch() to obtain a viable backend. :param engine_conf: engine type or URI and options (**depreciated**) :param backend: storage backend to use or configuration that defines it :param engine: engine type or URI :param kwargs: Arbitrary keyword arguments passed as options (merged with any extracted ``engine`` and ``engine_conf`` options). kind, options = _extract_engine(engine_conf=engine_conf, engine=engine, **kwargs) namespace, kind, invoke_args=(flow, flow_detail, backend, options)) raise exc.NotFound(""Could not find engine %s"" % (kind), e) engine_conf=None, backend=None, namespace=ENGINES_NAMESPACE, engine=ENGINE_DEFAULT, **kwargs): This function loads the flow into an engine (with the :func:`load() <load>` function) and runs the engine. The arguments are interpreted as for :func:`load() <load>`. namespace=namespace, engine=engine, **kwargs) namespace=ENGINES_NAMESPACE, engine=ENGINE_DEFAULT, **kwargs): it. Then, the flow is loaded into an engine with the :func:`load() <load>` function, and the factory function fully qualified name is saved to flow metadata so that it can be later resumed. Further arguments are interpreted as for :func:`load() <load>`. engine=engine, **kwargs) namespace=ENGINES_NAMESPACE, engine=ENGINE_DEFAULT, **kwargs): This reloads the flow using the :func:`flow_from_detail() <flow_from_detail>` function and then calls into the :func:`load() <load>` function to create an engine from that flow. Further arguments are interpreted as for :func:`load() <load>`. namespace=namespace, engine=engine, **kwargs)"," engine_conf=None, backend=None, namespace=ENGINES_NAMESPACE, **kwargs): This function creates and prepares engine to run the flow. All that is left is to run the engine with 'run()' method. Which engine to load is specified in 'engine_conf' parameter. It can be a string that names engine type or a dictionary which holds engine type (with 'engine' key) and additional engine-specific configuration. taskflow.persistence.backends.fetch to obtain backend. :param engine_conf: engine type and configuration configuration :param backend: storage backend to use or configuration if engine_conf is None: engine_conf = {'engine': 'default'} # NOTE(imelnikov): this allows simpler syntax. if isinstance(engine_conf, six.string_types): engine_conf = {'engine': engine_conf} engine_name = engine_conf['engine'] try: pieces = misc.parse_uri(engine_name) except (TypeError, ValueError): pass else: engine_name = pieces['scheme'] engine_conf = misc.merge_uri(pieces, engine_conf.copy()) namespace, engine_name, invoke_args=(flow, flow_detail, backend, engine_conf), invoke_kwds=kwargs) raise exc.NotFound(""Could not find engine %s"" % (engine_name), e) engine_conf=None, backend=None, namespace=ENGINES_NAMESPACE, **kwargs): This function load the flow into engine (with 'load' function) and runs the engine. Which engine to load is specified in 'engine_conf' parameter. It can be a string that names engine type or a dictionary which holds engine type (with 'engine' key) and additional engine-specific configuration. Which storage backend to use is defined by backend parameter. It can be backend itself, or a dictionary that is passed to taskflow.persistence.backends.fetch to obtain backend. :param flow: flow to run :param store: dict -- data to put to storage to satisfy flow requirements :param flow_detail: FlowDetail that holds the state of the flow (if one is not provided then one will be created for you in the provided backend) :param book: LogBook to create flow detail in if flow_detail is None :param engine_conf: engine type and configuration configuration :param backend: storage backend to use or configuration :param namespace: driver namespace for stevedore (default is fine if you don't know what is it) namespace=namespace, **kwargs) namespace=ENGINES_NAMESPACE, **kwargs): it. Then, flow is loaded into engine with load(), and factory function fully qualified name is saved to flow metadata so that it can be later resumed with resume. :param store: dict -- data to put to storage to satisfy flow requirements :param book: LogBook to create flow detail in :param engine_conf: engine type and configuration configuration :param backend: storage backend to use or configuration :param namespace: driver namespace for stevedore (default is fine if you don't know what is it) **kwargs) namespace=ENGINES_NAMESPACE, **kwargs): This reloads the flow using the flow_from_detail() function and then calls into the load() function to create an engine from that flow. :param store: dict -- data to put to storage to satisfy flow requirements :param engine_conf: engine type and configuration configuration :param backend: storage backend to use or configuration :param namespace: driver namespace for stevedore (default is fine if you don't know what is it) namespace=namespace, **kwargs)",91,99
openstack%2Fhorizon~master~Ie1c959df7f7074c38fb1e464715194f93b2dc112,openstack/horizon,master,Ie1c959df7f7074c38fb1e464715194f93b2dc112,Removes term inconsistency in the dashboard,MERGED,2014-02-13 09:50:19.000000000,2014-10-19 01:34:35.000000000,2014-10-19 01:34:34.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 6914}, {'_account_id': 7213}, {'_account_id': 8040}, {'_account_id': 8871}, {'_account_id': 9178}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9659}, {'_account_id': 9750}, {'_account_id': 10295}]","[{'number': 1, 'created': '2014-02-13 09:50:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a11e623fc28ea766bbeef7da8d2decfb83ad4ffc', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\nPartial-Bug: #1272141\n'}, {'number': 2, 'created': '2014-04-04 17:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6a206c89e63100ee1cb6f954eadae9d61f865b19', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\nPartial-Bug: #1272141\n'}, {'number': 3, 'created': '2014-04-04 19:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1647a2abc3fe73d0606b62742ef872da88c2b3b9', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\nFixes-Bug: #1272141\n'}, {'number': 4, 'created': '2014-04-05 06:13:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/519130a5610d81e34eceb06b9bcc2b8cedf28555', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\nFixes-bug: #1272141\n'}, {'number': 5, 'created': '2014-07-21 05:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/436f402b61b1075b1909308d447753319c76606b', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nFixes-bug: #1272141\n\nConflicts:\n\n\thorizon/static/horizon/js/horizon.instances.js\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\n'}, {'number': 6, 'created': '2014-07-21 05:51:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/65a7319b1201c4b84aa4eae2ce0d932d948f6c82', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nPartial-Bug: #1272141\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\n'}, {'number': 7, 'created': '2014-07-21 06:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/dbd121f8021a5e0bbc553498316f119fc00b00e7', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nPartial-Bug: #1272141\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\n'}, {'number': 8, 'created': '2014-07-21 06:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4ef02646888693776c11429c3c7f0294a9e1d705', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nPartial-Bug: #1272141\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\n'}, {'number': 9, 'created': '2014-07-21 06:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9aeb0bdc0927f7efc2b27e8c10e0658112797032', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nCloses-bug: #1272141\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\n'}, {'number': 10, 'created': '2014-07-21 12:07:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/09a726ec568c0265ef5aaf2f2fd6f49382b0a628', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nCloses-bug: #1272141\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\n'}, {'number': 11, 'created': '2014-07-22 06:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/af9e2e6ebf14c64412edec7c792ed0781a8af52c', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nCloses-bug: #1272141\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\n'}, {'number': 12, 'created': '2014-09-05 07:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9928d696119ac0f420fb38c7447a6c3760e7b0c5', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nCloses-bug: #1272141\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\n'}, {'number': 13, 'created': '2014-10-16 18:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d4126df4eea491fb594d3dce09d90cfd628277db', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nCloses-bug: #1272141\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\n'}, {'number': 14, 'created': '2014-10-16 20:34:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bbb3342240391008e3d565922a7bcdaf74336687', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nCloses-bug: #1272141\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\n'}, {'number': 15, 'created': '2014-10-17 10:00:07.000000000', 'files': ['horizon/templatetags/sizeformat.py', 'openstack_dashboard/dashboards/identity/users/templates/users/_update.html', 'openstack_dashboard/dashboards/project/instances/workflows/create_instance.py', 'openstack_dashboard/dashboards/project/instances/templates/instances/_detail_overview.html', 'openstack_dashboard/dashboards/project/volumes/volumes/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/057bfd86b7c6c2f24e5879c9bd3f1c530103da0c', 'message': 'Removes term inconsistency in the dashboard\n\nMakes some text edits in order to bring consistency in the terms mentioned.\n\nCloses-bug: #1272141\n\nChange-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112\n'}]",19,73222,057bfd86b7c6c2f24e5879c9bd3f1c530103da0c,92,14,15,9178,,,0,"Removes term inconsistency in the dashboard

Makes some text edits in order to bring consistency in the terms mentioned.

Closes-bug: #1272141

Change-Id: Ie1c959df7f7074c38fb1e464715194f93b2dc112
",git fetch https://review.opendev.org/openstack/horizon refs/changes/22/73222/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/instances/workflows/create_instance.py', 'openstack_dashboard/dashboards/admin/users/templates/users/_update.html', 'openstack_dashboard/dashboards/project/volumes/templates/volumes/_detail_overview.html', 'openstack_dashboard/dashboards/project/volumes/templates/volumes/_attach.html']",4,a11e623fc28ea766bbeef7da8d2decfb83ad4ffc,bug/1272141,"{% block modal-header %}{% trans ""Edit Volume Attachments"" %}{% endblock %}","{% block modal-header %}{% trans ""Manage Volume Attachments"" %}{% endblock %}",8,8
openstack%2Fpython-openstackclient~master~I877a29de97a42f85f12a14c274fc003e6fba5135,openstack/python-openstackclient,master,I877a29de97a42f85f12a14c274fc003e6fba5135,Remove now-unnecessary client creation hacks,MERGED,2014-10-18 05:06:17.000000000,2014-10-18 23:46:31.000000000,2014-10-18 23:46:30.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-10-18 05:06:17.000000000', 'files': ['openstackclient/image/client.py', 'openstackclient/tests/common/test_clientmanager.py', 'openstackclient/compute/client.py', 'openstackclient/common/clientmanager.py', 'openstackclient/network/client.py', 'openstackclient/volume/client.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0de67016c7daa1712b568cb2e49728fac3eb57ad', 'message': ""Remove now-unnecessary client creation hacks\n\nClients that can use ksc Session don't need the old junk to\nfake auth anymore:\n* compute\n* volume\n\nClients that still need to be fed credentials can pick directly\nfrom the auth object in clientmanager.  The _token attribute is\nremoved, the token can be retrieved from the auth object:\n\n  openstackclient/tests/common/test_clientmanager.py\n\nThis change will break any plugin that relies on getting a token\nfrom instance._token. They should be updated to use the above, or\npreferable, to use keystoneclient.session.Session to create its\nHTTP interface object.\n\nChange-Id: I877a29de97a42f85f12a14c274fc003e6fba5135\n""}]",0,129415,0de67016c7daa1712b568cb2e49728fac3eb57ad,8,3,1,970,,,0,"Remove now-unnecessary client creation hacks

Clients that can use ksc Session don't need the old junk to
fake auth anymore:
* compute
* volume

Clients that still need to be fed credentials can pick directly
from the auth object in clientmanager.  The _token attribute is
removed, the token can be retrieved from the auth object:

  openstackclient/tests/common/test_clientmanager.py

This change will break any plugin that relies on getting a token
from instance._token. They should be updated to use the above, or
preferable, to use keystoneclient.session.Session to create its
HTTP interface object.

Change-Id: I877a29de97a42f85f12a14c274fc003e6fba5135
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/15/129415/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/image/client.py', 'openstackclient/compute/client.py', 'openstackclient/tests/common/test_clientmanager.py', 'openstackclient/common/clientmanager.py', 'openstackclient/network/client.py', 'openstackclient/volume/client.py']",6,0de67016c7daa1712b568cb2e49728fac3eb57ad,client-cleanup," session=instance.session,"," username=instance._username, api_key=instance._password, project_id=instance._project_name, auth_url=instance._auth_url, cacert=instance._cacert, insecure=instance._insecure, region_name=instance._region_name, # Populate the Cinder client to skip another auth query to Identity if instance._url: # token flow client.client.management_url = instance._url else: # password flow client.client.management_url = instance.get_endpoint_for_service_type( API_NAME, region_name=instance._region_name) client.client.service_catalog = instance._service_catalog client.client.auth_token = instance._token ",6,41
openstack%2Ftaskflow~master~I1e6c6568b7f91765d654d25ca6e68e9b568603fc,openstack/taskflow,master,I1e6c6568b7f91765d654d25ca6e68e9b568603fc,Better handle the tree freeze method,MERGED,2014-07-16 19:38:40.000000000,2014-10-18 21:43:06.000000000,2014-10-18 21:43:04.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-07-16 19:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/83911304872973e8dd48553d445522cdb67f1dae', 'message': 'Better handle the tree freeze method\n\nInstead of dynamically replacing the existing method\nwith a new method, just have the existing method check\nif the node has been frozen and immediately abort, this\nworkers better with decorators, subclassing...\n\nAlso add a comment as to why we freeze our children\nbefore freezing ourself.\n\nChange-Id: I1e6c6568b7f91765d654d25ca6e68e9b568603fc\n'}, {'number': 2, 'created': '2014-07-23 08:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/123377041f8f965c5475a57613a7d86f07111f53', 'message': 'Better handle the tree freeze method\n\nInstead of dynamically replacing the existing method\nwith a new method, just have the existing method check\nif the node has been frozen and immediately abort, this\nworkers better with decorators, subclassing...\n\nAlso add a comment as to why we freeze our children\nbefore freezing ourself.\n\nChange-Id: I1e6c6568b7f91765d654d25ca6e68e9b568603fc\n'}, {'number': 3, 'created': '2014-09-18 20:54:06.000000000', 'files': ['taskflow/types/tree.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8bbc2fd05cd6b3c22d9ea96a1e371f1da35db9f5', 'message': 'Better handle the tree freeze method\n\nInstead of dynamically replacing the existing method\nwith a new method, just have the existing method check\nif the node has been frozen and immediately abort, this\nworkers better with decorators, subclassing...\n\nThis also unifies how freezing is done across all types\nthat support it, ensuring that the frozen attribute can\nbe set by users (if they so choose).\n\nChange-Id: I1e6c6568b7f91765d654d25ca6e68e9b568603fc\n'}]",0,107481,8bbc2fd05cd6b3c22d9ea96a1e371f1da35db9f5,16,2,3,1297,,,0,"Better handle the tree freeze method

Instead of dynamically replacing the existing method
with a new method, just have the existing method check
if the node has been frozen and immediately abort, this
workers better with decorators, subclassing...

This also unifies how freezing is done across all types
that support it, ensuring that the frozen attribute can
be set by users (if they so choose).

Change-Id: I1e6c6568b7f91765d654d25ca6e68e9b568603fc
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/81/107481/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/types/tree.py'],1,83911304872973e8dd48553d445522cdb67f1dae,tree," def __init__(self): super(FrozenNode, self).__init__(""Frozen node(s) can't be modified"") # This will DFS until all children are frozen as well, only # after that works do we freeze ourselves (this makes it so # that we don't become frozen if a child node fails to perform # the freeze operation). if self._frozen: raise FrozenNode()"," def _frozen_add(self, child): raise FrozenNode(""Frozen node(s) can't be modified"") self.add = self._frozen_add",8,4
openstack%2Ftaskflow~master~I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd,openstack/taskflow,master,I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd,Hoist the notifier to its own module,MERGED,2014-06-24 22:38:25.000000000,2014-10-18 21:42:58.000000000,2014-10-18 21:42:57.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 6648}]","[{'number': 1, 'created': '2014-06-24 22:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b055bcad992e549af16abfd6796dee538d158a95', 'message': 'Hoist the notifier to its own module\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 2, 'created': '2014-06-24 22:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dd0d602ef0ac3977d78ba8cd05b52935e870af35', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nclass that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 3, 'created': '2014-06-26 02:58:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7df5cbd605e147f8a72e46941582f0c5bf27c597', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nclass that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 4, 'created': '2014-06-26 04:03:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2850a09825c9c81007398ce726ee155d7ab81180', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 5, 'created': '2014-06-26 04:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cfff0c25eb9d34124701d00edcb8ce3b40f4e2c4', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 6, 'created': '2014-06-26 04:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/888ab6f2a917a4dd98b0d655e1cbed89769e6fc5', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 7, 'created': '2014-07-04 18:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0f444f0a3bc81395949209d6447a9f232c1deb4a', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 8, 'created': '2014-08-21 22:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5ad8463b227ab359153766ceb0a8cd95a07eb769', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 9, 'created': '2014-09-03 21:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0287a79a10e4851f3525942759d806b0ec464ea5', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 10, 'created': '2014-09-20 15:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/37340e94e908b58d66704e7a2f05f347e4a5da25', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 11, 'created': '2014-09-20 16:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d0c3431180b6f1086567338ba33cd806ed83e300', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 12, 'created': '2014-09-25 18:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f591978a85b9375dd435b415714d83cf0bb4362b', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 13, 'created': '2014-09-26 18:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ce2bd0406c2ddadb975c970f2e32177106a1cb37', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 14, 'created': '2014-09-27 21:48:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/021853f721a0409d4c87e7ac174350b8992617bc', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 15, 'created': '2014-09-27 22:13:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e29f0c81a01902f52fed1ab17c6d7a37810bc26c', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}, {'number': 16, 'created': '2014-10-18 19:47:27.000000000', 'files': ['taskflow/types/notifier.py', 'taskflow/tests/unit/test_utils.py', 'doc/source/types.rst', 'taskflow/tests/unit/test_notifier.py', 'taskflow/utils/misc.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/bf84288aa0fca3bc5b5582375d145d2966e10c0a', 'message': 'Hoist the notifier to its own module\n\nThe notifier module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd\n'}]",0,102372,bf84288aa0fca3bc5b5582375d145d2966e10c0a,51,3,16,1297,,,0,"Hoist the notifier to its own module

The notifier module needs to be hoisted out of the misc utility
file so that it can be depended on existing by users in a well
defined (non-utility) location.

This change does this hoisting process & creates a new module
and places the existing code there, then creates a deprecated
proxy that exists at the old location (this will be removed
in the next version + 1).

In a future change (in 0.5) we can remove this old location and
remove all references to the previous location (until then we
must keep the old location being used to ensure subclass checks
and other types checks function properly).

Part of blueprint top-level-types

Change-Id: I47fac110adf7cec5c859c2e055c1ceb1f25a7fbd
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/72/102372/16 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/types/notifier.py', 'taskflow/tests/unit/test_utils.py', 'taskflow/tests/unit/test_notifier.py', 'taskflow/utils/misc.py']",4,b055bcad992e549af16abfd6796dee538d158a95,bp/top-level-types,"from taskflow.types import notifierNotifier = deprecation.moved_class(notifier.Notifier, 'Notifier', __name__, version=""0.4"", removal_version=""0.5"") ","import collectionsimport copyclass Notifier(object): """"""A notification helper class. It is intended to be used to subscribe to notifications of events occurring as well as allow a entity to post said notifications to any associated subscribers without having either entity care about how this notification occurs. """""" RESERVED_KEYS = ('details',) ANY = '*' def __init__(self): self._listeners = collections.defaultdict(list) def __len__(self): """"""Returns how many callbacks are registered."""""" count = 0 for (_event_type, callbacks) in six.iteritems(self._listeners): count += len(callbacks) return count def is_registered(self, event_type, callback): """"""Check if a callback is registered."""""" listeners = list(self._listeners.get(event_type, [])) for (cb, _args, _kwargs) in listeners: if reflection.is_same_callback(cb, callback): return True return False def reset(self): """"""Forget all previously registered callbacks."""""" self._listeners.clear() def notify(self, event_type, details): """"""Notify about event occurrence. All callbacks registered to receive notifications about given event type will be called. :param event_type: event type that occurred :param details: addition event details """""" listeners = list(self._listeners.get(self.ANY, [])) for i in self._listeners[event_type]: if i not in listeners: listeners.append(i) if not listeners: return for (callback, args, kwargs) in listeners: if args is None: args = [] if kwargs is None: kwargs = {} kwargs['details'] = details try: callback(event_type, *args, **kwargs) except Exception: LOG.warn(""Failure calling callback %s to notify about event"" "" %s, details: %s"", callback, event_type, details, exc_info=True) def register(self, event_type, callback, args=None, kwargs=None): """"""Register a callback to be called when event of a given type occurs. Callback will be called with provided ``args`` and ``kwargs`` and when event type occurs (or on any event if ``event_type`` equals to ``Notifier.ANY``). It will also get additional keyword argument, ``details``, that will hold event details provided to :py:meth:`notify` method. """""" assert six.callable(callback), ""Callback must be callable"" if self.is_registered(event_type, callback): raise ValueError(""Callback %s already registered"" % (callback)) if kwargs: for k in self.RESERVED_KEYS: if k in kwargs: raise KeyError((""Reserved key '%s' not allowed in "" ""kwargs"") % k) kwargs = copy.copy(kwargs) if args: args = copy.copy(args) self._listeners[event_type].append((callback, args, kwargs)) def deregister(self, event_type, callback): """"""Remove a single callback from listening to event ``event_type``."""""" if event_type not in self._listeners: return for i, (cb, args, kwargs) in enumerate(self._listeners[event_type]): if reflection.is_same_callback(cb, callback): self._listeners[event_type].pop(i) break ",228,181
openstack%2Ftaskflow~master~I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c,openstack/taskflow,master,I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c,Move failure to its own type specific module,MERGED,2014-06-24 02:36:52.000000000,2014-10-18 21:40:56.000000000,2014-10-18 21:40:55.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 6648}, {'_account_id': 7366}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-24 02:36:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6d6074de51aef55df4b2fbe0fe9066440450ea36', 'message': 'Move failure to its own type module (WIP)\n\nThe failure module needs to be hoisted out of the misc\nutility file so that it can be depended on existing by\nusers in a well defined (non-utility) location.\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 2, 'created': '2014-06-24 05:19:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/11bfecdb8c242032022e01898d1f8679a91e13a3', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc\nutility file so that it can be depended on existing by\nusers in a well defined (non-utility) location. To begin\nthis hoisting process create a new module and place the\nexisting code there, then create a deprecated class that\nexists at the old location (this will be removed in the\nnext version + 1).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 3, 'created': '2014-06-24 07:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dc045b0f8763ea96a126c8dbc1efe0f16243457e', 'message': 'Move failure to its own type specific module (WIP)\n\nThe failure module needs to be hoisted out of the misc\nutility file so that it can be depended on existing by\nusers in a well defined (non-utility) location. To begin\nthis hoisting process create a new module and place the\nexisting code there, then create a deprecated class that\nexists at the old location (this will be removed in the\nnext version + 1).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 4, 'created': '2014-06-24 19:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7ae75ac4e3fbc7cef0c0b6f72836734fe852c6a5', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc\nutility file so that it can be depended on existing by\nusers in a well defined (non-utility) location. To begin\nthis hoisting process create a new module and place the\nexisting code there, then create a deprecated class that\nexists at the old location (this will be removed in the\nnext version + 1).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 5, 'created': '2014-06-24 19:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6420a07ddf1e5b040b4c0e082a7bedab27b555ae', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc\nutility file so that it can be depended on existing by\nusers in a well defined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nclass that exists at the old location (this will be removed\nin the next version + 1).\n\nAll the documentation is updated, and all current usage of\n``misc.Failure`` has been moved to use the new module and class\nlocation.\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 6, 'created': '2014-06-24 22:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/034b09a7215dd4a4fbdd05adbb5c4c8802cf8438', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nclass that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 7, 'created': '2014-06-26 01:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/490b3006fecd3291d47a0aa25022dadcf98d0244', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nclass that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 8, 'created': '2014-06-26 02:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dd3be79a72365f4cde65e3cc357e308dfebd947a', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nclass that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 9, 'created': '2014-06-26 04:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/abb96ee3a33448723b23f147c1032c3a83679586', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 10, 'created': '2014-06-26 04:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2f655021a2f8cb09c1b0f03b26d602cad284291a', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 11, 'created': '2014-06-26 04:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c45e275ce6c59a17d2ae6c2e6d7ef7dfc09c0c48', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 12, 'created': '2014-07-04 18:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5e267310d7f0a956b715962c1c557d161e46587a', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 13, 'created': '2014-08-21 22:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/da9ed61005d1da88d71ef53592f60e17905e75ca', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 14, 'created': '2014-09-03 20:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f440daaafe9d097c23dfa2ef6a2fcd7509e2ce86', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 15, 'created': '2014-09-20 15:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2025f23cefb942e64cd01af9859868f8ed038adc', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 16, 'created': '2014-09-20 15:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2a578dcc04dde84bac40a8476020953736139fbd', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 17, 'created': '2014-09-20 16:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6268ad96f757ced56408c1300c8332cbc1608d79', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 18, 'created': '2014-09-25 18:25:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ecd08b1093d26344706d936bdabc4c79bd9df372', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 19, 'created': '2014-09-26 18:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/42fe933a3d88298a15cf05e06c9cd11a1e43e63a', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 20, 'created': '2014-09-27 21:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/33558398f0a173b22edfa7d99f89c7295306d482', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}, {'number': 21, 'created': '2014-10-18 19:47:03.000000000', 'files': ['taskflow/utils/deprecation.py', 'taskflow/types/failure.py', 'taskflow/tests/unit/test_failure.py', 'taskflow/tests/unit/test_utils.py', 'doc/source/types.rst', 'taskflow/tests/unit/test_retries.py', 'taskflow/utils/misc.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f2ea4f128808316708a3854b3a7055e89773c061', 'message': 'Move failure to its own type specific module\n\nThe failure module needs to be hoisted out of the misc utility\nfile so that it can be depended on existing by users in a well\ndefined (non-utility) location.\n\nThis change does this hoisting process & creates a new module\nand places the existing code there, then creates a deprecated\nproxy that exists at the old location (this will be removed\nin the next version + 1).\n\nIn a future change (in 0.5) we can remove this old location and\nremove all references to the previous location (until then we\nmust keep the old location being used to ensure subclass checks\nand other types checks function properly).\n\nPart of blueprint top-level-types\n\nChange-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c\n'}]",3,102091,f2ea4f128808316708a3854b3a7055e89773c061,76,5,21,1297,,,0,"Move failure to its own type specific module

The failure module needs to be hoisted out of the misc utility
file so that it can be depended on existing by users in a well
defined (non-utility) location.

This change does this hoisting process & creates a new module
and places the existing code there, then creates a deprecated
proxy that exists at the old location (this will be removed
in the next version + 1).

In a future change (in 0.5) we can remove this old location and
remove all references to the previous location (until then we
must keep the old location being used to ensure subclass checks
and other types checks function properly).

Part of blueprint top-level-types

Change-Id: I7d13ad1e9e5f5ecc90ab81949cc92ddf7309f13c
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/91/102091/20 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/utils/deprecation.py', 'taskflow/types/failure.py', 'taskflow/utils/misc.py']",3,6d6074de51aef55df4b2fbe0fe9066440450ea36,bp/top-level-types,"from taskflow.types import failure from taskflow.utils import deprecationFailure = deprecation.moved_class(failure.Failure, 'Failure') ","import contextlibimport sysimport traceback def copy_exc_info(exc_info): """"""Make copy of exception info tuple, as deep as possible."""""" if exc_info is None: return None exc_type, exc_value, tb = exc_info # NOTE(imelnikov): there is no need to copy type, and # we can't copy traceback. return (exc_type, copy.deepcopy(exc_value), tb) def are_equal_exc_info_tuples(ei1, ei2): if ei1 == ei2: return True if ei1 is None or ei2 is None: return False # if both are None, we returned True above # NOTE(imelnikov): we can't compare exceptions with '==' # because we want exc_info be equal to it's copy made with # copy_exc_info above. if ei1[0] is not ei2[0]: return False if not all((type(ei1[1]) == type(ei2[1]), exc.exception_message(ei1[1]) == exc.exception_message(ei2[1]), repr(ei1[1]) == repr(ei2[1]))): return False if ei1[2] == ei2[2]: return True tb1 = traceback.format_tb(ei1[2]) tb2 = traceback.format_tb(ei2[2]) return tb1 == tb2 @contextlib.contextmanager def capture_failure(): """"""Captures the occuring exception and provides a failure back. This will save the current exception information and yield back a failure object for the caller to use (it will raise a runtime error if no active exception is being handled). This is useful since in some cases the exception context can be cleared, resulting in None being attempted to be saved after an exception handler is run. This can happen when eventlet switches greenthreads or when running an exception handler, code raises and catches an exception. In both cases the exception context will be cleared. To work around this, we save the exception state, yield a failure and then run other code. For example:: except Exception: with capture_failure() as fail: LOG.warn(""Activating cleanup"") cleanup() save_failure(fail) """""" exc_info = sys.exc_info() if not any(exc_info): raise RuntimeError(""No active exception is being handled"") else: yield Failure(exc_info=exc_info) class Failure(object): """"""Object that represents failure. Failure objects encapsulate exception information so that it can be re-used later to re-raise or inspect. """""" DICT_VERSION = 1 def __init__(self, exc_info=None, **kwargs): if not kwargs: if exc_info is None: exc_info = sys.exc_info() self._exc_info = exc_info self._exc_type_names = list( reflection.get_all_class_names(exc_info[0], up_to=Exception)) if not self._exc_type_names: raise TypeError('Invalid exception type: %r' % exc_info[0]) self._exception_str = exc.exception_message(self._exc_info[1]) self._traceback_str = ''.join( traceback.format_tb(self._exc_info[2])) else: self._exc_info = exc_info # may be None self._exception_str = kwargs.pop('exception_str') self._exc_type_names = kwargs.pop('exc_type_names', []) self._traceback_str = kwargs.pop('traceback_str', None) if kwargs: raise TypeError( 'Failure.__init__ got unexpected keyword argument(s): %s' % ', '.join(six.iterkeys(kwargs))) @classmethod def from_exception(cls, exception): return cls((type(exception), exception, None)) def _matches(self, other): if self is other: return True return (self._exc_type_names == other._exc_type_names and self.exception_str == other.exception_str and self.traceback_str == other.traceback_str) def matches(self, other): if not isinstance(other, Failure): return False if self.exc_info is None or other.exc_info is None: return self._matches(other) else: return self == other def __eq__(self, other): if not isinstance(other, Failure): return NotImplemented return (self._matches(other) and are_equal_exc_info_tuples(self.exc_info, other.exc_info)) def __ne__(self, other): return not (self == other) # NOTE(imelnikov): obj.__hash__() should return same values for equal # objects, so we should redefine __hash__. Failure equality semantics # is a bit complicated, so for now we just mark Failure objects as # unhashable. See python docs on object.__hash__ for more info: # http://docs.python.org/2/reference/datamodel.html#object.__hash__ __hash__ = None @property def exception(self): """"""Exception value, or None if exception value is not present. Exception value may be lost during serialization. """""" if self._exc_info: return self._exc_info[1] else: return None @property def exception_str(self): """"""String representation of exception."""""" return self._exception_str @property def exc_info(self): """"""Exception info tuple or None."""""" return self._exc_info @property def traceback_str(self): """"""Exception traceback as string."""""" return self._traceback_str @staticmethod def reraise_if_any(failures): """"""Re-raise exceptions if argument is not empty. If argument is empty list, this method returns None. If argument is list with single Failure object in it, this failure is reraised. Else, WrappedFailure exception is raised with failures list as causes. """""" failures = list(failures) if len(failures) == 1: failures[0].reraise() elif len(failures) > 1: raise exc.WrappedFailure(failures) def reraise(self): """"""Re-raise captured exception."""""" if self._exc_info: six.reraise(*self._exc_info) else: raise exc.WrappedFailure([self]) def check(self, *exc_classes): """"""Check if any of exc_classes caused the failure. Arguments of this method can be exception types or type names (stings). If captured exception is instance of exception of given type, the corresponding argument is returned. Else, None is returned. """""" for cls in exc_classes: if isinstance(cls, type): err = reflection.get_class_name(cls) else: err = cls if err in self._exc_type_names: return cls return None def __str__(self): return 'Failure: %s: %s' % (self._exc_type_names[0], self._exception_str) def __iter__(self): """"""Iterate over exception type names."""""" for et in self._exc_type_names: yield et @classmethod def from_dict(cls, data): data = dict(data) version = data.pop('version', None) if version != cls.DICT_VERSION: raise ValueError('Invalid dict version of failure object: %r' % version) return cls(**data) def to_dict(self): return { 'exception_str': self.exception_str, 'traceback_str': self.traceback_str, 'exc_type_names': list(self), 'version': self.DICT_VERSION, } def copy(self): return Failure(exc_info=copy_exc_info(self.exc_info), exception_str=self.exception_str, traceback_str=self.traceback_str, exc_type_names=self._exc_type_names[:])",327,230
openstack%2Fdjango_openstack_auth~master~I4136b866700a74aa93e38363fdcb29fe6c5ed65c,openstack/django_openstack_auth,master,I4136b866700a74aa93e38363fdcb29fe6c5ed65c,extract mock setup methods,MERGED,2014-10-02 15:26:00.000000000,2014-10-18 20:35:32.000000000,2014-10-18 20:35:31.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1816}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 4264}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 5733}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 8648}, {'_account_id': 9098}, {'_account_id': 9317}, {'_account_id': 11022}]","[{'number': 1, 'created': '2014-10-02 15:26:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/80043fa6c588d01cf07c93f27f2db197cf4ce412', 'message': 'extract mock setup methods\n\nPulls the common code for Version specific tests into a mixing\nclass, reducing code duplication significantly.\n\nChange-Id: I4136b866700a74aa93e38363fdcb29fe6c5ed65c\n'}, {'number': 2, 'created': '2014-10-04 01:15:05.000000000', 'files': ['openstack_auth/tests/tests.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/6cc5d50deca432ec9c7a132e1526e090e6567062', 'message': 'extract mock setup methods\n\nPulls the common code for Version specific tests into a mixing\nclass, reducing code duplication significantly.\n\nChange-Id: I4136b866700a74aa93e38363fdcb29fe6c5ed65c\n'}]",4,125673,6cc5d50deca432ec9c7a132e1526e090e6567062,11,15,2,2218,,,0,"extract mock setup methods

Pulls the common code for Version specific tests into a mixing
class, reducing code duplication significantly.

Change-Id: I4136b866700a74aa93e38363fdcb29fe6c5ed65c
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/73/125673/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_auth/tests/tests.py'],1,80043fa6c588d01cf07c93f27f2db197cf4ce412,auth-plugins,"class OpenStackAuthTestsMixin(object): '''Common functions for version specific tests.''' def tearDown(self): self.mox.UnsetStubs() self.mox.VerifyAll() def _mock_unscoped_client(self, user): self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) def _mock_unscoped_client_with_token(self, user, unscoped): self.mox.StubOutWithMock(self.ks_client_module, ""Client"") url = settings.OPENSTACK_KEYSTONE_URL self.ks_client_module.Client(user_id=user.id, auth_url=url, token=unscoped.auth_token, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) def _mock_client_token_auth_failure(self, unscoped, tenant_id): exc = keystone_exceptions.AuthorizationFailure self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=tenant_id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndRaise(exc) def _mock_client_password_auth_failure(self, username, password, exc): self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=password, username=username, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False).AndRaise(exc) def _mock_scoped_client_for_tenant(self, auth_ref, tenant_id, url=None): if url is None: auth_url = settings.OPENSTACK_KEYSTONE_URL else: auth_url = url self.ks_client_module.Client(auth_url=auth_url, tenant_id=tenant_id, insecure=False, cacert=None, token=auth_ref.auth_token, debug=False) \ .AndReturn(self.keystone_client_scoped) def get_form_data(self, user): return {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'password': user.password, 'username': user.name} class OpenStackAuthTestsV2(OpenStackAuthTestsMixin, test.TestCase): def _mock_unscoped_list_tenants(self, tenants): self.mox.StubOutWithMock(self.keystone_client_unscoped.tenants, ""list"") self.keystone_client_unscoped.tenants.list().AndReturn(tenants) def _mock_unscoped_client_list_tenants(self, user, tenants): self._mock_unscoped_client(user) self._mock_unscoped_list_tenants(tenants) form_data = self.get_form_data(user) self._mock_unscoped_client_list_tenants(user, tenants) self._mock_scoped_client_for_tenant(unscoped, self.data.tenant_two.id) form_data = self.get_form_data(user) self._mock_unscoped_client_list_tenants(user, tenants) self._mock_client_token_auth_failure(unscoped, self.data.tenant_two.id) self._mock_scoped_client_for_tenant(unscoped, self.data.tenant_one.id) form_data = self.get_form_data(user) self._mock_unscoped_client_list_tenants(user, tenants) self._mock_client_token_auth_failure(unscoped, self.data.tenant_two.id) self._mock_client_token_auth_failure(unscoped, self.data.tenant_one.id) form_data = self.get_form_data(user) self._mock_unscoped_client_list_tenants(user, []) form_data = self.get_form_data(user) form_data['password'] = ""invalid"" self._mock_client_password_auth_failure(user.name, ""invalid"", exc) form_data = self.get_form_data(user) self._mock_client_password_auth_failure(user.name, user.password, exc) form_data = self.get_form_data(user) self._mock_unscoped_client_list_tenants(user, tenants) self._mock_scoped_client_for_tenant(unscoped, self.data.tenant_two.id) self._mock_scoped_client_for_tenant(scoped, tenant.id, url=sc.url_for(endpoint_type=et)) form_data = self.get_form_data(user) self._mock_unscoped_client_list_tenants(user, tenants) self._mock_scoped_client_for_tenant(unscoped, self.data.tenant_two.id) self._mock_unscoped_client_with_token(user, unscoped) self._mock_unscoped_list_tenants(tenants) self._mock_unscoped_list_tenants(tenants) self._mock_unscoped_client_with_token(user, unscoped)class OpenStackAuthTestsV3(OpenStackAuthTestsMixin, test.TestCase): def _mock_unscoped_client_list_projects(self, user, projects): self._mock_unscoped_client(user) self._mock_unscoped_list_projects(user, projects) def _mock_unscoped_list_projects(self, user, projects): self.mox.StubOutWithMock(self.keystone_client_unscoped.projects, ""list"") self.keystone_client_unscoped.projects.list(user=user.id) \ .AndReturn(projects) form_data = self.get_form_data(user) self._mock_unscoped_client_list_projects(user, projects) self._mock_scoped_client_for_tenant(unscoped, self.data.project_two.id) form_data = self.get_form_data(user) self._mock_unscoped_client_list_projects(user, projects) self._mock_client_token_auth_failure(unscoped, self.data.project_two.id) self._mock_scoped_client_for_tenant(unscoped, self.data.project_one.id) form_data = self.get_form_data(user) self._mock_unscoped_client_list_projects(user, projects) self._mock_client_token_auth_failure(unscoped, self.data.project_two.id) self._mock_client_token_auth_failure(unscoped, self.data.project_one.id) form_data = self.get_form_data(user) self._mock_unscoped_client_list_projects(user, []) form_data = self.get_form_data(user) form_data['password'] = ""invalid"" self._mock_client_password_auth_failure(user.name, ""invalid"", exc) form_data = self.get_form_data(user) self._mock_client_password_auth_failure(user.name, user.password, exc) form_data = self.get_form_data(user) self._mock_unscoped_client_list_projects(user, projects) self._mock_scoped_client_for_tenant(unscoped, self.data.project_two.id) self._mock_scoped_client_for_tenant( unscoped, project.id, url=sc.url_for(endpoint_type=et)) form_data = self.get_form_data(user) self._mock_unscoped_client_list_projects(user, projects) self._mock_scoped_client_for_tenant(unscoped, self.data.project_two.id) self._mock_unscoped_client_with_token(user, unscoped) self._mock_unscoped_list_projects(user, projects) self._mock_unscoped_client_with_token(user, unscoped) self._mock_unscoped_list_projects(user, projects)","class OpenStackAuthTestsV2(test.TestCase): def tearDown(self): self.mox.UnsetStubs() self.mox.VerifyAll() form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'password': user.password, 'username': user.name} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.tenants, ""list"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.tenants.list().AndReturn(tenants) self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.tenant_two.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndReturn(self.keystone_client_scoped) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'password': user.password, 'username': user.name} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.tenants, ""list"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.tenants.list().AndReturn(tenants) exc = keystone_exceptions.AuthorizationFailure self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.tenant_two.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndRaise(exc) self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.tenant_one.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndReturn(self.keystone_client_scoped) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'password': user.password, 'username': user.name} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.tenants, ""list"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.tenants.list().AndReturn(tenants) exc = keystone_exceptions.AuthorizationFailure self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.tenant_two.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndRaise(exc) self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.tenant_one.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndRaise(exc) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'password': user.password, 'username': user.name} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.tenants, ""list"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.tenants.list().AndReturn([]) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'password': ""invalid"", 'username': user.name} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=""invalid"", username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False).AndRaise(exc) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'password': user.password, 'username': user.name} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False).AndRaise(exc) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'username': user.name, 'password': user.password} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.tenants, ""list"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False) \ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.tenants.list().AndReturn(tenants) self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.tenant_two.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndReturn(self.keystone_client_scoped) self.ks_client_module.Client(auth_url=sc.url_for(endpoint_type=et), tenant_id=tenant.id, token=scoped.auth_token, insecure=False, cacert=None, debug=False) \ .AndReturn(self.keystone_client_scoped) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'username': user.name, 'password': user.password} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.tenants, ""list"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False) \ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.tenants.list().AndReturn(tenants) self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.tenant_two.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndReturn(self.keystone_client_scoped) self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.tenants, ""list"") self.ks_client_module.Client(user_id=user.id, auth_url=settings.OPENSTACK_KEYSTONE_URL, token=unscoped.auth_token, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.tenants.list().AndReturn(tenants) self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.tenants, ""list"") self.ks_client_module.Client(user_id=user.id, auth_url=settings.OPENSTACK_KEYSTONE_URL, token=unscoped.auth_token, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.tenants.list().AndReturn(tenants) class OpenStackAuthTestsV3(test.TestCase): def tearDown(self): self.mox.UnsetStubs() self.mox.VerifyAll() form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'password': user.password, 'username': user.name} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.projects, ""list"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.projects.list(user=user.id) \ .AndReturn(projects) self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.project_two.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndReturn(self.keystone_client_scoped) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'password': user.password, 'username': user.name} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.projects, ""list"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.projects.list(user=user.id) \ .AndReturn(projects) exc = keystone_exceptions.AuthorizationFailure self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.project_two.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndRaise(exc) self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.project_one.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndReturn(self.keystone_client_scoped) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'password': user.password, 'username': user.name} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.projects, ""list"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.projects.list(user=user.id) \ .AndReturn(projects) exc = keystone_exceptions.AuthorizationFailure self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.project_two.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndRaise(exc) self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.project_one.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndRaise(exc) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'password': user.password, 'username': user.name} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.projects, ""list"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.projects.list(user=user.id) \ .AndReturn([]) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'password': ""invalid"", 'username': user.name} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=""invalid"", username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False).AndRaise(exc) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'password': user.password, 'username': user.name} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False).AndRaise(exc) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'username': user.name, 'password': user.password} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.projects, ""list"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False) \ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.projects.list(user=user.id) \ .AndReturn(projects) self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.project_two.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndReturn(self.keystone_client_scoped) self.ks_client_module.Client(auth_url=sc.url_for(endpoint_type=et), tenant_id=project.id, token=scoped.auth_token, insecure=False, cacert=None, debug=False) \ .AndReturn(self.keystone_client_scoped) form_data = {'region': settings.OPENSTACK_KEYSTONE_URL, 'domain': DEFAULT_DOMAIN, 'username': user.name, 'password': user.password} self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.projects, ""list"") self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, password=user.password, username=user.name, user_domain_name=DEFAULT_DOMAIN, insecure=False, cacert=None, debug=False) \ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.projects.list(user=user.id) \ .AndReturn(projects) self.ks_client_module.Client(auth_url=settings.OPENSTACK_KEYSTONE_URL, tenant_id=self.data.project_two.id, insecure=False, cacert=None, token=unscoped.auth_token, debug=False) \ .AndReturn(self.keystone_client_scoped) self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.projects, ""list"") self.ks_client_module.Client(user_id=user.id, auth_url=settings.OPENSTACK_KEYSTONE_URL, token=unscoped.auth_token, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.projects.list(user=user.id) \ .AndReturn(projects) self.mox.StubOutWithMock(self.ks_client_module, ""Client"") self.mox.StubOutWithMock(self.keystone_client_unscoped.projects, ""list"") self.ks_client_module.Client(user_id=user.id, auth_url=settings.OPENSTACK_KEYSTONE_URL, token=unscoped.auth_token, insecure=False, cacert=None, debug=False)\ .AndReturn(self.keystone_client_unscoped) self.keystone_client_unscoped.projects.list(user=user.id) \ .AndReturn(projects)",154,450
openstack%2Ftaskflow~master~I960340ead7b82b4620c6ac9ed0d3ae2470c3253c,openstack/taskflow,master,I960340ead7b82b4620c6ac9ed0d3ae2470c3253c,Remove leftover traces of oslo-incubator,ABANDONED,2014-09-30 20:10:39.000000000,2014-10-18 20:34:40.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-09-30 20:10:39.000000000', 'files': ['taskflow/utils/persistence_utils.py', 'taskflow/openstack/common/uuidutils.py', 'taskflow/tests/unit/persistence/base.py', 'taskflow/persistence/logbook.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/examples/fake_billing.py', 'taskflow/tests/unit/worker_based/test_protocol.py', 'taskflow/tests/unit/worker_based/test_pipeline.py', 'taskflow/openstack/__init__.py', 'taskflow/jobs/backends/impl_zookeeper.py', 'taskflow/jobs/job.py', 'taskflow/tests/unit/jobs/base.py', 'taskflow/tests/unit/persistence/test_zk_persistence.py', 'taskflow/tests/unit/worker_based/test_message_pump.py', 'taskflow/openstack/common/__init__.py', 'taskflow/storage.py', 'taskflow/examples/resume_vm_boot.py', 'taskflow/persistence/backends/sqlalchemy/models.py', 'openstack-common.conf', 'taskflow/tests/unit/jobs/test_zk_job.py', 'taskflow/utils/misc.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7255aff7ad02704a8efea6ccb709ddd145f804d2', 'message': 'Remove leftover traces of oslo-incubator\n\nWe no longer need to have oslo-incubator syncs just\nfor a simple uuidutils functionality that can easily\nbe placed as a single (or two) line in our own utility\nfile.\n\nChange-Id: I960340ead7b82b4620c6ac9ed0d3ae2470c3253c\n'}]",0,125180,7255aff7ad02704a8efea6ccb709ddd145f804d2,4,1,1,1297,,,0,"Remove leftover traces of oslo-incubator

We no longer need to have oslo-incubator syncs just
for a simple uuidutils functionality that can easily
be placed as a single (or two) line in our own utility
file.

Change-Id: I960340ead7b82b4620c6ac9ed0d3ae2470c3253c
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/80/125180/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/utils/persistence_utils.py', 'taskflow/openstack/common/uuidutils.py', 'taskflow/tests/unit/persistence/base.py', 'taskflow/persistence/logbook.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/examples/fake_billing.py', 'taskflow/tests/unit/worker_based/test_protocol.py', 'taskflow/tests/unit/worker_based/test_pipeline.py', 'taskflow/openstack/__init__.py', 'taskflow/jobs/backends/impl_zookeeper.py', 'taskflow/jobs/job.py', 'taskflow/tests/unit/jobs/base.py', 'taskflow/tests/unit/persistence/test_zk_persistence.py', 'taskflow/tests/unit/worker_based/test_message_pump.py', 'taskflow/openstack/common/__init__.py', 'taskflow/storage.py', 'taskflow/examples/resume_vm_boot.py', 'taskflow/persistence/backends/sqlalchemy/models.py', 'openstack-common.conf', 'taskflow/tests/unit/jobs/test_zk_job.py', 'taskflow/utils/misc.py']",21,7255aff7ad02704a8efea6ccb709ddd145f804d2,,"import uuiddef generate_uuid(): """"""Generate a random uuid helper."""""" return str(uuid.uuid4()) ",,65,136
openstack%2Ftaskflow~master~I43f2efdb48248c90f6c9f8c12b6651f81da45c9d,openstack/taskflow,master,I43f2efdb48248c90f6c9f8c12b6651f81da45c9d,Use the engine entrypoint function instead of direct class,ABANDONED,2014-09-16 01:22:32.000000000,2014-10-18 20:31:17.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-09-16 01:22:32.000000000', 'files': ['taskflow/examples/run_by_iter.py', 'taskflow/examples/run_by_iter_enumerate.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7fd9a595445f9e101d52d68ac4fe08b3ce956260', 'message': 'Use the engine entrypoint function instead of direct class\n\nInstead of advocating the direct creation of engine classes,\nwhich makes it hard to move those types around (or rename them)\njust have the examples use the engine loading functions instead\nto ensure we recommend good practices in our examples.\n\nChange-Id: I43f2efdb48248c90f6c9f8c12b6651f81da45c9d\n'}]",0,121725,7fd9a595445f9e101d52d68ac4fe08b3ce956260,6,2,1,1297,,,0,"Use the engine entrypoint function instead of direct class

Instead of advocating the direct creation of engine classes,
which makes it hard to move those types around (or rename them)
just have the examples use the engine loading functions instead
to ensure we recommend good practices in our examples.

Change-Id: I43f2efdb48248c90f6c9f8c12b6651f81da45c9d
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/25/121725/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/examples/run_by_iter.py', 'taskflow/examples/run_by_iter_enumerate.py']",2,7fd9a595445f9e101d52d68ac4fe08b3ce956260,,"from taskflow import enginese = engines.load(f, flow_detail=fd, backend=be)","from taskflow.engines.action_engine import enginee = engine.SingleThreadedActionEngine(f, fd, be, {})",5,8
openstack%2Ftaskflow~master~I077334820d36c64e272e93d158e3a0cd0d66a937,openstack/taskflow,master,I077334820d36c64e272e93d158e3a0cd0d66a937,Have the dispatch_job function return a future,MERGED,2014-07-01 03:34:46.000000000,2014-10-18 20:23:18.000000000,2014-10-18 20:23:17.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 9608}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-07-01 03:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a8de9b9edb61f7eda8c4d9a9362730364d8212f9', 'message': 'Have the dispatch_job function return a future\n\nTo make it easier to add in a multi-threaded conductor\nconvert the base dispatch_job function to return a future\nobject. This future object will contain a single result,\nwhether the job should be consumed or abandoned. In the\nsingle threaded conductor its dispatch_job function will\nreturn a future, after completing the job (in a multi\nthreaded conductor it would not return a future after\ndoing the work).\n\nChange-Id: I077334820d36c64e272e93d158e3a0cd0d66a937\n'}, {'number': 2, 'created': '2014-07-15 00:32:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d635f5304522abd1d8357027fe40242db84ea509', 'message': 'Have the dispatch_job function return a future\n\nTo make it easier to add in a multi-threaded conductor\nconvert the base dispatch_job function to return a future\nobject. This future object will contain a single result,\nwhether the job should be consumed or abandoned. In the\nsingle threaded conductor its dispatch_job function will\nreturn a future, after completing the job (in a multi\nthreaded conductor it would not return a future after\ndoing the work).\n\nChange-Id: I077334820d36c64e272e93d158e3a0cd0d66a937\n'}, {'number': 3, 'created': '2014-08-21 22:14:51.000000000', 'files': ['taskflow/conductors/single_threaded.py', 'taskflow/conductors/base.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/296e660cd3036db46a58ed3b16c907c769454f05', 'message': 'Have the dispatch_job function return a future\n\nTo make it easier to add in a multi-threaded conductor\nconvert the base dispatch_job function to return a future\nobject. This future object will contain a single result,\nwhether the job should be consumed or abandoned. In the\nsingle threaded conductor its dispatch_job function will\nreturn a future, after completing the job (in a multi\nthreaded conductor it would not return a future after\ndoing the work).\n\nChange-Id: I077334820d36c64e272e93d158e3a0cd0d66a937\n'}]",0,103712,296e660cd3036db46a58ed3b16c907c769454f05,21,4,3,1297,,,0,"Have the dispatch_job function return a future

To make it easier to add in a multi-threaded conductor
convert the base dispatch_job function to return a future
object. This future object will contain a single result,
whether the job should be consumed or abandoned. In the
single threaded conductor its dispatch_job function will
return a future, after completing the job (in a multi
threaded conductor it would not return a future after
doing the work).

Change-Id: I077334820d36c64e272e93d158e3a0cd0d66a937
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/12/103712/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/conductors/single_threaded.py', 'taskflow/conductors/base.py']",2,a8de9b9edb61f7eda8c4d9a9362730364d8212f9,, an engine. Returns a future object that represented the work to be completed sometime in the future. The future should return a single boolean from its result() method. This boolean determines whether the job will be consumed (true) or whether it should be abandoned (false)., an engine. Returns a boolean that signifies whether the job should be consumed. The job is consumed upon completion (unless False is returned which will signify the job should be abandoned instead).,8,5
openstack%2Ftaskflow~master~Id2dc3f8dc9ac94e511470e39f499f325b33537ee,openstack/taskflow,master,Id2dc3f8dc9ac94e511470e39f499f325b33537ee,Add a timing listener that also prints the results,MERGED,2014-07-08 21:54:02.000000000,2014-10-18 20:23:11.000000000,2014-10-18 20:23:10.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8136}, {'_account_id': 9608}]","[{'number': 1, 'created': '2014-07-08 21:54:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e791654a3817949c7f840c8b37991a4aa48fa03e', 'message': 'Add a timing listener that also prints the results\n\nInstead of just recording them it can also be quite\nuseful (especially for debugging) to print the start\nand stop timings as they occur.\n\nChange-Id: Id2dc3f8dc9ac94e511470e39f499f325b33537ee\n'}, {'number': 2, 'created': '2014-09-18 06:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c57deb940f3b64c8c9e5b528f5f103a3e0c83b5d', 'message': 'Add a timing listener that also prints the results\n\nInstead of just recording them it can also be quite\nuseful (especially for debugging) to print the start\nand stop timings as they occur.\n\nChange-Id: Id2dc3f8dc9ac94e511470e39f499f325b33537ee\n'}, {'number': 3, 'created': '2014-09-18 18:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/62a1a566378b8d2f2ab0f6781ca212617c7d0bc1', 'message': 'Add a timing listener that also prints the results\n\nInstead of just recording them it can also be quite\nuseful (especially for debugging) to print the start\nand stop timings as they occur.\n\nAlso adds an example that shows how this can be used\nand an explanation of why it is useful to have this type\nof capability.\n\nChange-Id: Id2dc3f8dc9ac94e511470e39f499f325b33537ee\n'}, {'number': 4, 'created': '2014-09-18 18:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/61edb76e6530c571ce08f9eed05f4f4a633e04d8', 'message': 'Add a timing listener that also prints the results\n\nInstead of just recording them it can also be quite\nuseful (especially for debugging) to print the start\nand stop timings as they occur.\n\nAlso adds an example that shows how this can be used\nand an explanation of why it is useful to have this type\nof capability.\n\nChange-Id: Id2dc3f8dc9ac94e511470e39f499f325b33537ee\n'}, {'number': 5, 'created': '2014-09-18 18:22:26.000000000', 'files': ['taskflow/examples/timing_listener.py', 'doc/source/examples.rst', 'taskflow/listeners/timing.py', 'doc/source/notifications.rst'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6bbf85b5a50437a65a8ce2acba9eb73c5003ff78', 'message': 'Add a timing listener that also prints the results\n\nInstead of just recording them it can also be quite\nuseful (especially for debugging) to print the start\nand stop timings as they occur.\n\nAlso adds an example that shows how this can be used\nand an explanation of why it is useful to have this type\nof capability.\n\nPart of blueprint more-examples\n\nChange-Id: Id2dc3f8dc9ac94e511470e39f499f325b33537ee\n'}]",0,105604,6bbf85b5a50437a65a8ce2acba9eb73c5003ff78,16,4,5,1297,,,0,"Add a timing listener that also prints the results

Instead of just recording them it can also be quite
useful (especially for debugging) to print the start
and stop timings as they occur.

Also adds an example that shows how this can be used
and an explanation of why it is useful to have this type
of capability.

Part of blueprint more-examples

Change-Id: Id2dc3f8dc9ac94e511470e39f499f325b33537ee
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/04/105604/5 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/listeners/timing.py'],1,e791654a3817949c7f840c8b37991a4aa48fa03e,bp/more-examples," 'duration': timer.elapsed(), timer = self._timers.pop(task_name) timer.stop() self._record_ending(timer, task_name) class PrintingTimingListener(TimingListener): """"""Listener that prints the start and stop instead of just recording it."""""" def _record_ending(self, timer, task_name): super(PrintingTimingListener, self)._record_ending(timer, task_name) print(""It took %s %0.2f (seconds) to finish."" % (task_name, timer.elapsed())) def _task_receiver(self, state, details): super(PrintingTimingListener, self)._task_receiver(state, details) if state in STARTING_STATES: print(""%s task started."" % (details['task_name']))"," 'duration': float(timer.elapsed()), self._record_ending(self._timers[task_name], task_name)",18,2
openstack%2Ftaskflow~master~I3a0f1f0dd777a1633b4937e16b50030275c84d1d,openstack/taskflow,master,I3a0f1f0dd777a1633b4937e16b50030275c84d1d,Expose only `ensure_atom` from storage,MERGED,2014-06-29 04:54:02.000000000,2014-10-18 20:16:41.000000000,2014-10-18 20:16:40.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 9608}]","[{'number': 1, 'created': '2014-06-29 04:54:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/375d7fbe8a047a15890a833a1514dc8da2fb059c', 'message': 'Expose only `ensure_atom` from storage\n\nMove the storage ensuring logic from being split\nacross the engine and the storage layer and expose\nonly a single `ensure_atom` function that does\nthe work instead.\n\nThis also removes the access to the `ensure_task`\nand `ensure_retry` methods as the internals of the\n`ensure_atom` function is now the only location\nthat needs to use these two functions.\n\nThis reduces the need to do type specific atom\nchecks in the non-storage components (which we\nwant to reduce overall).\n\nChange-Id: I3a0f1f0dd777a1633b4937e16b50030275c84d1d\n'}, {'number': 2, 'created': '2014-06-29 05:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fa02c7f96c9a013d785ec87d692c53be29229398', 'message': 'Expose only `ensure_atom` from storage\n\nMove the storage ensuring logic from being split\nacross the engine and the storage layer and expose\nonly a single `ensure_atom` function that does\nthe work instead.\n\nThis also removes the access to the `ensure_task`\nand `ensure_retry` methods as the internals of the\n`ensure_atom` function is now the only location\nthat needs to use these two functions.\n\nThis reduces the need to do type specific atom\nchecks in the non-storage components (which we\nwant to reduce overall).\n\nChange-Id: I3a0f1f0dd777a1633b4937e16b50030275c84d1d\n'}, {'number': 3, 'created': '2014-06-29 19:10:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b3837693ad2552be13c5a6741f7bcca2f5ceee6a', 'message': 'Expose only `ensure_atom` from storage\n\nMove the storage ensuring logic from being split\nacross the engine and the storage layer and expose\nonly a single `ensure_atom` function that does\nthe work instead.\n\nThis also removes the access to the `ensure_task`\nand `ensure_retry` methods as the internals of the\n`ensure_atom` function is now the only location\nthat needs to use these two functions.\n\nThis reduces the need to do type specific atom\nchecks in the non-storage components (which we\nwant to reduce overall).\n\nBreaking change: removes the public methods named\n`ensure_task` and `ensure_retry` (which should not\nbe used externally anyway) from the storage object\nand makes those internal/private methods instead.\n\nChange-Id: I3a0f1f0dd777a1633b4937e16b50030275c84d1d\n'}, {'number': 4, 'created': '2014-08-15 21:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5be2071a42ee747b58c961042b4d09b2597d715f', 'message': 'Expose only `ensure_atom` from storage\n\nMove the storage ensuring logic from being split\nacross the engine and the storage layer and expose\nonly a single `ensure_atom` function that does\nthe work instead.\n\nThis also removes the access to the `ensure_task`\nand `ensure_retry` methods as the internals of the\n`ensure_atom` function is now the only location\nthat needs to use these two functions.\n\nThis reduces the need to do type specific atom\nchecks in the non-storage components (which we\nwant to reduce overall).\n\nBreaking change: removes the public methods named\n`ensure_task` and `ensure_retry` (which should not\nbe used externally anyway) from the storage object\nand makes those internal/private methods instead.\n\nChange-Id: I3a0f1f0dd777a1633b4937e16b50030275c84d1d\n'}, {'number': 5, 'created': '2014-09-26 18:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c0e4f1e5ff0c38cc16c6548cd692a25121f59bd8', 'message': 'Expose only `ensure_atom` from storage\n\nMove the storage ensuring logic from being split\nacross the engine and the storage layer and expose\nonly a single `ensure_atom` function that does\nthe work instead.\n\nThis also removes the access to the `ensure_task`\nand `ensure_retry` methods as the internals of the\n`ensure_atom` function is now the only location\nthat needs to use these two functions.\n\nThis reduces the need to do type specific atom\nchecks in the non-storage components (which we\nwant to reduce overall).\n\nBreaking change: removes the public methods named\n`ensure_task` and `ensure_retry` (which should not\nbe used externally anyway) from the storage object\nand makes those internal/private methods instead.\n\nChange-Id: I3a0f1f0dd777a1633b4937e16b50030275c84d1d\n'}, {'number': 6, 'created': '2014-09-27 01:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a04be28b69e8c450536b01184c0f37e947d991b8', 'message': 'Expose only `ensure_atom` from storage\n\nMove the storage ensuring logic from being split\nacross the engine and the storage layer and expose\nonly a single `ensure_atom` function that does\nthe work instead.\n\nThis also removes the access to the `ensure_task`\nand `ensure_retry` methods as the internals of the\n`ensure_atom` function is now the only location\nthat needs to use these two functions.\n\nThis reduces the need to do type specific atom\nchecks in the non-storage components (which we\nwant to reduce overall).\n\nBreaking change: removes the public methods named\n`ensure_task` and `ensure_retry` (which should not\nbe used externally anyway) from the storage object\nand makes those internal/private methods instead.\n\nChange-Id: I3a0f1f0dd777a1633b4937e16b50030275c84d1d\n'}, {'number': 7, 'created': '2014-09-28 04:05:10.000000000', 'files': ['taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/tests/utils.py', 'taskflow/tests/unit/action_engine/test_runner.py', 'taskflow/tests/unit/worker_based/test_worker.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/eedc3353c8c362ba6df62182e20a8bb4f6ad6afe', 'message': 'Expose only `ensure_atom` from storage\n\nMove the storage ensuring logic from being split\nacross the engine and the storage layer and expose\nonly a single `ensure_atom` function that does\nthe work instead.\n\nThis also removes the access to the `ensure_task`\nand `ensure_retry` methods as the internals of the\n`ensure_atom` function is now the only location\nthat needs to use these two functions.\n\nThis reduces the need to do type specific atom\nchecks in the non-storage components (which we\nwant to reduce overall).\n\nBreaking change: removes the public methods named\n`ensure_task` and `ensure_retry` (which should not\nbe used externally anyway) from the storage object\nand makes those internal/private methods instead.\n\nChange-Id: I3a0f1f0dd777a1633b4937e16b50030275c84d1d\n'}]",4,103378,eedc3353c8c362ba6df62182e20a8bb4f6ad6afe,43,3,7,1297,,,0,"Expose only `ensure_atom` from storage

Move the storage ensuring logic from being split
across the engine and the storage layer and expose
only a single `ensure_atom` function that does
the work instead.

This also removes the access to the `ensure_task`
and `ensure_retry` methods as the internals of the
`ensure_atom` function is now the only location
that needs to use these two functions.

This reduces the need to do type specific atom
checks in the non-storage components (which we
want to reduce overall).

Breaking change: removes the public methods named
`ensure_task` and `ensure_retry` (which should not
be used externally anyway) from the storage object
and makes those internal/private methods instead.

Change-Id: I3a0f1f0dd777a1633b4937e16b50030275c84d1d
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/78/103378/5 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/tests/utils.py', 'taskflow/tests/unit/worker_based/test_worker.py']",5,375d7fbe8a047a15890a833a1514dc8da2fb059c,storage-type-checks, self.endpoint_count = 22, self.endpoint_count = 21,79,81
openstack%2Ftaskflow~master~I5fc21370d91ff578bd21c74f4bd7b8c0e130b144,openstack/taskflow,master,I5fc21370d91ff578bd21c74f4bd7b8c0e130b144,Add a state machine copy() method,MERGED,2014-09-11 23:23:43.000000000,2014-10-18 20:16:33.000000000,2014-10-18 20:16:33.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-09-11 23:23:43.000000000', 'files': ['taskflow/types/fsm.py', 'taskflow/tests/unit/test_types.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/26793dcbf9519b6ffd904415d7264bee2ac9b7fe', 'message': 'Add a state machine copy() method\n\nIn order to move the states.py constants to a state machine\nobject we need to be able to copy that object that will be\ndefined there so that it can be used by those states users.\n\nChange-Id: I5fc21370d91ff578bd21c74f4bd7b8c0e130b144\n'}]",0,120936,26793dcbf9519b6ffd904415d7264bee2ac9b7fe,6,2,1,1297,,,0,"Add a state machine copy() method

In order to move the states.py constants to a state machine
object we need to be able to copy that object that will be
defined there so that it can be used by those states users.

Change-Id: I5fc21370d91ff578bd21c74f4bd7b8c0e130b144
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/36/120936/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/types/fsm.py', 'taskflow/tests/unit/test_types.py']",2,26793dcbf9519b6ffd904415d7264bee2ac9b7fe,," def test_copy_states(self): c = fsm.FSM('down') self.assertEqual(0, len(c.states)) d = c.copy() c.add_state('up') c.add_state('down') self.assertEqual(2, len(c.states)) self.assertEqual(0, len(d.states)) def test_copy_reactions(self): c = fsm.FSM('down') d = c.copy() c.add_state('down') c.add_state('up') c.add_reaction('down', 'jump', lambda *args: 'up') c.add_transition('down', 'up', 'jump') self.assertEqual(1, c.events) self.assertEqual(0, d.events) self.assertNotIn('down', d) self.assertNotIn('up', d) self.assertEqual([], list(d)) self.assertEqual([('down', 'jump', 'up')], list(c)) def test_copy_initialized(self): j = self.jumper.copy() self.assertIsNone(j.current_state) for i, transition in enumerate(self.jumper.run_iter('jump')): if i == 4: break self.assertIsNone(j.current_state) self.assertIsNotNone(self.jumper.current_state) ",,50,0
openstack%2Ftaskflow~master~I61488e4158b38d39017435af008382f28d800049,openstack/taskflow,master,I61488e4158b38d39017435af008382f28d800049,Ensure state machine can be frozen,MERGED,2014-07-16 19:30:33.000000000,2014-10-18 20:16:30.000000000,2014-10-18 20:16:29.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-07-16 19:30:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2831d2d865c70a82104c39906605e6a7831e53cc', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions...\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 2, 'created': '2014-07-19 01:48:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3046f6aa02c791c85d623400108afde26f9ecb91', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions...\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 3, 'created': '2014-07-23 08:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/acb18ca5708f5c0a660b84fa4a793b334a08315e', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions...\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 4, 'created': '2014-07-23 19:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3d6970f3c19eb8b131f34cc4194353fcea3b0973', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions. To start use this freeze() capability in\nthe runner state machine when a machine build is requested.\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 5, 'created': '2014-07-26 02:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/000e42660527825e6f3e9897d9075da2e8829f1c', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions. To start use this freeze() capability in\nthe runner state machine when a machine build is requested.\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 6, 'created': '2014-07-31 01:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/12307e436dc98392c660a23bc3a885922eeeda9c', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions. To start use this freeze() capability in\nthe runner state machine when a machine build is requested.\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 7, 'created': '2014-08-01 03:37:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3897cc77f574db07aa302ff1d68be108599ab6c2', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions. To start use this freeze() capability in\nthe runner state machine when a machine build is requested.\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 8, 'created': '2014-08-11 18:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c6a29d58cb3c1dbd58cd9b88549e36d5cbdaa3a3', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions. To start use this freeze() capability in\nthe runner state machine when a machine build is requested.\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 9, 'created': '2014-08-21 22:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c1e85a42277ec17f1ca7813cad6b813cfd35a511', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions. To start use this freeze() capability in\nthe runner state machine when a machine build is requested.\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 10, 'created': '2014-08-28 05:58:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/41abb60ad763d89fbb979ddb1e2ed953d643b47c', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions. To start use this freeze() capability in\nthe runner state machine when a machine build is requested.\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 11, 'created': '2014-08-28 06:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8690dcbb4ac5691d0d467d7a0361ab71f43d076b', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions. To start use this freeze() capability in\nthe runner state machine when a machine build is requested.\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 12, 'created': '2014-08-28 06:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4b4dcb620678c1ea512f50f51e8d5ff8763e5fea', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions. To start use this freeze() capability in\nthe runner state machine when a machine build is requested.\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 13, 'created': '2014-08-28 17:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c57e539002e5678580fad4c546bc617b2009c0b0', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions. To start use this freeze() capability in\nthe runner state machine when a machine build is requested.\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 14, 'created': '2014-09-05 01:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/84d58a1cc3369c8e1ec4093238128eb020f66b36', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions. To start use this freeze() capability in\nthe runner state machine when a machine build is requested.\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 15, 'created': '2014-09-07 20:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c54347e5fde6135d886be9186da7ed24459fc224', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions. To start use this freeze() capability in\nthe runner state machine when a machine build is requested.\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}, {'number': 16, 'created': '2014-09-18 20:51:20.000000000', 'files': ['taskflow/types/fsm.py', 'taskflow/engines/action_engine/runner.py', 'taskflow/tests/unit/test_types.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c5c22112a229cf7705aa23fe754d8f6b4ecb0bec', 'message': 'Ensure state machine can be frozen\n\nTo match the other types ability to be frozen so that\nthey can no longer be mutated add a freeze() method to\nthe state machine type that ensures that subsequent\nadd_state, add_reaction, add_transition method calls will\nraise an exception.\n\nThis is quite useful when the state machine is constructed\nin one function and the creator wants to stop further adds\nby other functions. To start use this freeze() capability in\nthe runner state machine when a machine build is requested.\n\nPart of blueprint runner-state-machine\n\nChange-Id: I61488e4158b38d39017435af008382f28d800049\n'}]",0,107479,c5c22112a229cf7705aa23fe754d8f6b4ecb0bec,66,3,16,1297,,,0,"Ensure state machine can be frozen

To match the other types ability to be frozen so that
they can no longer be mutated add a freeze() method to
the state machine type that ensures that subsequent
add_state, add_reaction, add_transition method calls will
raise an exception.

This is quite useful when the state machine is constructed
in one function and the creator wants to stop further adds
by other functions. To start use this freeze() capability in
the runner state machine when a machine build is requested.

Part of blueprint runner-state-machine

Change-Id: I61488e4158b38d39017435af008382f28d800049
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/79/107479/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/types/fsm.py', 'taskflow/engines/action_engine/runner.py', 'taskflow/tests/unit/test_types.py']",3,2831d2d865c70a82104c39906605e6a7831e53cc,bp/runner-state-machine," def test_freeze(self): self.jumper.freeze() self.assertRaises(fsm.FrozenMachine, self.jumper.add_state, 'test') self.assertRaises(fsm.FrozenMachine, self.jumper.add_transition, 'test', 'test', 'test') self.assertRaises(fsm.FrozenMachine, self.jumper.add_reaction, 'test', 'test', lambda *args: 'test') ",,30,0
openstack%2Fhorizon~master~Ic51d6cadc7a95ac1918d0cf7762600abe17941c0,openstack/horizon,master,Ic51d6cadc7a95ac1918d0cf7762600abe17941c0,Update Horizon terminology relating to storage,MERGED,2014-10-15 12:50:27.000000000,2014-10-18 20:05:50.000000000,2014-10-18 20:05:49.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 5623}, {'_account_id': 7012}, {'_account_id': 9622}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-10-15 12:50:27.000000000', 'files': ['openstack_dashboard/dashboards/admin/hypervisors/templates/hypervisors/index.html', 'openstack_dashboard/dashboards/admin/hypervisors/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/84f78554f6277ecd8946e6e8e802366b9098aa44', 'message': ""Update Horizon terminology relating to storage\n\n    Currently, although the Horizon Hypervisors page only shows\n    local storage and not storage, this is unclear from the\n    terminology. Add 'local' to the description to clarify\n    that only local storage is being reported.\n\n    Closes-Bug: #1352405\n\nChange-Id: Ic51d6cadc7a95ac1918d0cf7762600abe17941c0\n""}]",0,128634,84f78554f6277ecd8946e6e8e802366b9098aa44,10,6,1,13638,,,0,"Update Horizon terminology relating to storage

    Currently, although the Horizon Hypervisors page only shows
    local storage and not storage, this is unclear from the
    terminology. Add 'local' to the description to clarify
    that only local storage is being reported.

    Closes-Bug: #1352405

Change-Id: Ic51d6cadc7a95ac1918d0cf7762600abe17941c0
",git fetch https://review.opendev.org/openstack/horizon refs/changes/34/128634/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/hypervisors/templates/hypervisors/index.html', 'openstack_dashboard/dashboards/admin/hypervisors/tables.py']",2,84f78554f6277ecd8946e6e8e802366b9098aa44,," verbose_name=_(""Local Storage (used)""), verbose_name=_(""Local Storage (total)""),"," verbose_name=_(""Storage (used)""), verbose_name=_(""Storage (total)""),",3,3
openstack%2Ftaskflow~master~I6e48df78d20389d65de8210c6157abb99f52d7dd,openstack/taskflow,master,I6e48df78d20389d65de8210c6157abb99f52d7dd,We can now use PyMySQL in py3.x tests,MERGED,2014-10-14 20:02:51.000000000,2014-10-18 19:38:40.000000000,2014-10-18 19:38:39.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7366}]","[{'number': 1, 'created': '2014-10-14 20:02:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/baf1b9c0c8855a0e9b85c26ef5bf16a26fdf6477', 'message': 'We can now use PyMySQL in py3.x tests\n\nThe requirement for PyMySQL got merged into the requirements\nrepo, so now instead of just testing sqlite in py3.x we can\nnow test against the mysql instance that should exist in the\ntest environments (just like we test with MySQL-python in py2.x).\n\nChange-Id: I6e48df78d20389d65de8210c6157abb99f52d7dd\n'}, {'number': 2, 'created': '2014-10-14 20:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c3b01017583dea425e2e095ca7e505de80574495', 'message': 'We can now use PyMySQL in py3.x tests\n\nThe requirement for PyMySQL got merged into the requirements\nrepo, so now instead of just testing sqlite in py3.x we can\nnow test against the mysql instance that should exist in the\ntest environments (just like we test with MySQL-python in py2.x).\n\nChange-Id: I6e48df78d20389d65de8210c6157abb99f52d7dd\n'}, {'number': 3, 'created': '2014-10-14 20:07:05.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/bcae66b21cdee23c8c857500a48d26f53d9ff6cb', 'message': 'We can now use PyMySQL in py3.x tests\n\nThe requirement for PyMySQL got merged into the requirements\nrepo, so now instead of just testing sqlite (or postgres) in py3.x\nwe can now test against the mysql instance that should exist in the\ntest environments (just like we test with MySQL-python in py2.x).\n\nChange-Id: I6e48df78d20389d65de8210c6157abb99f52d7dd\n'}]",0,128430,bcae66b21cdee23c8c857500a48d26f53d9ff6cb,10,3,3,1297,,,0,"We can now use PyMySQL in py3.x tests

The requirement for PyMySQL got merged into the requirements
repo, so now instead of just testing sqlite (or postgres) in py3.x
we can now test against the mysql instance that should exist in the
test environments (just like we test with MySQL-python in py2.x).

Change-Id: I6e48df78d20389d65de8210c6157abb99f52d7dd
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/30/128430/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,baf1b9c0c8855a0e9b85c26ef5bf16a26fdf6477,, PyMySQL>=0.6.2 PyMySQL>=0.6.2,,2,0
openstack%2Ftaskflow~master~I9b4f9061c7adb7d72315315f41bb0d742b6f56b5,openstack/taskflow,master,I9b4f9061c7adb7d72315315f41bb0d742b6f56b5,Bring in a newer optional eventlet,MERGED,2014-09-04 01:18:08.000000000,2014-10-18 19:38:33.000000000,2014-10-18 19:38:32.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-09-04 01:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0b39966fb527ce06ec5fb5bd37ec831bc70a8743', 'message': 'Bring in a newer optional eventlet\n\nSince the openstack requirements repo just accepted eventlet>=0.15.1\nwe might as well also use that version in our optional requirements\nand remove a piece of code that was dealing with a bug that was fixed\nin eventlet 0.15.\n\nChange-Id: I9b4f9061c7adb7d72315315f41bb0d742b6f56b5\n'}, {'number': 2, 'created': '2014-09-27 21:51:10.000000000', 'files': ['taskflow/utils/eventlet_utils.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7640b09250da85271bf69a0e6553be699b195066', 'message': 'Bring in a newer optional eventlet\n\nSince the openstack requirements repo just accepted eventlet>=0.15.1\nwe might as well also use that version in our optional requirements\nand remove a piece of code that was dealing with a bug that was fixed\nin eventlet 0.15.\n\nChange-Id: I9b4f9061c7adb7d72315315f41bb0d742b6f56b5\n'}]",0,118937,7640b09250da85271bf69a0e6553be699b195066,9,2,2,1297,,,0,"Bring in a newer optional eventlet

Since the openstack requirements repo just accepted eventlet>=0.15.1
we might as well also use that version in our optional requirements
and remove a piece of code that was dealing with a bug that was fixed
in eventlet 0.15.

Change-Id: I9b4f9061c7adb7d72315315f41bb0d742b6f56b5
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/37/118937/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/utils/eventlet_utils.py', 'optional-requirements.txt']",2,0b39966fb527ce06ec5fb5bd37ec831bc70a8743,,eventlet>=0.15.1,eventlet>=0.13.0,2,4
openstack%2Ftaskflow~master~I6174b4f1936858c13eeee416bfa3836cf20a1350,openstack/taskflow,master,I6174b4f1936858c13eeee416bfa3836cf20a1350,Update engine class names to better reflect there usage,MERGED,2014-10-07 18:26:19.000000000,2014-10-18 19:38:25.000000000,2014-10-18 19:38:24.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-10-07 18:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e12a9a04ab92e225599e2a90328b91cc43376f05', 'message': 'Update engine class names to better reflect there usage\n\nRename the single threaded engine to be the serial engine which\nbetter matches its entrypoint, do the same for the multi-threaded\nengine which better matches (renaming it to the parallel engine).\n\nChange-Id: I6174b4f1936858c13eeee416bfa3836cf20a1350\n'}, {'number': 2, 'created': '2014-10-08 05:17:47.000000000', 'files': ['taskflow/examples/run_by_iter.py', 'taskflow/examples/run_by_iter_enumerate.py', 'taskflow/engines/action_engine/engine.py', 'doc/source/notifications.rst', 'taskflow/tests/unit/test_engines.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8d143187eaa0c5554bb72b9258e2b3538e7c16ea', 'message': 'Update engine class names to better reflect there usage\n\nRename the single threaded engine to be the serial engine which\nbetter matches its entrypoint, do the same for the multithreaded\nengine (renaming it to the parallel engine).\n\nChange-Id: I6174b4f1936858c13eeee416bfa3836cf20a1350\n'}]",0,126651,8d143187eaa0c5554bb72b9258e2b3538e7c16ea,8,2,2,1297,,,0,"Update engine class names to better reflect there usage

Rename the single threaded engine to be the serial engine which
better matches its entrypoint, do the same for the multithreaded
engine (renaming it to the parallel engine).

Change-Id: I6174b4f1936858c13eeee416bfa3836cf20a1350
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/51/126651/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/examples/run_by_iter.py', 'taskflow/examples/run_by_iter_enumerate.py', 'taskflow/engines/action_engine/engine.py', 'doc/source/notifications.rst', 'taskflow/tests/unit/test_engines.py', 'setup.cfg']",6,e12a9a04ab92e225599e2a90328b91cc43376f05,, default = taskflow.engines.action_engine.engine:SerialActionEngine serial = taskflow.engines.action_engine.engine:SerialActionEngine parallel = taskflow.engines.action_engine.engine:ParallelActionEngine, default = taskflow.engines.action_engine.engine:SingleThreadedActionEngine serial = taskflow.engines.action_engine.engine:SingleThreadedActionEngine parallel = taskflow.engines.action_engine.engine:MultiThreadedActionEngine,25,28
openstack%2Ftaskflow~master~I12726812615052d8405071d46272ef2b8286cfe2,openstack/taskflow,master,I12726812615052d8405071d46272ef2b8286cfe2,Use constants for revert automatically provided kwargs,MERGED,2014-10-17 00:45:25.000000000,2014-10-18 19:38:18.000000000,2014-10-18 19:38:17.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-10-17 00:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3eae38291318f5d497ce9670d24eb03577bc0e1e', 'message': 'Use contants for revert automatically provided kwargs\n\nInstead of using strings use module level constants for\nthe automatically provided keyword arguments to the tasks\nrevert function. This makes it easier for users of taskflow\nto associate these constants with the actual keywords, without\nhaving to resort to using raw strings directly.\n\nChange-Id: I12726812615052d8405071d46272ef2b8286cfe2\n'}, {'number': 2, 'created': '2014-10-17 00:45:36.000000000', 'files': ['taskflow/task.py', 'taskflow/engines/action_engine/executor.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a15e07a0a12c808565f62c29007a61a1b0114809', 'message': 'Use constants for revert automatically provided kwargs\n\nInstead of using strings use module level constants for\nthe automatically provided keyword arguments to the tasks\nrevert function. This makes it easier for users of taskflow\nto associate these constants with the actual keywords, without\nhaving to resort to using raw strings directly.\n\nChange-Id: I12726812615052d8405071d46272ef2b8286cfe2\n'}]",0,129100,a15e07a0a12c808565f62c29007a61a1b0114809,7,2,2,1297,,,0,"Use constants for revert automatically provided kwargs

Instead of using strings use module level constants for
the automatically provided keyword arguments to the tasks
revert function. This makes it easier for users of taskflow
to associate these constants with the actual keywords, without
having to resort to using raw strings directly.

Change-Id: I12726812615052d8405071d46272ef2b8286cfe2
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/00/129100/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/task.py', 'taskflow/engines/action_engine/executor.py']",2,3eae38291318f5d497ce9670d24eb03577bc0e1e,,from taskflow import task as _task kwargs[_task.REVERT_RESULT] = result kwargs[_task.REVERT_FLOW_FAILURES] = failures, kwargs['result'] = result kwargs['flow_failures'] = failures,11,2
openstack%2Ftaskflow~master~I7b58380aeb57a58fa3b3c424c9f39de30f44f0e9,openstack/taskflow,master,I7b58380aeb57a58fa3b3c424c9f39de30f44f0e9,Link a few of the classes to implemented features/bugs in python,MERGED,2014-09-18 20:12:53.000000000,2014-10-18 19:38:09.000000000,2014-10-18 19:38:08.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-09-18 20:12:53.000000000', 'files': ['taskflow/utils/lock_utils.py', 'taskflow/types/latch.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/97e6bb162cb91b4e0bbb14c9a40824ef35cd98c8', 'message': 'Link a few of the classes to implemented features/bugs in python\n\nThis adds comments that associate the classes we have for threading\nusage to upstream bugs in python where similar features are being\ncreated (and potentially supported upstream).\n\nWhen we are able to reduce the number of supported python versions\nwe can/should try to remove our implementations and move to the ones\nthat may showup in the python standard library instead.\n\nChange-Id: I7b58380aeb57a58fa3b3c424c9f39de30f44f0e9\n'}]",0,122510,97e6bb162cb91b4e0bbb14c9a40824ef35cd98c8,6,2,1,1297,,,0,"Link a few of the classes to implemented features/bugs in python

This adds comments that associate the classes we have for threading
usage to upstream bugs in python where similar features are being
created (and potentially supported upstream).

When we are able to reduce the number of supported python versions
we can/should try to remove our implementations and move to the ones
that may showup in the python standard library instead.

Change-Id: I7b58380aeb57a58fa3b3c424c9f39de30f44f0e9
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/10/122510/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/utils/lock_utils.py', 'taskflow/types/latch.py']",2,97e6bb162cb91b4e0bbb14c9a40824ef35cd98c8,," """"""A class that ensures N-arrivals occur before unblocking. TODO(harlowja): replace with http://bugs.python.org/issue8777 when we no longer have to support python 2.6 or 2.7 and we can only support 3.2 or later. """""""," """"""A class that ensures N-arrivals occur before unblocking.""""""",9,1
openstack%2Ftaskflow~master~I93a858177be138bf09abfc32897c96a991f69386,openstack/taskflow,master,I93a858177be138bf09abfc32897c96a991f69386,Remove useless __exit__ return,MERGED,2014-09-17 00:44:14.000000000,2014-10-18 19:38:01.000000000,2014-10-18 19:38:01.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 9608}]","[{'number': 1, 'created': '2014-09-17 00:44:14.000000000', 'files': ['taskflow/types/timing.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c5aa2f94d15b89da119ba8a2b9a49a570e6d7357', 'message': ""Remove useless __exit__ return\n\nBy default we will return none, and that qualifies as\nfalsey, so we don't need to explicitly return false when\nthe default will do just fine.\n\nChange-Id: I93a858177be138bf09abfc32897c96a991f69386\n""}]",0,122034,c5aa2f94d15b89da119ba8a2b9a49a570e6d7357,8,3,1,1297,,,0,"Remove useless __exit__ return

By default we will return none, and that qualifies as
falsey, so we don't need to explicitly return false when
the default will do just fine.

Change-Id: I93a858177be138bf09abfc32897c96a991f69386
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/34/122034/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/types/timing.py'],1,c5aa2f94d15b89da119ba8a2b9a49a570e6d7357,,, # NOTE(harlowja): don't silence the exception. return False,0,2
openstack%2Ftaskflow~master~I98eeb180b31bd488ae0eadd730e1530d7bae1f1f,openstack/taskflow,master,I98eeb180b31bd488ae0eadd730e1530d7bae1f1f,Add a more dynamic/useful logging listener,MERGED,2014-09-18 00:09:33.000000000,2014-10-18 19:37:59.000000000,2014-10-18 19:37:58.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8759}]","[{'number': 1, 'created': '2014-09-18 00:09:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/14305ebd88715eafffff752d26e17595b6cc6b8b', 'message': 'Add a more dynamic/useful logging listener\n\nBoth cinder and glance are starting to share the same logic\nfor there engine notification listener, so instead of having\nthem copy around that code it will be much nicer if taskflow\ncan just provide itself a more capable listener that both\ncan share and use directly.\n\nThis avoids users of taskflow having to understand more about\nthe internals of taskflow and its associated state then they\nlikely need to understand (which makes taskflow easier to use\nand less work to integrate).\n\nRelevant locations where this already exists:\n\n- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py\n- https://review.openstack.org/#/c/85211/ (soon to be merged)\n\nChange-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f\n'}, {'number': 2, 'created': '2014-09-18 00:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c93f1e53f15da35abe335c06227f502678f29f4e', 'message': 'Add a more dynamic/useful logging listener\n\nBoth cinder and glance are starting to share the same logic\nfor there engine notification listener, so instead of having\nthem copy around that code it will be much nicer if taskflow\ncan just provide itself a more capable listener that both\ncan share and use directly.\n\nThis avoids users of taskflow having to understand more about\nthe internals of taskflow and its associated state then they\nlikely need to understand (which makes taskflow easier to use\nand less work to integrate).\n\nRelevant locations where this already exists:\n\n- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py\n- https://review.openstack.org/#/c/85211/ (soon to be merged)\n\nChange-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f\n'}, {'number': 3, 'created': '2014-09-18 00:28:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/02317c09ee5d83cb443500c972192361a0cb3fa7', 'message': 'Add a more dynamic/useful logging listener\n\nBoth cinder and glance are starting to share the same logic\nfor there engine notification listener, so instead of having\nthem copy around that code it will be much nicer if taskflow\ncan just provide itself a more capable listener that both\ncan share and use directly.\n\nThis avoids users of taskflow having to understand more about\nthe internals of taskflow and its associated state then they\nlikely need to understand (which makes taskflow easier to use\nand less work to integrate).\n\nRelevant locations where this already exists:\n\n- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py\n- https://review.openstack.org/#/c/85211/ (soon to be merged)\n\nChange-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f\n'}, {'number': 4, 'created': '2014-09-18 03:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6bc06c2a4907fe66baf397deca098e093e5754ee', 'message': 'Add a more dynamic/useful logging listener\n\nBoth cinder and glance are starting to share the same logic\nfor there engine notification listener, so instead of having\nthem copy around that code it will be much nicer if taskflow\ncan just provide itself a more capable listener that both\ncan share and use directly.\n\nThis avoids users of taskflow having to understand more about\nthe internals of taskflow and its associated state then they\nlikely need to understand (which makes taskflow easier to use\nand less work to integrate).\n\nRelevant locations where this already exists:\n\n- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py\n- https://review.openstack.org/#/c/85211/\n\nChange-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f\n'}, {'number': 5, 'created': '2014-09-18 04:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/95bf68f5cc86bad44d4cc79a15fb6207e52eeb60', 'message': 'Add a more dynamic/useful logging listener\n\nBoth cinder and glance are starting to share the same logic\nfor there engine notification listener, so instead of having\nthem copy around that code it will be much nicer if taskflow\ncan just provide itself a more capable listener that both\ncan share and use directly.\n\nThis avoids users of taskflow having to understand more about\nthe internals of taskflow and its associated state then they\nlikely need to understand (which makes taskflow easier to use\nand less work to integrate).\n\nRelevant locations where this already exists:\n\n- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py\n- https://review.openstack.org/#/c/85211/\n\nChange-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f\n'}, {'number': 6, 'created': '2014-09-18 04:20:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a9d73dc8fbbbe449c6cbfa89105c9229f950685e', 'message': 'Add a more dynamic/useful logging listener\n\nBoth cinder and glance are starting to share the same logic\nfor there engine notification listener, so instead of having\nthem copy around that code it will be much nicer if taskflow\ncan just provide itself a more capable listener that both\ncan share and use directly.\n\nThis avoids users of taskflow having to understand more about\nthe internals of taskflow and its associated state then they\nlikely need to understand (which makes taskflow easier to use\nand less work to integrate).\n\nRelevant locations where this already exists:\n\n- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py\n- https://review.openstack.org/#/c/85211/\n\nChange-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f\n'}, {'number': 7, 'created': '2014-09-18 23:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0733b580569aff65fa4de2f0dbd30dc66ff9fd03', 'message': 'Add a more dynamic/useful logging listener\n\nBoth cinder and glance are starting to share the same logic\nfor there engine notification listener, so instead of having\nthem copy around that code it will be much nicer if taskflow\ncan just provide itself a more capable listener that both\ncan share and use directly.\n\nThis avoids users of taskflow having to understand more about\nthe internals of taskflow and its associated state then they\nlikely need to understand (which makes taskflow easier to use\nand less work to integrate).\n\nRelevant locations where this already exists:\n\n- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py\n- https://review.openstack.org/#/c/85211/\n\nChange-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f\n'}, {'number': 8, 'created': '2014-09-18 23:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c6affbef6f84637243dbb5ad76e5512639e4adf3', 'message': 'Add a more dynamic/useful logging listener\n\nBoth cinder and glance are starting to share the same logic\nfor there engine notification listener, so instead of having\nthem copy around that code it will be much nicer if taskflow\ncan just provide itself a more capable listener that both\ncan share and use directly.\n\nThis avoids users of taskflow having to understand more about\nthe internals of taskflow and its associated state then they\nlikely need to understand (which makes taskflow easier to use\nand less work to integrate).\n\nRelevant locations where this already exists:\n\n- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py\n- https://review.openstack.org/#/c/85211/\n\nChange-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f\n'}, {'number': 9, 'created': '2014-09-18 23:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4111d7539a52601e2025ee5cbc173bc01803c5e3', 'message': 'Add a more dynamic/useful logging listener\n\nBoth cinder and glance are starting to share the same logic\nfor there engine notification listener, so instead of having\nthem copy around that code it will be much nicer if taskflow\ncan just provide itself a more capable listener that both\ncan share and use directly.\n\nThis avoids users of taskflow having to understand more about\nthe internals of taskflow and its associated state then they\nlikely need to understand (which makes taskflow easier to use\nand less work to integrate).\n\nRelevant locations where this already exists:\n\n- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py\n- https://review.openstack.org/#/c/85211/\n\nChange-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f\n'}, {'number': 10, 'created': '2014-09-28 04:18:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/af7ab0a1ce3bb155ee4adf295aaf5630a755b4b2', 'message': 'Add a more dynamic/useful logging listener\n\nBoth cinder and glance are starting to share the same logic\nfor there engine notification listener, so instead of having\nthem copy around that code it will be much nicer if taskflow\ncan just provide itself a more capable listener that both\ncan share and use directly.\n\nThis avoids users of taskflow having to understand more about\nthe internals of taskflow and its associated state then they\nlikely need to understand (which makes taskflow easier to use\nand less work to integrate).\n\nRelevant locations where this already exists:\n\n- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py\n- https://review.openstack.org/#/c/85211/\n\nChange-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f\n'}, {'number': 11, 'created': '2014-09-28 18:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4f38240acf7331d18110e39b1e8164a284cb1097', 'message': 'Add a more dynamic/useful logging listener\n\nBoth cinder and glance are starting to share the same logic\nfor there engine notification listener, so instead of having\nthem copy around that code it will be much nicer if taskflow\ncan just provide itself a more capable listener that both\ncan share and use directly.\n\nThis avoids users of taskflow having to understand more about\nthe internals of taskflow and its associated state then they\nlikely need to understand (which makes taskflow easier to use\nand less work to integrate).\n\nRelevant locations where this already exists:\n\n- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py\n- https://review.openstack.org/#/c/85211/\n\nChange-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f\n'}, {'number': 12, 'created': '2014-09-28 19:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/52bf6d1cd082a9621345a88991094675a2d98a29', 'message': 'Add a more dynamic/useful logging listener\n\nBoth cinder and glance are starting to share the same logic\nfor there engine notification listener, so instead of having\nthem copy around that code it will be much nicer if taskflow\ncan just provide itself a more capable listener that both\ncan share and use directly.\n\nThis avoids users of taskflow having to understand more about\nthe internals of taskflow and its associated state then they\nlikely need to understand (which makes taskflow easier to use\nand less work to integrate).\n\nRelevant locations where this already exists:\n\n- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py\n- https://review.openstack.org/#/c/85211/\n\nChange-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f\n'}, {'number': 13, 'created': '2014-09-29 01:39:25.000000000', 'files': ['taskflow/test.py', 'taskflow/tests/unit/test_duration.py', 'doc/source/notifications.rst', 'taskflow/listeners/logging.py', 'taskflow/tests/unit/test_listeners.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cf1e468cf16818cf19777031fde049416eec4e56', 'message': 'Add a more dynamic/useful logging listener\n\nBoth cinder and glance are starting to share the same logic\nfor there engine notification listener, so instead of having\nthem copy around that code it will be much nicer if taskflow\ncan just provide itself a more capable listener that both\ncan share and use directly.\n\nThis avoids users of taskflow having to understand more about\nthe internals of taskflow and its associated state then they\nlikely need to understand (which makes taskflow easier to use\nand less work to integrate).\n\nRelevant locations where this already exists:\n\n- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py\n- https://review.openstack.org/#/c/85211/\n\nChange-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f\n'}]",0,122272,cf1e468cf16818cf19777031fde049416eec4e56,29,3,13,1297,,,0,"Add a more dynamic/useful logging listener

Both cinder and glance are starting to share the same logic
for there engine notification listener, so instead of having
them copy around that code it will be much nicer if taskflow
can just provide itself a more capable listener that both
can share and use directly.

This avoids users of taskflow having to understand more about
the internals of taskflow and its associated state then they
likely need to understand (which makes taskflow easier to use
and less work to integrate).

Relevant locations where this already exists:

- https://github.com/openstack/cinder/blob/master/cinder/flow_utils.py
- https://review.openstack.org/#/c/85211/

Change-Id: I98eeb180b31bd488ae0eadd730e1530d7bae1f1f
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/72/122272/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/notifications.rst', 'taskflow/listeners/logging.py']",2,14305ebd88715eafffff752d26e17595b6cc6b8b,dynamic-listener,"import sysfrom taskflow import statesif sys.version_info[0:2] == (2, 6): _PY26 = True else: _PY26 = False # Fixes this for python 2.6 which was missing the is enabled for method # when a logger adapter is being used/provided, this will no longer be needed # when we can just support python 2.6 (which fixed the lack of this method # on adapters). def _isEnabledFor(logger, level): if _PY26 and isinstance(logger, logging.LoggerAdapter): return logger.logger.isEnabledFor(level) return logger.isEnabledFor(level) It listens for task and flow notifications and writes those notifications to a provided logger, or logger of its module (``taskflow.listeners.logging``) if none is provided. The log level can also be configured, ``logging.DEBUG`` is used by default when none is provided. class DynamicLoggingListener(base.ListenerBase): """"""Listener that logs notifications it receives. It listens for task and flow notifications and writes those notifications to a provided logger, or logger of its module (``taskflow.listeners.logging``) if none is provided. The log level can **not** be configured and ``logging.DEBUG`` or ``logging.WARNING`` will be selected automatically based on the execution state and results produced. The following flow states cause ``logging.WARNING`` to be used: * ``states.FAILURE`` * ``states.REVERTED`` The following task states cause ``logging.WARNING`` to be used: * ``states.FAILURE`` * ``states.RETRYING`` * ``states.REVERTING`` When a task produces a ``misc.Failure`` object as its result (typically this happens when a task raises an exception) this will **always** switch the logger to use ``logging.WARNING`` (if the failure object contains a ``exc_info`` tuple this will also be logged to provide a meaningful traceback). """""" def __init__(self, engine, task_listen_for=(misc.Notifier.ANY,), flow_listen_for=(misc.Notifier.ANY,), logger=None): super(DynamicLoggingListener, self).__init__( engine, task_listen_for=task_listen_for, flow_listen_for=flow_listen_for) if logger is None: self._logger = LOG else: self._logger = logger def _flow_receiver(self, state, details): # Gets called on flow state changes. level = logging.DEBUG if state in (states.FAILURE, states.REVERTED): level = logging.WARNING self._logger.log(level, ""Flow '%s' (%s) transitioned into state '%s'"" "" from state '%s'"", details['flow_name'], details['flow_uuid'], state, details.get('old_state')) def _task_receiver(self, state, details): # Gets called on task state changes. if 'result' in details and state in base.FINISH_STATES: # If the task failed, it's useful to show the exception traceback # and any other available exception information. result = details.get('result') if isinstance(result, misc.Failure): if result.exc_info: exc_info = result.exc_info else: exc_info = None self._logger.warn(""Task '%s' (%s) transitioned into state"" "" '%s'"", details['task_name'], details['task_uuid'], state, exc_info=exc_info) else: # Otherwise, depending on the enabled logging level/state we # will show or hide results that the task may have produced # during execution. level = logging.DEBUG if state == states.FAILURE: level = logging.WARNING if (_isEnabledFor(self._logger, logging.DEBUG) or state == states.FAILURE): self._logger.log(level, ""Task '%s' (%s) transitioned into"" "" state '%s' with result '%s'"", details['task_name'], details['task_uuid'], state, result) else: self._logger.log(level, ""Task '%s' (%s) transitioned into"" "" state '%s'"", details['task_name'], details['task_uuid'], state) else: level = logging.DEBUG if state in (states.REVERTING, states.RETRYING): level = logging.WARNING self._logger.log(level, ""Task '%s' (%s) transitioned into state"" "" '%s'"", details['task_name'], details['task_uuid'], state)"," It listens for task and flow notifications and writes those notifications to provided logger, or logger of its module (``taskflow.listeners.logging``) if none provided. Log level can also be configured, ``logging.DEBUG`` is used by default.",116,4
openstack%2Ftaskflow~master~I9f9a83cfb763a0a05d22efca4e0f80627ba8ca8f,openstack/taskflow,master,I9f9a83cfb763a0a05d22efca4e0f80627ba8ca8f,Document more function/class/method params,MERGED,2014-09-26 00:01:57.000000000,2014-10-18 19:27:57.000000000,2014-10-18 19:27:56.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-09-26 00:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/548f203a892fbacfa888818de150f088f7f69fdc', 'message': 'Document more function/class/method params\n\nTo help fill out the docs start adding on docstrings\nthat document what a parameter is and what its meaning\nand usage is to help users better understand the parameter.\n\nPart of ongoing bug 1374202\n\nChange-Id: I9f9a83cfb763a0a05d22efca4e0f80627ba8ca8f\n'}, {'number': 2, 'created': '2014-09-26 00:05:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6ade6a69ff0bb8f733d2fa58752ea6c7e032055a', 'message': 'Document more function/class/method params\n\nTo help fill out the docs start adding on docstrings\nthat document what a parameter is and what its meaning\nand usage is to help users better understand the parameter.\n\nPart of ongoing bug 1374202\n\nChange-Id: I9f9a83cfb763a0a05d22efca4e0f80627ba8ca8f\n'}, {'number': 3, 'created': '2014-09-26 18:43:52.000000000', 'files': ['taskflow/task.py', 'taskflow/atom.py', 'taskflow/exceptions.py', 'taskflow/retry.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9537f523512eed8603dc304d8502762caaa733cf', 'message': 'Document more function/class/method params\n\nTo help fill out the docs start adding on docstrings\nthat document what a parameter is and what its meaning\nand usage is to help users better understand the parameter.\n\nPart of ongoing bug 1374202\n\nChange-Id: I9f9a83cfb763a0a05d22efca4e0f80627ba8ca8f\n'}]",0,124228,9537f523512eed8603dc304d8502762caaa733cf,11,2,3,1297,,,0,"Document more function/class/method params

To help fill out the docs start adding on docstrings
that document what a parameter is and what its meaning
and usage is to help users better understand the parameter.

Part of ongoing bug 1374202

Change-Id: I9f9a83cfb763a0a05d22efca4e0f80627ba8ca8f
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/28/124228/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/task.py', 'taskflow/atom.py', 'taskflow/exceptions.py', 'taskflow/retry.py']",4,548f203a892fbacfa888818de150f088f7f69fdc,bug/1374202,"class Retry(atom.Atom): object is an atom it may also provide :meth:`.execute` and :meth:`.revert` methods to alter the inputs of connected atoms (depending on the desired strategy to be used this can be quite useful). NOTE(harlowja): the :meth:`.execute` and :meth:`.revert` and :meth:`.on_failure` will automatically be given a ``history`` parameter, which contains information about the past decisions and outcomes that have occurred (if available). """"""Executes the given retry. previously provided values and a ``history`` of prior failures from result returned by this retry during that failure resolution :param args: positional arguments that retry requires to execute. :param kwargs: any keyword arguments that retry requires to execute. """"""Reverts this retry. :param args: positional arguments that the retry required to execute. :param kwargs: any keyword arguments that the retry required to execute. """""" @abc.abstractmethod def on_failure(self, history, *args, **kwargs): """"""Makes a decision about the future. This method will typically use information about prior failures (if this historical failure information is not available or was not persisted the provided history will be empty). Returns a retry constant (one of): * ``RETRY``: when the controlling flow must be reverted and restarted again (for example with new parameters). * ``REVERT``: when this controlling flow must be completely reverted and the parent flow (if any) should make a decision about further flow execution. * ``REVERT_ALL``: when this controlling flow and the parent flow (if any) must be reverted and marked as a ``FAILURE``.","class Decider(object): """"""A class/mixin object that can decide how to resolve execution failures. A decider may be executed multiple times on subflow or other atom failure and it is expected to make a decision about what should be done to resolve the failure (retry, revert to the previous retry, revert the whole flow, etc.). """""" @abc.abstractmethod def on_failure(self, history, *args, **kwargs): """"""On failure makes a decision about the future. This method will typically use information about prior failures (if this historical failure information is not available or was not persisted this history will be empty). Returns retry action constant: * ``RETRY`` when subflow must be reverted and restarted again (maybe with new parameters). * ``REVERT`` when this subflow must be completely reverted and parent subflow should make a decision about the flow execution. * ``REVERT_ALL`` in a case when the whole flow must be reverted and marked as ``FAILURE``. """""" @six.add_metaclass(abc.ABCMeta) class Retry(atom.Atom, Decider): object is an atom it may also provide execute and revert methods to alter the inputs of connected atoms (depending on the desired strategy to be used this can be quite useful). """"""Executes the given retry atom. previously provided values and a history of prior failures from result returned by this retry controller during that failure resolution """"""Reverts this retry using the given context.",103,62
openstack%2Ftaskflow~master~I6153ff8379833844105545ddb21dede65a7d4d3a,openstack/taskflow,master,I6153ff8379833844105545ddb21dede65a7d4d3a,Use timeutils functions instead of misc.wallclock,MERGED,2014-09-16 22:38:50.000000000,2014-10-18 19:27:50.000000000,2014-10-18 19:27:49.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-09-16 22:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/07be58658589095565c296473a59d153946c8b30', 'message': 'Use timeutils functions instead of misc.wallclock\n\nThe common oslo timeutils functions can perform the\nsame time methods using the better datetime objects than\nusing the raw unix timestamps directly, so in order to\nreduce a little bit of code just use the functions that\nmodule provides instead of our own.\n\nAlso adds a few more tests that validate the various runtime\nerrors being thrown to ensure they are thrown when expected.\n\nChange-Id: I6153ff8379833844105545ddb21dede65a7d4d3a\n'}, {'number': 2, 'created': '2014-09-16 22:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a61062c8d88e2b65df9b559faacae69133b48e89', 'message': 'Use timeutils functions instead of misc.wallclock\n\nThe common oslo timeutils functions can perform the\nsame time methods using the better datetime objects than\nusing the raw unix timestamps directly, so in order to\nreduce a little bit of code just use the functions that\nmodule provides instead of our own.\n\nAlso adds a few more tests that validate the various runtime\nerrors being thrown to ensure they are thrown when expected.\n\nChange-Id: I6153ff8379833844105545ddb21dede65a7d4d3a\n'}, {'number': 3, 'created': '2014-09-16 23:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/284de16413b9f616cc411b83cb43876f59a7b455', 'message': 'Use timeutils functions instead of misc.wallclock\n\nThe common oslo timeutils functions can perform the\nsame time methods using the better datetime objects than\nusing the raw unix timestamps directly, so in order to\nreduce a little bit of code just use the functions that\nmodule provides instead of our own.\n\nAlso adds a few more tests that validate the various runtime\nerrors being thrown to ensure they are thrown when expected\nand handles the case where time goes backwards (say when ntpd\nupdates) in a more reliable manner (by not becoming negative).\n\nChange-Id: I6153ff8379833844105545ddb21dede65a7d4d3a\n'}, {'number': 4, 'created': '2014-09-16 23:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cc82001ca8236ccede420fa9cf6552ee7725a748', 'message': 'Use timeutils functions instead of misc.wallclock\n\nThe common oslo timeutils functions can perform the\nsame time methods using the better datetime objects than\nusing the raw unix timestamps directly, so in order to\nreduce a little bit of code just use the functions that\nmodule provides instead of our own.\n\nAlso adds a few more tests that validate the various runtime\nerrors being thrown to ensure they are thrown when expected\nand handles the case where time goes backwards (say when ntpd\nupdates) in a more reliable manner (by not becoming negative).\n\nChange-Id: I6153ff8379833844105545ddb21dede65a7d4d3a\n'}, {'number': 5, 'created': '2014-09-17 00:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0aad39d7419d8b0f5713f4acad11ed05cc5e097f', 'message': 'Use timeutils functions instead of misc.wallclock\n\nThe common oslo timeutils functions can perform the\nsame time methods using the better datetime objects than\nusing the raw unix timestamps directly, so in order to\nreduce a little bit of code just use the functions that\nmodule provides instead of our own.\n\nAlso adds a few more tests that validate the various runtime\nerrors being thrown to ensure they are thrown when expected\nand handles the case where time goes backwards (say when ntpd\nupdates) in a more reliable manner (by not becoming negative).\n\nChange-Id: I6153ff8379833844105545ddb21dede65a7d4d3a\n'}, {'number': 6, 'created': '2014-09-17 06:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/daea851704dbb9e3ac04c5c8ff70282aaeebf95c', 'message': 'Use timeutils functions instead of misc.wallclock\n\nThe common oslo timeutils functions can perform the\nsame time methods using the better datetime objects than\nusing the raw unix timestamps directly, so in order to\nreduce a little bit of code just use the functions that\nmodule provides instead of our own.\n\nAlso adds a few more tests that validate the various runtime\nerrors being thrown to ensure they are thrown when expected\nand handles the case where time goes backwards (say when ntpd\nupdates) in a more reliable manner (by not becoming negative).\n\nChange-Id: I6153ff8379833844105545ddb21dede65a7d4d3a\n'}, {'number': 7, 'created': '2014-09-27 21:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/934ce4a45bc6c4b4a7308fc1d3c297a665dfce92', 'message': 'Use timeutils functions instead of misc.wallclock\n\nThe common oslo timeutils functions can perform the\nsame time methods using the better datetime objects than\nusing the raw unix timestamps directly, so in order to\nreduce a little bit of code just use the functions that\nmodule provides instead of our own.\n\nAlso adds a few more tests that validate the various runtime\nerrors being thrown to ensure they are thrown when expected\nand handles the case where time goes backwards (say when ntpd\nupdates) in a more reliable manner (by not becoming negative).\n\nChange-Id: I6153ff8379833844105545ddb21dede65a7d4d3a\n'}, {'number': 8, 'created': '2014-09-28 01:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/961d318de17fb0711bbc88ec871915fabab231f9', 'message': 'Use timeutils functions instead of misc.wallclock\n\nThe common oslo timeutils functions can perform the\nsame time methods using the better datetime objects than\nusing the raw unix timestamps directly, so in order to\nreduce a little bit of code just use the functions that\nmodule provides instead of our own.\n\nAlso adds a few more tests that validate the various runtime\nerrors being thrown to ensure they are thrown when expected\nand handles the case where time goes backwards (say when ntpd\nupdates) in a more reliable manner (by not becoming negative).\n\nChange-Id: I6153ff8379833844105545ddb21dede65a7d4d3a\n'}, {'number': 9, 'created': '2014-09-28 04:20:17.000000000', 'files': ['taskflow/tests/unit/worker_based/test_protocol.py', 'taskflow/types/timing.py', 'taskflow/tests/unit/test_types.py', 'taskflow/utils/misc.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/be254eac665ae6fcbfd8bb640637e0e93d0ca9f9', 'message': 'Use timeutils functions instead of misc.wallclock\n\nThe common oslo timeutils functions can perform the\nsame time methods using the better datetime objects than\nusing the raw unix timestamps directly, so in order to\nreduce a little bit of code just use the functions that\nmodule provides instead of our own.\n\nAlso adds a few more tests that validate the various runtime\nerrors being thrown to ensure they are thrown when expected\nand handles the case where time goes backwards (say when ntpd\nupdates) in a more reliable manner (by not becoming negative).\n\nChange-Id: I6153ff8379833844105545ddb21dede65a7d4d3a\n'}]",0,122012,be254eac665ae6fcbfd8bb640637e0e93d0ca9f9,20,2,9,1297,,,0,"Use timeutils functions instead of misc.wallclock

The common oslo timeutils functions can perform the
same time methods using the better datetime objects than
using the raw unix timestamps directly, so in order to
reduce a little bit of code just use the functions that
module provides instead of our own.

Also adds a few more tests that validate the various runtime
errors being thrown to ensure they are thrown when expected
and handles the case where time goes backwards (say when ntpd
updates) in a more reliable manner (by not becoming negative).

Change-Id: I6153ff8379833844105545ddb21dede65a7d4d3a
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/12/122012/4 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/tests/unit/worker_based/test_protocol.py', 'taskflow/types/timing.py', 'taskflow/tests/unit/test_types.py']",3,07be58658589095565c296473a59d153946c8b30,more-time-utils," def test_bad_expiry(self): self.assertRaises(ValueError, tt.StopWatch, -1) def test_not_expired(self): def test_no_expiry(self): watch = tt.StopWatch(0.1) self.assertRaises(RuntimeError, watch.expired) def test_no_elapsed(self): watch = tt.StopWatch() self.assertRaises(RuntimeError, watch.elapsed) def test_no_leftover(self): watch = tt.StopWatch() self.assertRaises(RuntimeError, watch.leftover) watch = tt.StopWatch(1) self.assertRaises(RuntimeError, watch.leftover) ", def test_no_expiry(self):,58,20
openstack%2Ftaskflow~master~Ida4f86b308941ff708db5395a1d266c0c4b75815,openstack/taskflow,master,Ida4f86b308941ff708db5395a1d266c0c4b75815,Remove no longer needed r/w lock interface base class,MERGED,2014-09-20 05:21:18.000000000,2014-10-18 19:27:42.000000000,2014-10-18 19:27:41.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-09-20 05:21:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/656c66eb3d63e05a25aff40edb82fcd667d41a24', 'message': 'Remove no longer needed r/w lock abstract base class\n\nThis class was put in place when this code was being more\nactively developed to ensure that both the dummy and the\nactual class had the same methods, since these two classes\nhave apis that are now stable we no longer need to have a\nbase class to enforce the implemented api.\n\nChange-Id: Ida4f86b308941ff708db5395a1d266c0c4b75815\n'}, {'number': 2, 'created': '2014-09-20 05:33:16.000000000', 'files': ['taskflow/utils/lock_utils.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7fe2f5108cf64d7f7a6ab2229159782398db3200', 'message': 'Remove no longer needed r/w lock interface base class\n\nThis interface/class was put in place when this code was being\nmore actively developed to ensure that both the dummy and the\nactual class had the same methods, since these two classes\nhave apis that are now stable we no longer need to have a base\nclass to enforce the implemented api that itself provides no\nadded functionality.\n\nChange-Id: Ida4f86b308941ff708db5395a1d266c0c4b75815\n'}]",0,122917,7fe2f5108cf64d7f7a6ab2229159782398db3200,7,2,2,1297,,,0,"Remove no longer needed r/w lock interface base class

This interface/class was put in place when this code was being
more actively developed to ensure that both the dummy and the
actual class had the same methods, since these two classes
have apis that are now stable we no longer need to have a base
class to enforce the implemented api that itself provides no
added functionality.

Change-Id: Ida4f86b308941ff708db5395a1d266c0c4b75815
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/17/122917/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/utils/lock_utils.py'],1,656c66eb3d63e05a25aff40edb82fcd667d41a24,,"class ReaderWriterLock(object): """"""Returns if there are writers waiting to become the *one* writer."""""" """"""Returns if the caller is the active writer or a pending writer."""""" """"""Returns whether the lock is locked by a writer or reader."""""" """"""Returns if the caller is one of the readers."""""" """"""Context manager that grants a read lock. Will wait until no active or pending writers. Raises a RuntimeError if an active or pending writer tries to acquire a read lock. """""" """"""Context manager that grants a write lock. Will wait until no active readers. Blocks readers after acquiring. Raises a RuntimeError if an active reader attempts to acquire a lock. """"""class DummyReaderWriterLock(object):","@six.add_metaclass(abc.ABCMeta) class _ReaderWriterLockBase(object): """"""Base class for reader/writer lock implementations."""""" @abc.abstractproperty def has_pending_writers(self): """"""Returns if there are writers waiting to become the *one* writer."""""" @abc.abstractmethod def is_writer(self, check_pending=True): """"""Returns if the caller is the active writer or a pending writer."""""" @abc.abstractproperty def owner(self): """"""Returns whether the lock is locked by a writer or reader."""""" @abc.abstractmethod def is_reader(self): """"""Returns if the caller is one of the readers."""""" @abc.abstractmethod def read_lock(self): """"""Context manager that grants a read lock. Will wait until no active or pending writers. Raises a RuntimeError if an active or pending writer tries to acquire a read lock. """""" @abc.abstractmethod def write_lock(self): """"""Context manager that grants a write lock. Will wait until no active readers. Blocks readers after acquiring. Raises a RuntimeError if an active reader attempts to acquire a lock. """""" class ReaderWriterLock(_ReaderWriterLockBase):class DummyReaderWriterLock(_ReaderWriterLockBase):",19,42
openstack%2Fkeystone~feature%2Fhierarchical-multitenancy~I2b56a362df40b664e3a802d09ca027277678b300,openstack/keystone,feature/hierarchical-multitenancy,I2b56a362df40b664e3a802d09ca027277678b300,Add parent_id field to projects,MERGED,2014-08-29 13:55:09.000000000,2014-10-18 19:06:14.000000000,2014-10-18 19:06:13.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 1941}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6282}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 6537}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8866}, {'_account_id': 8871}, {'_account_id': 9101}, {'_account_id': 11022}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-08-29 13:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fbec628a103f7b5e8e0a2190352d5ef91d8cbae9', 'message': 'Add parent_project_id field\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 2, 'created': '2014-08-29 15:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dd6c2725160b8d8b2a1534b41db591a316aee236', 'message': 'Add parent_project_id field\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 3, 'created': '2014-08-29 20:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/16c5cf3c194f90802e9af5ecd1ed47e7ec83221c', 'message': 'Add parent_project_id field\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 4, 'created': '2014-09-01 12:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/af69b499cae7de5cf249c461da476a4307406f92', 'message': 'Add parent_project_id field\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 5, 'created': '2014-09-02 14:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d29158babe36b5cbd7c359cd2ba96f595afdf781', 'message': 'Add project_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 6, 'created': '2014-09-02 19:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c8116042a5c30827aea109331279c13ded8e32fe', 'message': 'Add project_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 7, 'created': '2014-09-05 14:43:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/58e289196ac0dabeaa1ba1d9a5282b30912121b1', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 8, 'created': '2014-09-08 19:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/01cb127dbf0a5e19ef86f5979db1a6b1434935c8', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 9, 'created': '2014-09-11 18:13:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9be0e986bb7be1fb0951b564d6b9a7eb538494be', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 10, 'created': '2014-09-11 20:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cd46a6f60bbf627294e23e382b2a9adc71dedd36', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 11, 'created': '2014-09-12 17:07:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e9e84203fd5bdbd9086fc1aa6916f44baa0118a3', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 12, 'created': '2014-09-17 16:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7b8cad3932e3c98fecc020e53333d5a0fb5d706a', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 13, 'created': '2014-09-17 19:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3b696b4ce626f103d2173d57bf73cf22c5573586', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 14, 'created': '2014-09-19 13:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/026bc0cafe39b8f73cdebb58ea8082c524b0b8c5', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 15, 'created': '2014-10-03 14:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ec96a4f5805e37a1ab8ffe6d539dc57acbc6271a', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 16, 'created': '2014-10-03 18:24:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b2fd5da1efffa89347b4f354f9398f36e8e62820', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 17, 'created': '2014-10-09 12:36:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ca4606ef28ae91aac71c3d7270d615e1bbe508a7', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 18, 'created': '2014-10-09 14:34:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e5df009e58a1c7034b1bf91292fb92cdeab70646', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 19, 'created': '2014-10-10 17:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2ebf707e26325007ea17c850de71e72f092bbdb2', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 20, 'created': '2014-10-13 16:45:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2a81bb87ee755bb3a217ded2ee885253c3e532ce', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 21, 'created': '2014-10-14 13:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b96f28e077ced19afebaab86671b350d7c5a94f1', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 22, 'created': '2014-10-16 17:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/03069f1c1697017daece660241e9b56e47cdf8e5', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}, {'number': 23, 'created': '2014-10-18 03:19:13.000000000', 'files': ['keystone/common/sql/migrate_repo/versions/061_add_parent_project.py', 'keystone/tests/default_fixtures.py', 'keystone/assignment/backends/sql.py', 'keystone/tests/test_sql_upgrade.py', 'keystone/tests/test_v3.py', 'keystone/tests/test_backend_ldap.py', 'keystone/tests/test_backend.py', 'keystone/assignment/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d81f23a6c3abf882c20b7c3e86a6c5315d9fb834', 'message': 'Add parent_id field to projects\n\nField to point to a parent project. This enables\nthe possibility to use hierarchical projects.\n\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>\n\nImplements: blueprint hierarchical-multitenancy\nChange-Id: I2b56a362df40b664e3a802d09ca027277678b300\n'}]",65,117784,d81f23a6c3abf882c20b7c3e86a6c5315d9fb834,103,20,23,11022,,,0,"Add parent_id field to projects

Field to point to a parent project. This enables
the possibility to use hierarchical projects.

Co-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>
Co-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>
Co-Authored-By: Telles Mota Vidal Nobrega <tellesmvn@lsd.ufcg.edu.br>

Implements: blueprint hierarchical-multitenancy
Change-Id: I2b56a362df40b664e3a802d09ca027277678b300
",git fetch https://review.opendev.org/openstack/keystone refs/changes/84/117784/22 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/assignment/backends/sql.py', 'keystone/assignment/core.py', 'keystone/common/sql/migrate_repo/versions/053_add_parent_project.py', 'keystone/tests/test_v3.py', 'keystone/tests/test_backend_ldap.py', 'keystone/assignment/backends/ldap.py', 'keystone/tests/test_backend.py']",7,fbec628a103f7b5e8e0a2190352d5ef91d8cbae9,bp/hierarchical-multitenancy," 'domain_id': domain['id'], 'parent_project_id': None} 'enabled': True, 'parent_project_id': None} 'enabled': True, 'parent_project_id': None}", 'domain_id': domain['id']} 'enabled': True} 'enabled': True},93,13
openstack%2Ftaskflow~master~I7f3914c126f39c56d0d2e3dfe02f3b112391ff43,openstack/taskflow,master,I7f3914c126f39c56d0d2e3dfe02f3b112391ff43,Increase robustness of WBE message and request processing,MERGED,2014-09-12 01:21:17.000000000,2014-10-18 18:25:47.000000000,2014-10-18 18:25:46.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 9608}]","[{'number': 1, 'created': '2014-09-12 01:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e39a3497705a16b0aa3e531dd893e1b52d1853eb', 'message': ""Increase robustness of WBE message and request processing\n\nWhen a notification request/response can't be processed ensure\nwe log an error message at the same level as the other function\nthat sends back responses.\n\nAlso adds in a return boolean from the _reply message (which\nis used for the X number of replies to a servers task request)\nfunction and use this boolean to determine if the worker should\nattempt to perform the final handler call that activates the\ndesired task.\n\nAlso ensures that before running commences that we have\nsuccessfully fetched the endpoint attribute and validated that\nit exists and is correct.\n\nChange-Id: I7f3914c126f39c56d0d2e3dfe02f3b112391ff43\n""}, {'number': 2, 'created': '2014-09-12 01:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/503bbb9ae8a55525e9d55b2d9b961f8546888f8b', 'message': ""Increase robustness of WBE message and request processing\n\nWhen a notification request/response can't be processed ensure\nwe log an error message at the same level as the other function\nthat sends back responses.\n\nAlso adds in a return boolean from the _reply message (which\nis used for the X number of replies to a servers task request)\nfunction and use this boolean to determine if the worker should\nattempt to perform the final handler call that activates the\ndesired task.\n\nAlso ensures that before running commences that we have\nsuccessfully fetched the endpoint attribute and validated that\nit exists and is correct.\n\nChange-Id: I7f3914c126f39c56d0d2e3dfe02f3b112391ff43\n""}, {'number': 3, 'created': '2014-09-12 05:13:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2d84fae6d5eda328b497675815416bdac2d4e5c9', 'message': ""Increase robustness of WBE message and request processing\n\nWhen a notification request/response can't be processed ensure\nwe log an error message at the same level as the other function\nthat sends back responses.\n\nAlso adds in a return boolean from the _reply message (which\nis used for the X number of replies to a servers task request)\nfunction and use this boolean to determine if the worker should\nattempt to perform the final handler call that activates the\ndesired task.\n\nChange-Id: I7f3914c126f39c56d0d2e3dfe02f3b112391ff43\n""}, {'number': 4, 'created': '2014-09-12 21:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ef3ed90a5d350c9615dabca21279fae2373cd1aa', 'message': ""Increase robustness of WBE message and request processing\n\nWhen a notification request/response can't be processed ensure\nwe log an error message at the same level as the other function\nthat sends back responses.\n\nAlso adds in a return boolean from the _reply message (which\nis used for the X number of replies to a servers task request)\nfunction and use this boolean to determine if the worker should\nattempt to perform the final handler call that activates the\ndesired task.\n\nChange-Id: I7f3914c126f39c56d0d2e3dfe02f3b112391ff43\n""}, {'number': 5, 'created': '2014-09-25 03:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8dfb904355df9f09f043f03bdaa31895a8143a0a', 'message': ""Increase robustness of WBE message and request processing\n\nWhen a notification request/response can't be processed ensure\nwe log an error message at the same level as the other function\nthat sends back responses.\n\nAlso adds in a return boolean from the _reply message (which\nis used for the X number of replies to a servers task request)\nfunction and use this boolean to determine if the worker should\nattempt to perform the final handler call that activates the\ndesired task.\n\nChange-Id: I7f3914c126f39c56d0d2e3dfe02f3b112391ff43\n""}, {'number': 6, 'created': '2014-09-27 21:58:34.000000000', 'files': ['taskflow/engines/worker_based/server.py', 'taskflow/tests/unit/worker_based/test_server.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dc688c18f13a9527ffce4d0175aa6a61450278af', 'message': ""Increase robustness of WBE message and request processing\n\nWhen a notification request/response can't be processed ensure\nwe log an error message at the same level as the other function\nthat sends back responses.\n\nAlso adds in a return boolean from the _reply message (which\nis used for the X number of replies to a servers task request)\nfunction and use this boolean to determine if the worker should\nattempt to perform the final handler call that activates the\ndesired task.\n\nChange-Id: I7f3914c126f39c56d0d2e3dfe02f3b112391ff43\n""}]",0,120960,dc688c18f13a9527ffce4d0175aa6a61450278af,17,3,6,1297,,,0,"Increase robustness of WBE message and request processing

When a notification request/response can't be processed ensure
we log an error message at the same level as the other function
that sends back responses.

Also adds in a return boolean from the _reply message (which
is used for the X number of replies to a servers task request)
function and use this boolean to determine if the worker should
attempt to perform the final handler call that activates the
desired task.

Change-Id: I7f3914c126f39c56d0d2e3dfe02f3b112391ff43
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/60/120960/4 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/worker_based/server.py', 'taskflow/tests/unit/worker_based/test_server.py']",2,e39a3497705a16b0aa3e531dd893e1b52d1853eb,more-robust," def test_on_run_reply_failure(self): request = self.make_request(task=utils.ProgressingTask(), arguments={}) self.proxy_inst_mock.publish.side_effect = RuntimeError('Woot!') # create server and process request s = self.server(reset_master_mock=True) s._process_request(request, self.message_mock) self.assertEqual(1, self.proxy_inst_mock.publish.call_count) "," mock.call.Response(pr.RUNNING), mock.call.proxy.publish(self.response_inst_mock, self.reply_to, correlation_id=self.task_uuid),",47,15
openstack%2Ftaskflow~master~Id215f88430971a4a083f9739fb2ec59d971dc8fa,openstack/taskflow,master,Id215f88430971a4a083f9739fb2ec59d971dc8fa,Add the database schema to the sqlalchemy docs,MERGED,2014-10-10 01:21:45.000000000,2014-10-18 18:25:39.000000000,2014-10-18 18:25:38.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-10-10 01:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7f8a2ad8c360645ed1f99311eb71c0987d656c7c', 'message': 'Add the database schema to the sqlalchemy persistence section\n\nIn order to show people that are reading the docs what the current\nschema for the database is create a helper tool that upgrades the\nschema to the newest version and then uses tabulate to create a\nrestructured text version of that schema which is then included in\nthe documentation.\n\nChange-Id: Id215f88430971a4a083f9739fb2ec59d971dc8fa\n'}, {'number': 2, 'created': '2014-10-10 04:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/471588c9b8aa0a599f13e6cb60ad12686584281b', 'message': 'Add the database schema to the sqlalchemy persistence section\n\nIn order to show people that are reading the docs what the current\nschema for the database is create a helper tool that upgrades the\nschema to the newest version and then uses tabulate to create a\nrestructured text version of that schema which is then included in\nthe documentation.\n\nChange-Id: Id215f88430971a4a083f9739fb2ec59d971dc8fa\n'}, {'number': 3, 'created': '2014-10-10 06:24:39.000000000', 'files': ['tools/schema_generator.py', 'doc/source/persistence.rst'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c90e36020a6993166bae1013402c30d827014317', 'message': 'Add the database schema to the sqlalchemy docs\n\nIn order to show people that are reading the docs what the current\nschema for the database is create a helper tool that upgrades the\nschema to the newest version and then uses tabulate to create a\nrestructured text version of that schema which is then included in\nthe documentation.\n\nChange-Id: Id215f88430971a4a083f9739fb2ec59d971dc8fa\n'}]",0,127398,c90e36020a6993166bae1013402c30d827014317,12,3,3,1297,,,0,"Add the database schema to the sqlalchemy docs

In order to show people that are reading the docs what the current
schema for the database is create a helper tool that upgrades the
schema to the newest version and then uses tabulate to create a
restructured text version of that schema which is then included in
the documentation.

Change-Id: Id215f88430971a4a083f9739fb2ec59d971dc8fa
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/98/127398/3 && git format-patch -1 --stdout FETCH_HEAD,"['tools/schema_generator.py', 'doc/source/persistence.rst']",2,7f8a2ad8c360645ed1f99311eb71c0987d656c7c,schema-in-docs,Schema ^^^^^^ *Logbooks* ========== ======== ============= Name Type Primary Key ========== ======== ============= created_at DATETIME False updated_at DATETIME False uuid VARCHAR True name VARCHAR False meta TEXT False ========== ======== ============= *Flow details* =========== ======== ============= Name Type Primary Key =========== ======== ============= created_at DATETIME False updated_at DATETIME False uuid VARCHAR True name VARCHAR False meta TEXT False state VARCHAR False parent_uuid VARCHAR False =========== ======== ============= *Atom details* =========== =========== ============= Name Type Primary Key =========== =========== ============= created_at DATETIME False updated_at DATETIME False uuid VARCHAR True name VARCHAR False meta TEXT False atom_type VARCHAR(12) False state VARCHAR False intention VARCHAR(7) False results TEXT False failure TEXT False version TEXT False parent_uuid VARCHAR False =========== =========== ============= ,,123,0
openstack%2Ftaskflow~master~I95bad23a33304ddbfa8715a00c913891d4c51f5d,openstack/taskflow,master,I95bad23a33304ddbfa8715a00c913891d4c51f5d,Add a couple of scope shadowing test cases,MERGED,2014-07-28 17:52:36.000000000,2014-10-18 18:25:32.000000000,2014-10-18 18:25:31.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-07-28 17:52:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/43e9e1e38674161842b2c7de599a697906a8cf92', 'message': 'Add a couple of scope shadowing test cases\n\nSince we now support symbol name shadowing we\nshould add a few test cases that ensure that\nthe correct shadowing order/capability is working\nas expected.\n\nChange-Id: I95bad23a33304ddbfa8715a00c913891d4c51f5d\n'}, {'number': 2, 'created': '2014-09-08 20:55:59.000000000', 'files': ['taskflow/tests/unit/test_action_engine_scoping.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d98f23d9c2b7e79f02dabfc04fbe90cd7e03545c', 'message': 'Add a couple of scope shadowing test cases\n\nSince we now support symbol name shadowing we\nshould add a few test cases that ensure that\nthe correct shadowing order/capability is working\nas expected.\n\nChange-Id: I95bad23a33304ddbfa8715a00c913891d4c51f5d\n'}]",0,110076,d98f23d9c2b7e79f02dabfc04fbe90cd7e03545c,15,3,2,1297,,,0,"Add a couple of scope shadowing test cases

Since we now support symbol name shadowing we
should add a few test cases that ensure that
the correct shadowing order/capability is working
as expected.

Change-Id: I95bad23a33304ddbfa8715a00c913891d4c51f5d
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/76/110076/2 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/tests/unit/test_action_engine_scoping.py'],1,43e9e1e38674161842b2c7de599a697906a8cf92,," def test_shadow_graph(self): r = gf.Flow(""root"") customer = test_utils.ProvidesRequiresTask(""customer"", provides=['dog'], requires=[]) customer2 = test_utils.ProvidesRequiresTask(""customer2"", provides=['dog'], requires=[]) washer = test_utils.ProvidesRequiresTask(""washer"", requires=['dog'], provides=['wash']) r.add(customer, washer) r.add(customer2, resolve_requires=False) r.link(customer2, washer) c = compiler.PatternCompiler(r).compile() # The order currently is *not* guaranteed to be 'customer' before # 'customer2' or the reverse, since either can occur before the # washer; since *either* is a valid topological ordering of the # dependencies... # # This may be different after/if the following is resolved: # # https://github.com/networkx/networkx/issues/1181 (and a few others) self.assertEqual(set(['customer', 'customer2']), set(_get_scopes(c, washer)[0])) self.assertEqual([], _get_scopes(c, customer2)) self.assertEqual([], _get_scopes(c, customer)) def test_shadow_linear(self): r = lf.Flow(""root"") customer = test_utils.ProvidesRequiresTask(""customer"", provides=['dog'], requires=[]) customer2 = test_utils.ProvidesRequiresTask(""customer2"", provides=['dog'], requires=[]) washer = test_utils.ProvidesRequiresTask(""washer"", requires=['dog'], provides=['wash']) r.add(customer, customer2, washer) c = compiler.PatternCompiler(r).compile() # This order is guaranteed... self.assertEqual(['customer2', 'customer'], _get_scopes(c, washer)[0])",,49,0
openstack%2Ftaskflow~master~I2e14de2131c3ba4e3e4eb3108477583d0f02dae2,openstack/taskflow,master,I2e14de2131c3ba4e3e4eb3108477583d0f02dae2,Relax the graph flow symbol constraints,MERGED,2014-07-19 01:33:17.000000000,2014-10-18 18:25:25.000000000,2014-10-18 18:25:24.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8871}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-07-19 01:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/34306595bb0068e94f784b1a61088fb13c02e6ab', 'message': 'Relax the graph flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax the constraints that are\nbeing imposed by the graph flow.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I2e14de2131c3ba4e3e4eb3108477583d0f02dae2\n'}, {'number': 2, 'created': '2014-07-19 01:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9c8247397e6a3026d5654a03cce8da4d556a02fc', 'message': 'Relax the graph flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax the constraints that are\nbeing imposed by the graph flow.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I2e14de2131c3ba4e3e4eb3108477583d0f02dae2\n'}, {'number': 3, 'created': '2014-07-25 18:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8e88d9f3bc7cb9a17a7c6df3880c925f790f98b9', 'message': 'Relax the graph flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax the constraints that are\nbeing imposed by the graph flow.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I2e14de2131c3ba4e3e4eb3108477583d0f02dae2\n'}, {'number': 4, 'created': '2014-07-26 03:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/47541394a5d6a24d30c1c7d8c017d1be75d27bf8', 'message': 'Relax the graph flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax the constraints that are\nbeing imposed by the graph flow.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I2e14de2131c3ba4e3e4eb3108477583d0f02dae2\n'}, {'number': 5, 'created': '2014-09-08 20:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3f9ae7a926d644bbb0a508530b4b6bf383346847', 'message': 'Relax the graph flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax the constraints that are\nbeing imposed by the graph flow.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I2e14de2131c3ba4e3e4eb3108477583d0f02dae2\n'}, {'number': 6, 'created': '2014-09-08 20:55:46.000000000', 'files': ['taskflow/tests/unit/patterns/test_graph_flow.py', 'taskflow/tests/unit/test_flow_dependencies.py', 'taskflow/exceptions.py', 'taskflow/patterns/graph_flow.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d6ef68762e847373be0584820fa0557fcbd5003f', 'message': 'Relax the graph flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax the constraints that are\nbeing imposed by the graph flow.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I2e14de2131c3ba4e3e4eb3108477583d0f02dae2\n'}]",0,108175,d6ef68762e847373be0584820fa0557fcbd5003f,36,4,6,1297,,,0,"Relax the graph flow symbol constraints

In order to make it possible to have a symbol
tree we need to relax the constraints that are
being imposed by the graph flow.

Part of blueprint taskflow-improved-scoping

Change-Id: I2e14de2131c3ba4e3e4eb3108477583d0f02dae2
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/75/108175/5 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/tests/unit/patterns/test_graph_flow.py', 'taskflow/tests/unit/test_flow_dependencies.py', 'taskflow/exceptions.py', 'taskflow/patterns/graph_flow.py']",4,34306595bb0068e94f784b1a61088fb13c02e6ab,bp/taskflow-improved-scoping,"def _unsatisfied_requires(node, graph, *additional_provided): """"""Extracts the unsatisified symbol requirements of a single node."""""" requires = set(node.requires) if not requires: return requires for provided in additional_provided: requires = requires - provided if not requires: return requires for pred in graph.bfs_predecessors_iter(node): requires = requires - pred.provides if not requires: return requires return requires "" will allow for logical"" "" edge traversal"") self._graph = graph.freeze() def add(self, *items, **kwargs): """"""Adds a given task/tasks/flow/flows to this flow. :param items: items to add to the flow :param kwargs: keyword arguments, the two keyword arguments currently processed are: * ``resolve_requires`` a boolean that when true (the default) implies that when items are added their symbol requirements will be matched to existing items and links will be automatically made to those providers. If multiple possible providers exist then a AmbiguousDependency exception will be raised. * ``resolve_existing``, a boolean that when true (the default) implies that on addition of a new item that existing items will have their requirements scanned for symbols that this newly added item can provide. If a match is found a link is automatically created from the newly added item to the requiree. """""" # This syntax will *hopefully* be better in future versions of python. # # See: http://legacy.python.org/dev/peps/pep-3102/ (python 3.0+) resolve_requires = bool(kwargs.get('resolve_requires', True)) resolve_existing = bool(kwargs.get('resolve_existing', True)) # Figure out what the existing nodes *still* require and what they # provide so we can do this lookup later when inferring. required = collections.defaultdict(list) provided = collections.defaultdict(list) retry_provides = set() if self._retry is not None: for value in self._retry.requires: required[value].append(self._retry) for value in self._retry.provides: retry_provides.add(value) provided[value].append(self._retry) for item in self._graph.nodes_iter(): for value in _unsatisfied_requires(item, self._graph, retry_provides): required[value].append(item) for value in item.provides: provided[value].append(item) # Try to find a valid provider. if resolve_requires: for value in _unsatisfied_requires(item, tmp_graph, retry_provides): if value in provided: providers = provided[value] if len(providers) > 1: provider_names = [n.name for n in providers] raise exc.AmbiguousDependency( ""Resolution error detected when"" "" adding %(item)s, multiple"" "" providers %(providers)s found for"" "" required symbol '%(value)s'"" % dict(item=item.name, providers=sorted(provider_names), value=value)) else: self._link(providers[0], item, graph=tmp_graph, reason=value) else: required[value].append(item) provided[value].append(item) # See if what we provide fulfills any existing requiree. if resolve_existing: for value in item.provides: if value in required: for requiree in list(required[value]): if requiree is not item: self._link(item, requiree, graph=tmp_graph, reason=value) required[value].remove(requiree) requires.update(_unsatisfied_requires(item, g, retry_provides))"," "" will allow for correct dependency"" "" resolution"") self._graph = graph self._graph.freeze() def add(self, *items): """"""Adds a given task/tasks/flow/flows to this flow."""""" requirements = collections.defaultdict(list) provided = {} def update_requirements(node): for value in node.requires: requirements[value].append(node) for node in self: update_requirements(node) for value in node.provides: provided[value] = node if self.retry: update_requirements(self.retry) provided.update(dict((k, self.retry) for k in self.retry.provides)) update_requirements(item) for value in item.provides: if value in provided: raise exc.DependencyFailure( ""%(item)s provides %(value)s but is already being"" "" provided by %(flow)s and duplicate producers"" "" are disallowed"" % dict(item=item.name, flow=provided[value].name, value=value)) if self.retry and value in self.retry.requires: raise exc.DependencyFailure( ""Flows retry controller %(retry)s requires %(value)s "" ""but item %(item)s being added to the flow produces "" ""that item, this creates a cyclic dependency and is "" ""disallowed"" % dict(item=item.name, retry=self.retry.name, value=value)) provided[value] = item for value in item.requires: if value in provided: self._link(provided[value], item, graph=tmp_graph, reason=value) if value in requirements: for node in requirements[value]: self._link(item, node, graph=tmp_graph, reason=value) item_requires = item.requires - retry_provides # Now scan predecessors to see if they provide what we want. if item_requires: for pred_item in g.bfs_predecessors_iter(item): item_requires = item_requires - pred_item.provides if not item_requires: break if item_requires: requires.update(item_requires)",140,67
openstack%2Ftaskflow~master~I80718b4bc01fbf0dce6a95cd2fac7e6e2e1814d1,openstack/taskflow,master,I80718b4bc01fbf0dce6a95cd2fac7e6e2e1814d1,Relax the unordered flow symbol constraints,MERGED,2014-07-18 22:16:41.000000000,2014-10-18 18:25:18.000000000,2014-10-18 18:25:17.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-07-18 22:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3b5809eebdc7160f2858a62fcd18d28be85cf7e3', 'message': 'Relax the unordered flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the unordeded constraints\nand later move those constraint checks and validations\ninto the engines compliation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I80718b4bc01fbf0dce6a95cd2fac7e6e2e1814d1\n'}, {'number': 2, 'created': '2014-07-18 22:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2b018cb284720f58323966bf2d822a8f045b5855', 'message': 'Relax the unordered flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the unordered constraints\nand later move those constraint checks and validations\ninto the engines compilation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I80718b4bc01fbf0dce6a95cd2fac7e6e2e1814d1\n'}, {'number': 3, 'created': '2014-07-18 22:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0332da77971d9c4d17ec9ac9b5e62a645587d610', 'message': 'Relax the unordered flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the unordered constraints\nand later move those constraint checks and validations\ninto the engines compilation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I80718b4bc01fbf0dce6a95cd2fac7e6e2e1814d1\n'}, {'number': 4, 'created': '2014-07-19 01:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b75a5b8b6f9183d44e398a1cf23cf793b7efff7b', 'message': 'Relax the unordered flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the unordered constraints\nand later move those constraint checks and validations\ninto the engines compilation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I80718b4bc01fbf0dce6a95cd2fac7e6e2e1814d1\n'}, {'number': 5, 'created': '2014-07-25 18:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f7eb30040b00229a4af7f3a4bacd4d5fd3bead09', 'message': 'Relax the unordered flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the unordered constraints\nand later move those constraint checks and validations\ninto the engines compilation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I80718b4bc01fbf0dce6a95cd2fac7e6e2e1814d1\n'}, {'number': 6, 'created': '2014-07-26 03:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6f6b8647cf6ae48c7b08cf8914c3b9706fb6fd51', 'message': 'Relax the unordered flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the unordered constraints\nand later move those constraint checks and validations\ninto the engines compilation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I80718b4bc01fbf0dce6a95cd2fac7e6e2e1814d1\n'}, {'number': 7, 'created': '2014-09-08 20:45:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/072cbbe879a1d49fd63582633858fd1459853183', 'message': 'Relax the unordered flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the unordered constraints\nand later move those constraint checks and validations\ninto the engines compilation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I80718b4bc01fbf0dce6a95cd2fac7e6e2e1814d1\n'}, {'number': 8, 'created': '2014-09-08 20:55:41.000000000', 'files': ['taskflow/patterns/unordered_flow.py', 'taskflow/tests/unit/test_flow_dependencies.py', 'taskflow/tests/unit/patterns/test_unordered_flow.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/76641d86b89cdba23ac49d8c65011467a098f6dc', 'message': 'Relax the unordered flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the unordered constraints\nand later move those constraint checks and validations\ninto the engines compilation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I80718b4bc01fbf0dce6a95cd2fac7e6e2e1814d1\n'}]",0,108161,76641d86b89cdba23ac49d8c65011467a098f6dc,31,3,8,1297,,,0,"Relax the unordered flow symbol constraints

In order to make it possible to have a symbol
tree we need to relax and remove the constraints
that are being imposed by the unordered constraints
and later move those constraint checks and validations
into the engines compilation stage.

Part of blueprint taskflow-improved-scoping

Change-Id: I80718b4bc01fbf0dce6a95cd2fac7e6e2e1814d1
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/61/108161/8 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/patterns/unordered_flow.py', 'taskflow/tests/unit/test_flow_dependencies.py', 'taskflow/tests/unit/patterns/test_unordered_flow.py']",3,3b5809eebdc7160f2858a62fcd18d28be85cf7e3,bp/taskflow-improved-scoping," def test_unordered_flow_two_tasks(self): def test_unordered_flow_two_tasks_two_different_calls(self): f.add(task2) self.assertEqual(len(f), 2) self.assertEqual(set(['a']), f.requires) self.assertEqual(set(['a']), f.provides) def test_unordered_flow_two_tasks_reverse_order(self): f = uf.Flow('test').add(task2).add(task1) self.assertEqual(len(f), 2) self.assertEqual(set(['a']), f.requires) self.assertEqual(set(['a']), f.provides) f.add(task2, task1) self.assertEqual(len(f), 2) def test_unordered_flow_with_retry_fully_satisfies(self): ret = retry.AlwaysRevert(provides=['b', 'a']) f = uf.Flow('test', ret) f.add(_task(name='task1', requires=['a'])) self.assertIs(f.retry, ret) self.assertEqual(ret.name, 'test_retry') self.assertEqual(f.requires, set([])) self.assertEqual(f.provides, set(['b', 'a']))","from taskflow import exceptions as exc def test_unordered_flow_two_independent_tasks(self): def test_unordered_flow_two_dependent_tasks(self): task1 = _task(name='task1', provides=['a']) task2 = _task(name='task2', requires=['a']) f = uf.Flow('test') self.assertRaises(exc.DependencyFailure, f.add, task1, task2) def test_unordered_flow_two_dependent_tasks_two_different_calls(self): self.assertRaises(exc.DependencyFailure, f.add, task2) def test_unordered_flow_two_dependent_tasks_reverse_order(self): f = uf.Flow('test') self.assertRaises(exc.DependencyFailure, f.add, task2, task1) def test_unordered_flow_two_dependent_tasks_reverse_order2(self): task1 = _task(name='task1', provides=['a']) task2 = _task(name='task2', requires=['a']) f = uf.Flow('test').add(task2) self.assertRaises(exc.DependencyFailure, f.add, task1) self.assertRaises(exc.DependencyFailure, f.add, task2, task1)",51,95
openstack%2Ftaskflow~master~I6efdc821ff991e83572d89f56be5c678d007f9f8,openstack/taskflow,master,I6efdc821ff991e83572d89f56be5c678d007f9f8,Relax the linear flow symbol constraints,MERGED,2014-07-18 05:58:42.000000000,2014-10-18 18:25:10.000000000,2014-10-18 18:25:09.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8871}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-07-18 05:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/eed820b05f7a239eb9e787ad912a55fffdb6f193', 'message': 'Relax the linear flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the linear constraints\nand move those constraint checks and validations\ninto the engines compliation stage.\n\nTo enable this we first need to relax those existing\nrestrictions (which are enforced later anyway) to\nallow for further development.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I6efdc821ff991e83572d89f56be5c678d007f9f8\n'}, {'number': 2, 'created': '2014-07-18 07:11:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5832c6456a6e3a0a2e7c7bf3d75d46ee46b7f515', 'message': 'Relax the linear flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the linear constraints\nand move those constraint checks and validations\ninto the engines compliation stage.\n\nTo enable this we first need to relax those existing\nrestrictions (which are enforced later anyway) to\nallow for further development.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I6efdc821ff991e83572d89f56be5c678d007f9f8\n'}, {'number': 3, 'created': '2014-07-18 19:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d9d9e7cfc962a7da69498efc5a13f30945ebe0cf', 'message': 'Relax the linear flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the linear constraints\nand move those constraint checks and validations\ninto the engines compliation stage.\n\nTo enable this we first need to relax those existing\nrestrictions (which are enforced later anyway) to\nallow for further development.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I6efdc821ff991e83572d89f56be5c678d007f9f8\n'}, {'number': 4, 'created': '2014-07-18 22:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c13b3ee3133c07f37d8c520c74e4f1d040bc5782', 'message': 'Relax the linear flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the linear constraints\nand later move those constraint checks and validations\ninto the engines compilation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I6efdc821ff991e83572d89f56be5c678d007f9f8\n'}, {'number': 5, 'created': '2014-07-19 01:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f9170ea7f194dec981190580129a6f2a8641c046', 'message': 'Relax the linear flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the linear constraints\nand later move those constraint checks and validations\ninto the engines compilation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I6efdc821ff991e83572d89f56be5c678d007f9f8\n'}, {'number': 6, 'created': '2014-07-25 18:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/955d0aa97dcb5c47c6a9f740fba28fd62a03cb6f', 'message': 'Relax the linear flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the linear constraints\nand later move those constraint checks and validations\ninto the engines compilation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I6efdc821ff991e83572d89f56be5c678d007f9f8\n'}, {'number': 7, 'created': '2014-07-26 03:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1fef100aa7af5034237112f345fae6afe6402ff5', 'message': 'Relax the linear flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the linear constraints\nand later move those constraint checks and validations\ninto the engines compilation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I6efdc821ff991e83572d89f56be5c678d007f9f8\n'}, {'number': 8, 'created': '2014-09-08 20:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/930042f046010f556a982c075c9f80ecf7b28239', 'message': 'Relax the linear flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the linear constraints\nand later move those constraint checks and validations\ninto the engines compilation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I6efdc821ff991e83572d89f56be5c678d007f9f8\n'}, {'number': 9, 'created': '2014-09-08 20:55:32.000000000', 'files': ['taskflow/patterns/linear_flow.py', 'taskflow/tests/unit/patterns/test_linear_flow.py', 'taskflow/tests/unit/test_flow_dependencies.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2339bacaf7edd9a781267cf8ca38b8639f34137b', 'message': 'Relax the linear flow symbol constraints\n\nIn order to make it possible to have a symbol\ntree we need to relax and remove the constraints\nthat are being imposed by the linear constraints\nand later move those constraint checks and validations\ninto the engines compilation stage.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: I6efdc821ff991e83572d89f56be5c678d007f9f8\n'}]",0,107897,2339bacaf7edd9a781267cf8ca38b8639f34137b,42,4,9,1297,,,0,"Relax the linear flow symbol constraints

In order to make it possible to have a symbol
tree we need to relax and remove the constraints
that are being imposed by the linear constraints
and later move those constraint checks and validations
into the engines compilation stage.

Part of blueprint taskflow-improved-scoping

Change-Id: I6efdc821ff991e83572d89f56be5c678d007f9f8
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/97/107897/5 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/patterns/linear_flow.py', 'taskflow/tests/unit/patterns/test_linear_flow.py', 'taskflow/tests/unit/test_flow_dependencies.py']",3,eed820b05f7a239eb9e787ad912a55fffdb6f193,bp/taskflow-improved-scoping,," def test_nested_flows_provides_same_values(self): flow = lf.Flow('lf').add( uf.Flow('uf').add(utils.TaskOneReturn(provides='x'))) self.assertRaises(exceptions.DependencyFailure, flow.add, gf.Flow('gf').add(utils.TaskOneReturn(provides='x'))) def test_linear_flow_retry_and_task_dependency_conflict(self): flow = lf.Flow('lf', retry.AlwaysRevert('rt', requires=['x'])) self.assertRaises(exceptions.DependencyFailure, flow.add, utils.TaskOneReturn(provides=['x'])) def test_linear_flow_retry_and_task_provide_same_value(self): flow = lf.Flow('lf', retry.AlwaysRevert('rt', provides=['x'])) self.assertRaises(exceptions.DependencyFailure, flow.add, utils.TaskOneReturn('t1', provides=['x'])) def test_two_retries_provide_same_values_in_nested_flows(self): flow = lf.Flow('lf', retry.AlwaysRevert('rt1', provides=['x'])) self.assertRaises(exceptions.DependencyFailure, flow.add, lf.Flow('lf1', retry.AlwaysRevert('rt2', provides=['x']))) def test_two_retries_provide_same_values(self): flow = lf.Flow('lf').add( lf.Flow('lf1', retry.AlwaysRevert('rt1', provides=['x']))) self.assertRaises(exceptions.DependencyFailure, flow.add, lf.Flow('lf2', retry.AlwaysRevert('rt2', provides=['x']))) ",2,84
openstack%2Ftaskflow~master~Id921a4abd9bf2b7b5c5a762337f8e90e8f1fe194,openstack/taskflow,master,Id921a4abd9bf2b7b5c5a762337f8e90e8f1fe194,Revamp the symbol lookup mechanism,MERGED,2014-07-25 18:26:08.000000000,2014-10-18 18:25:03.000000000,2014-10-18 18:25:02.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-07-25 18:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c2cc5a00709c4677be96f9c005df69cff0d423b3', 'message': 'Revamp the symbol lookup mechanism\n\nTo complement the future changes in patterns we also want\nto allow the execution of patterns to be affected in a similar\nmanner so that symbol lookup is no longer as confined as it was.\n\nThis change adds in the following:\n\n- Symbol lookup by walking through an atoms contained scope/s.\n- Better error messaging when symbols are not found.\n- Adjusted & new tests (existing ones work).\n- Better logging of the symbol lookup mechanism (helpful\n  during debugging, although it is very verbose...)\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: Id921a4abd9bf2b7b5c5a762337f8e90e8f1fe194\n'}, {'number': 2, 'created': '2014-07-26 03:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dc8b0e6cb9d8631a9243659e06f044252cf8962b', 'message': 'Revamp the symbol lookup mechanism\n\nTo complement the future changes in patterns we also want\nto allow the execution of patterns to be affected in a similar\nmanner so that symbol lookup is no longer as confined as it was.\n\nThis change adds in the following:\n\n- Symbol lookup by walking through an atoms contained scope/s.\n- Better error messaging when symbols are not found.\n- Adjusted & new tests (existing ones work).\n- Better logging of the symbol lookup mechanism (helpful\n  during debugging, although it is very verbose...)\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: Id921a4abd9bf2b7b5c5a762337f8e90e8f1fe194\n'}, {'number': 3, 'created': '2014-09-08 20:04:44.000000000', 'files': ['taskflow/tests/unit/test_storage.py', 'taskflow/types/tree.py', 'taskflow/engines/action_engine/runtime.py', 'taskflow/tests/unit/action_engine/test_compile.py', 'taskflow/tests/unit/action_engine/test_runner.py', 'taskflow/patterns/graph_flow.py', 'taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/engines/action_engine/scopes.py', 'taskflow/engines/action_engine/compiler.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/engines/action_engine/retry_action.py', 'taskflow/tests/unit/test_action_engine_scoping.py', 'taskflow/utils/misc.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fa077c953fac48cf8fcb8ef4d178017b93d4ffce', 'message': 'Revamp the symbol lookup mechanism\n\nTo complement the future changes in patterns we also want\nto allow the execution of patterns to be affected in a similar\nmanner so that symbol lookup is no longer as confined as it was.\n\nThis change adds in the following:\n\n- Symbol lookup by walking through an atoms contained scope/s.\n- Better error messaging when symbols are not found.\n- Adjusted & new tests (existing ones work).\n- Better logging of the symbol lookup mechanism (helpful\n  during debugging, although it is very verbose...)\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: Id921a4abd9bf2b7b5c5a762337f8e90e8f1fe194\n'}]",0,109672,fa077c953fac48cf8fcb8ef4d178017b93d4ffce,14,3,3,1297,,,0,"Revamp the symbol lookup mechanism

To complement the future changes in patterns we also want
to allow the execution of patterns to be affected in a similar
manner so that symbol lookup is no longer as confined as it was.

This change adds in the following:

- Symbol lookup by walking through an atoms contained scope/s.
- Better error messaging when symbols are not found.
- Adjusted & new tests (existing ones work).
- Better logging of the symbol lookup mechanism (helpful
  during debugging, although it is very verbose...)

Part of blueprint taskflow-improved-scoping

Change-Id: Id921a4abd9bf2b7b5c5a762337f8e90e8f1fe194
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/72/109672/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/tests/unit/test_storage.py', 'taskflow/types/tree.py', 'taskflow/engines/action_engine/runtime.py', 'taskflow/patterns/graph_flow.py', 'taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/engines/action_engine/scopes.py', 'taskflow/engines/action_engine/compiler.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/engines/action_engine/retry_action.py', 'taskflow/tests/unit/test_action_engine_scoping.py', 'taskflow/utils/misc.py', 'taskflow/tests/unit/test_action_engine_compile.py']",13,c2cc5a00709c4677be96f9c005df69cff0d423b3,bp/taskflow-improved-scoping," compilation = compiler.PatternCompiler(task).compile() msg_regex = ""^Retry controller .* must only be used .*"" compiler.PatternCompiler(r).compile) msg_regex = '^Unknown item .* requested to flatten' compiler.PatternCompiler(42).compile) def test_empty(self): flo = lf.Flow(""test"") self.assertRaises(exc.Empty, compiler.PatternCompiler(flo).compile) compilation = compiler.PatternCompiler(flo).compile() compiler.PatternCompiler(flo).compile) compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compiler.PatternCompiler(flo).compile) compiler.PatternCompiler(flo).compile) compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile() compilation = compiler.PatternCompiler(flo).compile()"," compilation = compiler.PatternCompiler().compile(task) msg_regex = ""^Retry controller: .* must only be used .*"" compiler.PatternCompiler().compile, r) msg_regex = '^Unknown type requested to flatten' compiler.PatternCompiler().compile, 42) compilation = compiler.PatternCompiler().compile(flo) compiler.PatternCompiler().compile, flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compiler.PatternCompiler().compile, flo) compiler.PatternCompiler().compile, flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo) compilation = compiler.PatternCompiler().compile(flo)",731,227
openstack%2Ftaskflow~master~Ie149c05b3305c5bfff9d9f2c05e7e064c3a6d0c7,openstack/taskflow,master,Ie149c05b3305c5bfff9d9f2c05e7e064c3a6d0c7,Be smarter about required flow symbols,MERGED,2014-07-18 19:24:16.000000000,2014-10-18 18:24:49.000000000,2014-10-18 18:24:48.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-07-18 19:24:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a6850387d171ca88d7902cef01e6bd42be308411', 'message': 'Be much smarter about required symbols\n\nInstead of blindly assuming all the symbols that\nare provided automatically work for all flows even\nif the flow has ordering constraints we should set\nthe base class requires property to be abstract\nand provide flow specific properties that can do the\nright analysis to determine what the flows unsatisfied\nsymbol requirements are.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: Ie149c05b3305c5bfff9d9f2c05e7e064c3a6d0c7\n'}, {'number': 2, 'created': '2014-07-18 19:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e40f140c83a8b8754701e20041819825235f1744', 'message': 'Be smarter about required flow symbols\n\nInstead of blindly assuming all the symbols that\nare provided automatically work for all flows even\nif the flow has ordering constraints we should set\nthe base flow class requires property to be abstract\nand provide flow specific properties that can do the\nappropriate analysis to determine what the flows\nunsatisfied symbol requirements actually are.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: Ie149c05b3305c5bfff9d9f2c05e7e064c3a6d0c7\n'}, {'number': 3, 'created': '2014-07-18 19:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/24d75b6e2820e1e2fe06f3d8c2518ec84ae43530', 'message': 'Be smarter about required flow symbols\n\nInstead of blindly assuming all the symbols that\nare provided automatically work for all flows even\nif the flow has ordering constraints we should set\nthe base flow class requires property to be abstract\nand provide flow specific properties that can do the\nappropriate analysis to determine what the flows\nunsatisfied symbol requirements actually are.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: Ie149c05b3305c5bfff9d9f2c05e7e064c3a6d0c7\n'}, {'number': 4, 'created': '2014-09-08 19:14:51.000000000', 'files': ['taskflow/flow.py', 'taskflow/types/graph.py', 'taskflow/patterns/linear_flow.py', 'doc/source/inputs_and_outputs.rst', 'taskflow/patterns/unordered_flow.py', 'taskflow/patterns/graph_flow.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e68d72f66e387f5b9f9a543d8ac3000ef5cfbbdc', 'message': 'Be smarter about required flow symbols\n\nInstead of blindly assuming all the symbols that\nare provided automatically work for all flows even\nif the flow has ordering constraints we should set\nthe base flow class requires property to be abstract\nand provide flow specific properties that can do the\nappropriate analysis to determine what the flows\nunsatisfied symbol requirements actually are.\n\nPart of blueprint taskflow-improved-scoping\n\nChange-Id: Ie149c05b3305c5bfff9d9f2c05e7e064c3a6d0c7\n'}]",0,108137,e68d72f66e387f5b9f9a543d8ac3000ef5cfbbdc,23,3,4,1297,,,0,"Be smarter about required flow symbols

Instead of blindly assuming all the symbols that
are provided automatically work for all flows even
if the flow has ordering constraints we should set
the base flow class requires property to be abstract
and provide flow specific properties that can do the
appropriate analysis to determine what the flows
unsatisfied symbol requirements actually are.

Part of blueprint taskflow-improved-scoping

Change-Id: Ie149c05b3305c5bfff9d9f2c05e7e064c3a6d0c7
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/37/108137/4 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/flow.py', 'taskflow/patterns/linear_flow.py', 'taskflow/types/graph.py', 'doc/source/inputs_and_outputs.rst', 'taskflow/patterns/unordered_flow.py', 'taskflow/patterns/graph_flow.py']",6,a6850387d171ca88d7902cef01e6bd42be308411,bp/taskflow-improved-scoping, @property def requires(self): requires = set() retry_provides = set() if self._retry is not None: requires.update(self._retry.requires) retry_provides.update(self._retry.provides) g = self._get_subgraph() for item in g.nodes_iter(): item_requires = item.requires - retry_provides # Now scan predecessors to see if they provide what we want. if item_requires: for pred_item in g.bfs_predecessors_iter(item): item_requires = item_requires - pred_item.provides if not item_requires: break if item_requires: requires.update(item_requires) return frozenset(requires) ,,75,28
openstack%2Fheat~master~Icefada18b5a33112b425cd90d31d3a6a5f06188a,openstack/heat,master,Icefada18b5a33112b425cd90d31d3a6a5f06188a,Remove deprecated function i18n.install('heat'),MERGED,2014-07-29 03:16:40.000000000,2014-10-18 16:06:17.000000000,2014-10-13 12:20:46.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6498}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8537}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-07-29 03:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b29d31a473cf88239e4527c4cd05fd7fc93e4e3b', 'message': ""Remove deprecated function i18n.install('heat')\n\nSince i18n.install() is deprecated, remove it from heat codes and\nimport i18n._() to where it needed.\n\nblueprint oslo-i18n\nChange-Id: Icefada18b5a33112b425cd90d31d3a6a5f06188a\n""}, {'number': 2, 'created': '2014-08-06 02:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5def5c11005058236c58ed14959719fac28e4228', 'message': ""Remove deprecated function i18n.install('heat')\n\nSince i18n.install() is deprecated, remove it from heat codes and\nimport i18n._() to where it needed.\n\nblueprint oslo-i18n\nChange-Id: Icefada18b5a33112b425cd90d31d3a6a5f06188a\n""}, {'number': 3, 'created': '2014-08-06 03:07:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/97a200d109c2060f7a423ba528991575d9a4f652', 'message': ""Remove deprecated function i18n.install('heat')\n\nSince i18n.install() is deprecated, remove it from heat codes and\nimport i18n._() to where it needed.\n\nblueprint oslo-i18n\nChange-Id: Icefada18b5a33112b425cd90d31d3a6a5f06188a\n""}, {'number': 4, 'created': '2014-08-06 08:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/06644dc17ac4f8831536797862ddc9a928ec36c2', 'message': ""Remove deprecated function i18n.install('heat')\n\nSince i18n.install() is deprecated, remove it from heat codes and\nimport i18n._() to where it needed.\n\nblueprint oslo-i18n\nChange-Id: Icefada18b5a33112b425cd90d31d3a6a5f06188a\n""}, {'number': 5, 'created': '2014-08-08 08:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ad8c428fab7ef8f4ef49e38c254e32852f1cf55c', 'message': ""Remove deprecated function i18n.install('heat')\n\nSince i18n.install() is deprecated, remove it from heat codes and\nimport i18n._() to where it needed.\n\nblueprint oslo-i18n\nChange-Id: Icefada18b5a33112b425cd90d31d3a6a5f06188a\n""}, {'number': 6, 'created': '2014-08-15 15:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1ab5905e62967b149cfd6741d427faa4c8c6984b', 'message': ""Remove deprecated function i18n.install('heat')\n\nSince i18n.install() is deprecated, remove it from heat codes and\nimport i18n._() to where it needed.\n\nblueprint oslo-i18n\nChange-Id: Icefada18b5a33112b425cd90d31d3a6a5f06188a\n""}, {'number': 7, 'created': '2014-09-02 06:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8e22b462a11f7adfe7aa35615dd7ec521cd519fe', 'message': ""Remove deprecated function i18n.install('heat')\n\nSince i18n.install() is deprecated, remove it from heat codes and\nimport i18n._() to where it needed.\n\nblueprint oslo-i18n\nChange-Id: Icefada18b5a33112b425cd90d31d3a6a5f06188a\n""}, {'number': 8, 'created': '2014-09-19 03:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/89c4b0abbf017565a28c538f0ba6e81636c968d4', 'message': ""Remove deprecated function i18n.install('heat')\n\nSince i18n.install() is deprecated, remove it from heat codes and\nimport i18n._() to where it needed.\n\nblueprint oslo-i18n\nChange-Id: Icefada18b5a33112b425cd90d31d3a6a5f06188a\n""}, {'number': 9, 'created': '2014-09-19 04:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2bcc372a2259787148c2e4b83c8d71c881f9ff45', 'message': ""Remove deprecated function i18n.install('heat')\n\nSince i18n.install() is deprecated, remove it from heat codes and\nimport i18n._() to where it needed.\n\nblueprint oslo-i18n\nChange-Id: Icefada18b5a33112b425cd90d31d3a6a5f06188a\n""}, {'number': 10, 'created': '2014-09-22 02:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9463b4d9bec376fb336af33eb41cc8b8c3b6981b', 'message': ""Remove deprecated function i18n.install('heat')\n\nSince i18n.install() is deprecated, remove it from heat codes and\nimport i18n._() to where it needed.\n\nblueprint oslo-i18n\nChange-Id: Icefada18b5a33112b425cd90d31d3a6a5f06188a\n""}, {'number': 11, 'created': '2014-10-13 03:00:36.000000000', 'files': ['heat/engine/resources/openstack/scaling_policy.py', 'heat/common/short_id.py', 'heat/common/lifecycle_plugin_utils.py', 'heat/engine/properties.py', 'heat/db/sync.py', 'heat/api/openstack/v1/stacks.py', 'heat/engine/resources/template_resource.py', 'heat/openstack/common/config/generator.py', 'heat/engine/resources/cloud_watch.py', 'heat/engine/resources/neutron/network_gateway.py', 'heat/engine/resources/security_group.py', 'heat/tests/test_validate.py', 'heat/engine/resources/ceilometer/alarm.py', 'heat/engine/resources/volume.py', 'heat/engine/cfn/functions.py', 'heat/engine/clients/os/nova.py', 'heat/engine/resources/neutron/port.py', 'heat/engine/resources/swift.py', 'heat/engine/resources/neutron/firewall.py', 'contrib/extraroute/extraroute/resources/extraroute.py', 'heat/engine/resources/autoscaling.py', 'heat/engine/support.py', 'heat/engine/resources/network_interface.py', 'heat/common/param_utils.py', 'heat/engine/hot/parameters.py', 'heat/tests/test_provider_template.py', 'heat/api/cloudwatch/__init__.py', 'heat/cmd/manage.py', 'heat/engine/resources/wait_condition.py', 'heat/api/openstack/v1/actions.py', 'heat/engine/plugin_manager.py', 'heat/common/timeutils.py', 'contrib/heat_barbican/heat_barbican/resources/secret.py', 'heat/engine/resources/s3.py', 'heat/common/i18n.py', 'contrib/heat_zaqar/heat_zaqar/resources/queue.py', 'heat/tests/test_exception.py', 'heat/tests/test_function.py', 'heat/engine/parameters.py', 'heat/engine/resources/neutron/loadbalancer.py', 'heat/engine/resources/stack.py', 'heat/engine/resources/neutron/provider_net.py', 'tox.ini', 'heat/common/config.py', 'heat/engine/resources/software_config/software_deployment.py', 'heat/engine/resources/vpc.py', 'heat/engine/resources/software_config/cloud_config.py', 'heat/engine/resources/route_table.py', 'heat/common/wsgi.py', 'heat/engine/resources/aws/launch_config.py', 'heat/engine/resources/neutron/metering.py', 'heat/engine/constraints.py', 'heat/tests/test_neutron_loadbalancer.py', 'heat/common/template_format.py', 'heat/engine/resources/subnet.py', 'heat/engine/cfn/template.py', 'heat/common/auth_url.py', 'heat/__init__.py', 'heat/common/custom_backend_auth.py', 'heat/common/identifier.py', 'heat/tests/__init__.py', 'heat/api/openstack/v1/events.py', 'heat/engine/resources/software_config/software_component.py', 'heat/engine/resources/neutron/subnet.py', 'heat/engine/resources/neutron/security_group.py', 'heat/engine/resources/neutron/floatingip.py', 'heat/engine/template.py', 'heat/engine/resources/neutron/net.py', 'heat/common/environment_format.py', 'contrib/heat_zaqar/heat_zaqar/client.py', 'heat/engine/resources/neutron/vpnservice.py', 'contrib/rackspace/rackspace/resources/auto_scale.py', 'heat/engine/resources/aws/scaling_policy.py', 'contrib/heat_barbican/heat_barbican/resources/order.py', 'heat/engine/hot/functions.py', 'heat/tests/test_fault_middleware.py', 'heat/engine/resources/software_config/structured_config.py', 'heat/common/exception.py', 'heat/engine/attributes.py', 'heat/engine/resources/neutron/neutron.py', 'heat/engine/resources/user.py', 'heat/engine/resources/neutron/router.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/11c1b62052e8ffe3c1af320aaced645a19868dff', 'message': ""Remove deprecated function i18n.install('heat')\n\nSince i18n.install() is deprecated, remove it from heat codes and\nimport i18n._() to where it needed.\n\nblueprint oslo-i18n\nChange-Id: Icefada18b5a33112b425cd90d31d3a6a5f06188a\n""}]",3,110192,11c1b62052e8ffe3c1af320aaced645a19868dff,61,14,11,7404,,,0,"Remove deprecated function i18n.install('heat')

Since i18n.install() is deprecated, remove it from heat codes and
import i18n._() to where it needed.

blueprint oslo-i18n
Change-Id: Icefada18b5a33112b425cd90d31d3a6a5f06188a
",git fetch https://review.opendev.org/openstack/heat refs/changes/92/110192/9 && git format-patch -1 --stdout FETCH_HEAD,"['heat/common/short_id.py', 'heat/common/systemd.py', 'heat/engine/properties.py', 'heat/db/sync.py', 'heat/api/openstack/v1/stacks.py', 'heat/engine/resources/template_resource.py', 'heat/openstack/common/config/generator.py', 'heat/engine/resources/cloud_watch.py', 'heat/engine/resources/neutron/network_gateway.py', 'heat/engine/resources/security_group.py', 'heat/tests/test_validate.py', 'heat/engine/resources/ceilometer/alarm.py', 'heat/engine/resources/volume.py', 'heat/engine/cfn/functions.py', 'heat/engine/resources/neutron/port.py', 'heat/engine/resources/swift.py', 'heat/engine/resources/neutron/firewall.py', 'contrib/extraroute/extraroute/resources/extraroute.py', 'heat/engine/resources/autoscaling.py', 'heat/engine/support.py', 'heat/engine/resources/network_interface.py', 'heat/common/notify.py', 'heat/engine/hot/parameters.py', 'heat/tests/test_provider_template.py', 'heat/api/cloudwatch/__init__.py', 'heat/cmd/manage.py', 'heat/engine/resources/wait_condition.py', 'heat/api/openstack/v1/actions.py', 'heat/engine/plugin_manager.py', 'heat/common/timeutils.py', 'heat/engine/resources/s3.py', 'heat/tests/test_exception.py', 'heat/tests/test_function.py', 'heat/engine/parameters.py', 'heat/engine/resources/neutron/loadbalancer.py', 'heat/engine/resources/stack.py', 'contrib/barbican/barbican/resources/secret.py', 'heat/engine/resources/neutron/provider_net.py', 'heat/common/config.py', 'heat/engine/resources/software_config/software_deployment.py', 'heat/engine/resources/vpc.py', 'heat/engine/resources/software_config/cloud_config.py', 'heat/engine/resources/route_table.py', 'heat/engine/resources/neutron/metering.py', 'heat/engine/constraints.py', 'heat/tests/test_neutron_loadbalancer.py', 'heat/engine/resources/subnet.py', 'heat/engine/cfn/template.py', 'heat/common/auth_url.py', 'heat/__init__.py', 'heat/common/identifier.py', 'heat/tests/__init__.py', 'heat/api/openstack/v1/events.py', 'heat/engine/resources/neutron/subnet.py', 'contrib/marconi/marconi/resources/queue.py', 'heat/engine/resources/neutron/security_group.py', 'heat/engine/resources/neutron/floatingip.py', 'heat/engine/template.py', 'heat/engine/resources/neutron/net.py', 'heat/common/environment_format.py', 'contrib/barbican/barbican/resources/order.py', 'heat/engine/resources/neutron/vpnservice.py', 'contrib/rackspace/rackspace/resources/auto_scale.py', 'heat/engine/hot/functions.py', 'contrib/marconi/marconi/clients.py', 'heat/engine/resources/software_config/structured_config.py', 'heat/engine/attributes.py', 'heat/engine/resources/neutron/neutron.py', 'heat/engine/resources/user.py', 'heat/engine/resources/neutron/router.py']",70,b29d31a473cf88239e4527c4cd05fd7fc93e4e3b,bp/oslo-i18n,from heat.common.i18n import _,,68,20
openstack%2Fnova~master~Ied08ceced643093d6f56e546b600400647cbb587,openstack/nova,master,Ied08ceced643093d6f56e546b600400647cbb587,Fixes Hyper-V COM initializazion race condition,ABANDONED,2014-10-13 23:43:48.000000000,2014-10-18 14:31:13.000000000,,"[{'_account_id': 3}, {'_account_id': 3185}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10635}]","[{'number': 1, 'created': '2014-10-13 23:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a5e95e349ed27db3179e4c848172dc86db42f5dd', 'message': ""Fixes Hyper-V COM initializazion race condition\n\nThe Nova Hyper-V driver fails occasionally with a x_wmi_uninitialised_thread\nexception due to lack of initialization of the COM library.\n\nSince it's not possible to know in advance which thread is assigned to the functions\nperforming COM calls, this patch adds a decorator to each relevant public method\nin any Hyper-V *utils module, wrapping calls in CoInitializeEx / ConUninitialize pairs.\n\nFor details:\nhttp://msdn.microsoft.com/en-us/library/windows/desktop/ms695279(v=vs.85).aspx\n\nChange-Id: Ied08ceced643093d6f56e546b600400647cbb587\nCloses-Bug: #1298034\n""}, {'number': 2, 'created': '2014-10-13 23:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bac10beed3bc780eacdae10502ffc55a31da6a7c', 'message': ""Fixes Hyper-V COM initializazion race condition\n\nThe Nova Hyper-V driver fails occasionally with a x_wmi_uninitialised_thread\nexception due to lack of initialization of the COM library.\n\nSince it's not possible to know in advance which thread is assigned to the functions\nperforming COM calls, this patch adds a decorator to each relevant public method\nin any Hyper-V *utils module, wrapping calls in CoInitializeEx / ConUninitialize pairs.\n\nFor details:\nhttp://msdn.microsoft.com/en-us/library/windows/desktop/ms695279(v=vs.85).aspx\n\nChange-Id: Ied08ceced643093d6f56e546b600400647cbb587\nCloses-Bug: #1298034\n""}, {'number': 3, 'created': '2014-10-14 00:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e6a311dc451f22800b6e5d56511f6f9656fbe48', 'message': ""Fixes Hyper-V COM initializazion race condition\n\nThe Nova Hyper-V driver fails occasionally with a x_wmi_uninitialised_thread\nexception due to lack of initialization of the COM library.\n\nSince it's not possible to know in advance which thread is assigned to the functions\nperforming COM calls, this patch adds a decorator to each relevant public method\nin any Hyper-V *utils module, wrapping calls in CoInitializeEx / ConUninitialize pairs.\n\nFor details:\nhttp://msdn.microsoft.com/en-us/library/windows/desktop/ms695279(v=vs.85).aspx\n\nChange-Id: Ied08ceced643093d6f56e546b600400647cbb587\nCloses-Bug: #1298034\n""}, {'number': 4, 'created': '2014-10-14 08:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5dd89b0bda8e99ff1a85b9a28817ea1c5bd60dbd', 'message': ""Fixes Hyper-V COM initializazion race condition\n\nThe Nova Hyper-V driver fails occasionally with a x_wmi_uninitialised_thread\nexception due to lack of initialization of the COM library.\n\nSince it's not possible to know in advance which thread is assigned to the functions\nperforming COM calls, this patch adds a decorator to each relevant public method\nin any Hyper-V *utils module, wrapping calls in CoInitializeEx / ConUninitialize pairs.\n\nFor details:\nhttp://msdn.microsoft.com/en-us/library/windows/desktop/ms695279(v=vs.85).aspx\n\nChange-Id: Ied08ceced643093d6f56e546b600400647cbb587\nCloses-Bug: #1298034\n""}, {'number': 5, 'created': '2014-10-14 09:08:54.000000000', 'files': ['nova/virt/hyperv/vhdutilsv2.py', 'nova/virt/hyperv/volumeutilsv2.py', 'nova/virt/hyperv/livemigrationutils.py', 'nova/virt/hyperv/comutils.py', 'nova/virt/hyperv/hostutils.py', 'nova/virt/hyperv/vhdutils.py', 'nova/virt/hyperv/vmutils.py', 'nova/virt/hyperv/networkutils.py', 'nova/virt/hyperv/networkutilsv2.py', 'nova/virt/hyperv/rdpconsoleutilsv2.py', 'nova/virt/hyperv/volumeutils.py', 'nova/virt/hyperv/vmutilsv2.py', 'nova/virt/hyperv/basevolumeutils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2ae305e445725a74ba67e77e741a40e36fbaca9d', 'message': ""Fixes Hyper-V COM initializazion race condition\n\nThe Nova Hyper-V driver fails occasionally with a x_wmi_uninitialised_thread\nexception due to lack of initialization of the COM library.\n\nSince it's not possible to know in advance which thread is assigned to the functions\nperforming COM calls, this patch adds a decorator to each relevant public method\nin any Hyper-V *utils module, wrapping calls in CoInitializeEx / ConUninitialize pairs.\n\nFor details:\nhttp://msdn.microsoft.com/en-us/library/windows/desktop/ms695279(v=vs.85).aspx\n\nChange-Id: Ied08ceced643093d6f56e546b600400647cbb587\nCloses-Bug: #1298034\n""}]",0,128136,2ae305e445725a74ba67e77e741a40e36fbaca9d,23,7,5,3185,,,0,"Fixes Hyper-V COM initializazion race condition

The Nova Hyper-V driver fails occasionally with a x_wmi_uninitialised_thread
exception due to lack of initialization of the COM library.

Since it's not possible to know in advance which thread is assigned to the functions
performing COM calls, this patch adds a decorator to each relevant public method
in any Hyper-V *utils module, wrapping calls in CoInitializeEx / ConUninitialize pairs.

For details:
http://msdn.microsoft.com/en-us/library/windows/desktop/ms695279(v=vs.85).aspx

Change-Id: Ied08ceced643093d6f56e546b600400647cbb587
Closes-Bug: #1298034
",git fetch https://review.opendev.org/openstack/nova refs/changes/36/128136/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/vhdutilsv2.py', 'nova/virt/hyperv/volumeutilsv2.py', 'nova/virt/hyperv/livemigrationutils.py', 'nova/virt/hyperv/hostutils.py', 'nova/virt/hyperv/vhdutils.py', 'nova/virt/hyperv/vmutils.py', 'nova/virt/hyperv/networkutils.py', 'nova/virt/hyperv/networkutilsv2.py', 'nova/virt/hyperv/rdpconsoleutilsv2.py', 'nova/virt/hyperv/volumeutils.py', 'nova/virt/hyperv/vmutilsv2.py', 'nova/virt/hyperv/basevolumeutils.py']",12,a5e95e349ed27db3179e4c848172dc86db42f5dd,bug/1298034,from nova.virt.hyperv import comutils comutils.coinitialize comutils.coinitialize comutils.coinitialize comutils.coinitialize comutils.coinitialize,,93,0
openstack%2Fcinder~master~I4c598c240b9290c81bd8001e5a0720c8c329aeb9,openstack/cinder,master,I4c598c240b9290c81bd8001e5a0720c8c329aeb9,Export cinder volumes only if the status is 'in-use',MERGED,2014-10-14 20:14:27.000000000,2014-10-18 13:41:57.000000000,2014-10-14 22:17:07.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 6491}, {'_account_id': 9176}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12369}]","[{'number': 1, 'created': '2014-10-14 20:14:27.000000000', 'files': ['cinder/volume/manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e2f28b967910625432be0eab6a851adf53ac58ea', 'message': ""Export cinder volumes only if the status is 'in-use'\n\nCurrently, cinder volumes are exported both 'in-use' and 'available'\nafter restarting cinder-volume service.\nThis behavior was introduced following commit.\n\n  commit ffefe18334a9456250e1b6ff88b7b47fb366f374\n  Author: Zhiteng Huang <zhithuang@ebaysf.com>\n  Date: Sat Aug 23 18:32:57 2014 +0000\n\nIf the volumes are attached to nova instances, they should be exported\nvia tgtd after restarting cinder-volume.\nBut the volumes which are not attached to instances must not be exported\nbecause everyone can connect these volumes.\n\nThis patch changes volume export behavior that exports a volume only if\nthe volume status is 'in-use'.\n\nChange-Id: I4c598c240b9290c81bd8001e5a0720c8c329aeb9\nSigned-off-by: Mitsuhiro Tanino <mitsuhiro.tanino@hds.com>\nCloses-bug: #1381106\n""}]",0,128437,e2f28b967910625432be0eab6a851adf53ac58ea,10,7,1,10115,,,0,"Export cinder volumes only if the status is 'in-use'

Currently, cinder volumes are exported both 'in-use' and 'available'
after restarting cinder-volume service.
This behavior was introduced following commit.

  commit ffefe18334a9456250e1b6ff88b7b47fb366f374
  Author: Zhiteng Huang <zhithuang@ebaysf.com>
  Date: Sat Aug 23 18:32:57 2014 +0000

If the volumes are attached to nova instances, they should be exported
via tgtd after restarting cinder-volume.
But the volumes which are not attached to instances must not be exported
because everyone can connect these volumes.

This patch changes volume export behavior that exports a volume only if
the volume status is 'in-use'.

Change-Id: I4c598c240b9290c81bd8001e5a0720c8c329aeb9
Signed-off-by: Mitsuhiro Tanino <mitsuhiro.tanino@hds.com>
Closes-bug: #1381106
",git fetch https://review.opendev.org/openstack/cinder refs/changes/37/128437/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/manager.py'],1,e2f28b967910625432be0eab6a851adf53ac58ea,bug/1381106," if volume['status'] in ['in-use']: self.driver.ensure_export(ctxt, volume)"," self.driver.ensure_export(ctxt, volume)",2,1
openstack%2Fzaqar~master~I63a79ddc52b5a397bc1c5c5c3ba2a98c4cb0d5f0,openstack/zaqar,master,I63a79ddc52b5a397bc1c5c5c3ba2a98c4cb0d5f0,Sync the zaqar.conf.sample file,MERGED,2014-10-14 02:43:01.000000000,2014-10-18 13:20:08.000000000,2014-10-18 13:20:08.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 10634}]","[{'number': 1, 'created': '2014-10-14 02:43:01.000000000', 'files': ['etc/zaqar.conf.sample'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/90dd98da01326d5285aa3cad9e456a4f90e27c68', 'message': 'Sync the zaqar.conf.sample file\n\nChange-Id: I63a79ddc52b5a397bc1c5c5c3ba2a98c4cb0d5f0\n'}]",0,128158,90dd98da01326d5285aa3cad9e456a4f90e27c68,8,4,1,7488,,,0,"Sync the zaqar.conf.sample file

Change-Id: I63a79ddc52b5a397bc1c5c5c3ba2a98c4cb0d5f0
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/58/128158/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/zaqar.conf.sample'],1,90dd98da01326d5285aa3cad9e456a4f90e27c68,sync_conf_sample,"# Activate privileged endpoints. (boolean value) #admin_mode=false # Enable pooling across multiple storage backends. If pooling # is enabled, the storage driver configuration is used to # determine where the catalogue/control plane data is kept. # (boolean value)# Disable all reliability constrains. (boolean value) #unreliable=<None>[drivers:storage:redis] # # Options defined in zaqar.queues.storage.redis # # Redis connection URI, taking one of three forms. For a # direct connection to a Redis server, use the form # ""redis://host[:port][?options]"", where port defaults to 6379 # if not specified. For an HA master-slave Redis cluster using # Redis Sentinel, use the form ""redis://host1[:port1][,host2[: # port2],...,hostN[:portN]][?options]"", where each host # specified corresponds to an instance of redis-sentinel. In # this form, the name of the Redis master used in the Sentinel # configuration must be included in the query string as # ""master=<name>"". Finally, to connect to a local instance of # Redis over a unix socket, you may use the form # ""redis:/path/to/redis.sock[?options]"". In all forms, the # ""socket_timeout"" option may be specified in the query # string. Its value is given in seconds. If not provided, # ""socket_timeout"" defaults to 0.1 seconds. (string value) #uri=redis://127.0.0.1:6379 # Maximum number of times to retry an operation that failed # due to a redis node failover. (integer value) #max_reconnect_attempts=10 # Base sleep interval between attempts to reconnect after a # redis node failover. (floating point value) #reconnect_sleep=1.0 # driver's controller methods. (list value)# driver's controller methods. (list value)# driver's controller methods. (list value)# Deprecated group/name - [DEFAULT]/max_message_size# # Options defined in zaqar.queues.transport.base # # (integer value) #default_message_ttl=3600 # (integer value) #default_claim_ttl=300 # (integer value) #default_claim_grace=60 ","# ('Enable pooling across multiple storage backends. ', 'If # pooling is enabled, the storage driver ', 'configuration is # used to determine where the ', 'catalogue/control plane data # is kept.') (boolean value)# Activate endpoints to manage pool registry. (boolean value) #admin_mode=false[drivers:storage:redis] # # Options defined in zaqar.queues.storage.redis # # Redis Server URI. Socket file based connectors are supported. # Example for socket file connector: redis:/tmp/redis.sock' #uri=<None> # Maximum number of times to retry an operation that failed # due to a primary node failover. (integer value) #max_reconnect_attempts=10 # Base sleep interval between attempts to reconnect after a # primary node failover. The actual sleep time increases # exponentially (power of 2) each time the operation is # retried. (floating point value) #reconnect_sleep=0.02 # driver's controller methods, which will always be appended # to this pipeline. (list value)# driver's controller methods, which will always be appended # to this pipeline. (list value)# driver's controller methods, which will always be appended # to this pipeline. (list value)# Options defined in zaqar.queues.transport.base # # (integer value) #default_message_ttl=3600 # (integer value) #default_claim_ttl=300 # (integer value) #default_claim_grace=60 #",59,46
openstack%2Ftempest~master~Id618aeeb85e3d4767ed07b4d29b908274eba76df,openstack/tempest,master,Id618aeeb85e3d4767ed07b4d29b908274eba76df,Add cleanup to test_verify_multiple_nics_order,MERGED,2014-10-17 15:00:15.000000000,2014-10-18 12:08:22.000000000,2014-10-18 12:08:21.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 6873}, {'_account_id': 10016}, {'_account_id': 10385}, {'_account_id': 10723}]","[{'number': 1, 'created': '2014-10-17 15:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6827fa1e013040164ac7d12c45e444995a872440', 'message': ""Add cleanup to test_verify_multiple_nics_order\n\nThis test doesn't cleanup the networks and subnets that it created. Following\nTempest tests in non-isolated environments are consequently failing because\nmultiple networks are found. This change deleted those networks and subnets.\n\nChange-Id: Id618aeeb85e3d4767ed07b4d29b908274eba76df\n""}, {'number': 2, 'created': '2014-10-17 15:31:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c62105db963e78ed1d546a978b47d652ae60b7be', 'message': ""Add cleanup to test_verify_multiple_nics_order\n\nThis test doesn't cleanup the networks and subnets that it created. Following\nTempest tests in non-isolated environments are consequently failing because\nmultiple networks are found. This change deleted those networks and subnets.\n\nRelated-Bug: #1329065\n\nChange-Id: Id618aeeb85e3d4767ed07b4d29b908274eba76df\n""}, {'number': 3, 'created': '2014-10-17 15:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6e8a57dd139c11cc19fcab5dd24c554e3c79fbe1', 'message': ""Add cleanup to test_verify_multiple_nics_order\n\nThis test doesn't cleanup the networks and subnets that it created. Following\nTempest tests in non-isolated environments are consequently failing because\nmultiple networks are found. This change deleted those networks and subnets.\n\nRelated-Bug: #1329065\n\nChange-Id: Id618aeeb85e3d4767ed07b4d29b908274eba76df\n""}, {'number': 4, 'created': '2014-10-17 18:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/68498e900cf3d1f59b4364a6ac4cc071ee31b5c9', 'message': ""Add cleanup to test_verify_multiple_nics_order\n\nThis test doesn't cleanup the networks and subnets that it created. Following\nTempest tests in non-isolated environments are consequently failing because\nmultiple networks are found. This change deleted those networks and subnets.\n\nRelated-Bug: #1329065\n\nChange-Id: Id618aeeb85e3d4767ed07b4d29b908274eba76df\n""}, {'number': 5, 'created': '2014-10-17 20:29:06.000000000', 'files': ['tempest/api/compute/servers/test_create_server.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e59f0fffb28a1b98476e3cc7dfaaed33f469711b', 'message': ""Add cleanup to test_verify_multiple_nics_order\n\nThis test doesn't cleanup the networks and subnets that it created. Following\nTempest tests in non-isolated environments are consequently failing because\nmultiple networks are found. This change deleted those networks and subnets.\n\nRelated-Bug: #1329065\n\nChange-Id: Id618aeeb85e3d4767ed07b4d29b908274eba76df\n""}]",11,129291,e59f0fffb28a1b98476e3cc7dfaaed33f469711b,46,8,5,10016,,,0,"Add cleanup to test_verify_multiple_nics_order

This test doesn't cleanup the networks and subnets that it created. Following
Tempest tests in non-isolated environments are consequently failing because
multiple networks are found. This change deleted those networks and subnets.

Related-Bug: #1329065

Change-Id: Id618aeeb85e3d4767ed07b4d29b908274eba76df
",git fetch https://review.opendev.org/openstack/tempest refs/changes/91/129291/5 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_create_server.py'],1,6827fa1e013040164ac7d12c45e444995a872440,bug/1329065, # Cleanup networks and subnets def cleanup(): self.client.delete_server(server_multi_nics['id']) self.client.wait_for_server_termination(server_multi_nics['id']) self.network_client.delete_subnet(subnet1['subnet']['id']) self.network_client.delete_subnet(subnet2['subnet']['id']) self.network_client.delete_network(net1['network']['id']) self.network_client.delete_network(net2['network']['id']) self.addCleanup(cleanup) ,,11,0
openstack%2Fhorizon~master~Ib65eee0fa2c8b6535e1e391579fcd1bdb0f83bc1,openstack/horizon,master,Ib65eee0fa2c8b6535e1e391579fcd1bdb0f83bc1,Stubout cinder.tenant_absolute_limits in cinder test,MERGED,2014-10-10 20:04:19.000000000,2014-10-18 12:04:41.000000000,2014-10-18 12:04:40.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 7213}, {'_account_id': 9622}, {'_account_id': 9981}]","[{'number': 1, 'created': '2014-10-10 20:04:19.000000000', 'files': ['openstack_dashboard/dashboards/project/volumes/volumes/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1828eecc855fc86980b27796c28f7ddbbcdccfef', 'message': 'Stubout cinder.tenant_absolute_limits in cinder test\n\nTo render dropdown actions to detail page, allowed() method\nin the volume table is called, so a method called in allowed()\nneeds to be stubout.\n\nChange-Id: Ib65eee0fa2c8b6535e1e391579fcd1bdb0f83bc1\nCloses-Bug: #1378907\n'}]",4,127642,1828eecc855fc86980b27796c28f7ddbbcdccfef,19,7,1,841,,,0,"Stubout cinder.tenant_absolute_limits in cinder test

To render dropdown actions to detail page, allowed() method
in the volume table is called, so a method called in allowed()
needs to be stubout.

Change-Id: Ib65eee0fa2c8b6535e1e391579fcd1bdb0f83bc1
Closes-Bug: #1378907
",git fetch https://review.opendev.org/openstack/horizon refs/changes/42/127642/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/volumes/volumes/tests.py'],1,1828eecc855fc86980b27796c28f7ddbbcdccfef,bug/1378907," @test.create_stubs({cinder: ('volume_get', 'tenant_absolute_limits'), cinder.tenant_absolute_limits(IsA(http.HttpRequest))\ .AndReturn(self.cinder_limits['absolute'])"," @test.create_stubs({cinder: ('volume_get',),",3,1
openstack%2Fsahara~master~Id474bcc06cf0f438c3b0571e8bf329cbd30e25d3,openstack/sahara,master,Id474bcc06cf0f438c3b0571e8bf329cbd30e25d3,Imported Translations from Transifex,MERGED,2014-10-17 06:14:17.000000000,2014-10-18 11:32:20.000000000,2014-10-18 11:32:19.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-10-17 06:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e470678e82e6b7da787c5413ac3d131a02cd9279', 'message': 'Imported Translations from Transifex\n\nChange-Id: Id474bcc06cf0f438c3b0571e8bf329cbd30e25d3\n'}, {'number': 2, 'created': '2014-10-18 06:13:33.000000000', 'files': ['sahara/locale/sahara-log-error.pot', 'sahara/locale/sahara.pot', 'sahara/locale/sahara-log-info.pot', 'sahara/locale/fr/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-error.po'], 'web_link': 'https://opendev.org/openstack/sahara/commit/5a4cd9d6ab6cd0e7ab46fe3f09c858c26ff85b8e', 'message': 'Imported Translations from Transifex\n\nChange-Id: Id474bcc06cf0f438c3b0571e8bf329cbd30e25d3\n'}]",0,129142,5a4cd9d6ab6cd0e7ab46fe3f09c858c26ff85b8e,20,5,2,11131,,,0,"Imported Translations from Transifex

Change-Id: Id474bcc06cf0f438c3b0571e8bf329cbd30e25d3
",git fetch https://review.opendev.org/openstack/sahara refs/changes/42/129142/2 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/locale/sahara-log-error.pot', 'sahara/locale/sahara.pot', 'sahara/locale/sahara-log-info.pot', 'sahara/locale/fr/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-error.po']",5,e470678e82e6b7da787c5413ac3d131a02cd9279,transifex/translations,"""POT-Creation-Date: 2014-10-17 06:14+0000\n""#: sahara/context.py:156#: sahara/service/ops.py:136#: sahara/service/ops.py:155#: sahara/service/volumes.py:160#: sahara/service/volumes.py:179#: sahara/service/volumes.py:204#: sahara/service/edp/job_manager.py:123#: sahara/service/edp/job_manager.py:156#: sahara/service/edp/job_manager.py:196#: sahara/utils/ssh_remote.py:269","""POT-Creation-Date: 2014-09-16 06:10+0000\n""#: sahara/context.py:131#: sahara/openstack/common/excutils.py:76 #, python-format msgid ""Original exception being dropped: %s"" msgstr ""Original exception being dropped: %s"" #: sahara/openstack/common/excutils.py:105 #, python-format msgid ""Unexpected exception occurred %d time(s)... retrying."" msgstr ""Unexpected exception occurred %d time(s)... retrying."" #: sahara/service/ops.py:120#: sahara/service/ops.py:139#: sahara/service/volumes.py:148#: sahara/service/volumes.py:167#: sahara/service/volumes.py:192#: sahara/service/edp/job_manager.py:121#: sahara/service/edp/job_manager.py:143#: sahara/service/edp/job_manager.py:169#: sahara/utils/ssh_remote.py:265",236,424
openstack%2Fhorizon~master~I0d2eedad44b87efd58f3816b27780203d9acbe1d,openstack/horizon,master,I0d2eedad44b87efd58f3816b27780203d9acbe1d,Imported Translations from Transifex,MERGED,2014-10-18 06:07:31.000000000,2014-10-18 11:04:22.000000000,2014-10-18 11:04:21.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6914}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-10-18 06:07:31.000000000', 'files': ['horizon/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'horizon/locale/es/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/bb7dd40a4b730df172e9822b98a38529d8ceed6b', 'message': 'Imported Translations from Transifex\n\nChange-Id: I0d2eedad44b87efd58f3816b27780203d9acbe1d\n'}]",0,129422,bb7dd40a4b730df172e9822b98a38529d8ceed6b,9,4,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I0d2eedad44b87efd58f3816b27780203d9acbe1d
",git fetch https://review.opendev.org/openstack/horizon refs/changes/22/129422/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'horizon/locale/es/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",16,bb7dd40a4b730df172e9822b98a38529d8ceed6b,transifex/translations,"""POT-Creation-Date: 2014-10-17 15:04-0500\n""#: api/ceilometer.py:745#: api/ceilometer.py:921#: api/ceilometer.py:925#: api/ceilometer.py:930#: api/ceilometer.py:934#: api/ceilometer.py:938#: api/ceilometer.py:942#: api/ceilometer.py:946#: api/ceilometer.py:950#: api/ceilometer.py:954#: api/ceilometer.py:958#: api/ceilometer.py:962#: api/ceilometer.py:966#: api/ceilometer.py:971#: api/ceilometer.py:976#: api/ceilometer.py:981#: api/ceilometer.py:986#: api/ceilometer.py:998#: api/ceilometer.py:1018#: api/ceilometer.py:1022#: api/ceilometer.py:1026#: api/ceilometer.py:1030#: api/ceilometer.py:1034#: api/ceilometer.py:1038#: api/ceilometer.py:1042#: api/ceilometer.py:1046#: api/ceilometer.py:1050#: api/ceilometer.py:1054#: api/ceilometer.py:1058#: api/ceilometer.py:1062#: api/ceilometer.py:1066#: api/ceilometer.py:1070#: api/ceilometer.py:1074#: api/ceilometer.py:1091#: api/ceilometer.py:1095#: api/ceilometer.py:1099#: api/ceilometer.py:1103#: api/ceilometer.py:1107#: api/ceilometer.py:1111#: api/ceilometer.py:1115#: api/ceilometer.py:1132#: api/ceilometer.py:1136#: api/ceilometer.py:1153#: api/ceilometer.py:1157#: api/ceilometer.py:1161#: api/ceilometer.py:1165#: api/ceilometer.py:1169#: api/ceilometer.py:1173#: api/ceilometer.py:1190#: api/ceilometer.py:1194#: api/cinder.py:210#: api/keystone.py:325#: api/keystone.py:350#: api/keystone.py:362 api/keystone.py:378#: api/neutron.py:849#: api/neutron.py:886#: api/neutron.py:1025#: api/neutron.py:1043#: api/neutron.py:1058#: api/nova.py:750#: api/nova.py:755#: api/swift.py:203#: dashboards/identity/projects/workflows.py:141#: dashboards/identity/projects/workflows.py:528#: dashboards/identity/projects/workflows.py:147 #: dashboards/identity/projects/workflows.py:507#: dashboards/identity/projects/workflows.py:145#: dashboards/identity/projects/workflows.py:135#: dashboards/identity/projects/workflows.py:195 #: dashboards/identity/projects/workflows.py:293#: dashboards/identity/projects/workflows.py:265#: dashboards/identity/projects/workflows.py:363#: dashboards/identity/projects/workflows.py:254#: dashboards/identity/projects/workflows.py:256#: dashboards/identity/projects/workflows.py:257#: dashboards/identity/projects/workflows.py:279#: dashboards/identity/projects/workflows.py:352#: dashboards/identity/projects/workflows.py:354#: dashboards/identity/projects/workflows.py:355#: dashboards/identity/projects/workflows.py:374 #: dashboards/identity/projects/workflows.py:375#: dashboards/identity/projects/workflows.py:527#: dashboards/identity/projects/workflows.py:97#: dashboards/identity/projects/workflows.py:102#: dashboards/identity/projects/workflows.py:109 #: dashboards/identity/projects/workflows.py:116 msgid ""Quota"" msgstr ""Quota"" #: dashboards/identity/projects/workflows.py:111 #: dashboards/identity/projects/workflows.py:118 msgid ""Set maximum quotas for the project."" msgstr ""Set maximum quotas for the project."" #: dashboards/identity/projects/workflows.py:138#: dashboards/identity/projects/workflows.py:162 #: dashboards/identity/projects/workflows.py:510#: dashboards/identity/projects/workflows.py:163#: dashboards/identity/projects/workflows.py:181#: dashboards/identity/projects/workflows.py:248 #: dashboards/identity/projects/workflows.py:255#: dashboards/identity/projects/workflows.py:346 #: dashboards/identity/projects/workflows.py:353#: dashboards/identity/projects/workflows.py:376#: dashboards/identity/projects/workflows.py:377#: dashboards/identity/projects/workflows.py:439#: dashboards/identity/projects/workflows.py:443#: dashboards/identity/projects/workflows.py:474#: dashboards/identity/projects/workflows.py:502#: dashboards/identity/projects/workflows.py:512#: dashboards/identity/projects/workflows.py:529#: dashboards/identity/projects/workflows.py:530#: dashboards/identity/projects/workflows.py:625#: dashboards/identity/projects/workflows.py:660#: dashboards/identity/projects/workflows.py:664#: dashboards/identity/projects/workflows.py:737#: dashboards/identity/projects/workflows.py:770#: dashboards/project/routers/forms.py:132#: dashboards/project/routers/forms.py:137#: usage/base.py:186 usage/quotas.py:354#: usage/quotas.py:340","""POT-Creation-Date: 2014-10-16 22:36-0500\n""#: api/ceilometer.py:747#: api/ceilometer.py:923#: api/ceilometer.py:927#: api/ceilometer.py:932#: api/ceilometer.py:936#: api/ceilometer.py:940#: api/ceilometer.py:944#: api/ceilometer.py:948#: api/ceilometer.py:952#: api/ceilometer.py:956#: api/ceilometer.py:960#: api/ceilometer.py:964#: api/ceilometer.py:968#: api/ceilometer.py:973#: api/ceilometer.py:978#: api/ceilometer.py:983#: api/ceilometer.py:988#: api/ceilometer.py:1000#: api/ceilometer.py:1020#: api/ceilometer.py:1024#: api/ceilometer.py:1028#: api/ceilometer.py:1032#: api/ceilometer.py:1036#: api/ceilometer.py:1040#: api/ceilometer.py:1044#: api/ceilometer.py:1048#: api/ceilometer.py:1052#: api/ceilometer.py:1056#: api/ceilometer.py:1060#: api/ceilometer.py:1064#: api/ceilometer.py:1068#: api/ceilometer.py:1072#: api/ceilometer.py:1076#: api/ceilometer.py:1093#: api/ceilometer.py:1097#: api/ceilometer.py:1101#: api/ceilometer.py:1105#: api/ceilometer.py:1109#: api/ceilometer.py:1113#: api/ceilometer.py:1117#: api/ceilometer.py:1134#: api/ceilometer.py:1138#: api/ceilometer.py:1155#: api/ceilometer.py:1159#: api/ceilometer.py:1163#: api/ceilometer.py:1167#: api/ceilometer.py:1171#: api/ceilometer.py:1175#: api/ceilometer.py:1192#: api/ceilometer.py:1196#: api/cinder.py:212#: api/keystone.py:326#: api/keystone.py:351#: api/keystone.py:363 api/keystone.py:379#: api/neutron.py:853#: api/neutron.py:890#: api/neutron.py:1029#: api/neutron.py:1047#: api/neutron.py:1062#: api/nova.py:752#: api/nova.py:757#: api/swift.py:205#: dashboards/identity/projects/workflows.py:125#: dashboards/identity/projects/workflows.py:512#: dashboards/identity/projects/workflows.py:131 #: dashboards/identity/projects/workflows.py:491#: dashboards/identity/projects/workflows.py:129#: dashboards/identity/projects/workflows.py:119#: dashboards/identity/projects/workflows.py:179 #: dashboards/identity/projects/workflows.py:277#: dashboards/identity/projects/workflows.py:249#: dashboards/identity/projects/workflows.py:347#: dashboards/identity/projects/workflows.py:238#: dashboards/identity/projects/workflows.py:240#: dashboards/identity/projects/workflows.py:241#: dashboards/identity/projects/workflows.py:263#: dashboards/identity/projects/workflows.py:336#: dashboards/identity/projects/workflows.py:338#: dashboards/identity/projects/workflows.py:339#: dashboards/identity/projects/workflows.py:358 #: dashboards/identity/projects/workflows.py:359#: dashboards/identity/projects/workflows.py:511#: dashboards/identity/projects/workflows.py:87 msgid ""Quota"" msgstr ""Quota"" #: dashboards/identity/projects/workflows.py:89 msgid ""Set maximum quotas for the project."" msgstr ""Set maximum quotas for the project."" #: dashboards/identity/projects/workflows.py:99#: dashboards/identity/projects/workflows.py:104#: dashboards/identity/projects/workflows.py:122#: dashboards/identity/projects/workflows.py:146 #: dashboards/identity/projects/workflows.py:494#: dashboards/identity/projects/workflows.py:147#: dashboards/identity/projects/workflows.py:165#: dashboards/identity/projects/workflows.py:232 #: dashboards/identity/projects/workflows.py:239#: dashboards/identity/projects/workflows.py:330 #: dashboards/identity/projects/workflows.py:337#: dashboards/identity/projects/workflows.py:360#: dashboards/identity/projects/workflows.py:361#: dashboards/identity/projects/workflows.py:423#: dashboards/identity/projects/workflows.py:427#: dashboards/identity/projects/workflows.py:458#: dashboards/identity/projects/workflows.py:486#: dashboards/identity/projects/workflows.py:496#: dashboards/identity/projects/workflows.py:513#: dashboards/identity/projects/workflows.py:514#: dashboards/identity/projects/workflows.py:609#: dashboards/identity/projects/workflows.py:644#: dashboards/identity/projects/workflows.py:648#: dashboards/identity/projects/workflows.py:721#: dashboards/identity/projects/workflows.py:754#: dashboards/project/routers/forms.py:129#: dashboards/project/routers/forms.py:134#: usage/base.py:186 usage/quotas.py:337#: usage/quotas.py:323",1815,1784
openstack%2Fnova-specs~master~Ic7e5f8bcf9fbff9a2986056427d745d449094746,openstack/nova-specs,master,Ic7e5f8bcf9fbff9a2986056427d745d449094746,The nested quota driver implements quota management in nested projects,ABANDONED,2014-10-18 10:30:46.000000000,2014-10-18 10:48:48.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-10-18 10:30:46.000000000', 'files': ['nested-quota-driver-api.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e799ef8d433170d69b8e3fe94bd41db6f49826a7', 'message': 'The nested quota driver implements quota management in\nnested projects\n\nChange-Id: Ic7e5f8bcf9fbff9a2986056427d745d449094746\n'}]",0,129428,e799ef8d433170d69b8e3fe94bd41db6f49826a7,3,1,1,11057,,,0,"The nested quota driver implements quota management in
nested projects

Change-Id: Ic7e5f8bcf9fbff9a2986056427d745d449094746
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/28/129428/1 && git format-patch -1 --stdout FETCH_HEAD,['nested-quota-driver-api.rst'],1,e799ef8d433170d69b8e3fe94bd41db6f49826a7,bp/nested-quota-driver-api,"which will allows enforcing quotas in nested projects in Openstack.The Users can have different roles inside each project: A normal user can make allowed to create sub-projects, assign quota on resources to these sub-projects and assign the project admin role to individual users of the admin.The user roles can be set as inherited, and if set, then an admin of a ","which will allows enforcing quotas in nested projects in Openstack. The Users can have different roles inside each project: A normal user can make allowed to create sub-projects, assign quota on resources to these sub-projects and assign the project admin role to individual users of the admin.The user roles can be set as inherited, and if set, then an admin of a ",5,5
openstack%2Fneutron~master~I5257e1e22645f3df9a77c0967b09a0ad0cf8b251,openstack/neutron,master,I5257e1e22645f3df9a77c0967b09a0ad0cf8b251,DB: Only ask for MAC instead of entire port,MERGED,2014-10-17 14:08:16.000000000,2014-10-18 09:35:33.000000000,2014-10-18 09:35:31.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-17 14:08:16.000000000', 'files': ['neutron/db/securitygroups_rpc_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/60dd689183469d2958d6dcb60d93a8d94ef694d1', 'message': 'DB: Only ask for MAC instead of entire port\n\nOptimize a query in _get_lla_gateway_ip_for_subnet\nto only grab the column used instead of every column\nin the port table.\n\nPartial-Bug: #1373851\nChange-Id: I5257e1e22645f3df9a77c0967b09a0ad0cf8b251\n'}]",0,129268,60dd689183469d2958d6dcb60d93a8d94ef694d1,40,24,1,7787,,,0,"DB: Only ask for MAC instead of entire port

Optimize a query in _get_lla_gateway_ip_for_subnet
to only grab the column used instead of every column
in the port table.

Partial-Bug: #1373851
Change-Id: I5257e1e22645f3df9a77c0967b09a0ad0cf8b251
",git fetch https://review.opendev.org/openstack/neutron refs/changes/68/129268/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/securitygroups_rpc_base.py'],1,60dd689183469d2958d6dcb60d93a8d94ef694d1,bug/1373851, query = context.session.query(models_v2.Port.mac_address) mac_address = query.one()[0], query = context.session.query(models_v2.Port) gateway_port = query.one() mac_address = gateway_port['mac_address'],2,3
openstack%2Fopenstack-manuals~master~Iac26b193db48376015e0b474bdba13698a25891d,openstack/openstack-manuals,master,Iac26b193db48376015e0b474bdba13698a25891d,Imported Translations from Transifex,MERGED,2014-10-18 06:12:36.000000000,2014-10-18 09:09:35.000000000,2014-10-18 09:09:34.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-18 06:12:36.000000000', 'files': ['doc/glossary/locale/fr.po', 'doc/image-guide/locale/image-guide.pot', 'doc/glossary/locale/de.po', 'doc/glossary/locale/ko_KR.po', 'doc/image-guide/locale/fr.po', 'doc/glossary/locale/ja.po', 'doc/glossary/locale/glossary.pot', 'doc/image-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ed6ca99413de89b832ce4498595d2531166b474c', 'message': 'Imported Translations from Transifex\n\nChange-Id: Iac26b193db48376015e0b474bdba13698a25891d\n'}]",0,129423,ed6ca99413de89b832ce4498595d2531166b474c,6,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: Iac26b193db48376015e0b474bdba13698a25891d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/23/129423/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/glossary/locale/fr.po', 'doc/image-guide/locale/image-guide.pot', 'doc/glossary/locale/de.po', 'doc/glossary/locale/ko_KR.po', 'doc/image-guide/locale/fr.po', 'doc/glossary/locale/ja.po', 'doc/glossary/locale/glossary.pot', 'doc/image-guide/locale/ja.po']",8,ed6ca99413de89b832ce4498595d2531166b474c,transifex/translations,"""POT-Creation-Date: 2014-10-17 12:39+0000\n"" ""PO-Revision-Date: 2014-10-17 09:11+0000\n""#: ./doc/image-guide/ch_openstack_images.xml245(title)#: ./doc/image-guide/ch_openstack_images.xml289(title)msgid ""The simplest way to support this is to install in your image the:"" msgstr """" #: ./doc/image-guide/ch_openstack_images.xml146(para) msgid """" ""<link href=\""https://launchpad.net/cloud-utils\"">cloud-utils</link> package,"" "" which contains the <placeholder-1/> tool for extending partitions."" msgstr """" #: ./doc/image-guide/ch_openstack_images.xml151(para) msgid """" ""<link href=\""https://launchpad.net/cloud-initramfs-tools\"">cloud-initramfs-"" ""growroot</link> package for Ubuntu, Debian and Fedora, which supports "" ""resizing root partition on the first boot."" msgstr """" #: ./doc/image-guide/ch_openstack_images.xml156(para) msgid """" ""<package>cloud-initramfs-growroot</package> package for Centos and RHEL."" msgstr """" #: ./doc/image-guide/ch_openstack_images.xml160(para) msgid ""<link href=\""https://launchpad.net/cloud-init\"">cloud-init</link> package."" msgstr """" #: ./doc/image-guide/ch_openstack_images.xml164(para) msgid """" ""With these packages installed, the image performs the root partition resize "" ""on boot. For example, in the <filename>/etc/rc.local</filename> file. These "" ""packages are in the Ubuntu and Debian package repository, as well as the "" ""EPEL repository (for Fedora/RHEL/CentOS/Scientific Linux guests)."" msgstr """" #: ./doc/image-guide/ch_openstack_images.xml171(para)#: ./doc/image-guide/ch_openstack_images.xml179(para)#: ./doc/image-guide/ch_openstack_images.xml186(title)#: ./doc/image-guide/ch_openstack_images.xml189(para)#: ./doc/image-guide/ch_openstack_images.xml200(para)#: ./doc/image-guide/ch_openstack_images.xml207(para)#: ./doc/image-guide/ch_openstack_images.xml215(replaceable) #: ./doc/image-guide/ch_openstack_images.xml222(replaceable) #: ./doc/image-guide/ch_openstack_images.xml229(replaceable)#: ./doc/image-guide/ch_openstack_images.xml213(para)#: ./doc/image-guide/ch_openstack_images.xml221(replaceable)#: ./doc/image-guide/ch_openstack_images.xml218(para)#: ./doc/image-guide/ch_openstack_images.xml228(replaceable) #: ./doc/image-guide/ch_openstack_images.xml234(replaceable)#: ./doc/image-guide/ch_openstack_images.xml225(para)#: ./doc/image-guide/ch_openstack_images.xml232(para)#: ./doc/image-guide/ch_openstack_images.xml198(para)#: ./doc/image-guide/ch_openstack_images.xml237(para)#: ./doc/image-guide/ch_openstack_images.xml246(para)#: ./doc/image-guide/ch_openstack_images.xml256(para)#: ./doc/image-guide/ch_openstack_images.xml262(para)#: ./doc/image-guide/ch_openstack_images.xml268(para)#: ./doc/image-guide/ch_openstack_images.xml274(para)#: ./doc/image-guide/ch_openstack_images.xml281(title)#: ./doc/image-guide/ch_openstack_images.xml282(para)#: ./doc/image-guide/ch_openstack_images.xml290(para)#: ./doc/image-guide/ch_openstack_images.xml298(title)#: ./doc/image-guide/ch_openstack_images.xml300(para)#: ./doc/image-guide/ch_openstack_images.xml307(title)#: ./doc/image-guide/ch_openstack_images.xml309(para)#: ./doc/image-guide/ch_openstack_images.xml317(para)#: ./doc/image-guide/ch_openstack_images.xml327(title)#: ./doc/image-guide/ch_openstack_images.xml329(para)#: ./doc/image-guide/ch_openstack_images.xml333(para)#: ./doc/image-guide/ch_openstack_images.xml373(para)#: ./doc/image-guide/ch_openstack_images.xml385(title)#: ./doc/image-guide/ch_openstack_images.xml387(para)""/user-guide/content/inserting_userdata.html\"">Provide user data to "" ""instances</link>, that the user submitted when requesting the image. For "" ""example, you might want to set the host name of the instance when it is "" ""booted. Or, you might wish to configure your image so that it executes user "" ""data content as a script on boot."" msgstr """" #: ./doc/image-guide/ch_openstack_images.xml395(para)""You can access this information through the metadata service or referring to"" "" <link href=\""http://docs.openstack.org/user-guide/content/config-"" ""drive.html\"">Store metadata on the configuration drive</link>. As the "" ""OpenStack metadata service is compatible with version 2009-04-04 of the "" ""Amazon EC2 metadata service, consult the Amazon EC2 documentation on <link ""msgstr """" #: ./doc/image-guide/ch_openstack_images.xml406(para)#: ./doc/image-guide/ch_openstack_images.xml413(title)#: ./doc/image-guide/ch_openstack_images.xml414(para)#: ./doc/image-guide/ch_openstack_images.xml418(para)#: ./doc/image-guide/ch_openstack_images.xml423(para)#: ./doc/image-guide/ch_openstack_images.xml432(para)#: ./doc/image-guide/ch_openstack_images.xml435(para)#: ./doc/image-guide/ch_openstack_images.xml440(title)#: ./doc/image-guide/ch_openstack_images.xml442(para)#: ./doc/image-guide/ch_openstack_images.xml452(title)#: ./doc/image-guide/ch_openstack_images.xml453(para)#: ./doc/image-guide/ch_openstack_images.xml460(para)#: ./doc/image-guide/ch_openstack_images.xml466(caption)#: ./doc/image-guide/ch_openstack_images.xml472(td)#: ./doc/image-guide/ch_openstack_images.xml473(td)#: ./doc/image-guide/ch_openstack_images.xml478(td)#: ./doc/image-guide/ch_openstack_images.xml479(para)#: ./doc/image-guide/ch_openstack_images.xml482(para)#: ./doc/image-guide/ch_openstack_images.xml487(para)#: ./doc/image-guide/ch_openstack_images.xml504(td)#: ./doc/image-guide/ch_openstack_images.xml505(td)#: ./doc/image-guide/ch_openstack_images.xml512(td)#: ./doc/image-guide/ch_openstack_images.xml513(td)#: ./doc/image-guide/ch_openstack_images.xml518(td)#: ./doc/image-guide/ch_openstack_images.xml519(td)#: ./doc/image-guide/ch_openstack_images.xml525(para)#: ./doc/image-guide/ch_openstack_images.xml529(para)#: ./doc/image-guide/ch_openstack_images.xml536(para)","""POT-Creation-Date: 2014-10-16 19:53+0000\n"" ""PO-Revision-Date: 2014-10-16 15:17+0000\n""#: ./doc/image-guide/ch_openstack_images.xml235(title)#: ./doc/image-guide/ch_openstack_images.xml279(title)msgid """" ""The simplest way to support this in your image is to install the <link "" ""href=\""https://launchpad.net/cloud-utils\"">cloud-utils</link> package "" ""(contains the <placeholder-1/> tool for extending partitions), the <link "" ""href=\""https://launchpad.net/cloud-initramfs-tools\"">cloud-initramfs-"" ""growroot</link> package (which supports resizing root partition on the first"" "" boot), and the <link href=\""https://launchpad.net/cloud-init\""><package"" "">cloud-init</package></link> package into your image. With these installed, "" ""the image performs the root partition resize on boot. For example, in the "" ""<filename>/etc/rc.local</filename> file. These packages are in the Ubuntu "" ""and Debian package repository, as well as the EPEL repository (for "" ""Fedora/RHEL/CentOS/Scientific Linux guests)."" msgstr ""これをサポートする最も簡単な方法は、<link href=\""https://launchpad.net/cloud-utils\"">cloud-utils</link> パッケージ (パーティションを拡張するための <placeholder-1/> ツールを含む)、<link href=\""https://launchpad.net/cloud-initramfs-tools\"">cloud-initramfs-growroot</link> パッケージ (初回起動時にルートパーティションのリサイズをサポート)、<link href=\""https://launchpad.net/cloud-init\""><package>cloud-init</package></link> パッケージをイメージの中にインストールすることです。これらをインストールすると、イメージは、起動時にルートパーティションをリサイズされます。例えば、<filename>/etc/rc.local</filename> ファイルにあります。これらのパッケージは、Ubuntu と Debian のパッケージリポジトリ、EPEL リポジトリ (Fedora/RHEL/CentOS/Scientific Linux ゲストの場合) にあります。"" #: ./doc/image-guide/ch_openstack_images.xml161(para)#: ./doc/image-guide/ch_openstack_images.xml169(para)#: ./doc/image-guide/ch_openstack_images.xml176(title)#: ./doc/image-guide/ch_openstack_images.xml179(para)#: ./doc/image-guide/ch_openstack_images.xml190(para)#: ./doc/image-guide/ch_openstack_images.xml197(para)#: ./doc/image-guide/ch_openstack_images.xml205(replaceable) #: ./doc/image-guide/ch_openstack_images.xml212(replaceable) #: ./doc/image-guide/ch_openstack_images.xml219(replaceable)#: ./doc/image-guide/ch_openstack_images.xml203(para)#: ./doc/image-guide/ch_openstack_images.xml211(replaceable)#: ./doc/image-guide/ch_openstack_images.xml208(para)#: ./doc/image-guide/ch_openstack_images.xml218(replaceable) #: ./doc/image-guide/ch_openstack_images.xml224(replaceable)#: ./doc/image-guide/ch_openstack_images.xml215(para)#: ./doc/image-guide/ch_openstack_images.xml222(para)#: ./doc/image-guide/ch_openstack_images.xml188(para)#: ./doc/image-guide/ch_openstack_images.xml227(para)#: ./doc/image-guide/ch_openstack_images.xml236(para)#: ./doc/image-guide/ch_openstack_images.xml246(para)#: ./doc/image-guide/ch_openstack_images.xml252(para)#: ./doc/image-guide/ch_openstack_images.xml258(para)#: ./doc/image-guide/ch_openstack_images.xml264(para)#: ./doc/image-guide/ch_openstack_images.xml271(title)#: ./doc/image-guide/ch_openstack_images.xml272(para)#: ./doc/image-guide/ch_openstack_images.xml280(para)#: ./doc/image-guide/ch_openstack_images.xml288(title)#: ./doc/image-guide/ch_openstack_images.xml290(para)#: ./doc/image-guide/ch_openstack_images.xml297(title)#: ./doc/image-guide/ch_openstack_images.xml299(para)#: ./doc/image-guide/ch_openstack_images.xml307(para)#: ./doc/image-guide/ch_openstack_images.xml317(title)#: ./doc/image-guide/ch_openstack_images.xml319(para)#: ./doc/image-guide/ch_openstack_images.xml323(para)#: ./doc/image-guide/ch_openstack_images.xml363(para)#: ./doc/image-guide/ch_openstack_images.xml375(title)#: ./doc/image-guide/ch_openstack_images.xml377(para)""/user-guide/content/user-data.html\"">user data</link> that the user "" ""submitted when requesting the image. For example, you might want to set the "" ""host name of the instance when it is booted. Or, you might wish to configure"" "" your image so that it executes user data content as a script on boot."" msgstr ""イメージが、SSH 公開鍵以外に、OpenStack から追加の情報を必要とするかもしれません。イメージの起動時にユーザーから渡される<link href=\""http://docs.openstack.org/user-guide/content/user-data.html\"">ユーザーデータ</link>などです。例えば、起動時にインスタンスのホスト名を設定したいかもしれません。または、起動時にスクリプトとしてユーザーデータの内容を実行するよう、イメージを設定したいかもしれません。"" #: ./doc/image-guide/ch_openstack_images.xml385(para)""This information is accessible through the metadata service or the <link "" ""href=\""http://docs.openstack.org/user-guide/content/config-"" ""drive.html\"">config drive</link>. As the OpenStack metadata service is "" ""compatible with version 2009-04-04 of the Amazon EC2 metadata service, "" ""consult the Amazon EC2 documentation on <link ""msgstr ""この情報は、メタデータサービスまたは<link href=\""http://docs.openstack.org/user-guide/content/config-drive.html\"">コンフィグドライブ</link>経由でアクセスできます。OpenStack メタデータサービスは、Amazon EC2 メタデータの 2009-04-04 版と互換性があるので、ユーザーデータの取得方法の詳細は、Amazon EC2 のドキュメント <link href=\""http://docs.amazonwebservices.com/AWSEC2/2009-04-04/UserGuide/AESDG-chapter-instancedata.html\"">Using Instance Metadata</link> を参照してください。"" #: ./doc/image-guide/ch_openstack_images.xml396(para)#: ./doc/image-guide/ch_openstack_images.xml403(title)#: ./doc/image-guide/ch_openstack_images.xml404(para)#: ./doc/image-guide/ch_openstack_images.xml408(para)#: ./doc/image-guide/ch_openstack_images.xml413(para)#: ./doc/image-guide/ch_openstack_images.xml422(para)#: ./doc/image-guide/ch_openstack_images.xml425(para)#: ./doc/image-guide/ch_openstack_images.xml430(title)#: ./doc/image-guide/ch_openstack_images.xml432(para)#: ./doc/image-guide/ch_openstack_images.xml442(title)#: ./doc/image-guide/ch_openstack_images.xml443(para)#: ./doc/image-guide/ch_openstack_images.xml450(para)#: ./doc/image-guide/ch_openstack_images.xml456(caption)#: ./doc/image-guide/ch_openstack_images.xml462(td)#: ./doc/image-guide/ch_openstack_images.xml463(td)#: ./doc/image-guide/ch_openstack_images.xml468(td)#: ./doc/image-guide/ch_openstack_images.xml469(para)#: ./doc/image-guide/ch_openstack_images.xml472(para)#: ./doc/image-guide/ch_openstack_images.xml477(para)#: ./doc/image-guide/ch_openstack_images.xml494(td)#: ./doc/image-guide/ch_openstack_images.xml495(td)#: ./doc/image-guide/ch_openstack_images.xml502(td)#: ./doc/image-guide/ch_openstack_images.xml503(td)#: ./doc/image-guide/ch_openstack_images.xml508(td)#: ./doc/image-guide/ch_openstack_images.xml509(td)#: ./doc/image-guide/ch_openstack_images.xml515(para)#: ./doc/image-guide/ch_openstack_images.xml519(para)#: ./doc/image-guide/ch_openstack_images.xml526(para)",7373,7101
openstack%2Fha-guide~master~I43fd580e8bbf1fef508922890d987c766655276b,openstack/ha-guide,master,I43fd580e8bbf1fef508922890d987c766655276b,Imported Translations from Transifex,MERGED,2014-10-18 06:00:07.000000000,2014-10-18 09:06:33.000000000,2014-10-18 09:06:32.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-18 06:00:07.000000000', 'files': ['doc/high-availability-guide/locale/ja.po', 'doc/high-availability-guide/locale/high-availability-guide.pot'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/dfa5093d9b58dd55f29a0b40667e7b3f556a8435', 'message': 'Imported Translations from Transifex\n\nChange-Id: I43fd580e8bbf1fef508922890d987c766655276b\n'}]",0,129421,dfa5093d9b58dd55f29a0b40667e7b3f556a8435,6,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I43fd580e8bbf1fef508922890d987c766655276b
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/21/129421/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/high-availability-guide/locale/ja.po', 'doc/high-availability-guide/locale/high-availability-guide.pot']",2,dfa5093d9b58dd55f29a0b40667e7b3f556a8435,transifex/translations,"""POT-Creation-Date: 2014-10-18 06:00+0000\n""#: ./doc/high-availability-guide/api/section_cinder_api.xml:41(para) ./doc/high-availability-guide/api/section_glance_api.xml:41(para) ./doc/high-availability-guide/api/section_ceilometer_agent_central.xml:37(para) ./doc/high-availability-guide/controller/section_rabbitmq.xml:165(para) ./doc/high-availability-guide/controller/section_mysql.xml:182(para) ./doc/high-availability-guide/network/section_highly_available_neutron_metadata_agent.xml:26(para) ./doc/high-availability-guide/network/section_highly_available_neutron_l3_agent.xml:30(para)msgid ""<link href=\""http://www.rabbitmq.com/ha.html\"">Active-active mirrored queues</link> is another method for configuring RabbitMQ versions 3.3.0 and later for high availability. You can also manage a RabbitMQ cluster with active-active mirrored queues using the Pacemaker cluster manager.""#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:41(title) ./doc/high-availability-guide/controller/section_mysql.xml:44(title)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:42(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:47(title)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:63(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:74(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:82(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:87(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:92(para) ./doc/high-availability-guide/controller/section_mysql.xml:95(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:103(title)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:104(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:109(para) ./doc/high-availability-guide/controller/section_mysql.xml:113(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:113(para) ./doc/high-availability-guide/controller/section_mysql.xml:117(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:119(title)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:120(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:133(title)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:134(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:168(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:172(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:177(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:181(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:186(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:192(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:198(title)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:199(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:203(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:209(para)","""POT-Creation-Date: 2014-10-14 07:13+0000\n""#: ./doc/high-availability-guide/api/section_cinder_api.xml:41(para) ./doc/high-availability-guide/api/section_glance_api.xml:41(para) ./doc/high-availability-guide/api/section_ceilometer_agent_central.xml:37(para) ./doc/high-availability-guide/controller/section_rabbitmq.xml:170(para) ./doc/high-availability-guide/controller/section_mysql.xml:182(para) ./doc/high-availability-guide/network/section_highly_available_neutron_metadata_agent.xml:26(para) ./doc/high-availability-guide/network/section_highly_available_neutron_l3_agent.xml:30(para)msgid ""There is an alternative method of configuring RabbitMQ for high availability. That approach, known as <link href=\""http://www.rabbitmq.com/ha.html\"">active-active mirrored queues</link>, happens to be the one preferred by the RabbitMQ developershowever it has shown less than ideal consistency and reliability in OpenStack clusters. Thus, at the time of writing, the Pacemaker/DRBD based approach remains the recommended one for OpenStack environments, although this may change in the near future as RabbitMQ active-active mirrored queues mature.""#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:46(title) ./doc/high-availability-guide/controller/section_mysql.xml:44(title)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:47(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:52(title)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:68(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:79(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:87(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:92(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:97(para) ./doc/high-availability-guide/controller/section_mysql.xml:95(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:108(title)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:109(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:114(para) ./doc/high-availability-guide/controller/section_mysql.xml:113(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:118(para) ./doc/high-availability-guide/controller/section_mysql.xml:117(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:124(title)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:125(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:138(title)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:139(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:173(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:177(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:182(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:186(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:191(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:197(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:203(title)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:204(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:208(para)#: ./doc/high-availability-guide/controller/section_rabbitmq.xml:214(para)",63,68
openstack%2Fneutron~master~I6dd04c5c506ff5f97f10ebab03943cd508fbfe60,openstack/neutron,master,I6dd04c5c506ff5f97f10ebab03943cd508fbfe60,openvswitch: Remove no longer used options,MERGED,2014-10-09 00:10:04.000000000,2014-10-18 09:02:03.000000000,2014-10-18 09:02:02.000000000,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 5756}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8655}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9911}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-09 00:10:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/faa853a703f1aa9d570e234db1f73128495835b7', 'message': 'openvswitch: Remove no longer used options\n\nThey are remainders of the recently removed monolithic plugin.\n\nPartial-Bug: #1323729\nChange-Id: I6dd04c5c506ff5f97f10ebab03943cd508fbfe60\n'}, {'number': 2, 'created': '2014-10-09 00:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea67a9acff1aa3b27610d64f2fa131de4b742e92', 'message': 'openvswitch: Remove no longer used options\n\nThey are remainders of the recently removed monolithic plugin.\n\nPartial-Bug: #1323729\nChange-Id: I6dd04c5c506ff5f97f10ebab03943cd508fbfe60\n'}, {'number': 3, 'created': '2014-10-14 05:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/87cd2b2fcd9dbd08a331cf4cb6c0b54200139b3e', 'message': 'openvswitch: Remove no longer used options\n\nThey are remainders of the recently removed monolithic plugin.\n\nPartial-Bug: #1323729\nChange-Id: I6dd04c5c506ff5f97f10ebab03943cd508fbfe60\n'}, {'number': 4, 'created': '2014-10-15 05:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb80d7cdf20ab5d848a4111705f091433164ce2e', 'message': 'openvswitch: Remove no longer used options\n\nThey are remainders of the recently removed monolithic plugin.\n\nPartial-Bug: #1323729\nChange-Id: I6dd04c5c506ff5f97f10ebab03943cd508fbfe60\n'}, {'number': 5, 'created': '2014-10-15 05:07:03.000000000', 'files': ['neutron/tests/unit/openvswitch/test_ovs_defaults.py', 'neutron/plugins/openvswitch/common/config.py', 'etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/105dba9addfdffecea41cce58f3646d2f2a6a6cc', 'message': 'openvswitch: Remove no longer used options\n\nThey are remainders of the recently removed monolithic OVS plugin.\nNote: This change does not touch options used by OVS agent.\n\nPartial-Bug: #1323729\nChange-Id: I6dd04c5c506ff5f97f10ebab03943cd508fbfe60\n'}]",18,127082,105dba9addfdffecea41cce58f3646d2f2a6a6cc,113,33,5,6854,,,0,"openvswitch: Remove no longer used options

They are remainders of the recently removed monolithic OVS plugin.
Note: This change does not touch options used by OVS agent.

Partial-Bug: #1323729
Change-Id: I6dd04c5c506ff5f97f10ebab03943cd508fbfe60
",git fetch https://review.opendev.org/openstack/neutron refs/changes/82/127082/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/openvswitch/test_ovs_defaults.py', 'neutron/plugins/openvswitch/common/config.py']",2,faa853a703f1aa9d570e234db1f73128495835b7,bug/1323729,," cfg.StrOpt('tenant_network_type', default='local', help=_(""Network type for tenant networks "" ""(local, vlan, gre, vxlan, or none)."")), cfg.ListOpt('network_vlan_ranges', default=DEFAULT_VLAN_RANGES, help=_(""List of <physical_network>:<vlan_min>:<vlan_max> "" ""or <physical_network>."")), cfg.ListOpt('tunnel_id_ranges', default=DEFAULT_TUNNEL_RANGES, help=_(""List of <tun_min>:<tun_max>."")), cfg.StrOpt('tunnel_type', default='', help=_(""The type of tunnels to use when utilizing tunnels, "" ""either 'gre' or 'vxlan'."")),",0,16
openstack%2Fdevstack~stable%2Ficehouse~I92fa4f39a986f5f9ee9840c11799ebb9a3b30e6c,openstack/devstack,stable/icehouse,I92fa4f39a986f5f9ee9840c11799ebb9a3b30e6c,Fix neutron.conf parameter,ABANDONED,2014-07-28 13:44:47.000000000,2014-10-18 06:41:40.000000000,,"[{'_account_id': 3}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-07-28 13:44:47.000000000', 'files': ['lib/neutron'], 'web_link': 'https://opendev.org/openstack/devstack/commit/16883aeb75238577506ab235011f1b3914103f5e', 'message': 'Fix neutron.conf parameter\n\nNeutron not notify_nova_on_port_status_change this parameter, the right\nshould be notify_nova_on_port_status_changes\n\nChange-Id: I92fa4f39a986f5f9ee9840c11799ebb9a3b30e6c\nCloses-Bug: #1349432\n'}]",0,109999,16883aeb75238577506ab235011f1b3914103f5e,5,2,1,9536,,,0,"Fix neutron.conf parameter

Neutron not notify_nova_on_port_status_change this parameter, the right
should be notify_nova_on_port_status_changes

Change-Id: I92fa4f39a986f5f9ee9840c11799ebb9a3b30e6c
Closes-Bug: #1349432
",git fetch https://review.opendev.org/openstack/devstack refs/changes/99/109999/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron'],1,16883aeb75238577506ab235011f1b3914103f5e,bug/1349432,Q_NOTIFY_NOVA_PORT_STATUS_CHANGES=${Q_NOTIFY_NOVA_PORT_STATUS_CHANGES:-True} Q_NOTIFY_NOVA_ON_PORT_DATA_CHANGES=${Q_NOTIFY_NOVA_ON_PORT_DATA_CHANGES:-True} iniset $NEUTRON_CONF DEFAULT notify_nova_on_port_status_changes $Q_NOTIFY_NOVA_PORT_STATUS_CHANGES,Q_NOTIFY_NOVA_PORT_STATUS_CHANGE=${Q_NOTIFY_NOVA_PORT_STATUS_CHANGE:-True} Q_NOTIFY_NOVA_ON_PORT_DATA_CHANGES=${Q_NOTIFY_NOVA_PORT_CHANGE:-True} iniset $NEUTRON_CONF DEFAULT notify_nova_on_port_status_change $Q_NOTIFY_NOVA_PORT_STATUS_CHANGE,3,3
openstack%2Fnova~master~Ib041eaac0507590e87f037008d9d832b8870bde5,openstack/nova,master,Ib041eaac0507590e87f037008d9d832b8870bde5,The nested quota driver implements quota allocation in nested projects,ABANDONED,2014-10-18 03:39:09.000000000,2014-10-18 06:16:15.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}]","[{'number': 1, 'created': '2014-10-18 03:39:09.000000000', 'files': ['nested-quota-driver-api.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/1f90f2300d7c3dbc75aaa7c2dc6eb8ed30eb9464', 'message': 'The nested quota driver implements quota allocation in\nnested projects\n\nChange-Id: Ib041eaac0507590e87f037008d9d832b8870bde5\n'}]",0,129413,1f90f2300d7c3dbc75aaa7c2dc6eb8ed30eb9464,6,4,1,11057,,,0,"The nested quota driver implements quota allocation in
nested projects

Change-Id: Ib041eaac0507590e87f037008d9d832b8870bde5
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/129413/1 && git format-patch -1 --stdout FETCH_HEAD,['nested-quota-driver-api.rst'],1,1f90f2300d7c3dbc75aaa7c2dc6eb8ed30eb9464,bp/nested-quota-driver-api,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================== nested-quota-diver-api ====================== https://blueprints.launchpad.net/nova/+spec/nested-quota-driver-api Nested quota driver will enable OpenStack projects to enforce quota in nested projects. Problem description =================== OpenStack is moving towards support for hierarchical ownership of objects. In this regard, the Keystone will change the organizational structure of Openstack, creating nested projects. The existing Quota Driver in Nova called ""DbQuotaDriver"" is useful to enforce quotas at both the project and the project-user level provided that all the projects are at the same level (i.e hierarchy level cannot be greater than 1). The proposal is to develop a new Quota Driver called ""NestedQuotaDriver"", which will allows enforcing quotas in nested projects in Openstack. The nested projects are having a hierarchical structure, where each project may contain users and projects (can be called sub-projects), except for the projects at the last level in the hierarchy ,called leaf nodes, which contain only users. Users can have different roles inside each project: A normal user can make use of resources of a project. A project admin is a user who in addition is allowed to create sub-projects, assign quota on resources to these sub-projects and assign the project admin role to individual users of the sub-projects.Resource quotas of the root project can only be set by the cloud admin.The user roles can be set as inherited, and if set, then an admin of a project is automatically an admin of all the projects in the tree below. Use Cases --------- **Actors** * Martha - Admin (i.e role:cloud-admin) of ProductionIT * Joe - Manager (i.e role: project-admin) of Project CMS * Sam - Manager (i.e role: project-admin) of Project ATLAS * Bill : is one important CMS user and needs access to the bulk of computing resources of CMS for a physics analysis Martha is an infrastructure provider and offers cloud services to Joe for Project CMS, and Sam for Project ATLAS. Martha needs to be able to set the quotas for both CMS and ATLAS, and manage quotas across the entire system. Joe has multiple sub-projects with many users under CMS. Joe needs the ability to create quotas, as well as the ability to list and delete resources across CMS. Sam and Joe cannot see or manipulate the resources owned by each other, only Martha has the ability to manage the whole cloud. Joe can approve the request of Bill for an increase of quota for his activity, and changes the quota of the Bill's projects without having to involve the cloud admin. Project Priority ----------------- This blueprint falls under priority ""Performance/Scalability"". There is an aleardy accepted blueprint for the implementation of nested projects in keystone and its development is also over.This blueprint deals with the quota allocation of those nested projects. Proposed change =============== 1. The default quota (hard limit) for any newly created project is set to 0. The neutral value of zero ensures consistency of data in the case of race conditions when several projects are created by admins at the same time. 2. A project is allowed to create a VM, only after setting the quota to a non-zero value (as default value is 0). After the creation of a new project, quota values must be set explicitly by a Nova API call to a value which ensures availability of free quota, before resources can be claimed in the project. 3. A user with role ""cloud-admin"" is permitted to do quota operations across the entire hierarchy, including the top level project. Cloud-Admins are the only users who are allowed to set the quota of the root project in a tree, and assign the project-admin role to users in the root project. 4. A person with role ""project-admin"" in a project is permitted to do quota operations on its sub-projects and users in the hierarchy. If the role ""project-admin"" in a project is set as inheritable in Keystone, then the user with this role is permitted to do quota operations starting from its immediate child projects to the last level project/user under the project hierarchy. 5. The total resources consumed by a project is divided into a.Used Quota - Resources used by the VMs in a project. (excluding child-projects) b.Reserved Quota - Resources reserved for future use by the project c.Allocated Quota - Sum of the quota ""hard_limit"" values of immediate child projects 6. The ""free"" quota available within a project is calculated as free quota = hard_limit - (used + reserved + allocated) Free quota is not stored in the database; it is calculated for each project on the fly. 7. An increase in the quota value of a project is allowed only if its parent has sufficient free quota available. If there is free quota available with the parent, then the quota update operation will result in the update of the ""hard_limit"" value of the project and ""allocated"" value update of its parent project. That's why, it should be noted that updating the quota of a project requires the token to be scoped at the parent level. * Hierarchy of Projects is as A->B->C (A is the root project) Project A (hard_limit = 100, used = 0, reserved = 0, allocated = 50) Project B (hard_limit = 50, used = 20, reserved = 0, allocated = 10) Project C (hard_limit = 10, used = 10, reserved = 0, allocated = 0) Free quota for projects would be: A:Free Quota = 100 {A:hard_limit} - ( 0 {A:used} + 0 {A:reserved} + 50 {A:Allocated to B}) A:Free Quota = 50 B:Free Quota = 50 {B:hard_limit} - ( 20 {B:used} + 0 {B:reserved} + 10 {B:Allocated to C}) B:Free Quota = 20 C:Free Quota = 10 {C:hard_limit} - ( 10 {C:used} + 0 {C:reserved} + 0 {C:Allocated}) C:Free Quota = 0 If Project C hard_limit is increased by 10, then this change results in: Project A (hard_limit = 100, used = 0, reserved = 0, allocated = 50) Project B (hard_limit = 50, used = 20, reserved = 0, allocated = 20) Project C (hard_limit = 20, used = 10, reserved = 0, allocated = 0) If Project C hard_limit needs to be increased further by 20, then this operation will be aborted, because the free quota available with its parent i.e Project B is only 10. So, first project-admin of A should increase the ""hard_limit"" of Project B (using scoped token to Project A, because of action at level A) and then increase the ""hard_limit"" of Project C (again scoped token to Project B) 8.A decrease in the quota value of a project is allowed only if it has free quota available free quota > 0 (zero) And, hence the maximum decraese in quota value is limited to free quota value. * Hierarchy of Projects is A->B->C,where A is the root project Project A (hard_limit = 100, used = 0, reserved = 0, allocated = 50) Project B (hard_limit = 50, used = 20, reserved = 0, allocated = 10) Project C (hard_limit = 10, used = 10, reserved = 0, allocated = 0) If Project B hard_limit is reduced by 10, then this change results in Project A (hard_limit = 100, used = 0, reserved = 0, allocated = 40) Project B (hard_limit = 40, used = 20, reserved = 0, allocated = 10) Project C (hard_limit = 10, used = 10, reserved = 0, allocated = 0) If Project B's hard_limit needs to be reduced further by 20, then this operation will be aborted, because the free quota of Project B should be greater than or equal to (20+0+10) Alternatives ------------ None Data model impact ----------------- Create a new column ""allocated"" in table ""quota_usages"" with default value 0. REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: * sajeesh Other contributors: * vishy * schwicke * raildo * vinod * nirbhay * nirupma * morganfainberg * tellesnobrega * rodrigodsousa * afaranha Work Items ---------- 1. Two new roles will be used ""cloud-admin"" and ""project-admin"". Users with role ""cloud-admin"" will be able to do quota operations on any project/user in the hierarchy. The user with ""project-admin"" role in a project will be able to do quota operations in projects starting from its immediate child projects to the last level project/user under the project hierarchy. 2. A new Quota Driver called ""NestedQuotaDriver"" will be implemented to enforce quotas in hierarchical multitenancy in OpenStack. Dependencies ============ Depends on bp Hierarchical Multitenancy * https://blueprints.launchpad.net/keystone/+spec/hierarchical-multitenancy Testing ======= * Unit tests will be added for all the REST APIs calls. * Add unit tests for integration with other services. Documentation Impact ==================== None References ========== * Wiki ""https://wiki.openstack.org/wiki/HierarchicalMultitenancy"" ",,281,0
openstack%2Fcinder~master~I8dcbfb770c412624d59c80bebe00d8c27ab0f823,openstack/cinder,master,I8dcbfb770c412624d59c80bebe00d8c27ab0f823,Remove vol_type_id cast to str,MERGED,2014-10-13 08:59:53.000000000,2014-10-18 03:37:01.000000000,2014-10-15 01:08:39.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 6491}, {'_account_id': 7350}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9533}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 12779}]","[{'number': 1, 'created': '2014-10-13 08:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dfbda3d2b4dca63fcdc7d1bf09f584bed0c755a1', 'message': ""Remove vol_type_id cast to str\n\nVolume Type ID is string field, so we don't need to cast it\nto srt one more time\n\nChange-Id: I8dcbfb770c412624d59c80bebe00d8c27ab0f823\n""}, {'number': 2, 'created': '2014-10-13 09:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2cd470b16fb38f9b12548ab90b09d9381e952ef8', 'message': ""Remove vol_type_id cast to str\n\nVolume Type ID is string field, so we don't need to cast it\nto srt one more time\n\nChange-Id: I8dcbfb770c412624d59c80bebe00d8c27ab0f823\n""}, {'number': 3, 'created': '2014-10-13 09:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e537cacf8154205ea122669af67e303657bd21a1', 'message': ""Remove vol_type_id cast to str\n\nVolume Type ID is string field, so we don't need to cast it\nto srt one more time\n\nChange-Id: I8dcbfb770c412624d59c80bebe00d8c27ab0f823\n""}, {'number': 4, 'created': '2014-10-13 11:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7d315317c689cd8192580885ffd19c9cc1821039', 'message': ""Remove vol_type_id cast to str\n\nVolume Type ID is string field, so we don't need to cast it\nto srt one more time\n\nChange-Id: I8dcbfb770c412624d59c80bebe00d8c27ab0f823\n""}, {'number': 5, 'created': '2014-10-13 20:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a9f7186e7aacf55e071f0a9fe7a1fc65b3e254c1', 'message': ""Remove vol_type_id cast to str\n\nVolume Type ID is string field, so we don't need to cast it\nto str one more time\n\nChange-Id: I8dcbfb770c412624d59c80bebe00d8c27ab0f823\n""}, {'number': 6, 'created': '2014-10-14 11:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/166a48c65d78407c5b5a0b3e08306dd3df6bc999', 'message': ""Remove vol_type_id cast to str\n\nVolume Type ID is string field, so we don't need to cast it\nto str one more time\n\nChange-Id: I8dcbfb770c412624d59c80bebe00d8c27ab0f823\n""}, {'number': 7, 'created': '2014-10-14 13:17:48.000000000', 'files': ['cinder/tests/api/v1/test_volumes.py', 'cinder/api/v1/types.py', 'cinder/api/v1/volumes.py', 'cinder/tests/api/v2/test_types.py', 'cinder/api/v2/types.py', 'cinder/tests/api/v1/test_types.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/bf17f8bd2dcab3364cb47a3a148121dcd8b3284d', 'message': ""Remove vol_type_id cast to str\n\nVolume Type ID is string field, so we don't need to cast it\nto str one more time\n\nChange-Id: I8dcbfb770c412624d59c80bebe00d8c27ab0f823\n""}]",3,127901,bf17f8bd2dcab3364cb47a3a148121dcd8b3284d,44,16,7,1736,,,0,"Remove vol_type_id cast to str

Volume Type ID is string field, so we don't need to cast it
to str one more time

Change-Id: I8dcbfb770c412624d59c80bebe00d8c27ab0f823
",git fetch https://review.opendev.org/openstack/cinder refs/changes/01/127901/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/v1/types.py', 'cinder/api/v2/types.py']",2,dfbda3d2b4dca63fcdc7d1bf09f584bed0c755a1,todo-cleanup, vol_type['id'] = vol_type['id'], # TODO(bcwaldon): remove str cast once we use uuids vol_type['id'] = str(vol_type['id']),2,4
openstack%2Fnova~master~I5388c9e6547e80746af7978642b5dc0c7ad70d0e,openstack/nova,master,I5388c9e6547e80746af7978642b5dc0c7ad70d0e,Make v2.1 API tests use v2 URLs(test_[r-v].*),MERGED,2014-10-09 01:22:53.000000000,2014-10-18 02:25:21.000000000,2014-10-18 02:25:18.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5292}, {'_account_id': 6062}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-09 01:22:53.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_server_group_quotas.py', 'nova/tests/api/openstack/compute/contrib/test_simple_tenant_usage.py', 'nova/tests/api/openstack/compute/contrib/test_server_usage.py', 'nova/tests/api/openstack/compute/contrib/test_security_groups.py', 'nova/tests/api/openstack/compute/contrib/test_volumes.py', 'nova/tests/api/openstack/compute/contrib/test_rescue.py', 'nova/tests/api/openstack/compute/contrib/test_server_groups.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a99df8a2ad044e1f7eb83ede99f0ddc0c1af5285', 'message': ""Make v2.1 API tests use v2 URLs(test_[r-v].*)\n\nMost v2.1 API tests are using v3 URLs, because there didn't exist\na fake router for v2.1 at the time. However, now the fake router\nexists.\nThis makes v2.1 API tests of use v2 URLs for testing v2.1 API as\nv2 compatible API for test_[r-v].*.py.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I5388c9e6547e80746af7978642b5dc0c7ad70d0e\n""}]",0,127101,a99df8a2ad044e1f7eb83ede99f0ddc0c1af5285,12,8,1,6167,,,0,"Make v2.1 API tests use v2 URLs(test_[r-v].*)

Most v2.1 API tests are using v3 URLs, because there didn't exist
a fake router for v2.1 at the time. However, now the fake router
exists.
This makes v2.1 API tests of use v2 URLs for testing v2.1 API as
v2 compatible API for test_[r-v].*.py.

Partially implements blueprint v2-on-v3-api

Change-Id: I5388c9e6547e80746af7978642b5dc0c7ad70d0e
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/127101/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/contrib/test_server_group_quotas.py', 'nova/tests/api/openstack/compute/contrib/test_server_usage.py', 'nova/tests/api/openstack/compute/contrib/test_simple_tenant_usage.py', 'nova/tests/api/openstack/compute/contrib/test_security_groups.py', 'nova/tests/api/openstack/compute/contrib/test_volumes.py', 'nova/tests/api/openstack/compute/contrib/test_rescue.py', 'nova/tests/api/openstack/compute/contrib/test_server_groups.py']",7,a99df8a2ad044e1f7eb83ede99f0ddc0c1af5285,bp/v2-on-v3-api," return fakes.wsgi_app_v21(init_only=('os-server-groups',)) return '/v2/fake'"," return fakes.wsgi_app_v3(init_only=('os-server-groups',)) return '/v3' def _get_url(self): return '/v2/fake' ",17,29
openstack%2Fnova~master~I0ec295685473659de9c34a8b1ec4fbc9ec793019,openstack/nova,master,I0ec295685473659de9c34a8b1ec4fbc9ec793019,Make v2.1 API tests use v2 URLs(test_[f-m].*),MERGED,2014-10-09 01:11:14.000000000,2014-10-18 02:21:53.000000000,2014-10-18 02:21:50.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5292}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-09 01:11:14.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_flavor_manage.py', 'nova/tests/api/openstack/compute/contrib/test_flavorextradata.py', 'nova/tests/api/openstack/compute/contrib/test_instance_actions.py', 'nova/tests/api/openstack/compute/contrib/test_flavors_extra_specs.py', 'nova/tests/api/openstack/compute/contrib/test_flavor_rxtx.py', 'nova/tests/api/openstack/compute/contrib/test_hypervisors.py', 'nova/tests/api/openstack/compute/contrib/test_multinic.py', 'nova/tests/api/openstack/compute/contrib/test_keypairs.py', 'nova/tests/api/openstack/compute/contrib/test_flavor_disabled.py', 'nova/tests/api/openstack/compute/contrib/test_image_size.py', 'nova/tests/api/openstack/compute/contrib/test_flavor_swap.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c6564956a2c1229550a6f784b4a79f2d6a615d56', 'message': ""Make v2.1 API tests use v2 URLs(test_[f-m].*)\n\nMost v2.1 API tests are using v3 URLs, because there didn't exist\na fake router for v2.1 at the time. However, now the fake router\nexists.\nThis makes v2.1 API tests of use v2 URLs for testing v2.1 API as\nv2 compatible API for test_[f-m].*.py.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I0ec295685473659de9c34a8b1ec4fbc9ec793019\n""}]",0,127098,c6564956a2c1229550a6f784b4a79f2d6a615d56,11,7,1,6167,,,0,"Make v2.1 API tests use v2 URLs(test_[f-m].*)

Most v2.1 API tests are using v3 URLs, because there didn't exist
a fake router for v2.1 at the time. However, now the fake router
exists.
This makes v2.1 API tests of use v2 URLs for testing v2.1 API as
v2 compatible API for test_[f-m].*.py.

Partially implements blueprint v2-on-v3-api

Change-Id: I0ec295685473659de9c34a8b1ec4fbc9ec793019
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/127098/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/contrib/test_flavor_manage.py', 'nova/tests/api/openstack/compute/contrib/test_flavorextradata.py', 'nova/tests/api/openstack/compute/contrib/test_instance_actions.py', 'nova/tests/api/openstack/compute/contrib/test_flavors_extra_specs.py', 'nova/tests/api/openstack/compute/contrib/test_flavor_rxtx.py', 'nova/tests/api/openstack/compute/contrib/test_hypervisors.py', 'nova/tests/api/openstack/compute/contrib/test_multinic.py', 'nova/tests/api/openstack/compute/contrib/test_keypairs.py', 'nova/tests/api/openstack/compute/contrib/test_flavor_disabled.py', 'nova/tests/api/openstack/compute/contrib/test_image_size.py', 'nova/tests/api/openstack/compute/contrib/test_flavor_swap.py']",11,c6564956a2c1229550a6f784b4a79f2d6a615d56,bp/v2-on-v3-api, base_url = '/v2/fake/flavors' res = req.get_response(fakes.wsgi_app_v21(init_only=('flavors'))), base_url = '/v3/flavors' res = req.get_response(fakes.wsgi_app_v3(init_only=('flavors'))) base_url = '/v2/fake/flavors',34,69
openstack%2Fkeystone~feature%2Fhierarchical-multitenancy~I7e27d042575609e4107764c1ff2e1048e5a14a02,openstack/keystone,feature/hierarchical-multitenancy,I7e27d042575609e4107764c1ff2e1048e5a14a02,Merge remote-tracking branch 'origin/master' into feature/hierarchical-multitenancy,MERGED,2014-10-17 20:05:42.000000000,2014-10-18 01:36:40.000000000,2014-10-18 01:36:38.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 11022}]","[{'number': 1, 'created': '2014-10-17 20:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6f806bdc9b58206ecccf29f79df1257e737e9f5b', 'message': ""Merge remote-tracking branch 'origin/master' into feature/hierarchical-multitenancy\n\nChange-Id: I7e27d042575609e4107764c1ff2e1048e5a14a02\n""}]",0,129376,6f806bdc9b58206ecccf29f79df1257e737e9f5b,10,3,1,2903,,,0,"Merge remote-tracking branch 'origin/master' into feature/hierarchical-multitenancy

Change-Id: I7e27d042575609e4107764c1ff2e1048e5a14a02
",git fetch https://review.opendev.org/openstack/keystone refs/changes/76/129376/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,6f806bdc9b58206ecccf29f79df1257e737e9f5b,bug/1381809,,,0,0
openstack%2Fnova~master~Ic5fe49ef0966c981756b5c6e1bf755e587a95ac1,openstack/nova,master,Ic5fe49ef0966c981756b5c6e1bf755e587a95ac1,Return HTTP 400 if use an in-use fixed ip to attach interface,MERGED,2014-09-02 08:17:36.000000000,2014-10-18 01:01:19.000000000,2014-10-18 01:01:16.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 6348}, {'_account_id': 6773}, {'_account_id': 7634}, {'_account_id': 7641}, {'_account_id': 8412}, {'_account_id': 8574}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-09-02 08:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7fd2fae784927a79534f9aaa7973d8e652efa2c7', 'message': ""(WIP)Return HTTP 400 if use an in-use fixed ip to attach interface\n\nWhen posting an 'attach interface' request to Nova with an in-used fixed ip,\nNova need to return HTTP 400, instead of HTTP 500, in order to inform the\nuser to correct the fixed ip in HTTP request.\n\nChange-Id: Ic5fe49ef0966c981756b5c6e1bf755e587a95ac1\nCloses-Bug: 1363901\n""}, {'number': 2, 'created': '2014-09-04 10:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/138b1d566ec226e8e720aaeb0e6c04572036f623', 'message': ""Return HTTP 400 if use an in-use fixed ip to attach interface\n\nWhen posting an 'attach interface' request to Nova with an in-used fixed ip,\nNova need to return HTTP 400, instead of HTTP 500, in order to inform the\nuser to correct the fixed ip in HTTP request.\n\nChange-Id: Ic5fe49ef0966c981756b5c6e1bf755e587a95ac1\nCloses-Bug: 1363901\n""}, {'number': 3, 'created': '2014-09-10 08:48:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/813fa1bca0e7fa990840597bac0e0f680684bacd', 'message': ""Return HTTP 400 if use an in-use fixed ip to attach interface\n\nWhen posting an 'attach interface' request to Nova with an in-used fixed ip,\nNova need to return HTTP 400, instead of HTTP 500, in order to inform the\nuser to correct the fixed ip in HTTP request.\n\nChange-Id: Ic5fe49ef0966c981756b5c6e1bf755e587a95ac1\nCloses-Bug: 1363901\n""}, {'number': 4, 'created': '2014-09-22 10:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86537e04b99392dbc033c60678071778eec06147', 'message': ""Return HTTP 409 if use an in-use fixed ip to attach interface\n\nWhen posting an 'attach interface' request to Nova with an in-used fixed ip,\nNova need to return HTTP 409, instead of HTTP 500, in order to inform the\nuser to correct the fixed ip in HTTP request.\n\nChange-Id: Ic5fe49ef0966c981756b5c6e1bf755e587a95ac1\nCloses-Bug: 1363901\n""}, {'number': 5, 'created': '2014-09-23 05:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/61fa866812e4a9db365d691ef7856415ef874eb1', 'message': ""Return HTTP 409 if use an in-use fixed ip to attach interface\n\nWhen posting an 'attach interface' request to Nova with an in-used fixed ip,\nNova need to return HTTP 409, instead of HTTP 500, in order to inform the\nuser to correct the fixed ip in HTTP request.\n\nChange-Id: Ic5fe49ef0966c981756b5c6e1bf755e587a95ac1\nCloses-Bug: 1363901\n""}, {'number': 6, 'created': '2014-10-14 02:49:48.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4aa6f7664effe7cd40362621a342a9439c87633c', 'message': ""Return HTTP 400 if use an in-use fixed ip to attach interface\n\nWhen posting an 'attach interface' request to Nova with an in-used fixed ip,\nNova need to return HTTP 400, instead of HTTP 500, in order to inform the\nuser to correct the fixed ip in HTTP request. This code change will take\neffect with Neutron only.\n\nChange-Id: Ic5fe49ef0966c981756b5c6e1bf755e587a95ac1\nCloses-Bug: 1363901\n""}]",23,118276,4aa6f7664effe7cd40362621a342a9439c87633c,90,20,6,8574,,,0,"Return HTTP 400 if use an in-use fixed ip to attach interface

When posting an 'attach interface' request to Nova with an in-used fixed ip,
Nova need to return HTTP 400, instead of HTTP 500, in order to inform the
user to correct the fixed ip in HTTP request. This code change will take
effect with Neutron only.

Change-Id: Ic5fe49ef0966c981756b5c6e1bf755e587a95ac1
Closes-Bug: 1363901
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/118276/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/exception.py']",2,7fd2fae784927a79534f9aaa7973d8e652efa2c7,bug/1363901," if 'instance_uuid' in locals(): msg_fmt = _(""Fixed IP address %(address)s is already in use "" ""on instance %(instance_uuid)s."") else: msg_fmt = _(""Fixed IP address %(address)s is already in use."")"," msg_fmt = _(""Fixed IP address %(address)s is already in use on instance "" ""%(instance_uuid)s."")",9,2
openstack%2Fpython-neutronclient~master~Ibd3a98ceb173e9a1fa106ac6c4ecdebb1a9a1e4f,openstack/python-neutronclient,master,Ibd3a98ceb173e9a1fa106ac6c4ecdebb1a9a1e4f,Fix E129 hacking check,MERGED,2014-10-06 10:26:34.000000000,2014-10-18 01:00:50.000000000,2014-10-18 01:00:50.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 7505}]","[{'number': 1, 'created': '2014-10-06 10:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4fc7d20ef93b922157798c788ce2522ef42d98a5', 'message': 'Fix E129 hacking check\n\nRemove E129 from the ignored checks and fix them\n\nChange-Id: Ibd3a98ceb173e9a1fa106ac6c4ecdebb1a9a1e4f\n'}, {'number': 2, 'created': '2014-10-17 11:02:17.000000000', 'files': ['neutronclient/client.py', 'neutronclient/common/validators.py', 'neutronclient/neutron/v2_0/__init__.py', 'neutronclient/neutron/v2_0/nec/packetfilter.py', 'neutronclient/neutron/v2_0/port.py', 'neutronclient/shell.py', 'tox.ini', 'neutronclient/common/serializer.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/64b2d8a01b74fb9c0e45e452a694d9b67e7088df', 'message': 'Fix E129 hacking check\n\nRemove E129 from the ignored checks and fix them\n\nChange-Id: Ibd3a98ceb173e9a1fa106ac6c4ecdebb1a9a1e4f\n'}]",0,126253,64b2d8a01b74fb9c0e45e452a694d9b67e7088df,15,5,2,7505,,,0,"Fix E129 hacking check

Remove E129 from the ignored checks and fix them

Change-Id: Ibd3a98ceb173e9a1fa106ac6c4ecdebb1a9a1e4f
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/53/126253/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/client.py', 'neutronclient/common/validators.py', 'neutronclient/neutron/v2_0/__init__.py', 'neutronclient/neutron/v2_0/nec/packetfilter.py', 'neutronclient/neutron/v2_0/port.py', 'neutronclient/shell.py', 'tox.ini', 'neutronclient/common/serializer.py']",8,4fc7d20ef93b922157798c788ce2522ef42d98a5,hacking-update," isinstance(e, getattr(etree, 'ParseError'))): attr.startswith('xmlns:') or attr == constants.XSI_ATTR or attr == constants.TYPE_ATTR):"," isinstance(e, getattr(etree, 'ParseError'))): attr.startswith('xmlns:') or attr == constants.XSI_ATTR or attr == constants.TYPE_ATTR):",12,13
openstack%2Ffuel-docs~master~Iff9571d0de11d78dd66a259ea485afec9a237649,openstack/fuel-docs,master,Iff9571d0de11d78dd66a259ea485afec9a237649,Prototype of Release Notes restructure,MERGED,2014-10-14 09:06:13.000000000,2014-10-18 00:32:15.000000000,2014-10-18 00:32:15.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-10-14 09:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/cb26f7a7f8de3ff8b3aa5e6eadbf4950ebfcb947', 'message': 'Prototype of Release Notes restructure\n\nI restructured the Release Notes to more closely match\nthe style of the Community Release Notes:  instead of having\nlong lists of all resolved issues and known issues, the issues\nare grouped by component, with each component having a link to\nthe Community Release Notes for that component (if any) and\nlist of new features and resolved issues as well as known issues.\nI then divided the 5.1 Known Issues up by these sections, since\nmost of these issues will be either Resolved or Known Issues for\n6.0 and it gives us a chance to see how this might all play out.\n\nPlease review only for general shape, not for details.\nI think having a separate main section for each component\nmay be overkill -- perhaps we can do more grouping.\n\nI like the looks of the sections that use bullet items rather\nthan subsection headings for each bug and that matches the style\nof the Community docs.  But does this work for support who may\nneed to send a link to a particular issue.\n\nChange-Id: Iff9571d0de11d78dd66a259ea485afec9a237649\n'}, {'number': 2, 'created': '2014-10-14 17:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/defaabc657b111fd9444d279202b328fa8c1e9fd', 'message': 'Prototype of Release Notes restructure\n\nI restructured the Release Notes to more closely match\nthe style of the Community Release Notes:  instead of having\nlong lists of all resolved issues and known issues, the issues\nare grouped by component, with each component having a link to\nthe Community Release Notes for that component (if any) and\nlist of new features and resolved issues as well as known issues.\nI then divided the 5.1 Known Issues up by these sections, since\nmost of these issues will be either Resolved or Known Issues for\n6.0 and it gives us a chance to see how this might all play out.\n\nPlease review only for general shape, not for details.\nI think having a separate main section for each component\nmay be overkill -- perhaps we can do more grouping.\n\nI like the looks of the sections that use bullet items rather\nthan subsection headings for each bug and that matches the style\nof the Community docs.  But does this work for support who may\nneed to send a link to a particular issue.\n\nChange-Id: Iff9571d0de11d78dd66a259ea485afec9a237649\n'}, {'number': 3, 'created': '2014-10-15 22:22:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/e6bc1e214173179ea22e3eed81bd2e8c3a4600b7', 'message': 'Prototype of Release Notes restructure\n\nI restructured the Release Notes to more closely match\nthe style of the Community Release Notes:  instead of having\nlong lists of all resolved issues and known issues, the issues\nare grouped by component, with each component having a link to\nthe Community Release Notes for that component (if any) and\nlist of new features and resolved issues as well as known issues.\nI then divided the 5.1 Known Issues up by these sections, since\nmost of these issues will be either Resolved or Known Issues for\n6.0 and it gives us a chance to see how this might all play out.\n\nPlease review only for general shape, not for details.\nI think having a separate main section for each component\nmay be overkill -- perhaps we can do more grouping.\n\nI like the looks of the sections that use bullet items rather\nthan subsection headings for each bug and that matches the style\nof the Community docs.  But does this work for support who may\nneed to send a link to a particular issue.\n\nChange-Id: Iff9571d0de11d78dd66a259ea485afec9a237649\n'}, {'number': 4, 'created': '2014-10-17 23:36:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/79f5773d34fb674500c009e31cc9f5476f0b561c', 'message': 'Prototype of Release Notes restructure\n\nI restructured the Release Notes to more closely match\nthe style of the Community Release Notes:  instead of having\nlong lists of all resolved issues and known issues, the issues\nare grouped by topic and include links to the Community Release\nNotes for each component (if any) and list of new features and\nresolved issues as well as known issues.\nI then divided the 5.1 Known Issues up by these sections, since\nmost of these issues will be either Resolved or Known Issues for\n6.0 and it gives us a chance to see how this might all play out.\n\nThe Component Versions (nee ""Supported Software"") is moved to the\nRelease Notes from the Planning Guide.\n\nAlso created the terminology/juno article stub.\n\nAlso includes updates to the infrastructure files to produce 6.0\ndocumentation.\n\nChange-Id: Iff9571d0de11d78dd66a259ea485afec9a237649\n'}, {'number': 5, 'created': '2014-10-18 00:08:06.000000000', 'files': ['pages/release-notes/v6-0/0025-supported-software-list.rst', 'pages/release-notes/v6-0/9100-mellanox.rst', 'pages/release-notes/v6-0/3000-storage.rst', 'pages/release-notes/v6-0/0060-obtain-the-product.rst', 'pages/release-notes/v6-0/0020-new-features.rst', 'contents/contents-release-notes.rst', 'pages/release-notes/v6-0/1030-fuel-install.rst', 'pages/preface/preface.rst', 'pages/release-notes/v6-0-juno-full.rst', 'pages/release-notes/v6-0/050-known-issues.rst', 'pages/release-notes/v6-0/other/4020-keystone.rst', 'pages/release-notes/v6-0/1050-network.rst', 'pages/release-notes/v6-0/6000-other.rst', 'pages/release-notes/v6-0/0070-support.rst', 'pages/release-notes/v6-0/monitoring/5010-ceilometer-mongodb.rst', 'pages/release-notes/v6-0/other/6040-murano.rst', 'pages/release-notes/v6-0/1040-hardware.rst', 'contents/contents-planning-guide.rst', 'pages/planning-guide/0025-supported-software-list.rst', 'pages/release-notes/v6-0/0010-what-is-mirantis-openstack.rst', 'pages/release-notes/v6-0/1060-general.rst', 'pages/release-notes/v6-0/1080-update-upgrade.rst', 'pages/release-notes/v6-0/vmware/9020-nsx.rst', 'pages/terminology/allterms.rst', 'common_conf.py', 'pages/release-notes/v6-0/5000-monitoring.rst', 'pages/terminology/j/juno.rst', 'pdf/pdf_relnotes.rst', 'pages/release-notes/v6-0/monitoring/5030-zabbix.rst', 'pages/release-notes/v6-0/9010-vmware-tech.rst', 'pages/release-notes/v6-0/1090-test.rst', 'pages/release-notes/v6-0/other/4010-horizon.rst', 'index.rst', 'pdf/conf.py'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/7174f6a9b6837de05b5f6db22b21fa3d66433ee0', 'message': 'Prototype of Release Notes restructure\n\nI restructured the Release Notes to more closely match\nthe style of the Community Release Notes:  instead of having\nlong lists of all resolved issues and known issues, the issues\nare grouped by topic and include links to the Community Release\nNotes for each component (if any) and list of new features and\nresolved issues as well as known issues.\nI then divided the 5.1 Known Issues up by these sections, since\nmost of these issues will be either Resolved or Known Issues for\n6.0 and it gives us a chance to see how this might all play out.\n\nThe Component Versions (nee ""Supported Software"") is moved to the\nRelease Notes from the Planning Guide.\n\nAlso created the terminology/juno article stub.\n\nAlso includes updates to the infrastructure files to produce 6.0\ndocumentation.\n\nChange-Id: Iff9571d0de11d78dd66a259ea485afec9a237649\n'}]",0,128210,7174f6a9b6837de05b5f6db22b21fa3d66433ee0,25,4,5,10014,,,0,"Prototype of Release Notes restructure

I restructured the Release Notes to more closely match
the style of the Community Release Notes:  instead of having
long lists of all resolved issues and known issues, the issues
are grouped by topic and include links to the Community Release
Notes for each component (if any) and list of new features and
resolved issues as well as known issues.
I then divided the 5.1 Known Issues up by these sections, since
most of these issues will be either Resolved or Known Issues for
6.0 and it gives us a chance to see how this might all play out.

The Component Versions (nee ""Supported Software"") is moved to the
Release Notes from the Planning Guide.

Also created the terminology/juno article stub.

Also includes updates to the infrastructure files to produce 6.0
documentation.

Change-Id: Iff9571d0de11d78dd66a259ea485afec9a237649
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/10/128210/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/release-notes/v6-0/0025-supported-software-list.rst', 'pages/release-notes/v6-0/9100-mellanox.rst', 'pages/release-notes/v6-0/4030-heat.rst', 'pages/release-notes/v6-0/0060-obtain-the-product.rst', 'pages/release-notes/v6-0/0020-new-features.rst', 'pages/release-notes/v6-0/3030-cinder.rst', 'pages/release-notes/v6-0/3010-swift.rst', 'contents/contents-release-notes.rst', 'pages/release-notes/v6-0/1030-fuel-install.rst', 'pages/preface/preface.rst', 'pages/release-notes/v6-0-juno-full.rst', 'pages/release-notes/v6-0/3040-ceph.rst', 'pages/release-notes/v6-0/050-known-issues.rst', 'pages/release-notes/v6-0/3020-glance.rst', 'pages/release-notes/v6-0/1050-network.rst', 'pages/release-notes/v6-0/0070-support.rst', 'pages/release-notes/v6-0/6040-murano.rst', 'pages/release-notes/v6-0/2010-docker.rst', 'pages/release-notes/v6-0/3100-nova.rst', 'pages/release-notes/v6-0/1040-hardware.rst', 'contents/contents-planning-guide.rst', 'pages/release-notes/v6-0/3950-nova-network.rst', 'pages/release-notes/v6-0/0010-what-is-mirantis-openstack.rst', 'pages/release-notes/v6-0/1060-general.rst', 'pages/release-notes/v6-0/1080-update-upgrade.rst', 'common_conf.py', 'pages/release-notes/v6-0/5030-zabbix.rst', 'pages/release-notes/v6-0/4010-horizon.rst', 'pages/release-notes/v6-0/9020-nsx.rst', 'pages/release-notes/v6-0/9010-vcenter.rst', 'pages/release-notes/v6-0/4020-keystone.rst', 'pages/release-notes/v6-0/5010-ceilometer-mongodb.rst', 'pdf/pdf_relnotes.rst', 'pages/release-notes/v6-0/1090-test.rst', 'index.rst', 'pages/release-notes/v6-0/3900-neutron.rst', 'pdf/conf.py']",37,cb26f7a7f8de3ff8b3aa5e6eadbf4950ebfcb947,relnotes6-structure," ('pdf/pdf_planning-guide', u'Mirantis-OpenStack-6.0-PlanningGuide', u'Planning Guide', u'2014, Mirantis Inc.'), ('pdf/pdf_user', u'Mirantis-OpenStack-6.0-UserGuide', u'User Guide', u'2014, Mirantis Inc.'), ('pdf/pdf_operations', u'Mirantis-OpenStack-6.0-OperationsGuide', u'Operations Guide', u'2014, Mirantis Inc.'), ('pdf/pdf_virtualbox', u'Mirantis-OpenStack-6.0-Running-Mirantis-OpenStack-on-VirtualBox', u'Running Mirantis OpenStack on VirtualBox', u'2014, Mirantis Inc.'), ('pdf/pdf_reference', u'Mirantis-OpenStack-6.0-ReferenceArchitecture', u'Reference Architecture', u'2014, Mirantis Inc.'), ('pdf/pdf_terminology', u'Mirantis-OpenStack-6.0-Terminology-Reference', u'Terminology Reference', u'2014, Mirantis Inc.'), ('pdf/pdf_relnotes', u'Mirantis-OpenStack-6.0-RelNotes', u'Release Notes', u'2014, Mirantis Inc.', {'pdf_use_toc': False}),"," ('pdf/pdf_planning-guide', u'Mirantis-OpenStack-5.1-PlanningGuide', u'Planning Guide', u'2014, Mirantis Inc.'), ('pdf/pdf_user', u'Mirantis-OpenStack-5.1-UserGuide', u'User Guide', u'2014, Mirantis Inc.'), ('pdf/pdf_operations', u'Mirantis-OpenStack-5.1-OperationsGuide', u'Operations Guide', u'2014, Mirantis Inc.'), ('pdf/pdf_virtualbox', u'Mirantis-OpenStack-5.1-Running-Mirantis-OpenStack-on-VirtualBox', u'Running Mirantis OpenStack on VirtualBox', u'2014, Mirantis Inc.'), ('pdf/pdf_reference', u'Mirantis-OpenStack-5.1-ReferenceArchitecture', u'Reference Architecture', u'2014, Mirantis Inc.'), ('pdf/pdf_terminology', u'Mirantis-OpenStack-5.1-Terminology-Reference', u'Terminology Reference', u'2014, Mirantis Inc.'), ('pdf/pdf_relnotes', u'Mirantis-OpenStack-5.1-RelNotes', u'Release Notes', u'2014, Mirantis Inc.', {'pdf_use_toc': False}),",1568,21
openstack%2Ffuel-specs~master~I2a12ecb805b7dcda7070e25d81494255a44af83b,openstack/fuel-specs,master,I2a12ecb805b7dcda7070e25d81494255a44af83b,Blueprint: multiple-cluster-networks,MERGED,2014-06-06 22:54:05.000000000,2014-10-18 00:10:08.000000000,2014-10-18 00:10:07.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6794}, {'_account_id': 8392}, {'_account_id': 8787}, {'_account_id': 8789}, {'_account_id': 8797}, {'_account_id': 8829}, {'_account_id': 8882}, {'_account_id': 8907}, {'_account_id': 8935}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-06-06 22:54:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/2eaed2875e8fe48a6993b86764f262dbae391ccb', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 2, 'created': '2014-06-11 00:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/c70350e26dc6f2c6dd831a9a03f9d27eed9a0e17', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 3, 'created': '2014-06-17 16:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/a929230d638e99390afc0307427f3e4861070f61', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 4, 'created': '2014-06-17 17:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/b0bf62ef43d6dea29bf9461b7fcc352e5632fb62', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 5, 'created': '2014-06-18 17:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/6244ae7345cc484b08e0777a691836ef6c0f2742', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 6, 'created': '2014-06-18 18:22:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/f0b2c81a0814b2b55591a6d569fb24e064fc0ae3', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 7, 'created': '2014-06-20 21:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/30c118354a52d631813dc05207c69f4c1b8fde45', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 8, 'created': '2014-06-20 23:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/caf5da8500954ea73d2c3295146b85466eabbaba', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 9, 'created': '2014-06-21 00:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/59d3df2ed209ea08048b1ed5ac23d83a6ac19aa9', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 10, 'created': '2014-09-04 16:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/161c9a3a2edb893e1c290d0eb767964d989a3a98', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 11, 'created': '2014-09-29 18:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/17bc0d45abd8a09a7c0c1ba3bf1dc6a103616952', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 12, 'created': '2014-09-29 18:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/c99d2b74c14b5c3d077f2ec2e298a3bcc5e1cd4a', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 13, 'created': '2014-09-29 18:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/36fa28d8897e9fd7cc99a87bc3529f666e4962b9', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 14, 'created': '2014-09-29 19:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/9cba6459c970e834fada1cfefcf80003529a06b1', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 15, 'created': '2014-09-29 19:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/a3f11ccaa2e661d5f17101f28acbf03104684121', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 16, 'created': '2014-10-02 21:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/416c9044709cc7c64ecfabe99fc6e2b131d0d1a7', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 17, 'created': '2014-10-02 21:19:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/de25595a347117b00748daf1fe15b03b7b453ef7', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}, {'number': 18, 'created': '2014-10-09 18:30:02.000000000', 'files': ['specs/6.0/multiple-cluster-networks.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/f67f91681afe1a475fbce0aaf104867f1ce5a4cf', 'message': 'Blueprint: multiple-cluster-networks\n\nChange-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b\n'}]",42,98550,f67f91681afe1a475fbce0aaf104867f1ce5a4cf,92,12,18,8829,,,0,"Blueprint: multiple-cluster-networks

Change-Id: I2a12ecb805b7dcda7070e25d81494255a44af83b
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/50/98550/12 && git format-patch -1 --stdout FETCH_HEAD,['specs/5.1/multiple-cluster-networks.rst'],1,2eaed2875e8fe48a6993b86764f262dbae391ccb,bp/multiple-cluster-networks,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ==================== Multiple L2 networks ==================== https://blueprints.launchpad.net/fuel/+spec/multiple-cluster-networks Problem description =================== Currently Fuel only supports one set of networks (admin, public, management, storage) for each cluster. The consequence of this is that a cluster will be a single L2 domain. Forcing the use of a single L2 domain presents scalability problems. Proposed change =============== Allow the creation of multiple instances of each network type for each cluster. Alternatives ------------ Leave it as-is. This will limit our ability to deploy large-scale environments. Data model impact ----------------- Networks are currently tied to a cluster. In order to support multiple networks per cluster we will add the concept of a node group. Networks will be attached to a node group, nodes will be assigned to a node group, and node groups will belong to a cluster. REST API impact --------------- New API handlers will need to be created to allow creation and modification of networks. Node-related APIs will be updated to work with node groups. Security impact --------------- None Notifications impact -------------------- Nodes can be assigned to a group automatically based on which admin network it recieves an address from. The user can be notified of this auto-association. Other end user impact --------------------- None Performance Impact ------------------ Performance of nailgun should not be impacted. Other deployer impact --------------------- A separate DHCP range will need to be configured for each admin network. The correct dnsmasq configurations can be generated automatically by nailgun. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Ryan Moe (rmoe@mirantis.com) Work Items ---------- None Dependencies ============ None Testing ======= None Documentation Impact ==================== The concept of node groups and how networks are assigned to nodes will need to be documented. References ========== https://review.openstack.org/#/c/83204/ ",,112,0
openstack%2Fneutron~master~I2d58fa2aea3b692834d64192d06ace727c7df8a0,openstack/neutron,master,I2d58fa2aea3b692834d64192d06ace727c7df8a0,Big Switch: Don't clear hash before sync,MERGED,2014-10-09 20:56:17.000000000,2014-10-18 00:09:33.000000000,2014-10-14 14:04:45.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 2031}, {'_account_id': 4395}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7591}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-09 20:56:17.000000000', 'files': ['neutron/plugins/bigswitch/servermanager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/24e4110eb284078775496501ff81630eb1619c11', 'message': ""Big Switch: Don't clear hash before sync\n\nThis patch removes the step of clearing the consistency\nhash from the DB before a topology sync. This will ensure\nthat inconsistency will be detected if the topology sync\nfails.\n\nThis logic was originally there to make sure the hash header\nwas not present on the topology sync call to the backend.\nHowever, the hash header is ignored by the backend in a sync\ncall so it wasn't necessary.\n\nCloses-Bug: #1379510\nChange-Id: I2d58fa2aea3b692834d64192d06ace727c7df8a0\n""}]",0,127345,24e4110eb284078775496501ff81630eb1619c11,29,23,1,7787,,,0,"Big Switch: Don't clear hash before sync

This patch removes the step of clearing the consistency
hash from the DB before a topology sync. This will ensure
that inconsistency will be detected if the topology sync
fails.

This logic was originally there to make sure the hash header
was not present on the topology sync call to the backend.
However, the hash header is ignored by the backend in a sync
call so it wasn't necessary.

Closes-Bug: #1379510
Change-Id: I2d58fa2aea3b692834d64192d06ace727c7df8a0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/45/127345/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/bigswitch/servermanager.py'],1,24e4110eb284078775496501ff81630eb1619c11,bug/1379510,, # The hash was incorrect so it needs to be removed hash_handler.put_hash(''),0,2
openstack%2Fneutron~stable%2Ficehouse~Ifa5a7c9749952bc2785a9bf3fed69ad55bf21acc,openstack/neutron,stable/icehouse,Ifa5a7c9749952bc2785a9bf3fed69ad55bf21acc,BSN: Optimistic locking strategy for consistency,ABANDONED,2014-09-26 09:01:59.000000000,2014-10-18 00:08:27.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9846}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-09-26 09:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/906cc96f4600c4853ea05d088318bb80c89f99e9', 'message': 'BSN: Optimistic locking strategy for consistency\n\nAdd an optimistic locking strategy for the Big Switch\nserver manager so multiple Neutron servers wanting to\ncommunicate with the backend do not receive the consistency\nhash for use simultaneously.\n\nConflicts:\n\n\tneutron/plugins/bigswitch/servermanager.py\n\nCloses-Bug: #1374261\nChange-Id: Ifa5a7c9749952bc2785a9bf3fed69ad55bf21acc\n(cherry picked from commit 2b2d6821015d51910b7318e231df90f6298a94e7)\n'}, {'number': 2, 'created': '2014-09-26 11:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3332cb382fff1fd40710e1bfcd814b2601719586', 'message': 'BSN: Optimistic locking strategy for consistency\n\nAdd an optimistic locking strategy for the Big Switch\nserver manager so multiple Neutron servers wanting to\ncommunicate with the backend do not receive the consistency\nhash for use simultaneously.\n\nConflicts:\n\n\tneutron/plugins/bigswitch/servermanager.py\n\nCloses-Bug: #1374261\nChange-Id: Ifa5a7c9749952bc2785a9bf3fed69ad55bf21acc\n(cherry picked from commit 2b2d6821015d51910b7318e231df90f6298a94e7)\n'}, {'number': 3, 'created': '2014-09-26 11:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1629dd34d2cb391baeff8347cd767ef3ecea5e1f', 'message': 'BSN: Optimistic locking strategy for consistency\n\nAdd an optimistic locking strategy for the Big Switch\nserver manager so multiple Neutron servers wanting to\ncommunicate with the backend do not receive the consistency\nhash for use simultaneously.\n\nConflicts:\n\n\tneutron/plugins/bigswitch/servermanager.py\n\nCloses-Bug: #1374261\nChange-Id: Ifa5a7c9749952bc2785a9bf3fed69ad55bf21acc\n(cherry picked from commit 2b2d6821015d51910b7318e231df90f6298a94e7)\n'}, {'number': 4, 'created': '2014-09-26 12:02:08.000000000', 'files': ['neutron/tests/unit/bigswitch/test_base.py', 'neutron/tests/unit/bigswitch/test_servermanager.py', 'neutron/plugins/bigswitch/servermanager.py', 'neutron/plugins/bigswitch/db/consistency_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5caa9ff43148afc6cac1422a15855683b14963f9', 'message': 'BSN: Optimistic locking strategy for consistency\n\nAdd an optimistic locking strategy for the Big Switch\nserver manager so multiple Neutron servers wanting to\ncommunicate with the backend do not receive the consistency\nhash for use simultaneously.\n\nConflicts:\n\n\tneutron/plugins/bigswitch/servermanager.py\n\nCloses-Bug: #1374261\nChange-Id: Ifa5a7c9749952bc2785a9bf3fed69ad55bf21acc\n(cherry picked from commit 2b2d6821015d51910b7318e231df90f6298a94e7)\n'}]",0,124336,5caa9ff43148afc6cac1422a15855683b14963f9,51,15,4,7787,,,0,"BSN: Optimistic locking strategy for consistency

Add an optimistic locking strategy for the Big Switch
server manager so multiple Neutron servers wanting to
communicate with the backend do not receive the consistency
hash for use simultaneously.

Conflicts:

	neutron/plugins/bigswitch/servermanager.py

Closes-Bug: #1374261
Change-Id: Ifa5a7c9749952bc2785a9bf3fed69ad55bf21acc
(cherry picked from commit 2b2d6821015d51910b7318e231df90f6298a94e7)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/36/124336/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/bigswitch/test_base.py', 'neutron/tests/unit/bigswitch/test_servermanager.py', 'neutron/plugins/bigswitch/servermanager.py', 'neutron/plugins/bigswitch/db/consistency_db.py']",4,906cc96f4600c4853ea05d088318bb80c89f99e9,bug/1374261,"import random import re import string import time from neutron.openstack.common.db import exception as db_exc from neutron.openstack.common.db.sqlalchemy import session# Maximum time in seconds to wait for a single record lock to be released # NOTE: The total time waiting may exceed this if there are multiple servers # waiting for the same lock MAX_LOCK_WAIT_TIME = 10 def clear_db(): '''Helper to unregister models and clear engine in unit tests.''' if not HashHandler._FACADE: return ConsistencyHash.metadata.drop_all(HashHandler._FACADE.get_engine()) HashHandler._FACADE = None This class needs an SQL engine completely independent of the main neutron connection so rollbacks from consistency hash operations don't affect the parent sessions. _FACADE = None def __init__(self, hash_id='1'): if HashHandler._FACADE is None: HashHandler._FACADE = session ConsistencyHash.metadata.create_all( HashHandler._FACADE.get_engine(sqlite_fk=True)) self.session = HashHandler._FACADE.get_session(autocommit=True, expire_on_commit=False) self.random_lock_id = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(10)) self.lock_marker = 'LOCKED_BY[%s]' % self.random_lock_id # an optimistic locking strategy with a timeout to avoid using a # consistency hash while another server is using it. lock_wait_start = None last_lock_owner = None while True: try: update = False with self.session.begin(subtransactions=True): res = (self.session.query(ConsistencyHash). filter_by(hash_id=self.hash_id).first()) if not res: res = ConsistencyHash(hash_id=self.hash_id, hash=self.lock_marker) self.session.add(res) break LOG.debug(""My lock ID is %s. Current hash is %s"" % ( self.random_lock_id, res.hash)) matches = re.findall(""^LOCKED_BY\[(\w+)\]"", res.hash) if matches: current_lock_owner = matches[0] if current_lock_owner == self.random_lock_id: # no change needed, we already have the table lock break if current_lock_owner != last_lock_owner: # the owner changed, but it wasn't to us. # reset the counter and log if not first time. if lock_wait_start: LOG.debug(""Lock owner changed from %s to %s while "" ""waiting to acquire it."", (last_lock_owner, current_lock_owner)) lock_wait_start = time.time() last_lock_owner = current_lock_owner if time.time() - lock_wait_start > MAX_LOCK_WAIT_TIME: # the lock has been held too long, steal it LOG.warning(_(""Gave up waiting for consistency DB "" ""lock, taking it from current holder. "" ""Current hash is: %s""), res.hash) update = res.hash.replace(current_lock_owner, self.random_lock_id) else: # no current lock update = self.lock_marker + res.hash if update: # need to check update row count in case another server is # doing this at the same time. Only one can succeed. query = sa.update(ConsistencyHash).values(hash=update) query = query.where(ConsistencyHash.hash_id == res.hash_id) query = query.where(ConsistencyHash.hash == res.hash) with self._FACADE.get_engine().begin() as conn: result = conn.execute(query) if result.rowcount == 1: # we successfully updated the table with our lock break # someone else beat us to it. restart the process LOG.debug(""Failed to acquire lock. Restarting lock wait."") lock_wait_start = time.time() last_lock_owner = None # we don't know who got it yet time.sleep(0.25) except db_exc.DBDuplicateEntry: # another server created a new record at the same time # retry process after waiting LOG.debug(""Concurrent record inserted. Retrying."") time.sleep(0.25) ret = (update.replace(self.lock_marker, '') if update else res.hash.replace(self.lock_marker, '')) LOG.debug(""Returning hash header %s"", ret) return ret def clear_lock(self): LOG.debug(""Clearing hash record lock of id %s"" % self.random_lock_id) if not res: LOG.warning(_(""Hash record already gone, no lock to clear."")) return if not res.hash.startswith(self.lock_marker): # if these are frequent the server is too slow LOG.warning(_(""Another server has already taken the lock. %s""), res.hash) return res.hash = res.hash.replace(self.lock_marker, '') res = (self.session.query(ConsistencyHash). filter_by(hash_id=self.hash_id).first()) if res: res.hash = hash","from neutron.db import api as db def __init__(self, context=None, hash_id='1'): self.session = db.get_session() if not context else context.session self.hash_db_obj = None # REVISIT(kevinbenton): locking here with the DB is prone to deadlocks # in various multi-REST-call scenarios (router intfs, flips, etc). # Since it doesn't work in Galera deployments anyway, another sync # mechanism will have to be introduced to prevent inefficient double # syncs in HA deployments. if not res: return '' self.hash_db_obj = res return res.hash if self.hash_db_obj is not None: self.hash_db_obj.hash = hash",238,16
openstack%2Fnova~stable%2Fjuno~I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc,openstack/nova,stable/juno,I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc,Fix XML UnicodeEncode serialization error,MERGED,2014-10-17 15:55:10.000000000,2014-10-17 23:27:34.000000000,2014-10-17 23:27:32.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5196}, {'_account_id': 5292}, {'_account_id': 6873}, {'_account_id': 7198}, {'_account_id': 10118}]","[{'number': 1, 'created': '2014-10-17 15:55:10.000000000', 'files': ['nova/api/openstack/wsgi.py', 'nova/tests/api/openstack/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3136cfc11f034cf0b17888f7348e80d38d563c2e', 'message': ""Fix XML UnicodeEncode serialization error\n\nThe generic Nova XMLSerializer code will currently attempt\nto cast to str the value for all leaf nodes. This patch\nensures that no attempt is made to convert unicode which\ncan cause a UnicodeEncode error. We don't need to convert\nunicode for XML text and regardless we encode to UTF-8 at\na later point.\n\nChange-Id: I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc\nCloses-Bug: #1279172\n(cherry picked from commit 53fe8696314fb73ca9943fce998d96fa6d0414b4)\n""}]",0,129307,3136cfc11f034cf0b17888f7348e80d38d563c2e,14,7,1,6873,,,0,"Fix XML UnicodeEncode serialization error

The generic Nova XMLSerializer code will currently attempt
to cast to str the value for all leaf nodes. This patch
ensures that no attempt is made to convert unicode which
can cause a UnicodeEncode error. We don't need to convert
unicode for XML text and regardless we encode to UTF-8 at
a later point.

Change-Id: I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc
Closes-Bug: #1279172
(cherry picked from commit 53fe8696314fb73ca9943fce998d96fa6d0414b4)
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/129307/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/wsgi.py', 'nova/tests/api/openstack/test_wsgi.py']",2,3136cfc11f034cf0b17888f7348e80d38d563c2e,," def test_xml_contains_unicode(self): input_dict = dict(test=u'\u89e3\u7801') expected_xml = '<test>\xe8\xa7\xa3\xe7\xa0\x81</test>' serializer = wsgi.XMLDictSerializer() result = serializer.serialize(input_dict) result = result.replace('\n', '').replace(' ', '') self.assertEqual(expected_xml, result) ",,11,1
openstack%2Fpython-openstackclient~master~I1a6059afa845a591eff92567ca346c09010a93af,openstack/python-openstackclient,master,I1a6059afa845a591eff92567ca346c09010a93af,Add plugin to support token-endpoint auth,MERGED,2014-10-10 21:13:20.000000000,2014-10-17 23:27:29.000000000,2014-10-17 23:27:28.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2218}, {'_account_id': 6482}, {'_account_id': 7186}, {'_account_id': 7191}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-10-10 21:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/155143a05edf467acfff5b47e6526d65ef847441', 'message': 'Add plugin to support token-flow auth\n\nThe ksc auth plugins do not have support for the original token-flow\nauth where the user supplies a token (possibly the Keystone admin_token)\nand an API endpoint.  This is used specifically for bootstrapping\nKeystone but also has other uses when a scoped user token is provided.\n\nThe api.auth:TokenFlow class is required to provide the same interface\nmethods so all of the special-case code branches to support token-flow\ncan be removed.\n\nSome additional cleanups related to ClientManager and creating the\nCompute client also were done to streamline using sessions.\n\nChange-Id: I1a6059afa845a591eff92567ca346c09010a93af\n'}, {'number': 2, 'created': '2014-10-12 21:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b5d8b28b590ef992f5d17c3f5032d4fced7cfd05', 'message': 'Add plugin to support token-endpoint auth\n\nThe ksc auth plugins do not have support for the original token-endpoint\n(aka token flow) auth where the user supplies a token (possibly the\nKeystone admin_token) and an API endpoint.  This is used for bootstrapping\nKeystone but also has other uses when a scoped user token is provided.\n\nThe api.auth:TokenEndpoint class is required to provide the same interface\nmethods so all of the special-case code branches to support token-endpoint\ncan be removed.\n\nSome additional cleanups related to ClientManager and creating the\nCompute client also were done to streamline using sessions.\n\nChange-Id: I1a6059afa845a591eff92567ca346c09010a93af\n'}, {'number': 3, 'created': '2014-10-12 21:49:49.000000000', 'files': ['openstackclient/api/auth.py', 'openstackclient/tests/common/test_clientmanager.py', 'openstackclient/compute/client.py', 'openstackclient/common/clientmanager.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c3c6edbe8a083aef0fb6aea3cb461ff8e715fc59', 'message': 'Add plugin to support token-endpoint auth\n\nThe ksc auth plugins do not have support for the original\ntoken-endpoint (aka token flow) auth where the user supplies\na token (possibly the Keystone admin_token) and an API endpoint.\nThis is used for bootstrapping Keystone but also has other uses\nwhen a scoped user token is provided.\n\nThe api.auth:TokenEndpoint class is required to provide the\nsame interface methods so all of the special-case code branches\nto support token-endpoint can be removed.\n\nSome additional cleanups related to ClientManager and creating\nthe Compute client also were done to streamline using sessions.\n\nChange-Id: I1a6059afa845a591eff92567ca346c09010a93af\n'}]",3,127655,c3c6edbe8a083aef0fb6aea3cb461ff8e715fc59,26,7,3,970,,,0,"Add plugin to support token-endpoint auth

The ksc auth plugins do not have support for the original
token-endpoint (aka token flow) auth where the user supplies
a token (possibly the Keystone admin_token) and an API endpoint.
This is used for bootstrapping Keystone but also has other uses
when a scoped user token is provided.

The api.auth:TokenEndpoint class is required to provide the
same interface methods so all of the special-case code branches
to support token-endpoint can be removed.

Some additional cleanups related to ClientManager and creating
the Compute client also were done to streamline using sessions.

Change-Id: I1a6059afa845a591eff92567ca346c09010a93af
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/55/127655/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/api/auth.py', 'openstackclient/compute/client.py', 'openstackclient/tests/common/test_clientmanager.py', 'openstackclient/common/clientmanager.py', 'setup.cfg']",5,155143a05edf467acfff5b47e6526d65ef847441,token-endpoint-auth,keystoneclient.auth.plugin = token_flow = openstackclient.api.auth:TokenFlow ,,123,57
openstack%2Fswift~feature%2Fec~I78b65b91debf2894cf020fe58834e423612b07c5,openstack/swift,feature/ec,I78b65b91debf2894cf020fe58834e423612b07c5,Generic payload trailer support for PUT requests,ABANDONED,2014-08-03 11:38:21.000000000,2014-10-17 23:20:02.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 2828}, {'_account_id': 5189}, {'_account_id': 6198}, {'_account_id': 7479}, {'_account_id': 7485}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-08-03 11:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/681a02ef954cafdd08d2869bebf1e2f0bb77978a', 'message': 'Generic payload trailer support for PUT requests\n\nThis patch adds support for payload trailer that proxy server\nsends to the object server at the end of object data stream\nduring a PUT request.  Useful when the object data is modified\nat the proxy server (encrypted, erasure coded etc) before\nstreaming it down to the object server.  In such cases the\nobject server has no way of knowing/calcuating the original\nobject size (in the erasure coding case) and/or the md5sum for\nthe original object data (in the encryption/erasure coding\ncases).  The proxy server needs to send this information to\nthe object server so the object server can store the object\nmetadata accurately along with the object and also in the\ncontainer database.\n\nWIP - adding trailer support to proxy unit test cases\n\nChange-Id: I78b65b91debf2894cf020fe58834e423612b07c5\nImplements: blueprint ec-proxy-work\n'}, {'number': 2, 'created': '2014-08-03 20:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1a02a6ebbb4918ce311f1e69ab08b3de8780595b', 'message': 'Generic payload trailer support for PUT requests\n\nThis patch adds support for payload trailer that proxy server\nsends to the object server at the end of object data stream\nduring a PUT request.  Useful when the object data is modified\nat the proxy server (encrypted, erasure coded etc) before\nstreaming it down to the object server.  In such cases the\nobject server has no way of knowing/calcuating the original\nobject size (in the erasure coding case) and/or the md5sum for\nthe original object data (in the encryption/erasure coding\ncases).  The proxy server needs to send this information to\nthe object server so the object server can store the object\nmetadata accurately along with the object and also in the\ncontainer database.\n\nWIP - adding trailer support to proxy unit test cases\n\nChange-Id: I78b65b91debf2894cf020fe58834e423612b07c5\nImplements: blueprint ec-proxy-work\n'}, {'number': 3, 'created': '2014-08-03 21:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7d413d2fc970a0f04b9299ef072d0127a1ef6677', 'message': 'Generic payload trailer support for PUT requests\n\nThis patch adds support for payload trailer that proxy server\nsends to the object server at the end of object data stream\nduring a PUT request.  Useful when the object data is modified\nat the proxy server (encrypted, erasure coded etc) before\nstreaming it down to the object server.  In such cases the\nobject server has no way of knowing/calcuating the original\nobject size (in the erasure coding case) and/or the md5sum for\nthe original object data (in the encryption/erasure coding\ncases).  The proxy server needs to send this information to\nthe object server so the object server can store the object\nmetadata accurately along with the object and also in the\ncontainer database.\n\nWIP - adding trailer support to proxy unit test cases\n\nChange-Id: I78b65b91debf2894cf020fe58834e423612b07c5\nImplements: blueprint ec-proxy-work\n'}, {'number': 4, 'created': '2014-08-04 02:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/923f2633a201bd25c018a7eaf4c597e7655b03c9', 'message': ""Generic payload trailer support for PUT requests\n\nThis patch adds support for payload trailer that proxy server\nsends to the object server at the end of object data stream\nduring a PUT request.  Useful when the object data is modified\nat the proxy server (encrypted, erasure coded etc) before\nstreaming it down to the object server.  In such cases the\nobject server has no way of knowing/calcuating the original\nobject size (in the erasure coding case) and/or the md5sum for\nthe original object data (in the encryption/erasure coding\ncases).  The proxy server needs to send this information to\nthe object server so the object server can store the object\nmetadata accurately along with the object and also in the\ncontainer database.\n\nChanges:\n\n * Add a helper class for payload trailer support\n   (swift/common/request_helpers.py:ObjectPayloadTrailer)\n * Proxy object controller modifications to insert object\n   trailer at the end of PUT request payload\n * Object server modifications to extract object metadata\n   and write to the object xattrs.  Note that the metadata\n   sent as part of the payload trailer is opaque to the\n   object server\n * Modifications to the object server HEAD method to\n   return 'X-Object-ETag' metadata value for object etag\n   and 'X-Object-Content-Length' value for object length.\n   This is so HEAD on the object server returns correct\n   object length and etag even though the original object\n   data has been altered.\n * Unit test code ObjectPayloadTrailer class\n\nWIP - add trailer support to object unit test cases\n\nChange-Id: I78b65b91debf2894cf020fe58834e423612b07c5\nImplements: blueprint ec-proxy-work\n""}, {'number': 5, 'created': '2014-08-04 03:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/db75d6b75d603d0003ab85da6a0cbbea40d59462', 'message': ""Generic payload trailer support for PUT requests\n\nThis patch adds support for payload trailer that proxy server\nsends to the object server at the end of object data stream\nduring a PUT request.  Useful when the object data is modified\nat the proxy server (encrypted, erasure coded etc) before\nstreaming it down to the object server.  In such cases the\nobject server has no way of knowing/calcuating the original\nobject size (in the erasure coding case) and/or the md5sum for\nthe original object data (in the encryption/erasure coding\ncases).  The proxy server needs to send this information to\nthe object server so the object server can store the object\nmetadata accurately along with the object and also in the\ncontainer database.\n\nChanges:\n\n * Add a helper class for payload trailer support\n   (swift/common/request_helpers.py:ObjectPayloadTrailer)\n * Proxy object controller modifications to insert object\n   trailer at the end of PUT request payload\n * Object server modifications to extract object metadata\n   and write to the object xattrs.  Note that the metadata\n   sent as part of the payload trailer is opaque to the\n   object server\n * Modifications to the object server GET method to\n   return 'X-Object-ETag' metadata value for object etag\n   and 'X-Object-Content-Length' value for object length.\n * Similar modifications to the object server HEAD method.\n   This is so HEAD on the object server returns correct\n   object length and etag even though the original object\n   data has been altered.\n * Unit test code ObjectPayloadTrailer class\n\nWIP - add trailer support to object unit test cases\n\nChange-Id: I78b65b91debf2894cf020fe58834e423612b07c5\nImplements: blueprint ec-proxy-work\n""}, {'number': 6, 'created': '2014-08-06 08:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cd401f2401bf16e67c78033fc912265a857e5070', 'message': ""Generic payload trailer support for PUT requests\n\nThis patch adds support for payload trailer that proxy server\nsends to the object server at the end of object data stream\nduring a PUT request.  Useful when the object data is modified\nat the proxy server (encrypted, erasure coded etc) before\nstreaming it down to the object server.  In such cases the\nobject server has no way of knowing/calcuating the original\nobject size (in the erasure coding case) and/or the md5sum for\nthe original object data (in the encryption/erasure coding\ncases).  The proxy server needs to send this information to\nthe object server so the object server can store the object\nmetadata accurately along with the object and also in the\ncontainer database.\n\nChanges:\n\n * Add a helper class for payload trailer support\n   (swift/common/request_helpers.py:ObjectPayloadTrailer)\n * Proxy object controller modifications to insert object\n   trailer at the end of PUT request payload\n * Object server modifications to extract object metadata\n   and write to the object xattrs.  Note that the metadata\n   sent as part of the payload trailer is opaque to the\n   object server\n * Modifications to the object server GET method to\n   return 'X-Object-ETag' metadata value for object etag\n   and 'X-Object-Content-Length' value for object length.\n * Similar modifications to the object server HEAD method.\n   This is so HEAD on the object server returns correct\n   object length and etag even though the original object\n   data has been altered.\n * Unit test code ObjectPayloadTrailer class\n\nWIP - add trailer support to object unit test cases\n\nChange-Id: I78b65b91debf2894cf020fe58834e423612b07c5\nImplements: blueprint ec-proxy-work\n""}, {'number': 7, 'created': '2014-08-06 22:18:57.000000000', 'files': ['swift/obj/server.py', 'test/unit/common/test_request_helpers.py', 'swift/proxy/controllers/obj.py', 'swift/common/request_helpers.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/fd83dfdf8eb4bfb73eb0c0c9bccd88e6e2e0976c', 'message': ""Generic payload trailer support for PUT requests\n\nThis patch adds support for payload trailer that proxy server\nsends to the object server at the end of object data stream\nduring a PUT request.  Useful when the object data is modified\nat the proxy server (encrypted, erasure coded etc) before\nstreaming it down to the object server.  In such cases the\nobject server has no way of knowing/calcuating the original\nobject size (in the erasure coding case) and/or the md5sum for\nthe original object data (in the encryption/erasure coding\ncases).  The proxy server needs to send this information to\nthe object server so the object server can store the object\nmetadata accurately along with the object and also in the\ncontainer database.\n\nChanges:\n\n * Add a helper class for payload trailer support\n   (swift/common/request_helpers.py:ObjectPayloadTrailer)\n * Proxy object controller modifications to insert object\n   trailer at the end of PUT request payload\n * Object server modifications to extract object metadata\n   and write to the object xattrs.  Note that the metadata\n   sent as part of the payload trailer is opaque to the\n   object server\n * Modifications to the object server GET method to\n   return 'X-Object-ETag' metadata value for object etag\n   and 'X-Object-Content-Length' value for object length.\n * Similar modifications to the object server HEAD method.\n   This is so HEAD on the object server returns correct\n   object length and etag even though the original object\n   data has been altered.\n * Unit test code ObjectPayloadTrailer class\n\nWIP - add trailer support to object unit test cases\n\nChange-Id: I78b65b91debf2894cf020fe58834e423612b07c5\nImplements: blueprint ec-proxy-work\n""}]",3,111562,fd83dfdf8eb4bfb73eb0c0c9bccd88e6e2e0976c,54,9,7,7485,,,0,"Generic payload trailer support for PUT requests

This patch adds support for payload trailer that proxy server
sends to the object server at the end of object data stream
during a PUT request.  Useful when the object data is modified
at the proxy server (encrypted, erasure coded etc) before
streaming it down to the object server.  In such cases the
object server has no way of knowing/calcuating the original
object size (in the erasure coding case) and/or the md5sum for
the original object data (in the encryption/erasure coding
cases).  The proxy server needs to send this information to
the object server so the object server can store the object
metadata accurately along with the object and also in the
container database.

Changes:

 * Add a helper class for payload trailer support
   (swift/common/request_helpers.py:ObjectPayloadTrailer)
 * Proxy object controller modifications to insert object
   trailer at the end of PUT request payload
 * Object server modifications to extract object metadata
   and write to the object xattrs.  Note that the metadata
   sent as part of the payload trailer is opaque to the
   object server
 * Modifications to the object server GET method to
   return 'X-Object-ETag' metadata value for object etag
   and 'X-Object-Content-Length' value for object length.
 * Similar modifications to the object server HEAD method.
   This is so HEAD on the object server returns correct
   object length and etag even though the original object
   data has been altered.
 * Unit test code ObjectPayloadTrailer class

WIP - add trailer support to object unit test cases

Change-Id: I78b65b91debf2894cf020fe58834e423612b07c5
Implements: blueprint ec-proxy-work
",git fetch https://review.opendev.org/openstack/swift refs/changes/62/111562/4 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/server.py', 'test/unit/common/test_request_helpers.py', 'swift/common/request_helpers.py', 'swift/proxy/controllers/obj.py']",4,681a02ef954cafdd08d2869bebf1e2f0bb77978a,bp/ec-proxy-work,"from swift.common.request_helpers import is_user_meta, ObjectPayloadTrailerfrom hashlib import md5 # Tell object servers about trailer magic req.headers['X-Backend-Payload-Trailer-Magic'] = \ ObjectPayloadTrailer.trailer_magic # Add trailer length to 'Content-Length' if req.content_length > 0: trailer_size = ObjectPayloadTrailer.get_trailer_size() req.headers['X-Backend-Payload-Trailer-Length'] = trailer_size req.content_length += trailer_size req.headers['Content-Length'] = str(req.content_length) object_etag = md5() for conn in conns: # Time to send payload trailer # For now, payload etag and original object # etags are identical (given object data is # not modified by the proxy server) trailer = ObjectPayloadTrailer( object_etag, bytes_transferred, object_etag) trailer_bytes = trailer.serialize() conn.queue.put( '%x\r\n%s\r\n' % (len(trailer_bytes), trailer_bytes) if chunked else trailer_bytes) bytes_transferred += len(trailer_bytes) object_etag.update(chunk)",from swift.common.request_helpers import is_user_meta,306,9
openstack%2Fmonasca-api~master~If3ed89b85651020afbaed47ea31d438bc53ed373,openstack/monasca-api,master,If3ed89b85651020afbaed47ea31d438bc53ed373,Fix alarm expression documentation,MERGED,2014-10-17 21:40:12.000000000,2014-10-17 22:45:39.000000000,2014-10-17 22:45:39.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11094}, {'_account_id': 11809}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-10-17 21:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/49a1ca4ea441d3a754b65e76e900fb4e9f9905ac', 'message': 'Fix alarm expression documentation\n\nChange-Id: If3ed89b85651020afbaed47ea31d438bc53ed373\n'}, {'number': 2, 'created': '2014-10-17 21:46:05.000000000', 'files': ['docs/monasca-api-spec.md'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/af216e1e048c52b00dff3b7ec751e95aa93b77ae', 'message': 'Fix alarm expression documentation\n\nChange-Id: If3ed89b85651020afbaed47ea31d438bc53ed373\n'}]",0,129390,af216e1e048c52b00dff3b7ec751e95aa93b77ae,8,5,2,12512,,,0,"Fix alarm expression documentation

Change-Id: If3ed89b85651020afbaed47ea31d438bc53ed373
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/90/129390/2 && git format-patch -1 --stdout FETCH_HEAD,['docs/monasca-api-spec.md'],1,49a1ca4ea441d3a754b65e76e900fb4e9f9905ac,bug/fix-alarm-expression-docs,"A metric can be a metric name only or a metric name followed by a list of dimensions. The dimensions further qualify the metric name. ``` metric : metric_name | metric_name '{' dimension_list '} ``` ```` dimension_list : dimension : dimension ',' dimension_list ```` ```` dimension : dimension_name '=' dimension_value ````In this example the average of the same metric as in the previous example is evaluated over a 120 second period for 3 times so that the expression will evaluate to true if the average is greater than 95 seconds for a total of 360 seconds.avg(cpu_perc{hostname=host.domain.com}, 120) > 95 times 3","The first subexpression shows a direct comparison of a metric to a threshold_value, done every 60 seconds.In this example the average of the same metric as in the previous example is evaluated over a 90 second period for 3 times.avg(cpu_perc{hostname=host.domain.com}, 85) > 90 times 3",18,3
openstack%2Fnova~master~Ia4c046641619f619f8bf6205f841b3a332d31260,openstack/nova,master,Ia4c046641619f619f8bf6205f841b3a332d31260,the value of retries is error in _allocate_network,MERGED,2014-09-05 01:07:04.000000000,2014-10-17 22:34:10.000000000,2014-10-17 22:34:07.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5511}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6773}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 10618}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-09-05 01:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b32653714b0c143495394cd8ec78c0e0ee51a95a', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 2, 'created': '2014-09-09 03:06:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/624d4000b4a2f35a6319c4789cd10ae634368701', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 3, 'created': '2014-09-09 08:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/61679f6a1e16263cb4dcc7e94108f859ca5a841e', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 4, 'created': '2014-09-09 12:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e32967a483b117dd23cbe9d21bb45a7461a473f0', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake. At present,results are as follows:\nretries=0,attempts=1;retries=1,attempts=1;retries=2,attempts=3\nWhen retries=1, attempts=1 ,It actually does not retry.\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 5, 'created': '2014-09-10 01:10:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3279c8d55e68c1d2c002050183255b9bf48e23a9', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 6, 'created': '2014-09-10 09:41:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e682e95860461be8f0042186edae9ed22a8f9d0f', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 7, 'created': '2014-09-11 00:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/358afcae1e3522860f6c39c802cd4b76e0b737d0', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 8, 'created': '2014-09-17 08:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d72ae434f97300d892f16917be6614e5defa7d70', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 9, 'created': '2014-09-17 09:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb22bdea13426049922a77ed58757688b4401d42', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 10, 'created': '2014-09-18 02:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14ef176218e5856c410202c8607fe3ffe132e684', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 11, 'created': '2014-09-18 03:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/338489caf9749d23619d2ba873e921f623a71adc', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 12, 'created': '2014-09-18 04:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a5ce56a01d5bedfabfe8069683f7ea6d4a4bf4f', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 13, 'created': '2014-09-18 04:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b2ffeb2677c188e8e77abf66cc6c50789dae397', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 14, 'created': '2014-09-18 06:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1668c8f081b1c7d32c0b353640494bd4e3df6af8', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 15, 'created': '2014-09-24 09:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c4548a0ccbe347a8fa12fe97df9b45765236590b', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}, {'number': 16, 'created': '2014-09-26 00:17:50.000000000', 'files': ['nova/tests/compute/test_compute_mgr.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4ba7ee4c1bb89b2fa48c2091df1d7f0bcf10ee02', 'message': ""the value of retries is error in _allocate_network\n\nthe variable 'retries' stands for the times retried by allocate\nnetwork ,but it makes a mistake\n\nChange-Id: Ia4c046641619f619f8bf6205f841b3a332d31260\nCloses-Bug: #1363326\n""}]",18,119270,4ba7ee4c1bb89b2fa48c2091df1d7f0bcf10ee02,94,15,16,11530,,,0,"the value of retries is error in _allocate_network

the variable 'retries' stands for the times retried by allocate
network ,but it makes a mistake

Change-Id: Ia4c046641619f619f8bf6205f841b3a332d31260
Closes-Bug: #1363326
",git fetch https://review.opendev.org/openstack/nova refs/changes/70/119270/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,b32653714b0c143495394cd8ec78c0e0ee51a95a,bug/1363326, attempts = retries >= 1 and retries + 1 or 1, attempts = retries > 1 and retries + 1 or 1,1,1
openstack%2Fpython-openstackclient~master~I7c8e8e6d5dffa85244368fd578616c9b19f4fd21,openstack/python-openstackclient,master,I7c8e8e6d5dffa85244368fd578616c9b19f4fd21,use jsonutils in oslo.serialization instead of keystoneclient,MERGED,2014-10-17 03:43:24.000000000,2014-10-17 22:33:54.000000000,2014-10-17 22:33:53.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-10-17 03:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/042d58cf3f887a3c4352813a45216fef616b5bd5', 'message': 'use jsonutils in oslo.serialization instead of keystoneclient\n\nIn this review https://review.openstack.org/#/c/128454/,\nopenstack/common/jsonutils.py is removed. Now, we use jsonutils in\noslo.serialization package.\n\nChange-Id: I7c8e8e6d5dffa85244368fd578616c9b19f4fd21\n'}, {'number': 2, 'created': '2014-10-17 06:16:06.000000000', 'files': ['requirements.txt', 'openstackclient/tests/common/test_clientmanager.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/deda02331474632c47b88c166241cd65b2952269', 'message': 'use jsonutils in oslo.serialization instead of keystoneclient\n\nkeystoneclient/openstack/common/jsonutils.py is removed in this patch\nhttps://review.openstack.org/#/c/128454/\nNow, we should use jsonutils in oslo.serialization package.\n\nChange-Id: I7c8e8e6d5dffa85244368fd578616c9b19f4fd21\n'}]",1,129121,deda02331474632c47b88c166241cd65b2952269,10,3,2,9101,,,0,"use jsonutils in oslo.serialization instead of keystoneclient

keystoneclient/openstack/common/jsonutils.py is removed in this patch
https://review.openstack.org/#/c/128454/
Now, we should use jsonutils in oslo.serialization package.

Change-Id: I7c8e8e6d5dffa85244368fd578616c9b19f4fd21
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/21/129121/2 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/tests/common/test_clientmanager.py'],1,042d58cf3f887a3c4352813a45216fef616b5bd5,jsonutils,from oslo.serialization import jsonutils,from keystoneclient.openstack.common import jsonutils,1,1
openstack%2Ftempest~master~I11e01a4410daa723a789a8736a8111676cdc81f9,openstack/tempest,master,I11e01a4410daa723a789a8736a8111676cdc81f9,Add admin_client support to create_test_server,ABANDONED,2014-10-17 21:41:48.000000000,2014-10-17 22:22:21.000000000,,[{'_account_id': 5196}],"[{'number': 1, 'created': '2014-10-17 21:41:48.000000000', 'files': ['tempest/api/compute/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a8a3fd7823bacfd7308e9d5c34805806a71b240b', 'message': 'Add admin_client support to create_test_server\n\nMake create_test_server useful when an admin made server is needed.\n\nChange-Id: I11e01a4410daa723a789a8736a8111676cdc81f9\n'}]",1,129392,a8a3fd7823bacfd7308e9d5c34805806a71b240b,3,1,1,1849,,,0,"Add admin_client support to create_test_server

Make create_test_server useful when an admin made server is needed.

Change-Id: I11e01a4410daa723a789a8736a8111676cdc81f9
",git fetch https://review.opendev.org/openstack/tempest refs/changes/92/129392/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/base.py'],1,a8a3fd7823bacfd7308e9d5c34805806a71b240b,bug/1372696," cls.admin_servers_client = cls.os_adm.servers_client cls.admin_servers_client = cls.os_adm.servers_client admin = kwargs.get('admin', False) if admin: resp, body = cls.admin_servers_client.create_server( name, image_id, flavor, **kwargs) else: resp, body = cls.servers_client.create_server( name, image_id, flavor, **kwargs)"," resp, body = cls.servers_client.create_server( name, image_id, flavor, **kwargs)",9,2
openstack%2Fpycadf~master~I6dc73504ba274e99cbc18b91c631cad2d56aa45a,openstack/pycadf,master,I6dc73504ba274e99cbc18b91c631cad2d56aa45a,Updated from global requirements,MERGED,2014-10-11 15:56:24.000000000,2014-10-17 22:10:52.000000000,2014-10-17 22:10:51.000000000,"[{'_account_id': 3}, {'_account_id': 6460}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-10-11 15:56:24.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/fd916997e36c1f9a6bc773a9a6df79fce22a60b2', 'message': 'Updated from global requirements\n\nChange-Id: I6dc73504ba274e99cbc18b91c631cad2d56aa45a\n'}]",0,127786,fd916997e36c1f9a6bc773a9a6df79fce22a60b2,9,3,1,11131,,,0,"Updated from global requirements

Change-Id: I6dc73504ba274e99cbc18b91c631cad2d56aa45a
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/86/127786/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,fd916997e36c1f9a6bc773a9a6df79fce22a60b2,openstack/requirements,"sphinx>=1.1.2,!=1.2.0,!=1.3b1,<1.3","sphinx>=1.1.2,!=1.2.0,<1.3",1,1
openstack%2Ftraining-guides~master~Ia50d73533f350d3d7d75c1455536badea12a3fb4,openstack/training-guides,master,Ia50d73533f350d3d7d75c1455536badea12a3fb4,change to training-cluster-by-script,MERGED,2014-10-16 21:19:41.000000000,2014-10-17 22:00:36.000000000,2014-10-17 22:00:36.000000000,"[{'_account_id': 3}, {'_account_id': 11109}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-10-16 21:19:41.000000000', 'files': ['doc/training-guides/training-cluster-by-script.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/457790ba98704707db885caa007fc7db43ba3929', 'message': 'change to training-cluster-by-script\n\nas a test environment, added “a”\nchanged although to even though\nchanged these to the below\n\nChange-Id: Ia50d73533f350d3d7d75c1455536badea12a3fb4\n'}]",0,129055,457790ba98704707db885caa007fc7db43ba3929,7,3,1,9382,,,0,"change to training-cluster-by-script

as a test environment, added “a”
changed although to even though
changed these to the below

Change-Id: Ia50d73533f350d3d7d75c1455536badea12a3fb4
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/55/129055/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/training-cluster-by-script.xml'],1,457790ba98704707db885caa007fc7db43ba3929,building_training," <para>To use VirtualBox as a test environment, you must attach even though it is recommended because your host machine might fail.</para> the below steps:</para>"," <para>To use VirtualBox as test environment, you must attach although it is recommended because your host machine might fail.</para> these steps:</para>",3,3
openstack%2Fproject-config~master~I46dd60798fa602d37f41de771fd76bb5df21caca,openstack/project-config,master,I46dd60798fa602d37f41de771fd76bb5df21caca,Rename config => system-config in README,MERGED,2014-10-03 21:40:32.000000000,2014-10-17 21:58:46.000000000,2014-10-17 21:45:23.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 5660}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 9624}]","[{'number': 1, 'created': '2014-10-03 21:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/de7ccdc176b444cc16bcea1d0ffc6eb927b37192', 'message': 'Rename config => system-config in README\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch edits the README.\n\nChange-Id: I46dd60798fa602d37f41de771fd76bb5df21caca\n'}, {'number': 2, 'created': '2014-10-09 16:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ef5b388b967bab0932a1dd673dc16676365e605b', 'message': 'Rename config => system-config in README\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch edits the README.\n\nChange-Id: I46dd60798fa602d37f41de771fd76bb5df21caca\n'}, {'number': 3, 'created': '2014-10-14 19:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0210fca68fdacb2818c46e462260ddb21a18f007', 'message': 'Rename config => system-config in README\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch edits the README.\n\nChange-Id: I46dd60798fa602d37f41de771fd76bb5df21caca\n'}, {'number': 4, 'created': '2014-10-15 23:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1e2cc15ec2bf8390fad035626138bd4069260b72', 'message': 'Rename config => system-config in README\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch edits the README.\n\nChange-Id: I46dd60798fa602d37f41de771fd76bb5df21caca\n'}, {'number': 5, 'created': '2014-10-17 19:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8a8aa0b4c913d3e77df93ce8513eac1684ec968c', 'message': 'Rename config => system-config in README\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch edits the README.\n\nChange-Id: I46dd60798fa602d37f41de771fd76bb5df21caca\n'}, {'number': 6, 'created': '2014-10-17 21:28:55.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cc521b35aa223aa76e3ea53545cdc27647f2046f', 'message': 'Rename config => system-config in README\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch edits the README.\n\nChange-Id: I46dd60798fa602d37f41de771fd76bb5df21caca\n'}]",0,126080,cc521b35aa223aa76e3ea53545cdc27647f2046f,27,9,6,6316,,,0,"Rename config => system-config in README

We are renaming the openstack-infra/config repo to
openstack-infra/system-config. This patch edits the README.

Change-Id: I46dd60798fa602d37f41de771fd76bb5df21caca
",git fetch https://review.opendev.org/openstack/project-config refs/changes/80/126080/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,de7ccdc176b444cc16bcea1d0ffc6eb927b37192,config-rename,openstack-infra/system-config puppet modules in order to deploy and,openstack-infra/config puppet modules in order to deploy and,1,1
openstack%2Fproject-config~master~I75de3128e9d179b700df465726ed057439e5401e,openstack/project-config,master,I75de3128e9d179b700df465726ed057439e5401e,Rename config => system-config for nodepool,MERGED,2014-10-03 21:36:14.000000000,2014-10-17 21:58:45.000000000,2014-10-17 21:45:02.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 6786}, {'_account_id': 8411}, {'_account_id': 9624}]","[{'number': 1, 'created': '2014-10-03 21:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e6e846e84cacfcbad679582ea4060e904f45c027', 'message': 'Rename config => system-config for nodepool\n\nWe are renaming openstack-infra/config to\nopenstack-infra/system-config. This patch edits paths for\nnodepool.\n\nChange-Id: I75de3128e9d179b700df465726ed057439e5401e\n'}, {'number': 2, 'created': '2014-10-09 16:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d9f46905f1440f72b8832dfbbf8674e97a27a0b7', 'message': 'Rename config => system-config for nodepool\n\nWe are renaming openstack-infra/config to\nopenstack-infra/system-config. This patch edits paths for\nnodepool.\n\nChange-Id: I75de3128e9d179b700df465726ed057439e5401e\n'}, {'number': 3, 'created': '2014-10-14 19:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d0f9015fd420cd9b5632bdb83812df705e19aa9b', 'message': 'Rename config => system-config for nodepool\n\nWe are renaming openstack-infra/config to\nopenstack-infra/system-config. This patch edits paths for\nnodepool.\n\nChange-Id: I75de3128e9d179b700df465726ed057439e5401e\n'}, {'number': 4, 'created': '2014-10-15 23:50:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/72875e4607f1e2987d30a2b0c093acde004fe262', 'message': 'Rename config => system-config for nodepool\n\nWe are renaming openstack-infra/config to\nopenstack-infra/system-config. This patch edits paths for\nnodepool.\n\nChange-Id: I75de3128e9d179b700df465726ed057439e5401e\n'}, {'number': 5, 'created': '2014-10-17 19:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/418a9af777687000b6b1ac0a2aee1c0cda123ee8', 'message': 'Rename config => system-config for nodepool\n\nWe are renaming openstack-infra/config to\nopenstack-infra/system-config. This patch edits paths for\nnodepool.\n\nChange-Id: I75de3128e9d179b700df465726ed057439e5401e\n'}, {'number': 6, 'created': '2014-10-17 19:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4f945358bde1bb9a230579a589de54b616da5a86', 'message': 'Rename config => system-config for nodepool\n\nWe are renaming openstack-infra/config to\nopenstack-infra/system-config. This patch edits paths for\nnodepool.\n\nChange-Id: I75de3128e9d179b700df465726ed057439e5401e\n'}, {'number': 7, 'created': '2014-10-17 21:28:55.000000000', 'files': ['nodepool/elements/puppet/bin/prepare-node', 'tools/build-dib-in-docker.sh', 'nodepool/scripts/prepare_node.sh', 'nodepool/elements/puppet/install.d/05-puppet', 'nodepool/elements/openstack-repos/extra-data.d/50-create-repo-list'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1cefee6026da9c3edd45f13b7f395a27ad265936', 'message': 'Rename config => system-config for nodepool\n\nWe are renaming openstack-infra/config to\nopenstack-infra/system-config. This patch edits paths for\nnodepool.\n\nChange-Id: I75de3128e9d179b700df465726ed057439e5401e\n'}]",1,126076,1cefee6026da9c3edd45f13b7f395a27ad265936,40,10,7,6316,,,0,"Rename config => system-config for nodepool

We are renaming openstack-infra/config to
openstack-infra/system-config. This patch edits paths for
nodepool.

Change-Id: I75de3128e9d179b700df465726ed057439e5401e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/76/126076/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/scripts/prepare_node.sh', 'nodepool/elements/openstack-repos/extra-data.d/50-create-repo-list']",2,e6e846e84cacfcbad679582ea4060e904f45c027,config-rename, # Clone openstack-infra/system-config again so that we can use it to # build the image without interferring with the slave repo cache. project = 'openstack-infra/system-config', # Clone openstack-infra/config again so that we can use it to build # the image without interferring with the slave repo cache. project = 'openstack-infra/config',5,5
openstack%2Fcongress~master~I70d528132e4dfaaaccf04166bec04db7024eecb6,openstack/congress,master,I70d528132e4dfaaaccf04166bec04db7024eecb6,Added column-references to datalog language,MERGED,2014-10-04 02:35:08.000000000,2014-10-17 21:56:19.000000000,2014-10-17 21:56:19.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 12293}, {'_account_id': 12669}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-10-04 02:35:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/399ffc6df25db7b5af1ca78e6020eca4dc86e340', 'message': 'Added column-references to datalog language\n\nPreviously, tables with many columns were hard to use in rules\nbecause it was hard to remember what the columns were, how many\nof them there were, and which column was which.  In addition,\npolicies were brittle because a change in the table would\nrequire rewriting all the policies.\n\nThis change adds the ability to reference columns by name or\nposition.  (Referencing columns by position is more brittle than\nreferencing by name, but it is less brittle than writing out all the\ncolumns.)  For example, instead of writing...\np(x) :- neutron:networks(x,x1,x2,x3,x4,x5,...,x10)\nwe can now write...\np(x) :- neutron:networks(id=x)\nOf course, this requires declaring the column names for each table,\nwhich the datasources already do.  So while this patch provides\na general mechanism for name or positional references, it does\nnot provide the ability to declare column names for tables defined\nwithin policy.\n\nChange-Id: I70d528132e4dfaaaccf04166bec04db7024eecb6\n'}, {'number': 2, 'created': '2014-10-06 16:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/bbd15c11b567135515ec83295a0c06e6e4408110', 'message': 'Added column-references to datalog language\n\nPreviously, tables with many columns were hard to use in rules\nbecause it was hard to remember what the columns were, how many\nof them there were, and which column was which.  In addition,\npolicies were brittle because a change in the table would\nrequire rewriting all the policies.\n\nThis change adds the ability to reference columns by name or\nposition.  (Referencing columns by position is more brittle than\nreferencing by name, but it is less brittle than writing out all the\ncolumns.)  For example, instead of writing...\n    p(x) :- neutron:networks(x,x1,x2,x3,x4,x5,...,x10)\nwe can now write...\n    p(x) :- neutron:networks(id=x)\nOf course, this requires declaring the column names for each table,\nwhich the datasources already do.  So while this patch provides\na general mechanism for name or positional references, it does\nnot provide the ability to declare column names for tables defined\nwithin policy.\n\nImplements: datalog-column-names\nChange-Id: I70d528132e4dfaaaccf04166bec04db7024eecb6\n'}, {'number': 3, 'created': '2014-10-14 22:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/aae38b4065c20b5041a1aff3dae4177757faff4f', 'message': 'Added column-references to datalog language\n\nPreviously, tables with many columns were hard to use in rules\nbecause it was hard to remember what the columns were, how many\nof them there were, and which column was which.  In addition,\npolicies were brittle because a change in the table would\nrequire rewriting all the policies.\n\nThis change adds the ability to reference columns by name or\nposition.  (Referencing columns by position is more brittle than\nreferencing by name, but it is less brittle than writing out all the\ncolumns.)  For example, instead of writing...\n    p(x) :- neutron:networks(x,x1,x2,x3,x4,x5,...,x10)\nwe can now write...\n    p(x) :- neutron:networks(id=x)\nOf course, this requires declaring the column names for each table,\nwhich the datasources already do.  So while this patch provides\na general mechanism for name or positional references, it does\nnot provide the ability to declare column names for tables defined\nwithin policy.\n\nImplements: datalog-column-names\nChange-Id: I70d528132e4dfaaaccf04166bec04db7024eecb6\n'}, {'number': 4, 'created': '2014-10-16 21:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d20eded6befbc7aed83b5dbf6976ae9a510b2bd0', 'message': 'Added column-references to datalog language\n\nPreviously, tables with many columns were hard to use in rules\nbecause it was hard to remember what the columns were, how many\nof them there were, and which column was which.  In addition,\npolicies were brittle because a change in the table would\nrequire rewriting all the policies.\n\nThis change adds the ability to reference columns by name or\nposition.  (Referencing columns by position is more brittle than\nreferencing by name, but it is less brittle than writing out all the\ncolumns.)  For example, instead of writing...\n    p(x) :- neutron:networks(x,x1,x2,x3,x4,x5,...,x10)\nwe can now write...\n    p(x) :- neutron:networks(id=x)\nOf course, this requires declaring the column names for each table,\nwhich the datasources already do.  So while this patch provides\na general mechanism for name or positional references, it does\nnot provide the ability to declare column names for tables defined\nwithin policy.\n\nImplements: datalog-column-names\nChange-Id: I70d528132e4dfaaaccf04166bec04db7024eecb6\n'}, {'number': 5, 'created': '2014-10-16 21:41:46.000000000', 'files': ['congress/policy/compile.py', 'congress/policy/Congress.g', 'congress/tests/test_congress.py', 'congress/tests/helper.py', 'congress/policy/tests/test_compiler.py', 'congress/policy/runtime.py', 'congress/api/rule_model.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/cca48083b7ab8804e5ede7f7f46f1ea7858e7a5a', 'message': 'Added column-references to datalog language\n\nPreviously, tables with many columns were hard to use in rules\nbecause it was hard to remember what the columns were, how many\nof them there were, and which column was which.  In addition,\npolicies were brittle because a change in the table would\nrequire rewriting all the policies.\n\nThis change adds the ability to reference columns by name or\nposition.  (Referencing columns by position is more brittle than\nreferencing by name, but it is less brittle than writing out all the\ncolumns.)  For example, instead of writing...\n    p(x) :- neutron:networks(x,x1,x2,x3,x4,x5,...,x10)\nwe can now write...\n    p(x) :- neutron:networks(id=x)\nOf course, this requires declaring the column names for each table,\nwhich the datasources already do.  So while this patch provides\na general mechanism for name or positional references, it does\nnot provide the ability to declare column names for tables defined\nwithin policy.\n\nImplements: datalog-column-names\nChange-Id: I70d528132e4dfaaaccf04166bec04db7024eecb6\n'}]",0,126109,cca48083b7ab8804e5ede7f7f46f1ea7858e7a5a,28,6,5,8215,,,0,"Added column-references to datalog language

Previously, tables with many columns were hard to use in rules
because it was hard to remember what the columns were, how many
of them there were, and which column was which.  In addition,
policies were brittle because a change in the table would
require rewriting all the policies.

This change adds the ability to reference columns by name or
position.  (Referencing columns by position is more brittle than
referencing by name, but it is less brittle than writing out all the
columns.)  For example, instead of writing...
    p(x) :- neutron:networks(x,x1,x2,x3,x4,x5,...,x10)
we can now write...
    p(x) :- neutron:networks(id=x)
Of course, this requires declaring the column names for each table,
which the datasources already do.  So while this patch provides
a general mechanism for name or positional references, it does
not provide the ability to declare column names for tables defined
within policy.

Implements: datalog-column-names
Change-Id: I70d528132e4dfaaaccf04166bec04db7024eecb6
",git fetch https://review.opendev.org/openstack/congress refs/changes/09/126109/3 && git format-patch -1 --stdout FETCH_HEAD,"['congress/policy/compile.py', 'congress/policy/Congress.g', 'congress/policy/tests/test_compiler.py']",3,399ffc6df25db7b5af1ca78e6020eca4dc86e340,cols,"from congress.tests import helper class TestParser(unittest.TestCase): def test_column_references_lowlevel(self): """"""Test column-references with low-level checks."""""" # do the first one the painful way, to ensure the parser # is doing something reasonable. ms = compile.ModuleSchemas() ms['nova'] = compile.Schema({'q': ('id', 'name', 'status')}) code = (""p(x) :- nova:q(id=x)"") actual = compile.parse(code, ms) self.assertEqual(len(actual), 1) rule = actual[0] self.assertEqual(len(rule.heads), 1) self.assertEqual(rule.head.table, ""p"") self.assertEqual(len(rule.head.arguments), 1) self.assertEqual(rule.head.arguments[0].name, 'x') self.assertEqual(len(rule.body), 1) lit = rule.body[0] self.assertFalse(lit.is_negated()) self.assertEqual(lit.table, ""nova:q"") self.assertEqual(len(lit.arguments), 3) self.assertEqual(lit.arguments[0].name, 'x') self.assertNotEqual(lit.arguments[0].name, lit.arguments[1].name) self.assertNotEqual(lit.arguments[0].name, lit.arguments[2].name) self.assertNotEqual(lit.arguments[1].name, lit.arguments[2].name) def test_column_references_atom(self): """"""Test column references occurring in a single atom in a rule."""""" ms = compile.ModuleSchemas() ms['nova'] = compile.Schema({'q': ('id', 'name', 'status')}) # Multiple column names code = (""p(x) :- nova:q(id=x, status=y)"") actual = compile.parse(code, ms) correct = ""p(x) :- nova:q(x, w, y)"" eq = helper.datalog_same(helper.pol2str(actual), correct) self.assertTrue(eq, 'Multiple column names') # Multiple column numbers code = (""p(x) :- nova:q(0=x, 1=y, 2=z)"") actual = compile.parse(code, ms) correct = ""p(x) :- nova:q(x, y, z)"" eq = helper.datalog_same(helper.pol2str(actual), correct) self.assertTrue(eq, 'Multiple column numbers') # Mix column names and numbers code = (""p(x) :- nova:q(id=x, 2=y)"") actual = compile.parse(code, ms) correct = ""p(x) :- nova:q(x, w, y)"" eq = helper.datalog_same(helper.pol2str(actual), correct) self.assertTrue(eq, 'Mix names and numbers') # Object constants code = (""p(x) :- nova:q(id=3, 2=2)"") actual = compile.parse(code, ms) correct = ""p(x) :- nova:q(3, w, 2)"" eq = helper.datalog_same(helper.pol2str(actual), correct) self.assertTrue(eq, 'Object constants') # Out of order code = (""p(x, y) :- nova:q(status=y, id=x)"") actual = compile.parse(code, ms) correct = ""p(x, y) :- nova:q(x, z, y)"" eq = helper.datalog_same(helper.pol2str(actual), correct) self.assertTrue(eq, 'Out of order') # Out of order with numbers code = (""p(x, y) :- nova:q(1=y, 0=x)"") actual = compile.parse(code, ms) correct = ""p(x, y) :- nova:q(x, y, z)"" eq = helper.datalog_same(helper.pol2str(actual), correct) self.assertTrue(eq, 'Out of order with numbers') # Positional plus named code = (""p(x, y) :- nova:q(x, status=y)"") actual = compile.parse(code, ms) correct = ""p(x, y) :- nova:q(x, z, y)"" eq = helper.datalog_same(helper.pol2str(actual), correct) self.assertTrue(eq, 'Positional plus named') # Positional plus named 2 code = (""p(x, y, z) :- nova:q(x, y, 2=z)"") actual = compile.parse(code, ms) correct = ""p(x, y, z) :- nova:q(x, y, z)"" eq = helper.datalog_same(helper.pol2str(actual), correct) self.assertTrue(eq, 'Positional plus named 2') # Pure positional (different since we are providing schema) code = (""p(x, y, z) :- nova:q(x, y, z)"") actual = compile.parse(code, ms) correct = ""p(x, y, z) :- nova:q(x, y, z)"" eq = helper.datalog_same(helper.pol2str(actual), correct) self.assertTrue(eq, 'Pure positional') # Pure positional (without schema) code = (""p(x) :- nova:q(x, y, z)"") actual = compile.parse(code, compile.ModuleSchemas()) correct = ""p(x) :- nova:q(x, y, z)"" eq = helper.datalog_same(helper.pol2str(actual), correct) self.assertTrue(eq, 'Pure positional without schema') def test_column_references_atom_errors(self): """"""Test invalid column references occurring in a single atom."""""" ms = compile.ModuleSchemas() ms['nova'] = compile.Schema({'q': ('id', 'name', 'status'), 'r': ('id', 'age', 'weight')}) def check_err(code, errmsg, msg): try: actual = compile.parse(code, ms) self.fail(""Error should have been thrown but was not: "" + msg) except compile.CongressException as e: emsg = ""Err message '{}' should include '{}'"".format( str(e), errmsg) self.assertTrue(errmsg in str(e), msg + "": "" + emsg) check_err( 'p(x) :- q(id=x, 0=y)', 'columns for table q have not been declared', 'Missing schema') check_err( 'p(x) :- nova:q(id=x, birthday=y)', 'column name birthday does not exist', 'Unknown column name') check_err( 'p(x) :- nova:q(id=x, status=x, id=y)', 'two values for column name id', 'Multiple values for column name') check_err( 'p(x) :- nova:q(4=y)', 'column number 4 is too large', 'Large column number') check_err( 'p(x) :- nova:q(4=y, id=w, 4=z)', 'two values for column number 4', 'Multiple values for column number') check_err( 'p(x) :- nova:q(id=x, 0=y)', 'column was given two values by reference parameters', 'Conflict between name and number references') check_err( 'p(x) :- nova:q(x, y, id=z)', 'already provided by position arguments', 'Conflict between name and position') check_err( 'p(x) :- nova:q(x, y, 1=z)', '1 is already provided by position arguments', 'Conflict between name and position') check_err( 'p(x) :- nova:q(x, 1=z, y)', 'positional parameter after a reference parameter', 'Positional parameter after reference parameter') def test_column_references_multiple_atoms(self): """"""Test column references occurring in multiple atoms in a rule."""""" ms = compile.ModuleSchemas() ms['nova'] = compile.Schema({'q': ('id', 'name', 'status'), 'r': ('id', 'age', 'weight')}) # Multiple atoms code = (""p(x) :- nova:q(id=x, 2=y), nova:r(id=x)"") actual = compile.parse(code, ms) correct = ""p(x) :- nova:q(x, x0, y), nova:r(x, y0, y1)"" eq = helper.datalog_same(helper.pol2str(actual), correct) self.assertTrue(eq, 'Multiple atoms') # Multiple atoms sharing column name but different variables code = (""p(x) :- nova:q(id=x), nova:r(id=y)"") actual = compile.parse(code, ms) correct = ""p(x) :- nova:q(x, x0, x1), nova:r(y, y0, y1)"" eq = helper.datalog_same(helper.pol2str(actual), correct) self.assertTrue(eq, 'Multiple atoms shared column name') # Multiple atoms, same table code = (""p(x) :- nova:q(id=x, 2=y), nova:q(id=x)"") actual = compile.parse(code, ms) correct = ""p(x) :- nova:q(x, x0, y), nova:q(x, y0, y1)"" eq = helper.datalog_same(helper.pol2str(actual), correct) self.assertTrue(eq, 'Multiple atoms, same table') ",,469,57
openstack%2Fcongress-specs~master~I98aac7c434db759e25e22d02c0fec22d131fe59f,openstack/congress-specs,master,I98aac7c434db759e25e22d02c0fec22d131fe59f,Spec for adding aggregate support for Datalog,MERGED,2014-10-09 05:02:47.000000000,2014-10-17 21:56:12.000000000,2014-10-17 21:56:12.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 12293}]","[{'number': 1, 'created': '2014-10-09 05:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/b97f4f8f9329d41007b8e91f4ab1981701f79f83', 'message': 'Spec for adding aggregate support for Datalog\n\nDatalog currently does not support using aggregates such as\nCOUNT, SUM, AVERAGE etc. These are required to write more\nreal policies involving aggregate queries like number of\nports in a subnet, number of VMs in a host, Average CPU\nutilization, Average number of bytes etc..\n\nChange-Id: I98aac7c434db759e25e22d02c0fec22d131fe59f\n'}, {'number': 2, 'created': '2014-10-09 05:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/e6a7ef618cb86a0dae589199e49dc25aebcf5873', 'message': 'Spec for adding aggregate support for Datalog\n\nDatalog currently does not support using aggregates such as\nCOUNT, SUM, AVERAGE etc. These are required to write more\nreal policies involving aggregate queries like number of\nports in a subnet, number of VMs in a host, Average CPU\nutilization, Average number of bytes etc..\n\nChange-Id: I98aac7c434db759e25e22d02c0fec22d131fe59f\n'}, {'number': 3, 'created': '2014-10-14 06:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/53828e6e0a532391d190eb1c13cf188cc9205c92', 'message': 'Spec for adding aggregate support for Datalog\n\nDatalog currently does not support using aggregates such as\nCOUNT, SUM, AVERAGE etc. These are required to write more\nreal policies involving aggregate queries like number of\nports in a subnet, number of VMs in a host, Average CPU\nutilization, Average number of bytes etc..\n\nChange-Id: I98aac7c434db759e25e22d02c0fec22d131fe59f\n'}, {'number': 4, 'created': '2014-10-16 06:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/884442cfb59396b94e8a4ec33af33544700aae84', 'message': 'Spec for adding aggregate support for Datalog\n\nDatalog currently does not support using aggregates such as\nCOUNT, SUM, AVERAGE etc. These are required to write more\nreal policies involving aggregate queries like number of\nports in a subnet, number of VMs in a host, Average CPU\nutilization, Average number of bytes etc..\n\nChange-Id: I98aac7c434db759e25e22d02c0fec22d131fe59f\n'}, {'number': 5, 'created': '2014-10-17 05:04:06.000000000', 'files': ['specs/juno/datalog-aggregates.rst'], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/bb6e7d3a94bbaa857aa2cf81b46f674af237bd27', 'message': 'Spec for adding aggregate support for Datalog\n\nDatalog currently does not support using aggregates such as\nCOUNT, SUM, AVERAGE etc. These are required to write more\nreal policies involving aggregate queries like number of\nports in a subnet, number of VMs in a host, Average CPU\nutilization, Average number of bytes etc..\n\nChange-Id: I98aac7c434db759e25e22d02c0fec22d131fe59f\n'}]",8,127134,bb6e7d3a94bbaa857aa2cf81b46f674af237bd27,18,3,5,12293,,,0,"Spec for adding aggregate support for Datalog

Datalog currently does not support using aggregates such as
COUNT, SUM, AVERAGE etc. These are required to write more
real policies involving aggregate queries like number of
ports in a subnet, number of VMs in a host, Average CPU
utilization, Average number of bytes etc..

Change-Id: I98aac7c434db759e25e22d02c0fec22d131fe59f
",git fetch https://review.opendev.org/openstack/congress-specs refs/changes/34/127134/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/datalog-aggregates.rst'],1,b97f4f8f9329d41007b8e91f4ab1981701f79f83,bp/datalog-aggregates,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Support for using Aggregates in Datalog ========================================== https://blueprints.launchpad.net/congress/+spec/datalog-aggregates Aggregates in datalog are required for writing policies involving multiple records in a single ATOM. Problem description =================== * Consider a policy statement ""The maximum number of ports on the Subnet X belonging to tenant Y should not exceed N"" To realize this policy, we need to use aggregations like COUNT, MAX, SUM etc. which span across multiple records of the table. * The current Datalog support in Congress does not allow writing policies with such aggregates. * Also there is no way to simulate aggregations using existing Datalog support. * When a policy engine subscribes to an aggregate on a data source table, the aggregates must be updated every time there is a change in the corresponding table. Proposed change =============== The aggregate support for Datalog allows writing policy atoms of the following form: Example: average(S, A) :- sum(S, A1), count(S, A2), div(A1, A2) * The aggregates like ""SUM"", ""COUNT"", etc must be defined as ANTLR Terms and Congress must be able to parse and compile these terms. * The runtime execution should be able to update tables corresponding to the aggregate terms with computed values Alternatives ------------ N/A Data model impact ----------------- No data model changes are expected. REST API impact --------------- This change does not impact REST APIs as the changes involved will only extend the policy syntax which is fed as input to the policy APIs Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ N/A Other deployer impact --------------------- None. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: Madhu Mohan (mmohan@mvista.com) Other contributors: None Work Items ---------- * Add new terms in Congress.g to allow ANTLR to recognize aggregate keywords * Extend parser/compiler to accept aggregate keywords as part of the rule syntax and validate * Extend runtime to compute aggregate values and update the corresponding tables * Add sufficient tests to validate support for aggregates Dependencies ============ None. Testing ======= We will add tests for DSE as well as DSE when instantiated as described above. * We will start with unit tests for DSE: instantiate two data sources, have one subscribe to the other, and check that publications are seen by the subscriber. * We will simulate changes in the underlying data sources and check that the policy engine receives those updates. * We will change policy and check that policy engine receives data for all the right tables. * We will change the data sources and check that they are properly instantiated in the framework. * We will simulate changes in those new data sources and check that the policy engine receives the proper updates. Documentation Impact ==================== Docs for external consumption will be unchanged. We don't yet have developer docs. References ========== None. ",,159,0
openstack%2Fproject-config~master~I81ff50b18cefa51d2b97e923bedc96cb123a229a,openstack/project-config,master,I81ff50b18cefa51d2b97e923bedc96cb123a229a,Rename config => system-config in tools/,MERGED,2014-10-03 21:38:08.000000000,2014-10-17 21:56:11.000000000,2014-10-17 21:45:14.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 8411}, {'_account_id': 9624}]","[{'number': 1, 'created': '2014-10-03 21:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/12b64467be79ad197fb82405ab85d96ea7862e78', 'message': 'Rename config => system-config in tools/\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch edits scripts in the\ntools directory.\n\nChange-Id: I81ff50b18cefa51d2b97e923bedc96cb123a229a\n'}, {'number': 2, 'created': '2014-10-09 16:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/51c449894d66b866b432932d3af234dfa82fd897', 'message': 'Rename config => system-config in tools/\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch edits scripts in the\ntools directory.\n\nChange-Id: I81ff50b18cefa51d2b97e923bedc96cb123a229a\n'}, {'number': 3, 'created': '2014-10-14 19:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/30be019cd4f1de3d8ba0837ac57e11a917e1638f', 'message': 'Rename config => system-config in tools/\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch edits scripts in the\ntools directory.\n\nChange-Id: I81ff50b18cefa51d2b97e923bedc96cb123a229a\n'}, {'number': 4, 'created': '2014-10-15 23:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8d4fbbdaca71ca861410b55db6bdd623ec511a65', 'message': 'Rename config => system-config in tools/\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch edits scripts in the\ntools directory.\n\nChange-Id: I81ff50b18cefa51d2b97e923bedc96cb123a229a\n'}, {'number': 5, 'created': '2014-10-17 19:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/36e56157f6faef532dcacfd05728d00fb3913d23', 'message': 'Rename config => system-config in tools/\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch edits scripts in the\ntools directory.\n\nChange-Id: I81ff50b18cefa51d2b97e923bedc96cb123a229a\n'}, {'number': 6, 'created': '2014-10-17 21:28:55.000000000', 'files': ['tools/build-image.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5710d6d61d2adbd4db3d692c69731d9b97cfaa0e', 'message': 'Rename config => system-config in tools/\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch edits scripts in the\ntools directory.\n\nChange-Id: I81ff50b18cefa51d2b97e923bedc96cb123a229a\n'}]",0,126077,5710d6d61d2adbd4db3d692c69731d9b97cfaa0e,29,9,6,6316,,,0,"Rename config => system-config in tools/

We are renaming the openstack-infra/config repo to
openstack-infra/system-config. This patch edits scripts in the
tools directory.

Change-Id: I81ff50b18cefa51d2b97e923bedc96cb123a229a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/77/126077/3 && git format-patch -1 --stdout FETCH_HEAD,['tools/build-image.sh'],1,12b64467be79ad197fb82405ab85d96ea7862e78,config-rename,export CONFIG_SOURCE=${CONFIG_SOURCE:-https://git.openstack.org/openstack-infra/system-config},export CONFIG_SOURCE=${CONFIG_SOURCE:-https://git.openstack.org/openstack-infra/config},1,1
openstack%2Fcongress~master~I7cfbd82c721509634c0acfd51e66031af2ed7f2d,openstack/congress,master,I7cfbd82c721509634c0acfd51e66031af2ed7f2d,Added schema error-checking to policy engine,MERGED,2014-09-29 22:12:56.000000000,2014-10-17 21:55:53.000000000,2014-10-17 21:55:53.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 12875}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-09-29 22:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/caedc2b1784749dea8f3751a643c5bc20c9344bb', 'message': 'Added schema error-checking to policy engine\n\nPreviously, datasources declared schemas but the policy engine\nfailed to check if those schemas were being obeyed.  There\nwere no errors thrown for rules using non-existent modules,\nnon-existent tables within a module, or tables within a\nmodule that had the wrong number of arguments.\n\nThis change introduces schemas to the policy engine, and the\nbeginnings of a module system.  Each datasource represents its\nown module, and its own schema.  The error-checking is\naware of modules and the fact that each has its own schema\nand does the appropriate error-checking.  Tables without module\nprefixes need not have a schema declared.\n\nCloses-bug: 1356617\nChange-Id: I7cfbd82c721509634c0acfd51e66031af2ed7f2d\n'}, {'number': 2, 'created': '2014-10-06 16:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/0ea850f77d8200091e9e7214d36c820149d2343b', 'message': 'Added schema error-checking to policy engine\n\nPreviously, datasources declared schemas but the policy engine\nfailed to check if those schemas were being obeyed.  There\nwere no errors thrown for rules using non-existent modules,\nnon-existent tables within a module, or tables within a\nmodule that had the wrong number of arguments.\n\nThis change introduces schemas to the policy engine, and the\nbeginnings of a module system.  Each datasource represents its\nown module, and its own schema.  The error-checking is\naware of modules and the fact that each has its own schema\nand does the appropriate error-checking.  Tables without module\nprefixes need not have a schema declared.\n\nCloses-bug: 1356617\nChange-Id: I7cfbd82c721509634c0acfd51e66031af2ed7f2d\n'}, {'number': 3, 'created': '2014-10-14 22:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/dccebdb27e524062f6a79f1cef2d8d063e7eb07c', 'message': 'Added schema error-checking to policy engine\n\nPreviously, datasources declared schemas but the policy engine\nfailed to check if those schemas were being obeyed.  There\nwere no errors thrown for rules using non-existent modules,\nnon-existent tables within a module, or tables within a\nmodule that had the wrong number of arguments.\n\nThis change introduces schemas to the policy engine, and the\nbeginnings of a module system.  Each datasource represents its\nown module, and its own schema.  The error-checking is\naware of modules and the fact that each has its own schema\nand does the appropriate error-checking.  Tables without module\nprefixes need not have a schema declared.\n\nCloses-bug: 1356617\nChange-Id: I7cfbd82c721509634c0acfd51e66031af2ed7f2d\n'}, {'number': 4, 'created': '2014-10-16 21:24:24.000000000', 'files': ['congress/policy/compile.py', 'congress/dse/tests/test_dse.py', 'congress/tests/test_congress.py', 'congress/datasources/tests/unit/test_neutron_driver.py', 'congress/harness.py', 'congress/datasources/tests/unit/test_nova_driver.py', 'congress/policy/tests/test_compiler.py', 'congress/policy/dsepolicy.py', 'congress/policy/runtime.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/d94a743627e4e5824a37a6591f1dfc4b9389606f', 'message': 'Added schema error-checking to policy engine\n\nPreviously, datasources declared schemas but the policy engine\nfailed to check if those schemas were being obeyed.  There\nwere no errors thrown for rules using non-existent modules,\nnon-existent tables within a module, or tables within a\nmodule that had the wrong number of arguments.\n\nThis change introduces schemas to the policy engine, and the\nbeginnings of a module system.  Each datasource represents its\nown module, and its own schema.  The error-checking is\naware of modules and the fact that each has its own schema\nand does the appropriate error-checking.  Tables without module\nprefixes need not have a schema declared.\n\nCloses-bug: 1356617\nChange-Id: I7cfbd82c721509634c0acfd51e66031af2ed7f2d\n'}]",12,124908,d94a743627e4e5824a37a6591f1dfc4b9389606f,38,5,4,8215,,,0,"Added schema error-checking to policy engine

Previously, datasources declared schemas but the policy engine
failed to check if those schemas were being obeyed.  There
were no errors thrown for rules using non-existent modules,
non-existent tables within a module, or tables within a
module that had the wrong number of arguments.

This change introduces schemas to the policy engine, and the
beginnings of a module system.  Each datasource represents its
own module, and its own schema.  The error-checking is
aware of modules and the fact that each has its own schema
and does the appropriate error-checking.  Tables without module
prefixes need not have a schema declared.

Closes-bug: 1356617
Change-Id: I7cfbd82c721509634c0acfd51e66031af2ed7f2d
",git fetch https://review.opendev.org/openstack/congress refs/changes/08/124908/2 && git format-patch -1 --stdout FETCH_HEAD,"['congress/policy/compile.py', 'congress/dse/tests/test_dse.py', 'congress/tests/test_congress.py', 'congress/datasources/tests/unit/test_neutron_driver.py', 'congress/harness.py', 'congress/datasources/tests/unit/test_nova_driver.py', 'congress/policy/tests/test_compiler.py', 'congress/policy/dsepolicy.py', 'congress/policy/runtime.py']",9,caedc2b1784749dea8f3751a643c5bc20c9344bb,cols," def __init__(self, name=None, abbr=None, module_schema=None): # reference to Runtime class, for cross-theory info # Especially for testing, we don't always need self.module_schema = module_schema def get_arity_includes(self, tablename): """"""Returns the number of arguments for the given TABLENAME or None. Ignores the global_schema. """""" result = th.get_arity_includes(tablename) def get_arity(self, tablename): """"""Returns the number of arguments for the given TABLENAME or None."""""" if self.module_schema is None: return self.get_arity_includes(tablename) (module, name) = self.module_schema.partition(tablename) if module is None: return self.get_arity_includes(tablename) if module in self.module_schema: return self.module_schema[module].arity(tablename) def get_columns(self, tablename): if tablename in self.global_schema: return self.schema[tablename] return None def __init__(self, name=None, abbr=None, module_schema=None): super(TopDownTheory, self).__init__( name=name, abbr=abbr, module_schema=module_schema) def __init__(self, name=None, abbr=None, module_schema=None): super(Database, self).__init__( name=name, abbr=abbr, module_schema=module_schema) errors.extend(compile.fact_errors( event.formula, self.module_schema)) def __init__(self, rules=None, name=None, abbr=None, module_schema=None): super(NonrecursiveRuleTheory, self).__init__( name=name, abbr=abbr, module_schema=module_schema) errors.extend(compile.fact_errors( event.formula, self.module_schema)) else: errors.extend(compile.rule_errors( event.formula, self.module_schema)) errors.extend(compile.fact_errors( event.formula, self.module_schema)) def __init__(self, name=None, abbr=None, module_schema=None): super(DeltaRuleTheory, self).__init__( name=name, abbr=abbr, module_schema=module_schema) def __init__(self, name=None, abbr=None, module_schema=None): super(MaterializedViewTheory, self).__init__( name=name, abbr=abbr, module_schema=module_schema) print ""module_schema: "" + str(self.module_schema) errors.extend(compile.fact_errors( event.formula, self.module_schema)) else: errors.extend(compile.rule_errors( event.formula, self.module_schema)) # schemas for each module self.module_schema = compile.ModuleSchemas() name=self.CLASSIFY_THEORY, abbr='Clas', module_schema=self.module_schema) def set_schema(self, name, schema): """"""Set the schema for module NAME to be SCHEMA."""""" self.module_schema[name] = compile.Schema(schema) "," def __init__(self, name=None, abbr=None): def get_arity(self, tablename): result = th.get_arity(tablename) def __init__(self, name=None, abbr=None): super(TopDownTheory, self).__init__(name=name, abbr=abbr) def __init__(self, name=None, abbr=None): super(Database, self).__init__(name=name, abbr=abbr) errors.extend(compile.fact_errors(event.formula)) def __init__(self, rules=None, name=None, abbr=None): super(NonrecursiveRuleTheory, self).__init__(name=name, abbr=abbr) errors.extend(compile.fact_errors(event.formula)) else: errors.extend(compile.rule_errors(event.formula)) errors.extend(compile.fact_errors(event.formula)) def __init__(self, name=None, abbr=None): super(DeltaRuleTheory, self).__init__(name=name, abbr=abbr) def __init__(self, name=None, abbr=None): super(MaterializedViewTheory, self).__init__(name=name, abbr=abbr) errors.extend(compile.fact_errors(event.formula)) else: errors.extend(compile.rule_errors(event.formula)) name=self.CLASSIFY_THEORY, abbr='Clas')",265,38
openstack%2Fproject-config~master~If70e06a990cf6874bfb1497e36cc41c55154a88a,openstack/project-config,master,If70e06a990cf6874bfb1497e36cc41c55154a88a,Rename config => system-config,MERGED,2014-10-03 21:21:47.000000000,2014-10-17 21:49:58.000000000,2014-10-17 21:30:01.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 6786}, {'_account_id': 8411}, {'_account_id': 9624}]","[{'number': 1, 'created': '2014-10-03 21:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/32826a6bacff8fbec347d899f8e492258cad6fc7', 'message': 'Rename config => system-config\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch does the rename.\n\nChange-Id: If70e06a990cf6874bfb1497e36cc41c55154a88a\n'}, {'number': 2, 'created': '2014-10-03 21:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/926de701c3a2b0ce26219ec9ea7c7e0513c12b1a', 'message': 'Rename config => system-config\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch does the rename.\n\nChange-Id: If70e06a990cf6874bfb1497e36cc41c55154a88a\n'}, {'number': 3, 'created': '2014-10-03 22:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/6ab6c85d8bf2989183e4f4f32eca90b6213191ae', 'message': 'Rename config => system-config\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch does the rename.\n\nChange-Id: If70e06a990cf6874bfb1497e36cc41c55154a88a\n'}, {'number': 4, 'created': '2014-10-09 16:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d63559ed6c8fd155c0926079a8e5d4eecd4cd5fe', 'message': 'Rename config => system-config\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch does the rename.\n\nChange-Id: If70e06a990cf6874bfb1497e36cc41c55154a88a\n'}, {'number': 5, 'created': '2014-10-14 18:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ab66f49b7149225077c920da0bc7765baf917f0d', 'message': 'Rename config => system-config\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch does the rename.\n\nChange-Id: If70e06a990cf6874bfb1497e36cc41c55154a88a\n'}, {'number': 6, 'created': '2014-10-14 18:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e0966fb84d20ef8fbf30560f3b11cf5e512ffd4f', 'message': 'Rename config => system-config\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch does the rename.\n\nChange-Id: If70e06a990cf6874bfb1497e36cc41c55154a88a\n'}, {'number': 7, 'created': '2014-10-14 18:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5e387c17d1dc309c09b0ffaf4a3230aea702fa62', 'message': 'Rename config => system-config\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch does the rename.\n\nChange-Id: If70e06a990cf6874bfb1497e36cc41c55154a88a\n'}, {'number': 8, 'created': '2014-10-17 21:28:55.000000000', 'files': ['jenkins/jobs/infra.yaml', 'gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/defaults.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/33fafbd5f7dac108a3c8c6fb0bd543f81f8ed950', 'message': 'Rename config => system-config\n\nWe are renaming the openstack-infra/config repo to\nopenstack-infra/system-config. This patch does the rename.\n\nChange-Id: If70e06a990cf6874bfb1497e36cc41c55154a88a\n'}]",8,126075,33fafbd5f7dac108a3c8c6fb0bd543f81f8ed950,42,10,8,6316,,,0,"Rename config => system-config

We are renaming the openstack-infra/config repo to
openstack-infra/system-config. This patch does the rename.

Change-Id: If70e06a990cf6874bfb1497e36cc41c55154a88a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/75/126075/8 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/infra.yaml', 'gerritbot/channels.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/defaults.yaml']",5,32826a6bacff8fbec347d899f8e492258cad6fc7,config-rename," <a href=""https://git.openstack.org/cgit/openstack-infra/system-config""> https://git.openstack.org/cgit/openstack-infra/system-config"," <a href=""https://git.openstack.org/cgit/openstack-infra/config""> https://git.openstack.org/cgit/openstack-infra/config",13,13
openstack%2Fproject-config~master~Ia5e5af19ca3d71c81519e74ef082f3a9000d11ec,openstack/project-config,master,Ia5e5af19ca3d71c81519e74ef082f3a9000d11ec,Rename the glance-formula project name,MERGED,2014-09-26 03:21:35.000000000,2014-10-17 21:40:49.000000000,2014-10-17 21:31:33.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6482}, {'_account_id': 6547}, {'_account_id': 6554}, {'_account_id': 6786}, {'_account_id': 7069}, {'_account_id': 7488}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-09-26 03:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7590faf046b32db6e0fdae39af819bf23ec38913', 'message': 'Rename the glance-formula project name\n\nRename the project name from glance-formula to glance-salt-formula.\n\nChange-Id: Ia5e5af19ca3d71c81519e74ef082f3a9000d11ec\n'}, {'number': 2, 'created': '2014-09-26 05:40:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/aa1ca9ec855a3020fce36dbb2ca126f6fa79afaa', 'message': 'Rename the glance-formula project name\n\nRename the project name from glance-formula to glance-salt-formula.\n\nChange-Id: Ia5e5af19ca3d71c81519e74ef082f3a9000d11ec\n'}, {'number': 3, 'created': '2014-10-01 06:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0271ba6c9c80b844a3b92fe6c781593769a6ca8f', 'message': 'Rename the glance-formula project name\n\nRename the project name from glance-formula to glance-salt-formula.\n\nChange-Id: Ia5e5af19ca3d71c81519e74ef082f3a9000d11ec\n'}, {'number': 4, 'created': '2014-10-08 02:35:48.000000000', 'files': ['jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/afd4c2b8234609d19ce675e66841efc36b3adcfd', 'message': 'Rename the glance-formula project name\n\nRename the project name from glance-formula to glance-salt-formula.\n\nChange-Id: Ia5e5af19ca3d71c81519e74ef082f3a9000d11ec\n'}]",0,124252,afd4c2b8234609d19ce675e66841efc36b3adcfd,35,9,4,7488,,,0,"Rename the glance-formula project name

Rename the project name from glance-formula to glance-salt-formula.

Change-Id: Ia5e5af19ca3d71c81519e74ef082f3a9000d11ec
",git fetch https://review.opendev.org/openstack/project-config refs/changes/52/124252/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",3,7590faf046b32db6e0fdae39af819bf23ec38913,rename_glance-formula, - name: stackforge/glance-salt-formula, - name: stackforge/glance-formula,3,3
openstack%2Fproject-config~master~Iea621a1cbc7f56ce3658023c9a78eb036872e080,openstack/project-config,master,Iea621a1cbc7f56ce3658023c9a78eb036872e080,Rename the keystone-formula project name,MERGED,2014-10-02 03:02:46.000000000,2014-10-17 21:35:45.000000000,2014-10-17 21:31:51.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 7488}]","[{'number': 1, 'created': '2014-10-02 03:02:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ddd92afd3ed880e8515ae131288eb585b764829b', 'message': 'Rename the keystone-formula project name\n\nRename the project name from keystone-formula to keystone-salt-formula.\n\nChange-Id: Iea621a1cbc7f56ce3658023c9a78eb036872e080\n'}, {'number': 2, 'created': '2014-10-08 02:38:47.000000000', 'files': ['jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3493ed8146eb7d86f4d710618932552a0f0a781a', 'message': 'Rename the keystone-formula project name\n\nRename the project name from keystone-formula to keystone-salt-formula.\n\nChange-Id: Iea621a1cbc7f56ce3658023c9a78eb036872e080\n'}]",0,125546,3493ed8146eb7d86f4d710618932552a0f0a781a,15,5,2,6786,,,0,"Rename the keystone-formula project name

Rename the project name from keystone-formula to keystone-salt-formula.

Change-Id: Iea621a1cbc7f56ce3658023c9a78eb036872e080
",git fetch https://review.opendev.org/openstack/project-config refs/changes/46/125546/2 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",3,ddd92afd3ed880e8515ae131288eb585b764829b,rename_keystone_formual, - name: stackforge/keystone-salt-formula, - name: stackforge/keystone-formula,4,4
openstack%2Fdevstack~stable%2Fjuno~I912b79983b11d79a2f2cfca499a48625b7cef13e,openstack/devstack,stable/juno,I912b79983b11d79a2f2cfca499a48625b7cef13e,Set defaults for stable/juno branch,MERGED,2014-10-17 17:21:57.000000000,2014-10-17 20:35:10.000000000,2014-10-17 20:35:10.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 9009}]","[{'number': 1, 'created': '2014-10-17 17:21:57.000000000', 'files': ['run_tests.sh', '.gitreview', 'stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/d265cbdc640d455a4feb62c4f98b7f609c3522f7', 'message': 'Set defaults for stable/juno branch\n\nChange-Id: I912b79983b11d79a2f2cfca499a48625b7cef13e\n'}]",0,129334,d265cbdc640d455a4feb62c4f98b7f609c3522f7,8,3,1,970,,,0,"Set defaults for stable/juno branch

Change-Id: I912b79983b11d79a2f2cfca499a48625b7cef13e
",git fetch https://review.opendev.org/openstack/devstack refs/changes/34/129334/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', '.gitreview', 'stackrc']",3,d265cbdc640d455a4feb62c4f98b7f609c3522f7,,CEILOMETER_BRANCH=${CEILOMETER_BRANCH:-stable/juno}CINDER_BRANCH=${CINDER_BRANCH:-stable/juno}GLANCE_BRANCH=${GLANCE_BRANCH:-stable/juno}HEAT_BRANCH=${HEAT_BRANCH:-stable/juno}HORIZON_BRANCH=${HORIZON_BRANCH:-stable/juno}IRONIC_BRANCH=${IRONIC_BRANCH:-stable/juno}KEYSTONE_BRANCH=${KEYSTONE_BRANCH:-stable/juno}NEUTRON_BRANCH=${NEUTRON_BRANCH:-stable/juno}NOVA_BRANCH=${NOVA_BRANCH:-stable/juno}SWIFT_BRANCH=${SWIFT_BRANCH:-stable/juno}TROVE_BRANCH=${TROVE_BRANCH:-stable/juno}REQUIREMENTS_BRANCH=${REQUIREMENTS_BRANCH:-stable/juno},CEILOMETER_BRANCH=${CEILOMETER_BRANCH:-master}CINDER_BRANCH=${CINDER_BRANCH:-master}GLANCE_BRANCH=${GLANCE_BRANCH:-master}HEAT_BRANCH=${HEAT_BRANCH:-master}HORIZON_BRANCH=${HORIZON_BRANCH:-master}IRONIC_BRANCH=${IRONIC_BRANCH:-master}KEYSTONE_BRANCH=${KEYSTONE_BRANCH:-master}NEUTRON_BRANCH=${NEUTRON_BRANCH:-master}NOVA_BRANCH=${NOVA_BRANCH:-master}SWIFT_BRANCH=${SWIFT_BRANCH:-master}TROVE_BRANCH=${TROVE_BRANCH:-master}REQUIREMENTS_BRANCH=${REQUIREMENTS_BRANCH:-master},14,13
openstack%2Fglance~master~I36d7425c033403dab030bf79c5249a90e0865e7e,openstack/glance,master,I36d7425c033403dab030bf79c5249a90e0865e7e,Add logging to image_members and image_tags,MERGED,2014-07-29 14:28:16.000000000,2014-10-17 20:20:29.000000000,2014-10-17 20:20:28.000000000,"[{'_account_id': 3}, {'_account_id': 4992}, {'_account_id': 5202}, {'_account_id': 6549}, {'_account_id': 8127}, {'_account_id': 8158}, {'_account_id': 8759}, {'_account_id': 11600}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-07-29 14:28:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fd61d3fcdb2ddb728ec71c221bc2f159fa2dabe6', 'message': 'Add logging to image_members and image_tags\n\nAdding exceptions logging in image_members and image_tags modules in\nREST API.\n\nChange-Id: I36d7425c033403dab030bf79c5249a90e0865e7e\nCloses-Bug: 1349845\n'}, {'number': 2, 'created': '2014-08-04 10:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8fde08fe0eb57ca033bb6a15510e46df85ed9800', 'message': 'Add logging to image_members and image_tags\n\nAdding exceptions logging in image_members and image_tags modules in\nREST API.\n\nChange-Id: I36d7425c033403dab030bf79c5249a90e0865e7e\nCloses-Bug: 1349845\nRelated to bp refactoring-glance-logging\nDocImpact\n'}, {'number': 3, 'created': '2014-08-05 08:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e91085d74b287023fa1cc9a40ccb71f022bffe51', 'message': 'Add logging to image_members and image_tags\n\nAdding exceptions logging in image_members and image_tags modules in\nREST API.\n\nChange-Id: I36d7425c033403dab030bf79c5249a90e0865e7e\nCloses-Bug: 1349845\nRelated to bp refactoring-glance-logging\nDocImpact\n'}, {'number': 4, 'created': '2014-08-21 15:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/62bead68d50b6eadb30b71467f3a24aa9b5fe31a', 'message': 'Add logging to image_members and image_tags\n\nAdding exceptions logging in image_members and image_tags modules in\nREST API.\n\nChange-Id: I36d7425c033403dab030bf79c5249a90e0865e7e\nCloses-Bug: 1349845\nRelated to bp refactoring-glance-logging\nDocImpact\n'}, {'number': 5, 'created': '2014-08-26 07:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f57a2dcd35b929f6fa8b9e99ef1fd58ac087a1b2', 'message': 'Add logging to image_members and image_tags\n\nAdding exceptions logging in image_members and image_tags modules in\nREST API.\n\nChange-Id: I36d7425c033403dab030bf79c5249a90e0865e7e\nCloses-Bug: 1349845\nRelated to bp refactoring-glance-logging\nDocImpact\n'}, {'number': 6, 'created': '2014-09-16 14:50:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d0413c960778405ffafa8caeec012f8d9645981a', 'message': 'Add logging to image_members and image_tags\n\nAdding exceptions logging in image_members and image_tags modules in\nREST API.\n\nChange-Id: I36d7425c033403dab030bf79c5249a90e0865e7e\nCloses-Bug: 1349845\nRelated to bp refactoring-glance-logging\nDocImpact\n'}, {'number': 7, 'created': '2014-10-16 11:52:51.000000000', 'files': ['glance/api/v2/image_members.py', 'glance/api/v2/image_tags.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/dbc562ac3312c09fce83b8beabfdadb8d617ce1e', 'message': 'Add logging to image_members and image_tags\n\nAdding exceptions logging in image_members and image_tags modules in\nREST API.\n\nChange-Id: I36d7425c033403dab030bf79c5249a90e0865e7e\nCloses-Bug: 1349845\nRelated to bp refactoring-glance-logging\nDocImpact\n'}]",2,110303,dbc562ac3312c09fce83b8beabfdadb8d617ce1e,36,9,7,11600,,,0,"Add logging to image_members and image_tags

Adding exceptions logging in image_members and image_tags modules in
REST API.

Change-Id: I36d7425c033403dab030bf79c5249a90e0865e7e
Closes-Bug: 1349845
Related to bp refactoring-glance-logging
DocImpact
",git fetch https://review.opendev.org/openstack/glance refs/changes/03/110303/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/api/v2/image_members.py', 'glance/api/v2/image_tags.py']",2,fd61d3fcdb2ddb728ec71c221bc2f159fa2dabe6,bug/1349845,from glance.openstack.common import gettextutils import glance.openstack.common.log as loggingLOG = logging.getLogger(__name__) _LI = gettextutils._LI LOG.info(utils.exception_to_str(e)) LOG.info(utils.exception_to_str(e)) LOG.info(utils.exception_to_str(e)) LOG.info(utils.exception_to_str(e)) LOG.info(utils.exception_to_str(e)),,29,0
openstack%2Fkolla~master~Id8c0137a271faf832b736e6e1cda0b87bec7e5c2,openstack/kolla,master,Id8c0137a271faf832b736e6e1cda0b87bec7e5c2,Add nova-novncproxy as a kube service,MERGED,2014-10-17 20:00:56.000000000,2014-10-17 20:14:24.000000000,2014-10-17 20:14:23.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 8745}]","[{'number': 1, 'created': '2014-10-17 20:00:56.000000000', 'files': ['k8s/service/nova-novncproxy-service.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/5bf71ab0a4d3d3a0b9e3e0ac0a35ccea3929dd1b', 'message': 'Add nova-novncproxy as a kube service\n\nCreate the nova-novncproxy service for kubernetes.\n\nChange-Id: Id8c0137a271faf832b736e6e1cda0b87bec7e5c2\n'}]",0,129375,5bf71ab0a4d3d3a0b9e3e0ac0a35ccea3929dd1b,7,3,1,10419,,,0,"Add nova-novncproxy as a kube service

Create the nova-novncproxy service for kubernetes.

Change-Id: Id8c0137a271faf832b736e6e1cda0b87bec7e5c2
",git fetch https://review.opendev.org/openstack/kolla refs/changes/75/129375/1 && git format-patch -1 --stdout FETCH_HEAD,['k8s/service/nova-novncproxy-service.yaml'],1,5bf71ab0a4d3d3a0b9e3e0ac0a35ccea3929dd1b,novnc-service,apiVersion: v1beta1 containerPort: 6080 id: nova-novncproxy kind: Service port: 6080 selector: name: nova-controller ,,7,0
openstack%2Fgrenade~master~I95ddcd3a16bd08c03385eab10939f02e7c209888,openstack/grenade,master,I95ddcd3a16bd08c03385eab10939f02e7c209888,Run dstat during the upgrade process,MERGED,2014-09-07 03:17:04.000000000,2014-10-17 20:14:16.000000000,2014-10-17 20:14:15.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2750}, {'_account_id': 3153}, {'_account_id': 5196}]","[{'number': 1, 'created': '2014-09-07 03:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/dff746bbb61cb2ae6e6f318e127f0ba069cb80f9', 'message': ""Run dstat during the upgrade process\n\nWhen using devstack directly we run dstat to monitor the machine stats\nto make sure we aren't overloading the machine too much. Do the same\nthing starting with the upgrade in grenade.\n\nChange-Id: I95ddcd3a16bd08c03385eab10939f02e7c209888\n""}, {'number': 2, 'created': '2014-09-29 22:12:34.000000000', 'files': ['grenade.sh', 'start-dstat'], 'web_link': 'https://opendev.org/openstack/grenade/commit/21f30b0d90e084bf47fe8288b94c5d645c4be4ee', 'message': ""Run dstat during the upgrade process\n\nWhen using devstack directly we run dstat to monitor the machine stats\nto make sure we aren't overloading the machine too much. Do the same\nthing starting with the upgrade in grenade.\n\nChange-Id: I95ddcd3a16bd08c03385eab10939f02e7c209888\n""}]",1,119591,21f30b0d90e084bf47fe8288b94c5d645c4be4ee,13,5,2,1849,,,0,"Run dstat during the upgrade process

When using devstack directly we run dstat to monitor the machine stats
to make sure we aren't overloading the machine too much. Do the same
thing starting with the upgrade in grenade.

Change-Id: I95ddcd3a16bd08c03385eab10939f02e7c209888
",git fetch https://review.opendev.org/openstack/grenade refs/changes/91/119591/2 && git format-patch -1 --stdout FETCH_HEAD,"['grenade.sh', 'start-dstat']",2,dff746bbb61cb2ae6e6f318e127f0ba069cb80f9,dstat,"#!/usr/bin/env bash # ``start-dstat`` # Keep track of the grenade directory GRENADE_DIR=$(cd $(dirname ""$0"") && pwd) # Import common functions source $GRENADE_DIR/functions # Determine what system we are running on. This provides ``os_VENDOR``, # ``os_RELEASE``, ``os_UPDATE``, ``os_PACKAGE``, ``os_CODENAME`` # and ``DISTRO`` GetDistro # Source params source $GRENADE_DIR/grenaderc # For debugging set -o xtrace # start dstat # ============ cd $TARGET_DEVSTACK_DIR source $TARGET_DEVSTACK_DIR/functions source $TARGET_DEVSTACK_DIR/stackrc source $TARGET_DEVSTACK_DIR/lib/dstat start_dstat ",,35,0
openstack%2Fswift~feature%2Fec~Id38f7e93e3473f19ff88123ae0501000ed9b2e89,openstack/swift,feature/ec,Id38f7e93e3473f19ff88123ae0501000ed9b2e89,Allow sending object metadata after data,MERGED,2014-10-15 01:17:47.000000000,2014-10-17 20:14:03.000000000,2014-10-17 20:14:03.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 7479}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-10-15 01:17:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2c8a95f411f89c2b71b816d2664770b2a6833f5e', 'message': 'Allow sending object metadata after data\n\nThis lets the proxy server send object metadata to the object server\nafter the object data. This is necessary for EC, as it allows us to\ncompute the etag of the object in the proxy server and still store it\nwith the object.\n\nThe wire format is a multipart MIME document. For sanity during a\nrolling upgrade, the multipart MIME document is only sent to the\nobject server if it indicates, via 100 Continue header, that it knows\nhow to consume it.\n\nExample 1 (new proxy, new obj server):\n\n   proxy: PUT /p/a/c/o\n          X-Backend-Obj-Metadata-Footer: yes\n\n     obj: 100 Continue\n        X-Obj-Metadata-Footer: yes\n\n   proxy: --MIMEmimeMIMEmime...\n\nExample2: (new proxy, old obj server)\n\n   proxy: PUT /p/a/c/o\n          X-Backend-Obj-Metadata-Footer: yes\n\n     obj: 100 Continue\n\n   proxy: <obj body>\n\nChange-Id: Id38f7e93e3473f19ff88123ae0501000ed9b2e89\n'}, {'number': 2, 'created': '2014-10-15 17:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6d5f6367570010bc70bd43dde4b3977262daa373', 'message': 'Allow sending object metadata after data\n\nThis lets the proxy server send object metadata to the object server\nafter the object data. This is necessary for EC, as it allows us to\ncompute the etag of the object in the proxy server and still store it\nwith the object.\n\nThe wire format is a multipart MIME document. For sanity during a\nrolling upgrade, the multipart MIME document is only sent to the\nobject server if it indicates, via 100 Continue header, that it knows\nhow to consume it.\n\nExample 1 (new proxy, new obj server):\n\n   proxy: PUT /p/a/c/o\n          X-Backend-Obj-Metadata-Footer: yes\n\n     obj: 100 Continue\n        X-Obj-Metadata-Footer: yes\n\n   proxy: --MIMEmimeMIMEmime...\n\nExample2: (new proxy, old obj server)\n\n   proxy: PUT /p/a/c/o\n          X-Backend-Obj-Metadata-Footer: yes\n\n     obj: 100 Continue\n\n   proxy: <obj body>\n\nChange-Id: Id38f7e93e3473f19ff88123ae0501000ed9b2e89\n'}, {'number': 3, 'created': '2014-10-16 21:47:15.000000000', 'files': ['swift/obj/server.py', 'test/unit/proxy/test_server.py', 'test/unit/proxy/controllers/test_obj.py', 'test/unit/obj/test_server.py', 'swift/common/middleware/formpost.py', 'swift/proxy/controllers/obj.py', 'swift/common/exceptions.py', 'swift/common/middleware/dlo.py', 'test/unit/proxy/test_mem_server.py', 'swift/common/utils.py', 'swift/common/middleware/slo.py', 'test/unit/proxy/test_sysmeta.py', 'swift/common/swob.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/04d87c8ca1705b850301a537db7eca6f05355e1f', 'message': 'Allow sending object metadata after data\n\nThis lets the proxy server send object metadata to the object server\nafter the object data. This is necessary for EC, as it allows us to\ncompute the etag of the object in the proxy server and still store it\nwith the object.\n\nThe wire format is a multipart MIME document. For sanity during a\nrolling upgrade, the multipart MIME document is only sent to the\nobject server if it indicates, via 100 Continue header, that it knows\nhow to consume it.\n\nExample 1 (new proxy, new obj server):\n\n   proxy: PUT /p/a/c/o\n          X-Backend-Obj-Metadata-Footer: yes\n\n     obj: 100 Continue\n        X-Obj-Metadata-Footer: yes\n\n   proxy: --MIMEmimeMIMEmime...\n\nExample2: (new proxy, old obj server)\n\n   proxy: PUT /p/a/c/o\n          X-Backend-Obj-Metadata-Footer: yes\n\n     obj: 100 Continue\n\n   proxy: <obj body>\n\nChange-Id: Id38f7e93e3473f19ff88123ae0501000ed9b2e89\n'}]",1,128491,04d87c8ca1705b850301a537db7eca6f05355e1f,17,5,3,2622,,,0,"Allow sending object metadata after data

This lets the proxy server send object metadata to the object server
after the object data. This is necessary for EC, as it allows us to
compute the etag of the object in the proxy server and still store it
with the object.

The wire format is a multipart MIME document. For sanity during a
rolling upgrade, the multipart MIME document is only sent to the
object server if it indicates, via 100 Continue header, that it knows
how to consume it.

Example 1 (new proxy, new obj server):

   proxy: PUT /p/a/c/o
          X-Backend-Obj-Metadata-Footer: yes

     obj: 100 Continue
        X-Obj-Metadata-Footer: yes

   proxy: --MIMEmimeMIMEmime...

Example2: (new proxy, old obj server)

   proxy: PUT /p/a/c/o
          X-Backend-Obj-Metadata-Footer: yes

     obj: 100 Continue

   proxy: <obj body>

Change-Id: Id38f7e93e3473f19ff88123ae0501000ed9b2e89
",git fetch https://review.opendev.org/openstack/swift refs/changes/91/128491/3 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/server.py', 'test/unit/proxy/test_server.py', 'test/unit/proxy/controllers/test_obj.py', 'test/unit/obj/test_server.py', 'swift/common/middleware/formpost.py', 'swift/proxy/controllers/obj.py', 'swift/common/exceptions.py', 'swift/common/middleware/dlo.py', 'requirements.txt', 'test/unit/proxy/test_mem_server.py', 'swift/common/utils.py', 'swift/common/middleware/slo.py', 'test/unit/proxy/test_sysmeta.py', 'swift/common/swob.py', 'test/unit/common/test_utils.py']",15,2c8a95f411f89c2b71b816d2664770b2a6833f5e,ec-putter, self.assertTrue('invalid starting boundary' in str(exc)) self.assertTrue('--unique' in str(exc))," self.assertEquals(str(exc), 'invalid starting boundary')",742,113
openstack%2Fpython-openstackclient~master~If9cb9a0c45a3a577082a5cdbb793769211f20ebb,openstack/python-openstackclient,master,If9cb9a0c45a3a577082a5cdbb793769211f20ebb,Move plugin stuff to clientmanager,MERGED,2014-10-13 17:35:26.000000000,2014-10-17 20:13:56.000000000,2014-10-17 20:13:55.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-10-13 17:35:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/46de7b4b1280f00df8fd1b0ac6e9de589d0b5b72', 'message': 'Move plugin stuff to clientmanager\n\nBring all plugin initialization into the clientmanager module.\n\nChange-Id: If9cb9a0c45a3a577082a5cdbb793769211f20ebb\n'}, {'number': 2, 'created': '2014-10-14 04:10:29.000000000', 'files': ['openstackclient/shell.py', 'openstackclient/common/clientmanager.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/897418edca52d9856ef7381a5822fce3bcf8a804', 'message': 'Move plugin stuff to clientmanager\n\nThe OSC plugins work by adding an object as an attribute to a\nClientManager instance.  The initialization and management of\nthos plugins belongs in clientmanager.py.\n\nAt this point the only part not moved is the API version dict\ninitialization bcause the timing and connection to the\nCommandManager initialization.  It gets refactored anyway when\nAPI discovery becomes operational.\n\nChange-Id: If9cb9a0c45a3a577082a5cdbb793769211f20ebb\n'}]",1,128023,897418edca52d9856ef7381a5822fce3bcf8a804,11,4,2,970,,,0,"Move plugin stuff to clientmanager

The OSC plugins work by adding an object as an attribute to a
ClientManager instance.  The initialization and management of
thos plugins belongs in clientmanager.py.

At this point the only part not moved is the API version dict
initialization bcause the timing and connection to the
CommandManager initialization.  It gets refactored anyway when
API discovery becomes operational.

Change-Id: If9cb9a0c45a3a577082a5cdbb793769211f20ebb
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/23/128023/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/shell.py', 'openstackclient/common/clientmanager.py']",2,46de7b4b1280f00df8fd1b0ac6e9de589d0b5b72,client-manager-init,"PLUGIN_MODULES = [] def get_plugin_modules(group): """"""Find plugin entry points"""""" LOG.debug('Found plugin %r', ep.name) # Add the plugin to the ClientManager def build_plugin_option_parser(parser): """"""Add plugin options to the parser"""""" # Loop through extensions to get parser additions for mod in PLUGIN_MODULES: parser = mod.build_option_parser(parser) return parser # Get list of base modules PLUGIN_MODULES = get_plugin_modules( 'openstack.cli.base', ) # Append list of extension modules PLUGIN_MODULES.extend(get_plugin_modules( 'openstack.cli.extension', ))","def get_extension_modules(group): """"""Add extension clients"""""" LOG.debug('found extension %r', ep.name)",28,18
openstack%2Frequirements~stable%2Ficehouse~I4fc46f963c6e9819efe2a77b0610f59fd1174773,openstack/requirements,stable/icehouse,I4fc46f963c6e9819efe2a77b0610f59fd1174773,Add dib-utils,MERGED,2014-10-17 09:43:53.000000000,2014-10-17 20:12:34.000000000,2014-10-17 20:12:33.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1420}, {'_account_id': 1955}, {'_account_id': 6928}, {'_account_id': 8788}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-10-17 09:43:53.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e6e82f09ee6f58a317cbb467d06758cb69a31277', 'message': 'Add dib-utils\n\nThis project was split off diskimage-builder to contain files used\nby other projects too.  In order to add it as a dependency of those\nprojects, it needs to be here.\n\nConflicts:\n\tglobal-requirements.txt\n\nChange-Id: I4fc46f963c6e9819efe2a77b0610f59fd1174773\n(cherry picked from commit 97316fa308e2cd89f1b4506086b7a1f90a84cf13)\n'}]",0,129190,e6e82f09ee6f58a317cbb467d06758cb69a31277,12,7,1,9656,,,0,"Add dib-utils

This project was split off diskimage-builder to contain files used
by other projects too.  In order to add it as a dependency of those
projects, it needs to be here.

Conflicts:
	global-requirements.txt

Change-Id: I4fc46f963c6e9819efe2a77b0610f59fd1174773
(cherry picked from commit 97316fa308e2cd89f1b4506086b7a1f90a84cf13)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/90/129190/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,e6e82f09ee6f58a317cbb467d06758cb69a31277,,dib-utils # Apache-2.0,,1,0
openstack%2Fnova~stable%2Ficehouse~I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc,openstack/nova,stable/icehouse,I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc,Fix XML UnicodeEncode serialization error,MERGED,2014-10-01 15:03:16.000000000,2014-10-17 20:02:25.000000000,2014-10-17 20:02:23.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5196}, {'_account_id': 5292}, {'_account_id': 6873}, {'_account_id': 7198}, {'_account_id': 10118}]","[{'number': 1, 'created': '2014-10-01 15:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c2b6336030d1fa05480007311029fbddfe55614f', 'message': ""Fix XML UnicodeEncode serialization error\n\nThe generic Nova XMLSerializer code will currently attempt\nto cast to str the value for all leaf nodes. This patch\nensures that no attempt is made to convert unicode which\ncan cause a UnicodeEncode error. We don't need to convert\nunicode for XML text and regardless we encode to UTF-8 at\na later point.\n\nChange-Id: I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc\nCloses-Bug: #1279172\n(cherry picked from commit 53fe8696314fb73ca9943fce998d96fa6d0414b4)\n""}, {'number': 2, 'created': '2014-10-17 16:07:32.000000000', 'files': ['nova/api/openstack/wsgi.py', 'nova/tests/api/openstack/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7cdb643cb3100dd100de471b5026b13ab94c21f7', 'message': ""Fix XML UnicodeEncode serialization error\n\nThe generic Nova XMLSerializer code will currently attempt\nto cast to str the value for all leaf nodes. This patch\nensures that no attempt is made to convert unicode which\ncan cause a UnicodeEncode error. We don't need to convert\nunicode for XML text and regardless we encode to UTF-8 at\na later point.\n\nChange-Id: I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc\nCloses-Bug: #1279172\n(cherry picked from commit 53fe8696314fb73ca9943fce998d96fa6d0414b4)\n(cherry picked from commit 3136cfc11f034cf0b17888f7348e80d38d563c2e)\n""}]",0,125374,7cdb643cb3100dd100de471b5026b13ab94c21f7,13,7,2,6873,,,0,"Fix XML UnicodeEncode serialization error

The generic Nova XMLSerializer code will currently attempt
to cast to str the value for all leaf nodes. This patch
ensures that no attempt is made to convert unicode which
can cause a UnicodeEncode error. We don't need to convert
unicode for XML text and regardless we encode to UTF-8 at
a later point.

Change-Id: I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc
Closes-Bug: #1279172
(cherry picked from commit 53fe8696314fb73ca9943fce998d96fa6d0414b4)
(cherry picked from commit 3136cfc11f034cf0b17888f7348e80d38d563c2e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/125374/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/wsgi.py', 'nova/tests/api/openstack/test_wsgi.py']",2,c2b6336030d1fa05480007311029fbddfe55614f,bug/1279172-icehouse," def test_xml_contains_unicode(self): input_dict = dict(test=u'\u89e3\u7801') expected_xml = '<test>\xe8\xa7\xa3\xe7\xa0\x81</test>' serializer = wsgi.XMLDictSerializer() result = serializer.serialize(input_dict) result = result.replace('\n', '').replace(' ', '') self.assertEqual(expected_xml, result) ",,11,1
openstack%2Fhorizon~master~I6a493989d7280eaa2a1c999a9d1be4365aa77d52,openstack/horizon,master,I6a493989d7280eaa2a1c999a9d1be4365aa77d52,Remove selenium dependency when not using selenium tests,MERGED,2014-10-08 00:30:55.000000000,2014-10-17 20:02:12.000000000,2014-10-17 20:02:11.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 6476}, {'_account_id': 6825}, {'_account_id': 8040}, {'_account_id': 9981}]","[{'number': 1, 'created': '2014-10-08 00:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/83fd6a7631a6a3ea6adbebca725a5f19c2c1796c', 'message': 'Remove selenium dependency when not using selenium tests\n\nCloses-Bug: 1377372\nChange-Id: I6a493989d7280eaa2a1c999a9d1be4365aa77d52\n'}, {'number': 2, 'created': '2014-10-08 16:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7d9995e6a6896a2bf58f1ecfae1d52e931f816d7', 'message': 'Remove selenium dependency when not using selenium tests\n\nCloses-Bug: 1377372\nChange-Id: I6a493989d7280eaa2a1c999a9d1be4365aa77d52\n'}, {'number': 3, 'created': '2014-10-08 18:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/45d8dde18d625cce201315d9398efdeb4618a419', 'message': 'Remove selenium dependency when not using selenium tests\n\nCloses-Bug: 1377372\nChange-Id: I6a493989d7280eaa2a1c999a9d1be4365aa77d52\n'}, {'number': 4, 'created': '2014-10-09 23:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2cd2fd0cbda93f05ae51c40f55c6b2b0543c0046', 'message': 'Remove selenium dependency when not using selenium tests\n\nCloses-Bug: 1377372\nChange-Id: I6a493989d7280eaa2a1c999a9d1be4365aa77d52\n'}, {'number': 5, 'created': '2014-10-10 15:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/21d94285a1741b52e4990ed7923511cc882e53b5', 'message': 'Remove selenium dependency when not using selenium tests\n\nCloses-Bug: 1377372\nChange-Id: I6a493989d7280eaa2a1c999a9d1be4365aa77d52\n'}, {'number': 6, 'created': '2014-10-10 17:45:36.000000000', 'files': ['horizon/test/webdriver.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/aad4565d9f64a97f10a9528f2c0efc5039343f2c', 'message': 'Remove selenium dependency when not using selenium tests\n\nCloses-Bug: 1377372\nChange-Id: I6a493989d7280eaa2a1c999a9d1be4365aa77d52\n'}]",5,126777,aad4565d9f64a97f10a9528f2c0efc5039343f2c,29,8,6,6825,,,0,"Remove selenium dependency when not using selenium tests

Closes-Bug: 1377372
Change-Id: I6a493989d7280eaa2a1c999a9d1be4365aa77d52
",git fetch https://review.opendev.org/openstack/horizon refs/changes/77/126777/6 && git format-patch -1 --stdout FETCH_HEAD,['horizon/test/webdriver.py'],1,83fd6a7631a6a3ea6adbebca725a5f19c2c1796c,bug/1377372,"import osfrom django.utils import unittest with_sel = os.environ.get('WITH_SELENIUM', False) if with_sel: from selenium.common import exceptions as selenium_exceptions from selenium.webdriver import firefox @unittest.skipUnless(os.environ.get('WITH_SELENIUM', False), ""The WITH_SELENIUM env variable is not set."") class FirefoxBinary(firefox.firefox_binary.FirefoxBinary): """"""Workarounds selenium firefox issues. There is race condition in the way firefox is spawned. The exact cause hasn't been properly diagnosed yet but it's around: - getting a free port from the OS with selenium.webdriver.common.utils free_port(), - release the port immediately but record it in ff prefs so that ff can listen on that port for the internal http server. It has been observed that this leads to hanging processes for 'firefox -silent'. """""" def _start_from_profile_path(self, path): self._firefox_env[""XRE_PROFILE_PATH""] = path if platform.system().lower() == 'linux': self._modify_link_library_path() command = [self._start_cmd, ""-silent""] if self.command_line is not None: for cli in self.command_line: command.append(cli) # The following exists upstream and is known to create hanging firefoxes, # leading to zombies. # subprocess.Popen(command, stdout=self._log_file, # stderr=subprocess.STDOUT, # env=self._firefox_env).communicate() command[1] = '-foreground' self.process = subprocess.Popen( command, stdout=self._log_file, stderr=subprocess.STDOUT, env=self._firefox_env) @unittest.skipUnless(os.environ.get('WITH_SELENIUM', False), ""The WITH_SELENIUM env variable is not set."") class WebDriver(firefox.webdriver.WebDriver): """"""Workarounds selenium firefox issues."""""" def __init__(self, firefox_profile=None, firefox_binary=None, timeout=30, capabilities=None, proxy=None): try: super(WebDriver, self).__init__( firefox_profile, FirefoxBinary(), timeout, capabilities, proxy) except selenium_exceptions.WebDriverException: # If we can't start, cleanup profile shutil.rmtree(self.profile.path) if self.profile.tempfolder is not None: shutil.rmtree(self.profile.tempfolder) raise","from selenium.common import exceptions as selenium_exceptions from selenium.webdriver import firefox class FirefoxBinary(firefox.firefox_binary.FirefoxBinary): """"""Workarounds selenium firefox issues. There is race condition in the way firefox is spawned. The exact cause hasn't been properly diagnosed yet but it's around: - getting a free port from the OS with selenium.webdriver.common.utils free_port(), - release the port immediately but record it in ff prefs so that ff can listen on that port for the internal http server. It has been observed that this leads to hanging processes for 'firefox -silent'. """""" def _start_from_profile_path(self, path): self._firefox_env[""XRE_PROFILE_PATH""] = path if platform.system().lower() == 'linux': self._modify_link_library_path() command = [self._start_cmd, ""-silent""] if self.command_line is not None: for cli in self.command_line: command.append(cli) # The following exists upstream and is known to create hanging firefoxes, # leading to zombies. # subprocess.Popen(command, stdout=self._log_file, # stderr=subprocess.STDOUT, # env=self._firefox_env).communicate() command[1] = '-foreground' self.process = subprocess.Popen( command, stdout=self._log_file, stderr=subprocess.STDOUT, env=self._firefox_env) class WebDriver(firefox.webdriver.WebDriver): """"""Workarounds selenium firefox issues."""""" def __init__(self, firefox_profile=None, firefox_binary=None, timeout=30, capabilities=None, proxy=None): try: super(WebDriver, self).__init__( firefox_profile, FirefoxBinary(), timeout, capabilities, proxy) except selenium_exceptions.WebDriverException: # If we can't start, cleanup profile shutil.rmtree(self.profile.path) if self.profile.tempfolder is not None: shutil.rmtree(self.profile.tempfolder) raise",52,44
openstack%2Fkeystone~feature%2Fhierarchical-multitenancy~Icc5646c143a234127a8b4ac8a74342ef3dca7e80,openstack/keystone,feature/hierarchical-multitenancy,Icc5646c143a234127a8b4ac8a74342ef3dca7e80,Validates controller methods exist when specified,ABANDONED,2014-10-17 19:52:25.000000000,2014-10-17 20:01:02.000000000,,[{'_account_id': 7725}],"[{'number': 1, 'created': '2014-10-17 19:52:25.000000000', 'files': ['keystone/common/wsgi.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/b64d455fea5bbdad0037e909a236c1faf7b219c6', 'message': 'Validates controller methods exist when specified\n\nIt was possible to specify an invalid controller method in a router.\nThis will not cause an error until runtime. This change catches the\nerror much earlier in the application lifecycle. In fact with this\nchange errors should not be able to pass unit tests even if there is\nno specific test for the behavior.\n\nRelated-bug: #1377304\nChange-Id: Icc5646c143a234127a8b4ac8a74342ef3dca7e80\n'}]",0,129369,b64d455fea5bbdad0037e909a236c1faf7b219c6,2,1,1,2903,,,0,"Validates controller methods exist when specified

It was possible to specify an invalid controller method in a router.
This will not cause an error until runtime. This change catches the
error much earlier in the application lifecycle. In fact with this
change errors should not be able to pass unit tests even if there is
no specific test for the behavior.

Related-bug: #1377304
Change-Id: Icc5646c143a234127a8b4ac8a74342ef3dca7e80
",git fetch https://review.opendev.org/openstack/keystone refs/changes/69/129369/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/wsgi.py'],1,b64d455fea5bbdad0037e909a236c1faf7b219c6,," getattr(controller, get_head_action) # ensure the attribute exists getattr(controller, get_action) # ensure the attribute exists getattr(controller, head_action) # ensure the attribute exists getattr(controller, put_action) # ensure the attribute exists getattr(controller, post_action) # ensure the attribute exists getattr(controller, patch_action) # ensure the attribute exists getattr(controller, delete_action) # ensure the attribute exists getattr(controller, get_post_action) # ensure the attribute exists",,8,0
openstack%2Fkeystone~feature%2Fhierarchical-multitenancy~I355798d1024399aca194e826ed8048812e44612b,openstack/keystone,feature/hierarchical-multitenancy,I355798d1024399aca194e826ed8048812e44612b,Switch LdapIdentitySqlAssignment to use oslo.mockpatch,ABANDONED,2014-10-17 19:52:25.000000000,2014-10-17 20:00:51.000000000,,[{'_account_id': 5638}],"[{'number': 1, 'created': '2014-10-17 19:52:25.000000000', 'files': ['keystone/tests/test_backend_ldap_pool.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/790632d9e26c6d9da5003c3f61230f02e433b0d9', 'message': 'Switch LdapIdentitySqlAssignment to use oslo.mockpatch\n\nReferenced bug has been fixed in oslotest 1.1.0\n\nChange-Id: I355798d1024399aca194e826ed8048812e44612b\n'}]",0,129370,790632d9e26c6d9da5003c3f61230f02e433b0d9,2,1,1,2903,,,0,"Switch LdapIdentitySqlAssignment to use oslo.mockpatch

Referenced bug has been fixed in oslotest 1.1.0

Change-Id: I355798d1024399aca194e826ed8048812e44612b
",git fetch https://review.opendev.org/openstack/keystone refs/changes/70/129370/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/test_backend_ldap_pool.py'],1,790632d9e26c6d9da5003c3f61230f02e433b0d9,,"from oslotest import mockpatch self.useFixture(mockpatch.PatchObject( ldap_core.PooledLDAPHandler, 'Connector', fakeldap.FakeLdapPool)) super(LdapIdentitySqlAssignment, self).setUp()"," # NOTE(dstanek): We need to patch the Connector before the # parent setUp is executed. The patch cleanup needs to happen # after the parent setUp runs because olsotest will try to # automagically stop all patches and that will cause an # exception. We could just not cleanup after ourselves since # oslotest will do it, but that seems wrong. Once bug #1365678 # is fixed and released in oslotest we can start using # oslotest.mockpatch.PatchObject instead. patcher = mock.patch.object(ldap_core.PooledLDAPHandler, 'Connector', fakeldap.FakeLdapPool) patcher.start() try: super(LdapIdentitySqlAssignment, self).setUp() finally: self.addCleanup(patcher.stop)",4,15
openstack%2Fkeystone~feature%2Fhierarchical-multitenancy~I6dc36b506452f99488c2a202da5eea518cc51b68,openstack/keystone,feature/hierarchical-multitenancy,I6dc36b506452f99488c2a202da5eea518cc51b68,Remove images directory from docs,ABANDONED,2014-10-17 19:52:25.000000000,2014-10-17 20:00:33.000000000,,[{'_account_id': 6482}],"[{'number': 1, 'created': '2014-10-17 19:52:25.000000000', 'files': ['doc/source/images/graphs_authCompDelegate.svg', 'doc/source/images/authComp.png', 'doc/source/images/graphs_authComp.svg', 'doc/source/images/graphs_authCompDelegate.png', 'doc/source/images/authComp.svg', 'doc/source/conf.py', 'doc/source/images/graphs_authComp.png'], 'web_link': 'https://opendev.org/openstack/keystone/commit/cb8b08864d33fe14ae77f319f669d21531ba66f0', 'message': ""Remove images directory from docs\n\nI can't find a single place these images are used in our docs.\nBest I can tell is that middleware docs have a few of them:\nhttp://docs.openstack.org/developer/keystonemiddleware/middlewarearchitecture.html\n\nChange-Id: I6dc36b506452f99488c2a202da5eea518cc51b68\n""}]",0,129368,cb8b08864d33fe14ae77f319f669d21531ba66f0,2,1,1,2903,,,0,"Remove images directory from docs

I can't find a single place these images are used in our docs.
Best I can tell is that middleware docs have a few of them:
http://docs.openstack.org/developer/keystonemiddleware/middlewarearchitecture.html

Change-Id: I6dc36b506452f99488c2a202da5eea518cc51b68
",git fetch https://review.opendev.org/openstack/keystone refs/changes/68/129368/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/images/graphs_authCompDelegate.svg', 'doc/source/images/authComp.png', 'doc/source/images/graphs_authComp.svg', 'doc/source/images/graphs_authCompDelegate.png', 'doc/source/images/authComp.svg', 'doc/source/conf.py', 'doc/source/images/graphs_authComp.png']",7,cb8b08864d33fe14ae77f319f669d21531ba66f0,,,,1,276
openstack%2Fkeystone~feature%2Fhierarchical-multitenancy~I02566b3168b5f1792149b67e582d8e97ff02f8a6,openstack/keystone,feature/hierarchical-multitenancy,I02566b3168b5f1792149b67e582d8e97ff02f8a6,Remove identity and assignment kvs backends,ABANDONED,2014-10-17 19:52:25.000000000,2014-10-17 20:00:17.000000000,,[{'_account_id': 5707}],"[{'number': 1, 'created': '2014-10-17 19:52:25.000000000', 'files': ['keystone/identity/backends/kvs.py', 'keystone/tests/test_backend_kvs.py', 'keystone/assignment/backends/kvs.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/b960170acd4c2cf3c98bceee52fa712dbd671cc7', 'message': 'Remove identity and assignment kvs backends\n\nAs part of deprecating the kvs backends, this patch removes those\nfor identity and assignment.\n\nPartially implements: bp removed-as-of-kilo\n\nChange-Id: I02566b3168b5f1792149b67e582d8e97ff02f8a6\n'}]",0,129371,b960170acd4c2cf3c98bceee52fa712dbd671cc7,2,1,1,2903,,,0,"Remove identity and assignment kvs backends

As part of deprecating the kvs backends, this patch removes those
for identity and assignment.

Partially implements: bp removed-as-of-kilo

Change-Id: I02566b3168b5f1792149b67e582d8e97ff02f8a6
",git fetch https://review.opendev.org/openstack/keystone refs/changes/71/129371/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/identity/backends/kvs.py', 'keystone/tests/test_backend_kvs.py', 'keystone/assignment/backends/kvs.py']",3,b960170acd4c2cf3c98bceee52fa712dbd671cc7,,,"# Copyright 2012 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from keystone import assignment from keystone import clean from keystone.common import kvs from keystone import config from keystone import exception from keystone.i18n import _ from keystone.openstack.common import versionutils CONF = config.CONF class Assignment(kvs.Base, assignment.Driver): """"""KVS Assignment backend. This backend uses the following mappings to store data: * Domains: * domain_list -> [domain_id, ...] * domain-{id} -> domain_ref * domain_name-{name} -> domain_ref * Projects: * tenant-{id} -> project_ref * tenant_name-{name} -> project_ref * Roles: * role_list -> [role_id, ...] * role-{id} -> role_ref * Role assignments: * metadata_user-{target}-{user_id} -> {'roles': [{'id': role-id, ...}, ...]} * metadata_group-{target}-{group_id} -> {'roles': [{'id': role-id, ...}, ...]} """""" @versionutils.deprecated(versionutils.deprecated.JUNO, in_favor_of='keystone.assignment.backends.sql', remove_in=+1, what='keystone.assignment.backends.kvs') def __init__(self): super(Assignment, self).__init__() # Public interface def get_project(self, tenant_id): try: return self.db.get('tenant-%s' % tenant_id) except exception.NotFound: raise exception.ProjectNotFound(project_id=tenant_id) def _build_project_refs(self): project_keys = (k for k in self.db.keys() if k.startswith('tenant-')) return [self.db.get(key) for key in project_keys] def list_projects(self, hints): return self._build_project_refs() def list_projects_in_domain(self, domain_id): project_refs = self._build_project_refs() self.get_domain(domain_id) return [ref for ref in project_refs if domain_id == ref['domain_id']] def get_project_by_name(self, tenant_name, domain_id): try: return self.db.get('tenant_name-%s' % tenant_name) except exception.NotFound: raise exception.ProjectNotFound(project_id=tenant_name) def list_user_ids_for_project(self, tenant_id): self.get_project(tenant_id) user_ids = set() metadata_keys = (k for k in self.db.keys() if k.startswith('metadata_user-')) for key in metadata_keys: i, meta_project_or_domain_id, meta_user_id = key.split('-') if meta_project_or_domain_id != tenant_id: # target is not the project, so on to next metadata. continue user_ids.add(meta_user_id) return list(user_ids) def _get_metadata(self, user_id=None, tenant_id=None, domain_id=None, group_id=None): try: if user_id: if tenant_id: return self.db.get('metadata_user-%s-%s' % (tenant_id, user_id)) else: return self.db.get('metadata_user-%s-%s' % (domain_id, user_id)) else: if tenant_id: return self.db.get('metadata_group-%s-%s' % (tenant_id, group_id)) else: return self.db.get('metadata_group-%s-%s' % (domain_id, group_id)) except exception.NotFound: raise exception.MetadataNotFound() def get_role(self, role_id): try: return self.db.get('role-%s' % role_id) except exception.NotFound: raise exception.RoleNotFound(role_id=role_id) def get_group_project_roles(self, groups, project_id, project_domain_id): role_list = [] for group_id in groups: try: metadata_ref = self._get_metadata( group_id=group_id, tenant_id=project_id) role_list += self._roles_from_role_dicts( metadata_ref.get('roles', {}), False) except exception.MetadataNotFound: # no group assignment, skip pass if CONF.os_inherit.enabled: # Now get any inherited group roles for the owning domain try: metadata_ref = self._get_metadata( group_id=group_id, domain_id=project_domain_id) role_list += self._roles_from_role_dicts( metadata_ref.get('roles', {}), True) except exception.MetadataNotFound: pass return role_list def list_roles(self, hints): return self._list_roles() def _list_roles(self): role_ids = self.db.get('role_list', []) return [self.get_role(x) for x in role_ids] def list_projects_for_user(self, user_id, group_ids, hints): project_ids = set() all_projects = self.list_projects(hints=None) metadata_keys = (k for k in self.db.keys() if (k.startswith('metadata_user-') or k.startswith('metadata_group-'))) for key in metadata_keys: i, meta_project_or_domain_id, meta_entity_id = key.split('-') if meta_entity_id != user_id and meta_entity_id not in group_ids: # Not the user not one of the groups, so on to next metadata. continue try: self.get_project(meta_project_or_domain_id) except exception.NotFound: # target is not a project, could it be a domain if not CONF.os_inherit.enabled: # Inheritance is disabled, skip domain handling continue try: self.get_domain(meta_project_or_domain_id) except exception.NotFound: # Not a domain, move on continue data = self.db.get(key) for role in data.get('roles', []): if role['inherited_to'] == 'projects': # Role is inherited for project in all_projects: # add all projects for the domain to the list # of ids if (project['domain_id'] == meta_project_or_domain_id): project_ids.add(project['id']) break continue project_id = meta_project_or_domain_id project_ids.add(project_id) project_refs = [] for project_id in project_ids: project_refs.append(self.get_project(project_id)) return project_refs def list_domains_for_user(self, user_id, group_ids, hints): raise exception.NotImplemented() def get_roles_for_groups(self, group_ids, project_id=None, domain_id=None): raise exception.NotImplemented() def list_projects_for_groups(self, group_ids): raise exception.NotImplemented() def list_domains_for_groups(self, group_ids): raise exception.NotImplemented() def add_role_to_user_and_project(self, user_id, tenant_id, role_id): self.get_project(tenant_id) self.get_role(role_id) try: metadata_ref = self._get_metadata(user_id, tenant_id) except exception.MetadataNotFound: metadata_ref = {} try: metadata_ref['roles'] = self._add_role_to_role_dicts( role_id, False, metadata_ref.get('roles', []), allow_existing=False) except KeyError: msg = ('User %s already has role %s in tenant %s' % (user_id, role_id, tenant_id)) raise exception.Conflict(type='role grant', details=msg) self._update_metadata(user_id, tenant_id, metadata_ref) def remove_role_from_user_and_project(self, user_id, tenant_id, role_id): try: metadata_ref = self._get_metadata(user_id, tenant_id) except exception.MetadataNotFound: metadata_ref = {} try: metadata_ref['roles'] = self._remove_role_from_role_dicts( role_id, False, metadata_ref.get('roles', [])) except KeyError: raise exception.RoleNotFound(message=_( 'Cannot remove role that has not been granted, %s') % role_id) if metadata_ref['roles']: self._update_metadata(user_id, tenant_id, metadata_ref) else: self.db.delete('metadata_user-%s-%s' % (tenant_id, user_id)) def list_role_assignments(self): """"""List the role assignments. We enumerate the metadata entries and extract the targets, actors, and roles. """""" assignment_list = [] metadata_keys = (k for k in self.db.keys() if k.startswith('metadata_user-')) for key in metadata_keys: template = {} i, meta_project_or_domain_id, template['user_id'] = key.split('-') try: self.get_project(meta_project_or_domain_id) template['project_id'] = meta_project_or_domain_id except exception.NotFound: template['domain_id'] = meta_project_or_domain_id entry = self.db.get(key) inherited = False for r in self._roles_from_role_dicts(entry.get('roles', {}), inherited): role_assignment = template.copy() role_assignment['role_id'] = r assignment_list.append(role_assignment) metadata_keys = (k for k in self.db.keys() if k.startswith('metadata_group-')) for key in metadata_keys: template = {} i, meta_project_or_domain_id, template['group_id'] = key.split('-') try: self.get_project(meta_project_or_domain_id) template['project_id'] = meta_project_or_domain_id except exception.NotFound: template['domain_id'] = meta_project_or_domain_id entry = self.db.get(key) inherited = False for r in self._roles_from_role_dicts(entry.get('roles', {}), inherited): role_assignment = template.copy() role_assignment['role_id'] = r assignment_list.append(role_assignment) return assignment_list # CRUD def create_project(self, tenant_id, tenant): tenant['name'] = clean.project_name(tenant['name']) try: self.get_project(tenant_id) except exception.ProjectNotFound: pass else: msg = 'Duplicate ID, %s.' % tenant_id raise exception.Conflict(type='tenant', details=msg) try: self.get_project_by_name(tenant['name'], tenant['domain_id']) except exception.ProjectNotFound: pass else: msg = 'Duplicate name, %s.' % tenant['name'] raise exception.Conflict(type='tenant', details=msg) self.db.set('tenant-%s' % tenant_id, tenant) self.db.set('tenant_name-%s' % tenant['name'], tenant) return tenant def update_project(self, tenant_id, tenant): if 'name' in tenant: tenant['name'] = clean.project_name(tenant['name']) try: existing = self.db.get('tenant_name-%s' % tenant['name']) if existing and tenant_id != existing['id']: msg = 'Duplicate name, %s.' % tenant['name'] raise exception.Conflict(type='tenant', details=msg) except exception.NotFound: pass # get the old name and delete it too try: old_project = self.db.get('tenant-%s' % tenant_id) except exception.NotFound: raise exception.ProjectNotFound(project_id=tenant_id) new_project = old_project.copy() new_project.update(tenant) new_project['id'] = tenant_id self.db.delete('tenant_name-%s' % old_project['name']) self.db.set('tenant-%s' % tenant_id, new_project) self.db.set('tenant_name-%s' % new_project['name'], new_project) return new_project def delete_project(self, tenant_id): try: old_project = self.db.get('tenant-%s' % tenant_id) except exception.NotFound: raise exception.ProjectNotFound(project_id=tenant_id) self.db.delete('tenant_name-%s' % old_project['name']) self.db.delete('tenant-%s' % tenant_id) def _create_metadata(self, user_id, tenant_id, metadata, domain_id=None, group_id=None): return self._update_metadata(user_id, tenant_id, metadata, domain_id, group_id) def _update_metadata(self, user_id, tenant_id, metadata, domain_id=None, group_id=None): if user_id: if tenant_id: self.db.set('metadata_user-%s-%s' % (tenant_id, user_id), metadata) else: self.db.set('metadata_user-%s-%s' % (domain_id, user_id), metadata) else: if tenant_id: self.db.set('metadata_group-%s-%s' % (tenant_id, group_id), metadata) else: self.db.set('metadata_group-%s-%s' % (domain_id, group_id), metadata) return metadata def create_role(self, role_id, role): try: self.get_role(role_id) except exception.RoleNotFound: pass else: msg = 'Duplicate ID, %s.' % role_id raise exception.Conflict(type='role', details=msg) for role_ref in self._list_roles(): if role['name'] == role_ref['name']: msg = 'Duplicate name, %s.' % role['name'] raise exception.Conflict(type='role', details=msg) self.db.set('role-%s' % role_id, role) role_list = set(self.db.get('role_list', [])) role_list.add(role_id) self.db.set('role_list', list(role_list)) return role def update_role(self, role_id, role): old_role_ref = None for role_ref in self._list_roles(): if role['name'] == role_ref['name'] and role_id != role_ref['id']: msg = 'Duplicate name, %s.' % role['name'] raise exception.Conflict(type='role', details=msg) if role_id == role_ref['id']: old_role_ref = role_ref if old_role_ref is None: raise exception.RoleNotFound(role_id=role_id) new_role = old_role_ref.copy() new_role.update(role) new_role['id'] = role_id self.db.set('role-%s' % role_id, new_role) return role def delete_role(self, role_id): self.get_role(role_id) metadata_keys = (k for k in self.db.keys() if k.startswith('metadata_user-')) for key in metadata_keys: i, meta_project_or_domain_id, meta_user_id = key.split('-') try: self.delete_grant(role_id, project_id=meta_project_or_domain_id, user_id=meta_user_id) except exception.NotFound: pass try: self.delete_grant(role_id, domain_id=meta_project_or_domain_id, user_id=meta_user_id) except exception.NotFound: pass metadata_keys = (k for k in self.db.keys() if k.startswith('metadata_group-')) for key in metadata_keys: i, meta_project_or_domain_id, meta_group_id = key.split('-') try: self.delete_grant(role_id, project_id=meta_project_or_domain_id, group_id=meta_group_id) except exception.NotFound: pass try: self.delete_grant(role_id, domain_id=meta_project_or_domain_id, group_id=meta_group_id) except exception.NotFound: pass self.db.delete('role-%s' % role_id) role_list = set(self.db.get('role_list', [])) role_list.remove(role_id) self.db.set('role_list', list(role_list)) def create_grant(self, role_id, user_id=None, group_id=None, domain_id=None, project_id=None, inherited_to_projects=False): self.get_role(role_id) if domain_id: self.get_domain(domain_id) if project_id: self.get_project(project_id) try: metadata_ref = self._get_metadata(user_id, project_id, domain_id, group_id) except exception.MetadataNotFound: metadata_ref = {} metadata_ref['roles'] = self._add_role_to_role_dicts( role_id, inherited_to_projects, metadata_ref.get('roles', [])) self._update_metadata(user_id, project_id, metadata_ref, domain_id, group_id) def list_grants(self, user_id=None, group_id=None, domain_id=None, project_id=None, inherited_to_projects=False): if domain_id: self.get_domain(domain_id) if project_id: self.get_project(project_id) try: metadata_ref = self._get_metadata(user_id, project_id, domain_id, group_id) except exception.MetadataNotFound: metadata_ref = {} return [self.get_role(x) for x in self._roles_from_role_dicts(metadata_ref.get('roles', []), inherited_to_projects)] def get_grant(self, role_id, user_id=None, group_id=None, domain_id=None, project_id=None, inherited_to_projects=False): self.get_role(role_id) if group_id: self.get_group(group_id) if domain_id: self.get_domain(domain_id) if project_id: self.get_project(project_id) try: metadata_ref = self._get_metadata(user_id, project_id, domain_id, group_id) except exception.MetadataNotFound: metadata_ref = {} role_ids = set(self._roles_from_role_dicts( metadata_ref.get('roles', []), inherited_to_projects)) if role_id not in role_ids: raise exception.RoleNotFound(role_id=role_id) return self.get_role(role_id) def delete_grant(self, role_id, user_id=None, group_id=None, domain_id=None, project_id=None, inherited_to_projects=False): self.get_role(role_id) if domain_id: self.get_domain(domain_id) if project_id: self.get_project(project_id) try: metadata_ref = self._get_metadata(user_id, project_id, domain_id, group_id) except exception.MetadataNotFound: metadata_ref = {} try: metadata_ref['roles'] = self._remove_role_from_role_dicts( role_id, inherited_to_projects, metadata_ref.get('roles', [])) except KeyError: raise exception.RoleNotFound(role_id=role_id) self._update_metadata(user_id, project_id, metadata_ref, domain_id, group_id) # domain crud def create_domain(self, domain_id, domain): try: self.get_domain(domain_id) except exception.DomainNotFound: pass else: msg = 'Duplicate ID, %s.' % domain_id raise exception.Conflict(type='domain', details=msg) try: self.get_domain_by_name(domain['name']) except exception.DomainNotFound: pass else: msg = 'Duplicate name, %s.' % domain['name'] raise exception.Conflict(type='domain', details=msg) self.db.set('domain-%s' % domain_id, domain) self.db.set('domain_name-%s' % domain['name'], domain) domain_list = set(self.db.get('domain_list', [])) domain_list.add(domain_id) self.db.set('domain_list', list(domain_list)) return domain def list_domains(self, hints): domain_ids = self.db.get('domain_list', []) return [self.get_domain(x) for x in domain_ids] def get_domain(self, domain_id): try: return self.db.get('domain-%s' % domain_id) except exception.NotFound: raise exception.DomainNotFound(domain_id=domain_id) def get_domain_by_name(self, domain_name): try: return self.db.get('domain_name-%s' % domain_name) except exception.NotFound: raise exception.DomainNotFound(domain_id=domain_name) def update_domain(self, domain_id, domain): orig_domain = self.get_domain(domain_id) domain['id'] = domain_id self.db.set('domain-%s' % domain_id, domain) self.db.set('domain_name-%s' % domain['name'], domain) if domain['name'] != orig_domain['name']: self.db.delete('domain_name-%s' % orig_domain['name']) return domain def delete_domain(self, domain_id): domain = self.get_domain(domain_id) self.db.delete('domain-%s' % domain_id) self.db.delete('domain_name-%s' % domain['name']) domain_list = set(self.db.get('domain_list', [])) domain_list.remove(domain_id) self.db.set('domain_list', list(domain_list)) def delete_user(self, user_id): """"""Deletes all assignments for a user. :raises: keystone.exception.RoleNotFound """""" # KVS doesn't bother cleaning up role assignments for the user. I # guess it's too difficult to implement or something. def delete_group(self, group_id): """"""Deletes all assignments for a group. :raises: keystone.exception.RoleNotFound """""" # KVS doesn't bother cleaning up role assignments for the group. I # guess it's too difficult to implement or something. ",2,1056
openstack%2Fkeystone~feature%2Fhierarchical-multitenancy~Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634,openstack/keystone,feature/hierarchical-multitenancy,Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634,Ensure sql upgrade tests can run with non-sqlite databases.,ABANDONED,2014-10-17 19:52:25.000000000,2014-10-17 20:00:13.000000000,,[{'_account_id': 5707}],"[{'number': 1, 'created': '2014-10-17 19:52:25.000000000', 'files': ['keystone/tests/test_sql_upgrade.py', 'keystone/contrib/federation/migrate_repo/versions/001_add_identity_provider_table.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/7c0c5c81de3f7013d911cb0da8f02d1e1c37b548', 'message': ""Ensure sql upgrade tests can run with non-sqlite databases.\n\nThis patch fixes the issues that were preventing the running of\nlive sql upgrade tests (either by running test_sql_upgrade directly\nor via test_sql_livetest), namely:\n\n- Dropping the tables that were in existence before the current\n  scope of migration in an order that is FK friendly\n- Fixing an issue where the tables were being dropped in the\n  wrong order in the downgrade of federation\n- Ensuring we don't hold sessions open over upgrade/downgrade\n  steps in our test methods\n\nLimitations:\n\n- This patch has not been tested with DB2\n\nCloses-Bug: 1363047\nCloses-Bug: 1375937\nChange-Id: Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634\n""}]",0,129372,7c0c5c81de3f7013d911cb0da8f02d1e1c37b548,2,1,1,2903,,,0,"Ensure sql upgrade tests can run with non-sqlite databases.

This patch fixes the issues that were preventing the running of
live sql upgrade tests (either by running test_sql_upgrade directly
or via test_sql_livetest), namely:

- Dropping the tables that were in existence before the current
  scope of migration in an order that is FK friendly
- Fixing an issue where the tables were being dropped in the
  wrong order in the downgrade of federation
- Ensuring we don't hold sessions open over upgrade/downgrade
  steps in our test methods

Limitations:

- This patch has not been tested with DB2

Closes-Bug: 1363047
Closes-Bug: 1375937
Change-Id: Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634
",git fetch https://review.opendev.org/openstack/keystone refs/changes/72/129372/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_sql_upgrade.py', 'keystone/contrib/federation/migrate_repo/versions/001_add_identity_provider_table.py']",2,7c0c5c81de3f7013d911cb0da8f02d1e1c37b548,," tables = ['federation_protocol', 'identity_provider']"," tables = ['identity_provider', 'federation_protocol']",65,19
openstack%2Fkolla~master~Ia0b9057887bf34423546ca36346d9253ef4c90b9,openstack/kolla,master,Ia0b9057887bf34423546ca36346d9253ef4c90b9,fix script name in nova-controller images,MERGED,2014-10-17 19:47:05.000000000,2014-10-17 19:57:37.000000000,2014-10-17 19:57:37.000000000,"[{'_account_id': 3}, {'_account_id': 2834}]","[{'number': 1, 'created': '2014-10-17 19:47:05.000000000', 'files': ['docker/nova-controller/nova-api/start.sh', 'docker/nova-controller/nova-conductor/start.sh', 'docker/nova-controller/nova-scheduler/start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/89534f43a1a9b29707d8ac62a23e3c28226f9cf5', 'message': 'fix script name in nova-controller images\n\nChange-Id: Ia0b9057887bf34423546ca36346d9253ef4c90b9\n'}]",0,129366,89534f43a1a9b29707d8ac62a23e3c28226f9cf5,6,2,1,8745,,,0,"fix script name in nova-controller images

Change-Id: Ia0b9057887bf34423546ca36346d9253ef4c90b9
",git fetch https://review.opendev.org/openstack/kolla refs/changes/66/129366/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/nova-controller/nova-api/start.sh', 'docker/nova-controller/nova-conductor/start.sh', 'docker/nova-controller/nova-scheduler/start.sh']",3,89534f43a1a9b29707d8ac62a23e3c28226f9cf5,larsks/nova-base,. /opt/kolla/config-nova.sh,. /opt/kolla/config-nova-controller.sh,3,3
openstack%2Fkeystone~feature%2Fhierarchical-multitenancy~I577c3860b4d0dda0488830f766d7538562809817,openstack/keystone,feature/hierarchical-multitenancy,I577c3860b4d0dda0488830f766d7538562809817,Imported Translations from Transifex,ABANDONED,2014-10-17 19:52:25.000000000,2014-10-17 19:56:44.000000000,,[{'_account_id': 11131}],"[{'number': 1, 'created': '2014-10-17 19:52:25.000000000', 'files': ['keystone/locale/fr/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/de/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/en_GB/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/vi_VN/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/keystone-log-error.pot', 'keystone/locale/en_AU/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/it/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/en_GB/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/en_US/LC_MESSAGES/keystone.po', 'keystone/locale/it/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/keystone.pot', 'keystone/locale/en_AU/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/ja/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/zh_TW/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/zh_TW/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/es/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/ja/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/es/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/de/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/en_AU/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/ko_KR/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/ko_KR/LC_MESSAGES/keystone-log-error.po'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0d58842bf6283832b15b2e73ebe10992bf329349', 'message': 'Imported Translations from Transifex\n\nChange-Id: I577c3860b4d0dda0488830f766d7538562809817\n'}]",0,129373,0d58842bf6283832b15b2e73ebe10992bf329349,2,1,1,2903,,,0,"Imported Translations from Transifex

Change-Id: I577c3860b4d0dda0488830f766d7538562809817
",git fetch https://review.opendev.org/openstack/keystone refs/changes/73/129373/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/locale/fr/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/de/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/en_GB/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/vi_VN/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/keystone-log-error.pot', 'keystone/locale/en_AU/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/it/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/en_GB/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/en_US/LC_MESSAGES/keystone.po', 'keystone/locale/it/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/keystone.pot', 'keystone/locale/en_AU/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/ja/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/zh_TW/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/zh_TW/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/es/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/ja/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/es/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/de/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/en_AU/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/ko_KR/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/ko_KR/LC_MESSAGES/keystone-log-error.po']",27,0d58842bf6283832b15b2e73ebe10992bf329349,,"""POT-Creation-Date: 2014-10-07 06:05+0000\n""#: keystone/catalog/core.py:60#: keystone/catalog/core.py:65#: keystone/catalog/core.py:71#: keystone/common/openssl.py:92#: keystone/common/openssl.py:120 #, python-format msgid ""Failed to remove file %(file_path)r: %(error)s"" msgstr """" #: keystone/contrib/federation/idp.py:405","""POT-Creation-Date: 2014-09-07 06:06+0000\n""#: keystone/catalog/core.py:56#: keystone/catalog/core.py:61#: keystone/catalog/core.py:67#: keystone/common/openssl.py:90#: keystone/contrib/federation/idp.py:404",243,2646
openstack%2Ftrove~master~I1c961195d48af3eb50036f04e75d8cbe4ff86672,openstack/trove,master,I1c961195d48af3eb50036f04e75d8cbe4ff86672,Obsolete oslo-incubator modules - exception,ABANDONED,2014-10-17 15:00:54.000000000,2014-10-17 19:49:46.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-10-17 15:00:54.000000000', 'files': ['trove/common/exception.py', 'openstack-common.conf', 'trove/openstack/common/exception.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/826b63f876f36de74568b0c4ed8dc3834f8e38b6', 'message': 'Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles the exception module (used to be\ntrove/openstack/common/exception.py).\n\nThe change here is to remove it from openstack-common.conf and handle\nthe ripple effect in trove/common/exception.py\n\nChange-Id: I1c961195d48af3eb50036f04e75d8cbe4ff86672\nBlueprint: trove-retire-unused-modules\nPartial-Bug: #1380789\n'}]",0,129293,826b63f876f36de74568b0c4ed8dc3834f8e38b6,6,3,1,9664,,,0,"Obsolete oslo-incubator modules - exception

This change is part of a multi-part change set to handle obsolete and
graduated oslo modules.

This commit handles the exception module (used to be
trove/openstack/common/exception.py).

The change here is to remove it from openstack-common.conf and handle
the ripple effect in trove/common/exception.py

Change-Id: I1c961195d48af3eb50036f04e75d8cbe4ff86672
Blueprint: trove-retire-unused-modules
Partial-Bug: #1380789
",git fetch https://review.opendev.org/openstack/trove refs/changes/93/129293/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/exception.py', 'openstack-common.conf', 'trove/openstack/common/exception.py']",3,826b63f876f36de74568b0c4ed8dc3834f8e38b6,bugs/bug-1380789-exceptions,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Exceptions common to OpenStack projects """""" import logging from trove.openstack.common.gettextutils import _ _FATAL_EXCEPTION_FORMAT_ERRORS = False class Error(Exception): def __init__(self, message=None): super(Error, self).__init__(message) class ApiError(Error): def __init__(self, message='Unknown', code='Unknown'): self.message = message self.code = code super(ApiError, self).__init__('%s: %s' % (code, message)) class NotFound(Error): pass class UnknownScheme(Error): msg = ""Unknown scheme '%s' found in URI"" def __init__(self, scheme): msg = self.__class__.msg % scheme super(UnknownScheme, self).__init__(msg) class BadStoreUri(Error): msg = ""The Store URI %s was malformed. Reason: %s"" def __init__(self, uri, reason): msg = self.__class__.msg % (uri, reason) super(BadStoreUri, self).__init__(msg) class Duplicate(Error): pass class NotAuthorized(Error): pass class NotEmpty(Error): pass class Invalid(Error): pass class BadInputError(Exception): """"""Error resulting from a client sending bad input to a server"""""" pass class MissingArgumentError(Error): pass class DatabaseMigrationError(Error): pass class ClientConnectionError(Exception): """"""Error resulting from a client connecting to a server"""""" pass def wrap_exception(f): def _wrap(*args, **kw): try: return f(*args, **kw) except Exception as e: if not isinstance(e, Error): #exc_type, exc_value, exc_traceback = sys.exc_info() logging.exception(_('Uncaught exception')) #logging.error(traceback.extract_stack(exc_traceback)) raise Error(str(e)) raise _wrap.func_name = f.func_name return _wrap class OpenstackException(Exception): """""" Base Exception To correctly use this class, inherit from it and define a 'message' property. That message will get printf'd with the keyword arguments provided to the constructor. """""" message = ""An unknown exception occurred"" def __init__(self, **kwargs): try: self._error_string = self.message % kwargs except Exception as e: if _FATAL_EXCEPTION_FORMAT_ERRORS: raise e else: # at least get the core message out if something happened self._error_string = self.message def __str__(self): return self._error_string class MalformedRequestBody(OpenstackException): message = ""Malformed message body: %(reason)s"" class InvalidContentType(OpenstackException): message = ""Invalid content type %(content_type)s"" ",34,148
openstack%2Fmonasca-ui~master~If73fa89796ca2b9385adf6cc3c0d01dcb4e15b5b,openstack/monasca-ui,master,If73fa89796ca2b9385adf6cc3c0d01dcb4e15b5b,Display fields from definitions in alarms Display services and hosts in overview panel,MERGED,2014-10-17 17:13:07.000000000,2014-10-17 19:37:08.000000000,2014-10-17 19:37:08.000000000,"[{'_account_id': 3}, {'_account_id': 6230}]","[{'number': 1, 'created': '2014-10-17 17:13:07.000000000', 'files': ['monitoring/alarmdefs/tables.py', 'monitoring/alarms/tables.py', 'monitoring/overview/views.py', 'config/local_settings.py', 'monitoring/alarms/views.py', 'monitoring/alarms/tests.py'], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/1bebcc81e01a8cd92acfd5dedacf8ec8a21c4ee9', 'message': 'Display fields from definitions in alarms\nDisplay services and hosts in overview panel\n\nChange-Id: If73fa89796ca2b9385adf6cc3c0d01dcb4e15b5b\n'}]",0,129331,1bebcc81e01a8cd92acfd5dedacf8ec8a21c4ee9,6,2,1,6230,,,0,"Display fields from definitions in alarms
Display services and hosts in overview panel

Change-Id: If73fa89796ca2b9385adf6cc3c0d01dcb4e15b5b
",git fetch https://review.opendev.org/openstack/monasca-ui refs/changes/31/129331/1 && git format-patch -1 --stdout FETCH_HEAD,"['monitoring/alarmdefs/tables.py', 'monitoring/alarms/tables.py', 'monitoring/overview/views.py', 'config/local_settings.py', 'monitoring/alarms/tests.py', 'monitoring/alarms/views.py']",6,1bebcc81e01a8cd92acfd5dedacf8ec8a21c4ee9,," results = api.monitor.alarm_list(self.request) if self.service != 'all': name, value = self.service.split('=') filtered = [] for row in results: if (name in row['metrics'][0]['dimensions'] and row['metrics'][0]['dimensions'][name] == value): filtered.append(row) results = filtered"," if self.service == 'all': results = api.monitor.alarm_list(self.request) else: results = api.monitor.alarm_list_by_service( self.request, self.service)",53,44
openstack%2Fkolla~master~I2399a1331992fae0f387f01e5b5c1c1d34f0637d,openstack/kolla,master,I2399a1331992fae0f387f01e5b5c1c1d34f0637d,Adds Neutron Server Support,MERGED,2014-10-15 05:33:48.000000000,2014-10-17 19:35:46.000000000,2014-10-17 19:35:46.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 5792}, {'_account_id': 6836}, {'_account_id': 8745}]","[{'number': 1, 'created': '2014-10-15 05:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c13c80a828039cdd0bc45f24e07e22ce739f84d4', 'message': 'Adds Neutron Server Support\n\nPreviously Kolla did not support Neutron. This patch provides\ninitial Neutron support by implementing neutron-server\nfunctionality. It also creates a neutron-base image that\nprovides common config and packages for all Neutron-based\nservices.\n\nPartially Implements: Blueprint Kubernetes Neutron Container\n\nChange-Id: I2399a1331992fae0f387f01e5b5c1c1d34f0637d\n'}, {'number': 2, 'created': '2014-10-15 07:54:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6aca8fe6e958682bd4982bb50dec4c8b335f33ff', 'message': 'Adds Neutron Server Support\n\nPreviously Kolla did not support Neutron. This patch provides\ninitial Neutron support by implementing neutron-server\nfunctionality. It also creates a neutron-base image that\nprovides common config and packages for all Neutron-based\nservices.\n\nPartially Implements: Blueprint Kubernetes Neutron Container\n\nChange-Id: I2399a1331992fae0f387f01e5b5c1c1d34f0637d\n'}, {'number': 3, 'created': '2014-10-15 20:14:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/179ac28adfe1a965dfd19c1bf04839b1271a746d', 'message': 'Adds Neutron Server Support\n\nPreviously Kolla did not support Neutron. This patch provides\ninitial Neutron support by implementing neutron-server\nfunctionality. It also creates a neutron-base image that\nprovides common config and packages for all Neutron-based\nservices.\n\nPartially Implements: Blueprint Kubernetes Neutron Container\n\nChange-Id: I2399a1331992fae0f387f01e5b5c1c1d34f0637d\n'}, {'number': 4, 'created': '2014-10-16 19:29:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a8a73f3ad3e44c271729c504bdf1610ce53467d5', 'message': 'Adds Neutron Server Support\n\nPreviously Kolla did not support Neutron. This patch provides\ninitial Neutron support by implementing neutron-server\nfunctionality. It also creates a neutron-base image that\nprovides common config and packages for all Neutron-based\nservices.\n\nPartially Implements: Blueprint Kubernetes Neutron Container\n\nChange-Id: I2399a1331992fae0f387f01e5b5c1c1d34f0637d\n'}, {'number': 5, 'created': '2014-10-16 19:50:37.000000000', 'files': ['docker/neutron/neutron-base/config-neutron.sh', 'tools/start-all-services', 'docker/neutron/neutron-server/check.sh', 'docker/neutron/neutron-base/Dockerfile', 'k8s/pod/neutron-controller-pod.yaml', 'tools/start-all-pods', 'docker/neutron/neutron-base/build', 'docker/neutron/neutron-server/Dockerfile', 'docker/neutron/neutron-server/start.sh', 'k8s/service/neutron-server-service.yaml', 'docker/neutron/neutron-server/build'], 'web_link': 'https://opendev.org/openstack/kolla/commit/de313681f94a75b3dbcb078fa023495e2c04617f', 'message': 'Adds Neutron Server Support\n\nPreviously Kolla did not support Neutron. This patch provides\ninitial Neutron support by implementing neutron-server\nfunctionality. It also creates a neutron-base image that\nprovides common config and packages for all Neutron-based\nservices.\n\nPartially Implements: Blueprint Kubernetes Neutron Container\n\nChange-Id: I2399a1331992fae0f387f01e5b5c1c1d34f0637d\n'}]",6,128558,de313681f94a75b3dbcb078fa023495e2c04617f,20,5,5,6836,,,0,"Adds Neutron Server Support

Previously Kolla did not support Neutron. This patch provides
initial Neutron support by implementing neutron-server
functionality. It also creates a neutron-base image that
provides common config and packages for all Neutron-based
services.

Partially Implements: Blueprint Kubernetes Neutron Container

Change-Id: I2399a1331992fae0f387f01e5b5c1c1d34f0637d
",git fetch https://review.opendev.org/openstack/kolla refs/changes/58/128558/5 && git format-patch -1 --stdout FETCH_HEAD,"['docker/neutron/neutron-base/config-neutron.sh', 'docker/neutron/neutron-server/check.sh', 'docker/neutron/neutron-base/Dockerfile', 'k8s/service/neutron-server-service.json', 'k8s/pod/neutron-controller-pod.json', 'docker/neutron/neutron-base/build', 'docker/neutron/neutron-server/Dockerfile', 'docker/neutron/neutron-server/start.sh', 'docker/neutron/neutron-server/build']",9,c13c80a828039cdd0bc45f24e07e22ce739f84d4,bp/Kubernetes,../../../tools/build-docker-image,,280,0
openstack%2Fkolla~master~Icfd780f12b01956093a2933dd484cde1e2d6d5bc,openstack/kolla,master,Icfd780f12b01956093a2933dd484cde1e2d6d5bc,Docker image and process cleaup tool,MERGED,2014-10-17 13:13:03.000000000,2014-10-17 19:34:53.000000000,2014-10-17 19:34:53.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 5792}, {'_account_id': 8745}]","[{'number': 1, 'created': '2014-10-17 13:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/dedd6425255bda3fbda5e797e5a15de685111ee7', 'message': 'Docker image and process cleaup tool\n\nWhen running Docker, you can unknowingly use up a lot\nof memory.  This tool will make it easier to clean up\nDocker.\n\nChange-Id: Icfd780f12b01956093a2933dd484cde1e2d6d5bc\n'}, {'number': 2, 'created': '2014-10-17 18:02:54.000000000', 'files': ['tools/cleanup-images', 'tools/cleanup-containers'], 'web_link': 'https://opendev.org/openstack/kolla/commit/d2194febb5829d66b91ac4151f96fac0bc6555c5', 'message': 'Docker image and process cleaup tool\n\nWhen running Docker, you can unknowingly use up a lot\nof memory.  This tool will make it easier to clean up\nDocker.\n\nChange-Id: Icfd780f12b01956093a2933dd484cde1e2d6d5bc\n'}]",0,129238,d2194febb5829d66b91ac4151f96fac0bc6555c5,11,4,2,10419,,,0,"Docker image and process cleaup tool

When running Docker, you can unknowingly use up a lot
of memory.  This tool will make it easier to clean up
Docker.

Change-Id: Icfd780f12b01956093a2933dd484cde1e2d6d5bc
",git fetch https://review.opendev.org/openstack/kolla refs/changes/38/129238/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/cleanup-images', 'tools/cleanup-processes']",2,dedd6425255bda3fbda5e797e5a15de685111ee7,(detached,#!/bin/bash docker rm $(docker ps -a -q) ,,6,0
openstack%2Fkolla~master~I325f70c278744a1e1fe99b891e05c59c4248c55f,openstack/kolla,master,I325f70c278744a1e1fe99b891e05c59c4248c55f,introduce a common base for compute and controller,MERGED,2014-10-17 19:23:44.000000000,2014-10-17 19:34:04.000000000,2014-10-17 19:34:04.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 5792}]","[{'number': 1, 'created': '2014-10-17 19:23:44.000000000', 'files': ['docker/nova-base/Dockerfile', 'docker/nova-controller/nova-ctr-base/nova.conf', 'docker/nova-compute/nova-compute/config-nova-compute.sh', 'docker/nova-base/build', 'docker/nova-controller/nova-conductor/Dockerfile', 'docker/nova-controller/nova-api/Dockerfile', 'docker/nova-compute/nova-compute/Dockerfile', 'docker/nova-base/config-nova.sh', 'docker/nova-controller/nova-ctr-base/build', 'docker/nova-controller/nova-scheduler/Dockerfile'], 'web_link': 'https://opendev.org/openstack/kolla/commit/a5f6222da89b2515f63531597d7143bb54957ee9', 'message': 'introduce a common base for compute and controller\n\nThis moves nova-ctr-base one level up and renames it nova-base, so that\nwe can share the same basic config between compute and controller pods.\n\nChange-Id: I325f70c278744a1e1fe99b891e05c59c4248c55f\n'}]",0,129362,a5f6222da89b2515f63531597d7143bb54957ee9,7,3,1,8745,,,0,"introduce a common base for compute and controller

This moves nova-ctr-base one level up and renames it nova-base, so that
we can share the same basic config between compute and controller pods.

Change-Id: I325f70c278744a1e1fe99b891e05c59c4248c55f
",git fetch https://review.opendev.org/openstack/kolla refs/changes/62/129362/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/nova-base/Dockerfile', 'docker/nova-controller/nova-ctr-base/nova.conf', 'docker/nova-compute/nova-compute/config-nova-compute.sh', 'docker/nova-base/build', 'docker/nova-controller/nova-conductor/Dockerfile', 'docker/nova-controller/nova-api/Dockerfile', 'docker/nova-compute/nova-compute/Dockerfile', 'docker/nova-base/config-nova.sh', 'docker/nova-controller/nova-ctr-base/build', 'docker/nova-controller/nova-scheduler/Dockerfile']",10,a5f6222da89b2515f63531597d7143bb54957ee9,larsks/nova-base,FROM kollaglue/fedora-rdo-nova-base,FROM kollaglue/fedora-rdo-nova-ctr-base,10,160
openstack%2Fkolla~master~I9249ae2721e375096fc42e1e8462a024c314118e,openstack/kolla,master,I9249ae2721e375096fc42e1e8462a024c314118e,remove glance-pod.json,MERGED,2014-10-17 17:44:13.000000000,2014-10-17 19:33:58.000000000,2014-10-17 19:33:58.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 5792}]","[{'number': 1, 'created': '2014-10-17 17:44:13.000000000', 'files': ['k8s/pod/glance-pod.json'], 'web_link': 'https://opendev.org/openstack/kolla/commit/75b169c663ae3b11e30bea92076e1def69c96305', 'message': 'remove glance-pod.json\n\nThis was replaced by glance-pod.yaml.\n\nChange-Id: I9249ae2721e375096fc42e1e8462a024c314118e\n'}]",0,129340,75b169c663ae3b11e30bea92076e1def69c96305,7,3,1,8745,,,0,"remove glance-pod.json

This was replaced by glance-pod.yaml.

Change-Id: I9249ae2721e375096fc42e1e8462a024c314118e
",git fetch https://review.opendev.org/openstack/kolla refs/changes/40/129340/1 && git format-patch -1 --stdout FETCH_HEAD,['k8s/pod/glance-pod.json'],1,75b169c663ae3b11e30bea92076e1def69c96305,,,"{ ""labels"": { ""name"": ""glance"" }, ""id"": ""glance"", ""desiredState"": { ""manifest"": { ""version"": ""v1beta1"", ""id"": ""glance-1"", ""containers"": [ { ""ports"": [ { ""containerPort"": 9191 } ], ""name"": ""glance-registry"", ""image"": ""kollaglue/fedora-rdo-glance-registry"", ""env"": [ { ""value"": ""password"", ""name"": ""DB_ROOT_PASSWORD"" }, { ""value"": ""password"", ""name"": ""GLANCE_DB_PASSWORD"" }, { ""value"": ""password"", ""name"": ""GLANCE_KEYSTONE_PASSWORD"" }, { ""value"": ""ADMINTOKEN"", ""name"": ""KEYSTONE_ADMIN_TOKEN"" } ] }, { ""ports"": [ { ""containerPort"": 9292 } ], ""name"": ""glance-api"", ""image"": ""kollaglue/fedora-rdo-glance-api"", ""env"": [ { ""value"": ""password"", ""name"": ""DB_ROOT_PASSWORD"" }, { ""value"": ""password"", ""name"": ""GLANCE_DB_PASSWORD"" }, { ""value"": ""password"", ""name"": ""GLANCE_KEYSTONE_PASSWORD"" }, { ""value"": ""ADMINTOKEN"", ""name"": ""KEYSTONE_ADMIN_TOKEN"" } ] } ] } } } ",0,68
openstack%2Fpython-swiftclient~master~I6314b4e45cf2fbffde2fe57a02df77a25e911e84,openstack/python-swiftclient,master,I6314b4e45cf2fbffde2fe57a02df77a25e911e84,Allow segment size to be specified in a human readable way.,MERGED,2014-10-06 14:39:50.000000000,2014-10-17 19:33:07.000000000,2014-10-17 19:33:06.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 7847}, {'_account_id': 8871}, {'_account_id': 11356}, {'_account_id': 13470}]","[{'number': 1, 'created': '2014-10-06 14:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/75c008a115ddbe03df73585c2fa9b9ca4d495337', 'message': ""Allow segment size to be specified in a human readable way.\n\nInstead of always specifying segment size in bytes the user\ncan now use the convention of appending B,K,M or G to the\nsize.\n\nConversion is done with Binary units (1024) rather than SI\nunits (1000).\n\ne.g\n\nswift upload test_container -S 1073741824 large_file\nwould become\nswift upload test_container -S 1G large_file\n\nThe change is backwards compatible as it ignores arguments to -S\nthat don't contain a trailing B,K,M or G\n\nChange-Id: I6314b4e45cf2fbffde2fe57a02df77a25e911e84\n""}, {'number': 2, 'created': '2014-10-07 11:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/f75037fec049878556a9354d940bc783697ff47d', 'message': ""Allow segment size to be specified in a human readable way.\n\nInstead of always specifying segment size in bytes the user\ncan now use B,K,M or G as suffixes for the corresponding\nsize.\n\nConversion is done with Binary units (1024) rather than SI\nunits (1000).\n\ne.g\n\nswift upload test_container -S 1073741824 large_file\nwould become\nswift upload test_container -S 1G large_file\n\nThe change is backwards compatible as it ignores arguments to -S\nthat don't have a B,K,M or G suffix.\n\nUpdated unit tests and help message.\n\nChange-Id: I6314b4e45cf2fbffde2fe57a02df77a25e911e84\n""}, {'number': 3, 'created': '2014-10-10 12:00:21.000000000', 'files': ['swiftclient/shell.py', 'tests/unit/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/5f89dcc46ea0ae126c9ebc328d6569da839336cd', 'message': ""Allow segment size to be specified in a human readable way.\n\nInstead of always specifying segment size in bytes the user\ncan now use B,K,M or G as suffixes for the corresponding\nsize.\n\nConversion is done with Binary units (1024) rather than SI\nunits (1000).\n\ne.g\n\nswift upload test_container -S 1073741824 large_file\ncan now be written\nswift upload test_container -S 1G large_file\n\nThe change is backwards compatible as it ignores arguments to -S\nthat don't have a valid suffix.\n\nUpdated unit tests and help message.\n\nChange-Id: I6314b4e45cf2fbffde2fe57a02df77a25e911e84\n""}]",9,126310,5f89dcc46ea0ae126c9ebc328d6569da839336cd,31,7,3,13470,,,0,"Allow segment size to be specified in a human readable way.

Instead of always specifying segment size in bytes the user
can now use B,K,M or G as suffixes for the corresponding
size.

Conversion is done with Binary units (1024) rather than SI
units (1000).

e.g

swift upload test_container -S 1073741824 large_file
can now be written
swift upload test_container -S 1G large_file

The change is backwards compatible as it ignores arguments to -S
that don't have a valid suffix.

Updated unit tests and help message.

Change-Id: I6314b4e45cf2fbffde2fe57a02df77a25e911e84
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/10/126310/1 && git format-patch -1 --stdout FETCH_HEAD,['swiftclient/shell.py'],1,75c008a115ddbe03df73585c2fa9b9ca4d495337,human_readable_seg_size," if options.segment_size: try: # If segment size only has digits assume it is bytes int(options.segment_size) except ValueError: try: size_mod = ""BKMG"".index(options.segment_size[-1].upper()) multiplier = int(options.segment_size[:-1]) except ValueError: output_manager.error(""Invalid segement size"") return options.segment_size = str(1024**(size_mod) * multiplier) ",,14,0
openstack%2Fhorizon~master~Iae11b46f2e5b340e2c69f812d4f09f390d018749,openstack/horizon,master,Iae11b46f2e5b340e2c69f812d4f09f390d018749,Improve sub-navigation styling,MERGED,2014-10-14 11:43:15.000000000,2014-10-17 19:32:57.000000000,2014-10-17 19:32:56.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 5623}, {'_account_id': 7509}, {'_account_id': 7699}, {'_account_id': 8871}, {'_account_id': 9317}]","[{'number': 1, 'created': '2014-10-14 11:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a6ba9a78cb864e96840a90c06b82d913d3cbd399', 'message': 'Improve sub-navigation styling\n\nChange-Id: Iae11b46f2e5b340e2c69f812d4f09f390d018749\nCloses-bug: #1378568\n'}, {'number': 2, 'created': '2014-10-15 11:15:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/080e98dfec01ffa742f338f2dc62e447b6fbb7e3', 'message': 'Improve sub-navigation styling\n\nChange-Id: Iae11b46f2e5b340e2c69f812d4f09f390d018749\nCloses-bug: #1378568\n'}, {'number': 3, 'created': '2014-10-15 11:48:05.000000000', 'files': ['openstack_dashboard/static/dashboard/scss/horizon.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e5155c7a752f8183039a2ca378f72293e6ad6f78', 'message': 'Improve sub-navigation styling\n\nChange-Id: Iae11b46f2e5b340e2c69f812d4f09f390d018749\nCloses-bug: #1378568\nCo-Authored by: Jiri Tomasek <jtomasek@redhat.com>\n'}]",1,128247,e5155c7a752f8183039a2ca378f72293e6ad6f78,23,7,3,9317,,,0,"Improve sub-navigation styling

Change-Id: Iae11b46f2e5b340e2c69f812d4f09f390d018749
Closes-bug: #1378568
Co-Authored by: Jiri Tomasek <jtomasek@redhat.com>
",git fetch https://review.opendev.org/openstack/horizon refs/changes/47/128247/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/dashboard/scss/horizon.scss'],1,a6ba9a78cb864e96840a90c06b82d913d3cbd399,nav-tabs, background-color: #f1f1f1; border-top: 1px solid #5a5a5a; border-radius: 0; &:hover { color: white; border-top-color: #5a5a5a; background-color: #5a5a5a; } color: white; background-color: #5a5a5a;, border-top: 1px solid $border-color; border-bottom: 1px solid $border-color;,10,2
openstack%2Fgrenade~master~I27eaee22d46643f847cdd40a86a14cb7d9aa794b,openstack/grenade,master,I27eaee22d46643f847cdd40a86a14cb7d9aa794b,Add within-kilo and update within-master,MERGED,2014-10-14 22:30:03.000000000,2014-10-17 19:16:38.000000000,2014-10-17 19:16:38.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1420}, {'_account_id': 1849}]","[{'number': 1, 'created': '2014-10-14 22:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/d3ec69a294c9184fa466d387fab57bae8f8def9e', 'message': 'Add within-kilo and update within-master\n\nMaster has moved to kilo, update sideways symlink to point to\nthe correct directory.\n\nChange-Id: I27eaee22d46643f847cdd40a86a14cb7d9aa794b\n'}, {'number': 2, 'created': '2014-10-14 22:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/7570d2c857fb72de127f502b5ce03fa8d255115c', 'message': 'Add within-kilo and update within-master\n\nMaster has moved to kilo, update sideways symlink to point to\nthe correct directory.\n\nChange-Id: I27eaee22d46643f847cdd40a86a14cb7d9aa794b\n'}, {'number': 3, 'created': '2014-10-15 18:23:19.000000000', 'files': ['within-master', 'within-kilo/README.rst'], 'web_link': 'https://opendev.org/openstack/grenade/commit/4e5c0bfa7eb709681aa6f7fb99618da3038dbce1', 'message': ""Add within-kilo and update within-master\n\nProjects master branches have opened for kilo and juno proposed+stable branches\nhave been cut. This update sideways master symlink to point to the correct\ndirectory, ensuring that sideways runs against master branches run the correct\n'within-kilo' scripts.\n\nChange-Id: I27eaee22d46643f847cdd40a86a14cb7d9aa794b\n""}]",1,128464,4e5c0bfa7eb709681aa6f7fb99618da3038dbce1,14,4,3,1420,,,0,"Add within-kilo and update within-master

Projects master branches have opened for kilo and juno proposed+stable branches
have been cut. This update sideways master symlink to point to the correct
directory, ensuring that sideways runs against master branches run the correct
'within-kilo' scripts.

Change-Id: I27eaee22d46643f847cdd40a86a14cb7d9aa794b
",git fetch https://review.opendev.org/openstack/grenade refs/changes/64/128464/2 && git format-patch -1 --stdout FETCH_HEAD,['within-master'],1,d3ec69a294c9184fa466d387fab57bae8f8def9e,open_kilo,within-kilo,within-juno/,1,1
openstack%2Fhorizon~master~I3ec84d14c8be7e3aae066119e963c4093f8aa345,openstack/horizon,master,I3ec84d14c8be7e3aae066119e963c4093f8aa345,Pass correct project ID to get tenant_usages,MERGED,2014-10-16 20:13:39.000000000,2014-10-17 19:16:29.000000000,2014-10-17 19:16:28.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 5623}, {'_account_id': 6635}, {'_account_id': 6637}, {'_account_id': 7213}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-10-16 20:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/62dffa4e4f2c058cf89d8059ccb37d0e16e9ba94', 'message': 'Pass correct project ID to get tenant_usages\n\nThe current implementation of tenant_quota_usages did not allow for\nqueries regarding projects that were not the currently active project,\nthis meant that when an admin went to edit or create a project it tried\nto verify the usages against the wrong project. This patch adds the\ncode for passing a project id to the tenant_quota_usages function so\nthat the usages can be fetched for a specific project, as well as\nremoves the need for usage validation on creation of a new project.\n\nChange-Id: I3ec84d14c8be7e3aae066119e963c4093f8aa345\nCloses-Bug: 1380701\n'}, {'number': 2, 'created': '2014-10-17 10:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b99288da6a05fa1547e5b7ab9594b22ab828d8a7', 'message': 'Pass correct project ID to get tenant_usages\n\nThe current implementation of tenant_quota_usages did not allow for\nqueries regarding projects that were not the currently active project,\nthis meant that when an admin went to edit or create a project it tried\nto verify the usages against the wrong project. This patch adds the\ncode for passing a project id to the tenant_quota_usages function so\nthat the usages can be fetched for a specific project, as well as\nremoves the need for usage validation on creation of a new project.\n\nChange-Id: I3ec84d14c8be7e3aae066119e963c4093f8aa345\nCloses-Bug: 1380701\n'}, {'number': 3, 'created': '2014-10-17 14:35:22.000000000', 'files': ['openstack_dashboard/dashboards/identity/projects/tests.py', 'openstack_dashboard/dashboards/identity/projects/views.py', 'openstack_dashboard/usage/quotas.py', 'openstack_dashboard/dashboards/identity/projects/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/193d40a41472adc6c27e18256524afb2dacb9156', 'message': 'Pass correct project ID to get tenant_usages\n\nThe current implementation of tenant_quota_usages did not allow for\nqueries regarding projects that were not the currently active project,\nthis meant that when an admin went to edit or create a project it tried\nto verify the usages against the wrong project. This patch adds the\ncode for passing a project id to the tenant_quota_usages function so\nthat the usages can be fetched for a specific project, as well as\nremoves the need for usage validation on creation of a new project.\n\nChange-Id: I3ec84d14c8be7e3aae066119e963c4093f8aa345\nCloses-Bug: 1380701\n'}]",6,129037,193d40a41472adc6c27e18256524afb2dacb9156,24,7,3,6637,,,0,"Pass correct project ID to get tenant_usages

The current implementation of tenant_quota_usages did not allow for
queries regarding projects that were not the currently active project,
this meant that when an admin went to edit or create a project it tried
to verify the usages against the wrong project. This patch adds the
code for passing a project id to the tenant_quota_usages function so
that the usages can be fetched for a specific project, as well as
removes the need for usage validation on creation of a new project.

Change-Id: I3ec84d14c8be7e3aae066119e963c4093f8aa345
Closes-Bug: 1380701
",git fetch https://review.opendev.org/openstack/horizon refs/changes/37/129037/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/identity/projects/tests.py', 'openstack_dashboard/dashboards/identity/projects/views.py', 'openstack_dashboard/usage/quotas.py', 'openstack_dashboard/dashboards/identity/projects/workflows.py']",4,62dffa4e4f2c058cf89d8059ccb37d0e16e9ba94,bug/1380701,"class ProjectQuotaAction(workflows.Action): super(ProjectQuotaAction, self).__init__(request, *args, **kwargs) class UpdateProjectQuotaAction(ProjectQuotaAction): usages = quotas.tenant_quota_usages( self.request, tenant_id=self.initial['project_id']) class Meta: name = _(""Quota"") slug = 'update_quotas' help_text = _(""Set maximum quotas for the project."") class CreateProjectQuotaAction(ProjectQuotaAction): def clean(self): return super(CreateProjectQuotaAction, self).clean() class Meta: name = _(""Quota"") slug = 'create_quotas' help_text = _(""Set maximum quotas for the project."") class CreateProjectQuota(workflows.Step): action_class = CreateProjectQuotaAction depends_on = (""project_id"",) contributes = quotas.QUOTA_FIELDS CreateProjectQuota) CreateProjectQuota)","class UpdateProjectQuotaAction(workflows.Action): super(UpdateProjectQuotaAction, self).__init__(request, *args, **kwargs) class Meta: name = _(""Quota"") slug = 'update_quotas' help_text = _(""Set maximum quotas for the project."") usages = quotas.tenant_quota_usages(self.request) UpdateProjectQuota) UpdateProjectQuota)",60,91
openstack%2Foslo.db~master~I676c9c5e418905160e4ab647b8a0f2fb601e8962,openstack/oslo.db,master,I676c9c5e418905160e4ab647b8a0f2fb601e8962,Set utf8 encoding for mysql and postgresql,MERGED,2014-08-01 10:51:47.000000000,2014-10-17 19:16:16.000000000,2014-10-17 19:16:15.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5803}, {'_account_id': 6849}, {'_account_id': 6928}, {'_account_id': 7491}, {'_account_id': 8041}, {'_account_id': 9656}, {'_account_id': 11816}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-08-01 10:51:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/94ce31b0609a6c4c3128cc06617404ee941898a9', 'message': ""Set utf8 encoding for mysql and postgresql\n\nCurrently, it's enforced in devstack through setting encoding in\nconnection URI. It would be beneficial if oslo.db handles that on its\nown, so that we can\n\n- remove those connection arguments from devstack;\n- more importantly, not rely on users to set it in all affected\n  projects.\n\nChange-Id: I676c9c5e418905160e4ab647b8a0f2fb601e8962\nCloses-Bug: 1340779\n""}, {'number': 2, 'created': '2014-08-01 11:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/4746ababbfb579d0182e908d74ddc3e32f14c065', 'message': ""Set utf8 encoding for mysql and postgresql\n\nCurrently, it's enforced in devstack through setting encoding in\nconnection URI. It would be beneficial if oslo.db handles that on its\nown, so that we can\n\n- remove those connection arguments from devstack;\n- more importantly, not rely on users to set it in all affected\n  projects.\n\nChange-Id: I676c9c5e418905160e4ab647b8a0f2fb601e8962\nCloses-Bug: 1340779\n""}, {'number': 3, 'created': '2014-08-11 11:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/ace1a08863e77668eb8feb29e99df72a261c8004', 'message': ""Set utf8 encoding for mysql and postgresql\n\nCurrently, it's enforced in devstack through setting encoding in\nconnection URI. It would be beneficial if oslo.db handles that on its\nown, so that we can\n\n- remove those connection arguments from devstack;\n- more importantly, not rely on users to set it in all affected\n  projects.\n\nChange-Id: I676c9c5e418905160e4ab647b8a0f2fb601e8962\nCloses-Bug: 1340779\n""}, {'number': 4, 'created': '2014-08-11 11:15:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/c1474cc8c27fda71bcdd6871d6ea2aeee5a72018', 'message': ""Set utf8 encoding for mysql and postgresql\n\nCurrently, it's enforced in devstack through setting encoding in\nconnection URI. It would be beneficial if oslo.db handles that on its\nown, so that we can\n\n- remove those connection arguments from devstack;\n- more importantly, not rely on users to set it in all affected\n  projects.\n\nChange-Id: I676c9c5e418905160e4ab647b8a0f2fb601e8962\nCloses-Bug: 1340779\n""}, {'number': 5, 'created': '2014-08-12 06:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/29bebf8b3a92825e4206df30f61ae2f3ec6011af', 'message': ""Set utf8 encoding for mysql and postgresql\n\nCurrently, it's enforced in devstack through setting encoding in\nconnection URI. It would be beneficial if oslo.db handles that on its\nown, so that we can\n\n- remove those connection arguments from devstack;\n- more importantly, not rely on users to set it in all affected\n  projects.\n\nChange-Id: I676c9c5e418905160e4ab647b8a0f2fb601e8962\nCloses-Bug: 1340779\n""}, {'number': 6, 'created': '2014-08-13 18:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/ab129c80b287ef4d8de24687f617822fb3c48b9c', 'message': ""Set utf8 encoding for mysql and postgresql\n\nCurrently, it's enforced in devstack through setting encoding in\nconnection URI. It would be beneficial if oslo.db handles that on its\nown, so that we can\n\n- remove those connection arguments from devstack;\n- more importantly, not rely on users to set it in all affected\n  projects.\n\nChange-Id: I676c9c5e418905160e4ab647b8a0f2fb601e8962\nCloses-Bug: 1340779\n""}, {'number': 7, 'created': '2014-08-22 21:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/40901ec9e27797c15fa777e1938f426922965df7', 'message': ""Set utf8 encoding for mysql and postgresql\n\nCurrently, it's enforced in devstack through setting encoding in\nconnection URI. It would be beneficial if oslo.db handles that on its\nown, so that we can\n\n- remove those connection arguments from devstack;\n- more importantly, not rely on users to set it in all affected\n  projects.\n\nChange-Id: I676c9c5e418905160e4ab647b8a0f2fb601e8962\nCloses-Bug: 1340779\n""}, {'number': 8, 'created': '2014-08-25 12:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/0acbf0360ebe0dafc5577df58d94fe354bc75a7d', 'message': ""Set utf8 encoding for mysql and postgresql\n\nCurrently, it's enforced in devstack through setting encoding in\nconnection URI. It would be beneficial if oslo.db handles that on its\nown, so that we can\n\n- remove those connection arguments from devstack;\n- more importantly, not rely on users to set it in all affected\n  projects.\n\nChange-Id: I676c9c5e418905160e4ab647b8a0f2fb601e8962\nCloses-Bug: 1340779\n""}, {'number': 9, 'created': '2014-09-08 09:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/6f2375eff2f5510b7459efffcd0981f7f1070291', 'message': ""Set utf8 encoding for mysql and postgresql\n\nCurrently, it's enforced in devstack through setting encoding in\nconnection URI. It would be beneficial if oslo.db handles that on its\nown, so that we can\n\n- remove those connection arguments from devstack;\n- more importantly, not rely on users to set it in all affected\n  projects.\n\nOursql and MySQLdb also require use_unicode=0 to avoid performance drop.\n\nChange-Id: I676c9c5e418905160e4ab647b8a0f2fb601e8962\nCloses-Bug: 1340779\n""}, {'number': 10, 'created': '2014-09-25 09:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/71c25693417c465b3fdc8e893fa67be990d6dbd9', 'message': ""Set utf8 encoding for mysql and postgresql\n\nCurrently, it's enforced in devstack through setting encoding in\nconnection URI. It would be beneficial if oslo.db handles that on its\nown, so that we can\n\n- remove those connection arguments from devstack;\n- more importantly, not rely on users to set it in all affected\n  projects.\n\nOursql and MySQLdb also require use_unicode=0 to avoid performance drop.\n\nChange-Id: I676c9c5e418905160e4ab647b8a0f2fb601e8962\nCloses-Bug: 1340779\n""}, {'number': 11, 'created': '2014-10-10 14:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/150077b9d2c1a15176cf1bd52ff08681f852c6ad', 'message': ""Set utf8 encoding for mysql and postgresql\n\nCurrently, it's enforced in devstack through setting encoding in\nconnection URI. It would be beneficial if oslo.db handles that on its\nown, so that we can\n\n- remove those connection arguments from devstack;\n- more importantly, not rely on users to set it in all affected\n  projects.\n\nOursql and MySQLdb also require use_unicode=0 to avoid performance drop.\n\nChange-Id: I676c9c5e418905160e4ab647b8a0f2fb601e8962\nCloses-Bug: 1340779\n""}, {'number': 12, 'created': '2014-10-17 10:05:30.000000000', 'files': ['tests/sqlalchemy/test_sqlalchemy.py', 'oslo/db/sqlalchemy/session.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/2a6dbcd09f7f181f026bf8b5e632f9d3b74884b3', 'message': ""Set utf8 encoding for mysql and postgresql\n\nCurrently, it's enforced in devstack through setting encoding in\nconnection URI. It would be beneficial if oslo.db handles that on its\nown, so that we can\n\n- remove those connection arguments from devstack;\n- more importantly, not rely on users to set it in all affected\n  projects.\n\nOursql and MySQLdb also require use_unicode=0 to avoid performance drop.\n\nChange-Id: I676c9c5e418905160e4ab647b8a0f2fb601e8962\nCloses-Bug: 1340779\n""}]",11,111236,2a6dbcd09f7f181f026bf8b5e632f9d3b74884b3,73,11,12,9656,,,0,"Set utf8 encoding for mysql and postgresql

Currently, it's enforced in devstack through setting encoding in
connection URI. It would be beneficial if oslo.db handles that on its
own, so that we can

- remove those connection arguments from devstack;
- more importantly, not rely on users to set it in all affected
  projects.

Oursql and MySQLdb also require use_unicode=0 to avoid performance drop.

Change-Id: I676c9c5e418905160e4ab647b8a0f2fb601e8962
Closes-Bug: 1340779
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/36/111236/12 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/db/sqlalchemy/session.py', 'tests/sqlalchemy/test_sqlalchemy.py']",2,94ce31b0609a6c4c3128cc06617404ee941898a9,bug/1340779," self.assertFalse( create_engine.mock_calls[0][2]['connect_args'] self.assertEqual( create_engine.mock_calls[0][2]['connect_args'], {'charset': 'utf8'} {'charset': 'utf8', 'raise_on_warnings': False} ) def test_postgresql_connect_args(self): with self._fixture() as (create_engine, listen_evt): session.create_engine(""postgresql://u:p@host/test"") self.assertEqual( create_engine.mock_calls[0][2]['connect_args'], {'client_encoding': 'utf8'}", self.assertTrue( 'connect_args' not in create_engine.mock_calls[0][2] self.assertTrue( 'connect_args' not in create_engine.mock_calls[0][2] {'raise_on_warnings': False},34,7
openstack%2Foslo-incubator~master~I47b8c8d71287eb4a37fb72ab8a179bd0b71cc2ad,openstack/oslo-incubator,master,I47b8c8d71287eb4a37fb72ab8a179bd0b71cc2ad,Use list.pop(0) to keep the code simpler,MERGED,2014-10-08 22:27:46.000000000,2014-10-17 18:42:27.000000000,2014-10-17 18:42:26.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 6928}, {'_account_id': 11022}, {'_account_id': 13140}, {'_account_id': 13463}]","[{'number': 1, 'created': '2014-10-08 22:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/20d5ef5d23b8b9986d024a8b8fca3ddd2a552a90', 'message': 'Fix attributes ordering at common/imageutils.py\n\nFix attributes alphabetical ordering at common/imageutils.py.\nAlso replace double quotes for single quotes and use pop(0) to keep the code simpler.\n\nChange-Id: I47b8c8d71287eb4a37fb72ab8a179bd0b71cc2ad\n'}, {'number': 2, 'created': '2014-10-10 21:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/66644d1b0d1641606ba9673da15b57975976449e', 'message': 'Fix attributes ordering at common/imageutils.py\n\nFix attributes alphabetical ordering at common/imageutils.py.\nAlso replace double quotes for single quotes and use pop(0) to keep the code simpler.\n\nChange-Id: I47b8c8d71287eb4a37fb72ab8a179bd0b71cc2ad\n'}, {'number': 3, 'created': '2014-10-15 03:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/15a3c1ce7f0dac703d6541fc84fa6734a3aa2ef6', 'message': 'Use list.pop(0) to keep the code simpler.\n\nUse ""x = list.pop(0)"" instead of ""x = list[0]; del list[0]"" to keep the code simpler. Also fix attributes alphabetical ordering and replace double quotes for single quotes.\n\nChange-Id: I47b8c8d71287eb4a37fb72ab8a179bd0b71cc2ad\n'}, {'number': 4, 'created': '2014-10-15 03:35:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/34da14119bb2008f30fd6ac44acc944e31215522', 'message': 'Use list.pop(0) to keep the code simpler.\n\nUse ""x = list.pop(0)"" instead of ""x = list[0]; del list[0]"" to keep the code simpler. \nAlso fix attributes alphabetical ordering and replace double quotes for single quotes.\n\nChange-Id: I47b8c8d71287eb4a37fb72ab8a179bd0b71cc2ad\n'}, {'number': 5, 'created': '2014-10-15 03:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/55b87fd728d09c732ce20890d4a69914f38f42d8', 'message': 'Use list.pop(0) to keep the code simpler\n\nUse ""x = list.pop(0)"" instead of ""x = list[0]; del list[0]"" to keep the code simpler. \nAlso fix attributes alphabetical ordering and replace double quotes for single quotes.\n\nChange-Id: I47b8c8d71287eb4a37fb72ab8a179bd0b71cc2ad\n'}, {'number': 6, 'created': '2014-10-16 00:50:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f2e32f0d51524e083be9299240a844738014c6b0', 'message': 'Use list.pop(0) to keep the code simpler\n\nUse ""x = list.pop(0)"" instead of ""x = list[0]; del list[0]"" to keep the code simpler.\n\nChange-Id: I47b8c8d71287eb4a37fb72ab8a179bd0b71cc2ad\n'}, {'number': 7, 'created': '2014-10-16 14:23:47.000000000', 'files': ['openstack/common/imageutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b2d35eecc1704328f55082ebdaae8004f029187a', 'message': 'Use list.pop(0) to keep the code simpler\n\nUse ""x = list.pop(0)"" instead of ""x = list[0]; del list[0]"" to keep the code simpler.\n\nChange-Id: I47b8c8d71287eb4a37fb72ab8a179bd0b71cc2ad\n'}]",16,127050,b2d35eecc1704328f55082ebdaae8004f029187a,30,7,7,13463,,,0,"Use list.pop(0) to keep the code simpler

Use ""x = list.pop(0)"" instead of ""x = list[0]; del list[0]"" to keep the code simpler.

Change-Id: I47b8c8d71287eb4a37fb72ab8a179bd0b71cc2ad
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/50/127050/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/imageutils.py'],1,20d5ef5d23b8b9986d024a8b8fca3ddd2a552a90,," BACKING_FILE_RE = re.compile((r'^(.*?)\s*\(actual\s+path\s*:' r'\s+(.*?)\)\s*$'), re.I) TOP_LEVEL_RE = re.compile(r'^([\w\d\s\_\-]+):(.*)$') SIZE_RE = re.compile(r'(\d*\.?\d+)(\w+)?(\s*\(\s*(\d+)\s+bytes\s*\))?', self.file_format = details.get('file_format') self.image = details.get('image') self.snapshots = details.get('snapshot_list', []) self.virtual_size = details.get('virtual_size') lines.append('snapshots: %s' % self.snapshots) if self.encrypted: lines.append('encrypted: %s' % self.encrypted) return '\n'.join(lines) for c in (' ', '-'): header = lines_after.pop(0) if not lines_after or not header.startswith('ID'): msg = _('Snapshot list encountered but no header found!') line = lines_after.pop(0) date_pieces = line_pieces[5].split(':') 'vm_clock': '%s %s' % (line_pieces[4], line_pieces[5])"," BACKING_FILE_RE = re.compile((r""^(.*?)\s*\(actual\s+path\s*:"" r""\s+(.*?)\)\s*$""), re.I) TOP_LEVEL_RE = re.compile(r""^([\w\d\s\_\-]+):(.*)$"") SIZE_RE = re.compile(r""(\d*\.?\d+)(\w+)?(\s*\(\s*(\d+)\s+bytes\s*\))?"", self.image = details.get('image') self.file_format = details.get('file_format') self.virtual_size = details.get('virtual_size') self.snapshots = details.get('snapshot_list', []) lines.append(""snapshots: %s"" % self.snapshots) if self.encrypted: lines.append(""encrypted: %s"" % self.encrypted) return ""\n"".join(lines) for c in ("" "", ""-""): if not lines_after or not lines_after[0].startswith(""ID""): msg = _(""Snapshot list encountered but no header found!"") del lines_after[0] line = lines_after[0] date_pieces = line_pieces[5].split("":"") 'vm_clock': line_pieces[4] + "" "" + line_pieces[5], del lines_after[0]",18,19
openstack%2Fglance~master~I1550bd519f100cdffcf5046e9838cf192d4aac50,openstack/glance,master,I1550bd519f100cdffcf5046e9838cf192d4aac50,Refactor metadef ORM classes to use to_dict instead of as_dict,MERGED,2014-09-16 13:43:32.000000000,2014-10-17 18:29:21.000000000,2014-10-17 18:29:20.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6493}, {'_account_id': 6549}, {'_account_id': 8759}, {'_account_id': 10383}, {'_account_id': 12363}, {'_account_id': 12395}]","[{'number': 1, 'created': '2014-09-16 13:43:32.000000000', 'files': ['glance/db/sqlalchemy/metadef_api/property.py', 'glance/db/sqlalchemy/models_metadef.py', 'glance/db/sqlalchemy/metadef_api/resource_type_association.py', 'glance/db/sqlalchemy/metadef_api/object.py', 'glance/db/sqlalchemy/metadef_api/resource_type.py', 'glance/db/sqlalchemy/metadef_api/namespace.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/7baa3d9ff8361fe87e0597486c8905338b4901fd', 'message': 'Refactor metadef ORM classes to use to_dict instead of as_dict\n\nThe Metadef ORM base dictionary class should replace as_dict with to_dict\nto be consistent with other Glance ORM classes.\n\nChange-Id: I1550bd519f100cdffcf5046e9838cf192d4aac50\nCloses-Bug: 1370058\n'}]",0,121836,7baa3d9ff8361fe87e0597486c8905338b4901fd,18,10,1,10383,,,0,"Refactor metadef ORM classes to use to_dict instead of as_dict

The Metadef ORM base dictionary class should replace as_dict with to_dict
to be consistent with other Glance ORM classes.

Change-Id: I1550bd519f100cdffcf5046e9838cf192d4aac50
Closes-Bug: 1370058
",git fetch https://review.opendev.org/openstack/glance refs/changes/36/121836/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/db/sqlalchemy/metadef_api/property.py', 'glance/db/sqlalchemy/models_metadef.py', 'glance/db/sqlalchemy/metadef_api/resource_type_association.py', 'glance/db/sqlalchemy/metadef_api/object.py', 'glance/db/sqlalchemy/metadef_api/resource_type.py', 'glance/db/sqlalchemy/metadef_api/namespace.py']",6,7baa3d9ff8361fe87e0597486c8905338b4901fd,bug/1370058," if not _is_namespace_visible(context, namespace_rec.to_dict()): if not _is_namespace_visible(context, namespace_rec.to_dict()): return map(lambda ns: ns.to_dict(), namespaces) return namespace_rec.to_dict() return namespace.to_dict() return namespace_rec.to_dict() return namespace_rec.to_dict() return namespace_rec.to_dict()"," if not _is_namespace_visible(context, namespace_rec.as_dict()): if not _is_namespace_visible(context, namespace_rec.as_dict()): return map(lambda ns: ns.as_dict(), namespaces) return namespace_rec.as_dict() return namespace.as_dict() return namespace_rec.as_dict() return namespace_rec.as_dict() return namespace_rec.as_dict()",26,26
openstack%2Fhorizon~master~Iccd0e2dfb545a95cb1b9a809187103bb3a5a76a7,openstack/horizon,master,Iccd0e2dfb545a95cb1b9a809187103bb3a5a76a7,Disable router HA attribute due to Neutron bug,MERGED,2014-10-14 16:04:42.000000000,2014-10-17 18:28:01.000000000,2014-10-17 18:28:01.000000000,"[{'_account_id': 3}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 7213}, {'_account_id': 9576}, {'_account_id': 11592}]","[{'number': 1, 'created': '2014-10-14 16:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/be7b0f1bbc9f83a56f3bec971073cbb4deff261a', 'message': 'Disable router HA attribute due to Neutron bug\n\nChange-Id: Iccd0e2dfb545a95cb1b9a809187103bb3a5a76a7\nCloses-Bug: #1378525\n'}, {'number': 2, 'created': '2014-10-14 16:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5b6c94bca9cedb9b7218b96c2d412eaa0239ea7a', 'message': 'Disable router HA attribute due to Neutron bug\n\nChange-Id: Iccd0e2dfb545a95cb1b9a809187103bb3a5a76a7\nCloses-Bug: #1378525\n'}, {'number': 3, 'created': '2014-10-17 12:51:05.000000000', 'files': ['openstack_dashboard/dashboards/project/routers/tests.py', 'openstack_dashboard/dashboards/project/routers/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/03c562736b984d8a3478c06bb1f8d9c1dbe5f537', 'message': 'Disable router HA attribute due to Neutron bug\n\nChange-Id: Iccd0e2dfb545a95cb1b9a809187103bb3a5a76a7\nCloses-Bug: #1378525\n'}]",0,128341,03c562736b984d8a3478c06bb1f8d9c1dbe5f537,16,6,3,841,,,0,"Disable router HA attribute due to Neutron bug

Change-Id: Iccd0e2dfb545a95cb1b9a809187103bb3a5a76a7
Closes-Bug: #1378525
",git fetch https://review.opendev.org/openstack/horizon refs/changes/41/128341/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/routers/tests.py', 'openstack_dashboard/dashboards/project/routers/forms.py']",2,be7b0f1bbc9f83a56f3bec971073cbb4deff261a,bug/1378525," # TODO(amotoki): Due to Neutorn Bug 1378525, Neutron disables # PUT operation. It will be fixed in Kilo cycle. # self.ha_allowed = api.neutron.get_feature_permission( # self.request, ""l3-ha"", ""update"") self.ha_allowed = False"," self.ha_allowed = api.neutron.get_feature_permission(self.request, ""l3-ha"", ""update"")",20,14
openstack%2Fhorizon~master~I5d90bae558ccbdcb0268bd7371161a10a722cca1,openstack/horizon,master,I5d90bae558ccbdcb0268bd7371161a10a722cca1,Adding policy-based support to Horizon's Dashboards,ABANDONED,2014-06-11 18:37:24.000000000,2014-10-17 18:22:58.000000000,,"[{'_account_id': 3}, {'_account_id': 8871}, {'_account_id': 10046}, {'_account_id': 10697}]","[{'number': 1, 'created': '2014-06-11 18:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/20039d45920658204b619a04313f0fa11e256811', 'message': ""Adding policy-based support to Horizon's Dashboards\n\n[better describe it before review]\n\nChange-Id: I5d90bae558ccbdcb0268bd7371161a10a722cca1\n""}, {'number': 2, 'created': '2014-06-11 20:35:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/193ad34b9f7a30d4a9ca2514a0d3ef911f21189a', 'message': ""Adding policy-based support to Horizon's Dashboards\n\n[better describe it before review]\n\nRelated-Bug: 1226627\nChange-Id: I5d90bae558ccbdcb0268bd7371161a10a722cca1\n""}, {'number': 3, 'created': '2014-06-12 14:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b59eff9f3e0e80c31a9e4e64b88e67a80bf98aa2', 'message': ""Adding policy-based support to Horizon's Dashboards\n\n[better describe it before review]\n\nRelated-Bug: 1226627\nChange-Id: I5d90bae558ccbdcb0268bd7371161a10a722cca1\n""}, {'number': 4, 'created': '2014-06-16 15:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/984c6d9c00962b5b70513825bfa3607bc66e552b', 'message': ""Adding policy-based support to Horizon's Dashboards\n\n[better describe it before review]\n\nRelated-Bug: 1226627\nChange-Id: I5d90bae558ccbdcb0268bd7371161a10a722cca1\n""}, {'number': 5, 'created': '2014-06-18 20:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/77f5acb584344064fb67f494c960a28e053bc461', 'message': ""Adding policy-based support to Horizon's Dashboards\n\n[better describe it before review]\n\nRelated-Bug: 1226627\nChange-Id: I5d90bae558ccbdcb0268bd7371161a10a722cca1\n""}, {'number': 6, 'created': '2014-06-18 21:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0c4e9bfcbc423b1138868f5b210e6df392137d1b', 'message': ""Adding policy-based support to Horizon's Dashboards\n\nIn order to remove hard-coded checks based on roles, this patch\ncreates a policy file to Horizon and enables the protection of\nDashboards using rules in this policy, adding more flexibility\nin protecting Horizon's capabilities.\n\nTo show how it could be acchieved, we protected the Admin Dashboard\nthrough a policy rule.\n\nRelated-Bug: 1226627\nChange-Id: I5d90bae558ccbdcb0268bd7371161a10a722cca1\n""}, {'number': 7, 'created': '2014-06-19 18:58:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/26227d73fe70d95a42ae315d33639ecf0b7b3bb4', 'message': ""Adding policy-based support to Horizon's Dashboards\n\nIn order to remove hard-coded checks based on roles, this patch\ncreates a policy file to Horizon and enables the protection of\nDashboards using rules in this policy, adding more flexibility\nin protecting Horizon's capabilities.\n\nTo show how it could be acchieved, we protected the Admin Dashboard\nthrough a policy rule.\n\nRelated-Bug: 1226627\nChange-Id: I5d90bae558ccbdcb0268bd7371161a10a722cca1\n""}, {'number': 8, 'created': '2014-06-20 13:05:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/64ac8630adf9bcfc34e2daa31e210cf3fdf96d97', 'message': ""Adding policy-based support to Horizon's Dashboards\n\nIn order to remove hard-coded checks based on roles, this patch\ncreates a policy file to Horizon and enables the protection of\nDashboards using rules in this policy, adding more flexibility\nin protecting Horizon's capabilities.\n\nTo show how it could be acchieved, we protected the Admin Dashboard\nthrough a policy rule.\n\nRelated-Bug: 1226627\nChange-Id: I5d90bae558ccbdcb0268bd7371161a10a722cca1\n""}, {'number': 9, 'created': '2014-07-15 19:36:13.000000000', 'files': ['openstack_dashboard/policy.py', 'horizon/base.py', 'horizon/decorators.py', 'openstack_dashboard/conf/horizon_policy.json', 'horizon/test/tests/base.py', 'openstack_dashboard/test/tests/policy.py', 'openstack_dashboard/dashboards/admin/dashboard.py', 'openstack_dashboard/settings.py', 'openstack_dashboard/test/settings.py', 'horizon/templatetags/horizon.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/728a3deecb03cb7c81294c75700a097390188a22', 'message': ""Adding policy-based support to Horizon's Dashboards\n\nIn order to remove hard-coded checks based on roles, this patch\ncreates a policy file to Horizon and enables the protection of\nDashboards using rules in this policy, adding more flexibility\nin protecting Horizon's capabilities.\n\nTo show how it could be acchieved, we protected the Admin Dashboard\nthrough a policy rule.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\n\nRelated-Bug: 1226627\nChange-Id: I5d90bae558ccbdcb0268bd7371161a10a722cca1\n""}]",0,99446,728a3deecb03cb7c81294c75700a097390188a22,36,4,9,10697,,,0,"Adding policy-based support to Horizon's Dashboards

In order to remove hard-coded checks based on roles, this patch
creates a policy file to Horizon and enables the protection of
Dashboards using rules in this policy, adding more flexibility
in protecting Horizon's capabilities.

To show how it could be acchieved, we protected the Admin Dashboard
through a policy rule.

Co-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>

Related-Bug: 1226627
Change-Id: I5d90bae558ccbdcb0268bd7371161a10a722cca1
",git fetch https://review.opendev.org/openstack/horizon refs/changes/46/99446/4 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/base.py', 'horizon/decorators.py', 'openstack_dashboard/dashboards/admin/dashboard.py']",3,20039d45920658204b619a04313f0fa11e256811,bug/1226627," policy_rules = ((""identity"", ""admin_required""),)"," permissions = ('openstack.roles.admin',)",63,6
openstack%2Ftrove~master~I8cbb728c7db41f50fb5eaf0662a2d7e99248b864,openstack/trove,master,I8cbb728c7db41f50fb5eaf0662a2d7e99248b864,Obsolete oslo-incubator modules - lockutils,ABANDONED,2014-10-17 11:08:14.000000000,2014-10-17 17:04:25.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-10-17 11:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b171763affd64803cd6a8728b9d658b567a12254', 'message': 'Do not use obsolete oslo-incubator modules\n\nThis change handles lockutils which is not used in trove.\n\nThe change is merely to delete the file and update\nopenstack-common.conf.\n\nChange-Id: I8cbb728c7db41f50fb5eaf0662a2d7e99248b864\nPartial-Bug: #1380789\nblueprint: trove-migrate-oslo-concurrency\n'}, {'number': 2, 'created': '2014-10-17 11:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/da11fa229e13bd3719782149c38914b51edee9a3', 'message': 'Do not use obsolete oslo-incubator modules\n\nThis change handles lockutils which is not used in trove.\n\nThe change is merely to delete the file and update\nopenstack-common.conf.\n\nChange-Id: I8cbb728c7db41f50fb5eaf0662a2d7e99248b864\nPartial-Bug: #1380789\nblueprint: trove-migrate-oslo-concurrency\nblueprint: trove-retire-unused-modules\n'}, {'number': 3, 'created': '2014-10-17 11:58:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/cbfedd6d87fd2c9638305e1ba1692848e95d939a', 'message': 'Obsolete oslo-incubator modules - lockutils\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis change handles lockutils which is not used in trove.\n\nThe change is merely to delete the file and update\nopenstack-common.conf.\n\nChange-Id: I8cbb728c7db41f50fb5eaf0662a2d7e99248b864\nPartial-Bug: #1380789\nblueprint: trove-migrate-oslo-concurrency\nblueprint: trove-retire-unused-modules\n'}, {'number': 4, 'created': '2014-10-17 12:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a444d55c5f41452610f391cbb3eba280f80f10eb', 'message': 'Obsolete oslo-incubator modules - lockutils\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis change handles lockutils which is not used in trove.\n\nThe change is merely to delete the file and update\nopenstack-common.conf.\n\nChange-Id: I8cbb728c7db41f50fb5eaf0662a2d7e99248b864\nPartial-Bug: #1380789\nblueprint: trove-retire-unused-modules\nblueprint: trove-migrate-oslo-concurrency\n'}, {'number': 5, 'created': '2014-10-17 14:27:46.000000000', 'files': ['trove/openstack/common/lockutils.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/trove/commit/05b93fb4c26b46f43b6033cac4d4e52c989192f6', 'message': 'Obsolete oslo-incubator modules - lockutils\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis change handles lockutils which is not used in trove.\n\nThe change is merely to delete the file and update\nopenstack-common.conf.\n\nChange-Id: I8cbb728c7db41f50fb5eaf0662a2d7e99248b864\nPartial-Bug: #1380789\nblueprint: trove-retire-unused-modules\nblueprint: trove-migrate-oslo-concurrency\n'}]",0,129207,05b93fb4c26b46f43b6033cac4d4e52c989192f6,22,4,5,9664,,,0,"Obsolete oslo-incubator modules - lockutils

This change is part of a multi-part change set to handle obsolete and
graduated oslo modules.

This change handles lockutils which is not used in trove.

The change is merely to delete the file and update
openstack-common.conf.

Change-Id: I8cbb728c7db41f50fb5eaf0662a2d7e99248b864
Partial-Bug: #1380789
blueprint: trove-retire-unused-modules
blueprint: trove-migrate-oslo-concurrency
",git fetch https://review.opendev.org/openstack/trove refs/changes/07/129207/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/openstack/common/lockutils.py', 'openstack-common.conf']",2,b171763affd64803cd6a8728b9d658b567a12254,bp/trove-retire-unused-modules,,module=lockutils,0,306
openstack%2Ftrove~master~If8d4a823ee60756d552a4561b96e400548e1aa05,openstack/trove,master,If8d4a823ee60756d552a4561b96e400548e1aa05,Obsolete oslo-incubator modules - exception,ABANDONED,2014-10-17 11:08:14.000000000,2014-10-17 17:04:14.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-10-17 11:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1bcabf0e846df0dcaa8db25b87610b90a9cd8ad9', 'message': 'Do not use obsolete oslo-incubator modules\n\nThis commit handles the exception module (used to be\ntrove/openstack/common/exception.py).\n\nThe change here is to remove it from openstack-common.conf and handle\nthe ripple effect in trove/common/exception.py\n\nChange-Id: If8d4a823ee60756d552a4561b96e400548e1aa05\nPartial-Bug: #1380789\n'}, {'number': 2, 'created': '2014-10-17 11:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/10f25ce12faca87eefae948185b2086cf9915024', 'message': 'Do not use obsolete oslo-incubator modules\n\nThis commit handles the exception module (used to be\ntrove/openstack/common/exception.py).\n\nThe change here is to remove it from openstack-common.conf and handle\nthe ripple effect in trove/common/exception.py\n\nBlueprint: trove-retire-unused-modules\nChange-Id: If8d4a823ee60756d552a4561b96e400548e1aa05\nPartial-Bug: #1380789\n'}, {'number': 3, 'created': '2014-10-17 11:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/659769bebf8ecc4f28805ad9975fcc821743cb10', 'message': 'Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles the exception module (used to be\ntrove/openstack/common/exception.py).\n\nThe change here is to remove it from openstack-common.conf and handle\nthe ripple effect in trove/common/exception.py\n\nBlueprint: trove-retire-unused-modules\nChange-Id: If8d4a823ee60756d552a4561b96e400548e1aa05\nPartial-Bug: #1380789\n'}, {'number': 4, 'created': '2014-10-17 14:27:27.000000000', 'files': ['trove/common/exception.py', 'openstack-common.conf', 'trove/openstack/common/exception.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/f6bb48f49ce85be77713d4399023495edf041dd4', 'message': 'Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles the exception module (used to be\ntrove/openstack/common/exception.py).\n\nThe change here is to remove it from openstack-common.conf and handle\nthe ripple effect in trove/common/exception.py\n\nBlueprint: trove-retire-unused-modules\nChange-Id: If8d4a823ee60756d552a4561b96e400548e1aa05\nPartial-Bug: #1380789\n'}]",0,129205,f6bb48f49ce85be77713d4399023495edf041dd4,18,4,4,9664,,,0,"Obsolete oslo-incubator modules - exception

This change is part of a multi-part change set to handle obsolete and
graduated oslo modules.

This commit handles the exception module (used to be
trove/openstack/common/exception.py).

The change here is to remove it from openstack-common.conf and handle
the ripple effect in trove/common/exception.py

Blueprint: trove-retire-unused-modules
Change-Id: If8d4a823ee60756d552a4561b96e400548e1aa05
Partial-Bug: #1380789
",git fetch https://review.opendev.org/openstack/trove refs/changes/05/129205/2 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/exception.py', 'openstack-common.conf', 'trove/openstack/common/exception.py']",3,1bcabf0e846df0dcaa8db25b87610b90a9cd8ad9,bp/trove-retire-unused-modules,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Exceptions common to OpenStack projects """""" import logging from trove.openstack.common.gettextutils import _ _FATAL_EXCEPTION_FORMAT_ERRORS = False class Error(Exception): def __init__(self, message=None): super(Error, self).__init__(message) class ApiError(Error): def __init__(self, message='Unknown', code='Unknown'): self.message = message self.code = code super(ApiError, self).__init__('%s: %s' % (code, message)) class NotFound(Error): pass class UnknownScheme(Error): msg = ""Unknown scheme '%s' found in URI"" def __init__(self, scheme): msg = self.__class__.msg % scheme super(UnknownScheme, self).__init__(msg) class BadStoreUri(Error): msg = ""The Store URI %s was malformed. Reason: %s"" def __init__(self, uri, reason): msg = self.__class__.msg % (uri, reason) super(BadStoreUri, self).__init__(msg) class Duplicate(Error): pass class NotAuthorized(Error): pass class NotEmpty(Error): pass class Invalid(Error): pass class BadInputError(Exception): """"""Error resulting from a client sending bad input to a server"""""" pass class MissingArgumentError(Error): pass class DatabaseMigrationError(Error): pass class ClientConnectionError(Exception): """"""Error resulting from a client connecting to a server"""""" pass def wrap_exception(f): def _wrap(*args, **kw): try: return f(*args, **kw) except Exception as e: if not isinstance(e, Error): #exc_type, exc_value, exc_traceback = sys.exc_info() logging.exception(_('Uncaught exception')) #logging.error(traceback.extract_stack(exc_traceback)) raise Error(str(e)) raise _wrap.func_name = f.func_name return _wrap class OpenstackException(Exception): """""" Base Exception To correctly use this class, inherit from it and define a 'message' property. That message will get printf'd with the keyword arguments provided to the constructor. """""" message = ""An unknown exception occurred"" def __init__(self, **kwargs): try: self._error_string = self.message % kwargs except Exception as e: if _FATAL_EXCEPTION_FORMAT_ERRORS: raise e else: # at least get the core message out if something happened self._error_string = self.message def __str__(self): return self._error_string class MalformedRequestBody(OpenstackException): message = ""Malformed message body: %(reason)s"" class InvalidContentType(OpenstackException): message = ""Invalid content type %(content_type)s"" ",34,148
openstack%2Ftrove~master~I4664c96a7733c4cfe45810f9db5e00f29d2f6a86,openstack/trove,master,I4664c96a7733c4cfe45810f9db5e00f29d2f6a86,Obsolete oslo-incubator modules - unused modules,ABANDONED,2014-10-17 11:08:14.000000000,2014-10-17 17:04:13.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-10-17 11:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/25342cc7a844460a7d92a0f3f713f98e9a576107', 'message': 'Do not use obsolete oslo-incubator modules\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nChange-Id: I4664c96a7733c4cfe45810f9db5e00f29d2f6a86\nPartial-Bug: #1380789\n'}, {'number': 2, 'created': '2014-10-17 11:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/53e9e88bc609d1fa44913b4987ecb2d6ab5931aa', 'message': 'Do not use obsolete oslo-incubator modules\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nBlueprint: trove-retire-unused-modules\nChange-Id: I4664c96a7733c4cfe45810f9db5e00f29d2f6a86\nPartial-Bug: #1380789\n'}, {'number': 3, 'created': '2014-10-17 11:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e4ef3af6d9561ea5391866d12ee4af148e944e2b', 'message': 'Obsolete oslo-incubator modules - unused modules\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nBlueprint: trove-retire-unused-modules\nChange-Id: I4664c96a7733c4cfe45810f9db5e00f29d2f6a86\nPartial-Bug: #1380789\n'}, {'number': 4, 'created': '2014-10-17 14:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7196d9fd77a5cd23e29e5e380b7dcf3713a60804', 'message': 'Obsolete oslo-incubator modules - unused modules\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nBlueprint: trove-retire-unused-modules\nChange-Id: I4664c96a7733c4cfe45810f9db5e00f29d2f6a86\nPartial-Bug: #1380789\n'}, {'number': 5, 'created': '2014-10-17 14:18:02.000000000', 'files': ['trove/openstack/common/testutils.py', 'trove/openstack/common/iniparser.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/trove/commit/ba605b20dce945877c1d59a46f2d6fc1ebdec264', 'message': 'Obsolete oslo-incubator modules - unused modules\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nBlueprint: trove-retire-unused-modules\nChange-Id: I4664c96a7733c4cfe45810f9db5e00f29d2f6a86\nPartial-Bug: #1380789\n'}]",0,129204,ba605b20dce945877c1d59a46f2d6fc1ebdec264,23,4,5,9664,,,0,"Obsolete oslo-incubator modules - unused modules

This change is part of a multi-part change set to handle obsolete and
graduated oslo modules.

This commit handles obsolete oslo-incubator modules that are not used
in Trove but are referenced in openstack-common.conf

The change here is to remove them from openstack-common.conf and
delete them from trove/openstack/common.

Blueprint: trove-retire-unused-modules
Change-Id: I4664c96a7733c4cfe45810f9db5e00f29d2f6a86
Partial-Bug: #1380789
",git fetch https://review.opendev.org/openstack/trove refs/changes/04/129204/2 && git format-patch -1 --stdout FETCH_HEAD,"['trove/openstack/common/testutils.py', 'trove/openstack/common/iniparser.py', 'trove/openstack/common/utils.py', 'openstack-common.conf']",4,25342cc7a844460a7d92a0f3f713f98e9a576107,bp/trove-retire-unused-modules,,module=iniparsermodule=testutilsmodule=utils,0,260
openstack%2Fmagnetodb~master~I52c05b8636842a0076e2cfa03de68155d2594355,openstack/magnetodb,master,I52c05b8636842a0076e2cfa03de68155d2594355,Use consistency level QUORUM for table operations,MERGED,2014-10-17 15:33:49.000000000,2014-10-17 17:01:45.000000000,2014-10-17 17:01:45.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8601}, {'_account_id': 8863}, {'_account_id': 11006}]","[{'number': 1, 'created': '2014-10-17 15:33:49.000000000', 'files': ['magnetodb/storage/driver/cassandra/cassandra_impl.py'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/3bcf0fcbfaa2a2cb964c7b43196b4a53fe8da7dd', 'message': 'Use consistency level QUORUM for table operations\n\nChange-Id: I52c05b8636842a0076e2cfa03de68155d2594355\nFixes-bug: 1382593\n'}]",0,129300,3bcf0fcbfaa2a2cb964c7b43196b4a53fe8da7dd,8,5,1,8491,,,0,"Use consistency level QUORUM for table operations

Change-Id: I52c05b8636842a0076e2cfa03de68155d2594355
Fixes-bug: 1382593
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/00/129300/1 && git format-patch -1 --stdout FETCH_HEAD,['magnetodb/storage/driver/cassandra/cassandra_impl.py'],1,3bcf0fcbfaa2a2cb964c7b43196b4a53fe8da7dd,bug/1382593," self.__cluster_handler.execute_query( """".join(query_builder), consistent=True) self.__cluster_handler.execute_query( query, consistent=True)"," self.__cluster_handler.execute_query("""".join(query_builder)) self.__cluster_handler.execute_query(query)",6,2
openstack%2Fcinder~master~Icc4cf601bffddb057f35537f3870c45dd5eb67cc,openstack/cinder,master,Icc4cf601bffddb057f35537f3870c45dd5eb67cc,Move SolidFire driver from httplib to requests,MERGED,2014-10-10 01:25:25.000000000,2014-10-17 16:58:20.000000000,2014-10-14 20:19:29.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1297}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5538}, {'_account_id': 6491}, {'_account_id': 7156}, {'_account_id': 9008}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 12779}, {'_account_id': 12780}]","[{'number': 1, 'created': '2014-10-10 01:25:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4d6718dfdfc54b78ec4d9aa9708d123cfb6b5b41', 'message': ""Move SolidFire driver from httplib to requests\n\nThe SolidFire driver has been pretty static for a number of\nyears now, this change is to move from httplib for API calls\nto requests.  There are a number of advantages to this, including\nperformance, simplicity and ability to add things like ssl support\neasily.\n\nIn addtion this change removes the confusing looping/retry mechanisms\nthat were in the issue_api_request method and replaces it with a\nretry decorator for the exceptions we're interested in retrying.\n\nFinally, I realize that my unit tests suck!  That will be one of the\nfollow up items after a bit more clean up in the driver.\n\nChange-Id: Icc4cf601bffddb057f35537f3870c45dd5eb67cc\n""}, {'number': 2, 'created': '2014-10-10 03:42:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3263915e85cdb4780b852472bb784cb43b64fc00', 'message': ""Move SolidFire driver from httplib to requests\n\nThe SolidFire driver has been pretty static for a number of\nyears now, this change is to move from httplib for API calls\nto requests.  There are a number of advantages to this, including\nperformance, simplicity and ability to add things like ssl support\neasily.\n\nIn addtion this change removes the confusing looping/retry mechanisms\nthat were in the issue_api_request method and replaces it with a\nretry decorator for the exceptions we're interested in retrying.\n\nFinally, I realize that my unit tests suck!  That will be one of the\nfollow up items after a bit more clean up in the driver.\n\nChange-Id: Icc4cf601bffddb057f35537f3870c45dd5eb67cc\n""}, {'number': 3, 'created': '2014-10-10 05:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0f4e46c6c0bee9b3b49e6f53a52b4a47973ad486', 'message': ""Move SolidFire driver from httplib to requests\n\nThe SolidFire driver has been pretty static for a number of\nyears now, this change is to move from httplib for API calls\nto requests.  There are a number of advantages to this, including\nperformance, simplicity and ability to add things like ssl support\neasily.\n\nIn addtion this change removes the confusing looping/retry mechanisms\nthat were in the issue_api_request method and replaces it with a\nretry decorator for the exceptions we're interested in retrying.\n\nFinally, I realize that my unit tests suck!  That will be one of the\nfollow up items after a bit more clean up in the driver.\n\nChange-Id: Icc4cf601bffddb057f35537f3870c45dd5eb67cc\n""}, {'number': 4, 'created': '2014-10-10 16:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/779178fe92216a17c172cba1be4d0c684cb222a8', 'message': ""Move SolidFire driver from httplib to requests\n\nThe SolidFire driver has been pretty static for a number of\nyears now, this change is to move from httplib for API calls\nto requests.  There are a number of advantages to this, including\nperformance, simplicity and ability to add things like ssl support\neasily.\n\nIn addtion this change removes the confusing looping/retry mechanisms\nthat were in the issue_api_request method and replaces it with a\nretry decorator for the exceptions we're interested in retrying.\n\nFinally, I realize that my unit tests suck!  That will be one of the\nfollow up items after a bit more clean up in the driver.\n\nChange-Id: Icc4cf601bffddb057f35537f3870c45dd5eb67cc\n""}, {'number': 5, 'created': '2014-10-12 17:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f94aecad4da35b80863a5ce1412865d5a78e3ea', 'message': ""Move SolidFire driver from httplib to requests\n\nThe SolidFire driver has been pretty static for a number of\nyears now, this change is to move from httplib for API calls\nto requests.  There are a number of advantages to this, including\nperformance, simplicity and ability to add things like ssl support\neasily.\n\nIn addtion this change removes the confusing looping/retry mechanisms\nthat were in the issue_api_request method and replaces it with a\nretry decorator for the exceptions we're interested in retrying.\n\nFinally, I realize that my unit tests suck!  That will be one of the\nfollow up items after a bit more clean up in the driver.\n\nChange-Id: Icc4cf601bffddb057f35537f3870c45dd5eb67cc\n""}, {'number': 6, 'created': '2014-10-13 17:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8a9383d4200100447f18ac36dd48dd8fef6e3afc', 'message': ""Move SolidFire driver from httplib to requests\n\nThe SolidFire driver has been pretty static for a number of\nyears now, this change is to move from httplib for API calls\nto requests.  There are a number of advantages to this, including\nperformance, simplicity and ability to add things like ssl support\neasily.\n\nIn addtion this change removes the confusing looping/retry mechanisms\nthat were in the issue_api_request method and replaces it with a\nretry decorator for the exceptions we're interested in retrying.\n\nFinally, I realize that my unit tests suck!  That will be one of the\nfollow up items after a bit more clean up in the driver.\n\nChange-Id: Icc4cf601bffddb057f35537f3870c45dd5eb67cc\n""}, {'number': 7, 'created': '2014-10-13 19:11:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/448d6c24397b825b1ba57a6ac89762fe88e88f4a', 'message': ""Move SolidFire driver from httplib to requests\n\nThe SolidFire driver has been pretty static for a number of\nyears now, this change is to move from httplib for API calls\nto requests.  There are a number of advantages to this, including\nperformance, simplicity and ability to add things like ssl support\neasily.\n\nIn addtion this change removes the confusing looping/retry mechanisms\nthat were in the issue_api_request method and replaces it with a\nretry decorator for the exceptions we're interested in retrying.\n\nFinally, I realize that my unit tests suck!  That will be one of the\nfollow up items after a bit more clean up in the driver.\n\nChange-Id: Icc4cf601bffddb057f35537f3870c45dd5eb67cc\n""}, {'number': 8, 'created': '2014-10-14 03:55:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b47b4fe9d494cd4fcf8c80ceefb5316571e79f33', 'message': ""Move SolidFire driver from httplib to requests\n\nThe SolidFire driver has been pretty static for a number of\nyears now, this change is to move from httplib for API calls\nto requests.  There are a number of advantages to this, including\nperformance, simplicity and ability to add things like ssl support\neasily.\n\nIn addtion this change removes the confusing looping/retry mechanisms\nthat were in the issue_api_request method and replaces it with a\nretry decorator for the exceptions we're interested in retrying.\n\nFinally, I realize that my unit tests suck!  That will be one of the\nfollow up items after a bit more clean up in the driver.\n\nChange-Id: Icc4cf601bffddb057f35537f3870c45dd5eb67cc\n""}, {'number': 9, 'created': '2014-10-14 11:37:23.000000000', 'files': ['cinder/volume/drivers/solidfire.py', 'cinder/exception.py', 'cinder/tests/test_solidfire.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fc9242f1e253fde7c2f15f8a5f61c06d4211f111', 'message': ""Move SolidFire driver from httplib to requests\n\nThe SolidFire driver has been pretty static for a number of\nyears now, this change is to move from httplib for API calls\nto requests.  There are a number of advantages to this, including\nperformance, simplicity and ability to add things like ssl support\neasily.\n\nIn addtion this change removes the confusing looping/retry mechanisms\nthat were in the issue_api_request method and replaces it with a\nretry decorator for the exceptions we're interested in retrying.\n\nFinally, I realize that my unit tests suck!  That will be one of the\nfollow up items after a bit more clean up in the driver.\n\nChange-Id: Icc4cf601bffddb057f35537f3870c45dd5eb67cc\n""}]",22,127399,fc9242f1e253fde7c2f15f8a5f61c06d4211f111,78,17,9,2243,,,0,"Move SolidFire driver from httplib to requests

The SolidFire driver has been pretty static for a number of
years now, this change is to move from httplib for API calls
to requests.  There are a number of advantages to this, including
performance, simplicity and ability to add things like ssl support
easily.

In addtion this change removes the confusing looping/retry mechanisms
that were in the issue_api_request method and replaces it with a
retry decorator for the exceptions we're interested in retrying.

Finally, I realize that my unit tests suck!  That will be one of the
follow up items after a bit more clean up in the driver.

Change-Id: Icc4cf601bffddb057f35537f3870c45dd5eb67cc
",git fetch https://review.opendev.org/openstack/cinder refs/changes/99/127399/9 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/solidfire.py', 'cinder/exception.py', 'cinder/tests/test_solidfire.py']",3,4d6718dfdfc54b78ec4d9aa9708d123cfb6b5b41,move_solidfire_driver_from_httplib_to_requests," self.stubs.Set(SolidFireDriver, '_build_endpoint_info', self.fake_build_endpoint_info) def fake_build_endpoint_info(obj, **kwargs): endpoint = {} endpoint['mvip'] = '1.1.1.1' endpoint['login'] = 'admin' endpoint['passwd'] = 'admin' endpoint['port'] = '443' endpoint['url'] = '{scheme}://{mvip}'.format(mvip='%s:%s' % (endpoint['mvip'], endpoint['port']), scheme='https') return endpoint ",,99,102
openstack%2Fironic~master~Ibcc77384f4d220759caa3cf63088c559fa4a4f69,openstack/ironic,master,Ibcc77384f4d220759caa3cf63088c559fa4a4f69,TestAgentVendor to use the fake_agent driver,MERGED,2014-10-17 13:41:34.000000000,2014-10-17 16:57:45.000000000,2014-10-17 16:57:44.000000000,"[{'_account_id': 3}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 12081}, {'_account_id': 12356}]","[{'number': 1, 'created': '2014-10-17 13:41:34.000000000', 'files': ['ironic/tests/drivers/test_agent.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/504ca9f04f886e1247a7f9e03a420b6bab22fb51', 'message': 'TestAgentVendor to use the fake_agent driver\n\nTestAgentVendor tor use the fake_agent driver and not the fake_pxe one.\n\nChange-Id: Ibcc77384f4d220759caa3cf63088c559fa4a4f69\n'}]",0,129251,504ca9f04f886e1247a7f9e03a420b6bab22fb51,11,5,1,6773,,,0,"TestAgentVendor to use the fake_agent driver

TestAgentVendor tor use the fake_agent driver and not the fake_pxe one.

Change-Id: Ibcc77384f4d220759caa3cf63088c559fa4a4f69
",git fetch https://review.opendev.org/openstack/ironic refs/changes/51/129251/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/tests/drivers/test_agent.py'],1,504ca9f04f886e1247a7f9e03a420b6bab22fb51,agent-vendor-pxe," mgr_utils.mock_the_extension_manager(driver=""fake_agent"") 'driver': 'fake_agent',"," mgr_utils.mock_the_extension_manager(driver=""fake_pxe"") 'driver': 'fake_pxe',",2,2
openstack%2Fnova~master~Ib05472445a2c736f7e2305622c91ba80b71fb6f5,openstack/nova,master,Ib05472445a2c736f7e2305622c91ba80b71fb6f5,Allow strategic loading of InstanceExtra columns,MERGED,2014-10-01 19:59:08.000000000,2014-10-17 16:55:46.000000000,2014-10-17 16:42:05.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-01 19:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0140b831a620f6ba3c43468a05387e5ae92d0b99', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 2, 'created': '2014-10-06 17:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3ef5f4be2792ad157501f78c607346357b7697c', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 3, 'created': '2014-10-07 14:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71b9fe1cc4b66ca7ba1bed3ff9eb71de00104f02', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 4, 'created': '2014-10-08 14:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0c5652d2350e6fbef89b713e85a62757764637e', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 5, 'created': '2014-10-08 18:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3b674ed549f8cf6713f0e20f376a0462fae61837', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 6, 'created': '2014-10-14 14:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8f8169aa78ddf08d48598a80abb5f6a4aca5e03', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 7, 'created': '2014-10-14 17:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c6d59e62cbdb553b81d441f01fca4727b07d6406', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 8, 'created': '2014-10-14 18:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/026a4540fae5e6b916a9aeb7e601fb9f057e6014', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 9, 'created': '2014-10-14 19:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/03b4825d49f040c061100a418fdce4d8972e6812', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 10, 'created': '2014-10-15 15:42:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f743564b5fa640a18685be2e9d1cd40836b9d51', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 11, 'created': '2014-10-15 18:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d8ba3e4a1e9e45453b2888adb249f9b7104f3dc8', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 12, 'created': '2014-10-15 19:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1148ac068f50cb413ebcda34ef4274e0b666a7ac', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 13, 'created': '2014-10-16 16:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9ff8e140cdb5248718706427152b4e739e6ea912', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 14, 'created': '2014-10-16 16:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7806bc6589446b8026072edfc3a950ee8086d03f', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}, {'number': 15, 'created': '2014-10-17 14:15:30.000000000', 'files': ['nova/tests/objects/test_instance.py', 'nova/db/sqlalchemy/models.py', 'nova/objects/instance_numa_topology.py', 'nova/tests/objects/test_instance_pci_requests.py', 'nova/objects/instance_pci_requests.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/tests/db/test_db_api.py', 'nova/db/api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8cf9dfe3fd759304beccc92b82310d61040925ec', 'message': 'Allow strategic loading of InstanceExtra columns\n\nThis makes it possible to pull out just one of the several Text\ncolumns with JSON blobs in instance_extra. Before this, we always\npull all the columns even though we only ever want one at a time.\nThis involves marking the big columns in InstanceExtra as deferred(),\nand specifying which ones we want each time. This is hidden in the\nAPI for querying, but should be noted in any joins.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5\n'}]",8,125481,8cf9dfe3fd759304beccc92b82310d61040925ec,88,13,15,4393,,,0,"Allow strategic loading of InstanceExtra columns

This makes it possible to pull out just one of the several Text
columns with JSON blobs in instance_extra. Before this, we always
pull all the columns even though we only ever want one at a time.
This involves marking the big columns in InstanceExtra as deferred(),
and specifying which ones we want each time. This is hidden in the
API for querying, but should be noted in any joins.

Related to blueprint flavor-from-sysmeta-to-blob

Change-Id: Ib05472445a2c736f7e2305622c91ba80b71fb6f5
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/125481/14 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/objects/test_instance.py', 'nova/objects/instance_numa_topology.py', 'nova/tests/objects/test_instance_pci_requests.py', 'nova/objects/instance_pci_requests.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/tests/db/test_db_api.py', 'nova/db/api.py', 'nova/db/sqlalchemy/api.py']",8,0140b831a620f6ba3c43468a05387e5ae92d0b99,bp/flavor-from-sysmeta-to-blob,"from sqlalchemy.orm import deferdef instance_extra_get_by_instance_uuid(context, instance_uuid, columns=None): if columns: big_columns = set(['numa_topology', 'pci_requests']) wanted_columns = set(columns) for unwanted in big_columns - wanted_columns: query = query.options(defer(unwanted))","def instance_extra_get_by_instance_uuid(context, instance_uuid):",24,8
openstack%2Ftempest~master~Id95d011f3d080effc7bfee6232578451f7ba72d9,openstack/tempest,master,Id95d011f3d080effc7bfee6232578451f7ba72d9,Remove OfficialClient dependency from HACKING.rst,MERGED,2014-10-06 05:01:31.000000000,2014-10-17 16:51:56.000000000,2014-10-17 16:51:55.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8623}, {'_account_id': 10016}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-06 05:01:31.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/tempest/commit/93424e50214f5e8b96580f4faf47c50c1853ffb5', 'message': ""Remove OfficialClient dependency from HACKING.rst\n\nThis commit migrates OfficialClientTest to ScenarioTest about\nTestVolumeBootPattern in HACKING.rst. We should not have such an example\nin the HACKING.rst because we don't use OfficialClientTest class in the\nscenario tests anymore.\n\nPartially-implements: bp:tempest-client-scenarios\n\nChange-Id: Id95d011f3d080effc7bfee6232578451f7ba72d9\n""}]",0,126214,93424e50214f5e8b96580f4faf47c50c1853ffb5,14,8,1,5689,,,0,"Remove OfficialClient dependency from HACKING.rst

This commit migrates OfficialClientTest to ScenarioTest about
TestVolumeBootPattern in HACKING.rst. We should not have such an example
in the HACKING.rst because we don't use OfficialClientTest class in the
scenario tests anymore.

Partially-implements: bp:tempest-client-scenarios

Change-Id: Id95d011f3d080effc7bfee6232578451f7ba72d9
",git fetch https://review.opendev.org/openstack/tempest refs/changes/14/126214/1 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,93424e50214f5e8b96580f4faf47c50c1853ffb5,bp/tempest-client-scenarios, class TestVolumeBootPattern(manager.ScenarioTest):, class TestVolumeBootPattern(manager.OfficialClientTest):,1,1
openstack%2Fpython-monascaclient~master~I6a454ff75fa4670489b19636961ec6f8f141d9d6,openstack/python-monascaclient,master,I6a454ff75fa4670489b19636961ec6f8f141d9d6,alarm formatting changes,MERGED,2014-10-16 21:22:40.000000000,2014-10-17 16:46:03.000000000,2014-10-17 16:46:03.000000000,"[{'_account_id': 3}, {'_account_id': 11809}, {'_account_id': 12133}]","[{'number': 1, 'created': '2014-10-16 21:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/424b5dfc65662f8aeb9a7f714c32412b817ac37e', 'message': 'alarm-list, alarm-definition, alarm-history, alarm-history-list formatting changes\n\nChange-Id: I6a454ff75fa4670489b19636961ec6f8f141d9d6\n'}, {'number': 2, 'created': '2014-10-16 21:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/c368e23c61ce694e806fc79d58f6a58bb8d340f6', 'message': 'alarm formatting changes\n\nChange-Id: I6a454ff75fa4670489b19636961ec6f8f141d9d6\n'}, {'number': 3, 'created': '2014-10-17 16:39:01.000000000', 'files': ['README.rst', 'monascaclient/v2_0/shell.py', 'ChangeLog', 'monascaclient/common/utils.py'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/aa1c054dc5d50a310d9344008f98124bbf32f70b', 'message': 'alarm formatting changes\n\nChange-Id: I6a454ff75fa4670489b19636961ec6f8f141d9d6\n'}]",6,129057,aa1c054dc5d50a310d9344008f98124bbf32f70b,14,3,3,12133,,,0,"alarm formatting changes

Change-Id: I6a454ff75fa4670489b19636961ec6f8f141d9d6
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/57/129057/1 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'monascaclient/v2_0/shell.py', 'ChangeLog', 'monascaclient/common/utils.py']",4,424b5dfc65662f8aeb9a7f714c32412b817ac37e,alarm-metric-format," def format_list(in_list): string_list = list() for k in in_list: if isinstance(k, unicode): key = k.encode('utf-8') else: key = k string_list.append(key) return '\n'.join(string_list)",,136,31
openstack%2Fproject-config~master~I6850ce17d4c8ad8c8bc59cbb5c85c96dde34ca60,openstack/project-config,master,I6850ce17d4c8ad8c8bc59cbb5c85c96dde34ca60,Fix groups-release-branch manifest issue,MERGED,2014-10-17 14:00:39.000000000,2014-10-17 16:22:38.000000000,2014-10-17 16:22:38.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-17 14:00:39.000000000', 'files': ['jenkins/jobs/groups.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/846a5dda55151e48534cb4623396ed86fefb7610', 'message': 'Fix groups-release-branch manifest issue\n\nA wrong parameter prevented the manifest file generation during\nbranch release job, so the distro tarball generation also failed.\nSo this patch replace the --manifesturl with the proper\n--manifest-url parameter.\n\nChange-Id: I6850ce17d4c8ad8c8bc59cbb5c85c96dde34ca60\n'}]",0,129263,846a5dda55151e48534cb4623396ed86fefb7610,8,3,1,6633,,,0,"Fix groups-release-branch manifest issue

A wrong parameter prevented the manifest file generation during
branch release job, so the distro tarball generation also failed.
So this patch replace the --manifesturl with the proper
--manifest-url parameter.

Change-Id: I6850ce17d4c8ad8c8bc59cbb5c85c96dde34ca60
",git fetch https://review.opendev.org/openstack/project-config refs/changes/63/129263/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/groups.yaml'],1,846a5dda55151e48534cb4623396ed86fefb7610,groups-release-fix, scripts/release-manifest.php --version=$VERSION --releasetar=groups-$PROJECT_VER.tar.gz --md5=$MD5HASH --outfile=$OUTFILE --manifest-url=$MANIFESTURL --verbose --debug, scripts/release-manifest.php --version=$VERSION --releasetar=groups-$PROJECT_VER.tar.gz --md5=$MD5HASH --outfile=$OUTFILE --manifesturl=$MANIFESTURL --verbose --debug,1,1
openstack%2Fdevstack~master~I4c2538f0fd3fb05bfdb69e7e4c3a8462af42ba10,openstack/devstack,master,I4c2538f0fd3fb05bfdb69e7e4c3a8462af42ba10,ofagent: Support physical_interface_mappings,MERGED,2014-09-12 18:01:50.000000000,2014-10-17 16:09:46.000000000,2014-10-17 16:09:46.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 6854}, {'_account_id': 7715}, {'_account_id': 9008}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-12 18:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6100a062aff0f617dfdab7e00372480939642cbb', 'message': 'ofagent: Support physical_interface_mappings\n\nAlso, add a knob to create a veth pair instead of a bridge\nto provide host connectivity for l3-agent.  (Q_USE_PUBLIC_VETH)\n\nRelated: blueprint ofagent-physical-interface-mappings\nChange-Id: I4c2538f0fd3fb05bfdb69e7e4c3a8462af42ba10\n'}, {'number': 2, 'created': '2014-09-12 18:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e3480ea0303338890e0417e6cce55a10be166db8', 'message': 'ofagent: Support physical_interface_mappings\n\nAlso, add a knob to create a veth pair instead of a bridge\nto provide host connectivity for l3-agent.  (Q_USE_PUBLIC_VETH)\n\nRelated: blueprint ofagent-physical-interface-mappings\nChange-Id: I4c2538f0fd3fb05bfdb69e7e4c3a8462af42ba10\n'}, {'number': 3, 'created': '2014-09-13 01:34:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/01e3d44bdd6f94a85bd0c714fb23218e605de723', 'message': 'ofagent: Support physical_interface_mappings\n\nAlso, add a knob to create a veth pair instead of a bridge\nto provide host connectivity for l3-agent.  (Q_USE_PUBLIC_VETH)\n\nRelated: blueprint ofagent-physical-interface-mappings\nChange-Id: I4c2538f0fd3fb05bfdb69e7e4c3a8462af42ba10\n'}, {'number': 4, 'created': '2014-09-13 04:08:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/66f5268c4b65cfdd7b26ebf376ef9d8601e72754', 'message': 'ofagent: Support physical_interface_mappings\n\nAlso, add a knob to create a veth pair instead of a bridge\nto provide host connectivity for l3-agent.  (Q_USE_PUBLIC_VETH)\n\nRelated: blueprint ofagent-physical-interface-mappings\nChange-Id: I4c2538f0fd3fb05bfdb69e7e4c3a8462af42ba10\n'}, {'number': 5, 'created': '2014-09-13 15:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e7e78f664859c25423916a7cbddd333554f6ceb6', 'message': 'ofagent: Support physical_interface_mappings\n\nAlso, add a knob to create a veth pair instead of a bridge\nto provide host connectivity for l3-agent.  (Q_USE_PUBLIC_VETH)\n\nRelated: blueprint ofagent-physical-interface-mappings\nChange-Id: I4c2538f0fd3fb05bfdb69e7e4c3a8462af42ba10\n'}, {'number': 6, 'created': '2014-09-30 00:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3ec53fb8a2b405c24f27ba5add28cf8497e965d6', 'message': 'ofagent: Support physical_interface_mappings\n\nAlso, add a knob to create a veth pair instead of a bridge\nto provide host connectivity for l3-agent.  (Q_USE_PUBLIC_VETH)\n\nRelated: blueprint ofagent-physical-interface-mappings\nChange-Id: I4c2538f0fd3fb05bfdb69e7e4c3a8462af42ba10\n'}, {'number': 7, 'created': '2014-10-17 01:18:40.000000000', 'files': ['lib/neutron_plugins/ofagent_agent', 'lib/neutron', 'lib/neutron_plugins/ovs_base'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0f18c23de880a38c15aa4bb5d3a8f114f48dfe20', 'message': 'ofagent: Support physical_interface_mappings\n\nAlso, add a knob to create a veth pair instead of a bridge\nto provide host connectivity for l3-agent.  (Q_USE_PUBLIC_VETH)\n\nRelated: blueprint ofagent-physical-interface-mappings\nChange-Id: I4c2538f0fd3fb05bfdb69e7e4c3a8462af42ba10\n'}]",3,121189,0f18c23de880a38c15aa4bb5d3a8f114f48dfe20,37,9,7,6854,,,0,"ofagent: Support physical_interface_mappings

Also, add a knob to create a veth pair instead of a bridge
to provide host connectivity for l3-agent.  (Q_USE_PUBLIC_VETH)

Related: blueprint ofagent-physical-interface-mappings
Change-Id: I4c2538f0fd3fb05bfdb69e7e4c3a8462af42ba10
",git fetch https://review.opendev.org/openstack/devstack refs/changes/89/121189/5 && git format-patch -1 --stdout FETCH_HEAD,"['lib/neutron_plugins/ofagent_agent', 'lib/neutron']",2,6100a062aff0f617dfdab7e00372480939642cbb,bp/ofagent-physical-interface-mappings,"# used for the network. In case of ofagent, you should add the # corresponding entry to your OFAGENT_PHYSICAL_INTERFACE_MAPPINGS. # For openvswitch agent, you should add the corresponding entry to # your OVS_BRIDGE_MAPPINGS.# eg. (ofagent) # Q_USE_PROVIDERNET_FOR_PUBLIC=True # Q_USE_PUBLIC_VETH=True # PUBLIC_PHYSICAL_NETWORK=public # OFAGENT_PHYSICAL_INTERFACE_MAPPINGS=public:veth-pub-int # # eg. (openvswitch agent)# If Q_USE_PUBLIC_VETH=True, create and use a veth pair instead of # PUBLIC_BRIDGE. This is intended to be used with # Q_USE_PROVIDERNET_FOR_PUBLIC=True. Q_USE_PUBLIC_VETH=${Q_USE_PUBLIC_VETH:-False} Q_PUBLIC_VETH_EX=${Q_USE_PUBLIC_VETH_EX:-veth-pub-ex} Q_PUBLIC_VETH_INT=${Q_USE_PUBLIC_VETH_INT:-veth-pub-int} local ext_gw_interface if [[ ""$Q_USE_PUBLIC_VETH"" = ""True"" ]]; then sudo ip link add $Q_PUBLIC_VETH_INT type veth \ peer name $Q_PUBLIC_VETH_EX sudo ip link set $Q_PUBLIC_VETH_INT up ext_gw_interface=$Q_PUBLIC_VETH_EX else # Disable in-band as we are going to use local port # to communicate with VMs sudo ovs-vsctl set Bridge $PUBLIC_BRIDGE \ other_config:disable-in-band=true ext_gw_interface=$PUBLIC_BRIDGE fi sudo ip addr add $EXT_GW_IP/$CIDR_LEN dev $ext_gw_interface sudo ip link set $ext_gw_interface up","# used for the network. In case of openvswitch agent, you should # add the corresponding entry to your OVS_BRIDGE_MAPPINGS.# eg. # Disable in-band as we are going to use local port # to communicate with VMs sudo ovs-vsctl set Bridge $PUBLIC_BRIDGE other_config:disable-in-band=true sudo ip addr add $EXT_GW_IP/$CIDR_LEN dev $PUBLIC_BRIDGE sudo ip link set $PUBLIC_BRIDGE up",38,8
openstack%2Fdevstack~master~I124b5e7e8ef7feb6c90de907916a9530409c4ad4,openstack/devstack,master,I124b5e7e8ef7feb6c90de907916a9530409c4ad4,Update the OpenDaylight support to the Helium release,MERGED,2014-10-16 14:22:35.000000000,2014-10-17 16:09:20.000000000,2014-10-17 16:09:19.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1653}, {'_account_id': 7118}, {'_account_id': 7715}, {'_account_id': 9009}, {'_account_id': 10385}, {'_account_id': 10386}, {'_account_id': 11240}]","[{'number': 1, 'created': '2014-10-16 14:22:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d1414ac53b7cd1dbf4c2dca20ba50d7ffdcb65fa', 'message': 'Update the OpenDaylight support to the Helium release\n\nThe OpenDaylight project recently released their latest release, codenamed\nHelium. This commit updates the devstack support for OpenDaylight to this\nnew version, which includes changes to configuration files as well as the\nstartup of OpenDaylight itself.\n\nChange-Id: I124b5e7e8ef7feb6c90de907916a9530409c4ad4\n'}, {'number': 2, 'created': '2014-10-16 17:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/00f3c0d8a9238661915ddbcd2fd9c754102ed59e', 'message': 'Update the OpenDaylight support to the Helium release\n\nThe OpenDaylight project recently released their latest release, codenamed\nHelium. This commit updates the devstack support for OpenDaylight to this\nnew version, which includes changes to configuration files as well as the\nstartup of OpenDaylight itself.\n\nChange-Id: I124b5e7e8ef7feb6c90de907916a9530409c4ad4\n'}, {'number': 3, 'created': '2014-10-17 01:40:09.000000000', 'files': ['lib/opendaylight', 'MAINTAINERS.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3d6d89935f13635d3fe982ccf870c017155ea903', 'message': 'Update the OpenDaylight support to the Helium release\n\nThe OpenDaylight project recently released their latest release, codenamed\nHelium. This commit updates the devstack support for OpenDaylight to this\nnew version, which includes changes to configuration files as well as the\nstartup of OpenDaylight itself.\n\nAlso update my email address in MAINTAINERS.rst.\n\nChange-Id: I124b5e7e8ef7feb6c90de907916a9530409c4ad4\n'}]",4,128937,3d6d89935f13635d3fe982ccf870c017155ea903,25,9,3,105,,,0,"Update the OpenDaylight support to the Helium release

The OpenDaylight project recently released their latest release, codenamed
Helium. This commit updates the devstack support for OpenDaylight to this
new version, which includes changes to configuration files as well as the
startup of OpenDaylight itself.

Also update my email address in MAINTAINERS.rst.

Change-Id: I124b5e7e8ef7feb6c90de907916a9530409c4ad4
",git fetch https://review.opendev.org/openstack/devstack refs/changes/37/128937/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/opendaylight'],1,d1414ac53b7cd1dbf4c2dca20ba50d7ffdcb65fa,bug/1382062,"ODL_PKG=${ODL_PKG:-distribution-karaf-0.2.0-Helium.zip}ODL_URL=${ODL_URL:-https://nexus.opendaylight.org/content/groups/public/org/opendaylight/integration/distribution-karaf/0.2.0-Helium} # Add odl-ovsdb-openstack if it's not already there local ODLOVSDB=$(cat $ODL_DIR/distribution-karaf-0.2.0-Helium/etc/org.apache.karaf.features.cfg | grep featuresBoot= | grep odl) if [ ""$ODLOVSDB"" == """" ]; then sed -i '/^featuresBoot=/ s/$/,odl-ovsdb-openstack/' $ODL_DIR/distribution-karaf-0.2.0-Helium/etc/org.apache.karaf.features.cfg fi # Configure OpenFlow 1.3 if it's not there local OFLOW13=$(cat $ODL_DIR/distribution-karaf-0.2.0-Helium/etc/custom.properties | grep of.version) if [ ""$OFLOW13"" == """" ]; then echo ""ovsdb.of.version=1.3"" >> $ODL_DIR/distribution-karaf-0.2.0-Helium/etc/custom.properties fi # Configure L3 FWD if it's not there local L3FWD=$(cat $ODL_DIR/distribution-karaf-0.2.0-Helium/etc/system.properties | grep ovsdb.l3.fwd.enabled) if [ ""$L3FWD"" == """" ]; then echo ""ovsdb.l3.fwd.enabled=yes"" >> $ODL_DIR/distribution-karaf-0.2.0-Helium/etc/system.properties fi run_process odl-server ""cd $ODL_DIR/distribution-karaf-0.2.0-Helium && JAVA_HOME=$JHOME bin/karaf""","ODL_PKG=${ODL_PKG:-distributions-virtualization-0.1.1-osgipackage.zip}ODL_URL=${ODL_URL:-https://nexus.opendaylight.org/content/repositories/opendaylight.release/org/opendaylight/integration/distributions-virtualization/0.1.1} # Remove simple forwarder rm -f $ODL_DIR/opendaylight/plugins/org.opendaylight.controller.samples.simpleforwarding* # Configure OpenFlow 1.3 echo ""ovsdb.of.version=1.3"" >> $ODL_DIR/opendaylight/configuration/config.ini # NOTE(chdent): Leaving this as screen_it instead of run_process until # the right thing for this service is determined. screen_it odl-server ""cd $ODL_DIR/opendaylight && JAVA_HOME=$JHOME ./run.sh $ODL_ARGS -of13 -virt ovsdb""",19,9
openstack%2Fcinder~master~If492810a2f10fa5954f8c8bb708b14be0b77fb90,openstack/cinder,master,If492810a2f10fa5954f8c8bb708b14be0b77fb90,Add client_socket_timeout option,MERGED,2014-09-05 12:57:42.000000000,2014-10-17 16:05:48.000000000,2014-10-17 16:05:46.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 1207}, {'_account_id': 2861}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9236}, {'_account_id': 9533}, {'_account_id': 10765}, {'_account_id': 11751}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12779}, {'_account_id': 13049}]","[{'number': 1, 'created': '2014-09-05 12:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fafea9586ab180ec8e8f1cd6f4c81fd5ea021fc7', 'message': ""Add client_socket_timeout option\n\nAdd a parameter to take advantage of the new(ish) eventlet socket timeout\nbehaviour.  Allows closing idle client connections after a period of\ntime, eg:\n\n$ time nc localhost 8776\nreal    1m0.063s\n\nSetting 'client_socket_timeout = 0' means do not timeout.\n\nDocImpact\n\nChange-Id: If492810a2f10fa5954f8c8bb708b14be0b77fb90\n""}, {'number': 2, 'created': '2014-09-09 10:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f30eb38e1845bc1cc09d50f99a696e846b8f631c', 'message': ""Add client_socket_timeout option\n\nAdd a parameter to take advantage of the new(ish) eventlet socket timeout\nbehaviour.  Allows closing idle client connections after a period of\ntime, eg:\n\n$ time nc localhost 8776\nreal    1m0.063s\n\nSetting 'client_socket_timeout = 0' means do not timeout.\n\nDocImpact\n\nChange-Id: If492810a2f10fa5954f8c8bb708b14be0b77fb90\n""}, {'number': 3, 'created': '2014-09-09 10:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8eb002b2215f6708aa40fa2d46fd97d0988dfd8d', 'message': ""Add client_socket_timeout option\n\nAdd a parameter to take advantage of the new(ish) eventlet socket timeout\nbehaviour.  Allows closing idle client connections after a period of\ntime, eg:\n\n$ time nc localhost 8776\nreal    1m0.063s\n\nSetting 'client_socket_timeout = 0' means do not timeout.\n\nDocImpact\n\nChange-Id: If492810a2f10fa5954f8c8bb708b14be0b77fb90\n""}, {'number': 4, 'created': '2014-09-11 12:15:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/16612384f417a3e07abb0b5a53ac1ed5aac4aa8a', 'message': ""Add client_socket_timeout option\n\nAdd a parameter to take advantage of the new(ish) eventlet socket timeout\nbehaviour.  Allows closing idle client connections after a period of\ntime, eg:\n\n$ time nc localhost 8776\nreal    1m0.063s\n\nSetting 'client_socket_timeout = 0' means do not timeout.\n\nDocImpact\n\nChange-Id: If492810a2f10fa5954f8c8bb708b14be0b77fb90\n""}, {'number': 5, 'created': '2014-09-18 09:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/672eb560b0ad19052cff6b805b0a5a8f3a4f520d', 'message': ""Add client_socket_timeout option\n\nAdd a parameter to take advantage of the new(ish) eventlet socket timeout\nbehaviour.  Allows closing idle client connections after a period of\ntime, eg:\n\n$ time nc localhost 8776\nreal    1m0.063s\n\nSetting 'client_socket_timeout = 0' means do not timeout.\n\nDocImpact\n\nChange-Id: If492810a2f10fa5954f8c8bb708b14be0b77fb90\nCloses-bug: #1371022\n""}, {'number': 6, 'created': '2014-10-16 09:53:37.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/wsgi.py', 'cinder/tests/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/08bfa77aeccb8ca589e3fb5cf9771879818f59de', 'message': ""Add client_socket_timeout option\n\nAdd a parameter to take advantage of the new(ish) eventlet socket timeout\nbehaviour.  Allows closing idle client connections after a period of\ntime, eg:\n\n$ time nc localhost 8776\nreal    1m0.063s\n\nSetting 'client_socket_timeout = 0' means do not timeout.\n\nDocImpact\n\nChange-Id: If492810a2f10fa5954f8c8bb708b14be0b77fb90\nCloses-bug: #1371022\n""}]",2,119365,08bfa77aeccb8ca589e3fb5cf9771879818f59de,54,16,6,455,,,0,"Add client_socket_timeout option

Add a parameter to take advantage of the new(ish) eventlet socket timeout
behaviour.  Allows closing idle client connections after a period of
time, eg:

$ time nc localhost 8776
real    1m0.063s

Setting 'client_socket_timeout = 0' means do not timeout.

DocImpact

Change-Id: If492810a2f10fa5954f8c8bb708b14be0b77fb90
Closes-bug: #1371022
",git fetch https://review.opendev.org/openstack/cinder refs/changes/65/119365/5 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'etc/cinder/cinder.conf.sample', 'cinder/wsgi.py']",3,fafea9586ab180ec8e8f1cd6f4c81fd5ea021fc7,bug/1371022," cfg.IntOpt('client_socket_timeout', default=900, help=""Timeout for client connections\' socket operations. "" ""If an incoming connection is idle for this number of "" ""seconds it will be closed. A value of \'0\' means "" ""wait forever.""), self.client_socket_timeout = CONF.client_socket_timeout or None 'log': self._wsgi_logger, 'socket_timeout' : self.client_socket_timeout", 'log': self._wsgi_logger,14,2
openstack%2Fkeystone~stable%2Fjuno~I94b7e3d514a04d00bbd89019c222b4d4dbffca18,openstack/keystone,stable/juno,I94b7e3d514a04d00bbd89019c222b4d4dbffca18,Opening stable/juno,MERGED,2014-10-16 14:51:52.000000000,2014-10-17 15:57:22.000000000,2014-10-17 15:57:21.000000000,"[{'_account_id': 3}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-10-16 14:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b61bba847124d2609fec88e99e598e06cc0895df', 'message': 'Opening stable/juno\n\nBump version to next stable release on icehouse branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I94b7e3d514a04d00bbd89019c222b4d4dbffca18\n'}, {'number': 2, 'created': '2014-10-16 14:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c2c71f9bfe451832add47f99077427f626233fe7', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I94b7e3d514a04d00bbd89019c222b4d4dbffca18\n'}, {'number': 3, 'created': '2014-10-17 09:01:07.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e9cba76e8e6d5fc5ce71fb355649d56eef961162', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I94b7e3d514a04d00bbd89019c222b4d4dbffca18\n'}]",0,128941,e9cba76e8e6d5fc5ce71fb355649d56eef961162,10,2,3,308,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I94b7e3d514a04d00bbd89019c222b4d4dbffca18
",git fetch https://review.opendev.org/openstack/keystone refs/changes/41/128941/2 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,b61bba847124d2609fec88e99e598e06cc0895df,stable-juno,version = 2014.2.1,version = 2014.2,2,1
openstack%2Fnova~master~I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc,openstack/nova,master,I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc,Fix XML UnicodeEncode serialization error,MERGED,2014-09-29 08:09:32.000000000,2014-10-17 15:55:11.000000000,2014-09-30 22:13:54.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 679}, {'_account_id': 1063}, {'_account_id': 2835}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5367}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 10618}]","[{'number': 1, 'created': '2014-09-29 08:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c3e8ea3479a8f7168a3d9d3cd8d7adad851e760', 'message': ""Fix XML UnicodeEncode serialization error\n\nThe generic Nova XMLSerializer code will currently attempt\nto cast to str the value for all leaf nodes. This patch\nensures that no attempt is made to convert unicode which\ncan cause a UnicodeEncode error. We don't need to convert\nunicode for XML text and regardless we encode to UTF-8 at\na later point.\n\nChange-Id: I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc\nCloses-Bug: 1279172\n""}, {'number': 2, 'created': '2014-09-30 00:47:27.000000000', 'files': ['nova/api/openstack/wsgi.py', 'nova/tests/api/openstack/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/53fe8696314fb73ca9943fce998d96fa6d0414b4', 'message': ""Fix XML UnicodeEncode serialization error\n\nThe generic Nova XMLSerializer code will currently attempt\nto cast to str the value for all leaf nodes. This patch\nensures that no attempt is made to convert unicode which\ncan cause a UnicodeEncode error. We don't need to convert\nunicode for XML text and regardless we encode to UTF-8 at\na later point.\n\nChange-Id: I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc\nCloses-Bug: #1279172\n""}]",10,124678,53fe8696314fb73ca9943fce998d96fa6d0414b4,28,11,2,5292,,,0,"Fix XML UnicodeEncode serialization error

The generic Nova XMLSerializer code will currently attempt
to cast to str the value for all leaf nodes. This patch
ensures that no attempt is made to convert unicode which
can cause a UnicodeEncode error. We don't need to convert
unicode for XML text and regardless we encode to UTF-8 at
a later point.

Change-Id: I8135d2b9a67db62b0eafdd301b7fdb67a5dd72cc
Closes-Bug: #1279172
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/124678/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/wsgi.py', 'nova/tests/api/openstack/test_wsgi.py']",2,3c3e8ea3479a8f7168a3d9d3cd8d7adad851e760,bug/1279172," def test_xml_contains_unicode(self): input_dict = dict(test=u'\u89e3\u7801') expected_xml = '<test>\xe8\xa7\xa3\xe7\xa0\x81</test>' serializer = wsgi.XMLDictSerializer() result = serializer.serialize(input_dict) result = result.replace('\n', '').replace(' ', '') self.assertEqual(result, expected_xml) ",,11,1
openstack%2Fswift~master~Ib4cc3cbc1503b85dfdfa0edab58a49c95eac5993,openstack/swift,master,Ib4cc3cbc1503b85dfdfa0edab58a49c95eac5993,use replication_ip in ssync,MERGED,2014-10-16 02:01:14.000000000,2014-10-17 15:29:18.000000000,2014-10-17 15:29:17.000000000,"[{'_account_id': 3}, {'_account_id': 995}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 13052}, {'_account_id': 13297}]","[{'number': 1, 'created': '2014-10-16 02:01:14.000000000', 'files': ['test/unit/obj/test_ssync_sender.py', 'swift/obj/ssync_sender.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/556568b1c38dd0daa9eb6a9de34f54272e4c6465', 'message': 'use replication_ip in ssync\n\nUpdate ssync_sender to use replication_ip and replication_port from the ring.\n\nThose attributes are supposed to allow for a separate replication network, and\nare used by rsync replication.\n\nChange-Id: Ib4cc3cbc1503b85dfdfa0edab58a49c95eac5993\n'}]",0,128808,556568b1c38dd0daa9eb6a9de34f54272e4c6465,10,6,1,2828,,,0,"use replication_ip in ssync

Update ssync_sender to use replication_ip and replication_port from the ring.

Those attributes are supposed to allow for a separate replication network, and
are used by rsync replication.

Change-Id: Ib4cc3cbc1503b85dfdfa0edab58a49c95eac5993
",git fetch https://review.opendev.org/openstack/swift refs/changes/08/128808/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_ssync_sender.py', 'swift/obj/ssync_sender.py']",2,556568b1c38dd0daa9eb6a9de34f54272e4c6465,ssync_ip," '%s:%s/%s/%s %s', self.node.get('replication_ip'), self.node.get('replication_port'), self.node.get('device'), self.node.get('replication_ip'), self.node.get('replication_port'), '%s:%s' % (self.node['replication_ip'], self.node['replication_port']))"," '%s:%s/%s/%s %s', self.node.get('ip'), self.node.get('port'), self.node.get('device'), self.node.get('ip'), self.node.get('port'), '%s:%s' % (self.node['ip'], self.node['port']))",22,12
openstack%2Ffuel-main~master~I1f8dfb159adf2545c4d255deaef25ad4f8b161ac,openstack/fuel-main,master,I1f8dfb159adf2545c4d255deaef25ad4f8b161ac,Test for deployment master with custom manifests,MERGED,2014-10-09 13:36:00.000000000,2014-10-17 15:21:19.000000000,2014-10-17 15:21:18.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7195}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10136}]","[{'number': 1, 'created': '2014-10-09 13:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/61d74451d8dfcb7d6257562f64f6e465bf88eed8', 'message': 'Test for deployment master with custom manifests\n\nFuelmenu=yes. After provisioning sync custom\nPuppet manifest with master. Kill pid of\nFuel menu. Deploy master with custom manifests\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I1f8dfb159adf2545c4d255deaef25ad4f8b161ac\n'}, {'number': 2, 'created': '2014-10-13 11:42:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ef06c35f8c45bc6175fb1dc2bc2f02a30aea53a2', 'message': 'Test for deployment master with custom manifests\n\nFuelmenu=yes. After provisioning sync custom\nPuppet manifest with master. Kill pid of\nFuel menu. Deploy master with custom manifests\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I1f8dfb159adf2545c4d255deaef25ad4f8b161ac\n'}, {'number': 3, 'created': '2014-10-14 11:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/93babb5fecd9fb67a73026baa5fbec52de42e301', 'message': 'Test for deployment master with custom manifests\n\nFuelmenu=yes. After provisioning sync custom\nPuppet manifest with master. Kill pid of\nFuel menu. Deploy master with custom manifests\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I1f8dfb159adf2545c4d255deaef25ad4f8b161ac\n'}, {'number': 4, 'created': '2014-10-14 11:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4f6021f478c8d07cb0638e60345beb21d217b221', 'message': 'Test for deployment master with custom manifests\n\nFuelmenu=yes. After provisioning sync custom\nPuppet manifest with master. Kill pid of\nFuel menu. Deploy master with custom manifests\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I1f8dfb159adf2545c4d255deaef25ad4f8b161ac\n'}, {'number': 5, 'created': '2014-10-14 11:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f49466d4727fc4bd24ce5b29d4146f24adc7a5c0', 'message': 'Test for deployment master with custom manifests\n\nFuelmenu=yes. After provisioning sync custom\nPuppet manifest with master. Kill pid of\nFuel menu. Deploy master with custom manifests\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I1f8dfb159adf2545c4d255deaef25ad4f8b161ac\n'}, {'number': 6, 'created': '2014-10-15 15:22:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/25bd0f0bc351866698f968a1b18a5320789bbd87', 'message': 'Test for deployment master with custom manifests\n\nFuelmenu=yes. After provisioning sync custom\nPuppet manifest with master. Kill pid of\nFuel menu. Deploy master with custom manifests\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I1f8dfb159adf2545c4d255deaef25ad4f8b161ac\n'}, {'number': 7, 'created': '2014-10-16 08:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d5f0d17d454759a9d99d54e61fadde902bdd13f3', 'message': 'Test for deployment master with custom manifests\n\nFuelmenu=yes. After provisioning sync custom\nPuppet manifest with master. Kill pid of\nFuel menu. Deploy master with custom manifests\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I1f8dfb159adf2545c4d255deaef25ad4f8b161ac\n'}, {'number': 8, 'created': '2014-10-16 14:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/77491ecc92f6b2b267f6659a5f42d123b413bce0', 'message': 'Test for deployment master with custom manifests\n\nFuelmenu=yes. After provisioning sync custom\nPuppet manifest with master. Kill pid of\nFuel menu. Deploy master with custom manifests\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I1f8dfb159adf2545c4d255deaef25ad4f8b161ac\n'}, {'number': 9, 'created': '2014-10-17 12:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8fb67f02b1d6d1e01bf9ccf06b140e71cddaf06b', 'message': 'Test for deployment master with custom manifests\n\nFuelmenu=yes. After provisioning sync custom\nPuppet manifest with master. Kill pid of\nFuel menu. Deploy master with custom manifests\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I1f8dfb159adf2545c4d255deaef25ad4f8b161ac\n'}, {'number': 10, 'created': '2014-10-17 14:31:08.000000000', 'files': ['fuelweb_test/models/environment.py', 'fuelweb_test/tests/test_admin_node.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/bd193f6d5b45a2b7d946d832580d06624559fa11', 'message': 'Test for deployment master with custom manifests\n\nFuelmenu=yes. After provisioning sync custom\nPuppet manifest with master. Kill pid of\nFuel menu. Deploy master with custom manifests\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I1f8dfb159adf2545c4d255deaef25ad4f8b161ac\n'}]",23,127241,bd193f6d5b45a2b7d946d832580d06624559fa11,61,7,10,9439,,,0,"Test for deployment master with custom manifests

Fuelmenu=yes. After provisioning sync custom
Puppet manifest with master. Kill pid of
Fuel menu. Deploy master with custom manifests

blueprint fuel-master-ci-tests

Change-Id: I1f8dfb159adf2545c4d255deaef25ad4f8b161ac
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/41/127241/6 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/models/environment.py', 'fuelweb_test/tests/test_admin_node.py', 'fuelweb_test/helpers/checkers.py']",3,61d74451d8dfcb7d6257562f64f6e465bf88eed8,bp/fuel-master-ci-tests,"from fuelweb_test import settings @logwrap def upload_master_manifests(remote): try: logger.info(""Uploading new manifests from %s"" % settings.UPLOAD_MANIFESTS_PATH) remote.execute('rm -rf /etc/puppet/modules/*') remote.upload(settings.UPLOAD_MANIFESTS_PATH, '/etc/puppet/modules/') logger.info(""Copying new site.pp from %s"" % settings.SITEPP_FOR_UPLOAD) remote.execute(""cp %s /etc/puppet/manifests"" % settings.SITEPP_FOR_UPLOAD) except Exception as e: logger.error(""Could not upload manifests {0}"".format(e)) raise return 0",,98,15
openstack%2Fsolum~master~Ia21889859898cced9bd005b47f27d2c54eae1291,openstack/solum,master,Ia21889859898cced9bd005b47f27d2c54eae1291,Check that the chef LP exists in chef unittest_app,MERGED,2014-10-16 16:11:24.000000000,2014-10-17 15:20:46.000000000,2014-10-17 15:20:45.000000000,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 9095}]","[{'number': 1, 'created': '2014-10-16 16:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/67ca9c08eeb2bef04f4870732255513b9aadd342', 'message': ""Check that the chef LP exists in chef unittest_app\n\nTrying to unittest with the Chef LP will fail unless\nthe LP is already built; the unittest-app script now checks\nand builds it itself if it's missing.\n\nChange-Id: Ia21889859898cced9bd005b47f27d2c54eae1291\n""}, {'number': 2, 'created': '2014-10-16 19:20:12.000000000', 'files': ['contrib/lp-chef/docker/unittest-app'], 'web_link': 'https://opendev.org/openstack/solum/commit/6e764bb9d7f831a722ffa2ed6530060ec2f48b82', 'message': ""Check that the chef LP exists in chef unittest_app\n\nTrying to unittest with the Chef LP will fail unless\nthe LP is already built; the unittest-app script now checks\nand builds it itself if it's missing.\n\nChange-Id: Ia21889859898cced9bd005b47f27d2c54eae1291\n""}]",5,128983,6e764bb9d7f831a722ffa2ed6530060ec2f48b82,14,5,2,1375,,,0,"Check that the chef LP exists in chef unittest_app

Trying to unittest with the Chef LP will fail unless
the LP is already built; the unittest-app script now checks
and builds it itself if it's missing.

Change-Id: Ia21889859898cced9bd005b47f27d2c54eae1291
",git fetch https://review.opendev.org/openstack/solum refs/changes/83/128983/2 && git format-patch -1 --stdout FETCH_HEAD,['contrib/lp-chef/docker/unittest-app'],1,67ca9c08eeb2bef04f4870732255513b9aadd342,autobuild-chef-lp,# Make sure the chef LP exists; build if it doesn't. docker inspect $DOCKER_REGISTRY/chef || docker build -t $DOCKER_REGISTRY/chef /opt/stack/solum/examples/language-packs/chef/ ,,3,0
openstack%2Fpython-ceilometerclient~master~I134101a2979edbadce352d9f2291db4fa603e59e,openstack/python-ceilometerclient,master,I134101a2979edbadce352d9f2291db4fa603e59e,Updated from global requirements,MERGED,2014-10-11 15:56:26.000000000,2014-10-17 15:03:59.000000000,2014-10-17 15:03:59.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-10-11 15:56:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/71962c3d5214329c57a3f943ef7e7646906160f0', 'message': 'Updated from global requirements\n\nChange-Id: I134101a2979edbadce352d9f2291db4fa603e59e\n'}, {'number': 2, 'created': '2014-10-11 22:37:38.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/a52bcff399cf7ed99b595997b8a2fb08b9d091be', 'message': 'Updated from global requirements\n\nChange-Id: I134101a2979edbadce352d9f2291db4fa603e59e\n'}]",0,127787,a52bcff399cf7ed99b595997b8a2fb08b9d091be,18,5,2,11131,,,0,"Updated from global requirements

Change-Id: I134101a2979edbadce352d9f2291db4fa603e59e
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/87/127787/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,71962c3d5214329c57a3f943ef7e7646906160f0,openstack/requirements,"sphinx>=1.1.2,!=1.2.0,!=1.3b1,<1.3","sphinx>=1.1.2,!=1.2.0,<1.3",1,1
openstack%2Ffuel-web~master~I09560d141be4b327418ea003c790424ab8d26b8b,openstack/fuel-web,master,I09560d141be4b327418ea003c790424ab8d26b8b,Fix for destroyed Logs on UI,MERGED,2014-10-17 14:15:07.000000000,2014-10-17 14:44:44.000000000,2014-10-17 14:44:43.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-10-17 14:15:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0ad491e72f847c8d3172d4fbeb6548d0de692c6f', 'message': 'Fix for destroyed Logs on UI\n\nChange-Id: I09560d141be4b327418ea003c790424ab8d26b8b\nCloses-Bug:#1382518\n'}, {'number': 2, 'created': '2014-10-17 14:17:58.000000000', 'files': ['nailgun/static/js/views/cluster_page_tabs/logs_tab.jsx'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/33654affeeaca073397d0b1d0d71924fd0a98511', 'message': 'Fix for destroyed Logs on UI\n\nChange-Id: I09560d141be4b327418ea003c790424ab8d26b8b\nCloses-Bug:#1382518\n'}]",0,129272,33654affeeaca073397d0b1d0d71924fd0a98511,14,6,2,9730,,,0,"Fix for destroyed Logs on UI

Change-Id: I09560d141be4b327418ea003c790424ab8d26b8b
Closes-Bug:#1382518
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/72/129272/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/views/cluster_page_tabs/logs_tab.jsx'],1,0ad491e72f847c8d3172d4fbeb6548d0de692c6f,bug/1382518," ref='bar' var chosenSource = type == 'local' ? _.first(this.sources.reject({remote: true})) : this.sources.findWhere({remote: true}), chosenLevelId = chosenSource ? _.first(chosenSource.get('levels')) : null; return options;"," var chosenSource = type == 'local' ? _.first(this.sources.reject({remote: true})) : this.sources.find({remote: true}), chosenLevelId = chosenSource ? _.find(this.sources.get(chosenSource.id).get('levels')) : null;",4,2
openstack%2Fkolla~master~I1433305e23d872cd773599c85053ba8f9aeb6145,openstack/kolla,master,I1433305e23d872cd773599c85053ba8f9aeb6145,fix nova auth configuration,MERGED,2014-10-17 14:17:07.000000000,2014-10-17 14:43:51.000000000,2014-10-17 14:43:51.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}]","[{'number': 1, 'created': '2014-10-17 14:17:07.000000000', 'files': ['docker/nova-controller/nova-ctr-base/config-nova-controller.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/1f3d58a97df5fbafb1fee4f04486a0ebd47048e8', 'message': ""fix nova auth configuration\n\nBased on\nhttp://lists.openstack.org/pipermail/openstack/2014-January/004667.html,\nthere is confusion in the openstack community on how auth_uri in\nnova.conf is supposed to interact with the other auth_* settings.\n\nI've modified our config to use both for now.\n\nChange-Id: I1433305e23d872cd773599c85053ba8f9aeb6145\n""}]",0,129273,1f3d58a97df5fbafb1fee4f04486a0ebd47048e8,7,3,1,8745,,,0,"fix nova auth configuration

Based on
http://lists.openstack.org/pipermail/openstack/2014-January/004667.html,
there is confusion in the openstack community on how auth_uri in
nova.conf is supposed to interact with the other auth_* settings.

I've modified our config to use both for now.

Change-Id: I1433305e23d872cd773599c85053ba8f9aeb6145
",git fetch https://review.opendev.org/openstack/kolla refs/changes/73/129273/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/nova-controller/nova-ctr-base/config-nova-controller.sh'],1,1f3d58a97df5fbafb1fee4f04486a0ebd47048e8,larsks/fix-nova-auth,# disabled pending answers to http://lists.openstack.org/pipermail/openstack/2014-October/009997.html #for option in auth_protocol auth_host auth_port; do # crudini --del $cfg \ # keystone_authtoken \ # $option #donecrudini --set $cfg keystone_authtoken auth_protocol http crudini --set $cfg keystone_authtoken auth_host ${KEYSTONE_PUBLIC_SERVICE_HOST} crudini --set $cfg keystone_authtoken auth_port 5000 ,for option in auth_protocol auth_host auth_port; do crudini --del $cfg \ keystone_authtoken \ $option done,10,5
openstack%2Ffuel-library~stable%2F5.0~I21ba3debcfda4d94d5e25786f97996f6431e5ec3,openstack/fuel-library,stable/5.0,I21ba3debcfda4d94d5e25786f97996f6431e5ec3,Fix hourly log rotation schedule,MERGED,2014-10-08 07:27:20.000000000,2014-10-17 14:43:23.000000000,2014-10-17 14:43:22.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8789}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-10-08 07:27:20.000000000', 'files': ['deployment/puppet/anacron/files/logrotate-hourly'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a6737e68030cd92ef13bb74f176b74294139cb50', 'message': ""Fix hourly log rotation schedule\n\nW/o this patch, new log rotation template for\nFuel 5.x master node with docker (which is\n/etc/logrotate.d/20-fuel-docker.conf) would\nnever be scheduled for execution.\nAnd that could have caused master node's /var/log/\nfree space exhausted until the next planned daily\nlog rotation will come.\n\nCloses-bug: #1378327\n\nChange-Id: I21ba3debcfda4d94d5e25786f97996f6431e5ec3\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}]",2,126828,a6737e68030cd92ef13bb74f176b74294139cb50,13,8,1,6926,,,0,"Fix hourly log rotation schedule

W/o this patch, new log rotation template for
Fuel 5.x master node with docker (which is
/etc/logrotate.d/20-fuel-docker.conf) would
never be scheduled for execution.
And that could have caused master node's /var/log/
free space exhausted until the next planned daily
log rotation will come.

Closes-bug: #1378327

Change-Id: I21ba3debcfda4d94d5e25786f97996f6431e5ec3
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/28/126828/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/anacron/files/logrotate-hourly'],1,a6737e68030cd92ef13bb74f176b74294139cb50,fix1378327_5.0,nice ionice -c3 /usr/sbin/logrotate /etc/logrotate.d/20-fuel*.conf >& /tmp/logrotate && grep -q error /tmp/logrotate,nice ionice -c3 /usr/sbin/logrotate /etc/logrotate.d/20-fuel.conf >& /tmp/logrotate && grep -q error /tmp/logrotate,1,1
openstack%2Ftrove~master~I815ec2c98588b32c44a7d7e9685ca6b902728d20,openstack/trove,master,I815ec2c98588b32c44a7d7e9685ca6b902728d20,Obsolete oslo-incubator modules - timeutils,ABANDONED,2014-10-17 11:08:14.000000000,2014-10-17 14:41:56.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-10-17 11:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4bcffea34cfcebbacfe27d74347a559a91e3981a', 'message': 'Do not use obsolete oslo-incubator modules\n\nThis commit handles the timeutils module\n\nThe change here is to remove it from openstack-common.conf and point\nall people who used to use that at oslo.utils. This also involves a\nchange to requirements.txt\n\nChange-Id: I815ec2c98588b32c44a7d7e9685ca6b902728d20\nPartial-Bug: #1380789\n'}, {'number': 2, 'created': '2014-10-17 11:57:28.000000000', 'files': ['trove/tests/api/limits.py', 'trove/guestagent/common/timeutils.py', 'trove/openstack/common/jsonutils.py', 'trove/common/utils.py', 'trove/openstack/common/loopingcall.py', 'trove/limits/views.py', 'trove/tests/unittests/taskmanager/test_models.py', 'requirements.txt', 'trove/openstack/common/timeutils.py', 'trove/taskmanager/models.py', 'openstack-common.conf', 'trove/openstack/common/notifier/api.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/b1b991a7e0fd901e7da25fcc6f3a0dac999b6f22', 'message': 'Obsolete oslo-incubator modules - timeutils\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles the timeutils module\n\nThe change here is to remove it from openstack-common.conf and point\nall people who used to use that at oslo.utils. This also involves a\nchange to requirements.txt\n\nChange-Id: I815ec2c98588b32c44a7d7e9685ca6b902728d20\nPartial-Bug: #1380789\nblueprint: trove-retire-unused-modules\n'}]",0,129206,b1b991a7e0fd901e7da25fcc6f3a0dac999b6f22,11,4,2,9664,,,0,"Obsolete oslo-incubator modules - timeutils

This change is part of a multi-part change set to handle obsolete and
graduated oslo modules.

This commit handles the timeutils module

The change here is to remove it from openstack-common.conf and point
all people who used to use that at oslo.utils. This also involves a
change to requirements.txt

Change-Id: I815ec2c98588b32c44a7d7e9685ca6b902728d20
Partial-Bug: #1380789
blueprint: trove-retire-unused-modules
",git fetch https://review.opendev.org/openstack/trove refs/changes/06/129206/2 && git format-patch -1 --stdout FETCH_HEAD,"['trove/tests/api/limits.py', 'trove/guestagent/common/timeutils.py', 'trove/openstack/common/jsonutils.py', 'trove/common/utils.py', 'trove/openstack/common/loopingcall.py', 'trove/limits/views.py', 'trove/tests/unittests/taskmanager/test_models.py', 'requirements.txt', 'trove/openstack/common/timeutils.py', 'trove/taskmanager/models.py', 'openstack-common.conf', 'trove/openstack/common/notifier/api.py']",12,4bcffea34cfcebbacfe27d74347a559a91e3981a,bp/trove-retire-unused-modules,from oslo.utils import timeutils,from trove.openstack.common import timeutils,14,221
openstack%2Ffuel-library~stable%2F5.1~I21ba3debcfda4d94d5e25786f97996f6431e5ec3,openstack/fuel-library,stable/5.1,I21ba3debcfda4d94d5e25786f97996f6431e5ec3,Fix hourly log rotation schedule,MERGED,2014-10-07 15:36:53.000000000,2014-10-17 14:41:09.000000000,2014-10-17 14:41:08.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8787}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-10-07 15:36:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f54de409398c3816c95fed7c76777f6171615427', 'message': ""Fix hourly log rotation schedule\n\nW/o this patch, new log rotation template for\nFuel 5.x master node with docker (which is\n/etc/logrotate.d/20-fuel-docker.conf) would\nnever be scheduled for execution.\nAnd that could have caused master node's /var/log/\nfree space exhausted until the next planned daily\nlog rotation will come.\n\nCloses-bug: #1378327\n\nChange-Id: I21ba3debcfda4d94d5e25786f97996f6431e5ec3\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}, {'number': 2, 'created': '2014-10-07 15:39:46.000000000', 'files': ['deployment/puppet/anacron/files/logrotate-hourly'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/76cdbb798d26f39711d776121f49f42a2a3b068a', 'message': ""Fix hourly log rotation schedule\n\nW/o this patch, new log rotation template for\nFuel 5.x master node with docker (which is\n/etc/logrotate.d/20-fuel-docker.conf) would\nnever be scheduled for execution.\nAnd that could have caused master node's /var/log/\nfree space exhausted until the next planned daily\nlog rotation will come.\n\nDocImpact\nCloses-bug: #1378327\n\nChange-Id: I21ba3debcfda4d94d5e25786f97996f6431e5ec3\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}]",0,126602,76cdbb798d26f39711d776121f49f42a2a3b068a,18,7,2,6926,,,0,"Fix hourly log rotation schedule

W/o this patch, new log rotation template for
Fuel 5.x master node with docker (which is
/etc/logrotate.d/20-fuel-docker.conf) would
never be scheduled for execution.
And that could have caused master node's /var/log/
free space exhausted until the next planned daily
log rotation will come.

DocImpact
Closes-bug: #1378327

Change-Id: I21ba3debcfda4d94d5e25786f97996f6431e5ec3
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/02/126602/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/anacron/files/logrotate-hourly'],1,f54de409398c3816c95fed7c76777f6171615427,fix1378327_5.1,nice ionice -c3 /usr/sbin/logrotate /etc/logrotate.d/20-fuel*.conf >& /tmp/logrotate && grep -q error /tmp/logrotate,nice ionice -c3 /usr/sbin/logrotate /etc/logrotate.d/20-fuel.conf >& /tmp/logrotate && grep -q error /tmp/logrotate,1,1
openstack%2Ffuel-library~stable%2F5.1~I8bf38ae18b5741b03e6bda5f8e69748a8ecdf2ec,openstack/fuel-library,stable/5.1,I8bf38ae18b5741b03e6bda5f8e69748a8ecdf2ec,Increase tolerance of install DHCP,MERGED,2014-10-17 09:19:19.000000000,2014-10-17 14:38:39.000000000,2014-10-17 14:38:39.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8787}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 12867}, {'_account_id': 13343}]","[{'number': 1, 'created': '2014-10-17 09:19:19.000000000', 'files': ['deployment/puppet/nailgun/manifests/cobbler.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/335f009ba3b4ab63f90e1394e9fe08cd16c84ead', 'message': 'Increase tolerance of install DHCP\n\nFor Ubuntu, added the following kernel options:\nnetcfg/link_detection_timeout=20\nnetcfg/dhcptimeout=120\nFor CentOS:\ndhcptimeout=120\n\nCloses-Bug: #1381266\nRelated-Bug: #1376680\nRelated-Bug: #1379917\nblueprint 100-nodes-support\n\nChange-Id: I8bf38ae18b5741b03e6bda5f8e69748a8ecdf2ec\n'}]",0,129184,335f009ba3b4ab63f90e1394e9fe08cd16c84ead,13,10,1,11090,,,0,"Increase tolerance of install DHCP

For Ubuntu, added the following kernel options:
netcfg/link_detection_timeout=20
netcfg/dhcptimeout=120
For CentOS:
dhcptimeout=120

Closes-Bug: #1381266
Related-Bug: #1376680
Related-Bug: #1379917
blueprint 100-nodes-support

Change-Id: I8bf38ae18b5741b03e6bda5f8e69748a8ecdf2ec
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/84/129184/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nailgun/manifests/cobbler.pp'],1,335f009ba3b4ab63f90e1394e9fe08cd16c84ead,bp/100-nodes-support," kopts => ""biosdevname=0 sshd=1 dhcptimeout=120"", kopts => ""netcfg/choose_interface=eth0 netcfg/dhcp_timeout=120 netcfg/link_detection_timeout=20"","," kopts => ""biosdevname=0 sshd=1"", kopts => ""netcfg/choose_interface=eth0"",",2,2
openstack%2Frally~master~Ie0b3f9b72a55e8bf783f7ebf80a3287a7daf5e66,openstack/rally,master,Ie0b3f9b72a55e8bf783f7ebf80a3287a7daf5e66,Add support for creating neutron networks,ABANDONED,2014-10-17 11:18:37.000000000,2014-10-17 14:30:17.000000000,,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 6172}]","[{'number': 1, 'created': '2014-10-17 11:18:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3b89fbc15f59a50cd79c1b5c684ac47caf4f6e32', 'message': 'Add support for creating neutron networks\n\nAdd support for creating Neutron networks/subnets as part of each tenant\ncontext, allowing instances in OpenStack deployments based on Neutron with\nper-tenant based overlay networks to be tested with an actual nic.\n\nRight now this is relatively simplistic in that each subnet created has\nthe same CIDR, so Neutron must be configured to allow overlapping IP ranges\nin tenant subnets.\n\nChange-Id: Ie0b3f9b72a55e8bf783f7ebf80a3287a7daf5e66\n'}, {'number': 2, 'created': '2014-10-17 11:19:32.000000000', 'files': ['tests/unit/benchmark/context/test_users.py', 'rally/benchmark/context/users.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/f49960d1002c3ff6ed919d35f0ca46e509084bde', 'message': 'Add support for creating neutron networks\n\nAdd support for creating Neutron networks/subnets as part of\neach tenant context, allowing instances in OpenStack\ndeployments based on Neutron with per-tenant based overlay\nnetworks to be tested with an actual nic.\n\nRight now this is relatively simplistic in that each subnet\ncreated has the same CIDR, so Neutron must be configured\nto allow overlapping IP ranges in tenant subnets.\n\nChange-Id: Ie0b3f9b72a55e8bf783f7ebf80a3287a7daf5e66\n'}]",1,129210,f49960d1002c3ff6ed919d35f0ca46e509084bde,7,3,2,935,,,0,"Add support for creating neutron networks

Add support for creating Neutron networks/subnets as part of
each tenant context, allowing instances in OpenStack
deployments based on Neutron with per-tenant based overlay
networks to be tested with an actual nic.

Right now this is relatively simplistic in that each subnet
created has the same CIDR, so Neutron must be configured
to allow overlapping IP ranges in tenant subnets.

Change-Id: Ie0b3f9b72a55e8bf783f7ebf80a3287a7daf5e66
",git fetch https://review.opendev.org/openstack/rally refs/changes/10/129210/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/benchmark/context/test_users.py', 'rally/benchmark/context/users.py']",2,3b89fbc15f59a50cd79c1b5c684ac47caf4f6e32,wip-neutron-context," ""network_subnet"": { ""type"": ""string"", }, PATTERN_NETWORK = ""ctx_rally_%(tenant_id)s_network_%(iter)i"" PATTERN_SUBNET = ""ctx_rally_%(tenant_id)s_subnet_%(iter)i"" # NOTE: disable network creation by default self.config.setdefault('network_subnet', None) self.context[""networks""] = [] self.context[""subnets""] = [] admin_endpoint, users_num, project_dom, user_dom, \ network_subnet, task_id, i = args if network_subnet: client = osclients.Clients(admin_endpoint).neutron() LOG.debug(""Creating network for tenant %s"" % (tenant.id)) network_msg = { 'network': { 'name': cls.PATTERN_NETWORK % {""tenant_id"": tenant.id, ""iter"": i}, 'shared': False, 'tenant_id': tenant.id } } network = client.create_network(network_msg)['network'] LOG.debug(""Creating subnet for tenant %s"" % (tenant.id)) subnet_msg = { 'subnet': { 'name': cls.PATTERN_SUBNET % {""tenant_id"": tenant.id, ""iter"": i}, 'network_id': network['id'], 'enable_dhcp': True, 'cidr': network_subnet, 'ip_version': 4, 'tenant_id': tenant.id } } subnet = client.create_subnet(subnet_msg)['subnet'] else: subnet = network = None return ({""id"": tenant.id, ""name"": tenant.name}, users, network, subnet) @classmethod def _delete_subnets(cls, args): """"""Delete given subnets. :param args: tuple arguments, for Pool.imap() """""" admin_endpoint, subnets = args client = osclients.Clients(admin_endpoint).neutron() for subnet in subnets: try: client.delete_subnet(subnet['id']) except Exception as ex: LOG.warning(""Failed to delete subnet: %(subnet_id)s. "" ""Exception: %(ex)s"" % {""subnet_id"": subnet[""id""], ""ex"": ex}) @classmethod def _delete_networks(cls, args): """"""Delete given networks. :param args: tuple arguments, for Pool.imap() """""" admin_endpoint, networks = args client = osclients.Clients(admin_endpoint).neutron() for network in networks: try: client.delete_network(network['id']) except Exception as ex: LOG.warning(""Failed to delete network: %(network_id)s. "" ""Exception: %(ex)s"" % {""network_id"": network[""id""], ""ex"": ex}) self.config[""user_domain""], self.config[""network_subnet""], self.task[""uuid""], i) for tenant, users, network, subnet in utils.run_concurrent( if network: self.context[""networks""].append(network) if subnet: self.context[""subnets""].append(subnet) # Delete subnets if 'subnets' in self.context: subnet_chunks = utils.chunks(self.context[""subnets""], concurrent) utils.run_concurrent( concurrent, UserGenerator, ""_delete_subnets"", [(self.endpoint, subnet) for subnet in subnet_chunks]) # Delete networks if 'networks' in self.context: network_chunks = utils.chunks(self.context[""networks""], concurrent) utils.run_concurrent( concurrent, UserGenerator, ""_delete_networks"", [(self.endpoint, network) for network in network_chunks]) "," admin_endpoint, users_num, project_dom, user_dom, task_id, i = args return ({""id"": tenant.id, ""name"": tenant.name}, users) self.config[""user_domain""], self.task[""uuid""], i) for tenant, users in utils.run_concurrent(",105,7
openstack%2Ftempest~master~Ied2924bba78ec8f4a3b51df1be69273b28362475,openstack/tempest,master,Ied2924bba78ec8f4a3b51df1be69273b28362475,Log identifiers of resources being cleaned up,MERGED,2014-10-08 13:55:54.000000000,2014-10-17 14:29:04.000000000,2014-10-17 14:29:03.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 5754}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-08 13:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5a4f0462383f736c8f0cc69d4aab1ff1ce2ddd73', 'message': 'Log identifiers of resources being cleaned up\n\nOn teardown compute API tests clean up resources such as servers\nand images. This patch simply logs the identifiers of these\nresources in order to help debugging failures which might originate\nfrom problems during cleanup.\n\nChange-Id: Ied2924bba78ec8f4a3b51df1be69273b28362475\nRelated-Bug: #1357055\n'}, {'number': 2, 'created': '2014-10-08 17:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/165578dd5a51f9b937967640166b56d39e68e060', 'message': 'Log identifiers of resources being cleaned up\n\nOn teardown compute API tests clean up resources such as servers\nand images. This patch simply logs the identifiers of these\nresources in order to help debugging failures which might originate\nfrom problems during cleanup.\n\nChange-Id: Ied2924bba78ec8f4a3b51df1be69273b28362475\nRelated-Bug: #1357055\n'}, {'number': 3, 'created': '2014-10-16 16:26:54.000000000', 'files': ['tempest/api/compute/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1422a9ac6c40df71978412cddce90870d578989c', 'message': 'Log identifiers of resources being cleaned up\n\nOn teardown compute API tests clean up resources such as servers\nand images. This patch simply logs the identifiers of these\nresources in order to help debugging failures which might originate\nfrom problems during cleanup.\n\nChange-Id: Ied2924bba78ec8f4a3b51df1be69273b28362475\nRelated-Bug: #1357055\n'}]",1,126908,1422a9ac6c40df71978412cddce90870d578989c,22,6,3,261,,,0,"Log identifiers of resources being cleaned up

On teardown compute API tests clean up resources such as servers
and images. This patch simply logs the identifiers of these
resources in order to help debugging failures which might originate
from problems during cleanup.

Change-Id: Ied2924bba78ec8f4a3b51df1be69273b28362475
Related-Bug: #1357055
",git fetch https://review.opendev.org/openstack/tempest refs/changes/08/126908/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/base.py'],1,5a4f0462383f736c8f0cc69d4aab1ff1ce2ddd73,bug/1357055," LOG.debug('Clearing servers: %s', ','.join( server['id'] for server in cls.servers)) LOG.debug('Clearing images: %s', ','.join(cls.images)) LOG.debug('Clearing security groups: %s', ','.join( sg['id'] for sg in cls.security_groups)) LOG.debug('Clearing images: %s', ','.join(cls.server_groups))",,6,0
openstack%2Fnova~master~I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26,openstack/nova,master,I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26,Make the block device mapping retries configurable,MERGED,2014-06-26 17:14:34.000000000,2014-10-17 14:25:53.000000000,2014-07-11 17:10:32.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6763}, {'_account_id': 6873}, {'_account_id': 8430}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12134}]","[{'number': 1, 'created': '2014-06-26 17:14:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5abc3bc958fce854a5884e2679cb7d9fa37bbad3', 'message': '[BUG# 1332382] Make the block device mapping retries configurable\n\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 2, 'created': '2014-06-26 18:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/73d600939292480b516c7c8481cdb8b35180a1d2', 'message': 'Make the block device mapping retries configurable\n\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 3, 'created': '2014-06-26 21:34:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8cd8ab07fe76aa35a3180109db79c50a828ee4a', 'message': 'Make the block device mapping retries configurable\n\nCloses-Bug: #1332382\nDocImpact\n\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 4, 'created': '2014-06-30 16:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2512a0893ce60beb6c39038eb06122a2b2b0065d', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and\nincreasing the volume size, instances can go in to\nerror state if the volume takes longer to create\nthan the hard code valuei (max_tries) set in the,\nnova/compute/manager.py\n\n  def _await_block_device_map_created(self, context, vol_id, max_tries=180,\n                                        wait_between=1):\n\nTo fix this, max_retries should be made configurable.\nLooking through the different releases, Grizzly was 30,\nHavana was 60 , IceHouse is 180.\n\nThis change add a configuration option `block_device_allocate_retries`\nwhich can be set in nova.conf by the user to configure the number\nof block device mapping retries.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 5, 'created': '2014-06-30 18:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64c89804f921ea4eabf34047d6d26903537229c4', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code valuei (max_tries) set in the\nnova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\n\nTo fix this, max_retries should be made configurable. Looking through\nthe different releases, Grizzly was 30, Havana was 60 , IceHouse is\n180.\n\nThis change add a configuration option `block_device_allocate_retries`\nwhich can be set in nova.conf by the user to configure the number\nof block device mapping retries.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 6, 'created': '2014-06-30 18:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f932f1212807d60a0b206c070867ff6a350eeb2d', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code valuei (max_tries) set in the\nnova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\n\nTo fix this, max_retries should be made configurable. Looking through\nthe different releases, Grizzly was 30, Havana was 60 , IceHouse is\n180.\n\nThis change add a configuration option `block_device_allocate_retries`\nwhich can be set in nova.conf by the user to configure the number\nof block device mapping retries.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 7, 'created': '2014-06-30 20:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01c1f624f145e21c8c856a7fc24eeb0eb6a75649', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code valuei (max_tries) set in the\nnova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\n\nTo fix this, max_retries should be made configurable. Looking through\nthe different releases, Grizzly was 30, Havana was 60 , IceHouse is\n180.\n\nThis change add a configuration option `block_device_allocate_retries`\nwhich can be set in nova.conf by the user to configure the number\nof block device mapping retries.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 8, 'created': '2014-07-08 18:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cac827bafe8ca2626380ed65a7b5002df228f9df', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code valuei (max_tries) set in the\nnova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\nTo fix this, max_retries should be made configurable. Looking through\nthe different releases, Grizzly was 30, Havana was 60 , IceHouse is\n180.\n\nThis change add a configuration option `block_device_allocate_retries`\nwhich can be set in nova.conf by the user to configure the number\nof block device mapping retries.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 9, 'created': '2014-07-08 18:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71c8cb54e5bc50db40e15012113c8b3688e62d3a', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code valuei (max_tries) set in the\nnova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\nTo fix this, max_retries should be made configurable. Looking through\nthe different releases, Grizzly was 30, Havana was 60 , IceHouse is\n180.\n\nThis change add a configuration option `block_device_allocate_retries`\nwhich can be set in nova.conf by the user to configure the number\nof block device mapping retries.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 10, 'created': '2014-07-08 18:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/552b39c62edd35e2d83ea880686263df810e808b', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code valuei (max_tries) set in the\nnova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\nTo fix this, max_retries should be made configurable. Looking through\nthe different releases, Grizzly was 30, Havana was 60 , IceHouse is\n180.\n\nThis change add a configuration option `block_device_allocate_retries`\nwhich can be set in nova.conf by the user to configure the number\nof block device mapping retries.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 11, 'created': '2014-07-08 19:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba52900aaf60d450ca8725c3e453505d67ff5c09', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code valuei (max_tries) set in the\nnova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\nTo fix this, max_retries should be made configurable. Looking through\nthe different releases, Grizzly was 30, Havana was 60 , IceHouse is\n180.\n\nThis change add a configuration option `block_device_allocate_retries`\nwhich can be set in nova.conf by the user to configure the number\nof block device mapping retries.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 12, 'created': '2014-07-10 17:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8421ec4d2969102c61b33395e3d27aba8f17d0d', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code valuei (max_tries) set in the\nnova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\n\nTo fix this, max_retries should be made configurable. Looking through\nthe different releases, Grizzly was 30, Havana was 60 , IceHouse is\n180.\n\nThis change add a configuration option `block_device_allocate_retries`\nwhich can be set in nova.conf by the user to configure the number\nof block device mapping retries.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 13, 'created': '2014-07-10 22:53:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7e5d4047f7f4dd0a4b1d614579c79d8a70c30b90', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code valuei (max_tries) set in the\nnova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\n\nTo fix this, max_retries should be made configurable. Looking through\nthe different releases, Grizzly was 30, Havana was 60 , IceHouse is\n180.\n\nThis change adds two configuration options:\n1.  `block_device_allocate_retries` which can be set in nova.conf\nby the user to configure the number of block device mapping retries.\nThis replaces the max_tries argument in the above method.\n2. `block_device_allocate_retries_interval` which allows the user\nto specify the time interval between consecutive retries. This replaces\nwait_between argument in the above method.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 14, 'created': '2014-07-10 23:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c9191c8015389647dd9d4cb64cd446574c401cb', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code valuei (max_tries) set in the\nnova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\n\nTo fix this, max_retries should be made configurable. Looking through\nthe different releases, Grizzly was 30, Havana was 60 , IceHouse is\n180.\n\nThis change adds two configuration options:\n1.  `block_device_allocate_retries` which can be set in nova.conf\nby the user to configure the number of block device mapping retries.\nThis replaces the max_tries argument in the above method.\n2. `block_device_allocate_retries_interval` which allows the user\nto specify the time interval between consecutive retries. This replaces\nwait_between argument in the above method.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 15, 'created': '2014-07-11 05:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3485c8c3ddddc45d62e888f4ebd8abebb713f64a', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code valuei (max_tries) set in the\nnova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\n\nTo fix this, max_retries should be made configurable. Looking through\nthe different releases, Grizzly was 30, Havana was 60 , IceHouse is\n180.\n\nThis change adds two configuration options:\na)  `block_device_allocate_retries` which can be set in nova.conf\nby the user to configure the number of block device mapping retries.\nIt defaults to 60 and replaces the max_tries argument in the above method.\nb) `block_device_allocate_retries_interval` which allows the user\nto specify the time interval between consecutive retries. It defaults to 3\nand replaces wait_between argument in the above method.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 16, 'created': '2014-07-11 05:54:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a1604b2b5dec7ad2b8b1a3cb1466703bdf06e59c', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code value (max_trie/wait_betweens)\nset in nova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\n\nTo fix this, max_retries should be made configurable. Looking through\nthe different releases, Grizzly was 30, Havana was 60 , IceHouse is\n180.\n\nThis change adds two configuration options:\na)  `block_device_allocate_retries` which can be set in nova.conf\nby the user to configure the number of block device mapping retries.\nIt defaults to 60 and replaces the max_tries argument in the above method.\nb) `block_device_allocate_retries_interval` which allows the user\nto specify the time interval between consecutive retries. It defaults to 3\nand replaces wait_between argument in the above method.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 17, 'created': '2014-07-11 05:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63c94be845b7b0e45cfd48cd37616540fc598588', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code value (max_tries(180)/wait_between(1))\nset in nova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\n\nTo fix this, max_retries should be made configurable. Looking through\nthe different releases, Grizzly was 30, Havana was 60 , IceHouse is\n180.\n\nThis change adds two configuration options:\na)  `block_device_allocate_retries` which can be set in nova.conf\nby the user to configure the number of block device mapping retries.\nIt defaults to 60 and replaces the max_tries argument in the above method.\nb) `block_device_allocate_retries_interval` which allows the user\nto specify the time interval between consecutive retries. It defaults to 3\nand replaces wait_between argument in the above method.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}, {'number': 18, 'created': '2014-07-11 05:56:56.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/66721eb2c0f53fc4260b2f0aa9a3811da0f7ddbd', 'message': 'Make the block device mapping retries configurable\n\nWhen booting instances passing in block-device and increasing the\nvolume size, instances can go in to error state if the volume takes\nlonger to create than the hard code value (max_tries(180)/wait_between(1))\nset in nova/compute/manager.py\n\ndef _await_block_device_map_created(self,\n                                    context,\n                                    vol_id,\n                                    max_tries=180,\n                                    wait_between=1):\n\nTo fix this, max_retries/wait_between should be made configurable.\nLooking through the different releases, Grizzly was 30, Havana was\n60 , IceHouse is 180.\n\nThis change adds two configuration options:\na)  `block_device_allocate_retries` which can be set in nova.conf\nby the user to configure the number of block device mapping retries.\nIt defaults to 60 and replaces the max_tries argument in the above method.\nb) `block_device_allocate_retries_interval` which allows the user\nto specify the time interval between consecutive retries. It defaults to 3\nand replaces wait_between argument in the above method.\n\nDocImpact\nCloses-Bug: #1332382\nChange-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26\n'}]",15,102891,66721eb2c0f53fc4260b2f0aa9a3811da0f7ddbd,164,20,18,12134,,,0,"Make the block device mapping retries configurable

When booting instances passing in block-device and increasing the
volume size, instances can go in to error state if the volume takes
longer to create than the hard code value (max_tries(180)/wait_between(1))
set in nova/compute/manager.py

def _await_block_device_map_created(self,
                                    context,
                                    vol_id,
                                    max_tries=180,
                                    wait_between=1):

To fix this, max_retries/wait_between should be made configurable.
Looking through the different releases, Grizzly was 30, Havana was
60 , IceHouse is 180.

This change adds two configuration options:
a)  `block_device_allocate_retries` which can be set in nova.conf
by the user to configure the number of block device mapping retries.
It defaults to 60 and replaces the max_tries argument in the above method.
b) `block_device_allocate_retries_interval` which allows the user
to specify the time interval between consecutive retries. It defaults to 3
and replaces wait_between argument in the above method.

DocImpact
Closes-Bug: #1332382
Change-Id: I16e4cd1a572bc5c2cd91fc94be85e72f576a8c26
",git fetch https://review.opendev.org/openstack/nova refs/changes/91/102891/13 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",2,5abc3bc958fce854a5884e2679cb7d9fa37bbad3,bug/1332382," self.context, '1', wait_between=0.1)"," self.context, '1', max_tries=2, wait_between=0.1) max_tries=4,",8,7
openstack%2Frally~master~I43b480feb20ff487639cee34cb9f8215e2017973,openstack/rally,master,I43b480feb20ff487639cee34cb9f8215e2017973,Fix endpoint type processing issue,ABANDONED,2014-10-15 23:00:22.000000000,2014-10-17 14:23:49.000000000,,"[{'_account_id': 3}, {'_account_id': 5950}, {'_account_id': 6172}, {'_account_id': 10475}]","[{'number': 1, 'created': '2014-10-15 23:00:22.000000000', 'files': ['tests/unit/test_osclients.py', 'rally/osclients.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/8f72c658dde48342e40bf80c8f4fbc53b92fafa7', 'message': 'Fix endpoint type processing issue\n\n  Closes-Bug: #1379876\n\nChange-Id: I43b480feb20ff487639cee34cb9f8215e2017973\n'}]",0,128784,8f72c658dde48342e40bf80c8f4fbc53b92fafa7,6,4,1,9601,,,0,"Fix endpoint type processing issue

  Closes-Bug: #1379876

Change-Id: I43b480feb20ff487639cee34cb9f8215e2017973
",git fetch https://review.opendev.org/openstack/rally refs/changes/84/128784/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_osclients.py', 'rally/osclients.py']",2,8f72c658dde48342e40bf80c8f4fbc53b92fafa7,bug/1379876,,"import urlparse if kw[""endpoint_type""] == consts.EndpointType.PUBLIC: mgmt_url = urlparse.urlparse(kw[""auth_url""]) if mgmt_url.port != kw[""admin_port""]: kw[""endpoint""] = ""{0}://{1}:{2}{3}"".format( mgmt_url.scheme, mgmt_url.hostname, kw[""admin_port""], mgmt_url.path ) else: kw[""endpoint""] = kw[""auth_url""]",3,22
openstack%2Fkolla~master~I5e1931d2e7ea35f741ab73b070e24926a3763054,openstack/kolla,master,I5e1931d2e7ea35f741ab73b070e24926a3763054,Properly create endpoints for Nova services,MERGED,2014-10-17 07:43:14.000000000,2014-10-17 14:13:52.000000000,2014-10-17 14:13:52.000000000,"[{'_account_id': 3}, {'_account_id': 8745}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-10-17 07:43:14.000000000', 'files': ['docker/nova-controller/nova-api/start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/e35e4f931a949027edaa8586a78f9484ec04a92d', 'message': 'Properly create endpoints for Nova services\n\nThe endpoints for Nova services needed to be properly created for ports\n8773 (ec2/ec2) and 8774(nova/compute) and 8774(novav3/computev3).\n\nChange-Id: I5e1931d2e7ea35f741ab73b070e24926a3763054\n'}]",0,129156,e35e4f931a949027edaa8586a78f9484ec04a92d,7,3,1,2834,,,0,"Properly create endpoints for Nova services

The endpoints for Nova services needed to be properly created for ports
8773 (ec2/ec2) and 8774(nova/compute) and 8774(novav3/computev3).

Change-Id: I5e1931d2e7ea35f741ab73b070e24926a3763054
",git fetch https://review.opendev.org/openstack/kolla refs/changes/56/129156/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/nova-controller/nova-api/start.sh'],1,e35e4f931a949027edaa8586a78f9484ec04a92d,," -n ec2 -t ec2 \ -I ""http://${NOVA_EC2_API_SERVICE_HOST}:8773/services/Cloud"" \ -P ""http://${PUBLIC_IP}:8773/services/Cloud"" \ -A ""http://${NOVA_EC2_API_SERVICE_HOST}:8773/services/Admin"" crux endpoint-create --remove-all \ -n nova -t compute \ -I ""http://${NOVA_API_SERVICE_HOST}:8774/v2/\$(tenant_id)s"" \ -P ""http://${PUBLIC_IP}:8774/v2/\$(tenant_id)s"" \ -A ""http://${NOVA_API_SERVICE_HOST}:8774/v2/\$(tenant_id)s"" crux endpoint-create --remove-all \ -n novav3 -t computev3 \ -I ""http://${NOVA_API_SERVICE_HOST}:8774/v3"" \ -P ""http://${PUBLIC_IP}:8774/v3"" \ -A ""http://${NOVA_API_SERVICE_HOST}:8774/v3"""," -n glance -t image \ -I ""http://${NOVA_API_SERVICE_HOST}:9292"" \ -P ""http://${PUBLIC_IP}:9292"" \ -A ""http://${NOVA_API_SERVICE_HOST}:9292""",16,4
openstack%2Fkolla~master~I5bcd21c59f341494206a09e882631185ce66f336,openstack/kolla,master,I5bcd21c59f341494206a09e882631185ce66f336,Make nova-compute work properly with libvirt,MERGED,2014-10-17 06:03:05.000000000,2014-10-17 14:13:31.000000000,2014-10-17 14:13:31.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-10-17 06:03:05.000000000', 'files': ['docker/nova-compute/nova-compute/start.sh', 'k8s/service/nova-libvirt-service.yaml', 'docker/nova-compute/nova-compute/config-nova-compute.sh', 'k8s/replication/nova-compute-replication.yaml', 'docker/nova-compute/nova-compute/Dockerfile'], 'web_link': 'https://opendev.org/openstack/kolla/commit/a14b8048c273f12aa4b941c0ff923997ad7524d6', 'message': 'Make nova-compute work properly with libvirt\n\nThe nova-compute POD now starts and produces nearly correct output.\nIt may be that the libvirt container needs additional attention as it\nis spitting out errors related to the firewall toolchain on the container.\n\nChange-Id: I5bcd21c59f341494206a09e882631185ce66f336\n'}]",0,129137,a14b8048c273f12aa4b941c0ff923997ad7524d6,7,3,1,2834,,,0,"Make nova-compute work properly with libvirt

The nova-compute POD now starts and produces nearly correct output.
It may be that the libvirt container needs additional attention as it
is spitting out errors related to the firewall toolchain on the container.

Change-Id: I5bcd21c59f341494206a09e882631185ce66f336
",git fetch https://review.opendev.org/openstack/kolla refs/changes/37/129137/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/nova-compute/nova-compute/start.sh', 'k8s/service/nova-libvirt-service.yaml', 'docker/nova-compute/nova-compute/config-nova-compute.sh', 'k8s/replication/nova-compute-replication.yaml', 'docker/nova-compute/nova-compute/Dockerfile']",5,a14b8048c273f12aa4b941c0ff923997ad7524d6,,ADD config-nova-compute.sh /opt/kolla/config-nova-compute.sh,,95,42
openstack%2Fkolla~master~I3ddd3aca54900686e3351de3dc11896347b14b6e,openstack/kolla,master,I3ddd3aca54900686e3351de3dc11896347b14b6e,Remove nova-base since there is only 1 image for nova-compute,MERGED,2014-10-17 06:03:05.000000000,2014-10-17 14:12:55.000000000,2014-10-17 14:12:55.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-10-17 06:03:05.000000000', 'files': ['docker/nova-compute/nova-base/build', 'docker/nova-compute/nova-base/Dockerfile', 'docker/nova-compute/nova-compute/Dockerfile'], 'web_link': 'https://opendev.org/openstack/kolla/commit/518e72484599defe3fa6d0d749558137c47543c1', 'message': 'Remove nova-base since there is only 1 image for nova-compute\n\nLibvirt imports from fedora-rdo-base rather then nova-base, so no need\nin generating an extra image.\n\nChange-Id: I3ddd3aca54900686e3351de3dc11896347b14b6e\n'}]",0,129136,518e72484599defe3fa6d0d749558137c47543c1,7,3,1,2834,,,0,"Remove nova-base since there is only 1 image for nova-compute

Libvirt imports from fedora-rdo-base rather then nova-base, so no need
in generating an extra image.

Change-Id: I3ddd3aca54900686e3351de3dc11896347b14b6e
",git fetch https://review.opendev.org/openstack/kolla refs/changes/36/129136/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/nova-compute/nova-base/build', 'docker/nova-compute/nova-base/Dockerfile', 'docker/nova-compute/nova-compute/Dockerfile']",3,518e72484599defe3fa6d0d749558137c47543c1,,FROM kollaglue/fedora-rdo-base,FROM kollaglue/fedora-rdo-nova-base,1,7
openstack%2Ffuel-main~master~If098654d1158aca6676f9cbb3fc3100fc2e8674d,openstack/fuel-main,master,If098654d1158aca6676f9cbb3fc3100fc2e8674d,Add building of Fuel deb packages during ISO build.,MERGED,2014-09-08 11:19:43.000000000,2014-10-17 14:02:30.000000000,2014-10-17 14:02:29.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8777}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 10474}]","[{'number': 1, 'created': '2014-09-08 11:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/bd393eb8016991492d420860d6b24fc3bf5e59fd', 'message': 'Add building of Fuel deb packages during ISO build.\n\n1) Add routines for building deb packages and adding them to local mirror.\n2) Add commands for creating Ubuntu-based build sandbox.\n3) Update deb specs for Fuel components.\n\nChange-Id: If098654d1158aca6676f9cbb3fc3100fc2e8674d\n'}, {'number': 2, 'created': '2014-09-08 15:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1f3c47d133d8b2c19f43025d4ea91124e0e69fe6', 'message': 'Add building of Fuel deb packages during ISO build.\n\n1) Add routines for building deb packages and adding them to local mirror.\n2) Add commands for creating Ubuntu-based build sandbox.\n3) Update deb specs for Fuel components.\n\nChange-Id: If098654d1158aca6676f9cbb3fc3100fc2e8674d\n'}, {'number': 3, 'created': '2014-09-24 12:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/db7d82e7c9f5f411e3f1afe26b4f6e5a3f738533', 'message': 'Add building of Fuel deb packages during ISO build.\n\n1) Add routines for building deb packages and adding them to local mirror.\n2) Add commands for creating Ubuntu-based build sandbox.\n3) Update deb specs for Fuel components.\n\nCloses-Bug: 1373400\nChange-Id: If098654d1158aca6676f9cbb3fc3100fc2e8674d\n'}, {'number': 4, 'created': '2014-09-30 12:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ffd6bf3fdfecbe608a5ca8b57854a9ad52a84ee1', 'message': 'Add building of Fuel deb packages during ISO build.\n\n1) Add routines for building deb packages and adding them to local mirror.\n2) Add commands for creating Ubuntu-based build sandbox.\n3) Update deb specs for Fuel components.\n\nCloses-Bug: 1373400\nChange-Id: If098654d1158aca6676f9cbb3fc3100fc2e8674d\n'}, {'number': 5, 'created': '2014-10-14 15:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/24419a1f2df208b8a8ea75dc2b1153108ce72571', 'message': 'Add building of Fuel deb packages during ISO build.\n\n1) Add routines for building deb packages and adding them to local mirror.\n2) Add commands for creating Ubuntu-based build sandbox.\n3) Update deb specs for Fuel components.\n\nCloses-Bug: 1373400\nChange-Id: If098654d1158aca6676f9cbb3fc3100fc2e8674d\n'}, {'number': 6, 'created': '2014-10-15 13:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/39b8dc87bc1b12fd7d89304a1df16579d66b43c1', 'message': 'Add building of Fuel deb packages during ISO build.\n\n1) Add routines for building deb packages and adding them to local mirror.\n2) Add commands for creating Ubuntu-based build sandbox.\n3) Update deb specs for Fuel components.\n\nCloses-Bug: 1373400\nChange-Id: If098654d1158aca6676f9cbb3fc3100fc2e8674d\n'}, {'number': 7, 'created': '2014-10-17 13:17:13.000000000', 'files': ['packages/deb/specs/fencing-agent/debian/changelog', 'packages/module.mk', 'packages/dpkg.patch', 'packages/deb/specs/nailgun-mcagents/debian/rules', 'packages/deb/specs/nailgun-agent/debian/nailgun-agent.cron.d', 'packages/deb/specs/nailgun-net-check/debian/changelog', 'packages/deb/specs/nailgun-agent/debian/changelog', 'sandbox.mk', 'packages/deb/module.mk', 'packages/multistrap.conf', 'packages/regenerate_ubuntu_repo', 'packages/deb/specs/nailgun-mcagents/debian/changelog', 'packages/rpm/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/967ec61eb62ed17771dcc9fb79a5ae6bacba03f2', 'message': 'Add building of Fuel deb packages during ISO build.\n\n1) Add routines for building deb packages and adding them to local mirror.\n2) Add commands for creating Ubuntu-based build sandbox.\n3) Update deb specs for Fuel components.\n\nCloses-Bug: 1373400\nChange-Id: If098654d1158aca6676f9cbb3fc3100fc2e8674d\n'}]",11,119733,967ec61eb62ed17771dcc9fb79a5ae6bacba03f2,49,7,7,10474,,,0,"Add building of Fuel deb packages during ISO build.

1) Add routines for building deb packages and adding them to local mirror.
2) Add commands for creating Ubuntu-based build sandbox.
3) Update deb specs for Fuel components.

Closes-Bug: 1373400
Change-Id: If098654d1158aca6676f9cbb3fc3100fc2e8674d
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/33/119733/5 && git format-patch -1 --stdout FETCH_HEAD,"['packages/deb/specs/fencing-agent/debian/changelog', 'packages/module.mk', 'packages/dpkg.patch', 'packages/deb/specs/nailgun-mcagents/debian/rules', 'packages/deb/specs/nailgun-agent/debian/nailgun-agent.cron.d', 'packages/deb/specs/nailgun-net-check/debian/changelog', 'packages/deb/specs/nailgun-agent/debian/changelog', 'sandbox.mk', 'packages/deb/module.mk', 'packages/multistrap.conf', 'packages/regenerate_ubuntu_repo', 'packages/deb/specs/nailgun-mcagents/debian/changelog']",12,bd393eb8016991492d420860d6b24fc3bf5e59fd,bug/1373400,"nailgun-mcagents (0.0.1-ubuntu1) precise; urgency=low * Update code from upstream -- OSCI Jenkins <dburmistrov@mirantis.com> Wed, 03 Sep 2014 15:20:13 +0400 ",,255,3
openstack%2Fmurano-dashboard~stable%2Fjuno~I9f0cf073d22715ce58a78eb8486390b7bd207685,openstack/murano-dashboard,stable/juno,I9f0cf073d22715ce58a78eb8486390b7bd207685,Opening stable/juno,MERGED,2014-10-17 13:28:14.000000000,2014-10-17 14:02:16.000000000,2014-10-17 14:02:16.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-10-17 13:28:14.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/6d81222bae4f8678e2c7d8a5e21c72fd86feb6b4', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I9f0cf073d22715ce58a78eb8486390b7bd207685\n'}]",0,129241,6d81222bae4f8678e2c7d8a5e21c72fd86feb6b4,8,3,1,6786,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I9f0cf073d22715ce58a78eb8486390b7bd207685
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/41/129241/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,6d81222bae4f8678e2c7d8a5e21c72fd86feb6b4,,version = 2014.2.1,version = 2014.2,2,1
openstack%2Fmurano~stable%2Fjuno~I310356fb042290759df7dec611e2139d97b29923,openstack/murano,stable/juno,I310356fb042290759df7dec611e2139d97b29923,Opening stable/juno,MERGED,2014-10-17 13:28:14.000000000,2014-10-17 14:00:57.000000000,2014-10-17 14:00:57.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-10-17 13:28:14.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/murano/commit/65f3cd88267ebcb7cb1b47f4ac4d0fe2760251d0', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I310356fb042290759df7dec611e2139d97b29923\n'}]",0,129242,65f3cd88267ebcb7cb1b47f4ac4d0fe2760251d0,8,3,1,6786,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I310356fb042290759df7dec611e2139d97b29923
",git fetch https://review.opendev.org/openstack/murano refs/changes/42/129242/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,65f3cd88267ebcb7cb1b47f4ac4d0fe2760251d0,,version = 2014.2.1,version = 2015.1,2,1
openstack%2Ftripleo-image-elements~stable%2Ficehouse~I0563375c46bd4dcc2b704128ddc742ec11bb6459,openstack/tripleo-image-elements,stable/icehouse,I0563375c46bd4dcc2b704128ddc742ec11bb6459,Update percona xtradb-cluster package,ABANDONED,2014-05-01 13:47:28.000000000,2014-10-17 13:57:14.000000000,,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 1726}, {'_account_id': 1926}, {'_account_id': 6488}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 9453}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-05-01 13:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0bd9d7ebabd10eae6efdb2b787de67ef4a4cecf2', 'message': 'Update percona xtradb-cluster package\n\nIt appears that percona no longer offers a binary with static linked\nssl. Updating the download URL and symlink hacks to work with new\npackage.\n\nCloses-Bug: #1304629\nChange-Id: I0563375c46bd4dcc2b704128ddc742ec11bb6459\n'}, {'number': 2, 'created': '2014-05-07 11:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/023c23d9cd3a62654081f4653b205b920c55345f', 'message': 'Update percona xtradb-cluster package\n\nIt appears that percona no longer offers a binary with static linked\nssl. Updating the download URL and symlink hacks to work with new\npackage.\n\nConflicts:\n\telements/mysql/install.d/20-galera-libssl-symlink\n\nCloses-Bug: #1304629\nChange-Id: I0563375c46bd4dcc2b704128ddc742ec11bb6459\n(cherry picked from commit 679626f4967da5f296cc0911c1aec9219b5a7119)\n'}, {'number': 3, 'created': '2014-08-26 14:03:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/26772907612c21ea5151e1fc1d08123f4f848117', 'message': 'Update percona xtradb-cluster package\n\nIt appears that percona no longer offers a binary with static linked\nssl. Updating the download URL and symlink hacks to work with new\npackage.\n\nConflicts:\n\telements/mysql/install.d/20-galera-libssl-symlink\n\nCloses-Bug: #1304629\nChange-Id: I0563375c46bd4dcc2b704128ddc742ec11bb6459\n(cherry picked from commit 679626f4967da5f296cc0911c1aec9219b5a7119)\n'}, {'number': 4, 'created': '2014-08-26 14:27:47.000000000', 'files': ['elements/mysql/install.d/20-galera-libssl-symlink', 'elements/mysql/source-repository-mysql'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e16ee8a141250416a800525325c4c4a69907079f', 'message': 'Update percona xtradb-cluster package\n\nIt appears that percona no longer offers a binary with static linked\nssl. Updating the download URL and symlink hacks to work with new\npackage.\n\nConflicts:\n\telements/mysql/install.d/20-galera-libssl-symlink\n\nCloses-Bug: #1304629\nChange-Id: I0563375c46bd4dcc2b704128ddc742ec11bb6459\n(cherry picked from commit 679626f4967da5f296cc0911c1aec9219b5a7119)\n'}]",2,91561,e16ee8a141250416a800525325c4c4a69907079f,52,9,4,215,,,0,"Update percona xtradb-cluster package

It appears that percona no longer offers a binary with static linked
ssl. Updating the download URL and symlink hacks to work with new
package.

Conflicts:
	elements/mysql/install.d/20-galera-libssl-symlink

Closes-Bug: #1304629
Change-Id: I0563375c46bd4dcc2b704128ddc742ec11bb6459
(cherry picked from commit 679626f4967da5f296cc0911c1aec9219b5a7119)
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/61/91561/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/mysql/install.d/20-galera-libssl-symlink', 'elements/mysql/source-repository-mysql']",2,0bd9d7ebabd10eae6efdb2b787de67ef4a4cecf2,stable/icehouse,xtradb-cluster tar /usr/local/Percona-XtraDB-Cluster http://www.percona.com/redir/downloads/Percona-XtraDB-Cluster/LATEST/binary/linux/$PERCONA_ARCH/Percona-XtraDB-Cluster-5.5.34-25.9.607.Linux.$PERCONA_ARCH.tar.gz,# Due to https://bugs.launchpad.net/percona-xtradb-cluster/+bug/1213855 we are running a testing build xtradb-cluster tar /usr/local/Percona-XtraDB-Cluster http://www.percona.com/redir/downloads/TESTING/Percona-XtraDB-Cluster/5.5.33-23.7.5/release-5.5.33/476/binary/linux/$PERCONA_ARCH/Percona-XtraDB-Cluster-5.5.33-23.7.5.476-static-openssl-1.0.1e.Linux.$PERCONA_ARCH.tar.gz,28,2
openstack%2Ftripleo-incubator~stable%2Ficehouse~I3b8f0cb6af0ed70ed81338575b93f758cac38535,openstack/tripleo-incubator,stable/icehouse,I3b8f0cb6af0ed70ed81338575b93f758cac38535,Use different filenames for normal/ironic ramdisks,ABANDONED,2014-09-02 14:14:26.000000000,2014-10-17 13:56:56.000000000,,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 4190}, {'_account_id': 6348}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 9453}, {'_account_id': 12459}]","[{'number': 1, 'created': '2014-09-02 14:14:26.000000000', 'files': ['scripts/setup-baremetal', 'scripts/devtest_ramdisk.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/97ddc8e023a4a48793085a94b9e0a869f5898104', 'message': 'Use different filenames for normal/ironic ramdisks\n\nThis avoids a nasty failure mode when using cached images and\nswitching between nova-bm and Ironic.\n\nChange-Id: I3b8f0cb6af0ed70ed81338575b93f758cac38535\n'}]",2,118346,97ddc8e023a4a48793085a94b9e0a869f5898104,21,9,1,215,,,0,"Use different filenames for normal/ironic ramdisks

This avoids a nasty failure mode when using cached images and
switching between nova-bm and Ironic.

Change-Id: I3b8f0cb6af0ed70ed81338575b93f758cac38535
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/46/118346/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/setup-baremetal', 'scripts/devtest_ramdisk.sh']",2,97ddc8e023a4a48793085a94b9e0a869f5898104,, DEPLOY_NAME=deploy-ramdisk DEPLOY_NAME=deploy-ramdisk-ironicif [ ! -e $TRIPLEO_ROOT/$DEPLOY_NAME.kernel -o \ ! -e $TRIPLEO_ROOT/$DEPLOY_NAME.initramfs -o \ $NODE_DIST $DEPLOY_IMAGE_ELEMENT -o $TRIPLEO_ROOT/$DEPLOY_NAME \,if [ ! -e $TRIPLEO_ROOT/deploy-ramdisk.kernel -o \ ! -e $TRIPLEO_ROOT/deploy-ramdisk.initramfs -o \ $NODE_DIST $DEPLOY_IMAGE_ELEMENT -o $TRIPLEO_ROOT/deploy-ramdisk \,13,5
openstack%2Ftripleo-incubator~stable%2Ficehouse~I1ff4bb98c99dfe87ccc4fb19767b93e27707d3a7,openstack/tripleo-incubator,stable/icehouse,I1ff4bb98c99dfe87ccc4fb19767b93e27707d3a7,Use the renamed deploy-baremetal element,ABANDONED,2014-09-02 14:14:26.000000000,2014-10-17 13:56:50.000000000,,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6348}, {'_account_id': 7585}, {'_account_id': 8449}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-09-02 14:14:26.000000000', 'files': ['scripts/devtest_ramdisk.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/7a9213625f1010b64cfa6ebaced411b2fcd4b47f', 'message': 'Use the renamed deploy-baremetal element\n\nThis is dependent upon a change in diskimage-builder:\nIbb4026e8fc8ba6378061461c4796a91ab2fa991f\n\nThe rename was performed so that each element had a more descriptive\nname, and so that each element could accurately set an element-provides\nof ""deploy"", given that the elements enable tripleo deploys via the\nramdisk image.\n\nChange-Id: I1ff4bb98c99dfe87ccc4fb19767b93e27707d3a7\n'}]",0,118347,7a9213625f1010b64cfa6ebaced411b2fcd4b47f,13,6,1,215,,,0,"Use the renamed deploy-baremetal element

This is dependent upon a change in diskimage-builder:
Ibb4026e8fc8ba6378061461c4796a91ab2fa991f

The rename was performed so that each element had a more descriptive
name, and so that each element could accurately set an element-provides
of ""deploy"", given that the elements enable tripleo deploys via the
ramdisk image.

Change-Id: I1ff4bb98c99dfe87ccc4fb19767b93e27707d3a7
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/47/118347/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_ramdisk.sh'],1,7a9213625f1010b64cfa6ebaced411b2fcd4b47f,, DEPLOY_IMAGE_ELEMENT=${DEPLOY_IMAGE_ELEMENT:-deploy-baremetal}, DEPLOY_IMAGE_ELEMENT=${DEPLOY_IMAGE_ELEMENT:-deploy},1,1
openstack%2Fmurano-agent~stable%2Fjuno~I11b561ad1f0014729288cc9a8650a2572cbab29c,openstack/murano-agent,stable/juno,I11b561ad1f0014729288cc9a8650a2572cbab29c,Opening stable/juno,MERGED,2014-10-17 13:28:14.000000000,2014-10-17 13:46:48.000000000,2014-10-17 13:32:20.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-10-17 13:28:14.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/2bf3d0488d04f3002107ae793e9c0a5084f5528e', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I11b561ad1f0014729288cc9a8650a2572cbab29c\n'}]",0,129240,2bf3d0488d04f3002107ae793e9c0a5084f5528e,8,3,1,6786,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I11b561ad1f0014729288cc9a8650a2572cbab29c
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/40/129240/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,2bf3d0488d04f3002107ae793e9c0a5084f5528e,,version = 2014.2.1,,2,0
openstack%2Fproject-config~master~Ia109de2ffeb242847f964fb9b636572d84c4a2fd,openstack/project-config,master,Ia109de2ffeb242847f964fb9b636572d84c4a2fd,Don't run gate-{name}-pypy for stable/icehouse,MERGED,2014-10-16 18:20:06.000000000,2014-10-17 13:38:26.000000000,2014-10-16 19:15:56.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-16 18:20:06.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/64825eb98932db9357006e70dcc649db0fdf45b1', 'message': ""Don't run gate-{name}-pypy for stable/icehouse\n\n* zuul/layout.yaml: Since we're only supporting PyPy on Ubuntu\nTrusty but we're not supporting stable/icehouse on Ubuntu Trusty,\nwe're transitively also not supporting PyPy for stable/icehouse.\nBased on a review of the zuul layout, the only project I can find\nwith a stable/icehouse branch and gate-{name}-pypy jobs from the\npypy-jobs project template or otherwise is openstack/requirements.\n\nChange-Id: Ia109de2ffeb242847f964fb9b636572d84c4a2fd\n""}]",0,129014,64825eb98932db9357006e70dcc649db0fdf45b1,9,4,1,5263,,,0,"Don't run gate-{name}-pypy for stable/icehouse

* zuul/layout.yaml: Since we're only supporting PyPy on Ubuntu
Trusty but we're not supporting stable/icehouse on Ubuntu Trusty,
we're transitively also not supporting PyPy for stable/icehouse.
Based on a review of the zuul layout, the only project I can find
with a stable/icehouse branch and gate-{name}-pypy jobs from the
pypy-jobs project template or otherwise is openstack/requirements.

Change-Id: Ia109de2ffeb242847f964fb9b636572d84c4a2fd
",git fetch https://review.opendev.org/openstack/project-config refs/changes/14/129014/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,64825eb98932db9357006e70dcc649db0fdf45b1,requirements-jobs, - name: gate-requirements-pypy branch: ^(?!stable/icehouse).*$,,2,0
openstack%2Frequirements~stable%2Ficehouse~I00f66b0f3c8e9f688429ee78bd51608a4dcac140,openstack/requirements,stable/icehouse,I00f66b0f3c8e9f688429ee78bd51608a4dcac140,Add oslo.serialization for latest keystoneclient,ABANDONED,2014-10-16 08:35:34.000000000,2014-10-17 13:38:05.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1812}, {'_account_id': 1955}, {'_account_id': 5263}, {'_account_id': 6482}, {'_account_id': 6547}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-10-16 08:35:34.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f53c90c3400aeea992007799702e82eb3a4faa6e', 'message': 'Add oslo.serialization for latest keystoneclient\n\nKeystone tests run against keystoneclient master which added\na new dependecy on oslo.serialization\n\nChange-Id: I00f66b0f3c8e9f688429ee78bd51608a4dcac140\n'}]",0,128849,f53c90c3400aeea992007799702e82eb3a4faa6e,15,8,1,1955,,,0,"Add oslo.serialization for latest keystoneclient

Keystone tests run against keystoneclient master which added
a new dependecy on oslo.serialization

Change-Id: I00f66b0f3c8e9f688429ee78bd51608a4dcac140
",git fetch https://review.opendev.org/openstack/requirements refs/changes/49/128849/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,f53c90c3400aeea992007799702e82eb3a4faa6e,,# only for Keystone tests running against keystoneclient master oslo.serialization>=1.0.0 # Apache-2.0,,2,0
openstack%2Fhorizon~master~Ib880e2c975b7c2acc55112d250d9423f64a2a749,openstack/horizon,master,Ib880e2c975b7c2acc55112d250d9423f64a2a749,Containers page responsive,ABANDONED,2014-05-21 11:45:24.000000000,2014-10-17 13:36:38.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 8794}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-21 11:45:24.000000000', 'files': ['openstack_dashboard/static/dashboard/less/horizon.less', 'openstack_dashboard/static/dashboard/less/responsive.less'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b02b213a68b4f12b19a6682d924f8b0a1cb495b6', 'message': 'Containers page responsive\n\nTo improve the Object Storage page in small screen size, the table ""Objects"" should move below the ""Containers"" table with media queries.\n\nChanges are:\n\n+ Separate both tables (container and objects).\n+ Add footer below each tab and remove the current one.\n\nChange-Id: Ib880e2c975b7c2acc55112d250d9423f64a2a749\nImplements: blueprint containers-page-responsive\n'}]",1,94589,b02b213a68b4f12b19a6682d924f8b0a1cb495b6,7,4,1,8794,,,0,"Containers page responsive

To improve the Object Storage page in small screen size, the table ""Objects"" should move below the ""Containers"" table with media queries.

Changes are:

+ Separate both tables (container and objects).
+ Add footer below each tab and remove the current one.

Change-Id: Ib880e2c975b7c2acc55112d250d9423f64a2a749
Implements: blueprint containers-page-responsive
",git fetch https://review.opendev.org/openstack/horizon refs/changes/89/94589/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/static/dashboard/less/horizon.less', 'openstack_dashboard/static/dashboard/less/responsive.less']",2,b02b213a68b4f12b19a6682d924f8b0a1cb495b6,bp/containers-page-responsive,"/*---------------------------------------------------------------------------*/ /* Horizon Responsive /*---------------------------------------------------------------------------*/ /* Object Storage Page */ //ResourceBrowser @dataTableBorderWidth: 1px; @dataTableBorderColor: #DDD; @actionsColumnPadding: 10px; @smallButtonHeight: 28px; @tdHeight: @smallButtonHeight; @tableCellPadding: 8px; @contentTableWidth: 70%; @navigationTableWidth: 30%; @browserWrapperWidth: 100%; @media screen and (max-width: 1300px) { #browser_wrapper { width: 100%; background: none; border: none; div.navigation_wrapper, div.content_wrapper { width: 100%; thead, tr { border: 1px solid rgb(221, 221, 221); } thead { background-color: rgb(238, 238, 238); th.table_header, .breadcrumb_td { border-top: 1px solid rgb(221, 221, 221); border-left: 1px solid rgb(221, 221, 221); border-right: 1px solid rgb(221, 221, 221); } } div.table_search.client input { background-color: #fff; } } div.content_wrapper { margin-top: 21px; } div.tfoot { display: none; } } } @media screen and (min-width: 1300px) { #browser_wrapper { width: @browserWrapperWidth; min-width: 1000px; background-color: @grayLighter; border: @dataTableBorderWidth solid @dataTableBorderColor; .border-radius(4px); .tfoot { clear: both; padding: 8px; border-top: 1px solid @dataTableBorderColor; background-color: #F1F1F1; font-size: 11px; line-height: 14px; span { display: inline-block; &.navigation_table_count { width: @navigationTableWidth; } } } form, table{ margin-bottom: 0; } .navigation_wrapper, .content_wrapper{ position: relative; float: left; } div.navigation_wrapper { z-index: 10; width: @navigationTableWidth; div.table_wrapper, thead th.table_header { border-right: 0 none; border-top-right-radius: 0; } td { &:first-child { border-left: 0 none; } &.breadcrumb_td { padding-right: 0px; max-width: 200px; } } tr.current_selected td { background-color: #E9F5FA; } tfoot td { border-right: 0 none; border-bottom-right-radius: 0; } ul.breadcrumb { padding-right: 0px; border-top-right-radius: 0px; border-bottom-right-radius: 0px; border-right: none; white-space: nowrap; } tbody td { border-right: @dataTableBorderWidth solid @dataTableBorderColor; background-color: @white; } } div.content_wrapper { width: @contentTableWidth; div.table_wrapper, thead th.table_header { border-left: 0 none; border-top-left-radius: 0; } td{ border-bottom: @dataTableBorderWidth solid @dataTableBorderColor; &:last-child { border-right: 0 none; } &.breadcrumb_td { padding-left: 0px; } } tfoot td { border-left: 0 none; border-bottom-left-radius: 0; } /* FIXME(Ke Wu): for now there are two breadcrumb tr in both table * and this one in the content table is hidden. This hack is made to * fix the alignment of two table, needs a better solution in the * future. */ ul.breadcrumb { padding-left: 0px; border-top-left-radius: 0px; border-bottom-left-radius: 0px; border-left: none; li { visibility: hidden; } } } table { border-collapse: collapse; thead { tr th { border-bottom: none; background-color: @grayLighter; } } tbody { tr:last-child td { border-bottom: 1px solid #ddd; border-radius: 0; } tr.empty td { height: @tdHeight; padding: @actionsColumnPadding; } td.actions_column { position: static; } } } .breadcrumb{ padding: 6px; margin: 0 0 1px 0; } tfoot { display: none; } } } ",,188,142
openstack%2Fsahara~stable%2Fjuno~I7e0104b282cee155b18f62c87c5caa77b79762c6,openstack/sahara,stable/juno,I7e0104b282cee155b18f62c87c5caa77b79762c6,Opening stable/juno,MERGED,2014-10-16 15:00:09.000000000,2014-10-17 13:10:29.000000000,2014-10-17 13:10:28.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 9656}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-16 15:00:09.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/sahara/commit/a7031f66c258c0d1c11e0667599cb8a28ed79e7d', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I7e0104b282cee155b18f62c87c5caa77b79762c6\n'}]",0,128949,a7031f66c258c0d1c11e0667599cb8a28ed79e7d,20,10,1,308,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I7e0104b282cee155b18f62c87c5caa77b79762c6
",git fetch https://review.opendev.org/openstack/sahara refs/changes/49/128949/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,a7031f66c258c0d1c11e0667599cb8a28ed79e7d,stable-juno,version = 2014.2.1,version = 2014.2,2,1
openstack%2Fsecurity-doc~master~I491584713339b0c15d6505c84a5eb1e5d19cd1c1,openstack/security-doc,master,I491584713339b0c15d6505c84a5eb1e5d19cd1c1,Updated from openstack-manuals,MERGED,2014-10-17 12:38:42.000000000,2014-10-17 13:10:06.000000000,2014-10-17 13:10:05.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-17 12:38:42.000000000', 'files': ['glossary/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/ce743d70d079aea550ac5466b506811f755b8d43', 'message': 'Updated from openstack-manuals\n\nChange-Id: I491584713339b0c15d6505c84a5eb1e5d19cd1c1\n'}]",0,129227,ce743d70d079aea550ac5466b506811f755b8d43,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I491584713339b0c15d6505c84a5eb1e5d19cd1c1
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/27/129227/1 && git format-patch -1 --stdout FETCH_HEAD,['glossary/glossary-terms.xml'],1,ce743d70d079aea550ac5466b506811f755b8d43,openstack/openstack-manuals," <glossterm>federated identity</glossterm> <indexterm class=""singular""> <primary>federated identity</primary> </indexterm> <glossdef> <para>A method to establish trusts between identity providers and the OpenStack cloud.</para> </glossdef> </glossentry> <glossentry> <glossterm>identity provider</glossterm> <indexterm class=""singular""> <primary>identity provider</primary> <secondary>basics of</secondary> </indexterm> <glossdef> <para>A directory service, which allows users to login with a user name and password. It is a typical source of authentication tokens.</para> </glossdef> </glossentry> <glossentry> <glossterm>SAML assertion</glossterm> <indexterm class=""singular""> <primary>SAML assertion</primary> </indexterm> <glossdef> <para>Contains information about a user as provided by the identity provider. It is an indication that a user has been authenticated.</para> </glossdef> </glossentry> <glossentry> <glossterm>service provider</glossterm> <indexterm class=""singular""> <primary>service provider</primary> </indexterm> <glossdef> <para>A system that provides services to other system entities. In case of federated identity, OpenStack Identity is the service provider.</para> </glossdef> </glossentry> <glossentry>",,51,0
openstack%2Foperations-guide~master~Iba75dd6d8a64a4035407dc6c393d12a838da90bd,openstack/operations-guide,master,Iba75dd6d8a64a4035407dc6c393d12a838da90bd,Updated from openstack-manuals,MERGED,2014-10-17 12:38:39.000000000,2014-10-17 13:09:04.000000000,2014-10-17 13:09:03.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-17 12:38:39.000000000', 'files': ['doc/glossary/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/2a912d584dba5e4c6bccaac81e2c7e8827fe7dfc', 'message': 'Updated from openstack-manuals\n\nChange-Id: Iba75dd6d8a64a4035407dc6c393d12a838da90bd\n'}]",0,129226,2a912d584dba5e4c6bccaac81e2c7e8827fe7dfc,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Iba75dd6d8a64a4035407dc6c393d12a838da90bd
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/26/129226/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/glossary-terms.xml'],1,2a912d584dba5e4c6bccaac81e2c7e8827fe7dfc,openstack/openstack-manuals," <glossterm>federated identity</glossterm> <indexterm class=""singular""> <primary>federated identity</primary> </indexterm> <glossdef> <para>A method to establish trusts between identity providers and the OpenStack cloud.</para> </glossdef> </glossentry> <glossentry> <glossterm>identity provider</glossterm> <indexterm class=""singular""> <primary>identity provider</primary> <secondary>basics of</secondary> </indexterm> <glossdef> <para>A directory service, which allows users to login with a user name and password. It is a typical source of authentication tokens.</para> </glossdef> </glossentry> <glossentry> <glossterm>SAML assertion</glossterm> <indexterm class=""singular""> <primary>SAML assertion</primary> </indexterm> <glossdef> <para>Contains information about a user as provided by the identity provider. It is an indication that a user has been authenticated.</para> </glossdef> </glossentry> <glossentry> <glossterm>service provider</glossterm> <indexterm class=""singular""> <primary>service provider</primary> </indexterm> <glossdef> <para>A system that provides services to other system entities. In case of federated identity, OpenStack Identity is the service provider.</para> </glossdef> </glossentry> <glossentry>",,51,0
openstack%2Fha-guide~master~Ie40ae6c08af7f4310c156d5adc70e2b8287d0045,openstack/ha-guide,master,Ie40ae6c08af7f4310c156d5adc70e2b8287d0045,Updated from openstack-manuals,MERGED,2014-10-17 12:38:34.000000000,2014-10-17 13:08:17.000000000,2014-10-17 13:08:17.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-17 12:38:34.000000000', 'files': ['doc/glossary/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/327534fd916f9b05d23d37c2803f0e86183e69dc', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ie40ae6c08af7f4310c156d5adc70e2b8287d0045\n'}]",0,129225,327534fd916f9b05d23d37c2803f0e86183e69dc,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Ie40ae6c08af7f4310c156d5adc70e2b8287d0045
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/25/129225/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/glossary-terms.xml'],1,327534fd916f9b05d23d37c2803f0e86183e69dc,openstack/openstack-manuals," <glossterm>federated identity</glossterm> <indexterm class=""singular""> <primary>federated identity</primary> </indexterm> <glossdef> <para>A method to establish trusts between identity providers and the OpenStack cloud.</para> </glossdef> </glossentry> <glossentry> <glossterm>identity provider</glossterm> <indexterm class=""singular""> <primary>identity provider</primary> <secondary>basics of</secondary> </indexterm> <glossdef> <para>A directory service, which allows users to login with a user name and password. It is a typical source of authentication tokens.</para> </glossdef> </glossentry> <glossentry> <glossterm>SAML assertion</glossterm> <indexterm class=""singular""> <primary>SAML assertion</primary> </indexterm> <glossdef> <para>Contains information about a user as provided by the identity provider. It is an indication that a user has been authenticated.</para> </glossdef> </glossentry> <glossentry> <glossterm>service provider</glossterm> <indexterm class=""singular""> <primary>service provider</primary> </indexterm> <glossdef> <para>A system that provides services to other system entities. In case of federated identity, OpenStack Identity is the service provider.</para> </glossdef> </glossentry> <glossentry>",,51,0
openstack%2Fhorizon~master~Icf99fc2adec8d3a044cca4486f332593a91474fa,openstack/horizon,master,Icf99fc2adec8d3a044cca4486f332593a91474fa,Restrict the length of user name input,MERGED,2014-10-16 03:41:04.000000000,2014-10-17 13:00:34.000000000,2014-10-17 13:00:33.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 9317}, {'_account_id': 9622}, {'_account_id': 11592}, {'_account_id': 13161}]","[{'number': 1, 'created': '2014-10-16 03:41:04.000000000', 'files': ['openstack_dashboard/dashboards/identity/users/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a696e5992e58ac65240df5f226000705c3370365', 'message': 'Restrict the length of user name input\n\nWhen updating users, user name should not be greater than 255.\n\nChange-Id: Icf99fc2adec8d3a044cca4486f332593a91474fa\nCloses-Bug: #1279579\n'}]",3,128819,a696e5992e58ac65240df5f226000705c3370365,14,7,1,6610,,,0,"Restrict the length of user name input

When updating users, user name should not be greater than 255.

Change-Id: Icf99fc2adec8d3a044cca4486f332593a91474fa
Closes-Bug: #1279579
",git fetch https://review.opendev.org/openstack/horizon refs/changes/19/128819/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/identity/users/forms.py'],1,a696e5992e58ac65240df5f226000705c3370365,bug/1279579," name = forms.CharField(max_length=255, label=_(""User Name""))"," name = forms.CharField(label=_(""User Name""))",1,1
openstack%2Fmurano~proposed%2Fjuno~I090a44b8fc452786a204187f2d91a731d4e16816,openstack/murano,proposed/juno,I090a44b8fc452786a204187f2d91a731d4e16816,Add initial information about debugging,ABANDONED,2014-10-14 16:41:40.000000000,2014-10-17 12:53:11.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-10-14 16:41:40.000000000', 'files': ['doc/source/index.rst', 'doc/source/articles/debug_tips.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/6c014b961d6c8c80262ac96168b3faaeb17001e4', 'message': 'Add initial information about debugging\n\nThis patch adds initial version of article that\nintends to help with debugging Murano.\n\nChange-Id: I090a44b8fc452786a204187f2d91a731d4e16816\n'}]",0,128354,6c014b961d6c8c80262ac96168b3faaeb17001e4,6,2,1,7549,,,0,"Add initial information about debugging

This patch adds initial version of article that
intends to help with debugging Murano.

Change-Id: I090a44b8fc452786a204187f2d91a731d4e16816
",git fetch https://review.opendev.org/openstack/murano refs/changes/54/128354/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/articles/debug_tips.rst']",2,6c014b961d6c8c80262ac96168b3faaeb17001e4,update_docs,".. Copyright 2014 Mirantis, Inc. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. ===================================== Murano TroubleShooting and Debug Tips ===================================== During installation and setting environment of new projects you can run into different problems. This section intends to reduce the time spent on the solution of these problems. Problems during configuration ============================= Log location ++++++++++++ *Murano* is a multi component project, there several places where logs could be found. The location of the log file completely depends on the setting in the config file of the corresponding component. *log_file* parameter points to the log file, and if it's omitted or commented logging will be sent to stdout. Possible problem list +++++++++++++++++++++++ * `murano-db-manage` failed to execute * Check `connection` parameter in provided config file. It should be a `connection string <http://docs.sqlalchemy.org/en/rel_0_8/core/engines.html>`_. * Murano Dashboard is not working * Check that settings.py has custom Murano data. To add that data execute *update_settings.sh* script or use `horizon plugin <http://docs.openstack.org/developer/horizon/topics/settings.html#pluggable-settings>`_ Note, that even if settings.py contains Murano data, the file could be outdated. *update_settings.sh* script could synchronize settings with horizon master. * Check, that dashboard is not inserted twice in the settings file and as a plugin. Problems during deployment ========================== Besides identifying errors from log files, there is another and more flexible way to browse deployment errors - directly from UI. After *Deploy Failed* status is appeared navigate to environment components and open *Deployment History* page. Click on the *Show details* button located at the corresponding deployment row of the table. Then go to the *Logs* tab. You can see steps of the deployments and the one that failed would have red color. * Deployment freeze after ``Begin execution: io.murano.system.Agent.call`` problem with connection between Murano Agent and spawned instance. * Need to check transport access to the virtual machine (check router has gateway). * Check for rabbitMq settings: verify that agent has been obtained valid rabbit parameters. Go to the spawned virtual machine and open */etc/murano/agent.conf* or *C:\Murano\Agent\agent.conf* on Windows-based machine. Also, you can examine agent logs, located by default at */var/log/murano-agent.log* The first part of the log file will contain reconnection attempts to the rabbit - since the valid rabbit address and queue have not been obtained yet. * Check that *notification_driver* option is set to `messagingv2` * Check that linux image name is not starts with 'w' letter * ``[exceptions.EnvironmentError]: Unexpected stack state NOT_FOUND`` - problem with heat stack creation, need to examine Heat log file. If you are running the deployment on new tenant check that router exists and it has gateway to the external network. * ``Router could not be created, no external network found`` - Find `external_network` parameter in config file and check that specified external network is really exist via UI or by executiong `neutron net-external-list` cimmand. * ``NoPackageForClassFound: Package for class io.murano.Environment is not found`` - Check that murano core package is uploaded. If no, the content of `meta/io.murano` folder should be zipped and uploaded to Murano.",,74,0
openstack%2Ffuel-specs~master~I13816f8019924d9e5965bf5a83da53294efa91d1,openstack/fuel-specs,master,I13816f8019924d9e5965bf5a83da53294efa91d1,blueprint: vcenter-vlan-manager,MERGED,2014-10-06 11:43:00.000000000,2014-10-17 12:52:40.000000000,2014-10-17 12:52:39.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8935}, {'_account_id': 10136}, {'_account_id': 11118}, {'_account_id': 11163}, {'_account_id': 11427}, {'_account_id': 12141}, {'_account_id': 12415}, {'_account_id': 13082}, {'_account_id': 13306}]","[{'number': 1, 'created': '2014-10-06 11:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/bf8857aa683a90f5e459beec71a7f9950182ebfc', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 2, 'created': '2014-10-06 11:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/65609a5af0db7bc60c7125ea9df86ca31a5929f7', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 3, 'created': '2014-10-06 15:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/127f4b2db9c38520b717949394fb65f04044547a', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 4, 'created': '2014-10-06 15:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/51bad1394a6d1b3dee4bde316e7cae3e844f88ff', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 5, 'created': '2014-10-08 16:46:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/ac7e8e8dda2be8ff78acad949ca0874e298178ae', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 6, 'created': '2014-10-08 16:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/e6b446a2bbdf32e5423cce0552cd23dde54d1f61', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 7, 'created': '2014-10-09 09:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/0e0771ca0356cfc40c81a8bc47ddf94b316ef40d', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 8, 'created': '2014-10-09 09:07:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/376ee615cc9babce4f2fa1098ccd63d931319137', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 9, 'created': '2014-10-09 09:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/8246b888b31af7f377cabd78ab4268ede95af028', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 10, 'created': '2014-10-13 11:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/17ad2b211f0c85f140538a6d6d7bd280576df4b7', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 11, 'created': '2014-10-13 11:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/b34521fb574b0a05f6336192f3e6bc20f45f060a', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 12, 'created': '2014-10-15 14:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/73562ffa9d9aec3daaa70ea45c55dea6f977bfde', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 13, 'created': '2014-10-15 14:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/4633ac4cf589cc55de4249d9364527e6efeb2459', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 14, 'created': '2014-10-15 14:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/d9f7cc408a27e3e78c82149db527e2719eac2e7f', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}, {'number': 15, 'created': '2014-10-15 14:48:56.000000000', 'files': ['specs/6.0/vcenter-vlan-manager.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/f60f7f13b7aea4e8ff2027300987173be189b313', 'message': 'blueprint: vcenter-vlan-manager\n\nChange-Id: I13816f8019924d9e5965bf5a83da53294efa91d1\n'}]",61,126268,f60f7f13b7aea4e8ff2027300987173be189b313,59,13,15,12199,,,0,"blueprint: vcenter-vlan-manager

Change-Id: I13816f8019924d9e5965bf5a83da53294efa91d1
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/68/126268/10 && git format-patch -1 --stdout FETCH_HEAD,['specs/6.0/vcenter-vlan-manager.rst'],1,bf8857aa683a90f5e459beec71a7f9950182ebfc,bp/vcenter-vlan-manager,"========================================== VLAN manager support for vCenter ========================================== https://blueprints.launchpad.net/fuel/+spec/vcenter-vlan-manager Now, in a 5.0 and 5.1 releases Fuel doesn't support Nova-Network in VLANmanager mode for vCenter as a hypervisor. We want to add this feature in Fuel 6.0. Problem description =================== Now only FlatDHCPManager (among nova networks mode) works properly with vCenter. In this case all virtual machines (even used by different tenants) be contained in one L2 broadcast domain. Also only one pool of ip adresses used for all tenants. It is a problem for security and scalability. Proposed change =============== There are some changes must be implement for full support VlanManager: * Deblock 'VLAN Manager' --- element of UI in 'Network Settings' tab for choosing this variant of networking mode. * Teach nova go to vCenter and make portgroup in it when nova create new vlan. Alternatives ------------ We could use VlanManager without full igtegration with vCenter. For it all vlan networks in OpenStack deployment and all portgroups in vCenter's distribution switch must be created manually. As it works for John Deere's deployment. Data model impact ----------------- None REST API impact --------------- None Upgrade impact -------------- Maybe additional packages will be installed for interaction with vCenter. Security impact --------------- Because in this mode virtual machines from different tenants works in different L2 segments, security of environment will be increased by this changes. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: gcon-monolake Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ None Testing ======= Doesn't need special methods of test for this. We must use ostf tests for network connectivities which we use for testing VlanManager with qemu hypervisor. Documentation Impact ==================== None References ========== None ",,124,0
openstack%2Fnova~master~I079f767ad1c4e966c22d6722c0dfea6d5f35c54d,openstack/nova,master,I079f767ad1c4e966c22d6722c0dfea6d5f35c54d,Makes the host aggregate functionality work with cells,ABANDONED,2013-04-01 11:58:26.000000000,2014-10-17 12:46:31.000000000,,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1501}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2468}, {'_account_id': 3031}, {'_account_id': 4419}, {'_account_id': 6992}, {'_account_id': 13530}]","[{'number': 1, 'created': '2013-04-01 11:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe27ff3ededc7a92fc3e5ea4392d4482eef169cd', 'message': 'Make the host aggregate functionality work with cells\n\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 2, 'created': '2013-04-02 22:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7608ca74a356250c594fb272e425f66b8bc68b5e', 'message': 'Make the host aggregate functionality work with cells\n\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 3, 'created': '2013-04-08 07:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c208f7889209e8160b58248d97cc5506d945ef4', 'message': 'Make the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in the nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone):\n     * get_aggregate(self, ctxt, aggregate_id):\n     * get_aggregate_list(self, ctxt, cell=None):\n     * update_aggregate(self, ctxt, aggregate_id, values):\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata):\n     * delete_aggregate(self, ctxt, aggregate_id):\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name):\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name):\n\n == YET TO DO: ==\n\n * Tests for nova.cells.manager\n * Make get_aggregate_list work in Broadcast mode\n\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 4, 'created': '2013-04-08 14:27:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee2a21f69b83f9826dca31a90e96ca810c48405d', 'message': 'Make the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in the nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone):\n     * get_aggregate(self, ctxt, aggregate_id):\n     * get_aggregate_list(self, ctxt, cell=None):\n     * update_aggregate(self, ctxt, aggregate_id, values):\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata):\n     * delete_aggregate(self, ctxt, aggregate_id):\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name):\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name):\n\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 8, 'created': '2013-04-08 19:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/04d6955fd9d7d9a536cae17002aeed995d5d3919', 'message': 'Make the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in the nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone)\n     * get_aggregate(self, ctxt, aggregate_id)\n     * get_aggregate_list(self, ctxt, cell=None)\n     * update_aggregate(self, ctxt, aggregate_id, values)\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata)\n     * delete_aggregate(self, ctxt, aggregate_id)\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name)\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name)\n\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 7, 'created': '2013-04-08 19:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/35d3a1eee426401dc236aa07fb8966c726bc97c3', 'message': 'Make the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in the nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone)\n     * get_aggregate(self, ctxt, aggregate_id)\n     * get_aggregate_list(self, ctxt, cell=None)\n     * update_aggregate(self, ctxt, aggregate_id, values)\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata)\n     * delete_aggregate(self, ctxt, aggregate_id)\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name)\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name)\n\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 6, 'created': '2013-04-08 19:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/99f150fbba52db9a58cde56df4d2546beb6fc886', 'message': 'Make the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in the nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone)\n     * get_aggregate(self, ctxt, aggregate_id)\n     * get_aggregate_list(self, ctxt, cell=None)\n     * update_aggregate(self, ctxt, aggregate_id, values)\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata)\n     * delete_aggregate(self, ctxt, aggregate_id)\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name)\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name)\n\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 5, 'created': '2013-04-08 19:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a6d7223b9b5aff5b814ddf03c6d1e436faece129', 'message': 'Make the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in the nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone)\n     * get_aggregate(self, ctxt, aggregate_id)\n     * get_aggregate_list(self, ctxt, cell=None)\n     * update_aggregate(self, ctxt, aggregate_id, values)\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata)\n     * delete_aggregate(self, ctxt, aggregate_id)\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name)\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name)\n\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 9, 'created': '2013-05-27 15:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8aa978949a59bc26a5dcc1fca3488ab11a58ac08', 'message': 'Make the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in the nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone)\n     * get_aggregate(self, ctxt, aggregate_id)\n     * get_aggregate_list(self, ctxt, cell=None)\n     * update_aggregate(self, ctxt, aggregate_id, values)\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata)\n     * delete_aggregate(self, ctxt, aggregate_id)\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name)\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name)\n\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 10, 'created': '2013-06-03 14:21:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a81280427f8a7c19ee65bb5c856c4d8795edeae', 'message': 'Make the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in the nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone)\n     * get_aggregate(self, ctxt, aggregate_id)\n     * get_aggregate_list(self, ctxt, cell=None)\n     * update_aggregate(self, ctxt, aggregate_id, values)\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata)\n     * delete_aggregate(self, ctxt, aggregate_id)\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name)\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name)\n\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 11, 'created': '2013-06-05 13:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a994ff0713fcabd543713a8473315a456ebea60b', 'message': 'Makes the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone)\n     * get_aggregate(self, ctxt, aggregate_id)\n     * get_aggregate_list(self, ctxt, cell=None)\n     * update_aggregate(self, ctxt, aggregate_id, values)\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata)\n     * delete_aggregate(self, ctxt, aggregate_id)\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name)\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name)\n + It increments the cells_api version from 1.8 to 1.9\n\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 12, 'created': '2013-06-06 13:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf3aa61332cb25d9245790af694723877457b4a9', 'message': 'Makes the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone)\n     * get_aggregate(self, ctxt, aggregate_id)\n     * get_aggregate_list(self, ctxt, cell=None)\n     * update_aggregate(self, ctxt, aggregate_id, values)\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata)\n     * delete_aggregate(self, ctxt, aggregate_id)\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name)\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name)\n + It increments the cells_api version from 1.9 to 1.10\n\nblueprint cells-aggregate-support\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 13, 'created': '2013-06-11 04:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3b73e4fdb1c68ec5cac8872810b5fe6536dd568e', 'message': 'Makes the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone)\n     * get_aggregate(self, ctxt, aggregate_id)\n     * get_aggregate_list(self, ctxt, cell=None)\n     * update_aggregate(self, ctxt, aggregate_id, values)\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata)\n     * delete_aggregate(self, ctxt, aggregate_id)\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name)\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name)\n + It increments the cells_api version from 1.9 to 1.10\n\nblueprint cells-aggregate-support\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 15, 'created': '2013-06-12 13:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f6a480794d9ffb293e4ba1ccfbdff10c25de266', 'message': 'Makes the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone)\n     * get_aggregate(self, ctxt, aggregate_id)\n     * get_aggregate_list(self, ctxt, cell=None)\n     * update_aggregate(self, ctxt, aggregate_id, values)\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata)\n     * delete_aggregate(self, ctxt, aggregate_id)\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name)\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name)\n + It increments the cells_api version from 1.9 to 1.10\n\nblueprint cells-aggregate-support\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 14, 'created': '2013-06-12 13:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/468021b0ddf2cf17304b35180d16a46751379ee4', 'message': 'Makes the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone)\n     * get_aggregate(self, ctxt, aggregate_id)\n     * get_aggregate_list(self, ctxt, cell=None)\n     * update_aggregate(self, ctxt, aggregate_id, values)\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata)\n     * delete_aggregate(self, ctxt, aggregate_id)\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name)\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name)\n + It increments the cells_api version from 1.9 to 1.10\n\nblueprint cells-aggregate-support\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}, {'number': 16, 'created': '2013-08-28 15:37:50.000000000', 'files': ['nova/api/openstack/compute/contrib/aggregates.py', 'nova/tests/compute/test_compute_cells.py', 'nova/cells/manager.py', 'nova/compute/cells_api.py', 'nova/tests/cells/test_cells_rpcapi.py', 'nova/cells/utils.py', 'nova/tests/cells/test_cells_messaging.py', 'nova/compute/__init__.py', 'nova/tests/cells/test_cells_manager.py', 'nova/cells/messaging.py', 'nova/cells/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a1474945c56517c618c63ccf869f76459439bd95', 'message': 'Makes the host aggregate functionality work with cells\n\n + In the openstack api, it moves database access and other\n   functionality to the nova.compute layer\n + It adds support for aggregates in nova.compute.cells_api\n + It adds the following host aggregate related functions to the cells\n   rpcapi and messaging systems:\n     * create_aggregate(self, ctxt, aggregate_name, availability_zone)\n     * get_aggregate(self, ctxt, aggregate_id)\n     * get_aggregate_list(self, ctxt, cell=None)\n     * update_aggregate(self, ctxt, aggregate_id, values)\n     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata)\n     * delete_aggregate(self, ctxt, aggregate_id)\n     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name)\n     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name)\n + It increments the cells_api version from 1.19 to 1.20\n\nblueprint cells-aggregate-support\nChange-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d\n'}]",8,25813,a1474945c56517c618c63ccf869f76459439bd95,79,10,16,4419,,,0,"Makes the host aggregate functionality work with cells

 + In the openstack api, it moves database access and other
   functionality to the nova.compute layer
 + It adds support for aggregates in nova.compute.cells_api
 + It adds the following host aggregate related functions to the cells
   rpcapi and messaging systems:
     * create_aggregate(self, ctxt, aggregate_name, availability_zone)
     * get_aggregate(self, ctxt, aggregate_id)
     * get_aggregate_list(self, ctxt, cell=None)
     * update_aggregate(self, ctxt, aggregate_id, values)
     * update_aggregate_metadata(self, ctxt, aggregate_id, metadata)
     * delete_aggregate(self, ctxt, aggregate_id)
     * add_host_to_aggregate(self, ctxt, aggregate_id, host_name)
     * remove_host_from_aggregate(self, ctxt, aggregate_id, host_name)
 + It increments the cells_api version from 1.19 to 1.20

blueprint cells-aggregate-support
Change-Id: I079f767ad1c4e966c22d6722c0dfea6d5f35c54d
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/25813/11 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/aggregates.py', 'nova/cells/manager.py', 'nova/compute/cells_api.py', 'nova/tests/cells/test_cells_rpcapi.py', 'nova/compute/__init__.py', 'nova/tests/cells/test_cells_manager.py', 'nova/cells/messaging.py', 'nova/scheduler/filters/spare_zone_filter.py', 'nova/cells/rpcapi.py']",9,fe27ff3ededc7a92fc3e5ea4392d4482eef169cd,bp/cells-aggregate-support," 1.8 - Adds create_aggregate(), get_aggregate(), get_aggregate_list(), update_aggregate(), update_aggregate_metadata(), delete_aggregate(), add_host_to_aggregate(), remove_host_from_aggregate(), def create_aggregate(self, ctxt, cell_name, aggregate_name, availability_zone): return self.call(ctxt, self.make_msg('create_aggregate', cell_name=cell_name, aggregate_name=aggregate_name, availability_zone=availability_zone), version='1.8') def get_aggregate(self, ctxt, cell_name, aggregate_id): return self.call(ctxt, self.make_msg('get_aggregate', cell_name=cell_name, aggregate_id=aggregate_id), version='1.8') def get_aggregate_list(self, ctxt, cell=None): return self.call(ctxt, self.make_msg('get_aggregate_list', cell_name=cell), version='1.8') def update_aggregate(self, ctxt, cell_name, aggregate_id, values): return self.call(ctxt, self.make_msg('update_aggregate', cell_name, aggregate_id=aggregate_id, values=values), version='1.8') def update_aggregate_metadata(self, ctxt, cell_name, aggregate_id, metadata): return self.call(ctxt, self.make_msg('update_aggregate_metadata', cell_name=cell_name, aggregate_id=aggregate_id, metadata=metadata), version='1.8') def delete_aggregate(self, ctxt, cell_name, aggregate_id): self.cast(ctxt, self.make_msg('delete_aggregate', cell_name=cell_name, aggregate_id=aggregate_id), version='1.8') def add_host_to_aggregate(self, ctxt, cell_name, aggregate_id, host_name): return self.call(ctxt, self.make_msg('add_host_to_aggregate', cell_name=cell_name, aggregate_id=aggregate_id, host_name=host_name), version='1.8') def remove_host_from_aggregate(self, ctxt, cell_name, aggregate_id, host_name): return self.call(ctxt, self.make_msg('remove_host_from_aggregate', cell_name=cell_name, aggregate_id=aggregate_id, host_name=host_name), version='1.8')",,389,2
openstack%2Ffuel-library~master~I6a2c773ada74bdd3ce02c546aa86773d519ca3e7,openstack/fuel-library,master,I6a2c773ada74bdd3ce02c546aa86773d519ca3e7,Increase settings for dnsmasq and sysctl,ABANDONED,2014-10-16 14:42:35.000000000,2014-10-17 12:39:08.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 9546}, {'_account_id': 12867}]","[{'number': 1, 'created': '2014-10-16 14:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cca1226e6073dee4ae549e409626f3fc1008aaef', 'message': 'Increase settings for dnsmasq and sysctl\n\n* Make a new variable dhcp_lease_max. It increases the default lease\n  time from 1000 to 1800. It allows to provision nodes on scale, when\n  Debian Installer or Anakonda looses IP in the middle of install\n* Add cache-size to dnsmasq template. dnsmasq will keep more entries in\n  case.\n* Increased neighbour table on master node to keep more ARP requests\n  that come in parallel once deployment is started. This change also\n  removes unneed broadcast traffic. New values are:\n  net.ipv4.neigh.default.gc_thresh1 = 256\n  net.ipv4.neigh.default.gc_thresh2 = 1024\n  net.ipv4.neigh.default.gc_thresh1 = 2048\n* Fix linting for server.pp\n\nDocImpact\n\nChange-Id: I6a2c773ada74bdd3ce02c546aa86773d519ca3e7\n'}, {'number': 2, 'created': '2014-10-16 14:50:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c46db6adc0c73525435e569662836a496aa06e1b', 'message': 'Increase settings for dnsmasq and sysctl\n\n* Make a new variable dhcp_lease_max. It increases the default lease\n  time from 1000 to 1800. It allows to provision nodes on scale, when\n  Debian Installer or Anaconda looses IP in the middle of install\n* Add cache-size to dnsmasq template. dnsmasq will keep more entries in\n  case.\n* Increased neighbour table on master node to keep more ARP requests\n  that come in parallel once deployment is started. This change also\n  removes unneed broadcast traffic. New values are:\n  net.ipv4.neigh.default.gc_thresh1 = 256\n  net.ipv4.neigh.default.gc_thresh2 = 1024\n  net.ipv4.neigh.default.gc_thresh1 = 2048\n* Fix linting for server.pp\n\nRelated-Bug: #1376680\nRelated-Bug: #1379917\nblueprint 100-nodes-support\nDocImpact\n\nChange-Id: I6a2c773ada74bdd3ce02c546aa86773d519ca3e7\n'}, {'number': 3, 'created': '2014-10-16 15:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f48f49460cf384fd289a4303e251605c9aec378d', 'message': 'Increase settings for dnsmasq and sysctl\n\n* Make a new variable dhcp_lease_max. It increases the default lease\n  time from 1000 to 1800. It allows to provision nodes on scale, when\n  Debian Installer or Anaconda looses IP in the middle of install\n* Add cache-size to dnsmasq template. dnsmasq will keep more entries in\n  case.\n* Increased neighbour table on master node to keep more ARP requests\n  that come in parallel once deployment is started. This change also\n  removes unneed broadcast traffic. New values are:\n  net.ipv4.neigh.default.gc_thresh1 = 256\n  net.ipv4.neigh.default.gc_thresh2 = 1024\n  net.ipv4.neigh.default.gc_thresh1 = 2048\n* Fix linting for server.pp\n\nRelated-Bug: #1376680\nRelated-Bug: #1379917\nblueprint 100-nodes-support\nDocImpact\n\nChange-Id: I6a2c773ada74bdd3ce02c546aa86773d519ca3e7\n'}, {'number': 4, 'created': '2014-10-16 15:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bfc70eebe4d06efdd1fb800aab60abb141e8c28d', 'message': 'Increase settings for dnsmasq and sysctl\n\n* Make a new variable dhcp_lease_max. It increases the number of\n  available leases from 1000 to 1800. It allows to provision nodes on\n  scale, when Debian Installer or Anaconda looses IP in the middle of\n  install.\n* Make a new variable lease_time. It increases the default lease size\n  to 120m, up from the default 60m.\n* Add cache-size to dnsmasq template. dnsmasq will keep more entries in\n  case.\n* Increased neighbour table on master node to keep more ARP requests\n  that come in parallel once deployment is started. This change also\n  removes unneed broadcast traffic. New values are:\n  net.ipv4.neigh.default.gc_thresh1 = 256\n  net.ipv4.neigh.default.gc_thresh2 = 1024\n  net.ipv4.neigh.default.gc_thresh1 = 2048\n* Fix linting for server.pp\n\nRelated-Bug: #1376680\nRelated-Bug: #1379917\nblueprint 100-nodes-support\nDocImpact\n\nChange-Id: I6a2c773ada74bdd3ce02c546aa86773d519ca3e7\n'}, {'number': 5, 'created': '2014-10-17 10:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b8a5ffa585753d10c4a30acd5fe41d09ea43e975', 'message': 'Increase settings for dnsmasq and sysctl\n\n* Make a new variable dhcp_lease_max. It increases the number of\n  available leases from 1000 to 1800. It allows to provision nodes on\n  scale, when Debian Installer or Anaconda looses IP in the middle of\n  install.\n* Make a new variable lease_time. It increases the default lease size\n  to 120m, up from the default 60m.\n* Add cache-size to dnsmasq template. dnsmasq will keep more entries in\n  case.\n* Increased neighbour table on master node to keep more ARP requests\n  that come in parallel once deployment is started. This change also\n  removes unneed broadcast traffic. New values are:\n  net.ipv4.neigh.default.gc_thresh1 = 256\n  net.ipv4.neigh.default.gc_thresh2 = 1024\n  net.ipv4.neigh.default.gc_thresh3 = 2048\n* Fix linting for server.pp\n\nRelated-Bug: #1376680\nRelated-Bug: #1379917\nRelated-Bug: #1381997\nblueprint 100-nodes-support\nDocImpact\n\nChange-Id: I6a2c773ada74bdd3ce02c546aa86773d519ca3e7\n'}, {'number': 6, 'created': '2014-10-17 10:53:23.000000000', 'files': ['deployment/puppet/cobbler/manifests/server.pp', 'deployment/puppet/cobbler/templates/dnsmasq.template.erb', 'deployment/puppet/nailgun/manifests/host.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/307ee9b30440640facced569c99b0f9dc4e368c3', 'message': 'Increase settings for dnsmasq and sysctl\n\n* Make a new variable dhcp_lease_max. It increases the number of\n  available leases from 1000 to 1800. It allows to provision nodes on\n  scale, when Debian Installer or Anaconda looses IP in the middle of\n  install.\n* Make a new variable lease_time. It increases the default lease size\n  to 120m, up from the default 60m.\n* Add cache-size to dnsmasq template. dnsmasq will keep more entries in\n  case.\n* Increased neighbour table on master node to keep more ARP requests\n  that come in parallel once deployment is started. This change also\n  removes unneed broadcast traffic. New values are:\n  net.ipv4.neigh.default.gc_thresh1 = 256\n  net.ipv4.neigh.default.gc_thresh2 = 1024\n  net.ipv4.neigh.default.gc_thresh3 = 2048\n* Fix linting for server.pp\n\nRelated-Bug: #1376680\nRelated-Bug: #1379917\nRelated-Bug: 1381997\nblueprint 100-nodes-support\nDocImpact\n\nChange-Id: I6a2c773ada74bdd3ce02c546aa86773d519ca3e7\n'}]",5,128939,307ee9b30440640facced569c99b0f9dc4e368c3,42,8,6,11090,,,0,"Increase settings for dnsmasq and sysctl

* Make a new variable dhcp_lease_max. It increases the number of
  available leases from 1000 to 1800. It allows to provision nodes on
  scale, when Debian Installer or Anaconda looses IP in the middle of
  install.
* Make a new variable lease_time. It increases the default lease size
  to 120m, up from the default 60m.
* Add cache-size to dnsmasq template. dnsmasq will keep more entries in
  case.
* Increased neighbour table on master node to keep more ARP requests
  that come in parallel once deployment is started. This change also
  removes unneed broadcast traffic. New values are:
  net.ipv4.neigh.default.gc_thresh1 = 256
  net.ipv4.neigh.default.gc_thresh2 = 1024
  net.ipv4.neigh.default.gc_thresh3 = 2048
* Fix linting for server.pp

Related-Bug: #1376680
Related-Bug: #1379917
Related-Bug: 1381997
blueprint 100-nodes-support
DocImpact

Change-Id: I6a2c773ada74bdd3ce02c546aa86773d519ca3e7
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/39/128939/3 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/cobbler/manifests/server.pp', 'deployment/puppet/cobbler/templates/dnsmasq.template.erb', 'deployment/puppet/nailgun/manifests/host.pp']",3,cca1226e6073dee4ae549e409626f3fc1008aaef,bug/1381997," owner => 'root', owner => 'root', file { ""/etc/dhcp/dhcp-enter-hooks"": content => template(""nailgun/dhcp-enter-hooks.erb""), owner => 'root', group => 'root', mode => '0755', } file { ""/etc/resolv.conf"": content => template(""nailgun/resolv.conf.erb""), owner => 'root', group => 'root', mode => '0644', sysctl::value{'kernel.printk': value => '4 1 1 7'} #Increase values for neighbour table sysctl::value{'net.ipv4.neigh.default.gc_thresh1': value => '256'} sysctl::value{'net.ipv4.neigh.default.gc_thresh2': value => '1024'} sysctl::value{'net.ipv4.neigh.default.gc_thresh3': value => '2048'}"," owner => 'root', owner => 'root', file { ""/etc/dhcp/dhcp-enter-hooks"": content => template(""nailgun/dhcp-enter-hooks.erb""), owner => 'root', group => 'root', mode => '0755', } file { ""/etc/resolv.conf"": content => template(""nailgun/resolv.conf.erb""), owner => 'root', group => 'root', mode => '0644', sysctl::value{'kernel.printk': value=>'4 1 1 7'}",93,72
openstack%2Fproject-config~master~I1fb4d58a36c9a12f87527f4fb551f4b664c386bd,openstack/project-config,master,I1fb4d58a36c9a12f87527f4fb551f4b664c386bd,Allow non standard docker-py in check-tempest-dsvm-f20-docker,MERGED,2014-10-16 18:27:58.000000000,2014-10-17 12:27:56.000000000,2014-10-17 12:27:55.000000000,"[{'_account_id': 3}, {'_account_id': 6316}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-10-16 18:27:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/714fbe1fc171a1de2a7c49cb629d704b9ff3b01f', 'message': ""Allow non standard docker-py in nova-docker dsvm jobs\n\nWe are investigating the use of docker-py to get rid of a custom\nhttp client and switch to a standard library docker-maintained\nby docker folks. So we need these dsvm jobs at the very least\nto see what works and what doesn't and how much regression we have\n\nReview against nova-docker:\nI3e17924b8319720ceb7cee480a81e953b809d0ee\n\nReview for docker-py in global requirements:\nI3100ad32a1cb414033a3aee495ddd6b82e6af268\n\nChange-Id: I1fb4d58a36c9a12f87527f4fb551f4b664c386bd\n""}, {'number': 2, 'created': '2014-10-16 23:39:36.000000000', 'files': ['jenkins/jobs/nova-docker.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/25bb27f6ff63d9a1a4d9e66fe659d1a01bff661f', 'message': ""Allow non standard docker-py in check-tempest-dsvm-f20-docker\n\nWe are investigating the use of docker-py to get rid of a custom\nhttp client and switch to a standard library docker-maintained\nby docker folks. So we need these dsvm jobs at the very least\nto see what works and what doesn't and how much regression we have\n\nThere are 2 dsvm jobs for nova-docker, we are making the change\nof switching on NON_STANDARD_REQS only for the f20 one. As we\njust need data points to make sure we are not regressing the\nnova-docker driver as compared to existing functionality in the\nreview mentioned below. Best case scenario, switching on the\nflag works as advertised and the requirements check will not\nfail the dsvm job at the point it is failing now. Worst case\nscenario the flag has no effect and we can delete the line\nflag at that point.\n\nReview against nova-docker:\nI3e17924b8319720ceb7cee480a81e953b809d0ee\n\nReview for docker-py in global requirements:\nI3100ad32a1cb414033a3aee495ddd6b82e6af268\n\nChange-Id: I1fb4d58a36c9a12f87527f4fb551f4b664c386bd\n""}]",0,129015,25bb27f6ff63d9a1a4d9e66fe659d1a01bff661f,11,3,2,5638,,,0,"Allow non standard docker-py in check-tempest-dsvm-f20-docker

We are investigating the use of docker-py to get rid of a custom
http client and switch to a standard library docker-maintained
by docker folks. So we need these dsvm jobs at the very least
to see what works and what doesn't and how much regression we have

There are 2 dsvm jobs for nova-docker, we are making the change
of switching on NON_STANDARD_REQS only for the f20 one. As we
just need data points to make sure we are not regressing the
nova-docker driver as compared to existing functionality in the
review mentioned below. Best case scenario, switching on the
flag works as advertised and the requirements check will not
fail the dsvm job at the point it is failing now. Worst case
scenario the flag has no effect and we can delete the line
flag at that point.

Review against nova-docker:
I3e17924b8319720ceb7cee480a81e953b809d0ee

Review for docker-py in global requirements:
I3100ad32a1cb414033a3aee495ddd6b82e6af268

Change-Id: I1fb4d58a36c9a12f87527f4fb551f4b664c386bd
",git fetch https://review.opendev.org/openstack/project-config refs/changes/15/129015/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/nova-docker.yaml'],1,714fbe1fc171a1de2a7c49cb629d704b9ff3b01f,, export NON_STANDARD_REQS=1 export NON_STANDARD_REQS=1,,2,0
openstack%2Fmagnetodb~master~Ic644bad58015348c057c5f3d6b55f21346daccf1,openstack/magnetodb,master,Ic644bad58015348c057c5f3d6b55f21346daccf1,Fixes logging_sample.conf,MERGED,2014-10-16 20:41:34.000000000,2014-10-17 12:27:26.000000000,2014-10-17 12:27:25.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8491}, {'_account_id': 8863}, {'_account_id': 11006}]","[{'number': 1, 'created': '2014-10-16 20:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/101497d97e4f4fd48539181f12c6f2f015bd49c0', 'message': ""Fixes logging.conf.sample\n\nLogging conf sample did not contain any loggers\nexcept 'root'. This configuration did not allow\nto operate internal logs of magnetodb service.\n\nCloses-bug: #1382223\nChange-Id: Ic644bad58015348c057c5f3d6b55f21346daccf1\n""}, {'number': 2, 'created': '2014-10-16 20:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/161f84f3ffa9389c1d9f6ecb4bea1d77a796d47f', 'message': ""Fixes logging.conf.sample\n\nLogging conf sample did not contain any loggers\nexcept 'root'. This configuration did not allow\nto operate internal logs of magnetodb service.\n\nCloses-bug: #1382223\nChange-Id: Ic644bad58015348c057c5f3d6b55f21346daccf1\n""}, {'number': 3, 'created': '2014-10-17 01:30:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/222feab92e64bbd7a03ac7bb282660dc38591946', 'message': ""Fixes logging.conf.sample\n\nLogging conf sample did not contain any loggers\nexcept 'root'. This configuration did not allow\nto operate internal logs of magnetodb service.\n\nCloses-bug: #1382223\nCloses-bug: #1381983\nChange-Id: Ic644bad58015348c057c5f3d6b55f21346daccf1\n""}, {'number': 4, 'created': '2014-10-17 10:02:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/c1a526f983d449571d16fc6f7347d8fc5897333f', 'message': ""Fixes logging.conf.sample\n\nLogging conf sample did not contain any loggers\nexcept 'root'. This configuration did not allow\nto operate internal logs of magnetodb service.\n\nCloses-bug: #1382223\nCloses-bug: #1381983\nChange-Id: Ic644bad58015348c057c5f3d6b55f21346daccf1\n""}, {'number': 5, 'created': '2014-10-17 10:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/83802b736b7087735c817da8d2da5078262d81c3', 'message': ""Fixes logging_sample.conf\n\nLogging conf sample did not contain any loggers\nexcept 'root'. This configuration did not allow\nto operate internal logs of magnetodb service.\n\nCloses-bug: #1382223\nCloses-bug: #1381983\nChange-Id: Ic644bad58015348c057c5f3d6b55f21346daccf1\n""}, {'number': 6, 'created': '2014-10-17 11:00:40.000000000', 'files': ['etc/logging_sample.conf', 'etc/logging.conf.sample', 'etc/magnetodb-async-task-executor.conf', 'etc/magnetodb-api.conf', 'etc/magnetodb-streaming-api.conf'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/661628b90ba1ea3b8f9ddc159f563f49e2ebaffd', 'message': ""Fixes logging_sample.conf\n\nLogging conf sample did not contain any loggers\nexcept 'root'. This configuration did not allow\nto operate internal logs of magnetodb service.\n\nCloses-bug: #1382223\nCloses-bug: #1381983\nChange-Id: Ic644bad58015348c057c5f3d6b55f21346daccf1\n""}]",2,129041,661628b90ba1ea3b8f9ddc159f563f49e2ebaffd,18,5,6,8863,,,0,"Fixes logging_sample.conf

Logging conf sample did not contain any loggers
except 'root'. This configuration did not allow
to operate internal logs of magnetodb service.

Closes-bug: #1382223
Closes-bug: #1381983
Change-Id: Ic644bad58015348c057c5f3d6b55f21346daccf1
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/41/129041/4 && git format-patch -1 --stdout FETCH_HEAD,['etc/logging.conf.sample'],1,101497d97e4f4fd48539181f12c6f2f015bd49c0,logging-conf-fix,"keys=root, magnetodblevel=NOTSET handlers= [logger_magnetodb]qualname=magnetodb",keys=root,6,1
openstack%2Fkeystone~stable%2Ficehouse~I00f66b0f3c8e9f688429ee78bd51608a4dcac140,openstack/keystone,stable/icehouse,I00f66b0f3c8e9f688429ee78bd51608a4dcac140,Add oslo.serialization for latest keystoneclient,MERGED,2014-10-16 08:37:52.000000000,2014-10-17 11:59:12.000000000,2014-10-17 11:59:11.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1941}, {'_account_id': 1970}, {'_account_id': 6482}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-10-16 08:37:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a96bd7fb9c6cc75a3cff492c5f7a3097fe88cd99', 'message': 'Add oslo.serialization for latest keystoneclient\n\nKeystone tests run against keystoneclient master which added\na new dependecy on oslo.serialization\n\nChange-Id: I00f66b0f3c8e9f688429ee78bd51608a4dcac140\n'}, {'number': 2, 'created': '2014-10-17 09:51:13.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9aec35a9d4d154546f5c456cece6055de5c179f5', 'message': 'Add oslo.serialization for latest keystoneclient\n\nKeystone tests run against keystoneclient master which added\na new dependecy on oslo.serialization\n\nChange-Id: I00f66b0f3c8e9f688429ee78bd51608a4dcac140\n'}]",0,128850,9aec35a9d4d154546f5c456cece6055de5c179f5,13,6,2,1955,,,0,"Add oslo.serialization for latest keystoneclient

Keystone tests run against keystoneclient master which added
a new dependecy on oslo.serialization

Change-Id: I00f66b0f3c8e9f688429ee78bd51608a4dcac140
",git fetch https://review.opendev.org/openstack/keystone refs/changes/50/128850/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a96bd7fb9c6cc75a3cff492c5f7a3097fe88cd99,,# only for Keystone tests running against keystoneclient master oslo.serialization>=1.0.0 # Apache-2.0,,2,0
openstack%2Fceilometer~master~Ia7f8a6758e8cb69568865e59d690b2598633d9c8,openstack/ceilometer,master,Ia7f8a6758e8cb69568865e59d690b2598633d9c8,Imported Translations from Transifex,MERGED,2014-10-17 06:11:24.000000000,2014-10-17 11:59:04.000000000,2014-10-17 11:59:03.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-10-17 06:11:24.000000000', 'files': ['ceilometer/locale/fr/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/fr/LC_MESSAGES/ceilometer-log-warning.po'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9cbaf47e141e2c09deb3bd907dfd60feeb5b795e', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ia7f8a6758e8cb69568865e59d690b2598633d9c8\n'}]",0,129140,9cbaf47e141e2c09deb3bd907dfd60feeb5b795e,8,4,1,11131,,,0,"Imported Translations from Transifex

Change-Id: Ia7f8a6758e8cb69568865e59d690b2598633d9c8
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/40/129140/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/locale/fr/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/fr/LC_MESSAGES/ceilometer-log-warning.po']",2,9cbaf47e141e2c09deb3bd907dfd60feeb5b795e,transifex/translations,"""POT-Creation-Date: 2014-10-17 06:11+0000\n"" ""PO-Revision-Date: 2014-10-16 07:56+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""","""POT-Creation-Date: 2014-10-16 07:50+0000\n"" ""PO-Revision-Date: 2014-09-25 09:45+0000\n"" ""Last-Translator: Maxime COQUEREL <max.coquerel@gmail.com>\n""",6,6
openstack%2Fneutron~master~I18fbbff9c51426f8cd9c1340cb2934a4771929ef,openstack/neutron,master,I18fbbff9c51426f8cd9c1340cb2934a4771929ef,Check for vxlan mod using /proc/modules,ABANDONED,2014-07-09 09:50:40.000000000,2014-10-17 11:51:21.000000000,,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 7217}, {'_account_id': 7787}, {'_account_id': 7805}, {'_account_id': 8124}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 11279}]","[{'number': 1, 'created': '2014-07-09 09:50:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a2a73ac3107fd68f92790671e56eae07488dfe10', 'message': ""Check for vxlan mod using /proc/modules\n\nReason: modinfo requires /lib/modules which isn't always available, for\nexample in LXC containers.\n\nChange-Id: I18fbbff9c51426f8cd9c1340cb2934a4771929ef\nCloses-Bug: #1339197\n""}, {'number': 2, 'created': '2014-07-10 10:31:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9af2d2abd8ec424559ddcd3c63f32922d0653bcf', 'message': ""Check for vxlan mod using /proc/modules\n\nReason: modinfo requires /lib/modules which isn't always available, for\nexample in LXC containers.\n\nChange-Id: I18fbbff9c51426f8cd9c1340cb2934a4771929ef\nCloses-Bug: #1339197\n""}, {'number': 3, 'created': '2014-07-10 10:53:52.000000000', 'files': ['neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/tests/unit/linuxbridge/test_lb_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8e71424a3c1d02178abe9f18390d1b701892edf1', 'message': ""Check for vxlan mod using /proc/modules\n\nReason: modinfo requires /lib/modules which isn't always available, for\nexample in LXC containers.\n\nChange-Id: I18fbbff9c51426f8cd9c1340cb2934a4771929ef\nCloses-Bug: #1339197\n""}]",8,105684,8e71424a3c1d02178abe9f18390d1b701892edf1,59,21,3,7217,,,0,"Check for vxlan mod using /proc/modules

Reason: modinfo requires /lib/modules which isn't always available, for
example in LXC containers.

Change-Id: I18fbbff9c51426f8cd9c1340cb2934a4771929ef
Closes-Bug: #1339197
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/105684/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py'],1,a2a73ac3107fd68f92790671e56eae07488dfe10,bug/1339197," utils.execute(cmd=['grep', '^vxlan\\b', '/proc/modules'])"," utils.execute(cmd=['modinfo', 'vxlan'])",1,1
openstack%2Fkeystone~stable%2Fjuno~I00f66b0f3c8e9f688429ee78bd51608a4dcac140,openstack/keystone,stable/juno,I00f66b0f3c8e9f688429ee78bd51608a4dcac140,Add oslo.serialization for latest keystoneclient,MERGED,2014-10-17 09:01:07.000000000,2014-10-17 11:33:12.000000000,2014-10-17 11:33:12.000000000,"[{'_account_id': 3}, {'_account_id': 1955}]","[{'number': 1, 'created': '2014-10-17 09:01:07.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d7eb99959c7937860896550574c85ba427c2be66', 'message': 'Add oslo.serialization for latest keystoneclient\n\nKeystone tests run against keystoneclient master which added\na new dependecy on oslo.serialization\n\nConflicts:\n\trequirements.txt\n\nChange-Id: I00f66b0f3c8e9f688429ee78bd51608a4dcac140\n(cherry picked from commit a96bd7fb9c6cc75a3cff492c5f7a3097fe88cd99)\n'}]",0,129170,d7eb99959c7937860896550574c85ba427c2be66,6,2,1,9656,,,0,"Add oslo.serialization for latest keystoneclient

Keystone tests run against keystoneclient master which added
a new dependecy on oslo.serialization

Conflicts:
	requirements.txt

Change-Id: I00f66b0f3c8e9f688429ee78bd51608a4dcac140
(cherry picked from commit a96bd7fb9c6cc75a3cff492c5f7a3097fe88cd99)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/70/129170/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,d7eb99959c7937860896550574c85ba427c2be66,,# only for Keystone tests running against keystoneclient master oslo.serialization>=1.0.0 # Apache-2.0,,2,0
openstack%2Frally~master~I58efeda8262f3663e445ace2d499ad0695292675,openstack/rally,master,I58efeda8262f3663e445ace2d499ad0695292675,Fix wrong argument in rally verify,MERGED,2014-10-17 09:00:53.000000000,2014-10-17 11:29:39.000000000,2014-10-17 11:29:38.000000000,"[{'_account_id': 3}, {'_account_id': 6124}, {'_account_id': 8507}]","[{'number': 1, 'created': '2014-10-17 09:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9dda3723edb777dbdd7581a1c9cff0e1fe05689a', 'message': 'Fix wrong argument in rally verify\n\nCloses-Bug: #1382428\n\nChange-Id: I58efeda8262f3663e445ace2d499ad0695292675\n'}, {'number': 2, 'created': '2014-10-17 09:04:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0bf3fd8de9ef9358ae597733b27ab3ba84e2b612', 'message': 'Fix wrong argument in rally verify\n\nCloses-Bug: #1382428\n\nChange-Id: I58efeda8262f3663e445ace2d499ad0695292675\n'}, {'number': 3, 'created': '2014-10-17 10:23:27.000000000', 'files': ['rally/benchmark/scenarios/tempest/tempest.py', 'rally/verification/verifiers/tempest/tempest.py', 'tests/unit/verification/verifiers/test_tempest.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/df4e8ff8138e00c2b47fb1602dad8455a836e747', 'message': 'Fix wrong argument in rally verify\n\nCloses-Bug: #1382428\n\nChange-Id: I58efeda8262f3663e445ace2d499ad0695292675\n'}]",0,129169,df4e8ff8138e00c2b47fb1602dad8455a836e747,10,3,3,9545,,,0,"Fix wrong argument in rally verify

Closes-Bug: #1382428

Change-Id: I58efeda8262f3663e445ace2d499ad0695292675
",git fetch https://review.opendev.org/openstack/rally refs/changes/69/129169/3 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/tempest/tempest.py', 'rally/verification/verifiers/tempest/tempest.py', 'tests/unit/verification/verifiers/test_tempest.py']",3,9dda3723edb777dbdd7581a1c9cff0e1fe05689a,," mock_run.assert_called_once_with(testr_arg=""smoke"")"," mock_run.assert_called_once_with(""smoke"")",15,11
openstack%2Fopenstack-manuals~master~I3f6af0d42254fb2c0b9f874af3b87d45c6ebbaaf,openstack/openstack-manuals,master,I3f6af0d42254fb2c0b9f874af3b87d45c6ebbaaf,Add devstack to index pages,MERGED,2014-10-15 18:09:42.000000000,2014-10-17 11:10:25.000000000,2014-10-17 11:10:24.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 970}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-15 18:09:42.000000000', 'files': ['www/icehouse/index.html', 'www/havana/index.html', 'www/trunk/index.html', 'www/juno/index.html', 'www/index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/da81c6a10ad9e4d486a1ce53bf31501deeb3d9c0', 'message': 'Add devstack to index pages\n\ndevstack is now on docs.openstack.org, add it to our index pages.\n\nChange-Id: I3f6af0d42254fb2c0b9f874af3b87d45c6ebbaaf\n'}]",0,128726,da81c6a10ad9e4d486a1ce53bf31501deeb3d9c0,10,5,1,6547,,,0,"Add devstack to index pages

devstack is now on docs.openstack.org, add it to our index pages.

Change-Id: I3f6af0d42254fb2c0b9f874af3b87d45c6ebbaaf
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/26/128726/1 && git format-patch -1 --stdout FETCH_HEAD,"['www/icehouse/index.html', 'www/havana/index.html', 'www/trunk/index.html', 'www/juno/index.html', 'www/index.html']",5,da81c6a10ad9e4d486a1ce53bf31501deeb3d9c0,add-devstack," <dd> <a href=""http://docs.openstack.org/developer/devstack/""> DevStack: Deploying OpenStack for Developers </a> </dd>",,25,0
openstack%2Fopenstack-manuals~master~I1852899aa595f8acba942af953a2d4863659198b,openstack/openstack-manuals,master,I1852899aa595f8acba942af953a2d4863659198b,Include glossary terms for Federated Identity section,MERGED,2014-10-13 01:19:19.000000000,2014-10-17 11:05:00.000000000,2014-10-17 11:04:59.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-13 01:19:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e74fee5ca688769a43651a363f845e0502905090', 'message': 'Include glossary terms for Federated Identity section\n\nUpdated the glossary file to include terms from the Federated Identity section\n\nChange-Id: I1852899aa595f8acba942af953a2d4863659198b\n'}, {'number': 2, 'created': '2014-10-15 23:54:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0f8e502d70fd68878ed4a169c4d179034e3e6fef', 'message': 'Include glossary terms for Federated Identity section\n\nUpdated the glossary file to include terms from the Federated Identity section\n\nChange-Id: I1852899aa595f8acba942af953a2d4863659198b\n'}, {'number': 3, 'created': '2014-10-16 23:21:38.000000000', 'files': ['doc/glossary/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/601fd724006501a2cb8a2b68de98ec414185fd1b', 'message': 'Include glossary terms for Federated Identity section\n\nUpdated the glossary file to include terms from the Federated Identity section\n\nChange-Id: I1852899aa595f8acba942af953a2d4863659198b\n'}]",12,127861,601fd724006501a2cb8a2b68de98ec414185fd1b,13,3,3,8103,,,0,"Include glossary terms for Federated Identity section

Updated the glossary file to include terms from the Federated Identity section

Change-Id: I1852899aa595f8acba942af953a2d4863659198b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/61/127861/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/glossary-terms.xml'],1,e74fee5ca688769a43651a363f845e0502905090,lp1319158-federated-glossary," <glossterm>Federated Identity</glossterm> <indexterm class=""singular""> <primary>Federated Identity</primary> </indexterm> <glossdef> <para>A method to establish trusts between identity providers and the OpenStack cloud.</para> </glossdef> </glossentry> <glossentry> <glossentry> <glossterm>Identity Provider</glossterm> <indexterm class=""singular""> <primary>Identity Provider</primary> <secondary>basics of</secondary> </indexterm> <glossdef> <para>A directory service, which allows users to login with a user name and password. It is a typical source of authentication tokens.</para> </glossdef> </glossentry> <glossentry> <glossterm>Mapping</glossterm> <indexterm class=""singular""> <primary>Mapping</primary> </indexterm> <glossdef> <para>A set of rules to map Federation protocol attributes to Identity API objects. An Indentity Provider has exactly one mapping specified per protocol.</para> </glossdef> </glossentry> <glossentry> <glossterm>Protocol</glossterm> <indexterm class=""singular""> <primary>Protocol</primary> </indexterm> <glossdef> <para>Contains information that dictates which Mapping rules to use for an incoming request made by an IdP. An IdP may support multiple protocols.</para> </glossdef> </glossentry> <glossentry> <glossterm>SAML assertion</glossterm> <indexterm class=""singular""> <primary>SAML assertion</primary> </indexterm> <glossdef> <para>Contains information about a user as provided by Identity Provider. It is an indication that a user has been authentication.</para> </glossdef> </glossentry> <glossentry> <glossterm>Service Provider (SP)</glossterm> <indexterm class=""singular""> <primary>Service Provider</primary> </indexterm> <glossdef> <para>A system that provides services to other system entities. In case of Federated Identity, OpenStack Identity is the Service Provider.</para> </glossdef> </glossentry> <glossentry>",,78,0
openstack%2Fdevstack~master~I136a20d7ac50fdf02cbd1102613e324e313b7b0a,openstack/devstack,master,I136a20d7ac50fdf02cbd1102613e324e313b7b0a,Use $() instead of ``,MERGED,2014-10-14 20:09:29.000000000,2014-10-17 11:03:59.000000000,2014-10-17 11:03:58.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 7118}, {'_account_id': 9009}, {'_account_id': 10385}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-10-14 20:09:29.000000000', 'files': ['lib/ceilometer'], 'web_link': 'https://opendev.org/openstack/devstack/commit/efdaafc0f973acdb3fc878434acb3b982e35ccaf', 'message': 'Use $() instead of ``\n\nThere are other instances of this in other files, just tidying\nceilometer at the moment.\n\nChange-Id: I136a20d7ac50fdf02cbd1102613e324e313b7b0a\n'}]",0,128433,efdaafc0f973acdb3fc878434acb3b982e35ccaf,21,6,1,11564,,,0,"Use $() instead of ``

There are other instances of this in other files, just tidying
ceilometer at the moment.

Change-Id: I136a20d7ac50fdf02cbd1102613e324e313b7b0a
",git fetch https://review.opendev.org/openstack/devstack refs/changes/33/128433/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ceilometer'],1,efdaafc0f973acdb3fc878434acb3b982e35ccaf,cd/process-wrap, iniset $CEILOMETER_CONF database connection $(database_connection_url ceilometer), iniset $CEILOMETER_CONF database connection `database_connection_url ceilometer`,1,1
openstack%2Fdevstack~master~I7a119664efac1124e54064311c243c63c2a7944b,openstack/devstack,master,I7a119664efac1124e54064311c243c63c2a7944b,XenAPI: Always update apt sources,MERGED,2014-10-15 17:40:25.000000000,2014-10-17 11:02:44.000000000,2014-10-17 11:02:42.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 5044}, {'_account_id': 6735}, {'_account_id': 7118}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-15 17:40:25.000000000', 'files': ['tools/xen/prepare_guest_template.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/fff07e864ed9b7c57c067457546e4e8c2985ba47', 'message': 'XenAPI: Always update apt sources\n\nIf an appliance is used as a base OS, the user might want to use that in\na different region. With this change we always update the used mirrors\nin the template.\n\nChange-Id: I7a119664efac1124e54064311c243c63c2a7944b\n'}]",0,128718,fff07e864ed9b7c57c067457546e4e8c2985ba47,14,7,1,5044,,,0,"XenAPI: Always update apt sources

If an appliance is used as a base OS, the user might want to use that in
a different region. With this change we always update the used mirrors
in the template.

Change-Id: I7a119664efac1124e54064311c243c63c2a7944b
",git fetch https://review.opendev.org/openstack/devstack refs/changes/18/128718/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/xen/prepare_guest_template.sh'],1,fff07e864ed9b7c57c067457546e4e8c2985ba47,always-update-apt, # Update ubuntu repositories cat > $STAGING_DIR/etc/apt/sources.list << EOF deb http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE} main restricted deb-src http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE} main restricted deb http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE}-updates main restricted deb-src http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE}-updates main restricted deb http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE} universe deb-src http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE} universe deb http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE}-updates universe deb-src http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE}-updates universe deb http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE} multiverse deb-src http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE} multiverse deb http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE}-updates multiverse deb-src http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE}-updates multiverse deb http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE}-backports main restricted universe multiverse deb-src http://${UBUNTU_INST_HTTP_HOSTNAME}${UBUNTU_INST_HTTP_DIRECTORY} ${UBUNTU_INST_RELEASE}-backports main restricted universe multiverse deb http://security.ubuntu.com/ubuntu ${UBUNTU_INST_RELEASE}-security main restricted deb-src http://security.ubuntu.com/ubuntu ${UBUNTU_INST_RELEASE}-security main restricted deb http://security.ubuntu.com/ubuntu ${UBUNTU_INST_RELEASE}-security universe deb-src http://security.ubuntu.com/ubuntu ${UBUNTU_INST_RELEASE}-security universe deb http://security.ubuntu.com/ubuntu ${UBUNTU_INST_RELEASE}-security multiverse deb-src http://security.ubuntu.com/ubuntu ${UBUNTU_INST_RELEASE}-security multiverse EOF,,25,0
openstack%2Fglance~stable%2Fjuno~I801b6e599d79f5cf6d171b27722de21687a4661a,openstack/glance,stable/juno,I801b6e599d79f5cf6d171b27722de21687a4661a,Opening stable/juno,MERGED,2014-10-16 14:54:33.000000000,2014-10-17 11:00:39.000000000,2014-10-17 11:00:38.000000000,"[{'_account_id': 3}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-10-16 14:54:33.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/glance/commit/e58013c2c0b6f0ffe57c2a70bd0b73f419f20bc9', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I801b6e599d79f5cf6d171b27722de21687a4661a\n'}]",0,128942,e58013c2c0b6f0ffe57c2a70bd0b73f419f20bc9,6,2,1,308,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I801b6e599d79f5cf6d171b27722de21687a4661a
",git fetch https://review.opendev.org/openstack/glance refs/changes/42/128942/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,e58013c2c0b6f0ffe57c2a70bd0b73f419f20bc9,stable-juno,version = 2014.2.1,version = 2014.2,2,1
openstack%2Fhorizon~stable%2Fjuno~I694b73e21a53977e5750831a0cdd49adbcd61f37,openstack/horizon,stable/juno,I694b73e21a53977e5750831a0cdd49adbcd61f37,Opening stable/juno,MERGED,2014-10-16 14:57:22.000000000,2014-10-17 11:00:28.000000000,2014-10-17 11:00:28.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-10-16 14:57:22.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/horizon/commit/73d0ff59066a013fadaed0eb7a5be1889c5641dd', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I694b73e21a53977e5750831a0cdd49adbcd61f37\n'}]",0,128946,73d0ff59066a013fadaed0eb7a5be1889c5641dd,8,3,1,308,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I694b73e21a53977e5750831a0cdd49adbcd61f37
",git fetch https://review.opendev.org/openstack/horizon refs/changes/46/128946/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,73d0ff59066a013fadaed0eb7a5be1889c5641dd,stable-juno,version = 2014.2.1,version = 2014.2,2,1
openstack%2Fswift~stable%2Fjuno~Ia1e67fdd719507166bdb36fbbbfc768d649c9ee0,openstack/swift,stable/juno,Ia1e67fdd719507166bdb36fbbbfc768d649c9ee0,Opening stable/juno,MERGED,2014-10-16 15:04:34.000000000,2014-10-17 11:00:07.000000000,2014-10-17 11:00:06.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 9656}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-10-16 15:04:34.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/swift/commit/4765537cba6a6970110953f11f4e1b419d0730d3', 'message': 'Opening stable/juno\n\nSet defaultbranch in .gitreview for convenience.\n\nChange-Id: Ia1e67fdd719507166bdb36fbbbfc768d649c9ee0\n'}]",0,128953,4765537cba6a6970110953f11f4e1b419d0730d3,8,4,1,308,,,0,"Opening stable/juno

Set defaultbranch in .gitreview for convenience.

Change-Id: Ia1e67fdd719507166bdb36fbbbfc768d649c9ee0
",git fetch https://review.opendev.org/openstack/swift refs/changes/53/128953/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,4765537cba6a6970110953f11f4e1b419d0730d3,stable-juno,defaultbranch=stable/juno,,1,0
openstack%2Ftrove~stable%2Fjuno~I8dad70cd47a44892191376b20aa334f2ac7cb3b4,openstack/trove,stable/juno,I8dad70cd47a44892191376b20aa334f2ac7cb3b4,Opening stable/juno,MERGED,2014-10-16 15:02:52.000000000,2014-10-17 10:56:05.000000000,2014-10-17 10:56:05.000000000,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-10-16 15:02:52.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/trove/commit/6c4ea5b845a4d6d71d3d3786517b5b358c30f3ec', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I8dad70cd47a44892191376b20aa334f2ac7cb3b4\n'}]",0,128952,6c4ea5b845a4d6d71d3d3786517b5b358c30f3ec,8,3,1,308,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I8dad70cd47a44892191376b20aa334f2ac7cb3b4
",git fetch https://review.opendev.org/openstack/trove refs/changes/52/128952/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,6c4ea5b845a4d6d71d3d3786517b5b358c30f3ec,stable-juno,version = 2014.2.1,version = 2014.2,2,1
openstack%2Fnova~stable%2Fjuno~I6616376d03a84b0cb0fc872f0d7c930f8ae40fa0,openstack/nova,stable/juno,I6616376d03a84b0cb0fc872f0d7c930f8ae40fa0,Opening stable/juno,MERGED,2014-10-16 14:55:59.000000000,2014-10-17 10:55:50.000000000,2014-10-17 10:55:48.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9656}, {'_account_id': 10118}]","[{'number': 1, 'created': '2014-10-16 14:55:59.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/nova/commit/b7738bfb6c2f271d047e8f20c0b74ef647367111', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I6616376d03a84b0cb0fc872f0d7c930f8ae40fa0\n'}]",0,128944,b7738bfb6c2f271d047e8f20c0b74ef647367111,8,4,1,308,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I6616376d03a84b0cb0fc872f0d7c930f8ae40fa0
",git fetch https://review.opendev.org/openstack/nova refs/changes/44/128944/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,b7738bfb6c2f271d047e8f20c0b74ef647367111,stable-juno,version = 2014.2.1,version = 2014.2,2,1
openstack%2Fhorizon~master~I67617ac6424907574d79ec2a57b513a548e220d2,openstack/horizon,master,I67617ac6424907574d79ec2a57b513a548e220d2,Do not log keystone token,MERGED,2014-10-16 09:43:23.000000000,2014-10-17 10:47:35.000000000,2014-10-17 09:24:54.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 6610}, {'_account_id': 7213}, {'_account_id': 12355}, {'_account_id': 13670}]","[{'number': 1, 'created': '2014-10-16 09:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/dd4f816c3e92476b96cebcdacfd1fdf49028fbf0', 'message': 'Do not log keystone token\n\nPreviously token values are logged as DEBUG level when a new client\nobject is instantiated. In other project and clients, token values\nare now not logged and is output as *REDACTED* instead.\nIn Horizon these log lines do not have much meaning and\nwe can simply remove them.\n\nChange-Id: I67617ac6424907574d79ec2a57b513a548e220d2\nCloses-Bug: #1380642\n'}, {'number': 2, 'created': '2014-10-17 07:11:09.000000000', 'files': ['openstack_dashboard/api/trove.py', 'openstack_dashboard/api/ceilometer.py', 'openstack_dashboard/api/swift.py', 'openstack_dashboard/api/heat.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/api/neutron.py', 'openstack_dashboard/api/keystone.py', 'openstack_dashboard/api/glance.py', 'openstack_dashboard/api/nova.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/47f1d49690fe3787a356175a069723f33ca12cfd', 'message': 'Do not log keystone token\n\nPreviously token values are logged as DEBUG level when a new client\nobject is instantiated. In other project and clients, token values\nare now not logged and is output as *REDACTED* instead.\nIn Horizon these log lines do not have much meaning and\nwe can simply remove them.\n\nChange-Id: I67617ac6424907574d79ec2a57b513a548e220d2\nCloses-Bug: #1380642\n'}]",1,128859,47f1d49690fe3787a356175a069723f33ca12cfd,17,6,2,841,,,0,"Do not log keystone token

Previously token values are logged as DEBUG level when a new client
object is instantiated. In other project and clients, token values
are now not logged and is output as *REDACTED* instead.
In Horizon these log lines do not have much meaning and
we can simply remove them.

Change-Id: I67617ac6424907574d79ec2a57b513a548e220d2
Closes-Bug: #1380642
",git fetch https://review.opendev.org/openstack/horizon refs/changes/59/128859/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/api/trove.py', 'openstack_dashboard/api/ceilometer.py', 'openstack_dashboard/api/swift.py', 'openstack_dashboard/api/heat.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/api/neutron.py', 'openstack_dashboard/api/glance.py', 'openstack_dashboard/api/keystone.py', 'openstack_dashboard/api/nova.py']",9,dd4f816c3e92476b96cebcdacfd1fdf49028fbf0,bug/1380642,," LOG.debug('novaclient connection created using token ""%s"" and url ""%s""' % (request.user.token.id, base.url_for(request, 'compute')))",0,19
openstack%2Fnova-specs~master~I1df3e3775e9248f4fb468cb44407e544c1efe5a2,openstack/nova-specs,master,I1df3e3775e9248f4fb468cb44407e544c1efe5a2,(Re)Propose: make resource tracker use objects,MERGED,2014-10-16 15:47:07.000000000,2014-10-17 10:45:50.000000000,2014-10-17 10:45:49.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 5441}]","[{'number': 1, 'created': '2014-10-16 15:47:07.000000000', 'files': ['specs/kilo/approved/make-resource-tracker-use-objects.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2e3f8a525418e1748877eca6bf8898a13934656f', 'message': '(Re)Propose: make resource tracker use objects\n\nThis spec for make-resource-tracker-use-objects contributes to\nconversion to Nova objects and the project priority for Live\nUpgrades.\n\nblueprint make-resource-tracker-use-objects\nPreviously-approved: juno\n\nChange-Id: I1df3e3775e9248f4fb468cb44407e544c1efe5a2\n'}]",0,128964,2e3f8a525418e1748877eca6bf8898a13934656f,6,4,1,7461,,,0,"(Re)Propose: make resource tracker use objects

This spec for make-resource-tracker-use-objects contributes to
conversion to Nova objects and the project priority for Live
Upgrades.

blueprint make-resource-tracker-use-objects
Previously-approved: juno

Change-Id: I1df3e3775e9248f4fb468cb44407e544c1efe5a2
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/64/128964/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/make-resource-tracker-use-objects.rst'],1,2e3f8a525418e1748877eca6bf8898a13934656f,bp/make-resource-tracker-use-objects,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Make Resource Tracker Use Objects ========================================== https://blueprints.launchpad.net/nova/+spec/make-resource-tracker-use-objects This blueprint was approved for Juno but missed feature freeze. Nova is converting data structures it uses to communicate via RPC and through the database to use an object encapsulation called Nova Objects. This supports of multi-versioning for live-upgrade and database schema independence. This blueprint covers the conversion of the resource tracker to use Nova Objects. Problem description =================== Conversion to Nova Objects will replace dict data structures that are currently communicated via the conductor API with Nova Object versions. Where necessary the Nova Objects will be extended to cover parameters that are not already implemented. Use Cases --------- As an operator I want to be able to upgrade Nova without any downtime. Project Priority ---------------- This blueprint fits under the Live Upgrades priority. Proposed change =============== The Nova Object classes that will be used include: - ComputeNode - Instance - Migrations - Flavor - Service The ComputeNode object is currently missing some parameters that exist in the compute_nodes table and are used in the resource tracker. The following parameters will be added to the ComputeNode: - pci_stats In addition, the following fields exist in the compute_nodes table but are not currently used by the resource tracker. We propose not to add fields to the ComputeNode object unless they are used, so these fields will not be added as part of this blueprint. - extra_resources When complete there will be no direct calls to conductor in the resource tracker. Alternatives ------------ There is another effort to split the scheduler from Nova. When the split is complete the resource tracker may no longer interact with the scheduler via the database. Initially, the scheduler-lib blueprint (see references) will make all compute node interaction with the scheduler go through a new scheduler library in preparation for the split. This suggests that it might be unnecessary to use the ComputeNode object at least. However, it is reasonable to continue using the ComputeNode object even if it is not used to persist data in the database, so we will go ahead with the existing plan to implement it. Data model impact ----------------- The objects isolate the code from the database schema. They are written to operate with existing data model versions. At present the scheduler does not the ComputeNode object, so code there will need to tolerate changes in database schema or the format of data stored in fields. The fields that need to be added to the ComputeNode object are as follows: **pci_stats** Database field type: text Object field type: fields.ObjectField('PciDeviceList', nullable=True) The pci_stats field is currently populated with a PciDeviceList serialized as an object primitive. This is already the correct form for an object field. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- The objects are written to be compatible with the database schema used in Juno. There is no database migration associated with this blueprint and the format of data stored in the fields of the database will not change. This means that a combination of Juno and Kilo versions of the compute nodes will be able to coexist and interact with the scheduler. Developer impact ---------------- Developers working on the resource tracker will be required to use the new objects instead of directly making database calls to conductor. Implementation ============== Assignee(s) ----------- Primary assignee: pmurray Work Items ---------- * Use flavor object in resource tracker * Use Service object in resource tracker * Use Instance object in resource tracker * Use Migrations object in resource tracker * Use ComputeNode object in resource tracker Some of these work items are currently ready for review: https://review.openstack.org/#/q/topic:bp/make-resource-tracker-use-objects,n,z Dependencies ============ None Testing ======= This does not affect existing tempest tests. Unit tests will be added for each object and existing tests will be modified to deal with the new data structure. Documentation Impact ==================== No new features or API changes so no document impact. References ========== https://blueprints.launchpad.net/nova/+spec/scheduler-lib ",,183,0
openstack%2Ftooz~master~I063e9832c825cf2b528c7f8899714a8a440f17a5,openstack/tooz,master,I063e9832c825cf2b528c7f8899714a8a440f17a5,Add a assertRaisesAny helper method,MERGED,2014-10-16 02:31:29.000000000,2014-10-17 10:43:49.000000000,2014-10-17 10:43:49.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 7450}]","[{'number': 1, 'created': '2014-10-16 02:31:29.000000000', 'files': ['tooz/tests/test_coordination.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/ed0e05d35542ff2df803d17f6bded3035b09d3ca', 'message': 'Add a assertRaisesAny helper method\n\nInstead of having special logic that checks if a\ngroup of expected exceptions are raised and fails\nif they are not just use the testtools framework\nto provide a similar function that integrates\nmore natively with testtools.\n\nChange-Id: I063e9832c825cf2b528c7f8899714a8a440f17a5\n'}]",0,128811,ed0e05d35542ff2df803d17f6bded3035b09d3ca,9,4,1,1297,,,0,"Add a assertRaisesAny helper method

Instead of having special logic that checks if a
group of expected exceptions are raised and fails
if they are not just use the testtools framework
to provide a similar function that integrates
more natively with testtools.

Change-Id: I063e9832c825cf2b528c7f8899714a8a440f17a5
",git fetch https://review.opendev.org/openstack/tooz refs/changes/11/128811/1 && git format-patch -1 --stdout FETCH_HEAD,['tooz/tests/test_coordination.py'],1,ed0e05d35542ff2df803d17f6bded3035b09d3ca,,"from testtools import matchers def assertRaisesAny(self, exc_classes, callable_obj, *args, **kwargs): checkers = [matchers.MatchesException(exc_class) for exc_class in exc_classes] matcher = matchers.Raises(matchers.MatchesAny(*checkers)) callable_obj = testcase.Nullary(callable_obj, *args, **kwargs) self.assertThat(callable_obj, matcher) self.assertRaisesAny([tooz.coordination.MemberNotJoined, tooz.coordination.GroupNotCreated], leave_group.get) self.assertRaisesAny([tooz.coordination.MemberNotJoined, tooz.coordination.GroupNotCreated], capa.get) self.assertRaisesAny([tooz.coordination.MemberNotJoined, tooz.coordination.GroupNotCreated], update_cap.get)"," try: leave_group.get() except (tooz.coordination.MemberNotJoined, tooz.coordination.GroupNotCreated): pass else: self.fail(""Exception not raised"") try: capa.get() except (tooz.coordination.MemberNotJoined, tooz.coordination.GroupNotCreated): pass else: self.fail(""Exception not raised"") try: update_cap.get() except (tooz.coordination.MemberNotJoined, tooz.coordination.GroupNotCreated): pass else: self.fail(""Exception not raised"")",17,21
openstack%2Foslo-specs~master~Ie8075430cf17c3249f9eee6f77ad65a06c4df9bf,openstack/oslo-specs,master,Ie8075430cf17c3249f9eee6f77ad65a06c4df9bf,"Add a spec describing the ServiceStatus implementation, to provide status feedback on systemd or OCF /SysV init.d service managers.",ABANDONED,2014-10-17 10:20:08.000000000,2014-10-17 10:20:46.000000000,,[],"[{'number': 1, 'created': '2014-10-17 10:20:08.000000000', 'files': ['requirements.txt', 'specs/kilo/service-status-interface.rst', 'doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/aa94a21a15c393c2f183014e5623249f6993dfe1', 'message': 'Add a spec describing the ServiceStatus implementation, to\nprovide status feedback on systemd or OCF /SysV init.d service\nmanagers.\n\nAdd the sphinxcontrib.seqdiag extension for sequence diagrams.\n\nChange-Id: Ie8075430cf17c3249f9eee6f77ad65a06c4df9bf\n'}]",0,129197,aa94a21a15c393c2f183014e5623249f6993dfe1,2,0,1,8788,,,0,"Add a spec describing the ServiceStatus implementation, to
provide status feedback on systemd or OCF /SysV init.d service
managers.

Add the sphinxcontrib.seqdiag extension for sequence diagrams.

Change-Id: Ie8075430cf17c3249f9eee6f77ad65a06c4df9bf
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/97/129197/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'specs/kilo/service-status-interface.rst', 'doc/source/conf.py']",3,aa94a21a15c393c2f183014e5623249f6993dfe1,," 'sphinxcontrib.seqdiag',",,263,0
openstack%2Fmurano-agent~master~I7bd8d7bb6c28754df922daf57be2561a4b92a898,openstack/murano-agent,master,I7bd8d7bb6c28754df922daf57be2561a4b92a898,Remove muranoagent.conf.sample,MERGED,2014-10-01 10:23:25.000000000,2014-10-17 10:19:55.000000000,2014-10-17 10:19:55.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-10-01 10:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/3228192257f3c04300137a59a49417d3887ae1d4', 'message': 'Remove muranoagent.conf.sample\n\nChange-Id: I7bd8d7bb6c28754df922daf57be2561a4b92a898\nCloses-Bug: #1369844\n'}, {'number': 2, 'created': '2014-10-01 14:38:23.000000000', 'files': ['tools/config/README', 'etc/muranoagent/muranoagent.conf.sample', 'etc/muranoagent/README-muranoagent.conf.txt'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/0d756babef26ece39c7c0be8ab6b6651b605a1eb', 'message': 'Remove muranoagent.conf.sample\n\nChange-Id: I7bd8d7bb6c28754df922daf57be2561a4b92a898\nCloses-Bug: #1369844\n'}]",0,125310,0d756babef26ece39c7c0be8ab6b6651b605a1eb,10,4,2,13149,,,0,"Remove muranoagent.conf.sample

Change-Id: I7bd8d7bb6c28754df922daf57be2561a4b92a898
Closes-Bug: #1369844
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/10/125310/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/config/README', 'etc/muranoagent/muranoagent.conf.sample', 'etc/muranoagent/README-muranoagent.conf.txt']",3,3228192257f3c04300137a59a49417d3887ae1d4,bug/1369844,"To generate the sample nova.conf file, run the following command from the top level of the murano-agent directory: tox -egenconfig ",,4,158
openstack%2Fmurano-agent~master~I59a57ced5db3b81a24c11c89c91da866818f17ff,openstack/murano-agent,master,I59a57ced5db3b81a24c11c89c91da866818f17ff,Remove generate_samlple.sh tool from the project,MERGED,2014-10-01 10:23:25.000000000,2014-10-17 10:19:15.000000000,2014-10-17 10:19:15.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-10-01 10:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/dbe43c575e4ec4b3cf268c086c66612ea3743bf8', 'message': 'Remove generate_samlple.sh tool from the project\n\nChange-Id: I59a57ced5db3b81a24c11c89c91da866818f17ff\nPartial-Bug: #1369844\n'}, {'number': 2, 'created': '2014-10-01 14:38:23.000000000', 'files': ['tools/config/check_uptodate.sh', 'tools/config/README', 'tools/config/generate_sample.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/a8f7d9b06d2bb385ff7f10848e408da24eb4cb14', 'message': 'Remove generate_samlple.sh tool from the project\n\nChange-Id: I59a57ced5db3b81a24c11c89c91da866818f17ff\nPartial-Bug: #1369844\n'}]",1,125309,a8f7d9b06d2bb385ff7f10848e408da24eb4cb14,12,4,2,13149,,,0,"Remove generate_samlple.sh tool from the project

Change-Id: I59a57ced5db3b81a24c11c89c91da866818f17ff
Partial-Bug: #1369844
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/09/125309/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/config/check_uptodate.sh', 'tools/config/README', 'tox.ini']",3,dbe43c575e4ec4b3cf268c086c66612ea3743bf8,bug/1369844,, {toxinidir}/tools/config/check_uptodate.sh,5,66
openstack%2Fmurano-agent~master~I33a75acadf95cbe0cac9f5e79244b39a5841f6d1,openstack/murano-agent,master,I33a75acadf95cbe0cac9f5e79244b39a5841f6d1,Use oslo.config generator,MERGED,2014-10-01 10:23:25.000000000,2014-10-17 10:17:54.000000000,2014-10-17 10:17:53.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 12769}]","[{'number': 1, 'created': '2014-10-01 10:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/062e520785292aa50606a424de60d621a2bbbdc2', 'message': 'Use oslo.config generator\n\nChange-Id: I33a75acadf95cbe0cac9f5e79244b39a5841f6d1\nPartial-Bug: #1369844\n'}, {'number': 2, 'created': '2014-10-01 14:38:23.000000000', 'files': ['muranoagent/openstack/common/log.py', 'muranoagent/openstack/common/eventlet_backdoor.py', 'muranoagent/common/config.py', 'config-generator.conf', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/ce6142557b00011a37085da0019e50e3a17e1344', 'message': 'Use oslo.config generator\n\nChange-Id: I33a75acadf95cbe0cac9f5e79244b39a5841f6d1\nPartial-Bug: #1369844\n'}]",2,125308,ce6142557b00011a37085da0019e50e3a17e1344,12,6,2,13149,,,0,"Use oslo.config generator

Change-Id: I33a75acadf95cbe0cac9f5e79244b39a5841f6d1
Partial-Bug: #1369844
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/08/125308/2 && git format-patch -1 --stdout FETCH_HEAD,"['muranoagent/openstack/common/log.py', 'muranoagent/openstack/common/eventlet_backdoor.py', 'muranoagent/common/config.py', 'config-generator.conf', 'etc/muranoagent/muranoagent.conf.sample', 'setup.cfg', 'tox.ini']",7,062e520785292aa50606a424de60d621a2bbbdc2,bug/1369844,[testenv:genconfig] commands = oslo-config-generator --config-file config-generator.conf ,,32,2
openstack%2Fnova~master~I6edff402b6929dfb7e62803e5ca75e37bb63e483,openstack/nova,master,I6edff402b6929dfb7e62803e5ca75e37bb63e483,mock.assert_called_once() is not a valid method,ABANDONED,2014-09-04 23:14:21.000000000,2014-10-17 10:12:51.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5638}, {'_account_id': 6172}, {'_account_id': 6618}, {'_account_id': 8125}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-04 23:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc9546d25977fa060f7a8c67046e92bd18abcd1d', 'message': ""mock.assert_called_once() is not a valid method\n\nmock.assert_called_once() is a no-op that tests nothing.  Instead\nwith mock.assert_called_once_with() should be used (or use\nassertEqual(1, mock_obj.call_count) if you don't want to check\nparameters).\n\nChange-Id: I6edff402b6929dfb7e62803e5ca75e37bb63e483\nCloses-Bug: #1365751\n""}, {'number': 2, 'created': '2014-09-04 23:27:18.000000000', 'files': ['nova/tests/virt/hyperv/test_ioutils.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0ed9accf7df6b296e42d7578da93b3c0ac88c40d', 'message': ""mock.assert_called_once() is not a valid method\n\nmock.assert_called_once() is a no-op that tests nothing.  Instead\nwith mock.assert_called_once_with() should be used (or use\nassertEqual(1, mock_obj.call_count) if you don't want to check\nparameters).\n\nChange-Id: I6edff402b6929dfb7e62803e5ca75e37bb63e483\nPartial-Bug: #1365751\n""}]",1,119249,0ed9accf7df6b296e42d7578da93b3c0ac88c40d,24,13,2,8125,,,0,"mock.assert_called_once() is not a valid method

mock.assert_called_once() is a no-op that tests nothing.  Instead
with mock.assert_called_once_with() should be used (or use
assertEqual(1, mock_obj.call_count) if you don't want to check
parameters).

Change-Id: I6edff402b6929dfb7e62803e5ca75e37bb63e483
Partial-Bug: #1365751
",git fetch https://review.opendev.org/openstack/nova refs/changes/49/119249/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/hyperv/test_ioutils.py', 'nova/tests/virt/libvirt/test_driver.py']",2,cc9546d25977fa060f7a8c67046e92bd18abcd1d,119249," # Don't want to check params, just one invocation self.assertEqual(1, mock_spawn.call_count)", mock_spawn.assert_called_once(),3,2
openstack%2Fmagnetodb~master~Ib9e3e4cb8ad58e2152435435fe4512cfc373f0a7,openstack/magnetodb,master,Ib9e3e4cb8ad58e2152435435fe4512cfc373f0a7,(WIP) Investigation problem with tox job timeout,ABANDONED,2014-09-05 20:24:58.000000000,2014-10-17 10:06:54.000000000,,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 10676}, {'_account_id': 11006}]","[{'number': 1, 'created': '2014-09-05 20:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/3fb9256a4079c67a5843203f4f763820a4445f39', 'message': 'Investigation problem with tox job timeout\n\nChange-Id: Ib9e3e4cb8ad58e2152435435fe4512cfc373f0a7\n'}, {'number': 2, 'created': '2014-09-05 20:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/3202ab4790d502ff6fb39c21eef55118718f7511', 'message': '(WIP) Investigation problem with tox job timeout\n\nChange-Id: Ib9e3e4cb8ad58e2152435435fe4512cfc373f0a7\n'}, {'number': 3, 'created': '2014-09-09 13:55:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/eabfec8dc5709fd1f4f520b342425319c6dfee65', 'message': '(WIP) Investigation problem with tox job timeout\n\nChange-Id: Ib9e3e4cb8ad58e2152435435fe4512cfc373f0a7\n'}, {'number': 4, 'created': '2014-09-15 15:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/51640cd4429051db9b8b2c38fe20021274115924', 'message': '(WIP) Investigation problem with tox job timeout\n\nChange-Id: Ib9e3e4cb8ad58e2152435435fe4512cfc373f0a7\n'}, {'number': 5, 'created': '2014-09-16 14:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/d5f19ccb618baf82bce1f630bc9678b528e28b7c', 'message': '(WIP) Investigation problem with tox job timeout\n\nChange-Id: Ib9e3e4cb8ad58e2152435435fe4512cfc373f0a7\n'}, {'number': 6, 'created': '2014-09-16 20:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/bc467788c3e69afccf9f9532eb6b8ae9d0e23bf3', 'message': '(WIP) Investigation problem with tox job timeout\n\nChange-Id: Ib9e3e4cb8ad58e2152435435fe4512cfc373f0a7\n'}, {'number': 7, 'created': '2014-09-17 15:07:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/61cb2cd785f48138c4c5da7d56f4fb4b7c67d7be', 'message': '(WIP) Investigation problem with tox job timeout\n\nChange-Id: Ib9e3e4cb8ad58e2152435435fe4512cfc373f0a7\n'}, {'number': 8, 'created': '2014-09-17 17:53:23.000000000', 'files': ['tools/install_cassandra_ccm.sh'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/335bcf40b85f5ac08374654c558357004074fbfb', 'message': '(WIP) Investigation problem with tox job timeout\n\nChange-Id: Ib9e3e4cb8ad58e2152435435fe4512cfc373f0a7\n'}]",1,119467,335bcf40b85f5ac08374654c558357004074fbfb,23,4,8,10676,,,0,"(WIP) Investigation problem with tox job timeout

Change-Id: Ib9e3e4cb8ad58e2152435435fe4512cfc373f0a7
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/67/119467/8 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_cassandra_ccm.sh'],1,3fb9256a4079c67a5843203f4f763820a4445f39,(detached,#!/bin/bash -x,#!/bin/bash,1,1
openstack%2Ffuel-docs~master~I7c0a2b404f45935aac17fdc5c3a3530c54a8aa71,openstack/fuel-docs,master,I7c0a2b404f45935aac17fdc5c3a3530c54a8aa71,Rename VIP resources,MERGED,2014-10-02 14:23:46.000000000,2014-10-17 10:06:40.000000000,2014-10-17 10:06:40.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 11090}, {'_account_id': 12867}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-10-02 14:23:46.000000000', 'files': ['pages/operations/troubleshoot/9105-crm-resources.rst', 'pages/reference-architecture/ha-notes/0130-how-fuel-deploys-ha.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/b2682cc28000f8abe92ee4382128541ae53349ff', 'message': 'Rename VIP resources\n\nRelated blueprint pacemaker-improvements\n\nChange-Id: I7c0a2b404f45935aac17fdc5c3a3530c54a8aa71\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,125649,b2682cc28000f8abe92ee4382128541ae53349ff,12,9,1,6926,,,0,"Rename VIP resources

Related blueprint pacemaker-improvements

Change-Id: I7c0a2b404f45935aac17fdc5c3a3530c54a8aa71
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/49/125649/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/operations/troubleshoot/9105-crm-resources.rst', 'pages/reference-architecture/ha-notes/0130-how-fuel-deploys-ha.rst']",2,b2682cc28000f8abe92ee4382128541ae53349ff,bp/pacemaker-improvements, primitive vip__management ocf:heartbeat:IPaddr2 \ primitive vip__public ocf:heartbeat:IPaddr2 \, primitive vip__management_old ocf:heartbeat:IPaddr2 \ primitive vip__public_old ocf:heartbeat:IPaddr2 \,4,4
openstack%2Ffuel-main~master~I5afd3070586cf8c56bd23f704904b287473a261f,openstack/fuel-main,master,I5afd3070586cf8c56bd23f704904b287473a261f,Rename VIP resources,MERGED,2014-10-02 14:15:24.000000000,2014-10-17 10:06:21.000000000,2014-10-17 10:06:21.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 6926}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11090}, {'_account_id': 12867}]","[{'number': 1, 'created': '2014-10-02 14:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9437974ca388ff31f03f979d1bf4e10661a7a10b', 'message': 'Rename VIP resources\n\nRelated blueprint pacemaker-improvements\n\nChange-Id: I5afd3070586cf8c56bd23f704904b287473a261f\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2014-10-02 14:25:17.000000000', 'files': ['fuelweb_test/tests/test_ha.py', 'fuelweb_test/tests/tests_strength/test_failover.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/422f2a3da6523f0f6c54ebd04b1b1cca2d4d5de6', 'message': 'Rename VIP resources\n\nDocImpact\nRelated blueprint pacemaker-improvements\n\nChange-Id: I5afd3070586cf8c56bd23f704904b287473a261f\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,125647,422f2a3da6523f0f6c54ebd04b1b1cca2d4d5de6,17,8,2,6926,,,0,"Rename VIP resources

DocImpact
Related blueprint pacemaker-improvements

Change-Id: I5afd3070586cf8c56bd23f704904b287473a261f
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/47/125647/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/test_ha.py', 'fuelweb_test/tests/tests_strength/test_failover.py']",2,9437974ca388ff31f03f979d1bf4e10661a7a10b,bp/pacemaker-improvements," re.search('vip__management\s+\(ocf::mirantis:ns_IPaddr2\):' re.search('vip__public\s+\(ocf::mirantis:ns_IPaddr2\):' 'primitive vip__management' in config, 'vip management') 'primitive vip__public' in config, 'vip public')"," re.search('vip__management_old\s+\(ocf::mirantis:ns_IPaddr2\):' re.search('vip__public_old\s+\(ocf::mirantis:ns_IPaddr2\):' 'primitive vip__management_old' in config, 'vip management') 'primitive vip__public_old' in config, 'vip public')",6,6
openstack%2Ffuel-astute~master~I305d6d290afa1d8d208a6a9e6b9565a50cd06df5,openstack/fuel-astute,master,I305d6d290afa1d8d208a6a9e6b9565a50cd06df5,Rename VIP resources,MERGED,2014-10-02 14:09:21.000000000,2014-10-17 10:06:13.000000000,2014-10-17 10:06:13.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8776}, {'_account_id': 8971}, {'_account_id': 10014}, {'_account_id': 11090}, {'_account_id': 12867}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-10-02 14:09:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/49f07135383c68779b48e370133371fdb40287ab', 'message': 'Rename VIP resources\n\nRelated blueprint pacemaker-improvements\n\nChange-Id: I305d6d290afa1d8d208a6a9e6b9565a50cd06df5\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2014-10-02 14:24:59.000000000', 'files': ['docs/pages/0010-attribute_list.rst'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/92e74f72c6caec47c477f0df82ff2ecd876a0796', 'message': 'Rename VIP resources\n\nDocImpact\nRelated blueprint pacemaker-improvements\n\nChange-Id: I305d6d290afa1d8d208a6a9e6b9565a50cd06df5\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,125642,92e74f72c6caec47c477f0df82ff2ecd876a0796,19,8,2,6926,,,0,"Rename VIP resources

DocImpact
Related blueprint pacemaker-improvements

Change-Id: I305d6d290afa1d8d208a6a9e6b9565a50cd06df5
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/42/125642/1 && git format-patch -1 --stdout FETCH_HEAD,['docs/pages/0010-attribute_list.rst'],1,49f07135383c68779b48e370133371fdb40287ab,bp/pacemaker-improvements, public => { management => { public => { management => {, public_old => { management_old => { public_old => { management_old => {,4,4
openstack%2Fsahara-image-elements~stable%2Fjuno~I9aea12b00a0e6fb9387e7bafdb32fa9e3be7e7c6,openstack/sahara-image-elements,stable/juno,I9aea12b00a0e6fb9387e7bafdb32fa9e3be7e7c6,Opening stable/juno,MERGED,2014-10-16 16:07:49.000000000,2014-10-17 10:06:03.000000000,2014-10-17 10:06:03.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7745}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 9656}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-16 16:07:49.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/9a8671adf751968b0b14c0eb67d5de74896f404b', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I9aea12b00a0e6fb9387e7bafdb32fa9e3be7e7c6\n'}]",0,128981,9a8671adf751968b0b14c0eb67d5de74896f404b,14,8,1,6786,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I9aea12b00a0e6fb9387e7bafdb32fa9e3be7e7c6
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/81/128981/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,9a8671adf751968b0b14c0eb67d5de74896f404b,,version = 2014.2.1,version = 2014.2,2,1
openstack%2Fsahara-extra~stable%2Fjuno~I11b7fdd3b775718ef905c5b64cde9a810c3d0984,openstack/sahara-extra,stable/juno,I11b7fdd3b775718ef905c5b64cde9a810c3d0984,Opening stable/juno,MERGED,2014-10-16 16:07:49.000000000,2014-10-17 10:05:57.000000000,2014-10-17 10:05:57.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 9656}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-16 16:07:49.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/sahara-extra/commit/83bdcc47962de6df2866930cef768a802ab3e389', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I11b7fdd3b775718ef905c5b64cde9a810c3d0984\n'}]",0,128980,83bdcc47962de6df2866930cef768a802ab3e389,11,6,1,6786,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I11b7fdd3b775718ef905c5b64cde9a810c3d0984
",git fetch https://review.opendev.org/openstack/sahara-extra refs/changes/80/128980/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,83bdcc47962de6df2866930cef768a802ab3e389,,version = 2014.2.1,version = 2014.2,2,1
openstack%2Ffuel-library~master~Ica5498ebda1e24e3fbc9011c4c703fe31eab112d,openstack/fuel-library,master,Ica5498ebda1e24e3fbc9011c4c703fe31eab112d,Rename VIP resources,MERGED,2014-10-02 14:11:14.000000000,2014-10-17 10:05:50.000000000,2014-10-17 10:05:49.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 12867}]","[{'number': 1, 'created': '2014-10-02 14:11:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/59bf6f2d3b3dff25e85c20417aa918aac8cef7b4', 'message': 'Rename VIP resources\n\nRelated blueprint pacemaker-improvements\n\nChange-Id: Ica5498ebda1e24e3fbc9011c4c703fe31eab112d\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2014-10-02 14:25:08.000000000', 'files': ['deployment/puppet/mysql/manifests/server.pp', 'deployment/puppet/cluster/manifests/haproxy_ocf.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8ff573af9ccf5fa49ad640395050e1c33da2a233', 'message': 'Rename VIP resources\n\nDocImpact\nRelated blueprint pacemaker-improvements\n\nChange-Id: Ica5498ebda1e24e3fbc9011c4c703fe31eab112d\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,125644,8ff573af9ccf5fa49ad640395050e1c33da2a233,17,6,2,6926,,,0,"Rename VIP resources

DocImpact
Related blueprint pacemaker-improvements

Change-Id: Ica5498ebda1e24e3fbc9011c4c703fe31eab112d
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/44/125644/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/mysql/manifests/server.pp', 'deployment/puppet/cluster/manifests/haproxy_ocf.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp']",3,59bf6f2d3b3dff25e85c20417aa918aac8cef7b4,bp/pacemaker-improvements, management => { $vips[public] = {, management_old => { $vips[public_old] = {,6,6
openstack%2Ffuel-library~master~I5835a09451d1604f6323a5cb50bfb7babb9304a5,openstack/fuel-library,master,I5835a09451d1604f6323a5cb50bfb7babb9304a5,Use single nova-api worker per compute node,MERGED,2014-10-06 08:54:11.000000000,2014-10-17 10:04:36.000000000,2014-10-17 10:04:36.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-10-06 08:54:11.000000000', 'files': ['deployment/puppet/openstack/manifests/compute.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f75cd8c41df7d3d710b2cbb40b7b67c04d9ea5b8', 'message': ""Use single nova-api worker per compute node\n\nThen using nova-network with metadata,\nwe don't have to spawn so many (processors core\ncount based) api workers for compute nodes.\n\nCloses-bug: #1377837\n\nChange-Id: I5835a09451d1604f6323a5cb50bfb7babb9304a5\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}]",0,126239,f75cd8c41df7d3d710b2cbb40b7b67c04d9ea5b8,12,7,1,6926,,,0,"Use single nova-api worker per compute node

Then using nova-network with metadata,
we don't have to spawn so many (processors core
count based) api workers for compute nodes.

Closes-bug: #1377837

Change-Id: I5835a09451d1604f6323a5cb50bfb7babb9304a5
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/39/126239/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/compute.pp'],1,f75cd8c41df7d3d710b2cbb40b7b67c04d9ea5b8,fix1377837," # NOTE(bogdando) 1 api worker for compute node is enough osapi_compute_workers => 1,",,2,0
openstack%2Fheat~master~I450d621465560c97508db4ce84f0621c4f2fe6e6,openstack/heat,master,I450d621465560c97508db4ce84f0621c4f2fe6e6,console url support in server resource,ABANDONED,2014-07-28 08:31:27.000000000,2014-10-17 10:04:05.000000000,,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7193}, {'_account_id': 7404}, {'_account_id': 7761}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 12437}]","[{'number': 1, 'created': '2014-07-28 08:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/71de4658744dc3e3e33aea5dee05a398df0842d3', 'message': 'console url support in server resource\n\nAdd property console-type and attribute console-url in server\nresource. So end users can retrieve console url in output according\nconsole type they set.\n\nChange-Id: I450d621465560c97508db4ce84f0621c4f2fe6e6\nImplements: blueprint vnc-console-attr\n'}, {'number': 2, 'created': '2014-07-29 15:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/11a3cc3dd1280a83cfbea5fcf9f8c3891e904b44', 'message': 'console url support in server resource\n\nAdd property console-type and attribute console-url in server\nresource. So end users can retrieve console url in output according\nconsole type they set.\n\nChange-Id: I450d621465560c97508db4ce84f0621c4f2fe6e6\nImplements: blueprint vnc-console-attr\n'}, {'number': 3, 'created': '2014-07-30 02:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a6d1b570279855b81ad8ba597b138d1c1bdd539b', 'message': 'console url support in server resource\n\nAdd property console-type and attribute console-url in server\nresource. So end users can retrieve console url in output according\nconsole type they set.\n\nChange-Id: I450d621465560c97508db4ce84f0621c4f2fe6e6\nImplements: blueprint vnc-console-attr\n'}, {'number': 4, 'created': '2014-08-05 09:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8dbdc0d0682302b3cd7a05d39cbd7c6db61555c6', 'message': 'console url support in server resource\n\nAdd property console-type and attribute console-url in server\nresource. So end users can retrieve console url in output according\nconsole type they set.\n\nChange-Id: I450d621465560c97508db4ce84f0621c4f2fe6e6\nImplements: blueprint vnc-console-attr\n'}, {'number': 5, 'created': '2014-08-05 15:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e17409dec01bd3cbaa269ce8c66335049d23ff73', 'message': 'console url support in server resource\n\nAdd property console-type and attribute console-url in server\nresource. So end users can retrieve console url in output according\nconsole type they set.\n\nChange-Id: I450d621465560c97508db4ce84f0621c4f2fe6e6\nImplements: blueprint vnc-console-attr\n'}, {'number': 6, 'created': '2014-08-06 06:08:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/562c51aff8f226eba527a55a2ddebfdbcd9f689c', 'message': 'console url support in server resource\n\nAdd property console-type and attribute console-url in server\nresource. So end users can retrieve console url in output according\nconsole type they set.\n\nChange-Id: I450d621465560c97508db4ce84f0621c4f2fe6e6\nImplements: blueprint vnc-console-attr\n'}, {'number': 7, 'created': '2014-08-06 06:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c12de0eb54fc90996c8ecbb64caf47487e4d6b05', 'message': 'console url support in server resource\n\nAdd property console-type and attribute console-url in server\nresource. So end users can retrieve console url in output according\nconsole type they set.\n\nChange-Id: I450d621465560c97508db4ce84f0621c4f2fe6e6\nImplements: blueprint vnc-console-attr\n'}, {'number': 8, 'created': '2014-08-06 09:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/40c6c1a460ea480cd3654b08251b2c50dd324ff2', 'message': 'console url support in server resource\n\nAdd property console-type and attribute console-url in server\nresource. So end users can retrieve console url in output according\nconsole type they set.\n\nChange-Id: I450d621465560c97508db4ce84f0621c4f2fe6e6\nImplements: blueprint vnc-console-attr\n'}, {'number': 9, 'created': '2014-08-13 08:30:50.000000000', 'files': ['heat/engine/resources/server.py', 'heat/engine/clients/os/nova.py', 'heat/tests/test_server.py', 'heat/tests/test_nova_utils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7a8f2faeba3f5596897493ac181543956d64dd41', 'message': 'console url support in server resource\n\nAdd property console-type and attribute console-url in server\nresource. So end users can retrieve console url in output according\nconsole type they set.\n\nChange-Id: I450d621465560c97508db4ce84f0621c4f2fe6e6\nImplements: blueprint vnc-console-attr\n'}]",25,109923,7a8f2faeba3f5596897493ac181543956d64dd41,55,10,9,7761,,,0,"console url support in server resource

Add property console-type and attribute console-url in server
resource. So end users can retrieve console url in output according
console type they set.

Change-Id: I450d621465560c97508db4ce84f0621c4f2fe6e6
Implements: blueprint vnc-console-attr
",git fetch https://review.opendev.org/openstack/heat refs/changes/23/109923/9 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/nova_utils.py', 'heat/engine/resources/server.py', 'heat/tests/test_server.py', 'heat/tests/test_nova_utils.py']",4,71de4658744dc3e3e33aea5dee05a398df0842d3,bp/vnc-console-attr," def test_get_console_url(self, console_type='novnc'): server = self.m.CreateMockAnything() console = { 'console': { 'type': console_type, 'url': '%s_console_url' % console_type } } if console_type is None: console['console']['url'] = None elif 'vnc' in console_type: server.get_vnc_console(console_type).AndReturn(console) elif 'spice' in console_type: server.get_spice_console(console_type).AndReturn(console) elif 'rdp' in console_type: server.get_rdp_console(console_type).AndReturn(console) else: console['console']['url'] = None self.m.ReplayAll() console_url = nova_utils.get_console_url(server, console_type) self.assertEqual(console['console']['url'], console_url) self.m.VerifyAll() def test_get_console_url_xvpvnc(self): self.test_get_console_url(console_type='xvpvnc') def test_get_console_url_spice(self): self.test_get_console_url(console_type='spice-html5') def test_get_console_url_rdp(self): self.test_get_console_url(console_type='rdp-html5') def test_get_console_url_none(self): self.test_get_console_url(None) ",,105,8
openstack%2Fmurano~proposed%2Fjuno~I9b15d59f8c84a1dd985ee9a16180ebdac4b68d89,openstack/murano,proposed/juno,I9b15d59f8c84a1dd985ee9a16180ebdac4b68d89,Update article about functional tests,MERGED,2014-10-17 09:15:48.000000000,2014-10-17 09:58:13.000000000,2014-10-17 09:58:12.000000000,"[{'_account_id': 3}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-10-17 09:15:48.000000000', 'files': ['doc/source/articles/test_docs.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/e980a99c316566e4b30cda870f511c3e4e8e0574', 'message': 'Update article about functional tests\n\nChange-Id: I9b15d59f8c84a1dd985ee9a16180ebdac4b68d89\n'}]",0,129181,e980a99c316566e4b30cda870f511c3e4e8e0574,8,3,1,7549,,,0,"Update article about functional tests

Change-Id: I9b15d59f8c84a1dd985ee9a16180ebdac4b68d89
",git fetch https://review.opendev.org/openstack/murano refs/changes/81/129181/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/articles/test_docs.rst'],1,e980a99c316566e4b30cda870f511c3e4e8e0574,,"This page describes automated tests for a Murano project: * where tests are located * how they are run * how execute tests on a local machine * how to find the the root of problems with FAILed tests Murano Continuous Integration ServiceMurano project has separate CI server, which runs tests for all commits and verifies that new code does not break anything.Murano CI url: https://murano-ci.mirantis.com/jenkins/ Anyone can login to that server, using launchpad credentials. There you can find each job for each repository: one for the **murano** and another one for **murano-dashboard**. * ""gate-murano-dashboard-selenium\*"" verifies each commit to murano-dashboard repository * ""gate-murano-integration\*"" verifies each commit to murano repositoryAll jobs are run on fresh installation of operation system and all components are installed on each run.Murano project has a Web User Interface and all possible user scenarios should be tested. All UI tests are located at the https://git.openstack.org/cgit/stackforge/murano-dashboard/tree/muranodashboard/tests/functional Automated tests for Murano Web UI are written in Python using special Selenium library. This library is used to automate web browser interaction from Python. For more information please visit https://selenium-python.readthedocs.org/ * Install Python module, called nose performing one of the following commands **easy_install nose** or **pip install nose*** Install external Python libraries, which are required for Murano Web UI tests: **testtools** and **selenium** Download and run tests: * git clone git://git.openstack.org/stackforge/murano-dashboard* * Change default settings: * Copy muranodashboard/tests/functional/config/config.conf.example to config.conf * Set appropriate urls and credentials for your OpenStack lab. Only admin users are appropriate. [murano] All tests are kept in *sanity_check.py* and divided into 5 test suites: * TestSuiteSmoke - verification of Murano panels; check, that could be open without errors. * TestSuiteEnvironment - verification of all operations with environment are finished successfully. * TestSuiteImage - verification of operations with images. * TestSuiteFields - verification of custom fields validators. * TestSuitePackages - verification of operations with Murano packages. * TestSuiteApplications - verification of Application Catalog page and of application creation process. To specify which tests/suite to run, pass test/suite names on the command line: * to run all tests: ``nosetests sanity_check.p`` * to run a single suite: ``nosetests sanity_check.py:<test suite name>`` * to run a single test: ``nosetests sanity_check.py:<test suite name>.<test name>`` In case of SUCCESS execution, you should see something like this: ......................... Ran 34 tests in 1.440s OK In case of FAILURE, folder with screenshots of the last operation of tests that finished with errors would be created. It's located in *muranodashboard/tests/functional* folder. There are also a number of command line options that can be used to control the test execution and generated outputs. For more details about *nosetests*, try: :: $ nosetests -hTempest tests for Murano are located at the: https://git.openstack.org/cgit/stackforge/murano/tree/murano/tests/functional API Tests +++++++++ Murano API tests are run on devstack gate and located at https://git.openstack.org/cgit/stackforge/murano/tree/murano/tests/functional/api * *test_murano_envs.py* contains test suite with actions on murano's environments(create, delete, get and etc.) * *test_murano_sessions.py* contains test suite with actions on murano's sessions(create, delete, get and etc.) * *test_murano_services.py* contains test suite with actions on murano's services(create, delete, get and etc.) * *test_murano_repository.py* contains test suite with actions on murano's package repository Engine Tests +++++++++++++++++++ Murano Engine Tests are run on murano-ci : https://git.openstack.org/cgit/stackforge/murano/tree/murano/tests/functional/engine * *base.py* contains base test class and tests with actions on deploy Murano services such as 'Telnet' and 'Apache'. Command Line Tests +++++++++++++++++++++++++ Murano CLI tests case are currently in the middle of creation. The current scope is read only operations on a cloud that are hard to test via unit tests. All tests have description and execution steps in there docstrings.","This page describes automated tests for OpenStack Murano project: how you can download and run tests, how understand the root of problems with FAILed tests and detailed description about each test, which executes upon every commit. Murano Continious Integration ServiceMurano project has the CI server, which tests all commits for Murano components and verifies that new code does not break nothing.Murano CI url: https://murano-ci.mirantis.com/jenkins/ There are two jobs for the **murano** repository and two jobs for the **murano-dashboard** repository : one of them runs on Ubuntu, another one on CentOS. Here you can see several Jenkins jobs with different targets: * Jobs ""murano-dashboard-integration-tests-\*"" allow to verify each commit to murano-dashboard repository on different distributive * Jobs ""murano-engine-app-deployment-tests-\*"" allow to verify each commit to murano repository on different distributiveMurano project has a Web User Interface and we have the test suite for Murano Web UI. All UI tests are located at the https://github.com/stackforge/murano-dashboard/functionaltests All automated tests for Murano Web UI are written on Python using advanced Selenium library.This library allows to find Web elements using captions for fields and other information to find elements without/with xpath. For more information please visit http://selenium-python.readthedocs.org/ How To Run ----------* Install Python module called nose using **easy_install nose** or **pip install nose*** Install external Python libraries which are required for Murano Web UI tests: **testtools** and **selenium** Download tests and run: *git clone https://github.com/stackforge/murano-dashboard* * Change default settings: * Open functionaltests/config/config_file.conf * Set appropriate urls and credentials. [common]* Go to the ""functionaltests"" directory where tests are stored * Some applications need to be uploaded to the Application Catalog since some tests use them. To upload a set of standard packages from special Murano repository need to create and execute following script which clone repository with packages, archive and store them in 'functionaltests' folder: git_url=""https://github.com/murano-project/murano-app-incubator"" clone_dir=""murano-app-incubator"" git clone $git_url $clone_dir cd $clone_dir for package_dir in io.murano.* do if [ -d ""$package_dir"" ]; then if [ -f ""${package_dir}/manifest.yaml"" ]; then sudo bash make-package.sh $package_dir fi fi done * All preparation is done. * All tests are grouped for a few suites. To specify which tests/suite to run, pass test/suite names on the command line: * to run all tests: *nosetests sanity_check.py* * to run single suite: *nosetests sanity_check.py:<test suite name>* * to run single test: *nosetests sanity_check.py:<test suite name>.<test name>* In case of SUCCESS you should see something like this: ......................... Ran 34 tests in 1.440s OK There are also a number of command line options that can be used to control the test execution and generated outputs. For help with nosetests’ many command-line options, try: *nosetests -h*Tempest tests for Murano are located at the: https://github.com/stackforge/murano/tree/master/functionaltestsTests on API which running on devstack gate can be founded here https://github.com/stackforge/murano/tree/master/functionaltests/api * test_murano_envs.py contains test suite with actions on murano's environments(create, delete, get and etc.) * test_murano_sessions.py contains test suite with actions on murano's sessions(create, delete, get and etc.) * test_murano_services.py contains test suite with actions on murano's services(create, delete, get and etc.) * test_murano_repository.py contains test suite with actions on murano's package repository Tests on engine which running on murano-ci : https://github.com/stackforge/murano/tree/master/functionaltests/engine * base.py contains base test class and tests with actions on deploy murano's services If you want to know, what steps this test performs, you can see test's scenario in code. For example: :: @attr(type='smoke') def test_get_environment(self): """""" Get environment by id Test create environment, afterthat test try to get environment's info, using environment's id, and finally delete this environment Target component: Murano Scenario: 1. Send request to create environment. 2. Send request to get environment 3. Send request to delete environment """""" resp, env = self.create_environment('test') self.environments.append(env) resp, infa = self.get_environment_by_id(env['id']) self.assertEqual(200, resp.status) self.assertEqual('test', infa['name']) self.delete_environment(env['id']) self.environments.pop(self.environments.index(env))",73,79
openstack%2Fceilometer~stable%2Fjuno~I4a6d5ba62f78843876a7775095c8f864432e8acf,openstack/ceilometer,stable/juno,I4a6d5ba62f78843876a7775095c8f864432e8acf,Opening stable/juno,MERGED,2014-10-16 15:01:02.000000000,2014-10-17 09:53:46.000000000,2014-10-17 09:53:45.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 9656}, {'_account_id': 10987}, {'_account_id': 12119}]","[{'number': 1, 'created': '2014-10-16 15:01:02.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4683a15b3f49fed3f78fa41a58a9a354b176b85e', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I4a6d5ba62f78843876a7775095c8f864432e8acf\n'}]",0,128950,4683a15b3f49fed3f78fa41a58a9a354b176b85e,9,5,1,308,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I4a6d5ba62f78843876a7775095c8f864432e8acf
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/50/128950/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,4683a15b3f49fed3f78fa41a58a9a354b176b85e,stable-juno,version = 2014.2.1,version = 2014.2,2,1
openstack%2Ffuel-astute~master~Ie66b59f4dfa99c5038cab17c1de57e975c62a986,openstack/fuel-astute,master,Ie66b59f4dfa99c5038cab17c1de57e975c62a986,Upload facts for each role separately,MERGED,2014-09-29 12:37:12.000000000,2014-10-17 09:53:27.000000000,2014-10-17 09:53:27.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8882}, {'_account_id': 8907}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-09-29 12:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/9d094a743533d64a6c11f0c14a7ce1bbd87ed1b4', 'message': 'Upload facts for each role separately\n\nInstead of force rewriting of astute.yaml\nupload role facts to /etc/<role>.yaml and\nthen do symbolic to astute.yaml\n\nAlso:\n- add tests;\n- update logs for log parsing tests.\n\nChange-Id: Ie66b59f4dfa99c5038cab17c1de57e975c62a986\n'}, {'number': 2, 'created': '2014-10-01 10:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/61db181f0c7cc484ddf07aecdaff1ae6887bd336', 'message': 'Upload facts for each role separately\n\nInstead of force rewriting of astute.yaml\nupload role facts to /etc/<role>.yaml and\nthen do symbolic to astute.yaml\n\nAlso:\n- add tests;\n- update logs for log parsing tests.\n\nChange-Id: Ie66b59f4dfa99c5038cab17c1de57e975c62a986\n'}, {'number': 3, 'created': '2014-10-10 14:21:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/1bf7a81c66db5020f2e8a691c9a2dc75fb8351f2', 'message': 'Upload facts for each role separately\n\nInstead of force rewriting of astute.yaml\nupload role facts to /etc/<role>.yaml and\nthen do symbolic to astute.yaml\n\nAlso:\n- add tests;\n- update logs for log parsing tests.\n\nChange-Id: Ie66b59f4dfa99c5038cab17c1de57e975c62a986\n'}, {'number': 4, 'created': '2014-10-10 17:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/246aec55f0321e52e5e7484b2344c3ea3e605b2a', 'message': 'Upload facts for each role separately\n\nInstead of force rewriting of astute.yaml\nupload role facts to /etc/<role>.yaml and\nthen do symbolic to astute.yaml\n\nAlso:\n- add tests;\n- update logs for log parsing tests.\n\nChange-Id: Ie66b59f4dfa99c5038cab17c1de57e975c62a986\n'}, {'number': 5, 'created': '2014-10-15 09:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/a82c256c153be28b3518b93f6c24f23f22f9a563', 'message': 'Upload facts for each role separately\n\nInstead of force rewriting of astute.yaml\nupload role facts to /etc/<role>.yaml and\nthen do symbolic to astute.yaml\n\nAlso:\n- add tests;\n- update logs for log parsing tests.\n\nChange-Id: Ie66b59f4dfa99c5038cab17c1de57e975c62a986\n'}, {'number': 6, 'created': '2014-10-15 19:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/df7e745abed98e74d5423e2faf4f342405a4643c', 'message': 'Upload facts for each role separately\n\nInstead of force rewriting of astute.yaml\nupload role facts to /etc/<role>.yaml and\nthen do symbolic to astute.yaml\n\nAlso:\n- add tests;\n- update logs for log parsing tests.\n\nChange-Id: Ie66b59f4dfa99c5038cab17c1de57e975c62a986\n'}, {'number': 7, 'created': '2014-10-15 19:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/41133a7d4533f06ab0a3f2bb19caa67f885ffad5', 'message': 'Upload facts for each role separately\n\nInstead of force rewriting of astute.yaml\nupload role facts to /etc/<role>.yaml and\nthen do symbolic to astute.yaml\n\nAlso:\n- add tests;\n- update logs for log parsing tests.\n\nRelated to blueprint granular-deployment-based-on-tasks\nRelated to blueprint fuel-dry-run-deploy\nRelated to blueprint cinder-neutron-plugins-in-fuel\n\nChange-Id: Ie66b59f4dfa99c5038cab17c1de57e975c62a986\n'}, {'number': 8, 'created': '2014-10-16 11:44:36.000000000', 'files': ['lib/astute/deployment_engine.rb', 'lib/astute/deploy_actions.rb', 'lib/astute/pre_deployment_actions/update_repo_sources.rb', 'spec/example-logs/main-menu.log_', 'lib/astute/pre_deployment_actions/sync_time.rb', 'spec/example-logs/anaconda.log_', 'lib/astute/pre_deploy_actions/connect_facts.rb', 'lib/astute/pre_deployment_actions/sync_puppet_stuff.rb', 'spec/example-logs/puppet-agent.log.multi.compute', 'spec/example-logs/puppet-agent.log.multi.contr', 'lib/astute/pre_deployment_actions/sync_tasks.rb', 'lib/astute/pre_deployment_actions/upload_facts.rb', 'spec/unit/pre_deployment_actions/upload_facts_hook_spec.rb', 'lib/astute/pre_deployment_actions/upload_ssh_keys.rb', 'spec/unit/deploy_actions_spec.rb', 'lib/astute/pre_deployment_actions/enable_puppet_deploy.rb', 'spec/unit/pre_deploy_actions/connect_facts_hook_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/b93496c744176c02fb4d2216de7dcddbaff02181', 'message': 'Upload facts for each role separately\n\nInstead of force rewriting of astute.yaml\nupload role facts to /etc/<role>.yaml and\nthen do symbolic to astute.yaml\n\nAlso:\n- add tests;\n- update logs for log parsing tests.\n\nRelated to blueprint granular-deployment-based-on-tasks\nRelated to blueprint fuel-dry-run-deploy\nRelated to blueprint cinder-neutron-plugins-in-fuel\n\nChange-Id: Ie66b59f4dfa99c5038cab17c1de57e975c62a986\n'}]",2,124728,b93496c744176c02fb4d2216de7dcddbaff02181,43,5,8,8776,,,0,"Upload facts for each role separately

Instead of force rewriting of astute.yaml
upload role facts to /etc/<role>.yaml and
then do symbolic to astute.yaml

Also:
- add tests;
- update logs for log parsing tests.

Related to blueprint granular-deployment-based-on-tasks
Related to blueprint fuel-dry-run-deploy
Related to blueprint cinder-neutron-plugins-in-fuel

Change-Id: Ie66b59f4dfa99c5038cab17c1de57e975c62a986
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/28/124728/8 && git format-patch -1 --stdout FETCH_HEAD,"['lib/astute/pre_deploy_actions/upload_facts.rb', 'spec/unit/pre_deploy_actions/upload_facts_hook_spec.rb', 'spec/example-logs/puppet-agent.log.multi.compute', 'spec/example-logs/puppet-agent.log.multi.contr', 'spec/example-logs/main-menu.log_', 'spec/example-logs/anaconda.log_']",6,9d094a743533d64a6c11f0c14a7ce1bbd87ed1b4,bp/cinder-neutron-plugins-in-fuel,"2014-09-26T14:07:32.588452+01:00 info: kernel command line: initrd=/images/centos-x86_64/initrd.img ksdevice=bootif lang= sshd=1 biosdevname=0 kssendmac locale=en_US text netcfg/choose_interface=52:54:00:00:01:02 udevrules=52:54:00:00:01:02_eth0,52:54:00:00:02:02_eth1,52:54:00:00:03:02_eth2 priority=critical ks=http://10.20.0.2/cblr/svc/op/ks/system/node-5 BOOT_IMAGE=/images/centos-x86_64/vmlinuz BOOTIF=01-52-54-00-00-01-02 2014-09-26T14:07:32.588633+01:00 info: 2014-09-26T14:07:32.588824+01:00 info: text mode forced from cmdline 2014-09-26T14:07:32.589066+01:00 debug: readNetInfo /tmp/s390net not found, early return 2014-09-26T14:07:32.589315+01:00 info: anaconda version 13.21.215 on x86_64 starting 2014-09-26T14:07:32.589466+01:00 debug: Saving module ipv6 2014-09-26T14:07:32.589667+01:00 debug: Saving module iscsi_ibft 2014-09-26T14:07:32.589853+01:00 debug: Saving module iscsi_boot_sysfs 2014-09-26T14:07:32.590046+01:00 debug: Saving module pcspkr 2014-09-26T14:07:32.590285+01:00 debug: Saving module edd 2014-09-26T14:07:32.590472+01:00 debug: Saving module floppy 2014-09-26T14:07:32.590668+01:00 debug: Saving module iscsi_tcp 2014-09-26T14:07:32.590845+01:00 debug: Saving module libiscsi_tcp 2014-09-26T14:07:32.591035+01:00 debug: Saving module libiscsi 2014-09-26T14:07:32.591248+01:00 debug: Saving module scsi_transport_iscsi 2014-09-26T14:07:32.591450+01:00 debug: Saving module squashfs 2014-09-26T14:07:32.591647+01:00 debug: Saving module cramfs 2014-09-26T14:07:32.591853+01:00 debug: probing buses 2014-09-26T14:07:32.592019+01:00 debug: waiting for hardware to initialize 2014-09-26T14:07:32.592231+01:00 debug: probing buses 2014-09-26T14:07:32.592445+01:00 debug: waiting for hardware to initialize 2014-09-26T14:07:32.592644+01:00 info: getting kickstart file 2014-09-26T14:07:32.592830+01:00 info: eth0 has link, using it 2014-09-26T14:07:32.593017+01:00 info: doing kickstart... setting it up 2014-09-26T14:07:32.593229+01:00 debug: activating device eth0 2014-09-26T14:07:32.593400+01:00 info: wait_for_iface_activation (2502): device eth0 activated 2014-09-26T14:07:32.593579+01:00 info: file location: http://10.20.0.2/cblr/svc/op/ks/system/node-5 2014-09-26T14:07:32.593772+01:00 info: transferring http://10.20.0.2/cblr/svc/op/ks/system/node-5 2014-09-26T14:07:32.594067+01:00 info: setting up kickstart 2014-09-26T14:07:32.594292+01:00 info: kickstart forcing text mode 2014-09-26T14:07:32.594485+01:00 info: kickstartFromUrl 2014-09-26T14:07:32.594679+01:00 info: results of url ks, url http://10.20.0.2:8080/centos/fuelweb/x86_64/ 2014-09-26T14:07:32.595853+01:00 warning: got to setupCdrom without a CD device 2014-09-26T14:07:32.596062+01:00 info: no stage2= given, assuming http://10.20.0.2:8080/centos/fuelweb/x86_64//images/install.img 2014-09-26T14:07:32.596263+01:00 debug: going to set language to en_US.UTF-8 2014-09-26T14:07:32.596489+01:00 info: setting language to en_US.UTF-8 2014-09-26T14:07:32.596695+01:00 info: starting STEP_METHOD 2014-09-26T14:07:32.596868+01:00 debug: loaderData->method is set, adding skipMethodDialog 2014-09-26T14:07:32.597089+01:00 debug: skipMethodDialog is set 2014-09-26T14:07:32.597292+01:00 info: starting STEP_STAGE2 2014-09-26T14:07:32.597511+01:00 info: URL_STAGE_MAIN: url is http://10.20.0.2:8080/centos/fuelweb/x86_64//images/install.img 2014-09-26T14:07:32.597704+01:00 info: transferring http://10.20.0.2:8080/centos/fuelweb/x86_64//images/updates.img 2014-09-26T14:07:32.597886+01:00 warning: Error downloading http://10.20.0.2:8080/centos/fuelweb/x86_64//images/updates.img: HTTP response code said error 2014-09-26T14:07:32.598060+01:00 info: transferring http://10.20.0.2:8080/centos/fuelweb/x86_64//images/product.img 2014-09-26T14:07:32.598268+01:00 warning: Error downloading http://10.20.0.2:8080/centos/fuelweb/x86_64//images/product.img: HTTP response code said error 2014-09-26T14:07:32.598471+01:00 info: transferring http://10.20.0.2:8080/centos/fuelweb/x86_64//images/install.img 2014-09-26T14:07:32.598623+01:00 info: mounted loopback device /mnt/runtime on /dev/loop0 as /tmp/install.img 2014-09-26T14:07:32.598807+01:00 info: got stage2 at url http://10.20.0.2:8080/centos/fuelweb/x86_64//images/install.img 2014-09-26T14:07:32.598970+01:00 info: Loading SELinux policy 2014-09-26T14:07:32.599138+01:00 info: getting ready to spawn shell now 2014-09-26T14:07:32.599333+01:00 info: Running anaconda script /usr/bin/anaconda 2014-09-26T14:07:32.599600+01:00 info: CentOS Linux is the highest priority installclass, using it 2014-09-26T14:07:32.599716+01:00 info: Running kickstart %%pre script(s) 2014-09-26T14:07:32.599887+01:00 warning: '/bin/sh' specified as full path 2014-09-26T14:07:54.372332+01:00 info: All kickstart %%pre script(s) have been run 2014-09-26T14:07:54.896350+01:00 info: ISCSID is /usr/sbin/iscsid 2014-09-26T14:07:54.896730+01:00 info: no initiator set 2014-09-26T14:07:54.896730+01:00 warning: '/usr/libexec/fcoe/fcoe_edd.sh' specified as full path 2014-09-26T14:07:54.896751+01:00 info: No FCoE EDD info found: No FCoE boot disk information is found in EDD! 2014-09-26T14:07:54.896890+01:00 info: 2014-09-26T14:07:54.897119+01:00 info: no /etc/zfcp.conf; not configuring zfcp 2014-09-26T14:07:54.897271+01:00 info: created new libuser.conf at /tmp/libuser.4GLvXH with instPath="""" 2014-09-26T14:07:54.897428+01:00 info: running ""ssh-keygen -q -t rsa -f /etc/ssh/ssh_host_rsa_key -C -N "" 2014-09-26T14:07:54.897736+01:00 info: created new libuser.conf at /tmp/libuser.48f7tY with instPath=""/mnt/sysimage"" 2014-09-26T14:07:54.897875+01:00 info: anaconda called with cmdline = ['/usr/bin/anaconda', '--stage2', 'http://10.20.0.2:8080/centos/fuelweb/x86_64//images/install.img', '--kickstart', '/tmp/ks.cfg', '-T', '--selinux', '--lang', 'en_US.UTF-8', '--keymap', 'us', '--repo', 'http://10.20.0.2:8080/centos/fuelweb/x86_64/'] 2014-09-26T14:07:54.898104+01:00 info: Display mode = t 2014-09-26T14:07:54.898172+01:00 info: Default encoding = utf-8 2014-09-26T14:07:54.898343+01:00 info: Detected 2016M of memory 2014-09-26T14:07:54.898514+01:00 info: Swap attempt of 4032M 2014-09-26T14:07:55.408054+01:00 info: running ""ssh-keygen -q -t dsa -f /etc/ssh/ssh_host_dsa_key -C -N "" 2014-09-26T14:07:55.408355+01:00 info: ISCSID is /usr/sbin/iscsid 2014-09-26T14:07:55.408355+01:00 info: no initiator set 2014-09-26T14:07:57.019643+01:00 info: setting installation environment hostname to node-5.domain.tld 2014-09-26T14:07:57.019857+01:00 info: setting installation environment hostname to node-5.domain.tld 2014-09-26T14:07:57.020143+01:00 info: setting installation environment hostname to node-5.domain.tld 2014-09-26T14:07:57.020406+01:00 warning: step installtype does not exist 2014-09-26T14:07:57.020693+01:00 warning: step confirminstall does not exist 2014-09-26T14:07:57.021017+01:00 warning: step complete does not exist 2014-09-26T14:07:57.021310+01:00 warning: step complete does not exist 2014-09-26T14:07:57.021584+01:00 warning: step complete does not exist 2014-09-26T14:07:57.021898+01:00 warning: step complete does not exist 2014-09-26T14:07:57.022167+01:00 warning: step complete does not exist 2014-09-26T14:07:57.022453+01:00 warning: step complete does not exist 2014-09-26T14:07:57.022719+01:00 warning: step complete does not exist 2014-09-26T14:07:57.023042+01:00 warning: step complete does not exist 2014-09-26T14:07:57.023345+01:00 warning: step complete does not exist 2014-09-26T14:07:57.023624+01:00 warning: step complete does not exist 2014-09-26T14:07:57.023929+01:00 warning: step complete does not exist 2014-09-26T14:07:57.024204+01:00 warning: step complete does not exist 2014-09-26T14:07:57.024492+01:00 warning: step complete does not exist 2014-09-26T14:07:57.024782+01:00 info: moving (1) to step setuptime 2014-09-26T14:07:57.025061+01:00 debug: setuptime is a direct step 2014-09-26T14:07:57.025348+01:00 warning: '/usr/sbin/hwclock' specified as full path 2014-09-26T14:07:57.025634+01:00 info: leaving (1) step setuptime 2014-09-26T14:07:57.026001+01:00 info: moving (1) to step autopartitionexecute 2014-09-26T14:07:57.026237+01:00 debug: autopartitionexecute is a direct step 2014-09-26T14:07:57.582270+01:00 info: leaving (1) step autopartitionexecute 2014-09-26T14:07:57.582511+01:00 info: moving (1) to step storagedone 2014-09-26T14:07:57.582727+01:00 debug: storagedone is a direct step 2014-09-26T14:07:57.583021+01:00 info: leaving (1) step storagedone 2014-09-26T14:07:57.583319+01:00 info: moving (1) to step enablefilesystems 2014-09-26T14:07:57.583681+01:00 debug: enablefilesystems is a direct step 2014-09-26T14:07:58.133444+01:00 debug: notifying kernel of 'change' event on device /sys/class/block/vda3 2014-09-26T14:07:58.645340+01:00 debug: notifying kernel of 'change' event on device /sys/class/block/vda4 2014-09-26T14:07:59.163828+01:00 debug: notifying kernel of 'change' event on device /sys/class/block/vda5 2014-09-26T14:08:01.676084+01:00 debug: notifying kernel of 'change' event on device /sys/class/block/dm-0 2014-09-26T14:08:02.178677+01:00 info: failed to set SELinux context for /mnt/sysimage: [Errno 95] Operation not supported 2014-09-26T14:08:02.178842+01:00 debug: isys.py:mount()- going to mount /dev/mapper/os-root on /mnt/sysimage as ext4 with options defaults 2014-09-26T14:08:02.179025+01:00 debug: isys.py:mount()- going to mount /dev/vda3 on /mnt/sysimage/boot as ext4 with options defaults 2014-09-26T14:08:02.179209+01:00 debug: isys.py:mount()- going to mount //dev on /mnt/sysimage/dev as bind with options defaults,bind 2014-09-26T14:08:02.179359+01:00 debug: isys.py:mount()- going to mount devpts on /mnt/sysimage/dev/pts as devpts with options gid=5,mode=620 2014-09-26T14:08:02.179576+01:00 debug: isys.py:mount()- going to mount tmpfs on /mnt/sysimage/dev/shm as tmpfs with options defaults 2014-09-26T14:08:02.179706+01:00 info: failed to get default SELinux context for /proc: [Errno 2] No such file or directory 2014-09-26T14:08:02.179846+01:00 debug: isys.py:mount()- going to mount proc on /mnt/sysimage/proc as proc with options defaults 2014-09-26T14:08:02.180071+01:00 info: failed to get default SELinux context for /proc: [Errno 2] No such file or directory 2014-09-26T14:08:02.180188+01:00 debug: isys.py:mount()- going to mount sysfs on /mnt/sysimage/sys as sysfs with options defaults 2014-09-26T14:08:02.180403+01:00 info: leaving (1) step enablefilesystems 2014-09-26T14:08:02.180601+01:00 info: moving (1) to step bootloadersetup 2014-09-26T14:08:02.180779+01:00 debug: bootloadersetup is a direct step 2014-09-26T14:08:02.180924+01:00 info: leaving (1) step bootloadersetup 2014-09-26T14:08:02.181086+01:00 info: moving (1) to step reposetup 2014-09-26T14:08:02.181292+01:00 debug: reposetup is a direct step 2014-09-26T14:08:02.702545+01:00 info: added repository nailgun with URL http://10.20.0.2:8080/centos/fuelweb/x86_64 2014-09-26T14:08:02.702750+01:00 debug: Grabbing http://10.20.0.2:8080/centos/fuelweb/x86_64/repodata/repomd.xml 2014-09-26T14:08:02.703081+01:00 debug: Grabbing http://10.20.0.2:8080/centos/fuelweb/x86_64/repodata/1b5da164a053a2273eb755cb1d9aa43d14c844c1c50dd95c8a083b49384234d4-primary.sqlite.bz2 2014-09-26T14:08:02.703430+01:00 debug: Grabbing http://10.20.0.2:8080/centos/fuelweb/x86_64/repodata/b4e0b9342ef85d3059ff095fa7f140f654c2cb492837de689a58c581207d9632-comps.xml 2014-09-26T14:08:05.208242+01:00 info: leaving (1) step reposetup 2014-09-26T14:08:05.208492+01:00 info: moving (1) to step basepkgsel 2014-09-26T14:08:05.208492+01:00 debug: basepkgsel is a direct step 2014-09-26T14:08:05.208625+01:00 debug: no package matching rhn-setup 2014-09-26T14:08:05.208863+01:00 warning: not adding Base group 2014-09-26T14:08:05.709984+01:00 info: leaving (1) step basepkgsel 2014-09-26T14:08:05.710241+01:00 info: moving (1) to step postselection 2014-09-26T14:08:05.710552+01:00 debug: postselection is a direct step 2014-09-26T14:08:05.710749+01:00 info: selected kernel package for kernel 2014-09-26T14:08:06.212168+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/fs/ext4/ext4.ko.gz 2014-09-26T14:08:06.212168+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/fs/jbd2/jbd2.ko.gz 2014-09-26T14:08:06.212489+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/fs/mbcache.ko.gz 2014-09-26T14:08:06.212489+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/scsi/fcoe/fcoe.ko.gz 2014-09-26T14:08:06.212747+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/scsi/fcoe/libfcoe.ko.gz 2014-09-26T14:08:06.212865+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/scsi/libfc/libfc.ko.gz 2014-09-26T14:08:06.213038+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/scsi/scsi_transport_fc.ko.gz 2014-09-26T14:08:06.213231+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/scsi/scsi_tgt.ko.gz 2014-09-26T14:08:06.213389+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/crypto/xts.ko.gz 2014-09-26T14:08:06.213725+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/crypto/lrw.ko.gz 2014-09-26T14:08:06.213725+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/crypto/gf128mul.ko.gz 2014-09-26T14:08:06.214013+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/crypto/sha256_generic.ko.gz 2014-09-26T14:08:06.214133+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/crypto/cbc.ko.gz 2014-09-26T14:08:06.214389+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/dm-raid.ko.gz 2014-09-26T14:08:06.214389+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/dm-crypt.ko.gz 2014-09-26T14:08:06.214591+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/dm-round-robin.ko.gz 2014-09-26T14:08:06.214983+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/dm-multipath.ko.gz 2014-09-26T14:08:06.214983+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/dm-snapshot.ko.gz 2014-09-26T14:08:06.215207+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/dm-mirror.ko.gz 2014-09-26T14:08:06.215346+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/dm-region-hash.ko.gz 2014-09-26T14:08:06.215486+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/dm-log.ko.gz 2014-09-26T14:08:06.215660+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/dm-zero.ko.gz 2014-09-26T14:08:06.215826+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/dm-mod.ko.gz 2014-09-26T14:08:06.216005+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/linear.ko.gz 2014-09-26T14:08:06.216286+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/raid10.ko.gz 2014-09-26T14:08:06.216286+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/raid456.ko.gz 2014-09-26T14:08:06.216499+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/crypto/async_tx/async_raid6_recov.ko.gz 2014-09-26T14:08:06.216695+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/crypto/async_tx/async_pq.ko.gz 2014-09-26T14:08:06.216861+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/lib/raid6/raid6_pq.ko.gz 2014-09-26T14:08:06.217028+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/crypto/async_tx/async_xor.ko.gz 2014-09-26T14:08:06.217297+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/crypto/xor.ko.gz 2014-09-26T14:08:06.217393+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/crypto/async_tx/async_memcpy.ko.gz 2014-09-26T14:08:06.217532+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/crypto/async_tx/async_tx.ko.gz 2014-09-26T14:08:06.217719+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/raid1.ko.gz 2014-09-26T14:08:06.217884+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/md/raid0.ko.gz 2014-09-26T14:08:06.218051+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/net/8021q/8021q.ko.gz 2014-09-26T14:08:06.218218+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/net/802/garp.ko.gz 2014-09-26T14:08:06.218562+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/net/802/stp.ko.gz 2014-09-26T14:08:06.218562+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/net/llc/llc.ko.gz 2014-09-26T14:08:06.218756+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/infiniband/hw/mlx4/mlx4_ib.ko.gz 2014-09-26T14:08:06.218916+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/net/mlx4/mlx4_en.ko.gz 2014-09-26T14:08:06.219118+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/net/mlx4/mlx4_core.ko.gz 2014-09-26T14:08:06.219287+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/infiniband/ulp/ipoib/ib_ipoib.ko.gz 2014-09-26T14:08:06.219453+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/infiniband/core/ib_cm.ko.gz 2014-09-26T14:08:06.219757+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/infiniband/core/ib_sa.ko.gz 2014-09-26T14:08:06.219823+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/infiniband/core/ib_mad.ko.gz 2014-09-26T14:08:06.219984+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/infiniband/core/ib_core.ko.gz 2014-09-26T14:08:06.220148+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/block/virtio_blk.ko.gz 2014-09-26T14:08:06.220315+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/net/virtio_net.ko.gz 2014-09-26T14:08:06.220478+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/virtio/virtio_pci.ko.gz 2014-09-26T14:08:06.220667+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/virtio/virtio_ring.ko.gz 2014-09-26T14:08:06.220944+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/virtio/virtio.ko.gz 2014-09-26T14:08:06.221009+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/ata/pata_acpi.ko.gz 2014-09-26T14:08:06.221174+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/ata/ata_generic.ko.gz 2014-09-26T14:08:06.221340+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/ata/ata_piix.ko.gz 2014-09-26T14:08:06.221505+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/net/ipv6/ipv6.ko.gz 2014-09-26T14:08:06.221694+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/firmware/iscsi_ibft.ko.gz 2014-09-26T14:08:06.221861+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/scsi/iscsi_boot_sysfs.ko.gz 2014-09-26T14:08:06.222139+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/input/misc/pcspkr.ko.gz 2014-09-26T14:08:06.222203+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/firmware/edd.ko.gz 2014-09-26T14:08:06.222366+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/block/floppy.ko.gz 2014-09-26T14:08:06.222533+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/scsi/iscsi_tcp.ko.gz 2014-09-26T14:08:06.222724+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/scsi/libiscsi_tcp.ko.gz 2014-09-26T14:08:06.222889+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/scsi/libiscsi.ko.gz 2014-09-26T14:08:06.223068+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/scsi/scsi_transport_iscsi.ko.gz 2014-09-26T14:08:06.223356+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/fs/squashfs/squashfs.ko.gz 2014-09-26T14:08:06.223356+01:00 debug: Checking for DUD module /lib/modules/2.6.32-431.el6.x86_64/kernel/fs/cramfs/cramfs.ko.gz 2014-09-26T14:08:06.223567+01:00 debug: selecting kernel-devel 2014-09-26T14:08:09.229225+01:00 info: leaving (1) step postselection 2014-09-26T14:08:09.229448+01:00 info: moving (1) to step install 2014-09-26T14:08:09.229845+01:00 info: leaving (1) step install 2014-09-26T14:08:09.230098+01:00 info: moving (1) to step preinstallconfig 2014-09-26T14:08:09.230390+01:00 debug: preinstallconfig is a direct step 2014-09-26T14:08:09.230717+01:00 debug: isys.py:mount()- going to mount /selinux on /mnt/sysimage/selinux as selinuxfs with options defaults 2014-09-26T14:08:09.231093+01:00 debug: isys.py:mount()- going to mount /proc/bus/usb on /mnt/sysimage/proc/bus/usb as usbfs with options defaults 2014-09-26T14:08:09.231455+01:00 info: copy_to_sysimage: source '/etc/multipath/wwids' does not exist. 2014-09-26T14:08:09.231645+01:00 info: copy_to_sysimage: source '/etc/multipath/bindings' does not exist. 2014-09-26T14:08:09.231964+01:00 info: copy_to_sysimage: source '/etc/multipath/wwids' does not exist. 2014-09-26T14:08:09.232258+01:00 info: copy_to_sysimage: source '/etc/multipath/bindings' does not exist. 2014-09-26T14:08:09.232568+01:00 info: leaving (1) step preinstallconfig 2014-09-26T14:08:09.232943+01:00 info: moving (1) to step installpackages 2014-09-26T14:08:09.233242+01:00 debug: installpackages is a direct step 2014-09-26T14:08:09.233507+01:00 info: Preparing to install packages 2014-09-26T14:08:12.260070+01:00 info: Installing libgcc-4.4.7-4.el6.x86_64 2014-09-26T14:08:12.260070+01:00 info: warning: libgcc-4.4.7-4.el6.x86_64: Header V3 RSA/SHA1 Signature, key ID c105b9de: NOKEY 2014-09-26T14:08:12.260304+01:00 info: Installing setup-2.8.14-20.el6_4.1.noarch 2014-09-26T14:08:12.260501+01:00 info: Installing filesystem-2.4.30-3.el6.x86_64 2014-09-26T14:08:13.263472+01:00 info: Installing basesystem-10.0-4.el6.noarch 2014-09-26T14:08:13.263669+01:00 info: Installing kernel-headers-2.6.32-431.20.3.el6.x86_64 2014-09-26T14:08:13.263762+01:00 info: warning: kernel-headers-2.6.32-431.20.3.el6.x86_64: Header V3 RSA/SHA1 Signature, key ID a218cd1f: NOKEY 2014-09-26T14:08:13.764961+01:00 info: Installing rubygem-mixlib-cli-1.2.2-3.el6.noarch 2014-09-26T14:08:13.765124+01:00 info: Installing rubygem-extlib-0.9.13-5.el6.noarch 2014-09-26T14:08:14.266349+01:00 info: Installing ncurses-base-5.7-3.20090208.el6.x86_64 2014-09-26T14:08:14.266561+01:00 info: Installing tzdata-2014e-1.el6.noarch 2014-09-26T14:08:15.268302+01:00 info: Installing glibc-common-2.12-1.132.el6_5.2.x86_64 2014-09-26T14:08:24.284548+01:00 info: Installing nss-softokn-freebl-3.14.3-10.el6_5.x86_64 2014-09-26T14:08:24.284753+01:00 info: Installing glibc-2.12-1.132.el6_5.2.x86_64 2014-09-26T14:08:25.286991+01:00 info: Installing ncurses-libs-5.7-3.20090208.el6.x86_64 2014-09-26T14:08:25.286991+01:00 info: Installing bash-4.1.2-15.el6_4.x86_64 2014-09-26T14:08:25.788361+01:00 info: Installing libattr-2.4.44-7.el6.x86_64 2014-09-26T14:08:25.788361+01:00 info: Installing libcap-2.16-5.5.el6.x86_64 2014-09-26T14:08:25.788751+01:00 info: Installing zlib-1.2.3-29.el6.x86_64 2014-09-26T14:08:25.788861+01:00 info: Installing info-4.13a-8.el6.x86_64 2014-09-26T14:08:25.789139+01:00 info: Installing popt-1.13-7.el6.x86_64 2014-09-26T14:08:25.789301+01:00 info: Installing chkconfig-1.3.49.3-2.el6_4.1.x86_64 2014-09-26T14:08:26.290761+01:00 info: Installing libacl-2.2.49-6.el6.x86_64 2014-09-26T14:08:26.290761+01:00 info: Installing audit-libs-2.2-4.el6_5.x86_64 2014-09-26T14:08:26.291065+01:00 info: Installing db4-4.7.25-18.el6_4.x86_64 2014-09-26T14:08:26.291181+01:00 info: Installing libcom_err-1.41.12-18.el6.x86_64 2014-09-26T14:08:26.291471+01:00 info: Installing nspr-4.10.2-1.el6_5.x86_64 2014-09-26T14:08:26.291642+01:00 info: Installing libstdc++-4.4.7-4.el6.x86_64 2014-09-26T14:08:26.291985+01:00 info: Installing nss-util-3.15.3-1.el6_5.x86_64 2014-09-26T14:08:26.291985+01:00 info: Installing bzip2-libs-1.0.5-7.el6_0.x86_64 2014-09-26T14:08:26.793742+01:00 info: Installing readline-6.0-4.el6.x86_64 2014-09-26T14:08:26.793742+01:00 info: Installing libxml2-2.7.6-14.el6_5.2.x86_64 2014-09-26T14:08:26.793988+01:00 info: Installing libsepol-2.0.41-4.el6.x86_64 2014-09-26T14:08:27.295233+01:00 info: Installing libselinux-2.0.94-5.3.el6_4.1.x86_64 2014-09-26T14:08:27.295322+01:00 info: Installing shadow-utils-4.1.4.2-13.el6.x86_64 2014-09-26T14:08:27.796830+01:00 info: Installing sed-4.2.1-10.el6.x86_64 2014-09-26T14:08:27.796984+01:00 info: Installing gmp-4.3.1-7.el6_2.2.x86_64 2014-09-26T14:08:27.797264+01:00 info: Installing libidn-1.18-2.el6.x86_64 2014-09-26T14:08:28.298522+01:00 info: Installing gawk-3.1.7-10.el6.x86_64 2014-09-26T14:08:28.298758+01:00 info: Installing file-libs-5.04-15.el6.x86_64 2014-09-26T14:08:28.298914+01:00 info: Installing libuuid-2.17.2-12.14.el6_5.x86_64 2014-09-26T14:08:28.299164+01:00 info: Installing libudev-147-2.51.el6.x86_64 2014-09-26T14:08:28.299275+01:00 info: Installing dbus-libs-1.2.24-7.el6_3.x86_64 2014-09-26T14:08:28.800783+01:00 info: Installing libblkid-2.17.2-12.14.el6_5.x86_64 2014-09-26T14:08:28.801018+01:00 info: Installing findutils-4.4.2-6.el6.x86_64 2014-09-26T14:08:28.801396+01:00 info: Installing libselinux-utils-2.0.94-5.3.el6_4.1.x86_64 2014-09-26T14:08:28.801649+01:00 info: Installing lua-5.1.4-4.1.el6.x86_64 2014-09-26T14:08:28.801932+01:00 info: Installing sqlite-3.6.20-1.el6.x86_64 2014-09-26T14:08:28.802241+01:00 info: Installing pcre-7.8-6.el6.x86_64 2014-09-26T14:08:29.303500+01:00 info: Installing grep-2.6.3-4.el6_5.1.x86_64 2014-09-26T14:08:29.303679+01:00 info: Installing cyrus-sasl-lib-2.1.23-13.el6_3.1.x86_64 2014-09-26T14:08:29.303835+01:00 info: Installing which-2.19-6.el6.x86_64 2014-09-26T14:08:29.304089+01:00 info: Installing libpcap-1.4.0-1.20130826git2dbcaa1.el6.x86_64 2014-09-26T14:08:29.304245+01:00 info: Installing gdbm-1.8.0-36.el6.x86_64 2014-09-26T14:08:29.304463+01:00 info: Installing perl-Pod-Escapes-1.04-136.el6.x86_64 2014-09-26T14:08:29.304631+01:00 info: Installing perl-libs-5.10.1-136.el6.x86_64 2014-09-26T14:08:29.806008+01:00 info: Installing perl-Module-Pluggable-3.90-136.el6.x86_64 2014-09-26T14:08:29.806008+01:00 info: Installing perl-version-0.77-136.el6.x86_64 2014-09-26T14:08:29.806249+01:00 info: Installing perl-Pod-Simple-3.13-136.el6.x86_64 2014-09-26T14:08:29.806393+01:00 info: Installing perl-5.10.1-136.el6.x86_64 2014-09-26T14:08:33.814058+01:00 info: Installing xz-libs-4.999.9-0.3.beta.20091007git.el6.x86_64 2014-09-26T14:08:33.814333+01:00 info: Installing elfutils-libelf-0.152-1.el6.x86_64 2014-09-26T14:08:33.814587+01:00 info: Installing expat-2.0.1-11.el6_2.x86_64 2014-09-26T14:08:33.814917+01:00 info: Installing libgpg-error-1.7-4.el6.x86_64 2014-09-26T14:08:33.815240+01:00 info: Installing nss-softokn-3.14.3-10.el6_5.x86_64 2014-09-26T14:08:34.316658+01:00 info: Installing checkpolicy-2.0.22-1.el6.x86_64 2014-09-26T14:08:34.316658+01:00 info: Installing bzip2-1.0.5-7.el6_0.x86_64 2014-09-26T14:08:34.316907+01:00 info: Installing cpio-2.10-11.el6_3.x86_64 2014-09-26T14:08:34.317089+01:00 info: Installing binutils-2.20.51.0.2-5.36.el6.x86_64 2014-09-26T14:08:35.319554+01:00 info: Installing libedit-2.11-4.20080712cvs.1.el6.x86_64 2014-09-26T14:08:35.319760+01:00 info: Installing tcp_wrappers-libs-7.6-57.el6.x86_64 2014-09-26T14:08:35.320048+01:00 info: Installing pciutils-libs-3.1.10-2.el6.x86_64 2014-09-26T14:08:35.320271+01:00 info: Installing sysvinit-tools-2.87-5.dsf.el6.x86_64 2014-09-26T14:08:35.320476+01:00 info: Installing pkgconfig-0.23-9.1.el6.x86_64 2014-09-26T14:08:35.320699+01:00 info: Installing libyaml-0.1.3-1.el6.x86_64 2014-09-26T14:08:35.320975+01:00 info: Installing dmidecode-2.11-2.el6.x86_64 2014-09-26T14:08:35.321122+01:00 info: Installing pth-2.0.7-9.3.el6.x86_64 2014-09-26T14:08:35.321442+01:00 info: Installing libtasn1-2.3-6.el6_5.x86_64 2014-09-26T14:08:35.321608+01:00 info: Installing p11-kit-0.18.5-2.el6_5.2.x86_64 2014-09-26T14:08:35.822988+01:00 info: Installing p11-kit-trust-0.18.5-2.el6_5.2.x86_64 2014-09-26T14:08:35.822988+01:00 info: Installing ca-certificates-2013.1.95-65.1.el6_5.noarch 2014-09-26T14:08:37.325977+01:00 info: Installing shared-mime-info-0.70-4.el6.x86_64 2014-09-26T14:08:37.326172+01:00 info: warning: %post(shared-mime-info-0.70-4.el6.x86_64) scriptlet failed, exit status 127 2014-09-26T14:08:37.326172+01:00 info: Installing glib2-2.26.1-7.el6_5.x86_64 2014-09-26T14:08:37.827535+01:00 info: Installing gamin-0.1.10-9.el6.x86_64 2014-09-26T14:08:37.827535+01:00 info: Installing grubby-7.0.15-5.el6.x86_64 2014-09-26T14:08:37.827885+01:00 info: Installing dbus-glib-0.86-6.el6.x86_64 2014-09-26T14:08:37.827885+01:00 info: Installing libgcrypt-1.4.5-11.el6_4.x86_64 2014-09-26T14:08:37.828182+01:00 info: Installing device-mapper-persistent-data-0.2.8-4.el6_5.x86_64 2014-09-26T14:08:38.329404+01:00 info: Installing libnih-1.0.1-7.el6.x86_64 2014-09-26T14:08:38.329635+01:00 info: Installing upstart-0.6.5-13.el6_5.3.x86_64 2014-09-26T14:08:38.329635+01:00 info: Installing file-5.04-15.el6.x86_64 2014-09-26T14:08:38.329993+01:00 info: Installing ppl-0.10.2-11.el6.x86_64 2014-09-26T14:08:38.831210+01:00 info: Installing cloog-ppl-0.15.7-1.2.el6.x86_64 2014-09-26T14:08:38.831210+01:00 info: Installing mpfr-2.4.1-6.el6.x86_64 2014-09-26T14:08:38.831482+01:00 info: Installing cpp-4.4.7-4.el6.x86_64 2014-09-26T14:08:39.833716+01:00 info: Installing libutempter-1.1.5-4.1.el6.x86_64 2014-09-26T14:08:39.833921+01:00 info: Installing MAKEDEV-3.24-6.el6.x86_64 2014-09-26T14:08:40.335441+01:00 info: Installing vim-minimal-7.2.411-1.8.el6.x86_64 2014-09-26T14:08:40.335441+01:00 info: Installing procps-3.2.8-25.el6.x86_64 2014-09-26T14:08:40.335678+01:00 info: Installing net-tools-1.60-110.el6_2.x86_64 2014-09-26T14:08:40.837004+01:00 info: Installing psmisc-22.6-19.el6_5.x86_64 2014-09-26T14:08:40.837004+01:00 info: Installing libselinux-ruby-2.0.94-5.3.el6_4.1.x86_64 2014-09-26T14:08:40.837242+01:00 info: Installing augeas-libs-1.0.0-5.mira1.x86_64 2014-09-26T14:08:40.837388+01:00 info: Installing tar-1.23-11.el6.x86_64 2014-09-26T14:08:41.338733+01:00 info: Installing libicu-4.2.1-9.1.el6_2.x86_64 2014-09-26T14:08:42.340615+01:00 info: Installing libusb-0.1.12-23.el6.x86_64 2014-09-26T14:08:42.340615+01:00 info: Installing libss-1.41.12-18.el6.x86_64 2014-09-26T14:08:42.340804+01:00 info: Installing e2fsprogs-libs-1.41.12-18.el6.x86_64 2014-09-26T14:08:42.340991+01:00 info: Installing db4-utils-4.7.25-18.el6_4.x86_64 2014-09-26T14:08:42.341172+01:00 info: Installing pinentry-0.7.6-6.el6.x86_64 2014-09-26T14:08:42.842512+01:00 info: Installing make-3.81-20.el6.x86_64 2014-09-26T14:08:42.842512+01:00 info: Installing libgomp-4.4.7-4.el6.x86_64 2014-09-26T14:08:42.842867+01:00 info: Installing diffutils-2.8.1-28.el6.x86_64 2014-09-26T14:08:42.843016+01:00 info: Installing m4-1.4.13-5.el6.x86_64 2014-09-26T14:08:42.843158+01:00 info: Installing vim-common-7.2.411-1.8.el6.x86_64 2014-09-26T14:08:45.348076+01:00 info: Installing glibc-headers-2.12-1.132.el6_5.2.x86_64 2014-09-26T14:08:45.849254+01:00 info: Installing glibc-devel-2.12-1.132.el6_5.2.x86_64 2014-09-26T14:08:46.350505+01:00 info: Installing dash-0.5.5.1-4.el6.x86_64 2014-09-26T14:08:46.350697+01:00 info: Installing ncurses-5.7-3.20090208.el6.x86_64 2014-09-26T14:08:46.350793+01:00 info: Installing groff-1.18.1.4-21.el6.x86_64 2014-09-26T14:08:47.352922+01:00 info: Installing less-436-10.el6.x86_64 2014-09-26T14:08:47.353109+01:00 info: Installing coreutils-libs-8.4-31.el6_5.2.x86_64 2014-09-26T14:08:47.353314+01:00 info: Installing gzip-1.3.12-19.el6_4.x86_64 2014-09-26T14:08:47.353540+01:00 info: Installing cracklib-2.8.16-4.el6.x86_64 2014-09-26T14:08:47.353771+01:00 info: Installing cracklib-dicts-2.8.16-4.el6.x86_64 2014-09-26T14:08:47.855331+01:00 info: Installing coreutils-8.4-31.el6_5.2.x86_64 2014-09-26T14:08:48.857357+01:00 info: Installing pam-1.1.1-17.el6.x86_64 2014-09-26T14:08:49.358399+01:00 info: Installing module-init-tools-3.9-21.el6_4.x86_64 2014-09-26T14:08:49.358573+01:00 info: Installing hwdata-0.233-9.1.el6.noarch 2014-09-26T14:08:49.859747+01:00 info: Installing redhat-logos-60.0.14-12.el6.centos.noarch 2014-09-26T14:08:50.861265+01:00 info: Installing plymouth-scripts-0.8.3-27.el6.centos.x86_64 2014-09-26T14:08:50.861265+01:00 info: Installing pciutils-3.1.10-2.el6.x86_64 2014-09-26T14:08:50.861538+01:00 info: Installing libpciaccess-0.13.1-2.el6.x86_64 2014-09-26T14:08:50.861538+01:00 info: Installing logrotate-3.8.7-1.el6.x86_64 2014-09-26T14:08:50.861740+01:00 info: Installing nss-3.15.3-6.el6_5.x86_64 2014-09-26T14:08:51.362884+01:00 info: Installing nss-sysinit-3.15.3-6.el6_5.x86_64 2014-09-26T14:08:51.363025+01:00 info: Installing nss-tools-3.15.3-6.el6_5.x86_64 2014-09-26T14:08:51.363200+01:00 info: Installing openldap-2.4.23-34.el6_5.1.x86_64 2014-09-26T14:08:51.363529+01:00 info: Installing libuser-0.56.13-5.el6.x86_64 2014-09-26T14:08:51.363529+01:00 info: Installing libcap-ng-0.6.4-3.el6_0.1.x86_64 2014-09-26T14:08:51.364095+01:00 info: Installing ethtool-3.5-1.4.el6_5.x86_64 2014-09-26T14:08:51.364095+01:00 info: Installing mingetty-1.08-5.el6.x86_64 2014-09-26T14:08:51.865064+01:00 info: Installing vconfig-1.9-8.1.el6.x86_64 2014-09-26T14:08:51.865064+01:00 info: Installing ruby-shadow-1.4.1-13.el6.x86_64 2014-09-26T14:08:51.865403+01:00 info: Installing gpm-libs-1.20.6-12.el6.x86_64 2014-09-26T14:08:51.865403+01:00 info: Installing keyutils-libs-1.4-4.el6.x86_64 2014-09-26T14:08:51.865619+01:00 info: Installing krb5-libs-1.10.3-15.el6_5.1.x86_64 2014-09-26T14:08:51.865759+01:00 info: Installing openssl-1.0.1e-16.el6_5.14.x86_64 2014-09-26T14:08:52.367122+01:00 info: Installing ruby-2.1.1-1.1.x86_64 2014-09-26T14:09:14.915830+01:00 info: Installing rubygem-json-1.7.7-101.el6.x86_64 2014-09-26T14:09:15.417056+01:00 info: Installing libssh2-1.4.2-1.el6.x86_64 2014-09-26T14:09:15.417234+01:00 info: Installing libcurl-7.19.7-37.el6_5.3.x86_64 2014-09-26T14:09:15.417357+01:00 info: Installing curl-7.19.7-37.el6_5.3.x86_64 2014-09-26T14:09:15.417588+01:00 info: Installing rpm-libs-4.8.0-37.el6.x86_64 2014-09-26T14:09:15.918863+01:00 info: Installing rpm-4.8.0-37.el6.x86_64 2014-09-26T14:09:15.919051+01:00 info: Installing gnupg2-2.0.14-6.el6_4.x86_64 2014-09-26T14:09:16.420189+01:00 info: Installing gpgme-1.1.8-3.el6.x86_64 2014-09-26T14:09:16.420189+01:00 info: Installing hiera-1.3.1-1.mira2.noarch 2014-09-26T14:09:16.921636+01:00 info: Installing ruby-augeas-0.5.0-17.3.x86_64 2014-09-26T14:09:16.921895+01:00 info: Installing rubygem-httpclient-2.3.2-5.el6.noarch 2014-09-26T14:09:16.921895+01:00 info: Installing ruby-rgen-0.6.5-1.el6.noarch 2014-09-26T14:09:16.922145+01:00 info: Installing rubygem-stomp-1.2.16-1.el6.noarch 2014-09-26T14:09:16.922319+01:00 info: Installing mcollective-common-2.3.3-3.el6.noarch 2014-09-26T14:09:17.924444+01:00 info: Installing rubygem-mixlib-log-1.4.1-1.el6.noarch 2014-09-26T14:09:17.924680+01:00 info: Installing rubygem-mixlib-config-1.1.2-1.el6.noarch 2014-09-26T14:09:18.425951+01:00 info: Installing rubygem-systemu-2.5.2-1.el6.noarch 2014-09-26T14:09:18.426157+01:00 info: Installing rubygem-cstruct-1.0.1-1.el6.noarch 2014-09-26T14:09:18.426316+01:00 info: Installing rubygem-rethtool-0.0.3-2.mira1.noarch 2014-09-26T14:09:18.426522+01:00 info: Installing tcpdump-4.0.0-3.20090921gitdf3cb4.2.el6.x86_64 2014-09-26T14:09:18.927887+01:00 info: Installing bind-libs-9.8.2-0.23.rc1.el6_5.1.x86_64 2014-09-26T14:09:18.928080+01:00 info: Installing mysql-libs-5.1.73-3.el6_5.x86_64 2014-09-26T14:09:19.429242+01:00 info: Installing fipscheck-lib-1.2.0-7.el6.x86_64 2014-09-26T14:09:19.429490+01:00 info: Installing fipscheck-1.2.0-7.el6.x86_64 2014-09-26T14:09:19.429609+01:00 info: Installing ustr-1.0.4-9.1.el6.x86_64 2014-09-26T14:09:19.429881+01:00 info: Installing libsemanage-2.0.43-4.2.el6.x86_64 2014-09-26T14:09:19.434007+01:00 info: Installing libffi-3.0.5-3.2.el6.x86_64 2014-09-26T14:09:19.434007+01:00 info: Installing python-2.6.6-52.el6.x86_64 2014-09-26T14:09:19.434032+01:00 info: Installing python-libs-2.6.6-52.el6.x86_64 2014-09-26T14:09:22.936615+01:00 info: Installing PyYAML-3.10-3.el6.x86_64 2014-09-26T14:09:23.437984+01:00 info: Installing python-argparse-1.2.1-2.el6.noarch 2014-09-26T14:09:23.437984+01:00 info: Installing python-daemonize-2.2.1-0.mira1.noarch 2014-09-26T14:09:23.438241+01:00 info: Installing python-tablib-0.9.11.20120702git752443f-5.el6.noarch 2014-09-26T14:09:24.440396+01:00 info: Installing python-pypcap-1.1-15.1.x86_64 2014-09-26T14:09:24.440658+01:00 info: Installing yum-metadata-parser-1.1.2-16.el6.x86_64 2014-09-26T14:09:24.440963+01:00 info: Installing pygpgme-0.1-18.20090824bzr68.el6.x86_64 2014-09-26T14:09:24.441240+01:00 info: Installing rpm-python-4.8.0-37.el6.x86_64 2014-09-26T14:09:24.441570+01:00 info: Installing python-pycurl-7.19.0-8.el6.x86_64 2014-09-26T14:09:24.441916+01:00 info: Installing python-urlgrabber-3.9.1-9.el6.noarch 2014-09-26T14:09:24.943428+01:00 info: Installing python-stevedore-0.14-1.el6.noarch 2014-09-26T14:09:24.943428+01:00 info: Installing scapy-2.0.0.10-5.el6.noarch 2014-09-26T14:09:25.444900+01:00 info: Installing python-iniparse-0.3.1-2.1.el6.noarch 2014-09-26T14:09:25.444900+01:00 info: Installing yum-plugin-fastestmirror-1.1.30-17.el6_5.noarch 2014-09-26T14:09:25.445244+01:00 info: Installing yum-3.2.29-43.el6.centos.noarch 2014-09-26T14:09:25.946570+01:00 info: Installing python-prettytable-0.7.2-1.el6.noarch 2014-09-26T14:09:25.946758+01:00 info: Installing python-setuptools-0.6.10-3.el6.noarch 2014-09-26T14:09:25.946819+01:00 info: Installing pyparsing-1.5.6-1.el6.noarch 2014-09-26T14:09:26.448102+01:00 info: Installing python-cmd2-0.6.4-7.el6.noarch 2014-09-26T14:09:26.448102+01:00 info: Installing python-cliff-1.4.4-1.el6.noarch 2014-09-26T14:09:26.448533+01:00 info: Installing python-cliff-tablib-1.1-1.2.noarch 2014-09-26T14:09:26.448834+01:00 info: Installing rubygem-yajl-ruby-1.1.0-1.el6.x86_64 2014-09-26T14:09:26.950205+01:00 info: Installing rubygem-ohai-6.14.0-1.el6.noarch 2014-09-26T14:09:26.950503+01:00 info: Installing slang-2.2.1-1.el6.x86_64 2014-09-26T14:09:27.451759+01:00 info: Installing newt-0.52.11-3.el6.x86_64 2014-09-26T14:09:27.451759+01:00 info: Installing newt-python-0.52.11-3.el6.x86_64 2014-09-26T14:09:27.451983+01:00 info: Installing plymouth-core-libs-0.8.3-27.el6.centos.x86_64 2014-09-26T14:09:27.452194+01:00 info: Installing rubygem-ipaddress-0.8.0-3.el6.noarch 2014-09-26T14:09:27.452390+01:00 info: Installing kbd-misc-1.15-11.el6.noarch 2014-09-26T14:09:27.953690+01:00 info: Installing centos-release-6-5.el6.centos.11.2.x86_64 2014-09-26T14:09:27.953886+01:00 info: Installing policycoreutils-2.0.83-19.39.el6.x86_64 2014-09-26T14:09:28.455035+01:00 info: Installing iptables-1.4.7-11.mira2.x86_64 2014-09-26T14:09:28.455035+01:00 info: Installing iproute-2.6.32-130.el6.netns.2.mira1.x86_64 2014-09-26T14:09:28.455280+01:00 info: Installing iputils-20071127-17.el6_4.2.x86_64 2014-09-26T14:09:28.455496+01:00 info: Installing util-linux-ng-2.17.2-12.14.el6_5.x86_64 2014-09-26T14:09:29.457697+01:00 info: Installing initscripts-9.03.40-2.el6.centos.1.x86_64 2014-09-26T14:09:29.959750+01:00 info: Installing udev-147-2.51.el6.x86_64 2014-09-26T14:09:30.460766+01:00 info: Installing device-mapper-libs-1.02.79-8.el6.x86_64 2014-09-26T14:09:30.460862+01:00 info: Installing device-mapper-1.02.79-8.el6.x86_64 2014-09-26T14:09:30.461042+01:00 info: Installing device-mapper-event-libs-1.02.79-8.el6.x86_64 2014-09-26T14:09:30.461284+01:00 info: Installing openssh-5.3p1-94.el6.x86_64 2014-09-26T14:09:30.461427+01:00 info: Installing device-mapper-event-1.02.79-8.el6.x86_64 2014-09-26T14:09:30.461610+01:00 info: Installing lvm2-libs-2.02.100-8.el6.x86_64 2014-09-26T14:09:30.461774+01:00 info: Installing libdrm-2.4.45-2.el6.x86_64 2014-09-26T14:09:30.963170+01:00 info: Installing plymouth-0.8.3-27.el6.centos.x86_64 2014-09-26T14:09:30.963170+01:00 info: Installing mcollective-2.3.3-3.el6.noarch 2014-09-26T14:09:30.963449+01:00 info: Installing kbd-1.15-11.el6.x86_64 2014-09-26T14:09:30.963563+01:00 info: Installing dracut-004-336.el6_5.2.noarch 2014-09-26T14:09:31.465232+01:00 info: Installing dracut-kernel-004-336.el6_5.2.noarch 2014-09-26T14:09:31.465485+01:00 info: Installing rsyslog-5.8.10-8.el6.x86_64 2014-09-26T14:09:31.465485+01:00 info: Installing ntpdate-4.2.6p5-1.el6.centos.x86_64 2014-09-26T14:09:31.966784+01:00 info: Installing cyrus-sasl-2.1.23-13.el6_3.1.x86_64 2014-09-26T14:09:31.966784+01:00 info: Installing postfix-2.6.6-6.el6_5.x86_64 2014-09-26T14:09:33.970587+01:00 info: Installing crontabs-1.10-33.el6.noarch 2014-09-26T14:09:33.970587+01:00 info: Installing cronie-anacron-1.4.4-12.el6.x86_64 2014-09-26T14:09:33.970810+01:00 info: Installing cronie-1.4.4-12.el6.x86_64 2014-09-26T14:09:33.970951+01:00 info: Installing virt-what-1.11-1.2.el6.x86_64 2014-09-26T14:09:33.971146+01:00 info: Installing facter-1.7.0-1.el6.x86_64 2014-09-26T14:09:34.472436+01:00 info: Installing iptables-ipv6-1.4.7-11.mira2.x86_64 2014-09-26T14:09:34.472436+01:00 info: Installing selinux-policy-3.7.19-231.el6_5.3.noarch 2014-09-26T14:09:35.474512+01:00 info: Installing dhcp-common-4.1.1-38.P1.el6.centos.x86_64 2014-09-26T14:09:35.474672+01:00 info: Installing linux-firmware-20140317-35.gitdec41bce.mira1.noarch 2014-09-26T14:09:39.481431+01:00 info: Installing rubygem-netaddr-1.5.0-2.el6.noarch 2014-09-26T14:09:39.481431+01:00 info: Installing rubygem-openstack-1.1.2-2.el6.noarch 2014-09-26T14:09:40.483536+01:00 info: Installing kernel-2.6.32-431.20.3.el6.x86_64 2014-09-26T14:09:46.495149+01:00 info: Installing dhclient-4.1.1-38.P1.el6.centos.x86_64 2014-09-26T14:09:46.495149+01:00 info: Installing selinux-policy-targeted-3.7.19-231.el6_5.3.noarch 2014-09-26T14:10:17.543656+01:00 info: Installing system-config-firewall-base-1.2.27-5.el6.noarch 2014-09-26T14:10:18.045213+01:00 info: Installing puppet-3.4.2-1.mira2.noarch 2014-09-26T14:10:20.549682+01:00 info: Installing ntp-4.2.6p5-1.el6.centos.x86_64 2014-09-26T14:10:20.549762+01:00 info: Installing nailgun-mcagents-0.1.0-3.x86_64 2014-09-26T14:10:20.549929+01:00 info: Installing lvm2-2.02.100-8.el6.x86_64 2014-09-26T14:10:20.550090+01:00 info: Installing openssh-clients-5.3p1-94.el6.x86_64 2014-09-26T14:10:21.051387+01:00 info: Installing openssh-server-5.3p1-94.el6.x86_64 2014-09-26T14:10:21.051387+01:00 info: Installing bfa-firmware-3.2.21.1-2.el6.noarch 2014-09-26T14:10:22.053655+01:00 info: Installing b43-openfwwf-5.2-4.el6.noarch 2014-09-26T14:10:22.053655+01:00 info: Installing aic94xx-firmware-30-2.el6.noarch 2014-09-26T14:10:22.054096+01:00 info: Installing nailgun-agent-0.1.0-3.x86_64 2014-09-26T14:10:22.054407+01:00 info: Installing authconfig-6.1.12-13.el6.x86_64 2014-09-26T14:10:22.054705+01:00 info: Installing nailgun-net-check-0.2-3.x86_64 2014-09-26T14:10:22.055024+01:00 info: Installing yum-utils-1.1.30-17.el6_5.noarch 2014-09-26T14:10:22.556274+01:00 info: Installing python-tasklib-0.1.0-1.x86_64 2014-09-26T14:10:22.556274+01:00 info: Installing vim-enhanced-7.2.411-1.8.el6.x86_64 2014-09-26T14:10:22.556806+01:00 info: Installing grub-0.97-83.el6.x86_64 2014-09-26T14:10:23.058334+01:00 info: Installing nmap-ncat-6.40-3.el6.x86_64 2014-09-26T14:10:23.058334+01:00 info: Installing bind-utils-9.8.2-0.23.rc1.el6_5.1.x86_64 2014-09-26T14:10:23.058593+01:00 info: Installing wget-1.12-1.11.el6_5.x86_64 2014-09-26T14:10:23.559871+01:00 info: Installing passwd-0.77-4.el6_2.2.x86_64 2014-09-26T14:10:23.559946+01:00 info: Installing sudo-1.8.6p3-12.el6.x86_64 2014-09-26T14:10:23.560138+01:00 info: Installing audit-2.2-4.el6_5.x86_64 2014-09-26T14:10:24.061438+01:00 info: Installing gcc-4.4.7-4.el6.x86_64 2014-09-26T14:10:25.564407+01:00 info: Installing e2fsprogs-1.41.12-18.el6.x86_64 2014-09-26T14:10:26.065636+01:00 info: Installing gdisk-0.8.4-1.el6.x86_64 2014-09-26T14:10:26.065834+01:00 info: Installing efibootmgr-0.5.4-11.el6.x86_64 2014-09-26T14:10:26.066098+01:00 info: Installing mlocate-0.22.2-4.el6.x86_64 2014-09-26T14:10:26.066435+01:00 info: Installing kernel-devel-2.6.32-431.20.3.el6.x86_64 2014-09-26T14:10:39.103864+01:00 info: Installing rsync-3.0.6-9.el6_4.1.x86_64 2014-09-26T14:10:39.103864+01:00 info: Installing acl-2.2.49-6.el6.x86_64 2014-09-26T14:10:39.104364+01:00 info: Installing attr-2.4.44-7.el6.x86_64 2014-09-26T14:10:39.104609+01:00 info: Installing telnet-0.17-47.el6_3.1.x86_64 2014-09-26T14:10:39.104814+01:00 info: Installing daemonize-1.7.3-1.el6.x86_64 2014-09-26T14:10:39.105021+01:00 info: Installing iwl1000-firmware-39.31.5.1-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:39.105309+01:00 info: Installing iwl5000-firmware-8.83.5.1_1-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:39.105569+01:00 info: Installing ivtv-firmware-20080701-20.2.noarch 2014-09-26T14:10:39.105774+01:00 info: Installing libertas-usb8388-firmware-20140317-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:39.105952+01:00 info: Installing xorg-x11-drv-ati-firmware-20140317-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:39.607162+01:00 info: Installing iwl6000-firmware-9.221.4.1-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:39.607309+01:00 info: Installing atmel-firmware-1.3-7.el6.noarch 2014-09-26T14:10:39.607440+01:00 info: Installing zd1211-firmware-1.4-4.el6.noarch 2014-09-26T14:10:39.607579+01:00 info: Installing iwl4965-firmware-228.61.2.24-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:39.607757+01:00 info: Installing iwl3945-firmware-15.32.2.9-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:39.607913+01:00 info: Installing iwl6000g2a-firmware-17.168.5.3-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:39.608029+01:00 info: Installing iwl6050-firmware-41.28.5.1-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:39.608153+01:00 info: Installing iwl100-firmware-39.31.5.1-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:40.109525+01:00 info: Installing iwl5150-firmware-8.24.2.2-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:40.109525+01:00 info: Installing ipw2100-firmware-1.3-11.el6.noarch 2014-09-26T14:10:40.109749+01:00 info: Installing ipw2200-firmware-3.1-4.el6.noarch 2014-09-26T14:10:40.109952+01:00 info: Installing rootfiles-8.1-6.1.el6.noarch 2014-09-26T14:10:40.110126+01:00 info: Installing ql2400-firmware-20140317-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:40.110331+01:00 info: Installing ql2100-firmware-20140317-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:40.110455+01:00 info: Installing ql2200-firmware-20140317-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:40.110561+01:00 info: Installing ql2500-firmware-20140317-35.gitdec41bce.mira1.noarch 2014-09-26T14:10:40.110695+01:00 info: Installing ql23xx-firmware-20140317-35.gitdec41bce.mira1.noarch 2014-09-26T14:11:35.710737+01:00 info: leaving (1) step installpackages 2014-09-26T14:11:35.710737+01:00 info: moving (1) to step postinstallconfig 2014-09-26T14:11:35.711184+01:00 debug: postinstallconfig is a direct step 2014-09-26T14:11:35.711586+01:00 debug: Removing cachedir: /mnt/sysimage/var/cache/yum/anaconda-CentOS-201311272149.x86_64 2014-09-26T14:11:35.711893+01:00 debug: Removing headers and packages from /mnt/sysimage/var/cache/yum/nailgun 2014-09-26T14:11:35.712314+01:00 info: leaving (1) step postinstallconfig 2014-09-26T14:11:35.712423+01:00 info: moving (1) to step writeconfig 2014-09-26T14:11:35.712694+01:00 debug: writeconfig is a direct step 2014-09-26T14:11:35.712975+01:00 info: Writing main configuration 2014-09-26T14:11:35.713235+01:00 warning: '/usr/sbin/authconfig' specified as full path 2014-09-26T14:11:35.713603+01:00 warning: '/usr/sbin/lokkit' specified as full path 2014-09-26T14:11:35.713908+01:00 info: *** FINISHED INSTALLING PACKAGES *** 2014-09-26T14:11:36.215452+01:00 warning: '/usr/sbin/lokkit' specified as full path 2014-09-26T14:11:36.215452+01:00 info: removing libuser.conf at /tmp/libuser.48f7tY 2014-09-26T14:11:36.215822+01:00 info: created new libuser.conf at /tmp/libuser.48f7tY with instPath=""/mnt/sysimage"" 2014-09-26T14:11:36.216120+01:00 info: leaving (1) step writeconfig 2014-09-26T14:11:36.216361+01:00 info: moving (1) to step firstboot 2014-09-26T14:11:36.216583+01:00 debug: firstboot is a direct step 2014-09-26T14:11:36.216822+01:00 info: leaving (1) step firstboot 2014-09-26T14:11:36.217137+01:00 info: moving (1) to step instbootloader 2014-09-26T14:11:36.217399+01:00 debug: instbootloader is a direct step 2014-09-26T14:11:36.217607+01:00 warning: '/sbin/grub-install' specified as full path 2014-09-26T14:11:36.217835+01:00 warning: '/sbin/grub' specified as full path 2014-09-26T14:11:36.768175+01:00 info: leaving (1) step instbootloader 2014-09-26T14:11:36.768175+01:00 info: moving (1) to step reipl 2014-09-26T14:11:36.768462+01:00 debug: reipl is a direct step 2014-09-26T14:11:36.768675+01:00 info: leaving (1) step reipl 2014-09-26T14:11:36.768865+01:00 info: moving (1) to step writeksconfig 2014-09-26T14:11:36.769093+01:00 debug: writeksconfig is a direct step 2014-09-26T14:11:36.769262+01:00 info: Writing autokickstart file 2014-09-26T14:11:36.769431+01:00 info: leaving (1) step writeksconfig 2014-09-26T14:11:36.769674+01:00 info: moving (1) to step setfilecon 2014-09-26T14:11:36.769857+01:00 debug: setfilecon is a direct step 2014-09-26T14:11:36.770023+01:00 info: setting SELinux contexts for anaconda created files 2014-09-26T14:11:39.274964+01:00 info: leaving (1) step setfilecon 2014-09-26T14:11:39.275341+01:00 info: moving (1) to step copylogs 2014-09-26T14:11:39.275735+01:00 debug: copylogs is a direct step 2014-09-26T14:11:39.276147+01:00 info: Copying anaconda logs 2014-09-26T14:11:39.276494+01:00 info: leaving (1) step copylogs 2014-09-26T14:11:39.276786+01:00 info: moving (1) to step methodcomplete 2014-09-26T14:11:39.277084+01:00 debug: methodcomplete is a direct step 2014-09-26T14:11:39.277347+01:00 info: leaving (1) step methodcomplete 2014-09-26T14:11:39.277620+01:00 info: moving (1) to step postscripts 2014-09-26T14:11:39.277940+01:00 debug: postscripts is a direct step 2014-09-26T14:11:39.278261+01:00 info: Running kickstart %%post script(s) 2014-09-26T14:11:39.278495+01:00 warning: '/bin/sh' specified as full path 2014-09-26T14:11:39.785947+01:00 warning: '/bin/sh' specified as full path 2014-09-26T14:11:48.802957+01:00 info: All kickstart %%post script(s) have been run 2014-09-26T14:11:48.802957+01:00 info: leaving (1) step postscripts 2014-09-26T14:11:48.803282+01:00 info: moving (1) to step dopostaction 2014-09-26T14:11:48.803508+01:00 debug: dopostaction is a direct step 2014-09-26T14:11:48.803745+01:00 info: leaving (1) step dopostaction","2013-01-23T09:24:16 info: 09:23:58,565 INFO : kernel command line: initrd=/images/centos63-x86_64/initrd.img ksdevice=bootif lang= locale=en_US text priority=critical kssendmac ks=http://10.0.168.2/cblr/svc/op/ks/system/slave-1 BOOT_IMAGE=/images/centos63-x86_64/vmlinuz BOOTIF=01-52-54-00-9a-db-f8 2013-01-23T09:24:16 info: 2013-01-23T09:24:16 info: 09:23:58,565 INFO : text mode forced from cmdline 2013-01-23T09:24:16 debug: 09:23:58,565 DEBUG : readNetInfo /tmp/s390net not found, early return 2013-01-23T09:24:16 info: 09:23:58,565 INFO : anaconda version 13.21.176 on x86_64 starting 2013-01-23T09:24:16 debug: 09:23:58,729 DEBUG : Saving module ipv6 2013-01-23T09:24:16 debug: 09:23:58,729 DEBUG : Saving module iscsi_ibft 2013-01-23T09:24:16 debug: 09:23:58,729 DEBUG : Saving module iscsi_boot_sysfs 2013-01-23T09:24:16 debug: 09:23:58,729 DEBUG : Saving module pcspkr 2013-01-23T09:24:16 debug: 09:23:58,729 DEBUG : Saving module edd 2013-01-23T09:24:16 debug: 09:23:58,729 DEBUG : Saving module floppy 2013-01-23T09:24:16 debug: 09:23:58,729 DEBUG : Saving module iscsi_tcp 2013-01-23T09:24:16 debug: 09:23:58,729 DEBUG : Saving module libiscsi_tcp 2013-01-23T09:24:16 debug: 09:23:58,729 DEBUG : Saving module libiscsi 2013-01-23T09:24:16 debug: 09:23:58,729 DEBUG : Saving module scsi_transport_iscsi 2013-01-23T09:24:16 debug: 09:23:58,729 DEBUG : Saving module squashfs 2013-01-23T09:24:16 debug: 09:23:58,729 DEBUG : Saving module cramfs 2013-01-23T09:24:16 debug: 09:23:58,730 DEBUG : probing buses 2013-01-23T09:24:16 debug: 09:23:58,863 DEBUG : waiting for hardware to initialize 2013-01-23T09:24:16 debug: 09:24:01,290 DEBUG : probing buses 2013-01-23T09:24:16 debug: 09:24:01,412 DEBUG : waiting for hardware to initialize 2013-01-23T09:24:16 info: 09:24:04,507 INFO : getting kickstart file 2013-01-23T09:24:16 info: 09:24:04,530 INFO : doing kickstart... setting it up 2013-01-23T09:24:16 debug: 09:24:04,531 DEBUG : activating device eth0 2013-01-23T09:24:16 info: 09:24:10,548 INFO : wait_for_iface_activation (2309): device eth0 activated 2013-01-23T09:24:16 info: 09:24:10,550 INFO : file location: http://10.0.168.2/cblr/svc/op/ks/system/slave-1 2013-01-23T09:24:16 info: 09:24:10,551 INFO : transferring http://10.0.168.2/cblr/svc/op/ks/system/slave-1 2013-01-23T09:24:16 info: 09:24:11,511 INFO : setting up kickstart 2013-01-23T09:24:16 info: 09:24:11,511 INFO : kickstart forcing text mode 2013-01-23T09:24:16 info: 09:24:11,511 INFO : kickstartFromUrl 2013-01-23T09:24:16 info: 09:24:11,511 INFO : results of url ks, url http://10.0.168.2:8080/centos/6.3/nailgun/x86_64 2013-01-23T09:24:16 err: 09:24:11,512 ERROR : got to setupCdrom without a CD device 2013-01-23T09:24:16 info: 09:24:11,512 INFO : no stage2= given, assuming http://10.0.168.2:8080/centos/6.3/nailgun/x86_64/images/install.img 2013-01-23T09:24:16 debug: 09:24:11,512 DEBUG : going to set language to en_US.UTF-8 2013-01-23T09:24:16 info: 09:24:11,512 INFO : setting language to en_US.UTF-8 2013-01-23T09:24:16 info: 09:24:11,551 INFO : starting STEP_METHOD 2013-01-23T09:24:16 debug: 09:24:11,551 DEBUG : loaderData->method is set, adding skipMethodDialog 2013-01-23T09:24:16 debug: 09:24:11,551 DEBUG : skipMethodDialog is set 2013-01-23T09:24:16 info: 09:24:11,560 INFO : starting STEP_STAGE2 2013-01-23T09:24:16 info: 09:24:11,560 INFO : URL_STAGE_MAIN: url is http://10.0.168.2:8080/centos/6.3/nailgun/x86_64/images/install.img 2013-01-23T09:24:16 info: 09:24:11,560 INFO : transferring http://10.0.168.2:8080/centos/6.3/nailgun/x86_64/images/updates.img 2013-01-23T09:24:16 err: 09:24:11,563 ERROR : Error downloading http://10.0.168.2:8080/centos/6.3/nailgun/x86_64/images/updates.img: HTTP response code said error 2013-01-23T09:24:16 info: 09:24:11,565 INFO : transferring http://10.0.168.2:8080/centos/6.3/nailgun/x86_64/images/product.img 2013-01-23T09:24:16 err: 09:24:11,568 ERROR : Error downloading http://10.0.168.2:8080/centos/6.3/nailgun/x86_64/images/product.img: HTTP response code said error 2013-01-23T09:24:16 info: 09:24:11,569 INFO : transferring http://10.0.168.2:8080/centos/6.3/nailgun/x86_64/images/install.img 2013-01-23T09:24:16 info: 09:24:12,077 INFO : mounted loopback device /mnt/runtime on /dev/loop0 as /tmp/install.img 2013-01-23T09:24:16 info: 09:24:12,078 INFO : got stage2 at url http://10.0.168.2:8080/centos/6.3/nailgun/x86_64/images/install.img 2013-01-23T09:24:16 info: 09:24:12,133 INFO : Loading SELinux policy 2013-01-23T09:24:16 info: 09:24:13,072 INFO : getting ready to spawn shell now 2013-01-23T09:24:16 info: 09:24:13,436 INFO : Running anaconda script /usr/bin/anaconda 2013-01-23T09:24:16 info: 09:24:16,109 INFO : CentOS Linux is the highest priority installclass, using it 2013-01-23T09:24:16 warning: 09:24:16,164 WARNING : /usr/lib/python2.6/site-packages/pykickstart/parser.py:713: DeprecationWarning: Script does not end with %end. This syntax has been deprecated. It may be removed from future releases, which will result in a fatal error from kickstart. Please modify your kickstart file to use this updated syntax. 2013-01-23T09:24:17 info: warnings.warn(_(""%s does not end with %%end. This syntax has been deprecated. It may be removed from future releases, which will result in a fatal error from kickstart. Please modify your kickstart file to use this updated syntax."") % _(""Script""), DeprecationWarning) 2013-01-23T09:24:17 info: 2013-01-23T09:24:17 info: 09:24:16,164 INFO : Running kickstart %%pre script(s) 2013-01-23T09:24:17 warning: 09:24:16,165 WARNING : '/bin/sh' specified as full path 2013-01-23T09:24:17 info: 09:24:17,369 INFO : All kickstart %%pre script(s) have been run 2013-01-23T09:24:17 info: 09:24:17,441 INFO : ISCSID is /usr/sbin/iscsid 2013-01-23T09:24:17 info: 09:24:17,442 INFO : no initiator set 2013-01-23T09:24:17 warning: 09:24:17,646 WARNING : '/usr/libexec/fcoe/fcoe_edd.sh' specified as full path 2013-01-23T09:24:18 info: 09:24:17,674 INFO : No FCoE EDD info found: No FCoE boot disk information is found in EDD! 2013-01-23T09:24:18 info: 2013-01-23T09:24:18 info: 09:24:17,674 INFO : no /etc/zfcp.conf; not configuring zfcp 2013-01-23T09:24:18 info: 09:24:17,776 INFO : created new libuser.conf at /tmp/libuser.JtvFQd with instPath=""/mnt/sysimage"" 2013-01-23T09:24:18 info: 09:24:17,777 INFO : anaconda called with cmdline = ['/usr/bin/anaconda', '--stage2', 'http://10.0.168.2:8080/centos/6.3/nailgun/x86_64/images/install.img', '--kickstart', '/tmp/ks.cfg', '-T', '--selinux', '--lang', 'en_US.UTF-8', '--keymap', 'us', '--repo', 'http://10.0.168.2:8080/centos/6.3/nailgun/x86_64'] 2013-01-23T09:24:18 info: 09:24:17,777 INFO : Display mode = t 2013-01-23T09:24:18 info: 09:24:17,777 INFO : Default encoding = utf-8 2013-01-23T09:24:18 info: 09:24:17,898 INFO : Detected 752M of memory 2013-01-23T09:24:18 info: 09:24:17,899 INFO : Swap attempt of 1504M 2013-01-23T09:24:18 info: 09:24:18,372 INFO : ISCSID is /usr/sbin/iscsid 2013-01-23T09:24:18 info: 09:24:18,373 INFO : no initiator set 2013-01-23T09:24:19 warning: 09:24:18,893 WARNING : Timezone UTC set in kickstart is not valid. 2013-01-23T09:24:19 info: 09:24:19,012 INFO : Detected 752M of memory 2013-01-23T09:24:19 info: 09:24:19,012 INFO : Swap attempt of 1504M 2013-01-23T09:24:19 info: 09:24:19,064 INFO : setting installation environment hostname to slave-1.mirantis.com 2013-01-23T09:24:19 warning: 09:24:19,076 WARNING : step installtype does not exist 2013-01-23T09:24:19 warning: 09:24:19,076 WARNING : step confirminstall does not exist 2013-01-23T09:24:19 warning: 09:24:19,077 WARNING : step complete does not exist 2013-01-23T09:24:19 warning: 09:24:19,077 WARNING : step complete does not exist 2013-01-23T09:24:19 warning: 09:24:19,077 WARNING : step complete does not exist 2013-01-23T09:24:19 warning: 09:24:19,077 WARNING : step complete does not exist 2013-01-23T09:24:19 warning: 09:24:19,078 WARNING : step complete does not exist 2013-01-23T09:24:19 warning: 09:24:19,078 WARNING : step complete does not exist 2013-01-23T09:24:19 warning: 09:24:19,078 WARNING : step complete does not exist 2013-01-23T09:24:19 warning: 09:24:19,078 WARNING : step complete does not exist 2013-01-23T09:24:19 warning: 09:24:19,079 WARNING : step complete does not exist 2013-01-23T09:24:19 warning: 09:24:19,079 WARNING : step complete does not exist 2013-01-23T09:24:19 info: 09:24:19,080 INFO : moving (1) to step setuptime 2013-01-23T09:24:19 debug: 09:24:19,081 DEBUG : setuptime is a direct step 2013-01-23T09:24:19 warning: 09:24:19,081 WARNING : '/usr/sbin/hwclock' specified as full path 2013-01-23T09:24:20 info: 09:24:20,002 INFO : leaving (1) step setuptime 2013-01-23T09:24:20 info: 09:24:20,003 INFO : moving (1) to step autopartitionexecute 2013-01-23T09:24:20 debug: 09:24:20,003 DEBUG : autopartitionexecute is a direct step 2013-01-23T09:24:20 info: 09:24:20,143 INFO : leaving (1) step autopartitionexecute 2013-01-23T09:24:20 info: 09:24:20,143 INFO : moving (1) to step storagedone 2013-01-23T09:24:20 debug: 09:24:20,144 DEBUG : storagedone is a direct step 2013-01-23T09:24:20 info: 09:24:20,144 INFO : leaving (1) step storagedone 2013-01-23T09:24:20 info: 09:24:20,144 INFO : moving (1) to step enablefilesystems 2013-01-23T09:24:20 debug: 09:24:20,144 DEBUG : enablefilesystems is a direct step 2013-01-23T09:25:01 debug: 09:25:00,646 DEBUG : notifying kernel of 'change' event on device /sys/class/block/vda1 2013-01-23T09:25:01 info: 09:25:01,684 INFO : failed to set SELinux context for /mnt/sysimage: [Errno 95] Operation not supported 2013-01-23T09:25:01 debug: 09:25:01,684 DEBUG : isys.py:mount()- going to mount /dev/vda1 on /mnt/sysimage as ext4 with options defaults 2013-01-23T09:25:01 debug: 09:25:01,704 DEBUG : isys.py:mount()- going to mount //dev on /mnt/sysimage/dev as bind with options defaults,bind 2013-01-23T09:25:01 debug: 09:25:01,715 DEBUG : isys.py:mount()- going to mount devpts on /mnt/sysimage/dev/pts as devpts with options gid=5,mode=620 2013-01-23T09:25:02 debug: 09:25:01,728 DEBUG : isys.py:mount()- going to mount tmpfs on /mnt/sysimage/dev/shm as tmpfs with options defaults 2013-01-23T09:25:02 info: 09:25:01,742 INFO : failed to get default SELinux context for /proc: [Errno 2] No such file or directory 2013-01-23T09:25:02 debug: 09:25:01,742 DEBUG : isys.py:mount()- going to mount proc on /mnt/sysimage/proc as proc with options defaults 2013-01-23T09:25:02 info: 09:25:01,746 INFO : failed to get default SELinux context for /proc: [Errno 2] No such file or directory 2013-01-23T09:25:02 debug: 09:25:01,755 DEBUG : isys.py:mount()- going to mount sysfs on /mnt/sysimage/sys as sysfs with options defaults 2013-01-23T09:25:02 info: 09:25:01,762 INFO : leaving (1) step enablefilesystems 2013-01-23T09:25:02 info: 09:25:01,762 INFO : moving (1) to step bootloadersetup 2013-01-23T09:25:02 debug: 09:25:01,762 DEBUG : bootloadersetup is a direct step 2013-01-23T09:25:02 info: 09:25:01,765 INFO : leaving (1) step bootloadersetup 2013-01-23T09:25:02 info: 09:25:01,765 INFO : moving (1) to step reposetup 2013-01-23T09:25:02 debug: 09:25:01,766 DEBUG : reposetup is a direct step 2013-01-23T09:25:02 err: 09:25:01,779 ERROR : Error downloading treeinfo file: [Errno 14] PYCURL ERROR 22 - ""The requested URL returned error: 404"" 2013-01-23T09:25:02 err: 09:25:01,917 ERROR : Error downloading treeinfo file: [Errno 14] PYCURL ERROR 22 - ""The requested URL returned error: 404"" 2013-01-23T09:25:02 err: 09:25:01,921 ERROR : Error downloading treeinfo file: [Errno 14] PYCURL ERROR 22 - ""The requested URL returned error: 404"" 2013-01-23T09:25:02 info: 09:25:01,922 INFO : added repository Nailgun with URL http://10.0.168.2:8080/centos/6.3/nailgun/x86_64 2013-01-23T09:25:02 debug: 09:25:01,930 DEBUG : Grabbing http://10.0.168.2:8080/centos/6.3/nailgun/x86_64/repodata/repomd.xml 2013-01-23T09:25:02 debug: 09:25:01,937 DEBUG : Grabbing http://10.0.168.2:8080/centos/6.3/nailgun/x86_64/repodata/primary.xml.gz 2013-01-23T09:25:02 debug: 09:25:01,944 DEBUG : Grabbing http://10.0.168.2:8080/centos/6.3/nailgun/x86_64/repodata/comps.xml 2013-01-23T09:25:04 info: 09:25:04,547 INFO : leaving (1) step reposetup 2013-01-23T09:25:04 info: 09:25:04,547 INFO : moving (1) to step basepkgsel 2013-01-23T09:25:04 debug: 09:25:04,547 DEBUG : basepkgsel is a direct step 2013-01-23T09:25:04 warning: 09:25:04,665 WARNING : not adding Base group 2013-01-23T09:25:05 info: 09:25:04,810 INFO : leaving (1) step basepkgsel 2013-01-23T09:25:05 info: 09:25:04,811 INFO : moving (1) to step postselection 2013-01-23T09:25:05 debug: 09:25:04,811 DEBUG : postselection is a direct step 2013-01-23T09:25:05 info: 09:25:04,814 INFO : selected kernel package for kernel 2013-01-23T09:25:05 debug: 09:25:05,546 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/fs/ext4/ext4.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,546 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/fs/mbcache.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,547 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/fs/jbd2/jbd2.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,547 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/scsi/fcoe/fcoe.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,547 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/scsi/fcoe/libfcoe.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,547 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/scsi/libfc/libfc.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,547 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/scsi/scsi_transport_fc.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,547 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/scsi/scsi_tgt.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,547 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/crypto/xts.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,547 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/crypto/lrw.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,547 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/crypto/gf128mul.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,548 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/crypto/sha256_generic.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,548 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/crypto/cbc.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,548 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/dm-crypt.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,548 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/dm-round-robin.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,548 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/dm-multipath.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,548 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/dm-snapshot.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,548 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/dm-mirror.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,548 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/dm-region-hash.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,549 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/dm-log.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,549 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/dm-zero.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,549 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/dm-mod.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,549 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/linear.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,549 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/raid10.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,549 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/raid456.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,549 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/crypto/async_tx/async_raid6_recov.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,549 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/crypto/async_tx/async_pq.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,549 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/lib/raid6/raid6_pq.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,549 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/crypto/async_tx/async_xor.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,549 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/crypto/xor.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,550 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/crypto/async_tx/async_memcpy.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,550 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/crypto/async_tx/async_tx.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,550 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/raid1.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,550 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/md/raid0.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,550 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/infiniband/hw/mlx4/mlx4_ib.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,550 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/net/mlx4/mlx4_en.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,550 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/net/mlx4/mlx4_core.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,550 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/infiniband/ulp/ipoib/ib_ipoib.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,550 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/infiniband/core/ib_cm.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,550 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/infiniband/core/ib_sa.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,551 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/infiniband/core/ib_mad.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,551 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/infiniband/core/ib_core.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,551 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/block/virtio_blk.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,551 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/net/virtio_net.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,551 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/ata/pata_acpi.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,551 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/ata/ata_generic.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,551 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/ata/ata_piix.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,551 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/virtio/virtio_pci.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,551 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/virtio/virtio_ring.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,551 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/virtio/virtio.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,551 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/net/ipv6/ipv6.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,551 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/firmware/iscsi_ibft.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,552 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/scsi/iscsi_boot_sysfs.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,552 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/input/misc/pcspkr.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,552 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/firmware/edd.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,552 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/block/floppy.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,552 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/scsi/iscsi_tcp.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,552 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/scsi/libiscsi_tcp.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,552 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/scsi/libiscsi.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,552 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/drivers/scsi/scsi_transport_iscsi.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,553 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/fs/squashfs/squashfs.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,553 DEBUG : Checking for DUD module /lib/modules/2.6.32-279.el6.x86_64/kernel/fs/cramfs/cramfs.ko.gz 2013-01-23T09:25:05 debug: 09:25:05,553 DEBUG : selecting kernel-devel 2013-01-23T09:25:05 debug: 09:25:05,561 DEBUG : no package matching kernel-devel.x86_64 2013-01-23T09:25:05 debug: 09:25:05,571 DEBUG : no package matching authconfig 2013-01-23T09:25:05 debug: 09:25:05,580 DEBUG : no package matching system-config-firewall-base 2013-01-23T09:25:08 info: 09:25:08,036 INFO : leaving (1) step postselection 2013-01-23T09:25:08 info: 09:25:08,037 INFO : moving (1) to step install 2013-01-23T09:25:08 info: 09:25:08,039 INFO : leaving (1) step install 2013-01-23T09:25:08 info: 09:25:08,040 INFO : moving (1) to step preinstallconfig 2013-01-23T09:25:08 debug: 09:25:08,040 DEBUG : preinstallconfig is a direct step 2013-01-23T09:25:08 debug: 09:25:08,045 DEBUG : isys.py:mount()- going to mount /selinux on /mnt/sysimage/selinux as selinuxfs with options defaults 2013-01-23T09:25:08 debug: 09:25:08,055 DEBUG : isys.py:mount()- going to mount /proc/bus/usb on /mnt/sysimage/proc/bus/usb as usbfs with options defaults 2013-01-23T09:25:08 info: 09:25:08,069 INFO : copy_to_sysimage: source '/etc/multipath/wwids' does not exist. 2013-01-23T09:25:08 info: 09:25:08,069 INFO : copy_to_sysimage: source '/etc/multipath/bindings' does not exist. 2013-01-23T09:25:08 info: 09:25:08,081 INFO : copy_to_sysimage: source '/etc/multipath/wwids' does not exist. 2013-01-23T09:25:08 info: 09:25:08,081 INFO : copy_to_sysimage: source '/etc/multipath/bindings' does not exist. 2013-01-23T09:25:08 info: 09:25:08,086 INFO : leaving (1) step preinstallconfig 2013-01-23T09:25:08 info: 09:25:08,086 INFO : moving (1) to step installpackages 2013-01-23T09:25:08 debug: 09:25:08,086 DEBUG : installpackages is a direct step 2013-01-23T09:25:08 info: 09:25:08,087 INFO : Preparing to install packages 2013-01-23T09:25:10 info: Installing libgcc-4.4.6-4.el6.x86_64 2013-01-23T09:25:10 info: warning: libgcc-4.4.6-4.el6.x86_64: Header V3 RSA/SHA1 Signature, key ID c105b9de: NOKEY 2013-01-23T09:25:10 info: Installing setup-2.8.14-16.el6.noarch 2013-01-23T09:25:10 info: Installing filesystem-2.4.30-3.el6.x86_64 2013-01-23T09:25:11 info: Installing basesystem-10.0-4.el6.noarch 2013-01-23T09:25:11 info: Installing kernel-headers-2.6.32-279.19.1.el6.centos.plus.x86_64 2013-01-23T09:25:11 info: Installing ca-certificates-2010.63-3.el6_1.5.noarch 2013-01-23T09:25:11 info: Installing ncurses-base-5.7-3.20090208.el6.x86_64 2013-01-23T09:25:12 info: Installing tzdata-2012i-2.el6.noarch 2013-01-23T09:25:13 info: Installing glibc-common-2.12-1.80.el6_3.6.x86_64 2013-01-23T09:25:25 info: Installing nss-softokn-freebl-3.12.9-11.el6.x86_64 2013-01-23T09:25:25 info: Installing glibc-2.12-1.80.el6_3.6.x86_64 2013-01-23T09:25:28 info: Installing ncurses-libs-5.7-3.20090208.el6.x86_64 2013-01-23T09:25:28 info: Installing bash-4.1.2-9.el6_2.x86_64 2013-01-23T09:25:28 info: Installing libattr-2.4.44-7.el6.x86_64 2013-01-23T09:25:29 info: Installing libcap-2.16-5.5.el6.x86_64 2013-01-23T09:25:29 info: Installing zlib-1.2.3-27.el6.x86_64 2013-01-23T09:25:29 info: Installing info-4.13a-8.el6.x86_64 2013-01-23T09:25:29 info: Installing db4-4.7.25-17.el6.x86_64 2013-01-23T09:25:29 info: Installing libacl-2.2.49-6.el6.x86_64 2013-01-23T09:25:29 info: Installing audit-libs-2.2-2.el6.x86_64 2013-01-23T09:25:29 info: Installing libcom_err-1.41.12-12.el6.x86_64 2013-01-23T09:25:29 info: Installing nspr-4.9.1-2.el6_3.x86_64 2013-01-23T09:25:29 info: Installing popt-1.13-7.el6.x86_64 2013-01-23T09:25:29 info: Installing chkconfig-1.3.49.3-2.el6.x86_64 2013-01-23T09:25:29 info: Installing nss-util-3.13.5-1.el6_3.x86_64 2013-01-23T09:25:30 info: Installing bzip2-libs-1.0.5-7.el6_0.x86_64 2013-01-23T09:25:30 info: Installing libsepol-2.0.41-4.el6.x86_64 2013-01-23T09:25:30 info: Installing libselinux-2.0.94-5.3.el6.x86_64 2013-01-23T09:25:30 info: Installing shadow-utils-4.1.4.2-13.el6.x86_64 2013-01-23T09:25:30 info: Installing sed-4.2.1-10.el6.x86_64 2013-01-23T09:25:30 info: Installing glib2-2.22.5-7.el6.x86_64 2013-01-23T09:25:30 info: Installing gamin-0.1.10-9.el6.x86_64 2013-01-23T09:25:31 info: Installing libstdc++-4.4.6-4.el6.x86_64 2013-01-23T09:25:31 info: Installing gmp-4.3.1-7.el6_2.2.x86_64 2013-01-23T09:25:31 info: Installing readline-6.0-4.el6.x86_64 2013-01-23T09:25:31 info: Installing sqlite-3.6.20-1.el6.x86_64 2013-01-23T09:25:31 info: Installing file-libs-5.04-13.el6.x86_64 2013-01-23T09:25:31 info: Installing dbus-libs-1.2.24-7.el6_3.x86_64 2013-01-23T09:25:32 info: Installing lua-5.1.4-4.1.el6.x86_64 2013-01-23T09:25:32 info: Installing pcre-7.8-4.el6.x86_64 2013-01-23T09:25:32 info: Installing grep-2.6.3-3.el6.x86_64 2013-01-23T09:25:32 info: Installing libidn-1.18-2.el6.x86_64 2013-01-23T09:25:32 info: Installing gawk-3.1.7-9.el6.x86_64 2013-01-23T09:25:32 info: Installing libuuid-2.17.2-12.7.el6_3.x86_64 2013-01-23T09:25:32 info: Installing libblkid-2.17.2-12.7.el6_3.x86_64 2013-01-23T09:25:32 info: Installing xz-libs-4.999.9-0.3.beta.20091007git.el6.x86_64 2013-01-23T09:25:32 info: Installing elfutils-libelf-0.152-1.el6.x86_64 2013-01-23T09:25:32 info: Installing gdbm-1.8.0-36.el6.x86_64 2013-01-23T09:25:32 info: Installing perl-Pod-Escapes-1.04-127.el6.x86_64 2013-01-23T09:25:32 info: Installing perl-libs-5.10.1-127.el6.x86_64 2013-01-23T09:25:32 info: Installing perl-Module-Pluggable-3.90-127.el6.x86_64 2013-01-23T09:25:32 info: Installing perl-version-0.77-127.el6.x86_64 2013-01-23T09:25:33 info: Installing perl-Pod-Simple-3.13-127.el6.x86_64 2013-01-23T09:25:33 info: Installing perl-5.10.1-127.el6.x86_64 2013-01-23T09:25:39 info: Installing libgpg-error-1.7-4.el6.x86_64 2013-01-23T09:25:39 info: Installing findutils-4.4.2-6.el6.x86_64 2013-01-23T09:25:39 info: Installing libselinux-utils-2.0.94-5.3.el6.x86_64 2013-01-23T09:25:39 info: Installing iptables-1.4.7-5.1.el6_2.x86_64 2013-01-23T09:25:39 info: Installing cyrus-sasl-lib-2.1.23-13.el6_3.1.x86_64 2013-01-23T09:25:39 info: Installing cpio-2.10-11.el6_3.x86_64 2013-01-23T09:25:39 info: Installing binutils-2.20.51.0.2-5.34.el6.x86_64 2013-01-23T09:25:40 info: Installing which-2.19-6.el6.x86_64 2013-01-23T09:25:40 info: Installing libedit-2.11-4.20080712cvs.1.el6.x86_64 2013-01-23T09:25:40 info: Installing sysvinit-tools-2.87-4.dsf.el6.x86_64 2013-01-23T09:25:40 info: Installing tcp_wrappers-libs-7.6-57.el6.x86_64 2013-01-23T09:25:40 info: Installing expat-2.0.1-11.el6_2.x86_64 2013-01-23T09:25:40 info: Installing pth-2.0.7-9.3.el6.x86_64 2013-01-23T09:25:41 info: Installing dbus-glib-0.86-5.el6.x86_64 2013-01-23T09:25:41 info: Installing iproute-2.6.32-20.el6.x86_64 2013-01-23T09:25:41 info: Installing libgcrypt-1.4.5-9.el6_2.2.x86_64 2013-01-23T09:25:41 info: Installing grubby-7.0.15-3.el6.x86_64 2013-01-23T09:25:41 info: Installing libnih-1.0.1-7.el6.x86_64 2013-01-23T09:25:41 info: Installing upstart-0.6.5-12.el6.x86_64 2013-01-23T09:25:41 info: Installing file-5.04-13.el6.x86_64 2013-01-23T09:25:41 info: Installing nss-softokn-3.12.9-11.el6.x86_64 2013-01-23T09:25:41 info: Installing ppl-0.10.2-11.el6.x86_64 2013-01-23T09:25:41 info: Installing cloog-ppl-0.15.7-1.2.el6.x86_64 2013-01-23T09:25:42 info: Installing mpfr-2.4.1-6.el6.x86_64 2013-01-23T09:25:42 info: Installing cpp-4.4.6-4.el6.x86_64 2013-01-23T09:25:43 info: Installing libusb-0.1.12-23.el6.x86_64 2013-01-23T09:25:43 info: Installing libutempter-1.1.5-4.1.el6.x86_64 2013-01-23T09:25:43 info: Installing MAKEDEV-3.24-6.el6.x86_64 2013-01-23T09:25:43 info: Installing vim-minimal-7.2.411-1.8.el6.x86_64 2013-01-23T09:25:43 info: Installing procps-3.2.8-23.el6.x86_64 2013-01-23T09:25:43 info: Installing psmisc-22.6-15.el6_0.1.x86_64 2013-01-23T09:25:43 info: Installing net-tools-1.60-110.el6_2.x86_64 2013-01-23T09:25:43 info: Installing checkpolicy-2.0.22-1.el6.x86_64 2013-01-23T09:25:44 info: Installing libselinux-ruby-2.0.94-5.3.el6.x86_64 2013-01-23T09:25:44 info: Installing augeas-libs-0.9.0-4.el6.x86_64 2013-01-23T09:25:44 info: Installing tar-1.23-7.el6.x86_64 2013-01-23T09:25:44 info: Installing bzip2-1.0.5-7.el6_0.x86_64 2013-01-23T09:25:44 info: Installing pinentry-0.7.6-6.el6.x86_64 2013-01-23T09:25:46 info: Installing libss-1.41.12-12.el6.x86_64 2013-01-23T09:25:46 info: Installing e2fsprogs-libs-1.41.12-12.el6.x86_64 2013-01-23T09:25:46 info: Installing db4-utils-4.7.25-17.el6.x86_64 2013-01-23T09:25:46 info: Installing libgomp-4.4.6-4.el6.x86_64 2013-01-23T09:25:46 info: Installing diffutils-2.8.1-28.el6.x86_64 2013-01-23T09:25:46 info: Installing libxml2-2.7.6-8.el6_3.3.x86_64 2013-01-23T09:25:47 info: Installing glibc-headers-2.12-1.80.el6_3.6.x86_64 2013-01-23T09:25:48 info: Installing glibc-devel-2.12-1.80.el6_3.6.x86_64 2013-01-23T09:25:49 info: Installing ncurses-5.7-3.20090208.el6.x86_64 2013-01-23T09:25:49 info: Installing groff-1.18.1.4-21.el6.x86_64 2013-01-23T09:25:50 info: Installing less-436-10.el6.x86_64 2013-01-23T09:25:50 info: Installing coreutils-libs-8.4-19.el6.x86_64 2013-01-23T09:25:50 info: Installing gzip-1.3.12-18.el6.x86_64 2013-01-23T09:25:50 info: Installing cracklib-2.8.16-4.el6.x86_64 2013-01-23T09:25:50 info: Installing cracklib-dicts-2.8.16-4.el6.x86_64 2013-01-23T09:25:51 info: Installing coreutils-8.4-19.el6.x86_64 2013-01-23T09:25:52 info: Installing pam-1.1.1-10.el6_2.1.x86_64 2013-01-23T09:25:54 info: Installing module-init-tools-3.9-20.el6.x86_64 2013-01-23T09:25:55 info: Installing hwdata-0.233-7.8.el6.noarch 2013-01-23T09:25:57 info: Installing redhat-logos-60.0.14-12.el6.centos.noarch 2013-01-23T09:25:59 info: Installing plymouth-scripts-0.8.3-24.el6.centos.x86_64 2013-01-23T09:25:59 info: Installing logrotate-3.7.8-15.el6.x86_64 2013-01-23T09:25:59 info: Installing nss-3.13.5-1.el6_3.x86_64 2013-01-23T09:25:59 info: Installing nss-sysinit-3.13.5-1.el6_3.x86_64 2013-01-23T09:25:59 info: Installing nss-tools-3.13.5-1.el6_3.x86_64 2013-01-23T09:26:00 info: Installing openldap-2.4.23-26.el6_3.2.x86_64 2013-01-23T09:26:00 info: Installing compat-readline5-5.2-17.1.el6.x86_64 2013-01-23T09:26:00 info: Installing libcap-ng-0.6.4-3.el6_0.1.x86_64 2013-01-23T09:26:00 info: Installing ethtool-2.6.33-0.3.el6.x86_64 2013-01-23T09:26:00 info: Installing mingetty-1.08-5.el6.x86_64 2013-01-23T09:26:00 info: Installing vconfig-1.9-8.1.el6.x86_64 2013-01-23T09:26:00 info: Installing dmidecode-2.11-2.el6.x86_64 2013-01-23T09:26:00 info: Installing keyutils-libs-1.4-4.el6.x86_64 2013-01-23T09:26:00 info: Installing krb5-libs-1.9-33.el6_3.3.x86_64 2013-01-23T09:26:01 info: Installing openssl-1.0.0-25.el6_3.1.x86_64 2013-01-23T09:26:01 info: Installing ruby-libs-1.8.7.352-7.el6_2.x86_64 2013-01-23T09:26:03 info: Installing ruby-1.8.7.352-7.el6_2.x86_64 2013-01-23T09:26:03 info: Installing libssh2-1.2.2-11.el6_3.x86_64 2013-01-23T09:26:03 info: Installing libcurl-7.19.7-26.el6_2.4.x86_64 2013-01-23T09:26:03 info: Installing curl-7.19.7-26.el6_2.4.x86_64 2013-01-23T09:26:03 info: Installing rpm-libs-4.8.0-27.el6.x86_64 2013-01-23T09:26:04 info: Installing rpm-4.8.0-27.el6.x86_64 2013-01-23T09:26:04 info: Installing gnupg2-2.0.14-4.el6.x86_64 2013-01-23T09:26:04 info: Installing gpgme-1.1.8-3.el6.x86_64 2013-01-23T09:26:05 info: Installing ruby-irb-1.8.7.352-7.el6_2.x86_64 2013-01-23T09:26:05 info: Installing ruby-rdoc-1.8.7.352-7.el6_2.x86_64 2013-01-23T09:26:06 info: Installing rubygems-1.3.7-1.el6.noarch 2013-01-23T09:26:06 info: Installing rubygem-stomp-1.1.8-1.el6.noarch 2013-01-23T09:26:06 info: warning: rubygem-stomp-1.1.8-1.el6.noarch: Header V3 RSA/SHA256 Signature, key ID 0608b895: NOKEY 2013-01-23T09:26:06 info: Installing mcollective-common-2.2.2-1.el6.noarch 2013-01-23T09:26:06 info: warning: mcollective-common-2.2.2-1.el6.noarch: Header V4 RSA/SHA1 Signature, key ID 4bd6ec30: NOKEY 2013-01-23T09:26:07 info: Installing mcollective-2.2.2-1.el6.noarch 2013-01-23T09:26:07 info: Installing ruby-augeas-0.4.1-1.el6.x86_64 2013-01-23T09:26:07 info: Installing ruby-shadow-1.4.1-13.el6.x86_64 2013-01-23T09:26:07 info: Installing fipscheck-lib-1.2.0-7.el6.x86_64 2013-01-23T09:26:07 info: Installing fipscheck-1.2.0-7.el6.x86_64 2013-01-23T09:26:07 info: Installing ustr-1.0.4-9.1.el6.x86_64 2013-01-23T09:26:07 info: Installing libsemanage-2.0.43-4.1.el6.x86_64 2013-01-23T09:26:07 info: Installing libffi-3.0.5-3.2.el6.x86_64 2013-01-23T09:26:07 info: Installing python-libs-2.6.6-29.el6_3.3.x86_64 2013-01-23T09:26:08 info: Installing python-2.6.6-29.el6_3.3.x86_64 2013-01-23T09:26:12 info: Installing scapy-2.0.0.10-5.el6.noarch 2013-01-23T09:26:13 info: Installing yum-metadata-parser-1.1.2-16.el6.x86_64 2013-01-23T09:26:13 info: Installing pygpgme-0.1-18.20090824bzr68.el6.x86_64 2013-01-23T09:26:13 info: Installing rpm-python-4.8.0-27.el6.x86_64 2013-01-23T09:26:13 info: Installing python-iniparse-0.3.1-2.1.el6.noarch 2013-01-23T09:26:13 info: Installing python-pycurl-7.19.0-8.el6.x86_64 2013-01-23T09:26:13 info: Installing python-urlgrabber-3.9.1-8.el6.noarch 2013-01-23T09:26:13 info: Installing yum-plugin-fastestmirror-1.1.30-14.el6.noarch 2013-01-23T09:26:13 info: Installing yum-3.2.29-30.el6.centos.noarch 2013-01-23T09:26:13 info: Installing dash-0.5.5.1-3.1.el6.x86_64 2013-01-23T09:26:14 info: Installing pciutils-libs-3.1.4-11.el6.x86_64 2013-01-23T09:26:14 info: Installing pciutils-3.1.4-11.el6.x86_64 2013-01-23T09:26:14 info: Installing facter-1.6.17-1.el6.x86_64 2013-01-23T09:26:14 info: Installing plymouth-core-libs-0.8.3-24.el6.centos.x86_64 2013-01-23T09:26:14 info: Installing kbd-misc-1.15-11.el6.noarch 2013-01-23T09:26:14 info: Installing centos-release-6-3.el6.centos.9.x86_64 2013-01-23T09:26:14 info: Installing iputils-20071127-16.el6.x86_64 2013-01-23T09:26:14 info: Installing util-linux-ng-2.17.2-12.7.el6_3.x86_64 2013-01-23T09:26:15 info: Installing initscripts-9.03.31-2.el6.centos.1.x86_64 2013-01-23T09:26:16 info: Installing udev-147-2.42.el6.x86_64 2013-01-23T09:26:16 info: Installing openssh-5.3p1-81.el6_3.x86_64 2013-01-23T09:26:16 info: Installing kbd-1.15-11.el6.x86_64 2013-01-23T09:26:16 info: Installing rsyslog-5.8.10-2.el6.x86_64 2013-01-23T09:26:17 info: Installing exim-4.72-4.el6.x86_64 2013-01-23T09:26:17 info: Installing crontabs-1.10-33.el6.noarch 2013-01-23T09:26:17 info: Installing cronie-anacron-1.4.4-7.el6.x86_64 2013-01-23T09:26:17 info: Installing cronie-1.4.4-7.el6.x86_64 2013-01-23T09:26:17 info: Installing ntpdate-4.2.4p8-2.el6.centos.x86_64 2013-01-23T09:26:17 info: Installing dhcp-common-4.1.1-31.0.1.P1.el6.centos.1.x86_64 2013-01-23T09:26:17 info: Installing kernel-firmware-2.6.32-279.19.1.el6.centos.plus.noarch 2013-01-23T09:26:19 info: Installing libdrm-2.4.25-2.el6.x86_64 2013-01-23T09:26:19 info: Installing plymouth-0.8.3-24.el6.centos.x86_64 2013-01-23T09:26:19 info: Installing dracut-004-284.el6_3.1.noarch 2013-01-23T09:26:19 info: Installing dracut-kernel-004-284.el6_3.1.noarch 2013-01-23T09:26:19 info: Installing kernel-2.6.32-279.19.1.el6.centos.plus.x86_64 2013-01-23T09:26:27 info: Installing dhclient-4.1.1-31.0.1.P1.el6.centos.1.x86_64 2013-01-23T09:26:27 info: Installing ntp-4.2.4p8-2.el6.centos.x86_64 2013-01-23T09:26:27 info: Installing openssh-clients-5.3p1-81.el6_3.x86_64 2013-01-23T09:26:27 info: Installing openssh-server-5.3p1-81.el6_3.x86_64 2013-01-23T09:26:28 info: Installing puppet-2.7.19-1.el6.noarch 2013-01-23T09:26:30 info: Installing policycoreutils-2.0.83-19.24.el6.x86_64 2013-01-23T09:26:31 info: Installing nailgun-net-check-0.0.2-1.x86_64 2013-01-23T09:26:31 info: Installing grub-0.97-77.el6.x86_64 2013-01-23T09:26:31 info: Installing nailgun-mcagents-0.1.0-1.x86_64 2013-01-23T09:26:31 info: Installing ruby-devel-1.8.7.352-7.el6_2.x86_64 2013-01-23T09:26:31 info: Installing wget-1.12-1.4.el6.x86_64 2013-01-23T09:26:31 info: Installing sudo-1.7.4p5-13.el6_3.x86_64 2013-01-23T09:26:31 info: Installing nailgun-agent-0.1.0-1.x86_64 2013-01-23T09:26:31 info: Installing gcc-4.4.6-4.el6.x86_64 2013-01-23T09:26:35 info: Installing e2fsprogs-1.41.12-12.el6.x86_64 2013-01-23T09:26:35 info: Installing iptables-ipv6-1.4.7-5.1.el6_2.x86_64 2013-01-23T09:26:35 info: Installing acl-2.2.49-6.el6.x86_64 2013-01-23T09:26:35 info: Installing make-3.81-20.el6.x86_64 2013-01-23T09:26:35 info: Installing attr-2.4.44-7.el6.x86_64 2013-01-23T09:27:14 info: 09:27:14,602 INFO : leaving (1) step installpackages 2013-01-23T09:27:14 info: 09:27:14,603 INFO : moving (1) to step postinstallconfig 2013-01-23T09:27:14 debug: 09:27:14,604 DEBUG : postinstallconfig is a direct step 2013-01-23T09:27:14 info: 09:27:14,628 INFO : leaving (1) step postinstallconfig 2013-01-23T09:27:14 info: 09:27:14,628 INFO : moving (1) to step writeconfig 2013-01-23T09:27:14 debug: 09:27:14,629 DEBUG : writeconfig is a direct step 2013-01-23T09:27:14 info: 09:27:14,629 INFO : Writing main configuration 2013-01-23T09:27:14 warning: 09:27:14,638 WARNING : '/usr/sbin/authconfig' specified as full path 2013-01-23T09:27:14 err: 09:27:14,661 ERROR : Error running /usr/sbin/authconfig: No such file or directory 2013-01-23T09:27:14 err: 09:27:14,662 ERROR : Error running ['--update', '--nostart', '--enableshadow', '--passalgo=sha512']: Error running /usr/sbin/authconfig: No such file or directory 2013-01-23T09:27:14 warning: 09:27:14,665 WARNING : '/usr/sbin/lokkit' specified as full path 2013-01-23T09:27:14 err: 09:27:14,680 ERROR : Error running /usr/sbin/lokkit: No such file or directory 2013-01-23T09:27:14 err: 09:27:14,681 ERROR : lokkit run failed: Error running /usr/sbin/lokkit: No such file or directory 2013-01-23T09:27:14 warning: 09:27:14,681 WARNING : '/usr/sbin/lokkit' specified as full path 2013-01-23T09:27:14 err: 09:27:14,694 ERROR : Error running /usr/sbin/lokkit: No such file or directory 2013-01-23T09:27:14 err: 09:27:14,695 ERROR : lokkit run failed: Error running /usr/sbin/lokkit: No such file or directory 2013-01-23T09:27:14 info: 09:27:14,798 INFO : removing libuser.conf at /tmp/libuser.JtvFQd 2013-01-23T09:27:14 info: 09:27:14,799 INFO : created new libuser.conf at /tmp/libuser.JtvFQd with instPath=""/mnt/sysimage"" 2013-01-23T09:27:14 info: 09:27:14,821 INFO : leaving (1) step writeconfig 2013-01-23T09:27:14 info: 09:27:14,821 INFO : moving (1) to step firstboot 2013-01-23T09:27:14 debug: 09:27:14,821 DEBUG : firstboot is a direct step 2013-01-23T09:27:14 info: 09:27:14,821 INFO : leaving (1) step firstboot 2013-01-23T09:27:14 info: 09:27:14,822 INFO : moving (1) to step instbootloader 2013-01-23T09:27:14 debug: 09:27:14,822 DEBUG : instbootloader is a direct step 2013-01-23T09:27:14 info: *** FINISHED INSTALLING PACKAGES *** 2013-01-23T09:27:15 warning: 09:27:14,989 WARNING : '/sbin/grub-install' specified as full path 2013-01-23T09:27:15 warning: 09:27:15,038 WARNING : '/sbin/grub' specified as full path 2013-01-23T09:27:17 info: 09:27:17,176 INFO : leaving (1) step instbootloader 2013-01-23T09:27:17 info: 09:27:17,177 INFO : moving (1) to step reipl 2013-01-23T09:27:17 debug: 09:27:17,177 DEBUG : reipl is a direct step 2013-01-23T09:27:17 info: 09:27:17,177 INFO : leaving (1) step reipl 2013-01-23T09:27:17 info: 09:27:17,177 INFO : moving (1) to step writeksconfig 2013-01-23T09:27:17 debug: 09:27:17,177 DEBUG : writeksconfig is a direct step 2013-01-23T09:27:17 info: 09:27:17,177 INFO : Writing autokickstart file 2013-01-23T09:27:17 info: 09:27:17,183 INFO : leaving (1) step writeksconfig 2013-01-23T09:27:17 info: 09:27:17,183 INFO : moving (1) to step setfilecon 2013-01-23T09:27:17 debug: 09:27:17,183 DEBUG : setfilecon is a direct step 2013-01-23T09:27:17 info: 09:27:17,184 INFO : setting SELinux contexts for anaconda created files 2013-01-23T09:27:19 info: 09:27:18,940 INFO : leaving (1) step setfilecon 2013-01-23T09:27:19 info: 09:27:18,940 INFO : moving (1) to step copylogs 2013-01-23T09:27:19 debug: 09:27:18,941 DEBUG : copylogs is a direct step 2013-01-23T09:27:19 info: 09:27:18,941 INFO : Copying anaconda logs 2013-01-23T09:27:19 info: 09:27:18,943 INFO : leaving (1) step copylogs 2013-01-23T09:27:19 info: 09:27:18,943 INFO : moving (1) to step methodcomplete 2013-01-23T09:27:19 debug: 09:27:18,943 DEBUG : methodcomplete is a direct step 2013-01-23T09:27:19 info: 09:27:18,943 INFO : leaving (1) step methodcomplete 2013-01-23T09:27:19 info: 09:27:18,943 INFO : moving (1) to step postscripts 2013-01-23T09:27:19 debug: 09:27:18,944 DEBUG : postscripts is a direct step 2013-01-23T09:27:19 info: 09:27:18,944 INFO : Running kickstart %%post script(s) 2013-01-23T09:27:19 warning: 09:27:18,946 WARNING : '/bin/sh' specified as full path 2013-01-23T09:28:30 info: 09:28:30,453 INFO : All kickstart %%post script(s) have been run 2013-01-23T09:28:30 info: 09:28:30,454 INFO : leaving (1) step postscripts 2013-01-23T09:28:30 info: 09:28:30,454 INFO : moving (1) to step dopostaction 2013-01-23T09:28:30 debug: 09:28:30,455 DEBUG : dopostaction is a direct step 2013-01-23T09:28:30 info: 09:28:30,455 INFO : leaving (1) step dopostaction",1903,839
openstack%2Fmurano~proposed%2Fjuno~I6396385f55300c20d968046511f26e9a3a55419c,openstack/murano,proposed/juno,I6396385f55300c20d968046511f26e9a3a55419c,Fix defects in API specification,MERGED,2014-10-15 16:02:41.000000000,2014-10-17 09:42:06.000000000,2014-10-17 09:42:05.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-10-15 16:02:41.000000000', 'files': ['doc/source/specification/murano-api.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/2b7a38414e03a27181f25907f33a696f476cd475', 'message': 'Fix defects in API specification\n\nChange-Id: I6396385f55300c20d968046511f26e9a3a55419c\n'}]",1,128688,2b7a38414e03a27181f25907f33a696f476cd475,13,4,1,7549,,,0,"Fix defects in API specification

Change-Id: I6396385f55300c20d968046511f26e9a3a55419c
",git fetch https://review.opendev.org/openstack/murano refs/changes/88/128688/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/specification/murano-api.rst'],1,2b7a38414e03a27181f25907f33a696f476cd475,update_docs,+----------+----------------------------------+-----------------------------------+----------------------------------+ | Method | URI | Header | Description | +==========+==================================+===================================+==================================+ | GET | /environments/{id} | X-Configuration-Session (optional)| Response detailed information | | | | | about Environment including | | | | | child entities | +----------+----------------------------------+-----------------------------------+----------------------------------+| POST | /environments/<env_id>/services | X-Configuration-Session |,+----------+----------------------------------+----------------------------------+ | Method | URI | Description | +==========+==================================+==================================+ | GET | /environments/{id} | Response detailed information | | | | about Environment including | | | | child entities | +----------+----------------------------------+----------------------------------+| POST | /environments/<env_id>/services | X-Configuration-Session (optional) |,8,8
openstack%2Fheat~stable%2Fjuno~Ibf7cf581c92bdfc53b161324f4a48a968abd2dee,openstack/heat,stable/juno,Ibf7cf581c92bdfc53b161324f4a48a968abd2dee,Opening stable/juno,MERGED,2014-10-16 15:02:03.000000000,2014-10-17 09:40:28.000000000,2014-10-17 09:40:27.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-10-16 15:02:03.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/heat/commit/a6e96514d37e288a37bce8fb5b4c8afa1970b706', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: Ibf7cf581c92bdfc53b161324f4a48a968abd2dee\n'}]",0,128951,a6e96514d37e288a37bce8fb5b4c8afa1970b706,8,3,1,308,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: Ibf7cf581c92bdfc53b161324f4a48a968abd2dee
",git fetch https://review.opendev.org/openstack/heat refs/changes/51/128951/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,a6e96514d37e288a37bce8fb5b4c8afa1970b706,stable-juno,version = 2014.2.1,version = 2014.2,2,1
openstack%2Fneutron~stable%2Fjuno~Ib6bd6b400ae15d5ae1bcb99b11221d58b9acae70,openstack/neutron,stable/juno,Ib6bd6b400ae15d5ae1bcb99b11221d58b9acae70,Opening stable/juno,MERGED,2014-10-16 14:58:21.000000000,2014-10-17 09:37:50.000000000,2014-10-17 09:37:49.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 5892}, {'_account_id': 6502}, {'_account_id': 6854}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-16 14:58:21.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7ccb76a00c9bd3896b84ea67076f27a0892861c3', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: Ib6bd6b400ae15d5ae1bcb99b11221d58b9acae70\n'}]",0,128947,7ccb76a00c9bd3896b84ea67076f27a0892861c3,21,16,1,308,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: Ib6bd6b400ae15d5ae1bcb99b11221d58b9acae70
",git fetch https://review.opendev.org/openstack/neutron refs/changes/47/128947/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,7ccb76a00c9bd3896b84ea67076f27a0892861c3,stable-juno,version = 2014.2.1,version = 2014.2,2,1
openstack%2Foslo.db~master~Id30858f9c4c7a2bfb7f9313d47930845fe354a70,openstack/oslo.db,master,Id30858f9c4c7a2bfb7f9313d47930845fe354a70,ModelsMigrationsSync:add correct server_default check for Enum,MERGED,2014-09-11 11:21:19.000000000,2014-10-17 09:35:15.000000000,2014-10-17 09:25:04.000000000,"[{'_account_id': 3}, {'_account_id': 6524}, {'_account_id': 6849}, {'_account_id': 7249}, {'_account_id': 7491}, {'_account_id': 7536}, {'_account_id': 11816}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-09-11 11:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/d48ea77c16c6c5210856fffc68b9ea6e4758e41d', 'message': 'ModelsMigrationsSync:add correct server_default check for Enum\n\nIf Column which type is Enum has server_default it is compared\nincorrectly for PostgreSQL.\n\nFor example, Column(\'test\', sa.Enum(\'one\', \'two\', name=\'enum\'),\n                     server_default=\'one\').\nIn model it has DefaultClause(\'one\', for_update=False)) alembic\nfinds it different from server variant ""\'one\'::enum"".\n\nChange-Id: Id30858f9c4c7a2bfb7f9313d47930845fe354a70\n'}, {'number': 2, 'created': '2014-09-15 11:47:53.000000000', 'files': ['tests/sqlalchemy/test_migrations.py', 'oslo/db/sqlalchemy/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/436dfdc737cdd1f0d330eac7b3c61b739bf75016', 'message': 'ModelsMigrationsSync:add correct server_default check for Enum\n\nIf Column which type is Enum has server_default it is compared\nincorrectly for PostgreSQL.\n\nFor example, Column(\'test\', sa.Enum(\'one\', \'two\', name=\'enum\'),\n                     server_default=\'one\').\nIn model it has DefaultClause(\'one\', for_update=False)) alembic\nfinds it different from server variant ""\'one\'::enum"".\n\nChange-Id: Id30858f9c4c7a2bfb7f9313d47930845fe354a70\n'}]",0,120746,436dfdc737cdd1f0d330eac7b3c61b739bf75016,22,8,2,7249,,,0,"ModelsMigrationsSync:add correct server_default check for Enum

If Column which type is Enum has server_default it is compared
incorrectly for PostgreSQL.

For example, Column('test', sa.Enum('one', 'two', name='enum'),
                     server_default='one').
In model it has DefaultClause('one', for_update=False)) alembic
finds it different from server variant ""'one'::enum"".

Change-Id: Id30858f9c4c7a2bfb7f9313d47930845fe354a70
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/46/120746/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/sqlalchemy/test_migrations.py', 'oslo/db/sqlalchemy/test_migrations.py']",2,d48ea77c16c6c5210856fffc68b9ea6e4758e41d,," if isinstance(meta_col.type, sqlalchemy.Enum): if meta_def is None or insp_def is None: return meta_def != insp_def return insp_def != ""'%s'::%s"" % (meta_def.arg, meta_col.type.name) elif isinstance(meta_col.type, sqlalchemy.String):"," if isinstance(meta_col.type, sqlalchemy.String):",13,1
openstack%2Fmurano~master~I9b15d59f8c84a1dd985ee9a16180ebdac4b68d89,openstack/murano,master,I9b15d59f8c84a1dd985ee9a16180ebdac4b68d89,Update article about functional tests,MERGED,2014-09-09 11:18:57.000000000,2014-10-17 09:28:37.000000000,2014-10-17 09:28:36.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 10063}]","[{'number': 1, 'created': '2014-09-09 11:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/9607186356b935d00608d5f94df84d2ed3e09290', 'message': 'Update article about functional tests\n\nChange-Id: I9b15d59f8c84a1dd985ee9a16180ebdac4b68d89\n'}, {'number': 2, 'created': '2014-10-08 07:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/78e5e3c1173851d6d64a37fb55cb9485759fccf6', 'message': 'Update article about functional tests\n\nChange-Id: I9b15d59f8c84a1dd985ee9a16180ebdac4b68d89\n'}, {'number': 3, 'created': '2014-10-17 08:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/68f9e1549f0b8d9bcb973f36f6ab28fb96f25318', 'message': 'Update article about functional tests\n\nChange-Id: I9b15d59f8c84a1dd985ee9a16180ebdac4b68d89\n'}, {'number': 4, 'created': '2014-10-17 08:32:40.000000000', 'files': ['doc/source/articles/test_docs.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/83053624c372080bc5e9ac4df43abab46fac1a56', 'message': 'Update article about functional tests\n\nChange-Id: I9b15d59f8c84a1dd985ee9a16180ebdac4b68d89\n'}]",1,120063,83053624c372080bc5e9ac4df43abab46fac1a56,20,9,4,7549,,,0,"Update article about functional tests

Change-Id: I9b15d59f8c84a1dd985ee9a16180ebdac4b68d89
",git fetch https://review.opendev.org/openstack/murano refs/changes/63/120063/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/articles/test_docs.rst'],1,9607186356b935d00608d5f94df84d2ed3e09290,docs,"This page describes automated tests for a Murano project: * where tests are located * how they are run * how execute tests on a local machine * how to find the the root of problems with FAILed tests Murano Continuous Integration ServiceMurano project has separate CI server, which runs tests for all commits and verifies that new code does not break anything.Murano CI url: https://murano-ci.mirantis.com/jenkins/ Anyone can login to that server, using launchpad credentials. There you can find each job for each repository: one for the **murano** and another one for **murano-dashboard**. * ""murano-dashboard-integration-tests-ubuntu-devstack\*"" verifies each commit to murano-dashboard repository * ""murano-engine-integration-tests-ubuntu-devstack\*"" verifies each commit to murano repositoryAll jobs are run on fresh installation of operation system and all components are installed on each run.Murano project has a Web User Interface and all possible user scenarios should be tested. All UI tests are located at the https://github.com/stackforge/murano-dashboard/tree/master/muranodashboard/tests/functional Automated tests for Murano Web UI are written in Python using special Selenium library. This library is used to automate web browser interaction from Python. For more information please visit http://selenium-python.readthedocs.org/ * Install Python module, called nose performing one of the following commands **easy_install nose** or **pip install nose*** Install external Python libraries, which are required for Murano Web UI tests: **testtools** and **selenium** Download and run tests: * git clone https://github.com/stackforge/murano-dashboard* * Change default settings: * Copy muranodashboard/tests/functional/config/config_file.conf.example to config_file.conf * Set appropriate urls and credentials for your OpenStack lab. Only admin users are appropriate. [murano] All tests are kept in *sanity_check.py* and divided into 5 test suites: * TestSuiteSmoke - verification of Murano panels; check, that could be open without errors. * TestSuiteEnvironment - verification of all operations with environment are finished successfully. * TestSuiteImage - verification of operations with images. * TestSuiteFields - verification of custom fields validators. * TestSuitePackages - verification of operations with Murano packages. * TestSuiteApplications - verification of Application Catalog page and of application creation process. To specify which tests/suite to run, pass test/suite names on the command line: * to run all tests: ``nosetests sanity_check.p`` * to run a single suite: ``nosetests sanity_check.py:<test suite name>`` * to run a single test: ``nosetests sanity_check.py:<test suite name>.<test name>`` In case of SUCCESS execution, you should see something like this: ......................... Ran 34 tests in 1.440s OK In case of FAILURE, folder with screenshots of the last operation of tests that finished with errors would be created. It's located in *muranodashboard/tests/functional* folder. There are also a number of command line options that can be used to control the test execution and generated outputs. For more details about *nosetests*, try: :: $ nosetests -hTempest tests for Murano are located at the: https://github.com/stackforge/murano/tree/master/murano/tests/functional API Tests +++++++++ Murano API tests are run on devstack gate and located at https://github.com/stackforge/murano/tree/master/murano/tests/functional/api/v1 * *test_murano_envs.py* contains test suite with actions on murano's environments(create, delete, get and etc.) * *test_murano_sessions.py* contains test suite with actions on murano's sessions(create, delete, get and etc.) * *test_murano_services.py* contains test suite with actions on murano's services(create, delete, get and etc.) * *test_murano_repository.py* contains test suite with actions on murano's package repository Engine Tests +++++++++++++++++++ Murano Engine Tests are run on murano-ci : https://github.com/stackforge/murano/tree/master/murano/tests/functional/engine * *base.py* contains base test class and tests with actions on deploy Murano services such as 'Telnet' and 'Apache'. Command Line Tests +++++++++++++++++++++++++ Murano CLI tests case are currently in the middle of creation. The current scope is read only operations on a cloud that are hard to test via unit tests. All tests have description and execution steps in there docstrings.","This page describes automated tests for OpenStack Murano project: how you can download and run tests, how understand the root of problems with FAILed tests and detailed description about each test, which executes upon every commit. Murano Continious Integration ServiceMurano project has the CI server, which tests all commits for Murano components and verifies that new code does not break nothing.Murano CI url: https://murano-ci.mirantis.com/jenkins/ There are two jobs for the **murano** repository and two jobs for the **murano-dashboard** repository : one of them runs on Ubuntu, another one on CentOS. Here you can see several Jenkins jobs with different targets: * Jobs ""murano-dashboard-integration-tests-\*"" allow to verify each commit to murano-dashboard repository on different distributive * Jobs ""murano-engine-app-deployment-tests-\*"" allow to verify each commit to murano repository on different distributiveMurano project has a Web User Interface and we have the test suite for Murano Web UI. All UI tests are located at the https://github.com/stackforge/murano-dashboard/functionaltests All automated tests for Murano Web UI are written on Python using advanced Selenium library.This library allows to find Web elements using captions for fields and other information to find elements without/with xpath. For more information please visit http://selenium-python.readthedocs.org/ How To Run ----------* Install Python module called nose using **easy_install nose** or **pip install nose*** Install external Python libraries which are required for Murano Web UI tests: **testtools** and **selenium** Download tests and run: *git clone https://github.com/stackforge/murano-dashboard* * Change default settings: * Open functionaltests/config/config_file.conf * Set appropriate urls and credentials. [common]* Go to the ""functionaltests"" directory where tests are stored * Some applications need to be uploaded to the Application Catalog since some tests use them. To upload a set of standard packages from special Murano repository need to create and execute following script which clone repository with packages, archive and store them in 'functionaltests' folder: git_url=""https://github.com/murano-project/murano-app-incubator"" clone_dir=""murano-app-incubator"" git clone $git_url $clone_dir cd $clone_dir for package_dir in io.murano.* do if [ -d ""$package_dir"" ]; then if [ -f ""${package_dir}/manifest.yaml"" ]; then sudo bash make-package.sh $package_dir fi fi done * All preparation is done. * All tests are grouped for a few suites. To specify which tests/suite to run, pass test/suite names on the command line: * to run all tests: *nosetests sanity_check.py* * to run single suite: *nosetests sanity_check.py:<test suite name>* * to run single test: *nosetests sanity_check.py:<test suite name>.<test name>* In case of SUCCESS you should see something like this: ......................... Ran 34 tests in 1.440s OK There are also a number of command line options that can be used to control the test execution and generated outputs. For help with nosetests’ many command-line options, try: *nosetests -h*Tempest tests for Murano are located at the: https://github.com/stackforge/murano/tree/master/functionaltestsTests on API which running on devstack gate can be founded here https://github.com/stackforge/murano/tree/master/functionaltests/api * test_murano_envs.py contains test suite with actions on murano's environments(create, delete, get and etc.) * test_murano_sessions.py contains test suite with actions on murano's sessions(create, delete, get and etc.) * test_murano_services.py contains test suite with actions on murano's services(create, delete, get and etc.) * test_murano_repository.py contains test suite with actions on murano's package repository Tests on engine which running on murano-ci : https://github.com/stackforge/murano/tree/master/functionaltests/engine * base.py contains base test class and tests with actions on deploy murano's services If you want to know, what steps this test performs, you can see test's scenario in code. For example: :: @attr(type='smoke') def test_get_environment(self): """""" Get environment by id Test create environment, afterthat test try to get environment's info, using environment's id, and finally delete this environment Target component: Murano Scenario: 1. Send request to create environment. 2. Send request to get environment 3. Send request to delete environment """""" resp, env = self.create_environment('test') self.environments.append(env) resp, infa = self.get_environment_by_id(env['id']) self.assertEqual(200, resp.status) self.assertEqual('test', infa['name']) self.delete_environment(env['id']) self.environments.pop(self.environments.index(env))",73,79
openstack%2Ftricircle~master~I59ecb92aca4b816dfcd4a3d0821a6297b625d136,openstack/tricircle,master,I59ecb92aca4b816dfcd4a3d0821a6297b625d136,Modify the arguments number lack bug,MERGED,2014-10-15 13:24:06.000000000,2014-10-17 09:22:21.000000000,2014-10-17 09:22:21.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2014-10-15 13:24:06.000000000', 'files': ['novaproxy/nova/compute/manager_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/d60ac07ff9e92bd0eb981829d5af3a566ddf5fb6', 'message': ""Modify the arguments number lack bug\n\nThe _heal_proxy_ports method in manager_proxy.py lacks an argument\nof 'instance', which make the vm can not launched.\n\nChange-Id: I59ecb92aca4b816dfcd4a3d0821a6297b625d136\n""}]",0,128647,d60ac07ff9e92bd0eb981829d5af3a566ddf5fb6,6,2,1,9684,,,0,"Modify the arguments number lack bug

The _heal_proxy_ports method in manager_proxy.py lacks an argument
of 'instance', which make the vm can not launched.

Change-Id: I59ecb92aca4b816dfcd4a3d0821a6297b625d136
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/47/128647/1 && git format-patch -1 --stdout FETCH_HEAD,['novaproxy/nova/compute/manager_proxy.py'],1,d60ac07ff9e92bd0eb981829d5af3a566ddf5fb6,," def _heal_proxy_ports(self, context, instance, network_info):"," def _heal_proxy_ports(self, context, network_info):",1,1
openstack%2Fhorizon~master~I994d72a754b7b04b2c4e2055852a184e0e023f67,openstack/horizon,master,I994d72a754b7b04b2c4e2055852a184e0e023f67,Angularize project instance table,ABANDONED,2014-09-25 18:49:59.000000000,2014-10-17 09:21:49.000000000,,"[{'_account_id': 3}, {'_account_id': 9576}]","[{'number': 1, 'created': '2014-09-25 18:49:59.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/templates/instances/_instances_table.html', 'openstack_dashboard/dashboards/project/instances/tables.py', 'openstack_dashboard/dashboards/project/instances/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/569c5c8d1ca07b37bd579aa9b34b9f42fd8ab230', 'message': 'Angularize project instance table\n\nThis patch is part of the larger initiative to move rendering logic to\nclientside. As demonstrated here, it can be achieve in 3 easy steps:\n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: I994d72a754b7b04b2c4e2055852a184e0e023f67\nImplements: blueprint table-client-rendering\n'}]",0,124130,569c5c8d1ca07b37bd579aa9b34b9f42fd8ab230,4,2,1,9576,,,0,"Angularize project instance table

This patch is part of the larger initiative to move rendering logic to
clientside. As demonstrated here, it can be achieve in 3 easy steps:

1. Inherit JSONTableMixin in your view and specify an encoder class.
2. Define a data-binding template (can even include scripts).
3. Reference this template in your table by overriding template.

Change-Id: I994d72a754b7b04b2c4e2055852a184e0e023f67
Implements: blueprint table-client-rendering
",git fetch https://review.opendev.org/openstack/horizon refs/changes/30/124130/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/instances/templates/instances/_instances_table.html', 'openstack_dashboard/dashboards/project/instances/tables.py', 'openstack_dashboard/dashboards/project/instances/views.py']",3,569c5c8d1ca07b37bd579aa9b34b9f42fd8ab230,bp/table-client-rendering,"from openstack_dashboard.utils import json_encoder class IndexView(tables.JSONTableMixin, tables.DataTableView): encoder_class = json_encoder.OSAPIJSONEncoder", class IndexView(tables.DataTableView):,78,3
openstack%2Fironic~stable%2Fjuno~If630ee6db112eef46987bf6aae9eead6a44c11ad,openstack/ironic,stable/juno,If630ee6db112eef46987bf6aae9eead6a44c11ad,Opening stable/juno,MERGED,2014-10-16 16:08:57.000000000,2014-10-17 09:21:45.000000000,2014-10-17 09:21:44.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 8106}, {'_account_id': 8125}, {'_account_id': 9656}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-10-16 16:08:57.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/ironic/commit/9a038a7e5d19ac47ca77119ed9691f2810e34065', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: If630ee6db112eef46987bf6aae9eead6a44c11ad\n'}]",0,128982,9a038a7e5d19ac47ca77119ed9691f2810e34065,12,6,1,308,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: If630ee6db112eef46987bf6aae9eead6a44c11ad
",git fetch https://review.opendev.org/openstack/ironic refs/changes/82/128982/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,9a038a7e5d19ac47ca77119ed9691f2810e34065,stable-juno,version = 2014.2.1,version = 2014.2,2,1
openstack%2Fhorizon~master~Ied8220c04701e5cc9b2ff68857073012b087d55a,openstack/horizon,master,Ied8220c04701e5cc9b2ff68857073012b087d55a,Angularize admin images table,ABANDONED,2014-07-17 00:09:30.000000000,2014-10-17 09:21:38.000000000,,"[{'_account_id': 3}, {'_account_id': 6620}, {'_account_id': 9576}]","[{'number': 1, 'created': '2014-07-17 00:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8930bd307d26aba7b8322830dfbe3ff3d9af3d6b', 'message': 'Angularize admin images table\n\nThis patch is part of the larger initiative to move rendering logic to\nclientside. As demonstrated here, it can be achieve in 3 easy steps:\n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: Ied8220c04701e5cc9b2ff68857073012b087d55a\nImplements: blueprint table-client-rendering\n'}, {'number': 2, 'created': '2014-07-29 23:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6e2b1507f30c7fa234fd262fba4cf1e54f6896e4', 'message': 'Angularize admin images table\n\nThis patch is part of the larger initiative to move rendering logic to\nclientside. As demonstrated here, it can be achieve in 3 easy steps:\n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: Ied8220c04701e5cc9b2ff68857073012b087d55a\nImplements: blueprint table-client-rendering\n'}, {'number': 3, 'created': '2014-08-04 23:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f17b75fbe0433f299aeb3e3e0a0514b05a8bc048', 'message': 'Angularize admin images table\n\nThis patch is part of the larger initiative to move rendering logic to\nclientside. As demonstrated here, it can be achieve in 3 easy steps:\n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: Ied8220c04701e5cc9b2ff68857073012b087d55a\nImplements: blueprint table-client-rendering\n'}, {'number': 4, 'created': '2014-09-25 18:38:23.000000000', 'files': ['openstack_dashboard/dashboards/admin/images/tables.py', 'openstack_dashboard/dashboards/admin/images/templates/images/table.html', 'openstack_dashboard/dashboards/admin/images/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c2a19d239b12015a541ad294dbe4734468f72c6d', 'message': 'Angularize admin images table\n\nThis patch is part of the larger initiative to move rendering logic to\nclientside. As demonstrated here, it can be achieve in 3 easy steps:\n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: Ied8220c04701e5cc9b2ff68857073012b087d55a\nImplements: blueprint table-client-rendering'}]",0,107532,c2a19d239b12015a541ad294dbe4734468f72c6d,15,3,4,9576,,,0,"Angularize admin images table

This patch is part of the larger initiative to move rendering logic to
clientside. As demonstrated here, it can be achieve in 3 easy steps:

1. Inherit JSONTableMixin in your view and specify an encoder class.
2. Define a data-binding template (can even include scripts).
3. Reference this template in your table by overriding template.

Change-Id: Ied8220c04701e5cc9b2ff68857073012b087d55a
Implements: blueprint table-client-rendering",git fetch https://review.opendev.org/openstack/horizon refs/changes/32/107532/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/images/tables.py', 'openstack_dashboard/dashboards/admin/images/templates/images/table.html', 'openstack_dashboard/dashboards/admin/images/views.py']",3,8930bd307d26aba7b8322830dfbe3ff3d9af3d6b,bp/table-client-rendering,"from openstack_dashboard.utils import json_encoder class IndexView(tables.JSONTableMixin, tables.DataTableView): encoder_class = json_encoder.OSAPIJSONEncoder", class IndexView(tables.DataTableView):,26,1
openstack%2Ffuel-astute~master~I1db257875c164ada60600bf976cb828a41585248,openstack/fuel-astute,master,I1db257875c164ada60600bf976cb828a41585248,Granular deployment (basic version),MERGED,2014-09-17 11:04:34.000000000,2014-10-17 09:21:35.000000000,2014-10-17 09:21:35.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8882}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 9037}]","[{'number': 1, 'created': '2014-09-17 11:04:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/310d5b01e2e549c8516a4c57f582501875767368', 'message': 'Granular deployment (basic version)\n\nSupport new way to deploy tasks. Instead of direct\npuppet run using one big universal manifests use\ngroup of tasks with pre and post checks.\n\nSupport old deployment process for backward\ncompatibility.\n\nNew feature:\n- add new sync agent for tasks;\n- add tasks processing;\n- add tests.\n\nRefactoring:\n* move pre deployment actions to separate class;\n* tests refactoring.\n\nRelated to blueprint granular-deployment-based-on-tasks\n\nChange-Id: I1db257875c164ada60600bf976cb828a41585248\n'}, {'number': 2, 'created': '2014-09-24 17:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/79d64d9b91e6408131fb9574332e6b5be843519d', 'message': 'Granular deployment (basic version)\n\nSupport new way to deploy tasks. Instead of direct\npuppet run using one big universal manifests use\ngroup of tasks with pre and post checks.\n\nSupport old deployment process for backward\ncompatibility.\n\nNew feature:\n- add new sync agent for tasks;\n- add tasks processing;\n- add tests.\n\nRefactoring:\n* move pre deployment actions to separate class;\n* tests refactoring.\n\nRelated to blueprint granular-deployment-based-on-tasks\n\nChange-Id: I1db257875c164ada60600bf976cb828a41585248\n'}, {'number': 3, 'created': '2014-09-26 18:56:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/2965bfbd62a24187eedba26f61d1d3d2651d5952', 'message': 'Granular deployment (basic version)\n\nSupport new way to deploy tasks. Instead of direct\npuppet run using one big universal manifests use\ngroup of tasks with pre and post checks.\n\nSupport old deployment process for backward\ncompatibility.\n\nNew feature:\n- add new sync agent for tasks;\n- add tasks processing;\n- add tests.\n\nRefactoring:\n* move pre deployment actions to separate class;\n* tests refactoring;\n* unify tasks and puppet methods.\n\nRelated to blueprint granular-deployment-based-on-tasks\n\nChange-Id: I1db257875c164ada60600bf976cb828a41585248\n'}, {'number': 4, 'created': '2014-09-30 10:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/e58d038a7897237a4a89371449cba34bed6e80b0', 'message': 'Granular deployment (basic version)\n\nSupport new way to deploy tasks. Instead of direct\npuppet run using one big universal manifests use\ngroup of tasks with pre and post checks.\n\nSupport old deployment process for backward\ncompatibility.\n\nNew feature:\n- add tasks processing;\n- add tests.\n\nRefactoring:\n* move pre deployment actions to separate class;\n* tests refactoring;\n* unify tasks and puppet methods.\n\nRelated to blueprint granular-deployment-based-on-tasks\n\nChange-Id: I1db257875c164ada60600bf976cb828a41585248\n'}, {'number': 5, 'created': '2014-10-03 19:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/867d9c45ec3677e255f0fe54f953de0622e7c727', 'message': 'Granular deployment (basic version)\n\nSupport new way to deploy tasks. Instead of direct\npuppet run using one big universal manifests use\ngroup of tasks with pre and post checks.\n\nSupport old deployment process for backward\ncompatibility.\n\nNew feature:\n- add tasks processing;\n- add tests.\n\nRefactoring:\n* move pre deployment actions to separate class;\n* tests refactoring;\n* unify tasks and puppet methods.\n\nRelated to blueprint granular-deployment-based-on-tasks\n\nChange-Id: I1db257875c164ada60600bf976cb828a41585248\n'}, {'number': 6, 'created': '2014-10-16 11:44:36.000000000', 'files': ['spec/unit/pre_deployment_actions/enable_puppet_deploy_hook_spec.rb', 'lib/astute/deploy_actions.rb', 'lib/astute/pre_deployment_actions/generate_ssh_keys.rb', 'lib/astute/server/dispatcher.rb', 'lib/astute/config.rb', 'spec/unit/pre_deployment_actions/sync_time_hook_spec.rb', 'lib/astute/deployment_engine/tasklib.rb', 'spec/unit/tasklib_spec.rb', 'lib/astute/pre_deployment_actions/sync_tasks.rb', 'spec/unit/pre_deployment_actions/sync_puppet_stuff_hook_spec.rb', 'spec/unit/deploy_actions_spec.rb', 'spec/unit/pre_deployment_actions/update_repo_sources_hook_spec.rb', 'lib/astute/orchestrator.rb', 'lib/astute/deployment_engine.rb', 'spec/unit/pre_deployment_actions/generate_ssh_keys_hook_spec.rb', 'lib/astute/pre_deployment_actions/update_repo_sources.rb', 'spec/unit/nailyfact_deploy_spec.rb', 'lib/astute/pre_deployment_actions/sync_time.rb', 'spec/unit/deployment_engine_spec.rb', 'README.md', 'lib/astute/pre_deployment_actions/sync_puppet_stuff.rb', 'lib/astute/pre_deploy_actions/upload_facts.rb', 'lib/astute/pre_deployment_actions/upload_ssh_keys.rb', 'spec/unit/pre_deployment_actions/upload_ssh_keys_hook_spec.rb', 'lib/astute.rb', 'lib/astute/pre_deployment_actions/enable_puppet_deploy.rb', 'lib/astute/deployment_engine/nailyfact.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/a9013b46333467c345388b06cbd928dfccf14656', 'message': 'Granular deployment (basic version)\n\nSupport new way to deploy tasks. Instead of direct\npuppet run using one big universal manifests use\ngroup of tasks with pre and post checks.\n\nSupport old deployment process for backward\ncompatibility.\n\nNew feature:\n- add tasks processing;\n- add tests.\n\nRefactoring:\n* move pre deployment actions to separate class;\n* tests refactoring;\n* unify tasks and puppet methods.\n\nRelated to blueprint granular-deployment-based-on-tasks\n\nChange-Id: I1db257875c164ada60600bf976cb828a41585248\n'}]",17,122117,a9013b46333467c345388b06cbd928dfccf14656,43,7,6,8776,,,0,"Granular deployment (basic version)

Support new way to deploy tasks. Instead of direct
puppet run using one big universal manifests use
group of tasks with pre and post checks.

Support old deployment process for backward
compatibility.

New feature:
- add tasks processing;
- add tests.

Refactoring:
* move pre deployment actions to separate class;
* tests refactoring;
* unify tasks and puppet methods.

Related to blueprint granular-deployment-based-on-tasks

Change-Id: I1db257875c164ada60600bf976cb828a41585248
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/17/122117/4 && git format-patch -1 --stdout FETCH_HEAD,"['lib/astute/deploy_actions.rb', 'lib/astute/pre_deployment_actions/generate_ssh_keys.rb', 'lib/astute/server/dispatcher.rb', 'mcagents/syncstuff.rb', 'lib/astute/config.rb', 'spec/unit/pre_deploy_actions/sync_puppet_stuff_hook_spec.rb', 'lib/astute/deployment_engine/tasklib.rb', 'spec/unit/tasklib_spec.rb', 'lib/astute/pre_deployment_actions/sync_tasks.rb', 'spec/unit/pre_deploy_actions/generate_ssh_keys_hook_spec.rb', 'spec/unit/pre_deploy_actions/sync_time_hook_spec.rb', 'lib/astute/orchestrator.rb', 'lib/astute/deployment_engine.rb', 'spec/unit/pre_deploy_actions/update_repo_sources_hook_spec.rb', 'spec/unit/pre_deploy_actions/upload_ssh_keys_hook_spec.rb', 'lib/astute/pre_deployment_actions/update_repo_sources.rb', 'spec/unit/nailyfact_deploy_spec.rb', 'lib/astute/pre_deployment_actions/sync_time.rb', 'spec/unit/deployment_engine_spec.rb', 'lib/astute/pre_deployment_actions/sync_puppet_stuff.rb', 'mcagents/syncstuff.ddl', 'lib/astute/pre_deploy_actions/upload_facts.rb', 'spec/unit/pre_deploy_actions/enable_puppet_deploy_hook_spec.rb', 'lib/astute/pre_deployment_actions/upload_ssh_keys.rb', 'lib/astute.rb', 'lib/astute/pre_deployment_actions/enable_puppet_deploy.rb', 'lib/astute/deployment_engine/nailyfact.rb']",27,310d5b01e2e549c8516a4c57f582501875767368,bp/cinder-neutron-plugins-in-fuel," Astute.logger.info ""#{@ctx.task_id}: Starting deployment""","require 'yaml' nodes.each { |node| upload_facts(node) } Astute.logger.info ""#{@ctx.task_id}: Required attrs/metadata passed via facts extension. Starting deployment."" private def upload_facts(node) Astute.logger.info ""#{@ctx.task_id}: storing metadata for node uid=#{node['uid']}"" Astute.logger.debug ""#{@ctx.task_id}: stores metadata: #{node.to_yaml}"" # This is synchronious RPC call, so we are sure that data were sent and processed remotely upload_mclient = Astute::MClient.new(@ctx, ""uploadfile"", [node['uid']]) upload_mclient.upload(:path => '/etc/astute.yaml', :content => node.to_yaml, :overwrite => true, :parents => true, :permissions => '0600' ) end ",1530,697
openstack%2Fhorizon~master~I40f4bf24173d7c42fc296a5928ae1832f62a0162,openstack/horizon,master,I40f4bf24173d7c42fc296a5928ae1832f62a0162,Angularize admin flavors table,ABANDONED,2014-07-16 22:09:07.000000000,2014-10-17 09:21:28.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 8871}, {'_account_id': 9576}]","[{'number': 1, 'created': '2014-07-16 22:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7e71d902a5d0f14345781fbf5413bb4650051749', 'message': 'Angularize admin flavors table\n\nThis patch is part of the larger initiative to move rendering logic to\nclientside. As demonstrated here, it can be achieve in 3 easy steps:\n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: I40f4bf24173d7c42fc296a5928ae1832f62a0162\nImplements: blueprint table-client-rendering\n'}, {'number': 2, 'created': '2014-07-16 23:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/44a7e84eae4f8daadee5b233432971610eb3463c', 'message': 'Angularize admin flavors table\n\nThis patch is part of the larger initiative to move rendering logic to\nclientside. As demonstrated here, it can be achieve in 3 easy steps:\n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: I40f4bf24173d7c42fc296a5928ae1832f62a0162\nImplements: blueprint table-client-rendering\n'}, {'number': 3, 'created': '2014-07-22 22:25:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/df7ce86e65ad31fa4d8d99f7b5f6f20335a75ea9', 'message': 'Angularize admin flavors table\n\nThis patch is part of the larger initiative to move rendering logic to\nclientside. As demonstrated here, it can be achieve in 3 easy steps: \n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: I40f4bf24173d7c42fc296a5928ae1832f62a0162\nImplements: blueprint table-client-rendering\n'}, {'number': 4, 'created': '2014-07-29 23:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/779c7be15b856d8c1d51516464f1f78a4f9f5862', 'message': 'Angularize admin flavors table\n\nThis patch is part of the larger initiative to move rendering logic to\nclientside. As demonstrated here, it can be achieve in 3 easy steps: \n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: I40f4bf24173d7c42fc296a5928ae1832f62a0162\nImplements: blueprint table-client-rendering\n'}, {'number': 5, 'created': '2014-08-04 23:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1df517f81568613d1e65557e5bab2f0fd0b3b98c', 'message': 'Angularize admin flavors table\n\nThis patch is part of the larger initiative to move rendering logic to\nclientside. As demonstrated here, it can be achieve in 3 easy steps: \n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: I40f4bf24173d7c42fc296a5928ae1832f62a0162\nImplements: blueprint table-client-rendering\n'}, {'number': 6, 'created': '2014-08-09 20:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/29f20ccca69e001604a6ca6744023dfa3cc3b230', 'message': 'Angularize admin flavors table\n\nThis patch is part of the larger initiative to move rendering logic to\nclientside. As demonstrated here, it can be achieve in 3 easy steps: \n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: I40f4bf24173d7c42fc296a5928ae1832f62a0162\nImplements: blueprint table-client-rendering\n'}, {'number': 7, 'created': '2014-09-08 16:08:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9d41fd50f8f12afd2aa3d6276a0e9a0b41c55be8', 'message': 'Angularize admin flavors table\n\nThis patch is part of the larger initiative to move rendering logic to\nclientside. As demonstrated here, it can be achieve in 3 easy steps: \n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: I40f4bf24173d7c42fc296a5928ae1832f62a0162\nImplements: blueprint table-client-rendering\n'}, {'number': 8, 'created': '2014-09-25 18:33:17.000000000', 'files': ['openstack_dashboard/dashboards/admin/flavors/tables.py', 'openstack_dashboard/dashboards/admin/flavors/views.py', 'openstack_dashboard/dashboards/admin/flavors/templates/flavors/table.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ee906a1572e5cab16566d2eca8be67e4e67e7311', 'message': 'Angularize admin flavors table\n\nThis patch is part of the larger initiative to move rendering logic to\nclientside. As demonstrated here, it can be achieve in 3 easy steps:\n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: I40f4bf24173d7c42fc296a5928ae1832f62a0162\nImplements: blueprint table-client-rendering'}]",0,107514,ee906a1572e5cab16566d2eca8be67e4e67e7311,27,4,8,9576,,,0,"Angularize admin flavors table

This patch is part of the larger initiative to move rendering logic to
clientside. As demonstrated here, it can be achieve in 3 easy steps:

1. Inherit JSONTableMixin in your view and specify an encoder class.
2. Define a data-binding template (can even include scripts).
3. Reference this template in your table by overriding template.

Change-Id: I40f4bf24173d7c42fc296a5928ae1832f62a0162
Implements: blueprint table-client-rendering",git fetch https://review.opendev.org/openstack/horizon refs/changes/14/107514/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/flavors/tables.py', 'openstack_dashboard/dashboards/admin/flavors/views.py', 'openstack_dashboard/dashboards/admin/flavors/templates/flavors/table.html']",3,7e71d902a5d0f14345781fbf5413bb4650051749,bp/table-client-rendering," {% extends 'horizon/angular/_table.html' %} {% load i18n %} {% block table_cells %} <td hz-table-checkbox></td> <td>{$ row.cells.name $}</td> <td>{$ row.cells.vcpus $}</td> <td>{$ row.cells.ram $}</td> <td>{$ row.cells.disk $}</td> <td>{$ row.cells.ephemeral $}</td> <td>{$ row.cells.swap $}</td> <td>{$ row.cells.flavor_id $}</td> <td>{$ row.cells.public $}</td> <td>{$ row.cells.extra_specs $}</td> <td class=""actions_column""> <hz-table-row-actions actions=""row.actions"" rid=""row['data-object-id']""> </hz-table-row-actions> </td> {% endblock table_cells %}",,24,1
openstack%2Fzaqar~stable%2Fjuno~I74953e8a91d29b589670836f367b8ca080f11f28,openstack/zaqar,stable/juno,I74953e8a91d29b589670836f367b8ca080f11f28,Opening stable/juno,MERGED,2014-10-16 16:15:16.000000000,2014-10-17 09:19:20.000000000,2014-10-17 09:19:18.000000000,"[{'_account_id': 3}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-10-16 16:15:16.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/fb3254ab720a699129fc8a941cea8eb35c25c7ab', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I74953e8a91d29b589670836f367b8ca080f11f28\n'}]",0,128986,fb3254ab720a699129fc8a941cea8eb35c25c7ab,6,2,1,308,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I74953e8a91d29b589670836f367b8ca080f11f28
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/86/128986/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,fb3254ab720a699129fc8a941cea8eb35c25c7ab,stable-juno,version = 2014.2.1,version = 2014.2,2,1
openstack%2Foslo-incubator~master~I1a1f70bb204d3f43bdacd4ded53225f8416f1639,openstack/oslo-incubator,master,I1a1f70bb204d3f43bdacd4ded53225f8416f1639,Fix build break - switch from str to hash for lookup,MERGED,2014-09-21 21:54:27.000000000,2014-10-17 09:17:17.000000000,2014-09-21 22:32:36.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-09-21 21:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/9d75f485528705ab452db7ad8f481fbfa681ff30', 'message': 'Fix build break - switch from str to hash for lookup\n\nChange-Id: I1a1f70bb204d3f43bdacd4ded53225f8416f1639\n'}, {'number': 2, 'created': '2014-09-21 21:55:02.000000000', 'files': ['openstack/common/rpc/impl_qpid.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/6b65a41dd2653aa9e2558c510fa9d3ca3538a908', 'message': 'Fix build break - switch from str to hash for lookup\n\nCloses-Bug: #1372177\nChange-Id: I1a1f70bb204d3f43bdacd4ded53225f8416f1639\n'}]",0,123017,6b65a41dd2653aa9e2558c510fa9d3ca3538a908,13,2,2,5638,,,0,"Fix build break - switch from str to hash for lookup

Closes-Bug: #1372177
Change-Id: I1a1f70bb204d3f43bdacd4ded53225f8416f1639
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/17/123017/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/rpc/impl_qpid.py'],1,9d75f485528705ab452db7ad8f481fbfa681ff30,bug/1372177, self.consumers[hash(consumer.get_receiver())] = consumer return self.consumers[hash(receiver)], self.consumers[str(consumer.get_receiver())] = consumer return self.consumers[str(receiver)],2,2
openstack%2Fha-guide~master~I34e73d404b49b3286634a66cfe78826a9d4f25b4,openstack/ha-guide,master,I34e73d404b49b3286634a66cfe78826a9d4f25b4,Update highly available RabbitMQ section,MERGED,2014-10-09 00:49:29.000000000,2014-10-17 09:12:08.000000000,2014-10-17 09:12:07.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 6926}, {'_account_id': 10705}]","[{'number': 1, 'created': '2014-10-09 00:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/ac35353842e6a3ffd94d827b2129ae9d6e6cef05', 'message': 'Update highly available RabbitMQ section\n\nEdited note to:\n1. include RabbitMQ version.\n2. remove the statement that Pacemaker with DRDB is preferred.\n\nChange-Id: I34e73d404b49b3286634a66cfe78826a9d4f25b4\nBackport: none\nCloses-bug: #1330738\n'}, {'number': 2, 'created': '2014-10-10 00:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/9785e0a9d92957a001afa727adef037ff7c547d7', 'message': 'Update highly available RabbitMQ section\n\nEdited note to:\n1. include RabbitMQ version.\n2. remove the statement that Pacemaker with DRDB is preferred.\n\nChange-Id: I34e73d404b49b3286634a66cfe78826a9d4f25b4\nBackport: none\nCloses-bug: #1330738\n'}, {'number': 3, 'created': '2014-10-17 01:26:16.000000000', 'files': ['doc/high-availability-guide/controller/section_rabbitmq.xml'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/aade10ab66412e14e4bb6549e2caef962249c047', 'message': 'Update highly available RabbitMQ section\n\nEdited note to:\n1. include RabbitMQ version.\n2. remove the statement that Pacemaker with DRDB is preferred.\n\nChange-Id: I34e73d404b49b3286634a66cfe78826a9d4f25b4\nBackport: none\nCloses-bug: #1330738\n'}]",8,127087,aade10ab66412e14e4bb6549e2caef962249c047,19,6,3,10705,,,0,"Update highly available RabbitMQ section

Edited note to:
1. include RabbitMQ version.
2. remove the statement that Pacemaker with DRDB is preferred.

Change-Id: I34e73d404b49b3286634a66cfe78826a9d4f25b4
Backport: none
Closes-bug: #1330738
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/87/127087/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/high-availability-guide/controller/section_rabbitmq.xml'],1,ac35353842e6a3ffd94d827b2129ae9d6e6cef05,rabbitmq-haguide/darren," <para><link xlink:href=""http://www.rabbitmq.com/ha.html"">active-active mirrored queues</link> is another method for configuring RabbitMQ versions 3.3.5 and earlier for high availability. This is the preferred method by RabbitMQ developers.</para>"," <para>There is an alternative method of configuring RabbitMQ for high availability. That approach, known as <link xlink:href=""http://www.rabbitmq.com/ha.html"">active-active mirrored queues</link>, happens to be the one preferred by the RabbitMQ developers&mdash;however it has shown less than ideal consistency and reliability in OpenStack clusters. Thus, at the time of writing, the Pacemaker/DRBD based approach remains the recommended one for OpenStack environments, although this may change in the near future as RabbitMQ active-active mirrored queues mature.</para>",4,9
openstack%2Fopenstack-manuals~master~Ibf773c642d87c037bacebab2f13b210f0b40014a,openstack/openstack-manuals,master,Ibf773c642d87c037bacebab2f13b210f0b40014a,Added image requirements package in the Image Guide,MERGED,2014-10-16 10:01:41.000000000,2014-10-17 09:09:44.000000000,2014-10-17 09:09:43.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 7923}, {'_account_id': 10705}]","[{'number': 1, 'created': '2014-10-16 10:01:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e1fa3d1e9e027380006b5ad3aeaa3b4374a6a281', 'message': 'Added image requirements package in the Image Guide\n\nAdded dracut-modules-growroot package for CentOS and RHEL\n\nChange-Id: Ibf773c642d87c037bacebab2f13b210f0b40014a\nbackport: none\nCloses-Bug: #1331971\n'}, {'number': 2, 'created': '2014-10-17 00:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/407ee5e82e9eedb9e8c31280bbf3c2cac450f441', 'message': 'Added image requirements package in the Image Guide\n\n1. Added dracut-modules-growroot package for CentOS and RHEL\n2. Fixed a broken link.\n\nChange-Id: Ibf773c642d87c037bacebab2f13b210f0b40014a\nbackport: none\nCloses-Bug: #1331971\n'}, {'number': 3, 'created': '2014-10-17 00:59:33.000000000', 'files': ['doc/image-guide/ch_openstack_images.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/af0877e6f7313d10e2c0495857b7b0c460a263de', 'message': 'Added image requirements package in the Image Guide\n\n1. Added dracut-modules-growroot package for CentOS and RHEL\n2. Fixed a broken link.\n\nChange-Id: Ibf773c642d87c037bacebab2f13b210f0b40014a\nbackport: none\nCloses-Bug: #1331971\n'}]",1,128865,af0877e6f7313d10e2c0495857b7b0c460a263de,13,5,3,10705,,,0,"Added image requirements package in the Image Guide

1. Added dracut-modules-growroot package for CentOS and RHEL
2. Fixed a broken link.

Change-Id: Ibf773c642d87c037bacebab2f13b210f0b40014a
backport: none
Closes-Bug: #1331971
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/65/128865/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/image-guide/ch_openstack_images.xml'],1,e1fa3d1e9e027380006b5ad3aeaa3b4374a6a281,partition_package/darren," <para>The simplest way to support this is to install in your image the:</para> <itemizedlist> <listitem> <para><link xlink:href=""https://launchpad.net/cloud-utils"">cloud-utils</link> package, which contains the <command>growpart</command> tool for extending partitions.</para> </listitem> <listitem> <para><link xlink:href=""https://launchpad.net/cloud-initramfs-tools"">cloud-initramfs-growroot</link> package for Ubuntu, Debian and Fedora, which supports resizing root partition on the first boot.</para> </listitem> <listitem> <para><package>cloud-initramfs-growroot</package> package for Centos and RHEL.</para> </listitem> <listitem> <para><link xlink:href=""https://launchpad.net/cloud-init"">cloud-init</link> package.</para> </listitem> </itemizedlist> <para>With these packages installed, the image"," <para>The simplest way to support this in your image is to install the <link xlink:href=""https://launchpad.net/cloud-utils"" >cloud-utils</link> package (contains the <command>growpart</command> tool for extending partitions), the <link xlink:href=""https://launchpad.net/cloud-initramfs-tools"" >cloud-initramfs-growroot</link> package (which supports resizing root partition on the first boot), and the <link xlink:href=""https://launchpad.net/cloud-init"" ><package>cloud-init</package></link> package into your image. With these installed, the image",23,13
openstack%2Ftripleo-image-elements~master~Ib6a498e469a8ce470c1e376b45efd8103e6f508e,openstack/tripleo-image-elements,master,Ib6a498e469a8ce470c1e376b45efd8103e6f508e,sets novnc endpoint uri to https if tls is enabled,MERGED,2014-10-16 10:16:54.000000000,2014-10-17 09:06:17.000000000,2014-10-17 09:06:16.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4330}, {'_account_id': 7582}, {'_account_id': 12459}]","[{'number': 1, 'created': '2014-10-16 10:16:54.000000000', 'files': ['elements/nova/os-apply-config/etc/nova/nova.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/524669b45f70be0c07196a6dac1f5bf747bce476', 'message': 'sets novnc endpoint uri to https if tls is enabled\n\nIf novnc proxy is being served behind stunnel then the uri\nsent to user needs to be an https endpoint. This patch checks if\nstunnel is set and makes the relevant change\n\nChange-Id: Ib6a498e469a8ce470c1e376b45efd8103e6f508e\n'}]",0,128871,524669b45f70be0c07196a6dac1f5bf747bce476,9,5,1,6896,,,0,"sets novnc endpoint uri to https if tls is enabled

If novnc proxy is being served behind stunnel then the uri
sent to user needs to be an https endpoint. This patch checks if
stunnel is set and makes the relevant change

Change-Id: Ib6a498e469a8ce470c1e376b45efd8103e6f508e
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/71/128871/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/nova/os-apply-config/etc/nova/nova.conf'],1,524669b45f70be0c07196a6dac1f5bf747bce476,novnc/tls-endpoint-if-enabled,{{#stunnel.connect_ip}} novncproxy_base_url=https://{{nova.public_ip}}:6080/vnc_auto.html {{/stunnel.connect_ip}} {{^stunnel.connect_ip}}{{/stunnel.connect_ip}},,5,0
openstack%2Fpython-neutronclient~master~I5e0dd1026803af065a99615e947a145bfc0810f2,openstack/python-neutronclient,master,I5e0dd1026803af065a99615e947a145bfc0810f2,Fix E128 hacking check,MERGED,2014-10-06 10:19:45.000000000,2014-10-17 09:05:15.000000000,2014-10-17 09:05:15.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 7505}]","[{'number': 1, 'created': '2014-10-06 10:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/11cb742ad4e1851414a2bfdf94e4af96ad2298a9', 'message': 'Fix E128 hacking check\n\nRemove E128 from the ignored checks and fix them.\n\nChange-Id: I5e0dd1026803af065a99615e947a145bfc0810f2\n'}, {'number': 2, 'created': '2014-10-06 13:24:18.000000000', 'files': ['neutronclient/neutron/v2_0/networkprofile.py', 'neutronclient/neutron/v2_0/router.py', 'neutronclient/neutron/v2_0/subnet.py', 'neutronclient/neutron/v2_0/nsx/networkgateway.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4d2133c072cf114a1cb10175727e2f737bce56fb', 'message': 'Fix E128 hacking check\n\nRemove E128 from the ignored checks and fix them.\n\nChange-Id: I5e0dd1026803af065a99615e947a145bfc0810f2\n'}]",2,126252,4d2133c072cf114a1cb10175727e2f737bce56fb,12,5,2,7505,,,0,"Fix E128 hacking check

Remove E128 from the ignored checks and fix them.

Change-Id: I5e0dd1026803af065a99615e947a145bfc0810f2
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/52/126252/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/neutron/v2_0/networkprofile.py', 'neutronclient/neutron/v2_0/router.py', 'neutronclient/neutron/v2_0/subnet.py', 'neutronclient/neutron/v2_0/nsx/networkgateway.py', 'tox.ini']",5,11cb742ad4e1851414a2bfdf94e4af96ad2298a9,hacking-update,"ignore = E113,E125,E129,E265,H302,H307,H405","# E128 continuation line under-indented for visual indentignore = E113,E125,E128,E129,E265,H302,H307,H405",13,12
openstack%2Fbarbican~stable%2Fjuno~I0691187846235b2533c0be4a454dd4cdb95638b9,openstack/barbican,stable/juno,I0691187846235b2533c0be4a454dd4cdb95638b9,Opening stable/juno,MERGED,2014-10-16 16:07:28.000000000,2014-10-17 09:03:58.000000000,2014-10-17 09:03:57.000000000,"[{'_account_id': 3}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-10-16 16:07:28.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/barbican/commit/c76e1bb95603d8c96d782e5f268ad69a505b09cd', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I0691187846235b2533c0be4a454dd4cdb95638b9\n'}]",0,128979,c76e1bb95603d8c96d782e5f268ad69a505b09cd,6,2,1,308,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I0691187846235b2533c0be4a454dd4cdb95638b9
",git fetch https://review.opendev.org/openstack/barbican refs/changes/79/128979/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,c76e1bb95603d8c96d782e5f268ad69a505b09cd,stable-juno,version = 2014.2.1,version = 2014.2,2,1
openstack%2Fneutron~master~If0502f57382441fdb4510c81a89794f57a38e696,openstack/neutron,master,If0502f57382441fdb4510c81a89794f57a38e696,Race for l2pop when ports go up/down on same host,MERGED,2014-09-23 09:49:50.000000000,2014-10-17 08:40:05.000000000,2014-10-15 03:39:59.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 1689}, {'_account_id': 2888}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7141}, {'_account_id': 7448}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9093}, {'_account_id': 9361}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12040}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-09-23 09:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/48a771d7c57f032c59279164b97ebb8a32350944', 'message': 'Race for l2pop when ports go up/down on same host\n\nWith l2pop enabled, race exists in delete_port_postcommit\nwhen both create/update_port and delete_port deal with\ndifferent ports on the same host, where such ports are\neither the first (or) last on same network for that host.\nThis race happens outside the DB locking zones in\nthe respective methods of ML2 plugin.\n\nTo fix this, we have moved determination of\nfdb_entries back to delete_port_postcommit and removed\ndelete_port_precommit altogether from l2pop mechanism\ndriver.  In order to accomodate dvr interfaces, we\nare storing and re-using the mechanism-driver context\nwhich hold dvr-port-binding information while\ninvoking delete_port_postcommit.\n\nChange-Id: If0502f57382441fdb4510c81a89794f57a38e696\n'}, {'number': 2, 'created': '2014-09-23 09:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b3041ea02c52bf92e5759ad2b67ba6fee5d0614', 'message': 'Race for l2pop when ports go up/down on same host\n\nWith l2pop enabled, race exists in delete_port_postcommit\nwhen both create/update_port and delete_port deal with\ndifferent ports on the same host, where such ports are\neither the first (or) last on same network for that host.\nThis race happens outside the DB locking zones in\nthe respective methods of ML2 plugin.\n\nTo fix this, we have moved determination of\nfdb_entries back to delete_port_postcommit and removed\ndelete_port_precommit altogether from l2pop mechanism\ndriver.  In order to accomodate dvr interfaces, we\nare storing and re-using the mechanism-driver context\nwhich hold dvr-port-binding information while\ninvoking delete_port_postcommit.\n\nCloses-Bug: #1372438\nChange-Id: If0502f57382441fdb4510c81a89794f57a38e696\n'}, {'number': 3, 'created': '2014-09-23 10:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/90a61775d59e7c707acf995ec08e96db8038ca76', 'message': 'Race for l2pop when ports go up/down on same host\n\nWith l2pop enabled, race exists in delete_port_postcommit\nwhen both create/update_port and delete_port deal with\ndifferent ports on the same host, where such ports are\neither the first (or) last on same network for that host.\nThis race happens outside the DB locking zones in\nthe respective methods of ML2 plugin.\n\nTo fix this, we have moved determination of\nfdb_entries back to delete_port_postcommit and removed\ndelete_port_precommit altogether from l2pop mechanism\ndriver.  In order to accomodate dvr interfaces, we\nare storing and re-using the mechanism-driver context\nwhich hold dvr-port-binding information while\ninvoking delete_port_postcommit.  We loop through\ndvr interface bindings invoking delete_port_postcommit\nsimilar to delete_port_precommit.\n\nCloses-Bug: #1372438\nChange-Id: If0502f57382441fdb4510c81a89794f57a38e696\n'}, {'number': 4, 'created': '2014-09-23 10:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/12d6ab8b7af72a6adaae5bdd8b1fb2b2c1890a60', 'message': 'Race for l2pop when ports go up/down on same host\n\nWith l2pop enabled, race exists in delete_port_postcommit\nwhen both create/update_port and delete_port deal with\ndifferent ports on the same host, where such ports are\neither the first (or) last on same network for that host.\nThis race happens outside the DB locking zones in\nthe respective methods of ML2 plugin.\n\nTo fix this, we have moved determination of\nfdb_entries back to delete_port_postcommit and removed\ndelete_port_precommit altogether from l2pop mechanism\ndriver.  In order to accomodate dvr interfaces, we\nare storing and re-using the mechanism-driver context\nwhich hold dvr-port-binding information while\ninvoking delete_port_postcommit.  We loop through\ndvr interface bindings invoking delete_port_postcommit\nsimilar to delete_port_precommit.\n\nCloses-Bug: #1372438\nChange-Id: If0502f57382441fdb4510c81a89794f57a38e696\n'}, {'number': 5, 'created': '2014-09-23 15:46:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0bb912970d070d694ee8b9cec552791ca2db863f', 'message': 'Race for l2pop when ports go up/down on same host\n\nWith l2pop enabled, race exists in delete_port_postcommit\nwhen both create/update_port and delete_port deal with\ndifferent ports on the same host, where such ports are\neither the first (or) last on same network for that host.\nThis race happens outside the DB locking zones in\nthe respective methods of ML2 plugin.\n\nTo fix this, we have moved determination of\nfdb_entries back to delete_port_postcommit and removed\ndelete_port_precommit altogether from l2pop mechanism\ndriver.  In order to accomodate dvr interfaces, we\nare storing and re-using the mechanism-driver context\nwhich hold dvr-port-binding information while\ninvoking delete_port_postcommit.  We loop through\ndvr interface bindings invoking delete_port_postcommit\nsimilar to delete_port_precommit.\n\nCloses-Bug: #1372438\nChange-Id: If0502f57382441fdb4510c81a89794f57a38e696\n'}, {'number': 6, 'created': '2014-09-29 16:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e83021a119feb4d2200a45d872bba50997f0997f', 'message': 'Race for l2pop when ports go up/down on same host\n\nWith l2pop enabled, race exists in delete_port_postcommit\nwhen both create/update_port and delete_port deal with\ndifferent ports on the same host, where such ports are\neither the first (or) last on same network for that host.\nThis race happens outside the DB locking zones in\nthe respective methods of ML2 plugin.\n\nTo fix this, we have moved determination of\nfdb_entries back to delete_port_postcommit and removed\ndelete_port_precommit altogether from l2pop mechanism\ndriver.  In order to accomodate dvr interfaces, we\nare storing and re-using the mechanism-driver context\nwhich hold dvr-port-binding information while\ninvoking delete_port_postcommit.  We loop through\ndvr interface bindings invoking delete_port_postcommit\nsimilar to delete_port_precommit.\n\nCloses-Bug: #1372438\nChange-Id: If0502f57382441fdb4510c81a89794f57a38e696\n'}, {'number': 7, 'created': '2014-10-14 17:05:50.000000000', 'files': ['neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/tests/unit/ml2/drivers/test_l2population.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3cd2163d5105faad389bee5175ef446f0bb90289', 'message': 'Race for l2pop when ports go up/down on same host\n\nWith l2pop enabled, race exists in delete_port_postcommit\nwhen both create/update_port and delete_port deal with\ndifferent ports on the same host, where such ports are\neither the first (or) last on same network for that host.\nThis race happens outside the DB locking zones in\nthe respective methods of ML2 plugin.\n\nTo fix this, we have moved determination of\nfdb_entries back to delete_port_postcommit and removed\ndelete_port_precommit altogether from l2pop mechanism\ndriver.  In order to accomodate dvr interfaces, we\nare storing and re-using the mechanism-driver context\nwhich hold dvr-port-binding information while\ninvoking delete_port_postcommit.  We loop through\ndvr interface bindings invoking delete_port_postcommit\nsimilar to delete_port_precommit.\n\nCloses-Bug: #1372438\nChange-Id: If0502f57382441fdb4510c81a89794f57a38e696\n'}]",15,123403,3cd2163d5105faad389bee5175ef446f0bb90289,148,34,7,9361,,,0,"Race for l2pop when ports go up/down on same host

With l2pop enabled, race exists in delete_port_postcommit
when both create/update_port and delete_port deal with
different ports on the same host, where such ports are
either the first (or) last on same network for that host.
This race happens outside the DB locking zones in
the respective methods of ML2 plugin.

To fix this, we have moved determination of
fdb_entries back to delete_port_postcommit and removed
delete_port_precommit altogether from l2pop mechanism
driver.  In order to accomodate dvr interfaces, we
are storing and re-using the mechanism-driver context
which hold dvr-port-binding information while
invoking delete_port_postcommit.  We loop through
dvr interface bindings invoking delete_port_postcommit
similar to delete_port_precommit.

Closes-Bug: #1372438
Change-Id: If0502f57382441fdb4510c81a89794f57a38e696
",git fetch https://review.opendev.org/openstack/neutron refs/changes/03/123403/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/plugins/ml2/plugin.py']",2,48a771d7c57f032c59279164b97ebb8a32350944,bug/1372438," bound_mech_contexts = [] bound_mech_contexts.append(mech_context) # for both DVR Interface ports, we will invoke postcommit # for every such replicated port available on compute hosts, # similar to the way we did precommit if device_owner == const.DEVICE_OWNER_DVR_INTERFACE: for mech_context in bound_mech_contexts: self.mechanism_manager.delete_port_postcommit(mech_context) else:"," # for both normal and DVR Interface ports, only one invocation of # delete_port_postcommit. We use gather/scatter technique for DVR # interface ports, where the bindings are gathered in # delete_port_precommit() call earlier and scattered as l2pop # rules to cloud nodes in delete_port_postcommit() here if mech_context:",16,27
openstack%2Fheat-templates~master~Ic5fd5efef0034cff2084d81f2c4cd5adc083b4b4,openstack/heat-templates,master,Ic5fd5efef0034cff2084d81f2c4cd5adc083b4b4,Use packaged heatclient in the heat-config element,MERGED,2014-10-16 14:11:49.000000000,2014-10-17 08:30:46.000000000,2014-10-17 05:47:34.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7193}]","[{'number': 1, 'created': '2014-10-16 14:11:49.000000000', 'files': ['hot/software-config/elements/heat-config/install.d/50-heat-config', 'hot/software-config/elements/heat-config/install.d/heat-config-package-install/50-heat-config-package', 'hot/software-config/elements/heat-config/install.d/heat-config-source-install/50-heat-config-soure'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/a22ee25ec2224c0a73f15d77cbc16c20f5af0a80', 'message': ""Use packaged heatclient in the heat-config element\n\nUpdates the heat-config element so that it optionally supports\ninstalling heatclient via a package instead of pip.\n\nTo do this you would set DIB_INSTALLTYPE_heat_config=package\nin your environment before running DIB.\n\nIdeally TripleO would have split out elements for each\nclient library thus allowing us to add something like\n'heatclient' to our element-deps.\n\nWe don't have that yet... today there is only openstack-clients which\ninstalls *everything*. So perhaps we can take this approach for\nnow and then migrate to using something cleaner if/when it exists.\n\nChange-Id: Ic5fd5efef0034cff2084d81f2c4cd5adc083b4b4\n""}]",0,128936,a22ee25ec2224c0a73f15d77cbc16c20f5af0a80,10,5,1,360,,,0,"Use packaged heatclient in the heat-config element

Updates the heat-config element so that it optionally supports
installing heatclient via a package instead of pip.

To do this you would set DIB_INSTALLTYPE_heat_config=package
in your environment before running DIB.

Ideally TripleO would have split out elements for each
client library thus allowing us to add something like
'heatclient' to our element-deps.

We don't have that yet... today there is only openstack-clients which
installs *everything*. So perhaps we can take this approach for
now and then migrate to using something cleaner if/when it exists.

Change-Id: Ic5fd5efef0034cff2084d81f2c4cd5adc083b4b4
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/36/128936/1 && git format-patch -1 --stdout FETCH_HEAD,"['hot/software-config/elements/heat-config/install.d/50-heat-config', 'hot/software-config/elements/heat-config/install.d/heat-config-package-install/50-heat-config-package', 'hot/software-config/elements/heat-config/install.d/heat-config-source-install/50-heat-config-soure']",3,a22ee25ec2224c0a73f15d77cbc16c20f5af0a80,heat-config-package-support,#!/bin/bash set -eux pip install python-heatclient ,,8,2
openstack%2Fhorizon~master~I9cc93b7c72b439a1630e7673327d2156f641ed12,openstack/horizon,master,I9cc93b7c72b439a1630e7673327d2156f641ed12,Imported Translations from Transifex,MERGED,2014-10-17 06:06:40.000000000,2014-10-17 08:27:52.000000000,2014-10-17 08:27:50.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-10-17 06:06:40.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'horizon/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'horizon/locale/cs/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e79523e6145eed727beeabcabfb966bd50de2c11', 'message': 'Imported Translations from Transifex\n\nChange-Id: I9cc93b7c72b439a1630e7673327d2156f641ed12\n'}]",0,129138,e79523e6145eed727beeabcabfb966bd50de2c11,9,4,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I9cc93b7c72b439a1630e7673327d2156f641ed12
",git fetch https://review.opendev.org/openstack/horizon refs/changes/38/129138/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'horizon/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'horizon/locale/cs/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",16,e79523e6145eed727beeabcabfb966bd50de2c11,transifex/translations,"""POT-Creation-Date: 2014-10-16 22:36-0500\n"" ""PO-Revision-Date: 2014-10-16 11:21+0000\n""#: settings.py:298#: settings.py:304#: settings.py:310#: api/ceilometer.py:747#: api/ceilometer.py:923#: api/ceilometer.py:927#: api/ceilometer.py:932#: api/ceilometer.py:936#: api/ceilometer.py:940#: api/ceilometer.py:944#: api/ceilometer.py:948#: api/ceilometer.py:952#: api/ceilometer.py:956#: api/ceilometer.py:960#: api/ceilometer.py:964#: api/ceilometer.py:968#: api/ceilometer.py:973#: api/ceilometer.py:978#: api/ceilometer.py:983#: api/ceilometer.py:988#: api/ceilometer.py:1000#: api/ceilometer.py:1020#: api/ceilometer.py:1024#: api/ceilometer.py:1028#: api/ceilometer.py:1032#: api/ceilometer.py:1036#: api/ceilometer.py:1040#: api/ceilometer.py:1044#: api/ceilometer.py:1048#: api/ceilometer.py:1052#: api/ceilometer.py:1056#: api/ceilometer.py:1060#: api/ceilometer.py:1064#: api/ceilometer.py:1068#: api/ceilometer.py:1072#: api/ceilometer.py:1076#: api/ceilometer.py:1093#: api/ceilometer.py:1097#: api/ceilometer.py:1101#: api/ceilometer.py:1105#: api/ceilometer.py:1109#: api/ceilometer.py:1113#: api/ceilometer.py:1117#: api/ceilometer.py:1134#: api/ceilometer.py:1138#: api/ceilometer.py:1155#: api/ceilometer.py:1159#: api/ceilometer.py:1163#: api/ceilometer.py:1167#: api/ceilometer.py:1171#: api/ceilometer.py:1175#: api/ceilometer.py:1192#: api/ceilometer.py:1196#: api/keystone.py:326#: api/keystone.py:351#: api/keystone.py:363 api/keystone.py:379 #: dashboards/settings/password/forms.py:65#: api/swift.py:205#: dashboards/admin/flavors/workflows.py:36 dashboards/admin/info/tables.py:64#: dashboards/admin/networks/forms.py:38 #: dashboards/admin/networks/forms.py:234#: dashboards/admin/volumes/snapshots/tables.py:59#: dashboards/project/data_processing/job_binaries/tables.py:82#: dashboards/project/data_processing/nodegroup_templates/tables.py:80#: dashboards/project/images/images/forms.py:189#: dashboards/project/vpn/forms.py:137 dashboards/project/vpn/forms.py:208 #: dashboards/project/vpn/tables.py:230 dashboards/project/vpn/tables.py:260 #: dashboards/project/vpn/tables.py:280 dashboards/project/vpn/tables.py:298#: dashboards/project/instances/tables.py:904#: dashboards/project/instances/workflows/create_instance.py:78 #: dashboards/project/volumes/volumes/forms.py:89#: dashboards/project/volumes/volumes/forms.py:95#: dashboards/admin/flavors/workflows.py:266#: dashboards/identity/projects/workflows.py:512#: dashboards/project/containers/templates/containers/_create_pseudo_folder.html:17#: dashboards/admin/defaults/workflows.py:81#: dashboards/project/instances/tables.py:923#: dashboards/admin/defaults/workflows.py:54#: dashboards/admin/defaults/workflows.py:53#: dashboards/admin/volumes/snapshots/tables.py:69#: dashboards/admin/defaults/workflows.py:52#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:108#: dashboards/project/instances/workflows/create_instance.py:497#: dashboards/admin/defaults/workflows.py:67#: dashboards/admin/defaults/workflows.py:69#: dashboards/admin/defaults/workflows.py:80#: dashboards/admin/defaults/workflows.py:82#: dashboards/admin/defaults/workflows.py:83 #: dashboards/admin/defaults/workflows.py:100#: dashboards/admin/flavors/workflows.py:179#: dashboards/admin/flavors/workflows.py:265#: dashboards/project/vpn/forms.py:139 dashboards/project/vpn/forms.py:210#: dashboards/router/nexus1000v/forms.py:174#: dashboards/project/images/images/forms.py:95 #: dashboards/project/images/images/forms.py:228#: dashboards/admin/flavors/workflows.py:39#: dashboards/admin/flavors/workflows.py:226#: dashboards/admin/flavors/workflows.py:239#: dashboards/admin/flavors/workflows.py:247#: dashboards/admin/flavors/workflows.py:151#: dashboards/admin/flavors/workflows.py:157#: dashboards/admin/flavors/workflows.py:160#: dashboards/admin/flavors/workflows.py:161#: dashboards/admin/flavors/workflows.py:162#: dashboards/admin/flavors/workflows.py:163#: dashboards/admin/flavors/workflows.py:180#: dashboards/admin/flavors/workflows.py:181#: dashboards/admin/flavors/workflows.py:206#: dashboards/admin/flavors/workflows.py:218#: dashboards/admin/flavors/workflows.py:228#: dashboards/admin/flavors/workflows.py:267#: dashboards/admin/flavors/workflows.py:268#: dashboards/admin/flavors/workflows.py:313#: dashboards/project/data_processing/data_sources/tables.py:64#: dashboards/project/volumes/volumes/forms.py:80#: dashboards/project/volumes/volumes/forms.py:86 #: dashboards/project/volumes/volumes/forms.py:646#: dashboards/project/instances/tables.py:865 #: dashboards/project/instances/tables.py:887 #: dashboards/project/instances/workflows/create_instance.py:81#: dashboards/admin/hypervisors/views.py:72#: dashboards/admin/hypervisors/compute/forms.py:29#: dashboards/admin/hypervisors/compute/forms.py:30#: dashboards/admin/hypervisors/compute/forms.py:32#: dashboards/admin/hypervisors/compute/forms.py:48#: dashboards/admin/hypervisors/compute/forms.py:50#: dashboards/admin/hypervisors/compute/forms.py:61#: dashboards/admin/hypervisors/compute/forms.py:67#: dashboards/admin/volumes/snapshots/tables.py:64#: dashboards/project/data_processing/clusters/tables.py:112#: dashboards/project/data_processing/job_executions/tables.py:153#: dashboards/project/instances/tables.py:899#: dashboards/project/vpn/tables.py:240 dashboards/project/vpn/tables.py:267#: dashboards/project/instances/tables.py:866#: dashboards/project/instances/tables.py:889#: dashboards/project/instances/workflows/create_instance.py:105 #: dashboards/project/volumes/volumes/forms.py:538#: dashboards/admin/images/views.py:178#: dashboards/admin/images/views.py:191#: dashboards/identity/projects/workflows.py:491#: dashboards/admin/networks/forms.py:40#: dashboards/admin/volumes/snapshots/tables.py:65#: dashboards/project/instances/workflows/create_instance.py:51 #: dashboards/router/nexus1000v/forms.py:119 #: dashboards/router/nexus1000v/forms.py:177#: dashboards/project/instances/tables.py:867#: dashboards/project/instances/tables.py:868#: dashboards/project/instances/tables.py:891#: dashboards/project/instances/tables.py:894#: dashboards/project/instances/tables.py:906#: dashboards/project/instances/tables.py:913#: dashboards/project/instances/tables.py:916 usage/tables.py:75#: dashboards/project/data_processing/cluster_templates/tables.py:124#: dashboards/project/data_processing/data_plugins/tables.py:36#: dashboards/project/data_processing/data_sources/tables.py:66#: dashboards/project/data_processing/job_binaries/tables.py:87#: dashboards/project/images/images/forms.py:190#: dashboards/project/volumes/snapshots/forms.py:28#: dashboards/project/volumes/volumes/forms.py:51 #: dashboards/project/volumes/volumes/forms.py:475 #: dashboards/project/volumes/volumes/forms.py:515#: dashboards/project/vpn/forms.py:142 dashboards/project/vpn/forms.py:213 #: dashboards/project/vpn/tables.py:262 dashboards/project/vpn/workflows.py:28#: dashboards/admin/networks/forms.py:30 #: dashboards/router/nexus1000v/forms.py:49 #: dashboards/router/nexus1000v/forms.py:69 msgid ""VLAN"" msgstr ""VLAN"" #: dashboards/admin/networks/forms.py:30 msgid ""GRE"" msgstr """" #: dashboards/admin/networks/forms.py:31 msgid ""VXLAN"" msgstr ""VXLAN"" #: dashboards/admin/networks/forms.py:45#: dashboards/admin/networks/forms.py:49#: dashboards/admin/networks/forms.py:50#: dashboards/admin/networks/forms.py:58 dashboards/admin/networks/forms.py:65 #: dashboards/admin/networks/forms.py:66 #: dashboards/router/nexus1000v/forms.py:112 #: dashboards/router/nexus1000v/forms.py:118#: dashboards/admin/networks/forms.py:59#: dashboards/admin/networks/forms.py:69 dashboards/admin/networks/forms.py:73 #: dashboards/admin/networks/forms.py:74 dashboards/admin/networks/forms.py:75#: dashboards/admin/networks/forms.py:79 #: dashboards/admin/networks/forms.py:238#: dashboards/project/vpn/forms.py:39 dashboards/project/vpn/forms.py:263#: dashboards/admin/networks/forms.py:80 #: dashboards/admin/networks/forms.py:239#: dashboards/admin/networks/forms.py:82 #: dashboards/admin/networks/forms.py:240#: dashboards/admin/networks/forms.py:91 dashboards/identity/users/forms.py:58#: dashboards/admin/networks/forms.py:115#: dashboards/admin/networks/forms.py:145 #: dashboards/project/instances/workflows/create_instance.py:695#: dashboards/admin/networks/forms.py:155 #: dashboards/project/instances/workflows/create_instance.py:705#: dashboards/admin/networks/forms.py:186#: dashboards/admin/networks/forms.py:192#: dashboards/admin/networks/forms.py:222#: dashboards/admin/networks/forms.py:225#: dashboards/admin/networks/forms.py:228#: dashboards/admin/networks/forms.py:252#: dashboards/admin/networks/forms.py:257#: dashboards/project/instances/workflows/create_instance.py:648#: dashboards/project/instances/tables.py:619#: dashboards/admin/networks/agents/forms.py:62#: dashboards/admin/networks/agents/forms.py:36#: dashboards/admin/networks/agents/forms.py:37#: dashboards/admin/networks/agents/forms.py:55#: dashboards/admin/networks/agents/forms.py:57#: dashboards/admin/networks/agents/forms.py:74#: dashboards/admin/networks/agents/forms.py:80#: dashboards/admin/volumes/tabs.py:50 dashboards/admin/volumes/tabs.py:119 #: dashboards/admin/volumes/snapshots/tables.py:52#: dashboards/admin/volumes/tabs.py:111 dashboards/project/volumes/tabs.py:90 #: dashboards/project/volumes/volumes/forms.py:203#: dashboards/admin/volumes/snapshots/tables.py:62#: dashboards/project/volumes/volumes/forms.py:48 #: dashboards/project/volumes/volumes/forms.py:512 #: dashboards/project/volumes/volumes/forms.py:535 #: dashboards/project/volumes/volumes/forms.py:595 #: dashboards/project/volumes/volumes/forms.py:643#: dashboards/project/instances/workflows/create_instance.py:99 #: dashboards/project/instances/workflows/create_instance.py:371#: dashboards/project/volumes/volumes/forms.py:220#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:303#: dashboards/project/data_processing/cluster_templates/workflows/create.py:225#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:174 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:302#: dashboards/admin/volumes/volume_types/views.py:131#: dashboards/identity/projects/workflows.py:347#: dashboards/identity/projects/workflows.py:336#: dashboards/identity/projects/workflows.py:338#: dashboards/identity/projects/workflows.py:339#: dashboards/identity/projects/workflows.py:359#: dashboards/identity/projects/workflows.py:511#: dashboards/identity/projects/workflows.py:494#: dashboards/identity/projects/workflows.py:330 #: dashboards/identity/projects/workflows.py:337#: dashboards/identity/projects/workflows.py:360#: dashboards/identity/projects/workflows.py:361#: dashboards/identity/projects/workflows.py:423#: dashboards/identity/projects/workflows.py:427#: dashboards/identity/projects/workflows.py:458#: dashboards/identity/projects/workflows.py:486#: dashboards/identity/projects/workflows.py:496#: dashboards/identity/projects/workflows.py:513#: dashboards/identity/projects/workflows.py:514#: dashboards/identity/projects/workflows.py:609#: dashboards/identity/projects/workflows.py:644#: dashboards/identity/projects/workflows.py:648#: dashboards/identity/projects/workflows.py:721#: dashboards/identity/projects/workflows.py:754#: dashboards/project/instances/forms.py:92 #: dashboards/project/instances/workflows/create_instance.py:546 #: dashboards/settings/password/forms.py:50#: dashboards/project/instances/forms.py:156#: dashboards/project/instances/workflows/create_instance.py:504#: dashboards/project/instances/tables.py:331#: dashboards/project/instances/tables.py:613#: dashboards/project/access_and_security/keypairs/forms.py:34#: dashboards/project/access_and_security/keypairs/forms.py:40 #: dashboards/project/access_and_security/keypairs/forms.py:50#: dashboards/project/instances/forms.py:116#: dashboards/project/access_and_security/keypairs/forms.py:53#: dashboards/project/access_and_security/keypairs/forms.py:64#: dashboards/project/access_and_security/keypairs/forms.py:69#: dashboards/project/instances/workflows/create_instance.py:573#: dashboards/project/data_processing/cluster_templates/tables.py:128#: dashboards/project/data_processing/cluster_templates/tables.py:116#: dashboards/project/data_processing/nodegroup_templates/tables.py:83#: dashboards/project/data_processing/cluster_templates/tables.py:118#: dashboards/project/data_processing/nodegroup_templates/tables.py:85#: dashboards/project/data_processing/cluster_templates/tables.py:120#: dashboards/project/data_processing/cluster_templates/workflows/create.py:206#: dashboards/project/instances/workflows/create_instance.py:84#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:100#: dashboards/project/data_processing/nodegroup_templates/tables.py:87#: dashboards/project/data_processing/cluster_templates/workflows/create.py:224#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:304#: dashboards/project/instances/workflows/create_instance.py:135#: dashboards/project/data_processing/cluster_templates/workflows/create.py:226#: dashboards/project/data_processing/cluster_templates/workflows/create.py:309#: dashboards/project/data_processing/clusters/tables.py:120#: dashboards/project/data_processing/clusters/tables.py:116#: dashboards/project/volumes/volumes/forms.py:208#: dashboards/project/instances/forms.py:39 #: dashboards/project/instances/forms.py:64 #: dashboards/project/instances/workflows/create_instance.py:393#: dashboards/project/data_processing/data_plugins/tables.py:40#: dashboards/project/data_processing/data_plugins/tables.py:31#: dashboards/project/data_processing/data_sources/tables.py:70#: dashboards/project/data_processing/job_binaries/tables.py:91#: dashboards/project/data_processing/job_binaries/tables.py:85#: dashboards/project/data_processing/job_executions/tables.py:162#: dashboards/project/data_processing/job_executions/tables.py:144#: dashboards/project/data_processing/job_executions/tables.py:148#: dashboards/project/instances/workflows/create_instance.py:791#: dashboards/project/data_processing/nodegroup_templates/tables.py:93#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:173 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:301#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:87#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:95#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:102#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:110#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:115#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:117#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:149#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:175#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:282#: dashboards/project/instances/workflows/create_instance.py:691#: dashboards/project/instances/tables.py:734 #: dashboards/project/instances/tables.py:741#: dashboards/project/instances/workflows/create_instance.py:793#: dashboards/project/instances/workflows/create_instance.py:810#: dashboards/project/volumes/volumes/forms.py:600#: dashboards/project/volumes/volumes/forms.py:604#: dashboards/project/instances/tables.py:305 #: dashboards/project/instances/tables.py:333 #: dashboards/project/instances/workflows/create_instance.py:790#: dashboards/project/instances/tables.py:349#: dashboards/project/instances/workflows/create_instance.py:85#: dashboards/project/instances/workflows/create_instance.py:652#: dashboards/project/instances/workflows/create_instance.py:654#: dashboards/project/instances/workflows/create_instance.py:676#: dashboards/project/instances/workflows/create_instance.py:678#: dashboards/project/instances/workflows/create_instance.py:792#: dashboards/project/images/images/forms.py:210#: dashboards/project/images/images/forms.py:205#: dashboards/project/images/images/forms.py:84 #: dashboards/project/images/images/forms.py:212#: dashboards/project/images/images/forms.py:86 #: dashboards/project/images/images/forms.py:214#: dashboards/project/images/images/forms.py:90 #: dashboards/project/images/images/forms.py:220#: dashboards/project/images/images/forms.py:92 #: dashboards/project/images/images/forms.py:222#: dashboards/project/images/images/forms.py:96 #: dashboards/project/images/images/forms.py:229#: dashboards/project/images/images/forms.py:139#: dashboards/project/images/images/forms.py:142#: dashboards/project/images/images/forms.py:180#: dashboards/project/images/images/forms.py:184#: dashboards/project/images/images/forms.py:194#: dashboards/project/images/images/forms.py:200#: dashboards/project/images/images/forms.py:242#: dashboards/project/images/images/forms.py:269#: dashboards/project/volumes/volumes/forms.py:539#: dashboards/project/instances/tables.py:385#: dashboards/project/instances/forms.py:44#: dashboards/project/instances/forms.py:50#: dashboards/project/instances/forms.py:53 #: dashboards/project/instances/workflows/create_instance.py:737#: dashboards/project/instances/forms.py:66 #: dashboards/project/instances/workflows/create_instance.py:395#: dashboards/project/instances/forms.py:78 #: dashboards/project/instances/workflows/create_instance.py:755#: dashboards/project/instances/forms.py:79 #: dashboards/project/instances/workflows/create_instance.py:756#: dashboards/project/instances/forms.py:82 #: dashboards/project/instances/workflows/create_instance.py:165 #: dashboards/project/instances/workflows/create_instance.py:765#: dashboards/project/instances/forms.py:106#: dashboards/project/instances/forms.py:109#: dashboards/project/instances/forms.py:117#: dashboards/project/instances/forms.py:124#: dashboards/project/instances/forms.py:127#: dashboards/project/instances/forms.py:142#: dashboards/project/instances/forms.py:148#: dashboards/project/instances/forms.py:152#: dashboards/project/instances/forms.py:160#: dashboards/project/instances/tables.py:248#: dashboards/project/instances/tables.py:263#: dashboards/project/instances/tables.py:243#: dashboards/project/instances/tables.py:258#: dashboards/project/instances/tables.py:372#: dashboards/project/instances/tables.py:398#: dashboards/project/instances/tables.py:418#: dashboards/project/instances/tables.py:435#: dashboards/project/instances/tables.py:459#: dashboards/project/instances/tables.py:472#: dashboards/project/instances/tables.py:485#: dashboards/project/instances/tables.py:502#: dashboards/project/instances/tables.py:525 #: dashboards/project/instances/tables.py:549#: dashboards/project/instances/tables.py:568#: dashboards/project/instances/tables.py:572#: dashboards/project/instances/tables.py:578#: dashboards/project/instances/tables.py:607#: dashboards/project/instances/tables.py:610#: dashboards/project/instances/tables.py:620#: dashboards/project/instances/tables.py:622#: dashboards/project/instances/tables.py:634#: dashboards/project/instances/tables.py:660#: dashboards/project/instances/tables.py:668#: dashboards/project/instances/tables.py:689#: dashboards/project/instances/tables.py:698#: dashboards/project/instances/tables.py:725#: dashboards/project/instances/tables.py:749 #: dashboards/project/instances/tables.py:771#: dashboards/project/instances/tables.py:750#: dashboards/project/instances/tables.py:751#: dashboards/project/instances/tables.py:753#: dashboards/project/instances/tables.py:754#: dashboards/project/instances/tables.py:755#: dashboards/project/instances/tables.py:757#: dashboards/project/instances/tables.py:759#: dashboards/project/instances/tables.py:761#: dashboards/project/instances/tables.py:762#: dashboards/project/instances/tables.py:764#: dashboards/project/instances/tables.py:765#: dashboards/project/instances/tables.py:766#: dashboards/project/instances/tables.py:768#: dashboards/project/instances/tables.py:769#: dashboards/project/instances/tables.py:770#: dashboards/project/instances/tables.py:773#: dashboards/project/instances/tables.py:774#: dashboards/project/instances/tables.py:776#: dashboards/project/instances/tables.py:782#: dashboards/project/instances/tables.py:784#: dashboards/project/instances/tables.py:786#: dashboards/project/instances/tables.py:787#: dashboards/project/instances/tables.py:789#: dashboards/project/instances/tables.py:791#: dashboards/project/instances/tables.py:793#: dashboards/project/instances/tables.py:795#: dashboards/project/instances/tables.py:797#: dashboards/project/instances/tables.py:799#: dashboards/project/instances/tables.py:801#: dashboards/project/instances/tables.py:803#: dashboards/project/instances/tables.py:805#: dashboards/project/instances/tables.py:807#: dashboards/project/instances/tables.py:809#: dashboards/project/instances/tables.py:811#: dashboards/project/instances/tables.py:812#: dashboards/project/instances/tables.py:814#: dashboards/project/instances/tables.py:815#: dashboards/project/instances/tables.py:816 #: dashboards/project/instances/tables.py:819#: dashboards/project/instances/tables.py:818#: dashboards/project/instances/tables.py:821#: dashboards/project/instances/tables.py:823#: dashboards/project/instances/tables.py:824#: dashboards/project/instances/tables.py:826#: dashboards/project/instances/tables.py:828#: dashboards/project/instances/tables.py:830#: dashboards/project/instances/tables.py:832#: dashboards/project/instances/tables.py:833#: dashboards/project/instances/tables.py:834#: dashboards/project/instances/tables.py:836#: dashboards/project/instances/tables.py:837#: dashboards/project/instances/tables.py:838#: dashboards/project/instances/tables.py:840#: dashboards/project/instances/tables.py:842#: dashboards/project/instances/tables.py:844#: dashboards/project/instances/tables.py:846#: dashboards/project/instances/tables.py:850#: dashboards/project/instances/tables.py:851#: dashboards/project/instances/tables.py:852#: dashboards/project/instances/tables.py:853#: dashboards/project/instances/tables.py:854#: dashboards/project/instances/tables.py:855#: dashboards/project/instances/tables.py:856#: dashboards/project/instances/tables.py:857#: dashboards/project/instances/tables.py:858#: dashboards/project/instances/tables.py:859#: dashboards/project/instances/tables.py:896 #: dashboards/project/instances/workflows/create_instance.py:482#: dashboards/project/instances/workflows/create_instance.py:52#: dashboards/project/instances/workflows/create_instance.py:66#: dashboards/project/instances/workflows/create_instance.py:87#: dashboards/project/instances/workflows/create_instance.py:90#: dashboards/project/instances/workflows/create_instance.py:92#: dashboards/project/instances/workflows/create_instance.py:93#: dashboards/project/instances/workflows/create_instance.py:96#: dashboards/project/instances/workflows/create_instance.py:101#: dashboards/project/instances/workflows/create_instance.py:112#: dashboards/project/instances/workflows/create_instance.py:116#: dashboards/project/instances/workflows/create_instance.py:119 #: dashboards/project/volumes/volumes/forms.py:405#: dashboards/project/instances/workflows/create_instance.py:122#: dashboards/project/instances/workflows/create_instance.py:128#: dashboards/project/instances/workflows/create_instance.py:131#: dashboards/project/instances/workflows/create_instance.py:151#: dashboards/project/instances/workflows/create_instance.py:152#: dashboards/project/instances/workflows/create_instance.py:153#: dashboards/project/instances/workflows/create_instance.py:156#: dashboards/project/instances/workflows/create_instance.py:163#: dashboards/project/instances/workflows/create_instance.py:170#: dashboards/project/instances/workflows/create_instance.py:181#: dashboards/project/instances/workflows/create_instance.py:208#: dashboards/project/instances/workflows/create_instance.py:215#: dashboards/project/instances/workflows/create_instance.py:222#: dashboards/project/instances/workflows/create_instance.py:237#: dashboards/project/instances/workflows/create_instance.py:240#: dashboards/project/instances/workflows/create_instance.py:243#: dashboards/project/instances/workflows/create_instance.py:266#: dashboards/project/instances/workflows/create_instance.py:283#: dashboards/project/instances/workflows/create_instance.py:294 #: dashboards/project/instances/workflows/create_instance.py:311#: dashboards/project/instances/workflows/create_instance.py:299#: dashboards/project/instances/workflows/create_instance.py:305#: dashboards/project/instances/workflows/create_instance.py:328 #: dashboards/project/volumes/volumes/forms.py:272#: dashboards/project/instances/workflows/create_instance.py:334 #: dashboards/project/volumes/volumes/forms.py:275#: dashboards/project/instances/workflows/create_instance.py:336 #: dashboards/project/volumes/volumes/forms.py:277#: dashboards/project/instances/workflows/create_instance.py:358#: dashboards/project/instances/workflows/create_instance.py:368 #: dashboards/project/volumes/volumes/forms.py:195#: dashboards/project/instances/workflows/create_instance.py:373#: dashboards/project/instances/workflows/create_instance.py:407#: dashboards/project/instances/workflows/create_instance.py:409#: dashboards/project/instances/workflows/create_instance.py:421 #: dashboards/project/volumes/volumes/forms.py:290#: dashboards/project/instances/workflows/create_instance.py:423#: dashboards/project/instances/workflows/create_instance.py:425#: dashboards/project/instances/workflows/create_instance.py:436#: dashboards/project/instances/workflows/create_instance.py:439#: dashboards/project/instances/workflows/create_instance.py:441#: dashboards/project/instances/workflows/create_instance.py:484#: dashboards/project/instances/workflows/create_instance.py:488#: dashboards/project/instances/workflows/create_instance.py:494#: dashboards/project/instances/workflows/create_instance.py:500#: dashboards/project/instances/workflows/create_instance.py:505#: dashboards/project/instances/workflows/create_instance.py:521#: dashboards/project/instances/workflows/create_instance.py:525#: dashboards/project/instances/workflows/create_instance.py:527#: dashboards/project/instances/workflows/create_instance.py:536#: dashboards/project/instances/workflows/create_instance.py:568#: dashboards/project/instances/workflows/create_instance.py:572#: dashboards/project/instances/workflows/create_instance.py:576#: dashboards/project/instances/workflows/create_instance.py:580#: dashboards/project/instances/workflows/create_instance.py:584 #: dashboards/project/instances/workflows/create_instance.py:589#: dashboards/project/instances/workflows/create_instance.py:593 #: dashboards/project/instances/workflows/create_instance.py:598#: dashboards/project/instances/workflows/create_instance.py:625#: dashboards/project/instances/workflows/create_instance.py:633#: dashboards/project/instances/workflows/create_instance.py:660#: dashboards/project/instances/workflows/create_instance.py:663#: dashboards/project/instances/workflows/create_instance.py:738#: dashboards/project/instances/workflows/create_instance.py:742#: dashboards/project/instances/workflows/create_instance.py:743#: dashboards/project/instances/workflows/create_instance.py:769#: dashboards/project/instances/workflows/create_instance.py:807#: dashboards/project/instances/workflows/create_instance.py:867#: dashboards/project/vpn/tables.py:263 dashboards/project/vpn/workflows.py:30#: dashboards/project/vpn/tables.py:264 dashboards/project/vpn/workflows.py:29#: dashboards/project/stacks/forms.py:230 #: dashboards/project/stacks/forms.py:379#: dashboards/project/stacks/forms.py:233 #: dashboards/project/stacks/forms.py:257 #: dashboards/project/stacks/forms.py:382#: dashboards/project/stacks/forms.py:242#: dashboards/project/stacks/forms.py:258#: dashboards/project/stacks/forms.py:261#: dashboards/project/stacks/forms.py:266#: dashboards/project/stacks/forms.py:267#: dashboards/project/stacks/forms.py:269#: dashboards/project/stacks/forms.py:270#: dashboards/project/stacks/forms.py:283#: dashboards/project/stacks/forms.py:284#: dashboards/project/stacks/forms.py:367#: dashboards/project/stacks/forms.py:376#: dashboards/project/stacks/forms.py:411#: dashboards/project/volumes/snapshots/forms.py:39#: dashboards/project/volumes/snapshots/forms.py:45#: dashboards/project/volumes/volumes/forms.py:52#: dashboards/project/volumes/volumes/forms.py:58#: dashboards/project/volumes/volumes/forms.py:65#: dashboards/project/volumes/volumes/forms.py:72#: dashboards/project/volumes/volumes/forms.py:87#: dashboards/project/volumes/volumes/forms.py:100#: dashboards/project/volumes/volumes/forms.py:120#: dashboards/project/volumes/volumes/forms.py:128#: dashboards/project/volumes/volumes/forms.py:139#: dashboards/project/volumes/volumes/forms.py:147#: dashboards/project/volumes/volumes/forms.py:158#: dashboards/project/volumes/volumes/forms.py:167#: dashboards/project/volumes/volumes/forms.py:174#: dashboards/project/volumes/volumes/forms.py:196#: dashboards/project/volumes/volumes/forms.py:209#: dashboards/project/volumes/volumes/forms.py:221#: dashboards/project/volumes/volumes/forms.py:230#: dashboards/project/volumes/volumes/forms.py:241#: dashboards/project/volumes/volumes/forms.py:245#: dashboards/project/volumes/volumes/forms.py:249#: dashboards/project/volumes/volumes/forms.py:258#: dashboards/project/volumes/volumes/forms.py:312#: dashboards/project/volumes/volumes/forms.py:325#: dashboards/project/volumes/volumes/forms.py:333#: dashboards/project/volumes/volumes/forms.py:344#: dashboards/project/volumes/volumes/forms.py:353#: dashboards/project/volumes/volumes/forms.py:360#: dashboards/project/volumes/volumes/forms.py:376#: dashboards/project/volumes/volumes/forms.py:384#: dashboards/project/volumes/volumes/forms.py:401#: dashboards/project/volumes/volumes/forms.py:402#: dashboards/project/volumes/volumes/forms.py:409#: dashboards/project/volumes/volumes/forms.py:491#: dashboards/project/volumes/volumes/forms.py:494#: dashboards/project/volumes/volumes/forms.py:507#: dashboards/project/volumes/volumes/forms.py:524#: dashboards/project/volumes/volumes/forms.py:530#: dashboards/project/volumes/volumes/forms.py:544#: dashboards/project/volumes/volumes/forms.py:579#: dashboards/project/volumes/volumes/forms.py:586#: dashboards/project/volumes/volumes/forms.py:612#: dashboards/project/volumes/volumes/forms.py:618#: dashboards/project/volumes/volumes/forms.py:632#: dashboards/project/volumes/volumes/forms.py:638#: dashboards/project/volumes/volumes/forms.py:647#: dashboards/project/volumes/volumes/forms.py:648#: dashboards/project/volumes/volumes/forms.py:649#: dashboards/project/volumes/volumes/forms.py:666#: dashboards/project/volumes/volumes/forms.py:675#: dashboards/project/volumes/volumes/forms.py:691#: dashboards/project/volumes/volumes/forms.py:700#: dashboards/project/vpn/forms.py:73 dashboards/project/vpn/forms.py:145 #: dashboards/project/vpn/tables.py:283 dashboards/project/vpn/tables.py:301#: dashboards/project/vpn/forms.py:74 dashboards/project/vpn/forms.py:146#: dashboards/project/vpn/forms.py:77 dashboards/project/vpn/forms.py:153 #: dashboards/project/vpn/tables.py:286 dashboards/project/vpn/tables.py:304#: dashboards/project/vpn/forms.py:78 dashboards/project/vpn/forms.py:154#: dashboards/project/vpn/forms.py:79 dashboards/project/vpn/forms.py:155#: dashboards/project/vpn/forms.py:80 dashboards/project/vpn/forms.py:156#: dashboards/project/vpn/forms.py:81 dashboards/project/vpn/forms.py:157#: dashboards/project/vpn/forms.py:89 dashboards/project/vpn/forms.py:161#: dashboards/project/vpn/forms.py:94 dashboards/project/vpn/forms.py:166#: dashboards/project/vpn/forms.py:96 dashboards/project/vpn/forms.py:168#: dashboards/project/vpn/forms.py:97 dashboards/project/vpn/forms.py:169#: dashboards/project/vpn/forms.py:98 dashboards/project/vpn/forms.py:170#: dashboards/project/vpn/forms.py:99 dashboards/project/vpn/forms.py:171#: dashboards/project/vpn/forms.py:124#: dashboards/project/vpn/forms.py:130#: dashboards/project/vpn/forms.py:149 dashboards/project/vpn/workflows.py:214#: dashboards/project/vpn/forms.py:150#: dashboards/project/vpn/forms.py:151#: dashboards/project/vpn/forms.py:160 dashboards/project/vpn/workflows.py:216#: dashboards/project/vpn/forms.py:165#: dashboards/project/vpn/forms.py:173 dashboards/project/vpn/workflows.py:222#: dashboards/project/vpn/forms.py:174#: dashboards/project/vpn/forms.py:175#: dashboards/project/vpn/forms.py:176#: dashboards/project/vpn/forms.py:195#: dashboards/project/vpn/forms.py:201#: dashboards/project/vpn/forms.py:215 dashboards/project/vpn/workflows.py:317#: dashboards/project/vpn/forms.py:216 dashboards/project/vpn/workflows.py:318#: dashboards/project/vpn/forms.py:221 dashboards/project/vpn/workflows.py:323#: dashboards/project/vpn/forms.py:222 dashboards/project/vpn/workflows.py:324#: dashboards/project/vpn/forms.py:227 dashboards/project/vpn/workflows.py:329#: dashboards/project/vpn/forms.py:228 dashboards/project/vpn/workflows.py:330#: dashboards/project/vpn/forms.py:235 dashboards/project/vpn/workflows.py:337#: dashboards/project/vpn/forms.py:238 dashboards/project/vpn/workflows.py:402#: dashboards/project/vpn/forms.py:239 dashboards/project/vpn/workflows.py:404#: dashboards/project/vpn/forms.py:243 dashboards/project/vpn/workflows.py:407#: dashboards/project/vpn/forms.py:244#: dashboards/project/vpn/forms.py:245#: dashboards/project/vpn/forms.py:246#: dashboards/project/vpn/forms.py:247#: dashboards/project/vpn/forms.py:248#: dashboards/project/vpn/forms.py:251 dashboards/project/vpn/workflows.py:409#: dashboards/project/vpn/forms.py:252 dashboards/project/vpn/workflows.py:411#: dashboards/project/vpn/forms.py:255 dashboards/project/vpn/workflows.py:413#: dashboards/project/vpn/forms.py:256 dashboards/project/vpn/workflows.py:415#: dashboards/project/vpn/forms.py:258 dashboards/project/vpn/workflows.py:416#: dashboards/project/vpn/forms.py:259#: dashboards/project/vpn/forms.py:260#: dashboards/project/vpn/forms.py:287#: dashboards/project/vpn/forms.py:293#: dashboards/project/vpn/tables.py:233#: dashboards/project/vpn/tables.py:235#: dashboards/project/vpn/tables.py:237#: dashboards/project/vpn/tables.py:246 dashboards/project/vpn/tabs.py:27#: dashboards/project/vpn/tables.py:273 dashboards/project/vpn/tabs.py:48#: dashboards/project/vpn/tables.py:287 dashboards/project/vpn/tables.py:305#: dashboards/project/vpn/tables.py:291 dashboards/project/vpn/tabs.py:68#: dashboards/project/vpn/tables.py:309 dashboards/project/vpn/tabs.py:88#: dashboards/project/vpn/tabs.py:40#: dashboards/project/vpn/tabs.py:60 dashboards/project/vpn/workflows.py:375#: dashboards/project/vpn/tabs.py:80 dashboards/project/vpn/workflows.py:346#: dashboards/project/vpn/tabs.py:100 dashboards/project/vpn/workflows.py:361#: dashboards/project/vpn/tabs.py:114#: dashboards/project/vpn/tabs.py:129#: dashboards/project/vpn/tabs.py:144#: dashboards/project/vpn/tabs.py:159#: dashboards/project/vpn/views.py:86#: dashboards/project/vpn/views.py:133#: dashboards/project/vpn/views.py:165#: dashboards/project/vpn/views.py:200#: dashboards/project/vpn/views.py:240#: dashboards/project/vpn/views.py:283#: dashboards/project/vpn/views.py:312#: dashboards/project/vpn/views.py:348#: dashboards/project/vpn/views.py:385#: dashboards/router/nexus1000v/forms.py:75#: dashboards/router/nexus1000v/forms.py:77 #: dashboards/router/nexus1000v/forms.py:83 #: dashboards/router/nexus1000v/forms.py:85#: dashboards/router/nexus1000v/forms.py:86#: dashboards/router/nexus1000v/forms.py:89 #: dashboards/router/nexus1000v/forms.py:96#: dashboards/router/nexus1000v/forms.py:97#: dashboards/router/nexus1000v/forms.py:101 #: dashboards/router/nexus1000v/forms.py:108#: dashboards/router/nexus1000v/forms.py:110#: dashboards/router/nexus1000v/forms.py:160#: dashboards/router/nexus1000v/forms.py:167#: dashboards/router/nexus1000v/forms.py:201#: dashboards/router/nexus1000v/forms.py:207#: dashboards/settings/password/forms.py:32#: dashboards/settings/password/forms.py:35#: dashboards/settings/password/forms.py:41#: dashboards/settings/password/forms.py:70#: dashboards/settings/password/forms.py:73","""POT-Creation-Date: 2014-10-14 23:28-0500\n"" ""PO-Revision-Date: 2014-10-14 07:54+0000\n""#: settings.py:296#: settings.py:302#: settings.py:308#: api/ceilometer.py:738#: api/ceilometer.py:912#: api/ceilometer.py:916#: api/ceilometer.py:921#: api/ceilometer.py:925#: api/ceilometer.py:929#: api/ceilometer.py:933#: api/ceilometer.py:937#: api/ceilometer.py:941#: api/ceilometer.py:945#: api/ceilometer.py:949#: api/ceilometer.py:953#: api/ceilometer.py:957#: api/ceilometer.py:962#: api/ceilometer.py:967#: api/ceilometer.py:972#: api/ceilometer.py:977#: api/ceilometer.py:989#: api/ceilometer.py:1009#: api/ceilometer.py:1013#: api/ceilometer.py:1017#: api/ceilometer.py:1021#: api/ceilometer.py:1025#: api/ceilometer.py:1029#: api/ceilometer.py:1033#: api/ceilometer.py:1037#: api/ceilometer.py:1041#: api/ceilometer.py:1045#: api/ceilometer.py:1049#: api/ceilometer.py:1053#: api/ceilometer.py:1057#: api/ceilometer.py:1061#: api/ceilometer.py:1065#: api/ceilometer.py:1082#: api/ceilometer.py:1086#: api/ceilometer.py:1090#: api/ceilometer.py:1094#: api/ceilometer.py:1098#: api/ceilometer.py:1102#: api/ceilometer.py:1106#: api/ceilometer.py:1123#: api/ceilometer.py:1127#: api/ceilometer.py:1144#: api/ceilometer.py:1148#: api/ceilometer.py:1152#: api/ceilometer.py:1156#: api/ceilometer.py:1160#: api/ceilometer.py:1164#: api/ceilometer.py:1181#: api/ceilometer.py:1185#: api/keystone.py:324#: api/keystone.py:350#: api/keystone.py:362 api/keystone.py:378 #: dashboards/settings/password/forms.py:62#: api/swift.py:204#: dashboards/admin/flavors/workflows.py:35 dashboards/admin/info/tables.py:64#: dashboards/admin/networks/forms.py:37 #: dashboards/admin/networks/forms.py:231#: dashboards/admin/volumes/snapshots/tables.py:58#: dashboards/project/data_processing/job_binaries/tables.py:81#: dashboards/project/data_processing/nodegroup_templates/tables.py:79#: dashboards/project/images/images/forms.py:193#: dashboards/project/vpn/forms.py:136 dashboards/project/vpn/forms.py:207 #: dashboards/project/vpn/tables.py:229 dashboards/project/vpn/tables.py:259 #: dashboards/project/vpn/tables.py:279 dashboards/project/vpn/tables.py:297#: dashboards/project/instances/tables.py:902#: dashboards/project/instances/workflows/create_instance.py:77 #: dashboards/project/volumes/volumes/forms.py:88 #: dashboards/project/volumes/volumes/forms.py:93#: dashboards/admin/flavors/workflows.py:264#: dashboards/identity/projects/workflows.py:511#: dashboards/admin/defaults/workflows.py:80#: dashboards/project/instances/tables.py:921#: dashboards/admin/defaults/workflows.py:53#: dashboards/admin/defaults/workflows.py:52#: dashboards/admin/volumes/snapshots/tables.py:68#: dashboards/admin/defaults/workflows.py:51#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:109#: dashboards/project/instances/workflows/create_instance.py:490#: dashboards/admin/defaults/workflows.py:66#: dashboards/admin/defaults/workflows.py:68#: dashboards/admin/defaults/workflows.py:79#: dashboards/admin/defaults/workflows.py:81#: dashboards/admin/defaults/workflows.py:82 #: dashboards/admin/defaults/workflows.py:99#: dashboards/admin/flavors/workflows.py:177#: dashboards/admin/flavors/workflows.py:263#: dashboards/project/vpn/forms.py:138 dashboards/project/vpn/forms.py:208#: dashboards/router/nexus1000v/forms.py:173#: dashboards/project/images/images/forms.py:99 #: dashboards/project/images/images/forms.py:232#: dashboards/admin/flavors/workflows.py:38#: dashboards/admin/flavors/workflows.py:224#: dashboards/admin/flavors/workflows.py:237#: dashboards/admin/flavors/workflows.py:245#: dashboards/admin/flavors/workflows.py:150#: dashboards/admin/flavors/workflows.py:156#: dashboards/admin/flavors/workflows.py:159#: dashboards/admin/flavors/workflows.py:160#: dashboards/admin/flavors/workflows.py:161#: dashboards/admin/flavors/workflows.py:162#: dashboards/admin/flavors/workflows.py:179#: dashboards/admin/flavors/workflows.py:180#: dashboards/admin/flavors/workflows.py:205#: dashboards/admin/flavors/workflows.py:216#: dashboards/admin/flavors/workflows.py:226#: dashboards/admin/flavors/workflows.py:265#: dashboards/admin/flavors/workflows.py:266#: dashboards/admin/flavors/workflows.py:311#: dashboards/project/data_processing/data_sources/tables.py:63#: dashboards/project/volumes/volumes/forms.py:79 #: dashboards/project/volumes/volumes/forms.py:84#: dashboards/project/volumes/volumes/forms.py:642#: dashboards/project/instances/tables.py:863 #: dashboards/project/instances/tables.py:885 #: dashboards/project/instances/workflows/create_instance.py:80#: dashboards/admin/hypervisors/views.py:71#: dashboards/admin/hypervisors/compute/forms.py:28#: dashboards/admin/hypervisors/compute/forms.py:29#: dashboards/admin/hypervisors/compute/forms.py:31#: dashboards/admin/hypervisors/compute/forms.py:47#: dashboards/admin/hypervisors/compute/forms.py:49#: dashboards/admin/hypervisors/compute/forms.py:60#: dashboards/admin/hypervisors/compute/forms.py:66#: dashboards/admin/volumes/snapshots/tables.py:63#: dashboards/project/data_processing/clusters/tables.py:111#: dashboards/project/data_processing/job_executions/tables.py:152#: dashboards/project/instances/tables.py:897#: dashboards/project/vpn/tables.py:239 dashboards/project/vpn/tables.py:266#: dashboards/project/instances/tables.py:864#: dashboards/project/instances/tables.py:887#: dashboards/project/instances/workflows/create_instance.py:104 #: dashboards/project/volumes/volumes/forms.py:534#: dashboards/admin/images/views.py:177#: dashboards/admin/images/views.py:190#: dashboards/identity/projects/workflows.py:490#: dashboards/admin/networks/forms.py:39#: dashboards/admin/volumes/snapshots/tables.py:64#: dashboards/project/instances/workflows/create_instance.py:50 #: dashboards/router/nexus1000v/forms.py:118 #: dashboards/router/nexus1000v/forms.py:176#: dashboards/project/instances/tables.py:865#: dashboards/project/instances/tables.py:866#: dashboards/project/instances/tables.py:889#: dashboards/project/instances/tables.py:892#: dashboards/project/instances/tables.py:904#: dashboards/project/instances/tables.py:911#: dashboards/project/instances/tables.py:914 usage/tables.py:75#: dashboards/project/data_processing/cluster_templates/tables.py:123#: dashboards/project/data_processing/data_plugins/tables.py:35#: dashboards/project/data_processing/data_sources/tables.py:65#: dashboards/project/data_processing/job_binaries/tables.py:86#: dashboards/project/images/images/forms.py:194#: dashboards/project/volumes/snapshots/forms.py:27#: dashboards/project/volumes/volumes/forms.py:50 #: dashboards/project/volumes/volumes/forms.py:474 #: dashboards/project/volumes/volumes/forms.py:512#: dashboards/project/vpn/forms.py:141 dashboards/project/vpn/forms.py:211 #: dashboards/project/vpn/tables.py:261 dashboards/project/vpn/workflows.py:28#: dashboards/admin/networks/forms.py:44#: dashboards/admin/networks/forms.py:48#: dashboards/admin/networks/forms.py:49#: dashboards/admin/networks/forms.py:57 dashboards/admin/networks/forms.py:64 #: dashboards/admin/networks/forms.py:65 #: dashboards/router/nexus1000v/forms.py:111 #: dashboards/router/nexus1000v/forms.py:117#: dashboards/admin/networks/forms.py:58#: dashboards/admin/networks/forms.py:68 dashboards/admin/networks/forms.py:72 #: dashboards/admin/networks/forms.py:73 dashboards/admin/networks/forms.py:74#: dashboards/admin/networks/forms.py:78 #: dashboards/admin/networks/forms.py:235#: dashboards/project/vpn/forms.py:39 dashboards/project/vpn/forms.py:261#: dashboards/admin/networks/forms.py:79 #: dashboards/admin/networks/forms.py:236#: dashboards/admin/networks/forms.py:81 #: dashboards/admin/networks/forms.py:237#: dashboards/admin/networks/forms.py:90 dashboards/identity/users/forms.py:58#: dashboards/admin/networks/forms.py:113#: dashboards/admin/networks/forms.py:142 #: dashboards/project/instances/workflows/create_instance.py:688#: dashboards/admin/networks/forms.py:152 #: dashboards/project/instances/workflows/create_instance.py:698#: dashboards/admin/networks/forms.py:183#: dashboards/admin/networks/forms.py:189#: dashboards/admin/networks/forms.py:219#: dashboards/admin/networks/forms.py:222#: dashboards/admin/networks/forms.py:225#: dashboards/admin/networks/forms.py:249#: dashboards/admin/networks/forms.py:254#: dashboards/project/instances/workflows/create_instance.py:641#: dashboards/project/instances/tables.py:617#: dashboards/admin/networks/agents/forms.py:61#: dashboards/admin/networks/agents/forms.py:35#: dashboards/admin/networks/agents/forms.py:36#: dashboards/admin/networks/agents/forms.py:54#: dashboards/admin/networks/agents/forms.py:56#: dashboards/admin/networks/agents/forms.py:73#: dashboards/admin/networks/agents/forms.py:79#: dashboards/admin/volumes/tabs.py:50 dashboards/admin/volumes/tabs.py:117 #: dashboards/admin/volumes/snapshots/tables.py:51#: dashboards/admin/volumes/tabs.py:109 dashboards/project/volumes/tabs.py:90 #: dashboards/project/volumes/volumes/forms.py:201#: dashboards/admin/volumes/snapshots/tables.py:61#: dashboards/project/volumes/volumes/forms.py:47 #: dashboards/project/volumes/volumes/forms.py:510 #: dashboards/project/volumes/volumes/forms.py:531 #: dashboards/project/volumes/volumes/forms.py:591 #: dashboards/project/volumes/volumes/forms.py:639#: dashboards/project/instances/workflows/create_instance.py:98 #: dashboards/project/instances/workflows/create_instance.py:364#: dashboards/project/volumes/volumes/forms.py:219#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:304#: dashboards/project/data_processing/cluster_templates/workflows/create.py:226#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:175 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:303#: dashboards/admin/volumes/volume_types/views.py:130#: dashboards/identity/projects/workflows.py:346#: dashboards/identity/projects/workflows.py:335#: dashboards/identity/projects/workflows.py:337#: dashboards/identity/projects/workflows.py:338#: dashboards/identity/projects/workflows.py:357#: dashboards/identity/projects/workflows.py:510#: dashboards/identity/projects/workflows.py:493#: dashboards/identity/projects/workflows.py:329 #: dashboards/identity/projects/workflows.py:336#: dashboards/identity/projects/workflows.py:359#: dashboards/identity/projects/workflows.py:360#: dashboards/identity/projects/workflows.py:422#: dashboards/identity/projects/workflows.py:426#: dashboards/identity/projects/workflows.py:457#: dashboards/identity/projects/workflows.py:485#: dashboards/identity/projects/workflows.py:495#: dashboards/identity/projects/workflows.py:512#: dashboards/identity/projects/workflows.py:513#: dashboards/identity/projects/workflows.py:608#: dashboards/identity/projects/workflows.py:643#: dashboards/identity/projects/workflows.py:647#: dashboards/identity/projects/workflows.py:720#: dashboards/identity/projects/workflows.py:753#: dashboards/project/instances/forms.py:89 #: dashboards/project/instances/workflows/create_instance.py:539 #: dashboards/settings/password/forms.py:47#: dashboards/project/instances/forms.py:153#: dashboards/project/instances/workflows/create_instance.py:497#: dashboards/project/instances/tables.py:329#: dashboards/project/instances/tables.py:611#: dashboards/project/access_and_security/keypairs/forms.py:33#: dashboards/project/access_and_security/keypairs/forms.py:41 #: dashboards/project/access_and_security/keypairs/forms.py:51#: dashboards/project/instances/forms.py:113#: dashboards/project/access_and_security/keypairs/forms.py:54#: dashboards/project/access_and_security/keypairs/forms.py:65#: dashboards/project/access_and_security/keypairs/forms.py:70#: dashboards/project/instances/workflows/create_instance.py:566#: dashboards/project/data_processing/cluster_templates/tables.py:127#: dashboards/project/data_processing/cluster_templates/tables.py:115#: dashboards/project/data_processing/nodegroup_templates/tables.py:82#: dashboards/project/data_processing/cluster_templates/tables.py:117#: dashboards/project/data_processing/nodegroup_templates/tables.py:84#: dashboards/project/data_processing/cluster_templates/tables.py:119#: dashboards/project/data_processing/cluster_templates/workflows/create.py:207#: dashboards/project/instances/workflows/create_instance.py:83#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:101#: dashboards/project/data_processing/nodegroup_templates/tables.py:86#: dashboards/project/data_processing/cluster_templates/workflows/create.py:225#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:305#: dashboards/project/instances/workflows/create_instance.py:134#: dashboards/project/data_processing/cluster_templates/workflows/create.py:227#: dashboards/project/data_processing/cluster_templates/workflows/create.py:310#: dashboards/project/data_processing/clusters/tables.py:119#: dashboards/project/data_processing/clusters/tables.py:115#: dashboards/project/volumes/volumes/forms.py:207#: dashboards/project/instances/forms.py:38 #: dashboards/project/instances/forms.py:61 #: dashboards/project/instances/workflows/create_instance.py:386#: dashboards/project/data_processing/data_plugins/tables.py:39#: dashboards/project/data_processing/data_plugins/tables.py:30#: dashboards/project/data_processing/data_sources/tables.py:69#: dashboards/project/data_processing/job_binaries/tables.py:90#: dashboards/project/data_processing/job_binaries/tables.py:84#: dashboards/project/data_processing/job_executions/tables.py:161#: dashboards/project/data_processing/job_executions/tables.py:143#: dashboards/project/data_processing/job_executions/tables.py:147#: dashboards/project/instances/workflows/create_instance.py:782#: dashboards/project/data_processing/nodegroup_templates/tables.py:92#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:174 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:302#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:88#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:96#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:103#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:111#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:116#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:118#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:150#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:176#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:283#: dashboards/project/instances/workflows/create_instance.py:684#: dashboards/project/instances/tables.py:732 #: dashboards/project/instances/tables.py:739#: dashboards/project/instances/workflows/create_instance.py:784#: dashboards/project/instances/workflows/create_instance.py:801#: dashboards/project/volumes/volumes/forms.py:596#: dashboards/project/volumes/volumes/forms.py:600#: dashboards/project/instances/tables.py:303 #: dashboards/project/instances/tables.py:331 #: dashboards/project/instances/workflows/create_instance.py:781#: dashboards/project/instances/tables.py:347#: dashboards/project/instances/workflows/create_instance.py:84#: dashboards/project/instances/workflows/create_instance.py:645#: dashboards/project/instances/workflows/create_instance.py:647#: dashboards/project/instances/workflows/create_instance.py:669#: dashboards/project/instances/workflows/create_instance.py:671#: dashboards/project/instances/workflows/create_instance.py:783#: dashboards/project/images/images/forms.py:214#: dashboards/project/images/images/forms.py:209#: dashboards/project/images/images/forms.py:83 #: dashboards/project/images/images/forms.py:216#: dashboards/project/images/images/forms.py:85 #: dashboards/project/images/images/forms.py:218#: dashboards/project/images/images/forms.py:91 #: dashboards/project/images/images/forms.py:224#: dashboards/project/images/images/forms.py:93 #: dashboards/project/images/images/forms.py:226#: dashboards/project/images/images/forms.py:100 #: dashboards/project/images/images/forms.py:233#: dashboards/project/images/images/forms.py:143#: dashboards/project/images/images/forms.py:146#: dashboards/project/images/images/forms.py:184#: dashboards/project/images/images/forms.py:188#: dashboards/project/images/images/forms.py:198#: dashboards/project/images/images/forms.py:204#: dashboards/project/images/images/forms.py:246#: dashboards/project/images/images/forms.py:273#: dashboards/project/volumes/volumes/forms.py:535#: dashboards/project/instances/tables.py:383#: dashboards/project/instances/forms.py:42#: dashboards/project/instances/forms.py:47#: dashboards/project/instances/forms.py:50 #: dashboards/project/instances/workflows/create_instance.py:729#: dashboards/project/instances/forms.py:63 #: dashboards/project/instances/workflows/create_instance.py:388#: dashboards/project/instances/forms.py:75 #: dashboards/project/instances/workflows/create_instance.py:746#: dashboards/project/instances/forms.py:76 #: dashboards/project/instances/workflows/create_instance.py:747#: dashboards/project/instances/forms.py:79 #: dashboards/project/instances/workflows/create_instance.py:158 #: dashboards/project/instances/workflows/create_instance.py:756#: dashboards/project/instances/forms.py:103#: dashboards/project/instances/forms.py:106#: dashboards/project/instances/forms.py:114#: dashboards/project/instances/forms.py:121#: dashboards/project/instances/forms.py:124#: dashboards/project/instances/forms.py:139#: dashboards/project/instances/forms.py:145#: dashboards/project/instances/forms.py:149#: dashboards/project/instances/forms.py:157#: dashboards/project/instances/tables.py:247#: dashboards/project/instances/tables.py:262#: dashboards/project/instances/tables.py:242#: dashboards/project/instances/tables.py:257#: dashboards/project/instances/tables.py:370#: dashboards/project/instances/tables.py:396#: dashboards/project/instances/tables.py:416#: dashboards/project/instances/tables.py:433#: dashboards/project/instances/tables.py:457#: dashboards/project/instances/tables.py:470#: dashboards/project/instances/tables.py:483#: dashboards/project/instances/tables.py:500#: dashboards/project/instances/tables.py:523 #: dashboards/project/instances/tables.py:547#: dashboards/project/instances/tables.py:566#: dashboards/project/instances/tables.py:570#: dashboards/project/instances/tables.py:576#: dashboards/project/instances/tables.py:605#: dashboards/project/instances/tables.py:608#: dashboards/project/instances/tables.py:618#: dashboards/project/instances/tables.py:620#: dashboards/project/instances/tables.py:632#: dashboards/project/instances/tables.py:658#: dashboards/project/instances/tables.py:666#: dashboards/project/instances/tables.py:687#: dashboards/project/instances/tables.py:696#: dashboards/project/instances/tables.py:723#: dashboards/project/instances/tables.py:747 #: dashboards/project/instances/tables.py:769#: dashboards/project/instances/tables.py:748#: dashboards/project/instances/tables.py:749#: dashboards/project/instances/tables.py:751#: dashboards/project/instances/tables.py:752#: dashboards/project/instances/tables.py:753#: dashboards/project/instances/tables.py:755#: dashboards/project/instances/tables.py:757#: dashboards/project/instances/tables.py:759#: dashboards/project/instances/tables.py:760#: dashboards/project/instances/tables.py:762#: dashboards/project/instances/tables.py:763#: dashboards/project/instances/tables.py:764#: dashboards/project/instances/tables.py:766#: dashboards/project/instances/tables.py:767#: dashboards/project/instances/tables.py:768#: dashboards/project/instances/tables.py:771#: dashboards/project/instances/tables.py:772#: dashboards/project/instances/tables.py:774#: dashboards/project/instances/tables.py:780#: dashboards/project/instances/tables.py:782#: dashboards/project/instances/tables.py:784#: dashboards/project/instances/tables.py:785#: dashboards/project/instances/tables.py:787#: dashboards/project/instances/tables.py:789#: dashboards/project/instances/tables.py:791#: dashboards/project/instances/tables.py:793#: dashboards/project/instances/tables.py:795#: dashboards/project/instances/tables.py:797#: dashboards/project/instances/tables.py:799#: dashboards/project/instances/tables.py:801#: dashboards/project/instances/tables.py:803#: dashboards/project/instances/tables.py:805#: dashboards/project/instances/tables.py:807#: dashboards/project/instances/tables.py:809#: dashboards/project/instances/tables.py:810#: dashboards/project/instances/tables.py:812#: dashboards/project/instances/tables.py:813#: dashboards/project/instances/tables.py:814 #: dashboards/project/instances/tables.py:817#: dashboards/project/instances/tables.py:816#: dashboards/project/instances/tables.py:819#: dashboards/project/instances/tables.py:821#: dashboards/project/instances/tables.py:822#: dashboards/project/instances/tables.py:824#: dashboards/project/instances/tables.py:826#: dashboards/project/instances/tables.py:828#: dashboards/project/instances/tables.py:830#: dashboards/project/instances/tables.py:831#: dashboards/project/instances/tables.py:832#: dashboards/project/instances/tables.py:834#: dashboards/project/instances/tables.py:835#: dashboards/project/instances/tables.py:836#: dashboards/project/instances/tables.py:838#: dashboards/project/instances/tables.py:840#: dashboards/project/instances/tables.py:842#: dashboards/project/instances/tables.py:844#: dashboards/project/instances/tables.py:848#: dashboards/project/instances/tables.py:849#: dashboards/project/instances/tables.py:850#: dashboards/project/instances/tables.py:851#: dashboards/project/instances/tables.py:852#: dashboards/project/instances/tables.py:853#: dashboards/project/instances/tables.py:854#: dashboards/project/instances/tables.py:855#: dashboards/project/instances/tables.py:856#: dashboards/project/instances/tables.py:857#: dashboards/project/instances/tables.py:894 #: dashboards/project/instances/workflows/create_instance.py:475#: dashboards/project/instances/workflows/create_instance.py:51#: dashboards/project/instances/workflows/create_instance.py:65#: dashboards/project/instances/workflows/create_instance.py:86#: dashboards/project/instances/workflows/create_instance.py:89#: dashboards/project/instances/workflows/create_instance.py:91#: dashboards/project/instances/workflows/create_instance.py:92#: dashboards/project/instances/workflows/create_instance.py:95#: dashboards/project/instances/workflows/create_instance.py:100#: dashboards/project/instances/workflows/create_instance.py:111#: dashboards/project/instances/workflows/create_instance.py:115#: dashboards/project/instances/workflows/create_instance.py:118 #: dashboards/project/volumes/volumes/forms.py:400#: dashboards/project/instances/workflows/create_instance.py:121#: dashboards/project/instances/workflows/create_instance.py:127#: dashboards/project/instances/workflows/create_instance.py:130#: dashboards/project/instances/workflows/create_instance.py:145#: dashboards/project/instances/workflows/create_instance.py:146#: dashboards/project/instances/workflows/create_instance.py:147#: dashboards/project/instances/workflows/create_instance.py:150#: dashboards/project/instances/workflows/create_instance.py:156#: dashboards/project/instances/workflows/create_instance.py:162#: dashboards/project/instances/workflows/create_instance.py:173#: dashboards/project/instances/workflows/create_instance.py:200#: dashboards/project/instances/workflows/create_instance.py:207#: dashboards/project/instances/workflows/create_instance.py:214#: dashboards/project/instances/workflows/create_instance.py:229#: dashboards/project/instances/workflows/create_instance.py:232#: dashboards/project/instances/workflows/create_instance.py:235#: dashboards/project/instances/workflows/create_instance.py:258#: dashboards/project/instances/workflows/create_instance.py:275#: dashboards/project/instances/workflows/create_instance.py:286 #: dashboards/project/instances/workflows/create_instance.py:303#: dashboards/project/instances/workflows/create_instance.py:291#: dashboards/project/instances/workflows/create_instance.py:297#: dashboards/project/instances/workflows/create_instance.py:320 #: dashboards/project/volumes/volumes/forms.py:271#: dashboards/project/instances/workflows/create_instance.py:326 #: dashboards/project/volumes/volumes/forms.py:274#: dashboards/project/instances/workflows/create_instance.py:328 #: dashboards/project/volumes/volumes/forms.py:276#: dashboards/project/instances/workflows/create_instance.py:351#: dashboards/project/instances/workflows/create_instance.py:361 #: dashboards/project/volumes/volumes/forms.py:194#: dashboards/project/instances/workflows/create_instance.py:366#: dashboards/project/instances/workflows/create_instance.py:400#: dashboards/project/instances/workflows/create_instance.py:402#: dashboards/project/instances/workflows/create_instance.py:414 #: dashboards/project/volumes/volumes/forms.py:289#: dashboards/project/instances/workflows/create_instance.py:416#: dashboards/project/instances/workflows/create_instance.py:418#: dashboards/project/instances/workflows/create_instance.py:429#: dashboards/project/instances/workflows/create_instance.py:432#: dashboards/project/instances/workflows/create_instance.py:434#: dashboards/project/instances/workflows/create_instance.py:477#: dashboards/project/instances/workflows/create_instance.py:481#: dashboards/project/instances/workflows/create_instance.py:487#: dashboards/project/instances/workflows/create_instance.py:493#: dashboards/project/instances/workflows/create_instance.py:498#: dashboards/project/instances/workflows/create_instance.py:514#: dashboards/project/instances/workflows/create_instance.py:518#: dashboards/project/instances/workflows/create_instance.py:520#: dashboards/project/instances/workflows/create_instance.py:529#: dashboards/project/instances/workflows/create_instance.py:561#: dashboards/project/instances/workflows/create_instance.py:565#: dashboards/project/instances/workflows/create_instance.py:569#: dashboards/project/instances/workflows/create_instance.py:573#: dashboards/project/instances/workflows/create_instance.py:577 #: dashboards/project/instances/workflows/create_instance.py:582#: dashboards/project/instances/workflows/create_instance.py:586 #: dashboards/project/instances/workflows/create_instance.py:591#: dashboards/project/instances/workflows/create_instance.py:618#: dashboards/project/instances/workflows/create_instance.py:626#: dashboards/project/instances/workflows/create_instance.py:653#: dashboards/project/instances/workflows/create_instance.py:656#: dashboards/project/instances/workflows/create_instance.py:730#: dashboards/project/instances/workflows/create_instance.py:733#: dashboards/project/instances/workflows/create_instance.py:734#: dashboards/project/instances/workflows/create_instance.py:760#: dashboards/project/instances/workflows/create_instance.py:798#: dashboards/project/instances/workflows/create_instance.py:857#: dashboards/project/vpn/tables.py:262 dashboards/project/vpn/workflows.py:30#: dashboards/project/vpn/tables.py:263 dashboards/project/vpn/workflows.py:29#: dashboards/project/stacks/forms.py:229 #: dashboards/project/stacks/forms.py:375#: dashboards/project/stacks/forms.py:231 #: dashboards/project/stacks/forms.py:255 #: dashboards/project/stacks/forms.py:377#: dashboards/project/stacks/forms.py:240#: dashboards/project/stacks/forms.py:256#: dashboards/project/stacks/forms.py:258#: dashboards/project/stacks/forms.py:263#: dashboards/project/stacks/forms.py:264#: dashboards/project/stacks/forms.py:266#: dashboards/project/stacks/forms.py:267#: dashboards/project/stacks/forms.py:280#: dashboards/project/stacks/forms.py:281#: dashboards/project/stacks/forms.py:364#: dashboards/project/stacks/forms.py:373#: dashboards/project/stacks/forms.py:406#: dashboards/project/volumes/snapshots/forms.py:37#: dashboards/project/volumes/snapshots/forms.py:43#: dashboards/project/volumes/volumes/forms.py:51#: dashboards/project/volumes/volumes/forms.py:57#: dashboards/project/volumes/volumes/forms.py:64#: dashboards/project/volumes/volumes/forms.py:71#: dashboards/project/volumes/volumes/forms.py:86#: dashboards/project/volumes/volumes/forms.py:99#: dashboards/project/volumes/volumes/forms.py:118#: dashboards/project/volumes/volumes/forms.py:127#: dashboards/project/volumes/volumes/forms.py:138#: dashboards/project/volumes/volumes/forms.py:146#: dashboards/project/volumes/volumes/forms.py:157#: dashboards/project/volumes/volumes/forms.py:166#: dashboards/project/volumes/volumes/forms.py:173#: dashboards/project/volumes/volumes/forms.py:195#: dashboards/project/volumes/volumes/forms.py:208#: dashboards/project/volumes/volumes/forms.py:220#: dashboards/project/volumes/volumes/forms.py:229#: dashboards/project/volumes/volumes/forms.py:240#: dashboards/project/volumes/volumes/forms.py:244#: dashboards/project/volumes/volumes/forms.py:248#: dashboards/project/volumes/volumes/forms.py:257#: dashboards/project/volumes/volumes/forms.py:311#: dashboards/project/volumes/volumes/forms.py:323#: dashboards/project/volumes/volumes/forms.py:330#: dashboards/project/volumes/volumes/forms.py:340#: dashboards/project/volumes/volumes/forms.py:348#: dashboards/project/volumes/volumes/forms.py:355#: dashboards/project/volumes/volumes/forms.py:371#: dashboards/project/volumes/volumes/forms.py:379#: dashboards/project/volumes/volumes/forms.py:396#: dashboards/project/volumes/volumes/forms.py:397#: dashboards/project/volumes/volumes/forms.py:404#: dashboards/project/volumes/volumes/forms.py:489#: dashboards/project/volumes/volumes/forms.py:492#: dashboards/project/volumes/volumes/forms.py:505#: dashboards/project/volumes/volumes/forms.py:520#: dashboards/project/volumes/volumes/forms.py:526#: dashboards/project/volumes/volumes/forms.py:540#: dashboards/project/volumes/volumes/forms.py:575#: dashboards/project/volumes/volumes/forms.py:582#: dashboards/project/volumes/volumes/forms.py:608#: dashboards/project/volumes/volumes/forms.py:614#: dashboards/project/volumes/volumes/forms.py:628#: dashboards/project/volumes/volumes/forms.py:634#: dashboards/project/volumes/volumes/forms.py:643#: dashboards/project/volumes/volumes/forms.py:644#: dashboards/project/volumes/volumes/forms.py:645#: dashboards/project/volumes/volumes/forms.py:662#: dashboards/project/volumes/volumes/forms.py:671#: dashboards/project/volumes/volumes/forms.py:687#: dashboards/project/volumes/volumes/forms.py:696#: dashboards/project/vpn/forms.py:73 dashboards/project/vpn/forms.py:144 #: dashboards/project/vpn/tables.py:282 dashboards/project/vpn/tables.py:300#: dashboards/project/vpn/forms.py:74 dashboards/project/vpn/forms.py:145#: dashboards/project/vpn/forms.py:77 dashboards/project/vpn/forms.py:152 #: dashboards/project/vpn/tables.py:285 dashboards/project/vpn/tables.py:303#: dashboards/project/vpn/forms.py:78 dashboards/project/vpn/forms.py:153#: dashboards/project/vpn/forms.py:79 dashboards/project/vpn/forms.py:154#: dashboards/project/vpn/forms.py:80 dashboards/project/vpn/forms.py:155#: dashboards/project/vpn/forms.py:81 dashboards/project/vpn/forms.py:156#: dashboards/project/vpn/forms.py:89 dashboards/project/vpn/forms.py:160#: dashboards/project/vpn/forms.py:94 dashboards/project/vpn/forms.py:165#: dashboards/project/vpn/forms.py:96 dashboards/project/vpn/forms.py:167#: dashboards/project/vpn/forms.py:97 dashboards/project/vpn/forms.py:168#: dashboards/project/vpn/forms.py:98 dashboards/project/vpn/forms.py:169#: dashboards/project/vpn/forms.py:99 dashboards/project/vpn/forms.py:170#: dashboards/project/vpn/forms.py:123#: dashboards/project/vpn/forms.py:129#: dashboards/project/vpn/forms.py:148 dashboards/project/vpn/workflows.py:214#: dashboards/project/vpn/forms.py:149#: dashboards/project/vpn/forms.py:150#: dashboards/project/vpn/forms.py:159 dashboards/project/vpn/workflows.py:216#: dashboards/project/vpn/forms.py:164#: dashboards/project/vpn/forms.py:172 dashboards/project/vpn/workflows.py:222#: dashboards/project/vpn/forms.py:173#: dashboards/project/vpn/forms.py:174#: dashboards/project/vpn/forms.py:175#: dashboards/project/vpn/forms.py:194#: dashboards/project/vpn/forms.py:200#: dashboards/project/vpn/forms.py:213 dashboards/project/vpn/workflows.py:317#: dashboards/project/vpn/forms.py:214 dashboards/project/vpn/workflows.py:318#: dashboards/project/vpn/forms.py:219 dashboards/project/vpn/workflows.py:323#: dashboards/project/vpn/forms.py:220 dashboards/project/vpn/workflows.py:324#: dashboards/project/vpn/forms.py:225 dashboards/project/vpn/workflows.py:329#: dashboards/project/vpn/forms.py:226 dashboards/project/vpn/workflows.py:330#: dashboards/project/vpn/forms.py:233 dashboards/project/vpn/workflows.py:337#: dashboards/project/vpn/forms.py:236 dashboards/project/vpn/workflows.py:402#: dashboards/project/vpn/forms.py:237 dashboards/project/vpn/workflows.py:404#: dashboards/project/vpn/forms.py:241 dashboards/project/vpn/workflows.py:407#: dashboards/project/vpn/forms.py:242#: dashboards/project/vpn/forms.py:243#: dashboards/project/vpn/forms.py:244#: dashboards/project/vpn/forms.py:245#: dashboards/project/vpn/forms.py:246#: dashboards/project/vpn/forms.py:249 dashboards/project/vpn/workflows.py:409#: dashboards/project/vpn/forms.py:250 dashboards/project/vpn/workflows.py:411#: dashboards/project/vpn/forms.py:253 dashboards/project/vpn/workflows.py:413#: dashboards/project/vpn/forms.py:254 dashboards/project/vpn/workflows.py:415#: dashboards/project/vpn/forms.py:256 dashboards/project/vpn/workflows.py:416#: dashboards/project/vpn/forms.py:257#: dashboards/project/vpn/forms.py:258#: dashboards/project/vpn/forms.py:285#: dashboards/project/vpn/forms.py:291#: dashboards/project/vpn/tables.py:232#: dashboards/project/vpn/tables.py:234#: dashboards/project/vpn/tables.py:236#: dashboards/project/vpn/tables.py:245 dashboards/project/vpn/tabs.py:27#: dashboards/project/vpn/tables.py:272 dashboards/project/vpn/tabs.py:47#: dashboards/project/vpn/tables.py:286 dashboards/project/vpn/tables.py:304#: dashboards/project/vpn/tables.py:290 dashboards/project/vpn/tabs.py:67#: dashboards/project/vpn/tables.py:308 dashboards/project/vpn/tabs.py:87#: dashboards/project/vpn/tabs.py:39#: dashboards/project/vpn/tabs.py:59 dashboards/project/vpn/workflows.py:375#: dashboards/project/vpn/tabs.py:79 dashboards/project/vpn/workflows.py:346#: dashboards/project/vpn/tabs.py:99 dashboards/project/vpn/workflows.py:361#: dashboards/project/vpn/tabs.py:113#: dashboards/project/vpn/tabs.py:128#: dashboards/project/vpn/tabs.py:143#: dashboards/project/vpn/tabs.py:158#: dashboards/project/vpn/views.py:85#: dashboards/project/vpn/views.py:132#: dashboards/project/vpn/views.py:164#: dashboards/project/vpn/views.py:199#: dashboards/project/vpn/views.py:239#: dashboards/project/vpn/views.py:282#: dashboards/project/vpn/views.py:311#: dashboards/project/vpn/views.py:347#: dashboards/project/vpn/views.py:384#: dashboards/router/nexus1000v/forms.py:49 #: dashboards/router/nexus1000v/forms.py:69 msgid ""VLAN"" msgstr ""VLAN"" #: dashboards/router/nexus1000v/forms.py:74#: dashboards/router/nexus1000v/forms.py:76 #: dashboards/router/nexus1000v/forms.py:82 #: dashboards/router/nexus1000v/forms.py:84#: dashboards/router/nexus1000v/forms.py:85#: dashboards/router/nexus1000v/forms.py:88 #: dashboards/router/nexus1000v/forms.py:95#: dashboards/router/nexus1000v/forms.py:96#: dashboards/router/nexus1000v/forms.py:100 #: dashboards/router/nexus1000v/forms.py:107#: dashboards/router/nexus1000v/forms.py:109#: dashboards/router/nexus1000v/forms.py:159#: dashboards/router/nexus1000v/forms.py:166#: dashboards/router/nexus1000v/forms.py:200#: dashboards/router/nexus1000v/forms.py:206#: dashboards/settings/password/forms.py:31#: dashboards/settings/password/forms.py:33#: dashboards/settings/password/forms.py:38#: dashboards/settings/password/forms.py:67#: dashboards/settings/password/forms.py:70",10190,10048
openstack%2Ffuel-library~master~Id6caeacc10b07898af06768f6dde5261d9ea5f89,openstack/fuel-library,master,Id6caeacc10b07898af06768f6dde5261d9ea5f89,The modified puppet code style,MERGED,2014-07-07 09:05:23.000000000,2014-10-17 08:18:31.000000000,2014-10-17 08:18:29.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 13343}]","[{'number': 1, 'created': '2014-07-07 09:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3000987e3da5ecf7107b1a384b10c8172a6eeb67', 'message': 'The modified puppet code style\n\nAdd the Rakefile file:\n * add dependency rubygems\n * disable 80 chars check\n * disable two-space soft tabs check\n * disable arrow alignment check\n * disable selector inside resource check\n * disable class parameter defaults\nThe remaining work is in the correction puppet code specifications\n\nChange-Id: Id6caeacc10b07898af06768f6dde5261d9ea5f89\nCloses-Bug: #1338477\n'}, {'number': 2, 'created': '2014-07-11 10:25:38.000000000', 'files': ['deployment/puppet/ceph/manifests/apt.pp', 'deployment/puppet/ceph/manifests/conf.pp', 'deployment/puppet/ceph/examples/site.pp', 'deployment/puppet/ceph/Rakefile', 'deployment/puppet/ceph/manifests/yum.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5487d0fec6eb3283769638c891ea5139842bf364', 'message': 'The modified puppet code style\n\nAdd the Rakefile file:\n * add dependency rubygems\n * disable 80 chars check\n * disable two-space soft tabs check\n * disable arrow alignment check\n * disable selector inside resource check\n * disable class parameter defaults\nThe remaining work is in the correction puppet code specifications\n\nChange-Id: Id6caeacc10b07898af06768f6dde5261d9ea5f89\nCloses-Bug: #1338477\n'}]",0,105097,5487d0fec6eb3283769638c891ea5139842bf364,25,7,2,9536,,,0,"The modified puppet code style

Add the Rakefile file:
 * add dependency rubygems
 * disable 80 chars check
 * disable two-space soft tabs check
 * disable arrow alignment check
 * disable selector inside resource check
 * disable class parameter defaults
The remaining work is in the correction puppet code specifications

Change-Id: Id6caeacc10b07898af06768f6dde5261d9ea5f89
Closes-Bug: #1338477
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/97/105097/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/ceph/manifests/apt.pp', 'deployment/puppet/ceph/manifests/conf.pp', 'deployment/puppet/ceph/examples/site.pp', 'deployment/puppet/ceph/Rakefile', 'deployment/puppet/ceph/manifests/yum.pp']",5,3000987e3da5ecf7107b1a384b10c8172a6eeb67,bug/1338477,{ } },{ } } ,21,11
openstack%2Ffuel-devops~master~I40fd026829d07d08ba9c10fb5e5d734d62197fa9,openstack/fuel-devops,master,I40fd026829d07d08ba9c10fb5e5d734d62197fa9,test,ABANDONED,2014-09-19 18:54:21.000000000,2014-10-17 08:16:13.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-09-19 18:54:21.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/4847d2e97a0da2593411ce06983c843957e81585', 'message': 'test\n\nChange-Id: I40fd026829d07d08ba9c10fb5e5d734d62197fa9\n'}]",0,122829,4847d2e97a0da2593411ce06983c843957e81585,5,2,1,406,,,0,"test

Change-Id: I40fd026829d07d08ba9c10fb5e5d734d62197fa9
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/29/122829/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,4847d2e97a0da2593411ce06983c843957e81585,, test,,3,0
openstack%2Fhorizon~master~Ieed4db962ccdadcb346c8ca7e6e789766f9838e5,openstack/horizon,master,Ieed4db962ccdadcb346c8ca7e6e789766f9838e5,Change django message storage backends default.,MERGED,2014-06-23 03:13:43.000000000,2014-10-17 08:06:56.000000000,2014-10-17 08:06:55.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 6650}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 10513}]","[{'number': 1, 'created': '2014-06-23 03:13:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/246914ebf24b0af0230b3f904fee7a705efcfb65', 'message': 'Change django message storage backends default.\n\nDue to original cookie storage backends have limit 4096 bytes,\nchange it to fallbackstorage, which could store extra message in\nsession storage.\n\nRelated django storage illustration\nhttps://docs.djangoproject.com/en/1.2/ref/contrib/messages/#storage-backends\n\nChange-Id: Ieed4db962ccdadcb346c8ca7e6e789766f9838e5\n'}, {'number': 2, 'created': '2014-08-02 07:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/59b3504511e225603e1689eba9c1217138f384b7', 'message': 'Change django message storage backends default.\n\nDue to original cookie storage backends have limit 2048 bytes,\nchange it to fallbackstorage, which could store extra message in\nsession storage.\n\nRelated django storage illustration\nhttps://docs.djangoproject.com/en/1.6/ref/contrib/messages/#module-django.contrib.messages\n\nFixes: bug #1168541\nChange-Id: Ieed4db962ccdadcb346c8ca7e6e789766f9838e5\n'}, {'number': 3, 'created': '2014-08-04 02:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1fd03597c1a27bdd65c3963eea3afc94fb6bd9ec', 'message': 'Change django message storage backends default.\n\nDue to original cookie storage backends have limit 2048 bytes,\nchange it to fallbackstorage, which could store extra message in\nsession storage.\n\nRelated django storage illustration\nhttps://docs.djangoproject.com/en/1.6/ref/contrib/messages/#module-django.contrib.messages\n\nCloses-Bug: #1168541\nChange-Id: Ieed4db962ccdadcb346c8ca7e6e789766f9838e5\n'}, {'number': 4, 'created': '2014-08-27 02:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/97cf00191228d8ab0197031ae05bb769cfd6343b', 'message': 'Change django message storage backends default.\n\nDue to original cookie storage backends have limit 2048 bytes,\nchange it to fallbackstorage, which could store extra message in\nsession storage.\n\nRelated django storage illustration\nhttps://docs.djangoproject.com/en/1.6/ref/contrib/messages/#module-django.contrib.messages\n\nCloses-Bug: #1168541\nChange-Id: Ieed4db962ccdadcb346c8ca7e6e789766f9838e5\n'}, {'number': 5, 'created': '2014-09-03 02:27:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/35c79a4a33973b550b2881eb6d66e316638668ba', 'message': 'Change django message storage backends default.\n\nDue to original cookie storage backends have limit 2048 bytes,\nchange it to fallbackstorage, which could store extra message in\nsession storage.\n\nRelated django storage illustration\nhttps://docs.djangoproject.com/en/1.6/ref/contrib/messages/#module-django.contrib.messages\n\nCloses-Bug: #1168541\nChange-Id: Ieed4db962ccdadcb346c8ca7e6e789766f9838e5\n'}, {'number': 6, 'created': '2014-09-17 03:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6d2096012c22fb9355c0a785865767613e340433', 'message': 'Change django message storage backends default.\n\nDue to original cookie storage backends have limit 2048 bytes,\nchange it to fallbackstorage, which could store extra message in\nsession storage.\n\nRelated django storage illustration\nhttps://docs.djangoproject.com/en/1.6/ref/contrib/messages/#module-django.contrib.messages\n\nCloses-Bug: #1168541\nChange-Id: Ieed4db962ccdadcb346c8ca7e6e789766f9838e5\n'}, {'number': 7, 'created': '2014-10-10 04:27:18.000000000', 'files': ['openstack_dashboard/settings.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d68e68c5bd743767ed3ff276d849f174e03cffbe', 'message': 'Change django message storage backends default.\n\nDue to original cookie storage backends have limit 2048 bytes,\nchange it to fallbackstorage, which could store extra message in\nsession storage.\n\nRelated django storage illustration\nhttps://docs.djangoproject.com/en/1.6/ref/contrib/messages/#module-django.contrib.messages\n\nCloses-Bug: #1168541\nChange-Id: Ieed4db962ccdadcb346c8ca7e6e789766f9838e5\n'}]",8,101791,d68e68c5bd743767ed3ff276d849f174e03cffbe,36,8,7,10513,,,0,"Change django message storage backends default.

Due to original cookie storage backends have limit 2048 bytes,
change it to fallbackstorage, which could store extra message in
session storage.

Related django storage illustration
https://docs.djangoproject.com/en/1.6/ref/contrib/messages/#module-django.contrib.messages

Closes-Bug: #1168541
Change-Id: Ieed4db962ccdadcb346c8ca7e6e789766f9838e5
",git fetch https://review.opendev.org/openstack/horizon refs/changes/91/101791/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/settings.py'],1,246914ebf24b0af0230b3f904fee7a705efcfb65,bug_1168541,MESSAGE_STORAGE = 'django.contrib.messages.storage.fallback.FallbackStorage',MESSAGE_STORAGE = 'django.contrib.messages.storage.cookie.CookieStorage',1,1
openstack%2Fheat~master~I4884a929ede1c6bff835fe789e5dd890a06831c2,openstack/heat,master,I4884a929ede1c6bff835fe789e5dd890a06831c2,ResourceGroup update refactor,MERGED,2014-10-14 17:03:43.000000000,2014-10-17 06:54:53.000000000,2014-10-17 06:54:52.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7256}, {'_account_id': 7404}]","[{'number': 1, 'created': '2014-10-14 17:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5eb6326a49381710d43f5291ba62e07f1890aed0', 'message': 'ResourceGroup update refactor\n\nReworks ResourceGroup.handle_update a little so we save the updated\nproperties in the resource object before processing the update.\n\nThis is required so we can have a hint property which specifies\nvictims to be removed on update\n\nChange-Id: I4884a929ede1c6bff835fe789e5dd890a06831c2\nblueprint: resourcegroup-force-remove\n'}, {'number': 2, 'created': '2014-10-14 22:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7e7d77a719506853c6c887f89db63216c9164310', 'message': 'ResourceGroup update refactor\n\nReworks ResourceGroup.handle_update a little so we save the updated\nproperties in the resource object before processing the update.\n\nThis is required so we can have a hint property which specifies\nvictims to be removed on update\n\nChange-Id: I4884a929ede1c6bff835fe789e5dd890a06831c2\nblueprint: resourcegroup-force-remove\n'}, {'number': 3, 'created': '2014-10-15 14:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8b24ddb9209c1637972215edec6f16a47e243149', 'message': 'ResourceGroup update refactor\n\nReworks ResourceGroup.handle_update a little so we save the updated\nproperties in the resource object before processing the update.\n\nThis is required so we can have a hint property which specifies\nvictims to be removed on update\n\nChange-Id: I4884a929ede1c6bff835fe789e5dd890a06831c2\nblueprint: resourcegroup-force-remove\n'}, {'number': 4, 'created': '2014-10-15 17:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f9f6dce5d9dc2e568686cb31c8e2a0342feb1234', 'message': 'ResourceGroup update refactor\n\nReworks ResourceGroup.handle_update a little so we save the updated\nproperties in the resource object before processing the update.\n\nThis is required so we can have a hint property which specifies\nvictims to be removed on update\n\nChange-Id: I4884a929ede1c6bff835fe789e5dd890a06831c2\nblueprint: resourcegroup-force-remove\n'}, {'number': 5, 'created': '2014-10-16 16:12:57.000000000', 'files': ['heat/tests/test_structured_config.py', 'heat/engine/resources/resource_group.py', 'heat/tests/test_software_deployment.py', 'heat/tests/test_resource_group.py', 'heat/engine/resources/software_config/software_deployment.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d2a8c0a38ebac6998911e201ab6dc3718308e262', 'message': 'ResourceGroup update refactor\n\nReworks ResourceGroup.handle_update a little so we save the updated\nproperties in the resource object before processing the update.\n\nThis is required so we can have a hint property which specifies\nvictims to be removed on update\n\nChange-Id: I4884a929ede1c6bff835fe789e5dd890a06831c2\nblueprint: resourcegroup-force-remove\n'}]",1,128364,d2a8c0a38ebac6998911e201ab6dc3718308e262,25,5,5,4328,,,0,"ResourceGroup update refactor

Reworks ResourceGroup.handle_update a little so we save the updated
properties in the resource object before processing the update.

This is required so we can have a hint property which specifies
victims to be removed on update

Change-Id: I4884a929ede1c6bff835fe789e5dd890a06831c2
blueprint: resourcegroup-force-remove
",git fetch https://review.opendev.org/openstack/heat refs/changes/64/128364/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/resource_group.py', 'heat/tests/test_resource_group.py']",2,5eb6326a49381710d43f5291ba62e07f1890aed0,bp/resourcegroup-force-remove," self.assertEqual(2, len(resg.nested())) resource_names = [r.name for r in resg.nested().iter_resources()] self.assertEqual(['0', '1'], sorted(resource_names)) old_snip = copy.deepcopy(resg.t) resource_names = [r.name for r in resg.nested().iter_resources()] self.assertEqual(['0', '1', '2'], sorted(resource_names)) scheduler.TaskRunner(resg.update, old_snip)() self.assertEqual((resg.UPDATE, resg.COMPLETE), resg.state) self.assertEqual((resg.UPDATE, resg.COMPLETE), resg.nested().state) self.assertEqual(2, len(resg.nested())) resource_names = [r.name for r in resg.nested().iter_resources()] self.assertEqual(['0', '1'], sorted(resource_names))",,26,11
openstack%2Fopenstack-manuals~master~I8a376782b79e9bb77df885ab0a8ff770f5238127,openstack/openstack-manuals,master,I8a376782b79e9bb77df885ab0a8ff770f5238127,Imported Translations from Transifex,MERGED,2014-10-17 06:13:46.000000000,2014-10-17 06:51:36.000000000,2014-10-17 06:51:35.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-17 06:13:46.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/user-guide/locale/ja.po', 'doc/config-reference/locale/config-reference.pot', 'doc/image-guide/locale/image-guide.pot', 'doc/user-guide/locale/fr.po', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/user-guide-admin/locale/ja.po', 'doc/user-guide/locale/user-guide.pot', 'doc/cli-reference/locale/cli-reference.pot', 'doc/user-guide-admin/locale/user-guide-admin.pot', 'doc/glossary/locale/ko_KR.po', 'doc/image-guide/locale/fr.po', 'doc/image-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4e385e5206df72aa688ccc970cfab94dfbd4830b', 'message': 'Imported Translations from Transifex\n\nChange-Id: I8a376782b79e9bb77df885ab0a8ff770f5238127\n'}]",0,129141,4e385e5206df72aa688ccc970cfab94dfbd4830b,6,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I8a376782b79e9bb77df885ab0a8ff770f5238127
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/41/129141/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/user-guide/locale/ja.po', 'doc/config-reference/locale/config-reference.pot', 'doc/image-guide/locale/image-guide.pot', 'doc/user-guide/locale/fr.po', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/user-guide-admin/locale/ja.po', 'doc/user-guide/locale/user-guide.pot', 'doc/cli-reference/locale/cli-reference.pot', 'doc/user-guide-admin/locale/user-guide-admin.pot', 'doc/glossary/locale/ko_KR.po', 'doc/image-guide/locale/fr.po', 'doc/image-guide/locale/ja.po']",15,4e385e5206df72aa688ccc970cfab94dfbd4830b,transifex/translations,"""POT-Creation-Date: 2014-10-16 19:53+0000\n"" ""PO-Revision-Date: 2014-10-16 15:17+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgid ""2014-10-15"" msgstr """" #: ./doc/image-guide/bk-imageguide.xml47(para) msgid ""Minor revisions for Juno."" msgstr """" #: ./doc/image-guide/bk-imageguide.xml54(date)#: ./doc/image-guide/bk-imageguide.xml58(para)#: ./doc/image-guide/bk-imageguide.xml68(date)#: ./doc/image-guide/bk-imageguide.xml72(para)#: ./doc/image-guide/bk-imageguide.xml79(date)#: ./doc/image-guide/bk-imageguide.xml83(para)#: ./doc/image-guide/bk-imageguide.xml89(date)#: ./doc/image-guide/bk-imageguide.xml93(para)#: ./doc/image-guide/bk-imageguide.xml100(date)#: ./doc/image-guide/bk-imageguide.xml104(para)","""POT-Creation-Date: 2014-10-06 16:27+0000\n"" ""PO-Revision-Date: 2014-10-07 03:50+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""#: ./doc/image-guide/bk-imageguide.xml47(para)#: ./doc/image-guide/bk-imageguide.xml57(date)#: ./doc/image-guide/bk-imageguide.xml61(para)#: ./doc/image-guide/bk-imageguide.xml68(date)#: ./doc/image-guide/bk-imageguide.xml72(para)#: ./doc/image-guide/bk-imageguide.xml78(date)#: ./doc/image-guide/bk-imageguide.xml82(para)#: ./doc/image-guide/bk-imageguide.xml89(date)#: ./doc/image-guide/bk-imageguide.xml93(para)",625,459
openstack%2Fheat~master~I090359c212df1d17b10e374d2e80e22344017aee,openstack/heat,master,I090359c212df1d17b10e374d2e80e22344017aee,Support Cinder scheduler hints,MERGED,2014-10-06 13:41:37.000000000,2014-10-17 06:41:00.000000000,2014-10-17 06:40:59.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8328}, {'_account_id': 9542}, {'_account_id': 10787}, {'_account_id': 12561}, {'_account_id': 13134}]","[{'number': 1, 'created': '2014-10-06 13:41:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0572801b378a802a0fea7e1c11d9c26df5f21452', 'message': ""Support Cinder scheduler hints\n\nAdd a 'scheduler_hints' option for OS::Cinder::Volume objects, as is\nit already done for OS::Nova::Server.\n\nImplements: blueprint cinder-scheduler-hints\nChange-Id: I090359c212df1d17b10e374d2e80e22344017aee\n""}, {'number': 2, 'created': '2014-10-06 19:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/152c343c2237e080d50caf743b41bdce03d3dacc', 'message': ""Support Cinder scheduler hints\n\nAdd a 'scheduler_hints' option for OS::Cinder::Volume objects, as is\nit already done for OS::Nova::Server.\n\nImplements: blueprint cinder-scheduler-hints\nChange-Id: I090359c212df1d17b10e374d2e80e22344017aee\n""}, {'number': 3, 'created': '2014-10-09 21:02:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5923cb5050c1ac98831e8a5d3a05aa9ae731793c', 'message': ""Support Cinder scheduler hints\n\nAdd a 'scheduler_hints' option for OS::Cinder::Volume objects, as is\nit already done for OS::Nova::Server.\n\nImplements: blueprint cinder-scheduler-hints\nChange-Id: I090359c212df1d17b10e374d2e80e22344017aee\n""}, {'number': 4, 'created': '2014-10-13 15:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7649f5b526e6c50ac2ea1b89479276e8b7b52727', 'message': ""Support Cinder scheduler hints\n\nAdd a 'scheduler_hints' option for OS::Cinder::Volume objects, as is\nit already done for OS::Nova::Server.\n\nImplements: blueprint cinder-scheduler-hints\nChange-Id: I090359c212df1d17b10e374d2e80e22344017aee\n""}, {'number': 5, 'created': '2014-10-16 14:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3fb55d3463177d7ff47c9c364558720a6bdcf5ec', 'message': ""Support Cinder scheduler hints\n\nAdd a 'scheduler_hints' option for OS::Cinder::Volume objects, as is\nit already done for OS::Nova::Server.\n\nImplements: blueprint cinder-scheduler-hints\nChange-Id: I090359c212df1d17b10e374d2e80e22344017aee\n""}, {'number': 6, 'created': '2014-10-16 19:02:04.000000000', 'files': ['heat/engine/resources/volume.py', 'heat/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/94f80c092d21111fb190480849e16c6151d71af2', 'message': ""Support Cinder scheduler hints\n\nAdd a 'scheduler_hints' option for OS::Cinder::Volume objects, as is\nit already done for OS::Nova::Server.\n\nImplements: blueprint cinder-scheduler-hints\nChange-Id: I090359c212df1d17b10e374d2e80e22344017aee\n""}]",9,126298,94f80c092d21111fb190480849e16c6151d71af2,51,11,6,12561,,,0,"Support Cinder scheduler hints

Add a 'scheduler_hints' option for OS::Cinder::Volume objects, as is
it already done for OS::Nova::Server.

Implements: blueprint cinder-scheduler-hints
Change-Id: I090359c212df1d17b10e374d2e80e22344017aee
",git fetch https://review.opendev.org/openstack/heat refs/changes/98/126298/6 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/volume.py', 'heat/tests/test_volume.py']",2,0572801b378a802a0fea7e1c11d9c26df5f21452,bp/cinder-scheduler-hints," volume3: type: OS::Cinder::Volume properties: availability_zone: nova size: 1 name: test_name scheduler_hints: {""hint1"": ""good_advice""} def test_cinder_create_with_scheduler_hints(self): fv = FakeVolume('creating', 'available') stack_name = 'test_volume_scheduler_hints_stack' cinder.CinderClientPlugin._create().AndReturn( self.cinder_fc) self.cinder_fc.volumes.create( size=1, name='test_name', description=None, availability_zone='nova', scheduler_hints={'hint1': 'good_advice'}).AndReturn(fv) self.m.ReplayAll() stack = utils.parse_stack(self.t, stack_name=stack_name) self.create_volume(self.t, stack, 'volume3') self.assertEqual('available', fv.status) self.m.VerifyAll() ",,42,3
openstack%2Fsecurity-doc~master~I5c08f4f1129fb863ffea59a6b7033b488a1b9310,openstack/security-doc,master,I5c08f4f1129fb863ffea59a6b7033b488a1b9310,Imported Translations from Transifex,MERGED,2014-10-17 06:02:29.000000000,2014-10-17 06:25:00.000000000,2014-10-17 06:25:00.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-17 06:02:29.000000000', 'files': ['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/5f56a060178dc961f448b6e79437f29aa7c38252', 'message': 'Imported Translations from Transifex\n\nChange-Id: I5c08f4f1129fb863ffea59a6b7033b488a1b9310\n'}]",0,129135,5f56a060178dc961f448b6e79437f29aa7c38252,6,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I5c08f4f1129fb863ffea59a6b7033b488a1b9310
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/35/129135/1 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po']",2,5f56a060178dc961f448b6e79437f29aa7c38252,transifex/translations,"""POT-Creation-Date: 2014-10-16 17:40+0000\n"" ""PO-Revision-Date: 2014-10-16 17:41+0000\n"""" signed certificate, such as Verisign, for your cloud. A recommended work "" ""around is to use an SSL-terminaton proxy such as stud, HAproxy or NGINX."" msgstr """" #: ./security-guide/ch_object-storage.xml275(para) msgid """" ""Although not extensively tested, another work around is to use an "" ""alternative webserver instead of the built-in web server, which supports "" ""sending both the public server certificate as well as the CA signing "" ""authorities intermediate certificate(s). This allows for end-point clients "" ""that have the CA root certificate in their trust store to be able to "" ""successfully validate your cloud environment's SSL certificate and chain. An"" "" example of how to do this with mod_wsgi and Apache is given below. Also "" ""consult the <link ""msgstr """" #: ./security-guide/ch_object-storage.xml288(para)#: ./security-guide/ch_object-storage.xml293(para)#: ./security-guide/ch_object-storage.xml297(para)#: ./security-guide/ch_object-storage.xml300(para)#: ./security-guide/ch_object-storage.xml306(title)#: ./security-guide/ch_object-storage.xml307(para)#: ./security-guide/ch_object-storage.xml327(para)#: ./security-guide/ch_object-storage.xml332(title)#: ./security-guide/ch_object-storage.xml333(para)#: ./security-guide/ch_object-storage.xml338(para)#: ./security-guide/ch_object-storage.xml346(para)#: ./security-guide/ch_object-storage.xml355(title)#: ./security-guide/ch_object-storage.xml356(para)#: ./security-guide/ch_object-storage.xml364(para)#: ./security-guide/ch_object-storage.xml368(title)#: ./security-guide/ch_object-storage.xml369(para)#: ./security-guide/ch_object-storage.xml377(title)#: ./security-guide/ch_object-storage.xml378(para)#: ./security-guide/ch_object-storage.xml387(title)#: ./security-guide/ch_object-storage.xml388(para)#: ./security-guide/ch_object-storage.xml395(para)","""POT-Creation-Date: 2014-10-03 18:54+0000\n"" ""PO-Revision-Date: 2014-10-04 04:44+0000\n"""" signed certificate, such as Verisign, for your cloud. The current work "" ""around is to not use the built-in web server but an alternative web server "" ""instead that supports sending both the public server certificate as well as "" ""the CA signing authorities intermediate certificate(s). This allows for end-"" ""point clients that have the CA root certificate in their trust store to be "" ""able to successfully validate your cloud environment's SSL certificate and "" ""chain. An example of how to do this with mod_wsgi and Apache is given below."" "" Also consult the <link ""msgstr ""OpenStack Object Storage に組み込みまたは同梱されているウェブサーバーは SSL をサポートします。しかし、SSL 証明書チェイン全体の送信をサポートしません。これにより、お使いのクラウド用に Verisign のような第三者機関により信頼されて署名された証明書を使用するときに問題を引き起こします。現在の回避策は組み込みのウェブサーバーを使用せず、公開サーバー証明書と CA 中間認証局の証明書の両方を送信することをサポートする別のウェブサーバーを代わりに使用することです。これにより、エンドポイントのクライアントがお使いのクラウド環境の SSL 証明書とチェインを正常に検証できるようになるために、それらの信頼ストアにある CA ルート証明書を持てるようになります。mod_wsgi と Apache を用いてこのようにする方法の例が以下にあります。また、<link href=\""http://docs.openstack.org/developer/swift/apache_deployment_guide.html\"">Apache Deployment Guide</link> を参照してください。"" #: ./security-guide/ch_object-storage.xml286(para)#: ./security-guide/ch_object-storage.xml291(para)#: ./security-guide/ch_object-storage.xml295(para)#: ./security-guide/ch_object-storage.xml298(para)#: ./security-guide/ch_object-storage.xml304(title)#: ./security-guide/ch_object-storage.xml305(para)#: ./security-guide/ch_object-storage.xml325(para)#: ./security-guide/ch_object-storage.xml330(title)#: ./security-guide/ch_object-storage.xml331(para)#: ./security-guide/ch_object-storage.xml336(para)#: ./security-guide/ch_object-storage.xml344(para)#: ./security-guide/ch_object-storage.xml353(title)#: ./security-guide/ch_object-storage.xml354(para)#: ./security-guide/ch_object-storage.xml362(para)#: ./security-guide/ch_object-storage.xml366(title)#: ./security-guide/ch_object-storage.xml367(para)#: ./security-guide/ch_object-storage.xml375(title)#: ./security-guide/ch_object-storage.xml376(para)#: ./security-guide/ch_object-storage.xml385(title)#: ./security-guide/ch_object-storage.xml386(para)#: ./security-guide/ch_object-storage.xml393(para)",65,55
openstack%2Fcinder~master~I22e2d8d7d9c5af797fa0e5f3396c54891a46054d,openstack/cinder,master,I22e2d8d7d9c5af797fa0e5f3396c54891a46054d,Storwize Driver:Should report capability:replication=False,ABANDONED,2014-09-22 07:12:34.000000000,2014-10-17 06:16:13.000000000,,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 1773}, {'_account_id': 4355}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10503}, {'_account_id': 11047}, {'_account_id': 11079}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12780}]","[{'number': 1, 'created': '2014-09-22 07:12:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/56f2815b6b129921e4220dcd7d687a2080c253f0', 'message': 'Storwize Driver:Should report capability:replication=False\n\nIf set volume-type with capability:replication=False, create volume\nwill fail because driver did not report this capability\n\nCloses-bug: #1370796\n\nChange-Id: I22e2d8d7d9c5af797fa0e5f3396c54891a46054d\n'}, {'number': 2, 'created': '2014-09-22 09:26:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/affe43c1b21b69f4d11096295ae17366ffca408d', 'message': 'Storwize Driver:Should report capability:replication=False\n\nIf set volume-type with capability:replication=False, create volume\nwill fail because driver did not report this capability\n\nCloses-bug: #1370796\n\nChange-Id: I22e2d8d7d9c5af797fa0e5f3396c54891a46054d\n'}, {'number': 3, 'created': '2014-09-24 03:22:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9590b46c30172cb10b4c3a6aaf070af656d8f4a4', 'message': 'Storwize Driver:Should report capability:replication=False\n\nIf set volume-type with capability:replication=False, scheduler\nwill fail to find the backend if driver not report it.\nIt will cause volume creation fail no matter replication enabled\nor not.\nTo fix this,driver should report replication=False even replication\nis enabled\n\nCloses-bug: #1370796\n\nChange-Id: I22e2d8d7d9c5af797fa0e5f3396c54891a46054d\n'}, {'number': 4, 'created': '2014-09-24 04:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3038f30cc5cd1cd566ad7789aab2c046e2c492fb', 'message': 'Storwize Driver:Should report capability:replication=False\n\nIf set volume-type with capability:replication=False, scheduler\nwill fail to find the backend when driver not report it.\nIt will cause volume creation fail no matter replication enabled\nor not.\nTo fix this,driver should report replication=False even replication\nis enabled.\n\nCloses-bug: #1370796\n\nChange-Id: I22e2d8d7d9c5af797fa0e5f3396c54891a46054d\n'}, {'number': 5, 'created': '2014-09-29 06:51:07.000000000', 'files': ['cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/volume/drivers/ibm/storwize_svc/replication.py', 'cinder/tests/test_storwize_svc.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/67c997b090deb72278db8637e6248349efb0737a', 'message': 'Storwize Driver:Should report capability:replication=False\n\nIf create a volume-type with capability:replication=False, and create\nvolume with this type, the schedule will fail to find the backend\nbecause storwize driver not report it.\n\nIf driver backend support replication, it will report\n""replication=True"".To support user to create no-replica volume with\nvolume-type capability:replication=False,driver should also report\nthe capabilities also ""replication=False""at the same time.\n\nSo when replication is supported by driver,the capibility should be\n""replication=[\'True\',\'False\']"".\nIf driver not support replication, the capability should be\n""replication=False"".\n\nCloses-bug: #1370796\n\nChange-Id: I22e2d8d7d9c5af797fa0e5f3396c54891a46054d\n'}]",8,123060,67c997b090deb72278db8637e6248349efb0737a,38,14,5,11079,,,0,"Storwize Driver:Should report capability:replication=False

If create a volume-type with capability:replication=False, and create
volume with this type, the schedule will fail to find the backend
because storwize driver not report it.

If driver backend support replication, it will report
""replication=True"".To support user to create no-replica volume with
volume-type capability:replication=False,driver should also report
the capabilities also ""replication=False""at the same time.

So when replication is supported by driver,the capibility should be
""replication=['True','False']"".
If driver not support replication, the capability should be
""replication=False"".

Closes-bug: #1370796

Change-Id: I22e2d8d7d9c5af797fa0e5f3396c54891a46054d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/60/123060/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/volume/drivers/ibm/storwize_svc/replication.py', 'cinder/tests/test_storwize_svc.py']",3,56f2815b6b129921e4220dcd7d687a2080c253f0,bug/1370796," # Replication is not enabled, capability:replication should be false stats = self.driver.get_volume_stats() self.assertFalse(stats['replication']) self.driver.do_setup(self.ctxt) # Replication is enabled, driver should report both True and False stats = self.driver.get_volume_stats() self.assertEqual([True, False], stats['replication'])", self.driver.do_setup(self.ctxt) ,13,3
openstack%2Fmurano~master~I7fff86ace8b1ff727eea8ff2824ba9e94cd96e72,openstack/murano,master,I7fff86ace8b1ff727eea8ff2824ba9e94cd96e72,Fix defects in API specification,MERGED,2014-10-14 09:27:36.000000000,2014-10-17 06:11:12.000000000,2014-10-17 06:11:12.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-10-14 09:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/0aabbb9894b20e57abf01f4baa63dd84e5c0ef5c', 'message': 'Update API specification\n\nChange-Id: I7fff86ace8b1ff727eea8ff2824ba9e94cd96e72\n'}, {'number': 2, 'created': '2014-10-14 13:38:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/21c8bfd2f4001eca22e18183bcedc2ee55ba0e39', 'message': 'Fix defects in API specification\n\nChange-Id: I7fff86ace8b1ff727eea8ff2824ba9e94cd96e72\n'}, {'number': 3, 'created': '2014-10-15 16:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/3a55c75a5ec6a448caa5a929b14e0b417cd0f509', 'message': 'Fix defects in API specification\n\nChange-Id: I7fff86ace8b1ff727eea8ff2824ba9e94cd96e72\n'}, {'number': 4, 'created': '2014-10-17 05:27:10.000000000', 'files': ['doc/source/specification/murano-api.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/75d976a1cd2af100c5c4fd391cedeb5b260dc95b', 'message': 'Fix defects in API specification\n\nChange-Id: I7fff86ace8b1ff727eea8ff2824ba9e94cd96e72\n'}]",0,128220,75d976a1cd2af100c5c4fd391cedeb5b260dc95b,24,4,4,7549,,,0,"Fix defects in API specification

Change-Id: I7fff86ace8b1ff727eea8ff2824ba9e94cd96e72
",git fetch https://review.opendev.org/openstack/murano refs/changes/20/128220/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/specification/murano-api.rst'],1,0aabbb9894b20e57abf01f4baa63dd84e5c0ef5c,update_docs,+----------+----------------------------------+-----------------------------------+----------------------------------+ | Method | URI | Header | Description | +==========+==================================+===================================+==================================+ | GET | /environments/{id} | X-Configuration-Session (optional)| Response detailed information | | | | | about Environment including | | | | | child entities | +----------+----------------------------------+-----------------------------------+----------------------------------+| POST | /environments/<env_id>/services | X-Configuration-Session |,+----------+----------------------------------+----------------------------------+ | Method | URI | Description | +==========+==================================+==================================+ | GET | /environments/{id} | Response detailed information | | | | about Environment including | | | | child entities | +----------+----------------------------------+----------------------------------+| POST | /environments/<env_id>/services | X-Configuration-Session (optional) |,8,8
openstack%2Ftripleo-image-elements~master~Iabfdd583ee0515a01fb50d9bb2ff42588e313593,openstack/tripleo-image-elements,master,Iabfdd583ee0515a01fb50d9bb2ff42588e313593,Update Horizon to use NEUTRON instead of QUANTUM,MERGED,2014-10-10 06:01:09.000000000,2014-10-17 06:02:53.000000000,2014-10-17 06:02:51.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4330}, {'_account_id': 9369}, {'_account_id': 12385}]","[{'number': 1, 'created': '2014-10-10 06:01:09.000000000', 'files': ['elements/horizon/os-apply-config/etc/horizon/local_settings.py'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/95fe54570acd023e9d5e1e66f02e230dfdf758a9', 'message': 'Update Horizon to use NEUTRON instead of QUANTUM\n\nChange-Id: Iabfdd583ee0515a01fb50d9bb2ff42588e313593\nCloses-Bug: #1365610\n'}]",0,127421,95fe54570acd023e9d5e1e66f02e230dfdf758a9,10,5,1,1941,,,0,"Update Horizon to use NEUTRON instead of QUANTUM

Change-Id: Iabfdd583ee0515a01fb50d9bb2ff42588e313593
Closes-Bug: #1365610
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/21/127421/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/horizon/os-apply-config/etc/horizon/local_settings.py'],1,95fe54570acd023e9d5e1e66f02e230dfdf758a9,bug/1365610, OPENSTACK_NEUTRON_NETWORK = {,OPENSTACK_QUANTUM_NETWORK = {,2,1
openstack%2Fswift~master~I5700e1f2de197e3b20d268e7b0d6639861916f55,openstack/swift,master,I5700e1f2de197e3b20d268e7b0d6639861916f55,Separate Backend from Broker,ABANDONED,2014-04-08 02:41:44.000000000,2014-10-17 05:12:12.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 6198}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 8871}, {'_account_id': 9625}, {'_account_id': 10378}]","[{'number': 1, 'created': '2014-04-08 02:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bc214d4f27da676dfc96e51f7a24661bd43109dd', 'message': ""Separate Backend from Broker\n\nWhen we started Pluggable Backends, we meant to keep the common API\n(class), which supported all kinds of usage, like today. However,\nit soon became apparent that needs of auditors, replicators, and\nservers are different. The current AccoubtBroker and ContainerBroker\nare able to function only because they presume the specific\nimplementation, in which a database filename exists. If filename\nis removed from the common API, the auditor has to do insane\ncontortions to deduce the database filenames instead of walking\nthe filesystem trees. Soon we were writing code to verify the\nconsistency between auditor's guesses and reality. It was nasty\nand stupid.\n\nSo, instead, we split up the Backend (for the use by servers) and\nthe Broker (for implementation-specific auditors and replicators).\nThe key change is how AccountBackend and ContainerBackend do not\ntake a filename when created, but rather what HTTP requests deliver.\n\nChange-Id: I5700e1f2de197e3b20d268e7b0d6639861916f55\n""}, {'number': 2, 'created': '2014-04-11 18:23:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/439b407080736c9e1ee496a4d0d0eff6b478bfc6', 'message': ""Separate Backend from Broker\n\nWhen we started Pluggable Backends, we meant to keep the common API\n(class), which supported all kinds of usage, like today. However,\nit soon became apparent that needs of auditors, replicators, and\nservers are different. The current AccoubtBroker and ContainerBroker\nare able to function only because they presume the specific\nimplementation, in which a database filename exists. If filename\nis removed from the common API, the auditor has to do insane\ncontortions to deduce the database filenames instead of walking\nthe filesystem trees. Soon we were writing code to verify the\nconsistency between auditor's guesses and reality. It was nasty\nand stupid.\n\nSo, instead, we split up the Backend (for the use by servers) and\nthe Broker (for implementation-specific auditors and replicators).\nThe key change is how AccountBackend and ContainerBackend do not\ntake a filename when created, but rather what HTTP requests deliver.\n\nChange-Id: I5700e1f2de197e3b20d268e7b0d6639861916f55\n""}, {'number': 3, 'created': '2014-05-23 04:00:33.000000000', 'files': ['swift/account/backend.py', 'swift/container/server.py', 'swift/account/server.py', 'swift/container/backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/59e97220c60822e087ec04036fe2f7d312f8c8af', 'message': ""Separate Backend from Broker\n\nWhen we started Pluggable Backends, we meant to keep the common API\n(class), which supported all kinds of usage, like today. However,\nit soon became apparent that needs of auditors, replicators, and\nservers are different. The current AccoubtBroker and ContainerBroker\nare able to function only because they presume the specific\nimplementation, in which a database filename exists. If filename\nis removed from the common API, the auditor has to do insane\ncontortions to deduce the database filenames instead of walking\nthe filesystem trees. Soon we were writing code to verify the\nconsistency between auditor's guesses and reality. It was nasty\nand stupid.\n\nSo, instead, we split up the Backend (for the use by servers) and\nthe Broker (for implementation-specific auditors and replicators).\nThe key change is how AccountBackend and ContainerBackend do not\ntake a filename when created, but rather what HTTP requests deliver.\n\nThis version of the patch does not use inheritance. Thus, the\nimplementors have one place to reference for the official docstrings.\n\nChange-Id: I5700e1f2de197e3b20d268e7b0d6639861916f55\n""}]",10,85909,59e97220c60822e087ec04036fe2f7d312f8c8af,39,10,3,597,,,0,"Separate Backend from Broker

When we started Pluggable Backends, we meant to keep the common API
(class), which supported all kinds of usage, like today. However,
it soon became apparent that needs of auditors, replicators, and
servers are different. The current AccoubtBroker and ContainerBroker
are able to function only because they presume the specific
implementation, in which a database filename exists. If filename
is removed from the common API, the auditor has to do insane
contortions to deduce the database filenames instead of walking
the filesystem trees. Soon we were writing code to verify the
consistency between auditor's guesses and reality. It was nasty
and stupid.

So, instead, we split up the Backend (for the use by servers) and
the Broker (for implementation-specific auditors and replicators).
The key change is how AccountBackend and ContainerBackend do not
take a filename when created, but rather what HTTP requests deliver.

This version of the patch does not use inheritance. Thus, the
implementors have one place to reference for the official docstrings.

Change-Id: I5700e1f2de197e3b20d268e7b0d6639861916f55
",git fetch https://review.opendev.org/openstack/swift refs/changes/09/85909/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/account/backend.py', 'swift/container/server.py', 'swift/account/server.py', 'test/unit/container/test_server.py', 'swift/container/backend.py']",5,bc214d4f27da676dfc96e51f7a24661bd43109dd,be/class,"from swift.common.utils import hash_path, normalize_timestamp, \ lock_parent_directory, storage_directory """"""Encapsulates working with a container database for in-tree users."""""" class ContainerBackend(ContainerBroker): """""" Encapsulates working with a container implemented by a database. :param path: Path to devices on the node :param device: Device name :param partition: Partition number as a string :param account: Account name, decoded from URL :param container: Container name :param logger: Keyword argument; means the logger to use """""" def __init__(self, path, device, partition, account, container, **kwargs): hsh = hash_path(account, container) top_path = os.path.join(path, device, DATADIR) dir_path = storage_directory(top_path, partition, hsh) db_path = os.path.join(dir_path, hsh + '.db') kwargs.setdefault('account', account) kwargs.setdefault('container', container) super(ContainerBackend, self).__init__(db_path, **kwargs)","from swift.common.utils import normalize_timestamp, lock_parent_directory """"""Encapsulates working with a container database.""""""",70,28
openstack%2Fcinder~stable%2Fjuno~I9312271d24982e1d251472aabaee92a62eb38970,openstack/cinder,stable/juno,I9312271d24982e1d251472aabaee92a62eb38970,Opening stable/juno,MERGED,2014-10-16 14:59:11.000000000,2014-10-17 05:02:35.000000000,2014-10-17 05:02:34.000000000,"[{'_account_id': 3}, {'_account_id': 7198}]","[{'number': 1, 'created': '2014-10-16 14:59:11.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8692741fae62c61a943ce10479d565941e3fe834', 'message': 'Opening stable/juno\n\nBump version to next stable release on juno branch, and set\ndefaultbranch in .gitreview for convenience.\n\nChange-Id: I9312271d24982e1d251472aabaee92a62eb38970\n'}]",0,128948,8692741fae62c61a943ce10479d565941e3fe834,10,2,1,308,,,0,"Opening stable/juno

Bump version to next stable release on juno branch, and set
defaultbranch in .gitreview for convenience.

Change-Id: I9312271d24982e1d251472aabaee92a62eb38970
",git fetch https://review.opendev.org/openstack/cinder refs/changes/48/128948/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'setup.cfg']",2,8692741fae62c61a943ce10479d565941e3fe834,stable-juno,version = 2014.2.1,version = 2014.2,2,1
openstack%2Fdevstack~master~Iaf45ec993d2b212cfc5bec29396dedf8a9da96b9,openstack/devstack,master,Iaf45ec993d2b212cfc5bec29396dedf8a9da96b9,Devstack changes to install congress Changes to include congress as a service in Keystone Corrected typo,ABANDONED,2014-08-06 05:28:23.000000000,2014-10-17 04:59:12.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-06 05:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c129625c87a163af64309e2c71f616eb3785fe0d', 'message': 'Devstack changes to include congress as a service.\n\nCloses bug: 1343545\n\nChange-Id: Iaf45ec993d2b212cfc5bec29396dedf8a9da96b9\n'}, {'number': 2, 'created': '2014-08-06 05:47:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/066e4df00922e61f21e12efd036ceb599baed9ab', 'message': 'Devstack changes to install congress\nChanges to include congress as a service in Keystone\n\nCloses bug: 1343545\n\nChange-Id: Iaf45ec993d2b212cfc5bec29396dedf8a9da96b9\n'}, {'number': 3, 'created': '2014-08-06 13:02:46.000000000', 'files': ['functions-common', 'lib/congress', 'unstack.sh', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/c9996745e7a2a71111b20d86f939b0417eb12a54', 'message': 'Devstack changes to install congress\nChanges to include congress as a service in Keystone\nCorrected typo\n\nCloses bug: 1343545\n\nChange-Id: Iaf45ec993d2b212cfc5bec29396dedf8a9da96b9\n'}]",3,112195,c9996745e7a2a71111b20d86f939b0417eb12a54,13,3,3,12293,,,0,"Devstack changes to install congress
Changes to include congress as a service in Keystone
Corrected typo

Closes bug: 1343545

Change-Id: Iaf45ec993d2b212cfc5bec29396dedf8a9da96b9
",git fetch https://review.opendev.org/openstack/devstack refs/changes/95/112195/1 && git format-patch -1 --stdout FETCH_HEAD,"['functions-common', 'lib/congress', 'unstack.sh', 'stack.sh']",4,c129625c87a163af64309e2c71f616eb3785fe0d,bug/1343545," log_error $LINENO ""missing $TOP_DIR/stackrc - did you grab more than just stack.sh?"" log_error $LINENO ""missing devstack/files"" log_error $LINENO ""missing devstack/lib"" echo ""FATAL: Use the actual swift service names to enable tham as required:""# The Debian Wheezy official repositories do not contain all required packages, # add gplhost repository. if [[ ""$os_VENDOR"" =~ (Debian) ]]; then echo 'deb http://archive.gplhost.com/debian grizzly main' | sudo tee /etc/apt/sources.list.d/gplhost_wheezy-backports.list echo 'deb http://archive.gplhost.com/debian grizzly-backports main' | sudo tee -a /etc/apt/sources.list.d/gplhost_wheezy-backports.list apt_get update apt_get install --force-yes gplhost-archive-keyring fi # Allow the use of an alternate protocol (such as https) for service endpoints SERVICE_PROTOCOL=${SERVICE_PROTOCOL:-http} source $TOP_DIR/lib/congress $TOP_DIR/tools/install_pip.sh# Do the ugly hacks for borken packages and distros #configure_ceilometerclientif is_service_enabled congress; then install_congressclient install_congress echo_summary ""Configuring Congress"" configure_congress #configure_congressclient fi if is_service_enabled congress; then create_congress_accounts fiif is_service_enabled ceilometer; then echo_summary ""Starting Congress"" init_congress start_congress fi # TODO(dtroyer): Remove EXTRA_OPTS after stable/icehouse branch is cut # Specific warning for deprecated configs if [[ -n ""$EXTRA_OPTS"" ]]; then echo """" echo_summary ""WARNING: EXTRA_OPTS is used"" echo ""You are using EXTRA_OPTS to pass configuration into nova.conf."" echo ""Please convert that configuration in localrc to a nova.conf section in local.conf:"" echo ""EXTRA_OPTS will be removed early in the Juno development cycle"" echo "" [[post-config|\$NOVA_CONF]] [DEFAULT] "" for I in ""${EXTRA_OPTS[@]}""; do # Replace the first '=' with ' ' for iniset syntax echo ${I} done fi # TODO(dtroyer): Remove EXTRA_BAREMETAL_OPTS after stable/icehouse branch is cut if [[ -n ""$EXTRA_BAREMETAL_OPTS"" ]]; then echo """" echo_summary ""WARNING: EXTRA_BAREMETAL_OPTS is used"" echo ""You are using EXTRA_BAREMETAL_OPTS to pass configuration into nova.conf."" echo ""Please convert that configuration in localrc to a nova.conf section in local.conf:"" echo ""EXTRA_BAREMETAL_OPTS will be removed early in the Juno development cycle"" echo "" [[post-config|\$NOVA_CONF]] [baremetal] "" for I in ""${EXTRA_BAREMETAL_OPTS[@]}""; do # Replace the first '=' with ' ' for iniset syntax echo ${I} done fi # TODO(dtroyer): Remove Q_DHCP_EXTRA_DEFAULT_OPTS after stable/icehouse branch is cut if [[ -n ""$Q_DHCP_EXTRA_DEFAULT_OPTS"" ]]; then echo_summary ""WARNING: Q_DHCP_EXTRA_DEFAULT_OPTS is used"" echo ""You are using Q_DHCP_EXTRA_DEFAULT_OPTS to pass configuration into $Q_DHCP_CONF_FILE."" echo ""Please convert that configuration in localrc to a $Q_DHCP_CONF_FILE section in local.conf:"" echo ""Q_DHCP_EXTRA_DEFAULT_OPTS will be removed early in the Juno development cycle""[[post-config|/\$Q_DHCP_CONF_FILE]] [DEFAULT] for I in ""${Q_DHCP_EXTRA_DEFAULT_OPTS[@]}""; do # Replace the first '=' with ' ' for iniset syntax echo ${I} done fi # TODO(dtroyer): Remove Q_SRV_EXTRA_DEFAULT_OPTS after stable/icehouse branch is cut if [[ -n ""$Q_SRV_EXTRA_DEFAULT_OPTS"" ]]; then echo """" echo_summary ""WARNING: Q_SRV_EXTRA_DEFAULT_OPTS is used"" echo ""You are using Q_SRV_EXTRA_DEFAULT_OPTS to pass configuration into $NEUTRON_CONF."" echo ""Please convert that configuration in localrc to a $NEUTRON_CONF section in local.conf:"" echo ""Q_SRV_EXTRA_DEFAULT_OPTS will be removed early in the Juno development cycle"" echo "" [[post-config|\$NEUTRON_CONF]] [DEFAULT] "" for I in ""${Q_SRV_EXTRA_DEFAULT_OPTS[@]}""; do # Replace the first '=' with ' ' for iniset syntax echo ${I} done"," die $LINENO ""missing $TOP_DIR/stackrc - did you grab more than just stack.sh?"" die $LINENO ""missing devstack/files"" die $LINENO ""missing devstack/lib"" echo ""FATAL: Use the actual swift service names to enable them as required:""if [[ is_fedora && $DISTRO =~ (rhel) ]]; then # poor old python2.6 doesn't have argparse by default, which # outfilter.py uses is_package_installed python-argparse || install_package python-argparse fi PYPI_ALTERNATIVE_URL=$PYPI_ALTERNATIVE_URL $TOP_DIR/tools/install_pip.sh# Do the ugly hacks for broken packages and distros # Extras Pre-install # ------------------ # Phase: pre-install if [[ -d $TOP_DIR/extras.d ]]; then for i in $TOP_DIR/extras.d/*.sh; do [[ -r $i ]] && source $i stack pre-install done fi create_volume_types# TODO(dtroyer): Remove CINDER_MULTI_LVM_BACKEND after stable/juno branch is cut if [[ ""$CINDER_MULTI_LVM_BACKEND"" = ""True"" ]]; then echo_summary ""WARNING: CINDER_MULTI_LVM_BACKEND is used"" echo ""You are using CINDER_MULTI_LVM_BACKEND to configure Cinder's multiple LVM backends"" echo ""Please convert that configuration in local.conf to use CINDER_ENABLED_BACKENDS."" echo ""CINDER_ENABLED_BACKENDS will be removed early in the 'K' development cycle""[[local|localrc]] CINDER_ENABLED_BACKENDS=lvm:lvmdriver-1,lvm:lvmdriver-2",380,33
openstack%2Fcongress~master~Ibca929773994c24110e026d57ad5c3e791d32e88,openstack/congress,master,Ibca929773994c24110e026d57ad5c3e791d32e88,Padding of datasource fields for minimal policy writing,ABANDONED,2014-10-06 06:14:55.000000000,2014-10-17 04:58:27.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-10-06 06:14:55.000000000', 'files': ['congress/policy/pad.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/2cd0afc313e8336788b2b4ae22a20d5effd50fc7', 'message': ""Padding of datasource fields for minimal policy writing\n\nPadding logic to add fields to the minimalistic policy atoms to make policy\nmaker's work easy. With this change, the policy writer can use only those\nfields he is interested in.\n\nthe format of the policy supported by this function is as below\n\nerror(name, id) :- nova:servers(id, name)\n\nThe function pads the additional arguments in the form nova:servers(id, name,\na1, a2, a3, a4, a5, a6)\n\nChange-Id: Ibca929773994c24110e026d57ad5c3e791d32e88\n""}]",0,126219,2cd0afc313e8336788b2b4ae22a20d5effd50fc7,10,4,1,12293,,,0,"Padding of datasource fields for minimal policy writing

Padding logic to add fields to the minimalistic policy atoms to make policy
maker's work easy. With this change, the policy writer can use only those
fields he is interested in.

the format of the policy supported by this function is as below

error(name, id) :- nova:servers(id, name)

The function pads the additional arguments in the form nova:servers(id, name,
a1, a2, a3, a4, a5, a6)

Change-Id: Ibca929773994c24110e026d57ad5c3e791d32e88
",git fetch https://review.opendev.org/openstack/congress refs/changes/19/126219/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/policy/pad.py'],1,2cd0afc313e8336788b2b4ae22a20d5effd50fc7,policy/formula_padding,"# Copyright (c) 2013 VMware, Inc. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # from congress.dse import deepsix from congress.policy import compile from congress.policy import runtime from congress.openstack.common import log as logging from congress.api import error_codes from congress.api import webservice from congress.datasources.datasource_driver import DataSourceDriver def pad_formula(self, formula): """"""Reads the input formula and pads missing fields from the datasource tables to the input formula. This is used to enable user to write simpler policies without needing to know all fields and positions of fields in the datasource tables."""""" pad_formula = formula LOG.debug(""Inside pad_formula with Formula %s"" % formula) #Derive datasource table dictionary from the input policy formula_body = compile.parse1(formula).body obj_dict = {} ref_args = None LOG.debug(""FORMULA BODY %s"" % formula_body) table_list = [] builtin_list = [] for label in formula_body: #Check if tuple has string object has_object = label.has_object() s_label = str(label) #Check if negation is used is_negation = label.negated if is_negation: is_negation = True s_label = s_label.strip(""not"").strip() if s_label.find("":"") != -1: _module = s_label.split(':')[0].strip() _table = s_label.split(':')[1].split('(')[0].strip() _args = s_label.split(':')[1].strip(_table).strip() if len(table_list): if _module not in [d['module'] for d in table_list] and _table not in [d['table'] for d in table_list]: table_list.append(dict(module=_module, table=_table, arguments=_args, hasobject=has_object)) ref_args = [d for d in table_list if (d['module'] == _module)][0]['arguments'] else: #Generate an Object Dictionary to include # ObjectConstants available in the formula if has_object and ref_args is not None: args_list = _args.strip('(').strip(')').split(',') cnt = 0 ref_list = ref_args.strip('(').strip(')').split(',') #FIXME: (madhumohan): Need to verify if this logic # works for non-string values in the arguments for ref in ref_list: if (ref.strip() != args_list[cnt]): obj_dict[ref.strip()] = eval(args_list[cnt]) cnt = cnt + 1 table_list.append(dict(module=_module, table=_table, arguments=_args, negated=is_negation, hasobject=has_object)) else: ref_args = [d for d in table_list if (d['module'] == _module)][0]['arguments'] else: table_list.append(dict(module=_module, table=_table, arguments=_args, negated=is_negation, hasobject=has_object)) ref_args = [d for d in table_list if (d['module'] == _module)][0]['arguments'] else: builtin_list.append(str(label)) LOG.debug(""Updated Table list %s"" % table_list) #Get Datasource modules available module_dict = self._get_module_dict() #Obtain Padded version of the compiled formula. padded_literals = self._get_padded_literals(table_list, module_dict, obj_dict) #Reconstruct the Policy rule for applying to the policy engine. padded_body = """" LOG.debug (""PADDED literals %s"" % padded_literals) for lits in padded_literals: if (lits != padded_literals[-1]): padded_body = padded_body + str(lits) + "", "" else: padded_body = padded_body + str(lits) if len(builtin_list) != 0: for val in builtin_list: padded_body = padded_body + "", "" + val if padded_body: pad_formula = str(compile.parse1(formula).head) + ' :- ' + padded_body LOG.debug(""PADDED Formula Being Sent back %s "" % [pad_formula]) return pad_formula def _get_module_dict(self): LOG.debug(""DATASOURCES %s"" % DataSourceDriver.__subclasses__()) #Get the expected dictionary from the datasources list ds_list = [x.__name__ for x in DataSourceDriver.__subclasses__()] ds_list = list(set(ds_list)) module_dict = {} for ds in ds_list: ds_module = ds.lower().split('driver')[0].strip() module_dict[ds_module] = ds LOG.debug(""Module Dictionary from DATASOURCEDRIVERS: %s"" % module_dict) return module_dict def _get_padded_literals(self, table_list, module_dict, obj_dict): #Argument padding process padded_tuple = None pad_list = [] padded_literals_list = [] LOG.debug(""INPUT TABLE_LIST:: %s, OBJ_DICT:: %s, MODULE_DICT:: %s"" % (table_list, obj_dict, module_dict)) for tab in table_list: if tab['module'] in module_dict.keys(): module_class = eval(module_dict[tab['module']]) mod_tuple = module_class.get_schema(tab['table']) LOG.debug(""MODULE Original Tuple value %s"" % str(mod_tuple)) in_args = tab['arguments'] in_tuple = tuple([x.strip() for x in in_args.strip('(').strip(')').split(',')]) LOG.debug(""ARGUMENTS in Formula %s"" % str(in_tuple)) #Handle padding if the tuple has string constants for val in mod_tuple: if val not in in_tuple: if val in obj_dict.keys(): pad_list.append(str('\""' + obj_dict[val] + '\""')) else: pad_list.append(""a""+str(mod_tuple.index(val))) else: pad_list.append(val) padded_tuple = tuple(pad_list) pad_list = [] padded_arguments = ""("" for item in padded_tuple: padded_arguments = padded_arguments + str(item) + "", "" padded_arguments = padded_arguments.rstrip(', ') + "")"" tab['arguments'] = padded_arguments #Convert strings to variables padded_var_tuple = None padded_var_list = [] for item in padded_tuple: padded_var_list.append(compile.Variable.create_from_python(item, force_var=True)) padded_var_tuple = tuple(padded_var_list) #Insert the padded argument list into the formula padded_literal = compile.Literal.create_from_table_tuple(tab['module']+':'+tab['table'], padded_var_tuple) padded_literal.negated = tab['negated'] padded_literals_list.append(padded_literal) LOG.debug(""Generated PADDED LITERAL List %s"" % padded_literals_list) return padded_literals_list ",,176,0
openstack%2Fmagnetodb~master~Id06dcaa8103b3337e69f8743b8adea550db24bd2,openstack/magnetodb,master,Id06dcaa8103b3337e69f8743b8adea550db24bd2,Improves tempest table creation and deletion waiting mechanism,MERGED,2014-10-15 16:54:06.000000000,2014-10-17 04:01:32.000000000,2014-10-17 04:01:31.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8491}, {'_account_id': 8601}, {'_account_id': 11006}]","[{'number': 1, 'created': '2014-10-15 16:54:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/ec2ff4c8679ecb5307622be6f7d80b3a3e323b56', 'message': 'Impoves tempest table creation and deletion waiting mechanism\n\nDue to new table states we can improve tempest table state waiting\nmechanism in cases of creation/deletion failure.\n\nImplements bp: tempest-table-waiting-improvement\nChange-Id: Id06dcaa8103b3337e69f8743b8adea550db24bd2\n'}, {'number': 2, 'created': '2014-10-16 10:03:41.000000000', 'files': ['tempest/api/keyvalue/rest_base/base.py'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/4d818bb2098006d37b4627529b9e5ff38a93ab49', 'message': 'Improves tempest table creation and deletion waiting mechanism\n\nDue to new table states we can improve tempest table state waiting\nmechanism in cases of creation/deletion failure.\n\nImplements bp: tempest-table-waiting-improvement\nChange-Id: Id06dcaa8103b3337e69f8743b8adea550db24bd2\n'}]",0,128706,4d818bb2098006d37b4627529b9e5ff38a93ab49,9,5,2,8863,,,0,"Improves tempest table creation and deletion waiting mechanism

Due to new table states we can improve tempest table state waiting
mechanism in cases of creation/deletion failure.

Implements bp: tempest-table-waiting-improvement
Change-Id: Id06dcaa8103b3337e69f8743b8adea550db24bd2
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/06/128706/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/keyvalue/rest_base/base.py'],1,ec2ff4c8679ecb5307622be6f7d80b3a3e323b56,bp/tempest-table-waiting-improvement,"from tempest import exceptionsTABLE_STATUS_ACTIVE = 'ACTIVE' TABLE_STATUS_CREATING = 'CREATING' TABLE_STATUS_DELETING = 'DELETING' TABLE_STATUS_CREATE_FAILED = 'CREATE_FAILED' TABLE_STATUS_DELETE_FAILED = 'DELETE_FAILED' def wait_for_table_active(self, table_name, timeout=120, interval=1, client = self.client if not alt else self.client_alt status = body[""table""][""table_status""] if status == TABLE_STATUS_CREATE_FAILED: self.fail('Table creation failure.') return body[""table""][""table_status""] == TABLE_STATUS_ACTIVE try: headers, body = client.describe_table(table_name) if ""table"" in body and ""table_status"" in body[""table""]: status = body[""table""][""table_status""] if status == TABLE_STATUS_DELETE_FAILED: self.fail('Table deletion failure.') except exceptions.NotFound: return True"," @classmethod def wait_for_table_active(cls, table_name, timeout=120, interval=1, client = cls.client if not alt else cls.client_alt return body[""table""][""table_status""] == ""ACTIVE"" names = [d['href'] for d in client.list_tables()[1]['tables']] return table_name not in names",22,6
openstack%2Fnova~master~Ifa69e4704ea3f60b4aced3504bf9c599e3868616,openstack/nova,master,Ifa69e4704ea3f60b4aced3504bf9c599e3868616,Fix instance_extra backref,MERGED,2014-10-01 19:59:08.000000000,2014-10-17 03:51:20.000000000,2014-10-17 03:51:17.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 5754}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-01 19:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e6480b1fe84ac73b8cae781e29358e4ea750f54', 'message': ""Fix instance_extra backref\n\nThis fixes cruft from the original NUMA patches that placed a backref on\nthe Instance model for numa_topology. This changes it to the generic\n'instance_extra'. Since this was not actually used, nothing breaks; the\nextra backref will be used in subsequent patches.\n\nChange-Id: Ifa69e4704ea3f60b4aced3504bf9c599e3868616\n""}, {'number': 2, 'created': '2014-10-06 17:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/936fca1c2fd6f90fbe7bd57206de9438c7eb8c7e', 'message': ""Fix instance_extra backref\n\nThis fixes cruft from the original NUMA patches that placed a backref on\nthe Instance model for numa_topology. This changes it to the generic\n'instance_extra'. Since this was not actually used, nothing breaks; the\nextra backref will be used in subsequent patches.\n\nChange-Id: Ifa69e4704ea3f60b4aced3504bf9c599e3868616\n""}, {'number': 3, 'created': '2014-10-07 14:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c7f07d445fff6a81711b551fac18b6732f45c06a', 'message': ""Fix instance_extra backref\n\nThis fixes cruft from the original NUMA patches that placed a backref on\nthe Instance model for numa_topology. This changes it to the generic\n'instance_extra'. Since this was not actually used, nothing breaks; the\nextra backref will be used in subsequent patches.\n\nChange-Id: Ifa69e4704ea3f60b4aced3504bf9c599e3868616\n""}, {'number': 4, 'created': '2014-10-08 14:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7b42b056ba589e8fe89c601353dc18e035569be', 'message': ""Fix instance_extra backref\n\nThis fixes cruft from the original NUMA patches that placed a backref on\nthe Instance model for numa_topology. This changes it to the generic\n'instance_extra'. Since this was not actually used, nothing breaks; the\nextra backref will be used in subsequent patches.\n\nChange-Id: Ifa69e4704ea3f60b4aced3504bf9c599e3868616\n""}, {'number': 5, 'created': '2014-10-08 18:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13c13862ac8b84dafbf79105f061747e5fecf553', 'message': ""Fix instance_extra backref\n\nThis fixes cruft from the original NUMA patches that placed a backref on\nthe Instance model for numa_topology. This changes it to the generic\n'instance_extra'. Since this was not actually used, nothing breaks; the\nextra backref will be used in subsequent patches.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ifa69e4704ea3f60b4aced3504bf9c599e3868616\n""}, {'number': 6, 'created': '2014-10-14 14:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a74b4960e0a82d4a8f42548c6dc95906886962f', 'message': ""Fix instance_extra backref\n\nThis fixes cruft from the original NUMA patches that placed a backref on\nthe Instance model for numa_topology. This changes it to the generic\n'instance_extra'. Since this was not actually used, nothing breaks; the\nextra backref will be used in subsequent patches.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ifa69e4704ea3f60b4aced3504bf9c599e3868616\n""}, {'number': 7, 'created': '2014-10-14 17:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ded81e00884375e799a1673f2974c63536eace8b', 'message': ""Fix instance_extra backref\n\nThis fixes cruft from the original NUMA patches that placed a backref on\nthe Instance model for numa_topology. This changes it to the generic\n'instance_extra'. Since this was not actually used, nothing breaks; the\nextra backref will be used in subsequent patches.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ifa69e4704ea3f60b4aced3504bf9c599e3868616\n""}, {'number': 8, 'created': '2014-10-14 18:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e77c113ecf6f7fff5a271de551c1b796f223f18', 'message': ""Fix instance_extra backref\n\nThis fixes cruft from the original NUMA patches that placed a backref on\nthe Instance model for numa_topology. This changes it to the generic\n'instance_extra'. Since this was not actually used, nothing breaks; the\nextra backref will be used in subsequent patches.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ifa69e4704ea3f60b4aced3504bf9c599e3868616\n""}, {'number': 9, 'created': '2014-10-14 19:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9d493ace027d93c863b278519894dc09ee0caa04', 'message': ""Fix instance_extra backref\n\nThis fixes cruft from the original NUMA patches that placed a backref on\nthe Instance model for numa_topology. This changes it to the generic\n'instance_extra'. Since this was not actually used, nothing breaks; the\nextra backref will be used in subsequent patches.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ifa69e4704ea3f60b4aced3504bf9c599e3868616\n""}, {'number': 10, 'created': '2014-10-15 15:42:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f5bb9db72c05bbf473bbac3f9faf62fc932e2883', 'message': ""Fix instance_extra backref\n\nThis fixes cruft from the original NUMA patches that placed a backref on\nthe Instance model for numa_topology. This changes it to the generic\n'instance_extra'. Since this was not actually used, nothing breaks; the\nextra backref will be used in subsequent patches.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ifa69e4704ea3f60b4aced3504bf9c599e3868616\n""}, {'number': 11, 'created': '2014-10-15 18:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d8dedd76255b0e7c5a6869f92c0e9b7944baffc', 'message': ""Fix instance_extra backref\n\nThis fixes cruft from the original NUMA patches that placed a backref on\nthe Instance model for numa_topology. This changes it to the generic\n'instance_extra'. Since this was not actually used, nothing breaks; the\nextra backref will be used in subsequent patches.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ifa69e4704ea3f60b4aced3504bf9c599e3868616\n""}, {'number': 12, 'created': '2014-10-15 19:31:37.000000000', 'files': ['nova/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/208054a7ef9678dbd4e853f15638e9fad87ea9df', 'message': ""Fix instance_extra backref\n\nThis fixes cruft from the original NUMA patches that placed a backref on\nthe Instance model for numa_topology. This changes it to the generic\n'instance_extra'. Since this was not actually used, nothing breaks; the\nextra backref will be used in subsequent patches.\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: Ifa69e4704ea3f60b4aced3504bf9c599e3868616\n""}]",3,125480,208054a7ef9678dbd4e853f15638e9fad87ea9df,67,12,12,4393,,,0,"Fix instance_extra backref

This fixes cruft from the original NUMA patches that placed a backref on
the Instance model for numa_topology. This changes it to the generic
'instance_extra'. Since this was not actually used, nothing breaks; the
extra backref will be used in subsequent patches.

Related to blueprint flavor-from-sysmeta-to-blob

Change-Id: Ifa69e4704ea3f60b4aced3504bf9c599e3868616
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/125480/12 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/models.py'],1,6e6480b1fe84ac73b8cae781e29358e4ea750f54,bp/flavor-from-sysmeta-to-blob," backref=orm.backref('extra',"," backref=orm.backref('numa_topology',",1,1
openstack%2Fnova~master~Iee3e9ea619417178618f8f6c192097444899dd26,openstack/nova,master,Iee3e9ea619417178618f8f6c192097444899dd26,Refactor compute tests to not use _objectify(),MERGED,2014-10-15 15:42:21.000000000,2014-10-17 03:50:54.000000000,2014-10-17 03:50:50.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1063}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8412}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-15 15:42:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b1f4d83b064d0a4e6d7265d06dd12d072b3f0893', 'message': 'Refactor compute tests to not use _objectify()\n\nDuring the objects conversion of nova-compute, we ended up with a lot of\nplaces in the tests where we would take a dict or sqlalchemy object\nand ""objectify"" it to pass it to a method that had been converted to\nexpect an obejct. That work is done now, but we have a LOT of cruft in\nthat code that needs to be cleaned up. This patch does that, and removes\nthe _objectify() helper.\n\nChange-Id: Iee3e9ea619417178618f8f6c192097444899dd26\n'}, {'number': 2, 'created': '2014-10-15 18:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb3e2084b1eb9217e981fc3539ebfb3162d05787', 'message': 'Refactor compute tests to not use _objectify()\n\nDuring the objects conversion of nova-compute, we ended up with a lot of\nplaces in the tests where we would take a dict or sqlalchemy object\nand ""objectify"" it to pass it to a method that had been converted to\nexpect an obejct. That work is done now, but we have a LOT of cruft in\nthat code that needs to be cleaned up. This patch does that, and removes\nthe _objectify() helper.\n\nChange-Id: Iee3e9ea619417178618f8f6c192097444899dd26\n'}, {'number': 3, 'created': '2014-10-15 19:31:37.000000000', 'files': ['nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/39da5313aa4c0dce7c2043811cbfd32c015f8d96', 'message': 'Refactor compute tests to not use _objectify()\n\nDuring the objects conversion of nova-compute, we ended up with a lot of\nplaces in the tests where we would take a dict or sqlalchemy object\nand ""objectify"" it to pass it to a method that had been converted to\nexpect an obejct. That work is done now, but we have a LOT of cruft in\nthat code that needs to be cleaned up. This patch does that, and removes\nthe _objectify() helper.\n\nChange-Id: Iee3e9ea619417178618f8f6c192097444899dd26\n'}]",2,128683,39da5313aa4c0dce7c2043811cbfd32c015f8d96,27,10,3,4393,,,0,"Refactor compute tests to not use _objectify()

During the objects conversion of nova-compute, we ended up with a lot of
places in the tests where we would take a dict or sqlalchemy object
and ""objectify"" it to pass it to a method that had been converted to
expect an obejct. That work is done now, but we have a LOT of cruft in
that code that needs to be cleaned up. This patch does that, and removes
the _objectify() helper.

Change-Id: Iee3e9ea619417178618f8f6c192097444899dd26
",git fetch https://review.opendev.org/openstack/nova refs/changes/83/128683/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/compute/test_compute.py'],1,b1f4d83b064d0a4e6d7265d06dd12d072b3f0893,bp/flavor-from-sysmeta-to-blob," return objects.Instance._from_db_object( self.context, objects.Instance(), db_inst, expected_attrs=instance_obj.INSTANCE_DEFAULT_FIELDS) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) instance.refresh() self.assertTrue(instance['launched_at'].replace(tzinfo=None) > launch) self.compute.terminate_instance(self.context, instance, [], []) self.assertTrue(instance['launched_at'].replace( tzinfo=None) < terminate) self.assertTrue(instance['deleted_at'].replace( tzinfo=None) > terminate) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, inst_obj, [], []) self.compute.terminate_instance(self.context, inst_obj, [], []) self.compute.rebuild_instance(self.context, instance, self.compute.terminate_instance(self.context, instance, [], []) self.compute.rebuild_instance(self.context, instance, self.compute.terminate_instance(self.context, instance, [], []) self.compute.rebuild_instance(self.context, instance, self.compute.terminate_instance(self.context, instance, [], []) self.compute.rebuild_instance(self.context, instance, instance.refresh() self.assertEqual(cur_time, instance['launched_at'].replace(tzinfo=None)) self.compute.terminate_instance(self.context, instance, [], []) self.compute.rebuild_instance(self.context, instance, self.compute.terminate_instance(self.context, instance, [], []) self.compute.reset_network(self.context, instance) self.compute.terminate_instance(self.context, instance, [], []) instance.task_state = task_states.IMAGE_SNAPSHOT_PENDING instance.save() return instance self.compute.terminate_instance(self.context, instance, [], []) instance=instance) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) instance.refresh() self.assertEqual(payload['instance_id'], instance['uuid']) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) instance.refresh() self.assertEqual(vm_states.ERROR, instance.vm_state) self.compute.terminate_instance(self.context, instance, [], []) instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) instance.refresh() # should fail with locked nonadmin context self.compute_api.lock(self.context, instance) non_admin_context, instance, 'SOFT') self.compute_api.unlock(self.context, instance) instance.task_state = task_states.REBOOTING instance.save() non_admin_context, instance, 'SOFT') instance.task_state = None instance.save() self.compute_api.reboot(self.context, instance, 'SOFT') self.compute.terminate_instance(self.context, instance, [], []) self.compute_api.lock(self.context, instance) self.compute_api.unlock(admin_context, instance) self.compute_api.lock(self.context, instance) self.compute_api.lock(admin_context, instance) instance.refresh() self.context, instance) self.compute_api.unlock(admin_context, instance) self.compute.terminate_instance(self.context, instance, bdms=[], reservations=resvs) self.context, instance, instance = self._create_fake_instance_obj( params=dict(task_state=task_states.SOFT_DELETING)) self.compute.terminate_instance(self.context, instance, bdms=[], reservations=resvs) self.compute.terminate_instance(self.context, instance, [], []) inst_ref.task_state = task_states.REBUILDING inst_ref.save() inst_ref, inst_ref.refresh() self.compute.terminate_instance(self.context, inst_ref, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) self.compute.terminate_instance(self.context, instance, [], []) instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj({ 'state': power_state.PAUSED}) instance = self._create_fake_instance_obj({ 'state': power_state.PAUSED}) instance) instance.refresh() instance = self._create_fake_instance_obj() instance.refresh() self.compute.terminate_instance(self.context, instance, [], []) instance = self._create_fake_instance_obj(params={'host': CONF.host}) self.compute_api.add_fixed_ip(self.context, instance, '1') instance, '192.168.1.1') self.compute_api.delete(self.context, instance) self.compute.terminate_instance(admin, instance, bdms, []) self.compute.terminate_instance(self.context, instance, bdms, []) self.compute_api.delete(self.context, instance) instance = self._create_fake_instance_obj() self.compute_api.delete(self.context, instance) instance = self._create_fake_instance_obj(params={'host': None, 'cell_name': 'foo'}) self.compute_api.delete(self.context, instance) instance_uuid = str(uuid.uuid4()) instance = self._create_fake_instance_obj( params={'uuid': instance_uuid})"," def _objectify(self, db_inst): return objects.Instance._from_db_object( self.context, objects.Instance(), db_inst, expected_attrs=instance_obj.INSTANCE_DEFAULT_FIELDS) return self._objectify(db_inst) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) instance = db.instance_get_by_uuid(self.context, instance['uuid']) self.assertTrue(instance['launched_at'] > launch) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.assertTrue(instance['launched_at'] < terminate) self.assertTrue(instance['deleted_at'] > terminate) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(inst_obj), [], []) self.compute.terminate_instance(self.context, self._objectify(inst_obj), [], []) self.compute.rebuild_instance(self.context, self._objectify(instance), self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.rebuild_instance(self.context, self._objectify(instance), self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.rebuild_instance(self.context, self._objectify(instance), self.compute.terminate_instance(self.context, self._objectify(instance), [], []) instance_uuid = instance['uuid'] self.compute.rebuild_instance(self.context, self._objectify(instance), instance = db.instance_get_by_uuid(self.context, instance_uuid,) self.assertEqual(cur_time, instance['launched_at']) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.rebuild_instance(self.context, self._objectify(instance), self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.reset_network(self.context, instance=self._objectify(instance)) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) instance = db.instance_update( self.context, instance['uuid'], {""task_state"": task_states.IMAGE_SNAPSHOT_PENDING}) return self._objectify(instance) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) instance=self._objectify(instance)) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) instance_uuid = instance['uuid'] inst_ref = db.instance_get_by_uuid(self.context, instance_uuid) self.assertEqual(payload['instance_id'], inst_ref['uuid']) self.compute.terminate_instance(self.context, self._objectify(inst_ref), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) instance = db.instance_get_by_uuid(context.get_admin_context(), instance['uuid']) self.assertEqual(vm_states.ERROR, instance['vm_state']) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) # should fail with locked nonadmin context inst_obj = objects.Instance.get_by_uuid(self.context, instance['uuid']) self.compute_api.lock(self.context, inst_obj) non_admin_context, inst_obj, 'SOFT') self.compute_api.unlock(self.context, inst_obj) instance = db.instance_update(self.context, instance_uuid, {'task_state': task_states.REBOOTING}) inst_obj.refresh() non_admin_context, inst_obj, 'SOFT') instance = db.instance_update(self.context, instance_uuid, {'task_state': None}) inst_obj.refresh() self.compute_api.reboot(self.context, inst_obj, 'SOFT') self.compute.terminate_instance(self.context, self._objectify(instance), [], []) inst_obj = self._objectify(instance) self.compute_api.lock(self.context, inst_obj) self.compute_api.unlock(admin_context, inst_obj) inst_obj = self._objectify(instance) self.compute_api.lock(self.context, inst_obj) self.compute_api.lock(admin_context, inst_obj) inst_obj.refresh() self.context, inst_obj) self.compute_api.unlock(admin_context, inst_obj) self.compute.terminate_instance(self.context, self._objectify(instance), bdms=[], reservations=resvs) self.context, self._objectify(instance), instance = self._objectify(self._create_fake_instance( params=dict(task_state=task_states.SOFT_DELETING))) self.compute.terminate_instance(self.context, self._objectify(instance), bdms=[], reservations=resvs) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) instance = db.instance_get_by_uuid(self.context, inst_ref['uuid']) db.instance_update(self.context, instance['uuid'], {""task_state"": task_states.REBUILDING}) self._objectify(instance), instance = db.instance_get_by_uuid(self.context, inst_ref['uuid']) self.compute.terminate_instance(self.context, self._objectify(inst_ref), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) instance = self._objectify(self._create_fake_instance_obj()) instance = self._objectify(self._create_fake_instance({ 'state': power_state.PAUSED})) instance = self._objectify(self._create_fake_instance({ 'state': power_state.PAUSED})) self._objectify(instance)) instance = db.instance_get_by_uuid(self.context, instance_uuid) instance = self._create_fake_instance() instance = db.instance_get_by_uuid(self.context, instance['uuid']) self.compute.terminate_instance(self.context, self._objectify(instance), [], []) instance = self._create_fake_instance(params={'host': CONF.host}) self.compute_api.add_fixed_ip(self.context, self._objectify(instance), '1') self._objectify(instance), '192.168.1.1') self.compute_api.delete(self.context, self._objectify(instance)) self.compute.terminate_instance(admin, self._objectify(instance), bdms, []) self.compute.terminate_instance(self.context, self._objectify(instance), bdms, []) self.compute_api.delete(self.context, self._objectify(instance)) instance = self._create_fake_instance() self.compute_api.delete(self.context, self._objectify(instance)) instance = self._objectify(instance) instance = self._create_fake_instance(params={'host': None, 'cell_name': 'foo'}) self.compute_api.delete(self.context, self._objectify(instance)) instance_uuid = ""12-34-56-78-90"" instance = fake_instance.fake_db_instance(uuid=instance_uuid) instance = self._objectify(instance)",118,172
openstack%2Fnova-specs~master~I322f4f51a0a1ea7ebc832c8cfec84d7681c1f9a4,openstack/nova-specs,master,I322f4f51a0a1ea7ebc832c8cfec84d7681c1f9a4,modified specs of thunder-boost Implements: blueprint thunder-boost,ABANDONED,2014-10-17 02:43:52.000000000,2014-10-17 03:44:52.000000000,,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 8247}, {'_account_id': 13437}]","[{'number': 1, 'created': '2014-10-17 02:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/577887ec3b1acd4c2b547c30cbf9b6254cc971d1', 'message': 'add specs of thunder-boost\nImplements: blueprint thunder-boost\n\nChange-Id: Id726cf053ed7c210eaea47d26fa1cdbf38b9cb57\n\nmodified  specs/kilo/approved/thunder-boost.rst\n\nChange-Id: Ia512d9794516c9f6def9d3dbb281d8e7700cbd57\n\nmodified thunder-boost.rst\nImplements: blueprint thunder-boost\n\nChange-Id: I322f4f51a0a1ea7ebc832c8cfec84d7681c1f9a4\n'}, {'number': 2, 'created': '2014-10-17 02:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/11b085b9a18216f4728959f0ee3e064a9c1bbf7d', 'message': 'add specs of thunder-boost\nImplements: blueprint thunder-boost\n\nChange-Id: I322f4f51a0a1ea7ebc832c8cfec84d7681c1f9a4\n'}, {'number': 3, 'created': '2014-10-17 03:17:57.000000000', 'files': ['specs/kilo/approved/thunder-boost.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/92c9e8bcf431e3f7a7a93b05891363ee7a03df87', 'message': 'modified specs of thunder-boost\nImplements: blueprint thunder-boost\n\nChange-Id: I322f4f51a0a1ea7ebc832c8cfec84d7681c1f9a4\n'}]",0,129113,92c9e8bcf431e3f7a7a93b05891363ee7a03df87,11,5,3,13437,,,0,"modified specs of thunder-boost
Implements: blueprint thunder-boost

Change-Id: I322f4f51a0a1ea7ebc832c8cfec84d7681c1f9a4
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/13/129113/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/thunder-boost.rst'],1,577887ec3b1acd4c2b547c30cbf9b6254cc971d1,bp/thunder-boost,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================================================= A Lightweight Proposal for Fast Booting Many Homogeneous Virtual Machines ========================================================================= https://blueprints.launchpad.net/nova/+spec/thunder-boost Nova supports to boot virtual machines (VMs) atop the Cinder volumes. However, in the current implementation (version j), booting up a large number of homogeneous VMs is time-consuming. To overcome this drawback, we propose a lightweight patch for Nova, which adopts a third-party library, called VMThunder, for fast booting homogeneous VMs. VMThunder accelerates the booting process through on-demand data transfer in a P2P manner. Problem description =================== Currently, Openstack provides two categories of methods for booting a virtual machine: (i) booting from a local image or (ii) booting from a remote Cinder volume. The first category needs to copy the entire image to a compute node, making it suffer from a long transfer delay for large images. The second category remotely attaches a volume to a VM and transfers only the necessary data from the volume, thus having better performance. However, this approach only allows booting a single VM from a volume at a time. Moreover, preparing a volume for each VM requires a long time. As a result, it is currently inevitable to take a long time for booting a large number of homogeneous VMs in Openstack. Use Cases ---------- For users who want to fast boot multiple homogeneous VMs, choose ""Boot from VMThunder"" in horizon and select the template volume(which contains image) that you want to boot from, click ""launch"" button, then you can launch vms. Project Priority ----------------- undefined Proposed change =============== We propose to add a new method, named ""Boot from VMThunder"", for fast booting multiple homogeneous VMs. This method uses a third-party library (VMThunder) to support simultaneous booting of a large number of VMs. VMThunder configures each VM with two volumes (the figure can be found here http://www.kylinx.com/vmthunder/vmthunder.png): a (read-only) template volume exactly the same as the pre-created original volume and a (writable) snapshot volume storing each VM's difference to the template. The original volume is the root of a template volume relay tree, and each VM fetches only the necessary data from its parent over the multi-path iSCSI protocol. In addition, VMThunder makes use of a compute node's local storage as a cache to accelerate the image transferring process and avoid a repetitive data transfer. The P2P-style, on-demand data transfer dramatically accelerates VMs' booting process. Our modification to Nova is light-weighted (about 80 lines of insertions and deletions). Two major functions, i.e., the creation and deletion of the template and snapshot volumes, are implemented as following: (i) creation: We add a volume-driver class (about 50 lines, depends on VMThunder's API) in file ""nova/virt/block_device.py"" to prepare the template and snapshot volumes. (ii) deletion: We add a delete method (about 20 lines, depends on VMThunder's API) in file ""nova/compute/manager.py' to destroy the unused template and snapshot volumes. More details of the implementation can be found in the following links: Paper, http://www.computer.org/csdl/trans/td/preprint/06719385.pdf Modification diff file, http://www.kylinx.com/vmthunder/diff2.txt VMThunder demo videos, http://www.kylinx.com/vmthunder/boot_vmthunder_win7_success-V2.mp4 Image booting demo videos, http://www.kylinx.com/vmthunder/boot_image_test_win7_success-V2.mp4 Alternatives ------------ (1)Image cache: Nova's image-caching facility reduces the start-up time for creating homogeneous virtual machines on one nova-compute node. However, it helps neither the first-time provisioning nor the Cinder-based booting process. (2)P2P transferring: The P2P protocol can increase the speed of the file distribution. For example, the glance-bittorrent-delivery proposal transfers the image templates from the glance storage to Nova-compute servers. This approach, however, needs to transfer the entire image to all peers. (3)Backend storage optimization: The distributed storages like NFS, cluster FS, distributed FS or SAN can decrease the size of transferred volumes. However, the I/O pressure on the storage servers increases dramatically when powering on a large number of homogeneous VMs, since there may not be enough replicas on the storage servers for offloading the I/O demands. (4)Multi-attach volume: (https://wiki.openstack.org/wiki/Cinder/blueprints/multi-attach-volume) This approach allows a volume to be attached to more than one instance simultaneously. As a result, volumes can be shared among multiple guests when the instances are already available. Besides, these volumes can also be used for booting a number of VMs by enforcing the multi-attach volumes as read-only image disks. Unfortunately, this approach does not scale well because of the star-structured topology in the data dissemination process. (5)Direct image access: (https://blueprints.launchpad.net/nova/+spec/nova-image-zero-copy). This approach uses the direct_url of the Glance v2 API, such that the number of needed hops to transfer an image to a Nova-compute node is decreased. When images are stored at multiple backend locations, the Nova-compute servers can select a proper image storage for speeding up the downloading process. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ We will significantly decrease the delay of booting up large numbers of Cinder-volume-based VMs. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: vmThunderGroup (vmthunder) Work Items ---------- We only add one lightweight patch for Nova. Dependencies ============ The patch depends on the VMThunder project (https://launchpad.net/VMThunder). Testing ======= We will add necessary tests into nova's test framework, in order to show the effectiveness of VMThunder. The unit tests and integrated tests will be added to the component. Documentation Impact ==================== We need to document how to create many homogeneous virtual machines though our new option. References ========== VMThunder: http://www.VMThunder.org/ Mailing list: http://lists.openstack.org/pipermail/openstack-dev/2014-April/032883.html VMThunder Publication:http://www.VMThunder.org/blog/2014/03/02/publication/ ",,199,0
openstack%2Fcinder-specs~master~I3e1868b827696bc5a448babc2fddecfe6bcc3e04,openstack/cinder-specs,master,I3e1868b827696bc5a448babc2fddecfe6bcc3e04,add spec of add-flashcachegroup-support,ABANDONED,2014-10-16 05:46:41.000000000,2014-10-17 03:38:02.000000000,,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 13437}]","[{'number': 1, 'created': '2014-10-16 05:46:41.000000000', 'files': ['specs/kilo/flashcahegroup.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/a29c3b7a974ffe8d9847c9739846bd471e32ad46', 'message': 'add spec of add-flashcachegroup-support\n\nChange-Id: I3e1868b827696bc5a448babc2fddecfe6bcc3e04\nImplements: blueprint add-flashcachegroup-support\n'}]",0,128833,a29c3b7a974ffe8d9847c9739846bd471e32ad46,5,3,1,13437,,,0,"add spec of add-flashcachegroup-support

Change-Id: I3e1868b827696bc5a448babc2fddecfe6bcc3e04
Implements: blueprint add-flashcachegroup-support
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/33/128833/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/flashcahegroup.rst'],1,a29c3b7a974ffe8d9847c9739846bd471e32ad46,bp/add-flashcachegroup-support,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================================================================== Add flashcachegroup support =============================================================================== https://blueprints.launchpad.net/cinder/+spec/add-flashcachegroup-support Flashcachegroup is a Python package that makes facebook's flashcache to cache a group of disks with one or multiple SSDs. As we know, flashcache allows one to use a fast block device such as SSD as cache to accelerate a slower drive. By using flashcachegroup, not only can we accelerate disk access performance, but also create group of disks more easily. Problem description =================== Currently, there is not a common data cache mechanism for block device storage in Cinder. The block device on the compute nodes are dynamically mounted from the storage server, therefore Cinder requires a dynamically configurable cache tool. Using cache mechanism on the compute nodes can improve the performance of compute nodes and ease the pressure of the storage server. Flashcachegroup enables a group of disk(s) (on storage server) shares a cache mechanism supplied by one or multiple SSDs (on compute nodes) to save read/write time. For the purpose of easy management, simply creating a group of hard disks is also feasible. Hard disk(s) can be dynamically added to or removed from the group on demand. Proposed change =============== Add flashcachegroup call interface in /cinder/volume/ path, and realize basic features: * create a flashcachegroup * delete a flashcachegroup * add disk to the flashcachegroup * remove disk to the flashcachegroup Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ The performance of accessing to the volume with local cache will improve. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: vmThunderGroup (vmthunder) Work Items ---------- Add the Flashcachegroup call interface to the cinder Add unit tests Dependencies ============ Flashcachegroup Python package and facebook's flashcache must already installed in running environment. Testing ======= The unit tests and integrated tests will be added to the component. Documentation Impact ==================== None References ========== Flashcachegroup: https://github.com/lihuiba/flashcachegroup ",,123,0
openstack%2Fnova~master~I10a66fc02df92e91700544c0cb12517908f09710,openstack/nova,master,I10a66fc02df92e91700544c0cb12517908f09710,Refactor compute and conductor tests to use objects,MERGED,2014-10-14 14:55:27.000000000,2014-10-17 03:33:46.000000000,2014-10-17 03:33:43.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-14 14:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9df6d8c3abdb7322fad7bf2378448e76f263c37', 'message': 'Refactor compute and conductor tests to use objects\n\nThere are still a lot of tests that pass primitives to compute\nand conductor methods that have expected objects for a long time\nnow. These also tend to do silly things like doing to_primitive()\non the db models, just to get the uuid out. Since this all makes\nthe following work harder, this patch converts them (all?) to use\nobjects.\n\nChange-Id: I10a66fc02df92e91700544c0cb12517908f09710\n'}, {'number': 2, 'created': '2014-10-14 17:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/032355cdb8bcafd3ef33a6765d0efad378d7db1f', 'message': 'Refactor compute and conductor tests to use objects\n\nThere are still a lot of tests that pass primitives to compute\nand conductor methods that have expected objects for a long time\nnow. These also tend to do silly things like doing to_primitive()\non the db models, just to get the uuid out. Since this all makes\nthe following work harder, this patch converts them (all?) to use\nobjects.\n\nChange-Id: I10a66fc02df92e91700544c0cb12517908f09710\n'}, {'number': 3, 'created': '2014-10-14 18:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8fece6696db1d81140cadc0c9b691674d5a8b65', 'message': 'Refactor compute and conductor tests to use objects\n\nThere are still a lot of tests that pass primitives to compute\nand conductor methods that have expected objects for a long time\nnow. These also tend to do silly things like doing to_primitive()\non the db models, just to get the uuid out. Since this all makes\nthe following work harder, this patch converts them (all?) to use\nobjects.\n\nChange-Id: I10a66fc02df92e91700544c0cb12517908f09710\n'}, {'number': 4, 'created': '2014-10-14 19:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1be616c197178c0e6c7e6499ab6b47319785ab24', 'message': 'Refactor compute and conductor tests to use objects\n\nThere are still a lot of tests that pass primitives to compute\nand conductor methods that have expected objects for a long time\nnow. These also tend to do silly things like doing to_primitive()\non the db models, just to get the uuid out. Since this all makes\nthe following work harder, this patch converts them (all?) to use\nobjects.\n\nChange-Id: I10a66fc02df92e91700544c0cb12517908f09710\n'}, {'number': 5, 'created': '2014-10-15 15:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b6bf6554701b48b5da70088ef6b819facde1f3b', 'message': 'Refactor compute and conductor tests to use objects\n\nThere are still a lot of tests that pass primitives to compute\nand conductor methods that have expected objects for a long time\nnow. These also tend to do silly things like doing to_primitive()\non the db models, just to get the uuid out. Since this all makes\nthe following work harder, this patch converts them (all?) to use\nobjects.\n\nChange-Id: I10a66fc02df92e91700544c0cb12517908f09710\n'}, {'number': 6, 'created': '2014-10-15 18:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e231b3c429b8345a1ce065a1045420fd6ba12c48', 'message': 'Refactor compute and conductor tests to use objects\n\nThere are still a lot of tests that pass primitives to compute\nand conductor methods that have expected objects for a long time\nnow. These also tend to do silly things like doing to_primitive()\non the db models, just to get the uuid out. Since this all makes\nthe following work harder, this patch converts them (all?) to use\nobjects.\n\nChange-Id: I10a66fc02df92e91700544c0cb12517908f09710\n'}, {'number': 7, 'created': '2014-10-15 19:31:38.000000000', 'files': ['nova/tests/conductor/test_conductor.py', 'nova/tests/compute/test_shelve.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fd8b29c8352c23bdf44d2c8dbb92056142475bf7', 'message': 'Refactor compute and conductor tests to use objects\n\nThere are still a lot of tests that pass primitives to compute\nand conductor methods that have expected objects for a long time\nnow. These also tend to do silly things like doing to_primitive()\non the db models, just to get the uuid out. Since this all makes\nthe following work harder, this patch converts them (all?) to use\nobjects.\n\nChange-Id: I10a66fc02df92e91700544c0cb12517908f09710\n'}]",35,128315,fd8b29c8352c23bdf44d2c8dbb92056142475bf7,56,11,7,4393,,,0,"Refactor compute and conductor tests to use objects

There are still a lot of tests that pass primitives to compute
and conductor methods that have expected objects for a long time
now. These also tend to do silly things like doing to_primitive()
on the db models, just to get the uuid out. Since this all makes
the following work harder, this patch converts them (all?) to use
objects.

Change-Id: I10a66fc02df92e91700544c0cb12517908f09710
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/128315/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/conductor/test_conductor.py', 'nova/tests/compute/test_shelve.py', 'nova/tests/compute/test_compute.py']",3,f9df6d8c3abdb7322fad7bf2378448e76f263c37,bp/flavor-from-sysmeta-to-blob," return dict([(key, value) for key, value in db.instance_create(self.context, inst).iteritems() if key != 'extra']) instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj( params={'config_drive': '1234', }) instance = self._create_fake_instance_obj( params={'config_drive': '1234', }) instance = self._create_fake_instance() instance = self._create_fake_instance() instance = self._create_fake_instance() instance = self._create_fake_instance_obj() instance, bdms, []) instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance, {}, {}, [], None, None, True, instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance['uuid']) instance = self._create_fake_instance_obj() self.compute.inject_network_info(self.context, instance=instance) instance, [], []) instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance, {}, {}, [], None, instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() for operation in actions: self._test_state_revert(instance, *operation) instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj( params=dict(task_state=task_states.SOFT_DELETING)) instance = self._create_fake_instance_obj( params=dict(vm_state=vm_states.SOFT_DELETED)) inst_ref = self._create_fake_instance() self.instance = self._create_fake_instance_obj(params) instance = self._create_fake_instance_obj() instance1 = self._create_fake_instance_obj({""deleted_at"": deleted_at, ""deleted"": True}) instance2 = self._create_fake_instance_obj({""deleted_at"": deleted_at, ""deleted"": True}) instance = self._create_fake_instance_obj({""deleted_at"": deleted_at, ""deleted"": True}) self._create_fake_instance_obj( self._create_fake_instance_obj( instance = self._create_fake_instance_obj(params, services=True) instance = self._create_fake_instance() instance = self._create_fake_instance_obj(params={'image_ref': ''}) instance = self._create_fake_instance_obj( params={'architecture': ''}) instance = self._create_fake_instance_obj() instance = self._create_fake_instance_obj(params={'host': CONF.host}) instance, {}, {}, None, None, instance = self._create_fake_instance_obj() instance, {}, {}, None, None, instance = self._create_fake_instance_obj() instance, {}, {}, None, None, self.instance = self._create_fake_instance_obj() inst_obj = self.instance self.inst_ref = self._create_fake_instance( {'host': 'fake_host_2', 'node': 'fakenode2'})"," return db.instance_create(self.context, inst) instance = self._create_fake_instance() instance = self._create_fake_instance() instance = self._create_fake_instance() instance = self._create_fake_instance() instance = jsonutils.to_primitive(self._create_fake_instance( params={'config_drive': '1234', })) instance = jsonutils.to_primitive(self._create_fake_instance( params={'config_drive': '1234', })) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) self._objectify(instance), bdms, []) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = self._create_fake_instance() jsonutils.to_primitive(instance), {}, {}, [], None, None, True, instance = self._objectify(instance) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = self._objectify(instance) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = self._objectify(instance) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = self._objectify(instance) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = self._objectify(instance) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = self._objectify(instance) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance.uuid) instance = jsonutils.to_primitive(self._create_fake_instance()) inst_obj = self._objectify(instance) self.compute.inject_network_info(self.context, instance=inst_obj) self._objectify(instance), [], []) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, jsonutils.to_primitive(instance), {}, {}, [], None, instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) want_objects = ['stop_instance', 'start_instance', 'terminate_instance', 'soft_delete_instance', 'revert_resize', 'confirm_resize' ] instance = self._create_fake_instance() inst_obj = objects.Instance._from_db_object( self.context, objects.Instance(), instance, expected_attrs=instance_obj.INSTANCE_DEFAULT_FIELDS) for operation in actions: if operation[0] in want_objects: self._test_state_revert(inst_obj, *operation) else: self._test_state_revert(instance, *operation) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive(self._create_fake_instance( params=dict(task_state=task_states.SOFT_DELETING))) instance = jsonutils.to_primitive(self._create_fake_instance( params=dict(vm_state=vm_states.SOFT_DELETED))) inst_ref = jsonutils.to_primitive(self._create_fake_instance()) self.instance = jsonutils.to_primitive( self._create_fake_instance(params)) instance = jsonutils.to_primitive(self._create_fake_instance()) instance1 = self._create_fake_instance({""deleted_at"": deleted_at, ""deleted"": True}) instance2 = self._create_fake_instance({""deleted_at"": deleted_at, ""deleted"": True}) instance = self._create_fake_instance({""deleted_at"": deleted_at, ""deleted"": True}) self._create_fake_instance( self._create_fake_instance( instance = jsonutils.to_primitive(self._create_fake_instance(params, services=True)) instance = jsonutils.to_primitive(self._create_fake_instance()) instance = jsonutils.to_primitive( self._create_fake_instance(params={'image_ref': ''})) instance = jsonutils.to_primitive(self._create_fake_instance( params={'architecture': ''})) instance = self._create_fake_instance() instance = self._create_fake_instance(params={'host': CONF.host}) jsonutils.to_primitive(instance), {}, {}, None, None, instance = self._create_fake_instance() jsonutils.to_primitive(instance), {}, {}, None, None, instance = self._create_fake_instance() jsonutils.to_primitive(instance), {}, {}, None, None, self.instance = self._create_fake_instance() inst_obj = self._objectify(self.instance) self.inst_ref = jsonutils.to_primitive(self._create_fake_instance ({'host': 'fake_host_2', 'node': 'fakenode2'}))",131,147
openstack%2Fhorizon~master~Icd94b601205657985a015a4ef7527878586a189f,openstack/horizon,master,Icd94b601205657985a015a4ef7527878586a189f,Fixing template syntax,MERGED,2014-10-16 19:29:56.000000000,2014-10-17 03:32:02.000000000,2014-10-17 03:32:02.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 7213}, {'_account_id': 9622}, {'_account_id': 11592}]","[{'number': 1, 'created': '2014-10-16 19:29:56.000000000', 'files': ['openstack_dashboard/dashboards/project/containers/templates/containers/_create_pseudo_folder.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0245407f448bb33fd15403792e0a7be9c9cc2e59', 'message': 'Fixing template syntax\n\nA quote was removed in a recent translation bug fix that causes\na template syntax exception resulting in an error on the page when\nattempting to create a pseudo folder. This fix allows for pseudo\nfolder creation again.\n\nCloses-Bug: #1382191\nChange-Id: Icd94b601205657985a015a4ef7527878586a189f\n'}]",0,129028,0245407f448bb33fd15403792e0a7be9c9cc2e59,11,6,1,5623,,,0,"Fixing template syntax

A quote was removed in a recent translation bug fix that causes
a template syntax exception resulting in an error on the page when
attempting to create a pseudo folder. This fix allows for pseudo
folder creation again.

Closes-Bug: #1382191
Change-Id: Icd94b601205657985a015a4ef7527878586a189f
",git fetch https://review.opendev.org/openstack/horizon refs/changes/28/129028/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/containers/templates/containers/_create_pseudo_folder.html'],1,0245407f448bb33fd15403792e0a7be9c9cc2e59,bug-1382191," <h3>{% trans ""Description:"" %}</h3>"," <h3>{% trans ""Description: %}</h3>",1,1
openstack%2Ftrove~master~I41c1bddf27be9986c43ce408eccfc6b43c5562a1,openstack/trove,master,I41c1bddf27be9986c43ce408eccfc6b43c5562a1,Mark trove as being a universal wheel,MERGED,2014-09-22 09:05:41.000000000,2014-10-17 03:31:59.000000000,2014-10-17 03:31:58.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}]","[{'number': 1, 'created': '2014-09-22 09:05:41.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/trove/commit/0a6819e9efb1fc5ed9d3817d6ca499ff39ba528a', 'message': 'Mark trove as being a universal wheel\n\nUniversal is used to identify pure-Python module(by bdist_wheel). For\nthese, it is sufficient to build a wheel with _any_ Python ABI\nversion and publish that to PyPI (by whatever means).\n\nChange-Id: I41c1bddf27be9986c43ce408eccfc6b43c5562a1\n'}]",0,123079,0a6819e9efb1fc5ed9d3817d6ca499ff39ba528a,10,5,1,6547,,,0,"Mark trove as being a universal wheel

Universal is used to identify pure-Python module(by bdist_wheel). For
these, it is sufficient to build a wheel with _any_ Python ABI
version and publish that to PyPI (by whatever means).

Change-Id: I41c1bddf27be9986c43ce408eccfc6b43c5562a1
",git fetch https://review.opendev.org/openstack/trove refs/changes/79/123079/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,0a6819e9efb1fc5ed9d3817d6ca499ff39ba528a,wheel-support, [wheel] universal = 1,,3,0
openstack%2Fnova-specs~master~Ia512d9794516c9f6def9d3dbb281d8e7700cbd57,openstack/nova-specs,master,Ia512d9794516c9f6def9d3dbb281d8e7700cbd57,add specs of thunder-boost,ABANDONED,2014-10-17 02:20:50.000000000,2014-10-17 02:46:20.000000000,,"[{'_account_id': 3}, {'_account_id': 6873}]","[{'number': 1, 'created': '2014-10-17 02:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/298b0c252c1bd6d9e395bee72855f6edea948951', 'message': 'add specs of thunder-boost\nImplements: blueprint thunder-boost\n\nChange-Id: Id726cf053ed7c210eaea47d26fa1cdbf38b9cb57\n\nmodified  specs/kilo/approved/thunder-boost.rst\n\nChange-Id: Ia512d9794516c9f6def9d3dbb281d8e7700cbd57\n'}, {'number': 2, 'created': '2014-10-17 02:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6e4fd3759edb59a3c8c7efb4355fde206aa56dae', 'message': 'add specs of thunder-boost\nImplements: blueprint thunder-boost\nChange-Id: Ia512d9794516c9f6def9d3dbb281d8e7700cbd57\n'}, {'number': 3, 'created': '2014-10-17 02:37:06.000000000', 'files': ['specs/kilo/approved/thunder-boost.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ad92be5abea497dd3920b14243a9d6ac650651b7', 'message': 'add specs of thunder-boost\n\nImplements: blueprint thunder-boost\nChange-Id: Ia512d9794516c9f6def9d3dbb281d8e7700cbd57\n'}]",1,129110,ad92be5abea497dd3920b14243a9d6ac650651b7,7,2,3,13437,,,0,"add specs of thunder-boost

Implements: blueprint thunder-boost
Change-Id: Ia512d9794516c9f6def9d3dbb281d8e7700cbd57
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/10/129110/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/thunder-boost.rst'],1,298b0c252c1bd6d9e395bee72855f6edea948951,bp/thunder-boost,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================================================= A Lightweight Proposal for Fast Booting Many Homogeneous Virtual Machines ========================================================================= https://blueprints.launchpad.net/nova/+spec/thunder-boost Nova supports to boot virtual machines (VMs) atop the Cinder volumes. However, in the current implementation (version j), booting up a large number of homogeneous VMs is time-consuming. To overcome this drawback, we propose a lightweight patch for Nova, which adopts a third-party library, called VMThunder, for fast booting homogeneous VMs. VMThunder accelerates the booting process through on-demand data transfer in a P2P manner. Problem description =================== Currently, Openstack provides two categories of methods for booting a virtual machine: (i) booting from a local image or (ii) booting from a remote Cinder volume. The first category needs to copy the entire image to a compute node, making it suffer from a long transfer delay for large images. The second category remotely attaches a volume to a VM and transfers only the necessary data from the volume, thus having better performance. However, this approach only allows booting a single VM from a volume at a time. Moreover, preparing a volume for each VM requires a long time. As a result, it is currently inevitable to take a long time for booting a large number of homogeneous VMs in Openstack. Use Cases ---------- For users who want to fast boot multiple homogeneous VMs, choose ""Boot from VMThunder"" in horizon and select the template volume(which contains image) that you want to boot from, click ""launch"" button, then you can launch vms. Project Priority ----------------- undefined Proposed change =============== We propose to add a new method, named ""Boot from VMThunder"", for fast booting multiple homogeneous VMs. This method uses a third-party library (VMThunder) to support simultaneous booting of a large number of VMs. VMThunder configures each VM with two volumes (the figure can be found here http://www.kylinx.com/vmthunder/vmthunder.png): a (read-only) template volume exactly the same as the pre-created original volume and a (writable) snapshot volume storing each VM's difference to the template. The original volume is the root of a template volume relay tree, and each VM fetches only the necessary data from its parent over the multi-path iSCSI protocol. In addition, VMThunder makes use of a compute node's local storage as a cache to accelerate the image transferring process and avoid a repetitive data transfer. The P2P-style, on-demand data transfer dramatically accelerates VMs' booting process. Our modification to Nova is light-weighted (about 80 lines of insertions and deletions). Two major functions, i.e., the creation and deletion of the template and snapshot volumes, are implemented as following: (i) creation: We add a volume-driver class (about 50 lines, depends on VMThunder's API) in file ""nova/virt/block_device.py"" to prepare the template and snapshot volumes. (ii) deletion: We add a delete method (about 20 lines, depends on VMThunder's API) in file ""nova/compute/manager.py' to destroy the unused template and snapshot volumes. More details of the implementation can be found in the following links: Paper, http://www.computer.org/csdl/trans/td/preprint/06719385.pdf Modification diff file, http://www.kylinx.com/vmthunder/diff2.txt VMThunder demo videos, http://www.kylinx.com/vmthunder/boot_vmthunder_win7_success-V2.mp4 Image booting demo videos, http://www.kylinx.com/vmthunder/boot_image_test_win7_success-V2.mp4 Alternatives ------------ (1)Image cache: Nova's image-caching facility reduces the start-up time for creating homogeneous virtual machines on one nova-compute node. However, it helps neither the first-time provisioning nor the Cinder-based booting process. (2)P2P transferring: The P2P protocol can increase the speed of the file distribution. For example, the glance-bittorrent-delivery proposal transfers the image templates from the glance storage to Nova-compute servers. This approach, however, needs to transfer the entire image to all peers. (3)Backend storage optimization: The distributed storages like NFS, cluster FS, distributed FS or SAN can decrease the size of transferred volumes. However, the I/O pressure on the storage servers increases dramatically when powering on a large number of homogeneous VMs, since there may not be enough replicas on the storage servers for offloading the I/O demands. (4)Multi-attach volume: (https://wiki.openstack.org/wiki/Cinder/blueprints/multi-attach-volume) This approach allows a volume to be attached to more than one instance simultaneously. As a result, volumes can be shared among multiple guests when the instances are already available. Besides, these volumes can also be used for booting a number of VMs by enforcing the multi-attach volumes as read-only image disks. Unfortunately, this approach does not scale well because of the star-structured topology in the data dissemination process. (5)Direct image access: (https://blueprints.launchpad.net/nova/+spec/nova-image-zero-copy). This approach uses the direct_url of the Glance v2 API, such that the number of needed hops to transfer an image to a Nova-compute node is decreased. When images are stored at multiple backend locations, the Nova-compute servers can select a proper image storage for speeding up the downloading process. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ We will significantly decrease the delay of booting up large numbers of Cinder-volume-based VMs. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: vmThunderGroup (vmthunder) Work Items ---------- We only add one lightweight patch for Nova. Dependencies ============ The patch depends on the VMThunder project (https://launchpad.net/VMThunder). Testing ======= We will add necessary tests into nova's test framework, in order to show the effectiveness of VMThunder. The unit tests and integrated tests will be added to the component. Documentation Impact ==================== We need to document how to create many homogeneous virtual machines though our new option. References ========== VMThunder: http://www.VMThunder.org/ Mailing list: http://lists.openstack.org/pipermail/openstack-dev/2014-April/032883.html VMThunder Publication:http://www.VMThunder.org/blog/2014/03/02/publication/ ",,199,0
openstack%2Fnova-specs~master~Id726cf053ed7c210eaea47d26fa1cdbf38b9cb57,openstack/nova-specs,master,Id726cf053ed7c210eaea47d26fa1cdbf38b9cb57,add specs of thunder-boost Implements: blueprint thunder-boost,ABANDONED,2014-10-17 02:02:46.000000000,2014-10-17 02:45:59.000000000,,"[{'_account_id': 3}, {'_account_id': 6873}]","[{'number': 1, 'created': '2014-10-17 02:02:46.000000000', 'files': ['specs/kilo/approved/thunder-boost.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/14b16dde07b7094813a02e069fa3b575ce278b5b', 'message': 'add specs of thunder-boost\nImplements: blueprint thunder-boost\n\nChange-Id: Id726cf053ed7c210eaea47d26fa1cdbf38b9cb57\n'}]",2,129108,14b16dde07b7094813a02e069fa3b575ce278b5b,5,2,1,13437,,,0,"add specs of thunder-boost
Implements: blueprint thunder-boost

Change-Id: Id726cf053ed7c210eaea47d26fa1cdbf38b9cb57
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/08/129108/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/thunder-boost.rst'],1,14b16dde07b7094813a02e069fa3b575ce278b5b,bp/thunder-boost,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================================================= A Lightweight Proposal for Fast Booting Many Homogeneous Virtual Machines ========================================================================= https://blueprints.launchpad.net/nova/+spec/thunder-boost Nova supports to boot virtual machines (VMs) atop the Cinder volumes. However, in the current implementation (version j), booting up a large number of homogeneous VMs is time-consuming. To overcome this drawback, we propose a lightweight patch for Nova, which adopts a third-party library, called VMThunder, for fast booting homogeneous VMs. VMThunder accelerates the booting process through on-demand data transfer in a P2P manner. Problem description =================== Currently, Openstack provides two categories of methods for booting a virtual machine: (i) booting from a local image or (ii) booting from a remote Cinder volume. The first category needs to copy the entire image to a compute node, making it suffer from a long transfer delay for large images. The second category remotely attaches a volume to a VM and transfers only the necessary data from the volume, thus having better performance. However, this approach only allows booting a single VM from a volume at a time. Moreover, preparing a volume for each VM requires a long time. As a result, it is currently inevitable to take a long time for booting a large number of homogeneous VMs in Openstack. Use Cases ---------- For users who want to fast boot multiple homogeneous VMs, choose ""Boot from VMThunder"" in horizon and select the template volume(which contains image) that you want to boot from, click ""launch"" button, then you can launch vms. Project Priority ----------------- undefined Proposed change =============== We propose to add a new method, named ""Boot from VMThunder"", for fast booting multiple homogeneous VMs. This method uses a third-party library (VMThunder) to support simultaneous booting of a large number of VMs. VMThunder configures each VM with two volumes (the figure can be found here http://www.kylinx.com/vmthunder/vmthunder.png): a (read-only) template volume exactly the same as the pre-created original volume and a (writable) snapshot volume storing each VM's difference to the template. The original volume is the root of a template volume relay tree, and each VM fetches only the necessary data from its parent over the multi-path iSCSI protocol. In addition, VMThunder makes use of a compute node's local storage as a cache to accelerate the image transferring process and avoid a repetitive data transfer. The P2P-style, on-demand data transfer dramatically accelerates VMs' booting process. Our modification to Nova is light-weighted (about 80 lines of insertions and deletions). Two major functions, i.e., the creation and deletion of the template and snapshot volumes, are implemented as following: (i) creation: We add a volume-driver class (about 50 lines, depends on VMThunder's API) in file ""nova/virt/block_device.py"" to prepare the template and snapshot volumes. (ii) deletion: We add a delete method (about 20 lines, depends on VMThunder's API) in file ""nova/compute/manager.py' to destroy the unused template and snapshot volumes. More details of the implementation can be found in the following links: Paper, http://www.computer.org/csdl/trans/td/preprint/06719385.pdf Modification diff file, http://www.kylinx.com/vmthunder/diff2.txt VMThunder demo videos, http://www.kylinx.com/vmthunder/boot_vmthunder_win7_success-V2.mp4 Image booting demo videos, http://www.kylinx.com/vmthunder/boot_image_test_win7_success-V2.mp4 Alternatives ------------ (1)Image cache: Nova's image-caching facility reduces the start-up time for creating homogeneous virtual machines on one nova-compute node. However, it helps neither the first-time provisioning nor the Cinder-based booting process. (2)P2P transferring: The P2P protocol can increase the speed of the file distribution. For example, the glance-bittorrent-delivery proposal transfers the image templates from the glance storage to Nova-compute servers. This approach, however, needs to transfer the entire image to all peers. (3)Backend storage optimization: The distributed storages like NFS, cluster FS, distributed FS or SAN can decrease the size of transferred volumes. However, the I/O pressure on the storage servers increases dramatically when powering on a large number of homogeneous VMs, since there may not be enough replicas on the storage servers for offloading the I/O demands. (4)Multi-attach volume: (https://wiki.openstack.org/wiki/Cinder/blueprints/multi-attach-volume) This approach allows a volume to be attached to more than one instance simultaneously. As a result, volumes can be shared among multiple guests when the instances are already available. Besides, these volumes can also be used for booting a number of VMs by enforcing the multi-attach volumes as read-only image disks. Unfortunately, this approach does not scale well because of the star-structured topology in the data dissemination process. (5)Direct image access: (https://blueprints.launchpad.net/nova/+spec/nova-image-zero-copy). This approach uses the direct_url of the Glance v2 API, such that the number of needed hops to transfer an image to a Nova-compute node is decreased. When images are stored at multiple backend locations, the Nova-compute servers can select a proper image storage for speeding up the downloading process. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ We will significantly decrease the delay of booting up large numbers of Cinder-volume-based VMs. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: vmThunderGroup (vmthunder) Work Items ---------- We only add one lightweight patch for Nova. Dependencies ============ The patch depends on the VMThunder project (https://launchpad.net/VMThunder). Testing ======= We will add necessary tests into nova's test framework, in order to show the effectiveness of VMThunder. The unit tests and integrated tests will be added to the component. Documentation Impact ==================== We need to document how to create many homogeneous virtual machines though our new option. References ========== VMThunder: http://www.VMThunder.org/ Mailing list: http://lists.openstack.org/pipermail/openstack-dev/2014-April/032883.html VMThunder Publication:http://www.VMThunder.org/blog/2014/03/02/publication/ ",,199,0
openstack%2Fswift~master~Ie9d80089a38d7a9b3464c66237d4d2d23331ebd5,openstack/swift,master,Ie9d80089a38d7a9b3464c66237d4d2d23331ebd5,Ssync does not replicate custom object headers,MERGED,2014-10-08 21:46:53.000000000,2014-10-17 02:25:05.000000000,2014-10-13 21:02:48.000000000,"[{'_account_id': 3}, {'_account_id': 1009}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 2828}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-10-08 21:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/085cbda0b4a514904d43993030795159c5854dad', 'message': 'Ssync does not replicate custom object headers\n\nChange-Id: Ie9d80089a38d7a9b3464c66237d4d2d23331ebd5\n'}, {'number': 2, 'created': '2014-10-10 18:59:49.000000000', 'files': ['swift/obj/server.py', 'test/unit/obj/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/7c1c8c0b4d36ec1795c11950652fa42564352264', 'message': 'Ssync does not replicate custom object headers\n\nCloses-Bug: #1329093\n\nChange-Id: Ie9d80089a38d7a9b3464c66237d4d2d23331ebd5\n'}]",1,127033,7c1c8c0b4d36ec1795c11950652fa42564352264,14,6,2,995,,,0,"Ssync does not replicate custom object headers

Closes-Bug: #1329093

Change-Id: Ie9d80089a38d7a9b3464c66237d4d2d23331ebd5
",git fetch https://review.opendev.org/openstack/swift refs/changes/33/127033/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/server.py', 'test/unit/obj/test_server.py']",2,085cbda0b4a514904d43993030795159c5854dad,bug/1329093," 'Content-Type': 'application/octet-stream', 'x-object-meta-test': 'one', 'Custom-Header': '*', 'X-Backend-Replication-Headers': 'Content-Type Content-Length'}) try: was_allowed_headers = self.object_controller self.object_controller.allowed_headers = ['Custom-Header'] resp = req.get_response(self.object_controller) finally: self.object_controller.allowed_headers = was_allowed_headers 'name': '/a/c/o', 'X-Object-Meta-Test': 'one', 'Custom-Header': '*'})", 'Content-Type': 'application/octet-stream'}) resp = req.get_response(self.object_controller) 'name': '/a/c/o'}),18,6
openstack%2Fcinder~master~I9cc3ffb2f36b65876b05ecb9f4654461be4516b7,openstack/cinder,master,I9cc3ffb2f36b65876b05ecb9f4654461be4516b7,"Fix unnecessary snap of glance image, with non-raw images",MERGED,2014-10-08 18:10:14.000000000,2014-10-17 02:24:51.000000000,2014-10-17 02:24:50.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9067}, {'_account_id': 10622}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12369}]","[{'number': 1, 'created': '2014-10-08 18:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/99db5322b81cc8921151b055da4e2fef005230f1', 'message': ""Fix unnecessary snap of glance image, with non-raw images\n\nWhen the glance image format is not raw, the glance image stored on\nGPFS should not be snapped. Because, we copy the image to cinder volume\nrepository converting the image format to 'raw'. So, no copy_on_write\nis supported.\n\nChange-Id: I9cc3ffb2f36b65876b05ecb9f4654461be4516b7\nCloses-Bug: #1378964\n""}, {'number': 2, 'created': '2014-10-14 07:10:08.000000000', 'files': ['cinder/volume/drivers/ibm/gpfs.py', 'cinder/tests/test_gpfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9710357f246e670bd3cacb153cae245941362c54', 'message': ""Fix unnecessary snap of glance image, with non-raw images\n\nWhen the glance image format is not raw, the glance image stored on\nGPFS should not be snapped. Because, we copy the image to cinder volume\nrepository converting the image format to 'raw'. So, no copy_on_write\nis supported.\n\nChange-Id: I9cc3ffb2f36b65876b05ecb9f4654461be4516b7\nCloses-Bug: #1378964\n""}]",2,126962,9710357f246e670bd3cacb153cae245941362c54,22,11,2,9067,,,0,"Fix unnecessary snap of glance image, with non-raw images

When the glance image format is not raw, the glance image stored on
GPFS should not be snapped. Because, we copy the image to cinder volume
repository converting the image format to 'raw'. So, no copy_on_write
is supported.

Change-Id: I9cc3ffb2f36b65876b05ecb9f4654461be4516b7
Closes-Bug: #1378964
",git fetch https://review.opendev.org/openstack/cinder refs/changes/62/126962/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/ibm/gpfs.py'],1,99db5322b81cc8921151b055da4e2fef005230f1,bug/1378964, # if the image is not already a GPFS snap file make it so if not self._is_gpfs_parent_file(image_path): self._create_gpfs_snap(image_path) , # if the image is not already a GPFS snap file make it so if not self._is_gpfs_parent_file(image_path): self._create_gpfs_snap(image_path),4,3
openstack%2Fpuppet-cinder~master~I54eceeb366a7ccd7e78b382fcb8830106f9153d3,openstack/puppet-cinder,master,I54eceeb366a7ccd7e78b382fcb8830106f9153d3,correct package name for cinder backup,MERGED,2014-10-14 09:46:57.000000000,2014-10-17 02:11:30.000000000,2014-10-17 02:11:30.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7156}, {'_account_id': 8123}, {'_account_id': 10540}, {'_account_id': 12747}]","[{'number': 1, 'created': '2014-10-14 09:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/9017ed1c6a58f7cfbc521d03b3857e70200d4de8', 'message': 'correct package name for cinder backup\n\nthe default backup_driver was mistyped and could not be loaded\n\nChange-Id: I54eceeb366a7ccd7e78b382fcb8830106f9153d3\nCloses-Bug: 1380716\n'}, {'number': 2, 'created': '2014-10-14 10:16:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/b486f0a97f1fe08f715f85b69209ded77e0ff6e0', 'message': 'correct package name for cinder backup\n\nthe default backup_driver was mistyped and could not be loaded\n\nChange-Id: I54eceeb366a7ccd7e78b382fcb8830106f9153d3\nCloses-Bug: 1380716\n'}, {'number': 3, 'created': '2014-10-15 08:35:10.000000000', 'files': ['manifests/backup/ceph.pp', 'spec/classes/cinder_backup_ceph_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/2a09e402eed1aba46c3734a2d7fadd3e78733368', 'message': 'correct package name for cinder backup\n\nthe default backup_driver was mistyped and could not be loaded\n\nChange-Id: I54eceeb366a7ccd7e78b382fcb8830106f9153d3\nCloses-Bug: 1380716\n'}]",1,128223,2a09e402eed1aba46c3734a2d7fadd3e78733368,15,6,3,8123,,,0,"correct package name for cinder backup

the default backup_driver was mistyped and could not be loaded

Change-Id: I54eceeb366a7ccd7e78b382fcb8830106f9153d3
Closes-Bug: 1380716
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/23/128223/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/backup/ceph.pp'],1,9017ed1c6a58f7cfbc521d03b3857e70200d4de8,bug/1380716," $backup_driver = 'cinder.backup.drivers.ceph',"," $backup_driver = 'cinder.backup.driver.ceph',",1,1
openstack%2Fnova-specs~master~I1efc9743850653322bef03fb5ccf2699cc05b262,openstack/nova-specs,master,I1efc9743850653322bef03fb5ccf2699cc05b262,add specs of thunder-boost,ABANDONED,2014-10-16 08:09:05.000000000,2014-10-17 02:00:24.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}]","[{'number': 1, 'created': '2014-10-16 08:09:05.000000000', 'files': ['doc/source/index.rst', 'specs/kilo/thunder-boost.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/40217428ef1480e85c70bd82590b8c14e526b344', 'message': 'add specs of thunder-boost\n\nChange-Id: I1efc9743850653322bef03fb5ccf2699cc05b262\nImplements: blueprint thunder-boost\n'}]",0,128845,40217428ef1480e85c70bd82590b8c14e526b344,4,2,1,13437,,,0,"add specs of thunder-boost

Change-Id: I1efc9743850653322bef03fb5ccf2699cc05b262
Implements: blueprint thunder-boost
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/45/128845/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'specs/kilo/thunder-boost.rst']",2,40217428ef1480e85c70bd82590b8c14e526b344,bp/thunder-boost,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================================================= A Lightweight Proposal for Fast Booting Many Homogeneous Virtual Machines ========================================================================= https://blueprints.launchpad.net/nova/+spec/thunder-boost Nova supports to boot virtual machines (VMs) atop the Cinder volumes. However, in the current implementation (version j), booting up a large number of homogeneous VMs is time-consuming. To overcome this drawback, we propose a lightweight patch for Nova, which adopts a third-party library, called VMThunder, for fast booting homogeneous VMs. VMThunder accelerates the booting process through on-demand data transfer in a P2P manner. Problem description =================== Currently, Openstack provides two categories of methods for booting a virtual machine: (i) booting from a local image or (ii) booting from a remote Cinder volume. The first category needs to copy the entire image to a compute node, making it suffer from a long transfer delay for large images. The second category remotely attaches a volume to a VM and transfers only the necessary data from the volume, thus having better performance. However, this approach only allows booting a single VM from a volume at a time. Moreover, preparing a volume for each VM requires a long time. As a result, it is currently inevitable to take a long time for booting a large number of homogeneous VMs in Openstack. Proposed change =============== We propose to add a new method, named ""Boot from VMThunder"", for fast booting multiple homogeneous VMs. This method uses a third-party library (VMThunder) to support simultaneous booting of a large number of VMs. VMThunder configures each VM with two volumes (the figure can be found here http://www.kylinx.com/vmthunder/vmthunder.png): a (read-only) template volume exactly the same as the pre-created original volume and a (writable) snapshot volume storing each VM's difference to the template. The original volume is the root of a template volume relay tree, and each VM fetches only the necessary data from its parent over the multi-path iSCSI protocol. In addition, VMThunder makes use of a compute node's local storage as a cache to accelerate the image transferring process and avoid a repetitive data transfer. The P2P-style, on-demand data transfer dramatically accelerates VMs' booting process. Our modification to Nova is light-weighted (about 80 lines of insertions and deletions). Two major functions, i.e., the creation and deletion of the template and snapshot volumes, are implemented as following: (i) creation: We add a volume-driver class (about 50 lines, depends on VMThunder's API) in file ""nova/virt/block_device.py"" to prepare the template and snapshot volumes. (ii) deletion: We add a delete method (about 20 lines, depends on VMThunder's API) in file ""nova/compute/manager.py' to destroy the unused template and snapshot volumes. More details of the implementation can be found in the following links: Paper, http://www.computer.org/csdl/trans/td/preprint/06719385.pdf Modification diff file, http://www.kylinx.com/vmthunder/diff2.txt VMThunder demo videos, http://www.kylinx.com/vmthunder/boot_vmthunder_win7_success-V2.mp4 Image booting demo videos, http://www.kylinx.com/vmthunder/boot_image_test_win7_success-V2.mp4 Alternatives ------------ (1)Image cache: Nova's image-caching facility reduces the start-up time for creating homogeneous virtual machines on one nova-compute node. However, it helps neither the first-time provisioning nor the Cinder-based booting process. (2)P2P transferring: The P2P protocol can increase the speed of the file distribution. For example, the glance-bittorrent-delivery proposal transfers the image templates from the glance storage to Nova-compute servers. This approach, however, needs to transfer the entire image to all peers. (3)Backend storage optimization: The distributed storages like NFS, cluster FS, distributed FS or SAN can decrease the size of transferred volumes. However, the I/O pressure on the storage servers increases dramatically when powering on a large number of homogeneous VMs, since there may not be enough replicas on the storage servers for offloading the I/O demands. (4)Multi-attach volume: (https://wiki.openstack.org/wiki/Cinder/blueprints/multi-attach-volume) This approach allows a volume to be attached to more than one instance simultaneously. As a result, volumes can be shared among multiple guests when the instances are already available. Besides, these volumes can also be used for booting a number of VMs by enforcing the multi-attach volumes as read-only image disks. Unfortunately, this approach does not scale well because of the star-structured topology in the data dissemination process. (5)Direct image access: (https://blueprints.launchpad.net/nova/+spec/nova-image-zero-copy). This approach uses the direct_url of the Glance v2 API, such that the number of needed hops to transfer an image to a Nova-compute node is decreased. When images are stored at multiple backend locations, the Nova-compute servers can select a proper image storage for speeding up the downloading process. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ We will significantly decrease the delay of booting up large numbers of Cinder-volume-based VMs. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: vmThunderGroup (vmthunder) Work Items ---------- We only add one lightweight patch for Nova. Dependencies ============ The patch depends on the VMThunder project (https://launchpad.net/VMThunder). Testing ======= We will add necessary tests into nova's test framework, in order to show the effectiveness of VMThunder. The unit tests and integrated tests will be added to the component. Documentation Impact ==================== We need to document how to create many homogeneous virtual machines though our new option. References ========== VMThunder: http://www.VMThunder.org/ Mailing list: http://lists.openstack.org/pipermail/openstack-dev/2014-April/032883.html VMThunder Publication:http://www.VMThunder.org/blog/2014/03/02/publication/ ",,197,0
openstack%2Fnova-specs~master~I27198ee2b5a425d5fd343614cc5ea1cd57e121df,openstack/nova-specs,master,I27198ee2b5a425d5fd343614cc5ea1cd57e121df,add specs of thunder-boost,ABANDONED,2014-10-17 00:21:47.000000000,2014-10-17 02:00:17.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-10-17 00:21:47.000000000', 'files': ['specs/kilo/approved/thunder-boost.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/659fd6e9b6f2ac46d41dfdea5a22fe306d185e4f', 'message': 'add specs of thunder-boost\n\nChange-Id: I27198ee2b5a425d5fd343614cc5ea1cd57e121df\nImplements: blueprint thunder-boost\n'}]",0,129093,659fd6e9b6f2ac46d41dfdea5a22fe306d185e4f,3,1,1,13437,,,0,"add specs of thunder-boost

Change-Id: I27198ee2b5a425d5fd343614cc5ea1cd57e121df
Implements: blueprint thunder-boost
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/93/129093/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/thunder-boost.rst'],1,659fd6e9b6f2ac46d41dfdea5a22fe306d185e4f,bp/thunder-boost,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================================================= A Lightweight Proposal for Fast Booting Many Homogeneous Virtual Machines ========================================================================= https://blueprints.launchpad.net/nova/+spec/thunder-boost Nova supports to boot virtual machines (VMs) atop the Cinder volumes. However, in the current implementation (version j), booting up a large number of homogeneous VMs is time-consuming. To overcome this drawback, we propose a lightweight patch for Nova, which adopts a third-party library, called VMThunder, for fast booting homogeneous VMs. VMThunder accelerates the booting process through on-demand data transfer in a P2P manner. Problem description =================== Currently, Openstack provides two categories of methods for booting a virtual machine: (i) booting from a local image or (ii) booting from a remote Cinder volume. The first category needs to copy the entire image to a compute node, making it suffer from a long transfer delay for large images. The second category remotely attaches a volume to a VM and transfers only the necessary data from the volume, thus having better performance. However, this approach only allows booting a single VM from a volume at a time. Moreover, preparing a volume for each VM requires a long time. As a result, it is currently inevitable to take a long time for booting a large number of homogeneous VMs in Openstack. Proposed change =============== We propose to add a new method, named ""Boot from VMThunder"", for fast booting multiple homogeneous VMs. This method uses a third-party library (VMThunder) to support simultaneous booting of a large number of VMs. VMThunder configures each VM with two volumes (the figure can be found here http://www.kylinx.com/vmthunder/vmthunder.png): a (read-only) template volume exactly the same as the pre-created original volume and a (writable) snapshot volume storing each VM's difference to the template. The original volume is the root of a template volume relay tree, and each VM fetches only the necessary data from its parent over the multi-path iSCSI protocol. In addition, VMThunder makes use of a compute node's local storage as a cache to accelerate the image transferring process and avoid a repetitive data transfer. The P2P-style, on-demand data transfer dramatically accelerates VMs' booting process. Our modification to Nova is light-weighted (about 80 lines of insertions and deletions). Two major functions, i.e., the creation and deletion of the template and snapshot volumes, are implemented as following: (i) creation: We add a volume-driver class (about 50 lines, depends on VMThunder's API) in file ""nova/virt/block_device.py"" to prepare the template and snapshot volumes. (ii) deletion: We add a delete method (about 20 lines, depends on VMThunder's API) in file ""nova/compute/manager.py' to destroy the unused template and snapshot volumes. More details of the implementation can be found in the following links: Paper, http://www.computer.org/csdl/trans/td/preprint/06719385.pdf Modification diff file, http://www.kylinx.com/vmthunder/diff2.txt VMThunder demo videos, http://www.kylinx.com/vmthunder/boot_vmthunder_win7_success-V2.mp4 Image booting demo videos, http://www.kylinx.com/vmthunder/boot_image_test_win7_success-V2.mp4 Alternatives ------------ (1)Image cache: Nova's image-caching facility reduces the start-up time for creating homogeneous virtual machines on one nova-compute node. However, it helps neither the first-time provisioning nor the Cinder-based booting process. (2)P2P transferring: The P2P protocol can increase the speed of the file distribution. For example, the glance-bittorrent-delivery proposal transfers the image templates from the glance storage to Nova-compute servers. This approach, however, needs to transfer the entire image to all peers. (3)Backend storage optimization: The distributed storages like NFS, cluster FS, distributed FS or SAN can decrease the size of transferred volumes. However, the I/O pressure on the storage servers increases dramatically when powering on a large number of homogeneous VMs, since there may not be enough replicas on the storage servers for offloading the I/O demands. (4)Multi-attach volume: (https://wiki.openstack.org/wiki/Cinder/blueprints/multi-attach-volume) This approach allows a volume to be attached to more than one instance simultaneously. As a result, volumes can be shared among multiple guests when the instances are already available. Besides, these volumes can also be used for booting a number of VMs by enforcing the multi-attach volumes as read-only image disks. Unfortunately, this approach does not scale well because of the star-structured topology in the data dissemination process. (5)Direct image access: (https://blueprints.launchpad.net/nova/+spec/nova-image-zero-copy). This approach uses the direct_url of the Glance v2 API, such that the number of needed hops to transfer an image to a Nova-compute node is decreased. When images are stored at multiple backend locations, the Nova-compute servers can select a proper image storage for speeding up the downloading process. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ We will significantly decrease the delay of booting up large numbers of Cinder-volume-based VMs. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: vmThunderGroup (vmthunder) Work Items ---------- We only add one lightweight patch for Nova. Dependencies ============ The patch depends on the VMThunder project (https://launchpad.net/VMThunder). Testing ======= We will add necessary tests into nova's test framework, in order to show the effectiveness of VMThunder. The unit tests and integrated tests will be added to the component. Documentation Impact ==================== We need to document how to create many homogeneous virtual machines though our new option. References ========== VMThunder: http://www.VMThunder.org/ Mailing list: http://lists.openstack.org/pipermail/openstack-dev/2014-April/032883.html VMThunder Publication:http://www.VMThunder.org/blog/2014/03/02/publication/ ",,189,0
openstack%2Ftrove~master~I2ea9a53311b3a7a82bac016bea14ec1f52471ab7,openstack/trove,master,I2ea9a53311b3a7a82bac016bea14ec1f52471ab7,Update config.template for Cassandra 2.1.0,MERGED,2014-10-02 23:03:55.000000000,2014-10-17 01:27:13.000000000,2014-10-17 01:27:13.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-10-02 23:03:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7876d4b0911032a6f930a1ff641179a6333c920e', 'message': ""Update config.template for Cassandra 2.1.0\n\nthe latest cassandra has removed support for various parameters,\nincluding (but not limited to): multithreaded_compaction,\nmemtable_flush_queue_size, preheat_kernel_page_cache,\nin_memory_compaction_limit_in_mb, and compaction_preheat_key_cache.\nthis patch updates config.template to be the default that's\nincluded as a part of a 2.1.0 install.\n\nChange-Id: I2ea9a53311b3a7a82bac016bea14ec1f52471ab7\nCloses-Bug: #1376951\n""}, {'number': 2, 'created': '2014-10-03 21:18:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8c6ee5e5a1857ca6499aefa4aaa59672e55ba591', 'message': ""Update config.template for Cassandra 2.1.0\n\nthe latest cassandra has removed support for various parameters,\nincluding (but not limited to): multithreaded_compaction,\nmemtable_flush_queue_size, preheat_kernel_page_cache,\nin_memory_compaction_limit_in_mb, and compaction_preheat_key_cache.\nthis patch updates config.template to be the default that's\nincluded as a part of a 2.1.0 install.\n\nChange-Id: I2ea9a53311b3a7a82bac016bea14ec1f52471ab7\nCloses-Bug: #1376951\n""}, {'number': 3, 'created': '2014-10-07 01:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7b47587bab28f1db06c04e78238b9e5c0a0e71f7', 'message': ""Update config.template for Cassandra 2.1.0\n\nthe latest cassandra has removed support for various parameters,\nincluding (but not limited to): multithreaded_compaction,\nmemtable_flush_queue_size, preheat_kernel_page_cache,\nin_memory_compaction_limit_in_mb, and compaction_preheat_key_cache.\nthis patch updates config.template to be the default that's\nincluded as a part of a 2.1.0 install.\n\nChange-Id: I2ea9a53311b3a7a82bac016bea14ec1f52471ab7\nCloses-Bug: #1376951\n""}, {'number': 4, 'created': '2014-10-14 17:48:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/87231d176a0eeb611192f870c5004e8854a9d8e8', 'message': ""Update config.template for Cassandra 2.1.0\n\nthe latest cassandra has removed support for various parameters,\nincluding (but not limited to): multithreaded_compaction,\nmemtable_flush_queue_size, preheat_kernel_page_cache,\nin_memory_compaction_limit_in_mb, and compaction_preheat_key_cache.\nthis patch updates config.template to be the default that's\nincluded as a part of a 2.1.0 install.\n\nChange-Id: I2ea9a53311b3a7a82bac016bea14ec1f52471ab7\nCloses-Bug: #1376951\n""}, {'number': 5, 'created': '2014-10-14 23:39:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e063bc223876ecfa59fefb3c0e7a4751e75fea17', 'message': ""Update config.template for Cassandra 2.1.0\n\nthe latest cassandra has removed support for various parameters,\nincluding (but not limited to): multithreaded_compaction,\nmemtable_flush_queue_size, preheat_kernel_page_cache,\nin_memory_compaction_limit_in_mb, and compaction_preheat_key_cache.\nthis patch updates config.template to be the default that's\nincluded as a part of a 2.1.0 install.\n\nChange-Id: I2ea9a53311b3a7a82bac016bea14ec1f52471ab7\nCloses-Bug: #1376951\n""}, {'number': 6, 'created': '2014-10-15 19:01:49.000000000', 'files': ['trove/templates/cassandra/config.template', 'trove/guestagent/datastore/cassandra/service.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/d613726cb8b963a8d25775cb54ca224088a09fe5', 'message': ""Update config.template for Cassandra 2.1.0\n\nthe latest cassandra has removed support for various parameters,\nincluding (but not limited to): multithreaded_compaction,\nmemtable_flush_queue_size, preheat_kernel_page_cache,\nin_memory_compaction_limit_in_mb, and compaction_preheat_key_cache.\nthis patch updates config.template to be the default that's\nincluded as a part of a 2.1.0 install.\n\nChange-Id: I2ea9a53311b3a7a82bac016bea14ec1f52471ab7\nCloses-Bug: #1376951\n""}]",4,125812,d613726cb8b963a8d25775cb54ca224088a09fe5,47,7,6,8214,,,0,"Update config.template for Cassandra 2.1.0

the latest cassandra has removed support for various parameters,
including (but not limited to): multithreaded_compaction,
memtable_flush_queue_size, preheat_kernel_page_cache,
in_memory_compaction_limit_in_mb, and compaction_preheat_key_cache.
this patch updates config.template to be the default that's
included as a part of a 2.1.0 install.

Change-Id: I2ea9a53311b3a7a82bac016bea14ec1f52471ab7
Closes-Bug: #1376951
",git fetch https://review.opendev.org/openstack/trove refs/changes/12/125812/4 && git format-patch -1 --stdout FETCH_HEAD,['trove/templates/cassandra/config.template'],1,7876d4b0911032a6f930a1ff641179a6333c920e,bug/1376951,"# Cassandra storage config YAML # NOTE: # See http://wiki.apache.org/cassandra/StorageConfiguration for # full explanations of configuration directives # /NOTE # The name of the cluster. This is mainly used to prevent machines in # one logical cluster from joining another. # This defines the number of tokens randomly assigned to this node on the ring # The more tokens, relative to other nodes, the larger the proportion of data # that this node will store. You probably want all nodes to have the same number # of tokens assuming they have equal hardware capability. # # If you leave this unspecified, Cassandra will use the default of 1 token for legacy compatibility, # and will use the initial_token as described below. # # Specifying initial_token will override this setting on the node's initial start, # on subsequent starts, this setting will apply even if initial token is set. # # If you already have a cluster with 1 token per node, and wish to migrate to # multiple tokens per node, see http://wiki.apache.org/cassandra/Operations # initial_token allows you to specify tokens manually. While you can use # it with # vnodes (num_tokens > 1, above) -- in which case you should provide a # comma-separated list -- it's primarily used when adding nodes # to legacy clusters # that do not have vnodes enabled. # initial_token: # See http://wiki.apache.org/cassandra/HintedHandoff # May either be ""true"" or ""false"" to enable globally, or contain a list # of data centers to enable per-datacenter. # hinted_handoff_enabled: DC1,DC2# this defines the maximum amount of time a dead host will have hints # generated. After it has been dead this long, new hints for it will not be # created until it has been seen alive and gone down again.# Maximum throttle in KBs per second, per delivery thread. This will be # reduced proportionally to the number of nodes in the cluster. (If there # are two nodes in the cluster, each delivery thread will use the maximum # rate; if there are three, each will throttle to half of the maximum, # since we expect two nodes to be delivering hints simultaneously.)# Number of threads with which to deliver hints; # Consider increasing this number when you have multi-dc deployments, since # cross-dc handoff tends to be slower # Maximum throttle in KBs per second, total. This will be # reduced proportionally to the number of nodes in the cluster. batchlog_replay_throttle_in_kb: 1024 # Authentication backend, implementing IAuthenticator; used to identify users # Out of the box, Cassandra provides org.apache.cassandra.auth.{AllowAllAuthenticator, # PasswordAuthenticator}. # # - AllowAllAuthenticator performs no checks - set it to disable authentication. # - PasswordAuthenticator relies on username/password pairs to authenticate # users. It keeps usernames and hashed passwords in system_auth.credentials table. # Please increase system_auth keyspace replication factor if you use this authenticator. # Authorization backend, implementing IAuthorizer; used to limit access/provide permissions # Out of the box, Cassandra provides org.apache.cassandra.auth.{AllowAllAuthorizer, # CassandraAuthorizer}. # # - AllowAllAuthorizer allows any action to any user - set it to disable authorization. # - CassandraAuthorizer stores permissions in system_auth.permissions table. Please # increase system_auth keyspace replication factor if you use this authorizer. # Validity period for permissions cache (fetching permissions can be an # expensive operation depending on the authorizer, CassandraAuthorizer is # one example). Defaults to 2000, set to 0 to disable. # Will be disabled automatically for AllowAllAuthorizer. # The partitioner is responsible for distributing groups of rows (by # partition key) across nodes in the cluster. You should leave this # alone for new clusters. The partitioner can NOT be changed without # reloading all data, so when upgrading you should set this to the # same partitioner you were already using. # # Besides Murmur3Partitioner, partitioners included for backwards # compatibility include RandomPartitioner, ByteOrderedPartitioner, and # OrderPreservingPartitioner. # # Directories where Cassandra should store data on disk. Cassandra # will spread data evenly across them, subject to the granularity of # the configured compaction strategy. # If not set, the default directory is $CASSANDRA_HOME/data/data. # commit log. when running on magnetic HDD, this should be a # separate spindle than the data directories. # If not set, the default directory is $CASSANDRA_HOME/data/commitlog. # policy for data disk failures: # stop_paranoid: shut down gossip and Thrift even for single-sstable errors. # stop: shut down gossip and Thrift, leaving the node effectively dead, but # can still be inspected via JMX. # best_effort: stop using the failed disk and respond to requests based on # remaining available sstables. This means you WILL see obsolete # data at CL.ONE! # ignore: ignore fatal errors and let requests fail, as in pre-1.2 Cassandra # policy for commit disk failures: # stop: shut down gossip and Thrift, leaving the node effectively dead, but # can still be inspected via JMX. # stop_commit: shutdown the commit log, letting writes collect but # continuing to service reads, as in pre-2.0.5 Cassandra # ignore: ignore fatal errors and let the batches fail commit_failure_policy: stop # Maximum size of the key cache in memory. # # Each key cache hit saves 1 seek and each row cache hit saves 2 seeks at the # minimum, sometimes more. The key cache is fairly tiny for the amount of # time it saves, so it's worthwhile to use it at large numbers. # The row cache saves even more time, but must contain the entire row, # so it is extremely space-intensive. It's best to only use the # row cache if you have hot rows or static rows. # # NOTE: if you reduce the size, you may not get you hottest keys loaded on startup. # # Default value is empty to make it ""auto"" (min(5% of Heap (in MB), 100MB)). Set to 0 to disable key cache. key_cache_size_in_mb: # Duration in seconds after which Cassandra should # save the key cache. Caches are saved to saved_caches_directory as # specified in this configuration file. # # Saved caches greatly improve cold-start speeds, and is relatively cheap in # terms of I/O for the key cache. Row cache saving is much more expensive and # has limited use. # # Default is 14400 or 4 hours. # Number of keys from the key cache to save # Disabled by default, meaning all keys are going to be saved # key_cache_keys_to_save: 100 # Maximum size of the row cache in memory. # NOTE: if you reduce the size, you may not get you hottest keys loaded on startup. # # Default value is 0, to disable row caching. # Duration in seconds after which Cassandra should # save the row cache. Caches are saved to saved_caches_directory as specified # in this configuration file. # # Saved caches greatly improve cold-start speeds, and is relatively cheap in # terms of I/O for the key cache. Row cache saving is much more expensive and # has limited use. # # Default is 0 to disable saving the row cache. # Number of keys from the row cache to save # Disabled by default, meaning all keys are going to be saved # row_cache_keys_to_save: 100 # Maximum size of the counter cache in memory. # # Counter cache helps to reduce counter locks' contention for hot counter cells. # In case of RF = 1 a counter cache hit will cause Cassandra to skip the read before # write entirely. With RF > 1 a counter cache hit will still help to reduce the duration # of the lock hold, helping with hot counter cell updates, but will not allow skipping # the read entirely. Only the local (clock, count) tuple of a counter cell is kept # in memory, not the whole counter, so it's relatively cheap. # # NOTE: if you reduce the size, you may not get you hottest keys loaded on startup. # # Default value is empty to make it ""auto"" (min(2.5% of Heap (in MB), 50MB)). Set to 0 to disable counter cache. # NOTE: if you perform counter deletes and rely on low gcgs, you should disable the counter cache. counter_cache_size_in_mb: # Duration in seconds after which Cassandra should # save the counter cache (keys only). Caches are saved to saved_caches_directory as # specified in this configuration file. # # Default is 7200 or 2 hours. counter_cache_save_period: 7200 # Number of keys from the counter cache to save # Disabled by default, meaning all keys are going to be saved # counter_cache_keys_to_save: 100 # The off-heap memory allocator. Affects storage engine metadata as # well as caches. Experiments show that JEMAlloc saves some memory # than the native GCC allocator (i.e., JEMalloc is more # fragmentation-resistant). # # Supported values are: NativeAllocator, JEMallocAllocator # # If you intend to use JEMallocAllocator you have to install JEMalloc as library and # modify cassandra-env.sh as directed in the file. # # Defaults to NativeAllocator # memory_allocator: NativeAllocator # saved caches # If not set, the default directory is $CASSANDRA_HOME/data/saved_caches. # commitlog_sync may be either ""periodic"" or ""batch."" # When in batch mode, Cassandra won't ack writes until the commit log # has been fsynced to disk. It will wait up to # commitlog_sync_batch_window_in_ms milliseconds for other writes, before # performing the sync. # # commitlog_sync: batch # commitlog_sync_batch_window_in_ms: 50 # # the other option is ""periodic"" where writes may be acked immediately # and the CommitLog is simply synced every commitlog_sync_period_in_ms # milliseconds. commitlog_periodic_queue_size allows 1024*(CPU cores) pending # entries on the commitlog queue by default. If you are writing very large # blobs, you should reduce that; 16*cores works reasonably well for 1MB blobs. # It should be at least as large as the concurrent_writes setting.# commitlog_periodic_queue_size: # The size of the individual commitlog file segments. A commitlog # segment may be archived, deleted, or recycled once all the data # in it (potentially from each columnfamily in the system) has been # flushed to sstables. # # The default size is 32, which is almost always fine, but if you are # archiving commitlog segments (see commitlog_archiving.properties), # then you probably want a finer granularity of archiving; 8 or 16 MB # is reasonable. # any class that implements the SeedProvider interface and has a # constructor that takes a Map<String, String> of parameters will do. seed_provider: # Addresses of hosts that are deemed contact points. # Cassandra nodes use this list of hosts to find each other and learn # the topology of the ring. You must change this if you are running # multiple nodes! # seeds is actually a comma-delimited list of addresses. # Ex: ""<ip1>,<ip2>,<ip3>"" # For workloads with more data than can fit in memory, Cassandra's # bottleneck will be reads that need to fetch data from # disk. ""concurrent_reads"" should be set to (16 * number_of_drives) in # order to allow the operations to enqueue low enough in the stack # that the OS and drives can reorder them. Same applies to # ""concurrent_counter_writes"", since counter writes read the current # values before incrementing and writing them back. # # On the other hand, since writes are almost never IO bound, the ideal # number of ""concurrent_writes"" is dependent on the number of cores in # your system; (8 * number_of_cores) is a good rule of thumb.concurrent_counter_writes: 32 # Total memory to use for sstable-reading buffers. Defaults to # the smaller of 1/4 of heap or 512MB. # file_cache_size_in_mb: 512 # Total permitted memory to use for memtables. Cassandra will stop # accepting writes when the limit is exceeded until a flush completes, # and will trigger a flush based on memtable_cleanup_threshold # If omitted, Cassandra will set both to 1/4 the size of the heap. # memtable_heap_space_in_mb: 2048 # memtable_offheap_space_in_mb: 2048 # Ratio of occupied non-flushing memtable size to total permitted size # that will trigger a flush of the largest memtable. Lager mct will # mean larger flushes and hence less compaction, but also less concurrent # flush activity which can make it difficult to keep your disks fed # under heavy write load. # # memtable_cleanup_threshold defaults to 1 / (memtable_flush_writers + 1) # memtable_cleanup_threshold: 0.11 # Specify the way Cassandra allocates and manages memtable memory. # Options are: # heap_buffers: on heap nio buffers # offheap_buffers: off heap (direct) nio buffers # offheap_objects: native memory, eliminating nio buffer heap overhead memtable_allocation_type: heap_buffers # Total space to use for commitlogs. Since commitlog segments are # mmapped, and hence use up address space, the default size is 32 # on 32-bit JVMs, and 8192 on 64-bit JVMs. # # If space gets above this value (it will round up to the next nearest # segment multiple), Cassandra will flush every dirty CF in the oldest # segment and remove it. So a small total commitlog space will tend # to cause more flush activity on less-active columnfamilies. # commitlog_total_space_in_mb: 8192 # This sets the amount of memtable flush writer threads. These will # be blocked by disk io, and each one will hold a memtable in memory # while blocked. # # memtable_flush_writers defaults to the smaller of (number of disks, # number of cores), with a minimum of 2 and a maximum of 8. # # If your data directories are backed by SSD, you should increase this # to the number of cores. #memtable_flush_writers: 8 # A fixed memory pool size in MB for for SSTable index summaries. If left # empty, this will default to 5% of the heap size. If the memory usage of # all index summaries exceeds this limit, SSTables with low read rates will # shrink their index summaries in order to meet this limit. However, this # is a best-effort process. In extreme conditions Cassandra may need to use # more than this amount of memory. index_summary_capacity_in_mb: # How frequently index summaries should be resampled. This is done # periodically to redistribute memory from the fixed-size pool to sstables # proportional their recent read rates. Setting to -1 will disable this # process, leaving existing index summaries at their current sampling level. index_summary_resize_interval_in_minutes: 60 # Whether to, when doing sequential writing, fsync() at intervals in # order to force the operating system to flush the dirty # buffers. Enable this to avoid sudden dirty buffer flushing from # impacting read latencies. Almost always a good idea on SSDs; not # necessarily on platters. # TCP port, for commands and data # SSL port, for encrypted communication. Unused unless enabled in # encryption_options # Address to bind to and tell other Cassandra nodes to connect to. You # _must_ change this if you want multiple nodes to be able to # communicate! # # Leaving it blank leaves it up to InetAddress.getLocalHost(). This # will always do the Right Thing _if_ the node is properly configured # (hostname, name resolution, etc), and the Right Thing is to use the # address associated with the hostname (it might not be). # # Setting this to 0.0.0.0 is always wrong. # Address to broadcast to other Cassandra nodes # Leaving this blank will set it to the same value as listen_address # broadcast_address: 1.2.3.4 # Internode authentication backend, implementing IInternodeAuthenticator; # used to allow/disallow connections from peer nodes. # internode_authenticator: org.apache.cassandra.auth.AllowAllInternodeAuthenticator # Whether to start the native transport server. # Please note that the address on which the native transport is bound is the # same as the rpc_address. The port however is different and specified below.# port for the CQL native transport to listen for clients on# The maximum threads for handling requests when the native transport is used. # This is similar to rpc_max_threads though the default differs slightly (and # there is no native_transport_min_threads, idle threads will always be stopped # after 30 seconds). # native_transport_max_threads: 128 # # The maximum size of allowed frame. Frame (requests) larger than this will # be rejected as invalid. The default is 256MB. # native_transport_max_frame_size_in_mb: 256 # Whether to start the thrift rpc server. # The address to bind the Thrift RPC service and native transport # server to. # # Leaving this blank has the same effect as on listen_address # (i.e. it will be based on the configured hostname of the node). # # Note that unlike listen_address, you can specify 0.0.0.0, but you must also # set broadcast_rpc_address to a value other than 0.0.0.0.# port for Thrift to listen for clients on # RPC address to broadcast to drivers and other Cassandra nodes. This cannot # be set to 0.0.0.0. If left blank, this will be set to the value of # rpc_address. If rpc_address is set to 0.0.0.0, broadcast_rpc_address must # be set. # broadcast_rpc_address: 1.2.3.4 # enable or disable keepalive on rpc/native connections # Cassandra provides two out-of-the-box options for the RPC Server: # # sync -> One thread per thrift connection. For a very large number of clients, memory # will be your limiting factor. On a 64 bit JVM, 180KB is the minimum stack size # per thread, and that will correspond to your use of virtual memory (but physical memory # may be limited depending on use of stack space). # # hsha -> Stands for ""half synchronous, half asynchronous."" All thrift clients are handled # asynchronously using a small number of threads that does not vary with the amount # of thrift clients (and thus scales well to many clients). The rpc requests are still # synchronous (one thread per active request). # # The default is sync because on Windows hsha is about 30% slower. On Linux, # sync/hsha performance is about the same, with hsha of course using less memory. # # Alternatively, can provide your own RPC server by providing the fully-qualified class name # of an o.a.c.t.TServerFactory that can create an instance of it. # Uncomment rpc_min|max_thread to set request pool size limits. # # Regardless of your choice of RPC server (see above), the number of maximum requests in the # RPC thread pool dictates how many concurrent requests are possible (but if you are using the sync # RPC server, it also dictates the number of clients that can be connected at all). # # The default is unlimited and thus provides no protection against clients overwhelming the server. You are # encouraged to set a maximum that makes sense for you in production, but do keep in mind that # rpc_max_threads represents the maximum number of client requests this server may execute concurrently. # # rpc_min_threads: 16 # rpc_max_threads: 2048 # uncomment to set socket buffer sizes on rpc connections # rpc_send_buff_size_in_bytes: # rpc_recv_buff_size_in_bytes: # Uncomment to set socket buffer size for internode communication # Note that when setting this, the buffer size is limited by net.core.wmem_max # and when not setting it it is defined by net.ipv4.tcp_wmem # See: # /proc/sys/net/core/wmem_max # /proc/sys/net/core/rmem_max # /proc/sys/net/ipv4/tcp_wmem # /proc/sys/net/ipv4/tcp_wmem # and: man tcp # internode_send_buff_size_in_bytes: # internode_recv_buff_size_in_bytes: # Frame size for thrift (maximum message length). # Set to true to have Cassandra create a hard link to each sstable # flushed or streamed locally in a backups/ subdirectory of the # keyspace data. Removing these links is the operator's # responsibility. # Whether or not to take a snapshot before each compaction. Be # careful using this option, since Cassandra won't clean up the # snapshots for you. Mostly useful if you're paranoid when there # is a data format change. # Whether or not a snapshot is taken of the data before keyspace truncation # or dropping of column families. The STRONGLY advised default of true # should be used to provide data safety. If you set this flag to false, you will # lose data on truncation or drop. # When executing a scan, within or across a partition, we need to keep the # tombstones seen in memory so we can return them to the coordinator, which # will use them to make sure other replicas also know about the deleted rows. # With workloads that generate a lot of tombstones, this can cause performance # problems and even exaust the server heap. # (http://www.datastax.com/dev/blog/cassandra-anti-patterns-queues-and-queue-like-datasets) # Adjust the thresholds here if you understand the dangers and want to # scan more tombstones anyway. These thresholds may also be adjusted at runtime # using the StorageService mbean. # Granularity of the collation index of rows within a partition. # Increase if your rows are large, or if you have a very large # number of rows per partition. The competing goals are these: # 1) a smaller granularity means more index entries are generated # and looking up rows withing the partition by collation column # is faster # 2) but, Cassandra will keep the collation index in memory for hot # rows (as part of the key cache), so a larger granularity means # you can cache more hot rows # Log WARN on any batch size exceeding this value. 5kb per batch by default. # Caution should be taken on increasing the size of this threshold as it can lead to node instability. batch_size_warn_threshold_in_kb: 5 # Number of simultaneous compactions to allow, NOT including # validation ""compactions"" for anti-entropy repair. Simultaneous # compactions can help preserve read performance in a mixed read/write # workload, by mitigating the tendency of small sstables to accumulate # during a single long running compactions. The default is usually # fine and if you experience problems with compaction running too # slowly or too fast, you should look at # compaction_throughput_mb_per_sec first. # # concurrent_compactors defaults to the smaller of (number of disks, # number of cores), with a minimum of 2 and a maximum of 8. # # If your data directories are backed by SSD, you should increase this # to the number of cores. #concurrent_compactors: 1 # Throttles compaction to the given total throughput across the entire # system. The faster you insert data, the faster you need to compact in # order to keep the sstable count down, but in general, setting this to # 16 to 32 times the rate you are inserting data is more than sufficient. # Setting this to 0 disables throttling. Note that this account for all types # of compaction, including validation compaction. # When compacting, the replacement sstable(s) can be opened before they # are completely written, and used in place of the prior sstables for # any range that has been written. This helps to smoothly transfer reads # between the sstables, reducing page cache churn and keeping hot rows hot sstable_preemptive_open_interval_in_mb: 50 # Throttles all outbound streaming file transfers on this node to the # given total throughput in Mbps. This is necessary because Cassandra does # mostly sequential IO when streaming data during bootstrap or repair, which # can lead to saturating the network connection and degrading rpc performance. # When unset, the default is 200 Mbps or 25 MB/s. # stream_throughput_outbound_megabits_per_sec: 200 # Throttles all streaming file transfer between the datacenters, # this setting allows users to throttle inter dc stream throughput in addition # to throttling all network stream traffic as configured with # stream_throughput_outbound_megabits_per_sec # inter_dc_stream_throughput_outbound_megabits_per_sec: # How long the coordinator should wait for read operations to complete# How long the coordinator should wait for seq or index scans to complete# How long the coordinator should wait for writes to complete# How long the coordinator should wait for counter writes to complete counter_write_request_timeout_in_ms: 5000 # How long a coordinator should continue to retry a CAS operation # that contends with other proposals for the same row# How long the coordinator should wait for truncates to complete # (This can be much longer, because unless auto_snapshot is disabled # we need to flush first so we can snapshot before removing the data.)# The default timeout for other, miscellaneous operations # Enable operation timeout information exchange between nodes to accurately # measure request timeouts. If disabled, replicas will assume that requests # were forwarded to them instantly by the coordinator, which means that # under overload conditions we will waste that much extra time processing # already-timed-out requests. # # Warning: before enabling this property make sure to ntp is installed # and the times are synchronized between the nodes. # Enable socket timeout for streaming operation. # When a timeout occurs during streaming, streaming is retried from the start # of the current file. This _can_ involve re-streaming an important amount of # data, so you should avoid setting the value too low. # Default value is 0, which never timeout streams. # streaming_socket_timeout_in_ms: 0 # phi value that must be reached for a host to be marked down. # most users should never need to adjust this. # phi_convict_threshold: 8 # endpoint_snitch -- Set this to a class that implements # IEndpointSnitch. The snitch has two functions: # - it teaches Cassandra enough about your network topology to route # requests efficiently # - it allows Cassandra to spread replicas around your cluster to avoid # correlated failures. It does this by grouping machines into # ""datacenters"" and ""racks."" Cassandra will do its best not to have # more than one replica on the same ""rack"" (which may not actually # be a physical location) # # IF YOU CHANGE THE SNITCH AFTER DATA IS INSERTED INTO THE CLUSTER, # YOU MUST RUN A FULL REPAIR, SINCE THE SNITCH AFFECTS WHERE REPLICAS # ARE PLACED. # # Out of the box, Cassandra provides # - SimpleSnitch: # Treats Strategy order as proximity. This can improve cache # locality when disabling read repair. Only appropriate for # single-datacenter deployments. # - GossipingPropertyFileSnitch # This should be your go-to snitch for production use. The rack # and datacenter for the local node are defined in # cassandra-rackdc.properties and propagated to other nodes via # gossip. If cassandra-topology.properties exists, it is used as a # fallback, allowing migration from the PropertyFileSnitch. # - PropertyFileSnitch: # Proximity is determined by rack and data center, which are # explicitly configured in cassandra-topology.properties. # - Ec2Snitch: # Appropriate for EC2 deployments in a single Region. Loads Region # and Availability Zone information from the EC2 API. The Region is # treated as the datacenter, and the Availability Zone as the rack. # Only private IPs are used, so this will not work across multiple # Regions. # - Ec2MultiRegionSnitch: # Uses public IPs as broadcast_address to allow cross-region # connectivity. (Thus, you should set seed addresses to the public # IP as well.) You will need to open the storage_port or # ssl_storage_port on the public IP firewall. (For intra-Region # traffic, Cassandra will switch to the private IP after # establishing a connection.) # - RackInferringSnitch: # Proximity is determined by rack and data center, which are # assumed to correspond to the 3rd and 2nd octet of each node's IP # address, respectively. Unless this happens to match your # deployment conventions, this is best used as an example of # writing a custom Snitch class and is provided in that spirit. # # You can use a custom Snitch by setting this to the full class name # of the snitch, which will be assumed to be on your classpath. # controls how often to perform the more expensive part of host score # calculation dynamic_snitch_update_interval_in_ms: 100 # controls how often to reset all host scores, allowing a bad host to # possibly recover# if set greater than zero and read_repair_chance is < 1.0, this will allow # 'pinning' of replicas to hosts in order to increase cache capacity. # The badness threshold will control how much worse the pinned host has to be # before the dynamic snitch will prefer other replicas over it. This is # expressed as a double which represents a percentage. Thus, a value of # 0.2 means Cassandra would continue to prefer the static snitch values # until the pinned host was 20% worse than the fastest. # request_scheduler -- Set this to a class that implements # RequestScheduler, which will schedule incoming client requests # according to the specific policy. This is useful for multi-tenancy # with a single Cassandra cluster. # NOTE: This is specifically for requests from the client and does # not affect inter node communication. # org.apache.cassandra.scheduler.NoScheduler - No scheduling takes place # org.apache.cassandra.scheduler.RoundRobinScheduler - Round robin of # client requests to a node with a separate queue for each # request_scheduler_id. The scheduler is further customized by # request_scheduler_options as described below. # Scheduler Options vary based on the type of scheduler # NoScheduler - Has no options # RoundRobin # - throttle_limit -- The throttle_limit is the number of in-flight # requests per client. Requests beyond # that limit are queued up until # running requests can complete. # The value of 80 here is twice the number of # concurrent_reads + concurrent_writes. # - default_weight -- default_weight is optional and allows for # overriding the default which is 1. # - weights -- Weights are optional and will default to 1 or the # overridden default_weight. The weight translates into how # many requests are handled during each turn of the # RoundRobin, based on the scheduler id. # # request_scheduler_options: # throttle_limit: 80 # default_weight: 5 # weights: # Keyspace1: 1 # Keyspace2: 5 # request_scheduler_id -- An identifier based on which to perform # the request scheduling. Currently the only valid option is keyspace. # request_scheduler_id: keyspace # Enable or disable inter-node encryption # Default settings are TLS v1, RSA 1024-bit keys (it is imperative that # users generate their own keys) TLS_RSA_WITH_AES_128_CBC_SHA as the cipher # suite for authentication, key exchange and encryption of the actual data transfers. # Use the DHE/ECDHE ciphers if running in FIPS 140 compliant mode. # NOTE: No custom encryption options are enabled at the moment # The available internode options are : all, none, dc, rack # # If set to dc cassandra will encrypt the traffic between the DCs # If set to rack cassandra will encrypt the traffic between the racks # # The passwords used in these options must match the passwords used when generating # the keystore and truststore. For instructions on generating these files, see: # http://download.oracle.com/javase/6/docs/technotes/guides/security/jsse/JSSERefGuide.html#CreateKeystore # # More advanced defaults below: # protocol: TLS # algorithm: SunX509 # store_type: JKS # cipher_suites: [TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA,TLS_DHE_RSA_WITH_AES_128_CBC_SHA,TLS_DHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA] # require_client_auth: false # enable or disable client/server encryption. # require_client_auth: false # Set trustore and truststore_password if require_client_auth is true # truststore: conf/.truststore # truststore_password: cassandra # More advanced defaults below: # protocol: TLS # algorithm: SunX509 # store_type: JKS # cipher_suites: [TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA,TLS_DHE_RSA_WITH_AES_128_CBC_SHA,TLS_DHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA] # internode_compression controls whether traffic between nodes is # compressed. # can be: all - all traffic is compressed # dc - traffic between different datacenters is compressed # none - nothing is compressed. # Enable or disable tcp_nodelay for inter-dc communication. # Disabling it will result in larger (but fewer) network packets being sent, # reducing overhead from the TCP protocol itself, at the cost of increasing # latency if you block for cross-datacenter responses. ",key_cache_size_in_mb:seed_provider:memtable_flush_queue_size: 4in_memory_compaction_limit_in_mb: 64 multithreaded_compaction: falsecompaction_preheat_key_cache: truedynamic_snitch_update_interval_in_ms: 100preheat_kernel_page_cache: false,682,6
openstack%2Fkolla~master~I766b0e61e247c47b4449c1ed2c204ddb8919a87d,openstack/kolla,master,I766b0e61e247c47b4449c1ed2c204ddb8919a87d,Run nova-api as privileged so it can muck with iptables,MERGED,2014-10-16 21:19:33.000000000,2014-10-17 00:43:37.000000000,2014-10-17 00:43:37.000000000,"[{'_account_id': 3}, {'_account_id': 8745}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-10-16 21:19:33.000000000', 'files': ['k8s/pod/nova-controller-pod.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/b47c6afed0bb39bf4d1c93a40206a8489adb1491', 'message': 'Run nova-api as privileged so it can muck with iptables\n\nNot sure if mucking with iptables is safe, but appears required.\n\nChange-Id: I766b0e61e247c47b4449c1ed2c204ddb8919a87d\n'}]",0,129054,b47c6afed0bb39bf4d1c93a40206a8489adb1491,7,3,1,2834,,,0,"Run nova-api as privileged so it can muck with iptables

Not sure if mucking with iptables is safe, but appears required.

Change-Id: I766b0e61e247c47b4449c1ed2c204ddb8919a87d
",git fetch https://review.opendev.org/openstack/kolla refs/changes/54/129054/1 && git format-patch -1 --stdout FETCH_HEAD,['k8s/pod/nova-controller-pod.yaml'],1,b47c6afed0bb39bf4d1c93a40206a8489adb1491,, privileged: true,,2,0
openstack%2Fkolla~master~I82f61f1c003ef9068a664e2d4cafaab1b5c47a00,openstack/kolla,master,I82f61f1c003ef9068a664e2d4cafaab1b5c47a00,configure nova database connection,MERGED,2014-10-16 21:26:10.000000000,2014-10-17 00:43:19.000000000,2014-10-17 00:43:19.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-10-16 21:26:10.000000000', 'files': ['docker/nova-controller/nova-ctr-base/config-nova-controller.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2d1f3dd9f2416354deebc2fa127bc15763f3b6fa', 'message': 'configure nova database connection\n\nconfig-nova-controller.sh needs to set the nova database connection\nstring.\n\nChange-Id: I82f61f1c003ef9068a664e2d4cafaab1b5c47a00\n'}]",0,129059,2d1f3dd9f2416354deebc2fa127bc15763f3b6fa,8,3,1,8745,,,0,"configure nova database connection

config-nova-controller.sh needs to set the nova database connection
string.

Change-Id: I82f61f1c003ef9068a664e2d4cafaab1b5c47a00
",git fetch https://review.opendev.org/openstack/kolla refs/changes/59/129059/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/nova-controller/nova-ctr-base/config-nova-controller.sh'],1,2d1f3dd9f2416354deebc2fa127bc15763f3b6fa,larsks/fix-nova-controller," NOVA_DB_PASSWORD NEUTRON_SHARED_SECRET# Configure database connection crudini --set $cfg \ database \ connection \ ""mysql://${NOVA_DB_USER}:${NOVA_DB_PASSWORD}@${MARIADB_SERVICE_HOST}/${NOVA_DB_NAME}""", NOVA_DB_PASSWORD NEUTRON_SHARED_SECRET,6,1
openstack%2Fpuppet-horizon~stable%2Ficehouse~I9f1d4f370fcc8e604a249ccb3ec689be0b489315,openstack/puppet-horizon,stable/icehouse,I9f1d4f370fcc8e604a249ccb3ec689be0b489315,Avoid backport mistakes,MERGED,2014-09-05 08:49:30.000000000,2014-10-17 00:26:33.000000000,2014-10-16 22:35:37.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7156}, {'_account_id': 8482}]","[{'number': 1, 'created': '2014-09-05 08:49:30.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/f17dfe554922bd9301f635e32415c94b1cdb6990', 'message': 'Avoid backport mistakes\n\nWith this patch using it will be possible to omit branch in review\ncommand.\n\nChange-Id: I9f1d4f370fcc8e604a249ccb3ec689be0b489315\n'}]",0,119323,f17dfe554922bd9301f635e32415c94b1cdb6990,9,4,1,5241,,,0,"Avoid backport mistakes

With this patch using it will be possible to omit branch in review
command.

Change-Id: I9f1d4f370fcc8e604a249ccb3ec689be0b489315
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/23/119323/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,f17dfe554922bd9301f635e32415c94b1cdb6990,fqdn-divide-icehouse,defaultbranch=stable/icehouse,,1,0
openstack%2Foslo-specs~master~Ia02726a3139d1728c1e8820a0ab9fbfc09753d04,openstack/oslo-specs,master,Ia02726a3139d1728c1e8820a0ab9fbfc09753d04,Support policy configuration directories,MERGED,2014-07-02 11:38:06.000000000,2014-10-17 00:18:44.000000000,2014-07-25 23:03:54.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2218}, {'_account_id': 2472}, {'_account_id': 2903}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-07-02 11:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/f4a6dfabd1e8a0e8d7edca62dfa76593d23b4dd4', 'message': 'Support policy configuration directories\n\nThis spec describes blueprint policy-configuration-directories\n\nChange-Id: Ia02726a3139d1728c1e8820a0ab9fbfc09753d04\n'}, {'number': 2, 'created': '2014-07-02 12:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/8ff214ebb2fad51e35a039a5e7812ddc9cbe2716', 'message': 'Support policy configuration directories\n\nThis spec describes blueprint policy-configuration-directories\n\nChange-Id: Ia02726a3139d1728c1e8820a0ab9fbfc09753d04\n'}, {'number': 3, 'created': '2014-07-03 08:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/bfc2849113078c60934fda715d349ec593014b11', 'message': 'Support policy configuration directories\n\nThis spec describes blueprint policy-configuration-directories\n\nChange-Id: Ia02726a3139d1728c1e8820a0ab9fbfc09753d04\n'}, {'number': 4, 'created': '2014-07-04 02:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/0bb0dfbaad6f30f2ff40a603d311b7aef2045b43', 'message': 'Support policy configuration directories\n\nThis spec describes blueprint policy-configuration-directories\n\nChange-Id: Ia02726a3139d1728c1e8820a0ab9fbfc09753d04\n'}, {'number': 5, 'created': '2014-07-08 02:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/8c03bf7623cc155fe80066b2c451d5b92f9899b4', 'message': 'Support policy configuration directories\n\nThis spec describes blueprint policy-configuration-directories\n\nChange-Id: Ia02726a3139d1728c1e8820a0ab9fbfc09753d04\n'}, {'number': 6, 'created': '2014-07-08 04:21:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/a1d1dfcc09f90d0d352f4fd4fa51cc06c1f5f9d5', 'message': 'Support policy configuration directories\n\nThis spec describes blueprint policy-configuration-directories\n\nChange-Id: Ia02726a3139d1728c1e8820a0ab9fbfc09753d04\n'}, {'number': 7, 'created': '2014-07-08 06:13:29.000000000', 'files': ['specs/juno/policy-configuration-directories.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/ee992eea7ba617029c7e500bdd9e6e369926c059', 'message': 'Support policy configuration directories\n\nThis spec describes blueprint policy-configuration-directories\n\nChange-Id: Ia02726a3139d1728c1e8820a0ab9fbfc09753d04\n'}]",36,104157,ee992eea7ba617029c7e500bdd9e6e369926c059,55,8,7,5754,,,0,"Support policy configuration directories

This spec describes blueprint policy-configuration-directories

Change-Id: Ia02726a3139d1728c1e8820a0ab9fbfc09753d04
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/57/104157/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/policy-configuration-directories.rst'],1,f4a6dfabd1e8a0e8d7edca62dfa76593d23b4dd4,bp/policy-configuration-directories,"============================= Support Policy configuration directories ============================= https://blueprints.launchpad.net/oslo/+spec/policy-configuration-directories This propose to add a way to override the default policy rules. Problem description =================== There some complain about policy configuration is hard to use. So think of there isn't a way to override default policy rule. The only way to modify default policy rule is to edit the policy.conf. This isn't convenient for deployer. Proposed change =============== Proposed to support for policy configuration directories. The policy rules that loaded from policy configuration directories will override the default policy rules from 'policy_file'. Add new configuration option: policy_configuration_directoires = [list of directories] 'policy_configuration_directoires' accept a list of directoires. Those directories will be iterated by order. The files in those directories will be loaded by alphabet order, and the rules will be overrided by that order. The sub-directories will be ignore. Alternatives ------------ None Impact on Existing APIs ----------------------- None Security impact --------------- The policy rules will be loaded from specified directories. If those directories have appropriate permissions, there won't have any security issue. Performance Impact ------------------ This change need iterated a list of directories, that will slow down the init/reload of policy rules. But that won't be an issue. Configuration Impact -------------------- This change introduce new configuration option: policy_definition_path = [list of directories] The default value is 'policy.d'. The option is convenient for deployer change where to store the policy config files. Developer Impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Alex Xu (xuhj@linux.vnet.ibm.com) Milestones ---------- Target Milestone for completion: Juno Work Items ---------- This change only need one single patch. Incubation ========== None Adoption -------- All the openstack projects can utilize this feature. Library ------- None Anticipated API Stabilization ----------------------------- None Documentation Impact ==================== None Dependencies ============ None References ========== https://etherpad.openstack.org/p/juno-nova-devops .. note:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ",,127,0
openstack%2Foslo.log~master~I10240f8af6c42508124659b3ed62c5ab93552953,openstack/oslo.log,master,I10240f8af6c42508124659b3ed62c5ab93552953,Remove audit log level,MERGED,2014-09-30 19:17:38.000000000,2014-10-17 00:16:18.000000000,2014-10-17 00:16:17.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-09-30 19:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/c3a902f0e7c96f6d59b8704f29ca055319af91a3', 'message': 'Remove audit log level\n\nRemove the AUDIT logging level and the method for the log adapter.\n\nbp/remove-context-adapter\n\nChange-Id: I10240f8af6c42508124659b3ed62c5ab93552953\n'}, {'number': 2, 'created': '2014-10-03 19:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/cee773f417b511593eaf75b99b12b9052ecb0033', 'message': 'Remove audit log level\n\nRemove the AUDIT logging level and the method for the log adapter.\n\nbp/remove-context-adapter\n\nChange-Id: I10240f8af6c42508124659b3ed62c5ab93552953\n'}, {'number': 3, 'created': '2014-10-09 19:55:08.000000000', 'files': ['tests/unit/test_log.py', 'oslo/log/log.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/03283c268350b164c45ce44e8c8b87329da96b15', 'message': 'Remove audit log level\n\nRemove the AUDIT logging level and the method for the log adapter.\n\nbp/remove-context-adapter\n\nChange-Id: I10240f8af6c42508124659b3ed62c5ab93552953\n'}]",0,125163,03283c268350b164c45ce44e8c8b87329da96b15,17,5,3,2472,,,0,"Remove audit log level

Remove the AUDIT logging level and the method for the log adapter.

bp/remove-context-adapter

Change-Id: I10240f8af6c42508124659b3ed62c5ab93552953
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/63/125163/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_log.py', 'oslo/log/log.py']",2,c3a902f0e7c96f6d59b8704f29ca055319af91a3,bp/remove-context-adapter,,"# our new audit level # NOTE(jkoelker) Since we synthesized an audit level, make the logging # module aware of it so it acts like other levels. logging.AUDIT = logging.INFO + 1 logging.addLevelName(logging.AUDIT, 'AUDIT') def audit(self, msg, *args, **kwargs): self.log(logging.AUDIT, msg, *args, **kwargs) ",5,18
openstack%2Fproject-config~master~Ib6eb3b833df24acf75d77338f1195344f7c1c125,openstack/project-config,master,Ib6eb3b833df24acf75d77338f1195344f7c1c125,Add tripleo-ansible to #tripleo,MERGED,2014-10-15 18:39:56.000000000,2014-10-17 00:10:18.000000000,2014-10-17 00:10:17.000000000,"[{'_account_id': 3}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6609}]","[{'number': 1, 'created': '2014-10-15 18:39:56.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1bb8bfc97d43737a761d9153da5fa043b22609cd', 'message': 'Add tripleo-ansible to #tripleo\n\nChange-Id: Ib6eb3b833df24acf75d77338f1195344f7c1c125\n'}]",0,128733,1bb8bfc97d43737a761d9153da5fa043b22609cd,8,4,1,6488,,,0,"Add tripleo-ansible to #tripleo

Change-Id: Ib6eb3b833df24acf75d77338f1195344f7c1c125
",git fetch https://review.opendev.org/openstack/project-config refs/changes/33/128733/1 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,1bb8bfc97d43737a761d9153da5fa043b22609cd,, - stackforge/tripleo-ansible,,1,0
openstack%2Fneutron~master~Ie6cefaee812cdf4354eb5b2e0361c46b1a1cffd3,openstack/neutron,master,Ie6cefaee812cdf4354eb5b2e0361c46b1a1cffd3,TEST: Fail on eventlet yield with SQL lock,ABANDONED,2014-10-15 09:28:40.000000000,2014-10-16 23:45:07.000000000,,"[{'_account_id': 3}, {'_account_id': 162}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-15 09:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/019c7d9f8b858e7a577be1687fed8cfcfd3d474a', 'message': 'TEST: Fail on eventlet yield with SQL lock\n\nSee if we can shake out bad functions calling RPC methods\nwhile holding an SQL lock.\n\nChange-Id: Ie6cefaee812cdf4354eb5b2e0361c46b1a1cffd3\n'}, {'number': 2, 'created': '2014-10-15 10:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/43c9fb327b94e11a366f114821b8208f23228d65', 'message': 'TEST: Fail on eventlet yield with SQL lock\n\nSee if we can shake out bad functions calling RPC methods\nwhile holding an SQL lock.\n\nChange-Id: Ie6cefaee812cdf4354eb5b2e0361c46b1a1cffd3\n'}, {'number': 3, 'created': '2014-10-15 23:44:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/066a7ce119d59f43cd1c193c3917a28f209fb284', 'message': 'TEST: Fail on eventlet yield with SQL lock\n\nSee if we can shake out bad functions calling RPC methods\nwhile holding an SQL lock.\n\nChange-Id: Ie6cefaee812cdf4354eb5b2e0361c46b1a1cffd3\n'}, {'number': 4, 'created': '2014-10-16 06:58:48.000000000', 'files': ['neutron/service.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9a98153dafb3d5ce56430eaaa8d2eeb240c30d5b', 'message': 'TEST: Fail on eventlet yield with SQL lock\n\nSee if we can shake out bad functions calling RPC methods\nwhile holding an SQL lock.\n\nChange-Id: Ie6cefaee812cdf4354eb5b2e0361c46b1a1cffd3\n'}]",0,128588,9a98153dafb3d5ce56430eaaa8d2eeb240c30d5b,63,19,4,7787,,,0,"TEST: Fail on eventlet yield with SQL lock

See if we can shake out bad functions calling RPC methods
while holding an SQL lock.

Change-Id: Ie6cefaee812cdf4354eb5b2e0361c46b1a1cffd3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/128588/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/service.py'],1,019c7d9f8b858e7a577be1687fed8cfcfd3d474a,no_rpc_during_lock," from eventlet.hubs import hub from sqlalchemy.orm import query from sqlalchemy.orm import session def check_for_active_sql_locks(): # this is only a rough approximation. a session might have has_lock # marked from a previous query if it lasted through multiple transactions if any([s.is_active for s in session._sessions.values() if getattr(s, 'has_lock', False)]): # clear all has_lock markers in case the Exception triggers more # eventlet switches leading back to here. map(lambda s: setattr(s, 'has_lock', False), session._sessions.values()) raise Exception(""Eventlet tried to switch out of a coroutine with an "" ""SQL lock."") def monkey_patch_sqlalchemy_query_to_register_locks(): oldlockfunc = query.Query.with_lockmode def new_lock_func(qry, mode): # mark the lock on the session the query belongs to setattr(qry.session, 'has_lock', True) return oldlockfunc(qry, mode) query.Query.with_lockmode = new_lock_func def monkey_patch_eventlet_hub_switch_to_trigger_check(): oldswitchfunc = hub.BaseHub.switch def new_switch_func(bhub): check_for_active_sql_locks() return oldswitchfunc(bhub) hub.BaseHub.switch = new_switch_func monkey_patch_eventlet_hub_switch_to_trigger_check() monkey_patch_sqlalchemy_query_to_register_locks()",,41,0
openstack%2Fnova~master~Icd926f34faf4e19286c471cc895f9184228464e4,openstack/nova,master,Icd926f34faf4e19286c471cc895f9184228464e4,Remove instance.obj_load_attr,ABANDONED,2014-10-16 17:34:31.000000000,2014-10-16 23:26:59.000000000,,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-16 17:34:31.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d381ecb85826169e8e7454a0467cccf64ab02cc0', 'message': ""Remove instance.obj_load_attr\n\nThere are some references in nova/compute/manager.py\nfor instance.obj_load_attr. It's not clear and not comply\nwith other code we have. Leave it in objects scope might\nbe better for debug and code review.\n\nChange-Id: Icd926f34faf4e19286c471cc895f9184228464e4\n""}]",0,129004,d381ecb85826169e8e7454a0467cccf64ab02cc0,10,7,1,6062,,,0,"Remove instance.obj_load_attr

There are some references in nova/compute/manager.py
for instance.obj_load_attr. It's not clear and not comply
with other code we have. Leave it in objects scope might
be better for debug and code review.

Change-Id: Icd926f34faf4e19286c471cc895f9184228464e4
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/129004/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,d381ecb85826169e8e7454a0467cccf64ab02cc0,remove_obj_load_attr," context, self.host, expected_attrs=['info_cache', 'metadata', 'system_metadata'])"," instance.obj_load_attr('metadata') instance.obj_load_attr('system_metadata') context, self.host, expected_attrs=['info_cache'])",2,3
openstack%2Foslo.log~master~I5a96d55355bf4ef68f2ee71160a3e0200c371e87,openstack/oslo.log,master,I5a96d55355bf4ef68f2ee71160a3e0200c371e87,Switch from ContextAdapter to ContextFormatter,MERGED,2014-09-30 19:17:38.000000000,2014-10-16 22:54:28.000000000,2014-10-16 22:54:27.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-09-30 19:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/66f6c3a63c00f70309f4e85cfaa20d84e7474861', 'message': 'Switch from ContextAdapter to ContextFormatter\n\nRemove the ContextAdapter and update getLogger to return\nKeywordArgumentAdapter instances instead.\n\nUpdate the JSONFormatter to do some context magic like the\nContextFormatter does so the extra properties from the context and the\nKeywordArgumentAdapter are included in the output JSON package.\n\nUpdate the ContextFormatter to include some nova-specific behavior that\nwas in ContextAdapter. We will replace that with changes to the way the\ndefault log format strings are constructed in a later patch.\n\nbp/remove-context-adapter\n\nChange-Id: I5a96d55355bf4ef68f2ee71160a3e0200c371e87\n'}, {'number': 2, 'created': '2014-10-03 19:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/ca213e0f4a366c6d9db36b4930d08cfd5168cd49', 'message': 'Switch from ContextAdapter to ContextFormatter\n\nRemove the ContextAdapter and update getLogger to return\nKeywordArgumentAdapter instances instead.\n\nUpdate the JSONFormatter to do some context magic like the\nContextFormatter does so the extra properties from the context and the\nKeywordArgumentAdapter are included in the output JSON package.\n\nUpdate the ContextFormatter to include some nova-specific behavior that\nwas in ContextAdapter. We will replace that with changes to the way the\ndefault log format strings are constructed in a later patch.\n\nbp/remove-context-adapter\n\nChange-Id: I5a96d55355bf4ef68f2ee71160a3e0200c371e87\n'}, {'number': 3, 'created': '2014-10-09 19:55:08.000000000', 'files': ['oslo/log/formatters.py', 'tests/unit/test_log.py', 'oslo/log/log.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/1ebed75c1ca7922775f2f750ef6498dac4fe1600', 'message': 'Switch from ContextAdapter to ContextFormatter\n\nRemove the ContextAdapter and update getLogger to return\nKeywordArgumentAdapter instances instead.\n\nUpdate the JSONFormatter to do some context magic like the\nContextFormatter does so the extra properties from the context and the\nKeywordArgumentAdapter are included in the output JSON package.\n\nUpdate the ContextFormatter to include some nova-specific behavior that\nwas in ContextAdapter. We will replace that with changes to the way the\ndefault log format strings are constructed in a later patch.\n\nbp/remove-context-adapter\n\nChange-Id: I5a96d55355bf4ef68f2ee71160a3e0200c371e87\n'}]",3,125162,1ebed75c1ca7922775f2f750ef6498dac4fe1600,18,5,3,2472,,,0,"Switch from ContextAdapter to ContextFormatter

Remove the ContextAdapter and update getLogger to return
KeywordArgumentAdapter instances instead.

Update the JSONFormatter to do some context magic like the
ContextFormatter does so the extra properties from the context and the
KeywordArgumentAdapter are included in the output JSON package.

Update the ContextFormatter to include some nova-specific behavior that
was in ContextAdapter. We will replace that with changes to the way the
default log format strings are constructed in a later patch.

bp/remove-context-adapter

Change-Id: I5a96d55355bf4ef68f2ee71160a3e0200c371e87
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/62/125162/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/log/formatters.py', 'tests/unit/test_log.py', 'oslo/log/log.py']",3,66f6c3a63c00f70309f4e85cfaa20d84e7474861,bp/remove-context-adapter," # NOTE(dhellmann): The gap between when the adapter is called # and when the formatter needs to know what the extra values # are is large enough that we can't get back to the original # extra dictionary easily. We leave a hint to ourselves here # in the form of a list of keys, which will eventually be # attributes of the LogRecord processed by the formatter. That # allows the formatter to know which values were original and # which were extra, so it can treat them differently (see # JSONFormatter for an example of this). We sort the keys so # it is possible to write sane unit tests. extra['extra_keys'] = list(sorted(extra.keys()))def getLogger(name=None, project='unknown', version='unknown'): """"""Build a logger with the given name. :param name: The name for the logger. This is usually the module name, ``__name__``. :type name: string :param project: The name of the project, to be injected into log messages. For example, ``'nova'``. :type project: string :param version: The version of the project, to be injected into log messages. For example, ``'2014.2'``. :type version: string if name not in _loggers: _loggers[name] = KeywordArgumentAdapter(logging.getLogger(name), {'project': project, 'version': version}) return _loggers[name]","from oslo.log import _localclass LazyAdapter(BaseLoggerAdapter): def __init__(self, name='unknown', version='unknown'): self._logger = None self.extra = {} self.name = name self.version = version @property def logger(self): if not self._logger: self._logger = getLogger(self.name, self.version) if six.PY3: # In Python 3, the code fails because the 'manager' attribute # cannot be found when using a LoggerAdapter as the # underlying logger. Work around this issue. self._logger.manager = self._logger.logger.manager return self._logger class ContextAdapter(BaseLoggerAdapter): warn = logging.LoggerAdapter.warning def __init__(self, logger, project_name, version_string): self.logger = logger self.project = project_name self.version = version_string self._deprecated_messages_sent = dict() @property def handlers(self): return self.logger.handlers def deprecated(self, msg, *args, **kwargs): """"""Call this method when a deprecated feature is used. If the system is configured for fatal deprecations then the message is logged at the 'critical' level and :class:`DeprecatedConfig` will be raised. Otherwise, the message will be logged (once) at the 'warn' level. :raises: :class:`DeprecatedConfig` if the system is configured for fatal deprecations. """""" stdmsg = _(""Deprecated: %s"") % msg if ctx._config.fatal_deprecations: self.critical(stdmsg, *args, **kwargs) raise DeprecatedConfig(msg=stdmsg) # Using a list because a tuple with dict can't be stored in a set. sent_args = self._deprecated_messages_sent.setdefault(msg, list()) if args in sent_args: # Already logged this message, so don't log it again. return sent_args.append(args) self.warn(stdmsg, *args, **kwargs) def process(self, msg, kwargs): # NOTE(jecarey): If msg is not unicode, coerce it into unicode # before it can get to the python logging and # possibly cause string encoding trouble if not isinstance(msg, six.text_type): msg = six.text_type(msg) if 'extra' not in kwargs: kwargs['extra'] = {} extra = kwargs['extra'] context = kwargs.pop('context', None) if not context: context = getattr(_local.store, 'context', None) if context: extra.update(formatters._dictify_context(context)) instance = kwargs.pop('instance', None) instance_uuid = (extra.get('instance_uuid') or kwargs.pop('instance_uuid', None)) instance_extra = '' if instance: instance_extra = ctx._config.instance_format % instance elif instance_uuid: instance_extra = (ctx._config.instance_uuid_format % {'uuid': instance_uuid}) extra['instance'] = instance_extra extra.setdefault('user_identity', kwargs.pop('user_identity', None)) extra['project'] = self.project extra['version'] = self.version extra['extra'] = extra.copy() return msg, kwargs def getLogger(name='unknown', version='unknown'): if name not in _loggers: _loggers[name] = ContextAdapter(logging.getLogger(name), name, version) return _loggers[name] def getLazyLogger(name='unknown', version='unknown'): """"""Returns lazy logger. Creates a pass-through logger that does not create the real logger until it is really needed and delegates all calls to the real logger once it is created. return LazyAdapter(name, version) class DeprecatedConfig(Exception): message = _(""Fatal call to deprecated config: %(msg)s"") def __init__(self, msg): super(Exception, self).__init__(self.message % dict(msg=msg))",151,164
openstack%2Fdevstack~master~Id1e1fe01f05bd0f19ea6e89c4f4c0f8be695dfce,openstack/devstack,master,Id1e1fe01f05bd0f19ea6e89c4f4c0f8be695dfce,Allow multi-line config items in meta-section of local.conf,MERGED,2014-10-16 01:44:07.000000000,2014-10-16 22:51:26.000000000,2014-10-16 22:51:25.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 7118}, {'_account_id': 7787}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-16 01:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/adb950cb1f4b31433710980e9a66dd75e4fb0173', 'message': 'Allow multi-line config items in meta-section of local.conf\n\nIt would behave such as the contents from each meta-section in\nlocal.conf is copied to the destination files. One exception is the multiline\noptions not grouped together. In that case, the contents will be grouped\ntogether in its destination config file.\n\nCheck tests/test_config.sh for examples.\n\nChange-Id: Id1e1fe01f05bd0f19ea6e89c4f4c0f8be695dfce\nPartial-Bug: #1374118\n'}, {'number': 2, 'created': '2014-10-16 01:50:54.000000000', 'files': ['functions-common', 'lib/config', 'tests/test_config.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/751ad1aadf8447c2b6945b6ae4ab73bf71a244ca', 'message': ""Allow multi-line config items in meta-section of local.conf\n\nIt would behave such as the contents from each meta-section in\nlocal.conf is copied to the destination files. One exception is the multiline\noptions not grouped together. In that case, the contents will be grouped\ntogether in its destination config file.\n\nCheck tests/test_config.sh for examples.\n\nThis was originally committed in https://review.openstack.org/128805.\nBut the original change used AWK syntax that is not supported in AWK\n3.1.8, and caused syntax error on servers with that AWK version. This\npatch makes the necessary change so that it's compatible with AWK\n3.1.8.\n\nChange-Id: Id1e1fe01f05bd0f19ea6e89c4f4c0f8be695dfce\nPartial-Bug: #1374118\n""}]",0,128805,751ad1aadf8447c2b6945b6ae4ab73bf71a244ca,11,6,2,6685,,,0,"Allow multi-line config items in meta-section of local.conf

It would behave such as the contents from each meta-section in
local.conf is copied to the destination files. One exception is the multiline
options not grouped together. In that case, the contents will be grouped
together in its destination config file.

Check tests/test_config.sh for examples.

This was originally committed in https://review.openstack.org/128805.
But the original change used AWK syntax that is not supported in AWK
3.1.8, and caused syntax error on servers with that AWK version. This
patch makes the necessary change so that it's compatible with AWK
3.1.8.

Change-Id: Id1e1fe01f05bd0f19ea6e89c4f4c0f8be695dfce
Partial-Bug: #1374118
",git fetch https://review.opendev.org/openstack/devstack refs/changes/05/128805/1 && git format-patch -1 --stdout FETCH_HEAD,"['functions-common', 'lib/config', 'tests/test_config.sh']",3,adb950cb1f4b31433710980e9a66dd75e4fb0173,bug/1374118," [[test-multi-sections|test-multi-sections.conf]] [sec-1] cfg_item1 = abcd cfg_item2 = efgh [sec-2] cfg_item1 = abcd cfg_item3 = /1/2/3/4:5 cfg_item4 = end [sec-3] cfg_item5 = 5555 cfg_item6 = 6666 cfg_item5 = 5555another [[test-multiline|test-multiline.conf]] [multi] cfg_item1 = ""ab"":""cd"", ""ef"": ""gh"" cfg_item1 = abcd cfg_item2 = efghtype = new additional = true"" check_result ""$VAL"" ""$EXPECT_VAL"" echo -n ""merge_config_file test-multi-sections: "" rm -f test-multi-sections.conf merge_config_file test.conf test-multi-sections test-multi-sections.conf VAL=$(cat test-multi-sections.conf) EXPECT_VAL=' [sec-1] cfg_item1 = abcd cfg_item2 = efgh [sec-2] cfg_item1 = abcd cfg_item3 = /1/2/3/4:5 cfg_item4 = end [sec-3] cfg_item5 = 5555 cfg_item5 = 5555another cfg_item6 = 6666' check_result ""$VAL"" ""$EXPECT_VAL"" echo -n ""merge_config_file test-multiline: "" rm -f test-multiline.conf merge_config_file test.conf test-multiline test-multiline.conf VAL=$(cat test-multiline.conf) EXPECT_VAL=' [multi] cfg_item1 = ""ab"":""cd"", ""ef"": ""gh"" cfg_item1 = abcd cfg_item2 = efgh'type = new additional = true""rm -f test-multiline.conf test-multi-sections.conf","additional = true type = new""additional = true type = new""",129,7
openstack%2Fpuppet-nova~stable%2Ficehouse~I25453f27c8864c8d56c023895d6aa4acf20a8ea0,openstack/puppet-nova,stable/icehouse,I25453f27c8864c8d56c023895d6aa4acf20a8ea0,Add extended logging options.,MERGED,2014-10-07 15:07:07.000000000,2014-10-16 22:42:59.000000000,2014-10-16 22:42:58.000000000,"[{'_account_id': 3}, {'_account_id': 7156}, {'_account_id': 8482}]","[{'number': 1, 'created': '2014-10-07 15:07:07.000000000', 'files': ['manifests/logging.pp', 'spec/classes/nova_logging_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/8b050bf8699937f5b62d1dba9f88d2bcb19d8057', 'message': 'Add extended logging options.\n\nThere is a range of extended logging options in Openstack services that use\nopenstack.common.logger (Ceilometer, Cinder, Heat, Keystone, Nova). Adding\nnova::logging to support them. This change is identical to\n<https://review.openstack.org/#/c/113560/> but it applies to puppet-nova\ninstead of puppet-ceilometer.\n\nNo blueprint/spec, as discussed in the IRC meeting on 08-11-2014.\n\nChange-Id: I25453f27c8864c8d56c023895d6aa4acf20a8ea0\n(cherry picked from commit fb44c989c21ff73e0c0382b976949893a4c45c61)\n'}]",0,126586,8b050bf8699937f5b62d1dba9f88d2bcb19d8057,7,3,1,12542,,,0,"Add extended logging options.

There is a range of extended logging options in Openstack services that use
openstack.common.logger (Ceilometer, Cinder, Heat, Keystone, Nova). Adding
nova::logging to support them. This change is identical to
<https://review.openstack.org/#/c/113560/> but it applies to puppet-nova
instead of puppet-ceilometer.

No blueprint/spec, as discussed in the IRC meeting on 08-11-2014.

Change-Id: I25453f27c8864c8d56c023895d6aa4acf20a8ea0
(cherry picked from commit fb44c989c21ff73e0c0382b976949893a4c45c61)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/86/126586/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/logging.pp', 'spec/classes/nova_logging_spec.rb']",2,8b050bf8699937f5b62d1dba9f88d2bcb19d8057,stable/icehouse,"require 'spec_helper' describe 'nova::logging' do let :params do { } end let :log_params do { :logging_context_format_string => '%(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [%(request_id)s %(user_identity)s] %(instance)s%(message)s', :logging_default_format_string => '%(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [-] %(instance)s%(message)s', :logging_debug_format_suffix => '%(funcName)s %(pathname)s:%(lineno)d', :logging_exception_prefix => '%(asctime)s.%(msecs)03d %(process)d TRACE %(name)s %(instance)s', :log_config_append => '/etc/nova/logging.conf', :publish_errors => true, :default_log_levels => { 'amqp' => 'WARN', 'amqplib' => 'WARN', 'boto' => 'WARN', 'qpid' => 'WARN', 'sqlalchemy' => 'WARN', 'suds' => 'INFO', 'iso8601' => 'WARN', 'requests.packages.urllib3.connectionpool' => 'WARN' }, :fatal_deprecations => true, :instance_format => '[instance: %(uuid)s] ', :instance_uuid_format => '[instance: %(uuid)s] ', :log_date_format => '%Y-%m-%d %H:%M:%S', } end shared_examples_for 'nova-logging' do context 'with extended logging options' do before { params.merge!( log_params ) } it_configures 'logging params set' end context 'without extended logging options' do it_configures 'logging params unset' end end shared_examples_for 'logging params set' do it 'enables logging params' do should contain_nova_config('DEFAULT/logging_context_format_string').with_value( '%(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [%(request_id)s %(user_identity)s] %(instance)s%(message)s') should contain_nova_config('DEFAULT/logging_default_format_string').with_value( '%(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [-] %(instance)s%(message)s') should contain_nova_config('DEFAULT/logging_debug_format_suffix').with_value( '%(funcName)s %(pathname)s:%(lineno)d') should contain_nova_config('DEFAULT/logging_exception_prefix').with_value( '%(asctime)s.%(msecs)03d %(process)d TRACE %(name)s %(instance)s') should contain_nova_config('DEFAULT/log_config_append').with_value( '/etc/nova/logging.conf') should contain_nova_config('DEFAULT/publish_errors').with_value( true) should contain_nova_config('DEFAULT/default_log_levels').with_value( 'amqp=WARN,amqplib=WARN,boto=WARN,iso8601=WARN,qpid=WARN,requests.packages.urllib3.connectionpool=WARN,sqlalchemy=WARN,suds=INFO') should contain_nova_config('DEFAULT/fatal_deprecations').with_value( true) should contain_nova_config('DEFAULT/instance_format').with_value( '[instance: %(uuid)s] ') should contain_nova_config('DEFAULT/instance_uuid_format').with_value( '[instance: %(uuid)s] ') should contain_nova_config('DEFAULT/log_date_format').with_value( '%Y-%m-%d %H:%M:%S') end end shared_examples_for 'logging params unset' do [ :logging_context_format_string, :logging_default_format_string, :logging_debug_format_suffix, :logging_exception_prefix, :log_config_append, :publish_errors, :default_log_levels, :fatal_deprecations, :instance_format, :instance_uuid_format, :log_date_format, ].each { |param| it { should contain_nova_config(""DEFAULT/#{param}"").with_ensure('absent') } } end context 'on Debian platforms' do let :facts do { :osfamily => 'Debian' } end it_configures 'nova-logging' end context 'on RedHat platforms' do let :facts do { :osfamily => 'RedHat' } end it_configures 'nova-logging' end end ",,315,0
openstack%2Fpuppet-nova~stable%2Ficehouse~I6a27ebf359c1910e221e9dc31711c6af569dc0ce,openstack/puppet-nova,stable/icehouse,I6a27ebf359c1910e221e9dc31711c6af569dc0ce,Makes kombu_ssl_* parameters optional when rabbit_use_ssl => true,MERGED,2014-09-26 22:45:36.000000000,2014-10-16 22:37:22.000000000,2014-10-16 22:37:21.000000000,"[{'_account_id': 3}, {'_account_id': 7156}, {'_account_id': 8482}]","[{'number': 1, 'created': '2014-09-26 22:45:36.000000000', 'files': ['manifests/init.pp', 'spec/classes/nova_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/6412d84dfe86293ac3a4abf0494001f07e86c7f6', 'message': 'Makes kombu_ssl_* parameters optional when rabbit_use_ssl => true\n\nThe kombu_ssl_* parameters should not be required when rabbit_use_ssl => true\nRather, rabbit_use_ssl must be set to true if the kombu_ssl_* parameters are\nused.\n\n(Similar to this patch to puppet-neutron: https://review.openstack.org/#/c/113671/ )\n\nConflicts:\n\tmanifests/init.pp\n\tspec/classes/nova_init_spec.rb\n\nCloses-Bug: 1356083\nChange-Id: I6a27ebf359c1910e221e9dc31711c6af569dc0ce\n(cherry picked from commit 61429e79ddfc0308657482cb57e411f82c8a0165)\n'}]",0,124532,6412d84dfe86293ac3a4abf0494001f07e86c7f6,7,3,1,9060,,,0,"Makes kombu_ssl_* parameters optional when rabbit_use_ssl => true

The kombu_ssl_* parameters should not be required when rabbit_use_ssl => true
Rather, rabbit_use_ssl must be set to true if the kombu_ssl_* parameters are
used.

(Similar to this patch to puppet-neutron: https://review.openstack.org/#/c/113671/ )

Conflicts:
	manifests/init.pp
	spec/classes/nova_init_spec.rb

Closes-Bug: 1356083
Change-Id: I6a27ebf359c1910e221e9dc31711c6af569dc0ce
(cherry picked from commit 61429e79ddfc0308657482cb57e411f82c8a0165)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/32/124532/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/nova_init_spec.rb']",2,6412d84dfe86293ac3a4abf0494001f07e86c7f6,bug/1356083," context 'with rabbit ssl enabled with kombu' do context 'with rabbit ssl enabled without kombu' do let :params do { :rabbit_hosts => ['rabbit:5673'], :rabbit_use_ssl => 'true', } end it 'configures rabbit' do should contain_nova_config('DEFAULT/rabbit_use_ssl').with_value(true) should contain_nova_config('DEFAULT/kombu_ssl_ca_certs').with_ensure('absent') should contain_nova_config('DEFAULT/kombu_ssl_certfile').with_ensure('absent') should contain_nova_config('DEFAULT/kombu_ssl_keyfile').with_ensure('absent') should contain_nova_config('DEFAULT/kombu_ssl_version').with_value('SSLv3') end end context 'with rabbit ssl disabled' do let :params do { :rabbit_password => 'pass', :rabbit_use_ssl => false, :kombu_ssl_version => 'SSLv3', } end it 'configures rabbit' do should contain_nova_config('DEFAULT/rabbit_use_ssl').with_value('false') should contain_nova_config('DEFAULT/kombu_ssl_ca_certs').with_ensure('absent') should contain_nova_config('DEFAULT/kombu_ssl_certfile').with_ensure('absent') should contain_nova_config('DEFAULT/kombu_ssl_keyfile').with_ensure('absent') should contain_nova_config('DEFAULT/kombu_ssl_version').with_ensure('absent') end end ", context 'with amqp ssl parameters' do,62,14
openstack%2Ftrove~master~I87124db66c5917c3aa95d2e10e9e0f37193e71d8,openstack/trove,master,I87124db66c5917c3aa95d2e10e9e0f37193e71d8,Add .idea folder to .gitignore,ABANDONED,2014-10-16 21:07:41.000000000,2014-10-16 22:35:23.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 10725}]","[{'number': 1, 'created': '2014-10-16 21:07:41.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/trove/commit/0016739320ea17f598a4178084c05fef47dc1dc7', 'message': 'Add .idea folder to .gitignore\n\nPyCharm Python IDE creating this folder to keep all project specific\nsettings.\n\nChange-Id: I87124db66c5917c3aa95d2e10e9e0f37193e71d8\n'}]",0,129050,0016739320ea17f598a4178084c05fef47dc1dc7,7,4,1,10725,,,0,"Add .idea folder to .gitignore

PyCharm Python IDE creating this folder to keep all project specific
settings.

Change-Id: I87124db66c5917c3aa95d2e10e9e0f37193e71d8
",git fetch https://review.opendev.org/openstack/trove refs/changes/50/129050/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,0016739320ea17f598a4178084c05fef47dc1dc7,master,.idea,,1,0
openstack%2Fmonasca-persister~master~Ia4ba36a4ff27d2529999784654066252a1f4c89f,openstack/monasca-persister,master,Ia4ba36a4ff27d2529999784654066252a1f4c89f,Specified all needed subpackages,MERGED,2014-10-16 22:19:03.000000000,2014-10-16 22:29:16.000000000,2014-10-16 22:29:15.000000000,"[{'_account_id': 3}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-10-16 22:19:03.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/fbf81b1404cd52baf306d6012e2f2af57480fcd6', 'message': 'Specified all needed subpackages\n\nChange-Id: Ia4ba36a4ff27d2529999784654066252a1f4c89f\n'}]",0,129083,fbf81b1404cd52baf306d6012e2f2af57480fcd6,6,2,1,11094,,,0,"Specified all needed subpackages

Change-Id: Ia4ba36a4ff27d2529999784654066252a1f4c89f
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/83/129083/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,fbf81b1404cd52baf306d6012e2f2af57480fcd6,, openstack openstack.common.fixture,,2,0
openstack%2Fdiskimage-builder~master~If121b2342ae888855ba435aa3189f039e985b812,openstack/diskimage-builder,master,If121b2342ae888855ba435aa3189f039e985b812,Allow for multiple image outputs from raw source,MERGED,2014-10-01 19:35:58.000000000,2014-10-16 21:56:29.000000000,2014-10-16 21:56:28.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1726}, {'_account_id': 4146}, {'_account_id': 6039}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 7118}, {'_account_id': 8532}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-10-01 19:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/86fc314af8750d7bb7104bd0f14297a35361701c', 'message': ""Allow for multiple image outputs from raw source\n\nWhen uploading images to multiple clouds it is possible that the same\nimage will be needed in multiple formats to accomodate hypervisors\nacross clouds. Update disk-image-create's -t flag to take a list of\ndesired output image formats so that a single disk-image-create can\noutput all of the desired image formats.\n\nChange-Id: If121b2342ae888855ba435aa3189f039e985b812\n""}, {'number': 2, 'created': '2014-10-02 19:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/2eeddc48df64c77dbf65522596fadae259c18a71', 'message': ""Allow for multiple image outputs from raw source\n\nWhen uploading images to multiple clouds it is possible that the same\nimage will be needed in multiple formats to accomodate hypervisors\nacross clouds. Update disk-image-create's -t flag to take a list of\ndesired output image formats so that a single disk-image-create can\noutput all of the desired image formats.\n\nChange-Id: If121b2342ae888855ba435aa3189f039e985b812\n""}, {'number': 3, 'created': '2014-10-02 19:37:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/428bec0a80b4fea84de8febfab507fa8f3f9402b', 'message': ""Allow for multiple image outputs from raw source\n\nWhen uploading images to multiple clouds it is possible that the same\nimage will be needed in multiple formats to accomodate hypervisors\nacross clouds. Update disk-image-create's -t flag to take a list of\ndesired output image formats so that a single disk-image-create can\noutput all of the desired image formats.\n\nChange-Id: If121b2342ae888855ba435aa3189f039e985b812\n""}, {'number': 4, 'created': '2014-10-02 21:14:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b64c0206312d6e58caa556d2bae326efc36e3d58', 'message': ""Allow for multiple image outputs from raw source\n\nWhen uploading images to multiple clouds it is possible that the same\nimage will be needed in multiple formats to accomodate hypervisors\nacross clouds. Update disk-image-create's -t flag to take a list of\ndesired output image formats so that a single disk-image-create can\noutput all of the desired image formats.\n\nChange-Id: If121b2342ae888855ba435aa3189f039e985b812\n""}, {'number': 5, 'created': '2014-10-02 21:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/0a2f1c45e7ec66d150e16bec834e36c45c9912f7', 'message': ""Allow for multiple image outputs from raw source\n\nWhen uploading images to multiple clouds it is possible that the same\nimage will be needed in multiple formats to accomodate hypervisors\nacross clouds. Update disk-image-create's -t flag to take a list of\ndesired output image formats so that a single disk-image-create can\noutput all of the desired image formats.\n\nChange-Id: If121b2342ae888855ba435aa3189f039e985b812\n""}, {'number': 6, 'created': '2014-10-10 17:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/064f59a3d05e853a5e6fcf738ece381a64a27aea', 'message': ""Allow for multiple image outputs from raw source\n\nWhen uploading images to multiple clouds it is possible that the same\nimage will be needed in multiple formats to accomodate hypervisors\nacross clouds. Update disk-image-create's -t flag to take a list of\ndesired output image formats so that a single disk-image-create can\noutput all of the desired image formats.\n\nChange-Id: If121b2342ae888855ba435aa3189f039e985b812\n""}, {'number': 7, 'created': '2014-10-10 23:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ed40fbc56f023d21d8ebfe69c15fa181983370e7', 'message': ""Allow for multiple image outputs from raw source\n\nWhen uploading images to multiple clouds it is possible that the same\nimage will be needed in multiple formats to accomodate hypervisors\nacross clouds. Update disk-image-create's -t flag to take a list of\ndesired output image formats so that a single disk-image-create can\noutput all of the desired image formats.\n\nChange-Id: If121b2342ae888855ba435aa3189f039e985b812\n""}, {'number': 8, 'created': '2014-10-10 23:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f07596510a9dd0d18b8251d9db267e2e089475bf', 'message': ""Allow for multiple image outputs from raw source\n\nWhen uploading images to multiple clouds it is possible that the same\nimage will be needed in multiple formats to accomodate hypervisors\nacross clouds. Update disk-image-create's -t flag to take a list of\ndesired output image formats so that a single disk-image-create can\noutput all of the desired image formats.\n\nChange-Id: If121b2342ae888855ba435aa3189f039e985b812\n""}, {'number': 9, 'created': '2014-10-11 00:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ffa90c0b8c4e69436405f0ccf2fff6ca61e34dfe', 'message': ""Allow for multiple image outputs from raw source\n\nWhen uploading images to multiple clouds it is possible that the same\nimage will be needed in multiple formats to accomodate hypervisors\nacross clouds. Update disk-image-create's -t flag to take a list of\ndesired output image formats so that a single disk-image-create can\noutput all of the desired image formats.\n\nChange-Id: If121b2342ae888855ba435aa3189f039e985b812\n""}, {'number': 10, 'created': '2014-10-11 03:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/394c408ad6344860df28ba086fbdaeabaf3ebc2d', 'message': ""Allow for multiple image outputs from raw source\n\nWhen uploading images to multiple clouds it is possible that the same\nimage will be needed in multiple formats to accomodate hypervisors\nacross clouds. Update disk-image-create's -t flag to take a list of\ndesired output image formats so that a single disk-image-create can\noutput all of the desired image formats.\n\nChange-Id: If121b2342ae888855ba435aa3189f039e985b812\n""}, {'number': 11, 'created': '2014-10-11 05:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/730d6c240f5828b3dc0484b61109a88090f2ee54', 'message': ""Allow for multiple image outputs from raw source\n\nWhen uploading images to multiple clouds it is possible that the same\nimage will be needed in multiple formats to accomodate hypervisors\nacross clouds. Update disk-image-create's -t flag to take a list of\ndesired output image formats so that a single disk-image-create can\noutput all of the desired image formats.\n\nChange-Id: If121b2342ae888855ba435aa3189f039e985b812\n""}, {'number': 12, 'created': '2014-10-13 16:17:03.000000000', 'files': ['bin/disk-image-create', 'lib/img-functions', 'lib/common-functions', 'elements/ramdisk/post-install.d/99-build-ramdisk'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ae928057bd2fc2205c91bf052d5503de64f9ea69', 'message': ""Allow for multiple image outputs from raw source\n\nWhen uploading images to multiple clouds it is possible that the same\nimage will be needed in multiple formats to accomodate hypervisors\nacross clouds. Update disk-image-create's -t flag to take a list of\ndesired output image formats so that a single disk-image-create can\noutput all of the desired image formats.\n\nChange-Id: If121b2342ae888855ba435aa3189f039e985b812\n""}]",17,125475,ae928057bd2fc2205c91bf052d5503de64f9ea69,53,10,12,4146,,,0,"Allow for multiple image outputs from raw source

When uploading images to multiple clouds it is possible that the same
image will be needed in multiple formats to accomodate hypervisors
across clouds. Update disk-image-create's -t flag to take a list of
desired output image formats so that a single disk-image-create can
output all of the desired image formats.

Change-Id: If121b2342ae888855ba435aa3189f039e985b812
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/75/125475/3 && git format-patch -1 --stdout FETCH_HEAD,['bin/disk-image-create'],1,86fc314af8750d7bb7104bd0f14297a35361701c,allow-multiple-image-outputs," echo "" This name should not include the file extension suffix"" echo "" -t qcow2,tar -- set the image types of the output image files (default qcow2)"" echo "" File types should be comma separated"" -t) IFS="","" read -a IMAGE_TYPES <<< ""$2""; export IMAGE_TYPES ; shift 2 ;;for X in ${!IMAGE_TYPES[@]} ; do if [ ""${IMAGE_TYPES[$X]}"" == ""tar"" ]; then sudo tar -C ${TMP_BUILD_DIR}/mnt -cf $IMAGE_NAME.tar --exclude ./sys \ --exclude ./proc --xattrs --xattrs-include=\* . sudo chown $USER: $IMAGE_NAME.tar unset IMAGE_TYPES[$X] fi doneif [ ""$IS_RAMDISK"" == ""0"" ]; then for IMAGE_TYPE in ${IMAGE_TYPES[@]} ; do compress_and_save_image $IMAGE_NAME.$IMAGE_TYPE done"," echo "" -t qcow2|tar -- set the imagetype of the output image file(default qcow2)"" -t) export IMAGE_TYPE=$2; shift 2 ;;export IMAGE_NAME=${IMAGE_NAME%%\.${IMAGE_TYPE}}if [ ""$IMAGE_TYPE"" == ""tar"" ]; then sudo tar -C ${TMP_BUILD_DIR}/mnt -cf $IMAGE_NAME.tar --exclude ./sys \ --exclude ./proc --xattrs --xattrs-include=\* . sudo chown $USER: $IMAGE_NAME.tar fiif [ ""$IS_RAMDISK"" == ""0"" -a ""$IMAGE_TYPE"" != ""tar"" ]; then compress_and_save_image $IMAGE_NAME.$IMAGE_TYPE",16,10
openstack%2Fneutron-specs~master~I9cd3ae89b4d048d970eddb6bd2cd8606d43c210a,openstack/neutron-specs,master,I9cd3ae89b4d048d970eddb6bd2cd8606d43c210a,Add support for DB2 as a backend database,ABANDONED,2014-06-04 16:38:47.000000000,2014-10-16 21:37:24.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 6601}, {'_account_id': 6854}, {'_account_id': 6873}, {'_account_id': 9970}]","[{'number': 1, 'created': '2014-06-04 16:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0949e774827bc97c094e75e9d8ce9845fb4444e1', 'message': 'Add support for DB2 as a backend database\n\nDetails the Neutron spec for blueprint db2-database\n\nChange-Id: I9cd3ae89b4d048d970eddb6bd2cd8606d43c210a\n'}, {'number': 2, 'created': '2014-06-20 16:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e4bc8cd878d3e8957b19f7189dd983357face37a', 'message': 'Add support for DB2 as a backend database\n\nDetails the Neutron spec for blueprint db2-database\n\nChange-Id: I9cd3ae89b4d048d970eddb6bd2cd8606d43c210a\n'}, {'number': 3, 'created': '2014-06-20 16:28:53.000000000', 'files': ['specs/juno/db2-database.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4422d575e79be7a5aaf5522000f899b2472f31ba', 'message': 'Add support for DB2 as a backend database\n\nDetails the Neutron spec for blueprint db2-database\n\nChange-Id: I9cd3ae89b4d048d970eddb6bd2cd8606d43c210a\n'}]",20,97851,4422d575e79be7a5aaf5522000f899b2472f31ba,17,7,3,6601,,,0,"Add support for DB2 as a backend database

Details the Neutron spec for blueprint db2-database

Change-Id: I9cd3ae89b4d048d970eddb6bd2cd8606d43c210a
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/51/97851/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/db2-database.rst'],1,0949e774827bc97c094e75e9d8ce9845fb4444e1,bp/db2-database,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== i18n Enablement for Neutron ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/db2-database The community currently supports MySQL and PostgreSQL production databases. Several other core projects already support DB2 (Keystone, Glance, Ceilometer, Heat). This blueprint adds support to Neutron for DB2 as a production database. Problem description =================== * Currently there is no support in the community for a deployer to run Neutron against a DB2 backend database. * For anyone running applications against an existing DB2 database that wants to move to OpenStack, they'd have to use a different database engine to run Neutron in OpenStack. * There is currently an inconsistent support matrix across the core projects since the majority of core projects support DB2 but Neutron (and Nova, and Cinder) don't yet. Proposed change =============== Add code to support migrating the Neutron database against a DB2 backend. This would require a fresh deployment of Neutron since there are no plans to migrate an existing Neutron database from another engine, e.g. MySQL, to DB2. Unit test code would also be updated to support running tests against a DB2 backend with the ibm_db_sa driver and all Neutron patches will be tested against a Tempest full run with 3rd party CI running DB2 that IBM will maintain. There is already some code in Oslo's db.api layer to support common function with DB2 like duplicate entry error handling and connection trace, so that is not part of this spec. Alternatives ------------ Deployers can use other supported database backends like MySQL or PostgreSQL, but this may not be an ideal option for customers already running applications with DB2 that want to integrate with OpenStack. In addition, you could run other core projects with multiple schemas in a single DB2 OpenStack database, but you'd have to run Neutron separately which is a maintenance/configuration problem. Data model impact ----------------- There are no impacts to the current Neutron data model. The following updates are needed for migration: * Update migration script 128e042a2b68_ext_gw_mode.py because the add_column() of alembic does support adding a non-nullable column with a default value to an existing database table in DB2. * Update migration script 50d5ba354c23_ml2_binding_vif_details.py because, after a number of ALTER TABLE statements containing REORG-recommended operations, the table will be placed in 'reorg pending' state so a reorg will need to be run in order to make the table available. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ The only performance impact on existing deployments is in the migration script changes which would be tested with turbo-hipster. Other deployer impact --------------------- There are no plans to migrate the Neutron database from a pre-existing installation (I.E. MySQL) to DB2. So deployers will need to be starting with a fresh Neutron installation to enable DB2 as a backend database. Developer impact ---------------- The only impact on developers is if they are adding DB API code or migrations that don't work with DB2 they will have to adjust those appropriately, just like we do today with MySQL and PostgreSQL. IBM ATCs would provide support/guidance on issues like this which require specific conditions for DB2, although for the most part the DB2 InfoCenter provides adequate detail on how to work with the engine and provides details on error codes. * DB2 SQL error message explanations can be found here: http://pic.dhe.ibm.com/infocenter/db2luw/v10r5/index.jsp? topic=%2Fcom.ibm.db2.luw.messages.sql.doc%2Fdoc%2Frsqlmsg.html * Information on developing with DB2 using python can be found here: http://pic.dhe.ibm.com/infocenter/db2luw/v10r5/index.jsp? topic=%2Fcom.ibm.swg.im.dbclient.python.doc%2Fdoc%2Fc0054366.html * Main contacts for DB2 questions in OpenStack: * Matt Riedemann (mriedem@us.ibm.com) - Nova core member * Brant Knudson (bknudson@us.ibm.com) - Keystone core member * Jay Bryant (jsbryant@us.ibm.com) - Cinder core member * Rahul Priyadarshi (rahul.priyadarshi@in.ibm.com) - ibm_db_sa maintainer Implementation ============== Assignee(s) ----------- Primary assignee: <jecarey@us.ibm.com> Work Items ---------- #.Update the migrations to work with a configured DB2 backend for running unit tests. #.Ensure 3rd party CI running DB2 includes Neutron testing. Dependencies ============ * DB2 support was added to sqlalchemy-migrate 0.9 during Icehouse: https://blueprints.launchpad.net/sqlalchemy-migrate/+spec/add-db2-support * There are no requirements changes in Neutron for the unit tests to work. The runtime requirements are the ibm-db-sa and ibm_db modules, which are both available from pypi. sqlalchemy-migrate optionally imports ibm-db-sa. The ibm-db-sa module requires a natively compiled ibm_db which has the c binding that talks to the DB2 ODBC/CLI driver. Testing ======= * IBM is already running 3rd party CI for DB2 for the core projects that currently support DB2 and for the existing Nova WIP patch that adds DB2 support. The same 3rd party CI is running against all sqlalchemy-migrate changes with DB2 on py26/py27 and runs Tempest against Keystone patches with a DB2 backend. Once the DB2 support is merged the DB2 3rd party CI would run against all Neutron patches with a full Tempest run. * While code will be added to make the Neutron unit tests work against a DB2 backend, running Neutron unit tests against DB2 with third party CI is not considered in the scope of this blueprint, but long-term this is something IBM wants to get running for additional QA coverage for DB2 in Neutron. This is something that would be worked on after getting Tempest running but for this blueprint I'm considering Tempest the required CI and UT CI to come later. * Running 3rd party turbo-hipster CI against DB2 is not in plan for this blueprint but like running unit tests against DB2 in 3rd party CI, running turbo-hipster against DB2 in 3rd party CI would be a long-term goal for QA and the IBM team will work on that after Tempest is running and after unit test CI is worked on. Documentation Impact ==================== * The install guides in the community do not go into specifics about setting up the database. The RHEL/Fedora install guide says to use the openstack-db script provided by openstack-utils in RDO which uses MySQL. The other install guides just say that SQLite3, MySQL and PostgreSQL are widely used databases. So for the install guides, those generic statements about supported databases would be updated to add DB2 to the list. Similar generic statements are also made in the following places which would be updated as well: * http://docs.openstack.org/training-guides/content/ developer-getting-started.html * http://docs.openstack.org/admin-guide-cloud/content/compute-service.html * http://docs.openstack.org/trunk/openstack-ops/content/ cloud_controller_design.html * There are database topics in the security guide, chapters 32-34, so there would be DB2 considerations there as well, specifically: * http://docs.openstack.org/security-guide/content/ ch041_database-backend-considerations.html * http://docs.openstack.org/security-guide/content/ ch042_database-overview.html * http://docs.openstack.org/security-guide/content/ ch043_database-transport-security.html References ========== * Nova DB2 blueprint: https://blueprints.launchpad.net/nova/+spec/db2-database * Work in progress nova patch: https://review.openstack.org/#/c/69047/ * Cinder DB2 blueprint: https://blueprints.launchpad.net/cinder/+spec/db2-database * There are Chef cookbooks on stackforge which support configuring OpenStack to run with an existing DB2 installation: http://git.openstack.org/cgit/stackforge/cookbook-openstack-common/ * Mailing list thread on making instances.uuid non-nullable: http://lists.openstack.org/pipermail/openstack-dev/2014-March/029467.html * DB2 10.5 InfoCenter: http://pic.dhe.ibm.com/infocenter/db2luw/v10r5/index.jsp * Some older manual setup instructions for DB2 with OpenStack: http://www.ibm.com/developerworks/cloud/library/cl-openstackdb2/index.html * ibm-db-sa: https://code.google.com/p/ibm-db/source/clones?repo=ibm-db-sa ",,237,0
openstack%2Fsahara~master~I3f4ea433f4cf78080ba97f9fa6eec22bc1ef21a3,openstack/sahara,master,I3f4ea433f4cf78080ba97f9fa6eec22bc1ef21a3,Use oslo.middleware instead of copy-pasted,MERGED,2014-08-05 13:38:38.000000000,2014-10-16 21:29:29.000000000,2014-10-16 21:29:28.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-08-05 13:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/afb25fca643b45c1a0808831d7aa5451b9d8f7e4', 'message': 'Use oslo.middleware instead if copy-pasted\n\nChange-Id: I3f4ea433f4cf78080ba97f9fa6eec22bc1ef21a3\n'}, {'number': 2, 'created': '2014-09-01 13:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b72dfed101329bcf6bd2710c508a6c1143b5c0e5', 'message': 'Use oslo.middleware instead if copy-pasted\n\nChange-Id: I3f4ea433f4cf78080ba97f9fa6eec22bc1ef21a3\n'}, {'number': 3, 'created': '2014-10-15 13:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/425e3316e6614ebb0d59ae88ed82395becfcee7f', 'message': 'Use oslo.middleware instead if copy-pasted\n\nChange-Id: I3f4ea433f4cf78080ba97f9fa6eec22bc1ef21a3\n'}, {'number': 4, 'created': '2014-10-16 08:51:19.000000000', 'files': ['requirements.txt', 'sahara/api/middleware/log_exchange.py', 'sahara/openstack/common/middleware/base.py', 'openstack-common.conf', 'sahara/openstack/common/middleware/__init__.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/94e78a8c63729e3e4ef620fb0e69e6755ff7805f', 'message': 'Use oslo.middleware instead of copy-pasted\n\nRelated-Bug:#1380725\nChange-Id: I3f4ea433f4cf78080ba97f9fa6eec22bc1ef21a3\n'}]",2,112017,94e78a8c63729e3e4ef620fb0e69e6755ff7805f,40,11,4,6786,,,0,"Use oslo.middleware instead of copy-pasted

Related-Bug:#1380725
Change-Id: I3f4ea433f4cf78080ba97f9fa6eec22bc1ef21a3
",git fetch https://review.opendev.org/openstack/sahara refs/changes/17/112017/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'sahara/api/middleware/log_exchange.py', 'openstack-common.conf']",3,afb25fca643b45c1a0808831d7aa5451b9d8f7e4,bug/1380725,,module=middleware.base,2,2
openstack%2Fkolla~master~Ia01973ef10b1ab94a2cb5ddd9186adb916066beb,openstack/kolla,master,Ia01973ef10b1ab94a2cb5ddd9186adb916066beb,fix sql typo in nova-conductor start script,MERGED,2014-10-16 21:22:15.000000000,2014-10-16 21:27:20.000000000,2014-10-16 21:27:20.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-10-16 21:22:15.000000000', 'files': ['docker/nova-controller/nova-conductor/start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/d02543c1bc4e59d44a05d10f391a80d9b8b7ab99', 'message': 'fix sql typo in nova-conductor start script\n\nChange-Id: Ia01973ef10b1ab94a2cb5ddd9186adb916066beb\n'}]",0,129056,d02543c1bc4e59d44a05d10f391a80d9b8b7ab99,7,3,1,8745,,,0,"fix sql typo in nova-conductor start script

Change-Id: Ia01973ef10b1ab94a2cb5ddd9186adb916066beb
",git fetch https://review.opendev.org/openstack/kolla refs/changes/56/129056/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/nova-controller/nova-conductor/start.sh'],1,d02543c1bc4e59d44a05d10f391a80d9b8b7ab99,larsks/fix-nova-controller,GRANT ALL PRIVILEGES ON ${NOVA_DB_NAME}.* TO,GRANT ALL PRIVILEGES ON nova* TO,1,1
openstack%2Ffuel-library~master~I8bf38ae18b5741b03e6bda5f8e69748a8ecdf2ec,openstack/fuel-library,master,I8bf38ae18b5741b03e6bda5f8e69748a8ecdf2ec,Increase tolerance of install DHCP,MERGED,2014-10-16 01:44:59.000000000,2014-10-16 21:22:14.000000000,2014-10-16 21:22:13.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13344}]","[{'number': 1, 'created': '2014-10-16 01:44:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/815658169f3fde4927c9b0fdc0df2f4fc58421d8', 'message': 'Increase tolerance of install DHCP\n\nFor Ubuntu, added the following kernel options:\nnetcfg/link_detection_timeout=20\nnetcfg/dhcptimeout=120\nFor CentOS:\ndhcptimeout=120\n\nCloses-Bug: #1381266\nRelated-Bug: #1376680\nRelated-Bug: #1379917\nblueprint 100-nodes-support\n\nChange-Id: I8bf38ae18b5741b03e6bda5f8e69748a8ecdf2ec\n'}, {'number': 2, 'created': '2014-10-16 01:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b5fd1a76128dbc5ecf3bf6773f4dccceab768317', 'message': 'Increase tolerance of install DHCP\n\nFor Ubuntu, added the following kernel options:\nnetcfg/link_detection_timeout=20\nnetcfg/dhcptimeout=120\nFor CentOS:\ndhcptimeout=120\n\nCloses-Bug: #1381266\nRelated-Bug: #1376680\nRelated-Bug: #1379917\nblueprint 100-nodes-support\n\nChange-Id: I8bf38ae18b5741b03e6bda5f8e69748a8ecdf2ec\n'}, {'number': 3, 'created': '2014-10-16 09:37:06.000000000', 'files': ['deployment/puppet/nailgun/manifests/cobbler.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a28fbb4ce9476bded8633abd11031a80b2eea47c', 'message': 'Increase tolerance of install DHCP\n\nFor Ubuntu, added the following kernel options:\nnetcfg/link_detection_timeout=20\nnetcfg/dhcptimeout=120\nFor CentOS:\ndhcptimeout=120\n\nCloses-Bug: #1381266\nRelated-Bug: #1376680\nRelated-Bug: #1379917\nblueprint 100-nodes-support\n\nChange-Id: I8bf38ae18b5741b03e6bda5f8e69748a8ecdf2ec\n'}]",1,128806,a28fbb4ce9476bded8633abd11031a80b2eea47c,32,11,3,8954,,,0,"Increase tolerance of install DHCP

For Ubuntu, added the following kernel options:
netcfg/link_detection_timeout=20
netcfg/dhcptimeout=120
For CentOS:
dhcptimeout=120

Closes-Bug: #1381266
Related-Bug: #1376680
Related-Bug: #1379917
blueprint 100-nodes-support

Change-Id: I8bf38ae18b5741b03e6bda5f8e69748a8ecdf2ec
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/06/128806/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nailgun/manifests/cobbler.pp'],1,815658169f3fde4927c9b0fdc0df2f4fc58421d8,bug/1381266," kopts => ""biosdevname=0 sshd=1 dhcptimeout=120"", kopts => ""netcfg/choose_interface=eth0 netcfg/dhcp_timeout=120 netcfg/link_detection_timeout=20"","," kopts => ""biosdevname=0 sshd=1"", kopts => ""netcfg/choose_interface=eth0"",",2,2
