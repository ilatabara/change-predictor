id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fneutron-dynamic-routing~master~Ibce68aa1335debdd1482011364af04160bed8f4d,openstack/neutron-dynamic-routing,master,Ibce68aa1335debdd1482011364af04160bed8f4d,Updated from global requirements,MERGED,2017-12-15 21:46:15.000000000,2017-12-19 07:07:16.000000000,2017-12-19 07:07:16.000000000,"[{'_account_id': 1653}, {'_account_id': 7715}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 21:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/cf560d1eac42d575e98fb1557f2cb08502b9aa22', 'message': 'Updated from global requirements\n\nChange-Id: Ibce68aa1335debdd1482011364af04160bed8f4d\n'}, {'number': 2, 'created': '2017-12-19 01:28:24.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/8ad30d47c21266faed8a3ffcd3f3acf516d6e136', 'message': 'Updated from global requirements\n\nChange-Id: Ibce68aa1335debdd1482011364af04160bed8f4d\n'}]",0,528417,8ad30d47c21266faed8a3ffcd3f3acf516d6e136,11,3,2,11131,,,0,"Updated from global requirements

Change-Id: Ibce68aa1335debdd1482011364af04160bed8f4d
",git fetch https://review.opendev.org/openstack/neutron-dynamic-routing refs/changes/17/528417/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,cf560d1eac42d575e98fb1557f2cb08502b9aa22,openstack/requirements,"oslo.service!=1.28.1,>=1.24.0 # Apache-2.0",oslo.service>=1.24.0 # Apache-2.0,1,1
openstack%2Fpython-qinlingclient~master~I2d2b9dcda6413475fe04fce55731d57c6c5563ab,openstack/python-qinlingclient,master,I2d2b9dcda6413475fe04fce55731d57c6c5563ab,Make sync as default execution model,MERGED,2017-12-19 03:31:53.000000000,2017-12-19 06:58:49.000000000,2017-12-19 06:58:49.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-19 03:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-qinlingclient/commit/ec81e0fd60462122e4d52e814ab56b0aee932f49', 'message': 'Make sync as default execution model\n\nChange-Id: I2d2b9dcda6413475fe04fce55731d57c6c5563ab\n'}, {'number': 2, 'created': '2017-12-19 04:33:45.000000000', 'files': ['qinlingclient/v1/function_execution.py', 'qinlingclient/osc/v1/base.py', 'qinlingclient/osc/v1/function_execution.py'], 'web_link': 'https://opendev.org/openstack/python-qinlingclient/commit/ad9ced929f62aaa1026ae5bb01b979f1da00e6fc', 'message': 'Make sync as default execution model\n\nChange-Id: I2d2b9dcda6413475fe04fce55731d57c6c5563ab\n'}]",0,528947,ad9ced929f62aaa1026ae5bb01b979f1da00e6fc,8,2,2,6732,,,0,"Make sync as default execution model

Change-Id: I2d2b9dcda6413475fe04fce55731d57c6c5563ab
",git fetch https://review.opendev.org/openstack/python-qinlingclient refs/changes/47/528947/2 && git format-patch -1 --stdout FETCH_HEAD,"['qinlingclient/v1/function_execution.py', 'qinlingclient/osc/v1/base.py', 'qinlingclient/osc/v1/function_execution.py']",3,ec81e0fd60462122e4d52e814ab56b0aee932f49,default-sync," group = parser.add_mutually_exclusive_group() dest='sync', default=True, action='store_false', dest='sync', default=True, input=parsed_args.input"," metavar='INPUT', group = parser.add_mutually_exclusive_group(required=True) action='store_true', if parsed_args.input: input = jsonutils.loads(parsed_args.input) else: input = {} input=input",9,11
openstack%2Fkuryr-libnetwork~master~Ied0ecdc63ea2b17a4994fa22c2a461d6ad63f31e,openstack/kuryr-libnetwork,master,Ied0ecdc63ea2b17a4994fa22c2a461d6ad63f31e,updated local conf file with services to enable/disable,NEW,2017-11-27 09:12:58.000000000,2017-12-19 06:43:46.000000000,,"[{'_account_id': 9820}, {'_account_id': 11536}, {'_account_id': 22348}, {'_account_id': 22406}, {'_account_id': 26131}, {'_account_id': 26827}]","[{'number': 1, 'created': '2017-11-27 09:12:58.000000000', 'files': ['devstack/local.conf.sample'], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/b659e900900fe4ee12726a15a1f93d297bf1ddd0', 'message': 'updated local conf file with services to enable/disable\n\nChange-Id: Ied0ecdc63ea2b17a4994fa22c2a461d6ad63f31e\n'}]",3,523065,b659e900900fe4ee12726a15a1f93d297bf1ddd0,9,6,1,26827,,,0,"updated local conf file with services to enable/disable

Change-Id: Ied0ecdc63ea2b17a4994fa22c2a461d6ad63f31e
",git fetch https://review.opendev.org/openstack/kuryr-libnetwork refs/changes/65/523065/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/local.conf.sample'],1,b659e900900fe4ee12726a15a1f93d297bf1ddd0,," # kuryr uses Neutron to provide networking services and by default neutron is enabled # nova-network was deprecated in the openstack Newton release # if you are using older than Newton release, uncomment below lines #enable_plugin neutron https://git.openstack.org/openstack/neutron #disable_service n-net #enable_service q-svc #enable_service q-dhcp #enable_service q-l3 #enable_service q-agt ",enable_plugin neutron https://git.openstack.org/openstack/neutron # Use Neutron instead of nova-network disable_service n-net enable_service q-svc enable_service q-dhcp enable_service q-l3 disable_service heat enable_service q-agt,10,8
openstack%2Fkeystone~master~I15ceae009f17cdb416626c9a34b3a722e3be0c19,openstack/keystone,master,I15ceae009f17cdb416626c9a34b3a722e3be0c19,Fix sphinx CI failure,ABANDONED,2017-12-19 04:12:15.000000000,2017-12-19 06:35:12.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-12-19 04:12:15.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2aa0c917c13d00badf108270b1a18e9243d9b4bf', 'message': 'Fix sphinx CI failure\n\nChange-Id: I15ceae009f17cdb416626c9a34b3a722e3be0c19\n'}]",0,528949,2aa0c917c13d00badf108270b1a18e9243d9b4bf,3,1,1,15054,,,0,"Fix sphinx CI failure

Change-Id: I15ceae009f17cdb416626c9a34b3a722e3be0c19
",git fetch https://review.opendev.org/openstack/keystone refs/changes/49/528949/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,2aa0c917c13d00badf108270b1a18e9243d9b4bf,ci_fix,autodoc_index_modules = True,autodoc_tree_index_modules = True,1,1
openstack%2Fproject-config~master~I149bc67b986396358e9555f75efcf1c34e451c4b,openstack/project-config,master,I149bc67b986396358e9555f75efcf1c34e451c4b,Normalize projects.yaml,MERGED,2017-12-19 06:10:27.000000000,2017-12-19 06:30:28.000000000,2017-12-19 06:30:28.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-19 06:10:27.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/adf41cb673c40447963e3324062a31b33199bcd3', 'message': 'Normalize projects.yaml\n\nChange-Id: I149bc67b986396358e9555f75efcf1c34e451c4b\n'}]",0,528963,adf41cb673c40447963e3324062a31b33199bcd3,6,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: I149bc67b986396358e9555f75efcf1c34e451c4b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/63/528963/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,adf41cb673c40447963e3324062a31b33199bcd3,project-yaml-normalization,, upstream: https://github.com/chkumar246/telemetry-tempest-plugin.git,0,1
openstack%2Ftripleo-common~stable%2Fpike~Ia23825aea938f6f9bcf536e35cad562a1b96c93b,openstack/tripleo-common,stable/pike,Ia23825aea938f6f9bcf536e35cad562a1b96c93b,Consume NodeDataLookup in ceph-ansible,MERGED,2017-12-18 16:38:56.000000000,2017-12-19 06:28:49.000000000,2017-12-19 06:28:49.000000000,"[{'_account_id': 18002}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 16:38:56.000000000', 'files': ['workbooks/ceph-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9bb5fcc5bd34fd138062c646da808921422d0b7a', 'message': 'Consume NodeDataLookup in ceph-ansible\n\nMakes it possible to provide per-node variables to ceph-ansible\nusing the NodeDataLookup parameter, the same consumed by the\n$roleExtraConfigPre resource for puppet hieradata.\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\nCo-Authored-By: fulton@redhat.com\n(cherry picked from commit eda02c05d7b688d3b81321377bf4b32bfa5329bd)\n'}]",0,528755,9bb5fcc5bd34fd138062c646da808921422d0b7a,10,2,1,6796,,,0,"Consume NodeDataLookup in ceph-ansible

Makes it possible to provide per-node variables to ceph-ansible
using the NodeDataLookup parameter, the same consumed by the
$roleExtraConfigPre resource for puppet hieradata.

Change-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b
Closes-Bug: #1736707
Co-Authored-By: fulton@redhat.com
(cherry picked from commit eda02c05d7b688d3b81321377bf4b32bfa5329bd)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/55/528755/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/ceph-ansible.yaml'],1,9bb5fcc5bd34fd138062c646da808921422d0b7a,bug/1736707," - node_data_lookup: '{}' on-success: merge_ip_lists merge_ip_lists: publish: ips_list: <% ($.mon_ips + $.osd_ips + $.mds_ips + $.rgw_ips + $.client_ips).toSet() %> publish: fork_count: <% min($.ips_list.count(), 100) %> # don't use >100 forks on-success: collect_nodes_uuid collect_nodes_uuid: action: tripleo.ansible-playbook input: inventory: overcloud: hosts: <% $.ips_list.toDict($, {}) %> remote_user: tripleo-admin become: true become_user: root verbosity: 0 ssh_private_key: <% $.private_key %> extra_env_variables: ANSIBLE_HOST_KEY_CHECKING: 'False' ANSIBLE_STDOUT_CALLBACK: 'json' playbook: - hosts: overcloud gather_facts: no tasks: - name: collect machine id command: dmidecode -s system-uuid publish: ansible_output: <% json_parse(task().result.stderr) %> on-success: set_ip_uuids set_ip_uuids: publish: ip_uuids: <% let(root => $.ansible_output.get('plays')[0].get('tasks')[0].get('hosts')) -> $.ips_list.toDict($, $root.get($).get('stdout')) %> on-success: parse_node_data_lookup parse_node_data_lookup: publish: json_node_data_lookup: <% json_parse($.node_data_lookup) %> on-success: map_node_data_lookup map_node_data_lookup: publish: ips_data: <% let(uuids => $.ip_uuids, root => $) -> $.ips_list.toDict($, $root.json_node_data_lookup.get($uuids.get($, ""NO-UUID-FOUND""), {})) %> hosts: <% let(root => $) -> $.mon_ips.toDict($, $root.ips_data.get($, {})) %> osds: hosts: <% let(root => $) -> $.osd_ips.toDict($, $root.ips_data.get($, {})) %> mdss: hosts: <% let(root => $) -> $.mds_ips.toDict($, $root.ips_data.get($, {})) %> rgws: hosts: <% let(root => $) -> $.rgw_ips.toDict($, $root.ips_data.get($, {})) %> clients: hosts: <% let(root => $) -> $.client_ips.toDict($, $root.ips_data.get($, {})) %> all: vars: <% $.extra_vars %>"," publish: # unique list of all IPs: make each list a set, take unions and count fork_count: <% min($.mon_ips.toSet().union($.osd_ips.toSet()).union($.mds_ips.toSet()).union($.rgw_ips.toSet()).union($.client_ips.toSet()).count(), 100) %> # don't use >100 forks hosts: <% $.mon_ips.toDict($, {}) %> osds: hosts: <% $.osd_ips.toDict($, {}) %> mdss: hosts: <% $.mds_ips.toDict($, {}) %> rgws: hosts: <% $.rgw_ips.toDict($, {}) %> clients: hosts: <% $.client_ips.toDict($, {}) %> extra_vars: <% $.extra_vars %>",49,8
openstack%2Fstackviz~master~Ib9805b5c7d3ba5a4b44045424fed4493322dcd67,openstack/stackviz,master,Ib9805b5c7d3ba5a4b44045424fed4493322dcd67,Fix indentations in docs,MERGED,2017-12-18 04:52:37.000000000,2017-12-19 06:19:11.000000000,2017-12-19 06:19:11.000000000,"[{'_account_id': 5689}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 04:52:37.000000000', 'files': ['CONTRIBUTING.rst', 'doc/source/man/stackviz-export.rst', 'README.rst', 'doc/source/man/stackviz-front.rst'], 'web_link': 'https://opendev.org/openstack/stackviz/commit/7eccb678494f2dceef3ce98188fe65245b3319ea', 'message': ""Fix indentations in docs\n\nThis commit fixes some indentations in stackviz docs. These indentations\nare weird. There's no specific reason to keep it.\n\nChange-Id: Ib9805b5c7d3ba5a4b44045424fed4493322dcd67\n""}]",1,528622,7eccb678494f2dceef3ce98188fe65245b3319ea,7,2,1,5689,,,0,"Fix indentations in docs

This commit fixes some indentations in stackviz docs. These indentations
are weird. There's no specific reason to keep it.

Change-Id: Ib9805b5c7d3ba5a4b44045424fed4493322dcd67
",git fetch https://review.opendev.org/openstack/stackviz refs/changes/22/528622/1 && git format-patch -1 --stdout FETCH_HEAD,"['CONTRIBUTING.rst', 'doc/source/man/stackviz-export.rst', 'README.rst', 'doc/source/man/stackviz-front.rst']",4,7eccb678494f2dceef3ce98188fe65245b3319ea,fix-indentation,"**pythonlogging** Contains logs for API calls that were used in the test. This log is often quite large, as it contains full headers for every request at INFO, DEBUG, WARNING, and ERROR levels. To make searching these logs easier, the test details page has a built in filter for parsing by log level. In the header of the test details page, the magnifying glass can be clicked to only show pythonlogging lines that correspond to a certain level of detail. To find errors in pythonlogging quickly, it is advisable to only select the WARNING and ERROR levels for display. **reason** Only available for skipped tests. Lists the reason for skipping the test, usually to avoid triggering an outstanding bug. **traceback** Only available for failed tests. Shows the full traceback of the test runner's error output when the test failed. This is useful in quickly isolating the cause of a failure. There can be multiple traceback logs (e.g. traceback, traceback1) for one test. - :code:`list` returns `config.json` using GET. - :code:`get(id)` calls :code:`list`, then iterates through all the available datasets for the requested id number. Rejects if not found. - :code:`raw(dataset)` returns `<dataset>_raw.json` file using GET. - :code:`details(dataset)` returns `<dataset>_details.json` file using GET. - :code:`tree(dataset)` returns `<dataset>_tree.json` file using GET. - :code:`dstat(dataset)` returns `dstat_log.csv` file using GET, if available."," **pythonlogging** Contains logs for API calls that were used in the test. This log is often quite large, as it contains full headers for every request at INFO, DEBUG, WARNING, and ERROR levels. To make searching these logs easier, the test details page has a built in filter for parsing by log level. In the header of the test details page, the magnifying glass can be clicked to only show pythonlogging lines that correspond to a certain level of detail. To find errors in pythonlogging quickly, it is advisable to only select the WARNING and ERROR levels for display. **reason** Only available for skipped tests. Lists the reason for skipping the test, usually to avoid triggering an outstanding bug. **traceback** Only available for failed tests. Shows the full traceback of the test runner's error output when the test failed. This is useful in quickly isolating the cause of a failure. There can be multiple traceback logs (e.g. traceback, traceback1) for one test. - :code:`list` returns `config.json` using GET. - :code:`get(id)` calls :code:`list`, then iterates through all the available datasets for the requested id number. Rejects if not found. - :code:`raw(dataset)` returns `<dataset>_raw.json` file using GET. - :code:`details(dataset)` returns `<dataset>_details.json` file using GET. - :code:`tree(dataset)` returns `<dataset>_tree.json` file using GET. - :code:`dstat(dataset)` returns `dstat_log.csv` file using GET, if available.",45,44
openstack%2Foslo.messaging~master~I7009a3b96ee250c177c10f5121eb73d908747a52,openstack/oslo.messaging,master,I7009a3b96ee250c177c10f5121eb73d908747a52,Update kafka functional test,MERGED,2017-09-21 19:32:18.000000000,2017-12-19 06:16:50.000000000,2017-12-19 06:16:50.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 8770}, {'_account_id': 9796}, {'_account_id': 20523}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-09-21 19:32:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d0ba929cf1db3638f4989fb63ce7ec24036ea2d9', 'message': 'Fix kafka func test\n\nPatch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n* adds java dependency\n* removes use of deprecated get_transport\n* revise test setup environment\n* use uuid for group for now\n\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 2, 'created': '2017-09-22 12:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/2c91ed9a9755be430a53529b481e8f090090d305', 'message': 'Update kafka functional test\n\nPatch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n* adds java dependency\n* removes use of deprecated get_transport\n* revise test setup environment\n* use uuid for group for now\n\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 3, 'created': '2017-09-26 19:47:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5959eaa5ae402077611e2ac58b1512517ad4855d', 'message': 'Update kafka functional test\n\nPatch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n* adds java dependency\n* removes use of deprecated get_transport\n* revise test setup environment\n* use uuid for group for now\n\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 4, 'created': '2017-10-06 19:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/45f1a5e34073284a5dc4a0d7a7600a16628ea935', 'message': 'Update kafka functional test\n\nPatch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n* adds java dependency\n* removes use of deprecated get_transport\n* revise test setup environment\n* use uuid for group for now\n\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 5, 'created': '2017-10-18 16:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f98c8b59dc3a66a840d0b40621beef30f7efc9a8', 'message': 'Update kafka functional test\n\nPatch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n* adds java dependency\n* removes use of deprecated get_transport\n* revise test setup environment\n* override consumer_group for each test\n\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 6, 'created': '2017-10-19 19:45:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/2402bc3494c25d9dfb09d62f988580265d95085e', 'message': 'Update kafka functional test\n\nPatch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n* adds java dependency\n* removes use of deprecated get_transport\n* revise test setup environment\n* override consumer_group for each test\n\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 7, 'created': '2017-11-10 16:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5b1830d16cadaae670a43d0b106f17a481784f06', 'message': 'Update kafka functional test\n\nThis patch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n* adds java dependency\n* removes use of deprecated get_transport\n* override consumer_group for each test\n* update to kafka 1.0.0 server\n\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 8, 'created': '2017-11-12 17:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a9f6be6ae1c1293c256d164af32d30e2786ea17d', 'message': 'Update kafka functional test\n\nThis patch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n* add java dependency\n* removes use of deprecated get_transport\n* override consumer_group for each test\n* update to kafka 1.0.0 server\n\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 9, 'created': '2017-11-15 15:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/39c8b191e1331543f9a0d43460e54125ea3b6af8', 'message': 'Update kafka functional test\n\nThis patch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n* add java dependency\n* removes use of deprecated get_transport\n* override consumer_group for each test\n* update to kafka 1.0.0 server\n\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 10, 'created': '2017-11-15 21:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/38f60e4c3272d95f424b01a986ce6d80a59c4864', 'message': 'Update kafka functional test\n\nThis patch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n* add java dependency\n* removes use of deprecated get_transport\n* override consumer_group for each test\n* update to kafka 1.0.0 server\n\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 11, 'created': '2017-11-29 19:51:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/ed8c4a5b41b5464e7c13df0de148e8468c6f46db', 'message': 'Update kafka functional test\n\nThis patch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n\n* removes use of deprecated get_transport\n* override consumer_group for each test\n* update to kafka 1.0.0 server\n\nDepends-On: Ib552152e841a9fc0bffdcb7c3f7bc75613d0ed62\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 12, 'created': '2017-11-29 19:57:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a1bc08d7806e73359677a1a52bac20b6b41670a3', 'message': 'Update kafka functional test\n\nThis patch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n\n* removes use of deprecated get_transport\n* override consumer_group for each test\n* update to kafka 1.0.0 server\n\nDepends-On: Ib552152e841a9fc0bffdcb7c3f7bc75613d0ed62\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 13, 'created': '2017-12-13 17:29:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/524ef68832245b40071a56b0aea0f6309e017fa5', 'message': 'Update kafka functional test\n\nThis patch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n\n* removes use of deprecated get_transport\n* override consumer_group for each test\n* update to kafka 1.0.0 server\n\nDepends-On: Ib552152e841a9fc0bffdcb7c3f7bc75613d0ed62\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 14, 'created': '2017-12-14 21:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/09cebbbf4e495506a8a3713fb9b72abefa6ca597', 'message': 'Update kafka functional test\n\nThis patch addresses use of one group id for consumers that broke\nfunctional tests.\n\nThis patch:\n\n* removes use of deprecated get_transport\n* override consumer_group for each test\n* changed to synchronous send\n* update to kafka 1.0.0 server\n\nDepends-On: Ib552152e841a9fc0bffdcb7c3f7bc75613d0ed62\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 15, 'created': '2017-12-16 16:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/8422d5af2218c680409a89a869760e8cba9b0170', 'message': 'Update kafka functional test\n\nThis patch addresses a number of issues that prevented the functional\ntests from running. The functional tests now execute and can complete\nsuccesfully. At times, the test will fail (noticiably in CI) indicating\nan underlying issue with consumer interaction with the kafka server.\n\nIt would be beneficial to merge this patch as it provides repeatability\nand visibility for driver-kafka server integration to facilitate\nadditional debugging and testing.\n\nThis patch:\n\n* removes use of deprecated get_transport\n* override consumer_group for each test\n* changed to synchronous send\n* update to kafka 1.0.0 server\n\nDepends-On: Ib552152e841a9fc0bffdcb7c3f7bc75613d0ed62\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}, {'number': 16, 'created': '2017-12-16 19:41:36.000000000', 'files': ['oslo_messaging/tests/functional/test_functional.py', 'tools/functions.sh', 'oslo_messaging/_drivers/impl_kafka.py', 'setup-test-env-kafka.sh', 'oslo_messaging/tests/functional/notify/test_logger.py', 'oslo_messaging/tests/drivers/test_impl_kafka.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/3afc3a0a1d076717085dcf5e73a1378c21b5ac4d', 'message': 'Update kafka functional test\n\nThis patch addresses a number of issues that prevented the functional\ntests from running. The functional tests now execute and can complete\nsuccesfully. At times, the test will fail (noticiably in CI) indicating\nan underlying issue with consumer interaction with the kafka server.\n\nIt would be beneficial to merge this patch as it provides repeatability\nand visibility for driver-kafka server integration to facilitate\nadditional debugging and testing.\n\nThis patch:\n\n* removes use of deprecated get_transport\n* override consumer_group for each test\n* changed to synchronous send\n* update to kafka 1.0.0 server\n\nDepends-On: Ib552152e841a9fc0bffdcb7c3f7bc75613d0ed62\nChange-Id: I7009a3b96ee250c177c10f5121eb73d908747a52\n'}]",7,506338,3afc3a0a1d076717085dcf5e73a1378c21b5ac4d,76,6,16,20523,,,0,"Update kafka functional test

This patch addresses a number of issues that prevented the functional
tests from running. The functional tests now execute and can complete
succesfully. At times, the test will fail (noticiably in CI) indicating
an underlying issue with consumer interaction with the kafka server.

It would be beneficial to merge this patch as it provides repeatability
and visibility for driver-kafka server integration to facilitate
additional debugging and testing.

This patch:

* removes use of deprecated get_transport
* override consumer_group for each test
* changed to synchronous send
* update to kafka 1.0.0 server

Depends-On: Ib552152e841a9fc0bffdcb7c3f7bc75613d0ed62
Change-Id: I7009a3b96ee250c177c10f5121eb73d908747a52
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/38/506338/9 && git format-patch -1 --stdout FETCH_HEAD,"['bindep.txt', 'oslo_messaging/_drivers/impl_kafka.py', 'setup-test-env-kafka.sh', 'oslo_messaging/tests/drivers/test_impl_kafka.py', 'tox.ini']",5,d0ba929cf1db3638f4989fb63ce7ec24036ea2d9,kafka-update, TRANSPORT_URL=kafka://127.0.0.1:9092// kafka-python>=1.3.4, TRANSPORT_DRIVER=kafka kafka-python>=1.3.1,98,15
openstack%2Fopenstack-helm-infra~master~I78a40e43cfeb7391699908a1f73b57846fedbcbb,openstack/openstack-helm-infra,master,I78a40e43cfeb7391699908a1f73b57846fedbcbb,Add alert templates via alertmanager's values.yaml file,MERGED,2017-12-15 14:42:00.000000000,2017-12-19 06:16:28.000000000,2017-12-19 06:16:28.000000000,"[{'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2017-12-15 14:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/caa470c8160a5b98d51779e6a54568e99cff9a5b', 'message': ""Add alertmanager templates via alertmanager's values.yaml file\n\nThis adds the ability to define custom alert template via the\nvalues.yaml file for Alertmanager. This will provide the ability\nfor an operator to define actions to be taken upon an alert firing\nsuch as sending Slack alerts, email alerts, or any other\norganization-specific action\n\nChange-Id: I78a40e43cfeb7391699908a1f73b57846fedbcbb\n""}, {'number': 2, 'created': '2017-12-15 14:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/01a0c9155b0f815899206050f93fb975837ebaec', 'message': ""Add alert templates via alertmanager's values.yaml file\n\nThis adds the ability to define custom alert template via the\nvalues.yaml file for Alertmanager. This will provide the ability\nfor an operator to define actions to be taken upon an alert firing\nsuch as sending Slack alerts, email alerts, or any other\norganization-specific action\n\nChange-Id: I78a40e43cfeb7391699908a1f73b57846fedbcbb\n""}, {'number': 3, 'created': '2017-12-15 15:49:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/dccf8dbc23c6888a20425033b329ebb9b2034b1b', 'message': ""Add alert templates via alertmanager's values.yaml file\n\nThis adds the ability to define custom alert template via the\nvalues.yaml file for Alertmanager. This will provide the ability\nfor an operator to define actions to be taken upon an alert firing\nsuch as sending Slack alerts, email alerts, or any other\norganization-specific action\n\nChange-Id: I78a40e43cfeb7391699908a1f73b57846fedbcbb\n""}, {'number': 4, 'created': '2017-12-17 20:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/121e8a3f2a367d2e5f55bdc0a8c2c2cd5946ef8f', 'message': ""Add alert templates via alertmanager's values.yaml file\n\nThis adds the ability to define custom alert template via the\nvalues.yaml file for Alertmanager. This will provide the ability\nfor an operator to define actions to be taken upon an alert firing\nsuch as sending Slack alerts, email alerts, or any other\norganization-specific action\n\nChange-Id: I78a40e43cfeb7391699908a1f73b57846fedbcbb\n""}, {'number': 5, 'created': '2017-12-18 17:24:51.000000000', 'files': ['prometheus-alertmanager/templates/statefulset.yaml', 'prometheus-alertmanager/templates/configmap-etc.yaml', 'prometheus-alertmanager/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/917865ed973e65b02b531fc987381a582aff82f1', 'message': ""Add alert templates via alertmanager's values.yaml file\n\nThis adds the ability to define custom alert template via the\nvalues.yaml file for Alertmanager. This will provide the ability\nfor an operator to define actions to be taken upon an alert firing\nsuch as sending Slack alerts, email alerts, or any other\norganization-specific action\n\nChange-Id: I78a40e43cfeb7391699908a1f73b57846fedbcbb\n""}]",0,528286,917865ed973e65b02b531fc987381a582aff82f1,14,3,5,17591,,,0,"Add alert templates via alertmanager's values.yaml file

This adds the ability to define custom alert template via the
values.yaml file for Alertmanager. This will provide the ability
for an operator to define actions to be taken upon an alert firing
such as sending Slack alerts, email alerts, or any other
organization-specific action

Change-Id: I78a40e43cfeb7391699908a1f73b57846fedbcbb
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/86/528286/4 && git format-patch -1 --stdout FETCH_HEAD,"['alertmanager/templates/statefulset.yaml', 'alertmanager/values.yaml', 'alertmanager/templates/configmap-etc.yaml']",3,caa470c8160a5b98d51779e6a54568e99cff9a5b,add_alertmanager_templates, alert_templates.tmpl: {{- toYaml .Values.conf.alert_templates | indent 4 }},,8,1
openstack%2Fopenstack-helm-infra~master~I2ba7f4aec88f73e6bc3ff31117973ebb4e85ceba,openstack/openstack-helm-infra,master,I2ba7f4aec88f73e6bc3ff31117973ebb4e85ceba,Add peer meshing to Alertmanager,MERGED,2017-12-14 14:20:22.000000000,2017-12-19 06:16:26.000000000,2017-12-19 06:16:26.000000000,"[{'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2017-12-14 14:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/160cc51897704248a63821e2c895977dee0d3090', 'message': 'WIP - Add additional command line flags to Alertmanager\n\nChange-Id: I2ba7f4aec88f73e6bc3ff31117973ebb4e85ceba\n'}, {'number': 2, 'created': '2017-12-14 20:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b5da5a74769edc5082e0d6d08ab205a98f11173e', 'message': 'Add peer meshing to Alertmanager\n\nAdds additional flags to Alertmanager for the peer meshing. This\nalso adds a headless discovery service so each instance can\ncalculate the DNS names of its mesh peers on startup.\n\nChange-Id: I2ba7f4aec88f73e6bc3ff31117973ebb4e85ceba\n'}, {'number': 3, 'created': '2017-12-14 21:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/98d0c2a71f8217bf5d92e16b023a675ca0256734', 'message': 'Add peer meshing to Alertmanager\n\nAdds additional flags to Alertmanager for the peer meshing. This\nalso adds a headless discovery service so each instance can\ncalculate the DNS names of its mesh peers on startup.\n\nChange-Id: I2ba7f4aec88f73e6bc3ff31117973ebb4e85ceba\n'}, {'number': 4, 'created': '2017-12-14 21:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ccebc0527d78fe9664fc74e3aa2eeb71ed95fa3e', 'message': 'Add peer meshing to Alertmanager\n\nAdds additional flags to Alertmanager for the peer meshing. This\nalso adds a headless discovery service so each instance can\ncalculate the DNS names of its mesh peers on startup.\n\nChange-Id: I2ba7f4aec88f73e6bc3ff31117973ebb4e85ceba\n'}, {'number': 5, 'created': '2017-12-14 23:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/000b3e4959515220fa8a6dffec57cbb5d63c48a8', 'message': 'Add peer meshing to Alertmanager\n\nAdds additional flags to Alertmanager for the peer meshing. This\nalso adds a headless discovery service so each instance can\ncalculate the DNS names of its mesh peers on startup.\n\nChange-Id: I2ba7f4aec88f73e6bc3ff31117973ebb4e85ceba\n'}, {'number': 6, 'created': '2017-12-17 20:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/feecc8deecc2b41dfb4e8a482082caf8055aee71', 'message': 'Add peer meshing to Alertmanager\n\nAdds additional flags to Alertmanager for the peer meshing. This\nalso adds a headless discovery service so each instance can\ncalculate the DNS names of its mesh peers on startup.\n\nChange-Id: I2ba7f4aec88f73e6bc3ff31117973ebb4e85ceba\n'}, {'number': 7, 'created': '2017-12-18 16:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/895cdb2b88222f6acd68577600419eceb22a2e2d', 'message': 'Add peer meshing to Alertmanager\n\nAdds additional flags to Alertmanager for the peer meshing. This\nalso adds a headless discovery service so each instance can\ncalculate the DNS names of its mesh peers on startup.\n\nChange-Id: I2ba7f4aec88f73e6bc3ff31117973ebb4e85ceba\n'}, {'number': 8, 'created': '2017-12-18 16:15:19.000000000', 'files': ['prometheus-alertmanager/templates/bin/_alertmanager.sh.tpl', 'prometheus-alertmanager/templates/statefulset.yaml', 'prometheus-alertmanager/values.yaml', 'prometheus-alertmanager/templates/service-discovery.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9fdbd235bed3d38e3d14adb0c9af2cdc643f2722', 'message': 'Add peer meshing to Alertmanager\n\nAdds additional flags to Alertmanager for the peer meshing. This\nalso adds a headless discovery service so each instance can\ncalculate the DNS names of its mesh peers on startup.\n\nChange-Id: I2ba7f4aec88f73e6bc3ff31117973ebb4e85ceba\n'}]",0,527973,9fdbd235bed3d38e3d14adb0c9af2cdc643f2722,20,3,8,17591,,,0,"Add peer meshing to Alertmanager

Adds additional flags to Alertmanager for the peer meshing. This
also adds a headless discovery service so each instance can
calculate the DNS names of its mesh peers on startup.

Change-Id: I2ba7f4aec88f73e6bc3ff31117973ebb4e85ceba
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/73/527973/3 && git format-patch -1 --stdout FETCH_HEAD,"['alertmanager/templates/service.yaml', 'alertmanager/templates/statefulset.yaml', 'alertmanager/values.yaml', 'alertmanager/templates/bin/_alertmanager.sh.tpl']",4,160cc51897704248a63821e2c895977dee0d3090,add_alertmanager_flags, -mesh.listen-address={{ .Values.conf.command_flags.mesh.listen_address }} \ -mesh.peer={{ .Values.conf.command_flags.mesh.peers }} \ -storage.path={{ .Values.conf.command_flags.storage.path }}, -storage.path=/var/lib/alertmanager/data,19,2
openstack%2Fmistral~master~I4fdbc4f6bc03936091e81c8f530a41a5139d7ec8,openstack/mistral,master,I4fdbc4f6bc03936091e81c8f530a41a5139d7ec8,Updated from global requirements,MERGED,2017-12-19 01:23:25.000000000,2017-12-19 06:13:30.000000000,2017-12-19 06:13:30.000000000,"[{'_account_id': 8731}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-19 01:23:25.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/mistral/commit/9b356b6486753efc388ebee4f8014c79fc733ef3', 'message': 'Updated from global requirements\n\nChange-Id: I4fdbc4f6bc03936091e81c8f530a41a5139d7ec8\n'}]",0,528872,9b356b6486753efc388ebee4f8014c79fc733ef3,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I4fdbc4f6bc03936091e81c8f530a41a5139d7ec8
",git fetch https://review.opendev.org/openstack/mistral refs/changes/72/528872/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9b356b6486753efc388ebee4f8014c79fc733ef3,openstack/requirements,oslo.utils>=3.33.0 # Apache-2.0,oslo.utils>=3.31.0 # Apache-2.0,1,1
openstack%2Fcongress~master~I6c439b039ff7eb78325bf5d44756b81f46d37032,openstack/congress,master,I6c439b039ff7eb78325bf5d44756b81f46d37032,Updated from global requirements,MERGED,2017-12-19 01:13:51.000000000,2017-12-19 06:13:14.000000000,2017-12-19 06:13:14.000000000,"[{'_account_id': 11278}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-19 01:13:51.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/congress/commit/11236f4545027a89ff5c4114469d9078fdd65bb3', 'message': 'Updated from global requirements\n\nChange-Id: I6c439b039ff7eb78325bf5d44756b81f46d37032\n'}]",0,528855,11236f4545027a89ff5c4114469d9078fdd65bb3,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I6c439b039ff7eb78325bf5d44756b81f46d37032
",git fetch https://review.opendev.org/openstack/congress refs/changes/55/528855/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,11236f4545027a89ff5c4114469d9078fdd65bb3,openstack/requirements,oslo.utils>=3.33.0 # Apache-2.0,oslo.utils>=3.31.0 # Apache-2.0,1,1
openstack%2Fkolla-ansible~master~I9ecd500035146134ec40e48aaacbe534fed03910,openstack/kolla-ansible,master,I9ecd500035146134ec40e48aaacbe534fed03910,Add missing check.yml in redis role,ABANDONED,2017-12-19 05:55:42.000000000,2017-12-19 06:05:24.000000000,,[],"[{'number': 1, 'created': '2017-12-19 05:55:42.000000000', 'files': ['ansible/roles/redis/tasks/check.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/14cf65d99baddefd722b441983a8e4b6f005353f', 'message': 'Add missing check.yml in redis role\n\nChange-Id: I9ecd500035146134ec40e48aaacbe534fed03910\nCloses-Bug: #1738801\n'}]",0,528958,14cf65d99baddefd722b441983a8e4b6f005353f,2,0,1,27515,,,0,"Add missing check.yml in redis role

Change-Id: I9ecd500035146134ec40e48aaacbe534fed03910
Closes-Bug: #1738801
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/58/528958/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/redis/tasks/check.yml'],1,14cf65d99baddefd722b441983a8e4b6f005353f,bug/1738801,"--- - name: Redis ping pong check command: ""docker exec redis redis-cli -h {{ api_interface_address }} -a {{ redis_master_password }} ping"" register: redis_check changed_when: ""redis_check.stdout != 'PONG'"" failed_when: ""redis_check.stdout != 'PONG'"" ",,6,0
openstack%2Fnetworking-ovn~master~Ia49c674fc532ce5eaac69b0de3ae1672daa31145,openstack/networking-ovn,master,Ia49c674fc532ce5eaac69b0de3ae1672daa31145,Imported Translations from Zanata,MERGED,2017-12-13 06:38:45.000000000,2017-12-19 05:59:33.000000000,2017-12-19 05:59:33.000000000,"[{'_account_id': 6773}, {'_account_id': 8788}, {'_account_id': 22348}, {'_account_id': 23458}]","[{'number': 1, 'created': '2017-12-13 06:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b42cc41309c5a56127720e8655e42050ee7dcdfe', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ia49c674fc532ce5eaac69b0de3ae1672daa31145\n'}, {'number': 2, 'created': '2017-12-14 06:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/cc4ab157ba2071325af81ec1494552f797b643d9', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ia49c674fc532ce5eaac69b0de3ae1672daa31145\n'}, {'number': 3, 'created': '2017-12-15 06:29:12.000000000', 'files': ['networking_ovn/locale/en_GB/LC_MESSAGES/networking_ovn.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/21f165e8d6dd9d0ae1af3f6571c2d686b8431771', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ia49c674fc532ce5eaac69b0de3ae1672daa31145\n'}]",0,527599,21f165e8d6dd9d0ae1af3f6571c2d686b8431771,15,4,3,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ia49c674fc532ce5eaac69b0de3ae1672daa31145
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/99/527599/3 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/locale/en_GB/LC_MESSAGES/networking_ovn.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po']",2,b42cc41309c5a56127720e8655e42050ee7dcdfe,zanata/translations,"""POT-Creation-Date: 2017-12-13 03:43+0000\n""""PO-Revision-Date: 2017-12-12 09:16+0000\n""msgid ""4.0.0.0b2"" msgstr ""4.0.0.0b2"" ""Now distributed floating IP is supported and a new configuration option "" ""``enable_distributed_floating_ip`` is added to ovn group to control the "" ""feature."" msgstr """" ""Now distributed Floating IP is supported and a new configuration option "" ""``enable_distributed_floating_ip`` is added to ovn group to control the "" ""feature."" msgid """"msgid ""Support distributed floating IP."" msgstr ""Support distributed Floating IP."" ""networking-ovn ML2 mechanism driver now supports binding of direct(SR-IOV) "" ""ports. Traffic Control(TC) hardware offload framework for SR-IOV VFs was "" ""introduced in Linux kernel 4.8. Open vSwitch(OVS) 2.8 supports offloading "" ""OVS datapath rules using the TC framework. By using OVS version 2.8 and "" ""Linux kernel >= 4.8, a SR-IOV VF can be controlled via Openflow control "" ""plane."" msgstr """" ""networking-ovn ML2 mechanism driver now supports binding of direct(SR-IOV) "" ""ports. Traffic Control(TC) hardware offload framework for SR-IOV VFs was "" ""introduced in Linux kernel 4.8. Open vSwitch(OVS) 2.8 supports offloading "" ""OVS datapath rules using the TC framework. By using OVS version 2.8 and "" ""Linux kernel >= 4.8, a SR-IOV VF can be controlled via Openflow control "" ""plane."" msgid """" msgid ""support for binding a SR-IOV port in a networking-ovn deployment."" msgstr ""support for binding a SR-IOV port in a networking-ovn deployment.""","""POT-Creation-Date: 2017-11-30 15:55+0000\n""""PO-Revision-Date: 2017-10-17 07:17+0000\n""",416,2
openstack%2Fheat~master~I5b5b16189d6618759f7caef8e7bd61213a45f2e3,openstack/heat,master,I5b5b16189d6618759f7caef8e7bd61213a45f2e3,Updated from global requirements,MERGED,2017-12-15 21:28:45.000000000,2017-12-19 05:58:34.000000000,2017-12-19 05:58:34.000000000,"[{'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 21:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f1b597fa0634efc9589eb4c64b360b9b9be24627', 'message': 'Updated from global requirements\n\nChange-Id: I5b5b16189d6618759f7caef8e7bd61213a45f2e3\n'}, {'number': 2, 'created': '2017-12-19 01:16:39.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/622af9952b9fceae328d815ceb7f651c2cb73c61', 'message': 'Updated from global requirements\n\nChange-Id: I5b5b16189d6618759f7caef8e7bd61213a45f2e3\n'}]",0,528401,622af9952b9fceae328d815ceb7f651c2cb73c61,14,2,2,11131,,,0,"Updated from global requirements

Change-Id: I5b5b16189d6618759f7caef8e7bd61213a45f2e3
",git fetch https://review.opendev.org/openstack/heat refs/changes/01/528401/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f1b597fa0634efc9589eb4c64b360b9b9be24627,openstack/requirements,"oslo.service!=1.28.1,>=1.24.0 # Apache-2.0",oslo.service>=1.24.0 # Apache-2.0,1,1
openstack%2Ftacker~master~I63e4c90db9395781f52782b65def9c5273c0c749,openstack/tacker,master,I63e4c90db9395781f52782b65def9c5273c0c749,Update the documention for doc migration,ABANDONED,2017-08-02 02:56:59.000000000,2017-12-19 05:54:53.000000000,,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 16237}, {'_account_id': 19930}, {'_account_id': 20560}]","[{'number': 1, 'created': '2017-08-02 02:56:59.000000000', 'files': ['doc/source/user/vnffg_usage_guide.rst', 'doc/source/user/scale_usage_guide.rst', 'doc/source/user/multisite_vim_usage_guide.rst'], 'web_link': 'https://opendev.org/openstack/tacker/commit/68e8be3528c35710ab46ca86b99c5e18db4c052f', 'message': 'Update the documention for doc migration\n\nChange-Id: I63e4c90db9395781f52782b65def9c5273c0c749\n'}]",0,489833,68e8be3528c35710ab46ca86b99c5e18db4c052f,9,5,1,25073,,,0,"Update the documention for doc migration

Change-Id: I63e4c90db9395781f52782b65def9c5273c0c749
",git fetch https://review.opendev.org/openstack/tacker refs/changes/33/489833/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/vnffg_usage_guide.rst', 'doc/source/user/scale_usage_guide.rst', 'doc/source/user/multisite_vim_usage_guide.rst']",3,68e8be3528c35710ab46ca86b99c5e18db4c052f,doc-migration,.. _manual installation: https://docs.openstack.org/tacker/latest/install/manual_installation.html#registering-default-vim,.. _manual installation: http://docs.openstack.org/developer/tacker/install/manual_installation.html#registering-default-vim,3,3
openstack%2Fpython-barbicanclient~master~Id93609bb6acd1f3eb74d2c812c57d148d585fd30,openstack/python-barbicanclient,master,Id93609bb6acd1f3eb74d2c812c57d148d585fd30,Fix some reST field lists in docstrings,ABANDONED,2017-09-29 00:59:08.000000000,2017-12-19 05:54:14.000000000,,"[{'_account_id': 19554}, {'_account_id': 19930}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-09-29 00:59:08.000000000', 'files': ['functionaltests/cli/v1/behaviors/container_behaviors.py', 'functionaltests/cli/v1/behaviors/secret_behaviors.py', 'functionaltests/utils.py', 'functionaltests/cli/v1/behaviors/acl_behaviors.py'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/8427ade3cb08e6d5e194dd6fe69ad71ee59c0820', 'message': 'Fix some reST field lists in docstrings\n\nProbably the most common format for documenting arguments is reST field\nlists [1]. This change updates some docstrings to comply with the field\nlists syntax.\n[1] http://www.sphinx-doc.org/en/stable/domains.html#info-field-lists\n\nChange-Id: Id93609bb6acd1f3eb74d2c812c57d148d585fd30\n'}]",0,508377,8427ade3cb08e6d5e194dd6fe69ad71ee59c0820,6,3,1,25073,,,0,"Fix some reST field lists in docstrings

Probably the most common format for documenting arguments is reST field
lists [1]. This change updates some docstrings to comply with the field
lists syntax.
[1] http://www.sphinx-doc.org/en/stable/domains.html#info-field-lists

Change-Id: Id93609bb6acd1f3eb74d2c812c57d148d585fd30
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/77/508377/1 && git format-patch -1 --stdout FETCH_HEAD,"['functionaltests/cli/v1/behaviors/container_behaviors.py', 'functionaltests/cli/v1/behaviors/secret_behaviors.py', 'functionaltests/utils.py', 'functionaltests/cli/v1/behaviors/acl_behaviors.py']",4,8427ade3cb08e6d5e194dd6fe69ad71ee59c0820,doc-migration, :return: If error returns stderr string otherwise returns None. :return: dict of 'read' operation ACL settings if found otherwise empty :return: dict of 'read' operation ACL settings if found otherwise empty :return: dict of 'read' operation ACL settings if found otherwise empty :return: dict of 'read' operation ACL settings if found otherwise empty, :return If error returns stderr string otherwise returns None. :return dict of 'read' operation ACL settings if found otherwise empty :return dict of 'read' operation ACL settings if found otherwise empty :return dict of 'read' operation ACL settings if found otherwise empty :return dict of 'read' operation ACL settings if found otherwise empty,9,9
openstack%2Fpython-tackerclient~master~Ifdf9aa3a03d268ba13c2d7c2f15ec728b909c37d,openstack/python-tackerclient,master,Ifdf9aa3a03d268ba13c2d7c2f15ec728b909c37d,Update the documentation link for doc migration,MERGED,2017-08-03 06:32:46.000000000,2017-12-19 05:00:58.000000000,2017-12-19 05:00:58.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 16237}, {'_account_id': 17130}, {'_account_id': 18955}, {'_account_id': 19930}, {'_account_id': 22348}, {'_account_id': 25073}, {'_account_id': 25903}]","[{'number': 1, 'created': '2017-08-03 06:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/48cac94b606eb6129309debb8125c8ce472f35b2', 'message': 'Update the documentation link for doc migration\n\nThis patch is proposed according to the Direction 10 of doc\nmigration(https://etherpad.openstack.org/p/doc-migration-tracking).\n\nChange-Id: Ifdf9aa3a03d268ba13c2d7c2f15ec728b909c37d\n'}, {'number': 2, 'created': '2017-10-12 06:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/d4334791df462a6e3a767dae2a2b08a40e80fbd3', 'message': 'Update the documentation link for doc migration\n\nThis patch is proposed according to the Direction 10 of doc\nmigration(https://etherpad.openstack.org/p/doc-migration-tracking).\n\nChange-Id: Ifdf9aa3a03d268ba13c2d7c2f15ec728b909c37d\n'}, {'number': 3, 'created': '2017-12-19 03:13:34.000000000', 'files': ['README.rst', 'setup.cfg', 'tackerclient/common/_i18n.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/5881bec6a647cfd17cd142fb60d1b9721985c053', 'message': 'Update the documentation link for doc migration\n\nThis patch is proposed according to the Direction 10 of doc\nmigration(https://etherpad.openstack.org/p/doc-migration-tracking).\n\nChange-Id: Ifdf9aa3a03d268ba13c2d7c2f15ec728b909c37d\n'}]",1,490344,5881bec6a647cfd17cd142fb60d1b9721985c053,20,9,3,25073,,,0,"Update the documentation link for doc migration

This patch is proposed according to the Direction 10 of doc
migration(https://etherpad.openstack.org/p/doc-migration-tracking).

Change-Id: Ifdf9aa3a03d268ba13c2d7c2f15ec728b909c37d
",git fetch https://review.opendev.org/openstack/python-tackerclient refs/changes/44/490344/2 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tackerclient/common/_i18n.py', 'HACKING.rst']",3,48cac94b606eb6129309debb8125c8ce472f35b2,doc-migration, https://docs.openstack.org/hacking/latest, http://docs.openstack.org/developer/hacking/,3,3
openstack%2Fhorizon~stable%2Fpike~I773ce1eec3ca33bf2694512a53c03993d1576d64,openstack/horizon,stable/pike,I773ce1eec3ca33bf2694512a53c03993d1576d64,Imported Translations from Zanata,MERGED,2017-12-16 07:37:34.000000000,2017-12-19 04:51:13.000000000,2017-12-19 04:51:13.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 11885}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-16 07:37:34.000000000', 'files': ['openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'horizon/locale/eo/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/djangojs.po', 'horizon/locale/ar/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/id/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/50dac5e2da3dc7d2aa736284b6f16affcb4daa53', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I773ce1eec3ca33bf2694512a53c03993d1576d64\n'}]",0,528455,50dac5e2da3dc7d2aa736284b6f16affcb4daa53,8,4,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I773ce1eec3ca33bf2694512a53c03993d1576d64
",git fetch https://review.opendev.org/openstack/horizon refs/changes/55/528455/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'horizon/locale/eo/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/djangojs.po', 'horizon/locale/ar/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/id/LC_MESSAGES/djangojs.po']",6,50dac5e2da3dc7d2aa736284b6f16affcb4daa53,zanata/translations,"""Project-Id-Version: horizon 12.0.2.dev10\n""""POT-Creation-Date: 2017-12-14 03:56+0000\n""""PO-Revision-Date: 2017-10-22 03:22+0000\n""""There are no allowed boot\n"" "" sources. If you think this is wrong please contact your administrator."" msgstr """" ""Tidak ada boot yang diizinkan\n"" "" sumber. Jika menurut anda ini salah silahkan hubungi administrator "" ""anda."" msgid """"","""Project-Id-Version: horizon 12.0.1.dev23\n""""POT-Creation-Date: 2017-10-07 17:45+0000\n""""PO-Revision-Date: 2017-08-09 07:26+0000\n""",881,16
openstack%2Fzun-tempest-plugin~master~Iebb6f1604a0b02919ad7419f42b4ecab47486021,openstack/zun-tempest-plugin,master,Iebb6f1604a0b02919ad7419f42b4ecab47486021,Fix Zun-tempest-plugin's documentation,MERGED,2017-12-14 04:39:54.000000000,2017-12-19 04:48:43.000000000,2017-12-19 04:48:43.000000000,"[{'_account_id': 3}, {'_account_id': 10206}, {'_account_id': 22076}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-14 04:39:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun-tempest-plugin/commit/b863a879182b70702cc7f4c69fcd6fd456b3613b', 'message': ""[WIP] Fix Zun-tempest-plugin's documentation return 404\n\nChange-Id: Iebb6f1604a0b02919ad7419f42b4ecab47486021\nCloses-Bug: #1738111\n""}, {'number': 2, 'created': '2017-12-14 07:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun-tempest-plugin/commit/7a10bf3ce377890b9334642a26a94d1857944d9d', 'message': ""[WIP] Fix Zun-tempest-plugin's documentation\n\nDepends-On: Ibddeacd8d04a063db8046c36226d96fed8273e4b\nChange-Id: Iebb6f1604a0b02919ad7419f42b4ecab47486021\n""}, {'number': 3, 'created': '2017-12-19 00:55:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun-tempest-plugin/commit/15c38c488a3af08b7b33c87112f7ca0dee271902', 'message': ""Fix Zun-tempest-plugin's documentation\n\nChange-Id: Iebb6f1604a0b02919ad7419f42b4ecab47486021\n""}, {'number': 4, 'created': '2017-12-19 01:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun-tempest-plugin/commit/cfa0a0abdbca7e3f08909e0c52c67b98678890df', 'message': ""Fix Zun-tempest-plugin's documentation\n\nChange-Id: Iebb6f1604a0b02919ad7419f42b4ecab47486021\n""}, {'number': 5, 'created': '2017-12-19 03:10:47.000000000', 'files': ['doc/source/index.rst', 'test-requirements.txt', 'README.rst', 'doc/source/conf.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/zun-tempest-plugin/commit/c7977097366870bd5afbdb27a82ef1e3eee1e280', 'message': ""Fix Zun-tempest-plugin's documentation\n\nChange-Id: Iebb6f1604a0b02919ad7419f42b4ecab47486021\n""}]",0,527851,c7977097366870bd5afbdb27a82ef1e3eee1e280,15,4,5,22406,,,0,"Fix Zun-tempest-plugin's documentation

Change-Id: Iebb6f1604a0b02919ad7419f42b4ecab47486021
",git fetch https://review.opendev.org/openstack/zun-tempest-plugin refs/changes/51/527851/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'test-requirements.txt', 'doc/source/conf.py', 'doc/source/readme.rst', 'tox.ini']",5,b863a879182b70702cc7f4c69fcd6fd456b3613b,bug/1738111,commands = doc8 -e .rst doc/source/ CONTRIBUTING.rst HACKING.rst README.rst python setup.py build_sphinx,commands = python setup.py build_sphinx,10,6
openstack%2Fosprofiler~master~Ia9763605db95b3f35c8b0e51211f96ee0dd3a82d,openstack/osprofiler,master,Ia9763605db95b3f35c8b0e51211f96ee0dd3a82d,Make collector configurable in DevStack plugin,MERGED,2017-12-12 14:00:31.000000000,2017-12-19 04:23:49.000000000,2017-12-19 04:23:49.000000000,"[{'_account_id': 3012}, {'_account_id': 5950}, {'_account_id': 21470}, {'_account_id': 22348}, {'_account_id': 23630}]","[{'number': 1, 'created': '2017-12-12 14:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/ab4c16948c85dd94ca2b271e14552872bbce56a8', 'message': 'Make collector configurable in DevStack plugin\n\nIn DevStack OSProfiler is by default configured to use messaging driver\nwith Ceilometer backend. User can change the driver, but still needs\nto install storage manually. This patch introduces configuration\noption `OSPROFILER_COLLECTOR` which is used to specify which\nstorage to install into DevStack. Currently 2 values are supported:\n * `redis` to install Redis server\n * <empty> to keep the default behavior\n\nChange-Id: Ia9763605db95b3f35c8b0e51211f96ee0dd3a82d\n'}, {'number': 2, 'created': '2017-12-14 13:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/8b8994406e79befb74c01140b6e3850b9c976950', 'message': 'Make collector configurable in DevStack plugin\n\nIn DevStack OSProfiler is by default configured to use messaging driver\nwith Ceilometer backend. User can change the driver, but still needs\nto install storage manually. This patch introduces configuration\noption `OSPROFILER_COLLECTOR` which is used to specify which\nstorage to install into DevStack. Currently 2 values are supported:\n * `redis` to install Redis server\n * <empty> to keep the default behavior\n\nChange-Id: Ia9763605db95b3f35c8b0e51211f96ee0dd3a82d\n'}, {'number': 3, 'created': '2017-12-15 10:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/79f9f7b1981566a915a1848fdbaee409c0ea2dd5', 'message': 'Make collector configurable in DevStack plugin\n\nIn DevStack OSProfiler is by default configured to use messaging\ndriver with Ceilometer backend. User can change the driver, but\nstill needs to install collector/storage manually. This patch\nintroduces configuration option `OSPROFILER_COLLECTOR` which is\nused to specify which collector/storage to install into DevStack.\n\nCurrently 2 values are supported:\n * `redis` to install Redis server and use Redis driver\n * <empty> to keep the default behavior and use messaging driver\n\nTo test the patch on DevStack, the following lines are needed in local.conf:\n  enable_plugin osprofiler https://git.openstack.org/openstack/osprofiler refs/changes/06/527406/3\n  OSPROFILER_BRANCH=refs/changes/06/527406/3\n  OSPROFILER_COLLECTOR=redis\n\nChange-Id: Ia9763605db95b3f35c8b0e51211f96ee0dd3a82d\n'}, {'number': 4, 'created': '2017-12-15 10:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/54678c6e1b4b99c7bb73a1f6a6af98f528009dda', 'message': 'Make collector configurable in DevStack plugin\n\nIn DevStack OSProfiler is by default configured to use messaging\ndriver with Ceilometer backend. User can change the driver, but\nstill needs to install collector/storage manually. This patch\nintroduces configuration option `OSPROFILER_COLLECTOR` which is\nused to specify which collector/storage to install into DevStack.\n\nCurrently 2 values are supported:\n * `redis` to install Redis server and use Redis driver\n * <empty> to keep the default behavior and use messaging driver\n\nTo test the patch on DevStack, the following lines are needed in local.conf:\n  enable_plugin osprofiler https://git.openstack.org/openstack/osprofiler refs/changes/06/527406/4\n  OSPROFILER_BRANCH=refs/changes/06/527406/4\n  OSPROFILER_COLLECTOR=redis\n\nChange-Id: Ia9763605db95b3f35c8b0e51211f96ee0dd3a82d\n'}, {'number': 5, 'created': '2017-12-15 14:09:42.000000000', 'files': ['devstack/plugin.sh', 'devstack/lib/osprofiler', 'devstack/README.rst', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/f15a7e47e6b9c088a2f3ab8f6d760a519cfafcd2', 'message': 'Make collector configurable in DevStack plugin\n\nIn DevStack OSProfiler is by default configured to use messaging\ndriver with Ceilometer backend. User can change the driver, but\nstill needs to install collector/storage manually. This patch\nintroduces configuration option `OSPROFILER_COLLECTOR` which is\nused to specify which collector/storage to install into DevStack.\n\nCurrently 2 values are supported:\n * `redis` to install Redis server and use Redis driver\n * <empty> to keep the default behavior and use messaging driver\n\nTo test the patch on DevStack, the following lines are needed in local.conf:\n  enable_plugin osprofiler https://git.openstack.org/openstack/osprofiler refs/changes/06/527406/5\n  OSPROFILER_BRANCH=refs/changes/06/527406/5\n  OSPROFILER_COLLECTOR=redis\n\nChange-Id: Ia9763605db95b3f35c8b0e51211f96ee0dd3a82d\n'}]",4,527406,f15a7e47e6b9c088a2f3ab8f6d760a519cfafcd2,18,5,5,5950,,,0,"Make collector configurable in DevStack plugin

In DevStack OSProfiler is by default configured to use messaging
driver with Ceilometer backend. User can change the driver, but
still needs to install collector/storage manually. This patch
introduces configuration option `OSPROFILER_COLLECTOR` which is
used to specify which collector/storage to install into DevStack.

Currently 2 values are supported:
 * `redis` to install Redis server and use Redis driver
 * <empty> to keep the default behavior and use messaging driver

To test the patch on DevStack, the following lines are needed in local.conf:
  enable_plugin osprofiler https://git.openstack.org/openstack/osprofiler refs/changes/06/527406/5
  OSPROFILER_BRANCH=refs/changes/06/527406/5
  OSPROFILER_COLLECTOR=redis

Change-Id: Ia9763605db95b3f35c8b0e51211f96ee0dd3a82d
",git fetch https://review.opendev.org/openstack/osprofiler refs/changes/06/527406/3 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/plugin.sh', 'devstack/lib/osprofiler', 'devstack/README.rst', 'devstack/settings']",4,ab4c16948c85dd94ca2b271e14552872bbce56a8,redis-collector,,"OSPROFILER_CONNECTION_STRING=${OSPROFILER_CONNECTION_STRING:-""messaging://""}",76,17
openstack%2Frequirements~master~I89a80cc5b90bf4f81ed4345cf0fa9c5111437365,openstack/requirements,master,I89a80cc5b90bf4f81ed4345cf0fa9c5111437365,Updated from generate-constraints,MERGED,2017-12-15 06:15:42.000000000,2017-12-19 04:18:40.000000000,2017-12-19 04:18:40.000000000,"[{'_account_id': 6593}, {'_account_id': 12898}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 06:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/023bdbfe250bfcba0be58cc6f961c3a3e5f02b64', 'message': 'Updated from generate-constraints\n\nChange-Id: I89a80cc5b90bf4f81ed4345cf0fa9c5111437365\n'}, {'number': 2, 'created': '2017-12-18 06:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/917ac213c10d6f72b676e23703470790bb34b332', 'message': 'Updated from generate-constraints\n\nChange-Id: I89a80cc5b90bf4f81ed4345cf0fa9c5111437365\n'}, {'number': 3, 'created': '2017-12-18 21:27:44.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/942b9a99c168a00b28a4888109f046c694b053bf', 'message': 'Updated from generate-constraints\n\nChange-Id: I89a80cc5b90bf4f81ed4345cf0fa9c5111437365\n'}]",0,528161,942b9a99c168a00b28a4888109f046c694b053bf,13,3,3,11131,,,0,"Updated from generate-constraints

Change-Id: I89a80cc5b90bf4f81ed4345cf0fa9c5111437365
",git fetch https://review.opendev.org/openstack/requirements refs/changes/61/528161/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,023bdbfe250bfcba0be58cc6f961c3a3e5f02b64,openstack/requirements/constraints,grpcio===1.8.0oslo.serialization===2.22.0keystonemiddleware===4.19.0iso8601===0.1.12pika===0.11.2python-magic===0.4.15kubernetes===4.0.0tenacity===4.8.0,grpcio===1.7.3python-magic===0.4.13oslo.serialization===2.21.1keystonemiddleware===4.18.0iso8601===0.1.11pika===0.10.0kubernetes===2.0.0tenacity===4.7.1,8,8
openstack%2Frequirements~master~I466b98a0645fbac73ad33b52178bcfbef14bfad3,openstack/requirements,master,I466b98a0645fbac73ad33b52178bcfbef14bfad3,Add cinder-tempest-plugin repo for updates,MERGED,2017-12-02 11:32:23.000000000,2017-12-19 04:18:39.000000000,2017-12-19 04:18:39.000000000,"[{'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-02 11:32:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/9226659911843e352f77545ac51f13bab93dde98', 'message': 'Add cinder-tempest-plugin repo for updates\n\nRequirements updates needed for new repo for split of in-tree tempest\ntests.\n\nChange-Id: I466b98a0645fbac73ad33b52178bcfbef14bfad3\n'}, {'number': 2, 'created': '2017-12-13 20:02:04.000000000', 'files': ['projects.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6fbf5cba95d8516f110326e7bece558cbb294e63', 'message': 'Add cinder-tempest-plugin repo for updates\n\nRequirements updates needed for new repo for split of in-tree tempest\ntests.\n\nDepends-on: I1a8b1be63f20c61ff2817e1202076cc9f177c8a1\n\nChange-Id: I466b98a0645fbac73ad33b52178bcfbef14bfad3\n'}]",0,524861,6fbf5cba95d8516f110326e7bece558cbb294e63,13,4,2,11904,,,0,"Add cinder-tempest-plugin repo for updates

Requirements updates needed for new repo for split of in-tree tempest
tests.

Depends-on: I1a8b1be63f20c61ff2817e1202076cc9f177c8a1

Change-Id: I466b98a0645fbac73ad33b52178bcfbef14bfad3
",git fetch https://review.opendev.org/openstack/requirements refs/changes/61/524861/1 && git format-patch -1 --stdout FETCH_HEAD,['projects.txt'],1,9226659911843e352f77545ac51f13bab93dde98,goal-split-tempest-plugin,openstack/cinder-tempest-plugin,,1,0
openstack%2Frequirements~master~I078b4cbb1f7dbea5bb56771acf68dcdbfb942205,openstack/requirements,master,I078b4cbb1f7dbea5bb56771acf68dcdbfb942205,update constraint for taskflow to new release 3.0.1,MERGED,2017-12-18 13:02:29.000000000,2017-12-19 04:18:38.000000000,2017-12-19 04:18:38.000000000,"[{'_account_id': 6593}, {'_account_id': 14288}, {'_account_id': 17130}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 13:02:29.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a2b8928fecebafd407c33387c792bcaadf4932f3', 'message': 'update constraint for taskflow to new release 3.0.1\n\nChange-Id: I078b4cbb1f7dbea5bb56771acf68dcdbfb942205\nmeta:version: 3.0.1\nmeta:diff-start: -\nmeta:series: queens\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Change-Id: I076de697e1a13bc106b488894b062a58c7c51f7a\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,528710,a2b8928fecebafd407c33387c792bcaadf4932f3,9,4,1,11131,,,0,"update constraint for taskflow to new release 3.0.1

Change-Id: I078b4cbb1f7dbea5bb56771acf68dcdbfb942205
meta:version: 3.0.1
meta:diff-start: -
meta:series: queens
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Change-Id: I076de697e1a13bc106b488894b062a58c7c51f7a
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/10/528710/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,a2b8928fecebafd407c33387c792bcaadf4932f3,new-release,taskflow===3.0.1,taskflow===3.0.0,1,1
openstack%2Fmanila~master~Iacf62484110250ff1f7763b037bab73603d002af,openstack/manila,master,Iacf62484110250ff1f7763b037bab73603d002af,Updated from global requirements,MERGED,2017-12-19 01:22:40.000000000,2017-12-19 04:04:37.000000000,2017-12-19 02:12:29.000000000,"[{'_account_id': 2417}, {'_account_id': 9003}, {'_account_id': 12017}, {'_account_id': 15100}, {'_account_id': 15942}, {'_account_id': 16657}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2017-12-19 01:22:40.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/manila/commit/daf509b66fdf5ddaa576e947d9fceeac5a017fc6', 'message': 'Updated from global requirements\n\nChange-Id: Iacf62484110250ff1f7763b037bab73603d002af\n'}]",0,528870,daf509b66fdf5ddaa576e947d9fceeac5a017fc6,17,12,1,11131,,,0,"Updated from global requirements

Change-Id: Iacf62484110250ff1f7763b037bab73603d002af
",git fetch https://review.opendev.org/openstack/manila refs/changes/70/528870/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,daf509b66fdf5ddaa576e947d9fceeac5a017fc6,openstack/requirements,oslo.utils>=3.33.0 # Apache-2.0,oslo.utils>=3.31.0 # Apache-2.0,1,1
openstack%2Foslo.messaging~master~I3d8c70f66931c15247b530ff7e1c89bfc753446f,openstack/oslo.messaging,master,I3d8c70f66931c15247b530ff7e1c89bfc753446f,Create doc/requirements.txt,MERGED,2017-12-11 18:59:39.000000000,2017-12-19 03:59:03.000000000,2017-12-19 03:59:03.000000000,"[{'_account_id': 2472}, {'_account_id': 6547}, {'_account_id': 8770}, {'_account_id': 9796}, {'_account_id': 20523}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 18:59:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f110ba7fbbc72aad0971de8e6055eafed1ebd48c', 'message': 'Create doc/requirements.txt\n\nFor compliance with the Project Testing Interface.\n\nChange-Id: I3d8c70f66931c15247b530ff7e1c89bfc753446f\n'}, {'number': 2, 'created': '2017-12-18 20:12:43.000000000', 'files': ['doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c7cc6d0742d989f0498bcfa13d362a1421e2d12a', 'message': 'Create doc/requirements.txt\n\nFor compliance with the Project Testing Interface as described in:\n\nhttps://governance.openstack.org/tc/reference/project-testing-interface.html\n\nRefer to:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-November/124815.html\n\nChange-Id: I3d8c70f66931c15247b530ff7e1c89bfc753446f\n'}]",1,527212,c7cc6d0742d989f0498bcfa13d362a1421e2d12a,17,6,2,8770,,,0,"Create doc/requirements.txt

For compliance with the Project Testing Interface as described in:

https://governance.openstack.org/tc/reference/project-testing-interface.html

Refer to:

http://lists.openstack.org/pipermail/openstack-dev/2017-November/124815.html

Change-Id: I3d8c70f66931c15247b530ff7e1c89bfc753446f
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/12/527212/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/requirements.txt'],1,f110ba7fbbc72aad0971de8e6055eafed1ebd48c,updated-pti,"# The order of packages is significant, because pip processes them in the order # of appearance. Changing the order has an impact on the overall integration # process, which may cause wedges in the gate later. openstackdocstheme>=1.17.0 # Apache-2.0 sphinx>=1.6.2 # BSD reno>=2.5.0 # Apache-2.0 # imported by the code during source code parsing: fixtures>=3.0.0 # Apache-2.0/BSD kafka-python>=1.3.1 # Apache-2.0 pyngus>=2.2.0 # Apache-2.0 ",,11,0
openstack%2Ftripleo-heat-templates~master~Ib105f60a1e54a6d6372d00bb2db6a9b378b2176e,openstack/tripleo-heat-templates,master,Ib105f60a1e54a6d6372d00bb2db6a9b378b2176e,"Add ""clean"" tox target",MERGED,2017-12-13 23:21:41.000000000,2017-12-19 03:54:55.000000000,2017-12-19 03:54:55.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 23:21:41.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f66df2ec12254b26b14fec68b09d0b21fe483329', 'message': 'Add ""clean"" tox target\n\nThis uses the -c parameter to process-templates.py to clean the\ngenerated templates in the local repo.\n\nChange-Id: Ib105f60a1e54a6d6372d00bb2db6a9b378b2176e\n'}]",0,527806,f66df2ec12254b26b14fec68b09d0b21fe483329,8,4,1,6928,,,0,"Add ""clean"" tox target

This uses the -c parameter to process-templates.py to clean the
generated templates in the local repo.

Change-Id: Ib105f60a1e54a6d6372d00bb2db6a9b378b2176e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/06/527806/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f66df2ec12254b26b14fec68b09d0b21fe483329,clean-templates,[testenv:clean] commands = python ./tools/process-templates.py -c ,,3,0
openstack%2Foslo.privsep~master~If4bdb9569236927449648a8b750ae0fa2da76f53,openstack/oslo.privsep,master,If4bdb9569236927449648a8b750ae0fa2da76f53,add bandit to pep8 job,MERGED,2017-11-30 05:28:32.000000000,2017-12-19 03:53:11.000000000,2017-12-19 03:53:11.000000000,"[{'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 8119}, {'_account_id': 9796}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-30 05:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/d21684aa1c069f514ea71daaad761f5d846db11a', 'message': '[WIP]add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\n\nChange-Id: If4bdb9569236927449648a8b750ae0fa2da76f53\n'}, {'number': 2, 'created': '2017-12-12 06:23:57.000000000', 'files': ['test-requirements.txt', 'oslo_privsep/tests/test_priv_context.py', 'oslo_privsep/priv_context.py', 'oslo_privsep/comm.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/518a811b9fd1fc776b0f37ce67fdc1135e59b3ee', 'message': ""add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\n* convert assert statement to raise AssertionError\n* Don't hard code temporary file path\n* skip B404,B603\n\nChange-Id: If4bdb9569236927449648a8b750ae0fa2da76f53\n""}]",0,524068,518a811b9fd1fc776b0f37ce67fdc1135e59b3ee,13,5,2,9796,,,0,"add bandit to pep8 job

Add the bandit security scanner to the pep8 job.
* convert assert statement to raise AssertionError
* Don't hard code temporary file path
* skip B404,B603

Change-Id: If4bdb9569236927449648a8b750ae0fa2da76f53
",git fetch https://review.opendev.org/openstack/oslo.privsep refs/changes/68/524068/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,d21684aa1c069f514ea71daaad761f5d846db11a,bandit,deps = -r{toxinidir}/test-requirements.txt commands = flake8 # Run security linter bandit -r oslo_privsep tests -n5,commands = flake8,9,1
openstack%2Fhorizon~master~I8dc50625e0e84fd2ce81d731bd54cbd0e08b100d,openstack/horizon,master,I8dc50625e0e84fd2ce81d731bd54cbd0e08b100d,Show volume snapshots in admin volume detail page,MERGED,2017-11-19 12:52:45.000000000,2017-12-19 03:50:16.000000000,2017-12-19 03:50:16.000000000,"[{'_account_id': 1736}, {'_account_id': 11885}, {'_account_id': 19554}, {'_account_id': 22348}, {'_account_id': 23630}]","[{'number': 1, 'created': '2017-11-19 12:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cebd8744b2e6ff78318c1276794807497c82d14e', 'message': 'Show volume snapshots in admin volume detail page\n\nTo show volume snapshots from different projects,\nwe need to specify all_tenants=True to the list operation.\n\nAlso fixes an issue that the actions in the snapshots table\nin the admin volume detail page refer to the project dashboard.\n\nChange-Id: I8dc50625e0e84fd2ce81d731bd54cbd0e08b100d\nCloses-Bug: #1733186\n'}, {'number': 2, 'created': '2017-11-19 15:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/005d94e1083c9fff634cae1f103a34e68a12d711', 'message': 'Show volume snapshots in admin volume detail page\n\nTo show volume snapshots from different projects,\nwe need to specify all_tenants=True to the list operation.\n\nAlso fixes an issue that the actions in the snapshots table\nin the admin volume detail page refer to the project dashboard.\n\nChange-Id: I8dc50625e0e84fd2ce81d731bd54cbd0e08b100d\nCloses-Bug: #1733186\n'}, {'number': 3, 'created': '2017-11-25 00:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/345d6c34445d98494b7604c448610ab295fa801a', 'message': 'Show volume snapshots in admin volume detail page\n\nTo show volume snapshots from different projects,\nwe need to specify all_tenants=True to the list operation.\n\nAlso fixes an issue that the actions in the snapshots table\nin the admin volume detail page refer to the project dashboard.\n\nChange-Id: I8dc50625e0e84fd2ce81d731bd54cbd0e08b100d\nCloses-Bug: #1733186\n'}, {'number': 4, 'created': '2017-12-09 17:07:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/629fc46d3f7fe0ab4db81747299f0817e0d77ffe', 'message': 'Show volume snapshots in admin volume detail page\n\nTo show volume snapshots from different projects,\nwe need to specify all_tenants=True to the list operation.\n\nAlso fixes an issue that the actions in the snapshots table\nin the admin volume detail page refer to the project dashboard.\n\nChange-Id: I8dc50625e0e84fd2ce81d731bd54cbd0e08b100d\nCloses-Bug: #1733186\n'}, {'number': 5, 'created': '2017-12-11 08:48:30.000000000', 'files': ['openstack_dashboard/dashboards/admin/volumes/tabs.py', 'openstack_dashboard/dashboards/admin/volumes/tests.py', 'openstack_dashboard/dashboards/admin/snapshots/tables.py', 'openstack_dashboard/dashboards/project/volumes/tabs.py', 'openstack_dashboard/dashboards/admin/volumes/views.py', 'openstack_dashboard/dashboards/project/volumes/tests.py', 'openstack_dashboard/dashboards/project/volumes/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/17b7e91472c530de4ae61abc5b97db0d5ea4b428', 'message': 'Show volume snapshots in admin volume detail page\n\nTo show volume snapshots from different projects,\nwe need to specify all_tenants=True to the list operation.\n\nAlso fixes an issue that the actions in the snapshots table\nin the admin volume detail page refer to the project dashboard.\n\nChange-Id: I8dc50625e0e84fd2ce81d731bd54cbd0e08b100d\nCloses-Bug: #1733186\n'}]",1,521367,17b7e91472c530de4ae61abc5b97db0d5ea4b428,19,5,5,841,,,0,"Show volume snapshots in admin volume detail page

To show volume snapshots from different projects,
we need to specify all_tenants=True to the list operation.

Also fixes an issue that the actions in the snapshots table
in the admin volume detail page refer to the project dashboard.

Change-Id: I8dc50625e0e84fd2ce81d731bd54cbd0e08b100d
Closes-Bug: #1733186
",git fetch https://review.opendev.org/openstack/horizon refs/changes/67/521367/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/volumes/tabs.py', 'openstack_dashboard/dashboards/project/volumes/tabs.py', 'openstack_dashboard/dashboards/admin/volumes/views.py']",3,cebd8744b2e6ff78318c1276794807497c82d14e,bug/1733186,from openstack_dashboard.dashboards.admin.volumes \ import tabs as volumes_tabs tab_group_class = volumes_tabs.VolumeDetailTabs, dashboard = 'admin',35,2
openstack%2Ftempest~master~Ibd92189d168308483e193a62aa5ecc1a0f79cb0d,openstack/tempest,master,Ibd92189d168308483e193a62aa5ecc1a0f79cb0d,Add tests for cold migration with target,ABANDONED,2017-02-14 11:36:45.000000000,2017-12-19 03:49:52.000000000,,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5689}, {'_account_id': 6873}, {'_account_id': 7350}, {'_account_id': 7634}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 11869}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 15941}, {'_account_id': 17685}, {'_account_id': 20190}, {'_account_id': 21884}, {'_account_id': 22348}, {'_account_id': 23186}, {'_account_id': 24903}, {'_account_id': 25632}]","[{'number': 1, 'created': '2017-02-14 11:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ea5726cf03119aa44b6e038eef7c916da2ff0bc2', 'message': 'Add tests for cold migration with target\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n'}, {'number': 2, 'created': '2017-02-14 11:41:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ba6bbdab75e7ae2b918c969b97a04b5958aa7bc5', 'message': 'Add tests for cold migration with target\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n'}, {'number': 3, 'created': '2017-02-28 08:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a1a4a5761a49c2165fad4bea83ef04b72ca626c3', 'message': 'Add tests for cold migration with target\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n'}, {'number': 4, 'created': '2017-02-28 08:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/32737a592087fbdda4acd3a88f994a18de8ebb34', 'message': 'Add tests for cold migration with target\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n'}, {'number': 5, 'created': '2017-02-28 11:07:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c1edc0f1f1287f83c622a08548dbef6356ee2455', 'message': 'Add tests for cold migration with target\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n'}, {'number': 6, 'created': '2017-02-28 11:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fb45a99756b9b7d0a1182624991ec45a1f38c1f9', 'message': 'Add tests for cold migration with target\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n'}, {'number': 7, 'created': '2017-03-06 05:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c2cc62492ccc8a5beb274d545ae248ed43a301df', 'message': 'Add tests for cold migration with target\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n'}, {'number': 8, 'created': '2017-03-30 08:30:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9d609c96eec019e0e59dcc364363f2d8276485ba', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 9, 'created': '2017-04-03 02:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9183162a9fa056e18a87719929d421c538b6d814', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 10, 'created': '2017-04-10 12:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/da5c5852513c56863596a0a0d26d7507de8172f5', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 11, 'created': '2017-04-13 08:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/db8a9777e34f7031836d0cc994ca7df5cd792abf', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 12, 'created': '2017-04-14 00:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dcf86178ea5dddc4bc8e7275ea904f0b6ac23ac9', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 13, 'created': '2017-04-25 07:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0cfafc787973d5ed08eb696fcd6d198d13143398', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 14, 'created': '2017-04-26 04:56:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a9b70ef313aab172e82eb7f844401a1d5f23f6ce', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 15, 'created': '2017-05-22 04:15:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3152822a839e24e7f2ce3d887ba1fcadcb254fc1', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 16, 'created': '2017-05-22 04:20:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1af3d0bac325f668d171e72d69be5ecb38fff2b6', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 17, 'created': '2017-05-25 07:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/aef6506b6f0212798bc841550c286f158ef127f0', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 18, 'created': '2017-06-05 02:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/65030f9a49d6c740da31876230426d384b4353cf', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 19, 'created': '2017-06-05 02:29:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8d4f566bde1d613a60ba9862dabe722ee198b0ac', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 20, 'created': '2017-06-12 06:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2185490d0962170eacc958b419a0d1a44bbd966f', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 21, 'created': '2017-06-12 15:49:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f166bc3076b252eb4862004be2af589345075b27', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 22, 'created': '2017-06-13 07:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2f6caf9884de892b634a50df31d08559fd625102', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 23, 'created': '2017-06-23 14:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1f8858f3551c43623f00c222acd9c0eb7bfca38b', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function (*1, *2).\n\n*1: https://blueprints.launchpad.net/nova/+spec/cold-migration-with-target-pike\n*2: https://specs.openstack.org/openstack/nova-specs/specs/pike/approved/cold-migration-with-target-pike.html\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 24, 'created': '2017-06-26 01:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/17fd3fc04e955fd82f5a98c797c4989acc3d7df0', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 25, 'created': '2017-06-28 02:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/714e6cd3ece31d88b8c0404bbd8320c853e95a04', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 26, 'created': '2017-07-03 02:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/19c12a3dd0f075bc5f7151d9e46d941b0596391a', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 27, 'created': '2017-07-03 02:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3e3ed3fa5b1ecad1177e4fbe7b15bbd178cce4f0', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 28, 'created': '2017-07-03 04:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e04136bc96175b9786a3ea6c81505d2883da8a0f', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 29, 'created': '2017-07-06 06:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cbab01d4877ba340c39de222f4c79e695d9802b4', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 30, 'created': '2017-07-06 06:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e8297b904185dce41be0db7c65a58554ff977c35', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 31, 'created': '2017-07-14 15:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/abee9163516c56b79c4b1cc56398988deee2377d', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 32, 'created': '2017-07-14 15:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ac32132b7ceab6779d6fc12bc2fb02fe35710f0e', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 33, 'created': '2017-07-15 03:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/69f0282829c8d557984775dbd5f5565bee3491f0', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 34, 'created': '2017-07-15 03:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4c352e654a7818fb1417e9a566ba5ad4a36a7edb', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 35, 'created': '2017-07-19 03:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b6c095df80abd759e248128f9783a431a7d4df8b', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 36, 'created': '2017-07-19 03:40:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6b37518794968fdbb045efe34f1c37e568038e60', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 37, 'created': '2017-07-22 11:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/955f90a468d7321c0f0f8a58b540e1fd99636a37', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 38, 'created': '2017-07-24 15:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7be37b6ecae4f11e9c127af101f9a736e6f05ce5', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 39, 'created': '2017-07-26 17:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1f92739f292b9d7d3e7ec63a096f7bcdbbea17fe', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 40, 'created': '2017-07-27 04:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cd738db6930a4a2b72bbf7fbfe53d6e1c0ef5fd2', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 41, 'created': '2017-07-31 08:19:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c96801e25a16e0f7eb3a0f89b741cdfb592d8a26', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 42, 'created': '2017-09-08 06:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6a7c92470d44e4b89b955d88c0f98d688fde539f', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-pike\n""}, {'number': 43, 'created': '2017-09-25 09:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/15d080af670dde7c368ca935f563a2146beea13b', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 44, 'created': '2017-09-25 14:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3525ca2ef243a0202231d3a09dcd8c7426618eb5', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 45, 'created': '2017-10-05 13:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a32ac590e3f4f7e52e3e2e134cbca43ae43648a4', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 46, 'created': '2017-10-11 09:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c369693f2f6ac5a9f849d3bfef52ae910926feb3', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 47, 'created': '2017-10-12 03:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4edfc29216258d1d3211a719d563386648283bd0', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 48, 'created': '2017-10-17 05:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/03c0bd72a396fd58b76e7441ccae9207d8622da4', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 49, 'created': '2017-10-23 06:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/36e293a2ba2c588710f327149cd76e857c83e656', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 50, 'created': '2017-10-26 01:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/49033b96911acbc5bed52a367ec84162f00e4794', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 51, 'created': '2017-10-26 01:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5641ed7158881b45c7ed81bf565ff18475264c40', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 52, 'created': '2017-10-30 02:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8d46ee6f6150208f9022106b634b2e0c300ee42b', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 53, 'created': '2017-11-14 23:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2bfb3e2cc77994d923ad9807bd19ccd65248b69f', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 54, 'created': '2017-11-14 23:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e3c953e31f9c8cc4f85eac8e7a8cd7fa76058571', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 55, 'created': '2017-11-15 06:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b4d45986bc1c5aa553c41809c4ab7288ad54d158', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 56, 'created': '2017-11-16 08:01:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4402ded23f223895f7595671f306d96afc147506', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 57, 'created': '2017-11-16 08:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2368477fd55c8138920e756cbf29e616b0cfdb79', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 58, 'created': '2017-11-16 23:37:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/595810e27751b7745ec2b2baf942efb65e220d88', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}, {'number': 59, 'created': '2017-11-24 06:02:38.000000000', 'files': ['tempest/api/compute/admin/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1a4781bdb03117713543f5ac1c7e00ea439f0c2e', 'message': ""Add tests for cold migration with target\n\nThe tests in this patch is added for testing the\n'cold migration with target' function.\n\nDepends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8\nChange-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d\nImplements: blueprint cold-migration-with-target-queens\n""}]",48,433602,1a4781bdb03117713543f5ac1c7e00ea439f0c2e,249,19,59,7634,,,0,"Add tests for cold migration with target

The tests in this patch is added for testing the
'cold migration with target' function.

Depends-On: Iee356c4dd097c846b6ca8617ead6a061300c83f8
Change-Id: Ibd92189d168308483e193a62aa5ecc1a0f79cb0d
Implements: blueprint cold-migration-with-target-queens
",git fetch https://review.opendev.org/openstack/tempest refs/changes/02/433602/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_migrations.py'],1,ea5726cf03119aa44b6e038eef7c916da2ff0bc2,bp/cold-migration-with-target-queens," class MigrationsAdminTestV243(base.BaseV2ComputeAdminTest): min_microversion = '2.43' max_microversion = 'latest' @classmethod def setup_clients(cls): super(MigrationsAdminTestV243, cls).setup_clients() cls.admin_servers_client = cls.os_adm.servers_client cls.hypervisor_client = cls.os_adm.hypervisor_client def _test_cold_migrate_server_with_host(self, force=False): resp = self.hypervisor_client.list_hypervisors() if (CONF.compute.min_compute_nodes < 2 or len(resp['hypervisors']) < 2): msg = ""Less than 2 compute nodes, skipping multinode tests."" raise self.skipException(msg) server = self.create_test_server(networks='none', wait_until=""ACTIVE"") src_host = self.admin_servers_client.show_server( server['id'])['server']['OS-EXT-SRV-ATTR:host'] # Get a host that is different from the source host target_host = None for hypervisor in resp['hypervisors']: if src_host == hypervisor['hypervisor_hostname']: continue else: target_host = hypervisor['hypervisor_hostname'] break self.admin_servers_client.migrate_server(server['id'], host=target_host, force=force) waiters.wait_for_server_status(self.servers_client, server['id'], 'VERIFY_RESIZE') self.servers_client.confirm_resize_server(server['id']) waiters.wait_for_server_status(self.servers_client, server['id'], 'ACTIVE') dst_host = self.admin_servers_client.show_server( server['id'])['server']['OS-EXT-SRV-ATTR:host'] self.assertEqual(target_host, dst_host) @decorators.idempotent_id('2a775512-6735-430c-8f92-29d11e07b052') def test_cold_migrate_server_with_host_force_false(self): self._test_cold_migrate_server_with_host(force=False) @decorators.idempotent_id('751e4677-be4f-432b-9063-1c11a3f1ce59') def test_cold_migrate_server_with_host_force_true(self): self._test_cold_migrate_server_with_host(force=True)",,56,0
openstack%2Fmanila~master~If7d52e08d00d435f2e26c30654f0d2180b17b81a,openstack/manila,master,If7d52e08d00d435f2e26c30654f0d2180b17b81a,Fix quota usages update deleting same share from several API endpoints,MERGED,2017-08-11 16:22:24.000000000,2017-12-19 03:49:33.000000000,2017-12-19 03:49:33.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 8851}, {'_account_id': 8871}, {'_account_id': 9003}, {'_account_id': 12017}, {'_account_id': 13984}, {'_account_id': 15100}, {'_account_id': 15831}, {'_account_id': 15942}, {'_account_id': 16643}, {'_account_id': 16657}, {'_account_id': 17565}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2017-08-11 16:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/da4d0d935e2497def8eac249266e392685edc874', 'message': ""Fix quota usages update deleting same share from several API endpoints\n\nIt is possible to update quota usages multiple times sending share\ndeletion request to several API endpoints concurrently.\nSo, move quota usages update logic that is triggered by share deletion,\nto DB functions level, which will be able to be executed only when\nshare deletion succeded. So, all concurrent requests, that failed to\ndelete DB record, won't commit quota usages updates.\n\nChange-Id: If7d52e08d00d435f2e26c30654f0d2180b17b81a\nCloses-Bug: #1707379\n""}, {'number': 2, 'created': '2017-11-21 09:17:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/9f7e72b643457ec19ed560269aa19b3a51303b3d', 'message': ""Fix quota usages update deleting same share from several API endpoints\n\nIt is possible to update quota usages multiple times sending share\ndeletion request to several API endpoints concurrently.\nSo, move quota usages update logic that is triggered by share deletion,\nto DB functions level, which will be able to be executed only when\nshare deletion succeded. So, all concurrent requests, that failed to\ndelete DB record, won't commit quota usages updates.\n\nChange-Id: If7d52e08d00d435f2e26c30654f0d2180b17b81a\nCloses-Bug: #1707379\n""}, {'number': 3, 'created': '2017-11-21 09:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a67b7cb77dfa352bd448d68d99c39f55b0f84c4a', 'message': ""Fix quota usages update deleting same share from several API endpoints\n\nIt is possible to update quota usages multiple times sending share\ndeletion request to several API endpoints concurrently.\nSo, move quota usages update logic that is triggered by share deletion,\nto DB functions level, which will be able to be executed only when\nshare deletion succeded. So, all concurrent requests, that failed to\ndelete DB record, won't commit quota usages updates.\n\nChange-Id: If7d52e08d00d435f2e26c30654f0d2180b17b81a\nCloses-Bug: #1707379\nCloses-bug: #1707377\n""}, {'number': 4, 'created': '2017-11-21 10:02:33.000000000', 'files': ['manila/db/api.py', 'manila/tests/share/test_api.py', 'manila/share/api.py', 'manila/tests/db/sqlalchemy/test_api.py', 'manila/db/sqlalchemy/api.py', 'manila/share/manager.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/3c596304991927f62290fd940a7f518ec1cae4a2', 'message': ""Fix quota usages update deleting same share from several API endpoints\n\nIt is possible to update quota usages multiple times sending share\ndeletion request to several API endpoints concurrently.\nSo, move quota usages update logic that is triggered by share deletion,\nto DB functions level, which will be able to be executed only when\nshare deletion succeded. So, all concurrent requests, that failed to\ndelete DB record, won't commit quota usages updates.\n\nChange-Id: If7d52e08d00d435f2e26c30654f0d2180b17b81a\nCloses-Bug: #1707379\nCloses-bug: #1707377\n""}]",0,493071,3c596304991927f62290fd940a7f518ec1cae4a2,28,18,4,8851,,,0,"Fix quota usages update deleting same share from several API endpoints

It is possible to update quota usages multiple times sending share
deletion request to several API endpoints concurrently.
So, move quota usages update logic that is triggered by share deletion,
to DB functions level, which will be able to be executed only when
share deletion succeded. So, all concurrent requests, that failed to
delete DB record, won't commit quota usages updates.

Change-Id: If7d52e08d00d435f2e26c30654f0d2180b17b81a
Closes-Bug: #1707379
Closes-bug: #1707377
",git fetch https://review.opendev.org/openstack/manila refs/changes/71/493071/4 && git format-patch -1 --stdout FETCH_HEAD,"['manila/db/api.py', 'manila/share/api.py', 'manila/db/sqlalchemy/api.py', 'manila/share/manager.py']",4,da4d0d935e2497def8eac249266e392685edc874,bug/1707379," self.db.share_instance_delete( context, share_instance_id, need_to_update_usages=True) "," self.db.share_instance_delete(context, share_instance_id)",45,42
openstack%2Foslo.rootwrap~master~Ie30163d32dc6884667f0725f5aced809c0de82d0,openstack/oslo.rootwrap,master,Ie30163d32dc6884667f0725f5aced809c0de82d0,Add bandit to pep8 job,MERGED,2017-12-07 05:53:20.000000000,2017-12-19 03:43:19.000000000,2017-12-19 03:43:19.000000000,"[{'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 8119}, {'_account_id': 9796}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 05:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/0c83f092c1b5c91414ff3ad17916f5a3b14fdabf', 'message': '[WIP]Add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\n\nChange-Id: Ie30163d32dc6884667f0725f5aced809c0de82d0\n'}, {'number': 2, 'created': '2017-12-12 06:59:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/f4eb9cf97396c7ed05a0183b26282061f3b7fe61', 'message': ""Add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\n* Don't hard code '/tmp' in test\n* skip B404\n\nChange-Id: Ie30163d32dc6884667f0725f5aced809c0de82d0\n""}, {'number': 3, 'created': '2017-12-13 03:26:05.000000000', 'files': ['oslo_rootwrap/tests/test_rootwrap.py', 'test-requirements.txt', 'oslo_rootwrap/client.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/24156a438fa543e2753fe8a2e7b0e639c7227d21', 'message': ""Add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\n* convert assert statement to raise AssertionError\n* Don't hard code '/tmp' in test\n* skip B404\n\nChange-Id: Ie30163d32dc6884667f0725f5aced809c0de82d0\n""}]",0,526285,24156a438fa543e2753fe8a2e7b0e639c7227d21,14,6,3,9796,,,0,"Add bandit to pep8 job

Add the bandit security scanner to the pep8 job.
* convert assert statement to raise AssertionError
* Don't hard code '/tmp' in test
* skip B404

Change-Id: Ie30163d32dc6884667f0725f5aced809c0de82d0
",git fetch https://review.opendev.org/openstack/oslo.rootwrap refs/changes/85/526285/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,0c83f092c1b5c91414ff3ad17916f5a3b14fdabf,bandit,deps = -r{toxinidir}/test-requirements.txt commands = flake8 # Run security linter bandit -r oslo_rootwrap tests -n5,commands = flake8,9,1
openstack%2Foslo.concurrency~master~Iad8b31d1c214376cbdca39fa28afa7f46af6ccca,openstack/oslo.concurrency,master,Iad8b31d1c214376cbdca39fa28afa7f46af6ccca,add bandit to pep8 job,MERGED,2017-11-30 03:00:14.000000000,2017-12-19 03:42:47.000000000,2017-12-19 03:42:47.000000000,"[{'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 8119}, {'_account_id': 9796}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-30 03:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/fc77eb005411dd0b3ae7a7117be608d03f1e20b5', 'message': 'add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\n\nChange-Id: Iad8b31d1c214376cbdca39fa28afa7f46af6ccca\n'}, {'number': 2, 'created': '2017-12-12 02:51:04.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/86fb3dcc275b00d1d059033e908b55a0ce82cbbb', 'message': ""add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\nNote: we skip some cases which we can't fix now.\n\nChange-Id: Iad8b31d1c214376cbdca39fa28afa7f46af6ccca\n""}]",0,524050,86fb3dcc275b00d1d059033e908b55a0ce82cbbb,15,5,2,9796,,,0,"add bandit to pep8 job

Add the bandit security scanner to the pep8 job.
Note: we skip some cases which we can't fix now.

Change-Id: Iad8b31d1c214376cbdca39fa28afa7f46af6ccca
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/50/524050/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,fc77eb005411dd0b3ae7a7117be608d03f1e20b5,bandit,deps = -r{toxinidir}/test-requirements.txt commands = flake8 # Run security linter bandit -r oslo_concurrency -x tests -n5,commands = flake8,9,1
openstack%2Foslo.reports~master~I5ae66767178d037d312eb2ab0374dd6f137ecc7b,openstack/oslo.reports,master,I5ae66767178d037d312eb2ab0374dd6f137ecc7b,Add bandit to pep8 job,MERGED,2017-12-07 05:44:02.000000000,2017-12-19 03:38:42.000000000,2017-12-19 03:38:42.000000000,"[{'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 8119}, {'_account_id': 9796}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 05:44:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.reports/commit/3d920ff101289ed852575187476bdfa56aba21bd', 'message': 'Add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\n\nChange-Id: I5ae66767178d037d312eb2ab0374dd6f137ecc7b\n'}, {'number': 2, 'created': '2017-12-12 06:43:21.000000000', 'files': ['oslo_reports/tests/test_guru_meditation_report.py', 'test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.reports/commit/4dde5f3cb27186a86be90e6b85508ea236dcb630', 'message': ""Add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\n* skip B314,B405\n* Don't use '/temp/file'\n\nChange-Id: I5ae66767178d037d312eb2ab0374dd6f137ecc7b\n""}]",0,526282,4dde5f3cb27186a86be90e6b85508ea236dcb630,13,5,2,9796,,,0,"Add bandit to pep8 job

Add the bandit security scanner to the pep8 job.
* skip B314,B405
* Don't use '/temp/file'

Change-Id: I5ae66767178d037d312eb2ab0374dd6f137ecc7b
",git fetch https://review.opendev.org/openstack/oslo.reports refs/changes/82/526282/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,3d920ff101289ed852575187476bdfa56aba21bd,bandit,deps = -r{toxinidir}/test-requirements.txt commands = flake8 # Run security linter bandit -r oslo_reports tests -n5,commands = flake8,9,1
openstack%2Fblazar~master~I22a48f9b7b32a9e7df9e9319a395f91e648ba5a7,openstack/blazar,master,I22a48f9b7b32a9e7df9e9319a395f91e648ba5a7,Use waiter method to check server status,MERGED,2017-12-14 06:52:00.000000000,2017-12-19 03:36:47.000000000,2017-12-19 03:36:47.000000000,"[{'_account_id': 8878}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 23840}]","[{'number': 1, 'created': '2017-12-14 06:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/8a3591e4f8a5f9861f90058c591bc53c170c82e6', 'message': ""Use waiters method to check server status\n\nThe status of an instance could be 'ACTIVE' right after end lease happens\nsince the task for deleting the instance is stil in progress.\n\nThis patch replaces the assertion to check whether the instance is terminated\nor not with waiters method. The method periodically checks an existance of the\nspecified instance until the instance is deleted.\n\nChange-Id: I22a48f9b7b32a9e7df9e9319a395f91e648ba5a7\n""}, {'number': 2, 'created': '2017-12-15 06:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/9c0049eb4f99cdc34d598b98f46e3752287adc36', 'message': ""Use waiters method to check server status\n\nThe status of an instance could be 'ACTIVE' right after end lease happens\nsince the task for deleting the instance is stil in progress.\n\nThis patch replaces the assertion to check whether the instance is terminated\nor not with waiters method. The method periodically checks an existance of the\nspecified instance until the instance is deleted.\n\nChange-Id: I22a48f9b7b32a9e7df9e9319a395f91e648ba5a7\n""}, {'number': 3, 'created': '2017-12-18 20:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/682c3ef37aeea05eca713cb4c011cd67a5b64347', 'message': ""Use waiters method to check server status\n\nThe status of an instance could be 'ACTIVE' right after a lease ends,\nsince the task of deleting the instance is still in progress.\n\nThis patch replaces the assertion to check whether the instance is\nterminated with a waiters method. The method periodically checks for the\nexistance of the specified instance until the instance is deleted.\n\nChange-Id: I22a48f9b7b32a9e7df9e9319a395f91e648ba5a7\n""}, {'number': 4, 'created': '2017-12-18 20:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/2aa025732fc1bcf7c651acf4cf039bc26e1d1aa0', 'message': ""Use waiter method to check server status\n\nThe status of an instance could be 'ACTIVE' right after a lease ends,\nsince the task of deleting the instance is still in progress.\n\nThis patch replaces the assertion to check whether the instance is\nterminated with a waiter method. The method periodically checks for the\nexistance of the specified instance until the instance is deleted.\n\nChange-Id: I22a48f9b7b32a9e7df9e9319a395f91e648ba5a7\n""}, {'number': 5, 'created': '2017-12-18 20:53:42.000000000', 'files': ['blazar_tempest_plugin/tests/scenario/test_host_reservation.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/576686bbbcbacd403e817720affe8767291ad201', 'message': ""Use waiter method to check server status\n\nThe status of an instance could be 'ACTIVE' right after a lease ends,\nsince the task of deleting the instance is still in progress.\n\nThis patch replaces the assertion to check whether the instance is\nterminated with a waiter method. The method periodically checks for the\nexistance of the specified instance until the instance is deleted.\n\nChange-Id: I22a48f9b7b32a9e7df9e9319a395f91e648ba5a7\n""}]",0,527874,576686bbbcbacd403e817720affe8767291ad201,14,4,5,8878,,,0,"Use waiter method to check server status

The status of an instance could be 'ACTIVE' right after a lease ends,
since the task of deleting the instance is still in progress.

This patch replaces the assertion to check whether the instance is
terminated with a waiter method. The method periodically checks for the
existance of the specified instance until the instance is deleted.

Change-Id: I22a48f9b7b32a9e7df9e9319a395f91e648ba5a7
",git fetch https://review.opendev.org/openstack/blazar refs/changes/74/527874/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/scenario/test_host_reservation.py'],1,8a3591e4f8a5f9861f90058c591bc53c170c82e6,fix-scenario-test," waiters.wait_for_server_termination(self.os_admin.servers_client, server['id'])"," self.assertRaises(exceptions.NotFound, self.os_admin.servers_client.show_server, server['id'])",2,3
openstack%2Frequirements~master~I84420ed83390e059a9c1b21e58808277882c6a61,openstack/requirements,master,I84420ed83390e059a9c1b21e58808277882c6a61,update constraint for python-zaqarclient to new release 1.8.0,MERGED,2017-12-18 13:01:46.000000000,2017-12-19 03:32:16.000000000,2017-12-19 03:32:16.000000000,"[{'_account_id': 6593}, {'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 17130}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 13:01:46.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c96fef197133be7b425a6ad95dee2e234b261346', 'message': 'update constraint for python-zaqarclient to new release 1.8.0\n\nChange-Id: I84420ed83390e059a9c1b21e58808277882c6a61\nmeta:version: 1.8.0\nmeta:diff-start: -\nmeta:series: queens\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: yes\nmeta:release:Author: ricolin <rico.lin@easystack.cn>\nmeta:release:Commit: ricolin <rico.lin@easystack.cn>\nmeta:release:Change-Id: I19f85b0fa54d766d65fe42d3c373916b293be795\nmeta:release:Code-Review+1: Feilong Wang <flwang@catalyst.net.nz>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,528709,c96fef197133be7b425a6ad95dee2e234b261346,10,5,1,11131,,,0,"update constraint for python-zaqarclient to new release 1.8.0

Change-Id: I84420ed83390e059a9c1b21e58808277882c6a61
meta:version: 1.8.0
meta:diff-start: -
meta:series: queens
meta:release-type: release
meta:pypi: yes
meta:first: yes
meta:release:Author: ricolin <rico.lin@easystack.cn>
meta:release:Commit: ricolin <rico.lin@easystack.cn>
meta:release:Change-Id: I19f85b0fa54d766d65fe42d3c373916b293be795
meta:release:Code-Review+1: Feilong Wang <flwang@catalyst.net.nz>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/09/528709/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,c96fef197133be7b425a6ad95dee2e234b261346,new-release,python-zaqarclient===1.8.0,python-zaqarclient===1.7.0,1,1
openstack%2Fosprofiler~master~I39d6b8d9f71fd2d0f63873554a6a8ff0075554b8,openstack/osprofiler,master,I39d6b8d9f71fd2d0f63873554a6a8ff0075554b8,Add functional test for Redis driver,MERGED,2017-11-29 10:48:17.000000000,2017-12-19 03:31:00.000000000,2017-12-19 03:31:00.000000000,"[{'_account_id': 3012}, {'_account_id': 22348}, {'_account_id': 23630}]","[{'number': 1, 'created': '2017-11-29 10:48:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/295b1b359f9241c61a64ca22ebaa6b732f219b38', 'message': 'Add functional test for Redis driver\n\nChange-Id: I39d6b8d9f71fd2d0f63873554a6a8ff0075554b8\n'}, {'number': 2, 'created': '2017-11-29 11:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/db058d9e21144e5f6d9cf9e8d5589cde16b592ac', 'message': 'Add functional test for Redis driver\n\nChange-Id: I39d6b8d9f71fd2d0f63873554a6a8ff0075554b8\n'}, {'number': 3, 'created': '2017-11-29 13:58:11.000000000', 'files': ['bindep.txt', 'osprofiler/tests/functional/test_driver.py'], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/23e53ec9eb445a032fc85666698cd94c19174d75', 'message': 'Add functional test for Redis driver\n\nChange-Id: I39d6b8d9f71fd2d0f63873554a6a8ff0075554b8\n'}]",0,523840,23e53ec9eb445a032fc85666698cd94c19174d75,10,3,3,5950,,,0,"Add functional test for Redis driver

Change-Id: I39d6b8d9f71fd2d0f63873554a6a8ff0075554b8
",git fetch https://review.opendev.org/openstack/osprofiler refs/changes/40/523840/1 && git format-patch -1 --stdout FETCH_HEAD,"['bindep.txt', 'osprofiler/tests/functional/test_driver.py']",2,295b1b359f9241c61a64ca22ebaa6b732f219b38,redis-job," class RedisDriverTestCase(DriverTestCase): def setUp(self): super(DriverTestCase, self).setUp() CONF([]) opts.set_defaults(CONF, connection_string='redis://localhost:6379', enabled=True, trace_sqlalchemy=False, hmac_keys=""SECRET_KEY"")",,12,0
openstack%2Fhorizon~master~I89fcdfb7fccdf8a79cc21a9a63e026bb72a4153c,openstack/horizon,master,I89fcdfb7fccdf8a79cc21a9a63e026bb72a4153c,Updated from global requirements,MERGED,2017-12-19 01:17:37.000000000,2017-12-19 03:29:58.000000000,2017-12-19 03:29:57.000000000,"[{'_account_id': 11885}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-19 01:17:37.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/bdba740a005db0187390056b33dcfdc6eb89f175', 'message': 'Updated from global requirements\n\nChange-Id: I89fcdfb7fccdf8a79cc21a9a63e026bb72a4153c\n'}]",0,528861,bdba740a005db0187390056b33dcfdc6eb89f175,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I89fcdfb7fccdf8a79cc21a9a63e026bb72a4153c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/61/528861/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,bdba740a005db0187390056b33dcfdc6eb89f175,openstack/requirements,oslo.utils>=3.33.0 # Apache-2.0,oslo.utils>=3.31.0 # Apache-2.0,1,1
openstack%2Fhorizon~master~Ic79ebce34b619efc55675d4da6d04d9955684436,openstack/horizon,master,Ic79ebce34b619efc55675d4da6d04d9955684436,Define default POLICY_DIRS value,MERGED,2017-12-11 14:26:47.000000000,2017-12-19 03:22:56.000000000,2017-12-19 03:22:56.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 11885}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 14:26:47.000000000', 'files': ['openstack_dashboard/settings.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/38690f1ee8a1294089cb02c1d468e445d0f81155', 'message': ""Define default POLICY_DIRS value\n\nHaving the default value {} for POLICY_DIRS is useful\nfor horizon plugin maintainers.\nHorizon plugins can add a setting like:\n\n  POLICY_DIRS['network'] = 'neutron_policy.d'\n\nand put their policy files in the policy.d directory.\n\nHowever, the default value is not set, they need to check\nPOLICY_DIRS exists to avoid overriding existing POLICY_DIRS.\nThis is a bit painful.\n\nChange-Id: Ic79ebce34b619efc55675d4da6d04d9955684436\n""}]",3,527104,38690f1ee8a1294089cb02c1d468e445d0f81155,9,4,1,841,,,0,"Define default POLICY_DIRS value

Having the default value {} for POLICY_DIRS is useful
for horizon plugin maintainers.
Horizon plugins can add a setting like:

  POLICY_DIRS['network'] = 'neutron_policy.d'

and put their policy files in the policy.d directory.

However, the default value is not set, they need to check
POLICY_DIRS exists to avoid overriding existing POLICY_DIRS.
This is a bit painful.

Change-Id: Ic79ebce34b619efc55675d4da6d04d9955684436
",git fetch https://review.opendev.org/openstack/horizon refs/changes/04/527104/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/settings.py'],1,38690f1ee8a1294089cb02c1d468e445d0f81155,policy-dirs,POLICY_DIRS = {},,1,0
openstack%2Frally~master~I5e5402df7dab13315b39b6be866f921b0ba56ff1,openstack/rally,master,I5e5402df7dab13315b39b6be866f921b0ba56ff1,Use atomic actions in cinder contexts,MERGED,2017-12-15 13:36:38.000000000,2017-12-19 03:21:08.000000000,2017-12-19 03:21:08.000000000,"[{'_account_id': 9545}, {'_account_id': 14817}, {'_account_id': 21528}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 13:36:38.000000000', 'files': ['rally/plugins/openstack/context/cinder/volumes.py', 'rally/plugins/openstack/context/cinder/volume_types.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/5c44ca33e890c787a95755046b3ecfcb4d3e63ac', 'message': 'Use atomic actions in cinder contexts\n\nChange-Id: I5e5402df7dab13315b39b6be866f921b0ba56ff1\n'}]",0,528270,5c44ca33e890c787a95755046b3ecfcb4d3e63ac,11,4,1,9545,,,0,"Use atomic actions in cinder contexts

Change-Id: I5e5402df7dab13315b39b6be866f921b0ba56ff1
",git fetch https://review.opendev.org/openstack/rally refs/changes/70/528270/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/context/cinder/volumes.py', 'rally/plugins/openstack/context/cinder/volume_types.py']",2,5c44ca33e890c787a95755046b3ecfcb4d3e63ac,contexts," admin_clients, name_generator=self.generate_random_name, atomic_inst=self.atomic_actions())"," admin_clients, name_generator=self.generate_random_name)",6,2
openstack%2Fironic~master~I492a140f22f52a3ddc52b83a774efc8c17e68c20,openstack/ironic,master,I492a140f22f52a3ddc52b83a774efc8c17e68c20,Use NamedExtensionManager for drivers,MERGED,2017-12-15 14:02:52.000000000,2017-12-19 03:18:52.000000000,2017-12-19 03:18:52.000000000,"[{'_account_id': 6618}, {'_account_id': 6637}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 26576}]","[{'number': 1, 'created': '2017-12-15 14:02:52.000000000', 'files': ['ironic/tests/unit/common/test_driver_factory.py', 'ironic/common/driver_factory.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/7eccab7dc0b8643486b4fad1b857bd20221b838a', 'message': ""Use NamedExtensionManager for drivers\n\nInstead of using stevedore NameDispatchExtensionManager and filter the\nenabled drivers, use NamedExtensionManager with the list of enabled\nnames. That has the benefit of not loading the drivers we don't want.\n\nChange-Id: I492a140f22f52a3ddc52b83a774efc8c17e68c20\nCloses-Bug: #1738411\n""}]",0,528277,7eccab7dc0b8643486b4fad1b857bd20221b838a,18,10,1,7385,,,0,"Use NamedExtensionManager for drivers

Instead of using stevedore NameDispatchExtensionManager and filter the
enabled drivers, use NamedExtensionManager with the list of enabled
names. That has the benefit of not loading the drivers we don't want.

Change-Id: I492a140f22f52a3ddc52b83a774efc8c17e68c20
Closes-Bug: #1738411
",git fetch https://review.opendev.org/openstack/ironic refs/changes/77/528277/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/common/test_driver_factory.py', 'ironic/common/driver_factory.py']",2,7eccab7dc0b8643486b4fad1b857bd20221b838a,bug/1738411,"from stevedore import named def missing_callback(names): cls._extension_manager = ( named.NamedExtensionManager( cls._entrypoint_name, cls._enabled_driver_list, invoke_on_load=True, on_load_failure_callback=_catch_driver_not_found, propagate_map_exceptions=True, on_missing_entrypoints_callback=missing_callback)) if cls._enabled_driver_list: cls._extension_manager.map(_warn_if_unsupported)","from stevedore import dispatch def _check_func(ext): return ext.name in cls._enabled_driver_list cls._extension_manager = ( dispatch.NameDispatchExtensionManager( cls._entrypoint_name, _check_func, invoke_on_load=True, on_load_failure_callback=_catch_driver_not_found, propagate_map_exceptions=True)) # NOTE(deva): if we were unable to load any configured driver, perhaps # because it is not present on the system, raise an error. if (sorted(cls._enabled_driver_list) != sorted(cls._extension_manager.names())): found = cls._extension_manager.names() names = [n for n in cls._enabled_driver_list if n not in found] # just in case more than one could not be found ... cls._extension_manager.map(cls._extension_manager.names(), _warn_if_unsupported)",19,27
openstack%2Fpython-troveclient~master~Idb57353c5d969783bbe860d659bbcbbcc29aa8d0,openstack/python-troveclient,master,Idb57353c5d969783bbe860d659bbcbbcc29aa8d0,Update the documentation link for doc migration,ABANDONED,2017-08-03 06:36:28.000000000,2017-12-19 03:15:01.000000000,,"[{'_account_id': 17130}, {'_account_id': 19930}, {'_account_id': 20378}, {'_account_id': 22348}, {'_account_id': 25067}, {'_account_id': 25073}, {'_account_id': 25903}]","[{'number': 1, 'created': '2017-08-03 06:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/319c6b521cb760e9952d94b93e5548133c95e621', 'message': 'Update the documentation link for doc migration\n\nThis patch is proposed according to the Direction 10 of doc\nmigration(https://etherpad.openstack.org/p/doc-migration-tracking).\n\nChange-Id: Idb57353c5d969783bbe860d659bbcbbcc29aa8d0\n'}, {'number': 2, 'created': '2017-08-03 09:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/0b3dcfc286833e443bcb4d17394104c176313b96', 'message': 'Update the documentation link for doc migration\n\nThis patch is proposed according to the Direction 10 of doc\nmigration(https://etherpad.openstack.org/p/doc-migration-tracking).\n\nChange-Id: Idb57353c5d969783bbe860d659bbcbbcc29aa8d0\n'}, {'number': 3, 'created': '2017-08-04 02:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/bb0e9e62d4004c7499d66c7fd430d02a032b0035', 'message': 'Update the documentation link for doc migration\n\nThis patch is proposed according to the Direction 10 of doc\nmigration(https://etherpad.openstack.org/p/doc-migration-tracking).\n\nChange-Id: Idb57353c5d969783bbe860d659bbcbbcc29aa8d0\n'}, {'number': 4, 'created': '2017-10-12 06:43:14.000000000', 'files': ['troveclient/_i18n.py', 'README.rst', 'troveclient/i18n.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/26529e0b4d9b9b96b13d4b3c87b179f82093f917', 'message': 'Update the documentation link for doc migration\n\nThis patch is proposed according to the Direction 10 of doc\nmigration(https://etherpad.openstack.org/p/doc-migration-tracking).\n\nChange-Id: Idb57353c5d969783bbe860d659bbcbbcc29aa8d0\n'}]",5,490345,26529e0b4d9b9b96b13d4b3c87b179f82093f917,18,7,4,25073,,,0,"Update the documentation link for doc migration

This patch is proposed according to the Direction 10 of doc
migration(https://etherpad.openstack.org/p/doc-migration-tracking).

Change-Id: Idb57353c5d969783bbe860d659bbcbbcc29aa8d0
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/45/490345/4 && git format-patch -1 --stdout FETCH_HEAD,"['troveclient/_i18n.py', 'README.rst', 'troveclient/i18n.py', 'setup.cfg']",4,319c6b521cb760e9952d94b93e5548133c95e621,doc-migration,home-page = https://docs.openstack.org/python-troveclient/latest,home-page = http://docs.openstack.org/developer/python-troveclient,4,4
openstack%2Ftripleo-heat-templates~master~Iaafe68328b507caff46c9d2610a72541f19b0979,openstack/tripleo-heat-templates,master,Iaafe68328b507caff46c9d2610a72541f19b0979,Fix permissions on .ssh directory.,MERGED,2017-12-15 19:31:26.000000000,2017-12-19 03:14:11.000000000,2017-12-19 03:14:11.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-15 19:31:26.000000000', 'files': ['extraconfig/post_deploy/undercloud_post.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5ada69131bae8668aef0314132f2df64e8ea6f45', 'message': 'Fix permissions on .ssh directory.\n\nTypo I think.. should be 700.\n\nChange-Id: Iaafe68328b507caff46c9d2610a72541f19b0979\n'}]",0,528377,5ada69131bae8668aef0314132f2df64e8ea6f45,9,4,1,2011,,,0,"Fix permissions on .ssh directory.

Typo I think.. should be 700.

Change-Id: Iaafe68328b507caff46c9d2610a72541f19b0979
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/77/528377/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/post_deploy/undercloud_post.sh'],1,5ada69131bae8668aef0314132f2df64e8ea6f45,undercloud, sudo chmod 700 $HOMEDIR/.ssh/, sudo chmod 7000 $HOMEDIR/.ssh/,1,1
openstack%2Foslo.vmware~master~I35e7dd997d72ad40d73fd6dbaccef0d7e084f380,openstack/oslo.vmware,master,I35e7dd997d72ad40d73fd6dbaccef0d7e084f380,Cleanup test-requirements,ABANDONED,2017-09-25 12:50:59.000000000,2017-12-19 03:05:53.000000000,,[{'_account_id': 9008}],"[{'number': 1, 'created': '2017-09-25 12:50:59.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/c2eb0276e0667ef1b9461154c3c22f1dfee3f7b5', 'message': 'Cleanup test-requirements\n\npython-subunit is not used directly anywhere\nand it is dependency of both testrepository\nand os-testr\n(probably was used by some tox wrapper script before)\n\nChange-Id: I35e7dd997d72ad40d73fd6dbaccef0d7e084f380\n'}]",0,507089,c2eb0276e0667ef1b9461154c3c22f1dfee3f7b5,5,1,1,17130,,,0,"Cleanup test-requirements

python-subunit is not used directly anywhere
and it is dependency of both testrepository
and os-testr
(probably was used by some tox wrapper script before)

Change-Id: I35e7dd997d72ad40d73fd6dbaccef0d7e084f380
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/89/507089/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,c2eb0276e0667ef1b9461154c3c22f1dfee3f7b5,update-requirements,,python-subunit>=0.0.18 # Apache-2.0/BSD,0,1
openstack%2Fmanila-ui~master~Ie5753af381979b7975651e48cc26d9ea16195a78,openstack/manila-ui,master,Ie5753af381979b7975651e48cc26d9ea16195a78,Updated from global requirements,MERGED,2017-12-19 01:22:53.000000000,2017-12-19 02:41:15.000000000,2017-12-19 02:41:15.000000000,"[{'_account_id': 2417}, {'_account_id': 9003}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-19 01:22:53.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/47af9f04ac362d2223e8015dd59d2dc86be4d9fd', 'message': 'Updated from global requirements\n\nChange-Id: Ie5753af381979b7975651e48cc26d9ea16195a78\n'}]",0,528871,47af9f04ac362d2223e8015dd59d2dc86be4d9fd,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ie5753af381979b7975651e48cc26d9ea16195a78
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/71/528871/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,47af9f04ac362d2223e8015dd59d2dc86be4d9fd,openstack/requirements,oslo.utils>=3.33.0 # Apache-2.0,oslo.utils>=3.31.0 # Apache-2.0,1,1
openstack%2Ftripleo-heat-templates~master~I9d9ac3b4fd3601b7da77f845d79cb02bfe3d42f7,openstack/tripleo-heat-templates,master,I9d9ac3b4fd3601b7da77f845d79cb02bfe3d42f7,DNM - Test RHSM with custom roles,ABANDONED,2017-12-18 17:02:21.000000000,2017-12-19 02:27:20.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-18 17:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0d2b6ec62884d8b48257051582b3fd4429979dd6', 'message': 'DNM - Test RHSM with custom roles\n\nChange-Id: I9d9ac3b4fd3601b7da77f845d79cb02bfe3d42f7\nDepends-On: I9829845b83bd43e1d66f6be010369dde8ef47b5a\n'}, {'number': 2, 'created': '2017-12-18 20:17:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b244ee9056fab5322ed3d5fa8251d24c57f0ab90', 'message': 'DNM - Test RHSM with custom roles\n\nChange-Id: I9d9ac3b4fd3601b7da77f845d79cb02bfe3d42f7\nDepends-On: I9829845b83bd43e1d66f6be010369dde8ef47b5a\n'}, {'number': 3, 'created': '2017-12-18 23:00:35.000000000', 'files': ['ci/environments/multinode-3nodes-registry.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5b24f2b87894a630ea361b0d8d9318c099a9a909', 'message': 'DNM - Test RHSM with custom roles\n\nChange-Id: I9d9ac3b4fd3601b7da77f845d79cb02bfe3d42f7\nDepends-On: I9829845b83bd43e1d66f6be010369dde8ef47b5a\n'}]",0,528762,5b24f2b87894a630ea361b0d8d9318c099a9a909,9,2,3,3153,,,0,"DNM - Test RHSM with custom roles

Change-Id: I9d9ac3b4fd3601b7da77f845d79cb02bfe3d42f7
Depends-On: I9829845b83bd43e1d66f6be010369dde8ef47b5a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/62/528762/2 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/multinode-3nodes-registry.yaml'],1,0d2b6ec62884d8b48257051582b3fd4429979dd6,3nodes/rhsm, ControllerRhsmVars: rhn_activation_key: 'controller-key' rhsub_repos: - repo-controller1 - repo-controller2 ControllerApiRhsmVars: rhn_activation_key: 'controller-api-key' rhsub_repos: - repo-controller-api1 - repo-controller-api2,,10,0
openstack%2Ftripleo-heat-templates~master~I6039c930680781b1c025ac8504416c8dee177dfd,openstack/tripleo-heat-templates,master,I6039c930680781b1c025ac8504416c8dee177dfd,Test https://review.openstack.org/#/c/522461,ABANDONED,2017-12-18 16:28:41.000000000,2017-12-19 02:26:53.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-12-18 16:28:41.000000000', 'files': ['ci/environments/multinode-containers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f184a3849fdbc89103e181ec0e25190b1a99bb93', 'message': 'Test https://review.openstack.org/#/c/522461\n\nChange-Id: I6039c930680781b1c025ac8504416c8dee177dfd\nDepends-On: Ib85479442ec68f9a67615c23e5c39bd217c9b109\n'}]",0,528751,f184a3849fdbc89103e181ec0e25190b1a99bb93,4,1,1,3153,,,0,"Test https://review.openstack.org/#/c/522461

Change-Id: I6039c930680781b1c025ac8504416c8dee177dfd
Depends-On: Ib85479442ec68f9a67615c23e5c39bd217c9b109
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/51/528751/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/multinode-containers.yaml'],1,f184a3849fdbc89103e181ec0e25190b1a99bb93,test-keystone, #,,1,0
openstack%2Fadjutant~master~Ie94672a90c88d27aaf951572bb6f8d172cd6de44,openstack/adjutant,master,Ie94672a90c88d27aaf951572bb6f8d172cd6de44,TerminateProject and ClearProject Tasks,NEW,2017-06-26 23:21:05.000000000,2017-12-19 02:19:34.000000000,,"[{'_account_id': 3}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-06-26 23:21:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/adjutant/commit/1052fca4a99aa8a03229a6d5bff03867000d9c3e', 'message': ""Added TerminateProject and ClearProject\n\nTerminateProject will clear all resources from an account and\ndisable it in keystone.\n\nClearProject takes an optional input of 'type_deletion_list'. If\nnot specified it will clear all resources, however if specifed\nit will clear only the resources from the specifed services,\ne.g. nova, swift\n\nThe sent token email includes a summary of their usage in all\nregions.\n\nChange-Id: Ie94672a90c88d27aaf951572bb6f8d172cd6de44\n""}, {'number': 2, 'created': '2017-09-04 22:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/adjutant/commit/1b31f54085cf3d57d567694bbeb9e32b8f554bf7', 'message': ""Added TerminateProject and ClearProject\n\nTerminateProject will clear all resources from an account and\ndisable it in keystone.\n\nClearProject takes an optional input of 'type_deletion_list'. If\nnot specified it will clear all resources, however if specifed\nit will clear only the resources from the specifed services,\ne.g. nova, swift\n\nThe sent token email includes a summary of their usage in all\nregions.\n\nChange-Id: Ie94672a90c88d27aaf951572bb6f8d172cd6de44\n""}, {'number': 3, 'created': '2017-12-08 03:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/adjutant/commit/3b54aafd7096cee4e881ab843e8ef2998a610e1b', 'message': ""Added TerminateProject and ClearProject\n\n* TerminateProject will clear all resources from an account and\n disable it in keystone.\n* ClearProject takes an optional input of 'type_deletion_list'. If\n  not specified it will clear all resources, however if specifed\n  it will clear only the resources from the specifed services,\n  e.g. compute, object_storege\n* The sent token email includes a summary of the relevant usage\n  accross all regions.\n* Subproject existence is checked, and subprojects must be\n  deleted before the parent project is.\n\nChange-Id: Ie94672a90c88d27aaf951572bb6f8d172cd6de44\n""}, {'number': 4, 'created': '2017-12-08 03:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/adjutant/commit/bcee7430becb93da41d5f8e48613ea41bfa595af', 'message': ""Added TerminateProject and ClearProject\n\n* TerminateProject will clear all resources from an account and\n disable it in keystone.\n* ClearProject takes an optional input of 'type_deletion_list'. If\n  not specified it will clear all resources, however if specifed\n  it will clear only the resources from the specifed services,\n  e.g. compute, object_storege\n* The sent token email includes a summary of the relevant usage\n  accross all regions.\n* Subproject existence is checked, and subprojects must be\n  deleted before the parent project is.\n\nChange-Id: Ie94672a90c88d27aaf951572bb6f8d172cd6de44\n""}, {'number': 5, 'created': '2017-12-08 03:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/adjutant/commit/347ff91372aa50630d407dcf13af3da4edc9cca6', 'message': ""Added TerminateProject and ClearProject\n\n* TerminateProject will clear all resources from an account and\n disable it in keystone.\n* ClearProject takes an optional input of 'type_deletion_list'. If\n  not specified it will clear all resources, however if specifed\n  it will clear only the resources from the specifed services,\n  e.g. compute, object_storege\n* The sent token email includes a summary of the relevant usage\n  accross all regions.\n* Subproject existence is checked, and subprojects must be\n  deleted before the parent project is.\n\nChange-Id: Ie94672a90c88d27aaf951572bb6f8d172cd6de44\n""}, {'number': 6, 'created': '2017-12-12 00:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/adjutant/commit/159384c21f69648951bb9135e0be5d387db3856c', 'message': ""TerminateProject and ClearProject Tasks\n\n* TerminateProject will clear all resources from an account and\n  disable it in keystone.\n* ClearProject takes an optional input of 'type_deletion_list'. If\n  not specified it will clear all resources, however if specifed\n  it will clear only the resources from the specifed services,\n  e.g. compute, object_storege\n* The sent token email includes a summary of the relevant usage\n  accross all regions.\n* Subproject existence is checked, and subprojects must be\n  deleted before the parent project is.\n* Full deletion of subprojects is auto approved, but deletion\n  of a root project requires adminitrative approval.\n\nChange-Id: Ie94672a90c88d27aaf951572bb6f8d172cd6de44\n""}, {'number': 7, 'created': '2017-12-12 00:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/adjutant/commit/b20bb4745753f251e2778bfad06a41d125f7f00d', 'message': ""TerminateProject and ClearProject Tasks\n\n* TerminateProject will clear all resources from an account and\n  disable it in keystone.\n* ClearProject takes an optional input of 'type_deletion_list'. If\n  not specified it will clear all resources, however if specifed\n  it will clear only the resources from the specifed services,\n  e.g. compute, object_storege\n* The sent token email includes a summary of the relevant usage\n  accross all regions.\n* Subproject existence is checked, and subprojects must be\n  deleted before the parent project is.\n* Full deletion of subprojects is auto approved, but deletion\n  of a root project requires adminitrative approval.\n\nChange-Id: Ie94672a90c88d27aaf951572bb6f8d172cd6de44\n""}, {'number': 8, 'created': '2017-12-18 01:20:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/adjutant/commit/caec882b3214b86ce19923b4c7ce346de985733c', 'message': ""TerminateProject and ClearProject Tasks\n\n* TerminateProject will clear all resources from an account and\n  disable it in keystone.\n* ClearProject takes an optional input of 'type_deletion_list'. If\n  not specified it will clear all resources, however if specifed\n  it will clear only the resources from the specifed services,\n  e.g. compute, object_storege\n* The sent token email includes a summary of the relevant usage\n  accross all regions.\n* Subproject existence is checked, and subprojects must be\n  deleted before the parent project is.\n* Full deletion of subprojects is auto approved, but deletion\n  of a root project requires adminitrative approval.\n\nChange-Id: Ie94672a90c88d27aaf951572bb6f8d172cd6de44\n""}, {'number': 9, 'created': '2017-12-19 02:12:30.000000000', 'files': ['api-ref/source/parameters.yaml', 'api-ref/source/taskviews.inc', 'doc/source/termination-tasks.rst', 'adjutant/api/v1/models.py', 'adjutant/api/v1/templates/account_terminate_token.txt', 'adjutant/common/tests/fake_clients.py', 'adjutant/actions/v1/models.py', 'adjutant/actions/v1/tests/test_deletion_actions.py', 'adjutant/actions/v1/serializers.py', 'adjutant/api/v1/templates/account_clear_completed.txt', 'doc/source/index.rst', 'requirements.txt', 'adjutant/api/v1/openstack.py', 'adjutant/actions/v1/deletion.py', 'adjutant/settings.py', 'adjutant/test_settings.py', 'adjutant/api/v1/tests/test_api_openstack.py', 'adjutant/api/v1/templates/account_clear_token.txt', 'adjutant/common/openstack_clients.py', 'conf/conf.yaml', 'adjutant/common/user_store.py', 'adjutant/api/utils.py'], 'web_link': 'https://opendev.org/openstack/adjutant/commit/83b10b7cb73cdf925d09b9abedea1fb7414466e7', 'message': ""TerminateProject and ClearProject Tasks\n\n* TerminateProject will clear all resources from an account and\n  disable it in keystone.\n* ClearProject takes an optional input of 'type_deletion_list'. If\n  not specified it will clear all resources, however if specifed\n  it will clear only the resources from the specifed services,\n  e.g. compute, object_storege\n* The sent token email includes a summary of the relevant usage\n  accross all regions.\n* Subproject existence is checked, and subprojects must be\n  deleted before the parent project is.\n* Full deletion of subprojects is auto approved, but deletion\n  of a root project requires adminitrative approval.\n\nChange-Id: Ie94672a90c88d27aaf951572bb6f8d172cd6de44\n""}]",0,477707,83b10b7cb73cdf925d09b9abedea1fb7414466e7,19,2,9,26263,,,0,"TerminateProject and ClearProject Tasks

* TerminateProject will clear all resources from an account and
  disable it in keystone.
* ClearProject takes an optional input of 'type_deletion_list'. If
  not specified it will clear all resources, however if specifed
  it will clear only the resources from the specifed services,
  e.g. compute, object_storege
* The sent token email includes a summary of the relevant usage
  accross all regions.
* Subproject existence is checked, and subprojects must be
  deleted before the parent project is.
* Full deletion of subprojects is auto approved, but deletion
  of a root project requires adminitrative approval.

Change-Id: Ie94672a90c88d27aaf951572bb6f8d172cd6de44
",git fetch https://review.opendev.org/openstack/adjutant refs/changes/07/477707/5 && git format-patch -1 --stdout FETCH_HEAD,"['adjutant/actions/v1/tests/__init__.py', 'adjutant/actions/user_store.py', 'adjutant/api/v1/models.py', 'adjutant/api/v1/templates/account_terminate_token.txt', 'adjutant/actions/v1/models.py', 'adjutant/actions/v1/tests/test_deletion_actions.py', 'adjutant/actions/v1/serializers.py', 'adjutant/api/v1/templates/account_clear_completed.txt', 'requirements.txt', 'adjutant/api/v1/openstack.py', 'adjutant/actions/v1/deletion.py', 'adjutant/test_settings.py', 'adjutant/api/v1/tests/test_api_openstack.py', 'adjutant/api/v1/templates/account_clear_token.txt', 'adjutant/actions/openstack_clients.py', 'conf/conf.yaml', 'adjutant/api/utils.py', 'adjutant/api/v1/tests/__init__.py']",18,1052fca4a99aa8a03229a6d5bff03867000d9c3e,new/octavia-terminate," 'heat_stack_owner': 'heat_stack_owner', 'Member': 'Member', return self.find_role(role) except (KeyError, ValueError): def list_regions(self): global temp_cache return [Region(name) for name in temp_cache['regions'].keys()] def get_project_users(self, project_id): # TODO: here project = self._project_from_id(project_id) user_list = [] for user_id in project.roles.keys(): u = mock.Mock() u.user = {'id': user_id} user_list.append(u) return user_list def disable_project(self, project_id, **kwargs): global temp_cache temp_cache['projects'][project_id].enabled = False def get_user_assignments(self, user_id): global temp_cache user_list = [] for project in temp_cache['projects']: project = self._project_from_id(project) try: for role in project.roles[user_id]: r = mock.Mock() r.user = {'id': user_id} r.scope = {'project': {'id': project.id}} r.role = {'id': role} user_list.append(r) except KeyError: pass return user_list def disable_user(self, user_id, **kwargs): temp_cache['users'][user_id].enabled = False class Region(object): def __init__(self, name): self.id = name "," 'heat_stack_owner': 'heat_stack_owner' return self.get_role(role) def disable_user(self, user): user = self._user_from_id(user) user.enabled = False except KeyError:",2520,68
openstack%2Fadjutant~master~Ibf1fdd6ade1b69e8652e3c675bd9555a8c108aed,openstack/adjutant,master,Ibf1fdd6ade1b69e8652e3c675bd9555a8c108aed,Add Octavia (LBaaS) to termination and clearing,NEW,2017-12-19 02:12:30.000000000,2017-12-19 02:18:49.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-12-19 02:12:30.000000000', 'files': ['requirements.txt', 'adjutant/api/v1/openstack.py', 'adjutant/actions/v1/deletion.py', 'doc/source/termination-tasks.rst', 'adjutant/test_settings.py', 'adjutant/api/v1/templates/account_terminate_token.txt', 'adjutant/api/v1/tests/test_api_openstack.py', 'adjutant/common/openstack_clients.py', 'adjutant/common/tests/fake_clients.py', 'adjutant/actions/v1/models.py', 'adjutant/actions/v1/tests/test_deletion_actions.py'], 'web_link': 'https://opendev.org/openstack/adjutant/commit/05e6e2d5ef232798b922b140617a50674aa8c05c', 'message': ""Add Octavia (LBaaS) to termination and clearing\n\n* By default not enabled, can be enabled as 'load_balancer'\n  under DELETION_SERVICE_TYPES in settings\n* Will place all values apart from induvidual l7 rules into\n  outgoing emails\n\nChange-Id: Ibf1fdd6ade1b69e8652e3c675bd9555a8c108aed\n""}]",0,528940,05e6e2d5ef232798b922b140617a50674aa8c05c,2,1,1,26263,,,0,"Add Octavia (LBaaS) to termination and clearing

* By default not enabled, can be enabled as 'load_balancer'
  under DELETION_SERVICE_TYPES in settings
* Will place all values apart from induvidual l7 rules into
  outgoing emails

Change-Id: Ibf1fdd6ade1b69e8652e3c675bd9555a8c108aed
",git fetch https://review.opendev.org/openstack/adjutant refs/changes/40/528940/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'adjutant/api/v1/openstack.py', 'adjutant/actions/v1/deletion.py', 'doc/source/termination-tasks.rst', 'adjutant/test_settings.py', 'adjutant/api/v1/templates/account_terminate_token.txt', 'adjutant/api/v1/tests/test_api_openstack.py', 'adjutant/common/openstack_clients.py', 'adjutant/common/tests/fake_clients.py', 'adjutant/actions/v1/models.py', 'adjutant/actions/v1/tests/test_deletion_actions.py']",11,05e6e2d5ef232798b922b140617a50674aa8c05c,new/octavia-terminate," DeleteGlanceAction, DeleteNeutronAction, DisableKeystoneAction, DeleteOctaviaAction)def setup_octavia_usage_fake_cache(region, project_id): """"""Sets up fake usage within Octavia"""""" loadbalancer = { ""description"": ""My favorite load balancer"", ""admin_state_up"": True, ""project_id"": project_id, ""provisioning_status"": ""PENDING_CREATE"", ""flavor"": """", ""vip_subnet_id"": ""d4af86e1-0051-488c-b7a0-527f97490c9a"", ""vip_address"": ""203.0.113.50"", ""vip_network_id"": ""d0d217df-3958-4fbf-a3c2-8dad2908c709"", ""vip_port_id"": ""b4ca07d1-a31e-43e2-891a-7d14f419f342"", ""provider"": ""octavia"", ""created_at"": ""2017-02-28T00:41:44"", ""updated_at"": ""2017-02-28T00:43:30"", ""id"": ""8a562351-f0fb-424c-a0af-513461424ea5"", ""operating_status"": ""ONLINE"", ""name"": ""best_load_balancer"" } listener = { ""description"": ""A great TLS listener"", ""admin_state_up"": True, ""project_id"": project_id, ""protocol"": ""TERMINATED_HTTPS"", ""protocol_port"": 443, ""provisioning_status"": ""ACTIVE"", ""loadbalancers"": [ { ""id"": ""8a562351-f0fb-424c-a0af-513461424ea5"" } ], ""created_at"": ""2017-02-28T00:42:44"", ""updated_at"": ""2017-02-28T00:44:30"", ""id"": ""023f2e34-7806-443b-bfae-16c324569a3d"", ""operating_status"": ""ONLINE"", ""default_pool_id"": ""ddb2b28f-89e9-45d3-a329-a359c3e39e4a"", ""l7policies"": [ { ""id"": ""5e618272-339d-4a80-8d14-dbc093091bb1"" } ], ""name"": ""great_tls_listener"" } listener2 = { ""description"": ""A great TLS listener"", ""admin_state_up"": True, ""project_id"": project_id, ""protocol"": ""TERMINATED_HTTPS"", ""protocol_port"": 443, ""provisioning_status"": ""ACTIVE"", ""loadbalancers"": [ { ""id"": ""8a562351-f0fb-424c-a0af-513461424ea5"" } ], ""created_at"": ""2017-02-28T00:42:44"", ""updated_at"": ""2017-02-28T00:44:30"", ""id"": ""A23f2e34-7806-443b-bfae-16c324569a3d"", ""operating_status"": ""ONLINE"", ""default_pool_id"": ""ddb2b28f-89e9-45d3-a329-a359c3e39e4a"", ""l7policies"": [], ""name"": ""great_tls_listener"" } if project_id not in fake_clients.octavia_cache[region]: fake_clients.octavia_cache[region][project_id] = {} project_cache = fake_clients.octavia_cache[region][project_id] project_cache['load_balancer'] = {loadbalancer['id']: loadbalancer} project_cache['listener'] = {listener['id']: listener, listener2['id']: listener2} healthmonitor = { ""project_id"": project_id, ""name"": ""super-pool-health-monitor"", ""admin_state_up"": True, ""pools"": [ { ""id"": ""pool_id"" } ], ""created_at"": ""2017-05-11T23:53:47"", ""provisioning_status"": ""ACTIVE"", ""updated_at"": ""2017-05-11T23:53:47"", ""delay"": 10, ""expected_codes"": ""200"", ""max_retries"": 1, ""http_method"": ""GET"", ""timeout"": 5, ""max_retries_down"": 3, ""url_path"": ""/"", ""type"": ""HTTP"", ""id"": ""8ed3c5ac-6efa-420c-bedb-99ba14e58db5"", ""operating_status"": ""ONLINE"" } project_cache['healthmonitor'] = {healthmonitor['id']: healthmonitor} pool = { ""lb_algorithm"": ""ROUND_ROBIN"", ""protocol"": ""HTTP"", ""description"": ""Super Round Robin Pool"", ""admin_state_up"": True, ""loadbalancers"": [ { ""id"": ""607226db-27ef-4d41-ae89-f2a800e9c2db"" } ], ""created_at"": ""2017-05-10T18:14:44"", ""provisioning_status"": ""ACTIVE"", ""updated_at"": ""2017-05-10T23:08:12"", ""session_persistence"": { ""cookie_name"": ""ChocolateChip"", ""type"": ""APP_COOKIE"" }, ""listeners"": [ { ""id"": listener['id'] } ], ""members"": [], ""healthmonitor_id"": None, ""project_id"": project_id, ""id"": ""pool_id"", ""operating_status"": ""ONLINE"", ""name"": ""super-pool"" } project_cache['pool'] = {pool['id']: pool} @mock.patch( 'adjutant.actions.v1.deletion.' + 'openstack_clients.get_octaviaclient', fake_clients.get_fake_octaviaclient) def test_delete_octavia(self): """""" Base case, delete octavia objects """""" project = fake_clients.FakeProject(name=""test_project"") fake_clients.setup_identity_cache(projects=[project]) setup_project_usage_fake_cache('RegionOne', project.id) setup_octavia_usage_fake_cache('RegionOne', project.id) task = Task.objects.create( ip_address=""0.0.0.0"", keystone_user={ 'roles': ['admin'], 'project_id': project.id}) data = { 'project_id': project.id, 'user_id': 'test_user_id', 'domain_id': 'default', 'type_deletion_list': ['load_balancer'] } action = DeleteOctaviaAction( data, task=task, order=1) action.pre_approve() self.assertEqual(action.valid, True) action.post_approve() self.assertEqual(action.valid, True) self.assertEqual( len(fake_clients.octavia_cache['RegionOne'][project.id][ 'load_balancer'].values()), 1) self.assertEqual( len(fake_clients.octavia_cache['RegionOne'][project.id][ 'listener']), 2) data = {""confirm"": True} action.submit(data) self.assertEqual(action.valid, True) self.assertEqual( len(fake_clients.octavia_cache['RegionOne'][project.id][ 'load_balancer']), 0) self.assertEqual( len(fake_clients.octavia_cache['RegionOne'][project.id][ 'listener']), 0) "," DeleteGlanceAction, DeleteNeutronAction, DisableKeystoneAction)",678,9
openstack%2Fpython-blazarclient~master~I2a5ab7f6d05c0351930f69d894005329ed637dd7,openstack/python-blazarclient,master,I2a5ab7f6d05c0351930f69d894005329ed637dd7,Support update lease API for instance reservation plugin,MERGED,2017-10-21 01:24:45.000000000,2017-12-19 02:17:22.000000000,2017-12-19 02:17:22.000000000,"[{'_account_id': 8878}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 23840}]","[{'number': 1, 'created': '2017-10-21 01:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/948e9d37dcb8a913dc9b2a466fb3abef686892ba', 'message': 'Support update lease API for instance reservation plugin\n\nThis patch enables Blazar CLI to support instance reservation update.\n\nChange-Id: I2a5ab7f6d05c0351930f69d894005329ed637dd7\nDepends-On: Ibdf7a730ae45ff6d8c17de62b0fc69262df2db79\n'}, {'number': 2, 'created': '2017-10-27 05:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/b05c78563c68eedbb3fbbc18960572a2f0377e8e', 'message': 'Support update lease API for instance reservation plugin\n\nThis patch enables Blazar CLI to support instance reservation update.\n\nChange-Id: I2a5ab7f6d05c0351930f69d894005329ed637dd7\nDepends-On: Ibdf7a730ae45ff6d8c17de62b0fc69262df2db79\n'}, {'number': 3, 'created': '2017-12-05 09:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/871985f913fbe250478ddcb4deaf2b314aa1bcf7', 'message': 'Support update lease API for instance reservation plugin\n\nThis patch enables Blazar CLI to support instance reservation update.\n\nChange-Id: I2a5ab7f6d05c0351930f69d894005329ed637dd7\nDepends-On: Ibdf7a730ae45ff6d8c17de62b0fc69262df2db79\n'}, {'number': 4, 'created': '2017-12-05 09:14:58.000000000', 'files': ['blazarclient/v1/shell_commands/leases.py', 'blazarclient/tests/v1/shell_commands/test_leases.py'], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/a46724a584b70658a26db745e70c1d8da539e09f', 'message': 'Support update lease API for instance reservation plugin\n\nThis patch adds instance reservation update support to the Blazar\ncommand-line client.\n\nChange-Id: I2a5ab7f6d05c0351930f69d894005329ed637dd7\nDepends-On: Ibdf7a730ae45ff6d8c17de62b0fc69262df2db79\n'}]",2,513888,a46724a584b70658a26db745e70c1d8da539e09f,16,4,4,8878,,,0,"Support update lease API for instance reservation plugin

This patch adds instance reservation update support to the Blazar
command-line client.

Change-Id: I2a5ab7f6d05c0351930f69d894005329ed637dd7
Depends-On: Ibdf7a730ae45ff6d8c17de62b0fc69262df2db79
",git fetch https://review.opendev.org/openstack/python-blazarclient refs/changes/88/513888/4 && git format-patch -1 --stdout FETCH_HEAD,"['blazarclient/v1/shell_commands/leases.py', 'blazarclient/tests/v1/shell_commands/test_leases.py']",2,948e9d37dcb8a913dc9b2a466fb3abef686892ba,instance-reservation-update," def test_args2body_instance_reservation_params(self): args = argparse.Namespace( name=None, prolong_for=None, reduce_by=None, end_date=None, defer_by=None, advance_by=None, start_date=None, reservation=[ 'id=798379a6-194c-45dc-ba34-1b5171d5552f,' 'vcpus=3,memory_mb=1024,disk_gb=20,' 'amount=4,affinity=False' ] ) expected = { 'reservations': [ { 'id': '798379a6-194c-45dc-ba34-1b5171d5552f', 'vcpus': 3, 'memory_mb': 1024, 'disk_gb': 20, 'amount': 4, 'affinity': 'False' } ] } self.assertDictEqual(self.cl.args2body(args), expected)",,32,2
openstack%2Fshade~master~Ic03a123cf57ff6fbd13da87e3203f2ef0e4b06b9,openstack/shade,master,Ic03a123cf57ff6fbd13da87e3203f2ef0e4b06b9,Add plumbing for betamax functional tests.,ABANDONED,2016-07-19 18:13:53.000000000,2017-12-19 02:16:37.000000000,,"[{'_account_id': 2}, {'_account_id': 2903}]","[{'number': 1, 'created': '2016-07-19 18:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/ac070abea2bd4769f5e0c474685524768ec4fa66', 'message': ""Migrate functional tests to betamax\n\nWe should run all of the functional tests under betamax. If we're\nrunning unittets, we run the recorded functional tests. If we're running\nfunctional tests, we run the functional tests live.\n\nChange-Id: Ic03a123cf57ff6fbd13da87e3203f2ef0e4b06b9\n""}, {'number': 2, 'created': '2016-07-19 19:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/1055127444a84d681ba40f6041085e42f0bbf3dd', 'message': ""Migrate functional tests to betamax\n\nWe should run all of the functional tests under betamax. If we're\nrunning unittets, we run the recorded functional tests. If we're running\nfunctional tests, we run the functional tests live.\n\nChange-Id: Ic03a123cf57ff6fbd13da87e3203f2ef0e4b06b9\n""}, {'number': 3, 'created': '2016-08-05 11:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/a6186950e5e7431dc85513a3534fafb934c889c7', 'message': ""Migrate functional tests to betamax\n\nWe should run all of the functional tests under betamax. If we're\nrunning unittets, we run the recorded functional tests. If we're running\nfunctional tests, we run the functional tests live.\n\nChange-Id: Ic03a123cf57ff6fbd13da87e3203f2ef0e4b06b9\n""}, {'number': 4, 'created': '2016-08-05 12:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/ea51337b685bf2594b356f7a483ec3346c221694', 'message': ""Add plumbing for betamax functional tests.\n\nWe should run all of the functional tests under betamax. If we're\nrunning unittets, we run the recorded functional tests. If we're running\nfunctional tests, we run the functional tests live.\n\nThis adds testscenarios generator to every functional test file that\nwill run the functional tests against cassettes if they exist for unit\ntests. It also does a pile of cleanup related to functional tests using\nthe admin cloud where the demo cloud would do just fine.\n\nChange-Id: Ic03a123cf57ff6fbd13da87e3203f2ef0e4b06b9\n""}, {'number': 5, 'created': '2016-08-05 21:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/2b24a3c4b45a86a7b9c3adf7b8d074db333208a9', 'message': ""Add plumbing for betamax functional tests.\n\nWe should run all of the functional tests under betamax. If we're\nrunning unittets, we run the recorded functional tests. If we're running\nfunctional tests, we run the functional tests live.\n\nThis adds testscenarios generator to every functional test file that\nwill run the functional tests against cassettes if they exist for unit\ntests. It also does a pile of cleanup related to functional tests using\nthe admin cloud where the demo cloud would do just fine.\n\nChange-Id: Ic03a123cf57ff6fbd13da87e3203f2ef0e4b06b9\n""}, {'number': 6, 'created': '2016-08-05 21:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/e73400971accc505669ba289fa8e6512c8f15910', 'message': ""Add plumbing for betamax functional tests.\n\nWe should run all of the functional tests under betamax. If we're\nrunning unittets, we run the recorded functional tests. If we're running\nfunctional tests, we run the functional tests live.\n\nThis adds testscenarios generator to every functional test file that\nwill run the functional tests against cassettes if they exist for unit\ntests. It also does a pile of cleanup related to functional tests using\nthe admin cloud where the demo cloud would do just fine.\n\nChange-Id: Ic03a123cf57ff6fbd13da87e3203f2ef0e4b06b9\n""}, {'number': 7, 'created': '2016-08-21 14:20:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/18ee87e211680a56e5b039b64fcc0b3b49d48db4', 'message': ""Add plumbing for betamax functional tests.\n\nWe should run all of the functional tests under betamax. If we're\nrunning unittets, we run the recorded functional tests. If we're running\nfunctional tests, we run the functional tests live.\n\nThis adds testscenarios generator to every functional test file that\nwill run the functional tests against cassettes if they exist for unit\ntests. It also does a pile of cleanup related to functional tests using\nthe admin cloud where the demo cloud would do just fine.\n\nChange-Id: Ic03a123cf57ff6fbd13da87e3203f2ef0e4b06b9\n""}, {'number': 8, 'created': '2016-08-21 17:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/7632a6dbf6aa4213b7c3cc1f1888ab6c6c2e5d71', 'message': ""Add plumbing for betamax functional tests.\n\nWe should run all of the functional tests under betamax. If we're\nrunning unittets, we run the recorded functional tests. If we're running\nfunctional tests, we run the functional tests live.\n\nThis adds testscenarios generator to every functional test file that\nwill run the functional tests against cassettes if they exist for unit\ntests. It also does a pile of cleanup related to functional tests using\nthe admin cloud where the demo cloud would do just fine.\n\nChange-Id: Ic03a123cf57ff6fbd13da87e3203f2ef0e4b06b9\n""}, {'number': 9, 'created': '2016-08-21 17:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/e9285db8a4288f40d2bc0eb3ec7f02e60d40157b', 'message': ""Add plumbing for betamax functional tests.\n\nWe should run all of the functional tests under betamax. If we're\nrunning unittets, we run the recorded functional tests. If we're running\nfunctional tests, we run the functional tests live.\n\nThis adds testscenarios generator to every functional test file that\nwill run the functional tests against cassettes if they exist for unit\ntests. It also does a pile of cleanup related to functional tests using\nthe admin cloud where the demo cloud would do just fine.\n\nChange-Id: Ic03a123cf57ff6fbd13da87e3203f2ef0e4b06b9\n""}, {'number': 10, 'created': '2016-09-21 11:55:13.000000000', 'files': ['shade/tests/functional/test_cluster_templates.py', 'shade/tests/functional/test_port.py', 'cassettes/README.rst', 'shade/tests/functional/test_domain.py', 'shade/tests/functional/test_inventory.py', 'shade/tests/functional/hooks/post_test_hook.sh', 'shade/tests/functional/test_endpoints.py', 'shade/tests/functional/test_services.py', 'shade/tests/functional/test_magnum_services.py', 'shade/tests/functional/test_stack.py', 'shade/tests/fixtures/clouds.yaml', 'shade/tests/functional/test_users.py', 'shade/tests/functional/test_floating_ip.py', 'shade/tests/functional/test_range_search.py', 'shade/tests/functional/test_floating_ip_pool.py', 'shade/tests/functional/base.py', 'shade/tests/functional/test_volume.py', 'shade/tests/functional/test_identity.py', 'shade/tests/functional/test_router.py', 'shade/tests/functional/test_server_group.py', 'doc/source/coding.rst', 'shade/tests/functional/test_project.py', 'shade/tests/functional/test_zone.py', '.testr.conf', 'shade/tests/functional/test_flavor.py', 'shade/tests/functional/test_image.py', 'shade/tests/functional/test_recordset.py', 'shade/tests/functional/test_object.py', 'shade/tests/functional/test_compute.py', 'shade/tests/functional/test_groups.py', 'shade/tests/functional/test_quotas.py', 'tox.ini', 'shade/tests/functional/test_aggregate.py', 'shade/tests/functional/test_network.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/86dbab613c130687087f0d425e6be23e7668530c', 'message': ""Add plumbing for betamax functional tests.\n\nWe should run all of the functional tests under betamax. If we're\nrunning unittets, we run the recorded functional tests. If we're running\nfunctional tests, we run the functional tests live.\n\nThis adds testscenarios generator to every functional test file that\nwill run the functional tests against cassettes if they exist for unit\ntests. It also does a pile of cleanup related to functional tests using\nthe admin cloud where the demo cloud would do just fine.\n\nChange-Id: Ic03a123cf57ff6fbd13da87e3203f2ef0e4b06b9\n""}]",11,344397,86dbab613c130687087f0d425e6be23e7668530c,26,2,10,2,,,0,"Add plumbing for betamax functional tests.

We should run all of the functional tests under betamax. If we're
running unittets, we run the recorded functional tests. If we're running
functional tests, we run the functional tests live.

This adds testscenarios generator to every functional test file that
will run the functional tests against cassettes if they exist for unit
tests. It also does a pile of cleanup related to functional tests using
the admin cloud where the demo cloud would do just fine.

Change-Id: Ic03a123cf57ff6fbd13da87e3203f2ef0e4b06b9
",git fetch https://review.opendev.org/openstack/shade refs/changes/97/344397/10 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/functional/test_baymodels.py', 'shade/tests/cassettes/citycloud/test_compute/TestCompute/test_set_and_delete_metadata.yaml', 'shade/tests/functional/test_port.py', 'shade/tests/functional/test_domain.py', 'shade/tests/functional/test_inventory.py', 'shade/tests/functional/hooks/post_test_hook.sh', 'shade/tests/functional/test_endpoints.py', 'shade/tests/functional/test_services.py', 'shade/tests/functional/test_magnum_services.py', 'shade/tests/functional/test_stack.py', 'shade/tests/fixtures/clouds.yaml', 'shade/tests/functional/test_users.py', 'shade/tests/functional/test_floating_ip.py', 'shade/tests/functional/test_range_search.py', 'shade/tests/functional/test_floating_ip_pool.py', 'shade/tests/functional/base.py', 'shade/tests/functional/test_volume.py', 'shade/tests/functional/test_identity.py', 'shade/tests/functional/test_router.py', 'shade/tests/functional/test_server_group.py', 'doc/source/coding.rst', 'shade/tests/functional/test_project.py', 'shade/tests/functional/test_zone.py', '.testr.conf', 'shade/tests/functional/test_flavor.py', 'shade/tests/functional/test_image.py', 'shade/tests/functional/test_recordset.py', 'shade/tests/functional/test_object.py', 'shade/tests/functional/test_compute.py', 'shade/tests/functional/test_groups.py', 'shade/tests/functional/test_quotas.py', 'tox.ini', 'shade/tests/functional/test_aggregate.py', 'shade/tests/functional/test_network.py']",34,ac070abea2bd4769f5e0c474685524768ec4fa66,fix-tests,"from testscenarios import load_tests_apply_scenarios as load_tests # noqa if not self.demo_cloud.has_service('network'): for network in self.demo_cloud.list_networks(): self.demo_cloud.delete_network(network['name']) net1 = self.demo_cloud.create_network(name=self.network_name) def test_list_networks_filtered(self): net1 = self.demo_cloud.create_network(name=self.network_name) self.assertIsNotNone(net1) net2 = self.demo_cloud.create_network( name=self.network_name + 'other') self.assertIsNotNone(net2) match = self.demo_cloud.list_networks( filters=dict(name=self.network_name)) self.assertEqual(1, len(match)) self.assertEqual(net1['name'], match[0]['name']) class TestAdminNetwork(base.OperatorFunctionalTestCase): def setUp(self): super(TestAdminNetwork, self).setUp() "," if not self.operator_cloud.has_service('network'): for network in self.operator_cloud.list_networks(): self.operator_cloud.delete_network(network['name']) net1 = self.operator_cloud.create_network(name=self.network_name) def test_list_networks_filtered(self): net1 = self.operator_cloud.create_network(name=self.network_name) self.assertIsNotNone(net1) net2 = self.operator_cloud.create_network( name=self.network_name + 'other') self.assertIsNotNone(net2) match = self.operator_cloud.list_networks( filters=dict(name=self.network_name)) self.assertEqual(1, len(match)) self.assertEqual(net1['name'], match[0]['name'])",33840,57
openstack%2Fnova~master~Ia6c87aecc1484a2366d50822b669291c9f954545,openstack/nova,master,Ia6c87aecc1484a2366d50822b669291c9f954545,Remove BuildRequest when scheduling fails,MERGED,2016-09-01 00:45:41.000000000,2017-12-19 01:55:41.000000000,2016-09-01 20:50:32.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}]","[{'number': 1, 'created': '2016-09-01 00:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39819da18b7810758d23eb4ba3441c108f02e298', 'message': ""Remove BuildRequest when scheduling fails\n\nIf there's a scheduler failure the instance is put into an error status\nand that's what should be returned by an instance show/list. However\nbecause the BuildRequest is not deleted that's what actually gets\nreturned. Delete the BuildRequest on scheduler failures.\n\nChange-Id: Ia6c87aecc1484a2366d50822b669291c9f954545\nPartially-implements: bp add-buildrequest-obj\n""}, {'number': 2, 'created': '2016-09-01 14:06:50.000000000', 'files': ['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f577f650c7ca9d8dd66eaec919e4805c09d16f6d', 'message': ""Remove BuildRequest when scheduling fails\n\nIf there's a scheduler failure the instance is put into an error status\nand that's what should be returned by an instance show/list. However\nbecause the BuildRequest is not deleted that's what actually gets\nreturned. Delete the BuildRequest on scheduler failures.\n\nChange-Id: Ia6c87aecc1484a2366d50822b669291c9f954545\nPartially-implements: bp add-buildrequest-obj\n""}]",9,364005,f577f650c7ca9d8dd66eaec919e4805c09d16f6d,34,13,2,5441,,,0,"Remove BuildRequest when scheduling fails

If there's a scheduler failure the instance is put into an error status
and that's what should be returned by an instance show/list. However
because the BuildRequest is not deleted that's what actually gets
returned. Delete the BuildRequest on scheduler failures.

Change-Id: Ia6c87aecc1484a2366d50822b669291c9f954545
Partially-implements: bp add-buildrequest-obj
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/364005/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/conductor/manager.py'],1,39819da18b7810758d23eb4ba3441c108f02e298,bp/add-buildrequest-obj," try: # If the BuildRequest stays around then instance show/lists # will pull from it rather than the errored instance. self._destroy_build_request(context, instance) except exception.BuildRequestNotFound: pass",,6,0
openstack%2Fkarbor~master~Id9ef136da4fab41b56bf917d0eb1b30caa9949f8,openstack/karbor,master,Id9ef136da4fab41b56bf917d0eb1b30caa9949f8,Add jsonschema validation for karbor scheduled operations API,MERGED,2017-12-18 03:10:41.000000000,2017-12-19 01:37:42.000000000,2017-12-19 01:37:42.000000000,"[{'_account_id': 17151}, {'_account_id': 21224}, {'_account_id': 22348}, {'_account_id': 26576}]","[{'number': 1, 'created': '2017-12-18 03:10:41.000000000', 'files': ['karbor/tests/unit/api/v1/test_scheduled_operation.py', 'karbor/api/v1/scheduled_operations.py', 'karbor/api/schemas/scheduled_operations.py'], 'web_link': 'https://opendev.org/openstack/karbor/commit/95db269d14a3bdfde58f8870ec2c691503a89e0e', 'message': 'Add jsonschema validation for karbor scheduled operations API\n\nChange-Id: Id9ef136da4fab41b56bf917d0eb1b30caa9949f8\nPartial-Implements: bp karbor-json-schema-validation\n'}]",0,528607,95db269d14a3bdfde58f8870ec2c691503a89e0e,8,4,1,17151,,,0,"Add jsonschema validation for karbor scheduled operations API

Change-Id: Id9ef136da4fab41b56bf917d0eb1b30caa9949f8
Partial-Implements: bp karbor-json-schema-validation
",git fetch https://review.opendev.org/openstack/karbor refs/changes/07/528607/1 && git format-patch -1 --stdout FETCH_HEAD,"['karbor/tests/unit/api/v1/test_scheduled_operation.py', 'karbor/api/v1/scheduled_operations.py', 'karbor/api/schemas/scheduled_operations.py']",3,95db269d14a3bdfde58f8870ec2c691503a89e0e,bp/karbor-json-schema-validation,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Schema for Karbor V1 scheduled operations API. """""" from karbor.api.validation import parameter_types create = { 'type': 'object', 'properties': { 'type': 'object', 'scheduled_operation': { 'type': 'object', 'properties': { 'name': parameter_types.name, 'description': parameter_types.description, 'operation_type': {'type': 'string'}, 'trigger_id': parameter_types.uuid, 'operation_definition': { 'type': 'object', 'properties': { 'provider_id': parameter_types.uuid, 'plan_id': parameter_types.uuid, }, 'required': ['provider_id', 'plan_id'], 'additionalProperties': False, }, }, 'required': ['operation_type', 'trigger_id', 'operation_definition'], 'additionalProperties': False, }, }, 'required': ['scheduled_operation'], 'additionalProperties': False, } ",,64,10
openstack%2Ffuel-library~master~I996ea315c7dc1156ee1d1e7ede8f6319ef9e2f68,openstack/fuel-library,master,I996ea315c7dc1156ee1d1e7ede8f6319ef9e2f68,Add swift::storage::filter::recon,ABANDONED,2017-11-13 10:22:45.000000000,2017-12-19 01:29:19.000000000,,"[{'_account_id': 17737}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-13 10:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e3d3a562d6b282812fd252fbfdd9d61fa40708eb', 'message': 'Add swift::storage::filter::recon\n\nChange-Id: I996ea315c7dc1156ee1d1e7ede8f6319ef9e2f68\nCloses-Bug: 1730937\n'}, {'number': 2, 'created': '2017-11-14 11:53:32.000000000', 'files': ['deployment/puppet/openstack_tasks/manifests/swift/parts/storage_node.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d466b1b906a9d137f4b71c1d28524e71420db5f2', 'message': 'Add swift::storage::filter::recon\n\nChange-Id: I996ea315c7dc1156ee1d1e7ede8f6319ef9e2f68\nCloses-Bug: 1730937\n'}]",0,519298,d466b1b906a9d137f4b71c1d28524e71420db5f2,6,2,2,13344,,,0,"Add swift::storage::filter::recon

Change-Id: I996ea315c7dc1156ee1d1e7ede8f6319ef9e2f68
Closes-Bug: 1730937
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/98/519298/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack_tasks/manifests/swift/parts/storage_node.pp'],1,e3d3a562d6b282812fd252fbfdd9d61fa40708eb,bug/1730937," swift::storage::filter::recon {'object': require => Class[swift], } ",,4,0
openstack%2Fpuppet-horizon~stable%2Fpike~I778b3dc076d611d40205edbe0982141a815e1830,openstack/puppet-horizon,stable/pike,I778b3dc076d611d40205edbe0982141a815e1830,Add parameter to configure instance defaults,MERGED,2017-12-18 20:31:56.000000000,2017-12-19 01:16:09.000000000,2017-12-19 01:16:09.000000000,"[{'_account_id': 3153}, {'_account_id': 8318}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 20:31:56.000000000', 'files': ['releasenotes/notes/added_instance_default_config_options-123cc41099d5e098.yaml', 'templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/31f0085cddf45de6e39f07049946950fae10da66', 'message': 'Add parameter to configure instance defaults\n\nNew parameter accepts a hash value to configure\nthe LAUNCH_INSTANCE_DEFAULTS options in horizon\nconfiguration.\n\nCloses-Bug: #1721774\nChange-Id: I778b3dc076d611d40205edbe0982141a815e1830\n(cherry picked from commit f583d96659bb8f9b0258fdb90b0b291ed1c43a4b)\n'}]",0,528809,31f0085cddf45de6e39f07049946950fae10da66,6,3,1,14985,,,0,"Add parameter to configure instance defaults

New parameter accepts a hash value to configure
the LAUNCH_INSTANCE_DEFAULTS options in horizon
configuration.

Closes-Bug: #1721774
Change-Id: I778b3dc076d611d40205edbe0982141a815e1830
(cherry picked from commit f583d96659bb8f9b0258fdb90b0b291ed1c43a4b)
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/09/528809/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/added_instance_default_config_options-123cc41099d5e098.yaml', 'templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb']",4,31f0085cddf45de6e39f07049946950fae10da66,bug/1721774," :instance_options => {'disable_image' => true, 'disable_instance_snapshot' => true, 'disable_volume' => true, 'disable_volume_snapshot' => true, 'create_volume' => false }, "" 'config_drive': False,"", "" 'create_volume': False,"", "" 'disable_image': True,"", "" 'disable_instance_snapshot': True,"", "" 'disable_volume': True,"", "" 'disable_volume_snapshot': True,"", "" 'enable_scheduler_hints': True,"",",,58,0
openstack%2Fpuppet-horizon~stable%2Fpike~I01d9fc44d957394acc4243f3ee34e6e50eec0bdf,openstack/puppet-horizon,stable/pike,I01d9fc44d957394acc4243f3ee34e6e50eec0bdf,Allow configuring 'CREATE_IMAGE_DEFAULTS' setting,MERGED,2017-12-18 20:31:56.000000000,2017-12-19 01:16:08.000000000,2017-12-19 01:16:08.000000000,"[{'_account_id': 1004}, {'_account_id': 3153}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 20:31:56.000000000', 'files': ['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/1134d806b85796a0741e72acffb94509febd2398', 'message': ""Allow configuring 'CREATE_IMAGE_DEFAULTS' setting\n\nHorizon now has the option of selecting various defaults for the\ncreate image panel.  This patch allows configuring those options.\n\nChange-Id: I01d9fc44d957394acc4243f3ee34e6e50eec0bdf\n(cherry picked from commit c60cb1a3927839014005af8ffda0433081331146)\n""}]",0,528808,1134d806b85796a0741e72acffb94509febd2398,6,3,1,14985,,,0,"Allow configuring 'CREATE_IMAGE_DEFAULTS' setting

Horizon now has the option of selecting various defaults for the
create image panel.  This patch allows configuring those options.

Change-Id: I01d9fc44d957394acc4243f3ee34e6e50eec0bdf
(cherry picked from commit c60cb1a3927839014005af8ffda0433081331146)
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/08/528808/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb']",3,1134d806b85796a0741e72acffb94509febd2398,bug/1721774," :create_image_defaults => {'image_visibility' => 'private'}, 'CREATE_IMAGE_DEFAULTS = {', "" 'image_visibility': 'private',"",",,22,1
openstack%2Frequirements~master~Ib87ea4b5d07d775b2299dbc262051045e8cf09cc,openstack/requirements,master,Ib87ea4b5d07d775b2299dbc262051045e8cf09cc,Bump castellan to 0.16.0,MERGED,2017-12-18 22:22:15.000000000,2017-12-19 01:14:36.000000000,2017-12-19 01:14:36.000000000,"[{'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 22:22:15.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/3017e60c6185a082bb587a748e63b1570ae5a5c4', 'message': 'Bump castellan to 0.16.0\n\nAs of Cinder change [1], Cinder is\nimplicitly requiring castellan 0.16.0\nto work correctly, as that release contains\nthis change [2].\n\n[1] https://review.openstack.org/#/c/524720/\n[2] https://review.openstack.org/#/c/514734/\n\nChange-Id: Ib87ea4b5d07d775b2299dbc262051045e8cf09cc\n'}]",0,528833,3017e60c6185a082bb587a748e63b1570ae5a5c4,7,4,1,4523,,,0,"Bump castellan to 0.16.0

As of Cinder change [1], Cinder is
implicitly requiring castellan 0.16.0
to work correctly, as that release contains
this change [2].

[1] https://review.openstack.org/#/c/524720/
[2] https://review.openstack.org/#/c/514734/

Change-Id: Ib87ea4b5d07d775b2299dbc262051045e8cf09cc
",git fetch https://review.opendev.org/openstack/requirements refs/changes/33/528833/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,3017e60c6185a082bb587a748e63b1570ae5a5c4,,castellan>=0.16.0 # Apache-2.0,castellan>=0.14.0 # Apache-2.0,1,1
openstack%2Fproject-config~master~I86a236b1b6f4a875481093b211eff7730054796c,openstack/project-config,master,I86a236b1b6f4a875481093b211eff7730054796c,Notify changes from neutron-vpnaas to neutron IRC,ABANDONED,2017-12-14 06:25:23.000000000,2017-12-19 01:10:45.000000000,,"[{'_account_id': 6854}, {'_account_id': 9061}, {'_account_id': 15905}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-14 06:25:23.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/00fa6bb420f5b4381be045db8261067e8bbd6fd6', 'message': 'Notify changes from neutron-vpnaas to neutron IRC\n\nneutron-vpnaas has just been jumped into neutron stadium.\nSo, we would like to add its changes to neutron IRC notification.\n\nDepends-on: I8c89a62566fdb332450b07448e96058933852675\n\nChange-Id: I86a236b1b6f4a875481093b211eff7730054796c\n'}]",0,527865,00fa6bb420f5b4381be045db8261067e8bbd6fd6,8,4,1,15905,,,0,"Notify changes from neutron-vpnaas to neutron IRC

neutron-vpnaas has just been jumped into neutron stadium.
So, we would like to add its changes to neutron IRC notification.

Depends-on: I8c89a62566fdb332450b07448e96058933852675

Change-Id: I86a236b1b6f4a875481093b211eff7730054796c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/65/527865/1 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,00fa6bb420f5b4381be045db8261067e8bbd6fd6,add-vpnaas-to-neutron, - openstack/neutron-vpnaas,,1,0
openstack%2Ftripleo-heat-templates~master~Ifc748648cc0f8caaf5a551fd0bc5724b94f3087d,openstack/tripleo-heat-templates,master,Ifc748648cc0f8caaf5a551fd0bc5724b94f3087d,Remove certificate before updating it,MERGED,2017-11-06 13:00:46.000000000,2017-12-19 01:08:23.000000000,2017-11-11 15:28:57.000000000,"[{'_account_id': 6926}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 17823}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-11-06 13:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fc6363ef223329d285126a42970d62beeb8a915d', 'message': 'Remove certificate before updating it\n\nContainerized HAProxy always tries to load the SSL certificate; if TLS\nis not enabled it will create the file as a directory. This messes up\nwith the script that actually injects the HAProxy certificate into the\nundercloud. To address this, we update that script to take this into\naccount.\n\nChange-Id: Ifc748648cc0f8caaf5a551fd0bc5724b94f3087d\nCloses-Bug: #1728267\n'}, {'number': 2, 'created': '2017-11-07 05:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4814f9e1f9a5a1fc9a20bdb94fb6841c40e6a6ed', 'message': 'Remove certificate before updating it\n\nContainerized HAProxy always tries to load the SSL certificate; if TLS\nis not enabled it will create the file as a directory. This messes up\nwith the script that actually injects the HAProxy certificate into the\nundercloud. To address this, we update that script to take this into\naccount.\n\nChange-Id: Ifc748648cc0f8caaf5a551fd0bc5724b94f3087d\nCloses-Bug: #1728267\n'}, {'number': 3, 'created': '2017-11-07 09:00:03.000000000', 'files': ['puppet/extraconfig/tls/tls-cert-inject.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d1f3b1f683216cf728846c6403994baefe02d5d6', 'message': 'Remove certificate before updating it\n\nContainerized HAProxy always tries to load the SSL certificate; if TLS\nis not enabled it will create the file as a directory. This messes up\nwith the script that actually injects the HAProxy certificate into the\nundercloud. To address this, we update that script to take this into\naccount.\n\nChange-Id: Ifc748648cc0f8caaf5a551fd0bc5724b94f3087d\nCloses-Bug: #1728267\n'}]",5,517984,d1f3b1f683216cf728846c6403994baefe02d5d6,27,9,3,10873,,,0,"Remove certificate before updating it

Containerized HAProxy always tries to load the SSL certificate; if TLS
is not enabled it will create the file as a directory. This messes up
with the script that actually injects the HAProxy certificate into the
undercloud. To address this, we update that script to take this into
account.

Change-Id: Ifc748648cc0f8caaf5a551fd0bc5724b94f3087d
Closes-Bug: #1728267
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/84/517984/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/extraconfig/tls/tls-cert-inject.yaml'],1,fc6363ef223329d285126a42970d62beeb8a915d,bug/1728267," # If the HAProxy container tried to load this, it'll be a directory and # will make this fail. rm -rf ${cert_path}",,3,0
openstack%2Frequirements~master~I741875eba329b762789a7c7c910a6c46beeff3fa,openstack/requirements,master,I741875eba329b762789a7c7c910a6c46beeff3fa,Bump oslo.utils to 3.33.0,MERGED,2017-12-18 03:20:31.000000000,2017-12-19 01:07:47.000000000,2017-12-19 01:07:47.000000000,"[{'_account_id': 6593}, {'_account_id': 12898}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 03:20:31.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/18e2f34a371aa0e71f016034aea9d8b8830f0603', 'message': 'Bump oslo.utils to 3.33.0\n\noslo.utils add method validate_integer, which can be used in\nCinder and Nova.\n\nChange-Id: I741875eba329b762789a7c7c910a6c46beeff3fa\n'}]",0,528610,18e2f34a371aa0e71f016034aea9d8b8830f0603,7,3,1,9796,,,0,"Bump oslo.utils to 3.33.0

oslo.utils add method validate_integer, which can be used in
Cinder and Nova.

Change-Id: I741875eba329b762789a7c7c910a6c46beeff3fa
",git fetch https://review.opendev.org/openstack/requirements refs/changes/10/528610/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,18e2f34a371aa0e71f016034aea9d8b8830f0603,oslo.utils,oslo.utils>=3.33.0 # Apache-2.0,oslo.utils>=3.31.0 # Apache-2.0,1,1
openstack%2Fmanila-tempest-plugin~master~I7c742475966b9fc4546ea676d969a2787dee973f,openstack/manila-tempest-plugin,master,I7c742475966b9fc4546ea676d969a2787dee973f,Moves test_security_services and test_share_networks tests,MERGED,2017-12-18 20:45:30.000000000,2017-12-19 00:53:38.000000000,2017-12-19 00:53:38.000000000,"[{'_account_id': 6491}, {'_account_id': 9003}, {'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 20:45:30.000000000', 'files': ['manila_tempest_tests/tests/api/test_share_networks_negative.py', 'manila_tempest_tests/tests/api/test_security_services_negative.py', 'manila_tempest_tests/tests/api/test_security_services.py', 'manila_tempest_tests/tests/api/test_share_networks.py'], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/2ce9a53e3e3b9f836196463ccabe82450a5e799d', 'message': 'Moves test_security_services and test_share_networks tests\n\nMoves ""Fix getting share networks and security services error""\nrelated tempest tests.\n\nRelated change: Ied021b66333f1254cd232bbc38562a4a9b762ad2\n\nTrivialFix\n\nChange-Id: I7c742475966b9fc4546ea676d969a2787dee973f\n'}]",0,528815,2ce9a53e3e3b9f836196463ccabe82450a5e799d,8,4,1,6413,,,0,"Moves test_security_services and test_share_networks tests

Moves ""Fix getting share networks and security services error""
related tempest tests.

Related change: Ied021b66333f1254cd232bbc38562a4a9b762ad2

TrivialFix

Change-Id: I7c742475966b9fc4546ea676d969a2787dee973f
",git fetch https://review.opendev.org/openstack/manila-tempest-plugin refs/changes/15/528815/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila_tempest_tests/tests/api/test_share_networks_negative.py', 'manila_tempest_tests/tests/api/test_security_services_negative.py', 'manila_tempest_tests/tests/api/test_security_services.py', 'manila_tempest_tests/tests/api/test_share_networks.py']",4,2ce9a53e3e3b9f836196463ccabe82450a5e799d,," def test_try_list_share_networks_all_tenants(self): listed = self.shares_client.list_share_networks_with_detail( params={'all_tenants': 1}) any(self.sn_with_ldap_ss[""id""] in sn[""id""] for sn in listed) # verify keys keys = [""name"", ""id""] [self.assertIn(key, sn.keys()) for sn in listed for key in keys] @tc.attr(base.TAG_POSITIVE, base.TAG_API) def test_try_list_share_networks_project_id(self): listed = self.shares_client.list_share_networks_with_detail( params={'project_id': 'some_project'}) any(self.sn_with_ldap_ss[""id""] in sn[""id""] for sn in listed) # verify keys keys = [""name"", ""id""] [self.assertIn(key, sn.keys()) for sn in listed for key in keys] @tc.attr(base.TAG_POSITIVE, base.TAG_API)",,28,18
openstack%2Fpuppet-openstacklib~stable%2Focata~I6b48842862a6860215ff774f73ae7224a34545e7,openstack/puppet-openstacklib,stable/ocata,I6b48842862a6860215ff774f73ae7224a34545e7,Ensure os_workers_large fact returns an Integer,MERGED,2017-12-18 18:54:17.000000000,2017-12-19 00:51:26.000000000,2017-12-19 00:51:26.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 18:54:17.000000000', 'files': ['spec/unit/facter/os_workers_spec.rb', 'releasenotes/notes/os_workers_large-fact-71afa253044ce56e.yaml', 'lib/facter/os_workers.rb', 'spec/unit/facter/os_workers_small_spec.rb', 'spec/unit/facter/os_workers_large_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/c869b478fffd610607f3b8058b98bfd97981cb95', 'message': 'Ensure os_workers_large fact returns an Integer\n\nAlso make sure it returns at least 1.\n\nCloses-bug: #1738082\nChange-Id: I6b48842862a6860215ff774f73ae7224a34545e7\n(cherry picked from commit e5005dc4ff40d75c5600723eb9a5b967aefb4a92)\n'}]",0,528789,c869b478fffd610607f3b8058b98bfd97981cb95,7,3,1,7156,,,0,"Ensure os_workers_large fact returns an Integer

Also make sure it returns at least 1.

Closes-bug: #1738082
Change-Id: I6b48842862a6860215ff774f73ae7224a34545e7
(cherry picked from commit e5005dc4ff40d75c5600723eb9a5b967aefb4a92)
",git fetch https://review.opendev.org/openstack/puppet-openstacklib refs/changes/89/528789/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/facter/os_workers_spec.rb', 'releasenotes/notes/os_workers_large-fact-71afa253044ce56e.yaml', 'lib/facter/os_workers.rb', 'spec/unit/facter/os_workers_small_spec.rb', 'spec/unit/facter/os_workers_large_spec.rb']",5,c869b478fffd610607f3b8058b98bfd97981cb95,bug/1738082-stable/pike-stable/ocata,require 'spec_helper' describe 'os_workers_large' do before { Facter.clear } after { Facter.clear } context 'with processorcount=1' do before do Facter.fact(:processorcount).stubs(:value).returns(1) end it 'returns a minimum of 1' do expect(Facter.fact(:os_workers_large).value).to eq(1) end end context 'with processorcount=8' do before do Facter.fact(:processorcount).stubs(:value).returns(8) end it 'returns processorcount/2' do expect(Facter.fact(:os_workers_large).value).to eq(4) end end end ,,107,1
openstack%2Fmurano~master~I69ce63b97548173ff470cc4ef5cc8c8216f02d13,openstack/murano,master,I69ce63b97548173ff470cc4ef5cc8c8216f02d13,Updated from global requirements,MERGED,2017-12-15 21:41:06.000000000,2017-12-19 00:43:40.000000000,2017-12-19 00:43:40.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2017-12-15 21:41:06.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/murano/commit/50ade74aa4520ff8d7546ceae923c3926304e0a9', 'message': 'Updated from global requirements\n\nChange-Id: I69ce63b97548173ff470cc4ef5cc8c8216f02d13\n'}]",0,528410,50ade74aa4520ff8d7546ceae923c3926304e0a9,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I69ce63b97548173ff470cc4ef5cc8c8216f02d13
",git fetch https://review.opendev.org/openstack/murano refs/changes/10/528410/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,50ade74aa4520ff8d7546ceae923c3926304e0a9,openstack/requirements,"oslo.service!=1.28.1,>=1.24.0 # Apache-2.0",oslo.service>=1.24.0 # Apache-2.0,1,1
openstack%2Frpm-packaging~master~Ic070b597c7b1e08348ff2ba3e84e29a1dce554da,openstack/rpm-packaging,master,Ic070b597c7b1e08348ff2ba3e84e29a1dce554da,Update oslo.service to 1.28.1,MERGED,2017-12-11 16:42:23.000000000,2017-12-19 00:41:16.000000000,2017-12-13 16:48:42.000000000,"[{'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-11 16:42:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/021333be5f7c4501d0f92cbd43c2dec497621e22', 'message': 'Update oslo.service to 1.28.1\n\nChange-Id: Ic070b597c7b1e08348ff2ba3e84e29a1dce554da\n'}, {'number': 2, 'created': '2017-12-12 23:54:43.000000000', 'files': ['openstack/oslo.service/oslo.service.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/f8283c94f683e96ad3dc0bbf4c3f185a97cf5086', 'message': 'Update oslo.service to 1.28.1\n\nDepends-on: I349e53273a7f259443b7bacc6d83af796caafa8e\nChange-Id: Ic070b597c7b1e08348ff2ba3e84e29a1dce554da\n'}]",0,527158,f8283c94f683e96ad3dc0bbf4c3f185a97cf5086,16,6,2,17130,,,0,"Update oslo.service to 1.28.1

Depends-on: I349e53273a7f259443b7bacc6d83af796caafa8e
Change-Id: Ic070b597c7b1e08348ff2ba3e84e29a1dce554da
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/58/527158/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.service/oslo.service.spec.j2'],1,021333be5f7c4501d0f92cbd43c2dec497621e22,oslo-service,{% set upstream_version = upstream_version('1.28.1') %},{% set upstream_version = upstream_version('1.28.0') %},1,1
openstack%2Fneutron~master~I069215c4f3031661b7ce2c692dcf4cce1bd29b6c,openstack/neutron,master,I069215c4f3031661b7ce2c692dcf4cce1bd29b6c,Allow __new__  method to accept extra arguments,MERGED,2017-01-18 16:36:09.000000000,2017-12-19 00:40:36.000000000,2017-12-19 00:40:36.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 7787}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10068}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 14208}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 17776}, {'_account_id': 20330}, {'_account_id': 22348}, {'_account_id': 24919}, {'_account_id': 26458}, {'_account_id': 27373}]","[{'number': 1, 'created': '2017-01-18 16:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/db86777439d8c6d215e783f7b36680c47a9b1167', 'message': 'Allow __new__  methods to accept extra arguments which are being overridden in l3_db.py\nso that the subclasses in their __init__ to accept arguments.\n\nChange-Id: I069215c4f3031661b7ce2c692dcf4cce1bd29b6c\nCloses-bug:#1657412\n'}, {'number': 2, 'created': '2017-01-18 18:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3dea50ae61e88db2f4e72ef4e956968e33ebe3d2', 'message': 'Allow __new__  methods to accept extra arguments\nwhich are being overridden in l3_db.py so that\nthe subclasses in their __init__ could accept arguments.\n\nChange-Id: I069215c4f3031661b7ce2c692dcf4cce1bd29b6c\nCloses-bug: #1657412\n'}, {'number': 3, 'created': '2017-01-18 18:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5942949e8794d882e8a45688b04c5e26ab6d560d', 'message': 'Allow __new__  methods to accept extra arguments\nwhich are being overridden in l3_db.py so\nthat the subclasses in their __init__ could\naccept arguments.\n\nChange-Id: I069215c4f3031661b7ce2c692dcf4cce1bd29b6c\nCloses-bug: #1657412\n'}, {'number': 4, 'created': '2017-01-19 14:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c0d9731f83657a2d46c31764a46d7c32fb84a218', 'message': 'Allow __new__  methods to accept extra arguments\n\nwhich are being overridden in l3_db.py so\nthat the subclasses in their __init__ could\naccept arguments.\n\nChange-Id: I069215c4f3031661b7ce2c692dcf4cce1bd29b6c\nCloses-bug: #1657412\n'}, {'number': 5, 'created': '2017-04-15 01:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e10f5b87281629d5fd67d34540dbebf357802140', 'message': 'Allow __new__  methods to accept extra arguments\n\nwhich are being overridden in l3_db.py so\nthat the subclasses in their __init__ could\naccept arguments.\n\nChange-Id: I069215c4f3031661b7ce2c692dcf4cce1bd29b6c\nCloses-bug: #1657412\n'}, {'number': 6, 'created': '2017-11-07 18:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/414d1c128b09c5bae9ec43d3779527eee3d19635', 'message': 'Allow __new__  method to accept extra arguments\n\nL3_NAT_dbonly_mixin accepts no extra arguments, but\nsome subclasses do want to be able to accept them.\n\nChange-Id: I069215c4f3031661b7ce2c692dcf4cce1bd29b6c\nCloses-bug: #1657412\n'}, {'number': 7, 'created': '2017-12-14 19:04:19.000000000', 'files': ['neutron/db/l3_db.py', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e862d280681bebecc590ce8853048287cb8d046a', 'message': 'Allow __new__  method to accept extra arguments\n\nL3_NAT_dbonly_mixin accepts no extra arguments, but\nsome subclasses do want to be able to accept them.\n\nChange-Id: I069215c4f3031661b7ce2c692dcf4cce1bd29b6c\nCloses-bug: #1657412\n'}]",10,422088,e862d280681bebecc590ce8853048287cb8d046a,84,20,7,24919,,,0,"Allow __new__  method to accept extra arguments

L3_NAT_dbonly_mixin accepts no extra arguments, but
some subclasses do want to be able to accept them.

Change-Id: I069215c4f3031661b7ce2c692dcf4cce1bd29b6c
Closes-bug: #1657412
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/422088/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_db.py'],1,db86777439d8c6d215e783f7b36680c47a9b1167,bug/1657412," def __new__(cls, *args, **kwargs): inst = super(L3_NAT_dbonly_mixin, cls).__new__(cls, *args, **kwargs) def __new__(cls, *args, **kwargs): return super(L3RpcNotifierMixin, cls).__new__(cls, *args, **kwargs)"," def __new__(cls): inst = super(L3_NAT_dbonly_mixin, cls).__new__(cls) def __new__(cls): return super(L3RpcNotifierMixin, cls).__new__(cls)",4,4
openstack%2Fmonasca-api~stable%2Focata~I7a6d259ffe15e310dd765327114e370289045fec,openstack/monasca-api,stable/ocata,I7a6d259ffe15e310dd765327114e370289045fec,Older versions of Kafka only available from archive.apache.org,ABANDONED,2017-12-05 16:38:23.000000000,2017-12-19 00:40:04.000000000,,"[{'_account_id': 10311}, {'_account_id': 11580}, {'_account_id': 14273}, {'_account_id': 14517}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-05 16:38:23.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/3eeb9fff736f8b1e5bc2cc97a2604a6101ad27c8', 'message': 'Older versions of Kafka only available from archive.apache.org\n\nThe apache.mirrors.tds.net site only has the latest two major\nversions of Kafka. As Ocata monasca-api needs Kafka 0.8.1.1, this\ncauses a 404 for devstack installs of stable/ocata.  Simple solution\nis to switch to the archive.apache.org site which has versions back\nas far as 0.8.0.\n\nNote this url change may need to be done for other branches\nin the future.\n\nChange-Id: I7a6d259ffe15e310dd765327114e370289045fec\n'}]",0,525682,3eeb9fff736f8b1e5bc2cc97a2604a6101ad27c8,10,5,1,10311,,,0,"Older versions of Kafka only available from archive.apache.org

The apache.mirrors.tds.net site only has the latest two major
versions of Kafka. As Ocata monasca-api needs Kafka 0.8.1.1, this
causes a 404 for devstack installs of stable/ocata.  Simple solution
is to switch to the archive.apache.org site which has versions back
as far as 0.8.0.

Note this url change may need to be done for other branches
in the future.

Change-Id: I7a6d259ffe15e310dd765327114e370289045fec
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/82/525682/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,3eeb9fff736f8b1e5bc2cc97a2604a6101ad27c8,ocata-old-kafka-version, local kafka_tarball_url=http://archive.apache.org/dist/kafka/${BASE_KAFKA_VERSION}/${kafka_tarball}, local kafka_tarball_url=http://apache.mirrors.tds.net/kafka/${BASE_KAFKA_VERSION}/${kafka_tarball},1,1
openstack%2Fpython-designateclient~master~I8ae98d08090e2e391ba725ddd5ff0125a03c8d47,openstack/python-designateclient,master,I8ae98d08090e2e391ba725ddd5ff0125a03c8d47,Split doc requirements into their own file,MERGED,2017-12-18 19:55:30.000000000,2017-12-19 00:38:00.000000000,2017-12-19 00:38:00.000000000,"[{'_account_id': 6547}, {'_account_id': 8099}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 19:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/42dc84383af9689069db9835f158268fb8e4c7c9', 'message': ""Split doc requirements into their own file\n\nWe don't need sphinx in the test virtualenvs, but we do need it for\ndocs.\n\nChange-Id: I8ae98d08090e2e391ba725ddd5ff0125a03c8d47\nDepends-On: Ie0c9f24df09255e871f904e079b68809144b36b4\n""}, {'number': 2, 'created': '2017-12-18 20:44:32.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/853dbddc2259fef333f0b5f3e6f215357e071a0b', 'message': ""Split doc requirements into their own file\n\nWe don't need sphinx in the test virtualenvs, but we do need it for\ndocs.\n\nChange-Id: I8ae98d08090e2e391ba725ddd5ff0125a03c8d47\nDepends-On: Ie0c9f24df09255e871f904e079b68809144b36b4\n""}]",0,528800,853dbddc2259fef333f0b5f3e6f215357e071a0b,13,3,2,2,,,0,"Split doc requirements into their own file

We don't need sphinx in the test virtualenvs, but we do need it for
docs.

Change-Id: I8ae98d08090e2e391ba725ddd5ff0125a03c8d47
Depends-On: Ie0c9f24df09255e871f904e079b68809144b36b4
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/00/528800/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,42dc84383af9689069db9835f158268fb8e4c7c9,updated-pti,deps = -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -r{toxinidir}/requirements.txt -r{toxinidir}/doc/requirements.txt commands = sphinx-build -b html doc/source doc/build/html,commands = rm -rf doc/build python setup.py build_sphinx,7,4
openstack%2Fpuppet-vitrage~stable%2Fpike~Idbff4de5e79f12fe7dda344d942adce9977f76df,openstack/puppet-vitrage,stable/pike,Idbff4de5e79f12fe7dda344d942adce9977f76df,Prepare for post-Pike updates,MERGED,2017-11-30 17:59:34.000000000,2017-12-19 00:08:13.000000000,2017-12-19 00:08:13.000000000,"[{'_account_id': 1004}, {'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-30 17:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-vitrage/commit/f55f67d60bb3917af4495ac40bafcdb22fa30687', 'message': 'Prepare for post-Pike updates\n\nPrepare the metadata for a post-Pike release.\n\nChange-Id: Idbff4de5e79f12fe7dda344d942adce9977f76df\n'}, {'number': 2, 'created': '2017-12-08 18:27:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-vitrage/commit/06426b3a85e211b40b8f96d5fe52b757524ac532', 'message': 'Prepare for post-Pike updates\n\nPrepare the metadata for a post-Pike release.\n\nChange-Id: Idbff4de5e79f12fe7dda344d942adce9977f76df\n'}, {'number': 3, 'created': '2017-12-08 19:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-vitrage/commit/c29a484d95c5524abaa07f73ba5bf810ef293159', 'message': 'Prepare for post-Pike updates\n\nPrepare the metadata for a post-Pike release.\n\nChange-Id: Idbff4de5e79f12fe7dda344d942adce9977f76df\n'}, {'number': 4, 'created': '2017-12-15 23:45:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-vitrage/commit/d200813ab8e6ce69469caa502b8e0c5086e3613d', 'message': 'Prepare for post-Pike updates\n\nPrepare the metadata for a post-Pike release.\n\nChange-Id: Idbff4de5e79f12fe7dda344d942adce9977f76df\n'}, {'number': 5, 'created': '2017-12-18 21:35:43.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-vitrage/commit/c786a4688576b3c37cc1a14a02a7907097104815', 'message': 'Prepare for post-Pike updates\n\nPrepare the metadata for a post-Pike release.\n\nChange-Id: Idbff4de5e79f12fe7dda344d942adce9977f76df\n'}]",0,524298,c786a4688576b3c37cc1a14a02a7907097104815,18,4,5,14985,,,0,"Prepare for post-Pike updates

Prepare the metadata for a post-Pike release.

Change-Id: Idbff4de5e79f12fe7dda344d942adce9977f76df
",git fetch https://review.opendev.org/openstack/puppet-vitrage refs/changes/98/524298/4 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,f55f67d60bb3917af4495ac40bafcdb22fa30687,post-pike-release," ""name"": ""openstack-vitrage"", ""version"": ""1.0.1"", ""author"": ""OpenStack Contributors"", ""summary"": ""Puppet module for OpenStack Vitrage"", ""license"": ""Apache-2.0"", ""source"": ""git://github.com/openstack/puppet-vitrage.git"", ""project_page"": ""https://launchpad.net/puppet-vitrage"", ""issues_url"": ""https://bugs.launchpad.net/puppet-vitrage"", ""description"": ""Installs and configures OpenStack Vitrage."", ""requirements"": [ { ""name"": ""pe"", ""version_requirement"": ""4.x"" }, { ""name"": ""puppet"", ""version_requirement"": ""4.x"" } ], ""operatingsystem_support"": [ { ""operatingsystem"": ""Debian"", ""operatingsystemrelease"": [ ""8"" ] }, { ""operatingsystem"": ""Fedora"", ""operatingsystemrelease"": [ ""21"", ""22"" ] }, { ""operatingsystem"": ""RedHat"", ""operatingsystemrelease"": [ ""7"" ] }, { ""operatingsystem"": ""Ubuntu"", ""operatingsystemrelease"": [ ""14.04"", ""16.04"" ] } ], ""dependencies"": [ { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">= 4.2.0 <5.0.0"" }, { ""name"": ""openstack/openstacklib"", ""version_requirement"": "">=11.3.0 <12.0.0"" }, { ""name"": ""openstack/keystone"", ""version_requirement"": "">=11.3.0 <12.0.0"" }, { ""name"": ""openstack/oslo"", ""version_requirement"": "">=11.3.0 <12.0.0"" } ]"," ""name"": ""openstack-vitrage"", ""version"": ""1.0.0"", ""author"": ""OpenStack Contributors"", ""summary"": ""Puppet module for OpenStack Vitrage"", ""license"": ""Apache-2.0"", ""source"": ""git://github.com/openstack/puppet-vitrage.git"", ""project_page"": ""https://launchpad.net/puppet-vitrage"", ""issues_url"": ""https://bugs.launchpad.net/puppet-vitrage"", ""description"": ""Installs and configures OpenStack Vitrage."", ""requirements"": [ { ""name"": ""pe"", ""version_requirement"": ""4.x"" }, { ""name"": ""puppet"", ""version_requirement"": ""4.x"" } ], ""operatingsystem_support"": [ { ""operatingsystem"": ""Debian"", ""operatingsystemrelease"": [""8""] }, { ""operatingsystem"": ""Fedora"", ""operatingsystemrelease"": [""21"",""22""] }, { ""operatingsystem"": ""RedHat"", ""operatingsystemrelease"": [""7""] }, { ""operatingsystem"": ""Ubuntu"", ""operatingsystemrelease"": [""14.04"",""16.04""] } ], ""dependencies"": [ { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">= 4.2.0 <5.0.0"" }, { ""name"": ""openstack/openstacklib"", ""version_requirement"": "">=9.1.0 <10.0.0"" }, { ""name"": ""openstack/keystone"", ""version_requirement"": "">=9.1.0 <10.0.0""}, { ""name"": ""openstack/oslo"", ""version_requirement"": "">=9.1.0 <10.0.0"" } ]",69,44
openstack%2Fpuppet-vitrage~stable%2Fpike~I998f04a0badf399edd55185eddd628ed59656cfb,openstack/puppet-vitrage,stable/pike,I998f04a0badf399edd55185eddd628ed59656cfb,"[pike] Add Puppet package to bindep, for module build",MERGED,2017-12-18 21:35:30.000000000,2017-12-19 00:08:12.000000000,2017-12-19 00:08:12.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 21:35:30.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/puppet-vitrage/commit/e0c31459436c92e192d13b216f003ea1c43f4244', 'message': '[pike] Add Puppet package to bindep, for module build\n\nWe need Puppet package deployed from bindep so we can\nrun puppet module build with the new zuul v3 job.\n\nChange-Id: I998f04a0badf399edd55185eddd628ed59656cfb\n(cherry picked from commit d3350118ee0ed84086eda18b582a1c3a43b2bf1a)\n'}]",0,528825,e0c31459436c92e192d13b216f003ea1c43f4244,6,2,1,14985,,,0,"[pike] Add Puppet package to bindep, for module build

We need Puppet package deployed from bindep so we can
run puppet module build with the new zuul v3 job.

Change-Id: I998f04a0badf399edd55185eddd628ed59656cfb
(cherry picked from commit d3350118ee0ed84086eda18b582a1c3a43b2bf1a)
",git fetch https://review.opendev.org/openstack/puppet-vitrage refs/changes/25/528825/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,e0c31459436c92e192d13b216f003ea1c43f4244,bindep/puppet-stable/pike,puppet [build],,1,0
openstack%2Fpython-designateclient~master~I597f7a50c9bc0f9f1b58b5c85b20277f6de715d7,openstack/python-designateclient,master,I597f7a50c9bc0f9f1b58b5c85b20277f6de715d7,Update doc build for new PTI,ABANDONED,2017-12-18 19:50:50.000000000,2017-12-19 00:07:11.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-12-18 19:50:50.000000000', 'files': ['.gitignore', 'doc/source/reference/index.rst', 'test-requirements.txt', 'doc/source/conf.py', 'doc/requirements.txt', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/54c999cb0d4cc376355fc310fb1677915b5c5ec1', 'message': ""Update doc build for new PTI\n\nThe PTI has updated and unfortunately the pbr autoindex stuff was\ninintended carnage. Turn it off and remove the reference to it so that\ndocs builds don't break.\n\nChange-Id: I597f7a50c9bc0f9f1b58b5c85b20277f6de715d7\n""}]",0,528797,54c999cb0d4cc376355fc310fb1677915b5c5ec1,3,1,1,2,,,0,"Update doc build for new PTI

The PTI has updated and unfortunately the pbr autoindex stuff was
inintended carnage. Turn it off and remove the reference to it so that
docs builds don't break.

Change-Id: I597f7a50c9bc0f9f1b58b5c85b20277f6de715d7
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/97/528797/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'doc/source/reference/index.rst', 'test-requirements.txt', 'doc/source/conf.py', 'doc/requirements.txt', 'setup.cfg', 'tox.ini']",7,54c999cb0d4cc376355fc310fb1677915b5c5ec1,updated-pti,deps = -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -r{toxinidir}/requirements.txt -r{toxinidir}/doc/requirements.txt commands = sphinx-build -b html doc/source doc/build/html,commands = rm -rf doc/build python setup.py build_sphinx,8,17
openstack%2Ftripleo-quickstart~master~I41add30cc8a71f86529b18e417a396992277fd9a,openstack/tripleo-quickstart,master,I41add30cc8a71f86529b18e417a396992277fd9a,Switch gate-check to THT patch,MERGED,2017-12-18 17:56:43.000000000,2017-12-19 00:07:09.000000000,2017-12-19 00:07:09.000000000,"[{'_account_id': 9976}, {'_account_id': 12715}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-12-18 17:56:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/79645bb4ca2b510609724d6d4167d20474322649', 'message': 'Switch gate-check to THT patch\n\nOur gate-check jobs have been broken for a while due to a\npackaging issue with tripleo-ui. This switches to using a THT\npatch so that we can keep getting feedback that our gates work\non a no-op change. We can switch back to the tripleo-ui patch\nonce the related bug is fixed.\n\nChange-Id: I41add30cc8a71f86529b18e417a396992277fd9a\nRelated-Bug: 1737335\n'}, {'number': 2, 'created': '2017-12-18 18:08:59.000000000', 'files': ['ci-scripts/full-deploy-ovb.sh', 'ci-scripts/full-deploy.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/fa91b3a03d509b24952501e3749d9b94b3c8af43', 'message': 'Switch gate-check to THT patch\n\nOur gate-check jobs have been broken for a while due to a\npackaging issue with tripleo-ui. This switches to using a THT\npatch so that we can keep getting feedback that our gates work\non a no-op change. We can switch back to the tripleo-ui patch\nonce the related bug is fixed.\n\nChange-Id: I41add30cc8a71f86529b18e417a396992277fd9a\nRelated-Bug: 1737335\n'}]",0,528775,fa91b3a03d509b24952501e3749d9b94b3c8af43,14,5,2,12715,,,0,"Switch gate-check to THT patch

Our gate-check jobs have been broken for a while due to a
packaging issue with tripleo-ui. This switches to using a THT
patch so that we can keep getting feedback that our gates work
on a no-op change. We can switch back to the tripleo-ui patch
once the related bug is fixed.

Change-Id: I41add30cc8a71f86529b18e417a396992277fd9a
Related-Bug: 1737335
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/75/528775/2 && git format-patch -1 --stdout FETCH_HEAD,['ci-scripts/full-deploy.sh'],1,79645bb4ca2b510609724d6d4167d20474322649,bug/1737335, export ZUUL_CHANGES=openstack/tripleo-heat-templates:master:refs/changes/70/528770/1, export ZUUL_CHANGES=openstack/tripleo-ui:master:refs/changes/25/422025/6,1,1
openstack%2Fpython-tripleoclient~master~Ie6b6a8578e4d12503a3dbfa5747309033d53466e,openstack/python-tripleoclient,master,Ie6b6a8578e4d12503a3dbfa5747309033d53466e,Remove Old baremetal commands provided by python-tripleoclient,MERGED,2017-12-18 00:58:32.000000000,2017-12-19 00:07:07.000000000,2017-12-19 00:07:07.000000000,"[{'_account_id': 3153}, {'_account_id': 9317}, {'_account_id': 9712}, {'_account_id': 12898}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 00:58:32.000000000', 'files': ['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/tests/v1/baremetal/fakes.py', 'tripleoclient/tests/v1/baremetal/test_baremetal.py', 'tripleoclient/v1/baremetal.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ada02718a1fcbc121bfcb4fe005c3df2989a214b', 'message': ""Remove Old baremetal commands provided by python-tripleoclient\n\npython-tripleoclient provides the following openstack baremetal\ncommands:\n\nopenstack baremetal instackenv validate:\nopenstack baremetal import:\nopenstack baremetal introspection bulk start:\nopenstack baremetal introspection bulk status:\nopenstack baremetal configure ready state:\nopenstack baremetal configure boot:\n\nBased on the data below several of these are already deprecated and have\nbeen so longer enough to be removed.\n\nopenstack baremetal instackenv validate:\n    tripleoclient.v1.baremetal:ValidateInstackEnv\n    NOT Deprecated\nopenstack baremetal import:\n    tripleoclient.v1.baremetal:ImportBaremetal\n    DEPRECATED in b272a5c6 2017-01-03\n    New command: openstack overcloud node import\nopenstack baremetal introspection bulk start:\n    tripleoclient.v1.baremetal:StartBaremetalIntrospectionBulk\n    DEPRECATED in b272a5c6 2017-01-03\n    New command: openstack overcloud node introspect\nopenstack baremetal introspection bulk status:\n    tripleoclient.v1.baremetal:StatusBaremetalIntrospectionBulk\n    NOT Deprecated\nopenstack baremetal configure ready state:\n    tripleoclient.v1.baremetal:ConfigureReadyState\n    NOT Deprecated\nopenstack baremetal configure boot:\n    tripleoclient.v1.baremetal:ConfigureBaremetalBoot\n    DEPRECATED in b272a5c6 2017-01-03\n    New command: openstack overcloud node configure\n\nThis leaves:\nopenstack baremetal instackenv validate\n- This is somewhat superceded by the mistral validation in\n  tripleo-common\nopenstack baremetal introspection bulk status\n- This should have been deprecated along with\n  'openstack baremetal introspection bulk start' and isn't useful without\n  the former.\nopenstack baremetal configure ready state\n- Seems to only support drac and requires a datafile no loner generated\n  by tools\n\nAs these commands have outlived their useful lifetime and do not require\ndeprecation we're free to remove them so let do it.\n\nChange-Id: Ie6b6a8578e4d12503a3dbfa5747309033d53466e\n""}]",0,528593,ada02718a1fcbc121bfcb4fe005c3df2989a214b,13,6,1,12898,,,0,"Remove Old baremetal commands provided by python-tripleoclient

python-tripleoclient provides the following openstack baremetal
commands:

openstack baremetal instackenv validate:
openstack baremetal import:
openstack baremetal introspection bulk start:
openstack baremetal introspection bulk status:
openstack baremetal configure ready state:
openstack baremetal configure boot:

Based on the data below several of these are already deprecated and have
been so longer enough to be removed.

openstack baremetal instackenv validate:
    tripleoclient.v1.baremetal:ValidateInstackEnv
    NOT Deprecated
openstack baremetal import:
    tripleoclient.v1.baremetal:ImportBaremetal
    DEPRECATED in b272a5c6 2017-01-03
    New command: openstack overcloud node import
openstack baremetal introspection bulk start:
    tripleoclient.v1.baremetal:StartBaremetalIntrospectionBulk
    DEPRECATED in b272a5c6 2017-01-03
    New command: openstack overcloud node introspect
openstack baremetal introspection bulk status:
    tripleoclient.v1.baremetal:StatusBaremetalIntrospectionBulk
    NOT Deprecated
openstack baremetal configure ready state:
    tripleoclient.v1.baremetal:ConfigureReadyState
    NOT Deprecated
openstack baremetal configure boot:
    tripleoclient.v1.baremetal:ConfigureBaremetalBoot
    DEPRECATED in b272a5c6 2017-01-03
    New command: openstack overcloud node configure

This leaves:
openstack baremetal instackenv validate
- This is somewhat superceded by the mistral validation in
  tripleo-common
openstack baremetal introspection bulk status
- This should have been deprecated along with
  'openstack baremetal introspection bulk start' and isn't useful without
  the former.
openstack baremetal configure ready state
- Seems to only support drac and requires a datafile no loner generated
  by tools

As these commands have outlived their useful lifetime and do not require
deprecation we're free to remove them so let do it.

Change-Id: Ie6b6a8578e4d12503a3dbfa5747309033d53466e
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/93/528593/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/tests/v1/baremetal/fakes.py', 'tripleoclient/tests/v1/baremetal/test_baremetal.py', 'tripleoclient/v1/baremetal.py', 'setup.cfg']",5,ada02718a1fcbc121bfcb4fe005c3df2989a214b,feature/remove-baremetal-commands,, baremetal_instackenv_validate = tripleoclient.v1.baremetal:ValidateInstackEnv baremetal_import = tripleoclient.v1.baremetal:ImportBaremetal baremetal_introspection_bulk_start = tripleoclient.v1.baremetal:StartBaremetalIntrospectionBulk baremetal_introspection_bulk_status = tripleoclient.v1.baremetal:StatusBaremetalIntrospectionBulk baremetal_configure_ready_state = tripleoclient.v1.baremetal:ConfigureReadyState baremetal_configure_boot = tripleoclient.v1.baremetal:ConfigureBaremetalBoot,1,1535
openstack%2Fpython-designateclient~master~I101424b101d7cc7de5e9249400b5e1c05ce98411,openstack/python-designateclient,master,I101424b101d7cc7de5e9249400b5e1c05ce98411,Add the old autoindex files as manually curated files,ABANDONED,2017-12-18 19:50:50.000000000,2017-12-19 00:07:01.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-12-18 19:50:50.000000000', 'files': ['doc/source/reference/api/designateclient.v1.touch.rst', 'doc/source/reference/api/designateclient.v2.utils.rst', 'doc/source/reference/api/designateclient.v2.cli.recordsets.rst', 'doc/source/reference/api/designateclient.v2.reverse.rst', 'doc/source/reference/api/designateclient.v1.records.rst', 'doc/source/reference/api/designateclient.cli.diagnostics.rst', 'doc/source/reference/api/designateclient.cli.reports.rst', 'doc/source/reference/api/designateclient.v2.cli.tlds.rst', 'doc/source/reference/api/designateclient.v2.zones.rst', 'doc/source/reference/api/designateclient.v2.nameservers.rst', 'doc/source/reference/api/designateclient.v2.pools.rst', 'doc/source/reference/api/designateclient.cli.servers.rst', 'doc/source/reference/api/designateclient.v2.service_statuses.rst', 'doc/source/reference/api/designateclient.v2.client.rst', 'doc/source/reference/api/designateclient.cli.quotas.rst', 'doc/source/reference/api/designateclient.v2.base.rst', 'doc/source/reference/api/designateclient.v1.quotas.rst', 'doc/source/reference/api/designateclient.cli.records.rst', 'doc/source/reference/api/designateclient.v1.servers.rst', 'doc/source/reference/api/designateclient.client.rst', 'doc/source/reference/api/designateclient.v2.tlds.rst', 'doc/source/reference/api/designateclient.v2.cli.service_statuses.rst', 'doc/source/reference/api/designateclient.v2.quotas.rst', 'doc/source/reference/api/designateclient.v1.domains.rst', 'doc/source/reference/api/designateclient.v2.cli.blacklists.rst', '.gitignore', 'doc/source/reference/api/index.rst', 'doc/source/reference/api/designateclient.v1.diagnostics.rst', 'doc/source/reference/api/designateclient.shell.rst', 'doc/source/reference/api/designateclient.osc.plugin.rst', 'doc/source/reference/api/designateclient.v2.cli.reverse.rst', 'doc/source/reference/api/designateclient.v2.cli.zones.rst', 'doc/source/reference/api/designateclient.v1.reports.rst', 'doc/source/reference/api/designateclient.warlock.rst', 'doc/source/reference/api/designateclient.v2.cli.common.rst', 'doc/source/reference/api/designateclient.v2.recordsets.rst', 'doc/source/reference/api/designateclient.cli.sync.rst', 'doc/source/reference/api/designateclient.v2.cli.tsigkeys.rst', 'doc/source/reference/api/designateclient.version.rst', 'doc/source/reference/api/designateclient.cli.base.rst', 'doc/source/reference/index.rst', 'doc/source/reference/api/designateclient.exceptions.rst', 'doc/source/reference/api/designateclient.cli.domains.rst', 'doc/source/reference/api/designateclient.v1.sync.rst', 'doc/source/reference/api/designateclient.v2.cli.quotas.rst', 'doc/source/reference/api/designateclient.cli.touch.rst', 'doc/source/reference/api/designateclient.utils.rst', 'doc/source/reference/api/designateclient.v2.limits.rst', 'doc/source/reference/api/designateclient.v2.tsigkeys.rst', 'doc/source/reference/api/designateclient.v2.blacklists.rst'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/0c91c26cb7891d98a841d98bdcf02b2f1382dcff', 'message': 'Add the old autoindex files as manually curated files\n\nUntil such a time as we have a good option for replacing\nautodoc_index_module (hopefully not soon) - one of the options is simply\ncommitting the originally generated code and managing it as source code\nmoving foward. This does that.\n\nChange-Id: I101424b101d7cc7de5e9249400b5e1c05ce98411\n'}]",0,528798,0c91c26cb7891d98a841d98bdcf02b2f1382dcff,3,1,1,2,,,0,"Add the old autoindex files as manually curated files

Until such a time as we have a good option for replacing
autodoc_index_module (hopefully not soon) - one of the options is simply
committing the originally generated code and managing it as source code
moving foward. This does that.

Change-Id: I101424b101d7cc7de5e9249400b5e1c05ce98411
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/98/528798/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/reference/api/designateclient.v1.touch.rst', 'doc/source/reference/api/designateclient.v2.utils.rst', 'doc/source/reference/api/designateclient.v2.cli.recordsets.rst', 'doc/source/reference/api/designateclient.v2.reverse.rst', 'doc/source/reference/api/designateclient.v1.records.rst', 'doc/source/reference/api/designateclient.cli.diagnostics.rst', 'doc/source/reference/api/designateclient.cli.reports.rst', 'doc/source/reference/api/designateclient.v2.cli.tlds.rst', 'doc/source/reference/api/designateclient.v2.zones.rst', 'doc/source/reference/api/designateclient.v2.nameservers.rst', 'doc/source/reference/api/designateclient.v2.pools.rst', 'doc/source/reference/api/designateclient.cli.servers.rst', 'doc/source/reference/api/designateclient.v2.service_statuses.rst', 'doc/source/reference/api/designateclient.v2.client.rst', 'doc/source/reference/api/designateclient.cli.quotas.rst', 'doc/source/reference/api/designateclient.v2.base.rst', 'doc/source/reference/api/designateclient.v1.quotas.rst', 'doc/source/reference/api/designateclient.cli.records.rst', 'doc/source/reference/api/designateclient.v1.servers.rst', 'doc/source/reference/api/designateclient.client.rst', 'doc/source/reference/api/designateclient.v2.tlds.rst', 'doc/source/reference/api/designateclient.v2.cli.service_statuses.rst', 'doc/source/reference/api/designateclient.v2.quotas.rst', 'doc/source/reference/api/designateclient.v1.domains.rst', 'doc/source/reference/api/designateclient.v2.cli.blacklists.rst', '.gitignore', 'doc/source/reference/api/index.rst', 'doc/source/reference/api/designateclient.v1.diagnostics.rst', 'doc/source/reference/api/designateclient.shell.rst', 'doc/source/reference/api/designateclient.osc.plugin.rst', 'doc/source/reference/api/designateclient.v2.cli.reverse.rst', 'doc/source/reference/api/designateclient.v2.cli.zones.rst', 'doc/source/reference/api/designateclient.v1.reports.rst', 'doc/source/reference/api/designateclient.warlock.rst', 'doc/source/reference/api/designateclient.v2.cli.common.rst', 'doc/source/reference/api/designateclient.v2.recordsets.rst', 'doc/source/reference/api/designateclient.cli.sync.rst', 'doc/source/reference/api/designateclient.v2.cli.tsigkeys.rst', 'doc/source/reference/api/designateclient.version.rst', 'doc/source/reference/api/designateclient.cli.base.rst', 'doc/source/reference/index.rst', 'doc/source/reference/api/designateclient.exceptions.rst', 'doc/source/reference/api/designateclient.cli.domains.rst', 'doc/source/reference/api/designateclient.v1.sync.rst', 'doc/source/reference/api/designateclient.v2.cli.quotas.rst', 'doc/source/reference/api/designateclient.cli.touch.rst', 'doc/source/reference/api/designateclient.utils.rst', 'doc/source/reference/api/designateclient.v2.limits.rst', 'doc/source/reference/api/designateclient.v2.tsigkeys.rst', 'doc/source/reference/api/designateclient.v2.blacklists.rst']",50,0c91c26cb7891d98a841d98bdcf02b2f1382dcff,updated-pti,The :mod:`designateclient.v2.blacklists` Module =============================================== .. automodule:: designateclient.v2.blacklists :members: :undoc-members: :show-inheritance: ,,383,1
openstack%2Fopenstack-ansible~master~Ib879d73ad99d3479eb7d29f2084f7c312a537e3a,openstack/openstack-ansible,master,Ib879d73ad99d3479eb7d29f2084f7c312a537e3a,Remove galera_address from playbook vars,MERGED,2017-12-13 20:34:38.000000000,2017-12-18 22:45:26.000000000,2017-12-18 22:45:26.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 22348}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-12-13 20:34:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/980eddbd09a4b3bd299b40cba0c4d35ba78e0d46', 'message': ""Remove galera_address from playbook vars\n\nWhen run against a galera server, the galera_client role will now\ndirectly its config to use a local server address. This also avoids\nprecedence issues if 'galera_address' was overridden through extra vars.\n\nDepends-On: I468b171c1e72697ea6450fe08aa0acb3faf91201\nChange-Id: Ib879d73ad99d3479eb7d29f2084f7c312a537e3a\n""}, {'number': 2, 'created': '2017-12-14 11:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6993db5e64b3ce93a861768c5e042dfd96ecae04', 'message': ""Remove galera_address from playbook vars\n\nWhen run against a galera server, the galera_client role will now\ndirectly its config to use a local server address. This also avoids\nprecedence issues if 'galera_address' was overridden through extra vars.\n\nDepends-On: I468b171c1e72697ea6450fe08aa0acb3faf91201\nChange-Id: Ib879d73ad99d3479eb7d29f2084f7c312a537e3a\n""}, {'number': 3, 'created': '2017-12-14 11:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/44d0334debb37dbd8798e5d717ff6a7c656f82fe', 'message': ""Remove galera_address from playbook vars\n\nWhen run against a galera server, the galera_client role will now\ndirectly its config to use a local server address. This also avoids\nprecedence issues if 'galera_address' was overridden through extra vars.\n\nDepends-On: I468b171c1e72697ea6450fe08aa0acb3faf91201\nChange-Id: Ib879d73ad99d3479eb7d29f2084f7c312a537e3a\n""}, {'number': 4, 'created': '2017-12-18 16:07:57.000000000', 'files': ['playbooks/galera-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b40fddb9fc8e8bd5e7199e604602bca46e5abe03', 'message': ""Remove galera_address from playbook vars\n\nWhen run against a galera server, the galera_client role will now\ndirectly its config to use a local server address. This also avoids\nprecedence issues if 'galera_address' was overridden through extra vars.\n\nDepends-On: I468b171c1e72697ea6450fe08aa0acb3faf91201\nChange-Id: Ib879d73ad99d3479eb7d29f2084f7c312a537e3a\n""}]",0,527778,b40fddb9fc8e8bd5e7199e604602bca46e5abe03,28,7,4,14805,,,0,"Remove galera_address from playbook vars

When run against a galera server, the galera_client role will now
directly its config to use a local server address. This also avoids
precedence issues if 'galera_address' was overridden through extra vars.

Depends-On: I468b171c1e72697ea6450fe08aa0acb3faf91201
Change-Id: Ib879d73ad99d3479eb7d29f2084f7c312a537e3a
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/78/527778/3 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/galera-install.yml'],1,980eddbd09a4b3bd299b40cba0c4d35ba78e0d46,remove_galera_address_play_var,, # overridden here to ensure the correct value for the galera_client role galera_address: 127.0.0.1,0,2
openstack%2Felection~master~I79a4940c36b7bef921c451de483b341f165f01d5,openstack/election,master,I79a4940c36b7bef921c451de483b341f165f01d5,Update ReadMe,MERGED,2017-12-11 20:56:54.000000000,2017-12-18 22:13:08.000000000,2017-12-18 22:13:08.000000000,"[{'_account_id': 6088}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 20:56:54.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/election/commit/ae99d7900626fd41754df6c05e1299811247f85e', 'message': 'Update ReadMe\n\nAdd info about the timing and picking of dates.\n\nChange-Id: I79a4940c36b7bef921c451de483b341f165f01d5\n'}]",0,527236,ae99d7900626fd41754df6c05e1299811247f85e,8,4,1,16708,,,0,"Update ReadMe

Add info about the timing and picking of dates.

Change-Id: I79a4940c36b7bef921c451de483b341f165f01d5
",git fetch https://review.opendev.org/openstack/election refs/changes/36/527236/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,ae99d7900626fd41754df6c05e1299811247f85e,update_readme,Selecting Election Dates ------------------------ Things to keep in mind when selecting election dates: * At least 48 hours in between cut-off of electorate and poll start * Consider extra-atcs approval deadlines * Should start around R-4 for nominations period ,,9,0
openstack%2Faodh~master~I4773ac55a5aedf4960c4ce611873813922ca01e5,openstack/aodh,master,I4773ac55a5aedf4960c4ce611873813922ca01e5,Replace jsonutils by ujson,MERGED,2017-10-30 08:42:46.000000000,2017-12-18 21:52:31.000000000,2017-11-21 12:20:31.000000000,"[{'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 8099}, {'_account_id': 19554}, {'_account_id': 22348}, {'_account_id': 25254}]","[{'number': 1, 'created': '2017-10-30 08:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/8452fbb283abc9a406f8e13668165c6319f409f9', 'message': 'Replace jsonutils by ujson\n\nujson is faster than jsonutils, and we do not need any fancy feature jsonutils\nmight offer.\n\nThis also has the benefit of removing a big dependency on Aodh.\n\nChange-Id: I4773ac55a5aedf4960c4ce611873813922ca01e5\n'}, {'number': 2, 'created': '2017-11-01 03:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/ad4c0f35fb2472bdb2cd451410bc108b39691e56', 'message': 'Replace jsonutils by ujson\n\nujson is faster than jsonutils, and we do not need any fancy feature jsonutils\nmight offer.\n\nThis also has the benefit of removing a big dependency on Aodh.\n\nChange-Id: I4773ac55a5aedf4960c4ce611873813922ca01e5\n'}, {'number': 3, 'created': '2017-11-01 09:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/3a591fdd49d01afcadab27e12e18d8a3c1773ad3', 'message': 'Replace jsonutils by ujson\n\nujson is faster than jsonutils, and we do not need any fancy feature jsonutils\nmight offer.\n\nThis also has the benefit of removing a big dependency on Aodh.\n\nChange-Id: I4773ac55a5aedf4960c4ce611873813922ca01e5\n'}, {'number': 4, 'created': '2017-11-01 09:21:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/5d1bd6632d0f7e05f5af62b23a7af846302180c7', 'message': 'Replace jsonutils by ujson\n\nujson is faster than jsonutils, and we do not need any fancy feature jsonutils\nmight offer.\n\nThis also has the benefit of removing a big dependency on Aodh.\n\nChange-Id: I4773ac55a5aedf4960c4ce611873813922ca01e5\n'}, {'number': 5, 'created': '2017-11-01 13:07:43.000000000', 'files': ['aodh/tests/tempest/service/client.py', 'requirements.txt', 'aodh/tests/unit/test_notifier.py', 'aodh/api/controllers/v2/alarm_rules/gnocchi.py', 'aodh/tests/functional/api/v2/test_alarm_scenarios.py', 'aodh/evaluator/event.py', 'aodh/tests/unit/evaluator/test_event.py', 'aodh/notifier/rest.py', 'aodh/evaluator/gnocchi.py'], 'web_link': 'https://opendev.org/openstack/aodh/commit/17feef6c66c552f3b747fd24e4dc7ec46a526b4f', 'message': 'Replace jsonutils by ujson\n\nujson is faster than jsonutils, and we do not need any fancy feature jsonutils\nmight offer.\n\nThis also has the benefit of removing a big dependency on Aodh.\n\nChange-Id: I4773ac55a5aedf4960c4ce611873813922ca01e5\n'}]",0,516212,17feef6c66c552f3b747fd24e4dc7ec46a526b4f,19,6,5,26185,,,0,"Replace jsonutils by ujson

ujson is faster than jsonutils, and we do not need any fancy feature jsonutils
might offer.

This also has the benefit of removing a big dependency on Aodh.

Change-Id: I4773ac55a5aedf4960c4ce611873813922ca01e5
",git fetch https://review.opendev.org/openstack/aodh refs/changes/12/516212/5 && git format-patch -1 --stdout FETCH_HEAD,"['aodh/tests/tempest/service/client.py', 'requirements.txt', 'aodh/tests/unit/test_notifier.py', 'aodh/api/controllers/v2/alarm_rules/gnocchi.py', 'aodh/tests/functional/api/v2/test_alarm_scenarios.py', 'aodh/evaluator/event.py', 'aodh/tests/unit/evaluator/test_event.py', 'aodh/notifier/rest.py', 'aodh/evaluator/gnocchi.py']",9,8452fbb283abc9a406f8e13668165c6319f409f9,,"import ujson query=ujson.loads(rule['query']),","from oslo_serialization import jsonutils query=jsonutils.loads(rule['query']),",42,43
openstack%2Freleases~master~I6f67a764420593e76a4ff1bb182a9b30404ed6f2,openstack/releases,master,I6f67a764420593e76a4ff1bb182a9b30404ed6f2,Use io.open for encoding support with py2.7,ABANDONED,2017-12-18 20:17:19.000000000,2017-12-18 21:47:35.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-12-18 20:17:19.000000000', 'files': ['openstack_releases/cmds/list_changes.py', 'openstack_releases/cmds/new_release.py', 'openstack_releases/cmds/validate.py', 'openstack_releases/cmds/list_constraints.py', 'openstack_releases/cmds/propose_library_branches.py', 'openstack_releases/deliverable.py', 'openstack_releases/cmds/missing.py'], 'web_link': 'https://opendev.org/openstack/releases/commit/30051f97a7058111229ded759da2a35f848bedd9', 'message': 'Use io.open for encoding support with py2.7\n\nGate failures seen due to open() not having an ""encoding"" kwarg\nwhen running under Python 2.7. This switches instances using it\nto use io.open instead. This is slightly slower on py2, but we\nare not using it in a way that should have a noticable impact.\nWith py3 it is just a pass through to the normal open() call.\n\nChange-Id: I6f67a764420593e76a4ff1bb182a9b30404ed6f2\n'}]",0,528803,30051f97a7058111229ded759da2a35f848bedd9,3,1,1,11904,,,0,"Use io.open for encoding support with py2.7

Gate failures seen due to open() not having an ""encoding"" kwarg
when running under Python 2.7. This switches instances using it
to use io.open instead. This is slightly slower on py2, but we
are not using it in a way that should have a noticable impact.
With py3 it is just a pass through to the normal open() call.

Change-Id: I6f67a764420593e76a4ff1bb182a9b30404ed6f2
",git fetch https://review.opendev.org/openstack/releases refs/changes/03/528803/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_releases/cmds/list_changes.py', 'openstack_releases/cmds/new_release.py', 'openstack_releases/cmds/validate.py', 'openstack_releases/cmds/list_constraints.py', 'openstack_releases/cmds/propose_library_branches.py', 'openstack_releases/deliverable.py', 'openstack_releases/cmds/missing.py']",7,30051f97a7058111229ded759da2a35f848bedd9,open_encoding,from io import open,,7,0
openstack%2Frpm-packaging~master~Ifb6e52ee7307a5c752643f9dff265d5263ff1c60,openstack/rpm-packaging,master,Ifb6e52ee7307a5c752643f9dff265d5263ff1c60,debtcollector: Build python2 and python3 from a single spec,ABANDONED,2017-05-22 15:06:10.000000000,2017-12-18 21:39:55.000000000,,"[{'_account_id': 1955}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 20656}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-05-22 15:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/14059223248e17b69826ac2a9e170dd266002bad', 'message': 'debtcollector: Build python2 and python3 from a single spec\n\nChange-Id: Ifb6e52ee7307a5c752643f9dff265d5263ff1c60\n'}, {'number': 2, 'created': '2017-05-25 05:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/45a2d5dd0f2f1625dcb20b0ec5c9db7c0b099aa0', 'message': 'debtcollector: Build python2 and python3 from a single spec\n\nChange-Id: Ifb6e52ee7307a5c752643f9dff265d5263ff1c60\n'}, {'number': 3, 'created': '2017-05-29 16:52:24.000000000', 'files': ['openstack/debtcollector/debtcollector.spec.j2', 'openstack/debtcollector/0001-Do-not-require-oslotest-for-testing.patch'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/679ad77d31fd52ccf7e2aedb41fe29910a548483', 'message': 'debtcollector: Build python2 and python3 from a single spec\n\nChange-Id: Ifb6e52ee7307a5c752643f9dff265d5263ff1c60\n'}]",0,466762,679ad77d31fd52ccf7e2aedb41fe29910a548483,25,5,3,7102,,,0,"debtcollector: Build python2 and python3 from a single spec

Change-Id: Ifb6e52ee7307a5c752643f9dff265d5263ff1c60
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/62/466762/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/debtcollector/debtcollector.spec.j2', 'openstack/debtcollector/0001-Do-not-require-oslotest-for-testing.patch']",2,14059223248e17b69826ac2a9e170dd266002bad,,"From 9e75ce70d914b191388bc7e74acc5687386c6bb2 Mon Sep 17 00:00:00 2001 From: Thomas Bechtold <tbechtold@suse.com> Date: Mon, 22 May 2017 11:24:11 +0200 Subject: [PATCH] Do not require oslotest for testing oslotest itself depends on debtcollector and debtcollector depends on oslotest. That's a cycle dependency which makes bootstrapping the whole module chain more difficult. Instead of using oslotest, just use the standard unittest.TestCase class as base to break the dependency cycle. Change-Id: Idcbe727883fe2742d62d463bb9a195592aeaba09 --- debtcollector/tests/base.py | 5 ++--- test-requirements.txt | 1 - 2 files changed, 2 insertions(+), 4 deletions(-) diff --git a/debtcollector/tests/base.py b/debtcollector/tests/base.py index 1c30cdb..aa8f41a 100644 --- a/debtcollector/tests/base.py +++ b/debtcollector/tests/base.py @@ -15,9 +15,8 @@ # License for the specific language governing permissions and limitations # under the License. -from oslotest import base +import unittest - -class TestCase(base.BaseTestCase): +class TestCase(unittest.TestCase): """"""Test case base class for all unit tests."""""" diff --git a/test-requirements.txt b/test-requirements.txt index 0a17355..8ea24fc 100644 --- a/test-requirements.txt +++ b/test-requirements.txt @@ -8,7 +8,6 @@ coverage!=4.4,>=4.0 # Apache-2.0 python-subunit>=0.0.18 # Apache-2.0/BSD sphinx!=1.6.1,>=1.5.1 # BSD oslosphinx>=4.7.0 # Apache-2.0 -oslotest>=1.10.0 # Apache-2.0 testrepository>=0.0.18 # Apache-2.0/BSD testtools>=1.4.0 # MIT fixtures>=3.0.0 # Apache-2.0/BSD -- 2.12.2 ",,78,20
openstack%2Fpuppet-vitrage~master~I998f04a0badf399edd55185eddd628ed59656cfb,openstack/puppet-vitrage,master,I998f04a0badf399edd55185eddd628ed59656cfb,"[pike] Add Puppet package to bindep, for module build",MERGED,2017-10-27 20:48:09.000000000,2017-12-18 21:35:30.000000000,2017-10-28 05:02:20.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-27 20:48:09.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/puppet-vitrage/commit/d3350118ee0ed84086eda18b582a1c3a43b2bf1a', 'message': '[pike] Add Puppet package to bindep, for module build\n\nWe need Puppet package deployed from bindep so we can\nrun puppet module build with the new zuul v3 job.\n\nChange-Id: I998f04a0badf399edd55185eddd628ed59656cfb\n'}]",0,515942,d3350118ee0ed84086eda18b582a1c3a43b2bf1a,7,2,1,3153,,,0,"[pike] Add Puppet package to bindep, for module build

We need Puppet package deployed from bindep so we can
run puppet module build with the new zuul v3 job.

Change-Id: I998f04a0badf399edd55185eddd628ed59656cfb
",git fetch https://review.opendev.org/openstack/puppet-vitrage refs/changes/42/515942/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,d3350118ee0ed84086eda18b582a1c3a43b2bf1a,bindep/puppet,puppet [build],,1,0
openstack%2Frpm-packaging~stable%2Fpike~Ie7fdbfecf9da06fdff5e04473f69f4117fd8e65f,openstack/rpm-packaging,stable/pike,Ie7fdbfecf9da06fdff5e04473f69f4117fd8e65f,Fix check run for tooz,MERGED,2017-12-06 08:41:42.000000000,2017-12-18 21:31:29.000000000,2017-12-18 21:31:29.000000000,"[{'_account_id': 6593}, {'_account_id': 13404}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-06 08:41:42.000000000', 'files': ['openstack/tooz/tooz.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0a0971304e33f0a7e3b69b227711abf5d3eacfe9', 'message': 'Fix check run for tooz\n\nPreviously no tests were run. Now set it up to\nrun at least the tests against memcached, extend\nbuildrequires accordingly, otherwise tests are failing with:\n\n  File ""/home/abuild/rpmbuild/BUILD/tooz-1.59.0/tooz/tests/__init__.py"", line 20, in <module>\n       import fixtures\n  ImportError: No module named fixtures\n\nChange-Id: Ie7fdbfecf9da06fdff5e04473f69f4117fd8e65f\n(cherry picked from commit 752ff6aabe9fa40decb018134dc58ac2ad4f61b5)\n'}]",0,525987,0a0971304e33f0a7e3b69b227711abf5d3eacfe9,14,6,1,6593,,,0,"Fix check run for tooz

Previously no tests were run. Now set it up to
run at least the tests against memcached, extend
buildrequires accordingly, otherwise tests are failing with:

  File ""/home/abuild/rpmbuild/BUILD/tooz-1.59.0/tooz/tests/__init__.py"", line 20, in <module>
       import fixtures
  ImportError: No module named fixtures

Change-Id: Ie7fdbfecf9da06fdff5e04473f69f4117fd8e65f
(cherry picked from commit 752ff6aabe9fa40decb018134dc58ac2ad4f61b5)
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/87/525987/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tooz/tooz.spec.j2'],1,0a0971304e33f0a7e3b69b227711abf5d3eacfe9,,"Source0: https://files.pythonhosted.org/packages/source/t/%{pypi_name}/%{pypi_name}-%{version}.tar.gz BuildRequires: memcachedBuildRequires: {{ py2pkg('fixtures') }}BuildRequires: {{ py2pkg('mock') }}BuildRequires: {{ py2pkg('pifpaf') }} BuildRequires: {{ py2pkg('pymemcache') }}BuildRequires: {{ py2pkg('redis') }}export TOOZ_TEST_DRIVERS=""memcached"" export PATH=%{_prefix}/sbin:$PATH bash run-tests.sh",Source0: https://pypi.io/packages/source/t/%{pypi_name}/%{pypi_name}-%{version}.tar.gz%{__python2} setup.py test,10,2
openstack%2Fqinling~master~If0622f776d9df613b9557541b0267ebbf16999af,openstack/qinling,master,If0622f776d9df613b9557541b0267ebbf16999af,Fix function service cron job failure,MERGED,2017-12-18 10:33:25.000000000,2017-12-18 21:24:41.000000000,2017-12-18 21:24:40.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 10:33:25.000000000', 'files': ['qinling/utils/etcd_util.py'], 'web_link': 'https://opendev.org/openstack/qinling/commit/2d8f7e10b9c2aa73085fbb08a0a5bfe36d1c0ae6', 'message': 'Fix function service cron job failure\n\nChange-Id: If0622f776d9df613b9557541b0267ebbf16999af\n'}]",0,528686,2d8f7e10b9c2aa73085fbb08a0a5bfe36d1c0ae6,8,2,1,6732,,,0,"Fix function service cron job failure

Change-Id: If0622f776d9df613b9557541b0267ebbf16999af
",git fetch https://review.opendev.org/openstack/qinling refs/changes/86/528686/1 && git format-patch -1 --stdout FETCH_HEAD,['qinling/utils/etcd_util.py'],1,2d8f7e10b9c2aa73085fbb08a0a5bfe36d1c0ae6,fix_function_service_cron, values = client.get('%s/service_url' % function_id) return None if not values else values[0], return client.get('%s/service_url' % function_id)[0],2,1
openstack%2Fpuppet-swift~master~I1d1d327b7d32f37550edcc036f5ab2bbb1b37ba1,openstack/puppet-swift,master,I1d1d327b7d32f37550edcc036f5ab2bbb1b37ba1,Allow a replication network to be specified,ABANDONED,2016-04-07 00:42:03.000000000,2017-12-18 21:24:39.000000000,,"[{'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8318}, {'_account_id': 8971}, {'_account_id': 10068}, {'_account_id': 11176}, {'_account_id': 12613}, {'_account_id': 14985}, {'_account_id': 18795}, {'_account_id': 22348}]","[{'number': 1, 'created': '2016-04-07 00:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/13eca0746444d5f553aae578d6ffffe68e868e87', 'message': 'Allow a replication network to be specified\nCloses-Bug: #1491660\nChange-Id: I1d1d327b7d32f37550edcc036f5ab2bbb1b37ba1\n'}, {'number': 2, 'created': '2016-04-07 08:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/9ecb9379b6be196ae80a338403ad12491a2a669a', 'message': 'Allow a replication network to be specified\nCloses-Bug: #1491660\nChange-Id: I1d1d327b7d32f37550edcc036f5ab2bbb1b37ba1\n'}, {'number': 3, 'created': '2016-04-07 22:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/45e13ad5630488bd5cb4bf16b378bda9ac2627e6', 'message': 'Allow a replication network to be specified\n\nCloses-Bug: #1491660\n\nChange-Id: I1d1d327b7d32f37550edcc036f5ab2bbb1b37ba1\n'}, {'number': 4, 'created': '2016-04-08 04:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/e0811d310ebaafe8e50d4eb96753751a0d96baa5', 'message': 'Allow a replication network to be specified\n\nCloses-Bug: #1491660\n\nChange-Id: I1d1d327b7d32f37550edcc036f5ab2bbb1b37ba1\n'}, {'number': 5, 'created': '2016-04-13 23:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/15306e8a31cd5cff93b08df066b6da9b66703090', 'message': 'Allow a replication network to be specified\n\nThe current ring device addition code allows specification of the\nform:\n\n- ip:port/device\n\nwhich is then passed to swift-ring-builder via the provider.\nHowever swift-ring-builder itself allows specification of\nseparate storage and replication networks via the form:\n\n- ip:portRrip:rport/device\n\nThis patch enhances the provider and type validators to handle\nthis extended form.\n\nCloses-Bug: #1491660\n\nChange-Id: I1d1d327b7d32f37550edcc036f5ab2bbb1b37ba1\n'}, {'number': 6, 'created': '2016-04-19 03:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/9dc3dbf2a02ffd266b489dd16f3f99e599a648ec', 'message': 'Allow a replication network to be specified\n\nThe current ring device addition code allows specification of the\nform:\n\n- ip:port/device\n\nwhich is then passed to swift-ring-builder via the provider.\nHowever swift-ring-builder itself allows specification of\nseparate storage and replication networks via the form:\n\n- ip:portRrip:rport/device\n\nThis patch enhances the provider and type validators to handle\nthis extended form.\n\nBecause this module installs servers with a single configuration\nfile, there are some restrictions on the servers listening address\nand the ring storage and replication ports:\n- servers need to listen both interfaces (or all e.g ::0)\n- same port number used on each inteface (i.e rport = port)\n\nCloses-Bug: #1491660\n\nChange-Id: I1d1d327b7d32f37550edcc036f5ab2bbb1b37ba1\n'}, {'number': 7, 'created': '2016-04-29 05:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/e7986f1047dadc9fe2c9472f2430b7c567c59292', 'message': 'Allow a replication network to be specified\n\nThe current ring device addition code allows specification of the\nform:\n\n- ip:port/device\n\nwhich is then passed to swift-ring-builder via the provider.\nHowever swift-ring-builder itself allows specification of\nseparate storage and replication networks via the form:\n\n- ip:portRrip:rport/device\n\nThis patch enhances the provider and type validators to handle\nthis extended form.\n\nBecause this module installs servers with a single configuration\nfile, there are some restrictions on the servers listening address\nand the ring storage and replication ports:\n- servers need to listen both interfaces (or all e.g ::0)\n- same port number used on each inteface (i.e rport = port)\n\nCloses-Bug: #1491660\n\nChange-Id: I1d1d327b7d32f37550edcc036f5ab2bbb1b37ba1\n'}, {'number': 8, 'created': '2016-10-20 19:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/15c1db86115053acaf45c91bc2bdde530bf6a173', 'message': 'Allow a replication network to be specified\n\nThe current ring device addition code allows specification of the\nform:\n\n- ip:port/device\n\nwhich is then passed to swift-ring-builder via the provider.\nHowever swift-ring-builder itself allows specification of\nseparate storage and replication networks via the form:\n\n- ip:portRrip:rport/device\n\nThis patch enhances the provider and type validators to handle\nthis extended form.\n\nBecause this module installs servers with a single configuration\nfile, there are some restrictions on the servers listening address\nand the ring storage and replication ports:\n- servers need to listen both interfaces (or all e.g ::0)\n- same port number used on each inteface (i.e rport = port)\n\nCloses-Bug: #1491660\n\nChange-Id: I1d1d327b7d32f37550edcc036f5ab2bbb1b37ba1\n'}, {'number': 9, 'created': '2016-11-14 23:28:22.000000000', 'files': ['lib/puppet/type/ring_account_device.rb', 'lib/puppet/type/ring_container_device.rb', 'lib/puppet/provider/swift_ring_builder.rb', 'spec/unit/puppet/type/ring_object_device_spec.rb', 'spec/unit/puppet/type/ring_account_device_spec.rb', 'spec/unit/puppet/type/ring_container_device_spec.rb', 'tests/replication_network.pp', 'lib/puppet/type/ring_object_device.rb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/00c28c2b2b5f911c5169255fc60824b174884753', 'message': 'Allow a replication network to be specified\n\nThe current ring device addition code allows specification of the\nform:\n\n- ip:port/device\n\nwhich is then passed to swift-ring-builder via the provider.\nHowever swift-ring-builder itself allows specification of\nseparate storage and replication networks via the form:\n\n- ip:portRrip:rport/device\n\nThis patch enhances the provider and type validators to handle\nthis extended form.\n\nBecause this module installs servers with a single configuration\nfile, there are some restrictions on the servers listening address\nand the ring storage and replication ports:\n- servers need to listen both interfaces (or all e.g ::0)\n- same port number used on each inteface (i.e rport = port)\n\nCloses-Bug: #1491660\n\nChange-Id: I1d1d327b7d32f37550edcc036f5ab2bbb1b37ba1\n'}]",18,302483,00c28c2b2b5f911c5169255fc60824b174884753,74,10,9,12613,,,0,"Allow a replication network to be specified

The current ring device addition code allows specification of the
form:

- ip:port/device

which is then passed to swift-ring-builder via the provider.
However swift-ring-builder itself allows specification of
separate storage and replication networks via the form:

- ip:portRrip:rport/device

This patch enhances the provider and type validators to handle
this extended form.

Because this module installs servers with a single configuration
file, there are some restrictions on the servers listening address
and the ring storage and replication ports:
- servers need to listen both interfaces (or all e.g ::0)
- same port number used on each inteface (i.e rport = port)

Closes-Bug: #1491660

Change-Id: I1d1d327b7d32f37550edcc036f5ab2bbb1b37ba1
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/83/302483/9 && git format-patch -1 --stdout FETCH_HEAD,"['tests/net.pp', 'lib/puppet/type/ring_account_device.rb', 'lib/puppet/type/ring_container_device.rb', 'lib/puppet/provider/swift_ring_builder.rb', 'lib/puppet/type/ring_object_device.rb']",5,13eca0746444d5f553aae578d6ffffe68e868e87,bug/1491660," if value[""R""] storuri = URI(""http://"" + value.split('R')[0]) address = storuri.host port_device = storuri.port repluri = URI(""http://"" + value.split('R')[1]) if ['','/'].include?(repluri.path) raise(Puppet::Error, ""namevar should contain a device"") end IPAddr.new(address) else # we have to have URI Scheme so we just add http:// and ignore it later uri = URI('http://' + value) address = uri.host port_device = uri.port if ['','/'].include?(uri.path) raise(Puppet::Error, ""namevar should contain a device"") end IPAddr.new(address)"," # we have to have URI Scheme so we just add http:// and ignore it later uri = URI('http://' + value) address = uri.host port_device = uri.port if ['','/'].include?(uri.path) raise(Puppet::Error, ""namevar should contain a device"") IPAddr.new(address)",203,31
openstack%2Fnova~stable%2Fpike~I6bf0fa19b72887803e77b66698587c2108c9372a,openstack/nova,stable/pike,I6bf0fa19b72887803e77b66698587c2108c9372a,Make request_spec.spec MediumText,MERGED,2017-12-15 16:40:58.000000000,2017-12-18 21:21:41.000000000,2017-12-18 21:21:41.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 8864}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 12898}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-12-15 16:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e75c5af847409783f3e871a852e6fafd8a1ec31', 'message': 'Make request_spec.spec MediumText\n\nrequest_spec.instance_group.members is a list of instance UUIDs. It\ncan get so long that it overflows its TEXT column. This patch changes\nrequest_spec.spec to MEDIUMTEXT.\n\nNOTE(artom): Conflicts in\nnova/tests/functional/db/api/test_migrations.py because of backport\nmigration renumbering.\n\nChange-Id: I6bf0fa19b72887803e77b66698587c2108c9372a\nCloses-bug: 1738094\n'}, {'number': 2, 'created': '2017-12-15 16:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/095265dd27f40311784bb9da59168074681348a8', 'message': 'Make request_spec.spec MediumText\n\nrequest_spec.instance_group.members is a list of instance UUIDs. It\ncan get so long that it overflows its TEXT column. This patch changes\nrequest_spec.spec to MEDIUMTEXT.\n\nNOTE(artom): Conflicts in\nnova/tests/functional/db/api/test_migrations.py because of backport\nmigration renumbering.\n\nChange-Id: I6bf0fa19b72887803e77b66698587c2108c9372a\nCloses-bug: 1738094\n(cherry picked from commit 40d74339082fe0eb1ce9216e89cf6e65a39e6968)\n'}, {'number': 3, 'created': '2017-12-18 15:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1cfcc406437c8ff3734bffef736407dc2a6440d9', 'message': 'Make request_spec.spec MediumText\n\nrequest_spec.instance_group.members is a list of instance UUIDs. It\ncan get so long that it overflows its TEXT column. This patch changes\nrequest_spec.spec to MEDIUMTEXT.\n\nNOTE(artom): Conflicts in\nnova/tests/functional/db/api/test_migrations.py because of backport\nmigration renumbering.\n\nNOTE(mriedem): Since this is a backport, this contains a release\nnote not found in the original change on master.\n\nChange-Id: I6bf0fa19b72887803e77b66698587c2108c9372a\nCloses-bug: 1738094\n(cherry picked from commit 40d74339082fe0eb1ce9216e89cf6e65a39e6968)\n'}, {'number': 4, 'created': '2017-12-18 15:37:31.000000000', 'files': ['nova/db/sqlalchemy/api_migrations/migrate_repo/versions/045_request_specs_spec_mediumtext.py', 'releasenotes/notes/bug-1738094-request_specs.spec-migration-22d3421ea1536a37.yaml', 'nova/db/sqlalchemy/api_models.py', 'nova/tests/functional/db/api/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9adf97c0132c3e0d34bbb2e33b59c6e5b00bec57', 'message': 'Make request_spec.spec MediumText\n\nrequest_spec.instance_group.members is a list of instance UUIDs. It\ncan get so long that it overflows its TEXT column. This patch changes\nrequest_spec.spec to MEDIUMTEXT.\n\nNOTE(artom): Conflicts in\nnova/tests/functional/db/api/test_migrations.py because of backport\nmigration renumbering.\n\nNOTE(mriedem): Since this is a backport, this contains a release\nnote not found in the original change on master.\n\nChange-Id: I6bf0fa19b72887803e77b66698587c2108c9372a\nCloses-bug: 1738094\n(cherry picked from commit 40d74339082fe0eb1ce9216e89cf6e65a39e6968)\n'}]",1,528330,9adf97c0132c3e0d34bbb2e33b59c6e5b00bec57,32,12,4,8864,,,0,"Make request_spec.spec MediumText

request_spec.instance_group.members is a list of instance UUIDs. It
can get so long that it overflows its TEXT column. This patch changes
request_spec.spec to MEDIUMTEXT.

NOTE(artom): Conflicts in
nova/tests/functional/db/api/test_migrations.py because of backport
migration renumbering.

NOTE(mriedem): Since this is a backport, this contains a release
note not found in the original change on master.

Change-Id: I6bf0fa19b72887803e77b66698587c2108c9372a
Closes-bug: 1738094
(cherry picked from commit 40d74339082fe0eb1ce9216e89cf6e65a39e6968)
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/528330/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/api_migrations/migrate_repo/versions/045_request_specs_spec_mediumtext.py', 'nova/db/sqlalchemy/api_models.py', 'nova/tests/functional/db/api/test_migrations.py']",3,1e75c5af847409783f3e871a852e6fafd8a1ec31,bug/1738094,"from oslo_serialization import jsonutilsfrom nova.test import uuids def _pre_upgrade_045(self, engine): request_specs = db_utils.get_table(engine, 'request_specs') # The spec value is a serialized json blob. spec = jsonutils.dumps( {""instance_group"": {""id"": 42, ""members"": [""uuid1"", ""uuid2"", ""uuid3""]}}) fake_request_spec = { 'id': 42, 'spec': spec, 'instance_uuid': uuids.instance} request_specs.insert().execute(fake_request_spec) def _check_045(self, engine, data): request_specs = db_utils.get_table(engine, 'request_specs') if engine.name == 'mysql': self.assertIsInstance(request_specs.c.spec.type, sqlalchemy.dialects.mysql.MEDIUMTEXT) expected_spec = {""instance_group"": {""id"": 42, ""members"": [""uuid1"", ""uuid2"", ""uuid3""]}} from_db_request_spec = request_specs.select( request_specs.c.id == 42).execute().first() self.assertEqual(uuids.instance, from_db_request_spec['instance_uuid']) db_spec = jsonutils.loads(from_db_request_spec['spec']) self.assertDictEqual(expected_spec, db_spec) ",,56,1
openstack%2Frally~master~I9fd55ec318086761a2e6f37b6c61c3dbc08b72f6,openstack/rally,master,I9fd55ec318086761a2e6f37b6c61c3dbc08b72f6,Remove outdated samples about deployment,MERGED,2017-10-06 01:46:06.000000000,2017-12-18 21:20:46.000000000,2017-12-18 21:20:45.000000000,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 14817}, {'_account_id': 22348}, {'_account_id': 25903}]","[{'number': 1, 'created': '2017-10-06 01:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4bb5938a5d12bb54d8d320852a82e49947c4f1fb', 'message': 'Remove SCREEN_LOGDIR from devstack\n\nSCREEN_LOGDIR has already been deprecated [1]\n[1] https://review.openstack.org/#/c/499186\n\nChange-Id: I9fd55ec318086761a2e6f37b6c61c3dbc08b72f6\n'}, {'number': 2, 'created': '2017-10-10 01:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/69a80d011f5a071f6043f1c41ead9e317b219f99', 'message': 'Remove SCREEN_LOGDIR from devstack\n\nSCREEN_LOGDIR has already been deprecated [1]\n[1] https://review.openstack.org/#/c/499186\n\nAs the suggestion from Andrey Kurilin, also remove the whole\nfor_deploying_openstack_with_rally directory because\nthese samples which are left after some refactoring,\nare redundant.\n\nChange-Id: I9fd55ec318086761a2e6f37b6c61c3dbc08b72f6\n'}, {'number': 3, 'created': '2017-10-10 01:26:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7ec566660f2fcf70d52a2fb976996cc47a0e841d', 'message': 'Remove SCREEN_LOGDIR from devstack\n\nSCREEN_LOGDIR has already been deprecated [1]\n[1] https://review.openstack.org/#/c/499186\n\nAs the suggestion from Andrey Kurilin, also remove the whole\nfor_deploying_openstack_with_rally directory because\nthese samples which are left after some refactoring,\nare redundant.\n\nChange-Id: I9fd55ec318086761a2e6f37b6c61c3dbc08b72f6\n'}, {'number': 4, 'created': '2017-12-18 18:40:45.000000000', 'files': ['samples/deployments/for_deploying_openstack_with_rally/devstack-in-existing-servers.json', 'samples/deployments/for_deploying_openstack_with_rally/devstack-in-lxc.json', 'samples/deployments/for_deploying_openstack_with_rally/devstack-lxc-engine-in-existing-servers.json', 'samples/deployments/for_deploying_openstack_with_rally/devstack-in-openstack.json', 'samples/deployments/for_deploying_openstack_with_rally/multihost.json', 'samples/deployments/for_deploying_openstack_with_rally/README.rst', 'samples/deployments/for_deploying_openstack_with_rally/devstack-by-cobbler.json', 'samples/deployments/for_deploying_openstack_with_rally/devstack-lxc-engine-in-existing-servers.rst', 'samples/deployments/for_deploying_openstack_with_rally/multihost.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/f9d380783bce22c3df00e3645cd90b925e4d9967', 'message': 'Remove outdated samples about deployment\n\nRemove the whole for_deploying_openstack_with_rally directory because\nthese samples which are left after some refactoring, are redundant.\n\nChange-Id: I9fd55ec318086761a2e6f37b6c61c3dbc08b72f6\n'}]",0,509951,f9d380783bce22c3df00e3645cd90b925e4d9967,20,5,4,25903,,,0,"Remove outdated samples about deployment

Remove the whole for_deploying_openstack_with_rally directory because
these samples which are left after some refactoring, are redundant.

Change-Id: I9fd55ec318086761a2e6f37b6c61c3dbc08b72f6
",git fetch https://review.opendev.org/openstack/rally refs/changes/51/509951/4 && git format-patch -1 --stdout FETCH_HEAD,"['samples/deployments/for_deploying_openstack_with_rally/devstack-lxc-engine-in-existing-servers.json', 'samples/deployments/for_deploying_openstack_with_rally/multihost.json', 'samples/deployments/for_deploying_openstack_with_rally/devstack-lxc-engine-in-existing-servers.rst']",3,4bb5938a5d12bb54d8d320852a82e49947c4f1fb,screen_logdir," ""ENABLED_SERVICES+"": "",-n-cpu"" ""ENABLED_SERVICES"": ""n-cpu,n-net"""," ""ENABLED_SERVICES+"": "",-n-cpu"", ""SCREEN_LOGDIR"": ""$DEST/logs/screen"" ""ENABLED_SERVICES"": ""n-cpu,n-net"", ""SCREEN_LOGDIR"": ""$DEST/logs/screen""",5,10
openstack%2Fpuppet-sahara~master~Ie7fea9e9ca8f0cd1762366d68f075e270d5b967f,openstack/puppet-sahara,master,Ie7fea9e9ca8f0cd1762366d68f075e270d5b967f,Updated from global requirements,ABANDONED,2017-03-22 09:52:22.000000000,2017-12-18 21:16:33.000000000,,[{'_account_id': 8971}],"[{'number': 1, 'created': '2017-03-22 09:52:22.000000000', 'files': ['setup.py'], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/da8d62c711d872496dbcd38779b29880c9d6d647', 'message': 'Updated from global requirements\n\nChange-Id: Ie7fea9e9ca8f0cd1762366d68f075e270d5b967f\n'}]",0,448476,da8d62c711d872496dbcd38779b29880c9d6d647,5,1,1,25005,,,0,"Updated from global requirements

Change-Id: Ie7fea9e9ca8f0cd1762366d68f075e270d5b967f
",git fetch https://review.opendev.org/openstack/puppet-sahara refs/changes/76/448476/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.py'],1,da8d62c711d872496dbcd38779b29880c9d6d647,pbr," setup_requires=['pbr>=2.0.0'],"," setup_requires=['pbr'],",1,1
openstack%2Faodh~master~Id8368c0091ef8eb6a567ba9036bd11d656bcf8d4,openstack/aodh,master,Id8368c0091ef8eb6a567ba9036bd11d656bcf8d4,don't use last keystonemiddleware,MERGED,2017-12-12 18:05:29.000000000,2017-12-18 21:16:32.000000000,2017-12-13 22:42:18.000000000,"[{'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 18:05:29.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/aodh/commit/607d4e876cacec35002e7f15e2aee84e1599f28c', 'message': ""don't use last keystonemiddleware\n\nRelated-bug: #1737115\nChange-Id: Id8368c0091ef8eb6a567ba9036bd11d656bcf8d4\n""}]",0,527486,607d4e876cacec35002e7f15e2aee84e1599f28c,13,3,1,2813,,,0,"don't use last keystonemiddleware

Related-bug: #1737115
Change-Id: Id8368c0091ef8eb6a567ba9036bd11d656bcf8d4
",git fetch https://review.opendev.org/openstack/aodh refs/changes/86/527486/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,607d4e876cacec35002e7f15e2aee84e1599f28c,bug/1737115,"keystonemiddleware>=2.2.0,!=4.19.0",keystonemiddleware>=2.2.0,1,1
openstack%2Fproject-config~master~I533e3edb6102ea871a5c0bf72299fb0da7a13c52,openstack/project-config,master,I533e3edb6102ea871a5c0bf72299fb0da7a13c52,Add new repo for Telemetry tempest plugin,MERGED,2017-12-09 15:45:52.000000000,2017-12-18 21:11:10.000000000,2017-12-18 21:11:10.000000000,"[{'_account_id': 1004}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 12393}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-09 15:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/63d11633969c1d39d3cee7679edb94fabf568852', 'message': 'Add new repo for Ceilometer tempest plugin\n\nIn addition to fulfilling Queens Goal ""Split Tempest Plugins into\nSeparate Repos/Projects"", This imports from a temporary github repo\nthat preserves the history of the plugin and additionally applies\nthe openstack cookiecutter to it.\n\nChange-Id: I533e3edb6102ea871a5c0bf72299fb0da7a13c52\nNeeded-By: Ie9e5b48ccdacb4cea08f1525d23348f7398c9dbf\n'}, {'number': 2, 'created': '2017-12-09 15:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/c4e4069bd8bfe3d1873c68030ec9f3b06721e22a', 'message': 'Add new repo for Ceilometer tempest plugin\n\nIn addition to fulfilling Queens Goal ""Split Tempest Plugins into\nSeparate Repos/Projects"", This imports from a temporary github repo\nthat preserves the history of the plugin and additionally applies\nthe openstack cookiecutter to it.\n\nChange-Id: I533e3edb6102ea871a5c0bf72299fb0da7a13c52\nNeeded-By: Ie9e5b48ccdacb4cea08f1525d23348f7398c9dbf\n'}, {'number': 3, 'created': '2017-12-10 06:38:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4fba4a69b0fb1d2ed1b8fd0dc6789f5b44a9c4c3', 'message': 'Add new repo for Telemetry tempest plugin\n\nIn addition to fulfilling Queens Goal ""Split Tempest Plugins into\nSeparate Repos/Projects"", This imports from a temporary github repo\nthat preserves the history of the plugin and additionally applies\nthe openstack cookiecutter to it.\n\nChange-Id: I533e3edb6102ea871a5c0bf72299fb0da7a13c52\nNeeded-By: Ie9e5b48ccdacb4cea08f1525d23348f7398c9dbf\n'}, {'number': 4, 'created': '2017-12-16 02:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f09e09938f4b5c20215ba0b07e23995bb73e7e5b', 'message': 'Add new repo for Telemetry tempest plugin\n\nIn addition to fulfilling Queens Goal ""Split Tempest Plugins into\nSeparate Repos/Projects"", This imports from a temporary github repo\nthat preserves the history of the plugin and additionally applies\nthe openstack cookiecutter to it.\n\nChange-Id: I533e3edb6102ea871a5c0bf72299fb0da7a13c52\nNeeded-By: Ie9e5b48ccdacb4cea08f1525d23348f7398c9dbf\n'}, {'number': 5, 'created': '2017-12-18 11:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ed12a75139eeddecdf68e19662e1cbe655f5b41d', 'message': 'Add new repo for Telemetry tempest plugin\n\nIn addition to fulfilling Queens Goal ""Split Tempest Plugins into\nSeparate Repos/Projects"", This imports from a temporary github repo\nthat preserves the history of the plugin and additionally applies\nthe openstack cookiecutter to it.\n\nChange-Id: I533e3edb6102ea871a5c0bf72299fb0da7a13c52\nNeeded-By: Ie9e5b48ccdacb4cea08f1525d23348f7398c9dbf\n'}, {'number': 6, 'created': '2017-12-18 20:21:33.000000000', 'files': ['gerritbot/channels.yaml', 'zuul/main.yaml', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f41abf87b79685d770a4041d67b910bdcf47e3ee', 'message': 'Add new repo for Telemetry tempest plugin\n\nIn addition to fulfilling Queens Goal ""Split Tempest Plugins into\nSeparate Repos/Projects"", This imports from a temporary github repo\nthat preserves the history of the plugin and additionally applies\nthe openstack cookiecutter to it.\n\nChange-Id: I533e3edb6102ea871a5c0bf72299fb0da7a13c52\nNeeded-By: Ie9e5b48ccdacb4cea08f1525d23348f7398c9dbf\n'}]",3,526863,f41abf87b79685d770a4041d67b910bdcf47e3ee,33,8,6,12393,,,0,"Add new repo for Telemetry tempest plugin

In addition to fulfilling Queens Goal ""Split Tempest Plugins into
Separate Repos/Projects"", This imports from a temporary github repo
that preserves the history of the plugin and additionally applies
the openstack cookiecutter to it.

Change-Id: I533e3edb6102ea871a5c0bf72299fb0da7a13c52
Needed-By: Ie9e5b48ccdacb4cea08f1525d23348f7398c9dbf
",git fetch https://review.opendev.org/openstack/project-config refs/changes/63/526863/6 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'gerrit/projects.yaml', 'zuul/main.yaml']",3,63d11633969c1d39d3cee7679edb94fabf568852,goal-split-tempest-plugins-patch4, - openstack/ceilometer-tempest-plugin,,8,0
openstack%2Fneutron~master~I7bc758eed56610c269485681f67a5379730d8ef5,openstack/neutron,master,I7bc758eed56610c269485681f67a5379730d8ef5,Ensure floating IP create does not break,MERGED,2017-12-17 09:14:38.000000000,2017-12-18 21:07:18.000000000,2017-12-18 21:07:18.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 12860}, {'_account_id': 22348}, {'_account_id': 25618}, {'_account_id': 27511}]","[{'number': 1, 'created': '2017-12-17 09:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/795bb917327ce93c06989f68b3102e3dff80cec8', 'message': ""Ensure floating IP does not break\n\nCommit 088e317cd2dd8488feb29a4fa6600227d1810479 breaks floating IP\nupdate.\n\nThis changed the API and mandated that 'subnet_id' and\n'floating_ip_address' be passe din the API. This is clearly wrong.\n\nChange-Id: I7bc758eed56610c269485681f67a5379730d8ef5\nCloses-Bug: #1738612\n""}, {'number': 2, 'created': '2017-12-17 09:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/063257c922c43b95c74c94853c47f2addeb72c15', 'message': ""Ensure floating IP create does not break\n\nCommit 088e317cd2dd8488feb29a4fa6600227d1810479 breaks floating IP\ncreation.\n\nThis changed the API and mandated that 'subnet_id' and\n'floating_ip_address' be passed in the API.\n\nChange-Id: I7bc758eed56610c269485681f67a5379730d8ef5\nCloses-Bug: #1738612\n""}, {'number': 3, 'created': '2017-12-17 09:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/55003f859ab2689cd4cef27ef92c2b347448a85c', 'message': ""Ensure floating IP create does not break\n\nCommit 088e317cd2dd8488feb29a4fa6600227d1810479 breaks floating IP\ncreation.\n\nThis changed the API and mandated that 'subnet_id' and\n'floating_ip_address' be passed in the API.\n\nChange-Id: I7bc758eed56610c269485681f67a5379730d8ef5\nCloses-Bug: #1738612\n""}, {'number': 4, 'created': '2017-12-17 10:57:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/df482f0e5722f1877218cb255dc191cce5d48507', 'message': ""Ensure floating IP create does not break\n\nCommit 088e317cd2dd8488feb29a4fa6600227d1810479 breaks floating IP\ncreation.\n\nThis changed the API and mandated that 'subnet_id' and\n'floating_ip_address' be passed in the API.\n\nChange-Id: I7bc758eed56610c269485681f67a5379730d8ef5\nCloses-Bug: #1738612\n""}, {'number': 5, 'created': '2017-12-18 06:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/af6359267fc12245453520136cb76d843dd8356f', 'message': ""Ensure floating IP create does not break\n\nCommit 088e317cd2dd8488feb29a4fa6600227d1810479 breaks floating IP\ncreation.\n\nThis changed the API and mandated that 'subnet_id' and\n'floating_ip_address' be passed in the API.\n\nChange-Id: I7bc758eed56610c269485681f67a5379730d8ef5\nCloses-Bug: #1738612\n""}, {'number': 6, 'created': '2017-12-18 08:22:50.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/db/l3_db.py', 'neutron/tests/functional/services/l3_router/test_l3_dvr_router_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3488f451ecf6e76ccbd001255fcd7f5e8d48b37', 'message': ""Ensure floating IP create does not break\n\nCommit 088e317cd2dd8488feb29a4fa6600227d1810479 breaks floating IP\ncreation.\n\nThis changed the API and mandated that 'subnet_id' and\n'floating_ip_address' be passed in the API.\n\nThis also cleans up tests with invalid inputs.\n\nChange-Id: I7bc758eed56610c269485681f67a5379730d8ef5\nCloses-Bug: #1738612\n""}]",4,528535,e3488f451ecf6e76ccbd001255fcd7f5e8d48b37,41,11,6,1653,,,0,"Ensure floating IP create does not break

Commit 088e317cd2dd8488feb29a4fa6600227d1810479 breaks floating IP
creation.

This changed the API and mandated that 'subnet_id' and
'floating_ip_address' be passed in the API.

This also cleans up tests with invalid inputs.

Change-Id: I7bc758eed56610c269485681f67a5379730d8ef5
Closes-Bug: #1738612
",git fetch https://review.opendev.org/openstack/neutron refs/changes/35/528535/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/db/l3_db.py']",2,795bb917327ce93c06989f68b3102e3dff80cec8,broke, if 'subnet_id' in fip: if 'floating_ip_address' in fip:, if fip['subnet_id']: if fip['floating_ip_address']:,2,3
openstack%2Ftempest~master~I0cda6692764031dbbee94965dd1d8d843dd94b12,openstack/tempest,master,I0cda6692764031dbbee94965dd1d8d843dd94b12,Remove resource_cleanup from test_object_version,MERGED,2017-12-15 08:26:20.000000000,2017-12-18 21:07:16.000000000,2017-12-18 21:07:16.000000000,"[{'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 08:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b45ba4321bf5700012337cb1747ab5fcf4255696', 'message': 'Remove resource_cleanup from test_object_version\n\ntest_object_version.py keep created containers till\nclass level cleanup which is not needed.\n\nThis patch makes it to use addCleanup to remove containers\nduring test itself.\n\nChange-Id: I0cda6692764031dbbee94965dd1d8d843dd94b12\n'}, {'number': 2, 'created': '2017-12-18 01:05:59.000000000', 'files': ['tempest/api/object_storage/test_object_version.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/d5a0a7200ea21f98a83ebc8d2d829c17db91c0d2', 'message': 'Remove resource_cleanup from test_object_version\n\ntest_object_version.py keep created containers till\nclass level cleanup which is not needed.\n\nThis patch makes it to use addCleanup to remove containers\nduring test itself.\n\nChange-Id: I0cda6692764031dbbee94965dd1d8d843dd94b12\n'}]",2,528200,d5a0a7200ea21f98a83ebc8d2d829c17db91c0d2,13,5,2,7038,,,0,"Remove resource_cleanup from test_object_version

test_object_version.py keep created containers till
class level cleanup which is not needed.

This patch makes it to use addCleanup to remove containers
during test itself.

Change-Id: I0cda6692764031dbbee94965dd1d8d843dd94b12
",git fetch https://review.opendev.org/openstack/tempest refs/changes/00/528200/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/object_storage/test_object_version.py'],1,b45ba4321bf5700012337cb1747ab5fcf4255696,," self.addCleanup(base.delete_containers, [vers_container_name], self.container_client, self.object_client) self.addCleanup(base.delete_containers, [base_container_name], self.container_client, self.object_client)"," cls.containers = [] @classmethod def resource_cleanup(cls): cls.delete_containers() super(ContainerTest, cls).resource_cleanup() self.containers.append(vers_container_name) self.containers.append(base_container_name)",8,8
openstack%2Fproject-config~master~I288528eccb64a50eba7be13a278a471addae8359,openstack/project-config,master,I288528eccb64a50eba7be13a278a471addae8359,Remove api-timeout from nodepool-launcher yaml file,MERGED,2017-12-06 19:38:59.000000000,2017-12-18 21:06:28.000000000,2017-12-18 21:06:28.000000000,"[{'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-06 19:38:59.000000000', 'files': ['nodepool/nl02.openstack.org.yaml', 'nodepool/nl01.openstack.org.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/fa73bf93e99b2072f5b1104ca94128961ba3ea39', 'message': 'Remove api-timeout from nodepool-launcher yaml file\n\nThis settings is nolonger used in nodepool, and moved into\nclouds.yaml.\n\nChange-Id: I288528eccb64a50eba7be13a278a471addae8359\nDepends-On: I01613df6d64e7af635018ad3837a50487ecd5950\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",0,526157,fa73bf93e99b2072f5b1104ca94128961ba3ea39,8,3,1,4162,,,0,"Remove api-timeout from nodepool-launcher yaml file

This settings is nolonger used in nodepool, and moved into
clouds.yaml.

Change-Id: I288528eccb64a50eba7be13a278a471addae8359
Depends-On: I01613df6d64e7af635018ad3837a50487ecd5950
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/57/526157/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/nl02.openstack.org.yaml', 'nodepool/nl01.openstack.org.yaml']",2,fa73bf93e99b2072f5b1104ca94128961ba3ea39,,, api-timeout: 60 api-timeout: 60 api-timeout: 60 api-timeout: 60 api-timeout: 60,0,11
openstack%2Fpuppet-openstack_extras~master~I6e0bb69794f0b232033c15c74d861ea7f499c666,openstack/puppet-openstack_extras,master,I6e0bb69794f0b232033c15c74d861ea7f499c666,Change http into https in setup.cfg,ABANDONED,2017-05-16 05:24:53.000000000,2017-12-18 21:01:10.000000000,,"[{'_account_id': 10068}, {'_account_id': 14509}, {'_account_id': 15471}, {'_account_id': 25254}, {'_account_id': 25571}, {'_account_id': 25695}]","[{'number': 1, 'created': '2017-05-16 05:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/c75930c2bbe4ff5beaa159802d6ef5df129e681c', 'message': 'Change http into https in setup.cfg\n\nChange-Id: I6e0bb69794f0b232033c15c74d861ea7f499c666\n'}, {'number': 2, 'created': '2017-07-24 07:05:07.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/51007784108ff5d4d57027fbfa3e5adb6942c2dc', 'message': 'Change http into https in setup.cfg\n\nChange-Id: I6e0bb69794f0b232033c15c74d861ea7f499c666\n'}]",2,464931,51007784108ff5d4d57027fbfa3e5adb6942c2dc,25,6,2,25695,,,0,"Change http into https in setup.cfg

Change-Id: I6e0bb69794f0b232033c15c74d861ea7f499c666
",git fetch https://review.opendev.org/openstack/puppet-openstack_extras refs/changes/31/464931/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,c75930c2bbe4ff5beaa159802d6ef5df129e681c,,home-page = https://docs.openstack.org/developer/puppet-openstack-guide,home-page = http://docs.openstack.org/developer/puppet-openstack-guide,1,1
openstack%2Fproject-config~master~I18e09aef00dd8d97768f8dbf05c8e9165156a6bb,openstack/project-config,master,I18e09aef00dd8d97768f8dbf05c8e9165156a6bb,Use horizon-tox jobs intead of legacy ones,MERGED,2017-12-17 18:28:25.000000000,2017-12-18 20:58:13.000000000,2017-12-18 20:58:13.000000000,"[{'_account_id': 2}, {'_account_id': 4146}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-17 18:28:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8b389a0093886fe64ea404a84a3a3de6fbe7f946', 'message': ""Use horizon-tox jobs intead of legacy ones\n\nThe dashboard projects have special tox jobs for different environments.\nThese are defined in horizon repository. Let's use these horizon jobs\nfor the dashboard projects instead of the legacy jobs since the horizon\njob definitions are generic.\n\nOnce these repos move jobs in-tree, they can move the horizon-tox\ndefinition as well.\n\nNeeded-By: I56fc1d74b8d1a0d8b42436ed1a18b9196e68c270\nChange-Id: I18e09aef00dd8d97768f8dbf05c8e9165156a6bb\n""}, {'number': 2, 'created': '2017-12-17 18:34:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b943a384aa72bd2a40a3a0502ec07dadacd42cec', 'message': ""Use horizon-tox jobs intead of legacy ones\n\nThe dashboard projects have special tox jobs for different environments.\nThese are defined in horizon repository. Let's use these horizon jobs\nfor the dashboard projects instead of the legacy jobs since the horizon\njob definitions are generic.\n\nOnce these repos move jobs in-tree, they can move the horizon-tox\ndefinition as well.\n\nNeeded-By: I56fc1d74b8d1a0d8b42436ed1a18b9196e68c270\nChange-Id: I18e09aef00dd8d97768f8dbf05c8e9165156a6bb\n""}, {'number': 3, 'created': '2017-12-17 18:39:51.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ce2b8f486a7341a3df0a715a2d7c1c1911991ce0', 'message': ""Use horizon-tox jobs intead of legacy ones\n\nThe dashboard projects have special tox jobs for different environments.\nThese are defined in horizon repository. Let's use these horizon jobs\nfor the dashboard projects instead of the legacy jobs since the horizon\njob definitions are generic.\n\nOnce these repos move jobs in-tree, they can move the horizon-tox\ndefinition as well.\n\nNeeded-By: I56fc1d74b8d1a0d8b42436ed1a18b9196e68c270\nChange-Id: I18e09aef00dd8d97768f8dbf05c8e9165156a6bb\n""}]",1,528580,ce2b8f486a7341a3df0a715a2d7c1c1911991ce0,12,4,3,6547,,,0,"Use horizon-tox jobs intead of legacy ones

The dashboard projects have special tox jobs for different environments.
These are defined in horizon repository. Let's use these horizon jobs
for the dashboard projects instead of the legacy jobs since the horizon
job definitions are generic.

Once these repos move jobs in-tree, they can move the horizon-tox
definition as well.

Needed-By: I56fc1d74b8d1a0d8b42436ed1a18b9196e68c270
Change-Id: I18e09aef00dd8d97768f8dbf05c8e9165156a6bb
",git fetch https://review.opendev.org/openstack/project-config refs/changes/80/528580/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,8b389a0093886fe64ea404a84a3a3de6fbe7f946,horizon-py, - horizon-tox-py27dj19 - horizon-tox-py27dj110 - horizon-tox-py27dj19 - horizon-tox-py27dj110 - horizon-py27dj18: - horizon-tox-py27dj19 - horizon-tox-py27dj110 - horizon-tox-py27dj18: - horizon-tox-py27dj19 - horizon-tox-py27dj110 - horizon-tox-py27dj19: - horizon-tox-py27dj110: - horizon-tox-py27dj19: - horizon-tox-py27dj110:, - legacy-craton-dashboard-tox-py27dj19 - legacy-craton-dashboard-tox-py27dj110 - legacy-craton-dashboard-tox-py27dj19 - legacy-craton-dashboard-tox-py27dj110 - legacy-django_openstack_auth-tox-py27dj18: - legacy-django_openstack_auth-tox-py27dj19 - legacy-django_openstack_auth-tox-py27dj110 - legacy-django_openstack_auth-tox-py27dj18: - legacy-django_openstack_auth-tox-py27dj19 - legacy-django_openstack_auth-tox-py27dj110 - legacy-manila-ui-tox-py27dj19: - legacy-manila-ui-tox-py27dj110: - legacy-manila-ui-tox-py27dj19: - legacy-manila-ui-tox-py27dj110:,14,14
openstack%2Fnetworking-odl~master~I973e43440269a0c036a3c8a091edb7e0a6527bbe,openstack/networking-odl,master,I973e43440269a0c036a3c8a091edb7e0a6527bbe,do not merge: pylint: disable inconsistent-return-statements and raising-format-tuple,ABANDONED,2017-12-18 20:34:21.000000000,2017-12-18 20:52:52.000000000,,[],"[{'number': 1, 'created': '2017-12-18 20:34:21.000000000', 'files': ['.pylintrc'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/bbb6059be2d3a0dc0d0d744b113a8960cf0b13bd', 'message': 'do not merge: pylint: disable inconsistent-return-statements and raising-format-tuple\n\nChange-Id: I973e43440269a0c036a3c8a091edb7e0a6527bbe\n'}]",0,528811,bbb6059be2d3a0dc0d0d744b113a8960cf0b13bd,2,0,1,333,,,0,"do not merge: pylint: disable inconsistent-return-statements and raising-format-tuple

Change-Id: I973e43440269a0c036a3c8a091edb7e0a6527bbe
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/11/528811/1 && git format-patch -1 --stdout FETCH_HEAD,['.pylintrc'],1,bbb6059be2d3a0dc0d0d744b113a8960cf0b13bd,pylint-r1710,"# TODO(yamahata): remove raising-format-tuple and inconsistent-return-statements # after fixing them. raising-format-tuple, inconsistent-return-statements,",,4,0
openstack%2Fproject-config~master~I700e758e917c4a01c6adb53b248b91013e80a5c3,openstack/project-config,master,I700e758e917c4a01c6adb53b248b91013e80a5c3,remove duplicated jobs from cinder-tempest-plugin,MERGED,2017-12-13 20:30:54.000000000,2017-12-18 20:51:26.000000000,2017-12-18 20:51:26.000000000,"[{'_account_id': 2}, {'_account_id': 4146}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 20:30:54.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/81154724d35d9437342dae2985ff4996479dcf2c', 'message': 'remove duplicated jobs from cinder-tempest-plugin\n\npep8 is part of the python-jobs - thus not needed to added again. Remove\nit.\n\nChange-Id: I700e758e917c4a01c6adb53b248b91013e80a5c3\n'}]",0,527776,81154724d35d9437342dae2985ff4996479dcf2c,8,4,1,6547,,,0,"remove duplicated jobs from cinder-tempest-plugin

pep8 is part of the python-jobs - thus not needed to added again. Remove
it.

Change-Id: I700e758e917c4a01c6adb53b248b91013e80a5c3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/76/527776/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,81154724d35d9437342dae2985ff4996479dcf2c,goal-split-tempest-plugin,, check: jobs: - openstack-tox-pep8 gate: jobs: - openstack-tox-pep8,0,6
openstack%2Fopenstack-ansible-os_cinder~master~I4f58507546b6990003e9465851c8039de9eeb35c,openstack/openstack-ansible-os_cinder,master,I4f58507546b6990003e9465851c8039de9eeb35c,Remove pip_install dependency,MERGED,2017-12-05 11:54:40.000000000,2017-12-18 20:49:53.000000000,2017-12-18 20:49:53.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-05 11:54:40.000000000', 'files': ['doc/source/index.rst', 'meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/9dbda04b9f3d267f4645ed87f7ebb92932131f6c', 'message': ""Remove pip_install dependency\n\nWith addition of pip_install on every node, we don't\nneed to have pip_install as a meta dependency.\n\nDepends-On: If3412bb888ebb854874bbc43eb76bfcb3e4a7868\nDepends-On: I79ff70c438b44753be2a93f004ebbc46de0a963d\nChange-Id: I4f58507546b6990003e9465851c8039de9eeb35c\n""}]",0,525547,9dbda04b9f3d267f4645ed87f7ebb92932131f6c,29,6,1,17068,,,0,"Remove pip_install dependency

With addition of pip_install on every node, we don't
need to have pip_install as a meta dependency.

Depends-On: If3412bb888ebb854874bbc43eb76bfcb3e4a7868
Depends-On: I79ff70c438b44753be2a93f004ebbc46de0a963d
Change-Id: I4f58507546b6990003e9465851c8039de9eeb35c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/47/525547/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'meta/main.yml']",2,9dbda04b9f3d267f4645ed87f7ebb92932131f6c,cleanup_pip,, - pip_install,8,5
openstack%2Fpuppet-nova~master~Ibb4e1e2501b628f411cd8790aedfb9a0abc4ba7f,openstack/puppet-nova,master,Ibb4e1e2501b628f411cd8790aedfb9a0abc4ba7f,Finish converting to rspec-puppet-facts,ABANDONED,2017-02-01 09:55:55.000000000,2017-12-18 20:46:33.000000000,,"[{'_account_id': 8971}, {'_account_id': 18795}]","[{'number': 1, 'created': '2017-02-01 09:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/f74569c30f1744d722e2b0b57a8dc403b49459fa', 'message': 'Finish converting to rspec-puppet-facts\n\nChange-Id: Ibb4e1e2501b628f411cd8790aedfb9a0abc4ba7f\n'}, {'number': 2, 'created': '2017-02-01 14:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/a55d15c76505dd8def319cffa2253cb4b06c76e1', 'message': 'Finish converting to rspec-puppet-facts\n\nChange-Id: Ibb4e1e2501b628f411cd8790aedfb9a0abc4ba7f\n'}, {'number': 3, 'created': '2017-02-02 15:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/3572444607d041cfe92741326eb0d411293cd809', 'message': 'Finish converting to rspec-puppet-facts\n\nChange-Id: Ibb4e1e2501b628f411cd8790aedfb9a0abc4ba7f\n'}, {'number': 4, 'created': '2017-02-21 16:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/8d0c1335b514b56a205fd3d49d4fe4df3f2cd164', 'message': 'Finish converting to rspec-puppet-facts\n\nChange-Id: Ibb4e1e2501b628f411cd8790aedfb9a0abc4ba7f\n'}, {'number': 5, 'created': '2017-02-22 10:07:35.000000000', 'files': ['spec/classes/nova_keystone_authtoken_spec.rb', 'spec/classes/nova_spicehtml5_proxy_spec.rb', 'spec/classes/nova_keystone_auth_placement_spec.rb', 'spec/classes/nova_wsgi_apache_placement_spec.rb', 'spec/classes/nova_consoleauth_spec.rb', 'spec/classes/nova_network_flatdhcp_spec.rb', 'spec/classes/nova_quota_spec.rb', 'spec/classes/nova_objectstore_spec.rb', 'spec/classes/nova_wsgi_apache_api_spec.rb', 'spec/classes/nova_migration_libvirt_spec.rb', 'spec/classes/nova_client_spec.rb', 'spec/classes/nova_vnc_proxy_spec.rb', 'spec/classes/nova_keystone_auth_spec.rb', 'spec/classes/nova_compute_spice_spec.rb', 'spec/classes/nova_compute_xenserver_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/fc2545afcfe2f38c1f5cadd9cda40d74c3cbe46e', 'message': 'Finish converting to rspec-puppet-facts\n\nChange-Id: Ibb4e1e2501b628f411cd8790aedfb9a0abc4ba7f\n'}]",0,427615,fc2545afcfe2f38c1f5cadd9cda40d74c3cbe46e,24,2,5,18795,,,0,"Finish converting to rspec-puppet-facts

Change-Id: Ibb4e1e2501b628f411cd8790aedfb9a0abc4ba7f
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/15/427615/5 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/nova_migration_libvirt_spec.rb'],1,f74569c30f1744d722e2b0b57a8dc403b49459fa,rspec-puppet-facts," on_supported_os({ :supported_os => OSDefaults.get_supported_os }).each do |os,facts| context ""on #{os}"" do case [:osfamily] when 'Debian' case [:operatingsystem] when 'Debian' let (:facts) do facts.merge!(OSDefaults.get_facts({ :os_package_family => 'debian', :operatingsystemmajrelease => '8'})) end it { is_expected.to contain_file_line('/etc/default/libvirtd libvirtd opts').with(:line => 'libvirtd_opts=""-d -l""') } it_behaves_like 'nova migration with libvirt' when 'Ubuntu' let (:facts) do facts.merge!(OSDefaults.get_facts({ :os_package_family => 'ubuntu', :operatingsystemmajrelease => '16'})) end it { is_expected.to contain_file_line('/etc/default/libvirtd libvirtd opts').with(:line => 'libvirtd_opts=""-d -l""') } it_behaves_like 'nova migration with libvirt' end when 'RedHat' let (:facts) do facts.merge!(OSDefaults.get_facts({ :os_package_type => 'rpm' })) end it { is_expected.to contain_file_line('/etc/sysconfig/libvirtd libvirtd args').with(:line => 'LIBVIRTD_ARGS=""--listen""') } it_behaves_like 'nova migration with libvirt' end"," # TODO (degorenko): switch to on_supported_os function when we got Xenial context 'on Debian platforms with Ubuntu release 16' do let :facts do @default_facts.merge({ :osfamily => 'Debian', :operatingsystem => 'Ubuntu', :operatingsystemmajrelease => '16' }) it_configures 'nova migration with libvirt' it { is_expected.to contain_file_line('/etc/default/libvirtd libvirtd opts').with(:line => 'libvirtd_opts=""-l""') } end context 'on Debian platforms release' do let :facts do @default_facts.merge({ :osfamily => 'Debian', :operatingsystem => 'Debian', :operatingsystemmajrelease => '8' }) end it_configures 'nova migration with libvirt' it { is_expected.to contain_file_line('/etc/default/libvirtd libvirtd opts').with(:line => 'libvirtd_opts=""-d -l""') } end context 'on RedHat platforms' do let :facts do @default_facts.merge({ :osfamily => 'RedHat', :operatingsystem => 'CentOS', :operatingsystemmajrelease => '7.0' }) end it_configures 'nova migration with libvirt' it { is_expected.to contain_file_line('/etc/sysconfig/libvirtd libvirtd args').with(:line => 'LIBVIRTD_ARGS=""--listen""') }",35,37
openstack%2Fpuppet-nova~master~I235bd8138e59ef302c2e3cee2300c172a18e4c7a,openstack/puppet-nova,master,I235bd8138e59ef302c2e3cee2300c172a18e4c7a,[WIP] Manage privsep helper for nova,ABANDONED,2016-08-16 15:18:16.000000000,2017-12-18 20:45:32.000000000,,"[{'_account_id': 7732}, {'_account_id': 8971}]","[{'number': 1, 'created': '2016-08-16 15:18:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/6ac9752c36a83da451887e9b3787c635510ed939', 'message': '[WIP] Add support for oslo privsep management\n\nChange-Id: I235bd8138e59ef302c2e3cee2300c172a18e4c7a\n'}, {'number': 2, 'created': '2016-08-16 15:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/f2c8d9e0ca9383afbcb9b9c2142644f5236aea51', 'message': '[WIP] Manage privsep helper for nova\n\nDepends-on: aec3fc00d27e01fb2462dd1c66dd8469df34f110\nChange-Id: I235bd8138e59ef302c2e3cee2300c172a18e4c7a\n'}, {'number': 3, 'created': '2016-08-17 10:21:42.000000000', 'files': ['manifests/compute.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/b9558916137465adbf87bd00d722be7dd02ec9b7', 'message': '[WIP] Manage privsep helper for nova\n\nDepends-on: If4d52487f2a97fd6e26edf9c0d5dbc2300c09482\nChange-Id: I235bd8138e59ef302c2e3cee2300c172a18e4c7a\n'}]",0,356005,b9558916137465adbf87bd00d722be7dd02ec9b7,17,2,3,7732,,,0,"[WIP] Manage privsep helper for nova

Depends-on: If4d52487f2a97fd6e26edf9c0d5dbc2300c09482
Change-Id: I235bd8138e59ef302c2e3cee2300c172a18e4c7a
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/05/356005/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/privsep_helper.pp'],1,6ac9752c36a83da451887e9b3787c635510ed939,,"# == Define: oslo::privsep # # Configure oslo_privsep options # # This resource configures Oslo privsep resources for an OpenStack service. # It will manage the [privsep_${entrypoint}] section in the given config resource. # # === Parameters: # # [*entrypoint*] # (Required) Privsep entrypoint. (string value) # # [*config*] # (Required) Configuration file to manage. (string value) # # [*user*] # (Optional) User that the privsep daemon should run as. (string value) # Defaults to $::os_service_default. # # [*group*] # (Optional) Group that the privsep daemon should run as. (string value) # Defaults to $::os_service_default. # # [*capabilities*] # (Optional) List of Linux capabilities retained by the privsep daemon. (list value) # Defaults to $::os_service_default. # # [*helper_command*] # (Optional) Command to invoke to start the privsep daemon if not using the ""fork"" method. # If not specified, a default is generated using ""sudo privsep-helper"" and arguments designed to # recreate the current configuration. This command must accept suitable --privsep_context # and --privsep_sock_path arguments. # Defaults to $::os_service_default. # define oslo::privsep ( $entrypoint = $name, $config = undef, $user = $::os_service_default, $group = $::os_service_default, $capabilities = $::os_service_default, $helper_command = $::os_service_default, ) { if $config { $privsep_options = { ""privsep_${entrypoint}/helper_command"": value => $helper_command; } create_resources($config, $privsep_options) } } ",,51,0
openstack%2Fopenstack-helm~master~I66108505aec6593c637dc8f9b545c8d935df22e9,openstack/openstack-helm,master,I66108505aec6593c637dc8f9b545c8d935df22e9,WIP: Nova/Neutron: Fix metadata interaction,ABANDONED,2017-08-28 21:45:09.000000000,2017-12-18 20:44:28.000000000,,[{'_account_id': 26201}],"[{'number': 1, 'created': '2017-08-28 21:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b7de328679e85a254853f0c284494f8fd4d8fd52', 'message': 'WIP: Nova/Neutron: Fix metadata interaction\n\nChange-Id: I66108505aec6593c637dc8f9b545c8d935df22e9\n'}, {'number': 2, 'created': '2017-08-29 02:24:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6141e6ae682921d003f86b57b3c36e34809f7f86', 'message': 'WIP: Nova/Neutron: Fix metadata interaction\n\nChange-Id: I66108505aec6593c637dc8f9b545c8d935df22e9\n'}, {'number': 3, 'created': '2017-08-29 03:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a7f0c38a67a0b0f18603bb7ef24cf6fef86d9f9a', 'message': 'WIP: Nova/Neutron: Fix metadata interaction\n\nChange-Id: I66108505aec6593c637dc8f9b545c8d935df22e9\n'}, {'number': 4, 'created': '2017-08-29 03:31:33.000000000', 'files': ['neutron/templates/bin/_neutron-metadata-agent.sh.tpl', 'nova/templates/bin/_nova-api-metadata.sh.tpl', 'nova/templates/configmap-etc.yaml', 'nova/templates/service-metadata.yaml', 'nova/templates/service-ingress-metadata.yaml', 'neutron/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/320b922589df40313389a6570b2f835f17c49bb4', 'message': 'WIP: Nova/Neutron: Fix metadata interaction\n\nChange-Id: I66108505aec6593c637dc8f9b545c8d935df22e9\n'}]",0,498608,320b922589df40313389a6570b2f835f17c49bb4,21,1,4,23928,,,0,"WIP: Nova/Neutron: Fix metadata interaction

Change-Id: I66108505aec6593c637dc8f9b545c8d935df22e9
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/08/498608/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/values.yaml'],1,b7de328679e85a254853f0c284494f8fd4d8fd52,nova/fix-metadata, nova_metadata_port: 8774, nova_metadata_port: 80,1,1
openstack%2Fproject-config~master~Ida4f142953e324e65410835c24a63b34e1fa481c,openstack/project-config,master,Ida4f142953e324e65410835c24a63b34e1fa481c,Add missing job descriptions,MERGED,2017-12-15 06:46:37.000000000,2017-12-18 20:44:25.000000000,2017-12-18 20:44:25.000000000,"[{'_account_id': 2}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 06:46:37.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/11a085c37d1505582d9555731798aa9542b14a0c', 'message': ""Add missing job descriptions\n\nNow that zuulv3.openstack.org can show jobs, it's clear how many do not\nhave a description. Add one for all jobs in this repository.\n\nChange-Id: Ida4f142953e324e65410835c24a63b34e1fa481c\n""}]",0,528166,11a085c37d1505582d9555731798aa9542b14a0c,7,3,1,6547,,,0,"Add missing job descriptions

Now that zuulv3.openstack.org can show jobs, it's clear how many do not
have a description. Add one for all jobs in this repository.

Change-Id: Ida4f142953e324e65410835c24a63b34e1fa481c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/66/528166/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,11a085c37d1505582d9555731798aa9542b14a0c,job-descriptions, description: | Sync content to other projects as a proposed change. description: | Update constraint files for requirements project with a proposed change. description: | Update project-config files with a proposed change. description: | Base job for building of wheel for OpenStack CI mirrors. description: | Build CentOS 7 wheels for OpenStaci CI mirrors. description: | Publish CentOS 7 wheels for OpenStaci CI mirrors. description: | Build Ubuntu Trusty wheels for OpenStaci CI mirrors. description: | Publish Ubuntu Trusty wheels for OpenStaci CI mirrors. description: | Build Ubuntu Xenial wheels for OpenStaci CI mirrors. description: | Publish Ubuntu Xenial wheels for OpenStaci CI mirrors. description: | Release published wheels to OpenStack CI mirrors. description: | Tag projects for a release. description: | Check file zuul.d/main.yaml in project-config. description: | Push strings for translation to translation server. description: | Import translations from translation server to projects as proposed change.,,32,0
openstack%2Fopenstack-helm~master~I6c9cb0007313319f59682d0bee2b690740dcdee8,openstack/openstack-helm,master,I6c9cb0007313319f59682d0bee2b690740dcdee8,RabbitMQ: fix centos and fedora docker support,ABANDONED,2017-09-20 05:13:39.000000000,2017-12-18 20:44:15.000000000,,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 23928}, {'_account_id': 26201}]","[{'number': 1, 'created': '2017-09-20 05:13:39.000000000', 'files': ['rabbitmq/templates/bin/_rabbitmq-liveness.sh.tpl', 'rabbitmq/templates/bin/_rabbitmq-readiness.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/753b6ac1867116588fd1bd3d4bcb15e674357fa7', 'message': 'RabbitMQ: fix centos and fedora docker support\n\nThis PS allows the probes to run, which were failing with newer\nversions of Docker on CentOS and Fedora.\n\nChange-Id: I6c9cb0007313319f59682d0bee2b690740dcdee8\n'}]",0,505492,753b6ac1867116588fd1bd3d4bcb15e674357fa7,18,4,1,23928,,,0,"RabbitMQ: fix centos and fedora docker support

This PS allows the probes to run, which were failing with newer
versions of Docker on CentOS and Fedora.

Change-Id: I6c9cb0007313319f59682d0bee2b690740dcdee8
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/92/505492/1 && git format-patch -1 --stdout FETCH_HEAD,"['rabbitmq/templates/bin/_rabbitmq-liveness.sh.tpl', 'rabbitmq/templates/bin/_rabbitmq-readiness.sh.tpl']",2,753b6ac1867116588fd1bd3d4bcb15e674357fa7,rabbitmq-check-fix,,exec 1>/proc/1/fd/2 2>/proc/1/fd/2,0,2
openstack%2Fopenstack-helm~master~I9f8a90fdf523733deacc531785723477df9d7519,openstack/openstack-helm,master,I9f8a90fdf523733deacc531785723477df9d7519,WIP: Make image names explicit across repo,ABANDONED,2017-09-26 13:19:00.000000000,2017-12-18 20:44:05.000000000,,[{'_account_id': 26201}],"[{'number': 1, 'created': '2017-09-26 13:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d19bcc3395d6fb17d92bb6cdd363cef7e5a719dc', 'message': 'WIP: Make image names explicit across repo\n\nThis PS amkes the image names across the repo explict, allowing a\nsingle yaml to change the images from one source to another (eg LOCI\nand Kolla).\n\nChange-Id: I9f8a90fdf523733deacc531785723477df9d7519\n'}, {'number': 2, 'created': '2017-09-26 13:19:57.000000000', 'files': ['cinder/templates/deployment-volume.yaml', 'cinder/templates/job-db-sync.yaml', 'barbican/values.yaml', 'ceph/templates/daemonset-mon.yaml', 'barbican/templates/job-db-sync.yaml', 'cinder/values.yaml', 'ceph/templates/deployment-moncheck.yaml', 'cinder/templates/deployment-backup.yaml', 'ceph/templates/deployment-mds.yaml', 'ceph/values.yaml', 'cinder/templates/deployment-api.yaml', 'cinder/templates/deployment-scheduler.yaml', 'ceph/templates/deployment-rgw.yaml', 'ceph/templates/job-bootstrap.yaml', 'ceph/templates/deployment-rbd-provisioner.yaml', 'barbican/templates/deployment-api.yaml', 'ceph/templates/daemonset-osd.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/fa8d5d85037fdee288872dcad09867c9aa120077', 'message': 'WIP: Make image names explicit across repo\n\nThis PS amkes the image names across the repo explict, allowing a\nsingle yaml to change the images from one source to another (eg LOCI\nand Kolla).\n\nChange-Id: I9f8a90fdf523733deacc531785723477df9d7519\n'}]",0,507533,fa8d5d85037fdee288872dcad09867c9aa120077,9,1,2,23928,,,0,"WIP: Make image names explicit across repo

This PS amkes the image names across the repo explict, allowing a
single yaml to change the images from one source to another (eg LOCI
and Kolla).

Change-Id: I9f8a90fdf523733deacc531785723477df9d7519
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/33/507533/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/templates/deployment-volume.yaml', 'cinder/templates/job-db-sync.yaml', 'barbican/values.yaml', 'ceph/templates/daemonset-mon.yaml', 'barbican/templates/job-db-sync.yaml', 'cinder/values.yaml', 'ceph/templates/deployment-moncheck.yaml', 'cinder/templates/deployment-backup.yaml', 'ceph/templates/deployment-mds.yaml', 'ceph/values.yaml', 'cinder/templates/deployment-api.yaml', 'cinder/templates/deployment-scheduler.yaml', 'ceph/templates/deployment-rgw.yaml', 'ceph/templates/job-bootstrap.yaml', 'ceph/templates/deployment-rbd-provisioner.yaml', 'barbican/templates/deployment-api.yaml', 'ceph/templates/daemonset-osd.yaml']",17,d19bcc3395d6fb17d92bb6cdd363cef7e5a719dc,image/names, image: {{ .Values.images.ceph_osd }} image: {{ .Values.images.ceph_osd }}, image: {{ .Values.images.daemon }} image: {{ .Values.images.daemon }},35,31
openstack%2Fopenstack-helm~master~Ib95a7c53952d1b9c217027ceecd2adb0b36fdcc0,openstack/openstack-helm,master,Ib95a7c53952d1b9c217027ceecd2adb0b36fdcc0,RFC: Move to LOCI images,ABANDONED,2017-09-10 08:19:04.000000000,2017-12-18 20:43:58.000000000,,"[{'_account_id': 8898}, {'_account_id': 23928}, {'_account_id': 26201}]","[{'number': 1, 'created': '2017-09-10 08:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d854557d1505ca217fa7e9415dd30d7b99e2052e', 'message': 'RFC: Move to LOCI images\n\nThis PS uses the images from dockerhub built from the charts in\nhttps://review.openstack.org/#/c/502264/ to deliver a LOCI deployment\nof openstack helm. Other service images are built to be as minimal as\npractical, and theonly remaining images from kolla are for rally and\nmistral, as these do not use openstack-requirements inline with other\nservices as of the Newton release.\n\nChange-Id: Ib95a7c53952d1b9c217027ceecd2adb0b36fdcc0\n'}, {'number': 2, 'created': '2017-09-10 08:22:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/600b2146133c528a77a4a66e80c6c710e209848d', 'message': 'RFC: Move to LOCI images\n\nThis PS uses the images from dockerhub built from the charts in\nhttps://review.openstack.org/#/c/502264/ to deliver a LOCI deployment\nof openstack helm. Other service images are built to be as minimal as\npractical, and theonly remaining images from kolla are for rally and\nmistral, as these do not use openstack-requirements inline with other\nservices as of the Newton release.\n\nChange-Id: Ib95a7c53952d1b9c217027ceecd2adb0b36fdcc0\n'}, {'number': 3, 'created': '2017-09-10 08:44:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d85fc3ec342d8a49a4a4085cf8fdd03ec7aac29a', 'message': 'RFC: Move to LOCI images\n\nThis PS uses the images from dockerhub built from the charts in\nhttps://review.openstack.org/#/c/502264/ to deliver a LOCI deployment\nof openstack helm. Other service images are built to be as minimal as\npractical, and theonly remaining images from kolla are for rally and\nmistral, as these do not use openstack-requirements inline with other\nservices as of the Newton release.\n\nChange-Id: Ib95a7c53952d1b9c217027ceecd2adb0b36fdcc0\n'}, {'number': 4, 'created': '2017-09-10 09:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5990ea2c405b3ce3077052ce2d4f3844a8d97367', 'message': 'RFC: Move to LOCI images\n\nThis PS uses the images from dockerhub built from the charts in\nhttps://review.openstack.org/#/c/502264/ to deliver a LOCI deployment\nof openstack helm. Other service images are built to be as minimal as\npractical, and theonly remaining images from kolla are for rally and\nmistral, as these do not use openstack-requirements inline with other\nservices as of the Newton release.\n\nChange-Id: Ib95a7c53952d1b9c217027ceecd2adb0b36fdcc0\n'}, {'number': 5, 'created': '2017-09-12 15:18:57.000000000', 'files': ['mistral/values.yaml', 'openvswitch/values.yaml', 'barbican/values.yaml', 'heat/values.yaml', 'cinder/values.yaml', 'magnum/values.yaml', 'doc/source/devref/images.rst', 'libvirt/values.yaml', 'ceph/values.yaml', 'glance/values.yaml', 'horizon/values.yaml', 'nova/values.yaml', 'keystone/values.yaml', 'neutron/values.yaml', 'ingress/values.yaml', 'rabbitmq/values.yaml', 'senlin/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/291570ceac4578fa571e07f450b9fde8f6c09fda', 'message': 'RFC: Move to LOCI images\n\nThis PS uses the images from dockerhub built from the charts in\nhttps://review.openstack.org/#/c/502264/ to deliver a LOCI deployment\nof openstack helm. Other service images are built to be as minimal as\npractical, and theonly remaining images from kolla are for rally and\nmistral, as these do not use openstack-requirements inline with other\nservices as of the Newton release.\n\nChange-Id: Ib95a7c53952d1b9c217027ceecd2adb0b36fdcc0\n'}]",0,502301,291570ceac4578fa571e07f450b9fde8f6c09fda,23,3,5,23928,,,0,"RFC: Move to LOCI images

This PS uses the images from dockerhub built from the charts in
https://review.openstack.org/#/c/502264/ to deliver a LOCI deployment
of openstack helm. Other service images are built to be as minimal as
practical, and theonly remaining images from kolla are for rally and
mistral, as these do not use openstack-requirements inline with other
services as of the Newton release.

Change-Id: Ib95a7c53952d1b9c217027ceecd2adb0b36fdcc0
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/01/502301/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/values.yaml', 'openvswitch/values.yaml', 'barbican/values.yaml', 'heat/values.yaml', 'cinder/values.yaml', 'magnum/values.yaml', 'doc/source/devref/images.rst', 'libvirt/values.yaml', 'ceph/values.yaml', 'glance/values.yaml', 'horizon/values.yaml', 'nova/values.yaml', 'keystone/values.yaml', 'neutron/values.yaml', 'ingress/values.yaml', 'rabbitmq/values.yaml', 'senlin/values.yaml']",17,d854557d1505ca217fa7e9415dd30d7b99e2052e,gantry/loci, bootstrap: docker.io/gantry/loci-heat:newton-ubuntu db_init: docker.io/gantry/loci-heat:newton-ubuntu db_sync: docker.io/gantry/loci-senlin:newton-ubuntu ks_user: docker.io/gantry/loci-heat:newton-ubuntu ks_service: docker.io/gantry/loci-heat:newton-ubuntu ks_endpoints: docker.io/gantry/loci-heat:newton-ubuntu api: docker.io/gantry/loci-senlin:newton-ubuntu engine: docker.io/gantry/loci-senlin:newton-ubuntu dep_check: docker.io/gantry/kubernetes-entrypoint:newton-ubuntu uid: 42424, bootstrap: docker.io/kolla/ubuntu-source-heat-engine:3.0.3 db_init: docker.io/kolla/ubuntu-source-heat-engine:3.0.3 db_sync: docker.io/kolla/ubuntu-source-senlin-api:3.0.3 ks_user: docker.io/kolla/ubuntu-source-heat-engine:3.0.3 ks_service: docker.io/kolla/ubuntu-source-heat-engine:3.0.3 ks_endpoints: docker.io/kolla/ubuntu-source-heat-engine:3.0.3 api: docker.io/kolla/ubuntu-source-senlin-api:3.0.3 engine: docker.io/kolla/ubuntu-source-senlin-engine:3.0.3 dep_check: docker.io/kolla/ubuntu-source-kubernetes-entrypoint:4.0.0 uid: 1000,132,132
openstack%2Fopenstack-helm~master~Iee6803fe00b33cc418c107e74b3625ad08fb2558,openstack/openstack-helm,master,Iee6803fe00b33cc418c107e74b3625ad08fb2558,WIP/DNM: Cluster docker registry,ABANDONED,2017-08-26 19:30:25.000000000,2017-12-18 20:43:45.000000000,,[{'_account_id': 26201}],"[{'number': 1, 'created': '2017-08-26 19:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8dbb292f150a7ff18f90c73267479a7ad3722e86', 'message': 'WIP/DNM: Cluster docker registry\n\nThis PS provides a cluster wide local docker registry.\n\nChange-Id: Iee6803fe00b33cc418c107e74b3625ad08fb2558\n'}, {'number': 2, 'created': '2017-08-26 19:58:48.000000000', 'files': ['tools/gate/launch-osh/basic.sh', 'registry/templates/service-registry.yaml', 'registry/templates/job-bootstrap.yaml', 'registry/templates/bin/_bootstrap.sh.tpl', 'registry/templates/daemonset-registry-proxy.yaml', 'glance/values.yaml', 'horizon/values.yaml', 'registry/templates/pvc-images.yaml', 'registry/requirements.yaml', 'keystone/values.yaml', 'registry/templates/deployment-registry.yaml', 'rabbitmq/values.yaml', 'senlin/values.yaml', 'mistral/values.yaml', 'registry/values.yaml', 'barbican/values.yaml', 'heat/values.yaml', 'registry/templates/bin/_registry-proxy.sh.tpl', 'cinder/values.yaml', 'magnum/values.yaml', 'registry/templates/configmap-bin.yaml', 'registry/Chart.yaml', 'registry/templates/bin/_registry.sh.tpl', 'nova/values.yaml', 'registry/templates/etc/_default.conf.tpl', 'registry/templates/configmap-etc.yaml', 'neutron/values.yaml', 'ingress/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/179e1e0e95207d5b51ac706c8323c69b8d35433e', 'message': 'WIP/DNM: Cluster docker registry\n\nThis PS provides a cluster wide local docker registry.\n\nChange-Id: Iee6803fe00b33cc418c107e74b3625ad08fb2558\n'}]",0,498210,179e1e0e95207d5b51ac706c8323c69b8d35433e,13,1,2,23928,,,0,"WIP/DNM: Cluster docker registry

This PS provides a cluster wide local docker registry.

Change-Id: Iee6803fe00b33cc418c107e74b3625ad08fb2558
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/10/498210/2 && git format-patch -1 --stdout FETCH_HEAD,"['registry/templates/service-registry.yaml', 'registry/templates/job-bootstrap.yaml', 'registry/templates/bin/_bootstrap.sh.tpl', 'ceph/values.yaml', 'registry/templates/daemonset-registry-proxy.yaml', 'glance/values.yaml', 'horizon/values.yaml', 'registry/templates/pvc-images.yaml', 'registry/requirements.yaml', 'keystone/values.yaml', 'registry/templates/deployment-registry.yaml', 'rabbitmq/values.yaml', 'senlin/values.yaml', 'mistral/values.yaml', 'registry/values.yaml', 'barbican/values.yaml', 'heat/values.yaml', 'registry/templates/bin/_registry-proxy.sh.tpl', 'cinder/values.yaml', 'magnum/values.yaml', 'registry/templates/configmap-bin.yaml', 'registry/Chart.yaml', 'tools/gate/launch-osh/common.sh', 'registry/templates/bin/_registry.sh.tpl', 'nova/values.yaml', 'registry/templates/etc/_default.conf.tpl', 'registry/templates/configmap-etc.yaml', 'neutron/values.yaml', 'ingress/values.yaml']",29,8dbb292f150a7ff18f90c73267479a7ad3722e86,loci-images, entrypoint: localhost:5000/docker.io/gantry/kubernetes-entrypoint:v.0.1.1, entrypoint: docker.io/gantry/kubernetes-entrypoint:v.0.1.1,703,75
openstack%2Fopenstack-helm~master~I388f7f7e1236c5f4b7d11746a377af5d76993d01,openstack/openstack-helm,master,I388f7f7e1236c5f4b7d11746a377af5d76993d01,RFC: Values.yaml: Sort keys alphabetically,ABANDONED,2017-07-09 20:09:26.000000000,2017-12-18 20:43:36.000000000,,"[{'_account_id': 8181}, {'_account_id': 17589}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 21307}, {'_account_id': 23928}]","[{'number': 1, 'created': '2017-07-09 20:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1508754926269777226ea73cc5da12d290d6b042', 'message': 'RFC: Values.yaml: Sort keys alphabetically\n\nThis PS proposes to sort the Default values.yaml alphabetically,\nthough it could be argued theat a more atheticly pleasing approach\nmay be possible - this reduces any abiguity and will not suffer from\nedge-cases.\n\nChange-Id: I388f7f7e1236c5f4b7d11746a377af5d76993d01\n'}, {'number': 2, 'created': '2017-07-09 20:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/85122dfcce91db715a083b974e9d8ca0ea0ed9d0', 'message': 'RFC: Values.yaml: Sort keys alphabetically\n\nThis PS proposes to sort the Default values.yaml alphabetically,\nthough it could be argued that a more aesthetically pleasing approach\nmay be possible - this removes any ambiguity and will not suffer from\nedge-cases as values are added and removed.\n\nChange-Id: I388f7f7e1236c5f4b7d11746a377af5d76993d01\n'}, {'number': 3, 'created': '2017-07-14 19:04:44.000000000', 'files': ['barbican/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8068f0fb1b843f987d2c36841b649f391a482664', 'message': 'RFC: Values.yaml: Sort keys alphabetically\n\nThis PS proposes to sort the Default values.yaml alphabetically, with a\nsmall subset brought to the top. Though it could be argued that a more\naesthetically pleasing approach may be possible - this removes any\nambiguity and will not suffer from edge-cases as values are added and\nremoved.\n\nChange-Id: I388f7f7e1236c5f4b7d11746a377af5d76993d01\n'}]",0,481964,8068f0fb1b843f987d2c36841b649f391a482664,16,6,3,23928,,,0,"RFC: Values.yaml: Sort keys alphabetically

This PS proposes to sort the Default values.yaml alphabetically, with a
small subset brought to the top. Though it could be argued that a more
aesthetically pleasing approach may be possible - this removes any
ambiguity and will not suffer from edge-cases as values are added and
removed.

Change-Id: I388f7f7e1236c5f4b7d11746a377af5d76993d01
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/64/481964/1 && git format-patch -1 --stdout FETCH_HEAD,['barbican/values.yaml'],1,1508754926269777226ea73cc5da12d290d6b042,values/cleanup,# Copyright 2017 The Openstack-Helm Authors. # # Default values for barbican. # This is a YAML-formatted file. # Declare name/value pairs to be passed into your templates. # name: value conf: audit_map: append: null override: null barbican: append: null barbican_api: barbican: config: bind_port: 9311 database: oslo: db: max_retries: -1 keystone_authtoken: keystonemiddleware: auth_token: auth_type: password auth_version: v3 override: null paste: append: null override: null policy: append: null override: null dependencies: api: jobs: - barbican-db-sync - barbican-ks-user - barbican-ks-endpoints services: - endpoint: internal service: oslo_db - endpoint: internal service: identity db_init: services: - endpoint: internal service: oslo_db db_sync: jobs: - barbican-db-init services: - endpoint: internal service: oslo_db ks_endpoints: jobs: - barbican-ks-service services: - endpoint: internal service: identity ks_service: services: - endpoint: internal service: identity ks_user: services: - endpoint: internal service: identity endpoints: identity: auth: admin: password: password project_domain_name: default project_name: admin region_name: RegionOne user_domain_name: default username: admin user: password: password project_domain_name: default project_name: service region_name: RegionOne role: admin user_domain_name: default username: barbican hosts: default: keystone-api public: keystone name: keystone path: default: /v3 port: admin: default: 35357 api: default: 80 scheme: default: http key-manager: hosts: default: barbican-api public: barbican name: barbican path: default: /v1 port: api: default: 9311 public: 80 scheme: default: http oslo_cache: hosts: default: memcached port: memcache: default: 11211 oslo_db: auth: admin: password: password username: root user: password: password username: barbican hosts: default: mariadb path: /barbican port: mysql: default: 3306 scheme: mysql+pymysql oslo_messaging: auth: admin: password: password username: admin user: password: password username: rabbitmq hosts: default: rabbitmq path: / port: amqp: default: 5672 scheme: rabbit images: api: 'docker.io/kolla/ubuntu-source-barbican-api:3.0.3' db_init: 'docker.io/kolla/ubuntu-source-barbican-api:3.0.3' db_sync: 'docker.io/kolla/ubuntu-source-barbican-api:3.0.3' dep_check: 'docker.io/kolla/ubuntu-source-kubernetes-entrypoint:4.0.0' ks_endpoints: 'docker.io/kolla/ubuntu-source-kolla-toolbox:3.0.3' ks_service: 'docker.io/kolla/ubuntu-source-kolla-toolbox:3.0.3' ks_user: 'docker.io/kolla/ubuntu-source-kolla-toolbox:3.0.3' pull_policy: IfNotPresentmounts: barbican_api: barbican_api: null init_container: nullpod_disruption_budget: api: min_available: 0 replicas: api: 1 resources: api: null enabled: false jobs: bootstrap: limits: cpu: 2000m memory: 1024Mi requests: cpu: 100m memory: 128Mi db_init: limits: cpu: 2000m memory: 1024Mi requests: cpu: 100m memory: 128Mi db_sync: limits: cpu: 2000m memory: 1024Mi requests: cpu: 100m memory: 128Mi ks_endpoints: limits: cpu: 2000m memory: 1024Mi requests: cpu: 100m memory: 128Mi ks_service: limits: cpu: 2000m memory: 1024Mi requests: cpu: 100m memory: 128Mi ks_user: limits: cpu: 2000m memory: 1024Mi requests: cpu: 100m memory: 128Mi tests: limits: cpu: 2000m memory: 1024Mi requests: cpu: 100m memory: 128Mi limits: cpu: 2000m memory: 1024Mi requests: cpu: 100m memory: 128Mi upgrades: deployments: pod_replacement_strategy: RollingUpdate revision_history: 3 rolling_update: max_surge: 3 max_unavailable: 1,"replicas: api: 1images: dep_check: docker.io/kolla/ubuntu-source-kubernetes-entrypoint:4.0.0 db_init: docker.io/kolla/ubuntu-source-barbican-api:3.0.3 db_sync: docker.io/kolla/ubuntu-source-barbican-api:3.0.3 ks_user: docker.io/kolla/ubuntu-source-kolla-toolbox:3.0.3 ks_service: docker.io/kolla/ubuntu-source-kolla-toolbox:3.0.3 ks_endpoints: docker.io/kolla/ubuntu-source-kolla-toolbox:3.0.3 api: docker.io/kolla/ubuntu-source-barbican-api:3.0.3 pull_policy: ""IfNotPresent"" upgrades: deployments: revision_history: 3 pod_replacement_strategy: RollingUpdate rolling_update: max_unavailable: 1 max_surge: 3 pod_disruption_budget: api: min_available: 0dependencies: db_init: services: - service: oslo_db endpoint: internal db_sync: jobs: - barbican-db-init services: - service: oslo_db endpoint: internal ks_user: services: - service: identity endpoint: internal ks_service: services: - service: identity endpoint: internal ks_endpoints: jobs: - barbican-ks-service services: - service: identity endpoint: internal api: jobs: - barbican-db-sync - barbican-ks-user - barbican-ks-endpoints services: - service: oslo_db endpoint: internal - service: identity endpoint: internal conf: paste: override: append: policy: override: append: audit_map: override: append: barbican: override: append: keystone_authtoken: keystonemiddleware: auth_token: auth_type: password auth_version: v3 database: oslo: db: max_retries: -1 barbican_api: barbican: config: bind_port: 9311 # Names of secrets used by bootstrap and environmental checksendpoints: identity: name: keystone auth: admin: region_name: RegionOne username: admin password: password project_name: admin user_domain_name: default project_domain_name: default user: role: admin region_name: RegionOne username: barbican password: password project_name: service user_domain_name: default project_domain_name: default hosts: default: keystone-api public: keystone path: default: /v3 scheme: default: http port: admin: default: 35357 api: default: 80 key-manager: name: barbican hosts: default: barbican-api public: barbican path: default: /v1 scheme: default: http port: api: default: 9311 public: 80 oslo_db: auth: admin: username: root password: password user: username: barbican password: password hosts: default: mariadb path: /barbican scheme: mysql+pymysql port: mysql: default: 3306 oslo_messaging: auth: admin: username: admin password: password user: username: rabbitmq password: password hosts: default: rabbitmq path: / scheme: rabbit port: amqp: default: 5672 oslo_cache: hosts: default: memcached port: memcache: default: 11211 resources: enabled: false api: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" jobs: bootstrap: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" db_init: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" db_sync: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" ks_endpoints: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" ks_service: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" ks_user: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" tests: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" mounts: barbican_api: init_container: null barbican_api:",236,229
openstack%2Fpuppet-neutron~master~Ifd62fc3fd93bebacbe51dd504ff4871dd3f267a5,openstack/puppet-neutron,master,Ifd62fc3fd93bebacbe51dd504ff4871dd3f267a5,Add interface mapping support for sriov configuration,ABANDONED,2017-08-31 04:12:07.000000000,2017-12-18 20:40:00.000000000,,"[{'_account_id': 6681}, {'_account_id': 8971}]","[{'number': 1, 'created': '2017-08-31 04:12:07.000000000', 'files': ['manifests/agents/ml2/sriov.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/15252eea59c72e4df5d3329cf9c42b9965a1c159', 'message': 'Add interface mapping support for sriov configuration\n\nChange-Id: Ifd62fc3fd93bebacbe51dd504ff4871dd3f267a5\n'}]",0,499450,15252eea59c72e4df5d3329cf9c42b9965a1c159,8,2,1,21151,,,0,"Add interface mapping support for sriov configuration

Change-Id: Ifd62fc3fd93bebacbe51dd504ff4871dd3f267a5
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/50/499450/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/agents/ml2/sriov.pp'],1,15252eea59c72e4df5d3329cf9c42b9965a1c159,logical_sriov_name," $exclude_devices_array = split($exclude_devices, ',') $exclude_devices_array.each | String $device | { $interface = split($device, ':') $mapping = generate('os-net-config', '-i', ${interface[1]}) $real_name = ${mapping[${interface[1]}]} $exclude_devices = regsubst($exclude_devices, $interface[1], $real_name) } $physical_device_mappings_array = split($physical_device_mappings, ',') $physical_device_mappings_array.each | String $device | { $interface = split($device, ':') $mapping = generate('os-net-config', '-i', ${interface[0]}) $real_name = ${mapping[${interface[0]}]} $physical_device_mappings = regsubst($physical_device_mappings, $interface[0], $real_name) } ",,16,0
openstack%2Fproject-config~master~I9272ff67510b13f2a7c2ffbfe194b73e7f53c964,openstack/project-config,master,I9272ff67510b13f2a7c2ffbfe194b73e7f53c964,Add all infra puppet modules to system-config queue,MERGED,2017-12-14 21:55:00.000000000,2017-12-18 20:39:53.000000000,2017-12-18 20:39:53.000000000,"[{'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-14 21:55:00.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c225934792a4733b8c2ab3ef5318a9b1d94a0538', 'message': 'Add all infra puppet modules to system-config queue\n\nChange-Id: I9272ff67510b13f2a7c2ffbfe194b73e7f53c964\n'}]",0,528095,c225934792a4733b8c2ab3ef5318a9b1d94a0538,7,3,1,1,,,0,"Add all infra puppet modules to system-config queue

Change-Id: I9272ff67510b13f2a7c2ffbfe194b73e7f53c964
",git fetch https://review.opendev.org/openstack/project-config refs/changes/95/528095/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,c225934792a4733b8c2ab3ef5318a9b1d94a0538,, gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config queue: system-config queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config gate: queue: system-config queue: system-config,,173,0
openstack%2Fpuppet-neutron~master~Ia2d1782458c49151bd78d225cd5f774454bc253c,openstack/puppet-neutron,master,Ia2d1782458c49151bd78d225cd5f774454bc253c,Disable DHCP agent notification if NSX plugin is used.,ABANDONED,2017-08-26 03:16:31.000000000,2017-12-18 20:39:11.000000000,,"[{'_account_id': 3}, {'_account_id': 1004}, {'_account_id': 8971}, {'_account_id': 12024}]","[{'number': 1, 'created': '2017-08-26 03:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/aae03f29558372a0115f095761cff4a2a60cd1f1', 'message': 'Disable DHCP agent notification if NSX plugin is used.\n\nThis patch disables DHCP agent notification, which is enabled in Neutron by\ndefault, since NSX handles DHCP services for networks.\n\nWithout this patch, errors can occur in Neutron because DHCP agents are not\nbeing used.\n\nChange-Id: Ia2d1782458c49151bd78d225cd5f774454bc253c\n'}, {'number': 2, 'created': '2017-08-26 03:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/33aa132564e3f529070f1e4bed00733b5bc39f19', 'message': 'Disable DHCP agent notification if NSX plugin is used.\n\nThis patch disables DHCP agent notification, which is enabled in Neutron by\ndefault, since NSX handles DHCP services for networks.\n\nWithout this patch, errors can occur in Neutron because DHCP agents are not\nbeing used.\n\nCloses-Bug: #1713190\nChange-Id: Ia2d1782458c49151bd78d225cd5f774454bc253c\n'}, {'number': 3, 'created': '2017-09-05 08:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/74ab489dff7e37616d312c7420a99b9083bb878c', 'message': 'Disable DHCP agent notification if NSX plugin is used.\n\nThis patch disables DHCP agent notification, which is enabled in Neutron by\ndefault, since NSX handles DHCP services for networks.\n\nWithout this patch, errors can occur in Neutron because DHCP agents are not\nbeing used.\n\nCloses-Bug: #1713190\nChange-Id: Ia2d1782458c49151bd78d225cd5f774454bc253c\n'}, {'number': 4, 'created': '2017-09-05 08:05:29.000000000', 'files': ['manifests/plugins/nsx.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/1a40f943efdcd445ea11e97c3d88f0eadffe6b66', 'message': 'Disable DHCP agent notification if NSX plugin is used.\n\nThis patch disables DHCP agent notification, which is enabled in Neutron by\ndefault, since NSX handles DHCP services for networks.\n\nWithout this patch, errors can occur in Neutron because DHCP agents are not\nbeing used.\n\nCloses-Bug: #1713190\nChange-Id: Ia2d1782458c49151bd78d225cd5f774454bc253c\n'}]",0,498141,1a40f943efdcd445ea11e97c3d88f0eadffe6b66,16,4,4,22093,,,0,"Disable DHCP agent notification if NSX plugin is used.

This patch disables DHCP agent notification, which is enabled in Neutron by
default, since NSX handles DHCP services for networks.

Without this patch, errors can occur in Neutron because DHCP agents are not
being used.

Closes-Bug: #1713190
Change-Id: Ia2d1782458c49151bd78d225cd5f774454bc253c
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/41/498141/4 && git format-patch -1 --stdout FETCH_HEAD,['manifests/plugins/nsx.pp'],1,aae03f29558372a0115f095761cff4a2a60cd1f1,bug/1713190,"# [*dhcp_agent_notification] # Flag to enable DHCP agent notification. # $default_overlay_tz = $::os_service_default, $default_tier0_router = $::os_service_default, $nsx_api_managers = $::os_service_default, $nsx_api_user = $::os_service_default, $nsx_api_password = $::os_service_default, $dhcp_profile_uuid = $::os_service_default, $metadata_proxy_uuid = $::os_service_default, $native_dhcp_metadata = $::os_service_default, $dhcp_agent_notification = $::os_service_default, $package_ensure = 'present', $purge_config = false, 'nsx_v3/default_overlay_tz': value => $default_overlay_tz; 'nsx_v3/default_tier0_router': value => $default_tier0_router; 'nsx_v3/nsx_api_managers': value => $nsx_api_managers; 'nsx_v3/nsx_api_user': value => $nsx_api_user; 'nsx_v3/nsx_api_password': value => $nsx_api_password; 'nsx_v3/dhcp_profile_uuid': value => $dhcp_profile_uuid; 'nsx_v3/metadata_proxy_uuid': value => $metadata_proxy_uuid; 'nsx_v3/native_dhcp_metadata': value => $native_dhcp_metadata; 'DEFAULT/dhcp_agent_notification': value => $dhcp_agent_notification;"," $default_overlay_tz = $::os_service_default, $default_tier0_router = $::os_service_default, $nsx_api_managers = $::os_service_default, $nsx_api_user = $::os_service_default, $nsx_api_password = $::os_service_default, $dhcp_profile_uuid = $::os_service_default, $metadata_proxy_uuid = $::os_service_default, $native_dhcp_metadata = $::os_service_default, $package_ensure = 'present', $purge_config = false, 'nsx_v3/default_overlay_tz': value => $default_overlay_tz; 'nsx_v3/default_tier0_router': value => $default_tier0_router; 'nsx_v3/nsx_api_managers': value => $nsx_api_managers; 'nsx_v3/nsx_api_user': value => $nsx_api_user; 'nsx_v3/nsx_api_password': value => $nsx_api_password; 'nsx_v3/dhcp_profile_uuid': value => $dhcp_profile_uuid; 'nsx_v3/metadata_proxy_uuid': value => $metadata_proxy_uuid; 'nsx_v3/native_dhcp_metadata': value => $native_dhcp_metadata;",23,18
openstack%2Fpuppet-neutron~master~Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1,openstack/puppet-neutron,master,Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1,Add support for neutron-agent-mlnx deployment,ABANDONED,2015-08-06 15:45:24.000000000,2017-12-18 20:38:06.000000000,,"[{'_account_id': 704}, {'_account_id': 6681}, {'_account_id': 7155}, {'_account_id': 7244}, {'_account_id': 7604}, {'_account_id': 8787}, {'_account_id': 9410}, {'_account_id': 11968}, {'_account_id': 16751}]","[{'number': 1, 'created': '2015-08-06 15:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/7adc45a74d4d02446931897c59f8b42db0ce7fb1', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to:\n1. Install Mellanox packages from Mellanox repository (or from other\n   openstack repository).\n2. Configure and start services: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 2, 'created': '2015-08-09 07:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/da8e918ca40e556bc73550ab9b1567214fb45408', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to:\n1. Install Mellanox packages from Mellanox repository (or from other\n   openstack repository).\n2. Configure and start services: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 3, 'created': '2015-08-09 07:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/ed98b80357003e57321e5b4738f2057fe8c2534b', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to:\n1. Install Mellanox packages from Mellanox repository (or from other\n   openstack repository).\n2. Configure and start services: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 4, 'created': '2015-08-09 10:11:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/29bc2b9bd2db8e9f3aab2830e994e95177ddcd50', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to:\n1. Install Mellanox packages from Mellanox repository (or from other\n   openstack repository).\n2. Configure and start services: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 5, 'created': '2015-08-09 10:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/aaaedbf6c0e29ca7813c69811d028d7765553817', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to:\n1. Install Mellanox packages from Mellanox repository (or from other\n   openstack repository).\n2. Configure and start services: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 6, 'created': '2015-08-09 11:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/ef74bcd9da3d5d30f047b155d23e863cf7e60543', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to:\n1. Install Mellanox packages from Mellanox repository (or from other\n   openstack repository).\n2. Configure and start services: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 7, 'created': '2015-08-13 13:18:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/69bee3bbe295e5ad69f030d9b26598fb4b5f1f12', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to:\n1. Install Mellanox packages from Mellanox repository (or from other\n   openstack repository).\n2. Configure and start services: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 8, 'created': '2015-08-16 12:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/e1c91ed1759489d4060cbd1525ff73c60f4cca94', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to:\n1. Install Mellanox packages from Mellanox repository (or from other\n   openstack repository).\n2. Configure and start services: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 9, 'created': '2015-08-19 14:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/6fe3866d8c27cc852d036ac984d19a325b264ead', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to:\n1. Install Mellanox packages from Mellanox repository (or from other\n   openstack repository).\n2. Configure and start services: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 10, 'created': '2015-11-02 10:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/fc30b2e4107cf185103114c39cc8054b816e2137', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to:\n1. Install Mellanox packages from Mellanox repository (or from other\n   openstack repository).\n2. Configure and start services: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 11, 'created': '2015-11-02 11:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/f40c66d6cbddc4be242eb72d8a9bfc0ff29fefb0', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to configure and start\nservices: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 12, 'created': '2015-11-02 11:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/5210496d83b6edcc0472de37e7d36009e27ed6ab', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to configure and start\nservices: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 13, 'created': '2015-11-02 12:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/81821bec10f0a8e83f571515ac75fda8d6e21010', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to configure and start\nservices: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 14, 'created': '2015-11-25 15:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/11bbc963f3a942ecb71524b08fa4f65d4736a8a9', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to configure and start\nservices: neutron-agent-mlnx and eswitchd.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}, {'number': 15, 'created': '2015-11-25 16:28:23.000000000', 'files': ['spec/unit/provider/neutron_agent_mlnx_config/ini_setting_spec.rb', 'lib/puppet/type/neutron_agent_mlnx_config.rb', 'manifests/agents/ml2/mlnx.pp', 'lib/puppet/provider/neutron_agent_mlnx_config/ini_setting.rb', 'manifests/params.pp', 'spec/classes/neutron_agents_ml2_mlnx_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/fcf3db3c560f2a4bb62e0a4d8ee27e253b3fcdc7', 'message': 'Add support for neutron-agent-mlnx deployment\n\nThis change adds the ability to configure and start\nservices: neutron-agent-mlnx.\n\nChange-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1\n'}]",34,209997,fcf3db3c560f2a4bb62e0a4d8ee27e253b3fcdc7,68,9,15,16751,,,0,"Add support for neutron-agent-mlnx deployment

This change adds the ability to configure and start
services: neutron-agent-mlnx.

Change-Id: Ib8ca0f46548e300aba0cca586b44d6f1e45b2ca1
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/97/209997/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/neutron_agent_mlnx_config/ini_setting_spec.rb', 'lib/puppet/type/neutron_mellanox_eswitchd_config.rb', 'spec/unit/provider/neutron_mellanox_eswitchd_config/ini_setting_spec.rb', 'lib/puppet/type/neutron_agent_mlnx_config.rb', 'manifests/agents/ml2/mlnx.pp', 'lib/puppet/provider/neutron_agent_mlnx_config/ini_setting.rb', 'manifests/params.pp', 'lib/puppet/provider/neutron_mellanox_eswitchd_config/ini_setting.rb', 'spec/classes/neutron_agents_ml2_mlnx_spec.rb']",9,7adc45a74d4d02446931897c59f8b42db0ce7fb1,add_neutron_agent_mlnx,"require 'spec_helper' describe 'neutron::agents::ml2::mlnx' do let :pre_condition do ""class { 'neutron': rabbit_password => 'passw0rd' }"" end let :default_params do { :package_ensure => 'present', :enabled => true, :physical_device_mappings => [], } end let :default_facts do { :operatingsystem => 'default', :operatingsystemrelease => 'default' } end let :params do {} end shared_examples_for 'neutron mlnx agent with ml2 plugin' do let :p do default_params.merge(params) end context 'when supplying device mapping' do before :each do params.merge!(:physical_device_mappings => ['physnet1:eth1']) end end end context 'on RedHat platforms' do let :facts do default_facts.merge({ :osfamily => 'RedHat' }) end let :platform_params do { :mlnx_agent_packages => ['openstack-neutron-mellanox','python-networking-mlnx'], :mlnx_agent_service => 'neutron-mlnx-agent' } end it_configures 'neutron mlnx agent with ml2 plugin' end context 'on Debian platforms' do let :facts do default_facts.merge({ :osfamily => 'Debian' }) end let :platform_params do { :mlnx_agent_packages => ['neutron-plugin-mlnx','neutron-plugin-mlnx-agent'], :mlnx_agent_service => 'neutron-plugin-mlnx-agent' } end it_configures 'neutron mlnx agent with ml2 plugin' end end ",,407,0
openstack%2Fopenstack-zuul-jobs~master~I0271a1430843ef546e991a7a3c4b572b3e404963,openstack/openstack-zuul-jobs,master,I0271a1430843ef546e991a7a3c4b572b3e404963,Remove python-glanceclient legacy jobs,MERGED,2017-12-04 04:48:43.000000000,2017-12-18 20:33:31.000000000,2017-12-18 20:33:31.000000000,"[{'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-04 04:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/2d9d9339e93771e0819274839cda59749b9f40b1', 'message': 'Remove python-glanceclient legacy jobs\n\nDepends-On: I0b974bf60da6bafabeb037a75ac10654e2a6406c\nDepends-On: I1977ee0d348645987107c2efb5b454d7f8b81adf\nChange-Id: I0271a1430843ef546e991a7a3c4b572b3e404963\n'}, {'number': 2, 'created': '2017-12-12 09:43:22.000000000', 'files': ['playbooks/legacy/glanceclient-dsvm-functional-identity-v3-only/run.yaml', 'zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/glanceclient-dsvm-functional-identity-v3-only/post.yaml', 'playbooks/legacy/glanceclient-dsvm-functional/post.yaml', 'playbooks/legacy/glanceclient-dsvm-functional/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/e2ba3319c425768d4e71e48d58d0150dd4b16d95', 'message': 'Remove python-glanceclient legacy jobs\n\nDepends-On: I0b974bf60da6bafabeb037a75ac10654e2a6406c\nChange-Id: I0271a1430843ef546e991a7a3c4b572b3e404963\n'}]",0,525046,e2ba3319c425768d4e71e48d58d0150dd4b16d95,9,3,2,5314,,,0,"Remove python-glanceclient legacy jobs

Depends-On: I0b974bf60da6bafabeb037a75ac10654e2a6406c
Change-Id: I0271a1430843ef546e991a7a3c4b572b3e404963
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/46/525046/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/legacy/glanceclient-dsvm-functional-identity-v3-only/run.yaml', 'zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/glanceclient-dsvm-functional-identity-v3-only/post.yaml', 'playbooks/legacy/glanceclient-dsvm-functional/post.yaml', 'playbooks/legacy/glanceclient-dsvm-functional/run.yaml']",5,2d9d9339e93771e0819274839cda59749b9f40b1,zuul3-migration-glanceclient,,"- hosts: all name: Autoconverted job legacy-glanceclient-dsvm-functional from old job gate-glanceclient-dsvm-functional-ubuntu-xenial tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x cat > clonemap.yaml << EOF clonemap: - name: openstack-infra/devstack-gate dest: devstack-gate EOF /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \ git://git.openstack.org \ openstack-infra/devstack-gate executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x export PYTHONUNBUFFERED=true export BRANCH_OVERRIDE=default export DEVSTACK_PROJECT_FROM_GIT=python-glanceclient if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi if [ """" == ""-identity-v3-only"" ] ; then export DEVSTACK_LOCAL_CONFIG=""ENABLE_IDENTITY_V2=False"" fi # TODO(rosmaita): remove when glanceclient tests no longer # use the Images v1 API export DEVSTACK_LOCAL_CONFIG+=$'\n'""GLANCE_V1_ENABLED=True"" function post_test_hook { # Configure and run functional tests $BASE/new/python-glanceclient/glanceclient/tests/functional/hooks/post_test_hook.sh } export -f post_test_hook cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",0,291
openstack%2Fopenstack-zuul-jobs~master~I649b560c16d8d30afb34a8208fbb47eb6a902e4a,openstack/openstack-zuul-jobs,master,I649b560c16d8d30afb34a8208fbb47eb6a902e4a,remove migrate storyboard-webclient jobs,MERGED,2017-12-15 16:46:12.000000000,2017-12-18 20:33:30.000000000,2017-12-18 20:33:30.000000000,"[{'_account_id': 2}, {'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 16:46:12.000000000', 'files': ['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/storyboard-webclient-nodejs4-npm-run-test-unit/post.yaml', 'playbooks/legacy/storyboard-webclient-nodejs4-npm-run-test-functional/run.yaml', 'playbooks/legacy/storyboard-webclient-nodejs4-npm-run-test-functional/post.yaml', 'playbooks/legacy/storyboard-webclient-nodejs4-npm-run-test-unit/run.yaml', 'playbooks/legacy/storyboard-webclient-nodejs4-npm-run-test-integration/post.yaml', 'playbooks/legacy/storyboard-webclient-nodejs4-npm-run-test-integration/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/ab035b1db2aa6003e5f939b4ae6c55261750056c', 'message': 'remove migrate storyboard-webclient jobs\n\nThese are now in-tree, remove them.\n\nChange-Id: I649b560c16d8d30afb34a8208fbb47eb6a902e4a\nDepends-On: I6187f97b0b32b5140d7e29bc5333e8cf3b8addc1\n'}]",0,528334,ab035b1db2aa6003e5f939b4ae6c55261750056c,11,4,1,6547,,,0,"remove migrate storyboard-webclient jobs

These are now in-tree, remove them.

Change-Id: I649b560c16d8d30afb34a8208fbb47eb6a902e4a
Depends-On: I6187f97b0b32b5140d7e29bc5333e8cf3b8addc1
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/34/528334/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/storyboard-webclient-nodejs4-npm-run-test-unit/post.yaml', 'playbooks/legacy/storyboard-webclient-nodejs4-npm-run-test-functional/run.yaml', 'playbooks/legacy/storyboard-webclient-nodejs4-npm-run-test-functional/post.yaml', 'playbooks/legacy/storyboard-webclient-nodejs4-npm-run-test-unit/run.yaml', 'playbooks/legacy/storyboard-webclient-nodejs4-npm-run-test-integration/post.yaml', 'playbooks/legacy/storyboard-webclient-nodejs4-npm-run-test-integration/run.yaml']",7,ab035b1db2aa6003e5f939b4ae6c55261750056c,zuul-npm,,"- hosts: all name: Autoconverted job legacy-storyboard-webclient-nodejs4-npm-run-test-integration from old job gate-storyboard-webclient-nodejs4-npm-run-test-integration tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x CLONEMAP=`mktemp` function cleanup { # In cases where zuul-cloner is aborted during a git # clone operation, git will remove the git work tree in # its cleanup. The work tree in these jobs is the # workspace directory, which means that subsequent # jenkins post-build actions can not run because the # workspace has been removed. # To reduce the likelihood of this having an impact, # recreate the workspace directory if needed mkdir -p $WORKSPACE rm -f $CLONEMAP } trap cleanup EXIT cat > $CLONEMAP << EOF clonemap: - name: $ZUUL_PROJECT dest: . EOF /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \ git://git.openstack.org $ZUUL_PROJECT executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: /usr/local/jenkins/slave_scripts/install-distro-packages.sh chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -u set -e set -x # Prerequisites sudo apt-get update sudo apt-get install -y apt-transport-https lsb-release curl DISTRO=$(lsb_release -c -s) # Install via nodesource curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | sudo apt-key add - echo ""deb https://deb.nodesource.com/node_4.x $DISTRO main"" | sudo tee /etc/apt/sources.list.d/nodesource.list echo ""deb-src https://deb.nodesource.com/node_4.x $DISTRO main"" | sudo tee -a /etc/apt/sources.list.d/nodesource.list sudo apt-get update sudo apt-get install -y nodejs # Output to the log for debugging sake. node --version npm --version executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | sudo apt-get update sudo apt-get install -y xvfb chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | sudo apt-get update sudo apt-get install -y chromium-browser chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | sudo apt-get update sudo apt-get install -y firefox dbus chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -x sudo rm -f /etc/sudoers.d/zuul # Prove that general sudo access is actually revoked ! sudo -n true executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | DIMENSIONS='1280x1024x24' /usr/bin/Xvfb :99 -screen 0 ${DIMENSIONS} -ac +extension GLX +render -noreset 2>&1 > /dev/null & chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -u set -e set -x export DISPLAY=:99 npm install --verbose # Try running as a standard lifecycle script, otherwise try custom. npm_lifecycle_phases=""publish install version test stop start restart pack"" if [[ $npm_lifecycle_phases =~ (^| )test-integration($| ) ]]; then npm test-integration --verbose else npm run test-integration --verbose fi # If no shrinkwrap exists, generate it. if [ ! -f ./npm-shrinkwrap.json ]; then npm prune # https://github.com/npm/npm/issues/6298 npm shrinkwrap fi executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | OUT=`git ls-files --other --exclude-standard --directory` if [ -z ""$OUT"" ]; then echo ""No extra files created during test."" exit 0 else echo ""The following un-ignored files were created during the test:"" echo ""$OUT"" exit 0 # TODO: change to 1 to fail tests. fi executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",0,630
openstack%2Fpython-neutronclient~master~I4a8f5c2d172ead3e2c40d2a8f5286aa60a73be72,openstack/python-neutronclient,master,I4a8f5c2d172ead3e2c40d2a8f5286aa60a73be72,Remove a workaround for osc-lib in FWaaS UT,MERGED,2017-12-15 19:45:28.000000000,2017-12-18 20:32:01.000000000,2017-12-18 20:32:01.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 6995}, {'_account_id': 11975}, {'_account_id': 13702}, {'_account_id': 17776}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 19:45:28.000000000', 'files': ['neutronclient/tests/unit/osc/v2/fwaas/test_firewallrule.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/7c01bdb8ba91f8baead830a0cd16fafa02d6124a', 'message': 'Remove a workaround for osc-lib in FWaaS UT\n\nThe issue was fixed in osc-lib 1.8.0 and the workaround in\nneutronclient UT is no longer needed. This commit drops it.\n\nChange-Id: I4a8f5c2d172ead3e2c40d2a8f5286aa60a73be72\nCloses-Bug: #1738430\n'}]",0,528381,7c01bdb8ba91f8baead830a0cd16fafa02d6124a,9,7,1,841,,,0,"Remove a workaround for osc-lib in FWaaS UT

The issue was fixed in osc-lib 1.8.0 and the workaround in
neutronclient UT is no longer needed. This commit drops it.

Change-Id: I4a8f5c2d172ead3e2c40d2a8f5286aa60a73be72
Closes-Bug: #1738430
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/81/528381/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/tests/unit/osc/v2/fwaas/test_firewallrule.py'],1,7c01bdb8ba91f8baead830a0cd16fafa02d6124a,bug/1738430,, # TODO(amotoki): This is required because of the logic of # osc_lib.utils.get_dict_properties(). # It needs to be fixed in osc-lib first. if val is None: return val,0,5
openstack%2Fopenstack-zuul-jobs~master~I5155ebffd3c7e8ec1f354b2afd6dfcb3986795fe,openstack/openstack-zuul-jobs,master,I5155ebffd3c7e8ec1f354b2afd6dfcb3986795fe,Update README for neutron-horizon-hack,MERGED,2017-12-16 18:36:02.000000000,2017-12-18 20:30:36.000000000,2017-12-18 20:30:36.000000000,"[{'_account_id': 2}, {'_account_id': 6854}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-16 18:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/614c24fc1e8c563b11d9976cd886864d72b1d409', 'message': ""Update README for neutron-horizon-hack\n\nLet's describe the API we need for tox_install.sh.\n\nChange-Id: I5155ebffd3c7e8ec1f354b2afd6dfcb3986795fe\n""}, {'number': 2, 'created': '2017-12-16 18:36:56.000000000', 'files': ['roles/neutron-horizon-hack/README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/64f521656c1f8063e2eacbc1939dae89974598ec', 'message': ""Update README for neutron-horizon-hack\n\nLet's describe the API we need for tox_install.sh.\n\nChange-Id: I5155ebffd3c7e8ec1f354b2afd6dfcb3986795fe\n""}]",0,528492,64f521656c1f8063e2eacbc1939dae89974598ec,9,4,2,6547,,,0,"Update README for neutron-horizon-hack

Let's describe the API we need for tox_install.sh.

Change-Id: I5155ebffd3c7e8ec1f354b2afd6dfcb3986795fe
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/92/528492/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/neutron-horizon-hack/README.rst'],1,614c24fc1e8c563b11d9976cd886864d72b1d409,updated-pti,"Note that this role only works if the file is called ``tools/tox_install.sh`` and takes three arguments ``constraints-file``, ``package`` and ``options``. The script must allow invocation with the single ``constraints-file`` argument as well. ",,6,0
openstack%2Fpuppet-tripleo~master~Id501931b7cb32463680cc861ab4e70230e2d98d1,openstack/puppet-tripleo,master,Id501931b7cb32463680cc861ab4e70230e2d98d1,correct unit tests,MERGED,2017-12-16 08:36:54.000000000,2017-12-18 20:30:35.000000000,2017-12-18 20:30:35.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-16 08:36:54.000000000', 'files': ['spec/defines/tripleo_haproxy_endpoint_spec.rb', 'spec/defines/tripleo_haproxy_service_endpoints_spec.rb', 'spec/defines/tripleo_firewall_service_rules_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/2f7d622b0a942d31290738ab60451f5c6f41d5d1', 'message': 'correct unit tests\n\nMoved to on_supported_os instead of hard-coded list\n\nChange-Id: Id501931b7cb32463680cc861ab4e70230e2d98d1\n'}]",0,528458,2f7d622b0a942d31290738ab60451f5c6f41d5d1,7,3,1,26828,,,0,"correct unit tests

Moved to on_supported_os instead of hard-coded list

Change-Id: Id501931b7cb32463680cc861ab4e70230e2d98d1
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/58/528458/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/defines/tripleo_haproxy_endpoint_spec.rb', 'spec/defines/tripleo_haproxy_service_endpoints_spec.rb', 'spec/defines/tripleo_firewall_service_rules_spec.rb']",3,2f7d622b0a942d31290738ab60451f5c6f41d5d1,rspec-on_supported_os," on_supported_os.each do |os, facts| context ""on #{os}"" do let(:facts) do facts.merge({}) end it_behaves_like 'tripleo firewall service rules'"," context 'on Debian platforms' do let :facts do { :osfamily => 'Debian', :hostname => 'myhost' } it_configures 'tripleo firewall service rules' end context 'on RedHat platforms' do let :facts do { :osfamily => 'RedHat', :hostname => 'myhost' } end it_configures 'tripleo firewall service rules'",21,45
openstack%2Fproject-config~master~I80bc50c4dc6c41c732051e57c78230a18c3673af,openstack/project-config,master,I80bc50c4dc6c41c732051e57c78230a18c3673af,"No longer consider ""jenkins"" votes when enqueuing",MERGED,2017-12-18 13:38:16.000000000,2017-12-18 20:27:42.000000000,2017-12-18 20:27:42.000000000,"[{'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 13:38:16.000000000', 'files': ['zuul.d/pipelines.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7a7c4eebe0f18a4367d560d38dad753a9657b214', 'message': 'No longer consider ""jenkins"" votes when enqueuing\n\nOur Gerrit no longer has any ""jenkins"" account verified votes on\nopen changes, so there is no reason to consider it in our pipeline\nconfiguration. Remove the reference and simplify configuration.\n\nChange-Id: I80bc50c4dc6c41c732051e57c78230a18c3673af\n'}]",0,528722,7a7c4eebe0f18a4367d560d38dad753a9657b214,8,4,1,5263,,,0,"No longer consider ""jenkins"" votes when enqueuing

Our Gerrit no longer has any ""jenkins"" account verified votes on
open changes, so there is no reason to consider it in our pipeline
configuration. Remove the reference and simplify configuration.

Change-Id: I80bc50c4dc6c41c732051e57c78230a18c3673af
",git fetch https://review.opendev.org/openstack/project-config refs/changes/22/528722/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/pipelines.yaml'],1,7a7c4eebe0f18a4367d560d38dad753a9657b214,zuulv3-jobs, username: zuul, username: ^(zuul|jenkins)$,1,1
openstack%2Fproject-config~master~I988f1de07911b6955dc93d2518ed836f6cfe30ca,openstack/project-config,master,I988f1de07911b6955dc93d2518ed836f6cfe30ca,networking-midonet: Remove some of legacy jobs,MERGED,2017-11-23 07:36:36.000000000,2017-12-18 20:27:40.000000000,2017-12-18 20:27:40.000000000,"[{'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-23 07:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1a20299c2bc51d662d6daa849c7c96a3f3100e39', 'message': 'networking-midonet: Remove some of legacy jobs\n\nRemove jobs which now have in-repo counterpart.\n\nRelated-Bug: #1728766\nDepends-On: I778ddb080cf1bdfffef52003632614dd43ae01ab\nChange-Id: I988f1de07911b6955dc93d2518ed836f6cfe30ca\n'}, {'number': 2, 'created': '2017-12-04 03:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/94804d0973cc9b327d8638f3478fe06a9fbe7ddb', 'message': 'networking-midonet: Remove some of legacy jobs\n\nRemove jobs which now have in-repo counterpart.\n\nRelated-Bug: #1728766\nDepends-On: I778ddb080cf1bdfffef52003632614dd43ae01ab\nChange-Id: I988f1de07911b6955dc93d2518ed836f6cfe30ca\n'}, {'number': 3, 'created': '2017-12-12 03:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8b0f1321c5d0410d7c6fa6cee03eed868d581c2c', 'message': 'networking-midonet: Remove some of legacy jobs\n\nRemove jobs which now have in-repo counterpart.\n\nRelated-Bug: #1728766\nDepends-On: I778ddb080cf1bdfffef52003632614dd43ae01ab\nChange-Id: I988f1de07911b6955dc93d2518ed836f6cfe30ca\n'}, {'number': 4, 'created': '2017-12-13 07:35:47.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cd02d859114c49e9524e155d45bf1bbcaa35a98f', 'message': 'networking-midonet: Remove some of legacy jobs\n\nRemove jobs which now have in-repo counterpart.\n\nRelated-Bug: #1728766\nDepends-On: I778ddb080cf1bdfffef52003632614dd43ae01ab\nChange-Id: I988f1de07911b6955dc93d2518ed836f6cfe30ca\n'}]",0,522465,cd02d859114c49e9524e155d45bf1bbcaa35a98f,14,3,4,6854,,,0,"networking-midonet: Remove some of legacy jobs

Remove jobs which now have in-repo counterpart.

Related-Bug: #1728766
Depends-On: I778ddb080cf1bdfffef52003632614dd43ae01ab
Change-Id: I988f1de07911b6955dc93d2518ed836f6cfe30ca
",git fetch https://review.opendev.org/openstack/project-config refs/changes/65/522465/4 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,1a20299c2bc51d662d6daa849c7c96a3f3100e39,bug/1728766,, - legacy-tempest-dsvm-networking-midonet-aio-v2: branches: ^stable/ocata$ irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-tempest-dsvm-networking-midonet-aio-v2-full: voting: false branches: ^stable/ocata irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-tempest-dsvm-networking-midonet-aio-ml2: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-tempest-dsvm-networking-midonet-aio-ml2-full: voting: false irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-tempest-dsvm-networking-midonet-aio-ml2-full-legacy: voting: false branches: ^(?!stable/(ocata|pike)).*$ irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-tempest-dsvm-networking-midonet-aio-ml2-centos-7: voting: false irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-tempest-dsvm-networking-midonet-aio-ml2-full-centos-7: voting: false irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-grenade-dsvm-networking-midonet-ml2: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-grenade-dsvm-networking-midonet-v2: branches: ^stable/pike$ irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-networking-midonet-rally-dsvm-ml2: irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^specs/.*$ - legacy-networking-midonet-rally-dsvm-v2: branches: ^stable/ocata irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^specs/.*$ - legacy-tempest-dsvm-networking-midonet-aio-v2: branches: ^stable/ocata$ irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-tempest-dsvm-networking-midonet-aio-ml2: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-grenade-dsvm-networking-midonet-ml2: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-grenade-dsvm-networking-midonet-v2: branches: ^stable/pike$ irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-networking-midonet-rally-dsvm-ml2: irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^specs/.*$ - legacy-networking-midonet-rally-dsvm-v2: branches: ^stable/ocata irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^specs/.*$ experimental: jobs: - legacy-tempest-dsvm-networking-midonet-multinode-ml2: voting: false irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$,0,152
openstack%2Fproject-config~master~I1a8b1be63f20c61ff2817e1202076cc9f177c8a1,openstack/project-config,master,I1a8b1be63f20c61ff2817e1202076cc9f177c8a1,Add requirements check to cinder-tempest-plugin repo,MERGED,2017-12-13 20:01:34.000000000,2017-12-18 20:25:47.000000000,2017-12-18 20:25:47.000000000,"[{'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 20:01:34.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/679df82bb6cbdde305c4693aa7a53f8c13cef6ac', 'message': 'Add requirements check to cinder-tempest-plugin repo\n\nAdding check-requirements to the Cinder tempest plugin repo\nin order to get requirements updates.\n\nChange-Id: I1a8b1be63f20c61ff2817e1202076cc9f177c8a1\n'}]",0,527774,679df82bb6cbdde305c4693aa7a53f8c13cef6ac,7,3,1,11904,,,0,"Add requirements check to cinder-tempest-plugin repo

Adding check-requirements to the Cinder tempest plugin repo
in order to get requirements updates.

Change-Id: I1a8b1be63f20c61ff2817e1202076cc9f177c8a1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/74/527774/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,679df82bb6cbdde305c4693aa7a53f8c13cef6ac,goal-split-tempest-plugin, - check-requirements,,1,0
openstack%2Fproject-config~master~Ia3a2b95abd9945f68e8e185a7a681e09b5a55d6b,openstack/project-config,master,Ia3a2b95abd9945f68e8e185a7a681e09b5a55d6b,publish sphinx-feature-class docs & use storyboard,MERGED,2017-12-08 21:37:17.000000000,2017-12-18 20:25:45.000000000,2017-12-18 20:25:45.000000000,"[{'_account_id': 170}, {'_account_id': 308}, {'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 10278}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-08 21:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f17adcca32358cb2ea64ff9fa92a35faffddea13', 'message': 'Build/publish sphinx-feature-classification docs\n\nChange-Id: Ia3a2b95abd9945f68e8e185a7a681e09b5a55d6b\n'}, {'number': 2, 'created': '2017-12-11 16:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/41a273104cc46649369f8b128db9fb1a6ac55a75', 'message': 'Build/publish sphinx-feature-classification docs\n\nChange-Id: Ia3a2b95abd9945f68e8e185a7a681e09b5a55d6b\n'}, {'number': 3, 'created': '2017-12-13 22:33:09.000000000', 'files': ['zuul.d/projects.yaml', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ab8b503ee88933d211ced6220b4720026de55bf1', 'message': 'publish sphinx-feature-class docs & use storyboard\n\nChange-Id: Ia3a2b95abd9945f68e8e185a7a681e09b5a55d6b\n'}]",3,526782,ab8b503ee88933d211ced6220b4720026de55bf1,15,6,3,170,,,0,"publish sphinx-feature-class docs & use storyboard

Change-Id: Ia3a2b95abd9945f68e8e185a7a681e09b5a55d6b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/82/526782/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,f17adcca32358cb2ea64ff9fa92a35faffddea13,support-matrix, - build-openstack-sphinx-docs post: jobs: - publish-openstack-sphinx-docs,,4,0
openstack%2Fproject-config~master~Ibddeacd8d04a063db8046c36226d96fed8273e4b,openstack/project-config,master,Ibddeacd8d04a063db8046c36226d96fed8273e4b,Publish Zun-tempest-plugin's documentation,MERGED,2017-12-14 07:42:41.000000000,2017-12-18 20:25:44.000000000,2017-12-18 20:25:43.000000000,"[{'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 22348}, {'_account_id': 22406}]","[{'number': 1, 'created': '2017-12-14 07:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3ad68864951ef55ce4be6fd6b705783887dff8e2', 'message': 'Add publish-docs template to Zun-tempest-plugin\n\nChange-Id: Ibddeacd8d04a063db8046c36226d96fed8273e4b\nCloses-Bug: #1738111\n'}, {'number': 2, 'created': '2017-12-14 07:49:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/68ddc1d08c996f5a8f6cf6d4802149581cb6eee2', 'message': ""Publish Zun-tempest-plugin's documentation\n\nChange-Id: Ibddeacd8d04a063db8046c36226d96fed8273e4b\nCloses-Bug: #1738111\n""}, {'number': 3, 'created': '2017-12-14 15:09:19.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/616382aaf0cb7bf32933966b46f8e48542b9211b', 'message': ""Publish Zun-tempest-plugin's documentation\n\n* Add template to publish documentation.\n* Add check-requirements as well\n\nChange-Id: Ibddeacd8d04a063db8046c36226d96fed8273e4b\nCloses-Bug: #1738111\n""}]",2,527886,616382aaf0cb7bf32933966b46f8e48542b9211b,14,6,3,22406,,,0,"Publish Zun-tempest-plugin's documentation

* Add template to publish documentation.
* Add check-requirements as well

Change-Id: Ibddeacd8d04a063db8046c36226d96fed8273e4b
Closes-Bug: #1738111
",git fetch https://review.opendev.org/openstack/project-config refs/changes/86/527886/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,3ad68864951ef55ce4be6fd6b705783887dff8e2,bug/1738111, - check-requirements - publish-openstack-sphinx-docs,,2,0
openstack%2Fqinling~master~Ia5ef99559044d5f8cd3803caba417e8def0872c8,openstack/qinling,master,Ia5ef99559044d5f8cd3803caba417e8def0872c8,Filter executions by status,MERGED,2017-12-18 10:27:24.000000000,2017-12-18 20:22:53.000000000,2017-12-18 20:22:53.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 10:27:24.000000000', 'files': ['qinling/tests/unit/api/controllers/v1/test_execution.py', 'qinling/api/controllers/v1/execution.py'], 'web_link': 'https://opendev.org/openstack/qinling/commit/96eb2a1416e407aaa659974375ec2a36b876de49', 'message': 'Filter executions by status\n\nPartially implements: blueprint qinling-execution-filter\n\nChange-Id: Ia5ef99559044d5f8cd3803caba417e8def0872c8\n'}]",0,528683,96eb2a1416e407aaa659974375ec2a36b876de49,6,2,1,6732,,,0,"Filter executions by status

Partially implements: blueprint qinling-execution-filter

Change-Id: Ia5ef99559044d5f8cd3803caba417e8def0872c8
",git fetch https://review.opendev.org/openstack/qinling refs/changes/83/528683/1 && git format-patch -1 --stdout FETCH_HEAD,"['qinling/tests/unit/api/controllers/v1/test_execution.py', 'qinling/api/controllers/v1/execution.py']",2,96eb2a1416e407aaa659974375ec2a36b876de49,bp/qinling-execution-filter," @wsme_pecan.wsexpose(resources.Executions, wtypes.text, bool, wtypes.text, wtypes.text) def get_all(self, function_id=None, all_projects=False, project_id=None, status=None): :param status: Optional. Filter by execution status. status=status,"," @wsme_pecan.wsexpose(resources.Executions, wtypes.text, bool, wtypes.text) def get_all(self, function_id=None, all_projects=False, project_id=None):",14,4
openstack%2Fproject-config~master~Ibdcadf7d7afb01c0ddcedad0fd4de75f15e68c09,openstack/project-config,master,Ibdcadf7d7afb01c0ddcedad0fd4de75f15e68c09,Adding jobs to new ec2api-tempest-plugin,MERGED,2017-12-09 14:50:26.000000000,2017-12-18 20:22:52.000000000,2017-12-18 20:22:52.000000000,"[{'_account_id': 6547}, {'_account_id': 8556}, {'_account_id': 9061}, {'_account_id': 12393}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-09 14:50:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7e149b646adb236b3b8a01635e0345011e0820c9', 'message': 'Adding jobs to new ec2api-tempest-plugin\n\nChange-Id: Ibdcadf7d7afb01c0ddcedad0fd4de75f15e68c09\nDepends-On: If8a2629b4802990b132dd00d572c8369580c85b1\n'}, {'number': 2, 'created': '2017-12-16 01:41:43.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0339ca3eb1aab886a50d9204518978d495d3390b', 'message': 'Adding jobs to new ec2api-tempest-plugin\n\nChange-Id: Ibdcadf7d7afb01c0ddcedad0fd4de75f15e68c09\nDepends-On: If8a2629b4802990b132dd00d572c8369580c85b1\n'}]",4,526854,0339ca3eb1aab886a50d9204518978d495d3390b,15,5,2,8556,,,0,"Adding jobs to new ec2api-tempest-plugin

Change-Id: Ibdcadf7d7afb01c0ddcedad0fd4de75f15e68c09
Depends-On: If8a2629b4802990b132dd00d572c8369580c85b1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/54/526854/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,7e149b646adb236b3b8a01635e0345011e0820c9,goal-split-tempest-plugins, name: openstack/ec2api-tempest-plugin templates: - system-required - openstack-python-jobs check: jobs: - openstack-tox-pep8 gate: jobs: - openstack-tox-pep8 - project:,,12,0
openstack%2Fproject-config~master~Ia8a9a1a61b442ec3bf34a4cd44a748f16f20bd09,openstack/project-config,master,Ia8a9a1a61b442ec3bf34a4cd44a748f16f20bd09,Added initial jobs for vitrage tempest plugin,MERGED,2017-12-09 11:51:28.000000000,2017-12-18 20:17:45.000000000,2017-12-18 20:17:45.000000000,"[{'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-09 11:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/18b3dbd9e4f099ac7f04daddb06bf62605e28c80', 'message': 'Added initial jobs for vitrage tempest plugin\n\nChange-Id: Ia8a9a1a61b442ec3bf34a4cd44a748f16f20bd09\n'}, {'number': 2, 'created': '2017-12-15 20:58:36.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/03d7751d0fd7107e08de7bca62943152711c1657', 'message': 'Added initial jobs for vitrage tempest plugin\n\nChange-Id: Ia8a9a1a61b442ec3bf34a4cd44a748f16f20bd09\n'}]",0,526837,03d7751d0fd7107e08de7bca62943152711c1657,14,3,2,12393,,,0,"Added initial jobs for vitrage tempest plugin

Change-Id: Ia8a9a1a61b442ec3bf34a4cd44a748f16f20bd09
",git fetch https://review.opendev.org/openstack/project-config refs/changes/37/526837/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,18b3dbd9e4f099ac7f04daddb06bf62605e28c80,vitrage-tempest-plugin, name: openstack/vitrage-tempest-plugin templates: - system-required check: jobs: - openstack-tox-pep8 gate: jobs: - openstack-tox-pep8 post: jobs: - publish-openstack-python-branch-tarball - project:,,14,0
openstack%2Fproject-config~master~I2aa8292cde1ccb737f840d96c8e8d8dd2341e72d,openstack/project-config,master,I2aa8292cde1ccb737f840d96c8e8d8dd2341e72d,add n8g-sfc as a required project for n8g-bagpipe,MERGED,2017-12-11 16:14:27.000000000,2017-12-18 20:17:43.000000000,2017-12-18 20:17:43.000000000,"[{'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 9061}, {'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 16:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/48d1364e2b7d87db767b52aa82533908d36dfc23', 'message': 'add n8g-sfc as a required project for n8g-bagpipe\n\nChange I44a0e56d83353975932b234f71a68921aa711fdcis introduces\ninto networking-bagpipe a driver for the networking-sfc project.\n\nHence networking-sfc becomes a ""required project"" for\nnetworking-bagpipe.\n\nChange-Id: I2aa8292cde1ccb737f840d96c8e8d8dd2341e72d\nNeeded-By: I44a0e56d83353975932b234f71a68921aa711fdc\n'}, {'number': 2, 'created': '2017-12-13 09:26:35.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b53d354d01c77e6c3b08fbec9ff5e8d98f35c576', 'message': 'add n8g-sfc as a required project for n8g-bagpipe\n\nChange I44a0e56d83353975932b234f71a68921aa711fdcis introduces\ninto networking-bagpipe a driver for the networking-sfc project.\n\nHence networking-sfc becomes a ""required project"" for\nnetworking-bagpipe.\n\nChange-Id: I2aa8292cde1ccb737f840d96c8e8d8dd2341e72d\nNeeded-By: I44a0e56d83353975932b234f71a68921aa711fdc\n'}]",2,527146,b53d354d01c77e6c3b08fbec9ff5e8d98f35c576,12,6,2,12021,,,0,"add n8g-sfc as a required project for n8g-bagpipe

Change I44a0e56d83353975932b234f71a68921aa711fdcis introduces
into networking-bagpipe a driver for the networking-sfc project.

Hence networking-sfc becomes a ""required project"" for
networking-bagpipe.

Change-Id: I2aa8292cde1ccb737f840d96c8e8d8dd2341e72d
Needed-By: I44a0e56d83353975932b234f71a68921aa711fdc
",git fetch https://review.opendev.org/openstack/project-config refs/changes/46/527146/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,48d1364e2b7d87db767b52aa82533908d36dfc23,n8g-bagpipe-sfc, - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc - openstack/networking-sfc,,16,0
openstack%2Fproject-config~master~I9cb78d3e99f2c00bef74d9bd63b9f1deedd089c3,openstack/project-config,master,I9cb78d3e99f2c00bef74d9bd63b9f1deedd089c3,Add releasenotes and docs job to congress-dashboard,MERGED,2017-12-18 09:29:26.000000000,2017-12-18 20:17:38.000000000,2017-12-18 20:17:38.000000000,"[{'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 09:29:26.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f5b9ee9c824b4966a5c9fa8e03c5e0c6b6b84a3b', 'message': 'Add releasenotes and docs job to congress-dashboard\n\nChange-Id: I9cb78d3e99f2c00bef74d9bd63b9f1deedd089c3\n'}]",0,528671,f5b9ee9c824b4966a5c9fa8e03c5e0c6b6b84a3b,7,3,1,11278,,,0,"Add releasenotes and docs job to congress-dashboard

Change-Id: I9cb78d3e99f2c00bef74d9bd63b9f1deedd089c3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/71/528671/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,f5b9ee9c824b4966a5c9fa8e03c5e0c6b6b84a3b,add-releasenotes-jobs, - release-notes-jobs - publish-openstack-sphinx-docs,,2,0
openstack%2Fproject-config~master~I662b991f25bb24ccdca46550acaa1bd7658eb2d2,openstack/project-config,master,I662b991f25bb24ccdca46550acaa1bd7658eb2d2,Add system-required jobs to congress-tempest-plugin,MERGED,2017-12-05 04:40:32.000000000,2017-12-18 20:17:36.000000000,2017-12-18 20:17:36.000000000,"[{'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 11278}, {'_account_id': 18591}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-05 04:40:32.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1ca96883e737d57bce8fcf1cc32c6a5a844348e4', 'message': 'Add system-required jobs to congress-tempest-plugin\n\nThis commit adds jobs to newly created project congress-tempest-plugin\n\nChange-Id: I662b991f25bb24ccdca46550acaa1bd7658eb2d2\n'}]",1,525421,1ca96883e737d57bce8fcf1cc32c6a5a844348e4,15,6,1,11278,,,0,"Add system-required jobs to congress-tempest-plugin

This commit adds jobs to newly created project congress-tempest-plugin

Change-Id: I662b991f25bb24ccdca46550acaa1bd7658eb2d2
",git fetch https://review.opendev.org/openstack/project-config refs/changes/21/525421/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,1ca96883e737d57bce8fcf1cc32c6a5a844348e4,add-jobs, name: openstack/congress-tempest-plugin templates: - system-required - openstack-python-jobs - openstack-python35-jobs - check-requirements - publish-to-pypi - project:,,9,0
openstack%2Fproject-config~master~Ib4c8dd783e1b27a5ae58d8d653ff9f4c77449ca6,openstack/project-config,master,Ib4c8dd783e1b27a5ae58d8d653ff9f4c77449ca6,Add initial jobs for trove tempest plugin,MERGED,2017-12-11 15:24:49.000000000,2017-12-18 20:13:53.000000000,2017-12-18 20:13:53.000000000,"[{'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 12393}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 15:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4fb56c0781d16610c6a3ad3b165fed15335e8dd3', 'message': 'Add initial jobs for trove tempest plugin\n\nChange-Id: Ib4c8dd783e1b27a5ae58d8d653ff9f4c77449ca6\n'}, {'number': 2, 'created': '2017-12-15 21:25:29.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4b099966f16c66fcb371053a41bf5e50093bdb13', 'message': 'Add initial jobs for trove tempest plugin\n\nChange-Id: Ib4c8dd783e1b27a5ae58d8d653ff9f4c77449ca6\n'}]",1,527123,4b099966f16c66fcb371053a41bf5e50093bdb13,22,4,2,12393,,,0,"Add initial jobs for trove tempest plugin

Change-Id: Ib4c8dd783e1b27a5ae58d8d653ff9f4c77449ca6
",git fetch https://review.opendev.org/openstack/project-config refs/changes/23/527123/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,4fb56c0781d16610c6a3ad3b165fed15335e8dd3,trove-tempest-plugin, name: openstack/trove-tempest-plugin templates: - system-required check: jobs: - openstack-tox-pep8 gate: jobs: - openstack-tox-pep8 post: jobs: - publish-openstack-python-branch-tarball - project:,,13,0
openstack%2Fproject-config~master~Ia6be703802d4f52a6078e205153ebafb06d7fe3a,openstack/project-config,master,Ia6be703802d4f52a6078e205153ebafb06d7fe3a,Added initial jobs for monasca tempest plugin,MERGED,2017-12-09 13:48:59.000000000,2017-12-18 20:10:20.000000000,2017-12-18 20:10:20.000000000,"[{'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 16222}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-09 13:48:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/fc9b0adfb70cfde6822880fa95de86c5712bd5d2', 'message': 'Added initial jobs for monasca tempest plugin\n\nChange-Id: Ia6be703802d4f52a6078e205153ebafb06d7fe3a\n'}, {'number': 2, 'created': '2017-12-17 07:00:32.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c681695b567f8a0bd90fa7cff6fe30796abf307a', 'message': 'Added initial jobs for monasca tempest plugin\n\nChange-Id: Ia6be703802d4f52a6078e205153ebafb06d7fe3a\n'}]",0,526847,c681695b567f8a0bd90fa7cff6fe30796abf307a,13,4,2,12393,,,0,"Added initial jobs for monasca tempest plugin

Change-Id: Ia6be703802d4f52a6078e205153ebafb06d7fe3a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/47/526847/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,fc9b0adfb70cfde6822880fa95de86c5712bd5d2,monasca-tempest-plugin, name: openstack/monasca-tempest-plugin templates: - system-required check: jobs: - openstack-tox-pep8 gate: jobs: - openstack-tox-pep8 post: jobs: - publish-openstack-python-branch-tarball - project:,,14,0
openstack%2Fvitrage~master~If04e25601d57ded4cb59a71ca34411609f05a758,openstack/vitrage,master,If04e25601d57ded4cb59a71ca34411609f05a758,dont run py27 and py35 in parallel,MERGED,2017-12-18 13:08:09.000000000,2017-12-18 20:08:27.000000000,2017-12-18 20:08:27.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 13:08:09.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/a6ede3f6bc584fee9b12a8b84ac9ffab01e38e34', 'message': 'dont run py27 and py35 in parallel\n\nwe have some issues with the db testing\nuse one worker until we fix it\n\nChange-Id: If04e25601d57ded4cb59a71ca34411609f05a758\n'}]",0,528711,a6ede3f6bc584fee9b12a8b84ac9ffab01e38e34,6,2,1,19134,,,0,"dont run py27 and py35 in parallel

we have some issues with the db testing
use one worker until we fix it

Change-Id: If04e25601d57ded4cb59a71ca34411609f05a758
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/11/528711/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a6ede3f6bc584fee9b12a8b84ac9ffab01e38e34,eyalb/tox, python setup.py testr --slowest --testr-args='--concurrency 1 {posargs}', python setup.py testr --slowest --testr-args='{posargs}',1,1
openstack%2Fvitrage~master~I1636181f4f0fc0adaf482ad95de7ea2631769263,openstack/vitrage,master,I1636181f4f0fc0adaf482ad95de7ea2631769263,call super for setUpClass,MERGED,2017-12-18 12:47:07.000000000,2017-12-18 20:08:27.000000000,2017-12-18 20:08:27.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 12:47:07.000000000', 'files': ['vitrage/tests/unit/notifier/snmp_notifier/test_snmp_sender_without_severity_map.py', 'vitrage/tests/unit/machine_learning/jaccard_correlation/test_jaccard_correlation.py', 'vitrage/tests/unit/entity_graph/test_transformer_manager.py', 'vitrage/tests/unit/datasources/static/test_static_driver.py', 'vitrage/tests/unit/datasources/zabbix/test_zabbix_configuration.py', 'vitrage/tests/unit/datasources/aodh/test_aodh_transformer.py', 'vitrage/tests/unit/datasources/zabbix/test_zabbix_transformer.py', 'vitrage/tests/unit/evaluator/recipes/test_add_causal_relationship_recipe.py', 'vitrage/tests/unit/evaluator/recipes/test_raise_alarm.py', 'vitrage/tests/functional/evaluator/test_scenario_evaluator.py', 'vitrage/tests/unit/evaluator/template_validation/test_def_template_syntax_validator.py', 'vitrage/tests/unit/datasources/static/test_static_transformer.py', 'vitrage/tests/unit/datasources/ceilometer/test_ceilometer_transformer.py', 'vitrage/tests/unit/datasources/nova/test_nova_host_transformer.py', 'vitrage/tests/unit/datasources/aodh/test_aodh_driver.py', 'vitrage/tests/unit/datasources/consistency/test_consistency_transformer.py', 'vitrage/tests/unit/datasources/heat/test_heat_stack_transformer.py', 'vitrage/tests/unit/datasources/nagios/test_nagios_driver.py', 'vitrage/tests/unit/evaluator/test_scenario_repository.py', 'vitrage/tests/unit/evaluator/template_validation/test_template_syntax_validator.py', 'vitrage/tests/unit/datasources/ceilometer/test_ceilometer_driver.py', 'vitrage/tests/unit/evaluator/recipes/test_set_state_recipe.py', 'vitrage/tests/unit/notifier/snmp_notifier/test_snmp_sender_with_severity_map.py', 'vitrage/tests/unit/notifier/snmp_notifier/test_snmp_notifier.py', 'vitrage/tests/unit/evaluator/recipes/test_mark_down.py', 'vitrage/tests/unit/evaluator/template_validation/content/test_template_content_validator.py', 'vitrage/tests/unit/datasources/collectd/test_collectd_driver.py', 'vitrage/tests/unit/datasources/static_physical/test_static_physical_transformer.py', 'vitrage/tests/functional/evaluator/test_action_executor.py', 'vitrage/tests/unit/datasources/nagios/test_nagios_transformer.py', 'vitrage/tests/unit/graph/test_graph_algo.py', 'vitrage/tests/unit/datasources/nova/test_nova_zone_transformer.py', 'vitrage/tests/unit/datasources/test_datasource_update_method.py', 'vitrage/tests/unit/datasources/zabbix/test_zabbix_driver.py', 'vitrage/tests/unit/evaluator/template_validation/content/base.py', 'vitrage/tests/unit/evaluator/recipes/test_execute_mistral.py', 'vitrage/tests/unit/datasources/nagios/test_nagios_config.py', 'vitrage/tests/unit/datasources/static_physical/test_static_physical_driver.py', 'vitrage/tests/unit/datasources/cinder/test_cinder_volume_transformer.py', 'vitrage/tests/unit/datasources/nova/test_nova_instance_transformer.py', 'vitrage/tests/unit/datasources/collectd/test_collectd_transformer.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/17a03d12548477f9879ee0f1e70f542ef0a8cd09', 'message': 'call super for setUpClass\n\nChange-Id: I1636181f4f0fc0adaf482ad95de7ea2631769263\n'}]",0,528702,17a03d12548477f9879ee0f1e70f542ef0a8cd09,8,2,1,19134,,,0,"call super for setUpClass

Change-Id: I1636181f4f0fc0adaf482ad95de7ea2631769263
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/02/528702/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/tests/unit/notifier/snmp_notifier/test_snmp_sender_without_severity_map.py', 'vitrage/tests/unit/machine_learning/jaccard_correlation/test_jaccard_correlation.py', 'vitrage/tests/unit/entity_graph/test_transformer_manager.py', 'vitrage/tests/unit/datasources/static/test_static_driver.py', 'vitrage/tests/unit/datasources/zabbix/test_zabbix_configuration.py', 'vitrage/tests/unit/datasources/aodh/test_aodh_transformer.py', 'vitrage/tests/unit/datasources/zabbix/test_zabbix_transformer.py', 'vitrage/tests/unit/evaluator/recipes/test_add_causal_relationship_recipe.py', 'vitrage/tests/unit/evaluator/recipes/test_raise_alarm.py', 'vitrage/tests/functional/evaluator/test_scenario_evaluator.py', 'vitrage/tests/unit/evaluator/template_validation/test_def_template_syntax_validator.py', 'vitrage/tests/unit/datasources/static/test_static_transformer.py', 'vitrage/tests/unit/datasources/ceilometer/test_ceilometer_transformer.py', 'vitrage/tests/unit/datasources/nova/test_nova_host_transformer.py', 'vitrage/tests/unit/datasources/aodh/test_aodh_driver.py', 'vitrage/tests/unit/datasources/consistency/test_consistency_transformer.py', 'vitrage/tests/unit/datasources/heat/test_heat_stack_transformer.py', 'vitrage/tests/unit/datasources/nagios/test_nagios_driver.py', 'vitrage/tests/unit/evaluator/test_scenario_repository.py', 'vitrage/tests/unit/evaluator/template_validation/test_template_syntax_validator.py', 'vitrage/tests/unit/datasources/ceilometer/test_ceilometer_driver.py', 'vitrage/tests/unit/evaluator/recipes/test_set_state_recipe.py', 'vitrage/tests/unit/notifier/snmp_notifier/test_snmp_sender_with_severity_map.py', 'vitrage/tests/unit/notifier/snmp_notifier/test_snmp_notifier.py', 'vitrage/tests/unit/evaluator/recipes/test_mark_down.py', 'vitrage/tests/unit/evaluator/template_validation/content/test_template_content_validator.py', 'vitrage/tests/unit/datasources/collectd/test_collectd_driver.py', 'vitrage/tests/unit/datasources/static_physical/test_static_physical_transformer.py', 'vitrage/tests/functional/evaluator/test_action_executor.py', 'vitrage/tests/unit/datasources/nagios/test_nagios_transformer.py', 'vitrage/tests/unit/graph/test_graph_algo.py', 'vitrage/tests/unit/datasources/nova/test_nova_zone_transformer.py', 'vitrage/tests/unit/datasources/test_datasource_update_method.py', 'vitrage/tests/unit/datasources/zabbix/test_zabbix_driver.py', 'vitrage/tests/unit/evaluator/template_validation/content/base.py', 'vitrage/tests/unit/evaluator/recipes/test_execute_mistral.py', 'vitrage/tests/unit/datasources/nagios/test_nagios_config.py', 'vitrage/tests/unit/datasources/static_physical/test_static_physical_driver.py', 'vitrage/tests/unit/datasources/cinder/test_cinder_volume_transformer.py', 'vitrage/tests/unit/datasources/nova/test_nova_instance_transformer.py', 'vitrage/tests/unit/datasources/collectd/test_collectd_transformer.py']",41,17a03d12548477f9879ee0f1e70f542ef0a8cd09,eyalb/tests," super(TestCollectdTransformer, cls).setUpClass()",,52,7
openstack%2Foctavia-tempest-plugin~master~I3c4d01042839690a723423643776bc6684a93ba9,openstack/octavia-tempest-plugin,master,I3c4d01042839690a723423643776bc6684a93ba9,Disable more services from the scenario jobs,MERGED,2017-12-18 17:57:14.000000000,2017-12-18 20:02:46.000000000,2017-12-18 20:02:46.000000000,"[{'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 17:57:14.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/a268ca72fa6f45e988282ec99669a6b2a98d7dec', 'message': 'Disable more services from the scenario jobs\n\nThere are more services enabled by default for our scenario jobs than we need.\nThis patch disables more of cinder, ceilometer, and swift\n\nChange-Id: I3c4d01042839690a723423643776bc6684a93ba9\n'}]",0,528776,a268ca72fa6f45e988282ec99669a6b2a98d7dec,7,3,1,11628,,,0,"Disable more services from the scenario jobs

There are more services enabled by default for our scenario jobs than we need.
This patch disables more of cinder, ceilometer, and swift

Change-Id: I3c4d01042839690a723423643776bc6684a93ba9
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/76/528776/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,a268ca72fa6f45e988282ec99669a6b2a98d7dec,, c-bak: false ceilometer-acentral: false ceilometer-acompute: false ceilometer-alarm-evaluator: false ceilometer-alarm-notifier: false ceilometer-anotification: false ceilometer-api: false ceilometer-collector: false cinder: false s-account: false s-container: false s-object: false s-proxy: false,,13,0
openstack%2Fpuppet-tripleo~master~Ia5eeaa60392815c921afd3985687379bb433c2b2,openstack/puppet-tripleo,master,Ia5eeaa60392815c921afd3985687379bb433c2b2,Fix up spec class for haproxy,MERGED,2017-12-18 16:03:41.000000000,2017-12-18 19:54:19.000000000,2017-12-18 19:54:19.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 16:03:41.000000000', 'files': ['spec/classes/tripleo_haproxy_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/96d608a3d679d23f01dac06d2268b81e3b1fab23', 'message': 'Fix up spec class for haproxy\n\nLet\'s kill the following warning due to unneeded duplicate keys:\nspec/classes/tripleo_haproxy_spec.rb:50: warning: key ""timeout client"" is duplicated and overwritten on line 53\nspec/classes/tripleo_haproxy_spec.rb:51: warning: key ""timeout server"" is duplicated and overwritten on line 54\n\nChange-Id: Ia5eeaa60392815c921afd3985687379bb433c2b2\n'}]",0,528747,96d608a3d679d23f01dac06d2268b81e3b1fab23,7,3,1,20172,,,0,"Fix up spec class for haproxy

Let's kill the following warning due to unneeded duplicate keys:
spec/classes/tripleo_haproxy_spec.rb:50: warning: key ""timeout client"" is duplicated and overwritten on line 53
spec/classes/tripleo_haproxy_spec.rb:51: warning: key ""timeout server"" is duplicated and overwritten on line 54

Change-Id: Ia5eeaa60392815c921afd3985687379bb433c2b2
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/47/528747/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/tripleo_haproxy_spec.rb'],1,96d608a3d679d23f01dac06d2268b81e3b1fab23,spec-fix,," 'timeout client' => ""90m"", 'timeout server' => ""90m"",",0,2
openstack%2Fneutron~master~Ic5258dc3fa14ded257dd95fe3417fa03aefa7372,openstack/neutron,master,Ic5258dc3fa14ded257dd95fe3417fa03aefa7372,DNM: testing neutron-plugin-repo unstable_test(),ABANDONED,2017-12-14 16:18:17.000000000,2017-12-18 19:43:35.000000000,,"[{'_account_id': 9845}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-14 16:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e0680c4b50b7e5b10a0c9b902a34102f4378e090', 'message': 'DNM: testing neutron-plugin-repo unstable_test()\n\nChange-Id: Ic5258dc3fa14ded257dd95fe3417fa03aefa7372\nDepends-on: I1aee29dfb59e9769ec0f1cb1f5d2933bc5dc0dc5\n'}, {'number': 2, 'created': '2017-12-14 18:16:09.000000000', 'files': ['neutron/tests/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4c8b96042633f7c749a5c24f9a4c5472afc8039', 'message': 'DNM: testing neutron-plugin-repo unstable_test()\n\nChange-Id: Ic5258dc3fa14ded257dd95fe3417fa03aefa7372\nDepends-on: I15fcdcba681d40c96f9f79aaa21881bc45fe3066\n'}]",0,528005,e4c8b96042633f7c749a5c24f9a4c5472afc8039,7,2,2,1131,,,0,"DNM: testing neutron-plugin-repo unstable_test()

Change-Id: Ic5258dc3fa14ded257dd95fe3417fa03aefa7372
Depends-on: I15fcdcba681d40c96f9f79aaa21881bc45fe3066
",git fetch https://review.opendev.org/openstack/neutron refs/changes/05/528005/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/base.py'],1,e0680c4b50b7e5b10a0c9b902a34102f4378e090,test-neutron-plugin-skip-unstable,# TEST,,1,0
openstack%2Fopenstack-ansible-os_cinder~master~I7abc8a06b3a7fd18cb4ae9c739a8ad0d252ae460,openstack/openstack-ansible-os_cinder,master,I7abc8a06b3a7fd18cb4ae9c739a8ad0d252ae460,Update static files,MERGED,2017-12-07 08:11:41.000000000,2017-12-18 19:41:26.000000000,2017-12-18 19:41:26.000000000,"[{'_account_id': 6816}, {'_account_id': 14805}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 08:11:41.000000000', 'files': ['files/rootwrap.d/volume.filters', 'templates/policy.json.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/647dbe8cc8ebaaabd451d9545e99f5f1b178007f', 'message': 'Update static files\n\nThis patch updates the role static files in tree\n\nChange-Id: I7abc8a06b3a7fd18cb4ae9c739a8ad0d252ae460\n'}]",0,526305,647dbe8cc8ebaaabd451d9545e99f5f1b178007f,16,4,1,17068,,,0,"Update static files

This patch updates the role static files in tree

Change-Id: I7abc8a06b3a7fd18cb4ae9c739a8ad0d252ae460
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/05/526305/1 && git format-patch -1 --stdout FETCH_HEAD,"['files/rootwrap.d/volume.filters', 'templates/policy.json.j2']",2,647dbe8cc8ebaaabd451d9545e99f5f1b178007f,osa_release," ""consistencygroup:get_all_cgsnapshots"": ""group:nobody"""," ""volume:create"": """", ""volume:create_from_image"": """", ""volume:delete"": ""rule:admin_or_owner"", ""volume:force_delete"": ""rule:admin_api"", ""volume:get"": ""rule:admin_or_owner"", ""volume:get_all"": ""rule:admin_or_owner"", ""volume:get_volume_metadata"": ""rule:admin_or_owner"", ""volume:create_volume_metadata"": ""rule:admin_or_owner"", ""volume:delete_volume_metadata"": ""rule:admin_or_owner"", ""volume:update_volume_metadata"": ""rule:admin_or_owner"", ""volume:get_volume_admin_metadata"": ""rule:admin_api"", ""volume:update_volume_admin_metadata"": ""rule:admin_api"", ""volume:extend"": ""rule:admin_or_owner"", ""volume:extend_attached_volume"": ""rule:admin_or_owner"", ""volume:update_readonly_flag"": ""rule:admin_or_owner"", ""volume:retype"": ""rule:admin_or_owner"", ""volume:update"": ""rule:admin_or_owner"", ""volume:revert_to_snapshot"": ""rule:admin_or_owner"", ""volume_extension:types_manage"": ""rule:admin_api"", ""volume_extension:types_extra_specs:create"": ""rule:admin_api"", ""volume_extension:types_extra_specs:delete"": ""rule:admin_api"", ""volume_extension:types_extra_specs:index"": ""rule:admin_api"", ""volume_extension:types_extra_specs:show"": ""rule:admin_api"", ""volume_extension:types_extra_specs:update"": ""rule:admin_api"", ""volume_extension:access_types_qos_specs_id"": ""rule:admin_api"", ""volume_extension:access_types_extra_specs"": ""rule:admin_api"", ""volume_extension:volume_type_access"": ""rule:admin_or_owner"", ""volume_extension:volume_type_access:addProjectAccess"": ""rule:admin_api"", ""volume_extension:volume_type_access:removeProjectAccess"": ""rule:admin_api"", ""volume_extension:volume_type_encryption"": ""rule:admin_api"", ""volume_extension:volume_encryption_metadata"": ""rule:admin_or_owner"", ""volume_extension:volume_image_metadata"": ""rule:admin_or_owner"", ""volume_extension:qos_specs_manage:create"": ""rule:admin_api"", ""volume_extension:qos_specs_manage:get"": ""rule:admin_api"", ""volume_extension:qos_specs_manage:get_all"": ""rule:admin_api"", ""volume_extension:qos_specs_manage:update"": ""rule:admin_api"", ""volume_extension:qos_specs_manage:delete"": ""rule:admin_api"", ""volume_extension:quotas:show"": """", ""volume_extension:quotas:update"": ""rule:admin_api"", ""volume_extension:quotas:delete"": ""rule:admin_api"", ""volume_extension:quota_classes"": ""rule:admin_api"", ""volume_extension:quota_classes:validate_setup_for_nested_quota_use"": ""rule:admin_api"", ""volume_extension:volume_admin_actions:reset_status"": ""rule:admin_api"", ""volume_extension:volume_admin_actions:force_delete"": ""rule:admin_api"", ""volume_extension:volume_admin_actions:force_detach"": ""rule:admin_api"", ""volume_extension:backup_admin_actions:force_delete"": ""rule:admin_api"", ""volume_extension:volume_admin_actions:migrate_volume"": ""rule:admin_api"", ""volume_extension:volume_admin_actions:migrate_volume_completion"": ""rule:admin_api"", ""volume_extension:volume_actions:upload_public"": ""rule:admin_api"", ""volume_extension:volume_actions:upload_image"": ""rule:admin_or_owner"", ""volume_extension:volume_host_attribute"": ""rule:admin_api"", ""volume_extension:volume_tenant_attribute"": ""rule:admin_or_owner"", ""volume_extension:volume_mig_status_attribute"": ""rule:admin_api"", ""volume_extension:hosts"": ""rule:admin_api"", ""volume_extension:services:index"": ""rule:admin_api"", ""volume_extension:services:update"" : ""rule:admin_api"", ""volume_extension:volume_manage"": ""rule:admin_api"", ""volume_extension:volume_unmanage"": ""rule:admin_api"", ""volume_extension:list_manageable"": ""rule:admin_api"", ""volume_extension:capabilities"": ""rule:admin_api"", ""volume:create_transfer"": ""rule:admin_or_owner"", ""volume:accept_transfer"": """", ""volume:delete_transfer"": ""rule:admin_or_owner"", ""volume:get_transfer"": ""rule:admin_or_owner"", ""volume:get_all_transfers"": ""rule:admin_or_owner"", ""volume:failover_host"": ""rule:admin_api"", ""volume:freeze_host"": ""rule:admin_api"", ""volume:thaw_host"": ""rule:admin_api"", ""consistencygroup:get_all_cgsnapshots"": ""group:nobody"", ""group:group_types_manage"": ""rule:admin_api"", ""group:group_types_specs"": ""rule:admin_api"", ""group:access_group_types_specs"": ""rule:admin_api"", ""group:group_type_access"": ""rule:admin_or_owner"", ""group:create"" : """", ""group:delete"": ""rule:admin_or_owner"", ""group:update"": ""rule:admin_or_owner"", ""group:get"": ""rule:admin_or_owner"", ""group:get_all"": ""rule:admin_or_owner"", ""group:create_group_snapshot"": """", ""group:delete_group_snapshot"": ""rule:admin_or_owner"", ""group:update_group_snapshot"": ""rule:admin_or_owner"", ""group:get_group_snapshot"": ""rule:admin_or_owner"", ""group:get_all_group_snapshots"": ""rule:admin_or_owner"", ""group:reset_group_snapshot_status"":""rule:admin_api"", ""group:reset_status"":""rule:admin_api"", ""group:enable_replication"": ""rule:admin_or_owner"", ""group:disable_replication"": ""rule:admin_or_owner"", ""group:failover_replication"": ""rule:admin_or_owner"", ""group:list_replication_targets"": ""rule:admin_or_owner"", ""scheduler_extension:scheduler_stats:get_pools"" : ""rule:admin_api"",",2,105
openstack%2Fopenstack-ansible-os_cinder~master~Ibb2b4036b488d5f2b53cb5ee146c9c38f4c188ae,openstack/openstack-ansible-os_cinder,master,Ibb2b4036b488d5f2b53cb5ee146c9c38f4c188ae,Allow the experimental trigger of the integrated repo,MERGED,2017-12-06 08:21:57.000000000,2017-12-18 19:41:25.000000000,2017-12-18 19:41:25.000000000,"[{'_account_id': 6816}, {'_account_id': 13095}, {'_account_id': 14805}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-06 08:21:57.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/b589084500269f44f98a905112a2fc84595e44f6', 'message': 'Allow the experimental trigger of the integrated repo\n\nThis would allow someone to test its change with an AIO.\n\nChange-Id: Ibb2b4036b488d5f2b53cb5ee146c9c38f4c188ae\n'}]",0,525951,b589084500269f44f98a905112a2fc84595e44f6,20,5,1,17068,,,0,"Allow the experimental trigger of the integrated repo

This would allow someone to test its change with an AIO.

Change-Id: Ibb2b4036b488d5f2b53cb5ee146c9c38f4c188ae
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/51/525951/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,b589084500269f44f98a905112a2fc84595e44f6,test_with_integrated_repo, experimental: jobs: - openstack-ansible-integrated-deploy-aio,,3,0
openstack%2Fpatrole~master~Ia9e748c1733abd8abdb73c50491ff2f1198e3193,openstack/patrole,master,Ia9e748c1733abd8abdb73c50491ff2f1198e3193,Adding 'reset_group_status' rbac test,MERGED,2017-12-08 05:44:04.000000000,2017-12-18 19:38:44.000000000,2017-12-18 19:38:44.000000000,"[{'_account_id': 8556}, {'_account_id': 17896}, {'_account_id': 22348}, {'_account_id': 23185}, {'_account_id': 23186}, {'_account_id': 25571}, {'_account_id': 25695}]","[{'number': 1, 'created': '2017-12-08 05:44:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/84b05f84034c0ed67a8fe449b1fc07104c0aa901', 'message': ""Adding Missing rbac test for Volume\n\nThis PS adds 'reset_group_status' test for policy[0],\nAPI ref is available here[1]\n\n[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/group_actions.py#L42\n[1]https://developer.openstack.org/api-ref/block-storage/v3/#reset-group-status\n\nChange-Id: Ia9e748c1733abd8abdb73c50491ff2f1198e3193\n""}, {'number': 2, 'created': '2017-12-08 06:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/2fd3c30bb2b1a968c7816c825b5e22b37b2d2be8', 'message': ""Adding 'reset_group_status' rbac test\n\nThis PS adds 'reset_group_status' test for policy[0],\nAPI ref is available here[1]\n\n[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/group_actions.py#L42\n[1]https://developer.openstack.org/api-ref/block-storage/v3/#reset-group-status\n\nCloses-Bug: #1718527\n\nChange-Id: Ia9e748c1733abd8abdb73c50491ff2f1198e3193\n""}, {'number': 3, 'created': '2017-12-12 10:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/c7bf9331187f36958ce16bb3081eb55911bcea32', 'message': ""Adding 'reset_group_status' rbac test\n\nThis PS adds 'reset_group_status' test for policy[0],\nAPI ref is available here[1]\n\n[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/group_actions.py#L42\n[1]https://developer.openstack.org/api-ref/block-storage/v3/#reset-group-status\n\nCloses-Bug: #1718527\n\nChange-Id: Ia9e748c1733abd8abdb73c50491ff2f1198e3193\n""}, {'number': 4, 'created': '2017-12-13 07:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/bed248d34a7d160ce5ffc82e1ff6e8f6fe077113', 'message': ""Adding 'reset_group_status' rbac test\n\nThis PS adds 'reset_group_status' test for policy[0],\nAPI ref is available here[1]\n\n[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/group_actions.py#L42\n[1]https://developer.openstack.org/api-ref/block-storage/v3/#reset-group-status\n\nCloses-Bug: #1718527\n\nChange-Id: Ia9e748c1733abd8abdb73c50491ff2f1198e3193\n""}, {'number': 5, 'created': '2017-12-14 03:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/9d369a14eb4f48cb3e1dee4aef580b783c36790c', 'message': ""Adding 'reset_group_status' rbac test\n\nThis PS adds 'reset_group_status' test for policy[0],\nAPI ref is available here[1]\n\n[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/group_actions.py#L42\n[1]https://developer.openstack.org/api-ref/block-storage/v3/#reset-group-status\n\nCloses-Bug: #1718527\n\nChange-Id: Ia9e748c1733abd8abdb73c50491ff2f1198e3193\n""}, {'number': 6, 'created': '2017-12-14 21:20:30.000000000', 'files': ['patrole_tempest_plugin/tests/api/volume/test_groups_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/0085d324cd76edc59dfe857293b5da9adeb2039a', 'message': ""Adding 'reset_group_status' rbac test\n\nThis PS adds 'reset_group_status' test for policy[0],\nAPI ref is available here[1]\n\n[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/group_actions.py#L42\n[1]https://developer.openstack.org/api-ref/block-storage/v3/#reset-group-status\n\nCloses-Bug: #1718527\n\nChange-Id: Ia9e748c1733abd8abdb73c50491ff2f1198e3193\nDepends-On: If123e20b10614e8e31ecaecf74e4beda6b575e40\n""}]",9,526596,0085d324cd76edc59dfe857293b5da9adeb2039a,32,7,6,25571,,,0,"Adding 'reset_group_status' rbac test

This PS adds 'reset_group_status' test for policy[0],
API ref is available here[1]

[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/group_actions.py#L42
[1]https://developer.openstack.org/api-ref/block-storage/v3/#reset-group-status

Closes-Bug: #1718527

Change-Id: Ia9e748c1733abd8abdb73c50491ff2f1198e3193
Depends-On: If123e20b10614e8e31ecaecf74e4beda6b575e40
",git fetch https://review.opendev.org/openstack/patrole refs/changes/96/526596/5 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/volume/test_groups_rbac.py'],1,84b05f84034c0ed67a8fe449b1fc07104c0aa901,reset_status,"class GroupsV320RbacTest(rbac_base.BaseVolumeRbacTest): _api_version = 3 min_microversion = '3.20' max_microversion = 'latest' def setUp(self): super(GroupsV320RbacTest, self).setUp() self.volume_type_id = self.create_volume_type()['id'] self.group_type_id = self.create_group_type()['id'] def _create_group(self, name=None, ignore_notfound=False, **kwargs): group_name = name or data_utils.rand_name( self.__class__.__name__ + '-Group') group = self.groups_client.create_group(name=group_name, **kwargs)[ 'group'] waiters.wait_for_volume_resource_status( self.groups_client, group['id'], 'available') if ignore_notfound: self.addCleanup(test_utils.call_and_ignore_notfound_exc, self._delete_group, group['id']) else: self.addCleanup(self._delete_group, group['id']) return group def _delete_group(self, group_id, delete_volumes=True): self.groups_client.delete_group(group_id, delete_volumes) self.groups_client.wait_for_resource_deletion(group_id) @decorators.idempotent_id('b849c1d4-3215-4f9d-b1e6-0aeb4b2b65ac') @rbac_rule_validation.action( service=""cinder"", rule=""group:reset_status"") def test_reset_group_status(self): group = self._create_group(ignore_notfound=True, group_type=self.group_type_id, volume_types=[self.volume_type_id]) status = 'available' self.rbac_utils.switch_role(self, toggle_rbac_role=True) self.groups_client.reset_group_status(group['id'], status) ",,44,0
openstack%2Fneutron-dynamic-routing~master~Ie7118a089e2c3fe058f90bd8d1e5a979ed9bf105,openstack/neutron-dynamic-routing,master,Ie7118a089e2c3fe058f90bd8d1e5a979ed9bf105,Address breakage from upstream change,MERGED,2017-12-17 09:17:42.000000000,2017-12-18 19:31:15.000000000,2017-12-18 19:31:15.000000000,"[{'_account_id': 1653}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 25618}]","[{'number': 1, 'created': '2017-12-17 09:17:42.000000000', 'files': ['neutron_dynamic_routing/tests/unit/db/test_bgp_db.py'], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/db343c12b1741cca1b5f6f279eb323c0fd8b6418', 'message': 'Address breakage from upstream change\n\nCommit 088e317cd2dd8488feb29a4fa6600227d1810479 broke the plugin.\nThis addresses that change.\n\nChange-Id: Ie7118a089e2c3fe058f90bd8d1e5a979ed9bf105\n'}]",3,528536,db343c12b1741cca1b5f6f279eb323c0fd8b6418,11,4,1,1653,,,0,"Address breakage from upstream change

Commit 088e317cd2dd8488feb29a4fa6600227d1810479 broke the plugin.
This addresses that change.

Change-Id: Ie7118a089e2c3fe058f90bd8d1e5a979ed9bf105
",git fetch https://review.opendev.org/openstack/neutron-dynamic-routing refs/changes/36/528536/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_dynamic_routing/tests/unit/db/test_bgp_db.py'],1,db343c12b1741cca1b5f6f279eb323c0fd8b6418,subnet-id," 'subnet_id': None, 'floating_ip_address': None, 'subnet_id': None, 'floating_ip_address': None, 'subnet_id': None, 'floating_ip_address': None, 'subnet_id': None, 'floating_ip_address': None, 'subnet_id': None, 'floating_ip_address': None, 'subnet_id': None, 'floating_ip_address': None, 'subnet_id': None, 'floating_ip_address': None, 'subnet_id': None, 'floating_ip_address': None,",,16,0
openstack%2Fmistral~master~Id773b4cd6ae2754365ba36e0e9773b3e705b7b87,openstack/mistral,master,Id773b4cd6ae2754365ba36e0e9773b3e705b7b87,Added cache options to the config file,ABANDONED,2017-12-18 19:14:51.000000000,2017-12-18 19:15:43.000000000,,[],"[{'number': 1, 'created': '2017-12-18 19:14:51.000000000', 'files': ['mistral/config.py', 'mistral/lang/parser.py', 'mistral/workflow/lookup_utils.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/a62973443a5da088b0f0333793bcb72a3069579f', 'message': 'Added cache options to the config file\n\nChange-Id: Id773b4cd6ae2754365ba36e0e9773b3e705b7b87\nSigned-off-by: Vitalii Solodilov <mcdkr@yandex.ru>\n'}]",0,528793,a62973443a5da088b0f0333793bcb72a3069579f,2,0,1,27008,,,0,"Added cache options to the config file

Change-Id: Id773b4cd6ae2754365ba36e0e9773b3e705b7b87
Signed-off-by: Vitalii Solodilov <mcdkr@yandex.ru>
",git fetch https://review.opendev.org/openstack/mistral refs/changes/93/528793/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/config.py', 'mistral/lang/parser.py', 'mistral/workflow/lookup_utils.py']",3,a62973443a5da088b0f0333793bcb72a3069579f,fix/configurable_cache,"from oslo_config import cfg CONF = cfg.CONF return cachetools.LRUCache(maxsize=CONF.engine.wf_ex_cache) maxsize=CONF.engine.tasks_cache,"," return cachetools.LRUCache(maxsize=500) maxsize=100,",32,6
openstack%2Fdesignate~master~Id6ee251e7fd3ba260543aa9beaf37415b0891028,openstack/designate,master,Id6ee251e7fd3ba260543aa9beaf37415b0891028,Updated from global requirements,MERGED,2017-12-15 21:24:52.000000000,2017-12-18 19:13:21.000000000,2017-12-18 19:13:21.000000000,"[{'_account_id': 8099}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 21:24:52.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/designate/commit/5eb58b941e1aabdcd9dba92a19583d8a0cdaaad9', 'message': 'Updated from global requirements\n\nChange-Id: Id6ee251e7fd3ba260543aa9beaf37415b0891028\n'}]",0,528398,5eb58b941e1aabdcd9dba92a19583d8a0cdaaad9,10,2,1,11131,,,0,"Updated from global requirements

Change-Id: Id6ee251e7fd3ba260543aa9beaf37415b0891028
",git fetch https://review.opendev.org/openstack/designate refs/changes/98/528398/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5eb58b941e1aabdcd9dba92a19583d8a0cdaaad9,openstack/requirements,"oslo.service!=1.28.1,>=1.24.0 # Apache-2.0",oslo.service>=1.24.0 # Apache-2.0,1,1
openstack%2Fopenstack-ansible-os_cinder~master~I7cf4e46512a0c392ec4f350eb2368e6035b56402,openstack/openstack-ansible-os_cinder,master,I7cf4e46512a0c392ec4f350eb2368e6035b56402,Updated from OpenStack Ansible Tests,MERGED,2017-12-06 00:05:55.000000000,2017-12-18 19:07:33.000000000,2017-12-18 19:07:33.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-06 00:05:55.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/57cfe69e9444e426be4dc146f3356df074b9f672', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I7cf4e46512a0c392ec4f350eb2368e6035b56402\n'}]",0,525807,57cfe69e9444e426be4dc146f3356df074b9f672,17,6,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I7cf4e46512a0c392ec4f350eb2368e6035b56402
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/07/525807/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,57cfe69e9444e426be4dc146f3356df074b9f672,openstack/openstack-ansible-tests/sync-tests,# The gcc compiler gcc libffi-devel [platform:rpm] openssl-devel [platform:rpm],gcc [platform:dpkg]gcc [platform:rpm]libffi-devel [platform:rpm !platform:opensuseproject-42] libffi-devel-gcc5 [platform:opensuseproject-42] openssl-devel [platform:redhat] libopenssl-devel [platform:suse],5,6
openstack%2Ftripleo-puppet-elements~master~I7c14b4a0df185125c4de55f922cfc30d13c0612f,openstack/tripleo-puppet-elements,master,I7c14b4a0df185125c4de55f922cfc30d13c0612f,Install collectd-gnocchi plugin,MERGED,2017-12-18 10:12:46.000000000,2017-12-18 18:58:47.000000000,2017-12-18 18:58:47.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 10:12:46.000000000', 'files': ['elements/overcloud-opstools/pkg-map', 'elements/overcloud-opstools/install.d/package-installs-overcloud-opstools'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/5a4f4d6bc52bbb7ead9af1ffc464f424950052d6', 'message': 'Install collectd-gnocchi plugin\n\nAdds to new packages to OpsTools list to enable collecting metrics to gnocchi.\n\nChange-Id: I7c14b4a0df185125c4de55f922cfc30d13c0612f\n'}]",0,528680,5a4f4d6bc52bbb7ead9af1ffc464f424950052d6,8,3,1,5241,,,0,"Install collectd-gnocchi plugin

Adds to new packages to OpsTools list to enable collecting metrics to gnocchi.

Change-Id: I7c14b4a0df185125c4de55f922cfc30d13c0612f
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/80/528680/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/overcloud-opstools/pkg-map', 'elements/overcloud-opstools/install.d/package-installs-overcloud-opstools']",2,5a4f4d6bc52bbb7ead9af1ffc464f424950052d6,feature/gnocchi-metrics,collectd_plugin_gnocchicollectd_plugin_python,,4,0
openstack%2Fpuppet-tripleo~master~I9258b5d7cc23b6c19708df2beb7e29484e5c9234,openstack/puppet-tripleo,master,I9258b5d7cc23b6c19708df2beb7e29484e5c9234,Enable collectd to send metrics to Gnocchi,MERGED,2017-12-06 13:33:41.000000000,2017-12-18 18:58:46.000000000,2017-12-18 18:58:46.000000000,"[{'_account_id': 1669}, {'_account_id': 3153}, {'_account_id': 4264}, {'_account_id': 5241}, {'_account_id': 6924}, {'_account_id': 6926}, {'_account_id': 13039}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-06 13:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/c933cfde0ac37e2376fb7dac99edaf7ed83cf646', 'message': 'Enable collectd to send metrics to Gnocchi\n\nAdds classes for collectd gnocchi plugin configuration.\n\nChange-Id: I9258b5d7cc23b6c19708df2beb7e29484e5c9234\n'}, {'number': 2, 'created': '2017-12-06 16:46:02.000000000', 'files': ['templates/collectd/collectd-gnocchi.conf.erb', 'manifests/profile/base/metrics/collectd.pp', 'manifests/profile/base/metrics/collectd/gnocchi.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/b6f76fa0fcd0014f37545eb1f81c3ea82ddb64f9', 'message': 'Enable collectd to send metrics to Gnocchi\n\nAdds classes for collectd gnocchi plugin configuration.\n\nChange-Id: I9258b5d7cc23b6c19708df2beb7e29484e5c9234\n'}]",2,526067,b6f76fa0fcd0014f37545eb1f81c3ea82ddb64f9,15,10,2,5241,,,0,"Enable collectd to send metrics to Gnocchi

Adds classes for collectd gnocchi plugin configuration.

Change-Id: I9258b5d7cc23b6c19708df2beb7e29484e5c9234
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/67/526067/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/collectd/collectd-gnocchi.conf.erb', 'manifests/profile/base/metrics/collectd.pp', 'manifests/profile/base/metrics/collectd/gnocchi.pp']",3,c933cfde0ac37e2376fb7dac99edaf7ed83cf646,feature/gnocchi-metrics,"# This is used to create configuration file for collectd-gnocchi plugin define tripleo::profile::base::metrics::collectd::gnocchi ( $ensure = 'present', $order = '00', $auth_mode = 'simple', $protocol = 'http', $server = undef, $port = undef, $user = undef, $keystone_auth_url = undef, $keystone_user_name = undef, $keystone_user_id = undef, $keystone_password = undef, $keystone_project_id = undef, $keystone_project_name = undef, $keystone_user_domain_id = undef, $keystone_user_domain_name = undef, $keystone_project_domain_id = undef, $keystone_project_domain_name = undef, $keystone_region_name = undef, $keystone_interface = undef, $keystone_endpoint = undef, $resource_type = 'collectd', $batch_size = 10, ) { include ::collectd package { ['python-collectd-gnocchi', 'collectd-python']: ensure => $ensure, } collectd::plugin { 'python': ensure => $ensure, order => $order, content => template('tripleo/collectd/collectd-gnocchi.conf.erb'), require => Package['python-collectd-gnocchi'] } } ",,234,0
openstack%2Fpuppet-openstacklib~master~I6b48842862a6860215ff774f73ae7224a34545e7,openstack/puppet-openstacklib,master,I6b48842862a6860215ff774f73ae7224a34545e7,Ensure os_workers_large fact returns an Integer,MERGED,2017-12-13 21:31:18.000000000,2017-12-18 18:54:11.000000000,2017-12-16 00:21:54.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 21:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/d41976604a087b16580238c7b451260027016a8b', 'message': 'Ensure os_workers_large fact returns an Integer\n\nAlso make sure it returns at least 1.\n\nCloses-bug: #1738082\nChange-Id: I6b48842862a6860215ff774f73ae7224a34545e7\n'}, {'number': 2, 'created': '2017-12-13 21:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/bc447e67f2f31cce1ca87697bab784acefe591b5', 'message': 'Ensure os_workers_large fact returns an Integer\n\nAlso make sure it returns at least 1.\n\nCloses-bug: #1738082\nChange-Id: I6b48842862a6860215ff774f73ae7224a34545e7\n'}, {'number': 3, 'created': '2017-12-13 22:40:34.000000000', 'files': ['spec/unit/facter/os_workers_spec.rb', 'releasenotes/notes/os_workers_large-fact-71afa253044ce56e.yaml', 'lib/facter/os_workers.rb', 'spec/unit/facter/os_workers_small_spec.rb', 'spec/unit/facter/os_workers_large_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/e5005dc4ff40d75c5600723eb9a5b967aefb4a92', 'message': 'Ensure os_workers_large fact returns an Integer\n\nAlso make sure it returns at least 1.\n\nCloses-bug: #1738082\nChange-Id: I6b48842862a6860215ff774f73ae7224a34545e7\n'}]",0,527788,e5005dc4ff40d75c5600723eb9a5b967aefb4a92,11,3,3,7156,,,0,"Ensure os_workers_large fact returns an Integer

Also make sure it returns at least 1.

Closes-bug: #1738082
Change-Id: I6b48842862a6860215ff774f73ae7224a34545e7
",git fetch https://review.opendev.org/openstack/puppet-openstacklib refs/changes/88/527788/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/facter/os_workers_spec.rb', 'lib/facter/os_workers.rb', 'spec/unit/facter/os_workers_small_spec.rb', 'spec/unit/facter/os_workers_large_spec.rb']",4,d41976604a087b16580238c7b451260027016a8b,bug/1738082,require 'spec_helper' describe 'os_workers_large' do before { Facter.clear } after { Facter.clear } context 'with processorcount=1' do before do Facter.fact(:processorcount).stubs(:value).returns(1) end it 'returns a minimum of 1' do expect(Facter.fact(:os_workers_large).value).to eq(1) end end context 'with processorcount=8' do before do Facter.fact(:processorcount).stubs(:value).returns(8) end it 'returns processorcount/2' do expect(Facter.fact(:os_workers_large).value).to eq(4) end end end ,,102,1
openstack%2Fpuppet-tripleo~master~I54c68a91fd39d7fe2f15a05359d60f6af559aa61,openstack/puppet-tripleo,master,I54c68a91fd39d7fe2f15a05359d60f6af559aa61,Remove old central and compute agent profiles,MERGED,2017-11-13 22:32:58.000000000,2017-12-18 18:46:15.000000000,2017-12-18 18:46:15.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-11-13 22:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ae543c2d11be6a043c5961f6d9612b93befd8609', 'message': ""Remove old central and compute agent profiles\n\nWe've been using polling agent profile with namespace for\nsometime now. We can drop these old unused classes.\n\nChange-Id: I54c68a91fd39d7fe2f15a05359d60f6af559aa61\n""}, {'number': 2, 'created': '2017-11-20 19:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/c8d8fae100e5137c0eb4034032a4245ac040d86d', 'message': ""Remove old central and compute agent profiles\n\nWe've been using polling agent profile with namespace for\nsometime now. We can drop these old unused classes.\n\nChange-Id: I54c68a91fd39d7fe2f15a05359d60f6af559aa61\n""}, {'number': 3, 'created': '2017-12-15 23:44:04.000000000', 'files': ['manifests/profile/base/ceilometer/agent/central.pp', 'manifests/profile/base/ceilometer/agent/compute.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ecefcffbe9c811208822b388050f09e6b259f40f', 'message': ""Remove old central and compute agent profiles\n\nWe've been using polling agent profile with namespace for\nsometime now. We can drop these old unused classes.\n\nChange-Id: I54c68a91fd39d7fe2f15a05359d60f6af559aa61\n""}]",0,519488,ecefcffbe9c811208822b388050f09e6b259f40f,21,4,3,6924,,,0,"Remove old central and compute agent profiles

We've been using polling agent profile with namespace for
sometime now. We can drop these old unused classes.

Change-Id: I54c68a91fd39d7fe2f15a05359d60f6af559aa61
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/88/519488/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/ceilometer/agent/central.pp', 'manifests/profile/base/ceilometer/agent/compute.pp']",2,ae543c2d11be6a043c5961f6d9612b93befd8609,remove-old-agents,,"# Copyright 2016 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # == Class: tripleo::profile::base::ceilometer::agent::compute # # Ceilometer Compute Agent profile for tripleo # # === Parameters # # [*step*] # (Optional) The current step in deployment. See tripleo-heat-templates # for more details. # Defaults to hiera('step') # class tripleo::profile::base::ceilometer::agent::compute ( $step = Integer(hiera('step')), ) { include ::tripleo::profile::base::ceilometer if $step >= 4 { include ::ceilometer::agent::auth include ::ceilometer::agent::compute } } ",0,85
openstack%2Frally~master~I9bb05fb79170a1cf5fbf2176a7dac338b453a1d8,openstack/rally,master,I9bb05fb79170a1cf5fbf2176a7dac338b453a1d8,Update OSProfiler's spec,ABANDONED,2017-08-11 13:11:11.000000000,2017-12-18 18:43:45.000000000,,"[{'_account_id': 3}, {'_account_id': 14817}, {'_account_id': 22960}]","[{'number': 1, 'created': '2017-08-11 13:11:11.000000000', 'files': ['doc/specs/in-progress/osprofiler.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/9d35872d9534eec387d29d8c88e634f661ac3160', 'message': ""Update OSProfiler's spec\n\nChange-Id: I9bb05fb79170a1cf5fbf2176a7dac338b453a1d8\n""}]",1,492998,9d35872d9534eec387d29d8c88e634f661ac3160,5,3,1,9545,,,0,"Update OSProfiler's spec

Change-Id: I9bb05fb79170a1cf5fbf2176a7dac338b453a1d8
",git fetch https://review.opendev.org/openstack/rally refs/changes/98/492998/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/specs/in-progress/osprofiler.rst'],1,9d35872d9534eec387d29d8c88e634f661ac3160,specs,"The trace id should be saved via ``self.add_output`` mechanism of scenarios with using proper chart plugins (see ``OSProfiler charts`` section for more details). Enabling profiling ------------------ Enabling/disabling profiling should be done via Rally configuration file: * It is common place for storing different kinds of options. * There is planned feature that will able to re-set config options via deployment config or task file. The default value of that options should be True. In case of missing HMAC key in credentials, attempt to initialize OSProfiler should not be started. OSProfiler charts ----------------- At the first step of integration OSProfiler in Rally, let's store the trace-idAs for next step, for better user experience as a result of better integration with OSProfiler it would be nice to display not just trace-id in HTML reports but embedded the whole OSProfiler's reports instead. To make it possible, we need to extend OpenStack deployment plugins again to support storing a connection string of OSProfiler. It should be optional as like ``HMAC_KEY``. Embedding OSProfiler's reports for all iterations of all workloads can lead to a huge amount of data, so we need to develop a new chart plugin which can show just trace-id or the whole reports based on Rally configuration file. As it was mentioned in previous paragraph, we need to develop a new chart plugins ``OSProfilerChart``. Our HTML reports was designed to be pluggable and extendable, so we can add a new plugin in OpenStack-related place (i.e under ``rally/plugins/openstack`` directory) and it will be auto-discoverable and do not affect not-openstack related things after splitting Rally core part to a separate repo. ``OSProfilerChart`` should take into account presence of connection string for OSProfiler in deployment and based on it display trace-id as text field or obtain html reports and embed them into Rally report. ","At the first step of integration OSProfiler in Rally, let's store that trace-idIn future, we should develop a separate chart that will embed OSProfiler html report as a separate tab in the Rally report. Enabling profiling ------------------ Enabling/disabling profiling should be done via rally configuration file: * It is common place for storing different kinds of options. * There is planned feature that will able to re-set config options via deployment config or task file. The default value of that options should be True. In case of missing HMAC key in credentials, attempt to initialize OSProfiler should not be started.",39,11
openstack%2Frally~master~I2110dae5c95c1c7f9a39ba3ac0fb64d226ff2d2d,openstack/rally,master,I2110dae5c95c1c7f9a39ba3ac0fb64d226ff2d2d,Rally verify support for any in-tree Openstack project functional tests,ABANDONED,2015-03-21 00:20:39.000000000,2017-12-18 18:42:54.000000000,,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 6835}, {'_account_id': 8576}, {'_account_id': 9545}, {'_account_id': 10068}, {'_account_id': 10459}, {'_account_id': 10475}, {'_account_id': 14817}, {'_account_id': 15661}]","[{'number': 1, 'created': '2015-03-21 00:20:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4f4f0b4f2bc9ecb526cdb90d7869ebb99c74c58d', 'message': 'rally-verify-generalization: Specs to add ability for rally verify to use any in-tree Openstack project functional tests\n\nChange-Id: I2110dae5c95c1c7f9a39ba3ac0fb64d226ff2d2d\nSigned-off-by: panbalag <panbalag@redhat.com>\n'}, {'number': 2, 'created': '2015-03-23 17:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ca0607b92d09b8fa34c00ca51929effa6a940c2c', 'message': 'Rally verify support for any in-tree Openstack project functional tests\n\nChange-Id: I2110dae5c95c1c7f9a39ba3ac0fb64d226ff2d2d\nSigned-off-by: panbalag <panbalag@redhat.com>\n'}, {'number': 3, 'created': '2015-03-23 18:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6b09bc00cb5c9531a1ecc9a73b6faca8d763eee9', 'message': 'Rally verify support for any in-tree Openstack project functional tests\n\nChange-Id: I2110dae5c95c1c7f9a39ba3ac0fb64d226ff2d2d\nSigned-off-by: panbalag <panbalag@redhat.com>\n'}, {'number': 4, 'created': '2015-03-23 20:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5d3f64bf37270cdaa9e23d28043ba1c89b43a3cf', 'message': 'Rally verify support for any in-tree Openstack project functional tests\n\nChange-Id: I2110dae5c95c1c7f9a39ba3ac0fb64d226ff2d2d\nSigned-off-by: panbalag <panbalag@redhat.com>\n'}, {'number': 5, 'created': '2015-03-23 21:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/950bd521a23f9424da7ed425575fe61669ee512c', 'message': 'Rally verify support for any in-tree Openstack project functional tests\n\nChange-Id: I2110dae5c95c1c7f9a39ba3ac0fb64d226ff2d2d\nSigned-off-by: panbalag <panbalag@redhat.com>\n'}, {'number': 6, 'created': '2015-03-24 00:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/90dcbda8be61253f8086db0d4a4b9e256819c170', 'message': 'Rally verify support for any in-tree Openstack project functional tests\n\nChange-Id: I2110dae5c95c1c7f9a39ba3ac0fb64d226ff2d2d\nSigned-off-by: panbalag <panbalag@redhat.com>\n'}, {'number': 7, 'created': '2015-05-07 18:16:54.000000000', 'files': ['doc/specs/in-progress/common-rally-verify.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/8cbf25b729fcfcb695427738daed29cc179d3547', 'message': 'Rally verify support for any in-tree Openstack project functional tests\n\nChange-Id: I2110dae5c95c1c7f9a39ba3ac0fb64d226ff2d2d\nSigned-off-by: panbalag <panbalag@redhat.com>\n'}]",34,166487,8cbf25b729fcfcb695427738daed29cc179d3547,56,10,7,15661,,,0,"Rally verify support for any in-tree Openstack project functional tests

Change-Id: I2110dae5c95c1c7f9a39ba3ac0fb64d226ff2d2d
Signed-off-by: panbalag <panbalag@redhat.com>
",git fetch https://review.opendev.org/openstack/rally refs/changes/87/166487/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/specs/in-progress/common-rally-verify.rst'],1,4f4f0b4f2bc9ecb526cdb90d7869ebb99c74c58d,,"======================= Common-rally-verify ======================= Rally Road map: --------------- https://docs.google.com/a/mirantis.com/spreadsheets/d/16DXpfbqvlzMFaqaXAcJsBzzpowb_XpymaK2aFY2gA2g/edit#gid=0 Rally verify genaralization (Line 17) - add abbility to use rally verify for in-tree functional tests of all projects. Problem description =================== There is a need for a common framework to support use of any Openstack project functional tests like Swift, Cinder, Glance, Sahara, etc. Since Rally already supports Tempest tests, it should be modified to support any tests from any in-tree OpenStack project functional tests. Proposed change =============== The solution is to modify rally/cmd/commands/verify.py to support Openstack project functional tests. Currently, Rally verify command works as follows: 1. Verify test set name (currently syupports test names hard coded in consts.py). 2. Verify test code for the specified deployment. a. Check if test code exists in the base directory. b. If it does not exist, pull test code from any repo via source argument (openstack/tempest by default). c. Create a copy of the test code for the specified deployment. 3. execute tempest tests via hard coded testr bash execution 4. collect results from testr The proposed changes would be, 1. Include the list of Openstack project functional tests in consts.py 2. Verify if functional tests directory exists for the specified project. a. If not, create the base directory by pulling test code via ""source"" argument. b. Create a copy of the test code for the specified deployment. 3. execute functional tests via ""testr"" (check if testr can be replaced by tox). 4. collect results from testr or tox. Implementation ============== Assignee(s) ----------- Primary assignee: panbalag@redhat.com yfried@redhat.com Milestones ---------- Target Milestone for completion: Kilo-2 Work Items ---------- 1. Create list of names of Openstack project functional test sets. /rally/consts.py, _FunctionalsTestSets() 2. Allow user input of any of the above functional project test sets. /rally/cmd/commands/verify.py, start(..) 3. Generalize base repo path and other configuration details. The plan is to create a separate directory to hold all code related to Openstack projects functional tests. /rally/verification/projects/projects.py, __init__ 4. Source project test code and create a copy of the code for specified deployment. /rally/verification/projects/projects.py, install() 5. Execute the project functional tests. /rally/verification/projects/projects.py, run() 6. Save the test results. /rally/verification/projects/projects.py, _save_test_results() Dependencies ============ - None ",,86,0
openstack%2Frally~master~I67d68b256761033667fdd062ff6846c074d730ec,openstack/rally,master,I67d68b256761033667fdd062ff6846c074d730ec,add image name support to VolumeGenerator,NEW,2016-09-20 19:05:10.000000000,2017-12-18 18:36:23.000000000,,"[{'_account_id': 9545}, {'_account_id': 10433}, {'_account_id': 11748}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-09-20 19:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/965a9c252756084973abfd979da71bbe8a6873c7', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}, {'number': 2, 'created': '2016-09-20 19:18:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3f520ce1e8d62471a56416d354233662a7f5da6c', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}, {'number': 3, 'created': '2016-09-20 21:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7470a75913b4e24f3521f064902e23c124156ec8', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}, {'number': 4, 'created': '2016-09-21 16:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/226ea66862582dd2985fb03ef8f1b7c537962354', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}, {'number': 5, 'created': '2016-09-21 21:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1ea0b76e8c5d49ad661c6f1cfbdc33c1db7c5774', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}, {'number': 6, 'created': '2016-09-22 15:44:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c80b87389f21a45de8059be2a74600fee1f8c6c4', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}, {'number': 7, 'created': '2016-09-22 19:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ce72579e02e270142251fe649586a98fa866af3a', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}, {'number': 8, 'created': '2016-09-26 19:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/adc8674144f1f1384c7420449e6db661ee405105', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}, {'number': 9, 'created': '2016-09-26 23:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a70efdf3bc24f3e2e4d68de3aa38421bb85d8c62', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}, {'number': 10, 'created': '2016-10-05 18:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/db4e14349e75245ae816d32e75f933c269a5d03d', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}, {'number': 11, 'created': '2016-10-05 20:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/eea00eea76259b4bdb8eea5d9f1aef496cf5418c', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}, {'number': 12, 'created': '2016-10-06 16:42:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/482428973128ac23bb4969d1d25acf8590940f36', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}, {'number': 13, 'created': '2016-10-06 17:42:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b64c54469fdeed89252a040b1a0a7b0a748955d3', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}, {'number': 14, 'created': '2016-10-06 18:03:40.000000000', 'files': ['tests/unit/plugins/openstack/context/cinder/test_volumes.py', 'rally/plugins/openstack/context/cinder/volumes.py', 'rally-jobs/cinder.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/ca830aa7fa07a2c23d9ece0e27c7f1ab9fd3bc56', 'message': 'add image name support to VolumeGenerator\n\nChange-Id: I67d68b256761033667fdd062ff6846c074d730ec\n'}]",14,373503,ca830aa7fa07a2c23d9ece0e27c7f1ab9fd3bc56,51,5,14,10433,,,0,"add image name support to VolumeGenerator

Change-Id: I67d68b256761033667fdd062ff6846c074d730ec
",git fetch https://review.opendev.org/openstack/rally refs/changes/03/373503/9 && git format-patch -1 --stdout FETCH_HEAD,['rally/plugins/openstack/context/cinder/volumes.py'],1,965a9c252756084973abfd979da71bbe8a6873c7,rally-cinder-dev-old-save,"from rally.plugins.openstack.scenarios.glance import utils as glance_utils }, ""image_name"": { ""type"" : [""string"", ""null""] }, image_name = self.config.get(""image_name"", None) image_id = None if image_name: glance_util = glance_utils.GlanceScenario({ ""user"": user, ""task"": self.context[""task""], ""config"": self.context[""config""], }) for image in glance_util._list_images(): if image.name == image_name: image_id = image.id vol = cinder_util._create_volume(size, volume_type=volume_type, imageRef=image_id)"," } vol = cinder_util._create_volume(size, volume_type=volume_type)",18,2
openstack%2Frally~master~Ib131a4f22562b8f12e6d8b3bbb103315e3809a90,openstack/rally,master,Ib131a4f22562b8f12e6d8b3bbb103315e3809a90,Fixes issue with CLI command - rally verify list - by fixing typo,ABANDONED,2017-10-02 18:51:54.000000000,2017-12-18 18:34:41.000000000,,"[{'_account_id': 6172}, {'_account_id': 9545}, {'_account_id': 10068}, {'_account_id': 14817}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-02 18:51:54.000000000', 'files': ['rally/api.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/3d6581a8fca8a0b369a6734f5b199a5bda5afc23', 'message': 'Fixes issue with CLI command - rally verify list - by fixing typo\n\nThe command, rally verify list, was not working because of an issue in\napi.py where the issue below was showing up.\n\n2017-09-28 20:27:24.621 13289 ERROR rally   File\n""/usr/lib/python2.7/site-packages/rally/api.py"", line 185, in get\n2017-09-28 20:27:24.621 13289 ERROR rally     for platform, creds in\ndeployment[""config""][""creds""].items():\n2017-09-28 20:27:24.621 13289 ERROR rally KeyError: \'creds\'\n\nThis fix just changes that line to get rid of the key error.\n\nChange-Id: Ib131a4f22562b8f12e6d8b3bbb103315e3809a90\n'}]",0,508967,3d6581a8fca8a0b369a6734f5b199a5bda5afc23,10,5,1,27011,,,0,"Fixes issue with CLI command - rally verify list - by fixing typo

The command, rally verify list, was not working because of an issue in
api.py where the issue below was showing up.

2017-09-28 20:27:24.621 13289 ERROR rally   File
""/usr/lib/python2.7/site-packages/rally/api.py"", line 185, in get
2017-09-28 20:27:24.621 13289 ERROR rally     for platform, creds in
deployment[""config""][""creds""].items():
2017-09-28 20:27:24.621 13289 ERROR rally KeyError: 'creds'

This fix just changes that line to get rid of the key error.

Change-Id: Ib131a4f22562b8f12e6d8b3bbb103315e3809a90
",git fetch https://review.opendev.org/openstack/rally refs/changes/67/508967/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/api.py'],1,3d6581a8fca8a0b369a6734f5b199a5bda5afc23,verify-list-bug," for platform, creds in deployment[""config""].items():"," for platform, creds in deployment[""config""][""creds""].items():",1,1
openstack%2Fopenstack-manuals~master~Ib84a3e34e4c25a1f565a506f3229453a0d997be3,openstack/openstack-manuals,master,Ib84a3e34e4c25a1f565a506f3229453a0d997be3,Add descriptions to zuul.yaml,MERGED,2017-12-16 15:34:26.000000000,2017-12-18 18:32:42.000000000,2017-12-18 18:32:42.000000000,"[{'_account_id': 17765}, {'_account_id': 20156}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-16 15:34:26.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/64e109dabb1e3cf52ed609baec5f67dc6b2b57c5', 'message': 'Add descriptions to zuul.yaml\n\nAdd missing descriptions to the jobs in .zuul.yaml.\n\nChange-Id: Ib84a3e34e4c25a1f565a506f3229453a0d997be3\n'}]",0,528485,64e109dabb1e3cf52ed609baec5f67dc6b2b57c5,7,3,1,6547,,,0,"Add descriptions to zuul.yaml

Add missing descriptions to the jobs in .zuul.yaml.

Change-Id: Ib84a3e34e4c25a1f565a506f3229453a0d997be3
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/85/528485/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,64e109dabb1e3cf52ed609baec5f67dc6b2b57c5,zuul-description," description: | Build manuals using ""checkbuild"" tox environment. description: | Build translated manuals using ""checklang"" tox environment.",,4,0
openstack%2Frally~master~I4f3345de19e49841b03790cbd20d96bfa8230631,openstack/rally,master,I4f3345de19e49841b03790cbd20d96bfa8230631,Empty change for testing,ABANDONED,2017-07-21 07:17:30.000000000,2017-12-18 18:31:49.000000000,,"[{'_account_id': 6172}, {'_account_id': 7118}, {'_account_id': 14817}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-07-21 07:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/18835a9c6c9fedb1f98dd6e3003fa4485488afaa', 'message': 'Empty change for testing\n\nChange-Id: I4f3345de19e49841b03790cbd20d96bfa8230631\n'}, {'number': 2, 'created': '2017-07-21 07:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/86afcd6750cae823544ef725e2714e0f2c3a0599', 'message': 'Empty change for testing\n\nDepends-On: If2664b5054d668f5e088699ae1493c54692a2e8c\nChange-Id: I4f3345de19e49841b03790cbd20d96bfa8230631\n'}, {'number': 3, 'created': '2017-07-23 16:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7251627a6ddb9c2cde4b42338b9fa5c56dec34d8', 'message': 'Empty change for testing\n\nDepends-On: If2664b5054d668f5e088699ae1493c54692a2e8c\nChange-Id: I4f3345de19e49841b03790cbd20d96bfa8230631\n'}, {'number': 4, 'created': '2017-07-24 06:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/686de49ea0e324b17317168a736c28a65b896092', 'message': 'Empty change for testing\n\nDepends-On: If2664b5054d668f5e088699ae1493c54692a2e8c\nChange-Id: I4f3345de19e49841b03790cbd20d96bfa8230631\n'}, {'number': 5, 'created': '2017-07-25 16:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7e7ef5ce3b4dc6e2e9129eac1c20f8ccba08b822', 'message': 'Empty change for testing\n\nDepends-On: If2664b5054d668f5e088699ae1493c54692a2e8c\nChange-Id: I4f3345de19e49841b03790cbd20d96bfa8230631\n'}, {'number': 6, 'created': '2017-07-28 20:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e9e999f72860755f4b68bd6f56a579e99332cdf4', 'message': 'Empty change for testing\n\nChange-Id: I4f3345de19e49841b03790cbd20d96bfa8230631\n'}, {'number': 7, 'created': '2017-07-28 21:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3ffd96609c05fac1dc86bc0a6459f0b1109d936e', 'message': 'Empty change for testing\n\nDepends-On: I2c62d8bcae4cc4d035fa2bb3aadffb0e1d190751\nChange-Id: I4f3345de19e49841b03790cbd20d96bfa8230631\n'}, {'number': 8, 'created': '2017-07-29 17:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ae69ada14e0059c21844d38922ccb087dbcd3967', 'message': 'Empty change for testing\n\nChange-Id: I4f3345de19e49841b03790cbd20d96bfa8230631\n'}, {'number': 9, 'created': '2017-07-29 17:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1d6216f65cdde017ec9c5e4e9d7dfc88ee8e7750', 'message': 'Empty change for testing\n\nChange-Id: I4f3345de19e49841b03790cbd20d96bfa8230631\n'}, {'number': 10, 'created': '2017-10-03 21:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/56f02c2c9196e1ff4071db3e02c20be2b4b7ed4d', 'message': 'Empty change for testing\n\nChange-Id: I4f3345de19e49841b03790cbd20d96bfa8230631\n'}, {'number': 11, 'created': '2017-10-03 23:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1be2e506b20a4f66de4527623970f5a3978ca5bf', 'message': 'Empty change for testing\n\nDepends-On: I2098d4eb2747282622cf486fa7dbf216f932f58b\nChange-Id: I4f3345de19e49841b03790cbd20d96bfa8230631\n'}, {'number': 12, 'created': '2017-10-04 06:36:29.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/rally/commit/02894b5bfeb7fb1fea888a84203d72a91f16ae41', 'message': 'Empty change for testing\n\nThis is testing a new version of the devstack keystone PKI\nstore directory removal\n\nDepends-On: I114a966cb8205d6fc1c62b4898eefddd1a1ce2e7\nChange-Id: I4f3345de19e49841b03790cbd20d96bfa8230631\n'}]",0,486017,02894b5bfeb7fb1fea888a84203d72a91f16ae41,59,4,12,6172,,,0,"Empty change for testing

This is testing a new version of the devstack keystone PKI
store directory removal

Depends-On: I114a966cb8205d6fc1c62b4898eefddd1a1ce2e7
Change-Id: I4f3345de19e49841b03790cbd20d96bfa8230631
",git fetch https://review.opendev.org/openstack/rally refs/changes/17/486017/6 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,18835a9c6c9fedb1f98dd6e3003fa4485488afaa,empty,,,1,0
openstack%2Finstack-undercloud~master~I39e42ff54fd7a461f7a03cfb8be17db92a35377e,openstack/instack-undercloud,master,I39e42ff54fd7a461f7a03cfb8be17db92a35377e,Fix wrong flag to prevent failure when selinux perm are correct.,MERGED,2017-12-18 12:01:06.000000000,2017-12-18 18:14:03.000000000,2017-12-18 18:14:03.000000000,"[{'_account_id': 3153}, {'_account_id': 6133}, {'_account_id': 10267}, {'_account_id': 14985}, {'_account_id': 21686}, {'_account_id': 22348}, {'_account_id': 27427}]","[{'number': 1, 'created': '2017-12-18 12:01:06.000000000', 'files': ['elements/undercloud-install/os-refresh-config/post-configure.d/98-undercloud-setup'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/e01745d3d8cf62f84a42af7b1274ee95bc789b8d', 'message': 'Fix wrong flag to prevent failure when selinux perm are correct.\n\nThis review[1] has a typo.  The bash flag was incorrect.  It was meant\nto be +e/-e to avoid trouble when grep failed.\n\n[1] https://review.openstack.org/#/q/Ib5873383632a1141c8dd3859b34ca29904020790\n\nChange-Id: I39e42ff54fd7a461f7a03cfb8be17db92a35377e\nRelated-Bug: #1736246\n'}]",0,528698,e01745d3d8cf62f84a42af7b1274ee95bc789b8d,13,7,1,8297,,,0,"Fix wrong flag to prevent failure when selinux perm are correct.

This review[1] has a typo.  The bash flag was incorrect.  It was meant
to be +e/-e to avoid trouble when grep failed.

[1] https://review.openstack.org/#/q/Ib5873383632a1141c8dd3859b34ca29904020790

Change-Id: I39e42ff54fd7a461f7a03cfb8be17db92a35377e
Related-Bug: #1736246
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/98/528698/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/undercloud-install/os-refresh-config/post-configure.d/98-undercloud-setup'],1,e01745d3d8cf62f84a42af7b1274ee95bc789b8d,bug/1736246, set +e set -e, set +x set -x,2,2
openstack%2Fpatrole~master~If0a73139fa339109881f52fa588eec94f8cec1c9,openstack/patrole,master,If0a73139fa339109881f52fa588eec94f8cec1c9,Migrate to override_role for compute module (part 1),MERGED,2017-12-10 20:03:28.000000000,2017-12-18 18:02:38.000000000,2017-12-18 18:02:38.000000000,"[{'_account_id': 17896}, {'_account_id': 22348}, {'_account_id': 23185}, {'_account_id': 25571}, {'_account_id': 25695}]","[{'number': 1, 'created': '2017-12-10 20:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/0e780865cea95ff996846a5d57214e7f5aa16af4', 'message': 'Migrate to override_role for compute module (part 1)\n\nNow that override_role has supplanted switch_role (which has\nbeen deprecated) in [0], the RBAC tests need to switch to use\noverride_role.\n\nThis PS switches to override_role for the compute module. This\nPS handles 11 modules; 2 follow-up patch sets will handle the\nremaining 22 modules.\n\nThis PS also removes unnecessary indexing into response bodies.\n\n[0] I670fba358bf321eae0d22d18cea6d2f530f00716\n\nChange-Id: If0a73139fa339109881f52fa588eec94f8cec1c9\n'}, {'number': 2, 'created': '2017-12-10 20:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/bf52bb78db90b717085f547c6c041e838db72058', 'message': 'Migrate to override_role for compute module (part 1)\n\nNow that override_role has supplanted switch_role (which has\nbeen deprecated) in [0], the RBAC tests need to switch to use\noverride_role.\n\nThis PS switches to override_role for the compute module. This\nPS handles 11 modules; 2 follow-up patch sets will handle the\nremaining 22 modules.\n\nThis PS also removes unnecessary indexing into response bodies.\n\n[0] I670fba358bf321eae0d22d18cea6d2f530f00716\n\nPartially Implements: blueprint rbac-utils-contextmanager\nChange-Id: If0a73139fa339109881f52fa588eec94f8cec1c9\n'}, {'number': 3, 'created': '2017-12-10 23:37:44.000000000', 'files': ['patrole_tempest_plugin/tests/api/compute/test_aggregates_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_availability_zone_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_flavor_extra_specs_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_floating_ips_bulk_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_agents_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_fixed_ips_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_flavor_access_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_flavor_manage_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_floating_ips_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_flavor_rxtx_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_floating_ip_pools_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/961212fb1c56bede029f0e8f08ccbfde60d1af1b', 'message': 'Migrate to override_role for compute module (part 1)\n\nNow that override_role has supplanted switch_role (which has\nbeen deprecated) in [0], the RBAC tests need to switch to use\noverride_role.\n\nThis PS switches to override_role for the compute module. This\nPS handles 11 modules; 2 follow-up patch sets will handle the\nremaining 22 modules.\n\nThis PS also removes unnecessary indexing into response bodies.\n\n[0] I670fba358bf321eae0d22d18cea6d2f530f00716\n\nPartially Implements: blueprint rbac-utils-contextmanager\nChange-Id: If0a73139fa339109881f52fa588eec94f8cec1c9\n'}]",0,526953,961212fb1c56bede029f0e8f08ccbfde60d1af1b,14,5,3,23186,,,0,"Migrate to override_role for compute module (part 1)

Now that override_role has supplanted switch_role (which has
been deprecated) in [0], the RBAC tests need to switch to use
override_role.

This PS switches to override_role for the compute module. This
PS handles 11 modules; 2 follow-up patch sets will handle the
remaining 22 modules.

This PS also removes unnecessary indexing into response bodies.

[0] I670fba358bf321eae0d22d18cea6d2f530f00716

Partially Implements: blueprint rbac-utils-contextmanager
Change-Id: If0a73139fa339109881f52fa588eec94f8cec1c9
",git fetch https://review.opendev.org/openstack/patrole refs/changes/53/526953/3 && git format-patch -1 --stdout FETCH_HEAD,"['patrole_tempest_plugin/tests/api/compute/test_aggregates_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_availability_zone_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_flavor_extra_specs_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_floating_ips_bulk_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_agents_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_fixed_ips_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_flavor_access_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_flavor_manage_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_floating_ips_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_flavor_rxtx_rbac.py', 'patrole_tempest_plugin/tests/api/compute/test_floating_ip_pools_rbac.py']",11,0e780865cea95ff996846a5d57214e7f5aa16af4,bp/rbac-utils-contextmanager, with self.rbac_utils.override_role(self): self.fip_pools_client.list_floating_ip_pools()," self.rbac_utils.switch_role(self, toggle_rbac_role=True) self.fip_pools_client.list_floating_ip_pools()['floating_ip_pools']",86,92
openstack%2Frally~master~I4cd4c98ed5b94e22f24106f741592b1ee3257855,openstack/rally,master,I4cd4c98ed5b94e22f24106f741592b1ee3257855,[ci] use latest pytest,ABANDONED,2017-06-02 15:31:12.000000000,2017-12-18 18:01:37.000000000,,"[{'_account_id': 8871}, {'_account_id': 14817}]","[{'number': 1, 'created': '2017-06-02 15:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/322a224a0490179424ff4763350e6c724e0545a3', 'message': '[ci] You latest pytest\n\nLatest putest includes warning library. It allows to fail test run in\ncase of deprecation warning and so on.\n\nChange-Id: I4cd4c98ed5b94e22f24106f741592b1ee3257855\n'}, {'number': 2, 'created': '2017-06-06 09:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a0e45fba085280d727040c054404f4957014d767', 'message': '[ci] use latest pytest\n\nLatest pytest includes warning library. It allows to fail test run in\ncase of deprecation warning and so on.\n\nChange-Id: I4cd4c98ed5b94e22f24106f741592b1ee3257855\n'}, {'number': 3, 'created': '2017-06-06 10:28:24.000000000', 'files': ['tests/unit/task/test_sla.py', 'tests/unit/task/test_types.py', 'test-requirements.txt', 'tests/unit/task/test_exporter.py', 'tests/unit/common/test_version.py', 'tests/ci/pytest_launcher.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/2c9d94d8ec2871ec5ee50a895a7ece3449fc3639', 'message': '[ci] use latest pytest\n\nLatest pytest includes warning library. It allows to fail test run in\ncase of different kind of warnings. It can be helpful to not miss\ndeprecation warnings and have enough time to fix them in time.\n\nChange-Id: I4cd4c98ed5b94e22f24106f741592b1ee3257855\n'}]",0,470333,2c9d94d8ec2871ec5ee50a895a7ece3449fc3639,12,2,3,9545,,,0,"[ci] use latest pytest

Latest pytest includes warning library. It allows to fail test run in
case of different kind of warnings. It can be helpful to not miss
deprecation warnings and have enough time to fix them in time.

Change-Id: I4cd4c98ed5b94e22f24106f741592b1ee3257855
",git fetch https://review.opendev.org/openstack/rally refs/changes/33/470333/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/task/test_sla.py', 'tests/unit/task/test_types.py', 'test-requirements.txt', 'tests/unit/task/test_exporter.py', 'tests/ci/pytest_launcher.py']",5,322a224a0490179424ff4763350e6c724e0545a3,pytest-update,"PYTEST_ARGUMENTS = (""py.test"" "" -rw"" # show warnings "" -W error"" # turn warnings into errors # ignore one exception for now "" -W ignore::oslo_db.exception.OsloDBDeprecationWarning""","PYTEST_ARGUMENTS = (""py.test"" # base command",14,10
openstack%2Frally~master~Iad7de28f4582bf4b0a26639bbca0d986cf8c38c3,openstack/rally,master,Iad7de28f4582bf4b0a26639bbca0d986cf8c38c3,[WIP] Move DD_Load task from BASH script to Rally scenario,ABANDONED,2017-01-25 13:35:50.000000000,2017-12-18 17:56:28.000000000,,[{'_account_id': 14817}],"[{'number': 1, 'created': '2017-01-25 13:35:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f72c09c513f1dd7088b2b11eb29aa5512a2b743f', 'message': '[WIP] Move DD_Load task from BASH script to Rally scenario\n\nMove DD_load task from BASH script to Rally by creating new task.\nDD_load task is based on VMTask.BootRuncommandDelete scenario\n\nChange-Id: Iad7de28f4582bf4b0a26639bbca0d986cf8c38c3\n'}, {'number': 2, 'created': '2017-01-27 13:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/62828202abddf8c04cad8a37b3daea5a9e63d543', 'message': '[WIP] Move DD_Load task from BASH script to Rally scenario\n\nMove DD_load task from BASH script to Rally by creating new task.\nDD_load task is based on VMTask.BootRuncommandDelete scenario\n\nChange-Id: Iad7de28f4582bf4b0a26639bbca0d986cf8c38c3\n'}, {'number': 3, 'created': '2017-01-30 10:47:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2e57d611888d4f6536defc44f4758a40765e0d4d', 'message': '[WIP] Move DD_Load task from BASH script to Rally scenario\n\nMove DD_load task from BASH script to Rally by creating new task.\nDD_load task is based on VMTask.BootRuncommandDelete scenario\n\nChange-Id: Iad7de28f4582bf4b0a26639bbca0d986cf8c38c3\n'}, {'number': 4, 'created': '2017-01-30 12:39:23.000000000', 'files': ['rally/plugins/openstack/scenarios/vm/vmtasks.py', 'samples/tasks/scenarios/vm/dd_load.json', 'rally-jobs/rally-neutron-existing-users.yaml', 'samples/tasks/scenarios/vm/boot-runcommand-delete.json', 'rally/plugins/openstack/scenarios/vm/utils.py', 'samples/tasks/scenarios/vm/dd_load_test.json', 'rally/task/runner.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/2e6a5bf0d9d46644e263b0fcdd671d3852e16c3a', 'message': '[WIP] Move DD_Load task from BASH script to Rally scenario\n\nMove DD_load task from BASH script to Rally by creating new task.\nDD_load task is based on VMTask.BootRuncommandDelete scenario\n\nChange-Id: Iad7de28f4582bf4b0a26639bbca0d986cf8c38c3\n'}]",0,425173,2e6a5bf0d9d46644e263b0fcdd671d3852e16c3a,14,1,4,23094,,,0,"[WIP] Move DD_Load task from BASH script to Rally scenario

Move DD_load task from BASH script to Rally by creating new task.
DD_load task is based on VMTask.BootRuncommandDelete scenario

Change-Id: Iad7de28f4582bf4b0a26639bbca0d986cf8c38c3
",git fetch https://review.opendev.org/openstack/rally refs/changes/73/425173/3 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/scenarios/vm/vmtasks.py', 'samples/tasks/scenarios/vm/dd_load.json', 'rally/plugins/openstack/scenarios/vm/utils.py']",3,f72c09c513f1dd7088b2b11eb29aa5512a2b743f,astarove-dd-load," def _run_command_over_ssh(self, ssh_instance, command): ssh_instance.put_file(command[""local_path""], remote_path[-1], return ssh_instance.execute(cmd, stdin=stdin) def _run_command(self, command, ssh_instance): Call run_command_over_ssh to actually execute the command trough existing ssh channel. :param command: Dictionary specifying command to execute. See `rally info find VMTasks.boot_runcommand_delete' parameter `command' docstring for explanation. :param ssh_instance: existed SSH connection :returns: tuple (exit_status, stdout, stderr) """""" return self._run_command_over_ssh(ssh_instance, command) @atomic.action_timer(""vm.greate_ssh_connection"") def _greate_ssh_instance(self, server_ip, port, username, password, pkey=None, timeout=120, interval=1): """"""Create SSH instance available). :returns: object of SSH class """""" return ssh"," def _run_command_over_ssh(self, ssh, command): ssh.put_file(command[""local_path""], remote_path[-1], return ssh.execute(cmd, stdin=stdin) def _run_command(self, server_ip, port, username, password, command, pkey=None, timeout=120, interval=1): available). Then call run_command_over_ssh to actually execute the command. :param command: Dictionary specifying command to execute. See `rally info find VMTasks.boot_runcommand_delete' parameter `command' docstring for explanation. :returns: tuple (exit_status, stdout, stderr) """""" return self._run_command_over_ssh(ssh, command)",90,17
openstack%2Ftripleo-heat-templates~master~I84faa8176d7967068d715af58f1377cec397b5e6,openstack/tripleo-heat-templates,master,I84faa8176d7967068d715af58f1377cec397b5e6,Add ceph-rbdmirror ansible container service,MERGED,2017-11-16 00:03:53.000000000,2017-12-18 17:52:10.000000000,2017-12-18 17:13:00.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 18002}, {'_account_id': 19564}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-11-16 00:03:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4ce31f75ee749c60cb74ff6f3d3f69b9b97f5ac8', 'message': 'Add ceph-rbdmirror ansible container service\n\nChange-Id: I84faa8176d7967068d715af58f1377cec397b5e6\n'}, {'number': 2, 'created': '2017-11-20 17:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1bb8675b285735399668000c102766b969d9ce82', 'message': 'Add ceph-rbdmirror ansible container service\n\nChange-Id: I84faa8176d7967068d715af58f1377cec397b5e6\nDepends-on: I2288d965da98b637aa91fd49b961f6e524610f60\n'}, {'number': 3, 'created': '2017-11-21 20:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c296a0182b8d2c10a5c9ac5cf73a00c25154c07f', 'message': 'Add ceph-rbdmirror ansible container service\n\nChange-Id: I84faa8176d7967068d715af58f1377cec397b5e6\nDepends-on: I2288d965da98b637aa91fd49b961f6e524610f60\n'}, {'number': 4, 'created': '2017-11-22 20:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/56a43584a2f53979de96d87ba89e9af9a28d5a58', 'message': 'Add ceph-rbdmirror ansible container service\n\nChange-Id: I84faa8176d7967068d715af58f1377cec397b5e6\nDepends-on: I2288d965da98b637aa91fd49b961f6e524610f60\n'}, {'number': 5, 'created': '2017-11-28 14:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c5e85ea5e72189307c8762ca0fd1f543b04afa1f', 'message': 'Add ceph-rbdmirror ansible container service\n\nChange-Id: I84faa8176d7967068d715af58f1377cec397b5e6\nDepends-on: I2288d965da98b637aa91fd49b961f6e524610f60\n'}, {'number': 6, 'created': '2017-12-05 20:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c3ccab2b7e3a3441e36a9eef1735977bedb89b73', 'message': 'Add ceph-rbdmirror ansible container service\n\nChange-Id: I84faa8176d7967068d715af58f1377cec397b5e6\nDepends-on: I2288d965da98b637aa91fd49b961f6e524610f60\n'}, {'number': 7, 'created': '2017-12-14 13:24:19.000000000', 'files': ['environments/ceph-ansible/ceph-rbdmirror.yaml', 'docker/services/ceph-ansible/ceph-rbdmirror.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3a94c99bde8d4c31a136738e4364da5b3528370d', 'message': 'Add ceph-rbdmirror ansible container service\n\nChange-Id: I84faa8176d7967068d715af58f1377cec397b5e6\nDepends-on: I2288d965da98b637aa91fd49b961f6e524610f60\n'}]",13,520244,3a94c99bde8d4c31a136738e4364da5b3528370d,80,6,7,19564,,,0,"Add ceph-rbdmirror ansible container service

Change-Id: I84faa8176d7967068d715af58f1377cec397b5e6
Depends-on: I2288d965da98b637aa91fd49b961f6e524610f60
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/44/520244/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/ceph-ansible/ceph-rbdmirror.yaml', 'docker/services/ceph-ansible/ceph-rbdmirror.yaml']",2,4ce31f75ee749c60cb74ff6f3d3f69b9b97f5ac8,add-rbd-mirror-ansible,"heat_template_version: pike description: > Ceph RBD Mirror service. parameters: ServiceData: default: {} description: Dictionary packing service data type: json ServiceNetMap: default: {} description: Mapping of service_name -> network name. Typically set via parameter_defaults in the resource registry. This mapping overrides those in ServiceNetMapDefaults. type: json DefaultPasswords: default: {} type: json RoleName: default: '' description: Role name on which the service is applied type: string RoleParameters: default: {} description: Parameters specific to the role type: json EndpointMap: default: {} description: Mapping of service endpoint -> protocol. Typically set via parameter_defaults in the resource registry. type: json CephRbdMirrorCopyAdminKey: default: false description: Some admins like to copy the admin key everywhere type: boolean CephRbdMirrorLocalUser: default: 'admin' description: deprecated generic local user id for pre-Luminous releases (will probably be removed) type: string CephRbdMirrorConfigure: default: false description: Perform mirror configuration between local and remote pool type: boolean CephRbdMirrorPool: default: '' description: Name of the local pool to mirror to remote cluster type: string CephRbdMirrorRemoteCluster: default: 'not-ceph' description: The name given to the remote Ceph cluster from the local cluster. keys will reside in the /etc/ceph directory type: string CephRbdMirrorRemoteUser: default: '' description: The rbd-mirror daemon needs a user to authenticate with the remote cluster. By default, this key should be available under /etc/ceph/<remote_cluster>.client.<remote_user>.keyring type: string resources: CephBase: type: ./ceph-base.yaml properties: ServiceData: {get_param: ServiceData} ServiceNetMap: {get_param: ServiceNetMap} DefaultPasswords: {get_param: DefaultPasswords} EndpointMap: {get_param: EndpointMap} RoleName: {get_param: RoleName} RoleParameters: {get_param: RoleParameters} outputs: role_data: description: Role data for the Ceph RBD Mirror service. value: service_name: ceph_rbdmirror upgrade_tasks: [] step_config: '' puppet_config: config_image: '' config_volume: '' step_config: '' docker_config: {} workflow_tasks: {get_attr: [CephBase, role_data, workflow_tasks]} config_settings: map_merge: - tripleo.ceph_rbdmirror.firewall_rules: '113 ceph_rbdmirror': dport: - '6800-7300' - ceph_rbdmirror_ansible_vars: map_merge: - {get_attr: [CephBase, role_data, config_settings, ceph_common_ansible_vars]} - copy_admin_key: {get_param: CephRbdMirrorCopyAdminKey} ceph_rbd_mirror_local_user: {get_param: CephRbdMirrorLocalUser} ceph_rbd_mirror_configure: {get_param: CephRbdMirrorConfigure} ceph_rbd_mirror_pool: {get_param: CephRbdMirrorPool} ceph_rbd_mirror_remote_cluster: {get_param: CephRbdMirrorRemoteCluster} ceph_rbd_mirror_remote_user: {get_param: CephRbdMirrorRemoteUser} ",,102,0
openstack%2Frally~master~Ic080e77aaa254a3af4b8aa6e9449557ba09debd5,openstack/rally,master,Ic080e77aaa254a3af4b8aa6e9449557ba09debd5,[WIP] Fix usage of keystone v3 on gate,ABANDONED,2016-08-01 13:32:13.000000000,2017-12-18 17:52:02.000000000,,"[{'_account_id': 9545}, {'_account_id': 14817}, {'_account_id': 18462}]","[{'number': 1, 'created': '2016-08-01 13:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/535284d1369eebcadf5c0312a548d12c9098fe16', 'message': '[WIP] Fix usage of keystone v3 on gate\n\nChange-Id: Ic080e77aaa254a3af4b8aa6e9449557ba09debd5\n'}, {'number': 2, 'created': '2016-08-01 15:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/afacee08eac5b5401805d214cff4e8b8bed23180', 'message': '[WIP] Fix usage of keystone v3 on gate\n\nChange-Id: Ic080e77aaa254a3af4b8aa6e9449557ba09debd5\n'}, {'number': 3, 'created': '2016-08-02 13:43:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/59045cb11e3b859d55c534ee0f10bead9fa13adf', 'message': '[WIP] Fix usage of keystone v3 on gate\n\nChange-Id: Ic080e77aaa254a3af4b8aa6e9449557ba09debd5\n'}, {'number': 4, 'created': '2016-08-03 14:00:02.000000000', 'files': ['devstack/lib/rally'], 'web_link': 'https://opendev.org/openstack/rally/commit/8f5f5ea1943f526e0cfb59e500fa64cfbd4c34fe', 'message': '[WIP] Fix usage of keystone v3 on gate\n\nChange-Id: Ic080e77aaa254a3af4b8aa6e9449557ba09debd5\n'}]",1,349504,8f5f5ea1943f526e0cfb59e500fa64cfbd4c34fe,16,3,4,12395,,,0,"[WIP] Fix usage of keystone v3 on gate

Change-Id: Ic080e77aaa254a3af4b8aa6e9449557ba09debd5
",git fetch https://review.opendev.org/openstack/rally refs/changes/04/349504/4 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/rally'],1,535284d1369eebcadf5c0312a548d12c9098fe16,fix_v3_gate,"echo $IDENTITY_API_VERSION if [[ ""$IDENTITY_API_VERSION"" -eq 2.0 ]]if [[ ""$IDENTITY_API_VERSION"" -eq 3 ]]","if [[ ""$IDENTITY_API_VERSION"" == 2.0 ]]if [[ ""$IDENTITY_API_VERSION"" == 3 ]]",3,2
openstack%2Frally~master~I598a45f07c6976f1a11decd88e82b38501fdaf9b,openstack/rally,master,I598a45f07c6976f1a11decd88e82b38501fdaf9b,[WIP][CI]Use existing users in 'create_and_list_networks',ABANDONED,2016-05-25 13:31:24.000000000,2017-12-18 17:51:19.000000000,,"[{'_account_id': 7369}, {'_account_id': 8491}, {'_account_id': 10475}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-05-25 13:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a83a472315dc236ab55989ee22f505daf9d85ad4', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 2, 'created': '2016-05-25 15:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8789c10bedff976312634a97798bc53a9818967d', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 3, 'created': '2016-05-26 10:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9c433a46115b2545c2f10e667fc62452479bba1a', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 4, 'created': '2016-05-26 10:55:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7fdf8a3c5a49d6df5a50ff8420b638dc3b9034f5', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 5, 'created': '2016-05-26 12:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9144905b0afa0e41c4810b91acdca9d6371a3ce5', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 6, 'created': '2016-05-26 13:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ebb422a13288be413ae108bd951409afce894726', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 7, 'created': '2016-05-26 14:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/aea6641eb13751932d872698e9e89a5581f6f7a5', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 8, 'created': '2016-05-27 06:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e7a526a17751a4a247da1092bfb3eb3e9f19cf66', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 9, 'created': '2016-05-27 08:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c2f375bc874e33d24a282fa713044f8cac20c408', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 10, 'created': '2016-05-27 08:32:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b3745a117a8a6d971d0a46d3a3065162351611c8', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 11, 'created': '2016-05-27 08:37:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4194186141875f35e75ddd7f403fdd69950ba6d1', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 12, 'created': '2016-05-27 09:27:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4dd2cec355b9971d555a8edfb3360ab8f8b12e6f', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 13, 'created': '2016-05-27 15:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1e78b8aa6c186572a0a54f7ed8b5e9fbf71a22f6', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 14, 'created': '2016-05-27 17:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/19e8e5778f96d2747a893947188c5ea3d8407517', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 15, 'created': '2016-05-30 10:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4c16d23f3f9d04ce60b909b9731c6e1ef497a657', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 16, 'created': '2016-05-31 11:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/eba575375d9a2f6f877e64cd4a421e0045d9d430', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 17, 'created': '2016-05-31 12:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3553728fd876f854a413a8abdbb91e35b483ab3e', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 18, 'created': '2016-05-31 13:56:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0a6eac9875a67215cdbab20c6dde1ddf034e3380', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 19, 'created': '2016-05-31 14:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/11a598ec2112ebd2d0c295476c67662512bef759', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 20, 'created': '2016-05-31 15:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d1ab55603cc28232c0aebcfa81ccd304576e9ac7', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 21, 'created': '2016-06-01 09:54:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4c1e2bb3aa371922252d278f11ec5b8f38a314c1', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 22, 'created': '2016-06-01 10:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2de72c21dcbab1a17db1decdc1eacab95d227ed4', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 23, 'created': '2016-06-01 11:02:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/79ca3b0f22033213ac069a06efb080c83fbfcfae', 'message': ""Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 24, 'created': '2016-06-01 11:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/87d9f73a159e81aea28ebcdeb444314cb557cac3', 'message': ""[WIP][CI]Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 25, 'created': '2016-06-01 13:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f395ee3a2acbeea7c26caa3ae951af2409aac72f', 'message': ""[WIP][CI]Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 26, 'created': '2016-06-02 08:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7cb1172cbf8ea3042861b47732d36a06cc24fc9b', 'message': ""[WIP][CI]Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 27, 'created': '2016-06-02 11:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d077a127543f5d74ab29903f52ee6f69e4b06e4f', 'message': ""[WIP][CI]Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 28, 'created': '2016-06-02 12:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/787aa5cab7c955c7372c55ad1ab7151dc3109859', 'message': ""[WIP][CI]Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}, {'number': 29, 'created': '2016-06-02 13:15:05.000000000', 'files': ['tests/ci/osresources.py', 'rally-jobs/rally-neutron.yaml', 'tests/ci/rally-gate.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/d42c7125852bad5d291b6473d6aade41670b52cd', 'message': ""[WIP][CI]Use existing users in 'create_and_list_networks'\n\nChange-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b\n""}]",6,320989,d42c7125852bad5d291b6473d6aade41670b52cd,83,4,29,8491,,,0,"[WIP][CI]Use existing users in 'create_and_list_networks'

Change-Id: I598a45f07c6976f1a11decd88e82b38501fdaf9b
",git fetch https://review.opendev.org/openstack/rally refs/changes/89/320989/9 && git format-patch -1 --stdout FETCH_HEAD,['rally-jobs/rally-neutron.yaml'],1,a83a472315dc236ab55989ee22f505daf9d85ad4,existing-users-test, #users: #tenants: {{smoke or 3}} #users_per_tenant: {{smoke or 2}}, users: tenants: {{smoke or 3}} users_per_tenant: {{smoke or 2}},3,3
openstack%2Frally~master~Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb,openstack/rally,master,Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb,Fix TypeError in tempest_tests_exists validator,ABANDONED,2016-03-23 11:23:32.000000000,2017-12-18 17:49:44.000000000,,"[{'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8491}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 11034}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 15371}, {'_account_id': 20196}, {'_account_id': 20299}, {'_account_id': 20777}]","[{'number': 1, 'created': '2016-03-23 11:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1501e750b78b637916b4151801335a7ab838fe7a', 'message': 'syntax err on wrong_tests arithmetic\n\nTrivialFix\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 2, 'created': '2016-03-24 06:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d50a1da6ab79bd1380a0a91d73149f47d60b6d0c', 'message': 'syntax err on wrong_tests arithmetic\n\nTrivialFix\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 3, 'created': '2016-03-30 14:11:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a9029df08fb0ff630c87dd5440d9a4904c799481', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nTrivialFix\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 4, 'created': '2016-04-08 11:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3762d638c3f3e8093ecb00bc8aab6561cade33e2', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nTrivialFix\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 5, 'created': '2016-04-08 13:33:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/db341f5f7c804d0600b0707b22de67f2d3c055c7', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nTrivialFix\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 6, 'created': '2016-04-08 18:29:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d3b96bfa9939bf0461104f996aebec65f3b5c7e3', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nTrivialFix\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 7, 'created': '2016-04-21 07:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2bc746891ecac955694ed1a3ac6fc9d151534f2a', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 8, 'created': '2016-04-27 14:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3f6084c5138c39c82ac218f3b56f0637cd366a9a', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 9, 'created': '2016-04-28 17:32:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/11788f378c52de23423009a2dbb4e7e2751a0e17', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 10, 'created': '2016-04-28 19:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c3957092a04ca8aa7e39c152bbce83a94b2ec523', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 11, 'created': '2016-04-28 21:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/257506db1469143f310f30f7c7ea43ab4444cd14', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 12, 'created': '2016-05-12 11:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/487d396671537f11b632f18c0016223a11f8edfe', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 13, 'created': '2016-05-23 09:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8a117b80bb94946d16f3f428c1dd032fab06f284', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 14, 'created': '2016-05-30 11:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c76bd484f0546a111c569a12c9160f4ae3c27677', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 15, 'created': '2016-05-30 12:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5a2f3240b8007d782433c9a3ed0d20bea7864108', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 16, 'created': '2016-05-30 13:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/40b94d6a5cb12533be750d719a4ccbf36274b114', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}, {'number': 17, 'created': '2016-05-30 18:54:36.000000000', 'files': ['rally/task/validation.py', 'rally-jobs/unstable-neutron.yaml', 'rally/plugins/openstack/context/not_for_production/tempest.py', 'tests/unit/task/test_validation.py', 'rally/common/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/4bab3e6198694671bfa851fb9c3f307904da41be', 'message': 'Fix TypeError in tempest_tests_exists validator\n\nTempest.discover_tests returns a list, but validator\ntempest_tests_exists expects set. This patch casts the\nlist into a set, without that you get ""TypeError"",\nwhen doing arithmetic on the list.\n\nChange-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb\n'}]",10,296379,4bab3e6198694671bfa851fb9c3f307904da41be,95,12,17,15371,,,0,"Fix TypeError in tempest_tests_exists validator

Tempest.discover_tests returns a list, but validator
tempest_tests_exists expects set. This patch casts the
list into a set, without that you get ""TypeError"",
when doing arithmetic on the list.

Change-Id: Ib1c927faf86fd7555c2f703968fd9b3a4dcd74cb
",git fetch https://review.opendev.org/openstack/rally refs/changes/79/296379/15 && git format-patch -1 --stdout FETCH_HEAD,['rally/task/validation.py'],1,1501e750b78b637916b4151801335a7ab838fe7a,bug/type_error, wrong_tests = list(set(tests) - set(allowed_tests)), wrong_tests = set(tests) - allowed_tests,1,1
openstack%2Frally~master~Ia1bb4b396cfdedc6b2ece837316ea711ab28bbdb,openstack/rally,master,Ia1bb4b396cfdedc6b2ece837316ea711ab28bbdb,Improve performance of _get_network_id,ABANDONED,2016-04-20 16:15:21.000000000,2017-12-18 17:49:05.000000000,,"[{'_account_id': 1736}, {'_account_id': 4428}, {'_account_id': 6172}, {'_account_id': 6577}, {'_account_id': 6835}, {'_account_id': 7132}, {'_account_id': 7369}, {'_account_id': 7428}, {'_account_id': 8491}, {'_account_id': 8576}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 11748}, {'_account_id': 12395}, {'_account_id': 13609}, {'_account_id': 13919}, {'_account_id': 14817}, {'_account_id': 17523}]","[{'number': 1, 'created': '2016-04-20 16:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3806afad760b5466595efc37105e48848a77d9af', 'message': 'Improve performance of _get_network_id\n\nUse network-show instead of network-list for exact match to\nimprove performance.\n\nChange-Id: Ia1bb4b396cfdedc6b2ece837316ea711ab28bbdb\nCloses-Bug: #1572617\n'}, {'number': 2, 'created': '2016-04-21 04:00:02.000000000', 'files': ['rally/plugins/openstack/scenarios/neutron/utils.py', 'tests/unit/plugins/openstack/scenarios/neutron/test_utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/68df2885df42d32d334b53b3fa1de2a7a1e6f0fa', 'message': 'Improve performance of _get_network_id\n\nUse network-show instead of network-list for exact match to\nimprove performance.\n\nChange-Id: Ia1bb4b396cfdedc6b2ece837316ea711ab28bbdb\nCloses-Bug: #1572617\n'}]",12,308444,68df2885df42d32d334b53b3fa1de2a7a1e6f0fa,17,18,2,17523,,,0,"Improve performance of _get_network_id

Use network-show instead of network-list for exact match to
improve performance.

Change-Id: Ia1bb4b396cfdedc6b2ece837316ea711ab28bbdb
Closes-Bug: #1572617
",git fetch https://review.opendev.org/openstack/rally refs/changes/44/308444/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/scenarios/neutron/utils.py', 'tests/unit/plugins/openstack/scenarios/neutron/test_utils.py']",2,3806afad760b5466595efc37105e48848a77d9af,bug/1572617," self.clients(""neutron"").show_network.return_value = networks[0] self.clients(""neutron"").show_network.assert_called_once_with(network) self.clients(""neutron"").show_network.reset_mock() self.clients(""neutron"").show_network.assert_called_once_with(network) self.clients(""neutron"").show_network.reset_mock() self.clients(""neutron"").show_network.return_value = None self.clients(""neutron"").show_network.assert_called_once_with( ""absent-network"")", self.scenario._list_networks = mock.Mock(return_value=networks) self.scenario._list_networks.assert_called_once_with( atomic_action=False) self.scenario._list_networks.reset_mock() self.scenario._list_networks.assert_called_once_with( atomic_action=False) self.scenario._list_networks.reset_mock() self.scenario._list_networks.assert_called_once_with( atomic_action=False),12,14
openstack%2Ftripleo-upgrade~master~I3838d95358522113ef869dfc99d716728f4bf80e,openstack/tripleo-upgrade,master,I3838d95358522113ef869dfc99d716728f4bf80e,Add the possibility to provide a custom UpgradeInitCommand.,MERGED,2017-12-12 15:47:53.000000000,2017-12-18 17:44:09.000000000,2017-12-18 17:44:08.000000000,"[{'_account_id': 8297}, {'_account_id': 8449}, {'_account_id': 10267}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 20775}, {'_account_id': 21537}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2017-12-12 15:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/862b9fa0c7de9b8124efa2fad9b7983affcc3101', 'message': 'Add the possibility to provide a custom UpgradeInitCommand.\n\nIn order to not have to deploy manually the repo on the overcloud\nbefore upgrade.\n\nThis will create a template with the specified commands and add it to\nthe list of templates during upgrade.\n\nChange-Id: I3838d95358522113ef869dfc99d716728f4bf80e\n'}, {'number': 2, 'created': '2017-12-13 16:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/9a880de32755f4f4968e38a58c36e96c24660f3d', 'message': 'Add the possibility to provide a custom UpgradeInitCommand.\n\nIn order to not have to deploy manually the repo on the overcloud\nbefore upgrade.\n\nThis will create a template with the specified commands and add it to\nthe list of templates during upgrade.\n\nChange-Id: I3838d95358522113ef869dfc99d716728f4bf80e\n'}, {'number': 3, 'created': '2017-12-14 10:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/7eed1e5ca7643c2094736a59e089daf9c6dd7958', 'message': 'Add the possibility to provide a custom UpgradeInitCommand.\n\nIn order to not have to deploy manually the repo on the overcloud\nbefore upgrade.\n\nThis will create a template with the specified commands and add it to\nthe list of templates during upgrade.\n\nChange-Id: I3838d95358522113ef869dfc99d716728f4bf80e\n'}, {'number': 4, 'created': '2017-12-18 11:19:55.000000000', 'files': ['templates/upgrade_init_command.yaml.j2', 'tasks/upgrade/create-upgrade-scripts.yaml', 'defaults/main.yml', 'README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/8067d83dcb83e6a43b75143e4459135145f3a1ef', 'message': 'Add the possibility to provide a custom UpgradeInitCommand.\n\nIn order to not have to deploy manually the repo on the overcloud\nbefore upgrade.\n\nThis will create a template with the specified commands and add it to\nthe list of templates during upgrade.\n\nChange-Id: I3838d95358522113ef869dfc99d716728f4bf80e\n'}]",12,527435,8067d83dcb83e6a43b75143e4459135145f3a1ef,31,10,4,26343,,,0,"Add the possibility to provide a custom UpgradeInitCommand.

In order to not have to deploy manually the repo on the overcloud
before upgrade.

This will create a template with the specified commands and add it to
the list of templates during upgrade.

Change-Id: I3838d95358522113ef869dfc99d716728f4bf80e
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/35/527435/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/upgrade_init_command.yaml.j2', 'tasks/upgrade/create-upgrade-scripts.yaml', 'defaults/main.yml', 'README.md']",4,862b9fa0c7de9b8124efa2fad9b7983affcc3101,merge_tripleo-upgrade,"* Repositories containing packages to be upgraded are already installed on undercloud and overcloud nodes (or, for overcloud, define an upgrade_init_command variable) upgrade_init_command: | rhos_release -P 12 String, defines a custom upgrade init command to be taken into account during overcloud upgrade. ",* Repositories containing packages to be upgraded are already installed on undercloud and overcloud nodes,22,1
openstack%2Ftripleo-heat-templates~master~I7e20ab2111e7d71380da844a15835b5fac1125d9,openstack/tripleo-heat-templates,master,I7e20ab2111e7d71380da844a15835b5fac1125d9,Add ovs hardware Offload support to ovs mechansim driver,MERGED,2017-09-26 08:17:51.000000000,2017-12-18 17:44:07.000000000,2017-12-18 17:44:07.000000000,"[{'_account_id': 3}, {'_account_id': 6681}, {'_account_id': 8655}, {'_account_id': 8873}, {'_account_id': 12171}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25241}]","[{'number': 1, 'created': '2017-09-26 08:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/31fed2a6ce662f7b1cfd22444d54a09a85a5b4b5', 'message': 'Adds environment file for OVS Hardware Offload\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 2, 'created': '2017-10-04 00:24:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/493171bc68a3dc28670844b61573534a78dc64b1', 'message': 'Adds environment file for OVS Hardware Offload\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 3, 'created': '2017-10-04 00:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0fe81e4ae52b5f621b136a7d7c8f8dce53ebbb3e', 'message': 'Adds environment file for OVS Hardware Offload\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 4, 'created': '2017-10-04 00:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bca0984ced742dbc7b5ee01bef79b74ffd1374e6', 'message': 'Adds environment file for OVS Hardware Offload\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 5, 'created': '2017-10-24 18:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b68d7f3139b2650fa9c5b134e073f036414962be', 'message': 'Adds environment file for OVS Hardware Offload\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 6, 'created': '2017-11-02 12:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2063243f87fd17fbe5e97ffac7af194cc5a683cc', 'message': 'Adds environment file for OVS Hardware Offload\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 7, 'created': '2017-11-04 17:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/79165610e1078770b7944f6fffbf799725a3f7dc', 'message': 'Adds environment file for OVS Hardware Offload\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 8, 'created': '2017-11-06 11:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/09c709cc84279fb0e5dc21469ab7fbcdcecee277', 'message': 'Adds environment file for OVS Hardware Offload\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\nImplements: tripleo-ovs-hw-offload\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 9, 'created': '2017-11-06 12:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ddec41c1c29af7faacd842a8cada9fc79b0acf2e', 'message': 'Adds environment file for OVS Hardware Offload\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\nImplements: blueprint tripleo-ovs-hw-offload\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 10, 'created': '2017-11-14 13:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/34e419893960798a7b193b24f712f51864f6ee5e', 'message': 'Adds environment file for OVS Hardware Offload\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\nImplements: blueprint tripleo-ovs-hw-offload\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 11, 'created': '2017-11-15 10:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/664bad16d506f93bbc0837af306fce513e66fa12', 'message': 'Adds environment file for OVS Hardware Offload\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\nImplements: blueprint tripleo-ovs-hw-offload\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 12, 'created': '2017-11-15 13:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c1f4f400858315abd39c2efda6d0d2aa013ae121', 'message': 'Adds environment file for OVS Hardware Offload\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\nImplements: blueprint tripleo-ovs-hw-offload\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 13, 'created': '2017-11-16 10:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3e6ca268666dcd3363b5dceedb9fb28b6871986c', 'message': 'Add ovs hardware Offload support to ovs mechansim driver\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\nImplements: blueprint tripleo-ovs-hw-offload\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 14, 'created': '2017-11-16 12:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cecc29364ab517d6e1199b13d3955c0e74467b0f', 'message': 'Add ovs hardware Offload support to ovs mechansim driver\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\nImplements: blueprint tripleo-ovs-hw-offload\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 15, 'created': '2017-12-11 20:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/63282c1e1830c498f0a31e5887e87fee7f3631fd', 'message': 'Add ovs hardware Offload support to ovs mechansim driver\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\nImplements: blueprint tripleo-ovs-hw-offload\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 16, 'created': '2017-12-13 14:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/195f110eae3ed273b20212877232862152b08e68', 'message': 'Add ovs hardware Offload support to ovs mechansim driver\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\nImplements: blueprint tripleo-ovs-hw-offload\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 17, 'created': '2017-12-13 14:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/65eaeae0e46d0bc26ee69fc605859816082b5cae', 'message': 'Add ovs hardware Offload support to ovs mechansim driver\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\nImplements: blueprint tripleo-ovs-hw-offload\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 18, 'created': '2017-12-13 14:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fe7d9c50a9e339d4cd78e575af8e467440ea2de0', 'message': 'Add ovs hardware Offload support to ovs mechansim driver\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\nImplements: blueprint tripleo-ovs-hw-offload\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}, {'number': 19, 'created': '2017-12-18 11:56:29.000000000', 'files': ['puppet/services/neutron-ovs-agent.yaml', 'releasenotes/notes/ovs-hw-offload-a6bf0fa9c39a8204.yaml', 'environments/neutron-ovs-hw-offload.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f3f1437cb23cc24d1d34cf61ffe27779ff688dc7', 'message': 'Add ovs hardware Offload support to ovs mechansim driver\n\nDepends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6\nDepends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\nImplements: blueprint tripleo-ovs-hw-offload\n\nChange-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9\n'}]",25,507401,f3f1437cb23cc24d1d34cf61ffe27779ff688dc7,104,10,19,12171,,,0,"Add ovs hardware Offload support to ovs mechansim driver

Depends-On: I3c0d24a31f0a1cac2cb8c5da8125051d4348eed6
Depends-On  I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1
Implements: blueprint tripleo-ovs-hw-offload

Change-Id: I7e20ab2111e7d71380da844a15835b5fac1125d9
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/01/507401/19 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/services/neutron-ovs-agent.yaml', 'environments/neutron-ovs-hw-offload.yaml']",2,31fed2a6ce662f7b1cfd22444d54a09a85a5b4b5,bp/tripleo-ovs-hw-offload,"# A Heat environment file that ena:`bles OVS Hardware Offload in the overcloud. # This works by configuring SR-IOV NIC with switchdev and OVS Hardware Offload on # compute nodes. The feature supported in OVS 2.8.0 resource_registry: OS::TripleO::Services::NeutronSriovHostConfig: ../puppet/services/neutron-sriov-host-config.yaml parameter_defaults: # Neutron OVS HW Offload NeutronOVSHwOffload: 'True' NovaSchedulerDefaultFilters: ['RetryFilter','AvailabilityZoneFilter','RamFilter','ComputeFilter','ComputeCapabilitiesFilter','ImagePropertiesFilter','ServerGroupAntiAffinityFilter','ServerGroupAffinityFilter','PciPassthroughFilter'] NovaSchedulerAvailableFilters: [""nova.scheduler.filters.all_filters"",""nova.scheduler.filters.pci_passthrough_filter.PciPassthroughFilter""] # Number of VFs that needs to be configured for a physical interface NeutronSriovNumVFs: ""ens3f0:4:switchdev"" NovaPCIPassthrough: - devname: ""ens3f0"" physical_network: ""sriov"" # Kernel arguments for Compute node ComputeParameters: KernelArgs: ""intel_iommu=on iommu=pt"" ",,31,0
openstack%2Fopenstack-helm-infra~master~I66b845f26b44ca7780be22fb77a5061a00834339,openstack/openstack-helm-infra,master,I66b845f26b44ca7780be22fb77a5061a00834339,Create NFS provisioner per service,ABANDONED,2017-12-02 02:47:18.000000000,2017-12-18 17:42:11.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-12-02 02:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/64bf0bf56df7305316ae492e8a8321695fcf346e', 'message': 'Create NFS provisioner per service\n\nDeploys an NFS provisioner for both Elasticsearch and Prometheus\nto create backing volumes per service\n\nChange-Id: I66b845f26b44ca7780be22fb77a5061a00834339\n'}, {'number': 2, 'created': '2017-12-02 03:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f3f7600860e78f6ab938d2ce7661ae2006e7a7d6', 'message': 'Create NFS provisioner per service\n\nDeploys an NFS provisioner for both Elasticsearch and Prometheus\nto create backing volumes per service\n\nChange-Id: I66b845f26b44ca7780be22fb77a5061a00834339\n'}, {'number': 3, 'created': '2017-12-02 03:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/47a12575c2c0ce0d2f166cfa11df86ab84e9d81a', 'message': 'Create NFS provisioner per service\n\nDeploys an NFS provisioner for both Elasticsearch and Prometheus\nto create backing volumes per service\n\nChange-Id: I66b845f26b44ca7780be22fb77a5061a00834339\n'}, {'number': 4, 'created': '2017-12-02 04:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/4b24e699204b0c83dd694b97d40868db9220b6d1', 'message': 'WIP: Create NFS provisioner per service\n\nDeploys an NFS provisioner for both Elasticsearch and Prometheus\nto create backing volumes per service\n\nChange-Id: I66b845f26b44ca7780be22fb77a5061a00834339\n'}, {'number': 5, 'created': '2017-12-02 04:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e35b0432ac0938c0c396c050402150edab2963eb', 'message': 'WIP: Create NFS provisioner per service\n\nDeploys an NFS provisioner for both Elasticsearch and Prometheus\nto create backing volumes per service\n\nChange-Id: I66b845f26b44ca7780be22fb77a5061a00834339\n'}, {'number': 6, 'created': '2017-12-02 04:59:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/42f952044047c8aade5fb6c8b74573aa7496ece3', 'message': 'WIP: Create NFS provisioner per service\n\nDeploys an NFS provisioner for both Elasticsearch and Prometheus\nto create backing volumes per service\n\nChange-Id: I66b845f26b44ca7780be22fb77a5061a00834339\n'}, {'number': 7, 'created': '2017-12-02 05:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cb199dc9f9688e58ceca3e44be8fb9779b999eb2', 'message': 'WIP: Create NFS provisioner per service\n\nDeploys an NFS provisioner for both Elasticsearch and Prometheus\nto create backing volumes per service\n\nChange-Id: I66b845f26b44ca7780be22fb77a5061a00834339\n'}, {'number': 8, 'created': '2017-12-02 05:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6d74413f730ddb387f5a47ac5dae382ccfacdfcf', 'message': 'Create NFS provisioner per service\n\nDeploys an NFS provisioner for both Elasticsearch and Prometheus\nto create backing volumes per service\n\nChange-Id: I66b845f26b44ca7780be22fb77a5061a00834339\n'}, {'number': 9, 'created': '2017-12-02 05:25:25.000000000', 'files': ['nfs-provisioner/templates/deployment.yaml', 'tools/gate/chart-deploys/default.yaml', 'nfs-provisioner/templates/configmap-bin.yaml', 'nfs-provisioner/templates/job-image-repo-sync.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d1fd7f216939b3b9de25ee1f79f1587990c415e4', 'message': 'Create NFS provisioner per service\n\nDeploys an NFS provisioner for both Elasticsearch and Prometheus\nto create backing volumes per service\n\nChange-Id: I66b845f26b44ca7780be22fb77a5061a00834339\n'}]",0,524776,d1fd7f216939b3b9de25ee1f79f1587990c415e4,13,1,9,17591,,,0,"Create NFS provisioner per service

Deploys an NFS provisioner for both Elasticsearch and Prometheus
to create backing volumes per service

Change-Id: I66b845f26b44ca7780be22fb77a5061a00834339
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/76/524776/6 && git format-patch -1 --stdout FETCH_HEAD,['tools/gate/chart-deploys/default.yaml'],1,64bf0bf56df7305316ae492e8a8321695fcf346e,nfs_per_service, - prometheus_nfs_provisioner - elasticsearch_nfs_provisioner prometheus_nfs_provisioner: chart_name: nfs-provisioner release: prometheus-nfs-provisioner namespace: openstack values: labels: node_selector_key: openstack-control-plane node_selector_value: enabled storageclass: name: prometheus-general manifests: clusterrole: false storage_class: prometheus-general requests: storage: 10Gi elasticsearch_nfs_provisioner: chart_name: nfs-provisioner release: elasticsearch-nfs-provisioner namespace: openstack values: labels: node_selector_key: openstack-control-plane node_selector_value: enabled storageclass: name: elasticsearch-general manifests: clusterrole: false serviceaccount: false storage_class: elasticsearch-general, enabled: false manifests: pvc: false enabled: false,33,4
openstack%2Fpatrole~master~I91ff96a85e9162af1f9510db1431a38fc2e3ea13,openstack/patrole,master,I91ff96a85e9162af1f9510db1431a38fc2e3ea13,"""get_association_qos"" test using wrong policy rule",MERGED,2017-12-15 09:59:53.000000000,2017-12-18 17:40:14.000000000,2017-12-18 17:40:14.000000000,"[{'_account_id': 8556}, {'_account_id': 17896}, {'_account_id': 22348}, {'_account_id': 23185}, {'_account_id': 23186}, {'_account_id': 25571}]","[{'number': 1, 'created': '2017-12-15 09:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/d0d60ca02d15b4040bf189d8f60db04bd46d8a2d', 'message': '""get_association_qos"" test using wrong policy rule\n\nAssociate list function should use under qos_specs_manage:get_all\npolicy rule [0]\n[0]https://github.com/openstack/cinder/blob/master/cinder/policies/qos_specs.py#L40\n\nChange-Id: I91ff96a85e9162af1f9510db1431a38fc2e3ea13\n'}, {'number': 2, 'created': '2017-12-15 11:42:12.000000000', 'files': ['patrole_tempest_plugin/tests/api/volume/test_qos_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/27e0c8ed4ec17611df886057f4d7ab4bfb0532d8', 'message': '""get_association_qos"" test using wrong policy rule\n\nAssociate list function should use under qos_specs_manage:get_all\npolicy rule [0]\n[0]https://github.com/openstack/cinder/blob/master/cinder/policies/qos_specs.py#L40\n\nChange-Id: I91ff96a85e9162af1f9510db1431a38fc2e3ea13\n'}]",1,528217,27e0c8ed4ec17611df886057f4d7ab4bfb0532d8,10,6,2,25695,,,0,"""get_association_qos"" test using wrong policy rule

Associate list function should use under qos_specs_manage:get_all
policy rule [0]
[0]https://github.com/openstack/cinder/blob/master/cinder/policies/qos_specs.py#L40

Change-Id: I91ff96a85e9162af1f9510db1431a38fc2e3ea13
",git fetch https://review.opendev.org/openstack/patrole refs/changes/17/528217/1 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/volume/test_qos_rbac.py'],1,d0d60ca02d15b4040bf189d8f60db04bd46d8a2d,," rule=""volume_extension:qos_specs_manage:get_all"")"," rule=""volume_extension:qos_specs_manage:get"")",1,1
openstack%2Fopenstack-helm-infra~master~I6ea66468e2814398785470198c5d9ebb34244f09,openstack/openstack-helm-infra,master,I6ea66468e2814398785470198c5d9ebb34244f09,Add support to back NFS with volume claims,ABANDONED,2017-12-03 00:04:24.000000000,2017-12-18 17:23:55.000000000,,"[{'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}]","[{'number': 1, 'created': '2017-12-03 00:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e2149fd9074022db7d4639d86eedcfef70943c42', 'message': 'Add support to back NFS with volume claims\n\nAdds the ability for nfs to use a volume claim for providing\nstorage for other services. This provides the ability to provide\nread-write-many access backed by a read-write-once storage class,\nin situations where such a requirement exists\n\nChange-Id: I6ea66468e2814398785470198c5d9ebb34244f09\n'}, {'number': 2, 'created': '2017-12-03 00:32:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/494348173f5634763031d4ed913308286ebdea0e', 'message': 'Add support to back NFS with volume claims\n\nAdds the ability for nfs to use a volume claim for providing\nstorage for other services. This provides the ability to provide\nread-write-many access backed by a read-write-once storage class,\nin situations where such a requirement exists\n\nChange-Id: I6ea66468e2814398785470198c5d9ebb34244f09\n'}, {'number': 3, 'created': '2017-12-17 19:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c91ffb0f0ab1666dd0c3f4fe74309c84fbb768ce', 'message': 'Add support to back NFS with volume claims\n\nAdds the ability for nfs to use a volume claim for providing\nstorage for other services. This provides the ability to provide\nread-write-many access backed by a read-write-once storage class,\nin situations where such a requirement exists\n\nChange-Id: I6ea66468e2814398785470198c5d9ebb34244f09\n'}, {'number': 4, 'created': '2017-12-17 19:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cf308d6d07229694321f7b57d10c9249cca293dd', 'message': 'Add support to back NFS with volume claims\n\nAdds the ability for nfs to use a volume claim for providing\nstorage for other services. This provides the ability to provide\nread-write-many access backed by a read-write-once storage class,\nin situations where such a requirement exists\n\nChange-Id: I6ea66468e2814398785470198c5d9ebb34244f09\n'}, {'number': 5, 'created': '2017-12-17 20:41:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cf3e5c9f12efd789fc389a341ce56de853965cf8', 'message': 'Add support to back NFS with volume claims\n\nAdds the ability for nfs to use a volume claim for providing\nstorage for other services. This provides the ability to provide\nread-write-many access backed by a read-write-once storage class,\nin situations where such a requirement exists\n\nCo-Authored-By: portdirect <pete@port.direct>\n\nChange-Id: I6ea66468e2814398785470198c5d9ebb34244f09\n'}, {'number': 6, 'created': '2017-12-17 20:52:33.000000000', 'files': ['nfs-provisioner/templates/storage_class.yaml', 'nfs-provisioner/templates/deployment.yaml', 'nfs-provisioner/templates/volume_claim.yaml', 'nfs-provisioner/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/aa1447a00267d57dd7decef003a464a8d21cc6db', 'message': 'Add support to back NFS with volume claims\n\nAdds the ability for nfs to use a volume claim for providing\nstorage for other services. This provides the ability to provide\nread-write-many access backed by a read-write-once storage class,\nin situations where such a requirement exists\n\nCo-Authored-By: portdirect <pete@port.direct>\n\nChange-Id: I6ea66468e2814398785470198c5d9ebb34244f09\n'}]",0,524931,aa1447a00267d57dd7decef003a464a8d21cc6db,12,4,6,17591,,,0,"Add support to back NFS with volume claims

Adds the ability for nfs to use a volume claim for providing
storage for other services. This provides the ability to provide
read-write-many access backed by a read-write-once storage class,
in situations where such a requirement exists

Co-Authored-By: portdirect <pete@port.direct>

Change-Id: I6ea66468e2814398785470198c5d9ebb34244f09
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/31/524931/2 && git format-patch -1 --stdout FETCH_HEAD,"['nfs-provisioner/templates/deployment.yaml', 'nfs-provisioner/templates/volume_claim.yaml', 'nfs-provisioner/values.yaml']",3,e2149fd9074022db7d4639d86eedcfef70943c42,support_nfs_pvc, volume: enabled: false access_mode: ReadWriteOnce class_name: rbd-general name: nfs-pvc size: 5Gi volume_claim: true,,45,1
openstack%2Fopenstack-helm-infra~master~I7dcf79b871fd4fa699ee4e3a50151a654f27761f,openstack/openstack-helm-infra,master,I7dcf79b871fd4fa699ee4e3a50151a654f27761f,NFS-Provisioner: Add support to back NFS with volume claims,MERGED,2017-12-18 15:40:33.000000000,2017-12-18 17:22:48.000000000,2017-12-18 17:22:48.000000000,"[{'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 15:40:33.000000000', 'files': ['nfs-provisioner/templates/storage_class.yaml', 'nfs-provisioner/templates/deployment.yaml', 'nfs-provisioner/templates/volume_claim.yaml', 'nfs-provisioner/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/dae9b829181249552980de090ec3043d5969b849', 'message': 'NFS-Provisioner: Add support to back NFS with volume claims\n\nThis ps adds the ability for the NFS-provisioner to use a volume\nclaim for providing storage for other services. This provides the\nability to provide read-write-many access backed by a\nread-write-once storage class, in situations where such a\nrequirement exists.\n\nChange-Id: I7dcf79b871fd4fa699ee4e3a50151a654f27761f\n'}]",0,528743,dae9b829181249552980de090ec3043d5969b849,7,3,1,23928,,,0,"NFS-Provisioner: Add support to back NFS with volume claims

This ps adds the ability for the NFS-provisioner to use a volume
claim for providing storage for other services. This provides the
ability to provide read-write-many access backed by a
read-write-once storage class, in situations where such a
requirement exists.

Change-Id: I7dcf79b871fd4fa699ee4e3a50151a654f27761f
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/43/528743/1 && git format-patch -1 --stdout FETCH_HEAD,"['nfs-provisioner/templates/storage_class.yaml', 'nfs-provisioner/templates/deployment.yaml', 'nfs-provisioner/templates/volume_claim.yaml', 'nfs-provisioner/values.yaml']",4,dae9b829181249552980de090ec3043d5969b849,nfs-pvc," type: hostPath hostPath: path: /var/lib/openstack-helm/nfs persistentVolumeClaim: access_mode: ReadWriteOnce class_name: general #NOTE(portdirect): Unless explicity set the PV name will be populated to # match ""{{ .Release.Name }}"". name: null size: 10Gi #NOTE(portdirect): Unless explicity set the provisioner name will be generated # with the format ""nfs/{{ .Release.Name }}"" provisioner: null #NOTE(portdirect): Unless explicity set the PV name will be populated to # match ""{{ .Release.Name }}"". name: null volume_claim: true", host: host_path: /var/lib/openstack-helm/nfs provisioner: example.com/nfs name: general,76,5
openstack%2Fopenstack-ansible-os_cinder~master~I6bb4f8568ff4e00c4b802bdb261ba222645a53c2,openstack/openstack-ansible-os_cinder,master,I6bb4f8568ff4e00c4b802bdb261ba222645a53c2,Reorder service restarts,MERGED,2017-12-14 22:13:51.000000000,2017-12-18 17:18:33.000000000,2017-12-18 17:18:33.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-14 22:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/a686e10cbf4da2fd8940026490fcb66d99989592', 'message': ""Reorder service restarts\n\nCinder's documented order for services being restarted during an upgrade\nhad conflicting information. That's been clarified now with\nIfa8ea98e494d3058ef1a29fee4ab9fa76149ce08.\n\nCinder services will now be restarted in order of cinder-scheduler,\ncinder-volume, cinder-backup and finally cinder-api.\n\nChange-Id: I6bb4f8568ff4e00c4b802bdb261ba222645a53c2\n""}, {'number': 2, 'created': '2017-12-15 15:53:56.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/a8588987ce2ee40e21369a20bd3776fb5d17bb9d', 'message': ""Reorder service restarts\n\nCinder's documented order for services being restarted during an upgrade\nhad conflicting information. That's been clarified now with\nIfa8ea98e494d3058ef1a29fee4ab9fa76149ce08.\n\nCinder services will now be restarted in order of cinder-scheduler,\ncinder-volume, cinder-backup and finally cinder-api.\n\nDepends-On: Ifa8ea98e494d3058ef1a29fee4ab9fa76149ce08\n\nChange-Id: I6bb4f8568ff4e00c4b802bdb261ba222645a53c2\n""}]",0,528103,a8588987ce2ee40e21369a20bd3776fb5d17bb9d,21,6,2,14805,,,0,"Reorder service restarts

Cinder's documented order for services being restarted during an upgrade
had conflicting information. That's been clarified now with
Ifa8ea98e494d3058ef1a29fee4ab9fa76149ce08.

Cinder services will now be restarted in order of cinder-scheduler,
cinder-volume, cinder-backup and finally cinder-api.

Depends-On: Ifa8ea98e494d3058ef1a29fee4ab9fa76149ce08

Change-Id: I6bb4f8568ff4e00c4b802bdb261ba222645a53c2
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/03/528103/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,a686e10cbf4da2fd8940026490fcb66d99989592,reorder_service_restarts," cinder-scheduler: group: cinder_scheduler service_name: cinder-scheduler init_config_overrides: ""{{ cinder_scheduler_init_overrides }}"" start_order: 1 cinder-volume: group: cinder_volume service_name: cinder-volume init_config_overrides: ""{{ cinder_volume_init_overrides }}"" start_order: 2 cinder-backup: group: cinder_backup service_name: cinder-backup condition: ""{{ cinder_service_backup_program_enabled | bool }}"" init_config_overrides: ""{{ cinder_backup_init_overrides }}"" start_order: 3"," start_order: 1 cinder-scheduler: group: cinder_scheduler service_name: cinder-scheduler init_config_overrides: ""{{ cinder_scheduler_init_overrides }}"" start_order: 2 cinder-volume: group: cinder_volume service_name: cinder-volume init_config_overrides: ""{{ cinder_volume_init_overrides }}"" start_order: 3 cinder-backup: group: cinder_backup service_name: cinder-backup condition: ""{{ cinder_service_backup_program_enabled | bool }}"" init_config_overrides: ""{{ cinder_backup_init_overrides }}""",16,16
openstack%2Ftempest~master~I5759918f7262def1f29d2d7345b4e0738e5d0e60,openstack/tempest,master,I5759918f7262def1f29d2d7345b4e0738e5d0e60,Add skip checks for snapshot manage and group snapshots tests,MERGED,2017-12-16 09:31:17.000000000,2017-12-18 17:16:40.000000000,2017-12-18 17:16:39.000000000,"[{'_account_id': 1921}, {'_account_id': 5689}, {'_account_id': 10385}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 23081}]","[{'number': 1, 'created': '2017-12-16 09:31:17.000000000', 'files': ['tempest/api/volume/admin/test_group_snapshots.py', 'tempest/api/volume/admin/test_snapshot_manage.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b134589333c9c0793454a5082b095d38152f22f2', 'message': 'Add skip checks for snapshot manage and group snapshots tests\n\nTempest tests for snapshot manage and group snapshots involves creating\nsnapshots, and it is necessary to add skip checks to verify the storage\nbackend drivers whether support snapshot feature firstly.\n\nChange-Id: I5759918f7262def1f29d2d7345b4e0738e5d0e60\n'}]",3,528462,b134589333c9c0793454a5082b095d38152f22f2,14,6,1,23081,,,0,"Add skip checks for snapshot manage and group snapshots tests

Tempest tests for snapshot manage and group snapshots involves creating
snapshots, and it is necessary to add skip checks to verify the storage
backend drivers whether support snapshot feature firstly.

Change-Id: I5759918f7262def1f29d2d7345b4e0738e5d0e60
",git fetch https://review.opendev.org/openstack/tempest refs/changes/62/528462/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/volume/admin/test_group_snapshots.py', 'tempest/api/volume/admin/test_snapshot_manage.py']",2,b134589333c9c0793454a5082b095d38152f22f2,snapshot_skip_check," if not CONF.volume_feature_enabled.snapshot: raise cls.skipException(""Cinder volume snapshots are disabled"") ",,12,0
openstack%2Fopenstack-zuul-jobs~master~Ic7372d24f93694ea796c3ae10c713f3da1ee3c29,openstack/openstack-zuul-jobs,master,Ic7372d24f93694ea796c3ae10c713f3da1ee3c29,"Revert ""Switch build-openstack-sphinx-docs to build-sphinx-docs""",ABANDONED,2017-12-18 16:57:44.000000000,2017-12-18 17:15:54.000000000,,"[{'_account_id': 2}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 16:57:44.000000000', 'files': ['playbooks/sphinx-docs/run.yaml', 'roles/neutron-horizon-hack/tasks/main.yaml', 'playbooks/sphinx-docs/neutron-horizon-hack.yaml', 'roles/neutron-horizon-hack/README.rst', 'zuul.d/jobs.yaml', 'roles/neutron-horizon-hack/defaults/main.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/262a044d65dd2f1c2010c82b73074f1237dd1f7c', 'message': 'Revert ""Switch build-openstack-sphinx-docs to build-sphinx-docs""\n\nThis is breaking jobs on TASK [ensure-sphinx : Get requirements files]:\n\nhttp://logs.openstack.org/06/527106/5/check/build-openstack-sphinx-docs/491d636/job-output.txt.gz\n\nThis reverts commit e1a793b8a1f093c24264c4d0c19480607c4e1c83.\n\nChange-Id: Ic7372d24f93694ea796c3ae10c713f3da1ee3c29\n'}]",0,528760,262a044d65dd2f1c2010c82b73074f1237dd1f7c,3,6,1,4162,,,0,"Revert ""Switch build-openstack-sphinx-docs to build-sphinx-docs""

This is breaking jobs on TASK [ensure-sphinx : Get requirements files]:

http://logs.openstack.org/06/527106/5/check/build-openstack-sphinx-docs/491d636/job-output.txt.gz

This reverts commit e1a793b8a1f093c24264c4d0c19480607c4e1c83.

Change-Id: Ic7372d24f93694ea796c3ae10c713f3da1ee3c29
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/60/528760/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/sphinx-docs/run.yaml', 'roles/neutron-horizon-hack/tasks/main.yaml', 'playbooks/sphinx-docs/neutron-horizon-hack.yaml', 'roles/neutron-horizon-hack/README.rst', 'zuul.d/jobs.yaml', 'roles/neutron-horizon-hack/defaults/main.yaml']",6,262a044d65dd2f1c2010c82b73074f1237dd1f7c,updated-pti,,"zuul_work_dir: ""{{ zuul.project.src_dir }}"" zuul_work_virtualenv: ""{{ ansible_user_dir }}/.venv"" ",22,62
openstack%2Ftripleo-heat-templates~stable%2Fpike~If38a4f7e25d4d1f4679d9684ad2c0db8475d679b,openstack/tripleo-heat-templates,stable/pike,If38a4f7e25d4d1f4679d9684ad2c0db8475d679b,Search for containers within stopped containers.,MERGED,2017-12-18 08:17:13.000000000,2017-12-18 17:12:59.000000000,2017-12-18 17:12:58.000000000,"[{'_account_id': 8297}, {'_account_id': 8449}, {'_account_id': 13039}, {'_account_id': 16515}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 08:17:13.000000000', 'files': ['docker/services/pacemaker/rabbitmq.yaml', 'docker/services/pacemaker/cinder-volume.yaml', 'docker/services/pacemaker/haproxy.yaml', 'docker/services/pacemaker/database/mysql.yaml', 'docker/services/pacemaker/database/redis.yaml', 'docker/services/pacemaker/cinder-backup.yaml', 'docker/services/pacemaker/manila-share.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1891e364e2402af1672b794edbd42362d99b65f9', 'message': ""Search for containers within stopped containers.\n\nDuring minor update pcs cluster is stopped during step 1.\nThen we search for pcs managed containers at step 2.\nBut since pcs cluster is stopped, 'docker ps' won't report stopped\ncontainers.\nThis change adds '--all' option to show all the containers.\n\nChange-Id: If38a4f7e25d4d1f4679d9684ad2c0db8475d679b\nCloses-Bug: #1737548\n(cherry picked from commit 09dcd7e26c45edeefc1463a2885f94882433589e)\n""}]",0,528648,1891e364e2402af1672b794edbd42362d99b65f9,8,5,1,21537,,,0,"Search for containers within stopped containers.

During minor update pcs cluster is stopped during step 1.
Then we search for pcs managed containers at step 2.
But since pcs cluster is stopped, 'docker ps' won't report stopped
containers.
This change adds '--all' option to show all the containers.

Change-Id: If38a4f7e25d4d1f4679d9684ad2c0db8475d679b
Closes-Bug: #1737548
(cherry picked from commit 09dcd7e26c45edeefc1463a2885f94882433589e)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/48/528648/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/pacemaker/rabbitmq.yaml', 'docker/services/pacemaker/cinder-volume.yaml', 'docker/services/pacemaker/database/mysql.yaml', 'docker/services/pacemaker/haproxy.yaml', 'docker/services/pacemaker/database/redis.yaml', 'docker/services/pacemaker/cinder-backup.yaml', 'docker/services/pacemaker/manila-share.yaml']",7,1891e364e2402af1672b794edbd42362d99b65f9,bug/1737548-stable/pike," shell: ""docker ps -a -q -f 'ancestor={{manila_share_image_id.stdout}}'"""," shell: ""docker ps -q -f 'ancestor={{manila_share_image_id.stdout}}'""",7,7
openstack%2Ftripleo-quickstart-extras~master~I3bc646f5d1d9584cef4e624e5904f7e88c59442e,openstack/tripleo-quickstart-extras,master,I3bc646f5d1d9584cef4e624e5904f7e88c59442e,Add ui_validate_simple to the logs collected,MERGED,2017-11-28 16:38:46.000000000,2017-12-18 17:12:58.000000000,2017-12-18 17:12:58.000000000,"[{'_account_id': 8652}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 12715}, {'_account_id': 13861}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-11-28 16:38:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/275085f54e150790abc9c6b104e42820c709f7c0', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since the logs are not collected.\nThis review adds these logs to those pulled off the localhost.\n\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\nRelated-Bug: 1734928\n'}, {'number': 2, 'created': '2017-11-28 17:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/6bca00d344e46ee1672a02f344cced39ce72e49a', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies the ui_validate_simple script and\nlog to the undercloud so that they are included in\nlog collection.\n\nRelated-Bug: 1734928\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}, {'number': 3, 'created': '2017-11-28 17:44:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/3a66f63baa9e31cf65d246a7a2793e7056a8f04d', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies the ui_validate_simple script and\nlog to the undercloud so that they are included in\nlog collection.\n\nRelated-Bug: 1734928\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}, {'number': 4, 'created': '2017-11-29 02:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/3fabc98f22c193db0de284848ca9b8426fe1ed73', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies the ui_validate_simple script and\nlog to the undercloud so that they are included in\nlog collection.\n\nRelated-Bug: 1734928\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}, {'number': 5, 'created': '2017-11-29 21:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/b494b3394c09f78681fc557e9e42d3381fadea11', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies the ui_validate_simple script and\nlog to the undercloud so that they are included in\nlog collection.\n\nRelated-Bug: 1734928\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}, {'number': 6, 'created': '2017-11-30 00:23:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1bebb43b2355c2a9e34c2334094196198c02a699', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies the ui_validate_simple script and\nlog to the undercloud so that they are included in\nlog collection.\n\nRelated-Bug: 1734928\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}, {'number': 7, 'created': '2017-11-30 23:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/480884e7de274406e9e671f8ddcc01091468cc3a', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies the ui_validate_simple script and\nlog to the undercloud so that they are included in\nlog collection.\n\nRelated-Bug: 1734928\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}, {'number': 8, 'created': '2017-12-01 00:04:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/317044c2e9b72be94a32a74918b662634c283ae0', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies the ui_validate_simple script and\nlog so that they are included in log collection.\n\nRelated-Bug: 1734928\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}, {'number': 9, 'created': '2017-12-01 01:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/7d584c6d5af328246e105bab995907c0a01206b0', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies the ui_validate_simple script and\nlog to the log directory that they are included in\nlog collection.\n\nRelated-Bug: 1734928\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}, {'number': 10, 'created': '2017-12-01 16:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/93546b99093cde457047ec4be3330ff69f46b123', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies all the .sh and .log files\nfrom the local working dir to the log directory so that\nthey are included in log collection.\n\nRelated-Bug: 1734928\nDepends-On: Ibb75fc895465cc899bc3257df053f5c6f8304507\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}, {'number': 11, 'created': '2017-12-01 20:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1d933ebcba8a8d2630f54c68deb45f7ba3a97b94', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies all the .sh and .log files\nfrom the local working dir to the log directory so that\nthey are included in log collection.\n\nRelated-Bug: 1734928\nDepends-On: Ibb75fc895465cc899bc3257df053f5c6f8304507\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}, {'number': 12, 'created': '2017-12-01 21:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/81bdd3cf587ea78a27927169b12cb8868c29a040', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies all the .sh and .log files\nfrom the local working dir to the log directory so that\nthey are included in log collection.\n\nRelated-Bug: 1734928\nDepends-On: Ibb75fc895465cc899bc3257df053f5c6f8304507\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}, {'number': 13, 'created': '2017-12-01 21:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/6eb11d5cad5db8121c69c8b83eef9275ad101f19', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies all the .sh and .log files\nfrom the local working dir to the log directory so that\nthey are included in log collection.\n\nRelated-Bug: 1734928\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}, {'number': 14, 'created': '2017-12-03 23:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d16b539d152f9b743a26111da5d01cbce899e3c6', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies all the .sh and .log files\nfrom the local working dir to the log directory so that\nthey are included in log collection.\n\nRelated-Bug: 1734928\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}, {'number': 15, 'created': '2017-12-04 18:25:52.000000000', 'files': ['roles/collect-logs/tasks/publish.yml', 'roles/validate-ui/tasks/main.yml', 'roles/validate-ui/meta/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/87b72781bd5b05cc072393c624dcc420f4fa8d6a', 'message': 'Add ui_validate_simple to the logs collected\n\nThe ui_validate_simple test has been failing of late and\nit is hard to debug since logs are not collected\nfrom localhost.\nThis review copies all the .sh and .log files\nfrom the local working dir to the log directory so that\nthey are included in log collection.\n\nRelated-Bug: 1734928\nChange-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e\n'}]",12,523461,87b72781bd5b05cc072393c624dcc420f4fa8d6a,90,9,15,9976,,,0,"Add ui_validate_simple to the logs collected

The ui_validate_simple test has been failing of late and
it is hard to debug since logs are not collected
from localhost.
This review copies all the .sh and .log files
from the local working dir to the log directory so that
they are included in log collection.

Related-Bug: 1734928
Change-Id: I3bc646f5d1d9584cef4e624e5904f7e88c59442e
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/61/523461/3 && git format-patch -1 --stdout FETCH_HEAD,['roles/collect-logs/defaults/main.yml'],1,275085f54e150790abc9c6b104e42820c709f7c0,bug/1734928," - ""{{ local_working_dir }}/ui_validate_simple.*""",,1,0
openstack%2Ftripleo-heat-templates~master~I2016d6f0b51f9f15b625c5dfed84c8b58f94ea4b,openstack/tripleo-heat-templates,master,I2016d6f0b51f9f15b625c5dfed84c8b58f94ea4b,OpenDaylight BGPVPN driver has been deprecated,MERGED,2017-12-01 13:01:46.000000000,2017-12-18 17:04:28.000000000,2017-12-18 17:04:28.000000000,"[{'_account_id': 3153}, {'_account_id': 17280}, {'_account_id': 20775}, {'_account_id': 21626}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2017-12-01 13:01:46.000000000', 'files': ['environments/neutron-bgpvpn-opendaylight.yaml', 'environments/neutron-bgpvpn.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/27b2cd890030e2f891a9be90c7e98115efee5881', 'message': 'OpenDaylight BGPVPN driver has been deprecated\n\n  It will be removed. Switch to new v2 Driver\n\nChange-Id: I2016d6f0b51f9f15b625c5dfed84c8b58f94ea4b\nSigned-off-by: Ricardo Noriega <rnoriega@redhat.com>\n'}]",0,524579,27b2cd890030e2f891a9be90c7e98115efee5881,28,7,1,21626,,,0,"OpenDaylight BGPVPN driver has been deprecated

  It will be removed. Switch to new v2 Driver

Change-Id: I2016d6f0b51f9f15b625c5dfed84c8b58f94ea4b
Signed-off-by: Ricardo Noriega <rnoriega@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/79/524579/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/neutron-bgpvpn-opendaylight.yaml', 'environments/neutron-bgpvpn.yaml']",2,27b2cd890030e2f891a9be90c7e98115efee5881,odl_v2,# - OpenDaylight: BGPVPN:OpenDaylight:networking_odl.bgpvpn.odl_v2.OpenDaylightBgpvpnDriver:default,# - OpenDaylight: BGPVPN:OpenDaylight:networking_bgpvpn.neutron.services.service_drivers.opendaylight.odl.OpenDaylightBgpvpnDriver:default,3,3
openstack%2Fopenstack-zuul-jobs~master~Ib121961c5a953a434e7b333cd70f7838a2671f69,openstack/openstack-zuul-jobs,master,Ib121961c5a953a434e7b333cd70f7838a2671f69,Switch build-openstack-sphinx-docs to build-sphinx-docs,MERGED,2017-11-17 17:42:12.000000000,2017-12-18 16:57:44.000000000,2017-12-18 15:58:11.000000000,"[{'_account_id': 2}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-17 17:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/ef1837c44ea132468b5a6a4d6ce8f4f1864309c1', 'message': 'Switch build-openstack-sphinx-docs to build-sphinx-docs\n\nAs per the recent PTI update, docs should be built without tox and\ninstead using direct sphinx-build commands. The general job\nbuild-sphinx-docs does this, so use it. Keep the\nbuild-openstack-sphinx-docs job because we need to set constraints\nsupport.\n\nChange-Id: Ib121961c5a953a434e7b333cd70f7838a2671f69\n'}, {'number': 2, 'created': '2017-11-17 21:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/4086a089dc5dff1b7d62076c64a1dac39f3f7cde', 'message': 'Switch build-openstack-sphinx-docs to build-sphinx-docs\n\nAs per the recent PTI update, docs should be built without tox and\ninstead using direct sphinx-build commands. The general job\nbuild-sphinx-docs does this, so use it. Keep the\nbuild-openstack-sphinx-docs job because we need to set constraints\nsupport.\n\nChange-Id: Ib121961c5a953a434e7b333cd70f7838a2671f69\n'}, {'number': 3, 'created': '2017-11-18 14:09:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/f464d8f0d753af8b3f9714a307273b749e189422', 'message': 'Switch build-openstack-sphinx-docs to build-sphinx-docs\n\nAs per the recent PTI update, docs should be built without tox and\ninstead using direct sphinx-build commands. The general job\nbuild-sphinx-docs does this, so use it. Keep the\nbuild-openstack-sphinx-docs job because we need to set constraints\nsupport.\n\nChange-Id: Ib121961c5a953a434e7b333cd70f7838a2671f69\n'}, {'number': 4, 'created': '2017-11-18 18:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/f23d4ee27c47da2a6f1bc0f2457d0aa0d11e2735', 'message': 'Switch build-openstack-sphinx-docs to build-sphinx-docs\n\nAs per the recent PTI update, docs should be built without tox and\ninstead using direct sphinx-build commands. The general job\nbuild-sphinx-docs does this, so use it. Keep the\nbuild-openstack-sphinx-docs job because we need to set constraints\nsupport.\n\nThis includes a hack to allow neutron and horizon plugin repos to work\nproperly with their tox_install.sh list of additional requirements.\n\nChange-Id: Ib121961c5a953a434e7b333cd70f7838a2671f69\n'}, {'number': 5, 'created': '2017-11-20 14:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/23602f4e3c5a003a6110997be8c8f195c39aa7a3', 'message': 'Switch build-openstack-sphinx-docs to build-sphinx-docs\n\nAs per the recent PTI update, docs should be built without tox and\ninstead using direct sphinx-build commands. The general job\nbuild-sphinx-docs does this, so use it. Keep the\nbuild-openstack-sphinx-docs job because we need to set constraints\nsupport.\n\nThis includes a hack to allow neutron and horizon plugin repos to work\nproperly with their tox_install.sh list of additional requirements.\n\nChange-Id: Ib121961c5a953a434e7b333cd70f7838a2671f69\n'}, {'number': 6, 'created': '2017-11-20 15:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/883327ee12d976efdfe231953d95f3b30261fea2', 'message': 'Switch build-openstack-sphinx-docs to build-sphinx-docs\n\nAs per the recent PTI update, docs should be built without tox and\ninstead using direct sphinx-build commands. The general job\nbuild-sphinx-docs does this, so use it. Keep the\nbuild-openstack-sphinx-docs job because we need to set constraints\nsupport.\n\nThis includes a hack to allow neutron and horizon plugin repos to work\nproperly with their tox_install.sh list of additional requirements.\n\nChange-Id: Ib121961c5a953a434e7b333cd70f7838a2671f69\n'}, {'number': 7, 'created': '2017-11-20 19:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/49b3526002f5df509fb987a427779183b2c45766', 'message': 'Switch build-openstack-sphinx-docs to build-sphinx-docs\n\nAs per the recent PTI update, docs should be built without tox and\ninstead using direct sphinx-build commands. The general job\nbuild-sphinx-docs does this, so use it. Keep the\nbuild-openstack-sphinx-docs job because we need to set constraints\nsupport.\n\nThis includes a hack to allow neutron and horizon plugin repos to work\nproperly with their tox_install.sh list of additional requirements.\n\nChange-Id: Ib121961c5a953a434e7b333cd70f7838a2671f69\n'}, {'number': 8, 'created': '2017-11-20 23:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/3e23559b8c76d4c497181dc1ca0cc59b628de0cd', 'message': 'Switch build-openstack-sphinx-docs to build-sphinx-docs\n\nAs per the recent PTI update, docs should be built without tox and\ninstead using direct sphinx-build commands. The general job\nbuild-sphinx-docs does this, so use it. Keep the\nbuild-openstack-sphinx-docs job because we need to set constraints\nsupport.\n\nThis includes a hack to allow neutron and horizon plugin repos to work\nproperly with their tox_install.sh list of additional requirements.\n\nChange-Id: Ib121961c5a953a434e7b333cd70f7838a2671f69\nDepends-On: Ie65dcb42c48e6a962f6715f7483ef3758caf2965\n'}, {'number': 9, 'created': '2017-11-28 09:14:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/7c85734b5a1fb9a9368a7a181550804fe94c6dfe', 'message': 'Switch build-openstack-sphinx-docs to build-sphinx-docs\n\nAs per the recent PTI update, docs should be built without tox and\ninstead using direct sphinx-build commands. The general job\nbuild-sphinx-docs does this, so use it. Keep the\nbuild-openstack-sphinx-docs job because we need to set constraints\nsupport.\n\nThis includes a hack to allow neutron and horizon plugin repos to work\nproperly with their tox_install.sh list of additional requirements.\n\nChange-Id: Ib121961c5a953a434e7b333cd70f7838a2671f69\nDepends-On: Ie65dcb42c48e6a962f6715f7483ef3758caf2965\n'}, {'number': 10, 'created': '2017-12-01 18:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/e19f5d54e85dd80c5db9132edce5cce0953d56af', 'message': 'Switch build-openstack-sphinx-docs to build-sphinx-docs\n\nAs per the recent PTI update, docs should be built without tox and\ninstead using direct sphinx-build commands. The general job\nbuild-sphinx-docs does this, so use it. Keep the\nbuild-openstack-sphinx-docs job because we need to set constraints\nsupport.\n\nThis includes a hack to allow neutron and horizon plugin repos to work\nproperly with their tox_install.sh list of additional requirements.\n\nChange-Id: Ib121961c5a953a434e7b333cd70f7838a2671f69\nDepends-On: Ie65dcb42c48e6a962f6715f7483ef3758caf2965\n'}, {'number': 11, 'created': '2017-12-01 19:03:54.000000000', 'files': ['playbooks/sphinx-docs/run.yaml', 'roles/neutron-horizon-hack/tasks/main.yaml', 'playbooks/sphinx-docs/neutron-horizon-hack.yaml', 'roles/neutron-horizon-hack/README.rst', 'zuul.d/jobs.yaml', 'roles/neutron-horizon-hack/defaults/main.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/e1a793b8a1f093c24264c4d0c19480607c4e1c83', 'message': 'Switch build-openstack-sphinx-docs to build-sphinx-docs\n\nAs per the recent PTI update, docs should be built without tox and\ninstead using direct sphinx-build commands. The general job\nbuild-sphinx-docs does this, so use it. Keep the\nbuild-openstack-sphinx-docs job because we need to set constraints\nsupport.\n\nThis includes a hack to allow neutron and horizon plugin repos to work\nproperly with their tox_install.sh list of additional requirements.\n\nChange-Id: Ib121961c5a953a434e7b333cd70f7838a2671f69\nDepends-On: Ie65dcb42c48e6a962f6715f7483ef3758caf2965\n'}]",5,521145,e1a793b8a1f093c24264c4d0c19480607c4e1c83,70,6,11,2,,,0,"Switch build-openstack-sphinx-docs to build-sphinx-docs

As per the recent PTI update, docs should be built without tox and
instead using direct sphinx-build commands. The general job
build-sphinx-docs does this, so use it. Keep the
build-openstack-sphinx-docs job because we need to set constraints
support.

This includes a hack to allow neutron and horizon plugin repos to work
properly with their tox_install.sh list of additional requirements.

Change-Id: Ib121961c5a953a434e7b333cd70f7838a2671f69
Depends-On: Ie65dcb42c48e6a962f6715f7483ef3758caf2965
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/45/521145/10 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,ef1837c44ea132468b5a6a4d6ce8f4f1864309c1,updated-pti, parent: build-sphinx-docs Builds documentation using build-sphinx-docs adding the ``openstack/requirements`` repo to the required-projects and specifying the OpenStack constraints file location.," parent: tox-docs Builds documentation using Sphinx per the OpenStack PTI and then collects the results into the log directory so that they can be examined in their published form after a successful build. It runs the prepare-docs-for-afs role so that AFS stamp files can be examined if desired, and also validates htaccess files using the whereto tool. run: playbooks/sphinx-docs/run.yaml success-url: html/ tox_envlist: venv tox_extra_args: -vv python setup.py build_sphinx run: playbooks/releasenotes/run.yaml post-run: playbooks/releasenotes/post.yaml files: - ^releasenotes/.* - ^tox.ini",4,16
openstack%2Fkolla-ansible~master~I2dd0f2859dc488b16a9229515c0e0008e7bcdae9,openstack/kolla-ansible,master,I2dd0f2859dc488b16a9229515c0e0008e7bcdae9,Update document to add note,ABANDONED,2017-08-30 22:09:04.000000000,2017-12-18 16:55:55.000000000,,"[{'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 10453}, {'_account_id': 10787}, {'_account_id': 17120}, {'_account_id': 19316}, {'_account_id': 26556}]","[{'number': 1, 'created': '2017-08-30 22:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/789174dd861558a20162ff432065c7297ceffd2f', 'message': 'Update document for Host Ubuntu\n\n/usr/bin/docker doesn\'t work for ubuntu, but document\nuses same for both centos and ubuntu.This patch changes\nit to /usr/bin/dockerd and also remove ""-"" from docker\nenvironment file path.\n\nChange-Id: I2dd0f2859dc488b16a9229515c0e0008e7bcdae9\n'}, {'number': 2, 'created': '2017-08-30 22:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/713dcc1b822dad4b985b00e5814062e3142f3f74', 'message': 'Update document to add note\n\n/usr/bin/docker daemon doesn\'t work for some docker vesrions,\nThis patch adds a note fpr /usr/bin/dockerd and also remove\n""-"" from docker environment file path.\n\nChange-Id: I2dd0f2859dc488b16a9229515c0e0008e7bcdae9\n'}, {'number': 3, 'created': '2017-08-30 22:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ce2720c9476175647dedd1b3d077c56079d0684a', 'message': 'Update document to add note\n\n/usr/bin/docker daemon doesn\'t work for some docker vesrions,\nThis patch adds a note fpr /usr/bin/dockerd and also remove\n""-"" from docker environment file path.\n\nChange-Id: I2dd0f2859dc488b16a9229515c0e0008e7bcdae9\n'}, {'number': 4, 'created': '2017-08-31 05:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/88c5556bd68d9eaa1a774d30c1727615260df5d5', 'message': 'Update document to add note\n\n/usr/bin/docker daemon doesn\'t work for some docker vesrions,\nThis patch adds a note fpr /usr/bin/dockerd and also remove\n""-"" from docker environment file path.\n\nChange-Id: I2dd0f2859dc488b16a9229515c0e0008e7bcdae9\n'}, {'number': 5, 'created': '2017-08-31 16:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/560510b58861ae1533d3362e7c916dd965e0b4e5', 'message': 'Update document to add note\n\n/usr/bin/docker daemon doesn\'t work for some docker vesrions,\nThis patch adds a note fpr /usr/bin/dockerd and also remove\n""-"" from docker environment file path.\n\nChange-Id: I2dd0f2859dc488b16a9229515c0e0008e7bcdae9\n'}, {'number': 6, 'created': '2017-08-31 17:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f6f3edc0d10e9ec735181838a34f31948139ee6b', 'message': 'Update document to add note\n\n/usr/bin/docker daemon doesn\'t work for some docker vesrions,\nThis patch adds a note fpr /usr/bin/dockerd and also remove\n""-"" from docker environment file path.\n\nChange-Id: I2dd0f2859dc488b16a9229515c0e0008e7bcdae9\n'}, {'number': 7, 'created': '2017-08-31 20:49:14.000000000', 'files': ['doc/multinode.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/585c37ce534cf09d3858e6ed5b8e7e4c9c3b1f8e', 'message': 'Update document to add note\n\n/usr/bin/docker daemon doesn\'t work for some docker vesrions,\nThis patch adds a note fpr /usr/bin/dockerd and also remove\n""-"" from docker environment file path.\n\nChange-Id: I2dd0f2859dc488b16a9229515c0e0008e7bcdae9\n'}]",10,499370,585c37ce534cf09d3858e6ed5b8e7e4c9c3b1f8e,23,7,7,17120,,,0,"Update document to add note

/usr/bin/docker daemon doesn't work for some docker vesrions,
This patch adds a note fpr /usr/bin/dockerd and also remove
""-"" from docker environment file path.

Change-Id: I2dd0f2859dc488b16a9229515c0e0008e7bcdae9
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/70/499370/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/multinode.rst'],1,789174dd861558a20162ff432065c7297ceffd2f,499370, EnvironmentFile=/etc/default/docker ExecStart=/usr/bin/dockerd -H fd:// $DOCKER_OPTS, EnvironmentFile=-/etc/default/docker ExecStart=/usr/bin/docker daemon -H fd:// $DOCKER_OPTS,2,2
openstack%2Fdevstack-gate~master~I834e02b75c7c65eb265de03c446f8db5a9e31c1c,openstack/devstack-gate,master,I834e02b75c7c65eb265de03c446f8db5a9e31c1c,Do not merge experimental,ABANDONED,2017-03-21 18:09:20.000000000,2017-12-18 16:55:31.000000000,,[],"[{'number': 1, 'created': '2017-03-21 18:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/840e63f47aea5caba756e95d3a3c32b000e523cc', 'message': 'Do not merge experimental\n\nChange-Id: I834e02b75c7c65eb265de03c446f8db5a9e31c1c\n'}, {'number': 2, 'created': '2017-03-22 21:24:45.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/045e56041c842b2eb2cc51859ea3e62d4b27a575', 'message': 'Do not merge experimental\n\nChange-Id: I834e02b75c7c65eb265de03c446f8db5a9e31c1c\n'}]",0,448218,045e56041c842b2eb2cc51859ea3e62d4b27a575,7,0,2,17120,,,0,"Do not merge experimental

Change-Id: I834e02b75c7c65eb265de03c446f8db5a9e31c1c
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/18/448218/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,840e63f47aea5caba756e95d3a3c32b000e523cc,, export TEMPEST_CONCURRENCY=2,,1,0
openstack%2Fdevstack~master~Ic82feaba5a50a4999a6a6f98dce244a5b34bb8f7,openstack/devstack,master,Ic82feaba5a50a4999a6a6f98dce244a5b34bb8f7,devstack failed on Etcd3,ABANDONED,2017-06-06 17:01:35.000000000,2017-12-18 16:55:01.000000000,,"[{'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 16376}]","[{'number': 1, 'created': '2017-06-06 17:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/774fa4277f6581547434d868ecb90a643ef42d68', 'message': 'devstack failed on Etcd3\n\nIn devstack/lib/etcd3 where it is doing wget on\netcd-v3.1.7-linux-amd64.tar.gz, it is writing it to\nfiles dir which does not exists and end up\non error there.\n\nChange-Id: Ic82feaba5a50a4999a6a6f98dce244a5b34bb8f7\n'}, {'number': 2, 'created': '2017-06-06 17:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f0f4d7949a6d862712b8c0eebe718df9e2ff9af8', 'message': 'devstack failed on Etcd3\n\nIn devstack/lib/etcd3 where it is doing wget on\netcd-v3.1.7-linux-amd64.tar.gz, it is writing it to\nfiles dir which does not exists and end up\non error there.\n\nChange-Id: Ic82feaba5a50a4999a6a6f98dce244a5b34bb8f7\n'}, {'number': 3, 'created': '2017-06-06 18:41:58.000000000', 'files': ['lib/etcd3'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7308dd21dba411f2b1ec1d4571f9f180d577cfcb', 'message': 'devstack failed on Etcd3\n\nIn devstack/lib/etcd3 where it is doing wget on\netcd-v3.1.7-linux-amd64.tar.gz, it is writing it to\nfiles dir which does not exists and end up\non error there.\n\nChange-Id: Ic82feaba5a50a4999a6a6f98dce244a5b34bb8f7\n'}]",0,471426,7308dd21dba411f2b1ec1d4571f9f180d577cfcb,14,7,3,17120,,,0,"devstack failed on Etcd3

In devstack/lib/etcd3 where it is doing wget on
etcd-v3.1.7-linux-amd64.tar.gz, it is writing it to
files dir which does not exists and end up
on error there.

Change-Id: Ic82feaba5a50a4999a6a6f98dce244a5b34bb8f7
",git fetch https://review.opendev.org/openstack/devstack refs/changes/26/471426/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/etcd3'],1,774fa4277f6581547434d868ecb90a643ef42d68,,"ETCD_FILES_DIR=""$DEST/files"" sudo mkdir -p $ETCD_FILES_DIR if [ ! -f ""$ETCD_FILES_DIR/etcd-$ETCD_VERSION-linux-$ETCD_ARCH/etcd"" ]; then wget $ETCD_DOWNLOAD_URL/$ETCD_VERSION/$ETCD_DOWNLOAD_FILE -O $ETCD_FILES_DIR/$ETCD_DOWNLOAD_FILE echo ""${ETCD_SHA256} files/${ETCD_DOWNLOAD_FILE}"" > $ETCD_FILES_DIR/etcd.sha256sum sha256sum -c $ETCD_FILES_DIR/etcd.sha256sum tar xzvf $ETCD_FILES_DIR/$ETCD_DOWNLOAD_FILE -C files sudo cp $ETCD_FILES_DIR/$ETCD_NAME/etcd $ETCD_BIN_DIR/etcd sudo cp $ETCD_FILES_DIR/$ETCD_NAME/etcd $ETCD_BIN_DIR/etcd"," if [ ! -f ""files/etcd-$ETCD_VERSION-linux-$ETCD_ARCH/etcd"" ]; then wget $ETCD_DOWNLOAD_URL/$ETCD_VERSION/$ETCD_DOWNLOAD_FILE -O files/$ETCD_DOWNLOAD_FILE echo ""${ETCD_SHA256} files/${ETCD_DOWNLOAD_FILE}"" > files/etcd.sha256sum sha256sum -c files/etcd.sha256sum tar xzvf files/$ETCD_DOWNLOAD_FILE -C files sudo cp files/$ETCD_NAME/etcd $ETCD_BIN_DIR/etcd sudo cp files/$ETCD_NAME/etcd $ETCD_BIN_DIR/etcd",9,7
openstack%2Fpatrole~master~Ib59ff6e4aee22915b408ddd5a30a443173ca4f81,openstack/patrole,master,Ib59ff6e4aee22915b408ddd5a30a443173ca4f81,"Add ""quotas"" Rbac test File.",ABANDONED,2017-12-18 10:39:27.000000000,2017-12-18 16:52:19.000000000,,"[{'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2017-12-18 10:39:27.000000000', 'files': ['patrole_tempest_plugin/tests/api/volume/test_quotas_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/35bf11da76d8dbbea61a6687b02912486eee2d5d', 'message': 'Add ""quotas"" Rbac test File.\n\nThis PS adds Rbac test for ""quotas"" policy [0], api-ref[1]\n\n[0] https://github.com/openstack/cinder/blob/master/cinder/policies/quotas.py\n[1[ https://developer.openstack.org/api-ref/block-storage/v2/index.html#show-quotas\n\nChange-Id: Ib59ff6e4aee22915b408ddd5a30a443173ca4f81\n'}]",0,528689,35bf11da76d8dbbea61a6687b02912486eee2d5d,4,2,1,25695,,,0,"Add ""quotas"" Rbac test File.

This PS adds Rbac test for ""quotas"" policy [0], api-ref[1]

[0] https://github.com/openstack/cinder/blob/master/cinder/policies/quotas.py
[1[ https://developer.openstack.org/api-ref/block-storage/v2/index.html#show-quotas

Change-Id: Ib59ff6e4aee22915b408ddd5a30a443173ca4f81
",git fetch https://review.opendev.org/openstack/patrole refs/changes/89/528689/1 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/volume/test_quotas_rbac.py'],1,35bf11da76d8dbbea61a6687b02912486eee2d5d,quotas,"# Copyright 2017 NEC Corporation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.common import utils from tempest.lib import decorators from patrole_tempest_plugin import rbac_rule_validation from patrole_tempest_plugin.tests.api.volume import rbac_base class QuotasV3RbacTest(rbac_base.BaseVolumeRbacTest): @classmethod def skip_checks(cls): super(QuotasV3RbacTest, cls).skip_checks() if not utils.is_extension_enabled('os-quota-sets', 'volume'): msg = (""%s skipped as os-quota-sets not enabled."" % cls.__name__) raise cls.skipException(msg) @classmethod def setup_clients(cls): super(QuotasV3RbacTest, cls).setup_clients() cls.quotas_client = cls.os_primary.quotas_client cls.quota_name = cls.os_primary.credentials.tenant_id @decorators.idempotent_id('dc589d7b-deae-44db-bd7b-84a812e7b7b9') @rbac_rule_validation.action(service=""cinder"", rule=""volume_extension:quotas:show"") def test_show_quota_class_set(self): with self.rbac_utils.override_role(self): self.quotas_client.show_quota_set( self.quota_name)['quota_set'] @decorators.idempotent_id('941b08df-145a-40b6-a3d0-e05dd422f63e') @rbac_rule_validation.action( service=""cinder"", rule=""volume_extension:quotas:show"") def test_show_default_quotas(self): with self.rbac_utils.override_role(self): self.quotas_client.show_default_quota_set( self.quota_name)['quota_set'] @decorators.idempotent_id('dda28d1b-3e9b-4449-8aa4-a45c3ce12a7f') @rbac_rule_validation.action( service=""cinder"", rule=""volume_extension:quotas:show"") def test_show_usage_quotas(self): with self.rbac_utils.override_role(self): self.quotas_client.show_quota_set(self.quota_name, {'usage': True}) ['quota-set'] @decorators.idempotent_id('7473093e-8806-4001-8d75-200c66e60ea3') @rbac_rule_validation.action(service=""cinder"", rule=""volume_extension:quotas:delete"") def test_delete_quota_set(self): with self.rbac_utils.override_role(self): self.quotas_client.delete_quota_set( self.quota_name) @decorators.idempotent_id('ee947c1f-ee39-47a3-98d7-a6681b44cb04') @rbac_rule_validation.action(service=""cinder"", rule=""volume_extension:quotas:update"") def test_update_quota__set(self): quota_set = self.quotas_client.show_quota_set( self.quota_name)['quota_set'] quota_set.pop('id') with self.rbac_utils.override_role(self): self.quotas_client.update_quota_set(self.quota_name, **quota_set) ",,83,0
openstack%2Fpatrole~master~I0237500328bd360482177845de3e7b05c8d175b2,openstack/patrole,master,I0237500328bd360482177845de3e7b05c8d175b2,Adding Missing rbac test for Volume,MERGED,2017-12-07 06:24:36.000000000,2017-12-18 16:52:11.000000000,2017-12-18 16:52:11.000000000,"[{'_account_id': 8556}, {'_account_id': 17896}, {'_account_id': 19457}, {'_account_id': 22348}, {'_account_id': 23185}, {'_account_id': 23186}]","[{'number': 1, 'created': '2017-12-07 06:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/fa0353234530b6b11afa325fb35da765af154563', 'message': ""Adding Missing rbac test for Volume\n\nThis PS adds 'update_snapshot_status' test for policy[0]\n\n[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/snapshot_actions.py#L37\n\nChange-Id: I0237500328bd360482177845de3e7b05c8d175b2\n""}, {'number': 2, 'created': '2017-12-07 07:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/62175e5a80d28f358e58f7dc6c3c35a097322cfe', 'message': ""Adding Missing rbac test for Volume\n\nThis PS adds 'update_snapshot_status' test for policy[0]\n\n[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/snapshot_actions.py#L37\n\nChange-Id: I0237500328bd360482177845de3e7b05c8d175b2\n""}, {'number': 3, 'created': '2017-12-08 05:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/9045955e538877c744c54bc6ea0d5f804d0a0c49', 'message': ""Adding Missing rbac test for Volume\n\nThis PS adds 'update_snapshot_status' test for policy[0]\n\n[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/snapshot_actions.py#L37\n\nChange-Id: I0237500328bd360482177845de3e7b05c8d175b2\n""}, {'number': 4, 'created': '2017-12-11 05:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/dcd8df69ef87229aaadc0680df64ffbb2d36e882', 'message': ""Adding Missing rbac test for Volume\n\nThis PS adds 'update_snapshot_status' test for policy[0]\n\n[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/snapshot_actions.py#L37\n\nChange-Id: I0237500328bd360482177845de3e7b05c8d175b2\n""}, {'number': 5, 'created': '2017-12-12 08:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/d655b3ef167e9841de84e38c15973a0c8fcc2f3a', 'message': ""Adding Missing rbac test for Volume\n\nThis PS adds 'update_snapshot_status' test for policy[0]\n\n[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/snapshot_actions.py#L37\n\nChange-Id: I0237500328bd360482177845de3e7b05c8d175b2\n""}, {'number': 6, 'created': '2017-12-12 14:26:44.000000000', 'files': ['patrole_tempest_plugin/tests/api/volume/test_snapshots_actions_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/b9e3fd8b89d7021955f202e7bba936b4979d0791', 'message': ""Adding Missing rbac test for Volume\n\nThis PS adds 'update_snapshot_status' test for policy[0]\n\n[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/snapshot_actions.py#L37\n\nChange-Id: I0237500328bd360482177845de3e7b05c8d175b2\n""}]",8,526291,b9e3fd8b89d7021955f202e7bba936b4979d0791,27,6,6,25571,,,0,"Adding Missing rbac test for Volume

This PS adds 'update_snapshot_status' test for policy[0]

[0]https://github.com/openstack/cinder/blob/0cf910d4345c000e8c306b1cb2b2dd291975cf71/cinder/policies/snapshot_actions.py#L37

Change-Id: I0237500328bd360482177845de3e7b05c8d175b2
",git fetch https://review.opendev.org/openstack/patrole refs/changes/91/526291/2 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/volume/test_snapshots_actions_rbac.py'],1,fa0353234530b6b11afa325fb35da765af154563,update_snapshot_status,"from tempest.common import waiters @decorators.idempotent_id('a95eab2a-c441-4609-9235-f7478627da88') @rbac_rule_validation.action( service=""cinder"", rule=""snapshot_extension:snapshot_actions:update_snapshot_status"") def test_update_snapshot_status(self): self.rbac_utils.switch_role(self, toggle_rbac_role=True) status = 'creating' self.snapshots_client.reset_snapshot_status( self.snapshot['id'], status) self.snapshots_client.update_snapshot_status(self.snapshot['id'], status='error')",,13,0
openstack%2Fdesignate~master~I4a364a0d1a0656f26d3a4c3b7baad7e43cddcb16,openstack/designate,master,I4a364a0d1a0656f26d3a4c3b7baad7e43cddcb16,Docs Refactor,MERGED,2017-10-31 18:00:57.000000000,2017-12-18 16:49:30.000000000,2017-12-18 16:49:29.000000000,"[{'_account_id': 8099}, {'_account_id': 13252}, {'_account_id': 15736}, {'_account_id': 19930}, {'_account_id': 20663}, {'_account_id': 22348}, {'_account_id': 26734}]","[{'number': 1, 'created': '2017-10-31 18:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/2d99d46664f5ca1a11496a67814c86930f4562c6', 'message': 'Docs Refactor\n\n* Move backend docs to admin guide\n* Add oslo.config sphinx extention\n* Add HA guide\n* Update drivers to log driver grade\n\nChange-Id: I4a364a0d1a0656f26d3a4c3b7baad7e43cddcb16\n'}, {'number': 2, 'created': '2017-11-01 12:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/5f2261de08d05049d176fb01ec6513ffb04ccfe1', 'message': 'Docs Refactor\n\n* Move backend docs to admin guide\n* Add oslo.config sphinx extention\n* Add HA guide\n* Update drivers to log driver grade\n\nChange-Id: I4a364a0d1a0656f26d3a4c3b7baad7e43cddcb16\n'}, {'number': 3, 'created': '2017-12-05 21:06:30.000000000', 'files': ['doc/source/admin/index.rst', 'test-requirements.txt', 'doc/source/admin/backends/infoblox.rst', 'doc/source/admin/backends/powerdns.rst', 'doc/source/admin/backends/sample_yaml_snippets/powerdns.yaml', 'designate/coordination.py', 'doc/source/contributor/index.rst', 'designate/worker/service.py', 'doc/source/admin/ha.rst', 'doc/source/admin/backends/gdnsd_agent.rst', 'doc/source/admin/backends/pdns4.rst', 'doc/source/admin/backends/index.rst', 'doc/source/admin/backends/agent.rst', 'doc/source/admin/backends/knot2_agent.rst', 'doc/source/admin/backends/sample_yaml_snippets/bind.yaml', 'designate/backend/__init__.py', 'doc/source/admin/backends/sample_yaml_snippets/pdns4.yaml', 'doc/source/admin/backends/bind9.rst', 'doc/source/conf.py', 'doc/source/admin/policy.rst', 'doc/source/admin/support-matrix.ini', 'doc/source/admin/backends/djbdns_agent.rst', 'doc/source/admin/backends/msdns_agent.rst', 'doc/source/admin/samples/config.rst', 'doc/source/admin/samples/index.rst', 'doc/source/configuration/index.rst', 'doc/source/admin/backends/sample_yaml_snippets/agent.yaml', 'doc/source/admin/config.rst', 'designate/pool_manager/service.py', 'doc/source/admin/samples/policy-yaml.rst', 'doc/source/admin/support-matrix.rst'], 'web_link': 'https://opendev.org/openstack/designate/commit/3955f474a505dccde7c0ad48319c5ba0c16fc35b', 'message': 'Docs Refactor\n\n* Move backend docs to admin guide\n* Add oslo.config sphinx extention\n* Add HA guide\n* Update drivers to log driver grade\n\nChange-Id: I4a364a0d1a0656f26d3a4c3b7baad7e43cddcb16\n'}]",1,516753,3955f474a505dccde7c0ad48319c5ba0c16fc35b,24,7,3,8099,,,0,"Docs Refactor

* Move backend docs to admin guide
* Add oslo.config sphinx extention
* Add HA guide
* Update drivers to log driver grade

Change-Id: I4a364a0d1a0656f26d3a4c3b7baad7e43cddcb16
",git fetch https://review.opendev.org/openstack/designate refs/changes/53/516753/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/index.rst', 'test-requirements.txt', 'doc/source/admin/backends/infoblox.rst', 'doc/source/admin/backends/powerdns.rst', 'doc/source/admin/backends/sample_yaml_snippets/powerdns.yaml', 'designate/coordination.py', 'doc/source/contributor/index.rst', 'designate/worker/service.py', 'doc/source/admin/ha.rst', 'doc/source/admin/backends/gdnsd_agent.rst', 'doc/source/admin/backends/pdns4.rst', 'doc/source/admin/backends/index.rst', 'doc/source/admin/backends/agent.rst', 'doc/source/admin/backends/knot2_agent.rst', 'doc/source/admin/backends/sample_yaml_snippets/bind.yaml', 'designate/backend/__init__.py', 'doc/source/admin/backends/sample_yaml_snippets/pdns4.yaml', 'doc/source/admin/backends/bind9.rst', 'doc/source/conf.py', 'doc/source/admin/policy.rst', 'doc/source/admin/support-matrix.ini', 'doc/source/admin/backends/djbdns_agent.rst', 'doc/source/admin/backends/msdns_agent.rst', 'doc/source/admin/samples/config.rst', 'doc/source/admin/samples/index.rst', 'doc/source/configuration/index.rst', 'doc/source/admin/backends/sample_yaml_snippets/agent.yaml', 'doc/source/admin/config.rst', 'designate/pool_manager/service.py', 'doc/source/admin/samples/policy-yaml.rst', 'doc/source/admin/support-matrix.rst']",31,2d99d46664f5ca1a11496a67814c86930f4562c6,docs-update,.. _driver_matrix: ,,278,22
openstack%2Fansible-hardening~stable%2Fpike~I2768182f5dde3368028a1a25af69db6ac7a75d9b,openstack/ansible-hardening,stable/pike,I2768182f5dde3368028a1a25af69db6ac7a75d9b,Remove old /etc/profile config block,MERGED,2017-12-15 22:08:40.000000000,2017-12-18 16:37:41.000000000,2017-12-18 16:37:41.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 27143}]","[{'number': 1, 'created': '2017-12-15 22:08:40.000000000', 'files': ['tasks/rhel7stig/misc.yml'], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/42d28b4e2040430b6b8155b42938101cbc9767c9', 'message': 'Remove old /etc/profile config block\n\nWhen the openstack-ansible-security role became ansible-hardening,\na new config block was added to `/etc/profile` without removing\nthe original one with the openstack-ansible-security markers. This\ncauses errors on the command prompt since `TMOUT` is defined twice.\n\nThis patch removes the old config block using blockinfile.\n\nCloses-Bug: 1736702\nChange-Id: I2768182f5dde3368028a1a25af69db6ac7a75d9b\n(cherry picked from commit c8a59a1c9ac00f0e6f9625a2786e3a1fa5168e28)\n'}]",0,528425,42d28b4e2040430b6b8155b42938101cbc9767c9,8,4,1,538,,,0,"Remove old /etc/profile config block

When the openstack-ansible-security role became ansible-hardening,
a new config block was added to `/etc/profile` without removing
the original one with the openstack-ansible-security markers. This
causes errors on the command prompt since `TMOUT` is defined twice.

This patch removes the old config block using blockinfile.

Closes-Bug: 1736702
Change-Id: I2768182f5dde3368028a1a25af69db6ac7a75d9b
(cherry picked from commit c8a59a1c9ac00f0e6f9625a2786e3a1fa5168e28)
",git fetch https://review.opendev.org/openstack/ansible-hardening refs/changes/25/528425/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/rhel7stig/misc.yml'],1,42d28b4e2040430b6b8155b42938101cbc9767c9,bug/1736702-stable/pike,"# NOTE(mhayden): This role changed names and this task ensures that the old # configuration block is properly removed. Without this task, /etc/profile # will have two config blocks that set the same variable and this leads to # errors on the command prompt. See LP bug 1736702. # TODO(mhayden): Remove this task when the Rocky release is in development. - name: Remove old config block for V-72223 from openstack-ansible-security blockinfile: dest: /etc/profile state: absent insertbefore: EOF marker: ""# {mark} MANAGED BY OPENSTACK-ANSIBLE-SECURITY"" tags: - medium - misc - V-72223 state: present",,17,0
openstack%2Fironic-lib~master~Ie069977b793705cea337dd263eb04af072c0e3b3,openstack/ironic-lib,master,Ie069977b793705cea337dd263eb04af072c0e3b3,Updated from global requirements,MERGED,2017-12-15 21:31:31.000000000,2017-12-18 16:36:23.000000000,2017-12-18 16:36:23.000000000,"[{'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 21:31:31.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic-lib/commit/3a5eef20dd722a368c0db91c5d572109a78c0aa4', 'message': 'Updated from global requirements\n\nChange-Id: Ie069977b793705cea337dd263eb04af072c0e3b3\n'}]",0,528403,3a5eef20dd722a368c0db91c5d572109a78c0aa4,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ie069977b793705cea337dd263eb04af072c0e3b3
",git fetch https://review.opendev.org/openstack/ironic-lib refs/changes/03/528403/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3a5eef20dd722a368c0db91c5d572109a78c0aa4,openstack/requirements,"oslo.service!=1.28.1,>=1.24.0 # Apache-2.0",oslo.service>=1.24.0 # Apache-2.0,1,1
openstack%2Ftripleo-heat-templates~master~Ie7a9f10f0c821b8c642494a4d3933b2901f39d40,openstack/tripleo-heat-templates,master,Ie7a9f10f0c821b8c642494a4d3933b2901f39d40,Passes NodeDataLookup to ceph-ansible workflow,MERGED,2017-12-06 13:57:39.000000000,2017-12-18 16:30:35.000000000,2017-12-18 16:30:35.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 8449}, {'_account_id': 9268}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-06 13:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fa4ae9b607fa0ed2d9575351166a5c2bfbc20cf3', 'message': 'Passes NodeDataLookup to ceph-ansible workflow\n\nPer-node customizations were only dumped as hieradata, so the\nceph-ansible workflow could not consume them.\nThis change passes the structure to the mistral workflow so that it\ncan consume the data and populate the inventory accordingly.\n\nChange-Id: Ie7a9f10f0c821b8c642494a4d3933b2901f39d40\nDepends-On: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 2, 'created': '2017-12-06 13:58:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3307d33d3af6ce0dc9000746f0c5525d412a48c8', 'message': 'Passes NodeDataLookup to ceph-ansible workflow\n\nPer-node customizations were only dumped as hieradata, so the\nceph-ansible workflow could not consume them.\nThis change passes the structure to the mistral workflow so that it\ncan consume the data and populate the inventory accordingly.\n\nChange-Id: Ie7a9f10f0c821b8c642494a4d3933b2901f39d40\nDepends-On: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 3, 'created': '2017-12-07 18:00:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/457619dcb2c3f8a3d666e6f73ac8249ec6f01ba0', 'message': 'Passes NodeDataLookup to ceph-ansible workflow\n\nPer-node customizations were only dumped as hieradata, so the\nceph-ansible workflow could not consume them.\nThis change passes the structure to the mistral workflow so that it\ncan consume the data and populate the inventory accordingly.\n\nChange-Id: Ie7a9f10f0c821b8c642494a4d3933b2901f39d40\nDepends-On: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 4, 'created': '2017-12-13 13:38:10.000000000', 'files': ['docker/services/ceph-ansible/ceph-base.yaml', 'puppet/extraconfig/pre_deploy/per_node.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1971e7b049f13a8a2d45fb77412ff1a87ca043c2', 'message': 'Passes NodeDataLookup to ceph-ansible workflow\n\nPer-node customizations were only dumped as hieradata, so the\nceph-ansible workflow could not consume them.\nThis change passes the structure to the mistral workflow so that it\ncan consume the data and populate the inventory accordingly.\n\nChange-Id: Ie7a9f10f0c821b8c642494a4d3933b2901f39d40\nDepends-On: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}]",1,526073,1971e7b049f13a8a2d45fb77412ff1a87ca043c2,20,7,4,6796,,,0,"Passes NodeDataLookup to ceph-ansible workflow

Per-node customizations were only dumped as hieradata, so the
ceph-ansible workflow could not consume them.
This change passes the structure to the mistral workflow so that it
can consume the data and populate the inventory accordingly.

Change-Id: Ie7a9f10f0c821b8c642494a4d3933b2901f39d40
Depends-On: Ia23825aea938f6f9bcf536e35cad562a1b96c93b
Closes-Bug: #1736707
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/73/526073/4 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/ceph-ansible/ceph-base.yaml'],1,fa4ae9b607fa0ed2d9575351166a5c2bfbc20cf3,bug/1736707, NodeDataLookup: type: json default: {} description: json containing per-node configuration map node_data_lokup: {get_param: NodeDataLookup},,5,0
openstack%2Fopenstack-ansible-pip_install~stable%2Fnewton~I6f5bfbb09e1fa45c8d79efb8963ba8cd7fe5d315,openstack/openstack-ansible-pip_install,stable/newton,I6f5bfbb09e1fa45c8d79efb8963ba8cd7fe5d315,Allow all boolean values for uca_enable,MERGED,2017-12-16 09:39:30.000000000,2017-12-18 16:29:54.000000000,2017-12-18 16:29:54.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-16 09:39:30.000000000', 'files': ['tasks/pre_install_apt.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/de2c7a93a825b164a1c26bb8c35faa9a88cf65ea', 'message': 'Allow all boolean values for uca_enable\n\nCurrently uca_enable has to be [Tt]rue or [Ffalse].\nThis patch allows it to be any boolean value recognised\nby ansible.\n\nChange-Id: I6f5bfbb09e1fa45c8d79efb8963ba8cd7fe5d315\n(cherry picked from commit 4e39e427667914c323ccf5dfd3fc53a4d9d85d93)\n'}]",0,528464,de2c7a93a825b164a1c26bb8c35faa9a88cf65ea,7,3,1,6816,,,0,"Allow all boolean values for uca_enable

Currently uca_enable has to be [Tt]rue or [Ffalse].
This patch allows it to be any boolean value recognised
by ansible.

Change-Id: I6f5bfbb09e1fa45c8d79efb8963ba8cd7fe5d315
(cherry picked from commit 4e39e427667914c323ccf5dfd3fc53a4d9d85d93)
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_install refs/changes/64/528464/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/pre_install_apt.yml'],1,de2c7a93a825b164a1c26bb8c35faa9a88cf65ea,uca-bool-stable/newton, - uca_enable | bool, - uca_enable,1,1
openstack%2Fopenstack-ansible-pip_install~stable%2Focata~I6f5bfbb09e1fa45c8d79efb8963ba8cd7fe5d315,openstack/openstack-ansible-pip_install,stable/ocata,I6f5bfbb09e1fa45c8d79efb8963ba8cd7fe5d315,Allow all boolean values for uca_enable,MERGED,2017-12-16 09:39:07.000000000,2017-12-18 16:29:53.000000000,2017-12-18 16:29:53.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-16 09:39:07.000000000', 'files': ['tasks/pre_install_apt.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/ac54eeae6fe04174508aa54632c2566c2df4a66a', 'message': 'Allow all boolean values for uca_enable\n\nCurrently uca_enable has to be [Tt]rue or [Ffalse].\nThis patch allows it to be any boolean value recognised\nby ansible.\n\nChange-Id: I6f5bfbb09e1fa45c8d79efb8963ba8cd7fe5d315\n(cherry picked from commit 4e39e427667914c323ccf5dfd3fc53a4d9d85d93)\n'}]",0,528463,ac54eeae6fe04174508aa54632c2566c2df4a66a,7,3,1,6816,,,0,"Allow all boolean values for uca_enable

Currently uca_enable has to be [Tt]rue or [Ffalse].
This patch allows it to be any boolean value recognised
by ansible.

Change-Id: I6f5bfbb09e1fa45c8d79efb8963ba8cd7fe5d315
(cherry picked from commit 4e39e427667914c323ccf5dfd3fc53a4d9d85d93)
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_install refs/changes/63/528463/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/pre_install_apt.yml'],1,ac54eeae6fe04174508aa54632c2566c2df4a66a,uca-bool-stable/ocata, - uca_enable | bool, - uca_enable,1,1
openstack%2Fcinder~master~Icb1289611bf9713dab9aea5e4701ebb84ebfb2ab,openstack/cinder,master,Icb1289611bf9713dab9aea5e4701ebb84ebfb2ab,CoprHD: Handle certificate error,ABANDONED,2017-01-03 13:22:27.000000000,2017-12-18 16:15:58.000000000,,"[{'_account_id': 4523}, {'_account_id': 6491}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10425}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 12176}, {'_account_id': 12369}, {'_account_id': 13499}, {'_account_id': 14208}, {'_account_id': 14384}, {'_account_id': 14624}, {'_account_id': 15296}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16422}, {'_account_id': 16862}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16952}, {'_account_id': 17103}, {'_account_id': 17565}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19004}, {'_account_id': 19146}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21990}, {'_account_id': 22248}, {'_account_id': 22381}, {'_account_id': 22495}, {'_account_id': 22797}, {'_account_id': 23613}, {'_account_id': 24578}]","[{'number': 1, 'created': '2017-01-03 13:22:27.000000000', 'files': ['cinder/volume/drivers/coprhd/helpers/authentication.py', 'cinder/volume/drivers/coprhd/common.py', 'cinder/volume/drivers/coprhd/helpers/commoncoprhdapi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e1adc82cdbb4e26ed9aaee1a373a1331fb8ebaae', 'message': 'CoprHD: Handle certificate error\n\nThis fix allows user to have secure communication with CoprHD with\neither self signed certificate or CA verified trusted certificate.\n\nUser needs to mention 2 parameters in the cinder.config file for this.\nThe first parameter to tell if certificate verification is needed at all\nand second parameter specifies the path to the self signed certificate.\n\nIf first parameter is true and the second parameter is set to None\nthen its assumed that the CoprHD CA signed certificate authority is\npresent in the trusted certs store of client.\n\nChange-Id: Icb1289611bf9713dab9aea5e4701ebb84ebfb2ab\nCloses-Bug: #1653626\n'}]",2,416236,e1adc82cdbb4e26ed9aaee1a373a1331fb8ebaae,53,39,1,22797,,,0,"CoprHD: Handle certificate error

This fix allows user to have secure communication with CoprHD with
either self signed certificate or CA verified trusted certificate.

User needs to mention 2 parameters in the cinder.config file for this.
The first parameter to tell if certificate verification is needed at all
and second parameter specifies the path to the self signed certificate.

If first parameter is true and the second parameter is set to None
then its assumed that the CoprHD CA signed certificate authority is
present in the trusted certs store of client.

Change-Id: Icb1289611bf9713dab9aea5e4701ebb84ebfb2ab
Closes-Bug: #1653626
",git fetch https://review.opendev.org/openstack/cinder refs/changes/36/416236/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/coprhd/helpers/authentication.py', 'cinder/volume/drivers/coprhd/common.py', 'cinder/volume/drivers/coprhd/helpers/commoncoprhdapi.py']",3,e1adc82cdbb4e26ed9aaee1a373a1331fb8ebaae,bug/1653626,"global VERIFY_CERT VERIFY_CERT = False response = requests.get(url, headers=headers, verify=VERIFY_CERT, verify=VERIFY_CERT, cookies=cookiejar) verify=VERIFY_CERT, cookies=cookiejar) elif http_method == 'DELETE': response = requests.delete(url, headers=headers, verify=VERIFY_CERT,"," response = requests.get(url, headers=headers, verify=False, verify=False, cookies=cookiejar) verify=False, cookies=cookiejar) elif http_method == 'DELETE': response = requests.delete(url, headers=headers, verify=False,",47,13
openstack%2Ftrove-dashboard~master~I7ec028aec01c2c9f400f4a65552b92d13952a1e3,openstack/trove-dashboard,master,I7ec028aec01c2c9f400f4a65552b92d13952a1e3,Fix incorrect example of mysql connection,MERGED,2017-12-11 14:06:04.000000000,2017-12-18 16:12:35.000000000,2017-12-18 16:12:35.000000000,"[{'_account_id': 9664}, {'_account_id': 22348}, {'_account_id': 22818}, {'_account_id': 24739}]","[{'number': 1, 'created': '2017-12-11 14:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/48d92f1c01f27e2b101fe0e44c380cfbb2a66473', 'message': 'Fix incorrect example of mysql connection\n\nThe connection examples of mysql show incorrect information.\nThis patch make it right.\n\nChange-Id: I7ec028aec01c2c9f400f4a65552b92d13952a1e3\n'}, {'number': 2, 'created': '2017-12-14 23:37:05.000000000', 'files': ['trove_dashboard/content/database_clusters/templates/database_clusters/_detail_overview_mysql.html'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/5a4903991e366f3678afc4cbbb34addebd2ef0d1', 'message': 'Fix incorrect example of mysql connection\n\nThe connection examples of mysql show incorrect information.\nThis patch make it right.\n\nChange-Id: I7ec028aec01c2c9f400f4a65552b92d13952a1e3\n'}]",0,527096,5a4903991e366f3678afc4cbbb34addebd2ef0d1,10,4,2,24739,,,0,"Fix incorrect example of mysql connection

The connection examples of mysql show incorrect information.
This patch make it right.

Change-Id: I7ec028aec01c2c9f400f4a65552b92d13952a1e3
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/96/527096/2 && git format-patch -1 --stdout FETCH_HEAD,['trove_dashboard/content/database_clusters/templates/database_clusters/_detail_overview_mysql.html'],1,48d92f1c01f27e2b101fe0e44c380cfbb2a66473,fix_connection_examples," <dd>mysql -h {{ ip }} -u {% trans ""USERNAME"" %} -p</dd> <dd>mysql://{% trans ""USERNAME"" %}:{% trans ""PASSWORD"" %}@{{ ip }}:3306/{% trans ""DATABASE""%}</dd>", <dd>mysql {{ ip }} 3306</dd>,2,1
openstack%2Ftrove-dashboard~master~I28136de2b7c79633dd51bdea5d704038c29aa516,openstack/trove-dashboard,master,I28136de2b7c79633dd51bdea5d704038c29aa516,Fix users page display error,MERGED,2017-12-13 08:30:54.000000000,2017-12-18 16:12:34.000000000,2017-12-18 16:12:34.000000000,"[{'_account_id': 22348}, {'_account_id': 22818}, {'_account_id': 24739}]","[{'number': 1, 'created': '2017-12-13 08:30:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/a3282b48ebeadfb6e8bfbf09358b81454b0650c5', 'message': 'Fix users page display error\n\nAccording bug description, the users page show error\nwith host and dbs.  The cause of the problem is we can\nnot only use user_name as id, it is not unique. Now I\nchanged the id as the combination of user_name and\nuser_host.\n\nChange-Id: I28136de2b7c79633dd51bdea5d704038c29aa516\nCloses-Bug: #1737695\n'}, {'number': 2, 'created': '2017-12-14 23:38:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/5aacdd6b55c2a4824127c4aa75d62b4b8767a056', 'message': 'Fix users page display error\n\nAccording bug description, the users page show error\nwith host and dbs.  The cause of the problem is we can\nnot only use user_name as id, it is not unique. Now I\nchanged the id as the combination of user_name and\nuser_host.\n\nChange-Id: I28136de2b7c79633dd51bdea5d704038c29aa516\nCloses-Bug: #1737695\n'}, {'number': 3, 'created': '2017-12-15 06:17:29.000000000', 'files': ['trove_dashboard/content/databases/tests.py', 'trove_dashboard/content/databases/tables.py'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/ac30be57ae4c02bcd122af28f3d0d73eafe34ac6', 'message': 'Fix users page display error\n\nAccording bug description, the users page show error\nwith host and dbs.  The cause of the problem is we can\nnot only use user_name as id, it is not unique. Now I\nchanged the id as the combination of user_name and\nuser_host.\n\nChange-Id: I28136de2b7c79633dd51bdea5d704038c29aa516\nCloses-Bug: #1737695\n'}]",0,527629,ac30be57ae4c02bcd122af28f3d0d73eafe34ac6,12,3,3,24739,,,0,"Fix users page display error

According bug description, the users page show error
with host and dbs.  The cause of the problem is we can
not only use user_name as id, it is not unique. Now I
changed the id as the combination of user_name and
user_host.

Change-Id: I28136de2b7c79633dd51bdea5d704038c29aa516
Closes-Bug: #1737695
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/29/527629/1 && git format-patch -1 --stdout FETCH_HEAD,['trove_dashboard/content/databases/tables.py'],1,a3282b48ebeadfb6e8bfbf09358b81454b0650c5,bug/1737695," obj_id = datum.name + ""@"" + datum.host return obj_id", return datum.name,2,1
openstack%2Ftrove-dashboard~master~I0693f6735eac58dcfb7f957e7b01b91b93a517ba,openstack/trove-dashboard,master,I0693f6735eac58dcfb7f957e7b01b91b93a517ba,Add host to user access show title,MERGED,2017-12-12 06:38:25.000000000,2017-12-18 16:12:34.000000000,2017-12-18 16:12:34.000000000,"[{'_account_id': 22348}, {'_account_id': 22818}]","[{'number': 1, 'created': '2017-12-12 06:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/77cb2d30d6537a0b54e5022b6407ab5d1a97f592', 'message': 'Add host to user access show title\n\nThe title of  access_detail page just show user_name,\nso we do not know which user_host is running the\nauthorized operation. This maybe cause confusion to user.\n To solve this, this patch add user_host in title.\n\nChange-Id: I0693f6735eac58dcfb7f957e7b01b91b93a517ba\n'}, {'number': 2, 'created': '2017-12-14 23:40:06.000000000', 'files': ['trove_dashboard/content/databases/views.py'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/5b5cf8579c21429354d8f5fb7ad3ce34a3fa635c', 'message': 'Add host to user access show title\n\nThe title of  access_detail page just show user_name,\nso we do not know which user_host is running the\nauthorized operation. This maybe cause confusion to user.\n To solve this, this patch add user_host in title.\n\nChange-Id: I0693f6735eac58dcfb7f957e7b01b91b93a517ba\n'}]",0,527314,5b5cf8579c21429354d8f5fb7ad3ce34a3fa635c,8,2,2,24739,,,0,"Add host to user access show title

The title of  access_detail page just show user_name,
so we do not know which user_host is running the
authorized operation. This maybe cause confusion to user.
 To solve this, this patch add user_host in title.

Change-Id: I0693f6735eac58dcfb7f957e7b01b91b93a517ba
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/14/527314/2 && git format-patch -1 --stdout FETCH_HEAD,['trove_dashboard/content/databases/views.py'],1,77cb2d30d6537a0b54e5022b6407ab5d1a97f592,add_host_to_user_access," page_title = _(""Database Access for: {{ user_name }}@{{user_host}}"")"," page_title = _(""Database Access for: {{ user_name }}"")",1,1
openstack%2Fansible-hardening~master~I24a23fb485f2269ae6f627533b3a725f6699d230,openstack/ansible-hardening,master,I24a23fb485f2269ae6f627533b3a725f6699d230,tasks: Add missing tags for async tasks,MERGED,2017-12-13 12:55:53.000000000,2017-12-18 16:10:44.000000000,2017-12-16 10:41:27.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 12:55:53.000000000', 'files': ['tasks/rhel7stig/auth.yml', 'tasks/rhel7stig/zypper.yml', 'tasks/rhel7stig/rpm.yml', 'tasks/rhel7stig/async_tasks.yml'], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/d6ead42b8fe48efaec2b61e26a7584cb5a636e06', 'message': 'tasks: Add missing tags for async tasks\n\nWhen running the role using a specific tag (eg -t auth), some tasks\ntry to check the status of the async ones and they fail because the\nasync task was never executed due to missing the \'always\' tag. We can\nfix that by adding the missing tags to the async tasks.\n\nFor example,\n\nTASK [ansible-hardening : Remove .shosts or shosts.equiv files]\n******************************************************************************************************************************\nfatal: [localhost]: FAILED! => {""failed"": true, ""msg"": ""\'job_result\' is undefined""}\n\nSo we add the appropriate tags to the async tasks.\n\nChange-Id: I24a23fb485f2269ae6f627533b3a725f6699d230\n'}]",0,527685,d6ead42b8fe48efaec2b61e26a7584cb5a636e06,8,3,1,23163,,,0,"tasks: Add missing tags for async tasks

When running the role using a specific tag (eg -t auth), some tasks
try to check the status of the async ones and they fail because the
async task was never executed due to missing the 'always' tag. We can
fix that by adding the missing tags to the async tasks.

For example,

TASK [ansible-hardening : Remove .shosts or shosts.equiv files]
******************************************************************************************************************************
fatal: [localhost]: FAILED! => {""failed"": true, ""msg"": ""'job_result' is undefined""}

So we add the appropriate tags to the async tasks.

Change-Id: I24a23fb485f2269ae6f627533b3a725f6699d230
",git fetch https://review.opendev.org/openstack/ansible-hardening refs/changes/85/527685/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/rhel7stig/auth.yml', 'tasks/rhel7stig/zypper.yml', 'tasks/rhel7stig/rpm.yml', 'tasks/rhel7stig/async_tasks.yml']",4,d6ead42b8fe48efaec2b61e26a7584cb5a636e06,fix-job-results, - rpm - high - V-71855 tags: - high - auth - V-72277 - V-72279,,21,0
openstack%2Freleases~master~I7722030643bd30ee883abf65bd6fca10dcf18cac,openstack/releases,master,I7722030643bd30ee883abf65bd6fca10dcf18cac,Release puppet-ceph 2.4.2,MERGED,2017-12-15 18:15:28.000000000,2017-12-18 16:02:58.000000000,2017-12-18 16:02:58.000000000,"[{'_account_id': 1004}, {'_account_id': 6796}, {'_account_id': 11904}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 18:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/bac677e6f95998040d1509b37411db3b3c0991c0', 'message': 'Release puppet-ceph 2.4.2\n\nChange-Id: I7722030643bd30ee883abf65bd6fca10dcf18cac\n'}, {'number': 2, 'created': '2017-12-15 22:17:06.000000000', 'files': ['deliverables/_independent/puppet-ceph.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/b86cd08fb5c26ca13594f1a17025f30ab7504716', 'message': 'Release puppet-ceph 2.4.2\n\nChange-Id: I7722030643bd30ee883abf65bd6fca10dcf18cac\n'}]",2,528367,b86cd08fb5c26ca13594f1a17025f30ab7504716,12,5,2,14985,,,0,"Release puppet-ceph 2.4.2

Change-Id: I7722030643bd30ee883abf65bd6fca10dcf18cac
",git fetch https://review.opendev.org/openstack/releases refs/changes/67/528367/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/puppet-ceph.yaml'],1,bac677e6f95998040d1509b37411db3b3c0991c0,puppet-ceph-2.4.2, - projects: - hash: da96ae79cd581841af35a5e0b31426d6a7974af9 repo: openstack/puppet-ceph version: 2.4.2 ,,5,0
openstack%2Fpuppet-nova~master~Icf0dc0ad8040a54147fd03f790825760b2c1a3f3,openstack/puppet-nova,master,Icf0dc0ad8040a54147fd03f790825760b2c1a3f3,Restore NoopQuotaDriver in child cell with CellsV1,MERGED,2017-12-13 16:18:31.000000000,2017-12-18 16:01:15.000000000,2017-12-18 16:01:15.000000000,"[{'_account_id': 3153}, {'_account_id': 7156}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 16:18:31.000000000', 'files': ['spec/classes/nova_cells_spec.rb', 'releasenotes/notes/cellsv1-quota-driver-24498d3b83e9e824.yaml', 'manifests/cells.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/027a7d35ac6c8bf5b9e9d5e7efcb1fc6cac21c78', 'message': 'Restore NoopQuotaDriver in child cell with CellsV1\n\nIt is still required to disable quota checking in child cells.\n\nChange-Id: Icf0dc0ad8040a54147fd03f790825760b2c1a3f3\nCloses-bug: #1738035\n'}]",2,527732,027a7d35ac6c8bf5b9e9d5e7efcb1fc6cac21c78,14,4,1,7156,,,0,"Restore NoopQuotaDriver in child cell with CellsV1

It is still required to disable quota checking in child cells.

Change-Id: Icf0dc0ad8040a54147fd03f790825760b2c1a3f3
Closes-bug: #1738035
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/32/527732/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/nova_cells_spec.rb', 'releasenotes/notes/cellsv1-quota-driver-24498d3b83e9e824.yaml', 'manifests/cells.pp']",3,027a7d35ac6c8bf5b9e9d5e7efcb1fc6cac21c78,bug/1738035, nova_config { 'DEFAULT/quota_driver': value => 'nova.quota.NoopQuotaDriver' },,7,0
openstack%2Fpuppet-designate~master~I150157162d7dce536606778d5dda5bd8356cb799,openstack/puppet-designate,master,I150157162d7dce536606778d5dda5bd8356cb799,Enable worker service when deploying it,MERGED,2017-12-14 18:12:00.000000000,2017-12-18 16:00:33.000000000,2017-12-16 03:32:53.000000000,"[{'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 7385}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-14 18:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/7d453d0889c001613b89f1a2b2f4122a71d31d40', 'message': 'Enable worker service when deploying it\n\nCurrently when deploying the worker service, you get a message like\n\nYou do not have designate-worker enabled, starting designate-worker\nis not allowed.\n\nin the log when the service attempts to start.  This is because the\nservice:worker/enabled setting is not set to true.  When the worker\nservice is enabled that setting should be as well.\n\nChange-Id: I150157162d7dce536606778d5dda5bd8356cb799\n'}, {'number': 2, 'created': '2017-12-14 18:28:39.000000000', 'files': ['manifests/worker.pp', 'spec/classes/designate_worker_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/dca15cf79a529c55db08303f0a6ee01479107781', 'message': 'Enable worker service when deploying it\n\nCurrently when deploying the worker service, you get a message like\n\nYou do not have designate-worker enabled, starting designate-worker\nis not allowed.\n\nin the log when the service attempts to start.  This is because the\nservice:worker/enabled setting is not set to true.  When the worker\nservice is enabled that setting should be as well.\n\nChange-Id: I150157162d7dce536606778d5dda5bd8356cb799\n'}]",0,528025,dca15cf79a529c55db08303f0a6ee01479107781,15,5,2,6928,,,0,"Enable worker service when deploying it

Currently when deploying the worker service, you get a message like

You do not have designate-worker enabled, starting designate-worker
is not allowed.

in the log when the service attempts to start.  This is because the
service:worker/enabled setting is not set to true.  When the worker
service is enabled that setting should be as well.

Change-Id: I150157162d7dce536606778d5dda5bd8356cb799
",git fetch https://review.opendev.org/openstack/puppet-designate refs/changes/25/528025/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/worker.pp'],1,7d453d0889c001613b89f1a2b2f4122a71d31d40,, 'service:worker/enabled': value => $enabled;,,1,0
openstack%2Fnetworking-sfc~stable%2Fpike~Ib70a72049bdf18047c52e00fe0d527fc1bad6ec6,openstack/networking-sfc,stable/pike,Ib70a72049bdf18047c52e00fe0d527fc1bad6ec6,Fix multinode tempest tests,ABANDONED,2017-10-31 08:42:26.000000000,2017-12-18 15:59:43.000000000,,"[{'_account_id': 6854}, {'_account_id': 11313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-31 08:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/db3602db0f4b2e5c9d2c0f96674f36f75fdbf34a', 'message': 'Fix multinode tempest tests\n\n* For server creation, use scheduler hints to select compute node\n* Merge single and multi node tests (base on compute nodes count)\n* Sync manager with current tempest version (should be trimmed out for\n  networking-sfc use later)\n\nChange-Id: Ib70a72049bdf18047c52e00fe0d527fc1bad6ec6\nCloses-Bug: #1660700\n(cherry picked from commit ef55b2d15bfed3337b8d803e80561f8d7d1c17ba)\n'}, {'number': 2, 'created': '2017-12-05 12:39:21.000000000', 'files': ['networking_sfc/tests/tempest_plugin/tests/scenario/manager.py', 'networking_sfc/tests/tempest_plugin/tests/scenario/test_sfc.py', 'networking_sfc/tests/tempest_plugin/tests/scenario/test_sfc_multinode.py'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/ffcbcc7562eef4cdbd8a0a85806b16def7b41db1', 'message': 'Fix multinode tempest tests\n\n* For server creation, use scheduler hints to select compute node\n* Merge single and multi node tests (base on compute nodes count)\n* Sync manager with current tempest version (should be trimmed out for\n  networking-sfc use later)\n\nChange-Id: Ib70a72049bdf18047c52e00fe0d527fc1bad6ec6\nCloses-Bug: #1660700\nDepends-On: Iaf6f8cc1eba9a75adbc824ec80d14519b4665642\n(cherry picked from commit ef55b2d15bfed3337b8d803e80561f8d7d1c17ba)\n'}]",2,516557,ffcbcc7562eef4cdbd8a0a85806b16def7b41db1,9,4,2,21798,,,0,"Fix multinode tempest tests

* For server creation, use scheduler hints to select compute node
* Merge single and multi node tests (base on compute nodes count)
* Sync manager with current tempest version (should be trimmed out for
  networking-sfc use later)

Change-Id: Ib70a72049bdf18047c52e00fe0d527fc1bad6ec6
Closes-Bug: #1660700
Depends-On: Iaf6f8cc1eba9a75adbc824ec80d14519b4665642
(cherry picked from commit ef55b2d15bfed3337b8d803e80561f8d7d1c17ba)
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/57/516557/2 && git format-patch -1 --stdout FETCH_HEAD,"['networking_sfc/tests/tempest_plugin/tests/scenario/manager.py', 'networking_sfc/tests/tempest_plugin/tests/scenario/test_sfc.py', 'networking_sfc/tests/tempest_plugin/tests/scenario/test_sfc_multinode.py']",3,db3602db0f4b2e5c9d2c0f96674f36f75fdbf34a,bug/1660700-stable/pike,,"# Copyright 2016 Futurewei. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import testscenarios from tempest.common import waiters from tempest import config from tempest import exceptions from networking_sfc.tests.tempest_plugin.tests.scenario import test_sfc CONF = config.CONF load_tests = testscenarios.load_tests_apply_scenarios class TestSfcMultinode(test_sfc.TestSfc): @classmethod def skip_checks(cls): super(TestSfcMultinode, cls).skip_checks() if CONF.compute.min_compute_nodes < 2: raise cls.skipException( ""Less than 2 compute nodes, skipping multinode tests."") # @classmethod # def setup_credentials(cls): # super(TestSfcMultinode, cls).setup_credentials() # cls.os_primary = cls.os_admin # cls.os = cls.os_adm @classmethod def setup_clients(cls): super(TestSfcMultinode, cls).setup_clients() # Use admin client by default # cls.os_primary = cls.os_admin # this is needed so that we can use the availability_zone:host # scheduler hint, which is admin_only by default # cls.servers_client = cls.os_admin.servers_client # super(TestSfcMultinode, cls).resource_setup() def _setup_security_group(self): self.security_group = self._create_security_group( security_group_rules_client=( self.os_admin.security_group_rules_client ), security_groups_client=self.os_admin.security_groups_client ) self._create_security_group_rule( self.security_group, security_group_rules_client=( self.os_admin.security_group_rules_client ), security_groups_client=self.os_admin.security_groups_client, protocol=None, direction='ingress' ) def setUp(self): super(TestSfcMultinode, self).setUp() host_client = self.os_primary.hosts_client hosts = host_client.list_hosts()['hosts'] hosts = [x for x in hosts if x['service'] == 'compute'] # ensure we have at least as many compute hosts as we expect if len(hosts) < CONF.compute.min_compute_nodes: raise exceptions.InvalidConfiguration( ""Host list %s is shorter than min_compute_nodes. "" ""Did a compute worker not boot correctly?"" % hosts) self.hosts = hosts self.host_index_to_create = 0 def _create_server(self, network): kwargs = {} host = self.hosts[self.host_index_to_create] if self.host_index_to_create >= len(self.hosts): self.host_index_to_create = 0 else: self.host_index_to_create += 1 if self.keypair is not None: kwargs['key_name'] = self.keypair['name'] if self.security_group is not None: kwargs['security_groups'] = [{'name': self.security_group['name']}] server = self.create_server( availability_zone='%(zone)s:%(host_name)s' % host, networks=[{'uuid': network['id']}], wait_until='ACTIVE', clients=self.os_admin, **kwargs) waiters.wait_for_server_status(self.servers_client, server['id'], 'ACTIVE') self._check_tenant_network_connectivity( server, self.ssh_user, self.keypair['private_key']) return server ",125,178
openstack%2Fcompute-hyperv~master~I9ab5fb42da16d6e13f6411ecd5eb475aea38960f,openstack/compute-hyperv,master,I9ab5fb42da16d6e13f6411ecd5eb475aea38960f,Adds docs and reno jobs,MERGED,2017-12-18 10:29:23.000000000,2017-12-18 15:59:36.000000000,2017-12-18 15:59:36.000000000,"[{'_account_id': 8213}, {'_account_id': 8543}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 10:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/01448ff8716c0c523c235ce2fba21cf34a0fef9a', 'message': 'Adds docs and reno jobs\n\nChange-Id: I9ab5fb42da16d6e13f6411ecd5eb475aea38960f\n'}, {'number': 2, 'created': '2017-12-18 11:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/b94cdfcf69112ee19fe8aa00aa336468d38ac93e', 'message': 'Adds docs and reno jobs\n\nChange-Id: I9ab5fb42da16d6e13f6411ecd5eb475aea38960f\n'}, {'number': 3, 'created': '2017-12-18 11:51:44.000000000', 'files': ['releasenotes/notes/.placeholder', 'releasenotes/source/unreleased.rst', '.gitignore', 'test-requirements.txt', '.zuul.yaml', 'releasenotes/source/_static/.placeholder', 'releasenotes/source/_templates/.placeholder', 'releasenotes/source/index.rst', 'tox.ini', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/a550636298ee7f02321826ab9a7d6c0d02e2c511', 'message': 'Adds docs and reno jobs\n\nChange-Id: I9ab5fb42da16d6e13f6411ecd5eb475aea38960f\n'}]",0,528684,a550636298ee7f02321826ab9a7d6c0d02e2c511,11,3,3,8213,,,0,"Adds docs and reno jobs

Change-Id: I9ab5fb42da16d6e13f6411ecd5eb475aea38960f
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/84/528684/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,01448ff8716c0c523c235ce2fba21cf34a0fef9a,,- project: name: openstack/compute-hyperv check: jobs: - build-openstack-releasenotes - build-openstack-sphinx-docs gate: jobs: - build-openstack-releasenotes - build-openstack-sphinx-docs ,,10,0
openstack%2Ftripleo-heat-templates~master~I704e3c294e74a3ed91b01b9ec2a47294c186ad83,openstack/tripleo-heat-templates,master,I704e3c294e74a3ed91b01b9ec2a47294c186ad83,DMN: testing scenarios,ABANDONED,2017-11-14 21:17:02.000000000,2017-12-18 15:58:32.000000000,,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-11-14 21:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/58076868ee3bec1934d2bf4c7ea56998ef63fe9c', 'message': 'DNM: Test heat-agents fix\n\nChange-Id: I704e3c294e74a3ed91b01b9ec2a47294c186ad83\nDepends-On: I82dff4a4b9fac05c5ec649db3eb379bdec71e208\nRelated-Bug: #1731540\n'}, {'number': 2, 'created': '2017-11-16 17:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d3f25685cf63076c8a9bbeb5abf8ec2d337274cd', 'message': 'DNM: Testing debug neutron metadata\n\nChange-Id: I704e3c294e74a3ed91b01b9ec2a47294c186ad83\nDepends-On: I7ef636b8ad4c6fe4f05970c41c05d522a0f0d892\n'}, {'number': 3, 'created': '2017-11-16 19:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d5dde6bf0d2611fe08a1b8c56f6986e626a44a4c', 'message': 'DNM: Testing debug neutron metadata\n\nChange-Id: I704e3c294e74a3ed91b01b9ec2a47294c186ad83\nDepends-On: I7ef636b8ad4c6fe4f05970c41c05d522a0f0d892\n'}, {'number': 4, 'created': '2017-11-17 04:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2c2ce1435c6e918196b0b90f196f4d113a7b2810', 'message': 'DNM: Testing debug neutron metadata\n\nChange-Id: I704e3c294e74a3ed91b01b9ec2a47294c186ad83\nDepends-On: I7ef636b8ad4c6fe4f05970c41c05d522a0f0d892\n'}, {'number': 5, 'created': '2017-11-17 21:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1f08446ceb75be7ff0875ae8267015c2fda28826', 'message': 'DNM: Testing debug neutron metadata\n\nChange-Id: I704e3c294e74a3ed91b01b9ec2a47294c186ad83\nDepends-On: I0a44bfc27b306bfb08dab0656e3362503f07d6b3\n'}, {'number': 6, 'created': '2017-11-22 17:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4e7a594ce3ce415fc06d2fe20fa28b5bfe403dcd', 'message': 'DNM: libvirt scram auth\n\nChange-Id: I704e3c294e74a3ed91b01b9ec2a47294c186ad83\nDepends-On: I3c2a7921426bcd99d6340a913787edfb9bbd8bbd\n'}, {'number': 7, 'created': '2017-11-22 17:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/484db3c1077ee1da459f0ed349bc3a04941c57fc', 'message': 'DNM: libvirt scram auth\n\nChange-Id: I704e3c294e74a3ed91b01b9ec2a47294c186ad83\n'}, {'number': 8, 'created': '2017-11-22 17:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eeb2fdbce6ec3e982419c2d601b3d88d40899d48', 'message': 'DNM: libvirt scram auth\n\nChange-Id: I704e3c294e74a3ed91b01b9ec2a47294c186ad83\n'}, {'number': 9, 'created': '2017-11-28 20:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d3dc311d1f7fdc69cc9e40de4078d60c5615f795', 'message': 'DMN: testing scenarios\n\nChange-Id: I704e3c294e74a3ed91b01b9ec2a47294c186ad83\n'}, {'number': 10, 'created': '2017-11-28 20:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a50a8c72e0819c5533c3c77b2592c368de5ba37a', 'message': 'DMN: testing scenarios\n\nChange-Id: I704e3c294e74a3ed91b01b9ec2a47294c186ad83\n'}, {'number': 11, 'created': '2017-11-28 20:44:31.000000000', 'files': ['ci/environments/scenario001-multinode-containers.yaml', 'ci/environments/scenario002-multinode-containers.yaml', 'ci/environments/scenario004-multinode-containers.yaml', 'ci/environments/scenario003-multinode-containers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b52085c1a31b39397343969c5c3f003fc12259a8', 'message': 'DMN: testing scenarios\n\nChange-Id: I704e3c294e74a3ed91b01b9ec2a47294c186ad83\n'}]",0,519756,b52085c1a31b39397343969c5c3f003fc12259a8,48,3,11,14985,,,0,"DMN: testing scenarios

Change-Id: I704e3c294e74a3ed91b01b9ec2a47294c186ad83
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/56/519756/2 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario001-multinode-containers.yaml', 'ci/environments/scenario002-multinode-containers.yaml', 'ci/environments/scenario004-multinode-containers.yaml', 'ci/environments/scenario003-multinode-containers.yaml']",4,58076868ee3bec1934d2bf4c7ea56998ef63fe9c,bug/1731540,#,,4,0
openstack%2Fpython-openstackclient~master~Iafca8b902d8a99368658e54dfdf39af23cbc3acf,openstack/python-openstackclient,master,Iafca8b902d8a99368658e54dfdf39af23cbc3acf,Develop api.versions for microversion discovery,ABANDONED,2017-03-30 01:52:06.000000000,2017-12-18 15:56:18.000000000,,"[{'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8276}, {'_account_id': 13252}, {'_account_id': 18332}]","[{'number': 1, 'created': '2017-03-30 01:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/30142537d47c65b3526f97c9e074b9b29aa46802', 'message': 'start using api.versions\n\nopenstackclient.api.versions implements some common discovery functions\nthat may move into keystoneauth someday.  It is based on ideas from\nnovaclient.api_versions, and the APIVersion class is directly lifted\nfrom there.  Exceptions have been changed to use ksa exceptions.\n\nConvert compute.client to use api.versions rather than novaclient for\nversion validation and discovery.\n\nChange-Id: Iafca8b902d8a99368658e54dfdf39af23cbc3acf\n'}, {'number': 2, 'created': '2017-03-30 17:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c9d31ca26ce6d8e8938f96aba89b12d129a50d61', 'message': 'start using api.versions\n\nopenstackclient.api.versions implements some common discovery functions\nthat may move into keystoneauth someday.  It is based on ideas from\nnovaclient.api_versions, and the APIVersion class is directly lifted\nfrom there.  Exceptions have been changed to use ksa exceptions.\n\nConvert compute.client to use api.versions rather than novaclient for\nversion validation and discovery.\n\nChange-Id: Iafca8b902d8a99368658e54dfdf39af23cbc3acf\n'}, {'number': 3, 'created': '2017-03-31 14:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/897ed93c8920ab1b3512ce3ee0b7c797e4f3b16e', 'message': 'start using api.versions\n\nopenstackclient.api.versions implements some common discovery functions\nthat may move into keystoneauth someday.  It is based on ideas from\nnovaclient.api_versions, and the APIVersion class is directly lifted\nfrom there.  Exceptions have been changed to use ksa exceptions.\n\nConvert compute.client to use api.versions rather than novaclient for\nversion validation and discovery.\n\nIncludes an example to compare novaclient with api.versions.\n\nChange-Id: Iafca8b902d8a99368658e54dfdf39af23cbc3acf\n'}, {'number': 4, 'created': '2017-03-31 22:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3be0b433b279b2814d49686c9279aed61ccbfc39', 'message': 'start using api.versions\n\nopenstackclient.api.versions implements some common discovery functions\nthat may move into keystoneauth someday.  It is based on ideas from\nnovaclient.api_versions, and the APIVersion class is directly lifted\nfrom there.  Exceptions have been changed to use ksa exceptions.\n\nConvert compute.client to use api.versions rather than novaclient for\nversion validation and discovery.\n\ndiscover_version() has changed in that it no longer considers the\nclient min/max versions as this is meant to be a general-use function.\nThe caller should first validate the version it is requesting.\n\nIncludes an example to compare novaclient with api.versions.\n\nChange-Id: Iafca8b902d8a99368658e54dfdf39af23cbc3acf\n'}, {'number': 5, 'created': '2017-04-05 18:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b58d0ec27dc53fcf6840bdbe3292d0d6772439df', 'message': 'Develop api.versions for microversion discovery\n\nopenstackclient.api.versions implements some common discovery functions\nthat may move into keystoneauth someday.  It is based on ideas from\nnovaclient and cinderclient api_versions, and the APIVersion class is\ndirectly lifted from there.  Exceptions have been changed to use ksa\nexceptions or define new ones.\n\nConvert compute.client to use api.versions rather than novaclient for\nversion validation and discovery.\n\ndiscover_version() has changed in that it no longer considers the\nclient min/max versions as this is meant to be a general-use function.\nget_range_overlap() has been added to perform this check so the\ncan first validate the version it is requesting.\n\nIncludes an example to compare novaclient with api.versions.\n\nChange-Id: Iafca8b902d8a99368658e54dfdf39af23cbc3acf\n'}, {'number': 6, 'created': '2017-04-26 16:33:57.000000000', 'files': ['openstackclient/tests/unit/api/test_versions.py', 'openstackclient/api/versions.py', 'openstackclient/compute/client.py', 'examples/versions.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/43dbd3f457246eadf394e325c16764921bfdde90', 'message': 'Develop api.versions for microversion discovery\n\nopenstackclient.api.versions implements some common discovery functions\nthat may move into keystoneauth someday.  It is based on ideas from\nnovaclient and cinderclient api_versions, and the APIVersion class is\ndirectly lifted from there.  Exceptions have been changed to use ksa\nexceptions or define new ones.\n\nConvert compute.client to use api.versions rather than novaclient for\nversion validation and discovery.\n\ndiscover_version() has changed in that it no longer considers the\nclient min/max versions as this is meant to be a general-use function.\nget_range_overlap() has been added to perform this check so the\ncan first validate the version it is requesting.\n\nIncludes an example to compare novaclient with api.versions.\n\nChange-Id: Iafca8b902d8a99368658e54dfdf39af23cbc3acf\n'}]",19,451618,43dbd3f457246eadf394e325c16764921bfdde90,26,5,6,970,,,0,"Develop api.versions for microversion discovery

openstackclient.api.versions implements some common discovery functions
that may move into keystoneauth someday.  It is based on ideas from
novaclient and cinderclient api_versions, and the APIVersion class is
directly lifted from there.  Exceptions have been changed to use ksa
exceptions or define new ones.

Convert compute.client to use api.versions rather than novaclient for
version validation and discovery.

discover_version() has changed in that it no longer considers the
client min/max versions as this is meant to be a general-use function.
get_range_overlap() has been added to perform this check so the
can first validate the version it is requesting.

Includes an example to compare novaclient with api.versions.

Change-Id: Iafca8b902d8a99368658e54dfdf39af23cbc3acf
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/18/451618/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/api/versions.py', 'openstackclient/compute/client.py']",2,30142537d47c65b3526f97c9e074b9b29aa46802,api-versions,"from keystoneauth1 import exceptions as ksa_exceptions from openstackclient.api import versions as osc_versions """"""Returns a compute service client"""""" from novaclient import api_versions as nova_versions endpoint = instance.get_endpoint_for_service_type( API_NAME, region_name=instance.region_name, interface=instance.interface, ) if _compute_api_version is not None: # Grab the saved client version object if available version = _compute_api_version else: # Use our default as the ultimate fallback version = osc_versions.get_api_version(DEFAULT_API_VERSION) version = osc_versions.discover_version( session=instance.session, url=endpoint, client_ver=version, ) # Make a Nova version version = nova_versions.get_api_version(version.get_string()) LOG.debug('Instantiating compute client for %s', version) """"""Validate API version supplied by user for client * throws an exception if the version is not supported by the client # from novaclient import api_versions # Hacks for compat if check_version == ""2"": check_version = ""2.0"" api_min_version = osc_versions.APIVersion( novaclient.API_MIN_VERSION.get_string(), ) api_max_version = osc_versions.APIVersion( novaclient.API_MAX_VERSION.get_string(), ) # Save the user-supplied version object for make_client() _compute_api_version = osc_versions.get_api_version(check_version, ['2']) if not _compute_api_version.is_latest(): if _compute_api_version > osc_versions.APIVersion(""2.0""): api_min_version, api_max_version, ): msg = _( ""Version %(version)s unsupported. Supported client "" ""versions are '%(min)s' to '%(max)s'"") % { ""version"": _compute_api_version.get_string(), raise ksa_exceptions.VersionNotAvailable(msg)","from osc_lib import exceptions """"""Returns a compute service client."""""" if _compute_api_version is not None: version = _compute_api_version else: version = instance._api_version[API_NAME] from novaclient import api_versions # convert to APIVersion object version = api_versions.get_api_version(version) if version.is_latest(): import novaclient # NOTE(RuiChen): executing version discovery make sense, but that need # an initialized REST client, it's not available now, # fallback to use the max version of novaclient side. version = novaclient.API_MAX_VERSION LOG.debug('Instantiating compute client for %s', version) """"""Validate version supplied by user * throws an exception if the version is no good TODO(dtroyer): make the exception thrown a version-related one from novaclient import api_versions # Copy some logic from novaclient 3.3.0 for basic version detection # NOTE(dtroyer): This is only enough to resume operations using API # version 2.0 or any valid version supplied by the user. _compute_api_version = api_versions.get_api_version(check_version) # Bypass X.latest format microversion if not _compute_api_version.is_latest(): if _compute_api_version > api_versions.APIVersion(""2.0""): novaclient.API_MIN_VERSION, novaclient.API_MAX_VERSION, ): msg = _(""versions supported by client: %(min)s - %(max)s"") % { raise exceptions.CommandError(msg)",311,34
openstack%2Fpanko~stable%2Fpike~I871c87e19b2dc09770830cda80aac586f90dd429,openstack/panko,stable/pike,I871c87e19b2dc09770830cda80aac586f90dd429,remove paas format,MERGED,2017-12-14 14:57:17.000000000,2017-12-18 15:53:12.000000000,2017-12-18 15:53:12.000000000,"[{'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-14 14:57:17.000000000', 'files': ['doc/source/format.rst'], 'web_link': 'https://opendev.org/openstack/panko/commit/512397613132ee3679c37462f19d6710f4321419', 'message': ""remove paas format\n\nthis isn't referenced anywhere and was removed a while ago in\nceilometer docs\n\nChange-Id: I871c87e19b2dc09770830cda80aac586f90dd429\nsee: I3a50edaf12921684e8c8bd070a2b7dbfee4311fd\n(cherry picked from commit c7dcbc8a0a99513ebdc802c6d17f1ac5a7f7b00d)\n""}]",0,527983,512397613132ee3679c37462f19d6710f4321419,8,3,1,6537,,,0,"remove paas format

this isn't referenced anywhere and was removed a while ago in
ceilometer docs

Change-Id: I871c87e19b2dc09770830cda80aac586f90dd429
see: I3a50edaf12921684e8c8bd070a2b7dbfee4311fd
(cherry picked from commit c7dcbc8a0a99513ebdc802c6d17f1ac5a7f7b00d)
",git fetch https://review.opendev.org/openstack/panko refs/changes/83/527983/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/format.rst'],1,512397613132ee3679c37462f19d6710f4321419,paas-stable/pike,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. _paas_event_format: ================= PaaS Event Format ================= There are a number of PaaS services that are currently under development and a growing number of applications running on top of OpenStack infrastructure. In an effort to avoid significant integration work that would be required if each service produced a unique notification payload, we have defined a minimum data set that provides the core data elements needed for downstream metering processes. This format is not enforced by Panko but serves as an advisory guideline for PaaS service developers: :: [ { ""Field"": ""event_type"", ""Type"": ""enumeration"", ""Description"": ""for event type records, this describes the actual event that occurred"", ""Compliance"": ""required for events"", ""Notes"": ""depends on service, defaults to create, exists, delete"" }, { ""Field"": ""timestamp"", ""Type"": ""UTC DateTime"", ""Description"": ""timestamp of when this event was generated at the resource"", ""Compliance"": ""required"", ""Notes"": ""ISO 8859 date YYYY-mm-ddThh:mm:ss"" }, { ""Field"": ""message_id"", ""Type"": ""String"", ""Description"": ""unique identifier for event"", ""Compliance"": ""required"", ""Notes"": """" }, { ""payload"": [ { ""Field"": ""version"", ""Type"": ""String"", ""Description"": ""Version of event format"", ""Compliance"": ""required"", ""Notes"": """" }, { ""Field"": ""audit_period_beginning"", ""Type"": ""UTC DateTime"", ""Description"": ""Represents start time for metrics reported"", ""Compliance"": ""required"", ""Notes"": ""Format ISO 8859 date YYYY-mm-ddThh:mm:ss"" }, { ""Field"": ""audit_period_ending"", ""Type"": ""UTC DateTime"", ""Description"": ""Represents end time for metrics reported"", ""Compliance"": ""required"", ""Notes"": ""Format ISO 8859 date YYYY-mm-ddThh:mm:ss"" }, { ""Field"": ""record_type"", ""Type"": ""enumeration "", ""Values"": { ""event"": ""events describe some kind of state change in the service"", ""quantity"": ""quantity describes a usage metric value"" }, ""Compliance"": ""optional"", ""Notes"": """" }, { ""Field"": ""project_id"", ""Type"": ""UUID"", ""Description"": ""Keystone project_id identifies the owner of the service instance"", ""Compliance"": ""required"", ""Notes"": """" }, { ""Field"": ""user_id"", ""Type"": ""UUID"", ""Description"": ""Keystone user_id identifies specific user"", ""Compliance"": ""optional"", ""Notes"": """" }, { ""Field"": ""service_id"", ""Type"": ""UUID"", ""Description"": ""Keystone service_id uniquely identifies a service"", ""Compliance"": ""required"", ""Notes"": """" }, { ""Field"": ""service_type"", ""Type"": ""String"", ""Description"": ""Keystone service_type uniquely identifies a service"", ""Compliance"": ""required"", ""Notes"": """" }, { ""Field"": ""instance_id"", ""Type"": ""UUID"", ""Description"": ""uniquely identifies an instance of the service"", ""Compliance"": ""required"", ""Notes"": ""assuming instance level reporting"" }, { ""Field"": ""display_name"", ""Type"": ""String"", ""Description"": ""text description of service"", ""Compliance"": ""optional"", ""Notes"": ""used if customer names instances"" }, { ""Field"": ""instance_type_id"", ""Type"": ""enumeration"", ""Description"": ""used to describe variations of a service"", ""Compliance"": ""required"", ""Notes"": ""needed if variations of service have different prices or need to be broken out separately"" }, { ""Field"": ""instance_type"", ""Type"": ""String"", ""Description"": ""text description of service variations"", ""Compliance"": ""optional"", ""Notes"": """" }, { ""Field"": ""availability_zone"", ""Type"": ""String"", ""Description"": ""where the service is deployed"", ""Compliance"": ""optional"", ""Notes"": ""required if service is deployed at an AZ level"" }, { ""Field"": ""region"", ""Type"": ""String"", ""Description"": ""data center that the service is deployed in"", ""Compliance"": ""optional"", ""Notes"": ""required if service is billed at a regional level"" }, { ""Field"": ""state"", ""Type"": ""enumeration"", ""Description"": ""status of the service at the time of record generation"", ""Compliance"": ""optional"", ""Notes"": ""required for existence events"" }, { ""Field"": ""state_description"", ""Type"": ""String"", ""Description"": ""text description of state of service"", ""Compliance"": """", ""Notes"": """" }, { ""Field"": ""license_code"", ""Type"": ""enumeration"", ""Description"": ""value that describes a specific license model"", ""Compliance"": ""optional"", ""Notes"": ""this field is TBD depending on dev_pay design work"" }, { ""metrics"": [ { ""Field"": ""metric_name"", ""Type"": ""String"", ""Description"": ""unique name for the metric that is represented in this record"", ""Compliance"": ""required"", ""Notes"": """" }, { ""Field"": ""metric_type"", ""Type"": ""enumeration"", ""Description"": ""gauge, cumulative, delta"", ""Compliance"": ""required"", ""Notes"": ""describes the behavior of the metric, from Panko"" }, { ""Field"": ""metric_value"", ""Type"": ""Float"", ""Description"": ""value of metric for quantity type records"", ""Compliance"": ""required for quantities"", ""Notes"": """" }, { ""Field"": ""metric_units"", ""Type"": ""enumeration"", ""Description"": ""describes the units for the quantity"", ""Compliance"": ""optional"", ""Notes"": """" } ] } ] } ] .. note:: **Required** means that it must be present and described as in the specification. **Optional** indicates it can be present or not, but if present it must be described as in the specifications. **Audit period timestamps** are not currently enforced against the audit period. Sample Events ============= The event format listed above is used to deliver two basic types of events: *quantity* and *state* events. Sample state events ------------------- These events describe the state of the metered service. They are very similar to the existing state events generated by Infrastructure. Generally there would be at least three types of events: create, exists and delete. Examples of these events for a DNS service are listed below. ``dns.zone.create`` event is sent after a zone has been created:: { ""event_type"": ""dns.zone.create"", ""time_stamp"": ""2013-04-07 22:56:30.026191"", ""message_id"": 52232791371, ""payload"": { ""instance_type"": ""type1"", ""availability_zone"": ""az1"", ""instance_id"": ""6accc078-81de-4567-894f-53af5653ac63"", ""audit_period_beginning"": ""2013-04-07 21:56:32.249876"", ""state"": ""active"", ""audit_period_ending"": ""2013-04-07 22:56:32.249712"", ""service_id"": ""1abbb078-81cd-4758-974e-35fa5653ac63"", ""version"": ""1.0"", ""tenant_id"": ""12345"", ""instance_type_id"": 1, ""display_name"": ""example100.com"", ""message_id"": 52232791371, ""user_id"": ""6789"", ""state_description"": ""happy DNS"" } } ``dns.zone.exists`` event is sent every hour for existing zones:: { ""event_type"": ""dns.zone.exists"", ""time_stamp"": ""2013-04-07 22:56:37.782573"", ""message_id"": 52232791372, ""payload"": { ""instance_type"": ""type1"", ""availability_zone"": ""az1"", ""instance_id"": ""6accc078-81de-4567-894f-53af5653ac63"", ""audit_period_beginning"": ""2013-04-07 21:56:37.783215"", ""state"": ""active"", ""audit_period_ending"": ""2013-04-07 22:56:37.783153"", ""service_id"": ""1abbb078-81cd-4758-974e-35fa5653ac63"", ""version"": ""1.0"", ""tenant_id"": ""12345"", ""instance_type_id"": 1, ""display_name"": ""example100.com"", ""message_id"": 52232791371, ""user_id"": ""6789"", ""state_description"": ""happy DNS"" } } The ``dns.zone.delete`` event is sent when a zone is deleted:: { ""event_type"": ""dns.zone.delete"", ""time_stamp"": ""2013-04-07 22:56:37.787774"", ""message_id"": 52232791373, ""payload"": { ""instance_type"": ""type1"", ""availability_zone"": ""az1"", ""instance_id"": ""6accc078-81de-4567-894f-53af5653ac63"", ""audit_period_beginning"": ""2013-04-07 21:56:37.788177"", ""state"": ""active"", ""audit_period_ending"": ""2013-04-07 22:56:37.788144"", ""service_id"": ""1abbb078-81cd-4758-974e-35fa5653ac63"", ""version"": ""1.0"", ""tenant_id"": ""12345"", ""instance_type_id"": 1, ""display_name"": ""example100.com"", ""message_id"": 52232791371, ""user_id"": ""6789"", ""state_description"": ""happy DNS"" } } Sample quantity events ---------------------- Quantity events have the same overall format, but additionally have a section called metrics which is a section called metrics which is an array of information about the meters that the event is reporting on. Each metric entry has a type, unit, name and volume. Multiple values can be reported in one event. ``dns.zone.usage`` is hourly event sent with usage for each zone instance:: { ""event_type"": ""dns.zone.usage"", ""time_stamp"": ""2013-04-08 10:05:31.618074"", ""message_id"": 52232791371, ""payload"": { ""metrics"": [ { ""metric_type"": ""delta"", ""metric_value"": 42, ""metric_units"": ""hits"", ""metric_name"": ""queries"" } ], ""instance_type"": ""type1"", ""availability_zone"": ""az1"", ""instance_id"": ""6accc078-81de-4567-894f-53af5653ac63"", ""audit_period_beginning"": ""2013-04-08 09:05:31.618204"", ""state"": ""active"", ""audit_period_ending"": ""2013-04-08 10:05:31.618191"", ""service_id"": ""1abbb078-81cd-4758-974e-35fa5653ac63"", ""version"": ""1.0"", ""tenant_id"": ""12345"", ""instance_type_id"": 1, ""display_name"": ""example100.com"", ""message_id"": 52232791371, ""user_id"": ""6789"", ""state_description"": ""happy DNS"" } } ",0,341
openstack%2Fopenstack-helm-infra~master~I4f391a10b64389022f01a94ea3704c110f8f9bb5,openstack/openstack-helm-infra,master,I4f391a10b64389022f01a94ea3704c110f8f9bb5,Include prometheus- prefix for select monitoring charts,MERGED,2017-12-17 21:56:01.000000000,2017-12-18 15:51:38.000000000,2017-12-18 15:51:38.000000000,"[{'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2017-12-17 21:56:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/08220fc415d9cb57f74afb9fc268abf8dbf3ba00', 'message': 'Include prometheus- prefix for select monitoring charts\n\nThis adds the prometheus- prefix to the alertmanager,\nkube-state-metrics and node exporter charts to reflect their\nintended usage as part of a prometheus centric monitoring solution\n\nThis will imply a logical grouping of these components, similar to\ntheir deployment in the osh-infra gates\n\nChange-Id: I4f391a10b64389022f01a94ea3704c110f8f9bb5\n'}, {'number': 2, 'created': '2017-12-17 22:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d9cef3af465c9d93a3de276c5713a4d417bc41b0', 'message': 'Include prometheus- prefix for select monitoring charts\n\nThis adds the prometheus- prefix to the alertmanager,\nkube-state-metrics and node exporter charts to reflect their\nintended usage as part of a prometheus centric monitoring solution\n\nThis will imply a logical grouping of these components, similar to\ntheir deployment in the osh-infra gates\n\nChange-Id: I4f391a10b64389022f01a94ea3704c110f8f9bb5\n'}, {'number': 3, 'created': '2017-12-18 04:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f50369b17f6ea3ad6ad11be66672241aea4f1e92', 'message': 'Include prometheus- prefix for select monitoring charts\n\nThis adds the prometheus- prefix to the alertmanager,\nkube-state-metrics and node exporter charts to reflect their\nintended usage as part of a prometheus centric monitoring solution\n\nThis will imply a logical grouping of these components, similar to\ntheir deployment in the osh-infra gates\n\nChange-Id: I4f391a10b64389022f01a94ea3704c110f8f9bb5\n'}, {'number': 4, 'created': '2017-12-18 04:22:57.000000000', 'files': ['prometheus-alertmanager/templates/ingress-alertmanager.yaml', 'prometheus-kube-state-metrics/templates/clusterrole.yaml', 'prometheus-kube-state-metrics/templates/service-kube-metrics.yaml', 'prometheus-alertmanager/templates/rbac-entrypoint.yaml', 'prometheus-node-exporter/templates/configmap-bin.yaml', 'prometheus-alertmanager/templates/service.yaml', 'prometheus-node-exporter/requirements.yaml', 'prometheus-alertmanager/Chart.yaml', 'prometheus-alertmanager/templates/clusterrolebinding.yaml', 'prometheus-kube-state-metrics/templates/service-scheduler.yaml', 'prometheus-alertmanager/templates/statefulset.yaml', 'prometheus-alertmanager/templates/configmap-etc.yaml', 'prometheus-kube-state-metrics/templates/clusterrolebinding.yaml', 'prometheus-node-exporter/Chart.yaml', 'prometheus-alertmanager/requirements.yaml', 'prometheus-alertmanager/values.yaml', 'prometheus-kube-state-metrics/Chart.yaml', 'prometheus-node-exporter/templates/job-image-repo-sync.yaml', 'prometheus-node-exporter/templates/daemonset.yaml', 'prometheus-alertmanager/templates/bin/_alertmanager.sh.tpl', 'prometheus-kube-state-metrics/templates/job-image-repo-sync.yaml', 'prometheus-node-exporter/templates/rbac-entrypoint.yaml', 'prometheus-kube-state-metrics/templates/service-controller-manager.yaml', 'tools/gate/chart-deploys/default.yaml', 'prometheus-kube-state-metrics/templates/rbac-entrypoint.yaml', 'prometheus-kube-state-metrics/requirements.yaml', 'prometheus-alertmanager/templates/service-ingress-alertmanager.yaml', 'prometheus-kube-state-metrics/values.yaml', 'prometheus-node-exporter/templates/serviceaccount.yaml', 'prometheus-node-exporter/values.yaml', 'prometheus-alertmanager/templates/job-image-repo-sync.yaml', 'prometheus-node-exporter/templates/service.yaml', 'prometheus-kube-state-metrics/templates/configmap-bin.yaml', 'prometheus-node-exporter/templates/clusterrolebinding.yaml', 'prometheus-kube-state-metrics/templates/deployment.yaml', 'prometheus-alertmanager/templates/pvc.yaml', 'prometheus-alertmanager/templates/serviceaccount.yaml', 'prometheus-kube-state-metrics/templates/serviceaccount.yaml', 'prometheus-alertmanager/templates/configmap-bin.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/938bce7370e5270ccce30cb864f528040c6d1f1a', 'message': 'Include prometheus- prefix for select monitoring charts\n\nThis adds the prometheus- prefix to the alertmanager,\nkube-state-metrics and node exporter charts to reflect their\nintended usage as part of a prometheus centric monitoring solution\n\nThis will imply a logical grouping of these components, similar to\ntheir deployment in the osh-infra gates\n\nChange-Id: I4f391a10b64389022f01a94ea3704c110f8f9bb5\n'}]",0,528587,938bce7370e5270ccce30cb864f528040c6d1f1a,16,3,4,17591,,,0,"Include prometheus- prefix for select monitoring charts

This adds the prometheus- prefix to the alertmanager,
kube-state-metrics and node exporter charts to reflect their
intended usage as part of a prometheus centric monitoring solution

This will imply a logical grouping of these components, similar to
their deployment in the osh-infra gates

Change-Id: I4f391a10b64389022f01a94ea3704c110f8f9bb5
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/87/528587/4 && git format-patch -1 --stdout FETCH_HEAD,"['prometheus-alertmanager/templates/ingress-alertmanager.yaml', 'prometheus-kube-state-metrics/templates/clusterrole.yaml', 'prometheus-kube-state-metrics/templates/service-kube-metrics.yaml', 'prometheus-alertmanager/templates/rbac-entrypoint.yaml', 'prometheus-node-exporter/templates/configmap-bin.yaml', 'prometheus-alertmanager/templates/service.yaml', 'prometheus-node-exporter/requirements.yaml', 'prometheus-alertmanager/Chart.yaml', 'prometheus-alertmanager/templates/clusterrolebinding.yaml', 'prometheus-kube-state-metrics/templates/service-scheduler.yaml', 'prometheus-alertmanager/templates/statefulset.yaml', 'prometheus-alertmanager/templates/configmap-etc.yaml', 'prometheus-kube-state-metrics/templates/clusterrolebinding.yaml', 'prometheus-node-exporter/Chart.yaml', 'prometheus-alertmanager/requirements.yaml', 'prometheus-alertmanager/values.yaml', 'prometheus-kube-state-metrics/Chart.yaml', 'prometheus-node-exporter/templates/job-image-repo-sync.yaml', 'prometheus-node-exporter/templates/daemonset.yaml', 'prometheus-alertmanager/templates/bin/_alertmanager.sh.tpl', 'prometheus-kube-state-metrics/templates/job-image-repo-sync.yaml', 'prometheus-node-exporter/templates/rbac-entrypoint.yaml', 'prometheus-kube-state-metrics/templates/service-controller-manager.yaml', 'tools/gate/chart-deploys/default.yaml', 'prometheus-kube-state-metrics/templates/rbac-entrypoint.yaml', 'prometheus-kube-state-metrics/requirements.yaml', 'prometheus-alertmanager/templates/service-ingress-alertmanager.yaml', 'prometheus-kube-state-metrics/values.yaml', 'prometheus-node-exporter/templates/serviceaccount.yaml', 'prometheus-node-exporter/values.yaml', 'prometheus-alertmanager/templates/job-image-repo-sync.yaml', 'prometheus-node-exporter/templates/service.yaml', 'prometheus-kube-state-metrics/templates/configmap-bin.yaml', 'prometheus-node-exporter/templates/clusterrolebinding.yaml', 'prometheus-kube-state-metrics/templates/deployment.yaml', 'prometheus-alertmanager/templates/pvc.yaml', 'prometheus-alertmanager/templates/serviceaccount.yaml', 'prometheus-kube-state-metrics/templates/serviceaccount.yaml', 'prometheus-alertmanager/templates/configmap-bin.yaml']",39,08220fc415d9cb57f74afb9fc268abf8dbf3ba00,update_chart_names,,,13,13
openstack%2Fopenstack-helm-infra~master~Ie3a8d67a64d6f9a9a58f8c6d935bd5cf204f98ca,openstack/openstack-helm-infra,master,Ie3a8d67a64d6f9a9a58f8c6d935bd5cf204f98ca,Gate: move all checks to voting,MERGED,2017-12-17 17:43:05.000000000,2017-12-18 15:51:38.000000000,2017-12-18 15:51:37.000000000,"[{'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-17 17:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7e4fa3caa4b2f07f79a1fdd20f8fb9edfb1d7029', 'message': 'RFC: Gate: move all checks to voting\n\nThis PS moves all the current checks to voting gates.\n\nChange-Id: Ie3a8d67a64d6f9a9a58f8c6d935bd5cf204f98ca\n'}, {'number': 2, 'created': '2017-12-17 20:33:26.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8c00d623efc57b7d955baf6455b7bb3eec456dff', 'message': 'Gate: move all checks to voting\n\nThis PS moves all the current checks to voting gates.\n\nChange-Id: Ie3a8d67a64d6f9a9a58f8c6d935bd5cf204f98ca\n'}]",0,528576,8c00d623efc57b7d955baf6455b7bb3eec456dff,10,3,2,23928,,,0,"Gate: move all checks to voting

This PS moves all the current checks to voting gates.

Change-Id: Ie3a8d67a64d6f9a9a58f8c6d935bd5cf204f98ca
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/76/528576/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,7e4fa3caa4b2f07f79a1fdd20f8fb9edfb1d7029,gate/voting, voting: true - openstack-helm-infra-fedora: voting: true - openstack-helm-infra-centos - openstack-helm-infra-fedora, voting: false - openstack-helm-infra-fedora: voting: false,4,2
openstack%2Fopenstack-helm~master~I5b5607c31c44e26fec8a76f0b395130e800b5707,openstack/openstack-helm,master,I5b5607c31c44e26fec8a76f0b395130e800b5707,DNM: WIP: Create Jenkins Chart,ABANDONED,2017-07-09 19:44:53.000000000,2017-12-18 15:50:06.000000000,,"[{'_account_id': 8181}, {'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 23928}, {'_account_id': 25731}]","[{'number': 1, 'created': '2017-07-09 19:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5f2b8d5f2fa604d798c77b0a7b63948d979ce35e', 'message': 'Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 2, 'created': '2017-07-09 22:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/aaa543f63129a75e01ba61889b86626f401f16f6', 'message': 'Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 3, 'created': '2017-07-09 23:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9452286d8633ccbde27d5b72f97239d1d2e8e6cc', 'message': 'Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 4, 'created': '2017-07-09 23:07:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/be80e1677af715b6530c0d700760da14c297e434', 'message': 'Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 5, 'created': '2017-07-10 01:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/2ffac7a266d6d0c4a61c2e6ffd9ec16ee65ef1d6', 'message': 'Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 6, 'created': '2017-07-10 01:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e230f928c59578b963d1d110e88dd2dff5d77931', 'message': 'Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 7, 'created': '2017-07-10 01:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f5c0ad75c5f167db121e55fc5711834b16b6361d', 'message': 'Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 8, 'created': '2017-07-10 01:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/bd1c60ecc03ec79460279bf8d90f4f91e724586d', 'message': 'DNM: WIP: Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 9, 'created': '2017-07-10 03:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8dbf50193f4fd87b01a9c21d6bcbfc66775bb625', 'message': 'DNM: WIP: Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 10, 'created': '2017-07-10 03:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b42818bec5cc8b5134eae41d2b238e4674e4936d', 'message': 'DNM: WIP: Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 11, 'created': '2017-07-10 03:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/7281f3fbf95cb4930625d6e13bbc4f3dbb44a213', 'message': 'DNM: WIP: Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 12, 'created': '2017-07-10 04:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/745c8652b4a9375672fa9ea1d1752cf41a5b7473', 'message': 'DNM: WIP: Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 13, 'created': '2017-07-14 18:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f34c792eecaff373166303c11c16262c086dcbc7', 'message': 'DNM: WIP: Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 14, 'created': '2017-07-18 17:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/38fc6af116b4e7254645ee5ea48888f29c742bc7', 'message': 'DNM: WIP: Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 15, 'created': '2017-07-18 21:10:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e06fa0be3d1905280bb47b4302b863a10ae9879b', 'message': 'DNM: WIP: Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}, {'number': 16, 'created': '2017-07-21 21:31:32.000000000', 'files': ['glance/templates/etc/_policy.json.tpl', 'jenkins/templates/pvc-jenkins.yaml', 'jenkins/templates/configmap-bin.yaml', 'jenkins/templates/secret-keystone.yaml', 'jenkins/templates/service-jenkins.yaml.tpl', 'jenkins/templates/etc/_plugins.txt.tpl', 'jenkins/templates/etc/_com.arkea.jenkins.openstack.heat.HOTPlayerSettings.xml.tpl', 'jenkins/templates/job-ks-user.yaml', 'jenkins/templates/bin/_jenkins-setup.sh.tpl', 'glance/values.yaml', 'jenkins/templates/deployment-jenkins.yaml.tpl', 'jenkins/templates/etc/_config.xml.tpl', 'jenkins/templates/bin/_jenkins-launch.sh.tpl', 'jenkins/requirements.yaml', 'jenkins/values.yaml', 'jenkins/templates/bin/_plugins.sh.tpl', 'jenkins/templates/etc/_jenkins.security.QueueItemAuthenticatorConfiguration.xml.tpl', 'jenkins/templates/configmap-etc.yaml', 'jenkins/templates/etc/_jenkins.security.UpdateSiteWarningsConfiguration.xml.tpl', 'tools/gate/basic_launch.sh', 'jenkins/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d438cc352bc44c4cd23e18468e57e70881537aec', 'message': 'DNM: WIP: Create Jenkins Chart\n\nThis patch set is creating a Jenkins chart that uses the\nOpenstack-cloud plugin.\n\nChange-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707\nCo-Authored-By: Pete Birley<pete@port.direct>\n'}]",0,481962,d438cc352bc44c4cd23e18468e57e70881537aec,34,5,16,25731,,,0,"DNM: WIP: Create Jenkins Chart

This patch set is creating a Jenkins chart that uses the
Openstack-cloud plugin.

Change-Id: I5b5607c31c44e26fec8a76f0b395130e800b5707
Co-Authored-By: Pete Birley<pete@port.direct>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/62/481962/16 && git format-patch -1 --stdout FETCH_HEAD,"['glance/templates/etc/_policy.json.tpl', 'jenkins/templates/service-jenkins.yaml.tpl', 'jenkins/values.yaml', 'Makefile', 'jenkins/Chart.yaml', 'jenkins/templates/deployment-jenkins.yaml.tpl']",6,5f2b8d5f2fa604d798c77b0a7b63948d979ce35e,jenkins-chart,apiVersion: v1 kind: Pod metadata: labels: component: jenkins name: jenkins namespace: openstack spec: containers: - image: jenkins:{{ .Values.containers.image.version }} name: jenkins ports: - containerPort: {{ .Values.containers.ports.containerPort }} resources: {} volumeMounts: - mountPath: {{ .Values.containers.volumeMounts.mountPath }} name: {{ .Values.containers.volumeMounts.name }} volumes: - hostPath: path: {{ .Values.volumes.hostPath.path }} name: {{ .Values.volumes.name }} ,,89,2
openstack%2Fhorizon~master~I542da986a8bbaf8b6b7e525f05dfb243834d18a7,openstack/horizon,master,I542da986a8bbaf8b6b7e525f05dfb243834d18a7,Imported Translations from Zanata,MERGED,2017-12-18 07:39:50.000000000,2017-12-18 15:44:48.000000000,2017-12-18 15:44:48.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 07:39:50.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3d471086c7da520373c52960f9636b02aa059880', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I542da986a8bbaf8b6b7e525f05dfb243834d18a7\n'}]",0,528642,3d471086c7da520373c52960f9636b02aa059880,10,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I542da986a8bbaf8b6b7e525f05dfb243834d18a7
",git fetch https://review.opendev.org/openstack/horizon refs/changes/42/528642/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,3d471086c7da520373c52960f9636b02aa059880,zanata/translations,"""POT-Creation-Date: 2017-12-18 06:23+0000\n""""PO-Revision-Date: 2017-12-17 07:45+0000\n""""The policy framework in horizon now supports policy directories per service. "" ""This corresponds to ``policy_dirs`` configuration option from \""oslo.policy"" ""\"" library. The new setting ``POLICY_DIRS`` was introduced. The setting "" ""allows to define multiple policy directories per service. For example, it is "" ""useful for a case where multiple projects provide policy files like neutron "" ""stadium projects. For detail, see `the horizon Setting Reference <https://"" ""docs.openstack.org/horizon/latest/configuration/settings.html#policy-"" ""dirs>`__."" msgstr """" ""The policy framework in Horizon now supports policy directories per service. "" ""This corresponds to ``policy_dirs`` configuration option from \""oslo.policy"" ""\"" library. The new setting ``POLICY_DIRS`` was introduced. The setting "" ""allows to define multiple policy directories per service. For example, it is "" ""useful for a case where multiple projects provide policy files like neutron "" ""stadium projects. For detail, see `the horizon Setting Reference <https://"" ""docs.openstack.org/horizon/latest/configuration/settings.html#policy-"" ""dirs>`__."" msgid """"","""POT-Creation-Date: 2017-12-16 13:44+0000\n""""PO-Revision-Date: 2017-12-17 02:07+0000\n""msgid ""13.0.0.0b2-24"" msgstr ""13.0.0.0b2-24"" ",21,5
openstack%2Fnova~master~I8b422d5d80e2e1ce23e1833541e80d7595fc207b,openstack/nova,master,I8b422d5d80e2e1ce23e1833541e80d7595fc207b,DNM: Test making column Text -> MediumText without migration,ABANDONED,2017-12-18 13:13:59.000000000,2017-12-18 15:42:00.000000000,,"[{'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}]","[{'number': 1, 'created': '2017-12-18 13:13:59.000000000', 'files': ['nova/db/sqlalchemy/api_models.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3852abbf26ea526a8bc019b24ca3fc8f3b59bc6f', 'message': 'DNM: Test making column Text -> MediumText without migration\n\nChange-Id: I8b422d5d80e2e1ce23e1833541e80d7595fc207b\n'}]",0,528712,3852abbf26ea526a8bc019b24ca3fc8f3b59bc6f,11,9,1,8864,,,0,"DNM: Test making column Text -> MediumText without migration

Change-Id: I8b422d5d80e2e1ce23e1833541e80d7595fc207b
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/528712/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/api_models.py'],1,3852abbf26ea526a8bc019b24ca3fc8f3b59bc6f,, description = Column(MediumText()), description = Column(Text),1,1
openstack%2Fproject-config~master~Ic267f06850ca93e1eeeb8a75bc226feee3db631b,openstack/project-config,master,Ic267f06850ca93e1eeeb8a75bc226feee3db631b,Remove revoke-sudo from translations playbook,MERGED,2017-12-18 09:19:06.000000000,2017-12-18 15:39:49.000000000,2017-12-18 15:39:49.000000000,"[{'_account_id': 2}, {'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 09:19:06.000000000', 'files': ['playbooks/translation/pre.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5b5b9a1b33b579263bfe9f77ccc6c3102a650756', 'message': 'Remove revoke-sudo from translations playbook\n\nThe translation jobs need sudo, remove revoke-sudo from pre.yaml.\n\nChange-Id: Ic267f06850ca93e1eeeb8a75bc226feee3db631b\n'}]",0,528664,5b5b9a1b33b579263bfe9f77ccc6c3102a650756,7,3,1,6547,,,0,"Remove revoke-sudo from translations playbook

The translation jobs need sudo, remove revoke-sudo from pre.yaml.

Change-Id: Ic267f06850ca93e1eeeb8a75bc226feee3db631b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/64/528664/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/translation/pre.yaml'],1,5b5b9a1b33b579263bfe9f77ccc6c3102a650756,fix-translations,, - revoke-sudo,0,1
openstack%2Fopenstack-helm~master~I6575cb9e1e7da8b6c690e433418d1115130e0eff,openstack/openstack-helm,master,I6575cb9e1e7da8b6c690e433418d1115130e0eff,Fix Makefile,MERGED,2017-12-18 04:55:35.000000000,2017-12-18 15:30:40.000000000,2017-12-18 15:24:42.000000000,"[{'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 26201}]","[{'number': 1, 'created': '2017-12-18 04:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/17080867d23bcad0f95ad9bc3a86c7398b8dea7f', 'message': 'Fix Makefile\n\nThis patch sets fixes the make clean target as it currently attempts\nto delete the generated */charts up the parents, where the directory\nis guaranteed to be non-empty.\n\nChange-Id: I6575cb9e1e7da8b6c690e433418d1115130e0eff\n'}, {'number': 2, 'created': '2017-12-18 06:39:45.000000000', 'files': ['Makefile'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f15f709266800d7d64cedc4d3311f84264c37a16', 'message': 'Fix Makefile\n\nThis patch sets fixes the make clean target as it currently attempts\nto delete the generated */charts up the parents, where the directory\nis guaranteed to be non-empty.\n\nChange-Id: I6575cb9e1e7da8b6c690e433418d1115130e0eff\n'}]",0,528623,f15f709266800d7d64cedc4d3311f84264c37a16,15,5,2,20466,,,0,"Fix Makefile

This patch sets fixes the make clean target as it currently attempts
to delete the generated */charts up the parents, where the directory
is guaranteed to be non-empty.

Change-Id: I6575cb9e1e7da8b6c690e433418d1115130e0eff
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/23/528623/2 && git format-patch -1 --stdout FETCH_HEAD,['Makefile'],1,17080867d23bcad0f95ad9bc3a86c7398b8dea7f,fix-makefile, -rm -rf */charts, -rmdir -p */charts,1,1
openstack%2Ftripleo-heat-templates~master~I873862a0936eb2b6a318f30e5103215ef16e468a,openstack/tripleo-heat-templates,master,I873862a0936eb2b6a318f30e5103215ef16e468a,Add CephAnsiblePlaybookVerbosity parameter to overcloud-ceph-ansible,MERGED,2017-11-07 19:14:50.000000000,2017-12-18 15:30:27.000000000,2017-11-16 23:02:44.000000000,"[{'_account_id': 6796}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 19564}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-11-07 19:14:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3f40146451cd3ceb307ce064be6150cb9789d53b', 'message': 'Add PlaybookVerbosity parameter to overcloud-ceph-ansible\n\nAdd new PlaybookVerbosity parameter to help user debug Ansible\nruns when deploying Ceph which can take a value between 0\n(default) and 5 for the amount of -v, -vv, ..., -vvvvv passed\nto the ansible-playbook.\n\nChange-Id: I873862a0936eb2b6a318f30e5103215ef16e468a\n'}, {'number': 2, 'created': '2017-11-08 13:37:44.000000000', 'files': ['docker/services/ceph-ansible/ceph-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9fa81be34f6afbeb0fc22c4e6f33fa571310dfe3', 'message': 'Add CephAnsiblePlaybookVerbosity parameter to overcloud-ceph-ansible\n\nAdd new CephAnsiblePlaybookVerbosity parameter to help user debug\nAnsible runs when deploying Ceph which can take a value between 0\n(default) and 5 for the amount of -v, -vv, ..., -vvvvv passed\nto the ansible-playbook command.\n\nChange-Id: I873862a0936eb2b6a318f30e5103215ef16e468a\n'}]",4,518383,9fa81be34f6afbeb0fc22c4e6f33fa571310dfe3,30,8,2,18002,,,0,"Add CephAnsiblePlaybookVerbosity parameter to overcloud-ceph-ansible

Add new CephAnsiblePlaybookVerbosity parameter to help user debug
Ansible runs when deploying Ceph which can take a value between 0
(default) and 5 for the amount of -v, -vv, ..., -vvvvv passed
to the ansible-playbook command.

Change-Id: I873862a0936eb2b6a318f30e5103215ef16e468a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/83/518383/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/ceph-ansible/ceph-base.yaml'],1,3f40146451cd3ceb307ce064be6150cb9789d53b,playbook-verbosity, PlaybookVerbosity: default: 0 description: verbosity of ceph-ansible playbook run between 0 and 5 type: number ansible_playbook_verbosity: {get_param: PlaybookVerbosity},,5,0
openstack%2Fceilometer~master~If6aae7a3ed5a677bafb145ac5c2ac16807cdcab5,openstack/ceilometer,master,If6aae7a3ed5a677bafb145ac5c2ac16807cdcab5,minor update to gnocchi contributor docs,MERGED,2017-12-06 22:19:22.000000000,2017-12-18 15:20:33.000000000,2017-12-18 15:20:33.000000000,"[{'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-06 22:19:22.000000000', 'files': ['doc/source/contributor/new_resource_types.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/282b91f488b449ca32fe84a5620ae1fe90a1a1c5', 'message': 'minor update to gnocchi contributor docs\n\nChange-Id: If6aae7a3ed5a677bafb145ac5c2ac16807cdcab5\n'}]",0,526215,282b91f488b449ca32fe84a5620ae1fe90a1a1c5,7,3,1,6537,,,0,"minor update to gnocchi contributor docs

Change-Id: If6aae7a3ed5a677bafb145ac5c2ac16807cdcab5
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/15/526215/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/new_resource_types.rst'],1,282b91f488b449ca32fe84a5620ae1fe90a1a1c5,gnocchi-contributor,a resource type into the :file:`ceilometer/publisher/data/gnocchi_resources.yaml`.,a resource type into :the file:`ceilometer/dispatcher/data/gnocchi_resources.yaml`.,1,1
openstack%2Foslo-specs~master~I247a2855f833485c4fcb4ce72f4b9b069ff23236,openstack/oslo-specs,master,I247a2855f833485c4fcb4ce72f4b9b069ff23236,Update kafka driver support,MERGED,2017-09-05 17:52:06.000000000,2017-12-18 15:19:04.000000000,2017-12-18 15:19:04.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 8770}, {'_account_id': 9796}, {'_account_id': 14758}, {'_account_id': 20523}, {'_account_id': 22348}, {'_account_id': 25100}]","[{'number': 1, 'created': '2017-09-05 17:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/883f7888df1bcc1df6c79acbd6d0c40a965c2cdd', 'message': 'Update kafka driver support\n\nChange-Id: I247a2855f833485c4fcb4ce72f4b9b069ff23236\n'}, {'number': 2, 'created': '2017-09-05 18:26:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/ae1c0975ad21a0692b007ebe149e49c13633f1ff', 'message': 'Update kafka driver support\n\nThis patch:\n\n* Add queens release\n* Add update kakfa driver spec\n\nChange-Id: I247a2855f833485c4fcb4ce72f4b9b069ff23236\n'}, {'number': 3, 'created': '2017-09-10 13:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/1115fc684ec3c0436d80cc50f26496ec26fd7ea7', 'message': 'Update kafka driver support\n\nThis patch:\n\n* Add queens release\n* Add update kakfa driver spec\n\nChange-Id: I247a2855f833485c4fcb4ce72f4b9b069ff23236\n'}, {'number': 4, 'created': '2017-09-22 14:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/eafc6b19a5cda95f184c4c0aea9432a7b197aa5f', 'message': 'Update kafka driver support\n\nThis patch:\n\n* Add queens release\n* Add update kakfa driver spec\n\nChange-Id: I247a2855f833485c4fcb4ce72f4b9b069ff23236\n'}, {'number': 5, 'created': '2017-10-04 19:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/d73281eb8bab80870714e09d5184ab2eaacc3a79', 'message': 'Update kafka driver support\n\nThis patch:\n\n* Add queens release\n* Add update kakfa driver spec\n\nChange-Id: I247a2855f833485c4fcb4ce72f4b9b069ff23236\n'}, {'number': 6, 'created': '2017-11-29 17:29:24.000000000', 'files': ['specs/queens/update-kafka-support.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/5564f12af0afd471b48a576758f45b3f2c9e89e7', 'message': 'Update kafka driver support\n\nThis patch:\n\n* Add queens release\n* Add update kakfa driver spec\n\nChange-Id: I247a2855f833485c4fcb4ce72f4b9b069ff23236\n'}]",46,500944,5564f12af0afd471b48a576758f45b3f2c9e89e7,37,8,6,20523,,,0,"Update kafka driver support

This patch:

* Add queens release
* Add update kakfa driver spec

Change-Id: I247a2855f833485c4fcb4ce72f4b9b069ff23236
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/44/500944/5 && git format-patch -1 --stdout FETCH_HEAD,"['specs/queens/index.rst', 'specs/queens/update-kafka-support.rst']",2,883f7888df1bcc1df6c79acbd6d0c40a965c2cdd,bp/kafka-driver-rev,"==================================================== Kafka Driver Revisions for Messaging Notifications ==================================================== https://blueprints.launchpad.net/oslo.messaging/+spec/update-kafka-support This specification proposes changes to the existing kafka driver that allows notification message transport over the Apache Kafka distributed streaming platform [1]_. The blueprint for the original driver implementation can be found here [2]_ and the spec for the implementation can be found here [3]_. The goal of the changes described by this specification is to transition the driver from 'experimental' to 'supported' status in order to encourage driver adoption. The driver will (continue to) only support notification messaging as the use of the kafka server is non-optimal for RPC messaging patterns. Thus, this kafka driver is intended for deployment in hybrid messaging configurations where RPC messaging will be provided by a separate messaging backend. Problem description =================== The original kafka driver was introduced during the mitaka release cycle. Adoption of the driver has been limited due to a number of factors such as its 'experimental' designation and its intended use for notification messaging only. Meanwhile, the kakfa server has experienced widespread adoption and is frequently included in application architectures to provide accurate analytics in cloud monitoring systems. This success and the progression of configuration frameworks to easily enable hybrid messaging deployments in OpenStack is a catalyst to revise this driver and provide active maintenance and support going forward. Kafka hybrid messaging deployment:: +------------+ +----------+ | RPC Caller | | Notifier | +-----+------+ +----+-----+ | | | | v v +-------------------+ +-------------------+ | RPC | | Notification | | Messaging Backend | | Messaging Backend | | (amqp:// or | | (kafka://) | | rabbit://) | | | +--------+----------+ +--------+----------+ | | | | v v +------------+ +------+-------+ | RPC | | Notification | | Server | | Server | +------------+ +--------------+ Proposed change =============== The revision to the kafka driver is not a major rework. A number of issues need to be resolved in order to support Notifications over a kafka server messaging backend: * release updates * virtual hosts * encryption and authentication * driver aspects * documentation * functional and integration testing Release Updates --------------- The driver should be updated to support the latest kakfa server software release and library dependencies. * scala version - 2.12 * kafka version - 0.11 * kafka-python version - 1.34 Virtual Hosts ------------- Currently, only the rabbitmq messaging backend supports vhosts contained in the transport url [4]_. Since the kafka server architecture does not natively support vhosts, the kafka driver revision will emulate vhost support by adding the virtual host name to the topic created on the kafka server. This will effectively create a private topic per virtual host that is configured for use. Related to this change the devstack kafka plugin will need to be updated so that the kafka backend does not fail. Encryption and Authentication ----------------------------- The Apache Kafka allows clients to connect over SSL. By default, SSL is disabled and the kafka driver will be updated to turn it on as needed. The configuration for SSL will be the same for both producer and consumer. If client authentication is not required, the following configuration options will be required: In section [oslo_messaging_kafka]: * ssl - attempt to connect via ssl * ssl_ca_file - file containing the trusted CA's digital certificate * ssl_cert_file - file containing driver digital certificate * ssl_key_file - file containing private key to sign ssl_cert_file * ssl_key_password - password used to decrypt private key SASL may be used with PLAINTEXT or SSL as the transport layer as specified by the security_protocol. The SASL configuration support is currently for PLAIN authentication only. The following configuration options will be provided by the driver: In section [oslo_messaging_kafka]: * sasl_mechanisms - space separated list of acceptable SASL mechanisms * sasl_username - user identifier for authentication * sasl_password - password for username Driver Aspects -------------- The revision to the kafka driver will include updates to a number of driver functional aspects to incorporate new features and to enhance driver support-ability: * config options - update the driver configuration options to include new security options as well as remove deprecated options removed from the oslo messaging library [5]_. * logging - add additional info, warning, debug messages to the driver to help operational and debugging tasks when deploying the driver * check kafka-python - check for installed library dependencies * connection management - review and identify any simplification that would benefit driver operation and support * ack/requeue message - investigate support of manual message commit in order to support message requeue following notify message dispatch Alternatives ------------ Presently, there are alternative oslo messaging drivers that can be used for different messaging backends. With hybrid messaging support, there is the flexibility to optimally align the messaging backend with the RPC or Notification communication patterns provided by the oslo messaging library. The objective to support and maintain the kafka driver should enhance the overall value of oslo messaging by providing users messaging backend alternatives that best suit their operational objectives and needs. The alternative is to deprecate this driver and support a single messaging backend for notifications (e.g. rabbit broker). Impact on Existing APIs ----------------------- The existing API should not require any changes. The changes to the kafka driver will preserve compatibility with existing experimental kafka deployments and will not affect other oslo.messaging drivers. Security impact --------------- With the additional support of authentication and encryption, there will be an expansion of the security model provided by the driver through its use of the kafka-python library and its interactions with the kafka server for message exchange. Performance Impact ------------------ Any performance impact should be limited to the users of the kafka driver for messaging notifications. Users of other drivers such as rabbitmq and amqp 1.0 will not be affected. Any performance changes realized in the kafka driver update may be due to: * changes to the underlying kafka protocol in the new server version Configuration Impact -------------------- New configuration items for authentication and security will be added as detailed above. The default value for these options will be determined as the driver is updated and revised. Developer Impact ---------------- To be considered as supported, any new features added to oslo.messaging that must be implemented via driver modification should be implemented in the kafka driver as well. In the circumstance when a new feature requires behaviors/capabilities that cannot be provided by kafka, the absence of functionality must be documented and included in the release notes. Testing Impact -------------- The kafka server will be used as the messaging backend for notifications in testing. An alternative backend such as rabbit or amqp 1.0 should be used as the messaging backend for RPC. The kafka driver tests should be expanded as necessary for the new features and capabilities in the update and the driver must pass all tests. The driver must pass the gate-oslo.messaging-src-dsvm-full and gate-oslo.messaging-dsvm-functional tests when deployed in a hybrid messaging configuration (e.g. when kafka is configured as the notification backend). The zookeeper, kafka, jdk and client will need to be avabilable in the CI environment in order to fully test this driver. Implementation ============== Assignee(s) ----------- Primary assignee: ansmith@redhat.com (ansmith on IRC) Other contributors: kgiusti@gmail.com (kgiusti on IRC) Milestones ---------- Target Milestone for completion: queens Work Items ---------- * Update environment for latest software release updates and dependencies * Implement virtual hosts support * Implement SSL and SASL integration * Implement new configuration items * Update documentation * Functional test integration * Update devstack plugin * Upstream CI integration Incubation ========== None. Adoption -------- The kafka driver is expected to be adopted in hybrid messaging deployments as the notification messaging backend. Adoption is likely in environments that already have kafka servers broadly deployed (e.g. operational benefit) or where the characteristics of the kafka server best suit the information analytics requirements. Library ------- oslo.messaging Anticipated API Stabilization ----------------------------- None Documentation Impact ==================== The kafka driver documentation will be added to the libary. This documentation will follow the style of documentation provided by the other drivers and should include the following topics: * theory of operation (overview) of the Apache Kafka messaging backend * pre-requisites * driver options overview * kafka server operations * devstack support * platforms and software Dependencies ============ The driver revision will require no additional dependencies. References ========== .. [1] https://kafka.apache.org/ .. [2] https://blueprints.launchpad.net/oslo.messaging/+spec/adding-kafka-support .. [3] https://review.openstack.org/#/c/189003/6/specs/liberty/adding-kafka-support.rst .. [4] https://bugs.launchpad.net/oslo.messaging/+bug/1706987 .. [5] https://etherpad.openstack.org/p/oslo-queens-tasks .. note:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ",,306,0
openstack%2Fopenstack-ansible~master~I77945703fc8ed511a7d6dafe4f37ef004897f6b9,openstack/openstack-ansible,master,I77945703fc8ed511a7d6dafe4f37ef004897f6b9,"Revert ""Freeze all SHAs for 17.0.0.0b2""",MERGED,2017-12-14 11:22:03.000000000,2017-12-18 15:12:58.000000000,2017-12-18 15:12:58.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 13095}, {'_account_id': 14805}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-12-14 11:22:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c7154b51768a72ddc1342fd360fd4adb89d85764', 'message': 'Revert ""Freeze all SHAs for 17.0.0.0b2""\n\nThis reverts commit 91cf1e88dc4028d43b3119862851e43c922f834f.\n\nChange-Id: I77945703fc8ed511a7d6dafe4f37ef004897f6b9\n'}, {'number': 2, 'created': '2017-12-14 11:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8d0139fe42e2d8be8744285168ede8cb9d5ee0a3', 'message': 'Revert ""Freeze all SHAs for 17.0.0.0b2""\n\nIn order to continue Queens development, the role\nSHA pins are removed.\n\nChange-Id: I77945703fc8ed511a7d6dafe4f37ef004897f6b9\n'}, {'number': 3, 'created': '2017-12-14 11:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9a9a2813870f7145c32f0cd030ac911767d9d175', 'message': 'Revert ""Freeze all SHAs for 17.0.0.0b2""\n\nIn order to continue Queens development, the role\nSHA pins are removed.\n\nChange-Id: I77945703fc8ed511a7d6dafe4f37ef004897f6b9\n'}, {'number': 4, 'created': '2017-12-15 11:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5f3411a78dc560792a4f103a7ca1b6058857beb4', 'message': 'Revert ""Freeze all SHAs for 17.0.0.0b2""\n\nIn order to continue Queens development, the role\nSHA pins are removed.\n\nChange-Id: I77945703fc8ed511a7d6dafe4f37ef004897f6b9\n'}, {'number': 5, 'created': '2017-12-18 10:39:04.000000000', 'files': ['inventory/group_vars/all/all.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cf9dcbcdef65b776ce510b1278200260e569662f', 'message': 'Revert ""Freeze all SHAs for 17.0.0.0b2""\n\nIn order to continue Queens development, the role\nSHA pins are removed.\n\nChange-Id: I77945703fc8ed511a7d6dafe4f37ef004897f6b9\n'}]",0,527936,cf9dcbcdef65b776ce510b1278200260e569662f,42,9,5,6816,,,0,"Revert ""Freeze all SHAs for 17.0.0.0b2""

In order to continue Queens development, the role
SHA pins are removed.

Change-Id: I77945703fc8ed511a7d6dafe4f37ef004897f6b9
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/36/527936/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/neutron-vpnaas-5c7c6508f2cc05c5.yaml', 'releasenotes/notes/horizon-arbitrary-config-8a36e4bd6818afe1.yaml', 'releasenotes/notes/world-writable-file-search-optional-7420269230a0e22f.yaml', 'releasenotes/notes/clustecheck-9311d05fb32f13b3.yaml', 'releasenotes/notes/custom_eventstreamer_queue_url-a1dcd1f6769816c5.yaml', 'releasenotes/notes/lxc-cache-prep-timeout-97dc18882f7b1e76.yaml', 'releasenotes/notes/static_uca_filename-849a6f491acae9c5.yaml', 'releasenotes/notes/new_healthcheck-9e559565745defd0.yaml', 'releasenotes/notes/add-security-headers-e46c205b42b9598b.yaml', 'releasenotes/notes/disable-check-of-package-checksums-by-default-3543840512c348d6.yaml', 'releasenotes/notes/pypiserver-pypi-cache-216e9e087f6d3f24.yaml', 'releasenotes/notes/remove_use_neutron-76135a385ef1345d.yaml', 'releasenotes/notes/launch-instance-defaults-support-533844543082b2f4.yaml', 'releasenotes/notes/neutron-bgp-552e6e1f6d37f38d.yaml', 'group_vars/all/all.yml', 'releasenotes/notes/glance-v2-api-only-0d4a61b0d4dade18.yaml', 'releasenotes/notes/disable-ksm-670aeb175826b7ca.yaml', 'releasenotes/notes/os-tempest-roles-cead45b2cd38811f.yaml', 'releasenotes/notes/permitrootlogin_options-a62e33ccc4a69657.yaml', 'releasenotes/notes/remove-duplicated-download-99a9ec5bfe4ba749.yaml', 'releasenotes/notes/ng-instance-management-f9134fc283aa289c.yaml', 'ansible-role-requirements.yml', 'releasenotes/notes/specific_kernel_modules_with_group_vars-8d169f564ffd450c.yaml', 'releasenotes/notes/openvswitch-nsh-support-a9f86a929e072cea.yaml', 'releasenotes/notes/neutron-fwaas-5c7c6508f2cc05c3.yaml', 'releasenotes/notes/support-ksm-fe6993158768a14e.yaml', 'releasenotes/notes/gid-and-uid-cinder-system-user-support-f69b87b4876c0dd8.yaml', 'releasenotes/notes/rhel7-stig-v1r3-update-c533ed40ba609ccf.yaml']",28,c7154b51768a72ddc1342fd360fd4adb89d85764,release_osa,,"--- features: - | The tasks within the ansible-hardening role are now based on Version 1, Release 3 of the Red Hat Enteprise Linux Security Technical Implementation Guide. - | The ``sysctl`` parameter ``kernel.randomize_va_space`` is now set to ``2`` by default. This matches the default of most modern Linux distributions and it ensures that Address Space Layout Randomization (ASLR) is enabled. - | The Datagram Congestion Control Protocol (DCCP) kernel module is now disabled by default, but a reboot is required to make the change effective. ",49,265
openstack%2Fcharm-neutron-openvswitch~stable%2F17.11~I7eaae8f33ed0dc5c97ef478bfe9e1fbd7f79783f,openstack/charm-neutron-openvswitch,stable/17.11,I7eaae8f33ed0dc5c97ef478bfe9e1fbd7f79783f,Fix use of iteritems in dnsmasq.conf templates.,MERGED,2017-12-15 17:11:46.000000000,2017-12-18 15:10:27.000000000,2017-12-18 15:10:27.000000000,"[{'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 27156}]","[{'number': 1, 'created': '2017-12-15 17:11:46.000000000', 'files': ['templates/dnsmasq.conf'], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/50ec140020ad7fe3a2c390903c9efa14f10ec763', 'message': 'Fix use of iteritems in dnsmasq.conf templates.\n\niteritems() method is no longer exists in Python 3 dictionaries\nwhich causes the neutron-openvswitch charm to throw an exception\nif dnsmasq_flags option is set. Code has been changed to\nitems() method to work in Python 3.\n\nChange-Id: I7eaae8f33ed0dc5c97ef478bfe9e1fbd7f79783f\nCloses-Bug: #1738198\n(cherry picked from commit 84fb4b906d535861f60a8509cab89b7e5ae026f2)\n'}]",0,528347,50ec140020ad7fe3a2c390903c9efa14f10ec763,9,5,1,935,,,0,"Fix use of iteritems in dnsmasq.conf templates.

iteritems() method is no longer exists in Python 3 dictionaries
which causes the neutron-openvswitch charm to throw an exception
if dnsmasq_flags option is set. Code has been changed to
items() method to work in Python 3.

Change-Id: I7eaae8f33ed0dc5c97ef478bfe9e1fbd7f79783f
Closes-Bug: #1738198
(cherry picked from commit 84fb4b906d535861f60a8509cab89b7e5ae026f2)
",git fetch https://review.opendev.org/openstack/charm-neutron-openvswitch refs/changes/47/528347/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/dnsmasq.conf'],1,50ec140020ad7fe3a2c390903c9efa14f10ec763,bug/1738198,"{% for key, value in dnsmasq_flags.items() -%}","{% for key, value in dnsmasq_flags.iteritems() -%}",1,1
openstack%2Fnetworking-ovn~master~I2962cb515abdeb1e67193bf6071eb5e8d22bdb54,openstack/networking-ovn,master,I2962cb515abdeb1e67193bf6071eb5e8d22bdb54,Use systemd service for all ovs/ovn process,MERGED,2017-11-07 02:40:00.000000000,2017-12-18 14:51:27.000000000,2017-12-18 14:51:27.000000000,"[{'_account_id': 6773}, {'_account_id': 8788}, {'_account_id': 10237}, {'_account_id': 22348}, {'_account_id': 23458}, {'_account_id': 24438}]","[{'number': 1, 'created': '2017-11-07 02:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/35dfd104f31e19b9c01df160de8b0fbe8c4e1f93', 'message': 'WIP: Use systemd service for all ovs/ovn process\n\nThere are some TODOs for systemd service in lib/networking-ovn.\nThis patch implements an ovn process wrapper and uses it for all ovs/ovn\nprocesses. In additional this patch replaces most of the process options\nwith default ones to simplify services.\n\nChange-Id: I2962cb515abdeb1e67193bf6071eb5e8d22bdb54\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}, {'number': 2, 'created': '2017-11-07 07:45:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/358287c3f6f6f3923dfbbda414f88eed1357f639', 'message': 'WIP: Use systemd service for all ovs/ovn process\n\nThere are some TODOs for systemd service in lib/networking-ovn.\nThis patch implements an ovn process wrapper and uses it for all ovs/ovn\nprocesses. In additional this patch replaces most of the process options\nwith default ones to simplify services.\n\nChange-Id: I2962cb515abdeb1e67193bf6071eb5e8d22bdb54\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}, {'number': 3, 'created': '2017-11-08 06:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/71fabeb8f2cef8693a0f015ff6e7e39177e9e4ee', 'message': 'Use systemd service for all ovs/ovn process\n\nThere are some TODOs for systemd service in lib/networking-ovn.\nThis patch implements an ovn process wrapper and uses it for all ovs/ovn\nprocesses. In additional this patch replaces most of the process options\nwith default ones to simplify services.\n\nChange-Id: I2962cb515abdeb1e67193bf6071eb5e8d22bdb54\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}, {'number': 4, 'created': '2017-11-08 12:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/ec07feaa7d4f1612ee97ad641106d2af6d952748', 'message': 'Use systemd service for all ovs/ovn process\n\nThere are some TODOs for systemd service in lib/networking-ovn.\nThis patch implements an ovn process wrapper and uses it for all ovs/ovn\nprocesses. In additional this patch replaces most of the process options\nwith default ones to simplify services.\n\nChange-Id: I2962cb515abdeb1e67193bf6071eb5e8d22bdb54\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}, {'number': 5, 'created': '2017-11-20 09:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/97a04631a4306d3e203ca558c94db7a53c4eda69', 'message': 'Use systemd service for all ovs/ovn process\n\nThere are some TODOs for systemd service in lib/networking-ovn.\nThis patch implements an ovn process wrapper and uses it for all ovs/ovn\nprocesses. In additional this patch replaces most of the process options\nwith default ones to simplify services.\n\nChange-Id: I2962cb515abdeb1e67193bf6071eb5e8d22bdb54\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}, {'number': 6, 'created': '2017-11-27 06:57:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/9204e68b36da7af602fcf237a10e8cc580b029a1', 'message': 'Use systemd service for all ovs/ovn process\n\nThere are some TODOs for systemd service in lib/networking-ovn.\nThis patch implements an ovn process wrapper and uses it for all ovs/ovn\nprocesses. In additional this patch replaces most of the process options\nwith default ones to simplify services.\n\nChange-Id: I2962cb515abdeb1e67193bf6071eb5e8d22bdb54\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}, {'number': 7, 'created': '2017-11-27 07:00:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/890ab3247702d4c5bb8d802ef10c4721b5d9ef28', 'message': 'Use systemd service for all ovs/ovn process\n\nThere are some TODOs for systemd service in lib/networking-ovn.\nThis patch implements an ovn process wrapper and uses it for all ovs/ovn\nprocesses. In additional this patch replaces most of the process options\nwith default ones to simplify services.\n\nChange-Id: I2962cb515abdeb1e67193bf6071eb5e8d22bdb54\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}, {'number': 8, 'created': '2017-12-15 13:35:11.000000000', 'files': ['playbooks/legacy/tempest-post-common.yml', 'devstack/lib/networking-ovn'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/0b634b23769a04c719300e5b44578653064038ea', 'message': 'Use systemd service for all ovs/ovn process\n\nThere are some TODOs for systemd service in lib/networking-ovn.\nThis patch implements an ovn process wrapper and uses it for all ovs/ovn\nprocesses. In additional this patch replaces most of the process options\nwith default ones to simplify services.\n\nChange-Id: I2962cb515abdeb1e67193bf6071eb5e8d22bdb54\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}]",9,518203,0b634b23769a04c719300e5b44578653064038ea,45,6,8,23458,,,0,"Use systemd service for all ovs/ovn process

There are some TODOs for systemd service in lib/networking-ovn.
This patch implements an ovn process wrapper and uses it for all ovs/ovn
processes. In additional this patch replaces most of the process options
with default ones to simplify services.

Change-Id: I2962cb515abdeb1e67193bf6071eb5e8d22bdb54
Signed-off-by: Dong Jun <dongj@dtdream.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/03/518203/4 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/networking-ovn'],1,35dfd104f31e19b9c01df160de8b0fbe8c4e1f93,devstack,"OVS_RUNDIR=/usr/local/var/run/openvswitch OVS_SHAREDIR=/usr/local/share/openvswitch OVS_SCRIPTDIR=$OVS_SHAREDIR/scripts OVS_DATADIR=$DATA_DIR/ovs function _ovn_run_process { local service=$1 local cmd=""$2"" local group=$3 local user=${4:-$STACK_USER} local systemd_service=""devstack@$service.service"" local unit_file=""$SYSTEMD_DIR/$systemd_service"" local environment=""OVS_RUNDIR=$OVS_RUNDIR OVS_DBDIR=$OVS_DATADIR OVS_LOGDIR=$LOGDIR"" echo ""Starting $service executed command"": $cmd write_user_unit_file $systemd_service ""$cmd"" ""$group"" ""$user"" iniset -sudo $unit_file ""Service"" ""Type"" ""forking"" iniset -sudo $unit_file ""Service"" ""RemainAfterExit"" ""yes"" iniset -sudo $unit_file ""Service"" ""KillMode"" ""mixed"" iniset -sudo $unit_file ""Service"" ""LimitNOFILE"" ""65536"" iniset -sudo $unit_file ""Service"" ""Environment"" ""$environment"" $SYSTEMCTL daemon-reload $SYSTEMCTL enable $systemd_service $SYSTEMCTL restart $systemd_service local testcmd=""test -e $OVS_RUNDIR/$service.pid"" test_with_retry ""$testcmd"" ""$service did not start"" $SERVICE_TIMEOUT 1 sudo ovs-appctl -t $service vlog/set console:off syslog:info file:info } iniset $OVN_META_CONF ovs ovsdb_connection unix:$OVS_RUNDIR/db.sock mkdir -p $OVS_DATADIR rm -f $OVS_DATADIR/*.db rm -f $OVS_DATADIR/.*.db.~lock~ remove_ovs_packages sudo rm -rf $OVS_RUNDIR/* sudo mkdir -p $OVS_RUNDIR sudo chown $(whoami) $OVS_RUNDIR # Archive log files and create new local log_archive_dir=$LOGDIR/archive mkdir -p $log_archive_dir for logfile in ovs-vswitchd.log ovn-northd.log ovn-controller.log ovn-controller-vtep.log ovs-vtep.log ovsdb-server.log ovsdb-server-nb.log ovsdb-server-sb.log; do if [ -f ""$LOGDIR/$logfile"" ] ; then mv ""$LOGDIR/$logfile"" ""$log_archive_dir/$logfile.${CURRENT_LOG_TIME}"" fi done # ovsdb-server and ovs-vswitchd are used privately in OVN as openvswitch service names. enable_service ovsdb-server enable_service ovs-vswitchd ovsdb-tool create $OVS_DATADIR/conf.db $OVS_SHAREDIR/vswitch.ovsschema if is_ovn_service_enabled ovn-controller-vtep; then ovsdb-tool create $OVS_DATADIR/vtep.db $OVS_SHAREDIR/vtep.ovsschema local dbcmd=""/usr/local/sbin/ovsdb-server --remote=punix:$OVS_RUNDIR/db.sock --pidfile --detach --log-file"" dbcmd+="" --remote=db:Open_vSwitch,Open_vSwitch,manager_options"" if is_ovn_service_enabled ovn-controller-vtep; then dbcmd+="" --remote=db:hardware_vtep,Global,managers $OVS_DATADIR/vtep.db"" fi dbcmd+="" $OVS_DATADIR/conf.db"" _ovn_run_process ovsdb-server ""$dbcmd"" local ovscmd=""$OVS_SCRIPTDIR/ovs-ctl --no-ovsdb-server --no-monitor --system-id=random start"" _ovn_run_process ovs-vswitchd ""$ovscmd"" ""$STACK_USER"" ""root"" echo ""Configuring OVS"" sudo ovs-vsctl --no-wait set open_vswitch . system-type=""devstack"" sudo ovs-vsctl --no-wait set open_vswitch . external-ids:system-id=""$OVN_UUID"" sudo ovs-vsctl --no-wait set open_vswitch . external-ids:ovn-remote=""$OVN_SB_REMOTE"" sudo ovs-vsctl --no-wait set open_vswitch . external-ids:ovn-bridge=""br-int"" sudo ovs-vsctl --no-wait set open_vswitch . external-ids:ovn-encap-type=""geneve,vxlan"" sudo ovs-vsctl --no-wait set open_vswitch . external-ids:ovn-encap-ip=""$HOST_IP"" sudo ovs-vsctl --no-wait set bridge br-int fail-mode=secure other-config:disable-in-band=true sudo ovs-vsctl set open . external-ids:ovn-bridge-mappings=${PHYSICAL_NETWORK}:${OVS_PHYSICAL_BRIDGE} if is_ovn_service_enabled ovn-controller-vtep ; then ovn_base_setup_bridge br-vtep sudo vtep-ctl add-ps br-vtep sudo vtep-ctl set Physical_Switch br-vtep tunnel_ips=$HOST_IP enable_service ovs-vtep local vtepcmd=""$OVS_SCRIPTDIR/ovs-vtep --log-file --pidfile --detach br-vtep"" _ovn_run_process ovs-vtep ""$vtepcmd"" ""$STACK_USER"" ""root"" sudo vtep-ctl set-manager tcp:$HOST_IP:6640 fi if is_ovn_service_enabled ovn-northd ; then local cmd=""$OVS_SCRIPTDIR/ovn-ctl --no-monitor start_northd"" cmd+="" --db-nb-create-insecure-remote=yes --db-sb-create-insecure-remote=yes"" _ovn_run_process ovn-northd ""$cmd"" sudo ovs-appctl -t $OVS_RUNDIR/ovnnb_db.ctl vlog/set console:off syslog:info file:info sudo ovs-appctl -t $OVS_RUNDIR/ovnnb_db.ctl vlog/set console:off syslog:info file:info fi if is_ovn_service_enabled ovn-controller ; then local cmd=""$OVS_SCRIPTDIR/ovn-ctl --no-monitor start_controller"" _ovn_run_process ovn-controller ""$cmd"" ""$STACK_USER"" ""root"" local cmd=""$OVS_SCRIPTDIR/ovn-ctl --no-monitor start_controller_vtep"" _ovn_run_process ovn-controller-vtep ""$cmd"" ""$STACK_USER"" ""root"" if is_ovn_service_enabled ovn-controller-vtep ; then stop_process ovn-controller-vtep fi if is_ovn_service_enabled ovn-controller ; then stop_process ovn-controller fi if is_ovn_service_enabled ovn-northd ; then stop_process ovn-northd fi if is_service_enabled ovs-vtep ; then stop_process ovs-vtep fi if is_service_enabled ovs-vswitchd ; then stop_process ovs-vswitchd fi if is_service_enabled ovsdb-server ; then stop_process ovsdb-server fi"," iniset $OVN_META_CONF ovs ovsdb_connection unix:/usr/local/var/run/openvswitch/db.sock base_dir=$DATA_DIR/ovs mkdir -p $base_dir for db in conf.db ovnsb.db ovnnb.db vtep.db ; do if [ -f $base_dir/$db ] ; then rm -f $base_dir/$db fi done rm -f $base_dir/.*.db.~lock~ echo ""Creating OVS, OVN-Southbound and OVN-Northbound Databases"" ovsdb-tool create $base_dir/conf.db $DEST/$OVN_REPO_NAME/vswitchd/vswitch.ovsschema if is_ovn_service_enabled ovn-northd ; then ovsdb-tool create $base_dir/ovnsb.db $DEST/$OVN_REPO_NAME/ovn/ovn-sb.ovsschema ovsdb-tool create $base_dir/ovnnb.db $DEST/$OVN_REPO_NAME/ovn/ovn-nb.ovsschema fi if is_ovn_service_enabled ovn-controller-vtep ; then ovsdb-tool create $base_dir/vtep.db $DEST/$OVN_REPO_NAME/vtep/vtep.ovsschema fi sudo mkdir -p /usr/local/var/run/openvswitch sudo chown $(whoami) /usr/local/var/run/openvswitch local _pwd=$(pwd) local ovsdb_logfile=""ovsdb-server.log.${CURRENT_LOG_TIME}"" bash -c ""cd '$LOGDIR' && touch '$ovsdb_logfile' && ln -sf '$ovsdb_logfile' ovsdb-server.log"" local ovsdb_nb_logfile=""ovsdb-server-nb.log.${CURRENT_LOG_TIME}"" bash -c ""cd '$LOGDIR' && touch '$ovsdb_nb_logfile' && ln -sf '$ovsdb_nb_logfile' ovsdb-server-nb.log"" local ovsdb_sb_logfile=""ovsdb-server-sb.log.${CURRENT_LOG_TIME}"" bash -c ""cd '$LOGDIR' && touch '$ovsdb_sb_logfile' && ln -sf '$ovsdb_sb_logfile' ovsdb-server-sb.log"" cd $DATA_DIR/ovs EXTRA_DBS="""" OVSDB_SB_REMOTE="""" if is_ovn_service_enabled ovn-northd ; then # TODO (regXboi): change ovn-ctl so that we can use something # other than --db-nb-port for port and ip address DB_NB_PORT=""6641"" DB_NB_INSECURE_REMOTE=""yes"" DB_NB_FILE=""$DATA_DIR/ovs/ovnnb.db"" OVN_NB_LOGFILE=""$LOGDIR/ovsdb-server-nb.log"" # TODO (regXboi): change ovn-ctl so that we can use something # other than --db-sb-port for port and ip address DB_SB_PORT=""6642"" DB_SB_INSECURE_REMOTE=""yes"" DB_SB_FILE=""$DATA_DIR/ovs/ovnsb.db"" OVN_SB_LOGFILE=""$LOGDIR/ovsdb-server-sb.log"" /usr/local/share/openvswitch/scripts/ovn-ctl start_ovsdb \ --db-nb-create-insecure-remote=$DB_NB_INSECURE_REMOTE \ --db-sb-create-insecure-remote=$DB_SB_INSECURE_REMOTE \ --db-nb-port=$DB_NB_PORT --db-sb-port=$DB_SB_PORT \ --db-nb-file=$DB_NB_FILE --ovn-nb-logfile=$OVN_NB_LOGFILE \ --db-sb-file=$DB_SB_FILE --ovn-sb-logfile=$OVN_SB_LOGFILE echo ""Waiting for ovn ovsdb servers to start ... "" DB_NB_SOCK=""/usr/local/var/run/openvswitch/ovnnb_db.sock"" DB_SB_SOCK=""/usr/local/var/run/openvswitch/ovnsb_db.sock"" local testcmd=""test -e $DB_NB_SOCK -a -e $DB_SB_SOCK"" test_with_retry ""$testcmd"" ""nb ovsdb-server did not start"" $SERVICE_TIMEOUT 1 echo ""done."" fi # TODO (regXboi): it would be nice to run the following with run_process # and have it end up under the control of screen. However, at the point # this is called, screen isn't running, so we'd have to overload # USE_SCREEN to get the process to start, but testing shows that the # resulting process doesn't want to create br-int, which leaves things # rather broken. So, stay with this for now and somebody more tenacious # than I can figure out how to make it work... local _OVSREMOTE=""--remote=db:Open_vSwitch,Open_vSwitch,manager_options"" local _VTEPREMOTE="""" local _OVSDB=conf.db local _VTEPDB="""" if is_ovn_service_enabled ovn-controller-vtep ; then _VTEPREMOTE=""--remote=db:hardware_vtep,Global,managers"" _VTEPDB=vtep.db ovsdb-server --remote=punix:/usr/local/var/run/openvswitch/db.sock \ $_OVSREMOTE $_VTEPREMOTE \ --pidfile --detach -vconsole:off \ --log-file=$LOGDIR/ovsdb-server.log \ $_OVSDB $_VTEPDB echo -n ""Waiting for ovsdb-server to start ... "" local testcmd=""test -e /usr/local/var/run/openvswitch/db.sock"" test_with_retry ""$testcmd"" ""ovsdb-server did not start"" $SERVICE_TIMEOUT 1 echo ""done."" ovs-vsctl --no-wait init ovs-vsctl --no-wait set open_vswitch . system-type=""devstack"" ovs-vsctl --no-wait set open_vswitch . external-ids:system-id=""$OVN_UUID"" fi if is_ovn_service_enabled ovn-controller || is_ovn_service_enabled ovn-controller-vtep ; then ovs-vsctl --no-wait set open_vswitch . external-ids:ovn-remote=""$OVN_SB_REMOTE"" ovs-vsctl --no-wait set open_vswitch . external-ids:ovn-bridge=""br-int"" ovs-vsctl --no-wait set open_vswitch . external-ids:ovn-encap-type=""geneve,vxlan"" ovs-vsctl --no-wait set open_vswitch . external-ids:ovn-encap-ip=""$HOST_IP"" ovs-vsctl --no-wait set bridge br-int fail-mode=secure other-config:disable-in-band=true local ovswd_logfile=""ovs-switchd.log.${CURRENT_LOG_TIME}"" bash -c ""cd '$LOGDIR' && touch '$ovswd_logfile' && ln -sf '$ovswd_logfile' ovs-vswitchd.log"" # Bump up the max number of open files ovs-vswitchd can have sudo sh -c ""ulimit -n 32000 && exec ovs-vswitchd --pidfile --detach -vconsole:off --log-file=$LOGDIR/ovs-vswitchd.log"" ovs-vsctl set open . external-ids:ovn-bridge-mappings=${PHYSICAL_NETWORK}:${OVS_PHYSICAL_BRIDGE} fi if is_ovn_service_enabled ovn-controller-vtep ; then ovn_base_setup_bridge br-vtep vtep-ctl add-ps br-vtep vtep-ctl set Physical_Switch br-vtep tunnel_ips=$HOST_IP sudo /usr/local/share/openvswitch/scripts/ovs-vtep --log-file=$LOGDIR/ovs-vtep.log --pidfile --detach br-vtep vtep-ctl set-manager tcp:$HOST_IP:6640 if is_ovn_service_enabled ovn-controller ; then # (regXboi) pulling out --log-file to avoid double logging # appears to break devstack, so let's not do that run_process ovn-controller ""/usr/local/bin/ovn-controller --pidfile --log-file unix:/usr/local/var/run/openvswitch/db.sock"" root root # This makes sure that the console logs have time stamps to # the millisecond, but we need to make sure ovs-appctl has # a pid file to work with, so ... echo -n ""Waiting for ovn-controller to start ... "" local testcmd=""test -e /usr/local/var/run/openvswitch/ovn-controller.pid"" test_with_retry ""$testcmd"" ""ovn-controller did not start"" $SERVICE_TIMEOUT 1 echo ""done."" sudo ovs-appctl -t ovn-controller vlog/set ""PATTERN:CONSOLE:%D{%Y-%m-%dT%H:%M:%S.###Z}|%05N|%c%T|%p|%m"" # (regXboi) pulling out --log-file to avoid double logging # appears to break devstack, so let's not do that run_process ovn-controller-vtep ""/usr/local/bin/ovn-controller-vtep --pidfile --log-file --vtep-db=unix:/usr/local/var/run/openvswitch/db.sock --ovnsb-db=$OVN_SB_REMOTE"" root root # This makes sure that the console logs have time stamps to # the millisecond, but we need to make sure ovs-appctl has # a pid file to work with, so ... echo -n ""Waiting for ovn-controller-vtep to start ... "" local testcmd=""test -e /usr/local/var/run/openvswitch/ovn-controller-vtep.pid"" test_with_retry ""$testcmd"" ""ovn-controller-vtep did not start"" $SERVICE_TIMEOUT 1 echo ""done."" sudo ovs-appctl -t ovn-controller-vtep vlog/set ""PATTERN:CONSOLE:%D{%Y-%m-%dT%H:%M:%S.###Z}|%05N|%c%T|%p|%m"" fi if is_ovn_service_enabled ovn-northd ; then run_process ovn-northd ""/usr/local/bin/ovn-northd --log-file=$LOGDIR/ovn-northd.log --pidfile"" # This makes sure that the console logs have time stamps to # the millisecond, but we need to make sure ovs-appctl has # a pid file to work with, so ... echo -n ""Waiting for ovn-northd to start ... "" OVN_NORTHD_PID=""/usr/local/var/run/openvswitch/ovn-northd.pid"" local testcmd=""test -e $OVN_NORTHD_PID"" test_with_retry ""$testcmd"" ""ovn-northd did not start"" $SERVICE_TIMEOUT 1 echo ""done."" sudo ovs-appctl -t ovn-northd vlog/set ""PATTERN:CONSOLE:%D{%Y-%m-%dT%H:%M:%S.###Z}|%05N|%c%T|%p|%m"" if is_ovn_service_enabled ovn-controller ; then stop_process ovn-controller sudo killall ovs-vswitchd fi if is_ovn_service_enabled ovn-controller-vtep ; then stop_process ovn-controller-vtep sudo killall ovs-vtep sudo killall ovs-vswitchd fi if is_ovn_service_enabled ovn-northd ; then /usr/local/share/openvswitch/scripts/ovn-ctl stop_northd fi sudo killall ovsdb-server",119,166
openstack%2Fhorizon~master~I550e6c59bb14c17da78d7b2abcde5783b2b6825d,openstack/horizon,master,I550e6c59bb14c17da78d7b2abcde5783b2b6825d,Use Cinder API v3 by default,MERGED,2017-12-13 19:25:53.000000000,2017-12-18 14:51:01.000000000,2017-12-18 14:51:01.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 19:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3ce3d320e329a8e8b41a3cc288e8ae5ac123811f', 'message': ""Use Cinder API v3 by default\n\nCinder API v3 was introduced several releases ago and is backward\ncompatible with API v2 so it's safe to swith to use it.\n\nChange-Id: I550e6c59bb14c17da78d7b2abcde5783b2b6825d\nCloses-Bug: #1728761\n""}, {'number': 2, 'created': '2017-12-18 10:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b716e5074f6dff22d4d2761e2bb5ab9b57b6ac33', 'message': ""Use Cinder API v3 by default\n\nCinder API v3 was introduced several releases ago and is backward\ncompatible with API v2 so it's safe to swith to use it.\n\nChange-Id: I550e6c59bb14c17da78d7b2abcde5783b2b6825d\nCloses-Bug: #1728761\n""}, {'number': 3, 'created': '2017-12-18 10:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ace4ac0b83ba9b163b698ddecb8252ccc2c901ef', 'message': ""Use Cinder API v3 by default\n\nCinder API v3 was introduced several releases ago and is backward\ncompatible with API v2 so it's safe to swith to use it.\n\nChange-Id: I550e6c59bb14c17da78d7b2abcde5783b2b6825d\nCloses-Bug: #1728761\n""}, {'number': 4, 'created': '2017-12-18 13:34:57.000000000', 'files': ['openstack_dashboard/dashboards/project/cgroups/panel.py', 'openstack_dashboard/dashboards/project/snapshots/panel.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/dashboards/admin/volumes/panel.py', 'openstack_dashboard/dashboards/project/backups/panel.py', 'openstack_dashboard/dashboards/project/snapshots/views.py', 'openstack_dashboard/dashboards/admin/volume_types/panel.py', 'openstack_dashboard/dashboards/admin/info/tabs.py', 'openstack_dashboard/dashboards/project/cg_snapshots/panel.py', 'openstack_dashboard/dashboards/project/cg_snapshots/tables.py', 'openstack_dashboard/test/unit/api/test_base.py', 'openstack_dashboard/dashboards/project/volumes/panel.py', 'openstack_dashboard/test/unit/api/test_cinder.py', 'openstack_dashboard/test/test_data/keystone_data.py', 'openstack_dashboard/dashboards/project/snapshots/tables.py', 'openstack_dashboard/dashboards/project/snapshots/tests.py', 'openstack_dashboard/dashboards/admin/snapshots/panel.py', 'releasenotes/notes/cinder-api-v3-by-default-d6e3c12760fdf655.yaml'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a774fa30dd41c12eacad154adb40605025a165e2', 'message': ""Use Cinder API v3 by default\n\nCinder API v3 was introduced several releases ago and is backward\ncompatible with API v2 so it's safe to swith to use it.\n\nChange-Id: I550e6c59bb14c17da78d7b2abcde5783b2b6825d\nCloses-Bug: #1728761\n""}]",9,527767,a774fa30dd41c12eacad154adb40605025a165e2,19,3,4,1736,,,0,"Use Cinder API v3 by default

Cinder API v3 was introduced several releases ago and is backward
compatible with API v2 so it's safe to swith to use it.

Change-Id: I550e6c59bb14c17da78d7b2abcde5783b2b6825d
Closes-Bug: #1728761
",git fetch https://review.opendev.org/openstack/horizon refs/changes/67/527767/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/cgroups/panel.py', 'openstack_dashboard/dashboards/project/snapshots/panel.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/dashboards/admin/volumes/panel.py', 'openstack_dashboard/dashboards/project/backups/panel.py', 'openstack_dashboard/dashboards/project/snapshots/views.py', 'openstack_dashboard/dashboards/admin/volume_types/panel.py', 'openstack_dashboard/dashboards/admin/info/tabs.py', 'openstack_dashboard/dashboards/project/cg_snapshots/panel.py', 'openstack_dashboard/dashboards/project/cg_snapshots/tables.py', 'openstack_dashboard/test/unit/api/test_base.py', 'openstack_dashboard/dashboards/project/volumes/panel.py', 'openstack_dashboard/test/unit/api/test_cinder.py', 'openstack_dashboard/test/test_data/keystone_data.py', 'openstack_dashboard/dashboards/project/snapshots/tables.py', 'openstack_dashboard/dashboards/project/snapshots/tests.py', 'openstack_dashboard/dashboards/admin/snapshots/panel.py']",17,3ce3d320e329a8e8b41a3cc288e8ae5ac123811f,bug/1728761," ('openstack.services.volume', 'openstack.services.volumev2', 'openstack.services.volumev3'),"," ('openstack.services.volume', 'openstack.services.volumev2'),",58,28
openstack%2Fvitrage~master~Ic7eed36098fe3489cb2c2d5568b06604966fb44d,openstack/vitrage,master,Ic7eed36098fe3489cb2c2d5568b06604966fb44d,use force_delete to delete instances in rollback,MERGED,2017-12-18 09:45:52.000000000,2017-12-18 14:42:50.000000000,2017-12-18 14:42:50.000000000,"[{'_account_id': 19134}, {'_account_id': 19194}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 09:45:52.000000000', 'files': ['vitrage_tempest_tests/tests/common/nova_utils.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/31ffcb8571158bbd294c798ef956318e47863ae9', 'message': 'use force_delete to delete instances in rollback\n\nChange-Id: Ic7eed36098fe3489cb2c2d5568b06604966fb44d\n'}]",0,528676,31ffcb8571158bbd294c798ef956318e47863ae9,11,3,1,19134,,,0,"use force_delete to delete instances in rollback

Change-Id: Ic7eed36098fe3489cb2c2d5568b06604966fb44d
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/76/528676/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage_tempest_tests/tests/common/nova_utils.py'],1,31ffcb8571158bbd294c798ef956318e47863ae9,eyalb/tempest, TempestClients.nova().servers.force_delete(item), TempestClients.nova().servers.delete(item),1,1
openstack%2Fwatcher~master~Iefc22b54995aa8d2f3a7b3698575f6eb800d4289,openstack/watcher,master,Iefc22b54995aa8d2f3a7b3698575f6eb800d4289,Update getting scoped storage CDM,MERGED,2017-11-28 04:36:07.000000000,2017-12-18 14:31:39.000000000,2017-12-18 14:31:39.000000000,"[{'_account_id': 12394}, {'_account_id': 13111}, {'_account_id': 18971}, {'_account_id': 19055}, {'_account_id': 19457}, {'_account_id': 21692}, {'_account_id': 22348}, {'_account_id': 22775}, {'_account_id': 24872}]","[{'number': 1, 'created': '2017-11-28 04:36:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/13bf48daf9ed5a6719b8f59b86645ca660e5beab', 'message': 'Update getting scoped storage CDM\n\nNow that CDM-scoping was implemented, Getting scoped storage model\nhave to be updated.\nThis patch updates getting storage cluster data model.\n\nChange-Id: Iefc22b54995aa8d2f3a7b3698575f6eb800d4289\nPartially-Implements: blueprint cdm-scoping\n'}, {'number': 2, 'created': '2017-11-29 03:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/0595644acdea30a984316edb168c88e538f71649', 'message': 'Update getting scoped storage CDM\n\nNow that CDM-scoping was implemented, Getting scoped storage model\nhave to be updated.\nThis patch updates getting storage cluster data model.\n\nChange-Id: Iefc22b54995aa8d2f3a7b3698575f6eb800d4289\n'}, {'number': 3, 'created': '2017-12-05 23:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/d7e3345e7cdad46f12d181159f3e080c204009e7', 'message': 'Update getting scoped storage CDM\n\nNow that CDM-scoping was implemented, Getting scoped storage model\nhave to be updated.\nThis patch updates getting storage cluster data model.\n\nChange-Id: Iefc22b54995aa8d2f3a7b3698575f6eb800d4289\n'}, {'number': 4, 'created': '2017-12-08 05:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/5422d45259e10ae3ea15c9cf09eb7d3df72dc3b1', 'message': 'Update getting scoped storage CDM\n\nNow that CDM-scoping was implemented, Getting scoped storage model\nhave to be updated.\nThis patch updates getting storage cluster data model.\n\nChange-Id: Iefc22b54995aa8d2f3a7b3698575f6eb800d4289\n'}, {'number': 5, 'created': '2017-12-12 04:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/d665fa05427eea8369ef1750f920279760db9af0', 'message': 'Update getting scoped storage CDM\n\nNow that CDM-scoping was implemented, Getting scoped storage model\nhave to be updated.\nThis patch updates getting storage cluster data model.\n\nChange-Id: Iefc22b54995aa8d2f3a7b3698575f6eb800d4289\n'}, {'number': 6, 'created': '2017-12-12 08:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/b1e6b8119b0cca0454b6b72f3fec71c57010f6f3', 'message': 'Update getting scoped storage CDM\n\nNow that CDM-scoping was implemented, Getting scoped storage model\nhave to be updated.\nThis patch updates getting storage cluster data model.\n\nChange-Id: Iefc22b54995aa8d2f3a7b3698575f6eb800d4289\n'}, {'number': 7, 'created': '2017-12-16 15:20:58.000000000', 'files': ['watcher/decision_engine/scope/storage.py', 'watcher/decision_engine/strategy/strategies/base.py', 'watcher/decision_engine/model/collector/cinder.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/c6afa7c320da1b276c23b3ac9206584d0157d72e', 'message': 'Update getting scoped storage CDM\n\nNow that CDM-scoping was implemented, Getting scoped storage model\nhave to be updated.\nThis patch updates getting storage cluster data model.\n\nChange-Id: Iefc22b54995aa8d2f3a7b3698575f6eb800d4289\n'}]",7,523296,c6afa7c320da1b276c23b3ac9206584d0157d72e,30,9,7,13111,,,0,"Update getting scoped storage CDM

Now that CDM-scoping was implemented, Getting scoped storage model
have to be updated.
This patch updates getting storage cluster data model.

Change-Id: Iefc22b54995aa8d2f3a7b3698575f6eb800d4289
",git fetch https://review.opendev.org/openstack/watcher refs/changes/96/523296/7 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/decision_engine/scope/storage.py', 'watcher/decision_engine/strategy/strategies/base.py', 'watcher/decision_engine/model/collector/cinder.py']",3,13bf48daf9ed5a6719b8f59b86645ca660e5beab,fix_scoped_storage_model,"from watcher.decision_engine.scope import storage as storage_scope if not self._audit_scope_handler: self._audit_scope_handler = storage_scope.StorageScope( self._audit_scope, self.config) return self._audit_scope_handler", return None,52,2
openstack%2Fneutron~master~I8c73220625f644234074dcf6b592da7582b894df,openstack/neutron,master,I8c73220625f644234074dcf6b592da7582b894df,WIP PoC of possible solution for not applied SG rules,ABANDONED,2017-12-13 15:46:57.000000000,2017-12-18 14:18:45.000000000,,"[{'_account_id': 1131}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 15:46:57.000000000', 'files': ['neutron/plugins/ml2/drivers/linuxbridge/agent/extension_drivers/qos_driver.py', 'neutron/agent/linux/iptables_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3127fdc56a1c388bc8955ca15cb165d113ebff50', 'message': 'WIP PoC of possible solution for not applied SG rules\n\nIt is now only ""dirty"" idea about possible solution to make\nQoS Linuxbridge agent extension not touching any other iptables\ntables then ""mangle"" which it needs.\n\nChange-Id: I8c73220625f644234074dcf6b592da7582b894df\nCloses-Bug: #1736674\n'}]",0,527722,3127fdc56a1c388bc8955ca15cb165d113ebff50,5,4,1,11975,,,0,"WIP PoC of possible solution for not applied SG rules

It is now only ""dirty"" idea about possible solution to make
QoS Linuxbridge agent extension not touching any other iptables
tables then ""mangle"" which it needs.

Change-Id: I8c73220625f644234074dcf6b592da7582b894df
Closes-Bug: #1736674
",git fetch https://review.opendev.org/openstack/neutron refs/changes/22/527722/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/linuxbridge/agent/extension_drivers/qos_driver.py', 'neutron/agent/linux/iptables_manager.py']",2,3127fdc56a1c388bc8955ca15cb165d113ebff50,bug/1736674," def __init__(self, _execute=None, use_base_tables=True, state_less=False, use_ipv6=False, namespace=None, binary_name=binary_name): self.ipv4 = {} self.ipv6 = {} builtin_chains = {4: {}, 6: {}} if use_base_tables: self.ipv4 = {'filter': IptablesTable(binary_name=self.wrap_name)} self.ipv6 = {'filter': IptablesTable(binary_name=self.wrap_name)} # Add a neutron-filter-top chain. It's intended to be shared # among the various neutron components. It sits at the very top # of FORWARD and OUTPUT. for tables in [self.ipv4, self.ipv6]: tables['filter'].add_chain('neutron-filter-top', wrap=False) tables['filter'].add_rule('FORWARD', '-j neutron-filter-top', wrap=False, top=True) tables['filter'].add_rule('OUTPUT', '-j neutron-filter-top', wrap=False, top=True) tables['filter'].add_chain('local') tables['filter'].add_rule('neutron-filter-top', '-j $local', wrap=False) # Wrap the built-in chains builtin_chains = {4: {'filter': ['INPUT', 'OUTPUT', 'FORWARD']}, 6: {'filter': ['INPUT', 'OUTPUT', 'FORWARD']}} if use_base_tables: self.ipv4.update( {'raw': IptablesTable(binary_name=self.wrap_name)}) builtin_chains[4].update({'raw': ['PREROUTING', 'OUTPUT']}) self.ipv6.update( {'raw': IptablesTable(binary_name=self.wrap_name)}) builtin_chains[6].update({'raw': ['PREROUTING', 'OUTPUT']})"," def __init__(self, _execute=None, state_less=False, use_ipv6=False, namespace=None, binary_name=binary_name): self.ipv4 = {'filter': IptablesTable(binary_name=self.wrap_name)} self.ipv6 = {'filter': IptablesTable(binary_name=self.wrap_name)} # Add a neutron-filter-top chain. It's intended to be shared # among the various neutron components. It sits at the very top # of FORWARD and OUTPUT. for tables in [self.ipv4, self.ipv6]: tables['filter'].add_chain('neutron-filter-top', wrap=False) tables['filter'].add_rule('FORWARD', '-j neutron-filter-top', wrap=False, top=True) tables['filter'].add_rule('OUTPUT', '-j neutron-filter-top', wrap=False, top=True) tables['filter'].add_chain('local') tables['filter'].add_rule('neutron-filter-top', '-j $local', wrap=False) # Wrap the built-in chains builtin_chains = {4: {'filter': ['INPUT', 'OUTPUT', 'FORWARD']}, 6: {'filter': ['INPUT', 'OUTPUT', 'FORWARD']}} self.ipv4.update({'raw': IptablesTable(binary_name=self.wrap_name)}) builtin_chains[4].update({'raw': ['PREROUTING', 'OUTPUT']}) self.ipv6.update({'raw': IptablesTable(binary_name=self.wrap_name)}) builtin_chains[6].update({'raw': ['PREROUTING', 'OUTPUT']})",33,24
openstack%2Fmanila~master~Ied021b66333f1254cd232bbc38562a4a9b762ad2,openstack/manila,master,Ied021b66333f1254cd232bbc38562a4a9b762ad2,Fix getting share networks and security services error,MERGED,2017-11-23 16:46:37.000000000,2017-12-18 14:12:46.000000000,2017-12-18 13:57:24.000000000,"[{'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 13984}, {'_account_id': 14384}, {'_account_id': 15100}, {'_account_id': 15831}, {'_account_id': 15942}, {'_account_id': 16643}, {'_account_id': 16657}, {'_account_id': 21224}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2017-11-23 16:46:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c7ed5f69d70c19d06e1352b8d6478b620f98b688', 'message': ""Fix getting share networks error with 'all_tenant=1'\n\nIt will fail when getting share networks with option\n'{all_tenants: 1}'. The reason is that when all_tenants\nis setted to 1, api will check the policy, and the\npolicy of get_all_share_networks is admin_api. It seems\nthis is not right, this patch will fix the issue.\n\nChange-Id: Ied021b66333f1254cd232bbc38562a4a9b762ad2\nCloses-Bug: #1721787\n""}, {'number': 2, 'created': '2017-11-24 01:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/33f30cb244de548a38e7e1491a9b38c72691064f', 'message': ""Fix getting share networks error with 'all_tenant=1'\n\nIt will fail when getting share networks with option\n'{all_tenants: 1}'. The reason is that when all_tenants\nis setted to 1, api will check the policy, and the\npolicy of get_all_share_networks is admin_api. It seems\nthis is not right, this patch will fix the issue.\n\nChange-Id: Ied021b66333f1254cd232bbc38562a4a9b762ad2\nCloses-Bug: #1721787\n""}, {'number': 3, 'created': '2017-11-24 02:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b953896c64046e125a2d99483befa69c79c327fc', 'message': ""Fix getting share networks error with 'all_tenant=1'\n\nIt will fail when getting share networks with option\n'{all_tenants: 1}'. The reason is that when all_tenants\nis setted to 1, api will check the policy, and the\npolicy of get_all_share_networks is admin_api. It seems\nthis is not right, this patch will fix the issue.\n\nChange-Id: Ied021b66333f1254cd232bbc38562a4a9b762ad2\nCloses-Bug: #1721787\n""}, {'number': 4, 'created': '2017-11-24 03:18:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/9e67cd5b80e9f2847bc49ae15dad620fae855e6b', 'message': ""Fix getting share networks error with 'all_tenant=1'\n\nIt will fail when getting share networks with option\n'{all_tenants: 1}'. The reason is that when all_tenants\nis setted to 1, api will check the policy, and the\npolicy of get_all_share_networks is admin_api. It seems\nthis is not right, this patch will fix the issue.\n\nChange-Id: Ied021b66333f1254cd232bbc38562a4a9b762ad2\nCloses-Bug: #1721787\n""}, {'number': 5, 'created': '2017-11-30 08:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2ff322e9a9411ed345c80fc1e1e470e0f14a2cf8', 'message': ""Fix getting share networks error\n\nIt will fail when non admin users try to get share\nnetworks with option '{all_tenants: 1}'. The reason\nis that the policy of 'get_all_share_networks' is\nadmin api, it do not allow the non admin users list\nthe share networks with all_tenants=1. This patch\nchange the policy of 'get_all_share_networks' to\ndefault (same with cinder) and ignore the value of\nall_tenants when the context user is not admin.\n\nChange-Id: Ied021b66333f1254cd232bbc38562a4a9b762ad2\nCloses-Bug: #1721787\n""}, {'number': 6, 'created': '2017-11-30 13:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0666266668a972540af5bd9f609f33cdfb2731c2', 'message': ""Fix getting share networks error\n\nIt will fail when non admin users try to get share\nnetworks with option '{all_tenants: 1}'. The reason\nis that the policy of 'get_all_share_networks' is\nadmin api, it do not allow the non admin users list\nthe share networks with all_tenants=1. This patch\nchange the policy of 'get_all_share_networks' to\ndefault (same with cinder) and ignore the value of\nall_tenants when the context user is not admin.\n\nChange-Id: Ied021b66333f1254cd232bbc38562a4a9b762ad2\nCloses-Bug: #1721787\n""}, {'number': 7, 'created': '2017-12-06 04:32:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4ad0d8549a1e69b89388e78584a2b7918139fb1c', 'message': ""Fix getting share networks and security services error\n\nIt will fail when non admin users try to get share networks\nand security services with option '{all_tenants: 1}'.\nThe reason is that the policy of 'get_all_share_networks' and\n'get_all_security_services' are admin api, they do not allow\nthe non admin users list the share networks and security services\nwith all_tenants=1. This patch change the policies to default\n(same with cinder) and ignore the value of all_tenants when the\ncontext user is not admin.\n\nChange-Id: Ied021b66333f1254cd232bbc38562a4a9b762ad2\nCloses-Bug: #1721787\n""}, {'number': 8, 'created': '2017-12-06 05:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b81f605d3163c9391ad45e7f13e13a7a38227f2e', 'message': ""Fix getting share networks and security services error\n\nIt will fail when non admin users try to get share networks\nand security services with option '{all_tenants: 1}'.\nThe reason is that the policy of 'get_all_share_networks' and\n'get_all_security_services' are admin api, they do not allow\nthe non admin users list the share networks and security services\nwith all_tenants=1. This patch change the policies to default\n(same with cinder) and ignore the value of all_tenants when the\ncontext user is not admin.\n\nChange-Id: Ied021b66333f1254cd232bbc38562a4a9b762ad2\nCloses-Bug: #1721787\n""}, {'number': 9, 'created': '2017-12-13 10:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2fc3fb36a3b6351d3485cd8479062efe809e92e6', 'message': ""Fix getting share networks and security services error\n\nIt will fail when non-admin tenants try to get share networks\nand security services with option '{all_tenants: 1}'.\nThe reason is that the policy of 'get_all_share_networks' and\n'get_all_security_services' are admin api, they do not allow\nthe non-admin tenants list the share networks and security\nservices with all_tenants=1. This patch removes the policy check\nof non-admin tenants and allows non-admin tenants to request to\nlist with 'all_tenants=1', however 'all_tenants' in the request\nis just ignored.\n\nChange-Id: Ied021b66333f1254cd232bbc38562a4a9b762ad2\nRelated-Bug: #1721787\n""}, {'number': 10, 'created': '2017-12-14 01:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/675294ce2855fce3736a217c47aae6b115b01915', 'message': ""Fix getting share networks and security services error\n\nIt will fail when non-admin tenants try to get share networks\nand security services with option '{all_tenants: 1}'.\nThe reason is that the policy of 'get_all_share_networks' and\n'get_all_security_services' are admin api, they do not allow\nthe non-admin tenants list the share networks and security\nservices with all_tenants=1. This patch removes the policy check\nof non-admin tenants and allows non-admin tenants to request to\nlist with 'all_tenants=1', however 'all_tenants' in the request\nis just ignored.\n\nChange-Id: Ied021b66333f1254cd232bbc38562a4a9b762ad2\nRelated-Bug: #1721787\n""}, {'number': 11, 'created': '2017-12-18 01:17:59.000000000', 'files': ['manila/api/v2/share_networks.py', 'manila_tempest_tests/tests/api/test_share_networks_negative.py', 'manila_tempest_tests/tests/api/test_security_services_negative.py', 'manila_tempest_tests/tests/api/test_security_services.py', 'releasenotes/notes/bug-1721787-fix-getting-share-networks-and-security-services-error-7e5e7981fcbf2b53.yaml', 'manila/api/v1/security_service.py', 'manila/tests/api/v2/test_share_networks.py', 'manila_tempest_tests/tests/api/test_share_networks.py', 'manila/tests/api/v1/test_security_service.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/9f69258cab9baf77384282b67feb390d0487d3b9', 'message': ""Fix getting share networks and security services error\n\nIt will fail when non-admin tenants try to get share networks\nand security services with option '{all_tenants: 1}'.\nThe reason is that the policy of 'get_all_share_networks' and\n'get_all_security_services' are admin api, they do not allow\nthe non-admin tenants list the share networks and security\nservices with all_tenants=1. This patch removes the policy check\nof non-admin tenants and allows non-admin tenants to request to\nlist with 'all_tenants=1', however 'all_tenants' in the request\nis just ignored.\n\nChange-Id: Ied021b66333f1254cd232bbc38562a4a9b762ad2\nCo-Authored-By: Goutham Pacha Ravi <gouthampravi@gmail.com>\nRelated-Bug: #1721787\n""}]",12,522607,9f69258cab9baf77384282b67feb390d0487d3b9,86,17,11,21224,,,0,"Fix getting share networks and security services error

It will fail when non-admin tenants try to get share networks
and security services with option '{all_tenants: 1}'.
The reason is that the policy of 'get_all_share_networks' and
'get_all_security_services' are admin api, they do not allow
the non-admin tenants list the share networks and security
services with all_tenants=1. This patch removes the policy check
of non-admin tenants and allows non-admin tenants to request to
list with 'all_tenants=1', however 'all_tenants' in the request
is just ignored.

Change-Id: Ied021b66333f1254cd232bbc38562a4a9b762ad2
Co-Authored-By: Goutham Pacha Ravi <gouthampravi@gmail.com>
Related-Bug: #1721787
",git fetch https://review.opendev.org/openstack/manila refs/changes/07/522607/8 && git format-patch -1 --stdout FETCH_HEAD,"['etc/manila/policy.json', 'manila/api/v2/share_networks.py', 'manila/tests/policy.json', 'manila/tests/api/v2/test_share_networks.py']",4,c7ed5f69d70c19d06e1352b8d6478b620f98b688,bug/1721787," @mock.patch.object(db_api, 'share_network_get_all_by_project', mock.Mock()) fake_context = req.environ['manila.context'] db_api.share_network_get_all_by_project.return_value = [] self.controller.index(req) db_api.share_network_get_all_by_project.assert_called_with( fake_context, fake_context.project_id) fake_context = req.environ['manila.context'] db_api.share_network_get_all_by_project.return_value = [] self.controller.index(req) db_api.share_network_get_all_by_project.assert_called_with( fake_context, fake_context.project_id)"," @mock.patch.object(db_api, 'share_network_get_all', mock.Mock()) self.assertRaises(exception.PolicyNotAuthorized, self.controller.index, req) self.assertFalse(db_api.share_network_get_all.called) self.assertRaises(exception.PolicyNotAuthorized, self.controller.index, req) self.assertFalse(db_api.share_network_get_all_by_project.called)",16,17
openstack%2Fvitrage~master~I7575d66a16e7cba2758370f66d07557147ad1a62,openstack/vitrage,master,I7575d66a16e7cba2758370f66d07557147ad1a62,fix log exception parameters,MERGED,2017-12-11 09:22:55.000000000,2017-12-18 14:04:59.000000000,2017-12-18 14:04:59.000000000,"[{'_account_id': 3}, {'_account_id': 18783}, {'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 19194}, {'_account_id': 19779}, {'_account_id': 21414}, {'_account_id': 22348}, {'_account_id': 26091}, {'_account_id': 27374}]","[{'number': 1, 'created': '2017-12-11 09:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/0918b7d9000f5436fcad38b2aab70fcea2a1f8d5', 'message': 'fix log exception parameters\n\nChange-Id: I7575d66a16e7cba2758370f66d07557147ad1a62\n'}, {'number': 2, 'created': '2017-12-11 15:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/eb03d2788a8400df18d77c4c66c1c3a13556fcd3', 'message': 'fix log exception parameters\n\nChange-Id: I7575d66a16e7cba2758370f66d07557147ad1a62\n'}, {'number': 3, 'created': '2017-12-12 08:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/1b51dd507f4459e037b1c0398178c8a149f866f9', 'message': 'fix log exception parameters\n\nChange-Id: I7575d66a16e7cba2758370f66d07557147ad1a62\n'}, {'number': 4, 'created': '2017-12-12 13:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/7dc2315e4abf7a968dee0e8b4848bfbf0fe6f9ee', 'message': 'fix log exception parameters\n\nit cannot format the parameters in the old way\n\nChange-Id: I7575d66a16e7cba2758370f66d07557147ad1a62\n'}, {'number': 5, 'created': '2017-12-15 13:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/466b9d658a168d81037dfdc9360759aba5131207', 'message': 'fix log exception parameters\n\nit cannot format the parameters in the old way\n\nDepends-On: I428d04598910edfe67e8b8deb608bcf1233d672d\nChange-Id: I7575d66a16e7cba2758370f66d07557147ad1a62\n'}, {'number': 6, 'created': '2017-12-18 06:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/63b5ad1b5bf243b310ae807db3b7e1daa3a6c74f', 'message': 'fix log exception parameters\n\nChange-Id: I7575d66a16e7cba2758370f66d07557147ad1a62\n'}, {'number': 7, 'created': '2017-12-18 10:09:00.000000000', 'files': ['vitrage/api/controllers/v1/rca.py', 'vitrage/api/controllers/v1/topology.py', 'vitrage/api/controllers/v1/count.py', 'vitrage/api/controllers/v1/alarm.py', 'vitrage/api/controllers/v1/template.py', 'vitrage/api/controllers/v1/event.py', 'vitrage/api/controllers/v1/resource.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/eddcfe8bc93be602cc31a1df6aba4f643683531c', 'message': 'fix log exception parameters\n\nChange-Id: I7575d66a16e7cba2758370f66d07557147ad1a62\n'}]",0,527026,eddcfe8bc93be602cc31a1df6aba4f643683531c,56,11,7,19134,,,0,"fix log exception parameters

Change-Id: I7575d66a16e7cba2758370f66d07557147ad1a62
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/26/527026/4 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/api/controllers/v1/resource.py'],1,0918b7d9000f5436fcad38b2aab70fcea2a1f8d5,eyalb/log," LOG.exception('failed to show resource %s, %s', vitrage_id, e)"," LOG.exception('failed to show resource %s, %s' % vitrage_id, e)",1,1
openstack%2Fcloudkitty~master~I598d0473289e88711ab02a8c4b6aad645ee68ae1,openstack/cloudkitty,master,I598d0473289e88711ab02a8c4b6aad645ee68ae1,Don't run non-voting jobs in gate,MERGED,2017-12-16 21:49:07.000000000,2017-12-18 13:55:40.000000000,2017-12-18 13:55:40.000000000,"[{'_account_id': 7923}, {'_account_id': 9642}, {'_account_id': 22348}, {'_account_id': 23060}, {'_account_id': 26767}]","[{'number': 1, 'created': '2017-12-16 21:49:07.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/51d1dd4635515f26ae83cc93d856d1407e8d6e11', 'message': ""Don't run non-voting jobs in gate\n\nThe gate pipeline should only run voting jobs, non-voting ones get\ncompletely ignored and just waste resources. Remove the non-voting job\nfrom gate pipeline.\n\nChange-Id: I598d0473289e88711ab02a8c4b6aad645ee68ae1\n""}]",0,528505,51d1dd4635515f26ae83cc93d856d1407e8d6e11,9,5,1,6547,,,0,"Don't run non-voting jobs in gate

The gate pipeline should only run voting jobs, non-voting ones get
completely ignored and just waste resources. Remove the non-voting job
from gate pipeline.

Change-Id: I598d0473289e88711ab02a8c4b6aad645ee68ae1
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/05/528505/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,51d1dd4635515f26ae83cc93d856d1407e8d6e11,gate,, gate: jobs: - cloudkitty-tempest-full: voting: false,0,4
openstack%2Ftripleo-heat-templates~master~Ia3f6b62118696792c6581f08f1beb5c75742c66f,openstack/tripleo-heat-templates,master,Ia3f6b62118696792c6581f08f1beb5c75742c66f,Add readme for experimental extraconfig/services,MERGED,2017-12-14 15:56:33.000000000,2017-12-18 13:53:27.000000000,2017-12-18 13:53:27.000000000,"[{'_account_id': 4328}, {'_account_id': 6159}, {'_account_id': 8042}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-14 15:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cde2058eb7a4480f8e296b411e61d9e8a774921e', 'message': ""Add readme for experimental extraconfig/services\n\nThese services only work with the new Ansible deploy workflow, which\nis currently considered experimental because it's yet to be integrated\nwith UI.\n\nChange-Id: Ia3f6b62118696792c6581f08f1beb5c75742c66f\n""}, {'number': 2, 'created': '2017-12-15 15:41:23.000000000', 'files': ['extraconfig/services/README.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/88bbed3d85c7eadcacd995776d327a675587c422', 'message': ""Add readme for experimental extraconfig/services\n\nThese services only work with the new Ansible deploy workflow, which\nis currently considered experimental because it's yet to be integrated\nwith UI.\n\nChange-Id: Ia3f6b62118696792c6581f08f1beb5c75742c66f\n""}]",0,527997,88bbed3d85c7eadcacd995776d327a675587c422,10,4,2,8042,,,0,"Add readme for experimental extraconfig/services

These services only work with the new Ansible deploy workflow, which
is currently considered experimental because it's yet to be integrated
with UI.

Change-Id: Ia3f6b62118696792c6581f08f1beb5c75742c66f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/97/527997/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/services/README.rst'],1,cde2058eb7a4480f8e296b411e61d9e8a774921e,openshift,============================= Externally Installed Services ============================= The services in this directory and the Ansible hook they use (`external_deploy_tasks`) are currently considered experimental. ,,6,0
openstack%2Ftripleo-heat-templates~master~I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b,openstack/tripleo-heat-templates,master,I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b,Deploy OpenShift using OOO on the overcloud,MERGED,2017-08-17 10:25:56.000000000,2017-12-18 13:53:25.000000000,2017-12-18 13:53:25.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6159}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 8871}, {'_account_id': 10873}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-08-17 10:25:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6777114a672b3060058ea3aa2a756a1769cab4b1', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// tripleo-admin user\nDepends-On: I2b67e578c8d718a53cfeeee2b5d391233efae05e\n\n// featureset033\nDepends-On:  I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Infra job (needs merge first)\nInfra-Job -> I72c4e061ec6807883dbf7a187c40263bf7244fab\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 2, 'created': '2017-08-21 09:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2f11e83e0358667bb9f0557b994011640d398087', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// Collect files: REMOVE!\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\n// featureset033\nDepends-On:  I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 3, 'created': '2017-08-21 09:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c4c8b09e5d4e1c5fb68db4ada5eba20e63e49e84', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\n// featureset033\nDepends-On:  I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 4, 'created': '2017-08-21 10:00:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b833a2555e0281c7c73e3b4c77dcf65d149a4b1c', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// featureset033\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 5, 'created': '2017-08-22 08:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2477bb4f833bf1403f7623d0b0004b4d5f0ee38e', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// featureset033\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 6, 'created': '2017-08-22 10:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a3660415e7f018dc6dfdca61bf7952f5e98744bc', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// featureset033\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 7, 'created': '2017-08-22 15:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2fc98c4cafb124153526c270ee62d65dd31ec543', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// featureset033\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 8, 'created': '2017-08-23 07:40:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bf13892ebc085de7fcac8d3c87d5d5b8d7eb663f', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// featureset033\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 9, 'created': '2017-08-23 12:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a746285f122d7c0073fede3ac99aa4bcef1a2ab0', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// featureset033\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 10, 'created': '2017-08-23 14:47:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/84ca033ac2508367c2795956d5a4324afa8cea0b', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// featureset033\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 11, 'created': '2017-08-24 12:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/26bd8bb9702533f336ef4e70c2106e7bd600e180', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// featureset033\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 12, 'created': '2017-08-25 07:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/50183dce825525a0c337b0a4d3a9f3eb476a4d7f', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// featureset033\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 13, 'created': '2017-08-25 09:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/655710e6dd435611ebb5dcbddde57b4d8ec60cdd', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// featureset033\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 14, 'created': '2017-08-25 13:45:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/06fa642dd60c32d7265b3e508ef2540ba7298447', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// featureset033\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 15, 'created': '2017-08-28 07:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bd9eea0f59159afd089a8d4aabb2ada6a14a774f', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// featureset033\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 16, 'created': '2017-08-29 05:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f0162bcdac389e5972ea2afb8bb86c4204d9caa6', 'message': 'WIP: Deploy OpenShift using OOO on the overcloud\n\n// featureset033\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\n\n// Collect files\nDepends-On: I6992310544caa63cec570ec01a980af1c8b312cc\n\n // Tripleo ansible action logs\nDepends-On: I7864e77646a0a594a3f9ca52f12a405a5e7563de\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 17, 'created': '2017-11-17 08:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/75a148dc08d75d8f2f041260e6aa88a1d8cc67fc', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 18, 'created': '2017-11-17 13:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3b4e8d52de2256a70be085c716bee04ca82aaa11', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 19, 'created': '2017-11-21 09:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f5f65b081600bcd7cfc817a015c4cd51e3e457ac', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 20, 'created': '2017-11-21 12:52:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/278a09f481ee8c1cf6456bbb9fada531fbb8ac25', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 21, 'created': '2017-11-21 15:52:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/187892bb2c767b0e6db60180f8eea7224dbd525d', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 22, 'created': '2017-11-21 16:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ca393ba69c7b7aedd8e6fc3e63c284253696f8cb', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 23, 'created': '2017-11-23 17:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/46b089d3dddadc20cd65cbd9a35dfaaf222ea9e7', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 24, 'created': '2017-11-28 08:46:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a42c4089d9d616b7b9800e5c62b506d90f91e4c1', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 25, 'created': '2017-11-29 13:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7c806cf9589ba14713320596166566c984f42b12', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 26, 'created': '2017-12-01 09:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2aaa1d6aec97a570bac24ff39d17b2be8c329eda', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 27, 'created': '2017-12-01 13:12:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4bcf0f5cc96317ae87505c8c26f877cb7798dff4', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 28, 'created': '2017-12-01 13:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0fe937c132e786c9f5f16e74041f115cf456157d', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 29, 'created': '2017-12-01 17:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8d9f6c2ef8427e8cef35a8db209ff206e96162d2', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 30, 'created': '2017-12-06 16:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/61833b540c7beed9f803029b29718281c6c00362', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 31, 'created': '2017-12-07 14:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a3d2cbe0d8d47e7249d71ade1fdf4e6823b9fc7c', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 32, 'created': '2017-12-07 14:43:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8694bd8aeb235b991b37e837c3e71dc88bd321eb', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 33, 'created': '2017-12-07 16:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7ccb4cec609815dba3abc112a14ce6fe7c604747', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nCo-Authored-By: Jiri Stransky <jistr@redhat.com>\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 34, 'created': '2017-12-12 15:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/68452ed67521364837e3c1d6e0e6b484baa4b835', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nCo-Authored-By: Jiri Stransky <jistr@redhat.com>\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 35, 'created': '2017-12-14 10:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/068a0f31b0bfe762163f83bc69013fe82c925007', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 36, 'created': '2017-12-14 13:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/69424e6f86b8953ecfc4e8c955e89a34dde54228', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nCo-Authored-By: Jiri Stransky <jistr@redhat.com>\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}, {'number': 37, 'created': '2017-12-15 15:41:15.000000000', 'files': ['overcloud-resource-registry-puppet.j2.yaml', 'environments/openshift.yaml', 'extraconfig/services/openshift-master.yaml', 'extraconfig/services/openshift-worker.yaml', 'ci/environments/scenario009-multinode.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8dd99ba7fd88cedd562ae5c0219ce0512cff8633', 'message': 'Deploy OpenShift using OOO on the overcloud\n\nAdd external_deploy_tasks for OpenShift installation. This makes\nOpenShift installation work with the config download mechanism.\n\nCo-Authored-By: Jiri Stransky <jistr@redhat.com>\nDepends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275\nChange-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b\n'}]",26,494470,8dd99ba7fd88cedd562ae5c0219ce0512cff8633,226,11,37,6159,,,0,"Deploy OpenShift using OOO on the overcloud

Add external_deploy_tasks for OpenShift installation. This makes
OpenShift installation work with the config download mechanism.

Co-Authored-By: Jiri Stransky <jistr@redhat.com>
Depends-On: I9786f1a27cb7c765211dffe0ea06afd75f8e5275
Change-Id: I4c995dcfd97b5c9ccb751862ff77ab785ad0ac5b
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/70/494470/30 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.j2.yaml', 'environments/openshift.yaml', 'extraconfig/services/openshift-master.yaml', 'extraconfig/services/openshift-worker.yaml', 'ci/environments/scenario009-multinode.yaml']",5,6777114a672b3060058ea3aa2a756a1769cab4b1,openshift,"# NOTE: This is an environment specific for containers CI. Mainly we # deploy non-pacemakerized overcloud. Once we are able to deploy and # upgrade pacemakerized and containerized overcloud, we should remove # this file and use normal CI multinode environments/scenarios. resource_registry: OS::TripleO::Controller::Net::SoftwareConfig: ../common/net-config-multinode.yaml OS::TripleO::Compute::Net::SoftwareConfig: ../common/net-config-multinode.yaml OS::TripleO::Services::SwiftProxy: OS::Heat::None OS::TripleO::Services::SwiftStorage: OS::Heat::None OS::TripleO::Services::SwiftRingBuilder: OS::Heat::None OS::TripleO::Services::Keystone: OS::Heat::None OS::TripleO::Services::GlanceApi: OS::Heat::None OS::TripleO::Services::MySQL: OS::Heat::None OS::TripleO::Services::MySQLClient: OS::Heat::None OS::TripleO::Services::NeutronBgpVpnApi: OS::Heat::None OS::TripleO::Services::NeutronDhcpAgent: OS::Heat::None OS::TripleO::Services::NeutronL3Agent: OS::Heat::None OS::TripleO::Services::NeutronMetadataAgent: OS::Heat::None OS::TripleO::Services::NeutronServer: OS::Heat::None OS::TripleO::Services::NeutronCorePlugin: OS::Heat::None OS::TripleO::Services::NeutronOvsAgent: OS::Heat::None OS::TripleO::Services::RabbitMQ: OS::Heat::None OS::TripleO::Services::HAproxy: OS::Heat::None OS::TripleO::Services::Keepalived: OS::Heat::None OS::TripleO::Services::Memcached: OS::Heat::None OS::TripleO::Services::NovaConductor: OS::Heat::None OS::TripleO::Services::NovaApi: OS::Heat::None OS::TripleO::Services::NovaPlacement: OS::Heat::None OS::TripleO::Services::NovaMetadata: OS::Heat::None OS::TripleO::Services::NovaScheduler: OS::Heat::None OS::TripleO::Services::NovaCompute: OS::Heat::None OS::TripleO::Services::NovaLibvirt: OS::Heat::None OS::TripleO::Services::Docker: ../../puppet/services/docker.yaml parameter_defaults: ControllerServices: - OS::TripleO::Services::Docker - OS::TripleO::Services::Kernel - OS::TripleO::Services::Ntp - OS::TripleO::Services::Snmp - OS::TripleO::Services::Timezone - OS::TripleO::Services::TripleoPackages - OS::TripleO::Services::TripleoFirewall - OS::TripleO::Services::Sshd - OS::TripleO::Services::OpenShift::Master - OS::TripleO::Services::OpenShift::Worker Debug: true ",,225,0
openstack%2Fopenstack-ansible-os_neutron~stable%2Focata~I1cbbb92de83affa0616bbda78e84ad694d2de9a3,openstack/openstack-ansible-os_neutron,stable/ocata,I1cbbb92de83affa0616bbda78e84ad694d2de9a3,Add [designate] section in neutron.conf,ABANDONED,2017-12-18 13:01:35.000000000,2017-12-18 13:42:52.000000000,,[{'_account_id': 6816}],"[{'number': 1, 'created': '2017-12-18 13:01:35.000000000', 'files': ['templates/neutron.conf.j2', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/55728dfe60f63cc9aaa0babb89f6e3f675b10b56', 'message': 'Add [designate] section in neutron.conf\n\nIf neutron_designate_enabled variable is true,\nthis will enable the [designate] section and all needed configuration.\n\nChange-Id: I1cbbb92de83affa0616bbda78e84ad694d2de9a3\nCloses-Bug: 1687594\nDepends-On: I46316c658a3746f91313641e5a26de49a03b2164\n'}]",1,528708,55728dfe60f63cc9aaa0babb89f6e3f675b10b56,3,1,1,26405,,,0,"Add [designate] section in neutron.conf

If neutron_designate_enabled variable is true,
this will enable the [designate] section and all needed configuration.

Change-Id: I1cbbb92de83affa0616bbda78e84ad694d2de9a3
Closes-Bug: 1687594
Depends-On: I46316c658a3746f91313641e5a26de49a03b2164
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/08/528708/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/neutron.conf.j2', 'defaults/main.yml']",2,55728dfe60f63cc9aaa0babb89f6e3f675b10b56,bug/1687594,## Designate integration neutron_designate_enabled: False neutron_allow_reverse_dns_lookup: True neutron_ipv4_ptr_zone_prefix_size: 24 neutron_ipv6_ptr_zone_prefix_size: 116 # Notifications topic for designate neutron_notifications_designate: notifications_designate ,,39,0
openstack%2Ftripleo-common~master~Ia23825aea938f6f9bcf536e35cad562a1b96c93b,openstack/tripleo-common,master,Ia23825aea938f6f9bcf536e35cad562a1b96c93b,Consume NodeDataLookup in ceph-ansible,MERGED,2017-12-06 11:02:26.000000000,2017-12-18 13:36:53.000000000,2017-12-18 13:36:53.000000000,"[{'_account_id': 1}, {'_account_id': 3153}, {'_account_id': 6159}, {'_account_id': 6796}, {'_account_id': 8449}, {'_account_id': 9268}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-06 11:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/475080505e5a66b3b0f52f225de9d2c594cf33c6', 'message': '[WIP] Consume NodeDataLookup in ceph-ansible\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 2, 'created': '2017-12-06 13:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/bf5cd87bbc05fe7588909de55d346e80a25196e9', 'message': '[WIP] Consume NodeDataLookup in ceph-ansible\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 3, 'created': '2017-12-07 12:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4f83014bc984222ec94cd002b69abe73f0331b8d', 'message': 'Consume NodeDataLookup in ceph-ansible\n\nMakes it possible to provide per-node variables to ceph-ansible\nusing the NodeDataLookup parameter, the same consumed by the\n$roleExtraConfigPre resource for puppet hieradata.\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 4, 'created': '2017-12-07 17:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/eb16ac7f84216998e63af306b2bc61f482a77c3e', 'message': 'Consume NodeDataLookup in ceph-ansible\n\nMakes it possible to provide per-node variables to ceph-ansible\nusing the NodeDataLookup parameter, the same consumed by the\n$roleExtraConfigPre resource for puppet hieradata.\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 5, 'created': '2017-12-07 17:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/840fc2a7aa19bf95597b3d6a6f85f8ea70eed92c', 'message': 'Consume NodeDataLookup in ceph-ansible\n\nMakes it possible to provide per-node variables to ceph-ansible\nusing the NodeDataLookup parameter, the same consumed by the\n$roleExtraConfigPre resource for puppet hieradata.\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 6, 'created': '2017-12-07 17:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1c846243f96081100767daa9061c17def2db49c2', 'message': 'Consume NodeDataLookup in ceph-ansible\n\nMakes it possible to provide per-node variables to ceph-ansible\nusing the NodeDataLookup parameter, the same consumed by the\n$roleExtraConfigPre resource for puppet hieradata.\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 7, 'created': '2017-12-07 17:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/34df33acc6789ea917ed2a775bd2697a6222590f', 'message': 'Consume NodeDataLookup in ceph-ansible\n\nMakes it possible to provide per-node variables to ceph-ansible\nusing the NodeDataLookup parameter, the same consumed by the\n$roleExtraConfigPre resource for puppet hieradata.\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 8, 'created': '2017-12-07 20:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/f80327670dcd3b9b19b77b2f46130b78e923261e', 'message': 'Consume NodeDataLookup in ceph-ansible\n\nMakes it possible to provide per-node variables to ceph-ansible\nusing the NodeDataLookup parameter, the same consumed by the\n$roleExtraConfigPre resource for puppet hieradata.\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 9, 'created': '2017-12-07 20:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e1ee1fe90081acfd91eec81860dccb4ec3d6c363', 'message': 'Consume NodeDataLookup in ceph-ansible\n\nMakes it possible to provide per-node variables to ceph-ansible\nusing the NodeDataLookup parameter, the same consumed by the\n$roleExtraConfigPre resource for puppet hieradata.\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 10, 'created': '2017-12-11 19:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/81c298e8ddac5cdecb795eda4c67ea270c6bf9d4', 'message': 'Consume NodeDataLookup in ceph-ansible\n\nMakes it possible to provide per-node variables to ceph-ansible\nusing the NodeDataLookup parameter, the same consumed by the\n$roleExtraConfigPre resource for puppet hieradata.\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 11, 'created': '2017-12-12 10:53:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c7af85973a2cbbacc5a9e3ef78d73176c68ea021', 'message': 'Consume NodeDataLookup in ceph-ansible\n\nMakes it possible to provide per-node variables to ceph-ansible\nusing the NodeDataLookup parameter, the same consumed by the\n$roleExtraConfigPre resource for puppet hieradata.\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 12, 'created': '2017-12-13 11:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/712aae8c69e2d619b64da1c442511bb0b5a92212', 'message': 'Consume NodeDataLookup in ceph-ansible\n\nMakes it possible to provide per-node variables to ceph-ansible\nusing the NodeDataLookup parameter, the same consumed by the\n$roleExtraConfigPre resource for puppet hieradata.\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\n'}, {'number': 13, 'created': '2017-12-14 21:09:09.000000000', 'files': ['workbooks/ceph-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/eda02c05d7b688d3b81321377bf4b32bfa5329bd', 'message': 'Consume NodeDataLookup in ceph-ansible\n\nMakes it possible to provide per-node variables to ceph-ansible\nusing the NodeDataLookup parameter, the same consumed by the\n$roleExtraConfigPre resource for puppet hieradata.\n\nChange-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b\nCloses-Bug: #1736707\nCo-Authored-By: fulton@redhat.com\n'}]",6,526030,eda02c05d7b688d3b81321377bf4b32bfa5329bd,67,10,13,6796,,,0,"Consume NodeDataLookup in ceph-ansible

Makes it possible to provide per-node variables to ceph-ansible
using the NodeDataLookup parameter, the same consumed by the
$roleExtraConfigPre resource for puppet hieradata.

Change-Id: Ia23825aea938f6f9bcf536e35cad562a1b96c93b
Closes-Bug: #1736707
Co-Authored-By: fulton@redhat.com
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/30/526030/6 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/ceph-ansible.yaml'],1,475080505e5a66b3b0f52f225de9d2c594cf33c6,bug/1736707," - node_data_lookup: {} on-success: merge_ip_lists merge_ip_lists: publish: ips_list: $.mon_ips.toSet().union($.mgr_ips.toSet()).union($.osd_ips.toSet()).union($.mds_ips.toSet()).union($.rgw_ips.toSet()).union($.nfs_ips.toSet()).union($.client_ips.toSet()).union($.rbdmirror_ips.toSet()) publish: fork_count: <% min($.ips_list.count(), 100) %> # don't use >100 forks on-success: append_node_data_lookup append_node_data_lookup: action: tripleo.ansible-playbook input: inventory: overcloud: hosts: <% $.ips_list.toDict($, {}) %> remote_user: tripleo-admin become: true become_user: root ssh_private_key: <% $.private_key %> extra_env_variables: ANSIBLE_HOST_KEY_CHECKING: 'False' ANSIBLE_STDOUT_CALLBACK: 'json' playbook: - hosts: overcloud gather_facts: no tasks: - name: collect machine id command: dmidecode -s system-uuid register: machine_id - name: output machine id debug: var: machine_id.stdout_lines publish: output: <% task().result %>"," publish: # unique list of all IPs: make each list a set, take unions and count fork_count: <% min($.mon_ips.toSet().union($.mgr_ips.toSet()).union($.osd_ips.toSet()).union($.mds_ips.toSet()).union($.rgw_ips.toSet()).union($.nfs_ips.toSet()).union($.client_ips.toSet()).union($.rbdmirror_ips.toSet()).count(), 100) %> # don't use >100 forks",33,2
openstack%2Fmonasca-events-api~master~Ic7c344360b5acec5af7751a825e2dff8346cf1f7,openstack/monasca-events-api,master,Ic7c344360b5acec5af7751a825e2dff8346cf1f7,Add events endpoint,MERGED,2017-08-16 14:19:37.000000000,2017-12-18 13:12:33.000000000,2017-12-18 13:12:33.000000000,"[{'_account_id': 3}, {'_account_id': 12542}, {'_account_id': 14123}, {'_account_id': 16168}, {'_account_id': 16222}, {'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2017-08-16 14:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/879e042e92121582604a8c5bf7c47425bc941018', 'message': 'WIP: Add events endpoint\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 2, 'created': '2017-08-17 06:22:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/bd18e559993e9dc5f9ec0418e44c505aa647eafe', 'message': 'WIP: Add events endpoint\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 3, 'created': '2017-08-21 09:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/4ecc3930331b628a27333b220d56a6bf2d294cd2', 'message': 'WIP: Add events endpoint\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 4, 'created': '2017-08-22 10:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/b51e7924db6c4da3a7a4ab25633c3a1964c9fea9', 'message': 'WIP: Add events endpoint\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 5, 'created': '2017-08-24 11:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/0d9cc4687b0cb5ea29f40a83fa371064be04f48f', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 6, 'created': '2017-09-14 12:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/049b97cbe0c158e0abd41d286c093c1a508f68b4', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 7, 'created': '2017-09-18 12:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/513254ebec7123620579a18d439119a2dc1ef86b', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 8, 'created': '2017-09-18 12:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/5c0e47c86b8854f17753328147b007b6b82788a8', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 9, 'created': '2017-09-18 12:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/191093e66961a5c014a06dc209a7147130a8f5ce', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 10, 'created': '2017-09-26 12:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/22376b036006c177d3ce9d5aa1abfeb865135bcc', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 11, 'created': '2017-09-26 12:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/35debb9af23321604fcc823bfd72175582689522', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 12, 'created': '2017-09-26 12:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/cecde836f88aabc8d407d8df2476201e5d464ec2', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 13, 'created': '2017-09-26 13:12:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/23ec7e24380f341885c96187103380ec89dcb965', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 14, 'created': '2017-09-27 11:37:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/d73b13910e0805db1b296b5908ab979ba7699cf2', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 15, 'created': '2017-09-28 10:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/043f3efb1e6fae8ec027928d25f1cb0bbae88db9', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 16, 'created': '2017-09-28 13:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/193e872a6c0f3c3014d0a412aad95e8ad5ed0a87', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 17, 'created': '2017-09-29 12:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/6a8881625629cd7a23d6a5eb71ae0938141ed914', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 18, 'created': '2017-10-03 13:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/a31b494e8285e789d55d66e958d036e526eb3393', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 19, 'created': '2017-10-04 11:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/14acae89279ad56dcae11aacb78b50bbae2f807b', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 20, 'created': '2017-10-04 11:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/63632421a3597fc94e153aba981dadad68956154', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 21, 'created': '2017-10-04 13:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/655e67a20a1818ef8cc176c03f33248dee2bad2a', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 22, 'created': '2017-10-06 12:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/52513786f7b17b3785ca1ece84434ae028acf435', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 23, 'created': '2017-10-06 12:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/a4c2dd3641c20cd24fad08617ee854f888746890', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 24, 'created': '2017-10-06 13:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/7560e2a66dfc0778621004605e078a2805177430', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 25, 'created': '2017-10-10 13:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/114771fa00212c6033f18fef99e3627e4a5b1202', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 26, 'created': '2017-10-10 13:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/556d274f9bd97e21148e91347ff412cecc3033f0', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 27, 'created': '2017-10-11 08:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/908b53df37cb8647d45c5081be45b2fcfbddc323', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 28, 'created': '2017-10-12 11:17:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/fae40abc2a22320253808e943e9978cebb1176f7', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 29, 'created': '2017-10-23 13:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/a7c35558fb2489eaf86d81233aa8c0096270e609', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 30, 'created': '2017-10-24 11:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/51e1c0858548caa851933b7dcae478f3d1d672cc', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 31, 'created': '2017-11-09 09:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/2dc398f3aa975637322e0c7d23020616f2c00213', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 32, 'created': '2017-11-13 12:17:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/a66aa4c2fd830b2f4f41a078a09179dce9ac368f', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 33, 'created': '2017-11-13 13:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/a827521584f8cb78eb20ddf88304be26e10b5119', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 34, 'created': '2017-11-14 14:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/daad77925373918786dd4a1f6c585d9ef267b620', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 35, 'created': '2017-12-18 11:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/aff0ac3b773abb3c02afb5334664b39e2c6a1618', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 36, 'created': '2017-12-18 11:19:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/6a7fde9adcc216859a9903e7e02503bcc8c705ce', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 37, 'created': '2017-12-18 12:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/566d94a5ba6bc371fe3a81a52ef183274695e240', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 38, 'created': '2017-12-18 12:30:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/0d6c98bc77332aa5b644e368ef6e3c799d949fc3', 'message': 'WIP: Add events endpoint\n\nProvide basic endpoint /v1.0/events.\nEndpoint reads request and returns HTTP code 200.\nAdd validation middleware. Middleware is executed before\nauth middleware.\nProvide tests and code to run application in WSGI mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 39, 'created': '2017-12-18 12:34:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/88edf9edba2f05a49dac3f591a835ed2a70e1740', 'message': 'Add events endpoint\n\nProvide basic endpoint: \n/v1.0/events/\n/healthcheck\n/version\nEndpoint reads request and returns HTTP code 200.\n\nProvide code to run application in gunicorn mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}, {'number': 40, 'created': '2017-12-18 12:43:27.000000000', 'files': ['monasca_events_api/app/model/__init__.py', 'test-requirements.txt', 'devstack/settings', 'monasca_events_api/app/common/__init__.py', 'monasca_events_api/app/healthcheck/__init__.py', 'monasca_events_api/tests/unit/test_validation_middleware.py', 'monasca_events_api/tests/unit/test_healthchecks.py', 'monasca_events_api/app/core/error_handlers.py', 'monasca_events_api/app/controller/v1/events.py', 'monasca_events_api/policies/__init__.py', 'monasca_events_api/app/wsgi.py', 'monasca_events_api/tests/unit/event_template_json/req_simple_event.json', 'monasca_events_api/app/healthcheck/kafka_check.py', 'monasca_events_api/config.py', 'monasca_events_api/app/controller/healthchecks.py', 'monasca_events_api/app/common/events_publisher.py', 'monasca_events_api/conf/__init__.py', 'monasca_events_api/app/controller/versions.py', 'monasca_events_api/app/model/envelope.py', 'monasca_events_api/middleware/__init__.py', 'monasca_events_api/policies/agent.py', 'policy-sample.yaml', 'monasca_events_api/app/controller/v1/__init__.py', 'monasca_events_api/tests/unit/test_body_valodiation.py', 'monasca_events_api/tests/unit/base.py', 'setup.cfg', 'tox.ini', 'monasca_events_api/app/controller/api/__init__.py', '.gitignore', 'etc/monasca/events-api-logging.conf', 'devstack/post_test_hook.sh', 'monasca_events_api/app/core/request.py', 'monasca_events_api/conf/events_publisher.py', 'etc/monasca/events-api-paste.ini', 'requirements.txt', 'monasca_events_api/app/api.py', 'monasca_events_api/app/core/model.py', 'monasca_events_api/app/common/helpers.py', 'monasca_events_api/middleware/validation_middleware.py', 'monasca_events_api/tests/unit/test_policy.py', '.stestr.conf', 'monasca_events_api/tests/unit/event_template_json/req_multiple_events.json', 'monasca_events_api/app/core/request_contex.py', 'monasca_events_api/app/controller/v1/bulk_processor.py', 'monasca_events_api/tests/unit/test_events_v1.py', 'monasca_events_api/app/controller/v1/body_validation.py', 'monasca_events_api/tests/unit/test_versions.py', 'monasca_events_api/version.py', 'monasca_events_api/app/controller/__init__.py', 'devstack/lib/events-api.sh'], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/620a477df04928b87a3e99200fd63cc386b4d114', 'message': 'Add events endpoint\n\nProvide basic endpoint:\n/v1.0/events/\n/healthcheck\n/version\nEndpoint reads request and returns HTTP code 200.\nProvide code to run application in gunicorn mode.\n\nStory: 2001112\nTask: 4863\n\nChange-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7\nDepends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298\n'}]",174,494223,620a477df04928b87a3e99200fd63cc386b4d114,89,8,40,20033,,,0,"Add events endpoint

Provide basic endpoint:
/v1.0/events/
/healthcheck
/version
Endpoint reads request and returns HTTP code 200.
Provide code to run application in gunicorn mode.

Story: 2001112
Task: 4863

Change-Id: Ic7c344360b5acec5af7751a825e2dff8346cf1f7
Depends-On: I18d9f4ec543c76bfe1311ed1ee940827d4162298
",git fetch https://review.opendev.org/openstack/monasca-events-api refs/changes/23/494223/40 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_events_api/app/controller/api/__init__.py', 'monasca_events_api/app/wsgi.py', 'monasca_events_api/app/main.py', 'monasca_events_api/app/model/__init__.py', 'monasca_events_api/conf/validation.py', 'etc/monasca/events-api-paste.ini', 'monasca_events_api/app/core/validation.py', 'monasca_events_api/app/model/envelope.py', 'monasca_events_api/app/common/__init__.py', 'monasca_events_api/middleware/__init__.py', 'monasca_events_api/app/controller/api/events_api.py', 'requirements.txt', 'monasca_events_api/app/controller/v1/__init__.py', 'monasca_events_api/app/api.py', 'monasca_events_api/app/core/error_handlers.py', 'monasca_events_api/app/controller/v1/events.py', 'monasca_events_api/app/common/helpers.py', 'monasca_events_api/app/controller/__init__.py', 'monasca_events_api/middleware/validation_middleware.py']",19,879e042e92121582604a8c5bf7c47425bc941018,events_api_endpoint,"# Copyright 2017 FUJITSU LIMITED # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import falcon from oslo_log import log from oslo_middleware import base from monasca_events_api import conf CONF = conf.CONF LOG = log.getLogger(__name__) class ValidationMiddleware(base.ConfigurableMiddleware): """"""Middleware that validates request content. """""" def __init__(self, application, conf=None): super(ValidationMiddleware, self).__init__(application, conf) validation = CONF.validation_middleware self._content_type = validation.supported_content_types self._path = validation.path self._payload_max_size = validation.max_event_size LOG.debug('Initialized ValidationMiddleware') def process_request(self, req): if not self._can_apply_middleware(req): LOG.debug('{0} skipped in validation middleware'.format(req.path)) return None self._validate_content_type(req) self._validate_payload_size(req) return def _validate_content_type(self, req): """"""Validate content type. Method validates request against correct content type. If Content-Type cannot be established (i.e. header is missing), :py:class:`falcon.HTTPMissingHeader` is thrown. If Content-Type is not **application/json** or **test/plain**, :py:class:`falcon.HTTPUnsupportedMediaType` is thrown. :param falcon.Request req: current request :exception: :py:class:`falcon.HTTPMissingHeader` :exception: :py:class:`falcon.HTTPUnsupportedMediaType` """""" content_type = req.content_type LOG.debug('Content-type is {0}'.format(content_type)) if content_type is None or len(content_type) == 0: raise falcon.HTTPMissingHeader('Content-Type') if content_type not in self._content_type: types = ','.join(self._content_type) details = ('Only [{0}] are accepted as events representation'. format(types)) raise falcon.HTTPUnsupportedMediaType(description=details) def _validate_payload_size(self, req): """"""Validate payload size. Method validates sent payload size. It expects that HTTP header **Content-Length** is present. If it does not, method raises :py:class:`falcon.HTTPLengthRequired`. Payload size is being compared with: [validation_middleware] max_event_size = 1048576 If sent payload exceeds maximum allowed content length :py:class:`falcon.HTTPRequestEntityTooLarge` is thrown. :param falcon.Request req: current request :exception: :py:class:`falcon.HTTPLengthRequired` :exception: :py:class:`falcon.HTTPRequestEntityTooLarge` """""" payload_size = req.content_length LOG.debug('Payload (content-length) is {0}'.format(payload_size)) if payload_size is None: raise falcon.HTTPLengthRequired( title='Content length header is missing', description='Content length is required to estimate if' 'payload can be processed' ) if payload_size >= self._payload_max_size: raise falcon.HTTPRequestEntityTooLarge( title='Events payload size exceeded', description='Maximum allowed size id {0:d}'. format(self._payload_max_size) ) def _can_apply_middleware(self, req): """"""Check if middleware should be applied for given path. :param falcon.Request req: current request :return: Returns True if middleware should be applied, otherwise False. """""" path = req.path method = req.method if method == 'OPTIONS': return False if self._path: for p in self._path: if path.startswith(p): return True return False ",,536,1
openstack%2Fwatcher~master~I793131dd8f24f1ac5f5a6a070bb4fe7980c8dfb2,openstack/watcher,master,I793131dd8f24f1ac5f5a6a070bb4fe7980c8dfb2,listen to 'compute.instance.rebuild.end' event,MERGED,2017-09-13 07:40:45.000000000,2017-12-18 13:12:26.000000000,2017-12-18 13:12:26.000000000,"[{'_account_id': 3}, {'_account_id': 13111}, {'_account_id': 19055}, {'_account_id': 21692}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-09-13 07:40:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/97daa4fe38bf044d123c80acf2cb66b4f6b47033', 'message': ""listen to 'compute.instance.rebuild.end' notifications\n\nChange-Id: I793131dd8f24f1ac5f5a6a070bb4fe7980c8dfb2\n""}, {'number': 2, 'created': '2017-09-13 09:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/204f96d03e757e8c509c3b644978d8435a5e9ddd', 'message': ""listen to 'compute.instance.rebuild.end' event\n\nChange-Id: I793131dd8f24f1ac5f5a6a070bb4fe7980c8dfb2\n""}, {'number': 3, 'created': '2017-09-13 09:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/11d84dac18fe37de39df7831459356615e202d16', 'message': ""listen to 'compute.instance.rebuild.end' event\n\nUseful to continuously-optimization,\nbecause such event shows the compute CDM changes.\n\nChange-Id: I793131dd8f24f1ac5f5a6a070bb4fe7980c8dfb2\n""}, {'number': 4, 'created': '2017-09-28 10:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/838c095cd6baa7808ce723d432c61969c62a8ba2', 'message': ""listen to 'compute.instance.rebuild.end' event\n\nUseful to continuously-optimization,\nbecause such event shows the compute CDM changes.\n\nChange-Id: I793131dd8f24f1ac5f5a6a070bb4fe7980c8dfb2\nImplements:blueprint listen-all-necessary-notifications\n""}, {'number': 5, 'created': '2017-10-12 08:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/7880a00741ca5daebc6f4df98fbf65b2d070821d', 'message': ""listen to 'compute.instance.rebuild.end' event\n\nIn one integrated cloud env, there would be many solutions, which would\nmake the compute resource strongly relocated. Watcher should listen to\nall the notifications which represent the compute resource changes, to\nupdate compute CDM. If not, the compute CDM will be stale, Watcher\ncouldn't work steadily and harmoniously.\n\nChange-Id: I793131dd8f24f1ac5f5a6a070bb4fe7980c8dfb2\nImplements:blueprint listen-all-necessary-notifications\n""}, {'number': 6, 'created': '2017-10-23 05:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/4a1111cb0b410101782b66d54d5033cc12da9048', 'message': ""listen to 'compute.instance.rebuild.end' event\n\nIn one integrated cloud env, there would be many solutions, which would\nmake the compute resource strongly relocated. Watcher should listen to\nall the notifications which represent the compute resource changes, to\nupdate compute CDM. If not, the compute CDM will be stale, Watcher\ncouldn't work steadily and harmoniously.\n\nChange-Id: I793131dd8f24f1ac5f5a6a070bb4fe7980c8dfb2\nImplements:blueprint listen-all-necessary-notifications\n""}, {'number': 7, 'created': '2017-11-27 09:10:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6f64df06670fc1919e60e41df1f55b06844b7d07', 'message': ""listen to 'compute.instance.rebuild.end' event\n\nIn one integrated cloud env, there would be many solutions, which would\nmake the compute resource strongly relocated. Watcher should listen to\nall the notifications which represent the compute resource changes, to\nupdate compute CDM. If not, the compute CDM will be stale, Watcher\ncouldn't work steadily and harmoniously.\n\nChange-Id: I793131dd8f24f1ac5f5a6a070bb4fe7980c8dfb2\nImplements:blueprint listen-all-necessary-notifications\n""}, {'number': 8, 'created': '2017-12-08 08:18:39.000000000', 'files': ['watcher/decision_engine/model/notification/nova.py', 'watcher/decision_engine/model/collector/nova.py', 'watcher/tests/decision_engine/model/notification/data/scenario3_legacy_instance-rebuild-end.json', 'watcher/tests/decision_engine/model/notification/test_nova_notifications.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/c38dc9828bb6cc92751325a2909604b8df253288', 'message': ""listen to 'compute.instance.rebuild.end' event\n\nIn one integrated cloud env, there would be many solutions, which would\nmake the compute resource strongly relocated. Watcher should listen to\nall the notifications which represent the compute resource changes, to\nupdate compute CDM. If not, the compute CDM will be stale, Watcher\ncouldn't work steadily and harmoniously.\n\nChange-Id: I793131dd8f24f1ac5f5a6a070bb4fe7980c8dfb2\nImplements:blueprint listen-all-necessary-notifications\n""}]",0,503549,c38dc9828bb6cc92751325a2909604b8df253288,28,5,8,24501,,,0,"listen to 'compute.instance.rebuild.end' event

In one integrated cloud env, there would be many solutions, which would
make the compute resource strongly relocated. Watcher should listen to
all the notifications which represent the compute resource changes, to
update compute CDM. If not, the compute CDM will be stale, Watcher
couldn't work steadily and harmoniously.

Change-Id: I793131dd8f24f1ac5f5a6a070bb4fe7980c8dfb2
Implements:blueprint listen-all-necessary-notifications
",git fetch https://review.opendev.org/openstack/watcher refs/changes/49/503549/4 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/decision_engine/model/notification/nova.py', 'watcher/tests/decision_engine/model/notification/data/scenario3_legacy_instance-rebuild-end.json', 'watcher/tests/decision_engine/model/notification/test_nova_notifications.py']",3,97daa4fe38bf044d123c80acf2cb66b4f6b47033,bp/listen-all-necessary-notifications," def test_legacy_instance_rebuild_end(self): compute_model = self.fake_cdmc.generate_scenario_3_with_2_nodes() self.fake_cdmc.cluster_data_model = compute_model handler = novanotification.LegacyLiveMigratedEnd(self.fake_cdmc) instance0_uuid = '73b09e16-35b7-4922-804e-e8f5d9b740fc' instance0 = compute_model.get_instance_by_uuid(instance0_uuid) node = compute_model.get_node_by_instance_uuid(instance0_uuid) self.assertEqual('Node_0', node.uuid) message = self.load_message( 'scenario3_legacy_instance-rebuild-end.json') handler.info( ctxt=self.context, publisher_id=message['publisher_id'], event_type=message['event_type'], payload=message['payload'], metadata=self.FAKE_METADATA, ) node = compute_model.get_node_by_instance_uuid(instance0_uuid) self.assertEqual('Node_1', node.uuid) self.assertEqual(element.InstanceState.ACTIVE.value, instance0.state)",,110,0
openstack%2Fmonasca-persister~master~I611a22362b2be5a11d2d7cc56be566f978fcacf9,openstack/monasca-persister,master,I611a22362b2be5a11d2d7cc56be566f978fcacf9,Add Cassandra tempest tests,MERGED,2017-12-18 08:59:06.000000000,2017-12-18 13:09:04.000000000,2017-12-18 13:09:04.000000000,"[{'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2017-12-18 08:59:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/d771c0360d89944f3293ec3ba96947bdf7486ea9', 'message': 'Add Cassandra tempest tests\n\nChange-Id: I611a22362b2be5a11d2d7cc56be566f978fcacf9\nStory: 2001231\nTask:  6098\n'}, {'number': 2, 'created': '2017-12-18 09:01:06.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/232e64c54ee5ed9005656771df7ee22d1902358a', 'message': 'Add Cassandra tempest tests\n\nChange-Id: I611a22362b2be5a11d2d7cc56be566f978fcacf9\nStory: 2001231\nTask:  6098\n'}]",0,528661,232e64c54ee5ed9005656771df7ee22d1902358a,9,3,2,16222,,,0,"Add Cassandra tempest tests

Change-Id: I611a22362b2be5a11d2d7cc56be566f978fcacf9
Story: 2001231
Task:  6098
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/61/528661/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,d771c0360d89944f3293ec3ba96947bdf7486ea9,, voting: false - monasca-tempest-python-cassandra voting: false - monasca-tempest-java-cassandra,,4,0
openstack%2Fcookbook-openstack-block-storage~stable%2Focata~I641fa32cac6025e44c1aeedc5f89a12b5efa4e58,openstack/cookbook-openstack-block-storage,stable/ocata,I641fa32cac6025e44c1aeedc5f89a12b5efa4e58,Implemented wsgi support for cinder-api,MERGED,2017-12-14 15:46:50.000000000,2017-12-18 12:49:31.000000000,2017-12-18 12:49:31.000000000,"[{'_account_id': 11915}, {'_account_id': 19193}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-14 15:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/d6eed1842494c18219bf4fceeda3ad9a1791d999', 'message': ""Implemented wsgi support for cinder-api\n\n- Cinder's API service is a WSGI service running behind Apache, which is\n  enabled by default on Ubuntu. Let's get with the times and manage that\n  service.\n\nChange-Id: I641fa32cac6025e44c1aeedc5f89a12b5efa4e58\n""}, {'number': 2, 'created': '2017-12-14 15:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/834a2467209575ec3f5a095fb639b58ccea2152d', 'message': ""Implemented wsgi support for cinder-api\n\n- Cinder's API service is a WSGI service running behind Apache, which is\n  enabled by default on Ubuntu. Let's get with the times and manage that\n  service.\n- version bump to pick up the new change\n\nChange-Id: I641fa32cac6025e44c1aeedc5f89a12b5efa4e58\n""}, {'number': 3, 'created': '2017-12-15 08:25:38.000000000', 'files': ['spec/spec_helper.rb', 'attributes/default.rb', 'recipes/api.rb', 'metadata.rb', 'templates/default/wsgi-template.conf.erb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/88e512ef181a8e18c7ec7e484b3f5f1b85aaa057', 'message': ""Implemented wsgi support for cinder-api\n\n- Cinder's API service is a WSGI service running behind Apache, which is\n  enabled by default on Ubuntu. Let's get with the times and manage that\n  service.\n- version bump to pick up the new change\n\nChange-Id: I641fa32cac6025e44c1aeedc5f89a12b5efa4e58\n""}]",0,527995,88e512ef181a8e18c7ec7e484b3f5f1b85aaa057,10,3,3,14790,,,0,"Implemented wsgi support for cinder-api

- Cinder's API service is a WSGI service running behind Apache, which is
  enabled by default on Ubuntu. Let's get with the times and manage that
  service.
- version bump to pick up the new change

Change-Id: I641fa32cac6025e44c1aeedc5f89a12b5efa4e58
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/95/527995/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/spec_helper.rb', 'attributes/default.rb', 'recipes/api.rb', 'templates/default/wsgi-template.conf.erb']",4,d6eed1842494c18219bf4fceeda3ad9a1791d999,527995,"<%= node[""openstack""][""compute""][""custom_template_banner""] %> Listen <%= @params[:server_host] %>:<%= @params[:server_port] %> <VirtualHost <%= @params[:server_host] %>:<%= @params[:server_port] %>> WSGIDaemonProcess <%= @params[:daemon_process] %> processes=2 threads=10 user=<%= @params[:user] %> group=<%= @params[:group] %> display-name=%{GROUP} WSGIProcessGroup <%= @params[:daemon_process] %> WSGIScriptAlias / <%= @params[:server_entry] %> WSGIApplicationGroup %{GLOBAL} WSGIPassAuthorization On <Directory /usr/bin> Require all granted </Directory> ErrorLogFormat ""%{cu}t %M"" ErrorLog <%= @params[:log_dir] %>/<%= @params[:daemon_process] %>_error.log CustomLog <%= @params[:log_dir] %>/<%= @params[:daemon_process] %>_access.log combined <% if [true, 'true', 'True'].include?(@params[:log_debug]) -%> LogLevel debug <% end -%> <% if @params[:use_ssl] -%> SSLEngine On SSLCertificateFile <%= @params[:cert_file] %> SSLCertificateKeyFile <%= @params[:key_file] %> SSLCACertificatePath <%= @params[:ca_certs_path] %> <% if @params[:chain_file] %> SSLCertificateChainFile <%= @params[:chain_file] %> <% end -%> SSLProtocol <%= @params[:protocol] %> <% if @params[:ciphers] -%> SSLCipherSuite <%= @params[:ciphers] %> <% end -%> <% if @params[:cert_required] -%> SSLVerifyClient require <% end -%> <% end -%> </VirtualHost> WSGISocketPrefix <%= @params[:run_dir] -%> ",,81,5
openstack%2Ftripleo-heat-templates~master~I695b558a9a68dde92557d86967906172815623a5,openstack/tripleo-heat-templates,master,I695b558a9a68dde92557d86967906172815623a5,Cleanup dead code,MERGED,2017-12-13 11:38:27.000000000,2017-12-18 12:46:33.000000000,2017-12-18 12:46:33.000000000,"[{'_account_id': 4328}, {'_account_id': 8449}, {'_account_id': 13039}, {'_account_id': 17280}, {'_account_id': 20866}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23630}]","[{'number': 1, 'created': '2017-12-13 11:38:27.000000000', 'files': ['puppet/services/opendaylight-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e8ab069d1c2cbf4d838c96bb7fdfca69614ac20b', 'message': 'Cleanup dead code\n\nRemove parameter to configure ODL DHCP services as it is recommended\nto not use it and is disabled from ODL side.\n\nChange-Id: I695b558a9a68dde92557d86967906172815623a5\n'}]",2,527674,e8ab069d1c2cbf4d838c96bb7fdfca69614ac20b,12,8,1,20866,,,0,"Cleanup dead code

Remove parameter to configure ODL DHCP services as it is recommended
to not use it and is disabled from ODL side.

Change-Id: I695b558a9a68dde92557d86967906172815623a5
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/74/527674/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/opendaylight-api.yaml'],1,e8ab069d1c2cbf4d838c96bb7fdfca69614ac20b,,, OpenDaylightEnableDHCP: description: Knob to enable/disable ODL DHCP Server type: boolean default: false opendaylight::enable_dhcp: {get_param: OpenDaylightEnableDHCP},0,5
openstack%2Freleases~master~I076de697e1a13bc106b488894b062a58c7c51f7a,openstack/releases,master,I076de697e1a13bc106b488894b062a58c7c51f7a,"Add oslo releases for queens Dec 18, 2017",MERGED,2017-12-18 08:21:46.000000000,2017-12-18 12:45:15.000000000,2017-12-18 12:45:15.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 08:21:46.000000000', 'files': ['deliverables/queens/oslo.privsep.yaml', 'deliverables/queens/taskflow.yaml', 'deliverables/queens/oslo.policy.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/c996cb323aa188f5947f3d13f3e7a88b77043715', 'message': 'Add oslo releases for queens Dec 18, 2017\n\nChange-Id: I076de697e1a13bc106b488894b062a58c7c51f7a\n'}]",0,528651,c996cb323aa188f5947f3d13f3e7a88b77043715,6,2,1,9796,,,0,"Add oslo releases for queens Dec 18, 2017

Change-Id: I076de697e1a13bc106b488894b062a58c7c51f7a
",git fetch https://review.opendev.org/openstack/releases refs/changes/51/528651/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/queens/oslo.privsep.yaml', 'deliverables/queens/taskflow.yaml', 'deliverables/queens/oslo.policy.yaml']",3,c996cb323aa188f5947f3d13f3e7a88b77043715,queens, - projects: - hash: 484bc968a6955c0e8ddf303fe1c4c9623c110c24 repo: openstack/oslo.policy version: 1.32.2,,12,0
openstack%2Freleases~master~Id95f0bba3b51515a88ab01e1e7990bb31edf2f08,openstack/releases,master,Id95f0bba3b51515a88ab01e1e7990bb31edf2f08,Release karbor-dashboard 0.5.0,MERGED,2017-12-15 08:03:20.000000000,2017-12-18 12:45:15.000000000,2017-12-18 12:45:15.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 08:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/985efacfe246aaceddda75bb3133efb8fa0994ed', 'message': 'Release karbor-dashboard 0.5.0\n\nChange-Id: Id95f0bba3b51515a88ab01e1e7990bb31edf2f08\n'}, {'number': 2, 'created': '2017-12-18 03:40:48.000000000', 'files': ['deliverables/queens/karbor-dashboard.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/52335c9ef7d3867b31cbebdcae1a9ae4d70337f3', 'message': 'Release karbor-dashboard 0.5.0\n\nChange-Id: Id95f0bba3b51515a88ab01e1e7990bb31edf2f08\n'}]",0,528194,52335c9ef7d3867b31cbebdcae1a9ae4d70337f3,8,2,2,17151,,,0,"Release karbor-dashboard 0.5.0

Change-Id: Id95f0bba3b51515a88ab01e1e7990bb31edf2f08
",git fetch https://review.opendev.org/openstack/releases refs/changes/94/528194/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/karbor-dashboard.yaml'],1,985efacfe246aaceddda75bb3133efb8fa0994ed,karbor-dashboard,releases: - projects: - hash: 761570ef879603188e546bc324ea883228c31114 repo: openstack/karbor-dashboard version: 0.5.0,,5,0
openstack%2Freleases~master~I19f85b0fa54d766d65fe42d3c373916b293be795,openstack/releases,master,I19f85b0fa54d766d65fe42d3c373916b293be795,release python-zaqarclient 1.8.0,MERGED,2017-12-17 12:58:12.000000000,2017-12-18 12:45:14.000000000,2017-12-18 12:45:14.000000000,"[{'_account_id': 6484}, {'_account_id': 11904}, {'_account_id': 12404}, {'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-17 12:58:12.000000000', 'files': ['deliverables/queens/python-zaqarclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/56bbcbb2207973027f7993afdcde3be034f36beb', 'message': 'release python-zaqarclient 1.8.0\n\nChange-Id: I19f85b0fa54d766d65fe42d3c373916b293be795\n'}]",0,528550,56bbcbb2207973027f7993afdcde3be034f36beb,9,5,1,12404,,,0,"release python-zaqarclient 1.8.0

Change-Id: I19f85b0fa54d766d65fe42d3c373916b293be795
",git fetch https://review.opendev.org/openstack/releases refs/changes/50/528550/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/python-zaqarclient.yaml'],1,56bbcbb2207973027f7993afdcde3be034f36beb,release-python-zaqarclient,releases: - version: 1.8.0 projects: - repo: openstack/python-zaqarclient hash: a2bc819589c4d606e7ded3b500275d0ef9e405ec,,5,0
openstack%2Freleases~master~I1fcdb578168a294dc7aef08bb4048bfaede8c156,openstack/releases,master,I1fcdb578168a294dc7aef08bb4048bfaede8c156,nova: release pike 16.0.4,MERGED,2017-12-12 00:14:05.000000000,2017-12-18 12:45:14.000000000,2017-12-18 12:45:13.000000000,"[{'_account_id': 6873}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 00:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/e750069e09317ee614f493f1d133b9199b08880b', 'message': 'nova: release pike 16.0.4\n\nContains a fix for a new CVE, a fix for an existing CVE errata,\nand a fix for an API regression.\n\nChange-Id: I1fcdb578168a294dc7aef08bb4048bfaede8c156\n'}, {'number': 2, 'created': '2017-12-12 22:38:05.000000000', 'files': ['deliverables/pike/nova.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/1bdda14b660fb1d746a6dbb3ebd61a92f0f935ba', 'message': 'nova: release pike 16.0.4\n\nContains a fix for a new CVE, a fix for an existing CVE errata,\nand a fix for an API regression.\n\nChange-Id: I1fcdb578168a294dc7aef08bb4048bfaede8c156\n'}]",0,527275,1bdda14b660fb1d746a6dbb3ebd61a92f0f935ba,10,3,2,6873,,,0,"nova: release pike 16.0.4

Contains a fix for a new CVE, a fix for an existing CVE errata,
and a fix for an API regression.

Change-Id: I1fcdb578168a294dc7aef08bb4048bfaede8c156
",git fetch https://review.opendev.org/openstack/releases refs/changes/75/527275/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/pike/nova.yaml'],1,e750069e09317ee614f493f1d133b9199b08880b,nova-pike-16.0.4, - version: 16.0.4 projects: - repo: openstack/nova hash: 11e856a53cdfab945947a1b08f9963b600f47b50,,4,0
openstack%2Fopenstack-ansible-os_neutron~stable%2Fpike~I937b74179f448c3f7d5a93098fb4d2440d105550,openstack/openstack-ansible-os_neutron,stable/pike,I937b74179f448c3f7d5a93098fb4d2440d105550,tests: test-neutron-upgrades.sh: Remove the exit trap,MERGED,2017-12-16 13:35:34.000000000,2017-12-18 12:43:32.000000000,2017-12-18 12:43:32.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-16 13:35:34.000000000', 'files': ['tests/test-neutron-upgrades.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/72770c6ccccda47f0c0fa51b367e45dc24ef5d65', 'message': ""tests: test-neutron-upgrades.sh: Remove the exit trap\n\nWe are already collecting logs as part of the post-run playbook so we\ndon't need to do that as part of the exit trap. This avoid collecting\nand compressing the logs twice.\n\nChange-Id: I937b74179f448c3f7d5a93098fb4d2440d105550\n(cherry picked from commit 59eb7ee024693b7a900c828d1ffa551b0cd2181e)\n""}]",0,528475,72770c6ccccda47f0c0fa51b367e45dc24ef5d65,11,4,1,23163,,,0,"tests: test-neutron-upgrades.sh: Remove the exit trap

We are already collecting logs as part of the post-run playbook so we
don't need to do that as part of the exit trap. This avoid collecting
and compressing the logs twice.

Change-Id: I937b74179f448c3f7d5a93098fb4d2440d105550
(cherry picked from commit 59eb7ee024693b7a900c828d1ffa551b0cd2181e)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/75/528475/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test-neutron-upgrades.sh'],1,72770c6ccccda47f0c0fa51b367e45dc24ef5d65,upgrade-not-collect-logs-twice-stable/pike,,"function gate_job_exit_tasks { source ""${COMMON_TESTS_PATH}/test-log-collect.sh"" } # Set gate job exit traps, this is run regardless of exit state when the job finishes. trap gate_job_exit_tasks EXIT ",0,7
openstack%2Ftempest~master~Iad059ce8a97da544948e5383461a4cc480067992,openstack/tempest,master,Iad059ce8a97da544948e5383461a4cc480067992,Remove confusing comment in common/compute.py,MERGED,2017-12-08 06:43:46.000000000,2017-12-18 12:34:40.000000000,2017-12-18 12:34:40.000000000,"[{'_account_id': 1921}, {'_account_id': 5689}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 20190}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-08 06:43:46.000000000', 'files': ['tempest/common/compute.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/544b3c85c1c5ab3f649b6297db17c1bc5b9fe7af', 'message': 'Remove confusing comment in common/compute.py\n\nThis commit removes a confusing comment. This ""l.58"" indicated that\naround line 126 - `if multiple_create_request:` condition, originally.\n(The condition has been modified from the original one, though.) And, we\nshouldn\'t fix it to \'l.126\' because it isn\'t stable.\n\nChange-Id: Iad059ce8a97da544948e5383461a4cc480067992\n'}]",2,526604,544b3c85c1c5ab3f649b6297db17c1bc5b9fe7af,13,7,1,5689,,,0,"Remove confusing comment in common/compute.py

This commit removes a confusing comment. This ""l.58"" indicated that
around line 126 - `if multiple_create_request:` condition, originally.
(The condition has been modified from the original one, though.) And, we
shouldn't fix it to 'l.126' because it isn't stable.

Change-Id: Iad059ce8a97da544948e5383461a4cc480067992
",git fetch https://review.opendev.org/openstack/tempest refs/changes/04/526604/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/compute.py'],1,544b3c85c1c5ab3f649b6297db17c1bc5b9fe7af,fix-wrong-comment, # creation will fail with the condition above., # creation will fail with the condition above (l.58).,1,1
openstack%2Fswift~master~If215446c558b61c1a8aea37ce6be8fcb5a9ea2f4,openstack/swift,master,If215446c558b61c1a8aea37ce6be8fcb5a9ea2f4,Move symlink versioning functional test,MERGED,2017-12-15 12:47:47.000000000,2017-12-18 12:27:41.000000000,2017-12-18 12:27:41.000000000,"[{'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 7847}, {'_account_id': 13052}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 12:47:47.000000000', 'files': ['test/functional/test_symlink.py', 'test/functional/test_versioned_writes.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/1984353f0d6db7512e4ea147ecad9e14dfb318d4', 'message': 'Move symlink versioning functional test\n\nThe functional test for versioning symlinks is better located in\ntest_versioned_writes where it can be added to\nTestObjectVersioning. This saves duplicated versioned_writes specific\nsetup code in test_symlink, and has the benefit of the test being\nrepeated for each of the versioned writes test subclasses.  With a\nsmall refactor this includes the test now running with\nx-history-location mode as well as x-versions-location mode.\n\nRelated-Change: I838ed71bacb3e33916db8dd42c7880d5bb9f8e18\nChange-Id: If215446c558b61c1a8aea37ce6be8fcb5a9ea2f4\n'}]",0,528253,1984353f0d6db7512e4ea147ecad9e14dfb318d4,12,5,1,7847,,,0,"Move symlink versioning functional test

The functional test for versioning symlinks is better located in
test_versioned_writes where it can be added to
TestObjectVersioning. This saves duplicated versioned_writes specific
setup code in test_symlink, and has the benefit of the test being
repeated for each of the versioned writes test subclasses.  With a
small refactor this includes the test now running with
x-history-location mode as well as x-versions-location mode.

Related-Change: I838ed71bacb3e33916db8dd42c7880d5bb9f8e18
Change-Id: If215446c558b61c1a8aea37ce6be8fcb5a9ea2f4
",git fetch https://review.opendev.org/openstack/swift refs/changes/53/528253/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/functional/test_symlink.py', 'test/functional/test_versioned_writes.py']",2,1984353f0d6db7512e4ea147ecad9e14dfb318d4,p-symlink-versioning-test," from swift.common.utils import MD5_OF_EMPTY_STRING # in history mode, cleanup after deleting 'container' files self.env.versions_container.delete_files() def _check_overwriting_symlink(self): # assertions common to x-versions-location and x-history-location modes container = self.env.container versions_container = self.env.versions_container tgt_a_name = Utils.create_name() tgt_b_name = Utils.create_name() tgt_a = container.file(tgt_a_name) tgt_a.write(""aaaaa"") tgt_b = container.file(tgt_b_name) tgt_b.write(""bbbbb"") symlink_name = Utils.create_name() sym_tgt_header = '%s/%s' % (container.name, tgt_a_name) sym_headers_a = {'X-Symlink-Target': sym_tgt_header} symlink = container.file(symlink_name) symlink.write("""", hdrs=sym_headers_a) self.assertEqual(""aaaaa"", symlink.read()) sym_headers_b = {'X-Symlink-Target': '%s/%s' % (container.name, tgt_b_name)} symlink.write("""", hdrs=sym_headers_b) self.assertEqual(""bbbbb"", symlink.read()) # the old version got saved off self.assertEqual(1, versions_container.info()['object_count']) versioned_obj_name = versions_container.files()[0] prev_version = versions_container.file(versioned_obj_name) prev_version_info = prev_version.info(parms={'symlink': 'get'}) self.assertEqual(""aaaaa"", prev_version.read()) self.assertEqual(MD5_OF_EMPTY_STRING, prev_version_info['etag']) self.assertEqual(sym_tgt_header, prev_version_info['x_symlink_target']) return symlink, tgt_a def test_overwriting_symlink(self): symlink, target = self._check_overwriting_symlink() # test delete symlink.delete() sym_info = symlink.info(parms={'symlink': 'get'}) self.assertEqual(""aaaaa"", symlink.read()) self.assertEqual(MD5_OF_EMPTY_STRING, sym_info['etag']) self.assertEqual('%s/%s' % (self.env.container.name, target.name), sym_info['x_symlink_target']) def test_overwriting_symlink(self): symlink, target = self._check_overwriting_symlink() # test delete symlink.delete() with self.assertRaises(ResponseError) as cm: symlink.read() self.assertEqual(404, cm.exception.status) ",,59,72
openstack%2Foctavia-tempest-plugin~master~Icca0c79a8c3670d72a44c40f63b30bf54954c4ae,openstack/octavia-tempest-plugin,master,Icca0c79a8c3670d72a44c40f63b30bf54954c4ae,Adding test_load_balancer_basic test.,ABANDONED,2017-10-17 09:16:56.000000000,2017-12-18 12:22:28.000000000,,"[{'_account_id': 6579}, {'_account_id': 10273}, {'_account_id': 18746}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-17 09:16:56.000000000', 'files': ['octavia_tempest_plugin/tests/scenario/test_load_balancer_basic.py'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/31166cbe7432421b9068f592141c5cc12175f77c', 'message': 'Adding test_load_balancer_basic test.\n\nAdjustment of neutron lbaas scenraio tests for Octavia.\n\nChange-Id: Icca0c79a8c3670d72a44c40f63b30bf54954c4ae\n'}]",1,512556,31166cbe7432421b9068f592141c5cc12175f77c,6,4,1,18746,,,0,"Adding test_load_balancer_basic test.

Adjustment of neutron lbaas scenraio tests for Octavia.

Change-Id: Icca0c79a8c3670d72a44c40f63b30bf54954c4ae
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/56/512556/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia_tempest_plugin/tests/scenario/test_load_balancer_basic.py'],1,31166cbe7432421b9068f592141c5cc12175f77c,new_octavia_test,"# Copyright 2015 Rackspace Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest import test from octavia.octavia.tests.tempest.v2.scenario import base class TestLoadBalancerBasic(base.BaseTestCase): @test.services('compute', 'network') def test_loadbalancer_basic(self): """"""This test checks basic load balancing. The following is the scenario outline: 1. Create an instance. 2. SSH to the instance and start two servers. 3. Create a load balancer with two members and with ROUND_ROBIN algorithm. 4. Associate the VIP with a floating ip. 5. Send NUM requests to the floating ip and check that they are shared between the two servers. dut - device under test. """""" import ipdb;ipdb.set_trace() server = self._create_server('http_server') self._start_backend_httpd_processes(server) dut_id = self._create_load_balancer() self._create_listener(tested_lb) pool_id = self._create_pool(dut_id)['id'] self._create_members(dut_id, pool_id, server) self._check_members_balanced() ",,45,0
openstack%2Frally~master~I701e7f784a62f6b9c745bc47eb2e4ea299ccddcb,openstack/rally,master,I701e7f784a62f6b9c745bc47eb2e4ea299ccddcb,Add live_migrate as bind action for boot-and-bounce,NEW,2015-03-09 16:26:41.000000000,2017-12-18 12:20:27.000000000,,"[{'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-03-09 16:26:41.000000000', 'files': ['rally/benchmark/scenarios/nova/servers.py', 'samples/tasks/scenarios/nova/boot-bounce-delete.yaml', 'samples/tasks/scenarios/nova/boot-bounce-delete.json'], 'web_link': 'https://opendev.org/openstack/rally/commit/c252fd7dd950514436f2ed06a03f837978b92b42', 'message': ""Add live_migrate as bind action for boot-and-bounce\n\n* The goal is to be able to perform multiple migration\n  of a single instance\n* boot-bounce scenario does not require admin privileges\n  but _live_migration does require so this change would\n  narrow the use of the scenario - That's why this review\n  is used as place holder for discussion about possible\n  solutions.\n\nChange-Id: I701e7f784a62f6b9c745bc47eb2e4ea299ccddcb\n""}]",0,162674,c252fd7dd950514436f2ed06a03f837978b92b42,10,4,1,15206,,,0,"Add live_migrate as bind action for boot-and-bounce

* The goal is to be able to perform multiple migration
  of a single instance
* boot-bounce scenario does not require admin privileges
  but _live_migration does require so this change would
  narrow the use of the scenario - That's why this review
  is used as place holder for discussion about possible
  solutions.

Change-Id: I701e7f784a62f6b9c745bc47eb2e4ea299ccddcb
",git fetch https://review.opendev.org/openstack/rally refs/changes/74/162674/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/nova/servers.py', 'samples/tasks/scenarios/nova/boot-bounce-delete.yaml', 'samples/tasks/scenarios/nova/boot-bounce-delete.json']",3,c252fd7dd950514436f2ed06a03f837978b92b42,multiplemig," {""rescue_unrescue"": 1}, {""live_migrate"": 2}"," {""rescue_unrescue"": 1}",22,3
openstack%2Fswift~master~I92ddbcce949c46dc71b427bf30414538d1e10297,openstack/swift,master,I92ddbcce949c46dc71b427bf30414538d1e10297,Updates the prehistoric multi-node install guide.,NEW,2014-06-03 10:07:45.000000000,2017-12-18 12:17:23.000000000,,"[{'_account_id': 2622}, {'_account_id': 5600}]","[{'number': 1, 'created': '2014-06-03 10:07:45.000000000', 'files': ['doc/source/howto_installmultinode.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/c758a19091635ac59365882b0e0ba972b28da01b', 'message': 'Updates the prehistoric multi-node install guide.\n\n(Note: this is still a WIP. This line will be removed from\n this commit message once things are tightened up a bit more.)\n\nChange-Id: I92ddbcce949c46dc71b427bf30414538d1e10297\n'}]",0,97445,c758a19091635ac59365882b0e0ba972b28da01b,10,2,1,5600,,,0,"Updates the prehistoric multi-node install guide.

(Note: this is still a WIP. This line will be removed from
 this commit message once things are tightened up a bit more.)

Change-Id: I92ddbcce949c46dc71b427bf30414538d1e10297
",git fetch https://review.opendev.org/openstack/swift refs/changes/45/97445/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/howto_installmultinode.rst'],1,c758a19091635ac59365882b0e0ba972b28da01b,prehistoric-archaeological-dig,"========================================================= Instructions for a Multi-Node Swift Installation (Ubuntu) ========================================================= * Ubuntu Server 12.04 LTS or 14.04 LTS .. note:: Swift can run with other Linux distributions, but for this document we will focus on installing on Ubuntu Server. If you follow along in another distribution, the requisite package names and versions may vary. - One Proxy node- Five Storage nodesthat is as isolated as possible from other nodes (separate servers, network equipment, power sources, or even geography). The ring guarantees that every replica is storedTo increase reliability, you may want to add additional Proxy servers for performance, as described in :ref:`add-proxy-server`. This document refers to two networks. The first is an external network where clients connect and issue requests to the Proxy server, and the second is a storage network that is not accessibile from outside the cluster, to which all of the nodes are connected. All of the Swift services, as well as the rsync daemon on the Storage nodes, are configured to listen on their storage network IP addresses. Run all commands in this guide as the root user. General OS configuration and drive partitioning for each node ------------------------------------------------------------- #. Install Ubuntu Server 12.04 LTS or 14.04 LTS on all nodes. A minimal installation is recommended. #. Install common packages, Swift, and the Swift client:: apt-get install curl openssh-server apt-get install swift python-swiftclient chown -R swift:swift /etc/swift # Unique hashes used for data placement that can never change (DO NOT LOSE) swift_hash_path_prefix = $(od -t x8 -N 8 -A n </dev/urandom) swift_hash_path_suffix = $(od -t x8 -N 8 -A n </dev/urandom) .. note:: The random strings of text in /etc/swift/swift.conf are used as a salt when hashing objects in order to determine where data is placed in the ring. #. Copy the swift.conf file to all other nodes in the cluster. It MUST be the same on every node in the cluster!:: scp /etc/swift/swift.conf node2.example.com:/etc/swift/swift.conf #. Export the local network IP addresses for use by scripts found later in this documentation:: export PROXY_LOCAL_NET_IP=10.1.2.10 export STORAGE1_LOCAL_NET_IP=10.1.2.20 export STORAGE2_LOCAL_NET_IP=10.1.2.21 the directory will be removed when the system shuts down or reboots. As a result, it is necessary to recreate this directory with the proper ownership when the system is restarted, so add the following lines to /etc/rc.local before line ""exit 0"".:: nodes (account, container or object server). The ownership of /srv/node should be root:root to ensure that the objects for swift will not be created in the directory /srv/node when storage disks are unmounted unexpectedly. You may skip this step for Proxy nodes.::#. Install the swift-proxy service::#. Create a self-signed certificate for SSL:: If you don't create the cert files, Swift silently uses http internally rather than https. This document assumes that you have created these certs, so if you're following along step-by-step, create them. In a production cluster, you should terminate SSL in front of your proxy server(s). SSL support is provided directly within Swift for testing purposes only. sed -e ""s/-l 127.0.0.1/-l $PROXY_LOCAL_NET_IP/"" -i /etc/memcached.conf pipeline = catch_errors gatekeeper healthcheck proxy-logging cache container_sync bulk tempurl slo dlo ratelimit formpost tempauth staticweb container-quotas account-quotas proxy-logging proxy-server [filter:bulk] use = egg:swift#bulk [filter:ratelimit] use = egg:swift#ratelimit [filter:formpost] use = egg:swift#formpost [filter:catch_errors] use = egg:swift#catch_errors [filter:staticweb] use = egg:swift#staticweb [filter:tempurl] use = egg:swift#tempurl [filter:container-quotas] use = egg:swift#container_quotas [filter:slo] use = egg:swift#slo [filter:dlo] use = egg:swift#dlo [filter:account-quotas] use = egg:swift#account_quotas [filter:gatekeeper] use = egg:swift#gatekeeper [filter:container_sync] use = egg:swift#container_sync `10.1.2.10:11211,10.1.2.11:11211`. Only the proxy server uses memcache. cd /etc/swift swift-ring-builder account.builder create 18 3 1 swift-ring-builder container.builder create 18 3 1 swift-ring-builder object.builder create 18 3 1 export REGION= # set the region number for this group of nodes export ZONE= # set the zone number for that storage device export STORAGE_LOCAL_NET_IP= # and the IP address export WEIGHT=100 # relative weight (higher for bigger/faster disks) export DEVICE=sdb1 swift-ring-builder account.builder add r${REGION}z${ZONE}-${STORAGE1_LOCAL_NET_IP}:6002/${DEVICE} ${WEIGHT} swift-ring-builder container.builder add r${REGION}z${ZONE}-${STORAGE1_LOCAL_NET_IP}:6001/${DEVICE} ${WEIGHT} swift-ring-builder object.builder add r${REGION}z${ZONE}-${STORAGE1_LOCAL_NET_IP}:6000/${DEVICE} ${WEIGHT} 1 and increment by one for each additional storage node. swift-ring-builder account.builder swift-ring-builder container.builder swift-ring-builder object.builder swift-ring-builder account.builder rebalance swift-ring-builder container.builder rebalance swift-ring-builder object.builder rebalance Rebalancing rings can take some time...enough time to go grab a lemon drink. scp /etc/swift/*.ring.gz node2.example.com:/etc/swift/ Extended Attributes (xattrs). We currently recommend XFS as has demonstrated the best overall performance for the Swift use case after considerable testing and benchmarking. It is also the only filesystem that has been thoroughly vetted. These instructions assume that you are going to devote /dev/sdb1 to an XFS filesystem.#. For every device on the node, create an XFS partition (/dev/sdb is used as an example), and determine its UUID and add it to fstab for automatic mounting on boot. Then, create its mount point and mount the disk there, so you can give Swift permissions to use the disk. echo ""UUID=$(blkid -s UUID -o value /dev/sdb1) /srv/node/sdb1 xfs noatime,nodiratime,nobarrier,logbufs=8 0 0"" >> /etc/fstab .. note:: Generally it is not recommended to add partitions to fstab based on the device name (i.e., /dev/sdb1), since device names can change after failures and replacement. .. note:: Add mount option ""inode64"" to the above fstab mount options to yield better performance on any disks with a capacity of 1TB or more. address = $STORAGE1_LOCAL_NET_IP#. Update the RSYNC_ENABLE line in /etc/default/rsync:: sed -e 's/RSYNC_ENABLE=false/RSYNC_ENABLE=true/' -i /etc/default/rsync The rsync daemon requires no authentication, so you should ensure it only listens and runs on bind_ip = $STORAGE1_LOCAL_NET_IP bind_ip = $STORAGE1_LOCAL_NET_IP bind_ip = $STORAGE1_LOCAL_NET_IP swift-init all start Note that if any service in question generates any output on its to /dev/null. If you encounter any problems, stop the server and run it swift-init object-server start swift-init object-replicator start swift-init object-updater start swift-init object-auditor start swift-init container-server start swift-init container-replicator start swift-init container-updater start swift-init container-auditor start swift-init account-server start swift-init account-replicator start swift-init account-auditor start swift --insecure -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass stat swift --insecure -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass upload myfiles bigfile1.tgz swift --insecure -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass upload myfiles bigfile2.tgz swift --insecure -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass download myfiles swift --insecure -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass upload builders /etc/swift/*.builder swift --insecure -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass list swift --insecure -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass list builders swift --insecure -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass download builders Once you have more than two proxies, you also want to load balance between the two, which means your storage endpoint also changes. You can select from different strategies for load balancing. For example, you could use round robin dns, or an actual load balancer (like haproxy or pound) in front of the two proxies, and point your storage endpoint to the load balancer.#. Update the list of memcache servers in /etc/swift/proxy-server.conf for all the added proxy servers. If you run multiple memcache servers, use this pattern for the multiple IP:port listings: `10.1.2.10:11211,10.1.2.11:11211` in each proxy server's conf file.:: Final Steps ----------- #. Copy all the ring information to all proxy and storage nodes (including any new proxy nodes). #. Make sure the admin has the keys in /etc/swift and the ownership for the ring file is correct. If you see problems, look in /var/log/syslog (or /var/log/messages on some Linux distributions). You may also look for hints at drive failures by checking for error messages in /var/log/kern.log. More debugging hints and tips are available in the :doc:`admin_guide`.","============================================================== Instructions for a Multiple Server Swift Installation (Ubuntu) ==============================================================* Ubuntu Server 10.04 LTS installation media .. note: Swift can run with other distros, but for this document we will focus on installing on Ubuntu Server, ypmv (your packaging may vary).- one Proxy node- five Storage nodesthat is as isolated as possible from other nodes (separate servers, network, power, even geography). The ring guarantees that every replica is storedTo increase reliability, you may want to add additional Proxy servers for performance which is described in :ref:`add-proxy-server`.This document refers to two networks. An external network for connecting to the Proxy server, and a storage network that is not accessibile from outside the cluster, to which all of the nodes are connected. All of the Swift services, as well as the rsync daemon on the Storage nodes are configured to listen on their STORAGE_LOCAL_NET IP addresses. Run all commands as the root user General OS configuration and partitioning for each node ------------------------------------------------------- #. Install the baseline Ubuntu Server 10.04 LTS on all nodes. #. Install common Swift software prereqs:: apt-get install python-software-properties add-apt-repository ppa:swift-core/release apt-get update apt-get install swift python-swiftclient openssh-server chown -R swift:swift /etc/swift/ # random unique strings that can never change (DO NOT LOSE) swift_hash_path_prefix = `od -t x8 -N 8 -A n </dev/random` swift_hash_path_suffix = `od -t x8 -N 8 -A n </dev/random`#. On the second and subsequent nodes: Copy that file over. It must be the same on every node in the cluster!:: scp firstnode.example.com:/etc/swift/swift.conf /etc/swift/ #. Publish the local network IP address for use by scripts found later in this documentation:: export STORAGE_LOCAL_NET_IP=10.1.2.3 export PROXY_LOCAL_NET_IP=10.1.2.4 when system shuts down, the directory will be gone. It is necessary to have the directory recreated when system is restarted. To do that, also add the following lines into /etc/rc.local before line ""exit 0"".:: node (account, container or object server). The ownership of /srv/node should be root:root, this is to ensure that when storage disks unmounted unexpectedly, the objects for swift will not be created in the directory /srv/node. If you have a node only runs proxy server, you can skip this step.::.. note:: The random string of text in /etc/swift/swift.conf is used as a salt when hashing to determine mappings in the ring... note:: It is assumed that all commands are run as the root user #. Install swift-proxy service::#. Create self-signed cert for SSL:: If you don't create the cert files, Swift silently uses http internally rather than https. This document assumes that you have created these certs, so if you're following along step-by-step, create them. In a production cluster, you should terminate SSL before the proxy server. SSL support is provided for testing purposes only. perl -pi -e ""s/-l 127.0.0.1/-l $PROXY_LOCAL_NET_IP/"" /etc/memcached.conf pipeline = healthcheck proxy-logging cache tempauth proxy-logging proxy-server `10.1.2.3:11211,10.1.2.4:11211`. Only the proxy server uses memcache. cd /etc/swift swift-ring-builder account.builder create 18 3 1 swift-ring-builder container.builder create 18 3 1 swift-ring-builder object.builder create 18 3 1 export ZONE= # set the zone number for that storage device export STORAGE_LOCAL_NET_IP= # and the IP address export WEIGHT=100 # relative weight (higher for bigger/faster disks) export DEVICE=sdb1 swift-ring-builder account.builder add z$ZONE-$STORAGE_LOCAL_NET_IP:6002/$DEVICE $WEIGHT swift-ring-builder container.builder add z$ZONE-$STORAGE_LOCAL_NET_IP:6001/$DEVICE $WEIGHT swift-ring-builder object.builder add z$ZONE-$STORAGE_LOCAL_NET_IP:6000/$DEVICE $WEIGHT 1 and increment by one for each additional node. swift-ring-builder account.builder swift-ring-builder container.builder swift-ring-builder object.builder swift-ring-builder account.builder rebalance swift-ring-builder container.builder rebalance swift-ring-builder object.builder rebalance Rebalancing rings can take some time. Extended Attributes (XATTRS). We currently recommend XFS as it demonstrated the best overall performance for the swift use case after considerable testing and benchmarking at Rackspace. It is also the only filesystem that has been thoroughly tested. These instructions assume that you are going to devote /dev/sdb1 to an XFS filesystem.#. For every device on the node, setup the XFS volume (/dev/sdb is used as an example), add mounting option inode64 when your disk is bigger than 1TB to archive a better performance.:: fdisk /dev/sdb (set up a single partition) echo ""/dev/sdb1 /srv/node/sdb1 xfs noatime,nodiratime,nobarrier,logbufs=8 0 0"" >> /etc/fstab address = $STORAGE_LOCAL_NET_IP#. Edit the RSYNC_ENABLE= line in /etc/default/rsync:: perl -pi -e 's/RSYNC_ENABLE=false/RSYNC_ENABLE=true/' /etc/default/rsync The rsync daemon requires no authentication, so it should be run on bind_ip = $STORAGE_LOCAL_NET_IP bind_ip = $STORAGE_LOCAL_NET_IP bind_ip = $STORAGE_LOCAL_NET_IP swift-init all start Note that if the server program in question generates any output on its to /dev/null. If you encounter any difficulty, stop the server and run it swift-init object-server start swift-init object-replicator start swift-init object-updater start swift-init object-auditor start swift-init container-server start swift-init container-replicator start swift-init container-updater start swift-init container-auditor start swift-init account-server start swift-init account-replicator start swift-init account-auditor start swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass stat swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass upload myfiles bigfile1.tgz swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass upload myfiles bigfile2.tgz swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass download myfiles swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass upload builders /etc/swift/*.builder swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass list swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass list builders swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass download buildersOnce you have more than two proxies, you also want to load balance between the two, which means your storage endpoint also changes. You can select from different strategies for load balancing. For example, you could use round robin dns, or an actual load balancer (like pound) in front of the two proxies, and point your storage url to the load balancer.#. Update the list of memcache servers in /etc/swift/proxy-server.conf for all the added proxy servers. If you run multiple memcache servers, use this pattern for the multiple IP:port listings: `10.1.2.3:11211,10.1.2.4:11211` in each proxy server's conf file.::#. Next, copy all the ring information to all the nodes, including your new proxy nodes, and ensure the ring info gets to all the storage nodes as well. #. After you sync all the nodes, make sure the admin has the keys in /etc/swift and the ownership for the ring file is correct.If you see problems, look in var/log/syslog (or messages on some distros). Also, at Rackspace we have seen hints at drive failures by looking at error messages in /var/log/kern.log. There are more debugging hints and tips in the :doc:`admin_guide`.",176,118
openstack%2Fswift~master~I305453f5a67849b24fa3db9f5d7612499fb1c733,openstack/swift,master,I305453f5a67849b24fa3db9f5d7612499fb1c733,Verifies overall metadata on account/container.,NEW,2014-09-12 12:32:46.000000000,2017-12-18 12:17:15.000000000,,"[{'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 10068}, {'_account_id': 12270}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-09-12 12:32:46.000000000', 'files': ['swift/proxy/controllers/account.py', 'swift/common/constraints.py', 'swift/proxy/controllers/container.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/2cd8d91f9d68b566a46b7210eb0b35115098fbfe', 'message': 'Verifies overall metadata on account/container.\n\nThis patch checks overall metadata on\naccount/container. Earlier only the\nmetadata in the individual request\nwere checked and as a result one can store\nmore than specific limit of metadata on\naccount/container. Now the overall\nmetadata will be checked to verify the\ndefined limit.\n\nChange-Id: I305453f5a67849b24fa3db9f5d7612499fb1c733\nCloses-Bug: 1365350\n'}]",2,121073,2cd8d91f9d68b566a46b7210eb0b35115098fbfe,9,5,1,12270,,,0,"Verifies overall metadata on account/container.

This patch checks overall metadata on
account/container. Earlier only the
metadata in the individual request
were checked and as a result one can store
more than specific limit of metadata on
account/container. Now the overall
metadata will be checked to verify the
defined limit.

Change-Id: I305453f5a67849b24fa3db9f5d7612499fb1c733
Closes-Bug: 1365350
",git fetch https://review.opendev.org/openstack/swift refs/changes/73/121073/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/proxy/controllers/account.py', 'swift/common/constraints.py', 'swift/proxy/controllers/container.py']",3,2cd8d91f9d68b566a46b7210eb0b35115098fbfe,bug/1365350,"from swift.common.constraints import check_metadata, check_overall_metadata req, self.app.container_ring, container_partition, 'HEAD', req.swift_entity_path, [headers] * len(containers)) if not is_success(resp.status_int): return resp error_response = check_overall_metadata(req, resp.headers, 'container') if error_response: return error_response clear_info_cache(self.app, req.environ, self.account_name, self.container_name) resp = self.make_requests(",from swift.common.constraints import check_metadata,61,3
openstack%2Fbashate~master~Id04a84ce48546f071a26caf2a5274c4ea1904490,openstack/bashate,master,Id04a84ce48546f071a26caf2a5274c4ea1904490,Add ability to ignore in-file,NEW,2014-10-21 00:18:41.000000000,2017-12-18 12:17:10.000000000,,[{'_account_id': 8895}],"[{'number': 1, 'created': '2014-10-21 00:18:41.000000000', 'files': ['bashate/tests/samples/inline_ignore.sh', 'bashate/bashate.py', 'README.rst', 'doc/source/conf.py', 'doc/source/man/bashate.rst', 'bashate/tests/test_bashate.py'], 'web_link': 'https://opendev.org/openstack/bashate/commit/8917d65e1b57581fb9edc45002ff7490c37b992e', 'message': 'Add ability to ignore in-file\n\nWhile looking at Idd856e897ff97095fb116294a9187ff4b198fa26 I realised\nthat our checking is picking up on embedded awk programs.\n\nFor something like this, I think we should be able to skip individual\ntests just for a single file.\n\nTo achieve this, we keep a list of tests to ignore from the command\nline, and append any tests we see from a special comment line as\ndescribed in the documentation.\n\nOne change is making it explicit that tests to ignore should be\nseparated by commas.  We don\'t want to mix ""|"" matching in there, as\nthat is exposing the implementation details of the regex-search.\nDocumentation is updated to make this clear, and test-cases modified.\n\nThis also includes a man page for bashate.1 which also describes these\nusage details, and links this from the readme.\n\nChange-Id: Id04a84ce48546f071a26caf2a5274c4ea1904490\n'}]",5,129761,8917d65e1b57581fb9edc45002ff7490c37b992e,4,1,1,7118,,,0,"Add ability to ignore in-file

While looking at Idd856e897ff97095fb116294a9187ff4b198fa26 I realised
that our checking is picking up on embedded awk programs.

For something like this, I think we should be able to skip individual
tests just for a single file.

To achieve this, we keep a list of tests to ignore from the command
line, and append any tests we see from a special comment line as
described in the documentation.

One change is making it explicit that tests to ignore should be
separated by commas.  We don't want to mix ""|"" matching in there, as
that is exposing the implementation details of the regex-search.
Documentation is updated to make this clear, and test-cases modified.

This also includes a man page for bashate.1 which also describes these
usage details, and links this from the readme.

Change-Id: Id04a84ce48546f071a26caf2a5274c4ea1904490
",git fetch https://review.opendev.org/openstack/bashate refs/changes/61/129761/1 && git format-patch -1 --stdout FETCH_HEAD,"['bashate/tests/samples/inline_ignore.sh', 'bashate/bashate.py', 'README.rst', 'doc/source/conf.py', 'doc/source/man/bashate.rst', 'bashate/tests/test_bashate.py']",6,8917d65e1b57581fb9edc45002ff7490c37b992e,skip-from-file," def test_multi_ignore_with_whitespace(self): self.run.register_ignores(' E001 , E011') def test_sample_inline_ignore(self): test_files = ['bashate/tests/samples/inline_ignore.sh'] self.run.check_files(test_files, False) self.assertEqual(0, self.run.ERRORS) "," def test_multi_ignore_with_slash(self): self.run.register_ignores('E001|E011') bashate.check_no_trailing_whitespace(""if "", self.run) bashate.check_if_then(""if "", self.run) self.assertEqual(0, self.run.ERRORS) def test_multi_ignore_mixed(self): self.run.register_ignores('E001|E002,E003|E011') bashate.check_indents("" echo"", self.run)",105,14
openstack%2Fswift~master~I551ef4a8ae76d31d50625649c71fc7282645ad94,openstack/swift,master,I551ef4a8ae76d31d50625649c71fc7282645ad94,wip: make /info configurable,NEW,2014-09-16 01:01:49.000000000,2017-12-18 12:17:01.000000000,,"[{'_account_id': 1179}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-09-16 01:01:49.000000000', 'files': ['swift/proxy/controllers/info.py', 'swift/common/utils.py', 'swift/proxy/server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/572556a85c4784fa9d92787146d7f5260e36958e', 'message': 'wip: make /info configurable\n\nThis is a pretty generic way we could let operators stick stuff into /info\n\nNot sure about precedence...\n\n * should keys already set be disallowed?\n * should disallowed sections be excluded from extra_info too?\n\nChange-Id: I551ef4a8ae76d31d50625649c71fc7282645ad94\n'}]",0,121723,572556a85c4784fa9d92787146d7f5260e36958e,6,2,1,1179,,,0,"wip: make /info configurable

This is a pretty generic way we could let operators stick stuff into /info

Not sure about precedence...

 * should keys already set be disallowed?
 * should disallowed sections be excluded from extra_info too?

Change-Id: I551ef4a8ae76d31d50625649c71fc7282645ad94
",git fetch https://review.opendev.org/openstack/swift refs/changes/23/121723/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/proxy/controllers/info.py', 'swift/common/utils.py', 'swift/proxy/server.py']",3,572556a85c4784fa9d92787146d7f5260e36958e,extra-info," affinity_key_function, affinity_locality_predicate, \ # N.B. the proxy's a/c/o controllers are all per-request, but the info # controller is for the whole app like the a/c/o server's controllers self.info_controller = InfoController(self, conf) return self.info_controller, {}"," affinity_key_function, affinity_locality_predicate, list_from_csv, \ self.expose_info = config_true_value( conf.get('expose_info', 'yes')) self.disallowed_sections = list_from_csv( conf.get('disallowed_sections')) self.admin_key = conf.get('admin_key', None) d = dict(version=None, expose_info=self.expose_info, disallowed_sections=self.disallowed_sections, admin_key=self.admin_key) return InfoController, d",106,20
openstack%2Fswift~master~I8d506791f22233adbc29d9aab26e08dd9c6419ef,openstack/swift,master,I8d506791f22233adbc29d9aab26e08dd9c6419ef,Add policy engine to keystoneauth,NEW,2014-04-28 20:01:23.000000000,2017-12-18 12:16:59.000000000,,"[{'_account_id': 330}, {'_account_id': 860}, {'_account_id': 7781}, {'_account_id': 8859}, {'_account_id': 9910}, {'_account_id': 12193}]","[{'number': 4, 'created': '2014-04-28 20:01:23.000000000', 'files': ['swift/common/middleware/keystoneauth/__init__.py', 'swift/common/middleware/keystoneauth/keystoneauth.py', 'test/unit/common/middleware/test_keystoneauth.py', 'swift/common/middleware/keystoneauth/enforcer.py', 'swift/common/middleware/keystoneauth.py', 'swift/common/middleware/keystoneauth/policy.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/6868951b00be7de23fe43975130a9388865c67e1', 'message': 'Add policy engine to keystoneauth\n\nThis patch add OpenStack Policy engine into keystaoneauth\nwithout altering the external interface of the middleware\nI.E: Only the internal implementation of the authorization checks\nwas changed, the middleware parameters and unittests\xa0\nremain the same.\n\nHow does it work:\n* ""authorize"" method were re-implemented to use an ""enforcer""\nwhich is base on the json policy format defined in OpenStack.\n* All keystoneauth authorisations logic were translated into json policy\xa0\nformat, to ensure backward compatibly.\n* No change to the middleware parameter were done for now,\xa0\nwhen the middleware is called with its usual parameters\xa0\n(operator_roles, reseller_role, and is_admin)\xa0\nwe pass those parameter to the enforcer, which know how to\xa0\ntranslate them into the corresponding json policy format, and then\xa0\napply checks based on the result.\n\n(In a next patch we would like to address the second step of the blue\nprint which is allowing to specify a json policy file as a parameter of\nthe middleware and handle authorization according to that file).\n\nPartially implements bp\xa0authorization-policy\n\nChange-Id: I8d506791f22233adbc29d9aab26e08dd9c6419ef\n'}, {'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2484b2b7a9ba6e8083d9ebfd27cf144c513270c0', 'message': 'Add policy engine to keystoneauth\n\nThis patch add OpenStack Policy engine into keystaoneauth\nwithout altering the external interface of the middleware\nI.E: Only the internal implementation of the authorization checks\nwas changed, the middleware parameters and unittests\xa0\nremain the same.\n\nHow does it work:\n* ""authorize"" method were re-implemented to use an ""enforcer""\nwhich is base on the json policy format defined in OpenStack.\n* All keystoneauth authorisations logic were translated into json policy\xa0\nformat, to ensure backward compatibly.\n* No change to the middleware parameter were done for now,\xa0\nwhen the middleware is called with its usual parameters\xa0\n(operator_roles, reseller_role, and is_admin)\xa0\nwe pass those parameter to the enforcer, which know how to\xa0\ntranslate them into the corresponding json policy format, and then\xa0\napply checks based on the result.\n\n(In a next patch we would like to address the second step of the blue\nprint which is allowing to specify a json policy file as a parameter of\nthe middleware and handle authorization according to that file).\n\nPartially implements Blueprint:\xa0authorization-policy\n\nChange-Id: I8d506791f22233adbc29d9aab26e08dd9c6419ef\n'}, {'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a24c2a5c2cff6249d57fa5af23b638c1ff40f09e', 'message': 'Add policy engine to keystoneauth\n\nThis patch add OpenStack Policy engine into keystaoneauth\nwithout altering the external interface of the middleware\nI.E: Only the internal implementation of the authorization checks\nwas changed, the middleware parameters and unittests\xa0\nremain the same.\n\nHow does it work:\n* ""authorize"" method were re-implemented to use an ""enforcer""\nwhich is base on the json policy format defined in OpenStack.\n* All keystoneauth authorisations logic were translated into json policy\xa0\nformat, to ensure backward compatibly.\n* No change to the middleware parameter were done for now,\xa0\nwhen the middleware is called with its usual parameters\xa0\n(operator_roles, reseller_role, and is_admin)\xa0\nwe pass those parameter to the enforcer, which know how to\xa0\ntranslate them into the corresponding json policy format, and then\xa0\napply checks based on the result.\n\n(In a next patch we would like to address the second step of the BP\nwhich is allowing to specify a json policy file as a parameter of\nthe middleware and handle authorization according to that file).\n\nPartially implements Blueprint:\xa0authorization-policy\n\nChange-Id: I8d506791f22233adbc29d9aab26e08dd9c6419ef\n'}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/44740a1aaf4f849e893ce8f7ebc99347bd440665', 'message': 'Add policy engine to keystoneauth\n\nThis patch add OpenStack Policy engine into keystaoneauth\nwithout altering the external interface of the middleware\nI.E: Only the internal implementation of the authorization checks\nwas changed, the middleware parameters and unittests\xa0\nremain the same.\n\nHow does it work:\n* ""authorize"" method were re-implemented to use an ""enforcer""\nwhich is base on the json policy format defined in OpenStack.\n* All keystoneauth authorisations logic were translated into json policy\xa0\nformat, to ensure backward compatibly.\n* No change to the middleware parameter were done for now,\xa0\nwhen the middleware is called with its usual parameters\xa0\n(operator_roles, reseller_role, and is_admin)\xa0\nwe pass those parameter to the enforcer, which know how to\xa0\ntranslate them into the corresponding json policy format, and then\xa0\napply checks based on the result.\n\n(In a next patch we would like to address the second step of the BP\nwhich is allowing to specify a json policy file as a parameter of\nthe middleware and handle authorization according to that file).\n\nPartially implements: blueprint\xa0authorization-policy\n\nChange-Id: I8d506791f22233adbc29d9aab26e08dd9c6419ef\n'}]",3,89568,6868951b00be7de23fe43975130a9388865c67e1,20,6,4,9910,,,0,"Add policy engine to keystoneauth

This patch add OpenStack Policy engine into keystaoneauth
without altering the external interface of the middleware
I.E: Only the internal implementation of the authorization checks
was changed, the middleware parameters and unittests
remain the same.

How does it work:
* ""authorize"" method were re-implemented to use an ""enforcer""
which is base on the json policy format defined in OpenStack.
* All keystoneauth authorisations logic were translated into json policy
format, to ensure backward compatibly.
* No change to the middleware parameter were done for now,
when the middleware is called with its usual parameters
(operator_roles, reseller_role, and is_admin)
we pass those parameter to the enforcer, which know how to
translate them into the corresponding json policy format, and then
apply checks based on the result.

(In a next patch we would like to address the second step of the blue
print which is allowing to specify a json policy file as a parameter of
the middleware and handle authorization according to that file).

Partially implements bpauthorization-policy

Change-Id: I8d506791f22233adbc29d9aab26e08dd9c6419ef
",git fetch https://review.opendev.org/openstack/swift refs/changes/68/89568/4 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/keystoneauth/__init__.py', 'swift/common/middleware/keystoneauth/keystoneauth.py', 'test/unit/common/middleware/test_keystoneauth.py', 'swift/common/middleware/keystoneauth/enforcer.py', 'swift/common/middleware/keystoneauth.py', 'swift/common/middleware/keystoneauth/policy.py']",6,6868951b00be7de23fe43975130a9388865c67e1,bp/authorization-policy,"# Copyright (c) 2012 OpenStack Foundation. # Based on: # https://github.com/openstack/oslo-incubator/blob/master # /openstack/common/policy.py # and adapted to remove dependency to oslo.cfg. # # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Common Policy Engine Implementation Policies can be expressed in one of two forms: A list of lists, or a string written in the new policy language. In the list-of-lists representation, each check inside the innermost list is combined as with an ""and"" conjunction--for that check to pass, all the specified checks must pass. These innermost lists are then combined as with an ""or"" conjunction. This is the original way of expressing policies, but there now exists a new way: the policy language. In the policy language, each check is specified the same way as in the list-of-lists representation: a simple ""a:b"" pair that is matched to the correct code to perform that check. However, conjunction operators are available, allowing for more expressiveness in crafting policies. As an example, take the following rule, expressed in the list-of-lists representation:: [[""role:admin""], [""project_id:%(project_id)s"", ""role:projectadmin""]] In the policy language, this becomes:: role:admin or (project_id:%(project_id)s and role:projectadmin) The policy language also has the ""not"" operator, allowing a richer policy rule:: project_id:%(project_id)s and not role:dunce It is possible to perform policy checks on the following user attributes (obtained through the token): user_id, domain_id or project_id:: domain_id:<some_value> Attributes sent along with API calls can be used by the policy engine (on the right side of the expression), by using the following syntax:: <some_value>:user.id Contextual attributes of objects identified by their IDs are loaded from the database. They are also available to the policy engine and can be checked through the `target` keyword:: <some_value>:target.role.name All these attributes (related to users, API calls, and context) can be checked against each other or against constants, be it literals (True, <a_number>) or strings. Finally, two special policy checks should be mentioned; the policy check ""@"" will always accept an access, and the policy check ""!"" will always reject an access. (Note that if a rule is either the empty list (""[]"") or the empty string, this is equivalent to the ""@"" policy check.) Of these, the ""!"" policy check is probably the most useful, as it allows particular rules to be explicitly disabled. """""" import abc import ast import re import six import six.moves.urllib.parse as urlparse import six.moves.urllib.request as urlrequest from swift import gettext_ as _ import json _checks = {} class PolicyNotAuthorized(Exception): def __init__(self, rule): msg = _(""Policy doesn't allow %s to be performed."") % rule super(PolicyNotAuthorized, self).__init__(msg) class Rules(dict): """"""A store for rules. Handles the default_rule setting directly."""""" @classmethod def load_json(cls, data, default_rule=None): """"""Allow loading of JSON rule data."""""" # Suck in the JSON data and parse the rules rules = dict((k, parse_rule(v)) for k, v in json.loads(data).items()) return cls(rules, default_rule) def __init__(self, rules=None, default_rule=None): """"""Initialize the Rules store."""""" super(Rules, self).__init__(rules or {}) self.default_rule = default_rule def __missing__(self, key): """"""Implements the default rule handling."""""" if isinstance(self.default_rule, dict): raise KeyError(key) # If the default rule isn't actually defined, do something # reasonably intelligent if not self.default_rule: raise KeyError(key) if isinstance(self.default_rule, BaseCheck): return self.default_rule # We need to check this or we can get infinite recursion if self.default_rule not in self: raise KeyError(key) elif isinstance(self.default_rule, six.string_types): return self[self.default_rule] def __str__(self): """"""Dumps a string representation of the rules."""""" # Start by building the canonical strings for the rules out_rules = {} for key, value in self.items(): # Use empty string for singleton TrueCheck instances if isinstance(value, TrueCheck): out_rules[key] = '' else: out_rules[key] = str(value) # Dump a pretty-printed JSON representation return json.dumps(out_rules, indent=4) class Enforcer(object): """"""Responsible for loading and enforcing rules. :param policy_file: Custom policy file to use, if none is specified, `CONF.policy_file` will be used. :param rules: Default dictionary / Rules to use. It will be considered just in the first instantiation. If `load_rules(True)`, `clear()` or `set_rules(True)` is called this will be overwritten. :param default_rule: Default rule to use, CONF.default_rule will be used if none is specified. """""" def __init__(self, policy_file=None, rules=None, default_rule=None): self.rules = Rules(rules, default_rule) self.default_rule = default_rule self.policy_path = None self.policy_file = policy_file def set_rules(self, rules, overwrite=True): """"""Create a new Rules object based on the provided dict of rules. :param rules: New rules to use. It should be an instance of dict. :param overwrite: Whether to overwrite current rules or update them with the new rules. :param use_conf: Whether to reload rules from cache or config file. """""" if not isinstance(rules, dict): raise TypeError(_(""Rules must be an instance of dict or Rules, "" ""got %s instead"") % type(rules)) if overwrite: self.rules = Rules(rules, self.default_rule) else: self.rules.update(rules) def clear(self): """"""Clears Enforcer rules, policy's cache and policy's path."""""" self.set_rules({}) self.default_rule = None self.policy_path = None def load_rules(self, force_reload=False): """"""Loads policy_path's rules. """""" raise NotImplemented def _get_policy_path(self): """"""Locate the policy json data file."""""" raise NotImplemented def enforce(self, rule, target, creds, do_raise=False, exc=None, *args, **kwargs): """"""Checks authorization of a rule against the target and credentials. :param rule: A string or BaseCheck instance specifying the rule to evaluate. :param target: As much information about the object being operated on as possible, as a dictionary. :param creds: As much information about the user performing the action as possible, as a dictionary. :param do_raise: Whether to raise an exception or not if check fails. :param exc: Class of the exception to raise if the check fails. Any remaining arguments passed to check() (both positional and keyword arguments) will be passed to the exception class. If not specified, PolicyNotAuthorized will be used. :return: Returns False if the policy does not allow the action and exc is not provided; otherwise, returns a value that evaluates to True. Note: for rules using the ""case"" expression, this True value will be the specified string from the expression. """""" # NOTE(flaper87): Not logging target or creds to avoid # potential security issues. #LOG.debug(""Rule %s will be now enforced"" % rule) self.load_rules() # Allow the rule to be a Check tree if isinstance(rule, BaseCheck): result = rule(target, creds, self) elif not self.rules: # No rules to reference means we're going to fail closed result = False else: try: # Evaluate the rule result = self.rules[rule](target, creds, self) except KeyError: #LOG.debug(""Rule [%s] doesn't exist"" % rule) # If the rule doesn't exist, fail closed result = False # If it is False, raise the exception if requested if do_raise and not result: if exc: raise exc(*args, **kwargs) raise PolicyNotAuthorized(rule) return result @six.add_metaclass(abc.ABCMeta) class BaseCheck(object): """"""Abstract base class for Check classes."""""" @abc.abstractmethod def __str__(self): """"""String representation of the Check tree rooted at this node."""""" pass @abc.abstractmethod def __call__(self, target, cred, enforcer): """"""Triggers if instance of the class is called. Performs the check. Returns False to reject the access or a true value (not necessary True) to accept the access. """""" pass class FalseCheck(BaseCheck): """"""A policy check that always returns False (disallow)."""""" def __str__(self): """"""Return a string representation of this check."""""" return ""!"" def __call__(self, target, cred, enforcer): """"""Check the policy."""""" return False class TrueCheck(BaseCheck): """"""A policy check that always returns True (allow)."""""" def __str__(self): """"""Return a string representation of this check."""""" return ""@"" def __call__(self, target, cred, enforcer): """"""Check the policy."""""" return True class Check(BaseCheck): """"""A base class to allow for user-defined policy checks."""""" def __init__(self, kind, match): """"""Initiates Check instance. :param kind: The kind of the check, i.e., the field before the ':'. :param match: The match of the check, i.e., the field after the ':'. """""" self.kind = kind self.match = match def __str__(self): """"""Return a string representation of this check."""""" return ""%s:%s"" % (self.kind, self.match) class NotCheck(BaseCheck): """"""Implements the ""not"" logical operator. A policy check that inverts the result of another policy check. """""" def __init__(self, rule): """"""Initialize the 'not' check. :param rule: The rule to negate. Must be a Check. """""" self.rule = rule def __str__(self): """"""Return a string representation of this check."""""" return ""not %s"" % self.rule def __call__(self, target, cred, enforcer): """"""Check the policy. Returns the logical inverse of the wrapped check. """""" return not self.rule(target, cred, enforcer) class AndCheck(BaseCheck): """"""Implements the ""and"" logical operator. A policy check that requires that a list of other checks all return True. """""" def __init__(self, rules): """"""Initialize the 'and' check. :param rules: A list of rules that will be tested. """""" self.rules = rules def __str__(self): """"""Return a string representation of this check."""""" return ""(%s)"" % ' and '.join(str(r) for r in self.rules) def __call__(self, target, cred, enforcer): """"""Check the policy. Requires that all rules accept in order to return True. """""" for rule in self.rules: if not rule(target, cred, enforcer): return False return True def add_check(self, rule): """"""Adds rule to be tested. Allows addition of another rule to the list of rules that will be tested. Returns the AndCheck object for convenience. """""" self.rules.append(rule) return self class OrCheck(BaseCheck): """"""Implements the ""or"" operator. A policy check that requires that at least one of a list of other checks returns True. """""" def __init__(self, rules): """"""Initialize the 'or' check. :param rules: A list of rules that will be tested. """""" self.rules = rules def __str__(self): """"""Return a string representation of this check."""""" return ""(%s)"" % ' or '.join(str(r) for r in self.rules) def __call__(self, target, cred, enforcer): """"""Check the policy. Requires that at least one rule accept in order to return True. """""" for rule in self.rules: if rule(target, cred, enforcer): return True return False def add_check(self, rule): """"""Adds rule to be tested. Allows addition of another rule to the list of rules that will be tested. Returns the OrCheck object for convenience. """""" self.rules.append(rule) return self def _parse_check(rule): """"""Parse a single base check rule into an appropriate Check object."""""" # Handle the special checks if rule == '!': return FalseCheck() elif rule == '@': return TrueCheck() try: kind, match = rule.split(':', 1) except Exception: #LOG.exception(_LE(""Failed to understand rule %s"") % rule) # If the rule is invalid, we'll fail closed return FalseCheck() # Find what implements the check if kind in _checks: return _checks[kind](kind, match) elif None in _checks: return _checks[None](kind, match) else: #LOG.error(_LE(""No handler for matches of kind %s"") % kind) return FalseCheck() def _parse_list_rule(rule): """"""Translates the old list-of-lists syntax into a tree of Check objects. Provided for backwards compatibility. """""" # Empty rule defaults to True if not rule: return TrueCheck() # Outer list is joined by ""or""; inner list by ""and"" or_list = [] for inner_rule in rule: # Elide empty inner lists if not inner_rule: continue # Handle bare strings if isinstance(inner_rule, six.string_types): inner_rule = [inner_rule] # Parse the inner rules into Check objects and_list = [_parse_check(r) for r in inner_rule] # Append the appropriate check to the or_list if len(and_list) == 1: or_list.append(and_list[0]) else: or_list.append(AndCheck(and_list)) # If we have only one check, omit the ""or"" if not or_list: return FalseCheck() elif len(or_list) == 1: return or_list[0] return OrCheck(or_list) # Used for tokenizing the policy language _tokenize_re = re.compile(r'\s+') def _parse_tokenize(rule): """"""Tokenizer for the policy language. Most of the single-character tokens are specified in the _tokenize_re; however, parentheses need to be handled specially, because they can appear inside a check string. Thankfully, those parentheses that appear inside a check string can never occur at the very beginning or end (""%(variable)s"" is the correct syntax). """""" for tok in _tokenize_re.split(rule): # Skip empty tokens if not tok or tok.isspace(): continue # Handle leading parens on the token clean = tok.lstrip('(') for i in range(len(tok) - len(clean)): yield '(', '(' # If it was only parentheses, continue if not clean: continue else: tok = clean # Handle trailing parens on the token clean = tok.rstrip(')') trail = len(tok) - len(clean) # Yield the cleaned token lowered = clean.lower() if lowered in ('and', 'or', 'not'): # Special tokens yield lowered, clean elif clean: # Not a special token, but not composed solely of ')' if len(tok) >= 2 and ((tok[0], tok[-1]) in [('""', '""'), (""'"", ""'"")]): # It's a quoted string yield 'string', tok[1:-1] else: yield 'check', _parse_check(clean) # Yield the trailing parens for i in range(trail): yield ')', ')' class ParseStateMeta(type): """"""Metaclass for the ParseState class. Facilitates identifying reduction methods. """""" def __new__(mcs, name, bases, cls_dict): """"""Create the class. Injects the 'reducers' list, a list of tuples matching token sequences to the names of the corresponding reduction methods. """""" reducers = [] for key, value in cls_dict.items(): if not hasattr(value, 'reducers'): continue for reduction in value.reducers: reducers.append((reduction, key)) cls_dict['reducers'] = reducers return super(ParseStateMeta, mcs).__new__(mcs, name, bases, cls_dict) def reducer(*tokens): """"""Decorator for reduction methods. Arguments are a sequence of tokens, in order, which should trigger running this reduction method. """""" def decorator(func): # Make sure we have a list of reducer sequences if not hasattr(func, 'reducers'): func.reducers = [] # Add the tokens to the list of reducer sequences func.reducers.append(list(tokens)) return func return decorator @six.add_metaclass(ParseStateMeta) class ParseState(object): """"""Implement the core of parsing the policy language. Uses a greedy reduction algorithm to reduce a sequence of tokens into a single terminal, the value of which will be the root of the Check tree. Note: error reporting is rather lacking. The best we can get with this parser formulation is an overall ""parse failed"" error. Fortunately, the policy language is simple enough that this shouldn't be that big a problem. """""" def __init__(self): """"""Initialize the ParseState."""""" self.tokens = [] self.values = [] def reduce(self): """"""Perform a greedy reduction of the token stream. If a reducer method matches, it will be executed, then the reduce() method will be called recursively to search for any more possible reductions. """""" for reduction, methname in self.reducers: if (len(self.tokens) >= len(reduction) and self.tokens[-len(reduction):] == reduction): # Get the reduction method meth = getattr(self, methname) # Reduce the token stream results = meth(*self.values[-len(reduction):]) # Update the tokens and values self.tokens[-len(reduction):] = [r[0] for r in results] self.values[-len(reduction):] = [r[1] for r in results] # Check for any more reductions return self.reduce() def shift(self, tok, value): """"""Adds one more token to the state. Calls reduce()."""""" self.tokens.append(tok) self.values.append(value) # Do a greedy reduce... self.reduce() @property def result(self): """"""Obtain the final result of the parse. Raises ValueError if the parse failed to reduce to a single result. """""" if len(self.values) != 1: raise ValueError(""Could not parse rule"") return self.values[0] @reducer('(', 'check', ')') @reducer('(', 'and_expr', ')') @reducer('(', 'or_expr', ')') def _wrap_check(self, _p1, check, _p2): """"""Turn parenthesized expressions into a 'check' token."""""" return [('check', check)] @reducer('check', 'and', 'check') def _make_and_expr(self, check1, _and, check2): """"""Create an 'and_expr'. Join two checks by the 'and' operator. """""" return [('and_expr', AndCheck([check1, check2]))] @reducer('and_expr', 'and', 'check') def _extend_and_expr(self, and_expr, _and, check): """"""Extend an 'and_expr' by adding one more check."""""" return [('and_expr', and_expr.add_check(check))] @reducer('check', 'or', 'check') def _make_or_expr(self, check1, _or, check2): """"""Create an 'or_expr'. Join two checks by the 'or' operator. """""" return [('or_expr', OrCheck([check1, check2]))] @reducer('or_expr', 'or', 'check') def _extend_or_expr(self, or_expr, _or, check): """"""Extend an 'or_expr' by adding one more check."""""" return [('or_expr', or_expr.add_check(check))] @reducer('not', 'check') def _make_not_expr(self, _not, check): """"""Invert the result of another check."""""" return [('check', NotCheck(check))] def _parse_text_rule(rule): """"""Parses policy to the tree. Translates a policy written in the policy language into a tree of Check objects. """""" # Empty rule means always accept if not rule: return TrueCheck() # Parse the token stream state = ParseState() for tok, value in _parse_tokenize(rule): state.shift(tok, value) try: return state.result except ValueError: # Couldn't parse the rule #LOG.exception(_LE(""Failed to understand rule %r"") % rule) # Fail closed return FalseCheck() def parse_rule(rule): """"""Parses a policy rule into a tree of Check objects."""""" # If the rule is a string, it's in the policy language if isinstance(rule, six.string_types): return _parse_text_rule(rule) return _parse_list_rule(rule) def register(name, func=None): """"""Register a function or Check class as a policy check. :param name: Gives the name of the check type, e.g., 'rule', 'role', etc. If name is None, a default check type will be registered. :param func: If given, provides the function or class to register. If not given, returns a function taking one argument to specify the function or class to register, allowing use as a decorator. """""" # Perform the actual decoration by registering the function or # class. Returns the function or class for compliance with the # decorator interface. def decorator(func): _checks[name] = func return func # If the function or class is given, do the registration if func: return decorator(func) return decorator @register(""rule"") class RuleCheck(Check): def __call__(self, target, creds, enforcer): """"""Recursively checks credentials based on the defined rules."""""" try: result = enforcer.rules[self.match](target, creds, enforcer) #LOG.debug(""Rule %s being evaluated to %s"" % (self.match, result)) return result except KeyError: # We don't have any matching rule; fail closed return False @register(""role"") class RoleCheck(Check): def __call__(self, target, creds, enforcer): """"""Check that there is a matching role in the cred dict."""""" return self.match.lower() in [x.lower() for x in creds['roles']] @register('http') class HttpCheck(Check): def __call__(self, target, creds, enforcer): """"""Check http: rules by calling to a remote server. This example implementation simply verifies that the response is exactly 'True'. """""" url = ('http:' + self.match) % target data = {'target': json.dumps(target), 'credentials': json.dumps(creds)} post_data = urlparse.urlencode(data) f = urlrequest.urlopen(url, post_data) return f.read() == ""True"" @register(None) class GenericCheck(Check): def __call__(self, target, creds, enforcer): """"""Check an individual match. Matches look like: tenant:%(tenant_id)s role:compute:admin True:%(user.enabled)s 'Member':%(role.name)s """""" # TODO(termie): do dict inspection via dot syntax try: match = self.match % target except KeyError: # While doing GenericCheck if key not # present in Target return false return False try: # Try to interpret self.kind as a literal leftval = ast.literal_eval(self.kind) except ValueError: try: leftval = creds[self.kind] except KeyError: return False return match == six.text_type(leftval) ",,1447,394
openstack%2Fironic-python-agent~master~Ie4cd4e369dec5b0b42a83a9d7a3e6f083124f778,openstack/ironic-python-agent,master,Ie4cd4e369dec5b0b42a83a9d7a3e6f083124f778,Refactor image writing,NEW,2014-10-15 16:37:22.000000000,2017-12-18 12:16:50.000000000,,[],"[{'number': 1, 'created': '2014-10-15 16:37:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/391c5784ca6ca8746293c7164b76c38545d1833a', 'message': ""Refactor image writing\n\nThis breaks image writing out of the standby extension and into its own\nset of classes that are exposed via the hardware manager. This will\nallow different image writing processes to be added more easily (e.g.,\nvhd writing -- which qemu_img doesn't fully support).\n\nChange-Id: Ie4cd4e369dec5b0b42a83a9d7a3e6f083124f778\n""}, {'number': 2, 'created': '2014-10-22 17:02:33.000000000', 'files': ['ironic_python_agent/hardware.py', 'ironic_python_agent/tests/extensions/standby.py', 'ironic_python_agent/shell/qemu_img_write_image.sh', 'ironic_python_agent/tests/imaging/qemu_img.py', 'ironic_python_agent/tests/imaging/base.py', 'ironic_python_agent/tests/imaging/__init__.py', 'ironic_python_agent/extensions/standby.py', 'ironic_python_agent/imaging/qemu_img.py', 'ironic_python_agent/tests/hardware.py', 'ironic_python_agent/imaging/__init__.py', 'ironic_python_agent/errors.py', 'ironic_python_agent/imaging/base.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/6563a532362f9ff6c994708bc0616963ce6d2016', 'message': ""Refactor image writing\n\nThis breaks image writing out of the standby extension and into its own\nset of classes that are exposed via the hardware manager. This will\nallow different image writing processes to be added more easily (e.g.,\nvhd writing -- which qemu_img doesn't fully support).\n\nChange-Id: Ie4cd4e369dec5b0b42a83a9d7a3e6f083124f778\n""}]",0,128701,6563a532362f9ff6c994708bc0616963ce6d2016,7,0,2,1030,,,0,"Refactor image writing

This breaks image writing out of the standby extension and into its own
set of classes that are exposed via the hardware manager. This will
allow different image writing processes to be added more easily (e.g.,
vhd writing -- which qemu_img doesn't fully support).

Change-Id: Ie4cd4e369dec5b0b42a83a9d7a3e6f083124f778
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/01/128701/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/hardware.py', 'ironic_python_agent/tests/extensions/standby.py', 'ironic_python_agent/shell/qemu_img_write_image.sh', 'ironic_python_agent/tests/imaging/qemu_img.py', 'ironic_python_agent/tests/imaging/base.py', 'ironic_python_agent/tests/imaging/__init__.py', 'ironic_python_agent/extensions/standby.py', 'ironic_python_agent/imaging/qemu_img.py', 'ironic_python_agent/tests/hardware.py', 'ironic_python_agent/imaging/__init__.py', 'ironic_python_agent/errors.py', 'ironic_python_agent/imaging/base.py']",12,391c5784ca6ca8746293c7164b76c38545d1833a,image_refactor,"# Copyright 2013-2014 Rackspace, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import base64 import contextlib import gzip import md5 import os import requests import shutil import StringIO import time from ironic_python_agent import errors from ironic_python_agent.openstack.common import log from ironic_python_agent.openstack.common import processutils from ironic_python_agent import utils LOG = log.getLogger(__name__) class BaseImageManager(object): def __init__(self, tmpdir=None): if tmpdir is None: tmpdir = '/tmp' self.tmpdir = tmpdir def _image_location(self, image_info): return os.path.join(self.tmpdir, image_info['id']) def _configdrive_location(self): return os.path.join(self.tmpdir, 'configdrive') @staticmethod def _path_to_script(script): cwd = os.path.dirname(os.path.realpath(__file__)) return os.path.join(cwd, '..', script) @staticmethod def _request_url(image_info, url): resp = requests.get(url, stream=True) if resp.status_code != 200: reason = 'Got HTTP status code of %s' % resp.status_code raise errors.ImageDownloadError(image_info['id'], reason) return resp def _fetch_image(self, image_info, read_cb): image_id = image_info['id'] if not image_info['urls']: raise errors.ImageDownloadError(image_id, 'No URLs provided') for url in image_info['urls']: starttime = time.time() LOG.info('Attempting to fetch image %(id)s from %(url)s', {'id': image_id, 'url': url}) try: resp = self._request_url(image_info, url) break except errors.ImageDownloadError as e: last_error = e LOG.warning('Image %(id)s failed to download from ' '%(url)s: %(reason)s', {'id': image_id, 'url': url, 'reason': e.reason}) else: raise errors.ImageDownloadError(image_id, last_error.reason) checksum = md5.new() try: for chunk in resp.iter_content(1024 * 1024): checksum.update(chunk) read_cb(chunk) except Exception as e: raise errors.ImageDownloadError(image_info['id'], str(e)) checksum = checksum.hexdigest() totaltime = time.time() - starttime LOG.info('Image %(id)s downloaded in %(time)s second(s)', {'id': image_id, 'time': totaltime}) if checksum != image_info['checksum']: LOG.error('MD5 Checksum mismatch detected for image ' '%(id)s: remote: %(rem)s, local: %(loc)s', {'id': image_id, 'rem': image_info['checksum'], 'loc': checksum}) raise errors.ImageChecksumError(image_id) @contextlib.contextmanager def _download_image(self, image_info): location = self._image_location(image_info) try: with open(location, 'w') as f: self._fetch_image(image_info, f.write) yield location finally: self._safe_remove_path(location) @staticmethod def _safe_remove_path(path): shutil.rmtree(path, ignore_errors=True) @contextlib.contextmanager def _unpack_configdrive(self, configdrive): location = self._configdrive_location() LOG.debug('Writing configdrive to %(loc)s', {'loc': location}) # configdrive data is base64'd, decode it first data = StringIO.StringIO(base64.b64decode(configdrive)) gunzipped = gzip.GzipFile('configdrive', 'rb', 9, data) try: with open(location, 'wb') as f: f.write(gunzipped.read()) gunzipped.close() gunzipped = None # check configdrive size before writing it filesize = os.stat(location).st_size if filesize > (64 * 1024 * 1024): raise errors.ConfigDriveTooLargeError(location, filesize) yield location finally: self._safe_remove_path(location) if gunzipped is not None: gunzipped.close() def write_os_image(self, image_info, device): """"""Download image and write it to a device."""""" pass def write_configdrive(self, configdrive, device): with self._unpack_configdrive(configdrive) as location: script = self._path_to_script('shell/copy_configdrive_to_disk.sh') command = ['/bin/bash', script, location, device] LOG.info('Copying configdrive to disk with command %(cmd)s', {'cmd': ' '.join(command)}) try: stdout, stderr = utils.execute(*command, check_exit_code=[0]) except processutils.ProcessExecutionError as e: raise errors.ConfigDriveWriteError(device, e.exit_code, e.stdout, e.stderr) ",,875,412
openstack%2Fironic-python-agent~master~I24d7940040e5edc413469b434778409bbac0c8f3,openstack/ironic-python-agent,master,I24d7940040e5edc413469b434778409bbac0c8f3,Add vhd writing support to agent,NEW,2014-10-16 21:54:58.000000000,2017-12-18 12:16:48.000000000,,[],"[{'number': 1, 'created': '2014-10-16 21:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/aa4835955c113b620d4dc35c6c4f5879d5a08997', 'message': ""Add vhd writing support to agent\n\nThis adds a VHDUtilImageManager class that supports writing out tar\nfiles that contain vhds. This relies on a 3rd party tool, 'vhd-util',\nand patches to that utility.\n\nA script to build vhd-util exists here:\n\nhttps://github.com/comstud/libvhd-builder\n\nThat will clone the appropriate repo for vhd-util and build it, as long\nas you have the correct dependencies (documented in the build script).\n\nThe vhd-util binary will need to be put into the following directory\nwithin the agent code (create the missing directories):\n\nimagebuild/coreos/oem/vhd-util/1.0\n\nbefore building the agent image.\n\nChange-Id: I24d7940040e5edc413469b434778409bbac0c8f3\n""}, {'number': 2, 'created': '2014-10-22 17:02:33.000000000', 'files': ['ironic_python_agent/imaging/vhd_util.py', 'ironic_python_agent/tests/imaging/vhd_util.py', 'ironic_python_agent/errors.py', 'ironic_python_agent/imaging/__init__.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/3d06ca373864cf874f1dc67af21b603cb569374f', 'message': ""Add vhd writing support to agent\n\nThis adds a VHDUtilImageManager class that supports writing out tar\nfiles that contain vhds. This relies on a 3rd party tool, 'vhd-util',\nand patches to that utility.\n\nA script to build vhd-util exists here:\n\nhttps://github.com/comstud/libvhd-builder\n\nThat will clone the appropriate repo for vhd-util and build it, as long\nas you have the correct dependencies (documented in the build script).\n\nThe vhd-util binary will need to be put into the following directory\nwithin the agent code (create the missing directories):\n\nimagebuild/coreos/oem/vhd-util/1.0\n\nbefore building the agent image.\n\nChange-Id: I24d7940040e5edc413469b434778409bbac0c8f3\n""}]",0,129070,3d06ca373864cf874f1dc67af21b603cb569374f,7,0,2,1030,,,0,"Add vhd writing support to agent

This adds a VHDUtilImageManager class that supports writing out tar
files that contain vhds. This relies on a 3rd party tool, 'vhd-util',
and patches to that utility.

A script to build vhd-util exists here:

https://github.com/comstud/libvhd-builder

That will clone the appropriate repo for vhd-util and build it, as long
as you have the correct dependencies (documented in the build script).

The vhd-util binary will need to be put into the following directory
within the agent code (create the missing directories):

imagebuild/coreos/oem/vhd-util/1.0

before building the agent image.

Change-Id: I24d7940040e5edc413469b434778409bbac0c8f3
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/70/129070/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/imaging/vhd_util.py', 'ironic_python_agent/tests/imaging/vhd_util.py', 'ironic_python_agent/errors.py', 'ironic_python_agent/imaging/__init__.py']",4,aa4835955c113b620d4dc35c6c4f5879d5a08997,image_refactor,"from ironic_python_agent.imaging import vhd_util _DISK_FORMAT_MAPPING = {'qcow2': qemu_img.QemuImgImageManager, 'vhd': vhd_util.VHDUtilImageManager}", _DISK_FORMAT_MAPPING = {'qcow2': qemu_img.QemuImgImageManager},431,1
openstack%2Fswift~master~I769680790b9549109a579d410f8a75fac745eb3d,openstack/swift,master,I769680790b9549109a579d410f8a75fac745eb3d,O_DIRECT: Use O_DIRECT for reading and writing object data.,NEW,2014-04-28 20:01:23.000000000,2017-12-18 12:16:04.000000000,,"[{'_account_id': 597}, {'_account_id': 10831}]","[{'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': ['swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/0e098aaeef9ed02288dbdb5b3d70ec28574ff0b0', 'message': 'O_DIRECT: Use O_DIRECT for reading and writing object data.\n\nFor reading, if disk_chunk_size is 4K aligned allocate a read buffer that is 4K\naligned using mmap and set the file descriptor flags to include O_DIRECT. If\nthere is an exception reading while O_DIRECT is set, it could be because the\nseek alignment is not 4K aligned, so disable O_DIRECT and perform a standard\nread.\n\nFor writing large files (>= network_chunk_size), if network_chunk_size is 4K\naligned then O_DIRECT will be used for network_chunk_size chunks. If the last\nchunk smaller then network_chunk_size, then O_DIRECT will be disabled and a\nnormal write used instead. For small files (< network_chunk_size), if the file\nsize is a multiple of 4K it will attempt to write using O_DIRECT, otherwise a\nnormal write will be used.\n\nThere are at least two ways this diff could be improved. Currently\nnetwork_chunk_size is not known at the diskfile.py layer so for writing the\nbuffer is allocated at 4K then increased to chunk length when the first write\ncomes in (assuming chunk length is 4K aligned). This double allocation could be\nremoved if network_chunk_size was available at this layer.\n\nThe 4K alignment was selected because O_DIRECT requires memory alignment to\nmatch the sector size of the underlying block device. This could be queried\nusing BLKSSZGET ioctl, but this seemed a bit excessive to do for each file, so\nI used a fixed 4K value which covers both 512 byte sectors and 4K sectors.\n\nTesting on a 5 storage node cluster improved read performance between 2.5x and\n5x using large files. Rate limiting was disabled in the proxy and object and\nclient chunk sizes set to 16K. Object servers used 2MB disk and network chunk\nsizes and 8 threads per disk.\n\nChange-Id: I769680790b9549109a579d410f8a75fac745eb3d\n'}]",3,81111,0e098aaeef9ed02288dbdb5b3d70ec28574ff0b0,8,2,1,10831,,,0,"O_DIRECT: Use O_DIRECT for reading and writing object data.

For reading, if disk_chunk_size is 4K aligned allocate a read buffer that is 4K
aligned using mmap and set the file descriptor flags to include O_DIRECT. If
there is an exception reading while O_DIRECT is set, it could be because the
seek alignment is not 4K aligned, so disable O_DIRECT and perform a standard
read.

For writing large files (>= network_chunk_size), if network_chunk_size is 4K
aligned then O_DIRECT will be used for network_chunk_size chunks. If the last
chunk smaller then network_chunk_size, then O_DIRECT will be disabled and a
normal write used instead. For small files (< network_chunk_size), if the file
size is a multiple of 4K it will attempt to write using O_DIRECT, otherwise a
normal write will be used.

There are at least two ways this diff could be improved. Currently
network_chunk_size is not known at the diskfile.py layer so for writing the
buffer is allocated at 4K then increased to chunk length when the first write
comes in (assuming chunk length is 4K aligned). This double allocation could be
removed if network_chunk_size was available at this layer.

The 4K alignment was selected because O_DIRECT requires memory alignment to
match the sector size of the underlying block device. This could be queried
using BLKSSZGET ioctl, but this seemed a bit excessive to do for each file, so
I used a fixed 4K value which covers both 512 byte sectors and 4K sectors.

Testing on a 5 storage node cluster improved read performance between 2.5x and
5x using large files. Rate limiting was disabled in the proxy and object and
client chunk sizes set to 16K. Object servers used 2MB disk and network chunk
sizes and 8 threads per disk.

Change-Id: I769680790b9549109a579d410f8a75fac745eb3d
",git fetch https://review.opendev.org/openstack/swift refs/changes/11/81111/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/obj/diskfile.py'],1,0e098aaeef9ed02288dbdb5b3d70ec28574ff0b0,O_DIRECT,"import fcntl import mmap # try to set O_DIRECT. Not all filesystems support O_DIRECT like tmpfs, # so it may fail. try: self._old_flags = fcntl.fcntl(fd, fcntl.F_GETFL) fcntl.fcntl(fd, fcntl.F_SETFL, self._old_flags | os.O_DIRECT) # the write buffer should be set to the network_chunk_size, however # thats not available here so setup a 4K buffer and increase later # when the writes come in. self._write_buffer = mmap.mmap(-1, 4096, mmap.MAP_PRIVATE) except Exception: self._old_flags = None self._write_buffer = None if self._old_flags: # increase write_buffer to chunk length if chunk length is # 4K aligned if len(chunk) % 4096 == 0 and len(chunk) > len(self._write_buffer): self._write_buffer.close() self._write_buffer = mmap.mmap(-1, len(chunk), mmap.MAP_PRIVATE) def _write_entire_chunk_direct(chunk): # try to write the chunk with aligned write_buffer if len(chunk) == len(self._write_buffer): self._write_buffer.seek(0) self._write_buffer.write(chunk) written = os.write(self._fd, self._write_buffer) self._upload_size += written chunk = chunk[written:] if not chunk: return # if it failed to write it all, turn off O_DIRECT and # proceed as usual if self._old_flags: fcntl.fcntl(self._fd, fcntl.F_SETFL, self._old_flags) self._old_flags = None self._write_buffer = None while chunk: written = os.write(self._fd, chunk) self._upload_size += written chunk = chunk[written:] self._threadpool.run_in_thread(_write_entire_chunk_direct, chunk) else: def _write_entire_chunk(chunk): while chunk: written = os.write(self._fd, chunk) self._upload_size += written chunk = chunk[written:] self._threadpool.run_in_thread(_write_entire_chunk, chunk) if self._old_flags: fcntl.fcntl(self._fd, fcntl.F_SETFL, self._old_flags) self._old_flags = None if disk_chunk_size % 4096 == 0: try: self._old_flags = fcntl.fcntl(fp, fcntl.F_GETFL) fcntl.fcntl(fp, fcntl.F_SETFL, self._old_flags | os.O_DIRECT) self._read_buffer = mmap.mmap(-1, disk_chunk_size, mmap.MAP_PRIVATE) except Exception: self._old_flags = None self._read_buffer = None else: self._old_flags = None self._read_buffer = None if self._old_flags: def _read_chunk_direct(): try: self._read_buffer.seek(0) bytes_read = self._fp.readinto(self._read_buffer) return self._read_buffer.read(bytes_read) except Exception: fcntl.fcntl(self._fp, fcntl.F_SETFL, self._old_flags) self._old_flags = None self._read_buffer = None return self._fp.read(self._disk_chunk_size) chunk = self._threadpool.run_in_thread(_read_chunk_direct) else: chunk = self._threadpool.run_in_thread( self._fp.read, self._disk_chunk_size) else: if self._old_flags: fcntl.fcntl(self._fp, fcntl.F_SETFL, self._old_flags) self._old_flags = None self._read_buffer = None"," def _write_entire_chunk(chunk): while chunk: written = os.write(self._fd, chunk) self._upload_size += written chunk = chunk[written:] self._threadpool.run_in_thread(_write_entire_chunk, chunk) chunk = self._threadpool.run_in_thread( self._fp.read, self._disk_chunk_size)",93,8
openstack%2Fdevstack-gate~master~Ifa5a81010fb598d4af5fed2361d73fba9aa6ba88,openstack/devstack-gate,master,Ifa5a81010fb598d4af5fed2361d73fba9aa6ba88,Get default branch from feature.yaml,NEW,2015-03-02 14:48:54.000000000,2017-12-18 12:15:36.000000000,,"[{'_account_id': 1}, {'_account_id': 8871}]","[{'number': 1, 'created': '2015-03-02 14:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/67de1d7f83160c9a5b1fae61a1b2a463c9a3bbea', 'message': 'Get default branch from feature.yaml\n\nThis is the first step in migrating away from the existing GIT_BRANCH\nimplementation to a feature.yaml based one.\n\nThe current logic allows setting the default branch via an\nenvironment variable. The default branch is already configured\nin features.yaml. Getting it from there instead.\n\nThe current implementation of GIT_BASE was going to be dropped in\nhttps://review.openstack.org/#/c/153023/, this change and the\nfollowing ones will provide an improved implementation instead.\n\nChange-Id: Ifa5a81010fb598d4af5fed2361d73fba9aa6ba88\n'}, {'number': 2, 'created': '2015-03-02 16:22:14.000000000', 'files': ['devstack-vm-gate-wrap.sh', 'test-matrix.py'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/fef294d93034527ac46e87cde2547992b9c5ff01', 'message': 'Get default branch from feature.yaml\n\nThis is the first step in migrating away from the existing GIT_BRANCH\nimplementation to a feature.yaml based one.\n\nThe current logic allows setting the default branch via an\nenvironment variable. The default branch is already configured\nin features.yaml. Getting it from there instead.\n\nThe current implementation of GIT_BASE was going to be dropped in\nhttps://review.openstack.org/#/c/153023/, this change and the\nfollowing ones will provide an improved implementation instead.\n\nChange-Id: Ifa5a81010fb598d4af5fed2361d73fba9aa6ba88\n'}]",0,160366,fef294d93034527ac46e87cde2547992b9c5ff01,7,2,2,1921,,,0,"Get default branch from feature.yaml

This is the first step in migrating away from the existing GIT_BRANCH
implementation to a feature.yaml based one.

The current logic allows setting the default branch via an
environment variable. The default branch is already configured
in features.yaml. Getting it from there instead.

The current implementation of GIT_BASE was going to be dropped in
https://review.openstack.org/#/c/153023/, this change and the
following ones will provide an improved implementation instead.

Change-Id: Ifa5a81010fb598d4af5fed2361d73fba9aa6ba88
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/66/160366/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack-vm-gate-wrap.sh', 'test-matrix.py']",2,67de1d7f83160c9a5b1fae61a1b2a463c9a3bbea,default_branch_from_matrix," help=""What to return (services, default_branch)"") if opts.mode == ""default_branch"": print GRID['branches']['default'] "," help=""What to return (services, compute-ext)"")",5,2
openstack%2Fheat-templates~master~Ib8dc9d87b7e148aa9dedcf85458368aa5fb43382,openstack/heat-templates,master,Ib8dc9d87b7e148aa9dedcf85458368aa5fb43382,Add example of using ASG health maintenance,NEW,2014-10-14 14:45:37.000000000,2017-12-18 12:15:16.000000000,,[{'_account_id': 8328}],"[{'number': 1, 'created': '2014-10-14 14:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/36cbe5d56504f23c89ca3927e3b96916fd42c767', 'message': 'Add example of using ASG health maintenance\n\nAdd an example of using https://review.openstack.org/#/c/127884/\n\nChange-Id: Ib8dc9d87b7e148aa9dedcf85458368aa5fb43382\n'}, {'number': 2, 'created': '2014-10-14 14:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/023fbf26fd8e12566ac48e6b4d97bbba92d037a2', 'message': 'Add example of using ASG health maintenance\n\nAdd an example of using https://review.openstack.org/#/c/127884/\n\nChange-Id: Ib8dc9d87b7e148aa9dedcf85458368aa5fb43382\n'}, {'number': 3, 'created': '2014-10-14 14:59:18.000000000', 'files': ['hot/lb_server.yaml', 'hot/autoscaling_with_health.yaml'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/7acf25d6cc290483abf13a51ca34af66bdf2ad60', 'message': 'Add example of using ASG health maintenance\n\nAdd an example of using https://review.openstack.org/#/c/127884/\n\nChange-Id: Ib8dc9d87b7e148aa9dedcf85458368aa5fb43382\n'}]",0,128311,7acf25d6cc290483abf13a51ca34af66bdf2ad60,7,1,3,8328,,,0,"Add example of using ASG health maintenance

Add an example of using https://review.openstack.org/#/c/127884/

Change-Id: Ib8dc9d87b7e148aa9dedcf85458368aa5fb43382
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/11/128311/1 && git format-patch -1 --stdout FETCH_HEAD,['hot/lb_server.yaml'],1,36cbe5d56504f23c89ca3927e3b96916fd42c767,add/health_example, outputs: pool_member: value: {get_resource: member},,7,0
openstack%2Fswift~master~Idc21bfff9c9e8ab058d658b6f32c51d7ba4865cd,openstack/swift,master,Idc21bfff9c9e8ab058d658b6f32c51d7ba4865cd,refactor kill_nonprimary_server,NEW,2015-02-19 00:59:17.000000000,2017-12-18 12:14:03.000000000,,"[{'_account_id': 1179}, {'_account_id': 7008}]","[{'number': 1, 'created': '2015-02-19 00:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2f1e861f6f8704c8f6ef85ab19c900d91d16a28c', 'message': 'refactor kill_nonprimary_server\n\n* use real ip and port numbers to verify server status\n\nChange-Id: Idc21bfff9c9e8ab058d658b6f32c51d7ba4865cd\n'}, {'number': 2, 'created': '2015-02-19 22:20:02.000000000', 'files': ['test/probe/common.py', 'test/probe/test_container_failures.py', 'test/probe/brain.py', 'test/probe/test_account_failures.py', 'test/probe/test_object_async_update.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/bc2a248001641108fd127d1ac9682f2a1788b35e', 'message': 'refactor kill_nonprimary_server\n\n* use real ip and port numbers to verify server status\n\nChange-Id: Idc21bfff9c9e8ab058d658b6f32c51d7ba4865cd\n'}]",26,157219,bc2a248001641108fd127d1ac9682f2a1788b35e,12,2,2,7008,,,0,"refactor kill_nonprimary_server

* use real ip and port numbers to verify server status

Change-Id: Idc21bfff9c9e8ab058d658b6f32c51d7ba4865cd
",git fetch https://review.opendev.org/openstack/swift refs/changes/19/157219/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/probe/common.py', 'test/probe/test_container_failures.py', 'test/probe/brain.py', 'test/probe/test_account_failures.py', 'test/probe/test_object_async_update.py']",5,2f1e861f6f8704c8f6ef85ab19c900d91d16a28c,refactor-kill_nonprimary_server,"from test.probe.common import kill_server, ReplProbeTest, start_server self.container_brain.kill_handoffs()","from test.probe.common import kill_nonprimary_server, \ kill_server, ReplProbeTest, start_server kill_nonprimary_server(cnodes, self.port2server, self.pids)",95,29
openstack%2Frally~master~Ibe9244e418bf638d15aba16fb1cedadb3c9f3ebb,openstack/rally,master,Ibe9244e418bf638d15aba16fb1cedadb3c9f3ebb,Add Heat create and abandon scenario,NEW,2015-04-14 17:26:02.000000000,2017-12-18 12:14:00.000000000,,"[{'_account_id': 13555}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-04-14 17:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ea2bcf0e0639e8ddc7fef3ae5a405387c6548708', 'message': 'Add Heat create and abandon scenario\n\nThis scenario covers ""stack-create"" and ""stack-abandon""\n\nChange-Id: Ibe9244e418bf638d15aba16fb1cedadb3c9f3ebb\n'}, {'number': 2, 'created': '2015-04-14 18:29:25.000000000', 'files': ['samples/tasks/scenarios/heat/create-and-abandon-stack.yaml', 'rally/benchmark/scenarios/heat/utils.py', 'rally/benchmark/scenarios/heat/stacks.py', 'tests/unit/benchmark/scenarios/heat/test_stacks.py', 'samples/tasks/scenarios/heat/create-and-abandon-stack.json', 'rally-jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/ab57cbb7b9921b0d0d41d83d8668b7d9a430b3b0', 'message': 'Add Heat create and abandon scenario\n\nThis scenario covers ""stack-create"" and ""stack-abandon""\n\nChange-Id: Ibe9244e418bf638d15aba16fb1cedadb3c9f3ebb\n'}]",0,173428,ab57cbb7b9921b0d0d41d83d8668b7d9a430b3b0,8,2,2,13555,,,0,"Add Heat create and abandon scenario

This scenario covers ""stack-create"" and ""stack-abandon""

Change-Id: Ibe9244e418bf638d15aba16fb1cedadb3c9f3ebb
",git fetch https://review.opendev.org/openstack/rally refs/changes/28/173428/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/heat/utils.py', 'samples/tasks/scenarios/heat/create-and-abandon-stack.yaml', 'rally/benchmark/scenarios/heat/stacks.py', 'tests/unit/benchmark/scenarios/heat/test_stacks.py', 'samples/tasks/scenarios/heat/create-and-abandon-stack.json', 'rally-jobs/rally.yaml']",6,ea2bcf0e0639e8ddc7fef3ae5a405387c6548708,create_and_abandon," HeatStacks.create_and_abandon_stack: - args: template_path: ""/home/jenkins/.rally/extra/random_strings.yaml.template"" runner: type: ""constant"" times: 6 concurrency: 2 context: users: tenants: 2 users_per_tenant: 2 sla: failure_rate: max: 0 ",,89,0
openstack%2Fdevstack-gate~master~I89da132c0c5fad842658bbbe9cb1ab5560db67de,openstack/devstack-gate,master,I89da132c0c5fad842658bbbe9cb1ab5560db67de,Move all the ansible calls into playbooks,NEW,2015-04-27 19:35:30.000000000,2017-12-18 12:13:49.000000000,,"[{'_account_id': 2}, {'_account_id': 4146}, {'_account_id': 6316}]","[{'number': 1, 'created': '2015-04-27 19:35:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/4ff7cdea45d8bd6b7e5351ac0767d36b929e35b6', 'message': 'Move all the ansible calls into playbooks\n\nNow that the input vars are in inventory variables, put the sections\nof ansible execution into playbooks, so that we can use slightly more\nadvanced ansible features, like stat.\n\nChange-Id: I89da132c0c5fad842658bbbe9cb1ab5560db67de\n'}, {'number': 2, 'created': '2015-04-28 16:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/89d0244bf1618488bd3d42aec197624b0f0f26fe', 'message': 'Move all the ansible calls into playbooks\n\nNow that the input vars are in inventory variables, put the sections\nof ansible execution into playbooks, so that we can use slightly more\nadvanced ansible features, like stat.\n\nChange-Id: I89da132c0c5fad842658bbbe9cb1ab5560db67de\n'}, {'number': 3, 'created': '2015-04-29 00:24:40.000000000', 'files': ['playbooks/setup-workspace-old.yaml', 'playbooks/cleanup-host.yaml', 'playbooks/setup-workspace-new.yaml', 'playbooks/setup-workspace.yaml', 'devstack-vm-gate-wrap.sh', 'playbooks/relocate-logs.yaml', 'playbooks/setup-host.yaml'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/0e02079743aab2ab9efd4b6b309d77adee2ec008', 'message': 'Move all the ansible calls into playbooks\n\nNow that the input vars are in inventory variables, put the sections\nof ansible execution into playbooks, so that we can use slightly more\nadvanced ansible features, like stat.\n\nChange-Id: I89da132c0c5fad842658bbbe9cb1ab5560db67de\n'}]",1,177944,0e02079743aab2ab9efd4b6b309d77adee2ec008,10,3,3,2,,,0,"Move all the ansible calls into playbooks

Now that the input vars are in inventory variables, put the sections
of ansible execution into playbooks, so that we can use slightly more
advanced ansible features, like stat.

Change-Id: I89da132c0c5fad842658bbbe9cb1ab5560db67de
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/44/177944/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/setup-workspace-old.yaml', 'playbooks/cleanup-host.yaml', 'playbooks/setup-workspace-new.yaml', 'playbooks/setup-workspace.yaml', 'devstack-vm-gate-wrap.sh', 'playbooks/relocate-logs.yaml', 'playbooks/setup-host.yaml']",7,4ff7cdea45d8bd6b7e5351ac0767d36b929e35b6,ansible-for-parallel,"--- - hosts: subnodes gather_facts: false tasks: - copy: ""src={{ workspace }}/devstack-gate dest={{ workspace }}"" - copy: ""src={{ workspace }}/test_env.sh dest={{ workspace }}/test_env.sh"" - hosts: all gather_facts: false - file: ""path='{{ workspace }}/logs' state=absent"" - file: ""path='{{ workspace }}/logs' state=directory"" - shell: ""source '{{ workspace }}/test_env.sh' && tsfilter setup_host"" executable=/bin/bash ",,48,32
openstack%2Fdevstack-gate~master~I5b35f442c5d608891ecf804418fc2a05542b6175,openstack/devstack-gate,master,I5b35f442c5d608891ecf804418fc2a05542b6175,Put input variables into ansible inventory,NEW,2015-04-27 19:35:30.000000000,2017-12-18 12:13:47.000000000,,"[{'_account_id': 4146}, {'_account_id': 6316}, {'_account_id': 7118}]","[{'number': 1, 'created': '2015-04-27 19:35:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/c59d63c3d832bea29e2191a14628e9d382b43ada', 'message': ""Put input variables into ansible inventory\n\nInstead of doing shell-substitution into ansible commands, just put the\nvariables that we need into the ansible inventory. While it's not a win\nin this patch, it paves the way for the following patch which moves\nansible commands into playbooks.\n\nChange-Id: I5b35f442c5d608891ecf804418fc2a05542b6175\n""}, {'number': 2, 'created': '2015-04-28 16:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/e8184c8f137bbf6f2b20fb64e9430693d266c83f', 'message': ""Put input variables into ansible inventory\n\nInstead of doing shell-substitution into ansible commands, just put the\nvariables that we need into the ansible inventory. While it's not a win\nin this patch, it paves the way for the following patch which moves\nansible commands into playbooks.\n\nChange-Id: I5b35f442c5d608891ecf804418fc2a05542b6175\n""}, {'number': 3, 'created': '2015-04-29 00:24:40.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/cfa80bc0a69b8ca8fbef60ac0ff2bd64fae9f318', 'message': ""Put input variables into ansible inventory\n\nInstead of doing shell-substitution into ansible commands, just put the\nvariables that we need into the ansible inventory. While it's not a win\nin this patch, it paves the way for the following patch which moves\nansible commands into playbooks.\n\nChange-Id: I5b35f442c5d608891ecf804418fc2a05542b6175\n""}]",2,177943,cfa80bc0a69b8ca8fbef60ac0ff2bd64fae9f318,10,3,3,2,,,0,"Put input variables into ansible inventory

Instead of doing shell-substitution into ansible commands, just put the
variables that we need into the ansible inventory. While it's not a win
in this patch, it paves the way for the following patch which moves
ansible commands into playbooks.

Change-Id: I5b35f442c5d608891ecf804418fc2a05542b6175
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/43/177943/3 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,c59d63c3d832bea29e2191a14628e9d382b43ada,ansible-for-parallel,"echo ""[all:vars]"" >> ""$WORKSPACE/inventory"" echo ""workspace=$WORKSPACE"" >> ""$WORKSPACE/inventory"" echo ""base=$BASE"" >> ""$WORKSPACE/inventory"" echo ""override_zuul_branch=$OVERRIDE_ZUUL_BRANCH"" >> ""$WORKSPACE/inventory"" echo ""grenade_new_branch=$GRENADE_NEW_BRANCH"" >> ""$WORKSPACE/inventory"" echo ""grenade_old_branch=$GRENADE_OLD_BRANCH"" >> ""$WORKSPACE/inventory"" # Write ansible.cfg file to set inventory mkdir -p /etc/ansible echo ""[defaults]"" > /etc/ansible/ansible.cfg echo ""hostfile $WORKSPACE/inventory"" >> /etc/ansible/ansible.cfgecho ""source '$WORKSPACE/devstack-gate/functions.sh"" >> ""$WORKSPACE/test_env.sh"" $ANSIBLE subnodes -f 5 -m copy \ -a ""src='{{ workspace }}/devstack-gate' dest='{{ workspace }}'"" $ANSIBLE subnodes -f 5 -m copy \ -a ""src='{{ workspace }}/test_env.sh' dest='{{ workspace }}/test_env.sh'""$ANSIBLE all -f 5 -m file \ -a ""path='{{ workspace }}/logs' state=absent"" $ANSIBLE all -f 5 -m file \ -a ""path='{{ workspace }}/logs' state=directory""$ANSIBLE all -f 5 -m shell \ -a ""source '{{ workspace }}/test_env.sh' && tsfilter setup_host executable=/bin/bash"" \ &> ""{{ workspace }}/logs/devstack-gate-setup-host.txt"" $ANSIBLE all -f 5 -m shell \ -a ""source '{{ workspace }}/test_env.sh' && tsfilter setup_workspace '{{ grenade_new_branch }}' '{{ base }}/new' copycache executable=/bin/bash"" \ $ANSIBLE all -f 5 -m shell \ -a ""source '{{ workspace }}/test_env.sh' && tsfilter setup_workspace '{{ grenade_old_branch }}' '{{ base }}/old' executable=/bin/bash"" \ $ANSIBLE all -f 5 -m shell \ -a ""source '{{ workspace }}/test_env.sh' && tsfilter setup_workspace '{{ override_zuul_branch }}' '{{ base }}/new' executable=/bin/bash"" \$ANSIBLE all -f 5 -m shell -a "" if [ -d '{{ workspace }}/logs' -a \! -e '{{ base }}/logs' ]; then sudo mv '{{ workspace }}/logs' '{{ base }}/' ln -s '{{ base }}/logs' '{{ workspace }}/'$ANSIBLE all -f 5 -m shell \ -a ""source '{{ workspace }}/test_env.sh' && tsfilter cleanup_host executable=/bin/bash"" \","$ANSIBLE subnodes -f 5 -i ""$WORKSPACE/inventory"" -m copy \ -a ""src='$WORKSPACE/devstack-gate' dest='$WORKSPACE'"" $ANSIBLE subnodes -f 5 -i ""$WORKSPACE/inventory"" -m copy \ -a ""src='$WORKSPACE/test_env.sh' dest='$WORKSPACE/test_env.sh'""$ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m file \ -a ""path='$WORKSPACE/logs' state=absent"" $ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m file \ -a ""path='$WORKSPACE/logs' state=directory""$ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m shell \ -a ""source '$WORKSPACE/test_env.sh' && source '$WORKSPACE/devstack-gate/functions.sh' && tsfilter setup_host executable=/bin/bash"" \ &> ""$WORKSPACE/logs/devstack-gate-setup-host.txt"" $ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m shell \ -a ""source '$WORKSPACE/test_env.sh' && source '$WORKSPACE/devstack-gate/functions.sh' && tsfilter setup_workspace '$GRENADE_NEW_BRANCH' '$BASE/new' copycache executable=/bin/bash"" \ $ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m shell \ -a ""source '$WORKSPACE/test_env.sh' && source '$WORKSPACE/devstack-gate/functions.sh' && tsfilter setup_workspace '$GRENADE_OLD_BRANCH' '$BASE/old' executable=/bin/bash"" \ $ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m shell \ -a ""source '$WORKSPACE/test_env.sh' && source '$WORKSPACE/devstack-gate/functions.sh' && tsfilter setup_workspace '$OVERRIDE_ZUUL_BRANCH' '$BASE/new' executable=/bin/bash"" \$ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m shell -a "" if [ -d '$WORKSPACE/logs' -a \! -e '$BASE/logs' ]; then sudo mv '$WORKSPACE/logs' '$BASE/' ln -s '$BASE/logs' '$WORKSPACE/'$ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m shell \ -a ""source '$WORKSPACE/test_env.sh' && source '$WORKSPACE/devstack-gate/functions.sh' && tsfilter cleanup_host executable=/bin/bash"" \",36,23
openstack%2Fdevstack-gate~master~Ic54c5286212b4f78b39d2c35ba8d18bd568f74b0,openstack/devstack-gate,master,Ic54c5286212b4f78b39d2c35ba8d18bd568f74b0,DO NOT MERGE: Examples of doing bash library commands,NEW,2015-05-05 01:33:16.000000000,2017-12-18 12:13:44.000000000,,[],"[{'number': 1, 'created': '2015-05-05 01:33:16.000000000', 'files': ['library/symlink_logs', 'library/run_command', 'devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/4f74713932d2b505066c888af6cb6201325b7677', 'message': ""DO NOT MERGE: Examples of doing bash library commands\n\nI'm not saying this is a good idea, or better than the other thing. I'm\nuploading it because I thought it would be good to have some referene on\nthe interface and how it works.\n\nChange-Id: Ic54c5286212b4f78b39d2c35ba8d18bd568f74b0\n""}]",0,179990,4f74713932d2b505066c888af6cb6201325b7677,3,0,1,2,,,0,"DO NOT MERGE: Examples of doing bash library commands

I'm not saying this is a good idea, or better than the other thing. I'm
uploading it because I thought it would be good to have some referene on
the interface and how it works.

Change-Id: Ic54c5286212b4f78b39d2c35ba8d18bd568f74b0
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/90/179990/1 && git format-patch -1 --stdout FETCH_HEAD,"['library/symlink_logs', 'library/run_command', 'devstack-vm-gate-wrap.sh']",3,4f74713932d2b505066c888af6cb6201325b7677,set-dash-e,"$ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m run_command \ -a ""WORKSPACE=$WORKSPACE COMMAND=setup_host"" &> ""$WORKSPACE/logs/devstack-gate-setup-host.txt"" $ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m run_command \ -a ""WORKSPACE=$WORKSPACE COMMAND=setup_host ARGS='$GRENADE_NEW_BRANCH $BASE/new'"" \ $ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m run_command \ -a ""WORKSPACE=$WORKSPACE COMMAND=setup_host ARGS='$GRENADE_NEW_BRANCH $BASE/old'"" \ $ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m run_command \ -a ""WORKSPACE=$WORKSPACE COMMAND=setup_workspace ARGS='$OVERRIDE_ZUUL_BRANCH $BASE/new'"" \$ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m symlink_logs \ -a ""WORKSPACE=$WORKSPACE BASE=$BASE""$ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m run_command \ -a ""WORKSPACE=$WORKSPACE COMMAND=cleanup_host"" \ &> ""$WORKSPACE/devstack-gate-cleanup-host.txt""","# little helper that runs anything passed in under tsfilter function run_command { local fn=""$@"" local cmd="""" # note that we want to keep the tsfilter separate; it's a trap for # new-players that errexit isn't applied if we do ""&& tsfilter # ..."" and thus we won't pick up any failures in the commands the # function runs. read -r -d '' cmd <<EOF source '$WORKSPACE/test_env.sh' source '$WORKSPACE/devstack-gate/functions.sh' set -o errexit tsfilter $fn executable=/bin/bash EOF echo ""$cmd"" } $ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m shell \ -a ""$(run_command setup_host)"" &> ""$WORKSPACE/logs/devstack-gate-setup-host.txt"" $ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m shell \ -a ""$(run_command setup_workspace '$GRENADE_NEW_BRANCH' '$BASE/new')"" \ $ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m shell \ -a ""$(run_command setup_workspace '$GRENADE_OLD_BRANCH' '$BASE/old')"" \ $ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m shell \ -a ""$(run_command setup_workspace '$OVERRIDE_ZUUL_BRANCH' '$BASE/new')"" \$ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m shell -a "" if [ -d '$WORKSPACE/logs' -a \! -e '$BASE/logs' ]; then sudo mv '$WORKSPACE/logs' '$BASE/' ln -s '$BASE/logs' '$WORKSPACE/' fi executable=/bin/bash""$ANSIBLE all -f 5 -i ""$WORKSPACE/inventory"" -m shell \ -a ""$(run_command cleanup_host)"" &> ""$WORKSPACE/devstack-gate-cleanup-host.txt""",44,35
openstack%2Frally~master~I78c7544828df07156d493fadfed33cae2998f73c,openstack/rally,master,I78c7544828df07156d493fadfed33cae2998f73c,Extends support for generating overlapping cidr for neutron,NEW,2015-04-16 08:31:39.000000000,2017-12-18 12:13:27.000000000,,"[{'_account_id': 8576}, {'_account_id': 10475}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-04-16 08:31:39.000000000', 'files': ['tests/unit/benchmark/scenarios/neutron/test_utils.py', 'rally/benchmark/wrappers/network.py', 'tests/unit/benchmark/scenarios/neutron/test_network.py', 'rally/benchmark/scenarios/neutron/network.py', 'rally/benchmark/scenarios/neutron/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/8c7cf44514afb9b070531c3407c121e45e7e4684', 'message': ""Extends support for generating overlapping cidr for neutron\n\nNew parameter called overlapping_ip introduced for the neutron scenario's\nto generate overlapping cidr (overlapping_ip=true) or non-overlapping\ncidr (overlapping_ip=false). Since different clouds behave differently\nfor different types of cidr, overlapping cidr's is the most common\nusecase.\n\nChange-Id: I78c7544828df07156d493fadfed33cae2998f73c\nCloses-Bug: #1442124\n""}]",2,174251,8c7cf44514afb9b070531c3407c121e45e7e4684,7,3,1,11893,,,0,"Extends support for generating overlapping cidr for neutron

New parameter called overlapping_ip introduced for the neutron scenario's
to generate overlapping cidr (overlapping_ip=true) or non-overlapping
cidr (overlapping_ip=false). Since different clouds behave differently
for different types of cidr, overlapping cidr's is the most common
usecase.

Change-Id: I78c7544828df07156d493fadfed33cae2998f73c
Closes-Bug: #1442124
",git fetch https://review.opendev.org/openstack/rally refs/changes/51/174251/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/benchmark/scenarios/neutron/test_utils.py', 'rally/benchmark/wrappers/network.py', 'tests/unit/benchmark/scenarios/neutron/test_network.py', 'rally/benchmark/scenarios/neutron/network.py', 'rally/benchmark/scenarios/neutron/utils.py']",5,8c7cf44514afb9b070531c3407c121e45e7e4684,overlapping_ip," def _create_subnet(self, network, subnet_create_args, start_cidr=None, overlapping_ip=False): network_wrapper.generate_cidr(start_cidr=start_cidr, overlapping_ip=overlapping_ip)) subnet_cidr_start=""1.0.0.0/24"", overlapping_ip=False): subnet_cidr_start, overlapping_ip)"," def _create_subnet(self, network, subnet_create_args, start_cidr=None): network_wrapper.generate_cidr(start_cidr=start_cidr)) subnet_cidr_start=""1.0.0.0/24""): subnet_cidr_start)",97,48
openstack%2Frally~master~Ic67121c46ace4b8dcda08966a59b93540283ebf1,openstack/rally,master,Ic67121c46ace4b8dcda08966a59b93540283ebf1,Simultaneous Runner for orchestrating processes,NEW,2015-05-22 08:21:22.000000000,2017-12-18 12:13:05.000000000,,"[{'_account_id': 9601}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-22 08:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/abcc8a5423cf877ce39c4975230d2564b27048b8', 'message': 'Simultaneous Runner for orchestrating processes\n\nWhile benchmarking methods that run after time consuming processes, one\ncould make sure parallel processes are in the same moment in code before\ngoing forward. New runner gives posibility to wait for task finalizing\nand synchronization between processes.\n\nE.g. during live migration benchmarking of multiple VM instances we want\nto be sure that all VMs are ready and all in the same state. With\nexisting runners this is not the case because VM launching takes\ndifferent amount of time. Additionaly, we could wait not for VMs being\nactive, but for VMs start real task processing.\n\nChange-Id: Ic67121c46ace4b8dcda08966a59b93540283ebf1\n'}, {'number': 2, 'created': '2015-05-25 18:03:32.000000000', 'files': ['samples/tasks/runners/simultaneous/boot-and-live-migrate.json', 'rally/plugins/common/runners/simultaneous.py', 'samples/tasks/runners/simultaneous/boot-and-live-migrate.yaml', 'tests/unit/plugins/common/runners/test_simultaneous.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/f02f7ce2fdf5330bdc6af37c7d181958d14c77ca', 'message': 'Simultaneous Runner for orchestrating processes\n\nNew runner is usefull for synchronization of time consuming methods.\nUser might want to be sure that parallel processes are waiting for each\nother in defined place of code. With this runner user has such\nposibility\n\nE.g. during live migration benchmarking of multiple VM instances we want\nto be sure that all VMs are ready and all in the same state. With\nexisting runners this is not the case because VM launching takes\ndifferent amount of time. Additionaly, we could wait not for VMs being\nactive, but for VMs start real task processing.\n\nChange-Id: Ic67121c46ace4b8dcda08966a59b93540283ebf1\n'}]",4,184972,f02f7ce2fdf5330bdc6af37c7d181958d14c77ca,8,2,2,13585,,,0,"Simultaneous Runner for orchestrating processes

New runner is usefull for synchronization of time consuming methods.
User might want to be sure that parallel processes are waiting for each
other in defined place of code. With this runner user has such
posibility

E.g. during live migration benchmarking of multiple VM instances we want
to be sure that all VMs are ready and all in the same state. With
existing runners this is not the case because VM launching takes
different amount of time. Additionaly, we could wait not for VMs being
active, but for VMs start real task processing.

Change-Id: Ic67121c46ace4b8dcda08966a59b93540283ebf1
",git fetch https://review.opendev.org/openstack/rally refs/changes/72/184972/1 && git format-patch -1 --stdout FETCH_HEAD,"['samples/tasks/runners/simultaneous/boot-and-live-migrate.json', 'rally/plugins/common/runners/simultaneous.py', 'tests/unit/plugins/common/runners/test_simultaneous.py']",3,abcc8a5423cf877ce39c4975230d2564b27048b8,host-maintenance,"# Copyright (C) 2015 Intel Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from rally.plugins.common.runners import simultaneous from tests.unit import test, fakes NOVA_UTILS = ""rally.benchmark.scenarios.nova.utils."" RUNNERS_BASE = ""rally.benchmark.runners.base."" RUNNERS = ""rally.plugins.common.runners."" class SimultaneousScenarioRunnerTestCase(test.TestCase): def setUp(self): self.task = mock.MagicMock() self.concurrency = 10 self.dummy_config = {""concurrency"": self.concurrency} self.config = { ""concurrency"": self.concurrency, ""orchestrate"": NOVA_UTILS + ""NovaScenario._live_migrate"" } super(SimultaneousScenarioRunnerTestCase, self).setUp() @mock.patch(RUNNERS + ""simultaneous.multiprocessing.Queue"") @mock.patch(RUNNERS + ""simultaneous.base"") def test__worker_process(self, mock_base, mock_queue): # prepare fake_ram_int = iter(range(10)) context = {""users"": [{""tenant_id"": ""t1"", ""endpoint"": ""e1"", ""id"": ""uuid1""}]} info = {""processes_to_start"": 1, ""processes_counter"": 1} # run simultaneous._worker_process(mock_queue, fake_ram_int, ""Dummy"", ""dummy"", context, (), info) # check mock_base._get_scenario_context.assert_called_once_with(context) @mock.patch(""rally.benchmark.runners.base._run_scenario_once"") def test__run_scenario(self, mock_run_once): # prepare result = {""duration"": 10, ""idle_duration"": 0, ""error"": [], ""scenario_output"": {}, ""atomic_actions"": {}} mock_run_once.return_value = result expected_results = [result for i in range(self.concurrency)] runner = simultaneous.SimultaneousScenarioRunner(self.task, self.dummy_config) # run runner._run_scenario(fakes.FakeScenario, ""do_it"", fakes.FakeUserContext({}).context, {}) # check results = list(runner.result_queue) self.assertEqual(len(runner.result_queue), self.concurrency) self.assertEqual(results, expected_results) @mock.patch.object(simultaneous.DummyOrchestrator, ""orchestrate"") def test__dummy_orchestrator(self, mock_orchestrate): # prepare runner = simultaneous.SimultaneousScenarioRunner(self.task, self.dummy_config) # run runner._run_scenario(fakes.FakeScenario, ""do_it"", fakes.FakeUserContext({}).context, {}) # check mock_orchestrate.assert_called_once_with() @mock.patch.object(simultaneous.Orchestrator, ""orchestrate"") def test__orchestrator(self, mock_orchestrate): # prepare runner = simultaneous.SimultaneousScenarioRunner(self.task, self.config) # run runner._run_scenario(fakes.FakeScenario, ""do_it"", fakes.FakeUserContext({}).context, {}) # check mock_orchestrate.assert_called_once_with() ",,280,0
openstack%2Fswift~master~I57d0fc8b2b92e1b07478b4e4a7a30641ca5bdfa2,openstack/swift,master,I57d0fc8b2b92e1b07478b4e4a7a30641ca5bdfa2,WIP Revert to another handoff when primary is unavailable,NEW,2015-04-22 17:26:09.000000000,2017-12-18 12:12:25.000000000,,"[{'_account_id': 330}, {'_account_id': 7847}]","[{'number': 1, 'created': '2015-04-22 17:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4d26a24676b2e7f7f36440a447877dd9780520b4', 'message': ""WIP Revert to another handoff when primary is unavailable\n\nWIP because:\n(a) we need to decide if this is the right thing to do.\n(b) I have a concern about a potential race, called out\nin the probe test.\n\nFix a KeyError when reconstructor attempted to revert\nto another handoff node (which has no 'index' key) by\nsetting the node's index to the job's frag_index.\n\nThis means that reconstructor will now attempt reverts to\nanother handoff. Those reverts may result in HTTP_CONFLICT\nif the other handoff has another fragment for the same object.\nThat causes ssync to fail and return an empty dict of in sync\nobjects, even when *some* fragments were successfully reverted.\nThat results in those fragments being duplicated on both handoff\nnodes.\n\nSo, this patch also changes ssync_sender to return the dict of\nobjects that are known to be in sync, regardless of the outcome\nof its updates. This at least means that duplicate fragments will\nbe cleaned up on a subsequent reconstructor run.\n\nBetter, but not yet implemented here, would be for ssync_sender to\nalso include objects that were successfuly sync'd during the updates\nphase. That will require the ssync_receiver returning individual\nsubrequest response status.\n\nChange-Id: I57d0fc8b2b92e1b07478b4e4a7a30641ca5bdfa2\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n""}, {'number': 2, 'created': '2015-04-24 13:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/430a3040f63a9c6eb4bf612e51c6b962e7d8c0a5', 'message': ""WIP Revert to another handoff when primary is unavailable\n\nWIP because:\n(a) we need to decide if this is the right thing to do.\n(b) I have a concern about a potential race, called out\nin the probe test.\n\nFix a KeyError when reconstructor attempted to revert\nto another handoff node (which has no 'index' key) by\nsetting the node's index to the job's frag_index.\n\nThis means that reconstructor will now attempt reverts to\nanother handoff. Those reverts may result in HTTP_CONFLICT\nif the other handoff has another fragment for the same object.\nThat causes ssync to fail and return an empty dict of in sync\nobjects, even when *some* fragments were successfully reverted.\nThat results in those fragments being duplicated on both handoff\nnodes.\n\nSo, this patch also changes ssync_sender to return the dict of\nobjects that are known to be in sync, regardless of the outcome\nof its updates. This at least means that duplicate fragments will\nbe cleaned up on a subsequent reconstructor run.\n\nBetter, but not yet implemented here, would be for ssync_sender to\nalso include objects that were successfuly sync'd during the updates\nphase. That will require the ssync_receiver returning individual\nsubrequest response status.\n\nChange-Id: I57d0fc8b2b92e1b07478b4e4a7a30641ca5bdfa2\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n""}, {'number': 3, 'created': '2015-04-27 15:52:10.000000000', 'files': ['test/probe/common.py', 'test/probe/test_reconstructor_revert.py', 'swift/obj/reconstructor.py', 'swift/obj/ssync_sender.py', 'test/unit/obj/test_reconstructor.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/9e814d81807f125a82a2f15b05504cdc4cf5355f', 'message': ""WIP Revert to another handoff when primary is unavailable\n\nWIP because:\n(a) we need to decide if this is the right thing to do.\n(b) I have a concern about a potential race, called out\nin the probe test.\n\nFix a KeyError when reconstructor attempted to revert\nto another handoff node (which has no 'index' key) by\nsetting the node's index to the job's frag_index.\n\nThis means that reconstructor will now attempt reverts to\nanother handoff. Those reverts may result in HTTP_CONFLICT\nif the other handoff has another fragment for the same object.\nThat causes ssync to fail and return an empty dict of in sync\nobjects, even when *some* fragments were successfully reverted.\nThat results in those fragments being duplicated on both handoff\nnodes.\n\nSo, this patch also changes ssync_sender to return the dict of\nobjects that are known to be in sync, regardless of the outcome\nof its updates. This at least means that duplicate fragments will\nbe cleaned up on a subsequent reconstructor run.\n\nBetter, but not yet implemented here, would be for ssync_sender to\nalso include objects that were successfuly sync'd during the updates\nphase. That will require the ssync_receiver returning individual\nsubrequest response status.\n\nChange-Id: I57d0fc8b2b92e1b07478b4e4a7a30641ca5bdfa2\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n""}]",1,176403,9e814d81807f125a82a2f15b05504cdc4cf5355f,11,2,3,7847,,,0,"WIP Revert to another handoff when primary is unavailable

WIP because:
(a) we need to decide if this is the right thing to do.
(b) I have a concern about a potential race, called out
in the probe test.

Fix a KeyError when reconstructor attempted to revert
to another handoff node (which has no 'index' key) by
setting the node's index to the job's frag_index.

This means that reconstructor will now attempt reverts to
another handoff. Those reverts may result in HTTP_CONFLICT
if the other handoff has another fragment for the same object.
That causes ssync to fail and return an empty dict of in sync
objects, even when *some* fragments were successfully reverted.
That results in those fragments being duplicated on both handoff
nodes.

So, this patch also changes ssync_sender to return the dict of
objects that are known to be in sync, regardless of the outcome
of its updates. This at least means that duplicate fragments will
be cleaned up on a subsequent reconstructor run.

Better, but not yet implemented here, would be for ssync_sender to
also include objects that were successfuly sync'd during the updates
phase. That will require the ssync_receiver returning individual
subrequest response status.

Change-Id: I57d0fc8b2b92e1b07478b4e4a7a30641ca5bdfa2
Co-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/03/176403/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/probe/test_reconstructor_revert.py', 'swift/obj/reconstructor.py', 'swift/obj/ssync_sender.py', 'test/unit/obj/test_reconstructor.py']",4,4d26a24676b2e7f7f36440a447877dd9780520b4,p-revert-to-handoff," # ssync gets called for the primary plus all of the handoffs - except # the last one (which is the local_dev) # this is ssync call to primary # ... plus all the calls to handoffs for i, call in enumerate(ssync_calls[1:]): handoff_node = handoff_nodes[i] handoff_node['index'] = job['frag_index'] self.assertEqual(call['node'], handoff_node) self.assertEqual(set(call['suffixes']), set(['123', 'abc']))", # this is ssync call to primary (which fails) plus the ssync call to # all of the handoffs (except the last one - which is the local_dev),274,15
openstack%2Fpython-swiftclient~master~I355ad2827a2f7c14526db6bbb691cc2d2a880b2a,openstack/python-swiftclient,master,I355ad2827a2f7c14526db6bbb691cc2d2a880b2a,Rename `obj` to `name` in *_object wrappers,NEW,2015-06-09 17:07:22.000000000,2017-12-18 12:12:20.000000000,,"[{'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 9216}, {'_account_id': 11356}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-09 17:07:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/ba47cbe51074f7506cf1d6bcde12ee0a3fafb631', 'message': 'Rename `obj` to `name` in *_object wrappers\n\nThis patch renames `obj` to `name` in the function signatures of\nclient.Connection.get_object and similar. This aims to reduce the\nambiguity of the autogenerated documentation, since the functions\nrequire the name of the swift object, not a reference to a python\nobject. The methods which are wrapped also refer to it as `name`.\n\nChange-Id: I355ad2827a2f7c14526db6bbb691cc2d2a880b2a\n'}, {'number': 2, 'created': '2015-06-24 22:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/dcfc94c11d66eca64da399d8e6f804079bd9e8ad', 'message': 'Rename `obj` to `name` in *_object wrappers\n\nThis patch renames `obj` to `name` in the function signatures of\nclient.Connection.get_object and similar. This aims to reduce the\nambiguity of the autogenerated documentation, since the functions\nrequire the name of the swift object, not a reference to a python\nobject. The methods which are wrapped also refer to it as `name`.\n\nDepends-On: I3f4e3eb8d91edbfd10dc2233e3e83a3f90313cac\nChange-Id: I355ad2827a2f7c14526db6bbb691cc2d2a880b2a\n'}, {'number': 3, 'created': '2015-06-25 09:13:15.000000000', 'files': ['swiftclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/e84f58815a71662697a0f47088be0cf929aa9d8b', 'message': 'Rename `obj` to `name` in *_object wrappers\n\nThis patch renames `obj` to `name` in the function signatures of\nclient.Connection.get_object and similar. This aims to reduce the\nambiguity of the autogenerated documentation, since the functions\nrequire the name of the swift object, not a reference to a python\nobject. The methods which are wrapped also refer to it as `name`.\n\nDepends-On: I3f4e3eb8d91edbfd10dc2233e3e83a3f90313cac\nChange-Id: I355ad2827a2f7c14526db6bbb691cc2d2a880b2a\n'}]",0,189815,e84f58815a71662697a0f47088be0cf929aa9d8b,42,5,3,11356,,,0,"Rename `obj` to `name` in *_object wrappers

This patch renames `obj` to `name` in the function signatures of
client.Connection.get_object and similar. This aims to reduce the
ambiguity of the autogenerated documentation, since the functions
require the name of the swift object, not a reference to a python
object. The methods which are wrapped also refer to it as `name`.

Depends-On: I3f4e3eb8d91edbfd10dc2233e3e83a3f90313cac
Change-Id: I355ad2827a2f7c14526db6bbb691cc2d2a880b2a
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/15/189815/2 && git format-patch -1 --stdout FETCH_HEAD,['swiftclient/client.py'],1,ba47cbe51074f7506cf1d6bcde12ee0a3fafb631,," def head_object(self, container, name): return self._retry(None, head_object, container, name) def get_object(self, container, name, resp_chunk_size=None, return self._retry(None, get_object, container, name, def put_object(self, container, name, contents, content_length=None, % (container, name)) return self._retry(reset_func, put_object, container, name, contents, def post_object(self, container, name, headers, response_dict=None): return self._retry(None, post_object, container, name, headers, def delete_object(self, container, name, query_string=None, return self._retry(None, delete_object, container, name,"," def head_object(self, container, obj): return self._retry(None, head_object, container, obj) def get_object(self, container, obj, resp_chunk_size=None, return self._retry(None, get_object, container, obj, def put_object(self, container, obj, contents, content_length=None, % (container, obj)) return self._retry(reset_func, put_object, container, obj, contents, def post_object(self, container, obj, headers, response_dict=None): return self._retry(None, post_object, container, obj, headers, def delete_object(self, container, obj, query_string=None, return self._retry(None, delete_object, container, obj,",11,11
openstack%2Frally~master~Icab0d347f3771125ebaaa527ccbe47758c5801f7,openstack/rally,master,Icab0d347f3771125ebaaa527ccbe47758c5801f7,New scenario for sample complex query,NEW,2015-06-25 12:28:26.000000000,2017-12-18 12:12:07.000000000,,"[{'_account_id': 14347}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-06-25 12:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ef092c3a1122019737542b55f4be689c5db18a6e', 'message': 'New scenario for sample complex query\n\nNow we have one scenario for sample complex query.\nIn this scenario created one sample and made query\nfor this sample.\n\nIn this patch created one more scenario.\n\nIn this scenario created many samples and made query\nfor this samples.\n\nChange-Id: Icab0d347f3771125ebaaa527ccbe47758c5801f7\n'}, {'number': 2, 'created': '2015-06-26 12:04:58.000000000', 'files': ['rally/plugins/openstack/scenarios/ceilometer/queries.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_queries.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/1df530660c14b873079af2cbbfdb6adc7c5545fc', 'message': 'New scenario for sample complex query\n\nNow we have one scenario for sample complex query.\nIn this scenario created one sample and made query\nfor this sample.\n\nIn this patch created one more scenario.\n\nIn this scenario created many samples and made query\nfor this samples.\n\nChange-Id: Icab0d347f3771125ebaaa527ccbe47758c5801f7\n'}]",0,195551,1df530660c14b873079af2cbbfdb6adc7c5545fc,9,2,2,14347,,,0,"New scenario for sample complex query

Now we have one scenario for sample complex query.
In this scenario created one sample and made query
for this sample.

In this patch created one more scenario.

In this scenario created many samples and made query
for this samples.

Change-Id: Icab0d347f3771125ebaaa527ccbe47758c5801f7
",git fetch https://review.opendev.org/openstack/rally refs/changes/51/195551/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/scenarios/ceilometer/queries.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_queries.py']",2,ef092c3a1122019737542b55f4be689c5db18a6e,test_sample_query," scenario.create_and_query_sample(""fake_counter_name"", ""fake_counter_type"", ""fake_counter_unit"", ""fake_counter_volume"", ""fake_resource_id"", ""fake_filter"", ""fake_orderby_attribute"", 10, fakearg=""f"") scenario.create_and_query_sample(""fake_counter_name"", ""fake_counter_type"", ""fake_counter_unit"", ""fake_counter_volume"", ""fake_resource_id"", None, ""fake_orderby_attribute"", 10, fakearg=""f"")"," scenario.create_and_query_samples(""fake_counter_name"", ""fake_counter_type"", ""fake_counter_unit"", ""fake_counter_volume"", ""fake_resource_id"", ""fake_filter"", ""fake_orderby_attribute"", 10, fakearg=""f"") scenario.create_and_query_samples(""fake_counter_name"", ""fake_counter_type"", ""fake_counter_unit"", ""fake_counter_volume"", ""fake_resource_id"", None, ""fake_orderby_attribute"", 10, fakearg=""f"")",43,19
openstack%2Fswift~master~I43cf294879dd1852409442a0e3c55533e41573b3,openstack/swift,master,I43cf294879dd1852409442a0e3c55533e41573b3,Added a check for request_method other than POST in formPOST middleware,NEW,2015-07-05 14:25:46.000000000,2017-12-18 12:11:52.000000000,,[{'_account_id': 6968}],"[{'number': 1, 'created': '2015-07-05 14:25:46.000000000', 'files': ['swift/common/middleware/formpost.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/25bb1e67bec888461210ff08dd73f76b832b2e33', 'message': 'Added a check for request_method other than POST in formPOST middleware\n\nChange-Id: I43cf294879dd1852409442a0e3c55533e41573b3\nCloses-Bug: 1471548\n'}]",0,198543,25bb1e67bec888461210ff08dd73f76b832b2e33,5,1,1,15153,,,0,"Added a check for request_method other than POST in formPOST middleware

Change-Id: I43cf294879dd1852409442a0e3c55533e41573b3
Closes-Bug: 1471548
",git fetch https://review.opendev.org/openstack/swift refs/changes/43/198543/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/middleware/formpost.py'],1,25bb1e67bec888461210ff08dd73f76b832b2e33,bug/1471548,"from swift.common.swob import HTTPUnauthorized, HTTPMethodNotAllowed if env['REQUEST_METHOD'] != 'POST': raise HTTPMethodNotAllowed() try: content_type, attrs = \ parse_content_disposition(env.get('CONTENT_TYPE') or '') if content_type == 'multipart/form-data' and \ 'boundary' in attrs: http_user_agent = ""%s FormPost"" % ( env.get('HTTP_USER_AGENT', '')) env['HTTP_USER_AGENT'] = http_user_agent.strip() status, headers, body = self._translate_form( env, attrs['boundary']) start_response(status, headers) except MimeInvalid: body = 'FormPost: invalid starting boundary' start_response( '400 Bad Request', (('Content-Type', 'text/plain'), ('Content-Length', str(len(body))))) return [body] except (FormInvalid, EOFError) as err: body = 'FormPost: %s' % err start_response( '400 Bad Request', (('Content-Type', 'text/plain'), ('Content-Length', str(len(body))))) return [body] except FormUnauthorized as err: message = 'FormPost: %s' % str(err).title() return HTTPUnauthorized(body=message)( env, start_response)","from swift.common.swob import HTTPUnauthorized if env['REQUEST_METHOD'] == 'POST': try: content_type, attrs = \ parse_content_disposition(env.get('CONTENT_TYPE') or '') if content_type == 'multipart/form-data' and \ 'boundary' in attrs: http_user_agent = ""%s FormPost"" % ( env.get('HTTP_USER_AGENT', '')) env['HTTP_USER_AGENT'] = http_user_agent.strip() status, headers, body = self._translate_form( env, attrs['boundary']) start_response(status, headers) return [body] except MimeInvalid: body = 'FormPost: invalid starting boundary' start_response( '400 Bad Request', (('Content-Type', 'text/plain'), ('Content-Length', str(len(body))))) except (FormInvalid, EOFError) as err: body = 'FormPost: %s' % err start_response( '400 Bad Request', (('Content-Type', 'text/plain'), ('Content-Length', str(len(body))))) return [body] except FormUnauthorized as err: message = 'FormPost: %s' % str(err).title() return HTTPUnauthorized(body=message)( env, start_response)",32,31
openstack%2Frally~master~Ic1e13a09c01614794318c6588426c6fe8b908e66,openstack/rally,master,Ic1e13a09c01614794318c6588426c6fe8b908e66,Add context for Designate Domains,NEW,2015-06-24 11:17:32.000000000,2017-12-18 12:11:37.000000000,,"[{'_account_id': 6835}, {'_account_id': 10185}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-06-24 11:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b28d3d3d1fc553a8f83a7d41e15ebff75675f4ed', 'message': 'Adds context for Designate Domains\n\nThis submission adds file designate.py\nunder rally/plugins/openstack/context/designate.py\nAlso, adds corresponding unittests under\ntests/unit/plugins/openstack/context/test_designate.py\n\nChange-Id: Ic1e13a09c01614794318c6588426c6fe8b908e66\n'}, {'number': 2, 'created': '2015-06-29 10:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c5a3ad24eea57c25a46ee04a0a5e26a1bfd1a785', 'message': 'Add context for Designate Domains\n\nChange-Id: Ic1e13a09c01614794318c6588426c6fe8b908e66\n'}, {'number': 3, 'created': '2015-07-07 07:31:00.000000000', 'files': ['rally/plugins/openstack/context/designate.py', 'samples/tasks/scenarios/designate/create-and-list-records.yaml', 'tests/unit/plugins/openstack/context/test_designate.py', 'samples/tasks/scenarios/designate/create-and-delete-records.yaml', 'samples/tasks/scenarios/designate/create-and-list-records.json', 'rally/plugins/openstack/scenarios/designate/basic.py', 'samples/tasks/scenarios/designate/create-and-delete-records.json'], 'web_link': 'https://opendev.org/openstack/rally/commit/cd6d634bdf06b8c1cc286c2452766743240719cc', 'message': 'Add context for Designate Domains\n\nModified scenarios create_and_delete_records,\ncreate_and_list_records so as to use the\ndomain context.\n\nChange-Id: Ic1e13a09c01614794318c6588426c6fe8b908e66\n'}]",10,195039,cd6d634bdf06b8c1cc286c2452766743240719cc,17,4,3,1687,,,0,"Add context for Designate Domains

Modified scenarios create_and_delete_records,
create_and_list_records so as to use the
domain context.

Change-Id: Ic1e13a09c01614794318c6588426c6fe8b908e66
",git fetch https://review.opendev.org/openstack/rally refs/changes/39/195039/2 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/context/designate.py', 'tests/unit/plugins/openstack/context/test_designate.py']",2,b28d3d3d1fc553a8f83a7d41e15ebff75675f4ed,designate/domain-context,"# All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy import mock from rally.plugins.openstack.context import designate from tests.unit import fakes from tests.unit import test CTX = ""rally.plugins.openstack.context"" SCN = ""rally.plugins.openstack.scenarios"" class DesignateDomainGeneratorTestCase(test.TestCase): def _gen_tenants(self, count): tenants = {} for id in range(count): tenants[str(id)] = dict(name=str(id)) return tenants def test_init(self): context = {} context[""task""] = mock.MagicMock() context[""config""] = { ""designate"": { ""domains_per_tenant"": 5, } } inst = designate.DesignateDomainGenerator(context) self.assertEqual(inst.config, context[""config""][""designate""]) @mock.patch(""%s.designate.utils.DesignateScenario._create_domain"" % SCN, return_value={""id"": ""uuid""}) @mock.patch(""%s.designate.osclients"" % CTX) def test_setup(self, mock_osclients, mock_designate_scenario__create_domain): fc = fakes.FakeClients() mock_osclients.Clients.return_value = fc tenants_count = 2 users_per_tenant = 5 domains_per_tenant = 5 tenants = self._gen_tenants(tenants_count) users = [] for id in tenants.keys(): for i in range(users_per_tenant): users.append({""id"": i, ""tenant_id"": id, ""endpoint"": ""endpoint""}) real_context = { ""config"": { ""users"": { ""tenants"": 2, ""users_per_tenant"": 5, ""concurrent"": 10, }, ""designate"": { ""domains_per_tenant"": 5, } }, ""admin"": { ""endpoint"": mock.MagicMock() }, ""task"": mock.MagicMock(), ""users"": users, ""tenants"": tenants } new_context = copy.deepcopy(real_context) for id in tenants.keys(): new_context[""tenants""][id].setdefault(""domains"", list()) for i in range(domains_per_tenant): new_context[""tenants""][id][""domains""].append({""id"": ""uuid""}) domains_ctx = designate.DesignateDomainGenerator(real_context) domains_ctx.setup() self.assertEqual(new_context, real_context) @mock.patch(""%s.designate.osclients"" % CTX) @mock.patch(""%s.designate.resource_manager.cleanup"" % CTX) def test_cleanup(self, mock_cleanup, mock_osclients): tenants_count = 2 users_per_tenant = 5 domains_per_tenant = 5 tenants = self._gen_tenants(tenants_count) users = [] for id in tenants.keys(): for i in range(users_per_tenant): users.append({""id"": i, ""tenant_id"": id, ""endpoint"": ""endpoint""}) tenants[id].setdefault(""domains"", list()) for j in range(domains_per_tenant): tenants[id][""domains""].append({""id"": ""uuid""}) context = { ""config"": { ""users"": { ""tenants"": 2, ""users_per_tenant"": 5, ""concurrent"": 10, }, ""designate"": { ""domains_per_tenant"": 5, } }, ""admin"": { ""endpoint"": mock.MagicMock() }, ""task"": mock.MagicMock(), ""users"": users, ""tenants"": tenants } designate_ctx = designate.DesignateDomainGenerator(context) designate_ctx.cleanup() mock_cleanup.assert_called_once_with(names=[""designate.domains""], users=context[""users""]) ",,205,0
openstack%2Frally~master~I2b7b9a5ed062c1023268415cd25926e05fde3f08,openstack/rally,master,I2b7b9a5ed062c1023268415cd25926e05fde3f08,Ability to boot VMs on each compute node Also add ability for rally to create admin users since VMs will be associated with right users Plus do not have to change all utility functions https://blueprints.launchpad.net/rally/+spec/rally-hypervisor-boot,NEW,2015-01-31 22:54:45.000000000,2017-12-18 12:11:04.000000000,,"[{'_account_id': 8576}, {'_account_id': 10068}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 16215}]","[{'number': 1, 'created': '2015-01-31 22:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5bb79eedbf8d8f24fe2a40ac8c76dc045f9b091a', 'message': 'Ability to boot VMs on each compute node\nAlso add ability for rally to create admin users since VMs will be associated with right users\nPlus do not have to change all utility functions\nhttps://blueprints.launchpad.net/rally/+spec/rally-hypervisor-boot\n\nChange-Id: I2b7b9a5ed062c1023268415cd25926e05fde3f08\n'}, {'number': 2, 'created': '2015-06-08 09:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/42ecb959735c67b0902f1c99e4b3406ddf24c236', 'message': 'Ability to boot VMs on each compute node\nAlso add ability for rally to create admin users since VMs will be associated with right users\nPlus do not have to change all utility functions\nhttps://blueprints.launchpad.net/rally/+spec/rally-hypervisor-boot\n\nChange-Id: I2b7b9a5ed062c1023268415cd25926e05fde3f08\n'}, {'number': 3, 'created': '2015-06-08 23:25:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/fb9bfd56107d0f6c23eda891c84d584e153b5a13', 'message': 'Ability to boot VMs on each compute node\nAlso add ability for rally to create admin users since VMs will be associated with right users\nPlus do not have to change all utility functions\nhttps://blueprints.launchpad.net/rally/+spec/rally-hypervisor-boot\n\nChange-Id: I2b7b9a5ed062c1023268415cd25926e05fde3f08\n'}, {'number': 4, 'created': '2015-07-21 22:45:40.000000000', 'files': ['rally/plugins/openstack/wrappers/keystone.py', 'rally/plugins/openstack/scenarios/nova/utils.py', 'rally/plugins/openstack/context/keystone/users.py', 'rally/plugins/openstack/context/nova/servers.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/ba3553bd247baea5d9a0136bc8e20370010c8b50', 'message': 'Ability to boot VMs on each compute node\nAlso add ability for rally to create admin users since VMs will be associated with right users\nPlus do not have to change all utility functions\nhttps://blueprints.launchpad.net/rally/+spec/rally-hypervisor-boot\n\nChange-Id: I2b7b9a5ed062c1023268415cd25926e05fde3f08\n'}]",20,151899,ba3553bd247baea5d9a0136bc8e20370010c8b50,21,5,4,14924,,,0,"Ability to boot VMs on each compute node
Also add ability for rally to create admin users since VMs will be associated with right users
Plus do not have to change all utility functions
https://blueprints.launchpad.net/rally/+spec/rally-hypervisor-boot

Change-Id: I2b7b9a5ed062c1023268415cd25926e05fde3f08
",git fetch https://review.opendev.org/openstack/rally refs/changes/99/151899/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/nova/utils.py', 'rally/benchmark/scenarios/nova/servers.py', 'samples/tasks/scenarios/nova/boot-hypervisor-list.yaml', 'samples/tasks/scenarios/nova/boot-hypervisor-list.json', 'rally/benchmark/wrappers/keystone.py', 'rally/benchmark/context/users.py']",6,5bb79eedbf8d8f24fe2a40ac8c76dc045f9b091a,bp/s," cfg.StrOpt(""user_role"", default=None, help=""Additional (admin) role for users""), ""user_role"": { ""type"": ""string"", }, self.config.setdefault(""user_role"", cfg.CONF.users_context.user_role) self.config[""user_domain""], tenant_id, self.config[""user_role""]) username, password, project_dom, user_dom, tenant_id, user_role = args if user_role: client.add_user_role(user.id, user_role, project_id=tenant_id)"," self.config[""user_domain""], tenant_id) username, password, project_dom, user_dom, tenant_id = args",137,3
openstack%2Fdevstack-gate~master~I15d092993a30864cafc65c32d69e79100e8d54f3,openstack/devstack-gate,master,I15d092993a30864cafc65c32d69e79100e8d54f3,"Revert part of ""Allow to configure git base URL""",NEW,2015-02-04 19:32:15.000000000,2017-12-18 12:10:45.000000000,,"[{'_account_id': 1}, {'_account_id': 1921}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-02-04 19:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/73cf018c005d5d82834264bab31bdedfb06a5ed5', 'message': 'Revert ""Allow to configure git base URL""\n\nThis was implemented without adequate discussion and should be\nreviewed in a broader context. See post-merge comments on\nI59c1c63d6e8ac8482821728bf03bfce69898e919 for details.\n\nThis reverts commit 537a2926745a2acbacfa682295f06fa44c42716a.\n\nChange-Id: I15d092993a30864cafc65c32d69e79100e8d54f3\n'}, {'number': 2, 'created': '2015-02-04 19:42:34.000000000', 'files': ['sub_node_prepare.sh', 'devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/62a8c36d9dce912b5dda478d5e53680d33d70b4e', 'message': 'Revert part of ""Allow to configure git base URL""\n\nThe GIT_BRANCH part of this was implemented without adequate\ndiscussion and should be reviewed in a broader context. See\npost-merge comments on I59c1c63d6e8ac8482821728bf03bfce69898e919 for\ndetails.\n\nThis reverts part of commit 537a2926745a2acbacfa682295f06fa44c42716a.\n\nChange-Id: I15d092993a30864cafc65c32d69e79100e8d54f3\n'}]",0,153023,62a8c36d9dce912b5dda478d5e53680d33d70b4e,16,4,2,5263,,,0,"Revert part of ""Allow to configure git base URL""

The GIT_BRANCH part of this was implemented without adequate
discussion and should be reviewed in a broader context. See
post-merge comments on I59c1c63d6e8ac8482821728bf03bfce69898e919 for
details.

This reverts part of commit 537a2926745a2acbacfa682295f06fa44c42716a.

Change-Id: I15d092993a30864cafc65c32d69e79100e8d54f3
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/23/153023/1 && git format-patch -1 --stdout FETCH_HEAD,"['sub_node_prepare.sh', 'devstack-vm-gate-wrap.sh', 'functions.sh']",3,73cf018c005d5d82834264bab31bdedfb06a5ed5,custom_git, git clone https://git.openstack.org/$project git_remote_set_url origin https://git.openstack.org/$project, local git_base=${GIT_BASE:-https://git.openstack.org} git clone $git_base/$project local git_base=${GIT_BASE:-https://git.openstack.org} git_remote_set_url origin $git_base/$project,6,13
openstack%2Fswift~master~I36d7d32b5521d9e000c6aa78746780d6a2791091,openstack/swift,master,I36d7d32b5521d9e000c6aa78746780d6a2791091,Basic container sharding middleware,NEW,2014-10-02 05:27:47.000000000,2017-12-18 12:10:41.000000000,,"[{'_account_id': 7233}, {'_account_id': 12170}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-10-02 05:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9ad64e75745ba1c79b8a113adcd579344fadc7d9', 'message': 'Basic container sharding middleware\n\nNOTE: This is version 0.1, it is still rough and am sure\n      many, many edge cases have been missed (and probably\n      not so edge cases). But the basic functionality is\n      working. I suspect if this middleware goes forward then\n      it will have a large number of patch sets ;)\n\nNOTE2: Tests still need to be added.\n\nThis middleware intercepts requests for a container marked for\nsharding and redirects the request to one of the potentially many\ncontainer ""shards"" to distribute the containers contents over the\ncluster.\n\nTo do this, this middleware uses the same path hashing and part_power\nmechanisms other parts of swift uses. But in this case the part_power\n(or in this case the shard-power) is configured on a per container\nlevel.\n\nA sharded container can only be specified at container creation time\n(for the moment) and is done by setting the\nX-Container-Meta-Shard-Power header on container PUT.\n\n  curl -i -X PUT -H ""X-Auth-Token: $TOKEN"" \\\n      -H ""X-Container-Meta-Shard-Power: 2""  $STORAGE_URL/Acct/cont\n\nOnce created, when an object is then put into the container, the hash\nis calculated and the shard-power is used to generate a \'shard\'\nnumber. Which determines which container shard to store this object\nin. If the container shard doesn\'t exist it is created with all the\nmetadata settings of the main container and the shard number is then\nadded to the list of shards stored in sysmeta-shards\n(which is stored as a json list) inside the shard container.\n\n                                      +---------------------+\n        +-----------------+           |  Acct/cont_shard_0  |\n        |    Acct/cont    |           +---------------------+\n        +-----------------+           |Objs:                |\n        |Metadata:        |           |   Obj3              |\n        |  shard-power: 2 +---------> |   Obj1              |\n        |  shards: 0,1    |           +---------------------+\n        |                 |\n        |Objs:            |           +---------------------+\n        |                 |           |  Acct/cont_shard_1  |\n        |                 |           +---------------------+\n        |                 +---------> |Objs:                |\n        |                 |           |   Obj2              |\n        +-----------------+           |   Obj4              |\n                                      +---------------------+\n\nWhen a request is issued to the shard container (/Acct/cont above)\ndirectly, the list of shards is iterated and it is run on all shard\ncontainers. When its a container listing the bodies from all\nsub-requests are returned.\n\nThis leads to a downside to this sharding middleware, the container\nlistings returned will not be properly sorted, the result of each\nsub request will break when they are all combined.\nTaking the diagram above as an example:\n\n  curl -i -X GET -H ""X-Auth-Token: $TOKEN"" $STORAGE_URL/Acct/cont\n\n  Obj1\n  Obj3\n  Obj2\n  Obj4\n\nThe current code as it is, isn\'t intercepting account listings so at\nthe moment the account listing will display the shard container and\nthe container shards. E.g:\n\n  curl -i -X GET -H ""X-Auth-Token: $TOKEN"" $STORAGE_URL/Acct\n\n  cont\n  cont_shard_0\n  cont_shard_1\n\nChange-Id: I36d7d32b5521d9e000c6aa78746780d6a2791091\n'}, {'number': 2, 'created': '2014-10-02 06:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fd45b02fecbf0a10df62d5d4b8c5a86198b91e8d', 'message': 'Basic container sharding middleware\n\nNOTE: This is version 0.1, it is still rough and am sure\n      many, many edge cases have been missed (and probably\n      not so edge cases). But the basic functionality is\n      working. I suspect if this middleware goes forward then\n      it will have a large number of patch sets ;)\n\nNOTE2: Tests still need to be added.\n\nThis middleware intercepts requests for a container marked for\nsharding and redirects the request to one of the potentially many\ncontainer ""shards"" to distribute the containers contents over the\ncluster.\n\nTo do this, this middleware uses the same path hashing and part_power\nmechanisms other parts of swift uses. But in this case the part_power\n(or in this case the shard-power) is configured on a per container\nlevel.\n\nA sharded container can only be specified at container creation time\n(for the moment) and is done by setting the\nX-Container-Meta-Shard-Power header on container PUT.\n\n  curl -i -X PUT -H ""X-Auth-Token: $TOKEN"" \\\n      -H ""X-Container-Meta-Shard-Power: 2""  $STORAGE_URL/Acct/cont\n\nOnce created, when an object is then put into the container, the hash\nis calculated and the shard-power is used to generate a \'shard\'\nnumber. Which determines which container shard to store this object\nin. If the container shard doesn\'t exist it is created with all the\nmetadata settings of the main container and the shard number is then\nadded to the list of shards stored in sysmeta-shards\n(which is stored as a json list) inside the shard container.\n\n                                      +---------------------+\n        +-----------------+           |  Acct/cont_shard_0  |\n        |    Acct/cont    |           +---------------------+\n        +-----------------+           |Objs:                |\n        |Metadata:        |           |   Obj3              |\n        |  shard-power: 2 +---------> |   Obj1              |\n        |  shards: 0,1    |           +---------------------+\n        |                 |\n        |Objs:            |           +---------------------+\n        |                 |           |  Acct/cont_shard_1  |\n        |                 |           +---------------------+\n        |                 +---------> |Objs:                |\n        |                 |           |   Obj2              |\n        +-----------------+           |   Obj4              |\n                                      +---------------------+\n\nWhen a request is issued to the shard container (/Acct/cont above)\ndirectly, the list of shards is iterated and it is run on all shard\ncontainers. When its a container listing the bodies from all\nsub-requests are returned.\n\nThis leads to a downside to this sharding middleware, the container\nlistings returned will not be properly sorted, the result of each\nsub request will break when they are all combined.\nTaking the diagram above as an example:\n\n  curl -i -X GET -H ""X-Auth-Token: $TOKEN"" $STORAGE_URL/Acct/cont\n\n  Obj1\n  Obj3\n  Obj2\n  Obj4\n\nThe current code as it is, isn\'t intercepting account listings so at\nthe moment the account listing will display the shard container and\nthe container shards. E.g:\n\n  curl -i -X GET -H ""X-Auth-Token: $TOKEN"" $STORAGE_URL/Acct\n\n  cont\n  cont_shard_0\n  cont_shard_1\n\nChange-Id: I36d7d32b5521d9e000c6aa78746780d6a2791091\n'}, {'number': 3, 'created': '2014-10-06 06:20:10.000000000', 'files': ['etc/proxy-server.conf-sample', 'swift/common/middleware/container_shard.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/swift/commit/430ab45cf40a7ced473a6f4de987d88ca02f212d', 'message': 'Basic container sharding middleware\n\nNOTE: This is version 0.1, it is still rough and am sure\n      many, many edge cases have been missed (and probably\n      not so edge cases). But the basic functionality is\n      working. I suspect if this middleware goes forward then\n      it will have a large number of patch sets ;)\n\nNOTE2: Tests still need to be added.\n\nThis middleware intercepts requests for a container marked for\nsharding and redirects the request to one of the potentially many\ncontainer ""shards"" to distribute the containers contents over the\ncluster.\n\nTo do this, this middleware uses the same path hashing and part_power\nmechanisms other parts of swift uses. But in this case the part_power\n(or in this case the shard-power) is configured on a per container\nlevel.\n\nA sharded container can only be specified at container creation time\n(for the moment) and is done by setting the\nX-Container-Meta-Shard-Power header on container PUT.\n\n  curl -i -X PUT -H ""X-Auth-Token: $TOKEN"" \\\n      -H ""X-Container-Meta-Shard-Power: 2""  $STORAGE_URL/Acct/cont\n\nOnce created, when an object is then put into the container, the hash\nis calculated and the shard-power is used to generate a \'shard\'\nnumber. Which determines which container shard to store this object\nin. If the container shard doesn\'t exist it is created with all the\nmetadata settings of the main container and the shard number is then\nadded to the list of shards stored in sysmeta-shards\n(which is stored as a json list) inside the shard container.\n\n                                      +---------------------+\n        +-----------------+           |  Acct/cont_shard_0  |\n        |    Acct/cont    |           +---------------------+\n        +-----------------+           |Objs:                |\n        |Metadata:        |           |   Obj3              |\n        |  shard-power: 2 +---------> |   Obj1              |\n        |  shards: 0,1    |           +---------------------+\n        |                 |\n        |Objs:            |           +---------------------+\n        |                 |           |  Acct/cont_shard_1  |\n        |                 |           +---------------------+\n        |                 +---------> |Objs:                |\n        |                 |           |   Obj2              |\n        +-----------------+           |   Obj4              |\n                                      +---------------------+\n\nWhen a request is issued to the shard container (/Acct/cont above)\ndirectly, the list of shards is iterated and it is run on all shard\ncontainers. When its a container listing the bodies from all\nsub-requests are returned.\n\nThis leads to a downside to this sharding middleware, the container\nlistings returned will not be properly sorted, the result of each\nsub request will break when they are all combined.\nTaking the diagram above as an example:\n\n  curl -i -X GET -H ""X-Auth-Token: $TOKEN"" $STORAGE_URL/Acct/cont\n\n  Obj1\n  Obj3\n  Obj2\n  Obj4\n\nIn this version of the code, limit and markers don\'t work as\nexpected as they are loaded into the SQL statement used in each\ncontainer shard database. I can do some hacking to get limit to work\nbut that might not be too useful without markers working.\n\nThe current code as it is, isn\'t intercepting account listings so at\nthe moment the account listing will display the shard container and\nthe container shards. E.g:\n\n  curl -i -X GET -H ""X-Auth-Token: $TOKEN"" $STORAGE_URL/Acct\n\n  cont\n  cont_shard_0\n  cont_shard_1\n\nChange-Id: I36d7d32b5521d9e000c6aa78746780d6a2791091\n'}]",0,125553,430ab45cf40a7ced473a6f4de987d88ca02f212d,15,3,3,7233,,,0,"Basic container sharding middleware

NOTE: This is version 0.1, it is still rough and am sure
      many, many edge cases have been missed (and probably
      not so edge cases). But the basic functionality is
      working. I suspect if this middleware goes forward then
      it will have a large number of patch sets ;)

NOTE2: Tests still need to be added.

This middleware intercepts requests for a container marked for
sharding and redirects the request to one of the potentially many
container ""shards"" to distribute the containers contents over the
cluster.

To do this, this middleware uses the same path hashing and part_power
mechanisms other parts of swift uses. But in this case the part_power
(or in this case the shard-power) is configured on a per container
level.

A sharded container can only be specified at container creation time
(for the moment) and is done by setting the
X-Container-Meta-Shard-Power header on container PUT.

  curl -i -X PUT -H ""X-Auth-Token: $TOKEN"" \
      -H ""X-Container-Meta-Shard-Power: 2""  $STORAGE_URL/Acct/cont

Once created, when an object is then put into the container, the hash
is calculated and the shard-power is used to generate a 'shard'
number. Which determines which container shard to store this object
in. If the container shard doesn't exist it is created with all the
metadata settings of the main container and the shard number is then
added to the list of shards stored in sysmeta-shards
(which is stored as a json list) inside the shard container.

                                      +---------------------+
        +-----------------+           |  Acct/cont_shard_0  |
        |    Acct/cont    |           +---------------------+
        +-----------------+           |Objs:                |
        |Metadata:        |           |   Obj3              |
        |  shard-power: 2 +---------> |   Obj1              |
        |  shards: 0,1    |           +---------------------+
        |                 |
        |Objs:            |           +---------------------+
        |                 |           |  Acct/cont_shard_1  |
        |                 |           +---------------------+
        |                 +---------> |Objs:                |
        |                 |           |   Obj2              |
        +-----------------+           |   Obj4              |
                                      +---------------------+

When a request is issued to the shard container (/Acct/cont above)
directly, the list of shards is iterated and it is run on all shard
containers. When its a container listing the bodies from all
sub-requests are returned.

This leads to a downside to this sharding middleware, the container
listings returned will not be properly sorted, the result of each
sub request will break when they are all combined.
Taking the diagram above as an example:

  curl -i -X GET -H ""X-Auth-Token: $TOKEN"" $STORAGE_URL/Acct/cont

  Obj1
  Obj3
  Obj2
  Obj4

In this version of the code, limit and markers don't work as
expected as they are loaded into the SQL statement used in each
container shard database. I can do some hacking to get limit to work
but that might not be too useful without markers working.

The current code as it is, isn't intercepting account listings so at
the moment the account listing will display the shard container and
the container shards. E.g:

  curl -i -X GET -H ""X-Auth-Token: $TOKEN"" $STORAGE_URL/Acct

  cont
  cont_shard_0
  cont_shard_1

Change-Id: I36d7d32b5521d9e000c6aa78746780d6a2791091
",git fetch https://review.opendev.org/openstack/swift refs/changes/53/125553/3 && git format-patch -1 --stdout FETCH_HEAD,"['etc/proxy-server.conf-sample', 'swift/common/middleware/container_shard.py', 'setup.cfg']",3,9ad64e75745ba1c79b8a113adcd579344fadc7d9,container_shard, container_shard = swift.common.middleware.container_shard:filter_factory,,434,0
openstack%2Fdevstack-gate~master~I08b4d13b56859e8ceb56ad668b71efa9a0f3eeb3,openstack/devstack-gate,master,I08b4d13b56859e8ceb56ad668b71efa9a0f3eeb3,Use ansible sudo capabilities rather than subshell,NEW,2015-07-16 13:42:35.000000000,2017-12-18 12:10:21.000000000,,"[{'_account_id': 1}, {'_account_id': 4146}, {'_account_id': 7118}, {'_account_id': 10035}, {'_account_id': 11610}]","[{'number': 1, 'created': '2015-07-16 13:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ff67cf96322bd9ed4e991369fe96811b9302d598', 'message': 'Use ansible sudo capabilities rather than subshell\n\nThe ansible command has sudo capabilities which we use in other places.\nThose include indicating the user to run the command as. Also, the\ndirectory to run in can be passed as a parameter. Use them.\n\nChange-Id: I08b4d13b56859e8ceb56ad668b71efa9a0f3eeb3\n'}, {'number': 2, 'created': '2015-08-11 18:14:16.000000000', 'files': ['devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/5bd01d6890118d6160e489f32f3c8dc1ba697d2d', 'message': 'Use ansible sudo capabilities rather than subshell\n\nThe ansible command has sudo capabilities which we use in other places.\nThose include indicating the user to run the command as. Also, the\ndirectory to run in can be passed as a parameter. Use them.\n\nChange-Id: I08b4d13b56859e8ceb56ad668b71efa9a0f3eeb3\n'}]",0,202566,5bd01d6890118d6160e489f32f3c8dc1ba697d2d,17,5,2,2,,,0,"Use ansible sudo capabilities rather than subshell

The ansible command has sudo capabilities which we use in other places.
Those include indicating the user to run the command as. Also, the
directory to run in can be passed as a parameter. Use them.

Change-Id: I08b4d13b56859e8ceb56ad668b71efa9a0f3eeb3
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/66/202566/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate.sh'],1,ff67cf96322bd9ed4e991369fe96811b9302d598,ansible_tightenup," $ANSIBLE primary --sudo -U stack -m shell \ -a ""stdbuf -oL -eL ./stack.sh executable=/bin/bash chdir=$BASE/new/devstack"" \ $ANSIBLE subnodes --sudo -U stack -m shell \ -a ""stdbuf -oL -eL ./stack.sh executable=/bin/bash chdir=$BASE/new/devstack"" \ $ANSIBLE ""$MTU_NODES"" --sudo -m shell \ -a ""ip link set mtu 1450 dev br-ex"" $ANSIBLE all --sudo -U stack -m shell \ -a ""./unstack.sh chdir=$BASE/new/devstack"" $ANSIBLE all --sudo -U stack -m shell \ -a ""./exercise.sh chdir=$BASE/new/devstack"""," $ANSIBLE primary -m shell \ -a ""cd '$BASE/new/devstack' && sudo -H -u stack stdbuf -oL -eL ./stack.sh executable=/bin/bash"" \ $ANSIBLE subnodes -m shell \ -a ""cd '$BASE/new/devstack' && sudo -H -u stack stdbuf -oL -eL ./stack.sh executable=/bin/bash"" \ $ANSIBLE ""$MTU_NODES"" -m shell \ -a ""sudo ip link set mtu 1450 dev br-ex"" $ANSIBLE all -m shell \ -a ""cd '$BASE/new/devstack' && sudo -H -u stack ./unstack.sh"" $ANSIBLE all -m shell \ -a ""cd '$BASE/new/devstack' && sudo -H -u stack ./exercise.sh""",10,10
openstack%2Fpython-swiftclient~master~Ie95ed469f6450537047e116f4872fbc0931f090a,openstack/python-swiftclient,master,Ie95ed469f6450537047e116f4872fbc0931f090a,Decode filesystem paths on Python 2,NEW,2015-05-18 22:57:54.000000000,2017-12-18 12:10:04.000000000,,"[{'_account_id': 6968}, {'_account_id': 9216}, {'_account_id': 12279}, {'_account_id': 15343}]","[{'number': 1, 'created': '2015-05-18 22:57:54.000000000', 'files': ['swiftclient/shell.py', 'tests/unit/test_service.py', 'tests/unit/test_shell.py', 'swiftclient/service.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/4f59cc0cb3959e0b454f3838ce7d1aa42d426ee5', 'message': 'Decode filesystem paths on Python 2\n\nYet another way raw bytes could appear in user messages.\n\nChange-Id: Ie95ed469f6450537047e116f4872fbc0931f090a\n'}]",1,184148,4f59cc0cb3959e0b454f3838ce7d1aa42d426ee5,9,4,1,15343,,,0,"Decode filesystem paths on Python 2

Yet another way raw bytes could appear in user messages.

Change-Id: Ie95ed469f6450537047e116f4872fbc0931f090a
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/48/184148/1 && git format-patch -1 --stdout FETCH_HEAD,"['swiftclient/shell.py', 'tests/unit/test_service.py', 'tests/unit/test_shell.py', 'swiftclient/service.py']",4,4f59cc0cb3959e0b454f3838ce7d1aa42d426ee5,unicode-file-paths,"from six import Iterator, StringIO, text_type if isinstance(source, text_type): if not object_name or not isinstance(object_name, text_type): if not isinstance(object_name, text_type) or not object_name: if isinstance(o, text_type): if isinstance(o, text_type):","from six import StringIO, text_typefrom six import Iterator, string_types if isinstance(source, string_types): if not object_name or not isinstance(object_name, string_types): if not isinstance(object_name, string_types) or not object_name: if isinstance(o, string_types): if isinstance(o, string_types):",23,15
openstack%2Fironic~master~I0af153e3deb5ad30303967042f6357816e27e661,openstack/ironic,master,I0af153e3deb5ad30303967042f6357816e27e661,Add credentials migration script,NEW,2015-06-18 17:08:41.000000000,2017-12-18 12:10:01.000000000,,[{'_account_id': 12356}],"[{'number': 1, 'created': '2015-06-18 17:08:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/42d21da3cfaf73e82e273dad481a0ac10758d030', 'message': 'Add credentials migration script.\n\nAdd migration script that allows to move credentials from storage to\nDB and from DB to storage.\n\nImplements blueprint: pluggable-credential-storage\n\nChange-Id: I0af153e3deb5ad30303967042f6357816e27e661\n'}, {'number': 2, 'created': '2015-06-18 17:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/06bf4b9428841275ad89130066bb37ed040e0a51', 'message': 'Add credentials migration script\n\nAdd migration script that allows to move credentials from storage to\nDB and from DB to storage.\n\nImplements blueprint: pluggable-credential-storage\n\nChange-Id: I0af153e3deb5ad30303967042f6357816e27e661\n'}, {'number': 3, 'created': '2015-08-25 14:38:27.000000000', 'files': ['tools/credentials_migrate.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/9d04988b5706cd865cb1f34dedf45a8d24d15a45', 'message': 'Add credentials migration script\n\nAdd migration script that allows to move credentials from storage to\nDB and from DB to storage.\n\nImplements blueprint: pluggable-credential-storage\n\nChange-Id: I0af153e3deb5ad30303967042f6357816e27e661\n'}]",0,193218,9d04988b5706cd865cb1f34dedf45a8d24d15a45,13,1,3,12356,,,0,"Add credentials migration script

Add migration script that allows to move credentials from storage to
DB and from DB to storage.

Implements blueprint: pluggable-credential-storage

Change-Id: I0af153e3deb5ad30303967042f6357816e27e661
",git fetch https://review.opendev.org/openstack/ironic refs/changes/18/193218/3 && git format-patch -1 --stdout FETCH_HEAD,['tools/credentials_migrate.py'],1,42d21da3cfaf73e82e273dad481a0ac10758d030,bp/pluggable-credential-storage,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" This is an administrative utility to be used for migrating credentials. It can be used to load credentials from storage to DB or to upload it from DB to currently configured storage. """""" import sys from oslo_config import cfg from oslo_utils import importutils import six from six.moves import configparser import sqlalchemy from ironic.common import credentials_factory from ironic.db.sqlalchemy import models cfg.CONF.register_cli_opts([ cfg.StrOpt('db-connection', required=True, dest='db_conn', short='c', help='Connection string to Ironic database.'), cfg.StrOpt('setup-file', required=True, dest='setup_cfg', short='s', help='Path to Ironic setup.cfg file.'), cfg.StrOpt('direction', required=True, dest='direction', short='d', choices=['db', 'storage'], help='Where to save credentials: either get them from DB and ' 'put it to storage or get them from storage and save to ' 'DB.'), ]) def to_db(nodes): provider = credentials_factory.CredentialsFactory().provider for node in nodes: driver_internal_info = node.driver_internal_info.copy() cred_id = driver_internal_info.get('credentials_id') if cred_id: driver_info = node.driver_info.copy() blob = provider.get(cred_id) for k in blob: driver_info[k] = blob[k] node.driver_info = driver_info del driver_internal_info['credentials_id'] node.driver_internal_info = driver_internal_info def to_storage(nodes, drivers): provider = credentials_factory.CredentialsFactory().provider for node in nodes: blob = {'node_uuid': node.uuid} driver_info = node.driver_info.copy() driver_internal_info = node.driver_internal_info.copy() if ('credentials_id' in driver_info or 'credentials_id' in driver_internal_info): continue cr_fields = get_driver_credentials(drivers[node.driver]) for k in cr_fields: value = driver_info.get(k) if value is not None: blob[k] = value driver_info[k] = '******' driver_internal_info['credentials_id'] = provider.upload( 'ironic-credentials', blob) node.driver_internal_info = driver_internal_info node.driver_info = driver_info def get_driver_credentials(driver_class): Driver = importutils.import_class(driver_class.replace(':', '.', 1)) credentials_fields = Driver().get_properties().get('credentials_fields', []) return credentials_fields def main(): config_parser = configparser.SafeConfigParser() config_parser.read(cfg.CONF.setup_cfg) drivers = dict(map(lambda s: map(lambda p: p.strip(), s.split('=')), config_parser.get('entry_points', 'ironic.drivers') .strip().splitlines())) ironic_engine = sqlalchemy.create_engine(cfg.CONF.db_conn) Session = sqlalchemy.orm.sessionmaker(bind=ironic_engine) session = Session() query = session.query(models.Node) try: nodes = query.all() except sqlalchemy.exc.OperationalError as err: six.print_(""Could not get nodes from Ironic DB:\n%s"" % err, file=sys.stderr) sys.exit(2) if cfg.CONF.direction == 'db': to_db(nodes) else: to_storage(nodes, drivers) session.add_all(nodes) session.commit() session.close() if __name__ == '__main__': cfg.CONF() main() ",,120,0
openstack%2Fpython-heatclient~master~I42f771d7a883f6810a144c9d7601083a7d1f2b1b,openstack/python-heatclient,master,I42f771d7a883f6810a144c9d7601083a7d1f2b1b,Add HTTP Basic/Digest auth,NEW,2015-07-21 13:04:05.000000000,2017-12-18 12:09:28.000000000,,"[{'_account_id': 12606}, {'_account_id': 13158}]","[{'number': 1, 'created': '2015-07-21 13:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/1c6b5fba6574ddc0b0a8830fec4a42e849998ffc', 'message': 'Add HTTP Basic/Digest auth\n\nThis commit adds support to HTTP Basic/Digest auth when fetching\nHTTP content.\n\nChange-Id: I42f771d7a883f6810a144c9d7601083a7d1f2b1b\n'}, {'number': 2, 'created': '2015-08-07 07:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/06b466733cdf815e217b2c875e3802b2384dd759', 'message': 'Add HTTP Basic/Digest auth\n\nThis commit adds support to HTTP Basic/Digest auth when fetching\nHTTP content.\n\nChange-Id: I42f771d7a883f6810a144c9d7601083a7d1f2b1b\n'}, {'number': 3, 'created': '2015-08-07 09:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/a394802de1b87018f1dc7de2a1316f0fbefd5abf', 'message': 'Add HTTP Basic/Digest auth\n\nThis commit adds support to HTTP Basic/Digest auth when fetching\nHTTP content.\n\nChange-Id: I42f771d7a883f6810a144c9d7601083a7d1f2b1b\n'}, {'number': 4, 'created': '2015-08-10 01:08:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/19f42aa48eb53b7c47c7517687a6db6b8c649076', 'message': 'Add HTTP Basic/Digest auth\n\nThis commit adds support to HTTP Basic/Digest auth when fetching\nHTTP content.\n\nChange-Id: I42f771d7a883f6810a144c9d7601083a7d1f2b1b\n'}, {'number': 5, 'created': '2015-08-14 06:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/40fa4aba846b6a6848ae68d0a40099bf9653cf2e', 'message': 'Add HTTP Basic/Digest auth\n\nThis commit adds support to HTTP Basic/Digest auth when fetching\nHTTP content.\n\nChange-Id: I42f771d7a883f6810a144c9d7601083a7d1f2b1b\n'}, {'number': 6, 'created': '2015-09-08 03:29:06.000000000', 'files': ['heatclient/tests/unit/test_shell.py', 'heatclient/tests/unit/test_utils.py', 'heatclient/common/template_utils.py', 'heatclient/common/utils.py', 'heatclient/v1/shell.py', 'heatclient/tests/unit/test_template_utils.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/2d4c1bb271063932bf53f132c76b44751eedd97a', 'message': 'Add HTTP Basic/Digest auth\n\nThis commit adds support to HTTP Basic/Digest auth when fetching\nHTTP content.\n\nChange-Id: I42f771d7a883f6810a144c9d7601083a7d1f2b1b\n'}]",0,204076,2d4c1bb271063932bf53f132c76b44751eedd97a,19,2,6,13158,,,0,"Add HTTP Basic/Digest auth

This commit adds support to HTTP Basic/Digest auth when fetching
HTTP content.

Change-Id: I42f771d7a883f6810a144c9d7601083a7d1f2b1b
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/76/204076/5 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/unit/test_shell.py', 'heatclient/tests/unit/test_utils.py', 'heatclient/common/template_utils.py', 'heatclient/common/utils.py', 'heatclient/tests/unit/test_template_utils.py']",5,1c6b5fba6574ddc0b0a8830fec4a42e849998ffc,http-auth," self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw(url).AndReturn(content) utils.read_url_content_raw(url).AndReturn(content) self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw('file://%s' % env_file).AndReturn( env) utils.read_url_content_raw('file:///home/b/a.yaml').AndReturn( self.template_a) utils.read_url_content_raw('file:///home/b/a.yaml').AndReturn( self.template_a) self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw(env_url).AndReturn( env) utils.read_url_content_raw('file:///home/my/dir/a.yaml').AndReturn( self.template_a) utils.read_url_content_raw('file:///home/my/dir/a.yaml').AndReturn( self.template_a) self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw(env_url).AndReturn( env) utils.read_url_content_raw('file:///home/my/bar/a.yaml').AndReturn( self.template_a) utils.read_url_content_raw('file:///home/my/bar/a.yaml').AndReturn( self.template_a) self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw(url).AndReturn(env) utils.read_url_content_raw(tmpl_url).AndReturn( self.template_a) utils.read_url_content_raw(tmpl_url).AndReturn(self.template_a) self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw('file://%s' % env_file).AndReturn( env) self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw('file://%s' % env_file1).AndReturn( env1) utils.read_url_content_raw('file:///home/b/a.yaml').AndReturn( self.template_a) utils.read_url_content_raw('file:///home/b/a.yaml').AndReturn( self.template_a) utils.read_url_content_raw('file://%s' % env_file2).AndReturn( env2) utils.read_url_content_raw('file:///home/b/b.yaml').AndReturn( self.template_a) utils.read_url_content_raw('file:///home/b/b.yaml').AndReturn( self.template_a) self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw( 'file://%s' % env_file1).InAnyOrder().AndReturn( env1) utils.read_url_content_raw( 'file:///home/b/a.yaml').InAnyOrder().AndReturn( self.template_a) utils.read_url_content_raw( 'file:///home/b/b.yaml').InAnyOrder().AndReturn( self.template_a) utils.read_url_content_raw( 'file:///home/b/a.yaml').InAnyOrder().AndReturn( self.template_a) utils.read_url_content_raw( 'file:///home/b/b.yaml').InAnyOrder().AndReturn( self.template_a) utils.read_url_content_raw( 'file://%s' % env_file2).InAnyOrder().AndReturn( env2) utils.read_url_content_raw( 'file:///home/b/a.yaml').InAnyOrder().AndReturn( self.template_a) utils.read_url_content_raw( 'file:///home/b/b.yaml').InAnyOrder().AndReturn( self.template_a) utils.read_url_content_raw( 'file:///home/b/a.yaml').InAnyOrder().AndReturn( self.template_a) utils.read_url_content_raw( 'file:///home/b/b.yaml').InAnyOrder().AndReturn( self.template_a) self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw(url).AndReturn(tmpl) self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw(url).AndReturn(raw_content) self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw(url).AndReturn( self.hot_template) utils.read_url_content_raw( b'bar contents') utils.read_url_content_raw( b'foo contents') utils.read_url_content_raw( b'baz1 contents') utils.read_url_content_raw( b'baz2 contents') utils.read_url_content_raw( b'baz3 contents') self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw(url).AndReturn( contents) utils.read_url_content_raw(foo_url).AndReturn( b'foo contents') self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw(url).AndReturn( contents) utils.read_url_content_raw(foo_url).AndReturn( b'foo contents') self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw( self.foo_template) utils.read_url_content_raw( self.foo_template) utils.read_url_content_raw(url).InAnyOrder().AndReturn( self.hot_template) utils.read_url_content_raw( self.egg_template) utils.read_url_content_raw( self.egg_template) self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw(url).InAnyOrder().AndReturn( self.hot_template) utils.read_url_content_raw(foo_url).InAnyOrder().AndReturn( self.foo_template) utils.read_url_content_raw(foo_url).InAnyOrder().AndReturn( self.foo_template) utils.read_url_content_raw(bar_url).InAnyOrder().AndReturn( self.bar_template) utils.read_url_content_raw(bar_url).InAnyOrder().AndReturn( self.bar_template) self.m.StubOutWithMock(utils, 'read_url_content_raw') utils.read_url_content_raw(env_url).AndReturn( env) utils.read_url_content_raw(template_url).AndReturn( self.hot_template) utils.read_url_content_raw(template_url).AndReturn( self.hot_template) utils.read_url_content_raw(foo_url).InAnyOrder().AndReturn( self.foo_template) utils.read_url_content_raw(egg_url).InAnyOrder().AndReturn( self.egg_template) utils.read_url_content_raw(ham_url).InAnyOrder().AndReturn( b'ham contents') utils.read_url_content_raw(one_url).InAnyOrder().AndReturn( self.foo_template) utils.read_url_content_raw(two_url).InAnyOrder().AndReturn( self.foo_template) utils.read_url_content_raw(three_url).InAnyOrder().AndReturn( b'three contents') utils.read_url_content_raw(foo_url).InAnyOrder().AndReturn( self.foo_template) utils.read_url_content_raw(egg_url).InAnyOrder().AndReturn( self.egg_template) utils.read_url_content_raw(one_url).InAnyOrder().AndReturn( self.foo_template) utils.read_url_content_raw(two_url).InAnyOrder().AndReturn( self.foo_template)","from six.moves.urllib import request self.m.StubOutWithMock(request, 'urlopen') request.urlopen(url).AndReturn(six.BytesIO(content)) request.urlopen(url).AndReturn(six.BytesIO(content)) self.m.StubOutWithMock(request, 'urlopen') request.urlopen('file://%s' % env_file).AndReturn( six.BytesIO(env)) request.urlopen('file:///home/b/a.yaml').AndReturn( six.BytesIO(self.template_a)) request.urlopen('file:///home/b/a.yaml').AndReturn( six.BytesIO(self.template_a)) self.m.StubOutWithMock(request, 'urlopen') request.urlopen(env_url).AndReturn( six.BytesIO(env)) request.urlopen('file:///home/my/dir/a.yaml').AndReturn( six.BytesIO(self.template_a)) request.urlopen('file:///home/my/dir/a.yaml').AndReturn( six.BytesIO(self.template_a)) self.m.StubOutWithMock(request, 'urlopen') request.urlopen(env_url).AndReturn( six.BytesIO(env)) request.urlopen('file:///home/my/bar/a.yaml').AndReturn( six.BytesIO(self.template_a)) request.urlopen('file:///home/my/bar/a.yaml').AndReturn( six.BytesIO(self.template_a)) self.m.StubOutWithMock(request, 'urlopen') request.urlopen(url).AndReturn(six.BytesIO(env)) request.urlopen(tmpl_url).AndReturn(six.BytesIO(self.template_a)) request.urlopen(tmpl_url).AndReturn(six.BytesIO(self.template_a)) self.m.StubOutWithMock(request, 'urlopen') request.urlopen('file://%s' % env_file).AndReturn(six.BytesIO(env)) self.m.StubOutWithMock(request, 'urlopen') request.urlopen('file://%s' % env_file1).AndReturn( six.BytesIO(env1)) request.urlopen('file:///home/b/a.yaml').AndReturn( six.BytesIO(self.template_a)) request.urlopen('file:///home/b/a.yaml').AndReturn( six.BytesIO(self.template_a)) request.urlopen('file://%s' % env_file2).AndReturn( six.BytesIO(env2)) request.urlopen('file:///home/b/b.yaml').AndReturn( six.BytesIO(self.template_a)) request.urlopen('file:///home/b/b.yaml').AndReturn( six.BytesIO(self.template_a)) self.m.StubOutWithMock(request, 'urlopen') request.urlopen('file://%s' % env_file1).InAnyOrder().AndReturn( six.BytesIO(env1)) request.urlopen('file:///home/b/a.yaml').InAnyOrder().AndReturn( six.BytesIO(self.template_a)) request.urlopen('file:///home/b/b.yaml').InAnyOrder().AndReturn( six.BytesIO(self.template_a)) request.urlopen('file:///home/b/a.yaml').InAnyOrder().AndReturn( six.BytesIO(self.template_a)) request.urlopen('file:///home/b/b.yaml').InAnyOrder().AndReturn( six.BytesIO(self.template_a)) request.urlopen('file://%s' % env_file2).InAnyOrder().AndReturn( six.BytesIO(env2)) request.urlopen('file:///home/b/a.yaml').InAnyOrder().AndReturn( six.BytesIO(self.template_a)) request.urlopen('file:///home/b/b.yaml').InAnyOrder().AndReturn( six.BytesIO(self.template_a)) request.urlopen('file:///home/b/a.yaml').InAnyOrder().AndReturn( six.BytesIO(self.template_a)) request.urlopen('file:///home/b/b.yaml').InAnyOrder().AndReturn( six.BytesIO(self.template_a)) self.m.StubOutWithMock(request, 'urlopen') request.urlopen(url).AndReturn(six.BytesIO(tmpl)) self.m.StubOutWithMock(request, 'urlopen') response = six.BytesIO(raw_content) request.urlopen(url).AndReturn(response) self.m.StubOutWithMock(request, 'urlopen') request.urlopen(url).AndReturn( six.BytesIO(self.hot_template)) request.urlopen( six.BytesIO(b'bar contents')) request.urlopen( six.BytesIO(b'foo contents')) request.urlopen( six.BytesIO(b'baz1 contents')) request.urlopen( six.BytesIO(b'baz2 contents')) request.urlopen( six.BytesIO(b'baz3 contents')) self.m.StubOutWithMock(request, 'urlopen') request.urlopen(url).AndReturn(six.BytesIO(contents)) request.urlopen(foo_url).AndReturn(six.BytesIO(b'foo contents')) self.m.StubOutWithMock(request, 'urlopen') request.urlopen(url).AndReturn(six.BytesIO(contents)) request.urlopen(foo_url).AndReturn(six.BytesIO(b'foo contents')) self.m.StubOutWithMock(request, 'urlopen') request.urlopen( six.BytesIO(self.foo_template)) request.urlopen( six.BytesIO(self.foo_template)) request.urlopen(url).InAnyOrder().AndReturn( six.BytesIO(self.hot_template)) request.urlopen( six.BytesIO(self.egg_template)) request.urlopen( six.BytesIO(self.egg_template)) self.m.StubOutWithMock(request, 'urlopen') request.urlopen(url).InAnyOrder().AndReturn( six.BytesIO(self.hot_template)) request.urlopen(foo_url).InAnyOrder().AndReturn( six.BytesIO(self.foo_template)) request.urlopen(foo_url).InAnyOrder().AndReturn( six.BytesIO(self.foo_template)) request.urlopen(bar_url).InAnyOrder().AndReturn( six.BytesIO(self.bar_template)) request.urlopen(bar_url).InAnyOrder().AndReturn( six.BytesIO(self.bar_template)) self.m.StubOutWithMock(request, 'urlopen') request.urlopen(env_url).AndReturn( six.BytesIO(env)) request.urlopen(template_url).AndReturn( six.BytesIO(self.hot_template)) request.urlopen(template_url).AndReturn( six.BytesIO(self.hot_template)) request.urlopen(foo_url).InAnyOrder().AndReturn( six.BytesIO(self.foo_template)) request.urlopen(egg_url).InAnyOrder().AndReturn( six.BytesIO(self.egg_template)) request.urlopen(ham_url).InAnyOrder().AndReturn( six.BytesIO(b'ham contents')) request.urlopen(one_url).InAnyOrder().AndReturn( six.BytesIO(self.foo_template)) request.urlopen(two_url).InAnyOrder().AndReturn( six.BytesIO(self.foo_template)) request.urlopen(three_url).InAnyOrder().AndReturn( six.BytesIO(b'three contents')) request.urlopen(foo_url).InAnyOrder().AndReturn( six.BytesIO(self.foo_template)) request.urlopen(egg_url).InAnyOrder().AndReturn( six.BytesIO(self.egg_template)) request.urlopen(one_url).InAnyOrder().AndReturn( six.BytesIO(self.foo_template)) request.urlopen(two_url).InAnyOrder().AndReturn( six.BytesIO(self.foo_template))",324,149
openstack%2Fsolum-specs~master~Ib4c5583131a85fd769be5f8778b478befe559732,openstack/solum-specs,master,Ib4c5583131a85fd769be5f8778b478befe559732,Added workflow implementation spec,NEW,2015-08-21 23:14:21.000000000,2017-12-18 12:09:25.000000000,,[{'_account_id': 668}],"[{'number': 1, 'created': '2015-08-21 23:14:21.000000000', 'files': ['specs/liberty/workflow-resource-implementation.rst'], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/f5df6f74c0011a96cfba3142c094924f50641f7d', 'message': 'Added workflow implementation spec\n\nPresents workflow implementation approach which will incrementally\nadd workflow resource to current Solum code\n\nChange-Id: Ib4c5583131a85fd769be5f8778b478befe559732\n'}]",0,215832,f5df6f74c0011a96cfba3142c094924f50641f7d,5,1,1,2506,,,0,"Added workflow implementation spec

Presents workflow implementation approach which will incrementally
add workflow resource to current Solum code

Change-Id: Ib4c5583131a85fd769be5f8778b478befe559732
",git fetch https://review.opendev.org/openstack/solum-specs refs/changes/32/215832/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/workflow-resource-implementation.rst'],1,f5df6f74c0011a96cfba3142c094924f50641f7d,implementing-workflow-resource,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================== Implementing workflow resource in Solum =========================================== Problem description =================== This spec discusses how to implement workflows [1] in Solum. Once workflows are implemented, it should be possible to perform app build and deploy using the workflow resource. Specifically, we consider the following question: How to introduce new workflow resource and db models in an incremental fashion to the current Solum code? Proposed change =============== Solution requirements and constraints: Requirements: - Avoid re-writing of code in key modules - New resources should become usable without having to wait for significant code development cycle Constraint: Solum code heavily uses assembly abstraction in following key modules: - solum/workers/handlers/shell.py - solum/deployer/handlers/heat.py Approach taken: Idea: Introduce the new resources and models (app and workflow), but in the key modules (shell.py and heat.py) keep using existing models (plan and assembly). How to implement above idea? - Introduce a adapter class which will: - for each workflow execution, it will create an assembly - it will maintain a one-to-one association between workflows and assemblies - Update status of new resources (app and workflow) when updating the status of an assembly Patches: - https://review.openstack.org/#/c/214310/ - https://review.openstack.org/#/c/214309/ - https://review.openstack.org/#/c/214308/ - https://review.openstack.org/#/c/215813/ Trying out patches: - Start with cloning Vagrant repo : https://github.com/rackerlabs/vagrant-solum-dev - Pull down above four patches - You will also need this CLI patch : https://review.openstack.org/#/c/204165/ For testing, use following steps inside your Vagrant VM: - source devstack/openrc - solum languagepack create python https://github.com/rackspace-solum-samples/solum-languagepack-python.git - solum app create /opt/stack/solum/examples/apps/cherrypy.yaml - solum app deploy cherrypy - solum app show cherrypy You can use the --debug flag with the app deploy command to check that it is hitting the workflow resource (instead of the assembly resource) Detailed Solum Docs: http://solum.readthedocs.org/en/latest/getting_started/ Alternatives ------------ One alternative is to change shell.py and heat.py to use workflow abstraction instead of assembly. But this is not favored because of following reasons: 1) Will need major overhaul and rewrite of these modules 2) Assemblies may still need to be around till we are supporting CAMP 3) As long as user facing interaction points (REST API and CLI) use workflow, it should not matter what data structures are used internally by Solum engine. Data model impact ----------------- - Workflow table modified to contain reference to assembly. - App and workflow tables enhanced to store status. App table enhanced to store the app_url. Security impact --------------- Notifications impact -------------------- Other end user impact --------------------- Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: <devdatta-kulkarni> Dependencies ============ None Testing ======= Documentation Impact ==================== References ========== [1] https://github.com/stackforge/solum-specs/blob/master/specs/liberty/app-resource.rst .. # vim: set sw=2 ts=2 sts=2 tw=79: ",,166,0
openstack%2Fswift~master~I1f2cd3102728fda15c440d308208bbf77d1fa07b,openstack/swift,master,I1f2cd3102728fda15c440d308208bbf77d1fa07b,WIP: new attempt at single-process,NEW,2015-02-25 23:22:04.000000000,2017-12-18 12:09:03.000000000,,"[{'_account_id': 1179}, {'_account_id': 6968}, {'_account_id': 6984}, {'_account_id': 8542}, {'_account_id': 9625}, {'_account_id': 13052}, {'_account_id': 13777}]","[{'number': 1, 'created': '2015-02-25 23:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dcc4e9181d48d704ed9b35ffa6a06e7cc08df4b9', 'message': ""WIP: new attempt at single-process\n\nThis new patch simplifies the paco PUT path by\nassuming that a paco node is also a 1-replica\nnode (e.g., swift-on-file). This allows us to\nbypass much of the PUT code to setup connections,\nsend data and get responses.\n\nTo test, create a new policy with one replica, also\ncreate a file under /etc/swift/single_process.conf\nwith the configuration for the new 'in-process'\nobject server. See https://review.openstack.org/#/c/149329\nfor example.\n\nChange-Id: I1f2cd3102728fda15c440d308208bbf77d1fa07b\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n""}, {'number': 2, 'created': '2015-02-26 23:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3fe6947ec55665870d437dfc6aa6f1aabf0ac067', 'message': ""WIP: new attempt at single-process\n\nThis new patch simplifies the paco PUT path by\nassuming that a paco node is also a 1-replica\nnode (e.g., swift-on-file). This allows us to\nbypass much of the PUT code to setup connections,\nsend data and get responses.\n\nTo test, create a new policy with one replica, also\ncreate a file under /etc/swift/single_process.conf\nwith the configuration for the new 'in-process'\nobject server. See https://review.openstack.org/#/c/149329\nfor example.\n\nChange-Id: I1f2cd3102728fda15c440d308208bbf77d1fa07b\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n""}, {'number': 3, 'created': '2015-04-29 04:40:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/650291af1f308379f255efada23d06acc5d46fd2', 'message': ""WIP: new attempt at single-process\n\nThis new patch simplifies the paco PUT path by assuming that a paco\nnode is also a 1-replica node (e.g., swift-on-file). This allows us\nto bypass much of the PUT code to setup connections, send data and\nget responses.\n\nTo test, create a new policy with one replica, also create a file\nunder /etc/swift/single-process.conf with the configuration for the\nnew 'in-process' object server.\n\nThe GET path is untouched as of now, it would still need a separate\nobject server process running.\n\nChange-Id: I1f2cd3102728fda15c440d308208bbf77d1fa07b\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\nSigned-off-by: Prashanth Pai <ppai@redhat.com>\n""}, {'number': 4, 'created': '2015-05-15 14:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/276949264e1f553b25c4db2804e5f84c46d839bc', 'message': ""WIP: new attempt at single-process\n\nThis new patch simplifies the paco PUT path by assuming that a paco\nnode is also a 1-replica node (e.g., swift-on-file). This allows us\nto bypass much of the PUT code to setup connections, send data and\nget responses.\n\nTo test, create a new policy with one replica, also create a file\nunder /etc/swift/single-process.conf with the configuration for the\nnew 'in-process' object server.\n\nCurrently, only PUT and GET path have been coded, next will be\nPOST, DELETE\n\nChange-Id: I1f2cd3102728fda15c440d308208bbf77d1fa07b\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\nSigned-off-by: Prashanth Pai <ppai@redhat.com>\n""}, {'number': 5, 'created': '2015-05-15 19:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c94a11ec3f1fab77a4c46c431349c7cc9bd809f3', 'message': ""WIP: new attempt at single-process\n\nThis new patch simplifies the paco PUT path by assuming that a paco\nnode is also a 1-replica node (e.g., swift-on-file). This allows us\nto bypass much of the PUT code to setup connections, send data and\nget responses.\n\nTo test, create a new policy with one replica, also create a file\nunder /etc/swift/single-process.conf with the configuration for the\nnew 'in-process' object server.\n\nCurrently, only PUT and GET path have been coded, next will be\nPOST, DELETE\n\nChange-Id: I1f2cd3102728fda15c440d308208bbf77d1fa07b\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\nSigned-off-by: Prashanth Pai <ppai@redhat.com>\n""}, {'number': 6, 'created': '2015-07-09 19:39:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4c0e15ad27e3ed11e7af97f1794f2b73dac853b9', 'message': ""WIP: new attempt at single-process\n\nThis new patch simplifies the paco PUT path by assuming that a paco\nnode is also a 1-replica node (e.g., swift-on-file). This allows us\nto bypass much of the PUT code to setup connections, send data and\nget responses.\n\nTo test, create a new policy with one replica, also create a file\nunder /etc/swift/single-process.conf with the configuration for the\nnew 'in-process' object server.\n\nCurrently, only PUT and GET path have been coded, next will be\nPOST, DELETE\n\nChange-Id: I1f2cd3102728fda15c440d308208bbf77d1fa07b\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\nSigned-off-by: Prashanth Pai <ppai@redhat.com>\n""}, {'number': 7, 'created': '2015-09-15 20:48:33.000000000', 'files': ['doc/saio/swift/proxy-server.conf', 'doc/saio/swift/swift.conf', 'doc/saio/bin/resetswift', 'doc/source/development_saio.rst', 'doc/saio/bin/remakerings', 'swift/common/storage_policy.py', 'swift/common/wsgi.py', 'swift/proxy/controllers/obj.py', 'doc/saio/swift/single-process.conf', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/a35891312ab2c037b05aded7f9e84b179f5c4ead', 'message': ""WIP: new attempt at single-process\n\nThis new patch simplifies the paco PUT path by assuming that a paco\nnode is also a 1-replica node (e.g., swift-on-file). This allows us\nto bypass much of the PUT code to setup connections, send data and\nget responses.\n\nTo test, create a new policy with one replica, also create a file\nunder /etc/swift/single-process.conf with the configuration for the\nnew 'in-process' object server.\n\nCurrently, only PUT and GET path have been coded, next will be\nPOST, DELETE\n\nChange-Id: I1f2cd3102728fda15c440d308208bbf77d1fa07b\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\nSigned-off-by: Prashanth Pai <ppai@redhat.com>\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n""}]",3,159285,a35891312ab2c037b05aded7f9e84b179f5c4ead,29,7,7,9625,,,0,"WIP: new attempt at single-process

This new patch simplifies the paco PUT path by assuming that a paco
node is also a 1-replica node (e.g., swift-on-file). This allows us
to bypass much of the PUT code to setup connections, send data and
get responses.

To test, create a new policy with one replica, also create a file
under /etc/swift/single-process.conf with the configuration for the
new 'in-process' object server.

Currently, only PUT and GET path have been coded, next will be
POST, DELETE

Change-Id: I1f2cd3102728fda15c440d308208bbf77d1fa07b
Signed-off-by: Thiago da Silva <thiago@redhat.com>
Signed-off-by: Prashanth Pai <ppai@redhat.com>
Signed-off-by: Thiago da Silva <thiago@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/85/159285/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/wsgi.py', 'swift/proxy/controllers/obj.py']",2,dcc4e9181d48d704ed9b35ffa6a06e7cc08df4b9,single_process," @staticmethod def _is_paco(req, nodes): # for now assuming that a paco system is also a 1-replica policy # e.g., swift-on-file if len(nodes) == 1: node = nodes[0] return all(['paco.object_server' in req.environ, node['port'] == int(req.environ.get('paco.bind_port', -1)), node['ip'] in ['localhost', '127.0.0.1']]) else: return False def _run_paco(self, nodes, req, part, headers): node = nodes[0] object_server = req.environ['paco.object_server'] environ = req.environ.copy() environ.update(headers[0]) path = req.swift_entity_path local_req = Request.blank(path, headers=headers[0], environ=environ) local_req.environ['PATH_INFO'] = '/' + node['device'] + \ '/' + str(part) + path return local_req.get_response(object_server) if self._is_paco(req, nodes): resp = self._run_paco(nodes, req, partition, outgoing_headers) else: conns = self._get_put_connections(req, nodes, partition, outgoing_headers, obj_ring) try: self._transfer_data(req, data_source, conns, nodes) statuses, reasons, bodies, etags = self._get_put_responses( req, conns, nodes) except HTTPException as resp: return resp finally: for conn in conns: conn.close() if len(etags) > 1: self.app.logger.error( _('Object servers returned %s mismatched etags'), len(etags)) return HTTPServerError(request=req) etag = etags.pop() if len(etags) else None resp = self.best_response(req, statuses, reasons, bodies, _('Object PUT'), etag=etag)"," conns = self._get_put_connections(req, nodes, partition, outgoing_headers, obj_ring) try: self._transfer_data(req, data_source, conns, nodes) statuses, reasons, bodies, etags = self._get_put_responses( req, conns, nodes) except HTTPException as resp: return resp finally: for conn in conns: conn.close() if len(etags) > 1: self.app.logger.error( _('Object servers returned %s mismatched etags'), len(etags)) return HTTPServerError(request=req) etag = etags.pop() if len(etags) else None resp = self.best_response(req, statuses, reasons, bodies, _('Object PUT'), etag=etag)",59,19
openstack%2Ftripleo-heat-templates~stable%2Fpike~I753861c69e64d341e313e8878ac629136aa5852c,openstack/tripleo-heat-templates,stable/pike,I753861c69e64d341e313e8878ac629136aa5852c,Memory channels parameter default value,MERGED,2017-12-14 06:52:18.000000000,2017-12-18 11:49:01.000000000,2017-12-18 11:49:01.000000000,"[{'_account_id': 3153}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-14 06:52:18.000000000', 'files': ['environments/neutron-ovs-dpdk.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2c8809e6a9d236e370f063e324775c5d76a346f5', 'message': 'Memory channels parameter default value\n\nThis change is to add memory channels parameter with default\nvalue as ""4"" and it can be updated based on hardware spec.\nMemory channels parameter is not derivable in mistral derive\nparameters using introspection memory bank data since format\nof memory slot name is not consitent on different environments.\n\nChange-Id: I753861c69e64d341e313e8878ac629136aa5852c\nCloses-Bug: #1734814\n(cherry picked from commit ebf312433f5d2bc9eb082871f93ed575e6aca056)\n'}]",0,527875,2c8809e6a9d236e370f063e324775c5d76a346f5,8,4,1,22865,,,0,"Memory channels parameter default value

This change is to add memory channels parameter with default
value as ""4"" and it can be updated based on hardware spec.
Memory channels parameter is not derivable in mistral derive
parameters using introspection memory bank data since format
of memory slot name is not consitent on different environments.

Change-Id: I753861c69e64d341e313e8878ac629136aa5852c
Closes-Bug: #1734814
(cherry picked from commit ebf312433f5d2bc9eb082871f93ed575e6aca056)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/75/527875/1 && git format-patch -1 --stdout FETCH_HEAD,['environments/neutron-ovs-dpdk.yaml'],1,2c8809e6a9d236e370f063e324775c5d76a346f5,bug/1734814-stable/pike," OvsDpdkMemoryChannels: ""4""",,1,0
openstack%2Ftricircle~master~Ic29ddf2f60517d3808e1d9865abb17d9c4614660,openstack/tricircle,master,Ic29ddf2f60517d3808e1d9865abb17d9c4614660,Updated from global requirements,MERGED,2017-12-07 13:51:08.000000000,2017-12-18 11:35:32.000000000,2017-12-18 11:35:32.000000000,"[{'_account_id': 12076}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 13:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/001230dca86f3741c3b44e9c9e28c2cc28547ebe', 'message': 'Updated from global requirements\n\nChange-Id: Ic29ddf2f60517d3808e1d9865abb17d9c4614660\n'}, {'number': 2, 'created': '2017-12-15 22:21:21.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/a5df0583b1a36fb89edccad3d9e3c2ea49c5e0c2', 'message': 'Updated from global requirements\n\nChange-Id: Ic29ddf2f60517d3808e1d9865abb17d9c4614660\n'}]",0,526396,a5df0583b1a36fb89edccad3d9e3c2ea49c5e0c2,10,2,2,11131,,,0,"Updated from global requirements

Change-Id: Ic29ddf2f60517d3808e1d9865abb17d9c4614660
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/96/526396/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,001230dca86f3741c3b44e9c9e28c2cc28547ebe,openstack/requirements,oslo.policy>=1.30.0 # Apache-2.0,oslo.policy>=1.23.0 # Apache-2.0,1,1
openstack%2Ffreezer-tempest-plugin~master~I8ec801c98fc212cef8ffec9d71ec76a17b114a97,openstack/freezer-tempest-plugin,master,I8ec801c98fc212cef8ffec9d71ec76a17b114a97,Remove python 3.3 from setup.cfg,MERGED,2017-06-20 15:03:01.000000000,2017-12-18 11:33:29.000000000,2017-12-18 11:33:29.000000000,"[{'_account_id': 13940}, {'_account_id': 22348}, {'_account_id': 22405}]","[{'number': 1, 'created': '2017-06-20 15:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-tempest-plugin/commit/7470ff744530a4202c6faf29907bf7221ec438b2', 'message': 'Remove python 3.3 from setup.cfg\n\nChange-Id: I8ec801c98fc212cef8ffec9d71ec76a17b114a97\n'}, {'number': 2, 'created': '2017-12-18 10:52:57.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/freezer-tempest-plugin/commit/0aba5f42cc36dc41ef399f5c1e1d73643ac173ca', 'message': 'Remove python 3.3 from setup.cfg\n\nChange-Id: I8ec801c98fc212cef8ffec9d71ec76a17b114a97\n'}]",0,475837,0aba5f42cc36dc41ef399f5c1e1d73643ac173ca,14,3,2,13940,,,0,"Remove python 3.3 from setup.cfg

Change-Id: I8ec801c98fc212cef8ffec9d71ec76a17b114a97
",git fetch https://review.opendev.org/openstack/freezer-tempest-plugin refs/changes/37/475837/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,7470ff744530a4202c6faf29907bf7221ec438b2,,, Programming Language :: Python :: 3.3,0,1
openstack%2Fmonasca-api~master~Ida5caa4d9999daceb381d14659af6d3ba8d2c343,openstack/monasca-api,master,Ida5caa4d9999daceb381d14659af6d3ba8d2c343,Replace iteritems() with items(),MERGED,2017-12-14 13:02:03.000000000,2017-12-18 11:30:10.000000000,2017-12-18 11:30:09.000000000,"[{'_account_id': 3}, {'_account_id': 14123}, {'_account_id': 15233}, {'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2017-12-14 13:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/b66428d88cff1b7150b8a5b003954304d32af03c', 'message': 'Replace iteritems() with items()\n\nIn process of Python 3 support implementation replacing dict.iteritems() with\ndict.items().\n\nChange-Id: Ida5caa4d9999daceb381d14659af6d3ba8d2c343\nStory: 2000975\nTask: 5948\n'}, {'number': 2, 'created': '2017-12-18 08:36:41.000000000', 'files': ['monasca_tempest_tests/services/monasca_client.py', 'devstack/files/schema/influxdb_setup.py', 'monasca_api/common/repositories/cassandra/metrics_repository.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/2639d50b3a06bb36a8291e07b4a9b03ebd009328', 'message': 'Replace iteritems() with items()\n\nIn process of Python 3 support implementation replacing dict.iteritems() with\ndict.items().\n\nChange-Id: Ida5caa4d9999daceb381d14659af6d3ba8d2c343\nStory: 2000975\nTask: 5948\n'}]",0,527953,2639d50b3a06bb36a8291e07b4a9b03ebd009328,14,6,2,16222,,,0,"Replace iteritems() with items()

In process of Python 3 support implementation replacing dict.iteritems() with
dict.items().

Change-Id: Ida5caa4d9999daceb381d14659af6d3ba8d2c343
Story: 2000975
Task: 5948
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/53/527953/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_tempest_tests/services/monasca_client.py', 'devstack/files/schema/influxdb_setup.py', 'monasca_api/common/repositories/cassandra/metrics_repository.py']",3,b66428d88cff1b7150b8a5b003954304d32af03c,python3," for k, v in dims.items(): for k, v in dims.items():"," for k, v in dims.iteritems(): for k, v in dims.iteritems():",8,8
openstack%2Fosprofiler~master~I861b619131845d601cfb22730c46a14ec683bafd,openstack/osprofiler,master,I861b619131845d601cfb22730c46a14ec683bafd,[WIP] Refactor drivers,ABANDONED,2017-10-27 15:11:00.000000000,2017-12-18 11:25:27.000000000,,"[{'_account_id': 5950}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-27 15:11:00.000000000', 'files': ['osprofiler/tests/unit/drivers/test_redis_driver.py', 'osprofiler/tests/unit/drivers/test_ceilometer.py', 'osprofiler/drivers/base.py', 'osprofiler/drivers/messaging.py', 'osprofiler/drivers/elasticsearch_driver.py', 'osprofiler/drivers/redis_driver.py', 'osprofiler/tests/unit/drivers/test_messaging.py', 'osprofiler/drivers/ceilometer.py', 'osprofiler/tests/unit/drivers/test_base.py', 'osprofiler/tests/unit/drivers/test_loginsight.py', 'osprofiler/tests/unit/drivers/test_mongodb.py', 'osprofiler/tests/unit/test_notifier.py', 'osprofiler/drivers/mongodb.py', 'osprofiler/cmd/commands.py', 'osprofiler/drivers/loginsight.py', 'osprofiler/notifier.py', 'osprofiler/tests/unit/cmd/test_shell.py', 'osprofiler/tests/unit/drivers/test_elasticsearch.py'], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/b024bf2310e3464955a74f83b4d0ecf510947a5c', 'message': '[WIP] Refactor drivers\n\n* Split drivers into NotificationDriver and ReportDriver\n* Clean-up driver API to avoid code duplicates\n\nChange-Id: I861b619131845d601cfb22730c46a14ec683bafd\n'}]",0,515739,b024bf2310e3464955a74f83b4d0ecf510947a5c,4,2,1,5950,,,0,"[WIP] Refactor drivers

* Split drivers into NotificationDriver and ReportDriver
* Clean-up driver API to avoid code duplicates

Change-Id: I861b619131845d601cfb22730c46a14ec683bafd
",git fetch https://review.opendev.org/openstack/osprofiler refs/changes/39/515739/1 && git format-patch -1 --stdout FETCH_HEAD,"['osprofiler/tests/unit/drivers/test_redis_driver.py', 'osprofiler/tests/unit/drivers/test_ceilometer.py', 'osprofiler/drivers/base.py', 'osprofiler/drivers/messaging.py', 'osprofiler/drivers/elasticsearch_driver.py', 'osprofiler/drivers/redis_driver.py', 'osprofiler/tests/unit/drivers/test_messaging.py', 'osprofiler/drivers/ceilometer.py', 'osprofiler/tests/unit/drivers/test_base.py', 'osprofiler/tests/unit/drivers/test_loginsight.py', 'osprofiler/tests/unit/drivers/test_mongodb.py', 'osprofiler/tests/unit/test_notifier.py', 'osprofiler/drivers/mongodb.py', 'osprofiler/cmd/commands.py', 'osprofiler/drivers/loginsight.py', 'osprofiler/notifier.py', 'osprofiler/tests/unit/cmd/test_shell.py', 'osprofiler/tests/unit/drivers/test_elasticsearch.py']",18,b024bf2310e3464955a74f83b4d0ecf510947a5c,refactor-drivers, self.elasticsearch.generate_report(base_id) self.elasticsearch.generate_report(base_id), get_report = self.elasticsearch.get_report get_report(base_id) self.elasticsearch.get_report(base_id),243,565
openstack%2Fkolla-ansible~stable%2Focata~I62512dc022426cc762ff603d8554e48651fa621f,openstack/kolla-ansible,stable/ocata,I62512dc022426cc762ff603d8554e48651fa621f,"The notify ""Restart keystone containers"" is not correct",MERGED,2017-12-18 03:33:20.000000000,2017-12-18 10:56:45.000000000,2017-12-18 10:56:45.000000000,"[{'_account_id': 167}, {'_account_id': 19316}, {'_account_id': 22037}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 03:33:20.000000000', 'files': ['ansible/roles/keystone/tasks/config.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/56d59337801a9b25cb28c5cdf38aa580dd6ebbd8', 'message': 'The notify ""Restart keystone containers"" is not correct\n\nNo handler named ""Restart keystone containers"", and we should restart\nthe keystone and the keystone-fernet container according to the context\n\nCloses-Bug: #1699924\n\nChange-Id: I62512dc022426cc762ff603d8554e48651fa621f\n(cherry picked from commit 77358dd920c1abab64d111496d94a77b9e5ca6c3)\n'}]",0,528612,56d59337801a9b25cb28c5cdf38aa580dd6ebbd8,7,4,1,7488,,,0,"The notify ""Restart keystone containers"" is not correct

No handler named ""Restart keystone containers"", and we should restart
the keystone and the keystone-fernet container according to the context

Closes-Bug: #1699924

Change-Id: I62512dc022426cc762ff603d8554e48651fa621f
(cherry picked from commit 77358dd920c1abab64d111496d94a77b9e5ca6c3)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/12/528612/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/keystone/tasks/config.yml'],1,56d59337801a9b25cb28c5cdf38aa580dd6ebbd8,, - Restart keystone container - Restart keystone-fernet container, - Restart keystone containers,2,1
openstack%2Fkolla-ansible~stable%2Focata~I05c1faf2551bb5e70c299e884adf58cd2af52739,openstack/kolla-ansible,stable/ocata,I05c1faf2551bb5e70c299e884adf58cd2af52739,Clear all l3 related namespace before starting neutron-l3-agent,MERGED,2017-08-16 05:43:25.000000000,2017-12-18 10:56:22.000000000,2017-12-18 10:56:22.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 7488}, {'_account_id': 11869}, {'_account_id': 19779}, {'_account_id': 22348}, {'_account_id': 24441}]","[{'number': 1, 'created': '2017-08-16 05:43:25.000000000', 'files': ['ansible/roles/neutron/handlers/main.yml', 'ansible/roles/neutron/templates/neutron-l3-agent-wrapper.sh.j2', 'ansible/roles/neutron/templates/neutron-vpnaas-agent.json.j2', 'ansible/roles/neutron/tasks/config.yml', 'ansible/roles/neutron/templates/neutron-vpnaas-agent-wrapper.sh.j2', 'ansible/roles/neutron/templates/neutron-l3-agent.json.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0bb7b386cb11ac0feeab15ec04c94688153383d1', 'message': 'Clear all l3 related namespace before starting neutron-l3-agent\n\nRemove all l3 related namespaces in case of multiple active routers in\nl3 high available mode. The root cause is that keepalived does not\nremove the vip address from nic during starting.\n\nneutron-vpnaas-agent is subclass of l3 agent, so should remove all l3\nrelated namespace before starting vpnaas agent.\n\nCloses-Bug: #1703078\nDepends-On: Ic9417d2eb03e0dd93f7c668b189b4ad9c72eae0f\nChange-Id: I05c1faf2551bb5e70c299e884adf58cd2af52739\n(cherry picked from commit 58964d6825492636405497567e0de968ea81f222)\n'}]",0,494078,0bb7b386cb11ac0feeab15ec04c94688153383d1,12,7,1,7488,,,0,"Clear all l3 related namespace before starting neutron-l3-agent

Remove all l3 related namespaces in case of multiple active routers in
l3 high available mode. The root cause is that keepalived does not
remove the vip address from nic during starting.

neutron-vpnaas-agent is subclass of l3 agent, so should remove all l3
related namespace before starting vpnaas agent.

Closes-Bug: #1703078
Depends-On: Ic9417d2eb03e0dd93f7c668b189b4ad9c72eae0f
Change-Id: I05c1faf2551bb5e70c299e884adf58cd2af52739
(cherry picked from commit 58964d6825492636405497567e0de968ea81f222)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/78/494078/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/neutron/handlers/main.yml', 'ansible/roles/neutron/templates/neutron-l3-agent-wrapper.sh.j2', 'ansible/roles/neutron/templates/neutron-vpnaas-agent.json.j2', 'ansible/roles/neutron/tasks/config.yml', 'ansible/roles/neutron/templates/neutron-vpnaas-agent-wrapper.sh.j2', 'ansible/roles/neutron/templates/neutron-l3-agent.json.j2']",6,0bb7b386cb11ac0feeab15ec04c94688153383d1,bug/1703078," ""command"": ""/usr/local/bin/neutron-l3-agent-wrapper.sh"", ""source"": ""{{ container_config_directory }}/neutron-l3-agent-wrapper.sh"", ""dest"": ""/usr/local/bin/neutron-l3-agent-wrapper.sh"", ""owner"": ""root"", ""perm"": ""0755"" }, {"," ""command"": ""neutron-l3-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/l3_agent.ini --config-file /etc/neutron/fwaas_driver.ini"",",75,2
openstack%2Fkolla-ansible~stable%2Focata~I38661a0bc2163a7f72febd98b7ae6f51c5d45ad5,openstack/kolla-ansible,stable/ocata,I38661a0bc2163a7f72febd98b7ae6f51c5d45ad5,Enable heat-api proxy header parsing,MERGED,2017-12-18 03:52:15.000000000,2017-12-18 10:56:21.000000000,2017-12-18 10:56:21.000000000,"[{'_account_id': 167}, {'_account_id': 7488}, {'_account_id': 19316}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 03:52:15.000000000', 'files': ['ansible/roles/heat/templates/heat.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7bbf6ba483fbbccd6a60c019bd58621947b33006', 'message': 'Enable heat-api proxy header parsing\n\nheat-api kept redirecting clients to use http:// instead of https://\nwhen communicating with our https:// only loadbalancer\n\nPlease examine the logic for enabling it carefully, it\'s hard to know\nif it should be enabled or not, potenitially it could be a security\nrisk.\n\nBased on openstack-ansible-os_heat:\ncommit 4033a0f854cba6719c61812ef5b553e932a6c6c2\nAuthor: Kyle L. Henderson <kyleh@us.ibm.com>\n\n    Enable oslo_middleware proxy header parsing\n\n""Heat has moved to using oslo_middleware for the http proxy header\nparsing, however the default is to not parse the headers.  When\nthe external protocol differs from the internal protocol this\nparsing is required in order for heat to work properly since it\nwill return 302 redirects to the client during some operations\n(such as delete stack).\n\nAn example of this is when using haproxy with https configured\nfor the external protocol and http for the internal protocol.\nIf the oslo_middleware does not parse the headers, then any\n302 redirects would specify a url with http rather than\ncorrectly specifying https and the heat client would fail to\nconnect on the redirect url.""\n\nChange-Id: I38661a0bc2163a7f72febd98b7ae6f51c5d45ad5\n(cherry picked from commit 63e5c444dda43958843f7729056a254708e92002)\n'}]",0,528614,7bbf6ba483fbbccd6a60c019bd58621947b33006,9,4,1,7488,,,0,"Enable heat-api proxy header parsing

heat-api kept redirecting clients to use http:// instead of https://
when communicating with our https:// only loadbalancer

Please examine the logic for enabling it carefully, it's hard to know
if it should be enabled or not, potenitially it could be a security
risk.

Based on openstack-ansible-os_heat:
commit 4033a0f854cba6719c61812ef5b553e932a6c6c2
Author: Kyle L. Henderson <kyleh@us.ibm.com>

    Enable oslo_middleware proxy header parsing

""Heat has moved to using oslo_middleware for the http proxy header
parsing, however the default is to not parse the headers.  When
the external protocol differs from the internal protocol this
parsing is required in order for heat to work properly since it
will return 302 redirects to the client during some operations
(such as delete stack).

An example of this is when using haproxy with https configured
for the external protocol and http for the internal protocol.
If the oslo_middleware does not parse the headers, then any
302 redirects would specify a url with http rather than
correctly specifying https and the heat client would fail to
connect on the redirect url.""

Change-Id: I38661a0bc2163a7f72febd98b7ae6f51c5d45ad5
(cherry picked from commit 63e5c444dda43958843f7729056a254708e92002)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/14/528614/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/heat/templates/heat.conf.j2'],1,7bbf6ba483fbbccd6a60c019bd58621947b33006,, {% if public_protocol != internal_protocol and kolla_external_fqdn != kolla_internal_fqdn %} [oslo_middleware] enable_proxy_headers_parsing = True {% endif %},,5,0
openstack%2Fkolla-ansible~master~Ic53308adb7fa3a10a7b1f1caa27ca7dd67037cdd,openstack/kolla-ansible,master,Ic53308adb7fa3a10a7b1f1caa27ca7dd67037cdd,missing permissions when running as non root,MERGED,2017-12-12 15:54:35.000000000,2017-12-18 10:56:21.000000000,2017-12-18 10:56:21.000000000,"[{'_account_id': 167}, {'_account_id': 8157}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 24759}]","[{'number': 1, 'created': '2017-12-12 15:54:35.000000000', 'files': ['ansible/roles/elasticsearch/tasks/config.yml', 'ansible/roles/openvswitch/tasks/config.yml', 'ansible/roles/neutron/tasks/config.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fc593d531b7bbd798dc301b9b214301d65d8abf6', 'message': 'missing permissions when running as non root\n\nsome tasks miss permissions to be run as a normal user\n\nChange-Id: Ic53308adb7fa3a10a7b1f1caa27ca7dd67037cdd\n'}]",0,527443,fc593d531b7bbd798dc301b9b214301d65d8abf6,9,6,1,2888,,,0,"missing permissions when running as non root

some tasks miss permissions to be run as a normal user

Change-Id: Ic53308adb7fa3a10a7b1f1caa27ca7dd67037cdd
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/43/527443/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/elasticsearch/tasks/config.yml', 'ansible/roles/openvswitch/tasks/config.yml', 'ansible/roles/neutron/tasks/config.yml']",3,fc593d531b7bbd798dc301b9b214301d65d8abf6,missing_become, become: true become: true,,5,0
openstack%2Fkeystone~master~Id96bdb9dc51640cef98c98c93400a503dd880371,openstack/keystone,master,Id96bdb9dc51640cef98c98c93400a503dd880371,Remove dead code for auth_context,MERGED,2017-12-04 21:33:15.000000000,2017-12-18 10:47:48.000000000,2017-12-18 10:47:48.000000000,"[{'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8482}, {'_account_id': 11022}, {'_account_id': 13063}, {'_account_id': 13478}, {'_account_id': 15054}, {'_account_id': 16465}, {'_account_id': 17860}, {'_account_id': 18338}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27372}]","[{'number': 1, 'created': '2017-12-04 21:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d26d894621a456d129afc40cabfe0e8371235c70', 'message': 'Remove dead code for auth_context\n\nChange-Id: Id96bdb9dc51640cef98c98c93400a503dd880371\n'}, {'number': 2, 'created': '2017-12-09 02:39:25.000000000', 'files': ['keystone/tests/unit/common/test_authorization.py', 'keystone/common/authorization.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e9332a29b546957be6be5421e78855daec042958', 'message': 'Remove dead code for auth_context\n\nChange-Id: Id96bdb9dc51640cef98c98c93400a503dd880371\n'}]",3,525325,e9332a29b546957be6be5421e78855daec042958,15,19,2,2218,,,0,"Remove dead code for auth_context

Change-Id: Id96bdb9dc51640cef98c98c93400a503dd880371
",git fetch https://review.opendev.org/openstack/keystone refs/changes/25/525325/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/common/test_authorization.py', 'keystone/common/authorization.py']",2,d26d894621a456d129afc40cabfe0e8371235c70,remove-auth-copy,,"from keystone.i18n import _""""""Environment variable used to convey the Keystone auth context. Auth context is essentially the user credential used for policy enforcement. It is a dictionary with the following attributes: * ``token``: Token from the request * ``user_id``: user ID of the principal * ``user_name``: user name of the principal * ``user_domain_id`` (optional): Domain ID of the principal if the principal has a domain. * ``user_domain_name`` (optional): Domain name of the principal if the principal has a domain. * ``project_id`` (optional): project ID of the scoped project if auth is project-scoped * ``project_name`` (optional): project name of the scoped project if auth is project-scoped * ``project_domain_id`` (optional): Domain ID of the scoped project if auth is project-scoped. * ``project_domain_name`` (optional): Domain name of the scoped project if auth is project-scoped. * ``domain_id`` (optional): domain ID of the scoped domain if auth is domain-scoped * ``domain_name`` (optional): domain name of the scoped domain if auth is domain-scoped * ``is_delegated_auth``: True if this is delegated (via trust or oauth) * ``trust_id``: Trust ID if trust-scoped, or None * ``trustor_id``: Trustor ID if trust-scoped, or None * ``trustee_id``: Trustee ID if trust-scoped, or None * ``consumer_id``: OAuth consumer ID, or None * ``access_token_id``: OAuth access token ID, or None * ``roles`` (optional): list of role names for the given scope * ``group_ids`` (optional): list of group IDs for which the API user has membership if token was for a federated user """"""def token_to_auth_context(token): if not isinstance(token, token_model.KeystoneToken): raise exception.UnexpectedError(_('token reference must be a ' 'KeystoneToken type, got: %s') % type(token)) auth_context = {'token': token, 'is_delegated_auth': False} try: auth_context['user_id'] = token.user_id except KeyError: LOG.warning('RBAC: Invalid user data in token') raise exception.Unauthorized(_('No user_id in token')) auth_context['user_name'] = token.user_name auth_context['user_domain_id'] = token.user_domain_id auth_context['user_domain_name'] = token.user_domain_name if token.project_scoped: auth_context['project_id'] = token.project_id auth_context['project_name'] = token.project_name auth_context['project_domain_id'] = token.project_domain_id auth_context['project_domain_name'] = token.project_domain_name auth_context['is_domain'] = token.is_domain elif token.domain_scoped: auth_context['domain_id'] = token.domain_id auth_context['domain_name'] = token.domain_name else: LOG.debug('RBAC: Proceeding without project or domain scope') if token.trust_scoped: auth_context['is_delegated_auth'] = True auth_context['trust_id'] = token.trust_id auth_context['trustor_id'] = token.trustor_user_id auth_context['trustee_id'] = token.trustee_user_id else: # NOTE(lbragstad): These variables will already be set to None but we # add the else statement here for readability. auth_context['trust_id'] = None auth_context['trustor_id'] = None auth_context['trustee_id'] = None roles = token.role_names if roles: auth_context['roles'] = roles if token.oauth_scoped: auth_context['is_delegated_auth'] = True auth_context['consumer_id'] = token.oauth_consumer_id auth_context['access_token_id'] = token.oauth_access_token_id else: # NOTE(lbragstad): These variables will already be set to None but we # add the else statement here for readability. auth_context['consumer_id'] = None auth_context['access_token_id'] = None if token.is_federated_user: auth_context['group_ids'] = token.federation_group_ids auth_context['is_admin_project'] = token.is_admin_project return auth_context ",0,264
openstack%2Fkolla-ansible~master~Ic0a9deb36fce154022925d26411e01a8ffe18b50,openstack/kolla-ansible,master,Ic0a9deb36fce154022925d26411e01a8ffe18b50,Make fluentd enabled configurable,MERGED,2017-12-15 02:27:11.000000000,2017-12-18 10:30:36.000000000,2017-12-18 10:30:36.000000000,"[{'_account_id': 2834}, {'_account_id': 7488}, {'_account_id': 10787}, {'_account_id': 19316}, {'_account_id': 20663}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 23717}, {'_account_id': 24072}, {'_account_id': 24759}, {'_account_id': 26299}, {'_account_id': 27272}]","[{'number': 1, 'created': '2017-12-15 02:27:11.000000000', 'files': ['ansible/roles/common/tasks/pull.yml', 'ansible/roles/common/tasks/config.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1d36adcb4ffc64df3fc7f1a1488bff02acf9b40f', 'message': 'Make fluentd enabled configurable\n\nAlthough there is an option ""enable_fluentd"", but there are still\nsome tasks that make fluentd not configurable.\n\nChange-Id: Ic0a9deb36fce154022925d26411e01a8ffe18b50\nSigned-off-by: Xinliang Liu <xinliang.liu@linaro.org>\n'}]",0,528143,1d36adcb4ffc64df3fc7f1a1488bff02acf9b40f,13,12,1,22997,,,0,"Make fluentd enabled configurable

Although there is an option ""enable_fluentd"", but there are still
some tasks that make fluentd not configurable.

Change-Id: Ic0a9deb36fce154022925d26411e01a8ffe18b50
Signed-off-by: Xinliang Liu <xinliang.liu@linaro.org>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/43/528143/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/common/tasks/pull.yml', 'ansible/roles/common/tasks/config.yml']",2,1d36adcb4ffc64df3fc7f1a1488bff02acf9b40f,fluentd-enabled-configurable-fix, when: - enable_fluentd | bool when: - enable_fluentd | bool,,6,0
openstack%2Fovsdbapp~master~Idf3b3a4a840b0db3cf91ead82d36d638cbb3f379,openstack/ovsdbapp,master,Idf3b3a4a840b0db3cf91ead82d36d638cbb3f379,Extend transaction with multiple commands,MERGED,2017-11-30 18:25:09.000000000,2017-12-18 10:28:17.000000000,2017-12-18 10:28:17.000000000,"[{'_account_id': 5756}, {'_account_id': 8655}, {'_account_id': 20229}, {'_account_id': 22348}, {'_account_id': 27378}]","[{'number': 1, 'created': '2017-11-30 18:25:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/c6ae5308a553e3f4fbde4d773aeb3878644c8446', 'message': 'Extend transaction with multiple commands\n\nAllow user to extend transaction with multiple commands in one call.\nThis is convenient when transaction is created in main scope, but\ncommands are created and returned from other functions.\n\nChange-Id: Idf3b3a4a840b0db3cf91ead82d36d638cbb3f379\n'}, {'number': 2, 'created': '2017-11-30 20:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/883fde0d36473be8560a907c29671e1c716960d3', 'message': 'Extend transaction with multiple commands\n\nAllow user to extend transaction with multiple commands in one call.\nThis is convenient when transaction is created in main scope, but\ncommands are created and returned from other functions.\n\nChange-Id: Idf3b3a4a840b0db3cf91ead82d36d638cbb3f379\n'}, {'number': 3, 'created': '2017-12-04 08:44:33.000000000', 'files': ['ovsdbapp/tests/functional/schema/open_vswitch/test_impl_idl.py', 'ovsdbapp/api.py'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/15836d3df224c773bc55ca9f77bc55dabc61eb5b', 'message': 'Extend transaction with multiple commands\n\nAllow user to extend transaction with multiple commands in one call.\nThis is convenient when transaction is created in main scope, but\ncommands are created and returned from other functions.\n\nChange-Id: Idf3b3a4a840b0db3cf91ead82d36d638cbb3f379\n'}]",2,524308,15836d3df224c773bc55ca9f77bc55dabc61eb5b,14,5,3,27378,,,0,"Extend transaction with multiple commands

Allow user to extend transaction with multiple commands in one call.
This is convenient when transaction is created in main scope, but
commands are created and returned from other functions.

Change-Id: Idf3b3a4a840b0db3cf91ead82d36d638cbb3f379
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/08/524308/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovsdbapp/tests/functional/schema/open_vswitch/test_impl_idl.py', 'ovsdbapp/api.py']",2,c6ae5308a553e3f4fbde4d773aeb3878644c8446,3," def extend(self, commands): """"""Add multiple OVSDB operations to the transaction"""""" for command in commands: self.add(command) ",,7,2
openstack%2Fovsdbapp~master~I2e07d2d577982e492b24844f303bb5edacf4f7ba,openstack/ovsdbapp,master,I2e07d2d577982e492b24844f303bb5edacf4f7ba,Document *_extenal_ids methods in open_vswitch/api.py,MERGED,2017-12-09 18:10:37.000000000,2017-12-18 10:22:33.000000000,2017-12-18 10:22:33.000000000,"[{'_account_id': 5756}, {'_account_id': 8655}, {'_account_id': 20229}, {'_account_id': 22348}, {'_account_id': 27378}]","[{'number': 1, 'created': '2017-12-09 18:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/6cea60cb7e6a732ceb818c8bbd8349fe737fca40', 'message': 'Document *_extenal_ids methods in open_vswitch/api.py\n\nChange-Id: I2e07d2d577982e492b24844f303bb5edacf4f7ba\n'}, {'number': 2, 'created': '2017-12-11 11:24:08.000000000', 'files': ['ovsdbapp/schema/open_vswitch/api.py'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/b72529470c49c588d1fd0f3e605653a751dedc49', 'message': 'Document *_extenal_ids methods in open_vswitch/api.py\n\nChange-Id: I2e07d2d577982e492b24844f303bb5edacf4f7ba\n'}]",4,526874,b72529470c49c588d1fd0f3e605653a751dedc49,12,5,2,27378,,,0,"Document *_extenal_ids methods in open_vswitch/api.py

Change-Id: I2e07d2d577982e492b24844f303bb5edacf4f7ba
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/74/526874/1 && git format-patch -1 --stdout FETCH_HEAD,['ovsdbapp/schema/open_vswitch/api.py'],1,6cea60cb7e6a732ceb818c8bbd8349fe737fca40,fix_open_vswitch_external_id_api," def br_set_external_id(self, name, field): """"""Create a command to set the OVS Bridge's external_ids :param name: The name of the bridge :type name: string :param field: The external_ids field to set :type field: string :param field: The external_ids value to set :type field: string :returns: :class:`Command` with field no result """""" @abc.abstractmethod @abc.abstractmethod def iface_get_external_id(self, name, field): """"""Create a command to return a field from the Interface's external_ids :param name: The name of the interface :type name: string :param field: The external_ids field to return :type field: string :returns: :class:`Command` with field value result """""" @abc.abstractmethod def iface_set_external_id(self, name, field): """"""Create a command to set the OVS Interface's external_ids :param name: The name of the interface :type name: string :param field: The external_ids field to set :type field: string :param field: The external_ids value to set :type field: string :returns: :class:`Command` with field no result """"""",,37,0
openstack%2Ftripleo-common~stable%2Fpike~I9970abae47ca355861e37cdb5db0ab24d564b57a,openstack/tripleo-common,stable/pike,I9970abae47ca355861e37cdb5db0ab24d564b57a,Add json_parse and yaml_parse mistral expression functions,MERGED,2017-12-15 14:27:18.000000000,2017-12-18 10:18:21.000000000,2017-12-16 14:29:30.000000000,"[{'_account_id': 7065}, {'_account_id': 9712}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-15 14:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c4d08af1ea4bf3eb4d7953594fd88a7dff69334b', 'message': 'Add json_parse and yaml_parse mistral actions\n\nThis change adds parsing of JSON and YAML as a mistral action.\n\nChange-Id: I9970abae47ca355861e37cdb5db0ab24d564b57a\nRelated-Bug: #1736707\n'}, {'number': 2, 'created': '2017-12-15 15:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b7f9737ed3f2009f33c063d54e5d4d88701f141e', 'message': 'Add json_parse and yaml_parse mistral actions\n\nThis change adds parsing of JSON and YAML as a mistral action.\n\nChange-Id: I9970abae47ca355861e37cdb5db0ab24d564b57a\nRelated-Bug: #1736707\n'}, {'number': 3, 'created': '2017-12-15 15:22:04.000000000', 'files': ['tripleo_common/utils/mistral_expression_utils.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9b29951875b4251bf0de578186ab6248daa3afac', 'message': 'Add json_parse and yaml_parse mistral expression functions\n\nThis change adds parsing of JSON and YAML as a mistral functions.\n\nChange-Id: I9970abae47ca355861e37cdb5db0ab24d564b57a\nRelated-Bug: #1736707\n'}]",0,528283,9b29951875b4251bf0de578186ab6248daa3afac,13,5,3,6796,,,0,"Add json_parse and yaml_parse mistral expression functions

This change adds parsing of JSON and YAML as a mistral functions.

Change-Id: I9970abae47ca355861e37cdb5db0ab24d564b57a
Related-Bug: #1736707
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/83/528283/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/actions/json_parse.py', 'tripleo_common/actions/yaml_parse.py', 'setup.cfg']",3,c4d08af1ea4bf3eb4d7953594fd88a7dff69334b,bug/1736707, tripleo.json_parse = tripleo_common.actions.json_parse:JsonParse tripleo.yaml_parse = tripleo_common.actions.yaml_parse:YamlParse,,22,0
openstack%2Ftripleo-ci~master~I5e0512bbea39467e9b6ee26208f915b2a9080c61,openstack/tripleo-ci,master,I5e0512bbea39467e9b6ee26208f915b2a9080c61,DNM: test stable branch repos,ABANDONED,2017-12-14 17:55:57.000000000,2017-12-18 09:56:15.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-14 17:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/edc8f7937d2c5457f19d9596cedec290987298e3', 'message': 'DNM: test stable branch repos\n\nChange-Id: I5e0512bbea39467e9b6ee26208f915b2a9080c61\nDepends-On: I96c6ccf05b27e9f81c3e4eed6538b35e7739452f\n'}, {'number': 2, 'created': '2017-12-18 09:46:27.000000000', 'files': ['toci_gate_test-oooq.sh', 'toci_quickstart.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fb0c4db3f2ae451c1617de01d0b2adf0293a95bc', 'message': 'DNM: test stable branch repos\n\nChange-Id: I5e0512bbea39467e9b6ee26208f915b2a9080c61\n'}]",0,528023,fb0c4db3f2ae451c1617de01d0b2adf0293a95bc,9,2,2,10969,,,0,"DNM: test stable branch repos

Change-Id: I5e0512bbea39467e9b6ee26208f915b2a9080c61
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/23/528023/2 && git format-patch -1 --stdout FETCH_HEAD,['toci_gate_test-oooq.sh'],1,edc8f7937d2c5457f19d9596cedec290987298e3,testbran,# test stable branch,,1,1
openstack%2Fmonasca-common~master~Ib09ba0f1e9fbfc72022870f268527cde1f05d565,openstack/monasca-common,master,Ib09ba0f1e9fbfc72022870f268527cde1f05d565,Add Cassandra tempest tests,MERGED,2017-12-18 08:54:56.000000000,2017-12-18 09:56:06.000000000,2017-12-18 09:56:06.000000000,"[{'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2017-12-18 08:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/e7e70309cb632fecf7d716519bad2a33707839d0', 'message': 'Add Cassandra tempest tests\n\nChange-Id: Ib09ba0f1e9fbfc72022870f268527cde1f05d565\nStory: 2001231\nTask: 6097\n'}, {'number': 2, 'created': '2017-12-18 09:01:16.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/b21dc03ddc125fd98a77dd990733aaaa2426db67', 'message': 'Add Cassandra tempest tests\n\nChange-Id: Ib09ba0f1e9fbfc72022870f268527cde1f05d565\nStory: 2001231\nTask: 6097\n'}]",0,528659,b21dc03ddc125fd98a77dd990733aaaa2426db67,9,3,2,16222,,,0,"Add Cassandra tempest tests

Change-Id: Ib09ba0f1e9fbfc72022870f268527cde1f05d565
Story: 2001231
Task: 6097
",git fetch https://review.opendev.org/openstack/monasca-common refs/changes/59/528659/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,e7e70309cb632fecf7d716519bad2a33707839d0,, voting: false - monasca-tempest-python-cassandra voting: false - monasca-tempest-java-cassandra,,4,0
openstack%2Frequirements~master~I292b0331a67f238779c8d565c5288d59a34dac69,openstack/requirements,master,I292b0331a67f238779c8d565c5288d59a34dac69,Add raven,MERGED,2017-12-06 12:01:45.000000000,2017-12-18 09:55:57.000000000,2017-12-18 09:55:57.000000000,"[{'_account_id': 6593}, {'_account_id': 11105}, {'_account_id': 14288}, {'_account_id': 16312}, {'_account_id': 22348}, {'_account_id': 26201}, {'_account_id': 26768}]","[{'number': 1, 'created': '2017-12-06 12:01:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/3ce979b5adb0481439eb2b25a9f9b6c841931066', 'message': 'Add raven\n\nRaven is client for Sentry error tracking tool. It is required\nfor sentry integration into oslo.log module.\n(https://review.openstack.org/#/c/518949/,\n https://blueprints.launchpad.net/oslo.log/+spec/sentry-handler)\nThe library is actively maintained, good code, python3 compatible,\nlicence compatible (BSD licence), packed in Ubuntu/Debian and\nFedora/RHEL.\n\nChange-Id: I292b0331a67f238779c8d565c5288d59a34dac69\n'}, {'number': 2, 'created': '2017-12-12 10:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/5142c73ca1c8141e4fb68bb85ad8c80f501fbfd5', 'message': ""Add raven\n\nRaven is client for Sentry error tracking tool. It is required\nfor sentry integration into oslo.log module.\n\nIs the library actively maintained?\nRaven is actively maintained (https://github.com/getsentry/raven-python)\n\nIs the library good code?\nCode looks good to me, testing via tox included.\n\nIs the library python 3 compatible?\nYes\n\nIs the library license compatible?\nYes (BSD licence)\n\nIs the library already packaged in the distros we target \n(Ubuntu latest / Fedora latest)?\nYes, both.\n\nIs the function of this library already covered by other libraries\nin global-requirements.txt?\nNo, as far as it's the only python library to integrate Sentry.\n\nIs the library required for OpenStack project or related dev or\ninfrastructure setup? (Answer to this should be Yes, of course) Which?\nSentry integration improves develepers experience and allows devs to\ncollect exceptions and bugs from live environment.\nhttps://review.openstack.org/#/c/518949/\nhttps://blueprints.launchpad.net/oslo.log/+spec/sentry-handler\n\nIf the library release is managed by the Openstack release process\ndoes it use the cycle-with-intermediary release type?\nRaven is 3rd party library, has nothing to do with OpenStack release\nprocess.\n\nDo I need to update anything else?\nNope.\n\nChange-Id: I292b0331a67f238779c8d565c5288d59a34dac69\n""}, {'number': 3, 'created': '2017-12-12 13:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/292b20cb02d89f9a3d7ae7f15ba6d052a6a06ad5', 'message': ""Add raven\n\nRaven is client for Sentry error tracking tool. It is required\nfor sentry integration into oslo.log module.\n\nIs the library actively maintained?\nRaven is actively maintained (https://github.com/getsentry/raven-python)\n\nIs the library good code?\nCode looks good to me, testing via tox included.\n\nIs the library python 3 compatible?\nYes\n\nIs the library license compatible?\nYes (BSD licence)\n\nIs the library already packaged in the distros we target \n(Ubuntu latest / Fedora latest)?\nYes, both.\n\nIs the function of this library already covered by other libraries\nin global-requirements.txt?\nNo, as far as it's the only python library to integrate Sentry.\n\nIs the library required for OpenStack project or related dev or\ninfrastructure setup? (Answer to this should be Yes, of course) Which?\nSentry integration improves develepers experience and allows devs to\ncollect exceptions and bugs from live environment.\nhttps://review.openstack.org/#/c/518949/\nhttps://blueprints.launchpad.net/oslo.log/+spec/sentry-handler\n\nIf the library release is managed by the Openstack release process\ndoes it use the cycle-with-intermediary release type?\nRaven is 3rd party library, has nothing to do with OpenStack release\nprocess.\n\nDo I need to update anything else?\nNope.\n\nChange-Id: I292b0331a67f238779c8d565c5288d59a34dac69\n""}, {'number': 4, 'created': '2017-12-15 21:35:33.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/58ce9cd44d5148f57fd4e052b9feb8f5cb36f59d', 'message': ""Add raven\n\nRaven is client for Sentry error tracking tool. It is required\nfor sentry integration into oslo.log module.\n\nIs the library actively maintained?\nRaven is actively maintained (https://github.com/getsentry/raven-python)\n\nIs the library good code?\nCode looks good to me, testing via tox included.\n\nIs the library python 3 compatible?\nYes\n\nIs the library license compatible?\nYes (BSD licence)\n\nIs the library already packaged in the distros we target \n(Ubuntu latest / Fedora latest)?\nYes, both.\n\nIs the function of this library already covered by other libraries\nin global-requirements.txt?\nNo, as far as it's the only python library to integrate Sentry.\n\nIs the library required for OpenStack project or related dev or\ninfrastructure setup? (Answer to this should be Yes, of course) Which?\nSentry integration improves develepers experience and allows devs to\ncollect exceptions and bugs from live environment.\nhttps://review.openstack.org/#/c/518949/\nhttps://blueprints.launchpad.net/oslo.log/+spec/sentry-handler\n\nIf the library release is managed by the Openstack release process\ndoes it use the cycle-with-intermediary release type?\nRaven is 3rd party library, has nothing to do with OpenStack release\nprocess.\n\nDo I need to update anything else?\nNope.\n\nChange-Id: I292b0331a67f238779c8d565c5288d59a34dac69\n""}]",0,526042,58ce9cd44d5148f57fd4e052b9feb8f5cb36f59d,27,7,4,26768,,,0,"Add raven

Raven is client for Sentry error tracking tool. It is required
for sentry integration into oslo.log module.

Is the library actively maintained?
Raven is actively maintained (https://github.com/getsentry/raven-python)

Is the library good code?
Code looks good to me, testing via tox included.

Is the library python 3 compatible?
Yes

Is the library license compatible?
Yes (BSD licence)

Is the library already packaged in the distros we target 
(Ubuntu latest / Fedora latest)?
Yes, both.

Is the function of this library already covered by other libraries
in global-requirements.txt?
No, as far as it's the only python library to integrate Sentry.

Is the library required for OpenStack project or related dev or
infrastructure setup? (Answer to this should be Yes, of course) Which?
Sentry integration improves develepers experience and allows devs to
collect exceptions and bugs from live environment.
https://review.openstack.org/#/c/518949/
https://blueprints.launchpad.net/oslo.log/+spec/sentry-handler

If the library release is managed by the Openstack release process
does it use the cycle-with-intermediary release type?
Raven is 3rd party library, has nothing to do with OpenStack release
process.

Do I need to update anything else?
Nope.

Change-Id: I292b0331a67f238779c8d565c5288d59a34dac69
",git fetch https://review.opendev.org/openstack/requirements refs/changes/42/526042/4 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,3ce979b5adb0481439eb2b25a9f9b6c841931066,bp/s,raven===6.3.0,,2,0
openstack%2Fsearchlight~master~I4f5c76522962c8ecaec3ef2798f05cdcb873f52f,openstack/searchlight,master,I4f5c76522962c8ecaec3ef2798f05cdcb873f52f,Updated from global requirements,MERGED,2017-12-15 22:17:41.000000000,2017-12-18 09:52:02.000000000,2017-12-18 09:52:02.000000000,"[{'_account_id': 16150}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 22:17:41.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/searchlight/commit/f5e7035bbe16bd30df776cfd420a2891165d5caa', 'message': 'Updated from global requirements\n\nChange-Id: I4f5c76522962c8ecaec3ef2798f05cdcb873f52f\n'}]",0,528428,f5e7035bbe16bd30df776cfd420a2891165d5caa,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I4f5c76522962c8ecaec3ef2798f05cdcb873f52f
",git fetch https://review.opendev.org/openstack/searchlight refs/changes/28/528428/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f5e7035bbe16bd30df776cfd420a2891165d5caa,openstack/requirements,"oslo.service!=1.28.1,>=1.24.0 # Apache-2.0",oslo.service>=1.24.0 # Apache-2.0,1,1
openstack%2Fgovernance~master~Id1f964ed801bd8f041705b7b04a7e74e8cae16d0,openstack/governance,master,Id1f964ed801bd8f041705b7b04a7e74e8cae16d0,Add networking-sfc-tempest-plugin to neutron project,ABANDONED,2017-10-09 12:28:27.000000000,2017-12-18 09:51:30.000000000,,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 4694}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-09 12:28:27.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/a42d842e9455deeaf58bea67681845a4bc573622', 'message': 'Add networking-sfc-tempest-plugin to neutron project\n\nCreate a separate repository networking-sfc tempest plugin to fulfill\nQueens goal ""Split Tempest Plugins into Separate Repos/Projects""\n\nDepends-On: Id318296425bd0a01057864571cc39c4ddb3a8948\nChange-Id: Id1f964ed801bd8f041705b7b04a7e74e8cae16d0\n'}]",0,510552,a42d842e9455deeaf58bea67681845a4bc573622,10,5,1,21798,,,0,"Add networking-sfc-tempest-plugin to neutron project

Create a separate repository networking-sfc tempest plugin to fulfill
Queens goal ""Split Tempest Plugins into Separate Repos/Projects""

Depends-On: Id318296425bd0a01057864571cc39c4ddb3a8948
Change-Id: Id1f964ed801bd8f041705b7b04a7e74e8cae16d0
",git fetch https://review.opendev.org/openstack/governance refs/changes/52/510552/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,a42d842e9455deeaf58bea67681845a4bc573622,goal-split-tempest-plugins, networking-sfc-tempest-plugin: repos: - openstack/networking-sfc-tempest-plugin,,3,0
openstack%2Fnova~master~Ib4f6f9b87560df43819d992254603e55ea8ff6a3,openstack/nova,master,Ib4f6f9b87560df43819d992254603e55ea8ff6a3,Flavors with illegal names.,ABANDONED,2017-12-17 14:18:17.000000000,2017-12-18 09:41:35.000000000,,"[{'_account_id': 6062}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15888}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 27288}]","[{'number': 1, 'created': '2017-12-17 14:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e4922ad5edaeae1de36d44e0e23ed1be130bb69', 'message': 'Flavors with illegal names.\n\nThis patch prevent creating flavors that has illegal name.\nNames may only contain letters, numbers, underscores,\nperiods and hyphens.\n\nChange-Id: Ib4f6f9b87560df43819d992254603e55ea8ff6a3\n'}, {'number': 2, 'created': '2017-12-17 14:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f60dbfaee70550354ad75e5d6fe7740bb47abbae', 'message': 'Flavors with illegal names.\n\nThis patch prevent creating flavors that has illegal name.\nNames may only contain letters, numbers, underscores,\nperiods and hyphens.\n\nCloses-Bug: 1738328\nChange-Id: Ib4f6f9b87560df43819d992254603e55ea8ff6a3\n'}, {'number': 3, 'created': '2017-12-18 08:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a5509c89f9ae830f2e30a0b36e3c58a013e768d', 'message': 'Flavors with illegal names.\n\nThis patch prevent creating flavors that has illegal name.\nNames may only contain letters, numbers, underscores,\nperiods and hyphens.\n\nCloses-Bug: 1738328\nChange-Id: Ib4f6f9b87560df43819d992254603e55ea8ff6a3\n'}, {'number': 4, 'created': '2017-12-18 08:12:05.000000000', 'files': ['nova/api/openstack/compute/schemas/flavor_manage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3fa30e5b31439b9111789cc99e8cc0e183142f75', 'message': 'Flavors with illegal names.\n\nThis patch prevent creating flavors that has illegal name.\nNames may only contain letters, numbers, underscores,\nperiods and hyphens.\n\nCloses-Bug: 1738328\nChange-Id: Ib4f6f9b87560df43819d992254603e55ea8ff6a3\n'}]",5,528563,3fa30e5b31439b9111789cc99e8cc0e183142f75,37,16,4,27288,,,0,"Flavors with illegal names.

This patch prevent creating flavors that has illegal name.
Names may only contain letters, numbers, underscores,
periods and hyphens.

Closes-Bug: 1738328
Change-Id: Ib4f6f9b87560df43819d992254603e55ea8ff6a3
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/528563/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/api/openstack/compute/flavor_manage.py']",2,1e4922ad5edaeae1de36d44e0e23ed1be130bb69,bug/1738328,"import re if re.match(r'^[\w\.\- ]+$', name) is None: raise exception.FlavorInvalidName exception.FlavorIdExists, exception.FlavorInvalidName) as err:", exception.FlavorIdExists) as err:,10,2
openstack%2Fpython-tripleoclient~stable%2Fpike~I6d7d894eb54308b7ee6fae6c5d7bda4acb94ee77,openstack/python-tripleoclient,stable/pike,I6d7d894eb54308b7ee6fae6c5d7bda4acb94ee77,DNM: Test for LP 1734353.,ABANDONED,2017-11-30 09:43:23.000000000,2017-12-18 09:32:29.000000000,,"[{'_account_id': 8297}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2017-11-30 09:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/99e8eb95a93c5a83c9a96342a1c4636c284a46d9', 'message': 'DNM: Test for LP 1734353.\n\nChange-Id: I6d7d894eb54308b7ee6fae6c5d7bda4acb94ee77\nDepends-On: I98937eff257509bda98888534b7a1cd33595315f\n'}, {'number': 2, 'created': '2017-11-30 17:24:29.000000000', 'files': ['tripleoclient/constants.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/578bfdf4e9449040b9beec943c4357e3c64fb50e', 'message': 'DNM: Test for LP 1734353.\n\nChange-Id: I6d7d894eb54308b7ee6fae6c5d7bda4acb94ee77\nDepends-On: I98937eff257509bda98888534b7a1cd33595315f\nDepends-On: Ic050bd58065904f1c55d6a71c7bd4b09ba72d19d\n'}]",0,524113,578bfdf4e9449040b9beec943c4357e3c64fb50e,13,4,2,26343,,,0,"DNM: Test for LP 1734353.

Change-Id: I6d7d894eb54308b7ee6fae6c5d7bda4acb94ee77
Depends-On: I98937eff257509bda98888534b7a1cd33595315f
Depends-On: Ic050bd58065904f1c55d6a71c7bd4b09ba72d19d
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/13/524113/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/constants.py'],1,99e8eb95a93c5a83c9a96342a1c4636c284a46d9,bug/1734353,#,,1,0
openstack%2Fnova~stable%2Fpike~I4aa99b563e1a5a87aa3e3dfb28800f107676df92,openstack/nova,stable/pike,I4aa99b563e1a5a87aa3e3dfb28800f107676df92,Handle InstanceNotFound when setting password via metadata,MERGED,2017-11-14 14:56:21.000000000,2017-12-18 09:24:03.000000000,2017-12-18 09:24:02.000000000,"[{'_account_id': 6873}, {'_account_id': 8213}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 27272}]","[{'number': 1, 'created': '2017-11-14 14:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd41b7fef4af6f702589dad7e3138a96528898ea', 'message': ""Handle InstanceNotFound when setting password via metadata\n\nWhen setting an instance password via the metadata service, if the\ninstance is not found it results in a 500 response to the caller.\n\nThis change handles the InstanceNotFound error and returns it as\na 400. Note it's a 400 since the instance uuid is part of the POST\nrequest body, not on the URL path so it's not a 404 response.\n\nChange-Id: I4aa99b563e1a5a87aa3e3dfb28800f107676df92\nPartial-Bug: #1696848\n(cherry picked from commit c91ee68d493e8c813f4dcc4e46b1794a50f69f32)\n""}, {'number': 2, 'created': '2017-11-14 17:02:41.000000000', 'files': ['nova/tests/unit/test_metadata.py', 'nova/api/metadata/password.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a2653ac0d0ffd100ed6a26ed1901ad610c1b38bb', 'message': ""Handle InstanceNotFound when setting password via metadata\n\nWhen setting an instance password via the metadata service, if the\ninstance is not found it results in a 500 response to the caller.\n\nThis change handles the InstanceNotFound error and returns it as\na 400. Note it's a 400 since the instance uuid is part of the POST\nrequest body, not on the URL path so it's not a 404 response.\n\nChange-Id: I4aa99b563e1a5a87aa3e3dfb28800f107676df92\nPartial-Bug: #1696848\n(cherry picked from commit c91ee68d493e8c813f4dcc4e46b1794a50f69f32)\n""}]",0,519659,a2653ac0d0ffd100ed6a26ed1901ad610c1b38bb,25,11,2,6873,,,0,"Handle InstanceNotFound when setting password via metadata

When setting an instance password via the metadata service, if the
instance is not found it results in a 500 response to the caller.

This change handles the InstanceNotFound error and returns it as
a 400. Note it's a 400 since the instance uuid is part of the POST
request body, not on the URL path so it's not a 404 response.

Change-Id: I4aa99b563e1a5a87aa3e3dfb28800f107676df92
Partial-Bug: #1696848
(cherry picked from commit c91ee68d493e8c813f4dcc4e46b1794a50f69f32)
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/519659/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/test_metadata.py', 'nova/api/metadata/password.py']",2,dd41b7fef4af6f702589dad7e3138a96528898ea,bug/1696848,"from nova import exception try: instance = objects.Instance.get_by_uuid(cctxt, meta_data.uuid) except exception.InstanceNotFound as e: raise exc.HTTPBadRequest(explanation=e.format_message())"," instance = objects.Instance.get_by_uuid(cctxt, meta_data.uuid)",19,1
openstack%2Finstack-undercloud~master~I90d585b1c93ba2a0cd5b0315effae20649da99e9,openstack/instack-undercloud,master,I90d585b1c93ba2a0cd5b0315effae20649da99e9,[WIP] Special handling of openvswitch,ABANDONED,2017-12-12 11:52:55.000000000,2017-12-18 09:18:02.000000000,,"[{'_account_id': 8297}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-12 11:52:55.000000000', 'files': ['instack_undercloud/undercloud.py'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/04915c0bad12e46b9bbcf21e0464e24a0cc25b5a', 'message': '[WIP] Special handling of openvswitch\n\nChange-Id: I90d585b1c93ba2a0cd5b0315effae20649da99e9\n'}]",0,527377,04915c0bad12e46b9bbcf21e0464e24a0cc25b5a,6,3,1,11090,,,0,"[WIP] Special handling of openvswitch

Change-Id: I90d585b1c93ba2a0cd5b0315effae20649da99e9
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/77/527377/1 && git format-patch -1 --stdout FETCH_HEAD,['instack_undercloud/undercloud.py'],1,04915c0bad12e46b9bbcf21e0464e24a0cc25b5a,ovs_upgrade,"import re import shutildef _openvswitch_need_restart(): try: import rpm except ImportError: LOG.info(""Non rpm distro, openvswitch workaround doesn't apply."") return False try: ts = rpm.TransactionSet() mi = ts.dbMatch('name', ""openvswitch"") ts.closeDB() for package in mi: LOG.info('Found openvswitch package with the following postun: %s', package['postun']) regexp = r'reload|restart' match = re.search(regexp, package['postun']) if match: return True except Exception: return False def _openvswitch_local_install(instack_env): if _openvswitch_need_restart(): LOG.info('OpenvSwitch package need special handling') try: tdir = tempfile.mkdtemp() except Exception: return False LOG.info('Downloading openvswitch packages') args = ['sudo', 'yumdownloader', '--downloaddir={0}'.format(tdir), '--resolve', 'openvswitch'] _run_command(args) LOG.info('Installing openvswitch without postun') args = ['sudo', 'rpm', '-U', '--replacepkgs', '--nopostun', '{0}/*.rpm'.format(tdir)] _run_command(args) shutil.rmtree(tdir) _openvswitch_local_instal(instack_env)",,38,0
openstack%2Fcharm-neutron-openvswitch~master~I3a4f4bc84327ee2e269d3ebd93d102494102b05e,openstack/charm-neutron-openvswitch,master,I3a4f4bc84327ee2e269d3ebd93d102494102b05e,Drop zeromq support,MERGED,2017-12-15 17:15:45.000000000,2017-12-18 09:17:38.000000000,2017-12-18 09:17:38.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 17:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/58cd8901ba7d9cd923c194a19a552263149f557b', 'message': 'Drop zeromq support\n\nSupport for the ZeroMQ messaging driver has bit-rotted over\nthe last few years across the OpenStack charms; drop support\nfor ZMQ inline with deprecation notices issued in 17.02 charm\nrelease.\n\nChange-Id: I3a4f4bc84327ee2e269d3ebd93d102494102b05e\n'}, {'number': 2, 'created': '2017-12-15 17:28:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/1910b2697378e436b81fc06f50c6ba8153ad59ac', 'message': 'Drop zeromq support\n\nSupport for the ZeroMQ messaging driver has bit-rotted over\nthe last few years across the OpenStack charms; drop support\nfor ZMQ inline with deprecation notices issued in 17.02 charm\nrelease.\n\nChange-Id: I3a4f4bc84327ee2e269d3ebd93d102494102b05e\n'}, {'number': 3, 'created': '2017-12-15 20:26:58.000000000', 'files': ['unit_tests/test_neutron_ovs_hooks.py', 'hooks/zeromq-configuration-relation-joined', 'hooks/neutron_ovs_hooks.py', 'hooks/neutron_ovs_utils.py', 'hooks/zeromq-configuration-relation-changed', 'metadata.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/46faae4ff8703c60ce58ce8f2ea8d7d7547ea4aa', 'message': 'Drop zeromq support\n\nSupport for the ZeroMQ messaging driver has bit-rotted over\nthe last few years across the OpenStack charms; drop support\nfor ZMQ inline with deprecation notices issued in 17.02 charm\nrelease.\n\nChange-Id: I3a4f4bc84327ee2e269d3ebd93d102494102b05e\n'}]",0,528348,46faae4ff8703c60ce58ce8f2ea8d7d7547ea4aa,15,4,3,935,,,0,"Drop zeromq support

Support for the ZeroMQ messaging driver has bit-rotted over
the last few years across the OpenStack charms; drop support
for ZMQ inline with deprecation notices issued in 17.02 charm
release.

Change-Id: I3a4f4bc84327ee2e269d3ebd93d102494102b05e
",git fetch https://review.opendev.org/openstack/charm-neutron-openvswitch refs/changes/48/528348/2 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_neutron_ovs_hooks.py', 'hooks/zeromq-configuration-relation-joined', 'hooks/neutron_ovs_hooks.py', 'hooks/neutron_ovs_utils.py', 'hooks/zeromq-configuration-relation-changed', 'metadata.yaml']",6,58cd8901ba7d9cd923c194a19a552263149f557b,remove-zmq,, zeromq-configuration: interface: zeromq-configuration scope: container,0,39
openstack%2Fmonasca-statsd~master~I143f8e7248aba612f38f1b84f921260c0e6273ed,openstack/monasca-statsd,master,I143f8e7248aba612f38f1b84f921260c0e6273ed,Provide DogStatsD resp. Prometheus statsd-exporter compat.,ABANDONED,2017-03-28 08:49:28.000000000,2017-12-18 09:16:27.000000000,,"[{'_account_id': 2419}, {'_account_id': 14768}]","[{'number': 1, 'created': '2017-03-28 08:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-statsd/commit/7f86e3586a22c62371b3f8c5a68346b152c8fc0a', 'message': ""Provide DogStatsD resp. Prometheus statsd-exporter compat.\n\n* use DogStatsD wire format for dimensions\n* use 'ms' for timer\n* add support for histograms\n* backoff when statsd port is closed\n* support environment variables for configuration\n\nChange-Id: I143f8e7248aba612f38f1b84f921260c0e6273ed\nTask: 4080\nStory: 2000951\nDepends-On: Ib4996b88a2845bceda9c803a386b76b2e0ae125a\n""}, {'number': 2, 'created': '2017-06-06 10:46:49.000000000', 'files': ['monascastatsd/counter.py', 'tests/test_monascastatsd.py', 'monascastatsd/connection.py', 'monascastatsd/timer.py', 'monascastatsd/histogram.py', 'monascastatsd/client.py', 'monascastatsd/gauge.py', 'README.md'], 'web_link': 'https://opendev.org/openstack/monasca-statsd/commit/5aea8c5283707e78486b6f5ad8536a6433537a58', 'message': ""Provide DogStatsD resp. Prometheus statsd-exporter compat.\n\n* use DogStatsD wire format for dimensions\n* use 'ms' for timer\n* add support for histograms\n* backoff when statsd port is closed\n* support environment variables for configuration\n\nChange-Id: I143f8e7248aba612f38f1b84f921260c0e6273ed\nTask: 4080\nStory: 2000951\nDepends-On: Ib4996b88a2845bceda9c803a386b76b2e0ae125a\n""}]",0,450639,5aea8c5283707e78486b6f5ad8536a6433537a58,6,2,2,17244,,,0,"Provide DogStatsD resp. Prometheus statsd-exporter compat.

* use DogStatsD wire format for dimensions
* use 'ms' for timer
* add support for histograms
* backoff when statsd port is closed
* support environment variables for configuration

Change-Id: I143f8e7248aba612f38f1b84f921260c0e6273ed
Task: 4080
Story: 2000951
Depends-On: Ib4996b88a2845bceda9c803a386b76b2e0ae125a
",git fetch https://review.opendev.org/openstack/monasca-statsd refs/changes/39/450639/2 && git format-patch -1 --stdout FETCH_HEAD,"['monascastatsd/counter.py', 'tests/test_monascastatsd.py', 'monascastatsd/connection.py', 'monascastatsd/timer.py', 'monascastatsd/histogram.py', 'monascastatsd/client.py', 'monascastatsd/gauge.py', 'README.md']",8,7f86e3586a22c62371b3f8c5a68346b152c8fc0a,dogstatsd_compat,"client = mstatsd.Client(auto_buffer=True, dimensions={'env': 'test'})",client = mstatsd.Client(dimensions={'env': 'test'}),243,68
openstack%2Fmonasca-agent~master~I304025658cb5b892e53748adeab6164ee9f207bf,openstack/monasca-agent,master,I304025658cb5b892e53748adeab6164ee9f207bf,Fix and refresh JMX support in Monasca Agent,ABANDONED,2017-03-13 17:45:37.000000000,2017-12-18 09:16:04.000000000,,"[{'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 14273}, {'_account_id': 14517}, {'_account_id': 17244}, {'_account_id': 18179}, {'_account_id': 20033}]","[{'number': 1, 'created': '2017-03-13 17:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/60a2a6ad09c0943e6e3a5f2d1a1f8e9d7fab58c9', 'message': 'Fix and refresh JMX support in Monasca Agent\n* fix runtime errors\n* update jmxfetch version\n* improve configuration\n* add documentation\n\nResolves-Bug: #1668637\nDepends-On: Ib4996b88a2845bceda9c803a386b76b2e0ae125a\nChange-Id: I304025658cb5b892e53748adeab6164ee9f207bf\n'}, {'number': 2, 'created': '2017-03-13 17:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/f68e921b84b02116d7a5f7adb2a871cf7b797640', 'message': 'Fix and refresh JMX support in Monasca Agent\n\n* fix runtime errors\n* update jmxfetch version\n* improve configuration\n* add documentation\n\nResolves-Bug: #1668637\nDepends-On: Ib4996b88a2845bceda9c803a386b76b2e0ae125a\nChange-Id: I304025658cb5b892e53748adeab6164ee9f207bf\n'}, {'number': 3, 'created': '2017-03-14 09:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/2e23781c4a90657e9c170ebbdf80411ee1590589', 'message': 'Fix and refresh JMX support in Monasca Agent\n\n* fix runtime errors\n* update jmxfetch version\n* improve configuration\n* add documentation\n\nResolves-Bug: #1668637\nDepends-On: Ib4996b88a2845bceda9c803a386b76b2e0ae125a\nChange-Id: I304025658cb5b892e53748adeab6164ee9f207bf\n'}, {'number': 4, 'created': '2017-03-24 14:50:18.000000000', 'files': ['monasca_agent/collector/daemon.py', 'agent.yaml.template', 'docs/Customizations.md', 'monasca_agent/collector/jmxfetch.py', 'docs/Plugins.md', 'conf.d/jmx.yaml.example', 'docs/Agent.md', 'monasca_agent/collector/checks/libs/jmxfetch-0.13.0-jar-with-dependencies.jar'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/351f98b3cc01275fbb2f73ee25de1c45eb7766ce', 'message': 'Fix and refresh JMX support in Monasca Agent\n\n* fix runtime errors\n* update jmxfetch version\n* improve configuration\n* add documentation\n\nResolves-Bug: #1668637\nDepends-On: Ib4996b88a2845bceda9c803a386b76b2e0ae125a\nChange-Id: I304025658cb5b892e53748adeab6164ee9f207bf\n'}]",2,445027,351f98b3cc01275fbb2f73ee25de1c45eb7766ce,14,7,4,17244,,,0,"Fix and refresh JMX support in Monasca Agent

* fix runtime errors
* update jmxfetch version
* improve configuration
* add documentation

Resolves-Bug: #1668637
Depends-On: Ib4996b88a2845bceda9c803a386b76b2e0ae125a
Change-Id: I304025658cb5b892e53748adeab6164ee9f207bf
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/27/445027/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_agent/collector/daemon.py', 'agent.yaml.template', 'docs/Customizations.md', 'monasca_agent/collector/jmxfetch.py', 'docs/Plugins.md', 'conf.d/jmx.yaml.example', 'docs/Agent.md', 'monasca_agent/collector/checks/libs/jmxfetch-0.13.0-jar-with-dependencies.jar']",8,60a2a6ad09c0943e6e3a5f2d1a1f8e9d7fab58c9,bug/1668637,,,223,112
openstack%2Fmonasca-api~master~I6d02a72b05d24dbe70d166b4b8f6534dcafa8c1b,openstack/monasca-api,master,I6d02a72b05d24dbe70d166b4b8f6534dcafa8c1b,Support templated alarm descriptions and notification templates,ABANDONED,2017-02-23 18:04:31.000000000,2017-12-18 09:15:27.000000000,,"[{'_account_id': 2419}, {'_account_id': 14768}, {'_account_id': 16168}]","[{'number': 1, 'created': '2017-02-23 18:04:31.000000000', 'files': ['monasca_api/common/repositories/sqla/sql_repository.py', 'requirements.txt', 'monasca_api/v2/reference/metrics.py', 'monasca_api/common/repositories/sqla/alarms_repository.py', 'monasca_api/common/repositories/influxdb/metrics_repository.py', 'monasca_api/monitoring/client.py', 'monasca_api/v2/reference/alarms.py', 'monasca_api/monitoring/metrics.py', 'monasca_api/expression_parser/alarm_expr_parser.py', 'monasca_api/common/messaging/kafka_publisher.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/ecea3a70445df6b56a6dd4fadcb0cee5e9cb3370', 'message': 'Support templated alarm descriptions and notification templates\n\n* support Jinja2 templating in alarm descriptions\n* added statsd instrumentation\n* fix for alarm-expression-parser (forbidden chars tolerated)\n\nChange-Id: I6d02a72b05d24dbe70d166b4b8f6534dcafa8c1b\nImplements: blueprint templated-alarms\n'}]",0,437548,ecea3a70445df6b56a6dd4fadcb0cee5e9cb3370,4,3,1,17244,,,0,"Support templated alarm descriptions and notification templates

* support Jinja2 templating in alarm descriptions
* added statsd instrumentation
* fix for alarm-expression-parser (forbidden chars tolerated)

Change-Id: I6d02a72b05d24dbe70d166b4b8f6534dcafa8c1b
Implements: blueprint templated-alarms
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/48/437548/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_api/common/repositories/sqla/sql_repository.py', 'requirements.txt', 'monasca_api/v2/reference/metrics.py', 'monasca_api/common/repositories/sqla/alarms_repository.py', 'monasca_api/common/repositories/influxdb/metrics_repository.py', 'monasca_api/monitoring/client.py', 'monasca_api/v2/reference/alarms.py', 'monasca_api/monitoring/metrics.py', 'monasca_api/common/messaging/kafka_publisher.py', 'monasca_api/expression_parser/alarm_expr_parser.py']",10,ecea3a70445df6b56a6dd4fadcb0cee5e9cb3370,bp/templated-alarms,"# See also validation.py: invalid_chars = ""<>={}(),\""\\\\|;&"" (unicode_printables + pyparsing.alphanums + r"".-_#!$%'*+/:?@[]^`~""))"," (unicode_printables + pyparsing.alphanums + "".-_#!$%&'*+/:;?@[\\]^`|~""))",280,12
openstack%2Fmonasca-notification~master~Iebc49ce69462ffb854ac855cdb59188dc3db9af3,openstack/monasca-notification,master,Iebc49ce69462ffb854ac855cdb59188dc3db9af3,Support templated alarm descriptions and notification templates,ABANDONED,2017-02-23 17:13:37.000000000,2017-12-18 09:15:17.000000000,,"[{'_account_id': 2419}, {'_account_id': 11131}, {'_account_id': 14768}]","[{'number': 1, 'created': '2017-02-23 17:13:37.000000000', 'files': ['monasca_notification/common/repositories/base/base_repo.py', 'monasca_notification/common/repositories/postgres/pgsql_repo.py', 'monasca_notification/processors/notification_processor.py', 'tests/test_email_notification.py', 'monasca_notification/types/notifiers.py', 'test-requirements.txt', 'tests/test_alarm_processor.py', 'tests/test_notifiers.py', 'monasca_notification/plugins/hipchat_notifier.py', 'monasca_notification/periodic_engine.py', 'monasca_notification/plugins/webhook_notifier.py', 'requirements.txt', 'monasca_notification/common/utils.py', 'monasca_notification/monitoring/metrics.py', 'notification.yaml', 'tests/test_pagerduty_notification.py', 'tests/test_notification_processor.py', 'monasca_notification/monitoring/client.py', 'monasca_notification/notification_engine.py', 'monasca_notification/common/repositories/orm/orm_repo.py', 'monasca_notification/processors/alarm_processor.py', 'tests/test_utils.py', 'monasca_notification/base_engine.py', 'monasca_notification/plugins/email_notifier.py', 'monasca_notification/plugins/jira_notifier.py', 'monasca_notification/common/repositories/orm/models.py', 'monasca_notification/plugins/slack_notifier.py', 'tests/test_webhook_notification.py', 'monasca_notification/common/repositories/mysql/mysql_repo.py', 'monasca_notification/main.py', 'monasca_notification/plugins/pagerduty_notifier.py', 'monasca_notification/retry_engine.py', 'monasca_notification/plugins/abstract_notifier.py', 'tests/test_notification.py', 'tests/test_mysql_repo.py', 'monasca_notification/notification.py'], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/776b0811cdce191c7a1282cb5ec5c2fbc6ef3fd6', 'message': 'Support templated alarm descriptions and notification templates\n\n* support Jinja2 templating in alarm descriptions\n* support MarkDown formatting in alarm descriptions\n* support Jinja2 templating for customizable notification messages\n* moved common code into base-classes to avoid duplication\n* reworked statsd instrumentation\n\nChange-Id: Iebc49ce69462ffb854ac855cdb59188dc3db9af3\nImplements: blueprint templated-alarms\n'}]",0,437532,776b0811cdce191c7a1282cb5ec5c2fbc6ef3fd6,4,3,1,17244,,,0,"Support templated alarm descriptions and notification templates

* support Jinja2 templating in alarm descriptions
* support MarkDown formatting in alarm descriptions
* support Jinja2 templating for customizable notification messages
* moved common code into base-classes to avoid duplication
* reworked statsd instrumentation

Change-Id: Iebc49ce69462ffb854ac855cdb59188dc3db9af3
Implements: blueprint templated-alarms
",git fetch https://review.opendev.org/openstack/monasca-notification refs/changes/32/437532/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_notification/common/repositories/base/base_repo.py', 'monasca_notification/common/repositories/postgres/pgsql_repo.py', 'monasca_notification/processors/notification_processor.py', 'tests/test_email_notification.py', 'monasca_notification/types/notifiers.py', 'test-requirements.txt', 'tests/test_alarm_processor.py', 'tests/test_notifiers.py', 'monasca_notification/plugins/hipchat_notifier.py', 'monasca_notification/periodic_engine.py', 'monasca_notification/plugins/webhook_notifier.py', 'requirements.txt', 'monasca_notification/common/utils.py', 'monasca_notification/monitoring/metrics.py', 'notification.yaml', 'tests/test_pagerduty_notification.py', 'tests/test_notification_processor.py', 'monasca_notification/monitoring/client.py', 'monasca_notification/notification_engine.py', 'monasca_notification/common/repositories/orm/orm_repo.py', 'monasca_notification/processors/alarm_processor.py', 'tests/test_utils.py', 'monasca_notification/base_engine.py', 'monasca_notification/plugins/email_notifier.py', 'monasca_notification/plugins/jira_notifier.py', 'monasca_notification/common/repositories/orm/models.py', 'monasca_notification/plugins/slack_notifier.py', 'tests/test_webhook_notification.py', 'monasca_notification/common/repositories/mysql/mysql_repo.py', 'monasca_notification/main.py', 'monasca_notification/plugins/pagerduty_notifier.py', 'monasca_notification/retry_engine.py', 'monasca_notification/plugins/abstract_notifier.py', 'tests/test_notification.py', 'tests/test_mysql_repo.py', 'monasca_notification/notification.py']",36,776b0811cdce191c7a1282cb5ec5c2fbc6ef3fd6,bp/templated-alarms,"import logging import time import datetime from jinja2 import Template from jinja2 import TemplateSyntaxError log = logging.getLogger(__name__) 'alarm_description', 'alarm_age', 'dimensions', 'metric_values', 'old_state', self.alarm_description = alarm['alarmDescription'] self.alarm_age = time.time() - self.alarm_timestamp self.old_state = alarm['oldState'] # collect alarm dimensions and render alarm-description as needed self.dimensions = {} for metric in self.metrics: for k, v in metric['dimensions'].iteritems(): old = self.dimensions.get(k) if not old: self.dimensions[k] = v elif isinstance(old, set): old.add(v) else: self.dimensions[k] = {old, v} for k, v in self.dimensions.iteritems(): if isinstance(v, set): self.dimensions[k] = "", "".join(v) # provide actual metric values leading to the alarm self.metric_values = {} for subalarm in alarm['subAlarms']: metric_name = subalarm['subAlarmExpression']['metricDefinition']['name'].replace('.', '_') metric_value = subalarm['currentValues'] if len(metric_value) == 0: self.metric_values[metric_name] = None elif len(metric_value) == 1: self.metric_values[metric_name] = metric_value[0] else: self.metric_values[metric_name] = metric_value # add additional variables template_vars = {} template_vars.update(self.dimensions) template_vars.update(self.metric_values) template_vars['_age'] = self.alarm_age template_vars['_timestamp'] = str(datetime.datetime.utcfromtimestamp(self.alarm_timestamp)).replace("" "", ""T"") + 'Z' template_vars['_state'] = self.state template_vars['_old_state'] = self.old_state # attempt interpreting description as Jinja2 template try: self.alarm_description = Template(self.alarm_description).render(**template_vars) except TemplateSyntaxError: pass except Exception: log.exception(""failed rendering alarm-definition: %s"", self.alarm_description) notification_data = self.to_dict() return json.dumps(notification_data) def to_dict(self): """""" 'alarm_description', 'old_state', return notification_data"," """""" return json.dumps(notification_data)",774,466
openstack%2Fnetworking-bagpipe~master~I6cc73c4d7add7cb3597da5a24efdcded1d9f4e5d,openstack/networking-bagpipe,master,I6cc73c4d7add7cb3597da5a24efdcded1d9f4e5d,Updated from global requirements,MERGED,2017-12-15 21:42:26.000000000,2017-12-18 09:15:05.000000000,2017-12-18 09:15:05.000000000,"[{'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 21:42:26.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/cf8260f806ff01523b684f96826b189baa95fefe', 'message': 'Updated from global requirements\n\nChange-Id: I6cc73c4d7add7cb3597da5a24efdcded1d9f4e5d\n'}]",0,528414,cf8260f806ff01523b684f96826b189baa95fefe,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I6cc73c4d7add7cb3597da5a24efdcded1d9f4e5d
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/14/528414/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,cf8260f806ff01523b684f96826b189baa95fefe,openstack/requirements,"oslo.service!=1.28.1,>=1.24.0 # Apache-2.0",oslo.service>=1.24.0 # Apache-2.0,1,1
openstack%2Fmonasca-persister~master~Icfd845c59b99c861f0501ad3fbb6ba98c0d112b7,openstack/monasca-persister,master,Icfd845c59b99c861f0501ad3fbb6ba98c0d112b7,Cleanup outer persister.py,ABANDONED,2016-08-20 11:57:07.000000000,2017-12-18 09:13:24.000000000,,"[{'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 14273}, {'_account_id': 14517}, {'_account_id': 15027}, {'_account_id': 16168}, {'_account_id': 16222}, {'_account_id': 18286}, {'_account_id': 20033}, {'_account_id': 20873}]","[{'number': 1, 'created': '2016-08-20 11:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/cce7ec21e3e33aacdc9640b05c956b6a4d82bd22', 'message': 'Cleanup outer persister.py\n\nChange-Id: Icfd845c59b99c861f0501ad3fbb6ba98c0d112b7\n'}, {'number': 2, 'created': '2016-08-20 12:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/732afa8cd0c00f801d127accc4ae805ecb37ccba', 'message': 'Cleanup outer persister.py\n\nChange-Id: Icfd845c59b99c861f0501ad3fbb6ba98c0d112b7\n'}, {'number': 3, 'created': '2016-08-22 14:02:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/0a8dc2e1dc0dae860452f830d5aefa0f5887ff17', 'message': 'Cleanup outer persister.py\n\nChange-Id: Icfd845c59b99c861f0501ad3fbb6ba98c0d112b7\n'}, {'number': 4, 'created': '2016-08-24 12:42:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/5674122f9281c7fcf7d997d55267150041ff779a', 'message': 'Cleanup outer persister.py\n\nSplit the different responsibilities to separate classes.\nExtract methods.\n\nChange-Id: Icfd845c59b99c861f0501ad3fbb6ba98c0d112b7\n'}, {'number': 5, 'created': '2016-08-24 12:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/4813a1bad9c4edcd6f0d67ee6e328b2a17c45d2c', 'message': 'Cleanup outer persister.py\n\nSplit the different responsibilities to separate classes.\nExtract methods.\n\nChange-Id: Icfd845c59b99c861f0501ad3fbb6ba98c0d112b7\n'}, {'number': 6, 'created': '2016-09-05 08:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/6aaa90e6ff90df3df90ba74b5e7ce7e0c592e733', 'message': 'Cleanup outer persister.py\n\nSplit the different responsibilities to separate classes.\nExtract methods.\n\nChange-Id: Icfd845c59b99c861f0501ad3fbb6ba98c0d112b7\n'}, {'number': 7, 'created': '2017-01-16 07:35:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/e15d5cd1e0b8cbf0bd2609a32bfcf415725aceb5', 'message': 'Cleanup outer persister.py\n\nSplit the different responsibilities to separate classes.\nExtract methods.\n\nChange-Id: Icfd845c59b99c861f0501ad3fbb6ba98c0d112b7\n'}, {'number': 8, 'created': '2017-01-16 10:20:23.000000000', 'files': ['monasca_persister/persister.py', 'monasca_persister/tests/test_persister_main.py'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/823b4df53b8ef37a0d8111ff3e5205e9c613224b', 'message': 'Cleanup outer persister.py\n\nSplit the different responsibilities to separate classes.\nExtract methods.\n\nChange-Id: Icfd845c59b99c861f0501ad3fbb6ba98c0d112b7\n'}]",2,358185,823b4df53b8ef37a0d8111ff3e5205e9c613224b,26,10,8,20873,,,0,"Cleanup outer persister.py

Split the different responsibilities to separate classes.
Extract methods.

Change-Id: Icfd845c59b99c861f0501ad3fbb6ba98c0d112b7
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/85/358185/6 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_persister/persister.py', 'monasca_persister/tests/test_persister_main.py']",2,cce7ec21e3e33aacdc9640b05c956b6a4d82bd22,cleanup, self.persister_module.PersisterMain().main(),"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # global variables change during runtime self.persister_module.processors = [] self.persister_module.exiting = False self.persister_module.main()",156,145
openstack%2Fmonasca-persister~master~Ib4540eaac83857e780c905310defa013814277e2,openstack/monasca-persister,master,Ib4540eaac83857e780c905310defa013814277e2,Fix metric-list with dimension having '/',NEW,2016-08-08 08:41:36.000000000,2017-12-18 09:07:50.000000000,,"[{'_account_id': 2419}, {'_account_id': 8126}, {'_account_id': 11809}, {'_account_id': 12512}, {'_account_id': 14273}, {'_account_id': 14517}, {'_account_id': 16222}, {'_account_id': 18179}, {'_account_id': 18286}, {'_account_id': 24580}, {'_account_id': 26733}]","[{'number': 1, 'created': '2016-08-08 08:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/5ee199f44d52a07ccc69c7b43540f8aa3a63a978', 'message': ""Fix metric-list with dimension having '/'\n\nApi expects dimension name and value are url quote escaped.\nBut prsister stores dimension with plain value.\n\nChange-Id: Ib4540eaac83857e780c905310defa013814277e2\n""}, {'number': 2, 'created': '2016-08-09 06:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/994494f31ad874652e243543cfcc1e5a4d30148a', 'message': ""Fix metric-list with dimension having '/'\n\nApi expects dimension name and value are url quote escaped.\nBut prsister stores dimension with plain value.\n\nChange-Id: Ib4540eaac83857e780c905310defa013814277e2\n""}, {'number': 3, 'created': '2016-08-09 06:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/5f174cf628a1524027286df38c528cae6fe8a2d2', 'message': ""Fix metric-list with dimension having '/'\n\nApi expects dimension name and value are url quote escaped.\nBut prsister stores dimension with plain value.\n\nChange-Id: Ib4540eaac83857e780c905310defa013814277e2\n""}, {'number': 4, 'created': '2016-08-09 07:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/16dc70273b089e3593a82e5d0332a1f32f97f30f', 'message': ""Fix metric-list with dimension having '/'\n\nApi expects dimension name and value are url quote escaped.\nBut prsister stores dimension with plain value.\n\nChange-Id: Ib4540eaac83857e780c905310defa013814277e2\n""}, {'number': 5, 'created': '2016-08-18 08:51:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/d06ddacefdeb596edf9f89c93140a670c374025e', 'message': ""Fix metric-list with dimension having '/'\n\nApi expects dimension name and value are url quote escaped.\nBut prsister stores dimension with plain value.\n\nChange-Id: Ib4540eaac83857e780c905310defa013814277e2\n""}, {'number': 6, 'created': '2016-08-19 00:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/1471d956b0a8eddc28a53851e4039e53645c839e', 'message': ""Fix metric-list with dimension having '/'\n\nApi expects dimension name and value are url quote escaped.\nBut persister stores dimension with plain value.\n\nChange-Id: Ib4540eaac83857e780c905310defa013814277e2\n""}, {'number': 7, 'created': '2016-08-19 01:16:41.000000000', 'files': ['monasca_persister/tests/test_cassandra_repository.py', '.gitignore', 'monasca_persister/repositories/cassandra/metrics_repository.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/3df86e9eb46864b70d7585abe16caaa9d33f6628', 'message': ""Fix metric-list with dimension having '/'\n\nApi expects dimension name and value are url quote escaped.\nBut persister stores dimension with plain value.\n\nChange-Id: Ib4540eaac83857e780c905310defa013814277e2\n""}]",9,352274,3df86e9eb46864b70d7585abe16caaa9d33f6628,29,11,7,18286,,,0,"Fix metric-list with dimension having '/'

Api expects dimension name and value are url quote escaped.
But persister stores dimension with plain value.

Change-Id: Ib4540eaac83857e780c905310defa013814277e2
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/74/352274/4 && git format-patch -1 --stdout FETCH_HEAD,['monasca_persister/repositories/cassandra/metrics_repository.py'],1,5ee199f44d52a07ccc69c7b43540f8aa3a63a978,allow_slash," quoted_dimensions = {} quoted_dimensions['__name__'] = urllib.quote_plus(metric_name) for name, value in dimensions.iteritems(): quoted_dimensions[urllib.quote_plus(name)] = urllib.quote_plus(value) for dim_name in sorted(quoted_dimensions.iterkeys()): dimension = dim_name + '=' + quoted_dimensions[dim_name] return bytearray.fromhex(sha1_hash), quoted_dimensions"," dimensions['__name__'] = urllib.quote_plus(metric_name) for dim_name in sorted(dimensions.iterkeys()): dimension = (urllib.quote_plus(dim_name) + '=' + urllib.quote_plus( dimensions[dim_name])) return bytearray.fromhex(sha1_hash), dimensions",9,5
openstack%2Fnova~stable%2Fpike~Id611678f53a2ad023dd336e30e62d5c3ae9ffd6e,openstack/nova,stable/pike,Id611678f53a2ad023dd336e30e62d5c3ae9ffd6e,Fix CellDatabases fixture swallowing exceptions,MERGED,2017-11-14 17:02:41.000000000,2017-12-18 09:01:43.000000000,2017-12-18 09:01:43.000000000,"[{'_account_id': 4393}, {'_account_id': 8213}, {'_account_id': 10135}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-11-14 17:02:41.000000000', 'files': ['nova/tests/fixtures.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/67caff67a98f56bee5d119459964e67d63bc6982', 'message': ""Fix CellDatabases fixture swallowing exceptions\n\nThe _wrap_target_cell() helper in the CellDatabases fixture was\naccidentally changing the behavior of the target_cell() functionality\nthat it wraps by swallowing any exceptions raised and always returning\nNone. That was not intentional, and introduced by copying the exception\nhandler below a special case and returning None in a finally: context.\n\nThis just removes that exception handler to allow it to propagate to\nthe caller (as it would in production code), but returns (the\nintended special case) if nothing is raised.\n\nThis also fixes a bit of the instance_list module that was working around\nthis quirk so that the code is more natural.\n\nConflicts:\n      nova/compute/instance_list.py\n\nNOTE(mriedem): nova/compute/instance_list.py didn't exist in Pike\nand isn't needed here, we just need the fixture fix.\n\nChange-Id: Id611678f53a2ad023dd336e30e62d5c3ae9ffd6e\n(cherry picked from commit af05d6208b4f95f1d9b882ed376552b75bb87506)\n""}]",0,519702,67caff67a98f56bee5d119459964e67d63bc6982,9,6,1,6873,,,0,"Fix CellDatabases fixture swallowing exceptions

The _wrap_target_cell() helper in the CellDatabases fixture was
accidentally changing the behavior of the target_cell() functionality
that it wraps by swallowing any exceptions raised and always returning
None. That was not intentional, and introduced by copying the exception
handler below a special case and returning None in a finally: context.

This just removes that exception handler to allow it to propagate to
the caller (as it would in production code), but returns (the
intended special case) if nothing is raised.

This also fixes a bit of the instance_list module that was working around
this quirk so that the code is more natural.

Conflicts:
      nova/compute/instance_list.py

NOTE(mriedem): nova/compute/instance_list.py didn't exist in Pike
and isn't needed here, we just need the fixture fix.

Change-Id: Id611678f53a2ad023dd336e30e62d5c3ae9ffd6e
(cherry picked from commit af05d6208b4f95f1d9b882ed376552b75bb87506)
",git fetch https://review.opendev.org/openstack/nova refs/changes/02/519702/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/fixtures.py'],1,67caff67a98f56bee5d119459964e67d63bc6982,bug/1696848," with self._real_target_cell(context, cell_mapping) as c: yield c return"," try: with self._real_target_cell(context, cell_mapping) as c: yield c finally: return",3,5
openstack%2Fneutron~master~Ifb3a6d155e0956bf79a3dd9422c2179c96314729,openstack/neutron,master,Ifb3a6d155e0956bf79a3dd9422c2179c96314729,l3_agentschedulers_db: convert from Agent model to OVO,MERGED,2017-12-12 07:43:46.000000000,2017-12-18 09:01:40.000000000,2017-12-18 09:01:40.000000000,"[{'_account_id': 1131}, {'_account_id': 9656}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 15471}, {'_account_id': 22348}, {'_account_id': 25903}, {'_account_id': 26072}]","[{'number': 1, 'created': '2017-12-12 07:43:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ae2bb95eb8aa132a7cdea46ccf223f662af9128c', 'message': 'l3_agentschedulers_db: convert from Agent model to OVO\n\nChange-Id: Ifb3a6d155e0956bf79a3dd9422c2179c96314729\nCo-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n'}, {'number': 2, 'created': '2017-12-15 07:35:26.000000000', 'files': ['neutron/db/l3_agentschedulers_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0a4ec17e6ca84c454771e87ce6879cbffccbd283', 'message': 'l3_agentschedulers_db: convert from Agent model to OVO\n\nChange-Id: Ifb3a6d155e0956bf79a3dd9422c2179c96314729\nCo-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n'}]",3,527330,0a4ec17e6ca84c454771e87ce6879cbffccbd283,27,8,2,25903,,,0,"l3_agentschedulers_db: convert from Agent model to OVO

Change-Id: Ifb3a6d155e0956bf79a3dd9422c2179c96314729
Co-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>
Partially-Implements: blueprint adopt-oslo-versioned-objects-for-db
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/527330/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_agentschedulers_db.py'],1,ae2bb95eb8aa132a7cdea46ccf223f662af9128c,bp/adopt-oslo-versioned-objects-for-db," column = getattr(ag_obj.Agent, key, None)","from neutron.db.models import agent as agent_model column = getattr(agent_model.Agent, key, None)",1,2
openstack%2Fdevstack~master~I2705daead3d3b95f6ad82261212f2a1f40a77fb5,openstack/devstack,master,I2705daead3d3b95f6ad82261212f2a1f40a77fb5,"Revert ""Resolve openSUSE devstack failures""",MERGED,2017-10-12 14:21:32.000000000,2017-12-18 08:52:16.000000000,2017-10-17 13:47:01.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6593}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 13404}, {'_account_id': 22348}, {'_account_id': 22595}]","[{'number': 1, 'created': '2017-10-12 14:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4f2488bd28de115ef7fb2cb2cedc57d216d372d0', 'message': 'stack.sh: use pip only after its installed\n\nRefactoring as pip is not installed on clean machine when install\nprereqs\n\nChange-Id: I2705daead3d3b95f6ad82261212f2a1f40a77fb5\n'}, {'number': 2, 'created': '2017-10-13 09:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/eb3d471d7fe774b64232cb84099bb28f676e6732', 'message': 'reverting openSUSE specific fixes\n\nReverting an old Ifb29b9089197c0429a5fc1cd08a25d2095d481f1,\nthe issue mentioned in the removed comment is not resolved\n\nChange-Id: I2705daead3d3b95f6ad82261212f2a1f40a77fb5\n'}, {'number': 3, 'created': '2017-10-13 09:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/52ac934c9cd07c0208f3b130a070f3578dfe6f1e', 'message': 'reverting openSUSE specific fixes\n\nReverting an old Ifb29b9089197c0429a5fc1cd08a25d2095d481f1,\nthe issue mentioned in the removed comment is not resolved\n\nChange-Id: I2705daead3d3b95f6ad82261212f2a1f40a77fb5\n'}, {'number': 4, 'created': '2017-10-13 13:12:37.000000000', 'files': ['tools/install_prereqs.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/135ebe955e19992e54350e2ed70c5f0517c93b26', 'message': 'Revert ""Resolve openSUSE devstack failures""\n\nThis reverts commit d325875508e7d35d6dd62302d852e83815be2278.\nthe issue mentioned in the comment is now resolved.\n\nChange-Id: I2705daead3d3b95f6ad82261212f2a1f40a77fb5\n'}]",1,511489,135ebe955e19992e54350e2ed70c5f0517c93b26,22,8,4,23735,,,0,"Revert ""Resolve openSUSE devstack failures""

This reverts commit d325875508e7d35d6dd62302d852e83815be2278.
the issue mentioned in the comment is now resolved.

Change-Id: I2705daead3d3b95f6ad82261212f2a1f40a77fb5
",git fetch https://review.opendev.org/openstack/devstack refs/changes/89/511489/4 && git format-patch -1 --stdout FETCH_HEAD,"['tools/install_prereqs.sh', 'stack.sh']",2,4f2488bd28de115ef7fb2cb2cedc57d216d372d0,pipfix,"if is_suse; then # now reinstall cryptography from source, in order to rebuilt it against the # system libssl rather than the bundled openSSL 1.1, which segfaults when combined # with a system provided openSSL 1.0 # see https://github.com/pyca/cryptography/issues/3804 and followup issues sudo pip install cryptography --no-binary :all: fi ",,8,9
openstack%2Fmonasca-api~master~I389a6b95825d7cfb052aeb7a2b6066377a277a2d,openstack/monasca-api,master,I389a6b95825d7cfb052aeb7a2b6066377a277a2d,Use monasca/grafana repository in devstack,MERGED,2017-12-08 08:36:44.000000000,2017-12-18 08:41:45.000000000,2017-12-18 08:41:45.000000000,"[{'_account_id': 17331}, {'_account_id': 17981}, {'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26639}]","[{'number': 1, 'created': '2017-12-08 08:36:44.000000000', 'files': ['devstack/settings'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/6ba8dbd740167d30f368c149cbc52655544cb79d', 'message': 'Use monasca/grafana repository in devstack\n\nsapcc/grafana repository is not maintained anymore.\n\nChange-Id: I389a6b95825d7cfb052aeb7a2b6066377a277a2d\n'}]",0,526625,6ba8dbd740167d30f368c149cbc52655544cb79d,9,5,1,16222,,,0,"Use monasca/grafana repository in devstack

sapcc/grafana repository is not maintained anymore.

Change-Id: I389a6b95825d7cfb052aeb7a2b6066377a277a2d
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/25/526625/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/settings'],1,6ba8dbd740167d30f368c149cbc52655544cb79d,,"GRAFANA_REPO=${GRAFANA_REPO:-""https://github.com/monasca/grafana.git""} GRAFANA_BRANCH=${GRAFANA_BRANCH:-""grafana4""}","GRAFANA_REPO=${GRAFANA_REPO:-""https://github.com/sapcc/grafana.git""} GRAFANA_BRANCH=${GRAFANA_BRANCH:-""keystone""}",2,2
openstack%2Fnetworking-odl~master~Ie5906f99d43c469706738cc3b3afe25e87dbf30b,openstack/networking-odl,master,Ie5906f99d43c469706738cc3b3afe25e87dbf30b,Fix test interval for periodic task,ABANDONED,2017-12-14 09:14:21.000000000,2017-12-18 08:36:49.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-12-14 09:14:21.000000000', 'files': ['networking_odl/tests/unit/journal/test_periodic_task.py'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/51a5df64e62c1406f2da93e9f324d7ab24ed3437', 'message': 'Fix test interval for periodic task\n\nWith a change of one of the libraries used the delay of 0 in the fixed\ninterval loop broke. This patch raises to a minimum accepted that works\nwith this updated library.\n\nChange-Id: Ie5906f99d43c469706738cc3b3afe25e87dbf30b\n'}]",0,527905,51a5df64e62c1406f2da93e9f324d7ab24ed3437,3,1,1,26507,,,0,"Fix test interval for periodic task

With a change of one of the libraries used the delay of 0 in the fixed
interval loop broke. This patch raises to a minimum accepted that works
with this updated library.

Change-Id: Ie5906f99d43c469706738cc3b3afe25e87dbf30b
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/05/527905/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_odl/tests/unit/journal/test_periodic_task.py'],1,51a5df64e62c1406f2da93e9f324d7ab24ed3437,fix/problematic_unit_tests,TEST_TASK_INTERVAL = 0.1,TEST_TASK_INTERVAL = 0,1,1
openstack%2Fmonasca-agent~master~I989456e0f8dea858a38611fb0f8a6bfea0633f01,openstack/monasca-agent,master,I989456e0f8dea858a38611fb0f8a6bfea0633f01,An InfluxDB plugin to check status and performance metrics,NEW,2015-06-26 17:49:51.000000000,2017-12-18 08:26:23.000000000,,"[{'_account_id': 2419}, {'_account_id': 11094}, {'_account_id': 11809}, {'_account_id': 12149}, {'_account_id': 15799}, {'_account_id': 16168}, {'_account_id': 17244}]","[{'number': 1, 'created': '2015-06-26 17:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/0b42137d534853ab80064bd96ecd18ba820351ea', 'message': 'An InfluxDB plugin to check up/down status and performance metrics\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n'}, {'number': 2, 'created': '2015-06-26 18:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/d51e7e9264cac951448e69985aed34f5dc28369f', 'message': 'An InfluxDB plugin to check up/down status and performance metrics\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n'}, {'number': 3, 'created': '2015-06-26 18:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/51a2021bd95506c3b64dac9672c17d46b483fbdc', 'message': 'An InfluxDB plugin to check up/down status and performance metrics\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n'}, {'number': 4, 'created': '2015-07-10 00:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/95f608925ba506a3d3b1e45e4a65baff61200dc3', 'message': 'An InfluxDB plugin to check up/down status and performance metrics\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n'}, {'number': 5, 'created': '2015-07-10 00:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/57b93725f83d69806bfb30ca95bfcd1d8bd04ccb', 'message': 'An InfluxDB plugin to check status and performance metrics\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n'}, {'number': 6, 'created': '2015-07-10 03:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/b3bfef9725f5fb1f3257745c865c404f42954f6d', 'message': 'An InfluxDB plugin to check status and performance metrics\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n'}, {'number': 7, 'created': '2015-07-14 23:18:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/127ba42cc322c439729c86e785033029854b88b6', 'message': 'An InfluxDB plugin to check status and performance metrics\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n'}, {'number': 8, 'created': '2015-12-01 15:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/6a21b1973a1b1ccf1a6f5cb2d1493b6fbc722f96', 'message': 'An InfluxDB plugin to check status and performance metrics\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n'}, {'number': 9, 'created': '2015-12-01 17:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/038592d5bdd00faff63737d555a9ca90387ee32d', 'message': ""An InfluxDB plugin to check status and performance metrics\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 10, 'created': '2015-12-01 17:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/50fa93f853a72d42081d1fdfc969e0eb30c2c385', 'message': ""An InfluxDB plugin to check status and performance metrics\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 11, 'created': '2015-12-07 14:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/17d6e6201e2392644cf1d4586be7021da4c7f88c', 'message': ""An InfluxDB plugin to check status and performance metrics\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 12, 'created': '2015-12-07 16:13:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/8d9ebc55e654bc52f16d89a6d511c8ecfb277b92', 'message': ""An InfluxDB plugin to check status and performance metrics\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 13, 'created': '2016-01-11 13:45:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/76e7d385dc32bae58b22f6d3df9aa934912dabc5', 'message': ""An InfluxDB plugin to check status and performance metrics\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 14, 'created': '2016-01-11 14:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/9c6806f145e0bfc57e23bdb9752dffb208ef2c31', 'message': ""An InfluxDB plugin to check status and performance metrics\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 15, 'created': '2016-01-11 14:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/8aff4ec388ca58edb883042d578d73dd5a3e7321', 'message': ""An InfluxDB plugin to check status and performance metrics\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 16, 'created': '2016-01-11 14:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/ae08b0f83d401b18366f3882768fd053578cfd0c', 'message': ""An InfluxDB plugin to check status and performance metrics\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 17, 'created': '2016-01-11 16:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/d6969e74964e6f56171c76c508946931f909d3d9', 'message': ""An InfluxDB plugin to check status and performance metrics\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 18, 'created': '2016-01-12 12:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/229349ec8d6cf55533e6e11dd1a6de8cf91481fe', 'message': ""An InfluxDB plugin to check status and performance metrics\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 19, 'created': '2016-01-12 12:29:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/4eae03438eaa363f081752721e8a2a0452b40d3e', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 20, 'created': '2016-01-12 14:33:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/6943866235b0cae9410c1e571b97b171581bb0fa', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 21, 'created': '2016-01-12 14:36:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/9d02d50cc39b5dce77c74ac96ed069c0e93210cd', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* removed conflicting discovery part in mon.py\n* group metrics by subsystem\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 22, 'created': '2016-01-12 14:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/30c0dd6a5dc125729ff71e692293164a6bf38fda', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* removed conflicting discovery part in mon.py\n* group metrics by subsystem\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 23, 'created': '2016-01-12 14:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/3374397af88a1b9d220846aab84f717321b6d5ec', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* removed conflicting discovery part in mon.py\n* group metrics by subsystem\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 24, 'created': '2016-01-12 15:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/08561d4f920d4a29120b9207f987a8fe4aa4c0dc', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* removed conflicting discovery part in mon.py\n* group metrics by subsystem\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 25, 'created': '2016-01-12 15:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/50f717cef741b56c94d628ab8188e1e8db1a4d0e', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* removed conflicting discovery part in mon.py\n* group metrics by subsystem\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 26, 'created': '2016-01-12 16:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/af5f8a8f77a061d64ed95eb5f1f3faf87690957b', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* removed conflicting discovery part in mon.py\n* group metrics by subsystem\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 27, 'created': '2016-01-12 16:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/9a1e0d6b6809c9259f0afcfbeeeadf11028284b2', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* removed conflicting discovery part in mon.py\n* group metrics by subsystem\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 28, 'created': '2016-01-13 16:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/d536c3520ea6249fdbfe89fc0ab544bf0e1a15cb', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* removed conflicting discovery part in mon.py\n* group metrics by subsystem\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 29, 'created': '2016-01-28 13:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/8279b848e2cbe6cc83e373a9566432d69a723971', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* removed conflicting discovery part in mon.py\n* group metrics by subsystem\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 30, 'created': '2016-01-28 13:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/54ccf56115db7dac5efe9853cbfd860b2b784f36', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* removed conflicting discovery part in mon.py\n* group metrics by subsystem\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 31, 'created': '2016-01-28 13:14:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/3c67e623fe85a1483b61556a6f46a9e60eeeaa09', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* removed conflicting discovery part in mon.py\n* group metrics by subsystem\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 32, 'created': '2016-01-28 13:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/7bee1854b30af5e4a30df1ced7f51cf044a6361f', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* removed conflicting discovery part in mon.py\n* group metrics by subsystem\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}, {'number': 33, 'created': '2016-02-01 09:48:51.000000000', 'files': ['monasca_setup/detection/plugins/influxdb.py', 'docs/Plugins.md', 'monasca_agent/collector/checks_d/influxdb.py', 'conf.d/influxdb.yaml.example', 'monasca_setup/detection/plugins/mon.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/9bc243b13410e0018c527755deb62ca21179ca76', 'message': ""An InfluxDB plugin to check status and performance metrics\n\n* reworked metric names to be shorter and more in line with other metrics\n* set 'component' dimension to 'influxdb', keep user setting for 'service'\n* removed conflicting discovery part in mon.py\n* group metrics by subsystem\n* fixed pep8 complaints\n\nChange-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01\n""}]",69,196167,9bc243b13410e0018c527755deb62ca21179ca76,85,7,33,12149,,,0,"An InfluxDB plugin to check status and performance metrics

* reworked metric names to be shorter and more in line with other metrics
* set 'component' dimension to 'influxdb', keep user setting for 'service'
* removed conflicting discovery part in mon.py
* group metrics by subsystem
* fixed pep8 complaints

Change-Id: I989456e0f8dea858a38611fb0f8a6bfea0633f01
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/67/196167/32 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_setup/detection/plugins/influxdb.py', 'monasca_agent/collector/checks_d/influxdb.py', 'conf.d/influxdb.yaml.example']",3,0b42137d534853ab80064bd96ecd18ba820351ea,influxdb,"init_config: instances: - name: InfluxDB url: http://localhost:8086/query? timeout: 1 # If your service uses basic authentication, you can optionally # specify a username and password that will be used in the check. # username: user # password: pass # The (optional) collect_response_time parameter will instruct the # check to create a metric 'network.http.response_time', tagged with # the url, reporting the response time in seconds. collect_response_time: true # The (optional) disable_ssl_validation will instruct the check # to skip the validation of the SSL certificate of the URL being tested. # This is mostly useful when checking SSL connections signed with # certificates that are not themselves signed by a public authority. # When true, the check logs a warning in collector.log # disable_ssl_validation: true # The (optional) headers parameter allows you to send extra headers # with the request. This is useful for explicitly specifying the host # header or perhaps adding headers for authorization purposes. Note # that the http client library converts all headers to lowercase. # This is legal according to RFC2616 # (See: http://tools.ietf.org/html/rfc2616#section-4.2) # but may be problematic with some HTTP servers # (See: https://code.google.com/p/httplib2/issues/detail?id=169) # headers: # Host: alternative.host.example.com # X-Auth-Token: SOME-AUTH-TOKEN # HTTP parameters k/v pairs. Generally used to supply URL parameters # to query InfluxDB params: q : SHOW STATS # Params will be urlencoded urlencode: !!bool true dimensions: !!map service : monitoring component : database # A list of metrics that will be published. The names here should be the # same as they appear in the series.name.server payload returned from # the InfluxDB json payload http://localhost:8086/query?q=SHOW%20STATS # NOTE: http_status is a special internal metric that does not come from # InfluxDB. # NOTE: response_time is a special internal metric that does not come from # InfluxDB. collect_response_time must be true in order for this metric to # be published. # If you have multiple agents querying the same instance you # can load balance amongst them to reduce the number of metrics Monasca # will ingest. whitelist: !!seq - queriesRx - queriesExecuted - http_status - response_time # This maps the metric received from InfluxDB (1st column) to the metric name # on the right and assigns a metric type to it. If there is base metric that # is received and it's in the whitelist, and not in the metricmap the metric # will retain the name it originally had and be published with that name and # get assigned a default type of 'gauge'. If it's not in the whitelist then # it will be ignored. # This mapping allows the user to make statuses unique so generic alarms will # not trigger on a unique metric. Conversely the same applies to generic alarms # and metric names. metricmap: !!map response_time : [ influx.db.http.latency.curr, gauge ] http_status : [ influx.db.http.status.curr, gauge ] broadcastMessageTx : [ influx.db.broadcastMessageTx.cnt.curr, rate ] writeSeriesMessageTx : [ influx.db.writeSeriesMessageTx.cnt.curr, rate ] queriesExecuted : [ influx.db.queriesExecuted.cnt.curr, rate ] queriesRx : [ influx.db.queriesRx.cnt.curr, rate ] shardsCreated : [ influx.db.shardsCreated.cnt.curr, rate ] broadcastMessageRx : [ influx.db.broadcastMessageRx.cnt.curr, rate ] batchWriteRx : [ influx.db.batchWriteRx.cnt.curr, rate ] pointWriteRx : [ influx.db.pointWriteRx.cnt.curr, rate ] ",,396,0
openstack%2Fmonasca-agent~master~Iead843c9f8adf8eb981894f5a3fbdb7d6695ff93,openstack/monasca-agent,master,Iead843c9f8adf8eb981894f5a3fbdb7d6695ff93,refer to https://github.com/jobrs/monasca-agent/blob/master/monasca_agent/collector/checks_d/influxdb.py for a less outdated version,ABANDONED,2017-12-18 08:25:04.000000000,2017-12-18 08:25:35.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-12-18 08:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/8c55a0724a602c4613c34241673b3fd81008ce7b', 'message': 'refer to https://github.com/jobrs/monasca-agent/blob/master/monasca_agent/collector/checks_d/influxdb.py for a less outdated version\n\nChange-Id: Iead843c9f8adf8eb981894f5a3fbdb7d6695ff93\n'}]",0,528652,8c55a0724a602c4613c34241673b3fd81008ce7b,3,1,1,17244,,,0,"refer to https://github.com/jobrs/monasca-agent/blob/master/monasca_agent/collector/checks_d/influxdb.py for a less outdated version

Change-Id: Iead843c9f8adf8eb981894f5a3fbdb7d6695ff93
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/52/528652/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,8c55a0724a602c4613c34241673b3fd81008ce7b,influxdb,,,0,0
openstack%2Fnova~master~Idc3972e39ee3e2df2dd423e49b6d868d598cf4c9,openstack/nova,master,Idc3972e39ee3e2df2dd423e49b6d868d598cf4c9,Add functional test for get_all_with_shared(),ABANDONED,2017-11-22 23:36:08.000000000,2017-12-18 08:22:02.000000000,,"[{'_account_id': 7}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 25625}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-11-22 23:36:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be8796953fcb517b141a68d6f8e862b488c35006', 'message': 'Add functional test for get_all_with_shared()\n\nThere are some tests in AllocationCandidatesTestCase to\nvalidate get_by_requests() in candidates. But there is no\nfunctional test of get_all_with_shared, which is more primitive\nSQL API.\n\nThis patch adds test_get_all_with_shared function in\nProviderDBHelperTestCase.\n\nChange-Id: Idc3972e39ee3e2df2dd423e49b6d868d598cf4c9\nRelated-Bug:#1731072\n'}, {'number': 2, 'created': '2017-11-24 04:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d873b64b98de93dccf938ebccb7e7308980193de', 'message': 'Add functional test for get_all_with_shared()\n\nThere are some tests in AllocationCandidatesTestCase to\nvalidate get_by_requests() in candidates. But there is no\nfunctional test of get_all_with_shared, which is more primitive\nSQL API.\n\nThis patch adds test_get_all_with_shared function in\nProviderDBHelperTestCase.\n\nChange-Id: Idc3972e39ee3e2df2dd423e49b6d868d598cf4c9\nRelated-Bug:#1731072\n'}, {'number': 3, 'created': '2017-12-01 14:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4b6bc23dcb2503aec74100a31df0680da98785a7', 'message': 'Add functional test for get_all_with_shared()\n\nThere are some tests in AllocationCandidatesTestCase to\nvalidate get_by_requests() in candidates. But there is no\nfunctional test of get_all_with_shared, which is more primitive\nSQL API.\n\nThis patch adds test_get_all_with_shared function in\nProviderDBHelperTestCase.\n\nChange-Id: Idc3972e39ee3e2df2dd423e49b6d868d598cf4c9\nRelated-Bug:#1731072\n'}, {'number': 4, 'created': '2017-12-08 01:17:32.000000000', 'files': ['nova/tests/functional/db/test_allocation_candidates.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fba6a54ec4b110d6f5d6ecd86613e16327a40385', 'message': 'Add functional test for get_all_with_shared()\n\nThere are some tests in AllocationCandidatesTestCase to\nvalidate get_by_requests() in candidates. But there is no\nfunctional test of get_all_with_shared, which is more primitive\nSQL API.\n\nThis patch adds test_get_all_with_shared function in\nProviderDBHelperTestCase.\n\nChange-Id: Idc3972e39ee3e2df2dd423e49b6d868d598cf4c9\nRelated-Bug:#1731072\n'}]",3,522408,fba6a54ec4b110d6f5d6ecd86613e16327a40385,26,10,4,25625,,,0,"Add functional test for get_all_with_shared()

There are some tests in AllocationCandidatesTestCase to
validate get_by_requests() in candidates. But there is no
functional test of get_all_with_shared, which is more primitive
SQL API.

This patch adds test_get_all_with_shared function in
ProviderDBHelperTestCase.

Change-Id: Idc3972e39ee3e2df2dd423e49b6d868d598cf4c9
Related-Bug:#1731072
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/522408/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/db/test_allocation_candidates.py'],1,be8796953fcb517b141a68d6f8e862b488c35006,bug/1702420," def test_get_all_with_shared(self): # These RPs are named based on whether we expect them to be 'incl'uded # or 'excl'uded in the result. # case1 should be OK (currently NG, bug:1731072(2)) # cn1: VCPU, MEM # ss1: DISK cn1 = self._create_provider('cn1', uuids.agg1) _add_inventory(cn1, fields.ResourceClass.VCPU, 15) _add_inventory(cn1, fields.ResourceClass.MEMORY_MB, 4096, max_unit=2048) ss1 = self._create_provider('ss1', uuids.agg1) _add_inventory(ss1, fields.ResourceClass.DISK_GB, 2000) _set_traits(ss1, 'MISC_SHARES_VIA_AGGREGATE') # case2 should be NG # cn2: VCPU, MEM # ss2: DISK(not enough) cn2 = self._create_provider('cn2', uuids.agg2) _add_inventory(cn2, fields.ResourceClass.VCPU, 15) _add_inventory(cn2, fields.ResourceClass.MEMORY_MB, 4096, max_unit=2048) ss2 = self._create_provider('ss2', uuids.agg2) _add_inventory(ss2, fields.ResourceClass.DISK_GB, 1000) _set_traits(ss2, 'MISC_SHARES_VIA_AGGREGATE') # case3 should be OK # cn3: VCPU, MEM, DISK(not enough) # ss3: DISK cn3 = self._create_provider('cn3', uuids.agg3) _add_inventory(cn3, fields.ResourceClass.VCPU, 15) _add_inventory(cn3, fields.ResourceClass.MEMORY_MB, 4096, max_unit=2048) _add_inventory(cn3, fields.ResourceClass.DISK_GB, 1000) ss3 = self._create_provider('ss3', uuids.agg3) _add_inventory(ss3, fields.ResourceClass.DISK_GB, 2000) _set_traits(ss3, 'MISC_SHARES_VIA_AGGREGATE') # case4 should be NG # cn4: VCPU, MEM, DISK(not enough) # ss4: DISK(not enough) cn4 = self._create_provider('cn4', uuids.agg4) _add_inventory(cn4, fields.ResourceClass.VCPU, 15) _add_inventory(cn4, fields.ResourceClass.MEMORY_MB, 4096, max_unit=2048) _add_inventory(cn4, fields.ResourceClass.DISK_GB, 1000) ss4 = self._create_provider('ss4', uuids.agg4) _add_inventory(ss4, fields.ResourceClass.DISK_GB, 1000) _set_traits(ss4, 'MISC_SHARES_VIA_AGGREGATE') # case5 should be OK # (currently both cn and ss are picked up, bug:1730730) # cn5: VCPU, MEM # ss5: DISK # This one is similar to case 1, but cn and ss are both # tagged with 'MISC_SHARES_VIA_AGGREGATE'. cn5 = self._create_provider('cn5', uuids.agg5) _add_inventory(cn5, fields.ResourceClass.VCPU, 15) _add_inventory(cn5, fields.ResourceClass.MEMORY_MB, 4096, max_unit=2048) _set_traits(cn5, 'MISC_SHARES_VIA_AGGREGATE') ss5 = self._create_provider('ss5', uuids.agg5) _add_inventory(ss5, fields.ResourceClass.DISK_GB, 2000) _set_traits(ss5, 'MISC_SHARES_VIA_AGGREGATE') # case6 and case8 are multiple aggregates cases # case6 should be OK (currently NG) # cn6: VCPU # ss6_1: MEM # ss6_2: DISK cn6 = self._create_provider('cn6', uuids.agg6, uuids.agg7) _add_inventory(cn6, fields.ResourceClass.VCPU, 15) ss6_1 = self._create_provider('ss6_1', uuids.agg6) _add_inventory(ss6_1, fields.ResourceClass.MEMORY_MB, 4096, max_unit=2048) _set_traits(ss6_1, 'MISC_SHARES_VIA_AGGREGATE') ss6_2 = self._create_provider('ss6_2', uuids.agg7) _add_inventory(ss6_2, fields.ResourceClass.DISK_GB, 2000) _set_traits(ss6_2, 'MISC_SHARES_VIA_AGGREGATE') # case8 should be OK # cn8: nothing # ss8_1: VCPU, MEM # ss8_2: DISK cn8 = self._create_provider('cn8', uuids.agg8, uuids.agg9) ss8_1 = self._create_provider('ss8_1', uuids.agg8) _add_inventory(ss8_1, fields.ResourceClass.VCPU, 15) _add_inventory(ss8_1, fields.ResourceClass.MEMORY_MB, 4096, max_unit=2048) _set_traits(ss8_1, 'MISC_SHARES_VIA_AGGREGATE') ss8_2 = self._create_provider('ss8_2', uuids.agg9) _add_inventory(ss8_2, fields.ResourceClass.DISK_GB, 2000) _set_traits(ss8_2, 'MISC_SHARES_VIA_AGGREGATE') resources = { fields.ResourceClass.STANDARD.index(fields.ResourceClass.VCPU): 5, fields.ResourceClass.STANDARD.index( fields.ResourceClass.MEMORY_MB): 1024, fields.ResourceClass.STANDARD.index( fields.ResourceClass.DISK_GB): 1500 } # Run it! res = [r[0] for r in rp_obj._get_all_with_shared(self.ctx, resources)] # we should get # expected = [cn1, cn3, cn5, cn6, cn8] # actual is expected = [cn3, cn5, ss5, cn8] self.assertEqual(set(rp.id for rp in expected), set(res)) ",,113,0
openstack%2Fcompute-hyperv~master~I5830079e21a27691e0746f164501c6c92de86a96,openstack/compute-hyperv,master,I5830079e21a27691e0746f164501c6c92de86a96,Updated from global requirements,MERGED,2017-12-15 21:24:07.000000000,2017-12-18 08:21:26.000000000,2017-12-18 08:21:26.000000000,"[{'_account_id': 8213}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 21:24:07.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/5912d4056ce433fcf2992926ecb411d360d2bdac', 'message': 'Updated from global requirements\n\nChange-Id: I5830079e21a27691e0746f164501c6c92de86a96\n'}]",0,528396,5912d4056ce433fcf2992926ecb411d360d2bdac,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I5830079e21a27691e0746f164501c6c92de86a96
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/96/528396/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5912d4056ce433fcf2992926ecb411d360d2bdac,openstack/requirements,"oslo.service!=1.28.1,>=1.24.0 # Apache-2.0",oslo.service>=1.24.0 # Apache-2.0,1,1
openstack%2Ftripleo-heat-templates~master~If38a4f7e25d4d1f4679d9684ad2c0db8475d679b,openstack/tripleo-heat-templates,master,If38a4f7e25d4d1f4679d9684ad2c0db8475d679b,Search for containers within stopped containers.,MERGED,2017-12-11 13:36:59.000000000,2017-12-18 08:17:13.000000000,2017-12-14 10:22:54.000000000,"[{'_account_id': 6926}, {'_account_id': 8297}, {'_account_id': 8449}, {'_account_id': 11166}, {'_account_id': 13039}, {'_account_id': 16515}, {'_account_id': 18851}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-11 13:36:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3077aff5b77c3f239214796a188188757303660b', 'message': ""Search for containers within stopped containers.\n\nDuring minor update pcs cluster is stopped during step 1.\nThen we search for pcs managed containers at step 2.\nBut since pcs cluster is stopped, 'docker ps' won't report stopped\ncontainers.\nThis change adds '--all' option to show all the containers.\n\nChange-Id: If38a4f7e25d4d1f4679d9684ad2c0db8475d679b\n""}, {'number': 2, 'created': '2017-12-11 13:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2bdc1ffdb8015e4292a5c21184f95716fa638d82', 'message': ""Search for containers within stopped containers.\n\nDuring minor update pcs cluster is stopped during step 1.\nThen we search for pcs managed containers at step 2.\nBut since pcs cluster is stopped, 'docker ps' won't report stopped\ncontainers.\nThis change adds '--all' option to show all the containers.\n\nChange-Id: If38a4f7e25d4d1f4679d9684ad2c0db8475d679b\nCloses-Bug: 1737548\n""}, {'number': 3, 'created': '2017-12-11 15:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c768f47a5fd562b9eb6a2da4fc8d676d9ec2ecb1', 'message': ""Search for containers within stopped containers.\n\nDuring minor update pcs cluster is stopped during step 1.\nThen we search for pcs managed containers at step 2.\nBut since pcs cluster is stopped, 'docker ps' won't report stopped\ncontainers.\nThis change adds '--all' option to show all the containers.\n\nChange-Id: If38a4f7e25d4d1f4679d9684ad2c0db8475d679b\nCloses-Bug: #1737548\n""}, {'number': 4, 'created': '2017-12-13 10:34:45.000000000', 'files': ['docker/services/pacemaker/rabbitmq.yaml', 'docker/services/pacemaker/cinder-volume.yaml', 'docker/services/pacemaker/haproxy.yaml', 'docker/services/pacemaker/database/mysql.yaml', 'docker/services/pacemaker/database/redis.yaml', 'docker/services/pacemaker/cinder-backup.yaml', 'docker/services/pacemaker/manila-share.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/09dcd7e26c45edeefc1463a2885f94882433589e', 'message': ""Search for containers within stopped containers.\n\nDuring minor update pcs cluster is stopped during step 1.\nThen we search for pcs managed containers at step 2.\nBut since pcs cluster is stopped, 'docker ps' won't report stopped\ncontainers.\nThis change adds '--all' option to show all the containers.\n\nChange-Id: If38a4f7e25d4d1f4679d9684ad2c0db8475d679b\nCloses-Bug: #1737548\n""}]",1,527086,09dcd7e26c45edeefc1463a2885f94882433589e,22,10,4,21537,,,0,"Search for containers within stopped containers.

During minor update pcs cluster is stopped during step 1.
Then we search for pcs managed containers at step 2.
But since pcs cluster is stopped, 'docker ps' won't report stopped
containers.
This change adds '--all' option to show all the containers.

Change-Id: If38a4f7e25d4d1f4679d9684ad2c0db8475d679b
Closes-Bug: #1737548
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/86/527086/4 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/pacemaker/rabbitmq.yaml', 'docker/services/pacemaker/cinder-volume.yaml', 'docker/services/pacemaker/database/mysql.yaml', 'docker/services/pacemaker/haproxy.yaml', 'docker/services/pacemaker/database/redis.yaml', 'docker/services/pacemaker/cinder-backup.yaml', 'docker/services/pacemaker/manila-share.yaml']",7,3077aff5b77c3f239214796a188188757303660b,bug/1737548," shell: ""docker ps -a -q -f 'ancestor={{manila_share_image_id.stdout}}'"""," shell: ""docker ps -q -f 'ancestor={{manila_share_image_id.stdout}}'""",7,7
openstack%2Fopenstacksdk~master~Icb27c6fd43b143676b23c3aca7f23d9d8ab0f04e,openstack/openstacksdk,master,Icb27c6fd43b143676b23c3aca7f23d9d8ab0f04e,Stop osSDK mangling Swift metadata keys,MERGED,2017-11-30 05:21:59.000000000,2017-12-18 08:16:59.000000000,2017-12-18 08:16:59.000000000,"[{'_account_id': 2}, {'_account_id': 170}, {'_account_id': 8246}, {'_account_id': 8257}, {'_account_id': 10420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-30 05:21:59.000000000', 'files': ['openstack/object_store/v1/_base.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/895db171233cfc74728a2eb5db3b63d29139055a', 'message': 'Stop osSDK mangling Swift metadata keys\n\nMake the _calculate_headers function check the values\nas well as the keys in _system_metadata for metadata\nkeys passed in, and otherwise first check if the key\nhas the _custom_metadata_prefix before prepending it.\n\nChange-Id: Icb27c6fd43b143676b23c3aca7f23d9d8ab0f04e\n'}]",0,524066,895db171233cfc74728a2eb5db3b63d29139055a,10,6,1,10420,,,0,"Stop osSDK mangling Swift metadata keys

Make the _calculate_headers function check the values
as well as the keys in _system_metadata for metadata
keys passed in, and otherwise first check if the key
has the _custom_metadata_prefix before prepending it.

Change-Id: Icb27c6fd43b143676b23c3aca7f23d9d8ab0f04e
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/66/524066/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/object_store/v1/_base.py'],1,895db171233cfc74728a2eb5db3b63d29139055a,bug/swift_metadata, if key in self._system_metadata.keys(): elif key in self._system_metadata.values(): header = key else: if key.startswith(self._custom_metadata_prefix): header = key else: header = self._custom_metadata_prefix + key, if key in self._system_metadata: else: header = self._custom_metadata_prefix + key,7,2
openstack%2Fblazar~master~Ibf97d2395836953c99e07d31dfaba5633df9d9fd,openstack/blazar,master,Ibf97d2395836953c99e07d31dfaba5633df9d9fd,Fix grammar in exception message,MERGED,2017-12-15 14:17:08.000000000,2017-12-18 07:58:37.000000000,2017-12-18 07:58:37.000000000,"[{'_account_id': 8878}, {'_account_id': 17352}, {'_account_id': 22348}, {'_account_id': 23840}]","[{'number': 1, 'created': '2017-12-15 14:17:08.000000000', 'files': ['blazar/manager/service.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/e0bff072c0b7c8e5c3b3d90aa8582f64158a4b19', 'message': 'Fix grammar in exception message\n\nChange-Id: Ibf97d2395836953c99e07d31dfaba5633df9d9fd\n'}]",0,528280,e0bff072c0b7c8e5c3b3d90aa8582f64158a4b19,8,4,1,15197,,,0,"Fix grammar in exception message

Change-Id: Ibf97d2395836953c99e07d31dfaba5633df9d9fd
",git fetch https://review.opendev.org/openstack/blazar refs/changes/80/528280/1 && git format-patch -1 --stdout FETCH_HEAD,['blazar/manager/service.py'],1,e0bff072c0b7c8e5c3b3d90aa8582f64158a4b19,grammar-fix, 'Start date must be later than current date') 'Start date must be later than current date'), 'Start date must later than current date') 'Start date must later than current date'),2,2
openstack%2Ftempest~master~I7094879126a83eabb5a6e1fafe3ce0ccfa8b4e7c,openstack/tempest,master,I7094879126a83eabb5a6e1fafe3ce0ccfa8b4e7c,Use addClassResourceCleanup in account service test,MERGED,2017-12-15 07:24:04.000000000,2017-12-18 07:56:03.000000000,2017-12-18 07:56:02.000000000,"[{'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 10385}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 07:24:04.000000000', 'files': ['tempest/api/object_storage/test_account_services.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/19355c9607bd799718c11c6b9ada430a02b784e2', 'message': 'Use addClassResourceCleanup in account service test\n\nThis patch is to use addClassResourceCleanup for the\naccount service test.\n\nChange-Id: I7094879126a83eabb5a6e1fafe3ce0ccfa8b4e7c\n'}]",0,528179,19355c9607bd799718c11c6b9ada430a02b784e2,8,4,1,12385,,,0,"Use addClassResourceCleanup in account service test

This patch is to use addClassResourceCleanup for the
account service test.

Change-Id: I7094879126a83eabb5a6e1fafe3ce0ccfa8b4e7c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/79/528179/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/object_storage/test_account_services.py'],1,19355c9607bd799718c11c6b9ada430a02b784e2,add-class-resource-cleanup-in-service-test," cls.addClassResourceCleanup(base.delete_containers, [name], cls.container_client, cls.object_client)"," @classmethod def resource_cleanup(cls): cls.delete_containers() super(AccountTest, cls).resource_cleanup() ",4,5
openstack%2Fkolla~stable%2Fpike~Ib634f8dcd3fbebdbba008c6611ad3ca9cdc75fc7,openstack/kolla,stable/pike,Ib634f8dcd3fbebdbba008c6611ad3ca9cdc75fc7,"Revert ""Fix deployment of ceph""",ABANDONED,2017-12-12 08:35:50.000000000,2017-12-18 07:53:13.000000000,,"[{'_account_id': 7488}, {'_account_id': 10787}, {'_account_id': 11869}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}]","[{'number': 1, 'created': '2017-12-12 08:35:50.000000000', 'files': ['docker/base/apt_preferences.ubuntu'], 'web_link': 'https://opendev.org/openstack/kolla/commit/a96962788cde14327c20f7985d411be792f08b66', 'message': 'Revert ""Fix deployment of ceph""\n\nUbuntu binary is broken even not using ceph, qemu-img is not able to parse image in installed version.\n\nhttp://logs.openstack.org/31/526931/1/check/kolla-ansible-ubuntu-binary/b5bfe87/primary/kolla/nova/nova-compute.txt.gz#_2017-12-10_17_54_18_791\n\nThis reverts commit c0d8c487fa9b3658d1b3cd78c518e8ef5983c26c.\n\nChange-Id: Ib634f8dcd3fbebdbba008c6611ad3ca9cdc75fc7\n'}]",0,527339,a96962788cde14327c20f7985d411be792f08b66,11,7,1,19316,,,0,"Revert ""Fix deployment of ceph""

Ubuntu binary is broken even not using ceph, qemu-img is not able to parse image in installed version.

http://logs.openstack.org/31/526931/1/check/kolla-ansible-ubuntu-binary/b5bfe87/primary/kolla/nova/nova-compute.txt.gz#_2017-12-10_17_54_18_791

This reverts commit c0d8c487fa9b3658d1b3cd78c518e8ef5983c26c.

Change-Id: Ib634f8dcd3fbebdbba008c6611ad3ca9cdc75fc7
",git fetch https://review.opendev.org/openstack/kolla refs/changes/39/527339/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/base/apt_preferences.ubuntu'],1,a96962788cde14327c20f7985d411be792f08b66,publisher-stable/pike,,Package: ceph* Pin: version 10.* Pin-Priority: 550 Package: *rbd* Pin: version 10.* Pin-Priority: 550 Package: python-cephfs Pin: version 10.* Pin-Priority: 550 Package: *rados* Pin: version 10.* Pin-Priority: 550 Package: *rgw* Pin: version 10.* Pin-Priority: 550 Package: qemu* Pin: version 1:2.5* Pin-Priority: 550 ,0,23
openstack%2Fproject-config~master~I0ea86040b91c1c3de4f5b315183974548e51b5fa,openstack/project-config,master,I0ea86040b91c1c3de4f5b315183974548e51b5fa,Use ensure-babel to make sure babel is installed,MERGED,2017-11-17 15:19:24.000000000,2017-12-18 07:51:28.000000000,2017-12-18 07:51:28.000000000,"[{'_account_id': 2}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2017-11-17 15:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/fcc136fd5c18eebb469a983425ed9c8240358ac8', 'message': 'Use ensure-babel to make sure babel is installed\n\nWe made an ensure-babel role. Use it instead of the shell script.\nFrom doing that, remove VENV references in the translation update\nscripts, since ensure-babel just does pip install --user.\n\nChange-Id: I0ea86040b91c1c3de4f5b315183974548e51b5fa\nDepends-On: I7827a63170168db5a6501b28d379e458171d556a\n'}, {'number': 2, 'created': '2017-11-20 15:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/79e7b92561460dedda08dfb745ac9ee87c6c8c73', 'message': 'Use ensure-babel to make sure babel is installed\n\nWe made an ensure-babel role. Use it instead of the shell script.\nFrom doing that, remove references in the translation update\nscripts and instead source the activate script. Ensure-babel currently\ninstalls into a venv, but may want to just do pip install --user in the\nfuture.\n\nChange-Id: I0ea86040b91c1c3de4f5b315183974548e51b5fa\nDepends-On: I1334ff1f469061884b222dd99e72a989d72c68be\n'}, {'number': 3, 'created': '2017-11-20 15:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f7a77d08905ace8386ac1e3a3bfd11cbcd0f9045', 'message': 'Use ensure-babel to make sure babel is installed\n\nWe made an ensure-babel role. Use it instead of the shell script.\nFrom doing that, remove references in the translation update\nscripts and instead source the activate script. Ensure-babel currently\ninstalls into a venv, but may want to just do pip install --user in the\nfuture.\n\nChange-Id: I0ea86040b91c1c3de4f5b315183974548e51b5fa\nDepends-On: I1334ff1f469061884b222dd99e72a989d72c68be\n'}, {'number': 4, 'created': '2017-12-16 14:43:17.000000000', 'files': ['playbooks/translation/pre.yaml', 'jenkins/scripts/upstream_translation_update.sh', 'jenkins/scripts/common_translation_update.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/d261ebdc96b3b1415af6e8e118047c2bdca25531', 'message': 'Use ensure-babel to make sure babel is installed\n\nWe made an ensure-babel role. Use it instead of the shell script.\nFrom doing that, remove references in the translation update\nscripts and instead source the activate script. Ensure-babel currently\ninstalls into a venv, but may want to just do pip install --user in the\nfuture.\n\nChange-Id: I0ea86040b91c1c3de4f5b315183974548e51b5fa\nDepends-On: I1334ff1f469061884b222dd99e72a989d72c68be\n'}]",7,521105,d261ebdc96b3b1415af6e8e118047c2bdca25531,22,5,4,2,,,0,"Use ensure-babel to make sure babel is installed

We made an ensure-babel role. Use it instead of the shell script.
From doing that, remove references in the translation update
scripts and instead source the activate script. Ensure-babel currently
installs into a venv, but may want to just do pip install --user in the
future.

Change-Id: I0ea86040b91c1c3de4f5b315183974548e51b5fa
Depends-On: I1334ff1f469061884b222dd99e72a989d72c68be
",git fetch https://review.opendev.org/openstack/project-config refs/changes/05/521105/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/translation/pre.yaml', 'jenkins/scripts/propose_translation_update.sh', 'jenkins/scripts/upstream_translation_update.sh', 'jenkins/scripts/common_translation_update.sh', 'zuul.d/jobs.yaml']",5,fcc136fd5c18eebb469a983425ed9c8240358ac8,updated-pti, pre-run: playbooks/translation/pre.yaml pre-run: playbooks/translation/pre.yaml, pre-run: playbooks/releasenotes/pre.yaml pre-run: playbooks/releasenotes/pre.yaml,26,66
openstack%2Fblazar~master~Ic6b66c2b321ea01ebe9d71486e4357f5b93a5fe2,openstack/blazar,master,Ic6b66c2b321ea01ebe9d71486e4357f5b93a5fe2,Change lease start date in some test scenarios,MERGED,2017-12-13 07:39:00.000000000,2017-12-18 07:48:32.000000000,2017-12-18 07:48:32.000000000,"[{'_account_id': 8878}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 23840}]","[{'number': 1, 'created': '2017-12-13 07:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/23aa8d8c33e3db5e033482100e593f8290a6f35e', 'message': 'Introduce a safety margin for lease start time\n\nThis patch introduces a 30 seconds safety margin for the start time of a\nlease in some test scenarios.\n\nChange-Id: Ic6b66c2b321ea01ebe9d71486e4357f5b93a5fe2\n'}, {'number': 2, 'created': '2017-12-13 07:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/ce54e4086e19ddb5c278f72f6720a50545970ca3', 'message': 'Introduce a safety margin for lease start time\n\nThis patch introduces a 30 seconds safety margin for the start time of a\nlease in some test scenarios.\n\nCloses-Bug: #1737880\nChange-Id: Ic6b66c2b321ea01ebe9d71486e4357f5b93a5fe2\n'}, {'number': 3, 'created': '2017-12-15 02:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/aed2f5a7639484f11bf61b262a12ba3cd0e8e2dd', 'message': 'Change a start date in some test scenarios\n\nThis patch changes a start date of a lease to ""now"" for preventing\na timing error.\n\nCloses-Bug: #1737880\nChange-Id: Ic6b66c2b321ea01ebe9d71486e4357f5b93a5fe2\n'}, {'number': 4, 'created': '2017-12-15 06:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/6709fee4a726338bb9260bdd8c2ea41a2d55c8a7', 'message': 'Change a start date in some test scenarios\n\nThis patch changes a start date of a lease to ""now"" for preventing\na timing error.\n\nCloses-Bug: #1737880\nChange-Id: Ic6b66c2b321ea01ebe9d71486e4357f5b93a5fe2\n'}, {'number': 5, 'created': '2017-12-15 14:20:53.000000000', 'files': ['blazar_tempest_plugin/tests/scenario/test_host_reservation.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/05bc2e45809331c43f4f0be3a65846fa4017b137', 'message': 'Change lease start date in some test scenarios\n\nThis patch changes the start date of leases to ""now"" to prevent them\nfrom being rejected for starting before the current date.\n\nCloses-Bug: #1737880\nChange-Id: Ic6b66c2b321ea01ebe9d71486e4357f5b93a5fe2\n'}]",0,527615,05bc2e45809331c43f4f0be3a65846fa4017b137,17,4,5,23840,,,0,"Change lease start date in some test scenarios

This patch changes the start date of leases to ""now"" to prevent them
from being rejected for starting before the current date.

Closes-Bug: #1737880
Change-Id: Ic6b66c2b321ea01ebe9d71486e4357f5b93a5fe2
",git fetch https://review.opendev.org/openstack/blazar refs/changes/15/527615/3 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/tempest/tempest/scenario/test_host_reservation.py', 'contrib/tempest/tempest/scenario/test_instance_reservation.py']",2,23aa8d8c33e3db5e033482100e593f8290a6f35e,bug/1737880,START_MARGIN_SECONDS = 30 start_date = datetime.datetime.utcnow() + datetime.timedelta( seconds=START_MARGIN_SECONDS), start_date = datetime.datetime.utcnow() + datetime.timedelta(minutes=1),20,7
openstack%2Fopenstack-zuul-jobs~master~I220bddabf24be5773c835635473e4b90e474eb09,openstack/openstack-zuul-jobs,master,I220bddabf24be5773c835635473e4b90e474eb09,Improve ensure-reno,MERGED,2017-12-16 14:45:56.000000000,2017-12-18 07:45:28.000000000,2017-12-18 07:45:28.000000000,"[{'_account_id': 2}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-16 14:45:56.000000000', 'files': ['roles/ensure-reno/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/7d47107a469444e98dc1c53ce25f082ac9c89a50', 'message': 'Improve ensure-reno\n\nFollow I1334ff1f469061884b222dd99e72a989d72c68be and fail if\nconstraints_file contains a file name that does not exist.\n\nChange-Id: I220bddabf24be5773c835635473e4b90e474eb09\n'}]",0,528477,7d47107a469444e98dc1c53ce25f082ac9c89a50,8,4,1,6547,,,0,"Improve ensure-reno

Follow I1334ff1f469061884b222dd99e72a989d72c68be and fail if
constraints_file contains a file name that does not exist.

Change-Id: I220bddabf24be5773c835635473e4b90e474eb09
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/77/528477/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/ensure-reno/tasks/main.yaml'],1,7d47107a469444e98dc1c53ce25f082ac9c89a50,ensure-reno," path: ""{{ constraints_file }}""- name: Fail if constraints file does not exist fail: msg: ""Variable constraints_file is set but file does not exist."" when: - constraints_file is defined - not stat_results|skipped and not stat_results.stat.exists "," path: ""{{ constraints_file|default('missing') }}""",8,1
openstack%2Fblazar~master~Ibdf7a730ae45ff6d8c17de62b0fc69262df2db79,openstack/blazar,master,Ibdf7a730ae45ff6d8c17de62b0fc69262df2db79,Support update reservation in instance reservation,MERGED,2017-10-18 09:50:37.000000000,2017-12-18 07:34:41.000000000,2017-12-18 07:34:41.000000000,"[{'_account_id': 8878}, {'_account_id': 13192}, {'_account_id': 22348}, {'_account_id': 23840}]","[{'number': 1, 'created': '2017-10-18 09:50:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/874538e832c3ac84ff4de83d8fb641986782f131', 'message': ""Support update reservation in instance reservation\n\nInstanceReservation plugin doesn't support update lease API\nin Pike release.\n\nThis patch enables InstanceReservation plugin to support update\nlease API.  If a reservation already starts, the API only accepts\nincrement of the amount since the change of reserved flavor requires\nusers resize their instances.\n\nCloses-Bugs: #1714437\nChange-Id: Ibdf7a730ae45ff6d8c17de62b0fc69262df2db79\n""}, {'number': 2, 'created': '2017-10-19 04:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/6b1333f6bd5a630bc8c869c937853d20186c8e65', 'message': ""Support update reservation in instance reservation\n\nInstanceReservation plugin doesn't support update lease API\nin Pike release.\n\nThis patch enables InstanceReservation plugin to support update\nlease API.  If a reservation already starts, the API only accepts\nincrement of the amount since the change of reserved flavor requires\nusers resize their instances.\n\nCloses-Bugs: #1714437\nChange-Id: Ibdf7a730ae45ff6d8c17de62b0fc69262df2db79\n""}, {'number': 3, 'created': '2017-10-20 06:14:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/90512e3dd5dcb5eeb2cab9c4101a56abca5359f5', 'message': ""Support update reservation in instance reservation\n\nInstanceReservation plugin doesn't support update lease API\nin Pike release.\n\nThis patch enables InstanceReservation plugin to support update\nlease API.  If a reservation already starts, the API only accepts\nincrement of the amount since the change of reserved flavor requires\nusers resize their instances.\n\nCloses-Bug: #1714437\nChange-Id: Ibdf7a730ae45ff6d8c17de62b0fc69262df2db79\n""}, {'number': 4, 'created': '2017-10-24 08:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/0af6665f3bb924b37ce422b3c5211152e6e702d0', 'message': ""Support update reservation in instance reservation\n\nInstanceReservation plugin doesn't support update lease API\nin Pike release.\n\nThis patch enables InstanceReservation plugin to support update\nlease API.  If a reservation already starts, the API only accepts\nincrement of the amount since the change of reserved flavor requires\nusers resize their instances.\n\nCloses-Bug: #1714437\nChange-Id: Ibdf7a730ae45ff6d8c17de62b0fc69262df2db79\n""}, {'number': 5, 'created': '2017-12-12 08:40:00.000000000', 'files': ['blazar/tests/plugins/instances/test_instance_plugin.py', 'blazar/plugins/instances/instance_plugin.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/0dc5eee2c36603a15ba7edf2d9743aa4243bdde4', 'message': ""Support update reservation in instance reservation\n\nInstanceReservation plugin doesn't support update lease API\nin Pike release.\n\nThis patch enables InstanceReservation plugin to support update\nlease API.  If a reservation already starts, the API only accepts\nincrement of the amount since the change of reserved flavor requires\nusers resize their instances.\n\nCloses-Bug: #1714437\nChange-Id: Ibdf7a730ae45ff6d8c17de62b0fc69262df2db79\n""}]",14,512988,0dc5eee2c36603a15ba7edf2d9743aa4243bdde4,27,4,5,8878,,,0,"Support update reservation in instance reservation

InstanceReservation plugin doesn't support update lease API
in Pike release.

This patch enables InstanceReservation plugin to support update
lease API.  If a reservation already starts, the API only accepts
increment of the amount since the change of reserved flavor requires
users resize their instances.

Closes-Bug: #1714437
Change-Id: Ibdf7a730ae45ff6d8c17de62b0fc69262df2db79
",git fetch https://review.opendev.org/openstack/blazar refs/changes/88/512988/3 && git format-patch -1 --stdout FETCH_HEAD,"['blazar/tests/plugins/instances/test_instance_plugin.py', 'blazar/plugins/instances/instance_plugin.py']",2,874538e832c3ac84ff4de83d8fb641986782f131,bug/1714437," def filter_hosts_by_reservation(self, hosts, start_date, end_date, excludes): if excludes: reservations = filter(lambda r: r['id'] not in excludes, reservations) def query_available_hosts(self, cpus, memory, disk, start_date, end_date, excludes_res=None): """"""Query hosts that are available for a reservation. Its return value is in the order of reserved hosts to free hosts now. """""" flavor_definitions = [ 'and', ["">="", ""$vcpus"", str(cpus)], ["">="", ""$memory_mb"", str(memory)], ["">="", ""$local_gb"", str(disk)], ] filters = plugins_utils.convert_requirements(flavor_definitions) hosts = db_api.host_get_all_by_queries(filters) free_hosts, reserved_hosts = \ self.filter_hosts_by_reservation(hosts, start_date, end_date, excludes_res) available_hosts = [] for host_info in reserved_hosts: host = host_info['host'] reservations = host_info['reservations'] max_cpus, max_memory, max_disk = self.max_usages(host, reservations) if not (max_cpus + cpus > host['vcpus'] or max_memory + memory > host['memory_mb'] or max_disk + disk > host['local_gb']): available_hosts.append(host) available_hosts.extend([h['host'] for h in free_hosts]) return available_hosts hosts = self.query_available_hosts(cpus, memory, disk, start_date, end_date) if len(hosts) >= int(amount): return [h['id'] for h in hosts][:int(amount)] def _create_flavor(self, reservation_id, vcpus, memory, disk, group_id): flavor_details = { 'flavorid': reservation_id, 'name': RESERVATION_PREFIX + "":"" + reservation_id, 'vcpus': vcpus, 'ram': memory, 'disk': disk, 'is_public': False } reserved_flavor = self.nova.nova.flavors.create(**flavor_details) extra_specs = { FLAVOR_EXTRA_SPEC: reservation_id, ""affinity_id"": group_id } reserved_flavor.set_keys(extra_specs) return reserved_flavor def _create_resources(self, inst_reservation): reservation_id = inst_reservation['reservation_id'] 'affinity' if inst_reservation['affinity'] else 'anti-affinity' reserved_flavor = self._create_flavor(reservation_id, inst_reservation['vcpus'], inst_reservation['memory_mb'], inst_reservation['disk_gb'], reserved_group.id) def update_resources(self, reservation_id): """"""Updates reserved resources in Nova. This method updates reserved resources in Compute service. If the reservation is in actice status, it adds new allocated hosts into a reserved aggregate. If the reservation is not started yet, it updates a reserved flavor. """""" reservation = db_api.reservation_get(reservation_id) if reservation['status'] == 'active': pool = nova.ReservationPool() for allocation in db_api.host_allocation_get_all_by_values( reservation_id=reservation['id']): host = db_api.host_get(allocation['compute_host_id']) try: pool.add_computehost( reservation['aggregate_id'], host['service_name'], stay_in=True) except mgr_exceptions.AggregateAlreadyHasHost: pass except nova_exceptions.ClientException: err_msg = ('Fail to add host %s to aggregate %s.' % (host, reservation['aggregate_id'])) raise mgr_exceptions.NovaClientError(err_msg) else: try: self.nova.nova.flavors.delete(reservation['id']) self._create_flavor(reservation['id'], reservation['vcpus'], reservation['memory_mb'], reservation['disk_gb'], reservation['server_group_id']) except nova_exceptions.ClientException: LOG.exception(""Failed to update Nova resources "" ""for reservation %s"" % reservation['id']) raise mgr_exceptions.NovaClientError() def select_allocation(self, new_values, reservation_id): old_allocs = db_api.host_allocation_get_all_by_values( reservation_id=reservation_id) new_hosts = self.query_available_hosts( new_values['vcpus'], new_values['memory_mb'], new_values['disk_gb'], new_values['start_date'], new_values['end_date'], excludes_res=[reservation_id]) old_host_ids = {h['compute_host_id'] for h in old_allocs} candidate_ids = {h['id'] for h in new_hosts} kept_host_ids = old_host_ids & candidate_ids removed_host_ids = old_host_ids - candidate_ids extra_host_ids = candidate_ids - old_host_ids added_host_ids = set([]) if len(kept_host_ids) > new_values['amount']: extra = len(kept_host_ids) - new_values['amount'] for i in range(extra): removed_host_ids.add(kept_host_ids.pop()) elif len(kept_host_ids) < new_values['amount']: less = new_values['amount'] - len(kept_host_ids) if less > len(extra_host_ids): raise mgr_exceptions.NotEnoughHostsAvailable() for i in range(less): added_host_ids.add(extra_host_ids.pop()) reservation = db_api.reservation_get(reservation_id) if reservation['status'] == 'active' and len(removed_host_ids) > 0: raise mgr_exceptions.NotEnoughHostsAvailable() return {'added': added_host_ids, 'removed': removed_host_ids} def update_host_allocations(self, added, removed, reservation_id): allocations = db_api.host_allocation_get_all_by_values( reservation_id=reservation_id) removed_allocs = [a for a in allocations if a['compute_host_id'] in removed] for alloc in removed_allocs: db_api.host_allocation_destroy(alloc['id']) for added_host in added: db_api.host_allocation_create({'compute_host_id': added_host, 'reservation_id': reservation_id}) def update_reservation(self, reservation_id, new_values): """"""Updates an instance reservation with requested parameters. This method allows users to update an instance reservation under the following conditions. - If an instance reservation doesn't start - vcpus, memory_mb disk_gb and amount can be updateable unless Blazar can accomodate the new request. - If an instance reservation has already started - only amount is increasable. """""" # TODO(masahito) the instance reservation plugin only supports # anti-affinity rule in short-term goal. if bool_from_string(new_values.get('affinity', None)): raise exceptions.BlazarException('affinity = True is not ' 'supported.') reservation = db_api.reservation_get(reservation_id) lease = db_api.lease_get(reservation['lease_id']) updatable = ['vcpus', 'memory_mb', 'disk_gb', 'affinity', 'amount'] if (not any([k in updatable for k in new_values.keys()]) and new_values['start_date'] >= lease['start_date'] and new_values['end_date'] <= lease['end_date']): # no update because of just shortening the reservation time return if (reservation['status'] == 'active' and any([k in updatable[:-1] for k in new_values.keys()])): raise mgr_exceptions.NotEnoughHostsAvailable() for key in updatable: if key not in new_values: new_values[key] = reservation[key] changed_hosts = self.select_allocation(new_values, reservation_id) db_api.instance_reservation_update( reservation['resource_id'], {key: new_values[key] for key in updatable}) self.update_host_allocations(changed_hosts['added'], changed_hosts['removed'], reservation_id) try: self.update_resources(reservation_id) except mgr_exceptions.NovaClientError: raise"," def filter_hosts_by_reservation(self, hosts, start_date, end_date): flavor_definitions = [ 'and', ["">="", ""$vcpus"", str(cpus)], ["">="", ""$memory_mb"", str(memory)], ["">="", ""$local_gb"", str(disk)], ] filters = plugins_utils.convert_requirements(flavor_definitions) hosts = db_api.host_get_all_by_queries(filters) free_hosts, reserved_hosts = \ self.filter_hosts_by_reservation(hosts, start_date, end_date) host_ids = [] for host_info in reserved_hosts: host = host_info['host'] reservations = host_info['reservations'] max_cpus, max_memory, max_disk = self.max_usages(host, reservations) if not (max_cpus + cpus > host['vcpus'] or max_memory + memory > host['memory_mb'] or max_disk + disk > host['local_gb']): host_ids.append(host['id']) if len(host_ids) >= int(amount): return host_ids[:int(amount)] elif len(host_ids) + len(free_hosts) >= int(amount): host_ids.extend([h['host']['id'] for h in free_hosts]) return host_ids[:int(amount)] def _create_resources(self, instance_reservation): reservation_id = instance_reservation['reservation_id'] 'affinity' if instance_reservation['affinity'] else 'anti-affinity' flavor_details = { 'flavorid': reservation_id, 'name': RESERVATION_PREFIX + "":"" + reservation_id, 'vcpus': instance_reservation['vcpus'], 'ram': instance_reservation['memory_mb'], 'disk': instance_reservation['disk_gb'], 'is_public': False } reserved_flavor = self.nova.nova.flavors.create(**flavor_details) extra_specs = { FLAVOR_EXTRA_SPEC: reservation_id, ""affinity_id"": reserved_group.id } reserved_flavor.set_keys(extra_specs) def update_reservation(self, reservation_id, values): raise NotImplementedError(""resource type virtual:instance doesn't "" ""support updates of reservation."")",501,50
openstack%2Fneutron~master~I6e5f4539b2dfd82f2af336da02f07324af8cec02,openstack/neutron,master,I6e5f4539b2dfd82f2af336da02f07324af8cec02,bugs.rst: Add rfe-postponed to the list of tags,MERGED,2017-12-12 04:41:46.000000000,2017-12-18 07:20:54.000000000,2017-12-17 10:52:57.000000000,"[{'_account_id': 4694}, {'_account_id': 6854}, {'_account_id': 7715}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 04:41:46.000000000', 'files': ['doc/source/contributor/policies/bugs.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4dca0e6bd220b9643b5cfab09fbfe4e1d3c80548', 'message': 'bugs.rst: Add rfe-postponed to the list of tags\n\nChange-Id: I6e5f4539b2dfd82f2af336da02f07324af8cec02\n'}]",0,527300,4dca0e6bd220b9643b5cfab09fbfe4e1d3c80548,10,4,1,6854,,,0,"bugs.rst: Add rfe-postponed to the list of tags

Change-Id: I6e5f4539b2dfd82f2af336da02f07324af8cec02
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/527300/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/policies/bugs.rst'],1,4dca0e6bd220b9643b5cfab09fbfe4e1d3c80548,rfe,| rfe-postponed_ | Postponed feature enhancements | Drivers Team | +-------------------------------+-----------------------------------------+----------------------+.. _rfe-postponed: RFE-Postponed +++++++++++++ * `RFE-Postponed - All bugs <https://bugs.launchpad.net/neutron/+bugs?field.tag=rfe-postponed>`_ * `RFE-Postponed - In progress <https://bugs.launchpad.net/neutron/+bugs?field.status%3Alist=INPROGRESS&field.tag=rfe-postponed>`_ ,,10,0
openstack%2Fmonasca-events-api~master~Ica021c2913cb4866b10b8014333e36df9d7dfc5d,openstack/monasca-events-api,master,Ica021c2913cb4866b10b8014333e36df9d7dfc5d,Zuul: add file extension to playbook path,MERGED,2017-11-29 00:32:03.000000000,2017-12-18 07:11:55.000000000,2017-12-18 07:11:55.000000000,"[{'_account_id': 236}, {'_account_id': 2419}, {'_account_id': 6547}, {'_account_id': 7052}, {'_account_id': 8126}, {'_account_id': 11809}, {'_account_id': 12512}, {'_account_id': 14123}, {'_account_id': 14273}, {'_account_id': 14517}, {'_account_id': 15027}, {'_account_id': 16168}, {'_account_id': 16222}, {'_account_id': 20033}, {'_account_id': 21922}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-29 00:32:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/335dd396e998c2ecf0cb695291ebcda6a60073db', 'message': 'Zuul: add file extension to playbook path\n\nZuul now supports including the file extension on the playbook path\nand omitting the extension is now deprecrated.  Update references\nto include the extension.\n\nChange-Id: Ica021c2913cb4866b10b8014333e36df9d7dfc5d\n'}, {'number': 2, 'created': '2017-11-29 00:40:55.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/9788b42685c11f35bf64148e0d86c9eb0ffeb944', 'message': 'Zuul: add file extension to playbook path\n\nZuul now supports including the file extension on the playbook path\nand omitting the extension is now deprecrated.  Update references\nto include the extension.\n\nChange-Id: Ica021c2913cb4866b10b8014333e36df9d7dfc5d\n'}]",0,523615,9788b42685c11f35bf64148e0d86c9eb0ffeb944,8,16,2,1,,,0,"Zuul: add file extension to playbook path

Zuul now supports including the file extension on the playbook path
and omitting the extension is now deprecrated.  Update references
to include the extension.

Change-Id: Ica021c2913cb4866b10b8014333e36df9d7dfc5d
",git fetch https://review.opendev.org/openstack/monasca-events-api refs/changes/15/523615/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,335dd396e998c2ecf0cb695291ebcda6a60073db,zuulv3-paths, run: playbooks/legacy/monasca-tempest-events-base/run.yaml post-run: playbooks/legacy/monasca-tempest-events-base/post.yaml - monascaevents-tempest-events-base , run: playbooks/legacy/monasca-tempest-events-base/run post-run: playbooks/legacy/monasca-tempest-events-base/post - monascaevents-tempest-events-base,3,3
openstack%2Felection~master~I1f881d3ad5d53f4d9dc76c6753dc65f904686d4c,openstack/election,master,I1f881d3ad5d53f4d9dc76c6753dc65f904686d4c,[WiP] Add a quick (manual) cache for the PTL names,ABANDONED,2017-10-10 00:18:17.000000000,2017-12-18 06:59:05.000000000,,[{'_account_id': 12898}],"[{'number': 1, 'created': '2017-10-10 00:18:17.000000000', 'files': ['openstack_election/utils.py'], 'web_link': 'https://opendev.org/openstack/election/commit/0bdb64d2d14651c092a4bf0b916b78b1ec737914', 'message': '[WiP] Add a quick (manual) cache for the PTL names\n\nChange-Id: I1f881d3ad5d53f4d9dc76c6753dc65f904686d4c\n'}]",0,510713,0bdb64d2d14651c092a4bf0b916b78b1ec737914,5,1,1,12898,,,0,"[WiP] Add a quick (manual) cache for the PTL names

Change-Id: I1f881d3ad5d53f4d9dc76c6753dc65f904686d4c
",git fetch https://review.opendev.org/openstack/election refs/changes/13/510713/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_election/utils.py'],1,0bdb64d2d14651c092a4bf0b916b78b1ec737914,queens_cache,"import sysdef update_exceptions(filepath, email, fullname): global exceptions comment = (""# Look up of %s for %s @ %s\n"" % (email, filepath, datetime.datetime.utcnow())) new_entry = ""%s: %s\n"" % (filepath, fullname) with open(""exceptions.txt"", ""a"") as f: f.write(comment) f.write(new_entry) exceptions = None print('[E] %s(%d): %s' % (url, r.status_code, r.text)) print(""Getting account data for %s from gerrit"" % (email), file=sys.stderr) # update_exceptions(filepath, email, u"" "".join(fullname))",,15,0
openstack%2Fmanila~master~I1ac39f4659975ec90df13241d7a425bf57242e29,openstack/manila,master,I1ac39f4659975ec90df13241d7a425bf57242e29,Change the condition of using max_over_subscription_ratio,ABANDONED,2016-01-22 07:58:40.000000000,2017-12-18 06:51:29.000000000,,"[{'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 12017}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 14624}, {'_account_id': 15100}, {'_account_id': 15942}, {'_account_id': 16203}, {'_account_id': 16643}, {'_account_id': 16652}, {'_account_id': 16657}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 18128}, {'_account_id': 18402}]","[{'number': 1, 'created': '2016-01-22 07:58:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7b116e59141b3690e0239a3569ef5d173037e3b1', 'message': 'Change the condition of using max_over_subscription_ratio\n\nmax_over_subscription_ratio is used when the following two\nconditions are both met:\n1. The capability of the pool contains ""thin_provision=True"";\n2. The share type contains ""capabilities:thin_provision=<is> True""\n\nChange-Id: I1ac39f4659975ec90df13241d7a425bf57242e29\nCloses-Bug: #1536936\n'}, {'number': 2, 'created': '2016-01-22 09:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ebced9960bb9c705ffd6ddd59df32eb0b020de9e', 'message': 'Change the condition of using max_over_subscription_ratio\n\nmax_over_subscription_ratio is used when the following two\nconditions are both met:\n1. The capability of the pool contains ""thin_provision=True"";\n2. The share type contains ""capabilities:thin_provision=<is> True""\n\nChange-Id: I1ac39f4659975ec90df13241d7a425bf57242e29\nCloses-Bug: #1536936\n'}, {'number': 3, 'created': '2016-01-25 07:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/83a636d6e2db0e444b660ffcba79133db1b50fa2', 'message': 'Change the condition of using max_over_subscription_ratio\n\nmax_over_subscription_ratio is used when the following two\nconditions are both met:\n1. The capability of the pool contains ""thin_provision=True"";\n2. The share type contains ""capabilities:thin_provision=<is> True""\n\nChange-Id: I1ac39f4659975ec90df13241d7a425bf57242e29\nCloses-Bug: #1536936\n'}, {'number': 4, 'created': '2016-01-25 11:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b885f11e7beaf52d27b713610c44096d5567fd0c', 'message': 'Change the condition of using max_over_subscription_ratio\n\nmax_over_subscription_ratio is used when the following two\nconditions are both met:\n1. The capability of the pool contains ""thin_provision=True"";\n2. The share type contains ""capabilities:thin_provision=<is> True""\n\nChange-Id: I1ac39f4659975ec90df13241d7a425bf57242e29\nCloses-Bug: #1536936\n'}, {'number': 5, 'created': '2016-01-28 07:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/cc119d5ffe4a48bc8d4350f201cff4071f963324', 'message': 'Change the condition of using max_over_subscription_ratio\n\nmax_over_subscription_ratio is used when the following two\nconditions are both met:\n1. The capability of the pool contains ""thin_provision=True"";\n2. The share type contains ""capabilities:thin_provision=<is> True""\n\nChange-Id: I1ac39f4659975ec90df13241d7a425bf57242e29\nCloses-Bug: #1536936\n'}, {'number': 6, 'created': '2016-01-30 07:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b3ba0cb81802e16a59f73815de81400a7fb07a8b', 'message': 'Change the condition of using max_over_subscription_ratio\n\nmax_over_subscription_ratio is used when the following two\nconditions are both met:\n1. The capability of the pool contains ""thin_provision=True"";\n2. The share type contains ""capabilities:thin_provision=<is> True""\n\nChange-Id: I1ac39f4659975ec90df13241d7a425bf57242e29\nCloses-Bug: #1536936\n'}, {'number': 7, 'created': '2016-01-30 08:29:21.000000000', 'files': ['manila/scheduler/filters/capacity.py', 'manila/tests/scheduler/filters/test_capacity.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/1314a56743aa0e5982910eb933ca6d0101350f27', 'message': 'Change the condition of using max_over_subscription_ratio\n\nmax_over_subscription_ratio is used when the following two\nconditions are both met:\n1. The capability of the pool contains ""thin_provision=True"";\n2. The share type contains ""capabilities:thin_provision=<is> True""\n\nChange-Id: I1ac39f4659975ec90df13241d7a425bf57242e29\nCloses-Bug: #1536936\n'}]",13,271172,1314a56743aa0e5982910eb933ca6d0101350f27,65,20,7,16652,,,0,"Change the condition of using max_over_subscription_ratio

max_over_subscription_ratio is used when the following two
conditions are both met:
1. The capability of the pool contains ""thin_provision=True"";
2. The share type contains ""capabilities:thin_provision=<is> True""

Change-Id: I1ac39f4659975ec90df13241d7a425bf57242e29
Closes-Bug: #1536936
",git fetch https://review.opendev.org/openstack/manila refs/changes/72/271172/4 && git format-patch -1 --stdout FETCH_HEAD,['manila/scheduler/filters/capacity.py'],1,7b116e59141b3690e0239a3569ef5d173037e3b1,bug/1536936,"import sixfrom manila.scheduler.filters import extra_specs_ops def _check_thin_in_type(self, resource_type): """"""Return True if thin_provisioning in resource_type is True."""""" extra_specs = resource_type.get('extra_specs', []) if not extra_specs: return False for key, req in six.iteritems(extra_specs): # Either not scoped format, or in capabilities scope scope = key.split(':') # Ignore scoped (such as vendor-specific) capabilities if len(scope) > 1 and scope[0] != ""capabilities"": continue # Strip off prefix if spec started with 'capabilities:' elif scope[0] == ""capabilities"": del scope[0] for index in range(len(scope)): if scope[index] == ""thin_provisioning"": return extra_specs_ops.match('True', req) return False resource_type = filter_properties.get('resource_type') share_thin = self._check_thin_in_type(resource_type) use_thin_capacity = (host_state.thin_provisioning and share_thin) if (use_thin_capacity and elif use_thin_capacity:", if (host_state.thin_provisioning and elif host_state.thin_provisioning:,31,2
openstack%2Fhorizon~master~I3cec286d01f319402dd652f2f0fe7a59e7d1cfbb,openstack/horizon,master,I3cec286d01f319402dd652f2f0fe7a59e7d1cfbb,Floating IP: Expose description field in form and tables,MERGED,2017-12-17 12:06:29.000000000,2017-12-18 06:14:18.000000000,2017-12-18 06:14:18.000000000,"[{'_account_id': 841}, {'_account_id': 22348}, {'_account_id': 23866}]","[{'number': 1, 'created': '2017-12-17 12:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/087301b7d1af9c3965d9f7aa4d04e1026ac831c6', 'message': 'Floating IP: Expose description field in form and tables\n\nThe networking API supports setting a description on floating IP addresses.\nThis patch adds a form input field to the allocation form, and a column to the\ntable that displays floating IP list.\n\nChange-Id: I3cec286d01f319402dd652f2f0fe7a59e7d1cfbb\n'}, {'number': 2, 'created': '2017-12-17 13:00:03.000000000', 'files': ['openstack_dashboard/dashboards/admin/floating_ips/tables.py', 'releasenotes/notes/floating_ip_description-f4d2df7949b9fde9.yaml', 'openstack_dashboard/api/neutron.py', 'openstack_dashboard/dashboards/project/floating_ips/tables.py', 'openstack_dashboard/dashboards/project/floating_ips/forms.py', 'openstack_dashboard/dashboards/admin/floating_ips/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d1225c606ea60b521057be5a7409b140c62cbd28', 'message': 'Floating IP: Expose description field in form and tables\n\nThe networking API supports setting a description on floating IP addresses.\nThis patch adds a form input field to the allocation form, and a column to the\ntable that displays floating IP list.\n\nCloses-Bug: #1738625\nChange-Id: I3cec286d01f319402dd652f2f0fe7a59e7d1cfbb\n'}]",4,528541,d1225c606ea60b521057be5a7409b140c62cbd28,12,3,2,23866,,,0,"Floating IP: Expose description field in form and tables

The networking API supports setting a description on floating IP addresses.
This patch adds a form input field to the allocation form, and a column to the
table that displays floating IP list.

Closes-Bug: #1738625
Change-Id: I3cec286d01f319402dd652f2f0fe7a59e7d1cfbb
",git fetch https://review.opendev.org/openstack/horizon refs/changes/41/528541/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/floating_ips/tables.py', 'openstack_dashboard/api/neutron.py', 'openstack_dashboard/dashboards/project/floating_ips/tables.py', 'openstack_dashboard/dashboards/project/floating_ips/forms.py', 'openstack_dashboard/dashboards/admin/floating_ips/forms.py']",5,087301b7d1af9c3965d9f7aa4d04e1026ac831c6,bug/1738625," description = forms.CharField(max_length=255, label=_(""Description""), required=False) if data['description']: param['description'] = data['description']",,20,3
openstack%2Fkolla-ansible~master~I58e7997630b1e99db3fd878923f09c88683a3482,openstack/kolla-ansible,master,I58e7997630b1e99db3fd878923f09c88683a3482,Support running both nova and ironic on same host.,ABANDONED,2016-11-30 10:08:51.000000000,2017-12-18 06:10:31.000000000,,"[{'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 16233}, {'_account_id': 19316}, {'_account_id': 21510}]","[{'number': 1, 'created': '2016-11-30 10:08:51.000000000', 'files': ['ansible/roles/nova/templates/nova.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/85be4949e3673aaefc00ae79dce98f998af6a7de', 'message': ""Support running both nova and ironic on same host.\n\nCurrently nova_compute won't be started if ironic is enabled.\nThe two compute containers can't run on the\nsame node. (nova_compute and nova_compute_ironic)\n\nThis is because two compute containers use same hostname\nin nova.conf.\nTo solve this problem, it will be modified host item in nova.conf\nof nova_compute_ironic.\n\nCloses-Bug: #1644137\n\nChange-Id: I58e7997630b1e99db3fd878923f09c88683a3482\nSigned-off-by: jangpro2 <jangseon.ryu@gmail.com>\n""}]",0,404706,85be4949e3673aaefc00ae79dce98f998af6a7de,10,5,1,21510,,,0,"Support running both nova and ironic on same host.

Currently nova_compute won't be started if ironic is enabled.
The two compute containers can't run on the
same node. (nova_compute and nova_compute_ironic)

This is because two compute containers use same hostname
in nova.conf.
To solve this problem, it will be modified host item in nova.conf
of nova_compute_ironic.

Closes-Bug: #1644137

Change-Id: I58e7997630b1e99db3fd878923f09c88683a3482
Signed-off-by: jangpro2 <jangseon.ryu@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/06/404706/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/nova/templates/nova.conf.j2'],1,85be4949e3673aaefc00ae79dce98f998af6a7de,bug/1644137,host = {{ ansible_hostname }}_{{ item }},,1,0
openstack%2Fironic~master~Ib327c7a141cfbca63b870027ad8e901c0f48bb2d,openstack/ironic,master,Ib327c7a141cfbca63b870027ad8e901c0f48bb2d,Use adapters for neutronclient,MERGED,2017-06-21 15:01:24.000000000,2017-12-18 05:51:38.000000000,2017-12-18 05:51:38.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6637}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 12356}, {'_account_id': 13689}, {'_account_id': 14629}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-06-21 15:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/67fecc8f54ed2ebd45f227612a81adfadac0eca8', 'message': 'Use adapters for neutronclient\n\ndeprecates some options in [neutron] section and starts to unify client\noptions loading from config\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\n'}, {'number': 2, 'created': '2017-06-21 15:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8e11c1cf56a6255810dfca9126027587acd65413', 'message': 'Use adapters for neutronclient\n\ndeprecates some options in [neutron] section and starts to unify client\noptions loading from config\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\n'}, {'number': 3, 'created': '2017-06-21 16:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/70d609e0f915ef0ace83a80c39ec21838f0140fb', 'message': 'Use adapters for neutronclient\n\ndeprecates some options in [neutron] section and starts to unify client\noptions loading from config\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\n'}, {'number': 4, 'created': '2017-06-23 16:36:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/028e1fd19eebd58b0bdb8b33c082e0636f2dc934', 'message': 'Use adapters for neutronclient\n\ndeprecates some options in [neutron] section and starts to unify client\noptions loading from config\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 5, 'created': '2017-06-29 09:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9b2171919c1e29a8939dbfebfcfc768912cc3354', 'message': 'Use adapters for neutronclient\n\ndeprecates some options in [neutron] section.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 6, 'created': '2017-06-29 12:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b0f1f295bc3e2d7cb972ca589d1503181019638b', 'message': 'Use adapters for neutronclient\n\ndeprecates some options in [neutron] section.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 7, 'created': '2017-07-31 21:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e4004f118b393c4cf403eae33b5d9e5ae4b19e51', 'message': 'Use adapters for neutronclient\n\ndeprecates some options in [neutron] section.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 8, 'created': '2017-08-01 09:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/45241c6f09f53fffb1f248e07a09404aa1a7bfaa', 'message': 'Use adapters for neutronclient\n\ndeprecates some options in [neutron] section.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 9, 'created': '2017-08-03 08:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/460e63a4f3e1b1049515024baac23adf654798a7', 'message': 'Use adapters for neutronclient\n\ndeprecates some options in [neutron] section.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 10, 'created': '2017-08-04 13:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f2f9cf949eab2fd3354e3bf562426a9af7b3d8cd', 'message': 'Use adapters for neutronclient\n\ndeprecates some options in [neutron] section.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 11, 'created': '2017-08-04 15:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c72a23ae6b3cadfb04cb9b54dc14e7ab55c738fa', 'message': 'Use adapters for neutronclient\n\ndeprecates some options in [neutron] section.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 12, 'created': '2017-08-07 10:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0f56349fe7b80cc9f2e03a0e190f5e95aae9913f', 'message': 'Use adapters for neutronclient\n\ndeprecates the followinf options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 13, 'created': '2017-08-17 18:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/cf0c9f65ed821c8582fd75277d11e92d058a4c0b', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal methods of networking interface and dhcp providers\nto accept either a full conductor task or at least a request context as\nargument. This allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 14, 'created': '2017-08-18 08:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4408a78606fc9f8c05cbf133be8373dc6a072e6a', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal methods of networking interface and dhcp providers\nto accept either a full conductor task or at least a request context as\nargument. This allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 15, 'created': '2017-08-21 11:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6d5880658ec13073861e02d0eb83b22b267637df', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as a mandatory first/second argument.\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, for now when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically, producing a warning in logs.\nIn Rocky, such backward-compatible handling will be removed.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 16, 'created': '2017-08-21 13:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/35630e5ae742878efdd7ab45b19a7ae0fda6b159', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as a mandatory first/second argument.\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, for now when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically, producing a warning in logs.\nIn Rocky, such backward-compatible handling will be removed.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 17, 'created': '2017-08-21 15:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d0c88ef1ac636047d4a6316f7bba9907b9f94ee9', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as a mandatory first/second argument.\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, for now when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically, producing a warning in logs.\nIn Rocky, such backward-compatible handling will be removed.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 18, 'created': '2017-08-23 10:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a585f89d6a1ea8b89a02b831752ca4960dc27f7b', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as a mandatory first/second argument.\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, for now when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically, producing a warning in logs.\nIn Rocky, such backward-compatible handling will be removed.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 19, 'created': '2017-08-25 13:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1e697d5a741af22e6535ef2295a8e495c7f35e20', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as a mandatory first/second argument.\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, for now when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically, producing a warning in logs.\nIn Rocky, such backward-compatible handling will be removed.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 20, 'created': '2017-08-25 18:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c1e0aefeaa30cb0d42d7494f44f7c1f862f5c01a', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as a mandatory first/second argument.\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, for now when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically, producing a warning in logs.\nIn Rocky, such backward-compatible handling will be removed.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 21, 'created': '2017-08-28 09:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b8f82f52ff7924cdb29e3fd2d181bcf3886f7c8d', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as optional keyword argument (defaults to\nNone).\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 22, 'created': '2017-09-07 17:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c74d89f36d7a640bf0cea5ae90a6c4999fe8262f', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as optional keyword argument (defaults to\nNone).\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 23, 'created': '2017-10-31 16:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1165158c2a25f7460cda0be4332098fc5432ebb6', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as optional keyword argument (defaults to\nNone).\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 24, 'created': '2017-11-06 18:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c2f95f1fbf0a9aea6f5c07dcb453031753ff45ec', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as optional keyword argument (defaults to\nNone).\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 25, 'created': '2017-11-07 12:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1cdf6f3767c2adf617dd0e30235d5a09907b4302', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as optional keyword argument (defaults to\nNone).\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 26, 'created': '2017-11-09 15:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/34765e7571d416e063e1ea13a49877bc6b59bd46', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as optional keyword argument (defaults to\nNone).\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 27, 'created': '2017-11-21 07:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/98b7eb1e960f4ffc0b8a7874557a508994a770fa', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as optional keyword argument (defaults to\nNone).\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 28, 'created': '2017-11-23 13:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/67e6b0b0bf8bd8ff97df59fffad6fbfdab430e47', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as optional keyword argument (defaults to\nNone).\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 29, 'created': '2017-12-04 15:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/78711dc242bd5db76b61caf327bf481fd182bf21', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as optional keyword argument (defaults to\nNone).\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 30, 'created': '2017-12-07 08:02:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3d5cd95670a4d4e76cc2e2b61ca671138bb78c74', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as optional keyword argument (defaults to\nNone).\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 31, 'created': '2017-12-11 17:59:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ed0c7f0fa5415892c582f6ec62ea69c62988f934', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as optional keyword argument (defaults to\nNone).\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 32, 'created': '2017-12-13 15:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/36d749a21e473677ef34d50672e5d8f2626534b4', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as optional keyword argument (defaults to\nNone).\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}, {'number': 33, 'created': '2017-12-14 11:43:28.000000000', 'files': ['ironic/dhcp/none.py', 'ironic/tests/unit/drivers/modules/network/test_common.py', 'ironic/tests/unit/common/test_neutron.py', 'ironic/conf/neutron.py', 'ironic/tests/unit/drivers/modules/network/test_flat.py', 'ironic/drivers/modules/network/neutron.py', 'ironic/tests/unit/drivers/modules/network/test_neutron.py', 'releasenotes/notes/deprecated-neutron-opts-2e1d9e65f00301d3.yaml', 'releasenotes/notes/keystoneauth-config-1baa45a0a2dd93b4.yaml', 'ironic/common/keystone.py', 'ironic/tests/unit/common/test_keystone.py', 'devstack/lib/ironic', 'ironic/dhcp/base.py', 'etc/ironic/ironic.conf.sample', 'ironic/dhcp/neutron.py', 'ironic/drivers/modules/network/common.py', 'ironic/common/neutron.py', 'ironic/drivers/modules/network/flat.py', 'ironic/tests/unit/dhcp/test_neutron.py', 'doc/source/install/include/configure-ironic-conductor.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4d43262955f8882cdeee2a042e852eaa8396178b', 'message': 'Use adapters for neutronclient\n\ndeprecates the following options in [neutron] section:\n- url\n- url_timeout\n- auth_strategy\n\nChanges some internal networking-related functions/methods\nto accept a request context as optional keyword argument (defaults to\nNone).\nThis allows to pass a global request id to neutron client and\nin future will simplify creating a user auth plugin from request\ncontext.\nFor backward compatibility, when calling those functions/methods\nwithout a request context, a dummy request context will be generated\nautomatically.\n\nChange-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d\nPartial-Bug: #1699547\n'}]",72,476170,4d43262955f8882cdeee2a042e852eaa8396178b,219,15,33,9542,,,0,"Use adapters for neutronclient

deprecates the following options in [neutron] section:
- url
- url_timeout
- auth_strategy

Changes some internal networking-related functions/methods
to accept a request context as optional keyword argument (defaults to
None).
This allows to pass a global request id to neutron client and
in future will simplify creating a user auth plugin from request
context.
For backward compatibility, when calling those functions/methods
without a request context, a dummy request context will be generated
automatically.

Change-Id: Ib327c7a141cfbca63b870027ad8e901c0f48bb2d
Partial-Bug: #1699547
",git fetch https://review.opendev.org/openstack/ironic refs/changes/70/476170/25 && git format-patch -1 --stdout FETCH_HEAD,"['etc/ironic/ironic.conf.sample', 'ironic/tests/unit/common/test_neutron.py', 'ironic/conf/neutron.py', 'ironic/common/neutron.py', 'releasenotes/notes/deprecated-neutron-opts-2e1d9e65f00301d3.yaml']",5,67fecc8f54ed2ebd45f227612a81adfadac0eca8,bug/1699547,"--- deprecations: - | Configuration option ``[neutron]url`` is deprecated and will be ignored in the Queens release. Instead, use ``[neutron]endpoint_override`` configuration option to set specific neutron api address when automatic discovery of neutron API endpoint from keystone catalog is not desired. This new option has no default value (``None``) and must be set explicitly. - | Configuration option ``[neutron]url_timeout`` is deprecated and will be ignored in the Queens release. Instead, use ``[neutron]timeout`` configuration option. This new option has no default value (``None``) and must be set explicitly. ",,169,93
openstack%2Fheat~master~I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93,openstack/heat,master,I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93,ForceDelete Instance,MERGED,2017-04-08 02:39:18.000000000,2017-12-18 05:46:11.000000000,2017-12-18 05:46:11.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 12404}, {'_account_id': 13499}, {'_account_id': 17842}, {'_account_id': 22348}, {'_account_id': 23037}]","[{'number': 1, 'created': '2017-04-08 02:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/473f3bd2c48d65c4664e409a2909cc9b89ee1191', 'message': ""ForceDelete Instance\n\nIf nova config 'reclaim_instance_interval', a instance will be\nsoft-deleted, that will cause a error, that volumes attached with the\ninstance will cann't be deleted for its 'in-use' status.\nForce-delete instances, even if with that config, the instance will be\ndelete, and that volumes would be deleted.\n\nChange-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93\n""}, {'number': 2, 'created': '2017-04-12 05:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b709274fe543514ec69c49e382d3ac5c849d7119', 'message': ""ForceDelete Instance\n\nIf nova config 'reclaim_instance_interval', a instance will be\nsoft-deleted, that will cause a error, that volumes attached with the\ninstance will cann't be deleted for its 'in-use' status.\nNow add a 'force_delete' property for resource 'OS::Nova::Server'.When the\nstack was deleted, the instances would be force-deleted if the instances'\nproperty 'force_delete' is True. So, the volumes which attach the instances\nwould be deleted success.\n\nChange-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93\n""}, {'number': 3, 'created': '2017-04-13 11:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f9d800cb7d4b5f4522f48d6f477e221c3ff0c1d6', 'message': ""ForceDelete Instance\n\nIf nova config 'reclaim_instance_interval', a instance will be\nsoft-deleted, that will cause a error, that volumes attached with the\ninstance will cann't be deleted for its 'in-use' status.\nNow add a 'force_delete' property for resource 'OS::Nova::Server'.When the\nstack was deleted, the instances would be force-deleted if the instances'\nproperty 'force_delete' is True. So, the volumes which attach the instances\nwould be deleted success.\n\nCloses-Bug: #1564265\nChange-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93\n""}, {'number': 4, 'created': '2017-04-14 02:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/10aa7c6ec1676627a5f72ca5b769dab3dbfb2649', 'message': ""ForceDelete Instance\n\nIf nova config 'reclaim_instance_interval', a instance will be\nsoft-deleted, that will cause a error, that volumes attached with the\ninstance will cann't be deleted for its 'in-use' status.\nNow add a 'force_delete' property for resource 'OS::Nova::Server'.When the\nstack was deleted, the instances would be force-deleted if the instances'\nproperty 'force_delete' is True. So, the volumes which attach the instances\nwould be deleted success.\n\nCloses-Bug: #1564265\nChange-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93\n""}, {'number': 5, 'created': '2017-04-17 10:51:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7f7805a313b65b3210b109dc7bd380004c64ab76', 'message': ""ForceDelete Instance\n\nIf nova config 'reclaim_instance_interval', a instance will be\nsoft-deleted, that will cause a error, that volumes or other attached with the\ninstance will cann't be deleted for its 'in-use' status.\nNow add a 'force_delete' property for resource 'OS::Nova::Server'.When the\nstack was deleted, the instances would be force-deleted if the instances'\nproperty 'force_delete' is True. So, the volumes which attach the instances\nwould be deleted success.\n\nCloses-Bug: #1564265\nChange-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93\n""}, {'number': 6, 'created': '2017-05-03 06:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6631b10392ddeda1f4e3e24b038518289df96df1', 'message': ""ForceDelete Instance\n\nIf nova config 'reclaim_instance_interval', a instance will be\nsoft-deleted, that will cause a error, that volumes or other attached with the\ninstance will cann't be deleted for its 'in-use' status.\nNow add a 'force_delete' property for resource 'OS::Nova::Server'.When the\nstack was deleted, the instances would be force-deleted if the instances'\nproperty 'force_delete' is True. So, the volumes which attach the instances\nwould be deleted success.\n\nCloses-Bug: #1564265\nChange-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93\n""}, {'number': 7, 'created': '2017-05-12 01:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/452857e4be193da7e98ce0f651e024977bcd9c13', 'message': ""ForceDelete Instance\n\nIf nova config 'reclaim_instance_interval', a instance will be\nsoft-deleted, that will cause a error, that volumes or other attached with the\ninstance will cann't be deleted for its 'in-use' status.\nNow add a 'force_delete' property for resource 'OS::Nova::Server'.When the\nstack was deleted, the instances would be force-deleted if the instances'\nproperty 'force_delete' is True. So, the volumes which attach the instances\nwould be deleted success.\n\nCloses-Bug: #1564265\nChange-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93\n""}, {'number': 8, 'created': '2017-09-08 08:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/90878ab7c93a0042544cdaf85e6cd5d8459f252e', 'message': ""ForceDelete Instance\n\nIf nova config 'reclaim_instance_interval', a instance will be\nsoft-deleted, that will cause a error, that volumes or other attached with the\ninstance will cann't be deleted for its 'in-use' status.\nNow force_delete the instance, the error no longer occurs.\n\nCloses-Bug: #1564265\nChange-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93\n""}, {'number': 9, 'created': '2017-09-08 11:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a2f7bc3a3d7429a4b76663b14178adaca56afcb5', 'message': ""ForceDelete Instance\n\nIf nova config 'reclaim_instance_interval', a instance will be\nsoft-deleted, that will cause a error, that volumes or other attached with the\ninstance will cann't be deleted for its 'in-use' status.\nNow force_delete the instance, the error no longer occurs.\n\nCloses-Bug: #1564265\nChange-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93\n""}, {'number': 10, 'created': '2017-11-23 06:44:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4c4738d99d230cb8c80f2ee481e299751b624292', 'message': ""ForceDelete Instance\n\nIf nova config 'reclaim_instance_interval', a instance will be\nsoft-deleted, that will cause a error, that volumes or other attached with the\ninstance will cann't be deleted for its 'in-use' status.\nNow force_delete the instance, the error no longer occurs.\n\nCloses-Bug: #1564265\nChange-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93\n""}, {'number': 11, 'created': '2017-11-23 07:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a025766d17b7d49e760b4eeee30d68863e5ea5c2', 'message': ""ForceDelete Instance\n\nIf nova config 'reclaim_instance_interval', a instance will be\nsoft-deleted, that will cause a error, that volumes or other attached with the\ninstance will cann't be deleted for its 'in-use' status.\nNow force_delete the instance, the error no longer occurs.\n\nCloses-Bug: #1564265\nChange-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93\n""}, {'number': 12, 'created': '2017-11-23 11:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1601d3fdf83e1aa0571f76db877b4dd4bc1d8e45', 'message': ""ForceDelete Instance\n\nIf nova config 'reclaim_instance_interval', a instance will be\nsoft-deleted, that will cause a error, that volumes or other attached with the\ninstance will cann't be deleted for its 'in-use' status.\nNow force_delete the instance, the error no longer occurs.\n\nCloses-Bug: #1564265\nChange-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93\n""}, {'number': 13, 'created': '2017-11-24 01:17:17.000000000', 'files': ['releasenotes/notes/force-delete-nova-instance-6ed5d7fbd5b6f5fe.yaml', 'heat/engine/clients/os/nova.py', 'heat/tests/openstack/nova/fakes.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/fedba4dddf48cb5136ec56e0e88b8b871c3a67f1', 'message': ""ForceDelete Instance\n\nIf nova config 'reclaim_instance_interval', a instance will be\nsoft-deleted, that will cause a error, that volumes or other attached with the\ninstance will cann't be deleted for its 'in-use' status.\nNow force_delete the instance, the error no longer occurs.\n\nCloses-Bug: #1564265\nChange-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93\n""}]",15,454941,fedba4dddf48cb5136ec56e0e88b8b871c3a67f1,66,9,13,17842,,,0,"ForceDelete Instance

If nova config 'reclaim_instance_interval', a instance will be
soft-deleted, that will cause a error, that volumes or other attached with the
instance will cann't be deleted for its 'in-use' status.
Now force_delete the instance, the error no longer occurs.

Closes-Bug: #1564265
Change-Id: I4d1dd33b23d5882481f4d2c06107c3fb8c08cb93
",git fetch https://review.opendev.org/openstack/heat refs/changes/41/454941/10 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/nova/server.py', 'heat/tests/openstack/nova/test_server.py', 'heat/tests/openstack/nova/fakes.py']",3,473f3bd2c48d65c4664e409a2909cc9b89ee1191,bug/1564265, elif action == 'forceDelete': assert body is not None ,,8,6
openstack%2Fheat~master~I161b7cc1c4824f6aa4a4667bf2d909a2ead81cb4,openstack/heat,master,I161b7cc1c4824f6aa4a4667bf2d909a2ead81cb4,Enable to specify network for Trove Cluster,MERGED,2017-09-20 07:42:36.000000000,2017-12-18 05:41:41.000000000,2017-12-18 05:41:41.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 8289}, {'_account_id': 8686}, {'_account_id': 8833}, {'_account_id': 8871}, {'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-09-20 07:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6cf3f5cb04e84ea7ae9d324707bd63e631a59020', 'message': 'Enable to specify network for Trove Cluster\n\nwe should enable heat to specify network for trove cluster\nafter [1] merged\n\n[1] https://review.openstack.org/#/c/179443/\n\nChange-Id: I161b7cc1c4824f6aa4a4667bf2d909a2ead81cb4\n'}, {'number': 2, 'created': '2017-09-25 07:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d2d310248a9d002e18bf66c3b63eb12e7bce9e48', 'message': 'Enable to specify network for Trove Cluster\n\nwe should enable heat to specify network for trove cluster\nafter [1] merged\n\n[1] https://review.openstack.org/#/c/179443/\n\nChange-Id: I161b7cc1c4824f6aa4a4667bf2d909a2ead81cb4\n'}, {'number': 3, 'created': '2017-09-25 12:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/24d1376bac3a9854ad3eb8c16e0304a1698f6276', 'message': 'Enable to specify network for Trove Cluster\n\nwe should enable heat to specify network for trove cluster\nafter [1] merged\n\n[1] https://review.openstack.org/#/c/179443/\n\nChange-Id: I161b7cc1c4824f6aa4a4667bf2d909a2ead81cb4\n'}, {'number': 4, 'created': '2017-09-26 02:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7b29dfd71145414586c92b9ba82a0a765ab70f87', 'message': 'Enable to specify network for Trove Cluster\n\nwe should enable heat to specify network for trove cluster\nafter [1] merged\n\n[1] https://review.openstack.org/#/c/179443/\n\nChange-Id: I161b7cc1c4824f6aa4a4667bf2d909a2ead81cb4\n'}, {'number': 5, 'created': '2017-09-26 07:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7679dd22bcca67d67c87b620e44b9a53dc8b27a6', 'message': 'Enable to specify network for Trove Cluster\n\nwe should enable heat to specify network for trove cluster\nafter [1] merged\n\n[1] https://review.openstack.org/#/c/179443/\n\nChange-Id: I161b7cc1c4824f6aa4a4667bf2d909a2ead81cb4\n'}, {'number': 6, 'created': '2017-09-27 12:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7574c202b5604ae5a5b46cc5c4e7d63dfaf92d30', 'message': 'Enable to specify network for Trove Cluster\n\nwe should enable heat to specify network for trove cluster\nafter [1] merged\n\n[1] https://review.openstack.org/#/c/179443/\n\nChange-Id: I161b7cc1c4824f6aa4a4667bf2d909a2ead81cb4\n'}, {'number': 7, 'created': '2017-09-28 10:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d7bb770ff8eb08d4be04bccc94b84e04213514a5', 'message': 'Enable to specify network for Trove Cluster\n\nwe should enable heat to specify network for trove cluster\nafter [1] merged\n\n[1] https://review.openstack.org/#/c/179443/\n\nChange-Id: I161b7cc1c4824f6aa4a4667bf2d909a2ead81cb4\n'}, {'number': 8, 'created': '2017-10-17 12:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4201251f59565f3bcc8d2ab9323e9864ae330227', 'message': 'Enable to specify network for Trove Cluster\n\nwe should enable heat to specify network for trove cluster\nafter [1] merged\n\n[1] https://review.openstack.org/#/c/179443/\n\nChange-Id: I161b7cc1c4824f6aa4a4667bf2d909a2ead81cb4\n'}, {'number': 9, 'created': '2017-12-15 11:52:49.000000000', 'files': ['heat/tests/test_translation_rule.py', 'releasenotes/notes/set-networks-for-trove-cluster-b997a049eedbad17.yaml', 'heat/tests/openstack/trove/test_cluster.py', 'heat/engine/resources/openstack/trove/cluster.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/2441a02c1c8538ab942b75c97818acf51aaf22e3', 'message': 'Enable to specify network for Trove Cluster\n\nwe should enable heat to specify network for trove cluster\nafter [1] merged\n\n[1] https://review.openstack.org/#/c/179443/\n\nChange-Id: I161b7cc1c4824f6aa4a4667bf2d909a2ead81cb4\n'}]",35,505521,2441a02c1c8538ab942b75c97818acf51aaf22e3,61,8,9,8686,,,0,"Enable to specify network for Trove Cluster

we should enable heat to specify network for trove cluster
after [1] merged

[1] https://review.openstack.org/#/c/179443/

Change-Id: I161b7cc1c4824f6aa4a4667bf2d909a2ead81cb4
",git fetch https://review.opendev.org/openstack/heat refs/changes/21/505521/8 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/openstack/trove/cluster.py'],1,6cf3f5cb04e84ea7ae9d324707bd63e631a59020,trove_cluster," NAME, DATASTORE_TYPE, DATASTORE_VERSION, INSTANCES, NETWORK, 'name', 'datastore_type', 'datastore_version', 'instances', 'network', ), NETWORK: properties.Schema( properties.Schema.STRING, _(""Name or ID of network.""), constraints=[ constraints.Length(max=255) ] net_id = None if self.properties[self.NETWORK] is not None: net_id = self.client_plugin('neutron').\ find_resourceid_by_name_or_id('network', self.properties[self.NETWORK]) instance_dict = { 'volume': {'size': instance[self.VOLUME_SIZE]}, } if net_id: instance_dict[""nics""] = [{""net-id"": net_id}] instances.append(instance_dict)"," NAME, DATASTORE_TYPE, DATASTORE_VERSION, INSTANCES, 'name', 'datastore_type', 'datastore_version', 'instances', instances.append({ 'volume': {'size': instance[self.VOLUME_SIZE]} })",20,5
openstack%2Fmurano-dashboard~master~Iafd23644559aecacf6ac436f8790a0782fbd731c,openstack/murano-dashboard,master,Iafd23644559aecacf6ac436f8790a0782fbd731c,Imported Translations from Zanata,MERGED,2017-12-16 07:03:37.000000000,2017-12-18 05:37:25.000000000,2017-12-18 05:37:25.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2017-12-16 07:03:37.000000000', 'files': ['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ru/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/zh_CN/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/1f6915799befafe9d3840b5b83e28b103f763d6f', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Iafd23644559aecacf6ac436f8790a0782fbd731c\n'}]",0,528447,1f6915799befafe9d3840b5b83e28b103f763d6f,7,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Iafd23644559aecacf6ac436f8790a0782fbd731c
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/47/528447/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ru/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/zh_CN/LC_MESSAGES/releasenotes.po']",7,1f6915799befafe9d3840b5b83e28b103f763d6f,zanata/translations,"""POT-Creation-Date: 2017-12-16 05:23+0000\n""","""POT-Creation-Date: 2017-12-14 15:37+0000\n""msgid ""2.0.0.0b2"" msgstr ""2.0.0.0b2"" msgid ""2.0.0.0b3"" msgstr ""2.0.0.0b3"" msgid ""2.0.0.0rc1"" msgstr ""2.0.0.0rc1"" msgid ""3.0.0.0b1"" msgstr ""3.0.0.0b1"" msgid ""3.0.0.0b2"" msgstr ""3.0.0.0b2"" msgid ""3.0.0.0b3"" msgstr ""3.0.0.0b3"" msgid ""3.0.0.0rc1"" msgstr ""3.0.0.0rc1"" msgid """" ""cve-2016-4972 has been addressed. In several places Murano used loaders "" ""inherited directly from yaml.Loader when parsing MuranoPL and UI files from "" ""packages. This is unsafe, because this loader is capable of creating custom "" ""python objects from specifically constructed yaml files. With this change "" ""all yaml loading operations are done using safe loaders instead."" msgstr """" ""cve-2016-4972 MuranoPLUI"" ""Muranoyaml.Loader. "" ""yamlpythonyaml"" """" ",11,195
openstack%2Frally~master~Ic94b3b6d07604fdb849180cca8f07f73d0f6805c,openstack/rally,master,Ic94b3b6d07604fdb849180cca8f07f73d0f6805c,Add Integrated Scenario for simulating real-life load,NEW,2015-10-01 07:26:18.000000000,2017-12-18 05:32:00.000000000,,"[{'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-10-01 07:26:18.000000000', 'files': ['rally-jobs/rally-integrated.yaml', 'rally/plugins/openstack/scenarios/integrated/__init__.py', 'samples/tasks/scenarios/integrated/nova-cinder-neutron.yaml', 'samples/tasks/scenarios/integrated/nova-cinder-neutron.json', 'tests/unit/plugins/openstack/scenarios/integrated/__init__.py', 'rally/plugins/openstack/scenarios/integrated/integrated.py', 'tests/unit/plugins/openstack/scenarios/integrated/test_integrated.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/3e2265e1becbe2778ee387ea6c1b681b72739c6f', 'message': 'Add Integrated Scenario for simulating real-life load\n\nThis is an integrated scenario which runs benchmark against\nmultiple services simultaneously, to simulate real life load.\nAdded a basic scenario which benchmarks nova, cinder and neutron\nsimultaneously.\n\nChange-Id: Ic94b3b6d07604fdb849180cca8f07f73d0f6805c\n'}]",2,229759,3e2265e1becbe2778ee387ea6c1b681b72739c6f,6,2,1,12689,,,0,"Add Integrated Scenario for simulating real-life load

This is an integrated scenario which runs benchmark against
multiple services simultaneously, to simulate real life load.
Added a basic scenario which benchmarks nova, cinder and neutron
simultaneously.

Change-Id: Ic94b3b6d07604fdb849180cca8f07f73d0f6805c
",git fetch https://review.opendev.org/openstack/rally refs/changes/59/229759/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally-jobs/rally-integrated.yaml', 'rally/plugins/openstack/scenarios/integrated/__init__.py', 'samples/tasks/scenarios/integrated/nova-cinder-neutron.yaml', 'samples/tasks/scenarios/integrated/nova-cinder-neutron.json', 'tests/unit/plugins/openstack/scenarios/integrated/__init__.py', 'rally/plugins/openstack/scenarios/integrated/integrated.py', 'tests/unit/plugins/openstack/scenarios/integrated/test_integrated.py']",7,3e2265e1becbe2778ee387ea6c1b681b72739c6f,,"# Copyright 2013: Mirantis Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from rally.plugins.openstack.scenarios.integrated import integrated from tests.unit import test NOVA_SERVERS_MODULE = ""rally.plugins.openstack.scenarios.nova.servers"" class IntegratedScenarioTestCase(test.ScenarioTestCase): def __init__(self): self.services = [] self.volume_size = 1 self.image = ""image"" self.flavor = ""0"" self.scenario = integrated.IntegratedScenario(self.context) self.server_mock = mock.Mock() def test_nova_cinder_neutron_scenario_basic(self): self.scenario._boot_server = mock.Mock(return_value=self.server_mock) self.scenario._delete_server = mock.Mock() self.scenario.nova_cinder_neutron_scenario( self.image, self.flavor, self.volume_size, self.services) self.scenario._boot_server.assert_called_once_with( self.image, self.flavor) self.scenario._delete_server.assert_called_once_with( self.server_mock) @mock.patch(NOVA_SERVERS_MODULE + "".network_wrapper.wrap"") def test_nova_cinder_neutron_scenario_neutron_only(self, mock_wrap): self.services = [""neutron""] self.scenario._boot_server = mock.Mock(return_value=self.server_mock) self.scenario._associate_floating_ip = mock.Mock() self.scenario._disassociate_floating_ip = mock.Mock() self.scenario._delete_server = mock.Mock() self.scenario.nova_cinder_neutron_scenario( self.image, self.flavor, self.volume_size, self.services) self.scenario._boot_server.assert_called_once_with( self.image, self.flavor) net_wrap = mock_wrap.return_value net_wrap.create_floating_ip.assert_called_once_with( tenant_id=self.server_mock.tenant_id) self.scenario._associate_floating_ip.assert_called_once_with( self.server_mock, net_wrap.create_floating_ip.return_value[""ip""]) self.scenario._disassociate_floating_ip.assert_called_once_with( self.server_mock, net_wrap.create_floating_ip.return_value[""ip""]) self.scenario._delete_server.assert_called_once_with( self.server_mock) def test_nova_cinder_neutron_scenario_cinder_only(self): self.services = [""cinder""] fake_volume_args = {""fake_arg"": ""fake_value""} self.scenario._boot_server = mock.Mock(return_value=self.server_mock) volume_mock = mock.Mock() self.scenario._create_volume = mock.Mock(return_value=volume_mock) self.scenario._attach_volume = mock.Mock() self.scenario._detach_volume = mock.Mock() self.scenario._delete_volume = mock.Mock() self.scenario._delete_server = mock.Mock() self.scenario.nova_cinder_neutron_scenario( self.image, self.flavor, self.services) self.scenario._boot_server.assert_called_once_with( self.image, self.flavor) self.scenario._create_volume.assert_called_once_with( self.volume_size, fake_volume_args) self.scenario._attach_volume.assert_called_once_with( self.server_mock, volume_mock) self.scenario._detach_volume.assert_called_once_with( self.server_mock, volume_mock) self.scenario._delete_volume.assert_called_once_with(volume_mock) self.scenario._delete_server.assert_called_once_with( self.server_mock) ",,233,0
openstack%2Frally~master~If1de74833e3d80454288df22b31db24c64349479,openstack/rally,master,If1de74833e3d80454288df22b31db24c64349479,New meter statistics scenarios,NEW,2015-06-25 12:14:11.000000000,2017-12-18 05:31:53.000000000,,"[{'_account_id': 12395}, {'_account_id': 14347}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-06-25 12:14:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cbf930eaec8713a012ece094c08e9958387c96b5', 'message': 'New meter statistics scenarios\n\nNow we have only one scenario for meter statistics.\nIn this scenario created meter, for this meter created\none sample and got statistics for this meter without\nperiod, groupby and aggregates.\n\nIn this patch created two meter statistics scenarios.\n\nFirst scenario allows to create one meter, many\ndifferent samples for this meter and get statistics for\nthis meter with period, groupby and aggregates options.\n\nSecond scenario allows to create one meter, many\ndifferent samples for this meter, get statistics for\nthis meter with group by resource, aggregates and without\nperiod and check results of standart aggregates.\n\nChange-Id: If1de74833e3d80454288df22b31db24c64349479\n'}, {'number': 2, 'created': '2015-06-26 12:00:58.000000000', 'files': ['rally/plugins/openstack/scenarios/ceilometer/stats.py', 'rally/plugins/openstack/scenarios/ceilometer/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/840b9feae0ad9145d4fcc5200806358b5fb92b17', 'message': 'New meter statistics scenarios\n\nNow we have only one scenario for meter statistics.\nIn this scenario created meter, for this meter created\none sample and got statistics for this meter without\nperiod, groupby and aggregates.\n\nIn this patch created two meter statistics scenarios.\n\nFirst scenario allows to create one meter, many\ndifferent samples for this meter and get statistics for\nthis meter with period, groupby and aggregates options.\n\nSecond scenario allows to create one meter, many\ndifferent samples for this meter, get statistics for\nthis meter with group by resource, aggregates and without\nperiod and check results of standart aggregates.\n\nChange-Id: If1de74833e3d80454288df22b31db24c64349479\n'}]",8,195548,840b9feae0ad9145d4fcc5200806358b5fb92b17,12,3,2,14347,,,0,"New meter statistics scenarios

Now we have only one scenario for meter statistics.
In this scenario created meter, for this meter created
one sample and got statistics for this meter without
period, groupby and aggregates.

In this patch created two meter statistics scenarios.

First scenario allows to create one meter, many
different samples for this meter and get statistics for
this meter with period, groupby and aggregates options.

Second scenario allows to create one meter, many
different samples for this meter, get statistics for
this meter with group by resource, aggregates and without
period and check results of standart aggregates.

Change-Id: If1de74833e3d80454288df22b31db24c64349479
",git fetch https://review.opendev.org/openstack/rally refs/changes/48/195548/2 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/scenarios/ceilometer/stats.py', 'rally/plugins/openstack/scenarios/ceilometer/utils.py']",2,cbf930eaec8713a012ece094c08e9958387c96b5,test_stats,"import copy import datetime import six from six import moves from rally import exceptions from oslo_utils import timeutils STANDARD_AGGREGATES = {""avg"", ""sum"", ""min"", ""max"", ""count""} ISO8601_TIME_FORMAT = '%Y-%m-%dT%H:%M:%S' source=None, timestamp=None, resource_metadata=None, interval=None): :param interval: interval between sample timestamps if not timestamp and interval: raise exceptions.InvalidArgumentsException( message=""Timestamp is required if intervall is added."" ) samples = [] for i in moves.xrange(count): new_sample = copy.deepcopy(sample) if interval: date_timestamp = timeutils.parse_strtime( new_sample[""timestamp""], ISO8601_TIME_FORMAT) date_timestamp += datetime.timedelta( seconds=i * interval) new_sample[""timestamp""] = timeutils.strtime( date_timestamp, ISO8601_TIME_FORMAT) samples.append(new_sample) def _prepare_samples(self, user_id, samples, meter_name=None): """"""Prepare samples for creating. Prepare and return samples for meter. Setup resource id to samples settings. :param user_id: specifies user id :param samples: specifies samples :param meter_name: specifies meter name :return: array of samples used to create samples """""" samples_to_create = [] for sample in samples: if 'user_id' in sample: raise exceptions.InvalidArgumentsException( 'Field user_id in sample should not be set.') sample['user_id'] = user_id if meter_name: if ('counter_name' in sample and meter_name != sample['counter_name']): raise exceptions.InvalidArgumentsException( 'Counter_name in sample and meter_name must be equal.') sample['counter_name'] = meter_name prepared_samples = self._make_samples(**sample) sample[""resource_id""] = prepared_samples[0][""resource_id""] samples_to_create.extend(prepared_samples) return samples_to_create def _group_stats_by_resource_id(self, stats): """"""Group statistics by resource id. :param stats: array of statistics :return: array of grouped statistics by id """""" grouped_stats = {} for statistic in stats: grouped_stats[statistic.groupby[""resource_id""]] = statistic return grouped_stats def _check_standard_aggregates(self, grouped_stats, samples, aggregates): """"""Check that statistics are correct. :param grouped_stats: array of grouped statistics by resource id from response :param samples: array of settings for samples :param aggregates: array of standard aggregates :return: True if statistics are correct and False if not """""" aggregates_values = {} for sample in samples: aggregates_values.setdefault(sample[""resource_id""], {}) resource_aggregation = aggregates_values[sample[""resource_id""]] for aggregate in STANDARD_AGGREGATES: if aggregate == ""count"": resource_aggregation.setdefault(""count"", 0) resource_aggregation[""count""] += sample[""count""] if aggregate == ""sum"": resource_aggregation.setdefault(""sum"", 0) resource_aggregation[""sum""] += ( sample[""count""] * sample[""counter_volume""]) if aggregate == ""max"": resource_aggregation.setdefault( ""max"", sample[""counter_volume""]) resource_aggregation[""max""] = max( resource_aggregation[""max""], sample[""counter_volume""]) if aggregate == ""min"": resource_aggregation.setdefault( ""min"", sample[""counter_volume""]) resource_aggregation[""min""] = min( resource_aggregation[""min""], sample[""counter_volume""]) for resource in six.itervalues(aggregates_values): resource[""avg""] = float(resource[""sum""]) / float(resource[""count""]) for resource, stat in six.iteritems(grouped_stats): for aggregate in aggregates: if aggregate[""func""] in STANDARD_AGGREGATES: if (stat.aggregate[aggregate[""func""]] != aggregates_values[resource][aggregate[""func""]]): return False return True def _get_stats(self, meter_name, q=None, period=None, groupby=None, aggregates=None): return self.clients(""ceilometer"").statistics.list(meter_name, q, period, groupby, aggregates)"," source=None, timestamp=None, resource_metadata=None): samples = [sample] * count def _get_stats(self, meter_name): return self.clients(""ceilometer"").statistics.list(meter_name)",183,4
openstack%2Frally~master~I9b864ca3431c1882ad0cfc384f1bcf59711240cb,openstack/rally,master,I9b864ca3431c1882ad0cfc384f1bcf59711240cb,Improve role context,NEW,2015-10-10 10:17:06.000000000,2017-12-18 05:31:28.000000000,,[{'_account_id': 14817}],"[{'number': 1, 'created': '2015-10-10 10:17:06.000000000', 'files': ['rally/plugins/openstack/wrappers/keystone.py', 'tests/unit/plugins/openstack/context/keystone/test_roles.py', 'tests/unit/plugins/openstack/wrappers/test_keystone.py', 'tests/unit/fakes.py', 'rally/plugins/openstack/context/keystone/roles.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/6b164492a9287c060467ad21d7649631b0a1d6c0', 'message': 'Improve role context\n\nThis patch improve role context on:\n* accept user name and role name in keystone wrapper (keystone client\n  could handle this. [0][1])\n* add get_role method on keystone wrapper\n* rename add_role to grant_role\n\n[0] https://github.com/openstack/python-keystoneclient/blob/master/keystoneclient/v3/roles.py#L46-L61\n[1] https://github.com/openstack/python-keystoneclient/blob/master/keystoneclient/v2_0/roles.py#L64-L72\n\nChange-Id: I9b864ca3431c1882ad0cfc384f1bcf59711240cb\n'}]",0,233360,6b164492a9287c060467ad21d7649631b0a1d6c0,4,1,1,6835,,,0,"Improve role context

This patch improve role context on:
* accept user name and role name in keystone wrapper (keystone client
  could handle this. [0][1])
* add get_role method on keystone wrapper
* rename add_role to grant_role

[0] https://github.com/openstack/python-keystoneclient/blob/master/keystoneclient/v3/roles.py#L46-L61
[1] https://github.com/openstack/python-keystoneclient/blob/master/keystoneclient/v2_0/roles.py#L64-L72

Change-Id: I9b864ca3431c1882ad0cfc384f1bcf59711240cb
",git fetch https://review.opendev.org/openstack/rally refs/changes/60/233360/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/wrappers/keystone.py', 'tests/unit/plugins/openstack/context/keystone/test_roles.py', 'tests/unit/plugins/openstack/wrappers/test_keystone.py', 'tests/unit/fakes.py', 'rally/plugins/openstack/context/keystone/roles.py']",5,6b164492a9287c060467ad21d7649631b0a1d6c0,role_context," def _grant_role(self, admin_endpoint, context_role): role = client.get_role(context_role) client.grant_role(user=user[""id""], role=context_role, project=user[""tenant_id""]) return {""id"": role.id, ""name"": role.name} self.context[""roles""] = [self._grant_role(self.endpoint, name)","from rally import exceptions def _add_role(self, admin_endpoint, context_role): default_roles = client.list_roles() for def_role in default_roles: if str(def_role.name) == context_role: role = def_role break else: raise exceptions.NoSuchRole(role=context_role) client.add_role(user_id=user[""id""], role_id=role.id, project_id=user[""tenant_id""]) return {""id"": str(role.id), ""name"": str(role.name)} self.context[""roles""] = [self._add_role(self.endpoint, name)",49,39
openstack%2Fswift~master~I380e7bac1ac7c91ac59991470546cfa68884bc4c,openstack/swift,master,I380e7bac1ac7c91ac59991470546cfa68884bc4c,Respect 'Accept' header in error responses,NEW,2015-07-21 18:24:45.000000000,2017-12-18 05:31:26.000000000,,"[{'_account_id': 330}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 2828}, {'_account_id': 6968}, {'_account_id': 8871}, {'_account_id': 13052}, {'_account_id': 13104}, {'_account_id': 13540}, {'_account_id': 16277}]","[{'number': 1, 'created': '2015-07-21 18:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bc3b7ad49a12ebfedaaf945e1be26872d0e892f7', 'message': 'Respect \'Accept\' header in error responses\n\nswob.py used to send HTML boilerplate text with message embedded\nfor all non 2xx error responses. This change checks if the Accept\nheader is set to \'application/json\' and if yes, send a JSON response\nin format,\n {""status"" : status, ""title"" : error_name,\n \t     \t     ""description"" : error_message }\nCloses-Bug: #1182155\n\nChange-Id: I380e7bac1ac7c91ac59991470546cfa68884bc4c\n'}, {'number': 2, 'created': '2015-07-21 18:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/83cde54cf94a94ec65bfb33a34754a705e8df803', 'message': 'Respect \'Accept\' header in error responses\n\nswob.py used to send HTML boilerplate text with message embedded\nfor all non 2xx error responses. This change checks if the Accept\nheader is set to \'application/json\' and if yes, send a JSON response\nin format,\n {""status"" : status, ""title"" : error_name,\n \t     \t     ""description"" : error_message }\nCloses-Bug: #1182155\n\nChange-Id: I380e7bac1ac7c91ac59991470546cfa68884bc4c\n'}, {'number': 3, 'created': '2015-07-22 03:31:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c3c322b7fb0da162a92d18a2c33ce2deadf40a21', 'message': 'Respect \'Accept\' header in error responses\n\nswob.py used to send HTML boilerplate text with message embedded\nfor all non 2xx error responses. This change checks if the Accept\nheader is set to \'application/json\' and if yes, send a JSON response\nin format,\n {""status"" : status, ""title"" : error_name,\n \t     \t     ""description"" : error_message }\nCloses-Bug: #1182155\n\nChange-Id: I380e7bac1ac7c91ac59991470546cfa68884bc4c\n'}, {'number': 4, 'created': '2015-07-22 03:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6c05cc7009c48a3dd8541d40061185d54acd61f7', 'message': 'Respect \'Accept\' header in error responses\n\nswob.py used to send HTML boilerplate text with message embedded\nfor all non 2xx error responses. This change checks if the Accept\nheader is set to \'application/json\' and if yes, send a JSON response\nin format,\n {""status"" : status, ""title"" : error_name,\n \t     \t     ""description"" : error_message }\nCloses-Bug: #1182155\n\nChange-Id: I380e7bac1ac7c91ac59991470546cfa68884bc4c\n'}, {'number': 5, 'created': '2015-07-23 02:55:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/34fc545e8031a5eef1ca35c49f39ffa3b6e331a1', 'message': 'Respect \'Accept\' header in error responses\n\nswob.py used to send HTML boilerplate text with message embedded\nfor all non 2xx error responses. This change checks if the Accept\nheader is set to \'application/json\' and if yes, send a JSON response\nin format,\n {""status"" : status, ""title"" : error_name,\n \t     \t     ""description"" : error_message }\nCloses-Bug: #1182155\n\nChange-Id: I380e7bac1ac7c91ac59991470546cfa68884bc4c\n'}, {'number': 6, 'created': '2015-07-23 05:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f4bad9008c4f5f499d685f1d7e829335b8912fe7', 'message': 'Respect \'Accept\' header in error responses\n\nswob.py used to send HTML boilerplate text with message embedded\nfor all non 2xx error responses. This change checks if the Accept\nheader is set to \'application/json\' and if yes, send a JSON response\nin format,\n {""status"" : status, ""title"" : error_name,\n \t     \t     ""description"" : error_message }\nCloses-Bug: #1182155\n\nChange-Id: I380e7bac1ac7c91ac59991470546cfa68884bc4c\n'}, {'number': 7, 'created': '2015-07-23 05:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b667fdd171daa691c81024322ab89e1b2e92aedd', 'message': 'Respect \'Accept\' header in error responses\n\nswob.py used to send HTML boilerplate text with message embedded\nfor all non 2xx error responses. This change checks if the Accept\nheader is set to \'application/json\' and if yes, send a JSON response\nin format,\n {""status"" : status, ""title"" : error_name,\n \t     \t     ""description"" : error_message }\nCloses-Bug: #1182155\n\nChange-Id: I380e7bac1ac7c91ac59991470546cfa68884bc4c\n'}, {'number': 8, 'created': '2015-07-30 05:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/03db7f90afa7b897e14968ff9feae78abcbdd7b4', 'message': 'Respect \'Accept\' header in error responses\n\nswob.py used to send HTML boilerplate text with message embedded\nfor all non 2xx error responses. This change checks if the Accept\nheader is set to \'application/json\' and if yes, send a JSON response\nin format,\n {""status"" : status, ""title"" : error_name,\n \t     \t     ""description"" : error_message }\nCloses-Bug: #1182155\nAPIImpact\n\nChange-Id: I380e7bac1ac7c91ac59991470546cfa68884bc4c\n'}, {'number': 9, 'created': '2015-08-01 07:03:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5246fad778c1a9122cdbe0f14e82941fc1841a54', 'message': 'Respect \'Accept\' header in error responses\n\nswob.py used to send HTML boilerplate text with message embedded\nfor all non 2xx error responses. This change checks if the Accept\nheader is set to \'application/json\' and if yes, send a JSON response\nin format,\n {""status"" : status, ""title"" : error_name,\n \t     \t     ""description"" : error_message }\nCloses-Bug: #1182155\nAPIImpact\n\nChange-Id: I380e7bac1ac7c91ac59991470546cfa68884bc4c\n'}, {'number': 10, 'created': '2015-09-20 18:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/80b6b1e9e8758381bced0874662124917b950310', 'message': 'Respect \'Accept\' header in error responses\n\nswob.py used to send HTML boilerplate text with message embedded\nfor all non 2xx error responses. This change checks if the Accept\nheader is set to \'application/json\' and if yes, send a JSON response\nin format,\n {""status"" : status, ""title"" : error_name,\n \t     \t     ""description"" : error_message }\nCloses-Bug: #1182155\nAPIImpact\n\nChange-Id: I380e7bac1ac7c91ac59991470546cfa68884bc4c\n'}, {'number': 11, 'created': '2015-10-10 12:13:14.000000000', 'files': ['swift/obj/server.py', 'test/unit/proxy/controllers/test_obj.py', 'swift/proxy/controllers/obj.py', 'test/functional/swift_test_client.py', 'swift/proxy/server.py', 'swift/container/server.py', 'test/functional/test_object.py', 'swift/common/swob.py', 'swift/proxy/controllers/account.py', 'swift/common/constraints.py', 'test/unit/common/test_swob.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/d22d43ffc033212b5342ade04969c7bb4ef6b777', 'message': 'Respect \'Accept\' header in error responses\n\nThe error response generation in all the servers inside swift is pretty\nmuch inconsistent. They don\'t respect the accept header of the request.\nIn some parts, the accept header isn\'t passed to the backend server at all.\nSome parts, even when the backend server responds with a proper format\nresponse such as JSON, and sets the content-type also accordingly, the proxy\nserver overwrites it with the standard text/html content-type. Some parts,\nwe always hard code and return text/plain error response, irrespective of the\ncontent type asked. This is a attempt to fix all those inconsistencies\nand starting it from the object server. This particular patch does the\nbelow two things:\n\n1. swob.py used to send HTML boilerplate text with message embedded\nfor all non 2xx error responses. This change checks if the Accept\nheader is set to \'application/json\' and if yes, send a JSON response\nin format,\n {""status"" : status, ""title"" : error_name,\n \t     \t     ""description"" : error_message }\n2. Automate error response formatting inside the HTTPException class.\nInstead of passing the whole body text, the servers can now specify\na error_msg argument, and the swob.HTTPException would take care of\nguessing the correct content-type and formatting the body. This also\nmeans text/plain remains the default format, when no other content-type\nor accept header is specified. So, this maintains backwards\ncompatibility with the existing tests.\n\nCloses-Bug: #1182155\nAPIImpact\n\nChange-Id: I380e7bac1ac7c91ac59991470546cfa68884bc4c\n'}]",12,204196,d22d43ffc033212b5342ade04969c7bb4ef6b777,58,11,11,13540,,,0,"Respect 'Accept' header in error responses

The error response generation in all the servers inside swift is pretty
much inconsistent. They don't respect the accept header of the request.
In some parts, the accept header isn't passed to the backend server at all.
Some parts, even when the backend server responds with a proper format
response such as JSON, and sets the content-type also accordingly, the proxy
server overwrites it with the standard text/html content-type. Some parts,
we always hard code and return text/plain error response, irrespective of the
content type asked. This is a attempt to fix all those inconsistencies
and starting it from the object server. This particular patch does the
below two things:

1. swob.py used to send HTML boilerplate text with message embedded
for all non 2xx error responses. This change checks if the Accept
header is set to 'application/json' and if yes, send a JSON response
in format,
 {""status"" : status, ""title"" : error_name,
 	     	     ""description"" : error_message }
2. Automate error response formatting inside the HTTPException class.
Instead of passing the whole body text, the servers can now specify
a error_msg argument, and the swob.HTTPException would take care of
guessing the correct content-type and formatting the body. This also
means text/plain remains the default format, when no other content-type
or accept header is specified. So, this maintains backwards
compatibility with the existing tests.

Closes-Bug: #1182155
APIImpact

Change-Id: I380e7bac1ac7c91ac59991470546cfa68884bc4c
",git fetch https://review.opendev.org/openstack/swift refs/changes/96/204196/9 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/swob.py', 'swift/common/request_helpers.py']",2,bc3b7ad49a12ebfedaaf945e1be26872d0e892f7,fix_api_error_inconsistencies,"def get_error_response_content_type(req): """""" Determine the content type to use for any error response. Currently this will choose either JSON or HTML response. Later if we have to support more error response types, they can be added. :params req: request object :returns: content type as a string (e.g. text/plain, application/json) """""" return req.accept.best_match( ['text/html', 'application/json']) ",,23,1
openstack%2Fswift~master~I0e0a4305f72f7d3fc3876d2940d14467c0ebd8ee,openstack/swift,master,I0e0a4305f72f7d3fc3876d2940d14467c0ebd8ee,Update swift-init restart to accommodate unsuccessful stops,NEW,2014-08-26 16:44:57.000000000,2017-12-18 05:31:24.000000000,,"[{'_account_id': 7134}, {'_account_id': 7847}, {'_account_id': 8871}, {'_account_id': 9625}]","[{'number': 1, 'created': '2014-08-26 16:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ff5a36d17937d479317fcc91a22530e59405705c', 'message': 'Update swift-init restart to accommodate unsuccessful stops\n\nCurrently, when ""swift-init restart <service(s)>"" is run and any of\nservices selected don\'t stop cleanly (generally due to taking longer\nthan the max time of 15sec), the code still tries to start a new\nprocess and the following warning is observed:\n\nWARNING: Unable to modify max process limit. Running as non-root?\n<service> running (<pid> - /etc/swift/<conf_file>)\n<service> already started...\n\nThis change ensures that this does not happen by changing the logic\nused in the ""restart"" function. The new format checks each service\nselected individually and if the particular service is not running,\nit will start a new process. If the service has a process running,\nthen the code will attempt to stop this process. If it successfully\nstops this process, it will start a new process, otherwise it will\nprint a warning to the user that the previous process could not be\nstopped and not bother trying to start another one.\n\nChange-Id: I0e0a4305f72f7d3fc3876d2940d14467c0ebd8ee\nCloses-Bug: 1324620\n'}, {'number': 2, 'created': '2014-08-27 10:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c4d44316f03f86a63df4addda7a2f1af44d93386', 'message': 'Update swift-init restart to accommodate unsuccessful stops\n\nCurrently, when ""swift-init restart <service(s)>"" is run and any of\nservices selected don\'t stop cleanly (generally due to taking longer\nthan the max time of 15sec), the code still tries to start a new\nprocess and the following warning is observed:\n\nWARNING: Unable to modify max process limit. Running as non-root?\n<service> running (<pid> - /etc/swift/<conf_file>)\n<service> already started...\n\nThis change ensures that this does not happen by changing the logic\nused in the ""restart"" function. The new format checks each service\nselected individually and if the particular service is not running,\nit will start a new process. If the service has a process running,\nthen the code will attempt to stop this process. If it successfully\nstops this process, it will start a new process, otherwise it will\nprint a warning to the user that the previous process could not be\nstopped and not bother trying to start another one.\n\nChange-Id: I0e0a4305f72f7d3fc3876d2940d14467c0ebd8ee\nCloses-Bug: 1324620\n'}, {'number': 3, 'created': '2014-08-27 14:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cb623d7c1f654d3bf35868d34c2fc52f55b7dfad', 'message': 'Update swift-init restart to accommodate unsuccessful stops\n\nCurrently, when ""swift-init restart <service(s)>"" is run and any of\nservices selected don\'t stop cleanly (generally due to taking longer\nthan the max time of 15sec), the code still tries to start a new\nprocess and the following warning is observed:\n\nWARNING: Unable to modify max process limit. Running as non-root?\n<service> running (<pid> - /etc/swift/<conf_file>)\n<service> already started...\n\nThis change ensures that this does not happen by changing the logic\nused in the ""restart"" function. The new format checks each service\nselected individually and if the particular service is not running,\nit will start a new process. If the service has a process running,\nthen the code will attempt to stop this process. If it successfully\nstops this process, it will start a new process, otherwise it will\nprint a warning to the user that the previous process could not be\nstopped and not bother trying to start another one.\n\nChange-Id: I0e0a4305f72f7d3fc3876d2940d14467c0ebd8ee\nCloses-Bug: 1324620\n'}, {'number': 4, 'created': '2014-09-05 14:59:40.000000000', 'files': ['test/unit/common/test_manager.py', 'swift/common/manager.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/9e3d88471fec98d49b0368715d938cea74aa29c4', 'message': 'Update swift-init restart to accommodate unsuccessful stops\n\nCurrently, when ""swift-init restart <service(s)>"" is run and any of\nservices selected don\'t stop cleanly (generally due to taking longer\nthan the max time of 15sec), the code still tries to start a new\nprocess and the following is observed:\n\nSignal <service>  pid: <pid>  signal: X\nWaited Y seconds for <service> to die; giving up\n<service> running (<pid> - /etc/swift/<conf_file>)\n<service> already started...\n\nThis can be misleading as it may be interpreted that the service\nhas been restarted. This change ensures that this does not happen\nby changing the logic used in the ""restart"" function. The new\nformat checks each service selected individually and if the\nparticular service is not running, it will start a new process. If\nthe service has a process running, then the code will attempt to\nstop this process. If it successfully stops this process, it will\nstart a new process, otherwise it will print a warning to the user\nthat the previous process could not be stopped and not bother\ntrying to start another one.\n\nChange-Id: I0e0a4305f72f7d3fc3876d2940d14467c0ebd8ee\nCloses-Bug: 1324620\n'}]",4,116944,9e3d88471fec98d49b0368715d938cea74aa29c4,24,4,4,7134,,,0,"Update swift-init restart to accommodate unsuccessful stops

Currently, when ""swift-init restart <service(s)>"" is run and any of
services selected don't stop cleanly (generally due to taking longer
than the max time of 15sec), the code still tries to start a new
process and the following is observed:

Signal <service>  pid: <pid>  signal: X
Waited Y seconds for <service> to die; giving up
<service> running (<pid> - /etc/swift/<conf_file>)
<service> already started...

This can be misleading as it may be interpreted that the service
has been restarted. This change ensures that this does not happen
by changing the logic used in the ""restart"" function. The new
format checks each service selected individually and if the
particular service is not running, it will start a new process. If
the service has a process running, then the code will attempt to
stop this process. If it successfully stops this process, it will
start a new process, otherwise it will print a warning to the user
that the previous process could not be stopped and not bother
trying to start another one.

Change-Id: I0e0a4305f72f7d3fc3876d2940d14467c0ebd8ee
Closes-Bug: 1324620
",git fetch https://review.opendev.org/openstack/swift refs/changes/44/116944/4 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/manager.py'],1,ff5a36d17937d479317fcc91a22530e59405705c,bug/1324620," for server in self.servers: m = Manager([server.server]) init_status = m.status(**kwargs) if init_status == 1: # If service is already stopped status = m.start(**kwargs) else: ser_status = m.stop(**kwargs) if ser_status == 0: # If service stops cleanly status += m.start(**kwargs) else: print ""Not starting {0} as it hasn't stopped cleanly.""\ .format(server) status += ser_status ", status += self.stop(**kwargs) status += self.start(**kwargs),18,2
openstack%2Fswift~master~Iaffb32d34636fb2bea064fb992a3a15a1b2cc9f4,openstack/swift,master,Iaffb32d34636fb2bea064fb992a3a15a1b2cc9f4,allows for swift-ring-builder write_builder to continue if one of devices is missing,NEW,2015-09-11 14:05:52.000000000,2017-12-18 05:31:16.000000000,,"[{'_account_id': 6968}, {'_account_id': 13052}, {'_account_id': 14152}]","[{'number': 1, 'created': '2015-09-11 14:05:52.000000000', 'files': ['swift/cli/ringbuilder.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/60ecbb3051047b58c6220959ef2b5df2333e5105', 'message': 'allows for swift-ring-builder write_builder to continue if one of devices is missing\n\nChange-Id: Iaffb32d34636fb2bea064fb992a3a15a1b2cc9f4\nCloses-Bug: #1487280\n'}]",0,222620,60ecbb3051047b58c6220959ef2b5df2333e5105,7,3,1,14152,,,0,"allows for swift-ring-builder write_builder to continue if one of devices is missing

Change-Id: Iaffb32d34636fb2bea064fb992a3a15a1b2cc9f4
Closes-Bug: #1487280
",git fetch https://review.opendev.org/openstack/swift refs/changes/20/222620/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/cli/ringbuilder.py'],1,60ecbb3051047b58c6220959ef2b5df2333e5105,bug/1487280," if dev is None: stderr.write(""Warning: can't find one of ring devices"") continue",,3,0
openstack%2Fswift~master~I7b54a322c0552789156fefd0a96ffdacc336cbfc,openstack/swift,master,I7b54a322c0552789156fefd0a96ffdacc336cbfc,"Keystonemiddleware needs a ""project"" config option",NEW,2015-06-10 21:53:18.000000000,2017-12-18 05:31:14.000000000,,"[{'_account_id': 2622}, {'_account_id': 7847}, {'_account_id': 12193}, {'_account_id': 15640}]","[{'number': 1, 'created': '2015-06-10 21:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d2abc4d1a2c4c22657f49e396057b7e46364f2f5', 'message': 'Keystonemiddleware needs a ""project"" config option\n\nAdd a a ""project = swift"" paste.deploy configuration option setting\nfor keystone auth middleware filter. This option will be used by\nkeystonemiddleware auth token to send the correct and complete\nuser-agent to Keystone.\n\nCloses-Bug: #1463992\nChange-Id: I7b54a322c0552789156fefd0a96ffdacc336cbfc\n'}, {'number': 2, 'created': '2015-06-10 21:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cbdbf547415990d586155b91ed3f1e01f8f4ab3c', 'message': 'Keystonemiddleware needs a ""project"" config option\n\nAdd ""project = swift"" paste.deploy configuration option setting\nfor keystone auth middleware filter. This option will be used by\nkeystonemiddleware auth token to send the correct and complete\nuser-agent to Keystone.\n\nCloses-Bug: #1463992\nChange-Id: I7b54a322c0552789156fefd0a96ffdacc336cbfc\n'}, {'number': 3, 'created': '2015-06-10 23:22:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d4873d280d1ccb132b80437b5a1d31f1f75fc12a', 'message': 'Keystonemiddleware needs a ""project"" config option\n\nAdd ""project = swift"" paste.deploy configuration option setting\nfor keystone auth middleware filter. This option will be used by\nkeystonemiddleware auth token to send the correct and complete\nuser-agent to Keystone.\n\nCloses-Bug: #1463992\nChange-Id: I7b54a322c0552789156fefd0a96ffdacc336cbfc\n'}, {'number': 4, 'created': '2015-06-11 17:41:35.000000000', 'files': ['etc/proxy-server.conf-sample', 'doc/source/overview_auth.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/604e4d024535fa29d9ca6111c8f8c25259c59cee', 'message': 'Keystonemiddleware needs a ""project"" config option\n\nAdd ""project = swift"" paste.deploy configuration option setting\nfor keystone auth middleware filter. This option will be used by\nkeystonemiddleware auth token to send the correct and complete\nuser-agent to Keystone.\n\nCloses-Bug: #1463992\nDepends-On: Ic87861d2f9fefb3fe78cc93adc73acad9a837b39\nChange-Id: I7b54a322c0552789156fefd0a96ffdacc336cbfc\n'}]",0,190370,604e4d024535fa29d9ca6111c8f8c25259c59cee,24,4,4,15640,,,0,"Keystonemiddleware needs a ""project"" config option

Add ""project = swift"" paste.deploy configuration option setting
for keystone auth middleware filter. This option will be used by
keystonemiddleware auth token to send the correct and complete
user-agent to Keystone.

Closes-Bug: #1463992
Depends-On: Ic87861d2f9fefb3fe78cc93adc73acad9a837b39
Change-Id: I7b54a322c0552789156fefd0a96ffdacc336cbfc
",git fetch https://review.opendev.org/openstack/swift refs/changes/70/190370/4 && git format-patch -1 --stdout FETCH_HEAD,['etc/proxy-server.conf-sample'],1,d2abc4d1a2c4c22657f49e396057b7e46364f2f5,bug/1463992,# The project option is used by keystonemiddleware to send the correct # user-agent to Keystone. # project = swift #,,4,0
openstack%2Fswift~master~Ibfe614af639479f3b16f2d17494f4a3a5468fec9,openstack/swift,master,Ibfe614af639479f3b16f2d17494f4a3a5468fec9,Possible pipeline auditor - WIP,NEW,2015-10-13 03:38:05.000000000,2017-12-18 05:31:09.000000000,,[{'_account_id': 7233}],"[{'number': 1, 'created': '2015-10-13 03:38:05.000000000', 'files': ['swift/common/middleware/__init__.py', 'swift/common/middleware/container_quotas.py', 'swift/common/middleware/versioned_writes.py', 'swift/common/middleware/xprofile.py', 'swift/common/middleware/staticweb.py', 'swift/common/middleware/memcache.py', 'swift/common/middleware/cname_lookup.py', 'swift/common/middleware/name_check.py', 'swift/common/middleware/bulk.py', 'swift/common/middleware/recon.py', 'swift/common/middleware/healthcheck.py', 'swift/common/middleware/account_quotas.py', 'swift/common/middleware/slo.py', 'swift/common/middleware/container_sync.py', 'swift/cli/pipeline_audit.py', 'swift/common/base_storage_server.py', 'swift/common/middleware/proxy_logging.py', 'bin/swift-pipeline-auditor', 'swift/common/middleware/tempurl.py', 'swift/common/middleware/formpost.py', 'swift/common/middleware/keystoneauth.py', 'swift/common/middleware/domain_remap.py', 'swift/proxy/server.py', 'swift/common/middleware/dlo.py', 'swift/common/middleware/gatekeeper.py', 'swift/common/middleware/ratelimit.py', 'swift/common/middleware/list_endpoints.py', 'swift/common/middleware/tempauth.py', 'swift/common/middleware/crossdomain.py', 'setup.cfg', 'swift/common/middleware/catch_errors.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/716f48eda1a13a129b7025872f3ff5298623b558', 'message': ""Possible pipeline auditor - WIP\n\nAt the last hackathon there was some talk about pipelines.\nI got to thinking of ways to tackle this, here is some code\nI've been playing with (No TESTS). This change is marked WIP and may never\nbe merged, but wanted to put it up to at least start some discussions.\n\nIt might be a little over engineered, and I'm not sold on the idea,\nbut I thought it is an interesting POC and so wanted to share it.\n\nThis adds a new tool, swift-pipeline-audit, which takes in a config that\ncontains a pipeline ({proxy,object,container,account}-server.conf), and\naudit the pipeline contained. It doesn't simply get a pipeline\nbecause there is a few this it actually does:\n\n 1. Validate that the required sections exist.\n 2. Validate that the required entrypoints for each middleware exists.\n 3. Then audits the pipeline by asking the middleware classes themselves.\n\nBy default, if incorrect, it will spit out in what position a middleware\nshould belong, or if it needs to be before, after, etc.\nIf you pass in a --correct flag, if the pipeline is incorrect it will\nspit out a correct flag. This --correct flag could be removed and just\nalways spit out a corrected pipeline.\n\nInstead of having a set of rules, the rules are stored inside the\nmiddlewares themselves, so custom middlewares can easily take advantage\nof the tool. To accomplish this all middleware now inherit from a\nBaseMiddleware class. Those that don't still work and will be treated\nand being in the NONE group, which wont attempt to be moved.\n\nThe BaseMiddleware class contains default filter values:\n\n  class BaseMiddleware(object):\n    # List of middleware class names that are required\n    requires = []\n\n    # List of middleware class names that this middleware should be\n    # before if it appears in this pipeline.\n    before = []\n\n    # List of middleware class names that this middleware should be\n    # after\n    # if it appears in this pipeline.\n    after = []\n\n    # Group this middleware is apart of (see comment at top of file)\n    group = NONE\n\nThe groups are as follows:\n  NONE\n    default, even for a middleware that doesn't inherit BaseMiddleware.\n    Middleware in this group will be left alone.\n  FIRST\n    Middleware what should appear first (e.g gatekeeper and\n    catch_errors)\n  SHORT_CIRCUIT\n    Middleware that respond to the user without hitting the app, and we\n    want\n    minimal processing when it does.\n  PRE_AUTH\n    Middleware what should appear before auth (e.g tempurl, formpost)\n  AUTH\n    Authentication middleware.\n  POST_AUTH\n    Middle that should sit post AUTH.\n  LAST\n    Middleware that should appear at the end of the pipeline.\n  APP\n    Application gets detected and marked, no middleware should get this\n    group.\n\nThe current rules in this change haven't been fully thought out, but\nenough to test. But it's easy to add more.\n\nNOTE: Because proxy-logging appears twice, it was placed in the NONE group.\n\nHere are some sample usages using the sample configs:\n\n$ swift-pipeline-auditor etc/proxy-server.conf-sample --correct\n\nMiddleware proxy-logging isn't a member of a group, so it will be up to\n  you to make sure it is in the correct position.\nMiddleware proxy-logging isn't a member of a group, so it will be up to\n  you to make sure it is in the correct position.\nMiddleware ratelimit needs to move to position 8\nMiddleware tempauth needs to move to position 9\nMiddleware bulk needs to move to position 10\nCurrent pipeline: catch_errors gatekeeper healthcheck proxy-logging\n  cache container_sync bulk tempurl ratelimit tempauth container-quotas\n  account-quotas slo dlo versioned_writes proxy-logging proxy-server\nCorrect pipeline: catch_errors gatekeeper healthcheck proxy-logging\n  cache container_sync tempurl ratelimit tempauth bulk container-quotas\n  account-quotas slo dlo versioned_writes proxy-logging proxy-server\n\n$ swift-pipeline-auditor etc/object-server.conf-sample --correct\n\nCurrent pipeline: healthcheck recon object-server\n\nThe object-server.conf is correct, so doesn't show any errors or need to\nprovide a correct pipeline.\n\nChange-Id: Ibfe614af639479f3b16f2d17494f4a3a5468fec9\n""}]",0,233922,716f48eda1a13a129b7025872f3ff5298623b558,4,1,1,7233,,,0,"Possible pipeline auditor - WIP

At the last hackathon there was some talk about pipelines.
I got to thinking of ways to tackle this, here is some code
I've been playing with (No TESTS). This change is marked WIP and may never
be merged, but wanted to put it up to at least start some discussions.

It might be a little over engineered, and I'm not sold on the idea,
but I thought it is an interesting POC and so wanted to share it.

This adds a new tool, swift-pipeline-audit, which takes in a config that
contains a pipeline ({proxy,object,container,account}-server.conf), and
audit the pipeline contained. It doesn't simply get a pipeline
because there is a few this it actually does:

 1. Validate that the required sections exist.
 2. Validate that the required entrypoints for each middleware exists.
 3. Then audits the pipeline by asking the middleware classes themselves.

By default, if incorrect, it will spit out in what position a middleware
should belong, or if it needs to be before, after, etc.
If you pass in a --correct flag, if the pipeline is incorrect it will
spit out a correct flag. This --correct flag could be removed and just
always spit out a corrected pipeline.

Instead of having a set of rules, the rules are stored inside the
middlewares themselves, so custom middlewares can easily take advantage
of the tool. To accomplish this all middleware now inherit from a
BaseMiddleware class. Those that don't still work and will be treated
and being in the NONE group, which wont attempt to be moved.

The BaseMiddleware class contains default filter values:

  class BaseMiddleware(object):
    # List of middleware class names that are required
    requires = []

    # List of middleware class names that this middleware should be
    # before if it appears in this pipeline.
    before = []

    # List of middleware class names that this middleware should be
    # after
    # if it appears in this pipeline.
    after = []

    # Group this middleware is apart of (see comment at top of file)
    group = NONE

The groups are as follows:
  NONE
    default, even for a middleware that doesn't inherit BaseMiddleware.
    Middleware in this group will be left alone.
  FIRST
    Middleware what should appear first (e.g gatekeeper and
    catch_errors)
  SHORT_CIRCUIT
    Middleware that respond to the user without hitting the app, and we
    want
    minimal processing when it does.
  PRE_AUTH
    Middleware what should appear before auth (e.g tempurl, formpost)
  AUTH
    Authentication middleware.
  POST_AUTH
    Middle that should sit post AUTH.
  LAST
    Middleware that should appear at the end of the pipeline.
  APP
    Application gets detected and marked, no middleware should get this
    group.

The current rules in this change haven't been fully thought out, but
enough to test. But it's easy to add more.

NOTE: Because proxy-logging appears twice, it was placed in the NONE group.

Here are some sample usages using the sample configs:

$ swift-pipeline-auditor etc/proxy-server.conf-sample --correct

Middleware proxy-logging isn't a member of a group, so it will be up to
  you to make sure it is in the correct position.
Middleware proxy-logging isn't a member of a group, so it will be up to
  you to make sure it is in the correct position.
Middleware ratelimit needs to move to position 8
Middleware tempauth needs to move to position 9
Middleware bulk needs to move to position 10
Current pipeline: catch_errors gatekeeper healthcheck proxy-logging
  cache container_sync bulk tempurl ratelimit tempauth container-quotas
  account-quotas slo dlo versioned_writes proxy-logging proxy-server
Correct pipeline: catch_errors gatekeeper healthcheck proxy-logging
  cache container_sync tempurl ratelimit tempauth bulk container-quotas
  account-quotas slo dlo versioned_writes proxy-logging proxy-server

$ swift-pipeline-auditor etc/object-server.conf-sample --correct

Current pipeline: healthcheck recon object-server

The object-server.conf is correct, so doesn't show any errors or need to
provide a correct pipeline.

Change-Id: Ibfe614af639479f3b16f2d17494f4a3a5468fec9
",git fetch https://review.opendev.org/openstack/swift refs/changes/22/233922/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/__init__.py', 'swift/common/middleware/container_quotas.py', 'swift/common/middleware/versioned_writes.py', 'swift/common/middleware/xprofile.py', 'swift/common/middleware/staticweb.py', 'swift/common/middleware/memcache.py', 'swift/common/middleware/cname_lookup.py', 'swift/common/middleware/name_check.py', 'swift/common/middleware/bulk.py', 'swift/common/middleware/recon.py', 'swift/common/middleware/healthcheck.py', 'swift/common/middleware/account_quotas.py', 'swift/common/middleware/slo.py', 'swift/common/middleware/container_sync.py', 'swift/cli/pipeline_audit.py', 'swift/common/base_storage_server.py', 'swift/common/middleware/proxy_logging.py', 'bin/swift-pipeline-auditor', 'swift/common/middleware/tempurl.py', 'swift/common/middleware/formpost.py', 'swift/common/middleware/keystoneauth.py', 'swift/common/middleware/domain_remap.py', 'swift/proxy/server.py', 'swift/common/middleware/dlo.py', 'swift/common/middleware/gatekeeper.py', 'swift/common/middleware/ratelimit.py', 'swift/common/middleware/list_endpoints.py', 'swift/common/middleware/tempauth.py', 'swift/common/middleware/crossdomain.py', 'setup.cfg', 'swift/common/middleware/catch_errors.py']",31,716f48eda1a13a129b7025872f3ff5298623b558,pipeline_audit,"from swift.common.middleware import BaseMiddleware, FIRSTclass CatchErrorMiddleware(BaseMiddleware): group = FIRST before = ['GatekeeperMiddleware']",class CatchErrorMiddleware(object):,533,28
openstack%2Fswift~master~Ieb64222a56d30930149e8ff70194a690936bbaec,openstack/swift,master,Ieb64222a56d30930149e8ff70194a690936bbaec,"Merge ""Drop redundant check in SLO segment-size validation""",NEW,2015-02-02 07:44:09.000000000,2017-12-18 05:31:07.000000000,,"[{'_account_id': 2622}, {'_account_id': 5263}, {'_account_id': 17130}]","[{'number': 1, 'created': '2015-02-02 07:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6a4054372436b7f4cce2431f6fb44d4d9ed8fec3', 'message': 'Merge ""Drop redundant check in SLO segment-size validation""\n\nChange-Id: Ieb64222a56d30930149e8ff70194a690936bbaec\n'}]",0,152011,6a4054372436b7f4cce2431f6fb44d4d9ed8fec3,9,3,1,11131,,,0,"Merge ""Drop redundant check in SLO segment-size validation""

Change-Id: Ieb64222a56d30930149e8ff70194a690936bbaec
",git fetch https://review.opendev.org/openstack/swift refs/changes/11/152011/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,6a4054372436b7f4cce2431f6fb44d4d9ed8fec3,broken-release-tag,,,0,0
openstack%2Fmasakari~master~I5cd2930d78db0efa7bdbe827671d06db595f41ad,openstack/masakari,master,I5cd2930d78db0efa7bdbe827671d06db595f41ad,Use method validate_integer from oslo.utils,ABANDONED,2017-12-18 05:15:01.000000000,2017-12-18 05:31:03.000000000,,"[{'_account_id': 9796}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-18 05:15:01.000000000', 'files': ['masakari/utils.py'], 'web_link': 'https://opendev.org/openstack/masakari/commit/ac1456a768a6150072cb44df1a1973afeaccadaa', 'message': 'Use method validate_integer from oslo.utils\n\nWe added method validate_integer in oslo.utils 3.33.0 [1],\nso we can simply the method validate_integer in masakari.\n\nDepends-On: I741875eba329b762789a7c7c910a6c46beeff3fa\n\n[1] https://review.openstack.org/#/c/508401/\n\nChange-Id: I5cd2930d78db0efa7bdbe827671d06db595f41ad\n'}]",0,528628,ac1456a768a6150072cb44df1a1973afeaccadaa,4,2,1,9796,,,0,"Use method validate_integer from oslo.utils

We added method validate_integer in oslo.utils 3.33.0 [1],
so we can simply the method validate_integer in masakari.

Depends-On: I741875eba329b762789a7c7c910a6c46beeff3fa

[1] https://review.openstack.org/#/c/508401/

Change-Id: I5cd2930d78db0efa7bdbe827671d06db595f41ad
",git fetch https://review.opendev.org/openstack/masakari refs/changes/28/528628/1 && git format-patch -1 --stdout FETCH_HEAD,['masakari/utils.py'],1,ac1456a768a6150072cb44df1a1973afeaccadaa,validate_integer,"from oslo_utils import strutils value = strutils.validate_integer(value, name, min_value, max_value) return value except ValueError as e: raise exception.InvalidInput(reason=six.text_type(e))"," value = int(str(value)) except (ValueError, UnicodeEncodeError): msg = _('%(value_name)s must be an integer') raise exception.InvalidInput(reason=( msg % {'value_name': name})) if min_value is not None: if value < min_value: msg = _('%(value_name)s must be >= %(min_value)d') raise exception.InvalidInput( reason=(msg % {'value_name': name, 'min_value': min_value})) if max_value is not None: if value > max_value: msg = _('%(value_name)s must be <= %(max_value)d') raise exception.InvalidInput( reason=( msg % {'value_name': name, 'max_value': max_value}) ) return value ",5,22
openstack%2Fswift~master~I29a14a553fc45297ecbee43b31bb23207aa3a577,openstack/swift,master,I29a14a553fc45297ecbee43b31bb23207aa3a577,Support for policies in swift-account-audit,NEW,2015-08-12 17:15:03.000000000,2017-12-18 05:30:39.000000000,,"[{'_account_id': 13052}, {'_account_id': 16896}, {'_account_id': 17883}]","[{'number': 1, 'created': '2015-08-12 17:15:03.000000000', 'files': ['bin/swift-account-audit'], 'web_link': 'https://opendev.org/openstack/swift/commit/c5561c7fa7ebc91713ab6b006b78482484d953b0', 'message': 'Support for policies in swift-account-audit\n\nChange-Id: I29a14a553fc45297ecbee43b31bb23207aa3a577\nCloses-Bug: #1484144\n'}]",6,212109,c5561c7fa7ebc91713ab6b006b78482484d953b0,9,3,1,17883,,,0,"Support for policies in swift-account-audit

Change-Id: I29a14a553fc45297ecbee43b31bb23207aa3a577
Closes-Bug: #1484144
",git fetch https://review.opendev.org/openstack/swift refs/changes/09/212109/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift-account-audit'],1,c5561c7fa7ebc91713ab6b006b78482484d953b0,bug/1484144," self.swift_dir = swift_dir def audit_object(self, account, container, name, policy): if policy is not ""0"": object_policy_ring = Ring(self.swift_dir, ring_name='object-' + policy) else: object_policy_ring = self.object_ring part, nodes = object_policy_ring.get_nodes( headers = {} if policy: headers = {'X-Backend-Storage-Policy-Index': policy} node['device'], part, 'GET', path, headers) path.encode('utf-8'), headers) try: if resp.getheader('ETag').strip('""') != hash: consistent = False self.object_checksum_mismatch += 1 print ' ETag mismatch for ""%s"" on %s/%s' \ % (path, node['ip'], node['device']) except AttributeError: continue rec_d[obj_name]['policy'] = responses \ .values()[0]['x-backend-storage-policy-index'] for obj in rec_d.iteritems(): self.pool.spawn_n(self.audit_object, account, name, obj[0], obj[1]['policy']) try: part, nodes = self.container_ring.get_nodes( account, container.encode('utf-8')) path = '/%s/%s' % (account, container) marker = '' conn = http_connect(nodes[0]['ip'], nodes[0]['port'], nodes[0]['device'], part, 'GET', path.encode('utf-8'), {}, 'format=json&marker=%s' % quote(marker.encode('utf-8'))) resp = conn.getresponse() policy = dict( resp.getheaders())['x-backend-storage-policy-index'] self.pool.spawn_n(self.audit_object, account, container, obj, policy) except Exception: print ' Exception GETting container ""%s"" on %s/%s' % \ (path, nodes[0]['ip'], nodes[0]['device']) return"," def audit_object(self, account, container, name): part, nodes = self.object_ring.get_nodes( node['device'], part, 'GET', path, {}) path.encode('utf-8'), {}) if resp.getheader('ETag').strip('""') != hash: consistent = False self.object_checksum_mismatch += 1 print ' ETag mismatch for ""%s"" on %s/%s' \ % (path, node['ip'], node['device']) for obj in rec_d.keys(): self.pool.spawn_n(self.audit_object, account, name, obj) self.pool.spawn_n(self.audit_object, account, container, obj)",46,12
openstack%2Fswift~master~Ib9e33dcde2ef20437ade9115a55bcfcd6c0ee2f2,openstack/swift,master,Ib9e33dcde2ef20437ade9115a55bcfcd6c0ee2f2,Refactor test/functional/tests.py into multiple smaller files,NEW,2015-10-08 16:52:13.000000000,2017-12-18 05:30:34.000000000,,"[{'_account_id': 330}, {'_account_id': 13052}, {'_account_id': 13540}]","[{'number': 1, 'created': '2015-10-08 16:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f2a35ed0a3b64ebfaa3c9cafa2277a7c37c606ec', 'message': 'Refactor test/functional/tests.py into multiple smaller files\n\nThe test/functional/tests.py is a huge beast holding tests for many\nfunctionalities. It makes it harder to reason about and refactor.\nSo splitting them into multiple files based on the functions the\ntest is testing.\n\nChange-Id: Ib9e33dcde2ef20437ade9115a55bcfcd6c0ee2f2\n'}, {'number': 2, 'created': '2015-10-10 07:51:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cca01e21e920183db2dcf8d54af0cd1d78a5da8a', 'message': 'Refactor test/functional/tests.py into multiple smaller files\n\nThe test/functional/tests.py is a huge beast holding tests for many\nfunctionalities. It makes it harder to reason about and refactor.\nSo splitting them into multiple files based on the functions the\ntest is testing.\n\nChange-Id: Ib9e33dcde2ef20437ade9115a55bcfcd6c0ee2f2\n'}, {'number': 3, 'created': '2015-10-10 08:44:26.000000000', 'files': ['test/functional/test_dlo.py', 'test/functional/test_temp_url.py', 'test/functional/tests.py', 'test/functional/test_slo.py', 'test/functional/common.py', 'test/functional/test_object_versioning.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/8187201c89b70d490cb6a978f9109abbcbad2502', 'message': 'Refactor test/functional/tests.py into multiple smaller files\n\nThe test/functional/tests.py is a huge beast holding tests for many\nfunctionalities. It makes it harder to reason about and refactor.\nSo splitting them into multiple files based on the functions the\ntest is testing.\n\nChange-Id: Ib9e33dcde2ef20437ade9115a55bcfcd6c0ee2f2\n'}]",0,232660,8187201c89b70d490cb6a978f9109abbcbad2502,15,3,3,13540,,,0,"Refactor test/functional/tests.py into multiple smaller files

The test/functional/tests.py is a huge beast holding tests for many
functionalities. It makes it harder to reason about and refactor.
So splitting them into multiple files based on the functions the
test is testing.

Change-Id: Ib9e33dcde2ef20437ade9115a55bcfcd6c0ee2f2
",git fetch https://review.opendev.org/openstack/swift refs/changes/60/232660/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/functional/test_dlo.py', 'test/functional/test_temp_url.py', 'test/functional/tests.py', 'test/functional/test_slo.py', 'test/functional/common.py', 'test/functional/test_object_versioning.py']",6,f2a35ed0a3b64ebfaa3c9cafa2277a7c37c606ec,refactor_functional_tests,"#!/usr/bin/python -u # Copyright (c) 2010-2012 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import time import unittest from copy import deepcopy from nose import SkipTest from test.functional import cluster_info from test.functional.common import Utils, Base, Base2 import test.functional as tf from test.functional.swift_test_client import Account, Connection, \ ResponseError class TestObjectVersioningEnv(object): versioning_enabled = None # tri-state: None initially, then True/False @classmethod def setUp(cls): cls.conn = Connection(tf.config) cls.storage_url, cls.storage_token = cls.conn.authenticate() cls.account = Account(cls.conn, tf.config.get('account', tf.config['username'])) # Second connection for ACL tests config2 = deepcopy(tf.config) config2['account'] = tf.config['account2'] config2['username'] = tf.config['username2'] config2['password'] = tf.config['password2'] cls.conn2 = Connection(config2) cls.conn2.authenticate() # avoid getting a prefix that stops halfway through an encoded # character prefix = Utils.create_name().decode(""utf-8"")[:10].encode(""utf-8"") cls.versions_container = cls.account.container(prefix + ""-versions"") if not cls.versions_container.create(): raise ResponseError(cls.conn.response) cls.container = cls.account.container(prefix + ""-objs"") if not cls.container.create( hdrs={'X-Versions-Location': cls.versions_container.name}): raise ResponseError(cls.conn.response) container_info = cls.container.info() # if versioning is off, then X-Versions-Location won't persist cls.versioning_enabled = 'versions' in container_info # setup another account to test ACLs config2 = deepcopy(tf.config) config2['account'] = tf.config['account2'] config2['username'] = tf.config['username2'] config2['password'] = tf.config['password2'] cls.conn2 = Connection(config2) cls.storage_url2, cls.storage_token2 = cls.conn2.authenticate() cls.account2 = cls.conn2.get_account() cls.account2.delete_containers() # setup another account with no access to anything to test ACLs config3 = deepcopy(tf.config) config3['account'] = tf.config['account'] config3['username'] = tf.config['username3'] config3['password'] = tf.config['password3'] cls.conn3 = Connection(config3) cls.storage_url3, cls.storage_token3 = cls.conn3.authenticate() cls.account3 = cls.conn3.get_account() @classmethod def tearDown(cls): cls.account.delete_containers() cls.account2.delete_containers() class TestCrossPolicyObjectVersioningEnv(object): # tri-state: None initially, then True/False versioning_enabled = None multiple_policies_enabled = None policies = None @classmethod def setUp(cls): cls.conn = Connection(tf.config) cls.conn.authenticate() if cls.multiple_policies_enabled is None: try: cls.policies = tf.FunctionalStoragePolicyCollection.from_info() except AssertionError: pass if cls.policies and len(cls.policies) > 1: cls.multiple_policies_enabled = True else: cls.multiple_policies_enabled = False cls.versioning_enabled = False return if cls.versioning_enabled is None: cls.versioning_enabled = 'versioned_writes' in cluster_info if not cls.versioning_enabled: return policy = cls.policies.select() version_policy = cls.policies.exclude(name=policy['name']).select() cls.account = Account(cls.conn, tf.config.get('account', tf.config['username'])) # Second connection for ACL tests config2 = deepcopy(tf.config) config2['account'] = tf.config['account2'] config2['username'] = tf.config['username2'] config2['password'] = tf.config['password2'] cls.conn2 = Connection(config2) cls.conn2.authenticate() # avoid getting a prefix that stops halfway through an encoded # character prefix = Utils.create_name().decode(""utf-8"")[:10].encode(""utf-8"") cls.versions_container = cls.account.container(prefix + ""-versions"") if not cls.versions_container.create( {'X-Storage-Policy': policy['name']}): raise ResponseError(cls.conn.response) cls.container = cls.account.container(prefix + ""-objs"") if not cls.container.create( hdrs={'X-Versions-Location': cls.versions_container.name, 'X-Storage-Policy': version_policy['name']}): raise ResponseError(cls.conn.response) container_info = cls.container.info() # if versioning is off, then X-Versions-Location won't persist cls.versioning_enabled = 'versions' in container_info # setup another account to test ACLs config2 = deepcopy(tf.config) config2['account'] = tf.config['account2'] config2['username'] = tf.config['username2'] config2['password'] = tf.config['password2'] cls.conn2 = Connection(config2) cls.storage_url2, cls.storage_token2 = cls.conn2.authenticate() cls.account2 = cls.conn2.get_account() cls.account2.delete_containers() # setup another account with no access to anything to test ACLs config3 = deepcopy(tf.config) config3['account'] = tf.config['account'] config3['username'] = tf.config['username3'] config3['password'] = tf.config['password3'] cls.conn3 = Connection(config3) cls.storage_url3, cls.storage_token3 = cls.conn3.authenticate() cls.account3 = cls.conn3.get_account() class TestObjectVersioning(Base): env = TestObjectVersioningEnv set_up = False def setUp(self): super(TestObjectVersioning, self).setUp() if self.env.versioning_enabled is False: raise SkipTest(""Object versioning not enabled"") elif self.env.versioning_enabled is not True: # just some sanity checking raise Exception( ""Expected versioning_enabled to be True/False, got %r"" % (self.env.versioning_enabled,)) def tearDown(self): super(TestObjectVersioning, self).tearDown() try: # only delete files and not container # as they were configured in self.env self.env.versions_container.delete_files() self.env.container.delete_files() except ResponseError: pass def test_clear_version_option(self): # sanity self.assertEqual(self.env.container.info()['versions'], self.env.versions_container.name) self.env.container.update_metadata( hdrs={'X-Versions-Location': ''}) self.assertEqual(self.env.container.info().get('versions'), None) # set location back to the way it was self.env.container.update_metadata( hdrs={'X-Versions-Location': self.env.versions_container.name}) self.assertEqual(self.env.container.info()['versions'], self.env.versions_container.name) def test_overwriting(self): container = self.env.container versions_container = self.env.versions_container cont_info = container.info() self.assertEquals(cont_info['versions'], versions_container.name) obj_name = Utils.create_name() versioned_obj = container.file(obj_name) versioned_obj.write(""aaaaa"", hdrs={'Content-Type': 'text/jibberish01'}) obj_info = versioned_obj.info() self.assertEqual('text/jibberish01', obj_info['content_type']) self.assertEqual(0, versions_container.info()['object_count']) versioned_obj.write(""bbbbb"", hdrs={'Content-Type': 'text/jibberish02', 'X-Object-Meta-Foo': 'Bar'}) versioned_obj.initialize() self.assertEqual(versioned_obj.content_type, 'text/jibberish02') self.assertEqual(versioned_obj.metadata['foo'], 'Bar') # the old version got saved off self.assertEqual(1, versions_container.info()['object_count']) versioned_obj_name = versions_container.files()[0] prev_version = versions_container.file(versioned_obj_name) prev_version.initialize() self.assertEqual(""aaaaa"", prev_version.read()) self.assertEqual(prev_version.content_type, 'text/jibberish01') # make sure the new obj metadata did not leak to the prev. version self.assertTrue('foo' not in prev_version.metadata) # check that POST does not create a new version versioned_obj.sync_metadata(metadata={'fu': 'baz'}) self.assertEqual(1, versions_container.info()['object_count']) # if we overwrite it again, there are two versions versioned_obj.write(""ccccc"") self.assertEqual(2, versions_container.info()['object_count']) versioned_obj_name = versions_container.files()[1] prev_version = versions_container.file(versioned_obj_name) prev_version.initialize() self.assertEqual(""bbbbb"", prev_version.read()) self.assertEqual(prev_version.content_type, 'text/jibberish02') self.assertTrue('foo' in prev_version.metadata) self.assertTrue('fu' in prev_version.metadata) # as we delete things, the old contents return self.assertEqual(""ccccc"", versioned_obj.read()) # test copy from a different container src_container = self.env.account.container(Utils.create_name()) self.assertTrue(src_container.create()) src_name = Utils.create_name() src_obj = src_container.file(src_name) src_obj.write(""ddddd"", hdrs={'Content-Type': 'text/jibberish04'}) src_obj.copy(container.name, obj_name) self.assertEqual(""ddddd"", versioned_obj.read()) versioned_obj.initialize() self.assertEqual(versioned_obj.content_type, 'text/jibberish04') # make sure versions container has the previous version self.assertEqual(3, versions_container.info()['object_count']) versioned_obj_name = versions_container.files()[2] prev_version = versions_container.file(versioned_obj_name) prev_version.initialize() self.assertEqual(""ccccc"", prev_version.read()) # test delete versioned_obj.delete() self.assertEqual(""ccccc"", versioned_obj.read()) versioned_obj.delete() self.assertEqual(""bbbbb"", versioned_obj.read()) versioned_obj.delete() self.assertEqual(""aaaaa"", versioned_obj.read()) self.assertEqual(0, versions_container.info()['object_count']) versioned_obj.delete() self.assertRaises(ResponseError, versioned_obj.read) def test_versioning_dlo(self): container = self.env.container versions_container = self.env.versions_container obj_name = Utils.create_name() for i in ('1', '2', '3'): time.sleep(.01) # guarantee that the timestamp changes obj_name_seg = obj_name + '/' + i versioned_obj = container.file(obj_name_seg) versioned_obj.write(i) versioned_obj.write(i + i) self.assertEqual(3, versions_container.info()['object_count']) man_file = container.file(obj_name) man_file.write('', hdrs={""X-Object-Manifest"": ""%s/%s/"" % (self.env.container.name, obj_name)}) # guarantee that the timestamp changes time.sleep(.01) # write manifest file again man_file.write('', hdrs={""X-Object-Manifest"": ""%s/%s/"" % (self.env.container.name, obj_name)}) self.assertEqual(3, versions_container.info()['object_count']) self.assertEqual(""112233"", man_file.read()) def test_versioning_container_acl(self): # create versions container and DO NOT give write access to account2 versions_container = self.env.account.container(Utils.create_name()) self.assertTrue(versions_container.create(hdrs={ 'X-Container-Write': '' })) # check account2 cannot write to versions container fail_obj_name = Utils.create_name() fail_obj = versions_container.file(fail_obj_name) self.assertRaises(ResponseError, fail_obj.write, ""should fail"", cfg={'use_token': self.env.storage_token2}) # create container and give write access to account2 # don't set X-Versions-Location just yet container = self.env.account.container(Utils.create_name()) self.assertTrue(container.create(hdrs={ 'X-Container-Write': self.env.conn2.user_acl})) # check account2 cannot set X-Versions-Location on container self.assertRaises(ResponseError, container.update_metadata, hdrs={ 'X-Versions-Location': versions_container}, cfg={'use_token': self.env.storage_token2}) # good! now let admin set the X-Versions-Location # p.s.: sticking a 'x-remove' header here to test precedence # of both headers. Setting the location should succeed. self.assertTrue(container.update_metadata(hdrs={ 'X-Remove-Versions-Location': versions_container, 'X-Versions-Location': versions_container})) # write object twice to container and check version obj_name = Utils.create_name() versioned_obj = container.file(obj_name) self.assertTrue(versioned_obj.write(""never argue with the data"", cfg={'use_token': self.env.storage_token2})) self.assertEqual(versioned_obj.read(), ""never argue with the data"") self.assertTrue( versioned_obj.write(""we don't have no beer, just tequila"", cfg={'use_token': self.env.storage_token2})) self.assertEqual(versioned_obj.read(), ""we don't have no beer, just tequila"") self.assertEqual(1, versions_container.info()['object_count']) # read the original uploaded object for filename in versions_container.files(): backup_file = versions_container.file(filename) break self.assertEqual(backup_file.read(), ""never argue with the data"") # user3 (some random user with no access to anything) # tries to read from versioned container self.assertRaises(ResponseError, backup_file.read, cfg={'use_token': self.env.storage_token3}) # user3 cannot write or delete from source container either self.assertRaises(ResponseError, versioned_obj.write, ""some random user trying to write data"", cfg={'use_token': self.env.storage_token3}) self.assertRaises(ResponseError, versioned_obj.delete, cfg={'use_token': self.env.storage_token3}) # user2 can't read or delete from versions-location self.assertRaises(ResponseError, backup_file.read, cfg={'use_token': self.env.storage_token2}) self.assertRaises(ResponseError, backup_file.delete, cfg={'use_token': self.env.storage_token2}) # but is able to delete from the source container # this could be a helpful scenario for dev ops that want to setup # just one container to hold object versions of multiple containers # and each one of those containers are owned by different users self.assertTrue(versioned_obj.delete( cfg={'use_token': self.env.storage_token2})) # tear-down since we create these containers here # and not in self.env versions_container.delete_recursive() container.delete_recursive() def test_versioning_check_acl(self): container = self.env.container versions_container = self.env.versions_container versions_container.create(hdrs={'X-Container-Read': '.r:*,.rlistings'}) obj_name = Utils.create_name() versioned_obj = container.file(obj_name) versioned_obj.write(""aaaaa"") self.assertEqual(""aaaaa"", versioned_obj.read()) versioned_obj.write(""bbbbb"") self.assertEqual(""bbbbb"", versioned_obj.read()) # Use token from second account and try to delete the object org_token = self.env.account.conn.storage_token self.env.account.conn.storage_token = self.env.conn2.storage_token try: self.assertRaises(ResponseError, versioned_obj.delete) finally: self.env.account.conn.storage_token = org_token # Verify with token from first account self.assertEqual(""bbbbb"", versioned_obj.read()) versioned_obj.delete() self.assertEqual(""aaaaa"", versioned_obj.read()) class TestObjectVersioningUTF8(Base2, TestObjectVersioning): set_up = False class TestCrossPolicyObjectVersioning(TestObjectVersioning): env = TestCrossPolicyObjectVersioningEnv set_up = False def setUp(self): super(TestCrossPolicyObjectVersioning, self).setUp() if self.env.multiple_policies_enabled is False: raise SkipTest('Cross policy test requires multiple policies') elif self.env.multiple_policies_enabled is not True: # just some sanity checking raise Exception(""Expected multiple_policies_enabled "" ""to be True/False, got %r"" % ( self.env.versioning_enabled,)) if __name__ == '__main__': unittest.main() ",,2107,1571
openstack%2Frally~master~If475e08ee7952b7025f859b92bf8d33e25f787de,openstack/rally,master,If475e08ee7952b7025f859b92bf8d33e25f787de,VM-VM throughput L2/L3 scenario support,NEW,2015-02-01 02:53:16.000000000,2017-12-18 05:30:32.000000000,,"[{'_account_id': 6172}, {'_account_id': 6835}, {'_account_id': 8576}, {'_account_id': 12395}, {'_account_id': 13555}, {'_account_id': 14817}, {'_account_id': 16215}]","[{'number': 1, 'created': '2015-02-01 02:53:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c3f4bc650a3d347a69f7730edf4552fcf35e409b', 'message': 'Changes for scenario for VM-VM throughput L2/L3\nFor now it supports iperf/TCP but plan is to support nuttcp by adding a new nuttcp class\nOnce my other boot_hypervisor_test review is merged i will provide ability to control same/different host\n\nChange-Id: If475e08ee7952b7025f859b92bf8d33e25f787de\n'}, {'number': 2, 'created': '2015-05-07 19:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c81a90012782aa9aa3a8453c2c106b9c6aa2be1b', 'message': 'Changes for scenario for VM-VM throughput L2/L3\nFor now it supports iperf/TCP but plan is to support nuttcp by adding a new nuttcp class\nOnce my other boot_hypervisor_test review is merged i will provide ability to control same/different host\n\nChange-Id: If475e08ee7952b7025f859b92bf8d33e25f787de\n'}, {'number': 3, 'created': '2015-05-07 21:56:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/abedc7332e50d2be3cdf7a675e61b3c006bfbd88', 'message': 'Changes for scenario for VM-VM throughput L2/L3\nFor now it supports iperf/TCP but plan is to support nuttcp by adding a new nuttcp class\nOnce my other boot_hypervisor_test review is merged i will provide ability to control same/different host\n\nChange-Id: If475e08ee7952b7025f859b92bf8d33e25f787de\n'}, {'number': 4, 'created': '2015-05-07 22:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3eb643a77c982571d7b959b1e1d6cbd40a3494e7', 'message': 'Changes for scenario for VM-VM throughput L2/L3\nFor now it supports iperf/TCP but plan is to support nuttcp by adding a new nuttcp class\nOnce my other boot_hypervisor_test review is merged i will provide ability to control same/different host\n\nChange-Id: If475e08ee7952b7025f859b92bf8d33e25f787de\n'}, {'number': 5, 'created': '2015-06-08 08:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/229e1da32fda6ee3a8cee496429a620abc683de6', 'message': 'VM-VM throughput L2/L3 scenario support\n\nMeasures throughput between 2 VMs booted from a custom image\nwith pre-instaled iperf.\n\nChange-Id: If475e08ee7952b7025f859b92bf8d33e25f787de\n'}, {'number': 6, 'created': '2015-07-21 23:07:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4e0a55b3b62b77b4a5b8c398bbebde0b2fd5bf3a', 'message': 'VM-VM throughput L2/L3 scenario support\n\nMeasures throughput between 2 VMs booted from a custom image\nwith pre-instaled iperf.\n\nChange-Id: If475e08ee7952b7025f859b92bf8d33e25f787de\n'}, {'number': 7, 'created': '2015-08-18 08:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e673095981b65d40929d7f198f4bd7847d787c9e', 'message': 'VM-VM throughput L2/L3 scenario support\n\nMeasures throughput between 2 VMs booted from a custom image\nwith pre-instaled iperf.\n\nChange-Id: If475e08ee7952b7025f859b92bf8d33e25f787de\n'}, {'number': 8, 'created': '2015-08-19 09:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c1c23cd75b2e34c49d08d3be194315b6ba120e34', 'message': 'VM-VM throughput L2/L3 scenario support\n\nMeasures throughput between 2 VMs booted from a custom image\nwith pre-instaled iperf.\n\nChange-Id: If475e08ee7952b7025f859b92bf8d33e25f787de\n'}, {'number': 9, 'created': '2015-08-19 09:56:07.000000000', 'files': ['samples/tasks/scenarios/vm/boot-runperf-delete.yaml', 'tests/unit/plugins/openstack/scenarios/vm/test_vmperf.py', 'rally/plugins/openstack/scenarios/vm/vm_perf.py', 'rally/plugins/openstack/context/vm/simple_tool_custom_image.py', 'rally/plugins/openstack/context/network/networks.py', 'samples/tasks/scenarios/vm/boot-runperf-delete.json'], 'web_link': 'https://opendev.org/openstack/rally/commit/d1620812d1c80970cc7ea80c5d1e32b570506b93', 'message': 'VM-VM throughput L2/L3 scenario support\n\nMeasures throughput between 2 VMs booted from a custom image\nwith pre-instaled iperf.\n\nChange-Id: If475e08ee7952b7025f859b92bf8d33e25f787de\n'}]",45,151905,d1620812d1c80970cc7ea80c5d1e32b570506b93,40,7,9,14924,,,0,"VM-VM throughput L2/L3 scenario support

Measures throughput between 2 VMs booted from a custom image
with pre-instaled iperf.

Change-Id: If475e08ee7952b7025f859b92bf8d33e25f787de
",git fetch https://review.opendev.org/openstack/rally refs/changes/05/151905/6 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/vm/vm_perf.py', 'rally/benchmark/scenarios/vm/instance.py', 'rally/common/sshutils.py', 'rally/benchmark/scenarios/vm/IperfInstance.py', 'rally/benchmark/scenarios/vm/tools/iperf', 'samples/tasks/scenarios/vm/boot-runperf-delete.json']",6,c3f4bc650a3d347a69f7730edf4552fcf35e409b,(detached,"{ ""VMPerf.boot_runperf_delete"": [ { ""args"": { ""flavor"": { ""name"": ""m1.small"" }, ""image"": { ""name"": ""Ubuntu Server 14.04"" }, ""src_file"": ""rally/benchmark/scenarios/vm/tools/iperf"", ""dst_file"": ""/tmp/iperf"", ""availability_zone"": ""nova"", ""fixed_network"": ""net04"", ""fixed_network_different"": ""net05"", ""floating_network"": ""net04_ext"", ""use_floatingip"": true, ""vm_case"" : ""all"", ""username"": ""ubuntu"" }, ""runner"": { ""type"": ""constant"", ""times"": 1, ""concurrency"": 1 }, ""context"": { ""users"": { ""tenants"": 1, ""users_per_tenant"": 1 }, ""network"": { ""start_cidr"": ""10.0.0.0/16"" } } } ] } ",,439,1
openstack%2Frally~master~I6c3edc83ca4537716bda57d0960b1d606021586f,openstack/rally,master,I6c3edc83ca4537716bda57d0960b1d606021586f,Use proper error msg for image/flavor validation,NEW,2015-08-14 02:41:47.000000000,2017-12-18 05:30:15.000000000,,"[{'_account_id': 6172}, {'_account_id': 6835}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 17265}]","[{'number': 1, 'created': '2015-08-14 02:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c6b18cbd2385043bc5d33b13974b6b48c5a4caff', 'message': 'Use proper error message on scenario validation\n\nIn validation of scenario, use error message that are\ngenerated by rally.task.types.ResourceType instead of\n""Image \'%s\' not found"" or ""Flavor \'%s\' not found"".\n\nChange-Id: I6c3edc83ca4537716bda57d0960b1d606021586f\nCloses-Bug: 1484756\n'}, {'number': 2, 'created': '2015-08-19 02:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3f4c0192a96de01913e38d369b3b2f96d9d8cb3a', 'message': 'Use proper error msg for image/flavor validation\n\nRally could match image/flavor from the name. A 404 means resource not\nfound. And there will be multiple matches for one name. Improve error\nmessage could help rally users.\n\nChange-Id: I6c3edc83ca4537716bda57d0960b1d606021586f\nCloses-Bug: 1484756\n'}, {'number': 3, 'created': '2015-10-08 16:44:55.000000000', 'files': ['rally/task/validation.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/5ddef1b5dee788ccd0ab15d0640677d7e72a993c', 'message': 'Use proper error msg for image/flavor validation\n\nRally could match image/flavor from the name. A 404 means resource not\nfound. And there will be multiple matches for one name. Improve error\nmessage could help rally users.\n\nCo-Authored-By: Kun Huang <gareth@openstacker.org>\n\nChange-Id: I6c3edc83ca4537716bda57d0960b1d606021586f\nCloses-Bug: 1484756\n'}]",4,212918,5ddef1b5dee788ccd0ab15d0640677d7e72a993c,30,5,3,17265,,,0,"Use proper error msg for image/flavor validation

Rally could match image/flavor from the name. A 404 means resource not
found. And there will be multiple matches for one name. Improve error
message could help rally users.

Co-Authored-By: Kun Huang <gareth@openstacker.org>

Change-Id: I6c3edc83ca4537716bda57d0960b1d606021586f
Closes-Bug: 1484756
",git fetch https://review.opendev.org/openstack/rally refs/changes/18/212918/2 && git format-patch -1 --stdout FETCH_HEAD,['rally/task/validation.py'],1,c6b18cbd2385043bc5d33b13974b6b48c5a4caff,bug/1484756," except glance_exc.HTTPNotFound: except exceptions.InvalidScenarioArgument as e: return (ValidationResult(False, e.kwargs), None) except (nova_exc.NotFound, exceptions.InvalidScenarioArgument) as e: if isinstance(e, exceptions.InvalidScenarioArgument): message = e.kwargs else: message = _(""Flavor '%s' not found"") % flavor_value"," except (glance_exc.HTTPNotFound, exceptions.InvalidScenarioArgument): except (nova_exc.NotFound, exceptions.InvalidScenarioArgument): message = _(""Flavor '%s' not found"") % flavor_value",8,3
openstack%2Frally~master~Ie7b062d5e866a17a040c47ca6e190e8b513ae569,openstack/rally,master,Ie7b062d5e866a17a040c47ca6e190e8b513ae569,Adding documentation on installing Rally with a proxy server,NEW,2015-11-03 04:33:52.000000000,2017-12-18 05:30:10.000000000,,"[{'_account_id': 4428}, {'_account_id': 6172}, {'_account_id': 6835}, {'_account_id': 7369}, {'_account_id': 14817}, {'_account_id': 16365}, {'_account_id': 18785}]","[{'number': 1, 'created': '2015-11-03 04:33:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5f05ffe7e651bf22e2f510ea8626d87fa370b0bb', 'message': 'Adding documentation on installing Rally with a proxy server\n\nChange-Id: Ie7b062d5e866a17a040c47ca6e190e8b513ae569\n'}, {'number': 2, 'created': '2015-11-04 05:19:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6ed9d509bf359bf8b02194ba18249e9b6ab4ed85', 'message': 'Adding documentation on installing Rally with a proxy server\n\n* Rewrote statements\n* Adding pip parameters\n\nChange-Id: Ie7b062d5e866a17a040c47ca6e190e8b513ae569\n'}, {'number': 3, 'created': '2015-11-06 18:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bf11c7537a127998134f4bcbd591969b8ed368e7', 'message': 'Adding documentation on installing Rally with a proxy server\n\nAdding patch for the install script\n\nChange-Id: Ie7b062d5e866a17a040c47ca6e190e8b513ae569\n'}, {'number': 4, 'created': '2015-11-10 12:24:41.000000000', 'files': ['doc/source/install.rst', 'install_rally-proxy.sh', 'install-patch.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/609c0ccbc65b2c648dfcf88aab1f42cd629ce383', 'message': 'Adding documentation on installing Rally with a proxy server\n\nAdding install rally with proxy info\n\nChange-Id: Ie7b062d5e866a17a040c47ca6e190e8b513ae569\n'}]",12,241095,609c0ccbc65b2c648dfcf88aab1f42cd629ce383,26,7,4,16365,,,0,"Adding documentation on installing Rally with a proxy server

Adding install rally with proxy info

Change-Id: Ie7b062d5e866a17a040c47ca6e190e8b513ae569
",git fetch https://review.opendev.org/openstack/rally refs/changes/95/241095/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install.rst'],1,5f05ffe7e651bf22e2f510ea8626d87fa370b0bb,proxy," Rally Installation in a Proxy Environment First you need the proxy information, and your network administator can provide details. Since the global proxy settings did not work in the RHEL 7 (CentOS 7, will be the same), a few updates needed to be applied. Settings for pip, wget, and git are needed for the Proxy settings. Whereas, settings for wget and git are set outside the installation script the pip will be set inside the installation script. instructions for the settings can be found at <https://github.com/itlinux/rally.git/>`_. For each service http, https or ftp use the sed command. .. code-block:: bash sed -i -e ""s/#http_proxy = http:\/\/proxy.yoyodyne.com:18023/http_proxy = http:\/\/proxy.remo.com:8080/g"" /etc/wgetrc sed -i -e ""s/#http_proxy = https:\/\/proxy.yoyodyne.com:18023/http_proxy = https:\/\/proxy.remo.com:8080/g"" /etc/wgetrc sed -i -e ""s/#ftp_proxy = http:\/\/proxy.yoyodyne.com:18023/http_proxy = http:\/\/proxy.remo.com:8080/g"" /etc/wgetrc for the pip proxy set the following: git since git does not like the proxy settings from the shell you need to set the proxy into the global variable for the git config file. .. code-block:: bash git config --global http.proxy http://proxy.remo:8080",,33,0
openstack%2Fbifrost~master~I563d77b37c156dbd29169d0939a84fb4e1e36141,openstack/bifrost,master,I563d77b37c156dbd29169d0939a84fb4e1e36141,Allow explicitly setting nginx/controller IP,NEW,2015-08-31 21:01:27.000000000,2017-12-18 05:29:58.000000000,,"[{'_account_id': 10035}, {'_account_id': 11655}]","[{'number': 1, 'created': '2015-08-31 21:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/12b7498aff80c81cd8f2fdf41fce9ae9e5050869', 'message': ""Allow explicitly setting nginx/controller IP\n\nThe controller and nginx arent always accessible over the same network\nthat ansible reports as the host's IP address. Allow the IP address for\nthese services to be set via configuration.\n\nChange-Id: I563d77b37c156dbd29169d0939a84fb4e1e36141\n""}, {'number': 2, 'created': '2015-08-31 21:20:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/f8c55fae79f1e0dbdbec07e3b6a0f8f1722673da', 'message': ""Allow explicitly setting nginx/controller IP\n\nThe controller and nginx arent always accessible over the same network\nthat ansible reports as the host's IP address. Allow the IP address for\nthese services to be set via configuration.\n\nChange-Id: I563d77b37c156dbd29169d0939a84fb4e1e36141\n""}, {'number': 3, 'created': '2015-09-02 17:10:14.000000000', 'files': ['playbooks/inventory/group_vars/baremetal', 'playbooks/inventory/group_vars/localhost', 'playbooks/roles/bifrost-ironic-install/templates/dnsmasq.conf.j2', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/roles/bifrost-ironic-install/tasks/ironic_config.yml', 'playbooks/roles/bifrost-deploy-nodes-dynamic/tasks/main.yml', 'playbooks/roles/ironic-enroll-dynamic/defaults/main.yml', 'playbooks/roles/bifrost-setup-nodes/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/27c69b086d26e4c231d38348001ee113524068bc', 'message': ""Allow explicitly setting nginx/controller IP\n\nThe controller and nginx arent always accessible over the same network\nthat ansible reports as the host's IP address. Allow the IP address for\nthese services to be set via configuration.\n\nChange-Id: I563d77b37c156dbd29169d0939a84fb4e1e36141\n""}]",3,219026,27c69b086d26e4c231d38348001ee113524068bc,9,2,3,10035,,,0,"Allow explicitly setting nginx/controller IP

The controller and nginx arent always accessible over the same network
that ansible reports as the host's IP address. Allow the IP address for
these services to be set via configuration.

Change-Id: I563d77b37c156dbd29169d0939a84fb4e1e36141
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/26/219026/3 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/inventory/group_vars/baremetal', 'playbooks/inventory/group_vars/localhost', 'playbooks/roles/bifrost-ironic-install/templates/dnsmasq.conf.j2', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/roles/bifrost-ironic-install/tasks/ironic_config.yml', 'playbooks/roles/bifrost-ironic-install/templates/agent_config.template.j2', 'playbooks/roles/ironic-enroll-dynamic/defaults/main.yml', 'playbooks/roles/bifrost-setup-nodes/tasks/main.yml']",8,12b7498aff80c81cd8f2fdf41fce9ae9e5050869,feature/ecplicit-controller-ip," config_drive: ""http://{{nginx_ip}}:{{nginx_port}}/configdrive-{{item.split(',')[9]}}.iso.gz"" instance_info: image_source: ""http://{{nginx_ip}}:{{nginx_port}}/{{deploy_image_filename}}"""," config_drive: ""http://{{ hostvars[inventory_hostname]['ansible_' + network_interface]['ipv4']['address'] }}:{{nginx_port}}/configdrive-{{item.split(',')[9]}}.iso.gz"" instance_info: image_source: ""http://{{ hostvars[inventory_hostname]['ansible_' + network_interface]['ipv4']['address'] }}:{{nginx_port}}/{{deploy_image_filename}}""",16,16
openstack%2Fdevstack-gate~master~I8b0ae72c18222d50a05d28ef4154393db45ab883,openstack/devstack-gate,master,I8b0ae72c18222d50a05d28ef4154393db45ab883,Allow to save custom product logs,NEW,2015-11-02 10:03:57.000000000,2017-12-18 05:29:46.000000000,,"[{'_account_id': 7118}, {'_account_id': 8871}, {'_account_id': 12408}, {'_account_id': 13431}]","[{'number': 1, 'created': '2015-11-02 10:03:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/bbcc12749994302f408e18469f122c466b260ca9', 'message': 'Allow to save custom product logs\n\nThey are usually useful for third-party software tested with dsvm jobs.\n\nUsage scenario:\n1) Add this to the job:\nexport DEVSTACK_GATE_CUSTOM_LOGS=""/var/log/vzctl.log /var/log/parallels.log""\n2) Find saved logs in ""custom"" subfolder.\n\nChange-Id: I8b0ae72c18222d50a05d28ef4154393db45ab883\n'}, {'number': 2, 'created': '2015-11-02 11:19:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/d226f85442c2dfb99cf9ea424bca3cf1ee4241f0', 'message': 'Allow to save custom product logs\n\nThey are usually useful for third-party software tested with dsvm jobs.\n\nUsage scenario:\n1) Add this to the job:\nexport DEVSTACK_GATE_CUSTOM_LOGS=""/var/log/vzctl.log /var/log/parallels.log""\n2) Find saved logs in ""custom"" subfolder.\n\nChange-Id: I8b0ae72c18222d50a05d28ef4154393db45ab883\n'}, {'number': 3, 'created': '2015-11-10 14:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/4563fb0cb9975d93982df9b9478228d2970206d7', 'message': 'Allow to save custom product logs\n\nThey are usually useful for third-party software tested with dsvm jobs.\n\nUsage scenario:\n1) Add this to the job:\nexport DEVSTACK_GATE_CUSTOM_LOGS=""/var/log/vzctl.log /var/log/parallels.log""\n2) Find saved logs in ""custom"" subfolder.\n\nChange-Id: I8b0ae72c18222d50a05d28ef4154393db45ab883\n'}, {'number': 4, 'created': '2015-11-23 14:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/cf1f17ca1e6ce6545aa072f03885fb18c0a0ec81', 'message': 'Allow to save custom product logs\n\nThey are usually useful for third-party software tested with dsvm jobs.\n\nUsage scenario:\n1) Add this to the job:\nexport DEVSTACK_GATE_THIRDPARTY_LOGS=""/var/log/vzctl.log /var/log/parallels.log""\n2) Find saved logs in ""thirdparty"" subfolder.\n\nChange-Id: I8b0ae72c18222d50a05d28ef4154393db45ab883\n'}, {'number': 5, 'created': '2015-11-23 14:53:38.000000000', 'files': ['functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/5a287b59f9af452d454d78a0bb259876cc0259cc', 'message': 'Allow to save custom product logs\n\nThey are usually useful for third-party software tested with dsvm jobs.\n\nUsage scenario:\n1) Add this to the job:\nexport DEVSTACK_GATE_THIRDPARTY_LOGS=""/var/log/vzctl.log /var/log/parallels.log""\n2) Find saved logs in ""thirdparty"" subfolder.\n\nChange-Id: I8b0ae72c18222d50a05d28ef4154393db45ab883\n'}]",1,240813,5a287b59f9af452d454d78a0bb259876cc0259cc,18,4,5,13431,,,0,"Allow to save custom product logs

They are usually useful for third-party software tested with dsvm jobs.

Usage scenario:
1) Add this to the job:
export DEVSTACK_GATE_THIRDPARTY_LOGS=""/var/log/vzctl.log /var/log/parallels.log""
2) Find saved logs in ""thirdparty"" subfolder.

Change-Id: I8b0ae72c18222d50a05d28ef4154393db45ab883
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/13/240813/2 && git format-patch -1 --stdout FETCH_HEAD,['functions.sh'],1,bbcc12749994302f408e18469f122c466b260ca9,custom_logs," if [[ -n ""$DEVSTACK_GATE_CUSTOM_LOGS"" ]]; then if [[ ! -d $BASE/logs/custom ]]; then sudo mkdir $BASE/logs/custom fi for log in ""$DEVSTACK_GATE_CUSTOM_LOGS""; do if [[ -f ""$log"" ]]; then sudo cp ""$log"" $BASE/logs/custom fi done fi ",,11,0
openstack%2Frally~master~Ib4bc836bbc47312a496df7f56b10dcc099fb6154,openstack/rally,master,Ib4bc836bbc47312a496df7f56b10dcc099fb6154,[WIP]Add verify export command,NEW,2015-12-08 14:48:29.000000000,2017-12-18 05:29:29.000000000,,[{'_account_id': 14817}],"[{'number': 1, 'created': '2015-12-08 14:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bbe6bd4194b106bce97b81bf4264f4db2a682f73', 'message': ""[WIP]Add verify export command\n\nSuper WIP! Don't revew it. Don't waste you time.\n\nChange-Id: Ib4bc836bbc47312a496df7f56b10dcc099fb6154\n""}, {'number': 2, 'created': '2015-12-08 14:55:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e3c1265b52e4ff5a19fb740fb39d0495d7279054', 'message': ""[WIP]Add verify export command\n\nSuper WIP! Don't review it. Don't waste your time.\n\nChange-Id: Ib4bc836bbc47312a496df7f56b10dcc099fb6154\n""}, {'number': 3, 'created': '2015-12-08 15:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b9e1e563bdd0e2b3386f166f74d564d60eddc224', 'message': ""[WIP]Add verify export command\n\nSuper WIP! Don't review it. Don't waste your time.\n\nChange-Id: Ib4bc836bbc47312a496df7f56b10dcc099fb6154\n""}, {'number': 4, 'created': '2015-12-08 17:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cbd58b57a8086f986345732ccfd33b0bd580f184', 'message': ""[WIP]Add verify export command\n\nSuper WIP! Don't review it. Don't waste your time.\n\nChange-Id: Ib4bc836bbc47312a496df7f56b10dcc099fb6154\n""}, {'number': 5, 'created': '2015-12-09 14:26:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/13083d17ebb385a896a551c47ebb8bf5f8f2368b', 'message': ""[WIP]Add verify export command\n\nSuper WIP! Don't review it. Don't waste your time.\n\nChange-Id: Ib4bc836bbc47312a496df7f56b10dcc099fb6154\n""}, {'number': 6, 'created': '2015-12-10 14:51:41.000000000', 'files': ['rally/plugins/openstack/exporter/__init__.py', 'rally/plugins/openstack/exporter/testrail/testrail.py', 'rally/plugins/openstack/exporter/testrail/__init__.py', 'rally/task/exporter.py', 'doc/specs/in-progress/task_and_verification_export.rst', 'rally/cli/commands/verify.py', 'etc/rally.bash_completion', 'rally/plugins/common/exporter/__init__.py', 'rally/plugins/openstack/exporter/testrail/client.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/c86b79da681f15c170b4c2958a6fa997587b926e', 'message': ""[WIP]Add verify export command\n\nSuper WIP! Don't review it. Don't waste your time.\n\nChange-Id: Ib4bc836bbc47312a496df7f56b10dcc099fb6154\n""}]",0,254797,c86b79da681f15c170b4c2958a6fa997587b926e,16,1,6,12395,,,0,"[WIP]Add verify export command

Super WIP! Don't review it. Don't waste your time.

Change-Id: Ib4bc836bbc47312a496df7f56b10dcc099fb6154
",git fetch https://review.opendev.org/openstack/rally refs/changes/97/254797/6 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/storage/__init__.py', 'rally/cli/commands/verify.py', 'rally/plugins/openstack/storage/client.py', 'rally/plugins/openstack/storage/testrail.py']",4,bbe6bd4194b106bce97b81bf4264f4db2a682f73,verify_export,"from rally.common.plugin.plugin import Plugin from rally.plugins.openstack.storage import client class TestRail(Plugin): def __init__(self): pass def upload_test_results(self, client, test_run, suite_id, test_results): """""" This function allows to upload large number of test results with the minimum number of APi requests to TestRail. """""" test_cases = client.get_cases(suite_id) results = [] statuses = {} for test_result in test_results: if test_result.status in statuses: status_id = statuses[test_result.status] else: status_id = client.get_status(test_result.status)['id'] statuses[test_result.status] = status_id if 'setUpClass' in test_result.name: i = test_result.name.find('tempest') group = test_result.name[i:-1] for test in test_cases: if group in test.get(""custom_test_group""): results.append({""case_id"": test['id'], ""status_id"": status_id}) else: for test in test_cases: if test_result.name in test.get(""title""): results.append({""case_id"": test['id'], ""status_id"": status_id}) client.add_results_for_tempest_cases(test_run['id'], results)",,150,0
openstack%2Frally~master~I08f8f9cab6da8dd714fdd185f2b5bbdfaddc2299,openstack/rally,master,I08f8f9cab6da8dd714fdd185f2b5bbdfaddc2299,Add the min_seconds_per_iteration's check We need to check the min_seconds_per_iteration when rally's task is running.,NEW,2015-12-10 13:55:00.000000000,2017-12-18 05:29:17.000000000,,"[{'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-12-10 13:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a79e44098a7072d1fbfa763b3b73240fbe0306ee', 'message': ""Add the min_seconds_per_iteration's check\nWe need to check the min_seconds_per_iteration when\nrally's task is running.\n\nChange-Id: I08f8f9cab6da8dd714fdd185f2b5bbdfaddc2299\n""}, {'number': 2, 'created': '2015-12-12 09:15:13.000000000', 'files': ['samples/tasks/sla/create-and-delete-user.json', 'samples/tasks/sla/create-and-delete-user.yaml', 'rally/plugins/common/sla/iteration_time.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/4c11463a5f4e6d6ae72ad92291c782f0f99e7c3a', 'message': ""Add the min_seconds_per_iteration's check\nWe need to check the min_seconds_per_iteration when\nrally's task is running.\n\nChange-Id: I08f8f9cab6da8dd714fdd185f2b5bbdfaddc2299\n""}]",6,255883,4c11463a5f4e6d6ae72ad92291c782f0f99e7c3a,9,2,2,18069,,,0,"Add the min_seconds_per_iteration's check
We need to check the min_seconds_per_iteration when
rally's task is running.

Change-Id: I08f8f9cab6da8dd714fdd185f2b5bbdfaddc2299
",git fetch https://review.opendev.org/openstack/rally refs/changes/83/255883/1 && git format-patch -1 --stdout FETCH_HEAD,"['samples/tasks/sla/create-and-delete-user.json', 'samples/tasks/sla/create-and-delete-user.yaml', 'rally/plugins/common/sla/iteration_time.py']",3,a79e44098a7072d1fbfa763b3b73240fbe0306ee,,"from rally import consts@sla.configure(name=""seconds_per_iteration"") class IterationTime(sla.SLA): """"""Maximum and Minimum time for one iteration in seconds."""""" CONFIG_SCHEMA = { ""type"": ""object"", ""$schema"": consts.JSON_SCHEMA, ""properties"": { ""max_seconds_per_iteration"": {""type"": ""number"", ""minimum"": 0.0, ""exclusiveMinimum"": True}, ""max_seconds_per_iteration"": {""type"": ""number"", ""minimum"": 0.0, ""exclusiveMinimum"": True} } } self.max_iteration_time = self.criterion_value.get( ""max_seconds_per_iteration"", 0) self.min_iteration_time = self.criterion_value.get( ""min_seconds_per_iteration"", 0) self.duration = 0.0 self.duration = iteration[""duration""] self.success = (self.min_iteration_time <= self.duration <= self.max_iteration_time) self.success = (self.min_iteration_time <= other.duration <= self.max_iteration_time) return (_(""Seconds per iteration %.2fs <= %.2fs <= %.2fs - %s"") % (self.min_iteration_time, self.duration, self.max_iteration_time, self.status()))","@sla.configure(name=""max_seconds_per_iteration"") class IterationTime(sla.SLA): """"""Maximum time for one iteration in seconds."""""" CONFIG_SCHEMA = {""type"": ""number"", ""minimum"": 0.0, ""exclusiveMinimum"": True} self.max_iteration_time = 0.0 if iteration[""duration""] > self.max_iteration_time: self.max_iteration_time = iteration[""duration""] self.success = self.max_iteration_time <= self.criterion_value if other.max_iteration_time > self.max_iteration_time: self.max_iteration_time = other.max_iteration_time self.success = self.max_iteration_time <= self.criterion_value return (_(""Maximum seconds per iteration %.2fs <= %.2fs - %s"") % (self.max_iteration_time, self.criterion_value, self.status()))",32,15
openstack%2Ftacker-specs~master~If1cc2aa0c063ebf4be251893cc1cf6630021ca0c,openstack/tacker-specs,master,If1cc2aa0c063ebf4be251893cc1cf6630021ca0c,Adds autoscaling support,NEW,2015-08-18 18:26:40.000000000,2017-12-18 05:28:58.000000000,,"[{'_account_id': 2874}, {'_account_id': 7404}, {'_account_id': 9375}, {'_account_id': 10182}, {'_account_id': 13380}, {'_account_id': 13485}, {'_account_id': 13997}, {'_account_id': 15755}, {'_account_id': 16511}, {'_account_id': 18186}]","[{'number': 1, 'created': '2015-08-18 18:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/538232b92f08fb50679f31fb837af1c4ef5cc0f6', 'message': 'Adds autoscaling support\n\nThis specification describes at a high level the autoscaling feature for\ntacker. It leverages Ceilometer based autoscaling support in Heat.\n\nChange-Id: If1cc2aa0c063ebf4be251893cc1cf6630021ca0c\nImplements: blueprint autoscaling\n'}, {'number': 2, 'created': '2015-08-18 21:44:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/769ea52740728102e22db42483ebb7115c3165fc', 'message': 'Adds autoscaling support\n\nThis specification describes at a high level the autoscaling feature for\ntacker. It leverages Ceilometer based autoscaling support in Heat.\n\nChange-Id: If1cc2aa0c063ebf4be251893cc1cf6630021ca0c\nImplements: blueprint autoscaling\n'}, {'number': 3, 'created': '2015-09-02 22:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/ddfa4816ba958d005f4f192bdfd16f7d9e3079b9', 'message': 'Adds autoscaling support\n\nThis specification describes at a high level the autoscaling feature for\ntacker. It leverages Ceilometer based autoscaling support in Heat.\n\nChange-Id: If1cc2aa0c063ebf4be251893cc1cf6630021ca0c\nImplements: blueprint autoscaling\n'}, {'number': 4, 'created': '2015-09-02 22:16:43.000000000', 'files': ['specs/liberty/Auto-Scaling.rst'], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/391f442774aff9916e0ee7b212469b8a3fe08716', 'message': 'Adds autoscaling support\n\nThis specification describes at a high level the autoscaling feature for\ntacker. It leverages Ceilometer based autoscaling support in Heat.\n\nChange-Id: If1cc2aa0c063ebf4be251893cc1cf6630021ca0c\nImplements: blueprint autoscaling\n'}]",25,214297,391f442774aff9916e0ee7b212469b8a3fe08716,18,10,4,16116,,,0,"Adds autoscaling support

This specification describes at a high level the autoscaling feature for
tacker. It leverages Ceilometer based autoscaling support in Heat.

Change-Id: If1cc2aa0c063ebf4be251893cc1cf6630021ca0c
Implements: blueprint autoscaling
",git fetch https://review.opendev.org/openstack/tacker-specs refs/changes/97/214297/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/Auto-Scaling.rst'],1,538232b92f08fb50679f31fb837af1c4ef5cc0f6,bp/autoscaling," .. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================== Autoscaling support for VNF manager =================================== Problem description =================== Auto scaling is way by which the amount of resources assigned to a VM or VNF in our case, is increased or decreased based on the system load. VNF performance can be improved either through scaling-up, where more resources in terms of CPU cores, memory and storage are added to existing VNFs, or scaling-out, where a new VNF instance is spawned off to handle newer clients. Use Cases ---------- Proposed change =============== Tacker uses Heat for VNF orchestration and lifecycle management. In combination with Ceilometer it is possible to setup auto-scaling enviroment using Heat and Heat template resource types. Heat template OS::Heat::AutoScalingGroup resource type is used to define the resources that should be scaled. Scaling policy is specified through OS::Heat::ScalingPolicy resource type. And finally OS::Ceilometer::Alarm resource type is used to setup Alarm in Ceilometer. Alternatives ------------ Another option is to write a custom auto-scaling infrastructure just for tacker. That would be unneccessary and time consuming at this point. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- Ceilometer uses notification bus to publish events. Other end user impact --------------------- User will have to specify auto-scaling policy in TOSCA template that is used to onboard VNF. Performance Impact ------------------ Auto-scaling will require enabling various Ceilometer services, which could affect the performance of node running OpenStack. In addition Ceilometer will be using message queues to push metrics periodically and publish Alarms. Impact of additional messages on system Performance is TBD. Other deployer impact --------------------- Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Work Items ---------- 1) Updating TOSCA template to add Auto-scaling support 2) TOSCA to heat template translation code will need to handle auto-scaling tags Dependencies ============ Testing ======= Documentation Impact ==================== References ========== http://superuser.openstack.org/articles/simple-auto-scaling-environment-with-heat History ======= ",,122,0
openstack%2Ftacker~master~Ib173698b66dfafb71bcfe65129545cfca01f9712,openstack/tacker,master,Ib173698b66dfafb71bcfe65129545cfca01f9712,Implement tenant_id support for vnf-create,NEW,2015-08-24 21:18:01.000000000,2017-12-18 05:28:56.000000000,,"[{'_account_id': 13380}, {'_account_id': 13485}, {'_account_id': 16511}, {'_account_id': 18186}]","[{'number': 1, 'created': '2015-08-24 21:18:01.000000000', 'files': ['tacker/vm/drivers/heat/heat.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/5e625e3284736cf9a3f3a200497596fed9f7ab8d', 'message': 'Implement tenant_id support for vnf-create\n\nThis fix provides the support of specifying tenant_id as part of\nvnf-create command to land a vnf in a particular tenant.\n\nChange-Id: Ib173698b66dfafb71bcfe65129545cfca01f9712\nCloses-Bug: 1488243\n'}]",0,216430,5e625e3284736cf9a3f3a200497596fed9f7ab8d,6,4,1,13485,,,0,"Implement tenant_id support for vnf-create

This fix provides the support of specifying tenant_id as part of
vnf-create command to land a vnf in a particular tenant.

Change-Id: Ib173698b66dfafb71bcfe65129545cfca01f9712
Closes-Bug: 1488243
",git fetch https://review.opendev.org/openstack/tacker refs/changes/30/216430/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/vm/drivers/heat/heat.py'],1,5e625e3284736cf9a3f3a200497596fed9f7ab8d,bug/1488243," heatclient_ = HeatClient(context, device) heatclient_ = HeatClient(context, device_dict) heatclient_ = HeatClient(context, device) def __init__(self, context, device=None): if 'tenant_id' in device and device['tenant_id']: tenant_id = device['tenant_id'] kc = ks_client.Client( tenant_id=tenant_id, token=context.auth_token, auth_url=auth_url) else: kc = ks_client.Client( tenant_name=authtoken.project_name, username=authtoken.username, password=authtoken.password, auth_url=auth_url) 'tenant_name': kc.tenant_name, 'username': context.user_name, } "," heatclient_ = HeatClient(context) heatclient_ = HeatClient(context) heatclient_ = HeatClient(context) def __init__(self, context, password=None): kc = ks_client.Client( tenant_name=authtoken.project_name, username=authtoken.username, password=authtoken.password, auth_url=auth_url) 'tenant_name': authtoken.project_name, 'username': authtoken.username, }",20,11
openstack%2Fswift~master~I26fb6fb391e6e84e63c0bdb94aa705e6210e4c72,openstack/swift,master,I26fb6fb391e6e84e63c0bdb94aa705e6210e4c72,Use entrypoints for storage policy implementation lookups,NEW,2015-07-27 15:02:09.000000000,2017-12-18 05:28:39.000000000,,"[{'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 7689}, {'_account_id': 7847}, {'_account_id': 13052}, {'_account_id': 13777}]","[{'number': 1, 'created': '2015-07-27 15:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/61c37be7efc781ebdb299cd37249197119e0440e', 'message': 'Use entrypoints for storage policy implementation lookups\n\nInstead of only supporting in-tree storage policy types (and related\n`DiskFileManager` and `ObjectController` implementations), this patch\nuses Setuptools entrypoints to lookup and load them.\n\nThis should support out-of-tree implementations, for both testing as\nwell as deployment purposes, e.g. the single-process work proposed in\nhttps://review.openstack.org/#/c/159285/.\n\nThe current implementation requires 3 distinct entrypoints to be\ndefined. A later refactoring could turn it into one which points to all\nrequired classes.\n\nChange-Id: I26fb6fb391e6e84e63c0bdb94aa705e6210e4c72\n'}, {'number': 2, 'created': '2015-08-03 12:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5f35e7a9f97b3633d229b01be35f2c1049a42fa1', 'message': 'Use entrypoints for storage policy implementation lookups\n\nInstead of only supporting in-tree storage policy types (and related\n`DiskFileManager` and `ObjectController` implementations), this patch\nuses Setuptools entrypoints to lookup and load them.\n\nThis should support out-of-tree implementations, for both testing as\nwell as deployment purposes, e.g. the single-process work proposed in\nhttps://review.openstack.org/#/c/159285/.\n\nThe current implementation requires 3 distinct entrypoints to be\ndefined. A later refactoring could turn it into one which points to all\nrequired classes.\n\nChange-Id: I26fb6fb391e6e84e63c0bdb94aa705e6210e4c72\n'}, {'number': 3, 'created': '2015-11-30 22:29:58.000000000', 'files': ['test/unit/common/test_storage_policy.py', 'swift/common/storage_policy.py', 'test/unit/obj/test_diskfile.py', 'swift/proxy/controllers/obj.py', 'setup.cfg', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/dd3b4d28322e8b1369b8b6add78a015ee6a04617', 'message': 'Use entrypoints for storage policy implementation lookups\n\nInstead of only supporting in-tree storage policy types (and related\n`DiskFileManager` and `ObjectController` implementations), this patch\nuses Setuptools entrypoints to lookup and load them.\n\nThis should support out-of-tree implementations, for both testing as\nwell as deployment purposes, e.g. the single-process work proposed in\nhttps://review.openstack.org/#/c/159285/.\n\nThe current implementation requires 3 distinct entrypoints to be\ndefined. A later refactoring could turn it into one which points to all\nrequired classes.\n\nChange-Id: I26fb6fb391e6e84e63c0bdb94aa705e6210e4c72\n'}]",0,206105,dd3b4d28322e8b1369b8b6add78a015ee6a04617,22,7,3,13777,,,0,"Use entrypoints for storage policy implementation lookups

Instead of only supporting in-tree storage policy types (and related
`DiskFileManager` and `ObjectController` implementations), this patch
uses Setuptools entrypoints to lookup and load them.

This should support out-of-tree implementations, for both testing as
well as deployment purposes, e.g. the single-process work proposed in
https://review.openstack.org/#/c/159285/.

The current implementation requires 3 distinct entrypoints to be
defined. A later refactoring could turn it into one which points to all
required classes.

Change-Id: I26fb6fb391e6e84e63c0bdb94aa705e6210e4c72
",git fetch https://review.opendev.org/openstack/swift refs/changes/05/206105/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_storage_policy.py', 'swift/common/storage_policy.py', 'test/unit/obj/test_diskfile.py', 'setup.cfg', 'swift/proxy/controllers/obj.py', 'swift/obj/diskfile.py']",6,61c37be7efc781ebdb299cd37249197119e0440e,entrypoints,"import pkg_resources get_policy_string, split_policy_string, PolicyError, POLICIES)DISKFILE_TYPE_ENTRY_POINT_GROUP = 'swift.diskfile' def _register(cls, policy_type): This is used by `load_diskfile_types` and kept as a method for some unit tests. @classmethod def load_diskfile_types(cls): '''Load diskfile implementations for policy types''' for entry_point in pkg_resources.iter_entry_points( DISKFILE_TYPE_ENTRY_POINT_GROUP, None): policy_type = entry_point.name diskfile_cls = entry_point.load() cls._register(policy_type)(diskfile_cls) # Note: this must happen at the end of the module, otherwise entrypoints can # refer to not-yet-defined names in this module DiskFileRouter.load_diskfile_types()"," get_policy_string, split_policy_string, PolicyError, POLICIES, REPL_POLICY, EC_POLICY) def register(cls, policy_type):@DiskFileRouter.register(REPL_POLICY)@DiskFileRouter.register(EC_POLICY)",66,24
openstack%2Fswift~master~I4be21597580c60cb9455fb768164cd81346b89bb,openstack/swift,master,I4be21597580c60cb9455fb768164cd81346b89bb,object-updater runs for all async_pending directories,NEW,2014-12-12 02:50:54.000000000,2017-12-18 05:28:37.000000000,,"[{'_account_id': 330}, {'_account_id': 597}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 8859}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-12-12 02:50:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e696164d23427c3d6048d67957be7f508f2a4cfd', 'message': ""Execute object daemons' tasks according to dir information\n\nCurrently, object-auditor execute its own tasks for each 'objects-%N'\ndirectory regardless of a policy setting. This means that, for example,\nif there are 'objects', 'objects-1' and 'objects-2' directories in the\ndevice and swift.conf contains only [storage-policy:0] and\n[storage-policy:1] sections, object-auditor audits all files not only in\n'objects' and 'objects-1' directories but also in 'objects-2' directory.\n\nOn the other hand, swift.conf gets preference over real directories for\nobject-replicator and object-updater. In the above swift.conf setting,\nobject-replicator does not replicate files in 'objects-2' dir and\nobject-updater also does not update containers specified by files in\n'async_pending-2' dir.\n\nBy some operational mistakes, policy settings might be inconsistent among\nservers of swift cluster. If one background server has swift.conf file\nwhich is inconsistent with the other background servers, this makes\nbad impacts to Swift's self-healing features such as delays of file\nrepairing or the loss of data in the worst case.\n\nThis patch fixes object-repliator and object-updater to execute their\nduties on the directory basis.\n\nChange-Id: I4be21597580c60cb9455fb768164cd81346b89bb\nCloses-Bug: 1375438\n""}, {'number': 2, 'created': '2015-02-02 02:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d26b7fd9bfaaaf8d086d8cb930e3b1d52612ac2a', 'message': ""Execute object daemons' tasks according to dir information\n\nCurrently, object-auditor execute its own tasks for each 'objects-%N'\ndirectory regardless of a policy setting. This means that, for example,\nif there are 'objects', 'objects-1' and 'objects-2' directories in the\ndevice and swift.conf contains only [storage-policy:0] and\n[storage-policy:1] sections (because of some operational mistakes),\nobject-auditor audits all files not only in 'objects' and 'objects-1'\ndirectories but also in 'objects-2' directory.\n\nOn the other hand, swift.conf gets preference over real directories for\nobject-replicator and object-updater. In the above swift.conf setting,\nobject-replicator does not replicate files in 'objects-2' dir and\nobject-updater also does not update containers specified by files in\n'async_pending-2' dir.\n\nBy some operational mistakes, policy settings might be inconsistent among\nservers of swift cluster. If one background server has swift.conf file\nwhich is inconsistent with the other background servers, this makes\nbad impacts to Swift's self-healing features such as delays of file\nrepairing or the loss of data in the worst case. This patch fixes\nobject-repliator and object-updater to execute their duties on the\ndirectory basis.\n\nOne unit test of object-replicator is deleted in this commit because\nsupposed error in the previous implementation is never occurred now.\n\nChange-Id: I4be21597580c60cb9455fb768164cd81346b89bb\nCloses-Bug: 1375438\n""}, {'number': 3, 'created': '2015-02-04 04:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/853c8256c24e4fe63731176d44d2433728de1677', 'message': ""Execute object daemons' tasks according to dir information\n\nCurrently, object-auditor execute its own tasks for each 'objects-%N'\ndirectory regardless of a policy setting. This means that, for example,\nif there are 'objects', 'objects-1' and 'objects-2' directories in the\ndevice and swift.conf contains only [storage-policy:0] and\n[storage-policy:1] sections (because of some operational mistakes),\nobject-auditor audits all files not only in 'objects' and 'objects-1'\ndirectories but also in 'objects-2' directory.\n\nOn the other hand, swift.conf gets preference over real directories for\nobject-replicator and object-updater. In the above swift.conf setting,\nobject-replicator does not replicate files in 'objects-2' dir and\nobject-updater also does not update containers specified by files in\n'async_pending-2' dir.\n\nBy some operational mistakes, policy settings might be inconsistent among\nservers of swift cluster. If one background server has swift.conf file\nwhich is inconsistent with the other background servers, this makes\nbad impacts to Swift's self-healing features such as delays of file\nrepairing or the loss of data in the worst case. This patch fixes\nobject-repliator and object-updater to execute their duties on the\ndirectory basis.\n\nOne unit test of object-replicator is deleted in this commit because\nsupposed error in the previous implementation is never occurred now.\n\nChange-Id: I4be21597580c60cb9455fb768164cd81346b89bb\nCloses-Bug: 1375438\n""}, {'number': 4, 'created': '2015-02-10 21:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/26d5f948090e14fdf27c436c4e9a30927fcbddfb', 'message': ""Execute object daemons' tasks according to dir information\n\nCurrently, object-auditor executes its own tasks for each 'objects-%N'\ndirectory regardless of a policy setting. This means that, for example,\nif there are 'objects', 'objects-1' and 'objects-2' directories in the\ndevice and swift.conf contains only [storage-policy:0] and\n[storage-policy:1] sections, object-auditor audits all files not only\nin 'objects' and 'objects-1' directories but also in 'objects-2' directory.\n\nOn the other hand, swift.conf gets preference over real directories for\nobject-replicator and object-updater. In the above swift.conf setting,\nobject-replicator does not seek files in 'objects-2' dir and\nobject-updater also does not update containers specified by files in\n'async_pending-2' dir.\n\nBy some operational mistakes or other reasons, policy settings might be\ninconsistent among servers of swift cluster. If one background server\nhas swift.conf file which is inconsistent with the other background\nservers, this makes bad impacts to Swift's self-healing features such\nas delays of file repairing or, in the worst case, the loss of data.\n\nThis patch fixes object-repliator to seek all 'objects*' directories.\nIf there is 'objects-2' dir but policy 2 definition is not included in\nswift.conf, object-replicator warns that policy 2 def is not found\nin the log file to enable operators to detect something wrong in their\ncluster. And, this patch fixes object-updater to notify all object\nput/delete operations to container-server following async pending files\nbeneath all 'async_pending*' directories, regardless of policy setting.\n\nOne unit test of object-replicator is deleted in this commit because\nsupposed error in the previous implementation is never occurred now.\n\nChange-Id: I4be21597580c60cb9455fb768164cd81346b89bb\nCloses-Bug: 1375438\n""}, {'number': 5, 'created': '2015-03-10 09:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/59b9dd871ad8ffe6972b555cdfe4d627cbd02f67', 'message': ""object-updater runs for all async_pending directories\n\nCurrently, object-auditor executes its own tasks for each 'objects-%N'\ndirectory regardless of a policy setting. This means that, for example,\nif there are 'objects', 'objects-1' and 'objects-2' directories in the\ndevice and swift.conf contains only [storage-policy:0] and\n[storage-policy:1] sections, object-auditor audits all files not only\nin 'objects' and 'objects-1' directories but also in 'objects-2' directory.\n\nOn the other hand, swift.conf gets preference over real directories for\nobject-updater. In the above swift.conf setting, object-updater does not\nupdate containers specified by files in 'async_pending-2' dir.\n\nBy some operational mistakes or other reasons, policy settings might be\ninconsistent among servers of swift cluster. If one background server\nhas swift.conf file which is inconsistent with the other background\nservers, this makes bad impacts to Swift's self-healing features such\nas delays of repairing inconsistency among container DBs.\n\nThis patch fixes object-updater to notify all object put/delete operations\nto container-server following async pending files beneath all\n'async_pending*' directories, regardless of policy setting.\n\nChange-Id: I4be21597580c60cb9455fb768164cd81346b89bb\nRelated-Bug: 1375438\n""}, {'number': 6, 'created': '2015-06-25 09:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0e7a6813a85b6eb0fc2a756490582b244f92c724', 'message': ""object-updater runs for all async_pending directories\n\nCurrently, object-auditor executes its own tasks for each 'objects-%N'\ndirectory regardless of a policy setting. This means that, for example,\nif there are 'objects', 'objects-1' and 'objects-2' directories in the\ndevice and swift.conf contains only [storage-policy:0] and\n[storage-policy:1] sections, object-auditor audits all files not only\nin 'objects' and 'objects-1' directories but also in 'objects-2' directory.\n\nOn the other hand, swift.conf gets preference over real directories for\nobject-updater. In the above swift.conf setting, object-updater does not\nupdate containers specified by files in 'async_pending-2' dir.\n\nBy some operational mistakes or other reasons, policy settings might be\ninconsistent among servers of swift cluster. If one background server\nhas swift.conf file which is inconsistent with the other background\nservers, this makes bad impacts to Swift's self-healing features such\nas delays of repairing inconsistency among container DBs.\n\nThis patch fixes object-updater to notify all object put/delete operations\nto container-server following async pending files beneath all\n'async_pending*' directories, regardless of policy setting.\n\nChange-Id: I4be21597580c60cb9455fb768164cd81346b89bb\nRelated-Bug: 1375438\n""}, {'number': 7, 'created': '2015-08-11 15:51:44.000000000', 'files': ['swift/obj/updater.py', 'swift/common/storage_policy.py', 'test/unit/obj/test_updater.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/d20a9efc62253eb8b4f08ca3d20782eb82a2e1f0', 'message': ""object-updater runs for all async_pending directories\n\nCurrently, object-auditor executes its own tasks for each 'objects-%N'\ndirectory regardless of a policy setting. This means that, for example,\nif there are 'objects', 'objects-1' and 'objects-2' directories in the\ndevice and swift.conf contains only [storage-policy:0] and\n[storage-policy:1] sections, object-auditor audits all files not only\nin 'objects' and 'objects-1' directories but also in 'objects-2' directory.\n\nOn the other hand, swift.conf gets preference over real directories for\nobject-updater. In the above swift.conf setting, object-updater does not\nupdate containers specified by files in 'async_pending-2' dir.\n\nBy some operational mistakes or other reasons, policy settings might be\ninconsistent among servers of swift cluster. If one background server\nhas swift.conf file which is inconsistent with the other background\nservers, this makes bad impacts to Swift's self-healing features such\nas delays of repairing inconsistency among container DBs.\n\nThis patch fixes object-updater to notify all object put/delete operations\nto container-server following async pending files beneath all\n'async_pending*' directories, regardless of policy setting.\n\nChange-Id: I4be21597580c60cb9455fb768164cd81346b89bb\nRelated-Bug: 1375438\n""}]",11,141252,d20a9efc62253eb8b4f08ca3d20782eb82a2e1f0,40,6,7,8859,,,0,"object-updater runs for all async_pending directories

Currently, object-auditor executes its own tasks for each 'objects-%N'
directory regardless of a policy setting. This means that, for example,
if there are 'objects', 'objects-1' and 'objects-2' directories in the
device and swift.conf contains only [storage-policy:0] and
[storage-policy:1] sections, object-auditor audits all files not only
in 'objects' and 'objects-1' directories but also in 'objects-2' directory.

On the other hand, swift.conf gets preference over real directories for
object-updater. In the above swift.conf setting, object-updater does not
update containers specified by files in 'async_pending-2' dir.

By some operational mistakes or other reasons, policy settings might be
inconsistent among servers of swift cluster. If one background server
has swift.conf file which is inconsistent with the other background
servers, this makes bad impacts to Swift's self-healing features such
as delays of repairing inconsistency among container DBs.

This patch fixes object-updater to notify all object put/delete operations
to container-server following async pending files beneath all
'async_pending*' directories, regardless of policy setting.

Change-Id: I4be21597580c60cb9455fb768164cd81346b89bb
Related-Bug: 1375438
",git fetch https://review.opendev.org/openstack/swift refs/changes/52/141252/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/replicator.py', 'swift/obj/updater.py', 'test/unit/obj/test_replicator.py', 'swift/common/storage_policy.py', 'test/unit/obj/test_updater.py', 'swift/obj/diskfile.py']",6,e696164d23427c3d6048d67957be7f508f2a4cfd,bug/1375438,"def extract_policy_index(obj_path, conf_check=True): :param conf_check: flag to check if policy_index is contained in swift.conf if conf_check and POLICIES.get_by_index(policy_idx) is None:",def extract_policy_index(obj_path): if POLICIES.get_by_index(policy_idx) is None:,98,60
openstack%2Frally~master~Ief16a99c8ded9f5277a70790994f932f474acc66,openstack/rally,master,Ief16a99c8ded9f5277a70790994f932f474acc66,Add test to check shell=True in subprocess calls,NEW,2015-11-24 16:30:37.000000000,2017-12-18 05:28:35.000000000,,"[{'_account_id': 7369}, {'_account_id': 8491}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-11-24 16:30:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6089c7512e9c594b0388bce814d1d425e0023542', 'message': 'Add test to check shell=True in subprocess calls\n\nUsing shell=True may be not safe.\n\nChange-Id: Ief16a99c8ded9f5277a70790994f932f474acc66\n'}, {'number': 2, 'created': '2015-12-05 19:05:33.000000000', 'files': ['tests/unit/test_subprocess_shell.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/39ca0fad09fc58c3a965a3fc653e8be51e34faee', 'message': 'Add test to check shell=True in subprocess calls\n\nUsing shell=True may be not safe.\n\nChange-Id: Ief16a99c8ded9f5277a70790994f932f474acc66\n'}]",1,249309,39ca0fad09fc58c3a965a3fc653e8be51e34faee,48,3,2,7369,,,0,"Add test to check shell=True in subprocess calls

Using shell=True may be not safe.

Change-Id: Ief16a99c8ded9f5277a70790994f932f474acc66
",git fetch https://review.opendev.org/openstack/rally refs/changes/09/249309/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/unit/test_subprocess_shell.py'],1,6089c7512e9c594b0388bce814d1d425e0023542,shell-false-test,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import ast import os import rally from tests.unit import test class SubprocessShellChecker(ast.NodeVisitor): err_lines = [] def visit_Call(self, node): val = getattr(node.func, ""value"", None) module = getattr(val, ""id"", None) if module == ""subprocess"": for kw in node.keywords: if kw.arg == ""shell"": self.err_lines.append(node.lineno) class SubprocessShellTestCase(test.TestCase): files_path = os.path.dirname(rally.__file__) def test_subprocess_shell(self): self.skip(""Not all `shell=True` removed"") err_files = """" for dirname, dienames, filenames in os.walk(self.files_path): for filename in filenames: if not filename.endswith("".py""): continue filename = os.path.relpath(os.path.join(dirname, filename)) tree = ast.parse(open(filename, ""rb"").read(), filename) visitor = SubprocessShellChecker() visitor.visit(tree) for err_line in visitor.err_lines: err_files += ""\n%s:%s"" % (filename, err_line) if err_files: self.fail(""Please don't use shell=True with subprocess. "" ""Files affected:"" + err_files) ",,50,0
openstack%2Frally~master~I80c5120579902b342ba5c0378eeec80120d3d4a4,openstack/rally,master,I80c5120579902b342ba5c0378eeec80120d3d4a4,Adding Cue scenario tests to Rally,NEW,2015-12-17 22:39:08.000000000,2017-12-18 05:28:06.000000000,,"[{'_account_id': 9545}, {'_account_id': 12395}, {'_account_id': 13771}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-12-17 22:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2226e548e5952d654b114af2ff2e794a2d47ae3a', 'message': 'Adding Cue scenario tests to Rally\n\nChange-Id: I80c5120579902b342ba5c0378eeec80120d3d4a4\n'}, {'number': 2, 'created': '2015-12-17 22:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/937e31524970c113b72657deff899c3ba1d95c4b', 'message': 'Adding Cue scenario tests to Rally\n\nChange-Id: I80c5120579902b342ba5c0378eeec80120d3d4a4\n'}, {'number': 3, 'created': '2016-01-04 20:09:26.000000000', 'files': ['rally/consts.py', 'rally/plugins/openstack/scenarios/cue/utils.py', 'rally-jobs/rally-cue.yml', 'rally/plugins/openstack/scenarios/cue/clusters.py', 'rally/plugins/openstack/scenarios/cue/__init__.py', 'rally/plugins/openstack/context/cleanup/resources.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/d8b49c7e8ec24276ab92bb6a4dc011cb8b083091', 'message': 'Adding Cue scenario tests to Rally\n\nChange-Id: I80c5120579902b342ba5c0378eeec80120d3d4a4\n'}]",69,259204,d8b49c7e8ec24276ab92bb6a4dc011cb8b083091,15,4,3,13771,,,0,"Adding Cue scenario tests to Rally

Change-Id: I80c5120579902b342ba5c0378eeec80120d3d4a4
",git fetch https://review.opendev.org/openstack/rally refs/changes/04/259204/3 && git format-patch -1 --stdout FETCH_HEAD,"['rally/consts.py', 'rally/plugins/openstack/scenarios/cue/utils.py', 'rally-jobs/rally-cue.yml', 'rally/plugins/openstack/scenarios/cue/clusters.py', 'rally/plugins/openstack/scenarios/cue/__init__.py']",5,2226e548e5952d654b114af2ff2e794a2d47ae3a,adding_cue_scenarios,__author__ = 'davideagnello' ,,505,0
openstack%2Fdiskimage-builder~master~Ib88266119e695395cb5993d80ee84e614bc15877,openstack/diskimage-builder,master,Ib88266119e695395cb5993d80ee84e614bc15877,Ramdisk should consider the size unit when inspecting the amount of RAM,NEW,2015-08-19 19:34:05.000000000,2017-12-18 05:28:01.000000000,,"[{'_account_id': 6488}, {'_account_id': 10035}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-08-19 19:34:05.000000000', 'files': ['elements/ironic-discoverd-ramdisk/init.d/80-ironic-discoverd-ramdisk'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/cea982a25859e963bba827e848fe2e0fc4aabc97', 'message': 'Ramdisk should consider the size unit when inspecting the amount of RAM\n\nThis change converts the previous code which did not detect whether\ndmidecude was reporting MB or GB to instead use /proc/meminfo for a\nRAM discovery source, since it always reports in KB units. It then\nconverts the KB unit to the expected unit of MB.\n\nChange-Id: Ib88266119e695395cb5993d80ee84e614bc15877\nCloses-bug: #1486689\n'}]",1,214771,cea982a25859e963bba827e848fe2e0fc4aabc97,8,3,1,14072,,,0,"Ramdisk should consider the size unit when inspecting the amount of RAM

This change converts the previous code which did not detect whether
dmidecude was reporting MB or GB to instead use /proc/meminfo for a
RAM discovery source, since it always reports in KB units. It then
converts the KB unit to the expected unit of MB.

Change-Id: Ib88266119e695395cb5993d80ee84e614bc15877
Closes-bug: #1486689
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/71/214771/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/ironic-discoverd-ramdisk/init.d/80-ironic-discoverd-ramdisk'],1,cea982a25859e963bba827e848fe2e0fc4aabc97,ramdisk-unit-conversion,RAM_KB=$(cat /proc/meminfo | grep MemTotal | awk '{ print $2; }' ) RAM=$(($RAM_KB/1024)),RAM=0 for i in $(dmidecode --type memory | grep Size | awk '{ print $2; }' | grep -E '[0-9]+'); do RAM=$(( RAM + $i )); done,2,5
openstack%2Fopenstack-health~master~I5a91e66232ebc81d43f0f4c68806367a1716036b,openstack/openstack-health,master,I5a91e66232ebc81d43f0f4c68806367a1716036b,WIP: Add global failure rate to per job table on grouped_runs,NEW,2016-01-09 01:43:53.000000000,2017-12-18 05:27:56.000000000,,[{'_account_id': 5196}],"[{'number': 1, 'created': '2016-01-09 01:43:53.000000000', 'files': ['openstack_health/run_aggregator.py', 'app/js/services/health-api.js', 'openstack_health/api.py', 'app/js/controllers/grouped-runs.js', 'app/views/grouped-runs.html'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/072a0e26e5cf8e62fe9ebe9c4671cd01edf358e1', 'message': 'WIP: Add global failure rate to per job table on grouped_runs\n\nIt is often useful to compare the local filtered failure rate per job\nto the global failure rate. This commit adds a new api call to get the\nfailure rate per job type across all runs in a date range and then adds\nthe corresponding column to the table.\n\nChange-Id: I5a91e66232ebc81d43f0f4c68806367a1716036b\n'}]",0,265494,072a0e26e5cf8e62fe9ebe9c4671cd01edf358e1,4,1,1,5196,,,0,"WIP: Add global failure rate to per job table on grouped_runs

It is often useful to compare the local filtered failure rate per job
to the global failure rate. This commit adds a new api call to get the
failure rate per job type across all runs in a date range and then adds
the corresponding column to the table.

Change-Id: I5a91e66232ebc81d43f0f4c68806367a1716036b
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/94/265494/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_health/run_aggregator.py', 'app/js/services/health-api.js', 'openstack_health/api.py', 'app/js/controllers/grouped-runs.js', 'app/views/grouped-runs.html']",5,072a0e26e5cf8e62fe9ebe9c4671cd01edf358e1,," <th sort-field=""globalRate"">Global % Failed</th> <td>{{ job.globalFailureRate|number:2 }}</td>",,58,0
openstack%2Frally~master~Iaf55b60a96c62350b62a73230ab50e8f76cb4e51,openstack/rally,master,Iaf55b60a96c62350b62a73230ab50e8f76cb4e51,[Cinder] Add do_delete flag to skip deletion of resources,NEW,2015-11-19 23:43:57.000000000,2017-12-18 05:27:54.000000000,,"[{'_account_id': 1736}, {'_account_id': 7369}, {'_account_id': 8491}, {'_account_id': 8840}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-11-19 23:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3b6ba88b65338e52e6e9005d5d95c5feda8f02a1', 'message': '[Cinder] Add do_delete flag to skip deletion of resources\n\nAdd do_delete parameter to create_and_attach_volume scenarios that\ncan optionally skip the detachment of the volume along with the deletion\nof the resources allocated.\n\nChange-Id: Iaf55b60a96c62350b62a73230ab50e8f76cb4e51\n'}, {'number': 2, 'created': '2015-11-20 17:58:21.000000000', 'files': ['tests/unit/plugins/openstack/scenarios/cinder/test_volumes.py', 'rally/plugins/openstack/scenarios/cinder/volumes.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/e2767f26cfaf80e621eb44213578aa6e21611e86', 'message': '[Cinder] Add do_delete flag to skip deletion of resources\n\nAdd do_delete parameter to create_and_attach_volume scenarios that\ncan optionally skip the detachment of the volume along with the deletion\nof the resources allocated.\n\nAdd unit tests for testing both cases of do_delete.\n\nChange-Id: Iaf55b60a96c62350b62a73230ab50e8f76cb4e51\n'}]",6,247842,e2767f26cfaf80e621eb44213578aa6e21611e86,17,6,2,8840,,,0,"[Cinder] Add do_delete flag to skip deletion of resources

Add do_delete parameter to create_and_attach_volume scenarios that
can optionally skip the detachment of the volume along with the deletion
of the resources allocated.

Add unit tests for testing both cases of do_delete.

Change-Id: Iaf55b60a96c62350b62a73230ab50e8f76cb4e51
",git fetch https://review.opendev.org/openstack/rally refs/changes/42/247842/2 && git format-patch -1 --stdout FETCH_HEAD,['rally/plugins/openstack/scenarios/cinder/volumes.py'],1,3b6ba88b65338e52e6e9005d5d95c5feda8f02a1,cinder-boot-attach-volume-delete," def create_and_attach_volume(self, size, image, flavor, do_delete=True, **kwargs): Simple test to create a VM and attach a volume which is then detached and both volume and VM are deleted. :param do_delete: detaches then deletes volume and server if True if do_delete: self._detach_volume(server, volume) self._delete_volume(volume) self._delete_server(server)"," def create_and_attach_volume(self, size, image, flavor, **kwargs): Simple test to create a VM and attach a volume, then detach the volume and delete volume/VM. self._detach_volume(server, volume) self._delete_volume(volume) self._delete_server(server)",9,6
openstack%2Fswift~master~I67cd57f79cea90c86519b0647522da3b68eeaae9,openstack/swift,master,I67cd57f79cea90c86519b0647522da3b68eeaae9,Delete python bytecode before every test run,NEW,2015-12-29 13:48:35.000000000,2017-12-18 05:27:52.000000000,,"[{'_account_id': 14173}, {'_account_id': 18838}]","[{'number': 1, 'created': '2015-12-29 13:48:35.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/swift/commit/0756e9f5e58a83504860b333414bcad6d38ec022', 'message': 'Delete python bytecode before every test run\n\nBecause python creates pyc files during tox runs, certain\nchanges in the tree, like deletes of files, or switching\nbranches, can create spurious errors.\n\nChange-Id: I67cd57f79cea90c86519b0647522da3b68eeaae9\nCloses-Bug: #1368661\n'}]",0,262217,0756e9f5e58a83504860b333414bcad6d38ec022,6,2,1,14173,,,0,"Delete python bytecode before every test run

Because python creates pyc files during tox runs, certain
changes in the tree, like deletes of files, or switching
branches, can create spurious errors.

Change-Id: I67cd57f79cea90c86519b0647522da3b68eeaae9
Closes-Bug: #1368661
",git fetch https://review.opendev.org/openstack/swift refs/changes/17/262217/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0756e9f5e58a83504860b333414bcad6d38ec022,bug/1368661,"commands = find . -type f -name ""*.pyc"" -delete nosetests {posargs:test/unit}",commands = nosetests {posargs:test/unit},2,1
openstack%2Fpython-swiftclient~master~I091cdb5a048592cd4ffc295abec3747a55bcdee5,openstack/python-swiftclient,master,I091cdb5a048592cd4ffc295abec3747a55bcdee5,Add validation of -S option for SLO upload,NEW,2015-12-17 05:04:59.000000000,2017-12-18 05:27:49.000000000,,"[{'_account_id': 12965}, {'_account_id': 15343}]","[{'number': 1, 'created': '2015-12-17 05:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/aca6113d1678fd656de42829f274c8ee4b34831c', 'message': ':Add validation of -S option for SLO upload\n\nChange-Id: I091cdb5a048592cd4ffc295abec3747a55bcdee5\nCloses-bug: #1514599\n'}, {'number': 2, 'created': '2015-12-29 03:21:17.000000000', 'files': ['tests/unit/test_service.py', 'swiftclient/service.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/926dc2eedb3c84679695f41562946c3629cb5e6e', 'message': 'Add validation of -S option for SLO upload\n\nCheck if slo middleware enabled and minimum segment size exceeded\n\nChange-Id: I091cdb5a048592cd4ffc295abec3747a55bcdee5\nCloses-bug: #1514599\n'}]",3,258800,926dc2eedb3c84679695f41562946c3629cb5e6e,8,2,2,12965,,,0,"Add validation of -S option for SLO upload

Check if slo middleware enabled and minimum segment size exceeded

Change-Id: I091cdb5a048592cd4ffc295abec3747a55bcdee5
Closes-bug: #1514599
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/00/258800/2 && git format-patch -1 --stdout FETCH_HEAD,['swiftclient/service.py'],1,aca6113d1678fd656de42829f274c8ee4b34831c,bug/1514599," # Check slo capability first before sending SLO if 'use_slo' in options.keys() and options['use_slo'] is True: capabilities_result = self.capabilities() cap_info = capabilities_result['capabilities'] if 'slo' in cap_info.keys(): slo_cap_info = cap_info['slo'] if slo_cap_info['min_segment_size'] > segment_size: raise SwiftError( ""Aborting slo creation because "" ""the segment size should not be less than %s"" % slo_cap_info['min_segment_size'] ) else: raise SwiftError( ""Aborting slo creation because"" ""the slo middleware not enabled"" ) ",,18,0
openstack%2Fpython-zaqarclient~master~Id9dc6143b90ea3fed1f5ee6fda09b10d1ddf169c,openstack/python-zaqarclient,master,Id9dc6143b90ea3fed1f5ee6fda09b10d1ddf169c,WIP: support building curl command for signed url,NEW,2016-01-12 22:29:21.000000000,2017-12-18 05:27:47.000000000,,[],"[{'number': 1, 'created': '2016-01-12 22:29:21.000000000', 'files': ['zaqarclient/queues/v2/cli.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/839406f4b16c9bb7d0615ea3f92481d426ffacd9', 'message': 'WIP: support building curl command for signed url\n\nChange-Id: Id9dc6143b90ea3fed1f5ee6fda09b10d1ddf169c\n'}]",0,266598,839406f4b16c9bb7d0615ea3f92481d426ffacd9,3,0,1,12321,,,0,"WIP: support building curl command for signed url

Change-Id: Id9dc6143b90ea3fed1f5ee6fda09b10d1ddf169c
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/98/266598/1 && git format-patch -1 --stdout FETCH_HEAD,['zaqarclient/queues/v2/cli.py'],1,839406f4b16c9bb7d0615ea3f92481d426ffacd9,signed_url," curl_params = data.copy() curl_params.update({ 'host': client.api_url, 'path': data['paths'][0], 'paths': ','.join(data['paths']), 'methods': ','.join(data['methods']) }) cmd = (""curl {host}{path} "" ""--header 'URL-Signature: {signature}' "" ""--header 'URL-Expires: {expires}' "" ""--header 'URL-Methods: {methods}' "" ""--header 'URL-Paths: {paths}' "" ""--header 'X-Project-ID: {project}' "" ""--header \""Client-ID: $(uuidgen)\"""".format(**curl_params)) ",,17,0
openstack%2Fswift~master~I801917a51d7cca723cb23b29b8de4b816b647cf3,openstack/swift,master,I801917a51d7cca723cb23b29b8de4b816b647cf3,Add functional test test_copy_to_same to test_object.py,NEW,2015-07-20 21:02:07.000000000,2017-12-18 05:27:08.000000000,,"[{'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 8871}, {'_account_id': 10068}, {'_account_id': 13052}, {'_account_id': 16550}]","[{'number': 1, 'created': '2015-07-20 21:02:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cca9cb7797b6d2fe4df4c59f109fb0813411ade7', 'message': 'add test_copy_to_same\n\nChange-Id: I801917a51d7cca723cb23b29b8de4b816b647cf3\n'}, {'number': 2, 'created': '2015-07-21 17:43:22.000000000', 'files': ['test/functional/test_object.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/3711b022df991890278e95788fe43b7aaaed5f04', 'message': 'Add functional test test_copy_to_same to test_object.py\n\ntest_copy_to_same checks that metadata is preserved when the COPY destination\nis the same as the COPY source.\nAfter each POST/COPY, the test now retries get_source until the expected\nx-object-meta-bravo is found.\n\nChange-Id: I801917a51d7cca723cb23b29b8de4b816b647cf3\n'}]",7,203820,3711b022df991890278e95788fe43b7aaaed5f04,21,6,2,16550,,,0,"Add functional test test_copy_to_same to test_object.py

test_copy_to_same checks that metadata is preserved when the COPY destination
is the same as the COPY source.
After each POST/COPY, the test now retries get_source until the expected
x-object-meta-bravo is found.

Change-Id: I801917a51d7cca723cb23b29b8de4b816b647cf3
",git fetch https://review.opendev.org/openstack/swift refs/changes/20/203820/2 && git format-patch -1 --stdout FETCH_HEAD,['test/functional/test_object.py'],1,cca9cb7797b6d2fe4df4c59f109fb0813411ade7,add-copy-same-func-test," def test_copy_to_same(self): if tf.skip: raise SkipTest source = '%s/%s' % (self.container, self.obj) # oiginal expected body from setUp() setup_body = 'test' # get contents of source def get_source(url, token, parsed, conn): conn.request('GET', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) # check setUp source obj resp = retry(get_source) source_contents = resp.read() self.assertEqual(resp.status, 200) self.assertEqual(source_contents, setup_body) # post orig metadata def post_meta_fruit(url, token, parsed, conn): conn.request('POST', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token, 'X-Object-Meta-Alfa': 'apple', 'X-Object-Meta-Bravo': 'banana'}) return check_response(conn) resp = retry(post_meta_fruit) resp.read() self.assertEqual(resp.status, 202) # accepted # check orig metadata resp = retry(get_source) source_contents = resp.read() self.assertEqual(resp.status, 200) self.assertEqual(resp.getheader('x-object-meta-alfa'), 'apple') self.assertEqual(resp.getheader('x-object-meta-bravo'), 'banana') self.assertEqual(resp.getheader('x-object-meta-charlie'), None) self.assertEqual(source_contents, setup_body) # copy source to source with COPY # incrementally add/modify some metadata def copy_to_same(url, token, parsed, conn): conn.request('COPY', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token, 'Destination': source, 'X-Object-Meta-Bravo': 'boat', 'X-Object-Meta-Charlie': 'car'}) return check_response(conn) resp = retry(copy_to_same) resp.read() self.assertEqual(resp.status, 201) # check metadata after copy_to_same resp = retry(get_source) source_contents = resp.read() self.assertEqual(resp.status, 200) self.assertEqual(resp.getheader('x-object-meta-alfa'), 'apple') self.assertEqual(resp.getheader('x-object-meta-bravo'), 'boat') self.assertEqual(resp.getheader('x-object-meta-charlie'), 'car') self.assertEqual(source_contents, setup_body) def post_meta_animals(url, token, parsed, conn): conn.request('POST', '%s/%s/%s' % ( parsed.path, self.container, self.obj), '', {'X-Auth-Token': token, 'X-Object-Meta-Alfa': 'aardvark', 'X-Object-Meta-Bravo': 'bird'}) return check_response(conn) resp = retry(post_meta_animals) resp.read() self.assertEqual(resp.status, 202) # check metadata after copy_put resp = retry(get_source) source_contents = resp.read() self.assertEqual(resp.status, 200) self.assertEqual(resp.getheader('x-object-meta-alfa'), 'aardvark') self.assertEqual(resp.getheader('x-object-meta-bravo'), 'bird') self.assertEqual(resp.getheader('x-object-meta-charlie'), None) self.assertEqual(source_contents, setup_body) pass ",,86,0
openstack%2Fswift~master~Ic0512fbb54b32d3e9f1937ac66dd0528b81666ab,openstack/swift,master,Ic0512fbb54b32d3e9f1937ac66dd0528b81666ab,Error handling of DiskFileNoSpace(),NEW,2015-07-06 22:26:24.000000000,2017-12-18 05:27:06.000000000,,"[{'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 9625}, {'_account_id': 12193}, {'_account_id': 13052}, {'_account_id': 13104}, {'_account_id': 17276}]","[{'number': 1, 'created': '2015-07-06 22:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9b6ced063629021d6e8bf351b9e1d0a1abf23b5a', 'message': 'Error handling of DiskFileNoSpace()\n\nThe DiskFileNoSpace() error is raised on multiple occasions in\nswift.obj.diskfile, but should pass in the expected argument when\nit is raised.\n\nChange-Id: Ic0512fbb54b32d3e9f1937ac66dd0528b81666ab\nCloses-Bug: #1472000\n'}, {'number': 2, 'created': '2015-07-16 18:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/94be0a78f3726dfc8787c44ddc617fb4d5e7b731', 'message': 'Error handling of DiskFileNoSpace()\n\nThe DiskFileNoSpace() error is raised on multiple occasions in\nswift.obj.diskfile, but should pass in the expected argument when\nit is raised.\n\nChange-Id: Ic0512fbb54b32d3e9f1937ac66dd0528b81666ab\nCloses-Bug: #1472000\n'}, {'number': 3, 'created': '2015-07-31 19:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/92d5dd89fb01d5a9532423622de3fc1d5a5611aa', 'message': 'Error handling of DiskFileNoSpace()\n\nThe DiskFileNoSpace() error is raised on multiple occasions in\nswift.obj.diskfile, but should pass in the expected argument when\nit is raised.\n\nChange-Id: Ic0512fbb54b32d3e9f1937ac66dd0528b81666ab\nCloses-Bug: #1472000\n'}, {'number': 4, 'created': '2015-08-04 20:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/03fe2e2e29fc395cc7703ec09e8f505b1d1be811', 'message': 'Error handling of DiskFileNoSpace()\n\nThe DiskFileNoSpace() error is raised on multiple occasions in\nswift.obj.diskfile, but should pass in the expected argument when\nit is raised.\n\nSome improvements to error handling in the diskfile module\nare included.\n\nChange-Id: Ic0512fbb54b32d3e9f1937ac66dd0528b81666ab\nCloses-Bug: #1472000\n'}, {'number': 5, 'created': '2015-08-04 22:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8dd7e11de8510bad49607fb06b5c1e98669e33e9', 'message': 'Error handling of DiskFileNoSpace()\n\nThe DiskFileNoSpace() error is raised on multiple occasions in\nswift.obj.diskfile, but should pass in the expected argument when\nit is raised.\n\nSome improvements to error handling of the diskfile module\nare included.\n\nChange-Id: Ic0512fbb54b32d3e9f1937ac66dd0528b81666ab\nCloses-Bug: #1472000\n'}, {'number': 6, 'created': '2015-08-07 00:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/004fdb4ddefd5d945a93610a85c72de026e48e34', 'message': 'Error handling of DiskFileNoSpace()\n\nThe DiskFileNoSpace() error is raised on multiple occasions in\nswift.obj.diskfile, but should pass in the expected argument when\nit is raised.\n\nSome improvements to error handling of the diskfile module\nare included.\n\nChange-Id: Ic0512fbb54b32d3e9f1937ac66dd0528b81666ab\nCloses-Bug: #1472000\n'}, {'number': 7, 'created': '2015-08-07 18:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/810a2456c631acf768ec08ff703d18a89313d52b', 'message': 'Error handling of DiskFileNoSpace()\n\nThe DiskFileNoSpace() error is raised on multiple occasions in\nswift.obj.diskfile, but should pass in the expected argument when\nit is raised.\n\nSome improvements to error handling of the diskfile module\nare included.\n\nChange-Id: Ic0512fbb54b32d3e9f1937ac66dd0528b81666ab\nCloses-Bug: #1472000\n'}, {'number': 8, 'created': '2015-08-17 20:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e597f8186e57d8295ceb80473404f8cab31c6abf', 'message': 'Error handling of DiskFileNoSpace()\n\nThe DiskFileNoSpace() error is raised on multiple occasions in\nswift.obj.diskfile, but should pass in the expected argument when\nit is raised.\n\nSome improvements to error handling of the diskfile module\nare included.\n\nChange-Id: Ic0512fbb54b32d3e9f1937ac66dd0528b81666ab\nCloses-Bug: #1472000\n'}, {'number': 9, 'created': '2015-11-09 14:49:26.000000000', 'files': ['test/unit/obj/test_diskfile.py', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/94772028b8660be66f758e73f11e122d10de69cd', 'message': 'Error handling of DiskFileNoSpace()\n\nThe DiskFileNoSpace() error is raised on multiple occasions in\nswift.obj.diskfile, but should pass in the expected argument when\nit is raised.\n\nSome improvements to error handling of the diskfile module\nare included.\n\nChange-Id: Ic0512fbb54b32d3e9f1937ac66dd0528b81666ab\nCloses-Bug: #1472000\n'}]",17,198909,94772028b8660be66f758e73f11e122d10de69cd,52,8,9,13104,,,0,"Error handling of DiskFileNoSpace()

The DiskFileNoSpace() error is raised on multiple occasions in
swift.obj.diskfile, but should pass in the expected argument when
it is raised.

Some improvements to error handling of the diskfile module
are included.

Change-Id: Ic0512fbb54b32d3e9f1937ac66dd0528b81666ab
Closes-Bug: #1472000
",git fetch https://review.opendev.org/openstack/swift refs/changes/09/198909/8 && git format-patch -1 --stdout FETCH_HEAD,['swift/obj/diskfile.py'],1,9b6ced063629021d6e8bf351b9e1d0a1abf23b5a,bug/1472000, raise DiskFileNoSpace(e) raise DiskFileNoSpace(err) raise DiskFileNoSpace(err) exc = DiskFileNoSpace(msg), raise DiskFileNoSpace() raise DiskFileNoSpace() raise DiskFileNoSpace() exc = DiskFileNoSpace(),4,4
openstack%2Fswift~master~If51cdad7e2fb95a78bd7eaab1a6633b147eec0c6,openstack/swift,master,If51cdad7e2fb95a78bd7eaab1a6633b147eec0c6,Functional testing for Swift API response headers,NEW,2016-01-19 18:49:33.000000000,2017-12-18 05:26:52.000000000,,"[{'_account_id': 10068}, {'_account_id': 13052}, {'_account_id': 19175}]","[{'number': 1, 'created': '2016-01-19 18:49:33.000000000', 'files': ['test/functional/test_object_api.py', 'test/functional/test_account_api.py', 'test/functional/test_container_api.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b88784cca128ae086f6dbcf55ef0700dff5ea0f7', 'message': 'Functional testing for Swift API response headers\n\nA few response headers returned by Swift APIs, as documented in\nhttp://developer.openstack.org/api-ref-objectstorage-v1.html, are\nmissing (e.g. X-Timestamps). Functional test cases are added to check\nwhether Swift API response headers are returned according to the\ndocumentation.\n\nChange-Id: If51cdad7e2fb95a78bd7eaab1a6633b147eec0c6\nRelated-Bug: #1509429\n'}]",0,269810,b88784cca128ae086f6dbcf55ef0700dff5ea0f7,9,3,1,19175,,,0,"Functional testing for Swift API response headers

A few response headers returned by Swift APIs, as documented in
http://developer.openstack.org/api-ref-objectstorage-v1.html, are
missing (e.g. X-Timestamps). Functional test cases are added to check
whether Swift API response headers are returned according to the
documentation.

Change-Id: If51cdad7e2fb95a78bd7eaab1a6633b147eec0c6
Related-Bug: #1509429
",git fetch https://review.opendev.org/openstack/swift refs/changes/10/269810/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/functional/test_object_api.py', 'test/functional/test_account_api.py', 'test/functional/test_container_api.py']",3,b88784cca128ae086f6dbcf55ef0700dff5ea0f7,api_func_tests,"#!/usr/bin/python # Copyright (c) 2010-2012 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. """""" FUNCTIONAL TESTS FOR CONTAINER API response headers as documented on http://developer.openstack.org/api-ref-objectstorage-v1.html with the exception of: HEAD: X-Container-Read X-Container-Write X-Container-Sync-To X-Container-Sync-Key """""" import json import unittest from nose import SkipTest from uuid import uuid4 from test.functional import check_response, retry import test.functional as tf class TestContainerApi(unittest.TestCase): def setUp(self): if tf.skip: raise SkipTest self.container = uuid4().hex self.containers = [] self._create_container(self.container) self._create_container(self.container, use_account=2) self.obj = uuid4().hex def put(url, token, parsed, conn): conn.request('PUT', '%s/%s/%s' % ( parsed.path, self.container, self.obj), 'test', {'X-Auth-Token': token}) return check_response(conn) resp = retry(put) resp.read() self.assertEqual(resp.status, 201) def post(url, token, parsed, conn, headers): new_headers = dict({'X-Auth-Token': token}, **headers) conn.request('POST', '%s/%s' % ( parsed.path, self.container), '', new_headers) return check_response(conn) resp = retry(post, headers={'X-Container-Meta-Test': 'test_name', 'X-Container-Meta-Temp-URL-Key': 'secret_url_key', 'X-Container-Meta-Temp-URL-Key-2': 'secret_url_key_2', 'X-Container-Meta-Quota-Bytes': 100000, 'X-Container-Meta-Quota-Count': 50}) resp.read() self.assertEqual(resp.status, 204) def _create_container(self, name=None, headers=None, use_account=1): if not name: name = uuid4().hex self.containers.append(name) headers = headers or {} def put(url, token, parsed, conn, name): new_headers = dict({'X-Auth-Token': token}, **headers) conn.request('PUT', parsed.path + '/' + name, '', new_headers) return check_response(conn) resp = retry(put, name, use_account=use_account) resp.read() self.assertEqual(resp.status, 201) return name def tearDown(self): if tf.skip: raise SkipTest # get list of objects in container def get(url, token, parsed, conn, container): conn.request( 'GET', parsed.path + '/' + container + '?format=json', '', {'X-Auth-Token': token}) return check_response(conn) # delete an object def delete(url, token, parsed, conn, container, obj): conn.request( 'DELETE', '/'.join([parsed.path, container, obj['name']]), '', {'X-Auth-Token': token}) return check_response(conn) for container in self.containers: while True: resp = retry(get, container) body = resp.read() if resp.status == 404: break self.assertTrue(resp.status // 100 == 2, resp.status) objs = json.loads(body) if not objs: break for obj in objs: resp = retry(delete, container, obj) resp.read() self.assertEqual(resp.status, 204) # delete the container def delete(url, token, parsed, conn, name): conn.request('DELETE', parsed.path + '/' + name, '', {'X-Auth-Token': token}) return check_response(conn) for container in self.containers: resp = retry(delete, container) resp.read() self.assertIn(resp.status, (204, 404)) # ******************************************* # Container GET # Response Headers # ******************************************* def test_api_get_content_length(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('GET', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('content-length'), None) def test_api_get_x_container_object_count(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('GET', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('x-container-object-count'), None) def test_api_get_accept_ranges(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('GET', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('accept-ranges'), None) def test_api_get_x_container_meta_test(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('GET', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('X-Container-Meta-Test'), None) self.assertEqual(resp.getheader('X-Container-Meta-Test'), 'test_name') def test_api_get_x_timestamp(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('GET', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('x-timestamp'), None) def test_api_get_x_container_bytes_used(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('GET', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('x-container-bytes-used'), None) def test_api_get_content_type(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('GET', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('content-type'), None) def test_api_get_x_trans_id(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('GET', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('x-trans-id'), None) def test_api_get_date(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('GET', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('date'), None) def test_api_get_x_container_meta_temp_url_key(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('GET', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('X-Container-Meta-Temp-URL-Key'), None) self.assertEqual(resp.getheader('X-Container-Meta-Temp-URL-Key'), 'secret_url_key') def test_api_get_x_container_meta_temp_url_key_2(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('GET', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('X-Container-Meta-Temp-URL-Key-2'), None) self.assertEqual(resp.getheader('X-Container-Meta-Temp-URL-Key-2'), 'secret_url_key_2') # ******************************************* # Container PUT # Response Headers # ******************************************* def test_api_put_content_length(self): if tf.skip: raise SkipTest dest = '%s' % ('test_container') def put(url, token, parsed, conn): conn.request('PUT', '%s/%s' % (parsed.path, dest), 'test_container', {'X-Auth-Token': token}) return check_response(conn) resp = retry(put) resp.read() self.assertEqual(resp.status, 201) self.assertNotEqual(resp.getheader('content-length'), None) def delete(url, token, parsed, conn): conn.request('DELETE', '%s/%s' % (parsed.path, dest), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(delete) resp.read() self.assertEqual(resp.status, 204) def test_api_put_content_type(self): if tf.skip: raise SkipTest dest = '%s' % ('test_container') def put(url, token, parsed, conn): conn.request('PUT', '%s/%s' % (parsed.path, dest), 'test_container', {'X-Auth-Token': token}) return check_response(conn) resp = retry(put) resp.read() self.assertEqual(resp.status, 201) self.assertNotEqual(resp.getheader('content-type'), None) def delete(url, token, parsed, conn): conn.request('DELETE', '%s/%s' % (parsed.path, dest), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(delete) resp.read() self.assertEqual(resp.status, 204) def test_api_put_x_timestamp(self): if tf.skip: raise SkipTest dest = '%s' % ('test_container') def put(url, token, parsed, conn): conn.request('PUT', '%s/%s' % (parsed.path, dest), 'test_container', {'X-Auth-Token': token}) return check_response(conn) resp = retry(put) resp.read() self.assertEqual(resp.status, 201) self.assertNotEqual(resp.getheader('x-timestamp'), None) def delete(url, token, parsed, conn): conn.request('DELETE', '%s/%s' % (parsed.path, dest), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(delete) resp.read() self.assertEqual(resp.status, 204) def test_api_put_x_trans_id(self): if tf.skip: raise SkipTest dest = '%s' % ('test_container') def put(url, token, parsed, conn): conn.request('PUT', '%s/%s' % (parsed.path, dest), 'test_container', {'X-Auth-Token': token}) return check_response(conn) resp = retry(put) resp.read() self.assertEqual(resp.status, 202) self.assertNotEqual(resp.getheader('x-trans-id'), None) def delete(url, token, parsed, conn): conn.request('DELETE', '%s/%s' % (parsed.path, dest), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(delete) resp.read() self.assertEqual(resp.status, 204) def test_api_put_date(self): if tf.skip: raise SkipTest dest = '%s' % ('test_container') def put(url, token, parsed, conn): conn.request('PUT', '%s/%s' % (parsed.path, dest), 'test_container', {'X-Auth-Token': token}) return check_response(conn) resp = retry(put) resp.read() self.assertEqual(resp.status, 201) self.assertNotEqual(resp.getheader('date'), None) def delete(url, token, parsed, conn): conn.request('DELETE', '%s/%s' % (parsed.path, dest), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(delete) resp.read() self.assertEqual(resp.status, 204) # ******************************************* # Container DELETE # Response Headers # ******************************************* def test_api_delete_content_length(self): if tf.skip: raise SkipTest dest = '%s' % ('test_container') def put(url, token, parsed, conn): conn.request('PUT', '%s/%s' % (parsed.path, dest), 'test_container', {'X-Auth-Token': token}) return check_response(conn) resp = retry(put) resp.read() def delete(url, token, parsed, conn): conn.request('DELETE', '%s/%s' % (parsed.path, dest), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(delete) resp.read() self.assertEqual(resp.status, 204) self.assertEqual(resp.getheader('content-length'), '0') def test_api_delete_content_type(self): if tf.skip: raise SkipTest dest = '%s' % ('test_container') def put(url, token, parsed, conn): conn.request('PUT', '%s/%s' % (parsed.path, dest), 'test_container', {'X-Auth-Token': token}) return check_response(conn) resp = retry(put) resp.read() def delete(url, token, parsed, conn): conn.request('DELETE', '%s/%s' % (parsed.path, dest), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(delete) resp.read() self.assertEqual(resp.status, 204) self.assertNotEqual(resp.getheader('content-type'), None) def test_api_delete_x_timestamp(self): if tf.skip: raise SkipTest dest = '%s' % ('test_container') def put(url, token, parsed, conn): conn.request('PUT', '%s/%s' % (parsed.path, dest), 'test_container', {'X-Auth-Token': token}) return check_response(conn) resp = retry(put) resp.read() def delete(url, token, parsed, conn): conn.request('DELETE', '%s/%s' % (parsed.path, dest), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(delete) resp.read() self.assertEqual(resp.status, 204) self.assertNotEqual(resp.getheader('x-timestamp'), None) def test_api_delete_x_trans_id(self): if tf.skip: raise SkipTest dest = '%s' % ('test_container') def put(url, token, parsed, conn): conn.request('PUT', '%s/%s' % (parsed.path, dest), 'test_container', {'X-Auth-Token': token}) return check_response(conn) resp = retry(put) def delete(url, token, parsed, conn): conn.request('DELETE', '%s/%s' % (parsed.path, dest), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(delete) resp.read() self.assertEqual(resp.status, 204) def test_api_delete_date(self): if tf.skip: raise SkipTest dest = '%s' % ('test_container') def put(url, token, parsed, conn): conn.request('PUT', '%s/%s' % (parsed.path, dest), 'test_container', {'X-Auth-Token': token}) return check_response(conn) resp = retry(put) def delete(url, token, parsed, conn): conn.request('DELETE', '%s/%s' % (parsed.path, dest), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(delete) resp.read() self.assertEqual(resp.status, 204) self.assertNotEqual(resp.getheader('date'), None) # ******************************************* # Container POST # Response Headers # ******************************************* def test_api_post_content_length(self): if tf.skip: raise SkipTest def post(url, token, parsed, conn, headers): new_headers = dict({'X-Auth-Token': token}, **headers) conn.request('POST', '%s/%s' % ( parsed.path, self.container), '', new_headers) return check_response(conn) resp = retry(post, headers={'X-Container-Meta-Test': 'test_name'}) resp.read() self.assertEqual(resp.status, 204) self.assertNotEqual(resp.getheader('content-length'), None) def test_api_post_content_type(self): if tf.skip: raise SkipTest def post(url, token, parsed, conn, headers): new_headers = dict({'X-Auth-Token': token}, **headers) conn.request('POST', '%s/%s' % ( parsed.path, self.container), '', new_headers) return check_response(conn) resp = retry(post, headers={'X-Container-Meta-Test': 'test_name'}) resp.read() self.assertEqual(resp.status, 204) self.assertNotEqual(resp.getheader('content-type'), None) def test_api_post_x_timestamp(self): if tf.skip: raise SkipTest def post(url, token, parsed, conn, headers): new_headers = dict({'X-Auth-Token': token}, **headers) conn.request('POST', '%s/%s' % ( parsed.path, self.container), '', new_headers) return check_response(conn) resp = retry(post, headers={'X-Container-Meta-Test': 'test_name'}) resp.read() self.assertEqual(resp.status, 204) self.assertNotEqual(resp.getheader('X-Timestamp'), None) def test_api_post_x_trans_id(self): if tf.skip: raise SkipTest def post(url, token, parsed, conn, headers): new_headers = dict({'X-Auth-Token': token}, **headers) conn.request('POST', '%s/%s' % ( parsed.path, self.container), '', new_headers) return check_response(conn) resp = retry(post, headers={'X-Container-Meta-Test': 'test_name'}) resp.read() self.assertEqual(resp.status, 204) self.assertNotEqual(resp.getheader('x-trans-id'), None) def test_api_post_date(self): if tf.skip: raise SkipTest def post(url, token, parsed, conn, headers): new_headers = dict({'X-Auth-Token': token}, **headers) conn.request('POST', '%s/%s' % ( parsed.path, self.container), '', new_headers) return check_response(conn) resp = retry(post, headers={'X-Container-Meta-Test': 'test_name'}) resp.read() self.assertEqual(resp.status, 204) self.assertNotEqual(resp.getheader('date'), None) # ******************************************* # Container HEAD # Response Headers # ******************************************* def test_api_head_content_length(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('HEAD', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) self.assertNotEqual(resp.getheader('content-length'), None) def test_api_head_x_container_object_count(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('HEAD', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) self.assertNotEqual(resp.getheader('x-container-object-count'), None) def test_api_head_accept_ranges(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('HEAD', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) self.assertNotEqual(resp.getheader('accept-ranges'), None) def test_api_head_x_container_meta_test(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('HEAD', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) self.assertNotEqual(resp.getheader('x-container-meta-test'), None) self.assertEqual(resp.getheader('x-container-meta-test'), 'test_name') def test_api_head_x_timestamp(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('HEAD', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) self.assertNotEqual(resp.getheader('x-timestamp'), None) def test_api_head_x_container_bytes_used(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('HEAD', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) self.assertNotEqual(resp.getheader('x-container-bytes-used'), None) def test_api_head_content_type(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('HEAD', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) self.assertNotEqual(resp.getheader('content-type'), None) def test_api_head_x_trans_id(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('HEAD', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) self.assertNotEqual(resp.getheader('x-trans-id'), None) def test_api_head_date(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('HEAD', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) self.assertNotEqual(resp.getheader('date'), None) def test_api_head_x_container_meta_temp_url_key(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('HEAD', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('X-Container-Meta-Temp-URL-Key'), None) self.assertEqual(resp.getheader('X-Container-Meta-Temp-URL-Key'), 'secret_url_key') def test_api_head_x_container_meta_temp_url_key_2(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('HEAD', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('X-Container-Meta-Temp-URL-Key-2'), None) self.assertEqual(resp.getheader('X-Container-Meta-Temp-URL-Key-2'), 'secret_url_key_2') def test_api_head_x_container_meta_quota_bytes(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('HEAD', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('X-Container-Meta-Quota-Bytes'), None) self.assertEqual(resp.getheader('X-Container-Meta-Quota-Bytes'), '100000') def test_api_head_x_container_meta_quota_count(self): if tf.skip: raise SkipTest source = '%s' % (self.container) def get_source(url, token, parsed, conn): conn.request('HEAD', '%s/%s' % (parsed.path, source), '', {'X-Auth-Token': token}) return check_response(conn) resp = retry(get_source) resp.read() self.assertNotEqual(resp.getheader('X-Container-Meta-Quota-Count'), None) self.assertEqual(resp.getheader('X-Container-Meta-Quota-Count'), '50') if __name__ == '__main__': unittest.main() ",,2477,0
openstack%2Fswift~master~Id77d32c037ae49156f96499aa84c0393c0e5f78f,openstack/swift,master,Id77d32c037ae49156f96499aa84c0393c0e5f78f,Unification of manpages and swift-* --help,NEW,2015-11-30 14:40:30.000000000,2017-12-18 05:26:35.000000000,,"[{'_account_id': 2622}, {'_account_id': 13052}, {'_account_id': 16896}, {'_account_id': 18015}]","[{'number': 1, 'created': '2015-11-30 14:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0743d4c3c69c64d037cf03a58622e475d4925dcd', 'message': 'Unification of manpages and swift-* --help\n\nAlso add missing manpages.\n\nChange-Id: Id77d32c037ae49156f96499aa84c0393c0e5f78f\n'}, {'number': 2, 'created': '2015-12-11 08:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5a7d591778194141cce2e1d54a46de2db9f2af3c', 'message': 'Unification of manpages and swift-* --help\n\nAlso add missing manpages.\n\nChange-Id: Id77d32c037ae49156f96499aa84c0393c0e5f78f\n'}, {'number': 3, 'created': '2016-01-20 14:44:35.000000000', 'files': ['doc/manpages/swift-get-nodes.1', 'doc/manpages/swift-container-auditor.1', 'doc/manpages/swift-account-info.1', 'doc/manpages/swift-init.1', 'doc/manpages/swift-account-audit.1', 'doc/manpages/swift-reconciler-enqueue.1', 'doc/manpages/swift-recon-cron.1', 'doc/manpages/swift-container-server.1', 'doc/manpages/swift-account-replicator.1', 'doc/manpages/swift-container-updater.1', 'doc/manpages/swift-object-info.1', 'doc/manpages/swift-oldies.1', 'doc/manpages/swift-ring-builder-analyzer.1', 'doc/manpages/swift-recon.1', 'doc/manpages/swift-container-replicator.1', 'doc/manpages/swift-object-replicator.1', 'doc/manpages/swift-dispersion-report.1', 'doc/manpages/swift-object-auditor.1', 'bin/swift-object-info', 'doc/manpages/swift-account-auditor.1', 'doc/manpages/swift-container-info.1', 'doc/manpages/swift-container-sync.1', 'doc/manpages/swift-form-signature.1', 'doc/manpages/swift-object-server.1', 'doc/manpages/swift-temp-url.1', 'doc/manpages/swift-drive-audit.1', 'doc/manpages/swift-account-server.1', 'doc/manpages/swift-object-updater.1', 'doc/manpages/swift-config.1', 'doc/manpages/swift-account-reaper.1', 'doc/manpages/swift-dispersion-populate.1', 'bin/swift-get-nodes', 'doc/manpages/swift-object-expirer.1', 'doc/manpages/swift-container-reconciler.1', 'swift/cli/recon.py', 'doc/manpages/swift-ring-builder.1', 'doc/manpages/swift-proxy-server.1', 'doc/manpages/swift-orphans.1'], 'web_link': 'https://opendev.org/openstack/swift/commit/6c70e6b4b0c743a3b354672186996fa3a2c8093b', 'message': 'Unification of manpages and swift-* --help\n\nAlso add missing manpages.\n\nChange-Id: Id77d32c037ae49156f96499aa84c0393c0e5f78f\n'}]",0,251397,6c70e6b4b0c743a3b354672186996fa3a2c8093b,20,4,3,18015,,,0,"Unification of manpages and swift-* --help

Also add missing manpages.

Change-Id: Id77d32c037ae49156f96499aa84c0393c0e5f78f
",git fetch https://review.opendev.org/openstack/swift refs/changes/97/251397/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/manpages/swift-get-nodes.1', 'doc/manpages/swift-container-auditor.1', 'doc/manpages/swift-account-info.1', 'doc/manpages/swift-init.1', 'doc/manpages/swift-account-audit.1', 'doc/manpages/swift-reconciler-enqueue.1', 'doc/manpages/swift-recon-cron.1', 'doc/manpages/swift-container-server.1', 'doc/manpages/swift-account-replicator.1', 'doc/manpages/swift-container-updater.1', 'doc/manpages/swift-object-info.1', 'doc/manpages/swift-oldies.1', 'doc/manpages/swift-ring-builder-analyzer.1', 'doc/manpages/swift-recon.1', 'doc/manpages/swift-container-replicator.1', 'doc/manpages/swift-object-replicator.1', 'doc/manpages/swift-dispersion-report.1', 'doc/manpages/swift-object-auditor.1', 'bin/swift-object-info', 'doc/manpages/swift-account-auditor.1', 'doc/manpages/swift-container-info.1', 'doc/manpages/swift-container-sync.1', 'doc/manpages/swift-form-signature.1', 'doc/manpages/swift-object-server.1', 'doc/manpages/swift-temp-url.1', 'doc/manpages/swift-drive-audit.1', 'doc/manpages/swift-account-server.1', 'doc/manpages/swift-object-updater.1', 'doc/manpages/swift-config.1', 'doc/manpages/swift-account-reaper.1', 'doc/manpages/swift-dispersion-populate.1', 'bin/swift-get-nodes', 'doc/manpages/swift-object-expirer.1', 'doc/manpages/swift-container-reconciler.1', 'swift/cli/recon.py', 'doc/manpages/swift-ring-builder.1', 'doc/manpages/swift-proxy-server.1', 'doc/manpages/swift-orphans.1']",38,0743d4c3c69c64d037cf03a58622e475d4925dcd,cli-manpages,"[-h|--help] [-a HOURS|--age=HOURS] [-k SIGNAL|--kill=SIGNAL] [-w|--wide] [-r RUN_DIR|--run-dir=RUN_DIR].SH OPTIONS .RS 0 .PD 1 .IP ""\fB-h, --help\fR"" show the help message and exit .IP ""\fB-a HOURS, --age=HOURS"" Look for processes at least HOURS old; default: 24 .IP ""\fB-k SIGNAL, --kill=SIGNAL"" Send SIGNAL to matched processes; default: just list process information .IP ""\fB-w, --wide"" Don't clip the listing at 80 characters .IP ""\fB-r RUN_DIR, --run-dir=RUN_DIR"" Alternative directory to store running pid files, default: /var/run/swiftAlso more specific documentation about swift-drive-audit can be found at .BI http://docs.openstack.org/developer/swift/admin_guide.html#swift-orphans","[-h|--help] [-a|--age] [-k|--kill] [-w|--wide] [-r|--run-dir]The options are as follows: .RS 4 .PD 0 .IP ""-a HOURS"" .IP ""--age=HOURS"" .RS 4 .IP ""Look for processes at least HOURS old; default: 24"" .RE .IP ""-k SIGNAL"" .IP ""--kill=SIGNAL"" .RS 4 .IP ""Send SIGNAL to matched processes; default: just list process information"" .RE .IP ""-w"" .IP ""--wide"" .RS 4 .IP ""Don't clip the listing at 80 characters"" .RE .PD .RE ",910,262
openstack%2Fswift~master~If5b85e5ad9d11195bcc1a3fbb7bb9725514a7c90,openstack/swift,master,If5b85e5ad9d11195bcc1a3fbb7bb9725514a7c90,"Ubuntu 14.04 do not support environment markers with <, >, etc.",NEW,2016-02-06 15:03:53.000000000,2017-12-18 05:25:42.000000000,,"[{'_account_id': 1179}, {'_account_id': 13052}, {'_account_id': 13390}]","[{'number': 1, 'created': '2016-02-06 15:03:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8d43fd82142f448c8ba6bee44aad348ffdb4811c', 'message': 'Ubuntu 14.04 do not support environment markers with <, >, etc.\n\nThe Python package setuptools in Ubuntu 14.04 do not support environment markers with <, >, etc.\nWhen running ""sudo python setup.py install"", the following error will be shown:\n\nerror in setup command: Invalid environment marker: (python_version>=\'3.0\')\n\nMeanwhile, we do not use any other version of Python except for  2.7 and 3.3,\nso we can just use the equal operator in the environment markers.\n\nChange-Id: If5b85e5ad9d11195bcc1a3fbb7bb9725514a7c90\nCloses-Bug: #1541966\n'}, {'number': 2, 'created': '2016-02-06 15:50:07.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/swift/commit/5332ffe2719cf30933a8b90a519517a2c78f1f95', 'message': 'Ubuntu 14.04 do not support environment markers with <, >, etc.\n\nThe Python package setuptools in Ubuntu 14.04 do not support environment markers with <, >, etc.\nWhen running ""sudo python setup.py install"", the following error will be shown:\n\nerror in setup command: Invalid environment marker: (python_version>=\'3.0\')\n\nMeanwhile, we do not use any other version of Python except for  2.7 and 3.4,\nso we can just use the equal operator in the environment markers.\n\nChange-Id: If5b85e5ad9d11195bcc1a3fbb7bb9725514a7c90\nCloses-Bug: #1541966\n'}]",0,277089,5332ffe2719cf30933a8b90a519517a2c78f1f95,11,3,2,13390,,,0,"Ubuntu 14.04 do not support environment markers with <, >, etc.

The Python package setuptools in Ubuntu 14.04 do not support environment markers with <, >, etc.
When running ""sudo python setup.py install"", the following error will be shown:

error in setup command: Invalid environment marker: (python_version>='3.0')

Meanwhile, we do not use any other version of Python except for  2.7 and 3.4,
so we can just use the equal operator in the environment markers.

Change-Id: If5b85e5ad9d11195bcc1a3fbb7bb9725514a7c90
Closes-Bug: #1541966
",git fetch https://review.opendev.org/openstack/swift refs/changes/89/277089/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,8d43fd82142f448c8ba6bee44aad348ffdb4811c,Ubuntu14.04-not-support-current-requirement.txt,dnspython>=1.12.0;python_version=='2.7' dnspython3>=1.12.0;python_version=='3.3',dnspython>=1.12.0;python_version<'3.0' dnspython3>=1.12.0;python_version>='3.0',2,2
openstack%2Frally~master~I22b9719b0175a52450e14cd3534cae4da05d1ce5,openstack/rally,master,I22b9719b0175a52450e14cd3534cae4da05d1ce5,Adds Designate record-update test,NEW,2015-12-30 06:32:07.000000000,2017-12-18 05:25:40.000000000,,"[{'_account_id': 8491}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 19811}]","[{'number': 1, 'created': '2015-12-30 06:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8b23bde50752b7f1e056570ce67337dfc75ff0e5', 'message': 'Adds Designate record-update test\nThis submission adds create_and_update_records method to rally/benchmark/scenarios/designate/basic.py.\nAdds update method to ""utils.py"" under ""rally/benchmark/scenarios/designate"".\nAdded configuration files for designate update-domain operation under samples/tasks/scenarios/designate.\n1) create-and-update-records.json\n2) create-and-update-records.yaml.\n\nAlso added unit tests to \'test_basic.py\' and \'test_utils.py\' under \'rally/tests/unit/plugins/openstack/scenarios/designate\'.\n\nChange-Id: I22b9719b0175a52450e14cd3534cae4da05d1ce5\n'}, {'number': 2, 'created': '2015-12-30 06:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b1dea886a20c426447ae53ee5c39f0842ae8d2a2', 'message': 'Adds Designate record-update test\n\nThis submission adds create_and_update_records method to rally/benchmark/scenarios/designate/basic.py.\nAdds update method to ""utils.py"" under ""rally/benchmark/scenarios/designate"".\nAdded configuration files for designate update-domain operation under samples/tasks/scenarios/designate.\n1) create-and-update-records.json\n2) create-and-update-records.yaml.\n\nAlso added unit tests to \'test_basic.py\' and \'test_utils.py\' under \'rally/tests/unit/plugins/openstack/scenarios/designate\'.\n\nChange-Id: I22b9719b0175a52450e14cd3534cae4da05d1ce5\n'}, {'number': 3, 'created': '2015-12-31 09:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/33a8a31770b90b299c792b94b532312c7bc0794b', 'message': 'Adds Designate record-update test\n\nThis submission adds create_and_update_records method to rally/benchmark/scenarios/designate/basic.py.\nAdds update method to ""utils.py"" under ""rally/benchmark/scenarios/designate"".\nAdded configuration files for designate update-domain operation under samples/tasks/scenarios/designate.\n1) create-and-update-records.json\n2) create-and-update-records.yaml.\n\nAlso added unit tests to \'test_basic.py\' and \'test_utils.py\' under \'rally/tests/unit/plugins/openstack/scenarios/designate\'.\n\nChange-Id: I22b9719b0175a52450e14cd3534cae4da05d1ce5\n'}, {'number': 4, 'created': '2016-01-04 11:32:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7a51456c5b49d36fce56781301b296ef76b87a3a', 'message': 'Adds Designate record-update test\n\nThis submission adds create_and_update_records method to rally/benchmark/scenarios/designate/basic.py.\nAdds update method to ""utils.py"" under ""rally/benchmark/scenarios/designate"".\nAdded configuration files for designate update-domain operation under samples/tasks/scenarios/designate.\n1) create-and-update-records.json\n2) create-and-update-records.yaml.\n\nAlso added unit tests to \'test_basic.py\' and \'test_utils.py\' under \'rally/tests/unit/plugins/openstack/scenarios/designate\'.\n\nChange-Id: I22b9719b0175a52450e14cd3534cae4da05d1ce5\n'}, {'number': 5, 'created': '2016-01-07 06:55:56.000000000', 'files': ['rally-jobs/rally-designate.yaml', 'tests/unit/plugins/openstack/scenarios/designate/test_basic.py', 'samples/tasks/scenarios/designate/create-and-update-records.yaml', 'rally/plugins/openstack/scenarios/designate/basic.py', 'tests/unit/plugins/openstack/scenarios/designate/test_utils.py', 'samples/tasks/scenarios/designate/create-and-update-records.json', 'rally/plugins/openstack/context/cleanup/resources.py', 'rally/plugins/openstack/scenarios/designate/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/c621c8750db21fc2589d102c467d940ee538c780', 'message': 'Adds Designate record-update test\n\nThis submission adds create_and_update_records method to rally/benchmark/scenarios/designate/basic.py.\nAdds update method to ""utils.py"" under ""rally/benchmark/scenarios/designate"".\nAdded configuration files for designate update-domain operation under samples/tasks/scenarios/designate.\n1) create-and-update-records.json\n2) create-and-update-records.yaml.\n\nAlso added unit tests to \'test_basic.py\' and \'test_utils.py\' under \'rally/tests/unit/plugins/openstack/scenarios/designate\'.\n\nChange-Id: I22b9719b0175a52450e14cd3534cae4da05d1ce5\n'}]",11,262390,c621c8750db21fc2589d102c467d940ee538c780,39,4,5,1795,,,0,"Adds Designate record-update test

This submission adds create_and_update_records method to rally/benchmark/scenarios/designate/basic.py.
Adds update method to ""utils.py"" under ""rally/benchmark/scenarios/designate"".
Added configuration files for designate update-domain operation under samples/tasks/scenarios/designate.
1) create-and-update-records.json
2) create-and-update-records.yaml.

Also added unit tests to 'test_basic.py' and 'test_utils.py' under 'rally/tests/unit/plugins/openstack/scenarios/designate'.

Change-Id: I22b9719b0175a52450e14cd3534cae4da05d1ce5
",git fetch https://review.opendev.org/openstack/rally refs/changes/90/262390/5 && git format-patch -1 --stdout FETCH_HEAD,"['rally-jobs/rally-designate.yaml', 'tests/unit/plugins/openstack/scenarios/designate/test_basic.py', 'samples/tasks/scenarios/designate/create-and-update-records.yaml', 'rally/plugins/openstack/scenarios/designate/basic.py', 'tests/unit/plugins/openstack/scenarios/designate/test_utils.py', 'samples/tasks/scenarios/designate/create-and-update-records.json', 'rally/plugins/openstack/scenarios/designate/utils.py']",7,8b23bde50752b7f1e056570ce67337dfc75ff0e5,separate/designate-records," @atomic.optional_action_timer(""designate.update_record"") def _update_record(self, domain, record): """"""Update a domain record. :param domain: designate domain :param record: designate record :param atomic_action: True if the record creation should be tracked as an atomic action. added and handled by the optional_action_timer() decorator """""" record[""type""] = ""A"" record[""data""] = ""10.0.0.1"" return self.clients(""designate"").records.update(domain, record) ",,146,0
openstack%2Fyaql~master~Ia60de3457e46c0bb26196955462869e4c27e6ca8,openstack/yaql,master,Ia60de3457e46c0bb26196955462869e4c27e6ca8,YAQL autocompletion (WiP),NEW,2016-02-10 16:58:29.000000000,2017-12-18 05:25:35.000000000,,[],"[{'number': 1, 'created': '2016-02-10 16:58:29.000000000', 'files': ['yaql/cli/cli_functions.py', 'yaql/language/utils.py', 'yaql/language/lexer.py', 'yaql/language/expressions.py', 'yaql/language/exceptions.py', 'yaql/language/parser.py', 'yaql/standard_library/system.py', 'yaql/tests/test_engine.py', 'yaql/language/contexts.py'], 'web_link': 'https://opendev.org/openstack/yaql/commit/47f5835777b6f08b4b570dd51da291ecaae8ae15', 'message': 'YAQL autocompletion (WiP)\n\nChange-Id: Ia60de3457e46c0bb26196955462869e4c27e6ca8\n'}]",0,278518,47f5835777b6f08b4b570dd51da291ecaae8ae15,3,0,1,8127,,,0,"YAQL autocompletion (WiP)

Change-Id: Ia60de3457e46c0bb26196955462869e4c27e6ca8
",git fetch https://review.opendev.org/openstack/yaql refs/changes/18/278518/1 && git format-patch -1 --stdout FETCH_HEAD,"['yaql/cli/cli_functions.py', 'yaql/language/utils.py', 'yaql/language/expressions.py', 'yaql/language/lexer.py', 'yaql/language/exceptions.py', 'yaql/language/parser.py', 'yaql/standard_library/system.py', 'yaql/tests/test_engine.py', 'yaql/language/contexts.py']",9,47f5835777b6f08b4b570dd51da291ecaae8ae15,," def get_functions(self, name, predicate=None, use_convention=False, partial_name=False): def collect_functions(self, name, predicate=None, use_convention=False, partial_name=False): name, context_predicate, use_convention, partial_name=partial_name) def get_functions(self, name, predicate=None, use_convention=False, partial_name=False): if partial_name: func_set = set() for func_name in self._functions.keys(): if func_name.startswith(name): func_set.update(self._functions[func_name]) else: func_set = self._functions.get(name, set()) set(six.moves.filter(predicate, func_set)), def get_functions(self, name, predicate=None, use_convention=False, partial_name=False): name, predicate, use_convention, partial_name)"," def get_functions(self, name, predicate=None, use_convention=False): def collect_functions(self, name, predicate=None, use_convention=False): name, context_predicate, use_convention) def get_functions(self, name, predicate=None, use_convention=False): set(six.moves.filter(predicate, self._functions.get(name, set()))), def get_functions(self, name, predicate=None, use_convention=False): name, predicate, use_convention)",200,11
openstack%2Ftacker~master~I20cc06bdf0bd29f1be3785598b7184a52f660df8,openstack/tacker,master,I20cc06bdf0bd29f1be3785598b7184a52f660df8,Set respawn limit to VNF respawn policy,NEW,2015-11-02 10:05:07.000000000,2017-12-18 05:25:33.000000000,,"[{'_account_id': 13380}, {'_account_id': 13485}, {'_account_id': 16511}, {'_account_id': 18186}]","[{'number': 1, 'created': '2015-11-02 10:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/a5164614a0bc85c189acca8910cf839d0e2fff7a', 'message': 'Set respawn limit to VNF respawn policy\n\n*Add support for specifying the respawn limit in VNFD\n*Add backend support to handle respawn limit\n\nCloses-Bug: #1503477\nChange-Id: I20cc06bdf0bd29f1be3785598b7184a52f660df8\n'}, {'number': 2, 'created': '2015-11-04 14:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/50ccdb7bde280327d062ae4e1543bec28f256816', 'message': 'Set respawn limit to VNF respawn policy\n\n*Add support for specifying the respawn limit in VNFD\n*Add backend support to handle respawn limit\n\nCloses-Bug: #1503477\nChange-Id: I20cc06bdf0bd29f1be3785598b7184a52f660df8\n'}, {'number': 3, 'created': '2015-11-04 14:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/7876981053d0326a1d561eb55d8c2edfd1379150', 'message': 'Set respawn limit to VNF respawn policy\n\n*Add support for specifying the respawn limit in VNFD\n*Add backend support to handle respawn limit\n\nCloses-Bug: #1503477\nChange-Id: I20cc06bdf0bd29f1be3785598b7184a52f660df8\n'}, {'number': 4, 'created': '2015-11-04 17:49:54.000000000', 'files': ['tacker/vm/plugin.py', 'devstack/samples/sample-vnfd-monitor-with-respawn-limit.yaml', 'tacker/tests/unit/vm/monitor_drivers/ping/test_ping.py', 'tacker/tests/unit/vm/test_monitor.py', 'tacker/vm/monitor_drivers/ping/ping.py', 'tacker/vm/monitor.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/da8ff1c06aa2cf662bdb381d969dc4623cba8a38', 'message': 'Set respawn limit to VNF respawn policy\n\n*Add support for specifying the respawn limit in VNFD\n*Add backend support to handle respawn limit\n\nCloses-Bug: #1503477\nChange-Id: I20cc06bdf0bd29f1be3785598b7184a52f660df8\n'}]",6,240814,da8ff1c06aa2cf662bdb381d969dc4623cba8a38,11,4,4,12455,,,0,"Set respawn limit to VNF respawn policy

*Add support for specifying the respawn limit in VNFD
*Add backend support to handle respawn limit

Closes-Bug: #1503477
Change-Id: I20cc06bdf0bd29f1be3785598b7184a52f660df8
",git fetch https://review.opendev.org/openstack/tacker refs/changes/14/240814/4 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/samples/sample-vnfd-monitor-with-respawn-limit.yaml', 'tacker/vm/monitor.py']",2,a5164614a0bc85c189acca8910cf839d0e2fff7a,bug1503477," tmp_hosting_vnf = hosting_vnf.copy() tmp_hosting_vnf['device']['monitoring_action'] = action if isinstance(action, unicode): action_name = action elif isinstance(action, dict): action_name = action['action_name'] hosting_vnf['action_cb'](tmp_hosting_vnf, action_name) limit = None action = device_dict['monitoring_action'] if isinstance(action, dict): limit = action['limit'] if limit and failure_count > limit: return"," hosting_vnf['action_cb'](hosting_vnf, action)",55,1
openstack%2Fheat-translator~master~I9d01a6071d893dd7f1c9ed419f81629c88d004e1,openstack/heat-translator,master,I9d01a6071d893dd7f1c9ed419f81629c88d004e1,Implement mapping of TOSCA nodes to HOT SoftwareComponents,NEW,2015-09-29 03:11:18.000000000,2017-12-18 05:25:30.000000000,,"[{'_account_id': 6456}, {'_account_id': 6460}, {'_account_id': 9498}, {'_account_id': 15642}]","[{'number': 1, 'created': '2015-09-29 03:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/281dad750e53a178fd90b21e71490a0bed543798', 'message': 'WIP: Implement mapping of TOSCA nodes to HOT SoftwareComponents\n\nCurrently TOSCA nodes are mapped to HOT SoftwareConfig resources. For HOT,\nSoftwareConfig allows for only one lifecycle per resource so this meant\nthat there were numerous SoftwareConfig resources (one per lifecycle) for\neach TOSCA node. The resultant HOT template becomes hard to distill how\nthe resources relate to the original TOSCA node definition (both visually\nfrom Horizon, and programmatically from the resource id\'s).\n\nNew to the HOT specification is the SoftwareComponent resource type. This\nworks very similar to the SoftwareConfig resource, but allows for multiple\nlifecycle ""configs"" within the singular SoftwareComponent resource type.\nThis makes for a straight one-to-one mapping from TOSCA nodes to the\nunderlying HOT resources.\n\nThis patch updates the translator implementation to use these new HOT\nSoftwareComponent resource types.\n\nChange-Id: I9d01a6071d893dd7f1c9ed419f81629c88d004e1\nImplements: blueprint tosca-softwarecomponents\n'}, {'number': 2, 'created': '2015-09-29 03:14:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/ff06299b86b8fd36c8c40e8a648a1915b58b18f8', 'message': 'WIP: Implement mapping of TOSCA nodes to HOT SoftwareComponents\n\nCurrently TOSCA nodes are mapped to HOT SoftwareConfig resources. For HOT,\nSoftwareConfig allows for only one lifecycle per resource so this meant\nthat there were numerous SoftwareConfig resources (one per lifecycle) for\neach TOSCA node. The resultant HOT template becomes hard to distill how\nthe resources relate to the original TOSCA node definition (both visually\nfrom Horizon, and programmatically from the resource id\'s).\n\nNew to the HOT specification is the SoftwareComponent resource type. This\nworks very similar to the SoftwareConfig resource, but allows for multiple\nlifecycle ""configs"" within the singular SoftwareComponent resource type.\nThis makes for a straight one-to-one mapping from TOSCA nodes to the\nunderlying HOT resources.\n\nThis patch updates the translator implementation to use these new HOT\nSoftwareComponent resource types.\n\nChange-Id: I9d01a6071d893dd7f1c9ed419f81629c88d004e1\nImplements: blueprint tosca-softarecomponents\n'}, {'number': 3, 'created': '2015-09-29 04:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/0e18202cc8031b83e8e3f1f38d42b6eda82c856b', 'message': 'WIP: Implement mapping of TOSCA nodes to HOT SoftwareComponents\n\nCurrently TOSCA nodes are mapped to HOT SoftwareConfig resources. For HOT,\nSoftwareConfig allows for only one lifecycle per resource so this meant\nthat there were numerous SoftwareConfig resources (one per lifecycle) for\neach TOSCA node. The resultant HOT template becomes hard to distill how\nthe resources relate to the original TOSCA node definition (both visually\nfrom Horizon, and programmatically from the resource id\'s).\n\nNew to the HOT specification is the SoftwareComponent resource type. This\nworks very similar to the SoftwareConfig resource, but allows for multiple\nlifecycle ""configs"" within the singular SoftwareComponent resource type.\nThis makes for a straight one-to-one mapping from TOSCA nodes to the\nunderlying HOT resources.\n\nThis patch updates the translator implementation to use these new HOT\nSoftwareComponent resource types.\n\nChange-Id: I9d01a6071d893dd7f1c9ed419f81629c88d004e1\nImplements: blueprint tosca-softarecomponents\n'}, {'number': 4, 'created': '2015-09-29 04:37:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/a0039e0c47b15d6ee2d910d1540097c0a8e4f2d0', 'message': 'WIP: Implement mapping of TOSCA nodes to HOT SoftwareComponents\n\nCurrently TOSCA nodes are mapped to HOT SoftwareConfig resources. For HOT,\nSoftwareConfig allows for only one lifecycle per resource so this meant\nthat there were numerous SoftwareConfig resources (one per lifecycle) for\neach TOSCA node. The resultant HOT template becomes hard to distill how\nthe resources relate to the original TOSCA node definition (both visually\nfrom Horizon, and programmatically from the resource id\'s).\n\nNew to the HOT specification is the SoftwareComponent resource type. This\nworks very similar to the SoftwareConfig resource, but allows for multiple\nlifecycle ""configs"" within the singular SoftwareComponent resource type.\nThis makes for a straight one-to-one mapping from TOSCA nodes to the\nunderlying HOT resources.\n\nThis patch updates the translator implementation to use these new HOT\nSoftwareComponent resource types.\n\nChange-Id: I9d01a6071d893dd7f1c9ed419f81629c88d004e1\nImplements: blueprint tosca-softarecomponents\n'}, {'number': 5, 'created': '2015-10-07 19:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/5e9fded6b1f0bd53503833d04fd52e17550c40e9', 'message': 'WIP: Implement mapping of TOSCA nodes to HOT SoftwareComponents\n\nCurrently TOSCA nodes are mapped to HOT SoftwareConfig resources. For HOT,\nSoftwareConfig allows for only one lifecycle per resource so this meant\nthat there were numerous SoftwareConfig resources (one per lifecycle) for\neach TOSCA node. The resultant HOT template becomes hard to distill how\nthe resources relate to the original TOSCA node definition (both visually\nfrom Horizon, and programmatically from the resource id\'s).\n\nNew to the HOT specification is the SoftwareComponent resource type. This\nworks very similar to the SoftwareConfig resource, but allows for multiple\nlifecycle ""configs"" within the singular SoftwareComponent resource type.\nThis makes for a straight one-to-one mapping from TOSCA nodes to the\nunderlying HOT resources.\n\nThis patch updates the translator implementation to use these new HOT\nSoftwareComponent resource types.\n\nChange-Id: I9d01a6071d893dd7f1c9ed419f81629c88d004e1\nImplements: blueprint tosca-softarecomponents\n'}, {'number': 6, 'created': '2015-10-13 22:19:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/7bbb4dab61707945da38f538c5ae2465ae8bb668', 'message': 'Implement mapping of TOSCA nodes to HOT SoftwareComponents\n\nCurrently TOSCA nodes are mapped to HOT SoftwareConfig resources. For HOT,\nSoftwareConfig allows for only one lifecycle per resource so this meant\nthat there were numerous SoftwareConfig resources (one per lifecycle) for\neach TOSCA node. The resultant HOT template becomes hard to distill how\nthe resources relate to the original TOSCA node definition (both visually\nfrom Horizon, and programmatically from the resource id\'s).\n\nNew to the HOT specification is the SoftwareComponent resource type. This\nworks very similar to the SoftwareConfig resource, but allows for multiple\nlifecycle ""configs"" within the singular SoftwareComponent resource type.\nThis makes for a straight one-to-one mapping from TOSCA nodes to the\nunderlying HOT resources.\n\nThis patch updates the translator implementation to use these new HOT\nSoftwareComponent resource types.\n\nChange-Id: I9d01a6071d893dd7f1c9ed419f81629c88d004e1\nImplements: blueprint tosca-softarecomponents\nCo-Authored-By: Matt Rutkowski\n'}, {'number': 7, 'created': '2015-10-15 17:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/0b100141671e3a4864578f359bad614311fb5763', 'message': 'Implement mapping of TOSCA nodes to HOT SoftwareComponents\n\nCurrently TOSCA nodes are mapped to HOT SoftwareConfig resources. For HOT,\nSoftwareConfig allows for only one lifecycle per resource so this meant\nthat there were numerous SoftwareConfig resources (one per lifecycle) for\neach TOSCA node. The resultant HOT template becomes hard to distill how\nthe resources relate to the original TOSCA node definition (both visually\nfrom Horizon, and programmatically from the resource id\'s).\n\nNew to the HOT specification is the SoftwareComponent resource type. This\nworks very similar to the SoftwareConfig resource, but allows for multiple\nlifecycle ""configs"" within the singular SoftwareComponent resource type.\nThis makes for a straight one-to-one mapping from TOSCA nodes to the\nunderlying HOT resources.\n\nThis patch updates the translator implementation to use these new HOT\nSoftwareComponent resource types.\n\nChange-Id: I9d01a6071d893dd7f1c9ed419f81629c88d004e1\nImplements: blueprint tosca-softarecomponents\nCo-Authored-By: Matt Rutkowski\n'}, {'number': 8, 'created': '2015-10-15 22:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/38532b38bdc8f7b19066bfaa36803ffce6bf0224', 'message': 'Implement mapping of TOSCA nodes to HOT SoftwareComponents\n\nCurrently TOSCA nodes are mapped to HOT SoftwareConfig resources. For HOT,\nSoftwareConfig allows for only one lifecycle per resource so this meant\nthat there were numerous SoftwareConfig resources (one per lifecycle) for\neach TOSCA node. The resultant HOT template becomes hard to distill how\nthe resources relate to the original TOSCA node definition (both visually\nfrom Horizon, and programmatically from the resource id\'s).\n\nNew to the HOT specification is the SoftwareComponent resource type. This\nworks very similar to the SoftwareConfig resource, but allows for multiple\nlifecycle ""configs"" within the singular SoftwareComponent resource type.\nThis makes for a straight one-to-one mapping from TOSCA nodes to the\nunderlying HOT resources.\n\nThis patch updates the translator implementation to use these new HOT\nSoftwareComponent resource types.\n\nChange-Id: I9d01a6071d893dd7f1c9ed419f81629c88d004e1\nImplements: blueprint tosca-softarecomponents\nCo-Authored-By: Matt Rutkowski\n'}, {'number': 9, 'created': '2015-11-03 11:21:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/437d9ad6adfaaf0c5be789d6dca6a010809888a5', 'message': 'Implement mapping of TOSCA nodes to HOT SoftwareComponents\n\nCurrently TOSCA nodes are mapped to HOT SoftwareConfig resources. For HOT,\nSoftwareConfig allows for only one lifecycle per resource so this meant\nthat there were numerous SoftwareConfig resources (one per lifecycle) for\neach TOSCA node. The resultant HOT template becomes hard to distill how\nthe resources relate to the original TOSCA node definition (both visually\nfrom Horizon, and programmatically from the resource id\'s).\n\nNew to the HOT specification is the SoftwareComponent resource type. This\nworks very similar to the SoftwareConfig resource, but allows for multiple\nlifecycle ""configs"" within the singular SoftwareComponent resource type.\nThis makes for a straight one-to-one mapping from TOSCA nodes to the\nunderlying HOT resources.\n\nThis patch updates the translator implementation to use these new HOT\nSoftwareComponent resource types.\n\nChange-Id: I9d01a6071d893dd7f1c9ed419f81629c88d004e1\nImplements: blueprint tosca-softarecomponents\nCo-Authored-By: Matt Rutkowski <mrutkows@us.ibm.com>\n'}, {'number': 10, 'created': '2015-11-10 16:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/70427c96d3e817f750da371b2ba7cd0982ed24d2', 'message': 'Implement mapping of TOSCA nodes to HOT SoftwareComponents\n\nCurrently TOSCA nodes are mapped to HOT SoftwareConfig resources. For HOT,\nSoftwareConfig allows for only one lifecycle per resource so this meant\nthat there were numerous SoftwareConfig resources (one per lifecycle) for\neach TOSCA node. The resultant HOT template becomes hard to distill how\nthe resources relate to the original TOSCA node definition (both visually\nfrom Horizon, and programmatically from the resource id\'s).\n\nNew to the HOT specification is the SoftwareComponent resource type. This\nworks very similar to the SoftwareConfig resource, but allows for multiple\nlifecycle ""configs"" within the singular SoftwareComponent resource type.\nThis makes for a straight one-to-one mapping from TOSCA nodes to the\nunderlying HOT resources.\n\nThis patch updates the translator implementation to use these new HOT\nSoftwareComponent resource types.\n\nChange-Id: I9d01a6071d893dd7f1c9ed419f81629c88d004e1\nImplements: blueprint tosca-softarecomponents\nCo-Authored-By: Matt Rutkowski <mrutkows@us.ibm.com>\n'}, {'number': 11, 'created': '2015-12-04 21:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/d10c9a4477eb427c24165e9e9b5732b5e8ecaac9', 'message': 'Implement mapping of TOSCA nodes to HOT SoftwareComponents\n\nCurrently TOSCA nodes are mapped to HOT SoftwareConfig resources. For HOT,\nSoftwareConfig allows for only one lifecycle per resource so this meant\nthat there were numerous SoftwareConfig resources (one per lifecycle) for\neach TOSCA node. The resultant HOT template becomes hard to distill how\nthe resources relate to the original TOSCA node definition (both visually\nfrom Horizon, and programmatically from the resource id\'s).\n\nNew to the HOT specification is the SoftwareComponent resource type. This\nworks very similar to the SoftwareConfig resource, but allows for multiple\nlifecycle ""configs"" within the singular SoftwareComponent resource type.\nThis makes for a straight one-to-one mapping from TOSCA nodes to the\nunderlying HOT resources.\n\nThis patch updates the translator implementation to use these new HOT\nSoftwareComponent resource types.\n\nChange-Id: I9d01a6071d893dd7f1c9ed419f81629c88d004e1\nImplements: blueprint tosca-softarecomponents\nCo-Authored-By: Matt Rutkowski <mrutkows@us.ibm.com>\n'}, {'number': 12, 'created': '2015-12-05 01:42:14.000000000', 'files': ['translator/tests/data/hot_output/hot_elk_from_csar.yaml', 'translator/tests/data/samples/softwareconfig/hot_elk_from_csar.yaml', 'translator/tests/data/samples/softwareconfig/hot_host_assignment.yaml', 'translator/tests/data/samples/softwareconfig/hot_software_component.yaml', 'translator/tests/data/samples/softwareconfig/hot_web_application.yaml', 'translator/tests/data/hot_output/hot_nodejs_mongodb_two_instances.yaml', 'translator/tests/data/samples/softwareconfig/hot_elk.yaml', 'translator/hot/syntax/hot_resource.py', 'translator/common/utils.py', 'translator/tests/data/samples/softwareconfig/hot_nodejs_mongodb_two_instances.yaml', 'translator/tests/data/samples/softwareconfig/hot_single_instance_wordpress.yaml', 'translator/tests/data/hot_output/hot_elk.yaml', 'translator/tests/data/hot_output/hot_single_instance_wordpress_from_csar.yaml', 'translator/hot/translate_node_templates.py', 'translator/tests/data/hot_output/hot_software_component.yaml', 'translator/tests/data/hot_output/hot_web_application.yaml', 'translator/tests/data/samples/softwareconfig/hot_single_instance_wordpress_from_csar.yaml', 'translator/tests/data/hot_output/hot_host_assignment.yaml', 'translator/tests/data/hot_output/hot_single_instance_wordpress.yaml'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/0dbc167b1960454da08ea46c62f0e3c9c1ed75a4', 'message': 'Implement mapping of TOSCA nodes to HOT SoftwareComponents\n\nCurrently TOSCA nodes are mapped to HOT SoftwareConfig resources. For HOT,\nSoftwareConfig allows for only one lifecycle per resource so this meant\nthat there were numerous SoftwareConfig resources (one per lifecycle) for\neach TOSCA node. The resultant HOT template becomes hard to distill how\nthe resources relate to the original TOSCA node definition (both visually\nfrom Horizon, and programmatically from the resource id\'s).\n\nNew to the HOT specification is the SoftwareComponent resource type. This\nworks very similar to the SoftwareConfig resource, but allows for multiple\nlifecycle ""configs"" within the singular SoftwareComponent resource type.\nThis makes for a straight one-to-one mapping from TOSCA nodes to the\nunderlying HOT resources.\n\nThis patch updates the translator implementation to use these new HOT\nSoftwareComponent resource types.\n\nChange-Id: I9d01a6071d893dd7f1c9ed419f81629c88d004e1\nImplements: blueprint tosca-softarecomponents\nCo-Authored-By: Matt Rutkowski <mrutkows@us.ibm.com>\n'}]",0,228701,0dbc167b1960454da08ea46c62f0e3c9c1ed75a4,44,4,12,15642,,,0,"Implement mapping of TOSCA nodes to HOT SoftwareComponents

Currently TOSCA nodes are mapped to HOT SoftwareConfig resources. For HOT,
SoftwareConfig allows for only one lifecycle per resource so this meant
that there were numerous SoftwareConfig resources (one per lifecycle) for
each TOSCA node. The resultant HOT template becomes hard to distill how
the resources relate to the original TOSCA node definition (both visually
from Horizon, and programmatically from the resource id's).

New to the HOT specification is the SoftwareComponent resource type. This
works very similar to the SoftwareConfig resource, but allows for multiple
lifecycle ""configs"" within the singular SoftwareComponent resource type.
This makes for a straight one-to-one mapping from TOSCA nodes to the
underlying HOT resources.

This patch updates the translator implementation to use these new HOT
SoftwareComponent resource types.

Change-Id: I9d01a6071d893dd7f1c9ed419f81629c88d004e1
Implements: blueprint tosca-softarecomponents
Co-Authored-By: Matt Rutkowski <mrutkows@us.ibm.com>
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/01/228701/9 && git format-patch -1 --stdout FETCH_HEAD,"['translator/hot/translate_node_templates.py', 'translator/hot/syntax/hot_resource.py']",2,281dad750e53a178fd90b21e71490a0bed543798,bp/tosca-softarecomponents,"from translator.toscalib.functions import GetInput from translator.toscalib.nodetemplate import NodeTemplate from translator.toscalib.utils.gettextutils import _ # if type == 'OS::Heat::SoftwareConfig': # self.properties['group'] = 'script' def create_sw_comp(self): '''Create SW Component and associated SW Deployment Resources''' # sw_comp_resources = [] deploy_lookup = {} # TODO(anyone): sequence for life cycle needs to cover different # scenarios and cannot be fixed or hard coded here interfaces_deploy_sequence = ['create', 'configure', 'start'] # NEW(jruano): Lifecycle scripts for resource configs = [] # hold the original name since it will be changed during # the transformation # NOTE(jruano): Not exactly sure that this is needed anymore node_name = self.name reserve_current = 'NONE' interfaces_actual = [] for interface in self.nodetemplate.interfaces: interfaces_actual.append(interface.name) # NOTE(jruano): not sure what this exactly is # supposed to do, but leaving it in for now for operation in interfaces_deploy_sequence: if operation in interfaces_actual: reserve_current = operation break # create the set of SoftwareDeployment and SoftwareConfig for # the interface operations # NOTE(jruano): This is most likely where things change hosting_server = None if self.nodetemplate.requirements is not None: hosting_server = self._get_hosting_server() # NOTE(jruano): Build configs? # # configs should look like: # # configs[{'actions':[...], 'config':' ', 'tool': 'script'}] for interface in self.nodetemplate.interfaces: actions = [] if interface.name in interfaces_deploy_sequence: actions.append(interface.name.upper()) config_file = {'get_file': interface.implementation} config = OrderedDict([('actions', actions), ('config', config_file), ('tool', 'script')]) configs.append(config) # config_name = node_name + '_' + interface.name + '_config' # deploy_name = node_name + '_' + interface.name + '_deploy' self.name = node_name + '_sw_comp' self.type = 'OS::Heat::SoftwareComponent' self.properties['configs'] = configs # Create deployment resource deploy_name = node_name + '_deploy' # hosting_server is None if requirements is None hosting_on_server = (hosting_server.name if hosting_server else None) # if interface.name == reserve_current: # deploy_resource = self # self.name = deploy_name # self.type = 'OS::Heat::SoftwareDeployment' # self.properties = {'config': {'get_resource': config_name}, # 'server': {'get_resource': # hosting_on_server}} # deploy_lookup[interface.name] = self # else: sd_config = {'config': {'get_resource': self.name}, 'server': {'get_resource': hosting_on_server}} deploy_resource = \ HotResource(self.nodetemplate, deploy_name, 'OS::Heat::SoftwareDeployment', sd_config) # sw_comp_resources.append(deploy_resource) # Add dependencies for the set of HOT resources in the sequence defined # in interfaces_deploy_sequence # TODO(anyone): find some better way to encode this implicit sequence ''' group = {} for op, hot in deploy_lookup.items(): # position to determine potential preceding nodes op_index = interfaces_deploy_sequence.index(op) for preceding_op in \ reversed(interfaces_deploy_sequence[:op_index]): preceding_hot = deploy_lookup.get(preceding_op) if preceding_hot: hot.depends_on.append(preceding_hot) hot.depends_on_nodes.append(preceding_hot) group[preceding_hot] = hot break # save this dependency chain in the set of HOT resources self.group_dependencies.update(group) for hot in hot_resources: hot.group_dependencies.update(group) ''' return deploy_resource ''' '''",from toscaparser.functions import GetInput from toscaparser.nodetemplate import NodeTemplate from toscaparser.utils.gettextutils import _ if type == 'OS::Heat::SoftwareConfig': self.properties['group'] = 'script',150,34
openstack%2Fironic-python-agent~master~I5e50c32609c6292e815b674874d4225f47395ff6,openstack/ironic-python-agent,master,I5e50c32609c6292e815b674874d4225f47395ff6,Cleanup tempdir if '_get_partition' dies,NEW,2015-09-02 23:41:01.000000000,2017-12-18 05:25:21.000000000,,"[{'_account_id': 1297}, {'_account_id': 10239}, {'_account_id': 10342}]","[{'number': 1, 'created': '2015-09-02 23:41:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/d480f053a1f87cd52a4311886576c92b669e71b6', 'message': ""Cleanup tempdir if '_get_partition' dies\n\nIn the case where the '_get_partition' function\nraises an exception we want to make sure that the\ntemporary directory is cleaned up (vs leaving it\naround).\n\nChange-Id: I5e50c32609c6292e815b674874d4225f47395ff6\n""}, {'number': 2, 'created': '2015-09-10 23:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/4d07fe93cb12ec977230d7c465c1093fd0b1be8b', 'message': ""Cleanup tempdir if '_get_partition' dies\n\nIn the case where the '_get_partition' function\nraises an exception we want to make sure that the\ntemporary directory is cleaned up (vs leaving it\naround).\n\nChange-Id: I5e50c32609c6292e815b674874d4225f47395ff6\n""}, {'number': 3, 'created': '2015-09-10 23:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/15ed0bcc169026114fe3e060c5f43b447d891fe0', 'message': ""Cleanup tempdir if '_get_partition' dies\n\nIn the case where the '_get_partition' function\nraises an exception we want to make sure that the\ntemporary directory is cleaned up (vs leaving it\naround).\n\nChange-Id: I5e50c32609c6292e815b674874d4225f47395ff6\n""}, {'number': 4, 'created': '2016-02-04 20:30:24.000000000', 'files': ['ironic_python_agent/tests/unit/extensions/test_image.py', 'ironic_python_agent/extensions/image.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/8f9937ad87ac4db55c5811d0eda425c52ddab21c', 'message': ""Cleanup tempdir if '_get_partition' dies\n\nIn the case where the '_get_partition' function\nraises an exception we want to make sure that the\ntemporary directory is cleaned up (vs leaving it\naround).\n\nChange-Id: I5e50c32609c6292e815b674874d4225f47395ff6\n""}]",2,219915,8f9937ad87ac4db55c5811d0eda425c52ddab21c,19,3,4,1297,,,0,"Cleanup tempdir if '_get_partition' dies

In the case where the '_get_partition' function
raises an exception we want to make sure that the
temporary directory is cleaned up (vs leaving it
around).

Change-Id: I5e50c32609c6292e815b674874d4225f47395ff6
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/15/219915/4 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent/extensions/image.py'],1,d480f053a1f87cd52a4311886576c92b669e71b6,219915,"from oslo_utils import excutils try: efi_partition = _get_partition(device, uuid=efi_system_part_uuid) except (errors.CommandExecutionError, errors.DeviceNotFound): with excutils.save_and_reraise_exception(): shutil.rmtree(path)"," efi_partition = _get_partition(device, uuid=efi_system_part_uuid)",7,1
openstack%2Fzaqar~master~Id9833d907eca7a808a09ac7c750bc3b54da848ab,openstack/zaqar,master,Id9833d907eca7a808a09ac7c750bc3b54da848ab,Decorator fuction to Validate UUIDs in Redis Driver,NEW,2015-03-18 22:25:48.000000000,2017-12-18 05:25:14.000000000,,"[{'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6484}, {'_account_id': 12321}, {'_account_id': 12758}, {'_account_id': 15470}, {'_account_id': 18009}]","[{'number': 1, 'created': '2015-03-18 22:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ddc83b47c342cd0512f237f1ffa70488717782ab', 'message': 'Decorator fuction to Validate UUIDs in Redis Driver\n\nImplemented a decorator function to validate UUIDs which\nare passed to functions as arguments. Created an error to\nbe raised if UUID is Invalid. Updated functions in the Redis\ndriver by wrapping the decorator.\n\nCloses-Bug #1367024\n\nChange-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab\n'}, {'number': 2, 'created': '2015-03-22 02:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/a391d02441acdcba28663575b119c3aa91dc6f49', 'message': 'Decorator fuction to Validate UUIDs in Redis Driver\n\nImplemented a decorator function to validate UUIDs which\nare passed to functions as arguments. Created an error to\nbe raised if UUID is Invalid. Updated functions in the Redis\ndriver by wrapping the decorator.\n\nCloses-Bug #1367024\n\nChange-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab\n'}, {'number': 3, 'created': '2015-07-28 15:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/b8ba4402b90f30e47ab664001afb989aa1bf71df', 'message': 'Decorator fuction to Validate UUIDs in Redis Driver\n\nImplemented a decorator function to validate UUIDs which\nare passed to functions as arguments. Created an error to\nbe raised if UUID is Invalid. Updated functions in the Redis\ndriver by wrapping the decorator.\n\nCloses-Bug #1367024\n\nChange-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab\n'}, {'number': 4, 'created': '2015-08-11 14:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/4c9a865b81b9c7cfc4b6546e1ed3dc8a4e697fff', 'message': 'Decorator fuction to Validate UUIDs in Redis Driver\n\nImplemented a decorator function to validate UUIDs which\nare passed to functions as arguments. Created an error to\nbe raised if UUID is Invalid. Updated functions in the Redis\ndriver by wrapping the decorator.\n\nCloses-Bug #1367024\n\nChange-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab\n'}, {'number': 5, 'created': '2015-10-03 00:32:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/75558d309aa1cdf5ca655ab2b3d37e6a56560592', 'message': 'Decorator fuction to Validate UUIDs in Redis Driver\n\nImplemented a decorator function to validate UUIDs which\nare passed to functions as arguments. Created an error to\nbe raised if UUID is Invalid. Updated functions in the Redis\ndriver by wrapping the decorator.\n\nCloses-Bug #1367024\n\nChange-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab\n'}, {'number': 6, 'created': '2015-10-28 19:05:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e593a79ef97bb3ee87977d49e51205f7ba8e5dd2', 'message': 'Decorator fuction to Validate UUIDs in Redis Driver\n\nImplemented a decorator function to validate UUIDs which\nare passed to functions as arguments. Created an error to\nbe raised if UUID is Invalid. Updated functions in the Redis\ndriver by wrapping the decorator.\n\nCloses-Bug #1367024\n\nChange-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab\n'}, {'number': 7, 'created': '2015-10-28 19:56:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/fed7265675aaa0684446adf44ad3b7df312b8fbe', 'message': 'Decorator fuction to Validate UUIDs in Redis Driver\n\nImplemented a decorator function to validate UUIDs which\nare passed to functions as arguments. Created an error to\nbe raised if UUID is Invalid. Updated functions in the Redis\ndriver by wrapping the decorator.\n\nCloses-Bug #1367024\n\nChange-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab\n'}, {'number': 8, 'created': '2015-10-28 21:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/a53ef17742118b5f62eba34808f7a0101dd19ae4', 'message': 'Decorator fuction to Validate UUIDs in Redis Driver\n\nImplemented a decorator function to validate UUIDs which\nare passed to functions as arguments. Created an error to\nbe raised if UUID is Invalid. Updated functions in the Redis\ndriver by wrapping the decorator.\n\nCloses-Bug #1367024\n\nChange-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab\n'}, {'number': 9, 'created': '2015-10-29 16:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/1fe9695eff554f6b01e88df1c122f4caa9bee8ec', 'message': 'Decorator fuction to Validate UUIDs in Redis Driver\n\nImplemented a decorator function to validate UUIDs which\nare passed to functions as arguments. Created an error to\nbe raised if UUID is Invalid. Updated functions in the Redis\ndriver by wrapping the decorator.\n\nCloses-Bug:1367024\n\nChange-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab\n'}, {'number': 10, 'created': '2015-10-29 16:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/19a72dabd969e691ead242f85bcee023644a6aa9', 'message': 'Decorator fuction to Validate UUIDs in Redis Driver\n\nImplemented a decorator function to validate UUIDs which\nare passed to functions as arguments. Created an error to\nbe raised if UUID is Invalid. Updated functions in the Redis\ndriver by wrapping the decorator. Wrote a test to check if\nthe new exception is being raised. \n\nCloses-Bug:1367024\n\nChange-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab\n'}, {'number': 11, 'created': '2015-10-29 17:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/78d6cd8556c2ed3282f533163fd1b413a0a85d6a', 'message': 'Decorator fuction to Validate UUIDs in Redis Driver\n\nImplemented a decorator function to validate UUIDs which\nare passed to functions as arguments. Created an error to\nbe raised if UUID is Invalid. Updated functions in the Redis\ndriver by wrapping the decorator. Wrote a test to check if\nthe new exception is being raised.\n\nCloses-Bug:1367024\n\nChange-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab\n'}, {'number': 12, 'created': '2015-10-30 21:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/94db70375c7b9b61bd36c92a8987933617167878', 'message': 'Decorator fuction to Validate UUIDs in Redis Driver\n\nImplemented a decorator function to validate UUIDs which\nare passed to functions as arguments. Created an error to\nbe raised if UUID is Invalid. Updated functions in the Redis\ndriver by wrapping the decorator. Wrote a test to check if\nthe new exception is being raised.\n\nCloses-Bug:1367024\n\nChange-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab\n'}, {'number': 13, 'created': '2015-10-31 12:10:58.000000000', 'files': ['zaqar/tests/unit/storage/test_impl_redis.py', 'zaqar/storage/errors.py', 'zaqar/storage/redis/messages.py', 'zaqar/common/decorators.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/826004d58465ccf75302a339ceadbe14db32dd55', 'message': 'Decorator fuction to Validate UUIDs in Redis Driver\n\nImplemented a decorator function to validate UUIDs which\nare passed to functions as arguments. Created an error to\nbe raised if UUID is Invalid. Updated functions in the Redis\ndriver by wrapping the decorator. Wrote a test to check if\nthe new exception is being raised.\n\nCloses-Bug:1367024\n\nChange-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab\n'}]",2,165632,826004d58465ccf75302a339ceadbe14db32dd55,38,7,13,15470,,,0,"Decorator fuction to Validate UUIDs in Redis Driver

Implemented a decorator function to validate UUIDs which
are passed to functions as arguments. Created an error to
be raised if UUID is Invalid. Updated functions in the Redis
driver by wrapping the decorator. Wrote a test to check if
the new exception is being raised.

Closes-Bug:1367024

Change-Id: Id9833d907eca7a808a09ac7c750bc3b54da848ab
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/32/165632/7 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/storage/errors.py', 'zaqar/storage/redis/messages.py', 'zaqar/common/decorators.py']",3,ddc83b47c342cd0512f237f1ffa70488717782ab,bug/1367024,"import inspect import uuidimport zaqar.storage.errors as StorageError def validate_uuid(fn): """"""Decorator for Redis Driver Methods that use UUIDs as Arguments. Validates UUIDs before calling function """""" @functools.wraps(fn) def wrapper(*args, **kwargs): # Makes a dictionary of argument names and values passed on function # call. frame = inspect.getargspec(fn) argval = {} for i in range(len(args)): argval.update({frame.args[i]: args[i]}) j = 0 for i in frame.args: if i not in argval: argval.update({i: frame.defaults[j]}) j = j + 1 argval.update(kwargs) # Validation of UUIDs uuid_parameters = ['client_uuid', 'message_id', 'claim', ] for i in argval: if i in uuid_parameters: try: uuid.UUID(argval[i], version=4) except ValueError: if i == 'claims' and argval[i] == 'None': pass else: raise StorageError.UUIDInvalid(i) ret = fn(*args, **kwargs) return ret return wrapper",,49,0
openstack%2Fswift~master~Id9cc2cddbf07fa1ab1dfe9f721c6ce5ddf0383be,openstack/swift,master,Id9cc2cddbf07fa1ab1dfe9f721c6ce5ddf0383be,Removed the unnecessary comment about FakeRing._get_parts method reported in bug #1488704,NEW,2016-01-04 15:36:49.000000000,2017-12-18 05:25:12.000000000,,[{'_account_id': 330}],"[{'number': 1, 'created': '2016-01-04 15:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/28faa2621cb71b5dc5dac045c02a1aa4ef96ebc3', 'message': 'Removed the unnecessary comment about FakeRing._get_parts method reported in bug #1488704\n\nChange-Id: Id9cc2cddbf07fa1ab1dfe9f721c6ce5ddf0383be\nCloses-Bug:#1488704\n'}, {'number': 2, 'created': '2016-01-04 15:43:50.000000000', 'files': ['test/unit/__init__.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/dd9c283923086646caf59b236eb5d08274d42afe', 'message': 'Removed the unnecessary comment about FakeRing._get_parts method\nreported in bug #1488704\n\nChange-Id: Id9cc2cddbf07fa1ab1dfe9f721c6ce5ddf0383be\nCloses-Bug:#1488704\n'}]",1,263307,dd9c283923086646caf59b236eb5d08274d42afe,5,1,2,13540,,,0,"Removed the unnecessary comment about FakeRing._get_parts method
reported in bug #1488704

Change-Id: Id9cc2cddbf07fa1ab1dfe9f721c6ce5ddf0383be
Closes-Bug:#1488704
",git fetch https://review.opendev.org/openstack/swift refs/changes/07/263307/2 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/__init__.py'],1,28faa2621cb71b5dc5dac045c02a1aa4ef96ebc3,bug/1488704,," """""" :param part_power: make part calculation based on the path If you set a part_power when you setup your FakeRing the parts you get out of ring methods will actually be based on the path - otherwise we exercise the real ring code, but ignore the result and return 1. """"""",0,7
openstack%2Frally~master~I11334a6b892b3679690b40e2c06474b5aa0b9d73,openstack/rally,master,I11334a6b892b3679690b40e2c06474b5aa0b9d73,Use dict and set comprehension instead of using dict() and set(),NEW,2016-01-28 10:47:54.000000000,2017-12-18 05:25:00.000000000,,"[{'_account_id': 6835}, {'_account_id': 8491}, {'_account_id': 9545}, {'_account_id': 11208}, {'_account_id': 14817}, {'_account_id': 18785}]","[{'number': 1, 'created': '2016-01-28 10:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e6a123430981f425b074086e9fc2414a46f233f0', 'message': 'Use dict and set comprehension instead of using dict() and set()\n\nChange-Id: I11334a6b892b3679690b40e2c06474b5aa0b9d73\nCloses-Bug: #1538519\n'}, {'number': 2, 'created': '2016-02-02 06:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c665c45343ba9c85759f1d20854353f1f88cbb2f', 'message': 'Use dict and set comprehension instead of using dict() and set()\n\nChange-Id: I11334a6b892b3679690b40e2c06474b5aa0b9d73\nCloses-Bug: #1538519\n'}, {'number': 3, 'created': '2016-02-02 12:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8ddd9c26a762a49188c3473ca47b2a74ad287f09', 'message': 'Use dict and set comprehension instead of using dict() and set()\n\nChange-Id: I11334a6b892b3679690b40e2c06474b5aa0b9d73\nCloses-Bug: #1538519\n'}, {'number': 4, 'created': '2016-02-03 02:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/95f1b4e8d171450ff604841dfc9364b260b920e1', 'message': 'Use dict and set comprehension instead of using dict() and set()\n\nChange-Id: I11334a6b892b3679690b40e2c06474b5aa0b9d73\nCloses-Bug: #1538519\n'}, {'number': 5, 'created': '2016-02-16 03:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/035c0c2ca9745797addcc10a975f9f4780d37a35', 'message': 'Use dict and set comprehension instead of using dict() and set()\n\nChange-Id: I11334a6b892b3679690b40e2c06474b5aa0b9d73\nCloses-Bug: #1538519\n'}, {'number': 6, 'created': '2016-02-23 05:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2bfc8bf83e2cf4f3ff05b92b9d7cb597a7bffd12', 'message': 'Use dict and set comprehension instead of using dict() and set()\n\nChange-Id: I11334a6b892b3679690b40e2c06474b5aa0b9d73\nCloses-Bug: #1538519\n'}, {'number': 7, 'created': '2016-02-23 06:59:23.000000000', 'files': ['tests/hacking/checks.py', 'tests/unit/common/db/test_api.py', 'tests/unit/common/test_utils.py', 'rally/plugins/openstack/context/api_versions.py', 'rally/task/sla.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/0beb074a269a8f80783e2764b52189437ec809c4', 'message': 'Use dict and set comprehension instead of using dict() and set()\n\nChange-Id: I11334a6b892b3679690b40e2c06474b5aa0b9d73\nCloses-Bug: #1538519\n'}]",6,273449,0beb074a269a8f80783e2764b52189437ec809c4,46,6,7,18785,,,0,"Use dict and set comprehension instead of using dict() and set()

Change-Id: I11334a6b892b3679690b40e2c06474b5aa0b9d73
Closes-Bug: #1538519
",git fetch https://review.opendev.org/openstack/rally refs/changes/49/273449/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/hacking/checks.py', 'tests/unit/common/db/test_api.py', 'tests/unit/common/test_utils.py', 'rally/plugins/openstack/context/api_versions.py', 'tests/ci/render.py', 'rally/task/sla.py', 'rally/task/utils.py']",7,e6a123430981f425b074086e9fc2414a46f233f0,new_dict, ready_statuses = set(s.upper() for s in ready_statuses or []) failure_statuses = set(s.upper() for s in failure_statuses or []), ready_statuses = set([s.upper() for s in ready_statuses or []]) failure_statuses = set([s.upper() for s in failure_statuses or []]),35,13
openstack%2Frally~master~I6b6eace0bd54cec8d8832fb952668e05d511bd78,openstack/rally,master,I6b6eace0bd54cec8d8832fb952668e05d511bd78,"[transform] ""NotFound"" exception for not found resource",NEW,2015-10-14 06:37:02.000000000,2017-12-18 05:24:45.000000000,,"[{'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-10-14 06:37:02.000000000', 'files': ['rally/exceptions.py', 'rally/task/types.py', 'tests/unit/task/test_types.py', 'rally/task/validation.py', 'rally/common/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/6d48b4f17e310cf0811ec5ef5658f214072c7f3a', 'message': '[transform] ""NotFound"" exception for not found resource\n\nBefore this fix, transform codes raise InvalidScenarioArgument for any\ncase. This will mess up bussiness logic in other module. For example, in\nthe related bug report, validation needs know notfound case and multiple\nfound case, but it has to do more try-except or if-else block to handle\nInvalidscenarioargument. With this patch, validation codes could be\nimproved easily.\n\nChange-Id: I6b6eace0bd54cec8d8832fb952668e05d511bd78\nRelated-Bug: #1484756\n'}]",0,234594,6d48b4f17e310cf0811ec5ef5658f214072c7f3a,6,2,1,6835,,,0,"[transform] ""NotFound"" exception for not found resource

Before this fix, transform codes raise InvalidScenarioArgument for any
case. This will mess up bussiness logic in other module. For example, in
the related bug report, validation needs know notfound case and multiple
found case, but it has to do more try-except or if-else block to handle
Invalidscenarioargument. With this patch, validation codes could be
improved easily.

Change-Id: I6b6eace0bd54cec8d8832fb952668e05d511bd78
Related-Bug: #1484756
",git fetch https://review.opendev.org/openstack/rally refs/changes/94/234594/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/exceptions.py', 'rally/task/types.py', 'tests/unit/task/test_types.py', 'rally/task/validation.py', 'rally/common/db/sqlalchemy/api.py']",5,6d48b4f17e310cf0811ec5ef5658f214072c7f3a,bug/1484756," raise exceptions.ResourceNotFound(config={""id"": id})", raise exceptions.ResourceNotFound(id=id),26,31
openstack%2Frally~master~I0f5ecb399f87ad8228fc73674022b976442f624b,openstack/rally,master,I0f5ecb399f87ad8228fc73674022b976442f624b,Adds Designate zone-update test,NEW,2016-01-08 10:47:08.000000000,2017-12-18 05:24:36.000000000,,"[{'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 19811}]","[{'number': 1, 'created': '2016-01-08 10:47:08.000000000', 'files': ['rally-jobs/rally-designate.yaml', 'samples/tasks/scenarios/designate/create-and-update-zone.json', 'tests/unit/plugins/openstack/scenarios/designate/test_basic.py', 'rally/plugins/openstack/scenarios/designate/basic.py', 'tests/unit/plugins/openstack/scenarios/designate/test_utils.py', 'samples/tasks/scenarios/designate/create-and-update-zone.yaml', 'rally/plugins/openstack/scenarios/designate/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/8cbfdeac1ae063a31cd98f8e757f3cb7e6238f2d', 'message': 'Adds Designate zone-update test\n\nThis submission adds create_and_update_zone method to rally/benchmark/scenarios/designate/basic.py.\nAdds update method to ""utils.py"" under ""rally/benchmark/scenarios/designate"".\nAdded configuration files for designate update-zone operation under samples/tasks/scenarios/designate.\n1) create-and-update-zone.json 2) create-and-update-zone.yaml.\nAlso added unit tests to \'test_basic.py\' and \'test_utils.py\' under \'rally/tests/unit/plugins/openstack/scenarios/designate\'\n\nChange-Id: I0f5ecb399f87ad8228fc73674022b976442f624b\n'}]",5,265178,8cbfdeac1ae063a31cd98f8e757f3cb7e6238f2d,11,3,1,1795,,,0,"Adds Designate zone-update test

This submission adds create_and_update_zone method to rally/benchmark/scenarios/designate/basic.py.
Adds update method to ""utils.py"" under ""rally/benchmark/scenarios/designate"".
Added configuration files for designate update-zone operation under samples/tasks/scenarios/designate.
1) create-and-update-zone.json 2) create-and-update-zone.yaml.
Also added unit tests to 'test_basic.py' and 'test_utils.py' under 'rally/tests/unit/plugins/openstack/scenarios/designate'

Change-Id: I0f5ecb399f87ad8228fc73674022b976442f624b
",git fetch https://review.opendev.org/openstack/rally refs/changes/78/265178/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally-jobs/rally-designate.yaml', 'samples/tasks/scenarios/designate/create-and-update-zone.json', 'tests/unit/plugins/openstack/scenarios/designate/test_basic.py', 'rally/plugins/openstack/scenarios/designate/basic.py', 'tests/unit/plugins/openstack/scenarios/designate/test_utils.py', 'samples/tasks/scenarios/designate/create-and-update-zone.yaml', 'rally/plugins/openstack/scenarios/designate/utils.py']",7,8cbfdeac1ae063a31cd98f8e757f3cb7e6238f2d,separate/designate-zones," @atomic.action_timer(""designate.update_zone"") def _update_zone(self, zone_id): """"""Update designate zone. :param zone_id: designate zone_id """""" values = {""ttl"": 70, ""description"": ""updated description"", ""email"": ""updated@random.name""} return self.clients(""designate"", version=""2"").zones.update(zone_id, values) ",,116,0
openstack%2Fopenstack~master~I49d49ec042faa1dcbfe44d29e2d7e7eeeecbdcad,openstack/openstack,master,I49d49ec042faa1dcbfe44d29e2d7e7eeeecbdcad,Periodic update of .gitmodules,NEW,2015-04-20 16:06:36.000000000,2017-12-18 05:24:28.000000000,,[],"[{'number': 1, 'created': '2015-04-20 16:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack/commit/435bb031cc16abdc2727cbf6e42097abae5aec15', 'message': 'Periodic update of .gitmodules\n\nUpdate this repo to better reflect the latest list of projects in\nopenstack.\n\nChange-Id: I49d49ec042faa1dcbfe44d29e2d7e7eeeecbdcad\n'}, {'number': 2, 'created': '2015-05-13 18:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack/commit/ce52a4fedf2ac0422a5580a9c01134c2c2f04ccb', 'message': 'Periodic update of .gitmodules\n\nUpdate this repo to better reflect the latest list of projects in\nopenstack.\n\nChange-Id: I49d49ec042faa1dcbfe44d29e2d7e7eeeecbdcad\n'}, {'number': 3, 'created': '2015-06-05 05:09:03.000000000', 'files': ['.gitmodules'], 'web_link': 'https://opendev.org/openstack/openstack/commit/7dc734f259712c764122d1abfeed3400ca9a8184', 'message': 'Periodic update of .gitmodules\n\nUpdate this repo to better reflect the latest list of projects in\nopenstack.\n\nChange-Id: I49d49ec042faa1dcbfe44d29e2d7e7eeeecbdcad\n'}]",0,175469,7dc734f259712c764122d1abfeed3400ca9a8184,8,0,3,1849,,,0,"Periodic update of .gitmodules

Update this repo to better reflect the latest list of projects in
openstack.

Change-Id: I49d49ec042faa1dcbfe44d29e2d7e7eeeecbdcad
",git fetch https://review.opendev.org/openstack/openstack refs/changes/69/175469/3 && git format-patch -1 --stdout FETCH_HEAD,['.gitmodules'],1,435bb031cc16abdc2727cbf6e42097abae5aec15,bigtent,"[submodule ""devstack-plugin-cookiecutter""] path = devstack-plugin-cookiecutter url = https://review.openstack.org/openstack-dev/devstack-plugin-cookiecutter.git branch = .[submodule ""ansible-puppet""] path = ansible-puppet url = https://review.openstack.org/openstack-infra/ansible-puppet.git branch = .[submodule ""bindep""] path = bindep url = https://review.openstack.org/openstack-infra/bindep.git branch = .[submodule ""puppet-bandersnatch""] path = puppet-bandersnatch url = https://review.openstack.org/openstack-infra/puppet-bandersnatch.git branch = .[submodule ""puppet-diskimage_builder""] path = puppet-diskimage_builder url = https://review.openstack.org/openstack-infra/puppet-diskimage_builder.git branch = .[submodule ""puppet-openstackci""] path = puppet-openstackci url = https://review.openstack.org/openstack-infra/puppet-openstackci.git branch = .[submodule ""puppet-pgsql_backup""] path = puppet-pgsql_backup url = https://review.openstack.org/openstack-infra/puppet-pgsql_backup.git branch = .[submodule ""puppet-puppet""] path = puppet-puppet url = https://review.openstack.org/openstack-infra/puppet-puppet.git branch = .[submodule ""congress""] path = congress url = https://review.openstack.org/openstack/congress.git branch = . [submodule ""congress-specs""] path = congress-specs url = https://review.openstack.org/openstack/congress-specs.git branch = . [submodule ""coreos-image-builder""] path = coreos-image-builder url = https://review.openstack.org/openstack/coreos-image-builder.git branch = .[submodule ""defcore""] path = defcore url = https://review.openstack.org/openstack/defcore.git branch = .[submodule ""gnocchi""] path = gnocchi url = https://review.openstack.org/openstack/gnocchi.git branch = .[submodule ""ironic-lib""] path = ironic-lib url = https://review.openstack.org/openstack/ironic-lib.git branch = .[submodule ""magnum""] path = magnum url = https://review.openstack.org/openstack/magnum.git branch = .[submodule ""murano""] path = murano url = https://review.openstack.org/openstack/murano.git branch = . [submodule ""murano-agent""] path = murano-agent url = https://review.openstack.org/openstack/murano-agent.git branch = . [submodule ""murano-apps""] path = murano-apps url = https://review.openstack.org/openstack/murano-apps.git branch = . [submodule ""murano-dashboard""] path = murano-dashboard url = https://review.openstack.org/openstack/murano-dashboard.git branch = . [submodule ""murano-deployment""] path = murano-deployment url = https://review.openstack.org/openstack/murano-deployment.git branch = . [submodule ""murano-specs""] path = murano-specs url = https://review.openstack.org/openstack/murano-specs.git branch = .[submodule ""os-brick""] path = os-brick url = https://review.openstack.org/openstack/os-brick.git branch = . [submodule ""os-client-config""] path = os-client-config url = https://review.openstack.org/openstack/os-client-config.git branch = .[submodule ""os-testr""] path = os-testr url = https://review.openstack.org/openstack/os-testr.git branch = .[submodule ""python-congressclient""] path = python-congressclient url = https://review.openstack.org/openstack/python-congressclient.git branch = .[submodule ""python-keystoneclient-saml2""] path = python-keystoneclient-saml2 url = https://review.openstack.org/openstack/python-keystoneclient-saml2.git branch = .[submodule ""python-magnumclient""] path = python-magnumclient url = https://review.openstack.org/openstack/python-magnumclient.git branch = .[submodule ""python-muranoclient""] path = python-muranoclient url = https://review.openstack.org/openstack/python-muranoclient.git branch = .[submodule ""rally""] path = rally url = https://review.openstack.org/openstack/rally.git branch = .[submodule ""tripleo-common""] path = tripleo-common url = https://review.openstack.org/openstack/tripleo-common.git branch = .","[submodule ""python-keystoneclient-federation""] path = python-keystoneclient-federation url = https://review.openstack.org/openstack/python-keystoneclient-federation.git branch = .",120,4
openstack%2Fzaqar~master~I032aee0d30b1115f6dc4de544700898809ad16c1,openstack/zaqar,master,I032aee0d30b1115f6dc4de544700898809ad16c1,DRY up usage of url_prefix in wsgi unit test,NEW,2015-10-14 12:48:51.000000000,2017-12-18 05:24:16.000000000,,"[{'_account_id': 6413}, {'_account_id': 12321}, {'_account_id': 15470}]","[{'number': 1, 'created': '2015-10-14 12:48:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0c6feaebe4baefd089117605b79cb27629197088', 'message': 'DRY up usage of url_prefix in wsgi unit test\nThe usage of this variable can be refactored to adhere to DRY\nprinciples. Introduced a check for the presence of url_prefix\nin the method call itself.\n\nChange-Id: I032aee0d30b1115f6dc4de544700898809ad16c1\nCloses-Bug:150616\n'}, {'number': 2, 'created': '2015-10-14 12:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/5e39a88a53f8ab15f3939b3a08fa90f5a6d726d0', 'message': 'DRY up usage of url_prefix in wsgi unit test\n\nThe variable url_prefix is repeatedly added to various\ninstances of paths in unit tests. This can be refactored by adding\na check for the presence of the url_prefix in the test method\nitself.\n\nChange-Id: I032aee0d30b1115f6dc4de544700898809ad16c1\nCloses-Bug:1506016\n'}, {'number': 3, 'created': '2015-10-28 21:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/47fecfffedaaab7f1e7c18773435e1413c515afa', 'message': 'DRY up usage of url_prefix in wsgi unit test\n\nThe variable url_prefix is repeatedly added to various\ninstances of paths in unit tests. This can be refactored by adding\na check for the presence of the url_prefix in the test method\nitself.\n\nChange-Id: I032aee0d30b1115f6dc4de544700898809ad16c1\nCloses-Bug:1506016\n'}, {'number': 4, 'created': '2015-10-28 21:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ed1d9ecddb3854490524c26fed30e49725147c8e', 'message': 'DRY up usage of url_prefix in wsgi unit test\n\nThe variable url_prefix is repeatedly added to various\ninstances of paths in unit tests. This can be refactored by adding\na check for the presence of the url_prefix in the test method\nitself.\n\nChange-Id: I032aee0d30b1115f6dc4de544700898809ad16c1\nCloses-Bug:1506016\n'}, {'number': 5, 'created': '2015-10-28 22:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/3b72e2758fa9784fc9e37f02add98b62bfdddc58', 'message': 'DRY up usage of url_prefix in wsgi unit test\n\nThe variable url_prefix is repeatedly added to various\ninstances of paths in unit tests. This can be refactored by adding\na check for the presence of the url_prefix in the test method\nitself.\n\nChange-Id: I032aee0d30b1115f6dc4de544700898809ad16c1\nCloses-Bug:1506016\n'}, {'number': 6, 'created': '2015-11-02 15:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/72063e0ed7dadc6a95897ad9128c40df24b78a14', 'message': 'DRY up usage of url_prefix in wsgi unit test\n\nThe variable url_prefix is repeatedly added to various\ninstances of paths in unit tests. This can be refactored by adding\na check for the presence of the url_prefix in the test method\nitself.\n\nChange-Id: I032aee0d30b1115f6dc4de544700898809ad16c1\nCloses-Bug:1506016\n'}, {'number': 7, 'created': '2015-11-07 00:36:06.000000000', 'files': ['zaqar/tests/unit/transport/wsgi/v1_1/test_health.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_default_limits.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_health.py', 'zaqar/tests/unit/transport/wsgi/v1/test_pools.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_subscriptions.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_pools.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1/test_queue_lifecycle.py', 'zaqar/tests/unit/transport/wsgi/v1/test_default_limits.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_validation.py', 'zaqar/tests/unit/transport/wsgi/v1/test_health.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_flavors.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_flavors.py', 'zaqar/tests/unit/transport/wsgi/v1/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1/test_home.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_ping.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_home.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_ping.py', 'zaqar/tests/unit/transport/wsgi/v1/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_validation.py', 'zaqar/tests/unit/transport/wsgi/base.py', 'zaqar/tests/unit/transport/wsgi/v1/test_auth.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_home.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_pools.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0690fbaef58562800d76cad8fd947a2495e4d6c6', 'message': 'DRY up usage of url_prefix in wsgi unit test\n\nThe variable url_prefix is repeatedly added to various\ninstances of paths in unit tests. This can be refactored by adding\na check for the presence of the url_prefix in the test method\nitself.\n\nChange-Id: I032aee0d30b1115f6dc4de544700898809ad16c1\nCloses-Bug:1506016\n'}]",20,234769,0690fbaef58562800d76cad8fd947a2495e4d6c6,19,3,7,15470,,,0,"DRY up usage of url_prefix in wsgi unit test

The variable url_prefix is repeatedly added to various
instances of paths in unit tests. This can be refactored by adding
a check for the presence of the url_prefix in the test method
itself.

Change-Id: I032aee0d30b1115f6dc4de544700898809ad16c1
Closes-Bug:1506016
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/69/234769/6 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/tests/unit/transport/wsgi/v1/test_health.py', 'zaqar/tests/unit/transport/wsgi/v1/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v1/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1/test_default_limits.py', 'zaqar/tests/unit/transport/wsgi/base.py', 'zaqar/tests/unit/transport/wsgi/v1/test_auth.py', 'zaqar/tests/unit/transport/wsgi/v1/test_home.py']",7,0c6feaebe4baefd089117605b79cb27629197088,bug/1506016," body = self.simulate_get(""/"") body = self.simulate_get(""/"")", body = self.simulate_get(self.url_prefix) body = self.simulate_get(self.url_prefix),29,24
openstack%2Fswift~master~I4837fb70db2df29267ea081949bcc556a625bc45,openstack/swift,master,I4837fb70db2df29267ea081949bcc556a625bc45,Extra X-Timestamp are removed from error responses,NEW,2016-01-15 14:38:33.000000000,2017-12-18 05:24:04.000000000,,"[{'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 13052}, {'_account_id': 16550}, {'_account_id': 18540}, {'_account_id': 19007}, {'_account_id': 19175}, {'_account_id': 19560}]","[{'number': 1, 'created': '2016-01-15 14:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/334ec7b42277d98724923292cc9bb4a67e574a14', 'message': 'X-Timestamp missing from response headers\n\nMissing X-Timestamp headers are added to the resposes which are Account POST, container POST/DELETE/PUT and object PUT/COPY/DELETE/POST.\nCloses-Bug: #1509429\n\nChange-Id: I4837fb70db2df29267ea081949bcc556a625bc45\n'}, {'number': 2, 'created': '2016-01-18 11:55:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e73e0dae4f2de53e1b485234121a888151af1beb', 'message': 'X-Timestamp missing from response headers\n\nMissing X-Timestamp headers are added to the resposes which are\nAccount POST, container POST/DELETE/PUT and object PUT/COPY/DELETE/POST.\n\nCloses-Bug: #1509429\nChange-Id: I4837fb70db2df29267ea081949bcc556a625bc45\n'}, {'number': 3, 'created': '2016-01-18 13:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/db0d01c3c86267c5d0aa4e22d75a1c6a782c442d', 'message': 'X-Timestamp missing from response headers\n\nMissing X-Timestamp headers are added to the resposes which are\nAccount POST, container POST/DELETE/PUT and object PUT/COPY/DELETE/POST.\n\nCloses-Bug: #1509429\nChange-Id: I4837fb70db2df29267ea081949bcc556a625bc45\n'}, {'number': 4, 'created': '2016-01-19 07:14:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/39ebeabb6e1978941baca6c801d60fe7e8508880', 'message': 'X-Timestamp missing from response headers\n\nMissing X-Timestamp headers are added to the respose of\nobject POST.\n\nCloses-Bug: #1509429\nChange-Id: I4837fb70db2df29267ea081949bcc556a625bc45\n'}, {'number': 5, 'created': '2016-01-19 09:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1c06620de33a9efc1d758a638c09eb13c82f1cf3', 'message': 'X-Timestamp missing from response headers\n\nMissing X-Timestamp headers are added to the respose of\nobject POST.\n\nCloses-Bug: #1509429\nChange-Id: I4837fb70db2df29267ea081949bcc556a625bc45\n'}, {'number': 6, 'created': '2016-01-20 17:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e08a74f9151a2a5f1c6a1020e78fe779ba76b033', 'message': 'X-Timestamp missing from response headers\n\nExtra X-Timestamp header is removed from Container\nDELETE ""404 Not Found"" response.\n\nCloses-Bug: #1509429\nChange-Id: I4837fb70db2df29267ea081949bcc556a625bc45\n'}, {'number': 7, 'created': '2016-01-20 17:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fdd5411ca48ff57fcf927a563d0c0d4e6ae87dee', 'message': 'Extra X-Timestamp are removed from error responses\n\nExtra X-Timestamp headers are removed from Container\noperation responses\n.\n\nCloses-Bug: #1509429\nChange-Id: I4837fb70db2df29267ea081949bcc556a625bc45\n'}, {'number': 8, 'created': '2016-02-12 09:05:34.000000000', 'files': ['swift/container/server.py', 'swift/account/server.py', 'swift/proxy/controllers/obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/6ccd5ba4fcbabe2c2a15b6db2b951edb2abac4ab', 'message': 'Extra X-Timestamp are removed from error responses\n\nExtra X-Timestamp headers are removed from Container\noperation responses\n.\n\nCloses-Bug: #1509429\nChange-Id: I4837fb70db2df29267ea081949bcc556a625bc45\n'}]",0,268163,6ccd5ba4fcbabe2c2a15b6db2b951edb2abac4ab,32,8,8,19007,,,0,"Extra X-Timestamp are removed from error responses

Extra X-Timestamp headers are removed from Container
operation responses
.

Closes-Bug: #1509429
Change-Id: I4837fb70db2df29267ea081949bcc556a625bc45
",git fetch https://review.opendev.org/openstack/swift refs/changes/63/268163/7 && git format-patch -1 --stdout FETCH_HEAD,"['get-pip.py', 'swift/container/server.py', 'swift/account/server.py', 'swift/proxy/controllers/obj.py']",4,334ec7b42277d98724923292cc9bb4a67e574a14,bug/1509429, resp.headers['X-Timestamp'] = req.timestamp.internal resp.headers['X-Timestamp'] = Timestamp(time.time()).internal,,17819,21
openstack%2Fswift~master~I26aa98f089851d04fb0c1de8c462af2bbd68fff2,openstack/swift,master,I26aa98f089851d04fb0c1de8c462af2bbd68fff2,Add missing unittests for some recon methods,NEW,2015-11-25 21:03:53.000000000,2017-12-18 05:23:36.000000000,,"[{'_account_id': 1179}, {'_account_id': 7233}, {'_account_id': 7244}, {'_account_id': 13052}, {'_account_id': 15932}, {'_account_id': 16896}, {'_account_id': 18015}, {'_account_id': 18838}]","[{'number': 1, 'created': '2015-11-25 21:03:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/99fe8ceb15b9ec5ace00162e68152ce6c528e1c6', 'message': 'Add missing unittests for some recon methods\n\nTest for following SwiftRecon methods:\nasync_check\numount_check\nexpirer_check\nupdater_check\nsocket_usage\nauditor_check\n\nChange-Id: I26aa98f089851d04fb0c1de8c462af2bbd68fff2\n'}, {'number': 2, 'created': '2015-11-26 09:09:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7f838170422f6efd856021b283859871bb4abc2f', 'message': 'Add missing unittests for some recon methods\n\nTest for following SwiftRecon methods:\nasync_check\numount_check\nexpirer_check\nupdater_check\nsocket_usage\nauditor_check\n\nChange-Id: I26aa98f089851d04fb0c1de8c462af2bbd68fff2\n'}, {'number': 3, 'created': '2015-12-04 08:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2cc38c9c53d8e966dd2a9f98ec328a30da2b21bc', 'message': ""Add missing unittests for some recon methods\n\nTest for following SwiftRecon methods:\nasync_check\nauditor_check\n\nFollow up Bill Huber's path #240036\n\nChange-Id: I26aa98f089851d04fb0c1de8c462af2bbd68fff2\n""}, {'number': 4, 'created': '2015-12-04 08:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/17729087114bfbe29b6ab04a4fc7e56659d372e1', 'message': ""Add missing unittests for some recon methods\n\nTest for following SwiftRecon methods:\nasync_check\nauditor_check\n\nFollow up Bill Huber's path #240036\n\nChange-Id: I26aa98f089851d04fb0c1de8c462af2bbd68fff2\n""}, {'number': 5, 'created': '2016-01-18 18:37:15.000000000', 'files': ['test/unit/cli/test_recon.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/de6046d010ff032cbd2ebb402944c671e81b57cc', 'message': ""Add missing unittests for some recon methods\n\nTest for following SwiftRecon methods:\nasync_check\nauditor_check\n\nFollow up Bill Huber's path #240036\n\nChange-Id: I26aa98f089851d04fb0c1de8c462af2bbd68fff2\n""}]",2,250022,de6046d010ff032cbd2ebb402944c671e81b57cc,23,8,5,18015,,,0,"Add missing unittests for some recon methods

Test for following SwiftRecon methods:
async_check
auditor_check

Follow up Bill Huber's path #240036

Change-Id: I26aa98f089851d04fb0c1de8c462af2bbd68fff2
",git fetch https://review.opendev.org/openstack/swift refs/changes/22/250022/4 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/cli/test_recon.py'],1,99fe8ceb15b9ec5ace00162e68152ce6c528e1c6,recon-tests-follow," def test_async_check(self): hosts = [('127.0.0.1', 6010), ('127.0.0.1', 6020), ('127.0.0.1', 6030), ('127.0.0.1', 6040)] # sample json response from http://<host>:<port>/recon/async responses = {6010: {'async_pending': 15}, 6020: {'async_pending': 0}, 6030: {'async_pending': 257}, 6040: {'async_pending': 56}} # <low> <high> <avg> <total> <Failed> <no_result> <reported> expected = (0, 257, 82.0, 328, 0.0, 0, 4) def mock_scout_async(app, host): url = 'http://%s:%s/recon/async' % host response = responses[host[1]] status = 200 return url, response, status, 0, 0 stdout = StringIO() with mock.patch('swift.cli.recon.Scout.scout', mock_scout_async), \ mock.patch('sys.stdout', new=stdout): self.recon_instance.async_check(hosts) output = stdout.getvalue() r = re.compile(""\[async_pending(.*)\](.*)"") lines = output.splitlines() self.assertTrue(lines) matched_lines = False for line in lines: m = r.match(line) if m: self.assertEqual(m.group(2), "" low: %s, high: %s, avg: %s, total: %s,"" "" Failed: %s%%, no_result: %s, reported: %s"" % expected) matched_lines = True self.assertTrue(matched_lines) def test_umount_check(self): hosts = [('127.0.0.1', 6010), ('127.0.0.1', 6020), ('127.0.0.1', 6030), ('127.0.0.1', 6040)] # sample json response from http://<host>:<port>/recon/unmounted responses = {6010: [{'device': 'sdb1', 'mounted': False}, {'device': 'sdb5', 'mounted': 'OSError'}], 6020: [{'device': 'sdb2', 'mounted': False}], 6030: [{'device': 'sdb3', 'mounted': 'OSError'}], 6040: []} # <low> <high> <avg> <total> <Failed> <no_result> <reported> expected = (""Not mounted: %s on %s:%s"" % (responses[6010][0]['device'], hosts[0][0], hosts[0][1]), ""Not mounted: %s on %s:%s"" % (responses[6020][0]['device'], hosts[1][0], hosts[1][1]), ""Device errors: %s on %s:%s"" % (responses[6010][1]['device'], hosts[0][0], hosts[0][1]), ""Device errors: %s on %s:%s"" % (responses[6030][0]['device'], hosts[2][0], hosts[2][1])) def mock_scout_umounted(app, host): url = 'http://%s:%s/recon/unmounted' % host response = responses[host[1]] status = 200 return url, response, status, 0, 0 stdout = StringIO() with mock.patch('swift.cli.recon.Scout.scout', mock_scout_umounted), \ mock.patch('sys.stdout', new=stdout): self.recon_instance.umount_check(hosts) output = stdout.getvalue() lines = output.splitlines() self.assertTrue(lines) for expected_line in expected: self.assertTrue(expected_line in lines) def test_expirer_check(self): hosts = [('127.0.0.1', 6010), ('127.0.0.1', 6020), ('127.0.0.1', 6030), ('127.0.0.1', 6040)] # sample json response from http://<host>:<port>/recon/expirer/object responses = {6010: {'object_expiration_pass': 15, 'expired_last_pass': 15}, 6020: {'object_expiration_pass': 0, 'expired_last_pass': 0}, 6030: {'object_expiration_pass': 257, 'expired_last_pass': 257}, 6040: {'object_expiration_pass': 56, 'expired_last_pass': 56}} # <low> <high> <avg> <total> <Failed> <no_result> <reported> expected = (0, 257, 82.0, 328, 0.0, 0, 4) def mock_scout_expirer(app, host): url = 'http://%s:%s/recon/expirer/object' % host response = responses[host[1]] status = 200 return url, response, status, 0, 0 stdout = StringIO() with mock.patch('swift.cli.recon.Scout.scout', mock_scout_expirer), \ mock.patch('sys.stdout', new=stdout): self.recon_instance.expirer_check(hosts) output = stdout.getvalue() r = re.compile(""\[(object_expiration_pass|expired_last_pass)\](.*)"") lines = output.splitlines() self.assertTrue(lines) matched_lines = False for line in lines: m = r.match(line) if m: self.assertEqual(m.group(2), "" low: %s, high: %s, avg: %s, total: %s,"" "" Failed: %s%%, no_result: %s, reported: %s"" % expected) matched_lines = True self.assertTrue(matched_lines) def test_updater_check(self): hosts = [('127.0.0.1', 6010), ('127.0.0.1', 6020), ('127.0.0.1', 6030), ('127.0.0.1', 6040)] # sample json response from http://<host>:<port>/recon/updater/object responses = {6010: {'object_updater_sweep': 15}, 6020: {'object_updater_sweep': None}, 6030: {'object_updater_sweep': 257}, 6040: {'object_updater_sweep': 56}} # <low> <high> <avg> <total> <Failed> <no_result> <reported> expected = (15, 257, 109.3, 328, 0.0, 0, 3) def mock_scout_updater(app, host): url = 'http://%s:%s/recon/updater/object' % host response = responses[host[1]] status = 200 return url, response, status, 0, 0 stdout = StringIO() with mock.patch('swift.cli.recon.Scout.scout', mock_scout_updater), \ mock.patch('sys.stdout', new=stdout): self.recon_instance.updater_check(hosts) output = stdout.getvalue() r = re.compile(""\[updater_last_sweep(.*)\](.*)"") lines = output.splitlines() self.assertTrue(lines) matched_lines = False for line in lines: m = r.match(line) if m: self.assertEqual(m.group(2), "" low: %s, high: %s, avg: %s, total: %s,"" "" Failed: %s%%, no_result: %s, reported: %s"" % expected) matched_lines = True self.assertTrue(matched_lines) def test_socket_usage(self): hosts = [('127.0.0.1', 6010), ('127.0.0.1', 6020), ('127.0.0.1', 6030), ('127.0.0.1', 6040)] # sample json response from http://<host>:<port>/recon/expirer responses = {6010: {'orphan': 0, 'tcp_in_use': 50, 'time_wait': 46, 'tcp_mem_allocated_bytes': 100000, 'tcp6_in_use': 2}, 6020: {'orphan': 3, 'tcp_in_use': 30, 'time_wait': 42, 'tcp_mem_allocated_bytes': 102000, 'tcp6_in_use': 3}, 6030: {'orphan': 1, 'tcp_in_use': 45, 'time_wait': 36, 'tcp_mem_allocated_bytes': 110000, 'tcp6_in_use': 1}, 6040: {'orphan': 0, 'tcp_in_use': 52, 'time_wait': 40, 'tcp_mem_allocated_bytes': 134000, 'tcp6_in_use': 5}} # <low> <high> <avg> <total> <Failed> <no_result> <reported> exp_val = (('orphan', 0, 3, 1.0, 4, 0.0, 0, 4), ('tcp_in_use', 30, 52, 44.2, 177, 0.0, 0, 4), ('time_wait', 36, 46, 41.0, 164, 0.0, 0, 4), ('tcp6_in_use', 1, 5, 2.8, 11, 0.0, 0, 4), ('tcp_mem_allocated_bytes', 100000, 134000, 111500.0, 446000, 0.0, 0, 4)) expected = [] for exp in exp_val: expected.append(""[%s] low: %s, high: %s, avg: %s, total: %s,"" "" Failed: %s%%, no_result: %s, reported: %s"" % exp) def mock_scout_socket_usage(app, host): url = 'http://%s:%s/recon/sockstat' % host response = responses[host[1]] status = 200 return url, response, status, 0, 0 stdout = StringIO() with mock.patch('swift.cli.recon.Scout.scout', mock_scout_socket_usage), \ mock.patch('sys.stdout', new=stdout): self.recon_instance.socket_usage(hosts) output = stdout.getvalue() lines = output.splitlines() for expected_line in expected: self.assertTrue(expected_line in lines) def test_auditor_check(self): hosts = [('127.0.0.1', 6010), ('127.0.0.1', 6020), ('127.0.0.1', 6030), ('127.0.0.1', 6040)] # sample json response # from http://<host>:<port>/recon/auditor/container responses = {6010: {'container_auditor_pass_completed': 0, 'container_audits_failed': 50, 'container_audits_passed': 46, 'container_audits_since': 1448003000}, 6020: {'container_auditor_pass_completed': 3, 'container_audits_failed': 30, 'container_audits_passed': 42, 'container_audits_since': 1448020000}, 6030: {'container_auditor_pass_completed': 1, 'container_audits_failed': 45, 'container_audits_passed': 36, 'container_audits_since': 1448000100}, 6040: {'container_auditor_pass_completed': 0, 'container_audits_failed': 52, 'container_audits_passed': 40, 'container_audits_since': 1448000000}} # <low> <high> <avg> <total> <Failed> <no_result> <reported> exp_val = (('container_auditor_pass_completed', 0, 3, 1.0, 4, 0.0, 0, 4), ('container_audits_failed', 30, 52, 44.2, 177, 0.0, 0, 4), ('container_audits_passed', 36, 46, 41.0, 164, 0.0, 0, 4)) expected = [] for exp in exp_val: expected.append(""[%s] low: %s, high: %s, avg: %s, total: %s,"" "" Failed: %s%%, no_result: %s, reported: %s"" % exp) expected.append('[last_pass] oldest: 2015-11-20 07:13:20, ' 'newest: 2015-11-20 12:46:40, ' 'avg: 2015-11-20 08:49:35') def mock_scout_socket_usage(app, host): url = 'http://%s:%s/recon/auditor/container' % host response = responses[host[1]] status = 200 return url, response, status, 0, 0 stdout = StringIO() with mock.patch('swift.cli.recon.Scout.scout', mock_scout_socket_usage), \ mock.patch('sys.stdout', new=stdout): self.recon_instance.server_type = 'container' self.recon_instance.auditor_check(hosts) output = stdout.getvalue() lines = output.splitlines() for expected_line in expected: print(expected_line, lines) self.assertTrue(expected_line in lines) ",,259,0
openstack%2Fswift~master~Ib4ebcf47fc854ae15608b2127fd4b7a531f9c45d,openstack/swift,master,Ib4ebcf47fc854ae15608b2127fd4b7a531f9c45d,Close open socket connection before function return in PUT,NEW,2016-03-07 21:25:47.000000000,2017-12-18 05:23:27.000000000,,"[{'_account_id': 330}, {'_account_id': 7233}, {'_account_id': 10068}, {'_account_id': 13052}, {'_account_id': 20728}]","[{'number': 1, 'created': '2016-03-07 21:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e350cc559aff08f8d78726e44a2f234b593b5383', 'message': '    close open socket connection before function return in PUT\n\n    After a HTTP request is completed, and response status is read,\n    there is no need to keep the connection open. Leaving the connection\n    open is not a problem with CPython as the interpreter where refcnt is used,\n    but does pose issues for other Python implementation such as PyPy where\n    Garbage Collection (GC) is used.  This patch explicitly close the connection\n    so that GC knows they are safe to be reclaimed.  This should not cause\n    any issue to Swift in terms of functionality, but may add\n    some performance impact as addtional codes are being executed\n\nChange-Id: Ib4ebcf47fc854ae15608b2127fd4b7a531f9c45d\n'}, {'number': 2, 'created': '2016-03-08 00:13:51.000000000', 'files': ['swift/proxy/controllers/obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/cb5ff8bd4776b22a867b1a019455a816df38da6d', 'message': 'Close open socket connection before function return in PUT\n\nAfter a HTTP request is completed, and response status is read,\nthere is no need to keep the connection open. Leaving the connection\nopen is not a problem with CPython as the interpreter where refcnt is\nused, but does pose issues for other Python implementation such as PyPy\nwhere Garbage Collection (GC) is used. This patch explicitly closes the\nconnection so that GC knows they are safe to be reclaimed. This should\nnot cause any issue to Swift in terms of functionality, but may add\nsome performance impact as addtional codes are being executed\n\nChange-Id: Ib4ebcf47fc854ae15608b2127fd4b7a531f9c45d\n'}]",2,289571,cb5ff8bd4776b22a867b1a019455a816df38da6d,14,5,2,20728,,,0,"Close open socket connection before function return in PUT

After a HTTP request is completed, and response status is read,
there is no need to keep the connection open. Leaving the connection
open is not a problem with CPython as the interpreter where refcnt is
used, but does pose issues for other Python implementation such as PyPy
where Garbage Collection (GC) is used. This patch explicitly closes the
connection so that GC knows they are safe to be reclaimed. This should
not cause any issue to Swift in terms of functionality, but may add
some performance impact as addtional codes are being executed

Change-Id: Ib4ebcf47fc854ae15608b2127fd4b7a531f9c45d
",git fetch https://review.opendev.org/openstack/swift refs/changes/71/289571/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/proxy/controllers/obj.py'],1,e350cc559aff08f8d78726e44a2f234b593b5383,explicit_close_conn,"def close_swift_conn(src): """""" Force close the http connection to the backend. :param src: the response from the backend """""" try: # Since the backends set ""Connection: close"" in their response # headers, the response object (src) is solely responsible for the # socket. The connection object (src.swift_conn) has no references # to the socket, so calling its close() method does nothing, and # therefore we don't do it. # # Also, since calling the response's close() method might not # close the underlying socket but only decrement some # reference-counter, we have a special method here that really, # really kills the underlying socket with a close() syscall. src.nuke_from_orbit() # it's the only way to be sure src = None #remove the ref for gc # update 3/7/2016 by pxwang: in CPython2.7, this nuke_from_orbit() does not have any impact # a sock.shutdown(socket.SHUT_RDWR) call is never made, and so OS never shutdowns the socket # the call could be made in the close() method of the class HTTPConnection in the standard Python # library httplib.py except Exception: pass response = conn.getresponse() conn.done = True return response for conn in conns: if (hasattr(conn, 'done')) and conn.done: conns.remove(conn) close_swift_conn(conn) conn.done = None", return conn.getresponse(),36,1
openstack%2Fswift~master~I32185119f12427ebb6ad51f82f266aefd023d4de,openstack/swift,master,I32185119f12427ebb6ad51f82f266aefd023d4de,Remove limit of 64K devices,NEW,2016-01-07 18:55:34.000000000,2017-12-18 05:23:22.000000000,,"[{'_account_id': 2828}, {'_account_id': 13052}, {'_account_id': 18838}]","[{'number': 1, 'created': '2016-01-07 18:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/40965be52b9dab0e9af5f7a96420a9db909ce88d', 'message': ""Remove limit of 64K devices by providing 4 bytes per device id when needed.\n\nRings are created and stored just as before, but when the 64K threshold is\nreached, the ring will automatically be updated by the builder to use 4 bytes\nper device id in order to accommodate the large number of device id slots.\n\nRing Data Format - no change to version. However, a new field 'device_id_bytes'\nis added to json metadata. This change maintains backwards compatibility by\ndefaulting the device_id_bytes value to 2 if the field is not present in json\nmetadata. If the field is present, its value (2 or 4) is used for device id\nstorage.\n\nRing Data Serialization - for serializing/deserializing 2 bytes per device id\n(the default), existing code (prior to this patch) is used. In the case of\nstoring 4 bytes per device id (more than 65K slots for device ids), instead of\nusing 'tostring' on the replica2dev_id array to write out the replica device\nids, there is an explicit write of device id packed with struct.pack. This\nmeans that instead of a single loop there are 2 loops (outer for each replica,\nand inner for each partition).\n\nBuilder - new field 'device_id_bytes' added to track whether 2 or 4 bytes are\nbeing used to store each device id. New rings are created using 2 bytes for\neach device id. When a device is added that goes beyond 65K device slots, the\nring will be automatically updated to use 4 bytes per device id.\n\nRefactoring - code to create part2dev_id arrays based on 2 bytes was modified\nto call new method in RingData class for creating the part2dev_id array based\non the device_id_bytes values. This refactoring allows existing code to\ncorrectly create the part2dev_id array regardless of the number of device id\nslots.\n\nNew hash values for rings - since this patch now includes a new field\n(device_id_bytes) in the ring data json, the hash of a ring will now be\ndifferent. A few unit tests for recon were updated to account for this change.\n\nBackwards Compatibility - maintained. Existing clusters can use these changes\nand the ring will be automatically resized when 4 bytes are needed for storing\ndevice id.\n\nConfig files - no changes\n\nLog files - no changes\n\nDocumentation - no changes (i don't think). Is the upper limit on number of\ndevices something that should be in documentation?\n\nRingbuilder CLI usage - no changes. The administration of a swift cluster is\nunchanged. All changes in this patch are invisible to the swift user and swift\nadmin.\n\nUnit Tests - new tests have been added for RingData and RingBuilder. The most\ninteresting new unit test is 'test_add_beyond_64k_devices'. This test exercises\nthe builder logic that will update an existing ring to use 4 bytes per device\nid instead of the 2 bytes that were used when it was first created.\n\nForced usage of 4 bytes - not available from CLI. Must be done programmatically\nby passing optional parameter on RingBuilder construction.\n\nChange-Id: I32185119f12427ebb6ad51f82f266aefd023d4de\nImplements: bp device-size-change\n""}, {'number': 2, 'created': '2016-01-22 00:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/501300cc12175adc4288010919e0cfcb9d60f0bd', 'message': 'Remove limit of 64K devices in ring\n\nChange-Id: I32185119f12427ebb6ad51f82f266aefd023d4de\nImplements: bp device-size-change\n'}, {'number': 3, 'created': '2016-01-22 19:17:59.000000000', 'files': ['swift/common/ring/builder.py', 'test/unit/common/ring/test_builder.py', 'test/unit/common/middleware/test_recon.py', 'test/unit/common/ring/test_ring.py', 'swift/common/ring/ring.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/8337a5c8754c48b16a812f33efa95226ad082b2c', 'message': ""Remove limit of 64K devices\n\nRings are created and stored just as before, but when the 64K threshold is\nreached, the ring will automatically be updated by the builder to use 4 bytes\nper device id in order to accommodate the large number of device id slots.\n\nRing Data Format - no change to version. However, a new field 'device_id_bytes'\nis added to json metadata. This change maintains backwards compatibility by\ndefaulting the device_id_bytes value to 2 if the field is not present in json\nmetadata. If the field is present, its value (2 or 4) is used for device id\nstorage.\n\nRing Data Serialization - for serializing/deserializing 2 bytes per device id\n(the default), existing code (prior to this patch) is used. In the case of\nstoring 4 bytes per device id (more than 65K slots for device ids), instead of\nusing 'tostring' on the replica2dev_id array to write out the replica device\nids, there is an explicit write of device id packed with struct.pack. This\nmeans that instead of a single loop there are 2 loops (outer for each replica,\nand inner for each partition).\n\nBuilder - new field 'device_id_bytes' added to track whether 2 or 4 bytes are\nbeing used to store each device id. New rings are created using 2 bytes for\neach device id. When a device is added that goes beyond 65K device slots, the\nring will be automatically updated to use 4 bytes per device id.\n\nRefactoring - code to create part2dev_id arrays based on 2 bytes was modified\nto call new method in RingData class for creating the part2dev_id array based\non the device_id_bytes values. This refactoring allows existing code to\ncorrectly create the part2dev_id array regardless of the number of device id\nslots.\n\nNew hash values for rings - since this patch now includes a new field\n(device_id_bytes) in the ring data json, the hash of a ring will now be\ndifferent. A few unit tests for recon were updated to account for this change.\n\nBackwards Compatibility - maintained. Existing clusters can use these changes\nand the ring will be automatically resized when 4 bytes are needed for storing\ndevice id.\n\nConfig files - no changes\n\nLog files - no changes\n\nDocumentation - no changes (i don't think). Is the upper limit on number of\ndevices something that should be in documentation?\n\nRingbuilder CLI usage - no changes. The administration of a swift cluster is\nunchanged. All changes in this patch are invisible to the swift user and swift\nadmin.\n\nUnit Tests - new tests have been added for RingData and RingBuilder. The most\ninteresting new unit test is 'test_add_beyond_64k_devices'. This test exercises\nthe builder logic that will update an existing ring to use 4 bytes per device\nid instead of the 2 bytes that were used when it was first created.\n\nForced usage of 4 bytes - not available from CLI. Must be done programmatically\nby passing optional parameter on RingBuilder construction.\n\nChange-Id: I32185119f12427ebb6ad51f82f266aefd023d4de\nImplements: bp device-size-change\n""}]",0,264922,8337a5c8754c48b16a812f33efa95226ad082b2c,16,3,3,18838,,,0,"Remove limit of 64K devices

Rings are created and stored just as before, but when the 64K threshold is
reached, the ring will automatically be updated by the builder to use 4 bytes
per device id in order to accommodate the large number of device id slots.

Ring Data Format - no change to version. However, a new field 'device_id_bytes'
is added to json metadata. This change maintains backwards compatibility by
defaulting the device_id_bytes value to 2 if the field is not present in json
metadata. If the field is present, its value (2 or 4) is used for device id
storage.

Ring Data Serialization - for serializing/deserializing 2 bytes per device id
(the default), existing code (prior to this patch) is used. In the case of
storing 4 bytes per device id (more than 65K slots for device ids), instead of
using 'tostring' on the replica2dev_id array to write out the replica device
ids, there is an explicit write of device id packed with struct.pack. This
means that instead of a single loop there are 2 loops (outer for each replica,
and inner for each partition).

Builder - new field 'device_id_bytes' added to track whether 2 or 4 bytes are
being used to store each device id. New rings are created using 2 bytes for
each device id. When a device is added that goes beyond 65K device slots, the
ring will be automatically updated to use 4 bytes per device id.

Refactoring - code to create part2dev_id arrays based on 2 bytes was modified
to call new method in RingData class for creating the part2dev_id array based
on the device_id_bytes values. This refactoring allows existing code to
correctly create the part2dev_id array regardless of the number of device id
slots.

New hash values for rings - since this patch now includes a new field
(device_id_bytes) in the ring data json, the hash of a ring will now be
different. A few unit tests for recon were updated to account for this change.

Backwards Compatibility - maintained. Existing clusters can use these changes
and the ring will be automatically resized when 4 bytes are needed for storing
device id.

Config files - no changes

Log files - no changes

Documentation - no changes (i don't think). Is the upper limit on number of
devices something that should be in documentation?

Ringbuilder CLI usage - no changes. The administration of a swift cluster is
unchanged. All changes in this patch are invisible to the swift user and swift
admin.

Unit Tests - new tests have been added for RingData and RingBuilder. The most
interesting new unit test is 'test_add_beyond_64k_devices'. This test exercises
the builder logic that will update an existing ring to use 4 bytes per device
id instead of the 2 bytes that were used when it was first created.

Forced usage of 4 bytes - not available from CLI. Must be done programmatically
by passing optional parameter on RingBuilder construction.

Change-Id: I32185119f12427ebb6ad51f82f266aefd023d4de
Implements: bp device-size-change
",git fetch https://review.opendev.org/openstack/swift refs/changes/22/264922/3 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/ring/builder.py', 'test/unit/common/ring/test_builder.py', 'test/unit/common/middleware/test_recon.py', 'test/unit/common/ring/test_ring.py', 'swift/common/ring/ring.py']",5,40965be52b9dab0e9af5f7a96420a9db909ce88d,bp/device-size-change," def __init__(self, replica2part2dev_id, devs, part_shift, device_id_bytes=2): self._device_id_bytes = device_id_bytes :returns: A dict containing `devs`, `part_shift`, `replica2part2dev_id`, and `device_id_bytes`. if 'device_id_bytes' not in ring_dict: ring_dict['device_id_bytes'] = 2 device_id_bytes = ring_dict['device_id_bytes'] if device_id_bytes == 2: for x in range(ring_dict['replica_count']): ring_dict['replica2part2dev_id'].append( array.array('H', gz_file.read(2 * partition_count))) else: dev_id_type_code = \ RingData.type_code_for_unsigned_byte_count(device_id_bytes) endian_dev_id_type_code = '<' + dev_id_type_code for x in range(ring_dict['replica_count']): replica_ids = [] for y in range(partition_count): packed_data = gz_file.read(device_id_bytes) if len(packed_data) == device_id_bytes: unpacked_data, = struct.unpack(endian_dev_id_type_code, packed_data) replica_ids.append(unpacked_data) replica_entries = array.array(dev_id_type_code, replica_ids) ring_dict['replica2part2dev_id'].append(replica_entries) ring_data['devs'], ring_data['part_shift'], ring_data['device_id_bytes']) def device_id_bytes_type_code(self): byte_count = self._device_id_bytes return RingData.type_code_for_unsigned_byte_count(byte_count) 'replica_count': len(ring['replica2part2dev_id']), 'device_id_bytes': ring['device_id_bytes']}) if ring['device_id_bytes'] == 2: for part2dev_id in ring['replica2part2dev_id']: file_obj.write(part2dev_id.tostring()) else: dev_id_bytes_type_code = '<' + self.device_id_bytes_type_code() for part2dev_id in ring['replica2part2dev_id']: for dev_id in part2dev_id: file_obj.write(struct.pack(dev_id_bytes_type_code, dev_id)) 'part_shift': self._part_shift, 'device_id_bytes': self._device_id_bytes} @staticmethod def type_code_for_unsigned_byte_count(unsigned_byte_count): if unsigned_byte_count == 1: type_code = 'B' # integer (unsigned char in C) elif unsigned_byte_count == 2: type_code = 'H' # integer (unsigned short in C) elif unsigned_byte_count == 4: type_code = 'I' # integer (unsigned long in C) elif unsigned_byte_count == 8: type_code = 'Q' # integer (unsigned long long in C) else: type_code = 'H' # default to 2 bytes return type_code @classmethod def create_part2dev_array(cls, list_part2dev, device_id_bytes=2): device_id_type_code = \ cls.type_code_for_unsigned_byte_count(device_id_bytes) return array.array(device_id_type_code, list_part2dev) def __eq__(self, other): return self.devs == other.devs and \ self._replica2part2dev_id == other._replica2part2dev_id and \ self._part_shift == other._part_shift and \ self._device_id_bytes == other._device_id_bytes"," def __init__(self, replica2part2dev_id, devs, part_shift): :returns: A dict containing `devs`, `part_shift`, and `replica2part2dev_id` for x in range(ring_dict['replica_count']): ring_dict['replica2part2dev_id'].append( array.array('H', gz_file.read(2 * partition_count))) ring_data['devs'], ring_data['part_shift']) 'replica_count': len(ring['replica2part2dev_id'])}) for part2dev_id in ring['replica2part2dev_id']: file_obj.write(part2dev_id.tostring()) 'part_shift': self._part_shift}",214,40
openstack%2Fironic~master~Ibcd1baacd4456aa51d01fd284060dcda7c3a3848,openstack/ironic,master,Ibcd1baacd4456aa51d01fd284060dcda7c3a3848,Catch Unhandled IronicException in 'do_agent_iscsi_deploy',NEW,2016-03-08 21:04:37.000000000,2017-12-18 05:23:17.000000000,,"[{'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 11929}, {'_account_id': 13362}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-03-08 21:04:37.000000000', 'files': ['ironic/drivers/modules/iscsi_deploy.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/1bff3f20d0b7970a5622e12c37104bcba53a35ba', 'message': ""Catch Unhandled IronicException in 'do_agent_iscsi_deploy'\n\nCurrently there are many unhandled IronicExceptions in the\nagent_client. This patch handles a call to 'start_iscsi_target'\nby wrapping it in a try/except block and throwing a\nInstanceDeployFailed exception instead. This is a less generic\nerror and arguably more accurate to the actual cause of the\nexception.\n\nChange-Id: Ibcd1baacd4456aa51d01fd284060dcda7c3a3848\nPartial-Bug: #1542506\n""}]",4,290131,1bff3f20d0b7970a5622e12c37104bcba53a35ba,9,5,1,11929,,,0,"Catch Unhandled IronicException in 'do_agent_iscsi_deploy'

Currently there are many unhandled IronicExceptions in the
agent_client. This patch handles a call to 'start_iscsi_target'
by wrapping it in a try/except block and throwing a
InstanceDeployFailed exception instead. This is a less generic
error and arguably more accurate to the actual cause of the
exception.

Change-Id: Ibcd1baacd4456aa51d01fd284060dcda7c3a3848
Partial-Bug: #1542506
",git fetch https://review.opendev.org/openstack/ironic refs/changes/31/290131/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/iscsi_deploy.py'],1,1bff3f20d0b7970a5622e12c37104bcba53a35ba,mjturek/1542506," try: result = agent_client.start_iscsi_target(node, iqn) except IronicException as e: msg = (_(""Failed to parse JSON response"")) raise exception.InstanceDeployFailure(reason=msg) "," result = agent_client.start_iscsi_target(node, iqn)",6,1
openstack%2Fopenstack-health~master~I03822797c0d6aacdd51d84513c9c3cafe71f5c69,openstack/openstack-health,master,I03822797c0d6aacdd51d84513c9c3cafe71f5c69,WIP: Use stacked bar chart on front page,NEW,2016-03-04 05:37:02.000000000,2017-12-18 05:22:24.000000000,,"[{'_account_id': 5689}, {'_account_id': 17001}]","[{'number': 1, 'created': '2016-03-04 05:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/c7ac7eb20e236c897876587bed941775a08abd32', 'message': 'WIP: Use stacked bar chart on front page\n\nThis combines the two separate homepage charts into a single stacked\nbar chart, where each bar represents one resolution unit (e.g. hour),\nwith sections proportional to the pass/fail rate. The opacity of each\nbar is then derived from the total number of tests in that period\nrelative to other periods to emphasize the sample size.\n\nChange-Id: I03822797c0d6aacdd51d84513c9c3cafe71f5c69\nCloses-Bug: #1552699\n'}, {'number': 2, 'created': '2016-03-08 03:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/91913c5602f075ff30c7d74fded86a03398ee7f9', 'message': 'WIP: Use stacked bar chart on front page\n\nThis combines the two separate homepage charts into a single stacked\nbar chart, where each bar represents one resolution unit (e.g. hour),\nwith sections proportional to the pass/fail rate. The opacity of each\nbar is then derived from the total number of tests in that period\nrelative to other periods to emphasize the sample size.\n\nChange-Id: I03822797c0d6aacdd51d84513c9c3cafe71f5c69\nCloses-Bug: #1552699\n'}, {'number': 3, 'created': '2016-03-10 00:57:27.000000000', 'files': ['app/js/directives/chart-bar-multi.js', 'app/views/home.html', 'app/js/controllers/home.js'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/921fe1da252a90e5b25182779d865943c7ebd959', 'message': 'WIP: Use stacked bar chart on front page\n\nThis combines the two separate homepage charts into a single stacked\nbar chart, where each bar represents one resolution unit (e.g. hour),\nwith sections proportional to the pass/fail rate. The opacity of each\nbar is then derived from the total number of tests in that period\nrelative to other periods to emphasize the sample size.\n\nChange-Id: I03822797c0d6aacdd51d84513c9c3cafe71f5c69\nCloses-Bug: #1552699\n'}]",0,288251,921fe1da252a90e5b25182779d865943c7ebd959,9,2,3,17001,,,0,"WIP: Use stacked bar chart on front page

This combines the two separate homepage charts into a single stacked
bar chart, where each bar represents one resolution unit (e.g. hour),
with sections proportional to the pass/fail rate. The opacity of each
bar is then derived from the total number of tests in that period
relative to other periods to emphasize the sample size.

Change-Id: I03822797c0d6aacdd51d84513c9c3cafe71f5c69
Closes-Bug: #1552699
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/51/288251/3 && git format-patch -1 --stdout FETCH_HEAD,"['app/js/directives/chart-bar-multi.js', 'app/views/home.html', 'app/js/controllers/home.js']",3,c7ac7eb20e236c897876587bed941775a08abd32,bug/1552699,"var d3 = require('d3'); max = { months: 1 }; preference = { weeks: 1 }; var accessor = function(d) { return d.metrics.passes + d.metrics.failures; }; var mean = d3.mean(dateStats, accessor); var stdev = d3.deviation(dateStats, accessor); var opacityScale = d3.scale.linear() .domain([-1.0, 1.0]) .range([0.15, 1.0]) .clamp(true); var color = function(r, g, b, d) { var z = (accessor(d) - mean) / stdev; var value = opacityScale(z); return 'rgba(' + r + ',' + g + ',' + b + ',' + value + ')'; }; entries.passes.push({ x: tempDate.getTime(), y: 0, stats: null }); entries.failures.push({ x: tempDate.getTime(), y: 0, status: null }); angular.forEach(dateStats, function(stats) { entries.passes.push({ x: stats.date.getTime(), y: 1 - stats.metrics.failRate, stats: stats, color: color(0, 0, 255, stats) }); entries.failures.push({ x: stats.date.getTime(), y: stats.metrics.failRate, stats: stats, color: color(255, 0, 0, stats) }); var timeFormat = d3.time.format('%x %X'); var pctFormat = d3.format('.2f'); var tooltipContentGenerator = function(d) { var ret = '<table>'; ret += '<thead><tr><th colspan=""2"">' + timeFormat(new Date(d.value)) + '</td></th><thead>'; ret += '<tbody>'; if (d.data.stats) { var m = d.data.stats.metrics; ret += '<tr><td>Passes:</td><td>' + m.passes + ' (' + pctFormat(100 * (1 - m.failRate)) + '%)' + '</td></tr>'; ret += '<tr><td>Failures:</td><td>' + m.failures + ' (' + pctFormat(100 * (m.failRate)) + '%)' + '</td></tr>'; ret += '<tr><td>Skips:</td><td>' + m.skips + '</td></tr>'; } else { ret += '<tr><td>Passes:</td><td>n/a</td></td><tr>'; ret += '<tr><td>Failures:</td><td>n/a</td></tr>'; ret += '<tr><td>Skips:</td><td>n/a</td></tr>'; } ret += '</tbody>'; ret += '</table>'; return ret; vm.tooltipContentGenerator = tooltipContentGenerator;"," max = { months: 3 }; preference = { months: 1 }; entries.passes.push(generateChartData(tempDate, 0)); entries.failures.push(generateChartData(tempDate, 0)); entries.failRate.push(generateChartData(tempDate, 0)); angular.forEach(dateStats, function(stats) { entries.passes.push(generateChartData(stats.date, stats.metrics.passes)); entries.failures.push(generateChartData(stats.date, stats.metrics.failures)); entries.failRate.push(generateChartData(stats.date, stats.metrics.failRate)); entries.failRate = entries.failRate.sort(byDate); var generateChartData = function(date, value) { return { x: date.getTime(), y: value };",147,22
openstack%2Frally~master~I0c50b05ff01f04031520f03e06051e1067db06e1,openstack/rally,master,I0c50b05ff01f04031520f03e06051e1067db06e1,networks context to support creating ports and fips,NEW,2016-03-08 05:04:04.000000000,2017-12-18 05:21:54.000000000,,"[{'_account_id': 10068}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 20857}]","[{'number': 1, 'created': '2016-03-08 05:04:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e38af5c1e7eb708872f084b894d9ac70b3c220db', 'message': 'networks context to support creating ports and fips\n\nChange-Id: I0c50b05ff01f04031520f03e06051e1067db06e1\n'}, {'number': 2, 'created': '2016-03-08 06:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4e170dcbbb5af72b5a74552cbb7567fd6adc9f41', 'message': 'networks context to support creating ports and fips\n\nChange-Id: I0c50b05ff01f04031520f03e06051e1067db06e1\n'}, {'number': 3, 'created': '2016-03-10 19:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e1e90e95d88b8d6cc5e5fd8cd607743c9c2fb06b', 'message': 'networks context to support creating ports and fips\n\nThis patch add following properties to ""network"" context:\n\n* ports_per_network: number of ports per network, with default 0. This setting\n  has no effect on nova-network as it doesnt support creating ports\n* floating_ips_per_tenant: Number of floating ips per tenant, with default 0.\n\nChange-Id: I0c50b05ff01f04031520f03e06051e1067db06e1\n'}, {'number': 4, 'created': '2016-03-11 07:00:21.000000000', 'files': ['tests/unit/plugins/openstack/context/network/test_network.py', 'rally-jobs/rally-neutron.yaml', 'rally/plugins/openstack/context/network/networks.py', 'rally-jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/d9318d83439774560f8d8ec02de01b7f0732ce18', 'message': 'networks context to support creating ports and fips\n\nThis patch add following properties to ""network"" context:\n\n* ports_per_network: number of ports per network, with default 0. This setting\n  has no effect on nova-network as it doesnt support creating ports\n* floating_ips_per_tenant: Number of floating ips per tenant, with default 0.\n\nChange-Id: I0c50b05ff01f04031520f03e06051e1067db06e1\n'}]",9,289708,d9318d83439774560f8d8ec02de01b7f0732ce18,17,4,4,20857,,,0,"networks context to support creating ports and fips

This patch add following properties to ""network"" context:

* ports_per_network: number of ports per network, with default 0. This setting
  has no effect on nova-network as it doesnt support creating ports
* floating_ips_per_tenant: Number of floating ips per tenant, with default 0.

Change-Id: I0c50b05ff01f04031520f03e06051e1067db06e1
",git fetch https://review.opendev.org/openstack/rally refs/changes/08/289708/2 && git format-patch -1 --stdout FETCH_HEAD,['rally/plugins/openstack/context/network/networks.py'],1,e38af5c1e7eb708872f084b894d9ac70b3c220db,network_context_fip_ports," }, ""ports_per_network"": { ""type"": ""integer"", ""minimum"": 0 }, ""floating_ips_per_tenant"": { ""type"": ""integer"", ""minimum"": 0 ""network_create_args"": {}, ""ports_per_network"": 0, ""floating_ips_per_tenant"": 0 self.context[""tenants""][tenant_id][""fips""] = [] for port in range(self.config[""ports_per_network""]): net_wrapper.create_port(network['id']) for i in range(self.config[""floating_ips_per_tenant""]): fip = net_wrapper.create_floating_ip(tenant_id=tenant_id) self.context[""tenants""][tenant_id][""fips""].append(fip) for fip in tenant_ctx.get(""fips"", []): with logging.ExceptionLogger( LOG, _(""Failed to delete floating ip for tenant %s"") % tenant_id): net_wrapper.delete_floating_ip(fip[""id""])"," ""network_create_args"": {}",24,1
openstack%2Frally~master~I93c8f4b90df9f93286bbd44be60f426e2a35be45,openstack/rally,master,I93c8f4b90df9f93286bbd44be60f426e2a35be45,Add content_length header for Swift upload object queries,NEW,2016-03-09 02:48:05.000000000,2017-12-18 05:21:52.000000000,,"[{'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8935}, {'_account_id': 9545}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-03-09 02:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e9e518f511cef208f7ee003675b50baf70155139', 'message': 'Add content_length header for Swift upload object queries\n\nRadosGW requires Content-Length to be presented when creating an object.\n\nChange-Id: I93c8f4b90df9f93286bbd44be60f426e2a35be45\nCloses-Bug: #1554854\n'}, {'number': 2, 'created': '2016-03-09 19:09:12.000000000', 'files': ['rally/plugins/openstack/scenarios/swift/objects.py', 'rally/plugins/openstack/context/swift/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/a3ed2ac80e331763c13e69f66976a9c5b746b1e4', 'message': 'Add content_length header for Swift upload object queries\n\nRadosGW requires Content-Length to be presented when creating an object.\n\nChange-Id: I93c8f4b90df9f93286bbd44be60f426e2a35be45\nCloses-Bug: #1554854\n'}]",2,290245,a3ed2ac80e331763c13e69f66976a9c5b746b1e4,13,6,2,8935,,,0,"Add content_length header for Swift upload object queries

RadosGW requires Content-Length to be presented when creating an object.

Change-Id: I93c8f4b90df9f93286bbd44be60f426e2a35be45
Closes-Bug: #1554854
",git fetch https://review.opendev.org/openstack/rally refs/changes/45/290245/2 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/scenarios/swift/objects.py', 'rally/plugins/openstack/context/swift/utils.py']",2,e9e518f511cef208f7ee003675b50baf70155139,bug/1554854," dummy_file, content_length=object_size)[1]", dummy_file)[1],5,1
openstack%2Fironic-python-agent~master~I9602e6b9b8a44decd8981c8877645fff9a4dca82,openstack/ironic-python-agent,master,I9602e6b9b8a44decd8981c8877645fff9a4dca82,Add support for assigning IP addresses to interfaces,NEW,2015-10-12 11:00:25.000000000,2017-12-18 05:21:20.000000000,,"[{'_account_id': 9285}, {'_account_id': 9315}, {'_account_id': 10202}, {'_account_id': 11076}, {'_account_id': 11297}, {'_account_id': 16635}]","[{'number': 1, 'created': '2015-10-12 11:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/eac011cf1d1ff0dd29f4efadd87e2468509f9dd3', 'message': ""Add support for assigning IP addresses to interfaces\n\nThis commit adds support for passing IP addresses for\ninterfaces as parameters to agent ramdisk and assigning\nthem with hardware manager. It adds two methods\n'assign_network_address' and 'set_name_servers' to the\nhardware manager interface and implements them in the\nGenericHardwareManager.\n\nDepends-On: Ib38751f9d040bd3eaffafbda077fa79bf1c78986\nImplements: blueprint ilo-virtualmedia-drivers-dhcpless-deploy\nChange-Id: I9602e6b9b8a44decd8981c8877645fff9a4dca82\n""}, {'number': 2, 'created': '2015-10-23 10:16:57.000000000', 'files': ['ironic_python_agent/hardware.py', 'ironic_python_agent/agent.py', 'ironic_python_agent/tests/unit/test_hardware.py', 'ironic_python_agent/tests/unit/test_agent.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/88c43fca536bdbd21574d447ba260bc4f6ba8e29', 'message': ""Add support for assigning IP addresses to interfaces\n\nThis commit adds support for passing IP addresses for\ninterfaces as parameters to agent ramdisk and assigning\nthem with hardware manager. It adds two methods\n'assign_network_address' and 'set_name_servers' to the\nhardware manager interface and implements them in the\nGenericHardwareManager.\n\nDepends-On: Ib38751f9d040bd3eaffafbda077fa79bf1c78986\nImplements: blueprint ilo-virtualmedia-drivers-dhcpless-deploy\nChange-Id: I9602e6b9b8a44decd8981c8877645fff9a4dca82\n""}]",8,233579,88c43fca536bdbd21574d447ba260bc4f6ba8e29,9,6,2,9315,,,0,"Add support for assigning IP addresses to interfaces

This commit adds support for passing IP addresses for
interfaces as parameters to agent ramdisk and assigning
them with hardware manager. It adds two methods
'assign_network_address' and 'set_name_servers' to the
hardware manager interface and implements them in the
GenericHardwareManager.

Depends-On: Ib38751f9d040bd3eaffafbda077fa79bf1c78986
Implements: blueprint ilo-virtualmedia-drivers-dhcpless-deploy
Change-Id: I9602e6b9b8a44decd8981c8877645fff9a4dca82
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/79/233579/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/hardware.py', 'ironic_python_agent/agent.py', 'ironic_python_agent/tests/unit/test_hardware.py', 'ironic_python_agent/tests/unit/test_agent.py']",4,eac011cf1d1ff0dd29f4efadd87e2468509f9dd3,bp/ilo-virtualmedia-drivers-dhcpless-deploy,"import base64from ironic_python_agent import utils @mock.patch.object(hardware, 'dispatch_to_managers') @mock.patch.object(utils, 'get_agent_params') def test_assign_ip_addresses_passed_with_params_no_networking_info( self, get_agent_params_mock, dispatch_to_managers_mock): get_agent_params_mock.return_value = {} self.agent.assign_ip_addresses_passed_with_params() get_agent_params_mock.assert_called_once_with() self.assertFalse(dispatch_to_managers_mock.called) @mock.patch.object(hardware, 'dispatch_to_managers') @mock.patch.object(utils, 'get_agent_params') def test_assign_ip_addresses_passed_with_params( self, get_agent_params_mock, dispatch_to_managers_mock): networking_info = {'interfaces': [ {'mac_address': '01:23:45:67:89:0a', 'ip_address': '1.2.3.4', 'netmask': '255.255.255.0', 'gateway': '5.6.7.8', 'nameservers': ['10.11.12.13', '14.15.16.17']}, {'mac_address': '01:23:45:67:89:0b', 'ip_address': '1.2.3.5', 'netmask': '255.255.255.0'}]} get_agent_params_mock.return_value = { 'networking_info': base64.b64encode( json.dumps(networking_info).encode('ascii'))} self.agent.assign_ip_addresses_passed_with_params() get_agent_params_mock.assert_called_once_with() dispatch_to_managers_mock.assert_has_calls( [mock.call('assign_network_address', mac_address='01:23:45:67:89:0a', ip_address='1.2.3.4', netmask='255.255.255.0', gateway='5.6.7.8'), mock.call('set_name_servers', ['10.11.12.13', '14.15.16.17']), mock.call('assign_network_address', mac_address='01:23:45:67:89:0b', ip_address='1.2.3.5', netmask='255.255.255.0', gateway=None)]) @mock.patch.object(hardware, 'dispatch_to_managers') @mock.patch.object(utils, 'get_agent_params') def test_assign_ip_addresses_passed_with_params_bad_networking_info( self, get_agent_params_mock, dispatch_to_managers_mock): get_agent_params_mock.return_value = { 'networking_info': 'foo'} self.assertRaises(errors.InvalidContentError, self.agent.assign_ip_addresses_passed_with_params) get_agent_params_mock.assert_called_once_with() self.assertFalse(dispatch_to_managers_mock.called) ",,260,0
openstack%2Fswift~master~Ib10abe68b21853ed1d5a6700cc8f6242f36ed1da,openstack/swift,master,Ib10abe68b21853ed1d5a6700cc8f6242f36ed1da,"Remove execute permissions from codes and tests without ""#! /usr/bin/env python""",NEW,2016-02-12 09:53:16.000000000,2017-12-18 05:21:05.000000000,,"[{'_account_id': 1179}, {'_account_id': 13052}, {'_account_id': 14766}]","[{'number': 1, 'created': '2016-02-12 09:53:16.000000000', 'files': ['test/unit/common/test_storage_policy.py', 'test/unit/obj/test_server.py', 'swift/common/storage_policy.py', 'test/unit/obj/test_reconstructor.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/2b7f5eeee72b5e6c7443d3e805b866847d47b8ed', 'message': 'Remove execute permissions from codes and tests without ""#! /usr/bin/env python""\n\nSome codes and tests have execute permissions in spite of they don\'t have ""#! /usr/bin/env python"".\nThis patch remove execute permissions from them.\n\nChange-Id: Ib10abe68b21853ed1d5a6700cc8f6242f36ed1da\n'}]",4,279441,2b7f5eeee72b5e6c7443d3e805b866847d47b8ed,7,3,1,14766,,,0,"Remove execute permissions from codes and tests without ""#! /usr/bin/env python""

Some codes and tests have execute permissions in spite of they don't have ""#! /usr/bin/env python"".
This patch remove execute permissions from them.

Change-Id: Ib10abe68b21853ed1d5a6700cc8f6242f36ed1da
",git fetch https://review.opendev.org/openstack/swift refs/changes/41/279441/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_storage_policy.py', 'test/unit/obj/test_server.py', 'swift/common/storage_policy.py', 'test/unit/obj/test_reconstructor.py']",4,2b7f5eeee72b5e6c7443d3e805b866847d47b8ed,fix_file_modes_of_codes_and_tests,,,0,0
openstack%2Frally~master~I159de93e6af570ebef5a1b46146362ffaaf59aee,openstack/rally,master,I159de93e6af570ebef5a1b46146362ffaaf59aee,Pass region_name to clients. Fix bug 1559403: pass project_domain_name_key and region_name_key in def _get_auth_info() and del kwargs['region_name'] in swift client,NEW,2016-03-26 00:18:03.000000000,2017-12-18 05:21:00.000000000,,[{'_account_id': 14817}],"[{'number': 1, 'created': '2016-03-26 00:18:03.000000000', 'files': ['rally/osclients.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/2d437a617a5fb8aa2e83b72744f890e41011a2a2', 'message': ""Pass region_name to clients.\nFix bug 1559403: pass project_domain_name_key and region_name_key in def _get_auth_info() and del kwargs['region_name'] in swift client\n\nChange-Id: I159de93e6af570ebef5a1b46146362ffaaf59aee\nCloses-Bug: #1559403\n""}]",0,297896,2d437a617a5fb8aa2e83b72744f890e41011a2a2,4,1,1,14541,,,0,"Pass region_name to clients.
Fix bug 1559403: pass project_domain_name_key and region_name_key in def _get_auth_info() and del kwargs['region_name'] in swift client

Change-Id: I159de93e6af570ebef5a1b46146362ffaaf59aee
Closes-Bug: #1559403
",git fetch https://review.opendev.org/openstack/rally refs/changes/96/297896/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/osclients.py'],1,2d437a617a5fb8aa2e83b72744f890e41011a2a2,bug/1559403," project_domain_name_key=""project_domain_name"", region_name_key=""region_name"" auth_url_key: self.credential.auth_url, region_name_key: self.credential.region_name, kwargs = self._get_auth_info(user_key=""user"", password_key=""key"", auth_url_key=""authurl"", project_name_key=""tenant_name"") del kwargs['region_name'] **kwargs"," project_domain_name_key=""project_domain_name"" auth_url_key: self.credential.auth_url **self._get_auth_info( user_key=""user"", password_key=""key"", auth_url_key=""authurl"", project_name_key=""tenant_name"")",10,7
openstack%2Fironic-webclient~master~Ib0d00c6714345be9d97baf3de87f18975a48aa5d,openstack/ironic-webclient,master,Ib0d00c6714345be9d97baf3de87f18975a48aa5d,Make node manageable,NEW,2016-02-19 18:45:50.000000000,2017-12-18 05:20:50.000000000,,[{'_account_id': 16628}],"[{'number': 1, 'created': '2016-02-19 18:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-webclient/commit/31a3dc072fc844628d97972e66fb3ff5720cb2b9', 'message': 'Make node manageable\n\nThis patch creates a generic provision state modal controller\nthat can manage multiple nodes, and hooks this controller into\nthe node list user interface.\n\nChange-Id: Ib0d00c6714345be9d97baf3de87f18975a48aa5d\n'}, {'number': 2, 'created': '2016-03-28 19:56:27.000000000', 'files': ['app/js/modules/ironic/controller/node_action_controller.js', 'app/js/modules/ironic/controller/action/unknown_action_modal_controller.js', 'test/spec/ironic/controller/action/unknown_action_modal_controller.js', 'test/spec/ironic/controller/node_action_controller.js', 'app/js/modules/ironic/controller/action/provision_action_modal_controller.js', 'app/view/ironic/action/manage_node.html', 'test/spec/ironic/controller/action/provision_action_modal_controller.js'], 'web_link': 'https://opendev.org/openstack/ironic-webclient/commit/bea33f5cf361ec6ded80bfc473c80ae8e3de3423', 'message': 'Make node manageable\n\nThis patch creates a generic provision state modal controller\nthat can manage multiple nodes, and hooks this controller into\nthe node list user interface.\n\nChange-Id: Ib0d00c6714345be9d97baf3de87f18975a48aa5d\n'}]",0,282458,bea33f5cf361ec6ded80bfc473c80ae8e3de3423,8,1,2,9717,,,0,"Make node manageable

This patch creates a generic provision state modal controller
that can manage multiple nodes, and hooks this controller into
the node list user interface.

Change-Id: Ib0d00c6714345be9d97baf3de87f18975a48aa5d
",git fetch https://review.opendev.org/openstack/ironic-webclient refs/changes/58/282458/1 && git format-patch -1 --stdout FETCH_HEAD,"['app/js/modules/ironic/controller/node_action_controller.js', 'app/js/modules/ironic/controller/action/unknown_action_modal_controller.js', 'test/spec/ironic/controller/action/unknown_action_modal_controller.js', 'app/js/modules/ironic/controller/action/provision_action_modal_controller.js', 'test/spec/ironic/controller/node_action_controller.js', 'app/view/ironic/action/manage_node.html', 'test/spec/ironic/controller/action/provision_action_modal_controller.js']",7,31a3dc072fc844628d97972e66fb3ff5720cb2b9,mvp,"/* * Copyright (c) 2016 Hewlett Packard Enterprise Development Company, L.P. * * Licensed under the Apache License, Version 2.0 (the ""License""); you may * not use this file except in compliance with the License. You may obtain * a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the * License for the specific language governing permissions and limitations * under the License. */ /** * Unit tests for the provision action modal controller. */ describe('ProvisionActionModalController', function() { 'use strict'; var $controller, $httpBackend, mockInjectionProperties, $rootScope; beforeEach(function() { module('ironic.api.mock.IronicNode'); module('template.mock'); module('ironic'); }); beforeEach(inject(function(_$controller_, $injector) { $httpBackend = $injector.get('$httpBackend'); $rootScope = $injector.get('$rootScope'); $controller = _$controller_; mockInjectionProperties = { $scope: {}, $modalInstance: { close: function() { }, dismiss: function() { } }, actionName: 'test', nodes: [{'uuid': 'test_node_1'}, {'uuid': 'test_node_2'}] }; })); afterEach(inject(function($$persistentStorage) { // Clear any config selections we've made. $$persistentStorage.remove('$$selectedConfiguration'); // Assert no outstanding requests. $httpBackend.verifyNoOutstandingExpectation(); $httpBackend.verifyNoOutstandingRequest(); })); describe('Controller Properties', function() { it('does not pollute the $scope', function() { $controller('ProvisionActionModalController', mockInjectionProperties); expect(mockInjectionProperties.$scope).toEqual({}); }); it('starts with the updating flag disabled', function() { var controller = $controller('ProvisionActionModalController', mockInjectionProperties); expect(controller.updating).toBeFalsy(); }); it('starts with the someUpdated flag disabled', function() { var controller = $controller('ProvisionActionModalController', mockInjectionProperties); expect(controller.someUpdated).toBeFalsy(); }); }); describe('Controller Initialization', function() { it('passes the actionName to the controller scope', function() { var controller = $controller('ProvisionActionModalController', mockInjectionProperties); expect(controller.actionName).toEqual('test'); }); it('Creates a context object for each passed node', function() { var controller = $controller('ProvisionActionModalController', mockInjectionProperties); expect(controller.nodes.length).toBe(2); angular.forEach(controller.nodes, function(ctx) { expect(ctx.node).toBeDefined(); expect(ctx.error).toBeNull(); expect(ctx.changed).toBe(false); expect(ctx.state).toBe('ready'); }); }); }); describe('close()', function() { it('invokes dismiss() if nothing updated', function() { var spyDismiss = spyOn(mockInjectionProperties.$modalInstance, 'dismiss'); var spyClose = spyOn(mockInjectionProperties.$modalInstance, 'close'); var controller = $controller('ProvisionActionModalController', mockInjectionProperties); controller.someUpdated = false; controller.close(); expect(spyDismiss.calls.count()).toEqual(1); expect(spyClose.calls.count()).toEqual(0); }); it('invokes close() with updated nodes if something updated', function() { var spyDismiss = spyOn(mockInjectionProperties.$modalInstance, 'dismiss'); var spyClose = spyOn(mockInjectionProperties.$modalInstance, 'close'); var controller = $controller('ProvisionActionModalController', mockInjectionProperties); controller.someUpdated = true; controller.nodes[0].state = 'complete'; controller.nodes[0].changed = true; controller.close(); expect(spyDismiss.calls.count()).toEqual(0); expect(spyClose.calls.count()).toEqual(1); expect(spyClose.calls.mostRecent().args[0]).toEqual([controller.nodes[0].node]); }); }); describe('apply()', function() { var mockError = { error_message: { faultstring: ""faultstring"", faultcode: ""faultcode"" } }; it('modifies nothing if invoked with no nodes.', function() { mockInjectionProperties.nodes = []; var controller = $controller('ProvisionActionModalController', mockInjectionProperties); expect(controller.updating).toBeFalsy(); expect(controller.someUpdated).toBeFalsy(); controller.apply(); $rootScope.$apply(); // Resolve promises expect(controller.updating).toBeFalsy(); expect(controller.someUpdated).toBeFalsy(); }); it('dismisses the modal if invoked with no nodes.', function() { var spyDismiss = spyOn(mockInjectionProperties.$modalInstance, 'dismiss'); mockInjectionProperties.nodes = []; var controller = $controller('ProvisionActionModalController', mockInjectionProperties); expect(controller.updating).toBeFalsy(); expect(controller.someUpdated).toBeFalsy(); controller.apply(); expect(controller.updating).toBeTruthy(); $rootScope.$apply(); expect(controller.updating).toBeFalsy(); expect(spyDismiss.calls.count()).toEqual(1); }); it('correctly flips the updating flag', function() { var controller = $controller('ProvisionActionModalController', mockInjectionProperties); $httpBackend .expectPUT('http://ironic.example.com:1000/nodes/test_node_1/states/provision') .respond(202); $httpBackend .expectPUT('http://ironic.example.com:1000/nodes/test_node_2/states/provision') .respond(202); expect(controller.updating).toBeFalsy(); controller.apply(); expect(controller.updating).toBeTruthy(); $httpBackend.flush(); expect(controller.updating).toBeFalsy(); }); it('flips the someUpdated flag if some nodes are updated and others are not', function() { var spyDismiss = spyOn(mockInjectionProperties.$modalInstance, 'dismiss'); var spyClose = spyOn(mockInjectionProperties.$modalInstance, 'close'); $httpBackend .expectPUT('http://ironic.example.com:1000/nodes/test_node_1/states/provision') .respond(400, {}); $httpBackend .expectPUT('http://ironic.example.com:1000/nodes/test_node_2/states/provision') .respond(202); var controller = $controller('ProvisionActionModalController', mockInjectionProperties); expect(controller.updating).toBeFalsy(); expect(controller.someUpdated).toBeFalsy(); controller.apply(); expect(controller.nodes[0].state).toBe('updating'); expect(controller.nodes[1].state).toBe('updating'); expect(controller.updating).toBeTruthy(); $httpBackend.flush(); expect(controller.updating).toBeFalsy(); expect(controller.someUpdated).toBeTruthy(); expect(controller.nodes[0].state).toBe('error'); expect(controller.nodes[1].state).toBe('complete'); expect(spyDismiss.calls.count()).toEqual(0); expect(spyClose.calls.count()).toEqual(0); }); it('changes a node\'s context state to ""updating"" and ""complete"".', function() { $httpBackend .expectPUT('http://ironic.example.com:1000/nodes/test_node_1/states/provision') .respond(202); $httpBackend .expectPUT('http://ironic.example.com:1000/nodes/test_node_2/states/provision') .respond(202); var controller = $controller('ProvisionActionModalController', mockInjectionProperties); expect(controller.updating).toBeFalsy(); expect(controller.someUpdated).toBeFalsy(); controller.apply(); expect(controller.nodes[0].state).toBe('updating'); expect(controller.nodes[1].state).toBe('updating'); expect(controller.updating).toBeTruthy(); $httpBackend.flush(); expect(controller.updating).toBeFalsy(); expect(controller.someUpdated).toBeTruthy(); expect(controller.nodes[0].state).toBe('complete'); expect(controller.nodes[1].state).toBe('complete'); }); it('Correctly reports a returned error if a request fails.', function() { $httpBackend .expectPUT('http://ironic.example.com:1000/nodes/test_node_1/states/provision') .respond(400, mockError); $httpBackend .expectPUT('http://ironic.example.com:1000/nodes/test_node_2/states/provision') .respond(400, mockError); var controller = $controller('ProvisionActionModalController', mockInjectionProperties); expect(controller.updating).toBeFalsy(); expect(controller.someUpdated).toBeFalsy(); controller.apply(); expect(controller.nodes[0].state).toBe('updating'); expect(controller.nodes[1].state).toBe('updating'); expect(controller.updating).toBeTruthy(); $httpBackend.flush(); expect(controller.updating).toBeFalsy(); expect(controller.someUpdated).toBeFalsy(); expect(controller.nodes[0].state).toBe('error'); expect(controller.nodes[0].error).toBeDefined(); expect(controller.nodes[1].state).toBe('error'); expect(controller.nodes[1].error).toBeDefined(); }); it('invokes $modalInstance.close() if all nodes have been updated.', function() { var spyDismiss = spyOn(mockInjectionProperties.$modalInstance, 'dismiss'); var spyClose = spyOn(mockInjectionProperties.$modalInstance, 'close'); $httpBackend .expectPUT('http://ironic.example.com:1000/nodes/test_node_1/states/provision') .respond(202); $httpBackend .expectPUT('http://ironic.example.com:1000/nodes/test_node_2/states/provision') .respond(202); var controller = $controller('ProvisionActionModalController', mockInjectionProperties); expect(controller.updating).toBeFalsy(); expect(controller.someUpdated).toBeFalsy(); controller.apply(); expect(controller.nodes[0].state).toBe('updating'); expect(controller.nodes[1].state).toBe('updating'); expect(controller.updating).toBeTruthy(); $httpBackend.flush(); expect(controller.updating).toBeFalsy(); expect(controller.someUpdated).toBeTruthy(); expect(controller.nodes[0].state).toBe('complete'); expect(controller.nodes[1].state).toBe('complete'); expect(spyDismiss.calls.count()).toEqual(0); expect(spyClose.calls.count()).toEqual(1); expect(spyClose.calls.mostRecent().args[0][0]).toEqual(controller.nodes[0].node); expect(spyClose.calls.mostRecent().args[0][1]).toEqual(controller.nodes[1].node); }); }); }); ",,525,110
openstack%2Fopenstack-health~master~I945d287525b97fc1d7f8f85b1215668c7d0a25c4,openstack/openstack-health,master,I945d287525b97fc1d7f8f85b1215668c7d0a25c4,[WIP] DO NOT MERGE: Add Integrated filter to projectService,NEW,2016-03-07 08:07:28.000000000,2017-12-18 05:20:45.000000000,,"[{'_account_id': 5196}, {'_account_id': 5689}]","[{'number': 1, 'created': '2016-03-07 08:07:28.000000000', 'files': ['app/js/services/projects.js', 'app/js/controllers/home.js'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/55cf68de4851ebf51ecdc5a17cec0b71a4cf1b95', 'message': '[WIP] DO NOT MERGE: Add Integrated filter to projectService\n\nThis commit adds an ""integrated"" filter to the projectService. But in\nthis version, the homepage shows always filtered with it.\n\nTODO:\n * Add UI for the filter\n * Add unit tests\n\nCloses-Bug: #1552700\nChange-Id: I945d287525b97fc1d7f8f85b1215668c7d0a25c4\n'}]",1,289214,55cf68de4851ebf51ecdc5a17cec0b71a4cf1b95,5,2,1,5689,,,0,"[WIP] DO NOT MERGE: Add Integrated filter to projectService

This commit adds an ""integrated"" filter to the projectService. But in
this version, the homepage shows always filtered with it.

TODO:
 * Add UI for the filter
 * Add unit tests

Closes-Bug: #1552700
Change-Id: I945d287525b97fc1d7f8f85b1215668c7d0a25c4
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/14/289214/1 && git format-patch -1 --stdout FETCH_HEAD,"['app/js/services/projects.js', 'app/js/controllers/home.js']",2,55cf68de4851ebf51ecdc5a17cec0b71a4cf1b95,bug/1552700," var INTEGRATED = [""openstack-dev/devstack"", ""openstack-infra/devstack-gate"", ""openstack/cinder"", ""openstack/glance"", ""openstack/keystone"", ""openstack/nova"", ""openstack/requirements"", ""openstack/tempest"" ]; var processData = function(data) { var projects = projectService.createProjects(data.runs, INTEGRATED);", var processData = function(data) { var projects = projectService.createProjects(data.runs);,16,5
openstack%2Fpython-ironicclient~master~Ib7c75151f7b6ed4110693bdbc05d550c64a6ae68,openstack/python-ironicclient,master,Ib7c75151f7b6ed4110693bdbc05d550c64a6ae68,"Add multi-delete support for the ""openstack baremetal delete""",NEW,2015-11-26 13:24:39.000000000,2017-12-18 05:20:40.000000000,,[{'_account_id': 6618}],"[{'number': 1, 'created': '2015-11-26 13:24:39.000000000', 'files': ['ironicclient/osc/v1/baremetal.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/2a4afb338ef568deafe907831aaf62c206095a7c', 'message': 'Add multi-delete support for the ""openstack baremetal delete""\n\nCurrently the ""openstack baremetal delete"" can only delete one node.\nThis patch tries to introduce the multi-delete feature to it.\n\nChange-Id: Ib7c75151f7b6ed4110693bdbc05d550c64a6ae68\n'}]",0,250372,2a4afb338ef568deafe907831aaf62c206095a7c,5,1,1,16066,,,0,"Add multi-delete support for the ""openstack baremetal delete""

Currently the ""openstack baremetal delete"" can only delete one node.
This patch tries to introduce the multi-delete feature to it.

Change-Id: Ib7c75151f7b6ed4110693bdbc05d550c64a6ae68
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/72/250372/1 && git format-patch -1 --stdout FETCH_HEAD,['ironicclient/osc/v1/baremetal.py'],1,2a4afb338ef568deafe907831aaf62c206095a7c,add_multi_delete," """"""Unregister baremetal node(s)"""""" nargs='+', help=""Node(s) to delete (name or ID)"") for node in parsed_args.node: baremetal_client.node.delete( oscutils.find_resource( baremetal_client.node, node).uuid)"," """"""Unregister a baremetal node"""""" help=""Node to delete (name or ID)"") node = oscutils.find_resource(baremetal_client.node, parsed_args.node) baremetal_client.node.delete(node.uuid)",8,5
openstack%2Fapp-catalog-ui~master~Ief445651455b6c20435599459798500cf9ddcde8,openstack/app-catalog-ui,master,Ief445651455b6c20435599459798500cf9ddcde8,Common App Catalog code,NEW,2016-04-01 01:24:32.000000000,2017-12-18 05:20:38.000000000,,[],"[{'number': 1, 'created': '2016-04-01 01:24:32.000000000', 'files': ['README.rst', 'app_catalog/static/dashboard/project/app_catalog/details_panel.html', 'app_catalog/static/dashboard/project/app_catalog/featured-corner-murano.png', 'app_catalog/templates/app_catalog/index.html', 'devstack/plugin.sh', 'app_catalog/__init__.py', 'app_catalog/enabled/_90_project_app_catalog_panel.py', 'component_catalog/templates/component_catalog/index.html', 'app_catalog/local_settings.d/_90_app_catalog_common.py', 'requirements.txt', 'app_catalog/static/dashboard/project/app_catalog/main_panel.html', 'app_catalog/static/dashboard/project/app_catalog/action.html', 'app_catalog/static/dashboard/project/app_catalog/featured-corner-heat.png', 'app_catalog/static/dashboard/project/app_catalog/app_catalog.scss', 'app_catalog/static/dashboard/project/app_catalog/1439233889_list.png', 'app_catalog/static/dashboard/project/app_catalog/featured-corner-glance.png', 'app_catalog/static/dashboard/project/app_catalog/1439233859_grid.png', 'app_catalog/static/dashboard/project/app_catalog/app_catalog.js', 'app_catalog/static/dashboard/project/app_catalog/retired_panel.html', 'app_catalog/static/dashboard/project/app_catalog/magic_search.html', 'app_catalog/static/dashboard/project/app_catalog/_details_panel.html'], 'web_link': 'https://opendev.org/openstack/app-catalog-ui/commit/6376b780f1f6995e2c1f4932bc5f8567defba7bb', 'message': 'Common App Catalog code\n\nMove most of the code over to the app-catalog-common repo so that it\ncan be shared between the app catalog website and the horizon plugin.\n\nChange-Id: Ief445651455b6c20435599459798500cf9ddcde8\n'}]",0,300275,6376b780f1f6995e2c1f4932bc5f8567defba7bb,3,0,1,9237,,,0,"Common App Catalog code

Move most of the code over to the app-catalog-common repo so that it
can be shared between the app catalog website and the horizon plugin.

Change-Id: Ief445651455b6c20435599459798500cf9ddcde8
",git fetch https://review.opendev.org/openstack/app-catalog-ui refs/changes/75/300275/1 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'app_catalog/static/dashboard/project/app_catalog/details_panel.html', 'app_catalog/static/dashboard/project/app_catalog/featured-corner-murano.png', 'app_catalog/templates/app_catalog/index.html', 'devstack/plugin.sh', 'app_catalog/__init__.py', 'app_catalog/enabled/_90_project_app_catalog_panel.py', 'component_catalog/templates/component_catalog/index.html', 'app_catalog/local_settings.d/_90_app_catalog_common.py', 'requirements.txt', 'app_catalog/static/dashboard/project/app_catalog/main_panel.html', 'app_catalog/static/dashboard/project/app_catalog/action.html', 'app_catalog/static/dashboard/project/app_catalog/featured-corner-heat.png', 'app_catalog/static/dashboard/project/app_catalog/app_catalog.scss', 'app_catalog/static/dashboard/project/app_catalog/1439233889_list.png', 'app_catalog/static/dashboard/project/app_catalog/featured-corner-glance.png', 'app_catalog/static/dashboard/project/app_catalog/1439233859_grid.png', 'app_catalog/static/dashboard/project/app_catalog/app_catalog.js', 'app_catalog/static/dashboard/project/app_catalog/retired_panel.html', 'app_catalog/static/dashboard/project/app_catalog/magic_search.html', 'app_catalog/static/dashboard/project/app_catalog/_details_panel.html']",21,6376b780f1f6995e2c1f4932bc5f8567defba7bb,common,,"<div> <dl class=""dl-horizontal""> <dt> <div style="" width:64px; height:64px; overflow: hidden; ""> <img style="" margin: {$ asset.icon.top/2 $}px 0px 0px {$ asset.icon.left/2 $}px; height: {$ asset.icon.height/2 $}px; "" src=""{$ asset.icon.url $}""> </div> </dt> <dd> <div>{$ asset.name $}</div> <div>{$ asset.provided_by.company $}</div> <div ng-switch=""appaction"" style=""float:right""> <div ng-switch-when='true' app-action ng-scope ng-init='extraclasses=""btn-lg"";installclasses=""btn-primary"";launchclasses=""btn-success""'></div> </div> </dd> <dt>License</dt> <dd ng-switch=""asset.license_url || '_undefined_'""> <div>{$ asset.license $}</div> <a ng-switch-default class=""btn btn-default btn-sm"" target=""_blank"" href=""{$ asset.license_url $}"">License Details</a> <div ng-switch-when=""_undefined_""></div> </dd> <dt>Description</dt> <dd>{$ asset.description $}</dd> <dt ng-switch=""asset.depends || '_undefined_'""> <div ng-switch-default>Dependencies</div> <div ng-switch-when=""_undefined_""></div> </dt> <dd ng-switch=""asset.depends || '_undefined_'""> <div ng-switch-default> <table> <tr ng-repeat=""dep in asset.depends""> <td>{$ dep.asset.name $}</td> <td><div app-action ng-scope ng-init='extraclasses=""btn-sm"";no_launch=true;asset=dep.asset'></div></td> </tr> </table> <div ng-switch-when=""_undefined_""></div> </dd> </dl> </div> ",20,881
openstack%2Fopenstack-health~master~I6215f3702c06ceb01b6d98b634f6bc4c492e87d4,openstack/openstack-health,master,I6215f3702c06ceb01b6d98b634f6bc4c492e87d4,[WIP] Introduce breadcrumb,NEW,2016-03-23 10:38:12.000000000,2017-12-18 05:20:33.000000000,,"[{'_account_id': 5689}, {'_account_id': 17001}]","[{'number': 1, 'created': '2016-03-23 10:38:12.000000000', 'files': ['app/js/on_config.js', 'app/js/main.js', 'app/views/crumb-menu.html', 'app/js/directives/crumb-menu.js', 'package.json'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/c461d85fa78a0190f0aa676667a457c022a8c1fe', 'message': ""[WIP] Introduce breadcrumb\n\nThis commit replaces the drop down menu with a breadcrumb at the\ncrumb-menu. Now, the menu has only 'Overview' and 'Tests' on it. But I\nthink it's unclear for users. Because there are more pages in the\nopenstack-health now. We should show the hierarchy and/or relationship\nbetween pages.\n\nTODO:\n * Should we implement without this breadcrumb lib?\n * Fix the design of crumb-menu\n * Should we follow the user history?\n   e.g.\n   Overview -> Tests -> Test\n     and\n   Overview -> Jobs -> Job -> Test\n     are different at the Test page?\n\nChange-Id: I6215f3702c06ceb01b6d98b634f6bc4c492e87d4\n""}]",0,296368,c461d85fa78a0190f0aa676667a457c022a8c1fe,6,2,1,5689,,,0,"[WIP] Introduce breadcrumb

This commit replaces the drop down menu with a breadcrumb at the
crumb-menu. Now, the menu has only 'Overview' and 'Tests' on it. But I
think it's unclear for users. Because there are more pages in the
openstack-health now. We should show the hierarchy and/or relationship
between pages.

TODO:
 * Should we implement without this breadcrumb lib?
 * Fix the design of crumb-menu
 * Should we follow the user history?
   e.g.
   Overview -> Tests -> Test
     and
   Overview -> Jobs -> Job -> Test
     are different at the Test page?

Change-Id: I6215f3702c06ceb01b6d98b634f6bc4c492e87d4
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/68/296368/1 && git format-patch -1 --stdout FETCH_HEAD,"['app/js/on_config.js', 'app/js/main.js', 'app/views/crumb-menu.html', 'app/js/directives/crumb-menu.js', 'package.json']",5,c461d85fa78a0190f0aa676667a457c022a8c1fe,introduce-breadcrumb," ""angular-breadcrumb"": ""^0.4.0"",",,41,23
openstack%2Fswift~master~Ibd15217bd65bcf74409422f08d561ee4501bc19d,openstack/swift,master,Ibd15217bd65bcf74409422f08d561ee4501bc19d,Let developers/operators add watchers to account audit,NEW,2016-01-18 00:58:01.000000000,2017-12-18 05:20:26.000000000,,"[{'_account_id': 7847}, {'_account_id': 13052}, {'_account_id': 14766}, {'_account_id': 16896}]","[{'number': 1, 'created': '2016-01-18 00:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/58afd252df62a939987c1eb1e455e7365694339e', 'message': 'Let developers/operators add watchers to account audit\n\nThis is the account version of patch 212824 and works on the same\nprinciples.\n\nCluster operators need to be able to gather information on Swift\naccounts in the cluster for utilization and auditing purposes,\nonly there is no central list of all accounts in the Swift cluster.\nRight now each operator must implement a method to discover accounts\non their own. This patch enables a way to hook into account auditors\nso they can be iterated over without additional disk IO.\n\nLike the object audit watcher, this patch makes the auditor locate,\nvia entry points, the watchers named in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger)\n   start(self, audit_type)\n   see_target(self, *data)\n   end(self)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_target(*data) for each account audited, and\nwatcher.end() at the end of an audit pass.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nChange-Id: Ibd15217bd65bcf74409422f08d561ee4501bc19d\n'}, {'number': 2, 'created': '2016-01-18 21:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ede9f31da3d7b327e0b7c16e79ef16503c1d285b', 'message': 'Let developers/operators add watchers to account audit\n\nThis is the account version of patch 212824 and works on the same\nprinciples.\n\nCluster operators need to be able to gather information on Swift\naccounts in the cluster for utilization and auditing purposes,\nonly there is no central list of all accounts in the Swift cluster.\nRight now each operator must implement a method to discover accounts\non their own. This patch enables a way to hook into account auditors\nso they can be iterated over without additional disk IO.\n\nLike the object audit watcher, this patch makes the auditor locate,\nvia entry points, the watchers named in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger)\n   start(self, audit_type)\n   see_target(self, *data)\n   end(self)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_target(*data) for each account audited, and\nwatcher.end() at the end of an audit pass.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nChange-Id: Ibd15217bd65bcf74409422f08d561ee4501bc19d\n'}, {'number': 3, 'created': '2016-01-20 03:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/46c78a19692581ec6fccac7b5fa9c44eef67a079', 'message': 'Let developers/operators add watchers to account audit\n\n    This is the account version of patch 212824 and works on the same\n    principles.\n\n    Cluster operators need to be able to gather information on Swift\n    accounts in the cluster for utilization and auditing purposes,\n    only there is no central list of all accounts in the Swift cluster.\n    Right now each operator must implement a method to discover accounts\n    on their own. This patch enables a way to hook into account auditors\n    so they can be iterated over without additional disk IO.\n\n    Like the object audit watcher, this patch makes the auditor locate,\n    via entry points, the watchers named in its config file.\n\n    A watcher is a class with at least these four methods:\n\n       __init__(self, conf, logger)\n       start(self, audit_type)\n       see_target(self, *data)\n       end(self)\n\n    The auditor will call watcher.start(audit_type) at the start of an\n    audit pass, watcher.see_target(*data) for each account audited, and\n    watcher.end() at the end of an audit pass.\n\n    The user-supplied watcher code runs entirely in a child process of the\n    auditor process (of which there may be many, if parallel audits are in\n    use). This lets the auditor continue working even if the watcher\n    crashes or hangs. These subprocesses are automatically killed (after a\n    short delay) upon completion of an audit pass.\n\nChange-Id: Ibd15217bd65bcf74409422f08d561ee4501bc19d\n'}, {'number': 4, 'created': '2016-01-20 23:42:29.000000000', 'files': ['swift/account/auditor.py', 'test/unit/account/test_auditor.py', 'setup.cfg', 'swift/common/middleware/audit_watcher.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/1b7e259e600364563b93a4b61fd62df5ac9d95bd', 'message': 'Let developers/operators add watchers to account audit\n\n    This is the account version of patch 212824 and works on the same\n    principles.\n\n    Cluster operators need to be able to gather information on Swift\n    accounts in the cluster for utilization and auditing purposes,\n    only there is no central list of all accounts in the Swift cluster.\n    Right now each operator must implement a method to discover accounts\n    on their own. This patch enables a way to hook into account auditors\n    so they can be iterated over without additional disk IO.\n\n    Like the object audit watcher, this patch makes the auditor locate,\n    via entry points, the watchers named in its config file.\n\n    A watcher is a class with at least these four methods:\n\n       __init__(self, conf, logger)\n       start(self, audit_type)\n       see_target(self, *data)\n       end(self)\n\n    The auditor will call watcher.start(audit_type) at the start of an\n    audit pass, watcher.see_target(*data) for each account audited, and\n    watcher.end() at the end of an audit pass.\n\n    The user-supplied watcher code runs entirely in a child process of the\n    auditor process (of which there may be many, if parallel audits are in\n    use). This lets the auditor continue working even if the watcher\n    crashes or hangs. These subprocesses are automatically killed (after a\n    short delay) upon completion of an audit pass.\n\nChange-Id: Ibd15217bd65bcf74409422f08d561ee4501bc19d\n'}]",3,268830,1b7e259e600364563b93a4b61fd62df5ac9d95bd,15,4,4,18978,,,0,"Let developers/operators add watchers to account audit

    This is the account version of patch 212824 and works on the same
    principles.

    Cluster operators need to be able to gather information on Swift
    accounts in the cluster for utilization and auditing purposes,
    only there is no central list of all accounts in the Swift cluster.
    Right now each operator must implement a method to discover accounts
    on their own. This patch enables a way to hook into account auditors
    so they can be iterated over without additional disk IO.

    Like the object audit watcher, this patch makes the auditor locate,
    via entry points, the watchers named in its config file.

    A watcher is a class with at least these four methods:

       __init__(self, conf, logger)
       start(self, audit_type)
       see_target(self, *data)
       end(self)

    The auditor will call watcher.start(audit_type) at the start of an
    audit pass, watcher.see_target(*data) for each account audited, and
    watcher.end() at the end of an audit pass.

    The user-supplied watcher code runs entirely in a child process of the
    auditor process (of which there may be many, if parallel audits are in
    use). This lets the auditor continue working even if the watcher
    crashes or hangs. These subprocesses are automatically killed (after a
    short delay) upon completion of an audit pass.

Change-Id: Ibd15217bd65bcf74409422f08d561ee4501bc19d
",git fetch https://review.opendev.org/openstack/swift refs/changes/30/268830/2 && git format-patch -1 --stdout FETCH_HEAD,"['examples/basic-account-watcher/LICENSE', 'swift/account/auditor.py', 'examples/basic-account-watcher/README.md', 'examples/basic-account-watcher/account_watcher/__init__.py', 'examples/basic-account-watcher/setup.py', 'test/unit/account/test_auditor.py', 'swift/common/middleware/audit_watcher.py']",7,58afd252df62a939987c1eb1e455e7365694339e,account-auditor-watcher,"# Copyright (c) 2015-2016 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import os import time import signal import multiprocessing class WatcherWrapper(object): """""" Run the user-supplied watcher in a subprocess. By isolating the user-supplied code to a subprocess, we can protect the auditor against all sorts of tomfoolery, like slow code, memory leaks, or use of os._exit(). We also let the auditor continue auditing at its full speed without pausing after every object to call some user-supplied code. """""" SUBPROCESS_TERM_TIMEOUT = 0.5 # seconds SUBPROCESS_KILL_TIMEOUT = 1.0 # seconds def __init__(self, watcher_class, conf, logger, max_queue_size=256): self.watcher_class = watcher_class self.conf = conf self.logger = logger self._queue = multiprocessing.Queue(max_queue_size) self._proc = multiprocessing.Process( target=self._child_process) self._proc.start() def start(self, audit_type): self._put(['start', audit_type]) def see_target(self, *object_details): self._put(['see_target'] + list(object_details)) def end(self): """""" Send the 'end' message to the watcher and also shut down the child process. """""" self._put(['end']) self._put(None) sentinel_at = time.time() # Hopefully the child process will see the None and exit on its own. while (self._proc.is_alive() and (time.time() - sentinel_at) < self.SUBPROCESS_TERM_TIMEOUT): time.sleep(0.1) if not self._proc.is_alive(): return # Well, the sentinel didn't do it, so let's try a SIGTERM. self._proc.terminate() # sends SIGTERM termed_at = time.time() while (self._proc.is_alive() and (time.time() - termed_at) < self.SUBPROCESS_KILL_TIMEOUT): time.sleep(0.1) if not self._proc.is_alive(): return # So much for the easy way. os.kill(self._proc.pid, signal.SIGKILL) def _put(self, item): try: self._queue.put_nowait(item) except multiprocessing.Queue.Full: pass def _child_process(self): try: watcher = self.watcher_class(self.conf, self.logger) except: # noqa self.logger.exception(""Error instantiating watcher %r"", self.watcher_class) return while True: item = self._queue.get() # block forever if item is None: # sentinel value meaning ""exit; work's complete"" break self._feed_item_to_watcher(item, watcher) def _feed_item_to_watcher(self, item, watcher): try: if item[0] == 'start': audit_type = item[1] watcher.start(audit_type) elif item[0] == 'see_target': watcher.see_target(*item[1:]) elif item[0] == 'end': watcher.end() else: self.logger.warning(""Unknown watcher item: %r"" % (item,)) except: # noqa # Yes, really catch everything; this is user-provided code, so # there's no way of knowing *anything* about its quality. self.logger.exception(""Unknown %s audit watcher exception"" % watcher) class AuditWatcher(object): def __init__(self, conf, logger): self.conf = conf self.logger = logger def start(self, audit_type): """""" The function called at the beginning of an audit. :param audit_type: String description of audit being conducted. """""" pass def see_target(self, *args): """""" The function called on each account/container/object discovered by the auditor. :param *args: Data collected by the auditor. """""" raise NotImplementedError(""Subclasses implementation required "" ""for AuditWatcher.see_target()"") def end(self): """""" The function called at the completion of an audit. """""" pass ",,765,4
openstack%2Ftacker~master~Ida7e1dcb52a691450cc8adde13b0bcc587a3fe9b,openstack/tacker,master,Ida7e1dcb52a691450cc8adde13b0bcc587a3fe9b,[WIP] Remove nova infra_driver from master,NEW,2016-02-19 15:29:29.000000000,2017-12-18 05:20:18.000000000,,"[{'_account_id': 13380}, {'_account_id': 13485}]","[{'number': 1, 'created': '2016-02-19 15:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/3aca8da938079729a10da06edc85576e46fb41e1', 'message': '[WIP] Remove nova infra_driver from master\n\nThis patch removes nova infra_driver related code\nfrom master branch after deprecated it in stable/liberty:\n\nconf option\ndriver\ndocumentation\ndevstack plugin\n\nChange-Id: Ida7e1dcb52a691450cc8adde13b0bcc587a3fe9b\nDepends-on: TBA\nCloses-Bug: #1544332\n'}, {'number': 2, 'created': '2016-02-19 21:45:24.000000000', 'files': ['tacker/db/vm/vm_db.py', 'tacker/common/constants.py', 'devstack/lib/tacker', 'etc/tacker/tacker.conf', 'tacker/vm/drivers/nova/nova.py', 'tacker/vm/drivers/nova/__init__.py', 'tacker/vm/mgmt_drivers/abstract_driver.py', 'tacker/common/clients.py', 'requirements.txt', 'doc/source/devref/manual_installation.rst', 'tacker/common/config.py', 'setup.cfg', 'tacker/vm/constants.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/6ee54c1eb78a03691841bf56fb0e63bc40a18c77', 'message': '[WIP] Remove nova infra_driver from master\n\nThis patch removes nova infra_driver related code\nfrom master branch after deprecated it in stable/liberty:\n\nconf option\ndriver\ndocumentation\ndevstack plugin\n\nChange-Id: Ida7e1dcb52a691450cc8adde13b0bcc587a3fe9b\nDepends-on: I66cd8dd17f06459fa84c2f2d6698abfb02eb26c2\nCloses-Bug: #1544332\n'}]",0,282386,6ee54c1eb78a03691841bf56fb0e63bc40a18c77,7,2,2,15755,,,0,"[WIP] Remove nova infra_driver from master

This patch removes nova infra_driver related code
from master branch after deprecated it in stable/liberty:

conf option
driver
documentation
devstack plugin

Change-Id: Ida7e1dcb52a691450cc8adde13b0bcc587a3fe9b
Depends-on: I66cd8dd17f06459fa84c2f2d6698abfb02eb26c2
Closes-Bug: #1544332
",git fetch https://review.opendev.org/openstack/tacker refs/changes/86/282386/2 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/db/vm/vm_db.py', 'tacker/common/constants.py', 'devstack/lib/tacker', 'etc/tacker/tacker.conf', 'tacker/vm/drivers/nova/nova.py', 'tacker/vm/drivers/nova/__init__.py', 'tacker/vm/mgmt_drivers/abstract_driver.py', 'tacker/common/clients.py', 'requirements.txt', 'doc/source/devref/manual_installation.rst', 'tacker/common/config.py', 'setup.cfg', 'tacker/vm/constants.py']",13,3aca8da938079729a10da06edc85576e46fb41e1,bug/1544332,,# attribute key for service to spin up device # for nova driver. novaclient library uses those ATTR_KEY_IMAGE = 'image' ATTR_KEY_FLAVOR = 'flavor' ATTR_KEY_MGMT_NETWORK = 'mgmt-network' ,5,432
openstack%2Fswift~master~Ia19d0c47fddc15b087fe186b17d19ec66ee3c55f,openstack/swift,master,Ia19d0c47fddc15b087fe186b17d19ec66ee3c55f,"Expand the container server API to allow ""since"".",NEW,2016-04-11 23:17:15.000000000,2017-12-18 05:19:58.000000000,,"[{'_account_id': 1179}, {'_account_id': 13052}, {'_account_id': 17363}]","[{'number': 1, 'created': '2016-04-11 23:17:15.000000000', 'files': ['swift/container/server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/85657ff28fa3856087b10bf3e7643b64c8aba9e8', 'message': 'Expand the container server API to allow ""since"".\n\nThe patch attempts to expand the container server API to allow queries\nfor records changed since some rowid. Currently, the get_items_since()\nquery is used by the container sync method. Exposing the query allows\nbuilding additional applications that may need to watch and propagate\nchanges.\n\nChange-Id: Ia19d0c47fddc15b087fe186b17d19ec66ee3c55f\n'}]",8,304332,85657ff28fa3856087b10bf3e7643b64c8aba9e8,7,3,1,17363,,,0,"Expand the container server API to allow ""since"".

The patch attempts to expand the container server API to allow queries
for records changed since some rowid. Currently, the get_items_since()
query is used by the container sync method. Exposing the query allows
building additional applications that may need to watch and propagate
changes.

Change-Id: Ia19d0c47fddc15b087fe186b17d19ec66ee3c55f
",git fetch https://review.opendev.org/openstack/swift refs/changes/32/304332/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/container/server.py'],1,85657ff28fa3856087b10bf3e7643b64c8aba9e8,," # When using the ""since"" parameter, the records may include additional # values, i.e. ""deleted"", ""storage_policy_index"", and ""ROWID"" if len(record) > 5: deleted, policy_index, rowid = record[5:] response['deleted'] = deleted response['policy_index'] = policy_index response['rowid'] = rowid since = get_param(req, 'since') # If ""since"" was specified, the prefix, delimiter, path, marker, and # reverse are ignored. if since: container_list = broker.get_items_since(since, limit) if container_list: container_list = [(entry['name'], entry['created_at'], entry['size'], entry['content_type'], entry['etag'], entry['deleted'], entry['storage_policy_index'], entry['ROWID']) for entry in container_list] else: container_list = broker.list_objects_iter( limit, marker, end_marker, prefix, delimiter, path, storage_policy_index=info['storage_policy_index'], reverse=reverse)"," container_list = broker.list_objects_iter( limit, marker, end_marker, prefix, delimiter, path, storage_policy_index=info['storage_policy_index'], reverse=reverse)",24,3
openstack%2Fapp-catalog~master~I936b4f0c415daaa88829d66a5c6350540cf8bb05,openstack/app-catalog,master,I936b4f0c415daaa88829d66a5c6350540cf8bb05,Additional check,NEW,2016-04-12 03:52:35.000000000,2017-12-18 05:19:56.000000000,,[],"[{'number': 1, 'created': '2016-04-12 03:52:35.000000000', 'files': ['openstack_catalog/tests/test_openstack_catalog.py'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/62b5ba0cd63574b7c6bcf59e0c1d87b58225672c', 'message': 'Additional check\n\nCheck to ensure all dependencies are in the catalog.\n\nChange-Id: I936b4f0c415daaa88829d66a5c6350540cf8bb05\n'}]",0,304379,62b5ba0cd63574b7c6bcf59e0c1d87b58225672c,3,0,1,9237,,,0,"Additional check

Check to ensure all dependencies are in the catalog.

Change-Id: I936b4f0c415daaa88829d66a5c6350540cf8bb05
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/79/304379/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_catalog/tests/test_openstack_catalog.py'],1,62b5ba0cd63574b7c6bcf59e0c1d87b58225672c,dep_check," for asset in data['assets']: if 'depends' in asset: for dep in asset['depends']: if dep['name'] not in names: self.fail(""Dependency %s not found in assets"" % dep['name'])",,5,0
openstack%2Fsolum-specs~master~Ifffc126a9f2db867491cc9f3b769e1b60484c70b,openstack/solum-specs,master,Ifffc126a9f2db867491cc9f3b769e1b60484c70b,Spec for micro-service based application architecture,NEW,2015-12-08 12:44:53.000000000,2017-12-18 05:19:46.000000000,,"[{'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 7230}, {'_account_id': 12400}]","[{'number': 1, 'created': '2015-12-08 12:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/4d1b673481a0037abb0b77cbb5ef6047d9803bba', 'message': 'Spec for micro-service based application architecture\n\nChange-Id: Ifffc126a9f2db867491cc9f3b769e1b60484c70b\n'}, {'number': 2, 'created': '2015-12-08 13:02:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/963a6ebe0a7c03f91716ac1a7a21353bbedc4298', 'message': 'Spec for micro-service based application architecture\n\nChange-Id: Ifffc126a9f2db867491cc9f3b769e1b60484c70b\n'}, {'number': 3, 'created': '2015-12-08 13:04:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/43200995fc2b909a23a9b83a0ca05f638c5c0175', 'message': 'Spec for micro-service based application architecture\n\nChange-Id: Ifffc126a9f2db867491cc9f3b769e1b60484c70b\n'}, {'number': 4, 'created': '2015-12-08 13:27:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/0b4526772131141c30bb85c422da98dfcc1adcf7', 'message': 'Spec for micro-service based application architecture\n\nChange-Id: Ifffc126a9f2db867491cc9f3b769e1b60484c70b\n'}, {'number': 5, 'created': '2015-12-08 14:01:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/da3c7e96b0078c3b32d1804f4ae22dcac7fc62c7', 'message': 'Spec for micro-service based application architecture\n\nChange-Id: Ifffc126a9f2db867491cc9f3b769e1b60484c70b\n'}, {'number': 6, 'created': '2015-12-08 14:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/c3d42830f10c869a9fbd8b52f3a14fdeee4ae135', 'message': 'Spec for micro-service based application architecture\n\nChange-Id: Ifffc126a9f2db867491cc9f3b769e1b60484c70b\n'}, {'number': 7, 'created': '2015-12-08 14:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/e2d823c7dd12b1145e20ab2d3eb7c4c7debb85a2', 'message': 'Spec for micro-service based application architecture\n\nChange-Id: Ifffc126a9f2db867491cc9f3b769e1b60484c70b\n'}, {'number': 8, 'created': '2015-12-08 15:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/0363dc5b2104992546402a57c03b1597e423aeaf', 'message': 'Spec for micro-service based application architecture\n\nChange-Id: Ifffc126a9f2db867491cc9f3b769e1b60484c70b\n'}, {'number': 9, 'created': '2015-12-08 15:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/423b9cffeabfac576a602af415ec17b3885c433f', 'message': 'Spec for micro-service based application architecture\n\nChange-Id: Ifffc126a9f2db867491cc9f3b769e1b60484c70b\n'}, {'number': 10, 'created': '2015-12-08 15:33:54.000000000', 'files': ['specs/mitaka/micro-service-architecture.rst'], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/b1edb4c5e306469b1e57adc992f33611bf3c95dd', 'message': 'Spec for micro-service based application architecture\n\nChange-Id: Ifffc126a9f2db867491cc9f3b769e1b60484c70b\n'}]",7,254729,b1edb4c5e306469b1e57adc992f33611bf3c95dd,18,4,10,2506,,,0,"Spec for micro-service based application architecture

Change-Id: Ifffc126a9f2db867491cc9f3b769e1b60484c70b
",git fetch https://review.opendev.org/openstack/solum-specs refs/changes/29/254729/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/mitaka/micro-service-architecture.rst'],1,4d1b673481a0037abb0b77cbb5ef6047d9803bba,micro-service-architecture,"Problem description =================== This spec considers requirements, implementation, and changes to Solum CLI and API to support micro-service applications where each service is built as a separate docker container. Problem Details: ------------------ An example of a micro-service application is solum itself. Solum consists of six services: solum-api, solum-worker, solum-deployer, solum-conductor, mysql, and rabbitmq. There is a dependency relationship between these services. solum-api, solum-worker, solum-deployer, and solum-conductor depend on rabbitmq for sending and receiving messages and on mysql for storage. Our goal is to be able to build and deploy such applications which may consist of one or more services using Solum. Proposed implementation: ------------------------- In order to support multi-service applications we need the following: (a) ability to represent multiple services in the app file (b) ability to specify different kinds of sources, such as github repository or image in docker hub, for service's code (b) ability to specify dependencies between different services Container orchestration systems such as docker-compose[1] and Kubernetes[2] natively support deploying of multi-container applications. In Solum we propose to leverage these systems to build out the feature of multi-container applications. Specifically, we plan to use docker-compose[1] as Proposed change =============== 1) App file changes: 2) API changes: 3) Worker changes: 4) Deployer changes: Alternatives ------------ Option 1: --------- Kubernetes[2] Option 2: --------- Data model impact ----------------- REST API impact --------------- Discussed above Security impact --------------- Notifications impact -------------------- Other end user impact --------------------- Performance Impact ------------------ Other deployer impact --------------------- Developer impact ---------------- Implementation ============== Assignee(s) ----------- Devdatta Kulkarni (devdatta-kulkarni) Work Items ---------- Dependencies ============ Testing ======= Documentation Impact ==================== Documentation would need to be updated to reflect the addition of new CLI commands. References ========== [1] https://docs.docker.com/compose/ [2] http://kubernetes.io/v1.1/multi-tier.html ",,133,0
openstack%2Fswift~master~I2bfcb8f928ab2e4eab30fca339f51aecf0394921,openstack/swift,master,I2bfcb8f928ab2e4eab30fca339f51aecf0394921,POC: Searchlight client library,NEW,2016-04-13 14:24:12.000000000,2017-12-18 05:19:41.000000000,,"[{'_account_id': 7665}, {'_account_id': 8959}, {'_account_id': 17363}]","[{'number': 1, 'created': '2016-04-13 14:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c340b2aa36ec88a07e6b82cd4a6aad1b8e39b2d5', 'message': 'POC: Searchlight client library\n\nSearchlight client library for indexing\nswift account/container/object info and\nmetadata directly in elasticsearch behind\nsearchlight server.\n\nChange-Id: I2bfcb8f928ab2e4eab30fca339f51aecf0394921\n'}, {'number': 2, 'created': '2016-04-13 14:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1a0c514fe8f22de7a328c09f810ae158938a20ac', 'message': 'POC: Searchlight client library\n\nSearchlight client library for indexing\nswift account/container/object info and\nmetadata directly in elasticsearch behind\nsearchlight server.\n\nChange-Id: I2bfcb8f928ab2e4eab30fca339f51aecf0394921\n'}, {'number': 3, 'created': '2016-04-13 16:14:36.000000000', 'files': ['swift/obj/server.py', 'swift/container/server.py', 'swift/common/elasticsearch_client.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/ee88781d88620e722043ef45aa22b158c1b68c71', 'message': 'POC: Searchlight client library\n\nSearchlight client library for indexing\nswift account/container/object info and\nmetadata directly in elasticsearch behind\nsearchlight server.\n\nChange-Id: I2bfcb8f928ab2e4eab30fca339f51aecf0394921\n'}]",10,305309,ee88781d88620e722043ef45aa22b158c1b68c71,15,3,3,8959,,,0,"POC: Searchlight client library

Searchlight client library for indexing
swift account/container/object info and
metadata directly in elasticsearch behind
searchlight server.

Change-Id: I2bfcb8f928ab2e4eab30fca339f51aecf0394921
",git fetch https://review.opendev.org/openstack/swift refs/changes/09/305309/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/server.py', 'swift/obj/server.py', 'swift/common/elasticsearch_client.py']",3,c340b2aa36ec88a07e6b82cd4a6aad1b8e39b2d5,bp/searchlight-client-library,"import copy import json import urllib2 es_url = ""http://127.0.0.1:9200/"" index = ""searchlight-search/"" ADMIN_SUFFIX = ""_ADMIN"" USER_SUFFIX = ""_USER"" CONTAINER_TYPE = ""OS::Swift::Container/"" OBJECT_TYPE = ""OS::Swift::Object/"" def _post_es(doc_type, resource_id, post_data): post_data = json.dumps(post_data) headers = {'Content-Type': 'application/json'} resource_id = resource_id.replace(""/"", ""%2F"") url = es_url + index + doc_type + resource_id with open(""/home/lakshmi/out"", ""a+"") as f: f.write(url) req = urllib2.Request(url, post_data, headers=headers) conn = urllib2.urlopen(req) es_out = conn.read() conn.close() return es_out def _get_role_adjusted_data(post_data): admin_data = copy.deepcopy(post_data) admin_data['id'] += ADMIN_SUFFIX admin_data['__searchlight-user-role'] = ""admin"" user_data = copy.deepcopy(post_data) user_data['id'] += USER_SUFFIX user_data['__searchlight-user-role'] = ""user"" return admin_data, user_data def create_container(name, account_id, account_name, created_at=None): id = account_id + ""/"" + name data = { ""id"": id, ""account_id"": account_id, ""name"": name, ""created_at"": created_at, ""account"": account_name } routing = ""&routing="" + account_name admin_id = id + ADMIN_SUFFIX + ""?parent="" +\ account_id + ADMIN_SUFFIX + routing user_id = id + USER_SUFFIX + ""?parent="" + \ account_id + USER_SUFFIX + routing admin_data, user_data = _get_role_adjusted_data(data) admin_out = _post_es(CONTAINER_TYPE, admin_id, admin_data) user_out = _post_es(CONTAINER_TYPE, user_id, user_data) return admin_out, user_out def create_object(account_name, container_name, account_id, name, content_type, content_length, etag, created_at=None): container_id = account_id + ""/"" + container_name object_id = container_id + ""/"" + name post_data = { ""content_length"": content_length, ""account"": account_name, ""container"": container_name, ""account_id"": account_id, ""created_at"": created_at, ""container_id"": container_id, ""__searchlight-user-role"": [ ""user"", ""admin"" ], ""updated_at"": created_at, ""etag"": etag, ""content_type"": content_type, ""id"": object_id, ""name"": name } container_id = container_id.replace(""/"", ""%2F"") object_id += ""?parent="" + container_id + USER_SUFFIX object_id += ""&routing="" + account_name return _post_es(OBJECT_TYPE, object_id, post_data) ",,102,0
openstack%2Fbifrost~master~I79180905732346a204d6b5c8712b30770702429e,openstack/bifrost,master,I79180905732346a204d6b5c8712b30770702429e,Set both forms of pxe_append_params,NEW,2016-03-22 18:54:50.000000000,2017-12-18 05:19:38.000000000,,"[{'_account_id': 5805}, {'_account_id': 11655}, {'_account_id': 12459}]","[{'number': 1, 'created': '2016-03-22 18:54:50.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/tasks/ironic_config.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/6e0ce232f3ca099b2f0bcc3a021ff9bc64571db9', 'message': 'Set both forms of pxe_append_params\n\nThere is a deprecated form of pxe_append_params. In the case where this\nis uncommented we want to make sure to set it to the same value as the\nnew var.\n\nChange-Id: I79180905732346a204d6b5c8712b30770702429e\n'}]",1,296007,6e0ce232f3ca099b2f0bcc3a021ff9bc64571db9,8,3,1,10035,,,0,"Set both forms of pxe_append_params

There is a deprecated form of pxe_append_params. In the case where this
is uncommented we want to make sure to set it to the same value as the
new var.

Change-Id: I79180905732346a204d6b5c8712b30770702429e
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/07/296007/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/bifrost-ironic-install/tasks/ironic_config.yml'],1,6e0ce232f3ca099b2f0bcc3a021ff9bc64571db9,fix-agent-pxe-append-params,"- name: ""For agent, send extra (deprecated) params"" lineinfile: dest=/etc/ironic/ironic.conf insertafter=""[pxe]"" regexp='^(.*)agent_pxe_append_params=(.*)$' line=""agent_pxe_append_params=systemd.journald.forward_to_console=yes {{extra_kernel_options | default('')}}""",,6,0
openstack%2Frally~master~I644720ced352406c609d00c3efb3a3544ca4468a,openstack/rally,master,I644720ced352406c609d00c3efb3a3544ca4468a,Add update and upload operations to Glance,NEW,2016-04-07 13:31:41.000000000,2017-12-18 05:19:36.000000000,,"[{'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 20645}]","[{'number': 1, 'created': '2016-04-07 13:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/806d45f91161da5bb0bb181e8254d9b1922a98d8', 'message': 'Add update and upload operations to Glance\n\nStarting from Glance v2 API image state machine has\nbeen changed, new state ""queued"" is added => it\'s possible\nto create image without data. In that case image will have\n""queued"" state. After image data uploading the image will\nhave ""active"" state.\n\nAt this moment create_image operation always create image\ntogether with image data. But we need to measure API calls\nfor both create and upload operations separately. This commit\nintroduces new methods ""update"" and ""upload"" for both\nGlance wrappers.\n\nFor Glance v1 wrapper create_image is splitted into create and\nupload operations. Upload operation is done by updating\n""data"" or ""copy_from"" image properties.\n\nFor Glance v2 wrapper create_image is splitted into create and\nupload operations. The upload operation uses native operation\nfrom Glance v2 client.\n\nUpdate operation uses native operation for both wrappers.\n\nChange-Id: I644720ced352406c609d00c3efb3a3544ca4468a\n'}, {'number': 2, 'created': '2016-04-08 08:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0eae3f7fee8a160f4255914b529c9e865e649c31', 'message': 'Add update and upload operations to Glance\n\nStarting from Glance v2 API image state machine has\nbeen changed, new state ""queued"" is added => it\'s possible\nto create image without data. In that case image will have\n""queued"" state. After image data uploading the image will\nhave ""active"" state.\n\nAt this moment create_image operation always create image\ntogether with image data. But we need to measure API calls\nfor both create and upload operations separately. This commit\nintroduces new methods ""update"" and ""upload"" for both\nGlance wrappers.\n\nFor Glance v1 wrapper create_image is splitted into create and\nupload operations. Upload operation is done by updating\n""data"" or ""copy_from"" image properties.\n\nFor Glance v2 wrapper create_image is splitted into create and\nupload operations. The upload operation uses native operation\nfrom Glance v2 client.\n\nUpdate operation uses native operation for both wrappers.\n\nChange-Id: I644720ced352406c609d00c3efb3a3544ca4468a\n'}, {'number': 3, 'created': '2016-04-11 12:41:43.000000000', 'files': ['samples/tasks/scenarios/glance/create-and-upload-image.yaml', 'tests/unit/plugins/openstack/scenarios/glance/test_images.py', 'tests/unit/plugins/openstack/scenarios/glance/test_utils.py', 'samples/tasks/scenarios/glance/create-and-update-image.yaml', 'rally/plugins/openstack/scenarios/glance/images.py', 'samples/tasks/scenarios/glance/create-and-update-image.json', 'rally/plugins/openstack/scenarios/glance/utils.py', 'etc/rally/rally.conf.sample', 'samples/tasks/scenarios/glance/create-and-upload-image.json', 'rally/plugins/openstack/wrappers/glance.py', 'rally-jobs/rally.yaml', 'tests/unit/plugins/openstack/wrappers/test_glance.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/14baba2afc075de1d455333d6424c0b5b4d01797', 'message': 'Add update and upload operations to Glance\n\nStarting from Glance v2 API image state machine has\nbeen changed, new state ""queued"" is added => it\'s possible\nto create image without data. In that case image will have\n""queued"" state. After image data uploading the image will\nhave ""active"" state.\n\nAt this moment create_image operation always create image\ntogether with image data. But we need to measure API calls\nfor both create and upload operations separately. This commit\nintroduces new methods ""update"" and ""upload"" for both\nGlance wrappers.\n\nFor Glance v1 wrapper create_image is splitted into create and\nupload operations. Upload operation is done by updating\n""data"" or ""copy_from"" image properties.\n\nFor Glance v2 wrapper create_image is splitted into create and\nupload operations. The upload operation uses native operation\nfrom Glance v2 client.\n\nUpdate operation uses native operation for both wrappers.\n\nChange-Id: I644720ced352406c609d00c3efb3a3544ca4468a\n'}]",6,302762,14baba2afc075de1d455333d6424c0b5b4d01797,22,3,3,20645,,,0,"Add update and upload operations to Glance

Starting from Glance v2 API image state machine has
been changed, new state ""queued"" is added => it's possible
to create image without data. In that case image will have
""queued"" state. After image data uploading the image will
have ""active"" state.

At this moment create_image operation always create image
together with image data. But we need to measure API calls
for both create and upload operations separately. This commit
introduces new methods ""update"" and ""upload"" for both
Glance wrappers.

For Glance v1 wrapper create_image is splitted into create and
upload operations. Upload operation is done by updating
""data"" or ""copy_from"" image properties.

For Glance v2 wrapper create_image is splitted into create and
upload operations. The upload operation uses native operation
from Glance v2 client.

Update operation uses native operation for both wrappers.

Change-Id: I644720ced352406c609d00c3efb3a3544ca4468a
",git fetch https://review.opendev.org/openstack/rally refs/changes/62/302762/1 && git format-patch -1 --stdout FETCH_HEAD,"['samples/tasks/scenarios/glance/create-and-upload-image.yaml', 'tests/unit/plugins/openstack/scenarios/glance/test_images.py', 'tests/unit/plugins/openstack/scenarios/glance/test_utils.py', 'samples/tasks/scenarios/glance/create-and-update-image.yaml', 'rally/plugins/openstack/scenarios/glance/images.py', 'samples/tasks/scenarios/glance/create-and-update-image.json', 'rally/plugins/openstack/scenarios/glance/utils.py', 'etc/rally/rally.conf.sample', 'samples/tasks/scenarios/glance/create-and-upload-image.json', 'rally/plugins/openstack/wrappers/glance.py', 'rally-jobs/rally.yaml', 'tests/unit/plugins/openstack/wrappers/test_glance.py']",12,806d45f91161da5bb0bb181e8254d9b1922a98d8,extend_glance_functionality," {""location"": ""image_location"", ""name"": ""image_name""}) def test_create_image_with_location(self, location, **kwargs): self.wrapped_client.upload_image = mock.Mock() return_image = self.wrapped_client.create_image(""container_format"", location, ""disk_format"", **kwargs) create_args = dict(kwargs) create_args[""container_format""] = ""container_format"" create_args[""disk_format""] = ""disk_format"" if ""name"" not in kwargs: create_args[""name""] = self.owner.generate_random_name.return_value self.client().images.create.assert_called_once_with(**create_args) self.mock_wait_for_status.mock.assert_called_once_with( self.client().images.create.return_value, [""queued""], update_resource=self.mock_get_from_manager.mock.return_value, check_interval=CONF.benchmark.glance_image_create_poll_interval, timeout=CONF.benchmark.glance_image_create_timeout ) self.wrapped_client.upload_image.assert_called_once_with( self.mock_wait_for_status.mock.return_value, location ) self.assertEqual(self.wrapped_client.upload_image.return_value, return_image) @ddt.data( {""location"": None, ""fakearg"": ""fake""}, {""location"": None, ""name"": ""image_name""}) @ddt.unpack def test_create_image_without_location(self, location, **kwargs): self.assertFalse(self.client().images.update.called) self.client().images.create.return_value, [""queued""], self.assertEqual(self.mock_get_from_manager.mock.call_count, 1) @ddt.data( {""fakearg"": ""fake""}, {""fakearg1"": ""fake"", ""fakearg2"": ""fake""}) @ddt.unpack def test_update_image(self, **kwargs): image = mock.Mock() return_image = self.wrapped_client.update_image(image, **kwargs) self.client().images.update.assert_called_once_with(image.id, **kwargs) self.assertEqual(self.client().images.update.return_value, return_image) @ddt.data( {""location"": ""image_location""}, {""location"": _tempfile.name}) @ddt.unpack @mock.patch(""six.moves.builtins.open"") def test_upload_image(self, mock_open, location): image = mock.Mock() return_image = self.wrapped_client.upload_image(image, location) update_args = {} if location.startswith(""/""): update_args[""data""] = mock_open.return_value mock_open.assert_called_once_with(location) mock_open.return_value.close.assert_called_once_with() else: update_args[""copy_from""] = location self.client().images.update.assert_called_once_with( image.id, **update_args) self.mock_wait_for_status.mock.assert_called_once_with( self.client().images.update.return_value, [""active""], update_resource=self.mock_get_from_manager.mock.return_value, check_interval=CONF.benchmark.glance_image_upload_poll_interval, timeout=CONF.benchmark.glance_image_upload_timeout ) self.assertEqual(self.mock_wait_for_status.mock.return_value, return_image) def test__refresh_image(self): return_image = self.wrapped_client._refresh_image(image) self.wrapped_client._refresh_image, image) {""location"": ""image_location"", ""name"": ""image_name""}) def test_create_image_with_location(self, location, **kwargs): self.wrapped_client._refresh_image = mock.Mock() self.wrapped_client.upload_image = mock.Mock() self.mock_wait_for_status.mock.assert_called_once_with( self.client().images.create.return_value, [""queued""], update_resource=self.wrapped_client._refresh_image, check_interval=CONF.benchmark. glance_image_create_poll_interval, timeout=CONF.benchmark.glance_image_create_timeout ) self.wrapped_client.upload_image.assert_called_once_with( self.mock_wait_for_status.mock.return_value, location ) self.assertEqual(self.wrapped_client.upload_image.return_value, return_image) @ddt.data( {""location"": None, ""fakearg"": ""fake""}, {""location"": None, ""name"": ""image_name""}) @ddt.unpack def test_create_image_without_location(self, location, **kwargs): self.wrapped_client._refresh_image = mock.Mock() return_image = self.wrapped_client.create_image(""container_format"", location, ""disk_format"", **kwargs) call_args = dict(kwargs) call_args[""container_format""] = ""container_format"" call_args[""disk_format""] = ""disk_format"" if ""name"" not in kwargs: call_args[""name""] = self.owner.generate_random_name.return_value self.client().images.create.assert_called_once_with(**call_args) self.assertFalse(self.client().images.update.called) self.assertFalse(self.client().images.upload.called) self.mock_wait_for_status.mock.assert_called_once_with( self.client().images.create.return_value, [""queued""], update_resource=self.wrapped_client._refresh_image, check_interval=CONF.benchmark.glance_image_create_poll_interval, timeout=CONF.benchmark.glance_image_create_timeout) self.assertEqual(self.mock_wait_for_status.mock.return_value, return_image) update_resource=self.wrapped_client._refresh_image, @ddt.data( {""fakearg"": ""fake""}, {""fakearg1"": ""fake"", ""fakearg2"": ""fake""}) @ddt.unpack def test_update_image(self, **kwargs): image = mock.Mock() return_image = self.wrapped_client.update_image(image, **kwargs) self.client().images.update.assert_called_once_with( image.id, None, **kwargs) self.assertEqual(self.client().images.update.return_value, return_image) @ddt.data( {""location"": ""image_location""}, {""location"": _tempfile.name}) @ddt.unpack @mock.patch(""six.moves.builtins.open"") @mock.patch(""requests.get"") def test_upload_image(self, mock_requests_get, mock_open, location): image = mock.Mock() self.wrapped_client._refresh_image = mock.Mock() return_image = self.wrapped_client.upload_image(image, location) if location.startswith(""/""): data = mock_open.return_value mock_open.assert_called_once_with(location) else: data = mock_requests_get.return_value.raw mock_requests_get.assert_called_once_with(location, stream=True) data.close.assert_called_once_with() self.client().images.upload.assert_called_once_with(image.id, data) self.mock_wait_for_status.mock.assert_called_once_with( image, [""active""], update_resource=self.wrapped_client._refresh_image, check_interval=CONF.benchmark.glance_image_upload_poll_interval, timeout=CONF.benchmark.glance_image_upload_timeout ) self.assertEqual(self.mock_wait_for_status.mock.return_value, return_image)"," {""location"": ""image_location"", ""name"": ""image_name""}, {""location"": _tempfile.name}) @mock.patch(""six.moves.builtins.open"") def test_create_image(self, mock_open, location, **kwargs): if location.startswith(""/""): call_args[""data""] = mock_open.return_value mock_open.assert_called_once_with(location) mock_open.return_value.close.assert_called_once_with() else: call_args[""copy_from""] = location self.client().images.create.return_value, [""active""], self.mock_get_from_manager.mock.assert_called_once_with() def test__update_image(self): return_image = self.wrapped_client._update_image(image) self.wrapped_client._update_image, image) {""location"": ""image_location"", ""name"": ""image_name""}, {""location"": _tempfile.name}) @mock.patch(""six.moves.builtins.open"") @mock.patch(""requests.get"") def test_create_image(self, mock_requests_get, mock_open, location, **kwargs): self.wrapped_client._update_image = mock.Mock() created_image = mock.Mock() uploaded_image = mock.Mock() self.mock_wait_for_status.mock.side_effect = [created_image, uploaded_image] if location.startswith(""/""): data = mock_open.return_value mock_open.assert_called_once_with(location) else: data = mock_requests_get.return_value.raw mock_requests_get.assert_called_once_with(location, stream=True) data.close.assert_called_once_with() self.client().images.upload.assert_called_once_with(created_image.id, data) self.mock_wait_for_status.mock.assert_has_calls([ mock.call( self.client().images.create.return_value, [""queued""], update_resource=self.wrapped_client._update_image, check_interval=CONF.benchmark. glance_image_create_poll_interval, timeout=CONF.benchmark.glance_image_create_timeout), mock.call( created_image, [""active""], update_resource=self.wrapped_client._update_image, check_interval=CONF.benchmark. glance_image_create_poll_interval, timeout=mock.ANY)]) self.assertEqual(uploaded_image, return_image) update_resource=self.wrapped_client._update_image,",544,97
openstack%2Fopenstack-health~master~I68aae7869e999f112df482fa70501afdfb1f8bc5,openstack/openstack-health,master,I68aae7869e999f112df482fa70501afdfb1f8bc5,Fix PEP8 (H302) error,NEW,2015-11-10 16:50:00.000000000,2017-12-18 05:19:22.000000000,,"[{'_account_id': 5196}, {'_account_id': 12767}, {'_account_id': 17995}, {'_account_id': 18001}, {'_account_id': 18064}]","[{'number': 1, 'created': '2015-11-10 16:50:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/1e6be27d5ee7aa21e123ab87f39b308055dd79b8', 'message': 'Fix PEP8 (H302) error\n\nThis addresses the H302 issue of importing anything other than modules.\n\nChange-Id: I68aae7869e999f112df482fa70501afdfb1f8bc5\n'}, {'number': 2, 'created': '2015-11-17 12:28:23.000000000', 'files': ['openstack_health/api.py'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/e6d03913aa20218045c9726cef3f1264d71eb7a2', 'message': 'Fix PEP8 (H302) error\n\nThis addresses the H302 issue of importing anything other than modules.\n\nChange-Id: I68aae7869e999f112df482fa70501afdfb1f8bc5\n'}]",0,243719,e6d03913aa20218045c9726cef3f1264d71eb7a2,9,5,2,9189,,,0,"Fix PEP8 (H302) error

This addresses the H302 issue of importing anything other than modules.

Change-Id: I68aae7869e999f112df482fa70501afdfb1f8bc5
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/19/243719/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_health/api.py'],1,1e6be27d5ee7aa21e123ab87f39b308055dd79b8,,"import operator total_runtime = sum(map(operator.itemgetter('run_time'), runs)) avg_runtime = total_runtime / len(runs) runs_by_time['job_data'] = sorted(job_data, key=operator.itemgetter('job_name')) aggregated_runs.sort(key=operator.itemgetter('datetime'))","from operator import itemgetter avg_runtime = sum(map(itemgetter('run_time'), runs)) / len(runs) runs_by_time['job_data'] = sorted(job_data, key=itemgetter('job_name')) aggregated_runs.sort(key=itemgetter('datetime'))",6,4
openstack%2Fopenstack-health~master~I2c19ac713159e996f17bbb143a0c9ed2036f2935,openstack/openstack-health,master,I2c19ac713159e996f17bbb143a0c9ed2036f2935,Add stack dump support,NEW,2016-03-10 18:47:29.000000000,2017-12-18 05:19:19.000000000,,"[{'_account_id': 5196}, {'_account_id': 5689}]","[{'number': 1, 'created': '2016-03-10 18:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/182bae06f46f1df01f2e56ebb1996acf9dea4261', 'message': 'WIP: Add stack dump support\n\nAdd the ability to dump the current stack when a sigusr2 is recieved\n\nChange-Id: I2c19ac713159e996f17bbb143a0c9ed2036f2935\n'}, {'number': 2, 'created': '2016-03-24 19:36:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/8d8f1a4fb30dc694e8c8beafcd2c7a56717b0e73', 'message': 'Add stack dump support\n\nAdd the ability to dump the current stack when a sigusr2 is recieved\n\nChange-Id: I2c19ac713159e996f17bbb143a0c9ed2036f2935\n'}, {'number': 3, 'created': '2016-04-06 21:35:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/2fd8bc2b50f35dc6aeee7c515c1ef1626afd8297', 'message': 'Add stack dump support\n\nAdd the ability to dump the current stack when a sigusr2 is recieved\n\nChange-Id: I2c19ac713159e996f17bbb143a0c9ed2036f2935\n'}, {'number': 4, 'created': '2016-04-07 05:40:40.000000000', 'files': ['openstack_health/api.py'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/be50deab5a1cee836db26c7fa6a171fc2c16a2be', 'message': 'Add stack dump support\n\nAdd the ability to dump the current stack when a sigusr2 is recieved\n\nChange-Id: I2c19ac713159e996f17bbb143a0c9ed2036f2935\n'}]",5,291359,be50deab5a1cee836db26c7fa6a171fc2c16a2be,17,2,4,5196,,,0,"Add stack dump support

Add the ability to dump the current stack when a sigusr2 is recieved

Change-Id: I2c19ac713159e996f17bbb143a0c9ed2036f2935
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/59/291359/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack_health/api.py'],1,182bae06f46f1df01f2e56ebb1996acf9dea4261,291359,"import logging import os import signalimport traceback def stack_dump_handler(signum, frame): signal.signal(signal.SIGUSR2, signal.SIG_IGN) log_str = """" log_str += ""Thread: %s\n"" % os.getpid() log_str += """".join(traceback.format_stack()) log = logging.getLogger(""openstack_health.api.stack_dump"") log.debug(log_str) signal.signal(signal.SIGUSR2, stack_dump_handler) def get_app(): signal.signal(signal.SIGUSR2, stack_dump_handler) signal.signal(signal.SIGUSR2, stack_dump_handler)",def get_app():,17,0
openstack%2Fzaqar~master~If88b2a28d4e366148710af508cccdb8ca0e6b575,openstack/zaqar,master,If88b2a28d4e366148710af508cccdb8ca0e6b575,url_prefix support for simulate functions,NEW,2016-04-21 06:30:41.000000000,2017-12-18 05:19:15.000000000,,[],"[{'number': 1, 'created': '2016-04-21 06:30:41.000000000', 'files': ['zaqar/tests/unit/transport/wsgi/v2_0/test_media_type.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_health.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_default_limits.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_health.py', 'zaqar/tests/unit/transport/wsgi/v1/test_pools.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_subscriptions.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_urls.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_pools.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1/test_queue_lifecycle.py', 'zaqar/tests/unit/transport/wsgi/v1/test_default_limits.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_validation.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_queue_lifecycle.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1/test_validation.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_flavors.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_flavors.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_media_type.py', 'zaqar/tests/unit/transport/wsgi/v1/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_default_limits.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_queue_lifecycle.py', 'zaqar/tests/unit/transport/wsgi/v1/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_validation.py', 'zaqar/tests/unit/transport/wsgi/v1/test_media_type.py', 'zaqar/tests/unit/transport/wsgi/base.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_pools.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/3b8ad8caa75371fbf61f578a8ea422ee4552bea4', 'message': ""url_prefix support for simulate functions\n\nAdd suppport in simulate_* functions for a 'base path' so we\ndon't have to concatenate against self.url_prefix in the code.\n\nChange-Id: If88b2a28d4e366148710af508cccdb8ca0e6b575\n""}]",0,308775,3b8ad8caa75371fbf61f578a8ea422ee4552bea4,3,0,1,20661,,,0,"url_prefix support for simulate functions

Add suppport in simulate_* functions for a 'base path' so we
don't have to concatenate against self.url_prefix in the code.

Change-Id: If88b2a28d4e366148710af508cccdb8ca0e6b575
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/75/308775/1 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/tests/unit/transport/wsgi/v2_0/test_media_type.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_health.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_default_limits.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_health.py', 'zaqar/tests/unit/transport/wsgi/v1/test_pools.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_subscriptions.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_urls.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_pools.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1/test_queue_lifecycle.py', 'zaqar/tests/unit/transport/wsgi/v1/test_default_limits.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_validation.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_queue_lifecycle.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1/test_validation.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_flavors.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_flavors.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_media_type.py', 'zaqar/tests/unit/transport/wsgi/v1/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_default_limits.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_queue_lifecycle.py', 'zaqar/tests/unit/transport/wsgi/v1/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_validation.py', 'zaqar/tests/unit/transport/wsgi/v1/test_media_type.py', 'zaqar/tests/unit/transport/wsgi/base.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_pools.py']",28,3b8ad8caa75371fbf61f578a8ea422ee4552bea4,bp/url-prefix-support," path = '/pools/' + name base = '/pools/' self.pool = '/pools/' + str(uuid.uuid1()) path = '/pools/' + str(uuid.uuid1()) path = '/pools/' + str(uuid.uuid1()) path = '/pools/' + str(uuid.uuid1()) path = '/pools/' + str(uuid.uuid1()) self.simulate_get('/pools/nonexisting') self.simulate_patch('/pools/notexists', result = self.simulate_get('/pools') result = self.simulate_get('/pools', result = self.simulate_get('/pools',"," path = test.url_prefix + '/pools/' + name base = test.url_prefix + '/pools/' self.pool = self.url_prefix + '/pools/' + str(uuid.uuid1()) path = self.url_prefix + '/pools/' + str(uuid.uuid1()) path = self.url_prefix + '/pools/' + str(uuid.uuid1()) path = self.url_prefix + '/pools/' + str(uuid.uuid1()) path = self.url_prefix + '/pools/' + str(uuid.uuid1()) self.simulate_get(self.url_prefix + '/pools/nonexisting') self.simulate_patch(self.url_prefix + '/pools/notexists', result = self.simulate_get(self.url_prefix + '/pools') result = self.simulate_get(self.url_prefix + '/pools', result = self.simulate_get(self.url_prefix + '/pools',",159,168
openstack%2Fdiskimage-builder~master~Ib44cbc2540c8f9919954da5ab4fa02acbc735e6c,openstack/diskimage-builder,master,Ib44cbc2540c8f9919954da5ab4fa02acbc735e6c,[WIP] use virt-sysprep to cleanup images,NEW,2016-04-19 06:52:36.000000000,2017-12-18 05:19:07.000000000,,[{'_account_id': 14288}],"[{'number': 1, 'created': '2016-04-19 06:52:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/94f17f9de06fbbcf572cf8baff582602e50ec744', 'message': ""[WIP] use virt-sysprep to cleanup images\n\nI've been using this and booting images cleaned with it.\n\nThis is mostly a test to see if this runs under CI at this point.\n\nIt might be better in a new phase that's dedicated specifically to\nmodifying the raw image before conversion.\n\nChange-Id: Ib44cbc2540c8f9919954da5ab4fa02acbc735e6c\n""}, {'number': 2, 'created': '2016-04-22 03:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/5416ac488846c6b117a654b0e1e1e5a103844c8d', 'message': ""[WIP] use virt-sysprep to cleanup images\n\nI've been using this and booting images cleaned with it.\n\nThis is mostly a test to see if this runs under CI at this point.\n\nIt might be better in a new phase that's dedicated specifically to\nmodifying the raw image before conversion.\n\nChange-Id: Ib44cbc2540c8f9919954da5ab4fa02acbc735e6c\n""}, {'number': 3, 'created': '2016-04-22 04:19:11.000000000', 'files': ['bin/disk-image-create', 'tests/install_test_deps.sh'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/014089b4e471229dcc784f7731a6da85e0014096', 'message': ""[WIP] use virt-sysprep to cleanup images\n\nI've been using this and booting images cleaned with it.\n\nThis is mostly a test to see if this runs under CI at this point.\n\nIt might be better in a new phase that's dedicated specifically to\nmodifying the raw image before conversion.\n\nChange-Id: Ib44cbc2540c8f9919954da5ab4fa02acbc735e6c\n""}]",0,307588,014089b4e471229dcc784f7731a6da85e0014096,13,1,3,7118,,,0,"[WIP] use virt-sysprep to cleanup images

I've been using this and booting images cleaned with it.

This is mostly a test to see if this runs under CI at this point.

It might be better in a new phase that's dedicated specifically to
modifying the raw image before conversion.

Change-Id: Ib44cbc2540c8f9919954da5ab4fa02acbc735e6c
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/88/307588/2 && git format-patch -1 --stdout FETCH_HEAD,"['bin/disk-image-create', 'tests/install_test_deps.sh']",2,94f17f9de06fbbcf572cf8baff582602e50ec744,virt-sysprep, uuid-runtime \ libguestfs-tools|| \ qemu-img \ libguestfs-tools, uuid-runtime || \ qemu-img,7,2
openstack%2Fopenstack-health~master~I55f67147d1b402733683f33ffa4584aa1dfdf04e,openstack/openstack-health,master,I55f67147d1b402733683f33ffa4584aa1dfdf04e,WIP DNM: Add StackViz links to recent runs tables,NEW,2016-04-19 19:45:37.000000000,2017-12-18 05:19:03.000000000,,"[{'_account_id': 5689}, {'_account_id': 17001}]","[{'number': 1, 'created': '2016-04-19 19:45:37.000000000', 'files': ['etc/config.json', 'app/views/home.html', 'app/js/controllers/job.js', 'app/views/job.html', 'app/js/controllers/grouped-runs.js', 'app/views/grouped-runs.html', 'app/js/controllers/home.js'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/b6faaed2e533510d94ffa601c13efb445de546f1', 'message': 'WIP DNM: Add StackViz links to recent runs tables\n\nThis patch adds buttons linking to StackViz runs to relevant entries\nin the recent runs tables on the home page, grouped runs page, and\njob page.\n\nThis WIP patch uses a hardcoded demo server for StackViz, this needs\nto be changed/removed before merging.\n\nChange-Id: I55f67147d1b402733683f33ffa4584aa1dfdf04e\n'}]",6,308013,b6faaed2e533510d94ffa601c13efb445de546f1,6,2,1,17001,,,0,"WIP DNM: Add StackViz links to recent runs tables

This patch adds buttons linking to StackViz runs to relevant entries
in the recent runs tables on the home page, grouped runs page, and
job page.

This WIP patch uses a hardcoded demo server for StackViz, this needs
to be changed/removed before merging.

Change-Id: I55f67147d1b402733683f33ffa4584aa1dfdf04e
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/13/308013/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/config.json', 'app/views/home.html', 'app/js/controllers/job.js', 'app/views/job.html', 'app/js/controllers/grouped-runs.js', 'app/views/grouped-runs.html', 'app/js/controllers/home.js']",7,b6faaed2e533510d94ffa601c13efb445de546f1,stackviz-link," config, healthService, projectService, viewService, tooltipService, periodsService) { config.get().then(function(config) { vm.stackviz = config.stackviz; }); vm.stackviz = null;"," healthService, projectService, viewService, tooltipService, periodsService) {",42,4
openstack%2Fswift~master~I836294256d47b71ea23fa3b758b72f4b46b93db3,openstack/swift,master,I836294256d47b71ea23fa3b758b72f4b46b93db3,skip object versioning tests when allow_versioned_writes = False,NEW,2015-11-24 18:25:56.000000000,2017-12-18 05:18:48.000000000,,"[{'_account_id': 2622}, {'_account_id': 12279}, {'_account_id': 13052}, {'_account_id': 15932}, {'_account_id': 18978}]","[{'number': 1, 'created': '2015-11-24 18:25:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cff0451ae8ceb6e09ed1b39bc471e034e9f7a16a', 'message': 'skip object versioning tests when allow_versioned_writes = False\n\nOriginally, functional tests from TestObjectVersioning and\nTestObjectVersioningUTF8 were all failing with 412 errors when\nallow_versioned_writes = False in the proxy.conf file. Since the 412 errors\nwere expected, the solution was to skip the object versioning tests when\nallow_versioned_writes = False. Skipping the tests was performed by\nincluding a new block of code in TestObjectVersioningEnv that checked the\nvalue of versioned_writes in cluster_info. If versioned_writes was False\nwhile running an object versioning test, the test was skipped.\n\nAlso, the variable set_up in the class TestObjectVersioningUTF8 was changed\nto be True. When set_up was set to False, each TestObjectVersioningUTF8 test\nfailed, since the condition that would have skipped the test was never\nmet.\n\nChange-Id: I836294256d47b71ea23fa3b758b72f4b46b93db3\n'}, {'number': 2, 'created': '2015-11-24 22:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c91e1d4b56731719437830a6ef588cac7dcc6666', 'message': 'skip object versioning tests when allow_versioned_writes = False\n\nOriginally, functional tests from TestObjectVersioning and\nTestObjectVersioningUTF8 were all failing with 412 errors when\nallow_versioned_writes = False in the proxy.conf file. Since the 412 errors\nwere expected, the solution was to skip the object versioning tests when\nallow_versioned_writes = False. Skipping the tests was performed by\nincluding a new block of code in TestObjectVersioningEnv that checked the\nvalue of versioned_writes in cluster_info. If versioned_writes was False\nwhile running an object versioning test, the test was skipped.\n\nAlso, the variable set_up in the class TestObjectVersioningUTF8 was changed\nto be True. When set_up was set to False, each TestObjectVersioningUTF8 test\nfailed, since the condition that would have skipped the test was never\nmet.\n\nChange-Id: I836294256d47b71ea23fa3b758b72f4b46b93db3\nCloses-Bug: #1517974\n'}, {'number': 3, 'created': '2015-12-03 22:33:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e40c9f477c175ad561da96399f093649ef4ad45d', 'message': 'skip object versioning tests when allow_versioned_writes = False\n\nOriginally, functional tests from TestObjectVersioning and\nTestObjectVersioningUTF8 were all failing with 412 errors when\nallow_versioned_writes = False in the proxy.conf file. Since the 412 errors\nwere expected, the solution was to skip the object versioning tests when\nallow_versioned_writes = False. Skipping the tests was performed by\nincluding a new block of code in TestObjectVersioningEnv that checked the\nstatus of ResponseError after attempting to create a container using headers.\nIf the status was 412, the test was skipped. Otherwise, the test failed.\n\nChange-Id: I836294256d47b71ea23fa3b758b72f4b46b93db3\nCloses-Bug: #1517974\n'}, {'number': 4, 'created': '2016-01-18 17:46:51.000000000', 'files': ['test/functional/tests.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/e442085370393bd219c3eaeb144e5c1f6e69c693', 'message': 'skip object versioning tests when allow_versioned_writes = False\n\nOriginally, functional tests from TestObjectVersioning and\nTestObjectVersioningUTF8 were all failing with 412 errors when\nallow_versioned_writes = False in the proxy.conf file. Since the 412 errors\nwere expected, the solution was to skip the object versioning tests when\nallow_versioned_writes = False. Skipping the tests was performed by\nincluding a new block of code in TestObjectVersioningEnv that checked the\nstatus of ResponseError after attempting to create a container using headers.\nIf the status was 412, the test was skipped. Otherwise, the test failed.\n\nChange-Id: I836294256d47b71ea23fa3b758b72f4b46b93db3\nCloses-Bug: #1517974\n'}]",4,249354,e442085370393bd219c3eaeb144e5c1f6e69c693,27,5,4,17625,,,0,"skip object versioning tests when allow_versioned_writes = False

Originally, functional tests from TestObjectVersioning and
TestObjectVersioningUTF8 were all failing with 412 errors when
allow_versioned_writes = False in the proxy.conf file. Since the 412 errors
were expected, the solution was to skip the object versioning tests when
allow_versioned_writes = False. Skipping the tests was performed by
including a new block of code in TestObjectVersioningEnv that checked the
status of ResponseError after attempting to create a container using headers.
If the status was 412, the test was skipped. Otherwise, the test failed.

Change-Id: I836294256d47b71ea23fa3b758b72f4b46b93db3
Closes-Bug: #1517974
",git fetch https://review.opendev.org/openstack/swift refs/changes/54/249354/4 && git format-patch -1 --stdout FETCH_HEAD,['test/functional/tests.py'],1,cff0451ae8ceb6e09ed1b39bc471e034e9f7a16a,(detached, if cls.versioning_enabled is None: cls.versioning_enabled = 'versioned_writes' in cluster_info if not cls.versioning_enabled: return set_up = True, set_up = False,6,1
openstack%2Fstackviz~master~Ie7b3eeb977a609fa2f6a1955fa535f7ff3ffe6fb,openstack/stackviz,master,Ie7b3eeb977a609fa2f6a1955fa535f7ff3ffe6fb,WIP: Parse dstat logs in a worker thread,NEW,2016-04-12 01:20:28.000000000,2017-12-18 05:18:36.000000000,,[{'_account_id': 17001}],"[{'number': 1, 'created': '2016-04-12 01:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/stackviz/commit/a256c33c4b7c7c678dc5a5b38949ec442077a1ba', 'message': 'WIP: Parse dstat logs in a worker thread\n\nThis moves dstat log parsing into a worker thread to lessen the impact\nof parsing on the framerate during initial page load. This reduces the\nuser-facing load impact by roughly 66%, and is particularly helpful\nfor larger dstat logs.\n\nA small amount of new build infrastructure is also added to generate\nindividual browserify bundles for each script in `app/workers/`. These\nscripts can then be loaded independently of the main bundle while only\nincluding necessary dependencies.\n\nChange-Id: Ie7b3eeb977a609fa2f6a1955fa535f7ff3ffe6fb\n'}, {'number': 2, 'created': '2016-04-12 01:37:57.000000000', 'files': ['app/js/util/array-util.js', 'app/js/directives/timeline.js', 'app/js/directives/timeline-dstat.js', 'app/workers/dstat-worker.js', 'gulp/tasks/workers.js', 'gulp/tasks/watch.js', 'package.json', 'gulp/config.js', 'gulp/tasks/development.js'], 'web_link': 'https://opendev.org/openstack/stackviz/commit/233e913f7c54823292ed61d6559a11cc76b51176', 'message': 'WIP: Parse dstat logs in a worker thread\n\nThis moves dstat log parsing into a worker thread to lessen the impact\nof parsing on the framerate during initial page load. This reduces the\nuser-facing load impact by roughly 66%, and is particularly helpful\nfor larger dstat logs.\n\nA small amount of new build infrastructure is also added to generate\nindividual browserify bundles for each script in `app/workers/`. These\nscripts can then be loaded independently of the main bundle while only\nincluding necessary dependencies.\n\nChange-Id: Ie7b3eeb977a609fa2f6a1955fa535f7ff3ffe6fb\n'}]",0,304353,233e913f7c54823292ed61d6559a11cc76b51176,7,1,2,17001,,,0,"WIP: Parse dstat logs in a worker thread

This moves dstat log parsing into a worker thread to lessen the impact
of parsing on the framerate during initial page load. This reduces the
user-facing load impact by roughly 66%, and is particularly helpful
for larger dstat logs.

A small amount of new build infrastructure is also added to generate
individual browserify bundles for each script in `app/workers/`. These
scripts can then be loaded independently of the main bundle while only
including necessary dependencies.

Change-Id: Ie7b3eeb977a609fa2f6a1955fa535f7ff3ffe6fb
",git fetch https://review.opendev.org/openstack/stackviz refs/changes/53/304353/2 && git format-patch -1 --stdout FETCH_HEAD,"['app/js/util/array-util.js', 'app/js/directives/timeline.js', 'app/js/directives/timeline-dstat.js', 'app/workers/dstat-worker.js', 'gulp/tasks/workers.js', 'gulp/tasks/watch.js', 'package.json', 'gulp/config.js', 'gulp/tasks/development.js']",9,a256c33c4b7c7c678dc5a5b38949ec442077a1ba,dstat-worker," runSequence( ['styles', 'fonts', 'data', 'views', 'browserify', 'workers'], 'watch', cb);"," runSequence(['styles', 'fonts', 'data', 'views', 'browserify'], 'watch', cb);",197,3
openstack%2Fironic~master~I66fa3df93247a61fc07bdfee325a4f9543d7ea61,openstack/ironic,master,I66fa3df93247a61fc07bdfee325a4f9543d7ea61,WIP: sshd serial console support,NEW,2016-04-29 17:12:58.000000000,2017-12-18 05:18:24.000000000,,"[{'_account_id': 136}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 17998}, {'_account_id': 20311}, {'_account_id': 20689}]","[{'number': 1, 'created': '2016-04-29 17:12:58.000000000', 'files': ['ironic/tests/unit/drivers/test_irmc.py', 'ironic/drivers/base.py', 'ironic/drivers/modules/ilo/console.py', 'ironic/tests/unit/drivers/modules/test_console_utils.py', 'ironic/drivers/fake.py', 'ironic/drivers/modules/console_utils.py', 'ironic/tests/unit/drivers/modules/test_seamicro.py', 'ironic/drivers/pxe.py', 'ironic/conductor/rpcapi.py', 'ironic/drivers/irmc.py', 'ironic/tests/unit/drivers/test_pxe.py', 'ironic/conductor/manager.py', 'ironic/drivers/agent.py', 'ironic/tests/unit/drivers/modules/test_ssh.py', 'ironic/drivers/modules/seamicro.py', 'ironic/drivers/modules/ssh.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/drivers/modules/ipminative.py', 'ironic/tests/unit/drivers/modules/test_ipminative.py', 'ironic/tests/unit/drivers/modules/ilo/test_console.py', 'ironic/tests/unit/drivers/modules/test_ipmitool.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/de2060990b9f068db567f37902214a1ed442dfa5', 'message': 'WIP: sshd serial console support\n\nChange-Id: I66fa3df93247a61fc07bdfee325a4f9543d7ea61\n'}]",0,311196,de2060990b9f068db567f37902214a1ed442dfa5,19,6,1,20689,,,0,"WIP: sshd serial console support

Change-Id: I66fa3df93247a61fc07bdfee325a4f9543d7ea61
",git fetch https://review.opendev.org/openstack/ironic refs/changes/96/311196/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/drivers/test_irmc.py', 'ironic/drivers/base.py', 'ironic/drivers/modules/ilo/console.py', 'ironic/tests/unit/drivers/modules/test_console_utils.py', 'ironic/drivers/fake.py', 'ironic/drivers/modules/console_utils.py', 'ironic/tests/unit/drivers/modules/test_seamicro.py', 'ironic/drivers/pxe.py', 'ironic/conductor/rpcapi.py', 'ironic/drivers/irmc.py', 'ironic/tests/unit/drivers/test_pxe.py', 'ironic/conductor/manager.py', 'ironic/drivers/agent.py', 'ironic/tests/unit/drivers/modules/test_ssh.py', 'ironic/drivers/modules/seamicro.py', 'ironic/drivers/modules/ssh.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/drivers/modules/ipminative.py', 'ironic/tests/unit/drivers/modules/test_ipminative.py', 'ironic/tests/unit/drivers/modules/ilo/test_console.py', 'ironic/tests/unit/drivers/modules/test_ipmitool.py', 'ironic/api/controllers/v1/node.py']",22,de2060990b9f068db567f37902214a1ed442dfa5,bug/1536572," @expose.expose(None, types.uuid_or_name, types.boolean, wtypes.text, def put(self, node_ident, enabled, ssh_key=None): rpc_node.uuid, enabled, ssh_key, topic)"," @expose.expose(None, types.uuid_or_name, types.boolean, def put(self, node_ident, enabled): rpc_node.uuid, enabled, topic)",253,112
openstack%2Fironic~master~I1885dce91fa7251e2667f5b01ef666fd42dcabd6,openstack/ironic,master,I1885dce91fa7251e2667f5b01ef666fd42dcabd6,Add VNC console support,NEW,2016-03-23 13:32:10.000000000,2017-12-18 05:18:07.000000000,,"[{'_account_id': 2889}, {'_account_id': 17998}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-03-23 13:32:10.000000000', 'files': ['ironic/drivers/modules/aten.py', 'ironic/drivers/modules/ssh.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a0f7ab421bc2eb6996c6e28efd4db0f76f569b51', 'message': 'Add VNC console support\n\nThis change introduces VNC console support for SSH/virt driver\nand ATEN KVM devices.\n\nChange-Id: I1885dce91fa7251e2667f5b01ef666fd42dcabd6\nImplements: bp/vnc-console\n'}]",0,296437,a0f7ab421bc2eb6996c6e28efd4db0f76f569b51,6,3,1,8259,,,0,"Add VNC console support

This change introduces VNC console support for SSH/virt driver
and ATEN KVM devices.

Change-Id: I1885dce91fa7251e2667f5b01ef666fd42dcabd6
Implements: bp/vnc-console
",git fetch https://review.opendev.org/openstack/ironic refs/changes/37/296437/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/aten.py', 'ironic/drivers/modules/ssh.py']",2,a0f7ab421bc2eb6996c6e28efd4db0f76f569b51,bp/vnc-console," 'get_vnc_port': ( ""{_BaseCmd_} dumpxml {_NodeName_} | "" ""grep \""graphics type='vnc'\"" | awk '{print $3}' | "" ""awk -F'=' ' {print $2}' | sed \""s/'//g\""""), class VNCConsole(base.ConsoleInterface): """"""A ConsoleInterface that uses ssh and VNC."""""" def get_properties(self): properties = COMMON_PROPERTIES.copy() properties.update(CONSOLE_PROPERTIES) return properties def validate(self, task): pass def start_console(self, task): pass def stop_console(self, task): pass def get_console(self, task): driver_info = _parse_driver_info(task.node) driver_info['macs'] = driver_utils.get_node_mac_addresses(task) cmd_to_exec = driver_info['cmd_set'].get('get_vnc_port') if cmd_to_exec: ssh_obj = _get_connection(task.node) node_name = _get_hosts_name_for_node(ssh_obj, driver_info) base_cmd = driver_info['cmd_set']['base_cmd'] cmd_to_exec = cmd_to_exec.replace('{_NodeName_}', node_name) cmd_to_exec = cmd_to_exec.replace('{_BaseCmd_}', base_cmd) stdout, stderr = _ssh_execute(ssh_obj, cmd_to_exec) vnc_port = stdout else: raise NotImplementedError() return {'type': 'novnc', 'host': driver_info['host'], 'port': vnc_port}",,86,0
openstack%2Fdiskimage-builder~master~Ib1adb077548d9e9a1d08c1aa695a5a44b0d2e541,openstack/diskimage-builder,master,Ib1adb077548d9e9a1d08c1aa695a5a44b0d2e541,[WIP] Allow using local image for ubuntu,NEW,2015-06-23 09:46:33.000000000,2017-12-18 05:17:43.000000000,,"[{'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 10035}, {'_account_id': 11105}, {'_account_id': 13795}]","[{'number': 1, 'created': '2015-06-23 09:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/0425bdaec0b0f0a988edb779f7e0b37ca63a8015', 'message': 'Allow using local image for ubuntu\n\nThis patch adds support for using local qcow2 and tar based image\nfor building ubuntu images.\n\nLocal qcow2 file is specified by setting DIB_CLOUD_IMAGES to\ndirectory path using file:/// uri and BASE_IMAGE_FILE to file\nname of qcow2 file.\nRoot parition extracted from qcow2 image is cached in\n$DIB_IMAGE_CACHE, to speed up build process by avoiding having to\nre-extract the root pariton from qcow2 image for each build.\nCached tar extract of qcow2 image is used when $DIB_OFFLINE is set.\n\nTar based local image can also be used by setting $DIB_OFFLINE and\n by setting DIB_CLOUD_IMAGES to directory path using file:/// uri\nand BASE_IMAGE_FILE to file name of tar image.\n\nChange-Id: Ib1adb077548d9e9a1d08c1aa695a5a44b0d2e541\nCloses-Bug: #1313792\n'}, {'number': 2, 'created': '2016-05-09 01:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/63041ee604258e7ef76d388852e66d7631a34cf5', 'message': '[WIP] Allow using local image for ubuntu\n\nThis patch adds support for using local qcow2 and tar based image\nfor building ubuntu images.\n\nLocal qcow2 file is specified by setting DIB_CLOUD_IMAGES to\ndirectory path using file:/// uri and BASE_IMAGE_FILE to file\nname of qcow2 file.\nRoot parition extracted from qcow2 image is cached in\n$DIB_IMAGE_CACHE, to speed up build process by avoiding having to\nre-extract the root pariton from qcow2 image for each build.\nCached tar extract of qcow2 image is used when $DIB_OFFLINE is set.\n\nTar based local image can also be used by setting $DIB_OFFLINE and\n by setting DIB_CLOUD_IMAGES to directory path using file:/// uri\nand BASE_IMAGE_FILE to file name of tar image.\n\nChange-Id: Ib1adb077548d9e9a1d08c1aa695a5a44b0d2e541\nCloses-Bug: #1313792\n'}, {'number': 3, 'created': '2016-05-09 01:53:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/582dd127ce38ba56c0c81ca775f158600f9596af', 'message': '[WIP] Allow using local image for ubuntu\n\nThis patch adds support for using local qcow2 and tar based image\nfor building ubuntu images.\n\nLocal qcow2 file is specified by setting DIB_CLOUD_IMAGES to\ndirectory path using file:/// uri and BASE_IMAGE_FILE to file\nname of qcow2 file.\nRoot parition extracted from qcow2 image is cached in\n$DIB_IMAGE_CACHE, to speed up build process by avoiding having to\nre-extract the root pariton from qcow2 image for each build.\nCached tar extract of qcow2 image is used when $DIB_OFFLINE is set.\n\nTar based local image can also be used by setting $DIB_OFFLINE and\n by setting DIB_CLOUD_IMAGES to directory path using file:/// uri\nand BASE_IMAGE_FILE to file name of tar image.\n\nChange-Id: Ib1adb077548d9e9a1d08c1aa695a5a44b0d2e541\nCloses-Bug: #1313792\n'}, {'number': 4, 'created': '2016-05-09 01:55:19.000000000', 'files': ['elements/ubuntu/root.d/10-cache-ubuntu-tarball'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/04cc044498f44fc3337a6358af08301e6cb4d01b', 'message': '[WIP] Allow using local image for ubuntu\n\nThis patch adds support for using local qcow2 and tar based image\nfor building ubuntu images.\n\nLocal qcow2 file is specified by setting DIB_CLOUD_IMAGES to\ndirectory path using file:/// uri and BASE_IMAGE_FILE to file\nname of qcow2 file.\nRoot parition extracted from qcow2 image is cached in\n$DIB_IMAGE_CACHE, to speed up build process by avoiding having to\nre-extract the root pariton from qcow2 image for each build.\nCached tar extract of qcow2 image is used when $DIB_OFFLINE is set.\n\nTar based local image can also be used by setting $DIB_OFFLINE and\n by setting DIB_CLOUD_IMAGES to directory path using file:/// uri\nand BASE_IMAGE_FILE to file name of tar image.\n\nChange-Id: Ib1adb077548d9e9a1d08c1aa695a5a44b0d2e541\nCloses-Bug: #1313792\n'}]",0,194574,04cc044498f44fc3337a6358af08301e6cb4d01b,18,5,4,13795,,,0,"[WIP] Allow using local image for ubuntu

This patch adds support for using local qcow2 and tar based image
for building ubuntu images.

Local qcow2 file is specified by setting DIB_CLOUD_IMAGES to
directory path using file:/// uri and BASE_IMAGE_FILE to file
name of qcow2 file.
Root parition extracted from qcow2 image is cached in
$DIB_IMAGE_CACHE, to speed up build process by avoiding having to
re-extract the root pariton from qcow2 image for each build.
Cached tar extract of qcow2 image is used when $DIB_OFFLINE is set.

Tar based local image can also be used by setting $DIB_OFFLINE and
 by setting DIB_CLOUD_IMAGES to directory path using file:/// uri
and BASE_IMAGE_FILE to file name of tar image.

Change-Id: Ib1adb077548d9e9a1d08c1aa695a5a44b0d2e541
Closes-Bug: #1313792
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/74/194574/4 && git format-patch -1 --stdout FETCH_HEAD,['elements/ubuntu/root.d/10-cache-ubuntu-tarball'],1,0425bdaec0b0f0a988edb779f7e0b37ca63a8015,bug/1313792,"if [ ""${DIB_CLOUD_IMAGES:0:7}"" == ""file://"" ] ; then CACHED_FILE=${DIB_CLOUD_IMAGES##file://}/$BASE_IMAGE_FILE if [[ ""`file $CACHED_FILE`"" =~ ""QCOW Image"" ]] ; then QCOW_FILE=$CACHED_FILE CACHED_FILE=$CACHED_FILE.tgz fi fiQCOW_FILE=${QCOW_FILE:-""""} elif [ -n ""$QCOW_FILE"" ] ; then echo ""Repacking base image as tarball."" WORKING=$(mktemp --tmpdir=${TMP_DIR:-/tmp} -d) EACTION=""rm -r $WORKING"" trap ""$EACTION"" EXIT echo ""Working in $WORKING"" RAW_FILE=$(mktemp --tmpdir=$WORKING XXXXXX.raw) qemu-img convert -f qcow2 -O raw $QCOW_FILE $RAW_FILE ROOT_PARTITON=p$(sudo kpartx -l $RAW_FILE | awk ""/loop[0-9]+p/""|wc -l) sudo udevadm settle # kpartx fails if no /dev/loop* exists, ""losetup -f"" prints first unused # loop device and creates it if it doesn't exist sudo losetup -f # XXX: Parsing stdout is dangerous, would like a better way to discover # the device used for the image. ROOT_LOOPDEV=$(sudo kpartx -av $RAW_FILE | \ awk ""/loop[0-9]+$ROOT_PARTITON/ {print \$3}"") # If running inside Docker, make our nodes manually, because udev will not be working. if ! timeout 5 sh -c ""while ! [ -e /dev/mapper/$ROOT_LOOPDEV ]; do sleep 1; done""; then echo ""Error: Could not find /dev/mapper/$ROOT_LOOPDEV"" exit 1 fi EACTION=""sudo kpartx -d $RAW_FILE ; $EACTION"" trap ""$EACTION"" EXIT mkdir $WORKING/mnt if [ ""xfs"" = ""$(sudo blkid -o value -s TYPE /dev/mapper/$ROOT_LOOPDEV)"" ]; then # mount xfs with nouuid, just in case that uuid is already mounted MOUNTOPTS=""-o nouuid"" else MOUNTOPTS="""" fi sudo mount $MOUNTOPTS /dev/mapper/$ROOT_LOOPDEV $WORKING/mnt EACTION=""sudo umount -f $WORKING/mnt ; $EACTION"" trap ""$EACTION"" EXIT # Chroot in so that we get the correct uid/gid sudo chroot $WORKING/mnt bin/tar -cz . > $WORKING/tmp.tar mv $WORKING/tmp.tar $CACHED_FILE sudo tar -C $TARGET_ROOT --numeric-owner -xzf $CACHED_FILE", sudo tar -C $TARGET_ROOT --numeric-owner -xzf $DIB_IMAGE_CACHE/$BASE_IMAGE_FILE,54,1
openstack%2Fopenstack-health~master~I8db799b1d962bb157041c83dd5fdee6b1fbbb4ff,openstack/openstack-health,master,I8db799b1d962bb157041c83dd5fdee6b1fbbb4ff,DNM: Add digging feature on charts,NEW,2016-05-10 08:31:48.000000000,2017-12-18 05:17:31.000000000,,[{'_account_id': 5689}],"[{'number': 1, 'created': '2016-05-10 08:31:48.000000000', 'files': ['app/js/directives/chart-line.js', 'app/js/directives/chart-scatter.js'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/77f3f96fc1ccb75b6c529b6ce8de078734aefb49', 'message': 'DNM: Add digging feature on charts\n\nThis commit will add a digging feature on charts.\nThis might need to get info of specified time period.\nTODO:\n * Handling clicking events - DONE\n * Get and put info to dig\n * etc\n\nChange-Id: I8db799b1d962bb157041c83dd5fdee6b1fbbb4ff\n'}]",0,314459,77f3f96fc1ccb75b6c529b6ce8de078734aefb49,4,1,1,5689,,,0,"DNM: Add digging feature on charts

This commit will add a digging feature on charts.
This might need to get info of specified time period.
TODO:
 * Handling clicking events - DONE
 * Get and put info to dig
 * etc

Change-Id: I8db799b1d962bb157041c83dd5fdee6b1fbbb4ff
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/59/314459/1 && git format-patch -1 --stdout FETCH_HEAD,"['app/js/directives/chart-line.js', 'app/js/directives/chart-scatter.js']",2,77f3f96fc1ccb75b6c529b6ce8de078734aefb49,add-event-on-chart," chart.scatter.dispatch.on('elementClick', function(e){ console.log('elementClick in callback', e); }); ",,8,0
openstack%2Fopenstack-health~master~Ie32d5cc384107a83f5622b3680d7f08223722ffa,openstack/openstack-health,master,Ie32d5cc384107a83f5622b3680d7f08223722ffa,DNM: Add sorting column to OH URLs,NEW,2016-05-11 07:28:16.000000000,2017-12-18 05:17:26.000000000,,[{'_account_id': 5689}],"[{'number': 1, 'created': '2016-05-11 07:28:16.000000000', 'files': ['app/js/directives/table-sort.js'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/4105f1f321588a9e67e610a1c594f955702d8382', 'message': 'DNM: Add sorting column to OH URLs\n\nThis commit adds a sorting column to openstack-health URLs.\n\nChange-Id: Ie32d5cc384107a83f5622b3680d7f08223722ffa\n'}]",0,314895,4105f1f321588a9e67e610a1c594f955702d8382,4,1,1,5689,,,0,"DNM: Add sorting column to OH URLs

This commit adds a sorting column to openstack-health URLs.

Change-Id: Ie32d5cc384107a83f5622b3680d7f08223722ffa
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/95/314895/1 && git format-patch -1 --stdout FETCH_HEAD,['app/js/directives/table-sort.js'],1,4105f1f321588a9e67e610a1c594f955702d8382,bug/1577420,"function tableSort($compile, $location) { controller.sortColumn = $location.search().sortColumn || ''; controller.sortReversed = $location.search().sortReversed || ''; // // $location.search('sortColumn', controller.sortColumn).replace(); // $location.search('sortReversed', controller.sortReversed).replace(); $location.search('sortColumn', controller.sortColumn).replace(); $location.search('sortReversed', controller.sortReversed).replace(); var controller = function($scope, $location) { vm.sortColumn = $location.search().sortColumn || vm.sortColumn; vm.sortReversed = $location.search().sortReversed || vm.sortReversed; console.log(""col, rev:"", vm.sortColumn, vm.sortReversed); vm.sortColumn = $location.search().sortColumn || vm.sortColumn; vm.sortReversed = $location.search().sortReversed || vm.sortReversed; ",function tableSort($compile) { var controller = function($scope) {,17,2
openstack%2Fopenstack-health~master~I647075f0c7543255666062a7e3e877b2e967d3d6,openstack/openstack-health,master,I647075f0c7543255666062a7e3e877b2e967d3d6,DNM: Fix graph timezone to UTC,NEW,2016-05-11 08:11:36.000000000,2017-12-18 05:17:23.000000000,,[{'_account_id': 5689}],"[{'number': 1, 'created': '2016-05-11 08:11:36.000000000', 'files': ['app/js/directives/chart-line.js', 'app/js/directives/chart-scatter.js', 'app/js/directives/chart-stack-area.js'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/10d23e19d4d6882a7caf5213d0ddc22fdea8cd37', 'message': ""DNM: Fix graph timezone to UTC\n\nThis commit fixes graph timezone to UTC. Because it's a little\ncomplicated to convert a local time to UTC by humans.\n\nChange-Id: I647075f0c7543255666062a7e3e877b2e967d3d6\n""}]",0,314909,10d23e19d4d6882a7caf5213d0ddc22fdea8cd37,4,1,1,5689,,,0,"DNM: Fix graph timezone to UTC

This commit fixes graph timezone to UTC. Because it's a little
complicated to convert a local time to UTC by humans.

Change-Id: I647075f0c7543255666062a7e3e877b2e967d3d6
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/09/314909/1 && git format-patch -1 --stdout FETCH_HEAD,"['app/js/directives/chart-line.js', 'app/js/directives/chart-scatter.js', 'app/js/directives/chart-stack-area.js']",3,10d23e19d4d6882a7caf5213d0ddc22fdea8cd37,to-utc, chart.xAxis.tickFormat(function(d) { return d3.time.format.utc('%m/%d %H:%M')(new Date(d)); });, chart.xAxis.tickFormat(function(d) { return d3.time.format('%m/%d %H:%M')(new Date(d)); });,3,3
openstack%2Fdiskimage-builder~master~I5459be536c58f880a77bf782a336640c7fafd251,openstack/diskimage-builder,master,I5459be536c58f880a77bf782a336640c7fafd251,Nothing to see here,NEW,2014-12-05 13:36:46.000000000,2017-12-18 05:16:59.000000000,,"[{'_account_id': 1926}, {'_account_id': 12092}]","[{'number': 1, 'created': '2014-12-05 13:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/82869bbeb4a9f3225fb624bcd41fbddb553bf7c5', 'message': 'Nothing to see here\n\nChange-Id: I5459be536c58f880a77bf782a336640c7fafd251\n'}, {'number': 2, 'created': '2014-12-05 15:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7ec1f57826eff9ed5c8f983ffeac46cd20b8897f', 'message': 'Nothing to see here\n\nChange-Id: I5459be536c58f880a77bf782a336640c7fafd251\n'}, {'number': 3, 'created': '2014-12-05 17:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f03f81f315808943a0052284af72b27c7c7f5f25', 'message': 'Nothing to see here\n\nThis is a test, ignore it.\n\nChange-Id: I5459be536c58f880a77bf782a336640c7fafd251\n'}, {'number': 4, 'created': '2014-12-15 10:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/410efab57cc492c32e729bf28efd7910267a1cfd', 'message': 'Nothing to see here\n\nThis is a test, ignore it.\nChange-Id: I5459be536c58f880a77bf782a336640c7fafd251\n'}, {'number': 5, 'created': '2015-09-03 08:56:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/e96968343302e8504d75fe6d8ce522780a107816', 'message': 'Nothing to see here\n\nThis is a test, ignore it.\nChange-Id: I5459be536c58f880a77bf782a336640c7fafd251\n'}, {'number': 6, 'created': '2015-10-20 11:53:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/e7a8dc880ae79eed334663bccadfc309d0678ea7', 'message': 'Nothing to see here\n\nThis is a test, ignore it.\nChange-Id: I5459be536c58f880a77bf782a336640c7fafd251\n'}, {'number': 7, 'created': '2016-05-16 10:01:10.000000000', 'files': ['lib/common-functions'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c23722a59b669c037b6600ca986ed865092e753c', 'message': 'Nothing to see here\n\nThis is a test, ignore it.\nRevert ""Properly fail/trap in eval_run_d""\n\nThis reverts commit 0d1d6bec7c58b2f52e6e1932f58767a02c86068b.\nChange-Id: I5459be536c58f880a77bf782a336640c7fafd251\n'}]",0,139627,c23722a59b669c037b6600ca986ed865092e753c,28,2,7,1926,,,0,"Nothing to see here

This is a test, ignore it.
Revert ""Properly fail/trap in eval_run_d""

This reverts commit 0d1d6bec7c58b2f52e6e1932f58767a02c86068b.
Change-Id: I5459be536c58f880a77bf782a336640c7fafd251
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/27/139627/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/fedora/post-install.d/01-set-fedora-mirror', 'elements/fedora/pre-install.d/01-set-fedora-mirror']",2,82869bbeb4a9f3225fb624bcd41fbddb553bf7c5,tip, yum install -y http://46.231.113.2/downloads/libeatmydata-105-3.fc20.x86_64.rpm echo /usr/lib64/libeatmydata.so > /etc/ld.so.preload,,9,0
openstack%2Fswift~master~If49d3d3d8cfb1ac2b1f043f34dcf64eb9155a026,openstack/swift,master,If49d3d3d8cfb1ac2b1f043f34dcf64eb9155a026,a well-commented skeleton middleware,NEW,2016-02-18 14:27:13.000000000,2017-12-18 05:16:44.000000000,,"[{'_account_id': 330}, {'_account_id': 7433}, {'_account_id': 9625}, {'_account_id': 12279}, {'_account_id': 13052}, {'_account_id': 15343}, {'_account_id': 21231}]","[{'number': 1, 'created': '2016-02-18 14:27:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/363aca49e66cda4b7dbed614074a3d521e2d7e1a', 'message': 'a well-commented skeleton middleware\n\nChange-Id: If49d3d3d8cfb1ac2b1f043f34dcf64eb9155a026\nCloses-Bug: https://bugs.launchpad.net/swift/+bug/1521349\n'}, {'number': 2, 'created': '2016-05-12 17:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9d450b8d5c828cd0385333778fa0abaa5738270e', 'message': 'a well-commented skeleton middleware\n\nChange-Id: If49d3d3d8cfb1ac2b1f043f34dcf64eb9155a026\nCloses-Bug: https://bugs.launchpad.net/swift/+bug/1521349\n'}, {'number': 3, 'created': '2016-05-13 19:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0702c157f60f737eb4f645a2775dfedd978f8422', 'message': 'a well-commented skeleton middleware\n\nChange-Id: If49d3d3d8cfb1ac2b1f043f34dcf64eb9155a026\nCloses-Bug: https://bugs.launchpad.net/swift/+bug/1521349\n'}, {'number': 4, 'created': '2016-05-18 19:54:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7a5a205e765fe15805eaae594d52f271923c2815', 'message': 'a well-commented skeleton middleware\n\nChange-Id: If49d3d3d8cfb1ac2b1f043f34dcf64eb9155a026\nCloses-Bug: https://bugs.launchpad.net/swift/+bug/1521349\n'}, {'number': 5, 'created': '2016-05-18 19:55:36.000000000', 'files': ['doc/middleware/sample/__init__.py', 'doc/middleware/sample/middleware.py', 'doc/middleware/sample/webhook.py', 'doc/middleware/sample/simple.py', 'doc/middleware/README.rst', 'doc/middleware/setup.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/17a203fe35bb83a07605924a15033c45da423a83', 'message': 'a well-commented skeleton middleware\n\nChange-Id: If49d3d3d8cfb1ac2b1f043f34dcf64eb9155a026\nCloses-Bug: https://bugs.launchpad.net/swift/+bug/1521349\n'}]",19,281885,17a203fe35bb83a07605924a15033c45da423a83,30,7,5,7433,,,0,"a well-commented skeleton middleware

Change-Id: If49d3d3d8cfb1ac2b1f043f34dcf64eb9155a026
Closes-Bug: https://bugs.launchpad.net/swift/+bug/1521349
",git fetch https://review.opendev.org/openstack/swift refs/changes/85/281885/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/middleware/sample/__init__.py', 'doc/middleware/sample/middleware.py', 'doc/middleware/sample/webhook.py', 'doc/middleware/sample/simple.py', 'doc/middleware/README.md', 'doc/middleware/.gitignore', 'doc/middleware/setup.py']",7,363aca49e66cda4b7dbed614074a3d521e2d7e1a,sample_middleware,"# Copyright (c) 2010-2015 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from setuptools import setup, find_packages from sample import name, version setup( name=name, version=version, author=""your name here"", author_email=""your.name@example.com"", description=""Reference proxy middleware for OpenStack Swift"", keywords=""openstack swift middleware"", url=""http://github.com/openstack/swift/examples/middleware"", packages=find_packages(), classifiers=[ 'Development Status :: 3 - Alpha', 'Environment :: OpenStack', 'Intended Audience :: Information Technology', 'Intended Audience :: System Administrators', 'License :: OSI Approved :: Apache Software License', 'Operating System :: POSIX :: Linux', 'Programming Language :: Python', 'Programming Language :: Python :: 2', 'Programming Language :: Python :: 2.7', ], install_requires=[], entry_points={ 'paste.filter_factory': [ 'swift_simple_middleware=sample.simple:filter_factory', 'swift_webhook_middleware=sample.webhook:filter_factory', ], }, ) ",,532,0
openstack%2Frally~master~Ic940bae91c3d61c83a5a40da0e7a5d2288ed0de3,openstack/rally,master,Ic940bae91c3d61c83a5a40da0e7a5d2288ed0de3,Add Cinder create_and_update_snapshot scenario,NEW,2015-08-10 12:57:29.000000000,2017-12-18 05:16:26.000000000,,"[{'_account_id': 2353}, {'_account_id': 4428}, {'_account_id': 7369}, {'_account_id': 10185}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-08-10 12:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ad2f847b756d93966a096baf6d114ec13583c480', 'message': 'Add Cinder create_and_update_volume_snapshot scenario\n\nImplement create_and_update_volume_snapshot scenario for cinder.\nAdds supporting method \'_update_snapshot\' to\n""rally/plugins/openstack/scenarios/cinder/utils.py"".\n\nChange-Id: Ic940bae91c3d61c83a5a40da0e7a5d2288ed0de3\n'}, {'number': 2, 'created': '2015-08-12 06:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bc7654123102b2b73f6e9cd3d9f6a3c269a32d78', 'message': 'Add Cinder create_and_update_volume_snapshot scenario\n\nImplement create_and_update_volume_snapshot scenario for cinder.\nAdds supporting method \'_update_snapshot\' to\n""rally/plugins/openstack/scenarios/cinder/utils.py"".\n\nChange-Id: Ic940bae91c3d61c83a5a40da0e7a5d2288ed0de3\n'}, {'number': 3, 'created': '2015-08-12 09:59:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9e2d18ff0c02f4b4d0866ead31762e881cd66876', 'message': 'Add Cinder create_and_update_snapshot scenario\n\nImplement create_and_update_snapshot scenario for cinder.\nAdds supporting method \'_update_snapshot\' to\n""rally/plugins/openstack/scenarios/cinder/utils.py"".\n\nChange-Id: Ic940bae91c3d61c83a5a40da0e7a5d2288ed0de3\n'}, {'number': 4, 'created': '2015-08-18 07:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c6da925f8e12f50b0d16a2c5ca8bf0768ff87956', 'message': 'Add Cinder create_and_update_snapshot scenario\n\nImplement create_and_update_snapshot scenario for cinder.\nAdds supporting method \'_update_snapshot\' to\n""rally/plugins/openstack/scenarios/cinder/utils.py"".\n\nChange-Id: Ic940bae91c3d61c83a5a40da0e7a5d2288ed0de3\n'}, {'number': 5, 'created': '2015-08-25 11:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1a8e6dfa117da400350adf02165759c9aef2281e', 'message': 'Add Cinder create_and_update_snapshot scenario\n\nImplement create_and_update_snapshot scenario for cinder.\nAdds supporting method \'_update_snapshot\' to\n""rally/plugins/openstack/scenarios/cinder/utils.py"".\n\nChange-Id: Ic940bae91c3d61c83a5a40da0e7a5d2288ed0de3\n'}, {'number': 6, 'created': '2015-08-26 04:50:04.000000000', 'files': ['samples/tasks/scenarios/cinder/create-and-update-snapshot.yaml', 'tests/unit/plugins/openstack/scenarios/cinder/test_volumes.py', 'rally/plugins/openstack/scenarios/cinder/utils.py', 'samples/tasks/scenarios/cinder/create-and-update-snapshot.json', 'rally-jobs/cinder.yaml', 'tests/unit/plugins/openstack/scenarios/cinder/test_utils.py', 'rally/plugins/openstack/scenarios/cinder/volumes.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/ff41d6669e892a550880aa3dc60463e14cf5dca8', 'message': 'Add Cinder create_and_update_snapshot scenario\n\nImplement create_and_update_snapshot scenario for cinder.\nAdds supporting method \'_update_snapshot\' to\n""rally/plugins/openstack/scenarios/cinder/utils.py"".\n\nChange-Id: Ic940bae91c3d61c83a5a40da0e7a5d2288ed0de3\n'}]",18,211132,ff41d6669e892a550880aa3dc60463e14cf5dca8,30,7,6,1687,,,0,"Add Cinder create_and_update_snapshot scenario

Implement create_and_update_snapshot scenario for cinder.
Adds supporting method '_update_snapshot' to
""rally/plugins/openstack/scenarios/cinder/utils.py"".

Change-Id: Ic940bae91c3d61c83a5a40da0e7a5d2288ed0de3
",git fetch https://review.opendev.org/openstack/rally refs/changes/32/211132/1 && git format-patch -1 --stdout FETCH_HEAD,"['samples/tasks/scenarios/cinder/create-and-update-snapshot.yaml', 'tests/unit/plugins/openstack/scenarios/cinder/test_volumes.py', 'rally/plugins/openstack/scenarios/cinder/utils.py', 'samples/tasks/scenarios/cinder/create-and-update-snapshot.json', 'tests/unit/plugins/openstack/scenarios/cinder/test_utils.py', 'rally/plugins/openstack/scenarios/cinder/volumes.py']",6,ad2f847b756d93966a096baf6d114ec13583c480,create-and-update-volume-snapshot," @validation.required_services(consts.Service.CINDER) @validation.required_contexts(""volumes"") @validation.required_openstack(users=True) @base.scenario(context={""cleanup"": [""cinder""]}) def create_and_update_snapshot(self, force=False, create_snapshot_kwargs=None, update_snapshot_kwargs=None): """"""Create and then update a volume-snapshot. :param force: when set to True, allows snapshot of a volume when the volume is attached to an instance :param create_snapshot_kwargs: dict, to be used to create snapshot :param update_snapshot_kwargs: dict, to be used to update snapshot """""" volume = random.choice(self.context[""tenant""][""volumes""]) create_snapshot_kwargs = create_snapshot_kwargs or {} update_snapshot_kwargs = update_snapshot_kwargs or {} snapshot = self._create_snapshot(volume[""id""], force=force, **create_snapshot_kwargs) self._update_snapshot(snapshot, **update_snapshot_kwargs) ",,110,0
openstack%2Fopenstack-health~master~I6530c04769204bfbfa880164e885fb2fddf1c7ba,openstack/openstack-health,master,I6530c04769204bfbfa880164e885fb2fddf1c7ba,Use Flask-SQLAlchemy for db scoped session,NEW,2016-03-31 07:55:21.000000000,2017-12-18 05:16:14.000000000,,[{'_account_id': 5689}],"[{'number': 1, 'created': '2016-03-31 07:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/3956ea4757eb67bb09bf448a97a5e6e04d9c2633', 'message': '[WIP] Use FlaskSQLAlchemy for db session\n\nDO NOT MERGE. Just dump currently.\nThis commit make api use FlaskSQLAlchemy for a db session. This Flask\nexternal library seems like useful for session management.\n\nChange-Id: I6530c04769204bfbfa880164e885fb2fddf1c7ba\n'}, {'number': 2, 'created': '2016-04-01 08:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/795e6837ddee697e3a9c495dd4498ff7cbed5788', 'message': ""Use Flask-SQLAlchemy for db scoped session\n\nThis commit changes to use Flask-SQLAlchemy for db sessions. This\nlibrary is designed to support for the SQLAlchemy and it's easy to\nmanage session scope for a application with this.\n\nChange-Id: I6530c04769204bfbfa880164e885fb2fddf1c7ba\n""}, {'number': 3, 'created': '2016-04-07 02:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/75a6492365c96c77610babe053426e6f4275df11', 'message': ""Use Flask-SQLAlchemy for db scoped session\n\nThis commit changes to use Flask-SQLAlchemy for db sessions. This\nlibrary is designed to support for the SQLAlchemy and it's easy to\nmanage session scope for a application with this.\n\nChange-Id: I6530c04769204bfbfa880164e885fb2fddf1c7ba\n""}, {'number': 4, 'created': '2016-04-07 02:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/93f588e023b01711950eb35bb8b03229178e7058', 'message': ""Use Flask-SQLAlchemy for db scoped session\n\nThis commit changes to use Flask-SQLAlchemy for db sessions. This\nlibrary is designed to support for the SQLAlchemy and it's easy to\nmanage session scope for a application with this.\n\nChange-Id: I6530c04769204bfbfa880164e885fb2fddf1c7ba\n""}, {'number': 5, 'created': '2016-04-21 04:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/1c40d81b3dd49dbd052a2afb9cbeb26e73258f13', 'message': ""Use Flask-SQLAlchemy for db scoped session\n\nThis commit changes to use Flask-SQLAlchemy for db sessions. This\nlibrary is designed to support for the SQLAlchemy and it's easy to\nmanage session scope for a application with this.\n\nChange-Id: I6530c04769204bfbfa880164e885fb2fddf1c7ba\n""}, {'number': 6, 'created': '2016-04-22 02:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/73bb0cc342bf9ca88c54e612140773db4ed2c557', 'message': ""Use Flask-SQLAlchemy for db scoped session\n\nThis commit changes to use Flask-SQLAlchemy for db sessions. This\nlibrary is designed to support for the SQLAlchemy and it's easy to\nmanage session scope for a application with this.\n\nChange-Id: I6530c04769204bfbfa880164e885fb2fddf1c7ba\n""}, {'number': 7, 'created': '2016-04-22 05:19:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/f2bdae5a1ceb675335ad2e7e48a959f413e651af', 'message': ""Use Flask-SQLAlchemy for db scoped session\n\nThis commit changes to use Flask-SQLAlchemy for db sessions. This\nlibrary is designed to support for the SQLAlchemy and it's easy to\nmanage session scope for a application with this.\n\nChange-Id: I6530c04769204bfbfa880164e885fb2fddf1c7ba\n""}, {'number': 8, 'created': '2016-04-23 02:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/5370048028a23406476bc27d57fcad45b6a493ba', 'message': ""Use Flask-SQLAlchemy for db scoped session\n\nThis commit changes to use Flask-SQLAlchemy for db sessions. This\nlibrary is designed to support for the SQLAlchemy and it's easy to\nmanage session scope for a application with this.\n\nChange-Id: I6530c04769204bfbfa880164e885fb2fddf1c7ba\n""}, {'number': 9, 'created': '2016-04-23 02:42:59.000000000', 'files': ['openstack_health/tests/test_api.py', 'requirements.txt', 'openstack_health/api.py'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/806d10039741a7552875095077c23c2a9e504aff', 'message': ""Use Flask-SQLAlchemy for db scoped session\n\nThis commit changes to use Flask-SQLAlchemy for db sessions. This\nlibrary is designed to support for the SQLAlchemy and it's easy to\nmanage session scope for a application with this.\n\nChange-Id: I6530c04769204bfbfa880164e885fb2fddf1c7ba\n""}]",0,299797,806d10039741a7552875095077c23c2a9e504aff,25,1,9,5689,,,0,"Use Flask-SQLAlchemy for db scoped session

This commit changes to use Flask-SQLAlchemy for db sessions. This
library is designed to support for the SQLAlchemy and it's easy to
manage session scope for a application with this.

Change-Id: I6530c04769204bfbfa880164e885fb2fddf1c7ba
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/97/299797/7 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'openstack_health/api.py']",2,3956ea4757eb67bb09bf448a97a5e6e04d9c2633,(HEAD,"import flask_sqlalchemyapp.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = Falsesession = None db = flask_sqlalchemy.SQLAlchemy() db.init_app(app) app.config['SQLALCHEMY_DATABASE_URI'] = db_uri app.config['SQLALCHEMY_POOL_SIZE'] = pool_size app.config['SQLALCHEMY_POOL_RECYCLE'] = pool_recycle global session session = db.session db_runs = api.get_runs_by_key_value('build_name', build_name, session) runs = [run.to_dict() for run in db_runs] return jsonify({'runs': runs}) existing_keys = set(api.get_all_run_metadata_keys(session)) allowed_keys = existing_keys.difference(ignored_keys) return jsonify(list(allowed_keys)) sec_runs = api.get_all_runs_time_series_by_key(key, start_date, stop_date, session) if datetime_resolution not in ['sec', 'min', 'hour', 'day']: return ('Datetime resolution: %s, is not a valid' ' choice' % datetime_resolution), 400 runs = RunAggregator(sec_runs).aggregate(datetime_resolution) return jsonify({'runs': runs}) tests = api.get_test_run_dict_by_run_meta_key_value(key, value, start_date, stop_date, session) tests = test_run_aggregator.TestRunAggregator(tests).aggregate( datetime_resolution=datetime_resolution) return jsonify({'tests': tests}) db_runs = api.get_all_runs_by_date(start_date, stop_date, session) runs = [run.to_dict() for run in db_runs] return jsonify({'runs': runs}) runs = (api.get_time_series_runs_by_key_value(run_metadata_key, value, start_date, stop_date, session)) # Groups runs by metadata group_by = ""build_name"" runs_by_build_name = _group_runs_by_key(runs, group_by) # Group runs by the chosen data_range. # That does not apply when you choose 'sec' since runs are already # grouped by it. aggregated_runs = \ RunAggregator(runs_by_build_name).aggregate(datetime_resolution) return jsonify(_aggregate_runs(aggregated_runs)) results = api.get_recent_runs_by_key_value_metadata( run_metadata_key, value, num_runs, session) runs = [] for result in results: if result.passes > 0 and result.fails == 0: status = 'success' elif result.fails > 0: status = 'fail' else: continue run = { 'id': result.uuid, 'status': status, 'start_date': result.run_at.isoformat(), 'link': result.artifacts, } run_meta = api.get_run_metadata(result.uuid, session) for meta in run_meta: if meta.key == 'build_name': run['build_name'] = meta.value break runs.append(run) return jsonify(runs) failed_runs = api.get_recent_failed_runs(num_runs, session) test_runs = api.get_test_runs_by_status_for_run_ids(status, failed_runs, session=session) output = [] for run in test_runs: run['start_time'] = run['start_time'].isoformat() run['stop_time'] = run['stop_time'].isoformat() output.append(run) return jsonify(output) db_tests = api.get_tests_from_run_id(run_id, session) tests = [test.to_dict() for test in db_tests] return jsonify({'tests': tests}) db_test_runs = api.get_tests_run_dicts_from_run_id(run_id, session) return jsonify(db_test_runs) db_tests = api.get_all_tests(session) tests = [test.to_dict() for test in db_tests] return jsonify({'tests': tests}) return jsonify(api.get_test_prefixes(session)) db_tests = api.get_tests_by_prefix(prefix, session, limit=limit, offset=offset) tests = [test.to_dict() for test in db_tests] return jsonify({'tests': tests}) db_test_runs = api.get_test_runs_by_test_test_id(test_id, session=session, start_date=start_date, stop_date=stop_date) if not db_test_runs: # NOTE(mtreinish) if no data is returned from the DB just return an # empty set response, the test_run_aggregator function assumes data # is present. return jsonify({'numeric': {}, 'data': {}}) test_runs =\ test_run_aggregator.convert_test_runs_list_to_time_series_dict( db_test_runs, datetime_resolution) return jsonify(test_runs)","from contextlib import contextmanagerfrom sqlalchemy import create_engine from sqlalchemy.orm import sessionmaker engine = create_engine(db_uri, pool_size=pool_size, pool_recycle=pool_recycle) global Session Session = sessionmaker(bind=engine) def get_session(): global Session if not Session: setup() return Session() @contextmanager def session_scope(): try: session = get_session() yield session session.commit() except Exception: session.rollback() raise finally: session.close() with session_scope() as session: db_runs = api.get_runs_by_key_value('build_name', build_name, session) runs = [run.to_dict() for run in db_runs] return jsonify({'runs': runs}) with session_scope() as session: existing_keys = set(api.get_all_run_metadata_keys(session)) allowed_keys = existing_keys.difference(ignored_keys) return jsonify(list(allowed_keys)) with session_scope() as session: sec_runs = api.get_all_runs_time_series_by_key(key, start_date, stop_date, session) if datetime_resolution not in ['sec', 'min', 'hour', 'day']: return ('Datetime resolution: %s, is not a valid' ' choice' % datetime_resolution), 400 runs = RunAggregator(sec_runs).aggregate(datetime_resolution) return jsonify({'runs': runs}) with session_scope() as session: tests = api.get_test_run_dict_by_run_meta_key_value(key, value, start_date, stop_date, session) tests = test_run_aggregator.TestRunAggregator(tests).aggregate( datetime_resolution=datetime_resolution) return jsonify({'tests': tests}) with session_scope() as session: db_runs = api.get_all_runs_by_date(start_date, stop_date, session) runs = [run.to_dict() for run in db_runs] return jsonify({'runs': runs}) with session_scope() as session: runs = (api.get_time_series_runs_by_key_value(run_metadata_key, value, start_date, stop_date, session)) # Groups runs by metadata group_by = ""build_name"" runs_by_build_name = _group_runs_by_key(runs, group_by) # Group runs by the chosen data_range. # That does not apply when you choose 'sec' since runs are already # grouped by it. aggregated_runs = \ RunAggregator(runs_by_build_name).aggregate(datetime_resolution) return jsonify(_aggregate_runs(aggregated_runs)) with session_scope() as session: results = api.get_recent_runs_by_key_value_metadata( run_metadata_key, value, num_runs, session) runs = [] for result in results: if result.passes > 0 and result.fails == 0: status = 'success' elif result.fails > 0: status = 'fail' else: continue run = { 'id': result.uuid, 'status': status, 'start_date': result.run_at.isoformat(), 'link': result.artifacts, } run_meta = api.get_run_metadata(result.uuid, session) for meta in run_meta: if meta.key == 'build_name': run['build_name'] = meta.value break runs.append(run) return jsonify(runs) with session_scope() as session: failed_runs = api.get_recent_failed_runs(num_runs, session) test_runs = api.get_test_runs_by_status_for_run_ids(status, failed_runs, session=session) output = [] for run in test_runs: run['start_time'] = run['start_time'].isoformat() run['stop_time'] = run['stop_time'].isoformat() output.append(run) return jsonify(output) with session_scope() as session: db_tests = api.get_tests_from_run_id(run_id, session) tests = [test.to_dict() for test in db_tests] return jsonify({'tests': tests}) with session_scope() as session: db_test_runs = api.get_tests_run_dicts_from_run_id(run_id, session) return jsonify(db_test_runs) with session_scope() as session: db_tests = api.get_all_tests(session) tests = [test.to_dict() for test in db_tests] return jsonify({'tests': tests}) with session_scope() as session: return jsonify(api.get_test_prefixes(session)) with session_scope() as session: db_tests = api.get_tests_by_prefix(prefix, session, limit=limit, offset=offset) tests = [test.to_dict() for test in db_tests] return jsonify({'tests': tests}) with session_scope() as session: db_test_runs = api.get_test_runs_by_test_test_id(test_id, session=session, start_date=start_date, stop_date=stop_date) if not db_test_runs: # NOTE(mtreinish) if no data is returned from the DB just return an # empty set response, the test_run_aggregator function assumes data # is present. return jsonify({'numeric': {}, 'data': {}}) test_runs =\ test_run_aggregator.convert_test_runs_list_to_time_series_dict( db_test_runs, datetime_resolution) return jsonify(test_runs)",106,137
openstack%2Frally~master~I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619,openstack/rally,master,I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619,Allow static fip in VMTasks.boot_runcommand_delete,NEW,2016-01-23 13:38:52.000000000,2017-12-18 05:16:03.000000000,,"[{'_account_id': 4428}, {'_account_id': 6172}, {'_account_id': 6835}, {'_account_id': 7369}, {'_account_id': 8491}, {'_account_id': 10475}, {'_account_id': 11748}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 15371}]","[{'number': 1, 'created': '2016-01-23 13:38:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/498e00dac9b8859244b83d34426d259f095a1424', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address to allow defining a static\nfloatingip address to be created from the given floating_network,\nduring the scenario run.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 2, 'created': '2016-01-25 08:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/fb41d4d21743d4b904a411a43ffa6e9cf58cb84d', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address to allow defining a static\nfloatingip address to be created from the given floating_network,\nduring the scenario run.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 3, 'created': '2016-01-25 09:59:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/aaf583051b07ca233b46aa0d2c95f12606f4544a', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address to allow defining a static\nfloatingip address to be created from the given floating_network,\nduring the scenario run.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 4, 'created': '2016-01-25 12:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/77a41b44ff73ee74c4bd4448911799925dfb87ad', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address to allow defining a static\nfloatingip address to be created from the given floating_network,\nduring the scenario run.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 5, 'created': '2016-01-25 12:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bed90a2ca4c1b44f851aaf81ca11f8ae97154a28', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address to allow defining a static\nfloatingip address to be created from the given floating_network,\nduring the scenario run.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 6, 'created': '2016-01-26 10:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f92499ac9b9f0507d9427fa7af7aa6215bd7da7e', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address to allow defining a static\nfloatingip address to be created from the given floating_network,\nduring the scenario run.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 7, 'created': '2016-01-26 12:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/722dcb64565f3839dea776b8d5883124daf6d960', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address to allow defining a static\nfloatingip address to be created from the given floating_network,\nduring the scenario run.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 8, 'created': '2016-02-02 13:08:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e58643dc1c96f7c576a2c1225bb7d995a91bf37e', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address to allow defining a static\nfloatingip address to be created from the given floating_network,\nduring the scenario run.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 9, 'created': '2016-03-18 21:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/57ec76290ee80d10aef845567bf380ad6b2035fb', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address to allow defining a static\nfloatingip address to be created from the given floating_network,\nduring the scenario run.\nThis new option only works with neutron networks and does not work\nwhen concurrent or threaded runner configs are used.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 10, 'created': '2016-03-18 22:20:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c2fb7908689227439d290a310585b19834c71604', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address to allow defining a static\nfloatingip address to be created from the given floating_network,\nduring the scenario run.\nThis new option only works with neutron networks and does not work\nwhen concurrent or threaded runner configs are used.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 11, 'created': '2016-03-21 09:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c2a5a375cf1367443cd8e13f08e6c27a361feb82', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address to allow defining a static\nfloatingip address to be created from the given floating_network,\nduring the scenario run.\nThis new option only works with neutron networks and does not work\nwhen concurrent or threaded runner configs are used.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 12, 'created': '2016-03-21 17:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b1345bc56c4e378837bea13e9a2eb17b029710d8', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address_start to allow defining\na static floatingip address to be created from the given\nfloating_network, during the scenario run.\nLater the parameter is intended to be used as start address for\nan address range, which would allow concurrent runners as well.\nThis new option only works with neutron networks and does not work\nwhen concurrent or threaded runner configs are used.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 13, 'created': '2016-03-22 16:33:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a803a0ca8ad4c419e8a21b2e9f39b8ad27588c10', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address_start to allow defining\na static floatingip address to be created from the given\nfloating_network, during the scenario run.\nLater the parameter is intended to be used as start address for\nan address range, which would allow concurrent runners as well.\nThis new option only works with neutron networks and does not work\nwhen concurrent or threaded runner configs are used.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 14, 'created': '2016-03-30 11:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b2a91b4d60b7ff9ddf0abdef198075e8624741c6', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address_start to allow defining\na static floatingip address to be created from the given\nfloating_network, during the scenario run.\nLater the parameter is intended to be used as start address for\nan address range, which would allow concurrent runners as well.\nThis new option only works with neutron networks and does not work\nwhen concurrent or threaded runner configs are used.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 15, 'created': '2016-04-15 21:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6413d58a302588675cf35c72c67b551f728757ee', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address_start to allow defining\na static floatingip address to be created from the given\nfloating_network, during the scenario run.\nLater the parameter is intended to be used as start address for\nan address range, which would allow concurrent runners as well.\nThis new option only works with neutron networks and does not work\nwhen concurrent or threaded runner configs are used.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 16, 'created': '2016-04-20 19:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/97fd86a2c2dbdd4027949f7f28a444c88ccbd770', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address_start to allow defining\na static floatingip address to be created from the given\nfloating_network, during the scenario run.\nLater the parameter is intended to be used as start address for\nan address range, which would allow concurrent runners as well.\nThis new option only works with neutron networks and does not work\nwhen concurrent or threaded runner configs are used.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 17, 'created': '2016-04-21 06:34:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b33c11ed55efc53938094dafd4e494a353e851ed', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address_start to allow defining\na static floatingip address to be created from the given\nfloating_network, during the scenario run.\nLater the parameter is intended to be used as start address for\nan address range, which would allow concurrent runners as well.\nThis new option only works with neutron networks and does not work\nwhen concurrent or threaded runner configs are used.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}, {'number': 18, 'created': '2016-04-21 07:53:49.000000000', 'files': ['rally/plugins/openstack/scenarios/vm/vmtasks.py', 'samples/tasks/scenarios/vm/boot-runcommand-delete-with-static-fip.yaml', 'rally/task/validation.py', 'tests/unit/plugins/openstack/wrappers/test_network.py', 'tests/unit/plugins/openstack/scenarios/vm/test_utils.py', 'rally/plugins/openstack/wrappers/network.py', 'tests/unit/task/test_validation.py', 'rally-jobs/rally-neutron.yaml', 'tests/unit/plugins/openstack/scenarios/vm/test_vmtasks.py', 'samples/tasks/scenarios/vm/boot-runcommand-delete-with-static-fip.json', 'rally/plugins/openstack/scenarios/vm/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/6e2cb1648a4430a9e14d866454635e0104fdcf06', 'message': 'Allow static fip in VMTasks.boot_runcommand_delete\n\nAdded new parameter floating_ip_address_start to allow defining\na static floatingip address to be created from the given\nfloating_network, during the scenario run.\nLater the parameter is intended to be used as start address for\nan address range, which would allow concurrent runners as well.\nThis new option only works with neutron networks and does not work\nwhen concurrent or threaded runner configs are used.\n\nChange-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619\nCloses-Bug: 1537360\n'}]",74,271704,6e2cb1648a4430a9e14d866454635e0104fdcf06,104,10,18,15371,,,0,"Allow static fip in VMTasks.boot_runcommand_delete

Added new parameter floating_ip_address_start to allow defining
a static floatingip address to be created from the given
floating_network, during the scenario run.
Later the parameter is intended to be used as start address for
an address range, which would allow concurrent runners as well.
This new option only works with neutron networks and does not work
when concurrent or threaded runner configs are used.

Change-Id: I59c6fcc18ef5dd2bf5f45fa836a3b1a98ef17619
Closes-Bug: 1537360
",git fetch https://review.opendev.org/openstack/rally refs/changes/04/271704/18 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/scenarios/vm/vmtasks.py', 'tests/unit/plugins/openstack/wrappers/test_network.py', 'tests/unit/plugins/openstack/scenarios/vm/test_utils.py', 'rally/plugins/openstack/wrappers/network.py', 'tests/unit/plugins/openstack/scenarios/vm/test_vmtasks.py', 'rally/plugins/openstack/scenarios/vm/utils.py']",6,498e00dac9b8859244b83d34426d259f095a1424,bug/1537360," floating_network=None, floating_ip_address=None, **kwargs): fip = self._attach_floating_ip(server, floating_network, floating_ip_address) def _attach_floating_ip(self, server, floating_network, floating_ip_address): tenant_id=server.tenant_id, fixed_ip=fixed_ip, floating_ip_address=floating_ip_address)"," floating_network=None, **kwargs): fip = self._attach_floating_ip(server, floating_network) def _attach_floating_ip(self, server, floating_network): tenant_id=server.tenant_id, fixed_ip=fixed_ip)",31,12
openstack%2Fironic~master~Icb33fff3991263a09d9ed65aba6a553897da5ac9,openstack/ironic,master,Icb33fff3991263a09d9ed65aba6a553897da5ac9,[EXPERIMENTAL] Hardware alerts - DB,NEW,2016-04-12 16:25:56.000000000,2017-12-18 05:16:01.000000000,,"[{'_account_id': 10118}, {'_account_id': 17998}]","[{'number': 1, 'created': '2016-04-12 16:25:56.000000000', 'files': ['ironic/common/exception.py', 'ironic/db/sqlalchemy/alembic/versions/c2043dac9df3_add_alert_sources_table.py', 'ironic/db/sqlalchemy/api.py', 'ironic/db/sqlalchemy/models.py', 'ironic/db/api.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/7c7b136cc5083fa4ee7635eff38704d471c3de5a', 'message': '[EXPERIMENTAL] Hardware alerts - DB\n\nRelated-bug: #1569439\n\nChange-Id: Icb33fff3991263a09d9ed65aba6a553897da5ac9\n'}]",0,304756,7c7b136cc5083fa4ee7635eff38704d471c3de5a,6,2,1,7711,,,0,"[EXPERIMENTAL] Hardware alerts - DB

Related-bug: #1569439

Change-Id: Icb33fff3991263a09d9ed65aba6a553897da5ac9
",git fetch https://review.opendev.org/openstack/ironic refs/changes/56/304756/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/exception.py', 'ironic/db/sqlalchemy/alembic/versions/c2043dac9df3_add_alert_sources_table.py', 'ironic/db/sqlalchemy/api.py', 'ironic/db/sqlalchemy/models.py', 'ironic/db/api.py']",5,7c7b136cc5083fa4ee7635eff38704d471c3de5a,alerts-api," @abc.abstractmethod def get_alert_source_by_id(self, alert_source_id): """"""Return an alert source."""""" @abc.abstractmethod def get_alert_source_by_uuid(self, platform_uuid): """"""Return an alert source."""""" @abc.abstractmethod def get_alert_source_list(self, limit=None, marker=None, sort_key=None, sort_dir=None): """"""Return a list of alert sources. """""" @abc.abstractmethod def create_alert_source(self, values): """"""Create a new alert source."""""" @abc.abstractmethod def destroy_alert_source(self, alert_source_id): """"""Destroy an alert source. """"""",,137,0
openstack%2Fironic~master~Iacbb9e4ce048e8a3e54151790090b9f7e2f86357,openstack/ironic,master,Iacbb9e4ce048e8a3e54151790090b9f7e2f86357,[EXPERIMENTAL] Hardware alerts - obj,NEW,2016-04-12 16:25:56.000000000,2017-12-18 05:15:58.000000000,,"[{'_account_id': 10118}, {'_account_id': 17998}]","[{'number': 1, 'created': '2016-04-12 16:25:56.000000000', 'files': ['ironic/objects/alert_source.py', 'ironic/tests/unit/objects/test_objects.py', 'ironic/objects/__init__.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/9cdbb1dc893aa5936231d2343e0e27c950c85209', 'message': '[EXPERIMENTAL] Hardware alerts - obj\n\nRelated-bug: #1569439\n\nChange-Id: Iacbb9e4ce048e8a3e54151790090b9f7e2f86357\n'}]",0,304757,9cdbb1dc893aa5936231d2343e0e27c950c85209,6,2,1,7711,,,0,"[EXPERIMENTAL] Hardware alerts - obj

Related-bug: #1569439

Change-Id: Iacbb9e4ce048e8a3e54151790090b9f7e2f86357
",git fetch https://review.opendev.org/openstack/ironic refs/changes/57/304757/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/objects/alert_source.py', 'ironic/tests/unit/objects/test_objects.py', 'ironic/objects/__init__.py']",3,9cdbb1dc893aa5936231d2343e0e27c950c85209,alerts-api, __import__('ironic.objects.alert_source'),,118,1
openstack%2Fironic~master~I672de41dac938a380a738457cef8701a72679c5b,openstack/ironic,master,I672de41dac938a380a738457cef8701a72679c5b,[EXPERIMENTAL] Hardware alerts - API,NEW,2016-04-12 16:25:56.000000000,2017-12-18 05:15:56.000000000,,"[{'_account_id': 10118}, {'_account_id': 17998}]","[{'number': 1, 'created': '2016-04-12 16:25:56.000000000', 'files': ['ironic/api/controllers/v1/__init__.py', 'ironic/api/controllers/v1/alert_source.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e07003d8ef5ee3eef648b15d459c2146928d5dd1', 'message': '[EXPERIMENTAL] Hardware alerts - API\n\nRelated-bug: #1569439\n\nChange-Id: I672de41dac938a380a738457cef8701a72679c5b\n'}]",0,304758,e07003d8ef5ee3eef648b15d459c2146928d5dd1,6,2,1,7711,,,0,"[EXPERIMENTAL] Hardware alerts - API

Related-bug: #1569439

Change-Id: I672de41dac938a380a738457cef8701a72679c5b
",git fetch https://review.opendev.org/openstack/ironic refs/changes/58/304758/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/__init__.py', 'ironic/api/controllers/v1/alert_source.py']",2,e07003d8ef5ee3eef648b15d459c2146928d5dd1,alerts-api,"# All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import datetime import pecan from pecan import rest from six.moves import http_client import wsme from wsme import types as wtypes from ironic.api.controllers import base from ironic.api.controllers import link from ironic.api.controllers.v1 import collection from ironic.api.controllers.v1 import types from ironic.api.controllers.v1 import utils as api_utils from ironic.api import expose from ironic import objects class AlertSource(base.APIBase): """"""API representation of alert source."""""" platform_uuid = wsme.wsattr(types.uuid, mandatory=True) """"""The UUID of the platform"""""" source_type = wsme.wsattr(wtypes.Enum(wtypes.text, 'node', 'chassis'), mandatory=True) """"""Type of source"""""" source_uuid = wsme.wsattr(types.uuid, mandatory=True) """"""Source UUID from Ironic"""""" links = wsme.wsattr([link.Link], readonly=True) """"""A list containing a self link and associated chassis links"""""" def __init__(self, **kwargs): self.fields = [] for field in objects.AlertSource.fields: # Skip fields we do not expose. if not hasattr(self, field): continue self.fields.append(field) setattr(self, field, kwargs.get(field, wtypes.Unset)) @staticmethod def convert_with_links(rpc_alert): alert = AlertSource(**rpc_alert.as_dict()) platform_uuid = alert.platform_uuid alert.links = [ link.Link.make_link('self', pecan.request.public_url, 'alert_sources', platform_uuid), link.Link.make_link('bookmark', pecan.request.public_url, 'alert_sources', platform_uuid, bookmark=True) ] return alert @classmethod def sample(cls): time = datetime.datetime(2000, 1, 1, 12, 0, 0) platform_uuid = '1e627a77-9b78-409f-b4a0-b3287f5e66a0' source_type = 'node' source_uuid = '89340349-013b-4504-aa00-d3556ddbad64' sample = cls(platform_uuid=platform_uuid, source_type=source_type, source_uuid=source_uuid, created_at=time, updated_at=time) return sample class AlertSourceCollection(collection.Collection): """"""API representation of a collection of alert sources."""""" alert_sources = [AlertSource] """"""A list containing alert sources objects"""""" def __init__(self, **kwargs): self._type = 'alert_sources' @staticmethod def convert_with_links(alert_sources, limit, **kwargs): collection = AlertSourceCollection() collection.alert_sources = [AlertSource.convert_with_links(al) for al in alert_sources] collection.next = collection.get_next(limit, url=None, **kwargs) return collection @classmethod def sample(cls): sample = cls() sample.alert_sources = [AlertSource.sample()] return sample class AlertSourcesController(rest.RestController): """"""REST controller for AlertSource."""""" def _get_alert_source_collection(self, marker, limit, sort_key, sort_dir): context = pecan.request.context limit = api_utils.validate_limit(limit) sort_dir = api_utils.validate_sort_dir(sort_dir) marker_obj = None if marker: marker_obj = objects.AlertSource.get_by_platform_uuid(context, marker) alerts = objects.AlertSource.list(context, limit, marker_obj, sort_key=sort_key, sort_dir=sort_dir) return AlertSourceCollection.convert_with_links(alerts, limit, sort_key=sort_key, sort_dir=sort_dir) @expose.expose(AlertSourceCollection, types.uuid, int, wtypes.text, wtypes.text) def get_all(self, marker=None, limit=None, sort_key='id', sort_dir='asc'): """"""Retrieve a list of alert sources."""""" return self._get_alert_source_collection(marker, limit, sort_key, sort_dir) @expose.expose(AlertSource, types.uuid, types.listtype) def get_one(self, platform_uuid, fields=None): """"""Retrieve information about the given alert source."""""" context = pecan.request.context rpc_alert = objects.AlertSource.get_by_platform_uuid(context, platform_uuid) return AlertSource.convert_with_links(rpc_alert) @expose.expose(AlertSource, body=AlertSource, status_code=http_client.CREATED) def post(self, alert_source): """"""Create a new alert source."""""" new_alert = objects.AlertSource(pecan.request.context, **alert_source.as_dict()) new_alert.create() # Set the HTTP Location Header pecan.response.location = link.build_url('alert_source', new_alert.platform_uuid) return AlertSource.convert_with_links(new_alert) @expose.expose(None, types.uuid, status_code=http_client.NO_CONTENT) def delete(self, platform_uuid): """"""Delete a alert source."""""" context = pecan.request.context rpc_alert = objects.AlertSource.get_by_platform_uuid(context, platform_uuid) rpc_alert.destroy() ",,160,0
openstack%2Frally~master~Idfbb0ce896a1cd33fa3fbfc929f7804e29f488a5,openstack/rally,master,Idfbb0ce896a1cd33fa3fbfc929f7804e29f488a5,Add flavor-delete API benchmark,NEW,2016-05-13 21:26:39.000000000,2017-12-18 05:15:18.000000000,,"[{'_account_id': 9545}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 20196}, {'_account_id': 21528}]","[{'number': 1, 'created': '2016-05-13 21:26:39.000000000', 'files': ['samples/tasks/scenarios/nova/create-and-delete-flavor.yaml', 'rally/plugins/openstack/scenarios/nova/utils.py', 'tests/unit/plugins/openstack/scenarios/nova/test_flavors.py', 'samples/tasks/scenarios/nova/create-and-delete-flavor.json', 'rally/plugins/openstack/scenarios/nova/flavors.py', 'rally-jobs/nova.yaml', 'tests/unit/plugins/openstack/scenarios/nova/test_utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/12d3bfa5b79d3b7865eadc139813ce752a2e3250', 'message': 'Add flavor-delete API benchmark\n\nBenchmark flavor delete API using create-and-delete-flavor\nNova scenario\n\nblueprint extend-api-benchmark-in-nova-scenarios\n\nChange-Id: Idfbb0ce896a1cd33fa3fbfc929f7804e29f488a5\n'}]",4,316292,12d3bfa5b79d3b7865eadc139813ce752a2e3250,10,5,1,20196,,,0,"Add flavor-delete API benchmark

Benchmark flavor delete API using create-and-delete-flavor
Nova scenario

blueprint extend-api-benchmark-in-nova-scenarios

Change-Id: Idfbb0ce896a1cd33fa3fbfc929f7804e29f488a5
",git fetch https://review.opendev.org/openstack/rally refs/changes/92/316292/1 && git format-patch -1 --stdout FETCH_HEAD,"['samples/tasks/scenarios/nova/create-and-delete-flavor.yaml', 'rally/plugins/openstack/scenarios/nova/utils.py', 'tests/unit/plugins/openstack/scenarios/nova/test_flavors.py', 'samples/tasks/scenarios/nova/create-and-delete-flavor.json', 'rally/plugins/openstack/scenarios/nova/flavors.py', 'rally-jobs/nova.yaml', 'tests/unit/plugins/openstack/scenarios/nova/test_utils.py']",7,12d3bfa5b79d3b7865eadc139813ce752a2e3250,bp/extend-api-benchmark-in-nova-scenarios," def test__delete_flavor(self): nova_scenario = utils.NovaScenario() result = nova_scenario._delete_flavor(""fake_flavor"") self.assertEqual( self.admin_clients(""nova"").flavors.delete.return_value, result) self.admin_clients(""nova"").flavors.delete.assert_called_once_with( ""fake_flavor"") self._test_atomic_action_timer(nova_scenario.atomic_actions(), ""nova.delete_flavor"")",,85,0
openstack%2Fswift~master~I2762cd739c00adff0c91d07124f07fffb7b7a6e3,openstack/swift,master,I2762cd739c00adff0c91d07124f07fffb7b7a6e3,In case the lenght of the data returned by the object service is not equal to required content length then raise exception so that client can close connection from its end. Fixes Bug 1568650,NEW,2016-06-01 09:33:50.000000000,2017-12-18 05:15:03.000000000,,"[{'_account_id': 1179}, {'_account_id': 12261}, {'_account_id': 12532}]","[{'number': 1, 'created': '2016-06-01 09:33:50.000000000', 'files': ['swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/a3388bffe373cefe3c56ac7013e70317d31dcdc7', 'message': 'In case the lenght of the data returned by the object service is not equal to required content length\nthen raise exception so that client can close connection from its end.\nFixes Bug 1568650\n\nChange-Id: I2762cd739c00adff0c91d07124f07fffb7b7a6e3\n'}]",2,323756,a3388bffe373cefe3c56ac7013e70317d31dcdc7,7,3,1,12532,,,0,"In case the lenght of the data returned by the object service is not equal to required content length
then raise exception so that client can close connection from its end.
Fixes Bug 1568650

Change-Id: I2762cd739c00adff0c91d07124f07fffb7b7a6e3
",git fetch https://review.opendev.org/openstack/swift refs/changes/56/323756/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/proxy/controllers/base.py'],1,a3388bffe373cefe3c56ac7013e70317d31dcdc7,bug/1568650," content_length = source[0].length or 0 # fix for 1568650: in case object service crashes in middle of GET operation (during body transfer) # client connection hangs. We here check that in case complete body length data is not transfered, we will raise # exception, so that client can exit gracefully with Internal Server Error. if (content_length - buf) > 0: self.app.logger.error(_('Incomplete bytes recieved from the source')) raise",,7,0
openstack%2Fopenstack-health~master~I449a44ed4e8ffc83eb88bd1adb67378e956258c6,openstack/openstack-health,master,I449a44ed4e8ffc83eb88bd1adb67378e956258c6,Add cache info to status response,NEW,2016-06-06 04:40:03.000000000,2017-12-18 05:14:12.000000000,,[{'_account_id': 5196}],"[{'number': 1, 'created': '2016-06-06 04:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/c5cbc53e0d5ee8613a61643b02c45ce16a2e1c28', 'message': 'Add cache info to status response\n\nThis commit adds some basic cache configuration information to the\nstatus page. This lets us verify how we configured the caching from\nthe api page.\n\nChange-Id: I449a44ed4e8ffc83eb88bd1adb67378e956258c6\n'}, {'number': 2, 'created': '2016-06-07 15:38:41.000000000', 'files': ['openstack_health/api.py'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/7c82ac394900aed5e802fa78528eedfda82de988', 'message': 'Add cache info to status response\n\nThis commit adds some basic cache configuration information to the\nstatus page. This lets us verify how we configured the caching from\nthe api page.\n\nChange-Id: I449a44ed4e8ffc83eb88bd1adb67378e956258c6\n'}]",0,325716,7c82ac394900aed5e802fa78528eedfda82de988,7,1,2,5196,,,0,"Add cache info to status response

This commit adds some basic cache configuration information to the
status page. This lets us verify how we configured the caching from
the api page.

Change-Id: I449a44ed4e8ffc83eb88bd1adb67378e956258c6
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/16/325716/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_health/api.py'],1,c5cbc53e0d5ee8613a61643b02c45ce16a2e1c28,325716," global backend global expire global cache_urldef get_recent_test_status(status): num_runs = flask.request.args.get('num_runs', 10) return jsonify(results)def _check_cache_info(): global backend out_backend = backend if backend == 'dogpile.cache.dbm': global cache_url if cache_url: out_backend = ('openstack_health.distributed_dbm.' 'MemcachedLockedDBMProxy') else: out_backent = backend global expire if isinstance(expire, datetime.timedelta): expire_str = '%s secs.' % str(expire.total_seconds()) else: expire_str = '%s secs.' % str(expire) return {'backend': out_backend, 'expiration_time': expire_str} cache_info = _check_cache_info() 'elastic-recheck': is_er_available}, 'cache': cache_info }}","def get_recent_test_status(status, num_runs=None): try: num_runs = flask.request.args.get('num_runs', 10) except RuntimeError: num_runs = num_runs or 10 try: return jsonify(results) except RuntimeError: return results 'elastic-recheck': is_er_available }}}",27,11
openstack%2Fmonasca-agent~master~If99378b3b953b7c8f1c2f63e6d5037bb46dd22a5,openstack/monasca-agent,master,If99378b3b953b7c8f1c2f63e6d5037bb46dd22a5,Refactors the hypervisor checker,NEW,2016-05-19 11:16:16.000000000,2017-12-18 05:14:10.000000000,,"[{'_account_id': 2419}, {'_account_id': 8213}]","[{'number': 1, 'created': '2016-05-19 11:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/000ec37dccb7b5ea4b784b4c7125ee63ebe42301', 'message': 'Refactor _hypervisor checker\n\nThis patch simplifies the code present in the _hypervisor checker,\nby reducing the indentation of certain blocks and removing\nduplicate behaviour.\n\nChange-Id: If99378b3b953b7c8f1c2f63e6d5037bb46dd22a5\n'}, {'number': 2, 'created': '2016-05-30 22:31:38.000000000', 'files': ['monasca_agent/collector/checks_d/hypervisor.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/4cff3f3e1abd4892e08d55de4f379480d4ca8d5e', 'message': 'Refactors the hypervisor checker\n\nThis patch simplifies the code present in the hypervisor checker,\nby reducing the indentation of certain blocks and removing\nduplicate behaviour.\n\nAdds _get_client method.\n\nAvoids filtering out inactive ports multiple times.\nAvoids filtering out ports without a router interface multiple times.\n\nFilters out ports that do not have fixed IPv4 IPs, in order to\nsimplify logic.\n\nAvoids inspecting the instance CPUs multiple times.\n\nCreates the _inspect_memory method.\n\nRefactors _inspect_network and _inspect_disks, as they have\nduplcate code.\n\nCreates the _inspect_ping method.\n\nChange-Id: If99378b3b953b7c8f1c2f63e6d5037bb46dd22a5\n'}]",2,318574,4cff3f3e1abd4892e08d55de4f379480d4ca8d5e,7,2,2,8213,,,0,"Refactors the hypervisor checker

This patch simplifies the code present in the hypervisor checker,
by reducing the indentation of certain blocks and removing
duplicate behaviour.

Adds _get_client method.

Avoids filtering out inactive ports multiple times.
Avoids filtering out ports without a router interface multiple times.

Filters out ports that do not have fixed IPv4 IPs, in order to
simplify logic.

Avoids inspecting the instance CPUs multiple times.

Creates the _inspect_memory method.

Refactors _inspect_network and _inspect_disks, as they have
duplcate code.

Creates the _inspect_ping method.

Change-Id: If99378b3b953b7c8f1c2f63e6d5037bb46dd22a5
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/74/318574/2 && git format-patch -1 --stdout FETCH_HEAD,['monasca_agent/collector/checks_d/_hypervisor.py'],1,000ec37dccb7b5ea4b784b4c7125ee63ebe42301,,"from neutronclient.v2_0 import client as neutronclient from novaclient import client as novaclient def _get_client(self, client, **kwargs): return client.Client( username=self.init_config.get('admin_user'), password=self.init_config.get('admin_password'), tenant_name=self.init_config.get('admin_tenant_name'), auth_url=self.init_config.get('identity_uri'), endpoint_type='internalURL', **kwargs) nova_client = self._get_client( novaclient, service_type=""compute"", region_name=self.init_config.get('region_name')) nu = self._get_client(neutronclient) # filter out ports that are inactive, or without a proper device_owner, # they're not useful and there is no need to iterate over them. port_cache = [p for p in port_cache if p['status'] == 'ACTIVE' and p['device_owner'].startswith('network:router_interface')] # filter out ips that are not fixed or IPv4. ips = (ip for ip in instance.addresses[net] if ip['OS-EXT-IPS:type'] == 'fixed' and ip['version'] == 4) for ip in ips: subnet_id = None nsuuid = None for port in port_cache: if ((port['mac_address'] == ip['OS-EXT-IPS-MAC:mac_addr'] and port['tenant_id'] == instance.tenant_id)): for fixed in port['fixed_ips']: if fixed['ip_address'] == ip['addr']: subnet_id = fixed['subnet_id'] # Use the subnet_id to find the router ping_allowed = False if subnet_id is not None: for port in port_cache: if port['tenant_id'] == instance.tenant_id: nsuuid = port['device_id'] for fixed in port['fixed_ips']: if fixed['subnet_id'] == subnet_id: # Validate security group if self._validate_secgroup(secgroup_cache, instance, fixed['ip_address']): ping_allowed = True break if nsuuid is not None: break if nsuuid is not None and ping_allowed: if 'network' not in id_cache[inst_name]: id_cache[inst_name]['network'] = [] id_cache[inst_name]['network'].append({'namespace': ""qrouter-{0}"".format(nsuuid), 'ip': ip['addr']}) elif ping_allowed is False: self.log.debug(""ICMP disallowed for {0} on {1}"".format(inst_name, ip['addr'])) inspected_cpus = self.inspector.inspect_cpus(inst) cpu_diff = inspected_cpus.time - metric_cache[inst_name]['cpu.time']['value'] .format(inst_name, inspected_cpus.time, 'value': .time} self.gauge('vm.cpu.time_ms', inspected_cpus.time, 'value': inspected_cpus.time} def _inspect_memory(self, inst, instance_cache, dims_customer, dims_operations): # Memory utilizaion try: mem_metrics = {'mem.free_mb': float(inst.memoryStats()['unused']) / 1024, 'mem.swap_used_mb': float(inst.memoryStats()['swap_out']) / 1024, 'mem.total_mb': float(inst.memoryStats()['available'] - inst.memoryStats()['unused']) / 1024, 'mem.used_mb': float(inst.memoryStats()['available'] - inst.memoryStats()['unused']) / 1024, 'mem.free_perc': float(inst.memoryStats()['unused']) / float(inst.memoryStats()['available']) * 100} for name in mem_metrics: self.gauge(name, mem_metrics[name], dimensions=dims_customer, delegated_tenant=instance_cache.get(inst_name)['tenant_id'], hostname=instance_cache.get(inst_name)['hostname']) self.gauge(""vm.{0}"".format(name), mem_metrics[name], dimensions=dims_operations) except KeyError: self.log.debug(""Balloon driver not active/available on guest {0} ({1})"".format(inst_name, instance_cache.get(inst_name)['hostname'])) for vnic in self.inspector.inspect_vnics(inst): self._inspect_metric( inst, instance_cache, metric_cache, dims_customer, dims_operations, vnic[0].name, vnic[1], ""net.%s"", self._get_network_rate_name) def _get_network_rate_name(self, metric_name): # Change the metric name to a rate, ie. ""net.rx_bytes"" # gets converted to ""net.rx_bytes_sec"" rate_name = ""{0}_sec"".format(metric_name) # Rename ""tx"" to ""out"" and ""rx"" to ""in"" rate_name = rate_name.replace(""tx"", ""out"") rate_name = rate_name.replace(""rx"", ""in"") if self.init_config.get('network_use_bits'): val_diff = val_diff * 8 rate_name.replace(""bytes"", ""bits"") return rate_name for disk in self.inspector.inspect_disks(inst): self._inspect_metric( inst, instance_cache, metric_cache, dims_customer, dims_operations, disk[0].device, disk[1], ""io.%s"", self._get_disk_rate_name) def _get_disk_rate_name(self, rate_name): # Change the metric name to a rate, ie. ""io.read_requests"" # gets converted to ""io.read_ops_sec"" return ""{0}_sec"".format(metric_name.replace('requests', 'ops')) def _inspect_metric(self, inst, instance_cache, metric_cache, dims_customer, dims_operations, device_name, device, metric_name_format, get_rate_name): inst_name = inst.name() sample_time = time.time() dimensions = {'device': device_name} for metric in device._fields: metric_name = metric_name_format % metric if metric_name not in metric_cache[inst_name]: metric_cache[inst_name][metric_name] = {} value = int(device.__getattribute__(metric)) if device_name in metric_cache[inst_name][metric_name]: val_diff = value - metric_cache[inst_name][metric_name][device_name]['value'] if val_diff < 0: # Bad value, save current reading and skip self.log.warn(""Ignoring negative sample for: "" ""{0} new value: {1} old value: {2}"" .format(inst_name, value, metric_cache[inst_name][metric_name][device_name]['value'])) metric_cache[inst_name][metric_name][device_name] = { 'timestamp': sample_time, 'value': value} continue rate_name = get_rate_name(rate_name) # Customer this_dimensions = dimensions.copy() this_dimensions.update(dims_customer) self.gauge(rate_name, val_diff, dimensions=this_dimensions, delegated_tenant=instance_cache.get(inst_name)['tenant_id'], hostname=instance_cache.get(inst_name)['hostname']) # Operations (metric name prefixed with ""vm."" this_dimensions = dimensions.copy() this_dimensions.update(dims_operations) self.gauge(""vm.{0}"".format(rate_name), val_diff, dimensions=this_dimensions) # Save this metric to the cache metric_cache[inst_name][metric_name][device_name] = { 'timestamp': sample_time, 'value': value} def _inspect_ping(self, inst, instance_cache, dims_customer, dims_operations): inst_name = inst.name() # Test instance's remote responsiveness (ping check) if possible if not (self.init_config.get('ping_check') and 'network' in instance_cache.get(inst_name)): # don't check ping. return for net in instance_cache.get(inst_name)['network']: ping_cmd = self.init_config.get('ping_check').replace('NAMESPACE', net['namespace']).split() ping_cmd.append(net['ip']) dims_customer_ip = dims_customer.copy() dims_operations_ip = dims_operations.copy() dims_customer_ip['ip'] = net['ip'] dims_operations_ip['ip'] = net['ip'] with open(os.devnull, ""w"") as fnull: try: self.log.debug(""Running ping test: {0}"".format(' '.join(ping_cmd))) res = subprocess.call(ping_cmd, stdout=fnull, stderr=fnull) self.gauge('ping_status', res, dimensions=dims_customer_ip, self.gauge('vm.ping_status', res, dimensions=dims_operations_ip) except OSError as e: self.log.warn(""OS error running '{0}' returned {1}"".format(ping_cmd, e)) self._inspect_memory(inst, instance_cache, dims_customer, dims_operations) self._inspect_ping(inst, instance_cache, dims_customer, dims_operations)"," from novaclient import client nova_client = client.Client(2, self.init_config.get('admin_user'), self.init_config.get('admin_password'), self.init_config.get('admin_tenant_name'), self.init_config.get('identity_uri'), endpoint_type='internalURL', service_type=""compute"", region_name=self.init_config.get('region_name')) from neutronclient.v2_0 import client nu = client.Client(username=self.init_config.get('admin_user'), password=self.init_config.get('admin_password'), tenant_name=self.init_config.get('admin_tenant_name'), auth_url=self.init_config.get('identity_uri'), endpoint_type='internalURL') for ip in instance.addresses[net]: if ip['OS-EXT-IPS:type'] == 'fixed' and ip['version'] == 4: subnet_id = None nsuuid = None for port in port_cache: if ((port['mac_address'] == ip['OS-EXT-IPS-MAC:mac_addr'] and port['tenant_id'] == instance.tenant_id and port['status'] == 'ACTIVE')): for fixed in port['fixed_ips']: if fixed['ip_address'] == ip['addr']: subnet_id = fixed['subnet_id'] break # Use the subnet_id to find the router ping_allowed = False if subnet_id is not None: for port in port_cache: if ((port['device_owner'].startswith('network:router_interface') and port['tenant_id'] == instance.tenant_id and port['status'] == 'ACTIVE')): nsuuid = port['device_id'] for fixed in port['fixed_ips']: if fixed['subnet_id'] == subnet_id: # Validate security group if self._validate_secgroup(secgroup_cache, instance, fixed['ip_address']): ping_allowed = True break if nsuuid is not None: if nsuuid is not None and ping_allowed: if 'network' not in id_cache[inst_name]: id_cache[inst_name]['network'] = [] id_cache[inst_name]['network'].append({'namespace': ""qrouter-{0}"".format(nsuuid), 'ip': ip['addr']}) elif ping_allowed is False: self.log.debug(""ICMP disallowed for {0} on {1}"".format(inst_name, ip['addr'])) cpu_diff = self.inspector.inspect_cpus(inst).time - metric_cache[inst_name]['cpu.time']['value'] .format(inst_name, self.inspector.inspect_cpus(inst).time, 'value': self.inspector.inspect_cpus(inst).time} self.gauge('vm.cpu.time_ms', self.inspector.inspect_cpus(inst).time, 'value': self.inspector.inspect_cpus(inst).time} inst_name = inst.name() for vnic in self.inspector.inspect_vnics(inst): sample_time = time.time() vnic_dimensions = {'device': vnic[0].name} for metric in vnic[1]._fields: metric_name = ""net.{0}"".format(metric) if metric_name not in metric_cache[inst_name]: metric_cache[inst_name][metric_name] = {} value = int(vnic[1].__getattribute__(metric)) if vnic[0].name in metric_cache[inst_name][metric_name]: val_diff = value - metric_cache[inst_name][metric_name][vnic[0].name]['value'] if val_diff < 0: # Bad value, save current reading and skip self.log.warn(""Ignoring negative network sample for: "" ""{0} new value: {1} old value: {2}"" .format(inst_name, value, metric_cache[inst_name][metric_name][vnic[0].name]['value'])) metric_cache[inst_name][metric_name][vnic[0].name] = { 'timestamp': sample_time, 'value': value} continue # Change the metric name to a rate, ie. ""net.rx_bytes"" # gets converted to ""net.rx_bytes_sec"" rate_name = ""{0}_sec"".format(metric_name) # Rename ""tx"" to ""out"" and ""rx"" to ""in"" rate_name = rate_name.replace(""tx"", ""out"") rate_name = rate_name.replace(""rx"", ""in"") if self.init_config.get('network_use_bits'): val_diff = val_diff * 8 rate_name.replace(""bytes"", ""bits"") # Customer this_dimensions = vnic_dimensions.copy() this_dimensions.update(dims_customer) self.gauge(rate_name, val_diff, dimensions=this_dimensions, delegated_tenant=instance_cache.get(inst_name)['tenant_id'], hostname=instance_cache.get(inst_name)['hostname']) # Operations (metric name prefixed with ""vm."" this_dimensions = vnic_dimensions.copy() this_dimensions.update(dims_operations) self.gauge(""vm.{0}"".format(rate_name), val_diff, dimensions=this_dimensions) # Save this metric to the cache metric_cache[inst_name][metric_name][vnic[0].name] = { 'timestamp': sample_time, 'value': value} inst_name = inst.name() for disk in self.inspector.inspect_disks(inst): sample_time = time.time() disk_dimensions = {'device': disk[0].device} for metric in disk[1]._fields: metric_name = ""io.{0}"".format(metric) if metric_name not in metric_cache[inst_name]: metric_cache[inst_name][metric_name] = {} value = int(disk[1].__getattribute__(metric)) if disk[0].device in metric_cache[inst_name][metric_name]: val_diff = value - metric_cache[inst_name][metric_name][disk[0].device]['value'] if val_diff < 0: # Bad value, save current reading and skip self.log.warn(""Ignoring negative disk sample for: "" ""{0} new value: {1} old value: {2}"" .format(inst_name, value, metric_cache[inst_name][metric_name][disk[0].device]['value'])) metric_cache[inst_name][metric_name][disk[0].device] = { 'timestamp': sample_time, 'value': value} continue # Change the metric name to a rate, ie. ""io.read_requests"" # gets converted to ""io.read_ops_sec"" rate_name = ""{0}_sec"".format(metric_name.replace('requests', 'ops')) # Customer this_dimensions = disk_dimensions.copy() this_dimensions.update(dims_customer) self.gauge(rate_name, val_diff, dimensions=this_dimensions, # Operations (metric name prefixed with ""vm."" this_dimensions = disk_dimensions.copy() this_dimensions.update(dims_operations) self.gauge(""vm.{0}"".format(rate_name), val_diff, dimensions=this_dimensions) # Save this metric to the cache metric_cache[inst_name][metric_name][disk[0].device] = { 'timestamp': sample_time, 'value': value} # Memory utilizaion try: mem_metrics = {'mem.free_mb': float(inst.memoryStats()['unused']) / 1024, 'mem.swap_used_mb': float(inst.memoryStats()['swap_out']) / 1024, 'mem.total_mb': float(inst.memoryStats()['available'] - inst.memoryStats()['unused']) / 1024, 'mem.used_mb': float(inst.memoryStats()['available'] - inst.memoryStats()['unused']) / 1024, 'mem.free_perc': float(inst.memoryStats()['unused']) / float(inst.memoryStats()['available']) * 100} for name in mem_metrics: self.gauge(name, mem_metrics[name], dimensions=dims_customer, delegated_tenant=instance_cache.get(inst_name)['tenant_id'], hostname=instance_cache.get(inst_name)['hostname']) self.gauge(""vm.{0}"".format(name), mem_metrics[name], dimensions=dims_operations) except KeyError: self.log.debug(""Balloon driver not active/available on guest {0} ({1})"".format(inst_name, instance_cache.get(inst_name)['hostname'])) # Test instance's remote responsiveness (ping check) if possible if self.init_config.get('ping_check') and 'network' in instance_cache.get(inst_name): for net in instance_cache.get(inst_name)['network']: ping_cmd = self.init_config.get('ping_check').replace('NAMESPACE', net['namespace']).split() ping_cmd.append(net['ip']) dims_customer_ip = dims_customer.copy() dims_operations_ip = dims_operations.copy() dims_customer_ip['ip'] = net['ip'] dims_operations_ip['ip'] = net['ip'] with open(os.devnull, ""w"") as fnull: try: self.log.debug(""Running ping test: {0}"".format(' '.join(ping_cmd))) res = subprocess.call(ping_cmd, stdout=fnull, stderr=fnull) self.gauge('ping_status', res, dimensions=dims_customer_ip, delegated_tenant=instance_cache.get(inst_name)['tenant_id'], hostname=instance_cache.get(inst_name)['hostname']) self.gauge('vm.ping_status', res, dimensions=dims_operations_ip) except OSError as e: self.log.warn(""OS error running '{0}' returned {1}"".format(ping_cmd, e))",181,178
openstack%2Fmurano-specs~master~I5ed1971311f72351c32164ffc794ad8897075c8f,openstack/murano-specs,master,I5ed1971311f72351c32164ffc794ad8897075c8f,[WIP] Add spec for LbaaS Library,NEW,2016-05-04 16:13:27.000000000,2017-12-18 05:14:03.000000000,,"[{'_account_id': 7700}, {'_account_id': 8127}, {'_account_id': 13149}, {'_account_id': 20563}, {'_account_id': 20773}]","[{'number': 1, 'created': '2016-05-04 16:13:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/80d1b3a571b9f15c1133c697eb4a4ed8fe83a83c', 'message': '[WIP] Add spec for LbaaS Library\n\nChange-Id: I5ed1971311f72351c32164ffc794ad8897075c8f\n'}, {'number': 2, 'created': '2016-06-08 09:57:05.000000000', 'files': ['specs/newton/approved/lbaas_library.rst'], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/eaab4ab71d70d0d524e9bbc9073b24e60a5d92cb', 'message': '[WIP] Add spec for LbaaS Library\n\nChange-Id: I5ed1971311f72351c32164ffc794ad8897075c8f\n'}]",31,312620,eaab4ab71d70d0d524e9bbc9073b24e60a5d92cb,12,5,2,13149,,,0,"[WIP] Add spec for LbaaS Library

Change-Id: I5ed1971311f72351c32164ffc794ad8897075c8f
",git fetch https://review.opendev.org/openstack/murano-specs refs/changes/20/312620/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/newton/approved/lbaas_library.rst'],1,80d1b3a571b9f15c1133c697eb4a4ed8fe83a83c,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================== Add LbaaS interfaces to murano core-library =========================================== https://blueprints.launchpad.net/murano/+spec/lbaas-library The purpose is to add to murano core-library a set of classes implementing interfaces and LbaaS primitives, which adds abiility to build applications with load balancing. Problem description =================== Murano provides great opportunities to implement different solutions for building MuranoPL-based applications with scaling, HA, load balancing and self-healing capabilities. But currently murano core-library does not has any interfaces or primitives, which can be used by app developers during applications building. This means that the developer has to build his own library for that. This spec proposes to add LbaaS interface abstractions to core-library. It will allow to write custom realizations of load balancers (HA-proxy or F5, for example), implementing methods of LbaaS library and can be the first step in building of murano-based framework providing abilities to use scaling and self-healing capabilities in murano applications. Proposed change =============== Architecture ------------ Here is a draft for suggested library :: +--------------------------+ +----------------------------------------+ | class LoadBalancer | | class Listener | +==========================+ +========================================+ | name: string | | name: string | | _listeners: [ Listener ] | | _members: [] | +--------------------------+ | address: string | | .init() | | protocol: string | | deploy(): return string | | algorithm: string | | joinListener(Listener) | | port: int | +--------------------------+ | loadBalancer: class(LoadBalancer) | +----------------------------------------+ | addMember(dict memberData): return [] | | deleteMember(string name): return [] | | getMembers(): return [] | +----------------------------------------+ During creating new applications for specific implementation of load balancer developer should write classes which must inherit these classes as well as a io.murano.Apllication class. This means, that in any custom realization of LbaaS user should create two independend applications and most of theirs properties should be an input of user via application UI. Consider the basic concepts of classes. **LoadBalancer** * *_listeners* - internal class property. It's a list of listeners associated with load balancer * *deploy()* - this method is used to install and configure all things related to specific realization. For example, in case of HA-proxy, deployment of instance(s) and installation of ha-proxy himself must be placed in this method. Also this method must be called each time, when configuration of load balancer is changing. This method should return a connection string to load balancer. * *joinListener(Listener obj)* - assosiates listener with Load Balancer. **Listener** * *loadBalancer* - reference to load balancer * *_members* - internal class property. It's a list of members joined to Listener * *addMember(dict memberData)* - connects member to listener. This method will be used dynamically during workflow of application. Alternatives ------------ TBD Data model impact ----------------- None REST API impact --------------- None Versioning impact ----------------- None Other end user impact --------------------- None Deployer impact --------------- None Developer impact ---------------- Application developers should use these classes as a parents of their applications classes and implement corresponding methods Murano-dashboard / Horizon impact --------------------------------- None Implementation ============== Assignee(s) ----------- Primary assignee: <ddovbii> Work Items ---------- * Inrease murano-core library by adding LbaaS interfaces to it * Create HA-proxy murano-app as an example of application implementing these interfaces Dependencies ============ None Testing ======= Some testing can be done using mocking machinery for MuranoPL Documentation Impact ==================== Core-library docs should be updated References ========== None ",,169,0
openstack%2Fironic~master~I7e548db42d8a69e9e736fefb44a5b45305afd948,openstack/ironic,master,I7e548db42d8a69e9e736fefb44a5b45305afd948,Check whether terminal command is available if console enabled,NEW,2015-10-15 08:28:11.000000000,2017-12-18 05:13:53.000000000,,"[{'_account_id': 6610}, {'_account_id': 6637}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 10239}, {'_account_id': 11042}, {'_account_id': 11076}, {'_account_id': 12356}, {'_account_id': 13636}, {'_account_id': 14629}]","[{'number': 1, 'created': '2015-10-15 08:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/79effe106ca1ff0dab63d2ec6297b4512559ece5', 'message': 'set-console-mode should validate terminal command\n\nNow, node-set-console-mode run with error but no any\nmessage from command client if shellinabox has not been\ninstalled.  This change add execution access check for the\nterminal command.\n\nChange-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948\nCloses-bug: #1402547\n'}, {'number': 2, 'created': '2015-10-16 06:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/acebe3d69d93f79b7e5cd9b77eaee347f24a2443', 'message': 'set-console-mode should validate terminal command\n\nNow, node-set-console-mode run with error but no any\nmessage from command client if shellinabox has not been\ninstalled.  This change add execution access check for the\nterminal command.\n\nChange-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948\nCloses-bug: #1402547\n'}, {'number': 3, 'created': '2015-10-20 04:58:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/cbf86631fb3fd9cb188e00bb39ef0d0c1c6adedc', 'message': 'set-console-mode should validate terminal command\n\nNow, node-set-console-mode run with error but no any\nmessage from command client if shellinabox has not been\ninstalled.  This change add execution access check for the\nterminal command.\n\nChange-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948\nCloses-bug: #1402547\n'}, {'number': 4, 'created': '2015-10-21 09:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/94475fd3b32600b2d15325d8f19bf2aa1f28f591', 'message': 'set-console-mode should validate terminal command\n\nNow, node-set-console-mode run with error but no any\nmessage from command client if shellinabox has not been\ninstalled.  This change add execution access check for the\nterminal command.\n\nChange-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948\nCloses-bug: #1402547\n'}, {'number': 5, 'created': '2015-10-28 07:16:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1dc7652ba5b6fb3b3fcd9566b0cc9d4b43291743', 'message': 'set-console-mode should validate terminal command\n\nNow, node-set-console-mode run with error but no any\nmessage from command client if shellinabox has not been\ninstalled.  This change add execution access check for the\nterminal command.\n\nChange-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948\nCloses-bug: #1402547\n'}, {'number': 6, 'created': '2015-11-17 03:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d521572a8a4e05acfb63dc4f7876add71fa09567', 'message': 'set-console-mode should validate terminal command\n\nNow, node-set-console-mode run with error but no any\nmessage from command client if shellinabox has not been\ninstalled.  This change add execution access check for the\nterminal command.\n\nChange-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948\nCloses-bug: #1402547\n'}, {'number': 7, 'created': '2015-11-19 05:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ea071289c8f973dfd58c722625a02abc890bb0ed', 'message': 'set-console-mode should validate terminal command\n\nNow, node-set-console-mode run with error but no any\nmessage from command client if shellinabox has not been\ninstalled.  This change add execution access check for the\nterminal command.\n\nChange-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948\nCloses-bug: #1402547\n'}, {'number': 8, 'created': '2015-11-24 08:03:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e417d5adf5c4b413828b86553321c7361e979a51', 'message': 'set-console-mode should validate terminal command\n\nNow, node-set-console-mode run with error but no any message from\ncommand client due to the invalid terminal parameter is specified in the\nconsole section of the configuration file. This patch try to check the\ncommand when validate the console configuration.\n\nChange-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948\nCloses-bug: #1402547\n'}, {'number': 9, 'created': '2015-11-30 07:38:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/407e47bcf3a5296b0caf8c0ef321144ba45e4e34', 'message': 'set-console-mode should validate terminal command\n\nNow, node-set-console-mode run with error but no any message from\ncommand client due to the invalid terminal parameter is specified in the\nconsole section of the configuration file. This patch try to check the\ncommand when validate the console configuration.\n\nChange-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948\nCloses-bug: #1402547\n'}, {'number': 10, 'created': '2016-01-18 07:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6f65874463dcc2408e14e03e428a54661f4520ac', 'message': 'Check whether terminal command is available if console enabled\n\nCurrently node-set-console-mode encounter an error due to the console\ndependency is not available. This patch add console enabled option to\nindicate whether to enable the console support. If true, check the\nconsole dependency when loading the console driver.\n\nChange-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948\nCloses-bug: #1402547\n'}, {'number': 11, 'created': '2016-01-27 10:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/97fda225139c5227f684542326c766ba8fe72efc', 'message': 'Check whether terminal command is available if console enabled\n\nCurrently node-set-console-mode encounter an error due to the console\ndependency is not available. This patch add console enabled option to\nindicate whether to enable the console support. If true, check the\nconsole dependency when loading the console driver.\n\nChange-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948\nCloses-bug: #1402547\n'}, {'number': 12, 'created': '2016-01-28 11:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/97e353b12edbaa5ac9e1f4e18d8a823ace29ef7e', 'message': 'Check whether terminal command is available if console enabled\n\nCurrently node-set-console-mode encounter an error due to the console\ndependency is not available. This patch add console enabled option to\nindicate whether to enable the console support. If true, check the\nconsole dependency when loading the console driver.\n\nChange-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948\nCloses-bug: #1402547\n'}, {'number': 13, 'created': '2016-01-29 01:57:47.000000000', 'files': ['ironic/tests/unit/drivers/test_irmc.py', 'ironic/tests/unit/conductor/test_manager.py', 'ironic/tests/unit/drivers/modules/test_console_utils.py', 'ironic/drivers/modules/console_utils.py', 'ironic/tests/unit/drivers/modules/test_inspector.py', 'ironic/tests/unit/drivers/modules/test_seamicro.py', 'ironic/tests/unit/drivers/modules/test_iscsi_deploy.py', 'ironic/drivers/pxe.py', 'ironic/drivers/irmc.py', 'ironic/tests/unit/drivers/test_pxe.py', 'ironic/drivers/ilo.py', 'ironic/drivers/agent.py', 'ironic/tests/unit/conductor/test_utils.py', 'ironic/tests/unit/drivers/modules/test_ssh.py', 'ironic/drivers/modules/seamicro.py', 'ironic/drivers/modules/ssh.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/drivers/modules/ipminative.py', 'ironic/tests/unit/drivers/modules/test_ipminative.py', 'ironic/tests/unit/drivers/modules/ilo/test_console.py', 'ironic/tests/unit/drivers/modules/test_ipmitool.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/fc4e5f1b5980bf2dbd357d72870aeae295831c08', 'message': 'Check whether terminal command is available if console enabled\n\nCurrently node-set-console-mode encounter an error due to the console\ndependency is not available. This patch add console enabled option to\nindicate whether to enable the console support. If true, check the\nconsole dependency when loading the console driver.\n\nChange-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948\nCloses-bug: #1402547\n'}]",38,235159,fc4e5f1b5980bf2dbd357d72870aeae295831c08,65,10,13,11042,,,0,"Check whether terminal command is available if console enabled

Currently node-set-console-mode encounter an error due to the console
dependency is not available. This patch add console enabled option to
indicate whether to enable the console support. If true, check the
console dependency when loading the console driver.

Change-Id: I7e548db42d8a69e9e736fefb44a5b45305afd948
Closes-bug: #1402547
",git fetch https://review.opendev.org/openstack/ironic refs/changes/59/235159/9 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/exception.py', 'ironic/conductor/manager.py', 'ironic/drivers/modules/seamicro.py', 'ironic/tests/unit/common/test_utils.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/tests/unit/drivers/modules/test_console_utils.py', 'ironic/drivers/modules/console_utils.py', 'ironic/drivers/modules/ipminative.py', 'ironic/common/utils.py', 'ironic/tests/unit/drivers/modules/test_ipmitool.py', 'ironic/conductor/rpcapi.py']",11,79effe106ca1ff0dab63d2ec6297b4512559ece5,bug/1402547, :raises: NoCommand when console command can not be found.,,102,4
openstack%2Frally~master~I95a6d5611b17a460579d9dc9a13dc2afea50f246,openstack/rally,master,I95a6d5611b17a460579d9dc9a13dc2afea50f246,[WIP]Add verify task exporter to testrail,NEW,2015-12-25 14:09:56.000000000,2017-12-18 05:13:50.000000000,,"[{'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-12-25 14:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/088587e21bff88698e115c7d6945896245c4e074', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 2, 'created': '2015-12-29 07:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/71c9d080cac836478c0124e57fe4933f5eaf617c', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 3, 'created': '2015-12-29 07:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/291921b3841908a1d12756184d646d07a6c8c653', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 4, 'created': '2016-01-04 15:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c9c7411152445d2e85a787dc3aafc111f6113d8b', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 5, 'created': '2016-01-06 15:58:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f9bbf4c9b065d27acb3127829cb14899378b4bc8', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 6, 'created': '2016-02-08 16:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cf51eaa51702ea83298e4b72f0ccc8e597912dc2', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 7, 'created': '2016-02-09 17:06:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f6ba0e9b0f2ebcd17f4c88a2146ac11fd623b956', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 8, 'created': '2016-02-11 18:20:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/46f53f671edf49a512998254ed1e85ad846206a1', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 9, 'created': '2016-02-12 11:39:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/dbdf124025c315ce95b932f0df3f149eff0f4d4a', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 10, 'created': '2016-02-18 15:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/09a4199452f211ebdee4a06e7d5ecf6141985a2f', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 11, 'created': '2016-03-10 17:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4afef5ec8e096c34d73214598960bcf583d67c0f', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 12, 'created': '2016-03-11 17:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/81bc844b96eaf5e7a278f92872d0946cfb1eb73d', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 13, 'created': '2016-03-14 18:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4310c8a2dacbea11df5d4bdf46ba5f974a081d3b', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 14, 'created': '2016-03-17 18:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4d52d03812fb118f729a9f2853af60081f96e442', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 15, 'created': '2016-03-18 18:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c303dde15137301e0853dd388e65d0b004e1ee4f', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 16, 'created': '2016-03-21 17:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/fbac222cc3e6751298435651f5619b843615cf0a', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 17, 'created': '2016-03-22 15:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e24c17ccea24cf6444c65d5562e105618df4c70a', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 18, 'created': '2016-03-23 13:52:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6a02c6b7cfb96e6ac7eaf0fc85d53219b0fe7fe5', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 19, 'created': '2016-03-23 15:18:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/491570bd5d507d4e7b384b6621f85924ca19036e', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 20, 'created': '2016-03-23 17:01:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6e394a95c1b68e74741e8dfaca9b623eccfde1d8', 'message': 'Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 21, 'created': '2016-06-12 12:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c8cd2e7b47a90376d47b681bdd9668bde725a88f', 'message': '[WIP]Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}, {'number': 22, 'created': '2016-06-12 13:36:01.000000000', 'files': ['rally/plugins/openstack/exporter/__init__.py', 'rally/plugins/openstack/exporter/testrail/testrail.py', 'rally/plugins/openstack/exporter/testrail/__init__.py', 'doc/specs/in-progress/task_and_verification_export.rst', 'rally/cli/commands/verify.py', 'etc/rally.bash_completion', 'rally/plugins/openstack/exporter/testrail/client.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/96ad1d6bf4efd86595247dedea32dea0a3d09d96', 'message': '[WIP]Add verify task exporter to testrail\n\nChange-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246\n'}]",0,261528,96ad1d6bf4efd86595247dedea32dea0a3d09d96,66,2,22,12395,,,0,"[WIP]Add verify task exporter to testrail

Change-Id: I95a6d5611b17a460579d9dc9a13dc2afea50f246
",git fetch https://review.opendev.org/openstack/rally refs/changes/28/261528/20 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/exporter/__init__.py', 'rally/plugins/openstack/exporter/testrail/testrail.py', 'rally/plugins/openstack/exporter/testrail/__init__.py', 'rally/cli/commands/verify.py', 'etc/rally.bash_completion', 'rally/plugins/openstack/exporter/testrail/client.py']",6,088587e21bff88698e115c7d6945896245c4e074,export,"# # TestRail API binding for Python 2.x (API v2, available since # TestRail 3.0) # # Learn more: # # http://docs.gurock.com/testrail-api2/start # http://docs.gurock.com/testrail-api2/accessing # # Copyright Gurock Software GmbH. See license.md for details. # import urllib2 import json import base64 class APIClient: def __init__(self, base_url): self.user = '' self.password = '' if not base_url.endswith('/'): base_url += '/' self.__url = base_url + 'index.php?/api/v2/' # # Send Get # # Issues a GET request (read) against the API and returns the result # (as Python dict). # # Arguments: # # uri The API method to call including parameters # (e.g. get_case/1) # def send_get(self, uri): return self.__send_request(""GET"", uri, None) # # Send POST # # Issues a POST request (write) against the API and returns the result # (as Python dict). # # Arguments: # # uri The API method to call including parameters # (e.g. add_case/1) # data The data to submit as part of the request (as # Python dict, strings must be UTF-8 encoded) # def send_post(self, uri, data): return self.__send_request(""POST"", uri, data) def __send_request(self, method, uri, data): url = self.__url + uri request = urllib2.Request(url) if method == ""POST"": request.add_data(json.dumps(data)) auth = base64.b64encode(""%s:%s"" % (self.user, self.password)) request.add_header(""Authorization"", ""Basic %s"" % auth) request.add_header(""Content-Type"", ""application/json"") e = None try: response = urllib2.urlopen(request).read() except urllib2.HTTPError as e: response = e.read() if response: result = json.loads(response) else: result = {} if e is not None: if result and ""error"" in result: error = '""' + result[""error""] + '""' else: error = ""No additional error message received"" raise APIError(""TestRail API returned HTTP %s (%s)"" % (e.code, error)) return result class APIError(Exception): pass",,220,0
openstack%2Frally~master~I2616ee74f17df4d50fbb1294c611901a4f3ef8ae,openstack/rally,master,I2616ee74f17df4d50fbb1294c611901a4f3ef8ae,[Exceptions] WIP! Propose new base class for exceptions,NEW,2016-06-13 12:10:28.000000000,2017-12-18 05:13:45.000000000,,[{'_account_id': 14817}],"[{'number': 1, 'created': '2016-06-13 12:10:28.000000000', 'files': ['rally/exceptions.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/affb03e65b742811f8f8cf041a4fdbf4cace6f8d', 'message': ""[Exceptions] WIP! Propose new base class for exceptions\n\nLet's discuss how we can add good i18n support\nfor exceptions in case of explicit use, without subclassing.\n\nCurrent base class RallyException does not support i18n\nwell enough if used explicitly.\n\nThis patch demonstrates how things can be well done\nby different base class RallyError.\n\nChange-Id: I2616ee74f17df4d50fbb1294c611901a4f3ef8ae\n""}]",0,328978,affb03e65b742811f8f8cf041a4fdbf4cace6f8d,4,1,1,10475,,,0,"[Exceptions] WIP! Propose new base class for exceptions

Let's discuss how we can add good i18n support
for exceptions in case of explicit use, without subclassing.

Current base class RallyException does not support i18n
well enough if used explicitly.

This patch demonstrates how things can be well done
by different base class RallyError.

Change-Id: I2616ee74f17df4d50fbb1294c611901a4f3ef8ae
",git fetch https://review.opendev.org/openstack/rally refs/changes/78/328978/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/exceptions.py'],1,affb03e65b742811f8f8cf041a4fdbf4cace6f8d,propose-new-rally-exception-class,"class RallyError(Exception): """"""Base Exception class. This can be used both explicitly and with subclassing, with full i18n support in both cases. For example, we have i18n part: ""Attention to key %(key)s with value %(value)s"" Explicit use: raise RallyError(""Attention to key %(key)s with value %(value)s"", key=""foo"", value=""bar"") Subclassing: class SpecificError(RallyError): msg_fmt = ""Attention to key %(key)s with value %(value)s"" raise SpecificError(key=""foo"", value=""bar"") """""" msg_fmt = None def __init__(self, message=None, **kwargs): self.kwargs = kwargs if self.msg_fmt: msg = _(self.msg_fmt) % kwargs else: msg = _(message) % kwargs super(RallyError, self).__init__(msg) def format_message(self): return six.text_type(self) ""check your connection string."") "," ""check your connection string."")",35,1
openstack%2Fironic~master~I2a563ab8f469e9ca0b31b4ec9cfd315f0c698285,openstack/ironic,master,I2a563ab8f469e9ca0b31b4ec9cfd315f0c698285,Allow user to specify a url for Ironic deploy images,NEW,2016-01-05 12:24:49.000000000,2017-12-18 05:13:33.000000000,,"[{'_account_id': 5174}, {'_account_id': 6637}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 11929}, {'_account_id': 12356}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-01-05 12:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/011c8c6e939bd1953b328fa064e52907b01714de', 'message': ""Allow user to specify a url for Ironic deploy images\n\nSame way we do for ordinary images, allow users to specify a url for their\nkernel and ramdisk *deploy* images.\nIt will be the last fallback in case we can't build the deploy images or it\ndoesn't exist previously.\n\nChange-Id: I2a563ab8f469e9ca0b31b4ec9cfd315f0c698285\n""}, {'number': 2, 'created': '2016-01-25 12:05:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/14ee5dc54cca9df46d980a951ea5704eca9d1855', 'message': ""Allow user to specify a url for Ironic deploy images\n\nSame way we do for ordinary images, allow users to specify a url for their\nkernel and ramdisk *deploy* images.\nIt will be the last fallback in case we can't build the deploy images or it\ndoesn't exist previously.\n\nChange-Id: I2a563ab8f469e9ca0b31b4ec9cfd315f0c698285\n""}, {'number': 3, 'created': '2016-06-13 12:39:21.000000000', 'files': ['devstack/lib/ironic'], 'web_link': 'https://opendev.org/openstack/ironic/commit/5ac8cf648bbaacdd6abc1c47a5cddff1f75f8b40', 'message': ""Allow user to specify a url for Ironic deploy images\n\nSame way we do for ordinary images, allow users to specify\na url for their kernel and ramdisk *deploy* images. It will\nbe the last fallback in case we can't build the deploy\nimages or it doesn't exist previously.\n\nChange-Id: I2a563ab8f469e9ca0b31b4ec9cfd315f0c698285\n""}]",2,263706,5ac8cf648bbaacdd6abc1c47a5cddff1f75f8b40,17,9,3,5174,,,0,"Allow user to specify a url for Ironic deploy images

Same way we do for ordinary images, allow users to specify
a url for their kernel and ramdisk *deploy* images. It will
be the last fallback in case we can't build the deploy
images or it doesn't exist previously.

Change-Id: I2a563ab8f469e9ca0b31b4ec9cfd315f0c698285
",git fetch https://review.opendev.org/openstack/ironic refs/changes/06/263706/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/ironic'],1,011c8c6e939bd1953b328fa064e52907b01714de,download-deploy-images," # ideally both downloads bellow would depend on the same variable # IRONIC_DEPLOY_{RAMDISK,KERNEL}_URL but that would break backward # compatibility with those using IRONIC_AGENT_{RAMDISK,KERNEL}_URL if [ -n ""$IRONIC_DEPLOY_KERNEL_URL"" -a -n ""$IRONIC_DEPLOY_RAMDISK_URL"" ]; then # download custom pre-built kernel and ramdisk wget ""$IRONIC_DEPLOY_KERNEL_URL"" -O $IRONIC_DEPLOY_KERNEL_PATH wget ""$IRONIC_DEPLOY_RAMDISK_URL"" -O $IRONIC_DEPLOY_RAMDISK_PATH elif is_deployed_with_ipa_ramdisk; then", if is_deployed_with_ipa_ramdisk; then,8,1
openstack%2Fopenstack-health~master~Ib4650dcf890ca0cbd833acd551d9a909c6a1a2d4,openstack/openstack-health,master,Ib4650dcf890ca0cbd833acd551d9a909c6a1a2d4,[WIP] Add caching to get_test_runs_for_test,NEW,2016-05-25 20:33:14.000000000,2017-12-18 05:13:31.000000000,,[{'_account_id': 5196}],"[{'number': 1, 'created': '2016-05-25 20:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/f7899c1c6ea06e374b9bc40d7c57b28395efacc5', 'message': '[WIP] Add caching to get_test_runs_for_test\n\nThis adds caching to test result listings.\n\nChange-Id: Ib4650dcf890ca0cbd833acd551d9a909c6a1a2d4\n'}, {'number': 2, 'created': '2016-05-25 20:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/b80f876454c1b6219c80438abcf286534274991d', 'message': '[WIP] Add caching to get_test_runs_for_test\n\nThis adds caching to test result listings.\n\nChange-Id: Ib4650dcf890ca0cbd833acd551d9a909c6a1a2d4\n'}, {'number': 3, 'created': '2016-06-14 19:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/aba453c0c23c4835c5c7d1758b3f99f836be064a', 'message': '[WIP] Add caching to get_test_runs_for_test\n\nThis adds caching to test result listings.\n\nChange-Id: Ib4650dcf890ca0cbd833acd551d9a909c6a1a2d4\n'}, {'number': 4, 'created': '2016-06-14 19:34:15.000000000', 'files': ['openstack_health/api.py'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/1e3b4cab2a62afff75ee9e535341dadf3300f2b5', 'message': '[WIP] Add caching to get_test_runs_for_test\n\nThis adds caching to test result listings.\n\nChange-Id: Ib4650dcf890ca0cbd833acd551d9a909c6a1a2d4\n'}]",0,321224,1e3b4cab2a62afff75ee9e535341dadf3300f2b5,8,1,4,4656,,,0,"[WIP] Add caching to get_test_runs_for_test

This adds caching to test result listings.

Change-Id: Ib4650dcf890ca0cbd833acd551d9a909c6a1a2d4
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/24/321224/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack_health/api.py'],1,f7899c1c6ea06e374b9bc40d7c57b28395efacc5,cache_improvements," cache_key = ""%s:%s:%s:%s"" % ( test_id, start_date, stop_date, datetime_resolution) db_test_runs = region.get(cache_key) if not db_test_runs: db_test_runs = api.get_test_runs_by_test_test_id(test_id, if not db_test_runs: # NOTE(mtreinish) if no data is returned from the DB just return an # empty set response, the test_run_aggregator function assumes data # is present. return jsonify({'numeric': {}, 'data': {}}) else: # Save in the cache region.set(cache_key, db_test_runs)"," db_test_runs = api.get_test_runs_by_test_test_id(test_id, if not db_test_runs: # NOTE(mtreinish) if no data is returned from the DB just return an # empty set response, the test_run_aggregator function assumes data # is present. return jsonify({'numeric': {}, 'data': {}})",14,6
openstack%2Fswift~master~I385c391749f04f738bb3c00e6942361e2c12ae68,openstack/swift,master,I385c391749f04f738bb3c00e6942361e2c12ae68,WIP Oslo.messaging middleware,NEW,2015-11-24 23:01:17.000000000,2017-12-18 05:13:26.000000000,,"[{'_account_id': 5600}, {'_account_id': 7665}, {'_account_id': 8959}, {'_account_id': 10063}, {'_account_id': 13052}]","[{'number': 1, 'created': '2015-11-24 23:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d5d1820fa758ba571c76e38c8d6ee4fcf7e3ed87', 'message': ""WIP Oslo.messaging middleware\n\nExperimental middleware to send notifications via oslo.messaging. This\nhas applications for user notifications, indexing, auditing, billing,\nas a potential alternative to the zaqar/http-based notification\nmiddleware in https://review.openstack.org/#/c/196755/\n\nAs discussed a couple of weeks ago, it's likely that because of its\ndependencies, this patch isn't something that will necessarily find a\nhome in swift (and thus I've not included tests in this patch).\nI'm uploading it for review for feedback, and also to get suggestions\nfor where it might live.\n\nChange-Id: I385c391749f04f738bb3c00e6942361e2c12ae68\n""}, {'number': 2, 'created': '2016-02-24 19:27:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/16a16ec6599c15c161c81f324d67edf4fc4d1a60', 'message': ""WIP Oslo.messaging middleware\n\nExperimental middleware to send notifications via oslo.messaging. This\nhas applications for user notifications, indexing, auditing, billing,\nas a potential alternative to the zaqar/http-based notification\nmiddleware in https://review.openstack.org/#/c/196755/\n\nAs discussed a couple of weeks ago, it's likely that because of its\ndependencies, this patch isn't something that will necessarily find a\nhome in swift (and thus I've not included tests in this patch).\nI'm uploading it for review for feedback, and also to get suggestions\nfor where it might live.\n\nChange-Id: I385c391749f04f738bb3c00e6942361e2c12ae68\n""}, {'number': 3, 'created': '2016-02-25 01:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/43137045c3aa1309ce1aab2e5095b693977beab7', 'message': ""WIP Oslo.messaging middleware\n\nExperimental middleware to send notifications via oslo.messaging. This\nhas applications for user notifications, indexing, auditing, billing,\nas a potential alternative to the zaqar/http-based notification\nmiddleware in https://review.openstack.org/#/c/196755/\n\nAs discussed a couple of weeks ago, it's likely that because of its\ndependencies, this patch isn't something that will necessarily find a\nhome in swift (and thus I've not included tests in this patch).\nI'm uploading it for review for feedback, and also to get suggestions\nfor where it might live.\n\nChange-Id: I385c391749f04f738bb3c00e6942361e2c12ae68\n""}, {'number': 4, 'created': '2016-02-25 19:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7e319fc98cd24ac2fc48edf6f9ffddd5475a3639', 'message': ""WIP Oslo.messaging middleware\n\nExperimental middleware to send notifications via oslo.messaging. This\nhas applications for user notifications, indexing, auditing, billing,\nas a potential alternative to the zaqar/http-based notification\nmiddleware in https://review.openstack.org/#/c/196755/\n\nAs discussed a couple of weeks ago, it's likely that because of its\ndependencies, this patch isn't something that will necessarily find a\nhome in swift (and thus I've not included tests in this patch).\nI'm uploading it for review for feedback, and also to get suggestions\nfor where it might live.\n\nChange-Id: I385c391749f04f738bb3c00e6942361e2c12ae68\n""}, {'number': 5, 'created': '2016-03-11 22:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/637c50a50823b481508711cbf8071adbce110c69', 'message': ""WIP Oslo.messaging middleware\n\nExperimental middleware to send notifications via oslo.messaging. This\nhas applications for user notifications, indexing, auditing, billing,\nas a potential alternative to the zaqar/http-based notification\nmiddleware in https://review.openstack.org/#/c/196755/\n\nAs discussed a couple of weeks ago, it's likely that because of its\ndependencies, this patch isn't something that will necessarily find a\nhome in swift (and thus I've not included tests in this patch).\nI'm uploading it for review for feedback, and also to get suggestions\nfor where it might live.\n\nChange-Id: I385c391749f04f738bb3c00e6942361e2c12ae68\n""}, {'number': 6, 'created': '2016-03-15 20:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9d2b25fba63e266c8253682da0902abf6c513358', 'message': ""WIP Oslo.messaging middleware\n\nExperimental middleware to send notifications via oslo.messaging. This\nhas applications for user notifications, indexing, auditing, billing,\nas a potential alternative to the zaqar/http-based notification\nmiddleware in https://review.openstack.org/#/c/196755/\n\nAs discussed a couple of weeks ago, it's likely that because of its\ndependencies, this patch isn't something that will necessarily find a\nhome in swift (and thus I've not included tests in this patch).\nI'm uploading it for review for feedback, and also to get suggestions\nfor where it might live.\n\nChange-Id: I385c391749f04f738bb3c00e6942361e2c12ae68\n""}, {'number': 7, 'created': '2016-06-15 18:26:34.000000000', 'files': ['swift/common/middleware/oslo_notifications.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/50abe8d84f91d571581cb06db5fb45bc92e82c32', 'message': ""WIP Oslo.messaging middleware\n\nExperimental middleware to send notifications via oslo.messaging. This\nhas applications for user notifications, indexing, auditing, billing,\nas a potential alternative to the zaqar/http-based notification\nmiddleware in https://review.openstack.org/#/c/196755/\n\nAs discussed a couple of weeks ago, it's likely that because of its\ndependencies, this patch isn't something that will necessarily find a\nhome in swift (and thus I've not included tests in this patch).\nI'm uploading it for review for feedback, and also to get suggestions\nfor where it might live.\n\nChange-Id: I385c391749f04f738bb3c00e6942361e2c12ae68\n""}]",0,249471,50abe8d84f91d571581cb06db5fb45bc92e82c32,27,5,7,10063,,,0,"WIP Oslo.messaging middleware

Experimental middleware to send notifications via oslo.messaging. This
has applications for user notifications, indexing, auditing, billing,
as a potential alternative to the zaqar/http-based notification
middleware in https://review.openstack.org/#/c/196755/

As discussed a couple of weeks ago, it's likely that because of its
dependencies, this patch isn't something that will necessarily find a
home in swift (and thus I've not included tests in this patch).
I'm uploading it for review for feedback, and also to get suggestions
for where it might live.

Change-Id: I385c391749f04f738bb3c00e6942361e2c12ae68
",git fetch https://review.opendev.org/openstack/swift refs/changes/71/249471/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/middleware/oslo_messaging.py'],1,d5d1820fa758ba571c76e38c8d6ee4fcf7e3ed87,oslo-notifications,"# Copyright (c) 2015 Hewlett-Packard Enterprise Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. """""" This middleware emits oslo.messaging notifications following successful object creation, deletion, copy or metadata operations. As such, it requires oslo.messaging to be installed along with any dependencies, including a suitable driver (rabbitmq, qpid, etc). In its current incarnation it also requires middleware that will identify a tenant to which the request refers, but that could be changed. The notification payload is dependent on the type of event, but always includes project_id, container, obj. For events other than deletion, timestamps, content lengths, metadata may be included. To configure, in proxy-server.conf: [filter:oslomiddleware] paste.filter_factory = swift_oslo_middleware.middleware:filter_factory publisher_id = swift.localhost transport_url = rabbit://stackrabbit:benoit@192.168.235.151:5672/ notification_driver = messaging notification_topics = notifications Additionally, in pipeline:main, add oslomiddleware to the pipeline; it should be added towards the end to ensure any required environment information is present when it runs. Finally, oslo.messaging needs to be installed with its dependencies. This has been tested with oslo.messaging==2.8.1. publisher_id will set the exchange name. transport_url instructs oslo_messaging how to connect to a broker. Since swift doesn't use oslo.config the full range of oslo.messaging options aren't available, which should be addressed. """""" from datetime import datetime from oslo_config import cfg import oslo_messaging from swift.common.swob import Request from swift.common import wsgi CONF = cfg.CONF class OsloMessagingContext(wsgi.WSGIContext): def __init__(self, app, notifier): wsgi.WSGIContext.__init__(self, app) self._notifier = notifier def _get_payload(self, env, container, obj): return { 'project_id': env['HTTP_X_TENANT_ID'], 'container': container, 'object': obj } def _timestamp_to_str(self, timestamp): dt = datetime.fromtimestamp(float(timestamp)) return dt.strftime('%Y-%m-%dT%H:%M:%S.%f') def _get_object_metadata(self, env): object_metadata = {} object_meta_prefix = 'HTTP_X_OBJECT_META_' for k, v in env.iteritems(): if k.startswith(object_meta_prefix): k = k[len(object_meta_prefix):].lower() if k == 'mtime': v = self._timestamp_to_str(v) object_metadata[k] = v return object_metadata def handle_request(self, env, start_response): request = Request(env) method = request.method if method not in ('POST', 'PUT', 'COPY', 'DELETE'): return self.app(env, start_response) try: ver, account, container, obj = request.split_path( 3, 4, rest_with_last=True) except ValueError: return self.app(env, start_response) # Only concern ourselves with objects, not containers, for now if not obj: return self.app(env, start_response) response = self._app_call(env) status_code = self._get_status_int() if status_code in (200, 201, 202, 204): payload = self._get_payload(env, container, obj) if method == 'DELETE': self._notifier.info({}, 'object.delete', payload) else: timestamp = env['HTTP_X_TIMESTAMP'] payload['updated_at'] = self._timestamp_to_str(timestamp) payload['metadata'] = self._get_object_metadata(env) if method == 'POST': # Metadata self._notifier.info({}, 'object.metadata', payload) else: event_type = ('object.copy' if method == 'COPY' else 'object.create') payload['content_length'] = env['CONTENT_LENGTH'] self._notifier.info({}, event_type, payload) # We don't want to tamper with the response start_response(self._response_status, self._response_headers, self._response_exc_info) return response class OsloMessagingMiddleware(object): def __init__(self, app, conf): self._app = app self._transport = oslo_messaging.get_transport( CONF, url=conf['transport_url']) self._notifier = oslo_messaging.Notifier( self._transport, driver=conf['notification_driver'], publisher_id=conf['publisher_id'], topic=conf['notification_topics']) def __call__(self, env, start_response): messaging_context = OsloMessagingContext(self._app, self._notifier) return messaging_context.handle_request(env, start_response) def filter_factory(global_conf, **local_conf): conf = global_conf.copy() conf.update(local_conf) def oslo_messaging_filter(app): return OsloMessagingMiddleware(app, conf) return oslo_messaging_filter ",,154,0
openstack%2Fironic~master~Ifc059457ec1142ef9b66e3041da494d836f81758,openstack/ironic,master,Ifc059457ec1142ef9b66e3041da494d836f81758,adds node name wildcard filter api support,NEW,2016-04-22 03:14:13.000000000,2017-12-18 05:13:21.000000000,,"[{'_account_id': 2889}, {'_account_id': 7711}, {'_account_id': 7933}, {'_account_id': 8106}, {'_account_id': 10118}, {'_account_id': 13295}, {'_account_id': 19686}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-04-22 03:14:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/83b8afa520dbe3d5a3a71adee32ce95bcff3780c', 'message': 'adds node name wildcard filter api support\n\nIn this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>\napi, support to filter nodes by regex string.\n\nChange-Id: Ifc059457ec1142ef9b66e3041da494d836f81758\nPartial-bug: #1526319\n'}, {'number': 2, 'created': '2016-04-22 03:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7fee08b2a03f1643d8b0f180eb5ae0257dda9d08', 'message': 'wip: adds node name wildcard filter api support\n\nIn this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>\napi, support to filter nodes by regex string.\n\nChange-Id: Ifc059457ec1142ef9b66e3041da494d836f81758\nPartial-bug: #1526319\n'}, {'number': 3, 'created': '2016-04-22 05:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7bd1cf377f9e744178c6cadb8ccedb109837c634', 'message': 'wip: adds node name wildcard filter api support\n\nIn this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>\napi, support to filter nodes by regex string.\n\nChange-Id: Ifc059457ec1142ef9b66e3041da494d836f81758\nPartial-bug: #1526319\n'}, {'number': 4, 'created': '2016-04-22 06:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1ebcdd1d01da023e96918728b7cab246dda1ba67', 'message': 'wip: adds node name wildcard filter api support\n\nIn this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>\napi, support to filter nodes by regex string.\n\nChange-Id: Ifc059457ec1142ef9b66e3041da494d836f81758\nPartial-bug: #1526319\n'}, {'number': 5, 'created': '2016-04-22 06:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ce730f57d9503f6d308d2c6b976a9a3ae0d79963', 'message': 'wip: adds node name wildcard filter api support\n\nIn this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>\napi, support to filter nodes by regex string.\n\nChange-Id: Ifc059457ec1142ef9b66e3041da494d836f81758\nPartial-bug: #1526319\n'}, {'number': 6, 'created': '2016-04-22 06:28:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ca5f92c91525fe3fa40d7d316fc5cd75d4e88e99', 'message': 'wip: adds node name wildcard filter api support\n\nIn this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>\napi, support to filter nodes by wildcard string.\n\nChange-Id: Ifc059457ec1142ef9b66e3041da494d836f81758\nPartial-bug: #1526319\n'}, {'number': 7, 'created': '2016-04-22 06:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6df393e6a43ed3c049ad804ab3cf3200c3a02345', 'message': 'wip: adds node name wildcard filter api support\n\nIn this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>\napi, support to filter nodes by wildcard string.\n\nChange-Id: Ifc059457ec1142ef9b66e3041da494d836f81758\nPartial-bug: #1526319\n'}, {'number': 8, 'created': '2016-04-25 02:28:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7e551fd3b0f369bf67dae57062a619d1f98ee461', 'message': 'adds node name wildcard filter api support\n\nIn this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>\napi, support to filter nodes by wildcard string.\n\nChange-Id: Ifc059457ec1142ef9b66e3041da494d836f81758\nPartial-bug: #1526319\n'}, {'number': 9, 'created': '2016-04-25 03:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/dd4cf9f0c927291a84693a591ac813fe6cd38b0b', 'message': 'adds node name wildcard filter api support\n\nIn this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>\napi, support to filter nodes by wildcard string.\n\nChange-Id: Ifc059457ec1142ef9b66e3041da494d836f81758\nPartial-bug: #1526319\n'}, {'number': 10, 'created': '2016-04-25 05:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0b63a38891fea8e6bf962d5dabe883739bcb589e', 'message': 'adds node name wildcard filter api support\n\nIn this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>\napi, support to filter nodes by wildcard string.\n\nChange-Id: Ifc059457ec1142ef9b66e3041da494d836f81758\nPartial-bug: #1526319\n'}, {'number': 11, 'created': '2016-04-27 03:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0390fe094301da6c23c5c2ee859619fde054c2a3', 'message': 'adds node name wildcard filter api support\n\nIn this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>\napi, support to filter nodes by wildcard string.\n\nChange-Id: Ifc059457ec1142ef9b66e3041da494d836f81758\nPartial-bug: #1526319\n'}, {'number': 12, 'created': '2016-04-27 05:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8e1019fcbca045f2e590acb9b13f8567f8676b05', 'message': 'adds node name wildcard filter api support\n\nIn this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>\napi, support to filter nodes by wildcard string.\n\nChange-Id: Ifc059457ec1142ef9b66e3041da494d836f81758\nPartial-bug: #1526319\n'}, {'number': 13, 'created': '2016-04-30 00:24:52.000000000', 'files': ['ironic/tests/unit/api/v1/test_nodes.py', 'ironic/api/controllers/v1/versions.py', 'ironic/db/sqlalchemy/api.py', 'releasenotes/notes/node-name-wildcard-9fbd723197a53145.yaml', 'ironic/api/controllers/v1/node.py', 'ironic/db/api.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a1ab61b48570dd1632384a2cd15fc9943db25362', 'message': 'adds node name wildcard filter api support\n\nIn this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>\napi, support to filter nodes by wildcard string.\n\nChange-Id: Ifc059457ec1142ef9b66e3041da494d836f81758\nPartial-bug: #1526319\n'}]",13,309250,a1ab61b48570dd1632384a2cd15fc9943db25362,46,8,13,8106,,,0,"adds node name wildcard filter api support

In this patch, will add /v1/nodes/?name_wildcard=<wildcard_str>
api, support to filter nodes by wildcard string.

Change-Id: Ifc059457ec1142ef9b66e3041da494d836f81758
Partial-bug: #1526319
",git fetch https://review.opendev.org/openstack/ironic refs/changes/50/309250/12 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/db/sqlalchemy/api.py', 'ironic/api/controllers/v1/node.py', 'ironic/db/api.py']",3,83b8afa520dbe3d5a3a71adee32ce95bcff3780c,rfe/1526319, :name_wildcard: node name wildcard :name_wildcard: node name wildcard,,28,15
openstack%2Fmonasca-agent~master~Ib1ba2c21622b508663a36b695a8f183ad5303ea3,openstack/monasca-agent,master,Ib1ba2c21622b508663a36b695a8f183ad5303ea3,Libvirt detection plugin should accept valid arguments,NEW,2016-06-10 09:44:32.000000000,2017-12-18 05:13:10.000000000,,"[{'_account_id': 11614}, {'_account_id': 14517}, {'_account_id': 14838}, {'_account_id': 15027}, {'_account_id': 18179}, {'_account_id': 20066}]","[{'number': 1, 'created': '2016-06-10 09:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/e2c8616d282f7184535341e7a6b73eb26ae3a946', 'message': 'Libvirt detection plugin should accept valid arguments\n\nRight now the libvirt detection plugin when called with arguments, accepts all\nof them without validating whether it is an acceptable argument or not. This\npatch provides the fix such that, only the valid arguments will be accepted and\ninvalid arguments are ignored with a warning.\n\nChange-Id: Ib1ba2c21622b508663a36b695a8f183ad5303ea3\nCloses-Bug: #1590659\n'}, {'number': 2, 'created': '2016-06-10 12:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/cc30df7ff177bec1572f94bfb6f446a67ae79e4d', 'message': 'Libvirt detection plugin should accept valid arguments\n\nRight now the libvirt detection plugin when called with arguments, accepts all\nof them without validating whether it is an acceptable argument or not. This\npatch provides the fix such that, only the valid arguments will be accepted and\ninvalid arguments are ignored with a warning.\n\nChange-Id: Ib1ba2c21622b508663a36b695a8f183ad5303ea3\nCloses-Bug: #1590659\n'}, {'number': 3, 'created': '2016-06-16 04:40:19.000000000', 'files': ['monasca_setup/detection/plugins/libvirt.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/3413e21eb3a7dcec43b09eb1eadd3d7ede29326e', 'message': 'Libvirt detection plugin should accept valid arguments\n\nRight now the libvirt detection plugin when called with arguments, accepts all\nof them without validating whether it is an acceptable argument or not. This\npatch provides the fix such that, only the valid arguments will be accepted and\ninvalid arguments are ignored with a warning.\n\nChange-Id: Ib1ba2c21622b508663a36b695a8f183ad5303ea3\nCloses-Bug: #1590659\n'}]",4,328201,3413e21eb3a7dcec43b09eb1eadd3d7ede29326e,19,6,3,14838,,,0,"Libvirt detection plugin should accept valid arguments

Right now the libvirt detection plugin when called with arguments, accepts all
of them without validating whether it is an acceptable argument or not. This
patch provides the fix such that, only the valid arguments will be accepted and
invalid arguments are ignored with a warning.

Change-Id: Ib1ba2c21622b508663a36b695a8f183ad5303ea3
Closes-Bug: #1590659
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/01/328201/3 && git format-patch -1 --stdout FETCH_HEAD,['monasca_setup/detection/plugins/libvirt.py'],1,e2c8616d282f7184535341e7a6b73eb26ae3a946,bug-1590659,"# Acceptable arguments acceptable_args = ['admin_user', 'admin_password', 'admin_tenant_name', 'identity_uri', 'cache_dir', 'nova_refresh', 'vm_probation', 'metadata', 'ping_check', 'alive_only'] if arg in acceptable_args: init_config[arg] = self.literal_eval(self.args[arg]) else: log.warn(""Invalid argument '{0}' "" ""has been provided!!!"".format(arg))", init_config[arg] = self.literal_eval(self.args[arg]),9,1
openstack%2Fnova-powervm~master~I96f0eb90c1d1274a51dde5c14eba0bf9f30786af,openstack/nova-powervm,master,I96f0eb90c1d1274a51dde5c14eba0bf9f30786af,"Decouple pypowervm calls from test_mgmt, test_vios",NEW,2016-05-06 15:50:01.000000000,2017-12-18 05:11:57.000000000,,[{'_account_id': 16128}],"[{'number': 1, 'created': '2016-05-06 15:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/c6f1debc3feba43845d4659b5b08637dbdbf99ae', 'message': 'Decouple pypowervm calls from test_mgmt, test_vios\n\nRemove calls to the pypowervm project from within nova-powervm\ntest_mgmt.py and test_vios.py.\n\nChange-Id: I96f0eb90c1d1274a51dde5c14eba0bf9f30786af\n'}, {'number': 2, 'created': '2016-05-24 18:40:25.000000000', 'files': ['nova_powervm/tests/virt/powervm/test_vios.py', 'nova_powervm/tests/virt/powervm/test_mgmt.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/ed98a6440355659999a8640df4ca16585a16f950', 'message': 'Decouple pypowervm calls from test_mgmt, test_vios\n\nRemove calls to the pypowervm project from within nova-powervm\ntest_mgmt.py and test_vios.py.\n\nChange-Id: I96f0eb90c1d1274a51dde5c14eba0bf9f30786af\n'}]",0,313616,ed98a6440355659999a8640df4ca16585a16f950,8,1,2,9572,,,0,"Decouple pypowervm calls from test_mgmt, test_vios

Remove calls to the pypowervm project from within nova-powervm
test_mgmt.py and test_vios.py.

Change-Id: I96f0eb90c1d1274a51dde5c14eba0bf9f30786af
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/16/313616/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/tests/virt/powervm/test_vios.py', 'nova_powervm/tests/virt/powervm/test_mgmt.py']",2,c6f1debc3feba43845d4659b5b08637dbdbf99ae,test_mgmt,,"from pypowervm.tests.test_utils import pvmhttpLPAR_HTTPRESP_FILE = ""lpar.txt"" lpar_http = pvmhttp.load_pvm_resp(LPAR_HTTPRESP_FILE, adapter=self.apt) self.assertNotEqual(lpar_http, None, ""Could not load %s "" % LPAR_HTTPRESP_FILE) self.resp = lpar_http.response ",20,21
openstack%2Fcongress~master~I7746f83591135f8224c36fc66ae178d9ce1a8a14,openstack/congress,master,I7746f83591135f8224c36fc66ae178d9ce1a8a14,Updated from global requirements,MERGED,2017-12-15 21:24:25.000000000,2017-12-18 05:09:50.000000000,2017-12-18 05:09:50.000000000,"[{'_account_id': 11278}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-15 21:24:25.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/congress/commit/b69d234197ed726dd30e112b361dfcf83ee8380d', 'message': 'Updated from global requirements\n\nChange-Id: I7746f83591135f8224c36fc66ae178d9ce1a8a14\n'}]",0,528397,b69d234197ed726dd30e112b361dfcf83ee8380d,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I7746f83591135f8224c36fc66ae178d9ce1a8a14
",git fetch https://review.opendev.org/openstack/congress refs/changes/97/528397/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b69d234197ed726dd30e112b361dfcf83ee8380d,openstack/requirements,"oslo.service!=1.28.1,>=1.24.0 # Apache-2.0",oslo.service>=1.24.0 # Apache-2.0,1,1
openstack%2Fkolla~master~I7701b768d1189db750c8d0818ced90c4ec508d22,openstack/kolla,master,I7701b768d1189db750c8d0818ced90c4ec508d22,"Revert ""Fix deployment of ceph""",MERGED,2017-12-14 15:49:55.000000000,2017-12-18 05:04:01.000000000,2017-12-18 05:04:01.000000000,"[{'_account_id': 11869}, {'_account_id': 22348}, {'_account_id': 22582}]","[{'number': 1, 'created': '2017-12-14 15:49:55.000000000', 'files': ['docker/base/apt_preferences.ubuntu'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2e77b1dcf36dc63bbbae29c9931a84b637db9d65', 'message': 'Revert ""Fix deployment of ceph""\n\nSince we have bump to ceph luminous. So no need to pin the ceph version\nany more.\n\nThis reverts commit a0b60bff4386a98a7e2c3e4d549738d34134f4dd.\n\nChange-Id: I7701b768d1189db750c8d0818ced90c4ec508d22\n'}]",0,527996,2e77b1dcf36dc63bbbae29c9931a84b637db9d65,7,3,1,7488,,,0,"Revert ""Fix deployment of ceph""

Since we have bump to ceph luminous. So no need to pin the ceph version
any more.

This reverts commit a0b60bff4386a98a7e2c3e4d549738d34134f4dd.

Change-Id: I7701b768d1189db750c8d0818ced90c4ec508d22
",git fetch https://review.opendev.org/openstack/kolla refs/changes/96/527996/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/base/apt_preferences.ubuntu'],1,2e77b1dcf36dc63bbbae29c9931a84b637db9d65,,,Package: ceph* Pin: version 10.* Pin-Priority: 550 Package: *rbd* Pin: version 10.* Pin-Priority: 550 Package: python-cephfs Pin: version 10.* Pin-Priority: 550 Package: *rados* Pin: version 10.* Pin-Priority: 550 Package: *rgw* Pin: version 10.* Pin-Priority: 550 Package: qemu* Pin: version 1:2.5* Pin-Priority: 550 ,0,23
openstack%2Fmurano~master~I5d5390db3ad2d57e6605e996c7e823e87ced9d1f,openstack/murano,master,I5d5390db3ad2d57e6605e996c7e823e87ced9d1f,WiP: Glare v1 support,NEW,2016-07-01 12:27:42.000000000,2017-12-18 05:02:43.000000000,,"[{'_account_id': 7821}, {'_account_id': 8127}]","[{'number': 1, 'created': '2016-07-01 12:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/efedff692fdc057f64f5db6a1dad986ef9178b5a', 'message': 'WiP: Glare v1 support\n\nChange-Id: I5d5390db3ad2d57e6605e996c7e823e87ced9d1f\n'}, {'number': 2, 'created': '2016-07-01 12:28:04.000000000', 'files': ['contrib/glance/muranoartifact/v2/murano_package.py', 'contrib/glance/muranoartifact/v2/__init__.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/d51188e749a337de388c19e65e4cb90f307ad2d1', 'message': 'WiP: Glare v1 support\n\nChange-Id: I5d5390db3ad2d57e6605e996c7e823e87ced9d1f\n'}]",0,336534,d51188e749a337de388c19e65e4cb90f307ad2d1,8,2,2,8127,,,0,"WiP: Glare v1 support

Change-Id: I5d5390db3ad2d57e6605e996c7e823e87ced9d1f
",git fetch https://review.opendev.org/openstack/murano refs/changes/34/336534/2 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/glance/muranoartifact/v2/murano_package.py', 'contrib/glance/muranoartifact/v2/__init__.py']",2,efedff692fdc057f64f5db6a1dad986ef9178b5a,,,,79,0
openstack%2Fswift~master~I4588b7c8b2e4b92b5a97fb8176cd012f36941b31,openstack/swift,master,I4588b7c8b2e4b92b5a97fb8176cd012f36941b31,Apply container update probe to both of REPL/EC,NEW,2016-05-30 11:25:26.000000000,2017-12-18 05:02:41.000000000,,"[{'_account_id': 4608}, {'_account_id': 7847}, {'_account_id': 13052}]","[{'number': 1, 'created': '2016-05-30 11:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/44121df146b7c09007c29e4c49dadbcbad3200b0', 'message': 'Apply some probe tests to both of REPL/EC polices\n\nThis is a follow up for https://review.openstack.org/#/c/317475\n\nThere are tests which should be asserted for both REPL/EC policies\nin test/probe/test_object_async_update. In particular, test_during_PUT\nseems for EC specific case (until crypt work finished? not sure) but\nit is running on only ReplPolicy case.\n\nWith this change, to be able to run both REPL/EC policies, the probe test\nhas new UpdateTestMixin inclues tests which should be verified in both policies\neach child test case class inherits the Mixin to enable the tests inside.\n\nChange-Id: I4588b7c8b2e4b92b5a97fb8176cd012f36941b31\n'}, {'number': 2, 'created': '2016-06-03 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/946915bb1afd0affcf284edafa10161de3ac1f0c', 'message': 'Apply container update probe to both of REPL/EC\n\nThis is a follow up for https://review.openstack.org/#/c/317475\n\nThere are tests which should be asserted for both REPL/EC policies\nin test/probe/test_object_async_update. However some tests are only\nin ECProbeTest case and others are only in ReplProbeTest case.\n\nWith this change, to cover both REPL/EC cases, I created a new\nUpdateTestMixin class includes all current existing tests, and then,\nI made 2 child classes for REPL and EC which have different parameters\nfor each tests in the Mixin.\n\nIn the new tests, all parametes for assertions are in instance\nvariables as follows:\n\nself.container_meta -> expected metadata in container db\nself.object_meta -> expected metadata in object (file xattr)\n\nChange-Id: I4588b7c8b2e4b92b5a97fb8176cd012f36941b31\n'}, {'number': 3, 'created': '2016-06-06 01:52:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/014eef87c3fee5cd0e7a89a420a7713da580c277', 'message': 'Apply container update probe to both of REPL/EC\n\nThis is a follow up for https://review.openstack.org/#/c/317475\n\nThere are tests which should be asserted for both REPL/EC policies\nin test/probe/test_object_async_update. However some tests are only\nin ECProbeTest case and others are only in ReplProbeTest case.\n\nWith this change, to cover both REPL/EC cases, I created a new\nUpdateTestMixin class includes all current existing tests, and then,\nI made 2 child classes for REPL and EC which have different parameters\nfor each tests in the Mixin.\n\nIn the new tests, all parametes for assertions are in instance\nvariables as follows:\n\nself.container_meta -> expected metadata in container db\nself.object_meta -> expected metadata in object (file xattr)\n\nChange-Id: I4588b7c8b2e4b92b5a97fb8176cd012f36941b31\n'}, {'number': 4, 'created': '2016-06-07 07:46:07.000000000', 'files': ['test/probe/test_object_async_update.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/0d2a57f9049f6e8a6716553d7cf07f9e1b56089a', 'message': 'Apply container update probe to both of REPL/EC\n\nThis is a follow up for https://review.openstack.org/#/c/317475\n\nThere are tests which should be asserted for both REPL/EC policies\nin test/probe/test_object_async_update. However some tests are only\nin ECProbeTest case and others are only in ReplProbeTest case.\n\nWith this change, to cover both REPL/EC cases, I created a new\nUpdateTestMixin class includes all current existing tests, and then,\nI made 2 child classes for REPL and EC which have different\nparameters for each tests in the Mixin.\n\nIn the new tests, all parametes for assertions are in instance\nvariables as follows:\n\nself.container_meta -> expected metadata in container db\nself.object_meta -> expected metadata in object (file xattr)\n\nChange-Id: I4588b7c8b2e4b92b5a97fb8176cd012f36941b31\n'}]",23,322773,0d2a57f9049f6e8a6716553d7cf07f9e1b56089a,18,3,4,4608,,,0,"Apply container update probe to both of REPL/EC

This is a follow up for https://review.openstack.org/#/c/317475

There are tests which should be asserted for both REPL/EC policies
in test/probe/test_object_async_update. However some tests are only
in ECProbeTest case and others are only in ReplProbeTest case.

With this change, to cover both REPL/EC cases, I created a new
UpdateTestMixin class includes all current existing tests, and then,
I made 2 child classes for REPL and EC which have different
parameters for each tests in the Mixin.

In the new tests, all parametes for assertions are in instance
variables as follows:

self.container_meta -> expected metadata in container db
self.object_meta -> expected metadata in object (file xattr)

Change-Id: I4588b7c8b2e4b92b5a97fb8176cd012f36941b31
",git fetch https://review.opendev.org/openstack/swift refs/changes/73/322773/4 && git format-patch -1 --stdout FETCH_HEAD,['test/probe/test_object_async_update.py'],1,44121df146b7c09007c29e4c49dadbcbad3200b0,follow-up-async-update,"from hashlib import md5class UpdateTestMixin(object): def _test_update_during_PUT(self, headers=None): headers = headers or {} content = u'stuff' StringIO(content), self.account, 'c1', 'o1', headers) # meta = int_client.get_object_metadata(self.account, 'c1', 'o1') opart, onodes = self.policy.object_ring.get_nodes( self.account, 'c1', 'o1') resp_headers = direct_client.direct_head_object( onodes[0], opart, self.account, 'c1', 'o1', headers={'X-Backend-Storage-Policy-Index': str(int(self.policy))}) return (resp_headers, content, obj) class TestUpdateOverrides(UpdateTestMixin, ReplProbeTest): # verify that the container update overrides used with EC policies make # it to the container servers when container updates are sync or async # and possibly re-ordered with respect to object PUT and POST requests. def test_update_during_PUT(self): headers = { 'Content-Type': 'text/plain', 'X-Backend-Container-Update-Override-Etag': 'override-etag', 'X-Backend-Container-Update-Override-Content-Type': 'override-type', 'X-Backend-Container-Update-Override-Size': '1999' } direct_resp_headers, content, listing_obj = \ self. _test_update_during_PUT(headers) etag = '""%s""' % md5(content).hexdigest() self.assertEqual(etag, direct_resp_headers['etag']) self.assertEqual(str(len(content)), direct_resp_headers['content-length']) self.assertEqual('override-etag', listing_obj['hash']) self.assertEqual('override-type', listing_obj['content_type']) self.assertEqual(1999, listing_obj['bytes']) class TestUpdateOverridesEC(UpdateTestMixin, ECProbeTest): # verify that the container update overrides used with EC policies make # it to the container servers when container updates are sync or async # and possibly re-ordered with respect to object PUT and POST requests. def test_update_during_PUT(self): direct_resp_headers, content, listing_obj = \ self. _test_update_during_PUT() # assert override original content etag/length content_etag = '%s' % md5(content).hexdigest() self.assertEqual( content_etag, direct_resp_headers['X-Object-Sysmeta-Ec-Etag']) self.assertEqual( str(len(content)), direct_resp_headers['X-Object-Sysmeta-Ec-Content-Length']) # assert actual erasure coded conent etag/length frag_index = int(direct_resp_headers['X-Object-Sysmeta-Ec-Frag-Index']) stored_content = self.policy.pyeclib_driver.encode(content)[frag_index] stored_content_etag = '""%s""' % md5(stored_content).hexdigest() self.assertEqual(stored_content_etag, direct_resp_headers['etag']) self.assertEqual( str(len(stored_content)), direct_resp_headers['content-length']) self.assertEqual(content_etag, listing_obj['hash']) self.assertEqual(direct_resp_headers['content-type'], listing_obj['content_type']) self.assertEqual(len(content), listing_obj['bytes']) ","class TestUpdateOverrides(ReplProbeTest): def test_update_during_PUT(self): headers = { 'Content-Type': 'text/plain', 'X-Backend-Container-Update-Override-Etag': 'override-etag', 'X-Backend-Container-Update-Override-Content-Type': 'override-type', 'X-Backend-Container-Update-Override-Size': '1999' } StringIO(u'stuff'), self.account, 'c1', 'o1', headers) meta = int_client.get_object_metadata(self.account, 'c1', 'o1') self.assertEqual('text/plain', meta['content-type']) self.assertEqual('c13d88cb4cb02003daedb8a84e5d272a', meta['etag']) self.assertEqual('5', meta['content-length']) self.assertEqual('override-etag', obj['hash']) self.assertEqual('override-type', obj['content_type']) self.assertEqual(1999, obj['bytes']) break class TestUpdateOverridesEC(ECProbeTest): # verify that the container update overrides used with EC policies make # it to the container servers when container updates are sync or async # and possibly re-ordered with respect to object PUT and POST requests.",68,24
openstack%2Fswift~master~I31b0fb33c5ab235a8fc56008ed36dedd440a3504,openstack/swift,master,I31b0fb33c5ab235a8fc56008ed36dedd440a3504,WIP: Force close backend socket at putter close,NEW,2016-07-05 05:44:08.000000000,2017-12-18 05:02:38.000000000,,"[{'_account_id': 4608}, {'_account_id': 13052}]","[{'number': 1, 'created': '2016-07-05 05:44:08.000000000', 'files': ['swift/proxy/controllers/obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/56b8c30f744f5db3f31f2fc5872b2fe78f018c13', 'message': 'WIP: Force close backend socket at putter close\n\nI\'m still not entirly sure the decresing a reference counter for\nBufferedHTTPResponse causes to kick the socket close (it seems to work\nwell with actual test but not sure for impelemntation) but I noticed\nwe already have had a way to close the socket via\nBufferedHTTPResponse.nuke_from_orbit so this patch change the closing\nfrom set None to resp to use close_swift_conn as well as ResumingGetter.\n\nWIP because ""I\'m not sure if this way is good for us"" and no additional\ntests right now. Welcome to better idea for fixing/testing.\n\nChange-Id: I31b0fb33c5ab235a8fc56008ed36dedd440a3504\nCloses-Bug: #1594739\n'}]",0,337431,56b8c30f744f5db3f31f2fc5872b2fe78f018c13,5,2,1,4608,,,0,"WIP: Force close backend socket at putter close

I'm still not entirly sure the decresing a reference counter for
BufferedHTTPResponse causes to kick the socket close (it seems to work
well with actual test but not sure for impelemntation) but I noticed
we already have had a way to close the socket via
BufferedHTTPResponse.nuke_from_orbit so this patch change the closing
from set None to resp to use close_swift_conn as well as ResumingGetter.

WIP because ""I'm not sure if this way is good for us"" and no additional
tests right now. Welcome to better idea for fixing/testing.

Change-Id: I31b0fb33c5ab235a8fc56008ed36dedd440a3504
Closes-Bug: #1594739
",git fetch https://review.opendev.org/openstack/swift refs/changes/31/337431/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/proxy/controllers/obj.py'],1,56b8c30f744f5db3f31f2fc5872b2fe78f018c13,bug/1594739," cors_validation, ResumingGetter, close_swift_conn if self.resp or self.final_resp: # Once we got a response with Connection: close, the resp is only # staff which can close the real socket. See NOTE: swift_conn in # swift/proxy/controllers/base.py close_swift_conn(self.resp) close_swift_conn(self.final_resp) else: # If we don't get resposne yet, conn.close is enough for closing self.conn.close()"," cors_validation, ResumingGetter self.resp = self.final_resp = None self.conn.close()",10,3
openstack%2Fironic~master~I514f7a1fb124cb9cbb8f13748ae285de2984c128,openstack/ironic,master,I514f7a1fb124cb9cbb8f13748ae285de2984c128,"Devstack: When appropriate, Skip setting cleaning_network_uuid",NEW,2016-06-29 15:39:27.000000000,2017-12-18 05:02:36.000000000,,"[{'_account_id': 6773}, {'_account_id': 7882}, {'_account_id': 11929}, {'_account_id': 12356}, {'_account_id': 14525}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-06-29 15:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c45b800c1da5894a2189799e91eb9c7aaf0b758b', 'message': ""Devstack: When appropriate, Skip setting cleaning_network_uuid\n\nDevstack's Neutron component does not require you to create\nnetworks initially. Through NEUTRON_CREATE_INITIAL_NETWORKS you\ncan skip network creation. However, when this is set, ironic still\ntries (and fails) to find the initial network so it can set the\ncleaning_network_uuid. This patch avoids setting this conf value\nwhen neutron is explicitly not creating the networks.\n\nChange-Id: I514f7a1fb124cb9cbb8f13748ae285de2984c128\n""}, {'number': 2, 'created': '2016-06-30 13:35:13.000000000', 'files': ['devstack/lib/ironic'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e038a5cefce1e3a47b689fb391e06ea1b582767f', 'message': ""Devstack: When appropriate, Skip setting cleaning_network_uuid\n\nDevstack's Neutron component does not require you to create\nnetworks initially. Through NEUTRON_CREATE_INITIAL_NETWORKS you\ncan skip network creation. However, when this is set, ironic still\ntries (and fails) to find the initial network so it can set the\ncleaning_network_uuid. This patch avoids setting this conf value\nwhen neutron is explicitly not creating the networks.\n\nChange-Id: I514f7a1fb124cb9cbb8f13748ae285de2984c128\n""}]",9,335567,e038a5cefce1e3a47b689fb391e06ea1b582767f,20,8,2,11929,,,0,"Devstack: When appropriate, Skip setting cleaning_network_uuid

Devstack's Neutron component does not require you to create
networks initially. Through NEUTRON_CREATE_INITIAL_NETWORKS you
can skip network creation. However, when this is set, ironic still
tries (and fails) to find the initial network so it can set the
cleaning_network_uuid. This patch avoids setting this conf value
when neutron is explicitly not creating the networks.

Change-Id: I514f7a1fb124cb9cbb8f13748ae285de2984c128
",git fetch https://review.opendev.org/openstack/ironic refs/changes/67/335567/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/ironic'],1,c45b800c1da5894a2189799e91eb9c7aaf0b758b,skip_set_clean_net," if is_service_enabled neutron && [[ ""$NEUTRON_CREATE_INITIAL_NETWORKS"" == ""True"" ]]", if is_service_enabled neutron; then,1,1
openstack%2Fdib-utils~master~I4062696209e0750e95d0a1c697af271be6a07052,openstack/dib-utils,master,I4062696209e0750e95d0a1c697af271be6a07052,Fix busybox portability,NEW,2016-05-02 01:47:53.000000000,2017-12-18 05:02:33.000000000,,"[{'_account_id': 10035}, {'_account_id': 12459}]","[{'number': 1, 'created': '2016-05-02 01:47:53.000000000', 'files': ['bin/dib-run-parts'], 'web_link': 'https://opendev.org/openstack/dib-utils/commit/0e226d8205fb3c0cf9218aeffe5cd06b490f5ef3', 'message': 'Fix busybox portability\n\nSome of the find arguments we use are not available on busybox and\ntherefore we cannot support creation of busybox images without chaning\nthem.\n\nChange-Id: I4062696209e0750e95d0a1c697af271be6a07052\n'}]",1,311648,0e226d8205fb3c0cf9218aeffe5cd06b490f5ef3,6,2,1,10035,,,0,"Fix busybox portability

Some of the find arguments we use are not available on busybox and
therefore we cannot support creation of busybox images without chaning
them.

Change-Id: I4062696209e0750e95d0a1c697af271be6a07052
",git fetch https://review.opendev.org/openstack/dib-utils refs/changes/48/311648/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/dib-run-parts'],1,0e226d8205fb3c0cf9218aeffe5cd06b490f5ef3,," targets=$(find $target_dir -maxdepth 1 -type f -exec basename {} \; | grep -E ""$allowed_regex"" | LANG=C sort -n || echo """") _targets='' while read -r target; do if [ -x $target_dir/$target ]; then if [ -z ""$targets"" ]; then _targets=""$target"" else _targets=$(echo -e ""$_targets\n$target"") fi fi done <<< ""$targets"" targets=$_targetsPROFILE_DIR=$(mktemp -d -t profiledir.XXXXXX) env_files=$(find $ENVIRONMENT_D_DIR -maxdepth 1 -type f | \for target in $(find . -name 'start_*' -exec basename {} \; | env LC_ALL=C sort -n) ; do #duration=$(echo - | awk ""{ print $stop_seconds - $start_seconds }"") #LC_NUMERIC=C LC_ALL=C printf ""%-40s %10.3f\n"" ${target##start_} $duration","targets=$(find $target_dir -maxdepth 1 -xtype f -executable -printf '%f\n' | grep -E ""$allowed_regex"" | LANG=C sort -n || echo """")PROFILE_DIR=$(mktemp -d --tmpdir profiledir.XXXXXX) env_files=$(find $ENVIRONMENT_D_DIR -maxdepth 1 -xtype f | \for target in $(find . -name 'start_*' -printf '%f\n' | env LC_ALL=C sort -n) ; do duration=$(echo - | awk ""{ print $stop_seconds - $start_seconds }"") LC_NUMERIC=C LC_ALL=C printf ""%-40s %10.3f\n"" ${target##start_} $duration",18,6
openstack%2Fheat-translator~master~I88bcfb0e35e0b670e71c3c566b3fff1728e54f5f,openstack/heat-translator,master,I88bcfb0e35e0b670e71c3c566b3fff1728e54f5f,Implements literal and folded string support,NEW,2016-05-17 00:29:26.000000000,2017-12-18 05:01:57.000000000,,"[{'_account_id': 6456}, {'_account_id': 10487}, {'_account_id': 12455}, {'_account_id': 13380}]","[{'number': 1, 'created': '2016-05-17 00:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/1414fd3c81e6c6c86219350a6923966b457dfa76', 'message': 'Implements literal and folded string support\n\nChange-Id: I88bcfb0e35e0b670e71c3c566b3fff1728e54f5f\nCloses-Bug: 1582448\n'}, {'number': 2, 'created': '2016-05-17 00:32:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/269165e969f521e92e78d8a89ea7391779a62bb8', 'message': 'Implements literal and folded string support\n\nChange-Id: I88bcfb0e35e0b670e71c3c566b3fff1728e54f5f\nCloses-Bug: 1582448\n'}, {'number': 3, 'created': '2016-05-19 01:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/7e6d9061af34de44e5d2e9113d529eba181ffd8f', 'message': 'Implements literal and folded string support\n\nChange-Id: I88bcfb0e35e0b670e71c3c566b3fff1728e54f5f\nCloses-Bug: 1582448\n'}, {'number': 4, 'created': '2016-05-19 01:54:32.000000000', 'files': ['translator/hot/syntax/hot_template.py', 'translator/tests/data/hot_output/hot_folded_string.yaml', 'translator/tests/test_tosca_hot_translation.py', 'translator/hot/syntax/hot_resource.py', 'translator/tests/data/hot_output/hot_literal_string.yaml', 'translator/tests/data/test_tosca_folded_string.yaml', 'translator/tests/data/test_tosca_literal_string.yaml'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/d593b22ee994d15753186d8353d0d0f057bda0a9', 'message': 'Implements literal and folded string support\n\nChange-Id: I88bcfb0e35e0b670e71c3c566b3fff1728e54f5f\nCloses-Bug: 1582448\n'}]",2,317150,d593b22ee994d15753186d8353d0d0f057bda0a9,15,4,4,16511,,,0,"Implements literal and folded string support

Change-Id: I88bcfb0e35e0b670e71c3c566b3fff1728e54f5f
Closes-Bug: 1582448
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/50/317150/1 && git format-patch -1 --stdout FETCH_HEAD,"['translator/conf/heat_translator_logging.conf', 'translator/hot/syntax/hot_template.py', 'translator/tests/data/hot_output/hot_folded_string.yaml', 'translator/tests/test_tosca_hot_translation.py', 'translator/hot/syntax/hot_resource.py', 'translator/tests/data/hot_output/hot_literal_string.yaml', 'translator/tests/data/test_tosca_folded_string.yaml', 'translator/tests/data/test_tosca_literal_string.yaml']",8,1414fd3c81e6c6c86219350a6923966b457dfa76,bug/1582448,"tosca_definitions_version: tosca_simple_yaml_1_0 description: Template for deploying a single server with predefined properties. node_types: tosca.nodes.Compute.Test: derived_from: tosca.nodes.Compute properties: user_data: type: string required: false topology_template: node_templates: my_server: type: tosca.nodes.Compute.Test properties: user_data: | #!/bin/sh echo ""This is a literal string that should keep"" echo ""all of the newlines intact"" capabilities: # Host container properties host: properties: num_cpus: 2 disk_size: 10 GB mem_size: 512 MB # Guest Operating System properties os: properties: # host Operating System image properties architecture: x86_64 type: Linux distribution: RHEL version: 6.5 ",,163,1
openstack%2Fswift~master~I0140375d513d8d6b9af9859299c7a2ed67f64af3,openstack/swift,master,I0140375d513d8d6b9af9859299c7a2ed67f64af3,Improvement of logging for invalid policies,NEW,2014-12-12 01:30:41.000000000,2017-12-18 05:01:49.000000000,,"[{'_account_id': 330}, {'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 4608}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 8859}, {'_account_id': 13052}, {'_account_id': 14967}]","[{'number': 1, 'created': '2014-12-12 01:30:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/01026a68959e8bef3e17032a3640cb36c9d4e4d4', 'message': 'Improvement of logging for PolicyError\n\nBy some operational mistakes, policy settings can be inconsistent\namong servers of swift cluster. Due to this, some of background\nrequests will not be handled.\n\nIn this case, Swift should output appropriate error logs so that\noperators can find the mis-configured server. Unfortunately, in some\ncases, there are no found logs about that, therefore it takes long\nto find the root cause. In other cases, logger outputs nasty stacktrace\nfor uncaught PolicyError, so operators can find the root cause by\nseeking long, long error logs, but obviously shorter logs are better.\n\nChange-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3\nCloses-Bug: 1375384\n'}, {'number': 2, 'created': '2015-01-20 07:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3b5b564177b5c7863615d64411761613d0c01d3f', 'message': 'Improvement of logging for PolicyError\n\nBy some operational mistakes, policy settings can be inconsistent\namong servers of swift cluster. Due to this, some of background\nrequests will not be handled.\n\nIn this case, Swift should output appropriate error logs so that\noperators can find the mis-configured server. Unfortunately, in some\ncases, there are no found logs about that, therefore it takes long time\nto find the root cause. In other cases, logger outputs nasty stacktrace\nfor uncaught PolicyError, so operators can find the root cause by\nseeking long, long error logs, but obviously shorter logs are better.\n\nChange-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3\nCloses-Bug: 1375384\n'}, {'number': 3, 'created': '2015-02-06 05:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4c68777585bd463ffd38703edfedd93676afac95', 'message': 'Improvement of logging for PolicyError\n\nBy some operational mistakes, policy settings can be inconsistent\namong servers of swift cluster. Due to this, some of background\nrequests will not be handled.\n\nIn this case, Swift should output appropriate error logs so that\noperators can find the mis-configured server. Unfortunately, in some\ncases, there are no found logs about that, therefore it takes long time\nto find the root cause. In other cases, logger outputs nasty stacktrace\nfor uncaught PolicyError, so operators can find the root cause by\nseeking long, long error logs, but obviously shorter logs are better.\n\nChange-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3\nCloses-Bug: 1375384\n'}, {'number': 4, 'created': '2015-02-12 18:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/20d7c0d1cc21f2eff92bb82a08024fcbf2851f95', 'message': 'Improvement of logging for PolicyError\n\nBy some operational mistakes, policy settings can be inconsistent\namong servers of swift cluster. Due to this, some of background\nrequests will not be handled.\n\nIn this case, Swift should output appropriate error logs so that\noperators can find the mis-configured server. Unfortunately, in some\ncases, there are no found logs about that, therefore it takes long time\nto find the root cause. In other cases, logger outputs nasty stacktrace\nfor uncaught PolicyError, so operators can find the root cause by\nseeking long, long error logs, but obviously shorter logs are better.\n\nChange-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3\nCloses-Bug: 1375384\n'}, {'number': 5, 'created': '2015-06-08 06:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/30d2f008c24c0e10867b6760a6344030f5f8a1c1', 'message': 'Improvement of logging for invalid policies\n\nBy some operational mistakes, policy settings can be inconsistent\namong servers of swift cluster. Due to this, some of background\nrequests will not be handled.\n\nIn this case, Swift should output appropriate error logs so that\noperators can find the mis-configured server. Unfortunately, in some\ncases, there are no found logs about that, therefore it takes long time\nto find the root cause. This commit improves logging when requested\npolicy is undefined in servers.\n\nChange-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3\nCloses-Bug: 1375384\n'}, {'number': 6, 'created': '2015-06-25 08:41:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3da43fa5b3f582cebc22e999d394d972547dd49a', 'message': 'Improvement of logging for invalid policies\n\nBy some operational mistakes, policy settings can be inconsistent\namong servers of swift cluster. Due to this, some of background\nrequests will not be handled.\n\nIn this case, Swift should output appropriate error logs so that\noperators can find the mis-configured server. Unfortunately, in some\ncases, there are no found logs about that, therefore it takes long time\nto find the root cause. This commit improves logging when requested\npolicy is undefined in servers.\n\nChange-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3\nCloses-Bug: 1375384\n'}, {'number': 7, 'created': '2015-08-10 22:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/20d116ad27b1183e05c2bae44ff9c639ba4030fd', 'message': 'Improvement of logging for invalid policies\n\nBy some operational mistakes, policy settings can be inconsistent\namong servers of swift cluster. Due to this, some of background\nrequests will not be handled.\n\nIn this case, Swift should output appropriate error logs so that\noperators can find the mis-configured server. Unfortunately, in some\ncases, there are no found logs about that, therefore it takes long time\nto find the root cause. This commit improves logging when requested\npolicy is undefined in servers.\n\nChange-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3\nCloses-Bug: 1375384\n'}, {'number': 8, 'created': '2015-08-11 15:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/437d81ff394117cd9f81f701c9c97a77aa6798eb', 'message': 'Improvement of logging for invalid policies\n\nBy some operational mistakes, policy settings can be inconsistent\namong servers of swift cluster. Due to this, some of background\nrequests will not be handled.\n\nIn this case, Swift should output appropriate error logs so that\noperators can find the mis-configured server. Unfortunately, in some\ncases, there are no found logs about that, therefore it takes long time\nto find the root cause. This commit improves logging when requested\npolicy is undefined in servers.\n\nChange-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3\nCloses-Bug: 1375384\n'}, {'number': 9, 'created': '2016-02-25 02:11:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c789d50ec955fe8859c4657efe958513fd499257', 'message': 'Improvement of logging for invalid policies\n\nBy some operational mistakes, policy settings can be inconsistent\namong servers of swift cluster. Due to this, some of background\nrequests will not be handled.\n\nIn this case, Swift should output appropriate error logs so that\noperators can find the mis-configured server. Unfortunately, in some\ncases, there are no found logs about that, therefore it takes long time\nto find the root cause. This commit improves logging when requested\npolicy is undefined in servers.\n\nChange-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3\nCloses-Bug: 1375384\n'}, {'number': 10, 'created': '2016-02-27 03:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d59148a51665e6cb9b3d9d1716d768783c5f368e', 'message': 'Improvement of logging for invalid policies\n\nBy some operational mistakes, policy settings can be inconsistent\namong servers of swift cluster. Due to this, some of background\nrequests will not be handled.\n\nIn this case, Swift should output appropriate error logs so that\noperators can find the mis-configured server. Unfortunately, in some\ncases, there are no found logs about that, therefore it takes long time\nto find the root cause. This commit improves logging when requested\npolicy is undefined in servers.\n\nChange-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3\nCloses-Bug: 1375384\n'}, {'number': 11, 'created': '2016-02-29 09:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/68b27facc846d7a70537d4f00d177c180f072125', 'message': 'Improvement of logging for invalid policies\n\nBy some operational mistakes, policy settings can be inconsistent\namong servers of swift cluster. Due to this, some of background\nrequests will not be handled.\n\nIn this case, Swift should output appropriate error logs so that\noperators can find the mis-configured server. Unfortunately, in some\ncases, there are no found logs about that, therefore it takes long time\nto find the root cause. This commit improves logging when requested\npolicy is undefined in servers.\n\nChange-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3\nCloses-Bug: 1375384\n'}, {'number': 12, 'created': '2016-02-29 16:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2a9d97734ee7d069bea0f70aed94794c4ba68132', 'message': 'Improvement of logging for invalid policies\n\nBy some operational mistakes, policy settings can be inconsistent\namong servers of swift cluster. Due to this, some of background\nrequests will not be handled.\n\nIn this case, Swift should output appropriate error logs so that\noperators can find the mis-configured server. Unfortunately, in some\ncases, there are no found logs about that, therefore it takes long time\nto find the root cause. This commit improves logging when requested\npolicy is undefined in servers.\n\nChange-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3\nCloses-Bug: 1375384\n'}, {'number': 13, 'created': '2016-03-01 09:19:20.000000000', 'files': ['swift/obj/server.py', 'swift/container/server.py', 'test/unit/account/test_utils.py', 'test/unit/proxy/test_server.py', 'test/unit/obj/test_server.py', 'swift/account/utils.py', 'test/unit/container/test_server.py', 'swift/proxy/server.py', 'swift/proxy/controllers/container.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/446995b20d6c920487cc044c1ad21743f32ea69c', 'message': 'Improvement of logging for invalid policies\n\nBy some operational mistakes, policy settings can be inconsistent\namong servers of swift cluster. Due to this, some of background\nrequests will not be handled.\n\nIn this case, Swift should output appropriate error logs so that\noperators can find the mis-configured server. Unfortunately, in some\ncases, there are no found logs about that, therefore it takes long time\nto find the root cause. This commit improves logging when requested\npolicy is undefined in servers.\n\nChange-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3\nCloses-Bug: 1375384\n'}]",30,141238,446995b20d6c920487cc044c1ad21743f32ea69c,65,9,13,8859,,,0,"Improvement of logging for invalid policies

By some operational mistakes, policy settings can be inconsistent
among servers of swift cluster. Due to this, some of background
requests will not be handled.

In this case, Swift should output appropriate error logs so that
operators can find the mis-configured server. Unfortunately, in some
cases, there are no found logs about that, therefore it takes long time
to find the root cause. This commit improves logging when requested
policy is undefined in servers.

Change-Id: I0140375d513d8d6b9af9859299c7a2ed67f64af3
Closes-Bug: 1375384
",git fetch https://review.opendev.org/openstack/swift refs/changes/38/141238/5 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/server.py', 'swift/obj/server.py', 'swift/account/utils.py', 'swift/account/server.py', 'swift/proxy/controllers/account.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/controllers/container.py']",7,01026a68959e8bef3e17032a3640cb36c9d4e4d4,bug/1375384," self.app.logger.error( 'Could not translate %s (%r) from %r to policy', 'X-Storage-Policy', policy_name, req.path)",,81,12
openstack%2Fswift~master~I267a271dd262013e552073babb9092a37da7ade7,openstack/swift,master,I267a271dd262013e552073babb9092a37da7ade7,Add unit test to test cli recon for the commands,NEW,2015-10-28 20:32:32.000000000,2017-12-18 05:01:39.000000000,,"[{'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 13052}, {'_account_id': 15932}, {'_account_id': 18015}, {'_account_id': 18838}]","[{'number': 1, 'created': '2015-10-28 20:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e2bf085f9eaad350ac412dbdf6f87abf83b840b5', 'message': 'Add unit test to test cli recon for the commands\n\nThis patch adds more unit testcases to increase coverage for\nthe commands under the cli recon utility to perform cluster\nreconnaissance.\n\nChange-Id: I267a271dd262013e552073babb9092a37da7ade7\n'}, {'number': 2, 'created': '2015-10-29 15:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c49aed06b293056814aa17c536d5725e9270a0bb', 'message': 'Add unit test to test cli recon for the commands\n\nThis patch adds more unit testcases to increase coverage for\nthe commands under the cli recon utility to perform cluster\nreconnaissance.\n\nChange-Id: I267a271dd262013e552073babb9092a37da7ade7\n'}, {'number': 3, 'created': '2015-10-29 16:33:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8051f6b6b43343cba321a43287b6222f5444f75a', 'message': 'Add unit test to test cli recon for the commands\n\nThis patch adds more unit testcases to increase coverage for\nthe commands under the cli recon utility to perform cluster\nreconnaissance.\n\nChange-Id: I267a271dd262013e552073babb9092a37da7ade7\n'}, {'number': 4, 'created': '2015-10-30 03:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d236f998d23a0865b4adaef46c063f824157ddeb', 'message': 'Add unit test to test cli recon for the commands\n\nThis patch adds more unit testcases to increase coverage for\nthe commands under the cli recon utility to perform cluster\nreconnaissance.\n\nChange-Id: I267a271dd262013e552073babb9092a37da7ade7\n'}, {'number': 5, 'created': '2015-12-04 08:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0a1f12006e5f2ac516e3b4ee79f1c7eb702dff0a', 'message': 'Add unit test to test cli recon for the commands\n\nThis patch adds more unit testcases to increase coverage for\nthe commands under the cli recon utility to perform cluster\nreconnaissance.\n\nChange-Id: I267a271dd262013e552073babb9092a37da7ade7\n'}, {'number': 6, 'created': '2016-01-18 18:35:20.000000000', 'files': ['test/unit/cli/test_recon.py', 'swift/cli/recon.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f80c947e44edd3124a17dbb07c1e65ea0a9b1700', 'message': 'Add unit test to test cli recon for the commands\n\nThis patch adds more unit testcases to increase coverage for\nthe commands under the cli recon utility to perform cluster\nreconnaissance.\n\nChange-Id: I267a271dd262013e552073babb9092a37da7ade7\n'}]",7,240036,f80c947e44edd3124a17dbb07c1e65ea0a9b1700,29,6,6,15932,,,0,"Add unit test to test cli recon for the commands

This patch adds more unit testcases to increase coverage for
the commands under the cli recon utility to perform cluster
reconnaissance.

Change-Id: I267a271dd262013e552073babb9092a37da7ade7
",git fetch https://review.opendev.org/openstack/swift refs/changes/36/240036/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/cli/test_recon.py'],1,e2bf085f9eaad350ac412dbdf6f87abf83b840b5,recon-tests-follow," def test_umount_check(self, mock_print): def dummy_request(*args, **kwargs): return [('http://127.0.0.1:6010/recon/unmounted', [ {""device"": ""sdb1"", ""mounted"": False}, {""device"": ""sdc1"", ""mounted"": False}, {""device"": ""sdd1"", ""mounted"": 'bad'}], 200, 0, 0)] cli = recon.SwiftRecon() cli.pool.imap = dummy_request expected_calls = [ mock.call('Not mounted: sdb1 on 127.0.0.1:6010'), mock.call('Not mounted: sdc1 on 127.0.0.1:6010'), mock.call('Device errors: sdd1 on 127.0.0.1:6010') ] cli.umount_check([('127.0.0.1', 6010)]) mock_print.assert_has_calls(expected_calls) @mock.patch('six.moves.builtins.print')",,23,0
openstack%2Fdiskimage-builder~master~Ib3b3ecaf238447c0ae44b6f23162a01739b38e88,openstack/diskimage-builder,master,Ib3b3ecaf238447c0ae44b6f23162a01739b38e88,Add backports and updates to debootstrap cache,NEW,2016-07-08 17:26:16.000000000,2017-12-18 05:01:37.000000000,,"[{'_account_id': 12459}, {'_account_id': 21741}]","[{'number': 1, 'created': '2016-07-08 17:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c2037927363e1b1b0f533605d7c5ec71e3f43c80', 'message': 'Add backports and updates to debootstrap cache\n\nDebootstrap does not allow specifying custom apt sources and does not\nenable updates or backports. This means that after we do a debootstrap\nwe then have to perform an upgrade of the result. By performing the\nupgrade immediately after debootstrap we can cache that result and speed\nup later image builds.\n\nChange-Id: Ib3b3ecaf238447c0ae44b6f23162a01739b38e88\n'}, {'number': 2, 'created': '2016-07-08 17:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/88aa862ca24aa894d354a88afacc26f719cb679a', 'message': 'Add backports and updates to debootstrap cache\n\nDebootstrap does not allow specifying custom apt sources and does not\nenable updates or backports. This means that after we do a debootstrap\nwe then have to perform an upgrade of the result. By performing the\nupgrade immediately after debootstrap we can cache that result and speed\nup later image builds.\n\nChange-Id: Ib3b3ecaf238447c0ae44b6f23162a01739b38e88\n'}, {'number': 3, 'created': '2016-07-08 21:36:36.000000000', 'files': ['elements/debootstrap/root.d/08-debootstrap', 'elements/ubuntu-minimal/environment.d/10-ubuntu-distro-name.bash'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f27df86656ec9f7dc99dccaa6635e818648f1fc3', 'message': 'Add backports and updates to debootstrap cache\n\nDebootstrap does not allow specifying custom apt sources and does not\nenable updates or backports. This means that after we do a debootstrap\nwe then have to perform an upgrade of the result. By performing the\nupgrade immediately after debootstrap we can cache that result and speed\nup later image builds.\n\nChange-Id: Ib3b3ecaf238447c0ae44b6f23162a01739b38e88\n'}]",0,339730,f27df86656ec9f7dc99dccaa6635e818648f1fc3,10,2,3,10035,,,0,"Add backports and updates to debootstrap cache

Debootstrap does not allow specifying custom apt sources and does not
enable updates or backports. This means that after we do a debootstrap
we then have to perform an upgrade of the result. By performing the
upgrade immediately after debootstrap we can cache that result and speed
up later image builds.

Change-Id: Ib3b3ecaf238447c0ae44b6f23162a01739b38e88
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/30/339730/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/debootstrap/root.d/08-debootstrap', 'elements/ubuntu-minimal/environment.d/10-ubuntu-distro-name.bash']",2,c2037927363e1b1b0f533605d7c5ec71e3f43c80,,"export DIB_DEBOOTSTRAP_APT_SOURCES_UPDATE=""deb $DIB_DISTRIBUTION_MIRROR $DIB_RELEASE main restricted universe \ deb $DIB_DISTRIBUTION_MIRROR $DIB_RELEASE-updates main restricted universe \ deb $DIB_DISTRIBUTION_MIRROR $DIB_RELEASE-backports main restricted universe \ deb $DIB_DISTRIBUTION_MIRROR $DIB_RELEASE-security main restricted universe""",,13,0
openstack%2Fopenstack-health~master~I6565695a4bdfc2846c0d2fd3528140576056ca4f,openstack/openstack-health,master,I6565695a4bdfc2846c0d2fd3528140576056ca4f,WIP: Add runs run_time graph to job page,NEW,2016-06-09 00:19:31.000000000,2017-12-18 05:01:22.000000000,,[],"[{'number': 1, 'created': '2016-06-09 00:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/ed2e6acf17586a07d24651812723591fa071d046', 'message': 'WIP: Add runs run_time graph to job page\n\nThis commit adds a 3rd graph to the jobs page to show the run_time for\nruns in that job over time.\n\nDepends-On: If03ae979092483d8acb7c4aa269dd5a5d0202946\nChange-Id: I6565695a4bdfc2846c0d2fd3528140576056ca4f\n'}, {'number': 2, 'created': '2016-06-11 00:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/f8b1bfcc4e6dddb947c131eaf31ba75d0ed180ce', 'message': 'WIP: Add runs run_time graph to job page\n\nThis commit adds a 3rd graph to the jobs page to show the run_time for\nruns in that job over time.\n\nDepends-On: If03ae979092483d8acb7c4aa269dd5a5d0202946\nChange-Id: I6565695a4bdfc2846c0d2fd3528140576056ca4f\n'}, {'number': 3, 'created': '2016-07-11 04:24:57.000000000', 'files': ['openstack_health/run_aggregator.py', 'openstack_health/api.py', 'app/js/controllers/job.js', 'app/views/job.html'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/9ffaa550109edf778641d4e909c661eae6804d89', 'message': 'WIP: Add runs run_time graph to job page\n\nThis commit adds a 3rd graph to the jobs page to show the run_time for\nruns in that job over time.\n\nDepends-On: Ibc99e87be027b14ba1648fcdd81b80642f5c4080\nChange-Id: I6565695a4bdfc2846c0d2fd3528140576056ca4f\n'}]",0,327432,9ffaa550109edf778641d4e909c661eae6804d89,7,0,3,5196,,,0,"WIP: Add runs run_time graph to job page

This commit adds a 3rd graph to the jobs page to show the run_time for
runs in that job over time.

Depends-On: Ibc99e87be027b14ba1648fcdd81b80642f5c4080
Change-Id: I6565695a4bdfc2846c0d2fd3528140576056ca4f
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/32/327432/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_health/test_run_aggregator.py', 'openstack_health/api.py', 'app/js/controllers/job.js', 'app/views/job.html']",4,ed2e6acf17586a07d24651812723591fa071d046,327432," <div class=row> <div class=""col-lg-12""> <div class=""panel panel-default""> <div class=""panel-heading""> <h3 class=""panel-title"">Run Time</h3> </div> <div class=""panel-body""> <chart-scatter data=""testCtrl.timeData"" width=""100%"" height=""450"" force-y=""[0]"" ></chart-scatter> </div> </div> </div> </div>",,77,6
openstack%2Ftacker~master~Ic1008e79e35356e96344ca14ac4fd74364b3daf0,openstack/tacker,master,Ic1008e79e35356e96344ca14ac4fd74364b3daf0,Fix parameterized TOSCA template,NEW,2016-05-30 12:41:48.000000000,2017-12-18 05:01:04.000000000,,"[{'_account_id': 2874}, {'_account_id': 10487}, {'_account_id': 13485}, {'_account_id': 16034}, {'_account_id': 18955}]","[{'number': 1, 'created': '2016-05-30 12:41:48.000000000', 'files': ['tacker/vm/infra_drivers/heat/heat.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/fcf069afeddebc014407dbe029c8091a2438dbfa', 'message': ""Fix parameterized TOSCA template\n\nThe param values need to be passed as serialized JSON. Otherwise\nwe get a DB error while saving dictionary to hash. Then we need\nto load it and encode it to utf-8, so it's correctly used for\nbuilding the heat template.\n\nChange-Id: Ic1008e79e35356e96344ca14ac4fd74364b3daf0\nCloses-Bug: #1587044\n""}]",2,322805,fcf069afeddebc014407dbe029c8091a2438dbfa,6,5,1,7585,,,0,"Fix parameterized TOSCA template

The param values need to be passed as serialized JSON. Otherwise
we get a DB error while saving dictionary to hash. Then we need
to load it and encode it to utf-8, so it's correctly used for
building the heat template.

Change-Id: Ic1008e79e35356e96344ca14ac4fd74364b3daf0
Closes-Bug: #1587044
",git fetch https://review.opendev.org/openstack/tacker refs/changes/05/322805/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/vm/infra_drivers/heat/heat.py'],1,fcf069afeddebc014407dbe029c8091a2438dbfa,bug/1587044," parsed_params = jsonutils.loads(dev_attrs.pop('param_values', '{}')) for key, value in parsed_params.iteritems(): if isinstance(parsed_params[key], basestring): parsed_params[key] = parsed_params[key].encode('utf-8')"," parsed_params = dev_attrs.pop('param_values', {})",4,1
openstack%2Ftacker~master~Ib3a177627f7693816cf40289334d8e4a31045bef,openstack/tacker,master,Ib3a177627f7693816cf40289334d8e4a31045bef,Add the hacking rules support in tacker,NEW,2016-04-28 07:49:40.000000000,2017-12-18 05:01:01.000000000,,"[{'_account_id': 2874}, {'_account_id': 13485}, {'_account_id': 15755}, {'_account_id': 18955}, {'_account_id': 19726}, {'_account_id': 19950}, {'_account_id': 20378}]","[{'number': 1, 'created': '2016-04-28 07:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/52512609feee7cb8c891525f35c499a7e71a544f', 'message': 'Add the hacking rules support in tacker\n\nAt present,in tacker project there is no hacking rules,\nwe should set up the checking rules step by step for the\nlong-term consideration.And we can use it to do some\nvalidations, prevent some deprecated methods, remove\nsome not used or support in python.\n\nChange-Id: Ib3a177627f7693816cf40289334d8e4a31045bef\nCloses-bug: #1575079\n'}, {'number': 2, 'created': '2016-05-10 02:45:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/1c03356ed0bae7fdba3d358181321c01a70dc124', 'message': 'Add the hacking rules support in tacker\n\nAt present,in tacker project there is no hacking rules,\nwe should set up the checking rules step by step for the\nlong-term consideration.And we can use it to do some\nvalidations, prevent some deprecated methods, remove\nsome not used or support in python.\n\nChange-Id: Ib3a177627f7693816cf40289334d8e4a31045bef\nCloses-bug: #1575079\n'}, {'number': 3, 'created': '2016-05-16 02:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/3f31081a5342ee16db7e5aa0679393673cc5142d', 'message': 'Add the hacking rules support in tacker\n\nAt present,in tacker project there is no hacking rules,\nwe should set up the checking rules step by step for the\nlong-term consideration.And we can use it to do some\nvalidations, prevent some deprecated methods, remove\nsome not used or support in python.\n\nChange-Id: Ib3a177627f7693816cf40289334d8e4a31045bef\nCloses-bug: #1575079\n'}, {'number': 4, 'created': '2016-05-16 03:34:41.000000000', 'files': ['tacker/tests/unit/test_post_mortem_debug.py', 'tacker/tests/unit/test_hacking.py', 'tacker/db/sqlalchemyutils.py', 'tacker/hacking/checks.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/tacker/commit/af9e67e8013591b08a54d753652c2ae3643d5d0f', 'message': 'Add the hacking rules support in tacker\n\nAt present,in tacker project there is no hacking rules,\nwe should set up the checking rules step by step for the\nlong-term consideration.And we can use it to do some\nvalidations, prevent some deprecated methods, remove\nsome not used or support in python.\n\nChange-Id: Ib3a177627f7693816cf40289334d8e4a31045bef\nCloses-bug: #1575079\n'}]",3,310689,af9e67e8013591b08a54d753652c2ae3643d5d0f,21,7,4,19950,,,0,"Add the hacking rules support in tacker

At present,in tacker project there is no hacking rules,
we should set up the checking rules step by step for the
long-term consideration.And we can use it to do some
validations, prevent some deprecated methods, remove
some not used or support in python.

Change-Id: Ib3a177627f7693816cf40289334d8e4a31045bef
Closes-bug: #1575079
",git fetch https://review.opendev.org/openstack/tacker refs/changes/89/310689/3 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/tests/unit/test_post_mortem_debug.py', 'tacker/tests/unit/test_hacking.py', 'tacker/db/sqlalchemyutils.py', 'tacker/hacking/checks.py', 'HACKING.rst']",5,52512609feee7cb8c891525f35c499a7e71a544f,bug/1575079,"This project was ultimately spawned from work done on the Neutron project. As such, we tend to follow Neutron conventions regarding coding style.- [T320] Validate that LOG messages, except debug ones, have translations - [T322] Python 3: Do not use xrange. - [T323] Validate that jsonutils module is used instead of json - [T324] Python 3: Do not use dict.iteritems. - [T325] Python 3: Do not use basestring. - [T326] Prevent use of deprecated contextlib.nested. - [T327] Validate that debug level logs are not translated - [T328] Detect common errors with assert_called_once_with - [T329] Enforce namespace-less imports for oslo libraries - [T330] Method's default argument shouldn't be mutable","- [N320] Validate that LOG messages, except debug ones, have translations ",231,5
openstack%2Fdiskimage-builder~master~Ied06baf7ae5e60a4664ee6016fb3f17f311e756c,openstack/diskimage-builder,master,Ied06baf7ae5e60a4664ee6016fb3f17f311e756c,Add ability to check for mount leaks,NEW,2016-02-14 19:35:21.000000000,2017-12-18 05:00:56.000000000,,"[{'_account_id': 6488}, {'_account_id': 7118}, {'_account_id': 10035}]","[{'number': 1, 'created': '2016-02-14 19:35:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/4825c03be4019e448727526f6e5acd0fe6b2152c', 'message': 'Add ability to check for mount leaks\n\nWe have had bugs in the past where we leak mounts (tmpfs we create, bind\nmounts, etc). We can check for these leaks after a run and error if we\ndetect them, which is useful for CI.\n\nChange-Id: Ied06baf7ae5e60a4664ee6016fb3f17f311e756c\n'}, {'number': 2, 'created': '2016-02-14 19:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/64fe3dc300a03c2403daaae005ae04ba0699f181', 'message': 'Add ability to check for mount leaks\n\nWe have had bugs in the past where we leak mounts (tmpfs we create, bind\nmounts, etc). We can check for these leaks after a run and error if we\ndetect them, which is useful for CI.\n\nChange-Id: Ied06baf7ae5e60a4664ee6016fb3f17f311e756c\n'}, {'number': 3, 'created': '2016-03-02 05:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/02824706ccca6421cfb01a7f532442ad005e16b9', 'message': 'Add ability to check for mount leaks\n\nWe have had bugs in the past where we leak mounts (tmpfs we create, bind\nmounts, etc). We can check for these leaks after a run and error if we\ndetect them, which is useful for CI.\n\nChange-Id: Ied06baf7ae5e60a4664ee6016fb3f17f311e756c\n'}, {'number': 4, 'created': '2016-04-24 15:35:48.000000000', 'files': ['bin/disk-image-create', 'lib/img-functions', 'tests/run_functests.sh', 'lib/common-functions'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/895c26c58994eb64d7e467bc334161590031c60c', 'message': 'Add ability to check for mount leaks\n\nWe have had bugs in the past where we leak mounts (tmpfs we create, bind\nmounts, etc). We can check for these leaks after a run and error if we\ndetect them, which is useful for CI.\n\nChange-Id: Ied06baf7ae5e60a4664ee6016fb3f17f311e756c\n'}]",0,280018,895c26c58994eb64d7e467bc334161590031c60c,18,3,4,10035,,,0,"Add ability to check for mount leaks

We have had bugs in the past where we leak mounts (tmpfs we create, bind
mounts, etc). We can check for these leaks after a run and error if we
detect them, which is useful for CI.

Change-Id: Ied06baf7ae5e60a4664ee6016fb3f17f311e756c
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/18/280018/2 && git format-patch -1 --stdout FETCH_HEAD,"['bin/disk-image-create', 'lib/img-functions', 'lib/common-functions']",3,4825c03be4019e448727526f6e5acd0fe6b2152c,feature/check-mounts,"function check_mounts() { if [ ""$DIB_CHECK_MOUNTS"" != ""0"" ]; then if [ ""$(mount | sha256sum)"" != ""$mounts_hash"" ]; then echo ""ERROR: Mounted filesystems have not been returned to their original state."" exit 1 fi fi } ",,22,1
openstack%2Fironic~master~I648ec29c0d03d5ec3d8f68054121442d1d280ba4,openstack/ironic,master,I648ec29c0d03d5ec3d8f68054121442d1d280ba4,Mock global variables,NEW,2016-07-07 02:57:03.000000000,2017-12-18 05:00:44.000000000,,"[{'_account_id': 6773}, {'_account_id': 7882}, {'_account_id': 13719}, {'_account_id': 19339}]","[{'number': 1, 'created': '2016-07-07 02:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/233bae08caa77599e5ccdc5de3e0cbb917f45cb6', 'message': 'Mock global variables\n\nThis patch set mock global variables instead of assigning values directly to\nthem.\n\nChange-Id: I648ec29c0d03d5ec3d8f68054121442d1d280ba4\n'}, {'number': 2, 'created': '2016-07-07 16:19:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/878d41fba3b0282e1c8873ccffe718a6d141a1a8', 'message': 'Mock global variables\n\nThis patch set mock global variables instead of assigning values directly to\nthem.\n\nChange-Id: I648ec29c0d03d5ec3d8f68054121442d1d280ba4\n'}, {'number': 3, 'created': '2016-07-08 14:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1e2bcecbdd3ff37cfe66d61537e3b748819a0aac', 'message': 'Mock global variables\n\nThis patch set mock global variables instead of assigning values directly to\nthem.\n\nChange-Id: I648ec29c0d03d5ec3d8f68054121442d1d280ba4\n'}, {'number': 4, 'created': '2016-07-12 01:57:42.000000000', 'files': ['ironic/tests/unit/drivers/modules/test_ipmitool.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/161ff5dcd1c4b9981b44acc54ccd67bcc2a1ac38', 'message': 'Mock global variables\n\nThis patch set mock global variables instead of assigning values directly to\nthem.\n\nChange-Id: I648ec29c0d03d5ec3d8f68054121442d1d280ba4\n'}]",15,338665,161ff5dcd1c4b9981b44acc54ccd67bcc2a1ac38,22,4,4,7882,,,0,"Mock global variables

This patch set mock global variables instead of assigning values directly to
them.

Change-Id: I648ec29c0d03d5ec3d8f68054121442d1d280ba4
",git fetch https://review.opendev.org/openstack/ironic refs/changes/65/338665/2 && git format-patch -1 --stdout FETCH_HEAD,['ironic/tests/unit/drivers/modules/test_ipmitool.py'],1,233bae08caa77599e5ccdc5de3e0cbb917f45cb6,mock_globalval," with mock.patch.object(ipmi, 'TMP_DIR_CHECKED'): mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None ipmi.IPMIPower() mock_support.assert_called_with(mock.ANY) mock_check_dir.assert_called_once_with() with mock.patch.object(ipmi, 'TMP_DIR_CHECKED'): mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None mock_check_dir.side_effect = exception.PathNotFound(dir=""foo_dir"") self.assertRaises(exception.PathNotFound, ipmi.IPMIPower) with mock.patch.object(ipmi, 'TMP_DIR_CHECKED'): mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None mock_check_dir.side_effect = exception.DirectoryNotWritable( dir=""foo_dir"") self.assertRaises(exception.DirectoryNotWritable, ipmi.IPMIPower) with mock.patch.object(ipmi, 'TMP_DIR_CHECKED'): mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None mock_check_dir.side_effect = exception.InsufficientDiskSpace( path=""foo_dir"", required=1, actual=0) self.assertRaises(exception.InsufficientDiskSpace, ipmi.IPMIPower) with mock.patch.object(ipmi, 'TMP_DIR_CHECKED'): mock_support.return_value = True ipmi.TMP_DIR_CHECKED = True ipmi.IPMIPower() mock_support.assert_called_with(mock.ANY) self.assertEqual(0, mock_check_dir.call_count) with mock.patch.object(ipmi, 'TMP_DIR_CHECKED'): mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None ipmi.IPMIManagement() mock_support.assert_called_with(mock.ANY) mock_check_dir.assert_called_once_with() with mock.patch.object(ipmi, 'TMP_DIR_CHECKED'): mock_support.return_value = True ipmi.TMP_DIR_CHECKED = False ipmi.IPMIManagement() mock_support.assert_called_with(mock.ANY) self.assertEqual(0, mock_check_dir.call_count) with mock.patch.object(ipmi, 'TMP_DIR_CHECKED'): mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None ipmi.VendorPassthru() mock_support.assert_called_with(mock.ANY) mock_check_dir.assert_called_once_with() with mock.patch.object(ipmi, 'TMP_DIR_CHECKED'): mock_support.return_value = True ipmi.TMP_DIR_CHECKED = True ipmi.VendorPassthru() mock_support.assert_called_with(mock.ANY) self.assertEqual(0, mock_check_dir.call_count) with mock.patch.object(ipmi, 'TMP_DIR_CHECKED'): mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None ipmi.IPMIShellinaboxConsole() mock_support.assert_called_with(mock.ANY) mock_check_dir.assert_called_once_with() with mock.patch.object(ipmi, 'TMP_DIR_CHECKED'): mock_support.return_value = True ipmi.TMP_DIR_CHECKED = True ipmi.IPMIShellinaboxConsole() mock_support.assert_called_with(mock.ANY) self.assertEqual(0, mock_check_dir.call_count)"," mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None ipmi.IPMIPower() mock_support.assert_called_with(mock.ANY) mock_check_dir.assert_called_once_with() mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None mock_check_dir.side_effect = iter( [exception.PathNotFound(dir=""foo_dir"")]) self.assertRaises(exception.PathNotFound, ipmi.IPMIPower) mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None mock_check_dir.side_effect = iter( [exception.DirectoryNotWritable(dir=""foo_dir"")]) self.assertRaises(exception.DirectoryNotWritable, ipmi.IPMIPower) mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None mock_check_dir.side_effect = iter([exception.InsufficientDiskSpace( path=""foo_dir"", required=1, actual=0)]) self.assertRaises(exception.InsufficientDiskSpace, ipmi.IPMIPower) mock_support.return_value = True ipmi.TMP_DIR_CHECKED = True ipmi.IPMIPower() mock_support.assert_called_with(mock.ANY) self.assertEqual(0, mock_check_dir.call_count) mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None ipmi.IPMIManagement() mock_support.assert_called_with(mock.ANY) mock_check_dir.assert_called_once_with() mock_support.return_value = True ipmi.TMP_DIR_CHECKED = False ipmi.IPMIManagement() mock_support.assert_called_with(mock.ANY) self.assertEqual(0, mock_check_dir.call_count) mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None ipmi.VendorPassthru() mock_support.assert_called_with(mock.ANY) mock_check_dir.assert_called_once_with() mock_support.return_value = True ipmi.TMP_DIR_CHECKED = True ipmi.VendorPassthru() mock_support.assert_called_with(mock.ANY) self.assertEqual(0, mock_check_dir.call_count) mock_support.return_value = True ipmi.TMP_DIR_CHECKED = None ipmi.IPMIShellinaboxConsole() mock_support.assert_called_with(mock.ANY) mock_check_dir.assert_called_once_with() mock_support.return_value = True ipmi.TMP_DIR_CHECKED = True ipmi.IPMIShellinaboxConsole() mock_support.assert_called_with(mock.ANY) self.assertEqual(0, mock_check_dir.call_count)",65,57
openstack%2Fironic~master~Id4133ffd17a14639aa3b0f8602bfda0f977ffcf1,openstack/ironic,master,Id4133ffd17a14639aa3b0f8602bfda0f977ffcf1,WIP: Add syslog support,NEW,2016-07-01 09:57:25.000000000,2017-12-18 05:00:41.000000000,,"[{'_account_id': 7882}, {'_account_id': 10118}, {'_account_id': 14525}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}]","[{'number': 1, 'created': '2016-07-01 09:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a62c49ed40b28c1072d3f09adbabf971b2f74df3', 'message': 'WIP: Add syslog support\n\nThis patch configures syslog server to listen and collect\nlogs from remote clients if COLLECT_LOGS_FROM_BOOTSTRAP is set.\nThe logs will be placed in /var/log/remove/<client-ip>/ directory.\n\nChange-Id: Id4133ffd17a14639aa3b0f8602bfda0f977ffcf1\n'}, {'number': 2, 'created': '2016-07-01 13:08:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e347e221305414063c6e8e432814038ab5792688', 'message': 'WIP: Add syslog support\n\nThis patch configures syslog server to listen and collect\nlogs from remote clients if COLLECT_LOGS_FROM_BOOTSTRAP is set.\nThe logs will be placed in /var/log/remove/<client-ip>/ directory.\n\nChange-Id: Id4133ffd17a14639aa3b0f8602bfda0f977ffcf1\n'}, {'number': 3, 'created': '2016-07-01 14:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/62fe06bf1ddf60d584e433776ac407bdd6207b2d', 'message': 'WIP: Add syslog support\n\nThis patch configures syslog server to listen and collect\nlogs from remote clients if COLLECT_LOGS_FROM_BOOTSTRAP is set.\nThe logs will be placed in /var/log/remove/<client-ip>/ directory.\n\nChange-Id: Id4133ffd17a14639aa3b0f8602bfda0f977ffcf1\nDepends-On: I6e52a2fffd7e57447f39674e471d349572d6af2a\n'}, {'number': 4, 'created': '2016-07-04 07:01:43.000000000', 'files': ['devstack/lib/ironic', 'devstack/plugin.sh', 'devstack/files/rpms/ironic', 'devstack/files/debs/ironic', 'devstack/files/30-remote.conf'], 'web_link': 'https://opendev.org/openstack/ironic/commit/93f11b96a5d00e0341f2fcbb4ce39dbffa80c879', 'message': 'WIP: Add syslog support\n\nThis patch configures syslog server to listen and collect\nlogs from remote clients if COLLECT_LOGS_FROM_BOOTSTRAP is set.\nThe logs will be placed in /var/log/remove/<client-ip>/ directory.\n\nChange-Id: Id4133ffd17a14639aa3b0f8602bfda0f977ffcf1\nDepends-On: I6e52a2fffd7e57447f39674e471d349572d6af2a\n'}]",0,336458,93f11b96a5d00e0341f2fcbb4ce39dbffa80c879,24,6,4,14525,,,0,"WIP: Add syslog support

This patch configures syslog server to listen and collect
logs from remote clients if COLLECT_LOGS_FROM_BOOTSTRAP is set.
The logs will be placed in /var/log/remove/<client-ip>/ directory.

Change-Id: Id4133ffd17a14639aa3b0f8602bfda0f977ffcf1
Depends-On: I6e52a2fffd7e57447f39674e471d349572d6af2a
",git fetch https://review.opendev.org/openstack/ironic refs/changes/58/336458/3 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/lib/ironic', 'devstack/plugin.sh', 'devstack/files/rpms/ironic', 'devstack/files/debs/ironic']",4,a62c49ed40b28c1072d3f09adbabf971b2f74df3,syslog,rsyslog,,36,0
openstack%2Ftricircle~master~I990fa46e887cc0822b8e6d74d199d92e39df0bd6,openstack/tricircle,master,I990fa46e887cc0822b8e6d74d199d92e39df0bd6,Distinguish the source of requests,MERGED,2017-11-08 01:40:29.000000000,2017-12-18 04:59:42.000000000,2017-12-18 04:59:42.000000000,"[{'_account_id': 11819}, {'_account_id': 12076}, {'_account_id': 19960}, {'_account_id': 21023}, {'_account_id': 22348}, {'_account_id': 22559}, {'_account_id': 26235}]","[{'number': 1, 'created': '2017-11-08 01:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/e4f9a5ada88607f825c4520e394de2088ef95ba5', 'message': ""Distinguish the source of requests\n\n1. What is the problem?\nWhen receiving a request, we don't know where it's from. In\norder to determine the source of the requests for example\n'local Neutron' or 'Central Neutron'.\n\n2. What is the solution to the problem?\nWe add a filter to get the source message in the header of requests. Next step we tag the source message into the\ncontext. When deploy the WSGI app, using this filter to\ncheckout the source of requests 'local Neutron' or\n'Central Neutron'.\n\n3. What the features need to be implemented to the Tricircle\nto realize the solution?\nNo\n\nChange-Id: I990fa46e887cc0822b8e6d74d199d92e39df0bd6\n""}, {'number': 2, 'created': '2017-11-09 15:37:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/33954028678166f9602c961f2d1de97eb80751b4', 'message': ""Distinguish the source of requests\n\n1. What is the problem?\nWhen receiving a request, we don't know where it's from. In\norder to determine the source of the requests for example\n'local Neutron' or 'Central Neutron'.\n\n2. What is the solution to the problem?\nWe add a filter to get the source message in the header of\nrequests. Next step we tag the source message into the\ncontext. When deploy the WSGI app, using this filter to\ncheckout the source of requests 'local Neutron' or\n'Central Neutron'.\n\n3. What the features need to be implemented to the Tricircle\nto realize the solution?\nNo\n\nChange-Id: I990fa46e887cc0822b8e6d74d199d92e39df0bd6\n""}, {'number': 3, 'created': '2017-11-10 09:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/dfa9294af7325bcec07bd5cdae423ed5f312a8d6', 'message': ""Distinguish the source of requests\n\n1. What is the problem?\nWhen receiving a request, we don't know where it's from. In\norder to determine the source of the requests for example\n'local Neutron' or 'Central Neutron'.\n\n2. What is the solution to the problem?\nWe add a filter to get the source message in the header of\nrequests. Next step we tag the source message into the\ncontext. When deploy the WSGI app, using this filter to\ncheckout the source of requests 'local Neutron' or\n'Central Neutron'.\n\n3. What the features need to be implemented to the Tricircle\nto realize the solution?\nNo\n\nChange-Id: I990fa46e887cc0822b8e6d74d199d92e39df0bd6\n""}, {'number': 4, 'created': '2017-11-12 03:28:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/906bb4443ff75eb3d035ed4a3adad531b7b328eb', 'message': ""Distinguish the source of requests\n\n1. What is the problem?\nWhen receiving a request, we don't know where it's from. In\norder to determine the source of the requests for example\n'local Neutron' or 'Central Neutron'.\n\n2. What is the solution to the problem?\nWe add a filter to get the source message in the header of\nrequests. Next step we tag the source message into the\ncontext. When deploy the WSGI app, using this filter to\ncheckout the source of requests 'local Neutron' or\n'Central Neutron'.\n\n3. What the features need to be implemented to the Tricircle\nto realize the solution?\nNo\n\nChange-Id: I990fa46e887cc0822b8e6d74d199d92e39df0bd6\n""}, {'number': 5, 'created': '2017-11-12 05:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/ddbc1b48ff6f054ae38da310b473c0762977cf12', 'message': ""Distinguish the source of requests\n\n1. What is the problem?\nWhen receiving a request, we don't know where it's from. In\norder to determine the source of the requests for example\n'local Neutron' or 'Central Neutron'.\n\n2. What is the solution to the problem?\nWe add a filter to get the source message in the header of\nrequests. Next step we tag the source message into the\ncontext. When deploy the WSGI app, using this filter to\ncheckout the source of requests 'local Neutron' or\n'Central Neutron'.\n\n3. What the features need to be implemented to the Tricircle\nto realize the solution?\nNo\n\nChange-Id: I990fa46e887cc0822b8e6d74d199d92e39df0bd6\n""}, {'number': 6, 'created': '2017-11-15 13:48:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/fa014a2e642ad9898151d9764d8e86cf3a3416c2', 'message': ""Distinguish the source of requests\n\n1. What is the problem?\nWhen receiving a request, we don't know where it's from. In\norder to determine the source of the requests for example\n'local Neutron' or 'Central Neutron', we add a filter to get\nthe source message in the header of requests.\n2. What is the solution to the problem?\nWe add a filter to get the source message in the header of\nrequests. Next step we tag the source message into the\ncontext. When deploy the WSGI app, using this filter to\ncheckout the source of requests 'Local Neutron' or\n'Central Neutron'.\n\n3. What the features need to be implemented to the Tricircle\nto realize the solution?\nNo\n\nChange-Id: I990fa46e887cc0822b8e6d74d199d92e39df0bd6\n""}, {'number': 7, 'created': '2017-11-16 02:00:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/099a5a3857ed03637c5632a7a89a9e322cb5d0c2', 'message': ""Distinguish the source of requests\n\n1. What is the problem?\nWhen receiving a request, we don't know whether the request\ncomes from  'Central Neutron' or 'Local Neutron'.\n\n2. What is the solution to the problem?\nIn order to determine the source of requests, we add a\nfilter to get the source message in the header of requests.\nNext step we tag the source message into the context. When\ndeploy the WSGI app, we checkout the User-Agent in the\nrequest's headers and tag the requests.\n\n3. What the features need to be implemented to the Tricircle\nto realize the solution?\nNo\n\nChange-Id: I990fa46e887cc0822b8e6d74d199d92e39df0bd6\n""}, {'number': 8, 'created': '2017-11-22 11:51:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/2dda50b9d285f65beefe751b17edb0ec07194446', 'message': ""Distinguish the source of requests\n\n1. What is the problem?\nWhen receiving a request, we don't know whether the request\ncomes from  'Central Neutron' or 'Local Neutron'.\n\n2. What is the solution to the problem?\nIn order to determine the source of requests, we add a\nfilter to get the source message in the header of requests.\nNext step we tag the source message into the context. When\ndeploy the WSGI app, we checkout the User-Agent in the\nrequest's headers and tag the requests.\n\n3. What the features need to be implemented to the Tricircle\nto realize the solution?\nNo\n\nChange-Id: I990fa46e887cc0822b8e6d74d199d92e39df0bd6\n""}, {'number': 9, 'created': '2017-12-03 13:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/06c8b0034c45ef563658adbefdf05f8c05d8feae', 'message': ""Distinguish the source of requests\n\n1. What is the problem?\nWhen receiving a request, we don't know whether the request\ncomes from  'Central Neutron' or 'Local Neutron'.\n\n2. What is the solution to the problem?\nIn order to determine the source of requests, we add a\nfilter to get the source message in the header of requests.\nNext step we tag the source message into the context. When\ndeploy the WSGI app, we checkout the User-Agent in the\nrequest's headers and tag the requests.\n\n3. What the features need to be implemented to the Tricircle\nto realize the solution?\nNo\n\nChange-Id: I990fa46e887cc0822b8e6d74d199d92e39df0bd6\n""}, {'number': 10, 'created': '2017-12-06 08:44:24.000000000', 'files': ['tricircle/common/constants.py', 'tricircle/network/local_plugin.py', 'tricircle/common/request_source.py', 'devstack/plugin.sh', 'tricircle/network/central_plugin.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/27346da0510e9fc23cee54e67088474ca9ad1f2b', 'message': ""Distinguish the source of requests\n\n1. What is the problem?\nWhen receiving a request, we don't know whether the request\ncomes from  'Central Neutron' or 'Local Neutron'.\n\n2. What is the solution to the problem?\nIn order to determine the source of requests, we add a\nfilter to get the source message in the header of requests.\nNext step we tag the source message into the context. When\ndeploy the WSGI app, we checkout the User-Agent in the\nrequest's headers and tag the requests.\n\n3. What the features need to be implemented to the Tricircle\nto realize the solution?\nNo\n\nChange-Id: I990fa46e887cc0822b8e6d74d199d92e39df0bd6\n""}]",32,518421,27346da0510e9fc23cee54e67088474ca9ad1f2b,43,7,10,26235,,,0,"Distinguish the source of requests

1. What is the problem?
When receiving a request, we don't know whether the request
comes from  'Central Neutron' or 'Local Neutron'.

2. What is the solution to the problem?
In order to determine the source of requests, we add a
filter to get the source message in the header of requests.
Next step we tag the source message into the context. When
deploy the WSGI app, we checkout the User-Agent in the
request's headers and tag the requests.

3. What the features need to be implemented to the Tricircle
to realize the solution?
No

Change-Id: I990fa46e887cc0822b8e6d74d199d92e39df0bd6
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/21/518421/10 && git format-patch -1 --stdout FETCH_HEAD,"['tricircle/common/constants.py', 'tricircle/common/request_source.py']",2,e4f9a5ada88607f825c4520e394de2088ef95ba5,tricircle_distinguish_requests,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from neutron_lib import context from oslo_log import log as logging from oslo_middleware import base import webob import constants as cons LOG = logging.getLogger(__name__) class RequestSource(base.ConfigurableMiddleware): """"""RequestSource Middleware This middleware distinguish the source of the requests. It can find out which request is from central Neutron and which is from local Neutron. This middleware will put the source of requests into request.environ, the filter:keystonecontext will update the context using environ, In order to make RequestSource Middleware work, this middleware should place after keystoneContext. """""" def distinguish_requests_source(self, req): request_source_header = req.headers.get(cons.REQUEST_SOURCE, """") if request_source_header: if request_source_header in cons.REQUEST_SOURCE_TYPE: req.environ[cons.REQUEST_SOURCE] = request_source_header ctx = context.Context.from_environ(req.environ) if not ctx.user_id: LOG.debug(""X_USER_ID is not found in request"") return webob.exc.HTTPUnauthorized() # Inject the context... req.environ['neutron.context'] = ctx @webob.dec.wsgify def __call__(self, req): self.distinguish_requests_source(req) response = req.get_response(self.application) return response ",,63,0
openstack%2Fkuryr-libnetwork~master~I222006b16e95db10fdf542eb2a122ce65b6c6f86,openstack/kuryr-libnetwork,master,I222006b16e95db10fdf542eb2a122ce65b6c6f86,move to Keystone v3 support,NEW,2016-07-24 10:09:50.000000000,2017-12-18 04:59:13.000000000,,[{'_account_id': 8279}],"[{'number': 1, 'created': '2016-07-24 10:09:50.000000000', 'files': ['kuryr_libnetwork/tests/unit/test_config.py', 'README.rst', 'devstack/plugin.sh', 'contrib/docker/libnetwork/README.rst', 'kuryr_libnetwork/controllers.py', 'kuryr_libnetwork/common/config.py', 'contrib/docker/libnetwork/Dockerfile', 'contrib/vagrant/config/kuryr_rc'], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/1000328fa4a28414b58a3c40f62cbb81edced25e', 'message': 'move to Keystone v3 support\n\nMoved Kuryr to use Keystone v3 authentication\n  - auth_url changed from v2.0 to v3\n  - renamed tenant_name to project_name\n  - added project_domain_id and user_domain_id params\n\nCloses-Bug: #1563011\nChange-Id: I222006b16e95db10fdf542eb2a122ce65b6c6f86\n'}]",0,346506,1000328fa4a28414b58a3c40f62cbb81edced25e,4,1,1,8279,,,0,"move to Keystone v3 support

Moved Kuryr to use Keystone v3 authentication
  - auth_url changed from v2.0 to v3
  - renamed tenant_name to project_name
  - added project_domain_id and user_domain_id params

Closes-Bug: #1563011
Change-Id: I222006b16e95db10fdf542eb2a122ce65b6c6f86
",git fetch https://review.opendev.org/openstack/kuryr-libnetwork refs/changes/06/346506/1 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_libnetwork/tests/unit/test_config.py', 'README.rst', 'devstack/plugin.sh', 'contrib/docker/libnetwork/README.rst', 'kuryr_libnetwork/controllers.py', 'contrib/docker/libnetwork/Dockerfile', 'kuryr_libnetwork/common/config.py', 'contrib/vagrant/config/kuryr_rc']",8,1000328fa4a28414b58a3c40f62cbb81edced25e,bug/1563011,export SERVICE_PROJECT_NAME=admin export SERVICE_PROJECT_DOMAIN_ID=default export SERVICE_USER_DOMAIN_ID=defaultexport IDENTITY_URL=http://127.0.0.1:5000/v3,export SERVICE_TENANT_NAME=adminexport IDENTITY_URL=http://127.0.0.1:5000/v2.0,50,24
openstack%2Fpython-swiftclient~master~I1da7d1a7b32e626072130944324b7747d8358ee5,openstack/python-swiftclient,master,I1da7d1a7b32e626072130944324b7747d8358ee5,tests: replace assertEqual() with assertIsNone(),NEW,2016-02-15 11:05:31.000000000,2017-12-18 04:58:56.000000000,,"[{'_account_id': 16871}, {'_account_id': 20556}]","[{'number': 1, 'created': '2016-02-15 11:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/0357ae16d590ddebd6db2cb888f8bad2055b1875', 'message': 'tests: replace assertEqual() with assertIsNone()\n\nChange-Id: I1da7d1a7b32e626072130944324b7747d8358ee5\nSigned-off-by: yangds <dongsheng.yang@easystack.cn>\n'}, {'number': 2, 'created': '2016-02-15 11:46:36.000000000', 'files': ['tests/unit/test_service.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/7010ae95d1a257f77e811da7454d59f8199d0758', 'message': 'tests: replace assertEqual() with assertIsNone()\n\nChange-Id: I1da7d1a7b32e626072130944324b7747d8358ee5\n'}]",0,280157,7010ae95d1a257f77e811da7454d59f8199d0758,12,2,2,20556,,,0,"tests: replace assertEqual() with assertIsNone()

Change-Id: I1da7d1a7b32e626072130944324b7747d8358ee5
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/57/280157/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/unit/test_service.py'],1,0357ae16d590ddebd6db2cb888f8bad2055b1875,isNone, self.assertIsNone(spo.options) self.assertIsNone(sr._content_length) self.assertIsNone(sr._expected_etag) self.assertIsNone(sr._content_length) self.assertIsNone(sr._expected_etag) self.assertIsNone(sr._actual_md5) self.assertIsNone(sr._content_length) self.assertIsNone(sr._expected_etag) self.assertIsNone(sr._actual_md5) self.assertIsNone(sr._expected_etag) self.assertIsNone(se.container) self.assertIsNone(se.obj) self.assertIsNone(se.segment) self.assertIsNone(se.exception) self.assertIsNone(suo.options) self.assertIsNone(suo.options) self.assertIsNone(suo.options) self.assertIsNone(suo.source) self.assertIsNone(suo.options)," self.assertEqual(spo.options, None) self.assertEqual(sr._content_length, None) self.assertEqual(sr._expected_etag, None) self.assertEqual(sr._content_length, None) self.assertEqual(sr._expected_etag, None) self.assertEqual(sr._actual_md5, None) self.assertEqual(sr._content_length, None) self.assertEqual(sr._expected_etag, None) self.assertEqual(sr._actual_md5, None) self.assertEqual(sr._expected_etag, None) self.assertEqual(se.container, None) self.assertEqual(se.obj, None) self.assertEqual(se.segment, None) self.assertEqual(se.exception, None) self.assertEqual(suo.options, None) self.assertEqual(suo.options, None) self.assertEqual(suo.options, None) self.assertEqual(suo.source, None) self.assertEqual(suo.options, None)",19,19
openstack%2Fswift~master~I70bea96f02289a0d349fa12785210fe291a871ca,openstack/swift,master,I70bea96f02289a0d349fa12785210fe291a871ca,Add thread level concurrency to container sync,NEW,2015-09-18 21:33:34.000000000,2017-12-18 04:58:54.000000000,,"[{'_account_id': 3094}, {'_account_id': 5600}, {'_account_id': 7002}, {'_account_id': 9816}, {'_account_id': 11317}, {'_account_id': 12193}, {'_account_id': 13052}]","[{'number': 1, 'created': '2015-09-18 21:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0cbf8d1b8b36927850f312f27012b1c30839b5f8', 'message': ""Add thread level concurrency to container sync\n\nThis change introduces a new config option 'threads' to the\ncontainer sync daemon. With threads > 1 the work of syncing a\ncertain container is distributed amongst several threads.\nRecall that multi-processes are used to parallelize the sync of\ndifferent containers. Each process uses a green thread pool, where\ndifferent threads are assigned different rows from the container db.\nWe have also changed the way PUT updates are done so as not to transferre\nan object that has been already synced.\n\nChanges in sync.py:\nThe container_sync method was modified to accommodate multi threading.\nWith the introduction of multiple threads we have quickly ran into\na bottleneck trying to read row by row from the db, and so an additional\nchange is to read rows in bulks. For this we introduce iterators\nover the db that yield rows to sync.\n\nThe container_sync_row method was modified to allow a conditioned put update\nThe condition is meant to prevent sending an object that already exists in\nthe remote side thus saving on BW. The check is done using HEAD with a\n'if-not-match: etag' header\nAn alternative to this check is to modify the PUT to work with e.g.\nExpect 100-continue plus a timestamp or etag. This, however has the\nfollowing drawbacks:\n(1) It means that we may initiate a redundant local GET\n(2) It requires changes on both the server and client side\n    which may be problematic deployment-wise.\nAlso, the object server seem to have built-in support for HEAD with\n'if-not-match: etag' especially for container sync\n\nChanges in test_sync.py:\nTests were updated to test\n(1) The modified structure of container_sync (test_phase_2, test_phase_1).\n(2) The condition introduced to the put updates\n\nChanges in internal_client.py\nAdding a wrapper over SimpleClient for a head operation similar to put / get.\n\nChanges in doc:\nsaio container-server config files were updated to have threads > 1.\nThis allows to test the sync daemon with parallelism while leaving\nthe 1 default so as not to impact the run time behavior in existing\ndeployments.\n\ncontainer-server-sample.conf was added with the threads option.\n\nChange-Id: I70bea96f02289a0d349fa12785210fe291a871ca\nCloses-Bug: #1068426\n""}, {'number': 2, 'created': '2015-09-19 19:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e50afdd257e6d78445582935034466d3a2753611', 'message': ""Add thread level concurrency to container sync\n\nThis change introduces a new config option 'threads' to the\ncontainer sync daemon. With threads > 1 the work of syncing a\ncertain container is distributed amongst several threads.\nRecall that multi-processes are used to parallelize the sync of\ndifferent containers. Each process uses a green thread pool, where\ndifferent threads are assigned different rows from the container db.\nWe have also changed the way PUT updates are done so as not to transferre\nan object that has been already synced.\n\nChanges in sync.py:\nThe container_sync method was modified to accommodate multi threading.\nWith the introduction of multiple threads we have quickly ran into\na bottleneck trying to read row by row from the db, and so an additional\nchange is to read rows in bulks. For this we introduce iterators\nover the db that yield rows to sync.\n\nThe container_sync_row method was modified to allow a conditioned put update\nThe condition is meant to prevent sending an object that already exists in\nthe remote side thus saving on BW. The check is done using HEAD with a\n'if-not-match: etag' header\nAn alternative to this check is to modify the PUT to work with e.g.\nExpect 100-continue plus a timestamp or etag. This, however has the\nfollowing drawbacks:\n(1) It means that we may initiate a redundant local GET\n(2) It requires changes on both the server and client side\n    which may be problematic deployment-wise.\nAlso, the object server seem to have built-in support for HEAD with\n'if-not-match: etag' especially for container sync\n\nChanges in test_sync.py:\nTests were updated to test\n(1) The modified structure of container_sync (test_phase_2, test_phase_1).\n(2) The condition introduced to the put updates\n\nChanges in internal_client.py\nAdding a wrapper over SimpleClient for a head operation similar to put / get.\n\nChanges in doc:\nsaio container-server config files were updated to have threads > 1.\nThis allows to test the sync daemon with parallelism while leaving\nthe 1 default so as not to impact the run time behavior in existing\ndeployments.\n\ncontainer-server-sample.conf was added with the threads option.\n\nChange-Id: I70bea96f02289a0d349fa12785210fe291a871ca\nCloses-Bug: #1068426\n""}, {'number': 3, 'created': '2015-11-23 08:33:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fa908b47dc4c4a9e6f8ade6beda7510a5c1efdfa', 'message': ""Add thread level concurrency to container sync\n\nThis change introduces a new config option 'threads' to the\ncontainer sync daemon. With threads > 1 the work of syncing a\ncertain container is distributed amongst several threads.\nRecall that multi-processes are used to parallelize the sync of\ndifferent containers. Each process uses a green thread pool, where\ndifferent threads are assigned different rows from the container db.\nWe have also changed the way PUT updates are done so as not to transferre\nan object that has been already synced.\n\nIn addition the patch includes a per container stats log that is emitted\nby each daemon as it finishes the processing of a container. These stats\nallow to:\n(1) Monitor the replication progress of each container\n(2) Keep track of deletes, puts, posts (place holder for fast post),\n    and total bytes being replicated per container\nThe stats are updated in the container_sync_row method, and the log is\nemitted in container_sync\n\nChanges in sync.py:\nThe container_sync method was modified to accommodate multi threading.\nWith the introduction of multiple threads we have quickly ran into\na bottleneck trying to read row by row from the db, and so an additional\nchange is to read rows in bulks. For this we introduce iterators\nover the db that yield rows to sync.\n\nThe container_sync_row method was modified to allow a conditioned put update\nThe condition is meant to prevent sending an object that already exists in\nthe remote side thus saving on BW. The check is done using HEAD with a\n'if-not-match: etag' header\nAn alternative to this check is to modify the PUT to work with e.g.\nExpect 100-continue plus a timestamp or etag. This, however has the\nfollowing drawbacks:\n(1) It requires changes on both the server and client side\n    which may be problematic deployment-wise.\n(2) The object server seem to have built-in support for HEAD with\n    'if-not-match: etag' especially for container sync\n\nChanges in test_sync.py:\nTests were updated to test\n(1) The modified structure of container_sync (test_phase_2, test_phase_1).\n(2) The condition introduced to the put updates\n\nChanges in internal_client.py\nAdding a wrapper over SimpleClient for a head operation similar to put / get.\n\nChanges in doc:\nsaio container-server config files were updated to have threads > 1.\nThis allows to test the sync daemon with parallelism while leaving\nthe 1 default so as not to impact the run time behavior in existing\ndeployments.\n\ncontainer-server-sample.conf was added with the threads option.\n\nChange-Id: I70bea96f02289a0d349fa12785210fe291a871ca\nCloses-Bug: #1068426\n""}, {'number': 4, 'created': '2016-03-21 12:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/12d856ec62a572827ac4e038429403b8627d6083', 'message': ""Add thread level concurrency to container sync\n\nThis change introduces a new config option 'threads' to the\ncontainer sync daemon. With threads > 1 the work of syncing a\ncertain container is distributed amongst several (green) threads.\nWe use a green thread pool of size 'threads', where each thread is assigned\na different row from the container db.\n\nChanges in sync.py:\nThe container_sync method was modified to accommodate multi threading.\nWith the introduction of multiple threads we have quickly ran into\na bottleneck trying to read row by row from the db, and so an additional\nchange is to read rows in bulks. For this we introduce iterators\nover the db that yield rows to sync.\n\nChanges in test_sync.py:\nTests were updated to test\n(1) The modified structure of container_sync (test_phase_2, test_phase_1).\n(2) The newly introduced iterators\n\nChanges in doc:\nsaio container-server config files were updated to have threads > 1.\nThis allows to test the sync daemon with parallelism while leaving\nthe 1 default so as not to impact the run time behavior in existing\ndeployments.\n\ncontainer-server-sample.conf was added with the threads option.\n\nChange-Id: I70bea96f02289a0d349fa12785210fe291a871ca\nCloses-Bug: #1068426\n""}, {'number': 5, 'created': '2016-03-23 16:36:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/15442e6142e168d2ff26d13f4aa674045fd4fc6f', 'message': ""Add thread level concurrency to container sync\n\nThis change introduces a new config option 'threads' to the\ncontainer sync daemon. With threads > 1 the work of syncing a\ncertain container is distributed amongst several (green) threads.\nWe use a green thread pool of size 'threads', where each thread is assigned\na different row from the container db.\n\nChanges in sync.py:\nThe container_sync method was modified to accommodate multi threading.\nWith the introduction of multiple threads we have quickly ran into\na bottleneck trying to read row by row from the db, and so an additional\nchange is to read rows in bulks. For this we introduce iterators\nover the db that yield rows to sync.\n\nChanges in test_sync.py:\nTests were updated to test\n(1) The modified structure of container_sync (test_phase_2, test_phase_1).\n(2) The newly introduced iterators\n\nChanges in doc:\nsaio container-server config files were updated to have threads > 1.\nThis allows to test the sync daemon with parallelism while leaving\nthe 1 default so as not to impact the run time behavior in existing\ndeployments.\n\ncontainer-server-sample.conf was added with the threads option.\n\nChange-Id: I70bea96f02289a0d349fa12785210fe291a871ca\nCloses-Bug: #1068426\n""}, {'number': 6, 'created': '2016-03-24 18:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/60954947ea3e87a230b6ea1ac34d1fcec51e6269', 'message': ""Add thread level concurrency to container sync\n\nThis change introduces a new config option 'threads' to the\ncontainer sync daemon. With threads > 1 the work of syncing a\ncertain container is distributed amongst several (green) threads.\nWe use a green thread pool of size 'threads', where each thread is assigned\na different row from the container db.\n\nChanges in sync.py:\nThe container_sync method was modified to accommodate multi threading.\nWith the introduction of multiple threads we have quickly ran into\na bottleneck trying to read row by row from the db, and so an additional\nchange is to read rows in bulks. For this we introduce iterators\nover the db that yield rows to sync.\n\nChanges in test_sync.py:\nTests were updated to test\n(1) The modified structure of container_sync (test_phase_2, test_phase_1).\n(2) The newly introduced iterators\n\nChanges in doc:\nsaio container-server config files were updated to have threads > 1.\nThis allows to test the sync daemon with parallelism while leaving\nthe 1 default so as not to impact the run time behavior in existing\ndeployments.\n\ncontainer-server-sample.conf was added with the threads option.\n\nChange-Id: I70bea96f02289a0d349fa12785210fe291a871ca\nCloses-Bug: #1068426\n""}, {'number': 7, 'created': '2016-03-27 18:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d078484831782445a7fa1968c3ca39a9e27f958d', 'message': ""Add thread level concurrency to container sync\n\nThis change introduces a new config option 'threads' to the\ncontainer sync daemon. With threads > 1 the work of syncing a\ncertain container is distributed amongst several (green) threads.\nWe use a green thread pool of size 'threads', where each thread is assigned\na different row from the container db.\n\nChanges in sync.py:\nThe container_sync method was modified to accommodate multi threading.\nWith the introduction of multiple threads we have quickly ran into\na bottleneck trying to read row by row from the db, and so an additional\nchange is to read rows in bulks. For this we introduce iterators\nover the db that yield rows to sync.\n\nChanges in test_sync.py:\nTests were updated to test\n(1) The modified structure of container_sync (test_phase_2, test_phase_1).\n(2) The newly introduced iterators\n\nChanges in doc:\nsaio container-server config files were updated to have threads > 1.\nThis allows to test the sync daemon with parallelism while leaving\nthe 1 default so as not to impact the run time behavior in existing\ndeployments.\n\ncontainer-server-sample.conf was added with the threads option.\n\nChange-Id: I70bea96f02289a0d349fa12785210fe291a871ca\nCloses-Bug: #1068426\n""}, {'number': 8, 'created': '2016-04-21 11:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/52105ec5ab7694e943c96eea440712f76b781693', 'message': ""Add thread level concurrency to container sync\n\nThis change introduces a new config option 'threads' to the\ncontainer sync daemon. With threads > 1 the work of syncing a\ncertain container is distributed amongst several (green) threads.\nWe use a green thread pool of size 'threads', where each thread is assigned\na different row from the container db.\n\nChanges in sync.py:\nThe container_sync method was modified to accommodate multi threading.\nWith the introduction of multiple threads we have quickly ran into\na bottleneck trying to read row by row from the db, and so an additional\nchange is to read rows in bulks. For this we introduce iterators over the\ndb that yield rows to sync.\n\nChanges in test_sync.py:\nTests were updated to test\n(1) The modified structure of container_sync (test_phase_2, test_phase_1).\n(2) The newly introduced iterators\n\nChanges in doc:\nsaio container-server config files were updated to have threads > 1.\nThis allows to test the sync daemon with parallelism while leaving\nthe 1 default so as not to impact the run time behavior in existing\ndeployments.\n\ncontainer-server-sample.conf was added with the threads option.\n\nChange-Id: I70bea96f02289a0d349fa12785210fe291a871ca\nCloses-Bug: #1068426\n""}, {'number': 9, 'created': '2016-05-02 08:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f2b4138ff3fd6612f8e1f3d43ceb9563954ca1b4', 'message': ""Add thread level concurrency to container sync\n\nThis change introduces a new config option 'threads' to the\ncontainer sync daemon. With threads > 1 the work of syncing a\ncertain container is distributed amongst several (green) threads.\nWe use a green thread pool of size 'threads', where each thread is assigned\na different row from the container db.\n\nChanges in sync.py:\nThe container_sync method was modified to accommodate multi threading.\nWith the introduction of multiple threads we have quickly ran into\na bottleneck trying to read row by row from the db, and so an additional\nchange is to read rows in bulks. For this we introduce iterators over the\ndb that yield rows to sync.\n\nChanges in test_sync.py:\nTests were updated to test\n(1) The modified structure of container_sync (test_phase_2, test_phase_1).\n(2) The newly introduced iterators\n\nChanges in doc:\nsaio container-server config files were updated to have threads > 1.\nThis allows to test the sync daemon with parallelism while leaving\nthe 1 default so as not to impact the run time behavior in existing\ndeployments.\n\ncontainer-server-sample.conf was added with the threads option.\n\nChange-Id: I70bea96f02289a0d349fa12785210fe291a871ca\nCloses-Bug: #1068426\n""}, {'number': 10, 'created': '2016-06-07 15:31:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8bf18bc1eaf4f8990972a6d53de66028b3099a43', 'message': ""Add thread level concurrency to container sync\n\nThis change introduces a new config option 'threads' to the\ncontainer sync daemon. With threads > 1 the work of syncing a\ncertain container is distributed amongst several (green) threads.\nWe use a green thread pool of size 'threads', where each thread is assigned\na different row from the container db.\n\nChanges in sync.py:\nThe container_sync method was modified to accommodate multi threading.\nWith the introduction of multiple threads we have quickly ran into\na bottleneck trying to read row by row from the db, and so an additional\nchange is to read rows in bulks. For this we introduce iterators over the\ndb that yield rows to sync.\n\nChanges in test_sync.py:\nTests were updated to test\n(1) The modified structure of container_sync (test_phase_2, test_phase_1).\n(2) The newly introduced iterators\n\nChanges in doc:\nsaio container-server config files were updated to have threads > 1.\nThis allows to test the sync daemon with parallelism while leaving\nthe 1 default so as not to impact the run time behavior in existing\ndeployments.\n\ncontainer-server-sample.conf was added with the threads option.\n\nChange-Id: I70bea96f02289a0d349fa12785210fe291a871ca\nCloses-Bug: #1068426\n""}, {'number': 11, 'created': '2016-06-23 11:26:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e4ffc1670867cd36e6475fec3271784bf8313cda', 'message': ""Add thread level concurrency to container sync\n\nThis change introduces a new config option 'threads' to the\ncontainer sync daemon. With threads > 1 the work of syncing a\ncertain container is distributed amongst several (green) threads.\nWe use a green thread pool of size 'threads', where each thread is assigned\na different row from the container db.\n\nChanges in sync.py:\nThe container_sync method was modified to accommodate multi threading.\nWith the introduction of multiple threads we have quickly ran into\na bottleneck trying to read row by row from the db, and so an additional\nchange is to read rows in bulks. For this we introduce iterators over the\ndb that yield rows to sync.\n\nChanges in test_sync.py:\nTests were updated to test\n(1) The modified structure of container_sync (test_phase_2, test_phase_1).\n(2) The newly introduced iterators\n\nChanges in doc:\nsaio container-server config files were updated to have threads > 1.\nThis allows to test the sync daemon with parallelism while leaving\nthe 1 default so as not to impact the run time behavior in existing\ndeployments.\n\ncontainer-server-sample.conf was added with the threads option.\n\nChange-Id: I70bea96f02289a0d349fa12785210fe291a871ca\nCloses-Bug: #1068426\n""}, {'number': 12, 'created': '2016-06-26 08:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fe7a2128f658bd741b3c003ab5a738a6b5735c5d', 'message': ""Add thread level concurrency to container sync\n\nThis change introduces a new config option 'threads' to the\ncontainer sync daemon. With threads > 1 the work of syncing a\ncertain container is distributed amongst several (green) threads.\nWe use a green thread pool of size 'threads', where each thread is assigned\na different row from the container db.\n\nChanges in sync.py:\nThe container_sync method was modified to accommodate multi threading.\nWith the introduction of multiple threads we have quickly ran into\na bottleneck trying to read row by row from the db, and so an additional\nchange is to read rows in bulks. For this we introduce iterators over the\ndb that yield rows to sync.\n\nChanges in test_sync.py:\nTests were updated to test\n(1) The modified structure of container_sync (test_phase_2, test_phase_1).\n(2) The newly introduced iterators\n\nChanges in doc:\nsaio container-server config files were updated to have threads > 1.\nThis allows to test the sync daemon with parallelism while leaving\nthe 1 default so as not to impact the run time behavior in existing\ndeployments.\n\ncontainer-server-sample.conf was added with the threads option.\n\nChange-Id: I70bea96f02289a0d349fa12785210fe291a871ca\nCloses-Bug: #1068426\n""}, {'number': 13, 'created': '2016-07-27 11:47:49.000000000', 'files': ['doc/saio/swift/container-server/3.conf', 'swift/container/sync.py', 'doc/saio/swift/container-server/1.conf', 'etc/container-server.conf-sample', 'test/unit/container/test_sync.py', 'doc/saio/swift/container-server/2.conf', 'doc/saio/swift/container-server/4.conf', 'test/probe/test_container_sync.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/d21446264ebcb368c10c46c15379f23a80b9e0f6', 'message': ""Add thread level concurrency to container sync\n\nThis change introduces a new config option 'threads' to the\ncontainer sync daemon. With threads > 1 the work of syncing a\ncertain container is distributed amongst several (green) threads.\nWe use a green thread pool of size 'threads', where each thread is assigned\na different row from the container db.\n\nChanges in sync.py:\nThe container_sync method was modified to accommodate multi threading.\nWith the introduction of multiple threads we have quickly ran into\na bottleneck trying to read row by row from the db, and so an additional\nchange is to read rows in bulks. For this we introduce iterators over the\ndb that yield rows to sync.\n\nChanges in test_sync.py:\nTests were updated to test\n(1) The modified structure of container_sync (test_phase_2, test_phase_1).\n(2) The newly introduced iterators\n\nChanges in doc:\nsaio container-server config files were updated to have threads > 1.\nThis allows to test the sync daemon with parallelism while leaving\nthe 1 default so as not to impact the run time behavior in existing\ndeployments.\n\ncontainer-server-sample.conf was added with the threads option.\n\nChange-Id: I70bea96f02289a0d349fa12785210fe291a871ca\nCloses-Bug: #1068426\n""}]",11,225338,d21446264ebcb368c10c46c15379f23a80b9e0f6,54,7,13,11317,,,0,"Add thread level concurrency to container sync

This change introduces a new config option 'threads' to the
container sync daemon. With threads > 1 the work of syncing a
certain container is distributed amongst several (green) threads.
We use a green thread pool of size 'threads', where each thread is assigned
a different row from the container db.

Changes in sync.py:
The container_sync method was modified to accommodate multi threading.
With the introduction of multiple threads we have quickly ran into
a bottleneck trying to read row by row from the db, and so an additional
change is to read rows in bulks. For this we introduce iterators over the
db that yield rows to sync.

Changes in test_sync.py:
Tests were updated to test
(1) The modified structure of container_sync (test_phase_2, test_phase_1).
(2) The newly introduced iterators

Changes in doc:
saio container-server config files were updated to have threads > 1.
This allows to test the sync daemon with parallelism while leaving
the 1 default so as not to impact the run time behavior in existing
deployments.

container-server-sample.conf was added with the threads option.

Change-Id: I70bea96f02289a0d349fa12785210fe291a871ca
Closes-Bug: #1068426
",git fetch https://review.opendev.org/openstack/swift refs/changes/38/225338/5 && git format-patch -1 --stdout FETCH_HEAD,"['doc/saio/swift/container-server/3.conf', 'swift/container/sync.py', 'doc/saio/swift/container-server/1.conf', 'etc/container-server.conf-sample', 'test/unit/container/test_sync.py', 'doc/saio/swift/container-server/2.conf', 'doc/saio/swift/container-server/4.conf', 'swift/common/internal_client.py']",8,0cbf8d1b8b36927850f312f27012b1c30839b5f8,bug/1068426,"def head_object(url, **kwargs): """"""For usage with container sync """""" client = SimpleClient(url=url) client.retry_request('HEAD', **kwargs) ",,578,59
openstack%2Fpython-tackerclient~master~Iabca4cf9c83afc5ebece7d9fd5098386e5c5943d,openstack/python-tackerclient,master,Iabca4cf9c83afc5ebece7d9fd5098386e5c5943d,Switch from keystoneclient to keystoneauth,NEW,2016-07-20 07:23:09.000000000,2017-12-18 04:57:45.000000000,,[{'_account_id': 22132}],"[{'number': 1, 'created': '2016-07-20 07:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/edc61224c60e39ef641f64e7e6055c6c16d69325', 'message': ""Switch from keystoneclient to keystoneauth\n\nThis patch has moved tackerclient to keystoneauth as\nkeystoneclient's auth session, plugins,and adapter code\nhas been deprecated.\nFor more information,here is links:\nhttp://docs.openstack.org/developer/keystoneauth/migrating.html\n\nChange-Id: Iabca4cf9c83afc5ebece7d9fd5098386e5c5943d\n""}, {'number': 2, 'created': '2016-07-20 07:40:46.000000000', 'files': ['requirements.txt', 'tackerclient/client.py', 'tackerclient/shell.py', 'tackerclient/tests/unit/test_auth.py'], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/bd50b8d657e23b0083022bc1d972cb5be918fc58', 'message': ""Switch from keystoneclient to keystoneauth\n\nThis patch has moved tackerclient to keystoneauth as\nkeystoneclient's auth session, plugins,and adapter code\nhas been deprecated.\nFor more information,here is links:\nhttp://docs.openstack.org/developer/keystoneauth/migrating.html\n\nChange-Id: Iabca4cf9c83afc5ebece7d9fd5098386e5c5943d\n""}]",0,344592,bd50b8d657e23b0083022bc1d972cb5be918fc58,6,1,2,22132,,,0,"Switch from keystoneclient to keystoneauth

This patch has moved tackerclient to keystoneauth as
keystoneclient's auth session, plugins,and adapter code
has been deprecated.
For more information,here is links:
http://docs.openstack.org/developer/keystoneauth/migrating.html

Change-Id: Iabca4cf9c83afc5ebece7d9fd5098386e5c5943d
",git fetch https://review.opendev.org/openstack/python-tackerclient refs/changes/92/344592/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'tackerclient/client.py', 'tackerclient/shell.py', 'tackerclient/tests/unit/test_auth.py']",4,edc61224c60e39ef641f64e7e6055c6c16d69325,keystoneclient_migrating,from keystoneauth1 import exceptions as k_exceptions,from keystoneclient import exceptions as k_exceptions,11,14
openstack%2Fswift~master~I0c532d1111b934e6c6415663f28cc0effdab8420,openstack/swift,master,I0c532d1111b934e6c6415663f28cc0effdab8420,Always reset epoch when reseting last_part_moves,NEW,2016-07-25 18:39:41.000000000,2017-12-18 04:57:38.000000000,,"[{'_account_id': 7233}, {'_account_id': 22059}]","[{'number': 1, 'created': '2016-07-25 18:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/273eeab84a25f3352dd8639179613fd1d8a97d4c', 'message': ""Always reset epoch when reseting last_part_moves\n\nThe _last_part_moves array in the ring isn't initialized until initial\nrebalance, so we can't reset it.  But since pretend_min_part_hours\nresets a couple pieces of state we should keep the reset behavior as\nconsistent and atomic as possible to avoid future bugs.\n\nChange-Id: I0c532d1111b934e6c6415663f28cc0effdab8420\n""}, {'number': 2, 'created': '2016-07-28 20:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2e9a54b0c053ef933fde93befa3763e47a640672', 'message': ""Always reset epoch when reseting last_part_moves\n\nThe _last_part_moves array in the ring isn't initialized until initial\nrebalance, so we can't reset it.  But since pretend_min_part_hours\nresets a couple pieces of state we should keep the reset behavior as\nconsistent and atomic as possible to avoid future bugs.\n\nN.B. before the Realted-Change this used to just TypeError\n\nRelated-Change: Ic83c7a338b45bfcf61f5ab6100e6db335c3fa81a\nChange-Id: I0c532d1111b934e6c6415663f28cc0effdab8420\n""}, {'number': 3, 'created': '2016-08-01 00:54:30.000000000', 'files': ['swift/common/ring/builder.py', 'test/unit/common/ring/test_builder.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/0fbfd4e688b166afbf3c5c83e6ae334f4f8f7379', 'message': ""Always reset epoch when reseting last_part_moves\n\nThe _last_part_moves array in the ring isn't initialized until initial\nrebalance, so we can't reset it.  But since pretend_min_part_hours\nresets a couple pieces of state we should keep the reset behavior as\nconsistent and atomic as possible to avoid future bugs.\n\nN.B. before the Related-Change this used to just TypeError\n\nRelated-Change: Ic83c7a338b45bfcf61f5ab6100e6db335c3fa81a\nChange-Id: I0c532d1111b934e6c6415663f28cc0effdab8420\n""}]",2,346979,0fbfd4e688b166afbf3c5c83e6ae334f4f8f7379,11,2,3,1179,,,0,"Always reset epoch when reseting last_part_moves

The _last_part_moves array in the ring isn't initialized until initial
rebalance, so we can't reset it.  But since pretend_min_part_hours
resets a couple pieces of state we should keep the reset behavior as
consistent and atomic as possible to avoid future bugs.

N.B. before the Related-Change this used to just TypeError

Related-Change: Ic83c7a338b45bfcf61f5ab6100e6db335c3fa81a
Change-Id: I0c532d1111b934e6c6415663f28cc0effdab8420
",git fetch https://review.opendev.org/openstack/swift refs/changes/79/346979/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/ring/builder.py', 'test/unit/common/ring/test_builder.py']",2,273eeab84a25f3352dd8639179613fd1d8a97d4c,bug/1578835,"import time def test_create_pretend_min_part_hours_passed(self): rb = ring.RingBuilder(8, 3, 1) # sanity self.assertEqual(rb._last_part_moves_epoch, 0) self.assertEqual(None, rb._last_part_moves) # unexpected internal state change rb._last_part_moves_epoch = int(time.time()) rb.pretend_min_part_hours_passed() # always reset self.assertEqual(rb._last_part_moves_epoch, 0) # ... even if the array is uninitialized self.assertEqual(None, rb._last_part_moves) ",,17,4
openstack%2Fglance_store~master~Iee2887a1fb5cfccdaab8cb6a87c54c2a55253e10,openstack/glance_store,master,Iee2887a1fb5cfccdaab8cb6a87c54c2a55253e10,WIP: remove configs related to old style swift url,NEW,2016-08-08 20:30:19.000000000,2017-12-18 04:57:20.000000000,,[],"[{'number': 1, 'created': '2016-08-08 20:30:19.000000000', 'files': ['glance_store/_drivers/swift/utils.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/c0d9d424c0991d6f30c548107609ff9f03a0b5bf', 'message': 'WIP: remove configs related to old style swift url\n\nChange-Id: Iee2887a1fb5cfccdaab8cb6a87c54c2a55253e10\n'}]",0,352593,c0d9d424c0991d6f30c548107609ff9f03a0b5bf,3,0,1,2537,,,0,"WIP: remove configs related to old style swift url

Change-Id: Iee2887a1fb5cfccdaab8cb6a87c54c2a55253e10
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/93/352593/1 && git format-patch -1 --stdout FETCH_HEAD,['glance_store/_drivers/swift/utils.py'],1,c0d9d424c0991d6f30c548107609ff9f03a0b5bf,remove-deprecated-swift-configs, raise exceptions.BadStoreConfiguration()," cfg.StrOpt('swift_store_auth_version', default='2', help=_('Version of the authentication service to use. ' 'Valid versions are 2 and 3 for keystone and 1 ' '(deprecated) for swauth and rackspace.'), deprecated_for_removal=True, deprecated_reason=_('Use ""auth_version"" in ' 'swift_store_config_file.')), cfg.StrOpt('swift_store_auth_address', help=_('The address where the Swift authentication ' 'service is listening.'), deprecated_for_removal=True, deprecated_reason=_('Use ""auth_address"" in ' 'swift_store_config_file')), cfg.StrOpt('swift_store_user', secret=True, help=_('The user to authenticate against the Swift ' 'authentication service.'), deprecated_for_removal=True, deprecated_reason=_('Use ""user"" in ' 'swift_store_config_file.')), cfg.StrOpt('swift_store_key', secret=True, help=_('Auth key for the user authenticating against the ' 'Swift authentication service.'), deprecated_for_removal=True, deprecated_reason=_('Use ""key"" in ' 'swift_store_config_file.') ), self.params = self._form_default_params() def _form_default_params(self): default = {} if ( self.conf.glance_store.swift_store_user and self.conf.glance_store.swift_store_key and self.conf.glance_store.swift_store_auth_address ): glance_store = self.conf.glance_store default['user'] = glance_store.swift_store_user default['key'] = glance_store.swift_store_key default['auth_address'] = glance_store.swift_store_auth_address default['project_domain_id'] = 'default' default['project_domain_name'] = None default['user_domain_id'] = 'default' default['user_domain_name'] = None default['auth_version'] = glance_store.swift_store_auth_version return {glance_store.default_swift_reference: default} return {}",1,48
openstack%2Fpython-tackerclient~master~Ibbe38d051ebf2a1beac89485aa163108eaa3cfec,openstack/python-tackerclient,master,Ibbe38d051ebf2a1beac89485aa163108eaa3cfec,Add comma to dicts/lists,NEW,2016-07-19 12:14:35.000000000,2017-12-18 04:57:03.000000000,,"[{'_account_id': 13380}, {'_account_id': 18955}, {'_account_id': 22132}]","[{'number': 1, 'created': '2016-07-19 12:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/b5a3ead2bcbb7b8eb9b4529afa688745c3aad23d', 'message': 'Add comma to dicts/lists\n\nThe last item in the dictionary should have a\ntrailing comma. This increases readability and simplifies\nfuture diffs.I think this is a good OpenStack style.I have\ntried my best to modify it.\n\nChange-Id: Ibbe38d051ebf2a1beac89485aa163108eaa3cfec\n'}, {'number': 2, 'created': '2016-07-20 01:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/2ca43a870817495daeac0ed6e67229476705113a', 'message': 'Add comma to dicts/lists\n\nThe last item in the dictionary should have a\ntrailing comma. This increases readability and simplifies\nfuture diffs.So I think this is a good OpenStack style.\n\nChange-Id: Ibbe38d051ebf2a1beac89485aa163108eaa3cfec\n'}, {'number': 3, 'created': '2016-08-04 05:42:34.000000000', 'files': ['tackerclient/tacker/v1_0/__init__.py', 'tackerclient/tests/unit/test_cli10.py', 'tackerclient/tests/unit/test_cli10_extensions.py', 'tackerclient/client.py', 'tackerclient/shell.py', 'tackerclient/tests/unit/vm/test_cli10_vim.py', 'tackerclient/tests/unit/vm/test_cli10_vnfd.py', 'tackerclient/tests/unit/test_shell.py', 'tackerclient/tests/unit/test_utils.py', 'tackerclient/tests/unit/test_ssl.py', 'tackerclient/tests/unit/vm/test_cli10_vnf.py', 'tackerclient/tests/unit/test_auth.py'], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/65fee799226ff1bf013f98d70e571722a30ff573', 'message': 'Add comma to dicts/lists\n\nThe last item in the dictionary should have a\ntrailing comma. This increases readability and simplifies\nfuture diffs.So I think this is a good OpenStack style.\n\nChange-Id: Ibbe38d051ebf2a1beac89485aa163108eaa3cfec\n'}]",0,344198,65fee799226ff1bf013f98d70e571722a30ff573,15,3,3,22132,,,0,"Add comma to dicts/lists

The last item in the dictionary should have a
trailing comma. This increases readability and simplifies
future diffs.So I think this is a good OpenStack style.

Change-Id: Ibbe38d051ebf2a1beac89485aa163108eaa3cfec
",git fetch https://review.opendev.org/openstack/python-tackerclient refs/changes/98/344198/2 && git format-patch -1 --stdout FETCH_HEAD,"['tackerclient/tacker/v1_0/__init__.py', 'tackerclient/tests/unit/test_cli10.py', 'tackerclient/tests/unit/test_cli10_extensions.py', 'tackerclient/client.py', 'tackerclient/shell.py', 'tackerclient/tests/unit/vm/test_cli10_vim.py', 'tackerclient/tests/unit/vm/test_cli10_vnfd.py', 'tackerclient/tests/unit/test_shell.py', 'tackerclient/tests/unit/test_utils.py', 'tackerclient/tests/unit/test_ssl.py', 'tackerclient/tests/unit/vm/test_cli10_vnf.py', 'tackerclient/tests/unit/test_auth.py']",12,b5a3ead2bcbb7b8eb9b4529afa688745c3aad23d,add_comma_for_dics/lists," 'tenant': {'id': str(uuid.uuid1()), }, }, 'user': {'id': str(uuid.uuid1()), }, 'region': REGION, }], 'name': 'Tacker Service', } }, 'publicURL': ENDPOINT_URL, }, ] 'endpoint_url': self.client.endpoint_url, }"," 'tenant': {'id': str(uuid.uuid1())}}, 'user': {'id': str(uuid.uuid1())}, 'region': REGION}], 'name': 'Tacker Service'} } 'publicURL': ENDPOINT_URL }] 'endpoint_url': self.client.endpoint_url}",72,72
openstack%2Fironic~master~Ieab877b8eb558820a3c2e6a767ebdbf02aa744c8,openstack/ironic,master,Ieab877b8eb558820a3c2e6a767ebdbf02aa744c8,[WIP] [POC] Torrent based image provisioning,NEW,2016-02-10 15:49:40.000000000,2017-12-18 04:57:00.000000000,,"[{'_account_id': 2889}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 8259}, {'_account_id': 9542}, {'_account_id': 10118}, {'_account_id': 12356}, {'_account_id': 14525}, {'_account_id': 14629}, {'_account_id': 17998}, {'_account_id': 18893}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-02-10 15:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7d41e9f23764c9c51057c7aeba8186750bd8f679', 'message': '[WIP] Torrent based image provisioning\n\nChange-Id: Ieab877b8eb558820a3c2e6a767ebdbf02aa744c8\n'}, {'number': 2, 'created': '2016-02-11 14:37:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0100198e6b971113e85041a1aa3d8586f650948b', 'message': '[WIP] Torrent based image provisioning\n\nChange-Id: Ieab877b8eb558820a3c2e6a767ebdbf02aa744c8\n'}, {'number': 3, 'created': '2016-02-12 15:41:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/56510598e0b6151da32c7d26f82fb3affa949738', 'message': '[WIP] Torrent based image provisioning\n\nChange-Id: Ieab877b8eb558820a3c2e6a767ebdbf02aa744c8\n'}, {'number': 4, 'created': '2016-02-12 22:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fdf66fb43f9cc493bbaef58620a90a737d104fd9', 'message': '[WIP] Torrent based image provisioning\n\nChange-Id: Ieab877b8eb558820a3c2e6a767ebdbf02aa744c8\n'}, {'number': 5, 'created': '2016-03-07 10:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/84d00a123e466613c142bd68cdc14ab335298ec4', 'message': '[WIP] Torrent based image provisioning\n\nChange-Id: Ieab877b8eb558820a3c2e6a767ebdbf02aa744c8\n'}, {'number': 6, 'created': '2016-04-26 14:31:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/41b30ad9190469fd2c51935b73de7b6f491d577e', 'message': '[WIP] [POC] Torrent based image provisioning\n\nChange-Id: Ieab877b8eb558820a3c2e6a767ebdbf02aa744c8\n'}, {'number': 7, 'created': '2016-04-27 16:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4592b63f738572e54d3ee2fe20ba997fcb01f5c5', 'message': '[WIP] [POC] Torrent based image provisioning\n\nChange-Id: Ieab877b8eb558820a3c2e6a767ebdbf02aa744c8\n'}, {'number': 8, 'created': '2016-04-28 15:04:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0b20b29b9f41a1824de95ea38c1abe0940040636', 'message': '[WIP] [POC] Torrent based image provisioning\n\nChange-Id: Ieab877b8eb558820a3c2e6a767ebdbf02aa744c8\n'}, {'number': 9, 'created': '2016-06-10 10:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/17f5fc1061b426b45271bfac9d3460f402402744', 'message': '[WIP] [POC] Torrent based image provisioning\n\nChange-Id: Ieab877b8eb558820a3c2e6a767ebdbf02aa744c8\n'}, {'number': 10, 'created': '2016-06-29 14:06:32.000000000', 'files': ['ironic/drivers/modules/agent.py', 'requirements.txt', 'ironic/common/bittorrent.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/83ca2fd24fc71876e65971f92a8834fd24c970b1', 'message': '[WIP] [POC] Torrent based image provisioning\n\nChange-Id: Ieab877b8eb558820a3c2e6a767ebdbf02aa744c8\n'}]",9,278469,83ca2fd24fc71876e65971f92a8834fd24c970b1,80,12,10,8259,,,0,"[WIP] [POC] Torrent based image provisioning

Change-Id: Ieab877b8eb558820a3c2e6a767ebdbf02aa744c8
",git fetch https://review.opendev.org/openstack/ironic refs/changes/69/278469/7 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/agent.py', 'ironic/common/swift.py', 'ironic/common/bittorrent.py']",3,7d41e9f23764c9c51057c7aeba8186750bd8f679,torrent,"# coding=utf-8 # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from copy import deepcopy import libtorrent import random from oslo_config import cfg from oslo_log import log from ironic.common import swift CONF = cfg.CONF bittorrent_opts = [ cfg.ListOpt('trackers', help=_('The list of trackers.')), cfg.IntOpt('client_seed_time', default=0, help=_('Time to stay on seeding when image downloaded (minutes).')), cfg.StrOpt('image_torrents_container', default='glance_torrents', help=_('Swift container with torrent files for images.')), cfg.StrOpt('node_torrents_container', default='ironic_torrents', help=_('Swift container with torrent files for nodes.')), ] CONF.register_opts(bittorrent_opts, group='bittorrent') LOG = log.getLogger(__name__) def _set_trackers(torrent, trackers): shuffled_trackers = deepcopy(trackers) random.shuffle(shuffled_trackers) decoded_data = libtorrent.bdecode(torrent) decoded_data['announce'] = shuffled_trackers.pop(0) if len(shuffled_trackers): decoded_data['announce-list'] = shuffled_trackers return libtorrent.bencode(decoded_data) def make_torrent_link(image_id, node_uuid): swift_api = swift.SwiftAPI() image_torrent = swift_api.get_object(CONF.bittorrent.image_torrents_container, image_id + '.torrent') node_torrent = _set_trackers(image_torrent, CONF.bittorrent.trackers) swift_api.upload_object(CONF.bittorrent.node_torrents_container, node_uuid + '.torrent', node_torrent) return swift_api.get_temp_url(CONF.bittorrent.node_torrents_container, node_uuid + '.torrent', 3600) ",,87,1
openstack%2Fdiskimage-builder~master~Ifb0fefe0580278281b6ed56c0c155211c234882c,openstack/diskimage-builder,master,Ifb0fefe0580278281b6ed56c0c155211c234882c,Make baseline-tools use pkg-map,NEW,2016-07-08 21:48:36.000000000,2017-12-18 04:56:43.000000000,,"[{'_account_id': 10035}, {'_account_id': 12459}]","[{'number': 1, 'created': '2016-07-08 21:48:36.000000000', 'files': ['elements/base/package-installs.yaml', 'elements/base/pkg-map', 'elements/base/pre-install.d/03-baseline-tools'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/59a5b8b2120e732e69ff8defd4a47afba1979d34', 'message': 'Make baseline-tools use pkg-map\n\nWe install add-apt-repository as part of the base element without using\npackage-installs. At the time we did not support release name mapping\nfor package-installs, but we do now, so lets use it.\n\nChange-Id: Ifb0fefe0580278281b6ed56c0c155211c234882c\n'}]",0,339834,59a5b8b2120e732e69ff8defd4a47afba1979d34,8,2,1,10035,,,0,"Make baseline-tools use pkg-map

We install add-apt-repository as part of the base element without using
package-installs. At the time we did not support release name mapping
for package-installs, but we do now, so lets use it.

Change-Id: Ifb0fefe0580278281b6ed56c0c155211c234882c
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/34/339834/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/base/package-installs.yaml', 'elements/base/pkg-map', 'elements/base/pre-install.d/03-baseline-tools']",3,59a5b8b2120e732e69ff8defd4a47afba1979d34,,,"#!/bin/bash # Install baseline packages and tools. if [ ${DIB_DEBUG_TRACE:-0} -gt 0 ]; then set -x fi set -eu set -o pipefail case $DISTRO_NAME in 'ubuntu'|'debian') # Note: add-apt-repository would be nice for RPM platforms too - so when we # need something like it, create a wrapper in dpkg/bin and fedora/bin. apt-get -y update if [ ""${DIB_RELEASE}"" = ""precise"" ]; then install-packages python-software-properties else install-packages software-properties-common fi ;; esac ",14,22
openstack%2Fjs-openstack-lib~master~Ie065b3f8b4aa89c97da458dbc95f94565bce06fe,openstack/js-openstack-lib,master,Ie065b3f8b4aa89c97da458dbc95f94565bce06fe,[WIP] OpenStack wrapper instance,NEW,2016-08-09 22:38:13.000000000,2017-12-18 04:56:39.000000000,,[{'_account_id': 8614}],"[{'number': 1, 'created': '2016-08-09 22:38:13.000000000', 'files': ['src/index.js', 'test/unit/indexTest.js'], 'web_link': 'https://opendev.org/openstack/js-openstack-lib/commit/3126ee1ce0b38a59b538bbad63658bcc350d6424', 'message': ""[WIP] OpenStack wrapper instance\n\nAn single wrapper instance that permits access to all of a cloud's\nfeatures.\n\nChange-Id: Ie065b3f8b4aa89c97da458dbc95f94565bce06fe\n""}]",0,353133,3126ee1ce0b38a59b538bbad63658bcc350d6424,4,1,1,9717,,,0,"[WIP] OpenStack wrapper instance

An single wrapper instance that permits access to all of a cloud's
features.

Change-Id: Ie065b3f8b4aa89c97da458dbc95f94565bce06fe
",git fetch https://review.opendev.org/openstack/js-openstack-lib refs/changes/33/353133/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/index.js', 'test/unit/indexTest.js']",2,3126ee1ce0b38a59b538bbad63658bcc350d6424,single_config_keystone,"import OpenStack from ""../../src/index""; const config = { region_name: 'Region1', auth: { username: 'user', password: 'pass', project_name: 'js-openstack-lib', auth_url: 'http://keystone' } }; let t = new OpenStack(config); t.authenticate();","import Test from ""../../src/index""; let t = new Test(); }); it(""should retrieve URL's"", (done) => { FetchMock.get(""http://example.com/"", { status: 200, body: ""This is a test"" }); let t = new Test(); t.getUrl(""http://example.com/"") .then((response) => { return response.text(); }) .then((body) => { expect(body).toEqual(""This is a test""); done(); });",23,25
openstack%2Fdiskimage-builder~master~I7c17953de316b25cee410803a167a2af4acb150b,openstack/diskimage-builder,master,I7c17953de316b25cee410803a167a2af4acb150b,Split pip out of pip-and-virtualenv,NEW,2016-05-02 02:23:03.000000000,2017-12-18 04:56:37.000000000,,"[{'_account_id': 7118}, {'_account_id': 10035}, {'_account_id': 12459}]","[{'number': 1, 'created': '2016-05-02 02:23:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/859dee754cf955ec4fb25db5027a404384f4ac07', 'message': 'Split pip out of pip-and-virtualenv\n\nIt is entirely reasonable for a user to only want pip installed and not\nvirtualenv.\n\nChange-Id: I7c17953de316b25cee410803a167a2af4acb150b\n'}, {'number': 2, 'created': '2016-05-05 14:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/6a26b7a50411efe768df7d537ed003de0fd5bd1a', 'message': 'Split pip out of pip-and-virtualenv\n\nIt is entirely reasonable for a user to only want pip installed and not\nvirtualenv.\n\nChange-Id: I7c17953de316b25cee410803a167a2af4acb150b\n'}, {'number': 3, 'created': '2016-05-05 15:35:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/5dacb93ef67ddc47be752a09d28bf3449d21d4cb', 'message': 'Split pip out of pip-and-virtualenv\n\nIt is entirely reasonable for a user to only want pip installed and not\nvirtualenv.\n\nChange-Id: I7c17953de316b25cee410803a167a2af4acb150b\n'}, {'number': 4, 'created': '2016-05-05 19:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7f3b94830cd75989cd4fbcbdac5594f5279ea80e', 'message': 'Split pip out of pip-and-virtualenv\n\nIt is entirely reasonable for a user to only want pip installed and not\nvirtualenv.\n\nChange-Id: I7c17953de316b25cee410803a167a2af4acb150b\n'}, {'number': 5, 'created': '2016-07-13 20:16:22.000000000', 'files': ['elements/pip-and-virtualenv/element-deps', 'elements/pip-and-virtualenv/package-installs.yaml', 'elements/pip/source-repository-pip-and-virtualenv', 'elements/pip/package-installs.yaml', 'elements/virtualenv/element-deps', 'elements/virtualenv/package-installs.yaml', 'elements/virtualenv/pkg-map', 'elements/virtualenv/install.d/virtualenv-source-install/20-install-virtualenv', 'elements/pip/install.d/pip-source-install/10-install-pip', 'elements/pip/element-deps', 'elements/pip/pkg-map', 'elements/pip/README.rst'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/4c4753c7c842016ac644a807c5d0799beb0cc8b1', 'message': 'Split pip out of pip-and-virtualenv\n\nIt is entirely reasonable for a user to only want pip installed and not\nvirtualenv.\n\nChange-Id: I7c17953de316b25cee410803a167a2af4acb150b\n'}]",0,311651,4c4753c7c842016ac644a807c5d0799beb0cc8b1,27,3,5,10035,,,0,"Split pip out of pip-and-virtualenv

It is entirely reasonable for a user to only want pip installed and not
virtualenv.

Change-Id: I7c17953de316b25cee410803a167a2af4acb150b
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/51/311651/4 && git format-patch -1 --stdout FETCH_HEAD,"['elements/pip-and-virtualenv/element-deps', 'elements/pip-and-virtualenv/package-installs.yaml', 'elements/pip/install.d/pip-and-virtualenv-source-install/01-install-pip', 'elements/pip/source-repository-pip-and-virtualenv', 'elements/pip/element-deps', 'elements/pip/package-installs.yaml']",6,859dee754cf955ec4fb25db5027a404384f4ac07,311651,python-pip: installtype: package ,,5,2
openstack%2Fdiskimage-builder~master~Id006976fc21625fb5d13fbc0ba2acb81b7fb964e,openstack/diskimage-builder,master,Id006976fc21625fb5d13fbc0ba2acb81b7fb964e,Create smart caching around debootstrap,NEW,2016-07-08 16:37:47.000000000,2017-12-18 04:55:43.000000000,,"[{'_account_id': 10035}, {'_account_id': 12459}]","[{'number': 1, 'created': '2016-07-08 16:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/bdd4386539f269fb1f72bdc251af3d9189295b6d', 'message': 'Create smart caching around debootstrap\n\nBy caching our debootstrap results we can greatly increase the speed of\nrepeated builds. Before disabling caching by default we were always\ncreating a tarball but never using it unless a user opted-in. We will\nnow use it until the cache either expires or is invalidated so lets turn\nit on by default as this should be generally useful.\n\nChange-Id: Id006976fc21625fb5d13fbc0ba2acb81b7fb964e\n'}, {'number': 2, 'created': '2016-07-08 16:45:58.000000000', 'files': ['elements/debootstrap/root.d/08-debootstrap', 'elements/debootstrap/README.rst'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/63cf15dbae065d57ee38936966daeec461bf072e', 'message': 'Create smart caching around debootstrap\n\nBy caching our debootstrap results we can greatly increase the speed of\nrepeated builds. Before disabling caching by default we were always\ncreating a tarball but never using it unless a user opted-in. We will\nnow use it until the cache either expires or is invalidated so lets turn\nit on by default as this should be generally useful.\n\nChange-Id: Id006976fc21625fb5d13fbc0ba2acb81b7fb964e\n'}]",3,339703,63cf15dbae065d57ee38936966daeec461bf072e,8,2,2,10035,,,0,"Create smart caching around debootstrap

By caching our debootstrap results we can greatly increase the speed of
repeated builds. Before disabling caching by default we were always
creating a tarball but never using it unless a user opted-in. We will
now use it until the cache either expires or is invalidated so lets turn
it on by default as this should be generally useful.

Change-Id: Id006976fc21625fb5d13fbc0ba2acb81b7fb964e
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/03/339703/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/debootstrap/root.d/08-debootstrap', 'elements/debootstrap/README.rst']",2,bdd4386539f269fb1f72bdc251af3d9189295b6d,,filesystem. By default this is 1 (enabled) and a 0 value disables this.,filesystem. By default this is 0 (disabled) and any other value enables this.,54,25
openstack%2Ftosca-parser~master~Ia7c019cd84ec623f72e829c8b119b05b8501b651,openstack/tosca-parser,master,Ia7c019cd84ec623f72e829c8b119b05b8501b651,TOSCA parser fails to load parsed template dict from another template,NEW,2016-06-21 12:44:29.000000000,2017-12-18 04:55:41.000000000,,[{'_account_id': 6456}],"[{'number': 1, 'created': '2016-06-21 12:44:29.000000000', 'files': ['toscaparser/functions.py'], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/7a2a966961433de2c3bc422c56727af8ad15c795', 'message': ""TOSCA parser fails to load parsed template dict from another template\n\n  Unable to create new TOSCA template class instance\n  from existing one by use of its attribute 'tpl'.\n  The problem hiddes in absense to type check while parsing dict\n  object, and it appears that for some reason not all\n  funcation are comming just as dict references like:\n        { function: [a, b] } or { function: a }\n\n  Given fix makes explicit type check for raw_function object.\n\nChange-Id: Ia7c019cd84ec623f72e829c8b119b05b8501b651\nCloses-Bug: #1594781\n""}]",0,332120,7a2a966961433de2c3bc422c56727af8ad15c795,5,1,1,18186,,,0,"TOSCA parser fails to load parsed template dict from another template

  Unable to create new TOSCA template class instance
  from existing one by use of its attribute 'tpl'.
  The problem hiddes in absense to type check while parsing dict
  object, and it appears that for some reason not all
  funcation are comming just as dict references like:
        { function: [a, b] } or { function: a }

  Given fix makes explicit type check for raw_function object.

Change-Id: Ia7c019cd84ec623f72e829c8b119b05b8501b651
Closes-Bug: #1594781
",git fetch https://review.opendev.org/openstack/tosca-parser refs/changes/20/332120/1 && git format-patch -1 --stdout FETCH_HEAD,['toscaparser/functions.py'],1,7a2a966961433de2c3bc422c56727af8ad15c795,bug/1594781," is_type_of_dict = isinstance(raw_function, dict) func_name = (list(raw_function.keys())[0] if is_type_of_dict else raw_function.name) func_args = (list(raw_function.values())[0] if is_type_of_dict else raw_function.args)", func_name = list(raw_function.keys())[0] func_args = list(raw_function.values())[0],6,2
openstack%2Frally~master~I0007e817fc06811af1587959b3db5afd50a95689,openstack/rally,master,I0007e817fc06811af1587959b3db5afd50a95689,Convert ResourceType.transform to ResourceType.preprocess,NEW,2016-05-17 18:47:20.000000000,2017-12-18 04:55:04.000000000,,"[{'_account_id': 10475}, {'_account_id': 11748}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-05-17 18:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1a0a5a7834d19ed6aa3bdcf16c0f4cadb129b3e7', 'message': 'Convert ResourceType.transform to ResourceType.preprocess\n\nThis will allow resource type plugins to retain persistent information\nabout the resources they front. It also starts to remove another point\nof dependency on OpenStack.\n\nImplements: blueprint pluggable-types\nChange-Id: I0007e817fc06811af1587959b3db5afd50a95689\n'}, {'number': 2, 'created': '2016-06-03 14:20:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0e5d3bdc3225ff441db3d9f8f5b7b184b9b87400', 'message': 'Convert ResourceType.transform to ResourceType.preprocess\n\nThis will allow resource type plugins to retain persistent information\nabout the resources they front. It also starts to remove another point\nof dependency on OpenStack.\n\nImplements: blueprint pluggable-types\nChange-Id: I0007e817fc06811af1587959b3db5afd50a95689\n'}, {'number': 3, 'created': '2016-06-06 16:47:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/504acb45c83019c2bcd1bf99b4ff7588c9aba17c', 'message': 'Convert ResourceType.transform to ResourceType.preprocess\n\nThis will allow resource type plugins to retain persistent information\nabout the resources they front. It also starts to remove another point\nof dependency on OpenStack.\n\nImplements: blueprint pluggable-types\nChange-Id: I0007e817fc06811af1587959b3db5afd50a95689\n'}, {'number': 4, 'created': '2016-06-29 13:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ed3167eb5baa44bad1a31ca9383c7dc9e59adda9', 'message': 'Convert ResourceType.transform to ResourceType.preprocess\n\nThis will allow resource type plugins to retain persistent information\nabout the resources they front. It also starts to remove another point\nof dependency on OpenStack.\n\nImplements: blueprint pluggable-types\nChange-Id: I0007e817fc06811af1587959b3db5afd50a95689\n'}, {'number': 5, 'created': '2016-08-18 15:26:02.000000000', 'files': ['rally/plugins/openstack/types.py', 'rally/task/types.py', 'tests/unit/task/test_types.py', 'rally/plugins/common/types.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/a03dbafd9c7685f773ca02766a2336ec774db4ca', 'message': 'Convert ResourceType.transform to ResourceType.preprocess\n\nThis will allow resource type plugins to retain persistent information\nabout the resources they front. It also starts to remove another point\nof dependency on OpenStack.\n\nImplements: blueprint pluggable-types\nChange-Id: I0007e817fc06811af1587959b3db5afd50a95689\n'}]",9,317674,a03dbafd9c7685f773ca02766a2336ec774db4ca,21,4,5,11748,,,0,"Convert ResourceType.transform to ResourceType.preprocess

This will allow resource type plugins to retain persistent information
about the resources they front. It also starts to remove another point
of dependency on OpenStack.

Implements: blueprint pluggable-types
Change-Id: I0007e817fc06811af1587959b3db5afd50a95689
",git fetch https://review.opendev.org/openstack/rally refs/changes/74/317674/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/types.py', 'rally/task/types.py', 'tests/unit/task/test_types.py', 'rally/plugins/common/types.py']",4,1a0a5a7834d19ed6aa3bdcf16c0f4cadb129b3e7,bp/pluggable-types," def preprocess(self, resource_config, context=None, clients=None): def preprocess(self, resource_config, context=None, clients=None): def preprocess(self, resource_config, context=None, clients=None):"," @classmethod def transform(cls, clients, resource_config): @classmethod def transform(cls, clients, resource_config): @classmethod def transform(cls, clients, resource_config):",173,96
openstack%2Fdiskimage-builder~master~I5b11b17dfa971e59a3c4408dbe773e39e52bbd9c,openstack/diskimage-builder,master,I5b11b17dfa971e59a3c4408dbe773e39e52bbd9c,Add tinycorelinux element,NEW,2016-05-02 01:46:16.000000000,2017-12-18 04:55:02.000000000,,"[{'_account_id': 10035}, {'_account_id': 12459}, {'_account_id': 21741}]","[{'number': 1, 'created': '2016-05-02 01:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c16c2310f501bacb3cad0165111848f331c30553', 'message': 'Add tinycorelinux element\n\nAllow for creation of Tiny Core Liunx images.\n\nChange-Id: I5b11b17dfa971e59a3c4408dbe773e39e52bbd9c\n'}, {'number': 2, 'created': '2016-05-02 01:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/4b21f09736b246579d9883cc569440ca7f3d52ce', 'message': 'Add tinycorelinux element\n\nAllow for creation of Tiny Core Liunx images.\n\nDepends-On: I4062696209e0750e95d0a1c697af271be6a07052\nChange-Id: I5b11b17dfa971e59a3c4408dbe773e39e52bbd9c\n'}, {'number': 3, 'created': '2016-05-02 02:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/919664e6d52e60a4aac203d8838d3f006d77d60e', 'message': 'Add tinycorelinux element\n\nAllow for creation of Tiny Core Liunx images.\n\nDepends-On: I4062696209e0750e95d0a1c697af271be6a07052\nChange-Id: I5b11b17dfa971e59a3c4408dbe773e39e52bbd9c\n'}, {'number': 4, 'created': '2016-05-02 02:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ab5e7e7133408173c7beb4ded7c116289ae741f2', 'message': 'Add tinycorelinux element\n\nAllow for creation of Tiny Core Liunx images.\n\nDepends-On: I4062696209e0750e95d0a1c697af271be6a07052\nChange-Id: I5b11b17dfa971e59a3c4408dbe773e39e52bbd9c\n'}, {'number': 5, 'created': '2016-05-05 14:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7f84f5bd24e83cf1b6b7a26482baeaef7ee3a64f', 'message': 'Add tinycorelinux element\n\nAllow for creation of Tiny Core Linux images.\n\nDepends-On: I4062696209e0750e95d0a1c697af271be6a07052\nChange-Id: I5b11b17dfa971e59a3c4408dbe773e39e52bbd9c\n'}, {'number': 6, 'created': '2016-05-05 14:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/49ddd0bd7249ad181ddf4676b7de63afcac3fa87', 'message': 'Add tinycorelinux element\n\nAllow for creation of Tiny Core Linux images.\n\nDepends-On: I4062696209e0750e95d0a1c697af271be6a07052\nChange-Id: I5b11b17dfa971e59a3c4408dbe773e39e52bbd9c\n'}, {'number': 7, 'created': '2016-05-05 15:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/1fad0e4b34107a72e6c57d9119207872e8a1fafc', 'message': 'Add tinycorelinux element\n\nAllow for creation of Tiny Core Linux images.\n\nDepends-On: I4062696209e0750e95d0a1c697af271be6a07052\nChange-Id: I5b11b17dfa971e59a3c4408dbe773e39e52bbd9c\n'}, {'number': 8, 'created': '2016-05-05 19:55:48.000000000', 'files': ['elements/tinycorelinux/root.d/10-cache-tinycorelinux', 'elements/tinycorelinux/extra-data.d/50-tinycorelinux', 'elements/tinycorelinux/environment.d/50-tinycorelinux-env', 'elements/tinycorelinux/bin/install-packages', 'elements/tinycorelinux/root.d/50-tinycorelinux', 'elements/tinycorelinux/element-deps', 'elements/tinycorelinux/element-provides'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f594ec77250ffb99d1728d5c082123f01b800a2f', 'message': 'Add tinycorelinux element\n\nAllow for creation of Tiny Core Linux images.\n\nDepends-On: I4062696209e0750e95d0a1c697af271be6a07052\nChange-Id: I5b11b17dfa971e59a3c4408dbe773e39e52bbd9c\n'}]",9,311647,f594ec77250ffb99d1728d5c082123f01b800a2f,35,3,8,10035,,,0,"Add tinycorelinux element

Allow for creation of Tiny Core Linux images.

Depends-On: I4062696209e0750e95d0a1c697af271be6a07052
Change-Id: I5b11b17dfa971e59a3c4408dbe773e39e52bbd9c
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/47/311647/7 && git format-patch -1 --stdout FETCH_HEAD,"['elements/tinycorelinux/environment.d/50-tinycorelinux-env', 'elements/tinycorelinux/bin/install-packages', 'elements/tinycorelinux/root.d/50-tinycorelinux', 'elements/tinycorelinux/extra-data.d/50-tinyipa', 'elements/tinycorelinux/source-repository-tinyipa', 'elements/tinycorelinux/element-deps', 'elements/tinycorelinux/element-provides', 'elements/tinycorelinux/root.d/10-cache-tinyipa', 'elements/tinycorelinux/install.d/50-install-pip']",9,c16c2310f501bacb3cad0165111848f331c30553,311647,#!/bin/bash if [ ${DIB_DEBUG_TRACE:-0} -gt 0 ]; then set -x fi set -eu set -o pipefail python /tmp/get-pip.py ,,141,0
openstack%2Fmonasca-notification~master~I0753eda53a8dcd3e3d017e9219c5b0f3fc67731d,openstack/monasca-notification,master,I0753eda53a8dcd3e3d017e9219c5b0f3fc67731d,I fixed H302. I fixed H302 by updating the hacking library in test-requirements.txt.,NEW,2016-08-17 09:01:10.000000000,2017-12-18 04:54:57.000000000,,"[{'_account_id': 2419}, {'_account_id': 10068}, {'_account_id': 14273}]","[{'number': 1, 'created': '2016-08-17 09:01:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/8e66074e0d0803bacf6e12abab9fca2b765a42b5', 'message': 'I fixed H302. I fixed H302 by updating the hacking library in test-requirements.txt.\n\nChange-Id: I0753eda53a8dcd3e3d017e9219c5b0f3fc67731d\n'}, {'number': 2, 'created': '2016-08-19 09:16:46.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/2f80b29ba0992a66c2a6f199f36e592b24ea711b', 'message': 'I fixed H302. I fixed H302 by updating the hacking library in test-requirements.txt.\n\nChange-Id: I0753eda53a8dcd3e3d017e9219c5b0f3fc67731d\n'}]",0,356320,2f80b29ba0992a66c2a6f199f36e592b24ea711b,8,3,2,23180,,,0,"I fixed H302. I fixed H302 by updating the hacking library in test-requirements.txt.

Change-Id: I0753eda53a8dcd3e3d017e9219c5b0f3fc67731d
",git fetch https://review.opendev.org/openstack/monasca-notification refs/changes/20/356320/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,8e66074e0d0803bacf6e12abab9fca2b765a42b5,,"hacking < 0.11, >= 0.10.0 pyflakes == 0.8.1mock >= 1.0.1","hacking>=0.11.0,<0.12 # Apache-2.0 pyflakes==0.8.1mock>=1.0.1",3,3
openstack%2Ftacker~master~Id0948501aba25ddbae6d12cfd97f2c793f4b76d4,openstack/tacker,master,Id0948501aba25ddbae6d12cfd97f2c793f4b76d4,Typo commits fixed a few spellings,NEW,2016-07-12 19:33:10.000000000,2017-12-18 04:54:47.000000000,,"[{'_account_id': 2874}, {'_account_id': 13380}, {'_account_id': 20991}]","[{'number': 1, 'created': '2016-07-12 19:33:10.000000000', 'files': ['tacker/db/vm/vm_db.py', 'tacker/vm/hosting_device_scheduler.py', 'tacker/vm/constants.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/487bd61c29c95514ba8a19947758c0f44e4a1e08', 'message': 'Typo commits fixed a few spellings\n\nChange-Id: Id0948501aba25ddbae6d12cfd97f2c793f4b76d4\n'}]",0,341153,487bd61c29c95514ba8a19947758c0f44e4a1e08,8,3,1,8514,,,0,"Typo commits fixed a few spellings

Change-Id: Id0948501aba25ddbae6d12cfd97f2c793f4b76d4
",git fetch https://review.opendev.org/openstack/tacker refs/changes/53/341153/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/db/vm/vm_db.py', 'tacker/vm/hosting_device_scheduler.py', 'tacker/vm/constants.py']",3,487bd61c29c95514ba8a19947758c0f44e4a1e08,TypoCommit,# service type,# sevice type,4,4
openstack%2Fpython-tackerclient~master~I6fa38242f515ca65cbde3499f4ae00256d8e6aa3,openstack/python-tackerclient,master,I6fa38242f515ca65cbde3499f4ae00256d8e6aa3,Stop using mox in tackerclient (2),NEW,2016-08-24 11:47:48.000000000,2017-12-18 04:54:22.000000000,,"[{'_account_id': 18401}, {'_account_id': 18955}, {'_account_id': 22132}]","[{'number': 1, 'created': '2016-08-24 11:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/8ed6a8a0a9042b7fa1a6405e4cf6d8bed70f5e10', 'message': 'Stop using mox in tackerclient (2)\n\n1.Introduce test.ContainKeyValue for replacing mox.ContainKeyValue\n  in test_client_vnf.py.\n2.Try to replace mox with mock in tackerclient/test/unit/\n  test_shell/test_client_vnf.py.\n\nChange-Id: I6fa38242f515ca65cbde3499f4ae00256d8e6aa3\n'}, {'number': 2, 'created': '2016-08-24 12:03:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/1ba5f1fb08616e60b67ab90df5ac8728b592ac34', 'message': 'Stop using mox in tackerclient (2)\n\n1.Introduce test.ContainKeyValue for replacing mox.ContainKeyValue\n  in test_client_vnf.py.\n2.Try to replace mox with mock in tackerclient/test/unit/\n  test_shell/test_client_vnf.py.\n\nChange-Id: I6fa38242f515ca65cbde3499f4ae00256d8e6aa3\n'}, {'number': 3, 'created': '2016-08-24 12:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/e989020085313f6d8e66202ca5d08809e531c7e4', 'message': 'Stop using mox in tackerclient (2)\n\n1.Introduce test.ContainKeyValue for replacing mox.ContainKeyValue\n  in test_client_vnf.py.\n2.Try to replace mox with mock in tackerclient/test/unit/\n  test_shell/test_client_vnf.py.\n\nChange-Id: I6fa38242f515ca65cbde3499f4ae00256d8e6aa3\n'}, {'number': 4, 'created': '2016-08-24 12:50:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/a8c6472efefd54565b6762e97ccdd47ebae6d2eb', 'message': 'Stop using mox in tackerclient (2)\n\n1.Introduce test.ContainKeyValue for replacing mox.ContainKeyValue\n  in test_client_vnf.py.\n2.Try to replace mox with mock in tackerclient/test/unit/\n  test_shell/test_client_vnf.py.\n\nChange-Id: I6fa38242f515ca65cbde3499f4ae00256d8e6aa3\n'}, {'number': 5, 'created': '2016-08-25 01:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/21e4733236588945b447d151d2a6a2d2b00b3583', 'message': 'Stop using mox in tackerclient (2)\n\n1.Introduce test.ContainKeyValue for replacing mox.ContainKeyValue\n  in test_client_vnf.py.\n2.Try to replace mox with mock in tackerclient/test/unit/\n  test_shell/test_client_vnf.py.\n\nChange-Id: I6fa38242f515ca65cbde3499f4ae00256d8e6aa3\n'}, {'number': 6, 'created': '2016-08-25 03:17:06.000000000', 'files': ['tackerclient/tests/unit/test_shell.py', 'tackerclient/tests/unit/vm/test_cli10_vnf.py'], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/be50a4c6681fad17b56bf398b14ac33f34eaea3d', 'message': 'Stop using mox in tackerclient (2)\n\n1.Introduce test.ContainKeyValue for replacing mox.ContainKeyValue\n  in test_client_vnf.py.\n2.Try to replace mox with mock in tackerclient/test/unit/\n  test_shell/test_client_vnf.py.\n\nChange-Id: I6fa38242f515ca65cbde3499f4ae00256d8e6aa3\n'}]",0,359817,be50a4c6681fad17b56bf398b14ac33f34eaea3d,18,3,6,22132,,,0,"Stop using mox in tackerclient (2)

1.Introduce test.ContainKeyValue for replacing mox.ContainKeyValue
  in test_client_vnf.py.
2.Try to replace mox with mock in tackerclient/test/unit/
  test_shell/test_client_vnf.py.

Change-Id: I6fa38242f515ca65cbde3499f4ae00256d8e6aa3
",git fetch https://review.opendev.org/openstack/python-tackerclient refs/changes/17/359817/6 && git format-patch -1 --stdout FETCH_HEAD,"['tackerclient/tests/unit/test_shell.py', 'tackerclient/tests/unit/vm/test_cli10_vnf.py']",2,8ed6a8a0a9042b7fa1a6405e4cf6d8bed70f5e10,mox_to_mock,"import mock with mock.patch.object(cmd.get_cleint(), 'MultipleTimes') as mock_get: mock_get.return_value = self.client mock_get.assert_called_once_with() with mock.patch.object(self.client.httpclient, ""request"") as mock_req: mock_req.return_value = (test_cli10.MyResp(200), resstr) mock_req.assert_called_once_with( test_cli10.end_url(path, format=self.format), 'POST', body=mox_body, headers=ContainsKeyValue('X-Auth-Token', TOKEN)) class ContainsKeyValue(object): """"""Checks whether a key/value pair is in a dict parameter. The ContainKeyValue class is a helper for use with the mock.assert_*() method that lets you assert that a particular dict contain a key/value paire. It enables strict check than the built in mock.ANY helper, and is the equivalent of the mox.ContainsKeyValue() function from the legacy mox library Example usage could be: mock_some_method.assert_called_once_with( ""hello"", ContainKeyValue('foo', bar), mock.ANY, ""world"", ContainKeyValue('hello', world)) """""" def __init__(self, wantkey, wantvalue): self.wantkey = wantkey self.wantvalue = wantvalue def __eq__(self, other): try: return other[self.wantkey] == self.wantvalue except (KeyError, TypeError): return False def __ne__(self, other): try: return other[self.wantkey] != self.wantvalue except (KeyError, TypeError): return True def __repr__(self): return ""<ContainKeyValue: key "" + str(self.wantkey) + \ "" and value "" + str(self.wantvalue) + "">""","import mox self.mox.StubOutWithMock(cmd, ""get_client"") self.mox.StubOutWithMock(self.client.httpclient, ""request"") cmd.get_client().MultipleTimes().AndReturn(self.client) self.client.httpclient.request( test_cli10.end_url(path, format=self.format), 'POST', body=mox_body, headers=mox.ContainsKeyValue( 'X-Auth-Token', TOKEN)).AndReturn(( test_cli10.MyResp(200), resstr)) self.mox.ReplayAll() self.mox.VerifyAll()",74,30
openstack%2Ftacker~master~I396fca69053e940bad30786f2cd19f4091717314,openstack/tacker,master,I396fca69053e940bad30786f2cd19f4091717314,Validate file size at server side,NEW,2016-07-24 19:49:27.000000000,2017-12-18 04:54:17.000000000,,"[{'_account_id': 2874}, {'_account_id': 9631}, {'_account_id': 16511}]","[{'number': 1, 'created': '2016-07-24 19:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/3f2ad6b3135bc60d9ebd36ad1837e0bf52ba9d21', 'message': 'Validate file size at server side\n\nValidate size of template and config file at api\nserver side before storing in db\nSize should be <= 64KBytes\n\nChange-Id: I396fca69053e940bad30786f2cd19f4091717314\n'}, {'number': 2, 'created': '2016-07-25 11:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/4c498e3f7a34deccaf4d5cba1b8e67a87a820a28', 'message': 'Validate file size at server side\n\nValidate size of template and config file at api\nserver side before storing in db\nSize should be <= 64KBytes\n\nChange-Id: I396fca69053e940bad30786f2cd19f4091717314\nPartial-Bug: 1506593\n'}, {'number': 3, 'created': '2016-07-25 14:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/aedf2d3187ff07a890c6c51fc24f5f76c57289f3', 'message': 'Validate file size at server side\n\nValidate size of template and config file at api\nserver side before storing in db\nSize should be <= 64KBytes\n\nChange-Id: I396fca69053e940bad30786f2cd19f4091717314\nPartial-Bug: 1506593\n'}, {'number': 4, 'created': '2016-07-25 14:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/93a3404454149437c828e5b7ea054f1ad6d9e45b', 'message': 'Validate file size at server side\n\nValidate size of template and config file at api\nserver side before storing in db\nSize should be <= 64KBytes\n\nChange-Id: I396fca69053e940bad30786f2cd19f4091717314\nPartial-Bug: 1506593\n'}, {'number': 5, 'created': '2016-08-25 07:39:16.000000000', 'files': ['tacker/common/constants.py', 'tacker/common/utils.py', 'tacker/vm/plugin.py', 'tacker/common/exceptions.py', 'tacker/tests/unit/test_common_utils.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/dacfefa495754396b2509c9695f426cbbe49678b', 'message': 'Validate file size at server side\n\nValidate size of template and config file at api\nserver side before storing in db\nSize should be <= 64KBytes\n\nChange-Id: I396fca69053e940bad30786f2cd19f4091717314\nPartial-Bug: 1506593\n'}]",6,346543,dacfefa495754396b2509c9695f426cbbe49678b,14,3,5,9631,,,0,"Validate file size at server side

Validate size of template and config file at api
server side before storing in db
Size should be <= 64KBytes

Change-Id: I396fca69053e940bad30786f2cd19f4091717314
Partial-Bug: 1506593
",git fetch https://review.opendev.org/openstack/tacker refs/changes/43/346543/5 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/common/constants.py', 'tacker/common/utils.py', 'tacker/vm/plugin.py', 'tacker/common/exceptions.py']",4,3f2ad6b3135bc60d9ebd36ad1837e0bf52ba9d21,bug/1506593," class MaxSizeError(TackerException): def __init__(self, message=None, **kwargs): self.message = message super(MaxSizeError, self).__init__()",,29,0
openstack%2Fpython-ironicclient~master~Ib0e7736116f7aa8c4227e1da06bf70578f07346c,openstack/python-ironicclient,master,Ib0e7736116f7aa8c4227e1da06bf70578f07346c,Introduce FakeBaremetal class,NEW,2016-04-06 05:59:00.000000000,2017-12-18 04:54:15.000000000,,"[{'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 11655}, {'_account_id': 12356}, {'_account_id': 13719}, {'_account_id': 16066}]","[{'number': 1, 'created': '2016-04-06 05:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/147e7387b24034e38221fcf240302f1956e15546', 'message': 'Introduce FakeBaremetal class\n\nIntroduce a FakeBaremetal class into baremetal unittest framework\nwith the following two advantages:\n1. generate more than one faked baremetal\n2. all faked baremetals information got by random\n\nChange-Id: Ib0e7736116f7aa8c4227e1da06bf70578f07346c\nImplenents: blueprint improve-baremetal-unittest\n'}, {'number': 2, 'created': '2016-04-11 02:36:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/862ce817b9ce97acf165d155d9902eed2c65449a', 'message': 'Introduce FakeBaremetal class\n\nIntroduce a FakeBaremetal class into baremetal unittest framework\nwith the following two advantages:\n1. generate more than one faked baremetal\n2. all faked baremetals information got by random\n\nChange-Id: Ib0e7736116f7aa8c4227e1da06bf70578f07346c\nCloses-Bug: #1568645\n'}, {'number': 3, 'created': '2016-04-11 11:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/f7899b37ee4913ec0fbd9359b9c1aac2451d699e', 'message': 'Introduce FakeBaremetal class\n\nIntroduce a FakeBaremetal class into baremetal unittest framework\nwith the following two advantages:\n1. generate more than one faked baremetal\n2. all faked baremetals information got by random\n\nChange-Id: Ib0e7736116f7aa8c4227e1da06bf70578f07346c\nCloses-Bug: #1568645\n'}, {'number': 4, 'created': '2016-04-11 13:30:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/635ab852ffa82c61a964cc10992ca68668c15c9e', 'message': 'Introduce FakeBaremetal class\n\nCurrently the faked baremetal nodes all are hardcoded so that\nit is not easy to write the test cases if which need more than\none faked baremetal nodes.\nA FakeBaremetal class is introducing to improve this framework:\n1. generate more than one faked baremetal\n2. all faked baremetals information got by random\n\nChange-Id: Ib0e7736116f7aa8c4227e1da06bf70578f07346c\nCloses-Bug: #1568645\n'}, {'number': 5, 'created': '2016-04-13 12:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/c9f50c05ab228b43487061b9d2562f256d2d55e5', 'message': 'Introduce FakeBaremetal class\n\nCurrently the faked baremetal nodes all are hardcoded so that\nit is not easy to write the test cases if which need more than\none faked baremetal nodes.\nA FakeBaremetal class is introducing to improve this framework:\n1. generate more than one faked baremetal\n2. all faked baremetals information got by random\n\nChange-Id: Ib0e7736116f7aa8c4227e1da06bf70578f07346c\nPartial-Bug: #1568645\n'}, {'number': 6, 'created': '2016-04-20 13:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/4b9319377297f63436bd8a0942f958075d01d0e5', 'message': 'Introduce FakeBaremetal class\n\nCurrently the faked baremetal nodes all are hardcoded so that\nit is not easy to write the test cases if which need more than\none faked baremetal nodes.\nA FakeBaremetal class is introducing to improve this framework:\n1. generate more than one faked baremetal\n2. all faked baremetals information got by random\n\nChange-Id: Ib0e7736116f7aa8c4227e1da06bf70578f07346c\nPartial-Bug: #1568645\n'}, {'number': 7, 'created': '2016-05-17 09:40:49.000000000', 'files': ['ironicclient/tests/unit/osc/v1/fakes.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/fef729c28b97d7d494657e1f74d9945d2ddc3908', 'message': 'Introduce FakeBaremetal class\n\nCurrently the faked baremetal nodes all are hardcoded so that\nit is not easy to write the test cases if which need more than\none faked baremetal nodes.\nA FakeBaremetal class is introducing to improve this framework:\n1. generate more than one faked baremetal\n2. all faked baremetals information got by random\n\nChange-Id: Ib0e7736116f7aa8c4227e1da06bf70578f07346c\n'}]",48,302037,fef729c28b97d7d494657e1f74d9945d2ddc3908,33,6,7,16066,,,0,"Introduce FakeBaremetal class

Currently the faked baremetal nodes all are hardcoded so that
it is not easy to write the test cases if which need more than
one faked baremetal nodes.
A FakeBaremetal class is introducing to improve this framework:
1. generate more than one faked baremetal
2. all faked baremetals information got by random

Change-Id: Ib0e7736116f7aa8c4227e1da06bf70578f07346c
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/37/302037/3 && git format-patch -1 --stdout FETCH_HEAD,['ironicclient/tests/unit/osc/v1/fakes.py'],1,147e7387b24034e38221fcf240302f1956e15546,improve-baremetal-unittest,"import random import uuid class FakeBaremetal(object): """"""Fake one or more baremetals."""""" @staticmethod def create_one_baremetal(attrs={}): """"""Create a fake baremetal. :param Dictionary attrs: A dictionary with all attributes :param Dictionary methods: A dictionary with all methods :return: A FakeBaremetalResource object """""" # Set default attributes. bm_info = { 'uuid': 'bm-uuid-' + uuid.uuid4().hex, 'name': 'bm-name-' + uuid.uuid4().hex, 'instance_uuid': 'bm-instance-uuid-' + uuid.uuid4().hex, 'power_state': random.choice(['power on', 'power off']), 'provision_state': random.choice(['manage', 'clean']), 'maintenance': bool(random.choice([0, 1])), 'links': [] } # Overwrite default attributes. bm_info.update(attrs) bm = FakeBaremetalResource(None, bm_info, loaded=True) return bm @staticmethod def create_baremetals(attrs={}, count=2): """"""Create multiple fake baremetals. :param Dictionary attrs: A dictionary with all attributes :param Dictionary methods: A dictionary with all methods :param int count: The number of baremetals to fake :return: A list of FakeBaremetalResource objects faking the baremetals """""" bms = [] for i in range(0, count): bms.append(FakeBaremetal.create_one_baremetal(attrs)) return bms @staticmethod def get_baremetals(bms=None, count=2): """"""Get an iterable MagicMock object with a list of faked baremetals. If aremetals list is provided, then initialize the Mock object with the list. Otherwise create one. :param List baremetals: A list of FakeBaremetalResource objects faking baremetals :param int count: The number of baremetals to fake :return: An iterable Mock object with side_effect set to a list of faked baremetals """""" if bms is None: bms = FakeBaremetal.create_baremetals(count=count) return mock.MagicMock(side_effect=bms) ",,73,0
openstack%2Fironic~master~If2fcab5d8dba434c1b07ee30e05a08dcff079881,openstack/ironic,master,If2fcab5d8dba434c1b07ee30e05a08dcff079881,[WIP] Break devstack when using pxe deploy with ipv6,NEW,2016-08-23 20:56:18.000000000,2017-12-18 04:53:41.000000000,,"[{'_account_id': 2889}, {'_account_id': 10118}, {'_account_id': 10697}, {'_account_id': 17998}, {'_account_id': 19339}]","[{'number': 1, 'created': '2016-08-23 20:56:18.000000000', 'files': ['devstack/lib/ironic'], 'web_link': 'https://opendev.org/openstack/ironic/commit/9279be59e470e41a9ca4d52484c13cb018d16704', 'message': '[WIP] Break devstack when using pxe deploy with ipv6\n\nChange-Id: If2fcab5d8dba434c1b07ee30e05a08dcff079881\n'}]",0,359422,9279be59e470e41a9ca4d52484c13cb018d16704,9,5,1,10697,,,0,"[WIP] Break devstack when using pxe deploy with ipv6

Change-Id: If2fcab5d8dba434c1b07ee30e05a08dcff079881
",git fetch https://review.opendev.org/openstack/ironic refs/changes/22/359422/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/ironic'],1,9279be59e470e41a9ca4d52484c13cb018d16704,ironic-ipv6,"# Neutron/Network variables IPV6_ENABLED=$(trueorfalse True IPV6_ENABLED) IPV6_SUBNET_ATTRIBUTES_ENABLED=$(trueorfalse True IPV6_SUBNET_ATTRIBUTES_ENABLED) if [[ -z ""${IRONIC_DEPLOY_DRIVER%%pxe}"" && (""$IPV6_ENABLED"" == ""True"" || ""$IPV6_SUBNET_ATTRIBUTES_ENABLED"" == True) ]]; then die $LINENO ""PXE drivers don't support IPv6 networks."" fi ",,7,0
openstack%2Fswift~master~I5d5301296f33cabe699fc2e72ab5873a48554dfa,openstack/swift,master,I5d5301296f33cabe699fc2e72ab5873a48554dfa,Minor cleanups in Putter,NEW,2016-07-01 23:11:10.000000000,2017-12-18 04:53:36.000000000,,"[{'_account_id': 1179}, {'_account_id': 7847}, {'_account_id': 13052}]","[{'number': 1, 'created': '2016-07-01 23:11:10.000000000', 'files': ['test/unit/__init__.py', 'test/unit/proxy/controllers/test_obj.py', 'swift/proxy/controllers/obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b3de24747466653a5ee86d85c4962009dd4f8592', 'message': 'Minor cleanups in Putter\n\n* end_of_object_data should noop on Content-Length objects\n* explicit termination condition in _send_file\n\nChange-Id: I5d5301296f33cabe699fc2e72ab5873a48554dfa\n'}]",6,336740,b3de24747466653a5ee86d85c4962009dd4f8592,8,3,1,1179,,,0,"Minor cleanups in Putter

* end_of_object_data should noop on Content-Length objects
* explicit termination condition in _send_file

Change-Id: I5d5301296f33cabe699fc2e72ab5873a48554dfa
",git fetch https://review.opendev.org/openstack/swift refs/changes/40/336740/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/__init__.py', 'test/unit/proxy/controllers/test_obj.py', 'swift/proxy/controllers/obj.py']",3,b3de24747466653a5ee86d85c4962009dd4f8592,putter-fixup, if self.chunked: self.queue.put('') try: chunk = self.queue.get() except GreenletExit: # killed by ContextPool break, self.queue.put('') chunk = self.queue.get(),63,18
openstack%2Fironic~master~I706bfce56f642ae3c092c6f3d7024f954a9b8768,openstack/ironic,master,I706bfce56f642ae3c092c6f3d7024f954a9b8768,[WIP] Custom power sync,NEW,2016-06-22 19:26:07.000000000,2017-12-18 04:53:09.000000000,,"[{'_account_id': 10118}, {'_account_id': 14629}, {'_account_id': 14943}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-06-22 19:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/af6397c92e12ad41c9849885dce358ec5363526e', 'message': '[WIP] Custom power sync\n\nChange-Id: I706bfce56f642ae3c092c6f3d7024f954a9b8768\n'}, {'number': 2, 'created': '2016-06-23 19:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/405cc5094eab3387db95ad5c87fe203828ec86d1', 'message': '[WIP] Custom power sync\n\nChange-Id: I706bfce56f642ae3c092c6f3d7024f954a9b8768\n'}, {'number': 3, 'created': '2016-06-29 12:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f834a1505781b13ff017764ab652314e86179f67', 'message': '[WIP] Custom power sync\n\nChange-Id: I706bfce56f642ae3c092c6f3d7024f954a9b8768\n'}, {'number': 4, 'created': '2016-07-05 19:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1dd2fbc8929ca014e004998f5a3789e8f5737338', 'message': '[WIP] Custom power sync\n\nChange-Id: I706bfce56f642ae3c092c6f3d7024f954a9b8768\n'}, {'number': 5, 'created': '2016-07-06 17:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a1730cca0b8638a94e3836978a5217cd617dc2bf', 'message': '[WIP] Custom power sync\n\nChange-Id: I706bfce56f642ae3c092c6f3d7024f954a9b8768\n'}, {'number': 6, 'created': '2016-07-06 18:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/708e0e7131f22bd184e23ceba0aee54a26fc25ba', 'message': '[WIP] Custom power sync\n\nChange-Id: I706bfce56f642ae3c092c6f3d7024f954a9b8768\n'}, {'number': 7, 'created': '2016-07-06 18:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d9eadaccb6ec2e921fa29ee726c5e1c56bbfb302', 'message': '[WIP] Custom power sync\n\nChange-Id: I706bfce56f642ae3c092c6f3d7024f954a9b8768\n'}, {'number': 8, 'created': '2016-07-06 19:48:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5cc8e9eb0922406729614a3811f932b3c8b61174', 'message': '[WIP] Custom power sync\n\nChange-Id: I706bfce56f642ae3c092c6f3d7024f954a9b8768\n'}, {'number': 9, 'created': '2016-09-07 15:05:01.000000000', 'files': ['ironic/drivers/modules/oneview/power.py', 'ironic/tests/unit/drivers/modules/oneview/test_power.py', 'ironic/conf/oneview.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4d8aaae162b8f4c50f6ebcc219c27615e4df7e6c', 'message': '[WIP] Custom power sync\n\nChange-Id: I706bfce56f642ae3c092c6f3d7024f954a9b8768\n'}]",0,332978,4d8aaae162b8f4c50f6ebcc219c27615e4df7e6c,39,7,9,10697,,,0,"[WIP] Custom power sync

Change-Id: I706bfce56f642ae3c092c6f3d7024f954a9b8768
",git fetch https://review.opendev.org/openstack/ironic refs/changes/78/332978/8 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/oneview/power.py'],1,af6397c92e12ad41c9849885dce358ec5363526e,power_stream,"from futurist import periodics CONF = common.CONF def _get_power_state(self, task): def get_power_state(self, task): return task.node.power_state def _watch_oneview_scmb(self): pass @periodics.periodic(spacing=CONF.oneview.periodic_check_interval, enabled=CONF.oneview.enable_periodic_tasks) def sync_power_state(self, manager, context): filters = { 'maintenance': False, 'driver': self.oneview_driver # ! } node_iter = manager.iter_nodes(filters=filters) for node_uuid, driver in node_iter: with task_manager.acquire( context, node_uuid, purpose='Oneview power_state sync', shared=True ) as task: current_state = self._get_power_state(task) if current_state != task.node.power_state: self.set_power_state(task, current_state) "," def get_power_state(self, task):",35,1
openstack%2Fswift~master~Id89fb2257307224c423cf6f6f1ca24f436b7821f,openstack/swift,master,Id89fb2257307224c423cf6f6f1ca24f436b7821f,Let object-info find files in a given directory,NEW,2015-06-08 10:30:30.000000000,2017-12-18 04:53:07.000000000,,"[{'_account_id': 2622}, {'_account_id': 2696}, {'_account_id': 4608}, {'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 9625}, {'_account_id': 9963}, {'_account_id': 12974}, {'_account_id': 13052}, {'_account_id': 13340}, {'_account_id': 13404}, {'_account_id': 18339}]","[{'number': 1, 'created': '2015-06-08 10:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/76ef78df51cb22dceae1008846e771ad3c1490fc', 'message': 'Let swift-object-info print information about files\nin given directory.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 2, 'created': '2015-06-08 11:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/16e41f76d4b2704bd8f01edd9f17ef222cd1e28b', 'message': 'Let swift-object-info print information about files\nin given directory.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 3, 'created': '2015-06-09 10:45:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0a92f7422b76c608ab6fd0b4fd3e93d65d720891', 'message': 'Let swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file together with --recursive option.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 4, 'created': '2015-06-09 12:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bb2cc7c4570b7b84e53237d7e649baa7b046b314', 'message': 'Let swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file together with --recursive option.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 5, 'created': '2015-06-09 18:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bd14bc061aec0eef9b2ca3bd7cdc072c5d6ad2fa', 'message': 'Let swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file together with --recursive option.\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 6, 'created': '2015-06-11 11:01:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ef6a3b4ea073aa89692bebba5d3d659b91505b03', 'message': 'Let swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file together with --recursive option.\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 7, 'created': '2015-06-11 11:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bcb4de26ea33c9a2b10ec0136149174179c6a79f', 'message': 'Let swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file together with --recursive option.\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 8, 'created': '2015-06-17 18:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9f7fa9ddffe7937b6684ec11dca8dee60870fa5b', 'message': 'Let swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file together with --recursive option.\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 9, 'created': '2015-06-30 09:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/eb47acf26ea3d31419017bebec07eff70fc6e7c5', 'message': 'Let object-info find files in a given directory\n\nLet swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file as an argument for OBJECT_FILE\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 10, 'created': '2015-07-10 12:20:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5bbdf0fb8ff3633ecbea770c1743fcbc3e9d4a32', 'message': 'Let object-info find files in a given directory\n\nLet swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file as an argument for OBJECT_FILE\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 11, 'created': '2015-08-26 09:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6104ad57a55182d56707e0f2bad1114d0551e004', 'message': 'Let object-info find files in a given directory\n\nLet swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file as an argument for OBJECT_FILE\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 12, 'created': '2015-08-26 11:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e5977e1ffacdc0b375e7da70467774bd2b2cba4a', 'message': 'Let object-info find files in a given directory\n\nLet swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file as an argument for OBJECT_FILE\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 13, 'created': '2015-08-27 09:56:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a69a4f3704d3e1625f143a49a0eb29d4295b4831', 'message': 'Let object-info find files in a given directory\n\nLet swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file as an argument for OBJECT_FILE\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 14, 'created': '2015-08-27 12:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/aa1b51ff17eaa4e537ddfcc026415d330c326cbb', 'message': 'Let object-info find files in a given directory\n\nLet swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file as an argument for OBJECT_FILE\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 15, 'created': '2015-08-27 13:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8f4fa84b6c1ca9ef68ecac4d52e1eb77d3dc4747', 'message': 'Let object-info find files in a given directory\n\nLet swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file as an argument for OBJECT_FILE\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 16, 'created': '2015-09-08 10:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4a24c8ff25b16f9bb8773211ea2866515b3ab09b', 'message': 'Let object-info find files in a given directory\n\nLet swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file as an argument for OBJECT_FILE\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 17, 'created': '2015-10-22 19:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1e4af5fe45f75ae8dad8c25498bd46086d6ac1a5', 'message': 'Let object-info find files in a given directory\n\nLet swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file as an argument for OBJECT_FILE\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 18, 'created': '2016-02-17 21:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/27f8f81ff451c40e1bccd1db39af458bb87836ac', 'message': 'Let object-info find files in a given directory\n\nLet swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file as an argument for OBJECT_FILE\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}, {'number': 19, 'created': '2016-09-07 19:56:35.000000000', 'files': ['swift/cli/info.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/feec4cd71fefb889d6b532859e8972691ee9304c', 'message': 'Let object-info find files in a given directory\n\nLet swift-object-info print information about files\nin given directory, if directory is provided instead\nof data file as an argument for OBJECT_FILE\n\nIf .meta file is present, use it to print updated\nmetadata information of the data file.\n\nChange-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f\nCloses-Bug: #1431334\n'}]",10,189258,feec4cd71fefb889d6b532859e8972691ee9304c,78,12,19,9963,,,0,"Let object-info find files in a given directory

Let swift-object-info print information about files
in given directory, if directory is provided instead
of data file as an argument for OBJECT_FILE

If .meta file is present, use it to print updated
metadata information of the data file.

Change-Id: Id89fb2257307224c423cf6f6f1ca24f436b7821f
Closes-Bug: #1431334
",git fetch https://review.opendev.org/openstack/swift refs/changes/58/189258/14 && git format-patch -1 --stdout FETCH_HEAD,['swift/cli/info.py'],1,76ef78df51cb22dceae1008846e771ad3c1490fc,bug/1431334," # if target datafile is directory, print info about files inside if os.path.isdir(datafile): for (dirpath, dirnames, filenames) in os.walk(datafile): for f in filenames: new_datafile = os.path.join(datafile,f) if os.path.isfile(new_datafile): print (""Checking file %s"" % new_datafile) print_obj(new_datafile, check_etag, swift_dir, policy_name) break # not going deeper return ",,11,0
openstack%2Ftacker~master~I3cc23a2f058a46618015bdd40a8b631e0001cb54,openstack/tacker,master,I3cc23a2f058a46618015bdd40a8b631e0001cb54,Fix error msg bug when delete a vnf in pending_delete state,NEW,2016-09-03 07:27:40.000000000,2017-12-18 04:53:04.000000000,,[{'_account_id': 18955}],"[{'number': 1, 'created': '2016-09-03 07:27:40.000000000', 'files': ['tacker/db/vm/vm_db.py', 'tacker/extensions/vnfm.py', 'doc/source/devref/tacker_functional_test.rst'], 'web_link': 'https://opendev.org/openstack/tacker/commit/9e7baaf4dd2b26ccc3250dd71d2f067eae830394', 'message': 'Fix error msg bug when delete a vnf in pending_delete state\n\ndelete a vnf in pending_delete status will get a error message ""\n404 VNF NOT FOUND"", this patch fix the bug, and return message ""\n409 VNF in invalid status""\n\nChange-Id: I3cc23a2f058a46618015bdd40a8b631e0001cb54\n'}]",2,365218,9e7baaf4dd2b26ccc3250dd71d2f067eae830394,5,1,1,19951,,,0,"Fix error msg bug when delete a vnf in pending_delete state

delete a vnf in pending_delete status will get a error message ""
404 VNF NOT FOUND"", this patch fix the bug, and return message ""
409 VNF in invalid status""

Change-Id: I3cc23a2f058a46618015bdd40a8b631e0001cb54
",git fetch https://review.opendev.org/openstack/tacker refs/changes/18/365218/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/db/vm/vm_db.py', 'tacker/extensions/vnfm.py', 'doc/source/devref/tacker_functional_test.rst']",3,9e7baaf4dd2b26ccc3250dd71d2f067eae830394,bug/error-exception-msg, , ,8,2
openstack%2Fstorlets~master~I106d6b5e640349730030d1fad86615ec9fc644d1,openstack/storlets,master,I106d6b5e640349730030d1fad86615ec9fc644d1,Cleanup code for FileManager and invocation_flow,NEW,2016-08-02 07:20:44.000000000,2017-12-18 04:52:47.000000000,,"[{'_account_id': 4608}, {'_account_id': 9816}]","[{'number': 1, 'created': '2016-08-02 07:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/841b4d41df7fe28f66c2fe85dc72dac9c75360cc', 'message': ""WIP: Items to consider for FileManager\n\nThis probably make a lack of cache efficiency in the case of\n\n swift_obj == local cache > docker_dir\n\nit's in TODO list\n\nChange-Id: I106d6b5e640349730030d1fad86615ec9fc644d1\n""}, {'number': 2, 'created': '2016-08-04 05:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/7b81484c652785ff0477a237963d9f3a3f0e853e', 'message': ""WIP: Items to consider for FileManager\n\nThis probably make a lack of cache efficiency in the case of\n\n swift_obj == local cache > docker_dir\n\nit's in TODO list\n\nChange-Id: I106d6b5e640349730030d1fad86615ec9fc644d1\n""}, {'number': 3, 'created': '2016-08-04 08:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/a98b46853eb7bf34334e1ecc04dc0e4ad2d75992', 'message': 'Cleanup code for FileManager and invocation_flow\n\nThis patch changes recent FileManager construction.\n\nThe older one requires single centralized file manager which needs\ngateway specific methods (e.g. put_log). However, IMHO, more general\nabstraction is suitable to develop the custom file managers as you want\nso that this patch reconstruct the FileManager class like as:\n\nStorletFileManager (This class):\n    |\n    |--- storlet_manager (instance) ------ get_file   (method)\n    |                                   |\n    |                                   -- write_file (method)\n    |\n    |--- dependency_manager (instance) --- get_file   (method)\n    |                                   |\n    |                                   -- write_file (method)\n    |\n    |--- log_manager (instance) ---------- get_file   (method)\n                                        |\n                                        -- write_file (method)\n\nEach manager instance only requires 2 methods\n\n- get_file: return a file instance to read from\n- write_file: take 2 args, object_name to write to, and file object\n              to read content from\n\nOn the invocation_flow perspective, this patch refactors the cache\nmanagement flow as splitting the routine into storlet apps and\ndependency files. And then, this makes each flow to go straight forward\nwithout ""if is_storlet"" branch.\n\nMisc.\n- Cleanup tests more!\n\nChange-Id: I106d6b5e640349730030d1fad86615ec9fc644d1\n'}, {'number': 4, 'created': '2016-08-04 10:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/b0304f11763da8e51b2886f48c072d981c4e794b', 'message': 'Cleanup code for FileManager and invocation_flow\n\nThis patch changes recent FileManager construction.\n\nThe older one requires single centralized file manager which needs\ngateway specific methods (e.g. put_log). However, IMHO, more general\nabstraction is suitable to develop the custom file managers as you want\nso that this patch reconstruct the FileManager class like as:\n\nStorletFileManager (This class):\n    |\n    |--- storlet_manager (instance) ------ get_file   (method)\n    |                                   |\n    |                                   -- write_file (method)\n    |\n    |--- dependency_manager (instance) --- get_file   (method)\n    |                                   |\n    |                                   -- write_file (method)\n    |\n    |--- log_manager (instance) ---------- get_file   (method)\n                                        |\n                                        -- write_file (method)\n\nEach manager instance only requires 2 methods\n\n- get_file: return a file instance to read from\n- write_file: take 2 args, object_name to write to, and file object\n              to read content from\n\nOn the invocation_flow perspective, this patch refactors the cache\nmanagement flow as splitting the routine into storlet apps and\ndependency files. And then, this makes each flow to go straight forward\nwithout ""if is_storlet"" branch.\n\nMisc.\n- Cleanup tests more!\n\nChange-Id: I106d6b5e640349730030d1fad86615ec9fc644d1\n'}, {'number': 5, 'created': '2016-08-05 01:14:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/bc913e2c49c357a65e0078de5cfa7913e3b9f830', 'message': 'Cleanup code for FileManager and invocation_flow\n\nThis patch changes recent FileManager construction.\n\nThe older one requires single centralized file manager which needs\ngateway specific methods (e.g. put_log). However, IMHO, more general\nabstraction is suitable to develop the custom file managers as you want\nso that this patch reconstruct the FileManager class like as:\n\nStorletFileManager (This class):\n    |\n    |--- storlet_manager (instance) ------ get_file   (method)\n    |                                   |\n    |                                   -- write_file (method)\n    |\n    |--- dependency_manager (instance) --- get_file   (method)\n    |                                   |\n    |                                   -- write_file (method)\n    |\n    |--- log_manager (instance) ---------- get_file   (method)\n                                        |\n                                        -- write_file (method)\n\nEach manager instance only requires 2 methods\n\n- get_file: return a file instance to read from\n- write_file: take 2 args, object_name to write to, and file object\n              to read content from\n\nOn the invocation_flow perspective, this patch refactors the cache\nmanagement flow as splitting the routine into storlet apps and\ndependency files. And then, this makes each flow to go straight forward\nwithout ""if is_storlet"" branch.\n\nMisc.\n- Cleanup tests more!\n\nChange-Id: I106d6b5e640349730030d1fad86615ec9fc644d1\n'}, {'number': 6, 'created': '2016-08-05 06:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/0ac209e7d7bf7ca9ea116534db52c4f214d9b81f', 'message': 'Cleanup code for FileManager and invocation_flow\n\nThis patch changes recent FileManager construction.\n\nThe older one requires single centralized file manager which needs\ngateway specific methods (e.g. put_log). However, IMHO, more general\nabstraction is suitable to develop the custom file managers as you want\nso that this patch reconstruct the FileManager class like as:\n\nStorletFileManager (This class):\n    |\n    |--- storlet_manager (instance) ------ get_file   (method)\n    |                                   |\n    |                                   -- write_file (method)\n    |\n    |--- dependency_manager (instance) --- get_file   (method)\n    |                                   |\n    |                                   -- write_file (method)\n    |\n    |--- log_manager (instance) ---------- get_file   (method)\n                                        |\n                                        -- write_file (method)\n\nEach manager instance only requires 2 methods\n\n- get_file: return a file instance to read from\n- write_file: take 2 args, object_name to write to, and file object\n              to read content from\n\nOn the invocation_flow perspective, this patch refactors the cache\nmanagement flow as splitting the routine into storlet apps and\ndependency files. And then, this makes each flow to go straight forward\nwithout ""if is_storlet"" branch.\n\nMisc.\n- Cleanup tests more!\n\nChange-Id: I106d6b5e640349730030d1fad86615ec9fc644d1\n'}, {'number': 7, 'created': '2016-08-05 06:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/7cd83fade4711556022dce4d90a9b7ebc19f1056', 'message': 'Cleanup code for FileManager and invocation_flow\n\nThis patch changes recent FileManager construction.\n\nThe older one requires single centralized file manager which needs\ngateway specific methods (e.g. put_log). However, IMHO, more general\nabstraction is suitable to develop the custom file managers as you want\nso that this patch reconstruct the FileManager class like as:\n\nStorletFileManager (This class):\n    |\n    |--- storlet_manager (instance) ------ get_file   (method)\n    |                                   |\n    |                                   -- write_file (method)\n    |\n    |--- dependency_manager (instance) --- get_file   (method)\n    |                                   |\n    |                                   -- write_file (method)\n    |\n    |--- log_manager (instance) ---------- get_file   (method)\n                                        |\n                                        -- write_file (method)\n\nEach manager instance only requires 2 methods\n\n- get_file: return a file instance to read from\n- write_file: take 2 args, object_name to write to, and file object\n              to read content from\n\nOn the invocation_flow perspective, this patch refactors the cache\nmanagement flow as splitting the routine into storlet apps and\ndependency files. And then, this makes each flow to go straight forward\nwithout ""if is_storlet"" branch.\n\nMisc.\n- Cleanup tests more!\n\nChange-Id: I106d6b5e640349730030d1fad86615ec9fc644d1\n'}, {'number': 8, 'created': '2016-08-16 01:48:59.000000000', 'files': ['Engine/swift/storlet_gateway/gateways/base.py', 'Engine/swift/storlet_middleware/handlers/obj.py', 'tests/unit/swift/__init__.py', 'tests/unit/swift/storlet_middleware/handlers/test_proxy.py', 'tests/unit/swift/storlet_middleware/handlers/test_base.py', 'Engine/swift/storlet_gateway/common/file_manager.py', 'Engine/swift/storlet_gateway/gateways/stub.py', 'Engine/swift/storlet_gateway/gateways/docker/gateway.py', 'tests/unit/swift/storlet_gateway/gateways/docker/test_gateway.py', 'Engine/swift/storlet_middleware/handlers/proxy.py', 'tests/unit/swift/storlet_middleware/handlers/test_obj.py', 'Engine/swift/storlet_middleware/storlet_handler.py', 'Engine/swift/storlet_middleware/handlers/base.py', 'tests/unit/swift/storlet_middleware/handlers/__init__.py'], 'web_link': 'https://opendev.org/openstack/storlets/commit/12a696ff795288f987d00338362826e6e7418ab1', 'message': 'Cleanup code for FileManager and invocation_flow\n\nThis patch changes recent FileManager construction.\n\nThe older one requires single centralized file manager which needs\ngateway specific methods (e.g. put_log). However, IMHO, more general\nabstraction is suitable to develop the custom file managers as you want\nso that this patch reconstruct the FileManager class like as:\n\nStorletFileManager (This class):\n    |\n    |--- storlet_manager (instance) ------ get_file   (method)\n    |                                   |\n    |                                   -- write_file (method)\n    |\n    |--- dependency_manager (instance) --- get_file   (method)\n    |                                   |\n    |                                   -- write_file (method)\n    |\n    |--- log_manager (instance) ---------- get_file   (method)\n                                        |\n                                        -- write_file (method)\n\nEach manager instance only requires 2 methods\n\n- get_file: return a file instance to read from\n- write_file: take 2 args, object_name to write to, and file object\n              to read content from\n\nOn the invocation_flow perspective, this patch refactors the cache\nmanagement flow as splitting the routine into storlet apps and\ndependency files. And then, this makes each flow to go straight forward\nwithout ""if is_storlet"" branch.\n\nMisc.\n- Cleanup tests more!\n\nChange-Id: I106d6b5e640349730030d1fad86615ec9fc644d1\n'}]",22,349834,12a696ff795288f987d00338362826e6e7418ab1,25,2,8,4608,,,0,"Cleanup code for FileManager and invocation_flow

This patch changes recent FileManager construction.

The older one requires single centralized file manager which needs
gateway specific methods (e.g. put_log). However, IMHO, more general
abstraction is suitable to develop the custom file managers as you want
so that this patch reconstruct the FileManager class like as:

StorletFileManager (This class):
    |
    |--- storlet_manager (instance) ------ get_file   (method)
    |                                   |
    |                                   -- write_file (method)
    |
    |--- dependency_manager (instance) --- get_file   (method)
    |                                   |
    |                                   -- write_file (method)
    |
    |--- log_manager (instance) ---------- get_file   (method)
                                        |
                                        -- write_file (method)

Each manager instance only requires 2 methods

- get_file: return a file instance to read from
- write_file: take 2 args, object_name to write to, and file object
              to read content from

On the invocation_flow perspective, this patch refactors the cache
management flow as splitting the routine into storlet apps and
dependency files. And then, this makes each flow to go straight forward
without ""if is_storlet"" branch.

Misc.
- Cleanup tests more!

Change-Id: I106d6b5e640349730030d1fad86615ec9fc644d1
",git fetch https://review.opendev.org/openstack/storlets refs/changes/34/349834/5 && git format-patch -1 --stdout FETCH_HEAD,"['Engine/swift/storlet_gateway/gateways/docker/gateway.py', 'tests/unit/swift/storlet_middleware/handlers/test_proxy.py', 'tests/unit/swift/storlet_middleware/handlers/test_base.py', 'tests/unit/swift/storlet_middleware/handlers/test_obj.py', 'Engine/swift/storlet_middleware/storlet_handler.py', 'Engine/swift/storlet_gateway/common/file_manager.py', 'Engine/swift/storlet_middleware/handlers/base.py', 'tests/unit/swift/storlet_middleware/handlers/__init__.py']",8,841b4d41df7fe28f66c2fe85dc72dac9c75360cc,thought-filemanagement,"import os.path import shutilfrom tempfile import mkdtempdef create_internal_client_conf(conf_path): with open(conf_path, 'w') as f: f.write("""""" [DEFAULT] [pipeline: main] pipeline = catch_errors proxy-logging cache proxy-server [app:proxy-server] use = egg:swift#proxy [filter:cache] use = egg:swift#memcache [filter:proxy-logging] use = egg:swift#proxy_logging [filter:catch_errors] use = egg:swift#catch_errors """""") self.tempdir = mkdtemp() self.internal_client_conf_path = os.path.join( self.tempdir, 'swift-proxy-server.conf') create_internal_client_conf(self.internal_client_conf_path) self.conf['internal_client_conf'] = self.internal_client_conf_path shutil.rmtree(self.tempdir) get_fake_logger:", pass get_fake_logger:,306,309
openstack%2Fheat-templates~master~I1c8740725c0df9be9c0547a68899acd8a18be998,openstack/heat-templates,master,I1c8740725c0df9be9c0547a68899acd8a18be998,Update image_id parameters of Fedora img url in HOT file,NEW,2016-09-12 07:44:21.000000000,2017-12-18 04:52:37.000000000,,[{'_account_id': 20559}],"[{'number': 1, 'created': '2016-09-12 07:44:21.000000000', 'files': ['hot/asg_of_stacks.yaml', 'hot/F24/WordPress_Native.yaml', 'hot/F24/WordPress_2_Instances.yaml', 'hot/asg_of_servers.yaml', 'hot/vm_with_cinder.yaml'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/19bf75a1d92cd43e416c4aaed22e7ad7a0e334e3', 'message': 'Update image_id parameters of Fedora img url in HOT file\n\nWhen creating stacks based on HOT files of heat-templates\nproject, the fedora img url of fedora-20.x86_64.qcow2 is\noutdated. The fedora img url of Fedora-Cloud-Base-24-1.2.x86\nhas been updated in corresponding HOT file.\nCreated the directory(F24) for keeping version consistency.\nChange-Id: I1c8740725c0df9be9c0547a68899acd8a18be998\n'}]",1,368607,19bf75a1d92cd43e416c4aaed22e7ad7a0e334e3,4,1,1,23457,,,0,"Update image_id parameters of Fedora img url in HOT file

When creating stacks based on HOT files of heat-templates
project, the fedora img url of fedora-20.x86_64.qcow2 is
outdated. The fedora img url of Fedora-Cloud-Base-24-1.2.x86
has been updated in corresponding HOT file.
Created the directory(F24) for keeping version consistency.
Change-Id: I1c8740725c0df9be9c0547a68899acd8a18be998
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/07/368607/1 && git format-patch -1 --stdout FETCH_HEAD,"['hot/asg_of_stacks.yaml', 'hot/F24/WordPress_Native.yaml', 'hot/F24/WordPress_2_Instances.yaml', 'hot/asg_of_servers.yaml', 'hot/vm_with_cinder.yaml']",5,19bf75a1d92cd43e416c4aaed22e7ad7a0e334e3,, You can get the default from https://download.fedoraproject.org/pub/fedora/linux/releases/24/\ CloudImages/x86_64/images/Fedora-Cloud-Base-24-1.2.x86_64.qcow2, You can get the default from http://cloud.fedoraproject.org/fedora-20.x86_64.qcow2 There is also http://cloud.fedoraproject.org/fedora-20.i386.qcow2,278,13
openstack%2Fglance~master~Id251419b84aa704c2355626287da81e12cf7f020,openstack/glance,master,Id251419b84aa704c2355626287da81e12cf7f020,Stop 500s when adding duplicate image property,NEW,2016-03-10 14:10:49.000000000,2017-12-18 04:52:30.000000000,,"[{'_account_id': 455}, {'_account_id': 2537}, {'_account_id': 5314}, {'_account_id': 8158}]","[{'number': 1, 'created': '2016-03-10 14:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4fb4b7cf8960958b43176369582fabf4353a9228', 'message': ""Stop 500s when adding duplicate image property\n\nAdds a new exception for DuplicatePropertyName and catches it in\nappropriate places in the Images v1 and v2 APIs.\n\n* Returns a 409 (Conflict) when a user tries to add a duplicate\n  property name when updating an image by PATCH (v2) or PUT (v1).\n* In the v2 API, returns a 400 (Bad Request) when a user tries\n  to create an image with duplicate property names in the request.\n* Leaves the v1 API behavior unmodified when a user tries to\n  create an image with duplicate property names in the request, as\n  (unlike for v2) the current behavior does not cause a 500 (and\n  hopefully v1 won't be around too much longer anyway).\n  ** using python-glanceclient: the first property name/value pair\n     is used, the other is ignored; property name is created as\n     all-lowercase regardless of how it was specified\n  ** using v1 API directly: single all-lowercase property name is\n     created, values of the duplicate name/value pairs are\n     concatenated together, comma-separated\n\nGlance is case-insensitive when detecting duplicate property names,\nbut it allows a user to store the name in any case combination.\n(This behavior is unchanged.)\n\nChange-Id: Id251419b84aa704c2355626287da81e12cf7f020\nCloses-bug: #1554232\n""}, {'number': 2, 'created': '2016-03-10 16:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/56b524233fcb80cd77dff68a3d512b5a48a3074d', 'message': ""Stop 500s when adding duplicate image property\n\nAdds a new exception for DuplicatePropertyName and catches it in\nappropriate places in the Images v1 and v2 APIs.\n\n* Returns a 409 (Conflict) when a user tries to add a duplicate\n  property name when updating an image by PATCH (v2) or PUT (v1).\n* In the v2 API, returns a 400 (Bad Request) when a user tries\n  to create an image with duplicate property names in the request.\n* Leaves the v1 API behavior unmodified when a user tries to\n  create an image with duplicate property names in the request, as\n  (unlike for v2) the current behavior does not cause a 500 (and\n  hopefully v1 won't be around too much longer anyway).\n  ** using python-glanceclient: the first property name/value pair\n     is used, the other is ignored; property name is created as\n     all-lowercase regardless of how it was specified\n  ** using v1 API directly: single all-lowercase property name is\n     created, values of the duplicate name/value pairs are\n     concatenated together, comma-separated\n\nGlance is case-insensitive when detecting duplicate property names,\nbut it allows a user to store the name in any case combination.\n(This behavior is unchanged.)\n\nChange-Id: Id251419b84aa704c2355626287da81e12cf7f020\nCloses-bug: #1554232\n""}, {'number': 3, 'created': '2016-03-18 01:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/65170ae3811635a7384f1269af3bea0ff738f10b', 'message': ""Stop 500s when adding duplicate image property\n\nAdds a new exception for DuplicatePropertyName and catches it in\nappropriate places in the Images v1 and v2 APIs.\n\n* Returns a 409 (Conflict) when a user tries to add a duplicate\n  property name when updating an image by PATCH (v2) or PUT (v1).\n* In the v2 API, returns a 400 (Bad Request) when a user tries\n  to create an image with duplicate property names in the request.\n* Leaves the v1 API behavior unmodified when a user tries to\n  create an image with duplicate property names in the request, as\n  (unlike for v2) the current behavior does not cause a 500 (and\n  hopefully v1 won't be around too much longer anyway).\n  ** using python-glanceclient: the first property name/value pair\n     is used, the other is ignored; property name is created as\n     all-lowercase regardless of how it was specified\n  ** using v1 API directly: single all-lowercase property name is\n     created, values of the duplicate name/value pairs are\n     concatenated together, comma-separated\n\nGlance is case-insensitive when detecting duplicate property names,\nbut it allows a user to store the name in any case combination.\n(This behavior is unchanged.)\n\nChange-Id: Id251419b84aa704c2355626287da81e12cf7f020\nCloses-bug: #1554232\n""}, {'number': 4, 'created': '2016-03-29 13:31:37.000000000', 'files': ['glance/registry/api/v1/images.py', 'glance/tests/unit/test_db.py', 'glance/common/exception.py', 'glance/db/simple/api.py', 'glance/api/v2/images.py', 'glance/tests/unit/v1/test_api.py', 'glance/db/sqlalchemy/api.py', 'glance/api/v1/images.py', 'glance/tests/unit/v2/test_images_resource.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/609a2ddb631880ab445c029132815c3b31b73db1', 'message': ""Stop 500s when adding duplicate image property\n\nAdds a new exception for DuplicatePropertyName and catches it in\nappropriate places in the Images v1 and v2 APIs.\n\n* Returns a 409 (Conflict) when a user tries to add a duplicate\n  property name when updating an image by PATCH (v2) or PUT (v1).\n* In the v2 API, returns a 400 (Bad Request) when a user tries\n  to create an image with duplicate property names in the request.\n* Leaves the v1 API behavior unmodified when a user tries to\n  create an image with duplicate property names in the request, as\n  (unlike for v2) the current behavior does not cause a 500 (and\n  hopefully v1 won't be around too much longer anyway).\n  ** using v1 API via python-glanceclient: the first property\n     name/value pair is used, the other is ignored; property name is\n     created as all-lowercase regardless of how it was specified\n  ** using v1 API directly: single all-lowercase property name is\n     created, values of the duplicate name/value pairs are\n     concatenated together, comma-separated\n\nGlance is case-insensitive when detecting duplicate property names,\nbut it allows a user to store the name in any case combination.\n(This behavior is unchanged.)\n\nChange-Id: Id251419b84aa704c2355626287da81e12cf7f020\nCloses-bug: #1554232\n""}]",8,291198,609a2ddb631880ab445c029132815c3b31b73db1,21,4,4,5314,,,0,"Stop 500s when adding duplicate image property

Adds a new exception for DuplicatePropertyName and catches it in
appropriate places in the Images v1 and v2 APIs.

* Returns a 409 (Conflict) when a user tries to add a duplicate
  property name when updating an image by PATCH (v2) or PUT (v1).
* In the v2 API, returns a 400 (Bad Request) when a user tries
  to create an image with duplicate property names in the request.
* Leaves the v1 API behavior unmodified when a user tries to
  create an image with duplicate property names in the request, as
  (unlike for v2) the current behavior does not cause a 500 (and
  hopefully v1 won't be around too much longer anyway).
  ** using v1 API via python-glanceclient: the first property
     name/value pair is used, the other is ignored; property name is
     created as all-lowercase regardless of how it was specified
  ** using v1 API directly: single all-lowercase property name is
     created, values of the duplicate name/value pairs are
     concatenated together, comma-separated

Glance is case-insensitive when detecting duplicate property names,
but it allows a user to store the name in any case combination.
(This behavior is unchanged.)

Change-Id: Id251419b84aa704c2355626287da81e12cf7f020
Closes-bug: #1554232
",git fetch https://review.opendev.org/openstack/glance refs/changes/98/291198/4 && git format-patch -1 --stdout FETCH_HEAD,"['glance/registry/api/v1/images.py', 'glance/common/exception.py', 'glance/api/v2/images.py', 'glance/db/sqlalchemy/api.py', 'glance/api/v1/images.py']",5,4fb4b7cf8960958b43176369582fabf4353a9228,bug-1554232," except exception.Duplicate as e: msg = encodeutils.exception_to_unicode(e) #TODO(rosmaita): log at info level instead? LOG.warn(_LW(""Problem updating image %(id)s: %(error)s""), {'id': id, 'error': msg}) raise HTTPConflict(body=msg, request=req, content_type='text/plain') except exception.Conflict as e:"," except (exception.Conflict, exception.Duplicate) as e:",38,2
openstack%2Ftacker~master~If47c816c237a3cbbfd3f7c6cea156295593a0592,openstack/tacker,master,If47c816c237a3cbbfd3f7c6cea156295593a0592,Add exception handle to delete vnfd in functional tests,NEW,2016-08-06 08:57:01.000000000,2017-12-18 04:52:20.000000000,,[{'_account_id': 18955}],"[{'number': 1, 'created': '2016-08-06 08:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/1115d80aeb5cec021e1f69dcdbe0150d11343f79', 'message': 'Add exception handle to delete vnfd in functional tests\n\nIn current code files, the exception handle of deleting vnfd\nin functional tests like this:\n\n    self.assertIsNotNone(vnfd_id)\n    try:\n        self.client.delete_vnfd(vnfd_id)\n    except Exception:\n        assert False, ""vnfd Delete failed""\n\nThis case just judge the failure of deleting vnfd. But if it didn\'t\ndelete vnfd, there is no possibility of falilure. So this code:\n\n   except Exception:\n        assert False, ""vnfd Delete failed""\n\nwill be skipped. But acctually, most cases we just think about delete\nvnfd successfully. This judgement is wrong.\nSo add a exception handle like this:\n\n    try:\n        self.client.delete_vnfd(vnfd_id)\n    except Exception:\n        assert False, ""vnfd Delete failed""\n    try:\n        vnfd_d = self.client.show_vnfd(vnfd_id)\n    except Exception:\n        assert True, ""Vnfd Delete success"" + str(vnfd_d) + str(Exception)\n\nUse show_vnfd(vnfd_id) again, which make sure the success of deleting vnfd.\n\nChange-Id: If47c816c237a3cbbfd3f7c6cea156295593a0592\n'}, {'number': 2, 'created': '2016-08-17 09:24:49.000000000', 'files': ['tacker/tests/functional/vnfm/test_vnfd.py', 'tacker/tests/functional/vnfm/test_tosca_vnfd.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/be6139466973d05283a920e003b7561b87d42b95', 'message': 'Add exception handle to delete vnfd in functional tests\n\nIn current code files, the exception handle of deleting vnfd\nin functional tests like this:\n\n    self.assertIsNotNone(vnfd_id)\n    try:\n        self.client.delete_vnfd(vnfd_id)\n    except Exception:\n        assert False, ""vnfd Delete failed""\n\nThis case just judge the failure of deleting vnfd. But if it didn\'t\ndelete vnfd, there is no possibility of failure. So this code:\n\n   except Exception:\n        assert False, ""vnfd Delete failed""\n\nwill be skipped. But actually, most cases we just think about delete\nvnfd successfully. This judgment is wrong.\nSo add a exception handle like this:\n\n    try:\n        self.client.delete_vnfd(vnfd_id)\n    except Exception:\n        assert False, ""vnfd Delete failed""\n    try:\n        vnfd_d = self.client.show_vnfd(vnfd_id)\n    except Exception:\n        assert True, ""Vnfd Delete success"" + str(vnfd_d) + str(Exception)\n\nUse show_vnfd(vnfd_id) again, which make sure the success of deleting vnfd.\n\nChange-Id: If47c816c237a3cbbfd3f7c6cea156295593a0592\n'}]",2,352009,be6139466973d05283a920e003b7561b87d42b95,7,1,2,22132,,,0,"Add exception handle to delete vnfd in functional tests

In current code files, the exception handle of deleting vnfd
in functional tests like this:

    self.assertIsNotNone(vnfd_id)
    try:
        self.client.delete_vnfd(vnfd_id)
    except Exception:
        assert False, ""vnfd Delete failed""

This case just judge the failure of deleting vnfd. But if it didn't
delete vnfd, there is no possibility of failure. So this code:

   except Exception:
        assert False, ""vnfd Delete failed""

will be skipped. But actually, most cases we just think about delete
vnfd successfully. This judgment is wrong.
So add a exception handle like this:

    try:
        self.client.delete_vnfd(vnfd_id)
    except Exception:
        assert False, ""vnfd Delete failed""
    try:
        vnfd_d = self.client.show_vnfd(vnfd_id)
    except Exception:
        assert True, ""Vnfd Delete success"" + str(vnfd_d) + str(Exception)

Use show_vnfd(vnfd_id) again, which make sure the success of deleting vnfd.

Change-Id: If47c816c237a3cbbfd3f7c6cea156295593a0592
",git fetch https://review.opendev.org/openstack/tacker refs/changes/09/352009/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/tests/functional/vnfm/test_vnfd.py', 'tacker/tests/functional/vnfm/test_tosca_vnfd.py']",2,1115d80aeb5cec021e1f69dcdbe0150d11343f79,exception_2_fun_tests," try: vnfd_d = self.client.show_vnfd(vnfd_id) except Exception: assert True, ""Vnfd Delete success"" + str(vnfd_d) + str(Exception)",,8,0
openstack%2Fmonasca-analytics~master~I19978b9251fbb32411fce1928a1628a6d46b185a,openstack/monasca-analytics,master,I19978b9251fbb32411fce1928a1628a6d46b185a,Implemented and tested the JSON configurable ingestor,NEW,2016-07-11 12:51:59.000000000,2017-12-18 04:52:15.000000000,,"[{'_account_id': 2419}, {'_account_id': 12193}, {'_account_id': 21466}, {'_account_id': 21885}]","[{'number': 1, 'created': '2016-07-11 12:51:59.000000000', 'files': ['test/ingestor/test_base.py', 'monasca_analytics/dsl/const.py', 'monasca_analytics/dsl/json_parser.py', 'test/util/test_common_util.py', 'monasca_analytics/ingestor/json_base.py', 'test/dsl/test_parser.py', 'monasca_analytics/dsl/parser.py', 'monasca_analytics/dsl/dsl.py', 'monasca_analytics/dsl/interpreter.py', 'test/ingestor/test_json_base.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/e80963e9f7b036290005de54379778eb3be6479c', 'message': 'Implemented and tested the JSON configurable ingestor\n\nChange-Id: I19978b9251fbb32411fce1928a1628a6d46b185a\n'}]",2,340353,e80963e9f7b036290005de54379778eb3be6479c,7,4,1,21739,,,0,"Implemented and tested the JSON configurable ingestor

Change-Id: I19978b9251fbb32411fce1928a1628a6d46b185a
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/53/340353/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/ingestor/test_base.py', 'monasca_analytics/dsl/const.py', 'monasca_analytics/dsl/json_parser.py', 'test/util/test_common_util.py', 'monasca_analytics/ingestor/json_base.py', 'test/dsl/test_parser.py', 'monasca_analytics/dsl/dsl.py', 'monasca_analytics/dsl/parser.py', 'monasca_analytics/dsl/interpreter.py', 'test/ingestor/test_json_base.py']",10,e80963e9f7b036290005de54379778eb3be6479c,json_parser_generator,"#!/usr/bin/env python # Copyright (c) 2016 Hewlett Packard Enterprise Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import json import logging.config import os import unittest from monasca_analytics.ingestor import json_base class JsonIngestorTest(unittest.TestCase): """""" Class that tests the Json Ingestor """""" def setup_logging(self): current_dir = os.path.dirname(__file__) logging_config_file = os.path.join(current_dir, ""../resources/logging.json"") with open(logging_config_file, ""rt"") as f: config = json.load(f) logging.config.dictConfig(config) def setUp(self): self.setup_logging() def tearDown(self): pass structure_numbers = { ""metric"": { ""temperature"": ""number"", ""usage"": { ""max"": ""number"", ""min"": ""number"" }, ""energy_cons"": ""number"" } } expected_features_numbers = ['metric.usage.max', 'metric.usage.min', 'metric.temperature', 'metric.energy_cons'] structure_enum = { ""person"": { ""city"": ""Barcelona Bristol London Madrid Paris"", ""job"": ""operations sysadmin engineer sales"" } } expected_features_enum = ['person.city.Barcelona', 'person.city.Bristol', 'person.city.London', 'person.city.Madrid', 'person.city.Paris', 'person.job.operations', 'person.job.sysadmin', 'person.job.engineer', 'person.job.sales'] def test_extract_features_from_structure_numbers(self): ji = json_base.JsonIngestor(""id1"", {""module"": ""test1""}, ""name1"", self.structure_numbers) self.assertItemsEqual(self.expected_features_numbers, ji._features) def test_extract_features_from_structure_enums(self): ji = json_base.JsonIngestor(""id1"", {""module"": ""test1""}, ""name1"", self.structure_enum) self.assertItemsEqual(self.expected_features_enum, ji._features) def test_extract_data_numbers(self): entry = { ""ctime"": ""Mon Apr 11 19:59:12 2016"", ""metric"": { ""id"": ""cpu"", ""temperature"": 75, ""usage"": { ""current"": 51.5, ""max"": 98, ""min"": 5.1 }, ""power_state"": ""on"", ""energy_cons"": 140 } } expected_values = [98, 5.1, 75, 140] ji = json_base.JsonIngestor(""id1"", {""module"": ""test1""}, ""name1"", self.structure_numbers) values = ji.extract_data(self.structure_numbers, entry) self.assertItemsEqual(expected_values, values) def test_extract_data_enums(self): entry = { ""ctime"": ""Mon Apr 11 19:59:12 2016"", ""person"": { ""id"": ""my_id"", ""age"": 25, ""city"": ""Barcelona"", ""job"": ""engineer"" } } structure = { ""person"": { ""city"": ""Barcelona Bristol London Madrid Paris"", ""job"": ""operations sysadmin engineer sales"" } } expected_values = [1, 0, 0, 0, 0, 0, 0, 1, 0] ji = json_base.JsonIngestor(""id2"", {""module"": ""test2""}, ""name2"", structure) values = ji.extract_data(structure, entry) self.assertItemsEqual(expected_values, values) def test_extract_order_features_data_numbers(self): ji = json_base.JsonIngestor(""id1"", {""module"": ""test1""}, ""name1"", self.structure_numbers) entry = { ""ctime"": ""Mon Apr 11 19:59:12 2016"", ""metric"": { ""id"": ""cpu"", ""temperature"": 75, ""usage"": { ""current"": 51.5, ""max"": 98, ""min"": 5.1 }, ""power_state"": ""on"", ""energy_cons"": 140 } } values = ji.extract_data(self.structure_numbers, entry) for i in range(len(ji._features)): if ji._features[i] == 'metric.usage.max': self.assertEqual(98, values[i]) elif ji._features[i] == 'metric.usage.min': self.assertEqual(5.1, values[i]) elif ji._features[i] == 'metric.temperature': self.assertEqual(75, values[i]) elif ji._features[i] == 'metric.energy_cons': self.assertEqual(140, values[i]) else: self.fail(""unknown feature : "" + ji._features[i]) def test_extract_order_features_data_enums(self): ji = json_base.JsonIngestor(""id1"", {""module"": ""test1""}, ""name1"", self.structure_enum) entry = { ""ctime"": ""Mon Apr 11 19:59:12 2016"", ""person"": { ""id"": ""my_id"", ""age"": 25, ""city"": ""Barcelona"", ""job"": ""engineer"" } } values = ji.extract_data(self.structure_enum, entry) for i in range(len(ji._features)): if ji._features[i] == 'person.city.Barcelona': self.assertEqual(1, values[i]) elif ji._features[i] == 'person.city.Bristol': self.assertEqual(0, values[i]) elif ji._features[i] == 'person.city.London': self.assertEqual(0, values[i]) elif ji._features[i] == 'person.city.Madrid': self.assertEqual(0, values[i]) elif ji._features[i] == 'person.city.Paris': self.assertEqual(0, values[i]) elif ji._features[i] == 'person.job.operations': self.assertEqual(0, values[i]) elif ji._features[i] == 'person.job.sysadmin': self.assertEqual(0, values[i]) elif ji._features[i] == 'person.job.engineer': self.assertEqual(1, values[i]) elif ji._features[i] == 'person.job.sales': self.assertEqual(0, values[i]) else: self.fail(""unknown feature : "" + ji._features[i]) ",,637,12
openstack%2Fmanila~master~Ie8e0ff7ef69650f7f79dd97f7401f64df0c81834,openstack/manila,master,Ie8e0ff7ef69650f7f79dd97f7401f64df0c81834,Adding NFS support to container driver,NEW,2016-07-04 05:34:00.000000000,2017-12-18 04:52:10.000000000,,"[{'_account_id': 2417}, {'_account_id': 6938}, {'_account_id': 8056}, {'_account_id': 9003}, {'_account_id': 9521}, {'_account_id': 10621}, {'_account_id': 12017}, {'_account_id': 13144}, {'_account_id': 13998}, {'_account_id': 14384}, {'_account_id': 15942}, {'_account_id': 16657}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 18128}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 20695}, {'_account_id': 21884}, {'_account_id': 22236}, {'_account_id': 22248}]","[{'number': 1, 'created': '2016-07-04 05:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/6e5cfa90e333a0718d298c0587b3f0249c57d307', 'message': 'Adding NFS support to container driver\n\nThis change adds support for NFS to container driver\nby providing extra helpers. The new helpers allow to interact\nwith nfs-ganesha running inside a container.\n\nChange-Id: Ie8e0ff7ef69650f7f79dd97f7401f64df0c81834\n'}, {'number': 2, 'created': '2016-07-05 09:00:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/fa7020363f4d7ebddbace308af7cd0f8aaf5b0ac', 'message': 'Adding NFS support to container driver\n\nThis change adds support for NFS to container driver\nby providing extra helpers. The new helpers allow to interact\nwith nfs-ganesha running inside a container.\n\nChange-Id: Ie8e0ff7ef69650f7f79dd97f7401f64df0c81834\n'}, {'number': 3, 'created': '2016-07-06 08:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/05da98f15f8ec5b93bc97a68840387aa0c0b8972', 'message': 'Adding NFS support to container driver\n\nThis change adds support for NFS to container driver\nby providing extra helpers. The new helpers allow to interact\nwith nfs-ganesha running inside a container.\n\nChange-Id: Ie8e0ff7ef69650f7f79dd97f7401f64df0c81834\n'}, {'number': 4, 'created': '2016-08-18 14:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/9760c581165dba0fdbd40ebb8a0e6fff0630ee70', 'message': 'Adding NFS support to container driver\n\nThis change adds support for NFS to container driver\nby providing extra helpers. The new helpers allow to interact\nwith nfs-ganesha running inside a container.\n\nChange-Id: Ie8e0ff7ef69650f7f79dd97f7401f64df0c81834\n'}, {'number': 5, 'created': '2016-08-19 10:40:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1cc8bd69c7c476aaa82d1716e523bf280f025138', 'message': 'Adding NFS support to container driver\n\nThis change adds support for NFS to container driver\nby providing extra helpers. The new helpers allow to interact\nwith nfs-ganesha running inside a container.\n\nDepends-On: I63f3480ace3be70100a245570d7f3579b333e972\nChange-Id: Ie8e0ff7ef69650f7f79dd97f7401f64df0c81834\n'}, {'number': 6, 'created': '2016-08-19 10:47:11.000000000', 'files': ['manila/tests/share/drivers/container/test_storage_helper.py', 'manila/share/drivers/container/protocol_helper.py', 'manila/tests/share/drivers/container/test_driver.py', 'manila/share/drivers/container/driver.py', 'manila/tests/share/drivers/container/test_container_helper.py', 'manila/share/drivers/container/storage_helper.py', 'manila/share/drivers/container/container_helper.py', 'manila/tests/share/drivers/container/test_protocol_helper.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/c298440bf66ad678a0683fa6452dcb797452dc08', 'message': 'Adding NFS support to container driver\n\nThis change adds support for NFS to container driver\nby providing extra helpers. The new helpers allow to interact\nwith nfs-ganesha running inside a container.\n\nChange-Id: Ie8e0ff7ef69650f7f79dd97f7401f64df0c81834\n'}]",16,337007,c298440bf66ad678a0683fa6452dcb797452dc08,82,21,6,6938,,,0,"Adding NFS support to container driver

This change adds support for NFS to container driver
by providing extra helpers. The new helpers allow to interact
with nfs-ganesha running inside a container.

Change-Id: Ie8e0ff7ef69650f7f79dd97f7401f64df0c81834
",git fetch https://review.opendev.org/openstack/manila refs/changes/07/337007/3 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/container/protocol_helper.py', 'manila/tests/share/drivers/container/test_driver.py', 'manila/share/drivers/container/driver.py', 'manila/tests/share/drivers/container/test_container_helper.py', 'manila/share/drivers/container/container_helper.py', 'manila/tests/share/drivers/container/test_protocol_helper.py']",6,6e5cfa90e333a0718d298c0587b3f0249c57d307,ganesha-support," kwargs[""execute_arguments""].append(args) class DockerGaneshaBaseHelperTestCase(test.TestCase): fake_export = """""" struct { uint16 3 string ""/other_fake"" boolean false boolean false boolean false boolean false boolean true boolean false boolean false boolean false struct { uint64 1466593507 uint64 376350833 } } struct { uint16 4 string ""/fake_name"" boolean false boolean false boolean false boolean false boolean true boolean false boolean false boolean false struct { uint64 1466593507 uint64 375449577 } } """""" def setUp(self): super(DockerGaneshaBaseHelperTestCase, self).setUp() self._helper = mock.Mock() self.fake_conf = mock.Mock() self.ganesha_base_helper = protocol_helper.DockerGaneshaBaseHelper( self._helper, share=fake_share(), config=self.fake_conf) def test__extract_address(self): ret_val = ""\n\n192.0.2.2"" self.ganesha_base_helper.container.execute = mock.Mock( return_value=(ret_val, '')) result = self.ganesha_base_helper._extract_address(""fake_id"") self.assertEqual(result, ""192.0.2.2"") def test_creat_share(self): ret_val = ""\n\n192.0.2.2"" self.ganesha_base_helper.container.execute = mock.Mock( return_value=(ret_val, '')) result = self.ganesha_base_helper.create_share(""fake_id"") self.assertEqual(result, ""192.0.2.2"") def test__write_local_config(self): tmp = __builtins__[""open""] fake_file = mock.Mock() __builtins__[""open""] = mock.Mock(return_value=fake_file) self.ganesha_base_helper._write_local_config(""fake_server_id"", ""fake_filename"", ""fake_config"") __builtins__[""open""].assert_called_once_with(""fake_filename"", ""w"") fake_file.write.assert_called_once_with(""fake_config"") fake_file.close.assert_called_once() __builtins__[""open""] = tmp def test__add_export_by_id(self): self.ganesha_base_helper.container.execute = mock.Mock( return_value=("""", '')) self.ganesha_base_helper._add_export_by_id(""fake_server_id"", ""fake_config"", ""fake_id"") self.ganesha_base_helper.container.execute.assert_called_once() def test__remove_export(self): self.ganesha_base_helper.container.execute = mock.Mock( return_value=("""", '')) self.ganesha_base_helper._remove_export(""fake_server_id"", ""fake_id"") self.ganesha_base_helper.container.execute.\ assert_called_once_with('fake_server_id', ['dbus-send', '--print-reply', '--system', '--dest=org.ganesha.nfsd', '/org/ganesha/nfsd/ExportMgr', 'org.ganesha.nfsd.exportmgr.RemoveExport', 'uint16:fake_id']) def test__get_exports(self): self.ganesha_base_helper.container.execute = mock.Mock( return_value=("""", '')) self.ganesha_base_helper._get_exports(""fake_server_id"") self.ganesha_base_helper.container.execute.\ assert_called_once_with('fake_server_id', ['dbus-send', '--print-reply', '--system', '--dest=org.ganesha.nfsd', '/org/ganesha/nfsd/ExportMgr', 'org.ganesha.nfsd.exportmgr.ShowExports']) def test__fetch_export_by_share(self): self.ganesha_base_helper._get_exports = mock.Mock( return_value=self.fake_export) result = self.ganesha_base_helper._fetch_export_by_share( ""fake_name"", ""fake_server_id"") self.assertEqual(result, ['uint16 4\n string ""/fake_name""']) def test__get_new_export_id(self): self.ganesha_base_helper._get_exports = mock.Mock( return_value=self.fake_export) result = self.ganesha_base_helper._get_new_export_id(""fake_server_id"") self.assertEqual(result, '5') def test_delete_share(self): self.ganesha_base_helper.share = mock.Mock() self.ganesha_base_helper.share.share_id = ""fake_name"" self.ganesha_base_helper._get_exports = mock.Mock( return_value=self.fake_export) self.ganesha_base_helper._remove_export = mock.Mock() self.ganesha_base_helper.delete_share(""fake_server_id"") self.ganesha_base_helper._remove_export.\ assert_called_with(""fake_server_id"", ""4"") def test_update_access_update_all(self): self.ganesha_base_helper._remove_export = mock.Mock() self.ganesha_base_helper._allow_access = mock.Mock() self.ganesha_base_helper._get_exports = mock.Mock( return_value=self.fake_export) self.ganesha_base_helper.update_access(""fake_name"", ""fake_server_id"", [""fake_access""]) self.ganesha_base_helper._remove_export.\ assert_called_with('fake_server_id', ""4"") self.ganesha_base_helper._allow_access.\ assert_called_with('fake_server_id', ""fake_access"") def test_update_access_add_rule(self): self.ganesha_base_helper._allow_access = mock.Mock() self.ganesha_base_helper.update_access(""fake_name"", ""fake_server_id"", [], [""fake_access""], []) self.ganesha_base_helper._allow_access.\ assert_called_with('fake_server_id', ""fake_access"") def test_update_access_delete_rule(self): self.ganesha_base_helper._deny_access = mock.Mock() self.ganesha_base_helper.update_access(""fake_name"", ""fake_server_id"", [], [], [""fake_access""]) self.ganesha_base_helper._deny_access.\ assert_called_with('fake_server_id', ""fake_access"") def test__get_config_name(self): edir = ""/tmp/fake_local"" self.ganesha_base_helper.conf.container_data_exchange_dir_in = edir result = self.ganesha_base_helper._get_config_name(""fake_share"") self.assertEqual(result, ""/tmp/fake_local/fake_share.conf"") class DockerGaneshaReexportingHelperTestCase(test.TestCase): def setUp(self): super(DockerGaneshaReexportingHelperTestCase, self).setUp() self._helper = mock.Mock() self.fake_conf = mock.Mock() self.ganesha_helper = protocol_helper.DockerGaneshaReexportingHelper( self._helper, share=fake_share(), config=self.fake_conf) def test_create_share(self): self._helper.execute = mock.Mock(return_value=[""\n\n192.0.2.3""]) result = self.ganesha_helper.create_share(""fake_server_id"") self.assertEqual(result, ""192.0.2.3:/fakeshareid--<random-suffix>"") def test__allow_access(self): edir = ""/tmp/fake_local"" self.ganesha_helper.conf.container_data_exchange_dir_in = edir fake_access = { ""id"": ""fake_access_id"", ""access_to"": ""192.0.2.3"", ""access_level"": ""rw"" } export = (""\n EXPORT\n {\n Export_ID = 1;\n "" ""Path = \""/shares/fakeshareid\"";\n "" ""Pseudo = \""/fakeshareid-pseudo-fake_access_id\"";\n "" ""Squash = No_Root_Squash;\n "" ""Disable_ACL = True;\n SecType = \""none\"";\n "" ""CLIENT {\n Clients = 192.0.2.3;\n "" ""Access_Type = RW;\n }\n FSAL {\n "" ""Name = VFS;\n }\n }\n "") expected = [ ""fake_server_id"", ""/tmp/fake_local/fakeshareid-pseudo-fake_access_id.conf"", export ] self.ganesha_helper._get_new_export_id = mock.Mock(return_value=""1"") self.ganesha_helper._write_local_config = mock.Mock() self.ganesha_helper._add_export_by_id = mock.Mock() self.ganesha_helper._allow_access(""fake_server_id"", fake_access) self.ganesha_helper._write_local_config.assert_called_once_with( *expected) self.ganesha_helper._add_export_by_id.assert_called_once_with( ""fake_server_id"", ""1"", ""/tmp/fake_local/fakeshareid-pseudo-fake_access_id.conf"") def test__deny_access_ok(self): fake_access = {""id"": ""fake_access_id""} self.ganesha_helper._fetch_export_by_share = mock.Mock( return_value=[""uint16 1;""]) self.ganesha_helper._remove_export = mock.Mock() protocol_helper.LOG.warning = mock.Mock() self.ganesha_helper._deny_access(""fake_server_id"", fake_access) self.ganesha_helper._remove_export.assert_called_once_with( ""fake_server_id"", ""1"") self.assertFalse(protocol_helper.LOG.warning.called) def test__deny_access_no_export(self): fake_access = {""id"": ""fake_access_id""} self.ganesha_helper._fetch_export_by_share = mock.Mock(return_value=[]) self.ganesha_helper._remove_export = mock.Mock() protocol_helper.LOG.warning = mock.Mock() self.ganesha_helper._deny_access(""fake_server_id"", fake_access) self.assertFalse(self.ganesha_helper._remove_export.called) protocol_helper.LOG.warning.assert_called_once_with( ""No fake_access_id was found for fakeshareid."") class DockerGaneshaUpdatingHelperTestCase(test.TestCase): def setUp(self): super(DockerGaneshaUpdatingHelperTestCase, self).setUp() self._helper = mock.Mock() self.fake_conf = mock.Mock() edir = ""/tmp/fake_local"" self.ganesha_helper = protocol_helper.DockerGaneshaUpdatingHelper( self._helper, share=fake_share(), config=self.fake_conf) self.ganesha_helper.conf.container_data_exchange_dir_in = edir self.raw_config = ( ""\n EXPORT\n {\n Export_ID = 1;\n "" ""Path = \""/shares/fakeshareid\"";\n "" ""Pseudo = \""/fakeshareid-pseudo-fake_access_id\"";\n "" ""Squash = No_Root_Squash;\n "" ""Disable_ACL = True;\n SecType = \""none\"";\n "" ""CLIENT {\n Clients = 192.0.2.3;\n "" ""Access_Type = RW;\n }\n FSAL {\n "" ""Name = VFS;\n }\n }\n "" ) def test_create_share(self): self._helper.execute = mock.Mock(return_value=[""\n\n192.0.2.3""]) self.ganesha_helper._get_new_export_id = mock.Mock(return_value=""1"") self.ganesha_helper._write_local_config = mock.Mock() result = self.ganesha_helper.create_share(""fake_server_id"") self.assertEqual(""192.0.2.3:/fakeshareid"", result) def test__parse_config(self): expected_result = { ""export_id"": ""1"", ""path_to_share"": ""/shares/fakeshareid"", ""share_name"": ""fakeshareid-pseudo-fake_access_id"", ""client_ip"": ""192.0.2.3"", ""access_type"": ""RW"" } result = self.ganesha_helper._parse_config(self.raw_config) self.assertEqual(expected_result, result) def test__allow_access(self): self.ganesha_helper.container.execute = mock.Mock( return_value=(self.raw_config, """")) self.ganesha_helper._remove_export = mock.Mock() self.ganesha_helper._write_local_config = mock.Mock() self.ganesha_helper._add_export_by_id = mock.Mock() fake_access = {""access_to"": ""192.0.2.4""} expected_config = ( ""\n EXPORT\n {\n Export_ID = 1;\n "" ""Path = \""/shares/fakeshareid\"";\n "" ""Pseudo = \""/fakeshareid-pseudo-fake_access_id\"";\n "" ""Squash = No_Root_Squash;\n Disable_ACL = True;\n "" ""SecType = \""none\"";\n CLIENT {\n "" ""Clients = 192.0.2.3, 192.0.2.4;\n "" ""Access_Type = RW;\n }\n FSAL {\n "" ""Name = VFS;\n }\n }\n "") self.ganesha_helper._allow_access(""fake_server_id"", fake_access) self.ganesha_helper.container.execute.assert_called_with( ""fake_server_id"", [""cat"", ""/tmp/fake_local/fakeshareid.conf""]) self.ganesha_helper._remove_export.assert_called_once_with( ""fake_server_id"", ""1"") self.ganesha_helper._write_local_config.assert_called_once_with( ""fake_server_id"", ""/tmp/fake_local/fakeshareid.conf"", expected_config) self.ganesha_helper._add_export_by_id.assert_called_once_with( ""fake_server_id"", ""1"", ""/tmp/fake_local/fakeshareid.conf"") def test__deny_access(self): self.ganesha_helper.container.execute = mock.Mock( return_value=(self.raw_config, """")) self.ganesha_helper._remove_export = mock.Mock() self.ganesha_helper._write_local_config = mock.Mock() self.ganesha_helper._add_export_by_id = mock.Mock() fake_access = {""access_to"": ""192.0.2.3""} expected_config = ( ""\n EXPORT\n {\n Export_ID = 1;\n "" ""Path = \""/shares/fakeshareid\"";\n "" ""Pseudo = \""/fakeshareid-pseudo-fake_access_id\"";\n "" ""Squash = No_Root_Squash;\n Disable_ACL = True;\n "" ""SecType = \""none\"";\n CLIENT {\n "" ""Clients = ;\n "" ""Access_Type = RW;\n }\n FSAL {\n "" ""Name = VFS;\n }\n }\n "") self.ganesha_helper._deny_access(""fake_server_id"", fake_access) self.ganesha_helper.container.execute.assert_called_with( ""fake_server_id"", [""cat"", ""/tmp/fake_local/fakeshareid.conf""]) self.ganesha_helper._remove_export.assert_called_once_with( ""fake_server_id"", ""1"") self.ganesha_helper._write_local_config.assert_called_once_with( ""fake_server_id"", ""/tmp/fake_local/fakeshareid.conf"", expected_config) self.ganesha_helper._add_export_by_id.assert_called_once_with( ""fake_server_id"", ""1"", ""/tmp/fake_local/fakeshareid.conf"")", kwargs['execute_arguments'].append(args),685,7
openstack%2Fironic~master~Id6c6ad0ed91216aa5010fd295060175e5d89bfc3,openstack/ironic,master,Id6c6ad0ed91216aa5010fd295060175e5d89bfc3,Move install-guide's troubleshooting to troubleshooting page,NEW,2015-12-02 12:46:35.000000000,2017-12-18 04:52:03.000000000,,"[{'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 12459}, {'_account_id': 14943}, {'_account_id': 16986}]","[{'number': 1, 'created': '2015-12-02 12:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c0d2b1980a2714ac1fee237c239f6c8e02ded57c', 'message': ""Move install-guide's troubleshooting to troubleshooting page\n\nWe have a new troubleshooting page for all troubleshooting information.\nAlso, we have a troubleshooting section as part of the install-guide [1]\nhttp://docs.openstack.org/developer/ironic/deploy/install-guide.html#troubleshooting.\nHere https://review.openstack.org/#/c/239206/ , we agree to move it to\nthe new troubleshooting page.\n\nChange-Id: Id6c6ad0ed91216aa5010fd295060175e5d89bfc3\nCloses-bug: #1521443\n""}, {'number': 2, 'created': '2015-12-03 15:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ecb65fbdd4ac6de66af9323462424deb41fc85cd', 'message': ""Move install-guide's troubleshooting to troubleshooting page\n\nWe have a new troubleshooting page for all troubleshooting information.\nAlso, we have a troubleshooting section as part of the install-guide [1]\nhttp://docs.openstack.org/developer/ironic/deploy/install-guide.html#troubleshooting.\nHere https://review.openstack.org/#/c/239206/ , we agree to move it to\nthe new troubleshooting page.\n\nChange-Id: Id6c6ad0ed91216aa5010fd295060175e5d89bfc3\nCloses-bug: #1521443\n""}, {'number': 3, 'created': '2015-12-04 10:50:53.000000000', 'files': ['doc/source/deploy/install-guide.rst', 'doc/source/deploy/troubleshooting.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b073ff4e952449fc5d6640f04da8ba6a38416b90', 'message': ""Move install-guide's troubleshooting to troubleshooting page\n\nWe have a new troubleshooting page for all troubleshooting information.\nAlso, we have a troubleshooting section as part of the install-guide [1]\nhttp://docs.openstack.org/developer/ironic/deploy/install-guide.html#troubleshooting.\nHere https://review.openstack.org/#/c/239206/ , we agreed to move it to\nthe new troubleshooting page.\n\nChange-Id: Id6c6ad0ed91216aa5010fd295060175e5d89bfc3\nCloses-bug: #1521443\n""}]",10,252371,b073ff4e952449fc5d6640f04da8ba6a38416b90,19,6,3,16986,,,0,"Move install-guide's troubleshooting to troubleshooting page

We have a new troubleshooting page for all troubleshooting information.
Also, we have a troubleshooting section as part of the install-guide [1]
http://docs.openstack.org/developer/ironic/deploy/install-guide.html#troubleshooting.
Here https://review.openstack.org/#/c/239206/ , we agreed to move it to
the new troubleshooting page.

Change-Id: Id6c6ad0ed91216aa5010fd295060175e5d89bfc3
Closes-bug: #1521443
",git fetch https://review.opendev.org/openstack/ironic refs/changes/71/252371/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/deploy/install-guide.rst', 'doc/source/deploy/troubleshooting.rst']",2,c0d2b1980a2714ac1fee237c239f6c8e02ded57c,bug/1521443," log, it means the conductor ran into a special error during deployment. Ironic Installation Troubleshooting =================================== Once all the services are running and configured properly, and a node has been enrolled with the Bare Metal service and is in the ``available`` provision state, the Compute service should detect the node as an available resource and expose it to the scheduler. .. note:: There is a delay, and it may take up to a minute (one periodic task cycle) for the Compute service to recognize any changes in the Bare Metal service's resources (both additions and deletions). In addition to watching ``nova-compute`` log files, you can see the available resources by looking at the list of Compute hypervisors. The resources reported therein should match the bare metal node properties, and the Compute service flavor. Here is an example set of commands to compare the resources in Compute service and Bare Metal service:: $ ironic node-list +--------------------------------------+---------------+-------------+--------------------+-------------+ | UUID | Instance UUID | Power State | Provisioning State | Maintenance | +--------------------------------------+---------------+-------------+--------------------+-------------+ | 86a2b1bb-8b29-4964-a817-f90031debddb | None | power off | available | False | +--------------------------------------+---------------+-------------+--------------------+-------------+ $ ironic node-show 86a2b1bb-8b29-4964-a817-f90031debddb +------------------------+----------------------------------------------------------------------+ | Property | Value | +------------------------+----------------------------------------------------------------------+ | instance_uuid | None | | properties | {u'memory_mb': u'1024', u'cpu_arch': u'x86_64', u'local_gb': u'10', | | | u'cpus': u'1'} | | maintenance | False | | driver_info | { [SNIP] } | | extra | {} | | last_error | None | | created_at | 2014-11-20T23:57:03+00:00 | | target_provision_state | None | | driver | pxe_ipmitool | | updated_at | 2014-11-21T00:47:34+00:00 | | instance_info | {} | | chassis_uuid | 7b49bbc5-2eb7-4269-b6ea-3f1a51448a59 | | provision_state | available | | reservation | None | | power_state | power off | | console_enabled | False | | uuid | 86a2b1bb-8b29-4964-a817-f90031debddb | +------------------------+----------------------------------------------------------------------+ $ nova hypervisor-show 1 +-------------------------+--------------------------------------+ | Property | Value | +-------------------------+--------------------------------------+ | cpu_info | baremetal cpu | | current_workload | 0 | | disk_available_least | - | | free_disk_gb | 10 | | free_ram_mb | 1024 | | host_ip | [ SNIP ] | | hypervisor_hostname | 86a2b1bb-8b29-4964-a817-f90031debddb | | hypervisor_type | ironic | | hypervisor_version | 1 | | id | 1 | | local_gb | 10 | | local_gb_used | 0 | | memory_mb | 1024 | | memory_mb_used | 0 | | running_vms | 0 | | service_disabled_reason | - | | service_host | my-test-host | | service_id | 6 | | state | up | | status | enabled | | vcpus | 1 | | vcpus_used | 0 | +-------------------------+--------------------------------------+ Maintenance mode ---------------- Maintenance mode may be used if you need to take a node out of the resource pool. Putting a node in maintenance mode will prevent Bare Metal service from executing periodic tasks associated with the node. This will also prevent Compute service from placing a tenant instance on the node by not exposing the node to the nova scheduler. Nodes can be placed into maintenance mode with the following command. :: $ ironic node-set-maintenance $NODE_UUID on As of the Kilo release, a maintenance reason may be included with the optional ``--reason`` command line option. This is a free form text field that will be displayed in the ``maintenance_reason`` section of the ``node-show`` command. :: $ ironic node-set-maintenance $UUID on --reason ""Need to add ram."" $ ironic node-show $UUID +------------------------+--------------------------------------+ | Property | Value | +------------------------+--------------------------------------+ | target_power_state | None | | extra | {} | | last_error | None | | updated_at | 2015-04-27T15:43:58+00:00 | | maintenance_reason | Need to add ram. | | ... | ... | | maintenance | True | | ... | ... | +------------------------+--------------------------------------+ To remove maintenance mode and clear any ``maintenance_reason`` use the following command. :: $ ironic node-set-maintenance $NODE_UUID off .. _diskimage-builder: https://github.com/openstack/diskimage-builder .. _ironic-python-agent: https://github.com/openstack/ironic-python-agent"," log, it means the conductor run into a special error during deployment.",126,127
openstack%2Fironic~master~I8fdf55799242642a348597e9b8fffae339402f48,openstack/ironic,master,I8fdf55799242642a348597e9b8fffae339402f48,Add 'baremetal' to enabled Neutron  mech. drivers.,NEW,2016-07-11 12:55:15.000000000,2017-12-18 04:51:41.000000000,,"[{'_account_id': 10118}, {'_account_id': 14525}, {'_account_id': 14943}, {'_account_id': 17998}, {'_account_id': 18893}, {'_account_id': 19003}, {'_account_id': 19339}]","[{'number': 1, 'created': '2016-07-11 12:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ca8532ee443fc53d95e22af8da1d22681e7bfb16', 'message': ""Add 'baremetal' to enabled Neutron  mech. drivers.\n\nThis patch update Neutron ML2 plugin configuration and adds\n`baremetal` to list of enabled metchnism_drivers.\n`baremetal` mechanism driver is introduced [0] and is responsible\nfor fake port binding with vnic_type=baremetal.\n\nReference:\n[0] https://review.openstack.org/#/c/339129/\n\nRelated-Bug: #1599836\nDepends-On: I99602a59270406179a1a56777dd7ca98e8d626fb\n\nChange-Id: I8fdf55799242642a348597e9b8fffae339402f48\n""}, {'number': 2, 'created': '2016-07-11 14:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/78a7a2974d2e5bc07e132c31067859d6aac72ace', 'message': ""Add 'baremetal' to enabled Neutron  mech. drivers.\n\nThis patch update Neutron ML2 plugin configuration and adds\n`baremetal` to list of enabled metchnism_drivers.\n`baremetal` mechanism driver is introduced [0] and is responsible\nfor fake port binding with vnic_type=baremetal.\n\nReference:\n[0] https://review.openstack.org/#/c/339129/\n\nRelated-Bug: #1599836\nDepends-On: I99602a59270406179a1a56777dd7ca98e8d626fb\n\nChange-Id: I8fdf55799242642a348597e9b8fffae339402f48\n""}, {'number': 3, 'created': '2016-07-11 15:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b8e67c91b5340ab5cad6c5ef501e57f4e4ac6f40', 'message': ""Add 'baremetal' to enabled Neutron  mech. drivers.\n\nThis patch update Neutron ML2 plugin configuration and adds\n`baremetal` to list of enabled metchnism_drivers.\n`baremetal` mechanism driver is introduced [0] and is responsible\nfor fake port binding with vnic_type=baremetal.\n\nReference:\n[0] https://review.openstack.org/#/c/339129/\n\nRelated-Bug: #1599836\nDepends-On: I99602a59270406179a1a56777dd7ca98e8d626fb\n\nChange-Id: I8fdf55799242642a348597e9b8fffae339402f48\n""}, {'number': 4, 'created': '2016-07-20 06:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5c65860298c0fa7df19970d661c7385e2215f185', 'message': ""Add 'baremetal' to enabled Neutron  mech. drivers.\n\nThis patch update Neutron ML2 plugin configuration and adds\n`baremetal` to list of enabled metchnism_drivers.\n`baremetal` mechanism driver is introduced [0] and is responsible\nfor fake port binding with vnic_type=baremetal.\n\nReference:\n[0] https://review.openstack.org/#/c/339129/\n\nRelated-Bug: #1599836\nDepends-On: I99602a59270406179a1a56777dd7ca98e8d626fb\n\nChange-Id: I8fdf55799242642a348597e9b8fffae339402f48\n""}, {'number': 5, 'created': '2016-07-20 07:15:15.000000000', 'files': ['devstack/lib/ironic', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e3710212b6ed29eb4bd0a3ee28aabf7880012659', 'message': ""Add 'baremetal' to enabled Neutron  mech. drivers.\n\nThis patch update Neutron ML2 plugin configuration and adds\n`baremetal` to list of enabled metchnism_drivers.\n`baremetal` mechanism driver is introduced [0] and is responsible\nfor fake port binding with vnic_type=baremetal.\n\nReference:\n[0] https://review.openstack.org/#/c/339129/\n\nRelated-Bug: #1599836\nDepends-On: I99602a59270406179a1a56777dd7ca98e8d626fb\n\nChange-Id: I8fdf55799242642a348597e9b8fffae339402f48\n""}]",2,340355,e3710212b6ed29eb4bd0a3ee28aabf7880012659,27,7,5,14525,,,0,"Add 'baremetal' to enabled Neutron  mech. drivers.

This patch update Neutron ML2 plugin configuration and adds
`baremetal` to list of enabled metchnism_drivers.
`baremetal` mechanism driver is introduced [0] and is responsible
for fake port binding with vnic_type=baremetal.

Reference:
[0] https://review.openstack.org/#/c/339129/

Related-Bug: #1599836
Depends-On: I99602a59270406179a1a56777dd7ca98e8d626fb

Change-Id: I8fdf55799242642a348597e9b8fffae339402f48
",git fetch https://review.opendev.org/openstack/ironic refs/changes/55/340355/5 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/lib/ironic', 'devstack/plugin.sh']",2,ca8532ee443fc53d95e22af8da1d22681e7bfb16,bug/1599836, configure_neutron ,,6,0
openstack%2Fstorlets~master~Ib3801efc97af0827b68cef295469b968ec01ff91,openstack/storlets,master,Ib3801efc97af0827b68cef295469b968ec01ff91,fix internal client configuration,NEW,2016-08-31 07:03:37.000000000,2017-12-18 04:51:37.000000000,,[{'_account_id': 8330}],"[{'number': 1, 'created': '2016-08-31 07:03:37.000000000', 'files': ['Engine/swift/storlet_middleware/handlers/base.py'], 'web_link': 'https://opendev.org/openstack/storlets/commit/7b70b5db212b0fe4ce6c40e4c8e938ffa27ea0de', 'message': 'fix internal client configuration\n\nChange-Id: Ib3801efc97af0827b68cef295469b968ec01ff91\n'}]",0,363435,7b70b5db212b0fe4ce6c40e4c8e938ffa27ea0de,5,1,1,8330,,,0,"fix internal client configuration

Change-Id: Ib3801efc97af0827b68cef295469b968ec01ff91
",git fetch https://review.opendev.org/openstack/storlets refs/changes/35/363435/1 && git format-patch -1 --stdout FETCH_HEAD,['Engine/swift/storlet_middleware/handlers/base.py'],1,7b70b5db212b0fe4ce6c40e4c8e938ffa27ea0de,fix_internal_client_configuration,import os.path if os.path.exists('/etc/swift/internal-client.conf'): self.client_conf_file = '/etc/swift/internal-client.conf' else: self.client_conf_file = '/etc/swift/storlet-proxy-server.conf', self.client_conf_file = '/etc/swift/storlet-proxy-server.conf',5,1
openstack%2Fdiskimage-builder~master~I254db84d18dac84cbbc4960a7db4a6c042153e51,openstack/diskimage-builder,master,I254db84d18dac84cbbc4960a7db4a6c042153e51,chmod +x to setup.py then set file setup.py executable,NEW,2016-09-18 10:18:53.000000000,2017-12-18 04:51:22.000000000,,"[{'_account_id': 4190}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-09-18 10:18:53.000000000', 'files': ['setup.py'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/cf43aae614c349755700d36719db67f4f9ac29c3', 'message': 'chmod +x to setup.py then set file setup.py executable\n\nChange-Id: I254db84d18dac84cbbc4960a7db4a6c042153e51\n'}]",0,372090,cf43aae614c349755700d36719db67f4f9ac29c3,6,2,1,15513,,,0,"chmod +x to setup.py then set file setup.py executable

Change-Id: I254db84d18dac84cbbc4960a7db4a6c042153e51
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/90/372090/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.py'],1,cf43aae614c349755700d36719db67f4f9ac29c3,CHMOD+X2SETUPPY,,,0,0
openstack%2Fironic~master~I916cc7934978b4681af332ebb331081e6b195a26,openstack/ironic,master,I916cc7934978b4681af332ebb331081e6b195a26,[POC] pxe: support boot from Cinder iSCSI volume using iPXE,NEW,2015-08-22 00:25:55.000000000,2017-12-18 04:51:09.000000000,,"[{'_account_id': 6610}, {'_account_id': 9066}, {'_account_id': 9176}, {'_account_id': 10115}, {'_account_id': 10202}, {'_account_id': 11076}, {'_account_id': 11297}, {'_account_id': 12411}, {'_account_id': 13636}, {'_account_id': 13997}, {'_account_id': 16066}, {'_account_id': 16635}, {'_account_id': 19701}, {'_account_id': 20105}, {'_account_id': 20311}]","[{'number': 1, 'created': '2015-08-22 00:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4723b4957c9df829b7a02d340840d61d3f211224', 'message': ""[POC] pxe: support boot from Cinder iSCSI volume using iPXE\n\nThis is a PoC patch for pxe driver to support boot-from-volume\nusing iPXE sanboot feature. With this patch and a series of\ndependent boot-from-volume patches for ironic&nova&ironicclient,\na iSCSI Cinder volume with CirrOS whole disk image can be used to\nboot baremetal servers via iPXE.\n\nThis is only for a testing purpose of a series of ironic boot-\nfrom-volume patches. Note that official CirrOS image doesn't have\niscsiadm tools, so the volume cannot be used after Linux booted.\n\nChange-Id: I916cc7934978b4681af332ebb331081e6b195a26\nPartially implements: blueprint volume-connection-information\nDepends-On: I319779af265684715f0142577a217ab66632bf4f\n""}, {'number': 2, 'created': '2015-08-26 22:51:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6adbccf764bb1a3f4812f998727abdff989aaab4', 'message': ""[POC] pxe: support boot from Cinder iSCSI volume using iPXE\n\nThis is a PoC patch for pxe driver to support boot-from-volume\nusing iPXE sanboot feature. With this patch and a series of\ndependent boot-from-volume patches for ironic&nova&ironicclient,\na iSCSI Cinder volume with CirrOS whole disk image can be used to\nboot baremetal servers via iPXE.\n\nThis is only for a testing purpose of a series of ironic boot-\nfrom-volume patches. Note that official CirrOS image doesn't have\niscsiadm tools, so the volume cannot be used after Linux booted.\n\nChange-Id: I916cc7934978b4681af332ebb331081e6b195a26\nPartially implements: blueprint volume-connection-information\nDepends-On: I319779af265684715f0142577a217ab66632bf4f\n""}, {'number': 3, 'created': '2015-08-27 15:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2c155f2fca618c2134e08881901b0e209b6696b2', 'message': ""[POC] pxe: support boot from Cinder iSCSI volume using iPXE\n\nThis is a PoC patch for pxe driver to support boot-from-volume\nusing iPXE sanboot feature. With this patch and a series of\ndependent boot-from-volume patches for ironic&nova&ironicclient,\na iSCSI Cinder volume with CirrOS whole disk image can be used to\nboot baremetal servers via iPXE.\n\nThis is only for a testing purpose of a series of ironic boot-\nfrom-volume patches. Note that official CirrOS image doesn't have\niscsiadm tools, so the volume cannot be used after Linux booted.\n\nChange-Id: I916cc7934978b4681af332ebb331081e6b195a26\nPartially implements: blueprint volume-connection-information\nDepends-On: I319779af265684715f0142577a217ab66632bf4f\n""}, {'number': 4, 'created': '2015-08-27 16:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a0d21e6b01ae5bbd66c1fcabc663a9cc897e6318', 'message': ""[POC] pxe: support boot from Cinder iSCSI volume using iPXE\n\nThis is a PoC patch for pxe driver to support boot-from-volume\nusing iPXE sanboot feature. With this patch and a series of\ndependent boot-from-volume patches for ironic&nova&ironicclient,\na iSCSI Cinder volume with CirrOS whole disk image can be used to\nboot baremetal servers via iPXE.\n\nThis is only for a testing purpose of a series of ironic\nboot-from-volume patches. Note that official CirrOS image doesn't\nhave iscsiadm, so the volume cannot be used after Linux booted.\n\nChange-Id: I916cc7934978b4681af332ebb331081e6b195a26\nPartially implements: blueprint volume-connection-information\nDepends-On: I319779af265684715f0142577a217ab66632bf4f\n""}, {'number': 5, 'created': '2015-08-28 19:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/49dd0dd65f12c26b03a2e86066f9aab0009d547c', 'message': ""[POC] pxe: support boot from Cinder iSCSI volume using iPXE\n\nThis is a PoC patch for pxe driver to support boot-from-volume\nusing iPXE sanboot feature. With this patch and a series of\ndependent boot-from-volume patches for ironic&nova&ironicclient,\na iSCSI Cinder volume with CirrOS whole disk image can be used to\nboot baremetal servers via iPXE.\n\nThis is only for a testing purpose of a series of ironic\nboot-from-volume patches. Note that official CirrOS image doesn't\nhave iscsiadm, so the volume cannot be used after Linux booted.\n\nChange-Id: I916cc7934978b4681af332ebb331081e6b195a26\nPartially implements: blueprint volume-connection-information\nDepends-On: I319779af265684715f0142577a217ab66632bf4f\n""}, {'number': 6, 'created': '2016-04-07 06:50:40.000000000', 'files': ['ironic/drivers/modules/deploy_utils.py', 'ironic/drivers/modules/iscsi_deploy.py', 'ironic/drivers/modules/pxe.py', 'ironic/common/pxe_utils.py', 'ironic/conductor/task_manager.py', 'ironic/drivers/modules/ipxe_config.template'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d4f31521a8bf64e86719dfe69c4331eb97849470', 'message': ""[POC] pxe: support boot from Cinder iSCSI volume using iPXE\n\nThis is a PoC patch for pxe driver to support boot-from-volume\nusing iPXE sanboot feature. With this patch and a series of\ndependent boot-from-volume patches for ironic&nova&ironicclient,\na iSCSI Cinder volume with CirrOS whole disk image can be used to\nboot baremetal servers via iPXE.\n\nThis is only for a testing purpose of a series of ironic\nboot-from-volume patches. Note that official CirrOS image doesn't\nhave iscsiadm, so the volume cannot be used after Linux booted.\n\nChange-Id: I916cc7934978b4681af332ebb331081e6b195a26\nPartially implements: blueprint volume-connection-information\nDepends-On: I319779af265684715f0142577a217ab66632bf4f\n""}]",15,215849,d4f31521a8bf64e86719dfe69c4331eb97849470,36,15,6,9176,,,0,"[POC] pxe: support boot from Cinder iSCSI volume using iPXE

This is a PoC patch for pxe driver to support boot-from-volume
using iPXE sanboot feature. With this patch and a series of
dependent boot-from-volume patches for ironic&nova&ironicclient,
a iSCSI Cinder volume with CirrOS whole disk image can be used to
boot baremetal servers via iPXE.

This is only for a testing purpose of a series of ironic
boot-from-volume patches. Note that official CirrOS image doesn't
have iscsiadm, so the volume cannot be used after Linux booted.

Change-Id: I916cc7934978b4681af332ebb331081e6b195a26
Partially implements: blueprint volume-connection-information
Depends-On: I319779af265684715f0142577a217ab66632bf4f
",git fetch https://review.opendev.org/openstack/ironic refs/changes/49/215849/6 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/deploy_utils.py', 'ironic/drivers/modules/iscsi_deploy.py', 'ironic/drivers/modules/pxe.py', 'ironic/common/pxe_utils.py', 'ironic/conductor/task_manager.py', 'ironic/drivers/modules/ipxe_config.template']",6,4723b4957c9df829b7a02d340840d61d3f211224,bp/volume-connection-information,sanboot --no-describe --drive {{ DISK_IDENTIFIER }} :san_boot {{ SANBOOT_PRESET }} sanboot {{ SANBOOT }},kernel chain.c32 append mbr:{{ DISK_IDENTIFIER }} boot,131,13
openstack%2Ftacker~master~Ic5e82f52ba15d355f75f4c2d82e7a46acf8a3034,openstack/tacker,master,Ic5e82f52ba15d355f75f4c2d82e7a46acf8a3034,Use plugin aware extension manager to load extensions,NEW,2016-07-20 11:26:10.000000000,2017-12-18 04:50:45.000000000,,[{'_account_id': 18955}],"[{'number': 1, 'created': '2016-07-20 11:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/0e4cdf1fadabee508d25397553d4848c7a184bbd', 'message': 'Use plugin aware extension manager to load extensions\n\nWith this extension manager, we can deploy tacker with specified\nextensions. Otherwise, all the extensions must be loaded.\n\nChange-Id: Ic5e82f52ba15d355f75f4c2d82e7a46acf8a3034\nCloses-bug: #1604778\n'}, {'number': 3, 'created': '2016-07-21 00:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/42d2e38300dc803b9b2c8be01f41460652cc6d42', 'message': 'Use plugin aware extension manager to load extensions\n\nWith this extension manager, tacker can be deployed with specified\nextensions. Otherwise, all the extensions must be loaded.\n\nChange-Id: Ic5e82f52ba15d355f75f4c2d82e7a46acf8a3034\nCloses-bug: #1604778\n'}, {'number': 4, 'created': '2016-07-22 06:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/fe5e28fc196d3193d9a4439373de58e1f3fc5b82', 'message': 'Use plugin aware extension manager to load extensions\n\nWith this extension manager, tacker can be deployed with specified\nextensions. Otherwise, all the extensions must be loaded.\n\nChange-Id: Ic5e82f52ba15d355f75f4c2d82e7a46acf8a3034\nCloses-bug: #1604778\n'}, {'number': 5, 'created': '2016-08-02 02:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/1d79d2e17ddba1d93eecb5a36136690544fff65b', 'message': 'Use plugin aware extension manager to load extensions\n\nWith this extension manager, tacker can be deployed with specified\nextensions. Otherwise, all the extensions must be loaded.\n\nAnd supported_extension_aliases is a list of extension alias, not\nname.\n\nChange-Id: Ic5e82f52ba15d355f75f4c2d82e7a46acf8a3034\nCloses-bug: #1604778\n'}, {'number': 6, 'created': '2016-08-03 09:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/85767785cee3702ee1c5f8ea4406b215381d2f51', 'message': 'Use plugin aware extension manager to load extensions\n\nWith this extension manager, tacker can be deployed with specified\nextensions. Otherwise, all the extensions must be loaded.\n\nAnd supported_extension_aliases is a list of extension alias, not\nname.\n\nChange-Id: Ic5e82f52ba15d355f75f4c2d82e7a46acf8a3034\nCloses-bug: #1604778\n'}, {'number': 7, 'created': '2016-08-05 03:59:24.000000000', 'files': ['etc/tacker/api-paste.ini', 'tacker/vm/plugin.py', 'tacker/api/v1/router.py', 'tacker/api/extensions.py', 'tacker/nfvo/nfvo_plugin.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/54a1a30eabf455b7109e626fac70b1d3e215519d', 'message': 'Use plugin aware extension manager to load extensions\n\nWith this extension manager, tacker can be deployed with specified\nextensions. Otherwise, all the extensions must be loaded.\n\nAnd supported_extension_aliases is a list of extension alias, not\nname.\n\nChange-Id: Ic5e82f52ba15d355f75f4c2d82e7a46acf8a3034\nCloses-bug: #1604778\n'}]",0,344765,54a1a30eabf455b7109e626fac70b1d3e215519d,15,1,6,2874,,,0,"Use plugin aware extension manager to load extensions

With this extension manager, tacker can be deployed with specified
extensions. Otherwise, all the extensions must be loaded.

And supported_extension_aliases is a list of extension alias, not
name.

Change-Id: Ic5e82f52ba15d355f75f4c2d82e7a46acf8a3034
Closes-bug: #1604778
",git fetch https://review.opendev.org/openstack/tacker refs/changes/65/344765/7 && git format-patch -1 --stdout FETCH_HEAD,"['etc/tacker/api-paste.ini', 'tacker/api/v1/router.py', 'tacker/api/extensions.py']",3,0e4cdf1fadabee508d25397553d4848c7a184bbd,bug/1604778,"from tacker import managerclass PluginAwareExtensionManager(ExtensionManager): _instance = None def __init__(self, path, plugins): self.plugins = plugins super(PluginAwareExtensionManager, self).__init__(path) self.check_if_plugin_extensions_loaded() def _check_extension(self, extension): """"""Check if an extension is supported by any plugin."""""" extension_is_valid = super(PluginAwareExtensionManager, self)._check_extension(extension) return (extension_is_valid and self._plugins_support(extension) and self._plugins_implement_interface(extension)) def _plugins_support(self, extension): alias = extension.get_alias() supports_extension = alias in self.get_supported_extension_aliases() if not supports_extension: LOG.warning(_(""Extension %s not supported by any of loaded "" ""plugins""), alias) return supports_extension def _plugins_implement_interface(self, extension): if extension.get_plugin_interface() is None: return True for plugin in self.plugins.values(): if isinstance(plugin, extension.get_plugin_interface()): return True LOG.warning(_(""Loaded plugins do not implement extension "" ""%s interface""), extension.get_alias()) return False @classmethod def get_instance(cls): if cls._instance is None: service_plugins = manager.TackerManager.get_service_plugins() cls._instance = cls(get_extensions_path(service_plugins), service_plugins) return cls._instance def get_plugin_supported_extension_aliases(self, plugin): """"""Return extension aliases supported by a given plugin"""""" aliases = set() # we also check all classes that the plugins inherit to see if they # directly provide support for an extension for item in [plugin] + plugin.__class__.mro(): try: aliases |= set( getattr(item, ""supported_extension_aliases"", [])) except TypeError: # we land here if a class has a @property decorator for # supported extension aliases. They only work on objects. pass return aliases def get_supported_extension_aliases(self): """"""Gets extension aliases supported by all plugins."""""" aliases = set() for plugin in self.plugins.values(): aliases |= self.get_plugin_supported_extension_aliases(plugin) return aliases @classmethod def clear_instance(cls): cls._instance = None def check_if_plugin_extensions_loaded(self): """"""Check if an extension supported by a plugin has been loaded."""""" plugin_extensions = self.get_supported_extension_aliases() missing_aliases = plugin_extensions - set(self.extensions) if missing_aliases: raise exceptions.ExtensionsNotFound( extensions=list(missing_aliases)) ",,83,2
openstack%2Ftacker~master~I490e0163e132282ef4ebc95b4822e108310f080b,openstack/tacker,master,I490e0163e132282ef4ebc95b4822e108310f080b,Fix vnfd template nodes order,NEW,2016-09-01 00:04:19.000000000,2017-12-18 04:50:43.000000000,,"[{'_account_id': 2874}, {'_account_id': 13485}]","[{'number': 1, 'created': '2016-09-01 00:04:19.000000000', 'files': ['tacker/vm/plugin.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/60beb53c6d658c7422275dfe95c73782a88a7842', 'message': 'Fix vnfd template nodes order\n\nWith the recent fix [1], the vnfd template appaears mangled for\nfew node types when we run vnfd-template-show . This patch enhances\n[1] to take the template as OrderedDict and perfom yaml.dump using\nthe mapped ordered dict.\n\n[1] https://review.openstack.org/#/c/360809/\n\nChange-Id: I490e0163e132282ef4ebc95b4822e108310f080b\n'}]",4,363988,60beb53c6d658c7422275dfe95c73782a88a7842,7,2,1,13485,,,0,"Fix vnfd template nodes order

With the recent fix [1], the vnfd template appaears mangled for
few node types when we run vnfd-template-show . This patch enhances
[1] to take the template as OrderedDict and perfom yaml.dump using
the mapped ordered dict.

[1] https://review.openstack.org/#/c/360809/

Change-Id: I490e0163e132282ef4ebc95b4822e108310f080b
",git fetch https://review.opendev.org/openstack/tacker refs/changes/88/363988/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/vm/plugin.py'],1,60beb53c6d658c7422275dfe95c73782a88a7842,ordered_yaml_safe_dump,"import collections def represent_ordereddict(self, dumper, data): nodes = [] for key, value in data.items(): node_key = dumper.represent_data(key) node_value = dumper.represent_data(value) nodes.append((node_key, node_value)) return yaml.nodes.MappingNode(u'tag:yaml.org,2002:map', nodes) yaml.add_representer(collections.OrderedDict, self.represent_ordereddict, Dumper=yaml.SafeDumper) yaml.add_representer(dict, self.represent_ordereddict, Dumper=yaml.SafeDumper) vnfd_data['attributes']['vnfd'] = yaml.dump( collections.OrderedDict(template), Dumper=yaml.SafeDumper)", vnfd_data['attributes']['vnfd'] = yaml.safe_dump( template),16,2
openstack%2Frally~master~I7a712463ba9da4198d081c82950f6fa54c27451b,openstack/rally,master,I7a712463ba9da4198d081c82950f6fa54c27451b,Test scenario for Neutron MTU,NEW,2016-09-23 09:18:22.000000000,2017-12-18 04:50:09.000000000,,"[{'_account_id': 10068}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-09-23 09:18:22.000000000', 'files': ['rally/exceptions.py', 'rally/plugins/openstack/scenarios/neutron/utils.py', 'samples/tasks/scenarios/neutron/test_netwrok_mtu.yml', 'rally/plugins/openstack/scenarios/neutron/network.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/e83a1af8a6cee3f4a37575ed9a18a51a68f62985', 'message': 'Test scenario for Neutron MTU\n\nChange-Id: I7a712463ba9da4198d081c82950f6fa54c27451b\n'}]",3,375343,e83a1af8a6cee3f4a37575ed9a18a51a68f62985,7,3,1,23328,,,0,"Test scenario for Neutron MTU

Change-Id: I7a712463ba9da4198d081c82950f6fa54c27451b
",git fetch https://review.opendev.org/openstack/rally refs/changes/43/375343/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/exceptions.py', 'rally/plugins/openstack/scenarios/neutron/utils.py', 'samples/tasks/scenarios/neutron/test_netwrok_mtu.yml', 'rally/plugins/openstack/scenarios/neutron/network.py']",4,e83a1af8a6cee3f4a37575ed9a18a51a68f62985,MTU-changes," @validation.required_services(consts.Service.NEUTRON) @validation.required_openstack(users=True) @scenario.configure(context={""cleanup"": [""neutron""]}) def test_network_mtu(self, network_create_args=None, network_test_args=None): """"""Create a network and Test the Maximum Transmission Unit. Test the MTU range with the provided input If you have only 1 user in your context, you will add 1 network on every iteration. So you will have more and more networks and will be able to measure the performance of the ""neutron net-list"" command depending on the number of networks owned by users. :param network_create_args: dict, POST /v2.0/networks request options :param network_test_args: dict, expected MTU range """""" self._test_network_mtu(network_create_args, network_test_args)",,55,0
openstack%2Fironic~master~Ia3130eac7bf4f0a281cafd125db4e53b9e2c1d93,openstack/ironic,master,Ia3130eac7bf4f0a281cafd125db4e53b9e2c1d93,Add keystone_auth descripton for Mitaka Release,NEW,2016-07-13 09:21:45.000000000,2017-12-18 04:49:38.000000000,,"[{'_account_id': 3211}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 16514}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-07-13 09:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5fa6ce296639a8af7347ec66c69917911cf7343e', 'message': 'Add keystone_auth descripton for Mitaka Release\n\nAppend keystone_auth setting in ironic-api configuration section for Mitaka Release.\n\nChange-Id: Ia3130eac7bf4f0a281cafd125db4e53b9e2c1d93\nCloses-Bug: #1602571\n'}, {'number': 2, 'created': '2016-07-13 10:39:43.000000000', 'files': ['doc/source/deploy/install-guide.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/6c8d3f28d0cd1a15da30c877c79ed91003d81825', 'message': 'Add keystone_auth descripton for Mitaka Release\n\nAppend keystone_auth setting in ironic-api configuration section for Mitaka Release.\n\nChange-Id: Ia3130eac7bf4f0a281cafd125db4e53b9e2c1d93\nCloses-Bug: #1602571\n'}]",4,341383,6c8d3f28d0cd1a15da30c877c79ed91003d81825,13,5,2,16514,,,0,"Add keystone_auth descripton for Mitaka Release

Append keystone_auth setting in ironic-api configuration section for Mitaka Release.

Change-Id: Ia3130eac7bf4f0a281cafd125db4e53b9e2c1d93
Closes-Bug: #1602571
",git fetch https://review.opendev.org/openstack/ironic refs/changes/83/341383/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/deploy/install-guide.rst'],1,5fa6ce296639a8af7347ec66c69917911cf7343e,bug/1602571, In Mitaka Release:: [keystone_authtoken] ... auth_uri=http://IDENTITY_IP:5000 auth_url=http://IDENTITY_IP:35357 memcached_servers=IDENTITY_IP:11211 auth_type=password project_domain_name=default user_domain_name=default project_name=service username=ironic password=IRONIC_PASSWORD ,,15,0
openstack%2Fironic~master~Ib40d8ade1dbbcfa429e1ac68e8e1a088b3a7c011,openstack/ironic,master,Ib40d8ade1dbbcfa429e1ac68e8e1a088b3a7c011,Remove duplication from documentation,NEW,2016-08-08 13:09:11.000000000,2017-12-18 04:49:36.000000000,,"[{'_account_id': 12356}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-08-08 13:09:11.000000000', 'files': ['doc/source/common/restart-ironic-api-service.txt', 'doc/source/drivers/ucs.rst', 'doc/source/common/restart-nova-compute-service.txt', 'doc/source/drivers/wol.rst', 'doc/source/common/restart-nova-scheduler-service.txt', 'doc/source/drivers/cimc.rst', 'doc/source/drivers/oneview.rst', 'doc/source/common/restart-neutron-dhcp-agent-service.txt', 'doc/source/drivers/ilo.rst', 'doc/source/drivers/seamicro.rst', 'doc/source/common/restart-ironic-conductor-service.txt', 'doc/source/deploy/install-guide.rst', 'doc/source/drivers/iboot.rst', 'doc/source/common/restart-neutron-plugin-openvswitch-agent-service.txt', 'doc/source/common/restart-glance-api-service.txt', 'doc/source/drivers/amt.rst', 'doc/source/drivers/ipmitool.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c15b374803d7a6e563a2abc3286c54734ef4cd14', 'message': 'Remove duplication from documentation\n\nRemove duplicate service restarts examples by moving them to\ncommon/restart-{service_name}-service.txt and using it as reference.\n\nChange-Id: Ib40d8ade1dbbcfa429e1ac68e8e1a088b3a7c011\n'}]",1,352406,c15b374803d7a6e563a2abc3286c54734ef4cd14,6,2,1,14525,,,0,"Remove duplication from documentation

Remove duplicate service restarts examples by moving them to
common/restart-{service_name}-service.txt and using it as reference.

Change-Id: Ib40d8ade1dbbcfa429e1ac68e8e1a088b3a7c011
",git fetch https://review.opendev.org/openstack/ironic refs/changes/06/352406/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/common/restart-ironic-api-service.txt', 'doc/source/drivers/ucs.rst', 'doc/source/common/restart-nova-compute-service.txt', 'doc/source/drivers/wol.rst', 'doc/source/common/restart-nova-scheduler-service.txt', 'doc/source/drivers/cimc.rst', 'doc/source/drivers/oneview.rst', 'doc/source/common/restart-neutron-dhcp-agent-service.txt', 'doc/source/drivers/ilo.rst', 'doc/source/drivers/seamicro.rst', 'doc/source/common/restart-ironic-conductor-service.txt', 'doc/source/deploy/install-guide.rst', 'doc/source/drivers/iboot.rst', 'doc/source/common/restart-neutron-plugin-openvswitch-agent-service.txt', 'doc/source/common/restart-glance-api-service.txt', 'doc/source/drivers/amt.rst', 'doc/source/drivers/ipmitool.rst']",17,c15b374803d7a6e563a2abc3286c54734ef4cd14,dupl_doc,#. Restart the Ironic conductor service: .. literalinclude:: ../common/restart-ironic-conductor-service.txt,#. Restart the Ironic conductor service:: service ironic-conductor restart,78,89
openstack%2Fironic~master~Ia1ecf53efa908f49ec7760f28e74285eedbac469,openstack/ironic,master,Ia1ecf53efa908f49ec7760f28e74285eedbac469,Clarify whole disk images local boot in install guide,NEW,2016-03-09 15:40:55.000000000,2017-12-18 04:49:34.000000000,,"[{'_account_id': 11076}, {'_account_id': 12356}, {'_account_id': 13362}, {'_account_id': 18675}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-03-09 15:40:55.000000000', 'files': ['doc/source/deploy/install-guide.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/2d3215a8c390bfb4595f4ccfd45c424f749e04b5', 'message': 'Clarify whole disk images local boot in install guide\n\nIn case of using iSCSI to deploy whole disk image, boot_option should\nbe set to local too, as it is in case of partition image. Otherwise\nironic will not switch boot device to disk, and a node will continue\ntrying netboot after deployment.\n\nChange-Id: Ia1ecf53efa908f49ec7760f28e74285eedbac469\n'}]",2,290597,2d3215a8c390bfb4595f4ccfd45c424f749e04b5,9,5,1,12356,,,0,"Clarify whole disk images local boot in install guide

In case of using iSCSI to deploy whole disk image, boot_option should
be set to local too, as it is in case of partition image. Otherwise
ironic will not switch boot device to disk, and a node will continue
trying netboot after deployment.

Change-Id: Ia1ecf53efa908f49ec7760f28e74285eedbac469
",git fetch https://review.opendev.org/openstack/ironic refs/changes/97/290597/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/deploy/install-guide.rst'],1,2d3215a8c390bfb4595f4ccfd45c424f749e04b5,wholedisk-doc,"Local boot with whole disk images ================================= If you want to deploy a whole disk image on a node using iSCSI, you'll also need to set ``local`` boot option as described in `Local boot with partition images`_. The only difference is that the bootloader won't be installed as it is already present in the image, ironic will just set the boot device to disk. ",,10,0
openstack%2Ftacker~master~I6e56364eaa480145de233808b942706a72b85a83,openstack/tacker,master,I6e56364eaa480145de233808b942706a72b85a83,Prevent update state to PENDING_UPDATE while initials are not done,NEW,2016-03-15 14:57:56.000000000,2017-12-18 04:49:02.000000000,,"[{'_account_id': 2874}, {'_account_id': 10487}, {'_account_id': 12455}, {'_account_id': 13380}, {'_account_id': 13485}, {'_account_id': 15755}, {'_account_id': 16034}, {'_account_id': 16511}, {'_account_id': 18955}, {'_account_id': 19726}, {'_account_id': 22132}]","[{'number': 1, 'created': '2016-03-15 14:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/980b45f40be901b7209898c41dada88df87620ae', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 2, 'created': '2016-03-29 06:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/187d7bacbca4e82e062b7cf50e0cca6b85ba6aa1', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 3, 'created': '2016-04-18 13:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/d34fbbe5c5116c816f517e1ab8518d7fd1808a9a', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 4, 'created': '2016-05-16 07:03:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/258f209d8852d559a2caf3bc90d8b1273fb3322c', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 5, 'created': '2016-05-31 05:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/73a8863d7791a0760c55c50f503ddc523e6fda47', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 6, 'created': '2016-06-05 00:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/b30513e23fea240ee047bcdd33749c4818951a1b', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 7, 'created': '2016-06-06 23:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/27d707356b0d4f13dfa2d957f665121364d1669c', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 8, 'created': '2016-06-20 10:25:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/c7ed138d83bc9bb99d11d114c82d0f4f4bcb8b61', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 9, 'created': '2016-06-20 23:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/e1245a53991809275f9470106816fb818643638d', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 10, 'created': '2016-06-29 02:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/19af443f8d07bad2a7040b9e61fd7b51d84b56bd', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 11, 'created': '2016-07-07 04:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/12c01ff7515ef6ec6a1998e0b5787df64207967d', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 12, 'created': '2016-07-07 06:08:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/487b75adb7d110ac130c9e9e61f5de471c25eef3', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 13, 'created': '2016-07-15 07:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/9dda6e34624ea7e816409692cbe4190b33f6bf78', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 14, 'created': '2016-07-15 09:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/daffc962a5b0245934b207bb4495efca8e78a31f', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 15, 'created': '2016-07-21 01:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/3e4bbd07c59d8db0f0026eedb379c19da12908c8', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 16, 'created': '2016-07-21 07:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/c268996f8eed17110e56fbff1e3a7f215e16d570', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}, {'number': 17, 'created': '2016-08-05 02:42:16.000000000', 'files': ['tacker/vm/plugin.py', 'tacker/tests/unit/vm/infra_drivers/heat/test_heat.py', 'tacker/tests/unit/db/utils.py', 'tacker/vm/infra_drivers/heat/heat.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/81fdb792a32be18f50fa3f83a010965cc0f81468', 'message': 'Prevent update state to PENDING_UPDATE while initials are not done\n\nWhile updating vnf, state should not be set to PENDING_UPDATE\nbefore validating user inputs(i.e. initial operations).\n\nChange-Id: I6e56364eaa480145de233808b942706a72b85a83\nCloses-Bug: #1525808\n'}]",39,292932,81fdb792a32be18f50fa3f83a010965cc0f81468,73,11,17,18955,,,0,"Prevent update state to PENDING_UPDATE while initials are not done

While updating vnf, state should not be set to PENDING_UPDATE
before validating user inputs(i.e. initial operations).

Change-Id: I6e56364eaa480145de233808b942706a72b85a83
Closes-Bug: #1525808
",git fetch https://review.opendev.org/openstack/tacker refs/changes/32/292932/5 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/db/vm/vm_db.py', 'tacker/vm/plugin.py', 'tacker/vm/infra_drivers/heat/heat.py']",3,980b45f40be901b7209898c41dada88df87620ae,bug_1525808," if not isinstance(update_dict, dict) or not update_dict: LOG.error(_('yaml for update, could not be parsed'))", if not update_dict:,11,4
openstack%2Fpython-ironicclient~master~I05921b4c779cc1b311266d82b7225341060a7d10,openstack/python-ironicclient,master,I05921b4c779cc1b311266d82b7225341060a7d10,Fixed for listing nodes which are in no_maintenance mode and also fixed for setting maintenance mode on or off,NEW,2016-10-03 06:57:55.000000000,2017-12-18 04:48:55.000000000,,"[{'_account_id': 15950}, {'_account_id': 16237}, {'_account_id': 19790}]","[{'number': 1, 'created': '2016-10-03 06:57:55.000000000', 'files': ['ironicclient/tests/unit/osc/v1/test_baremetal_node.py', 'ironicclient/osc/v1/baremetal_node.py', 'releasenotes/notes/osc-plugin-ff0d897d8441a9e1.yaml'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/8789f3111c92c563ff62a3744f401f2deba9f0e3', 'message': 'Fixed for listing nodes which are in no_maintenance mode and also fixed for setting maintenance mode on or off\n\nCloses_bug :#1619090\n\nCloses_bug :#1619087\n\nChange-Id: I05921b4c779cc1b311266d82b7225341060a7d10\n'}]",0,380946,8789f3111c92c563ff62a3744f401f2deba9f0e3,5,3,1,23511,,,0,"Fixed for listing nodes which are in no_maintenance mode and also fixed for setting maintenance mode on or off

Closes_bug :#1619090

Closes_bug :#1619087

Change-Id: I05921b4c779cc1b311266d82b7225341060a7d10
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/46/380946/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/osc/v1/baremetal_node.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_node.py', 'releasenotes/notes/osc-plugin-ff0d897d8441a9e1.yaml']",3,8789f3111c92c563ff62a3744f401f2deba9f0e3,bug/1619090, * openstack baremetal node maintenance on * opnestack baremetal node maintenance off, * openstack baremetal node maintenance set * opnestack baremetal node maintenance unset,46,7
openstack%2Fstorlets~master~Ie9bfab65086111d1c8c08a993d4019923ee2b893,openstack/storlets,master,Ie9bfab65086111d1c8c08a993d4019923ee2b893,WIP: check the capability for AWS lambda like execution,NEW,2016-09-21 10:35:38.000000000,2017-12-18 04:48:26.000000000,,"[{'_account_id': 4608}, {'_account_id': 9816}, {'_account_id': 11317}]","[{'number': 1, 'created': '2016-09-21 10:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/2de6588c5a9726fe6fff75f107bb6272574570d2', 'message': 'WIP: check the capability for AWS lambda like execution\n\nChange-Id: Ie9bfab65086111d1c8c08a993d4019923ee2b893\n'}, {'number': 2, 'created': '2016-09-23 06:21:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/e3047e7791d2ef8b1bdddd95985761841b6d43cf', 'message': 'WIP: check the capability for AWS lambda like execution\n\nChange-Id: Ie9bfab65086111d1c8c08a993d4019923ee2b893\n'}, {'number': 3, 'created': '2016-09-29 12:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/9fa673be3eb580dc1848e628c7d5668ea545fff5', 'message': 'WIP: check the capability for AWS lambda like execution\n\nChange-Id: Ie9bfab65086111d1c8c08a993d4019923ee2b893\n'}, {'number': 4, 'created': '2016-09-29 15:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/ae9b4fc51dbae99a9c93ba3d7b93381a2f2adfd3', 'message': 'WIP: check the capability for AWS lambda like execution\n\nChange-Id: Ie9bfab65086111d1c8c08a993d4019923ee2b893\n'}, {'number': 5, 'created': '2016-09-30 03:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/109f9ef119da0a5c2178e11726f23fc97cb7481c', 'message': 'WIP: check the capability for AWS lambda like execution\n\nChange-Id: Ie9bfab65086111d1c8c08a993d4019923ee2b893\n'}, {'number': 6, 'created': '2016-09-30 08:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/de48509e4bbe31a629653fd3cc29ade40d79f2a9', 'message': 'WIP: check the capability for AWS lambda like execution\n\nChange-Id: Ie9bfab65086111d1c8c08a993d4019923ee2b893\n'}, {'number': 7, 'created': '2016-09-30 09:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/a2876e3193c65446fed46ecc277c311a24373f51', 'message': 'WIP: check the capability for AWS lambda like execution\n\nChange-Id: Ie9bfab65086111d1c8c08a993d4019923ee2b893\n'}, {'number': 8, 'created': '2016-09-30 10:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/0616a8ea1a9fd942b5b7a58f8288b04e5cc5769a', 'message': 'WIP: check the capability for AWS lambda like execution\n\nChange-Id: Ie9bfab65086111d1c8c08a993d4019923ee2b893\n'}, {'number': 9, 'created': '2016-09-30 10:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/410a39b203b15f85db515b67ba94f41ede01d37f', 'message': 'WIP: check the capability for AWS lambda like execution\n\nChange-Id: Ie9bfab65086111d1c8c08a993d4019923ee2b893\n'}, {'number': 10, 'created': '2016-10-04 07:17:10.000000000', 'files': ['Engine/swift/storlet_gateway/common/stob.py', 'Engine/agent/storlet_daemon_factory/daemon_factory.py', 'StorletSamples/python/lambda/lambda.py', 'Engine/swift/storlet_gateway/gateways/docker/runtime.py', 'tests/unit/swift/storlet_gateway/gateways/docker/test_runtime.py', 'Engine/swift/storlet_gateway/gateways/docker/gateway.py', 'tests/functional/python/test_amazon_lambda_strolet.py', 'tests/unit/swift/storlet_gateway/gateways/docker/test_gateway.py', 'tests/unit/agent/storlet_daemon/test_daemon.py', 'Engine/agent/storlet_daemon/daemon.py', 'StorletSamples/python/lambda/source.txt', 'Engine/swift/storlet_middleware/handlers/base.py'], 'web_link': 'https://opendev.org/openstack/storlets/commit/2a4be6c9d50d5136f31c701771fc3fd014566d30', 'message': 'WIP: check the capability for AWS lambda like execution\n\nChange-Id: Ie9bfab65086111d1c8c08a993d4019923ee2b893\n'}]",4,374016,2a4be6c9d50d5136f31c701771fc3fd014566d30,26,3,10,4608,,,0,"WIP: check the capability for AWS lambda like execution

Change-Id: Ie9bfab65086111d1c8c08a993d4019923ee2b893
",git fetch https://review.opendev.org/openstack/storlets refs/changes/16/374016/8 && git format-patch -1 --stdout FETCH_HEAD,"['tests/functional/python/test_amazon_lambda_strolet.py', 'Engine/agent/storlet_daemon/daemon.py', 'StorletSamples/python/lambda/lambda.py']",3,2de6588c5a9726fe6fff75f107bb6272574570d2,lambda," def handler(event, context): for record in evnet['Records']: bucket = record['s3']['bucket']['name'] key = record['s3']['object']['key'] ",,116,8
openstack%2Fdiskimage-builder~master~Id194720311b7809d3e0a8f50ab7127d8daf50963,openstack/diskimage-builder,master,Id194720311b7809d3e0a8f50ab7127d8daf50963,Make map-packages use dib-python,NEW,2016-07-07 15:25:26.000000000,2017-12-18 04:48:24.000000000,,"[{'_account_id': 6488}, {'_account_id': 7118}, {'_account_id': 12459}]","[{'number': 1, 'created': '2016-07-07 15:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/bda4fa2703a20327478acba5578db212256b2879', 'message': 'Make map-packages use dib-python\n\nThis script currently attempts to use the default python interpreter so\nit fails if no python3 exists in the target image.\n\nAdditionally, change dib-python to succeed even if no python is\ninstalled (simply do nothing). This is to allow the creation of\nrhel/redhat-common images without python while still supporting\npython3 if it exists.\n\nChange-Id: Id194720311b7809d3e0a8f50ab7127d8daf50963\n'}, {'number': 2, 'created': '2016-07-07 15:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/2d6086ecee86619da13d2cfee868416161608f4e', 'message': 'Make map-packages use dib-python\n\nThis script currently attempts to use the default python interpreter so\nit fails if no python3 exists in the target image.\n\nAdditionally, change dib-python to succeed even if no python is\ninstalled (simply do nothing). This is to allow the creation of\nrhel/redhat-common images without python while still supporting\npython3 if it exists.\n\nCloses-Bud: #1599897\n\nChange-Id: Id194720311b7809d3e0a8f50ab7127d8daf50963\n'}, {'number': 3, 'created': '2016-07-07 15:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/10c549df7c6476f2888cc2cf2fc873af52f21e98', 'message': 'Make map-packages use dib-python\n\nThis script currently attempts to use the default python interpreter so\nit fails if no python3 exists in the target image.\n\nAdditionally, change dib-python to succeed even if no python is\ninstalled (simply do nothing). This is to allow the creation of\nrhel/redhat-common images without python while still supporting\npython3 if it exists.\n\nCloses-Bug: #1599897\n\nChange-Id: Id194720311b7809d3e0a8f50ab7127d8daf50963\n'}, {'number': 4, 'created': '2016-07-28 17:07:14.000000000', 'files': ['elements/redhat-common/element-deps', 'elements/redhat-common/bin/map-packages', 'elements/opensuse/element-deps', 'elements/rhel/element-deps', 'elements/rhel/bin/map-packages', 'elements/opensuse/bin/map-packages'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/69a074bb500d9107eab6c5eeaba9fb1c47d4bcd1', 'message': 'Make map-packages use dib-python\n\nThis script currently attempts to use the default python interpreter so\nit fails if no python3 exists in the target image.\n\nCloses-Bug: #1599897\n\nChange-Id: Id194720311b7809d3e0a8f50ab7127d8daf50963\n'}]",2,339065,69a074bb500d9107eab6c5eeaba9fb1c47d4bcd1,15,3,4,10035,,,0,"Make map-packages use dib-python

This script currently attempts to use the default python interpreter so
it fails if no python3 exists in the target image.

Closes-Bug: #1599897

Change-Id: Id194720311b7809d3e0a8f50ab7127d8daf50963
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/65/339065/3 && git format-patch -1 --stdout FETCH_HEAD,"['elements/redhat-common/element-deps', 'elements/redhat-common/bin/map-packages', 'elements/rhel/element-deps', 'elements/rhel/bin/map-packages']",4,bda4fa2703a20327478acba5578db212256b2879,bug/1599897,#!/usr/local/bin/dib-python,#!/usr/bin/env python,4,2
openstack%2Frally~master~I24410ae2656fa54baa99935dfc400be2ddf19e65,openstack/rally,master,I24410ae2656fa54baa99935dfc400be2ddf19e65,[wip] Add glare client and tests,NEW,2016-10-05 19:28:46.000000000,2017-12-18 04:48:11.000000000,,"[{'_account_id': 7369}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-10-05 19:28:46.000000000', 'files': ['samples/tasks/scenarios/glare/glare.yaml', 'rally/plugins/openstack/scenarios/glare/blob.py', 'rally/consts.py', 'rally/plugins/openstack/scenarios/glare/__init__.py', 'rally/osclients.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/f3e962d2309e9e9ae6e4c8b0cb8eaf8843d4bebb', 'message': '[wip] Add glare client and tests\n\nChange-Id: I24410ae2656fa54baa99935dfc400be2ddf19e65\n'}]",0,382631,f3e962d2309e9e9ae6e4c8b0cb8eaf8843d4bebb,5,2,1,7369,,,0,"[wip] Add glare client and tests

Change-Id: I24410ae2656fa54baa99935dfc400be2ddf19e65
",git fetch https://review.opendev.org/openstack/rally refs/changes/31/382631/1 && git format-patch -1 --stdout FETCH_HEAD,"['samples/tasks/scenarios/glare/glare.yaml', 'rally/plugins/openstack/scenarios/glare/blob.py', 'rally/consts.py', 'rally/plugins/openstack/scenarios/glare/__init__.py', 'rally/osclients.py']",5,f3e962d2309e9e9ae6e4c8b0cb8eaf8843d4bebb,glare,"@configure(""glare"", default_version=""1"", default_service_type=""artifact"", supported_versions=[""1""]) class Glare(OSClient): def create_client(self, version=None, service_type=None): """"""Return glare client."""""" from glareclient import client return client.Client(self.choose_version(version), session=self.keystone.get_session()[0], endpoint=self._get_endpoint(service_type)) ",,69,0
openstack%2Fswift~master~I864ee83ce08049b44eac76123f7e26fd9e59a308,openstack/swift,master,I864ee83ce08049b44eac76123f7e26fd9e59a308,Fix staticweb issue with not serving index page,NEW,2016-07-09 09:37:14.000000000,2017-12-18 04:47:42.000000000,,"[{'_account_id': 5600}, {'_account_id': 13052}]","[{'number': 1, 'created': '2016-07-09 09:37:14.000000000', 'files': ['swift/common/middleware/staticweb.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/eedeaf40a75c038b887aba6c2f32db02cbba8bd3', 'message': 'Fix staticweb issue with not serving index page\n\nSince change I382323b49dc8f6d67bf4494db7084a860a10db59 (commit\n75ab3cb78862647644af7eaf5e0fb590e73ae341), staticweb became a little\ntoo secure: if .rlistings are off, web-listings are off, but web-index\nis enabled and .r:* is set, staticweb still serves a 401 at the\ncontainer level instead of the index page.\n\nChange-Id: I864ee83ce08049b44eac76123f7e26fd9e59a308\n'}]",0,339991,eedeaf40a75c038b887aba6c2f32db02cbba8bd3,6,2,1,5600,,,0,"Fix staticweb issue with not serving index page

Since change I382323b49dc8f6d67bf4494db7084a860a10db59 (commit
75ab3cb78862647644af7eaf5e0fb590e73ae341), staticweb became a little
too secure: if .rlistings are off, web-listings are off, but web-index
is enabled and .r:* is set, staticweb still serves a 401 at the
container level instead of the index page.

Change-Id: I864ee83ce08049b44eac76123f7e26fd9e59a308
",git fetch https://review.opendev.org/openstack/swift refs/changes/91/339991/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/middleware/staticweb.py'],1,eedeaf40a75c038b887aba6c2f32db02cbba8bd3,fix-staticweb-indexes," authorize_resp = env['swift.authorize'](req) if authorize_resp and not self._index: resp = authorize_resp(env, self._start_response)"," aresp = env['swift.authorize'](req) if aresp: resp = aresp(env, self._start_response)",9,3
openstack%2Fswift~master~Ibf1e317c3eac1574e1832e6dfc82022f5a9cebd8,openstack/swift,master,Ibf1e317c3eac1574e1832e6dfc82022f5a9cebd8,Remove path gets quoted twice in proxy_logging,NEW,2016-10-04 16:35:28.000000000,2017-12-18 04:47:40.000000000,,"[{'_account_id': 1179}, {'_account_id': 13052}, {'_account_id': 17245}]","[{'number': 1, 'created': '2016-10-04 16:35:28.000000000', 'files': ['swift/common/middleware/proxy_logging.py', 'test/unit/common/middleware/test_proxy_logging.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c636dfbc0c0482f431eeef9dad6a5dc5c3ed2ab0', 'message': 'Remove path gets quoted twice in proxy_logging\n\nBefore this commit, paths like /v1/white%20space are logged as\n/v1/white%2520space by log_request. This can lead to irritations\nwhen analyzing log files and is unnecessary.\n\nThe reason lies in the fact, that the quote function is\neffectively called twice on the path string, because the\nmethod ""path"" of a request object does already quote it.\n\nThis commit ensures that the path gets only quoted once.\n\nChange-Id: Ibf1e317c3eac1574e1832e6dfc82022f5a9cebd8\n'}]",0,381977,c636dfbc0c0482f431eeef9dad6a5dc5c3ed2ab0,6,3,1,17245,,,0,"Remove path gets quoted twice in proxy_logging

Before this commit, paths like /v1/white%20space are logged as
/v1/white%2520space by log_request. This can lead to irritations
when analyzing log files and is unnecessary.

The reason lies in the fact, that the quote function is
effectively called twice on the path string, because the
method ""path"" of a request object does already quote it.

This commit ensures that the path gets only quoted once.

Change-Id: Ibf1e317c3eac1574e1832e6dfc82022f5a9cebd8
",git fetch https://review.opendev.org/openstack/swift refs/changes/77/381977/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/proxy_logging.py', 'test/unit/common/middleware/test_proxy_logging.py']",2,c636dfbc0c0482f431eeef9dad6a5dc5c3ed2ab0,logging-double-quoting," def test_path_quote(self): app = proxy_logging.ProxyLoggingMiddleware(FakeApp(), {}) app.access_logger = FakeLogger() req = Request.blank('/v1/with space', environ={'REQUEST_METHOD': 'GET'}) app(req.environ, start_response) log_parts = self._log_parts(app) self.assertEqual(log_parts[4], '/v1/with%20space')",,10,3
openstack%2Frally~master~I1c2371cf0bb7523b11837328906cd95ae943f302,openstack/rally,master,I1c2371cf0bb7523b11837328906cd95ae943f302,[WIP]Add migrating volume interface in cinder wrapper,NEW,2016-07-04 03:44:30.000000000,2017-12-18 04:47:30.000000000,,"[{'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 21528}]","[{'number': 1, 'created': '2016-07-04 03:44:30.000000000', 'files': ['rally/plugins/openstack/wrappers/cinder.py', 'tests/unit/plugins/openstack/wrappers/test_cinder.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/a09b0b5ee52e5b83203580788bbfbfc10b997990', 'message': '[WIP]Add migrating volume interface in cinder wrapper\n\nChange-Id: I1c2371cf0bb7523b11837328906cd95ae943f302\n'}]",1,336982,a09b0b5ee52e5b83203580788bbfbfc10b997990,8,3,1,21528,,,0,"[WIP]Add migrating volume interface in cinder wrapper

Change-Id: I1c2371cf0bb7523b11837328906cd95ae943f302
",git fetch https://review.opendev.org/openstack/rally refs/changes/82/336982/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/wrappers/cinder.py', 'tests/unit/plugins/openstack/wrappers/test_cinder.py']",2,a09b0b5ee52e5b83203580788bbfbfc10b997990,cinder.migrate_volume," def test_migrate_volume(self): self.wrapped_client.migrate_volume(""volume_id"", ""host_id"", True) (self.client.return_value.volumes.migrate_volume. assert_called_once_with( ""volume_id"", ""host_id"", True)) def test_migrate_volume(self): self.wrapped_client.migrate_volume(""volume_id"", ""host_id"", True, True) (self.client.return_value.volumes.migrate_volume. assert_called_once_with(""volume_id"", ""host_id"", True, True))",,27,0
openstack%2Ftacker~master~Ie67ab88de582a9f162b7ab1e3bff3a4da48f4e5f,openstack/tacker,master,Ie67ab88de582a9f162b7ab1e3bff3a4da48f4e5f,Remove unused references: pywin32 and wmi from tacker/hooks.py,NEW,2016-06-27 12:49:41.000000000,2017-12-18 04:47:23.000000000,,"[{'_account_id': 8213}, {'_account_id': 10068}, {'_account_id': 10487}, {'_account_id': 13380}, {'_account_id': 17555}]","[{'number': 1, 'created': '2016-06-27 12:49:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/8d79459f9c7a264c6b0904126ec267ec4f849b98', 'message': 'Remove unused references: pywin32 and wmi from tacker/hooks.py\n\nChange-Id: Ie67ab88de582a9f162b7ab1e3bff3a4da48f4e5f\n'}, {'number': 2, 'created': '2016-07-05 07:18:32.000000000', 'files': ['tacker/hooks.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/e08b59f752bbb7096d961311dfa4772ac132a8e7', 'message': 'Remove unused references: pywin32 and wmi from tacker/hooks.py\n\nIt appears that pywin32 and wmi references are not used\nanywhere. So removing them helps cleaning up the code.\n\nChange-Id: Ie67ab88de582a9f162b7ab1e3bff3a4da48f4e5f\n'}]",0,334458,e08b59f752bbb7096d961311dfa4772ac132a8e7,11,5,2,20979,,,0,"Remove unused references: pywin32 and wmi from tacker/hooks.py

It appears that pywin32 and wmi references are not used
anywhere. So removing them helps cleaning up the code.

Change-Id: Ie67ab88de582a9f162b7ab1e3bff3a4da48f4e5f
",git fetch https://review.opendev.org/openstack/tacker refs/changes/58/334458/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/hooks.py'],1,8d79459f9c7a264c6b0904126ec267ec4f849b98,remove_unused_references,,import sys if sys.platform == 'win32': requires.append('pywin32') requires.append('wmi'),0,5
openstack%2Fdiskimage-builder~master~I030ed91b6a51f847466362cd042fed2f669411a5,openstack/diskimage-builder,master,I030ed91b6a51f847466362cd042fed2f669411a5,Stop forcing oslosphinx for docs,NEW,2016-10-06 20:54:12.000000000,2017-12-18 04:47:18.000000000,,"[{'_account_id': 7118}, {'_account_id': 10035}]","[{'number': 1, 'created': '2016-10-06 20:54:12.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/fed79d483ceaaf00b2f8f55de28d6a3acacb36d9', 'message': 'Stop forcing oslosphinx for docs\n\nthe default theme is preferred in many ways (such as using the full\npage size).\n\nChange-Id: I030ed91b6a51f847466362cd042fed2f669411a5\n'}]",0,383456,fed79d483ceaaf00b2f8f55de28d6a3acacb36d9,7,2,1,10035,,,0,"Stop forcing oslosphinx for docs

the default theme is preferred in many ways (such as using the full
page size).

Change-Id: I030ed91b6a51f847466362cd042fed2f669411a5
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/56/383456/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,fed79d483ceaaf00b2f8f55de28d6a3acacb36d9,,extensions = [],extensions = ['oslosphinx'],1,1
openstack%2Fdiskimage-builder~master~I19d11ef0073a7d88b8bd08cb22ebbde7806f03af,openstack/diskimage-builder,master,I19d11ef0073a7d88b8bd08cb22ebbde7806f03af,Allow setting per-release mirrors for tests,NEW,2016-02-12 17:24:55.000000000,2017-12-18 04:47:11.000000000,,"[{'_account_id': 6488}, {'_account_id': 7118}, {'_account_id': 10035}, {'_account_id': 11105}, {'_account_id': 12459}]","[{'number': 1, 'created': '2016-02-12 17:24:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/04387971cba39137420115ace26be098d510fc50', 'message': 'Allow setting per-release mirrors for tests\n\nFor efficient testing it is desireable to specify a set of mirrors for\nuse by dib. Because the various elements use the same variable\n(DIB_DISTROBUTION_MIRROR) there needs to be some logic about breaking\nthos out into multiple variables.\n\nChange-Id: I19d11ef0073a7d88b8bd08cb22ebbde7806f03af\n'}, {'number': 2, 'created': '2016-02-12 17:49:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/38ed0b16786ce3ac649478e773cb40a65c5a5c5a', 'message': 'Allow setting per-release mirrors for tests\n\nFor efficient testing it is desireable to specify a set of mirrors for\nuse by dib. Because the various elements use the same variable\n(DIB_DISTROBUTION_MIRROR) there needs to be some logic about breaking\nthos out into multiple variables.\n\nChange-Id: I19d11ef0073a7d88b8bd08cb22ebbde7806f03af\n'}, {'number': 3, 'created': '2016-02-12 19:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/15dd0fedf78849d54e921778d4b26d47369e6469', 'message': 'Allow setting per-release mirrors for tests\n\nFor efficient testing it is desireable to specify a set of mirrors for\nuse by dib. Because the various elements use the same variable\n(DIB_DISTROBUTION_MIRROR) there needs to be some logic about breaking\nthos out into multiple variables.\n\nChange-Id: I19d11ef0073a7d88b8bd08cb22ebbde7806f03af\n'}, {'number': 4, 'created': '2016-02-12 19:30:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/65133baa97dee7534f73c4e69ea4d3e1b7256407', 'message': 'Allow setting per-release mirrors for tests\n\nFor efficient testing it is desireable to specify a set of mirrors for\nuse by dib. Because the various elements use the same variable\n(DIB_DISTROBUTION_MIRROR) there needs to be some logic about breaking\nthos out into multiple variables.\n\nChange-Id: I19d11ef0073a7d88b8bd08cb22ebbde7806f03af\n'}, {'number': 5, 'created': '2016-02-12 20:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/23c643c2ecbb4234cf244076de4223267725ee35', 'message': 'Allow setting per-release mirrors for tests\n\nFor efficient testing it is desireable to specify a set of mirrors for\nuse by dib. Because the various elements use the same variable\n(DIB_DISTROBUTION_MIRROR) there needs to be some logic about breaking\nthos out into multiple variables.\n\nChange-Id: I19d11ef0073a7d88b8bd08cb22ebbde7806f03af\n'}, {'number': 6, 'created': '2016-02-12 22:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/9aefac3ebd608511693c29487bf3e8a66e550a7e', 'message': 'Allow setting per-release mirrors for tests\n\nFor efficient testing it is desireable to specify a set of mirrors for\nuse by dib. Because the various elements use the same variable\n(DIB_DISTROBUTION_MIRROR) there needs to be some logic about breaking\nthos out into multiple variables.\n\nChange-Id: I19d11ef0073a7d88b8bd08cb22ebbde7806f03af\n'}, {'number': 7, 'created': '2016-04-24 15:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/341628ae7bb3dc215b3ae3f2045215537cc00aa5', 'message': 'Allow setting per-release mirrors for tests\n\nFor efficient testing it is desireable to specify a set of mirrors for\nuse by dib. Because the various elements use the same variable\n(DIB_DISTROBUTION_MIRROR) there needs to be some logic about breaking\nthos out into multiple variables.\n\nChange-Id: I19d11ef0073a7d88b8bd08cb22ebbde7806f03af\n'}, {'number': 8, 'created': '2016-05-13 17:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/2ba58d48528b5243941da2a06b92bd5dc5314c84', 'message': 'Allow setting per-release mirrors for tests\n\nFor efficient testing it is desireable to specify a set of mirrors for\nuse by dib. Because the various elements use the same variable\n(DIB_DISTROBUTION_MIRROR) there needs to be some logic about breaking\nthos out into multiple variables.\n\nChange-Id: I19d11ef0073a7d88b8bd08cb22ebbde7806f03af\n'}, {'number': 9, 'created': '2016-07-13 20:12:58.000000000', 'files': ['tests/elements/set-mirror/environment.d/90-set-mirror-env', 'tests/elements/set-mirror/extra-data.d/50-set-mirror-verify', 'tests/elements/set-mirror/README.rst', 'tests/run_functests.sh', 'tests/run_output_format_test.sh'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/9506f8aec4eca79802f2074f5d9746a8b3e33d56', 'message': 'Allow setting per-release mirrors for tests\n\nFor efficient testing it is desireable to specify a set of mirrors for\nuse by dib. Because the various elements use the same variable\n(DIB_DISTROBUTION_MIRROR) there needs to be some logic about breaking\nthos out into multiple variables.\n\nChange-Id: I19d11ef0073a7d88b8bd08cb22ebbde7806f03af\n'}]",3,279691,9506f8aec4eca79802f2074f5d9746a8b3e33d56,32,5,9,10035,,,0,"Allow setting per-release mirrors for tests

For efficient testing it is desireable to specify a set of mirrors for
use by dib. Because the various elements use the same variable
(DIB_DISTROBUTION_MIRROR) there needs to be some logic about breaking
thos out into multiple variables.

Change-Id: I19d11ef0073a7d88b8bd08cb22ebbde7806f03af
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/91/279691/9 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_functions.bash', 'tests/elements/set-mirror/environment.d/90-set-mirror-env', 'tests/elements/set-mirror/extra-data.d/50-set-mirror-verify', 'tests/run_functests.sh']",4,04387971cba39137420115ace26be098d510fc50,feature/use-nodepool-info,"# Keep this here until we merge the project-config change to export this before our test is run if [ -f /etc/nodepool/provider ]; then # See http://docs.openstack.org/infra/nodepool/scripts.html#ready-script source /etc/nodepool/provider mirror_base=""http://mirror.$NODEPOOL_REGION.$NODEPOOL_CLOUD.openstack.org"" export DIB_TEST_UBUNTU_TRUSTY_MIRROR=${DIB_TEST_UBUNTU_MIRROR:-$mirror_base/ubuntu} export DIB_TEST_DISABLE_MIRROR_VERIFY=1 fi ",,22,2
